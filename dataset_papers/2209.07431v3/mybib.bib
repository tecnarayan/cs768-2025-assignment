
@article{lynch_task-evoked_2018,
	title = {Task-evoked functional connectivity does not explain functional connectivity differences between rest and task conditions},
	volume = {39},
	issn = {1065-9471},
	url = {https://doi.org/10.1002/hbm.24335},
	doi = {10.1002/hbm.24335},
	abstract = {Abstract During complex tasks, patterns of functional connectivity differ from those in the resting state. However, what accounts for such differences remains unclear. Brain activity during a task reflects an unknown mixture of spontaneous and task-evoked activities. The difference in functional connectivity between a task state and the resting state may reflect not only task-evoked functional connectivity, but also changes in spontaneously emerging networks. Here, we characterized the differences in apparent functional connectivity between the resting state and when human subjects were watching a naturalistic movie. Such differences were marginally explained by the task-evoked functional connectivity involved in processing the movie content. Instead, they were mostly attributable to changes in spontaneous networks driven by ongoing activity during the task. The execution of the task reduced the correlations in ongoing activity among different cortical networks, especially between the visual and non-visual sensory or motor cortices. Our results suggest that task-evoked activity is not independent from spontaneous activity, and that engaging in a task may suppress spontaneous activity and its inter-regional correlation.},
	number = {12},
	journal = {Human Brain Mapping},
	author = {Lynch, Lauren K and Lu, Kun-Han and Wen, Haiguang and Zhang, Yizhen and Saykin, Andrew J and Liu, Zhongming},
	month = aug,
	year = {2018},
	keywords = {natural vision, spontaneous activity, task evoked functional connectivity, task–rest interaction},
	pages = {4939--4948},
	annote = {doi: 10.1002/hbm.24335},
	file = {Attachment:/Users/tito/Zotero/storage/L6UVW7SD/Lynch et al. - 2018 - Task-evoked functional connectivity does not explain functional connectivity differences between rest and task con.pdf:application/pdf},
}

@article{aertsen_dynamics_1989,
	title = {Dynamics of neuronal firing correlation: modulation of" effective connectivity"},
	volume = {61},
	issn = {0022-3077},
	number = {5},
	journal = {Journal of neurophysiology},
	author = {Aertsen, A M and Gerstein, G L and Habib, M K and Palm, GwtcoPGK},
	year = {1989},
	pages = {900--917},
	file = {Attachment:/Users/tito/Zotero/storage/3I72LWC6/Aertsen et al. - 1989 - Dynamics of neuronal firing correlation modulation of effective connectivity.pdf:application/pdf},
}

@article{castelo-branco_synchronization_1998,
	title = {Synchronization of visual responses between the cortex, lateral geniculate nucleus, and retina in the anesthetized cat},
	volume = {18},
	issn = {0270-6474},
	number = {16},
	journal = {Journal of neuroscience},
	author = {Castelo-Branco, Miguel and Neuenschwander, Sergio and Singer, Wolf},
	year = {1998},
	pages = {6395--6410},
	file = {Attachment:/Users/tito/Zotero/storage/WGEA4TFX/Castelo-Branco, Neuenschwander, Singer - 1998 - Synchronization of visual responses between the cortex, lateral geniculate nucleus, and.pdf:application/pdf},
}

@article{paz_measuring_2009,
	title = {Measuring {Correlations} and {Interactions} {Among} {Four} {Simultaneously} {Recorded} {Brain} {Regions} {During} {Learning}},
	volume = {101},
	issn = {0022-3077},
	url = {http://www.physiology.org/doi/10.1152/jn.91259.2008},
	doi = {10.1152/jn.91259.2008},
	abstract = {Brain function depends on coordinated interactions in spatially distributed neuronal populations. Thanks to recent technological advances, it is now possible to monitor the activity of large groups of neurons. Although significant progress has been made in analyzing neuronal interactions across large samples of simultaneously recorded cells, most of the available approaches do not allow direct visualization of multidimensional correlations in the time domain. This study describes a novel analysis technique, termed four-dimensional spike-triggered joint histogram (4-d STJH) that permits the study of co-modulations of unit activity across four simultaneously recorded brain regions while preserving the time domain. To illustrate how this technique works, we recorded simultaneously from basolateral amygdala (BLA) and medial prefrontal (mPFC), as well as perirhinal and entorhinal neurons in animals learning an appetitive trace-conditioning task. Using the 4d-STJH, we show that coincident activity in the BLA and mPFC modulates the interactions between perirhinal and entorhinal neurons in a manner that cannot be explained by a linear combination of the individual BLA and mPFC-related modulations. We conclude with a discussion of the strengths and limitations of 4-d STJH and offer recommendations regarding optimal conditions for its use.},
	number = {5},
	journal = {Journal of Neurophysiology},
	author = {Paz, Rony and Bauer, Elizabeth P. and Paré, Denis},
	year = {2009},
	pmid = {19244352},
	pages = {2507--2515},
}

@book{caffo_survey_2018,
	series = {Major {Reference} {Works}},
	title = {A {Survey} of {Statistics} in the {Neurological} {Sciences} with a {Focus} on {Human} {Neuroimaging}},
	isbn = {978-1-118-44511-2},
	url = {https://doi.org/10.1002/9781118445112.stat08047},
	abstract = {Abstract Neuroscience is a vast subject; understanding the brain is one of the most complex, deep, and challenging tasks in all of science. In this article, we survey statistical contributions to the field of neuroscience, though focus heavily on human brain imaging. Statistics has made fundamental contributions in the processing and analysis of neuroscience and neuroimaging data. Contributions range from processing the measurements of new technologies to analyzing large groups of subjects and inference on the impact of behavior or disease. Developments in statistical algorithms and signal processing help in the pipeline that takes raw images and converts them to those used for diagnosis or research. Statistics has provided key protections from type I errors for the high-dimensional spatially correlated and complex data arising in this domain. In addition, novel modeling and testing approaches have allowed researchers to perform inference for this challenging data. We end the article with recommendations for statisticians and other quantitative scientists to get involved in this exciting and rapidly evolving field.},
	author = {Caffo, Brian and Zhao, Yi and Eloyan, Ani and Wang, Zeyi and Mejia, Amanda and Lindquist, Martin},
	month = nov,
	year = {2018},
	doi = {10.1002/9781118445112.stat08047},
	keywords = {error rate control, fMRI, group analysis, MRI, neuroimaging, preprocessing},
	annote = {doi:10.1002/9781118445112.stat08047},
}

@article{barrett_analyzing_2018,
	title = {Analyzing biological and artificial neural networks: challenges with opportunities for synergy?},
	journal = {arXiv preprint arXiv:1810.13373},
	author = {Barrett, David G T and Morcos, Ari S and Macke, Jakob H},
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/GJHMLBWF/Barrett, Morcos, Macke - 2018 - Analyzing biological and artificial neural networks challenges with opportunities for synergy.pdf:application/pdf},
}

@article{ciric_mitigating_2018,
	title = {Mitigating head motion artifact in functional connectivity {MRI}},
	volume = {13},
	issn = {1750-2799},
	url = {https://doi.org/10.1038/s41596-018-0065-y},
	doi = {10.1038/s41596-018-0065-y},
	abstract = {Participant motion during functional magnetic resonance image (fMRI) acquisition produces spurious signal fluctuations that can confound measures of functional connectivity. Without mitigation, motion artifact can bias statistical inferences about relationships between connectivity and individual differences. To counteract motion artifact, this protocol describes the implementation of a validated, high-performance denoising strategy that combines a set of model features, including physiological signals, motion estimates, and mathematical expansions, to target both widespread and focal effects of subject movement. This protocol can be used to reduce motion-related variance to near zero in studies of functional connectivity, providing up to a 100-fold improvement over minimal-processing approaches in large datasets. Image denoising requires 40 min to 4 h of computing per image, depending on model specifications and data dimensionality. The protocol additionally includes instructions for assessing the performance of a denoising strategy. Associated software implements all denoising and diagnostic procedures, using a combination of established image-processing libraries and the eXtensible Connectivity Pipeline (XCP) software.},
	number = {12},
	journal = {Nature Protocols},
	author = {Ciric, Rastko and Rosen, Adon F G and Erus, Guray and Cieslak, Matthew and Adebimpe, Azeez and Cook, Philip A and Bassett, Danielle S and Davatzikos, Christos and Wolf, Daniel H and Satterthwaite, Theodore D},
	year = {2018},
	pages = {2801--2826},
	file = {Attachment:/Users/tito/Zotero/storage/9SHK5G94/Ciric et al. - 2018 - Mitigating head motion artifact in functional connectivity MRI.pdf:application/pdf},
}

@article{ji_mapping_2019,
	title = {Mapping the human brain's cortical-subcortical functional network organization},
	volume = {185},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918319657},
	doi = {https://doi.org/10.1016/j.neuroimage.2018.10.006},
	abstract = {Understanding complex systems such as the human brain requires characterization of the system's architecture across multiple levels of organization – from neurons, to local circuits, to brain regions, and ultimately large-scale brain networks. Here we focus on characterizing the human brain's large-scale network organization, as it provides an overall framework for the organization of all other levels. We developed a highly principled approach to identify cortical network communities at the level of functional systems, calibrating our community detection algorithm using extremely well-established sensory and motor systems as guides. Building on previous network partitions, we replicated and expanded upon well-known and recently-identified networks, including several higher-order cognitive networks such as a left-lateralized language network. We expanded these cortical networks to subcortex, revealing 358 highly-organized subcortical parcels that take part in forming whole-brain functional networks. Notably, the identified subcortical parcels are similar in number to a recent estimate of the number of cortical parcels (360). This whole-brain network atlas – released as an open resource for the neuroscience community – places all brain structures across both cortex and subcortex into a single large-scale functional framework, with the potential to facilitate a variety of studies investigating large-scale functional networks in health and disease.},
	journal = {NeuroImage},
	author = {Ji, Jie Lisa and Spronk, Marjolein and Kulkarni, Kaustubh and Repovš, Grega and Anticevic, Alan and Cole, Michael W},
	year = {2019},
	keywords = {Brain connectivity, Brain networks, Functional MRI, Resting-state functional connectivity},
	pages = {35--57},
	file = {Attachment:/Users/tito/Zotero/storage/VYFNMG6M/Ji et al. - 2019 - Mapping the human brain's cortical-subcortical functional network organization.pdf:application/pdf},
}

@article{chen_brain-wide_2018,
	title = {Brain-wide {Organization} of {Neuronal} {Activity} and {Convergent} {Sensorimotor} {Transformations} in {Larval} {Zebrafish}},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318308444},
	doi = {https://doi.org/10.1016/j.neuron.2018.09.042},
	abstract = {Summary Simultaneous recordings of large populations of neurons in behaving animals allow detailed observation of high-dimensional, complex brain activity. However, experimental approaches often focus on singular behavioral paradigms or brain areas. Here, we recorded whole-brain neuronal activity of larval zebrafish presented with a battery of visual stimuli while recording fictive motor output. We identified neurons tuned to each stimulus type and motor output and discovered groups of neurons in the anterior hindbrain that respond to different stimuli eliciting similar behavioral responses. These convergent sensorimotor representations were only weakly correlated to instantaneous motor activity, suggesting that they critically inform, but do not directly generate, behavioral choices. To catalog brain-wide activity beyond explicit sensorimotor processing, we developed an unsupervised clustering technique that organizes neurons into functional groups. These analyses enabled a broad overview of the functional organization of the brain and revealed numerous brain nuclei whose neurons exhibit concerted activity patterns.},
	journal = {Neuron},
	author = {Chen, Xiuye and Mu, Yu and Hu, Yu and Kuan, Aaron T and Nikitchenko, Maxim and Randlett, Owen and Chen, Alex B and Gavornik, Jeffery P and Sompolinsky, Haim and Engert, Florian and Ahrens, Misha B},
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/96U83EAD/Chen et al. - 2018 - Brain-wide Organization of Neuronal Activity and Convergent Sensorimotor Transformations in Larval Zebrafish.pdf:application/pdf},
}

@article{di__characterizations_2015,
	title = {Characterizations of resting-state modulatory interactions in the human brain},
	volume = {114},
	issn = {0022-3077},
	url = {https://doi.org/10.1152/jn.00893.2014},
	doi = {10.1152/jn.00893.2014},
	abstract = {Functional connectivity between two brain regions, measured using functional MRI (fMRI), has been shown to be modulated by other regions even in a resting state, i.e., without performing specific tasks. We aimed to characterize large-scale modulatory interactions by performing region-of-interest (ROI)-based physiophysiological interaction analysis on resting-state fMRI data. Modulatory interactions were calculated for every possible combination of three ROIs among 160 ROIs sampling the whole brain. Firstly, among all of the significant modulatory interactions, there were considerably more negative than positive effects; i.e., in more cases, an increase of activity in one region was associated with decreased functional connectivity between two other regions. Next, modulatory interactions were categorized as to whether the three ROIs were from one single network module, two modules, or three different modules (defined by a modularity analysis on their functional connectivity). Positive modulatory interactions were more represented than expected in cases in which the three ROIs were from a single module, suggesting an increase within module processing efficiency through positive modulatory interactions. In contrast, negative modulatory interactions were more represented than expected in cases in which the three ROIs were from two modules, suggesting a tendency of between-module segregation through negative modulatory interactions. Regions that were more likely to have modulatory interactions were then identified. The numbers of significant modulatory interactions for different regions were correlated with the regions' connectivity strengths and connection degrees. These results demonstrate whole-brain characteristics of modulatory interactions and may provide guidance for future studies of connectivity dynamics in both resting state and task state.},
	number = {5},
	journal = {Journal of Neurophysiology},
	author = {Di (邸新), Xin and Biswal, Bharat B},
	month = sep,
	year = {2015},
	pages = {2785--2796},
	annote = {doi: 10.1152/jn.00893.2014},
	file = {Attachment:/Users/tito/Zotero/storage/IQ9TNZP6/Di (邸新), Biswal - 2015 - Characterizations of resting-state modulatory interactions in the human brain.pdf:application/pdf},
}

@article{scholvinck_cortical_2015,
	title = {Cortical {State} {Determines} {Global} {Variability} and {Correlations} in {Visual} {Cortex}},
	volume = {35},
	url = {http://www.jneurosci.org/content/35/1/170.abstract},
	abstract = {The response of neurons in sensory cortex to repeated stimulus presentations is highly variable. To investigate the nature of this variability, we compared the spike activity of neurons in the primary visual cortex (V1) of cats with that of their afferents from lateral geniculate nucleus (LGN), in response to similar stimuli. We found variability to be much higher in V1 than in LGN. To investigate the sources of the additional variability, we measured the spiking activity of large V1 populations and found that much of the variability was shared across neurons: the variable portion of the responses of one neuron could be well predicted from the summed activity of the rest of the neurons. Variability thus mostly reflected global fluctuations affecting all neurons. The size and prevalence of these fluctuations, both in responses to stimuli and in ongoing activity, depended on cortical state, being larger in synchronized states than in more desynchronized states. Contrary to previous reports, these fluctuations invested the overall population, regardless of preferred orientation. The global fluctuations substantially increased variability in single neurons and correlations among pairs of neurons. Once this effect was removed, pairwise correlations were reduced and were similar regardless of cortical state. These results highlight the importance of cortical state in controlling cortical operation and can help reconcile previous studies, which differed widely in their estimate of neuronal variability and pairwise correlations.},
	number = {1},
	journal = {The Journal of Neuroscience},
	author = {Schölvinck, Marieke L and Saleem, Aman B and Benucci, Andrea and Harris, Kenneth D and Carandini, Matteo},
	month = jan,
	year = {2015},
	pages = {170 LP -- 178},
}

@article{franke_structures_2016,
	title = {Structures of {Neural} {Correlation} and {How} {They} {Favor} {Coding}},
	volume = {89},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627315011393},
	doi = {https://doi.org/10.1016/j.neuron.2015.12.037},
	abstract = {Summary The neural representation of information suffers from “noise”—the trial-to-trial variability in the response of neurons. The impact of correlated noise upon population coding has been debated, but a direct connection between theory and experiment remains tenuous. Here, we substantiate this connection and propose a refined theoretical picture. Using simultaneous recordings from a population of direction-selective retinal ganglion cells, we demonstrate that coding benefits from noise correlations. The effect is appreciable already in small populations, yet it is a collective phenomenon. Furthermore, the stimulus-dependent structure of correlation is key. We develop simple functional models that capture the stimulus-dependent statistics. We then use them to quantify the performance of population coding, which depends upon interplays of feature sensitivities and noise correlations in the population. Because favorable structures of correlation emerge robustly in circuits with noisy, nonlinear elements, they will arise and benefit coding beyond the confines of retina.},
	number = {2},
	journal = {Neuron},
	author = {Franke, Felix and Fiscella, Michele and Sevelev, Maksim and Roska, Botond and Hierlemann, Andreas and Azeredo da Silveira, Rava},
	year = {2016},
	pages = {409--422},
	file = {Attachment:/Users/tito/Zotero/storage/DU67TEDA/Franke et al. - 2016 - Structures of Neural Correlation and How They Favor Coding.pdf:application/pdf},
}

@article{kim_role_2017,
	title = {Role of graph architecture in controlling dynamical networks with applications to neural systems},
	volume = {14},
	url = {http://dx.doi.org/10.1038/nphys4268 http://10.0.4.14/nphys4268 https://www.nature.com/articles/nphys4268#supplementary-information},
	journal = {Nature Physics},
	author = {Kim, Jason Z and Soffer, Jonathan M and Kahn, Ari E and Vettel, Jean M and Pasqualetti, Fabio and Bassett, Danielle S},
	month = sep,
	year = {2017},
	pages = {91},
	file = {Attachment:/Users/tito/Zotero/storage/ZCZF6V6E/Kim et al. - 2017 - Role of graph architecture in controlling dynamical networks with applications to neural systems.pdf:application/pdf},
}

@article{tan_sensory_2014,
	title = {Sensory stimulation shifts visual cortex from synchronous to asynchronous states},
	volume = {509},
	url = {http://dx.doi.org/10.1038/nature13159 http://10.0.4.14/nature13159 https://www.nature.com/articles/nature13159#supplementary-information},
	journal = {Nature},
	author = {Tan, Andrew Y Y and Chen, Yuzhi and Scholl, Benjamin and Seidemann, Eyal and Priebe, Nicholas J},
	month = mar,
	year = {2014},
	pages = {226},
	file = {Attachment:/Users/tito/Zotero/storage/5YP7QDKC/Tan et al. - 2014 - Sensory stimulation shifts visual cortex from synchronous to asynchronous states.pdf:application/pdf},
}

@article{garrett_local_2018,
	title = {Local temporal variability reflects functional integration in the human brain},
	volume = {183},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918307171},
	doi = {https://doi.org/10.1016/j.neuroimage.2018.08.019},
	abstract = {Local moment-to-moment variability exists at every level of neural organization, but its driving forces remain opaque. Inspired by animal work demonstrating that local temporal variability may reflect synaptic input rather than locally-generated “noise,” we used publicly-available high-temporal-resolution fMRI data (N = 100 adults; 33 males) to test in humans whether greater BOLD signal variability in local brain regions was associated with functional integration (estimated via spatiotemporal PCA dimensionality). Using a multivariate partial least squares analysis, we indeed found that individuals with higher local temporal variability had a more integrated (lower dimensional) network fingerprint. Notably, temporal variability in the thalamus showed the strongest negative association with PCA dimensionality. Previous animal work also shows that local variability may upregulate from thalamus to visual cortex; however, such principled upregulation from thalamus to cortex has not been demonstrated in humans. In the current study, we rather establish a more general putative dynamic role of the thalamus by demonstrating that greater within-person thalamo-cortical upregulation in variability is itself a unique hallmark of greater functional integration that cannot be accounted for by local fluctuations in several other well-known integrative-hub regions. Our findings indicate that local variability primarily reflects functional integration, and establish a fundamental role for the thalamus in how the brain fluctuates and communicates across moments.},
	journal = {NeuroImage},
	author = {Garrett, Douglas D and Epp, Samira M and Perry, Alistair and Lindenberger, Ulman},
	year = {2018},
	keywords = {fMRI, Brain signal variability, Network dimensionality, Neural dynamics},
	pages = {776--787},
	file = {Attachment:/Users/tito/Zotero/storage/IN8QNFAS/Garrett et al. - 2018 - Local temporal variability reflects functional integration in the human brain.pdf:application/pdf},
}

@article{ni_learning_2018,
	title = {Learning and attention reveal a general relationship between population activity and behavior},
	volume = {359},
	url = {http://science.sciencemag.org/content/359/6374/463.abstract},
	abstract = {The responses of pairs of neurons to repeated presentations of the same stimulus are typically correlated, and an identical neuronal population can perform many functions. This suggests that the relevant units of computation are not single neurons but subspaces of the complete population activity. To test this idea, Ni et al. measured the relationship between neuronal population activity and performance in monkeys. They investigated attention, which improves perception of attended stimuli, and perceptual learning, which improves perception of well-practiced stimuli. These two processes operate on different time scales and are usually studied using different perceptual tasks. Manipulation of attention and learning in the same behavioral trials and the same neuronal populations revealed the dimensions of population activity that matter most for behavior.Science, this issue p. 463Prior studies have demonstrated that correlated variability changes with cognitive processes that improve perceptual performance. We tested whether correlated variability covaries with subjects' performance—whether performance improves quickly with attention or slowly with perceptual learning. We found a single, consistent relationship between correlated variability and behavioral performance, regardless of the time frame of correlated variability change. This correlated variability was oriented along the dimensions in population space used by the animal on a trial-by-trial basis to make decisions. That subjects' choices were predicted by specific dimensions that were aligned with the correlated variability axis clarifies long-standing paradoxes about the relationship between shared variability and behavior.},
	number = {6374},
	journal = {Science},
	author = {Ni, A M and Ruff, D A and Alberts, J J and Symmonds, J and Cohen, M R},
	month = jan,
	year = {2018},
	pages = {463 LP -- 465},
	file = {Attachment:/Users/tito/Zotero/storage/Q6NG2L3Q/Ni et al. - 2018 - Learning and attention reveal a general relationship between population activity and behavior.pdf:application/pdf},
}

@article{cohen_attention_2009,
	title = {Attention improves performance primarily by reducing interneuronal correlations},
	volume = {12},
	url = {http://dx.doi.org/10.1038/nn.2439 http://10.0.4.14/nn.2439 https://www.nature.com/articles/nn.2439#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Cohen, Marlene R and Maunsell, John H R},
	month = nov,
	year = {2009},
	pages = {1594},
	file = {Attachment:/Users/tito/Zotero/storage/T6JK3BEE/Cohen, Maunsell - 2009 - Attention improves performance primarily by reducing interneuronal correlations.pdf:application/pdf},
}

@article{behzadi_component_2007,
	title = {A component based noise correction method ({CompCor}) for {BOLD} and perfusion based {fMRI}},
	volume = {37},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811907003837},
	doi = {https://doi.org/10.1016/j.neuroimage.2007.04.042},
	abstract = {A component based method (CompCor) for the reduction of noise in both blood oxygenation level-dependent (BOLD) and perfusion-based functional magnetic resonance imaging (fMRI) data is presented. In the proposed method, significant principal components are derived from noise regions-of-interest (ROI) in which the time series data are unlikely to be modulated by neural activity. These components are then included as nuisance parameters within general linear models for BOLD and perfusion-based fMRI time series data. Two approaches for the determination of the noise ROI are considered. The first method uses high-resolution anatomical data to define a region of interest composed primarily of white matter and cerebrospinal fluid, while the second method defines a region based upon the temporal standard deviation of the time series data. With the application of CompCor, the temporal standard deviation of resting-state perfusion and BOLD data in gray matter regions was significantly reduced as compared to either no correction or the application of a previously described retrospective image based correction scheme (RETROICOR). For both functional perfusion and BOLD data, the application of CompCor significantly increased the number of activated voxels as compared to no correction. In addition, for functional BOLD data, there were significantly more activated voxels detected with CompCor as compared to RETROICOR. In comparison to RETROICOR, CompCor has the advantage of not requiring external monitoring of physiological fluctuations.},
	number = {1},
	journal = {NeuroImage},
	author = {Behzadi, Yashar and Restom, Khaled and Liau, Joy and Liu, Thomas T},
	year = {2007},
	pages = {90--101},
	file = {Attachment:/Users/tito/Zotero/storage/7DWJFK4H/Behzadi et al. - 2007 - A component based noise correction method (CompCor) for BOLD and perfusion based fMRI.pdf:application/pdf},
}

@article{van_dijk_influence_2012,
	title = {The influence of head motion on intrinsic functional connectivity {MRI}},
	volume = {59},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811911008214},
	doi = {https://doi.org/10.1016/j.neuroimage.2011.07.044},
	abstract = {Functional connectivity MRI (fcMRI) has been widely applied to explore group and individual differences. A confounding factor is head motion. Children move more than adults, older adults more than younger adults, and patients more than controls. Head motion varies considerably among individuals within the same population. Here we explored the influence of head motion on fcMRI estimates. Mean head displacement, maximum head displacement, the number of micro movements ({\textbackslash}textgreater0.1mm), and head rotation were estimated in 1000 healthy, young adult subjects each scanned for two resting-state runs on matched 3T scanners. The majority of fcMRI variation across subjects was not linked to head motion. However, head motion had significant, systematic effects on fcMRI network measures. Head motion was associated with decreased functional coupling in the default and frontoparietal control networks — two networks characterized by coupling among distributed regions of association cortex. Other network measures increased with motion including estimates of local functional coupling and coupling between left and right motor regions — a region pair sometimes used as a control in studies to establish specificity. Comparisons between groups of individuals with subtly different levels of head motion yielded difference maps that could be mistaken for neuronal effects in other contexts. These effects are important to consider when interpreting variation between groups and across individuals.},
	number = {1},
	journal = {NeuroImage},
	author = {Van Dijk, Koene R A and Sabuncu, Mert R and Buckner, Randy L},
	year = {2012},
	keywords = {Functional MRI, BOLD, Connectome, Movement, Resting-state},
	pages = {431--438},
	file = {Attachment:/Users/tito/Zotero/storage/GVBMKQIU/Van Dijk, Sabuncu, Buckner - 2012 - The influence of head motion on intrinsic functional connectivity MRI.pdf:application/pdf},
}

@article{muschelli_reduction_2014,
	title = {Reduction of motion-related artifacts in resting state {fMRI} using {aCompCor}},
	volume = {96},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191400175X},
	doi = {https://doi.org/10.1016/j.neuroimage.2014.03.028},
	abstract = {Recent studies have illustrated that motion-related artifacts remain in resting-state fMRI (rs-fMRI) data even after common corrective processing procedures have been applied, but the extent to which head motion distorts the data may be modulated by the corrective approach taken. We compare two different methods for estimating nuisance signals from tissues not expected to exhibit BOLD fMRI signals of neuronal origin: 1) the more commonly used mean signal method and 2) the principal components analysis approach (aCompCor: Behzadi et al., 2007). Further, we investigate the added benefit of “scrubbing” (Power et al., 2012) following both methods. We demonstrate that the use of aCompCor removes motion artifacts more effectively than tissue-mean signal regression. In addition, inclusion of more components from anatomically defined regions of no interest better mitigates motion-related artifacts and improves the specificity of functional connectivity estimates. While scrubbing further attenuates motion-related artifacts when mean signals are used, scrubbing provides no additional benefit in terms of motion artifact reduction or connectivity specificity when using aCompCor.},
	journal = {NeuroImage},
	author = {Muschelli, John and Nebel, Mary Beth and Caffo, Brian S and Barber, Anita D and Pekar, James J and Mostofsky, Stewart H},
	year = {2014},
	keywords = {Head motion, Nuisance regression, Resting state fMRI, Specificity},
	pages = {22--35},
	file = {Attachment:/Users/tito/Zotero/storage/C5B7FAFL/Muschelli et al. - 2014 - Reduction of motion-related artifacts in resting state fMRI using aCompCor.pdf:application/pdf},
}

@article{chai_anticorrelations_2012,
	title = {Anticorrelations in resting state networks without global signal regression},
	volume = {59},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811911009657},
	doi = {https://doi.org/10.1016/j.neuroimage.2011.08.048},
	abstract = {Anticorrelated relationships in spontaneous signal fluctuation have been previously observed in resting-state functional magnetic resonance imaging (fMRI). In particular, it was proposed that there exists two systems in the brain that are intrinsically organized into anticorrelated networks, the default mode network, which usually exhibits task-related deactivations, and the task-positive network, which usually exhibits task-related activations during tasks that demands external attention. However, it is currently under debate whether the anticorrelations observed in resting state fMRI were valid or were instead artificially introduced by global signal regression, a common preprocessing technique to remove physiological and other noise in resting-state fMRI signal. We examined positive and negative correlations in resting-state connectivity using two different preprocessing methods: a component base noise reduction method (CompCor, Behzadi et al., 2007), in which principal components from noise regions-of-interest were removed, and the global signal regression method. Robust anticorrelations between a default mode network seed region in the medial prefrontal cortex and regions of the task-positive network were observed under both methods. Specificity of the anticorrelations was similar between the two methods. Specificity and sensitivity for positive correlations were higher under CompCor compared to the global regression method. Our results suggest that anticorrelations observed in resting-state connectivity are not an artifact introduced by global signal regression and might have biological origins, and that the CompCor method can be used to examine valid anticorrelations during rest.},
	number = {2},
	journal = {NeuroImage},
	author = {Chai, Xiaoqian J and Castañón, Alfonso Nieto and Öngür, Dost and Whitfield-Gabrieli, Susan},
	year = {2012},
	keywords = {fMRI, Default mode network, Functional connectivity, Negative correlations, Physiological noise, Task-positive network},
	pages = {1420--1428},
	file = {Attachment:/Users/tito/Zotero/storage/PCHI664W/Chai et al. - 2012 - Anticorrelations in resting state networks without global signal regression.pdf:application/pdf},
}

@article{kohn_correlations_2016,
	title = {Correlations and {Neuronal} {Population} {Information}},
	volume = {39},
	issn = {0147-006X},
	url = {https://doi.org/10.1146/annurev-neuro-070815-013851},
	doi = {10.1146/annurev-neuro-070815-013851},
	abstract = {Brain function involves the activity of neuronal populations. Much recent effort has been devoted to measuring the activity of neuronal populations in different parts of the brain under various experimental conditions. Population activity patterns contain rich structure, yet many studies have focused on measuring pairwise relationships between members of a larger population?termed noise correlations. Here we review recent progress in understanding how these correlations affect population information, how information should be quantified, and what mechanisms may give rise to correlations. As population coding theory has improved, it has made clear that some forms of correlation are more important for information than others. We argue that this is a critical lesson for those interested in neuronal population responses more generally: Descriptions of population responses should be motivated by and linked to well-specified function. Within this context, we offer suggestions of where current theoretical frameworks fall short.},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Kohn, Adam and Coen-Cagli, Ruben and Kanitscheider, Ingmar and Pouget, Alexandre},
	month = jul,
	year = {2016},
	pages = {237--256},
	annote = {doi: 10.1146/annurev-neuro-070815-013851},
	file = {Attachment:/Users/tito/Zotero/storage/U4TSLD9Z/Kohn et al. - 2016 - Correlations and Neuronal Population Information.pdf:application/pdf;Full Text PDF:/Users/tito/Zotero/storage/S69NC9SY/Kohn et al. - 2016 - Correlations and Neuronal Population Information.pdf:application/pdf},
}

@article{jenkinson_improved_2002,
	title = {Improved {Optimization} for the {Robust} and {Accurate} {Linear} {Registration} and {Motion} {Correction} of {Brain} {Images}},
	volume = {17},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811902911328},
	doi = {https://doi.org/10.1006/nimg.2002.1132},
	abstract = {Linear registration and motion correction are important components of structural and functional brain image analysis. Most modern methods optimize some intensity-based cost function to determine the best registration. To date, little attention has been focused on the optimization method itself, even though the success of most registration methods hinges on the quality of this optimization. This paper examines the optimization process in detail and demonstrates that the commonly used multiresolution local optimization methods can, and do, get trapped in local minima. To address this problem, two approaches are taken: (1) to apodize the cost function and (2) to employ a novel hybrid global–local optimization method. This new optimization method is specifically designed for registering whole brain images. It substantially reduces the likelihood of producing misregistrations due to being trapped by local minima. The increased robustness of the method, compared to other commonly used methods, is demonstrated by a consistency test. In addition, the accuracy of the registration is demonstrated by a series of experiments with motion correction. These motion correction experiments also investigate how the results are affected by different cost functions and interpolation methods.},
	number = {2},
	journal = {NeuroImage},
	author = {Jenkinson, Mark and Bannister, Peter and Brady, Michael and Smith, Stephen},
	year = {2002},
	keywords = {accuracy, affine transformation, global optimization, motion correction, multimodal registration, multiresolution search, robustness},
	pages = {825--841},
	file = {Attachment:/Users/tito/Zotero/storage/PICLAURS/Jenkinson et al. - 2002 - Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images.pdf:application/pdf},
}

@article{moreno-bote_information-limiting_2014,
	title = {Information-limiting correlations},
	volume = {17},
	url = {http://dx.doi.org/10.1038/nn.3807 http://10.0.4.14/nn.3807 https://www.nature.com/articles/nn.3807#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Moreno-Bote, Rubén and Beck, Jeffrey and Kanitscheider, Ingmar and Pitkow, Xaq and Latham, Peter and Pouget, Alexandre},
	month = sep,
	year = {2014},
	pages = {1410},
	file = {Attachment:/Users/tito/Zotero/storage/K9DVG4A6/Moreno-Bote et al. - 2014 - Information-limiting correlations.pdf:application/pdf},
}

@article{mongillo_inhibitory_2018,
	title = {Inhibitory connectivity defines the realm of excitatory plasticity},
	issn = {1546-1726},
	url = {https://doi.org/10.1038/s41593-018-0226-x},
	doi = {10.1038/s41593-018-0226-x},
	abstract = {Recent experiments demonstrate substantial volatility of excitatory connectivity in the absence of any learning. This challenges the hypothesis that stable synaptic connections are necessary for long-term maintenance of acquired information. Here we measure ongoing synaptic volatility and use theoretical modeling to study its consequences on cortical dynamics. We show that in the balanced cortex, patterns of neural activity are primarily determined by inhibitory connectivity, despite the fact that most synapses and neurons are excitatory. Similarly, we show that the inhibitory network is more effective in storing memory patterns than the excitatory one. As a result, network activity is robust to ongoing volatility of excitatory synapses, as long as this volatility does not disrupt the balance between excitation and inhibition. We thus hypothesize that inhibitory connectivity, rather than excitatory, controls the maintenance and loss of information over long periods of time in the volatile cortex.},
	journal = {Nature Neuroscience},
	author = {Mongillo, Gianluigi and Rumpel, Simon and Loewenstein, Yonatan},
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/8ZJYBHSY/Mongillo, Rumpel, Loewenstein - 2018 - Inhibitory connectivity defines the realm of excitatory plasticity.pdf:application/pdf},
}

@article{rubin_stabilized_2015,
	title = {The {Stabilized} {Supralinear} {Network}: {A} {Unifying} {Circuit} {Motif} {Underlying} {Multi}-{Input} {Integration} in {Sensory} {Cortex}},
	volume = {85},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627314011350},
	doi = {https://doi.org/10.1016/j.neuron.2014.12.026},
	abstract = {Summary Neurons in sensory cortex integrate multiple influences to parse objects and support perception. Across multiple cortical areas, integration is characterized by two neuronal response properties: (1) surround suppression—modulatory contextual stimuli suppress responses to driving stimuli; and (2) “normalization”—responses to multiple driving stimuli add sublinearly. These depend on input strength: for weak driving stimuli, contextual influences facilitate or more weakly suppress and summation becomes linear or supralinear. Understanding the circuit operations underlying integration is critical to understanding cortical function and disease. We present a simple, general theory. A wealth of integrative properties, including the above, emerge robustly from four cortical circuit properties: (1) supralinear neuronal input/output functions; (2) sufficiently strong recurrent excitation; (3) feedback inhibition; and (4) simple spatial properties of intracortical connections. Integrative properties emerge dynamically as circuit properties, with excitatory and inhibitory neurons showing similar behaviors. In new recordings in visual cortex, we confirm key model predictions.},
	number = {2},
	journal = {Neuron},
	author = {Rubin, Daniel B. and Van Hooser, Stephen D. and Miller, Kenneth D.},
	year = {2015},
	pages = {402--417},
	file = {Attachment:/Users/tito/Zotero/storage/CTTX4CGY/Rubin, Van Hooser, Miller - 2015 - The Stabilized Supralinear Network A Unifying Circuit Motif Underlying Multi-Input Integration in Sen.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Y4QB8RQT/Rubin, Van Hooser, Miller - 2015 - The Stabilized Supralinear Network A Unifying Circuit Motif Underlying Multi-Input Integration in Sen.pdf:application/pdf},
}

@article{priebe_inhibition_2008,
	title = {Inhibition, {Spike} {Threshold}, and {Stimulus} {Selectivity} in {Primary} {Visual} {Cortex}},
	volume = {57},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627308001268},
	doi = {https://doi.org/10.1016/j.neuron.2008.02.005},
	abstract = {Ever since Hubel and Wiesel described orientation selectivity in the visual cortex, the question of how precise selectivity emerges has been marked by considerable debate. There are essentially two views of how selectivity arises. Feed-forward models rely entirely on the organization of thalamocortical inputs. Feedback models rely on lateral inhibition to refine selectivity relative to a weak bias provided by thalamocortical inputs. The debate is driven by two divergent lines of evidence. On the one hand, many response properties appear to require lateral inhibition, including precise orientation and direction selectivity and crossorientation suppression. On the other hand, intracellular recordings have failed to find consistent evidence for lateral inhibition. Here we demonstrate a resolution to this paradox. Feed-forward models incorporating the intrinsic nonlinear properties of cortical neurons and feed-forward circuits (i.e., spike threshold, contrast saturation, and spike-rate rectification) can account for properties that have previously appeared to require lateral inhibition.},
	number = {4},
	journal = {Neuron},
	author = {Priebe, Nicholas J and Ferster, David},
	year = {2008},
	pages = {482--497},
	file = {Attachment:/Users/tito/Zotero/storage/WMIRU8KH/Priebe, Ferster - 2008 - Inhibition, Spike Threshold, and Stimulus Selectivity in Primary Visual Cortex.pdf:application/pdf},
}

@article{miller_canonical_2016,
	title = {Canonical computations of cerebral cortex},
	volume = {37},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S095943881600009X},
	doi = {https://doi.org/10.1016/j.conb.2016.01.008},
	abstract = {The idea that there is a fundamental cortical circuit that performs canonical computations remains compelling though far from proven. Here we review evidence for two canonical operations within sensory cortical areas: a feedforward computation of selectivity; and a recurrent computation of gain in which, given sufficiently strong external input, perhaps from multiple sources, intracortical input largely, but not completely, cancels this external input. This operation leads to many characteristic cortical nonlinearities in integrating multiple stimuli. The cortical computation must combine such local processing with hierarchical processing across areas. We point to important changes in moving from sensory cortex to motor and frontal cortex and the possibility of substantial differences between cortex in rodents vs. species with columnar organization of selectivity.},
	journal = {Current Opinion in Neurobiology},
	author = {Miller, Kenneth D},
	year = {2016},
	pages = {75--84},
	file = {Attachment:/Users/tito/Zotero/storage/YLATLS5H/Miller - 2016 - Canonical computations of cerebral cortex.pdf:application/pdf},
}

@article{constantinidis_correlated_2002,
	title = {Correlated {Discharges} {Among} {Putative} {Pyramidal} {Neurons} and {Interneurons} in the {Primate} {Prefrontal} {Cortex}},
	volume = {88},
	issn = {0022-3077},
	url = {https://doi.org/10.1152/jn.00188.2002},
	doi = {10.1152/jn.00188.2002},
	abstract = {Neurophysiological recordings have revealed that the discharges of nearby cortical cells are positively correlated in time scales that range from millisecond synchronization of action potentials to much slower firing rate co-variations, evident in rates averaged over hundreds of milliseconds. The presence of correlated firing can offer insights into the patterns of connectivity between neurons; however, few models of population coding have taken account of the neuronal diversity present in cerebral cortex, notably a distinction between inhibitory and excitatory cells. We addressed this question in the monkey dorsolateral prefrontal cortex by recording neuronal activity from multiple micro-electrodes, typically spaced 0.2?0.3 mm apart. Putative excitatory and inhibitory neurons were distinguished based on their action potential waveform and baseline discharge rate. We tested each pair of simultaneously recorded neurons for presence of significant cross-correlation peaks and measured the correlation of their averaged firing rates in successive trials. When observed, cross-correlation peaks were centered attime 0, indicating synchronous firing consistent with two neurons receiving common input. Discharges in pairs of putative inhibitory interneurons were found to be significantly more strongly correlated than in pairs of putative excitatory cells. The degree of correlated firing was also higher for neurons with similar spatial receptive fields and neurons active in the same epochs of the behavioral task. These factors were important in predicting the strength of both short time scale ({\textbackslash}textless5 ms) correlations and of trial-to-trial discharge rate covariations. Correlated firing was only marginally accounted for by motor and behavioral variations between trials. Our findings suggest that nearby inhibitory neurons are more tightly synchronized than excitatory ones and account for much of the correlated discharges commonly observed in undifferentiated cortical networks. In contrast, the discharge of pyramidal neurons, the sole projection cells of the cerebral cortex, appears largely independent, suggesting that correlated firing may be a property confined within local circuits and only to a lesser degree propagated to distant cortical areas and modules.},
	number = {6},
	journal = {Journal of Neurophysiology},
	author = {Constantinidis, Christos and Goldman-Rakic, Patricia S},
	month = dec,
	year = {2002},
	pages = {3487--3497},
	annote = {doi: 10.1152/jn.00188.2002},
	annote = {doi: 10.1152/jn.00188.2002},
	file = {Attachment:/Users/tito/Zotero/storage/7LFX6QHH/Constantinidis, Goldman-Rakic - 2002 - Correlated Discharges Among Putative Pyramidal Neurons and Interneurons in the Primate Prefrontal.pdf:application/pdf},
}

@book{kass_analysis_2014,
	title = {Analysis of neural data},
	volume = {491},
	publisher = {Springer},
	author = {Kass, Robert E and Eden, Uri T and Brown, Emery N},
	year = {2014},
}

@article{kriegeskorte_cognitive_2018,
	title = {Cognitive computational neuroscience},
	volume = {21},
	issn = {1546-1726},
	url = {https://doi.org/10.1038/s41593-018-0210-5},
	doi = {10.1038/s41593-018-0210-5},
	abstract = {To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments. Cognitive science has developed computational models that decompose cognition into functional components. Computational neuroscience has modeled how interacting neurons can implement elementary components of cognition. It is time to assemble the pieces of the puzzle of brain computation and to better integrate these separate disciplines. Modern technologies enable us to measure and manipulate brain activity in unprecedentedly rich ways in animals and humans. However, experiments will yield theoretical insight only when employed to test brain-computational models. Here we review recent work in the intersection of cognitive science, computational neuroscience and artificial intelligence. Computational models that mimic brain information processing during perceptual, cognitive and control tasks are beginning to be developed and tested with brain and behavioral data.},
	number = {9},
	journal = {Nature Neuroscience},
	author = {Kriegeskorte, Nikolaus and Douglas, Pamela K},
	year = {2018},
	pages = {1148--1160},
	file = {Attachment:/Users/tito/Zotero/storage/WU4AJLUF/Kriegeskorte, Douglas - 2018 - Cognitive computational neuroscience.pdf:application/pdf},
}

@article{jacobs_cortical_2018,
	title = {Cortical state fluctuations during sensory decision making},
	url = {http://biorxiv.org/content/early/2018/06/17/348193.1.abstract},
	abstract = {Neocortical activity varies between states of "synchronization" and "desynchronization", with desynchronized states believed to occur specifically in regions engaged by the task. To disambiguate whether desynchronization is linked to task performance or engagement, we trained mice on tasks in which incorrect responses due to disengagement (neglect) differed from inaccurate task performance (incorrect choices). Using widefield calcium imaging to measure cortical state across many areas simultaneously, we found that desynchronization was correlated with engagement rather than accuracy. Consistent with this link between desynchronization and engagement, we found that rewards had a long-lasting desynchronizing effect. To determine whether engagement-related changes in cortical state depended on the sensory modality, we trained mice on visual and auditory task versions and found that desynchronization was similar in both and more pronounced in somatomotor than either sensory cortex. We conclude that variations in cortical state are predominately global and closely relate to variations in task engagement.},
	journal = {bioRxiv},
	author = {Jacobs, Elina A K and Steinmetz, Nicholas A and Carandini, Matteo and Harris, Kenneth D},
	month = jan,
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/ZC3H8VKQ/Jacobs et al. - 2018 - Cortical state fluctuations during sensory decision making.pdf:application/pdf},
}

@article{ryali_multivariate_2011,
	title = {Multivariate dynamical systems models for estimating causal interactions in {fMRI}},
	volume = {54},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910012528},
	doi = {https://doi.org/10.1016/j.neuroimage.2010.09.052},
	abstract = {Analysis of dynamical interactions between distributed brain areas is of fundamental importance for understanding cognitive information processing. However, estimating dynamic causal interactions between brain regions using functional magnetic resonance imaging (fMRI) poses several unique challenges. For one, fMRI measures Blood Oxygenation Level Dependent (BOLD) signals, rather than the underlying latent neuronal activity. Second, regional variations in the hemodynamic response function (HRF) can significantly influence estimation of causal interactions between them. Third, causal interactions between brain regions can change with experimental context over time. To overcome these problems, we developed a novel state-space Multivariate Dynamical Systems (MDS) model to estimate intrinsic and experimentally-induced modulatory causal interactions between multiple brain regions. A probabilistic graphical framework is then used to estimate the parameters of MDS as applied to fMRI data. We show that MDS accurately takes into account regional variations in the HRF and estimates dynamic causal interactions at the level of latent signals. We develop and compare two estimation procedures using maximum likelihood estimation (MLE) and variational Bayesian (VB) approaches for inferring model parameters. Using extensive computer simulations, we demonstrate that, compared to Granger causal analysis (GCA), MDS exhibits superior performance for a wide range of signal to noise ratios (SNRs), sample length and network size. Our simulations also suggest that GCA fails to uncover causal interactions when there is a conflict between the direction of intrinsic and modulatory influences. Furthermore, we show that MDS estimation using VB methods is more robust and performs significantly better at low SNRs and shorter time series than MDS with MLE. Our study suggests that VB estimation of MDS provides a robust method for estimating and interpreting causal network interactions in fMRI data.},
	number = {2},
	journal = {NeuroImage},
	author = {Ryali, Srikanth and Supekar, Kaustubh and Chen, Tianwen and Menon, Vinod},
	year = {2011},
	keywords = {Bilinear, Causality, Deconvolution, Dynamical systems, Expectation maximization, Kalman smoother, Variational Bayes},
	pages = {807--823},
	file = {Attachment:/Users/tito/Zotero/storage/UWDMFQA5/Ryali et al. - 2011 - Multivariate dynamical systems models for estimating causal interactions in fMRI.pdf:application/pdf},
}

@article{hennequin_inhibitory_2017,
	title = {Inhibitory {Plasticity}: {Balance}, {Control}, and {Codependence}},
	volume = {40},
	issn = {0147-006X},
	url = {https://doi.org/10.1146/annurev-neuro-072116-031005},
	doi = {10.1146/annurev-neuro-072116-031005},
	abstract = {Inhibitory neurons, although relatively few in number, exert powerful control over brain circuits. They stabilize network activity in the face of strong feedback excitation and actively engage in computations. Recent studies reveal the importance of a precise balance of excitation and inhibition in neural circuits, which often requires exquisite fine-tuning of inhibitory connections. We review inhibitory synaptic plasticity and its roles in shaping both feedforward and feedback control. We discuss the necessity of complex, codependent plasticity mechanisms to build nontrivial, functioning networks, and we end by summarizing experimental evidence of such interactions.},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Hennequin, Guillaume and Agnes, Everton J and Vogels, Tim P},
	month = jul,
	year = {2017},
	pages = {557--579},
	annote = {doi: 10.1146/annurev-neuro-072116-031005},
	file = {Attachment:/Users/tito/Zotero/storage/UA9A458R/Hennequin, Agnes, Vogels - 2017 - Inhibitory Plasticity Balance, Control, and Codependence.pdf:application/pdf},
}

@article{yang_dataset_2018,
	title = {A dataset and architecture for visual reasoning with a working memory},
	journal = {arXiv preprint arXiv:1803.06092},
	author = {Yang, Guangyu Robert and Ganichev, Igor and Wang, Xiao-Jing and Shlens, Jonathon and Sussillo, David},
	year = {2018},
}

@article{stroud_cortical_2018,
	title = {Cortical {Signal} {Propagation}: {Balance}, {Amplify}, {Transmit}},
	volume = {98},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318302344},
	doi = {https://doi.org/10.1016/j.neuron.2018.03.028},
	number = {1},
	journal = {Neuron},
	author = {Stroud, Jake P and Vogels, Tim P},
	year = {2018},
	pages = {8--9},
	file = {Attachment:/Users/tito/Zotero/storage/SG5HATZV/Stroud, Vogels - 2018 - Cortical Signal Propagation Balance, Amplify, Transmit.pdf:application/pdf},
}

@article{shine_dynamics_2016,
	title = {The {Dynamics} of {Functional} {Brain} {Networks}: {Integrated} {Network} {States} during {Cognitive} {Task} {Performance}},
	volume = {92},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627316305773},
	doi = {https://doi.org/10.1016/j.neuron.2016.09.018},
	number = {2},
	journal = {Neuron},
	author = {Shine, James M. and Bissett, Patrick G. and Bell, Peter T. and Koyejo, Oluwasanmi and Balsters, Joshua H. and Gorgolewski, Krzysztof J. and Moodie, Craig A. and Poldrack, Russell A.},
	year = {2016},
	pages = {544--554},
	file = {Attachment:/Users/tito/Zotero/storage/ACM375SZ/Shine et al. - 2016 - The Dynamics of Functional Brain Networks Integrated Network States during Cognitive Task Performance.pdf:application/pdf},
}

@article{yamins_using_2016,
	title = {Using goal-driven deep learning models to understand sensory cortex},
	volume = {19},
	url = {https://doi.org/10.1038/nn.4244 http://10.0.4.14/nn.4244},
	journal = {Nature Neuroscience},
	author = {Yamins, Daniel L K and DiCarlo, James J},
	month = feb,
	year = {2016},
	pages = {356},
	file = {Attachment:/Users/tito/Zotero/storage/X7P7C2SF/Yamins, DiCarlo - 2016 - Using goal-driven deep learning models to understand sensory cortex.pdf:application/pdf},
}

@article{fries_neuronal_2009,
	title = {Neuronal {Gamma}-{Band} {Synchronization} as a {Fundamental} {Process} in {Cortical} {Computation}},
	volume = {32},
	issn = {0147-006X},
	url = {https://doi.org/10.1146/annurev.neuro.051508.135603},
	doi = {10.1146/annurev.neuro.051508.135603},
	abstract = {Neuronal gamma-band synchronization is found in many cortical areas, is induced by different stimuli or tasks, and is related to several cognitive capacities. Thus, it appears as if many different gamma-band synchronization phenomena subserve many different functions. I argue that gamma-band synchronization is a fundamental process that subserves an elemental operation of cortical computation. Cortical computation unfolds in the interplay between neuronal dynamics and structural neuronal connectivity. A core motif of neuronal connectivity is convergence, which brings about both selectivity and invariance of neuronal responses. However, those core functions can be achieved simultaneously only if converging neuronal inputs are functionally segmented and if only one segment is selected at a time. This segmentation and selection can be elegantly achieved if structural connectivity interacts with neuronal synchronization. I propose that this process is at least one of the fundamental functions of gamma-band synchronization, which then subserves numerous higher cognitive functions.},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Fries, Pascal},
	month = jun,
	year = {2009},
	pages = {209--224},
	annote = {doi: 10.1146/annurev.neuro.051508.135603},
	file = {Attachment:/Users/tito/Zotero/storage/QQMETAM3/Fries - 2009 - Neuronal Gamma-Band Synchronization as a Fundamental Process in Cortical Computation.pdf:application/pdf},
}

@book{guarracino_noninvasive_2010,
	title = {Noninvasive {Ventilation} for {Awake} {Percutaneous} {Aortic} {Valve} {Implantation} in {High}-{Risk} {Respiratory} {Patients}: {A} {Case} {Series}.},
	volume = {294},
	isbn = {0892-0915 (Print)\${\textbackslash}backslash\$r0892-0915 (Linking)},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20857278},
	number = {24},
	author = {Guarracino, Fabio and Cabrini, Luca and Baldassarri, Rubia and Petronio, Sonia and De Carlo, Marco and Covello, Remo Daniel and Landoni, Giovanni and Gabbrielli, Luciano and Ambrosino, Nicolino},
	year = {2010},
	doi = {10.1053/j.jvca.2010.06.032},
	pmid = {20829068},
	file = {Attachment:/Users/tito/Zotero/storage/UGL94TS9/Guarracino et al. - 2010 - Noninvasive Ventilation for Awake Percutaneous Aortic Valve Implantation in High-Risk Respiratory Patients A.pdf:application/pdf},
}

@article{mochol_stochastic_2015,
	title = {Stochastic transitions into silence cause noise correlations in cortical circuits},
	url = {http://www.pnas.org/content/early/2015/03/03/1410509112.abstract},
	abstract = {Neurons in the cerebral cortex emit action potentials in a seemingly random manner. One puzzling aspect of this neuronal “noise” is that it is correlated among neighboring neurons, something thought to reflect the tendency of neurons to fire together. Here, we recorded the activity from populations of cortical neurons in rats and found that correlations could be largely explained by the tendency of cortical neurons to stop firing together. A computational network model whose activity alternated between periods of activity and silence was able to reproduce the pattern of correlations found in the experiments. Our findings shed light on the mechanisms causing neuronal variability and may contribute to elucidate its role in a neural code.The spiking activity of cortical neurons is highly variable. This variability is generally correlated among nearby neurons, an effect commonly interpreted to reflect the coactivation of neurons due to anatomically shared inputs. Recent findings, however, indicate that correlations can be dynamically modulated, suggesting that the underlying mechanisms are not well understood. Here, we investigate the hypothesis that correlations are dominated by neuronal coinactivation: the occurrence of brief silent periods during which all neurons in the local network stop firing. We recorded spiking activity from large populations of neurons in the auditory cortex of anesthetized rats across different brain states. During spontaneous activity, the reduction of correlation accompanying brain state desynchronization was largely explained by a decrease in the density of the silent periods. The presentation of a stimulus caused an initial drop of correlations followed by a rebound, a time course that was mimicked by the instantaneous silence density. We built a rate network model with fluctuation-driven transitions between a silent and an active attractor and assumed that neurons fired Poisson spike trains with a rate following the model dynamics. Variations of the network external input altered the transition rate into the silent attractor and reproduced the relation between correlation and silence density found in the data, both in spontaneous and evoked conditions. This suggests that the observed changes in correlation, occurring gradually with brain state variations or abruptly with sensory stimulation, are due to changes in the likeliness of the microcircuit to transiently cease firing.},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Mochol, Gabriela and Hermoso-Mendizabal, Ainhoa and Sakata, Shuzo and Harris, Kenneth D and de la Rocha, Jaime},
	month = mar,
	year = {2015},
	file = {Attachment:/Users/tito/Zotero/storage/4YVQH59R/Mochol et al. - 2015 - Stochastic transitions into silence cause noise correlations in cortical circuits.pdf:application/pdf},
}

@article{ecker_state_2014,
	title = {State {Dependence} of {Noise} {Correlations} in {Macaque} {Primary} {Visual} {Cortex}},
	volume = {82},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627314001044},
	doi = {https://doi.org/10.1016/j.neuron.2014.02.006},
	abstract = {Summary Shared, trial-to-trial variability in neuronal populations has a strong impact on the accuracy of information processing in the brain. Estimates of the level of such noise correlations are diverse, ranging from 0.01 to 0.4, with little consensus on which factors account for these differences. Here we addressed one important factor that varied across studies, asking how anesthesia affects the population activity structure in macaque primary visual cortex. We found that under opioid anesthesia, activity was dominated by strong coordinated fluctuations on a timescale of 1–2 Hz, which were mostly absent in awake, fixating monkeys. Accounting for these global fluctuations markedly reduced correlations under anesthesia, matching those observed during wakefulness and reconciling earlier studies conducted under anesthesia and in awake animals. Our results show that internal signals, such as brain state transitions under anesthesia, can induce noise correlations but can also be estimated and accounted for based on neuronal population activity.},
	number = {1},
	journal = {Neuron},
	author = {Ecker, Alexander S. and Berens, Philipp and Cotton, R. James and Subramaniyan, Manivannan and Denfield, George H. and Cadwell, Cathryn R. and Smirnakis, Stelios M. and Bethge, Matthias and Tolias, Andreas S.},
	year = {2014},
	pages = {235--248},
	file = {Attachment:/Users/tito/Zotero/storage/HL4TZGTS/Ecker et al. - 2014 - State Dependence of Noise Correlations in Macaque Primary Visual Cortex.pdf:application/pdf},
}

@article{muraskin_multimodal_2018,
	title = {A multimodal encoding model applied to imaging decision-related neural cascades in the human brain},
	volume = {180},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305323},
	doi = {https://doi.org/10.1016/j.neuroimage.2017.06.059},
	abstract = {Perception and cognition in the brain are naturally characterized as spatiotemporal processes. Decision-making, for example, depends on coordinated patterns of neural activity cascading across the brain, running in time from stimulus to response and in space from primary sensory regions to the frontal lobe. Measuring this cascade is key to developing an understanding of brain function. Here we report on a novel methodology that employs multi-modal imaging for inferring this cascade in humans at unprecedented spatiotemporal resolution. Specifically, we develop an encoding model to link simultaneously measured electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) signals to infer high-resolution spatiotemporal brain dynamics during a perceptual decision. After demonstrating replication of results from the literature, we report previously unobserved sequential reactivation of a substantial fraction of the pre-response network whose magnitude correlates with a proxy for decision confidence. Our encoding model, which temporally tags BOLD activations using time localized EEG variability, identifies a coordinated and spatially distributed neural cascade that is associated with a perceptual decision. In general the methodology illuminates complex brain dynamics that would otherwise be unobservable using fMRI or EEG acquired separately.},
	journal = {NeuroImage},
	author = {Muraskin, Jordan and Brown, Truman R and Walz, Jennifer M and Tu, Tao and Conroy, Bryan and Goldman, Robin I and Sajda, Paul},
	year = {2018},
	keywords = {fMRI, Confidence, Decision-making, EEG, Simultaneous acquisition},
	pages = {211--222},
	file = {Attachment:/Users/tito/Zotero/storage/YAMBP3JC/Muraskin et al. - 2018 - A multimodal encoding model applied to imaging decision-related neural cascades in the human brain.pdf:application/pdf},
}

@article{lin_nature_2015,
	title = {The {Nature} of {Shared} {Cortical} {Variability}},
	volume = {87},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S089662731500598X},
	doi = {https://doi.org/10.1016/j.neuron.2015.06.035},
	abstract = {Summary Neuronal responses of sensory cortex are highly variable, and this variability is correlated across neurons. To assess how variability reflects factors shared across a neuronal population, we analyzed the activity of many simultaneously recorded neurons in visual cortex. We developed a simple model that comprises two sources of shared variability: a multiplicative gain, which uniformly scales each neuron's sensory drive, and an additive offset, which affects different neurons to different degrees. This model captured the variability of spike counts and reproduced the dependence of pairwise correlations on neuronal tuning and stimulus orientation. The relative contributions of the additive and multiplicative fluctuations could vary over time and had marked impact on population coding. These observations indicate that shared variability of neuronal populations in sensory cortex can be largely explained by two factors that modulate the whole population.},
	number = {3},
	journal = {Neuron},
	author = {Lin, I-Chun and Okun, Michael and Carandini, Matteo and Harris, Kenneth D.},
	year = {2015},
	pages = {644--656},
	file = {Attachment:/Users/tito/Zotero/storage/TNAFYET5/Lin et al. - 2015 - The Nature of Shared Cortical Variability.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/ZJH74GBV/Lin et al. - 2015 - The Nature of Shared Cortical Variability.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/ASCTWCUK/S089662731500598X.html:text/html},
}

@article{ciric_benchmarking_2017,
	title = {Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity},
	volume = {154},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917302288},
	doi = {https://doi.org/10.1016/j.neuroimage.2017.03.020},
	abstract = {Since initial reports regarding the impact of motion artifact on measures of functional connectivity, there has been a proliferation of participant-level confound regression methods to limit its impact. However, many of the most commonly used techniques have not been systematically evaluated using a broad range of outcome measures. Here, we provide a systematic evaluation of 14 participant-level confound regression methods in 393 youths. Specifically, we compare methods according to four benchmarks, including the residual relationship between motion and connectivity, distance-dependent effects of motion on connectivity, network identifiability, and additional degrees of freedom lost in confound regression. Our results delineate two clear trade-offs among methods. First, methods that include global signal regression minimize the relationship between connectivity and motion, but result in distance-dependent artifact. In contrast, censoring methods mitigate both motion artifact and distance-dependence, but use additional degrees of freedom. Importantly, less effective de-noising methods are also unable to identify modular network structure in the connectome. Taken together, these results emphasize the heterogeneous efficacy of existing methods, and suggest that different confound regression strategies may be appropriate in the context of specific scientific goals.},
	journal = {NeuroImage},
	author = {Ciric, Rastko and Wolf, Daniel H and Power, Jonathan D and Roalf, David R and Baum, Graham L and Ruparel, Kosha and Shinohara, Russell T and Elliott, Mark A and Eickhoff, Simon B and Davatzikos, Christos and Gur, Ruben C and Gur, Raquel E and Bassett, Danielle S and Satterthwaite, Theodore D},
	year = {2017},
	keywords = {fMRI, Functional connectivity, Artifact, Confound, Motion, Noise},
	pages = {174--187},
	file = {Attachment:/Users/tito/Zotero/storage/4LKDQ7WU/Ciric et al. - 2017 - Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of.pdf:application/pdf},
}

@article{satterthwaite_improved_2013,
	title = {An improved framework for confound regression and filtering for control of motion artifact in the preprocessing of resting-state functional connectivity data},
	volume = {64},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912008609},
	doi = {https://doi.org/10.1016/j.neuroimage.2012.08.052},
	abstract = {Several recent reports in large, independent samples have demonstrated the influence of motion artifact on resting-state functional connectivity MRI (rsfc-MRI). Standard rsfc-MRI preprocessing typically includes regression of confounding signals and band-pass filtering. However, substantial heterogeneity exists in how these techniques are implemented across studies, and no prior study has examined the effect of differing approaches for the control of motion-induced artifacts. To better understand how in-scanner head motion affects rsfc-MRI data, we describe the spatial, temporal, and spectral characteristics of motion artifacts in a sample of 348 adolescents. Analyses utilize a novel approach for describing head motion on a voxelwise basis. Next, we systematically evaluate the efficacy of a range of confound regression and filtering techniques for the control of motion-induced artifacts. Results reveal that the effectiveness of preprocessing procedures on the control of motion is heterogeneous, and that improved preprocessing provides a substantial benefit beyond typical procedures. These results demonstrate that the effect of motion on rsfc-MRI can be substantially attenuated through improved preprocessing procedures, but not completely removed.},
	journal = {NeuroImage},
	author = {Satterthwaite, Theodore D and Elliott, Mark A and Gerraty, Raphael T and Ruparel, Kosha and Loughead, James and Calkins, Monica E and Eickhoff, Simon B and Hakonarson, Hakon and Gur, Ruben C and Gur, Raquel E and Wolf, Daniel H},
	year = {2013},
	keywords = {fMRI, Connectome, Resting-state, Artifact, Motion, Adolescence, Connectivity, Development, Network},
	pages = {240--256},
	file = {Attachment:/Users/tito/Zotero/storage/9NYTSDUT/Satterthwaite et al. - 2013 - An improved framework for confound regression and filtering for control of motion artifact in the preproce.pdf:application/pdf},
}

@article{brody_correlations_1999,
	title = {Correlations {Without} {Synchrony}},
	volume = {11},
	issn = {08997667},
	doi = {10.1162/089976699300016133},
	abstract = {Peaks in spike train correlograms are usually taken as indicative of spike timing synchronization between neurons. Strictly speaking, however, a peak merely indicates that the two spike trains were not independent. Two biologically plausible ways of departing from independence that are capable of generating peaks very similar to spike timing peaks are described here: covariations over trials in response latency and covariations over trials in neuronal excitability. Since peaks due to these interactions can be similar to spike timing peaks, interpreting a correlogram may be a problem with ambiguous solutions. What peak shapes do latency or excitability interactions generate? When are they similar to spike timing peaks? When can they be ruled out from having caused an observed correlogram peak? These are the questions addressed here. The previous article in this issue proposes quantitative methods to tell cases apart when latency or excitability covariations cannot be ruled out.},
	number = {7},
	journal = {Neural Computation},
	author = {Brody, Carlos D.},
	year = {1999},
	pmid = {10490937},
	pages = {1537--1551},
}

@article{series_tuning_2004,
	title = {Tuning curve sharpening for orientation selectivity: coding efficiency and the impact of correlations},
	volume = {7},
	url = {http://dx.doi.org/10.1038/nn1321 http://10.0.4.14/nn1321 https://www.nature.com/articles/nn1321#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Seriès, Peggy and Latham, Peter E and Pouget, Alexandre},
	month = sep,
	year = {2004},
	pages = {1129},
}

@article{lee_learning_2016,
	title = {Learning {Problem}-{Solving} {Rules} as {Search} {Through} a {Hypothesis} {Space}},
	volume = {40},
	issn = {15516709},
	doi = {10.1111/cogs.12275},
	abstract = {Learning to solve a class of problems can be characterized as a search through a space of hypotheses about the rules for solving these problems. A series of four experiments studied how different learning conditions affected the search among hypotheses about the solution rule for a simple computational problem. Experiment 1 showed that a problem property such as computa- tional difficulty of the rules biased the search process and so affected learning. Experiment 2 examined the impact of examples as instructional tools and found that their effectiveness was determined by whether they uniquely pointed to the correct rule. Experiment 3 compared verbal directions with examples and found that both could guide search. The final experiment tried to improve learning by using more explicit verbal directions or by adding scaffolding to the example. While both manipulations improved learning, learning still took the form of a search through a hypothesis space of possible rules. We describe a model that embodies two assumptions: (1) the instruction can bias the rules participants hypothesize rather than directly be encoded into a rule; (2) participants do not have memory for past wrong hypotheses and are likely to retry them. These assumptions are realized in a Markov model that fits all the data by estimating two sets of proba- bilities. First, the learning condition induced one set of Start probabilities of trying various rules. Second, should this first hypothesis prove wrong, the learning condition induced a second set of Choice probabilities of considering various rules. These findings broaden our understanding of effective instruction and provide implications for instructional design.},
	number = {5},
	journal = {Cognitive Science},
	author = {Lee, Hee Seung and Betts, Shawn and Anderson, John R.},
	year = {2016},
	keywords = {Examples, Hypothesis testing, Markov processes, Problem solving, Search space, Verbal direction},
	pages = {1036--1079},
	file = {Attachment:/Users/tito/Zotero/storage/E2YEFSU4/Lee, Betts, Anderson - 2016 - Learning Problem-Solving Rules as Search Through a Hypothesis Space.pdf:application/pdf},
}

@article{masse_circuit_2018,
	title = {Circuit mechanisms for the maintenance and manipulation of information in working memory},
	url = {http://biorxiv.org/content/early/2018/05/21/305714.abstract},
	abstract = {Recently it has been proposed that information in short-term memory may not always be stored in persistent neuronal activity, but can be maintained in "activity-silent" hidden states such as synaptic efficacies endowed with short-term plasticity (STP). However, working memory involves manipulation as well as maintenance of information in the absence of external stimuli. In this work, we investigated working memory representation using recurrent neural network (RNN) models trained to perform several working memory dependent tasks. We found that STP can support the short-term maintenance of information provided that the memory delay period is sufficiently short. However, in tasks that require actively manipulating information, persistent neuronal activity naturally emerges from learning, and the amount of persistent neuronal activity scales with the degree of manipulation required. These results shed insight into the current debate on working memory encoding, and suggest that persistent neural activity can vary markedly between tasks used in different experiments.},
	journal = {bioRxiv},
	author = {Masse, Nicolas Y and Yang, Guangyu R and Song, H Francis and Wang, Xiao-Jing and Freedman, David J},
	month = jan,
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/23ACLWS5/Masse et al. - 2018 - Circuit mechanisms for the maintenance and manipulation of information in working memory.pdf:application/pdf},
}

@article{grun_data-driven_2009,
	title = {Data-{Driven} {Significance} {Estimation} for {Precise} {Spike} {Correlation}},
	volume = {101},
	issn = {0022-3077},
	url = {https://doi.org/10.1152/jn.00093.2008},
	doi = {10.1152/jn.00093.2008},
	abstract = {The mechanisms underlying neuronal coding and, in particular, the role of temporal spike coordination are hotly debated. However, this debate is often confounded by an implicit discussion about the use of appropriate analysis methods. To avoid incorrect interpretation of data, the analysis of simultaneous spike trains for precise spike correlation needs to be properly adjusted to the features of the experimental spike trains. In particular, nonstationarity of the firing of individual neurons in time or across trials, a spike train structure deviating from Poisson, or a co-occurrence of such features in parallel spike trains are potent generators of false positives. Problems can be avoided by including these features in the null hypothesis of the significance test. In this context, the use of surrogate data becomes increasingly important, because the complexity of the data typically prevents analytical solutions. This review provides an overview of the potential obstacles in the correlation analysis of parallel spike data and possible routes to overcome them. The discussion is illustrated at every stage of the argument by referring to a specific analysis tool (the Unitary Events method). The conclusions, however, are of a general nature and hold for other analysis techniques. Thorough testing and calibration of analysis tools and the impact of potentially erroneous preprocessing stages are emphasized.},
	number = {3},
	journal = {Journal of Neurophysiology},
	author = {Grün, Sonja},
	month = mar,
	year = {2009},
	pages = {1126--1140},
	annote = {doi: 10.1152/jn.00093.2008},
}

@article{averbeck_neural_2006,
	title = {Neural correlations, population coding and computation},
	volume = {7},
	url = {http://dx.doi.org/10.1038/nrn1888 http://10.0.4.14/nrn1888},
	journal = {Nature Reviews Neuroscience},
	author = {Averbeck, Bruno B and Latham, Peter E and Pouget, Alexandre},
	month = may,
	year = {2006},
	pages = {358},
	file = {Attachment:/Users/tito/Zotero/storage/T653VMEL/Averbeck, Latham, Pouget - 2006 - Neural correlations, population coding and computation.pdf:application/pdf},
}

@article{tommasin_scale-invariant_2018,
	title = {Scale-invariant rearrangement of resting state networks in the human brain under sustained stimulation},
	volume = {179},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918305135},
	doi = {https://doi.org/10.1016/j.neuroimage.2018.06.006},
	abstract = {Brain activity at rest is characterized by widely distributed and spatially specific patterns of synchronized low-frequency blood-oxygenation level-dependent (BOLD) fluctuations, which correspond to physiologically relevant brain networks. This network behaviour is known to persist also during task execution, yet the details underlying task-associated modulations of within- and between-network connectivity are largely unknown. In this study we exploited a multi-parametric and multi-scale approach to investigate how low-frequency fluctuations adapt to a sustained n-back working memory task. We found that the transition from the resting state to the task state involves a behaviourally relevant and scale-invariant modulation of synchronization patterns within both task-positive and default mode networks. Specifically, decreases of connectivity within networks are accompanied by increases of connectivity between networks. In spite of large and widespread changes of connectivity strength, the overall topology of brain networks is remarkably preserved. We show that these findings are strongly influenced by connectivity at rest, suggesting that the absolute change of connectivity (i.e., disregarding the baseline) may not be the most suitable metric to study dynamic modulations of functional connectivity. Our results indicate that a task can evoke scale-invariant, distributed changes of BOLD fluctuations, further confirming that low frequency BOLD oscillations show a specialized response and are tightly bound to task-evoked activation.},
	journal = {NeuroImage},
	author = {Tommasin, Silvia and Mascali, Daniele and Moraschi, Marta and Gili, Tommaso and Hassan, Ibrahim Eid and Fratini, Michela and DiNuzzo, Mauro and Wise, Richard G and Mangia, Silvia and Macaluso, Emiliano and Giove, Federico},
	year = {2018},
	keywords = {Functional connectivity, Connectivity dynamics, Steady-state networks, Working memory},
	pages = {570--581},
	file = {Attachment:/Users/tito/Zotero/storage/4KNRZQRH/Tommasin et al. - 2018 - Scale-invariant rearrangement of resting state networks in the human brain under sustained stimulation.pdf:application/pdf},
}

@article{hopfield_neurons_1984,
	title = {Neurons with graded response have collective computational properties like those of two-state neurons},
	volume = {81},
	url = {http://www.pnas.org/content/81/10/3088.abstract},
	abstract = {A model for a large network of "neurons" with a graded response (or sigmoid input-output relation) is studied. This deterministic system has collective properties in very close correspondence with the earlier stochastic model based on McCulloch - Pitts neurons. The content- addressable memory and other emergent collective properties of the original model also are present in the graded response model. The idea that such collective properties are used in biological systems is given added credence by the continued presence of such properties for more nearly biological "neurons." Collective analog electrical circuits of the kind described will certainly function. The collective states of the two models have a simple correspondence. The original model will continue to be useful for simulations, because its connection to graded response systems is established. Equations that include the effect of action potentials in the graded response system are also developed.},
	number = {10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Hopfield, J J},
	month = may,
	year = {1984},
	pages = {3088 LP -- 3092},
	file = {Attachment:/Users/tito/Zotero/storage/CTCEK5H3/Hopfield - 1984 - Neurons with graded response have collective computational properties like those of two-state neurons.pdf:application/pdf},
}

@article{schuck_sequential_2018,
	title = {Sequential replay of non-spatial task states in the human hippocampus},
	url = {http://biorxiv.org/content/early/2018/05/07/315978.abstract},
	abstract = {Neurophysiological research has found that previously experienced sequences of spatial events are reactivated in the hippocampus of rodents during wakeful rest. This phenomenon has become a cornerstone of modern theories of memory and decision making. Yet, whether hippocampal sequence reactivation at rest is of general importance also for humans and non-spatial tasks has remained unclear. Here, we investigated sequences of fMRI BOLD activation patterns in humans during wakeful rest following a sequential but non-spatial decision-making task. We found that pattern reactivations within the human hippocampus reflected the order of previous task state sequences, and that the extent of this offline reactivation was related to the on-task representation of task states in the orbitofrontal cortex. Permutation analyses and fMRI signal simulations confirmed that these results reflected underlying neural activity, and showed that our novel statistical analyses are, in principle, sensitive to sequential neural events occurring as fast as one hundred milliseconds apart. Our results support the importance of sequential reactivation in the human hippocampus for decision making, and establish the feasibility of investigating such rapid signals with fMRI, despite its substantial temporal limitations.},
	journal = {bioRxiv},
	author = {Schuck, Nicolas W and Niv, Yael},
	month = jan,
	year = {2018},
}

@article{machens_flexible_2005,
	title = {Flexible {Control} of {Mutual} {Inhibition}: {A} {Neural} {Model} of {Two}-{Interval} {Discrimination}},
	volume = {307},
	url = {http://science.sciencemag.org/content/307/5712/1121.abstract},
	abstract = {Networks adapt to environmental demands by switching between distinct dynamical behaviors. The activity of frontal-lobe neurons during two-interval discrimination tasks is an example of these adaptable dynamics. Subjects first perceive a stimulus, then hold it in working memory, and finally make a decision by comparing it with a second stimulus. We present a simple mutual-inhibition network model that captures all three task phases within a single framework. The model integrates both working memory and decision making because its dynamical properties are easily controlled without changing its connectivity. Mutual inhibition between nonlinear units is a useful design motif for networks that must display multiple behaviors.},
	number = {5712},
	journal = {Science},
	author = {Machens, Christian K and Romo, Ranulfo and Brody, Carlos D},
	month = feb,
	year = {2005},
	pages = {1121 LP -- 1124},
	file = {Attachment:/Users/tito/Zotero/storage/PSUUYUPB/Machens, Romo, Brody - 2005 - Flexible Control of Mutual Inhibition A Neural Model of Two-Interval Discrimination.pdf:application/pdf},
}

@article{bassett_task-based_2013,
	title = {Task-{Based} {Core}-{Periphery} {Organization} of {Human} {Brain} {Dynamics}},
	volume = {9},
	url = {https://doi.org/10.1371/journal.pcbi.1003171},
	abstract = {Author Summary When someone learns a new skill, his/her brain dynamically alters individual synapses, regional activity, and larger-scale circuits. In this paper, we capture some of these dynamics by measuring and characterizing patterns of coherent brain activity during the learning of a motor skill. We extract time-evolving communities from these patterns and find that a temporal core that is composed primarily of primary sensorimotor and visual regions reconfigures little over time, whereas a periphery that is composed primarily of multimodal association regions reconfigures frequently. The core consists of densely connected nodes, and the periphery consists of sparsely connected nodes. Individual participants with a larger separation between core and periphery learn better in subsequent training sessions than individuals with a smaller separation. Conceptually, core-periphery organization provides a framework in which to understand how putative functional modules are linked. This, in turn, enables the prediction of fundamental human capacities, including the production of complex goal-directed behavior.},
	number = {9},
	journal = {PLOS Computational Biology},
	author = {Bassett, Danielle S and Wymbs, Nicholas F and Rombach, M Puck and Porter, Mason A and Mucha, Peter J and Grafton, Scott T},
	month = sep,
	year = {2013},
	pages = {e1003171},
}

@article{grootswagers_finding_2018,
	title = {Finding decodable information that can be read out in behaviour},
	volume = {179},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918305299},
	doi = {https://doi.org/10.1016/j.neuroimage.2018.06.022},
	abstract = {Multivariate decoding methods applied to neuroimaging data have become the standard in cognitive neuroscience for unravelling statistical dependencies between brain activation patterns and experimental conditions. The current challenge is to demonstrate that decodable information is in fact used by the brain itself to guide behaviour. Here we demonstrate a promising approach to do so in the context of neural activation during object perception and categorisation behaviour. We first localised decodable information about visual objects in the human brain using a multivariate decoding analysis and a spatially-unbiased searchlight approach. We then related brain activation patterns to behaviour by testing whether the classifier used for decoding can be used to predict behaviour. We show that while there is decodable information about visual category throughout the visual brain, only a subset of those representations predicted categorisation behaviour, which were strongest in anterior ventral temporal cortex. Our results have important implications for the interpretation of neuroimaging studies, highlight the importance of relating decoding results to behaviour, and suggest a suitable methodology towards this aim.},
	journal = {NeuroImage},
	author = {Grootswagers, Tijl and Cichy, Radoslaw M and Carlson, Thomas A},
	year = {2018},
	pages = {252--262},
	file = {Attachment:/Users/tito/Zotero/storage/XS3AUTCP/Grootswagers, Cichy, Carlson - 2018 - Finding decodable information that can be read out in behaviour.pdf:application/pdf},
}

@article{chen_sparse_2018,
	title = {The {Sparse} {Manifold} {Transform}},
	journal = {arXiv preprint arXiv:1806.08887},
	author = {Chen, Yubei and Paiton, Dylan M and Olshausen, Bruno A},
	year = {2018},
}

@article{williamson_equivalence_2015,
	title = {The {Equivalence} of {Information}-{Theoretic} and {Likelihood}-{Based} {Methods} for {Neural} {Dimensionality} {Reduction}},
	volume = {11},
	url = {https://doi.org/10.1371/journal.pcbi.1004141},
	abstract = {Author Summary A popular approach to the neural coding problem is to identify a low-dimensional linear projection of the stimulus space that preserves the aspects of the stimulus that affect a neuron's probability of spiking. Previous work has focused on both information-theoretic and likelihood-based estimators for finding such projections. Here, we show that these two approaches are in fact equivalent. We show that maximally informative dimensions (MID), a popular information-theoretic method for dimensionality reduction, is identical to the maximum-likelihood estimator for a particular linear-nonlinear encoding model with Poisson spiking. One implication of this equivalence is that MID may not find the information-theoretically optimal stimulus projection when spiking is non-Poisson, which we illustrate with a few simple examples. Using these insights, we propose novel dimensionality-reduction methods that incorporate non-Poisson spiking, and suggest new parametrizations that allow for tractable estimation of high-dimensional subspaces.},
	number = {4},
	journal = {PLOS Computational Biology},
	author = {Williamson, Ross S and Sahani, Maneesh and Pillow, Jonathan W},
	month = apr,
	year = {2015},
	pages = {e1004141},
	file = {Attachment:/Users/tito/Zotero/storage/TC6BP2AV/Williamson, Sahani, Pillow - 2015 - The Equivalence of Information-Theoretic and Likelihood-Based Methods for Neural Dimensionality Redu.PDF:application/pdf},
}

@book{mackay_information_2003,
	title = {Information theory, inference and learning algorithms},
	isbn = {0-521-64298-1},
	publisher = {Cambridge university press},
	author = {MacKay, David J C},
	year = {2003},
}

@article{sussillo_lfads-latent_2016,
	title = {{LFADS}-latent factor analysis via dynamical systems},
	journal = {arXiv preprint arXiv:1608.06315},
	author = {Sussillo, David and Jozefowicz, Rafal and Abbott, L F and Pandarinath, Chethan},
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/G67ZJ5IR/Sussillo et al. - 2016 - LFADS-latent factor analysis via dynamical systems.pdf:application/pdf},
}

@article{churchland_temporal_2007,
	title = {Temporal {Complexity} and {Heterogeneity} of {Single}-{Neuron} {Activity} in {Premotor} and {Motor} {Cortex}},
	volume = {97},
	issn = {0022-3077},
	url = {https://doi.org/10.1152/jn.00095.2007},
	doi = {10.1152/jn.00095.2007},
	abstract = {The relationship between neural activity in motor cortex and movement is highly debated. Although many studies have examined the spatial tuning (e.g., for direction) of cortical responses, less attention has been paid to the temporal properties of individual neuron responses. We developed a novel task, employing two instructed speeds, that allows meaningful averaging of neural responses across reaches with nearly identical velocity profiles. Doing so preserves fine temporal structure and reveals considerable complexity and heterogeneity of response patterns in primary motor and premotor cortex. Tuning for direction was prominent, but the preferred direction was frequently inconstant with respect to time, instructed-speed, and/or reach distance. Response patterns were often temporally complex and multiphasic, and varied with direction and instructed speed in idiosyncratic ways. A wide variety of patterns was observed, and it was not uncommon for a neuron to exhibit a pattern shared by no other neuron in our dataset. Response patterns of individual neurons rarely, if ever, matched those of individual muscles. Indeed, the set of recorded responses spanned a much higher dimensional space than would be expected for a model in which neural responses relate to a moderate number of factors?dynamic, kinematic, or otherwise. Complex responses may provide a basis-set representing many parameters. Alternately, it may be necessary to discard the notion that responses exist to ?represent? movement parameters. It has been argued that complex and heterogeneous responses are expected of a recurrent network that produces temporally patterned outputs, and the present results would seem to support this view.},
	number = {6},
	journal = {Journal of Neurophysiology},
	author = {Churchland, Mark M and Shenoy, Krishna V},
	month = jun,
	year = {2007},
	pages = {4235--4257},
	annote = {doi: 10.1152/jn.00095.2007},
}

@article{kosinski_private_2013,
	title = {Private traits and attributes are predictable from digital records of human behavior},
	volume = {110},
	url = {http://www.pnas.org/content/110/15/5802.abstract},
	abstract = {We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88\% of cases, African Americans and Caucasian Americans in 95\% of cases, and between Democrat and Republican in 85\% of cases. For the personality trait “Openness,” prediction accuracy is close to the test–retest accuracy of a standard personality test. We give examples of associations between attributes and Likes and discuss implications for online personalization and privacy.},
	number = {15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kosinski, Michal and Stillwell, David and Graepel, Thore},
	month = apr,
	year = {2013},
	pages = {5802 LP -- 5805},
	file = {Attachment:/Users/tito/Zotero/storage/BYAFZ6U6/Kosinski, Stillwell, Graepel - 2013 - Private traits and attributes are predictable from digital records of human behavior.pdf:application/pdf},
}

@article{churchland_neural_2012,
	title = {Neural population dynamics during reaching},
	volume = {487},
	url = {http://dx.doi.org/10.1038/nature11129 http://10.0.4.14/nature11129 https://www.nature.com/articles/nature11129#supplementary-information},
	journal = {Nature},
	author = {Churchland, Mark M and Cunningham, John P and Kaufman, Matthew T and Foster, Justin D and Nuyujukian, Paul and Ryu, Stephen I and Shenoy, Krishna V},
	month = jun,
	year = {2012},
	pages = {51},
}

@article{laughlin_simple_1981,
	title = {A simple coding procedure enhances a neuron's information capacity},
	volume = {36},
	issn = {1865-7125},
	number = {9-10},
	journal = {Zeitschrift für Naturforschung c},
	author = {Laughlin, Simon},
	year = {1981},
	pages = {910--912},
	file = {Attachment:/Users/tito/Zotero/storage/LH3RUM7X/Laughlin - 1981 - A simple coding procedure enhances a neuron's information capacity.pdf:application/pdf},
}

@article{carandini_normalization_2011,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	url = {http://dx.doi.org/10.1038/nrn3136 http://10.0.4.14/nrn3136},
	journal = {Nature Reviews Neuroscience},
	author = {Carandini, Matteo and Heeger, David J},
	month = nov,
	year = {2011},
	pages = {51},
}

@article{tomasi_functional_2014,
	title = {Functional {Connectivity} and {Brain} {Activation}: {A} {Synergistic} {Approach}},
	volume = {24},
	issn = {1047-3211},
	url = {http://dx.doi.org/10.1093/cercor/bht119},
	abstract = {Traditional functional magnetic resonance imaging (fMRI) studies exploit endogenous brain activity for mapping brain activation during “periodic” cognitive/emotional challenges or brain functional connectivity during the “resting state”. Previous studies demonstrated that these approaches provide a limited view of brain function which can be complemented by each other. We hypothesized that graph theory functional connectivity density (FCD) mapping would demonstrate regional FCD decreases between resting-state scan and a continuous “task-state” scan. Forty-five healthy volunteers underwent functional connectivity MRI during resting-state as well as a continuous visual attention task, and standard fMRI with a blocked version of the visual attention task. High-resolution data-driven FCD mapping was used to measure task-related connectivity changes without a priori hypotheses. Results demonstrate that task performance was associated with FCD decreases in brain regions weakly activated/deactivated by the task. Furthermore, a pronounced negative correlation between blood oxygen level-dependent-fMRI activation and task-related FCD decreases emerged across brain regions that also suggest the disconnection of task-irrelevant networks during task performance. The correlation between improved accuracy and stronger FCD decreases further suggests the disconnection of task-irrelevant networks during task performance. Functional connectivity can potentiate traditional fMRI studies and offer a more complete picture of brain function.},
	number = {10},
	journal = {Cerebral Cortex},
	author = {Tomasi, Dardo and Wang, Ruiliang and Wang, Gene-Jack and Volkow, Nora D},
	month = oct,
	year = {2014},
	pages = {2619--2629},
	annote = {10.1093/cercor/bht119},
	file = {Attachment:/Users/tito/Zotero/storage/DZ3JKARD/Tomasi et al. - 2014 - Functional Connectivity and Brain Activation A Synergistic Approach.pdf:application/pdf},
}

@article{borst_information_1999,
	title = {Information theory and neural coding},
	volume = {2},
	url = {http://dx.doi.org/10.1038/14731 http://10.0.4.14/14731},
	journal = {Nature Neuroscience},
	author = {Borst, Alexander and Theunissen, Frédéric E},
	month = nov,
	year = {1999},
	pages = {947},
}

@article{kaardal_identifying_2013,
	title = {Identifying functional bases for multidimensional neural computations},
	volume = {25},
	issn = {0899-7667},
	number = {7},
	journal = {Neural computation},
	author = {Kaardal, Joel and Fitzgerald, Jeffrey D and Berry, Michael J and Sharpee, Tatyana O},
	year = {2013},
	pages = {1870--1890},
	file = {Attachment:/Users/tito/Zotero/storage/JPRQWL37/Kaardal et al. - 2013 - Identifying functional bases for multidimensional neural computations.pdf:application/pdf},
}

@article{mantini_electrophysiological_2007,
	title = {Electrophysiological signatures of resting state networks in the human brain},
	volume = {104},
	url = {http://www.pnas.org/content/104/32/13170.abstract},
	abstract = {Functional neuroimaging and electrophysiological studies have documented a dynamic baseline of intrinsic (not stimulus- or task-evoked) brain activity during resting wakefulness. This baseline is characterized by slow (\&lt;0.1 Hz) fluctuations of functional imaging signals that are topographically organized in discrete brain networks, and by much faster (1–80 Hz) electrical oscillations. To investigate the relationship between hemodynamic and electrical oscillations, we have adopted a completely data-driven approach that combines information from simultaneous electroencephalography (EEG) and functional magnetic resonance imaging (fMRI). Using independent component analysis on the fMRI data, we identified six widely distributed resting state networks. The blood oxygenation level-dependent signal fluctuations associated with each network were correlated with the EEG power variations of delta, theta, alpha, beta, and gamma rhythms. Each functional network was characterized by a specific electrophysiological signature that involved the combination of different brain rhythms. Moreover, the joint EEG/fMRI analysis afforded a finer physiological fractionation of brain networks in the resting human brain. This result supports for the first time in humans the coalescence of several brain rhythms within large-scale brain networks as suggested by biophysical studies.},
	number = {32},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Mantini, D and Perrucci, M G and Del Gratta, C and Romani, G L and Corbetta, M},
	month = aug,
	year = {2007},
	pages = {13170 LP -- 13175},
	file = {Attachment:/Users/tito/Zotero/storage/FIMRQZCC/Mantini et al. - 2007 - Electrophysiological signatures of resting state networks in the human brain.pdf:application/pdf},
}

@article{sussillo_opening_2013,
	title = {Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks},
	volume = {25},
	issn = {0899-7667},
	number = {3},
	journal = {Neural computation},
	author = {Sussillo, David and Barak, Omri},
	year = {2013},
	pages = {626--649},
	file = {Attachment:/Users/tito/Zotero/storage/LID2JFLK/Sussillo, Barak - 2013 - Opening the black box low-dimensional dynamics in high-dimensional recurrent neural networks.pdf:application/pdf},
}

@article{shadlen_variable_1998,
	title = {The {Variable} {Discharge} of {Cortical} {Neurons}: {Implications} for {Connectivity}, {Computation}, and {Information} {Coding}},
	volume = {18},
	url = {http://www.jneurosci.org/content/18/10/3870.abstract},
	abstract = {Cortical neurons exhibit tremendous variability in the number and temporal distribution of spikes in their discharge patterns. Furthermore, this variability appears to be conserved over large regions of the cerebral cortex, suggesting that it is neither reduced nor expanded from stage to stage within a processing pathway. To investigate the principles underlying such statistical homogeneity, we have analyzed a model of synaptic integration incorporating a highly simplified integrate and fire mechanism with decay. We analyzed a “high-input regime” in which neurons receive hundreds of excitatory synaptic inputs during each interspike interval. To produce a graded response in this regime, the neuron must balance excitation with inhibition. We find that a simple integrate and fire mechanism with balanced excitation and inhibition produces a highly variable interspike interval, consistent with experimental data. Detailed information about the temporal pattern of synaptic inputs cannot be recovered from the pattern of output spikes, and we infer that cortical neurons are unlikely to transmit information in the temporal pattern of spike discharge. Rather, we suggest that quantities are represented as rate codes in ensembles of 50–100 neurons. These column-like ensembles tolerate large fractions of common synaptic input and yet covary only weakly in their spike discharge. We find that an ensemble of 100 neurons provides a reliable estimate of rate in just one interspike interval (10–50 msec). Finally, we derived an expression for the variance of the neural spike count that leads to a stable propagation of signal and noise in networks of neurons—that is, conditions that do not impose an accumulation or diminution of noise. The solution implies that single neurons perform simple algebra resembling averaging, and that more sophisticated computations arise by virtue of the anatomical convergence of novel combinations of inputs to the cortical column from external sources.},
	number = {10},
	journal = {The Journal of Neuroscience},
	author = {Shadlen, Michael N and Newsome, William T},
	month = may,
	year = {1998},
	pages = {3870 LP -- 3896},
	file = {Attachment:/Users/tito/Zotero/storage/2S67XSBD/Shadlen, Newsome - 1998 - The Variable Discharge of Cortical Neurons Implications for Connectivity, Computation, and Information Coding.pdf:application/pdf},
}

@article{taghia_uncovering_2018,
	title = {Uncovering hidden brain state dynamics that regulate performance and decision-making during cognition},
	volume = {9},
	issn = {2041-1723},
	url = {https://doi.org/10.1038/s41467-018-04723-6},
	doi = {10.1038/s41467-018-04723-6},
	abstract = {Human cognition is influenced not only by external task demands but also latent mental processes and brain states that change over time. Here, we use novel Bayesian switching dynamical systems algorithm to identify hidden brain states and determine that these states are only weakly aligned with external task conditions. We compute state transition probabilities and demonstrate how dynamic transitions between hidden states allow flexible reconfiguration of functional brain circuits. Crucially, we identify latent transient brain states and dynamic functional circuits that are optimal for cognition and show that failure to engage these states in a timely manner is associated with poorer task performance and weaker decision-making dynamics. We replicate findings in a large sample (N = 122) and reveal a robust link between cognition and flexible latent brain state dynamics. Our study demonstrates the power of switching dynamical systems models for investigating hidden dynamic brain states and functional interactions underlying human cognition.},
	number = {1},
	journal = {Nature Communications},
	author = {Taghia, Jalil and Cai, Weidong and Ryali, Srikanth and Kochalka, John and Nicholas, Jonathan and Chen, Tianwen and Menon, Vinod},
	year = {2018},
	pages = {2505},
	file = {Attachment:/Users/tito/Zotero/storage/N38C8E3G/Taghia et al. - 2018 - Uncovering hidden brain state dynamics that regulate performance and decision-making during cognition.pdf:application/pdf},
}

@article{dimatteo_bayesian_2001,
	title = {Bayesian curve‐fitting with free‐knot splines},
	volume = {88},
	issn = {0006-3444},
	url = {http://dx.doi.org/10.1093/biomet/88.4.1055},
	abstract = {We describe a Bayesian method, for fitting curves to data drawn from an exponential family, that uses splines for which the number and locations of knots are free parameters. The method uses reversible‐jump Markov chain Monte Carlo to change the knot configurations and a locality heuristic to speed up mixing. For nonnormal models, we approximate the integrated likelihood ratios needed to compute acceptance probabilities by using the Bayesian information criterion, BIC, under priors that make this approximation accurate. Our technique is based on a marginalised chain on the knot number and locations, but we provide methods for inference about the regression coefficients, and functions of them, in both normal and nonnormal models. Simulation results suggest that the method performs well, and we illustrate the method in two neuroscience applications.},
	number = {4},
	journal = {Biometrika},
	author = {Dimatteo, Ilaria and Genovese, Christopher R and Kass, Robert E},
	month = dec,
	year = {2001},
	pages = {1055--1071},
	annote = {10.1093/biomet/88.4.1055},
	file = {Attachment:/Users/tito/Zotero/storage/I5XMMT57/Dimatteo, Genovese, Kass - 2001 - Bayesian curve‐fitting with free‐knot splines.pdf:application/pdf},
}

@article{zhang_neural_2016,
	title = {Neural, electrophysiological and anatomical basis of brain-network variability and its characteristic changes in mental disorders},
	volume = {139},
	issn = {0006-8950},
	url = {http://dx.doi.org/10.1093/brain/aww143},
	abstract = {Functional brain networks demonstrate significant temporal variability and dynamic reconfiguration even in the resting state. Currently, most studies investigate temporal variability of brain networks at the scale of single (micro) or whole-brain (macro) connectivity. However, the mechanism underlying time-varying properties remains unclear, as the coupling between brain network variability and neural activity is not readily apparent when analysed at either micro or macroscales. We propose an intermediate (meso) scale analysis and characterize temporal variability of the functional architecture associated with a particular region. This yields a topography of variability that reflects the whole-brain and, most importantly, creates an analytical framework to establish the fundamental relationship between variability of regional functional architecture and its neural activity or structural connectivity. We find that temporal variability reflects the dynamical reconfiguration of a brain region into distinct functional modules at different times and may be indicative of brain flexibility and adaptability. Primary and unimodal sensory-motor cortices demonstrate low temporal variability, while transmodal areas, including heteromodal association areas and limbic system, demonstrate the high variability. In particular, regions with highest variability such as hippocampus/parahippocampus, inferior and middle temporal gyrus, olfactory gyrus and caudate are all related to learning, suggesting that the temporal variability may indicate the level of brain adaptability. With simultaneously recorded electroencephalography/functional magnetic resonance imaging and functional magnetic resonance imaging/diffusion tensor imaging data, we also find that variability of regional functional architecture is modulated by local blood oxygen level-dependent activity and α-band oscillation, and is governed by the ratio of intra- to inter-community structural connectivity. Application of the mesoscale variability measure to multicentre datasets of three mental disorders and matched controls involving 1180 subjects reveals that those regions demonstrating extreme, i.e. highest/lowest variability in controls are most liable to change in mental disorders. Specifically, we draw attention to the identification of diametrically opposing patterns of variability changes between schizophrenia and attention deficit hyperactivity disorder/autism. Regions of the default-mode network demonstrate lower variability in patients with schizophrenia, but high variability in patients with autism/attention deficit hyperactivity disorder, compared with respective controls. In contrast, subcortical regions, especially the thalamus, show higher variability in schizophrenia patients, but lower variability in patients with attention deficit hyperactivity disorder. The changes in variability of these regions are also closely related to symptom scores. Our work provides insights into the dynamic organization of the resting brain and how it changes in brain disorders. The nodal variability measure may also be potentially useful as a predictor for learning and neural rehabilitation.},
	number = {8},
	journal = {Brain},
	author = {Zhang, Jie and Cheng, Wei and Liu, Zhaowen and Zhang, Kai and Lei, Xu and Yao, Ye and Becker, Benjamin and Liu, Yicen and Kendrick, Keith M and Lu, Guangming and Feng, Jianfeng},
	month = aug,
	year = {2016},
	pages = {2307--2321},
	annote = {10.1093/brain/aww143},
	file = {Attachment:/Users/tito/Zotero/storage/952TVCUP/Zhang et al. - 2016 - Neural, electrophysiological and anatomical basis of brain-network variability and its characteristic changes in m.pdf:application/pdf},
}

@article{shine_modulation_2018,
	title = {The modulation of neural gain facilitates a transition between functional segregation and integration in the brain},
	volume = {7},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.31130},
	doi = {10.7554/eLife.31130},
	abstract = {Cognitive function relies on a dynamic, context-sensitive balance between functional integration and segregation in the brain. Previous work has proposed that this balance is mediated by global fluctuations in neural gain by projections from ascending neuromodulatory nuclei. To test this hypothesis in silico, we studied the effects of neural gain on network dynamics in a model of large-scale neuronal dynamics. We found that increases in neural gain directed the network through an abrupt dynamical transition, leading to an integrated network topology that was maximal in frontoparietal ‘rich club' regions. This gain-mediated transition was also associated with increased topological complexity, as well as increased variability in time-resolved topological structure, further highlighting the potential computational benefits of the gain-mediated network transition. These results support the hypothesis that neural gain modulation has the computational capacity to mediate the balance between integration and segregation in the brain.},
	journal = {eLife},
	author = {Shine, James M and Aburn, Matthew J and Breakspear, Michael and Poldrack, Russell A},
	editor = {Deco, Gustavo},
	year = {2018},
	keywords = {BOLD, biophysical Model, excitability, integration, neural gain, noradrenaline},
	pages = {e31130},
	file = {Attachment:/Users/tito/Zotero/storage/75FR87PT/Shine et al. - 2018 - The modulation of neural gain facilitates a transition between functional segregation and integration in the brain.pdf:application/pdf},
}

@article{rodu_detecting_2018,
	title = {Detecting {Multivariate} {Cross}-{Correlation} {Between} {Brain} {Regions}},
	issn = {0022-3077},
	url = {https://doi.org/10.1152/jn.00869.2017},
	doi = {10.1152/jn.00869.2017},
	abstract = {The problem of identifying functional connectivity from multiple time series data recorded in each of two or more brain areas arises in many neuroscientific investigations. For a single stationary time series in each of two brain areas statistical tools such as cross-correlation and Granger causality may be applied. On the other hand, to examine multivariate interactions at a single time point, canonical correlation, which finds the linear combinations of signals that maximize the correlation, may be used. We report here a new method that produces interpretations much like these standard techniques and, in addition, (a) extends the idea of canonical correlation to 3-way arrays (with dimensionality number of signals by number of time points by number of trials), (b) allows for non-stationarity, (c) also allows for nonlinearity, (d) scales well as the number of signals increases, and (e) captures predictive relationships, as is done with Granger causality. We demonstrate the effectiveness of the method through simulation studies, and illustrate by analyzing local field potentials recorded from a behaving primate.},
	journal = {Journal of Neurophysiology},
	author = {Rodu, Jordan and Klein, Natalie and Brincat, Scott Louis and Miller, Earl K and Kass, Robert E},
	month = jun,
	year = {2018},
	annote = {doi: 10.1152/jn.00869.2017},
	file = {Attachment:/Users/tito/Zotero/storage/IQPGVGUB/Rodu et al. - 2018 - Detecting Multivariate Cross-Correlation Between Brain Regions.pdf:application/pdf},
}

@article{cheng_polynomial_2018,
	title = {Polynomial {Regression} {As} an {Alternative} to {Neural} {Nets}},
	url = {http://arxiv.org/abs/1806.06850},
	doi = {arXiv:1806.06850v2},
	abstract = {Despite the success of neural networks (NNs), there is still a concern among many over their "black box" nature. Why do they work? Here we present a simple analytic argument that NNs are in fact essentially polynomial regression models. This view will have various implications for NNs, e.g. providing an explanation for why convergence problems arise in NNs, and it gives rough guidance on avoiding overfitting. In addition, we use this phenomenon to predict and confirm a multicollinearity property of NNs not previously reported in the literature. Most importantly, given this loose correspondence, one may choose to routinely use polynomial models instead of NNs, thus avoiding some major problems of the latter, such as having to set many tuning parameters and dealing with convergence issues. We present a number of empirical results; in each case, the accuracy of the polynomial approach matches or exceeds that of NN approaches. A many-featured, open-source software package, polyreg, is available.},
	journal = {arXiv},
	author = {Cheng, Xi and Khomtchouk, Bohdan and Matloff, Norman and Mohanty, Pete},
	year = {2018},
	pages = {1--28},
}

@article{tkacik_searching_2014,
	title = {Searching for {Collective} {Behavior} in a {Large} {Network} of {Sensory} {Neurons}},
	volume = {10},
	url = {https://doi.org/10.1371/journal.pcbi.1003408},
	abstract = {Author Summary Sensory neurons encode information about the world into sequences of spiking and silence. Multi-electrode array recordings have enabled us to move from single units to measuring the responses of many neurons simultaneously, and thus to ask questions about how populations of neurons as a whole represent their input signals. Here we build on previous work that has shown that in the salamander retina, pairs of retinal ganglion cells are only weakly correlated, yet the population spiking activity exhibits large departures from a model where the neurons would be independent. We analyze data from more than a hundred salamander retinal ganglion cells and characterize their collective response using maximum entropy models of statistical physics. With these models in hand, we can put bounds on the amount of information encoded by the neural population, constructively demonstrate that the code has error correcting redundancy, and advance two hypotheses about the neural code: that collective states of the network could carry stimulus information, and that the distribution of neural activity patterns has very nontrivial statistical properties, possibly related to critical systems in statistical physics.},
	number = {1},
	journal = {PLOS Computational Biology},
	author = {Tkačik, Gašper and Marre, Olivier and Amodei, Dario and Schneidman, Elad and Bialek, William and Berry II, Michael J},
	month = jan,
	year = {2014},
	pages = {e1003408},
}

@article{brincat_gradual_2018,
	title = {Gradual progression from sensory to task-related processing in cerebral cortex},
	volume = {115},
	url = {http://www.pnas.org/content/115/30/E7202.abstract},
	abstract = {The earliest stages of processing in cerebral cortex reflect a relatively faithful copy of sensory inputs, but intelligent behavior requires abstracting behaviorally relevant concepts and categories. We examined how this transformation progresses through multiple levels of the cortical hierarchy by comparing neural representations in six cortical areas in monkeys categorizing across three visual domains. We found that categorical abstraction occurred in a gradual fashion across the cortical hierarchy and reached an apex in prefrontal cortex. Categorical coding did not respect classical models of large-scale cortical organization. The dimensionality of neural population activity was reduced in parallel with these representational changes. Our results shed light on how raw sensory inputs are transformed into behaviorally relevant abstractions.Somewhere along the cortical hierarchy, behaviorally relevant information is distilled from raw sensory inputs. We examined how this transformation progresses along multiple levels of the hierarchy by comparing neural representations in visual, temporal, parietal, and frontal cortices in monkeys categorizing across three visual domains (shape, motion direction, and color). Representations in visual areas middle temporal (MT) and V4 were tightly linked to external sensory inputs. In contrast, lateral prefrontal cortex (PFC) largely represented the abstracted behavioral relevance of stimuli (task rule, motion category, and color category). Intermediate-level areas, including posterior inferotemporal (PIT), lateral intraparietal (LIP), and frontal eye fields (FEF), exhibited mixed representations. While the distribution of sensory information across areas aligned well with classical functional divisions (MT carried stronger motion information, and V4 and PIT carried stronger color and shape information), categorical abstraction did not, suggesting these areas may participate in different networks for stimulus-driven and cognitive functions. Paralleling these representational differences, the dimensionality of neural population activity decreased progressively from sensory to intermediate to frontal cortex. This shows how raw sensory representations are transformed into behaviorally relevant abstractions and suggests that the dimensionality of neural activity in higher cortical regions may be specific to their current task.},
	number = {30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brincat, Scott L and Siegel, Markus and von Nicolai, Constantin and Miller, Earl K},
	month = jul,
	year = {2018},
	pages = {E7202 LP -- E7211},
	file = {Attachment:/Users/tito/Zotero/storage/IU4Z2ZHU/Brincat et al. - 2018 - Gradual progression from sensory to task-related processing in cerebral cortex.pdf:application/pdf},
}

@article{rajan_stimulus-dependent_2010,
	title = {Stimulus-dependent suppression of chaos in recurrent neural networks},
	volume = {82},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.82.011903},
	doi = {10.1103/PhysRevE.82.011903},
	number = {1},
	journal = {Physical Review E},
	author = {Rajan, Kanaka and Abbott, L F and Sompolinsky, Haim},
	month = jul,
	year = {2010},
	pages = {11903},
	file = {Attachment:/Users/tito/Zotero/storage/T6DIM42F/Rajan, Abbott, Sompolinsky - 2010 - Stimulus-dependent suppression of chaos in recurrent neural networks.pdf:application/pdf},
}

@article{truccolo_collective_2009,
	title = {Collective dynamics in human and monkey sensorimotor cortex: predicting single neuron spikes},
	volume = {13},
	url = {http://dx.doi.org/10.1038/nn.2455 http://10.0.4.14/nn.2455 https://www.nature.com/articles/nn.2455#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Truccolo, Wilson and Hochberg, Leigh R and Donoghue, John P},
	month = dec,
	year = {2009},
	pages = {105},
	file = {Attachment:/Users/tito/Zotero/storage/RNBELHK6/Truccolo, Hochberg, Donoghue - 2009 - Collective dynamics in human and monkey sensorimotor cortex predicting single neuron spikes.pdf:application/pdf},
}

@article{marre_prediction_2009,
	title = {Prediction of {Spatiotemporal} {Patterns} of {Neural} {Activity} from {Pairwise} {Correlations}},
	volume = {102},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.102.138101},
	doi = {10.1103/PhysRevLett.102.138101},
	number = {13},
	journal = {Physical Review Letters},
	author = {Marre, O and El Boustani, S and Frégnac, Y and Destexhe, A},
	month = apr,
	year = {2009},
	pages = {138101},
	file = {Attachment:/Users/tito/Zotero/storage/WGET6CGB/Marre et al. - 2009 - Prediction of Spatiotemporal Patterns of Neural Activity from Pairwise Correlations.pdf:application/pdf},
}

@article{josic_stimulus-dependent_2009,
	title = {Stimulus-{Dependent} {Correlations} and {Population} {Codes}},
	volume = {21},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.2009.10-08-879},
	doi = {10.1162/neco.2009.10-08-879},
	abstract = {The magnitude of correlations between stimulus-driven responses of pairs of neurons can itself be stimulus dependent. We examine how this dependence affects the information carried by neural populations about the stimuli that drive them. Stimulus-dependent changes in correlations can both carry information directly and modulate the information separately carried by the firing rates and variances. We use Fisher information to quantify these effects and show that, although stimulus-dependent correlations often carry little information directly, their modulatory effects on the overall information can be large. In particular, if the stimulus dependence is such that correlations increase with stimulus-induced firing rates, this can significantly enhance the information of the population when the structure of correlations is determined solely by the stimulus. However, in the presence of additional strong spatial decay of correlations, such stimulus dependence may have a negative impact. Opposite relationships hold when correlations decrease with firing rates.},
	number = {10},
	journal = {Neural Computation},
	author = {Josić, Krešimir and Shea-Brown, Eric and Doiron, Brent and de la Rocha, Jaime},
	month = jul,
	year = {2009},
	pages = {2774--2804},
	annote = {doi: 10.1162/neco.2009.10-08-879},
}

@article{deco_neural_2012,
	title = {Neural {Network} {Mechanisms} {Underlying} {Stimulus} {Driven} {Variability} {Reduction}},
	volume = {8},
	url = {https://doi.org/10.1371/journal.pcbi.1002395},
	abstract = {Author Summary To understand how neurons encode information, neuroscientists record their firing activity while the animal executes a given task for many trials. Surprisingly, it has been found that the neural response is highly variable, which a priori limits the encoding of information by these neurons. However, recent experiments have shown that this variability is reduced when the animal receives a stimulus or attends to a particular one, suggesting an enhancement of information encoding. It is known that a cause of neural variability resides in the fact that individual neurons receive an input which fluctuates around their firing threshold. We demonstrate here that all the experimental results can naturally arise from the dynamics of a neural network. Using a realistic model, we show that the neural variability during spontaneous activity is particularly high because input noise induces large fluctuations between multiple –but unstable- network states. With stimulation or attention, one particular network state is stabilized and fluctuations decrease, leading to a neural variability reduction. In conclusion, our results suggest that the observed variability reduction is a property of the neural circuits of the brain.},
	number = {3},
	journal = {PLOS Computational Biology},
	author = {Deco, Gustavo and Hugues, Etienne},
	month = mar,
	year = {2012},
	pages = {e1002395},
	file = {Attachment:/Users/tito/Zotero/storage/7LUYCDB6/Deco, Hugues - 2012 - Neural Network Mechanisms Underlying Stimulus Driven Variability Reduction.PDF:application/pdf},
}

@article{harris_cortical_2011,
	title = {Cortical state and attention},
	volume = {12},
	url = {http://dx.doi.org/10.1038/nrn3084 http://10.0.4.14/nrn3084},
	journal = {Nature Reviews Neuroscience},
	author = {Harris, Kenneth D and Thiele, Alexander},
	month = aug,
	year = {2011},
	pages = {509},
	file = {Attachment:/Users/tito/Zotero/storage/2K2SD77H/Harris, Thiele - 2011 - Cortical state and attention.pdf:application/pdf},
}

@article{renart_mean-driven_2006,
	title = {Mean-{Driven} and {Fluctuation}-{Driven} {Persistent} {Activity} in {Recurrent} {Networks}},
	volume = {19},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.2007.19.1.1},
	doi = {10.1162/neco.2007.19.1.1},
	abstract = {Spike trains from cortical neurons show a high degree of irregularity, with coefficients of variation (CV) of their interspike interval (ISI) distribution close to or higher than one. It has been suggested that this irregularity might be a reflection of a particular dynamical state of the local cortical circuit in which excitation and inhibition balance each other. In this ?balanced? state, the mean current to the neurons is below threshold, and firing is driven by current fluctuations, resulting in irregular Poisson-like spike trains. Recent data show that the degree of irregularity in neuronal spike trains recorded during the delay period of working memory experiments is the same for both low-activity states of a few Hz and for elevated, persistent activity states of a few tens of Hz. Since the difference between these persistent activity states cannot be due to external factors coming from sensory inputs, this suggests that the underlying network dynamics might support coexisting balanced states at different firing rates. We use mean field techniques to study the possible existence of multiple balanced steady states in recurrent networks of current-based leaky integrate-and-fire (LIF) neurons. To assess the degree of balance of a steady state, we extend existing mean-field theories so that not only the firing rate, but also the coefficient of variation of the interspike interval distribution of the neurons, are determined self-consistently. Depending on the connectivity parameters of the network, we find bistable solutions of different types. If the local recurrent connectivity is mainly excitatory, the two stable steady states differ mainly in the mean current to the neurons. In this case, the mean drive in the elevated persistent activity state is suprathreshold and typically characterized by low spiking irregularity. If the local recurrent excitatory and inhibitory drives are both large and nearly balanced, or even dominated by inhibition, two stable states coexist, both with subthreshold current drive. In this case, the spiking variability in both the resting state and the mnemonic persistent state is large, but the balance condition implies parameter fine-tuning. Since the degree of required fine-tuning increases with network size and, on the other hand, the size of the fluctuations in the afferent current to the cells increases for small networks, overall we find that fluctuation-driven persistent activity in the very simplified type of models we analyze is not a robust phenomenon. Possible implications of considering more realistic models are discussed.},
	number = {1},
	journal = {Neural Computation},
	author = {Renart, Alfonso and Moreno-Bote, Rubén and Wang, Xiao-Jing and Parga, Néstor},
	month = nov,
	year = {2006},
	pages = {1--46},
	annote = {doi: 10.1162/neco.2007.19.1.1},
	file = {Attachment:/Users/tito/Zotero/storage/N3M45N9U/Renart et al. - 2006 - Mean-Driven and Fluctuation-Driven Persistent Activity in Recurrent Networks.pdf:application/pdf},
}

@article{renart_asynchronous_2010,
	title = {The {Asynchronous} {State} in {Cortical} {Circuits}},
	volume = {327},
	url = {http://science.sciencemag.org/content/327/5965/587.abstract},
	abstract = {Correlated spiking is often observed in cortical circuits, but its functional role is controversial. It is believed that correlations are a consequence of shared inputs between nearby neurons and could severely constrain information decoding. Here we show theoretically that recurrent neural networks can generate an asynchronous state characterized by arbitrarily low mean spiking correlations despite substantial amounts of shared input. In this state, spontaneous fluctuations in the activity of excitatory and inhibitory populations accurately track each other, generating negative correlations in synaptic currents which cancel the effect of shared input. Near-zero mean correlations were seen experimentally in recordings from rodent neocortex in vivo. Our results suggest a reexamination of the sources underlying observed correlations and their functional consequences for information processing.},
	number = {5965},
	journal = {Science},
	author = {Renart, Alfonso and de la Rocha, Jaime and Bartho, Peter and Hollender, Liad and Parga, Néstor and Reyes, Alex and Harris, Kenneth D},
	month = jan,
	year = {2010},
	pages = {587 LP -- 590},
	file = {Attachment:/Users/tito/Zotero/storage/EJU2YX48/Renart et al. - 2010 - The Asynchronous State in Cortical Circuits.pdf:application/pdf},
}

@article{chance_gain_2002,
	title = {Gain {Modulation} from {Background} {Synaptic} {Input}},
	volume = {35},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627302008206},
	doi = {https://doi.org/10.1016/S0896-6273(02)00820-6},
	abstract = {Gain modulation is a prominent feature of neuronal activity recorded in behaving animals, but the mechanism by which it occurs is unknown. By introducing a barrage of excitatory and inhibitory synaptic conductances that mimics conditions encountered in vivo into pyramidal neurons in slices of rat somatosensory cortex, we show that the gain of a neuronal response to excitatory drive can be modulated by varying the level of “background” synaptic input. Simultaneously increasing both excitatory and inhibitory background firing rates in a balanced manner results in a divisive gain modulation of the neuronal response without appreciable signal-independent increases in firing rate or spike-train variability. These results suggest that, within active cortical circuits, the overall level of synaptic input to a neuron acts as a gain control signal that modulates responsiveness to excitatory drive.},
	number = {4},
	journal = {Neuron},
	author = {Chance, Frances S and Abbott, L F and Reyes, Alex D},
	year = {2002},
	pages = {773--782},
}

@article{de_la_rocha_correlation_2007,
	title = {Correlation between neural spike trains increases with firing rate},
	volume = {448},
	url = {http://dx.doi.org/10.1038/nature06028 http://10.0.4.14/nature06028 https://www.nature.com/articles/nature06028#supplementary-information},
	journal = {Nature},
	author = {de la Rocha, Jaime and Doiron, Brent and Shea-Brown, Eric and Josić, Krešimir and Reyes, Alex},
	month = aug,
	year = {2007},
	pages = {802},
	file = {Attachment:/Users/tito/Zotero/storage/E4WDJ3N4/de la Rocha et al. - 2007 - Correlation between neural spike trains increases with firing rate.pdf:application/pdf},
}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	url = {http://dx.doi.org/10.1038/nature14236 http://10.0.4.14/nature14236 https://www.nature.com/articles/nature14236#supplementary-information},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	pages = {529},
	file = {Attachment:/Users/tito/Zotero/storage/INENVZA4/Mnih et al. - 2015 - Human-level control through deep reinforcement learning.pdf:application/pdf},
}

@article{rosenbaum_short-term_2012,
	title = {Short-term synaptic depression and stochastic vesicle dynamics reduce and shape neuronal correlations},
	volume = {109},
	issn = {0022-3077},
	url = {https://doi.org/10.1152/jn.00733.2012},
	doi = {10.1152/jn.00733.2012},
	abstract = {Correlated neuronal activity is an important feature in many neural codes, a neural correlate of a variety of cognitive states, as well as a signature of several disease states in the nervous system. The cellular and circuit mechanics of neural correlations is a vibrant area of research. Synapses throughout the cortex exhibit a form of short-term depression where increased presynaptic firing rates deplete neurotransmitter vesicles, which transiently reduces synaptic efficacy. The release and recovery of these vesicles are inherently stochastic, and this stochasticity introduces variability into the conductance elicited by depressing synapses. The impact of spiking and subthreshold membrane dynamics on the transfer of neuronal correlations has been studied intensively, but an investigation of the impact of short-term synaptic depression and stochastic vesicle dynamics on correlation transfer is lacking. We find that short-term synaptic depression and stochastic vesicle dynamics can substantially reduce correlations, shape the timescale over which these correlations occur, and alter the dependence of spiking correlations on firing rate. Our results show that short-term depression and stochastic vesicle dynamics need to be taken into account when modeling correlations in neuronal populations.},
	number = {2},
	journal = {Journal of Neurophysiology},
	author = {Rosenbaum, Robert and Rubin, Jonathan E and Doiron, Brent},
	month = oct,
	year = {2012},
	pages = {475--484},
	annote = {doi: 10.1152/jn.00733.2012},
	file = {Attachment:/Users/tito/Zotero/storage/YM4JJ6GT/Rosenbaum, Rubin, Doiron - 2012 - Short-term synaptic depression and stochastic vesicle dynamics reduce and shape neuronal correlations.pdf:application/pdf},
}

@article{love_algorithmic_2015,
	title = {The {Algorithmic} {Level} {Is} the {Bridge} {Between} {Computation} and {Brain}},
	volume = {7},
	issn = {1756-8757},
	url = {https://doi.org/10.1111/tops.12131},
	doi = {10.1111/tops.12131},
	abstract = {Abstract Every scientist chooses a preferred level of analysis and this choice shapes the research program, even determining what counts as evidence. This contribution revisits Marr's (1982) three levels of analysis (implementation, algorithmic, and computational) and evaluates the prospect of making progress at each individual level. After reviewing limitations of theorizing within a level, two strategies for integration across levels are considered. One is top?down in that it attempts to build a bridge from the computational to algorithmic level. Limitations of this approach include insufficient theoretical constraint at the computation level to provide a foundation for integration, and that people are suboptimal for reasons other than capacity limitations. Instead, an inside-out approach is forwarded in which all three levels of analysis are integrated via the algorithmic level. This approach maximally leverages mutual data constraints at all levels. For example, algorithmic models can be used to interpret brain imaging data, and brain imaging data can be used to select among competing models. Examples of this approach to integration are provided. This merging of levels raises questions about the relevance of Marr's tripartite view.},
	number = {2},
	journal = {Topics in Cognitive Science},
	author = {Love, Bradley C},
	month = mar,
	year = {2015},
	keywords = {Approximately Bayesian, Categorization, Levels of analysis, Model-based fMRI analysis, Rational analysis},
	pages = {230--242},
	annote = {doi: 10.1111/tops.12131},
	file = {Attachment:/Users/tito/Zotero/storage/3LD3RF4H/Love - 2015 - The Algorithmic Level Is the Bridge Between Computation and Brain.pdf:application/pdf},
}

@article{paninski_estimation_2003,
	title = {Estimation of {Entropy} and {Mutual} {Information}},
	volume = {15},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976603321780272},
	doi = {10.1162/089976603321780272},
	abstract = {We present some new results on the nonparametric estimation of entropy and mutual information. First, we use an exact local expansion of the entropy function to prove almost sure consistency and central limit theorems for three of the most commonly used discretized information estimators. The setup is related to Grenander's method of sieves and places no assumptions on the underlying probability measure generating the data. Second, we prove a converse to these consistency theorems, demonstrating that a misapplication of the most common estimation techniques leads to an arbitrarily poor estimate of the true information, even given unlimited data. This ?inconsistency? theorem leads to an analytical approximation of the bias, valid in surprisingly small sample regimes and more accurate than the usual formula of Miller and Madow over a large region of parameter space. The two most practical implications of these results are negative: (1) information estimates in a certain data regime are likely contaminated by bias, even if ?bias-corrected? estimators are used, and (2) confidence intervals calculated by standard techniques drastically underestimate the error of the most common estimation methods. Finally, we note a very useful connection between the bias of entropy estimators and a certain polynomial approximation problem. By casting bias calculation problems in this approximation theory framework, we obtain the best possible generalization of known asymptotic bias results. More interesting, this framework leads to an estimator with some nice properties: the estimator comes equipped with rigorous bounds on the maximum error over all possible underlying probability distributions, and this maximum error turns out to be surprisingly small. We demonstrate the application of this new estimator on both real and simulated data.},
	number = {6},
	journal = {Neural Computation},
	author = {Paninski, Liam},
	month = jun,
	year = {2003},
	pages = {1191--1253},
	annote = {doi: 10.1162/089976603321780272},
	file = {Attachment:/Users/tito/Zotero/storage/34M26TIY/Paninski - 2003 - Estimation of Entropy and Mutual Information.pdf:application/pdf},
}

@article{mastrogiuseppe_linking_2018,
	title = {Linking {Connectivity}, {Dynamics}, and {Computations} in {Low}-{Rank} {Recurrent} {Neural} {Networks}},
	issn = {0896-6273},
	url = {https://doi.org/10.1016/j.neuron.2018.07.003},
	doi = {10.1016/j.neuron.2018.07.003},
	abstract = {Large-scale neural recordings have established that the transformation of sensory stimuli into motor outputs relies on low-dimensional dynamics at the population level, while individual neurons exhibit complex selectivity. Understanding how low-dimensional computations on mixed, distributed representations emerge from the structure of the recurrent connectivity and inputs to cortical networks is a major challenge. Here, we study a class of recurrent network models in which the connectivity is a sum of a random part and a minimal, low-dimensional structure. We show that, in such networks, the dynamics are low dimensional and can be directly inferred from connectivity using a geometrical approach. We exploit this understanding to determine minimal connectivity required to implement specific computations and find that the dynamical range and computational capacity quickly increase with the dimensionality of the connectivity structure. This framework produces testable experimental predictions for the relationship between connectivity, low-dimensional dynamics, and computational features of recorded neurons.},
	journal = {Neuron},
	author = {Mastrogiuseppe, Francesca and Ostojic, Srdjan},
	month = aug,
	year = {2018},
	annote = {doi: 10.1016/j.neuron.2018.07.003},
	file = {Attachment:/Users/tito/Zotero/storage/N3XSZQNU/Mastrogiuseppe, Ostojic - 2017 - Linking connectivity, dynamics and computations in recurrent neural networks.pdf:application/pdf},
}

@article{bijsterbosch_investigations_2017,
	title = {Investigations into within- and between-subject resting-state amplitude variations},
	volume = {159},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305827},
	doi = {https://doi.org/10.1016/j.neuroimage.2017.07.014},
	abstract = {The amplitudes of spontaneous fluctuations in brain activity may be a significant source of within-subject and between-subject variability, and this variability is likely to be carried through into functional connectivity (FC) estimates (whether directly or indirectly). Therefore, improving our understanding of amplitude fluctuations over the course of a resting state scan and variation in amplitude across individuals is of great relevance to the interpretation of FC findings. We investigate resting state amplitudes in two large-scale studies (HCP and UK Biobank), with the aim of determining between-subject and within-subject variability. Between-subject clustering distinguished between two groups of brain networks whose amplitude variation across subjects were highly correlated with each other, revealing a clear distinction between primary sensory and motor regions (‘primary sensory/motor cluster') and cognitive networks. Within subjects, all networks in the primary sensory/motor cluster showed a consistent increase in amplitudes from the start to the end of the scan. In addition to the strong increases in primary sensory/motor amplitude, a large number of changes in FC were found when comparing the two scans acquired on the same day (HCP data). Additive signal change analysis confirmed that all of the observed FC changes could be fully explained by changes in amplitude. Between-subject correlations in UK Biobank data showed a negative correlation between primary sensory/motor amplitude and average sleep duration, suggesting a role of arousal. Our findings additionally reveal complex relationships between amplitude and head motion. These results suggest that network amplitude is a source of significant variability both across subjects, and within subjects on a within-session timescale. Future rfMRI studies may benefit from obtaining arousal-related (self report) measures, and may wish to consider the influence of amplitude changes on measures of (dynamic) functional connectivity.},
	journal = {NeuroImage},
	author = {Bijsterbosch, Janine and Harrison, Samuel and Duff, Eugene and Alfaro-Almagro, Fidel and Woolrich, Mark and Smith, Stephen},
	year = {2017},
	keywords = {Functional connectivity, Amplitude, Resting state, Variability},
	pages = {57--69},
}

@article{duff_disambiguating_2018,
	title = {Disambiguating brain functional connectivity},
	volume = {173},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918300533},
	doi = {https://doi.org/10.1016/j.neuroimage.2018.01.053},
	journal = {NeuroImage},
	author = {Duff, Eugene P and Makin, Tamar and Cottaar, Michiel and Smith, Stephen M and Woolrich, Mark W},
	year = {2018},
	keywords = {Functional connectivity, Correlation, Effective connectivity, FMRI, SNR},
	pages = {540--550},
	file = {Attachment:/Users/tito/Zotero/storage/LF23D7NJ/Duff et al. - 2018 - Disambiguating brain functional connectivity.pdf:application/pdf},
}

@article{ritchie_avoiding_2017,
	title = {Avoiding illusory effects in representational similarity analysis: {What} (not) to do with the diagonal},
	volume = {148},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811916308059},
	doi = {https://doi.org/10.1016/j.neuroimage.2016.12.079},
	journal = {NeuroImage},
	author = {Ritchie, J Brendan and Bracci, Stefania and Op de Beeck, Hans},
	year = {2017},
	keywords = {Neuroimaging, Object categorization, Representational similarity analysis, Ventral temporal cortex},
	pages = {197--200},
	file = {Attachment:/Users/tito/Zotero/storage/KEPVF3AT/Ritchie, Bracci, Op de Beeck - 2017 - Avoiding illusory effects in representational similarity analysis What (not) to do with the diagon.pdf:application/pdf},
}

@article{walther_reliability_2016,
	title = {Reliability of dissimilarity measures for multi-voxel pattern analysis},
	volume = {137},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811915011258},
	doi = {https://doi.org/10.1016/j.neuroimage.2015.12.012},
	journal = {NeuroImage},
	author = {Walther, Alexander and Nili, Hamed and Ejaz, Naveed and Alink, Arjen and Kriegeskorte, Nikolaus and Diedrichsen, Jörn},
	year = {2016},
	keywords = {fMRI, Representational similarity analysis, Classification, Crossvalidation, Decoding, Linear discriminant, Machine learning, Multi-voxel pattern analysis, Noise normalization},
	pages = {188--200},
	file = {Attachment:/Users/tito/Zotero/storage/CZ53S5KV/Walther et al. - 2016 - Reliability of dissimilarity measures for multi-voxel pattern analysis.pdf:application/pdf},
}

@article{kuchibhotla_parallel_2016,
	title = {Parallel processing by cortical inhibition enables context-dependent behavior},
	volume = {20},
	url = {http://dx.doi.org/10.1038/nn.4436 http://10.0.4.14/nn.4436 https://www.nature.com/articles/nn.4436#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Kuchibhotla, Kishore V and Gill, Jonathan V and Lindsay, Grace W and Papadoyannis, Eleni S and Field, Rachel E and Sten, Tom A Hindmarsh and Miller, Kenneth D and Froemke, Robert C},
	month = oct,
	year = {2016},
	pages = {62},
	file = {Attachment:/Users/tito/Zotero/storage/W996N6GS/Tononi, Edelman, Sporns - 1998 - Complexity and coherency integrating information in the brain(2).pdf:application/pdf},
}

@article{ahlheim_estimating_2018,
	title = {Estimating the functional dimensionality of neural representations},
	url = {http://biorxiv.org/content/early/2018/01/05/232454.abstract},
	abstract = {Recent advances in multivariate fMRI analysis stress the importance of information inherent to voxel patterns. Key to interpreting these patterns is estimating the underlying dimensionality of neural representations. Dimensions may correspond to psychological dimensions, such as length and orientation, or involve other coding schemes. Unfortunately, the noise structure of fMRI data inflates dimensionality estimates and thus makes it difficult to assess the true underlying dimensionality of a pattern. To address this challenge, we developed a novel approach to identify brain regions that carry reliable task-modulated signal and to derive an estimate of the signal\&\#039;s functional dimensionality. We combined singular value decomposition with cross-validation to find the best low-dimensional projection of a pattern of voxel-responses at a single-subject level. Goodness of the low-dimensional reconstruction is measured as Pearson correlation with a test set, which allows to test for significance of the low-dimensional reconstruction across participants. Using hierarchical Bayesian modeling, we derive the best estimate and associated uncertainty of underlying dimensionality across participants. We validated our method on simulated data of varying underlying dimensionality, showing that recovered dimensionalities match closely true dimensionalities. We then applied our method to three published fMRI data sets all involving processing of visual stimuli. The results highlight three possible applications of estimating the functional dimensionality of neural data. Firstly, it can aid evaluation of model-based analyses by revealing which areas express reliable, task-modulated signal that could be missed by specific models. Secondly, it can reveal functional differences across brain regions. Thirdly, knowing the functional dimensionality allows assessing task-related differences in the complexity of neural patterns.},
	journal = {bioRxiv},
	author = {Ahlheim, Christiane and Love, Bradley C},
	month = jan,
	year = {2018},
	keywords = {Dimensionality reduction, Multivariate analysis, Neural representations},
}

@article{khaligh-razavi_fixed_2017,
	title = {Fixed versus mixed {RSA}: {Explaining} visual representations by fixed and mixed feature sets from shallow and deep computational models},
	volume = {76},
	issn = {0022-2496},
	url = {http://www.sciencedirect.com/science/article/pii/S0022249616301134},
	doi = {https://doi.org/10.1016/j.jmp.2016.10.007},
	journal = {Journal of Mathematical Psychology},
	author = {Khaligh-Razavi, Seyed-Mahdi and Henriksson, Linda and Kay, Kendrick and Kriegeskorte, Nikolaus},
	year = {2017},
	keywords = {Representational similarity analysis, Deep convolutional networks, Mixed RSA, Object-vision models, Voxel-receptive-field modelling},
	pages = {184--197},
	file = {Attachment:/Users/tito/Zotero/storage/CZIHR45G/Khaligh-Razavi et al. - 2017 - Fixed versus mixed RSA Explaining visual representations by fixed and mixed feature sets from shallow and.pdf:application/pdf},
}

@article{grandjean_structural_2017,
	title = {Structural {Basis} of {Large}-{Scale} {Functional} {Connectivity} in the {Mouse}},
	volume = {37},
	url = {http://www.jneurosci.org/content/37/34/8092.abstract},
	abstract = {Translational neuroimaging requires approaches and techniques that can bridge between multiple different species and disease states. One candidate method that offers insights into the brain\&\#039;s functional connectivity (FC) is resting-state fMRI (rs-fMRI). In both humans and nonhuman primates, patterns of FC (often referred to as the functional connectome) have been related to the underlying structural connectivity (SC; also called the structural connectome). Given the recent rise in preclinical neuroimaging of mouse models, it is an important question whether the mouse functional connectome conforms to the underlying SC. Here, we compared FC derived from rs-fMRI in female mice with the underlying monosynaptic structural connectome as provided by the Allen Brain Connectivity Atlas. We show that FC between interhemispheric homotopic cortical and hippocampal areas, as well as in cortico-striatal pathways, emerges primarily via monosynaptic structural connections. In particular, we demonstrate that the striatum (STR) can be segregated according to differential rs-fMRI connectivity patterns that mirror monosynaptic connectivity with isocortex. In contrast, for certain subcortical networks, FC emerges along polysynaptic pathways as shown for left and right STR, which do not share direct anatomical connections, but high FC is putatively driven by a top-down cortical control. Finally, we show that FC involving cortico-thalamic pathways is limited, possibly confounded by the effect of anesthesia, small regional size, and tracer injection volume. These findings provide a critical foundation for using rs-fMRI connectivity as a translational tool to study complex brain circuitry interactions and their pathology due to neurological or psychiatric diseases across species.SIGNIFICANCE STATEMENT A comprehensive understanding of how the anatomical architecture of the brain, often referred to as the “connectome,” corresponds to its function is arguably one of the biggest challenges for understanding the brain and its pathologies. Here, we use the mouse as a model for comparing functional connectivity (FC) derived from resting-state fMRI with gold standard structural connectivity measures based on tracer injections. In particular, we demonstrate high correspondence between FC measurements of cortico-cortical and cortico-striatal regions and their anatomical underpinnings. This work provides a critical foundation for studying the pathology of these circuits across mouse models and human patients.},
	number = {34},
	journal = {The Journal of Neuroscience},
	author = {Grandjean, Joanes and Zerbi, Valerio and Balsters, Joshua Henk and Wenderoth, Nicole and Rudin, Markus},
	month = aug,
	year = {2017},
	pages = {8092 LP -- 8101},
	file = {Attachment:/Users/tito/Zotero/storage/FNU64534/Grandjean et al. - 2017 - Structural Basis of Large-Scale Functional Connectivity in the Mouse.pdf:application/pdf},
}

@article{betzel_specificity_2018,
	title = {Specificity and robustness of long-distance connections in weighted, interareal connectomes},
	url = {http://www.pnas.org/content/early/2018/05/07/1720186115.abstract},
	abstract = {Interareal communication occurs along physical pathways. The prevailing hypothesis is that long-distance connections reduce the processing length between brain areas, facilitating efficient communication. We show, in five weighted interareal network datasets, that the correlation of connection weight with distance implies that long-distance connections play only a minor role in reducing path length. Instead, long-distance connections add diversity to brain area inputs and outputs, leading to increasingly complex brain dynamics. These findings help to clarify our understanding of how brain structure contributes to interareal communication.Brain areas' functional repertoires are shaped by their incoming and outgoing structural connections. In empirically measured networks, most connections are short, reflecting spatial and energetic constraints. Nonetheless, a small number of connections span long distances, consistent with the notion that the functionality of these connections must outweigh their cost. While the precise function of long-distance connections is unknown, the leading hypothesis is that they act to reduce the topological distance between brain areas and increase the efficiency of interareal communication. However, this hypothesis implies a nonspecificity of long-distance connections that we contend is unlikely. Instead, we propose that long-distance connections serve to diversify brain areas' inputs and outputs, thereby promoting complex dynamics. Through analysis of five weighted interareal network datasets, we show that long-distance connections play only minor roles in reducing average interareal topological distance. In contrast, areas' long-distance and short-range neighbors exhibit marked differences in their connectivity profiles, suggesting that long-distance connections enhance dissimilarity between areal inputs and outputs. Next, we show that—in isolation—areas' long-distance connectivity profiles exhibit nonrandom levels of similarity, suggesting that the communication pathways formed by long connections exhibit redundancies that may serve to promote robustness. Finally, we use a linearization of Wilson–Cowan dynamics to simulate the covariance structure of neural activity and show that in the absence of long-distance connections a common measure of functional diversity decreases. Collectively, our findings suggest that long-distance connections are necessary for supporting diverse and complex brain dynamics.},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Betzel, Richard F and Bassett, Danielle S},
	month = may,
	year = {2018},
	keywords = {complex networks, connectome, communication, wiring cost},
	file = {Full Text PDF:/Users/tito/Zotero/storage/465LL465/Betzel and Bassett - 2018 - Specificity and robustness of long-distance connec.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/S89GZV78/E4880.html:text/html},
}

@article{hennequin_dynamical_2018,
	title = {The {Dynamical} {Regime} of {Sensory} {Cortex}: {Stable} {Dynamics} around a {Single} {Stimulus}-{Tuned} {Attractor} {Account} for {Patterns} of {Noise} {Variability}},
	volume = {98},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318303258},
	doi = {https://doi.org/10.1016/j.neuron.2018.04.017},
	number = {4},
	journal = {Neuron},
	author = {Hennequin, Guillaume and Ahmadian, Yashar and Rubin, Daniel B and Lengyel, Máté and Miller, Kenneth D},
	year = {2018},
	keywords = {circuit dynamics, cortical variability, MT, noise correlations, theoretical neuroscience, V1, variability quenching},
	pages = {846--860.e5},
	file = {Attachment:/Users/tito/Zotero/storage/V35JTU3S/Hennequin et al. - 2018 - The Dynamical Regime of Sensory Cortex Stable Dynamics around a Single Stimulus-Tuned Attractor Account for Pa.pdf:application/pdf},
}

@article{murphy_balanced_2009,
	title = {Balanced {Amplification}: {A} {New} {Mechanism} of {Selective} {Amplification} of {Neural} {Activity} {Patterns}},
	volume = {61},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627309001287},
	doi = {https://doi.org/10.1016/j.neuron.2009.02.005},
	abstract = {Summary In cerebral cortex, ongoing activity absent a stimulus can resemble stimulus-driven activity in size and structure. In particular, spontaneous activity in cat primary visual cortex (V1) has structure significantly correlated with evoked responses to oriented stimuli. This suggests that, from unstructured input, cortical circuits selectively amplify specific activity patterns. Current understanding of selective amplification involves elongation of a neural assembly's lifetime by mutual excitation among its neurons. We introduce a new mechanism for selective amplification without elongation of lifetime: “balanced amplification.” Strong balanced amplification arises when feedback inhibition stabilizes strong recurrent excitation, a pattern likely to be typical of cortex. Thus, balanced amplification should ubiquitously contribute to cortical activity. Balanced amplification depends on the fact that individual neurons project only excitatory or only inhibitory synapses. This leads to a hidden feedforward connectivity between activity patterns. We show in a detailed biophysical model that this can explain the cat V1 observations.},
	number = {4},
	journal = {Neuron},
	author = {Murphy, Brendan K and Miller, Kenneth D},
	year = {2009},
	keywords = {SYSNEURO},
	pages = {635--648},
	file = {Attachment:/Users/tito/Zotero/storage/PLADF3GC/Murphy, Miller - 2009 - Balanced Amplification A New Mechanism of Selective Amplification of Neural Activity Patterns.pdf:application/pdf},
}

@article{gratton_functional_2018,
	title = {Functional {Brain} {Networks} {Are} {Dominated} by {Stable} {Group} and {Individual} {Factors}, {Not} {Cognitive} or {Daily} {Variation}},
	volume = {98},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318302411},
	doi = {https://doi.org/10.1016/j.neuron.2018.03.035},
	number = {2},
	journal = {Neuron},
	author = {Gratton, Caterina and Laumann, Timothy O and Nielsen, Ashley N and Greene, Deanna J and Gordon, Evan M and Gilmore, Adrian W and Nelson, Steven M and Coalson, Rebecca S and Snyder, Abraham Z and Schlaggar, Bradley L and Dosenbach, Nico U F and Petersen, Steven E},
	year = {2018},
	keywords = {fMRI, brain networks, functional connectivity, individual differences},
	pages = {439--452.e5},
	file = {Attachment:/Users/tito/Zotero/storage/MMZNLAFB/Gratton et al. - 2018 - Functional Brain Networks Are Dominated by Stable Group and Individual Factors, Not Cognitive or Daily Variation.pdf:application/pdf},
}

@article{reinen_human_2018,
	title = {The human cortex possesses a reconfigurable dynamic network architecture that is disrupted in psychosis},
	volume = {9},
	issn = {2041-1723},
	url = {https://doi.org/10.1038/s41467-018-03462-y},
	doi = {10.1038/s41467-018-03462-y},
	abstract = {Higher-order cognition emerges through the flexible interactions of large-scale brain networks, an aspect of temporal coordination that may be impaired in psychosis. Here, we map the dynamic functional architecture of the cerebral cortex in healthy young adults, leveraging this atlas of transient network configurations (states), to identify state- and network-specific disruptions in patients with schizophrenia and psychotic bipolar disorder. We demonstrate that dynamic connectivity profiles are reliable within participants, and can act as a fingerprint, identifying specific individuals within a larger group. Patients with psychotic illness exhibit intermittent disruptions within cortical networks previously associated with the disease, and the individual connectivity profiles within specific brain states predict the presence of active psychotic symptoms. Taken together, these results provide evidence for a reconfigurable dynamic architecture in the general population and suggest that prior reports of network disruptions in psychosis may reflect symptom-relevant transient abnormalities, rather than a time-invariant global deficit.},
	number = {1},
	journal = {Nature Communications},
	author = {Reinen, Jenna M and Chén, Oliver Y and Hutchison, R Matthew and Yeo, B T Thomas and Anderson, Kevin M and Sabuncu, Mert R and Öngür, Dost and Roffman, Joshua L and Smoller, Jordan W and Baker, Justin T and Holmes, Avram J},
	year = {2018},
	pages = {1157},
	file = {Attachment:/Users/tito/Zotero/storage/VTUIVVXK/Reinen et al. - 2018 - The human cortex possesses a reconfigurable dynamic network architecture that is disrupted in psychosis.pdf:application/pdf},
}

@article{greve_survey_2013,
	title = {A {Survey} of the {Sources} of {Noise} in {fMRI}},
	volume = {78},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/s11336-012-9294-0},
	doi = {10.1007/s11336-012-9294-0},
	abstract = {Functional magnetic resonance imaging (fMRI) is a noninvasive method for measuring brain function by correlating temporal changes in local cerebral blood oxygenation with behavioral measures. fMRI is used to study individuals at single time points, across multiple time points (with or without intervention), as well as to examine the variation of brain function across normal and ill populations. fMRI may be collected at multiple sites and then pooled into a single analysis. This paper describes how fMRI data is analyzed at each of these levels and describes the noise sources introduced at each level.},
	number = {3},
	journal = {Psychometrika},
	author = {Greve, Douglas N and Brown, Gregory G and Mueller, Bryon A and Glover, Gary and Liu, Thomas T},
	year = {2013},
	pages = {396--416},
	file = {Attachment:/Users/tito/Zotero/storage/JPVIG23H/Greve et al. - 2013 - A Survey of the Sources of Noise in fMRI.pdf:application/pdf},
}

@article{joglekar_inter-areal_2018,
	title = {Inter-areal {Balanced} {Amplification} {Enhances} {Signal} {Propagation} in a {Large}-{Scale} {Circuit} {Model} of the {Primate} {Cortex}},
	volume = {98},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318301521},
	doi = {https://doi.org/10.1016/j.neuron.2018.02.031},
	abstract = {Summary Understanding reliable signal transmission represents a notable challenge for cortical systems, which display a wide range of weights of feedforward and feedback connections among heterogeneous areas. We re-examine the question of signal transmission across the cortex in a network model based on mesoscopic directed and weighted inter-areal connectivity data of the macaque cortex. Our findings reveal that, in contrast to purely feedforward propagation models, the presence of long-range excitatory feedback projections could compromise stable signal propagation. Using population rate models as well as a spiking network model, we find that effective signal propagation can be accomplished by balanced amplification across cortical areas while ensuring dynamical stability. Moreover, the activation of prefrontal cortex in our model requires the input strength to exceed a threshold, which is consistent with the ignition model of conscious processing. These findings demonstrate our model as an anatomically realistic platform for investigations of global primate cortex dynamics.},
	number = {1},
	journal = {Neuron},
	author = {Joglekar, Madhura R and Mejias, Jorge F and Yang, Guangyu Robert and Wang, Xiao-Jing},
	year = {2018},
	keywords = {computational modeling of large-scale monkey corte, ignition theory of awareness, inter-areal balanced excitation-inhibition, recurrent global brain network dynamics, signal propagation},
	pages = {222--234.e8},
	file = {Attachment:/Users/tito/Zotero/storage/SWPNZVGX/Joglekar et al. - 2018 - Inter-areal Balanced Amplification Enhances Signal Propagation in a Large-Scale Circuit Model of the Primate Co.pdf:application/pdf},
}

@article{anzellotti_measuring_2016,
	title = {Measuring and {Modeling} {Transformations} of {Information} {Between} {Brain} {Regions} with {fMRI}},
	doi = {10.1101/074856},
	abstract = {Investigating how information is transformed from brain region to brain region is a crucial step to understand the neural foundations of cognitive processes. This investigation requires a characterization of the representations encoded in different regions, and models of how they are transformed that can match the complexity of neural processes. We introduce an approach in which representations are characterized as points in multidimensional spaces, and processes transforming representations from region to region are modeled as nonlinear functions using artificial neural networks. Across multiple experiments with different stimuli and tasks, we show that this approach reveals functionally relevant network structure and outperforms comparable linear models at predicting independent data. Cognition consists of processes operating on representations. A key challenge for cognitive neuroscience is therefore to characterize the transformation of representations that occurs during neural processing. Representations in cortex can be characterized in terms of distinct patterns of neural population activity (using direct electrophysiological recording 1) or of blood oxygenation (e.g. using functional magnetic resonance imaging, fMRI 2). For example, different object categories evoke distinct spatial patterns of activity across ventral temporal cortex 3 . Over the past decade, several new methods have been developed to characterize neural representations by exploiting the rich variability in multivariate neural responses: to extract information about stimuli or tasks 2-6 , and to directly model the encoding of this information within a cortical region 7 . The next open question is: How are representations transformed as they are processed, between brain regions? This article describes an approach to investigate this question. The approach is described and tested using fMRI data, but it is more generally applicable to other data acquisition techniques. Existing methods for capturing inter-region interactions using fMRI data assume, implicitly or explicitly, that such interactions are linear. For example, widely used techniques, like functional connectivity 8},
	journal = {bioRxiv},
	author = {Anzellotti, Stefano and Fedorenko, Evelina and Caramazza, Alfonso and Saxe, Rebecca},
	year = {2016},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/XCZ3Z5LL/Anzellotti et al. - 2016 - Measuring and modeling transformations of nformation between brain regions with fMRI.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/KY4NDSFE/Anzellotti et al. - 2016 - Measuring and modeling transformations of nformation between brain regions with fMRI.pdf:application/pdf},
}

@article{szucs_frequency-dependent_2017,
	title = {Frequency-dependent regulation of intrinsic excitability by voltage-activated membrane conductances, computational modeling and dynamic clamp},
	volume = {46},
	issn = {14609568},
	doi = {10.1111/ejn.13708},
	abstract = {As one of the most unique properties of nerve cells, their intrinsic excitability allows them to transform synaptic inputs into action potentials. This process reflects a complex interplay between the synaptic inputs and the voltage-dependent membrane currents of the postsynaptic neuron. While neurons in natural conditions mostly fire under the action of intense synaptic bombardment and receive fluctuating patterns of excitation and inhibition, conventional techniques to characterize intrinsic excitability mainly utilize static means of stimulation. Recently we have shown that voltage-gated membrane currents regulate the firing responses under current step stimulation and under physiologically more realistic inputs in a differential manner. At the same time, a multitude of neuron types have been shown to exhibit some form of subthreshold resonance that potentially allows them to respond to synaptic inputs in a frequency-selective manner. In the present study we performed virtual experiments in computational models of neurons to examine how specific voltage-gated currents regulate their excitability under simulated frequency-modulated synaptic inputs. The model simulations and subsequent dynamic clamp experiments on mouse hippocampal pyramidal neurons revealed that the impact of voltage-gated currents in regulating the firing output is strongly frequency-dependent and mostly affecting the synaptic integration at theta-frequencies. Notably, robust frequency-dependent regulation of intrinsic excitability was observed even when conventional analysis of membrane impedance suggested no such tendency. Consequently, plastic or homeostatic regulation of intrinsic membrane properties can tune the frequency-selectivity of neuron populations in a way that is not readily expected from subthreshold impedance measurements. This article is protected by copyright. All rights reserved.},
	number = {9},
	journal = {European Journal of Neuroscience},
	author = {Szűcs, Attila and Rátkai, Anikó and Schlett, Katalin and Huerta, Ramon},
	year = {2017},
	pmid = {28921695},
	keywords = {computational model, firing, oscillation, physiological properties, resonance, Resonance},
	pages = {2429--2444},
	file = {Attachment:/Users/tito/Zotero/storage/QKCRVBCR/Szűcs et al. - 2017 - Frequency-dependent regulation of intrinsic excitability by voltage-activated membrane conductances, computati(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/3NB4DR6D/Szűcs et al. - 2017 - Frequency-dependent regulation of intrinsic excitability by voltage-activated membrane conductances, computati(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/NYKMPPWU/Szűcs et al. - 2017 - Frequency-dependent regulation of intrinsic excitability by voltage-activated membrane conductances, computationa.pdf:application/pdf},
}

@article{zhou_compressive_2017,
	title = {Compressive {Temporal} {Summation} in {Human} {Visual} {Cortex}},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1724-17.2017},
	doi = {10.1523/JNEUROSCI.1724-17.2017},
	abstract = {Combining sensory inputs over space and time is fundamental to vision. Population receptive field models have been successful in characterizing spatial encoding throughout the human visual pathways. A parallel question, how visual areas in the human brain process information distributed over time, has received less attention. One challenge is that the most widely used neuroimaging method, fMRI, has coarse temporal resolution compared with the time-scale of neural dynamics. Here, via carefully controlled temporally modulated stimuli, we show that information about temporal processing can be readily derived from fMRI signal amplitudes in male and female subjects. We find that all visual areas exhibit subadditive summation, whereby responses to longer stimuli are less than the linear prediction from briefer stimuli. We also find fMRI evidence that the neural response to two stimuli is reduced for brief interstimulus intervals (indicating adaptation). These effects are more pronounced in visual areas anterior to V1-V3. Finally, we develop a general model that shows how these effects can be captured with two simple operations: temporal summation followed by a compressive nonlinearity. This model operates for arbitrary temporal stimulation patterns and provides a simple and interpretable set of computa-tions that can be used to characterize neural response properties across the visual hierarchy. Importantly, compressive temporal sum-mation directly parallels earlier findings of compressive spatial summation in visual cortex describing responses to stimuli distributed across space. This indicates that, for space and time, cortex uses a similar processing strategy to achieve higher-level and increasingly invariant representations of the visual world.},
	journal = {The Journal of Neuroscience},
	author = {Zhou, Jingyang and Benson, Noah C. and Kay, Kendrick and Winawer, Jonathan},
	year = {2017},
	pmid = {29192127},
	pages = {1724--17},
	file = {Attachment:/Users/tito/Zotero/storage/H8P349ZU/Zhou et al. - 2017 - Compressive Temporal Summation in Human Visual Cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/AYR4UU67/Zhou et al. - 2017 - Compressive Temporal Summation in Human Visual Cortex.pdf:application/pdf},
}

@article{robinson_msm:_2014,
	title = {{MSM}: {A} new flexible framework for multimodal surface matching},
	volume = {100},
	issn = {10959572},
	doi = {10.1016/j.neuroimage.2014.05.069},
	abstract = {Surface-based cortical registration methods that are driven by geometrical features, such as folding, provide sub-optimal alignment of many functional areas due to variable correlation between cortical folding patterns and function. This has led to the proposal of new registration methods using features derived from functional and diffusion imaging. However, as yet there is no consensus over the best set of features for optimal alignment of brain function. In this paper we demonstrate the utility of a new Multimodal Surface Matching (MSM) algorithm capable of driving alignment using a wide variety of descriptors of brain architecture, function and connectivity. The versatility of the framework originates from adapting the discrete Markov Random Field (MRF) registration method to surface alignment. This has the benefit of being very flexible in the choice of a similarity measure and relatively insensitive to local minima. The method offers significant flexibility in the choice of feature set, and we demonstrate the advantages of this by performing registrations using univariate descriptors of surface curvature and myelination, multivariate feature sets derived from resting fMRI, and multimodal descriptors of surface curvature and myelination. We compare the results with two state of the art surface registration methods that use geometric features: FreeSurfer and Spherical Demons. In the future, the MSM technique will allow explorations into the best combinations of features and alignment strategies for inter-subject alignment of cortical functional areas for a wide range of neuroimaging data sets. © 2014 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Robinson, Emma C. and Jbabdi, Saad and Glasser, Matthew F. and Andersson, Jesper and Burgess, Gregory C. and Harms, Michael P. and Smith, Stephen M. and Van Essen, David C. and Jenkinson, Mark},
	year = {2014},
	pmid = {24939340},
	keywords = {Discrete optimisation, Functional alignment, Multimodal, Surface-based cortical registration},
	pages = {414--426},
	file = {Attachment:/Users/tito/Zotero/storage/H64Q8LR3/Robinson et al. - 2014 - MSM A new flexible framework for Multimodal Surface Matching.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/FHN4CIT8/Robinson et al. - 2014 - MSM A new flexible framework for Multimodal Surface Matching.pdf:application/pdf},
}

@article{stringer_differentiation_2011,
	title = {Differentiation of somatosensory cortices by high-resolution {fMRI} at {7T}},
	volume = {54},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2010.09.058},
	doi = {10.1016/j.neuroimage.2010.09.058},
	abstract = {This study aimed to evaluate the ability of BOLD signals at high MRI field (7. T) to map fine-scale single-digit activations in subdivisions (areas 3b and 1) of the human primary somatosensory cortex (SI) in individual subjects. We acquired BOLD fMRI data from cortical areas around the central suclus in six healthy human subjects while stimulating individual finger pads with 2-Hz air puffs. Discrete, single-digit responses were identified in an area along the posterior bank of the central sulcus corresponding to area 3b and in an area along the crest of the postcentral gyrus corresponding to area 1. In single subjects, activations of digits 1 to 4 in both areas 3b and 1 were organized in a somatotopic manner. The separation of digit representations was measured for adjacent digits and was approximately 1.6 times greater in area 3b than in area 1. Within individual subjects, the cortical responses to single-digit stimulations and the magnitude of the BOLD signals were reproducible across imaging runs and were comparable across subjects. Our findings demonstrate that BOLD fMRI at 7. T is capable of revealing the somatotopic organization of single-digit activations with good within-subject reliability and reproducibility, and activation maps can be acquired within a reasonably short time window, which are essential characteristics for several neurological applications within patient populations. © 2010 Elsevier Inc.},
	number = {2},
	journal = {NeuroImage},
	author = {Stringer, Elizabeth Ann and Chen, Li Min and Friedman, Robert M. and Gatenby, Christopher and Gore, John C.},
	year = {2011},
	pmid = {20887793},
	keywords = {fMRI, FMRI, High MR field, High-resolution imaging, Human digit, Primary somatosensory cortex, Somatotopy},
	pages = {1012--1020},
	file = {Attachment:/Users/tito/Zotero/storage/3F4ICIMK/Stringer et al. - 2011 - Differentiation of somatosensory cortices by high-resolution fMRI at 7T.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/WBQKB3MX/Stringer et al. - 2011 - Differentiation of somatosensory cortices by high-resolution fMRI at 7T.pdf:application/pdf},
}

@article{naselaris_cognitive_2018,
	title = {Cognitive {Computational} {Neuroscience}: {A} {New} {Conference} for an {Emerging} {Discipline}},
	volume = {22},
	issn = {1879307X},
	url = {https://doi.org/10.1016/j.tics.2018.02.008},
	doi = {10.1016/j.tics.2018.02.008},
	abstract = {Understanding the computational principles that underlie complex behavior is a central goal in cognitive science, artificial intelligence, and neuroscience. In an attempt to unify these disconnected communities, we created a new conference called Cognitive Computational Neuroscience (CCN). The inaugural meeting revealed considerable enthusiasm but significant obstacles remain.},
	number = {5},
	journal = {Trends in Cognitive Sciences},
	author = {Naselaris, Thomas and Bassett, Danielle S. and Fletcher, Alyson K. and Kording, Konrad and Kriegeskorte, Nikolaus and Nienborg, Hendrikje and Poldrack, Russell A. and Shohamy, Daphna and Kay, Kendrick},
	year = {2018},
	pmid = {29500078},
	keywords = {artificial intelligence, cognitive science, computational modeling, machine learning, neural networks},
	pages = {365--367},
	annote = {doi: 10.1016/j.tics.2018.02.008},
	file = {Attachment:/Users/tito/Zotero/storage/44PWEKM3/Naselaris et al. - 2018 - Cognitive Computational Neuroscience A New Conference for an Emerging Discipline.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/LETGCRNX/Naselaris et al. - 2018 - Cognitive Computational Neuroscience A New Conference for an Emerging Discipline.pdf:application/pdf},
}

@article{litwin-kumar_slow_2012,
	title = {Slow dynamics and high variability in balanced cortical networks with clustered connections},
	volume = {15},
	issn = {10976256},
	url = {http://dx.doi.org/10.1038/nn.3220},
	doi = {10.1038/nn.3220},
	abstract = {Anatomical studies demonstrate that excitatory connections in cortex are not uniformly distributed across a network but instead exhibit clustering into groups of highly connected neurons. The implications of clustering for cortical activity are unclear. We studied the effect of clustered excitatory connections on the dynamics of neuronal networks that exhibited high spike time variability owing to a balance between excitation and inhibition. Even modest clustering substantially changed the behavior of these networks, introducing slow dynamics during which clusters of neurons transiently increased or decreased their firing rate. Consequently, neurons exhibited both fast spiking variability and slow firing rate fluctuations. A simplified model shows how stimuli bias networks toward particular activity states, thereby reducing firing rate variability as observed experimentally in many cortical areas. Our model thus relates cortical architecture to the reported variability in spontaneous and evoked spiking activity.},
	number = {11},
	journal = {Nature Neuroscience},
	author = {Litwin-Kumar, Ashok and Doiron, Brent},
	year = {2012},
	pmid = {23001062},
	pages = {1498--1505},
	file = {Attachment:/Users/tito/Zotero/storage/P7X4THUQ/Litwin-Kumar, Doiron - 2012 - Slow dynamics and high variability in balanced cortical networks with clustered connections(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/3CQTUQTR/Litwin-kumar, Doiron - 2012 - Slow dynamics and high variability in balanced cortical networks with clustered connections.pdf:application/pdf},
}

@article{lisman_theta-gamma_2013,
	title = {The {Theta}-{Gamma} {Neural} {Code}},
	volume = {77},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2013.03.007},
	doi = {10.1016/j.neuron.2013.03.007},
	abstract = {Theta and gamma frequency oscillations occur in the same brain regions and interact with each other, a process called cross-frequency coupling. Here, we review evidence for the following hypothesis: that the dual oscillations form a code for representing multiple items in an ordered way. This form of coding has been most clearly demonstrated in the hippocampus, where different spatial information is represented in different gamma subcycles of a theta cycle. Other experiments have tested the functional importance of oscillations and their coupling. These involve correlation of oscillatory properties with memory states, correlation with memory performance, and effects of disrupting oscillations on memory. Recent work suggests that this coding scheme coordinates communication between brain regions and is involved in sensory as well as memory processes},
	number = {6},
	journal = {Neuron},
	author = {Lisman, John E. and Jensen, Ole},
	year = {2013},
	pmid = {23522038},
	pages = {1002--1016},
	annote = {doi: 10.1016/j.neuron.2013.03.007},
	file = {Attachment:/Users/tito/Zotero/storage/B2WDKAY2/Lisman, Jensen - 2013 - The Theta-Gamma Neural Code.pdf:application/pdf},
}

@article{rangaprakash_hemodynamic_2018,
	title = {Hemodynamic response function ({HRF}) variability confounds resting-state {fMRI} functional connectivity},
	issn = {07403194},
	url = {http://doi.wiley.com/10.1002/mrm.27146},
	doi = {10.1002/mrm.27146},
	abstract = {PURPOSE fMRI is the convolution of the hemodynamic response function (HRF) and unmeasured neural activity. HRF variability (HRFv) across the brain could, in principle, alter functional connectivity (FC) estimates from resting-state fMRI (rs-fMRI). Given that HRFv is driven by both neural and non-neural factors, it is problematic when it confounds FC. However, this aspect has remained largely unexplored even though FC studies have grown exponentially. We hypothesized that HRFv confounds FC estimates in the brain's default-mode-network. METHODS We tested this hypothesis using both simulations (where the ground truth is known and modulated) as well as rs-fMRI data obtained in a 7T MRI scanner (N = 47, healthy). FC was obtained using 2 pipelines: data with hemodynamic deconvolution (DC) to estimate the HRF and minimize HRFv, and data with no deconvolution (NDC, HRFv-ignored). DC and NDC FC networks were compared, along with regional HRF differences, revealing potential false connectivities that resulted from HRFv. RESULTS We found evidence supporting our hypothesis using both simulations and experimental data. With simulations, we found that HRFv could cause a change of up to 50\% in FC. With rs-fMRI, several potential false connectivities attributable to HRFv, with majority connections being between different lobes, were identified. We found a double exponential relationship between the magnitude of HRFv and its impact on FC, with a mean/median error of 30.5/11.5\% caused in FC by HRF confounds. CONCLUSION HRFv, if ignored, could cause identification of false FC. FC findings from HRFv-ignored data should be interpreted cautiously. We suggest deconvolution to minimize HRFv.},
	number = {November 2017},
	journal = {Magnetic Resonance in Medicine},
	author = {Rangaprakash, D. and Wu, Guo-Rong and Marinazzo, Daniele and Hu, Xiaoping and Deshpande, Gopikrishna},
	year = {2018},
	pmid = {29656446},
	keywords = {functional connectivity, 1, 17, 2018, deconvolution, function, functional magnetic resonance imaging, hemodynamic response, hrf variability, magn reson med, hemodynamic response function, HRF variability},
	pages = {1--17},
	annote = {doi: 10.1002/mrm.27146},
	file = {Attachment:/Users/tito/Zotero/storage/6M24WRIJ/Rangaprakash et al. - 2018 - Hemodynamic response function (HRF) variability confounds resting-state fMRI functional connectivity.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/4K4N7MJG/Rangaprakash et al. - 2018 - Hemodynamic response function (HRF) variability confounds resting-state fMRI functional connectivity.pdf:application/pdf},
}

@article{avena-koenigsberger_communication_2017,
	title = {Communication dynamics in complex brain networks},
	volume = {19},
	issn = {1471-003X},
	url = {http://www.nature.com/doifinder/10.1038/nrn.2017.149},
	doi = {10.1038/nrn.2017.149},
	abstract = {The brain comprises complex structural and functional networks, but much remains to be determined regarding how these networks support the communication processes that underlie neuronal computation. In this Review, Avena-Koenigsberger, Misic and Sporns discuss the network basis of communication dynamics in the brain.},
	number = {1},
	journal = {Nature Reviews Neuroscience},
	author = {Avena-Koenigsberger, Andrea and Misic, Bratislav and Sporns, Olaf},
	year = {2017},
	pmid = {29238085},
	pages = {17--33},
	file = {Attachment:/Users/tito/Zotero/storage/IGI684FS/Avena-Koenigsberger, Misic, Sporns - 2017 - Communication dynamics in complex brain networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TJ9U2VKA/Avena-Koenigsberger, Misic, Sporns - 2017 - Communication dynamics in complex brain networks.pdf:application/pdf},
}

@article{cohen_measuring_2011,
	title = {Measuring and interpreting neuronal correlations},
	volume = {14},
	issn = {10976256},
	doi = {10.1038/nn.2842},
	abstract = {Mounting evidence suggests that understanding how the brain encodes information and performs computations will require studying the correlations between neurons. The recent advent of recording techniques such as multielectrode arrays and two-photon imaging has made it easier to measure correlations, opening the door for detailed exploration of their properties and contributions to cortical processing. However, studies have reported discrepant findings, providing a confusing picture. Here we briefly review these studies and conduct simulations to explore the influence of several experimental and physiological factors on correlation measurements. Differences in response strength, the time window over which spikes are counted, spike sorting conventions and internal states can all markedly affect measured correlations and systematically bias estimates. Given these complicating factors, we offer guidelines for interpreting correlation data and a discussion of how best to evaluate the effect of correlations on cortical processing.},
	number = {7},
	journal = {Nature Neuroscience},
	author = {Cohen, Marlene R. and Kohn, Adam},
	year = {2011},
	pmid = {21709677},
	pages = {811--819},
	file = {Attachment:/Users/tito/Zotero/storage/EZCPXXIC/Cohen, Kohn - 2011 - Measuring and interpreting neuronal correlations.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/S8EI643L/Cohen, Kohn - 2011 - Measuring and interpreting neuronal correlations.pdf:application/pdf},
}

@article{baldassano_discovering_2017,
	title = {Discovering {Event} {Structure} in {Continuous} {Narrative} {Perception} and {Memory}},
	volume = {95},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2017.06.041},
	doi = {10.1016/j.neuron.2017.06.041},
	abstract = {During realistic, continuous perception, humans automatically segment experiences into discrete events. Using a novel model of cortical event dynamics, we investigate how cortical structures generate event representations during narrative perception and how these events are stored to and retrieved from memory. Our data-driven approach allows us to detect event boundaries as shifts between stable patterns of brain activity without relying on stimulus annotations and reveals a nested hierarchy from short events in sensory regions to long events in high-order areas (including angular gyrus and posterior medial cortex), which represent abstract, multimodal situation models. High-order event boundaries are coupled to increases in hippocampal activity, which predict pattern reinstatement during later free recall. These areas also show evidence of anticipatory reinstatement as subjects listen to a familiar narrative. Based on these results, we propose that brain activity is naturally structured into nested events, which form the basis of long-term memory representations.},
	number = {3},
	journal = {Neuron},
	author = {Baldassano, Christopher and Chen, Janice and Zadbood, Asieh and Pillow, Jonathan W. and Hasson, Uri and Norman, Kenneth A.},
	year = {2017},
	pmid = {28772125},
	keywords = {fMRI, event model, event segmentation, Hidden Markov Model, hippocampus, memory, narrative, perception, recall, reinstatement, situation model},
	pages = {709--721.e5},
	annote = {doi: 10.1016/j.neuron.2017.06.041},
	file = {Attachment:/Users/tito/Zotero/storage/M9JCZJZ8/Baldassano et al. - 2018 - Discovering Event Structure in Continuous Narrative Perception and Memory.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/WQB2EISM/Baldassano et al. - 2018 - Discovering Event Structure in Continuous Narrative Perception and Memory.pdf:application/pdf},
}

@article{chen_regional_2018,
	title = {Regional {GABA} {Concentrations} {Modulate} {Inter}-network {Resting}-state {Functional} {Connectivity}},
	issn = {1047-3211},
	url = {http://dx.doi.org/10.1093/cercor/bhy059},
	abstract = {Coordinated activity within and differential activity between large-scale neuronal networks such as the default mode network (DMN) and the control network (CN) is a critical feature of brain organization. The CN usually exhibits activations in response to cognitive tasks while the DMN shows deactivations; in addition, activity between the two networks is anti-correlated at rest. To address this issue, we used functional MRI to measure whole-brain BOLD signal during resting-state and task-evoked conditions, and MR spectroscopy (MRS) to quantify GABA and glutamate concentrations, in nodes within the DMN and CN (MPFC and DLPFC, respectively) in 19 healthy individuals at 3 Tesla. We found that GABA concentrations in the MPFC were significantly associated with DMN deactivation during a working memory task and with anti-correlation between DMN and CN at rest and during task performance, while GABA concentrations in the DLPFC weakly modulated DMN–CN anti-correlation in the opposite direction. Highlighting specificity, glutamate played a less significant role related to brain activity. These findings indicate that GABA in the MPFC is potentially involved in orchestrating between-network brain activity at rest and during task performance.},
	journal = {Cerebral Cortex},
	author = {Chen, Xi and Fan, Xiaoying and Hu, Yuzheng and Zuo, Chun and Whitfield-Gabrieli, Susan and Holt, Daphne and Gong, Qiyong and Yang, Yihong and Pizzagalli, Diego A and Du, Fei and Ongur, Dost},
	month = mar,
	year = {2018},
	keywords = {anti-correlation, default mode network, fmri, gaba, glutamate},
	annote = {10.1093/cercor/bhy059},
	file = {Attachment:/Users/tito/Zotero/storage/8TFU3K8Y/Chen et al. - 2018 - Regional GABA Concentrations Modulate Inter- network Resting-state Functional Connectivity.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TC7EZUT5/Chen et al. - 2018 - Regional GABA Concentrations Modulate Inter- network Resting-state Functional Connectivity.pdf:application/pdf},
}

@article{isaacson_how_2011,
	title = {How {Inhibition} {Shapes} {Cortical} {Activity}},
	volume = {72},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627311008798},
	doi = {https://doi.org/10.1016/j.neuron.2011.09.027},
	abstract = {Cortical processing reflects the interplay of synaptic excitation and synaptic inhibition. Rapidly accumulating evidence is highlighting the crucial role of inhibition in shaping spontaneous and sensory-evoked cortical activity and thus underscores how a better knowledge of inhibitory circuits is necessary for our understanding of cortical function. We discuss current views of how inhibition regulates the function of cortical neurons and point to a number of important open questions.},
	number = {2},
	journal = {Neuron},
	author = {Isaacson, Jeffry S. and Scanziani, Massimo},
	year = {2011},
	pages = {231--243},
	file = {Attachment:/Users/tito/Zotero/storage/B7VFXZJ6/Isaacson, Scanziani - 2011 - How inhibition shapes cortical activity.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6AYL8KUY/Isaacson, Scanziani - 2011 - How inhibition shapes cortical activity.pdf:application/pdf},
}

@article{nanou_control_2018,
	title = {Control of excitation/inhibition balance in a hippocampal circuit by calcium sensor protein regulation of presynaptic calcium channels},
	url = {http://www.jneurosci.org/content/early/2018/04/13/JNEUROSCI.0022-18.2018.abstract},
	abstract = {Activity-dependent regulation controls the balance of synaptic excitation to inhibition in neural circuits, and disruption of this regulation impairs learning and memory and causes many neurological disorders. The molecular mechanisms underlying short-term synaptic plasticity are incompletely understood, and their role in inhibitory synapses remains uncertain. Here we show that regulation of voltage-gated calcium (Ca2+) channel type 2.1 (CaV2.1) by neuronal Ca2+ sensor (CaS) proteins controls synaptic plasticity and excitation/inhibition balance in a hippocampal circuit. Prevention of CaS protein regulation by introducing the IM-AA mutation in CaV2.1 channels in male and female mice impairs short-term synaptic facilitation at excitatory synapses of CA3 pyramidal neurons onto parvalbumin (PV)-expressing basket cells. In sharp contrast, the IM-AA mutation abolishes rapid synaptic depression in the inhibitory synapses of PV basket cells onto CA1 pyramidal neurons. These results show that CaS protein regulation of facilitation and inactivation of CaV2.1 channels controls the direction of short-term plasticity at these two synapses. Deletion of the CaS protein CaBP1/caldendrin also blocks rapid depression at PV-CA1 synapses, implicating its up-regulation of inactivation of CaV2.1 channels in control of short-term synaptic plasticity at this inhibitory synapse. Studies of local-circuit function revealed reduced inhibition of CA1 pyramidal neurons by the disynaptic pathway from CA3 pyramidal cells via PV basket cells and greatly increased excitation/inhibition ratio of the direct excitatory input vs. indirect inhibitory input from CA3 pyramidal neurons to CA1 pyramidal neurons. This striking defect in local-circuit function may contribute to the dramatic impairment of spatial learning and memory in IM-AA mice.SIGNIFICANCE STATEMENTMany forms of short-term synaptic plasticity in neuronal circuits rely on regulation of presynaptic voltage-gated Ca2+ (CaV) channels. Regulation of CaV2.1 channels by neuronal calcium sensor (CaS) proteins controls short-term synaptic plasticity. Here we demonstrate a direct link between regulation of CaV2.1 channels and short-term synaptic plasticity in native hippocampal excitatory and inhibitory synapses. We also identify CaBP1/caldendrin as the calcium sensor interacting with CaV2.1 channels to mediate rapid synaptic depression in the inhibitory hippocampal synapses of parvalbumin-expressing basket cells to CA1 pyramidal cells. Disruption of this regulation causes altered short-term plasticity and impaired balance of hippocampal excitatory to inhibitory circuits.},
	journal = {The Journal of Neuroscience},
	author = {Nanou, Evanthia and Lee, Amy and Catterall, William A},
	month = apr,
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/6SAIRSHY/Nanou, Lee, Catterall - 2018 - Control of excitationinhibition balance in a hippocampal circuit by calcium sensor protein regulation of.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/JBLGMKTB/Nanou, Lee, Catterall - 2018 - Control of excitationinhibition balance in a hippocampal circuit by calcium sensor protein regulation of.pdf:application/pdf},
}

@article{van_uden_modeling_2018,
	title = {Modeling semantic encoding in a common neural representational space},
	url = {http://biorxiv.org/content/early/2018/03/25/288605.abstract},
	abstract = {Encoding models for mapping voxelwise semantic tuning are typically estimated separately for each individual, limiting their generalizability. In the current report, we develop a method for estimating semantic encoding models that generalize across individuals. Functional MRI was used to measure brain responses while participants freely viewed a naturalistic audiovisual movie. Word embeddings capturing agent-, action-, object-, and scene-related semantic content were assigned to each imaging volume based on an annotation of the film. We constructed both conventional within-subject semantic encoding models and between-subject models where the model was trained on a subset of participants and validated on a left-out participant. Between-subject models were trained using cortical surface-based anatomical normalization or surface-based whole-cortex hyperalignment. We used hyperalignment to project group data into an individual\&\#039;s unique anatomical space via a common representational space, thus leveraging a larger volume of data for out-of-sample prediction while preserving the individual\&\#039;s fine-grained functional–anatomical idiosyncrasies. Our findings demonstrate that anatomical normalization degrades the spatial specificity of between-subject encoding models relative to within-subject models. Hyperalignment, on the other hand, recovers the spatial specificity of semantic tuning lost during anatomical normalization, and yields model performance exceeding that of within-subject models.},
	journal = {bioRxiv},
	author = {Van Uden, Cara E and Nastase, Samuel A and Connolly, Andrew C and Feilong, Ma and Hansen, Isabella and Gobbini, M Ida and Haxby, James V},
	month = jan,
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/QIDTRPP6/Van Uden et al. - 2018 - Modeling semantic encoding in a common neural representational space.pdf:application/pdf},
}

@article{smith_small_2018,
	title = {Small is beautiful: {In} defense of the small-{N} design},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-018-1451-8},
	doi = {10.3758/s13423-018-1451-8},
	abstract = {The dominant paradigm for inference in psychology is a null-hypothesis significance testing one. Recently, the foundations of this paradigm have been shaken by several notable replication failures. One recommendation to remedy the replication crisis is to collect larger samples of participants. We argue that this recommendation misses a critical point, which is that increasing sample size will not remedy psychology's lack of strong measurement, lack of strong theories and models, and lack of effective experimental control over error variance. In contrast, there is a long history of research in psychology employing small-N designs that treats the individual participant as the replication unit, which addresses each of these failings, and which produces results that are robust and readily replicated. We illustrate the properties of small-N and large-N designs using a simulated paradigm investigating the stage structure of response times. Our simulations highlight the high power and inferential validity of the small-N design, in contrast to the lower power and inferential indeterminacy of the large-N design. We argue that, if psychology is to be a mature quantitative science, then its primary theoretical aim should be to investigate systematic, functional relationships as they are manifested at the individual participant level and that, wherever possible, it should use methods that are optimized to identify relationships of this kind.},
	journal = {Psychonomic Bulletin \& Review},
	author = {Smith, Philip L and Little, Daniel R},
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/4SB5IH3C/Smith, Little - 2018 - Small is beautiful In defense of the small-N design.pdf:application/pdf},
}

@article{matsui_neuronal_2018,
	title = {Neuronal {Origin} of the {Temporal} {Dynamics} of {Spontaneous} {BOLD} {Activity} {Correlation}},
	issn = {1047-3211},
	url = {http://dx.doi.org/10.1093/cercor/bhy045},
	abstract = {Resting-state functional connectivity (FC) has become a major functional magnetic resonance imaging method to study network organization of human brains. There has been recent interest in the temporal fluctuations of FC calculated using short time windows (“dynamic FC”) because this method could provide information inaccessible with conventional “static” FC, which is typically calculated using the entire scan lasting several tens of minutes. Although multiple studies have revealed considerable temporal fluctuations in FC, it is still unclear whether the fluctuations of FC measured in hemodynamics reflect the dynamics of underlying neural activity. We addressed this question using simultaneous imaging of neuronal calcium and hemodynamic signals in mice and found coordinated temporal dynamics of calcium FC and hemodynamic FC measured in the same short time windows. Moreover, we found that variation in transient neuronal coactivation patterns was significantly related to temporal fluctuations of sliding window FC in hemodynamics. Finally, we show that the observed dynamics of FC cannot be fully accounted for by simulated data assuming stationary FC. These results provide evidence for the neuronal origin of dynamic FC and further suggest that information relevant to FC is condensed in temporally sparse events that can be extracted using a small number of time points.},
	journal = {Cerebral Cortex},
	author = {Matsui, Teppei and Murakami, Tomonari and Ohki, Kenichi},
	month = mar,
	year = {2018},
	annote = {10.1093/cercor/bhy045},
	file = {Attachment:/Users/tito/Zotero/storage/LZ8YMZG2/Matsui, Murakami, Ohki - 2018 - Neuronal Origin of the Temporal Dynamics of Spontaneous BOLD Activity Correlation.pdf:application/pdf},
}

@book{strogatz_nonlinear_1994,
	title = {Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering ({Cambridge}, {MA}},
	publisher = {Westview Press},
	author = {Strogatz, S H},
	year = {1994},
}

@article{churchland_stimulus_2010,
	title = {Stimulus onset quenches neural variability: a widespread cortical phenomenon},
	volume = {13},
	url = {http://dx.doi.org/10.1038/nn.2501 http://10.0.4.14/nn.2501 https://www.nature.com/articles/nn.2501#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
	month = feb,
	year = {2010},
	pages = {369},
	file = {Attachment:/Users/tito/Zotero/storage/RBEJ4DBJ/Churchland et al. - 2010 - Stimulus onset quenches neural variability a widespread cortical phenomenon.pdf:application/pdf},
}

@article{saggar_towards_2018,
	title = {Towards a new approach to reveal dynamical organization of the brain using topological data analysis},
	volume = {9},
	issn = {2041-1723},
	url = {https://doi.org/10.1038/s41467-018-03664-4},
	doi = {10.1038/s41467-018-03664-4},
	abstract = {Little is known about how our brains dynamically adapt for efficient functioning. Most previous work has focused on analyzing changes in co-fluctuations between a set of brain regions over several temporal segments of the data. We argue that by collapsing data in space or time, we stand to lose useful information about the brain's dynamical organization. Here we use Topological Data Analysis to reveal the overall organization of whole-brain activity maps at a single-participant level—as an interactive representation—without arbitrarily collapsing data in space or time. Using existing multitask fMRI datasets, with the known ground truth about the timing of transitions from one task-block to next, our approach tracks both within- and between-task transitions at a much faster time scale (∼4–9 s) than before. The individual differences in the revealed dynamical organization predict task performance. In summary, our approach distills complex brain dynamics into interactive and behaviorally relevant representations.},
	number = {1},
	journal = {Nature Communications},
	author = {Saggar, Manish and Sporns, Olaf and Gonzalez-Castillo, Javier and Bandettini, Peter A and Carlsson, Gunnar and Glover, Gary and Reiss, Allan L},
	year = {2018},
	pages = {1399},
	file = {Attachment:/Users/tito/Zotero/storage/449F37BM/Saggar et al. - 2018 - Towards a new approach to reveal dynamical organization of the brain using topological data analysis.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Y7FFZNDN/Saggar et al. - 2018 - Towards a new approach to reveal dynamical organization of the brain using topological data analysis.pdf:application/pdf},
}

@article{rall_statistical_1955,
	title = {A statistical theory of monosynaptic input‐output relations},
	volume = {46},
	issn = {0095-9898},
	url = {https://doi.org/10.1002/jcp.1030460302},
	doi = {10.1002/jcp.1030460302},
	number = {3},
	journal = {Journal of Cellular and Comparative Physiology},
	author = {Rall, Wilfrid},
	month = feb,
	year = {1955},
	pages = {373--411},
	annote = {doi: 10.1002/jcp.1030460302},
	file = {Attachment:/Users/tito/Zotero/storage/MQERNE6D/Rall - 1955 - A statistical theory of monosynaptic input‐output relations.pdf:application/pdf},
}

@article{rall_experimental_1955,
	title = {Experimental monosynaptic input‐output relations in the mammalian spinal cord},
	volume = {46},
	issn = {0095-9898},
	url = {https://doi.org/10.1002/jcp.1030460303},
	doi = {10.1002/jcp.1030460303},
	number = {3},
	journal = {Journal of Cellular and Comparative Physiology},
	author = {Rall, Wilfrid},
	month = feb,
	year = {1955},
	pages = {413--437},
	annote = {doi: 10.1002/jcp.1030460303},
	file = {Attachment:/Users/tito/Zotero/storage/WD5GEINT/Rall - 1955 - Experimental monosynaptic input‐output relations in the mammalian spinal cord.pdf:application/pdf},
}

@article{wilson_excitatory_1972,
	title = {Excitatory and {Inhibitory} {Interactions} in {Localized} {Populations} of {Model} {Neurons}},
	volume = {12},
	issn = {0006-3495},
	url = {http://www.sciencedirect.com/science/article/pii/S0006349572860685},
	doi = {https://doi.org/10.1016/S0006-3495(72)86068-5},
	abstract = {Coupled nonlinear differential equations are derived for the dynamics of spatially localized populations containing both excitatory and inhibitory model neurons. Phase plane methods and numerical solutions are then used to investigate population responses to various types of stimuli. The results obtained show simple and multiple hysteresis phenomena and limit cycle activity. The latter is particularly interesting since the frequency of the limit cycle oscillation is found to be a monotonic function of stimulus intensity. Finally, it is proved that the existence of limit cycle dynamics in response to one class of stimuli implies the existence of multiple stable states and hysteresis in response to a different class of stimuli. The relation between these findings and a number of experiments is discussed.},
	number = {1},
	journal = {Biophysical Journal},
	author = {Wilson, Hugh R and Cowan, Jack D},
	year = {1972},
	pages = {1--24},
	file = {Attachment:/Users/tito/Zotero/storage/5DTHH9JM/Wilson, Cowan - 1972 - Excitatory and Inhibitory Interactions in Localized Populations of Model Neurons.pdf:application/pdf},
}

@article{bolt_combining_2018,
	title = {Combining region- and network-level brain-behavior relationships in a structural equation model},
	volume = {165},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917308200},
	doi = {https://doi.org/10.1016/j.neuroimage.2017.10.007},
	journal = {NeuroImage},
	author = {Bolt, Taylor and Prince, Emily B and Nomi, Jason S and Messinger, Daniel and Llabre, Maria M and Uddin, Lucina Q},
	year = {2018},
	pages = {158--169},
	file = {Attachment:/Users/tito/Zotero/storage/AWZMYEFR/Bolt et al. - 2018 - Combining region- and network-level brain-behavior relationships in a structural equation model.pdf:application/pdf},
}

@article{abeysuriya_biophysical_2018,
	title = {A biophysical model of dynamic balancing of excitation and inhibition in fast oscillatory large-scale networks},
	volume = {14},
	url = {https://doi.org/10.1371/journal.pcbi.1006007},
	abstract = {Author summary Recently there has been much interest in investigating the role of synaptic plasticity in supporting healthy brain activity. In particular, the balance between excitation and inhibition in the brain is believed to play a critical role in brain dynamics, and it is likely that this balance is regulated by homeostatic mechanisms. Biophysical models of the brain have previously been used to predict functional connectivity, but are typically extremely sensitive to changes in parameter values and require extremely fine tuning to achieve realistic dynamics. In this study, we investigated whether including a homeostatic plasticity mechanism would improve the robustness of simulated neural dynamics. We focused on functional connectivity in MEG data, which can resolve fast oscillations in neural activity, unlike fMRI. We found that including a simple plasticity rule to balance excitation and inhibition resulted in more realistic model predictions, and reduced sensitivity to changes in model parameters.},
	number = {2},
	journal = {PLOS Computational Biology},
	author = {Abeysuriya, Romesh G and Hadida, Jonathan and Sotiropoulos, Stamatios N and Jbabdi, Saad and Becker, Robert and Hunt, Benjamin A E and Brookes, Matthew J and Woolrich, Mark W},
	month = feb,
	year = {2018},
	pages = {e1006007},
	file = {Attachment:/Users/tito/Zotero/storage/K7CZTCIV/Abeysuriya et al. - 2018 - A biophysical model of dynamic balancing of excitation and inhibition in fast oscillatory large-scale network.pdf:application/pdf},
}

@article{burgess_evaluation_2016,
	title = {Evaluation of {Denoising} {Strategies} to {Address} {Motion}-{Correlated} {Artifacts} in {Resting}-{State} {Functional} {Magnetic} {Resonance} {Imaging} {Data} from the {Human} {Connectome} {Project}},
	volume = {6},
	issn = {2158-0014},
	url = {https://doi.org/10.1089/brain.2016.0435},
	doi = {10.1089/brain.2016.0435},
	number = {9},
	journal = {Brain Connectivity},
	author = {Burgess, Gregory C and Kandala, Sridhar and Nolan, Dan and Laumann, Timothy O and Power, Jonathan D and Adeyemo, Babatunde and Harms, Michael P and Petersen, Steven E and Barch, Deanna M},
	month = aug,
	year = {2016},
	pages = {669--680},
	annote = {doi: 10.1089/brain.2016.0435},
	file = {Attachment:/Users/tito/Zotero/storage/WRSDSN5K/Burgess et al. - 2016 - Evaluation of Denoising Strategies to Address Motion-Correlated Artifacts in Resting-State Functional Magnetic R.pdf:application/pdf},
}

@article{stone_information_nodate,
	title = {Information {Theory} : {A} {Tutorial} {Introduction}},
	journal = {arXiv},
	author = {Stone, James V},
	file = {Attachment:/Users/tito/Zotero/storage/T6HZMMR3/Stone - Unknown - Information Theory A Tutorial Introduction.pdf:application/pdf},
}

@article{abdelnour_functional_2018,
	title = {Functional brain connectivity is predictable from anatomic network's {Laplacian} eigen-structure},
	volume = {172},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811918301046},
	doi = {https://doi.org/10.1016/j.neuroimage.2018.02.016},
	abstract = {Abstract How structural connectivity (SC) gives rise to functional connectivity (FC) is not fully understood. Here we mathematically derive a simple relationship between SC measured from diffusion tensor imaging, and FC from resting state fMRI. We establish that SC and FC are related via (structural) Laplacian spectra, whereby FC and SC share eigenvectors and their eigenvalues are exponentially related. This gives, for the first time, a simple and analytical relationship between the graph spectra of structural and functional networks. Laplacian eigenvectors are shown to be good predictors of functional eigenvectors and networks based on independent component analysis of functional time series. A small number of Laplacian eigenmodes are shown to be sufficient to reconstruct FC matrices, serving as basis functions. This approach is fast, and requires no time-consuming simulations. It was tested on two empirical SC/FC datasets, and was found to significantly outperform generative model simulations of coupled neural masses.},
	journal = {NeuroImage},
	author = {Abdelnour, Farras and Dayan, Michael and Devinsky, Orrin and Thesen, Thomas and Raj, Ashish},
	month = may,
	year = {2018},
	keywords = {Eigen decomposition, Functional network, Graph theory, Laplacian, Networks, Structural network},
	pages = {728--739},
	file = {Attachment:/Users/tito/Zotero/storage/QRQ39Z7V/Abdelnour et al. - 2018 - Functional brain connectivity is predictable from anatomic network's Laplacian eigen-structure.pdf:application/pdf},
}

@article{pillai_symmetry_2018,
	title = {Symmetry {Breaking} in {Space}-{Time} {Hierarchies} {Shapes} {Brain} {Dynamics} and {Behavior}},
	volume = {94},
	issn = {0896-6273},
	url = {http://dx.doi.org/10.1016/j.neuron.2017.05.013},
	doi = {10.1016/j.neuron.2017.05.013},
	number = {5},
	journal = {Neuron},
	author = {Pillai, Ajay S and Jirsa, Viktor K},
	month = feb,
	year = {2018},
	pages = {1010--1026},
	annote = {doi: 10.1016/j.neuron.2017.05.013},
	file = {Attachment:/Users/tito/Zotero/storage/AIMI5RPC/Pillai, Jirsa - 2018 - Symmetry Breaking in Space-Time Hierarchies Shapes Brain Dynamics and Behavior.pdf:application/pdf},
}

@article{shine_low_2018,
	title = {The low dimensional dynamic and integrative core of cognition in the human brain},
	url = {http://biorxiv.org/content/early/2018/02/18/266635.abstract},
	abstract = {The human brain seamlessly integrates innumerable cognitive functions into a coherent whole, shifting with fluidity between changing task demands. To test the hypothesis that the brain contains a core dynamic network that integrates specialized regions across a range of unique task demands, we investigated whether brain activity across multiple cognitive tasks could be embedded within a relatively low dimensional, dynamic manifold. Analysis of task-related fMRI data from the Human Connectome Project revealed a core brain system that fluctuates in accordance with cognitive demands, bringing new brain systems on-line in accordance with changing task demands, while maximizing temporal information processing complexity. Regional differences in noradrenergic neurotransmitter receptor density align with this integrative core, providing a biologically plausible mechanism for the control of global brain dynamics. Our results advance a unique window into functional brain organization that emphasizes the confluence between low dimensional neural activity, network topology, neuromodulator systems and cognitive function.},
	journal = {bioRxiv},
	author = {Shine, James M and Breakspear, Michael and Bell, Peter and Ehgoetz Martens, Kaylena and Shine, Richard and Koyejo, Oluwasanmi and Sporns, Olaf and Poldrack, Russell},
	month = jan,
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/WT6NFM7X/Ito, Cole - 2018 - Network dimensionality underlies flexible representation of cognitive information.pdf:application/pdf},
}

@article{mastrogiuseppe_intrinsically-generated_2017,
	title = {Intrinsically-generated fluctuating activity in excitatory-inhibitory networks},
	volume = {13},
	url = {https://doi.org/10.1371/journal.pcbi.1005498},
	abstract = {Author summary Electrophysiological recordings from cortical circuits reveal strongly irregular and highly complex temporal patterns of in-vivo neural activity. In the last decades, a large number of theoretical studies have speculated on the possible sources of fluctuations in neural assemblies, pointing out the possibility of self-sustained irregularity, intrinsically generated by network mechanisms. In particular, a seminal study showed that purely deterministic, but randomly connected rate networks intrinsically develop chaotic fluctuations due to the recurrent feedback. In the simple and highly symmetric class of models considered in classical works, the transition from stationary activity to chaos is characterized by the behavior of the auto-correlation function and the critical slowing down of fluctuations. Following up on recent works, here we combine analytical and numerical tools to investigate the macroscopic dynamics generated by more realistic models of excitatory and inhibitory rate units. We show that the presence of excitation leads to a strong signature of the onset of chaos in the first-order statistics of the network activity, and that this effect is highly robust with respect to spiking noise. We moreover find that excitation leads to two different types of fluctuating activity at moderate and strong synaptic coupling, even when inhibition dominates. Finally, we test the appearance of analogous dynamical regimes in networks of integrate-and-fire neurons.},
	number = {4},
	journal = {PLOS Computational Biology},
	author = {Mastrogiuseppe, Francesca and Ostojic, Srdjan},
	month = apr,
	year = {2017},
	pages = {e1005498},
	file = {Attachment:/Users/tito/Zotero/storage/LGGAMM9J/Mastrogiuseppe, Ostojic - 2017 - Intrinsically-generated fluctuating activity in excitatory-inhibitory networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/MZ2CZV83/Mastrogiuseppe, Ostojic - Unknown - Intrinsically-generated fluctuating activity in excitatory-inhibitory networks.pdf:application/pdf},
}

@article{miconi_biologically_2017,
	title = {Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks},
	volume = {6},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.20899},
	doi = {10.7554/eLife.20899},
	abstract = {Neural activity during cognitive tasks exhibits complex dynamics that flexibly encode task-relevant variables. Chaotic recurrent networks, which spontaneously generate rich dynamics, have been proposed as a model of cortical computation during cognitive tasks. However, existing methods for training these networks are either biologically implausible, and/or require a continuous, real-time error signal to guide learning. Here we show that a biologically plausible learning rule can train such recurrent networks, guided solely by delayed, phasic rewards at the end of each trial. Networks endowed with this learning rule can successfully learn nontrivial tasks requiring flexible (context-dependent) associations, memory maintenance, nonlinear mixed selectivities, and coordination among multiple outputs. The resulting networks replicate complex dynamics previously observed in animal cortex, such as dynamic encoding of task features and selective integration of sensory inputs. We conclude that recurrent neural networks offer a plausible model of cortical dynamics during both learning and performance of flexible behavior.},
	journal = {eLife},
	author = {Miconi, Thomas},
	editor = {Frank, Michael J},
	year = {2017},
	keywords = {cognition, computational neuroscience, learning, modeling, recurrent neural networks},
	pages = {e20899},
	file = {Attachment:/Users/tito/Zotero/storage/4XV92CXN/Miconi - 2017 - Biologically plausible learning in recurrent neural networks reproduces neural dynamics observed during cognitive tasks.pdf:application/pdf},
}

@article{solomon_widespread_2017,
	title = {Widespread theta synchrony and high-frequency desynchronization underlies enhanced cognition},
	volume = {8},
	issn = {2041-1723},
	url = {https://doi.org/10.1038/s41467-017-01763-2},
	doi = {10.1038/s41467-017-01763-2},
	abstract = {The idea that synchronous neural activity underlies cognition has driven an extensive body of research in human and animal neuroscience. Yet, insufficient data on intracranial electrical connectivity has precluded a direct test of this hypothesis in a whole-brain setting. Through the lens of memory encoding and retrieval processes, we construct whole-brain connectivity maps of fast gamma (30–100 Hz) and slow theta (3–8 Hz) spectral neural activity, based on data from 294 neurosurgical patients fitted with indwelling electrodes. Here we report that gamma networks desynchronize and theta networks synchronize during encoding and retrieval. Furthermore, for nearly all brain regions we studied, gamma power rises as that region desynchronizes with gamma activity elsewhere in the brain, establishing gamma as a largely asynchronous phenomenon. The abundant phenomenon of theta synchrony is positively correlated with a brain region's gamma power, suggesting a predominant low-frequency mechanism for inter-regional communication.},
	number = {1},
	journal = {Nature Communications},
	author = {Solomon, E A and Kragel, J E and Sperling, M R and Sharan, A and Worrell, G and Kucewicz, M and Inman, C S and Lega, B and Davis, K A and Stein, J M and Jobst, B C and Zaghloul, K A and Sheth, S A and Rizzuto, D S and Kahana, M J},
	year = {2017},
	pages = {1704},
	file = {Attachment:/Users/tito/Zotero/storage/DJ5N7ZJQ/Solomon et al. - 2017 - Widespread theta synchrony and high-frequency desynchronization underlies enhanced cognition.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/38TS2VKA/Solomon et al. - 2017 - Widespread theta synchrony and high-frequency desynchronization underlies enhanced cognition.pdf:application/pdf},
}

@article{saxe_brain_2018,
	title = {Brain entropy and human intelligence: {A} resting-state {fMRI} study},
	volume = {13},
	url = {https://doi.org/10.1371/journal.pone.0191582},
	abstract = {Human intelligence comprises comprehension of and reasoning about an infinitely variable external environment. A brain capable of large variability in neural configurations, or states, will more easily understand and predict variable external events. Entropy measures the variety of configurations possible within a system, and recently the concept of brain entropy has been defined as the number of neural states a given brain can access. This study investigates the relationship between human intelligence and brain entropy, to determine whether neural variability as reflected in neuroimaging signals carries information about intellectual ability. We hypothesize that intelligence will be positively associated with entropy in a sample of 892 healthy adults, using resting-state fMRI. Intelligence is measured with the Shipley Vocabulary and WASI Matrix Reasoning tests. Brain entropy was positively associated with intelligence. This relation was most strongly observed in the prefrontal cortex, inferior temporal lobes, and cerebellum. This relationship between high brain entropy and high intelligence indicates an essential role for entropy in brain functioning. It demonstrates that access to variable neural states predicts complex behavioral performance, and specifically shows that entropy derived from neuroimaging signals at rest carries information about intellectual capacity. Future work in this area may elucidate the links between brain entropy in both resting and active states and various forms of intelligence. This insight has the potential to provide predictive information about adaptive behavior and to delineate the subdivisions and nature of intelligence based on entropic patterns.},
	number = {2},
	journal = {PLOS ONE},
	author = {Saxe, Glenn N and Calderone, Daniel and Morales, Leah J},
	month = feb,
	year = {2018},
	pages = {e0191582},
	file = {Attachment:/Users/tito/Zotero/storage/JEY8EVRY/Saxe, Calderone, Morales - 2018 - Brain entropy and human intelligence A resting-state fMRI study.pdf:application/pdf},
}

@article{doiron_mechanics_2016,
	title = {The mechanics of state-dependent neural correlations},
	volume = {19},
	url = {http://dx.doi.org/10.1038/nn.4242 http://10.0.4.14/nn.4242 https://www.nature.com/articles/nn.4242#supplementary-information},
	journal = {Nature Neuroscience},
	author = {Doiron, Brent and Litwin-Kumar, Ashok and Rosenbaum, Robert and Ocker, Gabriel K and Josić, Krešimir},
	month = feb,
	year = {2016},
	pages = {383},
	file = {Attachment:/Users/tito/Zotero/storage/S7LLMUSR/Doiron et al. - 2016 - The mechanics of state-dependent neural correlations.pdf:application/pdf},
}

@article{ocker_statistics_2017,
	title = {From the statistics of connectivity to the statistics of spike times in neuronal networks},
	volume = {46},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438817300740},
	doi = {https://doi.org/10.1016/j.conb.2017.07.011},
	journal = {Current Opinion in Neurobiology},
	author = {Ocker, Gabriel Koch and Hu, Yu and Buice, Michael A and Doiron, Brent and Josić, Krešimir and Rosenbaum, Robert and Shea-Brown, Eric},
	year = {2017},
	pages = {109--119},
	file = {Attachment:/Users/tito/Zotero/storage/ANIF5UQF/Ocker et al. - 2017 - From the statistics of connectivity to the statistics of spike times in neuronal networks.pdf:application/pdf},
}

@article{kanashiro_attentional_2017,
	title = {Attentional modulation of neuronal variability in circuit models of cortex},
	volume = {6},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.23978},
	doi = {10.7554/eLife.23978},
	abstract = {The circuit mechanisms behind shared neural variability (noise correlation) and its dependence on neural state are poorly understood. Visual attention is well-suited to constrain cortical models of response variability because attention both increases firing rates and their stimulus sensitivity, as well as decreases noise correlations. We provide a novel analysis of population recordings in rhesus primate visual area V4 showing that a single biophysical mechanism may underlie these diverse neural correlates of attention. We explore model cortical networks where top-down mediated increases in excitability, distributed across excitatory and inhibitory targets, capture the key neuronal correlates of attention. Our models predict that top-down signals primarily affect inhibitory neurons, whereas excitatory neurons are more sensitive to stimulus specific bottom-up inputs. Accounting for trial variability in models of state dependent modulation of neuronal activity is a critical step in building a mechanistic theory of neuronal cognition.},
	journal = {eLife},
	author = {Kanashiro, Tatjana and Ocker, Gabriel Koch and Cohen, Marlene R and Doiron, Brent},
	editor = {Latham, Peter},
	year = {2017},
	keywords = {noise correlations, inhibitory feedback, mean field model, neural correlates of attention},
	pages = {e23978},
	file = {Attachment:/Users/tito/Zotero/storage/FD8K9ZAY/Kanashiro et al. - 2017 - Attentional modulation of neuronal variability in circuit models of cortex.pdf:application/pdf},
}

@article{he_scale-free_2011,
	title = {Scale-{Free} {Properties} of the {Functional} {Magnetic} {Resonance} {Imaging} {Signal} during {Rest} and {Task}},
	volume = {31},
	url = {http://www.jneurosci.org/content/31/39/13786.abstract},
	abstract = {It has been shown recently that a significant portion of brain electrical field potentials consists of scale-free dynamics. These scale-free brain dynamics contain complex spatiotemporal structures and are modulated by task performance. Here we show that the fMRI signal recorded from the human brain is also scale free; its power-law exponent differentiates between brain networks and correlates with fMRI signal variance and brain glucose metabolism. Importantly, in parallel to brain electrical field potentials, the variance and power-law exponent of the fMRI signal decrease during task activation, suggesting that the signal contains more long-range memory during rest and conversely is more efficient at online information processing during task. Remarkably, similar changes also occurred in task-deactivated brain regions, revealing the presence of an optimal dynamic range in the fMRI signal. The scale-free properties of the fMRI signal and brain electrical field potentials bespeak their respective stationarity and nonstationarity. This suggests that neurovascular coupling mechanism is likely to contain a transformation from nonstationarity to stationarity. In summary, our results demonstrate the functional relevance of scale-free properties of the fMRI signal and impose constraints on future models of neurovascular coupling.},
	number = {39},
	journal = {The Journal of Neuroscience},
	author = {He, Biyu J},
	month = sep,
	year = {2011},
	pages = {13786 LP -- 13795},
	file = {Attachment:/Users/tito/Zotero/storage/GGZ7TG4L/He - 2011 - Scale-Free Properties of the Functional Magnetic Resonance Imaging Signal during Rest and Task.pdf:application/pdf},
}

@article{ecker_effect_2011,
	title = {The {Effect} of {Noise} {Correlations} in {Populations} of {Diversely} {Tuned} {Neurons}},
	volume = {31},
	url = {http://www.jneurosci.org/content/31/40/14272.abstract},
	abstract = {The amount of information encoded by networks of neurons critically depends on the correlation structure of their activity. Neurons with similar stimulus preferences tend to have higher noise correlations than others. In homogeneous populations of neurons, this limited range correlation structure is highly detrimental to the accuracy of a population code. Therefore, reduced spike count correlations under attention, after adaptation, or after learning have been interpreted as evidence for a more efficient population code. Here, we analyze the role of limited range correlations in more realistic, heterogeneous population models. We use Fisher information and maximum-likelihood decoding to show that reduced correlations do not necessarily improve encoding accuracy. In fact, in populations with more than a few hundred neurons, increasing the level of limited range correlations can substantially improve encoding accuracy. We found that this improvement results from a decrease in noise entropy that is associated with increasing correlations if the marginal distributions are unchanged. Surprisingly, for constant noise entropy and in the limit of large populations, the encoding accuracy is independent of both structure and magnitude of noise correlations.},
	number = {40},
	journal = {The Journal of Neuroscience},
	author = {Ecker, Alexander S and Berens, Philipp and Tolias, Andreas S and Bethge, Matthias},
	month = oct,
	year = {2011},
	pages = {14272 LP -- 14283},
	file = {Attachment:/Users/tito/Zotero/storage/D5YFWCBP/Ecker et al. - 2011 - The Effect of Noise Correlations in Populations of Diversely Tuned Neurons.pdf:application/pdf},
}

@article{cafaro_noise_2010,
	title = {Noise correlations improve response fidelity and stimulus encoding},
	volume = {468},
	url = {http://dx.doi.org/10.1038/nature09570 http://10.0.4.14/nature09570 https://www.nature.com/articles/nature09570#supplementary-information},
	journal = {Nature},
	author = {Cafaro, Jon and Rieke, Fred},
	month = dec,
	year = {2010},
	pages = {964},
	file = {Attachment:/Users/tito/Zotero/storage/H6V53W49/Cafaro, Rieke - 2010 - Noise correlations improve response fidelity and stimulus encoding.pdf:application/pdf},
}

@article{zipser_back-propagation_1988,
	title = {A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons},
	volume = {331},
	url = {http://dx.doi.org/10.1038/331679a0 http://10.0.4.14/331679a0},
	journal = {Nature},
	author = {Zipser, David and Andersen, Richard A},
	month = feb,
	year = {1988},
	pages = {679},
	file = {Attachment:/Users/tito/Zotero/storage/ET25KHVS/Zipser, Andersen - 1988 - A back-propagation programmed network that simulates response properties of a subset of posterior parietal neu.pdf:application/pdf},
}

@article{kilic_models_2017,
	title = {Models that allow us to perceive the world more accurately also allow us to remember past events more accurately via differentiation},
	volume = {92},
	issn = {0010-0285},
	url = {http://www.sciencedirect.com/science/article/pii/S001002851530061X},
	doi = {https://doi.org/10.1016/j.cogpsych.2016.11.005},
	journal = {Cognitive Psychology},
	author = {Kılıç, Aslı and Criss, Amy H and Malmberg, Kenneth J and Shiffrin, Richard M},
	year = {2017},
	keywords = {Memory models, Output interference, Recognition memory, The strength based mirror effect},
	pages = {65--86},
}

@article{watson_temporal_nodate,
	title = {Temporal coupling of field potentials and action potentials in the neocortex},
	issn = {1460-9568},
	url = {http://dx.doi.org/10.1111/ejn.13807},
	doi = {10.1111/ejn.13807},
	journal = {European Journal of Neuroscience},
	author = {Watson, Brendon O and Ding, Mingxin and Buzsáki, György},
	keywords = {action potential, cortex, local field potential},
	pages = {n/a--n/a},
}

@article{buzsaki_origin_2012,
	title = {The origin of extracellular fields and currents — {EEG}, {ECoG}, {LFP} and spikes},
	volume = {13},
	url = {http://dx.doi.org/10.1038/nrn3241 http://10.0.4.14/nrn3241 https://www.nature.com/articles/nrn3241#supplementary-information},
	journal = {Nature Reviews Neuroscience},
	author = {Buzsáki, György and Anastassiou, Costas A and Koch, Christof},
	month = may,
	year = {2012},
	pages = {407},
}

@article{woolgar_fluid_2010,
	title = {Fluid intelligence loss linked to restricted regions of damage within frontal and parietal cortex},
	volume = {107},
	url = {http://www.pnas.org/content/107/33/14899.abstract},
	abstract = {Tests of fluid intelligence predict success in a wide range of cognitive activities. Much uncertainty has surrounded brain lesions producing deficits in these tests, with standard group comparisons delivering no clear result. Based on findings from functional imaging, we propose that the uncertainty of lesion data may arise from the specificity and complexity of the relevant neural circuit. Fluid intelligence tests give a characteristic pattern of activity in posterolateral frontal, dorsomedial frontal, and midparietal cortex. To test the causal role of these regions, we examined fluid intelligence in 80 patients with focal cortical lesions. Damage to each of the proposed regions predicted fluid intelligence loss, whereas damage outside these regions was not predictive. The results suggest that coarse group comparisons (e.g., frontal vs. posterior) cannot show the neural underpinnings of fluid intelligence tests. Instead, deficits reflect the extent of damage to a restricted but complex brain circuit comprising specific regions within both frontal and posterior cortex.},
	number = {33},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Woolgar, Alexandra and Parr, Alice and Cusack, Rhodri and Thompson, Russell and Nimmo-Smith, Ian and Torralva, Teresa and Roca, Maria and Antoun, Nagui and Manes, Facundo and Duncan, John},
	month = aug,
	year = {2010},
	pages = {14899 LP -- 14902},
}

@article{leal_integrating_2018,
	title = {Integrating new findings and examining clinical applications of pattern separation},
	issn = {1546-1726},
	url = {https://doi.org/10.1038/s41593-017-0065-1},
	doi = {10.1038/s41593-017-0065-1},
	abstract = {Pattern separation, the ability to independently represent and store similar experiences, is a crucial facet of episodic memory. Growing evidence suggests that the hippocampus possesses unique circuitry that is computationally capable of resolving mnemonic interference by using pattern separation. In this Review, we discuss recent advances in the understanding of this process and evaluate the caveats and limitations of linking across animal and human studies. We summarize clinical and translational studies using methods that are sensitive to pattern separation impairments, an approach that stems from the fact that the hippocampus is a major site of disruption in many brain disorders. We critically evaluate the assumptions that guide fundamental and translational studies in this area. Finally, we suggest guidelines for future research and offer ways to overcome potential interpretational challenges to increase the utility of pattern separation as a construct that can further understanding of both memory processes and brain disease.},
	journal = {Nature Neuroscience},
	author = {Leal, Stephanie L and Yassa, Michael A},
	year = {2018},
	file = {Attachment:/Users/tito/Zotero/storage/FKTFMYIK/Leal, Yassa - 2018 - Integrating new findings and examining clinical applications of pattern separation.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/4C8ZIWBZ/Leal, Yassa - 2018 - Integrating new findings and examining clinical applications of pattern separation.pdf:application/pdf},
}

@article{bijsterbosch_relationship_2018,
	title = {The relationship between spatial configuration and functional connectivity of brain regions},
	volume = {7},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.32992},
	doi = {10.7554/eLife.32992},
	abstract = {Brain connectivity is often considered in terms of the communication between functionally distinct brain regions. Many studies have investigated the extent to which patterns of coupling strength between multiple neural populations relates to behaviour. For example, studies have used 'functional connectivity fingerprints' to characterise individuals' brain activity. Here, we investigate the extent to which the exact spatial arrangement of cortical regions interacts with measures of brain connectivity. We find that the shape and exact location of brain regions interact strongly with the modelling of brain connectivity, and present evidence that the spatial arrangement of functional regions is strongly predictive of non-imaging measures of behaviour and lifestyle. We believe that, in many cases, cross-subject variations in the spatial configuration of functional brain regions are being interpreted as changes in functional connectivity. Therefore, a better understanding of these effects is important when interpreting the relationship between functional imaging data and cognitive traits.},
	journal = {eLife},
	author = {Bijsterbosch, Janine Diane and Woolrich, Mark W and Glasser, Matthew F and Robinson, Emma C and Beckmann, Christian F and Van Essen, David C and Harrison, Samuel J and Smith, Stephen M},
	editor = {Honey, Chris},
	year = {2018},
	keywords = {functional connectivity, resting state, fingerprinting, functional connectomes, parcellation},
	pages = {e32992},
	file = {Attachment:/Users/tito/Zotero/storage/DZETW27I/Bijsterbosch et al. - 2018 - The relationship between spatial configuration and functional connectivity of brain regions.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/UKCI7WYJ/Bijsterbosch et al. - 2018 - The relationship between spatial configuration and functional connectivity of brain regions(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/62TZAGYW/Bijsterbosch et al. - 2018 - The relationship between spatial configuration and functional connectivity of brain regions.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TUD5XA2L/Bijsterbosch et al. - 2018 - The relationship between spatial configuration and functional connectivity of brain regions(2).pdf:application/pdf},
}

@article{shine_modulation_2017,
	title = {The modulation of neural gain facilitates a transition between functional segregation and integration in the brain},
	url = {http://dx.doi.org/10.1101/182444},
	doi = {10.1101/182444},
	abstract = {Cognitive function relies on a dynamic, context-sensitive balance between functional integration and segregation in the brain. Previous work has proposed that this balance is mediated by global fluctuations in neural gain by projections from ascending neuromodulatory nuclei. To test this hypothesis in silico, we studied the effects of neural gain on network dynamics in a model of large-scale neuronal dynamics. We found that increases in neural gain pushed the network through an abrupt dynamical transition, leading to an integrated network topology that was maximal in frontoparietal ‘rich club' regions. This gain-mediated transition was also associated with increased topological complexity, as well as increased variability in time-resolved topological structure, further highlighting the potential computational benefits of the gain-mediated network transition. These results support the hypothesis that neural gain modulation has the computational capacity to mediate the balance between integration and segregation in the brain.},
	journal = {eLife},
	author = {Shine, James M and Aburn, Matthew J and Breakspear, Michael and Russell, A},
	year = {2017},
	pages = {1--28},
	file = {Attachment:/Users/tito/Zotero/storage/QWSIPHLZ/Shine et al. - 2017 - The modulation of neural gain facilitates a transition between functional segregation and integration in the brain.pdf:application/pdf},
}

@article{mattar_predicting_2016,
	title = {Predicting future learning from baseline network architecture},
	volume = {172},
	issn = {10538119},
	url = {http://www.biorxiv.org/content/early/2016/06/03/056861.abstract},
	doi = {10.1101/056861},
	abstract = {Human behavior and cognition result from a complex pattern of interactions between brain regions. The flexible reconfiguration of these patterns enables behavioral adaptation, such as the acquisition of a new motor skill. Yet, the degree to which these reconfigurations depend on the brain's baseline sensorimotor integration is far from understood. Here, we asked whether spontaneous fluctuations in sensorimotor networks at baseline were predictive of individual differences in future learning. We collected functional MRI data from 22 participants prior to six weeks of training on a new motor skill. We found that visual-motor connectivity was inversely related to learning rate: sensorimotor autonomy at baseline corresponded to faster learning in the future. Using three additional scans, we found that visual-motor connectivity at baseline is a relatively stable individual trait. These results demonstrate that individual differences in motor skill learning can be reliably predicted from sensorimotor autonomy at baseline prior to task execution.},
	number = {January},
	journal = {bioRxiv},
	author = {Mattar, Marcelo and Wymbs, Nicholas F and Bock, Andrew S and Aguirre, Geoffrey K and Grafton, Scott T and Bassett, Danielle S},
	year = {2016},
	pages = {056861},
	file = {Attachment:/Users/tito/Zotero/storage/544TXJZ7/Mattar et al. - 2016 - Predicting future learning from baseline network architecture.pdf:application/pdf},
}

@article{vidaurre_brain_2017,
	title = {Brain network dynamics are hierarchically organized in time},
	url = {http://www.pnas.org/content/early/2017/10/26/1705120114.abstract},
	abstract = {We address the important question of the temporal organization of large-scale brain networks, finding that the spontaneous transitions between networks of interacting brain areas are predictable. More specifically, the network activity is highly organized into a hierarchy of two distinct metastates, such that transitions are more probable within, than between, metastates. One of these metastates represents higher order cognition, and the other represents the sensorimotor systems. Furthermore, the time spent in each metastate is subject-specific, is heritable, and relates to behavior. Although evidence of non–random-state transitions has been found at the microscale, this finding at the whole-brain level, together with its relation to behavior, has wide implications regarding the cognitive role of large-scale resting-state networks.The brain recruits neuronal populations in a temporally coordinated manner in task and at rest. However, the extent to which large-scale networks exhibit their own organized temporal dynamics is unclear. We use an approach designed to find repeating network patterns in whole-brain resting fMRI data, where networks are defined as graphs of interacting brain areas. We find that the transitions between networks are nonrandom, with certain networks more likely to occur after others. Further, this nonrandom sequencing is itself hierarchically organized, revealing two distinct sets of networks, or metastates, that the brain has a tendency to cycle within. One metastate is associated with sensory and motor regions, and the other involves areas related to higher order cognition. Moreover, we find that the proportion of time that a subject spends in each brain network and metastate is a consistent subject-specific measure, is heritable, and shows a significant relationship with cognitive traits.},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Vidaurre, Diego and Smith, Stephen M and Woolrich, Mark W},
	month = oct,
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/KI6RGFY4/Vidaurre, Smith, Woolrich - 2017 - Brain network dynamics are hierarchically organized in time.pdf:application/pdf},
}

@article{ciuciu_interplay_2014,
	title = {Interplay between functional connectivity and scale-free dynamics in intrinsic {fMRI} networks},
	volume = {95},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2014.03.047},
	doi = {10.1016/j.neuroimage.2014.03.047},
	abstract = {Studies employing functional connectivity-type analyses have established that spontaneous fluctuations in functional magnetic resonance imaging (fMRI) signals are organized within large-scale brain networks. Meanwhile, fMRI signals have been shown to exhibit 1/f-type power spectra - a hallmark of scale-free dynamics. We studied the interplay between functional connectivity and scale-free dynamics in fMRI signals, utilizing the fractal connectivity framework - a multivariate extension of the univariate fractional Gaussian noise model, which relies on a wavelet formulation for robust parameter estimation. We applied this framework to fMRI data acquired from healthy young adults at rest and while performing a visual detection task. First, we found that scale-invariance existed beyond univariate dynamics, being present also in bivariate cross-temporal dynamics. Second, we observed that frequencies within the scale-free range do not contribute evenly to inter-regional connectivity, with a systematically stronger contribution of the lowest frequencies, both at rest and during task. Third, in addition to a decrease of the Hurst exponent and inter-regional correlations, task performance modified cross-temporal dynamics, inducing a larger contribution of the highest frequencies within the scale-free range to global correlation. Lastly, we found that across individuals, a weaker task modulation of the frequency contribution to inter-regional connectivity was associated with better task performance manifesting as shorter and less variable reaction times. These findings bring together two related fields that have hitherto been studied separately - resting-state networks and scale-free dynamics, and show that scale-free dynamics of human brain activity manifest in cross-regional interactions as well. © 2014 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Ciuciu, Philippe and Abry, Patrice and He, Biyu J.},
	year = {2014},
	pmid = {24675649},
	keywords = {FMRI, Cross-temporal dynamics, Intrinsic brain activity, Scale-free dynamics, Task modulation},
	pages = {248--263},
	file = {Attachment:/Users/tito/Zotero/storage/BMNEKKLT/Ciuciu, Abry, He - 2014 - Interplay between functional connectivity and scale-free dynamics in intrinsic fMRI networks.pdf:application/pdf},
}

@article{betzel_diversity_2017,
	title = {Diversity of meso-scale architecture in human and non-human connectomes},
	issn = {2041-1723},
	url = {http://arxiv.org/abs/1702.02807},
	doi = {10.1038/s41467-017-02681-z},
	abstract = {The brain's functional diversity is reflected in the meso-scale architecture of its connectome, i.e. its division into clusters and communities of topologically-related brain regions. The dominant view, and one that is reinforced by current analysis techniques, is that communities are strictly assortative and segregated from one another, purportedly for the purpose of carrying out specialized information processing. Such a view, however, precludes the possibility of non-assortative communities that could engender a richer functional repertoire by allowing for a more complex set of inter-community interactions. Here, we use weighted stochastic blockmodels to uncover the meso-scale architecture of \${\textbackslash}backslash\$emph\{Drosophila\}, mouse, rat, macaque, and human connectomes. We confirm that while many communities are assortative, others form core-periphery and disassortative structures, which in the human better recapitulate observed patterns of functional connectivity and in the mouse better recapitulate observed patterns of gene co-expression than other community detection techniques. We define a set of network measures for quantifying the diversity of community types in which brain regions participate. Finally, we show that diversity is peaked in control and subcortical systems in humans, and that individual differences in diversity within those systems predicts cognitive performance on Stroop and Navon tasks. In summary, our report paints a more diverse portrait of connectome meso-scale structure and demonstrates its relevance for cognitive performance.},
	number = {2018},
	journal = {Nature Communications},
	author = {Betzel, Richard F. and Medaglia, John D. and Bassett, Danielle S.},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/YF36RS6Q/Betzel, Medaglia, Bassett - 2017 - Diversity of meso-scale architecture in human and non-human connectomes.pdf:application/pdf},
}

@article{smith_statistical_2018,
	title = {Statistical {Challenges} in “{Big} {Data}” {Human} {Neuroimaging}},
	volume = {97},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627317311418},
	doi = {10.1016/j.neuron.2017.12.018},
	number = {2},
	journal = {Neuron},
	author = {Smith, Stephen M. and Nichols, Thomas E.},
	year = {2018},
	pages = {263--268},
	file = {Attachment:/Users/tito/Zotero/storage/DSLRWMIG/Smith, Nichols - 2018 - Statistical Challenges in “Big Data” Human Neuroimaging.pdf:application/pdf},
}

@article{van_den_heuvel_rich-club_2011,
	title = {Rich-{Club} {Organization} of the {Human} {Connectome}},
	volume = {31},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3539-11.2011},
	doi = {10.1523/JNEUROSCI.3539-11.2011},
	abstract = {The human brain is a complex network of interlinked regions. Recent studies have demonstrated the existence of a number of highly connected and highly central neocortical hub regions, regions that play a key role in global information integration between different parts of the network. The potential functional importance of these "brain hubs" is underscored by recent studies showing that disturbances of their structural and functional connectivity profile are linked to neuropathology. This study aims to map out both the subcortical and neocortical hubs of the brain and examine their mutual relationship, particularly their structural linkages. Here, we demonstrate that brain hubs form a so-called "rich club," characterized by a tendency for high-degree nodes to be more densely connected among themselves than nodes of a lower degree, providing important information on the higher-level topology of the brain network. Whole-brain structural networks of 21 subjects were reconstructed using diffusion tensor imaging data. Examining the connectivity profile of these networks revealed a group of 12 strongly interconnected bihemispheric hub regions, comprising the precuneus, superior frontal and superior parietal cortex, as well as the subcortical hippocampus, putamen, and thalamus. Importantly, these hub regions were found to be more densely interconnected than would be expected based solely on their degree, together forming a rich club. We discuss the potential functional implications of the rich-club organization of the human connectome, particularly in light of its role in information integration and in conferring robustness to its structural core.},
	number = {44},
	journal = {Journal of Neuroscience},
	author = {van den Heuvel, M. P. and Sporns, O.},
	year = {2011},
	pmid = {22049421},
	pages = {15775--15786},
	file = {Attachment:/Users/tito/Zotero/storage/4MI4EK3U/van den Heuvel, Sporns - 2011 - Rich-Club Organization of the Human Connectome.pdf:application/pdf},
}

@article{cohen_its_2011,
	title = {It's about time},
	volume = {5},
	doi = {10.3389/fnhum.2011.00002},
	number = {January},
	author = {Cohen, Michael X},
	year = {2011},
	pages = {1--15},
}

@article{douglas_modulating_2015,
	title = {Modulating conscious movement intention by noninvasive brain stimulation and the underlying neural mechanisms},
	volume = {35},
	number = {18},
	journal = {Journal of Neuroscience},
	author = {Douglas, Zachary H and Maniscalco, Brian and Hallett, Mark and Wassermann, Eric M and He, Biyu J},
	year = {2015},
	keywords = {spontaneous activity, eeg, movement intention, slow cortical potential, tdcs, volition},
	pages = {7239--7255},
	file = {Attachment:/Users/tito/Zotero/storage/V2TJ283S/Douglas et al. - 2015 - Modulating conscious movement intention by noninvasive brain stimulation and the underlying neural mechanisms.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/VEQH4P6W/Douglas et al. - 2015 - Modulating conscious movement intention by noninvasive brain stimulation and the underlying neural mechanisms.pdf:application/pdf},
}

@article{wang_brain_2013,
	title = {Brain mechanisms for simple perception and bistable perception},
	volume = {2013},
	doi = {10.1073/pnas.1221945110/-/DCSupplemental.www.pnas.org/cgi/doi/10.1073/pnas.1221945110},
	author = {Wang, Megan and Arteaga, Daniel and He, Biyu J},
	year = {2013},
	file = {Attachment:/Users/tito/Zotero/storage/M8Z4MU6C/Wang, Arteaga, He - 2013 - Brain mechanisms for simple perception and bistable perception.pdf:application/pdf},
}

@article{wang_brain_2013-1,
	title = {Brain mechanisms for simple perception and bistable perception},
	volume = {110},
	url = {http://www.pnas.org/content/110/35/E3350.abstract},
	doi = {10.1073/pnas.1221945110},
	abstract = {When faced with ambiguous sensory inputs, subjective perception alternates between the different interpretations in a stochastic manner. Such multistable perception phenomena have intrigued scientists and laymen alike for over a century. Despite rigorous investigations, the underlying mechanisms of multistable perception remain elusive. Recent studies using multivariate pattern analysis revealed that activity patterns in posterior visual areas correlate with fluctuating percepts. However, increasing evidence suggests that vision—and perception at large—is an active inferential process involving hierarchical brain systems. We applied searchlight multivariate pattern analysis to functional magnetic resonance imaging signals across the human brain to decode perceptual content during bistable perception and simple unambiguous perception. Although perceptually reflective activity patterns during simple perception localized predominantly to posterior visual regions, bistable perception involved additionally many higher-order frontoparietal and temporal regions. Moreover, compared with simple perception, both top-down and bottom-up influences were dramatically enhanced during bistable perception. We further studied the intermittent presentation of ambiguous images—a condition that is known to elicit perceptual memory. Compared with continuous presentation, intermittent presentation recruited even more higher-order regions and was accompanied by further strengthened top-down influences but relatively weakened bottom-up influences. Taken together, these results strongly support an active top-down inferential process in perception.},
	number = {35},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Wang, Megan and Arteaga, Daniel and He, Biyu J},
	month = aug,
	year = {2013},
	pages = {E3350--E3359},
	annote = {10.1073/pnas.1221945110},
	file = {Attachment:/Users/tito/Zotero/storage/CWBF2WCA/Wang, Arteaga, He - 2013 - Brain mechanisms for simple perception and bistable perception.pdf:application/pdf},
}

@article{baria_initial-state-dependent_2017,
	title = {Initial-state-dependent, robust, transient neural dynamics encode conscious visual perception},
	volume = {13},
	url = {https://doi.org/10.1371/journal.pcbi.1005806},
	abstract = {Author summary What brain mechanisms underlie conscious perception? A commonly adopted paradigm for studying this question is to present human subjects with threshold-level stimuli. When shown repeatedly, the same stimulus is sometimes consciously perceived, sometimes not. Using magnetoencephalography, we shed light on the neural mechanisms governing whether the stimulus is consciously perceived in a given trial. We observed that depending on the initial brain state defined by widespread activity pattern in the slow cortical potential ({\textbackslash}textless5 Hz) range, a physically identical, brief (30–60 ms) stimulus input triggers distinct sequences of activity pattern evolution over time that correspond to either consciously perceiving the stimulus or not. Such activity pattern evolution forms a “trajectory” in the state space and affords significant single-trial decoding of perceptual outcome from 1 sec before to 3 sec after stimulus onset. While previous theories on conscious perception have emphasized sustained, high-level activity, we found that brain dynamics underlying conscious perception exhibit fast-changing activity patterns. These results significantly further our understanding on the neural mechanisms governing conscious access of a stimulus and the dynamical nature of distributed neural activity underlying conscious perception.},
	number = {11},
	journal = {PLOS Computational Biology},
	author = {Baria, Alexis T and Maniscalco, Brian and He, Biyu J},
	month = nov,
	year = {2017},
	pages = {e1005806},
	file = {Attachment:/Users/tito/Zotero/storage/23662MLZ/Baria, Maniscalco, He - 2017 - Initial-state-dependent, robust, transient neural dynamics encode conscious visual perception.pdf:application/pdf},
}

@article{marcus_deep_nodate,
	title = {Deep {Learning} : {A} {Critical} {Appraisal}},
	author = {Marcus, Gary},
	pages = {1--27},
	file = {Attachment:/Users/tito/Zotero/storage/YSUDQSKS/Marcus - Unknown - Deep Learning A Critical Appraisal.pdf:application/pdf},
}

@article{arazi_magnitude_2017,
	title = {The {Magnitude} of {Trial}-{By}-{Trial} {Neural} {Variability} {Is} {Reproducible} over {Time} and across {Tasks} in {Humans}},
	volume = {4},
	url = {http://eneuro.org/content/4/6/ENEURO.0292-17.2017.abstract},
	abstract = {Numerous studies have shown that neural activity in sensory cortices is remarkably variable over time and across trials even when subjects are presented with an identical repeating stimulus or task. This trial-by-trial neural variability is relatively large in the prestimulus period and considerably smaller (quenched) following stimulus presentation. Previous studies have suggested that the magnitude of neural variability affects behavior such that perceptual performance is better on trials and in individuals where variability quenching is larger. To what degree are neural variability magnitudes of individual subjects flexible or static? Here, we used EEG recordings from adult humans to demonstrate that neural variability magnitudes in visual cortex are remarkably consistent across different tasks and recording sessions. While magnitudes of neural variability differed dramatically across individual subjects, they were surprisingly stable across four tasks with different stimuli, temporal structures, and attentional/cognitive demands as well as across experimental sessions separated by one year. These experiments reveal that, in adults, neural variability magnitudes are mostly solidified individual characteristics that change little with task or time, and are likely to predispose individual subjects to exhibit distinct behavioral capabilities.},
	number = {6},
	journal = {eneuro},
	author = {Arazi, Ayelet and Gonen-Yaacovi, Gil and Dinstein, Ilan},
	month = nov,
	year = {2017},
	keywords = {variability quenching, eeg, brain activity varies dramatically, exhibit different magnitudes of, from one moment to, neural noise, recent research has revealed, significance statement, that humans, the next, their perceptual, trial-by-trial neural variability, trial-by-trial variability, which explain differences in},
	file = {Attachment:/Users/tito/Zotero/storage/9SDFB72X/Arazi, Gonen-yaacovi - 2017 - The Magnitude of Trial-By-Trial Neural Variability Is Reproducible over Time and across Tasks in Humans.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/QFV2LGN7/Arazi, Gonen-yaacovi - 2017 - The Magnitude of Trial-By-Trial Neural Variability Is Reproducible over Time and across Tasks in Humans.pdf:application/pdf},
}

@article{baria_neural_2017,
	title = {neural dynamics encode conscious visual perception},
	author = {Baria, Alexis T and Maniscalco, Brian and He, Biyu J},
	year = {2017},
	pages = {1--29},
	file = {Attachment:/Users/tito/Zotero/storage/QGE4KFX3/Baria, Maniscalco, He - 2017 - Initial-state-dependent, robust, transient neural dynamics encode conscious visual perception.pdf:application/pdf},
}

@article{kopell_beyond_2014,
	title = {Beyond the {Connectome}: {The} {Dynome}},
	volume = {83},
	issn = {0896-6273},
	url = {http://dx.doi.org/10.1016/j.neuron.2014.08.016},
	doi = {10.1016/j.neuron.2014.08.016},
	number = {6},
	journal = {Neuron},
	author = {Kopell, Nancy J. and Gritton, Howard J. and Whittington, Miles A. and Kramer, Mark A.},
	month = dec,
	year = {2014},
	pages = {1319--1328},
	annote = {doi: 10.1016/j.neuron.2014.08.016},
	file = {Attachment:/Users/tito/Zotero/storage/6ISASXAM/Kopell et al. - 2014 - Perspective Beyond the Connectome The Dynome.pdf:application/pdf},
}

@article{anzellotti_beyond_2017,
	title = {Beyond {Functional} {Connectivity} : {Investigating} {Networks} of {Multivariate} {Representations}},
	volume = {xx},
	issn = {1364-6613},
	url = {http://dx.doi.org/10.1016/j.tics.2017.12.002},
	doi = {10.1016/j.tics.2017.12.002},
	journal = {Trends in Cognitive Sciences},
	author = {Anzellotti, Stefano and Coutanche, Marc N},
	year = {2017},
	pages = {1--12},
	file = {Attachment:/Users/tito/Zotero/storage/XM8LUKDR/Anzellotti, Coutanche - 2017 - Beyond Functional Connectivity Investigating Networks of Multivariate Representations.pdf:application/pdf},
}

@article{yan_network_2017,
	title = {Network control principles predict neuron function in the {Caenorhabditis} elegans connectome},
	volume = {550},
	issn = {14764687},
	url = {http://dx.doi.org/10.1038/nature24056},
	doi = {10.1038/nature24056},
	abstract = {{\textbackslash}textlessp{\textbackslash}textgreaterApplication of network control theory to the neuronal connectome of {\textbackslash}textlessi{\textbackslash}textgreaterCaenorhabditis elegans{\textbackslash}textless/i{\textbackslash}textgreater, allowing prediction of the involvement of individual neurons in locomotion.{\textbackslash}textless/p{\textbackslash}textgreater},
	number = {7677},
	journal = {Nature},
	author = {Yan, Gang and Vértes, Petra E. and Towlson, Emma K. and Chew, Yee Lian and Walker, Denise S. and Schafer, William R. and Barabási, Albert László},
	year = {2017},
	pmid = {11507039},
	pages = {519--523},
	file = {Attachment:/Users/tito/Zotero/storage/MCY3PVJL/Yan et al. - 2017 - Network control principles predict neuron function in the Caenorhabditis elegans connectome.pdf:application/pdf},
}

@article{harush_dynamic_nodate,
	title = {Dynamic patterns of information flow in complex networks},
	issn = {2041-1723},
	url = {http://dx.doi.org/10.1038/s41467-017-01916-3},
	doi = {10.1038/s41467-017-01916-3},
	journal = {Nature Communications},
	author = {Harush, Uzi and Barzel, Baruch},
	pages = {1--11},
	file = {Attachment:/Users/tito/Zotero/storage/4NAU7EGN/Harush, Barzel - Unknown - Dynamic patterns of information flow in complex networks.pdf:application/pdf},
}

@article{gratton_control_2017,
	title = {Control networks and hubs},
	issn = {00485772},
	url = {http://doi.wiley.com/10.1111/psyp.13032},
	doi = {10.1111/psyp.13032},
	number = {September},
	journal = {Psychophysiology},
	author = {Gratton, Caterina and Sun, Haoxin and Petersen, Steven E.},
	year = {2017},
	keywords = {functional connectivity, networks, fmri, cognitive control, executive control},
	pages = {1--18},
	file = {Attachment:/Users/tito/Zotero/storage/8PLPJH3P/Gratton, Sun, Petersen - 2017 - Control networks and hubs.pdf:application/pdf},
}

@article{epstein_cognitive_2017,
	title = {The cognitive map in humans : spatial navigation and beyond},
	doi = {10.1038/nn.4656},
	number = {October},
	author = {Epstein, Russell A and Patai, Eva Zita and Julian, Joshua B and Spiers, Hugo J},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/Q8XLT8QR/Epstein et al. - 2017 - The cognitive map in humans spatial navigation and beyond.pdf:application/pdf},
}

@article{frank_anatomy_2006,
	title = {Anatomy of a {Decision} : {Striato}-{Orbitofrontal} {Interactions} in {Reinforcement} {Learning} , {Decision} {Making} , and {Reversal}},
	volume = {113},
	doi = {10.1037/0033-295X.113.2.300},
	number = {2},
	author = {Frank, Michael J and Claus, Eric D},
	year = {2006},
	keywords = {decision making, orbitofrontal cortex, basal ganglia, choos-, even when having to, gains, incur short-term losses, make choices that lead, making skills depend on, neural network, reinforcement learning, selection, such decision-, the processes of action, to long-term, what enables humans to},
	pages = {300--326},
	file = {Attachment:/Users/tito/Zotero/storage/BAZEBE9Q/Frank, Claus - 2006 - Anatomy of a Decision Striato-Orbitofrontal Interactions in Reinforcement Learning , Decision Making , and Revers.pdf:application/pdf},
}

@article{constantinescu_h_2016,
	title = {H ( 9 ).},
	volume = {352},
	number = {6292},
	author = {Constantinescu, Alexandra O},
	year = {2016},
}

@article{holroyd_motivation_2012,
	title = {Motivation of extended behaviors by anterior cingulate cortex},
	volume = {16},
	doi = {10.1016/j.tics.2011.12.008},
	number = {2},
	author = {Holroyd, Clay B and Yeung, Nick},
	year = {2012},
	file = {Attachment:/Users/tito/Zotero/storage/6KI8BK9K/Holroyd, Yeung - 2012 - Motivation of extended behaviors by anterior cingulate cortex.pdf:application/pdf},
}

@article{vassena_computational_2017,
	title = {Computational {Models} of {Anterior} {Cingulate} {Cortex} : {At} the {Crossroads} between {Prediction} and {Effort}},
	volume = {11},
	doi = {10.3389/fnins.2017.00316},
	number = {June},
	author = {Vassena, Eliana and Holroyd, Clay B and Alexander, William H},
	year = {2017},
	keywords = {modeling, acc, anterior cingulate cortex, anterior cingulate cortex (ACC), computational, computational models of acc, effort, effortful control, predictio, prediction error},
	pages = {1--9},
	file = {Attachment:/Users/tito/Zotero/storage/4UCH6DSD/Vassena, Holroyd, Alexander - 2017 - Computational Models of Anterior Cingulate Cortex At the Crossroads between Prediction and Effort.pdf:application/pdf},
}

@article{cirelli_review_2015,
	title = {Review {Cortical} {Development} , {Electroencephalogram} {Rhythms} , and the {Sleep} / {Wake} {Cycle}},
	volume = {77},
	issn = {0006-3223},
	url = {http://dx.doi.org/10.1016/j.biopsych.2014.12.017},
	doi = {10.1016/j.biopsych.2014.12.017},
	number = {12},
	journal = {Biological Psychiatry},
	author = {Cirelli, Chiara and Tononi, Giulio and Wake, Sleep and In, Behavior and Development, Early},
	year = {2015},
	keywords = {017, 10, 1016, 12, 2014, active sleep, Active sleep, biopsych, doi, dx, gamma activity, Gamma activity, http, j, nrem sleep, NREM sleep, org, quiet sleep, Quiet sleep, rem sleep, REM sleep, spindle bursts, Spindle bursts, theta activity, Theta activity},
	pages = {1071--1078},
	file = {Attachment:/Users/tito/Zotero/storage/PIYE4H9X/Cirelli et al. - 2015 - Review Cortical Development , Electroencephalogram Rhythms , and the Sleep Wake Cycle.pdf:application/pdf},
}

@article{fox_how_2010,
	title = {How the {Timing} and {Quality} of {Early} {Experiences} {Influence} the {Development} of {Brain} {Architecture}},
	volume = {81},
	number = {1},
	author = {Fox, Sharon E and Iii, Charles A Nelson},
	year = {2010},
	pages = {28--40},
	file = {Attachment:/Users/tito/Zotero/storage/63GJFM9P/Fox, Iii - 2010 - How the Timing and Quality of Early Experiences Influence the Development of Brain Architecture.pdf:application/pdf},
}

@article{sandrini_neuroscience_2011,
	title = {Neuroscience and {Biobehavioral} {Reviews} {The} use of transcranial magnetic stimulation in cognitive neuroscience : {A} new synthesis of methodological issues},
	volume = {35},
	issn = {0149-7634},
	url = {http://dx.doi.org/10.1016/j.neubiorev.2010.06.005},
	doi = {10.1016/j.neubiorev.2010.06.005},
	number = {3},
	journal = {Neuroscience and Biobehavioral Reviews},
	author = {Sandrini, Marco and Umiltà, Carlo and Rusconi, Elena},
	year = {2011},
	pages = {516--536},
}

@article{blumberg_twitching_2013,
	title = {Twitching in {Sensorimotor} {Development} from {Sleeping} {Rats} to {Robots} {Minireview}},
	volume = {23},
	issn = {0960-9822},
	url = {http://dx.doi.org/10.1016/j.cub.2013.04.075},
	doi = {10.1016/j.cub.2013.04.075},
	number = {12},
	journal = {CURBIO},
	author = {Blumberg, Mark S and Marques, Hugo Gravato},
	year = {2013},
	pages = {R532--R537},
	file = {Attachment:/Users/tito/Zotero/storage/S9FITFJQ/Blumberg, Marques - 2013 - Twitching in Sensorimotor Development from Sleeping Rats to Robots Minireview.pdf:application/pdf},
}

@article{chang_representation_nodate,
	title = {The representation of colored objects in macaque color patches},
	issn = {2041-1723},
	url = {http://dx.doi.org/10.1038/s41467-017-01912-7},
	doi = {10.1038/s41467-017-01912-7},
	journal = {Nature Communications},
	author = {Chang, Le and Bao, Pinglei and Tsao, Doris Y},
	pages = {1--14},
	file = {Attachment:/Users/tito/Zotero/storage/N3QGGVG8/Chang, Bao, Tsao - Unknown - The representation of colored objects in macaque color patches.pdf:application/pdf},
}

@article{charil_prenatal_2010,
	title = {Prenatal stress and brain development},
	volume = {65},
	issn = {0165-0173},
	url = {http://dx.doi.org/10.1016/j.brainresrev.2010.06.002},
	doi = {10.1016/j.brainresrev.2010.06.002},
	number = {1},
	journal = {Brain Research Reviews},
	author = {Charil, Arnaud and Laplante, David P and Vaillancourt, Cathy and King, Suzanne},
	year = {2010},
	pages = {56--79},
	file = {Attachment:/Users/tito/Zotero/storage/VDKP632E/Charil et al. - 2010 - Prenatal stress and brain development.pdf:application/pdf},
}

@article{carmichael_measurement_2017,
	title = {Measurement of the mapping between intracranial {EEG} and {fMRI} recordings in the human brain},
	url = {http://biorxiv.org/content/early/2017/12/21/237198.abstract},
	abstract = {There are considerable gaps in our understanding of the relationship between human brain activity measured at different temporal and spatial scales by intracranial electroencephalography and fMRI. By comparing individual features and summary descriptions of intracranial EEG activity we determined which best predict fMRI changes in the sensorimotor cortex in two brain states: at rest and during motor performance. We also then examine the specificity of this relationship to spatial colocalisation of the two signals. We acquired electrocorticography and fMRI simultaneously (ECoG-fMRI) in the sensorimotor cortex of 3 patients with epilepsy. During motor activity, high gamma power was the only frequency band where the electrophysiological response was co-localised with fMRI measures across all subjects. The best model of fMRI changes was its principal components, a parsimonious description of the entire ECoG spectrogram. This model performed much better than a model based on the classical frequency bands both during task and rest periods or models derived on a summary of cross spectral changes (e.g. root mean squared EEG frequency). This suggests that the region specific fMRI signal is reflected in spatially and spectrally distributed EEG activity.},
	journal = {bioRxiv},
	author = {Carmichael, David W and Vulliemoz, Serge and Murta, Teresa and Chaudhary, Umair and Perani, Suejen and Rodionov, Roman and Rosa, Maria M J and Friston, Karl and Lemieux, Louis},
	month = jan,
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/WVC4DYE4/Carmichael et al. - 2017 - Measurement of the mapping between intracranial EEG and fMRI recordings in the human brain.pdf:application/pdf},
}

@article{badre_frontal_2017,
	title = {Frontal {Cortex} and the {Hierarchical} {Control} of {Behavior}},
	volume = {xx},
	issn = {13646613},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661317302450},
	doi = {10.1016/j.tics.2017.11.005},
	abstract = {The frontal lobes are important for cognitive control, yet their functional orga-nization remains controversial. An influential class of theory proposes that the frontal lobes are organized along their rostrocaudal axis to support hierarchical cognitive control. Here, we take an updated look at the literature on hierarchical control, with particular focus on the functional organization of lateral frontal cortex. Our review of the evidence supports neither a unitary model of lateral frontal function nor a unidimensional abstraction gradient. Rather, separate frontal networks interact via local and global hierarchical structure to support diverse task demands. Cognitive Control and Functional Organization of Frontal Lobes Humans have an unrivaled ability to envision a desired state of affairs and then carry out the actions to achieve it. This capacity to manage goal-directed behaviors in novel situations, counter to habit, or amidst competing action choices is termed cognitive control [1–3]. In the brain, cognitive control (see Glossary) has a close dependency on the frontal lobes and their associated systems [4]. However, there has been persistent controversy regarding the func-tional organization of the frontal lobes, whether there exist one or more functionally distinct areas or networks, and how these components interact to support controlled behavior. Here, we take an updated look at an influential class of hypotheses surrounding the rostro-caudal organization of function in the frontal lobes. Though several variants of this organizing principle have been proposed (reviewed in [5]), the common element has been that rostral frontal areas are involved in more abstract forms of control than more caudal areas. This putative rostrocaudal abstraction gradient has been theorized to support a hierarchical proc-essing architecture of the frontal lobes, wherein abstract goals are actively translated into movements via a rostral-to-caudal flow of processing, and rostral areas of frontal cortex influence and organize processing in posterior areas [6–8]. The past decade has witnessed numerous tests of these basic hypotheses. Here, we revisit the evidence for a hierarchical organization of the frontal lobe and offer a revised framework. Though the evidence supports the hypothesis that the frontal lobes are organized hierarchically, there is likely not a unidimen-sional gradient of abstraction. Rather, the apex of the hierarchy may be more caudal than previously thought, with rostrolateral prefrontal cortex (RLPFC) supporting a distinct functional role. What Is Hierarchical Control? Much of the evidence informing the rostrocaudal organization of frontal cortex has come from studies examining hierarchical cognitive control. In some sense, all cognitive control is hierarchical in that it concerns how top–down contextual signals modulate pathways from stimulus to response. However, hierarchical cognitive control distinguishes those cases wherein actions must be controlled based on immediate contextual signals that are themselves Highlights It has been proposed that rostral fron-tal regions support more abstract cog-nitive control. Current evidence supports three dis-tinct functional networks supporting sensory–motor control, control based on a present context, and control based on an internal state (schematic control).},
	journal = {Trends in Cognitive Sciences},
	author = {Badre, David and Nee, Derek Evan},
	year = {2017},
	pmid = {29229206},
	pages = {1--19},
	file = {Attachment:/Users/tito/Zotero/storage/7GMTQQTK/Badre, Nee - 2017 - Frontal Cortex and the Hierarchical Control of Behavior.pdf:application/pdf},
}

@article{jaime_delta_2017,
	title = {Delta {Rhythm} {Orchestrates} the {Neural} {Activity} {Underlying} the {Resting} {State} {BOLD} {Signal} via {Phase} – amplitude {Coupling}},
	doi = {10.1093/cercor/bhx310},
	number = {November},
	journal = {Cerebral Cortex},
	author = {Jaime, Saul and Gu, Hong and Sadacca, Brian F and Stein, Elliot A and Cavazos, Jose E and Yang, Yihong and Lu, Hanbing},
	year = {2017},
	keywords = {bold, dopamine, spontaneous fl uctuation, striatum, vta},
	pages = {1--15},
	file = {Attachment:/Users/tito/Zotero/storage/49TQZ7UH/Jaime et al. - 2017 - Delta Rhythm Orchestrates the Neural Activity Underlying the Resting State BOLD Signal via Phase – amplitude Cou.pdf:application/pdf},
}

@article{langer_functional_2012,
	title = {Functional {Brain} {Network} {Efficiency} {Predicts} {Intelligence}},
	volume = {1406},
	doi = {10.1002/hbm.21297},
	author = {Langer, Nicolas and Pedroni, Andreas and Gianotti, Lorena R R and Knoch, Daria and Ja, Lutz},
	year = {2012},
	keywords = {eeg, intelligence, neuroscience, small-world network},
	pages = {1393--1406},
	file = {Attachment:/Users/tito/Zotero/storage/5U54MSDE/Langer et al. - 2012 - Functional Brain Network Efficiency Predicts Intelligence.pdf:application/pdf},
}

@article{hilger_intelligence_2017,
	title = {Intelligence is associated with the modular structure of intrinsic brain networks},
	issn = {2045-2322},
	url = {http://dx.doi.org/10.1038/s41598-017-15795-7},
	doi = {10.1038/s41598-017-15795-7},
	number = {November},
	journal = {Scientific Reports},
	author = {Hilger, Kirsten and Ekman, Matthias and Fiebach, Christian J and Basten, Ulrike},
	year = {2017},
	pages = {1--12},
	file = {Attachment:/Users/tito/Zotero/storage/M9JGFTNQ/Hilger et al. - 2017 - Intelligence is associated with the modular structure of intrinsic brain networks.pdf:application/pdf},
}

@article{cremers_relation_2017,
	title = {The relation between statistical power and inference in {fMRI}},
	journal = {PLoS ONE},
	author = {Cremers, Henk R and Wager, Tor D and Yarkoni, Tal},
	year = {2017},
	pages = {1--20},
	file = {Attachment:/Users/tito/Zotero/storage/ZKQZT2E3/Cremers, Wager, Yarkoni - 2017 - The relation between statistical power and inference in fMRI.pdf:application/pdf},
}

@article{vatansever_default_2017,
	title = {Default mode contributions to automated information processing},
	issn = {0027-8424},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1710521114},
	doi = {10.1073/pnas.1710521114},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Vatansever, Deniz and Menon, David K. and Stamatakis, Emmanuel A.},
	year = {2017},
	pmid = {29078345},
	pages = {201710521},
	file = {Attachment:/Users/tito/Zotero/storage/VWRXAUV8/Vatansever, Menon, Stamatakis - 2017 - Default mode contributions to automated information processing.pdf:application/pdf},
}

@article{wig_segregated_2017,
	title = {Segregated {Systems} of {Human} {Brain} {Networks}},
	volume = {xx},
	issn = {13646613},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661317301948},
	doi = {10.1016/j.tics.2017.09.006},
	journal = {Trends in Cognitive Sciences},
	author = {Wig, Gagan S.},
	year = {2017},
	pmid = {29100737},
	pages = {1--16},
	file = {Attachment:/Users/tito/Zotero/storage/9MEHHIGH/Wig - 2017 - Segregated Systems of Human Brain Networks.pdf:application/pdf},
}

@article{gosak_network_2017,
	title = {Network science of biological systems at different scales : {A} review},
	volume = {1},
	doi = {10.1016/j.plrev.2017.11.003},
	journal = {Physics of life reviews},
	author = {Gosak, Marko and Markoviˇ, Rene},
	year = {2017},
	keywords = {beta cells, biological systems, calcium signaling, complex networks, corresponding author at, faculty of medicine, institute of physiology, intercellular communication, multilayer networks, si-2000 maribor, slovenia, taborska 8, university of maribor},
	pages = {1--18},
	file = {Attachment:/Users/tito/Zotero/storage/EXU8ZVT6/Gosak, Markoviˇ - 2017 - Network science of biological systems at different scales A review.pdf:application/pdf},
}

@article{ozdemir_david_2017,
	title = {David {Bowie} and the {Art} of {Slow} {Innovation}: {A} {Fast}-{Second} {Winner} {Strategy} for {Biotechnology} and {Precision} {Medicine} {Global} {Development}},
	volume = {21},
	issn = {1557-8100},
	url = {http://online.liebertpub.com/doi/10.1089/omi.2017.0148},
	doi = {10.1089/omi.2017.0148},
	number = {11},
	journal = {OMICS: A Journal of Integrative Biology},
	author = {Özdemir, Vural and Patrinos, George P.},
	year = {2017},
	keywords = {been done, biomarkers and, david bowie, diagnostics, have never been tried, innovators don, precision medicine, slow innovation, t do things that, technology foresight, the fast-second winner, they do, things that have never},
	pages = {633--637},
}

@article{sussillo_generating_2009,
	title = {Generating {Coherent} {Patterns} of {Activity} from {Chaotic} {Neural} {Networks}},
	volume = {63},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2009.07.018},
	doi = {10.1016/j.neuron.2009.07.018},
	abstract = {Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated. © 2009 Elsevier Inc. All rights reserved.},
	number = {4},
	journal = {Neuron},
	author = {Sussillo, David and Abbott, L. F.},
	year = {2009},
	pmid = {19709635},
	keywords = {SYSNEURO},
	pages = {544--557},
	file = {Attachment:/Users/tito/Zotero/storage/IQCKWCSX/Sussillo, Abbott - 2009 - Generating Coherent Patterns of Activity from Chaotic Neural Networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/28MFE3BM/Sussillo, Abbott - 2009 - Generating Coherent Patterns of Activity from Chaotic Neural Networks.pdf:application/pdf},
}

@article{darshan_canonical_2017,
	title = {A canonical neural mechanism for behavioral variability},
	volume = {8},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms15415},
	doi = {10.1038/ncomms15415},
	abstract = {The ability to generate variable movements is essential for learning and adjusting complex behaviours. This variability has been linked to the temporal irregularity of neuronal activity in the central nervous system. However, how neuronal irregularity actually translates into behavioural variability is unclear. Here we combine modelling, electrophysiological and behavioural studies to address this issue. We demonstrate that a model circuit comprising topographically organized and strongly recurrent neural networks can autonomously generate irregular motor behaviours. Simultaneous recordings of neurons in singing finches reveal that neural correlations increase across the circuit driving song variability, in agreement with the model predictions. Analysing behavioural data, we find remarkable similarities in the babbling statistics of 5-6-month-old human infants and juveniles from three songbird species and show that our model naturally accounts for these 'universal' statistics.},
	number = {May},
	journal = {Nature Communications},
	author = {Darshan, Ran and Wood, William E. and Peters, Susan and Leblois, Arthur and Hansel, David},
	year = {2017},
	pmid = {28530225},
	pages = {15415},
	file = {Attachment:/Users/tito/Zotero/storage/PGXX3GPY/Darshan et al. - 2017 - A canonical neural mechanism for behavioral variability.pdf:application/pdf},
}

@article{lea-carnall_cortical_2016,
	title = {Cortical {Resonance} {Frequencies} {Emerge} from {Network} {Size} and {Connectivity}},
	volume = {12},
	issn = {15537358},
	doi = {10.1371/journal.pcbi.1004740},
	abstract = {Neural oscillations occur within a wide frequency range with different brain regions exhibiting resonance-like characteristics at specific points in the spectrum. At the microscopic scale, single neurons possess intrinsic oscillatory properties, such that is not yet known whether cortical resonance is consequential to neural oscillations or an emergent property of the networks that interconnect them. Using a network model of loosely-coupled Wilson-Cowan oscillators to simulate a patch of cortical sheet, we demonstrate that the size of the activated network is inversely related to its resonance frequency. Further analysis of the parameter space indicated that the number of excitatory and inhibitory connections, as well as the average transmission delay between units, determined the resonance frequency. The model predicted that if an activated network within the visual cortex increased in size, the resonance frequency of the network would decrease. We tested this prediction experimentally using the steady-state visual evoked potential where we stimulated the visual cortex with different size stimuli at a range of driving frequencies. We demonstrate that the frequency corresponding to peak steady-state response inversely correlated with the size of the network. We conclude that although individual neurons possess resonance properties, oscillatory activity at the macroscopic level is strongly influenced by network interactions, and that the steady-state response can be used to investigate functional networks.},
	number = {2},
	journal = {PLoS Computational Biology},
	author = {Lea-Carnall, Caroline A. and Montemurro, Marcelo A. and Trujillo-Barreto, Nelson J. and Parkes, Laura M. and El-Deredy, Wael},
	year = {2016},
	pmid = {26914905},
	pages = {1--19},
	file = {Attachment:/Users/tito/Zotero/storage/RHKHNVJA/Lea-Carnall et al. - 2016 - Cortical Resonance Frequencies Emerge from Network Size and Connectivity.PDF:application/pdf},
}

@article{vreeswijk_chaos_1996,
	title = {Chaos in {Neuronal} {Networks} with {Balanced} {Excitatory} and {Inhibitory} {Activity}},
	volume = {274},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.274.5293.1724},
	doi = {10.1126/science.274.5293.1724},
	abstract = {Neurons in the cortex of behaving animals show temporally irregular spiking patterns. The origin of this irregularity and its implications for neural processing are unknown. The hypothesis that the temporal variability in the firing of a neuron results from an approximate balance between its excitatory and inhibitory inputs was investigated theoretically. Such a balance emerges naturally in large networks of excitatory and inhibitory neuronal populations that are sparsely connected by relatively strong synapses. The resulting state is characterized by strongly chaotic dynamics, even when the external inputs to the network are constant in time. Such a network exhibits a linear response, despite the highly nonlinear dynamics of single neurons, and reacts to changing external stimuli on time scales much smaller than the integration time constant of a single neuron.},
	number = {5293},
	journal = {Science},
	author = {Vreeswijk, C. v. and Sompolinsky, H.},
	year = {1996},
	pmid = {8939866},
	pages = {1724--1726},
	file = {Attachment:/Users/tito/Zotero/storage/SRPQN583/Vreeswijk, Sompolinsky - 1996 - Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity.pdf:application/pdf},
}

@article{renart_cortical_2010,
	title = {in {Cortical} {Circuits}},
	volume = {327},
	doi = {10.1126/science.1179850.The},
	number = {January},
	journal = {Science},
	author = {Renart, Alfonso and Rocha, Jaime De and Bartho, Peter and Hollender, Liad and Parga, Néstor and Reyes, Alex and Harris, Kenneth D},
	year = {2010},
	pages = {587--591},
	file = {Attachment:/Users/tito/Zotero/storage/KKFGH8BL/Renart et al. - 2010 - in Cortical Circuits.pdf:application/pdf},
}

@article{winder_weak_2017,
	title = {Weak correlations between hemodynamic signals and ongoing neural activity during the resting state},
	issn = {1097-6256},
	url = {http://www.nature.com/articles/s41593-017-0007-y},
	doi = {10.1038/s41593-017-0007-y},
	journal = {Nature Neuroscience},
	author = {Winder, Aaron T. and Echagarruga, Christina and Zhang, Qingguang and Drew, Patrick J.},
	year = {2017},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/K45RY3Q9/Winder et al. - 2017 - Weak correlations between hemodynamic signals and ongoing neural activity during the resting state.pdf:application/pdf},
}

@article{mateo_entrainment_2017,
	title = {Entrainment of {Arteriole} {Vasomotor} {Fluctuations} by {Neural} {Activity} {Is} a {Basis} of {Blood}-{Oxygenation}-{Level}-{Dependent} “{Resting}-{State}” {Connectivity}},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627317309807},
	doi = {10.1016/j.neuron.2017.10.012},
	journal = {Neuron},
	author = {Mateo, Celine and Knutsen, Per M. and Tsai, Philbert S. and Shih, Andy Y. and Kleinfeld, David},
	year = {2017},
	pmid = {29107517},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/FIXG4CUK/Mateo et al. - 2017 - Entrainment of Arteriole Vasomotor Fluctuations by Neural Activity Is a Basis of Blood-Oxygenation-Level-Depen.pdf:application/pdf},
}

@article{ujfalussy_space_2009,
	title = {Space and {Time} in the},
	volume = {485},
	number = {October},
	journal = {History},
	author = {UJFALUSSY, BALÁZS and Dissertation, Doctoral},
	year = {2009},
	pages = {482--485},
}

@article{tschentscher_fluid_2017,
	title = {Fluid {Intelligence} {Predicts} {Novel} {Rule} {Implementation} in a {Distributed} {Frontoparietal} {Control} {Network}},
	volume = {37},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2478-16.2017},
	doi = {10.1523/JNEUROSCI.2478-16.2017},
	abstract = {Fluid intelligence has been associated with a distributed cognitive control or multiple-demand (MD) network, comprising regions of lateral frontal, insular, dorsomedial frontal, and parietal cortex. Human fluid intelligence is also intimately linked to task complexity, and the process of solving complex problems in a sequence of simpler, more focused parts. Here, a complex target detection task included multiple independent rules, applied one at a time in successive task epochs. Although only one rule was applied at a time, increasing task complexity (i.e., the number of rules) impaired performance in participants of lower fluid intelligence. Accompanying this loss of performance was reduced response to rule-critical events across the distributed MD network. The results link fluid intelligence and MD function to a process of attentional focus on the successive parts of complex behavior.SIGNIFICANCE STATEMENT Fluid intelligence is intimately linked to the ability to structure complex problems in a sequence of simpler, more focused parts. We examine the basis for this link in the functions of a distributed frontoparietal or multiple-demand (MD) network. With increased task complexity, participants of lower fluid intelligence showed reduced responses to task-critical events. Reduced responses in the MD system were accompanied by impaired behavioral performance. Low fluid intelligence is linked to poor foregrounding of task-critical information across a distributed MD system.},
	number = {18},
	journal = {The Journal of Neuroscience},
	author = {Tschentscher, Nadja and Mitchell, Daniel and Duncan, John},
	year = {2017},
	pmid = {28408412},
	keywords = {fmri, significance statement, distributed frontoparietal or multiple-demand, executive functions, fluid intelligence, fluid intelligence is intimately, for this link in, frontoparietal control system, goal-directed behavior, in a sequence of, linked to the ability, md, more focused parts, network, simpler, the functions of a, to structure complex problems, we examine the basis, with},
	pages = {4841--4847},
	file = {Attachment:/Users/tito/Zotero/storage/MV8T8I66/Tschentscher, Mitchell, Duncan - 2017 - Fluid Intelligence Predicts Novel Rule Implementation in a Distributed Frontoparietal Control Ne.pdf:application/pdf},
}

@article{buzsaki_space_2017,
	title = {Space and time in the brain},
	volume = {358},
	url = {http://science.sciencemag.org/content/358/6362/482.abstract},
	abstract = {Nothing is more intuitive, yet more complex, than the concepts of space and time. In contrast to spacetime in physics, space and time in neuroscience remain separate coordinates to which we attach our observations. Investigators of navigation and memory relate neuronal activity to position, distance, time point, and duration and compare these parameters to units of measuring instruments. Although spatial-temporal sequences of brain activity often correlate with distance and duration measures, these correlations may not correspond to neuronal representations of space or time. Neither instruments nor brains sense space or time. Neuronal activity can be described as a succession of events without resorting to the concepts of space or time. Instead of searching for brain representations of our preconceived ideas, we suggest investigating how brain mechanisms give rise to inferential, model-building explanations.},
	number = {6362},
	journal = {Science},
	author = {Buzsáki, György and Llinás, Rodolfo},
	month = oct,
	year = {2017},
	pages = {482 LP -- 485},
}

@article{bertolero_diverse_2017,
	title = {The diverse club},
	volume = {8},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-017-01189-w},
	doi = {10.1038/s41467-017-01189-w},
	number = {1},
	journal = {Nature Communications},
	author = {Bertolero, M. A. and Yeo, B. T. T. and D'Esposito, M.},
	year = {2017},
	pages = {1277},
}

@article{hopfield_physics_1994,
	title = {Physics, {Computation}, and {Why} {Biology} {Looks} so {Different}},
	volume = {171},
	issn = {0022-5193},
	url = {http://www.sciencedirect.com/science/article/pii/S0022519384712112},
	doi = {https://doi.org/10.1006/jtbi.1994.1211},
	number = {1},
	journal = {Journal of Theoretical Biology},
	author = {Hopfield, J J},
	year = {1994},
	pages = {53--60},
	file = {Attachment:/Users/tito/Zotero/storage/TFKGBTMU/Hopfield - 1994 - Physics, Computation, and Why Biology Looks so Different.pdf:application/pdf},
}

@article{rosenbaum_spatial_2016,
	title = {The spatial structure of correlated neuronal variability},
	volume = {20},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.4433},
	doi = {10.1038/nn.4433},
	abstract = {Shared neural variability is ubiquitous in cortical populations. While this variability is presumed to arise from overlapping synaptic input, its precise relationship to local circuit architecture remains unclear. We combine computational models and in vivo recordings to study the relationship between the spatial structure of connectivity and correlated variability in neural circuits. Extending the theory of networks with balanced excitation and inhibition, we find that spatially localized lateral projections promote weakly correlated spiking, but broader lateral projections produce a distinctive spatial correlation structure: nearby neuron pairs are positively correlated, pairs at intermediate distances are negatively correlated and distant pairs are weakly correlated. This non-monotonic dependence of correlation on distance is revealed in a new analysis of recordings from superficial layers of macaque primary visual cortex. Our findings show that incorporating distance-dependent connectivity improves the extent to which balanced network theory can explain correlated neural variability.},
	number = {1},
	journal = {Nature Neuroscience},
	author = {Rosenbaum, Robert and Smith, Matthew A and Kohn, Adam and Rubin, Jonathan E and Doiron, Brent},
	year = {2016},
	pmid = {27798630},
	pages = {107--114},
	file = {Attachment:/Users/tito/Zotero/storage/348HK4YY/Rosenbaum et al. - 2016 - The spatial structure of correlated neuronal variability.pdf:application/pdf},
}

@article{richter_jackknife_2015,
	title = {A jackknife approach to quantifying single-trial correlation between covariance-based metrics undefined on a single-trial basis},
	volume = {114},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2015.04.040},
	doi = {10.1016/j.neuroimage.2015.04.040},
	abstract = {The quantification of covariance between neuronal activities (functional connectivity) requires the observation of correlated changes and therefore multiple observations. The strength of such neuronal correlations may itself undergo moment-by-moment fluctuations, which might e.g. lead to fluctuations in single-trial metrics such as reaction time (RT), or may co-fluctuate with the correlation betwe'en activity in other brain areas. Yet, quantifying the relation between moment-by-moment co-fluctuations in neuronal correlations is precluded by the fact that neuronal correlations are not defined per single observation. The proposed solution quantifies this relation by first calculating neuronal correlations for all leave-one-out subsamples (i.e. the jackknife replications of all observations) and then correlating these values. Because the correlation is calculated between jackknife replications, we address this approach as jackknife correlation (JC). First, we demonstrate the equivalence of JC to conventional correlation for simulated paired data that are defined per observation and therefore allow the calculation of conventional correlation. While the JC recovers the conventional correlation precisely, alternative approaches, like sorting-and-binning, result in detrimental effects of the analysis parameters. We then explore the case of relating two spectral correlation metrics, like coherence, that require multiple observation epochs, where the only viable alternative analysis approaches are based on some form of epoch subdivision, which results in reduced spectral resolution and poor spectral estimators. We show that JC outperforms these approaches, particularly for short epoch lengths, without sacrificing any spectral resolution. Finally, we note that the JC can be applied to relate fluctuations in any smooth metric that is not defined on single observations.},
	journal = {NeuroImage},
	author = {Richter, Craig G. and Thompson, William H. and Bosman, Conrado A. and Fries, Pascal},
	year = {2015},
	pmid = {25917516},
	keywords = {Functional connectivity, Coherence, Granger causality, Jackknife, Single-trial correlation, Spectral analysis},
	pages = {57--70},
	file = {Attachment:/Users/tito/Zotero/storage/A8VPVCYF/Richter et al. - 2015 - A jackknife approach to quantifying single-trial correlation between covariance-based metrics undefined on a sin.pdf:application/pdf},
}

@article{richter_top-down_2017,
	title = {Top-{Down} {Beta} {Enhances} {Bottom}-{Up} {Gamma}},
	volume = {37},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3771-16.2017},
	doi = {10.1523/JNEUROSCI.3771-16.2017},
	abstract = {Several recent studies have demonstrated that the bottom-up signaling of a visual stimulus is subserved by interareal gamma-band synchronization, whereas top-down influences are mediated by alpha-beta band synchronization. These processes may implement top-down control of stimulus processing if top-down and bottom-up mediating rhythms are coupled via cross-frequency interaction. To test this possibility, we investigated Granger-causal influences among awake male macaque primary visual area V1, higher visual area V4 and parietal control area 7a during attentional task performance. Top-down 7a-to-V1 beta-band influences enhanced visually driven V1-to-V4 gamma-band influences. This enhancement was spatially specific and largest when beta-band activity preceded gamma-band activity by ∼0.1 s, suggesting a causal effect of top-down processes on bottom-up processes. We propose that this cross-frequency interaction mechanistically subserves the attentional control of stimulus selection.SIGNIFICANCE STATEMENTContemporary research indicates that the alpha-beta frequency band underlies top-down control, while the gamma-band mediates bottom-up stimulus processing. This arrangement inspires an attractive hypothesis, which posits that top-down beta-band influences directly modulate bottom-up gamma band influences via cross-frequency interaction. We evaluate this hypothesis determining that beta-band top-down influences from parietal area 7a to visual area V1 are correlated with bottom-up gamma frequency oscillations from V1 to area V4, in a spatially specific manner, and that this correlation is maximal when top-down activity precedes bottom-up activity. These results show that for top-down processes such as spatial attention, elevated top-down beta-band influences directly enhance feedforward stimulus induced gamma-band processing, leading to enhancement of the selected stimulus.},
	number = {28},
	journal = {The Journal of Neuroscience},
	author = {Richter, Craig G. and Thompson, William H. and Bosman, Conrado A. and Fries, Pascal},
	year = {2017},
	pmid = {28592697},
	keywords = {oscillation, significance statement, attention, attractive hypothesis, beta, beta-, contemporary research indicates that, gamma, granger causality, mediates bottom-up stimulus processing, synchronization, the alpha-beta frequency band, this arrangement inspires an, underlies top-down control, whereas the gamma-band, which posits that top-down},
	pages = {6698--6711},
	file = {Attachment:/Users/tito/Zotero/storage/T4K7Z5XT/Richter et al. - 2017 - Top-Down Beta Enhances Bottom-Up Gamma(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/3P3WSFQY/Richter et al. - 2017 - Top-Down Beta Enhances Bottom-Up Gamma.pdf:application/pdf},
}

@article{barreiro_symmetries_2016,
	title = {Symmetries constrain dynamics in a family of balanced neural networks},
	issn = {2190-8567},
	url = {http://arxiv.org/abs/1602.05092},
	doi = {10.1186/s13408-017-0052-6},
	abstract = {We examine a family of random firing-rate neural networks in which we enforce the neurobiological constraint of Dale's Law — each neuron makes either excitatory or inhibitory connections onto its post-synaptic targets. We find that this constrained system may be described as a perturbation from a system with non-trivial symmetries. We analyze the symmetric system using the tools of equivariant bifurcation theory, and demonstrate that the symmetry-implied structures remain evident in the perturbed system. In comparison, spectral characteristics of the network coupling matrix are relatively uninformative about the behavior of the constrained system.},
	journal = {J. Math. Neurosc.},
	author = {Barreiro, Andrea K. and Kutz, J. Nathan and Shlizerman, Eli},
	year = {2016},
	keywords = {Bifurcations, Equivariant, Random network, Recurrent networks, Symmetry, bifurcations, equivariant, random network, recurrent networks},
	pages = {1--28},
	file = {Attachment:/Users/tito/Zotero/storage/QHZL2BUY/Barreiro, Kutz, Shlizerman - 2016 - Symmetries constrain dynamics in a family of balanced neural networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/75PG35D8/Barreiro, Kutz, Shlizerman - 2016 - Symmetries constrain dynamics in a family of balanced neural networks.pdf:application/pdf},
}

@article{schirner_bridging_2016,
	title = {Bridging multiple scales in the human brain using computational modelling},
	url = {http://biorxiv.org/content/early/2016/11/03/085548.abstract},
	abstract = {Brain dynamics span multiple spatial and temporal scales, from fast spiking neurons to slow fluctuations over distributed areas. No single experimental method links data across scales. Here, we bridge this gap using The Virtual Brain connectome-based modelling platform to integrate multimodal data with biophysical models and support neurophysiological inference. Simulated cell populations were linked with subject-specific white-matter connectivity estimates and driven by electroencephalography-derived electric source activity. The models were fit to subject-specific resting-state functional magnetic resonance imaging data, and overfitting was excluded using 5-fold cross-validation. Further evaluation of the models show how balancing excitation with feedback inhibition generates an inverse relationship between α-rhythms and population firing on a faster time scale and resting-state network oscillations on a slower time scale. Lastly, large-scale interactions in the model lead to the emergence of scale-free power-law spectra. Our novel findings underscore the integrative role for computational modelling to complement empirical studies.},
	journal = {bioRxiv},
	author = {Schirner, Michael and McIntosh, Anthony Randal and Jirsa, Viktor and Deco, Gustavo and Ritter, Petra},
	month = jan,
	year = {2016},
	keywords = {functional connectivity, eeg, alpha rhythm, computational modelling, connectome, excitation-inhibition balance, feedback inhibition, functional mri, gating by inhibition, inhibition, mean-field model, pulsed, resting-state networks, structural connectivity},
	file = {Attachment:/Users/tito/Zotero/storage/WE49AGU6/Schirner et al. - 2016 - Bridging multiple scales in the human brain using computational modelling.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/JTAS56RN/Schirner et al. - 2016 - Bridging multiple scales in the human brain using computational modelling.pdf:application/pdf},
}

@article{friston_free-energy_2010,
	title = {The free-energy principle: a unified brain theory?},
	volume = {11},
	url = {http://dx.doi.org/10.1038/nrn2787 http://10.0.4.14/nrn2787 https://www.nature.com/articles/nrn2787#supplementary-information},
	journal = {Nature Reviews Neuroscience},
	author = {Friston, Karl},
	month = jan,
	year = {2010},
	pages = {127},
	file = {Attachment:/Users/tito/Zotero/storage/H8AUYF2U/Friston - 2010 - The free-energy principle a unified brain theory.pdf:application/pdf},
}

@article{maloney_bayesian_2009,
	title = {Bayesian decision theory as a model of human visual perception: {Testing} {Bayesian} transfer},
	volume = {26},
	issn = {0952-5238},
	url = {https://www.cambridge.org/core/article/bayesian-decision-theory-as-a-model-of-human-visual-perception-testing-bayesian-transfer/468DEB6A3ECC645B8942C0583BBD8F6E},
	doi = {DOI: 10.1017/S0952523808080905},
	abstract = {AbstractBayesian decision theory (BDT) is a mathematical framework that allows the experimenter to model ideal performance in a wide variety of visuomotor tasks. The experimenter can use BDT to compute benchmarks for ideal performance in such tasks and compare human performance to ideal. Recently, researchers have asked whether BDT can also be treated as a process model of visuomotor processing. It is unclear what sorts of experiments are appropriate to testing such claims and whether such claims are even meaningful. Any such claim presupposes that observers' performance is close to ideal, and typical experimental tests involve comparison of human performance to ideal. We argue that this experimental criterion, while necessary, is weak. We illustrate how to achieve near-optimal performance in combining perceptual cues with a process model bearing little resemblance to BDT. We then propose experimental criteria termed transfer criteria that constitute more powerful tests of BDT as a model of perception and action. We describe how recent work in motor control can be viewed as tests of transfer properties of BDT. The transfer properties discussed here comprise the beginning of an operationalization (Bridgman, ) of what it means to claim that perception is or is not Bayesian inference (Knill \& Richards, ). They are particularly relevant to research concerning natural scenes since they assess the ability of the organism to rapidly adapt to novel tasks in familiar environments or carry out familiar tasks in novel environments without learning.},
	number = {1},
	journal = {Visual Neuroscience},
	author = {Maloney, Laurence T and Mamassian, Pascal},
	year = {2009},
	keywords = {Bayesian decision theory, Bayesian transfer, Loss function, Perception, Statistical models},
	pages = {147--155},
	file = {Attachment:/Users/tito/Zotero/storage/P5DKIPG3/Maloney, Mamassian - 2009 - Bayesian decision theory as a model of human visual perception Testing Bayesian transfer.pdf:application/pdf},
}

@article{wen_transferring_2017,
	title = {Transferring and {Generalizing} {Deep}-{Learning}-based {Neural} {Encoding} {Models} across {Subjects}},
	url = {http://biorxiv.org/content/early/2017/08/01/171017.abstract},
	abstract = {Recent studies have shown the value of using deep learning models for mapping and characterizing how the brain represents and organizes information for natural vision. However, modeling the relationship between deep learning models and the brain (or encoding models), requires measuring cortical responses to large and diverse sets of natural visual stimuli from single subjects. This requirement limits prior studies to few subjects, making it difficult to generalize findings across subjects or for a population. In this study, we developed new methods to transfer and generalize encoding models across subjects. To train encoding models specific to a subject, the models trained for other subjects were used as the prior models and were refined efficiently using Bayesian inference with a limited amount of data from the specific subject. To train encoding models for a population, the models were progressively trained and updated with incremental data from different subjects. For the proof of principle, we applied these methods to functional magnetic resonance imaging (fMRI) data from three subjects watching tens of hours of naturalistic videos, while deep residual neural network driven by image recognition was used to model the visual cortical processing. Results demonstrate that the methods developed herein provide an efficient and effective strategy to establish subject-specific or population-wide predictive models of cortical representations of high-dimensional and hierarchical visual features.},
	journal = {bioRxiv},
	author = {Wen, Haiguang and Shi, Junxing and Chen, Wei and Liu, Zhongming},
	month = jan,
	year = {2017},
}

@article{betzel_generative_2017,
	title = {Generative models for network neuroscience: prospects and promise},
	volume = {14},
	url = {http://rsif.royalsocietypublishing.org/content/14/136/20170623.abstract},
	abstract = {Network neuroscience is the emerging discipline concerned with investigating the complex patterns of interconnections found in neural systems, and identifying principles with which to understand them. Within this discipline, one particularly powerful approach is network generative modelling, in which wiring rules are algorithmically implemented to produce synthetic network architectures with the same properties as observed in empirical network data. Successful models can highlight the principles by which a network is organized and potentially uncover the mechanisms by which it grows and develops. Here, we review the prospects and promise of generative models for network neuroscience. We begin with a primer on network generative models, with a discussion of compressibility and predictability, and utility in intuiting mechanisms, followed by a short history on their use in network science, broadly. We then discuss generative models in practice and application, paying particular attention to the critical need for cross-validation. Next, we review generative models of biological neural networks, both at the cellular and large-scale level, and across a variety of species including Caenorhabditis elegans, Drosophila, mouse, rat, cat, macaque and human. We offer a careful treatment of a few relevant distinctions, including differences between generative models and null models, sufficiency and redundancy, inferring and claiming mechanism, and functional and structural connectivity. We close with a discussion of future directions, outlining exciting frontiers both in empirical data collection efforts as well as in method and theory development that, together, further the utility of the generative network modelling approach for network neuroscience.},
	number = {136},
	journal = {Journal of The Royal Society Interface},
	author = {Betzel, Richard F and Bassett, Danielle S},
	month = nov,
	year = {2017},
	keywords = {bioengineering, systems biology},
	file = {Attachment:/Users/tito/Zotero/storage/JYGV5SGQ/Betzel, Bassett - 2017 - Generative models for network neuroscience prospects and promise.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/HYNMNL6D/Betzel, Bassett - 2017 - Generative models for network neuroscience prospects and promise.pdf:application/pdf},
}

@article{loonis_article_nodate,
	title = {Article {A} {Meta}-{Analysis} {Suggests} {Different} {Neural} {Correlates} for {Implicit} and {Explicit} {Learning} {Article} {A} {Meta}-{Analysis} {Suggests} {Different} {Neural} {Correlates}},
	volume = {96},
	issn = {0896-6273},
	url = {https://doi.org/10.1016/j.neuron.2017.09.032},
	doi = {10.1016/j.neuron.2017.09.032},
	number = {2},
	journal = {Neuron},
	author = {Loonis, Roman F and Brincat, Scott L and Antzoulatos, Evan G and Miller, Earl K and Loonis, Roman F and Brincat, Scott L and Antzoulatos, Evan G and Miller, Earl K},
	pmid = {29024670},
	pages = {521--534.e7},
	file = {Attachment:/Users/tito/Zotero/storage/7ZRL2LJJ/Loonis et al. - Unknown - Article A Meta-Analysis Suggests Different Neural Correlates for Implicit and Explicit Learning Article A Meta.pdf:application/pdf},
}

@article{vazquez_stochastic_2017,
	title = {Stochastic resonance and optimal information transfer at criticality on a network model of the human connectome},
	issn = {2045-2322},
	doi = {10.1038/s41598-017-13400-5},
	number = {April},
	author = {Vázquez, Bertha and Avena-koenigsberger, Andrea and Bertha, V},
	year = {2017},
	pages = {1--20},
}

@article{cohen_behavioral_2017,
	title = {The behavioral and cognitive relevance of time-varying, dynamic changes in functional connectivity},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S105381191730784X},
	doi = {10.1016/j.neuroimage.2017.09.036},
	number = {April},
	journal = {NeuroImage},
	author = {Cohen, Jessica R.},
	year = {2017},
	keywords = {dynamic functional connectivity},
	pages = {1--11},
	file = {Attachment:/Users/tito/Zotero/storage/2PLDS3JJ/Cohen - 2017 - The behavioral and cognitive relevance of time-varying, dynamic changes in functional connectivity.pdf:application/pdf},
}

@article{varoquaux_assessing_2017,
	title = {Assessing and tuning brain decoders: {Cross}-validation, caveats, and guidelines},
	volume = {145},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2016.10.038},
	doi = {10.1016/j.neuroimage.2016.10.038},
	abstract = {Decoding, i.e. prediction from brain images or signals, calls for empirical evaluation of its predictive power. Such evaluation is achieved via cross-validation, a method also used to tune decoders' hyper-parameters. This paper is a review on cross-validation procedures for decoding in neuroimaging. It includes a didactic overview of the relevant theoretical considerations. Practical aspects are highlighted with an extensive empirical study of the common decoders in within- and across-subject predictions, on multiple datasets –anatomical and functional MRI and MEG– and simulations. Theory and experiments outline that the popular “leave-one-out” strategy leads to unstable and biased estimates, and a repeated random splits method should be preferred. Experiments outline the large error bars of cross-validation in neuroimaging settings: typical confidence intervals of 10\%. Nested cross-validation can tune decoders' parameters while avoiding circularity bias. However we find that it can be favorable to use sane defaults, in particular for non-sparse decoders.},
	number = {October 2016},
	journal = {NeuroImage},
	author = {Varoquaux, Gaël and Raamana, Pradeep Reddy and Engemann, Denis A. and Hoyos-Idrobo, Andrés and Schwartz, Yannick and Thirion, Bertrand},
	year = {2017},
	pmid = {27989847},
	keywords = {FMRI, Decoding, Bagging, Cross-validation, Model selection, MVPA, Sparse},
	pages = {166--179},
	file = {Attachment:/Users/tito/Zotero/storage/KBALF6QQ/Varoquaux et al. - 2017 - Assessing and tuning brain decoders Cross-validation, caveats, and guidelines.pdf:application/pdf},
}

@article{lindsay_hebbian_2017,
	title = {Hebbian {Learning} in a {Random} {Network} {Captures} {Selectivity} {Properties} of {Prefrontal} {Cortex}},
	issn = {0270-6474},
	url = {http://dx.doi.org/10.1101/133025%5Cnhttp://biorxiv.org/content/early/2017/05/02/133025},
	doi = {10.1101/133025},
	abstract = {Complex cognitive behaviors, such as context-switching and rule-following, are thought to be supported by prefrontal cortex (PFC). Neural activity in PFC must thus be specialized to specific tasks while retaining flexibility. Nonlinear 'mixed' selectivity is an important neurophysiological trait for enabling complex and context-dependent behaviors. Here we investigate (1) the extent to which PFC exhibits computationally-relevant properties such as mixed selectivity and (2) how such properties could arise via circuit mechanisms. We show that PFC cells recorded during a complex task show a moderate level of specialization and structure that is not replicated by a model wherein cells receive random feedforward inputs. While random connectivity can be effective at generating mixed selectivity, the data shows significantly more mixed selectivity than predicted by a model with otherwise matched parameters. A simple Hebbian learning rule applied to the random connectivity, however, increases mixed selectivity and allows the model to match the data more accurately. To explain how learning achieves this, we provide analysis along with a clear geometric interpretation of the impact of learning on selectivity. After learning, the model also matches the data on measures of noise, response density, clustering, and the distribution of selectivities. Of two styles of Hebbian learning tested, the simpler and more biologically plausible option better matches the data. These modeling results give intuition about how neural properties important for cognition can arise in a circuit and make clear experimental predictions regarding how various measures of selectivity would evolve during animal training. Significance Statement: Prefrontal cortex (PFC) is a brain region believed to support the ability of animals to engage in complex behavior. How neurons in this area respond to stimuli—and in particular, to combinations of stimuli (" mixed selectivity ")—is a topic of interest. Despite the fact that models with random feedfor-ward connectivity are capable of creating computationally-relevant mixed selectivity, such a model does not match the levels of mixed selectivity seen in the data analyzed in this study. Adding simple Hebbian learning to the model increases mixed selectivity to the correct level and makes the model match the data on several other relevant mea-sures. This study thus offers predictions on how mixed selectivity and other properties evolve with training.},
	journal = {bioRxiv},
	author = {Lindsay, Grace W and Rigotti, Mattia and Warden, Melissa R. and Miller, Earl K and Fusi, Stefano},
	year = {2017},
	pmid = {28986463},
	file = {Attachment:/Users/tito/Zotero/storage/5BSCZQJB/Lindsay et al. - 2017 - Hebbian Learning in a Random Network Captures Selectivity Properties of Prefrontal Cortex.pdf:application/pdf},
}

@article{carhart-harris_psilocybin_2017,
	title = {Psilocybin for treatment-resistant depression: {fMRI}-measured brain mechanisms},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-13282-7},
	doi = {10.1038/s41598-017-13282-7},
	number = {1},
	journal = {Scientific Reports},
	author = {Carhart-Harris, Robin L and Roseman, Leor and Bolstridge, Mark and Demetriou, Lysia and Pannekoek, J Nienke and Wall, Matthew B and Tanner, Mark and Kaelen, Mendel and McGonigle, John and Murphy, Kevin and Leech, Robert and Curran, H Valerie and Nutt, David J},
	year = {2017},
	pages = {13187},
	file = {Attachment:/Users/tito/Zotero/storage/2IVB8DTI/Carhart-Harris et al. - 2017 - Psilocybin for treatment-resistant depression fMRI-measured brain mechanisms.pdf:application/pdf},
}

@article{shen_using_2017,
	title = {Using connectome-based predictive modeling to predict individual behavior from brain connectivity},
	volume = {12},
	issn = {1754-2189},
	url = {http://www.nature.com/doifinder/10.1038/nprot.2016.178},
	doi = {10.1038/nprot.2016.178},
	abstract = {Neuroimaging is a fast-developing research area in which anatomical and functional images of human brains are collected using techniques such as functional magnetic resonance imaging (fMRI), diffusion tensor imaging (DTI), and electroencephalography (EEG). Technical advances and large-scale data sets have allowed for the development of models capable of predicting individual differences in traits and behavior using brain connectivity measures derived from neuroimaging data. Here, we present connectome-based predictive modeling (CPM), a data-driven protocol for developing predictive models of brain-behavior relationships from connectivity data using cross-validation. This protocol includes the following steps: (i) feature selection, (ii) feature summarization, (iii) model building, and (iv) assessment of prediction significance. We also include suggestions for visualizing the most predictive features (i.e., brain connections). The final result should be a generalizable model that takes brain connectivity data as input and generates predictions of behavioral measures in novel subjects, accounting for a considerable amount of the variance in these measures. It has been demonstrated that the CPM protocol performs as well as or better than many of the existing approaches in brain-behavior prediction. As CPM focuses on linear modeling and a purely data-driven approach, neuroscientists with limited or no experience in machine learning or optimization will find it easy to implement these protocols. Depending on the volume of data to be processed, the protocol can take 10-100 min for model building, 1-48 h for permutation testing, and 10-20 min for visualization of results.},
	number = {3},
	journal = {Nature Protocols},
	author = {Shen, Xilin and Finn, Emily S and Scheinost, Dustin and Rosenberg, Monica D and Chun, Marvin M and Papademetris, Xenophon and Constable, R Todd},
	year = {2017},
	pmid = {28182017},
	pages = {506--518},
	file = {Attachment:/Users/tito/Zotero/storage/5JKZ9RBQ/Shen et al. - 2017 - Using connectome-based predictive modeling to predict individual behavior from brain connectivity.pdf:application/pdf},
}

@article{bastos_communication_2015,
	title = {Communication through coherence with inter-areal delays},
	volume = {31},
	issn = {18736882},
	url = {http://dx.doi.org/10.1016/j.conb.2014.11.001},
	doi = {10.1016/j.conb.2014.11.001},
	abstract = {The communication-through-coherence (CTC) hypothesis proposes that anatomical connections are dynamically rendered effective or ineffective through the presence or absence of rhythmic synchronization, in particular in the gamma and beta bands. The original CTC statement proposed that uni-directional communication is due to rhythmic entrainment with an inter-areal delay and a resulting non-zero phase relation, whereas bi-directional communication is due to zero-phase synchronization. Recent studies found that inter-areal gamma-band synchronization entails a non-zero phase lag. We therefore modify the CTC hypothesis and propose that bi-directional cortical communication is realized separately for the two directions by uni-directional CTC mechanisms entailing delays in both directions. We review evidence suggesting that inter-areal influences in the feedforward and feedback directions are segregated both anatomically and spectrally.},
	journal = {Current Opinion in Neurobiology},
	author = {Bastos, Andre M. and Vezoli, Julien and Fries, Pascal},
	year = {2015},
	pmid = {25460074},
	pages = {173--180},
	file = {Attachment:/Users/tito/Zotero/storage/RTQZGBPI/Bastos, Vezoli, Fries - 2015 - Communication through coherence with inter-areal delays.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/UVJAYIAI/Bastos, Vezoli, Fries - 2015 - Communication through coherence with inter-areal delays.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TS84HEFY/Bastos, Vezoli, Fries - 2015 - Communication through coherence with inter-areal delays.pdf:application/pdf},
}

@article{freyer_canonical_2012,
	title = {A {Canonical} {Model} of {Multistability} and {Scale}-{Invariance} in {Biological} {Systems}},
	volume = {8},
	issn = {1553734X},
	doi = {10.1371/journal.pcbi.1002634},
	abstract = {Multistability and scale-invariant fluctuations occur in a wide variety of biological organisms from bacteria to humans as well as financial, chemical and complex physical systems. Multistability refers to noise driven switches between multiple weakly stable states. Scale-invariant fluctuations arise when there is an approximately constant ratio between the mean and standard deviation of a system's fluctuations. Both are an important property of human perception, movement, decision making and computation and they occur together in the human alpha rhythm, imparting it with complex dynamical behavior. Here, we elucidate their fundamental dynamical mechanisms in a canonical model of nonlinear bifurcations under stochastic fluctuations. We find that the co-occurrence of multistability and scale-invariant fluctuations mandates two important dynamical properties: Multistability arises in the presence of a subcritical Hopf bifurcation, which generates co-existing attractors, whilst the introduction of multiplicative (state-dependent) noise ensures that as the system jumps between these attractors, fluctuations remain in constant proportion to their mean and their temporal statistics become long-tailed. The simple algebraic construction of this model affords a systematic analysis of the contribution of stochastic and nonlinear processes to cortical rhythms, complementing a recently proposed biophysical model. Similar dynamics also occur in a kinetic model of gene regulation, suggesting universality across a broad class of biological phenomena.},
	number = {8},
	journal = {PLoS Computational Biology},
	author = {Freyer, Frank and Roberts, James A. and Ritter, Petra and Breakspear, Michael},
	year = {2012},
	pmid = {22912567},
	file = {Attachment:/Users/tito/Zotero/storage/WTX2KM8B/Freyer et al. - 2012 - A Canonical Model of Multistability and Scale-Invariance in Biological Systems.pdf:application/pdf},
}

@article{murray_hierarchy_2014,
	title = {A hierarchy of intrinsic timescales across primate cortex},
	volume = {17},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3862},
	doi = {10.1038/nn.3862},
	abstract = {Specialization and hierarchy are organizing principles for primate cortex, yet there is little direct evidence for how cortical areas are specialized in the temporal domain. We measured timescales of intrinsic fluctuations in spiking activity across areas and found a hierarchical ordering, with sensory and prefrontal areas exhibiting shorter and longer timescales, respectively. On the basis of our findings, we suggest that intrinsic timescales reflect areal specialization for task-relevant computations over multiple temporal ranges.},
	number = {12},
	journal = {Nature Neuroscience},
	author = {Murray, John D and Bernacchia, Alberto and Freedman, David J and Romo, Ranulfo and Wallis, Jonathan D and Cai, Xinying and Padoa-Schioppa, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
	year = {2014},
	pmid = {25383900},
	pages = {1661--1663},
	file = {Attachment:/Users/tito/Zotero/storage/Y5C2KHNJ/Murray et al. - 2014 - A hierarchy of intrinsic timescales across primate cortex.pdf:application/pdf},
}

@article{mante_context-dependent_2013,
	title = {Context-dependent computation by recurrent dynamics in prefrontal cortex},
	volume = {503},
	issn = {0028-0836},
	url = {http://www.nature.com/doifinder/10.1038/nature12742},
	doi = {10.1038/nature12742},
	abstract = {Prefrontal cortex is thought to have a fundamental role in flexible, context-dependent behaviour, but the exact nature of the computations underlying this role remains largely unknown. In particular, individual prefrontal neurons often generate remarkably complex responses that defy deep understanding of their contribution to behaviour. Here we study prefrontal cortex activity in macaque monkeys trained to flexibly select and integrate noisy sensory inputs towards a choice. We find that the observed complexity and functional roles of single neurons are readily understood in the framework of a dynamical process unfolding at the level of the population. The population dynamics can be reproduced by a trained recurrent neural network, which suggests a previously unknown mechanism for selection and integration of task-relevant inputs. This mechanism indicates that selection and integration are two aspects of a single dynamical process unfolding within the same prefrontal circuits, and potentially provides a novel, general framework for understanding context-dependent computations.},
	number = {7474},
	journal = {Nature},
	author = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V. and Newsome, William T.},
	year = {2013},
	pmid = {24201281},
	pages = {78--84},
	file = {Attachment:/Users/tito/Zotero/storage/LADIAQKH/Mante et al. - 2013 - Context-dependent computation by recurrent dynamics in prefrontal cortex.pdf:application/pdf},
}

@article{elston_pyramidal_2000,
	title = {Pyramidal cells of the frontal lobe: all the more spinous to think with.},
	volume = {20},
	issn = {0270-6474},
	doi = {20004498 [pii]},
	abstract = {The basal dendritic arbors of pyramidal cells in prefrontal areas 10, 11, and 12 of the macaque monkey were revealed by intracellular injection in fixed, flat-mounted, cortical slices. The size, number of branches, and spine density of the basal dendrites were quantified and compared with those of pyramidal cells in the occipital, parietal, and temporal lobes. These analyses revealed that cells in the frontal lobe were significantly more spinous than those in the other lobes, having as many as 16 times more spines than cells in the primary visual area (V1), four times more those in area 7a, and 45\% more than those in area TE. As each dendritic spine receives at least one excitatory input, the large number of spines reported for layer III cells in prefrontal cortex suggests that they are capable of integrating a greater number of excitatory inputs than layer III pyramidal cells so far studied in the occipital, parietal, and temporal lobes. The ability to integrate a large number of excitatory inputs may be important for the sustained tonic activity characteristic of neurons in prefrontal cortex and their role in memory and cognition.},
	number = {RC95},
	journal = {The Journal of Neuroscience},
	author = {Elston, G N},
	year = {2000},
	pmid = {10974092},
	pages = {1--4},
	file = {Attachment:/Users/tito/Zotero/storage/AH4LINXA/Elston - 2000 - Pyramidal cells of the frontal lobe all the more spinous to think with.pdf:application/pdf},
}

@article{yang_dendritic_2016,
	title = {A dendritic disinhibitory circuit mechanism for pathway-specific gating},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms12815},
	doi = {10.1038/ncomms12815},
	abstract = {While reading a book in a noisy café, how does your brain 'gate in' visual information while filtering out auditory stimuli? Here we propose a mechanism for such flexible routing of information flow in a complex brain network (pathway-specific gating), tested using a network model of pyramidal neurons and three classes of interneurons with connection probabilities constrained by data. We find that if inputs from different pathways cluster on a pyramidal neuron dendrite, a pathway can be gated-on by a disinhibitory circuit motif. The branch-specific disinhibition can be achieved despite dense interneuronal connectivity, even with random connections. Moreover, clustering of input pathways on dendrites can naturally emerge through synaptic plasticity regulated by dendritic inhibition. This gating mechanism in a neural circuit is further demonstrated by performing a context-dependent decision-making task. The model suggests that cognitive flexibility engages top-down signalling of behavioural rule or context that targets specific classes of inhibitory neurons.},
	number = {May},
	journal = {Nature Communications},
	author = {Yang, Guangyu Robert and Murray, John D. and Wang, Xiao-Jing},
	year = {2016},
	pmid = {27649374},
	pages = {12815},
	file = {Attachment:/Users/tito/Zotero/storage/IV9WBGPM/Yang, Murray, Wang - 2016 - A dendritic disinhibitory circuit mechanism for pathway-specific gating.pdf:application/pdf},
}

@article{kass_ten_2016,
	title = {Ten {Simple} {Rules} for {Effective} {Statistical} {Practice}},
	volume = {12},
	issn = {15537358},
	doi = {10.1371/journal.pcbi.1004961},
	abstract = {Every article on statistics requires at least one caveat. Here is ours: we refer in this article to “science” as a convenient shorthand for investigations using data to study questions of interest. This includes social science, engineering, digital humanities, finance, and so on. Statisticians are not shy about reminding administrators that statistical science has an impact on nearly every part of almost all organizations... Among the many articles reporting on the ASA's statement on p-values, we particularly liked a quote from biostatistician Andrew Vickers in [21]: “Treat statistics as a science, not a recipe.” This is a great candidate for Rule 0.},
	number = {6},
	journal = {PLoS Computational Biology},
	author = {Kass, Robert E. and Caffo, Brian S. and Davidian, Marie and Meng, Xiao Li and Yu, Bin and Reid, Nancy},
	year = {2016},
	pmid = {27281180},
	pages = {1--8},
	file = {Attachment:/Users/tito/Zotero/storage/BDKK75WV/Kass et al. - 2016 - Ten Simple Rules for Effective Statistical Practice.pdf:application/pdf},
}

@article{shine_distinct_2017,
	title = {Distinct patterns of temporal and directional connectivity among intrinsic networks in the human brain},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1574-17.2017},
	doi = {10.1523/JNEUROSCI.1574-17.2017},
	journal = {The Journal of Neuroscience},
	author = {Shine, James M. and Kucyi, Aaron and Foster, Brett L. and Bickel, Stephan and Wang, Danhong and Liu, Hesheng and Poldrack, Russell A. and Hsieh, Liang-Tien and Chun Hsiang, Jen and Parvizi, Josef},
	year = {2017},
	pmid = {28893929},
	pages = {1574--17},
	file = {Attachment:/Users/tito/Zotero/storage/YH6X6HCL/Shine et al. - 2017 - Distinct patterns of temporal and directional connectivity among intrinsic networks in the human brain.pdf:application/pdf},
}

@article{gallego_multiple_2017,
	title = {Multiple tasks viewed from the neural manifold: {Stable} control of varied behavior},
	url = {http://www.biorxiv.org/content/biorxiv/early/2017/08/21/176081.full.pdf},
	doi = {10.1101/176081},
	journal = {bioRxiv},
	author = {Gallego, Juan A and Perich, Matthew G and Naufel, Stephanie N and Ethier, Christian and Solla, Sara A and Miller, Lee E},
	year = {2017},
	pages = {1--27},
	file = {Attachment:/Users/tito/Zotero/storage/ATQV5EEJ/Gallego et al. - 2017 - Multiple tasks viewed from the neural manifold Stable control of varied behavior.pdf:application/pdf},
}

@article{guntupalli_disentangling_2017,
	title = {Disentangling the {Representation} of {Identity} from {Head} {View} {Along} the {Human} {Face} {Processing} {Pathway}},
	volume = {27},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/2557348/Disentangling},
	doi = {10.1093/cercor/bhw344},
	abstract = {Neural models of a distributed system for face perception implicate a network of regions in the ventral visual stream for recognition of identity. Here, we report a functional magnetic resonance imaging (fMRI) neural decoding study in humans that shows that this pathway culminates in the right inferior frontal cortex face area (rIFFA) with a representation of individual identities that has been disentangled from variable visual features in different images of the same person. At earlier stages in the pathway, processing begins in early visual cortex and the occipital face area with representations of head view that are invariant across identities, and proceeds to an intermediate level of representation in the fusiform face area in which identity is emerging but still entangled with head view. Three-dimensional, view-invariant representation of identities in the rIFFA may be the critical link to the extended system for face perception, affording activation of person knowledge and emotional responses to familiar faces.},
	number = {1},
	journal = {Cerebral Cortex},
	author = {Guntupalli, J. Swaroop and Wheeler, Kelsey G. and Gobbini, M. Ida},
	year = {2017},
	pmid = {27899565},
	keywords = {neural decoding, fusiform face area, inferior frontal face area, occipital face area, view-invariant face identity},
	pages = {46--53},
	file = {Attachment:/Users/tito/Zotero/storage/PDYKRMEN/Guntupalli, Wheeler, Gobbini - 2017 - Disentangling the Representation of Identity from Head View Along the Human Face Processing Pathwa.pdf:application/pdf},
}

@article{crosse_multivariate_2016,
	title = {The {Multivariate} {Temporal} {Response} {Function} ({mTRF}) {Toolbox}: {A} {MATLAB} {Toolbox} for {Relating} {Neural} {Signals} to {Continuous} {Stimuli}},
	volume = {10},
	issn = {1662-5161},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00604/full},
	doi = {10.3389/fnhum.2016.00604},
	abstract = {Understanding how brains process sensory signals in natural environments is one of the key goals of 21st century neuroscience. While brain imaging and invasive electrophysiology will play key roles in this endeavor, there is also an important role to be played by noninvasive, macroscopic techniques with high temporal resolution such as electro- and magnetoencephalography. But challenges exist in determining how best to analyze such complex, time-varying neural responses to complex, time-varying and multivariate natural sensory stimuli. There has been a long history of applying system identification techniques to relate the firing activity of neurons to complex sensory stimuli and such techniques are now seeing increased application to EEG and MEG data. One particular example involves fitting a filter – often referred to as a temporal response function – that describes a mapping between some feature(s) of a sensory stimulus and the neural response. Here, we first briefly review the history of these system identification approaches and describe a specific technique for deriving temporal response functions known as regularized linear regression. We then introduce a new open-source toolbox for performing this analysis. We describe how it can be used to derive (multivariate) temporal response functions describing a mapping between stimulus and response in both directions. We also explain the importance of regularizing the analysis and how this regularization can be optimized for a particular dataset. We then outline specifically how the toolbox implements these analyses and provide several examples of the types of results that the toolbox can produce. Finally, we consider some of the limitations of the toolbox and opportunities for future development and application.},
	number = {November},
	journal = {Frontiers in Human Neuroscience},
	author = {Crosse, Michael J. and Di Liberto, Giovanni M. and Bednar, Adam and Lalor, Edmund C.},
	year = {2016},
	pmid = {27965557},
	keywords = {eeg, meg, reverse correlation, sensory processing, stimul, stimulus reconstruction, system identification},
	pages = {1--14},
	file = {Attachment:/Users/tito/Zotero/storage/H2X8RSWY/Crosse et al. - 2016 - The Multivariate Temporal Response Function (mTRF) Toolbox A MATLAB Toolbox for Relating Neural Signals to Contin.pdf:application/pdf},
}

@article{loula_decoding_2017,
	title = {Decoding {fMRI} activity in the time domain improves classification performance},
	issn = {10959572},
	doi = {10.1016/j.neuroimage.2017.08.018},
	abstract = {Most current functional Magnetic Resonance Imaging (fMRI) decoding analyses rely on statistical summaries of the data resulting from a deconvolution approach: each stimulation event is associated with a brain response. This standard approach leads to simple learning procedures, yet it is ill-suited for decoding events with short inter-stimulus intervals. In order to overcome this issue, we propose a novel framework that separates the spatial and temporal components of the prediction by decoding the fMRI time-series continuously, i.e. scan-by-scan. The stimulation events can then be identified through a deconvolution of the reconstructed time series. We show that this model performs as well as or better than standard approaches across several datasets, most notably in regimes with small inter-stimuli intervals (3-5s), while also offering predictions that are highly interpretable in the time domain. This opens the way toward analyzing datasets not normally thought of as suitable for decoding and makes it possible to run decoding on studies with reduced scan time.},
	journal = {NeuroImage},
	author = {Loula, João and Varoquaux, Gaël and Thirion, Bertrand},
	year = {2017},
	keywords = {Decoding, MVPA, Classification analysis, Functional magnetic resonance imaging, Rapid event-related design},
	pages = {1--8},
	file = {Attachment:/Users/tito/Zotero/storage/88DA2NPZ/Loula, Varoquaux, Thirion - 2017 - Decoding fMRI activity in the time domain improves classification performance.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6L4RLNKD/Loula, Varoquaux, Thirion - 2017 - Decoding fMRI activity in the time domain improves classification performance.pdf:application/pdf},
}

@article{petri_universal_2017,
	title = {Universal limits to parallel processing capability of network architectures},
	url = {http://arxiv.org/abs/1708.03263},
	abstract = {The ability to learn new tasks and generalize performance to others is one of the most remarkable characteristics of the human brain and of recent AI systems. The ability to perform multiple tasks simultaneously is also a signature characteristic of large-scale parallel architectures, that is evident in the human brain, and has been exploited effectively more traditional, massively parallel computational architectures. Here, we show that these two characteristics are in tension, reflecting a fundamental tradeoff between interactive parallelism that supports learning and generalization, and independent parallelism that supports processing efficiency through concurrent multitasking. We formally show that, while the maximum number of tasks that can be performed simultaneously grows linearly with network size, under realistic scenarios (e.g. in an unpredictable environment), the expected number that can be performed concurrently grows radically sub-linearly with network size. Hence, even modest reliance on shared representation strictly constrains the number of tasks that can be performed simultaneously, implying profound consequences for the development of artificial intelligence that optimally manages the tradeoff between learning and processing, and for understanding the human brains remarkably puzzling mix of sequential and parallel capabilities.},
	author = {Petri, Giovanni and Musslick, Sebastian and Dey, Biswadip and Ozcimder, Kayhan and Ahmed, Nesreen K. and Willke, Theodore and Cohen, Jonathan D.},
	year = {2017},
	pages = {1--14},
	file = {Attachment:/Users/tito/Zotero/storage/26D3HZC9/Petri et al. - 2017 - Universal limits to parallel processing capability of network architectures.pdf:application/pdf},
}

@article{gonzalez-castillo_task-based_2017,
	title = {Task-based dynamic functional connectivity: {Recent} findings and open questions},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2017.08.006},
	doi = {10.1016/j.neuroimage.2017.08.006},
	abstract = {The temporal evolution of functional connectivity (FC) within the confines of individual scans is nowadays often explored with functional neuroimaging. This is particularly true for resting-state; yet, FC-dynamics have also been investigated as subjects engage on numerous tasks. It is these research efforts that constitute the core of this survey. First, empirical observations on how FC differs between task and rest-independent of temporal scale-are reviewed, as they underscore how, despite overall preservation of network topography, the brain's FC does reconfigure in systematic ways to accommodate task demands. Next, reports on the relationships between instantaneous FC and perception/performance in subsequent trials are discussed. Similarly, research where different aspects of task-concurrent FC-dynamics are explored or utilized to predict ongoing mental states are also examined. The manuscript finishes with an incomplete list of challenges that hopefully fuels future work in this vibrant area of neuroscientific research. Overall, this review concludes that task-concurrent FC-dynamics, when properly characterized, are relevant to behavior, and that their translational value holds considerable promise.},
	number = {May},
	journal = {NeuroImage},
	author = {Gonzalez-Castillo, Javier and Bandettini, Peter A.},
	year = {2017},
	keywords = {Connectivity dynamics, Dynamic functional connectivity, Functional connectivity states, Task vs. rest, Task-concurrent functional connectivity},
	pages = {1--8},
	file = {Attachment:/Users/tito/Zotero/storage/9NDYVSX4/Gonzalez-Castillo, Bandettini - 2017 - Task-based dynamic functional connectivity Recent findings and open questions.pdf:application/pdf},
}

@article{park_bayesian_2017,
	title = {Bayesian {Efficient} {Coding}},
	url = {http://www.biorxiv.org/content/early/2017/08/22/178418.full.pdf+html},
	doi = {10.1101/178418},
	abstract = {The efficient coding hypothesis, which proposes that neurons are optimized to maximize information about the environment, has provided a guiding theoretical framework for sensory and systems neuroscience. More recently, a theory known as the Bayesian Brain hypothesis has focused on the brain's ability to integrate sensory and prior sources of information in order to perform Bayesian inference. However, there is as yet no com-prehensive theory connecting these two theoretical frameworks. Here we bridge this gap by formalizing a Bayesian theory of ef-ficient coding. We define Bayesian efficient codes in terms of four basic ingredients: (1) a stimulus prior distribution; (2) an en-coding model; (3) a capacity constraint, specifying a neural re-source limit; and (4) a loss function, quantifying the desirability or undesirability of various posterior distributions. Classic efficient codes can be seen as a special case in which the loss function is the posterior entropy, leading to a code that maximizes mu-tual information, but alternate loss functions give solutions that differ dramatically from information-maximizing codes. In par-ticular, we show that decorrelation of sensory inputs, which is optimal under classic efficient codes in low-noise settings, can be disadvantageous for loss functions that penalize large errors. Bayesian efficient coding therefore enlarges the family of nor-matively optimal codes and provides a more general framework for understanding the design principles of sensory systems. We examine Bayesian efficient codes for linear receptive fields and nonlinear input-output functions, and show that our theory invites reinterpretation of Laughlin's seminal analysis of efficient coding in the blowfly visual system.},
	journal = {bioRxiv},
	author = {Park, Il Memming and Pillow, Jonathan W},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/3H8BBVJT/Park, Pillow - 2017 - Bayesian Efficient Coding.pdf:application/pdf},
}

@article{chaisangmongkon_computing_2017,
	title = {Computing by {Robust} {Transience}: {How} the {Fronto}-{Parietal} {Network} {Performs} {Sequential}, {Category}-{Based} {Decisions}},
	volume = {93},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2017.03.002},
	doi = {10.1016/j.neuron.2017.03.002},
	abstract = {Decision making involves dynamic interplay between internal judgements and external perception, which has been investigated in delayed match-to-category (DMC) experiments. Our analysis of neural recordings shows that, during DMC tasks, LIP and PFC neurons demonstrate mixed, time-varying, and heterogeneous selectivity, but previous theoretical work has not established the link between these neural characteristics and population-level computations. We trained a recurrent network model to perform DMC tasks and found that the model can remarkably reproduce key features of neuronal selectivity at the single-neuron and population levels. Analysis of the trained networks elucidates that robust transient trajectories of the neural population are the key driver of sequential categorical decisions. The directions of trajectories are governed by network self-organized connectivity, defining a “neural landscape” consisting of a task-tailored arrangement of slow states and dynamical tunnels. With this model, we can identify functionally relevant circuit motifs and generalize the framework to solve other categorization tasks.},
	number = {6},
	journal = {Neuron},
	author = {Chaisangmongkon, Warasinee and Swaminathan, Sruthi K. and Freedman, David J. and Wang, Xiao Jing},
	year = {2017},
	pmid = {28334612},
	keywords = {decision making, category learning, delayed match-to-category task, hessian-free algorithm, lateral intraparietal cortex, LIP, PFC, prefrontal cortex, recurrent neural network, working memory},
	pages = {1504--1517.e4},
	file = {Attachment:/Users/tito/Zotero/storage/ZS7LB9SC/Chaisangmongkon et al. - 2017 - Computing by Robust Transience How the Fronto-Parietal Network Performs Sequential, Category-Based Decis.pdf:application/pdf},
}

@article{hanke_studyforrest_2016,
	title = {A studyforrest extension, simultaneous {fMRI} and eye gaze recordings during prolonged natural stimulation},
	volume = {3},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201692},
	doi = {10.1038/sdata.2016.92},
	abstract = {Here we present an update of the studyforrest (http://studyforrest.org) dataset that complements the previously released functional magnetic resonance imaging (fMRI) data for natural language processing with a new two-hour 3 Tesla fMRI acquisition while 15 of the original participants were shown an audio-visual version of the stimulus motion picture. We demonstrate with two validation analyses that these new data support modeling specific properties of the complex natural stimulus, as well as a substantial within-subject BOLD response congruency in brain areas related to the processing of auditory inputs, speech, and narrative when compared to the existing fMRI data for audio-only stimulation. In addition, we provide participants' eye gaze location as recorded simultaneously with fMRI, and an additional sample of 15 control participants whose eye gaze trajectories for the entire movie were recorded in a lab setting-to enable studies on attentional processes and comparative investigations on the potential impact of the stimulation setting on these processes.},
	journal = {Scientific Data},
	author = {Hanke, Michael and Adelhöfer, Nico and Kottke, Daniel and Iacovella, Vittorio and Sengupta, Ayan and Kaule, Falko R. and Nigbur, Roland and Waite, Alexander Q. and Baumgartner, Florian and Stadler, Jörg},
	year = {2016},
	pmid = {27779621},
	pages = {160092},
	file = {Attachment:/Users/tito/Zotero/storage/CPX6NCZ4/Hanke et al. - 2016 - A studyforrest extension, simultaneous fMRI and eye gaze recordings during prolonged natural stimulation.pdf:application/pdf},
}

@article{sengupta_studyforrest_2016,
	title = {A studyforrest extension, retinotopic mapping and localization of higher visual areas},
	volume = {3},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201693},
	doi = {10.1038/sdata.2016.93},
	abstract = {The studyforrest (http://studyforrest.org) dataset is likely the largest neuroimaging dataset on natural language and story processing publicly available today. In this article, along with a companion publication, we present an update of this dataset that extends its scope to vision and multi-sensory research. 15 participants of the original cohort volunteered for a series of additional studies: a clinical examination of visual function, a standard retinotopic mapping procedure, and a localization of higher visual areas-such as the fusiform face area. The combination of this update, the previous data releases for the dataset, and the companion publication, which includes neuroimaging and eye tracking data from natural stimulation with a motion picture, form an extremely versatile and comprehensive resource for brain imaging research-with almost six hours of functional neuroimaging data across five different stimulation paradigms for each participant. Furthermore, we describe employed paradigms and present results that document the quality of the data for the purpose of characterising major properties of participants' visual processing stream.},
	journal = {Scientific Data},
	author = {Sengupta, Ayan and Kaule, Falko R. and Guntupalli, J. Swaroop and Hoffmann, Michael B. and Häusler, Christian and Stadler, Jörg and Hanke, Michael},
	year = {2016},
	pmid = {27779618},
	pages = {160093},
	file = {Attachment:/Users/tito/Zotero/storage/IAWCT5JZ/Sengupta et al. - 2016 - A studyforrest extension, retinotopic mapping and localization of higher visual areas.pdf:application/pdf},
}

@article{poldrack_scanning_2017,
	title = {Scanning the horizon: towards transparent and reproducible neuroimaging research},
	volume = {18},
	issn = {1471-003X},
	url = {http://dx.doi.org/10.1038/nrn.2016.167 http://10.0.4.14/nrn.2016.167 http://www.nature.com/nrn/journal/v18/n2/abs/nrn.2016.167.html#supplementary-information},
	abstract = {Functional neuroimaging techniques have transformed our ability to probe the neurobiological basis of behaviour and are increasingly being applied by the wider neuroscience community. However, concerns have recently been raised that the conclusions that are drawn from some human neuroimaging studies are either spurious or not generalizable. Problems such as low statistical power, flexibility in data analysis, software errors and a lack of direct replication apply to many fields, but perhaps particularly to functional MRI. Here, we discuss these problems, outline current and suggested best practices, and describe how we think the field should evolve to produce the most meaningful and reliable answers to neuroscientific questions.},
	number = {2},
	journal = {Nat Rev Neurosci},
	author = {Poldrack, Russell A and Baker, Chris I and Durnez, Joke and Gorgolewski, Krzysztof J and Matthews, Paul M and Munafo, Marcus R and Nichols, Thomas E and Poline, Jean-Baptiste and Vul, Edward and Yarkoni, Tal},
	month = feb,
	year = {2017},
	pages = {115--126},
}

@article{hanke_high-resolution_2014,
	title = {A high-resolution 7-{Tesla} {fMRI} dataset from complex natural stimulation with an audio movie.},
	volume = {1},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata20143},
	doi = {10.1038/sdata.2014.3},
	abstract = {Here we present a high-resolution functional magnetic resonance (fMRI) dataset - 20 participants recorded at high field strength (7 Tesla) during prolonged stimulation with an auditory feature film ("Forrest Gump"). In addition, a comprehensive set of auxiliary data (T1w, T2w, DTI, susceptibility-weighted image, angiography) as well as measurements to assess technical and physiological noise components have been acquired. An initial analysis confirms that these data can be used to study common and idiosyncratic brain response patterns to complex auditory stimulation. Among the potential uses of this dataset are the study of auditory attention and cognition, language and music perception, and social perception. The auxiliary measurements enable a large variety of additional analysis strategies that relate functional response patterns to structural properties of the brain. Alongside the acquired data, we provide source code and detailed information on all employed procedures - from stimulus creation to data analysis. In order to facilitate replicative and derived works, only free and open-source software was utilized.},
	journal = {Scientific data},
	author = {Hanke, Michael and Baumgartner, Florian J and Ibe, Pierre and Kaule, Falko R and Pollmann, Stefan and Speck, Oliver and Zinke, Wolf and Stadler, Jörg},
	year = {2014},
	pmid = {25977761},
	keywords = {Perception, Functional magnetic resonance imaging, Auditory system, Language},
	pages = {140003},
	file = {Attachment:/Users/tito/Zotero/storage/H8VYU3CT/Hanke et al. - 2014 - A high-resolution 7-Tesla fMRI dataset from complex natural stimulation with an audio movie.pdf:application/pdf},
}

@article{stein_identification_2012,
	title = {Identification of common variants associated with human hippocampal and intracranial volumes.},
	volume = {44},
	issn = {1546-1718},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22504417 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3635491},
	doi = {10.1038/ng.2250},
	abstract = {Identifying genetic variants influencing human brain structures may reveal new biological mechanisms underlying cognition and neuropsychiatric illness. The volume of the hippocampus is a biomarker of incipient Alzheimer's disease and is reduced in schizophrenia, major depression and mesial temporal lobe epilepsy. Whereas many brain imaging phenotypes are highly heritable, identifying and replicating genetic influences has been difficult, as small effects and the high costs of magnetic resonance imaging (MRI) have led to underpowered studies. Here we report genome-wide association meta-analyses and replication for mean bilateral hippocampal, total brain and intracranial volumes from a large multinational consortium. The intergenic variant rs7294919 was associated with hippocampal volume (12q24.22; N = 21,151; P = 6.70 × 10(-16)) and the expression levels of the positional candidate gene TESC in brain tissue. Additionally, rs10784502, located within HMGA2, was associated with intracranial volume (12q14.3; N = 15,782; P = 1.12 × 10(-12)). We also identified a suggestive association with total brain volume at rs10494373 within DDR2 (1q23.3; N = 6,500; P = 5.81 × 10(-7)).},
	number = {5},
	journal = {Nature genetics},
	author = {Stein, Jason L and Medland, Sarah E and Vasquez, Alejandro Arias and Hibar, Derrek P and Senstad, Rudy E and Winkler, Anderson M and Toro, Roberto and Appel, Katja and Bartecek, Richard and Bergmann, Ørjan and Bernard, Manon and Brown, Andrew A and Cannon, Dara M and Chakravarty, M Mallar and Christoforou, Andrea and Domin, Martin and Grimm, Oliver and Hollinshead, Marisa and Holmes, Avram J and Homuth, Georg and Hottenga, Jouke-Jan and Langan, Camilla and Lopez, Lorna M and Hansell, Narelle K and Hwang, Kristy S and Kim, Sungeun and Laje, Gonzalo and Lee, Phil H and Liu, Xinmin and Loth, Eva and Lourdusamy, Anbarasu and Mattingsdal, Morten and Mohnke, Sebastian and Maniega, Susana Muñoz and Nho, Kwangsik and Nugent, Allison C and O'Brien, Carol and Papmeyer, Martina and Pütz, Benno and Ramasamy, Adaikalavan and Rasmussen, Jerod and Rijpkema, Mark and Risacher, Shannon L and Roddey, J Cooper and Rose, Emma J and Ryten, Mina and Shen, Li and Sprooten, Emma and Strengman, Eric and Teumer, Alexander and Trabzuni, Daniah and Turner, Jessica and van Eijk, Kristel and van Erp, Theo G M and van Tol, Marie-Jose and Wittfeld, Katharina and Wolf, Christiane and Woudstra, Saskia and Aleman, Andre and Alhusaini, Saud and Almasy, Laura and Binder, Elisabeth B and Brohawn, David G and Cantor, Rita M and Carless, Melanie A and Corvin, Aiden and Czisch, Michael and Curran, Joanne E and Davies, Gail and de Almeida, Marcio A A and Delanty, Norman and Depondt, Chantal and Duggirala, Ravi and Dyer, Thomas D and Erk, Susanne and Fagerness, Jesen and Fox, Peter T and Freimer, Nelson B and Gill, Michael and Göring, Harald H H and Hagler, Donald J and Hoehn, David and Holsboer, Florian and Hoogman, Martine and Hosten, Norbert and Jahanshad, Neda and Johnson, Matthew P and Kasperaviciute, Dalia and Kent, Jack W and Kochunov, Peter and Lancaster, Jack L and Lawrie, Stephen M and Liewald, David C and Mandl, René and Matarin, Mar and Mattheisen, Manuel and Meisenzahl, Eva and Melle, Ingrid and Moses, Eric K and Mühleisen, Thomas W and Nauck, Matthias and Nöthen, Markus M and Olvera, Rene L and Pandolfo, Massimo and Pike, G Bruce and Puls, Ralf and Reinvang, Ivar and Rentería, Miguel E and Rietschel, Marcella and Roffman, Joshua L and Royle, Natalie A and Rujescu, Dan and Savitz, Jonathan and Schnack, Hugo G and Schnell, Knut and Seiferth, Nina and Smith, Colin and Steen, Vidar M and Valdés Hernández, Maria C and Van den Heuvel, Martijn and van der Wee, Nic J and Van Haren, Neeltje E M and Veltman, Joris A and Völzke, Henry and Walker, Robert and Westlye, Lars T and Whelan, Christopher D and Agartz, Ingrid and Boomsma, Dorret I and Cavalleri, Gianpiero L and Dale, Anders M and Djurovic, Srdjan and Drevets, Wayne C and Hagoort, Peter and Hall, Jeremy and Heinz, Andreas and Jack, Clifford R and Foroud, Tatiana M and Le Hellard, Stephanie and Macciardi, Fabio and Montgomery, Grant W and Poline, Jean Baptiste and Porteous, David J and Sisodiya, Sanjay M and Starr, John M and Sussmann, Jessika and Toga, Arthur W and Veltman, Dick J and Walter, Henrik and Weiner, Michael W and {Alzheimer's Disease Neuroimaging Initiative} and {EPIGEN Consortium} and {IMAGEN Consortium} and {Saguenay Youth Study Group} and Bis, Joshua C and Ikram, M Arfan and Smith, Albert V and Gudnason, Vilmundur and Tzourio, Christophe and Vernooij, Meike W and Launer, Lenore J and DeCarli, Charles and Seshadri, Sudha and {Cohorts for Heart and Aging Research in Genomic Epidemiology Consortium} and Andreassen, Ole A and Apostolova, Liana G and Bastin, Mark E and Blangero, John and Brunner, Han G and Buckner, Randy L and Cichon, Sven and Coppola, Giovanni and de Zubicaray, Greig I and Deary, Ian J and Donohoe, Gary and de Geus, Eco J C and Espeseth, Thomas and Fernández, Guillén and Glahn, David C and Grabe, Hans J and Hardy, John and Hulshoff Pol, Hilleke E and Jenkinson, Mark and Kahn, René S and McDonald, Colm and McIntosh, Andrew M and McMahon, Francis J and McMahon, Katie L and Meyer-Lindenberg, Andreas and Morris, Derek W and Müller-Myhsok, Bertram and Nichols, Thomas E and Ophoff, Roel A and Paus, Tomas and Pausova, Zdenka and Penninx, Brenda W and Potkin, Steven G and Sämann, Philipp G and Saykin, Andrew J and Schumann, Gunter and Smoller, Jordan W and Wardlaw, Joanna M and Weale, Michael E and Martin, Nicholas G and Franke, Barbara and Wright, Margaret J and Thompson, Paul M and {Enhancing Neuro Imaging Genetics through Meta-Analysis Consortium}},
	month = apr,
	year = {2012},
	pmid = {22504417},
	pages = {552--61},
}

@article{burgess_using_2015,
	title = {Using published data in {Mendelian} randomization: a blueprint for efficient identification of causal risk factors.},
	volume = {30},
	issn = {1573-7284},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25773750 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4516908},
	doi = {10.1007/s10654-015-0011-z},
	abstract = {Finding individual-level data for adequately-powered Mendelian randomization analyses may be problematic. As publicly-available summarized data on genetic associations with disease outcomes from large consortia are becoming more abundant, use of published data is an attractive analysis strategy for obtaining precise estimates of the causal effects of risk factors on outcomes. We detail the necessary steps for conducting Mendelian randomization investigations using published data, and present novel statistical methods for combining data on the associations of multiple (correlated or uncorrelated) genetic variants with the risk factor and outcome into a single causal effect estimate. A two-sample analysis strategy may be employed, in which evidence on the gene-risk factor and gene-outcome associations are taken from different data sources. These approaches allow the efficient identification of risk factors that are suitable targets for clinical intervention from published data, although the ability to assess the assumptions necessary for causal inference is diminished. Methods and guidance are illustrated using the example of the causal effect of serum calcium levels on fasting glucose concentrations. The estimated causal effect of a 1 standard deviation (0.13 mmol/L) increase in calcium levels on fasting glucose (mM) using a single lead variant from the CASR gene region is 0.044 (95 \% credible interval -0.002, 0.100). In contrast, using our method to account for the correlation between variants, the corresponding estimate using 17 genetic variants is 0.022 (95 \% credible interval 0.009, 0.035), a more clearly positive causal effect.},
	number = {7},
	journal = {European journal of epidemiology},
	author = {Burgess, Stephen and Scott, Robert A and Timpson, Nicholas J and Davey Smith, George and Thompson, Simon G and {EPIC- InterAct Consortium}},
	month = jul,
	year = {2015},
	pmid = {25773750},
	pages = {543--52},
}

@article{ioannidis_false-positive_2011,
	title = {The false-positive to false-negative ratio in epidemiologic studies.},
	volume = {22},
	issn = {1531-5487},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21490505},
	doi = {10.1097/EDE.0b013e31821b506e},
	abstract = {The ratio of false-positive to false-negative findings (FP:FN ratio) is an informative metric that warrants further evaluation. The FP:FN ratio varies greatly across different epidemiologic areas. In genetic epidemiology, it has varied from very high values (possibly even {\textbackslash}textgreater100:1) for associations reported in candidate-gene studies to very low values (1:100 or lower) for associations with genome-wide significance. The substantial reduction over time in the FP:FN ratio in human genome epidemiology has corresponded to the routine adoption of stringent inferential criteria and comprehensive, agnostic reporting of all analyses. Most traditional fields of epidemiologic research more closely follow the practices of past candidate gene epidemiology, and thus have high FP:FN ratios. Further, FP and FN results do not necessarily entail the same consequences, and their relative importance may vary in different settings. This ultimately has implications for what is the acceptable FP:FN ratio and for how the results of published epidemiologic studies should be presented and interpreted.},
	number = {4},
	journal = {Epidemiology (Cambridge, Mass.)},
	author = {Ioannidis, John P A and Tarone, Robert and McLaughlin, Joseph K},
	month = jul,
	year = {2011},
	pmid = {21490505},
	pages = {450--6},
}

@article{zuo_open_2014,
	title = {An open science resource for establishing reliability and reproducibility in functional connectomics.},
	volume = {1},
	issn = {2052-4463},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25977800 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4421932},
	doi = {10.1038/sdata.2014.49},
	abstract = {Efforts to identify meaningful functional imaging-based biomarkers are limited by the ability to reliably characterize inter-individual differences in human brain function. Although a growing number of connectomics-based measures are reported to have moderate to high test-retest reliability, the variability in data acquisition, experimental designs, and analytic methods precludes the ability to generalize results. The Consortium for Reliability and Reproducibility (CoRR) is working to address this challenge and establish test-retest reliability as a minimum standard for methods development in functional connectomics. Specifically, CoRR has aggregated 1,629 typical individuals' resting state fMRI (rfMRI) data (5,093 rfMRI scans) from 18 international sites, and is openly sharing them via the International Data-sharing Neuroimaging Initiative (INDI). To allow researchers to generate various estimates of reliability and reproducibility, a variety of data acquisition procedures and experimental designs are included. Similarly, to enable users to assess the impact of commonly encountered artifacts (for example, motion) on characterizations of inter-individual variation, datasets of varying quality are included.},
	journal = {Scientific data},
	author = {Zuo, Xi-Nian and Anderson, Jeffrey S and Bellec, Pierre and Birn, Rasmus M and Biswal, Bharat B and Blautzik, Janusch and Breitner, John C S and Buckner, Randy L and Calhoun, Vince D and Castellanos, F Xavier and Chen, Antao and Chen, Bing and Chen, Jiangtao and Chen, Xu and Colcombe, Stanley J and Courtney, William and Craddock, R Cameron and Di Martino, Adriana and Dong, Hao-Ming and Fu, Xiaolan and Gong, Qiyong and Gorgolewski, Krzysztof J and Han, Ying and He, Ye and He, Yong and Ho, Erica and Holmes, Avram and Hou, Xiao-Hui and Huckins, Jeremy and Jiang, Tianzi and Jiang, Yi and Kelley, William and Kelly, Clare and King, Margaret and LaConte, Stephen M and Lainhart, Janet E and Lei, Xu and Li, Hui-Jie and Li, Kaiming and Li, Kuncheng and Lin, Qixiang and Liu, Dongqiang and Liu, Jia and Liu, Xun and Liu, Yijun and Lu, Guangming and Lu, Jie and Luna, Beatriz and Luo, Jing and Lurie, Daniel and Mao, Ying and Margulies, Daniel S and Mayer, Andrew R and Meindl, Thomas and Meyerand, Mary E and Nan, Weizhi and Nielsen, Jared A and O'Connor, David and Paulsen, David and Prabhakaran, Vivek and Qi, Zhigang and Qiu, Jiang and Shao, Chunhong and Shehzad, Zarrar and Tang, Weijun and Villringer, Arno and Wang, Huiling and Wang, Kai and Wei, Dongtao and Wei, Gao-Xia and Weng, Xu-Chu and Wu, Xuehai and Xu, Ting and Yang, Ning and Yang, Zhi and Zang, Yu-Feng and Zhang, Lei and Zhang, Qinglin and Zhang, Zhe and Zhang, Zhiqiang and Zhao, Ke and Zhen, Zonglei and Zhou, Yuan and Zhu, Xing-Ting and Milham, Michael P},
	year = {2014},
	pmid = {25977800},
	pages = {140049},
}

@article{gorgolewski_brain_2016,
	title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments.},
	volume = {3},
	issn = {2052-4463},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27326542 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4978148},
	doi = {10.1038/sdata.2016.44},
	abstract = {The development of magnetic resonance imaging (MRI) techniques has defined modern neuroimaging. Since its inception, tens of thousands of studies using techniques such as functional MRI and diffusion weighted imaging have allowed for the non-invasive study of the brain. Despite the fact that MRI is routinely used to obtain data for neuroscience research, there has been no widely adopted standard for organizing and describing the data collected in an imaging experiment. This renders sharing and reusing data (within or between labs) difficult if not impossible and unnecessarily complicates the application of automatic pipelines and quality assurance protocols. To solve this problem, we have developed the Brain Imaging Data Structure (BIDS), a standard for organizing and describing MRI datasets. The BIDS standard uses file formats compatible with existing software, unifies the majority of practices already common in the field, and captures the metadata necessary for most common data processing operations.},
	journal = {Scientific data},
	author = {Gorgolewski, Krzysztof J and Auer, Tibor and Calhoun, Vince D and Craddock, R Cameron and Das, Samir and Duff, Eugene P and Flandin, Guillaume and Ghosh, Satrajit S and Glatard, Tristan and Halchenko, Yaroslav O and Handwerker, Daniel A and Hanke, Michael and Keator, David and Li, Xiangrui and Michael, Zachary and Maumet, Camille and Nichols, B Nolan and Nichols, Thomas E and Pellman, John and Poline, Jean-Baptiste and Rokem, Ariel and Schaefer, Gunnar and Sochat, Vanessa and Triplett, William and Turner, Jessica A and Varoquaux, Gaël and Poldrack, Russell A},
	month = jun,
	year = {2016},
	pmid = {27326542},
	pages = {160044},
}

@article{flint_candidate_2013,
	title = {Candidate and non-candidate genes in behavior genetics.},
	volume = {23},
	issn = {1873-6882},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22878161 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3752971},
	doi = {10.1016/j.conb.2012.07.005},
	abstract = {In this review we discuss recent developments in psychiatric genetics: on the one hand, studies using whole genome approaches (genome-wide association studies (GWAS) and exome sequencing) are coming close to finding genes and molecular variants that contribute to disease susceptibility; on the other candidate genes, such as the serotonin transporter, continue to dominate in genetic studies of brain imaging phenotypes and in protracted searches for gene by environment interactions. These two areas intersect, in that new information about genetic effects from whole genome approaches, should (but does not always) inform the single locus analyses.},
	number = {1},
	journal = {Current opinion in neurobiology},
	author = {Flint, Jonathan and Munafò, Marcus R},
	month = feb,
	year = {2013},
	pmid = {22878161},
	pages = {57--61},
}

@article{memelli_self-referential_2013,
	title = {Self-referential forces are sufficient to explain different dendritic morphologies.},
	volume = {7},
	issn = {1662-5196},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23386828 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3558683},
	doi = {10.3389/fninf.2013.00001},
	abstract = {Dendritic morphology constrains brain activity, as it determines first which neuronal circuits are possible and second which dendritic computations can be performed over a neuron's inputs. It is known that a range of chemical cues can influence the final shape of dendrites during development. Here, we investigate the extent to which self-referential influences, cues generated by the neuron itself, might influence morphology. To this end, we developed a phenomenological model and algorithm to generate virtual morphologies, which are then compared to experimentally reconstructed morphologies. In the model, branching probability follows a Galton-Watson process, while the geometry is determined by "homotypic forces" exerting influence on the direction of random growth in a constrained space. We model three such homotypic forces, namely an inertial force based on membrane stiffness, a soma-oriented tropism, and a force of self-avoidance, as directional biases in the growth algorithm. With computer simulations we explored how each bias shapes neuronal morphologies. We show that based on these principles, we can generate realistic morphologies of several distinct neuronal types. We discuss the extent to which homotypic forces might influence real dendritic morphologies, and speculate about the influence of other environmental cues on neuronal shape and circuitry.},
	journal = {Frontiers in neuroinformatics},
	author = {Memelli, Heraldo and Torben-Nielsen, Benjamin and Kozloski, James},
	year = {2013},
	pmid = {23386828},
	keywords = {computational, dendrite, growth cone, model, morphology, simulation},
	pages = {1},
}

@article{begley_drug_2012,
	title = {Drug development: {Raise} standards for preclinical cancer research.},
	volume = {483},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22460880},
	doi = {10.1038/483531a},
	number = {7391},
	journal = {Nature},
	author = {Begley, C Glenn and Ellis, Lee M},
	month = mar,
	year = {2012},
	pmid = {22460880},
	pages = {531--3},
}

@article{nieuwenhuis_erroneous_2011,
	title = {Erroneous analyses of interactions in neuroscience: a problem of significance.},
	volume = {14},
	issn = {1546-1726},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21878926},
	doi = {10.1038/nn.2886},
	abstract = {In theory, a comparison of two experimental effects requires a statistical test on their difference. In practice, this comparison is often based on an incorrect procedure involving two separate tests in which researchers conclude that effects differ when one effect is significant (P {\textbackslash}textless 0.05) but the other is not (P {\textbackslash}textgreater 0.05). We reviewed 513 behavioral, systems and cognitive neuroscience articles in five top-ranking journals (Science, Nature, Nature Neuroscience, Neuron and The Journal of Neuroscience) and found that 78 used the correct procedure and 79 used the incorrect procedure. An additional analysis suggests that incorrect analyses of interactions are even more common in cellular and molecular neuroscience. We discuss scenarios in which the erroneous procedure is particularly beguiling.},
	number = {9},
	journal = {Nature neuroscience},
	author = {Nieuwenhuis, Sander and Forstmann, Birte U and Wagenmakers, Eric-Jan},
	month = aug,
	year = {2011},
	pmid = {21878926},
	pages = {1105--7},
}

@article{poldrack_can_2006,
	title = {Can cognitive processes be inferred from neuroimaging data?},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16406760},
	doi = {10.1016/j.tics.2005.12.004},
	abstract = {There is much interest currently in using functional neuroimaging techniques to understand better the nature of cognition. One particular practice that has become common is 'reverse inference', by which the engagement of a particular cognitive process is inferred from the activation of a particular brain region. Such inferences are not deductively valid, but can still provide some information. Using a Bayesian analysis of the BrainMap neuroimaging database, I characterize the amount of additional evidence in favor of the engagement of a cognitive process that can be offered by a reverse inference. Its usefulness is particularly limited by the selectivity of activation in the region of interest. I argue that cognitive neuroscientists should be circumspect in the use of reverse inference, particularly when selectivity of the region in question cannot be established or is known to be weak.},
	number = {2},
	journal = {Trends in cognitive sciences},
	author = {Poldrack, Russell A},
	month = feb,
	year = {2006},
	pmid = {16406760},
	pages = {59--63},
	file = {Snapshot:/Users/tito/Zotero/storage/73Z8QK46/S1364-6613(05)00336-0.html:text/html},
}

@article{carp_secret_2012,
	title = {The secret lives of experiments: methods reporting in the {fMRI} literature.},
	volume = {63},
	issn = {1095-9572},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22796459},
	doi = {10.1016/j.neuroimage.2012.07.004},
	abstract = {Replication of research findings is critical to the progress of scientific understanding. Accordingly, most scientific journals require authors to report experimental procedures in sufficient detail for independent researchers to replicate their work. To what extent do research reports in the functional neuroimaging literature live up to this standard? The present study evaluated methods reporting and methodological choices across 241 recent fMRI articles. Many studies did not report critical methodological details with regard to experimental design, data acquisition, and analysis. Further, many studies were underpowered to detect any but the largest statistical effects. Finally, data collection and analysis methods were highly flexible across studies, with nearly as many unique analysis pipelines as there were studies in the sample. Because the rate of false positive results is thought to increase with the flexibility of experimental designs, the field of functional neuroimaging may be particularly vulnerable to false positives. In sum, the present study documented significant gaps in methods reporting among fMRI studies. Improved methodological descriptions in research reports would yield significant benefits for the field.},
	number = {1},
	journal = {NeuroImage},
	author = {Carp, Joshua},
	month = oct,
	year = {2012},
	pmid = {22796459},
	pages = {289--300},
}

@article{poldrack_guidelines_2008,
	title = {Guidelines for reporting an {fMRI} study.},
	volume = {40},
	issn = {1053-8119},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18191585 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2287206},
	doi = {10.1016/j.neuroimage.2007.11.048},
	abstract = {In this editorial, we outline a set of guidelines for the reporting of methods and results in functional magnetic resonance imaging studies and provide a checklist to assist authors in preparing manuscripts that meet these guidelines.},
	number = {2},
	journal = {NeuroImage},
	author = {Poldrack, Russell A and Fletcher, Paul C and Henson, Richard N and Worsley, Keith J and Brett, Matthew and Nichols, Thomas E},
	month = apr,
	year = {2008},
	pmid = {18191585},
	pages = {409--14},
}

@article{waskom_frontoparietal_2014,
	title = {Frontoparietal representations of task context support the flexible control of goal-directed cognition.},
	volume = {34},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25100605 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4200112},
	doi = {10.1523/JNEUROSCI.5282-13.2014},
	abstract = {Cognitive control allows stimulus-response processing to be aligned with internal goals and is thus central to intelligent, purposeful behavior. Control is thought to depend in part on the active representation of task information in prefrontal cortex (PFC), which provides a source of contextual bias on perception, decision making, and action. In the present study, we investigated the organization, influences, and consequences of context representation as human subjects performed a cued sorting task that required them to flexibly judge the relationship between pairs of multivalent stimuli. Using a connectivity-based parcellation of PFC and multivariate decoding analyses, we determined that context is specifically and transiently represented in a region spanning the inferior frontal sulcus during context-dependent decision making. We also found strong evidence that decision context is represented within the intraparietal sulcus, an area previously shown to be functionally networked with the inferior frontal sulcus at rest and during task performance. Rule-guided allocation of attention to different stimulus dimensions produced discriminable patterns of activation in visual cortex, providing a signature of top-down bias over perception. Furthermore, demands on cognitive control arising from the task structure modulated context representation, which was found to be strongest after a shift in task rules. When context representation in frontoparietal areas increased in strength, as measured by the discriminability of high-dimensional activation patterns, the bias on attended stimulus features was enhanced. These results provide novel evidence that illuminates the mechanisms by which humans flexibly guide behavior in complex environments.},
	number = {32},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Waskom, Michael L and Kumaran, Dharshan and Gordon, Alan M and Rissman, Jesse and Wagner, Anthony D},
	month = aug,
	year = {2014},
	pmid = {25100605},
	keywords = {decision making, cognitive control, attention, prefrontal cortex},
	pages = {10743--55},
}

@article{hunt_hierarchical_2014,
	title = {Hierarchical competitions subserving multi-attribute choice.},
	volume = {17},
	issn = {1546-1726},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25306549 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4685756},
	doi = {10.1038/nn.3836},
	abstract = {Valuation is a key tenet of decision neuroscience, where it is generally assumed that different attributes of competing options are assimilated into unitary values. Such values are central to current neural models of choice. By contrast, psychological studies emphasize complex interactions between choice and valuation. Principles of neuronal selection also suggest that competitive inhibition may occur in early valuation stages, before option selection. We found that behavior in multi-attribute choice is best explained by a model involving competition at multiple levels of representation. This hierarchical model also explains neural signals in human brain regions previously linked to valuation, including striatum, parietal and prefrontal cortex, where activity represents within-attribute competition, competition between attributes and option selection. This multi-layered inhibition framework challenges the assumption that option values are computed before choice. Instead, our results suggest a canonical competition mechanism throughout all stages of a processing hierarchy, not simply at a final choice stage.},
	number = {11},
	journal = {Nature neuroscience},
	author = {Hunt, Laurence T and Dolan, Raymond J and Behrens, Timothy E J},
	month = nov,
	year = {2014},
	pmid = {25306549},
	pages = {1613--22},
}

@article{hayasaka_validating_2003,
	title = {Validating cluster size inference: random field and permutation methods.},
	volume = {20},
	issn = {1053-8119},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/14683734},
	doi = {10.1016/j.neuroimage.2003.08.003},
	abstract = {Cluster size tests used in analyses of brain images can have more sensitivity compared to intensity based tests. The random field (RF) theory has been widely used in implementation of such tests, however the behavior of such tests is not well understood, especially when the RF assumptions are in doubt. In this paper, we carried out a simulation study of cluster size tests under varying smoothness, thresholds, and degrees of freedom, comparing RF performance to that of the permutation test, which is known to be exact. For Gaussian images, we find that the RF methods are generally conservative, especially for low smoothness and low threshold. For t images, the RF tests are found to be conservative at lower thresholds and do not perform well unless the threshold is high and images are sufficiently smooth. The permutation test performs well for any settings though the discreteness in cluster size must be accounted for. We make specific recommendations on when permutation tests are to be preferred to RF tests.},
	number = {4},
	journal = {NeuroImage},
	author = {Hayasaka, Satoru and Nichols, Thomas E},
	month = dec,
	year = {2003},
	pmid = {14683734},
	pages = {2343--56},
}

@article{lieberman_type_2009,
	title = {Type {I} and {Type} {II} error concerns in {fMRI} research: re-balancing the scale.},
	volume = {4},
	issn = {1749-5024},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20035017 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2799956},
	doi = {10.1093/scan/nsp052},
	abstract = {Statistical thresholding (i.e. P-values) in fMRI research has become increasingly conservative over the past decade in an attempt to diminish Type I errors (i.e. false alarms) to a level traditionally allowed in behavioral science research. In this article, we examine the unintended negative consequences of this single-minded devotion to Type I errors: increased Type II errors (i.e. missing true effects), a bias toward studying large rather than small effects, a bias toward observing sensory and motor processes rather than complex cognitive and affective processes and deficient meta-analyses. Power analyses indicate that the reductions in acceptable P-values over time are producing dramatic increases in the Type II error rate. Moreover, the push for a mapwide false discovery rate (FDR) of 0.05 is based on the assumption that this is the FDR in most behavioral research; however, this is an inaccurate assessment of the conventions in actual behavioral research. We report simulations demonstrating that combined intensity and cluster size thresholds such as P {\textbackslash}textless 0.005 with a 10 voxel extent produce a desirable balance between Types I and II error rates. This joint threshold produces high but acceptable Type II error rates and produces a FDR that is comparable to the effective FDR in typical behavioral science articles (while a 20 voxel extent threshold produces an actual FDR of 0.05 with relatively common imaging parameters). We recommend a greater focus on replication and meta-analysis rather than emphasizing single studies as the unit of analysis for establishing scientific truth. From this perspective, Type I errors are self-erasing because they will not replicate, thus allowing for more lenient thresholding to avoid Type II errors.},
	number = {4},
	journal = {Social cognitive and affective neuroscience},
	author = {Lieberman, Matthew D and Cunningham, William A},
	month = dec,
	year = {2009},
	pmid = {20035017},
	pages = {423--8},
}

@article{wager_meta-analysis_2007,
	title = {Meta-analysis of functional neuroimaging data: current and future directions.},
	volume = {2},
	issn = {1749-5024},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18985131 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2555451},
	doi = {10.1093/scan/nsm015},
	abstract = {Meta-analysis is an increasingly popular and valuable tool for summarizing results across many neuroimaging studies. It can be used to establish consensus on the locations of functional regions, test hypotheses developed from patient and animal studies and develop new hypotheses on structure-function correspondence. It is particularly valuable in neuroimaging because most studies do not adequately correct for multiple comparisons; based on statistical thresholds used, we estimate that roughly 10-20\% of reported activations in published studies are false positives. In this article, we briefly summarize some of the most popular meta-analytic approaches and their limitations, and we outline a revised multilevel approach with increased validity for establishing consistency across studies. We also discuss multivariate methods by which meta-analysis can be used to develop and test hypotheses about co-activity of brain regions. Finally, we argue that meta-analyses can make a uniquely valuable contribution to predicting psychological states from patterns of brain activity, and we briefly discuss some methods for making such predictions.},
	number = {2},
	journal = {Social cognitive and affective neuroscience},
	author = {Wager, Tor D and Lindquist, Martin and Kaplan, Lauren},
	month = jun,
	year = {2007},
	pmid = {18985131},
	pages = {150--8},
}

@article{nichols_controlling_2003,
	title = {Controlling the familywise error rate in functional neuroimaging: a comparative review.},
	volume = {12},
	issn = {0962-2802},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/14599004},
	doi = {10.1191/0962280203sm341ra},
	abstract = {Functional neuroimaging data embodies a massive multiple testing problem, where 100,000 correlated test statistics must be assessed. The familywise error rate, the chance of any false positives is the standard measure of Type I errors in multiple testing. In this paper we review and evaluate three approaches to thresholding images of test statistics: Bonferroni, random field and the permutation test. Owing to recent developments, improved Bonferroni procedures, such as Hochberg's methods, are now applicable to dependent data. Continuous random field methods use the smoothness of the image to adapt to the severity of the multiple testing problem. Also, increased computing power has made both permutation and bootstrap methods applicable to functional neuroimaging. We evaluate these approaches on t images using simulations and a collection of real datasets. We find that Bonferroni-related tests offer little improvement over Bonferroni, while the permutation method offers substantial improvement over the random field method for low smoothness and low degrees of freedom. We also show the limitations of trying to find an equivalent number of independent tests for an image of correlated test statistics.},
	number = {5},
	journal = {Statistical methods in medical research},
	author = {Nichols, Thomas and Hayasaka, Satoru},
	month = oct,
	year = {2003},
	pmid = {14599004},
	pages = {419--46},
}

@article{cox_afni:_2012,
	title = {{AFNI}: what a long strange trip it's been.},
	volume = {62},
	issn = {1095-9572},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21889996 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3246532},
	doi = {10.1016/j.neuroimage.2011.08.056},
	abstract = {AFNI is an open source software package for the analysis and display of functional MRI data. It originated in 1994 to meet the specific needs of researchers at the Medical College of Wisconsin, in particular the mapping of activation maps to Talairach-Tournoux space, but has been expanded steadily since then into a wide-ranging set of tool for FMRI data analyses. AFNI was the first platform for real-time 3D functional activation and registration calculations. One of AFNI's main strengths is its flexibility and transparency. In recent years, significant efforts have been made to increase the user-friendliness of AFNI's FMRI processing stream, with the introduction of "super-scripts" to setup the entire analysis, and graphical front-ends for these managers.},
	number = {2},
	journal = {NeuroImage},
	author = {Cox, Robert W},
	month = aug,
	year = {2012},
	pmid = {21889996},
	pages = {743--7},
}

@article{eklund_cluster_2016,
	title = {Cluster failure: {Why} {fMRI} inferences for spatial extent have inflated false-positive rates.},
	volume = {113},
	issn = {1091-6490},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27357684 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4948312},
	doi = {10.1073/pnas.1602413113},
	abstract = {The most widely used task functional magnetic resonance imaging (fMRI) analyses use parametric statistical methods that depend on a variety of assumptions. In this work, we use real resting-state data and a total of 3 million random task group analyses to compute empirical familywise error rates for the fMRI software packages SPM, FSL, and AFNI, as well as a nonparametric permutation method. For a nominal familywise error rate of 5\%, the parametric statistical methods are shown to be conservative for voxelwise inference and invalid for clusterwise inference. Our results suggest that the principal cause of the invalid cluster inferences is spatial autocorrelation functions that do not follow the assumed Gaussian shape. By comparison, the nonparametric permutation test is found to produce nominal results for voxelwise as well as clusterwise inference. These findings speak to the need of validating the statistical methods being used in the field of neuroimaging.},
	number = {28},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Eklund, Anders and Nichols, Thomas E and Knutsson, Hans},
	month = jul,
	year = {2016},
	pmid = {27357684},
	keywords = {fMRI, cluster inference, false positives, permutation test, statistics},
	pages = {7900--5},
	file = {Attachment:/Users/tito/Zotero/storage/EJQXEKCF/Eklund, Nichols, Knutsson - 2016 - Cluster failure Why fMRI inferences for spatial extent have inflated false-positive rates.pdf:application/pdf},
}

@article{carp_plurality_2012,
	title = {On the plurality of (methodological) worlds: estimating the analytic flexibility of {FMRI} experiments.},
	volume = {6},
	issn = {1662-453X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23087605 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3468892},
	doi = {10.3389/fnins.2012.00149},
	abstract = {How likely are published findings in the functional neuroimaging literature to be false? According to a recent mathematical model, the potential for false positives increases with the flexibility of analysis methods. Functional MRI (fMRI) experiments can be analyzed using a large number of commonly used tools, with little consensus on how, when, or whether to apply each one. This situation may lead to substantial variability in analysis outcomes. Thus, the present study sought to estimate the flexibility of neuroimaging analysis by submitting a single event-related fMRI experiment to a large number of unique analysis procedures. Ten analysis steps for which multiple strategies appear in the literature were identified, and two to four strategies were enumerated for each step. Considering all possible combinations of these strategies yielded 6,912 unique analysis pipelines. Activation maps from each pipeline were corrected for multiple comparisons using five thresholding approaches, yielding 34,560 significance maps. While some outcomes were relatively consistent across pipelines, others showed substantial methods-related variability in activation strength, location, and extent. Some analysis decisions contributed to this variability more than others, and different decisions were associated with distinct patterns of variability across the brain. Qualitative outcomes also varied with analysis parameters: many contrasts yielded significant activation under some pipelines but not others. Altogether, these results reveal considerable flexibility in the analysis of fMRI experiments. This observation, when combined with mathematical simulations linking analytic flexibility with elevated false positive rates, suggests that false positive results may be more prevalent than expected in the literature. This risk of inflated false positive rates may be mitigated by constraining the flexibility of analytic choices or by abstaining from selective analysis reporting.},
	journal = {Frontiers in neuroscience},
	author = {Carp, Joshua},
	year = {2012},
	pmid = {23087605},
	keywords = {fMRI, analysis flexibility, data analysis, false positive results, selective reporting},
	pages = {149},
}

@article{kerr_harking:_1998,
	title = {{HARKing}: hypothesizing after the results are known.},
	volume = {2},
	issn = {1088-8683},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15647155},
	doi = {10.1207/s15327957pspr0203_4},
	abstract = {This article considers a practice in scientific communication termed HARKing (Hypothesizing After the Results are Known). HARKing is defined as presenting a post hoc hypothesis (i.e., one based on or informed by one's results) in one's research report as i f it were, in fact, an a priori hypotheses. Several forms of HARKing are identified and survey data are presented that suggests that at least some forms of HARKing are widely practiced and widely seen as inappropriate. I identify several reasons why scientists might HARK. Then I discuss several reasons why scientists ought not to HARK. It is conceded that the question of whether HARKing ' s costs exceed its benefits is a complex one that ought to be addressed through research, open discussion, and debate. To help stimulate such discussion (and for those such as myself who suspect that HARKing's costs do exceed its benefits), I conclude the article with some suggestions for deterring HARKing.},
	number = {3},
	journal = {Personality and social psychology review : an official journal of the Society for Personality and Social Psychology, Inc},
	author = {Kerr, N L},
	year = {1998},
	pmid = {15647155},
	pages = {196--217},
}

@article{poldrack_long-term_2015,
	title = {Long-term neural and physiological phenotyping of a single human.},
	volume = {6},
	issn = {2041-1723},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26648521 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4682164},
	doi = {10.1038/ncomms9885},
	abstract = {Psychiatric disorders are characterized by major fluctuations in psychological function over the course of weeks and months, but the dynamic characteristics of brain function over this timescale in healthy individuals are unknown. Here, as a proof of concept to address this question, we present the MyConnectome project. An intensive phenome-wide assessment of a single human was performed over a period of 18 months, including functional and structural brain connectivity using magnetic resonance imaging, psychological function and physical health, gene expression and metabolomics. A reproducible analysis workflow is provided, along with open access to the data and an online browser for results. We demonstrate dynamic changes in brain connectivity over the timescales of days to months, and relations between brain connectivity, gene expression and metabolites. This resource can serve as a testbed to study the joint dynamics of human brain and metabolic function over time, an approach that is critical for the development of precision medicine strategies for brain disorders.},
	journal = {Nature communications},
	author = {Poldrack, Russell A and Laumann, Timothy O and Koyejo, Oluwasanmi and Gregory, Brenda and Hover, Ashleigh and Chen, Mei-Yen and Gorgolewski, Krzysztof J and Luci, Jeffrey and Joo, Sung Jun and Boyd, Ryan L and Hunicke-Smith, Scott and Simpson, Zack Booth and Caven, Thomas and Sochat, Vanessa and Shine, James M and Gordon, Evan and Snyder, Abraham Z and Adeyemo, Babatunde and Petersen, Steven E and Glahn, David C and Reese Mckay, D and Curran, Joanne E and Göring, Harald H H and Carless, Melanie A and Blangero, John and Dougherty, Robert and Leemans, Alexander and Handwerker, Daniel A and Frick, Laurie and Marcotte, Edward M and Mumford, Jeanette A},
	month = dec,
	year = {2015},
	pmid = {26648521},
	pages = {8885},
}

@article{mennes_making_2013,
	title = {Making data sharing work: the {FCP}/{INDI} experience.},
	volume = {82},
	issn = {1095-9572},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23123682 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3959872},
	doi = {10.1016/j.neuroimage.2012.10.064},
	abstract = {Over a decade ago, the fMRI Data Center (fMRIDC) pioneered open-access data sharing in the task-based functional neuroimaging community. Well ahead of its time, the fMRIDC effort encountered logistical, sociocultural and funding barriers that impeded the field-wise instantiation of open-access data sharing. In 2009, ambitions for open-access data sharing were revived in the resting state functional MRI community in the form of two grassroots initiatives: the 1000 Functional Connectomes Project (FCP) and its successor, the International Neuroimaging Datasharing Initiative (INDI). Beyond providing open access to thousands of clinical and non-clinical imaging datasets, the FCP and INDI have demonstrated the feasibility of large-scale data aggregation for hypothesis generation and testing. Yet, the success of the FCP and INDI should not be confused with widespread embracement of open-access data sharing. Reminiscent of the challenges faced by fMRIDC, key controversies persist and include participant privacy, the role of informatics, and the logistical and cultural challenges of establishing an open science ethos. We discuss the FCP and INDI in the context of these challenges, highlighting the promise of current initiatives and suggesting solutions for possible pitfalls.},
	journal = {NeuroImage},
	author = {Mennes, Maarten and Biswal, Bharat B and Castellanos, F Xavier and Milham, Michael P},
	month = nov,
	year = {2013},
	pmid = {23123682},
	keywords = {fMRI, Database, Informatics, Neuroinformatics, Open science, Open-access, R-fMRI},
	pages = {683--91},
}

@article{desikan_automated_2006,
	title = {An automated labeling system for subdividing the human cerebral cortex on {MRI} scans into gyral based regions of interest.},
	volume = {31},
	issn = {1053-8119},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16530430},
	doi = {10.1016/j.neuroimage.2006.01.021},
	abstract = {In this study, we have assessed the validity and reliability of an automated labeling system that we have developed for subdividing the human cerebral cortex on magnetic resonance images into gyral based regions of interest (ROIs). Using a dataset of 40 MRI scans we manually identified 34 cortical ROIs in each of the individual hemispheres. This information was then encoded in the form of an atlas that was utilized to automatically label ROIs. To examine the validity, as well as the intra- and inter-rater reliability of the automated system, we used both intraclass correlation coefficients (ICC), and a new method known as mean distance maps, to assess the degree of mismatch between the manual and the automated sets of ROIs. When compared with the manual ROIs, the automated ROIs were highly accurate, with an average ICC of 0.835 across all of the ROIs, and a mean distance error of less than 1 mm. Intra- and inter-rater comparisons yielded little to no difference between the sets of ROIs. These findings suggest that the automated method we have developed for subdividing the human cerebral cortex into standard gyral-based neuroanatomical regions is both anatomically valid and reliable. This method may be useful for both morphometric and functional studies of the cerebral cortex as well as for clinical investigations aimed at tracking the evolution of disease-induced changes over time, including clinical trials in which MRI-based measures are used to examine response to treatment.},
	number = {3},
	journal = {NeuroImage},
	author = {Desikan, Rahul S and Ségonne, Florent and Fischl, Bruce and Quinn, Brian T and Dickerson, Bradford C and Blacker, Deborah and Buckner, Randy L and Dale, Anders M and Maguire, R Paul and Hyman, Bradley T and Albert, Marilyn S and Killiany, Ronald J},
	month = jul,
	year = {2006},
	pmid = {16530430},
	pages = {968--80},
}

@article{van_essen_wu-minn_2013,
	title = {The {WU}-{Minn} {Human} {Connectome} {Project}: an overview.},
	volume = {80},
	issn = {1095-9572},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23684880 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3724347},
	doi = {10.1016/j.neuroimage.2013.05.041},
	abstract = {The Human Connectome Project consortium led by Washington University, University of Minnesota, and Oxford University is undertaking a systematic effort to map macroscopic human brain circuits and their relationship to behavior in a large population of healthy adults. This overview article focuses on progress made during the first half of the 5-year project in refining the methods for data acquisition and analysis. Preliminary analyses based on a finalized set of acquisition and preprocessing protocols demonstrate the exceptionally high quality of the data from each modality. The first quarterly release of imaging and behavioral data via the ConnectomeDB database demonstrates the commitment to making HCP datasets freely accessible. Altogether, the progress to date provides grounds for optimism that the HCP datasets and associated methods and software will become increasingly valuable resources for characterizing human brain connectivity and function, their relationship to behavior, and their heritability and genetic underpinnings.},
	journal = {NeuroImage},
	author = {Van Essen, David C and Smith, Stephen M and Barch, Deanna M and Behrens, Timothy E J and Yacoub, Essa and Ugurbil, Kamil and {WU-Minn HCP Consortium}},
	month = oct,
	year = {2013},
	pmid = {23684880},
	pages = {62--79},
	file = {Attachment:/Users/tito/Zotero/storage/Q7W6RY4W/Van Essen et al. - 2013 - The WU-Minn Human Connectome Project an overview.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/2VR7VG28/Van Essen et al. - 2013 - The WU-Minn Human Connectome Project an overview.pdf:application/pdf},
}

@article{worsley_unified_1996,
	title = {A unified statistical approach for determining significant signals in images of cerebral activation.},
	volume = {4},
	issn = {1065-9471},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20408186},
	doi = {10.1002/(SICI)1097-0193(1996)4:1<58::AID-HBM4>3.0.CO;2-O},
	abstract = {We present a unified statistical theory for assessing the significance of apparent signal observed in noisy difference images. The results are usable in a wide range of applications, including fMRI, but are discussed with particular reference to PET images which represent changes in cerebral blood flow elicited by a specific cognitive or sensorimotor task. Our main result is an estimate of the P-value for local maxima of Gaussian, t, chi(2) and F fields over search regions of any shape or size in any number of dimensions. This unifies the P-values for large search areas in 2-D (Friston et al. [1991]: J Cereb Blood Flow Metab 11:690-699) large search regions in 3-D (Worsley et al. [1992]: J Cereb Blood Flow Metab 12:900-918) and the usual uncorrected P-value at a single pixel or voxel.},
	number = {1},
	journal = {Human brain mapping},
	author = {Worsley, K J and Marrett, S and Neelin, P and Vandal, A C and Friston, K J and Evans, A C},
	year = {1996},
	pmid = {20408186},
	pages = {58--73},
}

@article{jenkinson_fsl._2012,
	title = {{FSL}.},
	volume = {62},
	issn = {1095-9572},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21979382},
	doi = {10.1016/j.neuroimage.2011.09.015},
	abstract = {FSL (the FMRIB Software Library) is a comprehensive library of analysis tools for functional, structural and diffusion MRI brain imaging data, written mainly by members of the Analysis Group, FMRIB, Oxford. For this NeuroImage special issue on "20 years of fMRI" we have been asked to write about the history, developments and current status of FSL. We also include some descriptions of parts of FSL that are not well covered in the existing literature. We hope that some of this content might be of interest to users of FSL, and also maybe to new research groups considering creating, releasing and supporting new software packages for brain image analysis.},
	number = {2},
	journal = {NeuroImage},
	author = {Jenkinson, Mark and Beckmann, Christian F and Behrens, Timothy E J and Woolrich, Mark W and Smith, Stephen M},
	month = aug,
	year = {2012},
	pmid = {21979382},
	pages = {782--90},
}

@article{friston_comparing_1991,
	title = {Comparing functional ({PET}) images: the assessment of significant change.},
	volume = {11},
	issn = {0271-678X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/2050758},
	doi = {10.1038/jcbfm.1991.122},
	abstract = {Statistical parametric maps (SPMs) are potentially powerful ways of localizing differences in regional cerebral activity. This potential is limited by uncertainties in assessing the significance of these maps. In this report, we describe an approach that may partially resolve this issue. A distinction is made between using SPMs as images of change significance and using them to identify foci of significant change. In the first case, the SPM can be reported nonselectively as a single mathematical object with its omnibus significance. Alternatively, the SPM constitutes a large number of repeated measures over the brain. To reject the null hypothesis, that no change has occurred at a specific location, a threshold adjustment must be made that accounts for the large number of comparisons made. This adjustment is shown to depend on the SPM's smoothness. Smoothness can be determined empirically and be used to calculate a threshold required to identify significant foci. The approach models the SPM as a stationary stochastic process. The theory and applications are illustrated using uniform phantom images and data from a verbal fluency activation study of four normal subjects.},
	number = {4},
	journal = {Journal of cerebral blood flow and metabolism : official journal of the International Society of Cerebral Blood Flow and Metabolism},
	author = {Friston, K J and Frith, C D and Liddle, P F and Frackowiak, R S},
	month = jul,
	year = {1991},
	pmid = {2050758},
	pages = {690--9},
}

@article{yarkoni_large-scale_2011,
	title = {Large-scale automated synthesis of human functional neuroimaging data.},
	volume = {8},
	issn = {1548-7105},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21706013 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3146590},
	doi = {10.1038/nmeth.1635},
	abstract = {The rapid growth of the literature on neuroimaging in humans has led to major advances in our understanding of human brain function but has also made it increasingly difficult to aggregate and synthesize neuroimaging findings. Here we describe and validate an automated brain-mapping framework that uses text-mining, meta-analysis and machine-learning techniques to generate a large database of mappings between neural and cognitive states. We show that our approach can be used to automatically conduct large-scale, high-quality neuroimaging meta-analyses, address long-standing inferential problems in the neuroimaging literature and support accurate 'decoding' of broad cognitive states from brain activity in both entire studies and individual human subjects. Collectively, our results have validated a powerful and generative framework for synthesizing human neuroimaging data on an unprecedented scale.},
	number = {8},
	journal = {Nature methods},
	author = {Yarkoni, Tal and Poldrack, Russell A and Nichols, Thomas E and Van Essen, David C and Wager, Tor D},
	month = jun,
	year = {2011},
	pmid = {21706013},
	pages = {665--70},
}

@article{david_potential_2013,
	title = {Potential reporting bias in {fMRI} studies of the brain.},
	volume = {8},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23936149 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3723634},
	doi = {10.1371/journal.pone.0070104},
	abstract = {BACKGROUND Functional magnetic resonance imaging (fMRI) studies have reported multiple activation foci associated with a variety of conditions, stimuli or tasks. However, most of these studies used fewer than 40 participants. METHODOLOGY After extracting data (number of subjects, condition studied, number of foci identified and threshold) from 94 brain fMRI meta-analyses (k = 1,788 unique datasets) published through December of 2011, we analyzed the correlation between individual study sample sizes and number of significant foci reported. We also performed an analysis where we evaluated each meta-analysis to test whether there was a correlation between the sample size of the meta-analysis and the number of foci that it had identified. Correlation coefficients were then combined across all meta-analyses to obtain a summary correlation coefficient with a fixed effects model and we combine correlation coefficients, using a Fisher's z transformation. PRINCIPAL FINDINGS There was no correlation between sample size and the number of foci reported in single studies (r = 0.0050) but there was a strong correlation between sample size and number of foci in meta-analyses (r = 0.62, p{\textbackslash}textless0.001). Only studies with sample sizes {\textbackslash}textless45 identified larger ({\textbackslash}textgreater40) numbers of foci and claimed as many discovered foci as studies with sample sizes ≥ 45, whereas meta-analyses yielded a limited number of foci relative to the yield that would be anticipated from smaller single studies. CONCLUSIONS These results are consistent with possible reporting biases affecting small fMRI studies and suggest the need to promote standardized large-scale evidence in this field. It may also be that small studies may be analyzed and reported in ways that may generate a larger number of claimed foci or that small fMRI studies with inconclusive, null, or not very promising results may not be published at all.},
	number = {7},
	journal = {PloS one},
	author = {David, Sean P and Ware, Jennifer J and Chu, Isabella M and Loftus, Pooja D and Fusar-Poli, Paolo and Radua, Joaquim and Munafò, Marcus R and Ioannidis, John P A},
	year = {2013},
	pmid = {23936149},
	pages = {e70104},
}

@article{yarkoni_big_2009,
	title = {Big {Correlations} in {Little} {Studies}: {Inflated} {fMRI} {Correlations} {Reflect} {Low} {Statistical} {Power}-{Commentary} on {Vul} et al. (2009).},
	volume = {4},
	issn = {1745-6916},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26158966},
	doi = {10.1111/j.1745-6924.2009.01127.x},
	abstract = {Vul, Harris, Winkielman, and Pashler (2009), (this issue) argue that correlations in many cognitive neuroscience studies are grossly inflated due to a widespread tendency to use nonindependent analyses. In this article, I argue that Vul et al.'s primary conclusion is correct, but for different reasons than they suggest. I demonstrate that the primary cause of grossly inflated correlations in whole-brain fMRI analyses is not nonindependence, but the pernicious combination of small sample sizes and stringent alpha-correction levels. Far from defusing Vul et al.'s conclusions, the simulations presented suggest that the level of inflation may be even worse than Vul et al.'s empirical analysis would suggest.},
	number = {3},
	journal = {Perspectives on psychological science : a journal of the Association for Psychological Science},
	author = {Yarkoni, Tal},
	month = may,
	year = {2009},
	pmid = {26158966},
	pages = {294--8},
}

@article{button_power_2013,
	title = {Power failure: why small sample size undermines the reliability of neuroscience.},
	volume = {14},
	issn = {1471-0048},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23571845},
	doi = {10.1038/nrn3475},
	abstract = {A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.},
	number = {5},
	journal = {Nature reviews. Neuroscience},
	author = {Button, Katherine S and Ioannidis, John P A and Mokrysz, Claire and Nosek, Brian A and Flint, Jonathan and Robinson, Emma S J and Munafò, Marcus R},
	year = {2013},
	pmid = {23571845},
	keywords = {Humans, Neurosciences, Probability, Reproducibility of Results, Sample Size},
	pages = {365--76},
	file = {Attachment:/Users/tito/Zotero/storage/W7LZGIKX/Button et al. - 2013 - Power failure why small sample size undermines the reliability of neuroscience.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TVTHE88Z/Button et al. - 2013 - Power failure why small sample size undermines the reliability of neuroscience.pdf:application/pdf},
}

@article{ioannidis_meta-research:_2015,
	title = {Meta-research: {Evaluation} and {Improvement} of {Research} {Methods} and {Practices}.},
	volume = {13},
	issn = {1545-7885},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26431313 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4592065},
	doi = {10.1371/journal.pbio.1002264},
	abstract = {As the scientific enterprise has grown in size and diversity, we need empirical evidence on the research process to test and apply interventions that make it more efficient and its results more reliable. Meta-research is an evolving scientific discipline that aims to evaluate and improve research practices. It includes thematic areas of methods, reporting, reproducibility, evaluation, and incentives (how to do, report, verify, correct, and reward science). Much work is already done in this growing field, but efforts to-date are fragmented. We provide a map of ongoing efforts and discuss plans for connecting the multiple meta-research efforts across science worldwide.},
	number = {10},
	journal = {PLoS biology},
	author = {Ioannidis, John P A and Fanelli, Daniele and Dunne, Debbie Drake and Goodman, Steven N},
	month = oct,
	year = {2015},
	pmid = {26431313},
	pages = {e1002264},
}

@article{collins_policy:_2014,
	title = {Policy: {NIH} plans to enhance reproducibility.},
	volume = {505},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24482835 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4058759},
	doi = {10.1038/505612a},
	number = {7485},
	journal = {Nature},
	author = {Collins, Francis S and Tabak, Lawrence A},
	month = jan,
	year = {2014},
	pmid = {24482835},
	pages = {612--3},
}

@article{ioannidis_why_2005,
	title = {Why most published research findings are false.},
	volume = {2},
	issn = {1549-1676},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16060722 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC1182327},
	doi = {10.1371/journal.pmed.0020124},
	abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
	number = {8},
	journal = {PLoS medicine},
	author = {Ioannidis, John P A},
	month = aug,
	year = {2005},
	pmid = {16060722},
	pages = {e124},
}

@article{boulesteix_ten_2015,
	title = {Ten simple rules for reducing overoptimistic reporting in methodological computational research},
	volume = {11},
	doi = {10.1371/journal.pcbi.1004191},
	journal = {PLoS Comput. Biol.},
	author = {Boulesteix, A.-L.},
	year = {2015},
}

@article{simmons_false-positive_2011,
	title = {False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant.},
	volume = {22},
	issn = {1467-9280},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22006061},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	number = {11},
	journal = {Psychological science},
	author = {Simmons, Joseph P and Nelson, Leif D and Simonsohn, Uri},
	month = nov,
	year = {2011},
	pmid = {22006061},
	pages = {1359--66},
}

@article{biswal_toward_2010,
	title = {Toward discovery science of human brain function.},
	volume = {107},
	issn = {1091-6490},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20176931 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2842060},
	doi = {10.1073/pnas.0911855107},
	abstract = {Although it is being successfully implemented for exploration of the genome, discovery science has eluded the functional neuroimaging community. The core challenge remains the development of common paradigms for interrogating the myriad functional systems in the brain without the constraints of a priori hypotheses. Resting-state functional MRI (R-fMRI) constitutes a candidate approach capable of addressing this challenge. Imaging the brain during rest reveals large-amplitude spontaneous low-frequency ({\textbackslash}textless0.1 Hz) fluctuations in the fMRI signal that are temporally correlated across functionally related areas. Referred to as functional connectivity, these correlations yield detailed maps of complex neural systems, collectively constituting an individual's "functional connectome." Reproducibility across datasets and individuals suggests the functional connectome has a common architecture, yet each individual's functional connectome exhibits unique features, with stable, meaningful interindividual differences in connectivity patterns and strengths. Comprehensive mapping of the functional connectome, and its subsequent exploitation to discern genetic influences and brain-behavior relationships, will require multicenter collaborative datasets. Here we initiate this endeavor by gathering R-fMRI data from 1,414 volunteers collected independently at 35 international centers. We demonstrate a universal architecture of positive and negative functional connections, as well as consistent loci of inter-individual variability. Age and sex emerged as significant determinants. These results demonstrate that independent R-fMRI datasets can be aggregated and shared. High-throughput R-fMRI can provide quantitative phenotypes for molecular genetic studies and biomarkers of developmental and pathological processes in the brain. To initiate discovery science of brain function, the 1000 Functional Connectomes Project dataset is freely accessible at www.nitrc.org/projects/fcon\_1000/.},
	number = {10},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Biswal, Bharat B and Mennes, Maarten and Zuo, Xi-Nian and Gohel, Suril and Kelly, Clare and Smith, Steve M and Beckmann, Christian F and Adelstein, Jonathan S and Buckner, Randy L and Colcombe, Stan and Dogonowski, Anne-Marie and Ernst, Monique and Fair, Damien and Hampson, Michelle and Hoptman, Matthew J and Hyde, James S and Kiviniemi, Vesa J and Kötter, Rolf and Li, Shi-Jiang and Lin, Ching-Po and Lowe, Mark J and Mackay, Clare and Madden, David J and Madsen, Kristoffer H and Margulies, Daniel S and Mayberg, Helen S and McMahon, Katie and Monk, Christopher S and Mostofsky, Stewart H and Nagel, Bonnie J and Pekar, James J and Peltier, Scott J and Petersen, Steven E and Riedl, Valentin and Rombouts, Serge A R B and Rypma, Bart and Schlaggar, Bradley L and Schmidt, Sein and Seidler, Rachael D and Siegle, Greg J and Sorg, Christian and Teng, Gao-Jun and Veijola, Juha and Villringer, Arno and Walter, Martin and Wang, Lihong and Weng, Xu-Chu and Whitfield-Gabrieli, Susan and Williamson, Peter and Windischberger, Christian and Zang, Yu-Feng and Zhang, Hong-Ying and Castellanos, F Xavier and Milham, Michael P},
	month = mar,
	year = {2010},
	pmid = {20176931},
	pages = {4734--9},
}

@article{kriegeskorte_matching_2008,
	title = {Matching categorical object representations in inferior temporal cortex of man and monkey.},
	volume = {60},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19109916 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3143574},
	doi = {10.1016/j.neuron.2008.10.043},
	abstract = {Inferior temporal (IT) object representations have been intensively studied in monkeys and humans, but representations of the same particular objects have never been compared between the species. Moreover, IT's role in categorization is not well understood. Here, we presented monkeys and humans with the same images of real-world objects and measured the IT response pattern elicited by each image. In order to relate the representations between the species and to computational models, we compare response-pattern dissimilarity matrices. IT response patterns form category clusters, which match between man and monkey. The clusters correspond to animate and inanimate objects; within the animate objects, faces and bodies form subclusters. Within each category, IT distinguishes individual exemplars, and the within-category exemplar similarities also match between the species. Our findings suggest that primate IT across species may host a common code, which combines a categorical and a continuous representation of objects.},
	number = {6},
	journal = {Neuron},
	author = {Kriegeskorte, Nikolaus and Mur, Marieke and Ruff, Douglas A and Kiani, Roozbeh and Bodurka, Jerzy and Esteky, Hossein and Tanaka, Keiji and Bandettini, Peter A},
	month = dec,
	year = {2008},
	pmid = {19109916},
	pages = {1126--41},
}

@article{poldrack_inferring_2011,
	title = {Inferring mental states from neuroimaging data: from reverse inference to large-scale decoding.},
	volume = {72},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22153367 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3240863},
	doi = {10.1016/j.neuron.2011.11.001},
	abstract = {A common goal of neuroimaging research is to use imaging data to identify the mental processes that are engaged when a subject performs a mental task. The use of reasoning from activation to mental functions, known as "reverse inference," has been previously criticized on the basis that it does not take into account how selectively the area is activated by the mental process in question. In this Perspective, I outline the critique of informal reverse inference and describe a number of new developments that provide the ability to more formally test the predictive power of neuroimaging data.},
	number = {5},
	journal = {Neuron},
	author = {Poldrack, Russell A},
	month = dec,
	year = {2011},
	pmid = {22153367},
	pages = {692--7},
}

@article{norman_beyond_2006,
	title = {Beyond mind-reading: multi-voxel pattern analysis of {fMRI} data.},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16899397},
	doi = {10.1016/j.tics.2006.07.005},
	abstract = {A key challenge for cognitive neuroscience is determining how mental representations map onto patterns of neural activity. Recently, researchers have started to address this question by applying sophisticated pattern-classification algorithms to distributed (multi-voxel) patterns of functional MRI data, with the goal of decoding the information that is represented in the subject's brain at a particular point in time. This multi-voxel pattern analysis (MVPA) approach has led to several impressive feats of mind reading. More importantly, MVPA methods constitute a useful new tool for advancing our understanding of neural information processing. We review how researchers are using MVPA methods to characterize neural coding and information processing in domains ranging from visual perception to memory search.},
	number = {9},
	journal = {Trends in cognitive sciences},
	author = {Norman, Kenneth A and Polyn, Sean M and Detre, Greg J and Haxby, James V},
	month = sep,
	year = {2006},
	pmid = {16899397},
	pages = {424--30},
	file = {Attachment:/Users/tito/Zotero/storage/PD4RSCAJ/Norman et al. - 2006 - Beyond mind-reading multi-voxel pattern analysis of fMRI data.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/L7HZEINJ/Norman et al. - 2006 - Beyond mind-reading multi-voxel pattern analysis of fMRI data.pdf:application/pdf},
}

@article{logothetis_what_2008,
	title = {What we can do and what we cannot do with {fMRI}.},
	volume = {453},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18548064},
	doi = {10.1038/nature06976},
	abstract = {Functional magnetic resonance imaging (fMRI) is currently the mainstay of neuroimaging in cognitive neuroscience. Advances in scanner technology, image acquisition protocols, experimental design, and analysis methods promise to push forward fMRI from mere cartography to the true study of brain organization. However, fundamental questions concerning the interpretation of fMRI data abound, as the conclusions drawn often ignore the actual limitations of the methodology. Here I give an overview of the current state of fMRI, and draw on neuroimaging and physiological data to present the current understanding of the haemodynamic signals and the constraints they impose on neuroimaging data interpretation.},
	number = {7197},
	journal = {Nature},
	author = {Logothetis, Nikos K},
	month = jun,
	year = {2008},
	pmid = {18548064},
	pages = {869--78},
}

@article{poldrack_progress_2015,
	title = {Progress and challenges in probing the human brain.},
	volume = {526},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26469048},
	doi = {10.1038/nature15692},
	abstract = {Perhaps one of the greatest scientific challenges is to understand the human brain. Here we review current methods in human neuroscience, highlighting the ways that they have been used to study the neural bases of the human mind. We begin with a consideration of different levels of description relevant to human neuroscience, from molecules to large-scale networks, and then review the methods that probe these levels and the ability of these methods to test hypotheses about causal mechanisms. Functional MRI is considered in particular detail, as it has been responsible for much of the recent growth of human neuroscience research. We briefly review its inferential strengths and weaknesses and present examples of new analytic approaches that allow inferences beyond simple localization of psychological processes. Finally, we review the prospects for real-world applications and new scientific challenges for human neuroscience.},
	number = {7573},
	journal = {Nature},
	author = {Poldrack, Russell A and Farah, Martha J},
	month = oct,
	year = {2015},
	pmid = {26469048},
	pages = {371--9},
}

@article{cole_rapid_2011,
	title = {Rapid {Transfer} of {Abstract} {Rules} to {Novel} {Contexts} in {Human} {Lateral} {Prefrontal} {Cortex}},
	volume = {5},
	issn = {1662-5161},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2011.00142/abstract},
	doi = {10.3389/fnhum.2011.00142},
	abstract = {Flexible, adaptive behavior is thought to rely on abstract rule representations within lateral prefrontal cortex (LPFC), yet it remains unclear how these representations provide such flexibility. We recently demonstrated that humans can learn complex novel tasks in seconds. Here we hypothesized that this impressive mental flexibility may be possible due to rapid transfer of practiced rule representations within LPFC to novel task contexts. We tested this hypothesis using functional MRI and multivariate pattern analysis, classifying LPFC activity patterns across 64 tasks. Classifiers trained to identify abstract rules based on practiced task activity patterns successfully generalized to novel tasks. This suggests humans can transfer practiced rule representations within LPFC to rapidly learn new tasks, facilitating cognitive performance in novel circumstances.},
	journal = {Frontiers in Human Neuroscience},
	author = {Cole, Michael W. and Etzel, Joset A. and Zacks, Jeffrey M. and Schneider, Walter and Braver, Todd S.},
	month = nov,
	year = {2011},
	keywords = {fMRI, fmri, cognitive control, intelligence, Intelligence, multivariate pattern analysis, rapid instructed task learning, rapid instructed},
	pages = {142},
	file = {Attachment:/Users/tito/Zotero/storage/JXVDBT6V/Cole et al. - 2011 - Rapid Transfer of Abstract Rules to Novel Contexts in Human Lateral Prefrontal Cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/P6DAK5JX/Cole et al. - 2011 - Rapid Transfer of Abstract Rules to Novel Contexts in Human Lateral Prefrontal Cortex.pdf:application/pdf},
}

@article{palmigiano_flexible_2017,
	title = {Flexible information routing by transient synchrony},
	volume = {20},
	issn = {1097-6256},
	url = {http://dx.doi.org/10.1038/nn.4569 http://10.0.4.14/nn.4569 http://www.nature.com/neuro/journal/v20/n7/abs/nn.4569.html#supplementary-information},
	abstract = {Perception, cognition and behavior rely on flexible communication between microcircuits in distinct cortical regions. The mechanisms underlying rapid information rerouting between such microcircuits are still unknown. It has been proposed that changing patterns of coherence between local gamma rhythms support flexible information rerouting. The stochastic and transient nature of gamma oscillations in vivo, however, is hard to reconcile with such a function. Here we show that models of cortical circuits near the onset of oscillatory synchrony selectively route input signals despite the short duration of gamma bursts and the irregularity of neuronal firing. In canonical multiarea circuits, we find that gamma bursts spontaneously arise with matched timing and frequency and that they organize information flow by large-scale routing states. Specific self-organized routing states can be induced by minor modulations of background activity.},
	number = {7},
	journal = {Nat Neurosci},
	author = {Palmigiano, Agostina and Geisel, Theo and Wolf, Fred and Battaglia, Demian},
	month = jul,
	year = {2017},
	pages = {1014--1022},
	file = {Attachment:/Users/tito/Zotero/storage/L7I2J2LJ/Palmigiano et al. - 2017 - Flexible information routing by transient synchrony.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/C4DZDQS7/Palmigiano et al. - 2017 - Flexible information routing by transient synchrony.pdf:application/pdf},
}

@article{pinotsis_intersubject_2016,
	title = {Intersubject variability and induced gamma in the visual cortex: {DCM} with empirical {Bayes} and neural fields},
	volume = {37},
	issn = {10659471},
	url = {http://doi.wiley.com/10.1002/hbm.23331},
	doi = {10.1002/hbm.23331},
	number = {12},
	journal = {Human Brain Mapping},
	author = {Pinotsis, Dimitris A. and Perry, Gavin and Litvak, Vladimir and Singh, Krish D. and Friston, Karl J.},
	month = dec,
	year = {2016},
	pages = {4597--4614},
}

@article{frenzel_partial_2007,
	title = {Partial mutual information for coupling analysis of multivariate time series.},
	volume = {99},
	issn = {0031-9007},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18233144},
	doi = {10.1103/PhysRevLett.99.204101},
	abstract = {We propose a method to discover couplings in multivariate time series, based on partial mutual information, an information-theoretic generalization of partial correlation. It represents the part of mutual information of two random quantities that is not contained in a third one. By suitable choice of the latter, we can differentiate between direct and indirect interactions and derive an appropriate graphical model. An efficient estimator for partial mutual information is presented as well.},
	number = {20},
	journal = {Physical review letters},
	author = {Frenzel, Stefan and Pompe, Bernd},
	month = nov,
	year = {2007},
	pmid = {18233144},
	pages = {204101},
}

@article{vakorin_confounding_2009,
	title = {Confounding effects of indirect connections on causality estimation.},
	volume = {184},
	issn = {1872-678X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19628006},
	doi = {10.1016/j.jneumeth.2009.07.014},
	abstract = {Addressing the issue of effective connectivity, this study focuses on effects of indirect connections on inferring stable causal relations: partial transfer entropy. We introduce a Granger causality measure based on a multivariate version of transfer entropy. The statistic takes into account the influence of the rest of the network (environment) on observed coupling between two given nodes. This formalism allows us to quantify, for a specific pathway, the total amount of indirect coupling mediated by the environment. We show that partial transfer entropy is a more sensitive technique to identify robust causal relations than its bivariate equivalent. In addition, we demonstrate the confounding effects of the variation in indirect coupling on the detectability of robust causal links. Finally, we consider the problem of model misspecification and its effect on the robustness of the observed connectivity patterns, showing that misspecifying the model may be an issue even for model-free information-theoretic approach.},
	number = {1},
	journal = {Journal of neuroscience methods},
	author = {Vakorin, Vasily A and Krakovska, Olga A and McIntosh, Anthony R},
	month = oct,
	year = {2009},
	pmid = {19628006},
	pages = {152--60},
}

@article{orlandi_transfer_2014,
	title = {Transfer entropy reconstruction and labeling of neuronal connections from simulated calcium imaging.},
	volume = {9},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24905689 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4048312},
	doi = {10.1371/journal.pone.0098842},
	abstract = {Neuronal dynamics are fundamentally constrained by the underlying structural network architecture, yet much of the details of this synaptic connectivity are still unknown even in neuronal cultures in vitro. Here we extend a previous approach based on information theory, the Generalized Transfer Entropy, to the reconstruction of connectivity of simulated neuronal networks of both excitatory and inhibitory neurons. We show that, due to the model-free nature of the developed measure, both kinds of connections can be reliably inferred if the average firing rate between synchronous burst events exceeds a small minimum frequency. Furthermore, we suggest, based on systematic simulations, that even lower spontaneous inter-burst rates could be raised to meet the requirements of our reconstruction algorithm by applying a weak spatially homogeneous stimulation to the entire network. By combining multiple recordings of the same in silico network before and after pharmacologically blocking inhibitory synaptic transmission, we show then how it becomes possible to infer with high confidence the excitatory or inhibitory nature of each individual neuron.},
	number = {6},
	journal = {PloS one},
	author = {Orlandi, Javier G and Stetter, Olav and Soriano, Jordi and Geisel, Theo and Battaglia, Demian},
	year = {2014},
	pmid = {24905689},
	pages = {e98842},
}

@article{stetter_model-free_2012,
	title = {Model-free reconstruction of excitatory neuronal connectivity from calcium imaging signals.},
	volume = {8},
	issn = {1553-7358},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22927808 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3426566},
	doi = {10.1371/journal.pcbi.1002653},
	abstract = {A systematic assessment of global neural network connectivity through direct electrophysiological assays has remained technically infeasible, even in simpler systems like dissociated neuronal cultures. We introduce an improved algorithmic approach based on Transfer Entropy to reconstruct structural connectivity from network activity monitored through calcium imaging. We focus in this study on the inference of excitatory synaptic links. Based on information theory, our method requires no prior assumptions on the statistics of neuronal firing and neuronal connections. The performance of our algorithm is benchmarked on surrogate time series of calcium fluorescence generated by the simulated dynamics of a network with known ground-truth topology. We find that the functional network topology revealed by Transfer Entropy depends qualitatively on the time-dependent dynamic state of the network (bursting or non-bursting). Thus by conditioning with respect to the global mean activity, we improve the performance of our method. This allows us to focus the analysis to specific dynamical regimes of the network in which the inferred functional connectivity is shaped by monosynaptic excitatory connections, rather than by collective synchrony. Our method can discriminate between actual causal influences between neurons and spurious non-causal correlations due to light scattering artifacts, which inherently affect the quality of fluorescence imaging. Compared to other reconstruction strategies such as cross-correlation or Granger Causality methods, our method based on improved Transfer Entropy is remarkably more accurate. In particular, it provides a good estimation of the excitatory network clustering coefficient, allowing for discrimination between weakly and strongly clustered topologies. Finally, we demonstrate the applicability of our method to analyses of real recordings of in vitro disinhibited cortical cultures where we suggest that excitatory connections are characterized by an elevated level of clustering compared to a random graph (although not extreme) and can be markedly non-local.},
	number = {8},
	journal = {PLoS computational biology},
	author = {Stetter, Olav and Battaglia, Demian and Soriano, Jordi and Geisel, Theo},
	year = {2012},
	pmid = {22927808},
	pages = {e1002653},
}

@article{ito_extending_2011,
	title = {Extending transfer entropy improves identification of effective connectivity in a spiking cortical network model.},
	volume = {6},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22102894 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3216957},
	doi = {10.1371/journal.pone.0027431},
	abstract = {Transfer entropy (TE) is an information-theoretic measure which has received recent attention in neuroscience for its potential to identify effective connectivity between neurons. Calculating TE for large ensembles of spiking neurons is computationally intensive, and has caused most investigators to probe neural interactions at only a single time delay and at a message length of only a single time bin. This is problematic, as synaptic delays between cortical neurons, for example, range from one to tens of milliseconds. In addition, neurons produce bursts of spikes spanning multiple time bins. To address these issues, here we introduce a free software package that allows TE to be measured at multiple delays and message lengths. To assess performance, we applied these extensions of TE to a spiking cortical network model (Izhikevich, 2006) with known connectivity and a range of synaptic delays. For comparison, we also investigated single-delay TE, at a message length of one bin (D1TE), and cross-correlation (CC) methods. We found that D1TE could identify 36\% of true connections when evaluated at a false positive rate of 1\%. For extended versions of TE, this dramatically improved to 73\% of true connections. In addition, the connections correctly identified by extended versions of TE accounted for 85\% of the total synaptic weight in the network. Cross correlation methods generally performed more poorly than extended TE, but were useful when data length was short. A computational performance analysis demonstrated that the algorithm for extended TE, when used on currently available desktop computers, could extract effective connectivity from 1 hr recordings containing 200 neurons in ∼5 min. We conclude that extending TE to multiple delays and message lengths improves its ability to assess effective connectivity between spiking neurons. These extensions to TE soon could become practical tools for experimentalists who record hundreds of spiking neurons.},
	number = {11},
	journal = {PloS one},
	author = {Ito, Shinya and Hansen, Michael E and Heiland, Randy and Lumsdaine, Andrew and Litke, Alan M and Beggs, John M},
	year = {2011},
	pmid = {22102894},
	pages = {e27431},
}

@article{garofalo_evaluation_2009,
	title = {Evaluation of the performance of information theory-based methods and cross-correlation to estimate the functional connectivity in cortical networks.},
	volume = {4},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19652720 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2715865},
	doi = {10.1371/journal.pone.0006482},
	abstract = {Functional connectivity of in vitro neuronal networks was estimated by applying different statistical algorithms on data collected by Micro-Electrode Arrays (MEAs). First we tested these "connectivity methods" on neuronal network models at an increasing level of complexity and evaluated the performance in terms of ROC (Receiver Operating Characteristic) and PPC (Positive Precision Curve), a new defined complementary method specifically developed for functional links identification. Then, the algorithms better estimated the actual connectivity of the network models, were used to extract functional connectivity from cultured cortical networks coupled to MEAs. Among the proposed approaches, Transfer Entropy and Joint-Entropy showed the best results suggesting those methods as good candidates to extract functional links in actual neuronal networks from multi-site recordings.},
	number = {8},
	journal = {PloS one},
	author = {Garofalo, Matteo and Nieus, Thierry and Massobrio, Paolo and Martinoia, Sergio},
	month = aug,
	year = {2009},
	pmid = {19652720},
	pages = {e6482},
}

@article{honey_network_2007,
	title = {Network structure of cerebral cortex shapes functional connectivity on multiple time scales.},
	volume = {104},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17548818 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC1891224},
	doi = {10.1073/pnas.0701519104},
	abstract = {Neuronal dynamics unfolding within the cerebral cortex exhibit complex spatial and temporal patterns even in the absence of external input. Here we use a computational approach in an attempt to relate these features of spontaneous cortical dynamics to the underlying anatomical connectivity. Simulating nonlinear neuronal dynamics on a network that captures the large-scale interregional connections of macaque neocortex, and applying information theoretic measures to identify functional networks, we find structure-function relations at multiple temporal scales. Functional networks recovered from long windows of neural activity (minutes) largely overlap with the underlying structural network. As a result, hubs in these long-run functional networks correspond to structural hubs. In contrast, significant fluctuations in functional topology are observed across the sequence of networks recovered from consecutive shorter (seconds) time windows. The functional centrality of individual nodes varies across time as interregional couplings shift. Furthermore, the transient couplings between brain regions are coordinated in a manner that reveals the existence of two anticorrelated clusters. These clusters are linked by prefrontal and parietal regions that are hub nodes in the underlying structural network. At an even faster time scale (hundreds of milliseconds) we detect individual episodes of interregional phase-locking and find that slow variations in the statistics of these transient episodes, contingent on the underlying anatomical structure, produce the transfer entropy functional connectivity and simulated blood oxygenation level-dependent correlation patterns observed on slower time scales.},
	number = {24},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Honey, Christopher J and Kötter, Rolf and Breakspear, Michael and Sporns, Olaf},
	month = jun,
	year = {2007},
	pmid = {17548818},
	pages = {10240--5},
	file = {Attachment:/Users/tito/Zotero/storage/ZQ7SL39R/Honey et al. - 2007 - Network structure of cerebral cortex shapes functional connectivity on multiple time scales.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/KSVS7CSQ/Honey et al. - 2007 - Network structure of cerebral cortex shapes functional connectivity on multiple time scales.pdf:application/pdf},
}

@article{gourevitch_evaluating_2007,
	title = {Evaluating information transfer between auditory cortical neurons.},
	volume = {97},
	issn = {0022-3077},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17202243},
	doi = {10.1152/jn.01106.2006},
	abstract = {Transfer entropy, presented as a new tool for investigating neural assemblies, quantifies the fraction of information in a neuron found in the past history of another neuron. The asymmetry of the measure allows feedback evaluations. In particular, this tool has potential applications in investigating windows of temporal integration and stimulus-induced modulation of firing rate. Transfer entropy is also able to eliminate some effects of common history in spike trains and obtains results that are different from cross-correlation. The basic transfer entropy properties are illustrated with simulations. The information transfer through a network of 16 simultaneous multiunit recordings in cat's auditory cortex was examined for a large number of acoustic stimulus types. Application of the transfer entropy to a large database of multiple single-unit activity in cat's primary auditory cortex revealed that most windows of temporal integration found during spontaneous activity range between 2 and 15 ms. The normalized transfer entropy shows similarities and differences with the strength of cross-correlation; these form the basis for revisiting the neural assembly concept.},
	number = {3},
	journal = {Journal of neurophysiology},
	author = {Gourévitch, Boris and Eggermont, Jos J},
	month = mar,
	year = {2007},
	pmid = {17202243},
	pages = {2533--43},
}

@article{wibral_measuring_2013,
	title = {Measuring information-transfer delays.},
	volume = {8},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23468850 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3585400},
	doi = {10.1371/journal.pone.0055809},
	abstract = {In complex networks such as gene networks, traffic systems or brain circuits it is important to understand how long it takes for the different parts of the network to effectively influence one another. In the brain, for example, axonal delays between brain areas can amount to several tens of milliseconds, adding an intrinsic component to any timing-based processing of information. Inferring neural interaction delays is thus needed to interpret the information transfer revealed by any analysis of directed interactions across brain structures. However, a robust estimation of interaction delays from neural activity faces several challenges if modeling assumptions on interaction mechanisms are wrong or cannot be made. Here, we propose a robust estimator for neuronal interaction delays rooted in an information-theoretic framework, which allows a model-free exploration of interactions. In particular, we extend transfer entropy to account for delayed source-target interactions, while crucially retaining the conditioning on the embedded target state at the immediately previous time step. We prove that this particular extension is indeed guaranteed to identify interaction delays between two coupled systems and is the only relevant option in keeping with Wiener's principle of causality. We demonstrate the performance of our approach in detecting interaction delays on finite data by numerical simulations of stochastic and deterministic processes, as well as on local field potential recordings. We also show the ability of the extended transfer entropy to detect the presence of multiple delays, as well as feedback loops. While evaluated on neuroscience data, we expect the estimator to be useful in other fields dealing with network dynamics.},
	number = {2},
	journal = {PloS one},
	author = {Wibral, Michael and Pampu, Nicolae and Priesemann, Viola and Siebenhühner, Felix and Seiwert, Hannes and Lindner, Michael and Lizier, Joseph T and Vicente, Raul},
	year = {2013},
	pmid = {23468850},
	pages = {e55809},
}

@article{vicente_transfer_2011,
	title = {Transfer entropy–a model-free measure of effective connectivity for the neurosciences.},
	volume = {30},
	issn = {1573-6873},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20706781 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3040354},
	doi = {10.1007/s10827-010-0262-3},
	abstract = {Understanding causal relationships, or effective connectivity, between parts of the brain is of utmost importance because a large part of the brain's activity is thought to be internally generated and, hence, quantifying stimulus response relationships alone does not fully describe brain dynamics. Past efforts to determine effective connectivity mostly relied on model based approaches such as Granger causality or dynamic causal modeling. Transfer entropy (TE) is an alternative measure of effective connectivity based on information theory. TE does not require a model of the interaction and is inherently non-linear. We investigated the applicability of TE as a metric in a test for effective connectivity to electrophysiological data based on simulations and magnetoencephalography (MEG) recordings in a simple motor task. In particular, we demonstrate that TE improved the detectability of effective connectivity for non-linear interactions, and for sensor level MEG signals where linear methods are hampered by signal-cross-talk due to volume conduction.},
	number = {1},
	journal = {Journal of computational neuroscience},
	author = {Vicente, Raul and Wibral, Michael and Lindner, Michael and Pipa, Gordon},
	month = feb,
	year = {2011},
	pmid = {20706781},
	pages = {45--67},
}

@article{golomb_number_2000,
	title = {The number of synaptic inputs and the synchrony of large, sparse neuronal networks.},
	volume = {12},
	issn = {0899-7667},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10905810},
	doi = {10.1162/089976600300015529},
	abstract = {The prevalence of coherent oscillations in various frequency ranges in the central nervous system raises the question of the mechanisms that synchronize large populations of neurons. We study synchronization in models of large networks of spiking neurons with random sparse connectivity. Synchrony occurs only when the average number of synapses, M, that a cell receives is larger than a critical value, Mc. Below Mc, the system is in an asynchronous state. In the limit of weak coupling, assuming identical neurons, we reduce the model to a system of phase oscillators that are coupled via an effective interaction, gamma. In this framework, we develop an approximate theory for sparse networks of identical neurons to estimate Mc analytically from the Fourier coefficients of gamma. Our approach relies on the assumption that the dynamics of a neuron depend mainly on the number of cells that are presynaptic to it. We apply this theory to compute Mc for a model of inhibitory networks of integrate-and-fire (I\&F) neurons as a function of the intrinsic neuronal properties (e.g., the refractory period Tr), the synaptic time constants, and the strength of the external stimulus, Iext. The number Mc is found to be nonmonotonous with the strength of Iext. For Tr = 0, we estimate the minimum value of Mc over all the parameters of the model to be 363.8. Above Mc, the neurons tend to fire in smeared one-cluster states at high firing rates and smeared two-or-more-cluster states at low firing rates. Refractoriness decreases Mc at intermediate and high firing rates. These results are compared to numerical simulations. We show numerically that systems with different sizes, N, behave in the same way provided the connectivity, M, is such that 1/Meff = 1/M - 1/N remains constant when N varies. This allows extrapolating the large N behavior of a network from numerical simulations of networks of relatively small sizes (N = 800 in our case). We find that our theory predicts with remarkable accuracy the value of Mc and the patterns of synchrony above Mc, provided the synaptic coupling is not too large. We also study the strong coupling regime of inhibitory sparse networks. All of our simulations demonstrate that increasing the coupling strength reduces the level of synchrony of the neuronal activity. Above a critical coupling strength, the network activity is asynchronous. We point out a fundamental limitation for the mechanisms of synchrony relying on inhibition alone, if heterogeneities in the intrinsic properties of the neurons and spatial fluctuations in the external input are also taken into account.},
	number = {5},
	journal = {Neural computation},
	author = {Golomb, D and Hansel, D},
	month = may,
	year = {2000},
	pmid = {10905810},
	pages = {1095--139},
}

@article{strong_entropy_1998,
	title = {Entropy and information in neural spike trains},
	volume = {80},
	doi = {10.1103/PhysRevLett.80.197},
	journal = {Phys. Rev. Lett.},
	author = {Strong, S.},
	year = {1998},
}

@article{bastos_visual_2015,
	title = {Visual areas exert feedforward and feedback influences through distinct frequency channels.},
	volume = {85},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25556836},
	doi = {10.1016/j.neuron.2014.12.018},
	abstract = {Visual cortical areas subserve cognitive functions by interacting in both feedforward and feedback directions. While feedforward influences convey sensory signals, feedback influences modulate feedforward signaling according to the current behavioral context. We investigated whether these interareal influences are subserved differentially by rhythmic synchronization. We correlated frequency-specific directed influences among 28 pairs of visual areas with anatomical metrics of the feedforward or feedback character of the respective interareal projections. This revealed that in the primate visual system, feedforward influences are carried by theta-band (∼ 4 Hz) and gamma-band (∼ 60-80 Hz) synchronization, and feedback influences by beta-band (∼ 14-18 Hz) synchronization. The functional directed influences constrain a functional hierarchy similar to the anatomical hierarchy, but exhibiting task-dependent dynamic changes in particular with regard to the hierarchical positions of frontal areas. Our results demonstrate that feedforward and feedback signaling use distinct frequency channels, suggesting that they subserve differential communication requirements.},
	number = {2},
	journal = {Neuron},
	author = {Bastos, André Moraes and Vezoli, Julien and Bosman, Conrado Arturo and Schoffelen, Jan-Mathijs and Oostenveld, Robert and Dowdall, Jarrod Robert and De Weerd, Peter and Kennedy, Henry and Fries, Pascal},
	month = jan,
	year = {2015},
	pmid = {25556836},
	pages = {390--401},
}

@article{hipp_large-scale_2012,
	title = {Large-scale cortical correlation structure of spontaneous oscillatory activity.},
	volume = {15},
	issn = {1546-1726},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22561454 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3861400},
	doi = {10.1038/nn.3101},
	abstract = {Little is known about the brain-wide correlation of electrophysiological signals. We found that spontaneous oscillatory neuronal activity exhibited frequency-specific spatial correlation structure in the human brain. We developed an analysis approach that discounts spurious correlation of signal power caused by the limited spatial resolution of electrophysiological measures. We applied this approach to source estimates of spontaneous neuronal activity reconstructed from magnetoencephalography. Overall, correlation of power across cortical regions was strongest in the alpha to beta frequency range (8–32 Hz) and correlation patterns depended on the underlying oscillation frequency. Global hubs resided in the medial temporal lobe in the theta frequency range (4–6 Hz), in lateral parietal areas in the alpha to beta frequency range (8–23 Hz) and in sensorimotor areas for higher frequencies (32–45 Hz). Our data suggest that interactions in various large-scale cortical networks may be reflected in frequency-specific power envelope correlations.},
	number = {6},
	journal = {Nature neuroscience},
	author = {Hipp, Joerg F and Hawellek, David J and Corbetta, Maurizio and Siegel, Markus and Engel, Andreas K},
	month = jun,
	year = {2012},
	pmid = {22561454},
	pages = {884--90},
}

@article{cannon_neurosystems:_2014,
	title = {Neurosystems: brain rhythms and cognitive processing.},
	volume = {39},
	issn = {1460-9568},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24329933 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4916881},
	doi = {10.1111/ejn.12453},
	abstract = {Neuronal rhythms are ubiquitous features of brain dynamics, and are highly correlated with cognitive processing. However, the relationship between the physiological mechanisms producing these rhythms and the functions associated with the rhythms remains mysterious. This article investigates the contributions of rhythms to basic cognitive computations (such as filtering signals by coherence and/or frequency) and to major cognitive functions (such as attention and multi-modal coordination). We offer support to the premise that the physiology underlying brain rhythms plays an essential role in how these rhythms facilitate some cognitive operations.},
	number = {5},
	journal = {The European journal of neuroscience},
	author = {Cannon, Jonathan and McCarthy, Michelle M and Lee, Shane and Lee, Jung and Börgers, Christoph and Whittington, Miles A and Kopell, Nancy},
	month = mar,
	year = {2014},
	pmid = {24329933},
	keywords = {attention, beta rhythm, coherence filtering, frequency filtering, gamma rhythm},
	pages = {705--19},
}

@article{colgin_frequency_2009,
	title = {Frequency of gamma oscillations routes flow of information in the hippocampus.},
	volume = {462},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19924214},
	doi = {10.1038/nature08573},
	abstract = {Gamma oscillations are thought to transiently link distributed cell assemblies that are processing related information, a function that is probably important for network processes such as perception, attentional selection and memory. This 'binding' mechanism requires that spatially distributed cells fire together with millisecond range precision; however, it is not clear how such coordinated timing is achieved given that the frequency of gamma oscillations varies substantially across space and time, from approximately 25 to almost 150 Hz. Here we show that gamma oscillations in the CA1 area of the hippocampus split into distinct fast and slow frequency components that differentially couple CA1 to inputs from the medial entorhinal cortex, an area that provides information about the animal's current position, and CA3, a hippocampal subfield essential for storage of such information. Fast gamma oscillations in CA1 were synchronized with fast gamma in medial entorhinal cortex, and slow gamma oscillations in CA1 were coherent with slow gamma in CA3. Significant proportions of cells in medial entorhinal cortex and CA3 were phase-locked to fast and slow CA1 gamma waves, respectively. The two types of gamma occurred at different phases of the CA1 theta rhythm and mostly on different theta cycles. These results point to routeing of information as a possible function of gamma frequency variations in the brain and provide a mechanism for temporal segregation of potentially interfering information from different sources.},
	number = {7271},
	journal = {Nature},
	author = {Colgin, Laura Lee and Denninger, Tobias and Fyhn, Marianne and Hafting, Torkel and Bonnevie, Tora and Jensen, Ole and Moser, May-Britt and Moser, Edvard I},
	month = nov,
	year = {2009},
	pmid = {19924214},
	pages = {353--7},
}

@article{lisman_theta/gamma_2005,
	title = {The theta/gamma discrete phase code occuring during the hippocampal phase precession may be a more general brain coding scheme.},
	volume = {15},
	issn = {1050-9631},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16161035},
	doi = {10.1002/hipo.20121},
	abstract = {In the hippocampus, oscillations in the theta and gamma frequency range occur together and interact in several ways, indicating that they are part of a common functional system. It is argued that these oscillations form a coding scheme that is used in the hippocampus to organize the readout from long-term memory of the discrete sequence of upcoming places, as cued by current position. This readout of place cells has been analyzed in several ways. First, plots of the theta phase of spikes vs. position on a track show a systematic progression of phase as rats run through a place field. This is termed the phase precession. Second, two cells with nearby place fields have a systematic difference in phase, as indicated by a cross-correlation having a peak with a temporal offset that is a significant fraction of a theta cycle. Third, several different decoding algorithms demonstrate the information content of theta phase in predicting the animal's position. It appears that small phase differences corresponding to jitter within a gamma cycle do not carry information. This evidence, together with the finding that principle cells fire preferentially at a given gamma phase, supports the concept of theta/gamma coding: a given place is encoded by the spatial pattern of neurons that fire in a given gamma cycle (the exact timing within a gamma cycle being unimportant); sequential places are encoded in sequential gamma subcycles of the theta cycle (i.e., with different discrete theta phase). It appears that this general form of coding is not restricted to readout of information from long-term memory in the hippocampus because similar patterns of theta/gamma oscillations have been observed in multiple brain regions, including regions involved in working memory and sensory integration. It is suggested that dual oscillations serve a general function: the encoding of multiple units of information (items) in a way that preserves their serial order. The relationship of such coding to that proposed by Singer and von der Malsburg is discussed; in their scheme, theta is not considered. It is argued that what theta provides is the absolute phase reference needed for encoding order. Theta/gamma coding therefore bears some relationship to the concept of "word" in digital computers, with word length corresponding to the number of gamma cycles within a theta cycle, and discrete phase corresponding to the ordered "place" within a word.},
	number = {7},
	journal = {Hippocampus},
	author = {Lisman, John},
	year = {2005},
	pmid = {16161035},
	pages = {913--22},
}

@article{salazar_content-specific_2012,
	title = {Content-specific fronto-parietal synchronization during visual working memory.},
	volume = {338},
	issn = {1095-9203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23118014 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4038369},
	doi = {10.1126/science.1224000},
	abstract = {Lateral prefrontal and posterior parietal cortical areas exhibit task-dependent activation during working memory tasks in humans and monkeys. Neurons in these regions become synchronized during attention-demanding tasks, but the contribution of these interactions to working memory is largely unknown. Using simultaneous recordings of neural activity from multiple areas in both regions, we find widespread, task-dependent, and content-specific synchronization of activity across the fronto-parietal network during visual working memory. The patterns of synchronization are prevalent among stimulus-selective neurons and are governed by influences arising in parietal cortex. These results indicate that short-term memories are represented by large-scale patterns of synchronized activity across the fronto-parietal network.},
	number = {6110},
	journal = {Science (New York, N.Y.)},
	author = {Salazar, R F and Dotson, N M and Bressler, S L and Gray, C M},
	month = nov,
	year = {2012},
	pmid = {23118014},
	pages = {1097--100},
}

@article{buzsaki_neural_2010,
	title = {Neural syntax: cell assemblies, synapsembles, and readers.},
	volume = {68},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21040841 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3005627},
	doi = {10.1016/j.neuron.2010.09.023},
	abstract = {A widely discussed hypothesis in neuroscience is that transiently active ensembles of neurons, known as "cell assemblies," underlie numerous operations of the brain, from encoding memories to reasoning. However, the mechanisms responsible for the formation and disbanding of cell assemblies and temporal evolution of cell assembly sequences are not well understood. I introduce and review three interconnected topics, which could facilitate progress in defining cell assemblies, identifying their neuronal organization, and revealing causal relationships between assembly organization and behavior. First, I hypothesize that cell assemblies are best understood in light of their output product, as detected by "reader-actuator" mechanisms. Second, I suggest that the hierarchical organization of cell assemblies may be regarded as a neural syntax. Third, constituents of the neural syntax are linked together by dynamically changing constellations of synaptic weights ("synapsembles"). The existing support for this tripartite framework is reviewed and strategies for experimental testing of its predictions are discussed.},
	number = {3},
	journal = {Neuron},
	author = {Buzsáki, György},
	month = nov,
	year = {2010},
	pmid = {21040841},
	pages = {362--85},
}

@article{harris_organization_2003,
	title = {Organization of cell assemblies in the hippocampus.},
	volume = {424},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12891358},
	doi = {10.1038/nature01834},
	abstract = {Neurons can produce action potentials with high temporal precision. A fundamental issue is whether, and how, this capability is used in information processing. According to the 'cell assembly' hypothesis, transient synchrony of anatomically distributed groups of neurons underlies processing of both external sensory input and internal cognitive mechanisms. Accordingly, neuron populations should be arranged into groups whose synchrony exceeds that predicted by common modulation by sensory input. Here we find that the spike times of hippocampal pyramidal cells can be predicted more accurately by using the spike times of simultaneously recorded neurons in addition to the animals location in space. This improvement remained when the spatial prediction was refined with a spatially dependent theta phase modulation. The time window in which spike times are best predicted from simultaneous peer activity is 10-30 ms, suggesting that cell assemblies are synchronized at this timescale. Because this temporal window matches the membrane time constant of pyramidal neurons, the period of the hippocampal gamma oscillation and the time window for synaptic plasticity, we propose that cooperative activity at this timescale is optimal for information transmission and storage in cortical circuits.},
	number = {6948},
	journal = {Nature},
	author = {Harris, Kenneth D and Csicsvari, Jozsef and Hirase, Hajime and Dragoi, George and Buzsáki, György},
	month = jul,
	year = {2003},
	pmid = {12891358},
	pages = {552--6},
}

@article{rigotti_importance_2013,
	title = {The importance of mixed selectivity in complex cognitive tasks.},
	volume = {497},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23685452 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4412347},
	doi = {10.1038/nature12160},
	abstract = {Single-neuron activity in the prefrontal cortex (PFC) is tuned to mixtures of multiple task-related aspects. Such mixed selectivity is highly heterogeneous, seemingly disordered and therefore difficult to interpret. We analysed the neural activity recorded in monkeys during an object sequence memory task to identify a role of mixed selectivity in subserving the cognitive functions ascribed to the PFC. We show that mixed selectivity neurons encode distributed information about all task-relevant aspects. Each aspect can be decoded from the population of neurons even when single-cell selectivity to that aspect is eliminated. Moreover, mixed selectivity offers a significant computational advantage over specialized responses in terms of the repertoire of input-output functions implementable by readout neurons. This advantage originates from the highly diverse nonlinear selectivity to mixtures of task-relevant variables, a signature of high-dimensional neural representations. Crucially, this dimensionality is predictive of animal behaviour as it collapses in error trials. Our findings recommend a shift of focus for future studies from neurons that have easily interpretable response tuning to the widely observed, but rarely analysed, mixed selectivity neurons.},
	number = {7451},
	journal = {Nature},
	author = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang, Xiao-Jing and Daw, Nathaniel D and Miller, Earl K and Fusi, Stefano},
	month = may,
	year = {2013},
	pmid = {23685452},
	keywords = {Behavior, Cognition, Prefrontal Cortex, Models, Neurological, Animals, Neurons, Neurons: physiology, Animal, Animal: physiology, Cognition: physiology, Haplorhini, Haplorhini: physiology, Memory, Memory: physiology, Prefrontal Cortex: cytology, Prefrontal Cortex: physiology, Single-Cell Analysis},
	pages = {585--90},
	file = {Attachment:/Users/tito/Zotero/storage/CTXBEAUG/Rigotti et al. - 2013 - The importance of mixed selectivity in complex cognitive tasks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/69YJZA9Q/Rigotti et al. - 2013 - The importance of mixed selectivity in complex cognitive tasks(2).pdf:application/pdf},
}

@article{osborne_neural_2008,
	title = {The neural basis for combinatorial coding in a cortical population response.},
	volume = {28},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19074026 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2693376},
	doi = {10.1523/JNEUROSCI.4390-08.2008},
	abstract = {We have used a combination of theory and experiment to assess how information is represented in a realistic cortical population response, examining how motion direction and timing is encoded in groups of neurons in cortical area MT. Combining data from several single-unit experiments, we constructed model population responses in small time windows and represented the response in each window as a binary vector of 1s or 0s signifying spikes or no spikes from each cell. We found that patterns of spikes and silence across a population of nominally redundant neurons can carry up to twice as much information about visual motion than does population spike count, even when the neurons respond independently to their sensory inputs. This extra information arises by virtue of the broad diversity of firing rate dynamics found in even very similarly tuned groups of MT neurons. Additionally, specific patterns of spiking and silence can carry more information than the sum of their parts (synergy), opening up the possibility for combinatorial coding in cortex. These results also held for populations in which we imposed levels of nonindependence (correlation) comparable to those found in cortical recordings. Our findings suggest that combinatorial codes are advantageous for representing stimulus information on short time scales, even when neurons have no complicated, stimulus-dependent correlation structure.},
	number = {50},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Osborne, Leslie C and Palmer, Stephanie E and Lisberger, Stephen G and Bialek, William},
	month = dec,
	year = {2008},
	pmid = {19074026},
	pages = {13522--31},
}

@article{dotson_frontoparietal_2014,
	title = {Frontoparietal correlation dynamics reveal interplay between integration and segregation during visual working memory.},
	volume = {34},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25297089 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4188963},
	doi = {10.1523/JNEUROSCI.1961-14.2014},
	abstract = {Working memory requires large-scale cooperation among widespread cortical and subcortical brain regions. Importantly, these processes must achieve an appropriate balance between functional integration and segregation, which are thought to be mediated by task-dependent spatiotemporal patterns of correlated activity. Here, we used cross-correlation analysis to estimate the incidence, magnitude, and relative phase angle of temporally correlated activity from simultaneous local field potential recordings in a network of prefrontal and posterior parietal cortical areas in monkeys performing an oculomotor, delayed match-to-sample task. We found long-range intraparietal and frontoparietal correlations that display a bimodal distribution of relative phase values, centered near 0° and 180°, suggesting a possible basis for functional segregation among distributed networks. Both short- and long-range correlations display striking task-dependent transitions in strength and relative phase, indicating that cognitive events are accompanied by robust changes in the pattern of temporal coordination across the frontoparietal network.},
	number = {41},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Dotson, Nicholas M and Salazar, Rodrigo F and Gray, Charles M},
	month = oct,
	year = {2014},
	pmid = {25297089},
	keywords = {working memory, electrophysiology, frontoparietal, monkey, oscillations, synchrony},
	pages = {13600--13},
}

@article{burkhalter_many_2008,
	title = {Many specialists for suppressing cortical excitation.},
	volume = {2},
	issn = {1662-453X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19225588 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2622740},
	doi = {10.3389/neuro.01.026.2008},
	abstract = {Cortical computations are critically dependent on GABA-releasing neurons for dynamically balancing excitation with inhibition that is proportional to the overall level of activity. Although it is widely accepted that there are multiple types of interneurons, defining their identities based on qualitative descriptions of morphological, molecular and physiological features has failed to produce a universally accepted 'parts list', which is needed to understand the roles that interneurons play in cortical processing. A list of features has been published by the Petilla Interneurons Nomenclature Group, which represents an important step toward an unbiased classification of interneurons. To this end some essential features have recently been studied quantitatively and their association was examined using multidimensional cluster analyses. These studies revealed at least 3 distinct electrophysiological, 6 morphological and 15 molecular phenotypes. This is a conservative estimate of the number of interneuron types, which almost certainly will be revised as more quantitative studies will be performed and similarities will be defined objectively. It is clear that interneurons are organized with physiological attributes representing the most general, molecular characteristics the most detailed and morphological features occupying the middle ground. By themselves, none of these features are sufficient to define classes of interneurons. The challenge will be to determine which features belong together and how cell type-specific feature combinations are genetically specified.},
	number = {2},
	journal = {Frontiers in neuroscience},
	author = {Burkhalter, Andreas},
	month = dec,
	year = {2008},
	pmid = {19225588},
	keywords = {inhibition, cerebral cortex, GABAergic neurons, interneurons},
	pages = {155--67},
}

@article{battaglia_temporal_2007,
	title = {Temporal decorrelation of collective oscillations in neural networks with local inhibition and long-range excitation.},
	volume = {99},
	issn = {0031-9007},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18233419},
	doi = {10.1103/PhysRevLett.99.238106},
	abstract = {We consider two neuronal networks coupled by long-range excitatory interactions. Oscillations in the gamma frequency band are generated within each network by local inhibition. When long-range excitation is weak, these oscillations phase lock with a phase shift dependent on the strength of local inhibition. Increasing the strength of long-range excitation induces a transition to chaos via period doubling or quasiperiodic scenarios. In the chaotic regime, oscillatory activity undergoes fast temporal decorrelation. The generality of these dynamical properties is assessed in firing-rate models as well as in large networks of conductance-based neurons.},
	number = {23},
	journal = {Physical review letters},
	author = {Battaglia, Demian and Brunel, Nicolas and Hansel, David},
	month = dec,
	year = {2007},
	pmid = {18233419},
	pages = {238106},
}

@article{tiesinga_mechanisms_2010,
	title = {Mechanisms for {Phase} {Shifting} in {Cortical} {Networks} and their {Role} in {Communication} through {Coherence}.},
	volume = {4},
	issn = {1662-5161},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21103013 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2987601},
	doi = {10.3389/fnhum.2010.00196},
	abstract = {In the primate visual cortex, the phase of spikes relative to oscillations in the local field potential (LFP) in the gamma frequency range (30-80 Hz) can be shifted by stimulus features such as orientation and thus the phase may carry information about stimulus identity. According to the principle of communication through coherence (CTC), the relative LFP phase between the LFPs in the sending and receiving circuits affects the effectiveness of the transmission. CTC predicts that phase shifting can be used for stimulus selection. We review and investigate phase shifting in models of periodically driven single neurons and compare it with phase shifting in models of cortical networks. In a single neuron, as the driving current is increased, the spike phase varies systematically while the firing rate remains constant. In a network model of reciprocally connected excitatory (E) and inhibitory (I) cells phase shifting occurs in response to both injection of constant depolarizing currents and to brief pulses to I cells. These simple models provide an account for phase-shifting observed experimentally and suggest a mechanism for implementing CTC. We discuss how this hypothesis can be tested experimentally using optogenetic techniques.},
	journal = {Frontiers in human neuroscience},
	author = {Tiesinga, Paul H and Sejnowski, Terrence J},
	year = {2010},
	pmid = {21103013},
	keywords = {attention, synchrony, gamma oscillations, phase locking, phase shifting},
	pages = {196},
}

@article{witt_controlling_2013,
	title = {Controlling the oscillation phase through precisely timed closed-loop optogenetic stimulation: a computational study.},
	volume = {7},
	issn = {1662-5110},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23616748 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3627980},
	doi = {10.3389/fncir.2013.00049},
	abstract = {Dynamic oscillatory coherence is believed to play a central role in flexible communication between brain circuits. To test this communication-through-coherence hypothesis, experimental protocols that allow a reliable control of phase-relations between neuronal populations are needed. In this modeling study, we explore the potential of closed-loop optogenetic stimulation for the control of functional interactions mediated by oscillatory coherence. The theory of non-linear oscillators predicts that the efficacy of local stimulation will depend not only on the stimulation intensity but also on its timing relative to the ongoing oscillation in the target area. Induced phase-shifts are expected to be stronger when the stimulation is applied within specific narrow phase intervals. Conversely, stimulations with the same or even stronger intensity are less effective when timed randomly. Stimulation should thus be properly phased with respect to ongoing oscillations (in order to optimally perturb them) and the timing of the stimulation onset must be determined by a real-time phase analysis of simultaneously recorded local field potentials (LFPs). Here, we introduce an electrophysiologically calibrated model of Channelrhodopsin 2 (ChR2)-induced photocurrents, based on fits holding over two decades of light intensity. Through simulations of a neural population which undergoes coherent gamma oscillations-either spontaneously or as an effect of continuous optogenetic driving-we show that precisely-timed photostimulation pulses can be used to shift the phase of oscillation, even at transduction rates smaller than 25\%. We consider then a canonic circuit with two inter-connected neural populations oscillating with gamma frequency in a phase-locked manner. We demonstrate that photostimulation pulses applied locally to a single population can induce, if precisely phased, a lasting reorganization of the phase-locking pattern and hence modify functional interactions between the two populations.},
	journal = {Frontiers in neural circuits},
	author = {Witt, Annette and Palmigiano, Agostina and Neef, Andreas and El Hady, Ahmed and Wolf, Fred and Battaglia, Demian},
	year = {2013},
	pmid = {23616748},
	keywords = {functional connectivity, modeling, oscillations, closed-loop systems, optogenetic stimulation, phase response},
	pages = {49},
}

@article{canolty_oscillatory_2010,
	title = {Oscillatory phase coupling coordinates anatomically dispersed functional cell assemblies.},
	volume = {107},
	issn = {1091-6490},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20855620 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2951408},
	doi = {10.1073/pnas.1008306107},
	abstract = {Hebb proposed that neuronal cell assemblies are critical for effective perception, cognition, and action. However, evidence for brain mechanisms that coordinate multiple coactive assemblies remains lacking. Neuronal oscillations have been suggested as one possible mechanism for cell assembly coordination. Prior studies have shown that spike timing depends upon local field potential (LFP) phase proximal to the cell body, but few studies have examined the dependence of spiking on distal LFP phases in other brain areas far from the neuron or the influence of LFP-LFP phase coupling between distal areas on spiking. We investigated these interactions by recording LFPs and single-unit activity using multiple microelectrode arrays in several brain areas and then used a unique probabilistic multivariate phase distribution to model the dependence of spike timing on the full pattern of proximal LFP phases, distal LFP phases, and LFP-LFP phase coupling between electrodes. Here we show that spiking activity in single neurons and neuronal ensembles depends on dynamic patterns of oscillatory phase coupling between multiple brain areas, in addition to the effects of proximal LFP phase. Neurons that prefer similar patterns of phase coupling exhibit similar changes in spike rates, whereas neurons with different preferences show divergent responses, providing a basic mechanism to bind different neurons together into coordinated cell assemblies. Surprisingly, phase-coupling-based rate correlations are independent of interneuron distance. Phase-coupling preferences correlate with behavior and neural function and remain stable over multiple days. These findings suggest that neuronal oscillations enable selective and dynamic control of distributed functional cell assemblies.},
	number = {40},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Canolty, Ryan T and Ganguly, Karunesh and Kennerley, Steven W and Cadieu, Charles F and Koepsell, Kilian and Wallis, Jonathan D and Carmena, Jose M},
	month = oct,
	year = {2010},
	pmid = {20855620},
	pages = {17356--61},
}

@article{mazzoni_encoding_2008,
	title = {Encoding of naturalistic stimuli by local field potential spectra in networks of excitatory and inhibitory neurons.},
	volume = {4},
	issn = {1553-7358},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19079571 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2585056},
	doi = {10.1371/journal.pcbi.1000239},
	abstract = {Recordings of local field potentials (LFPs) reveal that the sensory cortex displays rhythmic activity and fluctuations over a wide range of frequencies and amplitudes. Yet, the role of this kind of activity in encoding sensory information remains largely unknown. To understand the rules of translation between the structure of sensory stimuli and the fluctuations of cortical responses, we simulated a sparsely connected network of excitatory and inhibitory neurons modeling a local cortical population, and we determined how the LFPs generated by the network encode information about input stimuli. We first considered simple static and periodic stimuli and then naturalistic input stimuli based on electrophysiological recordings from the thalamus of anesthetized monkeys watching natural movie scenes. We found that the simulated network produced stimulus-related LFP changes that were in striking agreement with the LFPs obtained from the primary visual cortex. Moreover, our results demonstrate that the network encoded static input spike rates into gamma-range oscillations generated by inhibitory-excitatory neural interactions and encoded slow dynamic features of the input into slow LFP fluctuations mediated by stimulus-neural interactions. The model cortical network processed dynamic stimuli with naturalistic temporal structure by using low and high response frequencies as independent communication channels, again in agreement with recent reports from visual cortex responses to naturalistic movies. One potential function of this frequency decomposition into independent information channels operated by the cortical network may be that of enhancing the capacity of the cortical column to encode our complex sensory environment.},
	number = {12},
	journal = {PLoS computational biology},
	author = {Mazzoni, Alberto and Panzeri, Stefano and Logothetis, Nikos K and Brunel, Nicolas},
	month = dec,
	year = {2008},
	pmid = {19079571},
	pages = {e1000239},
}

@article{ecker_decorrelated_2010,
	title = {Decorrelated neuronal firing in cortical microcircuits.},
	volume = {327},
	issn = {1095-9203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20110506},
	doi = {10.1126/science.1179867},
	abstract = {Correlated trial-to-trial variability in the activity of cortical neurons is thought to reflect the functional connectivity of the circuit. Many cortical areas are organized into functional columns, in which neurons are believed to be densely connected and to share common input. Numerous studies report a high degree of correlated variability between nearby cells. We developed chronically implanted multitetrode arrays offering unprecedented recording quality to reexamine this question in the primary visual cortex of awake macaques. We found that even nearby neurons with similar orientation tuning show virtually no correlated variability. Our findings suggest a refinement of current models of cortical microcircuit architecture and function: Either adjacent neurons share only a few percent of their inputs or, alternatively, their activity is actively decorrelated.},
	number = {5965},
	journal = {Science (New York, N.Y.)},
	author = {Ecker, Alexander S and Berens, Philipp and Keliris, Georgios A and Bethge, Matthias and Logothetis, Nikos K and Tolias, Andreas S},
	month = jan,
	year = {2010},
	pmid = {20110506},
	pages = {584--7},
	file = {Attachment:/Users/tito/Zotero/storage/F5523KZM/Ecker et al. - 2010 - Decorrelated neuronal firing in cortical microcircuits.pdf:application/pdf},
}

@article{somers_rapid_1993,
	title = {Rapid synchronization through fast threshold modulation.},
	volume = {68},
	issn = {0340-1200},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/8476980},
	doi = {10.1007/BF00198772},
	abstract = {Synchronization properties of locally coupled neural oscillators were investigated analytically and by computer simulation. When coupled in a manner that mimics excitatory chemical synapses, oscillators having more than one time scale (relaxation oscillators) are shown to approach synchrony using mechanisms very different from that of oscillators with a more sinusoidal waveform. The relaxation oscillators make critical use of fast modulations of their thresholds, leading to a rate of synchronization relatively independent of coupling strength within some basin of attraction; this rate is faster for oscillators that have conductance-based features than for neural caricatures such as the FitzHugh-Nagumo equations that lack such features. Computer simulations of one-dimensional arrays show that oscillators in the relaxation regime synchronize much more rapidly than oscillators with the same equations whose parameters have been modulated to yield a more sinusoidal waveform. We present a heuristic explanation of this effect based on properties of the coupling mechanisms that can affect the way the synchronization scales with array length. These results suggest that the emergent synchronization behavior of oscillating neural networks can be dramatically influenced by the intrinsic properties of the network components. Possible implications for perceptual feature binding and attention are discussed.},
	number = {5},
	journal = {Biological cybernetics},
	author = {Somers, D and Kopell, N},
	year = {1993},
	pmid = {8476980},
	pages = {393--407},
}

@article{bosman_attentional_2012,
	title = {Attentional stimulus selection through selective synchronization between monkey visual areas.},
	volume = {75},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22958827 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3457649},
	doi = {10.1016/j.neuron.2012.06.037},
	abstract = {A central motif in neuronal networks is convergence, linking several input neurons to one target neuron. In visual cortex, convergence renders target neurons responsive to complex stimuli. Yet, convergence typically sends multiple stimuli to a target, and the behaviorally relevant stimulus must be selected. We used two stimuli, activating separate electrocorticographic V1 sites, and both activating an electrocorticographic V4 site equally strongly. When one of those stimuli activated one V1 site, it gamma synchronized (60-80 Hz) to V4. When the two stimuli activated two V1 sites, primarily the relevant one gamma synchronized to V4. Frequency bands of gamma activities showed substantial overlap containing the band of interareal coherence. The relevant V1 site had its gamma peak frequency 2-3 Hz higher than the irrelevant V1 site and 4-6 Hz higher than V4. Gamma-mediated interareal influences were predominantly directed from V1 to V4. We propose that selective synchronization renders relevant input effective, thereby modulating effective connectivity.},
	number = {5},
	journal = {Neuron},
	author = {Bosman, Conrado A and Schoffelen, Jan-Mathijs and Brunet, Nicolas and Oostenveld, Robert and Bastos, Andre M and Womelsdorf, Thilo and Rubehn, Birthe and Stieglitz, Thomas and De Weerd, Peter and Fries, Pascal},
	month = sep,
	year = {2012},
	pmid = {22958827},
	pages = {875--88},
}

@article{schreiber_measuring_2000,
	title = {Measuring information transfer},
	volume = {85},
	issn = {1079-7114},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10991308},
	doi = {10.1103/PhysRevLett.85.461},
	abstract = {An information theoretic measure is derived that quantifies the statistical coherence between systems evolving in time. The standard time delayed mutual information fails to distinguish information that is actually exchanged from shared information due to common history and input signals. In our new approach, these influences are excluded by appropriate conditioning of transition probabilities. The resulting transfer entropy is able to distinguish effectively driving and responding elements and to detect asymmetry in the interaction of subsystems.},
	number = {2},
	journal = {Physical review letters},
	author = {Schreiber, T.},
	month = jul,
	year = {2000},
	pmid = {10991308},
	pages = {461--4},
}

@article{chakrabarti_synchronization_2014,
	title = {Synchronization patterns suggest different functional organization in parietal reach region and dorsal premotor cortex.},
	volume = {112},
	issn = {1522-1598},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25231609},
	doi = {10.1152/jn.00621.2013},
	abstract = {The parietal reach region (PRR) and dorsal premotor cortex (PMd) form part of the fronto-parietal reach network. While neural selectivity profiles of single-cell activity in these areas can be remarkably similar, other data suggest that both areas serve different computational functions in visually guided reaching. Here we test the hypothesis that different neural functional organizations characterized by different neural synchronization patterns might be underlying the putatively different functional roles. We use cross-correlation analysis on single-unit activity (SUA) and multiunit activity (MUA) to determine the prevalence of synchronized neural ensembles within each area. First, we reliably find synchronization in PRR but not in PMd. Second, we demonstrate that synchronization in PRR is present in different cognitive states, including "idle" states prior to task-relevant instructions and without neural tuning. Third, we show that local field potentials (LFPs) in PRR but not PMd are characterized by an increased power and spike field coherence in the beta frequency range (12-30 Hz), further indicating stronger synchrony in PRR compared with PMd. Finally, we show that neurons with similar tuning properties tend to be correlated in their random spike rate fluctuations in PRR but not in PMd. Our data support the idea that PRR and PMd, despite striking similarity in single-cell tuning properties, are characterized by unequal local functional organization, which likely reflects different network architectures to support different functional roles within the fronto-parietal reach network.},
	number = {12},
	journal = {Journal of neurophysiology},
	author = {Chakrabarti, Shubhodeep and Martinez-Vazquez, Pablo and Gail, Alexander},
	month = dec,
	year = {2014},
	pmid = {25231609},
	keywords = {cross-correlation analysis, posterior parietal cortex, visually guided reaching},
	pages = {3138--53},
}

@article{roberts_robust_2013,
	title = {Robust gamma coherence between macaque {V1} and {V2} by dynamic frequency matching.},
	volume = {78},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23664617},
	doi = {10.1016/j.neuron.2013.03.003},
	abstract = {Current theories propose that coherence of oscillatory brain activity in the gamma band (30-80 Hz) constitutes an avenue for communication among remote neural populations. However, reports documenting stimulus dependency and time variability of gamma frequency suggest that distant neuronal populations may, at any one time, operate at different frequencies precluding synchronization. To test this idea, we recorded from macaque V1 and V2 simultaneously while presenting gratings of varying contrast. Although gamma frequency increased with stimulus contrast in V1 and V2 (by ∼25 Hz), V1-V2 gamma coherence was maintained for all contrasts. Moreover, while gamma frequency fluctuated by ∼15 Hz during constant contrast stimulation, this fluctuation was highly correlated between V1 and V2. The strongest coherence connections showed a layer-specific pattern, matching feedforward anatomical connectivity. Hence, gamma coherence among remote populations can occur despite large stimulus-induced and time-dependent changes in gamma frequency, allowing communication through coherence to operate without a stimulus independent, fixed-frequency gamma channel.},
	number = {3},
	journal = {Neuron},
	author = {Roberts, Mark J and Lowet, Eric and Brunet, Nicolas M and Ter Wal, Marije and Tiesinga, Paul and Fries, Pascal and De Weerd, Peter},
	month = may,
	year = {2013},
	pmid = {23664617},
	pages = {523--36},
}

@article{bartos_synaptic_2007,
	title = {Synaptic mechanisms of synchronized gamma oscillations in inhibitory interneuron networks.},
	volume = {8},
	issn = {1471-003X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17180162},
	doi = {10.1038/nrn2044},
	abstract = {Gamma frequency oscillations are thought to provide a temporal structure for information processing in the brain. They contribute to cognitive functions, such as memory formation and sensory processing, and are disturbed in some psychiatric disorders. Fast-spiking, parvalbumin-expressing, soma-inhibiting interneurons have a key role in the generation of these oscillations. Experimental analysis in the hippocampus and the neocortex reveals that synapses among these interneurons are highly specialized. Computational analysis further suggests that synaptic specialization turns interneuron networks into robust gamma frequency oscillators.},
	number = {1},
	journal = {Nature reviews. Neuroscience},
	author = {Bartos, Marlene and Vida, Imre and Jonas, Peter},
	month = jan,
	year = {2007},
	pmid = {17180162},
	pages = {45--56},
}

@article{brunel_what_2003,
	title = {What determines the frequency of fast network oscillations with irregular neural discharges? {I}. {Synaptic} dynamics and excitation-inhibition balance.},
	volume = {90},
	issn = {0022-3077},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12611969},
	doi = {10.1152/jn.01095.2002},
	abstract = {When the local field potential of a cortical network displays coherent fast oscillations ( approximately 40-Hz gamma or approximately 200-Hz sharp-wave ripples), the spike trains of constituent neurons are typically irregular and sparse. The dichotomy between rhythmic local field and stochastic spike trains presents a challenge to the theory of brain rhythms in the framework of coupled oscillators. Previous studies have shown that when noise is large and recurrent inhibition is strong, a coherent network rhythm can be generated while single neurons fire intermittently at low rates compared to the frequency of the oscillation. However, these studies used too simplified synaptic kinetics to allow quantitative predictions of the population rhythmic frequency. Here we show how to derive quantitatively the coherent oscillation frequency for a randomly connected network of leaky integrate-and-fire neurons with realistic synaptic parameters. In a noise-dominated interneuronal network, the oscillation frequency depends much more on the shortest synaptic time constants (delay and rise time) than on the longer synaptic decay time, and approximately 200-Hz frequency can be realized with synaptic time constants taken from slice data. In a network composed of both interneurons and excitatory cells, the rhythmogenesis is a compromise between two scenarios: the fast purely interneuronal mechanism, and the slower feedback mechanism (relying on the excitatory-inhibitory loop). The properties of the rhythm are determined essentially by the ratio of time scales of excitatory and inhibitory currents and by the balance between the mean recurrent excitation and inhibition. Faster excitation than inhibition, or a higher excitation/inhibition ratio, favors the feedback loop and a much slower oscillation (typically in the gamma range).},
	number = {1},
	journal = {Journal of neurophysiology},
	author = {Brunel, Nicolas and Wang, Xiao-Jing},
	month = jul,
	year = {2003},
	pmid = {12611969},
	pages = {415--30},
}

@article{okun_diverse_2015,
	title = {Diverse coupling of neurons to populations in sensory cortex.},
	volume = {521},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25849776 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4449271},
	doi = {10.1038/nature14273},
	abstract = {A large population of neurons can, in principle, produce an astronomical number of distinct firing patterns. In cortex, however, these patterns lie in a space of lower dimension, as if individual neurons were "obedient members of a huge orchestra". Here we use recordings from the visual cortex of mouse (Mus musculus) and monkey (Macaca mulatta) to investigate the relationship between individual neurons and the population, and to establish the underlying circuit mechanisms. We show that neighbouring neurons can differ in their coupling to the overall firing of the population, ranging from strongly coupled 'choristers' to weakly coupled 'soloists'. Population coupling is largely independent of sensory preferences, and it is a fixed cellular attribute, invariant to stimulus conditions. Neurons with high population coupling are more strongly affected by non-sensory behavioural variables such as motor intention. Population coupling reflects a causal relationship, predicting the response of a neuron to optogenetically driven increases in local activity. Moreover, population coupling indicates synaptic connectivity; the population coupling of a neuron, measured in vivo, predicted subsequent in vitro estimates of the number of synapses received from its neighbours. Finally, population coupling provides a compact summary of population activity; knowledge of the population couplings of n neurons predicts a substantial portion of their n(2) pairwise correlations. Population coupling therefore represents a novel, simple measure that characterizes the relationship of each neuron to a larger population, explaining seemingly complex network firing patterns in terms of basic circuit variables.},
	number = {7553},
	journal = {Nature},
	author = {Okun, Michael and Steinmetz, Nicholas and Cossell, Lee and Iacaruso, M Florencia and Ko, Ho and Barthó, Péter and Moore, Tirin and Hofer, Sonja B and Mrsic-Flogel, Thomas D and Carandini, Matteo and Harris, Kenneth D},
	month = may,
	year = {2015},
	pmid = {25849776},
	pages = {511--515},
}

@article{brunel_fast_1999,
	title = {Fast global oscillations in networks of integrate-and-fire neurons with low firing rates.},
	volume = {11},
	issn = {0899-7667},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10490941},
	doi = {10.1162/089976699300016179},
	abstract = {We study analytically the dynamics of a network of sparsely connected inhibitory integrate-and-fire neurons in a regime where individual neurons emit spikes irregularly and at a low rate. In the limit when the number of neurons –{\textbackslash}textgreater infinity, the network exhibits a sharp transition between a stationary and an oscillatory global activity regime where neurons are weakly synchronized. The activity becomes oscillatory when the inhibitory feedback is strong enough. The period of the global oscillation is found to be mainly controlled by synaptic times but depends also on the characteristics of the external input. In large but finite networks, the analysis shows that global oscillations of finite coherence time generically exist both above and below the critical inhibition threshold. Their characteristics are determined as functions of systems parameters in these two different regions. The results are found to be in good agreement with numerical simulations.},
	number = {7},
	journal = {Neural computation},
	author = {Brunel, N and Hakim, V},
	month = oct,
	year = {1999},
	pmid = {10490941},
	pages = {1621--71},
}

@article{jia_no_2013,
	title = {No consistent relationship between gamma power and peak frequency in macaque primary visual cortex.},
	volume = {33},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23283318 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3560843},
	doi = {10.1523/JNEUROSCI.1687-12.2013},
	abstract = {Neural activity in the gamma frequency range ("gamma") is elevated during active cognitive states. Gamma has been proposed to play an important role in cortical function, although this is debated. Understanding what function gamma might fulfill requires a better understanding of its properties and the mechanisms that generate it. Gamma is characterized by its spectral power and peak frequency, and variations in both parameters have been associated with changes in behavioral performance. Modeling studies suggest these properties are co-modulated, but this has not been established. To test the relationship between these properties, we measured local field potentials (LFPs) and neuronal spiking responses in primary visual cortex of anesthetized monkeys, for drifting sinusoidal gratings of different sizes, contrasts, orientations and masked with different levels of noise. We find that there is no fixed relationship between LFP gamma power and peak frequency, and neither is related to the strength of spiking activity. We propose a simple model that can account for the complex stimulus dependence we observe, and suggest that separate mechanisms determine gamma power and peak frequency.},
	number = {1},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Jia, Xiaoxuan and Xing, Dajun and Kohn, Adam},
	month = jan,
	year = {2013},
	pmid = {23283318},
	pages = {17--25},
}

@article{ray_differences_2010,
	title = {Differences in gamma frequencies across visual cortex restrict their possible use in computation.},
	volume = {67},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20826318 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3001273},
	doi = {10.1016/j.neuron.2010.08.004},
	abstract = {Neuronal oscillations in the gamma band (30-80 Hz) have been suggested to play a central role in feature binding or establishing channels for neural communication. For these functions, the gamma rhythm frequency must be consistent across neural assemblies encoding the features of a stimulus. Here we test the dependence of gamma frequency on stimulus contrast in V1 cortex of awake behaving macaques and show that gamma frequency increases monotonically with contrast. Changes in stimulus contrast over time leads to a reliable gamma frequency modulation on a fast timescale. Further, large stimuli whose contrast varies across space generate gamma rhythms at significantly different frequencies in simultaneously recorded neuronal assemblies separated by as little as 400 microm, making the gamma rhythm a poor candidate for binding or communication, at least in V1. Instead, our results suggest that the gamma rhythm arises from local interactions between excitation and inhibition.},
	number = {5},
	journal = {Neuron},
	author = {Ray, Supratim and Maunsell, John H R},
	month = sep,
	year = {2010},
	pmid = {20826318},
	pages = {885--96},
}

@article{ray_gamma_2015,
	title = {Do gamma oscillations play a role in cerebral cortex?},
	volume = {19},
	issn = {1879-307X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25555444 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5403517},
	doi = {10.1016/j.tics.2014.12.002},
	abstract = {Gamma rhythm (which has a center frequency between 30 and 80 Hz) is modulated by cognitive mechanisms such as attention and memory, and has been hypothesized to play a role in mediating these processes by supporting communication channels between cortical areas or encoding information in its phase. We highlight several issues related to gamma rhythms, such as low and inconsistent power, its dependence on low-level stimulus features, problems due to conduction delays, and contamination due to spike-related activity that makes accurate estimation of gamma phase difficult. Gamma rhythm could be a potentially useful signature of excitation-inhibition interactions in the brain, but whether it also provides a mechanism for information processing or coding remains an open question.},
	number = {2},
	journal = {Trends in cognitive sciences},
	author = {Ray, Supratim and Maunsell, John H R},
	month = feb,
	year = {2015},
	pmid = {25555444},
	keywords = {gamma, coherence, communication through coherence, excitation–inhibition, phase coding, spike–LFP relationship},
	pages = {78--85},
}

@article{jia__2013,
	title = {γ and the coordination of spiking activity in early visual cortex.},
	volume = {77},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23439127 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3632874},
	doi = {10.1016/j.neuron.2012.12.036},
	abstract = {Gamma components of the local field potential (LFP) are elevated during cognitive and perceptual processes. It has been suggested that gamma power indicates the strength of neuronal population synchrony, which influences the relaying of signals between cortical areas. However, the relationship between coordinated spiking activity and gamma remains unclear, and the influence on corticocortical signaling largely untested. We investigated these issues by recording from neuronal populations in areas V1 and V2 of anesthetized macaque monkeys. We found that visual stimuli that induce a strong, coherent gamma rhythm result in enhanced pairwise and higher-order V1 synchrony. This is associated with stronger coupling of V1-V2 spiking activity, in a retinotopically specific manner. Coupling is more strongly related to the gamma modulation of V1 firing than to the downstream V2 rhythm. Our results thus show that elevated gamma power is associated with stronger coordination of spiking activity both within and between cortical areas.},
	number = {4},
	journal = {Neuron},
	author = {Jia, Xiaoxuan and Tanabe, Seiji and Kohn, Adam},
	month = feb,
	year = {2013},
	pmid = {23439127},
	pages = {762--74},
}

@article{xing_stochastic_2012,
	title = {Stochastic generation of gamma-band activity in primary visual cortex of awake and anesthetized monkeys.},
	volume = {32},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23035096 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3752128},
	doi = {10.1523/JNEUROSCI.5644-11.2012},
	abstract = {Oscillatory neural activity within the gamma band (25-90 Hz) is generally thought to be able to provide a timing signal for harmonizing neural computations across different brain regions. Using time-frequency analyses of the dynamics of gamma-band activity in the local field potentials recorded from monkey primary visual cortex, we found identical temporal characteristics of gamma activity in both awake and anesthetized brain states, including large variability of peak frequency, brief oscillatory epochs ({\textbackslash}textless100 ms on average), and stochastic statistics of the incidence and duration of oscillatory events. These findings indicate that gamma-band activity is temporally unstructured and is inherently a stochastic signal generated by neural networks. This idea was corroborated further by our neural-network simulations. Our results suggest that gamma-band activity is too random to serve as a clock signal for synchronizing neuronal responses in awake as in anesthetized monkeys. Instead, gamma-band activity is more likely to be filtered neuronal network noise. Its mean frequency changes with global state and is reduced under anesthesia.},
	number = {40},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Xing, Dajun and Shen, Yutai and Burns, Samuel and Yeh, Chun-I and Shapley, Robert and Li, Wu},
	month = oct,
	year = {2012},
	pmid = {23035096},
	pages = {13873--80a},
}

@article{burns_is_2011,
	title = {Is gamma-band activity in the local field potential of {V1} cortex a "clock" or filtered noise?},
	volume = {31},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21715631 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3518456},
	doi = {10.1523/JNEUROSCI.0660-11.2011},
	abstract = {Gamma-band (25-90 Hz) peaks in local field potential (LFP) power spectra are present throughout the cerebral cortex and have been related to perception, attention, memory, and disorders (e.g., schizophrenia and autism). It has been theorized that gamma oscillations provide a "clock" for precise temporal encoding and "binding" of signals about stimulus features across brain regions. For gamma to function as a clock, it must be autocoherent: phase and frequency conserved over a period of time. We computed phase and frequency trajectories of gamma-band bursts, using time-frequency analysis of LFPs recorded in macaque primary visual cortex (V1) during visual stimulation. The data were compared with simulations of random networks and clock signals in noise. Gamma-band bursts in LFP data were statistically indistinguishable from those found in filtered broadband noise. Therefore, V1 LFP data did not contain clock-like gamma-band signals. We consider possible functions for stochastic gamma-band activity, such as a synchronizing pulse signal.},
	number = {26},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Burns, Samuel P and Xing, Dajun and Shapley, Robert M},
	month = jun,
	year = {2011},
	pmid = {21715631},
	pages = {9658--64},
}

@article{grothe_switching_2012,
	title = {Switching neuronal inputs by differential modulations of gamma-band phase-coherence.},
	volume = {32},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23152601},
	doi = {10.1523/JNEUROSCI.0890-12.2012},
	abstract = {Receptive fields (RFs) of cortical sensory neurons increase in size along consecutive processing stages. When multiple stimuli are present in a large visual RF, a neuron typically responds to an attended stimulus as if only that stimulus were present. However, the mechanism by which a neuron selectively responds to a subset of its inputs while discarding all others is unknown. Here, we show that neurons can switch between subsets of their afferent inputs by highly specific modulations of interareal gamma-band phase-coherence (PC). We measured local field potentials, single- and multi-unit activity in two male macaque monkeys (Macaca mulatta) performing an attention task. Two small stimuli were placed on a screen; the stimuli were driving separate local V1 populations, while both were driving the same local V4 population. In each trial, we cued one of the two stimuli to be attended. We found that gamma-band PC of the local V4 population with multiple subpopulations of its V1 input was differentially modulated. It was high with the input subpopulation representing the attended stimulus, while simultaneously it was very low between the same V4 population and the other input-providing subpopulation representing the irrelevant stimulus. These differential modulations, which depend on stimulus relevance, were also found in the locking of spikes from V4 neurons to the gamma-band oscillations of the V1 input subpopulations. This rapid, highly specific interareal locking provides neurons with a powerful dynamic routing mechanism to select and process only the currently relevant signals.},
	number = {46},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Grothe, Iris and Neitzel, Simon D and Mandon, Sunita and Kreiter, Andreas K},
	month = nov,
	year = {2012},
	pmid = {23152601},
	pages = {16172--80},
}

@article{gregoriou_high-frequency_2009,
	title = {High-frequency, long-range coupling between prefrontal and visual cortex during attention.},
	volume = {324},
	issn = {1095-9203},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19478185 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2849291},
	doi = {10.1126/science.1171402},
	abstract = {Electrical recordings in humans and monkeys show attentional enhancement of evoked responses and gamma synchrony in ventral stream cortical areas. Does this synchrony result from intrinsic activity in visual cortex or from inputs from other structures? Using paired recordings in the frontal eye field (FEF) and area V4, we found that attention to a stimulus in their joint receptive field leads to enhanced oscillatory coupling between the two areas, particularly at gamma frequencies. This coupling appeared to be initiated by FEF and was time-shifted by about 8 to 13 milliseconds across a range of frequencies. Considering the expected conduction and synaptic delays between the areas, this time-shifted coupling at gamma frequencies may optimize the postsynaptic impact of spikes from one area upon the other, improving cross-area communication with attention.},
	number = {5931},
	journal = {Science (New York, N.Y.)},
	author = {Gregoriou, Georgia G and Gotts, Stephen J and Zhou, Huihui and Desimone, Robert},
	month = may,
	year = {2009},
	pmid = {19478185},
	pages = {1207--10},
}

@article{harnack_model_2015,
	title = {A model for attentional information routing through coherence predicts biased competition and multistable perception.},
	volume = {114},
	issn = {1522-1598},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26108958 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4563023},
	doi = {10.1152/jn.01038.2014},
	abstract = {Selective attention allows to focus on relevant information and to ignore distracting features of a visual scene. These principles of information processing are reflected in response properties of neurons in visual area V4: if a neuron is presented with two stimuli in its receptive field, and one is attended, it responds as if the nonattended stimulus was absent (biased competition). In addition, when the luminance of the two stimuli is temporally and independently varied, local field potentials are correlated with the modulation of the attended stimulus and not, or much less, correlated with the nonattended stimulus (information routing). To explain these results in one coherent framework, we present a two-layer spiking cortical network model with distance-dependent lateral connectivity and converging feed-forward connections. With oscillations arising inherently from the network structure, our model reproduces both experimental observations. Hereby, lateral interactions and shifts of relative phases between sending and receiving layers (communication through coherence) are identified as the main mechanisms underlying both biased competition as well as selective routing. Exploring the parameter space, we show that the effects are robust and prevalent over a broad range of parameters. In addition, we identify the strength of lateral inhibition in the first model layer as crucial for determining the working regime of the system: increasing lateral inhibition allows a transition from a network configuration with mixed representations to one with bistable representations of the competing stimuli. The latter is discussed as a possible neural correlate of multistable perception phenomena such as binocular rivalry.},
	number = {3},
	journal = {Journal of neurophysiology},
	author = {Harnack, Daniel and Ernst, Udo Alexander and Pawelzik, Klaus Richard},
	month = sep,
	year = {2015},
	pmid = {26108958},
	keywords = {attention, coherence, biased competition, multistable perception, routing},
	pages = {1593--605},
}

@article{hahn_communication_2014,
	title = {Communication through resonance in spiking neuronal networks.},
	volume = {10},
	issn = {1553-7358},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25165853 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4148205},
	doi = {10.1371/journal.pcbi.1003811},
	abstract = {The cortex processes stimuli through a distributed network of specialized brain areas. This processing requires mechanisms that can route neuronal activity across weakly connected cortical regions. Routing models proposed thus far are either limited to propagation of spiking activity across strongly connected networks or require distinct mechanisms that create local oscillations and establish their coherence between distant cortical areas. Here, we propose a novel mechanism which explains how synchronous spiking activity propagates across weakly connected brain areas supported by oscillations. In our model, oscillatory activity unleashes network resonance that amplifies feeble synchronous signals and promotes their propagation along weak connections ("communication through resonance"). The emergence of coherent oscillations is a natural consequence of synchronous activity propagation and therefore the assumption of different mechanisms that create oscillations and provide coherence is not necessary. Moreover, the phase-locking of oscillations is a side effect of communication rather than its requirement. Finally, we show how the state of ongoing activity could affect the communication through resonance and propose that modulations of the ongoing activity state could influence information processing in distributed cortical networks.},
	number = {8},
	journal = {PLoS computational biology},
	author = {Hahn, Gerald and Bujan, Alejandro F and Frégnac, Yves and Aertsen, Ad and Kumar, Arvind},
	month = aug,
	year = {2014},
	pmid = {25165853},
	pages = {e1003811},
}

@article{zylberberg_brains_2010,
	title = {The brain's router: a cortical network model of serial processing in the primate brain.},
	volume = {6},
	issn = {1553-7358},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20442869 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2861701},
	doi = {10.1371/journal.pcbi.1000765},
	abstract = {The human brain efficiently solves certain operations such as object recognition and categorization through a massively parallel network of dedicated processors. However, human cognition also relies on the ability to perform an arbitrarily large set of tasks by flexibly recombining different processors into a novel chain. This flexibility comes at the cost of a severe slowing down and a seriality of operations (100-500 ms per step). A limit on parallel processing is demonstrated in experimental setups such as the psychological refractory period (PRP) and the attentional blink (AB) in which the processing of an element either significantly delays (PRP) or impedes conscious access (AB) of a second, rapidly presented element. Here we present a spiking-neuron implementation of a cognitive architecture where a large number of local parallel processors assemble together to produce goal-driven behavior. The precise mapping of incoming sensory stimuli onto motor representations relies on a "router" network capable of flexibly interconnecting processors and rapidly changing its configuration from one task to another. Simulations show that, when presented with dual-task stimuli, the network exhibits parallel processing at peripheral sensory levels, a memory buffer capable of keeping the result of sensory processing on hold, and a slow serial performance at the router stage, resulting in a performance bottleneck. The network captures the detailed dynamics of human behavior during dual-task-performance, including both mean RTs and RT distributions, and establishes concrete predictions on neuronal dynamics during dual-task experiments in humans and non-human primates.},
	number = {4},
	journal = {PLoS computational biology},
	author = {Zylberberg, Ariel and Fernández Slezak, Diego and Roelfsema, Pieter R and Dehaene, Stanislas and Sigman, Mariano},
	month = apr,
	year = {2010},
	pmid = {20442869},
	pages = {e1000765},
}

@article{akam_oscillations_2010,
	title = {Oscillations and filtering networks support flexible routing of information.},
	volume = {67},
	issn = {1097-4199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20670837 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3125699},
	doi = {10.1016/j.neuron.2010.06.019},
	abstract = {The mammalian brain exhibits profuse interregional connectivity. How information flow is rapidly and flexibly switched among connected areas remains poorly understood. Task-dependent changes in the power and interregion coherence of network oscillations suggest that such oscillations play a role in signal routing. We show that switching one of several convergent pathways from an asynchronous to an oscillatory state allows accurate selective transmission of population-coded information, which can be extracted even when other convergent pathways fire asynchronously at comparable rates. We further show that the band-pass filtering required to perform this information extraction can be implemented in a simple spiking network model with a single feed-forward interneuron layer. This constitutes a mechanism for flexible signal routing in neural circuits, which exploits sparsely synchronized network oscillations and temporal filtering by feed-forward inhibition.},
	number = {2},
	journal = {Neuron},
	author = {Akam, Thomas and Kullmann, Dimitri M},
	month = jul,
	year = {2010},
	pmid = {20670837},
	pages = {308--20},
}

@article{abeles_modeling_2004,
	title = {Modeling compositionality by dynamic binding of synfire chains.},
	volume = {17},
	issn = {0929-5313},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15306739},
	doi = {10.1023/B:JCNS.0000037682.18051.5f},
	abstract = {This paper examines the feasibility of manifesting compositionality by a system of synfire chains. Compositionality is the ability to construct mental representations, hierarchically, in terms of parts and their relations. We show that synfire chains may synchronize their waves when a few orderly cross links are available. We propose that synchronization among synfire chains can be used for binding component into a whole. Such synchronization is shown both for detailed simulations, and by numerical analysis of the propagation of a wave along a synfire chain. We show that global inhibition may prevent spurious synchronization among synfire chains. We further show that selecting which synfire chains may synchronize to which others may be improved by including inhibitory neurons in the synfire pools. Finally we show that in a hierarchical system of synfire chains, a part-binding problem may be resolved, and that such a system readily demonstrates the property of priming. We compare the properties of our system with the general requirements for neural networks that demonstrate compositionality.},
	number = {2},
	journal = {Journal of computational neuroscience},
	author = {Abeles, Moshe and Hayon, Gaby and Lehmann, Daniel},
	year = {2004},
	pmid = {15306739},
	pages = {179--201},
}

@article{vogels_gating_2009,
	title = {Gating multiple signals through detailed balance of excitation and inhibition in spiking networks.},
	volume = {12},
	issn = {1546-1726},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19305402 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2693069},
	doi = {10.1038/nn.2276},
	abstract = {Recent theoretical work has provided a basic understanding of signal propagation in networks of spiking neurons, but mechanisms for gating and controlling these signals have not been investigated previously. Here we introduce an idea for the gating of multiple signals in cortical networks that combines principles of signal propagation with aspects of balanced networks. Specifically, we studied networks in which incoming excitatory signals are normally cancelled by locally evoked inhibition, leaving the targeted layer unresponsive. Transmission can be gated 'on' by modulating excitatory and inhibitory gains to upset this detailed balance. We illustrate gating through detailed balance in large networks of integrate-and-fire neurons. We show successful gating of multiple signals and study failure modes that produce effects reminiscent of clinically observed pathologies. Provided that the individual signals are detectable, detailed balance has a large capacity for gating multiple signals.},
	number = {4},
	journal = {Nature neuroscience},
	author = {Vogels, Tim P and Abbott, L F},
	month = apr,
	year = {2009},
	pmid = {19305402},
	pages = {483--91},
}

@article{kumar_conditions_2008,
	title = {Conditions for propagating synchronous spiking and asynchronous firing rates in a cortical network model.},
	volume = {28},
	issn = {1529-2401},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18480283},
	doi = {10.1523/JNEUROSCI.2542-07.2008},
	abstract = {Isolated feedforward networks (FFNs) of spiking neurons have been studied extensively for their ability to propagate transient synchrony and asynchronous firing rates, in the presence of activity independent synaptic background noise (Diesmann et al., 1999; van Rossum et al., 2002). In a biologically realistic scenario, however, the FFN should be embedded in a recurrent network, such that the activity in the FFN and the network activity may dynamically interact. Previously, transient synchrony propagating in an FFN was found to destabilize the dynamics of the embedding network (Mehring et al., 2003). Here, we show that by modeling synapses as conductance transients, rather than current sources, it is possible to embed and propagate transient synchrony in the FFN, without destabilizing the background network dynamics. However, the network activity has a strong impact on the type of activity that can be propagated in the embedded FFN. Global synchrony and high firing rates in the embedding network prohibit the propagation of both, synchronous and asynchronous spiking activity. In contrast, asynchronous low-rate network states support the propagation of both, synchronous spiking and asynchronous, but only low firing rates. In either case, spiking activity tends to synchronize as it propagates, challenging the feasibility to transmit information in asynchronous firing rates. Finally, asynchronous network activity allows to embed more than one FFN, with the amount of cross talk depending on the degree of overlap in the FFNs. This opens the possibility of computational mechanisms using transient synchrony among the activities in multiple FFNs.},
	number = {20},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Kumar, Arvind and Rotter, Stefan and Aertsen, Ad},
	month = may,
	year = {2008},
	pmid = {18480283},
	pages = {5268--80},
}

@article{tobyne_sensory-biased_2017,
	title = {Sensory-biased attention networks in human lateral frontal cortex revealed by intrinsic functional connectivity},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811917306675},
	doi = {10.1016/j.neuroimage.2017.08.020},
	journal = {NeuroImage},
	author = {Tobyne, Sean M. and Osher, David E. and Michalka, Samantha W. and Somers, David C.},
	month = aug,
	year = {2017},
}

@article{yassa_pattern_2011,
	title = {Pattern separation in the hippocampus},
	volume = {34},
	url = {http://www.cell.com/trends/neurosciences/pdf/S0166-2236(11)00102-0.pdf},
	doi = {10.1016/j.tins.2011.06.006},
	abstract = {The ability to discriminate among similar experiences is a crucial feature of episodic memory. This ability has long been hypothesized to require the hippocampus, and computational models suggest that it is dependent on pattern separation. However, empirical data for the role of the hippocampus in pattern separation have not been available until recently. This review summarizes data from electrophysiological recordings, lesion stud-ies, immediate-early gene imaging, transgenic mouse models, as well as human functional neuroimaging, that provide convergent evidence for the involvement of particular hippocampal subfields in this key process. We discuss the impact of aging and adult neurogenesis on pattern separation, and also highlight several chal-lenges to linking across species and approaches, and suggest future directions for investigation.},
	journal = {Trends in Neurosciences},
	author = {Yassa, Michael A and Stark, Craig E L},
	year = {2011},
	pages = {515--525},
	file = {Attachment:/Users/tito/Zotero/storage/XS39BN7F/Yassa, Stark - 2011 - Pattern separation in the hippocampus.pdf:application/pdf},
}

@article{tononi_measure_1994,
	title = {A measure for brain complexity: {Relating} functional segregation and integration in the nervous system},
	volume = {91},
	url = {http://www.pnas.org/content/91/11/5033.full.pdf},
	abstract = {In brains ofhigher vertebrates, the functional segregation of local areas that differ in their anatomy and physiology contrasts sharply with their global ination dur-ing perception and behavior. In this paper, we introduce a measure, called neural complexity (CN), that captures the interplay between these two dental aspects of brain organization. We express functional segregation within a neu-ral system in terms of the relative statistical independence of small subsets of the system and functional integration in terms of signicant deviations from independence of large subsets. CN is then obtained from estimates of the average deviation from statistical independence for subsets of increasing size. CN is shown to be high when functional segregation coexists with integration and to be low when the components of a system are either completely independent (segregated) or completely de-pendent (integrated). We apply this complexity measure in computer simulations of cortical areas to examine how some basic principles of neuroanatomical organization constrain brain dynamics. We show that the connectivity patterns of the},
	journal = {Neurobiology},
	author = {Tononi, Giulio and Sporns, Olaf and Edelman, Gerald M},
	year = {1994},
	pages = {5033--5037},
	file = {Attachment:/Users/tito/Zotero/storage/LWG5GHME/Tononi, Sporns, Edelman - 1994 - A measure for brain complexity Relating functional segregation and integration in the nervous system.pdf:application/pdf},
}

@article{zuo_network_2012,
	title = {Network {Centrality} in the {Human} {Functional} {Connectome}},
	volume = {22},
	issn = {1460-2199},
	url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhr269},
	doi = {10.1093/cercor/bhr269},
	number = {8},
	journal = {Cerebral Cortex},
	author = {Zuo, Xi-Nian and Ehmke, Ross and Mennes, Maarten and Imperati, Davide and Castellanos, F. Xavier and Sporns, Olaf and Milham, Michael P.},
	month = aug,
	year = {2012},
	pages = {1862--1875},
	file = {Attachment:/Users/tito/Zotero/storage/NZ9C258R/Zuo et al. - 2012 - Network Centrality in the Human Functional Connectome.pdf:application/pdf},
}

@article{kim_new_2017,
	title = {A {New} {Modular} {Brain} {Organization} of the {BOLD} {Signal} during {Natural} {Vision}},
	volume = {27},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhx175},
	doi = {10.1093/cercor/bhx175},
	number = {1},
	journal = {Cerebral Cortex},
	author = {Kim, DoHyun and Kay, Kendrick and Shulman, Gordon L. and Corbetta, Maurizio},
	month = jul,
	year = {2017},
	pages = {1--17},
	file = {Attachment:/Users/tito/Zotero/storage/I2IEK83Y/Kim et al. - 2017 - A New Modular Brain Organization of the BOLD Signal during Natural Vision.pdf:application/pdf},
}

@article{rumelhart_general_1986,
	title = {A general framework for parallel distributed processing},
	volume = {1},
	journal = {Parallel distributed processing: Explorations in the microstructure of cognition},
	author = {Rumelhart, David E and Hinton, Geoffrey E and McClelland, James L and {Others}},
	year = {1986},
	pages = {45--76},
}

@article{hassabis_neuroscience-inspired_2017,
	title = {Neuroscience-{Inspired} {Artificial} {Intelligence}},
	volume = {95},
	issn = {0896-6273},
	url = {http://dx.doi.org/10.1016/j.neuron.2017.06.011},
	doi = {10.1016/j.neuron.2017.06.011},
	number = {2},
	journal = {Neuron},
	author = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
	year = {2017},
	pmid = {28728020},
	pages = {245--258},
	file = {Attachment:/Users/tito/Zotero/storage/WZIHMTHL/Hassabis et al. - 2017 - Neuroscience-Inspired Artificial Intelligence.pdf:application/pdf},
}

@article{hermes_neuronal_2017,
	title = {Neuronal synchrony and the relation between the blood-oxygen-level dependent response and the local field potential},
	volume = {15},
	url = {https://doi.org/10.1371/journal.pbio.2001461},
	doi = {10.1371/journal.pbio.2001461},
	abstract = {Author summary There are several methods for measuring activity in the living human brain. Here, we studied functional magnetic resonance imaging (fMRI), which depends on the vascular response to neuronal activity, and surface field potentials, which measure electrical activity from many neurons. These two widely used measurements of human brain activity often provide different and potentially conflicting results. We propose a quantitative model for how these two measurements integrate activity from neuronal populations. The fMRI signal is highly sensitive to the average level of local neuronal activity but not the degree of synchrony between neurons. In contrast, the field potential is most sensitive to synchronous neuronal signals. Our model accounts for several observations seen in fMRI and field potential data: some very large features of field potential recordings, such as gamma oscillations, can occur with little to no associated fMRI signal. The model predicts this because the gamma oscillations result more from increased neuronal synchrony than increased neuronal activity. Other field potential signals, such as broadband changes, which are likely driven by the level of neuronal activity rather than a change in synchrony, are highly correlated with fMRI. The two measures thus provide complementary information about human brain activity.},
	number = {7},
	journal = {PLOS Biology},
	author = {Hermes, Dora and Nguyen, Mai and Winawer, Jonathan},
	year = {2017},
	pages = {1--42},
}

@article{saxe_exact_2013,
	title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	volume = {abs/1312.6},
	url = {http://arxiv.org/abs/1312.6120},
	journal = {CoRR},
	author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	year = {2013},
}

@article{runyan_distinct_2017,
	title = {Distinct timescales of population coding across cortex},
	volume = {548},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature23020},
	doi = {10.1038/nature23020},
	number = {7665},
	journal = {Nature Publishing Group},
	author = {Runyan, Caroline A and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christorpher D.},
	year = {2017},
	pmid = {28723889},
	pages = {1--29},
}

@article{glomb_resting_2017,
	title = {Resting state networks in empirical and simulated dynamic functional connectivity},
	volume = {159},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811917306468},
	doi = {10.1016/j.neuroimage.2017.07.065},
	journal = {NeuroImage},
	author = {Glomb, Katharina and Ponce-Alvarez, Adrián and Gilson, Matthieu and Ritter, Petra and Deco, Gustavo},
	month = oct,
	year = {2017},
	pages = {388--402},
	file = {Attachment:/Users/tito/Zotero/storage/C8ZA6MJG/Glomb et al. - 2017 - Resting state networks in empirical and simulated dynamic functional connectivity.pdf:application/pdf},
}

@article{wills_detecting_2017,
	title = {Detecting {Topological} {Changes} in {Dynamic} {Community} {Networks}},
	url = {http://arxiv.org/abs/1707.07362},
	abstract = {The study of time-varying (dynamic) networks (graphs) is of fundamental importance for computer network analytics. Several methods have been proposed to detect the effect of significant structural changes in a time series of graphs. The main contribution of this work is a detailed analysis of a dynamic community graph model. This model is formed by adding new vertices, and randomly attaching them to the existing nodes. It is a dynamic extension of the well-known stochastic blockmodel. The goal of the work is to detect the time at which the graph dynamics switches from a normal evolution – where balanced communities grow at the same rate – to an abnormal behavior – where communities start merging. In order to circumvent the problem of decomposing each graph into communities, we use a metric to quantify changes in the graph topology as a function of time. The detection of anomalies becomes one of testing the hypothesis that the graph is undergoing a significant structural change. In addition the the theoretical analysis of the test statistic, we perform Monte Carlo simulations of our dynamic graph model to demonstrate that our test can detect changes in graph topology.},
	author = {Wills, Peter and Meyer, Francois G.},
	month = jul,
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/RXETLB9E/Wills, Meyer - 2017 - Detecting Topological Changes in Dynamic Community Networks.pdf:application/pdf},
}

@article{gordon_precision_2017,
	title = {Precision {Functional} {Mapping} of {Individual} {Human} {NeuroResource} {Precision} {Functional} {Mapping} of {Individual} {Human} {Brains}},
	issn = {0896-6273},
	url = {http://dx.doi.org/10.1016/j.neuron.2017.07.011},
	doi = {10.1016/j.neuron.2017.07.011},
	journal = {Neuron},
	author = {Gordon, Evan M and Laumann, Timothy O and Gilmore, Adrian W and Petersen, Steven E and Nelson, Steven M and Dosenbach, Nico U F and Gordon, Evan M and Laumann, Timothy O and Gilmore, Adrian W and Newbold, Dillan J and Greene, Deanna J},
	year = {2017},
	pages = {1--17},
	file = {Attachment:/Users/tito/Zotero/storage/PQJDHQAZ/Gordon et al. - 2017 - Precision Functional Mapping of Individual Human NeuroResource Precision Functional Mapping of Individual Human B.pdf:application/pdf},
}

@article{cocchi_criticality_2017,
	title = {Criticality in the brain: {A} synthesis of neurobiology, models and cognition},
	issn = {0301-0082},
	url = {http://www.sciencedirect.com/science/article/pii/S0301008216301630},
	doi = {https://doi.org/10.1016/j.pneurobio.2017.07.002},
	abstract = {Abstract Cognitive function requires the coordination of neural activity across many scales, from neurons and circuits to large-scale networks. As such, it is unlikely that an explanatory framework focused upon any single scale will yield a comprehensive theory of brain activity and cognitive function. Modelling and analysis methods for neuroscience should aim to accommodate multiscale phenomena. Emerging research now suggests that multi-scale processes in the brain arise from so-called critical phenomena that occur very broadly in the natural world. Criticality arises in complex systems perched between order and disorder, and is marked by fluctuations that do not have any privileged spatial or temporal scale. We review the core nature of criticality, the evidence supporting its role in neural systems and its explanatory potential in brain health and disease.},
	journal = {Progress in Neurobiology},
	author = {Cocchi, Luca and Gollo, Leonardo L and Zalesky, Andrew and Breakspear, Michael},
	year = {2017},
	keywords = {Bifurcations, cognition, dynamics, metastability, multistability, power-law},
	file = {Attachment:/Users/tito/Zotero/storage/TXPDRX82/Cocchi et al. - 2017 - Criticality in the brain A synthesis of neurobiology, models and cognition.pdf:application/pdf},
}

@article{bolt_data-driven_2017,
	title = {Data-{Driven} {Extraction} of a {Nested} {Model} of {Human} {Brain} {Function}},
	doi = {10.1523/JNEUROSCI.0323-17.2017},
	journal = {The Journal of Neuroscience},
	author = {Bolt, Taylor and Nomi, Jason S and Yeo, B T Thomas and Uddin, Lucina Q},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/BQLE8NXD/Bolt et al. - 2017 - Data-Driven Extraction of a Nested Model of Human Brain Function(2).pdf:application/pdf},
}

@article{jalili_information_2017,
	title = {Information cascades in complex networks},
	doi = {10.1093/comnet/cnx019},
	author = {Jalili, Mahdi},
	year = {2017},
	keywords = {centrality measure, complex network, epidemics, influence, information cascade, information spreading, maximization, memes, online popularity, social dynamics},
	pages = {1--22},
	file = {Attachment:/Users/tito/Zotero/storage/ZZ9Q2N2X/Jalili - 2017 - Information cascades in complex networks.pdf:application/pdf},
}

@article{lorenz_dissociating_2017,
	title = {Dissociating frontoparietal brain networks with neuroadaptive {Bayesian} optimization},
	author = {Lorenz, Romy and Violante, Ines R and Monti, Ricardo Pio and Montana, Giovanni},
	year = {2017},
	pages = {1--27},
	file = {Attachment:/Users/tito/Zotero/storage/HFFBRCL9/Lorenz et al. - 2017 - Dissociating frontoparietal brain networks with neuroadaptive Bayesian optimization.pdf:application/pdf},
}

@article{denil_programmable_2017,
	title = {Programmable {Agents}},
	number = {Nips},
	author = {Denil, Misha and Gómez, Sergio},
	year = {2017},
}

@article{arenas_synchronization_2006,
	title = {Synchronization reveals topological scales in complex networks},
	volume = {96},
	issn = {00319007},
	doi = {10.1103/PhysRevLett.96.114102},
	abstract = {We study the relationship between topological scales and dynamic time scales in complex networks. The analysis is based on the full dynamics towards synchronization of a system of coupled oscillators. In the synchronization process, modular structures corresponding to well defined communities of nodes emerge in different time scales, ordered in a hierarchical way. The analysis also provides a useful connection between synchronization dynamics, complex networks topology and spectral graph analysis.},
	number = {11},
	journal = {Physical Review Letters},
	author = {Arenas, Alex and Diaz-Guilera, Albert and Perez-Vicente, Conrad J.},
	year = {2006},
	pmid = {16605825},
	pages = {1--4},
}

@article{zanudo_structure-based_2017,
	title = {Structure-based control of complex networks with nonlinear dynamics},
	doi = {10.1073/pnas.1617387114/-/DCSupplemental.www.pnas.org/cgi/doi/10.1073/pnas.1617387114},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Zanudo, Jorge Gomez Tejeda and Yang, Gang and Albert, Réka},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/RE2AK8SY/Zanudo, Yang, Albert - 2017 - Structure-based control of complex networks with nonlinear dynamics.pdf:application/pdf},
}

@article{khambhati_modeling_2017,
	title = {Modeling and interpreting mesoscale network dynamics},
	issn = {1053-8119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2017.06.029},
	doi = {10.1016/j.neuroimage.2017.06.029},
	number = {June},
	journal = {NeuroImage},
	author = {Khambhati, Ankit N and Sizemore, Ann E and Betzel, Richard F and Bassett, Danielle S},
	year = {2017},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/8ZDLKPR9/Khambhati et al. - 2017 - NeuroImage Modeling and interpreting mesoscale network dynamics.pdf:application/pdf},
}

@article{diego_measures_1999,
	title = {Measures of degeneracy and redundancy in biological networks},
	volume = {96},
	number = {March},
	author = {Diego, San},
	year = {1999},
	pages = {3257--3262},
	file = {Attachment:/Users/tito/Zotero/storage/RMICWYA6/Diego - 1999 - Measures of degeneracy and redundancy in biological networks.pdf:application/pdf},
}

@article{tononi_measures_1999,
	title = {Measures of degeneracy and redundancy in biological networks},
	volume = {96},
	url = {http://www.pnas.org/content/96/6/3257.abstract},
	abstract = {Degeneracy, the ability of elements that are structurally different to perform the same function, is a prominent property of many biological systems ranging from genes to neural networks to evolution itself. Because structurally different elements may produce different outputs in different contexts, degeneracy should be distinguished from redundancy, which occurs when the same function is performed by identical elements. However, because of ambiguities in the distinction between structure and function and because of the lack of a theoretical treatment, these two notions often are conflated. By using information theoretical concepts, we develop here functional measures of the degeneracy and redundancy of a system with respect to a set of outputs. These measures help to distinguish the concept of degeneracy from that of redundancy and make it operationally useful. Through computer simulations of neural systems differing in connectivity, we show that degeneracy is low both for systems in which each element affects the output independently and for redundant systems in which many elements can affect the output in a similar way but do not have independent effects. By contrast, degeneracy is high for systems in which many different elements can affect the output in a similar way and at the same time can have independent effects. We demonstrate that networks that have been selected for degeneracy have high values of complexity, a measure of the average mutual information between the subsets of a system. These measures promise to be useful in characterizing and understanding the functional robustness and adaptability of biological networks.},
	number = {6},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Tononi, Giulio and Sporns, Olaf and Edelman, Gerald M},
	month = mar,
	year = {1999},
	pages = {3257--3262},
	annote = {10.1073/pnas.96.6.3257},
}

@article{chang_code_2017,
	title = {The {Code} for {Facial} {Identity} in the {Primate} {Brain} {Facial} identity is encoded via a remarkably simple neural code that relies on the ability of neurons to distinguish facial features along specific axes in face space, disavowing the long-standing assumptio},
	volume = {169},
	issn = {0092-8674},
	url = {http://dx.doi.org/10.1016/j.cell.2017.05.011},
	doi = {10.1016/j.cell.2017.05.011},
	abstract = {Graphical Abstract Highlights d Facial images can be linearly reconstructed using responses of 200 face cells d Face cells display flat tuning along dimensions orthogonal to the axis being coded d The axis model is more efficient, robust, and flexible than the exemplar model d Face patches ML/MF and AM carry complementary information about faces},
	number = {6},
	journal = {Cell},
	author = {Chang, Le and Tsao, Doris Y},
	year = {2017},
	pmid = {28575666},
	keywords = {electrophysiology, decoding, face processing, inferior temporal cortex, primate vision},
	pages = {1013--1020.e14},
}

@article{diedrichsen_representational_2017,
	title = {Representational models: {A} common framework for understanding encoding, pattern-component, and representational-similarity analysis},
	volume = {13},
	url = {https://doi.org/10.1371/journal.pcbi.1005508},
	abstract = {Author summary Modern neuroscience can measure activity of many neurons or the local blood oxygenation of many brain locations simultaneously. As the number of simultaneous measurements grows, we can better investigate how the brain represents and transforms information, to enable perception, cognition, and behavior. Recent studies go beyond showing that a brain region is involved in some function. They use representational models that specify how different perceptions, cognitions, and actions are encoded in brain-activity patterns. In this paper, we provide a general mathematical framework for such representational models, which clarifies the relationships between three different methods that are currently used in the neuroscience community. All three methods evaluate the same core feature of the data, but each has distinct advantages and disadvantages. Pattern component modelling (PCM) implements the most powerful test between models, and is analytically tractable and expandable. Representational similarity analysis (RSA) provides a highly useful summary statistic (the dissimilarity) and enables model comparison with weaker distributional assumptions. Finally, encoding models characterize individual responses and enable the study of their layout across cortex. We argue that these methods should be considered components of a larger toolkit for testing hypotheses about the way the brain represents information.},
	number = {4},
	journal = {PLOS Computational Biology},
	author = {Diedrichsen, Jörn and Kriegeskorte, Nikolaus},
	month = apr,
	year = {2017},
	pages = {e1005508},
	file = {Attachment:/Users/tito/Zotero/storage/ZXWV87EJ/Diedrichsen, Kriegeskorte - 2017 - Representational models A common framework for understanding encoding, pattern-component, and represe.pdf:application/pdf},
}

@article{alonso_nonlinear_2017,
	title = {Nonlinear resonances and multi-stability in simple neural circuits},
	volume = {27},
	issn = {10541500},
	doi = {10.1063/1.4974028},
	abstract = {We present an efficient numerical procedure to generate models of neural circuits which exhibit rich dynamical behavior. This is achieved by imposing that the circuits are close to many nonlinear resonances. The procedure is applied to generate circuits consisting of two interacting neural populations. When driven by external input, the resulting circuits present multiple stable patterns of periodic activity organized in complex tuning diagrams and signatures of low dimensional chaos.},
	number = {1},
	journal = {Chaos},
	author = {Alonso, Leandro M.},
	year = {2017},
}

@article{deco_dynamics_2016,
	title = {The dynamics of resting fluctuations in the brain: metastability and its dynamical cortical core},
	issn = {2045-2322},
	url = {http://biorxiv.org/lookup/doi/10.1101/065284},
	doi = {10.1101/065284},
	abstract = {In the human brain, spontaneous activity during resting state consists of rapid transitions between functional network states over time but the underlying mechanisms are not understood. We use computational brain network modeling to reveal fundamental principles of how the human brain generates large scale activity observable by noninvasive neuroimaging. By including individual structural and functional neuroimaging data into brain network models we construct personalized brain models. With this novel approach, we reveal that the human brain during resting state operates at maximum metastability, i.e. in a state of maximum network switching. Personalized, i.e. person-specific brain network modelling goes beyond correlational neuroimaging analysis and reveals the network mechanisms underlying non-invasive observations.},
	number = {April},
	journal = {bioRxiv},
	author = {Deco, Gustavo and Kringelbach, Morten L and Jirsa, Viktor and Ritter, Petra},
	year = {2016},
	keywords = {resting-state networks, metastability, brain, dynamical system, whole-brain modelling},
	pages = {065284},
}

@article{winkler_permutation_2014,
	title = {Permutation inference for the general linear model},
	volume = {92},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2014.01.060},
	doi = {10.1016/j.neuroimage.2014.01.060},
	abstract = {Permutation methods can provide exact control of false positives and allow the use of non-standard statistics, making only weak assumptions about the data. With the availability of fast and inexpensive computing, their main limitation would be some lack of flexibility to work with arbitrary experimental designs. In this paper we report on results on approximate permutation methods that are more flexible with respect to the experimental design and nuisance variables, and conduct detailed simulations to identify the best method for settings that are typical for imaging research scenarios. We present a generic framework for permutation inference for complex general linear models (glms) when the errors are exchangeable and/or have a symmetric distribution, and show that, even in the presence of nuisance effects, these permutation inferences are powerful while providing excellent control of false positives in a wide range of common and relevant imaging research scenarios. We also demonstrate how the inference on glm parameters, originally intended for independent data, can be used in certain special but useful cases in which independence is violated. Detailed examples of common neuroimaging applications are provided, as well as a complete algorithm - the "randomise" algorithm - for permutation inference with the GLM. ?? 2014 The Authors.},
	journal = {NeuroImage},
	author = {Winkler, Anderson M. and Ridgway, Gerard R. and Webster, Matthew A. and Smith, Stephen M. and Nichols, Thomas E.},
	year = {2014},
	pmid = {24530839},
	keywords = {General linear model, Multiple regression, Permutation inference, Randomise},
	pages = {381--397},
	file = {Attachment:/Users/tito/Zotero/storage/U6CIQRRM/Winkler et al. - 2014 - Permutation inference for the general linear model.pdf:application/pdf},
}

@article{nichols_nonparametric_2001,
	title = {Nonparametric {Permutation} {Tests} for {Functional} {Neuroimaging} {Experiments}: {A} {Primer} with examples},
	volume = {15},
	issn = {1065-9471},
	url = {http://www3.interscience.wiley.com/cgi-bin/abstract/86010644/},
	doi = {10.1002/hbm.1058},
	abstract = {Requiring only minimal assumptions for validity; nonparametric permutation testing provides a flexible and intuitive methodology for the statistical analysis of data from functional neuroimaging experiments; at some computational expense. Introduced into the functional neuroimaging literature by Holmes et al. ([1996]: J Cereb Blood Flow Metab 16:7–22); the permutation approach readily accounts for the multiple comparisons problem implicit in the standard voxel-by-voxel hypothesis testing framework. When the appropriate assumptions hold; the nonparametric permutation approach gives results similar to those obtained from a comparable Statistical Parametric Mapping approach using a general linear model with multiple comparisons corrections derived from random field theory. For analyses with low degrees of freedom; such as single subject PET/SPECT experiments or multi-subject PET/SPECT or fMRI designs assessed for population effects; the nonparametric approach employing a locally pooled (smoothed) variance estimate can outperform the comparable Statistical Parametric Mapping approach. Thus; these nonparametric techniques can be used to verify the validity of less computationally expensive parametric approaches. Although the theory and relative advantages of permutation approaches have been discussed by various authors; there has been no accessible explication of the method; and no freely distributed software implementing it. Consequently; there have been few practical applications of the technique. This article; and the accompanying MATLAB software; attempts to address these issues. The standard nonparametric randomization and permutation testing ideas are developed at an accessible level; using practical examples from functional neuroimaging; and the extensions for multiple comparisons described. Three worked examples from PET and fMRI are presented; with discussion; and comparisons with standard parametric approaches made where appropriate. Practical considerations are given throughout; and relevant statistical concepts are expounded in appendices.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {Nichols, T E and Holmes, Andrew P},
	year = {2001},
	pmid = {11747097},
	keywords = {permutation test, general linear model, hypothesis test, multiple comparisons, nonparametric, randomization test, SPM, statistic image, spm},
	pages = {1--25},
	file = {Attachment:/Users/tito/Zotero/storage/AL9UAXIW/Nichols, Holmes - 2001 - Nonparametric Permutation Tests for Functional Neuroimaging Experiments A Primer with examples.pdf:application/pdf},
}

@article{braga_parallel_2017,
	title = {Parallel {Interdigitated} {Distributed} {Networks} within the {Individual} {Estimated} by {Intrinsic} {Functional} {Connectivity}},
	volume = {95},
	issn = {08966273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627317305627},
	doi = {10.1016/j.neuron.2017.06.038},
	abstract = {Certain organizational features of brain networks present in the individual are lost when central tendencies are examined in the group. Here we investigated the detailed network organization of four individuals each scanned 24 times using MRI. We discovered that the distributed network known as the default network is comprised of two separate networks possessing adjacent regions in eight or more cortical zones. A distinction between the networks is that one is coupled to the hippocampal formation while the other is not. Further exploration revealed that these two networks were juxtaposed with additional networks that themselves fractionate group-defined networks. The collective networks display a repeating spatial progression in multiple cortical zones, suggesting that they are embedded within a broad macroscale gradient. Regions contributing to the newly defined networks are spatially variable across individuals and adjacent to distinct networks, raising issues for network estimation in group-averaged data and applied endeavors, including targeted neuromodulation.},
	number = {2},
	journal = {Neuron},
	author = {Braga, Rodrigo M. and Buckner, Randy L.},
	year = {2017},
	pages = {457--471.e5},
	file = {Attachment:/Users/tito/Zotero/storage/5DW83JFA/Braga et al. - 2017 - Parallel Interdigitated Distributed Networks within the Individual Estimated by Intrinsic Functional Article Paral.pdf:application/pdf},
}

@book{kriegeskorte_representational_2017,
	title = {Representational models : {A} common framework for understanding encoding ,},
	isbn = {1-111-11111-1},
	author = {Kriegeskorte, Nikolaus},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/ICXIHJ9X/Diedrichsen, Kriegeskorte - 2017 - Representational models A common framework for understanding encoding, pattern-component, and represe.pdf:application/pdf},
}

@article{palminteri_importance_2017,
	title = {The {Importance} of {Falsi} fi cation in {Computational} {Cognitive} {Modeling}},
	volume = {21},
	doi = {10.1016/j.tics.2017.03.011},
	number = {6},
	author = {Palminteri, Stefano and Wyart, Valentin and Koechlin, Etienne},
	year = {2017},
	pages = {425--433},
	file = {Attachment:/Users/tito/Zotero/storage/QF4TEWBQ/Palminteri, Wyart, Koechlin - 2017 - The Importance of Falsi fi cation in Computational Cognitive Modeling.pdf:application/pdf},
}

@article{laje_robust_2013,
	title = {Robust timing and motor patterns by taming chaos in recurrent neural networks},
	volume = {16},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3405},
	doi = {10.1038/nn.3405},
	abstract = {The brain's ability to tell time and produce complex spatiotemporal motor patterns is critical for anticipating the next ring of a telephone or playing a musical instrument. One class of models proposes that these abilities emerge from dynamically changing patterns of neural activity generated in recurrent neural networks. However, the relevant dynamic regimes of recurrent networks are highly sensitive to noise; that is, chaotic. We developed a firing rate model that tells time on the order of seconds and generates complex spatiotemporal patterns in the presence of high levels of noise. This is achieved through the tuning of the recurrent connections. The network operates in a dynamic regime that exhibits coexisting chaotic and locally stable trajectories. These stable patterns function as 'dynamic attractors' and provide a feature that is characteristic of biological systems: the ability to 'return' to the pattern being generated in the face of perturbations.},
	number = {7},
	journal = {Nature Neuroscience},
	author = {Laje, Rodrigo and Buonomano, Dean V},
	year = {2013},
	pmid = {23708144},
	pages = {925--933},
	file = {Attachment:/Users/tito/Zotero/storage/E9BGTL64/Laje, Buonomano - 2013 - Robust timing and motor patterns by taming chaos in recurrent neural networks.pdf:application/pdf},
}

@article{hoerzer_emergence_2014,
	title = {Emergence of complex computational structures from chaotic neural networks through reward-modulated hebbian learning},
	volume = {24},
	issn = {10473211},
	doi = {10.1093/cercor/bhs348},
	abstract = {This paper addresses the question how generic microcircuits of neurons in different parts of the cortex can attain and maintain different computational specializations. We show that if stochastic variations in the dynamics of local microcircuits are correlated with signals related to functional improvements of the brain (e.g. in the control of behavior), the computational operation of these microcircuits can become optimized for specific tasks such as the generation of specific periodic signals and task-dependent routing of information. Furthermore, we show that working memory can autonomously emerge through reward-modulated Hebbian learning, if needed for specific tasks. Altogether, our results suggest that reward-modulated synaptic plasticity can not only optimize the network parameters for specific computational tasks, but also initiate a functional rewiring that re-programs microcircuits, thereby generating diverse computational functions in different generic cortical microcircuits. On a more general level, this work provides a new perspective for a standard model for computations in generic cortical microcircuits (liquid computing model). It shows that the arguably most problematic assumption of this model, the postulate of a teacher that trains neural readouts through supervised learning, can be eliminated. We show that generic networks of neurons can learn numerous biologically relevant computations through trial and error.},
	number = {3},
	journal = {Cerebral Cortex},
	author = {Hoerzer, Gregor M. and Legenstein, Robert and Maass, Wolfgang},
	year = {2014},
	pmid = {23146969},
	keywords = {working memory, cortical microcircuit model, cortical plasticity, pattern generation},
	pages = {677--690},
	file = {Attachment:/Users/tito/Zotero/storage/XXNGNY5U/Hoerzer, Legenstein, Maass - 2014 - Emergence of complex computational structures from chaotic neural networks through reward-modulated.pdf:application/pdf},
}

@article{landau_impact_2016,
	title = {The {Impact} of {Structural} {Heterogeneity} on {Excitation}-{Inhibition} {Balance} in {Cortical} {Networks}},
	volume = {92},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2016.10.027},
	doi = {10.1016/j.neuron.2016.10.027},
	abstract = {Models of cortical dynamics often assume a homogeneous connectivity structure. However, we show that heterogeneous input connectivity can prevent the dynamic balance between excitation and inhibition, a hallmark of cortical dynamics, and yield unrealistically sparse and temporally regular firing. Anatomically based estimates of the connectivity of layer 4 (L4) rat barrel cortex and numerical simulations of this circuit indicate that the local network possesses substantial heterogeneity in input connectivity, sufficient to disrupt excitation-inhibition balance. We show that homeostatic plasticity in inhibitory synapses can align the functional connectivity to compensate for structural heterogeneity. Alternatively, spike-frequency adaptation can give rise to a novel state in which local firing rates adjust dynamically so that adaptation currents and synaptic inputs are balanced. This theory is supported by simulations of L4 barrel cortex during spontaneous and stimulus-evoked conditions. Our study shows how synaptic and cellular mechanisms yield fluctuation-driven dynamics despite structural heterogeneity in cortical circuits.},
	number = {5},
	journal = {Neuron},
	author = {Landau, Itamar D. and Egger, Robert and Dercksen, Vincent J. and Oberlaender, Marcel and Sompolinsky, Haim},
	year = {2016},
	pmid = {27866797},
	keywords = {inhibition, dynamics, adaptation, balance, cortical networks, homeostatic plasticity},
	pages = {1106--1121},
	file = {Attachment:/Users/tito/Zotero/storage/ELT8RA46/Landau et al. - 2016 - The Impact of Structural Heterogeneity on Excitation-Inhibition Balance in Cortical Networks.pdf:application/pdf},
}

@article{he_spontaneous_2013,
	title = {Spontaneous and {Task}-{Evoked} {Brain} {Activity} {Negatively} {Interact}},
	volume = {33},
	doi = {10.1523/JNEUROSCI.2922-12.2013},
	number = {11},
	author = {He, Biyu J},
	year = {2013},
	pages = {4672--4682},
	file = {Attachment:/Users/tito/Zotero/storage/BNGK23D5/He - 2013 - Spontaneous and Task-Evoked Brain Activity Negatively Interact.pdf:application/pdf},
}

@article{ponce-alvarez_task-driven_2015,
	title = {Task-{Driven} {Activity} {Reduces} the {Cortical} {Activity} {Space} of the {Brain} : {Experiment} and {Whole}-{Brain} {Modeling}},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1004445},
	doi = {10.1371/journal.pcbi.1004445},
	author = {Ponce-alvarez, Adrián and He, Biyu J and Hagmann, Patric and Deco, Gustavo},
	year = {2015},
	pages = {1--26},
	file = {Attachment:/Users/tito/Zotero/storage/YXZ8ME8N/Ponce-alvarez et al. - 2015 - Task-Driven Activity Reduces the Cortical Activity Space of the Brain Experiment and Whole-Brain Modeling.pdf:application/pdf},
}

@article{abbott_interactions_2011,
	title = {Interactions between {Intrinsic} and {Stimulus}-{Evoked} {Activity} in {Recurrent} {Neural} {Networks}},
	doi = {10.1093/acprof:oso/9780195393798.003.0004},
	abstract = {Trial-to-trial variability is an essential feature of neural responses, but its source is a subject of active debate. Response variability (Mast and Victor, 1991; Arieli et al., 1995 \& 1996; Anderson et al., 2000 \& 2001; Kenet et al., 2003; Petersen et al., 2003a \& b; Fiser, Chiu and Weliky, 2004; MacLean et al., 2005; Yuste et al., 2005; Vincent et al., 2007) is often treated as random noise, generated either by other brain areas, or by stochastic processes within the circuitry being studied. We call such sources of variability external to stress the independence of this form of noise from activity driven by the stimulus. Variability can also be generated internally by the same network dynamics that generates responses to a stimulus. How can we distinguish between external and internal sources of response variability? Here we show that internal sources of variability interact nonlinearly with stimulus-induced activity, and this interaction yields a suppression of noise in the evoked state. This provides a theoretical basis and potential mechanism for the experimental observation that, in many brain areas, stimuli cause significant suppression of neuronal variability (Werner and Mountcastle, 1963; Fortier, Smith and Kalaska, 1993; Anderson et al., 2000; Friedrich and Laurent, 2004; Churchland et al., 2006; Finn, Priebe and Ferster, 2007; Mitchell, Sundberg and Reynolds, 2007; Churchland et al., 2009). The combined theoretical and experimental results suggest that internally generated activity is a significant contributor to response variability in neural circuits.},
	journal = {The Dynamic Brain: An Exploration of Neuronal Variability and Its Functional Significance},
	author = {Abbott, Larry F. and Rajan, Kanaka and Sompolinsky, Haim},
	year = {2011},
	keywords = {Variability, Networks, Chaos, Noise suppression, Spontaneous activity},
	pages = {1--16},
	file = {Attachment:/Users/tito/Zotero/storage/XU4Y4LBU/Abbott, Rajan, Sompolinsky - 2011 - Interactions between Intrinsic and Stimulus-Evoked Activity in Recurrent Neural Networks.pdf:application/pdf},
}

@article{park_effort-based_2017,
	title = {Effort-based reinforcement processing and functional connectivity underlying amotivation in medicated patients with depression and schizophrenia.},
	volume = {37},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2524-16.2017%0Ahttp://www.ncbi.nlm.nih.gov/pubmed/28283562},
	doi = {10.1523/JNEUROSCI.2524-16.2017},
	abstract = {Amotivation is a common phenotype of major depressive disorder and schizophrenia which are clinically distinct disorders. Effective treatment targets and strategies can be discovered by examining the dopaminergic reward network function underlying amotivation between these disorders. We conducted a functional MRI study in healthy human participants and medicated patients with depression and schizophrenia using an effort-based reinforcement task. We examined regional activations related to reward type (positive and negative reinforcement), effort level, and their composite value as well as resting-state functional connectivities within the meso-striatal-prefrontal pathway. We found that integrated reward and effort values of low effort-positive reinforcement and high effort-negative reinforcement were behaviorally anticipated and represented in the putamen and medial orbitofrontal cortex activities. Patients with schizophrenia and depression did not show anticipation-related and work-related reaction time reductions, respectively. Greater amotivation severity correlated with smaller work-related putamen activity changes according to reward type in schizophrenia and effort level in depression. Patients with schizophrenia showed feedback-related putamen hyperactivity of low effort compared to healthy controls and depressed patients. The strength of medial orbitofrontal-striatal functional connectivity predicted work-related reaction time reduction of high effort negative reinforcement in healthy controls and amotivation severity in both patients with schizophrenia and depression. Patients with depression showed deficient medial orbitofrontal-striatal functional connectivity compared to healthy controls and patients with schizophrenia. These results indicate that amotivations in depression and schizophrenia involve different pathophysiology in the prefrontal-striatal circuitry.Significance StatementAmotivation is present in both depression and schizophrenia. However, treatment involves use of drugs that enhance serotonin activity in depression and inhibit serotonin and dopamine activity in schizophrenia. Understanding how motivation processed in the mesocorticolimbic and nigostriatal pathways is affected in depression and schizophrenia is important in discovering treatment targets and strategies for amotivation. To our knowledge this is the first study to compare patients with depression and schizophrenia in a common functional construct. By using an effort-based reinforcement task and examining resting-state functional connectivity in the dopaminergic network, we propose that difference in striato-orbitofrontal dysfunction in effort-based reinforcement between depression and schizophrenia may be related to difference in the extent of functional dysconnectivity in the dopaminergic pathway.},
	number = {16},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Park, Ho Il and Lee, Boung Chul and Kim, Jae-Jin and Il Kim, Joong and Koo, Min-Seung},
	year = {2017},
	pmid = {28283562},
	keywords = {significance statement, amotivation is present in, and inhibit serotonin and, both depression and schizophrenia, depression, dopamine activity in schizophrenia, functional neuroimaging, however, motivation, of drugs that enhance, schizophrenia, sero-, tonin activity in depression, treatment involves the use, understanding how motivation pro-, ventral tegmental area},
	pages = {2524--16},
	file = {Attachment:/Users/tito/Zotero/storage/ICLZ8PMQ/Park et al. - 2017 - Effort-based reinforcement processing and functional connectivity underlying amotivation in medicated patients with.pdf:application/pdf},
}

@article{bell_information_1995,
	title = {An {Information} {Maximization} {Approach} to {Blind} {Separation} and {Blind} {Deconvolution}},
	volume = {7},
	issn = {0899-7667},
	doi = {DOI: 10.1162/neco.1995.7.6.1129},
	abstract = {We derive a new self organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zeronoise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higherorder moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higherorder generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in "blind" signal processing.},
	number = {1994},
	journal = {Neural computation},
	author = {Bell, Anthony J and Sejnowski, Terrence J},
	year = {1995},
	pmid = {7584893},
	pages = {1129},
	file = {Attachment:/Users/tito/Zotero/storage/ZHSH22FE/Bell, Sejnowski - 1995 - An Information Maximization Approach to Blind Separation and Blind Deconvolution.pdf:application/pdf},
}

@article{bertolero_diverse_2017-1,
	title = {The {Diverse} {Club}: {The} {Integrative} {Core} of {Complex} {Networks}},
	journal = {arXiv preprint arXiv:1701.01150},
	author = {Bertolero, M A and Yeo, B T T and D'Esposito, M},
	year = {2017},
}

@article{battaglia_dynamic_2012,
	title = {Dynamic {Effective} {Connectivity} of {Inter}-{Areal} {Brain} {Circuits}},
	volume = {8},
	url = {https://doi.org/10.1371/journal.pcbi.1002438},
	abstract = {Author Summary The circuits of the brain must perform a daunting amount of functions. But how can “brain states” be flexibly controlled, given that anatomic inter-areal connections can be considered as fixed, on timescales relevant for behavior? We hypothesize that, thanks to the nonlinear interaction between brain rhythms, even a simple circuit involving few brain areas can originate a multitude of effective circuits, associated with alternative functions selectable “on demand”. A distinction is usually made between structural connectivity, which describes actual synaptic connections, and effective connectivity, quantifying, beyond correlation, directed inter-areal causal influences. In our study, we measure effective connectivity based on time-series of neural activity generated by model inter-areal circuits. We find that “causality follows dynamics”. We show indeed that different effective networks correspond to different dynamical states associated to a same structural network (in particular, different phase-locking patterns between local neuronal oscillations). We then find that “information follows causality” (and thus, again, dynamics). We demonstrate that different effective networks give rise to alternative modalities of information routing between brain areas wired together in a fixed structural network. In particular, we show that the self-organization of interacting “analog” rate oscillations control the flow of “digital-like” information encoded in complex spiking patterns.},
	number = {3},
	journal = {PLOS Computational Biology},
	author = {Battaglia, Demian and Witt, Annette and Wolf, Fred and Geisel, Theo},
	month = mar,
	year = {2012},
	pages = {e1002438},
	file = {Attachment:/Users/tito/Zotero/storage/5EI9FPPZ/Battaglia et al. - 2012 - Dynamic Effective Connectivity of Inter-Areal Brain Circuits.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/VS9VDXKT/Battaglia et al. - 2012 - Dynamic Effective Connectivity of Inter-Areal Brain Circuits.pdf:application/pdf},
}

@article{anzellotti_directed_2017,
	title = {Directed network discovery with dynamic network modelling},
	volume = {99},
	issn = {0028-3932},
	url = {http://www.sciencedirect.com/science/article/pii/S0028393217300520},
	doi = {https://doi.org/10.1016/j.neuropsychologia.2017.02.006},
	abstract = {Abstract Cognitive tasks recruit multiple brain regions. Understanding how these regions influence each other (the network structure) is an important step to characterize the neural basis of cognitive processes. Often, limited evidence is available to restrict the range of hypotheses a priori, and techniques that sift efficiently through a large number of possible network structures are needed (network discovery). This article introduces a novel modelling technique for network discovery (Dynamic Network Modelling or DNM) that builds on ideas from Granger Causality and Dynamic Causal Modelling introducing three key changes: (1) efficient network discovery is implemented with statistical tests on the consistency of model parameters across participants, (2) the tests take into account the magnitude and sign of each influence, and (3) variance explained in independent data is used as an absolute (rather than relative) measure of the quality of the network model. In this article, we outline the functioning of DNM, we validate DNM in simulated data for which the ground truth is known, and we report an example of its application to the investigation of influences between regions during emotion recognition, revealing top-down influences from brain regions encoding abstract representations of emotions (medial prefrontal cortex and superior temporal sulcus) onto regions engaged in the perceptual analysis of facial expressions (occipital face area and fusiform face area) when participants are asked to switch between reporting the emotional valence and the age of a face.},
	journal = {Neuropsychologia},
	author = {Anzellotti, Stefano and Kliemann, Dorit and Jacoby, Nir and Saxe, Rebecca},
	month = may,
	year = {2017},
	keywords = {Connectivity, Granger causality, Dynamic causal modelling, Dynamic network modelling, Emotions},
	pages = {1--11},
}

@article{cohen_computational_2017,
	title = {Computational approaches to {fMRI} analysis},
	volume = {20},
	issn = {1097-6256},
	url = {http://dx.doi.org/10.1038/nn.4499 http://10.0.4.14/nn.4499},
	abstract = {Analysis methods in cognitive neuroscience have not always matched the richness of fMRI data. Early methods focused on estimating neural activity within individual voxels or regions, averaged over trials or blocks and modeled separately in each participant. This approach mostly neglected the distributed nature of neural representations over voxels, the continuous dynamics of neural activity during tasks, the statistical benefits of performing joint inference over multiple participants and the value of using predictive models to constrain analysis. Several recent exploratory and theory-driven methods have begun to pursue these opportunities. These methods highlight the importance of computational techniques in fMRI analysis, especially machine learning, algorithmic optimization and parallel computing. Adoption of these techniques is enabling a new generation of experiments and analyses that could transform our understanding of some of the most complex[mdash]and distinctly human[mdash]signals in the brain: acts of cognition such as thoughts, intentions and memories.},
	number = {3},
	journal = {Nat Neurosci},
	author = {Cohen, Jonathan D and Daw, Nathaniel and Engelhardt, Barbara and Hasson, Uri and Li, Kai and Niv, Yael and Norman, Kenneth A and Pillow, Jonathan and Ramadge, Peter J and Turk-Browne, Nicholas B and Willke, Theodore L},
	month = mar,
	year = {2017},
	pages = {304--313},
}

@article{warren_surgically_2017,
	title = {Surgically disconnected temporal pole exhibits resting functional connectivity with remote brain regions 1},
	author = {Warren, David E. and Sutterer, Matthew J. and Bruss, Joel and Abel, Taylor J. and Jones, Andrew and Kawasaki, Hiroto and Voss, Michelle and Cassell, Martin and Howard, Matthew A. and Tranel, Daniel},
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/H8CKB3ME/Warren et al. - 2017 - Surgically disconnected temporal pole exhibits resting functional connectivity with remote brain regions 1.pdf:application/pdf},
}

@article{litwin-kumar_optimal_2017,
	title = {Optimal {Degrees} of {Synaptic} {Connectivity}},
	volume = {0},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627317300545},
	doi = {10.1016/j.neuron.2017.01.030},
	number = {0},
	journal = {Neuron},
	author = {Litwin-Kumar, Ashok and Harris, Kameron Decker and Axel, Richard and Sompolinsky, Haim and Abbott, L.F.},
	year = {2017},
	pmid = {28215558},
	pages = {1153--1164.e7},
	file = {Attachment:/Users/tito/Zotero/storage/RPXJDDUW/Litwin-Kumar et al. - 2017 - Optimal Degrees of Synaptic Connectivity.pdf:application/pdf},
}

@article{kay_bottom-up_2016,
	title = {Bottom-up and top-down computations in high-level visual cortex},
	issn = {2337-4349},
	doi = {10.1101/053595},
	journal = {bioRxiv},
	author = {Kay, Kendrick and Yeatman, Jason},
	year = {2016},
	pages = {1--29},
	file = {Attachment:/Users/tito/Zotero/storage/4IR9MJ4J/Kay, Yeatman - 2016 - Bottom-up and top-down computations in high-level visual cortex.pdf:application/pdf},
}

@article{damicelli_modular_2017,
	title = {Modular topology emerges from plasticity in a minimalistic excitable network model},
	volume = {27},
	issn = {1054-1500},
	url = {http://aip.scitation.org/doi/10.1063/1.4979561},
	doi = {10.1063/1.4979561},
	number = {4},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Damicelli, Fabrizio and Hilgetag, Claus C. and Hütt, Marc-Thorsten and Messé, Arnaud},
	year = {2017},
	pages = {047406},
	file = {Attachment:/Users/tito/Zotero/storage/DAQ25LVZ/Damicelli et al. - 2017 - Modular topology emerges from plasticity in a minimalistic excitable network model.pdf:application/pdf},
}

@article{lombardi_balance_2017,
	title = {Balance of excitation and inhibition determines 1/f power spectrum in neuronal networks},
	volume = {27},
	issn = {1054-1500},
	url = {http://aip.scitation.org/doi/10.1063/1.4979043},
	doi = {10.1063/1.4979043},
	number = {4},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Lombardi, F. and Herrmann, H. J. and de Arcangelis, L.},
	year = {2017},
	pages = {047402},
	file = {Attachment:/Users/tito/Zotero/storage/8G7YDVFN/Lombardi, Herrmann, de Arcangelis - 2017 - Balance of excitation and inhibition determines 1f power spectrum in neuronal networks.pdf:application/pdf},
}

@article{chaudhuri_large-scale_2015,
	title = {A {Large}-{Scale} {Circuit} {Mechanism} for {Hierarchical} {Dynamical} {Processing} in the {Primate} {Cortex}},
	volume = {88},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2015.09.008},
	doi = {10.1016/j.neuron.2015.09.008},
	abstract = {We developed a large-scale dynamical model of the macaque neocortex, which is based on recently acquired directed- and weighted-connectivity data from tract-tracing experiments, and which incorporates heterogeneity across areas. A hierarchy of timescales naturally emerges from this system: sensory areas show brief, transient responses to input (appropriate for sensory processing), whereas association areas integrate inputs over time and exhibit persistent activity (suitable for decision-making and working memory). The model displays multiple temporal hierarchies, as evidenced by contrasting responses to visual versus somatosensory stimulation. Moreover, slower prefrontal and temporal areas have a disproportionate impact on global brain dynamics. These findings establish a circuit mechanism for "temporal receptive windows" that are progressively enlarged along the cortical hierarchy, suggest an extension of time integration in decision making from local to large circuits, and should prompt a re-evaluation of the analysis of functional connectivity (measured by fMRI or electroencephalography/magnetoencephalography) by taking into account inter-areal heterogeneity. Chaudhuri et al. report a large-scale model of the macaque cortex incorporating quantitative anatomical data and inter-areal heterogeneity. This model gives rise to a hierarchy of timescales and suggests a revision of functional connectivity analysis of global brain dynamics.},
	number = {2},
	journal = {Neuron},
	author = {Chaudhuri, Rishidev and Knoblauch, Kenneth and Gariel, Marie Alice and Kennedy, Henry and Wang, Xiao Jing},
	year = {2015},
	pmid = {26439530},
	pages = {419--431},
	file = {Attachment:/Users/tito/Zotero/storage/FP7NPHAV/Chaudhuri et al. - 2015 - A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex.pdf:application/pdf},
}

@article{waskom_distributed_2016,
	title = {Distributed representation of context by intrinsic subnetworks in prefrontal cortex},
	volume = {114},
	issn = {0027-8424},
	doi = {https://doi.org/10.1101/074880},
	number = {8},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Waskom, Michael L and Wagner, Anthony D},
	year = {2016},
	pmid = {28174269},
	pages = {2030--2035},
	file = {Attachment:/Users/tito/Zotero/storage/WZCEIAQE/Waskom, Wagner - 2016 - Distributed representation of context by intrinsic subnetworks in prefrontal cortex.pdf:application/pdf},
}

@article{gray_oscillatory_2015,
	title = {Oscillatory {Recruitment} of {Bilateral} {Visual} {Cortex} during {Spatial} {Attention} to {Competing} {Rhythmic} {Inputs}},
	volume = {35},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/content/35/14/5489.short},
	doi = {10.1523/JNEUROSCI.2891-14.2015},
	abstract = {Selective attention uses temporal regularity of relevant inputs to bias the phase of ongoing population-level neuronal oscillations. This phase entrainment streamlines processing, allowing attended information to arrive at moments of high neural excitability. How entrainment resolves competition between spatially segregated inputs during visuospatial tasks is not yet established. Using high-density electroencephalography in humans, a bilateral entrainment response to the rhythm (1.3 or 1.5 Hz) of an attended stimulation stream was observed, concurrent with a considerably weaker contralateral entrainment to a competing rhythm. That ipsilateral visual areas strongly entrained to the attended stimulus is notable because competitive inputs to these regions were being driven at an entirely different rhythm. Strong modulations of phase locking and weak modulations of single-trial power suggest that entrainment was primarily driven by phase-alignment of ongoing oscillatory activity. In addition, interhemispheric differences in entrained phase were found to be modulated by attended hemifield, implying that the bilateral nature of the response reflected a functional flow of information between hemispheres. This modulation was strongest at the third of at least four harmonics that were strongly entrained. Ipsilateral increases in alpha-band (8-12 Hz) power were also observed during bilateral entrainment, reflecting suppression of the ignored stimulation stream. Furthermore, both entrainment and alpha lateralization significantly affected task performance. We conclude that oscillatory entrainment is a functionally relevant mechanism that synchronizes endogenous activity across the cortical hierarchy to resolve spatial competition. We further speculate that concurrent suppression of ignored input might facilitate the widespread propagation of attended information during spatial attention.},
	number = {14},
	journal = {Journal of Neuroscience},
	author = {Gray, M. J. and Frey, H.-P. and Wilson, T. J. and Foxe, J. J.},
	year = {2015},
	pmid = {25855167},
	keywords = {attention, oscillations, biased competition, delta band, entrainment, harmonics},
	pages = {5489--5503},
	file = {Attachment:/Users/tito/Zotero/storage/4CAJQV3M/Gray et al. - 2015 - Oscillatory Recruitment of Bilateral Visual Cortex during Spatial Attention to Competing Rhythmic Inputs.pdf:application/pdf},
}

@article{rau_firing-rate_2015,
	title = {Firing-rate resonances in the peripheral auditory system of the cricket, {Gryllus} bimaculatus},
	volume = {201},
	issn = {14321351},
	doi = {10.1007/s00359-015-1036-1},
	abstract = {In many communication systems, information is encoded in the temporal pattern of signals. For rhythmic signals that carry information in specific frequency bands, a neuronal system may profit from tuning its inherent filtering properties towards a peak sensitivity in the respective frequency range. The cricket Gryllus bimaculatus evaluates acoustic communication signals of both conspecifics and predators. The song signals of conspecifics exhibit a characteristic pulse pattern that contains only a narrow range of modulation frequencies. We examined individual neurons (AN1, AN2, ON1) in the peripheral auditory system of the cricket for tuning towards specific modulation frequencies by assessing their firing-rate resonance. Acoustic stimuli with a swept-frequency envelope allowed an efficient characterization of the cells' modulation transfer functions. Some of the examined cells exhibited tuned band-pass properties. Using simple computational models, we demonstrate how different, cell-intrinsic or network-based mechanisms such as subthreshold resonances, spike-triggered adaptation, as well as an interplay of excitation and inhibition can account for the experimentally observed firing-rate resonances. Therefore, basic neuronal mechanisms that share negative feedback as a common theme may contribute to selectivity in the peripheral auditory pathway of crickets that is designed towards mate recognition and predator avoidance.},
	number = {11},
	journal = {Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology},
	author = {Rau, Florian and Clemens, Jan and Naumov, Victor and Hennig, R. Matthias and Schreiber, Susanne},
	year = {2015},
	pmid = {26293318},
	keywords = {Acoustic communication, Auditory processing, Band-pass filtering, Negative feedback, Neuron models},
	pages = {1075--1090},
	file = {Attachment:/Users/tito/Zotero/storage/XE83B8SJ/Rau et al. - 2015 - Firing-rate resonances in the peripheral auditory system of the cricket, Gryllus bimaculatus.pdf:application/pdf},
}

@article{foxe_role_2011,
	title = {The role of alpha-band brain oscillations as a sensory suppression mechanism during selective attention},
	volume = {2},
	issn = {16641078},
	doi = {10.3389/fpsyg.2011.00154},
	abstract = {Evidence has amassed from both animal intracranial recordings and human electrophysiology that neural oscillatory mechanisms play a critical role in a number of cognitive functions such as learning, memory, feature binding and sensory gating. The wide availability of high-density electrical and magnetic recordings (64-256 channels) over the past two decades has allowed for renewed efforts in the characterization and localization of these rhythms. A variety of cognitive effects that are associated with specific brain oscillations have been reported, which range in spectral, temporal, and spatial characteristics depending on the context. Our laboratory has focused on investigating the role of alpha-band oscillatory activity (8-14 Hz) as a potential attentional suppression mechanism, and this particular oscillatory attention mechanism will be the focus of the current review. We discuss findings in the context of intersensory selective attention as well as intrasensory spatial and feature-based attention in the visual, auditory, and tactile domains. The weight of evidence suggests that alpha-band oscillations can be actively invoked within cortical regions across multiple sensory systems, particularly when these regions are involved in processing irrelevant or distracting information. That is, a central role for alpha seems to be as an attentional suppression mechanism when objects or features need to be specifically ignored or selected against.},
	number = {JUL},
	journal = {Frontiers in Psychology},
	author = {Foxe, John J. and Snyder, Adam C.},
	year = {2011},
	pmid = {21779269},
	keywords = {EEG, Alpha, Attention, Biasing, Brain, Oscillations, Selection, Suppression},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/IBX6MX4K/Foxe, Snyder - 2011 - The role of alpha-band brain oscillations as a sensory suppression mechanism during selective attention.pdf:application/pdf},
}

@article{breakspear_dynamic_2017,
	title = {Dynamic models of large-scale brain activity},
	volume = {20},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.4497},
	doi = {10.1038/nn.4497},
	number = {3},
	journal = {Nature Neuroscience},
	author = {Breakspear, Michael},
	year = {2017},
	pages = {340--352},
	file = {Attachment:/Users/tito/Zotero/storage/8B77VPI2/Breakspear - 2017 - Dynamic models of large-scale brain activity.pdf:application/pdf},
}

@article{eickhoff_topographic_2017,
	title = {Topographic organization of the cerebral cortex and brain cartography},
	issn = {10538119},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/28219775%0Ahttp://linkinghub.elsevier.com/retrieve/pii/S1053811917301222},
	doi = {10.1016/j.neuroimage.2017.02.018},
	abstract = {One of the most specific but also challenging properties of the brain is its topographic organization into distinct modules or cortical areas. In this paper, we first review the concept of topographic organization and its historical development. Next, we provide a critical discussion of the current definition of what constitutes a cortical area, why the concept has been so central to the field of neuroimaging and the challenges that arise from this view. A key aspect in this discussion is the issue of spatial scale and hierarchy in the brain. Focusing on in-vivo brain parcellation as a rapidly expanding field of research, we highlight potential limitations of the classical concept of cortical areas in the context of multi-modal parcellation and propose a revised interpretation of cortical areas building on the concept of neurobiological atoms that may be aggregated into larger units within and across modalities. We conclude by presenting an outlook on the implication of this revised concept for future mapping studies and raise some open questions in the context of brain parcellation.},
	number = {February},
	journal = {NeuroImage},
	author = {Eickhoff, Simon B. and Constable, R. Todd and Yeo, B.T. Thomas},
	year = {2017},
	pmid = {28219775},
	pages = {1--16},
	file = {Attachment:/Users/tito/Zotero/storage/2MFZFEQS/Eickhoff, Constable, Yeo - 2017 - Topographic organization of the cerebral cortex and brain cartography.pdf:application/pdf},
}

@article{reddan_effect_2017,
	title = {Effect {Size} {Estimation} in {Neuroimaging}},
	volume = {4},
	issn = {2168-622X},
	doi = {10.1001/JAMAPSYCHIATRY.2016.3356},
	number = {5},
	journal = {JAMA Psychiatry},
	author = {Reddan, Marianne C. and Lindquist, Martin A. and Wager, Tor D. and RJ, Grissom and KS, Button and MA, Lindquist and LJ, Chang and T, Hastie},
	year = {2017},
	pmid = {28099973},
	keywords = {neuroimaging},
	pages = {863},
	file = {Attachment:/Users/tito/Zotero/storage/V53FJMKW/Reddan et al. - 2017 - Effect Size Estimation in Neuroimaging.pdf:application/pdf},
}

@article{pernet_misconceptions_2014,
	title = {Misconceptions in the use of the {General} {Linear} {Model} applied to functional {MRI}: {A} tutorial for junior neuro-imagers},
	volume = {8},
	issn = {1662453X},
	doi = {10.3389/fnins.2014.00001},
	abstract = {This tutorial presents several misconceptions related to the use the General Linear Model (GLM) in functional Magnetic Resonance Imaging (fMRI). The goal is not to present mathematical proofs but to educate using examples and computer code (in Matlab). In particular, I address issues related to (1) model parameterization (modeling baseline or null events) and scaling of the design matrix; (2) hemodynamic modeling using basis functions, and (3) computing percentage signal change. Using a simple controlled block design and an alternating block design, I first show why "baseline" should not be modeled (model over-parameterization), and how this affects effect sizes. I also show that, depending on what is tested; over-parameterization does not necessarily impact upon statistical results. Next, using a simple periodic vs. random event related design, I show how the hemodynamic model (hemodynamic function only or using derivatives) can affects parameter estimates, as well as detail the role of orthogonalization. I then relate the above results to the computation of percentage signal change. Finally, I discuss how these issues affect group analyses and give some recommendations.},
	number = {8 JAN},
	journal = {Frontiers in Neuroscience},
	author = {Pernet, Cyril R.},
	year = {2014},
	pmid = {24478622},
	keywords = {FMRI, Baseline, Derivatives, GLM, Modeling, Percentage signal change},
	pages = {1--12},
	file = {Attachment:/Users/tito/Zotero/storage/BFVXC74C/Pernet - 2014 - Misconceptions in the use of the General Linear Model applied to functional MRI A tutorial for junior neuro-imagers.pdf:application/pdf},
}

@article{mill_connectome_2017,
	title = {From connectome to cognition: {The} search for mechanism in human functional brain networks},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2017.01.060},
	doi = {10.1016/j.neuroimage.2017.01.060},
	abstract = {Recent developments in functional connectivity research have expanded the scope of human neuroimaging, from identifying changes in regional activation amplitudes to detailed mapping of large-scale brain networks. However, linking network processes to a clear role in cognition demands advances in the theoretical frameworks, algorithms, and experimental approaches applied. This would help evolve the field from a descriptive to an explanatory state, by targeting network interactions that can mechanistically account for cognitive effects. In the present review, we provide an explicit framework to aid this search for “network mechanisms”, which anchors recent methodological advances in functional connectivity estimation to a renewed emphasis on careful experimental design. We emphasize how this framework can address specific questions in network neuroscience. These span ambiguity over the cognitive relevance of resting-state networks, how to characterize task-evoked and spontaneous network dynamics, how to identify directed or “effective” connections, and how to apply multivariate pattern analysis at the network level. In parallel, we apply the framework to highlight the mechanistic interaction of network components that remain “stable” across task domains and more “flexible” components associated with on-task reconfiguration. By emphasizing the need to structure the use of diverse analytic approaches with sound experimentation, our framework promotes an explanatory mapping between the workings of the cognitive mind and the large-scale network mechanisms of the human brain.},
	number = {January},
	journal = {NeuroImage},
	author = {Mill, Ravi D. and Ito, Takuya and Cole, Michael W.},
	year = {2017},
	keywords = {Functional connectivity, functional connectivity, MVPA, Computational modeling, directed connectivity, Directed connectivity, dynamic connectivity, Dynamic connectivity, Multi-modal neuroimaging},
	pages = {0--1},
	file = {Attachment:/Users/tito/Zotero/storage/ZX9T4E76/Mill, Ito, Cole - 2017 - From connectome to cognition The search for mechanism in human functional brain networks.pdf:application/pdf},
}

@article{bassett_network_2017,
	title = {Network neuroscience},
	volume = {20},
	issn = {1097-6256},
	doi = {10.1038/nn.4502},
	abstract = {Despite substantial recent progress, our understanding of the principles and mechanisms underlying complex brain function and cognition remains incomplete. Network neuroscience proposes to tackle these enduring challenges. Approaching brain structure and function from an explicitly integrative perspective, network neuroscience pursues new ways to map, record, analyze and model the elements and interactions of neurobiological systems. Two parallel trends drive the approach: the availability of new empirical tools to create comprehensive maps and record dynamic patterns among molecules, neurons, brain areas and social systems; and the theoretical framework and computational tools of modern network science. The convergence of empirical and computational advances opens new frontiers of scientific inquiry, including network dynamics, manipulation and control of brain networks, and integration of network processes across spatiotemporal domains. We review emerging trends in network neuroscience and attempt to chart a path toward a better understanding of the brain as a multiscale networked system.},
	number = {3},
	journal = {Nature Neuroscience},
	author = {Bassett, Danielle S and Sporns, Olaf},
	year = {2017},
	pages = {353},
	file = {Attachment:/Users/tito/Zotero/storage/KWRASESD/Bassett, Sporns - 2017 - Network neuroscience.pdf:application/pdf},
}

@article{friedman_analysis_2016,
	title = {Analysis of complex neural circuits with nonlinear multidimensional hidden state models},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/113/23/6538%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/27222584%5Cnhttp://www.pnas.org/content/113/23/6538.full%5Cnhttp://www.pnas.org/content/113/23/6538.full.pdf},
	doi = {10.1073/pnas.1606280113},
	abstract = {A universal need in understanding complex networks is the identification of individual information channels and their mutual interactions under different conditions. In neuroscience, our premier example, networks made up of billions of nodes dynamically interact to bring about thought and action. Granger causality is a powerful tool for identifying linear interactions, but handling nonlinear interactions remains an unmet challenge. We present a nonlinear multidimensional hidden state (NMHS) approach that achieves interaction strength analysis and decoding of networks with nonlinear interactions by including latent state variables for each node in the network. We compare NMHS to Granger causality in analyzing neural circuit recordings and simulations, improvised music, and sociodemographic data. We conclude that NMHS significantly extends the scope of analyses of multidimensional, nonlinear networks, notably in coping with the complexity of the brain.},
	number = {23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Friedman, Alexander and Slocum, Joshua F. and Tyulmankov, Danil and Gibb, Leif G. and Altshuler, Alex and Ruangwises, Suthee and Shi, Qinru and Arana, Sebastian E. Toro and Beck, Dirk W. and Sholes, Jacquelyn E. C. and Graybiel, Ann M.},
	year = {2016},
	pmid = {27222584},
	pages = {6538--6543},
	file = {Attachment:/Users/tito/Zotero/storage/PBJNXX96/Friedman et al. - 2016 - Analysis of complex neural circuits with nonlinear multidimensional hidden state models.pdf:application/pdf},
}

@article{melnikoff_mythical_2018,
	title = {The {Mythical} {Number} {Two}},
	volume = {22},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S136466131830024X},
	doi = {10.1016/j.tics.2018.02.001},
	abstract = {It is often said that there are two types of psychological processes: one that is intentional, controllable, conscious, and inefficient, and another that is unintentional, uncontrollable, unconscious, and efficient. Yet, there have been persistent and increasing objections to this widely influential dual-process typology. Critics point out that the ‘two types’ framework lacks empirical support, contradicts well-established findings, and is internally incoherent. Moreover, the untested and untenable assumption that psychological phenomena can be partitioned into two types, we argue, has the consequence of systematically thwarting scientific progress. It is time that we as a field come to terms with these issues. In short, the dual-process typology is a convenient and seductive myth, and we think cognitive science can do better.},
	number = {4},
	urldate = {2018-11-29},
	journal = {Trends in Cognitive Sciences},
	author = {Melnikoff, David E. and Bargh, John A.},
	month = apr,
	year = {2018},
	keywords = {automaticity, dual process, dual system, type 1, type 2},
	pages = {280--293},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/EPG6UT9T/Melnikoff and Bargh - 2018 - The Mythical Number Two.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/PZ7EXE8L/S136466131830024X.html:text/html},
}

@article{becker_identification_nodate,
	title = {{IDENTIFICATION} {OF} {NETWORKS} {OF} {WILSON}-{COWAN} {NEURONAL} {OSCILLATORS} {BY} {INVERSE} {SIGMOIDAL} {TRANSFORMATION} {University} of {Pennsylvania} {Department} of {Electrical} and {Systems} {Engineering} {Department} of {Bioengineering} {Philadelphia} , {PA} 19104 {USA}},
	author = {Becker, Cassiano O and Khambhati, Ankit N and Bassett, Danielle S and Preciado, Victor M},
	file = {Attachment:/Users/tito/Zotero/storage/2Q64HXNN/Becker et al. - Unknown - IDENTIFICATION OF NETWORKS OF WILSON-COWAN NEURONAL OSCILLATORS BY INVERSE SIGMOIDAL TRANSFORMATION University.pdf:application/pdf},
}

@article{havlicek_dynamic_2011,
	title = {Dynamic modeling of neuronal responses in {fMRI} using cubature {Kalman} filtering},
	volume = {56},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2011.03.005},
	doi = {10.1016/j.neuroimage.2011.03.005},
	abstract = {This paper presents a new approach to inverting (fitting) models of coupled dynamical systems based on state-of-the-art (cubature) Kalman filtering. Crucially, this inversion furnishes posterior estimates of both the hidden states and parameters of a system, including any unknown exogenous input. Because the underlying generative model is formulated in continuous time (with a discrete observation process) it can be applied to a wide variety of models specified with either ordinary or stochastic differential equations. These are an important class of models that are particularly appropriate for biological time-series, where the underlying system is specified in terms of kinetics or dynamics (i.e., dynamic causal models). We provide comparative evaluations with generalized Bayesian filtering (dynamic expectation maximization) and demonstrate marked improvements in accuracy and computational efficiency. We compare the schemes using a series of difficult (nonlinear) toy examples and conclude with a special focus on hemodynamic models of evoked brain responses in fMRI. Our scheme promises to provide a significant advance in characterizing the functional architectures of distributed neuronal systems, even in the absence of known exogenous (experimental) input; e.g., resting state fMRI studies and spontaneous fluctuations in electrophysiological studies. Importantly, unlike current Bayesian filters (e.g. DEM), our scheme provides estimates of time-varying parameters, which we will exploit in future work on the adaptation and enabling of connections in the brain. ?? 2011 Elsevier Inc.},
	number = {4},
	journal = {NeuroImage},
	author = {Havlicek, Martin and Friston, Karl J. and Jan, Jiri and Brazdil, Milan and Calhoun, Vince D.},
	year = {2011},
	pmid = {21396454},
	keywords = {FMRI, Blind deconvolution, Cubature Kalman filter, Dynamic expectation maximization, Hemodynamic modeling, Neuronal, Nonlinear, Smoother, Stochastic},
	pages = {2109--2128},
	file = {Attachment:/Users/tito/Zotero/storage/WLDTLK2B/Havlicek et al. - 2011 - Dynamic modeling of neuronal responses in fMRI using cubature Kalman filtering.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TRQFQ74A/Havlicek et al. - 2011 - Dynamic modeling of neuronal responses in fMRI using cubature Kalman filtering.pdf:application/pdf},
}

@article{jazayeri_perspective_2017,
	title = {Perspective {Navigating} the {Neural} {Space} in {Search} of the {Neural} {Code}},
	volume = {93},
	issn = {0896-6273},
	url = {http://dx.doi.org/10.1016/j.neuron.2017.02.019},
	doi = {10.1016/j.neuron.2017.02.019},
	number = {5},
	journal = {Neuron},
	author = {Jazayeri, Mehrdad and Afraz, Arash},
	year = {2017},
	pages = {1003--1014},
	file = {Attachment:/Users/tito/Zotero/storage/65YNSMGS/Jazayeri, Afraz - 2017 - Perspective Navigating the Neural Space in Search of the Neural Code.pdf:application/pdf},
}

@article{borgers_synchronization_2003,
	title = {Synchronization in networks of excitatory and inhibitory neurons with sparse, random connectivity.},
	volume = {15},
	issn = {0899-7667},
	doi = {10.1162/089976603321192059},
	abstract = {In model networks of E-cells and I-cells (excitatory and inhibitory neurons, respectively), synchronous rhythmic spiking often comes about from the interplay between the two cell groups: the E-cells synchronize the I-cells and vice versa. Under ideal conditions-homogeneity in relevant network parameters and all-to-all connectivity, for instance-this mechanism can yield perfect synchronization. We find that approximate, imperfect synchronization is possible even with very sparse, random connectivity. The crucial quantity is the expected number of inputs per cell. As long as it is large enough (more precisely, as long as the variance of the total number of synaptic inputs per cell is small enough), tight synchronization is possible. The desynchronizing effect of random connectivity can be reduced by strengthening the E –{\textbackslash}textgreater I synapses. More surprising, it cannot be reduced by strengthening the I –{\textbackslash}textgreater E synapses. However, the decay time constant of inhibition plays an important role. Faster decay yields tighter synchrony. In particular, in models in which the inhibitory synapses are assumed to be instantaneous, the effects of sparse, random connectivity cannot be seen.},
	journal = {Neural computation},
	author = {Börgers, Christoph and Kopell, Nancy},
	year = {2003},
	pmid = {12620157},
	pages = {509--538},
}

@article{stark_local_2015,
	title = {Local generation of multineuronal spike sequences in the hippocampal {CA1} region.},
	volume = {112},
	issn = {1091-6490},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26240336%5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4547251},
	doi = {10.1073/pnas.1508785112},
	abstract = {Sequential activity of multineuronal spiking can be observed during theta and high-frequency ripple oscillations in the hippocampal CA1 region and is linked to experience, but the mechanisms underlying such sequences are unknown. We compared multineuronal spiking during theta oscillations, spontaneous ripples, and focal optically induced high-frequency oscillations ("synthetic" ripples) in freely moving mice. Firing rates and rate modulations of individual neurons, and multineuronal sequences of pyramidal cell and interneuron spiking, were correlated during theta oscillations, spontaneous ripples, and synthetic ripples. Interneuron spiking was crucial for sequence consistency. These results suggest that participation of single neurons and their sequential order in population events are not strictly determined by extrinsic inputs but also influenced by local-circuit properties, including synapses between local neurons and single-neuron biophysics.},
	number = {33},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Stark, Eran and Roux, Lisa and Eichler, Ronny and Buzsáki, György},
	year = {2015},
	pmid = {26240336},
	keywords = {hippocampus, mouse, optogenetics, ripples, temporal precision},
	pages = {10521--6},
	file = {Attachment:/Users/tito/Zotero/storage/W3NYIKRW/Stark et al. - 2015 - Local generation of multineuronal spike sequences in the hippocampal CA1 region.pdf:application/pdf},
}

@article{stokes_dynamic_2017,
	title = {Dynamic {Coding} for {Flexible} {Cognitive} {Control}},
	author = {Stokes, Mark G and Buschman, Timothy J and Miller, Earl K},
	year = {2017},
	pages = {221--241},
	file = {Attachment:/Users/tito/Zotero/storage/88SYRE27/Stokes, Buschman, Miller - 2017 - Dynamic Coding for Flexible Cognitive Control.pdf:application/pdf},
}

@article{stark_pyramidal_2014,
	title = {Pyramidal cell-interneuron interactions underlie hippocampal ripple oscillations},
	volume = {83},
	issn = {10974199},
	doi = {10.1016/j.neuron.2014.06.023},
	abstract = {High-frequency ripple oscillations, observed most prominently in the hippocampal CA1 pyramidal layer, are associated with memory consolidation. The cellular and network mechanisms underlying the generation, frequency control, and spatial coherence of the rhythm are poorly understood. Using multisite optogenetic manipulations in freely behaving rodents, we found that depolarization of a small group of nearby pyramidal cells was sufficient toinduce high-frequency oscillations, whereas closed-loop silencing of pyramidal cells or activation of parvalbumin- (PV) or somatostatin-immunoreactive interneurons aborted spontaneously occurring ripples. Focal pharmacological blockade of GABAA receptors abolished ripples. Localized PV interneuron activation paced ensemble spiking, and simultaneous induction of high-frequency oscillations at multiple locations resulted in a temporally coherent pattern mediated by phase-locked interneuron spiking. These results constrain competing models of ripple generation and indicate that temporally precise local interactions between excitatory and inhibitory neurons support ripple generation in the intact hippocampus. © 2014 Elsevier Inc.},
	number = {2},
	journal = {Neuron},
	author = {Stark, Eran and Roux, Lisa and Eichler, Ronny and Senzai, Yuta and Royer, Sebastien and Buzsáki, György},
	year = {2014},
	pmid = {25033186},
	pages = {467--480},
	file = {Attachment:/Users/tito/Zotero/storage/ZSH6IK33/Stark et al. - 2014 - Pyramidal cell-interneuron interactions underlie hippocampal ripple oscillations.pdf:application/pdf},
}

@article{brunton_discovering_2015,
	title = {Discovering governing equations from data: {Sparse} identification of nonlinear dynamical systems},
	volume = {1},
	issn = {0027-8424},
	url = {http://arxiv.org/abs/1509.03580},
	doi = {10.1073/pnas.1517384113},
	abstract = {The ability to discover physical laws and governing equations from data is one of humankind's greatest intellectual achievements. A quantitative understanding of dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled advanced technological achievements, including aircraft, combustion engines, satellites, and electrical power. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing physical equations from measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized, time-varying, or externally forced systems.},
	number = {609},
	journal = {arXiv},
	author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
	year = {2015},
	pmid = {27035946},
	keywords = {system identification, compressed sensing, dynamical systems, sparse regression},
	pages = {1--26},
	file = {Attachment:/Users/tito/Zotero/storage/ZPU6I9IQ/Brunton, Proctor, Kutz - 2015 - Discovering governing equations from data Sparse identification of nonlinear dynamical systems.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/EIPUC4UJ/Brunton, Proctor, Kutz - 2015 - Discovering governing equations from data Sparse identification of nonlinear dynamical systems(2).pdf:application/pdf},
}

@article{nitzan_revealing_2016,
	title = {Revealing physical network interactions from statistics of collective dynamics},
	issn = {2375-2548},
	doi = {10.1126/sciadv.1600396},
	number = {February},
	journal = {Nature Comm., submitted},
	author = {Nitzan, M. and Casadiego, J. and Timme, M.},
	year = {2016},
	pages = {2--8},
	file = {Attachment:/Users/tito/Zotero/storage/ZENFUUTE/Nitzan, Casadiego, Timme - 2017 - Revealing physical interaction networks from statistics of collective dynamics.pdf:application/pdf},
}

@article{borgers_effects_2005,
	title = {Effects of noisy drive on rhythms in networks of excitatory and inhibitory neurons},
	volume = {17},
	issn = {0899-7667},
	url = {papers3://publication/uuid/43D46EDB-663B-4F21-9553-8F0A6FF4C617},
	doi = {10.1162/0899766053019908},
	abstract = {Synchronous rhythmic spiking in neuronal networks can be brought about by the interaction between E-cells and Icells ( excitatory and inhibitory cells). The I-cells gate and synchronize the E-cells, and the E-cells drive and synchronize the I-cells. We refer to rhythms generated in this way as PING ( pyramidal-interneuronal gamma) rhythms. The PING mechanism requires that the drive I-I to the I-cells be sufficiently low; the rhythm is lost when I-I gets too large. This can happen in at least two ways. In the first mechanism, the I-cells spike in synchrony, but get ahead of the E-cells, spiking without being prompted by the E-cells. We call this phase walkthrough of the I-cells. In the second mechanism, the I-cells fail to synchronize, and their activity leads to complete suppression of the E-cells. Noisy spiking in the E-cells, generated by noisy external drive, adds excitatory drive to the I-cells and may lead to phase walkthrough. Noisy spiking in the I-cells adds inhibition to the E-cells and may lead to suppression of the E-cells. An analysis of the conditions under which noise leads to phase walkthrough of the I-cells or suppression of the E-cells shows that PING rhythms at frequencies far below the gamma range are robust to noise only if network parameter values are tuned very carefully. Together with an argument explaining why the PING mechanism does not work far above the gamma range in the presence of heterogeneity, this justifies the "G" in "PING.".},
	number = {3},
	journal = {Neural Computation},
	author = {Borgers, C and Kopell, N},
	year = {2005},
	pmid = {15802007},
	pages = {557--608},
	file = {Attachment:/Users/tito/Zotero/storage/7QF474NZ/Borgers, Kopell - 2005 - Effects of noisy drive on rhythms in networks of excitatory and inhibitory neurons.pdf:application/pdf},
}

@article{lewis_long_2013,
	title = {The long reach of the gene},
	volume = {26},
	issn = {09528229},
	doi = {10.1162/jocn},
	abstract = {The negotiation of social order is intimately connected to the capacity to infer and track status relationships. Despite the foundational role of status in social cognition, we know little about how the brain constructs status from social interactions that display it. Although emerging cognitive neuroscience reveals that status judgments depend on the intraparietal sulcus, a brain region that supports the comparison of targets along a quantitative continuum, we present evidence that status judgments do not necessarily reduce to ranking targets along a quantitative continuum. The process of judging status also fits a social interdependence analysis. Consistent with third-party perceivers judging status by inferring whose goals are dictating the terms of the interaction and who is subordinating their desires to whom, status judgments were associated with increased recruitment of medial pFC and STS, brain regions implicated in mental state inference},
	number = {3},
	journal = {Psychologist},
	author = {Lewis, Gary J. and Bates, Timothy C.},
	year = {2013},
	pmid = {23647519},
	pages = {194--198},
	file = {Attachment:/Users/tito/Zotero/storage/QZVZTJ3J/Lewis, Bates - 2013 - The long reach of the gene(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/UQ79Z6J6/Lewis, Bates - 2013 - The long reach of the gene.pdf:application/pdf},
}

@article{durstewitz_vers_2016,
	title = {Vers 02 {Nov} 2016},
	author = {Durstewitz, Daniel},
	year = {2016},
	pages = {1--33},
	file = {Attachment:/Users/tito/Zotero/storage/VURX3ZCU/Durstewitz - 2016 - Vers 02 Nov 2016.pdf:application/pdf},
}

@article{tu_estimating_2013,
	title = {Estimating the varying topology of discrete-time dynamical networks with noise},
	volume = {11},
	issn = {18951082 16443608},
	doi = {10.2478/s11534-013-0297-y},
	abstract = {We propose an improved method to estimate the varying topology of discrete-time dynamical networks using autosynchronization. The networks considered in this paper can be weighted or unweighted and directed or undirected, and the dynamics of each node can be nonuniform. Furthermore, we suggest using a moving-average filter to suppress the influence of noise on parameter estimation. Finally, several examples are illustrated to verify the theoretical results by numerical simulation. ? 2013 Versita Warsaw and Springer-Verlag Wien.},
	number = {8},
	journal = {Central European Journal of Physics},
	author = {Tu, C. and Cheng, Y. and Chen, K.},
	year = {2013},
	keywords = {complex network, [autosynchronization, discrete-ti},
	pages = {1045--1055},
	file = {Attachment:/Users/tito/Zotero/storage/23HM53GG/Tu, Cheng, Chen - 2013 - Estimating the varying topology of discrete-time dynamical networks with noise.pdf:application/pdf},
}

@article{egner_cognitive_2005,
	title = {Cognitive control mechanisms resolve conflict through cortical amplification of task-relevant information.},
	volume = {8},
	issn = {1097-6256},
	url = {http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&DbFrom=pubmed&Cmd=Link&LinkName=pubmed_pubmed&LinkReadableName=Related Articles&IdsFromResult=16286928&ordinalpos=3&itool=EntrezSystem2.PEntrez.Pubmed.Pubmed_ResultsPanel.Pubmed_RVDocSum},
	doi = {10.1038/nn1594},
	abstract = {A prominent model of how the brain regulates attention proposes that the anterior cingulate cortex monitors the occurrence of conflict between incompatible response tendencies and signals this information to a cognitive control system in dorsolateral prefrontal cortex. Cognitive control is thought to resolve conflict through the attentional biasing of perceptual processing, emphasizing task-relevant stimulus information. It is not known, however, whether conflict resolution is mediated by amplifying neural representations of task-relevant information, inhibiting representations of task-irrelevant information, or both. Here we manipulated trial-by-trial levels of conflict and control during a Stroop task using face stimuli, while recording hemodynamic responses from human visual cortex specialized for face processing. We show that, in response to high conflict, cognitive control mechanisms enhance performance by transiently amplifying cortical responses to task-relevant information rather than by inhibiting responses to task-irrelevant information. These results implicate attentional target-feature amplification as the primary mechanism for conflict resolution through cognitive control.},
	number = {12},
	journal = {Nature neuroscience},
	author = {Egner, Tobias and Hirsch, Joy},
	year = {2005},
	pmid = {16286928},
	keywords = {Attention, Adult, Behavior, Brain Mapping, Cerebral Cortex, Cerebrovascular Circulation, Cognition, Conflict (Psychology), Decision Making, Female, Functional Laterality, Humans, Magnetic Resonance Imaging, Male, Nerve Net, Neural Pathways, Neuropsychological Tests, Pattern Recognition, Photic Stimulation, Prefrontal Cortex, Reaction Time, Visual, Visual Cortex, Volition},
	pages = {1784--1790},
	file = {Attachment:/Users/tito/Zotero/storage/CF8K3I6D/Egner, Hirsch - 2005 - Cognitive control mechanisms resolve conflict through cortical amplification of task-relevant information.pdf:application/pdf},
}

@article{nitzan_revealing_2017,
	title = {Revealing physical interaction networks from statistics of collective dynamics},
	volume = {3},
	url = {http://advances.sciencemag.org/content/3/2/e1600396.abstract},
	abstract = {Revealing physical interactions in complex systems from observed collective dynamics constitutes a fundamental inverse problem in science. Current reconstruction methods require access to a system's model or dynamical data at a level of detail often not available. We exploit changes in invariant measures, in particular distributions of sampled states of the system in response to driving signals, and use compressed sensing to reveal physical interaction networks. Dynamical observations following driving suffice to infer physical connectivity even if they are temporally disordered, are acquired at large sampling intervals, and stem from different experiments. Testing various nonlinear dynamic processes emerging on artificial and real network topologies indicates high reconstruction quality for existence as well as type of interactions. These results advance our ability to reveal physical interaction networks in complex synthetic and natural systems.},
	number = {2},
	journal = {Science Advances},
	author = {Nitzan, Mor and Casadiego, Jose and Timme, Marc},
	month = feb,
	year = {2017},
	file = {Attachment:/Users/tito/Zotero/storage/NSQZDQVS/Nitzan, Casadiego, Timme - 2017 - Revealing physical interaction networks from statistics of collective dynamics.pdf:application/pdf},
}

@article{cichy_similarity-based_2016,
	title = {Similarity-{Based} {Fusion} of {MEG} and {fMRI} {Reveals} {Spatio}-{Temporal} {Dynamics} in {Human} {Cortex} {During} {Visual} {Object} {Recognition}},
	volume = {26},
	issn = {14602199},
	doi = {10.1093/cercor/bhw135},
	abstract = {Every human cognitive function, such as visual object recognition, is realized in a complex spatio-temporal activity pattern in the brain. Current brain imaging techniques in isolation cannot resolve the brain's spatio-temporal dynamics, because they provide either high spatial or temporal resolution but not both. To overcome this limitation, we developed an integration approach that uses representational similarities to combine measurements of magnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI) to yield a spatially and temporally integrated characterization of neuronal activation. Applying this approach to 2 independent MEG-fMRI data sets, we observed that neural activity first emerged in the occipital pole at 50-80 ms, before spreading rapidly and progressively in the anterior direction along the ventral and dorsal visual streams. Further region-of-interest analyses established that dorsal and ventral regions showed MEG-fMRI correspondence in representations later than early visual cortex. Together, these results provide a novel and comprehensive, spatio-temporally resolved view of the rapid neural dynamics during the first few hundred milliseconds of object vision. They further demonstrate the feasibility of spatially unbiased representational similarity-based fusion of MEG and fMRI, promising new insights into how the brain computes complex cognitive functions.},
	number = {8},
	journal = {Cerebral Cortex},
	author = {Cichy, Radoslaw Martin and Pantazis, Dimitrios and Oliva, Aude},
	year = {2016},
	pmid = {27235099},
	keywords = {fMRI, fmri, meg, MEG, multimodal integration, representational similarity analysis, visual object recognition},
	pages = {3563--3579},
	file = {Attachment:/Users/tito/Zotero/storage/LMISZTFW/Cichy, Pantazis, Oliva - 2016 - Similarity-Based Fusion of MEG and fMRI Reveals Spatio-Temporal Dynamics in Human Cortex During Visual O.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/PCJNVEQC/Cichy, Pantazis, Oliva - 2016 - Similarity-Based Fusion of MEG and fMRI Reveals Spatio-Temporal Dynamics in Human Cortex During Visua(2).pdf:application/pdf},
}

@article{atasoy_human_2016,
	title = {Human brain networks function in connectome-specific harmonic waves},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms10340%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26792267%5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4735826%5Cnhttp://www.nature.com/doifinder/10.1038/ncomms10340},
	doi = {10.1038/ncomms10340},
	abstract = {A key characteristic of human brain activity is coherent, spatially distributed oscillations forming behaviour-dependent brain networks. However, a fundamental principle underlying these networks remains unknown. Here we report that functional networks of the human brain are predicted by harmonic patterns, ubiquitous throughout nature, steered by the anatomy of the human cerebral cortex, the human connectome. We introduce a new technique extending the Fourier basis to the human connectome. In this new frequency-specific representation of cortical activity, that we call 'connectome harmonics', oscillatory networks of the human brain at rest match harmonic wave patterns of certain frequencies. We demonstrate a neural mechanism behind the self-organization of connectome harmonics with a continuous neural field model of excitatory-inhibitory interactions on the connectome. Remarkably, the critical relation between the neural field patterns and the delicate excitation-inhibition balance fits the neurophysiological changes observed during the loss and recovery of consciousness.},
	journal = {Nature Communications},
	author = {Atasoy, Selen and Donnelly, Isaac and Pearson, Joel},
	year = {2016},
	pmid = {26792267},
	pages = {10340},
	file = {Attachment:/Users/tito/Zotero/storage/AAFV4HYN/Atasoy, Donnelly, Pearson - 2016 - Human brain networks function in connectome-specific harmonic waves.pdf:application/pdf},
}

@article{zeighami_network_2015,
	title = {Network structure of brain atrophy in de novo parkinson???s disease},
	volume = {4},
	issn = {2050084X},
	doi = {10.7554/eLife.08440},
	abstract = {We mapped the distribution of atrophy in Parkinson's Disease (PD) using MRI and clinical data from 232 PD patients and 117 controls from the Parkinson's Progression Markers Initiative. Deformation based morphometry and independent component analysis identified PD-specific atrophy in the midbrain, basal ganglia, basal forebrain, medial temporal lobe, and discrete cortical regions. The degree of atrophy reflected clinical measures of disease severity. The spatial pattern of atrophy demonstrated overlap with intrinsic networks present in healthy brain, as derived from functional MRI. Moreover, the degree of atrophy in each brain region reflected its functional and anatomical proximity to a presumed disease epicenter in the substantia nigra, compatible with a trans-neuronal spread of the disease. These results support a network-spread mechanism in PD. Finally, the atrophy pattern in PD was also seen in healthy aging, where it also correlated with the loss of striatal dopaminergic innervation.},
	number = {September 2015},
	journal = {eLife},
	author = {Zeighami, Yashar and Ulla, Miguel and Iturria-Medina, Yasser and Dadar, Mahsa and Zhang, Yu and Larcher, Kevin Michel Herve and Fonov, Vladimir and Evans, Alan C. and Collins, D. Louis and Dagher, Alain},
	year = {2015},
	pmid = {26344547},
	pages = {1--20},
	file = {Attachment:/Users/tito/Zotero/storage/FTBY6X6B/Zeighami et al. - 2015 - Network structure of brain atrophy in de novo parkinsons disease.pdf:application/pdf},
}

@article{cole_variable_2011,
	title = {Variable global dysconnectivity and individual differences in schizophrenia},
	volume = {70},
	issn = {00063223},
	url = {http://dx.doi.org/10.1016/j.biopsych.2011.02.010},
	doi = {10.1016/j.biopsych.2011.02.010},
	abstract = {Background: A fundamental challenge for understanding neuropsychiatric disease is identifying sources of individual differences in psychopathology, especially when there is substantial heterogeneity of symptom expression, such as is found in schizophrenia (SCZ). We hypothesized that such heterogeneity might arise in part from consistently widespread yet variably patterned alterations in the connectivity of focal brain regions. Methods: We used resting state functional connectivity magnetic resonance imaging to identify variable global dysconnectivity in 23 patients with DSM-IV SCZ relative to 22 age-, gender-, and parental socioeconomic status-matched control subjects with a novel global brain connectivity method that is robust to high variability across individuals. We examined cognitive functioning with a modified Sternberg task and subtests from the Wechsler Adult Intelligence ScaleThird Edition. We measured symptom severity with the Scale for Assessment of Positive and Negative Symptoms. Results: We identified a dorsolateral prefrontal cortex (PFC) region with global and highly variable dysconnectivity involving within-PFC underconnectivity and non-PFC overconnectivity in patients. Variability in this "under/over" pattern of dysconnectivity strongly predicted the severity of cognitive deficits (matrix reasoning IQ, verbal IQ, and working memory performance) as well as individual differences in every cardinal symptom domain of SCZ (poverty, reality distortion, and disorganization). Conclusions: These results suggest that global dysconnectivity underlies dorsolateral PFC involvement in the neuropathology of SCZ. Furthermore, these results demonstrate the possibility that specific patterns of dysconnectivity with a given network hub region might explain individual differences in symptom presentation in SCZ. Critically, such findings might extend to other neuropathologies with diverse presentation. ?? 2011 Society of Biological Psychiatry.},
	number = {1},
	journal = {Biological Psychiatry},
	author = {Cole, Michael W. and Anticevic, Alan and Repovs, Grega and Barch, Deanna},
	year = {2011},
	pmid = {21496789},
	keywords = {fMRI, functional connectivity, prefrontal cortex, schizophrenia, global brain connectivity, psychopathology},
	pages = {43--50},
	file = {Attachment:/Users/tito/Zotero/storage/XJVHQIZF/Cole et al. - 2011 - Variable global dysconnectivity and individual differences in schizophrenia.pdf:application/pdf},
}

@article{lafer-sousa_color-biased_2016,
	title = {Color-{Biased} {Regions} of the {Ventral} {Visual} {Pathway} {Lie} between {Face}- and {Place}-{Selective} {Regions} in {Humans}, as in {Macaques}.},
	volume = {36},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/content/36/5/1682.short},
	doi = {10.1523/JNEUROSCI.3164-15.2016},
	abstract = {UNLABELLED: The existence of color-processing regions in the human ventral visual pathway (VVP) has long been known from patient and imaging studies, but their location in the cortex relative to other regions, their selectivity for color compared with other properties (shape and object category), and their relationship to color-processing regions found in nonhuman primates remain unclear. We addressed these questions by scanning 13 subjects with fMRI while they viewed two versions of movie clips (colored, achromatic) of five different object classes (faces, scenes, bodies, objects, scrambled objects). We identified regions in each subject that were selective for color, faces, places, and object shape, and measured responses within these regions to the 10 conditions in independently acquired data. We report two key findings. First, the three previously reported color-biased regions (located within a band running posterior-anterior along the VVP, present in most of our subjects) were sandwiched between face-selective cortex and place-selective cortex, forming parallel bands of face, color, and place selectivity that tracked the fusiform gyrus/collateral sulcus. Second, the posterior color-biased regions showed little or no selectivity for object shape or for particular stimulus categories and showed no interaction of color preference with stimulus category, suggesting that they code color independently of shape or stimulus category; moreover, the shape-biased lateral occipital region showed no significant color bias. These observations mirror results in macaque inferior temporal cortex (Lafer-Sousa and Conway, 2013), and taken together, these results suggest a homology in which the entire tripartite face/color/place system of primates migrated onto the ventral surface in humans over the course of evolution.\${\textbackslash}backslash\$n\${\textbackslash}backslash\$nSIGNIFICANCE STATEMENT: Here we report that color-biased cortex is sandwiched between face-selective and place-selective cortex on the bottom surface of the brain in humans. This face/color/place organization mirrors that seen on the lateral surface of the temporal lobe in macaques, suggesting that the entire tripartite system is homologous between species. This result validates the use of macaques as a model for human vision, making possible more powerful investigations into the connectivity, precise neural codes, and development of this part of the brain. In addition, we find substantial segregation of color from shape selectivity in posterior regions, as observed in macaques, indicating a considerable dissociation of the processing of shape and color in both species.},
	number = {5},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Lafer-Sousa, Rosa and Conway, Bevil R and Kanwisher, Nancy G},
	year = {2016},
	pmid = {26843649},
	keywords = {fmri, significance statement, between face-selective and place-selective, color, color-biased cortex is sandwiched, cortex on the bottom, here we report that, homology, it, lobe in macaques, place organization mirrors that, seen on the lateral, surface of, surface of the temporal, the brain in humans, this face, topography, vvp},
	pages = {1682--97},
	file = {Attachment:/Users/tito/Zotero/storage/5Z68JLZM/Lafer-Sousa, Conway, Kanwisher - 2016 - Color-Biased Regions of the Ventral Visual Pathway Lie between Face- and Place-Selective Regions.pdf:application/pdf},
}

@article{shannon_premotor_2011,
	title = {Premotor functional connectivity predicts impulsivity in juvenile offenders.},
	volume = {108},
	issn = {1091-6490},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3131347&tool=pmcentrez&rendertype=abstract},
	doi = {10.1073/pnas.1108241108},
	abstract = {Teenagers are often impulsive. In some cases this is a phase of normal development; in other cases impulsivity contributes to criminal behavior. Using functional magnetic resonance imaging, we examined resting-state functional connectivity among brain systems and behavioral measures of impulsivity in 107 juveniles incarcerated in a high-security facility. In less-impulsive juveniles and normal controls, motor planning regions were correlated with brain networks associated with spatial attention and executive control. In more-impulsive juveniles, these same regions correlated with the default-mode network, a constellation of brain areas associated with spontaneous, unconstrained, self-referential cognition. The strength of these brain-behavior relationships was sufficient to predict impulsivity scores at the individual level. Our data suggest that increased functional connectivity of motor-planning regions with networks subserving unconstrained, self-referential cognition, rather than those subserving executive control, heightens the predisposition to impulsive behavior in juvenile offenders. To further explore the relationship between impulsivity and neural development, we studied functional connectivity in the same motor-planning regions in 95 typically developing individuals across a wide age span. The change in functional connectivity with age mirrored that of impulsivity: younger subjects tended to exhibit functional connectivity similar to the more-impulsive incarcerated juveniles, whereas older subjects exhibited a less-impulsive pattern. This observation suggests that impulsivity in the offender population is a consequence of a delay in typical development, rather than a distinct abnormality.},
	number = {27},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Shannon, Benjamin J and Raichle, Marcus E and Snyder, Abraham Z and Fair, Damien a and Mills, Kathryn L and Zhang, Dongyang and Bache, Kevin and Calhoun, Vince D and Nigg, Joel T and Nagel, Bonnie J and Stevens, Alexander a and Kiehl, Kent a},
	year = {2011},
	pmid = {21709236},
	keywords = {Attention, Brain, Female, Humans, Magnetic Resonance Imaging, Male, Nerve Net, Adolescent, Adolescent Behavior, Adolescent Behavior: physiology, Adolescent Behavior: psychology, Algorithms, Attention: physiology, Brain: growth \& development, Brain: physiopathology, Criminals, Criminals: psychology, Executive Function, Executive Function: physiology, Impulsive Behavior, Impulsive Behavior: physiopathology, Magnetic Resonance Imaging: methods, Models, Motor Cortex, Motor Cortex: growth \& development, Motor Cortex: physiopathology, Nerve Net: physiopathology, Neurological, Prisoners, Prisoners: psychology, Young Adult},
	pages = {11241--11245},
}

@article{salmela_spatiotemporal_2016,
	title = {Spatiotemporal {Dynamics} of {Attention} {Networks} {Revealed} by {Representational} {Similarity} {Analysis} of {EEG} and {fMRI}},
	issn = {1047-3211},
	url = {http://cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhw389},
	doi = {10.1093/cercor/bhw389},
	number = {Logothetis 2008},
	journal = {Cerebral Cortex},
	author = {Salmela, V. and Salo, E. and Salmi, J. and Alho, K.},
	year = {2016},
	pmid = {27999122},
	keywords = {brain networks, fmri, eeg, attention, representational similarity analysis},
	pages = {1--12},
	file = {Attachment:/Users/tito/Zotero/storage/A3AQK6ZE/Salmela et al. - 2016 - Spatiotemporal Dynamics of Attention Networks Revealed by Representational Similarity Analysis of EEG and fMRI.pdf:application/pdf},
}

@article{mccandliss_visual_2003,
	title = {The visual word form area: {Expertise} for reading in the fusiform gyrus},
	volume = {7},
	issn = {13646613},
	doi = {10.1016/S1364-6613(03)00134-7},
	abstract = {Brain imaging studies reliably localize a region of visual cortex that is especially responsive to visual words. This brain specialization is essential to rapid reading ability because it enhances perception of words by becoming specifically tuned to recurring properties of a writing system. The origin of this specialization poses a challenge for evolutionary accounts involving innate mechanisms for functional brain organization. We propose an alternative account, based on studies of other forms of visual expertise (i.e. bird and car experts) that lead to functional reorganization. We argue that the interplay between the unique demands of word reading and the structural constraints of the visual system lead to the emergence of the Visual Word Form Area.},
	number = {7},
	journal = {Trends in Cognitive Sciences},
	author = {McCandliss, Bruce D. and Cohen, Laurent and Dehaene, Stanislas},
	year = {2003},
	pmid = {12860187},
	pages = {293--299},
	file = {Attachment:/Users/tito/Zotero/storage/79B4WMII/McCandliss, Cohen, Dehaene - 2003 - The visual word form area Expertise for reading in the fusiform gyrus.pdf:application/pdf},
}

@article{dehaene_unique_2011,
	title = {The unique role of the visual word form area in reading},
	volume = {15},
	issn = {13646613},
	url = {http://dx.doi.org/10.1016/j.tics.2011.04.003},
	doi = {10.1016/j.tics.2011.04.003},
	abstract = {Reading systematically activates the left lateral occipitotemporal sulcus, at a site known as the visual word form area (VWFA). This site is reproducible across individuals/scripts, attuned to reading-specific processes, and partially selective for written strings relative to other categories such as line drawings. Lesions affecting the VWFA cause pure alexia, a selective deficit in word recognition. These findings must be reconciled with the fact that human genome evolution cannot have been influenced by such a recent and culturally variable activity as reading. Capitalizing on recent functional magnetic resonance imaging experiments, we provide strong corroborating evidence for the hypothesis that reading acquisition partially recycles a cortical territory evolved for object and face recognition, the prior properties of which influenced the form of writing systems. ?? 2011 Elsevier Ltd.},
	number = {6},
	journal = {Trends in Cognitive Sciences},
	author = {Dehaene, Stanislas and Cohen, Laurent},
	year = {2011},
	pmid = {21592844},
	pages = {254--262},
	file = {Attachment:/Users/tito/Zotero/storage/ADJX4NPN/Dehaene, Cohen - 2011 - The unique role of the visual word form area in reading.pdf:application/pdf},
}

@article{smith_positive-negative_2015,
	title = {A positive-negative mode of population covariation links brain connectivity, demographics and behavior},
	volume = {18},
	issn = {1097-6256},
	url = {http://dx.doi.org/10.1038/nn.4125},
	doi = {10.1038/nn.4125},
	abstract = {The Human Connectome Project (HCP) 1 is acquiring high-quality in vivo macroscopic-level connectome imaging data from over a thousand healthy adult subjects in an effort to elucidate the neural pathways and networks that underlie brain function and behavior. An overarching aim is to reveal much about what makes us uniquely human and what makes individuals different from each other by understanding how brain networks integrate information through the complex pattern of neural connections. To date, data sets from 500 subjects have been publicly released, including imaging data measuring functional and structural brain connectivity, as well as 280 non-imaging subject measures (SMs), including demographics (age, sex, income, education level, drug use, etc.), psychometrics (IQ, language performance, etc.) and other behavioral measures such as 'rule-breaking behavior' . We sought to relate functional connectomes to behavior in a single integrated analysis. This goes further than simply investigating which SMs correlate with other SMs; we wanted to discover whether any specific patterns of brain connectivity are associated with specific sets of correlated demographics and behavior, as brain-behavior modes of population co-variation. We used resting-state functional magnetic resonance imaging (fMRI) data from 461 HCP subjects, and network modeling tools from FSL (FMRIB Software Library). A population-average brain parcellation was estimated using independent component analysis 2 , yielding 200 distinct brain regions; these constitute the nodes in our network modeling. The functional connections (edges) between these nodes were estimated using Tikhonov-regularized partial correlation, resulting in a 200 × 200 connectome for each subject. These connec-tomes were combined into a single large connectome matrix (con-taining all connectomes from all subjects; Supplementary Fig. 1). Separately, 158 behavioral and demographic non-imaging SMs from the same set of subjects were formed into a subject measure matrix. We regressed potential confounds (including brain size and head motion) out of both matrices. Redundancies among connectomes and SMs were reduced by (separately) keeping just the first 100 principal components of each matrix. A natural choice of method for investigating underlying relation-ships between two sets of variables is canonical correlation analysis (CCA) 3 , a procedure that seeks maximal correlations between com-binations of variables in both sets. Using CCA, we estimated pairs of canonical variates along which sets of SMs and patterns of brain con-nectivity co-vary in a similar way across subjects. We refer to each such pair of variates as a mode of co-variation. Strict tests were applied to avoid over-fitting and false-positive inflation. Statistical significance was determined with a permutation test that accounted for the fam-ily structure of the HCP data 4 . This analysis revealed a single highly significant CCA mode that relates functional connectomes to subject measures (r = 0.87, P {\textbackslash}textless 10 −5 corrected for multiple comparisons across all modes estimated). These analyses were driven by and report only correlations; inferring and interpreting the (presumably complex and diverse) causalities remains a challenging issue for the future.},
	number = {September},
	journal = {Nature Neuroscience},
	author = {Smith, Stephen M and Nichols, Thomas E and Vidaurre, Diego and Winkler, Anderson M and J Behrens, Timothy E and Glasser, Matthew F and Ugurbil, Kamil and Barch, Deanna M and Van Essen, David C and Miller, Karla L},
	year = {2015},
	pmid = {26414616},
	pages = {1--7},
	file = {Attachment:/Users/tito/Zotero/storage/XW6PKU7K/Smith et al. - 2015 - A positive-negative mode of population covariation links brain connectivity, demographics and behavior.pdf:application/pdf},
}

@article{chen_shared_2016,
	title = {Shared memories reveal shared structure in neural activity across individuals},
	volume = {advance on},
	issn = {1546-1726},
	url = {http://dx.doi.org/10.1038/nn.4450%5Cnhttp://10.1038/nn.4450%5Cnhttp://www.nature.com/neuro/journal/vaop/ncurrent/abs/nn.4450.html#supplementary-information},
	doi = {10.1038/nn.4450},
	abstract = {Our lives revolve around sharing experiences and memories with others. When different people recount the same events, how similar are their underlying neural representations? Participants viewed a 50-min movie, then verbally described the events during functional MRI, producing unguided detailed descriptions lasting up to 40 min. As each person spoke, event-specific spatial patterns were reinstated in default-network, medial-temporal, and high-level visual areas. Individual event patterns were both highly discriminable from one another and similar among people, suggesting consistent spatial organization. In many high-order areas, patterns were more similar between people recalling the same event than between recall and perception, indicating systematic reshaping of percept into memory. These results reveal the existence of a common spatial organization for memories in high-level cortical areas, where encoded information is largely abstracted beyond sensory constraints, and that neural patterns during perception are altered systematically across people into shared memory representations for real-life events.},
	number = {1},
	journal = {Nat Neurosci},
	author = {Chen, Janice and Leong, Yuan Chang and Honey, Christopher J and Yong, Chung H and Norman, Kenneth A and Hasson, Uri},
	year = {2016},
	pmid = {27918531},
	file = {Attachment:/Users/tito/Zotero/storage/7HA689A9/Chen et al. - 2016 - Shared memories reveal shared structure in neural activity across individuals.pdf:application/pdf},
}

@article{baldassano_discovering_2016,
	title = {Discovering event structure in continuous narrative perception and memory},
	doi = {10.1101/081018},
	journal = {bioRxiv},
	author = {Baldassano, Christopher and Chen, Janice and Zadbood, Asieh and Pillow, Jonathan W and Hasson, Uri and Norman, Kenneth A},
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/SZ2YG9FU/Baldassano et al. - 2016 - Discovering event structure in continuous narrative perception and memory.pdf:application/pdf},
}

@article{toyoizumi_theory_2013,
	title = {A {Theory} of the {Transition} to {Critical} {Period} {Plasticity}: {Inhibition} {Selectively} {Suppresses} {Spontaneous} {Activity}},
	volume = {80},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2013.07.022},
	doi = {10.1016/j.neuron.2013.07.022},
	abstract = {What causes critical periods (CPs) to open?? For the best-studied case, ocular dominance plasticity in primary visual cortex in response to monocular deprivation (MD), the maturation of inhibition is necessary and sufficient. How does inhibition open the CP?? We present a theory: the transition from pre-CP to CP plasticity arises because inhibition preferentially suppresses responses to spontaneous relative to visually driven input activity, switching learning cues from internal to external sources. This differs from previous proposals in (1) arguing that the CP can open without changes in plasticity mechanisms when activity patterns become more sensitive to sensory experience through circuit development, and (2) explaining not simply a transition from no plasticity to plasticity, but a change in outcome of MD-induced plasticity from pre-CP to CP. More broadly, hierarchical organization of sensory-motor pathways may develop through a cascade of CPs induced as circuit maturation progresses from "lower" to "higher" cortical areas},
	number = {1},
	journal = {Neuron},
	author = {Toyoizumi, Taro and Miyamoto, Hiroyuki and Yazaki-Sugiyama, Yoko and Atapour, Nafiseh and Hensch, Takao K. and Miller, Kenneth D.},
	year = {2013},
	pmid = {24094102},
	pages = {51--63},
	file = {Attachment:/Users/tito/Zotero/storage/J4GBQGER/Toyoizumi et al. - 2013 - A Theory of the Transition to Critical Period Plasticity Inhibition Selectively Suppresses Spontaneous Activit.pdf:application/pdf},
}

@article{alkemade_towards_nodate,
	title = {Towards a mechanistic understanding of the human subcortex},
	author = {Alkemade, Anneke and Keuken, Max C},
}

@article{van_den_heuvel_functionally_2009,
	title = {Functionally linked resting-state networks reflect the underlying structural connectivity architecture of the human brain},
	volume = {30},
	issn = {10659471},
	doi = {10.1002/hbm.20737},
	abstract = {During rest, multiple cortical brain regions are functionally linked forming resting-state networks. This high level of functional connectivity within resting-state networks suggests the existence of direct neuroanatomical connections between these functionally linked brain regions to facilitate the ongoing interregional neuronal communication. White matter tracts are the structural highways of our brain, enabling information to travel quickly from one brain region to another region. In this study, we examined both the functional and structural connections of the human brain in a group of 26 healthy subjects, combining 3 Tesla resting-state functional magnetic resonance imaging time-series with diffusion tensor imaging scans. Nine consistently found functionally linked resting-state networks were retrieved from the resting-state data. The diffusion tensor imaging scans were used to reconstruct the white matter pathways between the functionally linked brain areas of these resting-state networks. Our results show that well-known anatomical white matter tracts interconnect at least eight of the nine commonly found resting-state networks, including the default mode network, the core network, primary motor and visual network, and two lateralized parietal-frontal networks. Our results suggest that the functionally linked resting-state networks reflect the underlying structural connectivity architecture of the human brain. Hum Brain Mapp 2009. © 2009 Wiley-Liss, Inc.},
	number = {10},
	journal = {Human Brain Mapping},
	author = {van den Heuvel, Martijn P. and Mandl, René C W and Kahn, René S. and Hulshoff Pol, Hilleke E.},
	year = {2009},
	pmid = {19235882},
	keywords = {fMRI, Functional connectivity, Connectivity, Anatomical connectivity, Diffusion tensor imaging, DTI, Resting-state connectivity, Resting-state fMRI, White matter},
	pages = {3127--3141},
	file = {Attachment:/Users/tito/Zotero/storage/54KLW6G7/van den Heuvel et al. - 2009 - Functionally linked resting-state networks reflect the underlying structural connectivity architecture of.pdf:application/pdf},
}

@article{marrelec_functional_2016,
	title = {Functional {Connectivity}'s {Degenerate} {View} of {Brain} {Computation}},
	volume = {12},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1005031},
	doi = {10.1371/journal.pcbi.1005031},
	number = {10},
	journal = {PLOS Computational Biology},
	author = {Marrelec, Guillaume and Messé, Arnaud and Giron, Alain and Rudrauf, David},
	year = {2016},
	pages = {e1005031},
}

@article{callaway_monosynaptic_2015,
	title = {Monosynaptic {Circuit} {Tracing} with {Glycoprotein}-{Deleted} {Rabies} {Viruses}},
	volume = {35},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0409-15.2015},
	doi = {10.1523/JNEUROSCI.0409-15.2015},
	abstract = {Editor's Note: Toolboxes are intended to describe and evaluate methods that are becoming widely relevant to the neuroscience community or to provide a critical analysis of established techniques. For more information, see http://www.jneurosci.org/misc/ ifa\_minireviews.dtl.},
	number = {24},
	journal = {Journal of Neuroscience},
	author = {Callaway, E. M. and Luo, L.},
	year = {2015},
	pmid = {26085623},
	pages = {8979--8985},
	file = {Attachment:/Users/tito/Zotero/storage/HSNB33DU/Callaway, Luo - 2015 - Monosynaptic Circuit Tracing with Glycoprotein-Deleted Rabies Viruses.pdf:application/pdf},
}

@article{levanon_references_2005,
	title = {References and {Notes} 1.},
	volume = {341},
	issn = {1095-9203},
	doi = {10.1126/science.1225053},
	number = {March},
	author = {Levanon, M and Leiserowitz, L and Lahav, M and Ozin, G A and Penner, R M and Bawendi, M G and Ward, M D and Yip, C M and Ward, M D and Malkin, A J and Kuznetsov, Y G and Mcpherson, A and Yoreo, J J De and Dove, P M and Orme, C A and Yoreo, J J De and Miles, M J and Hobbs, J K and Miles, M J and Miles, M J and Zhu, J and Xu, F and Hong, S and Mirkin, C A and Zhang, H and Mirkin, C A and Li, J and Lu, C and Liu, J and Stellacci, F and Sowards, L A and Naik, R R and Stone, M O and Branton, D and Ravindra, R and Nicolini, C and Jansen, R and Tsukruk, V V and Microscopy, Scanning Probe and Society, Chemical and Arend, H and Hulliger, J and State, Solid and Fox, D and Labes, M M and Weissberger, A and Mirkin, C A and Chung, S W and Wang, X and Zou, J and Mirkin, C A},
	year = {2005},
	pmid = {23118188},
	pages = {1766--1769},
	file = {Attachment:/Users/tito/Zotero/storage/9BXVFSTE/Levanon et al. - 2005 - References and Notes 1.pdf:application/pdf},
}

@article{kanwisher_fusiform_1997,
	title = {The {Fusiform} {Face} {Area}: {A} {Module} in {Human} {Extrastriate} {Cortex} {Specialized} for {Face} {Perception}},
	volume = {17},
	url = {http://www.jneurosci.org/content/17/11/4302.abstract},
	abstract = {Using functional magnetic resonance imaging (fMRI), we found an area in the fusiform gyrus in 12 of the 15 subjects tested that was significantly more active when the subjects viewed faces than when they viewed assorted common objects. This face activation was used to define a specific region of interest individually for each subject, within which several new tests of face specificity were run. In each of five subjects tested, the predefined candidate “face area” also responded significantly more strongly to passive viewing of (1) intact than scrambled two-tone faces, (2) full front-view face photos than front-view photos of houses, and (in a different set of five subjects) (3) three-quarter-view face photos (with hair concealed) than photos of human hands; it also responded more strongly during (4) a consecutive matching task performed on three-quarter-view faces versus hands. Our technique of running multiple tests applied to the same region defined functionally within individual subjects provides a solution to two common problems in functional imaging: (1) the requirement to correct for multiple statistical comparisons and (2) the inevitable ambiguity in the interpretation of any study in which only two or three conditions are compared. Our data allow us to reject alternative accounts of the function of the fusiform face area (area “FF”) that appeal to visual attention, subordinate-level classification, or general processing of any animate or human forms, demonstrating that this region is selectively involved in the perception of faces.},
	number = {11},
	journal = {The Journal of Neuroscience},
	author = {Kanwisher, Nancy and McDermott, Josh and Chun, Marvin M},
	month = jun,
	year = {1997},
	pages = {4302 LP -- 4311},
}

@article{tsao_cortical_2006,
	title = {A {Cortical} {Region} {Consisting} {Entirely} of {Face}-{Selective} {Cells}},
	volume = {311},
	url = {http://science.sciencemag.org/content/311/5761/670.abstract},
	abstract = {Face perception is a skill crucial to primates. In both humans and macaque monkeys, functional magnetic resonance imaging (fMRI) reveals a system of cortical regions that show increased blood flow when the subject views images of faces, compared with images of objects. However, the stimulus selectivity of single neurons within these fMRI-identified regions has not been studied. We used fMRI to identify and target the largest face-selective region in two macaques for single-unit recording. Almost all (97\%) of the visually responsive neurons in this region were strongly face selective, indicating that a dedicated cortical area exists to support face processing in the macaque.},
	number = {5761},
	journal = {Science},
	author = {Tsao, Doris Y and Freiwald, Winrich A and Tootell, Roger B H and Livingstone, Margaret S},
	month = feb,
	year = {2006},
	pages = {670 LP -- 674},
}

@article{mark_metabolic_2015,
	title = {Metabolic and vascular origins of the {BOLD} effect: {Implications} for imaging pathology and resting-state brain function},
	volume = {42},
	issn = {15222586},
	doi = {10.1002/jmri.24786},
	abstract = {The blood oxygenation level-dependent (BOLD) phenomenon has profoundly revolutionized neuroscience, with applications ranging from normal brain development and aging, to brain disorders and diseases. While the BOLD effect represents an invaluable tool to map brain function, it does not measure neural activity directly; rather, it reflects changes in blood oxygenation resulting from the relative balance between cerebral oxygen metabolism (through neural activity) and oxygen supply (through cerebral blood flow and volume). As such, there are cases in which BOLD signals might be dissociated from neural activity, leading to misleading results. The emphasis of this review is to develop a critical perspective for interpreting BOLD results, through a comprehensive consideration of BOLD's metabolic and vascular underpinnings. We demonstrate that such an understanding is especially important under disease or resting conditions. We also describe state-of-the-art acquisition and analytical techniques to reveal physiological information on the mechanisms underlying measured BOLD signals. With these goals in mind, this review is structured to provide a fundamental understanding of: 1) the physiological and physical sources of the BOLD contrast; 2) the extraction of information regarding oxidative metabolism and cerebrovascular reactivity from the BOLD signal, critical to investigating neuropathology; and 3) the fundamental importance of metabolic and vascular mechanisms for interpreting resting-state BOLD measurements.},
	number = {2},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Mark, Clarisse I. and Mazerolle, Erin L. and Chen, J. Jean},
	year = {2015},
	pmid = {25727523},
	keywords = {calibrated BOLD, cerebral metabolic rate of oxygen consumption, cerebrovascular reactivity, neuropathology, neurovascular uncoupling, resting-state functional connectivity},
	pages = {231--246},
	file = {Attachment:/Users/tito/Zotero/storage/TRUDEQHT/Mark, Mazerolle, Chen - 2015 - Metabolic and vascular origins of the BOLD effect Implications for imaging pathology and resting-state br.pdf:application/pdf},
}

@article{genovese_operating_2002,
	title = {Operating characteristics and extensions of the false discovery rate procedure},
	volume = {64},
	issn = {1467-9868},
	number = {3},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Genovese, Christopher and Wasserman, Larry},
	year = {2002},
	pages = {499--517},
}

@article{szucs_empirical_2016,
	title = {Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature},
	url = {http://biorxiv.org/content/early/2016/08/25/071530.abstract},
	abstract = {We have empirically assessed the distribution of published effect sizes and estimated power by extracting more than 100,000 statistical records from about 10,000 cognitive neuroscience and psychology papers published during the past 5 years. The reported median effect size was d=0.93 (inter-quartile range: 0.64-1.46) for nominally statistically significant results and d=0.24 (0.11-0.42) for non-significant results. Median power to detect small, medium and large effects was 0.12, 0.44 and 0.73, reflecting no improvement through the past half-century. Power was lowest for cognitive neuroscience journals. 14\% of papers reported some statistically significant results, although the respective F statistic and degrees of freedom proved that these were non-significant; p value errors positively correlated with journal impact factors. False report probability is likely to exceed 50\% for the whole literature. In light of our findings the recently reported low replication success in psychology is realistic and worse performance may be expected for cognitive neuroscience.},
	journal = {bioRxiv},
	author = {Szucs, Denes and Ioannidis, John P A},
	month = aug,
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/F8Z4VDNZ/Szucs, Ioannidis - 2016 - Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology l.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Y6V9699A/Szucs, Ioannidis - 2016 - Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology l.pdf:application/pdf},
}

@book{schneider_e-prime:_2002,
	title = {E-{Prime}: {User}'s guide},
	publisher = {Psychology Software Incorporated},
	author = {Schneider, Walter and Eschman, Amy and Zuccolotto, Anthony},
	year = {2002},
}

@article{jutla_generalized_2011,
	title = {A generalized {Louvain} method for community detection implemented in {MATLAB}},
	journal = {URL http://netwiki. amath. unc. edu/GenLouvain},
	author = {Jutla, Inderjit S and Jeub, Lucas G S and Mucha, Peter J},
	year = {2011},
}

@article{schonemann_generalized_1966,
	title = {A generalized solution of the orthogonal procrustes problem},
	volume = {31},
	issn = {1860-0980},
	url = {http://dx.doi.org/10.1007/BF02289451},
	doi = {10.1007/BF02289451},
	abstract = {A solutionT of the least-squares problemAT=B +E, givenA andB so that trace (E′E)= minimum andT′T=I is presented. It is compared with a less general solution of the same problem which was given by Green [5]. The present solution, in contrast to Green's, is applicable to matricesA andB which are of less than full column rank. Some technical suggestions for the numerical computation ofT and an illustrative example are given.},
	number = {1},
	journal = {Psychometrika},
	author = {Schönemann, Peter H},
	year = {1966},
	pages = {1--10},
}

@article{chehelcheraghi_neural_2016,
	title = {A neural mass model of phase???amplitude coupling},
	volume = {110},
	issn = {14320770},
	doi = {10.1007/s00422-016-0687-5},
	number = {2-3},
	journal = {Biological Cybernetics},
	author = {Chehelcheraghi, Mojtaba and Nakatani, Chie and Steur, Erik and van Leeuwen, Cees},
	year = {2016},
	keywords = {Alpha???gamma coupling, Cross-frequency coupling, Fast inhibitory interneurons, Frequency-dependent synaptic depression, Self-inhibitory feedback},
	pages = {171--192},
	file = {Attachment:/Users/tito/Zotero/storage/LPKPKW67/Chehelcheraghi et al. - 2016 - A neural mass model of phaseamplitude coupling.pdf:application/pdf},
}

@article{miller_working_2015,
	title = {Working {Memory} {Capacity}: {Limits} on the {Bandwidth} of {Cognition}},
	volume = {144},
	issn = {0011-5266},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/DAED_a_00320},
	doi = {10.1162/DAED_a_00320},
	abstract = {Why can your brain store a lifetime of experiences but process only a few thoughts at once? In this article we discuss “cognitive capacity” (the number of items that can be held “in mind” simul taneously) and suggest that the limit is inherent to processing based on oscillatory brain rhythms, or “brain waves,” which may regulate neural communication. Neurons that “hum” together temporarily “wire” to gether, allowing the brain to form and re-form networks on the fly, which may explain a hallmark of intel ligence and cognition: mental flexibility. But this comes at a cost; only a small number of thoughts can ½t into each wave. This explains why you should never talk on a mobile phone when driving},
	number = {1},
	journal = {Daedalus},
	author = {Miller, Earl K and Buschman, Timothy J},
	year = {2015},
	pages = {112--122},
	file = {Attachment:/Users/tito/Zotero/storage/I63AK55I/Miller, Buschman - 2015 - Working Memory Capacity Limits on the Bandwidth of Cognition.pdf:application/pdf},
}

@book{rabbitt_methodology_1997,
	address = {Hove, East Sussex, U.K.},
	title = {Methodology of frontal and executive function},
	isbn = {0-585-10249-X 978-0-585-10249-8 0-203-34418-9 978-0-203-34418-7 978-1-135-47203-0 1-135-47203-3},
	url = {http://public.eblib.com/choice/publicfullrecord.aspx?p=201286},
	abstract = {This volume is a collection of essays by active researchers who discuss their own work on the definition of "executive" or "controlled" behaviours, and on the relation of these behaviours to specific areas of the frontal cortex.},
	language = {English},
	publisher = {Psychology Press},
	author = {Rabbitt, Patrick.},
	year = {1997},
}

@article{cohen_segregation_2016,
	title = {The {Segregation} and {Integration} of {Distinct} {Brain} {Networks} and {Their} {Relationship} to {Cognition}},
	volume = {36},
	issn = {0270-6474},
	doi = {10.1523/JNEUROSCI.2965-15.2016},
	number = {48},
	journal = {Journal of Neuroscience},
	author = {Cohen, Jessica R. and D'Esposito, Mark},
	year = {2016},
	keywords = {functional connectivity, individual differences, resting state, significance statement, working memory, are capable, cognition of which humans, collected fmri data from, graph theory, healthy young adults and, measured large-scale functional connectivity, motor execution, patterns between regions dis-, range of behaviors and, rise to the wide, the dynamic nature of, the human brain gives, we},
	pages = {12083--12094},
	file = {Attachment:/Users/tito/Zotero/storage/69QKB9K8/Cohen, D'Esposito - 2016 - The Segregation and Integration of Distinct Brain Networks and Their Relationship to Cognition.pdf:application/pdf},
}

@article{tadic_algebraic_2016,
	title = {Algebraic {Topology} of {Multi}-{Brain} {Connectivity} {Networks} {Reveals} {Dissimilarity} in {Functional} {Patterns} during {Spoken} {Communications}},
	volume = {11},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0166787},
	doi = {10.1371/journal.pone.0166787},
	number = {11},
	journal = {Plos One},
	author = {Tadić, Bosiljka and Andjelković, Miroslav and Boshkoska, Biljana Mileva and Levnajić, Zoran and Babiloni, F and Cincotti, F and Babiloni, C and Carducci, F and Mattia, D and Astolfi, L and McNab, JA and Edlow, BL and Witzel, T and Huang, SY and Bhat, H and Heberlein, Kea and Bullmore, E and Sporns, O and Rubinov, M and Sporns, O and Shen, X and Papademetris, X and Constable, RT and Zalesky, A and Fornito, A and Harding, IH and Cocchi, L and Yocel, M and Pantelis, C and van den Heuvel, J Martijn P and Sporns, O and Hassan, M and Dufor, O and Merlet, I and Berrou, C and Wendling, F and Bassett, DS and Porter, MA and Wymbs, NF and Grafton, ST and Carlson, JM and Mucha, PJ and Garcia-Martinez, B and Martinez-Rodrigo, A and Cantabrana, R Zangrniz and Garcia, JM Pastor and Alcaraz, R and Gaier, C and Lhnertz, K and Bialonski, S and Sockeel, S and Schwartz, D and Pelegrini-Issac, M and Benali, H and Sammler, D and Grigutsch, M and Fritz, T and Koelsch, S and Padovani, EC and Parker, CS and Deligianni, F and Cardoso, MJ and Daga, P and Modat, M and Dayan, M and Deco, G and Tononi, G and Boly, M and Kringelbach, ML and Mišić, B and Sporns, O and McIntosh, AR and Mišić, B and Goñi, J and Betzel, RF and Sporns, O and McIntosh, AR and Womelsdorf, T and Everling, S and Shi, G and Pasqualetti, F and Cieslak, M and Telesford, QK and Yu, AB and Kahn, AE and Krauzlis, RJ and Bollimunta, A and Arcizet, F and Wang, L and Bisley, JW and Goldberg, ME and Bassett, DS and Wymbs, NF and Porter, MA and Mucha, PJ and Carlson, JM and Grafton, ST and Riemer, M and Diersch, N and Bublatzky, F and Wolbers, T and Kim, SY and Qi, T and Feng, X and Ding, G and Liu, L and Cao, F and Zeng, LL and Shen, H and Liu, L and Wang, L and Li, B and Fang, P and Adolphs, R and Amodio, DM and Frith, CD and Uddin, LQ and Iacoboni, M and Lange, C and Keenan, JP and Konvalinka, I and Roepstorff, A and Yun, K and Watanabe, K and Shimojo, S and Dumas, G and Nadel, J and Soussignan, R and Martinerie, J and Garnero, L and Krueger, F and McCabe, K and Moll, J and Kriegerskorte, N and Zahn, R and Fallani, F De Vico and Nicosia, V and Sinatra, R and Astolfi, L and Cincotti, F and Jiang, J and Dai, B and Peng, D and Zhu, C and Liu, L and Jiang, J and Cheng, C and Dai, B and Shi, G and Ding, G and Liu, L and Liu, N and Mok, C and Witt, EE and Pradhan, AH and Chen, JE and Reiss, AL and Müller, V and Sänger, J and Lindenberger, U and Duan, L and Liu, WJ and Dai, RN and Li, R and Lu, CM and Huang, YX and Zhu, CZ and Dai, RN and Xiao, X and Sun, PP and Li, Z and Zhu, CZ and Kuhlen, AK and Allefeld, C and Haynes, JD and Fallani, FDV and Richardi, J and Chavez, M and Achard, S and Chavez, M and Valencia, M and Navarro, V and Latora, V and Martinerie, J and Mantegna, RN and Stanley, EH and Živković, J and Mitrović, M and Tadić, B and Madi, A and Friedman, Y and Roth, D and Regev, T and Bransburg-Zabary, S and Jacob, EB and Tadić, B and Mitrović, M and Baruchi, I and Ben-Jacob, E and Bollobas, B and Dorogovtsev, S and Meunier, D and Lambiotte, R and Bullmore, ET and Gronchi, G and Guazzini, A and Massaro, E and Bagnoli, F and Menche, J and Sharma, A and Kitsak, M and Ghiassian, SD and Vidal, M and Loscalzo, J and Li, J and Luo, P and Wu, C and Phillips, HN and Blenkmann, A and Hughes, L and Bekinschtein, TA and Rowe, JJ and Arenas, A and Díaz-Guilera, A and Pérez-Vicente, CJ and Mitrović, M and Tadić, B and Fortunato, S and Lancichinetti, A and Kivela, M and Saramaki, J and Fortunato, S and Hatcher, A and Jonsson, J and Kozlov, D and Bandelt, HJ and Chepoi, V and Goodman, JE and Pach, J and Pollack, R. and Bron, C and Kerbosch, J and Freeman, LC and Gould, P and Atkin, RH and Andjelković, M and Tadić, B and Maletić, S and Rajković, M and Andjelković, M and Gupte, N and Tadić, B and Gao, X and Xiao, B and Tao, D},
	year = {2016},
	pages = {e0166787},
}

@article{hartman_layered_1990,
	title = {Layered {Neural} {Networks} with {Gaussian} {Hidden} {Units} as {Universal} {Approximations}},
	volume = {2},
	issn = {0899-7667},
	doi = {10.1162/neco.1990.2.2.210},
	abstract = {A neural network with a single layer of hidden units of gaussian type is proved to be a universal approximator for real-valued maps defined on convex, compact sets of R " . 1 Introduction Neural networks functioning as approximators of general maps are cur-rently under intense investigation, with concentration on network ap-proximation capabilities and performance for different architectures and different types of hidden units. A very important class of applications is nonlinear signal processing, particularly the prediction problem for a chaotic, deterministic time series. In this case a network learns input se-quences and produces a global approximation to an unknown, in general, map of the Takens type (see, e.g., Eckmann and Ruelle 1985) for a de-terministic system on its attractor. Such systems may tell the difference between purely random and deterministic processes, and in the latter case allow longer time predictions. The overall performance of various proposed neural net schemes is good for quite different types of hidden units. Lapedes and Farber (1987) used an architecture with two layers of standard " sigmoid " hidden units. They tested the network prediction capability for two model systems: the logistic map and the Mackey-Glass delay equation with its " tunable " at-tractor characteristics. Nonstandard hidden units with localized receptive fields have been considered in a series of papers by Moody and Darken (1989a,b), Moody (19891, Lee and Kil (1988), and Niranjan and Fallside (1988). The success of approximation schemes with standard (sigmoidal) pro-cessing units opened the question of how " good these devices are as approximators in a given functional space. The network universality Neural Computation 2,210-215 (1990) @ 1990 Massachusetts Institute of Technology Neural Networks with Gaussian Units 211 property was rigorously proved by Hornik et al. (1989) and Stinchcombe and White (1989) for a broad class of single or multilayer networks where the hidden units are described by any continuous, nonconstant function G : R " + R. These units are assumed to be " semiaffine, " that is, they process their inputs via composition G . A, where A : R " 4 R is an affine map: A(x) = (w,x) + b, where x is an input vector, w is a vector},
	number = {2},
	journal = {Neural Computation},
	author = {Hartman, Eric J. and Keeler, James D. and Kowalski, Jacek M.},
	year = {1990},
	pages = {210--215},
	file = {Attachment:/Users/tito/Zotero/storage/QD6V7WZC/Hartman, Keeler, Kowalski - 1990 - Layered Neural Networks with Gaussian Hidden Units as Universal Approximations.pdf:application/pdf},
}

@article{poldrack_decoding_2009,
	title = {Decoding the large-scale structure of brain function by classifying mental states across individuals},
	volume = {20},
	issn = {09567976},
	doi = {10.1111/j.1467-9280.2009.02460.x},
	abstract = {Brain-imaging research has largely focused on localizing patterns of activity related to specific mental processes, but recent work has shown that mental states can be identified from neuroimaging data using statistical classifiers. We investigated whether this approach could be extended to predict the mental state of an individual using a statistical classifier trained on other individuals, and whether the information gained in doing so could provide new insights into how mental processes are organized in the brain. Using a variety of classifier techniques, we achieved cross-validated classification accuracy of 80\% across individuals (chance = 13\%). Using a neural network classifier, we recovered a low-dimensional representation common to all the cognitive-perceptual tasks in our data set, and we used an ontology of cognitive processes to determine the cognitive concepts most related to each dimension. These results revealed a small organized set of large-scale networks that map cognitive processes across a highly diverse set of mental tasks, suggesting a novel way to characterize the neural basis of cognition.},
	number = {11},
	journal = {Psychological Science},
	author = {Poldrack, Russell A. and Halchenko, Yaroslav O. and Hanson, Stephen José},
	year = {2009},
	pmid = {19883493},
	pages = {1364--1372},
	file = {Attachment:/Users/tito/Zotero/storage/TP84GX9X/Poldrack, Halchenko, Hanson - 2009 - Decoding the large-scale structure of brain function by classifying mental states across individual.pdf:application/pdf},
}

@article{smith_computational_2006,
	title = {Computational inference of neural information flow networks},
	volume = {2},
	issn = {1553734X},
	doi = {10.1371/journal.pcbi.0020161},
	abstract = {Determining how information flows along anatomical brain pathways is a fundamental requirement for understanding how animals perceive their environments, learn, and behave. Attempts to reveal such neural information flow have been made using linear computational methods, but neural interactions are known to be nonlinear. Here, we demonstrate that a dynamic Bayesian network (DBN) inference algorithm we originally developed to infer nonlinear transcriptional regulatory networks from gene expression data collected with microarrays is also successful at inferring nonlinear neural information flow networks from electrophysiology data collected with microelectrode arrays. The inferred networks we recover from the songbird auditory pathway are correctly restricted to a subset of known anatomical paths, are consistent with timing of the system, and reveal both the importance of reciprocal feedback in auditory processing and greater information flow to higher-order auditory areas when birds hear natural as opposed to synthetic sounds. A linear method applied to the same data incorrectly produces networks with information flow to non-neural tissue and over paths known not to exist. To our knowledge, this study represents the first biologically validated demonstration of an algorithm to successfully infer neural information flow networks.},
	number = {11},
	journal = {PLoS Computational Biology},
	author = {Smith, V. Anne and Yu, Jing and Smulders, Tom V. and Hartemink, Alexander J. and Jarvis, Erich D.},
	year = {2006},
	pmid = {17121460},
	pages = {1436--1449},
	file = {Attachment:/Users/tito/Zotero/storage/28SFJH9F/Smith et al. - 2006 - Computational inference of neural information flow networks.pdf:application/pdf},
}

@article{hoel_quantifying_2013,
	title = {Quantifying causal emergence shows that macro can beat micro.},
	volume = {110},
	issn = {1091-6490},
	url = {http://www.pnas.org/cgi/content/long/110/49/19790},
	doi = {10.1073/pnas.1314922110},
	abstract = {Causal interactions within complex systems can be analyzed at multiple spatial and temporal scales. For example, the brain can be analyzed at the level of neurons, neuronal groups, and areas, over tens, hundreds, or thousands of milliseconds. It is widely assumed that, once a micro level is fixed, macro levels are fixed too, a relation called supervenience. It is also assumed that, although macro descriptions may be convenient, only the micro level is causally complete, because it includes every detail, thus leaving no room for causation at the macro level. However, this assumption can only be evaluated under a proper measure of causation. Here, we use a measure [effective information (EI)] that depends on both the effectiveness of a system's mechanisms and the size of its state space: EI is higher the more the mechanisms constrain the system's possible past and future states. By measuring EI at micro and macro levels in simple systems whose micro mechanisms are fixed, we show that for certain causal architectures EI can peak at a macro level in space and/or time. This happens when coarse-grained macro mechanisms are more effective (more deterministic and/or less degenerate) than the underlying micro mechanisms, to an extent that overcomes the smaller state space. Thus, although the macro level supervenes upon the micro, it can supersede it causally, leading to genuine causal emergence–the gain in EI when moving from a micro to a macro level of analysis.},
	number = {49},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Hoel, Erik P and Albantakis, Larissa and Tononi, Giulio},
	year = {2013},
	pmid = {24248356},
	keywords = {Models, Computer Simulation, Information Theory, Systems Biology, Systems Biology: methods, Theoretical},
	pages = {19790--5},
	file = {Attachment:/Users/tito/Zotero/storage/IDTJK5EF/Hoel, Albantakis, Tononi - 2013 - Quantifying causal emergence shows that macro can beat micro.pdf:application/pdf},
}

@article{sporns_integration_2016,
	title = {Integration and segregation of large-scale brain networks during short-term task automatization},
	issn = {2041-1723},
	doi = {10.1038/ncomms13217},
	journal = {Nature communications},
	author = {Sporns, Olaf and Richiardi, Jonas and Mohr, Holger and Wolfensteller, Uta and Betzel, Richard F and Mis, Bratislav},
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/JY2P92CZ/Sporns et al. - 2016 - Integration and segregation of large-scale brain networks during short-term task automatization.pdf:application/pdf},
}

@article{glasser_human_2016,
	title = {The {Human} {Connectome} {Project}'s neuroimaging approach.},
	volume = {19},
	issn = {1546-1726},
	url = {http://www.nature.com/neuro/journal/v19/n9/pdf/nn.4361.pdf%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/27571196},
	doi = {10.1038/nn.4361},
	abstract = {Noninvasive human neuroimaging has yielded many discoveries about the brain. Numerous methodological advances have also occurred, though inertia has slowed their adoption. This paper presents an integrated approach to data acquisition, analysis and sharing that builds upon recent advances, particularly from the Human Connectome Project (HCP). The 'HCP-style' paradigm has seven core tenets: (i) collect multimodal imaging data from many subjects; (ii) acquire data at high spatial and temporal resolution; (iii) preprocess data to minimize distortions, blurring and temporal artifacts; (iv) represent data using the natural geometry of cortical and subcortical structures; (v) accurately align corresponding brain areas across subjects and studies; (vi) analyze data using neurobiologically accurate brain parcellations; and (vii) share published data via user-friendly databases. We illustrate the HCP-style paradigm using existing HCP data sets and provide guidance for future research. Widespread adoption of this paradigm should accelerate progress in understanding the brain in health and disease.},
	number = {9},
	journal = {Nature neuroscience},
	author = {Glasser, Matthew F and Smith, Stephen M and Marcus, Daniel S and Andersson, Jesper L R and Auerbach, Edward J and Behrens, Timothy E J and Coalson, Timothy S and Harms, Michael P and Jenkinson, Mark and Moeller, Steen and Robinson, Emma C and Sotiropoulos, Stamatios N and Xu, Junqian and Yacoub, Essa and Ugurbil, Kamil and Van Essen, David C},
	year = {2016},
	pmid = {27571196},
	pages = {1175--87},
	file = {Attachment:/Users/tito/Zotero/storage/M75IA7RF/Glasser et al. - 2016 - The Human Connectome Project's neuroimaging approach.pdf:application/pdf},
}

@article{glasser_minimal_2013,
	title = {The minimal preprocessing pipelines for the {Human} {Connectome} {Project}},
	volume = {80},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2013.04.127},
	doi = {10.1016/j.neuroimage.2013.04.127},
	abstract = {The Human Connectome Project (HCP) faces the challenging task of bringing multiple magnetic resonance imaging (MRI) modalities together in a common automated preprocessing framework across a large cohort of subjects. The MRI data acquired by the HCP differ in many ways from data acquired on conventional 3. Tesla scanners and often require newly developed preprocessing methods. We describe the minimal preprocessing pipelines for structural, functional, and diffusion MRI that were developed by the HCP to accomplish many low level tasks, including spatial artifact/distortion removal, surface generation, cross-modal registration, and alignment to standard space. These pipelines are specially designed to capitalize on the high quality data offered by the HCP. The final standard space makes use of a recently introduced CIFTI file format and the associated grayordinate spatial coordinate system. This allows for combined cortical surface and subcortical volume analyses while reducing the storage and processing requirements for high spatial and temporal resolution data. Here, we provide the minimum image acquisition requirements for the HCP minimal preprocessing pipelines and additional advice for investigators interested in replicating the HCP's acquisition protocols or using these pipelines. Finally, we discuss some potential future improvements to the pipelines. ?? 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Glasser, Matthew F. and Sotiropoulos, Stamatios N. and Wilson, J. Anthony and Coalson, Timothy S. and Fischl, Bruce and Andersson, Jesper L. and Xu, Junqian and Jbabdi, Saad and Webster, Matthew and Polimeni, Jonathan R. and Van Essen, David C. and Jenkinson, Mark},
	year = {2013},
	pmid = {23668970},
	keywords = {CIFTI, Grayordinates, Human Connectome Project, Image analysis pipeline, Multi-modal data integration, Surface-based analysis},
	pages = {105--124},
	file = {Attachment:/Users/tito/Zotero/storage/7MB9WQ5H/Glasser et al. - 2013 - The minimal preprocessing pipelines for the Human Connectome Project.pdf:application/pdf},
}

@article{lim_inferring_2015,
	title = {Inferring learning rules from distributions of firing rates},
	volume = {18},
	issn = {1097-6256},
	url = {http://www.nature.com/neuro/journal/v18/n12/full/nn.4158.html#close},
	doi = {10.1038/nn.4158},
	abstract = {Information about external stimuli is thought to be stored in cortical circuits through experience-dependent modifications of synaptic connectivity. These modifications of network connectivity should lead to changes in neuronal activity as a particular stimulus is repeatedly encountered. Here we ask what plasticity rules are consistent with the differences in the statistics of the visual response to novel and familiar stimuli in inferior temporal cortex, an area underlying visual object recognition. We introduce a method that allows one to infer the dependence of the presumptive learning rule on postsynaptic firing rate, and we show that the inferred learning rule exhibits depression for low postsynaptic rates and potentiation for high rates. The threshold separating depression from potentiation is strongly correlated with both mean and s.d. of the firing rate distribution. Finally, we show that network models implementing a rule extracted from data show stable learning dynamics and lead to sparser representations of stimuli.},
	number = {12},
	journal = {Nature neuroscience},
	author = {Lim, Sukbin and McKee, Jillian L and Woloszyn, Luke and Amit, Yali and Freedman, David J and Sheinberg, David L and Brunel, Nicolas},
	year = {2015},
	pmid = {26523643},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/2PRFAAFQ/Lim et al. - 2015 - Inferring learning rules from distributions of firing rates.pdf:application/pdf},
}

@article{barral_synaptic_2016,
	title = {Synaptic scaling rule preserves excitatory–inhibitory balance and salient neuronal network dynamics},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.4415},
	doi = {10.1038/nn.4415},
	number = {October},
	journal = {Nature Neuroscience},
	author = {Barral, Jérémie and Reyes, Alex D},
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/UYCWN7DX/Barral, Reyes - 2016 - Synaptic scaling rule preserves excitatory–inhibitory balance and salient neuronal network dynamics.pdf:application/pdf},
}

@article{harrison_multivariate_2003,
	title = {Multivariate autoregressive modeling of {fMRI} time series},
	volume = {19},
	issn = {10538119},
	doi = {10.1016/S1053-8119(03)00160-5},
	abstract = {We propose the use of multivariate autoregressive (MAR) models of functional magnetic resonance imaging time series to make inferences about functional integration within the human brain. The method is demonstrated with synthetic and real data showing how such models are able to characterize interregional dependence. We extend linear MAR models to accommodate nonlinear interactions to model top-down modulatory processes with bilinear terms. MAR models are time series models and thereby model temporal order within measured brain activity. A further benefit of the MAR approach is that connectivity maps may contain loops, yet exact inference can proceed within a linear framework. Model order selection and parameter estimation are implemented by using Bayesian methods. ?? 2003 Elsevier Science (USA). All rights reserved.},
	number = {4},
	journal = {NeuroImage},
	author = {Harrison, L. and Penny, W. D. and Friston, K.},
	year = {2003},
	pmid = {12948704},
	pages = {1477--1491},
	file = {Attachment:/Users/tito/Zotero/storage/TK9YGHIC/Harrison, Penny, Friston - 2003 - Multivariate autoregressive modeling of fMRI time series.pdf:application/pdf},
}

@article{funamizu_neural_2016,
	title = {Neural substrate of dynamic {Bayesian} inference in the cerebral cortex},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.4390},
	doi = {10.1038/nn.4390},
	number = {September},
	journal = {Nature Neuroscience},
	author = {Funamizu, Akihiro and Kuhn, Bernd and Doya, Kenji},
	year = {2016},
	pmid = {27643432},
	file = {Attachment:/Users/tito/Zotero/storage/PYC5DPQK/Funamizu, Kuhn, Doya - 2016 - Neural substrate of dynamic Bayesian inference in the cerebral cortex.pdf:application/pdf},
}

@article{morrison_diversity_2016,
	title = {Diversity of emergent dynamics in competitive threshold-linear networks: a preliminary report},
	url = {http://arxiv.org/abs/1605.04463},
	abstract = {Threshold-linear networks consist of simple units interacting in the presence of a threshold nonlinearity. Competitive threshold-linear networks have long been known to exhibit multistability, where the activity of the network settles into one of potentially many steady states. In this work, we find conditions that guarantee the absence of steady states, while maintaining bounded activity. These conditions lead us to define a combinatorial family of competitive threshold-linear networks, parametrized by a simple directed graph. By exploring this family, we discover that threshold-linear networks are capable of displaying a surprisingly rich variety of nonlinear dynamics, including limit cycles, quasiperiodic attractors, and chaos. In particular, several types of nonlinear behaviors can co-exist in the same network. Our mathematical results also enable us to engineer networks with multiple dynamic patterns. Taken together, these theoretical and computational findings suggest that threshold-linear networks may be a valuable tool for understanding the relationship between network connectivity and emergent dynamics.},
	author = {Morrison, Katherine and Degeratu, Anda and Itskov, Vladimir and Curto, Carina},
	year = {2016},
	pages = {1--12},
	file = {Attachment:/Users/tito/Zotero/storage/B7M9CTH9/Morrison et al. - 2016 - Diversity of emergent dynamics in competitive threshold-linear networks a preliminary report.pdf:application/pdf},
}

@article{gratton_evidence_2016,
	title = {Evidence for {Two} {Independent} {Factors} that {Modify} {Brain} {Networks} to {Meet} {Task} {Goals}},
	volume = {17},
	issn = {22111247},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S2211124716313717},
	doi = {10.1016/j.celrep.2016.10.002},
	number = {5},
	journal = {Cell Reports},
	author = {Gratton, Caterina and Laumann, Timothy O. and Gordon, Evan M. and Adeyemo, Babatunde and Petersen, Steven E.},
	year = {2016},
	pages = {1276--1288},
	file = {Attachment:/Users/tito/Zotero/storage/E972GT8X/Gratton et al. - 2016 - Evidence for Two Independent Factors that Modify Brain Networks to Meet Task Goals.pdf:application/pdf},
}

@article{fox_spontaneous_2007,
	title = {Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging},
	volume = {8},
	issn = {1471-003X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17704812},
	doi = {10.1038/nrn2201},
	abstract = {The majority of functional neuroscience studies have focused on the brain's response to a task or stimulus. However, the brain is very active even in the absence of explicit input or output. In this Article we review recent studies examining spontaneous fluctuations in the blood oxygen level dependent (BOLD) signal of functional magnetic resonance imaging as a potentially important and revealing manifestation of spontaneous neuronal activity. Although several challenges remain, these studies have provided insight into the intrinsic functional architecture of the brain, variability in behaviour and potential physiological correlates of neurological and psychiatric disease.},
	number = {9},
	journal = {Nat Rev Neurosci},
	author = {Fox, M D and Raichle, M E},
	year = {2007},
	pmid = {17704812},
	keywords = {Humans, *Brain Mapping, *Magnetic Resonance Imaging, Animals, Brain/*blood supply/*physiology, Computer-Assisted, Image Processing, Oxygen/blood},
	pages = {700--711},
	file = {Attachment:/Users/tito/Zotero/storage/BNZDJA6R/Fox, Raichle - 2007 - Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging.pdf:application/pdf},
}

@article{power_spurious_2012,
	title = {Spurious but systematic correlations in functional connectivity {MRI} networks arise from subject motion},
	volume = {59},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2011.10.018},
	doi = {10.1016/j.neuroimage.2011.10.018},
	abstract = {Here, we demonstrate that subject motion produces substantial changes in the timecourses of resting state functional connectivity MRI (rs-fcMRI) data despite compensatory spatial registration and regression of motion estimates from the data. These changes cause systematic but spurious correlation structures throughout the brain. Specifically, many long-distance correlations are decreased by subject motion, whereas many short-distance correlations are increased. These changes in rs-fcMRI correlations do not arise from, nor are they adequately countered by, some common functional connectivity processing steps. Two indices of data quality are proposed, and a simple method to reduce motion-related effects in rs-fcMRI analyses is demonstrated that should be flexibly implementable across a variety of software platforms. We demonstrate how application of this technique impacts our own data, modifying previous conclusions about brain development. These results suggest the need for greater care in dealing with subject motion, and the need to critically revisit previous rs-fcMRI work that may not have adequately controlled for effects of transient subject movements. ?? 2011 Elsevier Inc.},
	number = {3},
	journal = {NeuroImage},
	author = {Power, Jonathan D. and Barnes, Kelly A. and Snyder, Abraham Z. and Schlaggar, Bradley L. and Petersen, Steven E.},
	year = {2012},
	pmid = {22019881},
	keywords = {Movement, Artifact, Motion, Noise, Network, Resting state, FMRI, FcMRI},
	pages = {2142--2154},
	file = {Attachment:/Users/tito/Zotero/storage/XQS3VXKN/Power et al. - 2012 - Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion.pdf:application/pdf},
}

@article{lewis_fast_2016,
	title = {Fast {fMRI} can detect oscillatory neural activity in humans},
	issn = {0027-8424},
	doi = {10.1073/pnas.1608117113},
	abstract = {Oscillatory neural dynamics play an important role in the coordination of large-scale brain networks. High-level cognitive processes depend on dynamics evolving over hundreds of milliseconds, so measuring neural activity in this frequency range is important for cognitive neuroscience. However, current noninvasive neuroimaging methods are not able to precisely localize oscillatory neural activity above 0.2 Hz. Electroencephalography and magnetoencephalography have limited spatial resolution, whereas fMRI has limited temporal resolution because it measures vascular responses rather than directly recording neural activity. We hypothesized that the recent development of fast fMRI techniques, combined with the extra sensitivity afforded by ultra-high-field systems, could enable precise localization of neural oscillations. We tested whether fMRI can detect neural oscillations using human visual cortex as a model system. We detected small oscillatory fMRI signals in response to stimuli oscillating at up to 0.75 Hz within single scan sessions, and these responses were an order of magnitude larger than predicted by canonical linear models. Simultaneous EEG–fMRI and simulations based on a biophysical model of the hemodynamic response to neuronal activity suggested that the blood oxygen level-dependent response becomes faster for rapidly varying stimuli, enabling the detection of higher frequencies than expected. Accounting for phase delays across voxels further improved detection, demonstrating that identifying vascular delays will be of increasing importance with higher-frequency activity. These results challenge the assumption that the hemodynamic response is slow, and demonstrate that fMRI has the potential to map neural oscillations directly throughout the brain.},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Lewis, Laura D. and Setsompop, Kawin and Rosen, Bruce R. and Polimeni, Jonathan R.},
	year = {2016},
	pmid = {27729529},
	file = {Attachment:/Users/tito/Zotero/storage/INMFMAEU/Lewis et al. - 2016 - Fast fMRI can detect oscillatory neural activity in humans.pdf:application/pdf},
}

@article{zhang_choosing_2013,
	title = {Choosing the rules: distinct and overlapping frontoparietal representations of task rules for perceptual decisions.},
	volume = {33},
	issn = {1529-2401},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3713727&tool=pmcentrez&rendertype=abstract},
	doi = {10.1523/JNEUROSCI.5193-12.2013},
	abstract = {Behavior is governed by rules that associate stimuli with responses and outcomes. Human and monkey studies have shown that rule-specific information is widely represented in the frontoparietal cortex. However, it is not known how establishing a rule under different contexts affects its neural representation. Here, we use event-related functional MRI (fMRI) and multivoxel pattern classification methods to investigate the human brain's mechanisms of establishing and maintaining rules for multiple perceptual decision tasks. Rules were either chosen by participants or specifically instructed to them, and the fMRI activation patterns representing rule-specific information were compared between these contexts. We show that frontoparietal regions differ in the properties of their rule representations during active maintenance before execution. First, rule-specific information maintained in the dorsolateral and medial frontal cortex depends on the context in which it was established (chosen vs specified). Second, rule representations maintained in the ventrolateral frontal and parietal cortex are independent of the context in which they were established. Furthermore, we found that the rule-specific coding maintained in anticipation of stimuli may change with execution of the rule: representations in context-independent regions remain invariant from maintenance to execution stages, whereas rule representations in context-dependent regions do not generalize to execution stage. The identification of distinct frontoparietal systems with context-independent and context-dependent task rule representations, and the distinction between anticipatory and executive rule representations, provide new insights into the functional architecture of goal-directed behavior.},
	number = {29},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Zhang, Jiaxiang and Kriegeskorte, Nikolaus and Carlin, Johan D and Rowe, James B},
	year = {2013},
	pmid = {23864675},
	keywords = {Adult, Brain Mapping, Decision Making, Female, Humans, Magnetic Resonance Imaging, Male, Photic Stimulation, Reaction Time, Computer-Assisted, Image Processing, Decision Making: physiology, Frontal Lobe, Frontal Lobe: physiology, Learning, Learning: physiology, Parietal Lobe, Parietal Lobe: physiology, Psychomotor Performance, Psychomotor Performance: physiology, Reaction Time: physiology, Visual Perception, Visual Perception: physiology},
	pages = {11852--62},
	file = {Attachment:/Users/tito/Zotero/storage/D4WS4R67/Zhang et al. - 2013 - Choosing the rules distinct and overlapping frontoparietal representations of task rules for perceptual decisions.pdf:application/pdf},
}

@article{horwitz_elusive_2003,
	title = {The elusive concept of brain connectivity},
	volume = {19},
	issn = {10538119},
	doi = {10.1016/S1053-8119(03)00112-5},
	abstract = {Neurons and neural populations do not function as islands onto themselves. Rather, they interact with other such elements through their afferent and efferent connections in an orchestrated manner so as to enable different sensorimotor and cognitive tasks to be performed. The concept of functional connectivity and the allied notion of effective connectivity were introduced to designate the functional strengths of such interactions. Functional neuroimaging methods, especially PET and fMRI, have been used extensively to evaluate the functional connectivity between different brain regions. After providing a brief historical review of these notions of brain connectivity, I argue that the conceptual formulations of functional and effective connectivity are far from clear. Specifically, the terms functional and effective connectivity are applied to quantities computed on types of functional imaging data (e.g., PET, fMRI, EEG) that vary in spatial, temporal, and other features, using different definitions (even for data of the same modality) and employing different computational algorithms. Until it is understood what each definition means in terms of an underlying neural substrate, comparisons of functional and/or effective connectivity across studies may appear inconsistent and should be performed with great caution. © 2003 Elsevier Science (USA). All rights reserved.},
	number = {2},
	journal = {NeuroImage},
	author = {Horwitz, Barry},
	year = {2003},
	pmid = {12814595},
	pages = {466--470},
	file = {Attachment:/Users/tito/Zotero/storage/V8F23FTS/Horwitz - 2003 - The elusive concept of brain connectivity.pdf:application/pdf},
}

@article{churchland_variance_2011,
	title = {Variance as a {Signature} of {Neural} {Computations} during {Decision} {Making}},
	volume = {69},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2010.12.037},
	doi = {10.1016/j.neuron.2010.12.037},
	abstract = {Traditionally, insights into neural computation have been furnished by averaged firing rates from many??stimulus repetitions or trials. We pursue an analysis of neural response variance to unveil neural computations that cannot be discerned from measures of??average firing rate. We analyzed single-neuron recordings from the lateral intraparietal area (LIP), during a perceptual decision-making task. Spike count variance was divided into two components using the law of total variance for doubly stochastic processes: (1) variance of counts that would be produced by a stochastic point process with a given rate, and loosely (2) the variance of the rates that would produce those counts (i.e., " conditional expectation" ). The variance and correlation of the conditional expectation exposed several neural mechanisms: mixtures of firing rate states preceding the decision, accumulation of stochastic " evidence" during decision formation, and a stereotyped response at decision end. These analyses help to differentiate among several alternative decision-making models. ?? 2011 Elsevier Inc.},
	number = {4},
	journal = {Neuron},
	author = {Churchland, Anne K. and Kiani, R. and Chaudhuri, R. and Wang, Xiao Jing and Pouget, Alexandre and Shadlen, M. N.},
	year = {2011},
	pmid = {21338889},
	pages = {818--831},
	file = {Attachment:/Users/tito/Zotero/storage/7HQYSVXP/Churchland et al. - 2011 - Variance as a Signature of Neural Computations during Decision Making.pdf:application/pdf},
}

@article{fox_intrinsic_2007,
	title = {Intrinsic {Fluctuations} within {Cortical} {Systems} {Account} for {Intertrial} {Variability} in {Human} {Behavior}},
	volume = {56},
	issn = {08966273},
	doi = {10.1016/j.neuron.2007.08.023},
	abstract = {The resting brain is not silent, but exhibits organized fluctuations in neuronal activity even in the absence of tasks or stimuli. This intrinsic brain activity persists during task performance and contributes to variability in evoked brain responses. What is unknown is if this intrinsic activity also contributes to variability in behavior. In the current fMRI study, we identify a relationship between human brain activity in the left somatomotor cortex and spontaneous trial-to-trial variability in button press force. We then demonstrate that 74\% of this brain-behavior relationship is attributable to ongoing fluctuations in intrinsic activity similar to those observed during resting fixation. In addition to establishing a functional and behavioral significance of intrinsic brain activity, these results lend new insight into the origins of variability in human behavior. © 2007 Elsevier Inc. All rights reserved.},
	number = {1},
	journal = {Neuron},
	author = {Fox, Michael D. and Snyder, Abraham Z. and Vincent, Justin L. and Raichle, Marcus E.},
	year = {2007},
	pmid = {17920023},
	keywords = {SYSNEURO, SYSBIO},
	pages = {171--184},
	file = {Attachment:/Users/tito/Zotero/storage/Z6BQKYUU/Fox et al. - 2007 - Intrinsic Fluctuations within Cortical Systems Account for Intertrial Variability in Human Behavior.pdf:application/pdf},
}

@article{cole_activity_2016,
	title = {Activity flow over resting-state networks shapes cognitive task activations},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.4406},
	doi = {10.1038/nn.4406},
	journal = {Nature Neuroscience},
	author = {Cole, Michael W and Ito, Takuya and Bassett, Danielle S and Schultz, Douglas H},
	month = oct,
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/CGALUSVE/Cole et al. - 2016 - Activity flow over resting-state networks shapes cognitive task activations.pdf:application/pdf},
}

@article{siegel_cortical_2015,
	title = {Cortical information flow during flexible sensorimotor decisions},
	volume = {348},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/content/348/6241/1352.full},
	doi = {10.1126/science.aab0551},
	abstract = {During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.},
	number = {6241},
	journal = {Science},
	author = {Siegel, Markus and Buschman, Timothy J and Miller, Earl K},
	year = {2015},
	pmid = {26089513},
	pages = {1352--55},
	file = {Attachment:/Users/tito/Zotero/storage/HEHLF9FZ/Siegel, Buschman, Miller - 2015 - Cortical information flow during flexible sensorimotor decisions.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Y4RPJUJE/Siegel, Buschman, Miller - 2015 - Cortical information flow during flexible sensorimotor decisions(5).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/D626LKX9/Siegel, Buschman, Miller - 2015 - Cortical information flow during flexible sensorimotor decisions.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/4ZI5WHIS/Siegel, Buschman, Miller - 2015 - Cortical information flow during flexible sensorimotor decisions(3).pdf:application/pdf},
}

@article{laumann_stability_2016,
	title = {On the {Stability} of {BOLD} {fMRI} {Correlations}},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhw265},
	doi = {10.1093/cercor/bhw265},
	abstract = {Measurement of correlations between brain regions (functional connectivity) using blood oxygen level dependent (BOLD) fMRI has proven to be a powerful tool for studying the functional organization of the brain. Recently, dynamic functional connectivity has emerged as a major topic in the resting-state BOLD fMRI literature. Here, using simulations and multiple sets of empirical observations, we confirm that imposed task states can alter the correlation structure of BOLD activity. However, we find that observations of “dynamic” BOLD correlations during the resting state are largely explained by sampling variability. Beyond sampling variability, the largest part of observed “dynamics” during rest is attributable to head motion. An additional component of dynamic variability during rest is attributable to fluctuating sleep state. Thus, aside from the preceding explanatory factors, a single correlation structure—as opposed to a sequence of distinct correlation structures—may adequately describe the resting state as measured by BOLD fMRI. These results suggest that resting-state BOLD correlations do not primarily reflect moment-to-moment changes in cognitive content. Rather, resting-state BOLD correlations may predominantly reflect processes concerned with the maintenance of the long-term stability of the brain's functional organization.},
	journal = {Cerebral Cortex},
	author = {Laumann, Timothy O. and Snyder, Abraham Z. and Mitra, Anish and Gordon, Evan M. and Gratton, Caterina and Adeyemo, Babatunde and Gilmore, Adrian W. and Nelson, Steven M. and Berg, Jeff J. and Greene, Deanna J. and McCarthy, John E. and Tagliazucchi, Enzo and Laufs, Helmut and Schlaggar, Bradley L. and Dosenbach, Nico U. F. and Petersen, Steven E.},
	year = {2016},
	pmid = {27591147},
	keywords = {functional connectivity, resting state, dynamics, all rights reserved, bold fmri, com, for permissions, journals, nonstationarity, oup, permissions, please e-mail, press, published by oxford university, the author 2016},
	pages = {1--14},
	file = {Attachment:/Users/tito/Zotero/storage/I8I7SL8D/Laumann et al. - 2016 - On the Stability of BOLD fMRI Correlations.pdf:application/pdf},
}

@article{buschman_behavior_2015,
	title = {From {Behavior} to {Neural} {Dynamics}: {An} {Integrated} {Theory} of {Attention}},
	volume = {88},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2015.09.017},
	doi = {10.1016/j.neuron.2015.09.017},
	abstract = {The brain has a limited capacity and therefore needs mechanisms to selectively enhance the information most relevant to one's current behavior. We refer to these mechanisms as "attention." Attention acts by increasing the strength of selected neural representations and preferentially routing them through the brain's large-scale network. This is a critical component of cognition and therefore has been a central topic in cognitive neuroscience. Here we review a diverse literature that has studied attention at the level of behavior, networks, circuits, and neurons. We then integrate these disparate results into a unified theory of attention.},
	number = {1},
	journal = {Neuron},
	author = {Buschman, Timothy J. and Kastner, Sabine},
	year = {2015},
	pmid = {26447577},
	pages = {127--144},
	file = {Attachment:/Users/tito/Zotero/storage/3866L44Y/Buschman, Kastner - 2015 - From Behavior to Neural Dynamics An Integrated Theory of Attention.pdf:application/pdf},
}

@article{van_den_heuvel_network_2013,
	title = {Network hubs in the human brain},
	volume = {17},
	issn = {13646613},
	url = {http://dx.doi.org/10.1016/j.tics.2013.09.012},
	doi = {10.1016/j.tics.2013.09.012},
	abstract = {Virtually all domains of cognitive function require the integration of distributed neural activity. Network analysis of human brain connectivity has consistently identified sets of regions that are critically important for enabling efficient neuronal signaling and communication. The central embedding of these candidate 'brain hubs' in anatomical networks supports their diverse functional roles across a broad range of cognitive tasks and widespread dynamic coupling within and across functional networks. The high level of centrality of brain hubs also renders them points of vulnerability that are susceptible to disconnection and dysfunction in brain disorders. Combining data from numerous empirical and computational studies, network approaches strongly suggest that brain hubs play important roles in information integration underpinning numerous aspects of complex cognitive function. ?? 2013 Elsevier Ltd.},
	number = {12},
	journal = {Trends in Cognitive Sciences},
	author = {van den Heuvel, Martijn P. and Sporns, Olaf},
	year = {2013},
	pmid = {24231140},
	pages = {683--696},
	file = {Attachment:/Users/tito/Zotero/storage/8RWD69S6/van den Heuvel, Sporns - 2013 - Network hubs in the human brain.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/7WIIET59/van den Heuvel, Sporns - 2013 - Network hubs in the human brain.pdf:application/pdf},
}

@article{raichle_default_2001,
	title = {A default mode of brain function.},
	volume = {98},
	issn = {0027-8424},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=14647&tool=pmcentrez&rendertype=abstract},
	doi = {10.1073/pnas.98.2.676},
	abstract = {A baseline or control state is fundamental to the understanding of most complex systems. Defining a baseline state in the human brain, arguably our most complex system, poses a particular challenge. Many suspect that left unconstrained, its activity will vary unpredictably. Despite this prediction we identify a baseline state of the normal adult human brain in terms of the brain oxygen extraction fraction or OEF. The OEF is defined as the ratio of oxygen used by the brain to oxygen delivered by flowing blood and is remarkably uniform in the awake but resting state (e.g., lying quietly with eyes closed). Local deviations in the OEF represent the physiological basis of signals of changes in neuronal activity obtained with functional MRI during a wide variety of human behaviors. We used quantitative metabolic and circulatory measurements from positron-emission tomography to obtain the OEF regionally throughout the brain. Areas of activation were conspicuous by their absence. All significant deviations from the mean hemisphere OEF were increases, signifying deactivations, and resided almost exclusively in the visual system. Defining the baseline state of an area in this manner attaches meaning to a group of areas that consistently exhibit decreases from this baseline, during a wide variety of goal-directed behaviors monitored with positron-emission tomography and functional MRI. These decreases suggest the existence of an organized, baseline default mode of brain function that is suspended during specific goal-directed behaviors.},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Raichle, M E and MacLeod, A M and Snyder, A Z and Powers, W J and Gusnard, D A and Shulman, G L},
	year = {2001},
	pmid = {11209064},
	keywords = {Attention, Brain, Adult, Brain Mapping, Cerebrovascular Circulation, Female, Humans, Magnetic Resonance Imaging, Male, Attention: physiology, Models, Neurological, Parietal Lobe, Parietal Lobe: physiology, 80 and over, Aged, Brain Chemistry, Brain: physiology, Brain: radionuclide imaging, Emission-Computed, Middle Aged, Oxygen, Oxygen Consumption, Oxygen: blood, Oxyhemoglobins, Oxyhemoglobins: analysis, Rest, Rest: physiology, Supine Position, Tomography, Wakefulness, Wakefulness: physiology},
	pages = {676--82},
	file = {Attachment:/Users/tito/Zotero/storage/EYM2X4LL/Raichle et al. - 2001 - A default mode of brain function.pdf:application/pdf},
}

@article{zalesky_time-resolved_2014,
	title = {Time-resolved resting-state brain networks},
	volume = {111},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1400181111},
	language = {en},
	number = {28},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Zalesky, A. and Fornito, A. and Cocchi, L. and Gollo, L. L. and Breakspear, M.},
	month = jul,
	year = {2014},
	pages = {10341--10346},
}

@article{schippers_effect_2011,
	title = {The effect of intra- and inter-subject variability of hemodynamic responses on group level {Granger} causality analyses},
	volume = {57},
	issn = {1095-9572},
	doi = {10.1016/j.neuroimage.2011.02.008},
	abstract = {Granger causality analyses aim to reveal the direction of influence between brain areas by analyzing temporal precedence: if a signal change in area A consistently precedes a signal change in area B, then A Granger-causes B. fMRI-based Granger causality inferences are mediated by the hemodynamic response function which can vary across brain regions. This variability might induce a bias in Granger causality analyses. Here we use simulations to investigate the effect of hemodynamic response variability on Granger causality analyses at the level of a group of twenty participants. We used a set of hemodynamic responses measured by Handwerker et al. (Neuroimage, 2004) and simulated 200 experiments in which time series with known directions of influence are convolved with these hemodynamic responses and submitted to Granger causality analysis. Results show that the average chance to find a significant Granger causality effect when no actual influence is present in the data stays well below the p-level imposed on the second level statistics. Most importantly, when the analyses reveal a significant directed influence, this direction was accurate in the vast majority of the cases. The sensitivity of the analyses however depended on the neuronal delay between the source and target regions and their relative hemodynamic delay. Influences flowing from regions to one with the same or a slower hemodynamic response function were detected in over 80\% of the cases when the neuronal delay was at least 100 ms. Influences flowing to a region with a faster hemodynamic delay were detected in over 80\% of the cases when delays are above 1s.},
	language = {eng},
	number = {1},
	journal = {NeuroImage},
	author = {Schippers, Marleen B. and Renken, Remco and Keysers, Christian},
	month = jul,
	year = {2011},
	pmid = {21316469},
	pages = {22--36},
}

@article{douglas_neuronal_2004,
	title = {{NEURONAL} {CIRCUITS} {OF} {THE} {NEOCORTEX}},
	volume = {27},
	issn = {0147-006X, 1545-4126},
	doi = {10.1146/annurev.neuro.27.070203.144152},
	language = {en},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Douglas, Rodney J. and Martin, Kevan A.C.},
	month = jul,
	year = {2004},
	pages = {419--451},
}

@article{nolte_robustly_2008,
	title = {Robustly {Estimating} the {Flow} {Direction} of {Information} in {Complex} {Physical} {Systems}},
	volume = {100},
	issn = {0031-9007, 1079-7114},
	doi = {10.1103/PhysRevLett.100.234101},
	language = {en},
	number = {23},
	journal = {Physical Review Letters},
	author = {Nolte, Guido and Ziehe, Andreas and Nikulin, Vadim V. and Schlögl, Alois and Krämer, Nicole and Brismar, Tom and Müller, Klaus-Robert},
	month = jun,
	year = {2008},
}

@article{hipp_bold_2015,
	title = {{BOLD} {fMRI} {Correlation} {Reflects} {Frequency}-{Specific} {Neuronal} {Correlation}},
	volume = {25},
	issn = {09609822},
	doi = {10.1016/j.cub.2015.03.049},
	language = {en},
	number = {10},
	journal = {Current Biology},
	author = {Hipp, Joerg F. and Siegel, Markus},
	month = may,
	year = {2015},
	pages = {1368--1374},
}

@article{goldman-rakic_topography_1988,
	title = {Topography of cognition: parallel distributed networks in primate association cortex},
	volume = {11},
	issn = {0147-006X},
	doi = {10.1146/annurev.ne.11.030188.001033},
	language = {eng},
	journal = {Annual Review of Neuroscience},
	author = {Goldman-Rakic, P. S.},
	year = {1988},
	pmid = {3284439},
	pages = {137--156},
}

@article{sudre_tracking_2012,
	title = {Tracking neural coding of perceptual and semantic features of concrete nouns},
	volume = {62},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2012.04.048},
	language = {en},
	number = {1},
	journal = {NeuroImage},
	author = {Sudre, Gustavo and Pomerleau, Dean and Palatucci, Mark and Wehbe, Leila and Fyshe, Alona and Salmelin, Riitta and Mitchell, Tom},
	month = aug,
	year = {2012},
	pages = {451--463},
}

@article{handwerker_variation_2004,
	title = {Variation of {BOLD} hemodynamic responses across subjects and brain regions and their effects on statistical analyses},
	volume = {21},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2003.11.029},
	abstract = {Estimates of hemodynamic response functions (HRF) are often integral parts of event-related fMRI analyses. Although HRFs vary across individuals and brain regions, few studies have investigated how variations affect the results of statistical analyses using the general linear model (GLM). In this study, we empirically estimated HRFs from primary motor and visual cortices and frontal and supplementary eye fields (SEF) in 20 subjects. We observed more variability across subjects than regions and correlated variation of time-to-peak values across several pairs of regions. Simulations examined the effects of observed variability on statistical results and ways different experimental designs and statistical models can limit these effects. Widely spaced and rapid event-related experimental designs with two sampling rates were tested. Statistical models compared an empirically derived HRF to a canonical HRF and included the first derivative of the HRF in the GLM. Small differences between the estimated and true HRFs did not cause false negatives, but larger differences within an observed range of variation, such as a 2.5-s time-to-onset misestimate, led to false negatives. Although small errors minimally affected detection of activity, time-to-onset misestimates as small as 1 s influenced model parameter estimation and therefore random effects analyses across subjects. Experiment and analysis design methods such as decreasing the sampling rate or including the HRF's temporal derivative in the GLM improved results, but did not eliminate errors caused by HRF misestimates. These results highlight the benefits of determining the best possible HRF estimate and potential negative consequences of assuming HRF consistency across subjects or brain regions.},
	language = {eng},
	number = {4},
	journal = {NeuroImage},
	author = {Handwerker, Daniel A. and Ollinger, John M. and D'Esposito, Mark},
	month = apr,
	year = {2004},
	pmid = {15050587},
	pages = {1639--1651},
}

@article{brookes_investigating_2011,
	title = {Investigating the electrophysiological basis of resting state networks using magnetoencephalography},
	volume = {108},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1112685108},
	language = {en},
	number = {40},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brookes, M. J. and Woolrich, M. and Luckhoo, H. and Price, D. and Hale, J. R. and Stephenson, M. C. and Barnes, G. R. and Smith, S. M. and Morris, P. G.},
	month = oct,
	year = {2011},
	pages = {16783--16788},
}

@article{shannon_mathematical_1948,
	title = {A {Mathematical} {Theory} of {Communication}},
	volume = {27},
	issn = {15387305},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.},
	number = {3},
	journal = {Bell System Technical Journal},
	author = {Shannon, C. E.},
	year = {1948},
	pmid = {9230594},
	pages = {379--423},
	file = {Attachment:/Users/tito/Zotero/storage/IMWGEPNZ/Shannon - 1948 - A Mathematical Theory of Communication.pdf:application/pdf},
}

@article{de-wit_is_2016,
	title = {Is neuroimaging measuring information in the brain?},
	issn = {1531-5320},
	url = {http://dx.doi.org/10.3758/s13423-016-1002-0},
	doi = {10.3758/s13423-016-1002-0},
	abstract = {Psychology moved beyond the stimulus response mapping of behaviorism by adopting an information processing framework. This shift from behavioral to cognitive science was partly inspired by work demonstrating that the concept of information could be defined and quantified (Shannon, 1948). This transition developed further from cognitive science into cognitive neuroscience, in an attempt to measure information in the brain. In the cognitive neurosciences, however, the term information is often used without a clear definition. This paper will argue that, if the formulation proposed by Shannon is applied to modern neuroimaging, then numerous results would be interpreted differently. More specifically, we argue that much modern cognitive neuroscience implicitly focuses on the question of how we can interpret the activations we record in the brain (experimenter-as-receiver), rather than on the core question of how the rest of the brain can interpret those activations (cortex-as-receiver). A clearer focus on whether activations recorded via neuroimaging can actually act as information in the brain would not only change how findings are interpreted but should also change the direction of empirical research in cognitive neuroscience.},
	journal = {Psychonomic Bulletin \& Review},
	author = {De-Wit, Lee and Alexander, David and Ekroll, Vebjørn and Wagemans, Johan},
	year = {2016},
	pmid = {26833316},
	keywords = {neuroimaging, cognitive neuroscience},
	pages = {1--14},
	file = {Attachment:/Users/tito/Zotero/storage/5RPZG93K/de-Wit et al. - 2016 - Is neuroimaging measuring information in the brain.pdf:application/pdf},
}

@article{duyn_future_2012,
	title = {The future of ultra-high field {MRI} and {fMRI} for study of the human brain},
	volume = {62},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2011.10.065},
	language = {en},
	number = {2},
	journal = {NeuroImage},
	author = {Duyn, Jeff H.},
	month = aug,
	year = {2012},
	pages = {1241--1248},
}

@article{kohler_pattern_2013,
	title = {Pattern classification precedes region-average hemodynamic response in early visual cortex},
	volume = {78},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2013.04.019},
	language = {en},
	journal = {NeuroImage},
	author = {Kohler, Peter J. and Fogelson, Sergey V. and Reavis, Eric A. and Meng, Ming and Guntupalli, J. Swaroop and Hanke, Michael and Halchenko, Yaroslav O. and Connolly, Andrew C. and Haxby, James V. and Tse, Peter U.},
	month = sep,
	year = {2013},
	pages = {249--260},
}

@article{patel_bayesian_2006,
	title = {A {Bayesian} approach to determining connectivity of the human brain},
	volume = {27},
	issn = {1065-9471},
	doi = {10.1002/hbm.20182},
	abstract = {Recent work regarding the analysis of brain imaging data has focused on examining functional and effective connectivity of the brain. We develop a novel descriptive and inferential method to analyze the connectivity of the human brain using functional MRI (fMRI). We assess the relationship between pairs of distinct brain regions by comparing expected joint and marginal probabilities of elevated activity of voxel pairs through a Bayesian paradigm, which allows for the incorporation of previously known anatomical and functional information. We define the relationship between two distinct brain regions by measures of functional connectivity and ascendancy. After assessing the relationship between all pairs of brain voxels, we are able to construct hierarchical functional networks from any given brain region and assess significant functional connectivity and ascendancy in these networks. We illustrate the use of our connectivity analysis using data from an fMRI study of social cooperation among women who played an iterated "Prisoner's Dilemma" game. Our analysis reveals a functional network that includes the amygdala, anterior insula cortex, and anterior cingulate cortex, and another network that includes the ventral striatum, orbitofrontal cortex, and anterior insula. Our method can be used to develop causal brain networks for use with structural equation modeling and dynamic causal models.},
	language = {eng},
	number = {3},
	journal = {Human Brain Mapping},
	author = {Patel, Rajan S. and Bowman, F. Dubois and Rilling, James K.},
	month = mar,
	year = {2006},
	pmid = {16092131},
	pages = {267--276},
}

@article{klamer_differences_2015,
	title = {Differences {Between} {MEG} and {High}-{Density} {EEG} {Source} {Localizations} {Using} a {Distributed} {Source} {Model} in {Comparison} to {fMRI}},
	volume = {28},
	issn = {0896-0267, 1573-6792},
	doi = {10.1007/s10548-014-0405-3},
	language = {en},
	number = {1},
	journal = {Brain Topography},
	author = {Klamer, Silke and Elshahabi, Adham and Lerche, Holger and Braun, Christoph and Erb, Michael and Scheffler, Klaus and Focke, Niels K.},
	month = jan,
	year = {2015},
	pages = {87--94},
}

@article{kumar_spiking_2010,
	title = {Spiking activity propagation in neuronal networks: reconciling different perspectives on neural coding},
	volume = {11},
	issn = {1471-003X, 1471-0048},
	doi = {10.1038/nrn2886},
	number = {9},
	journal = {Nature Reviews Neuroscience},
	author = {Kumar, Arvind and Rotter, Stefan and Aertsen, Ad},
	month = sep,
	year = {2010},
	pages = {615--627},
}

@article{barredo_ventral_2015,
	title = {Ventral {Fronto}-{Temporal} {Pathway} {Supporting} {Cognitive} {Control} of {Episodic} {Memory} {Retrieval}},
	volume = {25},
	issn = {1047-3211, 1460-2199},
	doi = {10.1093/cercor/bht291},
	language = {en},
	number = {4},
	journal = {Cerebral Cortex},
	author = {Barredo, J. and Oztekin, I. and Badre, D.},
	month = apr,
	year = {2015},
	pages = {1004--1019},
}

@article{smith_resting-state_2013,
	title = {Resting-state {fMRI} in the {Human} {Connectome} {Project}},
	volume = {80},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2013.05.039},
	language = {en},
	journal = {NeuroImage},
	author = {Smith, Stephen M. and Beckmann, Christian F. and Andersson, Jesper and Auerbach, Edward J. and Bijsterbosch, Janine and Douaud, Gwenaëlle and Duff, Eugene and Feinberg, David A. and Griffanti, Ludovica and Harms, Michael P. and Kelly, Michael and Laumann, Timothy and Miller, Karla L. and Moeller, Steen and Petersen, Steve and Power, Jonathan and Salimi-Khorshidi, Gholamreza and Snyder, Abraham Z. and Vu, An T. and Woolrich, Mark W. and Xu, Junqian and Yacoub, Essa and Uğurbil, Kamil and Van Essen, David C. and Glasser, Matthew F.},
	month = oct,
	year = {2013},
	pages = {144--168},
}

@article{sadaghiani_ongoing_2015,
	title = {Ongoing dynamics in large-scale functional connectivity predict perception},
	volume = {112},
	issn = {1091-6490},
	doi = {10.1073/pnas.1420687112},
	abstract = {Most brain activity occurs in an ongoing manner not directly locked to external events or stimuli. Regional ongoing activity fluctuates in unison with some brain regions but not others, and the degree of long-range coupling is called functional connectivity, often measured with correlation. Strength and spatial distributions of functional connectivity dynamically change in an ongoing manner over seconds to minutes, even when the external environment is held constant. Direct evidence for any behavioral relevance of these continuous large-scale dynamics has been limited. Here, we investigated whether ongoing changes in baseline functional connectivity correlate with perception. In a continuous auditory detection task, participants perceived the target sound in roughly one-half of the trials. Very long (22-40 s) interstimulus intervals permitted investigation of baseline connectivity unaffected by preceding evoked responses. Using multivariate classification, we observed that functional connectivity before the target predicted whether it was heard or missed. Using graph theoretical measures, we characterized the difference in functional connectivity between states that lead to hits vs. misses. Before misses compared with hits and task-free rest, connectivity showed reduced modularity, a measure of integrity of modular network structure. This effect was strongest in the default mode and visual networks and caused by both reduced within-network connectivity and enhanced across-network connections before misses. The relation of behavior to prestimulus connectivity was dissociable from that of prestimulus activity amplitudes. In conclusion, moment to moment dynamic changes in baseline functional connectivity may shape subsequent behavioral performance. A highly modular network structure seems beneficial to perceptual efficiency.},
	language = {eng},
	number = {27},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sadaghiani, Sepideh and Poline, Jean-Baptiste and Kleinschmidt, Andreas and D'Esposito, Mark},
	month = jul,
	year = {2015},
	pmid = {26106164},
	pages = {8463--8468},
	file = {Attachment:/Users/tito/Zotero/storage/IT7QFD5R/Sadaghiani et al. - 2015 - Ongoing dynamics in large-scale functional connectivity predict perception.pdf:application/pdf},
}

@article{greicius_functional_2003,
	title = {Functional connectivity in the resting brain: a network analysis of the default mode hypothesis},
	volume = {100},
	issn = {0027-8424},
	doi = {10.1073/pnas.0135058100},
	abstract = {Functional imaging studies have shown that certain brain regions, including posterior cingulate cortex (PCC) and ventral anterior cingulate cortex (vACC), consistently show greater activity during resting states than during cognitive tasks. This finding led to the hypothesis that these regions constitute a network supporting a default mode of brain function. In this study, we investigate three questions pertaining to this hypothesis: Does such a resting-state network exist in the human brain? Is it modulated during simple sensory processing? How is it modulated during cognitive processing? To address these questions, we defined PCC and vACC regions that showed decreased activity during a cognitive (working memory) task, then examined their functional connectivity during rest. PCC was strongly coupled with vACC and several other brain regions implicated in the default mode network. Next, we examined the functional connectivity of PCC and vACC during a visual processing task and show that the resultant connectivity maps are virtually identical to those obtained during rest. Last, we defined three lateral prefrontal regions showing increased activity during the cognitive task and examined their resting-state connectivity. We report significant inverse correlations among all three lateral prefrontal regions and PCC, suggesting a mechanism for attenuation of default mode network activity during cognitive processing. This study constitutes, to our knowledge, the first resting-state connectivity analysis of the default mode and provides the most compelling evidence to date for the existence of a cohesive default mode network. Our findings also provide insight into how this network is modulated by task demands and what functions it might subserve.},
	language = {eng},
	number = {1},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Greicius, Michael D. and Krasnow, Ben and Reiss, Allan L. and Menon, Vinod},
	month = jan,
	year = {2003},
	pmid = {12506194},
	pages = {253--258},
}

@article{deshpande_effect_2010,
	title = {Effect of hemodynamic variability on {Granger} causality analysis of {fMRI}},
	volume = {52},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2009.11.060},
	language = {en},
	number = {3},
	journal = {NeuroImage},
	author = {Deshpande, Gopikrishna and Sathian, K. and Hu, Xiaoping},
	month = sep,
	year = {2010},
	pages = {884--896},
}

@article{siegel_spectral_2012,
	title = {Spectral fingerprints of large-scale neuronal interactions},
	issn = {1471-003X, 1471-0048},
	doi = {10.1038/nrn3137},
	journal = {Nature Reviews Neuroscience},
	author = {Siegel, Markus and Donner, Tobias H. and Engel, Andreas K.},
	month = jan,
	year = {2012},
	file = {Siegel et al. - 2012 - Spectral fingerprints of large-scale neuronal inte.pdf:/Users/tito/Downloads/Siegel et al. - 2012 - Spectral fingerprints of large-scale neuronal inte.pdf:application/pdf},
}

@book{craver_explaining_2007,
	address = {Oxford : New York : Oxford University Press},
	title = {Explaining the brain: mechanisms and the mosaic unity of neuroscience},
	isbn = {978-0-19-929931-7},
	publisher = {Clarendon Press},
	author = {Craver, Carl F.},
	year = {2007},
}

@article{roebroeck_mapping_2005,
	title = {Mapping directed influence over the brain using {Granger} causality and {fMRI}},
	volume = {25},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2004.11.017},
	abstract = {We propose Granger causality mapping (GCM) as an approach to explore directed influences between neuronal populations (effective connectivity) in fMRI data. The method does not rely on a priori specification of a model that contains pre-selected regions and connections between them. This distinguishes it from other fMRI effective connectivity approaches that aim at testing or contrasting specific hypotheses about neuronal interactions. Instead, GCM relies on the concept of Granger causality to define the existence and direction of influence from information in the data. Temporal precedence information is exploited to compute Granger causality maps that identify voxels that are sources or targets of directed influence for any selected region-of-interest. We investigated the method by simulations and by application to fMRI data of a complex visuomotor task. The presented exploratory approach of mapping influences between a region of interest and the rest of the brain can form a useful complement to existing models of effective connectivity.},
	language = {eng},
	number = {1},
	journal = {NeuroImage},
	author = {Roebroeck, Alard and Formisano, Elia and Goebel, Rainer},
	month = mar,
	year = {2005},
	pmid = {15734358},
	pages = {230--242},
}

@article{ramsey_multi-subject_2011,
	title = {Multi-subject search correctly identifies causal connections and most causal directions in the {DCM} models of the {Smith} et al. simulation study},
	volume = {58},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2011.06.068},
	language = {en},
	number = {3},
	journal = {NeuroImage},
	author = {Ramsey, Joseph D. and Hanson, Stephen José and Glymour, Clark},
	month = oct,
	year = {2011},
	pages = {838--848},
}

@article{schoffelen_source_2009,
	title = {Source connectivity analysis with {MEG} and {EEG}},
	volume = {30},
	issn = {10659471, 10970193},
	doi = {10.1002/hbm.20745},
	language = {en},
	number = {6},
	journal = {Human Brain Mapping},
	author = {Schoffelen, Jan-Mathijs and Gross, Joachim},
	month = jun,
	year = {2009},
	pages = {1857--1865},
}

@article{laird_networks_2013,
	title = {Networks of task co-activations},
	volume = {80},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2013.04.073},
	language = {en},
	journal = {NeuroImage},
	author = {Laird, Angela R. and Eickhoff, Simon B. and Rottschy, Claudia and Bzdok, Danilo and Ray, Kimberly L. and Fox, Peter T.},
	month = oct,
	year = {2013},
	pages = {505--514},
}

@article{allen_tracking_2014,
	title = {Tracking whole-brain connectivity dynamics in the resting state},
	volume = {24},
	issn = {1460-2199},
	doi = {10.1093/cercor/bhs352},
	abstract = {Spontaneous fluctuations are a hallmark of recordings of neural signals, emergent over time scales spanning milliseconds and tens of minutes. However, investigations of intrinsic brain organization based on resting-state functional magnetic resonance imaging have largely not taken into account the presence and potential of temporal variability, as most current approaches to examine functional connectivity (FC) implicitly assume that relationships are constant throughout the length of the recording. In this work, we describe an approach to assess whole-brain FC dynamics based on spatial independent component analysis, sliding time window correlation, and k-means clustering of windowed correlation matrices. The method is applied to resting-state data from a large sample (n = 405) of young adults. Our analysis of FC variability highlights particularly flexible connections between regions in lateral parietal and cingulate cortex, and argues against a labeling scheme where such regions are treated as separate and antagonistic entities. Additionally, clustering analysis reveals unanticipated FC states that in part diverge strongly from stationary connectivity patterns and challenge current descriptions of interactions between large-scale networks. Temporal trends in the occurrence of different FC states motivate theories regarding their functional roles and relationships with vigilance/arousal. Overall, we suggest that the study of time-varying aspects of FC can unveil flexibility in the functional coordination between different neural systems, and that the exploitation of these dynamics in further investigations may improve our understanding of behavioral shifts and adaptive processes.},
	language = {eng},
	number = {3},
	journal = {Cerebral Cortex (New York, N.Y.: 1991)},
	author = {Allen, Elena A. and Damaraju, Eswar and Plis, Sergey M. and Erhardt, Erik B. and Eichele, Tom and Calhoun, Vince D.},
	month = mar,
	year = {2014},
	pmid = {23146964},
	pages = {663--676},
}

@article{woolrich_biophysical_2013,
	title = {Biophysical network models and the human connectome},
	volume = {80},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2013.03.059},
	language = {en},
	journal = {NeuroImage},
	author = {Woolrich, Mark W. and Stephan, Klaas E.},
	month = oct,
	year = {2013},
	pages = {330--338},
}

@article{wen_causal_2012,
	title = {Causal {Interactions} in {Attention} {Networks} {Predict} {Behavioral} {Performance}},
	volume = {32},
	issn = {0270-6474, 1529-2401},
	doi = {10.1523/JNEUROSCI.2817-11.2012},
	language = {en},
	number = {4},
	journal = {Journal of Neuroscience},
	author = {Wen, X. and Yao, L. and Liu, Y. and Ding, M.},
	month = jan,
	year = {2012},
	pages = {1284--1292},
}

@article{friston_dynamic_2003,
	title = {Dynamic causal modelling},
	volume = {19},
	issn = {10538119},
	doi = {10.1016/S1053-8119(03)00202-7},
	language = {en},
	number = {4},
	journal = {NeuroImage},
	author = {Friston, K.J. and Harrison, L. and Penny, W.},
	month = aug,
	year = {2003},
	pages = {1273--1302},
	file = {Attachment:/Users/tito/Zotero/storage/NEBXM2CK/Friston, Harrison, Penny - 2003 - Dynamic causal modelling.pdf:application/pdf},
}

@article{goni_resting-brain_2014,
	title = {Resting-brain functional connectivity predicted by analytic measures of network communication},
	volume = {111},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1315529111},
	language = {en},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Goni, J. and van den Heuvel, M. P. and Avena-Koenigsberger, A. and Velez de Mendizabal, N. and Betzel, R. F. and Griffa, A. and Hagmann, P. and Corominas-Murtra, B. and Thiran, J.-P. and Sporns, O.},
	month = jan,
	year = {2014},
	pages = {833--838},
}

@article{smith_correspondence_2009,
	title = {Correspondence of the brain's functional architecture during activation and rest},
	volume = {106},
	issn = {1091-6490},
	doi = {10.1073/pnas.0905267106},
	abstract = {Neural connections, providing the substrate for functional networks, exist whether or not they are functionally active at any given moment. However, it is not known to what extent brain regions are continuously interacting when the brain is "at rest." In this work, we identify the major explicit activation networks by carrying out an image-based activation network analysis of thousands of separate activation maps derived from the BrainMap database of functional imaging studies, involving nearly 30,000 human subjects. Independently, we extract the major covarying networks in the resting brain, as imaged with functional magnetic resonance imaging in 36 subjects at rest. The sets of major brain networks, and their decompositions into subnetworks, show close correspondence between the independent analyses of resting and activation brain dynamics. We conclude that the full repertoire of functional networks utilized by the brain in action is continuously and dynamically "active" even when at "rest."},
	language = {eng},
	number = {31},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Smith, Stephen M. and Fox, Peter T. and Miller, Karla L. and Glahn, David C. and Fox, P. Mickle and Mackay, Clare E. and Filippini, Nicola and Watkins, Kate E. and Toro, Roberto and Laird, Angela R. and Beckmann, Christian F.},
	month = aug,
	year = {2009},
	pmid = {19620724},
	pages = {13040--13045},
	file = {Attachment:/Users/tito/Zotero/storage/Q5UW9XAC/Smith et al. - 2009 - Correspondence of the brain's functional architecture during activation and rest.pdf:application/pdf},
}

@article{mitra_lag_2015,
	title = {Lag threads organize the brain's intrinsic activity},
	volume = {112},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1503960112},
	language = {en},
	number = {17},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Mitra, Anish and Snyder, Abraham Z. and Blazey, Tyler and Raichle, Marcus E.},
	month = apr,
	year = {2015},
	pages = {E2235--E2244},
}

@article{de_pasquale_temporal_2010,
	title = {Temporal dynamics of spontaneous {MEG} activity in brain networks},
	volume = {107},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.0913863107},
	language = {en},
	number = {13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {de Pasquale, F. and Della Penna, S. and Snyder, A. Z. and Lewis, C. and Mantini, D. and Marzetti, L. and Belardinelli, P. and Ciancetta, L. and Pizzella, V. and Romani, G. L. and Corbetta, M.},
	month = mar,
	year = {2010},
	pages = {6040--6045},
}

@article{dobrunz_heterogeneity_1997,
	title = {Heterogeneity of release probability, facilitation, and depletion at central synapses},
	volume = {18},
	issn = {0896-6273},
	abstract = {Previous studies of short-term plasticity in central nervous systems synapses have largely focused on average synaptic properties. In this study, we use recordings from putative single synaptic release sites in hippocampal slices to show that significant heterogeneity exists in facilitation and depletion among synapses. In particular, the amount of paired-pulse facilitation is inversely related to the initial release probability of the synapse. We also examined depletion at individual synapses using high frequency stimulation, and estimated the size of the readily releasable vesicle pool, which averaged 5.0 +/- 3.0 quanta (n = 13 synapses). In addition, these experiments demonstrate that the release probability at a synapse is directly correlated with the size of its readily releasable vesicle pool.},
	language = {eng},
	number = {6},
	journal = {Neuron},
	author = {Dobrunz, L. E. and Stevens, C. F.},
	month = jun,
	year = {1997},
	pmid = {9208866},
	pages = {995--1008},
}

@article{gjorgjieva_intrinsic_2014,
	title = {Intrinsic {Neuronal} {Properties} {Switch} the {Mode} of {Information} {Transmission} in {Networks}},
	volume = {10},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1003962},
	language = {en},
	number = {12},
	journal = {PLoS Computational Biology},
	author = {Gjorgjieva, Julijana and Mease, Rebecca A. and Moody, William J. and Fairhall, Adrienne L.},
	editor = {Einhäuser, Wolfgang},
	month = dec,
	year = {2014},
	pages = {e1003962},
}

@article{zheng_directionality_2011,
	title = {Directionality index of neural information flow as a measure of synaptic plasticity in chronic unpredictable stress rats},
	volume = {490},
	issn = {03043940},
	doi = {10.1016/j.neulet.2010.12.024},
	language = {en},
	number = {1},
	journal = {Neuroscience Letters},
	author = {Zheng, Chenguang and Quan, Meina and Yang, Zhuo and Zhang, Tao},
	month = feb,
	year = {2011},
	pages = {52--56},
}

@article{markov_weight_2011,
	title = {Weight {Consistency} {Specifies} {Regularities} of {Macaque} {Cortical} {Networks}},
	volume = {21},
	issn = {1047-3211, 1460-2199},
	doi = {10.1093/cercor/bhq201},
	language = {en},
	number = {6},
	journal = {Cerebral Cortex},
	author = {Markov, N. T. and Misery, P. and Falchier, A. and Lamy, C. and Vezoli, J. and Quilodran, R. and Gariel, M. A. and Giroud, P. and Ercsey-Ravasz, M. and Pilaz, L. J. and Huissoud, C. and Barone, P. and Dehay, C. and Toroczkai, Z. and Van Essen, D. C. and Kennedy, H. and Knoblauch, K.},
	month = jun,
	year = {2011},
	pages = {1254--1272},
}

@article{feinberg_multiplexed_2010,
	title = {Multiplexed {Echo} {Planar} {Imaging} for {Sub}-{Second} {Whole} {Brain} {FMRI} and {Fast} {Diffusion} {Imaging}},
	volume = {5},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0015710},
	language = {en},
	number = {12},
	journal = {PLoS ONE},
	author = {Feinberg, David A. and Moeller, Steen and Smith, Stephen M. and Auerbach, Edward and Ramanna, Sudhir and Glasser, Matt F. and Miller, Karla L. and Ugurbil, Kamil and Yacoub, Essa},
	editor = {Valdes-Sosa, Pedro Antonio},
	month = dec,
	year = {2010},
	pages = {e15710},
}

@article{soon_unconscious_2008,
	title = {Unconscious determinants of free decisions in the human brain},
	volume = {11},
	issn = {1097-6256},
	doi = {10.1038/nn.2112},
	number = {5},
	journal = {Nature Neuroscience},
	author = {Soon, Chun Siong and Brass, Marcel and Heinze, Hans-Jochen and Haynes, John-Dylan},
	month = may,
	year = {2008},
	pages = {543--545},
}

@article{laughlin_communication_2003,
	title = {Communication in neuronal networks},
	volume = {301},
	issn = {1095-9203},
	doi = {10.1126/science.1089662},
	abstract = {Brains perform with remarkable efficiency, are capable of prodigious computation, and are marvels of communication. We are beginning to understand some of the geometric, biophysical, and energy constraints that have governed the evolution of cortical networks. To operate efficiently within these constraints, nature has optimized the structure and function of cortical networks with design principles similar to those used in electronic networks. The brain also exploits the adaptability of biological systems to reconfigure in response to changing needs.},
	language = {eng},
	number = {5641},
	journal = {Science (New York, N.Y.)},
	author = {Laughlin, Simon B. and Sejnowski, Terrence J.},
	month = sep,
	year = {2003},
	pmid = {14512617},
	pages = {1870--1874},
	file = {Attachment:/Users/tito/Zotero/storage/PUGQ66R8/Laughlin, Sejnowski - 2003 - Communication in neuronal networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/DMV9TVUG/Laughlin, Sejnowski - 2003 - Communication in neuronal networks.pdf:application/pdf},
}

@article{mill_differentiating_2015,
	title = {Differentiating the functional contributions of resting connectivity networks to memory decision-making: {fMRI} support for multistage control processes},
	volume = {27},
	issn = {1530-8898},
	doi = {10.1162/jocn_a_00808},
	abstract = {Neural substrates of memory control are engaged when participants encounter unexpected mnemonic stimuli (e.g., a new word when told to expect an old word). The present fMRI study (n = 18) employed the likelihood cueing recognition task to elucidate the role of functional connectivity (fcMRI) networks in supporting memory control processes engaged by these unexpected events. Conventional task-evoked BOLD analyses recovered a memory control network similar to that previously reported, comprising medial prefrontal, lateral prefrontal, and inferior parietal regions. These were split by their differential affiliation to distinct fcMRI networks ("conflict detection" and "confirmatory retrieval" networks). Subsequent ROI analyses clarified the functional significance of this connectivity differentiation, with "conflict" network-affiliated regions specifically sensitive to cue strength, but not to response confidence, and "retrieval" network-affiliated regions showing the opposite pattern. BOLD time course analyses corroborated the segregation of memory control regions into "early" conflict detection and "late" retrieval analysis, with both processes underlying the allocation of memory control. Response specificity and time course findings were generalized beyond task-recruited ROIs to clusters within the large-scale fcMRI networks, suggesting that this connectivity architecture could underlie efficient processing of distinct processes within cognitive tasks. The findings raise important parallels between prevailing theories of memory and cognitive control.},
	language = {eng},
	number = {8},
	journal = {Journal of Cognitive Neuroscience},
	author = {Mill, Ravi D. and Cavin, Ian and O'Connor, Akira R.},
	month = aug,
	year = {2015},
	pmid = {25803597},
	pages = {1617--1632},
}

@article{bassett_dynamic_2011,
	title = {Dynamic reconfiguration of human brain networks during learning},
	volume = {108},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1018985108},
	language = {en},
	number = {18},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bassett, D. S. and Wymbs, N. F. and Porter, M. A. and Mucha, P. J. and Carlson, J. M. and Grafton, S. T.},
	month = may,
	year = {2011},
	pages = {7641--7646},
	file = {Attachment:/Users/tito/Zotero/storage/WBALRGAD/Bassett et al. - 2011 - Dynamic reconfiguration of human brain networks during learning.pdf:application/pdf},
}

@article{sejnowski_book_1999,
	title = {The {Book} of {Hebb}},
	volume = {24},
	issn = {08966273},
	doi = {10.1016/S0896-6273(00)81025-9},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Sejnowski, Terrence J},
	month = dec,
	year = {1999},
	pages = {773--776},
}

@article{raichle_two_2010,
	title = {Two views of brain function},
	volume = {14},
	issn = {13646613},
	doi = {10.1016/j.tics.2010.01.008},
	language = {en},
	number = {4},
	journal = {Trends in Cognitive Sciences},
	author = {Raichle, Marcus E.},
	month = apr,
	year = {2010},
	pages = {180--190},
}

@article{bassett_learning-induced_2015,
	title = {Learning-induced autonomy of sensorimotor systems},
	volume = {18},
	issn = {1097-6256, 1546-1726},
	doi = {10.1038/nn.3993},
	number = {5},
	journal = {Nature Neuroscience},
	author = {Bassett, Danielle S and Yang, Muzhi and Wymbs, Nicholas F and Grafton, Scott T},
	month = apr,
	year = {2015},
	pages = {744--751},
	file = {Attachment:/Users/tito/Zotero/storage/6Y3WKFUE/Bassett et al. - 2015 - Learning-induced autonomy of sensorimotor systems.pdf:application/pdf},
}

@article{lewis_learning_2009,
	title = {Learning sculpts the spontaneous activity of the resting human brain},
	volume = {106},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.0902455106},
	language = {en},
	number = {41},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Lewis, C. M. and Baldassarre, A. and Committeri, G. and Romani, G. L. and Corbetta, M.},
	month = oct,
	year = {2009},
	pages = {17558--17563},
}

@article{van_veen_localization_1997,
	title = {Localization of brain electrical activity via linearly constrained minimum variance spatial filtering},
	volume = {44},
	issn = {00189294},
	doi = {10.1109/10.623056},
	number = {9},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Van Veen, B.D. and Van Drongelen, W. and Yuchtman, M. and Suzuki, A.},
	month = sep,
	year = {1997},
	pages = {867--880},
}

@article{wheeler_evidence_2006,
	title = {Evidence for separate perceptual reactivation and search processes during remembering},
	volume = {16},
	issn = {1047-3211},
	doi = {10.1093/cercor/bhj037},
	abstract = {Remembering involves the coordinated recruitment of strategic search processes and processes involved in reconstructing the content of the past experience. In the present study we used a cueing paradigm based on event-related functional magnetic resonance imaging to separate activity in the initial preparation phases of retrieval from later phases during which retrieval search ensued, and detailed auditory and visual memories were reconstructed. Results suggest a dissociation among inferior temporal (IT) and parieto-occipital (PO) processing regions in how they were influenced by preparatory cues prior to remembering, and indicate a dissociation in how they were influenced by the subsequent validity of those cues during remembering. Regions in IT cortex appeared to show search-related activity during retrieval, as well as robust modality effects, but they were not influenced by preparatory cues. These findings suggest a specific role for IT regions in reconstruction of visual details during remembering. While dorsal regions in parietal and superior occipital cortex also appeared to show search-related activity as well as robust modality effects, they were also influenced by preparatory cues during the retrieval phase, and to a lesser degree during the cue phase. These findings indicate a role in integrating perceptual reactivation and search processes during remembering.},
	language = {eng},
	number = {7},
	journal = {Cerebral Cortex (New York, N.Y.: 1991)},
	author = {Wheeler, Mark E. and Shulman, Gordon L. and Buckner, Randy L. and Miezin, Francis M. and Velanova, Katerina and Petersen, Steven E.},
	month = jul,
	year = {2006},
	pmid = {16162854},
	pages = {949--959},
}

@article{liu_time-varying_2013,
	title = {Time-varying functional network information extracted from brief instances of spontaneous brain activity},
	volume = {110},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1216856110},
	language = {en},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Liu, X. and Duyn, J. H.},
	month = mar,
	year = {2013},
	pages = {4392--4397},
	file = {Attachment:/Users/tito/Zotero/storage/2U2GAXFY/Liu, Duyn - 2013 - Time-varying functional network information extracted from brief instances of spontaneous brain activity.pdf:application/pdf},
}

@article{montijn_population-level_2016,
	title = {Population-{Level} {Neural} {Codes} {Are} {Robust} to {Single}-{Neuron} {Variability} from a {Multidimensional} {Coding} {Perspective}},
	volume = {16},
	issn = {22111247},
	doi = {10.1016/j.celrep.2016.07.065},
	language = {en},
	number = {9},
	journal = {Cell Reports},
	author = {Montijn, Jorrit S. and Meijer, Guido T. and Lansink, Carien S. and Pennartz, Cyriel M.A.},
	month = aug,
	year = {2016},
	pages = {2486--2498},
}

@article{kanwisher_functional_2010,
	title = {Functional specificity in the human brain: {A} window into the functional architecture of the mind},
	volume = {107},
	issn = {0027-8424},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1005062107},
	doi = {10.1073/pnas.1005062107},
	abstract = {Is the human mind/brain composed of a set of highly specialized components, each carrying out a specific aspect of human cognition, or is it more of a general-purpose device, in which each component participates in a wide variety of cognitive processes? For nearly two centuries, proponents of specialized organs or modules of the mind and brain–from the phrenologists to Broca to Chomsky and Fodor–have jousted with the proponents of distributed cognitive and neural processing–from Flourens to Lashley to McClelland and Rumelhart. I argue here that research using functional MRI is beginning to answer this long-standing question with new clarity and precision by indicating that at least a few specific aspects of cognition are implemented in brain regions that are highly specialized for that process alone. Cortical regions have been identified that are specialized not only for basic sensory and motor processes but also for the high-level perceptual analysis of faces, places, bodies, visually presented words, and even for the very abstract cognitive function of thinking about another person's thoughts. I further consider the as-yet unanswered questions of how much of the mind and brain are made up of these functionally specialized components and how they arise developmentally.},
	language = {en},
	number = {25},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kanwisher, Nancy},
	month = jun,
	year = {2010},
	pmid = {20484679},
	pages = {11163--11170},
	file = {Attachment:/Users/tito/Zotero/storage/JCP4NMAJ/Kanwisher - 2010 - Functional specificity in the human brain A window into the functional architecture of the mind.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/3BE4K2BG/Kanwisher - 2010 - Functional specificity in the human brain A window into the functional architecture of the mind.pdf:application/pdf},
}

@article{hutchison_resting-state_2013,
	title = {Resting-state networks show dynamic functional connectivity in awake humans and anesthetized macaques: {Dynamic} {Functional} {Connectivity}},
	volume = {34},
	issn = {10659471},
	doi = {10.1002/hbm.22058},
	language = {en},
	number = {9},
	journal = {Human Brain Mapping},
	author = {Hutchison, R. Matthew and Womelsdorf, Thilo and Gati, Joseph S. and Everling, Stefan and Menon, Ravi S.},
	month = sep,
	year = {2013},
	pages = {2154--2177},
}

@article{cordes_mapping_2000,
	title = {Mapping functionally related regions of brain with functional connectivity {MR} imaging},
	volume = {21},
	issn = {0195-6108},
	abstract = {BACKGROUND AND PURPOSE: In subjects who are performing no prescribed cognitive task, functional connectivity mapped with MR imaging (fcMRI) shows regions with synchronous fluctuations of cerebral blood flow. When specific tasks are performed, functional MR imaging (fMRI) can map locations in which regional cerebral blood flow increases synchronously with the performance of the task. We tested the hypothesis that fcMRI maps, based on the synchrony of low-frequency blood flow fluctuations, identify brain regions that show activation on fMRI maps of sensorimotor, visual, language, and auditory tasks. METHODS: In four volunteers, task-activation fMRI and functional connectivity (resting-state) fcMRI data were acquired. A small region of interest (in an area that showed maximal task activation) was chosen, and the correlation coefficient of the corresponding resting-state signal with the signal of all other voxels in the resting data set was calculated. The correlation coefficient was decomposed into frequency components and its distribution determined for each fcMRI map. The fcMRI maps were compared with the fMRI maps. RESULTS: For each task, fcMRI maps based on one to four seed voxel(s) produced clusters of voxels in regions of eloquent cortex. For each fMRI map a closely corresponding fcMRI map was obtained. The frequencies that predominated in the cross-correlation coefficients for the functionally related regions were below 0.1 Hz. CONCLUSION: Functionally related brain regions can be identified by means of their synchronous slow fluctuations in signal intensity. Such blood flow synchrony can be detected in sensorimotor areas, expressive and receptive language regions, and the visual cortex by fcMRI. Regions identified by the slow synchronous fluctuations are similar to those activated by motor, language, or visual tasks.},
	language = {eng},
	number = {9},
	journal = {AJNR. American journal of neuroradiology},
	author = {Cordes, D. and Haughton, V. M. and Arfanakis, K. and Wendt, G. J. and Turski, P. A. and Moritz, C. H. and Quigley, M. A. and Meyerand, M. E.},
	month = oct,
	year = {2000},
	pmid = {11039342},
	pages = {1636--1644},
}

@article{smith_temporally-independent_2012,
	title = {Temporally-independent functional modes of spontaneous brain activity},
	volume = {109},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1121329109},
	language = {en},
	number = {8},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Smith, S. M. and Miller, K. L. and Moeller, S. and Xu, J. and Auerbach, E. J. and Woolrich, M. W. and Beckmann, C. F. and Jenkinson, M. and Andersson, J. and Glasser, M. F. and Van Essen, D. C. and Feinberg, D. A. and Yacoub, E. S. and Ugurbil, K.},
	month = feb,
	year = {2012},
	pages = {3131--3136},
}

@article{fox_human_2005,
	title = {The human brain is intrinsically organized into dynamic, anticorrelated functional networks},
	volume = {102},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.0504136102},
	language = {en},
	number = {27},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fox, M. D. and Snyder, A. Z. and Vincent, J. L. and Corbetta, M. and Van Essen, D. C. and Raichle, M. E.},
	month = jul,
	year = {2005},
	pages = {9673--9678},
	file = {Attachment:/Users/tito/Zotero/storage/YXMEIF5V/Fox et al. - 2005 - The human brain is intrinsically organized into dynamic, anticorrelated functional networks.pdf:application/pdf},
}

@article{nolte_identifying_2004,
	title = {Identifying true brain interaction from {EEG} data using the imaginary part of coherency},
	volume = {115},
	issn = {1388-2457},
	doi = {10.1016/j.clinph.2004.04.029},
	abstract = {OBJECTIVE: The main obstacle in interpreting EEG/MEG data in terms of brain connectivity is the fact that because of volume conduction, the activity of a single brain source can be observed in many channels. Here, we present an approach which is insensitive to false connectivity arising from volume conduction. METHODS: We show that the (complex) coherency of non-interacting sources is necessarily real and, hence, the imaginary part of coherency provides an excellent candidate to study brain interactions. Although the usual magnitude and phase of coherency contain the same information as the real and imaginary parts, we argue that the Cartesian representation is far superior for studying brain interactions. The method is demonstrated for EEG measurements of voluntary finger movement. RESULTS: We found: (a) from 5 s before to movement onset a relatively weak interaction around 20 Hz between left and right motor areas where the contralateral side leads the ipsilateral side; and (b) approximately 2-4 s after movement, a stronger interaction also at 20 Hz in the opposite direction. CONCLUSIONS: It is possible to reliably detect brain interaction during movement from EEG data. SIGNIFICANCE: The method allows unambiguous detection of brain interaction from rhythmic EEG/MEG data.},
	language = {eng},
	number = {10},
	journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	author = {Nolte, Guido and Bai, Ou and Wheaton, Lewis and Mari, Zoltan and Vorbach, Sherry and Hallett, Mark},
	month = oct,
	year = {2004},
	pmid = {15351371},
	pages = {2292--2307},
}

@article{biswal_functional_1995,
	title = {Functional connectivity in the motor cortex of resting human brain using echo-planar {MRI}},
	volume = {34},
	issn = {0740-3194},
	abstract = {An MRI time course of 512 echo-planar images (EPI) in resting human brain obtained every 250 ms reveals fluctuations in signal intensity in each pixel that have a physiologic origin. Regions of the sensorimotor cortex that were activated secondary to hand movement were identified using functional MRI methodology (FMRI). Time courses of low frequency ({\textbackslash}textless 0.1 Hz) fluctuations in resting brain were observed to have a high degree of temporal correlation (P {\textbackslash}textless 10(-3)) within these regions and also with time courses in several other regions that can be associated with motor function. It is concluded that correlation of low frequency fluctuations, which may arise from fluctuations in blood oxygenation or flow, is a manifestation of functional connectivity of the brain.},
	language = {eng},
	number = {4},
	journal = {Magnetic Resonance in Medicine},
	author = {Biswal, B. and Yetkin, F. Z. and Haughton, V. M. and Hyde, J. S.},
	month = oct,
	year = {1995},
	pmid = {8524021},
	pages = {537--541},
}

@article{krienen_reconfigurable_2014,
	title = {Reconfigurable task-dependent functional coupling modes cluster around a core functional architecture},
	volume = {369},
	issn = {0962-8436, 1471-2970},
	doi = {10.1098/rstb.2013.0526},
	language = {en},
	number = {1653},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Krienen, F. M. and Yeo, B. T. T. and Buckner, R. L.},
	month = sep,
	year = {2014},
	pages = {20130526--20130526},
}

@article{mennes_extrinsic_2013,
	title = {The {Extrinsic} and {Intrinsic} {Functional} {Architectures} of the {Human} {Brain} {Are} {Not} {Equivalent}},
	volume = {23},
	issn = {1047-3211, 1460-2199},
	doi = {10.1093/cercor/bhs010},
	language = {en},
	number = {1},
	journal = {Cerebral Cortex},
	author = {Mennes, M. and Kelly, C. and Colcombe, S. and Castellanos, F. X. and Milham, M. P.},
	month = jan,
	year = {2013},
	pages = {223--229},
}

@article{thompson_short-time_2013,
	title = {Short-time windows of correlation between large-scale functional brain networks predict vigilance intraindividually and interindividually: {Short}-{Time} {Window} {Activity} {Predicts} {Vigilance}},
	volume = {34},
	issn = {10659471},
	doi = {10.1002/hbm.22140},
	language = {en},
	number = {12},
	journal = {Human Brain Mapping},
	author = {Thompson, Garth John and Magnuson, Matthew Evan and Merritt, Michael Donelyn and Schwarb, Hillary and Pan, Wen-Ju and McKinley, Andrew and Tripp, Lloyd D. and Schumacher, Eric H. and Keilholz, Shella Dawn},
	month = dec,
	year = {2013},
	pages = {3280--3298},
}

@article{yeo_organization_2011,
	title = {The organization of the human cerebral cortex estimated by intrinsic functional connectivity},
	volume = {106},
	issn = {0022-3077, 1522-1598},
	doi = {10.1152/jn.00338.2011},
	language = {en},
	number = {3},
	journal = {Journal of Neurophysiology},
	author = {Yeo, B. T. and Krienen, F. M. and Sepulcre, J. and Sabuncu, M. R. and Lashkari, D. and Hollinshead, M. and Roffman, J. L. and Smoller, J. W. and Zollei, L. and Polimeni, J. R. and Fischl, B. and Liu, H. and Buckner, R. L.},
	month = sep,
	year = {2011},
	pages = {1125--1165},
	file = {Attachment:/Users/tito/Zotero/storage/26CA5TRN/Yeo et al. - 2011 - The organization of the human cerebral cortex estimated by intrinsic functional connectivity.pdf:application/pdf},
}

@article{baker_fast_2014,
	title = {Fast transient networks in spontaneous human brain activity},
	volume = {3},
	issn = {2050-084X},
	doi = {10.7554/eLife.01867},
	language = {en},
	journal = {eLife},
	author = {Baker, Adam P and Brookes, Matthew J and Rezek, Iead A and Smith, Stephen M and Behrens, Timothy and Probert Smith, Penny J and Woolrich, Mark},
	month = mar,
	year = {2014},
}

@article{kriegeskorte_information-based_2006,
	title = {Information-based functional brain mapping},
	volume = {103},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.0600244103},
	language = {en},
	number = {10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kriegeskorte, N. and Goebel, R. and Bandettini, P.},
	month = mar,
	year = {2006},
	pages = {3863--3868},
}

@article{borst_tracking_2016,
	title = {Tracking cognitive processing stages with {MEG}: {A} spatio-temporal model of associative recognition in the brain},
	volume = {141},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2016.08.002},
	language = {en},
	journal = {NeuroImage},
	author = {Borst, Jelmer P. and Ghuman, Avniel S. and Anderson, John R.},
	month = nov,
	year = {2016},
	pages = {416--430},
}

@article{wang_systematic_2014,
	title = {A systematic framework for functional connectivity measures},
	volume = {8},
	issn = {1662-453X},
	doi = {10.3389/fnins.2014.00405},
	journal = {Frontiers in Neuroscience},
	author = {Wang, Huifang E. and BÃ©nar, Christian G. and Quilichini, Pascale P. and Friston, Karl J. and Jirsa, Viktor K. and Bernard, Christophe},
	month = dec,
	year = {2014},
}

@article{spira_multi-electrode_2013,
	title = {Multi-electrode array technologies for neuroscience and cardiology},
	volume = {8},
	issn = {1748-3387, 1748-3395},
	doi = {10.1038/nnano.2012.265},
	number = {2},
	journal = {Nature Nanotechnology},
	author = {Spira, Micha E. and Hai, Aviad},
	month = feb,
	year = {2013},
	pages = {83--94},
}

@article{friston_statistical_1994,
	title = {Statistical parametric maps in functional imaging: {A} general linear approach},
	volume = {2},
	issn = {10659471},
	doi = {10.1002/hbm.460020402},
	language = {en},
	number = {4},
	journal = {Human Brain Mapping},
	author = {Friston, K. J. and Holmes, A. P. and Worsley, K. J. and Poline, J.-P. and Frith, C. D. and Frackowiak, R. S. J.},
	year = {1994},
	pages = {189--210},
}

@article{mill_pupil_2016,
	title = {Pupil dilation during recognition memory: {Isolating} unexpected recognition from judgment uncertainty},
	volume = {154},
	issn = {00100277},
	doi = {10.1016/j.cognition.2016.05.018},
	language = {en},
	journal = {Cognition},
	author = {Mill, Ravi D. and O'Connor, Akira R. and Dobbins, Ian G.},
	month = sep,
	year = {2016},
	pages = {81--94},
}

@article{vaadia_dynamics_1995,
	title = {Dynamics of neuronal interactions in monkey cortex in relation to behavioural events},
	volume = {373},
	issn = {0028-0836},
	doi = {10.1038/373515a0},
	number = {6514},
	journal = {Nature},
	author = {Vaadia, E. and Haalman, I. and Abeles, M. and Bergman, H. and Prut, Y. and Slovin, H. and Aertsen, A.},
	month = feb,
	year = {1995},
	pages = {515--518},
}

@article{wen_top-down_2013,
	title = {Top-{Down} {Regulation} of {Default} {Mode} {Activity} in {Spatial} {Visual} {Attention}},
	volume = {33},
	issn = {0270-6474, 1529-2401},
	doi = {10.1523/JNEUROSCI.4939-12.2013},
	language = {en},
	number = {15},
	journal = {Journal of Neuroscience},
	author = {Wen, X. and Liu, Y. and Yao, L. and Ding, M.},
	month = apr,
	year = {2013},
	pages = {6444--6453},
}

@article{huth_continuous_2012,
	title = {A {Continuous} {Semantic} {Space} {Describes} the {Representation} of {Thousands} of {Object} and {Action} {Categories} across the {Human} {Brain}},
	volume = {76},
	issn = {08966273},
	doi = {10.1016/j.neuron.2012.10.014},
	abstract = {Humans can see and name thousands of distinct object and action categories, so it is unlikely that each category is represented in a distinct brain area. A more efficient scheme would be to represent categories as locations in a continuous semantic space mapped smoothly across the cortical surface. To search for such a space, we used fMRI to measure human brain activity evoked by natural movies. We then used voxelwise models to examine the cortical representation of 1,705 object and action categories. The first few dimensions of the underlying semantic space were recovered from the fit models by principal components analysis. Projection of the recovered semantic space onto cortical flat maps shows that semantic selectivity is organized into smooth gradients that cover much of visual and nonvisual cortex. Furthermore, both the recovered semantic space and the cortical organization of the space are shared across different individuals.},
	number = {6},
	journal = {Neuron},
	author = {Huth, Alexander G. and Nishimoto, Shinji and Vu, An T. and Gallant, Jack L.},
	year = {2012},
	pmid = {23259955},
	pages = {1210--1224},
	file = {Attachment:/Users/tito/Zotero/storage/QCQ6A8DQ/Huth et al. - 2012 - A Continuous Semantic Space Describes the Representation of Thousands of Object and Action Categories across the(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/BJMKC4ZA/Huth et al. - 2012 - A Continuous Semantic Space Describes the Representation of Thousands of Object and Action Categories across the Hu.pdf:application/pdf},
}

@article{gallant_system_2010,
	title = {System identification, encoding models, and decoding models, a powerful new approach to {fMRI} research},
	abstract = {... it has provided critical information about the homology\${\textbackslash}backslash\$nbetween the visual systems of humans ... Gourtzelidis and\${\textbackslash}backslash\$ncolleagues used this encoding model to identify a spatially ...\${\textbackslash}backslash\$nSystem Identification , Encoding Models , and Decoding Models\${\textbackslash}backslash\$n179 classifier differs from the voxel-based ...},
	journal = {Understanding visual population codes},
	author = {Gallant, Jack and Nishimoto, Shinji and Naslaris, Thomas and Wu, Michael C K},
	year = {2010},
	pages = {1--26},
	file = {Attachment:/Users/tito/Zotero/storage/GP7BF4WZ/Gallant et al. - 2010 - System identification, encoding models, and decoding models, a powerful new approach to fMRI research.pdf:application/pdf},
}

@article{yeo_organization_2011-1,
	title = {The organization of the human cerebral cortex estimated by intrinsic functional connectivity},
	volume = {106},
	issn = {1522-1598},
	url = {http://jn.physiology.org/content/106/3/1125.short},
	doi = {10.1152/jn.00338.2011.},
	abstract = {Information processing in the cerebral cortex involves interactions among distributed areas. Anatomical connectivity suggests that certain areas form local hierarchical relations such as within the visual system. Other connectivity patterns, particularly among association areas, suggest the presence of large-scale circuits without clear hierarchical relations. In this study the organization of networks in the human cerebrum was explored using resting-state functional connectivity MRI. Data from 1,000 subjects were registered using surface-based alignment. A clustering approach was employed to identify and replicate networks of functionally coupled regions across the cerebral cortex. The results revealed local networks confined to sensory and motor cortices as well as distributed networks of association regions. Within the sensory and motor cortices, functional connectivity followed topographic representations across adjacent areas. In association cortex, the connectivity patterns often showed abrupt transitions between network boundaries. Focused analyses were performed to better understand properties of network connectivity. A canonical sensory-motor pathway involving primary visual area, putative middle temporal area complex (MT+), lateral intraparietal area, and frontal eye field was analyzed to explore how interactions might arise within and between networks. Results showed that adjacent regions of the MT+ complex demonstrate differential connectivity consistent with a hierarchical pathway that spans networks. The functional connectivity of parietal and prefrontal association cortices was next explored. Distinct connectivity profiles of neighboring regions suggest they participate in distributed networks that, while showing evidence for interactions, are embedded within largely parallel, interdigitated circuits. We conclude by discussing the organization of these large-scale cerebral networks in relation to monkey anatomy and their potential evolutionary expansion in humans to support cognition.},
	journal = {Journal of neurophysiology},
	author = {Yeo, B.T. Thomas and Krienen, Fenna M. and Sepulcre, Jorge and Sabuncu, Mert R. and Lashkari, D. and Hollinshead, Marisa and Roffman, Joshua L. and Smoller, Jordan W. and Zollei, Lilla and Polimeni, Jonathan R. and Fischl, Bruce and Liu, Hesheng and Buckner, Randy L.},
	year = {2011},
	pmid = {21653723},
	pages = {1125--1165},
	file = {Attachment:/Users/tito/Zotero/storage/PZMUN7QW/Yeo et al. - 2011 - The organization of the human cerebral cortex estimated by intrinsic functional connectivity.pdf:application/pdf},
}

@article{valencia_dynamic_2013,
	title = {Dynamic {Interaction} of {Spindles} and {Gamma} {Activity} during {Cortical} {Slow} {Oscillations} and {Its} {Modulation} by {Subcortical} {Afferents}},
	volume = {8},
	issn = {19326203},
	doi = {10.1371/journal.pone.0067540},
	abstract = {Slow oscillations are a hallmark of slow wave sleep. They provide a temporal framework for a variety of phasic events to occur and interact during sleep, including the expression of high-frequency oscillations and the discharge of neurons across the entire brain. Evidence shows that the emergence of distinct high-frequency oscillations during slow oscillations facilitates the communication among brain regions whose activity was correlated during the preceding waking period. While the frequencies of oscillations involved in such interactions have been identified, their dynamics and the correlations between them require further investigation. Here we analyzed the structure and dynamics of these signals in anesthetized rats. We show that spindles and gamma oscillations coexist but have distinct temporal dynamics across the slow oscillation cycle. Furthermore, we observed that spindles and gamma are functionally coupled to the slow oscillations and between each other. Following the activation of ascending pathways from the brainstem by means of a carbachol injection in the pedunculopontine nucleus, we were able to modify the gain in the gamma oscillations that are independent of the spindles while the spindle amplitude was reduced. Furthermore, carbachol produced a decoupling of the gamma oscillations that are dependent on the spindles but with no effect on their amplitude. None of the changes in the high-frequency oscillations affected the onset or shape of the slow oscillations, suggesting that slow oscillations occur independently of the phasic events that coexist with them. Our results provide novel insights into the regulation, dynamics and homeostasis of cortical slow oscillations.},
	number = {7},
	journal = {PLoS ONE},
	author = {Valencia, Miguel and Artieda, Julio and Bolam, J. Paul and Mena-Segovia, Juan},
	year = {2013},
	pmid = {23844020},
	file = {Attachment:/Users/tito/Zotero/storage/2UZIMHUZ/Valencia et al. - 2013 - Dynamic Interaction of Spindles and Gamma Activity during Cortical Slow Oscillations and Its Modulation by Subc.pdf:application/pdf},
}

@article{buzsaki_mechanisms_2012,
	title = {Mechanisms of {Gamma} {Oscillations}.},
	issn = {1545-4126},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/22443509},
	doi = {10.1146/annurev-neuro-062111-150444},
	abstract = {Gamma rhythms are commonly observed in many brain regions during both waking and sleep states, yet their functions and mechanisms remain a matter of debate. Here we review the cellular and synaptic mechanisms underlying gamma oscillations and outline empirical questions and controversial conceptual issues. Our main points are as follows: First, gamma-band rhythmogenesis is inextricably tied to perisomatic inhibition. Second, gamma oscillations are short-lived and typically emerge from the coordinated interaction of excitation and inhibition, which can be detected as local field potentials. Third, gamma rhythm typically concurs with irregular firing of single neurons, and the network frequency of gamma oscillations varies extensively depending on the underlying mechanism. To document gamma oscillations, efforts should be made to distinguish them from mere increases of gamma-band power and/or increased spiking activity. Fourth, the magnitude of gamma oscillation is modulated by slower rhythms. Such cross-frequency coupling may serve to couple active patches of cortical circuits. Because of their ubiquitous nature and strong correlation with the "operational modes" of local circuits, gamma oscillations continue to provide important clues about neuronal population dynamics in health and disease. Expected final online publication date for the Annual Review of Neuroscience Volume 35 is June 17, 2012. Please see http://www.annualreviews.org/catalog/pubdates.aspx for revised estimates.},
	number = {March},
	journal = {Annual review of neuroscience},
	author = {Buzsáki, György and Wang, Xiao-Jing},
	year = {2012},
	pmid = {22443509},
	keywords = {cross-frequency coupling, dynamical cell assembly, excitatory-inhibitory, inhibitory interneurons, interneuronal network, irregular spiking, long-distance communication, loop, spike timing},
	pages = {203--225},
}

@article{shinbrot_network_2017,
	title = {Network simulations of optical illusions},
	volume = {28},
	doi = {10.1142/S0129183117500188},
	number = {1},
	author = {Shinbrot, Troy and Lazo, Miguel Vivar and Siu, Theo},
	year = {2017},
	keywords = {dynamics, 18, 35, 75, 84, 87, 89, i, kd, network simulations, optical illusions, pacs nos, sn},
	pages = {1--17},
	file = {Attachment:/Users/tito/Zotero/storage/649FGM4K/Shinbrot, Lazo, Siu - 2017 - Network simulations of optical illusions.pdf:application/pdf},
}

@article{cohen_control_1990,
	title = {On the control of automatic processes: a parallel distributed processing account of the {Stroop} effect.},
	volume = {97},
	issn = {0033-295X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/2200075},
	doi = {10.1037/0033-295X.97.3.332},
	abstract = {Traditional views of automaticity are in need of revision. For example, automaticity often has been treated as an all-or-none phenomenon, and traditional theories have held that automatic processes are independent of attention. Yet recent empirical data suggest that automatic processes are continuous, and furthermore are subject to attentional control. A model of attention is presented to address these issues. Within a parallel distributed processing framework, it is proposed that the attributes of automaticity depend on the strength of a processing pathway and that strength increases with training. With the Stroop effect as an example, automatic processes are shown to be continuous and to emerge gradually with practice. Specifically, a computational model of the Stroop task simulates the time course of processing as well as the effects of learning. This was accomplished by combining the cascade mechanism described by McClelland (1979) with the backpropagation learning algorithm (Rumelhart, Hinton, \& Williams, 1986). The model can simulate performance in the standard Stroop task, as well as aspects of performance in variants of this task that manipulate stimulus-onset asynchrony, response set, and degree of practice. The model presented is contrasted against other models, and its relation to many of the central issues in the literature on attention, automaticity, and interference is discussed.},
	number = {3},
	journal = {Psychological review},
	author = {Cohen, J D and Dunbar, K and McClelland, J L},
	year = {1990},
	pmid = {2200075},
	keywords = {Attention, Humans, Reaction Time, Color Perception, Semantics},
	pages = {332--61},
	file = {Attachment:/Users/tito/Zotero/storage/TR7IHZG5/Cohen, Dunbar, McClelland - 1990 - On the control of automatic processes a parallel distributed processing account of the Stroop effect.pdf:application/pdf},
}

@article{hodgkin_quantitative_1952,
	title = {A quantitative description of membrane current and its application to conduction and excitation in nerve.},
	volume = {117},
	issn = {0022-3751},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12991237 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC1392413},
	number = {4},
	journal = {The Journal of physiology},
	author = {Hodgkin, A L and Huxley, A F},
	month = aug,
	year = {1952},
	pmid = {12991237},
	keywords = {AXONS},
	pages = {500--44},
	file = {Attachment:/Users/tito/Zotero/storage/ND2JB78L/HODGKIN, HUXLEY - 1990 - A quantitative description of membrane current and its application to conduction and excitation in nerve.pdf:application/pdf},
}

@article{rissman_measuring_2004,
	title = {Measuring functional connectivity during distinct stages of a cognitive task},
	volume = {23},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2004.06.035},
	abstract = {The inherently multivariate nature of functional brain imaging data affords the unique opportunity to explore how anatomically disparate brain areas interact during cognitive tasks. We introduce a new method for characterizing inter-regional interactions using event-related functional magnetic resonance imaging (fMRI) data. This method's principle advantage over existing analytical techniques is its ability to model the functional connectivity between brain regions during distinct stages of a cognitive task. The method is implemented by using separate covariates to model the activity evoked during each stage of each individual trial in the context of the general linear model (GLM). The resulting parameter estimates (beta values) are sorted according to the stage from which they were derived to form a set of stage-specific beta series. Regions whose beta series are correlated during a given stage are inferred to be functionally interacting during that stage. To validate the assumption that correlated fluctuations in trial-to-trial beta values imply functional connectivity, we applied the method to an event-related fMRI data set in which subjects performed two sequence-tapping tasks. In concordance with previous electrophysiological and fMRI coherence studies, we found that the task requiring greater bimanual coordination induced stronger correlations between motor regions of the two hemispheres. The method was then applied to an event-related fMRI data set in which subjects performed a delayed recognition task. Distinct functional connectivity maps were generated during the component stages of this task, illustrating how important and novel observations of neural networks within the isolated stages of a cognitive task can be obtained. ?? 2004 Elsevier Inc. All rights reserved.},
	number = {2},
	journal = {NeuroImage},
	author = {Rissman, Jesse and Gazzaley, Adam and D'Esposito, Mark},
	year = {2004},
	pmid = {15488425},
	keywords = {Functional connectivity, Network, Working memory, Correlation, Delay period},
	pages = {752--763},
	file = {Attachment:/Users/tito/Zotero/storage/E7WN6DP9/Rissman, Gazzaley, D'Esposito - 2004 - Measuring functional connectivity during distinct stages of a cognitive task.pdf:application/pdf},
}

@book{kriegeskorte_visual_2012,
	title = {Visual population codes : toward a common multivariate framework for cell recording and functional imaging},
	isbn = {978-0-262-01624-7},
	abstract = {Grandmother cells and distributed representations / Simon J. Thorpe – Strategies for finding neural codes / Sheila Nirenberg – Multineuron representations of visual attention / Jasper Poort, Arezoo Pooresmaeili, and Pieter R. Roelfsema – Decoding early visual representations from fMRI ensemble responses / Yukiyasu Kamitani – Understanding visual representation by developing receptive-field models / Kendrick N. Kay – System identification, encoding models, and decoding models: a powerful new approach to fMRI research / Jack L. Gallant, Shinji Nishimoto, Thomas Naselaris, and Michael C.K. Wu – Population coding of object contour shape in V4 and posterior inferotemporal cortex / Anitha Pasupathy and Scott I. Brincat. Measuring representational distances: the Spike-train metrics approach / Conor Houghton and Jonathan D. Victor – The role of categories, features, and learning for the representation of visual object similarity in the human brain / Hans P. Op de Beeck – Ultrafast decoding from cells in the Macaque monkey / Chou P. Hung and James J. DiCarlo – Representational similarity analysis of object population codes in humans, monkeys, and models / Nikolaus Kriegeskorte and Marieke Mur – Three virtues of similarity-based multivariate pattern analysis: an example from the human object vision pathway / Andrew C. Connolly, M. Ida Gobbini, and James V. Haxby – Investigating high-level visual representations: objects, bodies, and scenes / Dwight J. Kravitz, Annie W-Y. Chan and Chris I. Baker – To err is human: correlating fMRI decoding and behavioral errors to probe the neural representation of natural scene categories / Dirk B. Walther, Diane M. Beck and Li Fei-Fei – Decoding visual consciousness from human brain signals / John Dylan Haynes – Probabilistic codes and hierarchical inference in the brain / Karl Friston. Introduction to the anatomy and function of visual cortex / Kendra S. Burbank and Gabriel Kreiman – Introduction to statistical learning and pattern classification / Jed Singer and Gabriel Kreiman – Tutorial on pattern classification in cell recording / Ethan Meyers and Gabriel Kreiman – Tutorial on pattern classification in functional imaging / Marieke Mur and Nikolaus Kriegeskorte – Information-theoretic approaches to pattern analysis / Stefano Panzeri and Robin A.A. Ince – Local field potentials, BOLD, and spiking activity: relationships and physiological mechanism / Philip Berens, Nikos K. Logothetis and Andreas S. Tolias.},
	publisher = {MIT Press},
	author = {Kriegeskorte, Nikolaus and Kreiman, Gabriel},
	year = {2012},
}

@article{deneux_temporal_2016,
	title = {Temporal asymmetries in auditory coding and perception reflect multi-layered nonlinearities},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms12682},
	doi = {10.1038/ncomms12682},
	journal = {Nature Communications},
	author = {Deneux, Thomas and Kempf, Alexandre and Daret, Aurélie and Ponsot, Emmanuel and Bathellier, Brice},
	year = {2016},
	pages = {12682},
	file = {Attachment:/Users/tito/Zotero/storage/ICW7QAZ7/Deneux et al. - 2016 - Temporal asymmetries in auditory coding and perception reflect multi-layered nonlinearities.pdf:application/pdf},
}

@article{van_vreeswijk_when_1994,
	title = {When inhibition not excitation synchronizes neural firing},
	volume = {1},
	issn = {0929-5313},
	url = {http://link.springer.com/10.1007/BF00961879},
	doi = {10.1007/BF00961879},
	number = {4},
	journal = {Journal of Computational Neuroscience},
	author = {Van Vreeswijk, Carl and Abbott, L. F. and Bard Ermentrout, G.},
	month = dec,
	year = {1994},
	pages = {313--321},
	file = {Attachment:/Users/tito/Zotero/storage/NKSGHWIN/Van Vreeswijk, Abbott, Bard Ermentrout - 1994 - When inhibition not excitation synchronizes neural firing.pdf:application/pdf},
}

@article{jaderberg_decoupled_2016,
	title = {Decoupled {Neural} {Interfaces} using {Synthetic} {Gradients}},
	url = {http://arxiv.org/abs/1608.05343},
	abstract = {Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagating error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropagated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which are decoupled in both the forward and backwards pass – amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.},
	author = {Jaderberg, Max and Czarnecki, Wojciech Marian and Osindero, Simon and Vinyals, Oriol and Graves, Alex and Kavukcuoglu, Koray},
	month = aug,
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/FX8L22EL/Author, Address - 2016 - Decoupled Neural Interfaces using Synthetic Gradients.pdf:application/pdf},
}

@article{betzel_multi-scale_nodate,
	title = {Multi-scale brain networks},
	abstract = {The network architecture of the human brain has become a feature of increasing interest to the neuroscientific community, largely because of its potential to illuminate human cognition, its variation over development and aging, and its alteration in disease or injury. Traditional tools and approaches to study this architecture have largely focused on single scales – of topology, time, and space. Expanding beyond this narrow view, we focus this review on pertinent questions and novel methodological advances for the multi-scale brain. We separate our exposition into content related to multi-scale topological structure, multi-scale temporal structure, and multi-scale spatial structure. In each case, we recount empirical evidence for such structures, survey network-based methodological approaches to reveal these structures, and outline current frontiers and open questions. Although predominantly peppered with examples from human neuroimaging, we hope that this account will offer an accessible guide to any neuroscientist aiming to measure, characterize, and understand the full richness of the brain's multiscale network structure – irrespective of species, imaging modality, or spatial resolution.},
	author = {Betzel, Richard F and Bassett, Danielle S},
}

@article{schultz_higher_2016,
	title = {Higher {Intelligence} {Is} {Associated} with {Less} {Task}-{Related} {Brain} {Network} {Reconfiguration}},
	volume = {36},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0358-16.2016},
	doi = {10.1523/JNEUROSCI.0358-16.2016},
	number = {33},
	journal = {Journal of Neuroscience},
	author = {Schultz, D. H. and Cole, M. W.},
	year = {2016},
	keywords = {individual differences, fmri, cognitive control, significance statement, intelligence, asked to make a, based on current task, brain connectivity, decision, demands, efficiency of, for example, functional brain connections are, nized in one way, orga-, quietly but in another, s network configuration varies, task switching, the brain, way if one is, we found that the, when one is resting},
	pages = {8551--8561},
	file = {Attachment:/Users/tito/Zotero/storage/47TG9A3E/Schultz, Cole - 2016 - Higher Intelligence Is Associated with Less Task-Related Brain Network Reconfiguration.pdf:application/pdf},
}

@article{kucyi_dynamic_2014,
	title = {Dynamic functional connectivity of the default mode network tracks daydreaming},
	volume = {100},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2014.06.044},
	doi = {10.1016/j.neuroimage.2014.06.044},
	abstract = {Humans spend much of their time engaged in stimulus-independent thoughts, colloquially known as "daydreaming" or "mind-wandering." A fundamental question concerns how awake, spontaneous brain activity represents the ongoing cognition of daydreaming versus unconscious processes characterized as "intrinsic." Since daydreaming involves brief cognitive events that spontaneously fluctuate, we tested the hypothesis that the dynamics of brain network functional connectivity (FC) are linked with daydreaming. We determined the general tendency to daydream in healthy adults based on a daydreaming frequency scale (DDF). Subjects then underwent both resting state functional magnetic resonance imaging (rs-fMRI) and fMRI during sensory stimulation with intermittent thought probes to determine the occurrences of mind-wandering events. Brain regions within the default mode network (DMN), purported to be involved in daydreaming, were assessed for 1) static FC across the entire fMRI scans, and 2) dynamic FC based on FC variability (FCV) across 30. s progressively sliding windows of 2. s increments within each scan. We found that during both resting and sensory stimulation states, individual differences in DDF were negatively correlated with static FC between the posterior cingulate cortex and a ventral DMN subsystem involved in future-oriented thought. Dynamic FC analysis revealed that DDF was positively correlated with FCV within the same DMN subsystem in the resting state but not during stimulation. However, dynamic but not static FC, in this subsystem, was positively correlated with an individual's degree of self-reported mind-wandering during sensory stimulation. These findings identify temporal aspects of spontaneous DMN activity that reflect conscious and unconscious processes. ?? 2014 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Kucyi, Aaron and Davis, Karen D.},
	year = {2014},
	pmid = {24973603},
	keywords = {Awareness, Brain dynamics, Consciousness, Spontaneous cognition, Stimulus-independent thought},
	pages = {471--480},
	file = {Attachment:/Users/tito/Zotero/storage/N6IBR7IJ/Kucyi, Davis - 2014 - Dynamic functional connectivity of the default mode network tracks daydreaming.pdf:application/pdf},
}

@article{author_decoupled_2016,
	title = {Decoupled {Neural} {Interfaces} using {Synthetic} {Gradients}},
	number = {Nips},
	author = {Author, Anonymous and Address, Affiliation},
	year = {2016},
}

@article{siegel_data_2016,
	title = {Data {Quality} {Influences} {Observed} {Links} {Between} {Functional} {Connectivity} and {Behavior}},
	issn = {1047-3211},
	doi = {10.1093/cercor/bhw253},
	abstract = {A growing field of research explores links between behavioral measures and functional connectivity (FC) assessed using resting-state functional magnetic resonance imaging. Recent studies suggest that measurement of these relationships may be corrupted by head motion artifact. Using data from the Human Connectome Project (HCP), we find that a surprising number of behavioral, demographic, and physiological measures (23 of 122), including fluid intelligence, reading ability, weight, and psychiatric diagnostic scales, correlate with head motion. We demonstrate that “trait” (across-subject) and “state” (across-day, within-subject) effects of motion on FC are remarkably similar in HCP data, suggesting that state effects of motion could potentially mimic trait correlates of behavior. Thus, head motion is a likely source of systematic errors (bias) in the measurement of FC:behavior relationships. Next, we show that data cleaning strategies reduce the influence of head motion and substantially alter previously reported FC:behavior relationship. Our results suggest that spurious relationships mediated by head motion may be widespread in studies linking FC to behavior.},
	journal = {Cerebral Cortex},
	author = {Siegel, Joshua S. and Mitra, Anish and Laumann, Timothy O. and Seitzman, Benjamin A. and Raichle, Marcus and Corbetta, Maurizio and Snyder, Abraham Z.},
	year = {2016},
	keywords = {functional connectivity, resting state, head motion, iq, movement},
	pages = {1--11},
	file = {Attachment:/Users/tito/Zotero/storage/K3HEUXQX/Siegel et al. - 2016 - Data Quality Influences Observed Links Between Functional Connectivity and Behavior.pdf:application/pdf},
}

@article{mitra_how_2016,
	title = {How networks communicate : propagation patterns in spontaneous brain activity},
	volume = {371},
	url = {http://rstb.royalsocietypublishing.org/content/371/1705/20150546},
	doi = {10.1098/rstb.2015.0546},
	abstract = {Initially regarded as ‘noise', spontaneous (intrinsic) activity accounts for a large portion of the brain's metabolic cost. Moreover, it is now widely known that infra-slow (less than 0.1 Hz) spontaneous activity, measured using resting state functional magnetic resonance imaging of the blood oxygen level-dependent (BOLD) signal, is correlated within functionally defined resting state networks (RSNs). However, despite these advances, the temporal organization of spontaneous BOLD fluctuations has remained elusive. By studying temporal lags in the resting state BOLD signal, we have recently shown that spontaneous BOLD fluctuations consist of remarkably reproducible patterns of whole brain propagation. Embedded in these propagation patterns are unidirectional ‘motifs' which, in turn, give rise to RSNs. Additionally, propagation patterns are markedly altered as a function of state, whether physiological or pathological. Understanding such propagation patterns will likely yield deeper insights into the role of spontaneous activity in brain function in health and disease.},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Mitra, Anish and Raichle, Marcus E},
	year = {2016},
	pages = {20150546},
	file = {Attachment:/Users/tito/Zotero/storage/KWE4YTHY/Mitra, Raichle - 2016 - How networks communicate propagation patterns in spontaneous brain activity.pdf:application/pdf},
}

@article{shine_temporal_2016,
	title = {Temporal meta-states are associated with differential patterns of dynamic connectivity, network topology and attention},
	issn = {0027-8424},
	url = {http://arxiv.org/abs/1601.05065},
	doi = {10.1073/pnas.1604898113},
	abstract = {Little is currently known about the coordination of neural activity over longitudinal time-scales and how these changes relate to behavior. To investigate this issue, we used resting-state fMRI data from a single individual to identify the presence of two distinct temporal states that fluctuated over the course of 18 months. We then demonstrated that these temporal states were associated with distinct neural dynamics within individual scanning sessions. In addition, the temporal states were also related to significant alterations in global efficiency, as well as differences in self-reported attention. These patterns were replicated in a separate longitudinal dataset, providing further supportive evidence for the presence of fluctuations in functional network topology over time. Together, our results underscore the importance of longitudinal phenotyping in cognitive neuroscience.},
	number = {10},
	author = {Shine, James M. and Koyejo, Oluwasanmi and Poldrack, Russell A.},
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/H5QI3AAH/Shine, Koyejo, Poldrack - 2016 - Temporal meta-states are associated with differential patterns of dynamic connectivity, network topolog.pdf:application/pdf},
}

@article{betzel_positive_2016,
	title = {A positive mood, a flexible brain},
	url = {http://arxiv.org/abs/1601.07881},
	abstract = {Flexible reconfiguration of human brain networks supports cognitive flexibility and learning. However, modulating flexibility to enhance learning requires an understanding of the relationship between flexibility and brain state. In an unprecedented longitudinal data set, we investigate the relationship between flexibility and mood, demonstrating that flexibility is positively correlated with emotional state. Our results inform the modulation of brain state to enhance response to training in health and injury.},
	author = {Betzel, Richard F. and Satterthwaite, Theodore D. and Gold, Joshua I. and Bassett, Danielle S.},
	year = {2016},
	pages = {1--15},
	file = {Attachment:/Users/tito/Zotero/storage/PVDIK4VU/Betzel et al. - 2016 - A positive mood, a flexible brain.pdf:application/pdf},
}

@article{buzsaki_large-scale_2004,
	title = {Large-scale recording of neuronal ensembles.},
	volume = {7},
	issn = {1097-6256},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15114356},
	doi = {10.1038/nn1233},
	abstract = {How does the brain orchestrate perceptions, thoughts and actions from the spiking activity of its neurons? Early single-neuron recording research treated spike pattern variability as noise that needed to be averaged out to reveal the brain's representation of invariant input. Another view is that variability of spikes is centrally coordinated and that this brain-generated ensemble pattern in cortical structures is itself a potential source of cognition. Large-scale recordings from neuronal ensembles now offer the opportunity to test these competing theoretical frameworks. Currently, wire and micro-machined silicon electrode arrays can record from large numbers of neurons and monitor local neural circuits at work. Achieving the full potential of massively parallel neuronal recordings, however, will require further development of the neuron-electrode interface, automated and efficient spike-sorting algorithms for effective isolation and identification of single neurons, and new mathematical insights for the analysis of network properties.},
	number = {5},
	journal = {Nature neuroscience},
	author = {Buzsáki, György},
	year = {2004},
	pmid = {15114356},
	keywords = {Brain, Humans, Nerve Net, Animals, Brain: physiology, Action Potentials, Action Potentials: physiology, Brain: cytology, Electrophysiology, Electrophysiology: methods, Microelectrodes, Nerve Net: physiology, Neurons, Neurons: physiology, Neurophysiology},
	pages = {446--51},
}

@article{gonzalez-castillo_whole-brain_2012,
	title = {Whole-brain, time-locked activation with simple tasks revealed using massive averaging and model-free analysis.},
	volume = {109},
	issn = {1091-6490},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3325687&tool=pmcentrez&rendertype=abstract},
	doi = {10.1073/pnas.1121049109},
	abstract = {The brain is the body's largest energy consumer, even in the absence of demanding tasks. Electrophysiologists report on-going neuronal firing during stimulation or task in regions beyond those of primary relationship to the perturbation. Although the biological origin of consciousness remains elusive, it is argued that it emerges from complex, continuous whole-brain neuronal collaboration. Despite converging evidence suggesting the whole brain is continuously working and adapting to anticipate and actuate in response to the environment, over the last 20 y, task-based functional MRI (fMRI) have emphasized a localizationist view of brain function, with fMRI showing only a handful of activated regions in response to task/stimulation. Here, we challenge that view with evidence that under optimal noise conditions, fMRI activations extend well beyond areas of primary relationship to the task; and blood-oxygen level-dependent signal changes correlated with task-timing appear in over 95\% of the brain for a simple visual stimulation plus attention control task. Moreover, we show that response shape varies substantially across regions, and that whole-brain parcellations based on those differences produce distributed clusters that are anatomically and functionally meaningful, symmetrical across hemispheres, and reproducible across subjects. These findings highlight the exquisite detail lying in fMRI signals beyond what is normally examined, and emphasize both the pervasiveness of false negatives, and how the sparseness of fMRI maps is not a result of localized brain function, but a consequence of high noise and overly strict predictive response models.},
	number = {14},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Gonzalez-Castillo, Javier and Saad, Ziad S and Handwerker, Daniel A and Inati, Souheil J and Brenowitz, Noah and Bandettini, Peter A},
	year = {2012},
	pmid = {22431587},
	keywords = {Brain, Humans, Magnetic Resonance Imaging, Models, Theoretical, Brain: physiology, Task Performance and Analysis},
	pages = {5487--92},
	file = {Attachment:/Users/tito/Zotero/storage/GDA9XUU9/Gonzalez-Castillo et al. - 2012 - Whole-brain, time-locked activation with simple tasks revealed using massive averaging and model-free.pdf:application/pdf},
}

@article{kriegeskorte_inferring_nodate,
	title = {Inferring brain-computational mechanisms with models of activity measurements},
	volume = {2},
	number = {Abbott 2008},
	author = {Kriegeskorte, Nikolaus and Diedrichsen, Jörn},
	pages = {1--19},
	file = {Attachment:/Users/tito/Zotero/storage/FFV95MLU/Kriegeskorte, Diedrichsen - Unknown - Inferring brain-computational mechanisms with models of activity measurements.pdf:application/pdf},
}

@article{sprague_restoring_2016,
	title = {Restoring {Latent} {Visual} {Working} {Memory} {Representations} in {Human} {Cortex}},
	volume = {91},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S089662731630352X},
	doi = {10.1016/j.neuron.2016.07.006},
	number = {3},
	journal = {Neuron},
	author = {Sprague, Thomas C. and Ester, Edward F. and Serences, John T.},
	year = {2016},
	pages = {694--707},
	file = {Attachment:/Users/tito/Zotero/storage/DHNPU9TC/Sprague, Ester, Serences - 2016 - Restoring Latent Visual Working Memory Representations in Human Cortex.pdf:application/pdf},
}

@article{marblestone_towards_nodate,
	title = {Towards an integration of deep learning and neuroscience},
	doi = {10.1101/058545},
	author = {Marblestone, Adam H and Wayne, Greg and Kording, Konrad P},
	keywords = {neural networks, neuroscience, cognitive architecture, cost functions},
	pages = {1--61},
	file = {Attachment:/Users/tito/Zotero/storage/IQ7MJKQC/Marblestone, Wayne, Kording - Unknown - Towards an integration of deep learning and neuroscience.pdf:application/pdf},
}

@article{testolin_probabilistic_2016,
	title = {Probabilistic {Models} and {Generative} {Neural} {Networks}: {Towards} an {Unified} {Framework} for {Modeling} {Normal} and {Impaired} {Neurocognitive} {Functions}},
	volume = {July},
	issn = {1662-5188},
	doi = {10.3389/fncom.2016.00073},
	number = {July},
	journal = {Frontiers in computational neuroscience},
	author = {Testolin, Alberto and Zorzi, Marco},
	year = {2016},
	keywords = {computational neuropsychology, connectionist modeling, dee, deep neural networks, probabilistic generative models, unsupervised learning},
	pages = {1--9},
	file = {Attachment:/Users/tito/Zotero/storage/Q6CLMNJS/Testolin, Zorzi - 2016 - Probabilistic Models and Generative Neural Networks Towards an Unified Framework for Modeling Normal and Impair.pdf:application/pdf},
}

@article{saxe_deep_2013,
	title = {{DEEP} {LINEAR} {NEURAL} {NETWORKS}: {A} {THEORY} {OF} {LEARNING} {IN} {THE} {BRAIN} {AND} {MIND}},
	number = {September},
	author = {Saxe, Andrew M},
	year = {2013},
	file = {Attachment:/Users/tito/Zotero/storage/EDU89FW6/Saxe - 2013 - DEEP LINEAR NEURAL NETWORKS A THEORY OF LEARNING IN THE BRAIN AND MIND.pdf:application/pdf},
}

@article{jeter_task_2009,
	title = {Task precision at transfer determines speci fi city of perceptual learning},
	volume = {9},
	doi = {10.1167/9.3.1.Introduction},
	number = {3},
	journal = {Journal of Vision},
	author = {Jeter, Pamela E and Dosher, Barbara Anne and Lu, Zhong-lin},
	year = {2009},
	keywords = {1, 10, doi, http, org, -l, 1167, 13, 2009, 3, 9, a, b, citation, determines speci fi city, dosher, e, jeter, journal of vision, journalofvision, lu, of, p, perceptual learning, petrov, precision, speci fi city, task dif fi culty, task precision at transfer, transfer, z},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/C576MV4Q/Jeter, Dosher, Lu - 2009 - Task precision at transfer determines speci fi city of perceptual learning.pdf:application/pdf},
}

@article{jazayeri_optimal_2006,
	title = {Optimal representation of sensory information by neural populations},
	volume = {9},
	issn = {1097-6256},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16617339%5Cnhttp://www.nature.com/neuro/journal/v9/n5/pdf/nn1691.pdf},
	doi = {10.1038/nn1691},
	abstract = {Sensory information is encoded by populations of neurons. The responses of individual neurons are inherently noisy, so the brain must interpret this information as reliably as possible. In most situations, the optimal strategy for decoding the population signal is to compute the likelihoods of the stimuli that are consistent with an observed neural response. But it has not been clear how the brain can directly compute likelihoods. Here we present a simple and biologically plausible model that can realize the likelihood function by computing a weighted sum of sensory neuron responses. The model provides the basis for an optimal decoding of sensory information. It explains a variety of psychophysical observations on detection, discrimination and identification, and it also directly predicts the relative contributions that different sensory neurons make to perceptual judgments.},
	number = {5},
	journal = {Nat Neurosci},
	author = {Jazayeri, M and Movshon, J A},
	year = {2006},
	pmid = {16617339},
	keywords = {Humans, Neurological, Animals, *Automatic Data Processing, *Models, *Neurons, Afferent, Brain/cytology, Discrimination (Psychology), Likelihood Functions, Nerve Net/physiology, Stochastic Processes, Visual Fields/physiology, Visual Perception/*physiology},
	pages = {690--696},
	file = {Attachment:/Users/tito/Zotero/storage/RV6E5WC8/Jazayeri, Movshon - 2006 - Optimal representation of sensory information by neural populations.pdf:application/pdf},
}

@article{kriegeskorte_representational_2013,
	title = {Representational geometry: {Integrating} cognition, computation, and the brain},
	volume = {17},
	issn = {13646613},
	url = {http://dx.doi.org/10.1016/j.tics.2013.06.007},
	doi = {10.1016/j.tics.2013.06.007},
	abstract = {The cognitive concept of representation plays a key role in theories of brain information processing. However, linking neuronal activity to representational content and cognitive theory remains challenging. Recent studies have characterized the representational geometry of neural population codes by means of representational distance matrices, enabling researchers to compare representations across stages of processing and to test cognitive and computational theories. Representational geometry provides a useful intermediate level of description, capturing both the information represented in a neuronal population code and the format in which it is represented. We review recent insights gained with this approach in perception, memory, cognition, and action. Analyses of representational geometry can compare representations between models and the brain, and promise to explain brain computation as transformation of representational similarity structure. ?? 2013 Elsevier Ltd.},
	number = {8},
	journal = {Trends in Cognitive Sciences},
	author = {Kriegeskorte, Nikolaus and Kievit, Rogier A.},
	year = {2013},
	pmid = {23876494},
	pages = {401--412},
	file = {Attachment:/Users/tito/Zotero/storage/2I8F86DT/Kriegeskorte, Kievit - 2013 - Representational geometry Integrating cognition, computation, and the brain.pdf:application/pdf},
}

@article{sporns_human_2013,
	title = {The human connectome: {Origins} and challenges},
	volume = {80},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2013.03.023},
	doi = {10.1016/j.neuroimage.2013.03.023},
	abstract = {The human connectome refers to a map of the brain's structural connections, rendered as a connection matrix or network. This article attempts to trace some of the historical origins of the connectome, in the process clarifying its definition and scope, as well as its putative role in illuminating brain function. Current efforts to map the connectome face a number of significant challenges, including the issue of capturing network connectivity across multiple spatial scales, accounting for individual variability and structural plasticity, as well as clarifying the role of the connectome in shaping brain dynamics. Throughout, the article argues that these challenges require the development of new approaches for the statistical analysis and computational modeling of brain network data, and greater collaboration across disciplinary boundaries, especially with researchers in complex systems and network science. ?? 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Sporns, Olaf},
	year = {2013},
	pmid = {23528922},
	keywords = {Connectivity, Graph theory, Brain network, Connectomics, Diffusion imaging, Neuroanatomy},
	pages = {53--61},
	file = {Attachment:/Users/tito/Zotero/storage/4TMLI8PE/Sporns - 2013 - The human connectome Origins and challenges.pdf:application/pdf},
}

@article{sadaghiani_functional_2013,
	title = {Functional interactions between intrinsic brain activity and behavior},
	volume = {80},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2013.04.100},
	doi = {10.1016/j.neuroimage.2013.04.100},
	abstract = {The brain continuously maintains a remarkably high level of intrinsic activity. This activity is non-stationary and its dynamics reveal highly structured patterns across several spatial scales, from fine-grained functional architecture in sensory cortices to large-scale networks. The mechanistic function of this activity is only poorly understood. The central goal of the current review is to provide an integrated summary of recent studies on structure, dynamics and behavioral consequences of spontaneous brain activity. In light of these empirical observations we propose that the structure of ongoing activity and its itinerant nature can be understood as an indispensible memory system modeling the statistical structure of the world. We review the dynamic properties of ongoing activity, and how they are malleable over short to long temporal scales that permit adapting over a range of short- to long-term cognitive challenges. We conclude by reviewing how the functional significance of ongoing activity manifests in its impact on human action, perception, and higher cognitive function. ?? 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Sadaghiani, Sepideh and Kleinschmidt, Andreas},
	year = {2013},
	pmid = {23643921},
	pages = {379--386},
	file = {Attachment:/Users/tito/Zotero/storage/NUZDJR42/Sadaghiani, Kleinschmidt - 2013 - Functional interactions between intrinsic brain activity and behavior.pdf:application/pdf},
}

@article{fornito_graph_2013,
	title = {Graph analysis of the human connectome: {Promise}, progress, and pitfalls},
	volume = {80},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2013.04.087},
	doi = {10.1016/j.neuroimage.2013.04.087},
	abstract = {The human brain is a complex, interconnected network par excellence. Accurate and informative mapping of this human connectome has become a central goal of neuroscience. At the heart of this endeavor is the notion that brain connectivity can be abstracted to a graph of nodes, representing neural elements (e.g., neurons, brain regions), linked by edges, representing some measure of structural, functional or causal interaction between nodes. Such a representation brings connectomic data into the realm of graph theory, affording a rich repertoire of mathematical tools and concepts that can be used to characterize diverse anatomical and dynamical properties of brain networks. Although this approach has tremendous potential - and has seen rapid uptake in the neuroimaging community - it also has a number of pitfalls and unresolved challenges which can, if not approached with due caution, undermine the explanatory potential of the endeavor. We review these pitfalls, the prevailing solutions to overcome them, and the challenges at the forefront of the field. ?? 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Fornito, Alex and Zalesky, Andrew and Breakspear, Michael},
	year = {2013},
	pmid = {23643999},
	pages = {426--444},
	file = {Attachment:/Users/tito/Zotero/storage/QJV7R7P6/Fornito, Zalesky, Breakspear - 2013 - Graph analysis of the human connectome Promise, progress, and pitfalls.pdf:application/pdf},
}

@article{richardson_subthreshold_2003,
	title = {From subthreshold to firing-rate resonance.},
	volume = {89},
	issn = {0022-3077},
	url = {http://jn.physiology.org/cgi/doi/10.1152/jn.00955.2002},
	doi = {10.1152/jn.00955.2002},
	abstract = {Many types of neurons exhibit subthreshold resonance. However, little is known about whether this frequency preference influences spike emission. Here, the link between subthreshold resonance and firing rate is examined in the framework of conductance-based models. A classification of the subthreshold properties of a general class of neurons is first provided. In particular, a class of neurons is identified in which the input impedance exhibits a suppression at a nonzero low frequency as well as a peak at higher frequency. The analysis is then extended to the effect of subthreshold resonance on the dynamics of the firing rate. The considered input current comprises a background noise term, mimicking the massive synaptic bombardment in vivo. Of interest is the modulatory effect an additional weak oscillating current has on the instantaneous firing rate. When the noise is weak and firing regular, the frequency most preferentially modulated is the firing rate itself. Conversely, when the noise is strong and firing irregular, the modulation is strongest at the subthreshold resonance frequency. These results are demonstrated for two specific conductance-based models and for a generalization of the integrate-and-fire model that captures subthreshold resonance. They suggest that resonant neurons are able to communicate their frequency preference to postsynaptic targets when the level of noise is comparable to that prevailing in vivo.},
	number = {5},
	journal = {Journal of neurophysiology},
	author = {Richardson, Magnus J. E. and Brunel, Nicolas and Hakim, Vincent},
	year = {2003},
	pmid = {12611957},
	pages = {2538--2554},
	file = {Attachment:/Users/tito/Zotero/storage/9U2WVF95/Richardson, Brunel, Hakim - 2003 - From subthreshold to firing-rate resonance.pdf:application/pdf},
}

@article{kriegeskorte_deep_2015,
	title = {Deep {Neural} {Networks}: {A} {New} {Framework} for {Modeling} {Biological} {Vision} and {Brain} {Information} {Processing}},
	volume = {1},
	issn = {2374-4642},
	url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-vision-082114-035447},
	doi = {10.1146/annurev-vision-082114-035447},
	abstract = {Recent advances in neural network modeling have enabled major strides in computer vision and other artificial intelligence applications. Human-level visual recognition abilities are coming within reach of artificial systems. Artificial neural networks are inspired by the brain, and their computations could be implemented in biological neurons. Convolutional feedforward networks, which now dominate computer vision, take further inspiration from the architecture of the primate visual hierarchy. However, the current models are designed with engineering goals, not to model brain computations. Nevertheless, initial studies comparing internal representations between these models and primate brains find surprisingly similar representational spaces. With human-level performance no longer out of reach, we are entering an exciting new era, in which we will be able to build biologically faithful feedforward and recurrent computational models of how biological brains perform high-level feats of intelligence, includin...},
	number = {1},
	journal = {Annual Review of Vision Science},
	author = {Kriegeskorte, Nikolaus},
	year = {2015},
	keywords = {artificial intelligence, computational neuroscience, neural network, biological vision, computer vision, deep learning, object recognition},
	pages = {417--446},
	file = {Attachment:/Users/tito/Zotero/storage/S8UUADJH/Kriegeskorte - 2015 - Deep Neural Networks A New Framework for Modeling Biological Vision and Brain Information Processing.pdf:application/pdf},
}

@article{sherman_neural_2016,
	title = {Neural mechanisms of transient neocortical beta rhythms : {Converging} evidence from humans, computational modeling, monkeys, and mice},
	issn = {0027-8424},
	doi = {10.1073/pnas.1604135113},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sherman, Maxwell A and Lee, Shane and Law, Robert and Haegens, Saskia and Thorn, Catherine A and Hämäläinen, Matti S},
	year = {2016},
	pmid = {27469163},
	file = {Attachment:/Users/tito/Zotero/storage/YYZT4764/Sherman et al. - 2016 - Neural mechanisms of transient neocortical beta rhythms Converging evidence from humans, computational modeling.pdf:application/pdf},
}

@article{riley_functional_2016,
	title = {Functional specialization of areas along the anterior–posterior axis of the primate prefrontal cortex},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhw190},
	doi = {10.1093/cercor/bhw190},
	journal = {Cerebral Cortex},
	author = {Riley, Mitchell R. and Qi, Xue-Lian and Constantinidis, Christos},
	year = {2016},
	pmid = {27371761},
	keywords = {working memory, monkey, anatomical specialization, principal sulcus, visuospatial processing},
	pages = {1--15},
	file = {Attachment:/Users/tito/Zotero/storage/MKM98N66/Riley, Qi, Constantinidis - 2016 - Functional specialization of areas along the anterior–posterior axis of the primate prefrontal cort.pdf:application/pdf},
}

@article{medaglia_cognitive_2015,
	title = {Cognitive {Network} {Neuroscience}},
	volume = {27},
	doi = {10.1162/jocn_a_00810},
	abstract = {■ Network science provides theoretical, computational, and empirical tools that can be used to understand the structure and function of the human brain in novel ways using simple concepts and mathematical representations. Network neuro-science is a rapidly growing field that is providing considerable insight into human structural connectivity, functional connectiv-ity while at rest, changes in functional networks over time (dynamics), and how these properties differ in clinical popu-lations. In addition, a number of studies have begun to quantify network characteristics in a variety of cognitive processes and provide a context for understanding cognition from a network perspective. In this review, we outline the contributions of net-work science to cognitive neuroscience. We describe the meth-odology of network science as applied to the particular case of neuroimaging data and review its uses in investigating a range of cognitive functions including sensory processing, language, emotion, attention, cognitive control, learning, and memory. In conclusion, we discuss current frontiers and the specific chal-lenges that must be overcome to integrate these complemen-tary disciplines of network science and cognitive neuroscience. Increased communication between cognitive neuroscientists and network scientists could lead to significant discoveries under an emerging scientific intersection known as cognitive network neuroscience. ■},
	number = {8},
	journal = {Journal of Cognitive Neuroscience},
	author = {Medaglia, John D and Lynall, Mary-Ellen and Bassett, Danielle S},
	year = {2015},
	pages = {1471--1491},
	file = {Attachment:/Users/tito/Zotero/storage/XUWF5J2W/Lewis, Bates - 2013 - The long reach of the gene.pdf:application/pdf},
}

@article{glasser_multi-modal_2016,
	title = {A multi-modal parcellation of human cerebral cortex},
	issn = {0028-0836},
	url = {http://www.nature.com/doifinder/10.1038/nature18933},
	doi = {10.1038/nature18933},
	journal = {Nature},
	author = {Glasser, Matthew F. and Coalson, Timothy S. and Robinson, Emma C. and Hacker, Carl D. and Harwell, John and Yacoub, Essa and Ugurbil, Kamil and Andersson, Jesper and Beckmann, Christian F. and Jenkinson, Mark and Smith, Stephen M. and Van Essen, David C.},
	year = {2016},
	pmid = {11507039},
	pages = {1--11},
	file = {Attachment:/Users/tito/Zotero/storage/49FA9KJC/Glasser et al. - 2016 - A multi-modal parcellation of human cerebral cortex.pdf:application/pdf},
}

@article{simony_dynamical_2016,
	title = {Dynamical reconfiguration of the default mode network during narrative comprehension},
	volume = {7},
	issn = {2041-1723},
	url = {http://dx.doi.org/10.1038/ncomms12141},
	doi = {10.1038/ncomms12141},
	number = {May 2015},
	journal = {Nature Communications},
	author = {Simony, Erez and Honey, Christopher J. and Chen, Janice and Lositsky, Olga and Yeshurun, Yaara and Wiesel, Ami and Hasson, Uri},
	year = {2016},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/JFJBJ7EY/Simony et al. - 2016 - Dynamical reconfiguration of the default mode network during narrative comprehension.pdf:application/pdf},
}

@article{zabelina_dynamic_2016,
	title = {Dynamic network interactions supporting internally-oriented cognition},
	volume = {40},
	issn = {09594388},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438816300800},
	doi = {10.1016/j.conb.2016.06.014},
	journal = {Current Opinion in Neurobiology},
	author = {Zabelina, Darya L and Andrews-Hanna, Jessica R},
	year = {2016},
	pages = {86--93},
	file = {Attachment:/Users/tito/Zotero/storage/N5TT7KHX/Zabelina, Andrews-Hanna - 2016 - Dynamic network interactions supporting internally-oriented cognition.pdf:application/pdf},
}

@article{manning_topographic_2014,
	title = {Topographic factor analysis: {A} {Bayesian} model for inferring brain networks from neural data},
	volume = {9},
	issn = {19326203},
	doi = {10.1371/journal.pone.0094914},
	abstract = {The neural patterns recorded during a neuroscientific experiment reflect complex interactions between many brain regions, each comprising millions of neurons. However, the measurements themselves are typically abstracted from that underlying structure. For example, functional magnetic resonance imaging (fMRI) datasets comprise a time series of three-dimensional images, where each voxel in an image (roughly) reflects the activity of the brain structure(s)-located at the corresponding point in space-at the time the image was collected. FMRI data often exhibit strong spatial correlations, whereby nearby voxels behave similarly over time as the underlying brain structure modulates its activity. Here we develop topographic factor analysis (TFA), a technique that exploits spatial correlations in fMRI data to recover the underlying structure that the images reflect. Specifically, TFA casts each brain image as a weighted sum of spatial functions. The parameters of those spatial functions, which may be learned by applying TFA to an fMRI dataset, reveal the locations and sizes of the brain structures activated while the data were collected, as well as the interactions between those structures.},
	number = {5},
	journal = {PLoS ONE},
	author = {Manning, Jeremy R. and Ranganath, Rajesh and Norman, Kenneth A. and Blei, David M.},
	year = {2014},
	pmid = {24804795},
	file = {Attachment:/Users/tito/Zotero/storage/Z4XPGWGE/Manning et al. - 2014 - Topographic factor analysis A Bayesian model for inferring brain networks from neural data.pdf:application/pdf},
}

@article{litwin-kumar_formation_2014,
	title = {Formation and maintenance of neuronal assemblies through synaptic plasticity},
	volume = {5},
	issn = {2041-1723},
	url = {http://www.nature.com/ncomms/2014/141114/ncomms6319/full/ncomms6319.html%5Cnhttp://www.nature.com/doifinder/10.1038/ncomms6319},
	doi = {10.1038/ncomms6319},
	abstract = {The architecture of cortex is flexible, permitting neuronal networks to store recent sensory experiences as specific synaptic connectivity patterns. However, it is unclear how these patterns are maintained in the face of the high spike time variability associated with cortex. Here we demonstrate, using a large-scale cortical network model, that realistic synaptic plasticity rules coupled with homeostatic mechanisms lead to the formation of neuronal assemblies that reflect previously experienced stimuli. Further, reverberation of past evoked states in spontaneous spiking activity stabilizes, rather than erases, this learned architecture. Spontaneous and evoked spiking activity contains a signature of learned assembly structures, leading to testable predictions about the effect of recent sensory experience on spike train statistics. Our work outlines requirements for synaptic plasticity rules capable of modifying spontaneous dynamics and shows that this modification is beneficial for stability of learned network architectures.},
	number = {May},
	journal = {Nature Communications},
	author = {Litwin-Kumar, Ashok and Doiron, Brent},
	year = {2014},
	pmid = {25395015},
	pages = {5319},
	file = {Attachment:/Users/tito/Zotero/storage/CVI4LX4H/Litwin-Kumar, Doiron - 2014 - Formation and maintenance of neuronal assemblies through synaptic plasticity.pdf:application/pdf},
}

@article{gu_optimal_2016,
	title = {Optimal {Trajectories} of {Brain} {State} {Transitions}},
	url = {http://arxiv.org/abs/1607.01706},
	abstract = {The complexity of neural dynamics stems in part from the complexity of the underlying anatomy. Yet how the organization of white matter architecture constrains how the brain transitions from one cognitive state to another remains unknown. Here we address this question from a computational perspective by defining a brain state as a pattern of activity across brain regions. Drawing on recent advances in network control theory, we model the underlying mechanisms of brain state transitions as elicited by the collective control of region sets. Specifically, we examine how the brain moves from a specified initial state (characterized by high activity in the default mode) to a specified target state (characterized by high activity in primary sensorimotor cortex) in finite time. Across all state transitions, we observe that the supramarginal gyrus and the inferior parietal lobule consistently acted as efficient, low energy control hubs, consistent with their strong anatomical connections to key input areas of sensorimotor cortex. Importantly, both these and other regions in the fronto-parietal, cingulo-opercular, and attention systems are poised to affect a broad array of state transitions that cannot easily be classified by traditional notions of control common in the engineering literature. This theoretical versatility comes with a vulnerability to injury. In patients with mild traumatic brain injury, we observe a loss of specificity in putative control processes, suggesting greater susceptibility to damage-induced noise in neurophysiological activity. These results offer fundamentally new insights into the mechanisms driving brain state transitions in healthy cognition and their alteration following injury.},
	author = {Gu, Shi and Betzel, Richard F. and Cieslak, Matthew and Delio, Philip R. and Grafton, Scott T. and Pasqualetti, Fabio and Bassett, Danielle S.},
	year = {2016},
	pages = {1--10},
	file = {Attachment:/Users/tito/Zotero/storage/NBBLTSLB/Gu et al. - 2016 - Optimal Trajectories of Brain State Transitions.pdf:application/pdf},
}

@article{golowasch_ionic_2014,
	title = {Ionic current variability and functional stability in the nervous system},
	volume = {64},
	issn = {15253244},
	doi = {10.1093/biosci/biu070},
	abstract = {Identified neurons in different animals express ionic currents at highly variable levels (population variability). If neuronal identity is associated with stereotypical function, as is the case in genetically identical neurons or in unambiguously identified individual neurons, this variability poses a conundrum: How is activity the same if the components that generate it-ionic current levels-are different? In some cases, ionic current variability across similar neurons generates an output gradient. However, many neurons produce very similar output activity, despite substantial variability in ionic conductances. It appears that, in many such cells, conductance levels of one ionic current vary in proportion to the conductance levels of another current. As a result, in a population of neurons, these conductances appear to be correlated. Here, I review theoretical and experimental work that suggests that neuronal ionic current correlation can reduce the global ionic current variability and can contribute to functional stability.},
	number = {7},
	journal = {BioScience},
	author = {Golowasch, Jorge},
	year = {2014},
	pmid = {26069342},
	keywords = {animal physiology, conductances, homeostasis, neurobiology, variability},
	pages = {570--580},
	file = {Attachment:/Users/tito/Zotero/storage/XZ578HKU/Golowasch - 2014 - Ionic current variability and functional stability in the nervous system.pdf:application/pdf},
}

@article{schulz_quantitative_2007,
	title = {Quantitative expression profiling of identified neurons reveals cell-specific constraints on highly variable levels of gene expression.},
	volume = {104},
	issn = {0027-8424},
	doi = {10.1073/pnas.0705827104},
	abstract = {The postdevelopmental basis of cellular identity and the unique cellular output of a particular neuron type are of particular interest in the nervous system because a detailed understanding of circuits responsible for complex processes in the brain is impeded by the often ambiguous classification of neurons in these circuits. Neurons have been classified by morphological, electrophysiological, and neurochemical techniques. More recently, molecular approaches, particularly microarray, have been applied to the question of neuronal identity. With the realization that proteins expressed exclusively in only one type of neuron are rare, expression profiles obtained from neuronal subtypes are analyzed to search for diagnostic patterns of gene expression. However, this expression profiling hinges on one critical and implicit assumption: that neurons of the same type in different animals achieve their conserved functional output via conserved levels and quantitative relationships of gene expression. Here we exploit the unambiguously identifiable neurons in the crab stomatogastric ganglion to investigate the precise quantitative expression profiling of neurons at the level of single-cell ion channel expression. By measuring absolute mRNA levels of six different channels in the same individually identified neurons, we demonstrate that not only do individual cell types possess highly variable levels of channel expression but that this variability is constrained by unique patterns of correlated channel expression.},
	number = {32},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Schulz, David J and Goaillard, Jean-Marc and Marder, Eve E},
	year = {2007},
	pmid = {17652510},
	pages = {13187--13191},
	file = {Attachment:/Users/tito/Zotero/storage/V4RP82AY/Schulz, Goaillard, Marder - 2007 - Quantitative expression profiling of identified neurons reveals cell-specific constraints on highly v.pdf:application/pdf},
}

@article{maclean_activity-independent_2005,
	title = {Activity-{Independent} {Coregulation} of},
	doi = {10.1152/jn.00281.2005.},
	journal = {Journal of Neurophysiology},
	author = {Maclean, Jason N and Zhang, Ying and Goeritz, Marie L and Casey, Richard and Oliva, Ricardo and Guckenheimer, John and Harris-warrick, Ronald M},
	year = {2005},
	pages = {3601--3617},
	file = {Attachment:/Users/tito/Zotero/storage/T59Z6V5Q/Maclean et al. - 2005 - Activity-Independent Coregulation of.pdf:application/pdf},
}

@article{potjans_cell-type_2014,
	title = {The cell-type specific cortical microcircuit: {Relating} structure and activity in a full-scale spiking network model},
	volume = {24},
	issn = {10473211},
	doi = {10.1093/cercor/bhs358},
	abstract = {In the past decade, the cell-type specific connectivity and activity of local cortical networks have been characterized experimentally to some detail. In parallel, modeling has been established as a tool to relate network structure to activity dynamics. While available comprehensive connectivity maps ( Thomson, West, et al. 2002; Binzegger et al. 2004) have been used in various computational studies, prominent features of the simulated activity such as the spontaneous firing rates do not match the experimental findings. Here, we analyze the properties of these maps to compile an integrated connectivity map, which additionally incorporates insights on the specific selection of target types. Based on this integrated map, we build a full-scale spiking network model of the local cortical microcircuit. The simulated spontaneous activity is asynchronous irregular and cell-type specific firing rates are in agreement with in vivo recordings in awake animals, including the low rate of layer 2/3 excitatory cells. The interplay of excitation and inhibition captures the flow of activity through cortical layers after transient thalamic stimulation. In conclusion, the integration of a large body of the available connectivity data enables us to expose the dynamical consequences of the cortical microcircuitry.},
	number = {3},
	journal = {Cerebral Cortex},
	author = {Potjans, Tobias C. and Diesmann, Markus},
	year = {2014},
	pmid = {23203991},
	keywords = {connectivity maps, cortical microcircuit, large-scale models, layered network, specificity of connections},
	pages = {785--806},
	file = {Attachment:/Users/tito/Zotero/storage/5BHWFJ39/Potjans, Diesmann - 2014 - The cell-type specific cortical microcircuit Relating structure and activity in a full-scale spiking network.pdf:application/pdf},
}

@article{tsuda_dynamic_1992,
	title = {Dynamic link of memory - chaotic memory map in nonequilibrium neural networks},
	volume = {5},
	journal = {Neural Networks},
	author = {Tsuda, I},
	year = {1992},
	keywords = {memory, neural network, chaos, Hubert, MAPS, NETWORK, NEURAL},
	pages = {313--326},
	file = {Attachment:/Users/tito/Zotero/storage/X6U9BXTP/Tsuda - 1992 - Dynamic link of memory - chaotic memory map in nonequilibrium neural networks.pdf:application/pdf},
}

@article{buzsaki_log-dynamic_2014,
	title = {The log-dynamic brain: how skewed distributions affect network operations.},
	volume = {15},
	issn = {1471-0048},
	url = {http://www.nature.com.scd-rproxy.u-strasbg.fr/nrn/journal/v15/n4/full/nrn3687.html},
	doi = {10.1038/nrn3687},
	abstract = {We often assume that the variables of functional and structural brain parameters - such as synaptic weights, the firing rates of individual neurons, the synchronous discharge of neural populations, the number of synaptic contacts between neurons and the size of dendritic boutons - have a bell-shaped distribution. However, at many physiological and anatomical levels in the brain, the distribution of numerous parameters is in fact strongly skewed with a heavy tail, suggesting that skewed (typically lognormal) distributions are fundamental to structural and functional brain organization. This insight not only has implications for how we should collect and analyse data, it may also help us to understand how the different levels of skewed distributions - from synapses to cognition - are related to each other.},
	number = {4},
	journal = {Nature reviews. Neuroscience},
	author = {Buzsáki, György and Mizuseki, Kenji},
	year = {2014},
	pmid = {24569488},
	keywords = {Brain, Humans, Nerve Net, Models, Neurological, Animals, Brain: physiology, Nerve Net: physiology},
	pages = {264--78},
}

@article{rajan_eigenvalue_2006,
	title = {Eigenvalue spectra of random matrices for neural networks},
	volume = {97},
	issn = {00319007},
	doi = {10.1103/PhysRevLett.97.188104},
	abstract = {The dynamics of neural networks is influenced strongly by the spectrum of eigenvalues of the matrix describing their synaptic connectivity. In large networks, elements of the synaptic connectivity matrix can be chosen randomly from appropriate distributions, making results from random matrix theory highly relevant. Unfortunately, classic results on the eigenvalue spectra of random matrices do not apply to synaptic connectivity matrices because of the constraint that individual neurons are either excitatory or inhibitory. Therefore, we compute eigenvalue spectra of large random matrices with excitatory and inhibitory columns drawn from distributions with different means and equal or different variances.},
	number = {18},
	journal = {Physical Review Letters},
	author = {Rajan, Kanaka and Abbott, L. F.},
	year = {2006},
	pmid = {17155583},
	pages = {2--5},
	file = {Attachment:/Users/tito/Zotero/storage/BHA6KWHK/Rajan, Abbott - 2006 - Eigenvalue spectra of random matrices for neural networks.pdf:application/pdf},
}

@article{hiratani_associative_2012,
	title = {Associative memory model with long-tail-distributed {Hebbian} synaptic connections.},
	volume = {6},
	issn = {1662-5188},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3566427&tool=pmcentrez&rendertype=abstract},
	doi = {10.3389/fncom.2012.00102},
	abstract = {The postsynaptic potentials of pyramidal neurons have a non-Gaussian amplitude distribution with a heavy tail in both hippocampus and neocortex. Such distributions of synaptic weights were recently shown to generate spontaneous internal noise optimal for spike propagation in recurrent cortical circuits. However, whether this internal noise generation by heavy-tailed weight distributions is possible for and beneficial to other computational functions remains unknown. To clarify this point, we construct an associative memory (AM) network model of spiking neurons that stores multiple memory patterns in a connection matrix with a lognormal weight distribution. In AM networks, non-retrieved memory patterns generate a cross-talk noise that severely disturbs memory recall. We demonstrate that neurons encoding a retrieved memory pattern and those encoding non-retrieved memory patterns have different subthreshold membrane-potential distributions in our model. Consequently, the probability of responding to inputs at strong synapses increases for the encoding neurons, whereas it decreases for the non-encoding neurons. Our results imply that heavy-tailed distributions of connection weights can generate noise useful for AM recall.},
	number = {February},
	journal = {Frontiers in computational neuroscience},
	author = {Hiratani, Naoki and Teramae, Jun-Nosuke and Fukai, Tomoki},
	year = {2012},
	pmid = {23403536},
	keywords = {hippocampus, computational neuroscience, 10, doi, 00102, 07 february 2013, 2012, 3389, attractor, fncom, ginal research article, integrate-and-fire, mean-field, published, stochastic r, stochastic resonance, storage capacity},
	pages = {102},
	file = {Attachment:/Users/tito/Zotero/storage/C74MRG75/Hiratani, Teramae, Fukai - 2012 - Associative memory model with long-tail-distributed Hebbian synaptic connections.pdf:application/pdf},
}

@article{stern_dynamics_2014,
	title = {Dynamics of random neural networks with bistable units},
	volume = {90},
	issn = {15502376},
	doi = {10.1103/PhysRevE.90.062710},
	abstract = {We construct and analyze a rate-based neural network model in which self-interacting units represent clusters of neurons with strong local connectivity and random interunit connections reflect long-range interactions. When sufficiently strong, the self-interactions make the individual units bistable. Simulation results, mean-field calculations, and stability analysis reveal the different dynamic regimes of this network and identify the locations in parameter space of its phase transitions. We identify an interesting dynamical regime exhibiting transient but long-lived chaotic activity that combines features of chaotic and multiple fixed-point attractors.},
	number = {6},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Stern, M. and Sompolinsky, H. and Abbott, L. F.},
	year = {2014},
	pmid = {25615132},
	pages = {1--7},
	file = {Attachment:/Users/tito/Zotero/storage/MR6ECUXV/Stern, Sompolinsky, Abbott - 2014 - Dynamics of random neural networks with bistable units.pdf:application/pdf},
}

@article{aoki_synchrony-induced_2007,
	title = {Synchrony-induced switching behavior of spike pattern attractors created by spike-timing-dependent plasticity.},
	volume = {19},
	issn = {0899-7667},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17716009},
	doi = {10.1162/neco.2007.19.10.2720},
	abstract = {Although context-dependent spike synchronization among populations of neurons has been experimentally observed, its functional role remains controversial. In this modeling study, we demonstrate that in a network of spiking neurons organized according to spike-timing-dependent plasticity, an increase in the degree of synchrony of a uniform input can cause transitions between memorized activity patterns in the order presented during learning. Furthermore, context-dependent transitions from a single pattern to multiple patterns can be induced under appropriate learning conditions. These findings suggest one possible functional role of neuronal synchrony in controlling the flow of information by altering the dynamics of the network.},
	number = {10},
	journal = {Neural computation},
	author = {Aoki, Takaaki and Aoyagi, Toshio},
	year = {2007},
	pmid = {17716009},
	keywords = {Humans, Reaction Time, Animals, Learning, Learning: physiology, Action Potentials, Neurons, Neurons: physiology, Memory, Memory: physiology, Neural Networks (Computer), Neuronal Plasticity, Neuronal Plasticity: physiology},
	pages = {2720--38},
	file = {Attachment:/Users/tito/Zotero/storage/PT8D9GX8/Aoki, Aoyagi - 2007 - Synchrony-induced switching behavior of spike pattern attractors created by spike-timing-dependent plasticity.pdf:application/pdf},
}

@article{brunel_dynamics_2000,
	title = {Dynamics of sparsely connected networls of excitatory and inhibitory neurons},
	volume = {8},
	issn = {09284257},
	doi = {10.1016/S0928-4257(00)01084-6},
	abstract = {The dynamics of networks of sparsely connected excitatory and inhibitory integrate-and-fire neurons are studied analytically. The analysis reveals a rich repertoire of states, including synchronous states in which neurons fire regularly; asynchronous states with stationary global activity and very irregular individual cell activity; and states in which the global activity oscillates but individual cells fire irregularly, typically at rates lower than the global oscillation frequency. The network can switch between these states, provided the external frequency, or the balance between excitation and inhibition, is varied. Two types of network oscillations are observed. In the fast oscillatory state, the network frequency is almost fully controlled by the synaptic time scale. In the slow oscillatory state, the network frequency depends mostly on the membrane time constant. Finite size effects in the asynchronous state are also discussed},
	journal = {Computational Neuroscience},
	author = {Brunel, N},
	year = {2000},
	pmid = {11165912},
	keywords = {synchronization, recurrent network},
	pages = {183--208},
	file = {Attachment:/Users/tito/Zotero/storage/DS8AB9VE/Brunel - 2000 - Dynamics of sparsely connected networls of excitatory and inhibitory neurons.pdf:application/pdf},
}

@article{enel_reservoir_2016,
	title = {Reservoir {Computing} {Properties} of {Neural} {Dynamics} in {Prefrontal} {Cortex}},
	volume = {12},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1004967},
	doi = {10.1371/journal.pcbi.1004967},
	number = {6},
	journal = {PLOS Computational Biology},
	author = {Enel, Pierre and Procyk, Emmanuel and Quilodran, René and Dominey, Peter Ford},
	year = {2016},
	pages = {e1004967},
	file = {Attachment:/Users/tito/Zotero/storage/FMCTXS22/Enel et al. - 2016 - Reservoir Computing Properties of Neural Dynamics in Prefrontal Cortex.pdf:application/pdf},
}

@article{teramae_optimal_2012,
	title = {Optimal spike-based communication in excitable networks with strong-sparse and weak-dense links.},
	volume = {2},
	issn = {2045-2322},
	url = {http://www.nature.com/doifinder/10.1038/srep00485%5Cnpapers3://publication/doi/10.1038/srep00485},
	doi = {10.1038/srep00485},
	abstract = {The connectivity of complex networks and functional implications has been attracting much interest in many physical, biological and social systems. However, the significance of the weight distributions of network links remains largely unknown except for uniformly- or Gaussian-weighted links. Here, we show analytically and numerically, that recurrent neural networks can robustly generate internal noise optimal for spike transmission between neurons with the help of a long-tailed distribution in the weights of recurrent connections. The structure of spontaneous activity in such networks involves weak-dense connections that redistribute excitatory activity over the network as noise sources to optimally enhance the responses of individual neurons to input at sparse-strong connections, thus opening multiple signal transmission pathways. Electrophysiological experiments confirm the importance of a highly broad connectivity spectrum supported by the model. Our results identify a simple network mechanism for internal noise generation by highly inhomogeneous connection strengths supporting both stability and optimal communication.},
	journal = {Scientific Reports},
	author = {Teramae, Jun-Nosuke and Tsubo, Yasuhiro and Fukai, Tomoki},
	year = {2012},
	pmid = {22761993},
	pages = {485},
	file = {Attachment:/Users/tito/Zotero/storage/Q9M4UQ3L/Teramae, Tsubo, Fukai - 2012 - Optimal spike-based communication in excitable networks with strong-sparse and weak-dense links.pdf:application/pdf},
}

@article{kleinfeld_sequential_1986,
	title = {Sequential {State} {Generation} by {Model} {Neural} {Networks}},
	volume = {83},
	issn = {0027-8424},
	doi = {10.1073/pnas.83.24.9469},
	abstract = {Sequential patterns of neural output activity form the basis of many biological processes, such as the cyclic pattern of outputs that control locomotion. I show how such sequences can be generated by a class of model neural networks that make defined sets of transitions between selected memory states. Sequence-generating networks depend upon the interplay between two sets of synaptic connections. One set acts to stabilize the network in its current memory state, while the second set, whose action is delayed in time, causes the network to make specified transitions between the memories. The dynamic properties of these networks are described in terms of motion along an energy surface. The performance of the networks, both with intact connections and with noisy or missing connections, is illustrated by numerical examples. In addition, I present a scheme for the recognition of externally generated sequences by these networks.},
	number = {24},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kleinfeld, D.},
	year = {1986},
	pmid = {3467316},
	pages = {9469--9473},
	file = {Attachment:/Users/tito/Zotero/storage/V7SAR9H8/Kleinfeld - 1986 - Sequential State Generation by Model Neural Networks.pdf:application/pdf},
}

@article{giusti_twos_2016,
	title = {Two's company, three (or more) is a simplex: {Algebraic}-topological tools for understanding higher-order structure in neural data},
	volume = {115},
	issn = {0031-9007},
	url = {http://link.aps.org/doi/10.1103/PhysRevLett.115.194101%5Cnhttp://arxiv.org/abs/1601.01704},
	doi = {10.1103/PhysRevLett.115.194101},
	abstract = {The language of graph theory, or network science, has proven to be an exceptional tool for addressing myriad problems in neuroscience. Yet, the use of networks is predicated on a critical simplifying assumption: that the quintessential unit of interest in a brain is a dyad – two nodes (neurons or brain regions) connected by an edge. While rarely mentioned, this fundamental assumption inherently limits the types of neural structure and function that graphs can be used to model. Here, we describe a generalization of graphs that overcomes these limitations, thereby offering a broad range of new possibilities in terms of modeling and measuring neural phenomena. Specifically, we explore the use of \${\textbackslash}backslash\$emph\{simplicial complexes\}, a theoretical notion developed in the field of mathematics known as algebraic topology, which is now becoming applicable to real data due to a rapidly growing computational toolset. We review the underlying mathematical formalism as well as the budding literature applying simplicial complexes to neural data, from electrophysiological recordings in animal models to hemodynamic fluctuations in humans. Based on the exceptional flexibility of the tools and recent ground-breaking insights into neural function, we posit that this framework has the potential to eclipse graph theory in unraveling the fundamental mysteries of cognition.},
	number = {19},
	journal = {Physical Review Letters},
	author = {Giusti, Chad and Ghrist, Robert and Bassett, Danielle S.},
	year = {2016},
	keywords = {networks, Networks, Filtration, simplicial complex, Simplicial complex, topology, Topology},
	pages = {194101},
	file = {Attachment:/Users/tito/Zotero/storage/FZSMQF7F/Giusti, Ghrist, Bassett - 2016 - Two's company, three (or more) is a simplex Algebraic-topological tools for understanding higher-ord(2).pdf:application/pdf},
}

@article{hass_detailed_2016,
	title = {A {Detailed} {Data}-{Driven} {Network} {Model} of {Prefrontal} {Cortex} {Reproduces} {Key} {Features} of {In} {Vivo} {Activity}},
	volume = {12},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1004930},
	doi = {10.1371/journal.pcbi.1004930},
	number = {5},
	journal = {PLOS Computational Biology},
	author = {Hass, Joachim and Hertäg, Loreen and Durstewitz, Daniel},
	year = {2016},
	pmid = {27203563},
	pages = {e1004930},
}

@article{wong_recurrent_2006,
	title = {A {Recurrent} {Network} {Mechanism} of {Time} {Integration} in {Perceptual} {Decisions}},
	volume = {26},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3733-05.2006},
	doi = {10.1523/JNEUROSCI.3733-05.2006},
	number = {4},
	journal = {Journal of Neuroscience},
	author = {Wong, K.-F. and Wang, X-J},
	year = {2006},
	keywords = {computational modeling, dynamical systems, intraparietal cortex, nmda, reaction time, sensory discrimination},
	pages = {1314--1328},
	file = {Attachment:/Users/tito/Zotero/storage/25U8P67W/Wong, Wang - 2006 - A Recurrent Network Mechanism of Time Integration in Perceptual Decisions.pdf:application/pdf},
}

@article{kadmon_transition_2015,
	title = {Transition to chaos in random neuronal networks},
	volume = {5},
	issn = {21603308},
	doi = {10.1103/PhysRevX.5.041030},
	abstract = {Firing patterns in the central nervous system often exhibit strong temporal irregularity and heterogeneity in their time averaged response properties. Previous studies suggested that these properties are outcome of an intrinsic chaotic dynamics. Indeed, simplified rate-based large neuronal networks with random synaptic connections are known to exhibit sharp transition from fixed point to chaotic dynamics when the synaptic gain is increased. However, the existence of a similar transition in neuronal circuit models with more realistic architectures and firing dynamics has not been established. In this work we investigate rate based dynamics of neuronal circuits composed of several subpopulations and random connectivity. Nonzero connections are either positive-for excitatory neurons, or negative for inhibitory ones, while single neuron output is strictly positive; in line with known constraints in many biological systems. Using Dynamic Mean Field Theory, we find the phase diagram depicting the regimes of stable fixed point, unstable dynamic and chaotic rate fluctuations. We characterize the properties of systems near the chaotic transition and show that dilute excitatory-inhibitory architectures exhibit the same onset to chaos as a network with Gaussian connectivity. Interestingly, the critical properties near transition depend on the shape of the single- neuron input-output transfer function near firing threshold. Finally, we investigate network models with spiking dynamics. When synaptic time constants are slow relative to the mean inverse firing rates, the network undergoes a sharp transition from fast spiking fluctuations and static firing rates to a state with slow chaotic rate fluctuations. When the synaptic time constants are finite, the transition becomes smooth and obeys scaling properties, similar to crossover phenomena in statistical mechanics},
	number = {4},
	journal = {Physical Review X},
	author = {Kadmon, Jonathan and Sompolinsky, Haim},
	year = {2015},
	pmid = {25768781},
	keywords = {ac, corresponding author, huji, il, interdisciplinary physics, jonathan, kadmon, mail, nonlinear dynamics, statistical physics},
	pages = {1--28},
	file = {Attachment:/Users/tito/Zotero/storage/VX3AL5PK/Kadmon, Sompolinsky - 2015 - Transition to chaos in random neuronal networks.pdf:application/pdf},
}

@article{vogels_neural_2005,
	title = {Neural {Network} {Dynamics}},
	volume = {28},
	issn = {0147-006X},
	url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.neuro.28.061604.135637},
	doi = {10.1146/annurev.neuro.28.061604.135637},
	abstract = {Neural network modeling is often concerned with stimulus-driven responses, but most of the activity in the brain is internally generated. Here, we review network models of internally generated activity, focusing on three types of network dynamics: (a) sustained responses to transient stimuli, which provide a model of working memory; (b) oscillatory network activity; and (c) chaotic activity, which models complex patterns of background spiking in cortical and other circuits. We also review propagation of stimulus-driven activity through spontaneously active networks. Exploring these aspects of neural network dynamics is critical for understanding how neural circuits produce cognitive function.},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Vogels, Tim P and Rajan, Kanaka and Abbott, L.F.},
	year = {2005},
	pmid = {16022600},
	keywords = {signal propagation, memory, balance, states, sustained activity},
	pages = {357--376},
	file = {Attachment:/Users/tito/Zotero/storage/NN2UKH87/Vogels, Rajan, Abbott - 2005 - Neural Network Dynamics.pdf:application/pdf},
}

@article{rinzel_analysis_1998,
	title = {Analysis of neural excitability and oscillations. {Methods} in neuronal modelling: from synapses to networks},
	journal = {Methods in neuronal modelling: from synapses to networks},
	author = {Rinzel, J. and Ermentrout, G B},
	year = {1998},
	pages = {251--291},
	file = {Attachment:/Users/tito/Zotero/storage/8HCSWHKW/Rinzel, Ermentrout - 1998 - Analysis of neural excitability and oscillations. Methods in neuronal modelling from synapses to networks.pdf:application/pdf},
}

@article{attneave_multistability_1971,
	title = {Multistability in perception},
	volume = {225},
	issn = {0036-8733},
	doi = {10.1038/scientificamerican1271-62},
	abstract = {Ambiguous (multistable) figures may provide clues to the nature of\${\textbackslash}backslash\$nbasic perceptual processes. Several multistable figures are presented\${\textbackslash}backslash\$nand discussed in terms of the Gestalt principle of Pr\{ä\}gnanz and\${\textbackslash}backslash\$nsatiation of neural structures},
	number = {6},
	journal = {Scientific American},
	author = {Attneave, Fred},
	year = {1971},
	pmid = {5116412},
	pages = {62--71},
	file = {Attachment:/Users/tito/Zotero/storage/6HXZJ9ZJ/Attneave - 1971 - Multistability in perception.pdf:application/pdf},
}

@article{borisyuk_understanding_2005,
	title = {Understanding neuronal dynamics by geometrical dissection of minimal models},
	volume = {80},
	issn = {09248099},
	doi = {10.1016/S0924-8099(05)80008-3},
	number = {C},
	journal = {Les Houches Summer School Proceedings},
	author = {Borisyuk, A. and Rinzel, J.},
	year = {2005},
	pages = {17--72},
	file = {Attachment:/Users/tito/Zotero/storage/NTN8JM24/Borisyuk, Rinzel - 2005 - Understanding neuronal dynamics by geometrical dissection of minimal models.pdf:application/pdf},
}

@article{huth_natural_2016,
	title = {Natural speech reveals the semantic maps that tile human cerebral cortex},
	volume = {532},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/nature17637},
	doi = {10.1038/nature17637},
	abstract = {The meaning of language is represented in regions of the cerebral cortex collectively known as the ‘semantic system'. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods—commonplace in studies of human neuroanatomy and functional connectivity—provide a powerful and efficient means for mapping functional representations in the brain.},
	number = {7600},
	journal = {Nature},
	author = {Huth, Alexander G and Heer, Wendy A De and Griffiths, Thomas L and Theunissen, Frédéric E and Jack, L},
	year = {2016},
	pmid = {27121839},
	pages = {453--458},
	file = {Attachment:/Users/tito/Zotero/storage/UHDYCZ2S/Huth et al. - 2016 - Natural speech reveals the semantic maps that tile human cerebral cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/BK82RFEU/Huth et al. - 2016 - Natural speech reveals the semantic maps that tile human cerebral cortex.pdf:application/pdf},
}

@article{cukur_attention_2013,
	title = {Attention during natural vision warps semantic representation across the human brain.},
	volume = {16},
	issn = {1546-1726},
	url = {http://www.nature.com.ezproxy.cul.columbia.edu/neuro/journal/v16/n6/full/nn.3381.html},
	doi = {10.1038/nn.3381},
	abstract = {Little is known about how attention changes the cortical representation of sensory information in humans. On the basis of neurophysiological evidence, we hypothesized that attention causes tuning changes to expand the representation of attended stimuli at the cost of unattended stimuli. To investigate this issue, we used functional magnetic resonance imaging to measure how semantic representation changed during visual search for different object categories in natural movies. We found that many voxels across occipito-temporal and fronto-parietal cortex shifted their tuning toward the attended category. These tuning shifts expanded the representation of the attended category and of semantically related, but unattended, categories, and compressed the representation of categories that were semantically dissimilar to the target. Attentional warping of semantic representation occurred even when the attended category was not present in the movie; thus, the effect was not a target-detection artifact. These results suggest that attention dynamically alters visual representation to optimize processing of behaviorally relevant objects during natural vision.},
	number = {6},
	journal = {Nature neuroscience},
	author = {Çukur, Tolga and Nishimoto, Shinji and Huth, Alexander G and Gallant, Jack L},
	year = {2013},
	pmid = {23603707},
	keywords = {Attention, Adult, Brain Mapping, Cerebral Cortex, Humans, Magnetic Resonance Imaging, Male, Neuropsychological Tests, Attention: physiology, Magnetic Resonance Imaging: methods, Visual Perception, Visual Perception: physiology, Semantics, Brain Mapping: instrumentation, Brain Mapping: methods, Cerebral Cortex: physiology, Concept Formation, Concept Formation: physiology, Magnetic Resonance Imaging: instrumentation, Motion Pictures as Topic},
	pages = {763--70},
}

@article{nishimoto_reconstructing_2011,
	title = {Reconstructing visual experiences from brain activity evoked by natural movies},
	volume = {21},
	issn = {09609822},
	doi = {10.1016/j.cub.2011.08.031},
	abstract = {Quantitative modeling of human brain activity can provide crucial insights about cortical representations [1, 2] and can form the basis for brain decoding devices [3-5]. Recent functional magnetic resonance imaging (fMRI) studies have modeled brain activity elicited by static visual patterns and have reconstructed these patterns from brain activity [6-8]. However, blood oxygen level-dependent (BOLD) signals measured via fMRI are very slow [9], so it has been difficult to model brain activity elicited by dynamic stimuli such as natural movies. Here we present a new motion-energy [10, 11] encoding model that largely overcomes this limitation. The model describes fast visual information and slow hemodynamics by separate components. We recorded BOLD signals in occipitotemporal visual cortex of human subjects who watched natural movies and fit the model separately to individual voxels. Visualization of the fit models reveals how early visual areas represent the information in movies. To demonstrate the power of our approach, we also constructed a Bayesian decoder [8] by combining estimated encoding models with a sampled natural movie prior. The decoder provides remarkable reconstructions of the viewed movies. These results demonstrate that dynamic brain activity measured under naturalistic conditions can be decoded using current fMRI technology. ?? 2011 Elsevier Ltd. All rights reserved.},
	number = {19},
	journal = {Current Biology},
	author = {Nishimoto, Shinji and Vu, An T. and Naselaris, Thomas and Benjamini, Yuval and Yu, Bin and Gallant, Jack L.},
	year = {2011},
	pmid = {21945275},
	pages = {1641--1646},
	file = {Attachment:/Users/tito/Zotero/storage/AX7EQ5SR/Nishimoto et al. - 2011 - Reconstructing visual experiences from brain activity evoked by natural movies.pdf:application/pdf},
}

@article{muhle-karbe_neural_2016,
	title = {Neural {Coding} for {Instruction}-{Based} {Task} {Sets} in {Human} {Frontoparietal} and {Visual} {Cortex}},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhw032},
	doi = {10.1093/cercor/bhw032},
	abstract = {Task preparation has traditionally been thought to rely upon persistent representations of instructions that permit their execution after delays. Accumulating evidence suggests, however, that accurate retention of task knowledge can be insufficient for successful performance. Here,we hypothesized that instructed facts would be organized into a task set; a temporary coding scheme that proactively tunes sensorimotor pathways according to instructions to enable highly efficient “reflex-like” performance.We devised a paradigm requiring either implementation or memorization of novel stimulus–response mapping instructions, and used multivoxel pattern analysis of neuroimaging data to compare neural coding of instructions during the pretarget phase. Although participants could retain instructions under both demands,we observed striking differences in their representation. To-be-memorized instructions could only be decoded from mid-occipital and posterior parietal cortices, consistent with previous workon visual short-termmemorystorage. In contrast, to-be-implemented instructions could also be decoded from frontoparietal “multiple-demand” regions, and dedicated visual areas, implicated in processing instructed stimuli. Neural specificity in the latter moreover correlated with performance speed only when instructions were prepared, likely reflecting the preconfiguration of instructed decision circuits. Together, these data illuminate how the brain proactively optimizes performance, and help dissociate neural mechanisms supporting task control and short-term memory storage.},
	journal = {Cerebral Cortex},
	author = {Muhle-Karbe, Paul S. and Duncan, John and De Baene, Wouter and Mitchell, Daniel J and Brass, Marcel},
	year = {2016},
	pmid = {26908634},
	keywords = {cognitive control, working memory, frontoparietal cortex, mvpa, task preparation, visual cortex},
	pages = {bhw032},
	file = {Attachment:/Users/tito/Zotero/storage/QZ96QMTU/Muhle-Karbe et al. - 2016 - Neural Coding for Instruction-Based Task Sets in Human Frontoparietal and Visual Cortex(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/XH6ZMLFL/Muhle-Karbe et al. - 2016 - Neural Coding for Instruction-Based Task Sets in Human Frontoparietal and Visual Cortex.pdf:application/pdf},
}

@article{eliasmith_biospaun:_2015,
	title = {{BioSpaun}: {A} large-scale behaving brain model with complex neurons},
	author = {Eliasmith, Chris and Duggins, Peter and Gosmann, Jan and Choo, Xuan},
	year = {2015},
	keywords = {architecture, biological cognition, conductance neurons, neural engineering framework, semantic pointer, spaun},
	file = {Attachment:/Users/tito/Zotero/storage/ES5XH5LJ/Eliasmith et al. - 2015 - BioSpaun A large-scale behaving brain model with complex neurons.pdf:application/pdf},
}

@article{stewart_large-scale_2014,
	title = {Large-scale synthesis of functional spiking neural circuits},
	volume = {102},
	issn = {00189219},
	doi = {10.1109/JPROC.2014.2306061},
	abstract = {In this paper, we review the theoretical and software tools used to construct Spaun, the first (and so far only) brain model capable of performing cognitive tasks. This tool set allowed us to configure 2.5 million simple nonlinear components (neurons) with 60 billion connections between them (synapses) such that the resulting model can perform eight different perceptual, motor, and cognitive tasks. To reverse-engineer the brain in this way, a method is needed that shows how large numbers of simple components, each of which receives thousands of inputs from other components, can be organized to perform the desired computations. We achieve this through the neural engineering framework (NEF), a mathematical theory that provides methods for systematically generating biologically plausible spiking networks to implement nonlinear and linear dynamical systems. On top of this, we propose the semantic pointer architecture (SPA), a hypothesis regarding some aspects of the organization, function, and representational resources used in the mammalian brain. We conclude by discussing Spaun, which is an example model that uses the SPA and is implemented using the NEF. Throughout, we discuss the software tool Neural ENGineering Objects (Nengo), which allows for the synthesis and simulation of neural models efficiently on the scale of Spaun, and provides support for constructing models using the NEF and the SPA. The resulting NEF/SPA/Nengo combination is a general tool set for both evaluating hypotheses about how the brain works, and for building systems that compute particular functions using neuron-like components.},
	number = {5},
	journal = {Proceedings of the IEEE},
	author = {Stewart, Terrence C. and Eliasmith, Chris},
	year = {2014},
	keywords = {Neural computation, neural engineering framework (NEF), neural modeling, neuromorphic engineering, semantic pointer architecture (SPA), Spaun, spiking neural networks},
	pages = {881--898},
	file = {Attachment:/Users/tito/Zotero/storage/MJ7Y8V95/Stewart, Eliasmith - 2014 - Large-scale synthesis of functional spiking neural circuits.pdf:application/pdf},
}

@article{fox_spontaneous_2006,
	title = {Spontaneous neuronal activity distinguishes human dorsal and ventral attention systems.},
	volume = {103},
	issn = {0027-8424},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1480402&tool=pmcentrez&rendertype=abstract},
	doi = {10.1073/pnas.0604187103},
	abstract = {On the basis of task-related imaging studies in normal human subjects, it has been suggested that two attention systems exist in the human brain: a bilateral dorsal attention system involved in top-down orienting of attention and a right-lateralized ventral attention system involved in reorienting attention in response to salient sensory stimuli. An important question is whether this functional organization emerges only in response to external attentional demands or is represented more fundamentally in the internal dynamics of brain activity. To address this question, we examine correlations in spontaneous fluctuations of the functional MRI blood oxygen level-dependent signal in the absence of task, stimuli, or explicit attentional demands. We identify a bilateral dorsal attention system and a right-lateralized ventral attention system solely on the basis of spontaneous activity. Further, we observe regions in the prefrontal cortex correlated with both systems, a potential mechanism for mediating the functional interaction between systems. These findings demonstrate that the neuroanatomical substrates of human attention persist in the absence of external events, reflected in the correlation structure of spontaneous activity.},
	number = {26},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fox, Michael D and Corbetta, Maurizio and Snyder, Abraham Z and Vincent, Justin L and Raichle, Marcus E},
	year = {2006},
	pmid = {16788060},
	keywords = {Attention, Brain Mapping, Humans, Magnetic Resonance Imaging, Prefrontal Cortex, Attention: physiology, Oxygen, Oxygen: blood, Neurons, Neurons: physiology, Prefrontal Cortex: cytology, Prefrontal Cortex: physiology},
	pages = {10046--51},
	file = {Attachment:/Users/tito/Zotero/storage/7KJD4Q4G/Fox et al. - 2006 - Spontaneous neuronal activity distinguishes human dorsal and ventral attention systems.pdf:application/pdf},
}

@article{kirst_low-dielectric-constant_2016,
	title = {Low-dielectric-constant polyimide aerogel composite films with low water uptake},
	issn = {0032-3896},
	url = {http://www.nature.com/doifinder/10.1038/pj.2016.37},
	doi = {10.1038/pj.2016.37},
	journal = {Polymer Journal},
	author = {Kirst, Christoph and Timme, Marc and Battaglia, Demian},
	year = {2016},
	pmid = {27111507},
	file = {Attachment:/Users/tito/Zotero/storage/GSC2X6DP/Kirst, Timme, Battaglia - 2016 - Low-dielectric-constant polyimide aerogel composite films with low water uptake.pdf:application/pdf},
}

@article{heinzle_topographically_2011,
	title = {Topographically specific functional connectivity between visual field maps in the human brain},
	volume = {56},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2011.02.077},
	doi = {10.1016/j.neuroimage.2011.02.077},
	abstract = {Neural activity in mammalian brains exhibits large spontaneous fluctuations whose structure reveals the intrinsic functional connectivity of the brain on many spatial and temporal scales. Between remote brain regions, spontaneous activity is organized into large-scale functional networks. To date, it has remained unclear whether the intrinsic functional connectivity between brain regions scales down to the fine detail of anatomical connections, for example the fine-grained topographic connectivity structure in visual cortex. Here, we show that fMRI signal fluctuations reveal a detailed retinotopically organized functional connectivity structure between the visual field maps of remote areas of the human visual cortex. The structured coherent fluctuations were even preserved in complete darkness when all visual input was removed. While the topographic connectivity structure was clearly visible in within hemisphere connections, the between hemisphere connectivity structure differs for representations along the vertical and horizontal meridian respectively. These results suggest a tight link between spontaneous neural activity and the fine-grained topographic connectivity pattern of the human brain. Thus, intrinsic functional connectivity reflects the detailed connectivity structure of the cortex at a fine spatial scale. It might thus be a valuable tool to complement anatomical studies of the human connectome, which is one of the keys to understand the functioning of the human brain. ?? 2011 Elsevier Inc.},
	number = {3},
	journal = {NeuroImage},
	author = {Heinzle, Jakob and Kahnt, Thorsten and Haynes, John Dylan},
	year = {2011},
	pmid = {21376818},
	pages = {1426--1436},
	file = {Attachment:/Users/tito/Zotero/storage/5YZM68V2/Heinzle, Kahnt, Haynes - 2011 - Topographically specific functional connectivity between visual field maps in the human brain.pdf:application/pdf},
}

@article{timme_high-degree_2016,
	title = {High-{Degree} {Neurons} {Feed} {Cortical} {Computations}},
	volume = {12},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1004858},
	doi = {10.1371/journal.pcbi.1004858},
	number = {5},
	journal = {PLOS Computational Biology},
	author = {Timme, Nicholas M. and Ito, Shinya and Myroshnychenko, Maxym and Nigam, Sunny and Shimono, Masanori and Yeh, Fang-Chin and Hottowy, Pawel and Litke, Alan M. and Beggs, John M.},
	year = {2016},
	pages = {e1004858},
	file = {Attachment:/Users/tito/Zotero/storage/6GJCC7Z6/Timme et al. - 2016 - High-Degree Neurons Feed Cortical Computations.pdf:application/pdf},
}

@article{corbetta_control_2002,
	title = {Control of {Goal}-{Directed} and {Stimulus}-{Driven} {Attention} in the {Brain}},
	volume = {3},
	issn = {14710048},
	url = {http://www.nature.com/doifinder/10.1038/nrn755},
	doi = {10.1038/nrn755},
	number = {3},
	journal = {Nature Reviews Neuroscience},
	author = {Corbetta, Maurizio and Shulman, Gordon L.},
	year = {2002},
	pmid = {11994752},
	pages = {215--229},
	file = {Attachment:/Users/tito/Zotero/storage/3Z7TIKQ3/Corbetta, Shulman - 2002 - Control of Goal-Directed and Stimulus-Driven Attention in the Brain.pdf:application/pdf},
}

@article{oherron_neural_2016,
	title = {Neural correlates of single-vessel haemodynamic responses in vivo},
	issn = {0028-0836},
	url = {http://www.nature.com/doifinder/10.1038/nature17965},
	doi = {10.1038/nature17965},
	journal = {Nature},
	author = {O'Herron, Philip and Chhatbar, Pratik Y. and Levy, Manuel and Shen, Zhiming and Schramm, Adrien E. and Lu, Zhongyang and Kara, Prakash},
	year = {2016},
	pages = {1--17},
}

@article{michalka_short-term_2015,
	title = {Short-{Term} {Memory} for {Space} and {Time} {Flexibly} {Recruit} {Complementary} {Sensory}-{Biased} {Frontal} {Lobe} {Attention} {Networks}},
	volume = {87},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2015.07.028},
	doi = {10.1016/j.neuron.2015.07.028},
	abstract = {The frontal lobes control wide-ranging cognitive functions; however, functional subdivisions of human frontal cortex are only coarsely mapped. Here, functional magnetic resonance imaging reveals two distinct visual-biased attention regions in lateral frontal cortex, superior precentral sulcus (sPCS) and inferior precentral sulcus (iPCS), anatomically interdigitated with two auditory-biased attention regions, transverse gyrus intersecting precentral sulcus (tgPCS) and caudal inferior frontal sulcus (cIFS). Intrinsic functional connectivity analysis demonstrates that sPCS and iPCS fall within a broad visual-attention network, while tgPCS and cIFS fall within a broad auditory-attention network. Interestingly, we observe that spatial and temporal short-term memory (STM), respectively, recruit visual and auditory attention networks in the frontal lobe, independent of sensory modality. These findings not only demonstrate that both sensory modality and information domain influence frontal lobe functional organization, they also demonstrate that spatial processing co-localizes with visual processing and that temporal processing co-localizes with auditory processing in lateral frontal cortex. Michalka et al. report four interleaved vision-biased and auditory-biased attention regions bilaterally in human lateral frontal cortex. Short-term memory for space and for time recruits the frontal visual and auditory networks, respectively across sensory modalities.},
	number = {4},
	journal = {Neuron},
	author = {Michalka, Samantha W. and Kong, Lingqiang and Rosen, Maya L. and Shinn-Cunningham, Barbara G. and Somers, David C.},
	year = {2015},
	pmid = {26291168},
	pages = {882--892},
	file = {Attachment:/Users/tito/Zotero/storage/CV2VB26Y/Michalka et al. - 2015 - Short-Term Memory for Space and Time Flexibly Recruit Complementary Sensory-Biased Frontal Lobe Attention Netwo.pdf:application/pdf},
}

@article{manor_synaptic_2001,
	title = {Synaptic depression mediates bistability in neuronal networks with recurrent inhibitory connectivity.},
	volume = {21},
	issn = {1529-2401},
	abstract = {When depressing synapses are embedded in a circuit composed of a pacemaker neuron and a neuron with no autorhythmic properties, the network can show two modes of oscillation. In one mode the synapses are mostly depressed, and the oscillations are dominated by the properties of the oscillating neuron. In the other mode, the synapses recover from depression, and the oscillations are primarily controlled by the synapses. We demonstrate the two modes of oscillation in a hybrid circuit consisting of a biological pacemaker and a model neuron, reciprocally coupled via model depressing synapses. We show that across a wide range of parameter values this network shows robust bistability of the oscillation mode and that it is possible to switch the network from one mode to the other by injection of a brief current pulse in either neuron. The underlying mechanism for bistability may be present in many types of circuits with reciprocal connections and synaptic depression.},
	number = {23},
	journal = {The Journal of Neuroscience},
	author = {Manor, Y and Nadim, Farzan},
	year = {2001},
	pmid = {11717380},
	keywords = {oscillation, crustacean, cycle period, determine the, dynamic clamp, erties of the neurons, in this mode, motor systems, or nothing to the, reciprocal inhibition, stomatogastric nervous system, that are involved primarily, the intrinsic prop-},
	pages = {9460--9470},
	file = {Attachment:/Users/tito/Zotero/storage/KXA7GLDM/Manor, Nadim - 2001 - Synaptic depression mediates bistability in neuronal networks with recurrent inhibitory connectivity.pdf:application/pdf},
}

@article{haak_connective_2013,
	title = {Connective field modeling},
	volume = {66},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2012.10.037},
	abstract = {The traditional way to study the properties of visual neurons is to measure their responses to visually presented stimuli. A second way to understand visual neurons is to characterize their responses in terms of activity elsewhere in the brain. Understanding the relationships between responses in distinct locations in the visual system is essential to clarify this network of cortical signaling pathways. Here, we describe and validate connective field modeling, a model-based analysis for estimating the dependence between signals in distinct cortical regions using functional magnetic resonance imaging (fMRI). Just as the receptive field of a visual neuron predicts its response as a function of stimulus position, the connective field of a neuron predicts its response as a function of activity in another part of the brain. Connective field modeling opens up a wide range of research opportunities to study information processing in the visual system and other topographically organized cortices. ?? 2012 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Haak, Koen V. and Winawer, Jonathan and Harvey, Ben M. and Renken, Remco and Dumoulin, Serge O. and Wandell, Brian A. and Cornelissen, Frans W.},
	year = {2013},
	pmid = {23110879},
	keywords = {Functional connectivity, FMRI, Connective field, Population receptive field, Visual cortex},
	pages = {376--384},
	file = {Attachment:/Users/tito/Zotero/storage/PFWIIJMN/Haak et al. - 2013 - Connective field modeling.pdf:application/pdf},
}

@article{geerligs_functional_2016,
	title = {Functional connectivity and structural covariance between regions of interest can be measured more accurately using multivariate distance correlation},
	volume = {135},
	issn = {1053-8119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2016.04.047},
	doi = {10.1016/j.neuroimage.2016.04.047},
	journal = {NeuroImage},
	author = {Geerligs, Linda and {Cam-CAN} and Henson, Richard N},
	year = {2016},
	pmid = {27114055},
	keywords = {Functional connectivity, Resting state, functional connectivity, Graph theory, Distance correlation, Multivariate, structural covariance, Structural covariance},
	pages = {16--31},
	file = {Attachment:/Users/tito/Zotero/storage/WWVBZVS2/Geerligs, Cam-CAN, Henson - 2016 - Functional connectivity and structural covariance between regions of interest can be measured more ac.pdf:application/pdf},
}

@article{moca_membrane_2014,
	title = {Membrane resonance enables stable and robust gamma oscillations},
	volume = {24},
	issn = {10473211},
	doi = {10.1093/cercor/bhs293},
	abstract = {Neuronal mechanisms underlying beta/gamma oscillations (20-80 Hz) are not completely understood. Here, we show that in vivo beta/gamma oscillations in the cat visual cortex sometimes exhibit remarkably stable frequency even when inputs fluctuate dramatically. Enhanced frequency stability is associated with stronger oscillations measured in individual units and larger power in the local field potential. Simulations of neuronal circuitry demonstrate that membrane properties of inhibitory interneurons strongly determine the characteristics of emergent oscillations. Exploration of networks containing either integrator or resonator inhibitory interneurons revealed that: (i) Resonance, as opposed to integration, promotes robust oscillations with large power and stable frequency via a mechanism called RING (Resonance INduced Gamma); resonance favors synchronization by reducing phase delays between interneurons and imposes bounds on oscillation cycle duration; (ii) Stability of frequency and robustness of the oscillation also depend on the relative timing of excitatory and inhibitory volleys within the oscillation cycle; (iii) RING can reproduce characteristics of both Pyramidal INterneuron Gamma (PING) and INterneuron Gamma (ING), transcending such classifications; (iv) In RING, robust gamma oscillations are promoted by slow but are impaired by fast inputs. Results suggest that interneuronal membrane resonance can be an important ingredient for generation of robust gamma oscillations having stable frequency.},
	number = {1},
	journal = {Cerebral Cortex},
	author = {Moca, Vasile V. and Nikoli??, Danko and Singer, Wolf and Mure??an, Raul C.},
	year = {2014},
	pmid = {23042733},
	keywords = {Visual cortex, ING, Oscillation frequency, PING, RING},
	pages = {119--142},
	file = {Attachment:/Users/tito/Zotero/storage/3BXTL7FP/Moca et al. - 2014 - Membrane resonance enables stable and robust gamma oscillations.pdf:application/pdf},
}

@article{izhikevich_bursts_2003,
	title = {Bursts as a unit of neural information: {Selective} communication via resonance},
	volume = {26},
	issn = {01662236},
	doi = {10.1016/S0166-2236(03)00034-1},
	abstract = {What is the functional significance of generating a burst of spikes, as opposed to a single spike? A dominant point of view is that bursts are needed to increase the reliability of communication between neurons. Here, we discuss the alternative, but complementary, hypothesis: bursts with specific resonant interspike frequencies are more likely to cause a postsynaptic cell to fire than are bursts with higher or lower frequencies. Such a frequency preference might occur at the level of individual synapses because of the interplay between short-term synaptic depression and facilitation, or at the postsynaptic cell level because of subthreshold membrane potential oscillations and resonance. As a result, the same burst could resonate for some synapses or cells and not resonate for others, depending on their natural resonance frequencies. This observation suggests that, in addition to increasing reliability of synaptic transmission, bursts of action potentials might provide effective mechanisms for selective communication between neurons.},
	number = {3},
	journal = {Trends in Neurosciences},
	author = {Izhikevich, Eugene M. and Desai, Niraj S. and Walcott, Elisabeth C. and Hoppensteadt, Frank C.},
	year = {2003},
	pmid = {12591219},
	pages = {161--167},
	file = {Attachment:/Users/tito/Zotero/storage/GWGIT78U/Izhikevich et al. - 2003 - Bursts as a unit of neural information Selective communication via resonance.pdf:application/pdf},
}

@article{brunel_is_2016,
	title = {Is cortical connectivity optimized for storing information?},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.4286},
	doi = {10.1038/nn.4286},
	number = {April},
	journal = {Nature Neuroscience},
	author = {Brunel, Nicolas},
	year = {2016},
	pmid = {27065365},
	pages = {1--9},
	file = {Attachment:/Users/tito/Zotero/storage/L89LLF4N/Brunel - 2016 - Is cortical connectivity optimized for storing information.pdf:application/pdf},
}

@article{kopell_gamma_2000,
	title = {Gamma rhythms and beta rhythms have different synchronization properties.},
	volume = {97},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/10677548},
	doi = {10.1073/pnas.97.4.1867},
	abstract = {Experimental and modeling efforts suggest that rhythms in the CA1 region of the hippocampus that are in the beta range (12-29 Hz) have a different dynamical structure than that of gamma (30-70 Hz). We use a simplified model to show that the different rhythms employ different dynamical mechanisms to synchronize, based on different ionic currents. The beta frequency is able to synchronize over long conduction delays (corresponding to signals traveling a significant distance in the brain) that apparently cannot be tolerated by gamma rhythms. The synchronization properties are consistent with data suggesting that gamma rhythms are used for relatively local computations whereas beta rhythms are used for higher level interactions involving more distant structures.},
	number = {4},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Kopell, N and Ermentrout, G B and Whittington, M A and Traub, R D},
	year = {2000},
	pmid = {10677548},
	keywords = {Models, Neurological, Animals, Cortical Synchronization, Electroencephalography, Hippocampus, Hippocampus: physiology},
	pages = {1867--1872},
	file = {Attachment:/Users/tito/Zotero/storage/RSTV38NJ/Kopell et al. - 2000 - Gamma rhythms and beta rhythms have different synchronization properties.pdf:application/pdf},
}

@article{misic_network-level_2016,
	title = {Network-{Level} {Structure}-{Function} {Relationships} in {Human} {Neocortex}},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhw089},
	doi = {10.1093/cercor/bhw089},
	journal = {Cerebral Cortex},
	author = {Mišić, Bratislav and Betzel, Richard F. and de Reus, Marcel A. and van den Heuvel, Martijn P. and Berman, Marc G. and McIntosh, Anthony R. and Sporns, Olaf},
	year = {2016},
	keywords = {network, connectome, multivariate, partial least squares},
	pages = {bhw089},
}

@article{haxby_distributed_2006,
	title = {Distributed and {Overlapping} {Representations} of {Faces} and {Objects} in {Ventral} {Temporal} {Cortex}},
	volume = {2425},
	issn = {00368075},
	doi = {10.1126/science.1063736},
	number = {2001},
	author = {Haxby, James V and Gobbini, M Ida and Furey, Maura L and Ishai, Alumit and Schouten, Jennifer L and Pietrini, Pietro},
	year = {2006},
	pmid = {11577229},
	pages = {2425--2431},
	file = {Attachment:/Users/tito/Zotero/storage/8HVIDB2K/Haxby et al. - 2006 - Distributed and Overlapping Representations of Faces and Objects in Ventral Temporal Cortex.pdf:application/pdf},
}

@article{sakamoto_increased_2013,
	title = {Increased firing irregularity as an emergent property of neural-state transition in monkey prefrontal cortex},
	volume = {8},
	issn = {19326203},
	doi = {10.1371/journal.pone.0080906},
	abstract = {Flexible behaviors are organized by complex neural networks in the prefrontal cortex. Recent studies have suggested that such networks exhibit multiple dynamical states, and can switch rapidly from one state to another. In many complex systems such as the brain, the early-warning signals that may predict whether a critical threshold for state transitions is approaching are extremely difficult to detect. We hypothesized that increases in firing irregularity are a crucial measure for predicting state transitions in the underlying neuronal circuits of the prefrontal cortex. We used both experimental and theoretical approaches to test this hypothesis. Experimentally, we analyzed activities of neurons in the prefrontal cortex while monkeys performed a maze task that required them to perform actions to reach a goal. We observed increased firing irregularity before the activity changed to encode goal-to-action information. Theoretically, we constructed theoretical generic neural networks and demonstrated that changes in neuronal gain on functional connectivity resulted in a loss of stability and an altered state of the networks, accompanied by increased firing irregularity. These results suggest that assessing the temporal pattern of neuronal fluctuations provides important clues regarding the state stability of the prefrontal network. We also introduce a novel scheme that the prefrontal cortex functions in a metastable state near the critical point of bifurcation. According to this scheme, firing irregularity in the prefrontal cortex indicates that the system is about to change its state and the flow of information in a flexible manner, which is essential for executive functions. This metastable and/or critical dynamical state of the prefrontal cortex may account for distractibility and loss of flexibility in the prefrontal cortex in major mental illnesses such as schizophrenia.},
	number = {12},
	journal = {PLoS ONE},
	author = {Sakamoto, Kazuhiro and Katori, Yuichi and Saito, Naohiro and Yoshida, Shun and Aihara, Kazuyuki and Mushiake, Hajime},
	year = {2013},
	pmid = {24349020},
	file = {Attachment:/Users/tito/Zotero/storage/PQBR2CLK/Sakamoto et al. - 2013 - Increased firing irregularity as an emergent property of neural-state transition in monkey prefrontal cortex.pdf:application/pdf},
}

@article{lee_global_2010,
	title = {Global and local {fMRI} signals driven by neurons defined optogenetically by type and wiring},
	volume = {465},
	issn = {0028-0836},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3177305&tool=pmcentrez&rendertype=abstract},
	doi = {10.1038/nature09108},
	abstract = {Despite a rapidly-growing scientific and clinical brain imaging literature based on functional magnetic resonance imaging (fMRI) using blood oxygenation level-dependent (BOLD) signals, it remains controversial whether BOLD signals in a particular region can be caused by activation of local excitatory neurons. This difficult question is central to the interpretation and utility of BOLD, with major significance for fMRI studies in basic research and clinical applications. Using a novel integrated technology unifying optogenetic control of inputs with high-field fMRI signal readouts, we show here that specific stimulation of local CaMKIIalpha-expressing excitatory neurons, either in the neocortex or thalamus, elicits positive BOLD signals at the stimulus location with classical kinetics. We also show that optogenetic fMRI (of MRI) allows visualization of the causal effects of specific cell types defined not only by genetic identity and cell body location, but also by axonal projection target. Finally, we show that of MRI within the living and intact mammalian brain reveals BOLD signals in downstream targets distant from the stimulus, indicating that this approach can be used to map the global effects of controlling a local cell population. In this respect, unlike both conventional fMRI studies based on correlations and fMRI with electrical stimulation that will also directly drive afferent and nearby axons, this of MRI approach provides causal information about the global circuits recruited by defined local neuronal activity patterns. Together these findings provide an empirical foundation for the widely-used fMRI BOLD signal, and the features of of MRI define a potent tool that may be suitable for functional circuit analysis as well as global phenotyping of dysfunctional circuitry.},
	number = {7299},
	journal = {Nature},
	author = {Lee, Jin Hyung and Durand, Remy and Gradinaru, Viviana and Zhang, Feng and Goshen, Inbal and Kim, Dae-Shik and Fenno, Lief E. and Ramakrishnan, Charu and Deisseroth, Karl},
	year = {2010},
	pmid = {20473285},
	keywords = {Brain, Cerebrovascular Circulation, Magnetic Resonance Imaging, Neural Pathways, Photic Stimulation, Motor Cortex, Animals, Oxygen, Oxygen: blood, Action Potentials, Brain: cytology, Neurons, Action Potentials: radiation effects, Anesthesia, Brain: anatomy \& histology, Brain: blood supply, Brain: radiation effects, Cerebrovascular Circulation: radiation effects, Chlorophyta, Luminescent Measurements, Luminescent Proteins, Luminescent Proteins: genetics, Luminescent Proteins: metabolism, Motor Cortex: blood supply, Motor Cortex: cytology, Motor Cortex: metabolism, Motor Cortex: radiation effects, Neural Pathways: radiation effects, Neurons: classification, Neurons: cytology, Neurons: metabolism, Neurons: radiation effects, Oxygen: metabolism, Rats, Rhodopsin, Rhodopsin: genetics, Rhodopsin: metabolism, Rhodopsin: radiation effects, Thalamus, Thalamus: blood supply, Thalamus: cytology, Thalamus: metabolism, Thalamus: radiation effects},
	pages = {788--792},
	file = {Attachment:/Users/tito/Zotero/storage/IPSFIS7F/Lee et al. - 2010 - Global and local fMRI signals driven by neurons defined optogenetically by type and wiring.pdf:application/pdf},
}

@article{siero_bold_2014,
	title = {{BOLD} matches neuronal activity at the mm scale: {A} combined {7T} {fMRI} and {ECoG} study in human sensorimotor cortex},
	volume = {101},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2014.07.002},
	doi = {10.1016/j.neuroimage.2014.07.002},
	abstract = {High resolution BOLD fMRI has the potential to map activation patterns of small neuronal populations at the scale of cortical columns. However, BOLD fMRI does not measure neuronal activity, but only a correlate thereof, since it measures blood dynamics. To confirm that BOLD activation maps reflect neuronal population activity patterns, a direct comparison with neuro-electrophysiological data from the same cortical patch is necessary. Here, we compare BOLD activation patterns obtained with fMRI at 7. T to electrophysiological patterns obtained with implanted high density electrocorticography (ECoG) grids in the same patch of human sensorimotor cortex, and with similar resolution (1.5. mm). We used high spatially sampled high-frequency broadband (HFB) power from ECoG, which reflects local neuronal population activity. The spatial distribution of 7. T BOLD activation matched the spatial distribution of ECoG HFB-power changes in the covered patch of sensorimotor cortex. BOLD fMRI activation foci were located within 1-3. mm of the HFB-power ECoG foci. Both methods distinguished individual finger movement activation within a 1. cm cortical patch, revealing a topographical medial to lateral layout for the little finger to index to thumb. These findings demonstrate that the BOLD signal at 7. T is strongly correlated with the underlying electrophysiology, and is capable of discriminating patterns of neuronal population activity at a millimeter scale. The results further indicate the utility of 7. T fMRI for investigation of intra-area organization of function and network dynamics. ?? 2014 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Siero, Jeroen C W and Hermes, Dora and Hoogduin, Hans and Luijten, Peter R. and Ramsey, Nick F. and Petridou, Natalia},
	year = {2014},
	pmid = {25026157},
	keywords = {FMRI, Somatotopy, 7 tesla, Blood-oxygenation-level-dependent (BOLD), Finger, Intracranial electrocorticography (ECoG), Sensorimotor cortex},
	pages = {177--184},
	file = {Attachment:/Users/tito/Zotero/storage/UANUK94Q/Siero et al. - 2014 - BOLD matches neuronal activity at the mm scale A combined 7T fMRI and ECoG study in human sensorimotor cortex.pdf:application/pdf},
}

@article{chen_method_2012,
	title = {A method to determine the necessity for global signal regression in resting-state {fMRI} studies},
	volume = {68},
	issn = {07403194},
	doi = {10.1002/mrm.24201},
	abstract = {In resting-state functional MRI studies, the global signal (operationally defined as the global average of resting-state functional MRI time courses) is often considered a nuisance effect and commonly removed in preprocessing. This global signal regression method can introduce artifacts, such as false anticorrelated resting-state networks in functional connectivity analyses. Therefore, the efficacy of this technique as a correction tool remains questionable. In this article, we establish that the accuracy of the estimated global signal is determined by the level of global noise (i.e., non-neural noise that has a global effect on the resting-state functional MRI signal). When the global noise level is low, the global signal resembles the resting-state functional MRI time courses of the largest cluster, but not those of the global noise. Using real data, we demonstrate that the global signal is strongly correlated with the default mode network components and has biological significance. These results call into question whether or not global signal regression should be applied. We introduce a method to quantify global noise levels. We show that a criteria for global signal regression can be found based on the method. By using the criteria, one can determine whether to include or exclude the global signal regression in minimizing errors in functional connectivity measures.},
	number = {6},
	journal = {Magnetic Resonance in Medicine},
	author = {Chen, Gang and Chen, Guangyu and Xie, Chunming and Ward, B. Douglas and Li, Wenjun and Antuono, Piero and Li, Shi Jiang},
	year = {2012},
	pmid = {22334332},
	keywords = {global noise, global signal, global signal regression, resting-state fMRI},
	pages = {1828--1835},
	file = {Attachment:/Users/tito/Zotero/storage/SWNX88W4/Chen et al. - 2012 - A method to determine the necessity for global signal regression in resting-state fMRI studies.pdf:application/pdf},
}

@article{armbruster_prefrontal_2012,
	title = {Prefrontal cortical mechanisms underlying individual differences in cognitive flexibility and stability},
	volume = {24},
	issn = {0898-929X},
	url = {papers2://publication/uuid/3708E35A-DD84-452F-8D44-F377C76BA2D5},
	doi = {10.1162/jocn_a_00286},
	abstract = {The pFC is critical for cognitive flexibility (i.e., our ability to flexibly adjust behavior to changing environmental demands), but also for cognitive stability (i.e., our ability to follow behavioral plans in the face of distraction). Behavioral research suggests that individuals differ in their cognitive flexibility and stability, and neurocomputational theories of working memory relate this variability to the concept of attractor stability in recurrently connected neural networks. We introduce a novel task paradigm to simultaneously assess flexible switching between task rules (cognitive flexibility) and task performance in the presence of irrelevant distractors (cognitive stability) and to furthermore assess the individual "spontaneous switching rate" in response to ambiguous stimuli to quantify the individual dispositional cognitive flexibility in a theoretically motivated way (i.e., as a proxy for attractor stability). Using fMRI in healthy human participants, a common network consisting of parietal and frontal areas was found for task switching and distractor inhibition. More flexible persons showed reduced activation and reduced functional coupling in frontal areas, including the inferior frontal junction, during task switching. Most importantly, the individual spontaneous switching rate antagonistically affected the functional coupling between inferior frontal junction and the superior frontal gyrus during task switching and distractor inhibition, respectively, indicating that individual differences in cognitive flexibility and stability are indeed related to a common prefrontal neural mechanism. We suggest that the concept of attractor stability of prefrontal working memory networks is a meaningful model for individual differences in cognitive stability versus flexibility.},
	number = {12},
	journal = {Journal of Cognitive Neuroscience},
	author = {Armbruster, Diana J. N. and Ueltzhöffer, Kai and Basten, Ulrike and Fiebach, Christian J.},
	year = {2012},
	pmid = {22905818},
	pages = {2385--2399},
	file = {Attachment:/Users/tito/Zotero/storage/2Y6J7DJT/Armbruster et al. - 2012 - Prefrontal cortical mechanisms underlying individual differences in cognitive flexibility and stability.pdf:application/pdf},
}

@article{durstewitz_computational_2008,
	title = {Computational significance of transient dynamics in cortical networks},
	volume = {27},
	issn = {0953816X},
	doi = {10.1111/j.1460-9568.2007.05976.x},
	abstract = {Neural responses are most often characterized in terms of the sets of environmental or internal conditions or stimuli with which their firing rate [corrected]increases or decreases are correlated [corrected] Their transient (nonstationary) temporal profiles of activity have received comparatively less attention. Similarly, the computational framework of attractor neural networks puts most emphasis on the representational or computational properties of the stable states of a neural system. Here we review a couple of neurophysiological observations and computational ideas that shift the focus to the transient dynamics of neural systems. We argue that there are many situations in which the transient neural behaviour, while hopping between different attractor states or moving along 'attractor ruins', carries most of the computational and/or behavioural significance, rather than the attractor states eventually reached. Such transients may be related to the computation of temporally precise predictions or the probabilistic transitions among choice options, accounting for Weber's law in decision-making tasks. Finally, we conclude with a more general perspective on the role of transient dynamics in the brain, promoting the view that brain activity is characterized by a high-dimensional chaotic ground state from which transient spatiotemporal patterns (metastable states) briefly emerge. Neural computation has to exploit the itinerant dynamics between these states.},
	number = {1},
	journal = {European Journal of Neuroscience},
	author = {Durstewitz, Daniel and Deco, Gustavo},
	year = {2008},
	pmid = {18093174},
	keywords = {Decision-making, Working memory, Attractors, Fluctuations, Interval time, Irregular activity, Neurodynamics},
	pages = {217--227},
	file = {Attachment:/Users/tito/Zotero/storage/U8YCSB6R/Durstewitz, Deco - 2008 - Computational significance of transient dynamics in cortical networks.pdf:application/pdf},
}

@article{shah_reliability_2016,
	title = {Reliability and reproducibility of individual differences in functional connectivity acquired during task and resting state},
	volume = {456},
	issn = {21623279},
	url = {http://doi.wiley.com/10.1002/brb3.456},
	doi = {10.1002/brb3.456},
	journal = {Brain and Behavior},
	author = {Shah, Lubdha M. and Cramer, Justin A. and Ferguson, Michael A. and Birn, Rasmus M. and Anderson, Jeffrey S.},
	year = {2016},
	keywords = {functional connectivity, resting state fmri},
	pages = {n/a--n/a},
	file = {Attachment:/Users/tito/Zotero/storage/TP6FQKM2/Shah et al. - 2016 - Reliability and reproducibility of individual differences in functional connectivity acquired during task and resti.pdf:application/pdf},
}

@article{wimmer_thalamic_2015,
	title = {Thalamic control of sensory selection in divided attention},
	volume = {526},
	issn = {0028-0836},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26503050},
	doi = {10.1038/nature15398},
	abstract = {How the brain selects appropriate sensory inputs and suppresses distractors is unknown. Given the well-established role of the prefrontal cortex (PFC) in executive function, its interactions with sensory cortical areas during attention have been hypothesized to control sensory selection. To test this idea and, more generally, dissect the circuits underlying sensory selection, we developed a cross-modal divided-attention task in mice that allowed genetic access to this cognitive process. By optogenetically perturbing PFC function in a temporally precise window, the ability of mice to select appropriately between conflicting visual and auditory stimuli was diminished. Equivalent sensory thalamocortical manipulations showed that behaviour was causally dependent on PFC interactions with the sensory thalamus, not sensory cortex. Consistent with this notion, we found neurons of the visual thalamic reticular nucleus (visTRN) to exhibit PFC-dependent changes in firing rate predictive of the modality selected. visTRN activity was causal to performance as confirmed by bidirectional optogenetic manipulations of this subnetwork. Using a combination of electrophysiology and intracellular chloride photometry, we demonstrated that visTRN dynamically controls visual thalamic gain through feedforward inhibition. Our experiments introduce a new subcortical model of sensory selection, in which the PFC biases thalamic reticular subnetworks to control thalamic sensory gain, selecting appropriate inputs for further processing.},
	number = {7575},
	journal = {Nature},
	author = {Wimmer, Ralf D. and Schmitt, L. Ian and Davidson, Thomas J. and Nakajima, Miho and Deisseroth, Karl and Halassa, Michael M.},
	year = {2015},
	pmid = {26503050},
	pages = {705--9},
	file = {Attachment:/Users/tito/Zotero/storage/EQMF5YP8/Wimmer et al. - 2015 - Thalamic control of sensory selection in divided attention.pdf:application/pdf},
}

@article{stark_when_2001,
	title = {When zero is not zero: the problem of ambiguous baseline conditions in {fMRI}.},
	volume = {98},
	issn = {00278424},
	doi = {10.1073/pnas.221462998},
	abstract = {By using blocked and rapid event-related functional MRI studies of memory, we explored the implications of using rest periods as a baseline condition in functional MRI studies. Activity in the medial temporal lobe (as well as in other brain regions) was substantially higher during rest than during several alternative baseline conditions. The effect of this elevated activity during rest was to reduce, eliminate, or even reverse the sign of the activity during task conditions relevant to memory functions. The results demonstrate that periods of rest are associated with significant cognitive activity and, therefore, provide a nonoptimal baseline for memory tasks. These results were observed not only when relatively long blocks of rest were used (experiment 1), but also when rest consisted of the short null trials typically used in rapid event-related designs (experiment 2). The findings have important implications for the design and interpretation of a wide range of fMRI studies of cognition.},
	number = {22},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Stark, C E and Squire, L R},
	year = {2001},
	pmid = {11592989},
	pages = {12760--12766},
	file = {Attachment:/Users/tito/Zotero/storage/9STBBR79/Stark, Squire - 2001 - When zero is not zero the problem of ambiguous baseline conditions in fMRI.pdf:application/pdf},
}

@article{najafi_overlapping_2016,
	title = {Overlapping communities reveal rich structure in large-scale brain networks during rest and task conditions},
	volume = {135},
	issn = {1053-8119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2016.04.054},
	doi = {10.1016/j.neuroimage.2016.04.054},
	journal = {NeuroImage},
	author = {Najafi, Mahshid and Mcmenamin, Brenton W and Simon, Jonathan Z and Pessoa, Luiz},
	year = {2016},
	pages = {92--106},
	file = {Attachment:/Users/tito/Zotero/storage/Z235HK7T/Najafi et al. - 2016 - Overlapping communities reveal rich structure in large-scale brain networks during rest and task conditions.pdf:application/pdf},
}

@article{parga_network_2007,
	title = {Network model of spontaneous activity exhibiting synchronous transitions between up and down {States}.},
	volume = {1},
	issn = {16624548},
	doi = {10.3389/neuro.01.1.1.004.2007},
	abstract = {Both in vivo and in vitro recordings indicate that neuronal membrane potentials can make spontaneous transitions between distinct up and down states. At the network level, populations of neurons have been observed to make these transitions synchronously. Although synaptic activity and intrinsic neuron properties play an important role, the precise nature of the processes responsible for these phenomena is not known. Using a computational model, we explore the interplay between intrinsic neuronal properties and synaptic fluctuations. Model neurons of the integrate-and-fire type were extended by adding a nonlinear membrane current. Networks of these neurons exhibit large amplitude synchronous spontaneous fluctuations that make the neurons jump between up and down states, thereby producing bimodal membrane potential distributions. The effect of sensory stimulation on network responses depends on whether the stimulus is applied during an up state or deeply inside a down state. External noise can be varied to modulate the network continuously between two extreme regimes in which it remains permanently in either the up or the down state.},
	number = {1},
	journal = {Frontiers in neuroscience},
	author = {Parga, Néstor and Abbott, Larry F},
	year = {2007},
	pmid = {18982119},
	keywords = {cortical dynamics, cortical network, neuronal modeling, up-down state transitions},
	pages = {57--66},
	file = {Attachment:/Users/tito/Zotero/storage/42NKTDJD/Parga, Abbott - 2007 - Network model of spontaneous activity exhibiting synchronous transitions between up and down States.pdf:application/pdf},
}

@article{mcintosh_increased_2008,
	title = {Increased brain signal variability accompanies lower behavioral variability in development},
	volume = {4},
	issn = {1553734X},
	doi = {10.1371/journal.pcbi.1000106},
	abstract = {As the brain matures, its responses become optimized. Behavioral measures show this through improved accuracy and decreased trial-to-trial variability. The question remains whether the supporting brain dynamics show a similar decrease in variability. We examined the relation between variability in single trial evoked electrical activity of the brain (measured with EEG) and performance of a face memory task in children (8-15 y) and young adults (20-33 y). Behaviorally, children showed slower, more variable response times (RT), and less accurate recognition than adults. However, brain signal variability increased with age, and showed strong negative correlations with intrasubject RT variability and positive correlations with accuracy. Thus, maturation appears to lead to a brain with greater functional variability, which is indicative of enhanced neural complexity. This variability may reflect a broader repertoire of metastable brain states and more fluid transitions among them that enable optimum responses. Our results suggest that the moment-to-moment variability in brain activity may be a critical index of the cognitive capacity of the brain.},
	number = {7},
	journal = {PLoS Computational Biology},
	author = {McIntosh, Anthony Randal and Kovacevic, Natasa and Itier, Roxane J.},
	year = {2008},
	pmid = {18604265},
	file = {Attachment:/Users/tito/Zotero/storage/T6GWZEVB/McIntosh, Kovacevic, Itier - 2008 - Increased brain signal variability accompanies lower behavioral variability in development.pdf:application/pdf},
}

@article{cole_cognitive_2007,
	title = {The cognitive control network: {Integrated} cortical regions with dissociable functions},
	volume = {37},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2007.03.071},
	doi = {10.1016/j.neuroimage.2007.03.071},
	abstract = {Consensus across hundreds of published studies indicates that the same cortical regions are involved in many forms of cognitive control. Using functional magnetic resonance imaging (fMRI), we found that these coactive regions form a functionally connected cognitive control network (CCN). Network status was identified by convergent methods, including: high inter-regional correlations during rest and task performance, consistently higher correlations within the CCN than the rest of cortex, co-activation in a visual search task, and mutual sensitivity to decision difficulty. Regions within the CCN include anterior cingulate cortex/pre-supplementary motor area (ACC/pSMA), dorsolateral prefrontal cortex (DLPFC), inferior frontal junction (IFJ), anterior insular cortex (AIC), dorsal pre-motor cortex (dPMC), and posterior parietal cortex (PPC). We used a novel visual line search task which included periods when the probe stimuli were occluded but subjects had to maintain and update working memory in preparation for the sudden appearance of a probe stimulus. The six CCN regions operated as a tightly coupled network during the 'non-occluded' portions of this task, with all regions responding to probe events. In contrast, the network was differentiated during occluded search. DLPFC, not ACC/pSMA, was involved in target memory maintenance when probes were absent, while both regions became active in preparation for difficult probes at the end of each occluded period. This approach illustrates one way in which a neuronal network can be identified, its high functional connectivity established, and its components dissociated in order to better understand the interactive and specialized internal mechanisms of that network. ?? 2007 Elsevier Inc. All rights reserved.},
	number = {1},
	journal = {NeuroImage},
	author = {Cole, Michael W. and Schneider, Walter},
	year = {2007},
	pmid = {17553704},
	pages = {343--360},
	file = {Attachment:/Users/tito/Zotero/storage/77XHME5H/Cole, Schneider - 2007 - The cognitive control network Integrated cortical regions with dissociable functions.pdf:application/pdf},
}

@article{mcdonnell_what_2009,
	title = {What is stochastic resonance? {Definitions}, misconceptions, debates, and its relevance to biology},
	volume = {5},
	issn = {1553734X},
	doi = {10.1371/journal.pcbi.1000348},
	abstract = {Stochastic resonance is said to be observed when increases in levels of unpredictable fluctuations–e.g., random noise–cause an increase in a metric of the quality of signal transmission or detection performance, rather than a decrease. This counterintuitive effect relies on system nonlinearities and on some parameter ranges being "suboptimal". Stochastic resonance has been observed, quantified, and described in a plethora of physical and biological systems, including neurons. Being a topic of widespread multidisciplinary interest, the definition of stochastic resonance has evolved significantly over the last decade or so, leading to a number of debates, misunderstandings, and controversies. Perhaps the most important debate is whether the brain has evolved to utilize random noise in vivo, as part of the "neural code". Surprisingly, this debate has been for the most part ignored by neuroscientists, despite much indirect evidence of a positive role for noise in the brain. We explore some of the reasons for this and argue why it would be more surprising if the brain did not exploit randomness provided by noise–via stochastic resonance or otherwise–than if it did. We also challenge neuroscientists and biologists, both computational and experimental, to embrace a very broad definition of stochastic resonance in terms of signal-processing "noise benefits", and to devise experiments aimed at verifying that random variability can play a functional role in the brain, nervous system, or other areas of biology.},
	number = {5},
	journal = {PLoS Computational Biology},
	author = {McDonnell, Mark D. and Abbott, Derek},
	year = {2009},
	pmid = {19562010},
	file = {Attachment:/Users/tito/Zotero/storage/BVLE62PG/McDonnell, Abbott - 2009 - What is stochastic resonance Definitions, misconceptions, debates, and its relevance to biology.pdf:application/pdf},
}

@article{garrett_blood_2010,
	title = {Blood {Oxygen} {Level}-{Dependent} {Signal} {Variability} {Is} {More} than {Just} {Noise}},
	volume = {30},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5166-09.2010},
	doi = {10.1523/JNEUROSCI.5166-09.2010},
	abstract = {Functional magnetic resonance imaging (fMRI) research often attributes blood oxygen level-dependent (BOLD) signal variance to measurement-related confounds. However, what is typically considered "noise" variance in data may be a vital feature of brain function. We examined fMRI signal variability during fixation baseline periods, and then compared SD- and mean-based spatial patterns and their relations with chronological age (20-85 years). We found that not only was the SD-based pattern robust, it differed greatly, both spatially and statistically, from the mean-based pattern. Notably, the unique age-predictive power of the SD-based pattern was more than five times that of the mean-based pattern. This reliable SD-based pattern of activity highlights an important "signal" within what is often considered measurement-related "noise." We suggest that examination of BOLD signal variability may reveal a host of novel brain-related effects not previously considered in neuroimaging research.},
	number = {14},
	journal = {Journal of Neuroscience},
	author = {Garrett, D. D. and Kovacevic, N. and McIntosh, A. R. and Grady, C. L.},
	year = {2010},
	pmid = {20371811},
	pages = {4914--4921},
	file = {Attachment:/Users/tito/Zotero/storage/BHEKHCPJ/Garrett et al. - 2010 - Blood Oxygen Level-Dependent Signal Variability Is More than Just Noise.pdf:application/pdf},
}

@article{schmiedek_relation_2009,
	title = {On the relation of mean reaction time and intraindividual reaction time variability.},
	volume = {24},
	issn = {0882-7974},
	doi = {10.1037/a0017799},
	abstract = {Researchers often statistically control for means when examining individual or age-associated differences in variances, assuming that the relation between the 2 is linear and invariant within and across individuals and age groups. We tested this assumption in the domain of working memory by applying variance-heterogeneity multilevel models to reaction times in the n-back task. Data are from the COGITO study, which comprises 101 younger and 103 older adults assessed in over 100 daily sessions. We found that relations between means and variances vary reliably across age groups and individuals, thereby contradicting the invariant linearity assumption. We argue that statistical control approaches need to be replaced by theoretical models that simultaneously estimate central tendency and dispersion of latencies and accuracies and illustrate this claim by applying the diffusion model to the same data. Finally, we note that differences in reliability between estimates for means and variances need to be considered when comparing their unique contributions to developmental outcomes.},
	number = {4},
	journal = {Psychology and aging},
	author = {Schmiedek, Florian and Lövdén, Martin and Lindenberger, Ulman},
	year = {2009},
	pmid = {20025400},
	keywords = {working memory, intraindividual variability, multilevel models, variance heterogeneity},
	pages = {841--857},
}

@article{fries_mechanism_2005,
	title = {A mechanism for cognitive dynamics: {Neuronal} communication through neuronal coherence},
	volume = {9},
	issn = {13646613},
	doi = {10.1016/j.tics.2005.08.011},
	abstract = {At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility. ?? 2005 Elsevier Ltd. All rights reserved.},
	number = {10},
	journal = {Trends in Cognitive Sciences},
	author = {Fries, Pascal},
	year = {2005},
	pmid = {16150631},
	pages = {474--480},
	file = {Attachment:/Users/tito/Zotero/storage/VVLW9GQP/Fries - 2005 - A mechanism for cognitive dynamics Neuronal communication through neuronal coherence.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/ZYLXS7MV/Fries - 2005 - A mechanism for cognitive dynamics Neuronal communication through neuronal coherence.pdf:application/pdf},
}

@article{deco_key_2009,
	title = {Key role of coupling, delay, and noise in resting brain fluctuations.},
	volume = {106},
	issn = {1091-6490},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2690605&tool=pmcentrez&rendertype=abstract},
	doi = {10.1073/pnas.0901831106},
	abstract = {A growing body of neuroimaging research has documented that, in the absence of an explicit task, the brain shows temporally coherent activity. This so-called "resting state" activity or, more explicitly, the default-mode network, has been associated with daydreaming, free association, stream of consciousness, or inner rehearsal in humans, but similar patterns have also been found under anesthesia and in monkeys. Spatiotemporal activity patterns in the default-mode network are both complex and consistent, which raises the question whether they are the expression of an interesting cognitive architecture or the consequence of intrinsic network constraints. In numerical simulation, we studied the dynamics of a simplified cortical network using 38 noise-driven (Wilson-Cowan) oscillators, which in isolation remain just below their oscillatory threshold. Time delay coupling based on lengths and strengths of primate corticocortical pathways leads to the emergence of 2 sets of 40-Hz oscillators. The sets showed synchronization that was anticorrelated at {\textbackslash}textless0.1 Hz across the sets in line with a wide range of recent experimental observations. Systematic variation of conduction velocity, coupling strength, and noise level indicate a high sensitivity of emerging synchrony as well as simulated blood flow blood oxygen level-dependent (BOLD) on the underlying parameter values. Optimal sensitivity was observed around conduction velocities of 1-2 m/s, with very weak coupling between oscillators. An additional finding was that the optimal noise level had a characteristic scale, indicating the presence of stochastic resonance, which allows the network dynamics to respond with high sensitivity to changes in diffuse feedback activity.},
	number = {25},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Deco, Gustavo and Jirsa, Viktor and McIntosh, a R and Sporns, Olaf and Kötter, Rolf},
	year = {2009},
	pmid = {19497858},
	keywords = {Noise, Brain, Brain Mapping, Animals, Brain: physiology, Rest, Macaca},
	pages = {10302--7},
	file = {Attachment:/Users/tito/Zotero/storage/ZD46N299/Deco et al. - 2009 - Key role of coupling, delay, and noise in resting brain fluctuations.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/29WM8B9S/Deco et al. - 2009 - Key role of coupling, delay, and noise in resting brain fluctuations.pdf:application/pdf},
}

@article{dubois_building_2016,
	title = {Building a {Science} of {Individual} {Differences} from {fMRI}},
	volume = {xx},
	issn = {13646613},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661316300079},
	doi = {10.1016/j.tics.2016.03.014},
	journal = {Trends in Cognitive Sciences},
	author = {Dubois, Julien and Adolphs, Ralph},
	year = {2016},
	pages = {1--19},
	file = {Attachment:/Users/tito/Zotero/storage/CUYTTWYL/Dubois, Adolphs - 2016 - Building a Science of Individual Differences from fMRI.pdf:application/pdf},
}

@article{pike_distinct_2000,
	title = {Distinct frequency preferences of different types of rat hippocampal neurones in response to oscillatory input currents.},
	volume = {529 Pt 1},
	issn = {0022-3751},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2270176&tool=pmcentrez&rendertype=abstract},
	doi = {10.1111/j.1469-7793.2000.00205.x},
	abstract = {1. Coherent network oscillations in several distinct frequency bands are seen in the hippocampus of behaving animals. To investigate how different neuronal types within this network respond to oscillatory inputs we made whole-cell current clamp recordings from three different types of neurones in the CA1 region of rat hippocampal slices: pyramidal cells, fast-spiking interneurones and horizontal interneurones, and recorded their response to sinusoidal inputs at physiologically relevant frequencies (1-100 Hz). 2. Pyramidal neurones showed firing preference to inputs at theta frequencies (range 2-7 Hz; n = 30). They showed subthreshold resonance in the same frequency range (2-7 Hz; mean 4.1 +/- 0.4 Hz; n = 19). 3. Interneurones differed in their firing properties. Horizontal interneurones in the stratum oriens showed firing preference to inputs at theta frequencies (range 1.5-10 Hz; n = 10). These interneurones also showed resonance at low frequencies (range 1-5 Hz; mean 2.4 +/- 0.5 Hz; n = 7). In contrast, fast-spiking interneurones with cell bodies in the pyramidal cell layer fired preferentially at input frequencies in the gamma band (range 30-50 Hz; n = 10/12). These interneurones showed resonance at beta-gamma frequencies (10-50 Hz; mean 26 +/- 5 Hz; n = 7/8). 4. Thus, in the hippocampus, different types of neurones have distinct frequency preferences. Therefore, in the CA1 layer of the hippocampal network, a compound oscillatory input may be segregated into distinct frequency components which are processed locally by distinct types of neurones.},
	journal = {The Journal of physiology},
	author = {Pike, F G and Goddard, R S and Suckling, J M and Ganter, P and Kasthuri, N and Paulsen, O},
	year = {2000},
	pmid = {11080262},
	keywords = {Female, Male, Nerve Net, Algorithms, Animals, Action Potentials, Action Potentials: physiology, Electrophysiology, Nerve Net: physiology, Neurons, Neurons: physiology, Hippocampus, Hippocampus: physiology, Rats, Action Potentials: drug effects, Electric Stimulation, Hippocampus: cytology, Hippocampus: drug effects, Interneurons, Interneurons: drug effects, Interneurons: physiology, Nerve Net: drug effects, Neurons: drug effects, Patch-Clamp Techniques, Pyramidal Cells, Pyramidal Cells: drug effects, Pyramidal Cells: physiology, Tetrodotoxin, Tetrodotoxin: pharmacology, Wistar},
	pages = {205--13},
	file = {Attachment:/Users/tito/Zotero/storage/QDY48C67/Pike et al. - 2000 - Distinct frequency preferences of different types of rat hippocampal neurones in response to oscillatory input curr.pdf:application/pdf},
}

@article{derrfuss_involvement_2005,
	title = {Involvement of the inferior frontal junction in cognitive control: {Meta}-analyses of switching and stroop studies},
	volume = {25},
	issn = {10659471},
	doi = {10.1002/hbm.20127},
	abstract = {There is growing evidence that a specific region in the posterior frontolateral cortex is involved intimately in cognitive control processes. This region, located in the vicinity of the junction of the inferior frontal sulcus and the inferior precentral sulcus, was termed the inferior frontal junction (IFJ). The IFJ was shown to be involved in the updating of task representations and to be activated commonly in a within-subject investigation of a task-switching paradigm, the Stroop task, and a verbal n-back task. Here, we investigate the involvement of the IFJ in cognitive control by employing a meta-analytic approach. Two quantitative meta-analyses of functional magnetic resonance imaging (fMRI) studies were conducted. One meta-analysis included frontal activations from task-switching, set-shifting, and stimulus-response (S-R) reversal studies, the other included frontal activations from color-word Stroop studies. Results showed highly significant clustering of activations in the IFJ in both analyses. These results provide strong evidence for the consistent involvement of the IFJ in both switching and Stroop paradigms. Furthermore, they support our concept of areal specialization in the frontolateral cortex, which posits that it is not only the middorsolateral part that plays an important role in cognitive control, but also the IFJ. Finally, our results demonstrate how quantitative meta-analyses can be used to test hypotheses about the involvement of specific brain regions in cognitive control.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {Derrfuss, Jan and Brass, Marcel and Neumann, Jane and Von Cramon, D. Yves},
	year = {2005},
	pmid = {15846824},
	keywords = {Executive functions, Meta-analysis, Prefrontal cortex, S-R reversal, Set shifting, Stroop task, Task switching},
	pages = {22--34},
	file = {Attachment:/Users/tito/Zotero/storage/NKXF82LV/Derrfuss et al. - 2005 - Involvement of the inferior frontal junction in cognitive control Meta-analyses of switching and stroop studies.pdf:application/pdf},
}

@article{garrett_modulation_2013,
	title = {The modulation of {BOLD} variability between cognitive states varies by age and processing speed},
	volume = {23},
	issn = {10473211},
	doi = {10.1093/cercor/bhs055},
	abstract = {Increasing evidence suggests that brain variability plays a number of important functional roles for neural systems. However, the relationship between brain variability and changing cognitive demands remains understudied. In the current study, we demonstrate experimental condition-based modulation in brain variability using functional magnetic resonance imaging. Within a sample of healthy younger and older adults, we found that blood oxygen level-dependent signal variability was an effective discriminator between fixation and external cognitive demand. Across a number of regions, brain variability increased broadly on task compared with fixation, particularly in younger and faster performing adults. Conversely, older and slower performing adults exhibited fewer changes in brain variability within and across experimental conditions and brain regions, indicating a reduction in variability-based neural specificity. Increases in brain variability on task may represent a more complex neural system capable of greater dynamic range between brain states, as well as an enhanced ability to efficiently process varying and unexpected external stimuli. The current results help establish the developmental and performance correlates of state-to-state brain variability-based transitions and offer a new line of inquiry in the study of rest versus task modes in the human brain.},
	number = {3},
	journal = {Cerebral Cortex},
	author = {Garrett, Douglas D. and Kovacevic, Natasa and McIntosh, Anthony R. and Grady, Cheryl L.},
	year = {2013},
	pmid = {22419679},
	keywords = {fMRI, brain variability, default mode, noise},
	pages = {684--693},
	file = {Attachment:/Users/tito/Zotero/storage/5ZVSASMA/Garrett et al. - 2013 - The modulation of BOLD variability between cognitive states varies by age and processing speed.pdf:application/pdf},
}

@article{mesulam_evolving_2012,
	title = {The evolving landscape of human cortical connectivity: {Facts} and inferences},
	volume = {62},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2011.12.033},
	doi = {10.1016/j.neuroimage.2011.12.033},
	abstract = {Human cognitive brain mapping is at a crossroads. On the one hand, it can access a rich data set of synaptic connectivity in the cerebral cortex of the monkey, an animal that lacks many of the complicated behaviors of interest. On the other hand, it is rapidly amassing an even richer data set on the functional map of the human cerebral cortex, but with relatively little hard data on underlying structural connectivity. This second point tends to be blurred in the current literature because of the multiple ways in which the term 'connection' is used in the context of the human brain. In some instances the term is used at a conceptual level, to designate a pathway that should be there if the behavior is to be performed. In other instances, it refers to the computational demonstration of a functional relationship, the structural basis of which is not necessarily known. A third usage is based on connections that are known to exist in the monkey and that are inferred to also exist in the human. The fourth and most direct usage involves connections structurally proven to exist in the human. These four usages have been invoked interchangeably to propose connectivistic mechanisms of human cognitive function. To enlarge the currently limited data set on structural connectivity is of considerable importance for conducting biologically more valid explorations of large-scale neurocognitive networks. This challenging goal will require histological laboratory investigations of the human brain to resume their former prominence and to play an increasingly more substantial role in brain mapping research. ?? 2011 Elsevier Inc.},
	number = {4},
	journal = {NeuroImage},
	author = {Mesulam, Marsel},
	year = {2012},
	pmid = {22209814},
	keywords = {Connectivity, Network, Heteromodal, Human brain, Paralimbic, Transmodal},
	pages = {2182--2189},
	file = {Attachment:/Users/tito/Zotero/storage/3PDHAUJL/Mesulam - 2012 - The evolving landscape of human cortical connectivity Facts and inferences.pdf:application/pdf},
}

@article{sanz_leon_virtual_2013,
	title = {The {Virtual} {Brain}: a simulator of primate brain network dynamics.},
	volume = {7},
	issn = {1662-5196},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3678125&tool=pmcentrez&rendertype=abstract},
	doi = {10.3389/fninf.2013.00010},
	abstract = {We present The Virtual Brain (TVB), a neuroinformatics platform for full brain network simulations using biologically realistic connectivity. This simulation environment enables the model-based inference of neurophysiological mechanisms across different brain scales that underlie the generation of macroscopic neuroimaging signals including functional MRI (fMRI), EEG and MEG. Researchers from different backgrounds can benefit from an integrative software platform including a supporting framework for data management (generation, organization, storage, integration and sharing) and a simulation core written in Python. TVB allows the reproduction and evaluation of personalized configurations of the brain by using individual subject data. This personalization facilitates an exploration of the consequences of pathological changes in the system, permitting to investigate potential ways to counteract such unfavorable processes. The architecture of TVB supports interaction with MATLAB packages, for example, the well known Brain Connectivity Toolbox. TVB can be used in a client-server configuration, such that it can be remotely accessed through the Internet thanks to its web-based HTML5, JS, and WebGL graphical user interface. TVB is also accessible as a standalone cross-platform Python library and application, and users can interact with the scientific core through the scripting interface IDLE, enabling easy modeling, development and debugging of the scientific kernel. This second interface makes TVB extensible by combining it with other libraries and modules developed by the Python scientific community. In this article, we describe the theoretical background and foundations that led to the development of TVB, the architecture and features of its major software components as well as potential neuroscience applications.},
	number = {June},
	journal = {Frontiers in neuroinformatics},
	author = {Sanz Leon, Paula and Knock, Stuart a and Woodman, M Marmaduke and Domide, Lia and Mersmann, Jochen and McIntosh, Anthony R and Jirsa, Viktor},
	year = {2013},
	pmid = {23781198},
	keywords = {connectome, full-brain, full-brain network model, large-scale simulation, neural masses, python, time delays, virtual brain, web platform},
	pages = {10},
	file = {Attachment:/Users/tito/Zotero/storage/U8P82VCE/Sanz Leon et al. - 2013 - The Virtual Brain a simulator of primate brain network dynamics.pdf:application/pdf},
}

@article{garrett_moment--moment_2013,
	title = {Moment-to-moment brain signal variability: {A} next frontier in human brain mapping?},
	volume = {37},
	issn = {01497634},
	url = {http://dx.doi.org/10.1016/j.neubiorev.2013.02.015},
	doi = {10.1016/j.neubiorev.2013.02.015},
	abstract = {Neuroscientists have long observed that brain activity is naturally variable from moment-to-moment, but neuroimaging research has largely ignored the potential importance of this phenomenon. An emerging research focus on within-person brain signal variability is providing novel insights, and offering highly predictive, complementary, and even orthogonal views of brain function in relation to human lifespan development, cognitive performance, and various clinical conditions. As a result, brain signal variability is evolving as a bona fide signal of interest, and should no longer be dismissed as meaningless noise when mapping the human brain. ?? 2013 Elsevier Ltd.},
	number = {4},
	journal = {Neuroscience and Biobehavioral Reviews},
	author = {Garrett, Douglas D. and Samanez-Larkin, Gregory R. and MacDonald, Stuart W S and Lindenberger, Ulman and McIntosh, Anthony R. and Grady, Cheryl L.},
	year = {2013},
	pmid = {23458776},
	keywords = {Brain signal variability, EEG, Noise, FMRI, MEG, Complexity, Dynamics},
	pages = {610--624},
	file = {Attachment:/Users/tito/Zotero/storage/9N58B4IA/Garrett et al. - 2013 - Moment-to-moment brain signal variability A next frontier in human brain mapping.pdf:application/pdf},
}

@article{hagmann_mapping_2008,
	title = {Mapping the structural core of human cerebral cortex},
	volume = {6},
	issn = {15449173},
	doi = {10.1371/journal.pbio.0060159},
	abstract = {Structurally segregated and functionally specialized regions of the human cerebral cortex are interconnected by a dense network of cortico-cortical axonal pathways. By using diffusion spectrum imaging, we noninvasively mapped these pathways within and across cortical hemispheres in individual human participants. An analysis of the resulting large-scale structural brain networks reveals a structural core within posterior medial and parietal cerebral cortex, as well as several distinct temporal and frontal modules. Brain regions within the structural core share high degree, strength, and betweenness centrality, and they constitute connector hubs that link all major structural modules. The structural core contains brain regions that form the posterior components of the human default network. Looking both within and outside of core regions, we observed a substantial correspondence between structural connectivity and resting-state functional connectivity measured in the same participants. The spatial and topological centrality of the core within cortex suggests an important role in functional integration.},
	number = {7},
	journal = {PLoS Biology},
	author = {Hagmann, Patric and Cammoun, Leila and Gigandet, Xavier and Meuli, Reto and Honey, Christopher J. and Van Wedeen, J. and Sporns, Olaf},
	year = {2008},
	pmid = {18597554},
	pages = {1479--1493},
	file = {Attachment:/Users/tito/Zotero/storage/4SWIYN7Z/Hagmann et al. - 2008 - Mapping the structural core of human cerebral cortex.pdf:application/pdf},
}

@article{deco_emerging_2011,
	title = {Emerging concepts for the dynamical organization of resting-state activity in the brain.},
	volume = {12},
	issn = {1471-003X},
	url = {http://dx.doi.org/10.1038/nrn2961},
	doi = {10.1038/nrn2961},
	abstract = {A broad body of experimental work has demonstrated that apparently spontaneous brain activity is not random. At the level of large-scale neural systems, as measured with functional MRI (fMRI), this ongoing activity reflects the organization of a series of highly coherent functional networks. These so-called resting-state networks (RSNs) closely relate to the underlying anatomical connectivity but cannot be understood in those terms alone. Here we review three large-scale neural system models of primate neocortex that emphasize the key contributions of local dynamics, signal transmission delays and noise to the emerging RSNs. We propose that the formation and dissolution of resting-state patterns reflects the exploration of possible functional network configurations around a stable anatomical skeleton.},
	number = {1},
	journal = {Nature reviews. Neuroscience},
	author = {Deco, Gustavo and Jirsa, Viktor K and McIntosh, Anthony R},
	year = {2011},
	pmid = {21170073},
	pages = {43--56},
	file = {Attachment:/Users/tito/Zotero/storage/ZH3Q4S8X/Deco, Jirsa, McIntosh - 2011 - Emerging concepts for the dynamical organization of resting-state activity in the brain.pdf:application/pdf},
}

@article{kirst_dynamic_2016,
	title = {Dynamic information routing in complex networks},
	url = {http://www.nature.com/doifinder/10.1038/ncomms11061},
	doi = {10.1038/ncomms11061},
	journal = {Nature Communications},
	author = {Kirst, Christoph and Timme, Marc and Bettaglia, Demian},
	year = {2016},
	file = {Attachment:/Users/tito/Zotero/storage/T66B75TX/Kirst, Timme, Bettaglia - 2016 - Dynamic information routing in complex networks.pdf:application/pdf},
}

@article{le_bihan_artifacts_2006,
	title = {Artifacts and pitfalls in diffusion {MRI}},
	volume = {24},
	issn = {10531807},
	doi = {10.1002/jmri.20683},
	abstract = {Although over the last 20 years diffusion MRI has become an established technique with a great impact on health care and neurosciences, like any other MRI technique it remains subject to artifacts and pitfalls. In addition to common MRI artifacts, there are specific problems that one may encounter when using MRI scanner gradient hardware for diffusion MRI, especially in terms of eddy currents and sensitivity to motion. In this article we review those artifacts and pitfalls on a qualitative basis, and introduce possible strategies that have been developed to mitigate or overcome them.},
	number = {3},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Le Bihan, Denis and Poupon, Cyril and Amadon, Alexis and Lethimonnier, Franck},
	year = {2006},
	pmid = {16897692},
	keywords = {Artifacts, Diffusion, Eddy currents, EPI, MRI physics},
	pages = {478--488},
	file = {Attachment:/Users/tito/Zotero/storage/CMQ6JKXF/Le Bihan et al. - 2006 - Artifacts and pitfalls in diffusion MRI.pdf:application/pdf},
}

@article{liu_decomposition_2013,
	title = {Decomposition of spontaneous brain activity into distinct {fMRI} co-activation patterns.},
	volume = {7},
	issn = {1662-5137},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3913885&tool=pmcentrez&rendertype=abstract},
	doi = {10.3389/fnsys.2013.00101},
	abstract = {Recent fMRI studies have shown that analysis of the human brain's spontaneous activity may provide a powerful approach to reveal its functional organization. Dedicated methods have been proposed to investigate co-variation of signals from different brain regions, with the goal of revealing neuronal networks (NNs) that may serve specialized functions. However, these analysis methods generally do not take into account a potential non-stationary (variable) interaction between brain regions, and as a result have limited effectiveness. To address this, we propose a novel analysis method that uses clustering analysis to sort and selectively average fMRI activity time frames to produce a set of co-activation patterns. Compared to the established networks extracted with conventional analysis methods, these co-activation patterns demonstrate novel network features with apparent relevance to the brain's functional organization.},
	number = {December},
	journal = {Frontiers in systems neuroscience},
	author = {Liu, Xiao and Chang, Catie and Duyn, Jeff H},
	year = {2013},
	pmid = {24550788},
	keywords = {clustering, dynamic, network dynamics, non-stationary connectivity, resting-state network},
	pages = {101},
	file = {Attachment:/Users/tito/Zotero/storage/2ISAFS2W/Liu, Chang, Duyn - 2013 - Decomposition of spontaneous brain activity into distinct fMRI co-activation patterns.pdf:application/pdf},
}

@article{anderson_tracking_2012,
	title = {Tracking problem solving by multivariate pattern analysis and {Hidden} {Markov} {Model} algorithms},
	volume = {50},
	issn = {00283932},
	url = {http://dx.doi.org/10.1016/j.neuropsychologia.2011.07.025},
	doi = {10.1016/j.neuropsychologia.2011.07.025},
	abstract = {Multivariate pattern analysis can be combined with Hidden Markov Model algorithms to track the second-by-second thinking as people solve complex problems. Two applications of this methodology are illustrated with a data set taken from children as they interacted with an intelligent tutoring system for algebra. The first "mind reading" application involves using fMRI activity to track what students are doing as they solve a sequence of algebra problems. The methodology achieves considerable accuracy at determining both what problem-solving step the students are taking and whether they are performing that step correctly. The second "model discovery" application involves using statistical model evaluation to determine how many substates are involved in performing a step of algebraic problem solving. This research indicates that different steps involve different numbers of substates and these substates are associated with different fluency in algebra problem solving. ?? 2011 Elsevier Ltd.},
	number = {4},
	journal = {Neuropsychologia},
	author = {Anderson, John R.},
	year = {2012},
	pmid = {21820455},
	keywords = {Problem solving, Multi-voxel pattern analysis, Hidden Markov Models, Intelligent tutoring systems, Model discovery},
	pages = {487--498},
	file = {Attachment:/Users/tito/Zotero/storage/WQAIVV2Q/Anderson - 2012 - Tracking problem solving by multivariate pattern analysis and Hidden Markov Model algorithms.pdf:application/pdf},
}

@article{steinmetz_eye_2014,
	title = {Eye {Movement} {Preparation} {Modulates} {Neuronal} {Responses} in {Area} {V4} {When} {Dissociated} from {Attentional} {Demands}},
	volume = {83},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2014.06.014},
	doi = {10.1016/j.neuron.2014.06.014},
	abstract = {We examined whether the preparation of saccadic eye movements, when behaviorally dissociated from covert attention, modulates activity within visual cortex. We measured single-neuron and local field potential (LFP) responses to visual stimuli in area V4 while monkeys covertly attended a stimulus at one location and prepared saccades to a potential target at another. In spite of the irrelevance of visual information at the saccade target, visual activity at that location was modulated at least as much as, and often more than, activity at the covertly attended location. Modulations of activity at the attended and saccade target locations were qualitatively similar and included increased response magnitude, stimulus selectivity, and spiking reliability, as well as increased gamma and decreased low-frequency power of LFPs. These results demonstrate that saccade preparation is sufficient to modulate visual cortical representations and suggest that the interrelationship of oculomotor and attention-related mechanisms extends to posterior visual cortex. © 2014 Elsevier Inc.},
	number = {2},
	journal = {Neuron},
	author = {Steinmetz, Nicholas A. and Moore, Tirin},
	year = {2014},
	pmid = {25033188},
	pages = {496--506},
	file = {Attachment:/Users/tito/Zotero/storage/HWNLIQBJ/Steinmetz, Moore - 2014 - Eye Movement Preparation Modulates Neuronal Responses in Area V4 When Dissociated from Attentional Demands.pdf:application/pdf},
}

@article{zirnsak_visual_2014,
	title = {Visual space is compressed in prefrontal cortex before eye movements.},
	volume = {507},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24670771},
	doi = {10.1038/nature13149},
	abstract = {We experience the visual world through a series of saccadic eye movements, each one shifting our gaze to bring objects of interest to the fovea for further processing. Although such movements lead to frequent and substantial displacements of the retinal image, these displacements go unnoticed. It is widely assumed that a primary mechanism underlying this apparent stability is an anticipatory shifting of visual receptive fields (RFs) from their presaccadic to their postsaccadic locations before movement onset. Evidence of this predictive 'remapping' of RFs has been particularly apparent within brain structures involved in gaze control. However, critically absent among that evidence are detailed measurements of visual RFs before movement onset. Here we show that during saccade preparation, rather than remap, RFs of neurons in a prefrontal gaze control area massively converge towards the saccadic target. We mapped the visual RFs of prefrontal neurons during stable fixation and immediately before the onset of eye movements, using multi-electrode recordings in monkeys. Following movements from an initial fixation point to a target, RFs remained stationary in retinocentric space. However, in the period immediately before movement onset, RFs shifted by as much as 18 degrees of visual angle, and converged towards the target location. This convergence resulted in a threefold increase in the proportion of RFs responding to stimuli near the target region. In addition, like in human observers, the population of prefrontal neurons grossly mislocalized presaccadic stimuli as being closer to the target. Our results show that RF shifts do not predict the retinal displacements due to saccades, but instead reflect the overriding perception of target space during eye movements.},
	number = {7493},
	journal = {Nature},
	author = {Zirnsak, Marc and Steinmetz, Nicholas a and Noudoost, Behrad and Xu, Kitty Z and Moore, Tirin},
	year = {2014},
	pmid = {24670771},
	keywords = {Humans, Male, Prefrontal Cortex, Models, Neurological, Animals, Visual Perception, Visual Perception: physiology, Neurons, Neurons: physiology, Prefrontal Cortex: cytology, Prefrontal Cortex: physiology, Electrodes, Fixation, Macaca mulatta, Ocular, Ocular: physiology, Retina, Retina: physiology, Saccades, Saccades: physiology, Visual Acuity, Visual Acuity: physiology, Visual Fields, Visual Fields: physiology},
	pages = {504--7},
	file = {Attachment:/Users/tito/Zotero/storage/G449MHCG/Zirnsak et al. - 2014 - Visual space is compressed in prefrontal cortex before eye movements.pdf:application/pdf},
}

@article{king_characterizing_2014,
	title = {Characterizing the dynamics of mental representations: {The} temporal generalization method},
	volume = {18},
	issn = {1879307X},
	url = {http://dx.doi.org/10.1016/j.tics.2014.01.002},
	doi = {10.1016/j.tics.2014.01.002},
	abstract = {Parsing a cognitive task into a sequence of operations is a central problem in cognitive neuroscience. We argue that a major advance is now possible owing to the application of pattern classifiers to time-resolved recordings of brain activity [electroencephalography (EEG), magnetoencephalography (MEG), or intracranial recordings]. By testing at which moment a specific mental content becomes decodable in brain activity, we can characterize the time course of cognitive codes. Most importantly, the manner in which the trained classifiers generalize across time, and from one experimental condition to another, sheds light on the temporal organization of information-processing stages. A repertoire of canonical dynamical patterns is observed across various experiments and brain regions. This method thus provides a novel way to understand how mental representations are manipulated and transformed. ?? 2014 Elsevier Ltd.},
	number = {4},
	journal = {Trends in Cognitive Sciences},
	author = {King, J. R. and Dehaene, S.},
	year = {2014},
	pmid = {24593982},
	keywords = {EEG, Decoding, MEG, Multivariate pattern analyses, Parallel processing, Serial processing, Temporal generalization},
	pages = {203--210},
	file = {Attachment:/Users/tito/Zotero/storage/Z2N3QH84/King, Dehaene - 2014 - Characterizing the dynamics of mental representations The temporal generalization method.pdf:application/pdf},
}

@article{tikidji-hamburyan_resonant_2015,
	title = {Resonant {Interneurons} {Can} {Increase} {Robustness} of {Gamma} {Oscillations}},
	volume = {35},
	issn = {0270-6474},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26609160},
	doi = {10.1523/JNEUROSCI.2601-15.2015},
	abstract = {UNLABELLED: Gamma oscillations are believed to play a critical role in in information processing, encoding, and retrieval. Inhibitory interneuronal network gamma (ING) oscillations may arise from a coupled oscillator mechanism in which individual neurons oscillate or from a population oscillator in which individual neurons fire sparsely and stochastically. All ING mechanisms, including the one proposed herein, rely on alternating waves of inhibition and windows of opportunity for spiking. The coupled oscillator model implemented with Wang-Buzsáki model neurons is not sufficiently robust to heterogeneity in excitatory drive, and therefore intrinsic frequency, to account for in vitro models of ING. Similarly, in a tightly synchronized regime, the stochastic population oscillator model is often characterized by sparse firing, whereas interneurons both in vivo and in vitro do not fire sparsely during gamma, but rather on average every other cycle. We substituted so-called resonator neural models, which exhibit class 2 excitability and postinhibitory rebound (PIR), for the integrators that are typically used. This results in much greater robustness to heterogeneity that actually increases as the average participation in spikes per cycle approximates physiological levels. Moreover, dynamic clamp experiments that show autapse-induced firing in entorhinal cortical interneurons support the idea that PIR can serve as a network gamma mechanism. Furthermore, parvalbumin-positive (PV(+)) cells were much more likely to display both PIR and autapse-induced firing than GAD2(+) cells, supporting the view that PV(+) fast-firing basket cells are more likely to exhibit class 2 excitability than other types of inhibitory interneurons. SIGNIFICANCE STATEMENT: Gamma oscillations are believed to play a critical role in information processing, encoding, and retrieval. Networks of inhibitory interneurons are thought to be essential for these oscillations. We show that one class of interneurons with an abrupt onset of firing at a threshold frequency may allow more robust synchronization in the presence of noise and heterogeneity. The mechanism for this robustness depends on the intrinsic resonance at this threshold frequency. Moreover, we show experimentally the feasibility of the proposed mechanism and suggest a way to distinguish between this mechanism and another proposed mechanism: that of a stochastic population oscillator independent of the dynamics of individual neurons.},
	number = {47},
	journal = {Journal of Neuroscience},
	author = {Tikidji-Hamburyan, R. A. and Martinez, J. J. and White, J. A. and Canavier, C. C.},
	year = {2015},
	pmid = {26609160},
	keywords = {excitability, resonance, significance statement, gamma, oscillations, synchrony, an abrupt onset of, and retrieval, be essential for these, class of interneurons with, encoding, gamma oscillations are believed, interneurons are thought to, networks of inhibitory, role in information processing, to play a critical, we show that one},
	pages = {15682--15695},
	file = {Attachment:/Users/tito/Zotero/storage/2ZG3KNCP/Tikidji-Hamburyan et al. - 2015 - Resonant Interneurons Can Increase Robustness of Gamma Oscillations.pdf:application/pdf},
}

@article{cole_prefrontal_2010,
	title = {Prefrontal {Dynamics} {Underlying} {Rapid} {Instructed} {Task} {Learning} {Reverse} with {Practice}},
	volume = {30},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1662-10.2010},
	doi = {10.1523/JNEUROSCI.1662-10.2010},
	number = {42},
	journal = {Journal of Neuroscience},
	author = {Cole, M. W. and Bagic, A. and Kass, R. and Schneider, W.},
	year = {2010},
	pages = {14245--14254},
	file = {Attachment:/Users/tito/Zotero/storage/JAVUY8M5/Cole et al. - 2010 - Prefrontal Dynamics Underlying Rapid Instructed Task Learning Reverse with Practice.pdf:application/pdf},
}

@article{rotstein_frequency_2014,
	title = {Frequency preference in two-dimensional neural models: {A} linear analysis of the interaction between resonant and amplifying currents},
	volume = {37},
	issn = {15736873},
	doi = {10.1007/s10827-013-0483-3},
	abstract = {Many neuron types exhibit preferred frequency responses in their voltage amplitude (resonance) or phase shift to subthreshold oscillatory currents, but the effect of biophysical parameters on these properties is not well understood. We propose a general framework to analyze the role of different ionic currents and their interactions in shaping the properties of impedance amplitude and phase in linearized biophysical models and demonstrate this approach in a two-dimensional linear model with two effective conductances g L and g 1 . We compute the key attributes of impedance and phase (resonance frequency and amplitude, zero-phase-frequency, selectivity, etc.) in the g L −g 1 parameter space. Using these attribute diagrams we identify two basic mechanisms for the generation of resonance: an increase in the resonance amplitude as g 1 increases while the overall impedance is decreased, and an increase in the maximal impedance, without any change in the input resistance, as the ionic current time constant increases. We use the attribute diagrams to analyze resonance and phase of the linearization of two biophysical models that include resonant (I h or slow potassium) and amplifying currents (persistent sodium). In the absence of amplifying currents, the two models behave similarly as the conductances of the resonant currents is increased whereas, with the amplifying current present, the two models have qualitatively opposite responses. This work provides a general method for decoding the effect of biophysical parameters on linear membrane resonance and phase by tracking trajectories, parametrized by the relevant biophysical parameter, in pre-constructed attribute diagrams.},
	number = {1},
	journal = {Journal of Computational Neuroscience},
	author = {Rotstein, Horacio G. and Nadim, Farzan},
	year = {2014},
	pmid = {24254440},
	keywords = {Resonance, Impedance, Model neuron, Subthreshold oscillations, Zero phase frequency},
	pages = {9--28},
	file = {Attachment:/Users/tito/Zotero/storage/76ASIM6I/Rotstein, Nadim - 2014 - Frequency preference in two-dimensional neural models A linear analysis of the interaction between resonant and.pdf:application/pdf},
}

@article{nili_toolbox_2014,
	title = {A {Toolbox} for {Representational} {Similarity} {Analysis}},
	volume = {10},
	issn = {15537358},
	doi = {10.1371/journal.pcbi.1003553},
	abstract = {Neuronal population codes are increasingly being investigated with multivariate pattern-information analyses. A key challenge is to use measured brain-activity patterns to test computational models of brain information processing. One approach to this problem is representational similarity analysis (RSA), which characterizes a representation in a brain or computational model by the distance matrix of the response patterns elicited by a set of stimuli. The representational distance matrix encapsulates what distinctions between stimuli are emphasized and what distinctions are de-emphasized in the representation. A model is tested by comparing the representational distance matrix it predicts to that of a measured brain region. RSA also enables us to compare representations between stages of processing within a given brain or model, between brain and behavioral data, and between individuals and species. Here, we introduce a Matlab toolbox for RSA. The toolbox supports an analysis approach that is simultaneously data- and hypothesis-driven. It is designed to help integrate a wide range of computational models into the analysis of multichannel brain-activity measurements as provided by modern functional imaging and neuronal recording techniques. Tools for visualization and inference enable the user to relate sets of models to sets of brain regions and to statistically test and compare the models using nonparametric inference methods. The toolbox supports searchlight-based RSA, to continuously map a measured brain volume in search of a neuronal population code with a specific geometry. Finally, we introduce the linear-discriminant t value as a measure of representational discriminability that bridges the gap between linear decoding analyses and RSA. In order to demonstrate the capabilities of the toolbox, we apply it to both simulated and real fMRI data. The key functions are equally applicable to other modalities of brain-activity measurement. The toolbox is freely available to the community under an open-source license agreement (http://www.mrc-cbu.cam.ac.uk/methods-and-resources/toolboxes/license/).},
	number = {4},
	journal = {PLoS Computational Biology},
	author = {Nili, Hamed and Wingfield, Cai and Walther, Alexander and Su, Li and Marslen-Wilson, William and Kriegeskorte, Nikolaus},
	year = {2014},
	pmid = {24743308},
	file = {Attachment:/Users/tito/Zotero/storage/Z8PJ9BWH/Nili et al. - 2014 - A Toolbox for Representational Similarity Analysis.pdf:application/pdf},
}

@article{shine_estimation_2015,
	title = {Estimation of dynamic functional connectivity using {Multiplication} of {Temporal} {Derivatives}},
	volume = {122},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2015.07.064},
	doi = {10.1016/j.neuroimage.2015.07.064},
	abstract = {Functional connectivity provides an informative and powerful framework for exploring brain organization. Despite this, few statistical methods are available for the accurate estimation of dynamic changes in functional network architecture. To date, the majority of existing statistical techniques have assumed that connectivity structure is stationary, which is in direct contrast to emerging data that suggests that the strength of connectivity between regions is variable over time. Therefore, the development of statistical methods that enable exploration of dynamic changes in functional connectivity is currently of great importance to the neuroscience community. In this paper, we introduce the 'Multiplication of Temporal Derivatives' (MTD) and then demonstrate the utility of this metric to: (i) detect dynamic changes in connectivity using data from a novel state-switching simulation; (ii) accurately estimate graph structure in a previously-described 'ground-truth' simulated dataset; and (iii) identify task-driven alterations in functional connectivity. We show that the MTD is more sensitive than existing sliding-window methods in detecting dynamic alterations in connectivity structure across a range of correlation strengths and window lengths in simulated data. In addition to the temporal precision offered by MTD, we demonstrate that the metric is also able to accurately estimate stationary network structure in both simulated and real task-based data, suggesting that the method may be used to identify dynamic changes in network structure as they evolve through time.},
	journal = {NeuroImage},
	author = {Shine, James M. and Koyejo, Oluwasanmi and Bell, Peter T. and Gorgolewski, Krzysztof J. and Gilat, Moran and Poldrack, Russell A.},
	year = {2015},
	pmid = {26231247},
	pages = {399--407},
	file = {Attachment:/Users/tito/Zotero/storage/6EUD93M5/Shine et al. - 2015 - Estimation of dynamic functional connectivity using Multiplication of Temporal Derivatives.pdf:application/pdf},
}

@article{stokes_activity-silent_2015,
	title = {‘{Activity}-silent' working memory in prefrontal cortex: a dynamic coding framework},
	volume = {19},
	issn = {13646613},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661315001023},
	doi = {10.1016/j.tics.2015.05.004},
	abstract = {Working memory (WM) provides the functional backbone to high-level cognition. Maintenance in WM is often assumed to depend on the stationary persistence of neural activity patterns that represent memory content. However, accumulating evidence suggests that persistent delay activity does not always accompany WM maintenance but instead seems to wax and wane as a function of the current task relevance of memoranda. Furthermore, new methods for measuring and analysing population-level patterns show that activity states are highly dynamic. At first glance, these dynamics seem at odds with the very nature of WM. How can we keep a stable thought in mind while brain activity is constantly changing? This review considers how neural dynamics might be functionally important for WM maintenance.},
	number = {7},
	journal = {Trends in Cognitive Sciences},
	author = {Stokes, Mark G.},
	year = {2015},
	pmid = {26051384},
	pages = {394--405},
}

@article{catterall_hodgkin-huxley_2012,
	title = {The {Hodgkin}-{Huxley} {Heritage}: {From} {Channels} to {Circuits}},
	volume = {32},
	issn = {0270-6474},
	doi = {10.1523/JNEUROSCI.3403-12.2012},
	abstract = {The Hodgkin-Huxley studies of the action potential, published 60 years ago, are a central pillar of modern neuroscience research, ranging from molecular investigations of the structural basis of ion channel function to the computational implications at circuit level. In this Symposium Review, we aim to demonstrate the ongoing impact of Hodgkin's and Huxley's ideas. The Hodgkin-Huxley model established a framework in which to describe the structural and functional properties of ion channels, including the mechanisms of ion permeation, selectivity, and gating. At a cellular level, the model is used to understand the conditions that control both the rate and timing of action potentials, essential for neural encoding of information. Finally, the Hodgkin-Huxley formalism is central to computational neuroscience to understand both neuronal integration and circuit level information processing, and how these mechanisms might have evolved to minimize energy cost.},
	number = {41},
	journal = {The Journal of Neuroscience},
	author = {Catterall, W. a. and Raman, I. M. and Robinson, H. P. C. and Sejnowski, T. J. and Paulsen, O.},
	year = {2012},
	pmid = {23055474},
	pages = {14064--14073},
	file = {Attachment:/Users/tito/Zotero/storage/52VFGE7E/Catterall et al. - 2012 - The Hodgkin-Huxley Heritage From Channels to Circuits.pdf:application/pdf},
}

@article{hanke_pymvpa_2009,
	title = {{PyMVPA} : a unifying approach to the analysis of neuroscientific data},
	volume = {3},
	issn = {16625196},
	doi = {10.3389/neuro.11.003.2009},
	number = {February},
	journal = {Neuroinformatics},
	author = {Hanke, Michael and Halchenko, Yaroslav O and Sederberg, Per B and Olivetti, Emanuele and Fründ, Ingo and Garcia, Samuel and Claude, Université},
	year = {2009},
	keywords = {machine learning, functional magnetic resonance imaging, python, electroencephalography, extracellular, magnetoencephalography, recordings},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/EQX6IKHB/Hanke et al. - 2009 - PyMVPA a unifying approach to the analysis of neuroscientific data.pdf:application/pdf},
}

@article{guntupalli_model_2016,
	title = {A {Model} of {Representational} {Spaces} in {Human} {Cortex}},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhw068},
	doi = {10.1093/cercor/bhw068},
	journal = {Cerebral Cortex},
	author = {Guntupalli, J. Swaroop and Hanke, Michael and Halchenko, Yaroslav O. and Connolly, Andrew C. and Ramadge, Peter J. and Haxby, James V.},
	year = {2016},
	pmid = {26980615},
	keywords = {functional magnetic resonance imaging, fmri, multivariate pattern analysis, decoding, representational similarity analysis, mvpa, hyperalignment, neural, rsa},
	pages = {bhw068},
	file = {Attachment:/Users/tito/Zotero/storage/QYCY9AYA/Guntupalli et al. - 2016 - A Model of Representational Spaces in Human Cortex.pdf:application/pdf},
}

@article{herweg_theta-alpha_2016,
	title = {Theta-{Alpha} {Oscillations} {Bind} the {Hippocampus}, {Prefrontal} {Cortex}, and {Striatum} during {Recollection}: {Evidence} from {Simultaneous} {EEG}-{fMRI}},
	volume = {36},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3629-15.2016},
	doi = {10.1523/JNEUROSCI.3629-15.2016},
	number = {12},
	journal = {Journal of Neuroscience},
	author = {Herweg, N. A. and Apitz, T. and Leicht, G. and Mulert, C. and Fuentemilla, L. and Bunzeck, N.},
	year = {2016},
	pmid = {27013686},
	keywords = {hippocampus, fmri, eeg, significance statement, striatum, humans, investigate this phenomenon in, large-scale network centered on, low-frequency oscillations are supposed, of information across a, pocampus, recollection, the electrophysiological means to, the hip-, theta-alpha, to drive the binding, which supports mnemonic functions},
	pages = {3579--3587},
	file = {Attachment:/Users/tito/Zotero/storage/XR3YKJSR/Herweg et al. - 2016 - Theta-Alpha Oscillations Bind the Hippocampus, Prefrontal Cortex, and Striatum during Recollection Evidence from.pdf:application/pdf},
}

@article{armbruster-genc_brain_2016,
	title = {Brain {Signal} {Variability} {Differentially} {Affects} {Cognitive} {Flexibility} and {Cognitive} {Stability}},
	volume = {36},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2517-14.2016},
	doi = {10.1523/JNEUROSCI.2517-14.2016},
	number = {14},
	journal = {Journal of Neuroscience},
	author = {Armbruster-Genc, D. J. N. and Ueltzhoffer, K. and Fiebach, C. J.},
	year = {2016},
	keywords = {fmri, significance statement, variability, and suggested that this, behavioral variability, bold-signal variability, cognitive flexibility, cognitive stability, computational models of prefrontal, different, effects of variability for, improves performance, neural networks predict differential, recent neuroscientific research showed, signal is intrinsically variable, that the human brain},
	pages = {3978--3987},
	file = {Attachment:/Users/tito/Zotero/storage/HJHE74KV/Armbruster-Genc, Ueltzhoffer, Fiebach - 2016 - Brain Signal Variability Differentially Affects Cognitive Flexibility and Cognitive Stabi.pdf:application/pdf},
}

@article{haxby_common_2011,
	title = {A common, high-dimensional model of the representational space in human ventral temporal cortex},
	volume = {72},
	issn = {08966273},
	doi = {10.1016/j.neuron.2011.08.026},
	abstract = {We present a high-dimensional model of the representational space in human ventral temporal (VT) cortex in which dimensions are response-tuning functions that are common across individuals and patterns of response are modeled as weighted sums of basis patterns associated with these response tunings. We map response-pattern vectors, measured with fMRI, from individual subjects' voxel spaces into this common model space using a new method, " hyperalignment." Hyperalignment parameters based on responses during one experiment-movie viewing-identified 35 common response-tuning functions that captured fine-grained distinctions among a wide range of stimuli in the movie and in two category perception experiments. Between-subject classification (BSC, multivariate pattern classification based on other subjects' data) of response-pattern vectors in common model space greatly exceeded BSC of anatomically aligned responses and matched within-subject classification. Results indicate that population codes for complex visual stimuli in VT cortex are based on response-tuning functions that are common across individuals. © 2011 Elsevier Inc.},
	number = {2},
	journal = {Neuron},
	author = {Haxby, James V. and Guntupalli, J. Swaroop and Connolly, Andrew C. and Halchenko, Yaroslav O. and Conroy, Bryan R. and Gobbini, M. Ida and Hanke, Michael and Ramadge, Peter J.},
	year = {2011},
	pmid = {22017997},
	pages = {404--416},
	file = {Attachment:/Users/tito/Zotero/storage/TEYD53AH/Haxby et al. - 2011 - A common, high-dimensional model of the representational space in human ventral temporal cortex.pdf:application/pdf},
}

@article{haxby_decoding_2014,
	title = {Decoding {Neural} {Representational} {Spaces} {Using} {Multivariate} {Pattern} {Analysis}.},
	issn = {1545-4126},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25002277},
	doi = {10.1146/annurev-neuro-062012-170325},
	abstract = {A major challenge for systems neuroscience is to break the neural code. Computational algorithms for encoding information into neural activity and extracting information from measured activity afford understanding of how percepts, memories, thought, and knowledge are represented in patterns of brain activity. The past decade and a half has seen significant advances in the development of methods for decoding human neural activity, such as multivariate pattern classification, representational similarity analysis, hyperalignment, and stimulus-model-based encoding and decoding. This article reviews these advances and integrates neural decoding methods into a common framework organized around the concept of high-dimensional representational spaces. Expected final online publication date for the Annual Review of Neuroscience Volume 37 is July 08, 2014. Please see http://www.annualreviews.org/catalog/pubdates.aspx for revised estimates.},
	number = {June},
	journal = {Annual review of neuroscience},
	author = {Haxby, James V and Connolly, Andrew C and Guntupalli, J Swaroop},
	year = {2014},
	pmid = {25002277},
	keywords = {neural decoding, fmri, mvpa, hyperalignment, rsa, population response},
	pages = {435--456},
	file = {Attachment:/Users/tito/Zotero/storage/4YHEJ6UP/Haxby, Connolly, Guntupalli - 2014 - Decoding Neural Representational Spaces Using Multivariate Pattern Analysis.pdf:application/pdf},
}

@article{tsvetanov_extrinsic_2016,
	title = {Extrinsic and {Intrinsic} {Brain} {Network} {Connectivity} {Maintains} {Cognition} across the {Lifespan} {Despite} {Accelerated} {Decay} of {Regional} {Brain} {Activation}},
	volume = {36},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2733-15.2016},
	doi = {10.1523/JNEUROSCI.2733-15.2016},
	number = {11},
	journal = {Journal of Neuroscience},
	author = {Tsvetanov, K. A. and Henson, R. N. A. and Tyler, L. K. and Razi, A. and Geerligs, L. and Ham, T. E. and Rowe, J. B.},
	year = {2016},
	pmid = {26985024},
	keywords = {fmri, significance statement, resting-state networks, we, 18, 88 years, across the lifespan, aging, basis of cognitive function, between-, cohort, critical to successful aging, cross-spectral dynamic causal modelling, maintaining cognitive function is, n ϭ 602, salience network, separating neural connectivity from, studied a large population-based, to study the neural, vascular components of, within-network},
	pages = {3115--3126},
	file = {Attachment:/Users/tito/Zotero/storage/CQ9WM7F9/Tsvetanov et al. - 2016 - Extrinsic and Intrinsic Brain Network Connectivity Maintains Cognition across the Lifespan Despite Accelerated.pdf:application/pdf},
}

@book{merabet_activation_2009,
	title = {Activation of the visual cortex by {Braille} reading in blind subjects},
	isbn = {978-0-19-172392-6},
	abstract = {Primary visual cortex receives visual input from the eyes through the lateral geniculate nuclei, but is not known to receive input from other sensory modalities. Its level of activity, both at rest and during auditory or tactile tasks, is higher in blind subjects than in normal controls, suggesting that it can subserve nonvisual functions; however, a direct effect of non-visual tasks on activation has not been demonstrated. To determine whether the visual cortex receives input from the somatosensory system we used positron emission tomography (PET) to measure activation during tactile discrimination tasks in normal subjects and in Braille readers blinded in early life. Blind subjects showed activation of primary and secondary visual cortical areas during tactile tasks, whereas normal controls showed deactivation. A simple tactile stimulus that did not require discrimination produced no activation of visual areas in either group. Thus in blind subjects, cortical areas normally reserved for vision may be activated by other sensory modalities.},
	author = {Merabet, Lotfi B. and Amedi, Amir and Pascual-Leone, Alvaro},
	year = {2009},
	doi = {10.1093/acprof:oso/9780198528999.003.0022},
	pmid = {8606771},
	keywords = {BlIndness, Imaging studies, Occipital cortex, Stimuli},
	file = {Attachment:/Users/tito/Zotero/storage/EA5QM9XV/Merabet, Amedi, Pascual-Leone - 2009 - Activation of the visual cortex by Braille reading in blind subjects.pdf:application/pdf},
}

@article{feng_multitasking_2014,
	title = {Multitasking versus multiplexing: {Toward} a normative account of limitations in the simultaneous execution of control-demanding behaviors},
	volume = {14},
	issn = {1531-135X},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24481850},
	doi = {10.3758/s13415-013-0236-9},
	abstract = {Why is it that behaviors that rely on control, so striking in their diversity and flexibility, are also subject to such striking limitations? Typically, people cannot engage in more than a few-and usually only a single-control-demanding task at a time. This limitation was a defining element in the earliest conceptualizations of controlled processing; it remains one of the most widely accepted axioms of cognitive psychology, and is even the basis for some laws (e.g., against the use of mobile devices while driving). Remarkably, however, the source of this limitation is still not understood. Here, we examine one potential source of this limitation, in terms of a trade-off between the flexibility and efficiency of representation ("multiplexing") and the simultaneous engagement of different processing pathways ("multitasking"). We show that even a modest amount of multiplexing rapidly introduces cross-talk among processing pathways, thereby constraining the number that can be productively engaged at once. We propose that, given the large number of advantages of efficient coding, the human brain has favored this over the capacity for multitasking of control-demanding processes.},
	number = {1},
	journal = {Cogn Affect Behav Neurosci},
	author = {Feng, S F and Schwemmer, M and Gershman, S J and Cohen, J D},
	year = {2014},
	pmid = {24481850},
	keywords = {computational model, capacity constraint},
	pages = {129--146},
	file = {Attachment:/Users/tito/Zotero/storage/APC9CHZ4/Feng et al. - 2014 - Multitasking versus multiplexing Toward a normative account of limitations in the simultaneous execution of control.pdf:application/pdf},
}

@article{gilson_estimation_2016,
	title = {Estimation of {Directed} {Effective} {Connectivity} from {fMRI} {Functional} {Connectivity} {Hints} at {Asymmetries} in {Cortical} {Connectome}},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1004762},
	abstract = {The brain exhibits complex spatio-temporal patterns of activity. This phenomenon is governed by an interplay between the internal neural dynamics of cortical areas and their connectivity. Uncovering this complex relationship has raised much interest, both for theory and the interpretation of experimental data (e.g., fMRI recordings) using dynamical models. Here we focus on the so-called inverse problem: the inference of network parameters in a cortical model to reproduce empirically observed activity. Although it has received a lot of interest, recovering directed connectivity for large networks has been rather unsuccessful so far. The present study specifically addresses this point for a noise-diffusion network model. We develop a Lyapunov optimization that iteratively tunes the network connectivity in order to reproduce second-order moments of the node activity, or functional connectivity. We show theoretically and numerically that the use of covariances with both zero and non-zero time shifts is the key to infer directed connectivity. The first main theoretical finding is that an accurate estimation of the underlying network connectivity requires that the time shift for covariances is matched with the time constant of the dynamical system. In addition to the network connectivity, we also adjust the intrinsic noise received by each network node. The framework is applied to experimental fMRI data recorded for subjects at rest. Diffusion-weighted MRI data provide an estimate of anatomical connections, which is incorporated to constrain the cortical model. The empirical covariance structure is reproduced faithfully, especially its temporal component (i.e., time-shifted covariances) in addition to the spatial component that is usually the focus of studies. We find that the cortical interactions, referred to as effective connectivity, in the tuned model are not reciprocal. In particular, hubs are either receptors or feeders: they do not exhibit both strong incoming and outgoing connections. Our results sets a quantitative ground to explore the propagation of activity in the cortex.},
	journal = {PLoS computational biology},
	author = {Gilson, Matthieu and Moreno-Bote, Ruben and Ponce-Alvarez, Adrián and Ritter, Petra and Deco, Gustavo},
	year = {2016},
	pmid = {26982185},
	pages = {1--30},
	file = {Attachment:/Users/tito/Zotero/storage/DBGGSTVD/Gilson et al. - 2016 - Estimation of Directed Effective Connectivity from fMRI Functional Connectivity Hints at Asymmetries in Cortical.pdf:application/pdf},
}

@article{gu_controllability_2015,
	title = {Controllability of structural brain networks},
	volume = {6},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms9414},
	doi = {10.1038/ncomms9414},
	abstract = {Cognitive function is driven by dynamic interactions between large-scale neural circuits or networks, enabling behaviour. However, fundamental principles constraining these dynamic network processes have remained elusive. Here we use tools from control and network theories to offer a mechanistic explanation for how the brain moves between cognitive states drawn from the network organization of white matter microstructure. Our results suggest that densely connected areas, particularly in the default mode system, facilitate the movement of the brain to many easily reachable states. Weakly connected areas, particularly in cognitive control systems, facilitate the movement of the brain to difficult-to-reach states. Areas located on the boundary between network communities, particularly in attentional control systems, facilitate the integration or segregation of diverse cognitive systems. Our results suggest that structural network differences between cognitive circuits dictate their distinct roles in controlling trajectories of brain network function.},
	journal = {Nature Communications},
	author = {Gu, Shi and Pasqualetti, Fabio and Cieslak, Matthew and Telesford, Qawi K. and Yu, Alfred B. and Kahn, Ari E. and Medaglia, John D. and Vettel, Jean M. and Miller, Michael B. and Grafton, Scott T. and Bassett, Danielle S.},
	year = {2015},
	pmid = {26423222},
	pages = {8414},
	file = {Attachment:/Users/tito/Zotero/storage/WMHFGY9L/Gu et al. - 2015 - Controllability of structural brain networks.pdf:application/pdf},
}

@article{berenyi_closed-loop_2012,
	title = {Closed-loop control of epilepsy by transcranial electrical stimulation.},
	volume = {337},
	issn = {1095-9203},
	url = {http://science.sciencemag.org/content/337/6095/735.abstract},
	doi = {10.1126/science.1223154},
	abstract = {Many neurological and psychiatric diseases are associated with clinically detectable, altered brain dynamics. The aberrant brain activity, in principle, can be restored through electrical stimulation. In epilepsies, abnormal patterns emerge intermittently, and therefore, a closed-loop feedback brain control that leaves other aspects of brain functions unaffected is desirable. Here, we demonstrate that seizure-triggered, feedback transcranial electrical stimulation (TES) can dramatically reduce spike-and-wave episodes in a rodent model of generalized epilepsy. Closed-loop TES can be an effective clinical tool to reduce pathological brain patterns in drug-resistant patients.},
	number = {6095},
	journal = {Science (New York, N.Y.)},
	author = {Berényi, Antal and Belluscio, Mariano and Mao, Dun and Buzsáki, György},
	year = {2012},
	pmid = {22879515},
	keywords = {Cerebral Cortex, Male, Animals, Rats, Thalamus, Electric Stimulation, Electrodes, Absence, Absence: physiopathology, Absence: therapy, Brain Waves, Cerebral Cortex: physiopathology, Deep Brain Stimulation, Epilepsy, Feedback, Implanted, Long-Evans, Physiological, Thalamus: physiopathology},
	pages = {735--7},
}

@article{johnen_causal_2015,
	title = {Causal manipulation of functional connectivity in a specific neural pathway during behaviour and at rest},
	volume = {2015},
	issn = {2050084X},
	doi = {10.7554/eLife.04585},
	abstract = {Correlations in brain activity between two areas (functional connectivity) have been shown to relate to their underlying structural connections. We examine the possibility that functional connectivity also reflects short-term changes in synaptic efficacy. We demonstrate that paired transcranial magnetic stimulation (TMS) near ventral premotor cortex (PMv) and primary motor cortex (M1) with a short 8-ms inter-pulse interval evoking synchronous pre- and post-synaptic activity and which strengthens interregional connectivity between the two areas in a pattern consistent with Hebbian plasticity, leads to increased functional connectivity between PMv and M1 as measured with functional magnetic resonance imaging (fMRI). Moreover, we show that strengthening connectivity between these nodes has effects on a wider network of areas, such as decreasing coupling in a parallel motor programming stream. A control experiment revealed that identical TMS pulses at identical frequencies caused no change in fMRI-measured functional connectivity when the inter-pulse-interval was too long for Hebbian-like plasticity.},
	number = {4},
	journal = {eLife},
	author = {Johnen, Vanessa M. and Neubert, Franz Xaver and Buch, Ethan R. and Verhagen, Lennart M. and O???Reilly, Jill and Mars, Rogier B. and Rushworth, Matthew F S},
	year = {2015},
	pmid = {25664941},
	pages = {1--23},
	file = {Attachment:/Users/tito/Zotero/storage/QQ4AS24J/Johnen et al. - 2015 - Causal manipulation of functional connectivity in a specific neural pathway during behaviour and at rest.pdf:application/pdf},
}

@article{wang_gamma_1996,
	title = {Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network model.},
	volume = {16},
	issn = {0270-6474},
	doi = {citeulike-article-id:134404},
	abstract = {Fast neuronal oscillations (gamma, 20-80 Hz) have been observed in the neocortex and hippocampus during behavioral arousal. Using computer simulations, we investigated the hypothesis that such rhythmic activity can emerge in a random network of interconnected GABAergic fast-spiking interneurons. Specific conditions for the population synchronization, on properties of single cells and the circuit, were identified. These include the following: (1) that the amplitude of spike afterhyperpolarization be above the GABAA synaptic reversal potential; (2) that the ratio between the synaptic decay time constant and the oscillation period be sufficiently large; (3) that the effects of heterogeneities be modest because of a steep frequency-current relationship of fast-spiking neurons. Furthermore, using a population coherence measure, based on coincident firings of neural pairs, it is demonstrated that large-scale network synchronization requires a critical (minimal) average number of synaptic contacts per cell, which is not sensitive to the network size. By changing the GABAA synaptic maximal conductance, synaptic decay time constant, or the mean external excitatory drive to the network, the neuronal firing frequencies were gradually and monotonically varied. By contrast, the network synchronization was found to be high only within a frequency band coinciding with the gamma (20-80 Hz) range. We conclude that the GABAA synaptic transmission provides a suitable mechanism for synchronized gamma oscillations in a sparsely connected network of fast-spiking interneurons. In turn, the interneuronal network can presumably maintain subthreshold oscillations in principal cell populations and serve to synchronize discharges of spatially distributed neurons.},
	number = {20},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Wang, X J and Buzsáki, G},
	year = {1996},
	pmid = {8815919},
	keywords = {hippocampus, synchronization, gamma rhythm, interneurons, 1992, chen and, computer model, epsps and ipsps phase-locked, gaba a, jagadeesh et al, pyramidal cells revealed both, the field oscillation frequencies, to},
	pages = {6402--6413},
}

@article{fell_role_2011,
	title = {The role of phase synchronization in memory processes.},
	volume = {12},
	issn = {1471-0048},
	shorttitle = {Nat {Rev} {Neurosci}},
	url = {http://dx.doi.org/10.1038/nrn2979},
	doi = {10.1038/nrn2979},
	abstract = {In recent years, studies ranging from single-unit recordings in animals to electroencephalography and magnetoencephalography studies in humans have demonstrated the pivotal role of phase synchronization in memory processes. Phase synchronization - here referring to the synchronization of oscillatory phases between different brain regions - supports both working memory and long-term memory and acts by facilitating neural communication and by promoting neural plasticity. There is evidence that processes underlying working and long-term memory might interact in the medial temporal lobe. We propose that this is accomplished by neural operations involving phase-phase and phase-amplitude synchronization. A deeper understanding of how phase synchronization supports the flexibility of and interaction between memory systems may yield new insights into the functions of phase synchronization in general.},
	number = {2},
	journal = {Nature reviews. Neuroscience},
	author = {Fell, Juergen and Axmacher, Nikolai},
	month = feb,
	year = {2011},
	pmid = {21248789},
	keywords = {Humans, Nerve Net, Animals, Nerve Net: physiology, Memory, Neuronal Plasticity, Neuronal Plasticity: physiology, Cortical Synchronization, Electroencephalography, Cortical Synchronization: physiology, Long-Term, Long-Term: physiology, Short-Term, Short-Term: physiology, Temporal Lobe, Temporal Lobe: physiology},
	pages = {105--18},
}

@article{fortin_critical_2002,
	title = {Critical role of the hippocampus in memory for sequences of events.},
	volume = {5},
	issn = {1097-6256},
	shorttitle = {Nat {Neurosci}},
	url = {http://dx.doi.org/10.1038/nn834},
	doi = {10.1038/nn834},
	abstract = {Recent models of hippocampal function emphasize the potential role of this brain structure in encoding and retrieving sequences of events that compose episodic memories. Here we show that hippocampal lesions produce a severe and selective impairment in the capacity of rats to remember the sequential ordering of a series of odors, despite an intact capacity to recognize odors that recently occurred. These findings support the hypothesis that hippocampal networks mediate associations between sequential events that constitute elements of an episodic memory.},
	number = {5},
	journal = {Nature neuroscience},
	author = {Fortin, Norbert J and Agster, Kara L and Eichenbaum, Howard B},
	month = may,
	year = {2002},
	pmid = {11976705},
	keywords = {Behavior, Nerve Net, Animals, Nerve Net: physiology, Animal, Animal: physiology, Memory, Memory: physiology, Hippocampus, Hippocampus: physiology, Rats, Long-Evans, Short-Term, Short-Term: physiology, Association, Chemical, Choice Behavior, Choice Behavior: physiology, Odors, Recognition (Psychology), Recognition (Psychology): physiology, Smell, Smell: physiology, Stimulation},
	pages = {458--62},
	file = {Attachment:/Users/tito/Zotero/storage/2WX6KDGB/Fortin, Agster, Eichenbaum - 2002 - Critical role of the hippocampus in memory for sequences of events.pdf:application/pdf},
}

@article{roux_working_2014,
	title = {Working memory and neural oscillations: {Alpha}-gamma versus theta-gamma codes for distinct {WM} information?},
	volume = {18},
	issn = {13646613},
	doi = {10.1016/j.tics.2013.10.010},
	abstract = {Neural oscillations at different frequencies have recently been related to a wide range of basic and higher cognitive processes. One possible role of oscillatory activity is to assure the maintenance of information in working memory (WM). Here we review the possibility that rhythmic activity at theta, alpha, and gamma frequencies serve distinct functional roles during WM maintenance. Specifically, we propose that gamma-band oscillations are generically involved in the maintenance of WM information. By contrast, alpha-band activity reflects the active inhibition of task-irrelevant information, whereas theta-band oscillations underlie the organization of sequentially ordered WM items. Finally, we address the role of cross-frequency coupling (CFC) in enabling alpha-gamma and theta-gamma codes for distinct WM information. ?? 2013 Elsevier Ltd.},
	number = {1},
	journal = {Trends in Cognitive Sciences},
	author = {Roux, Fr??d??ric and Uhlhaas, Peter J.},
	year = {2014},
	pmid = {24268290},
	keywords = {Working memory, Oscillations, Cognition, Humans, Cross-frequency coupling, Neurons, Neurons: physiology, Memory, Brain Waves, Short-Term, Short-Term: physiology, Cell assemblies, MEG/EEG, Alpha Rhythm, Alpha Rhythm: physiology, Brain Waves: physiology, Theta Rhythm, Theta Rhythm: physiology},
	pages = {16--25},
}

@article{lundqvist_gamma_2016,
	title = {Gamma and {Beta} {Bursts} {Underlie} {Working} {Memory}},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316001458},
	doi = {10.1016/j.neuron.2016.02.028},
	journal = {Neuron},
	author = {Lundqvist, Mikael and Rose, Jonas and Herman, Pawel and Brincat, Scott L. and Buschman, Timothy J. and Miller, Earl K.},
	year = {2016},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/WNJP2MXY/Lundqvist et al. - 2016 - Gamma and Beta Bursts Underlie Working Memory.pdf:application/pdf},
}

@article{xia_nucleus_2011,
	title = {Nucleus accumbens medium spiny neurons target non-dopaminergic neurons in the ventral tegmental area.},
	volume = {31},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/content/31/21/7811.full},
	doi = {10.1523/JNEUROSCI.1504-11.2011},
	abstract = {The midbrain ventral tegmental area (VTA) projection to the nucleus accumbens (NAc) is implicated in motivation and reinforcement. A significant number of NAc medium spiny neurons (MSNs) project back to the VTA, although the nature of this projection is essentially unknown. For example, do NAc MSNs directly target accumbens-projecting dopamine neurons and do they act via the GABA(A) or GABA(B) receptor? To address these issues, we expressed the light-sensitive channel rhodopsin-2 in the rat NAc and made electrophysiological recordings from VTA neurons ex vivo. We found that the NAc directly targets non-dopaminergic VTA neurons, including some that project back to the NAc. These MSN GABAergic terminals are opioid sensitive and act via GABA(A) receptors.},
	number = {21},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Xia, Yanfang and Driscoll, Joseph R and Wilbrecht, Linda and Margolis, Elyssa B and Fields, Howard L and Hjelmstad, Gregory O},
	month = may,
	year = {2011},
	pmid = {21613494},
	keywords = {Male, Nerve Net, Animals, Action Potentials, Action Potentials: physiology, Nerve Net: physiology, Neurons, Neurons: physiology, Neurons: cytology, Rats, Dendritic Spines, Dendritic Spines: physiology, Dopamine, Dopamine: physiology, Nerve Net: cytology, Nucleus Accumbens, Nucleus Accumbens: cytology, Nucleus Accumbens: physiology, Sprague-Dawley, Ventral Tegmental Area, Ventral Tegmental Area: cytology, Ventral Tegmental Area: physiology},
	pages = {7811--6},
}

@article{chuhma_functional_2011,
	title = {Functional connectome of the striatal medium spiny neuron.},
	volume = {31},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/content/31/4/1183.long},
	doi = {10.1523/JNEUROSCI.3833-10.2011},
	abstract = {Dopamine system disorders ranging from movement disorders to addiction and schizophrenia involve striatal medium spiny neurons (MSNs), yet their functional connectivity has been difficult to determine comprehensively. We generated a mouse with conditional channelrhodopsin-2 expression restricted to medium spiny neurons and assessed the specificity and strength of their intrinsic connections in the striatum and their projections to the globus pallidus and the substantia nigra. In the striatum, medium spiny neurons connected with other MSNs and tonically active cholinergic interneurons, but not with fast-spiking GABA interneurons. In the globus pallidus, medium spiny neurons connected strongly with one class of electrophysiologically identified neurons, but weakly with the other. In the substantia nigra, medium spiny neurons connected strongly with GABA, but not with dopamine neurons. Projections to the globus pallidus showed solely D2-mediated presynaptic inhibition, whereas projections to the substantia nigra showed solely D1-mediated presynaptic facilitation. This optogenetic approach defines the functional connectome of the striatal medium spiny neuron.},
	number = {4},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Chuhma, Nao and Tanaka, Kenji F and Hen, René and Rayport, Stephen},
	month = jan,
	year = {2011},
	pmid = {21273403},
	keywords = {Animals, Action Potentials, Neurons, Neurons: physiology, Rhodopsin, Rhodopsin: genetics, Interneurons, Interneurons: physiology, Patch-Clamp Techniques, Dendritic Spines, Dendritic Spines: physiology, Dopamine, Dopamine: physiology, Corpus Striatum, Corpus Striatum: physiology, gamma-Aminobutyric Acid, gamma-Aminobutyric Acid: physiology, Globus Pallidus, Globus Pallidus: physiology, In Vitro Techniques, Inhibitory Postsynaptic Potentials, Mice, Neural Inhibition, Rhodopsin: biosynthesis, Substantia Nigra, Substantia Nigra: physiology, Transgenic},
	pages = {1183--92},
	file = {Attachment:/Users/tito/Zotero/storage/WQRUG6EL/Chuhma et al. - 2011 - Functional connectome of the striatal medium spiny neuron.pdf:application/pdf},
}

@article{song_training_2016,
	title = {Training {Excitatory}-{Inhibitory} {Recurrent} {Neural} {Networks} for {Cognitive} {Tasks}: {A} {Simple} and {Flexible} {Framework}},
	volume = {12},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1004792},
	doi = {10.1371/journal.pcbi.1004792},
	number = {2},
	journal = {PLOS Computational Biology},
	author = {Song, H. Francis and Yang, Guangyu R. and Wang, Xiao-Jing},
	year = {2016},
	pages = {e1004792},
	file = {Attachment:/Users/tito/Zotero/storage/52E9ZFVR/Song, Yang, Wang - 2016 - Training Excitatory-Inhibitory Recurrent Neural Networks for Cognitive Tasks A Simple and Flexible Framework.pdf:application/pdf},
}

@article{sadeh_emergence_2015,
	title = {Emergence of {Functional} {Specificity} in {Balanced} {Networks} with {Synaptic} {Plasticity}},
	volume = {11},
	issn = {15537358},
	doi = {10.1371/journal.pcbi.1004307},
	abstract = {In rodent visual cortex, synaptic connections between orientation-selective neurons are unspecific at the time of eye opening, and become to some degree functionally specific only later during development. An explanation for this two-stage process was proposed in terms of Hebbian plasticity based on visual experience that would eventually enhance connections between neurons with similar response features. For this to work, however, two conditions must be satisfied: First, orientation selective neuronal responses must exist before specific recurrent synaptic connections can be established. Second, Hebbian learning must be compatible with the recurrent network dynamics contributing to orientation selectivity, and the resulting specific connectivity must remain stable for unspecific background activity. Previous studies have mainly focused on very simple models, where the receptive fields of neurons were essentially determined by feedforward mechanisms, and where the recurrent network was small, lacking the complex recurrent dynamics of large-scale networks of excitatory and inhibitory neurons. Here we studied the emergence of functionally specific connectivity in large-scale recurrent networks with synaptic plasticity. Our results show that balanced random networks, which already exhibit highly selective responses at eye opening, can develop feature-specific connectivity if appropriate rules of synaptic plasticity are invoked within and between excitatory and inhibitory populations. If these conditions are met, the initial orientation selectivity guides the process of Hebbian learning and, as a result, functionally specific and a surplus of bidirectional connections emerge. Our results thus demonstrate the cooperation of synaptic plasticity and recurrent dynamics in large-scale functional networks with realistic receptive fields, highlight the role of inhibition as a critical element in this process, and paves the road for further computational studies of sensory processing in neocortical network models equipped with synaptic plasticity.},
	number = {6},
	journal = {PLoS Computational Biology},
	author = {Sadeh, Sadra and Clopath, Claudia and Rotter, Stefan},
	year = {2015},
	pmid = {26090844},
	pages = {1--27},
	file = {Attachment:/Users/tito/Zotero/storage/ZUYQYS6C/Sadeh, Clopath, Rotter - 2015 - Emergence of Functional Specificity in Balanced Networks with Synaptic Plasticity.pdf:application/pdf},
}

@article{watabe-uchida_whole-brain_2012,
	title = {Whole-{Brain} {Mapping} of {Direct} {Inputs} to {Midbrain} {Dopamine} {Neurons}},
	volume = {74},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2012.03.017},
	doi = {10.1016/j.neuron.2012.03.017},
	abstract = {Recent studies indicate that dopamine neurons in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc) convey distinct signals. To explore this difference, we comprehensively identified each area@s monosynaptic inputs using the rabies virus. We show that dopamine neurons in both areas integrate inputs from a more diverse collection of areas than previously thought, including autonomic, motor, and somatosensory areas. SNc and VTA dopamine neurons receive contrasting excitatory inputs: the former from the somatosensory/motor cortex and subthalamic nucleus, which may explain their short-latency responses to salient events; and the latter from the lateral hypothalamus, which may explain their involvement in value coding. We demonstrate that neurons in the striatum that project directly to dopamine neurons form patches in both the dorsal and ventral striatum, whereas those projecting to GABAergic neurons are distributed in the matrix compartment. Neuron-type-specific connectivity lays a foundation for studying how dopamine neurons compute outputs.},
	number = {5},
	journal = {Neuron},
	author = {Watabe-Uchida, Mitsuko and Zhu, Lisa and Ogawa, Sachie K. and Vamanrao, Archana and Uchida, Naoshige},
	year = {2012},
	pmid = {22681690},
	pages = {858--873},
	file = {Attachment:/Users/tito/Zotero/storage/SREF9WQR/Watabe-Uchida et al. - 2012 - Whole-Brain Mapping of Direct Inputs to Midbrain Dopamine Neurons.pdf:application/pdf},
}

@article{castrillon_correction_2016,
	title = {Correction for {Riedl} et al., {Metabolic} connectivity mapping reveals effective connectivity in the resting human brain},
	volume = {113},
	issn = {0027-8424},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1600692113},
	doi = {10.1073/pnas.1600692113},
	number = {8},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Castrillón, Gabriel and Grimmer, Timo and Rauschecker, Josef P and Ploner, Markus and Friston, Karl J and Drzezga, Alexander},
	year = {2016},
	pages = {201600692},
}

@article{cole_functional_2016,
	title = {Functional connectivity change as shared signal dynamics},
	volume = {259},
	issn = {1872678X},
	doi = {10.1016/j.jneumeth.2015.11.011},
	abstract = {Background: An increasing number of neuroscientific studies gain insights by focusing on differences in functional connectivity-between groups, individuals, temporal windows, or task conditions. We found using simulations that additional insights into such differences can be gained by forgoing variance normalization, a procedure used by most functional connectivity measures. Simulations indicated that these functional connectivity measures are sensitive to increases in independent fluctuations (unshared signal) in time series, consistently reducing functional connectivity estimates (e.g., correlations) even though such changes are unrelated to corresponding fluctuations (shared signal) between those time series. This is inconsistent with the common notion of functional connectivity as the amount of inter-region interaction. New method: Simulations revealed that a version of correlation without variance normalization - covariance - was able to isolate differences in shared signal, increasing interpretability of observed functional connectivity change. Simulations also revealed cases problematic for non-normalized methods, leading to a "covariance conjunction" method combining the benefits of both normalized and non-normalized approaches. Results: We found that covariance and covariance conjunction methods can detect functional connectivity changes across a variety of tasks and rest in both clinical and non-clinical functional MRI datasets. Comparison with existing method(s): We verified using a variety of tasks and rest in both clinical and non-clinical functional MRI datasets that it matters in practice whether correlation, covariance, or covariance conjunction methods are used. Conclusions: These results demonstrate the practical and theoretical utility of isolating changes in shared signal, improving the ability to interpret observed functional connectivity change.},
	journal = {Journal of Neuroscience Methods},
	author = {Cole, Michael W. and Yang, Genevieve J. and Murray, John D. and Repovš, Grega and Anticevic, Alan},
	year = {2016},
	pmid = {26642966},
	keywords = {Functional MRI, Resting-state functional connectivity, Functional connectivity, Schizophrenia, Task functional connectivity},
	pages = {22--39},
	file = {Attachment:/Users/tito/Zotero/storage/SD9B34B5/Cole et al. - 2016 - Functional connectivity change as shared signal dynamics.pdf:application/pdf},
}

@article{hellyer_local_2016,
	title = {Local inhibitory plasticity tunes macroscopic brain dynamics and allows the emergence of functional brain networks},
	volume = {124},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2015.08.069},
	doi = {10.1016/j.neuroimage.2015.08.069},
	abstract = {Rich, spontaneous brain activity has been observed across a range of different temporal and spatial scales. These dynamics are thought to be important for efficient neural functioning. A range of experimental evidence suggests that these neural dynamics are maintained across a variety of different cognitive states, in response to alterations of the environment and to changes in brain configuration (e.g., across individuals, development and in many neurological disorders). This suggests that the brain has evolved mechanisms to maintain rich dynamics across a broad range of situations. Several mechanisms based around homeostatic plasticity have been proposed to explain how these dynamics emerge from networks of neurons at the microscopic scale. Here we explore how a homeostatic mechanism may operate at the macroscopic scale: in particular, focusing on how it interacts with the underlying structural network topology and how it gives rise to well-described functional connectivity networks. We use a simple mean-field model of the brain, constrained by empirical white matter structural connectivity where each region of the brain is simulated using a pool of excitatory and inhibitory neurons. We show, as with the microscopic work, that homeostatic plasticity regulates network activity and allows for the emergence of rich, spontaneous dynamics across a range of brain configurations, which otherwise show a very limited range of dynamic regimes. In addition, the simulated functional connectivity of the homeostatic model better resembles empirical functional connectivity network. To accomplish this, we show how the inhibitory weights adapt over time to capture important graph theoretic properties of the underlying structural network. Therefore, this work presents suggests how inhibitory homeostatic mechanisms facilitate stable macroscopic dynamics to emerge in the brain, aiding the formation of functional connectivity networks.},
	journal = {NeuroImage},
	author = {Hellyer, Peter J. and Jachs, Barbara and Clopath, Claudia and Leech, Robert},
	year = {2016},
	pmid = {26348562},
	keywords = {Neural dynamics, Homeostasis, Intrinsic connectivity networks, Plasticity},
	pages = {85--95},
	file = {Attachment:/Users/tito/Zotero/storage/QN3LLTWW/Hellyer et al. - 2016 - Local inhibitory plasticity tunes macroscopic brain dynamics and allows the emergence of functional brain networ.pdf:application/pdf},
}

@article{ogawa_organization_2014,
	title = {Organization of monosynaptic inputs to the serotonin and dopamine neuromodulatory systems},
	volume = {8},
	issn = {22111247},
	url = {http://dx.doi.org/10.1016/j.celrep.2014.06.042},
	doi = {10.1016/j.celrep.2014.06.042},
	abstract = {Serotonin and dopamine are major neuromodulators. Here, we used a modified rabies virus to identify monosynaptic inputs to serotonin neurons in the dorsal and median raphe (DR and MR). We found that inputs to DR and MR serotonin neurons are spatially shifted in the forebrain, and MR serotonin neurons receive inputs from more medial structures. Then, we compared these data with inputs to dopamine neurons in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc). We found that DRserotonin neurons receive inputs from a remarkably similar set of areas as VTA dopamine neurons apart from the striatum, which preferentially targets dopamine neurons. Our results suggest three major inputstreams: a medial stream regulates MR serotonin neurons, an intermediate stream regulates DR serotonin and VTA dopamine neurons, and a lateral stream regulates SNc dopamine neurons. These results provide fundamental organizational principles of afferent control for serotonin and dopamine. © 2014 The Authors.},
	number = {4},
	journal = {Cell Reports},
	author = {Ogawa, Sachie K. and Cohen, Jeremiah Y. and Hwang, Dabin and Uchida, Naoshige and Watabe-Uchida, Mitsuko},
	year = {2014},
	pmid = {25108805},
	pages = {1105--1118},
	file = {Attachment:/Users/tito/Zotero/storage/6Q8ESL7Y/Ogawa et al. - 2014 - Organization of monosynaptic inputs to the serotonin and dopamine neuromodulatory systems.pdf:application/pdf},
}

@article{deneve_efficient_2016,
	title = {Efficient codes and balanced networks},
	volume = {19},
	issn = {1097-6256},
	shorttitle = {Nat {Neurosci}},
	url = {http://dx.doi.org/10.1038/nn.4243},
	doi = {10.1038/nn.4243},
	abstract = {Recent years have seen a growing interest in inhibitory interneurons and their circuits. A striking property of cortical inhibition is how tightly it balances excitation. Inhibitory currents not only match excitatory currents on average, but track them on a millisecond time scale, whether they are caused by external stimuli or spontaneous fluctuations. We review, together with experimental evidence, recent theoretical approaches that investigate the advantages of such tight balance for coding and computation. These studies suggest a possible revision of the dominant view that neurons represent information with firing rates corrupted by Poisson noise. Instead, tight excitatory/inhibitory balance may be a signature of a highly cooperative code, orders of magnitude more precise than a Poisson rate code. Moreover, tight balance may provide a template that allows cortical neurons to construct high-dimensional population codes and learn complex functions of their inputs.},
	number = {3},
	journal = {Nature Neuroscience},
	author = {Denève, Sophie and Machens, Christian K},
	month = feb,
	year = {2016},
	pages = {375--382},
}

@article{abbott_building_2016,
	title = {Building {Functional} {Networks} of {Spiking} {Model} {Neurons}},
	issn = {1097-6256},
	doi = {10.1038/nn.4241},
	number = {November 2015},
	journal = {Nature neuroscience},
	author = {Abbott, L F and Depasquale, Brian and Memmesheimer, Raoul-martin},
	year = {2016},
	pages = {1--16},
	file = {Attachment:/Users/tito/Zotero/storage/T25YRTB3/Abbott, Depasquale, Memmesheimer - 2016 - Building Functional Networks of Spiking Model Neurons.pdf:application/pdf},
}

@article{widrow_30_1990,
	title = {30 {Years} of {Adaptive} {Neural} {Networks}: {Perceptron}, {Madaline}, and {Backpropagation}},
	volume = {78},
	issn = {15582256},
	doi = {10.1109/5.58323},
	abstract = {Fundamental developments in feedforward artificial neural networks from the past thirty years are reviewed. The history, origination, operating characteristics, and basic theory of several supervised neural-network training algorithms (including the perceptron rule, the least-mean-square algorithm, three Madaline rules, and the backpropagation technique) are described. The concept underlying these iterative adaptation algorithms is the minimal disturbance principle, which suggests that during training it is advisable to inject new information into a network in a manner that disturbs stored information to the smallest extent possible. The two principal kinds of online rules that have developed for altering the weights of a network are examined for both single-threshold elements and multielement networks. They are error-correction rules, which alter the weights of a network to correct error in the output response to the present input pattern, and gradient rules, which alter the weights of a network during each pattern presentation by gradient descent with the objective of reducing mean-square error (averaged over all training patterns)},
	number = {9},
	journal = {Proceedings of the IEEE},
	author = {Widrow, Bernard and Lehr, Michael A.},
	year = {1990},
	pages = {1415--1442},
	file = {Attachment:/Users/tito/Zotero/storage/K2XQ8RZN/Widrow, Lehr - 1990 - 30 Years of Adaptive Neural Networks Perceptron, Madaline, and Backpropagation.pdf:application/pdf},
}

@article{elman_finding_1990,
	title = {Finding structure in time* 1},
	volume = {14},
	issn = {03640213},
	doi = {10.1207/s15516709cog1402_1},
	abstract = {[PDF]},
	number = {2},
	journal = {Cognitive science},
	author = {Elman, J L},
	year = {1990},
	pmid = {19563812},
	pages = {179--211},
	file = {Attachment:/Users/tito/Zotero/storage/LVGBXL76/Elman - 1990 - Finding structure in time 1.pdf:application/pdf},
}

@article{bradfield_thalamostriatal_2013,
	title = {The {Thalamostriatal} {Pathway} and {Cholinergic} {Control} of {Goal}-{Directed} {Action}: {Interlacing} {New} with {Existing} {Learning} in the {Striatum}},
	volume = {79},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2013.04.039},
	doi = {10.1016/j.neuron.2013.04.039},
	abstract = {The capacity for goal-directed action depends on encoding specific action-outcome associations, a learning process mediated by the posterior dorsomedial striatum (pDMS). In a changing environment, plasticity has to remain flexible, requiring interference between new and existing learning to be minimized, yet it is not known how new and existing learning are interlaced in this way. Here we investigated the role of the thalamostriatal pathway linking the parafascicular thalamus (Pf) with cholinergic interneurons (CINs) in the pDMS in this process. Removing the excitatory input from Pf to the CINs was found to reduce the firing rate and intrinsic activity of these neurons and produced an enduring deficit in goal-directed learning after changes in the action-outcome contingency. Disconnection of the Pf-pDMS pathway produced similar behavioral effects. These data suggest that CINs reduce interference between new and existing learning, consistent with claims that the thalamostriatal pathway exerts state control over learning-related plasticity},
	number = {1},
	journal = {Neuron},
	author = {Bradfield, LauraA and Bertran-Gonzalez, Jesus and Chieng, Billy and Balleine, Bernard W.},
	year = {2013},
	pmid = {23770257},
	pages = {153--166},
	file = {Attachment:/Users/tito/Zotero/storage/XZCI4RSQ/Bradfield et al. - 2013 - The Thalamostriatal Pathway and Cholinergic Control of Goal-Directed Action Interlacing New with Existing Lear.pdf:application/pdf},
}

@article{wimmer_bump_2014,
	title = {Bump attractor dynamics in prefrontal cortex explains behavioral precision in spatial working memory.},
	volume = {17},
	issn = {1546-1726},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24487232},
	doi = {10.1038/nn.3645},
	abstract = {Prefrontal persistent activity during the delay of spatial working memory tasks is thought to maintain spatial location in memory. A 'bump attractor' computational model can account for this physiology and its relationship to behavior. However, direct experimental evidence linking parameters of prefrontal firing to the memory report in individual trials is lacking, and, to date, no demonstration exists that bump attractor dynamics underlies spatial working memory. We analyzed monkey data and found model-derived predictive relationships between the variability of prefrontal activity in the delay and the fine details of recalled spatial location, as evident in trial-to-trial imprecise oculomotor responses. Our results support a diffusing bump representation for spatial working memory instantiated in persistent prefrontal activity. These findings reinforce persistent activity as a basis for spatial working memory, provide evidence for a continuous prefrontal representation of memorized space and offer experimental support for bump attractor dynamics mediating cognitive tasks in the cortex.},
	number = {3},
	journal = {Nature neuroscience},
	author = {Wimmer, Klaus and Nykamp, Duane Q and Constantinidis, Christos and Compte, Albert},
	year = {2014},
	pmid = {24487232},
	keywords = {Behavior, Male, Neuropsychological Tests, Prefrontal Cortex, Models, Neurological, Animals, Psychomotor Performance, Psychomotor Performance: physiology, Microelectrodes, Neurons, Neurons: physiology, Animal, Animal: physiology, Memory, Prefrontal Cortex: physiology, Macaca mulatta, Short-Term, Short-Term: physiology, Cues, Electrophysiological Phenomena, Electrophysiological Phenomena: physiology, Eye Movement Measurements, Eye Movements, Eye Movements: physiology, Space Perception, Space Perception: physiology, Time Factors},
	pages = {431--9},
	file = {Attachment:/Users/tito/Zotero/storage/XG75PV8E/Wimmer et al. - 2014 - Bump attractor dynamics in prefrontal cortex explains behavioral precision in spatial working memory.pdf:application/pdf},
}

@article{hinton_fast_2006,
	title = {A fast learning algorithm for deep belief nets.},
	volume = {18},
	issn = {0899-7667},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.7.1527#.Vtio25MrKRs},
	doi = {10.1162/neco.2006.18.7.1527},
	abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
	language = {en},
	number = {7},
	journal = {Neural computation},
	author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
	month = jul,
	year = {2006},
	pmid = {16764513},
	keywords = {Humans, Algorithms, Animals, Learning, Learning: physiology, Neurons, Neurons: physiology, Neural Networks (Computer)},
	pages = {1527--54},
	file = {Attachment:/Users/tito/Zotero/storage/L8JRFLM9/Hinton, Osindero, Teh - 2006 - A fast learning algorithm for deep belief nets.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/GMGAG6WL/Hinton, Osindero, Teh - 2006 - A fast learning algorithm for deep belief nets.pdf:application/pdf},
}

@article{rubinov_weight-conserving_2011,
	title = {Weight-conserving characterization of complex functional brain networks.},
	volume = {56},
	issn = {1095-9572},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191100348X},
	doi = {10.1016/j.neuroimage.2011.03.069},
	abstract = {Complex functional brain networks are large networks of brain regions and functional brain connections. Statistical characterizations of these networks aim to quantify global and local properties of brain activity with a small number of network measures. Important functional network measures include measures of modularity (measures of the goodness with which a network is optimally partitioned into functional subgroups) and measures of centrality (measures of the functional influence of individual brain regions). Characterizations of functional networks are increasing in popularity, but are associated with several important methodological problems. These problems include the inability to characterize densely connected and weighted functional networks, the neglect of degenerate topologically distinct high-modularity partitions of these networks, and the absence of a network null model for testing hypotheses of association between observed nontrivial network properties and simple weighted connectivity properties. In this study we describe a set of methods to overcome these problems. Specifically, we generalize measures of modularity and centrality to fully connected and weighted complex networks, describe the detection of degenerate high-modularity partitions of these networks, and introduce a weighted-connectivity null model of these networks. We illustrate our methods by demonstrating degenerate high-modularity partitions and strong correlations between two complementary measures of centrality in resting-state functional magnetic resonance imaging (MRI) networks from the 1000 Functional Connectomes Project, an open-access repository of resting-state functional MRI datasets. Our methods may allow more sound and reliable characterizations and comparisons of functional brain networks across conditions and subjects.},
	number = {4},
	journal = {NeuroImage},
	author = {Rubinov, Mikail and Sporns, Olaf},
	month = jun,
	year = {2011},
	pmid = {21459148},
	keywords = {Brain, Brain Mapping, Humans, Magnetic Resonance Imaging, Nerve Net, Algorithms, Models, Neurological, Computer-Assisted, Brain: physiology, Nerve Net: physiology, Brain Mapping: methods, Computer-Assisted: methods, Image Interpretation},
	pages = {2068--79},
	file = {Attachment:/Users/tito/Zotero/storage/MHJQ3A9I/Rubinov, Sporns - 2011 - Weight-conserving characterization of complex functional brain networks.pdf:application/pdf},
}

@article{churchland_conceptual_2016,
	title = {Conceptual and technical advances define a key moment for theoretical neuroscience},
	volume = {19},
	issn = {1097-6256},
	shorttitle = {Nat {Neurosci}},
	url = {http://dx.doi.org/10.1038/nn.4255},
	doi = {10.1038/nn.4255},
	number = {3},
	journal = {Nature Neuroscience},
	author = {Churchland, Anne K and Abbott, L F},
	month = feb,
	year = {2016},
	pages = {348--349},
	file = {Attachment:/Users/tito/Zotero/storage/IX4DP2DP/Churchland, Abbott - 2016 - Conceptual and technical advances define a key moment for theoretical neuroscience.pdf:application/pdf},
}

@book{zhong_web_2007,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Web {Intelligence} {Meets} {Brain} {Informatics}},
	volume = {4845},
	isbn = {978-3-540-77027-5},
	url = {http://www.springerlink.com/index/10.1007/978-3-540-77028-2},
	publisher = {Springer Berlin Heidelberg},
	editor = {Zhong, Ning and Liu, Jiming and Yao, Yiyu and Wu, Jinglong and Lu, Shengfu and Li, Kuncheng},
	year = {2007},
	doi = {10.1007/978-3-540-77028-2},
}

@article{hacker_resting_2013,
	title = {Resting state network estimation in individual subjects.},
	volume = {82},
	issn = {1095-9572},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3909699&tool=pmcentrez&rendertype=abstract},
	doi = {10.1016/j.neuroimage.2013.05.108},
	abstract = {Resting state functional magnetic resonance imaging (fMRI) has been used to study brain networks associated with both normal and pathological cognitive functions. The objective of this work is to reliably compute resting state network (RSN) topography in single participants. We trained a supervised classifier (multi-layer perceptron; MLP) to associate blood oxygen level dependent (BOLD) correlation maps corresponding to pre-defined seeds with specific RSN identities. Hard classification of maps obtained from a priori seeds was highly reliable across new participants. Interestingly, continuous estimates of RSN membership retained substantial residual error. This result is consistent with the view that RSNs are hierarchically organized, and therefore not fully separable into spatially independent components. After training on a priori seed-based maps, we propagated voxel-wise correlation maps through the MLP to produce estimates of RSN membership throughout the brain. The MLP generated RSN topography estimates in individuals consistent with previous studies, even in brain regions not represented in the training data. This method could be used in future studies to relate RSN topography to other measures of functional brain organization (e.g., task-evoked responses, stimulation mapping, and deficits associated with lesions) in individuals. The multi-layer perceptron was directly compared to two alternative voxel classification procedures, specifically, dual regression and linear discriminant analysis; the perceptron generated more spatially specific RSN maps than either alternative.},
	journal = {NeuroImage},
	author = {Hacker, Carl D and Laumann, Timothy O and Szrama, Nicholas P and Baldassarre, Antonello and Snyder, Abraham Z and Leuthardt, Eric C and Corbetta, Maurizio},
	month = nov,
	year = {2013},
	pmid = {23735260},
	keywords = {Brain, Adult, Brain Mapping, Female, Humans, Magnetic Resonance Imaging, Male, Adolescent, Young Adult, Computer-Assisted, Image Processing, Brain: physiology, Rest, Rest: physiology, Brain Mapping: methods, Computer-Assisted: methods},
	pages = {616--33},
	file = {Attachment:/Users/tito/Zotero/storage/D5F32I29/Hacker et al. - 2013 - Resting state network estimation in individual subjects.pdf:application/pdf},
}

@article{deco_how_2014,
	title = {How local excitation-inhibition ratio impacts the whole brain dynamics.},
	volume = {34},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/content/34/23/7886.full},
	doi = {10.1523/JNEUROSCI.5068-13.2014},
	abstract = {The spontaneous activity of the brain shows different features at different scales. On one hand, neuroimaging studies show that long-range correlations are highly structured in spatiotemporal patterns, known as resting-state networks, on the other hand, neurophysiological reports show that short-range correlations between neighboring neurons are low, despite a large amount of shared presynaptic inputs. Different dynamical mechanisms of local decorrelation have been proposed, among which is feedback inhibition. Here, we investigated the effect of locally regulating the feedback inhibition on the global dynamics of a large-scale brain model, in which the long-range connections are given by diffusion imaging data of human subjects. We used simulations and analytical methods to show that locally constraining the feedback inhibition to compensate for the excess of long-range excitatory connectivity, to preserve the asynchronous state, crucially changes the characteristics of the emergent resting and evoked activity. First, it significantly improves the model's prediction of the empirical human functional connectivity. Second, relaxing this constraint leads to an unrealistic network evoked activity, with systematic coactivation of cortical areas which are components of the default-mode network, whereas regulation of feedback inhibition prevents this. Finally, information theoretic analysis shows that regulation of the local feedback inhibition increases both the entropy and the Fisher information of the network evoked responses. Hence, it enhances the information capacity and the discrimination accuracy of the global network. In conclusion, the local excitation-inhibition ratio impacts the structure of the spontaneous activity and the information transmission at the large-scale brain level.},
	number = {23},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Deco, Gustavo and Ponce-Alvarez, Adrián and Hagmann, Patric and Romani, Gian Luca and Mantini, Dante and Corbetta, Maurizio},
	month = jun,
	year = {2014},
	pmid = {24899711},
	keywords = {Brain, Humans, Nerve Net, Neural Pathways, Models, Neurological, Computer Simulation, Brain: physiology, Action Potentials, Action Potentials: physiology, Brain: cytology, Nerve Net: physiology, Neurons, Neurons: physiology, Feedback, Physiological, Neural Inhibition, Entropy, Neural Inhibition: physiology, Neural Pathways: physiology, Nonlinear Dynamics, Physiological: physiology},
	pages = {7886--98},
	file = {Attachment:/Users/tito/Zotero/storage/Y5SQE24B/Deco et al. - 2014 - How local excitation-inhibition ratio impacts the whole brain dynamics.pdf:application/pdf},
}

@article{wig_concepts_2011,
	title = {Concepts and principles in the analysis of brain networks},
	volume = {1224},
	issn = {00778923},
	doi = {10.1111/j.1749-6632.2010.05947.x},
	abstract = {The brain is a large-scale network, operating at multiple levels of information processing ranging from neurons, to local circuits, to systems of brain areas. Recent advances in the mathematics of graph theory have provided tools with which to study networks. These tools can be employed to understand how the brain's behavioral repertoire is mediated by the interactions of objects of information processing. Within the graph-theoretic framework, networks are defined by independent objects (nodes) and the relationships shared between them (edges). Importantly, the accurate incorporation of graph theory into the study of brain networks mandates careful consideration of the assumptions, constraints, and principles of both the mathematics and the underlying neurobiology. This review focuses on understanding these principles and how they guide what constitutes a brain network and its elements, specifically focusing on resting-state correlations in humans. We argue that approaches that fail to take the principles of graph theory into consideration and do not reflect the underlying neurobiological properties of the brain will likely mischaracterize brain network structure and function.},
	number = {1},
	journal = {Annals of the New York Academy of Sciences},
	author = {Wig, Gagan S. and Schlaggar, Bradley L. and Petersen, Steven E.},
	year = {2011},
	pmid = {21486299},
	keywords = {Brain networks, Graph theory, Resting state functional connectivity},
	pages = {126--146},
	file = {Attachment:/Users/tito/Zotero/storage/JT7GHI9A/Wig, Schlaggar, Petersen - 2011 - Concepts and principles in the analysis of brain networks.pdf:application/pdf},
}

@article{power_evidence_2013,
	title = {Evidence for hubs in human functional brain networks},
	volume = {79},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2013.07.035},
	doi = {10.1016/j.neuron.2013.07.035},
	abstract = {Hubs integrate and distribute information in powerful ways due to the number and positioning of their contacts in a network. Several resting-state functional connectivity MRI reports have implicated regions of the default mode system as brain hubs; we demonstrate that previous degree-based approaches to hub identification may have identified portions of large brain systems rather than critical nodes of brain networks. We utilize two methods to identify hub-like brain regions: (1) finding network nodes that participate in multiple subnetworks of the brain, and (2) finding spatial locations in which several systems are represented within a small volume. These methods converge on a distributed set of regions that differ from previous reports on hubs. This work identifies regions that support multiple systems, leading to spatially constrained predictions about brain function that may be tested in terms of lesions, evoked responses, and dynamic patterns of activity},
	number = {4},
	journal = {Neuron},
	author = {Power, Jonathan D and Schlaggar, Bradley L and Lessov-Schlaggar, Christina N and Petersen, Steven E},
	year = {2013},
	pmid = {23972601},
	pages = {798--813},
	file = {Attachment:/Users/tito/Zotero/storage/MJ3A8FGU/Power et al. - 2013 - Evidence for hubs in human functional brain networks.pdf:application/pdf},
}

@article{mckenzie_hippocampal_2014,
	title = {Hippocampal representation of related and opposing memories develop within distinct, hierarchically organized neural schemas.},
	volume = {83},
	issn = {1097-4199},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4082468&tool=pmcentrez&rendertype=abstract},
	doi = {10.1016/j.neuron.2014.05.019},
	abstract = {Recent evidence suggests that the hippocampus may integrate overlapping memories into relational representations, or schemas, that link indirectly related events and support flexible memory expression. Here we explored the nature of hippocampal neural population representations for multiple features of events and the locations and contexts in which they occurred. Hippocampal networks developed hierarchical organizations of associated elements of related but separately acquired memories within a context, and distinct organizations for memories where the contexts differentiated object-reward associations. These findings reveal neural mechanisms for the development and organization of relational representations.},
	number = {1},
	journal = {Neuron},
	author = {McKenzie, Sam and Frank, Andrea J and Kinsky, Nathaniel R and Porter, Blake and Rivière, Pamela D and Eichenbaum, Howard},
	month = jul,
	year = {2014},
	pmid = {24910078},
	keywords = {Male, Nerve Net, Animals, Psychomotor Performance, Psychomotor Performance: physiology, Nerve Net: physiology, Neurons, Neurons: physiology, Memory, Memory: physiology, Hippocampus, Hippocampus: physiology, Rats, Hippocampus: cytology, Long-Evans, Nerve Net: cytology, Random Allocation, Reward},
	pages = {202--15},
	file = {Attachment:/Users/tito/Zotero/storage/TBNHBC7L/McKenzie et al. - 2014 - Hippocampal representation of related and opposing memories develop within distinct, hierarchically organized n.pdf:application/pdf},
}

@article{buckmaster_entorhinal_2004,
	title = {Entorhinal cortex lesions disrupt the relational organization of memory in monkeys.},
	volume = {24},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/content/24/44/9811.long},
	doi = {10.1523/JNEUROSCI.1532-04.2004},
	abstract = {Recent accounts suggest that the hippocampal system critically supports two central characteristics of episodic memory: the ability to establish and maintain representations for the salient relationships between experienced events (relational representation) and the capacity to flexibly manipulate memory (flexible memory expression). To test this proposal in monkeys, intact controls and subjects with bilateral aspiration lesions of the entorhinal cortex were trained postoperatively on two standard memory tasks, delayed nonmatchingto-sample (DNMS) and two-choice object discrimination (OD) learning, and three procedures intended to emphasize relational representation and flexible memory expression: a paired associate (PA) task, a transitive inference (TI) test of learning and memory for hierarchical stimulus relationships, and a spatial delayed recognition span (SDRS) procedure. The latter assessments each included critical "probe" tests that asked monkeys to evaluate the relationships among previously learned stimuli presented in novel combinations. Subjects with entorhinal cortex lesions scored as accurately as controls on all phases of DNMS and OD, procedures that can be solved on the basis of memory for individual stimuli. In contrast, experimental monkeys displayed deficits relative to controls on all phases of the PA, TI, and SDRS tasks that emphasized the flexible manipulation of memory for the relationships between familiar items. Together, the findings support the conclusion that the primate hippocampal system critically enables the relational organization of declarative memory.},
	number = {44},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Buckmaster, Cindy A and Eichenbaum, Howard and Amaral, David G and Suzuki, Wendy A and Rapp, Peter R},
	month = nov,
	year = {2004},
	pmid = {15525766},
	keywords = {Functional Laterality, Male, Animals, Memory, Memory: physiology, Hippocampus, Hippocampus: physiology, Association Learning, Association Learning: physiology, Discrimination Learning, Discrimination Learning: physiology, Entorhinal Cortex, Entorhinal Cortex: physiology, Functional Laterality: physiology, Macaca fascicularis, Retention (Psychology), Retention (Psychology): physiology},
	pages = {9811--25},
}

@article{davachi_item_2006,
	title = {Item, context and relational episodic encoding in humans.},
	volume = {16},
	issn = {0959-4388},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17097284},
	doi = {10.1016/j.conb.2006.10.012},
	abstract = {Recent functional imaging work supports the view that item and relational memory depend upon distinct encoding operations within the medial temporal lobe. Specifically, emerging findings demonstrate that the level of engagement of perirhinal cortex predicts later memory for individual items, whereas the level of hippocampal processing correlates with later relational memory, or recovery of additional episodic details. Furthermore, recent functional magnetic resonance imaging evidence in humans suggests that medial temporal lobe cortical input structures, the perirhinal and posterior parahippocampal cortices, differentially participate in the encoding of objects and their context, providing domain-specific input to the hippocampus. Taken together, these data help to construct a working model of how distinct medial temporal lobe structures participate in episodic memory formation with domain-general relational binding mechanisms supported by the hippocampus and provide emerging evidence for domain-specificity within the perirhinal and parahippocampal cortices.},
	number = {6},
	journal = {Current opinion in neurobiology},
	author = {Davachi, Lila},
	month = dec,
	year = {2006},
	pmid = {17097284},
	keywords = {Perception, Brain Mapping, Functional Laterality, Humans, Magnetic Resonance Imaging, Neural Pathways, Learning, Learning: physiology, Memory, Memory: physiology, Hippocampus, Hippocampus: physiology, Neural Pathways: physiology, Functional Laterality: physiology, Hippocampus: anatomy \& histology, Neural Pathways: anatomy \& histology, Parahippocampal Gyrus, Parahippocampal Gyrus: anatomy \& histology, Parahippocampal Gyrus: physiology, Perception: physiology},
	pages = {693--700},
}

@article{murray_dorsolateral_2007,
	title = {The dorsolateral prefrontal cortex contributes to successful relational memory encoding.},
	volume = {27},
	issn = {1529-2401},
	url = {http://www.jneurosci.org/content/27/20/5515.short},
	doi = {10.1523/JNEUROSCI.0406-07.2007},
	abstract = {Results from neuroimaging studies of long-term memory (LTM) encoding have contributed to the view that the ventrolateral prefrontal cortex (VLPFC) contributes to successful LTM formation, whereas the dorsolateral prefrontal cortex (DLPFC) does not. We hypothesized that the DLPFC does contribute to LTM, but under specific circumstances. That is, the DLPFC may be critical for building relationships between items during on-line processing, and this may promote LTM for associations between items. We used event-related functional magnetic resonance imaging (fMRI) to test this hypothesis by examining brain activity during sequential encoding of unrelated word pairs. During presentation of the second ("target") word in each pair, subjects either made a semantic judgment specific to the target word ("item-specific" trials), or a semantic judgment that involved a comparison between the target word and the first word in the pair ("relational" trials). Behaviorally, recognition memory for target words was equivalent between the two trial types but associative recognition of studied word pairs was significantly greater for relational trials. fMRI results showed that DLPFC activity was greater during relational compared with item-specific encoding and that DLPFC activity predicted successful memory for associations but not successful item memory. Activity in the VLPFC was also greater for relational compared with item-specific encoding, but VLPFC activation predicted successful memory for both associations and items. These results support the view that the DLPFC may contribute to LTM through its role in active processing of relationships during encoding, whereas the VLPFC may have a more general role in promoting successful LTM formation.},
	number = {20},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Murray, Linda J and Ranganath, Charan},
	month = may,
	year = {2007},
	pmid = {17507573},
	keywords = {Adult, Female, Humans, Magnetic Resonance Imaging, Male, Photic Stimulation, Prefrontal Cortex, Reaction Time, Adolescent, Magnetic Resonance Imaging: methods, Reaction Time: physiology, Memory, Memory: physiology, Prefrontal Cortex: physiology, Photic Stimulation: methods, Word Association Tests, Word Association Tests: statistics \& numerical dat},
	pages = {5515--22},
}

@article{mannino_foundational_2015,
	title = {Foundational perspectives on causality in large-scale brain networks.},
	volume = {15},
	issn = {1873-1457},
	url = {http://www.sciencedirect.com/science/article/pii/S157106451500161X},
	doi = {10.1016/j.plrev.2015.09.002},
	abstract = {A profusion of recent work in cognitive neuroscience has been concerned with the endeavor to uncover causal influences in large-scale brain networks. However, despite the fact that many papers give a nod to the important theoretical challenges posed by the concept of causality, this explosion of research has generally not been accompanied by a rigorous conceptual analysis of the nature of causality in the brain. This review provides both a descriptive and prescriptive account of the nature of causality as found within and between large-scale brain networks. In short, it seeks to clarify the concept of causality in large-scale brain networks both philosophically and scientifically. This is accomplished by briefly reviewing the rich philosophical history of work on causality, especially focusing on contributions by David Hume, Immanuel Kant, Bertrand Russell, and Christopher Hitchcock. We go on to discuss the impact that various interpretations of modern physics have had on our understanding of causality. Throughout all this, a central focus is the distinction between theories of deterministic causality (DC), whereby causes uniquely determine their effects, and probabilistic causality (PC), whereby causes change the probability of occurrence of their effects. We argue that, given the topological complexity of its large-scale connectivity, the brain should be considered as a complex system and its causal influences treated as probabilistic in nature. We conclude that PC is well suited for explaining causality in the brain for three reasons: (1) brain causality is often mutual; (2) connectional convergence dictates that only rarely is the activity of one neuronal population uniquely determined by another one; and (3) the causal influences exerted between neuronal populations may not have observable effects. A number of different techniques are currently available to characterize causal influence in the brain. Typically, these techniques quantify the statistical likelihood that a change in the activity of one neuronal population affects the activity in another. We argue that these measures access the inherently probabilistic nature of causal influences in the brain, and are thus better suited for large-scale brain network analysis than are DC-based measures. Our work is consistent with recent advances in the philosophical study of probabilistic causality, which originated from inherent conceptual problems with deterministic regularity theories. It also resonates with concepts of stochasticity that were involved in establishing modern physics. In summary, we argue that probabilistic causality is a conceptually appropriate foundation for describing neural causality in the brain.},
	journal = {Physics of life reviews},
	author = {Mannino, Michael and Bressler, Steven L},
	month = sep,
	year = {2015},
	pmid = {26429630},
	keywords = {Brain connectivity, Causality, Brain, Probability, Determinism, Large-scale neurocognitive networks},
	pages = {107--123},
	file = {Attachment:/Users/tito/Zotero/storage/3EUCAJ43/Mannino, Bressler - 2015 - Foundational perspectives on causality in large-scale brain networks(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/UVAAQZ6R/Mannino, Bressler - 2015 - Foundational perspectives on causality in large-scale brain networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6PH2SFNC/Mannino, Bressler - 2015 - Foundational perspectives on causality in large-scale brain networks.pdf:application/pdf},
}

@article{buss_reversal_1956,
	title = {Reversal and nonreversal shifts in concept formation with partial reinforcement eliminated.},
	volume = {52},
	issn = {0022-1015},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/13357698},
	number = {3},
	journal = {Journal of experimental psychology},
	author = {BUSS, A H},
	month = sep,
	year = {1956},
	pmid = {13357698},
	keywords = {Humans, Learning, Concept Formation, Reinforcement (Psychology)},
	pages = {162--6},
}

@article{mccool_differential_2008,
	title = {Differential involvement of {M1}-type and {M4}-type muscarinic cholinergic receptors in the dorsomedial striatum in task switching.},
	volume = {89},
	issn = {1095-9564},
	url = {http://www.sciencedirect.com/science/article/pii/S1074742707000913},
	doi = {10.1016/j.nlm.2007.06.005},
	abstract = {Previous experiments have demonstrated that the rat dorsomedial striatum is one brain area that plays a crucial role in learning when conditions require a shift in strategies. Further evidence indicates that muscarinic cholinergic receptors in this brain area support adaptations in behavioral responses. Unknown is whether specific muscarinic receptor subtypes in the dorsomedial striatum contribute to a flexible shift in response patterns. The present experiments investigated whether blockade of M1-type and/or M4-type cholinergic receptors in the dorsomedial striatum underlie place reversal learning. Experiment 1 investigated the effects of the M1-type muscarinic cholinergic antagonist, muscarinic-toxin 7 (MT-7) infused into the dorsomedial striatum in place acquisition and reversal learning. Experiment 2 investigated the effects of the M4-type muscarinic cholinergic antagonist, muscarinic-toxin 3 (MT-3) injected into the dorsomedial striatum in place acquisition and reversal learning. All testing occurred in a modified cross-maze across two consecutive sessions. Bilateral injections of MT-7 into the dorsomedial striatum at 1 or 2 microg, but not 0.05 microg impaired place reversal learning. Analysis of the errors revealed that MT-7 at 1 and 2 microg significantly increased regressive errors, but not perseverative errors. An injection of MT-7 2 microg into the dorsomedial striatum prior to place acquisition did not affect learning. Experiment 2 revealed that dorsomedial striatal injections of MT-3 (0.05, 1 or 2 microg) did not affect place acquisition or reversal learning. The findings suggest that activation of M1-type muscarinic cholinergic receptors in the dorsomedial striatum, but not M4-type muscarinic cholinergic receptors facilitate the flexible shifting of response patterns by maintaining or learning a new choice pattern once selected.},
	number = {2},
	journal = {Neurobiology of learning and memory},
	author = {McCool, Martha F and Patel, Sima and Talati, Ravi and Ragozzino, Michael E},
	month = feb,
	year = {2008},
	pmid = {17709264},
	keywords = {Attention, Cognition, Male, Animals, Cognition: physiology, Rats, Long-Evans, Corpus Striatum, Discrimination Learning, Discrimination Learning: physiology, Attention: drug effects, Basal Ganglia, Basal Ganglia: drug effects, Cholinergic, Cholinergic: drug effects, Cholinergic: metabolism, Corpus Striatum: metabolism, Discrimination Learning: drug effects, Drug Administration Schedule, Elapid Venoms, Elapid Venoms: administration \& dosage, Elapid Venoms: pharmacology, Maze Learning, Maze Learning: drug effects, Muscarinic M1, Muscarinic M1: antagonists \& inhibitors, Muscarinic M1: metabolism, Muscarinic M4, Muscarinic M4: antagonists \& inhibitors, Muscarinic M4: metabolism, Peptides, Peptides: administration \& dosage, Peptides: pharmacology, Receptor, Receptors},
	pages = {114--24},
	file = {Attachment:/Users/tito/Zotero/storage/87M3KRW7/McCool et al. - 2008 - Differential involvement of M1-type and M4-type muscarinic cholinergic receptors in the dorsomedial striatum in t.pdf:application/pdf},
}

@article{sadeh_zeta_2015,
	title = {Zeta {Inhibitory} {Peptide}, a {Candidate} {Inhibitor} of {Protein} {Kinase} {M} , {Is} {Excitotoxic} to {Cultured} {Hippocampal} {Neurons}},
	volume = {35},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0976-15.2015},
	doi = {10.1523/JNEUROSCI.0976-15.2015},
	abstract = {The zeta-inhibitory peptide (ZIP) is considered a candidate inhibitor of the atypical protein kinase M zeta (PKM zeta). ZIP has been shown to reverse established LTP and disrupt several forms of long-term memory. However, recent studies have challenged the specificity of ZIP, as it was reported to exert its effect also in PKM zeta knock-out mice. These results raise the question of what are the targets of ZIP that may underlie its effect on LTP and memory. Here we report that ZIP as well as its inactive analog, scrambled ZIP, induced a dose-dependent increase in spontaneous activity of neurons in dissociated cultures of rat hippocampus. This was followed by a sustained elevation of intracellular calcium concentration ([Ca2+](i)) which could not be blocked by conventional channel blockers. Furthermore, ZIP caused an increase in frequency of mEPSCs followed by an increase in membrane noise in patch-clamped neurons both in culture and in acute brain slices. Finally, at 5-10 mu M, ZIP-induced excitotoxic death of the cultured neurons. Together, our results suggest that the potential contribution of cellular toxicity should be taken into account in interpretation of ZIP's effects on neuronal and behavioral plasticity.},
	number = {36},
	journal = {Journal of Neuroscience},
	author = {Sadeh, N. and Verbitsky, S. and Dudai, Y. and Segal, M.},
	year = {2015},
	keywords = {hippocampus, significance statement, here we report that, -inhibitory peptide, and disrupt several forms, calcium, culture, inhibitor of the atypical, is considered a candidate, its inactive analog, of long-term memory, pkm, protein kinase m, the, to reverse established ltp, toxicity, zip, zip as well as, zip has been shown},
	pages = {12404--12411},
	file = {Attachment:/Users/tito/Zotero/storage/XT92MQFW/Sadeh et al. - 2015 - Zeta Inhibitory Peptide, a Candidate Inhibitor of Protein Kinase M , Is Excitotoxic to Cultured Hippocampal Neuron.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/NU66PHFW/Sadeh et al. - 2015 - Zeta Inhibitory Peptide, a Candidate Inhibitor of Protein Kinase M , Is Excitotoxic to Cultured Hippocampal Neuron.pdf:application/pdf},
}

@article{pastalkova_storage_2006,
	title = {Storage of spatial information by the maintenance mechanism of {LTP}.},
	volume = {313},
	issn = {0036-8075},
	doi = {10.1126/science.1128657},
	abstract = {Analogous to learning and memory storage, long-term potentiation (LTP) is divided into induction and maintenance phases. Testing the hypothesis that the mechanism of LTP maintenance stores information requires reversing this mechanism in vivo and finding out whether long-term stored information is lost. This was not previously possible. Recently however, persistent phosphorylation by the atypical protein kinase C isoform, protein kinase Mzeta (PKMz), has been found to maintain late LTP in hippocampal slices. Here we show that a cell-permeable PKMz inhibitor, injected in the rat hippocampus, both reverses LTP maintenance in vivo and produces persistent loss of 1-day-old spatial information. Thus, the mechanism maintaining LTP sustains spatial memory.},
	number = {5790},
	journal = {Science (New York, N.Y.)},
	author = {Pastalkova, Eva and Serrano, Peter and Pinkhasova, Deana and Wallace, Emma and Fenton, André Antonio and Sacktor, Todd Charlton},
	year = {2006},
	pmid = {16931766},
	pages = {1141--1144},
	file = {Attachment:/Users/tito/Zotero/storage/94MYPNRE/Pastalkova et al. - 2006 - Storage of spatial information by the maintenance mechanism of LTP.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/52SRNM9Q/Pastalkova et al. - 2006 - Storage of spatial information by the maintenance mechanism of LTP.pdf:application/pdf},
}

@article{b??nstrup_dynamic_2016,
	title = {Dynamic causal modelling of {EEG} and {fMRI} to characterize network architectures in a simple motor task},
	volume = {124},
	issn = {10959572},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2015.08.052},
	doi = {10.1016/j.neuroimage.2015.08.052},
	abstract = {Dynamic causal modelling (DCM) has extended the understanding of brain network dynamics in a variety of functional systems. In the motor system, DCM studies based on functional magnetic resonance imaging (fMRI) or on magneto-/electroencephalography (M/EEG) have demonstrated movement-related causal information flow from secondary to primary motor areas and have provided evidence for nonlinear cross-frequency interactions among motor areas. The present study sought to investigate to what extent fMRI- and EEG-based DCM might provide complementary and synergistic insights into neuronal network dynamics. Both modalities share principal similarities in the formulation of the DCM. Thus, we hypothesized that DCM based on induced EEG responses (DCM-IR) and on fMRI would reveal congruent task-dependent network dynamics. Brain electrical (63-channel surface EEG) and Blood Oxygenation Level Dependent (BOLD) signals were recorded in separate sessions from 14 healthy participants performing simple isometric right and left hand grips. DCM-IR and DCM-fMRI were used to estimate coupling parameters modulated by right and left hand grips within a core motor network of six regions comprising bilateral primary motor cortex (M1), ventral premotor cortex (PMv) and supplementary motor area (SMA). We found that DCM-fMRI and DCM-IR similarly revealed significant grip-related increases in facilitatory coupling between SMA and M1 contralateral to the active hand. A grip-dependent interhemispheric reciprocal inhibition between M1 bilaterally was only revealed by DCM-fMRI but not by DCM-IR. Frequency-resolved coupling analysis showed that the information flow from contralateral SMA to M1 was predominantly a linear alpha-to-alpha (9-13 Hz) interaction. We also detected some cross-frequency coupling from SMA to contralateral M1, i.e., between lower beta (14-21 Hz) at the SMA and higher beta (22-30 Hz) at M1 during right hand grip and between alpha (9-13 Hz) at SMA and lower beta (14-21 Hz) at M1 during left hand grip. In conclusion, the strategy of informing EEG source-space configurations with fMRI-derived coordinates, cross-validating basic connectivity maps and analysing frequency coding allows for deeper insight into the motor network architecture of the human brain. The present results provide evidence for the robustness of non-invasively measured causal information flow from secondary motor areas such as SMA towards M1 and further contribute to the validation of the methodological approach of multimodal DCM to explore human network dynamics.},
	journal = {NeuroImage},
	author = {B??nstrup, Marlene and Schulz, Robert and Feldheim, Jan and Hummel, Friedhelm C. and Gerloff, Christian},
	year = {2016},
	pmid = {26334836},
	keywords = {EEG, Effective connectivity, FMRI, DCM, Motor network},
	pages = {498--508},
	file = {Attachment:/Users/tito/Zotero/storage/FV77SIDW/Bnstrup et al. - 2016 - Dynamic causal modelling of EEG and fMRI to characterize network architectures in a simple motor task.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/BCYUKRFG/Bnstrup et al. - 2016 - Dynamic causal modelling of EEG and fMRI to characterize network architectures in a simple motor task.pdf:application/pdf},
}

@article{sporns_classes_2001,
	title = {Classes of network connectivity and dynamics},
	volume = {7},
	issn = {1076-2787},
	url = {http://dx.doi.org/10.1002/cplx.10015%5Cnhttp://doi.wiley.com/10.1002/cplx.10015},
	doi = {10.1002/cplx.10015},
	abstract = {Many kinds of complex systems exhibit characteristic patterns of temporal correlations that emerge as the result of functional interactions within a structured network. One such complex system is the brain, composed of numerous neuronal units linked by synaptic connections. The activity of these neuronal units gives rise to dynamic states that are characterized by specific patterns of neuronal activation and co-activation. These patterns, called functional connectivity, are possible neural correlates of perceptual and cognitive processes. Which functional connectivity patterns arise depends on the anatomical structure of the underlying network, which in turn is modified by a broad range of activity-dependent processes. Given this intricate relationship between structure and function, the question of how patterns of anatomical connectivity constrain or determine dynamical patterns is of considerable theoretical importance. The present study develops computational tools to analyze networks in terms of their structure and dynamics. We identify different classes of network, including networks that are characterized by high complexity. These highly complex networks have distinct structural characteristics such as clustered connectivity and short wiring length similar to those of large-scale networks of the cerebral cortex. � 2002 Wiley Periodicals, Inc.},
	number = {1},
	journal = {Complexity},
	author = {Sporns, Olaf and Tononi, Giulio},
	year = {2001},
	keywords = {connectivity, networks, complexity, covariance, information theory},
	pages = {28--38},
	file = {Attachment:/Users/tito/Zotero/storage/YNFCGHCD/Sporns, Tononi - 2001 - Classes of network connectivity and dynamics.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/2SRBXP65/Sporns, Tononi - 2001 - Classes of network connectivity and dynamics.pdf:application/pdf},
}

@article{analysis_phase-plane_2009,
	title = {Phase-{Plane} {Analysis} of {Neural} {Nets}},
	author = {Analysis, Phase-plane and Nets, Neural},
	year = {2009},
	pages = {1--10},
	file = {Attachment:/Users/tito/Zotero/storage/KKNEHN5X/Analysis, Nets - 2009 - Phase-Plane Analysis of Neural Nets.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/JHFUUKT8/Analysis, Nets - 2009 - Phase-Plane Analysis of Neural Nets.pdf:application/pdf},
}

@article{traud_comparing_2011,
	title = {Comparing {Community} {Structure} to {Characteristics} in {Online} {Collegiate} {Social} {Networks}},
	volume = {53},
	issn = {0036-1445},
	url = {http://arxiv.org/abs/0809.0690},
	doi = {10.1137/080734315},
	abstract = {We study the structure of social networks of students by examining the graphs of Facebook "friendships" at five American universities at a single point in time. We investigate each single-institution network's community structure and employ graphical and quantitative tools, including standardized pair-counting methods, to measure the correlations between the network communities and a set of self-identified user characteristics (residence, class year, major, and high school). We review the basic properties and statistics of the pair-counting indices employed and recall, in simplified notation, a useful analytical formula for the z-score of the Rand coefficient. Our study illustrates how to examine different instances of social networks constructed in similar environments, emphasizes the array of social forces that combine to form "communities," and leads to comparative observations about online social lives that can be used to infer comparisons about offline social structures. In our illustration of this methodology, we calculate the relative contributions of different characteristics to the community structure of individual universities and subsequently compare these relative contributions at different universities, measuring for example the importance of common high school affiliation to large state universities and the varying degrees of influence common major can have on the social structure at different universities. The heterogeneity of communities that we observe indicates that these networks typically have multiple organizing factors rather than a single dominant one.},
	number = {3},
	journal = {SIAM Review},
	author = {Traud, Amanda L. and Kelsic, Eric D. and Mucha, Peter J. and Porter, Mason a.},
	year = {2011},
	keywords = {networks, 10, doi, 080734315, 1137, 2008, 62h17, 82-08, 91-08, 91d30, accepted for publication, ams subject classifications, august, community structure, contingency tables, in revised form, pair counting, received by the editors, september 4},
	pages = {17},
	file = {Attachment:/Users/tito/Zotero/storage/QJEU3EPN/Traud et al. - 2010 - Comparing community structure to characteristics in online collegiate social networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/2E96P5SI/Traud et al. - 2010 - Comparing community structure to characteristics in online collegiate social networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Z33IHNI5/Traud et al. - 2010 - Comparing community structure to characteristics in online collegiate social networks.pdf:application/pdf},
}

@article{newman_physics_2008,
	title = {The physics of networks},
	number = {November},
	author = {Newman, Mark},
	year = {2008},
	keywords = {November 2008, p 33-38, Physics Today},
	pages = {33--38},
	file = {Attachment:/Users/tito/Zotero/storage/FFGSA84H/Nilsson, Nilsson - 2001 - The physics of.pdf:application/pdf},
}

@article{newman_finding_2004,
	title = {Finding and evaluating community structure in networks},
	volume = {69},
	issn = {1539-3755},
	doi = {10.1103/PhysRevE.69.026113},
	number = {2},
	journal = {Physical Review E},
	author = {{Newman} and Girvan, M.},
	year = {2004},
	pmid = {14995526},
	pages = {026113},
	file = {Attachment:/Users/tito/Zotero/storage/UQ5BNBCQ/Newman, Girvan - 2004 - Finding and evaluating community structure in networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/AEBRWJKB/Newman, Girvan - 2004 - Finding and evaluating community structure in networks.pdf:application/pdf},
}

@article{blondel_fast_2008,
	title = {Fast unfolding of communities in large networks},
	volume = {10008},
	issn = {1742-5468},
	url = {http://arxiv.org/abs/0803.0476},
	doi = {10.1088/1742-5468/2008/10/P10008},
	abstract = {We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection method in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2.6 million customers and by analyzing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad-hoc modular networks. .},
	number = {10},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
	year = {2008},
	pmid = {260529900010},
	keywords = {networks, critical phenomena of socio-economic, fast unfolding of communities, in large networks, random graphs, socio-economic networks, systems},
	pages = {6},
	file = {Attachment:/Users/tito/Zotero/storage/75PH3MIL/Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/H24H5JW2/Blondel et al. - 2008 - Fast unfolding of communities in large networks.pdf:application/pdf},
}

@article{cole_rapid_2012,
	title = {Rapid instructed task learning: {A} new window into the human brain's unique capacity for flexible cognitive control},
	issn = {1530-7026},
	doi = {10.3758/s13415-012-0125-7},
	abstract = {The human ability to flexibly adapt to novel circumstances is extraordinary. Perhaps the most illustrative, yet underappreciated, form of this cognitive flexibility is rapid instructed task learning (RITL)–the ability to rapidly reconfigure our minds to perform new tasks from instructions. This ability is important for everyday life (e.g., learning to use new technologies) and is used to instruct participants in nearly every study of human cognition. We review the development of RITL as a circumscribed domain of cognitive neuroscience investigation, culminating in recent demonstrations that RITL is implemented via brain circuits centered on lateral prefrontal cortex. We then build on this and the recent discovery of compositional representations within lateral prefrontal cortex to develop an integrative theory of cognitive flexibility and cognitive control that identifies mechanisms that may enable RITL within the human brain. The insights gained from this new theoretical account have important implications for further developments and applications of RITL research.},
	journal = {Cognitive, Affective, \& Behavioral Neuroscience},
	author = {Cole, Michael W. and Laurent, Patryk and Stocco, Andrea},
	year = {2012},
	pmid = {23065743},
	keywords = {computational model, cognitive control, prefrontal cortex, Language, Intelligence, Brain, Cognition, Humans, Prefrontal Cortex, Models, Animals, Learning, Learning: physiology, Brain: physiology, Animal, Cognition: physiology, Prefrontal Cortex: physiology, cognitive flexibility, animal models, compositionality, control, flexible cognitive, Intelligence: physiology, Psychological},
	pages = {1--22},
	file = {Attachment:/Users/tito/Zotero/storage/4RPVMCNH/Cole, Laurent, Stocco - 2013 - Rapid instructed task learning a new window into the human brain's unique capacity for flexible cognitive.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/9BRAXTI4/Cole, Laurent, Stocco - 2013 - Rapid instructed task learning a new window into the human brain's unique capacity for flexible cognitive.pdf:application/pdf},
}

@article{girvan_community_2002,
	title = {Community structure in social and biological networks},
	volume = {99},
	issn = {0027-8424},
	url = {http://www.pnas.org/content/99/12/7821.abstract%5Cnhttp://www.pnas.org/content/99/12/7821.full.pdf%5Cnhttp://www.pnas.org/cgi/content/abstract/99/12/7821},
	doi = {10.1073/pnas.122653799},
	abstract = {10.1073/pnas.122653799 A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well knownâa collaboration network and a food webâand find that it detects significant and informative community divisions in both cases.},
	number = {12},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Girvan, M. and Girvan, M. and Newman, M. E. J. and Newman, M. E. J.},
	year = {2002},
	pmid = {12060727},
	pages = {7821--7826},
	file = {Attachment:/Users/tito/Zotero/storage/R63WXTKH/Girvan et al. - 2002 - Community structure in social and biological networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/NSETUDJW/Girvan et al. - 2002 - Community structure in social and biological networks.pdf:application/pdf},
}

@article{ledoux_dynamics_2011,
	title = {Dynamics of networks of excitatory and inhibitory neurons in response to time-dependent inputs.},
	volume = {5},
	issn = {1662-5188},
	doi = {10.3389/fncom.2011.00025},
	abstract = {We investigate the dynamics of recurrent networks of excitatory (E) and inhibitory (I) neurons in the presence of time-dependent inputs. The dynamics is characterized by the network dynamical transfer function, i.e., how the population firing rate is modulated by sinusoidal inputs at arbitrary frequencies. Two types of networks are studied and compared: (i) a Wilson-Cowan type firing rate model; and (ii) a fully connected network of leaky integrate-and-fire (LIF) neurons, in a strong noise regime. We first characterize the region of stability of the "asynchronous state" (a state in which population activity is constant in time when external inputs are constant) in the space of parameters characterizing the connectivity of the network. We then systematically characterize the qualitative behaviors of the dynamical transfer function, as a function of the connectivity. We find that the transfer function can be either low-pass, or with a single or double resonance, depending on the connection strengths and synaptic time constants. Resonances appear when the system is close to Hopf bifurcations, that can be induced by two separate mechanisms: the I-I connectivity and the E-I connectivity. Double resonances can appear when excitatory delays are larger than inhibitory delays, due to the fact that two distinct instabilities exist with a finite gap between the corresponding frequencies. In networks of LIF neurons, changes in external inputs and external noise are shown to be able to change qualitatively the network transfer function. Firing rate models are shown to exhibit the same diversity of transfer functions as the LIF network, provided delays are present. They can also exhibit input-dependent changes of the transfer function, provided a suitable static non-linearity is incorporated.},
	number = {May},
	journal = {Frontiers in computational neuroscience},
	author = {Ledoux, Erwan and Brunel, Nicolas},
	year = {2011},
	pmid = {21647353},
	keywords = {feedback inhibition, inhibition, dynamics of neural networks, feed-forward, leaky integrate-and-fire neuron, sinusoidal inputs, synaptic connectivity, ti, time-dependent inputs, transfer function},
	pages = {25},
	file = {Attachment:/Users/tito/Zotero/storage/J6NHPCDA/Ledoux, Brunel - 2011 - Dynamics of networks of excitatory and inhibitory neurons in response to time-dependent inputs.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/KYSN3ELX/Ledoux, Brunel - 2011 - Dynamics of networks of excitatory and inhibitory neurons in response to time-dependent inputs.pdf:application/pdf},
}

@article{bekolay_nengo:_2014,
	title = {Nengo: a {Python} tool for building large-scale functional brain models.},
	volume = {7},
	issn = {1662-5196},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24431999},
	doi = {10.3389/fninf.2013.00048},
	abstract = {Neuroscience currently lacks a comprehensive theory of how cognitive processes can be implemented in a biological substrate. The Neural Engineering Framework (NEF) proposes one such theory, but has not yet gathered significant empirical support, partly due to the technical challenge of building and simulating large-scale models with the NEF. Nengo is a software tool that can be used to build and simulate large-scale models based on the NEF; currently, it is the primary resource for both teaching how the NEF is used, and for doing research that generates specific NEF models to explain experimental data. Nengo 1.4, which was implemented in Java, was used to create Spaun, the world's largest functional brain model (Eliasmith et al., 2012). Simulating Spaun highlighted limitations in Nengo 1.4's ability to support model construction with simple syntax, to simulate large models quickly, and to collect large amounts of data for subsequent analysis. This paper describes Nengo 2.0, which is implemented in Python and overcomes these limitations. It uses simple and extendable syntax, simulates a benchmark model on the scale of Spaun 50 times faster than Nengo 1.4, and has a flexible mechanism for collecting simulation results.},
	number = {January},
	journal = {Frontiers in neuroinformatics},
	author = {Bekolay, Trevor and Bergstra, James and Hunsberger, Eric and Dewolf, Travis and Stewart, Terrence C and Rasmussen, Daniel and Choo, Xuan and Voelker, Aaron Russell and Eliasmith, Chris},
	year = {2014},
	pmid = {24431999},
	keywords = {theoretical neuroscience, neuroscience, neural engineering framework, python, control theory, nengo, neuro, Python},
	pages = {48},
	file = {Attachment:/Users/tito/Zotero/storage/UDVQ44VB/Bekolay et al. - 2014 - Nengo a Python tool for building large-scale functional brain models.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/UH5I5SSI/Bekolay et al. - 2014 - Nengo a Python tool for building large-scale functional brain models.pdf:application/pdf},
}

@article{stokes_dynamic_2013,
	title = {Dynamic coding for cognitive control in prefrontal cortex},
	volume = {78},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2013.01.039},
	doi = {10.1016/j.neuron.2013.01.039},
	abstract = {Cognitive flexibility is fundamental to adaptive intelligent behavior. Prefrontal cortex has long been associated with flexible cognitive function, but the neurophysiological principles that enable prefrontal cells to adapt their response properties according to context-dependent rules remain poorly understood. Here, we use time-resolved population-level neural pattern analyses to explore how context is encoded and maintained in primate prefrontal cortex and used in flexible decision making. We show that an instruction cue triggers a rapid series of state transitions before settling into a stable low-activity state. The postcue state is differentially tuned according to the current task-relevant rule. During decision making, the response to a choice stimulus is characterized by an initial stimulus-specific population response but evolves to different final decision-related states depending on the current rule. These results demonstrate how neural tuning profiles in prefrontal cortex adapt to accommodate changes in behavioral context. Highly flexible tuning could be mediated via short-term synaptic plasticity},
	number = {2},
	journal = {Neuron},
	author = {Stokes, Mark G. and Kusunoki, Makoto and Sigala, Natasha and Nili, Hamed and Gaffan, David and Duncan, John},
	year = {2013},
	pmid = {23562541},
	pages = {364--375},
	file = {Attachment:/Users/tito/Zotero/storage/IBJCUGAF/Stokes et al. - 2013 - Dynamic coding for cognitive control in prefrontal cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/WIMEVA8I/Stokes et al. - 2013 - Dynamic coding for cognitive control in prefrontal cortex.pdf:application/pdf},
}

@article{wang_division_2004,
	title = {Division of labor among distinct subtypes of inhibitory neurons in a cortical microcircuit of working memory.},
	volume = {101},
	issn = {0027-8424},
	doi = {10.1073/pnas.0305337101},
	abstract = {A conspicuous feature of cortical organization is the wide diversity of inhibitory interneurons; their differential computational functions remain unclear. Here we propose a local cortical circuit in which three major subtypes of interneurons play distinct roles. In a model designed for spatial working memory, stimulus tuning of persistent activity arises from the concerted action of widespread inhibition mediated by perisoma-targeting (parvalbumin-containing) interneurons and localized disinhibition of pyramidal cells via interneuron-targeting (calretinin-containing) interneurons. Moreover, resistance against distracting stimuli (a fundamental property of working memory) is dynamically controlled by dendrite-targeting (calbindin-containing) interneurons. The experimental observation of inverted tuning curves of monkey prefrontal neurons recorded during working memory supports a key model prediction. This work suggests a framework for understanding the division of labor and cooperation among different inhibitory cell types in a recurrent cortical circuit.},
	number = {5},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Wang, X-J and Tegnér, J and Constantinidis, C and Goldman-Rakic, P S},
	year = {2004},
	pmid = {14742867},
	pages = {1368--1373},
	file = {Attachment:/Users/tito/Zotero/storage/T5AJGTHK/Wang et al. - 2004 - Division of labor among distinct subtypes of inhibitory neurons in a cortical microcircuit of working memory.pdf:application/pdf},
}

@article{yamins_performance-optimized_2014,
	title = {Performance-optimized hierarchical models predict neural responses in higher visual cortex},
	volume = {111},
	issn = {0027-8424},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1403112111},
	doi = {10.1073/pnas.1403112111},
	number = {23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Yamins, D. L. K. and Hong, H. and Cadieu, C. F. and Solomon, E. A. and Seibert, D. and DiCarlo, J. J.},
	year = {2014},
	pages = {8619--8624},
	file = {Attachment:/Users/tito/Zotero/storage/UL8BHALM/Yamins et al. - 2014 - Performance-optimized hierarchical models predict neural responses in higher visual cortex.pdf:application/pdf},
}

@article{winograd_hyperpolarization-activated_2008,
	title = {Hyperpolarization-activated graded persistent activity in the prefrontal cortex.},
	volume = {105},
	issn = {0027-8424},
	doi = {10.1073/pnas.0800360105},
	abstract = {We describe a phenomenon of hyperpolarization-activated graded persistent activity (HAGPA) in prefrontal cortex neurons. Successive hyperpolarizing pulses induced increasingly higher rates of tonic firing that remained stable for tens of seconds, allowing the neuron to retain a memory of the previous history of stimulation. This phenomenon occurred at the cellular level and in the absence of neuromodulators. Neurons with HAGPA had a sag during hyperpolarization, and blocking h-current eliminated the sag and prevented HAGPA, suggesting that the activation of this hyperpolarization-activated cationic current was necessary for the occurrence of the phenomenon. A single-neuron biophysical model including h-current modulation by intracellular calcium was able to display HAGPA. This form of neuronal memory not only allows the transformation of inhibition into an increase of firing rate, but also endows neurons with a mechanism to compute the properties of successive inputs into persistent activity, thus solving a difficult computational problem.},
	number = {20},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Winograd, Milena and Destexhe, Alain and Sanchez-Vives, Maria V},
	year = {2008},
	pmid = {18474856},
	pages = {7298--7303},
	file = {Attachment:/Users/tito/Zotero/storage/P5BAWPXR/Winograd, Destexhe, Sanchez-Vives - 2008 - Hyperpolarization-activated graded persistent activity in the prefrontal cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/ZN86BUHF/Winograd, Destexhe, Sanchez-Vives - 2008 - Hyperpolarization-activated graded persistent activity in the prefrontal cortex.pdf:application/pdf},
}

@article{taylor_global_2015,
	title = {The global landscape of cognition: hierarchical aggregation as an organizational principle of human cortical networks and functions},
	volume = {5},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep18112},
	doi = {10.1038/srep18112},
	number = {November},
	journal = {Scientific Reports},
	author = {Taylor, P. and Hobbs, J. N. and Burroni, J. and Siegelmann, H. T.},
	year = {2015},
	pages = {18112},
	file = {Attachment:/Users/tito/Zotero/storage/3HEPBP2M/Taylor et al. - 2015 - The global landscape of cognition hierarchical aggregation as an organizational principle of human cortical netwo.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/SLNI7637/Taylor et al. - 2015 - The global landscape of cognition hierarchical aggregation as an organizational principle of human cortical netwo.pdf:application/pdf},
}

@article{buzsaki_hippocampal_2015,
	title = {Hippocampal sharp wave-ripple: {A} cognitive biomarker for episodic memory and planning},
	volume = {25},
	issn = {10981063},
	doi = {10.1002/hipo.22488},
	abstract = {Sharp wave ripples (SPW-Rs) represent the most synchronous population pattern in the mammalian brain. Their excitatory output affects a wide area of the cortex and several subcortical nuclei. SPW-Rs occur during "off-line" states of the brain, associated with consummatory behaviors and non-REM sleep, and are influenced by numerous neurotransmitters and neuromodulators. They arise from the excitatory recurrent system of the CA3 region and the SPW-induced excitation brings about a fast network oscillation (ripple) in CA1. The spike content of SPW-Rs is temporally and spatially coordinated by a consortium of interneurons to replay fragments of waking neuronal sequences in a compressed format. SPW-Rs assist in transferring this compressed hippocampal representation to distributed circuits to support memory consolidation; selective disruption of SPW-Rs interferes with memory. Recently acquired and pre-existing information are combined during SPW-R replay to influence decisions, plan actions and, potentially, allow for creative thoughts. In addition to the widely studied contribution to memory, SPW-Rs may also affect endocrine function via activation of hypothalamic circuits. Alteration of the physiological mechanisms supporting SPW-Rs leads to their pathological conversion, "p-ripples," which are a marker of epileptogenic tissue and can be observed in rodent models of schizophrenia and Alzheimer's Disease. Mechanisms for SPW-R genesis and function are discussed in this review. © 2015 The Authors Hippocampus Published by Wiley Periodicals, Inc.},
	number = {10},
	journal = {Hippocampus},
	author = {Buzsáki, György},
	year = {2015},
	pmid = {26135716},
	keywords = {Learning, Memory, Epilepsy, Imagining, Planning},
	pages = {1073--1188},
}

@article{kessler_modality-spanning_2014,
	title = {Modality-{Spanning} {Deficits} in {Attention}-{Deficit}/{Hyperactivity} {Disorder} in {Functional} {Networks}, {Gray} {Matter}, and {White} {Matter}},
	volume = {34},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3156-14.2014},
	doi = {10.1523/JNEUROSCI.3156-14.2014},
	number = {50},
	journal = {Journal of Neuroscience},
	author = {Kessler, D. and Angstadt, M. and Welsh, R. C. and Sripada, C.},
	year = {2014},
	keywords = {default mode network, resting state fmri, adhd, joint ica, multimodal, structural mri},
	pages = {16555--16566},
	file = {Attachment:/Users/tito/Zotero/storage/7L4LCNIH/Kessler et al. - 2014 - Modality-Spanning Deficits in Attention-DeficitHyperactivity Disorder in Functional Networks, Gray Matter, and W.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/5CFWIUMA/Kessler et al. - 2014 - Modality-Spanning Deficits in Attention-DeficitHyperactivity Disorder in Functional Networks, Gray Matter, and W.pdf:application/pdf},
}

@article{jensen_cross-frequency_2007,
	title = {Cross-frequency coupling between neuronal oscillations},
	volume = {11},
	issn = {13646613},
	doi = {10.1016/j.tics.2007.05.003},
	abstract = {Electrophysiological recordings in animals, including humans, are modulated by oscillatory activities in several frequency bands. Little is known about how oscillations in various frequency bands interact. Recent findings from the human neocortex show that the power of fast gamma oscillations (30-150 Hz) is modulated by the phase of slower theta oscillations (5-8 Hz). Given that this coupling reflects a specific interplay between large ensembles of neurons, it is likely to have profound implications for neuronal processing. ?? 2007 Elsevier Ltd. All rights reserved.},
	number = {7},
	journal = {Trends in Cognitive Sciences},
	author = {Jensen, Ole and Colgin, Laura L.},
	year = {2007},
	pmid = {17548233},
	pages = {267--269},
	file = {Attachment:/Users/tito/Zotero/storage/ZC447YJJ/Jensen, Colgin - 2007 - Cross-frequency coupling between neuronal oscillations.pdf:application/pdf},
}

@article{colgin_gamma_2010,
	title = {Gamma oscillations in the hippocampus},
	volume = {25},
	issn = {1548-9221},
	url = {http://physiologyonline.physiology.org/content/nips/25/5/319.full.pdf},
	doi = {10.1152/physiol.00021.2010},
	abstract = {Gamma oscillations are thought to temporally link the activity of distributed cells. We discuss mechanisms of gamma oscillations in the hippocampus and review evidence supporting a functional role for such oscillations in several key hippocampal operations, including cell grouping, dynamic routing, and memory. We propose that memory encoding and retrieval are coordinated by different frequencies of hippocampal gamma oscillations and suggest how transitions between slow and fast gamma may occur.},
	number = {5},
	journal = {Physiology (Bethesda)},
	author = {Colgin, L L and Moser, E I},
	year = {2010},
	pmid = {20940437},
	keywords = {Humans, Animals, Rats, Theta Rhythm, Mice, *Biological Clocks, *Brain Waves, Hippocampus/cytology/*physiology, Interneurons/physiology, Memory/*physiology, Pyramidal Cells/physiology},
	pages = {319--329},
	file = {Attachment:/Users/tito/Zotero/storage/CV7HHS8F/Colgin, Moser - 2010 - Gamma oscillations in the hippocampus.pdf:application/pdf},
}

@article{pospischil_minimal_2008,
	title = {Minimal {Hodgkin}-{Huxley} type models for different classes of cortical and thalamic neurons},
	volume = {99},
	issn = {03401200},
	doi = {10.1007/s00422-008-0263-8},
	abstract = {We review here the development of Hodgkin-Huxley (HH) type models of cerebral cortex and thalamic neurons for network simulations. The intrinsic electrophysiological properties of cortical neurons were analyzed from several preparations, and we selected the four most prominent electrophysiological classes of neurons. These four classes are "fast spiking", "regular spiking", "intrinsically bursting" and "low-threshold spike" cells. For each class, we fit "minimal" HH type models to experimental data. The models contain the minimal set of voltage-dependent currents to account for the data. To obtain models as generic as possible, we used data from different preparations in vivo and in vitro, such as rat somatosensory cortex and thalamus, guinea-pig visual and frontal cortex, ferret visual cortex, cat visual cortex and cat association cortex. For two cell classes, we used automatic fitting procedures applied to several cells, which revealed substantial cell-to-cell variability within each class. The selection of such cellular models constitutes a necessary step towards building network simulations of the thalamocortical system with realistic cellular dynamical properties.},
	number = {4-5},
	journal = {Biological Cybernetics},
	author = {Pospischil, Martin and Toledo-Rodriguez, Maria and Monier, Cyril and Piwkowska, Zuzanna and Bal, Thierry and Frégnac, Yves and Markram, Henry and Destexhe, Alain},
	year = {2008},
	pmid = {19011929},
	keywords = {Thalamus, Biophysical models, Cerebral cortex, Computational models, Intracellular recordings, Intrinsic neuronal properties, Model fitting},
	pages = {427--441},
	file = {Attachment:/Users/tito/Zotero/storage/8BAWGLMQ/Pospischil et al. - 2008 - Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/RESXU8JH/Pospischil et al. - 2008 - Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons.pdf:application/pdf},
}

@article{eliasmith_how_2007,
	title = {How to build a brain: from function to implementation},
	volume = {159},
	issn = {0039-7857},
	url = {http://link.springer.com/10.1007/s11229-007-9235-0},
	doi = {10.1007/s11229-007-9235-0},
	number = {3},
	journal = {Synthese},
	author = {Eliasmith, Chris},
	year = {2007},
	keywords = {neural networks, cognitive architecture, functional integration, mental representation, neural architecture, neurophilosophy, statistical models},
	pages = {373--388},
	file = {Attachment:/Users/tito/Zotero/storage/C3JBZQRD/Eliasmith - 2007 - How to build a brain from function to implementation.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/WUGVI6VF/Eliasmith - 2007 - How to build a brain from function to implementation.pdf:application/pdf},
}

@article{colgin_mechanisms_2013,
	title = {Mechanisms and functions of theta rhythms.},
	volume = {36},
	issn = {1545-4126},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23724998},
	doi = {10.1146/annurev-neuro-062012-170330},
	abstract = {The theta rhythm is one of the largest and most sinusoidal activity patterns in the brain. Here I survey progress in the field of theta rhythms research. I present arguments supporting the hypothesis that theta rhythms emerge owing to intrinsic cellular properties yet can be entrained by several theta oscillators throughout the brain. I review behavioral correlates of theta rhythms and consider how these correlates inform our understanding of theta rhythms' functions. I discuss recent work suggesting that one function of theta is to package related information within individual theta cycles for more efficient spatial memory processing. Studies examining the role of theta phase precession in spatial memory, particularly sequence retrieval, are also summarized. Additionally, I discuss how interregional coupling of theta rhythms facilitates communication across brain regions. Finally, I conclude by summarizing how theta rhythms may support cognitive operations in the brain, including learning.},
	journal = {Annual review of neuroscience},
	author = {Colgin, Laura Lee},
	year = {2013},
	pmid = {23724998},
	keywords = {Brain, Humans, Animals, Brain: physiology, Memory, Memory: physiology, Theta Rhythm, Theta Rhythm: physiology, Biological Clocks, Biological Clocks: physiology},
	pages = {295--312},
	file = {Attachment:/Users/tito/Zotero/storage/5MQRUT9U/Colgin - 2013 - Mechanisms and functions of theta rhythms.pdf:application/pdf},
}

@article{laurent_emergence_2008,
	title = {The emergence of saliency and novelty responses from {Reinforcement} {Learning} principles},
	volume = {21},
	issn = {08936080},
	url = {http://dx.doi.org/10.1016/j.neunet.2008.09.004},
	doi = {10.1016/j.neunet.2008.09.004},
	abstract = {Recent attempts to map reward-based learning models, like Reinforcement Learning [Sutton, R. S., \& Barto, A. G. (1998). Reinforcement Learning: An introduction. Cambridge, MA: MIT Press], to the brain are based on the observation that phasic increases and decreases in the spiking of dopamine-releasing neurons signal differences between predicted and received reward [Gillies, A., \& Arbuthnott, G. (2000). Computational models of the basal ganglia. Movement Disorders, 15(5), 762-770; Schultz, W. (1998). Predictive reward signal of dopamine neurons. Journal of Neurophysiology, 80(1), 1-27]. However, this reward-prediction error is only one of several signals communicated by that phasic activity; another involves an increase in dopaminergic spiking, reflecting the appearance of salient but unpredicted non-reward stimuli [Doya, K. (2002). Metalearning and neuromodulation. Neural Networks, 15(4-6), 495-506; Horvitz, J. C. (2000). Mesolimbocortical and nigrostriatal dopamine responses to salient non-reward events. Neuroscience, 96(4), 651-656; Redgrave, P., \& Gurney, K. (2006). The short-latency dopamine signal: A role in discovering novel actions? Nature Reviews Neuroscience, 7(12), 967-975], especially when an organism subsequently orients towards the stimulus [Schultz, W. (1998). Predictive reward signal of dopamine neurons. Journal of Neurophysiology, 80(1), 1-27]. To explain these findings, Kakade and Dayan [Kakade, S., \& Dayan, P. (2002). Dopamine: Generalization and bonuses. Neural Networks, 15(4-6), 549-559.] and others have posited that novel, unexpected stimuli are intrinsically rewarding. The simulation reported in this article demonstrates that this assumption is not necessary because the effect it is intended to capture emerges from the reward-prediction learning mechanisms of Reinforcement Learning. Thus, Reinforcement Learning principles can be used to understand not just reward-related activity of the dopaminergic neurons of the basal ganglia, but also some of their apparently non-reward-related activity. ?? 2008 Elsevier Ltd. All rights reserved.},
	number = {10},
	journal = {Neural Networks},
	author = {Laurent, Patryk A.},
	year = {2008},
	pmid = {18938058},
	keywords = {Dopamine, Novelty response, Orienting, Reinforcement learning, Reward-prediction error},
	pages = {1493--1499},
	file = {Attachment:/Users/tito/Zotero/storage/ALJ48N3R/Laurent - 2008 - The emergence of saliency and novelty responses from Reinforcement Learning principles.pdf:application/pdf},
}

@article{colgin_oscillations_2011,
	title = {Oscillations and hippocampal–prefrontal synchrony},
	volume = {21},
	issn = {09594388},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438811000390 http://linkinghub.elsevier.com/retrieve/pii/S095943881100064X},
	doi = {10.1016/j.conb.2011.02.012},
	number = {3},
	journal = {Current Opinion in Neurobiology},
	author = {Colgin, Laura Lee and Gordon, Joshua A},
	year = {2011},
	pages = {486--491},
	file = {Attachment:/Users/tito/Zotero/storage/Y2JZPL4N/Colgin, Gordon - 2011 - Oscillations and hippocampal–prefrontal synchrony.pdf:application/pdf},
}

@article{rigotti_estimating_2015,
	title = {Estimating the dimensionality of neural responses with {fMRI} {Repetition} {Suppression}},
	author = {Rigotti, Mattia and Fusi, Stefano},
	year = {2015},
	file = {Attachment:/Users/tito/Zotero/storage/S8ZDIC8K/Rigotti, Fusi - 2015 - Estimating the dimensionality of neural responses with fMRI Repetition Suppression.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/EG6CJGHS/Rigotti, Fusi - 2015 - Estimating the dimensionality of neural responses with fMRI Repetition Suppression.pdf:application/pdf},
}

@article{hahn_spontaneous_2012,
	title = {Spontaneous persistent activity in entorhinal cortex modulates cortico-hippocampal interaction in vivo},
	volume = {15},
	issn = {1097-6256},
	url = {http://dx.doi.org/10.1038/nn.3236},
	doi = {10.1038/nn.3236},
	abstract = {Persistent activity is thought to mediate working memory during behavior. Can it also occur during sleep? We found that the membrane potential of medial entorhinal cortex layer III (MECIII) neurons, a gateway between neocortex and hippocampus, showed spontaneous, stochastic persistent activity in vivo in mice during Up-Down state oscillations (UDS). This persistent activity was locked to the neocortical Up states with a short delay, but persisted over several cortical UDS cycles. Lateral entorhinal neurons did not show substantial persistence, and current injections similar to those used in vitro failed to elicit persistence in vivo, implicating network mechanisms. Hippocampal CA1 neurons' spiking activity was reduced during neocortical Up states, but was increased during MECIII persistent states. These results provide, to the best of our knowledge, the first direct evidence for persistent activity in MECIII neurons in vivo and reveal its contribution to cortico-hippocampal interaction that could be involved in working memory and learning of long behavioral sequences during behavior, and memory consolidation during sleep.},
	number = {11},
	journal = {Nature Neuroscience},
	author = {Hahn, Thomas T G and McFarland, James M and Berberich, Sven and Sakmann, Bert and Mehta, Mayank R},
	year = {2012},
	pmid = {23042081},
	pages = {1531--1538},
	file = {Attachment:/Users/tito/Zotero/storage/GYCD2GIR/Hahn et al. - 2012 - Spontaneous persistent activity in entorhinal cortex modulates cortico-hippocampal interaction in vivo.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/H6A9IK4I/Hahn et al. - 2012 - Spontaneous persistent activity in entorhinal cortex modulates cortico-hippocampal interaction in vivo.pdf:application/pdf},
}

@article{beer_dynamics_1995,
	title = {On the {Dynamics} of {Small} {Continuous}-{Time} {Recurrent} {Neural} {Networks}},
	volume = {3},
	issn = {1059-7123},
	url = {http://adb.sagepub.com/cgi/doi/10.1177/105971239500300405},
	doi = {10.1177/105971239500300405},
	number = {4},
	journal = {Adapt Behav},
	author = {Beer, R D},
	year = {1995},
	keywords = {nonlinear dynamics, computational neuroethology, dynamical neural networks, evolutionary search},
	pages = {469--509},
	file = {Attachment:/Users/tito/Zotero/storage/X3BT5TWA/Beer - 1995 - On the Dynamics of Small Continuous-Time Recurrent Neural Networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/JW8PRES7/Beer - 1995 - On the Dynamics of Small Continuous-Time Recurrent Neural Networks.pdf:application/pdf},
}

@article{volk_pkm-zeta_2013,
	title = {{PKM}-zeta is not required for hippocampal synaptic plasticity, learning and memory},
	volume = {493},
	issn = {1476-4687},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23283174},
	doi = {10.1038/nature11802},
	abstract = {Long-term potentiation (LTP), a well-characterized form of synaptic plasticity, has long been postulated as a cellular correlate of learning and memory. Although LTP can persist for long periods of time, the mechanisms underlying LTP maintenance, in the midst of ongoing protein turnover and synaptic activity, remain elusive. Sustained activation of the brain-specific protein kinase C (PKC) isoform protein kinase M-zeta (PKM-zeta) has been reported to be necessary for both LTP maintenance and long-term memory. Inhibiting PKM-zeta activity using a synthetic zeta inhibitory peptide (ZIP) based on the PKC-zeta pseudosubstrate sequence reverses established LTP in vitro and in vivo. More notably, infusion of ZIP eliminates memories for a growing list of experience-dependent behaviours, including active place avoidance, conditioned taste aversion, fear conditioning and spatial learning. However, most of the evidence supporting a role for PKM-zeta in LTP and memory relies heavily on pharmacological inhibition of PKM-zeta by ZIP. To further investigate the involvement of PKM-zeta in the maintenance of LTP and memory, we generated transgenic mice lacking PKC-zeta and PKM-zeta. We find that both conventional and conditional PKC-zeta/PKM-zeta knockout mice show normal synaptic transmission and LTP at Schaffer collateral-CA1 synapses, and have no deficits in several hippocampal-dependent learning and memory tasks. Notably, ZIP still reverses LTP in PKC-zeta/PKM-zeta knockout mice, indicating that the effects of ZIP are independent of PKM-zeta.},
	number = {7432},
	journal = {Nature},
	author = {Volk, L J and Bachman, J L and Johnson, R and Yu, Y and Huganir, R L},
	year = {2013},
	pmid = {23283174},
	keywords = {Behavior, Female, Male, Animals, Memory, Mice, Animal/drug effects/physiology, Avoidance Learning/drug effects/physiology, Classical, Conditioning, Fear, Hippocampus/drug effects/*physiology, Isoenzymes/deficiency/genetics/metabolism, Knockout, Lipopeptides/pharmacology, Long-Term Potentiation/drug effects/genetics/physi, Long-Term/drug effects/*physiology, Neuronal Plasticity/genetics/*physiology, Protein Kinase C/antagonists \& inhibitors/deficien, Synapses/drug effects/*metabolism, Synaptic Transmission/drug effects},
	pages = {420--423},
	file = {Attachment:/Users/tito/Zotero/storage/9UB72MSV/Volk et al. - 2013 - PKM-zeta is not required for hippocampal synaptic plasticity, learning and memory.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/83U6WUW5/Volk et al. - 2013 - PKM-zeta is not required for hippocampal synaptic plasticity, learning and memory.pdf:application/pdf},
}

@article{friedrich_goal-directed_2016,
	title = {Goal-{Directed} {Decision} {Making} with {Spiking} {Neurons}},
	volume = {36},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2854-15.2016},
	doi = {10.1523/JNEUROSCI.2854-15.2016},
	number = {5},
	journal = {Journal of Neuroscience},
	author = {Friedrich, J. and Lengyel, M.},
	year = {2016},
	pmid = {26843636},
	keywords = {decision making, computational modeling, significance statement, reinforcement learning, but their circuit-level mechanisms, goal-directed actions requiring prospective, model circuit of biologically, neuroeconomics, planning, planning pervade decision making, problem in a, realistic spiking neurons can, remain elusive, solve this computationally challenging, spiking neurons, we show how a},
	pages = {1529--1546},
	file = {Attachment:/Users/tito/Zotero/storage/DFARKVMG/Friedrich, Lengyel - 2016 - Goal-Directed Decision Making with Spiking Neurons.pdf:application/pdf},
}

@article{ling_protein_2002,
	title = {Protein kinase {Mzeta} is necessary and sufficient for {LTP} maintenance.},
	volume = {5},
	issn = {1097-6256},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/11914719},
	doi = {10.1038/nn829},
	abstract = {Long-term potentiation (LTP), a persistent synaptic enhancement thought to be a substrate for memory1, can be divided into two phases: induction, triggering potentiation, and maintenance, sustaining it over time1, 2. Many postsynaptic events are implicated in induction, including N-methyl-D-aspartate receptor (NMDAR) activation, calcium increases and stimulation of several protein kinases1; in contrast, the mechanism maintaining LTP is not yet characterized1. Here we show the constitutively active form of an atypical protein kinase C (PKC) isozyme, protein kinase M zeta (PKMzeta), is necessary and sufficient for LTP maintenance.},
	number = {4},
	journal = {Nature neuroscience},
	author = {Ling, Douglas S F and Benardo, Larry S and Serrano, Peter a and Blace, Nancy and Kelly, Matthew T and Crary, John F and Sacktor, Todd C},
	year = {2002},
	pmid = {11914719},
	keywords = {Animals, Hippocampus, Hippocampus: cytology, Patch-Clamp Techniques, Pyramidal Cells, Pyramidal Cells: drug effects, Receptors, Alkaloids, AMPA, AMPA: metabolism, Benzophenanthridines, Enzyme Inhibitors, Enzyme Inhibitors: pharmacology, Excitatory Postsynaptic Potentials, Excitatory Postsynaptic Potentials: physiology, Hippocampus: metabolism, Long-Term Potentiation, Long-Term Potentiation: physiology, N-Methyl-D-Aspartate, N-Methyl-D-Aspartate: metabolism, Phenanthridines, Phenanthridines: pharmacology, Protein Kinase C, Protein Kinase C: antagonists \& inhibitors, Protein Kinase C: metabolism, Pyramidal Cells: metabolism, Staurosporine, Staurosporine: pharmacology},
	pages = {295--296},
	file = {Attachment:/Users/tito/Zotero/storage/FPKH2MX5/Ling et al. - 2002 - Protein kinase Mzeta is necessary and sufficient for LTP maintenance.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/CF7KRARL/Ling et al. - 2002 - Protein kinase Mzeta is necessary and sufficient for LTP maintenance.pdf:application/pdf},
}

@article{watts_collective_1998,
	title = {Collective dynamics of 'small-world' networks.},
	volume = {393},
	issn = {0028-0836},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/9623998},
	doi = {10.1038/30918},
	abstract = {Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon (popularly known as six degrees of separation. The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.},
	number = {6684},
	journal = {Nature},
	author = {Watts, D J and Strogatz, S H},
	year = {1998},
	pmid = {9623998},
	keywords = {Nerve Net, Models, Neurological, Theoretical, Animals, Biological, Caenorhabditis elegans, Caenorhabditis elegans: physiology, Communicable Diseases, Communicable Diseases: transmission, Experimental, Games},
	pages = {440--2},
	file = {Attachment:/Users/tito/Zotero/storage/XYGH2CWL/Watts, Strogatz - 1998 - Collective dynamics of 'small-world' networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/QLVIL4B8/Watts, Strogatz - 1998 - Collective dynamics of 'small-world' networks.pdf:application/pdf},
}

@article{buzs??ki_theta_2002,
	title = {Theta oscillations in the hippocampus},
	volume = {33},
	issn = {08966273},
	doi = {10.1016/S0896-6273(02)00586-X},
	abstract = {Theta oscillations represent the "on-line" state of the hippocampus. The extracellular currents underlying theta waves are generated mainly by the entorhinal input, CA3 (Schaffer) collaterals, and voltage-dependent Ca2+ currents in pyramidal cell dendrites. The rhythm is believed to be critical for temporal coding/decoding of active neuronal ensembles and the modification of synaptic weights. Nevertheless, numerous critical issues regarding both the generation of theta oscillations and their functional significance remain challenges for future research.},
	number = {3},
	journal = {Neuron},
	author = {Buzs??ki, Gy??rgy},
	year = {2002},
	pmid = {11832222},
	pages = {325--340},
	file = {Attachment:/Users/tito/Zotero/storage/C784GTLV/Buzski - 2002 - Theta oscillations in the hippocampus.pdf:application/pdf},
}

@article{wandell_computational_2015,
	title = {Computational neuroimaging and population receptive fields},
	volume = {19},
	issn = {1879307X},
	url = {http://dx.doi.org/10.1016/j.tics.2015.03.009},
	doi = {10.1016/j.tics.2015.03.009},
	abstract = {Functional magnetic resonance imaging (fMRI) noninvasively measures human brain activity at millimeter resolution. Scientists use different approaches to take advantage of the remarkable opportunities presented by fMRI. Here, we describe progress using the computational neuroimaging approach in human visual cortex, which aims to build models that predict the neural responses from the stimulus and task. We focus on a particularly active area of research, the use of population receptive field (pRF) models to characterize human visual cortex responses to a range of stimuli, in a variety of tasks and different subject populations.},
	number = {6},
	journal = {Trends in Cognitive Sciences},
	author = {Wandell, Brian A. and Winawer, Jonathan},
	year = {2015},
	pmid = {25850730},
	pages = {349--357},
	file = {Attachment:/Users/tito/Zotero/storage/3DC8RB3D/Wandell, Winawer - 2015 - Computational neuroimaging and population receptive fields.pdf:application/pdf},
}

@article{wang_neurophysiological_2010,
	title = {Neurophysiological and computational principles of cortical rhythms in cognition.},
	volume = {90},
	issn = {1522-1210},
	url = {http://physrev.physiology.org/content/90/3/1195},
	doi = {10.1152/physrev.00035.2008},
	abstract = {Synchronous rhythms represent a core mechanism for sculpting temporal coordination of neural activity in the brain-wide network. This review focuses on oscillations in the cerebral cortex that occur during cognition, in alert behaving conditions. Over the last two decades, experimental and modeling work has made great strides in elucidating the detailed cellular and circuit basis of these rhythms, particularly gamma and theta rhythms. The underlying physiological mechanisms are diverse (ranging from resonance and pacemaker properties of single cells to multiple scenarios for population synchronization and wave propagation), but also exhibit unifying principles. A major conceptual advance was the realization that synaptic inhibition plays a fundamental role in rhythmogenesis, either in an interneuronal network or in a reciprocal excitatory-inhibitory loop. Computational functions of synchronous oscillations in cognition are still a matter of debate among systems neuroscientists, in part because the notion of regular oscillation seems to contradict the common observation that spiking discharges of individual neurons in the cortex are highly stochastic and far from being clocklike. However, recent findings have led to a framework that goes beyond the conventional theory of coupled oscillators and reconciles the apparent dichotomy between irregular single neuron activity and field potential oscillations. From this perspective, a plethora of studies will be reviewed on the involvement of long-distance neuronal coherence in cognitive functions such as multisensory integration, working memory, and selective attention. Finally, implications of abnormal neural synchronization are discussed as they relate to mental disorders like schizophrenia and autism.},
	number = {3},
	journal = {Physiological reviews},
	author = {Wang, Xiao-Jing},
	year = {2010},
	pmid = {20664082},
	keywords = {Cerebral Cortex, Cognition, Nerve Net, Animals, Nerve Net: physiology, Neurons, Neurons: physiology, Cognition: physiology, Cerebral Cortex: physiology, Cortical Synchronization, Electroencephalography, Theta Rhythm, Cerebral Cortex: cytology, Computational Biology, Computational Biology: methods, Mental Disorders, Mental Disorders: physiopathology, Oscillometry},
	pages = {1195--268},
	file = {Attachment:/Users/tito/Zotero/storage/QLUWXN9N/Wang - 2010 - Neurophysiological and computational principles of cortical rhythms in cognition.pdf:application/pdf},
}

@article{barabasi_emergence_1999,
	title = {Emergence of {Scaling} in {Random} {Networks}},
	volume = {286},
	issn = {00368075},
	doi = {10.1126/science.286.5439.509},
	number = {October},
	author = {Barabasi, A L and Albert, R},
	year = {1999},
	pmid = {10521342},
	pages = {509--512},
	file = {Attachment:/Users/tito/Zotero/storage/I6WL3DYQ/Kinder et al. - 1999 - Et Al .pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/ILJZEV8L/Kinder et al. - 1999 - Et Al .pdf:application/pdf},
}

@article{cowan_wilson-cowan_2016,
	title = {Wilson-{Cowan} {Equations} for {Neocortical} {Dynamics}.},
	volume = {6},
	issn = {2190-8567},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26728012%5Cnhttp://dx.doi.org/10.1186/s13408-015-0034-5},
	doi = {10.1186/s13408-015-0034-5},
	abstract = {In 1972-1973 Wilson and Cowan introduced a mathematical model of the population dynamics of synaptically coupled excitatory and inhibitory neurons in the neocortex. The model dealt only with the mean numbers of activated and quiescent excitatory and inhibitory neurons, and said nothing about fluctuations and correlations of such activity. However, in 1997 Ohira and Cowan, and then in 2007-2009 Buice and Cowan introduced Markov models of such activity that included fluctuation and correlation effects. Here we show how both models can be used to provide a quantitative account of the population dynamics of neocortical activity.We first describe how the Markov models account for many recent measurements of the resting or spontaneous activity of the neocortex. In particular we show that the power spectrum of large-scale neocortical activity has a Brownian motion baseline, and that the statistical structure of the random bursts of spiking activity found near the resting state indicates that such a state can be represented as a percolation process on a random graph, called directed percolation.Other data indicate that resting cortex exhibits pair correlations between neighboring populations of cells, the amplitudes of which decay slowly with distance, whereas stimulated cortex exhibits pair correlations which decay rapidly with distance. Here we show how the Markov model can account for the behavior of the pair correlations.Finally we show how the 1972-1973 Wilson-Cowan equations can account for recent data which indicates that there are at least two distinct modes of cortical responses to stimuli. In mode 1 a low intensity stimulus triggers a wave that propagates at a velocity of about 0.3 m/s, with an amplitude that decays exponentially. In mode 2 a high intensity stimulus triggers a larger response that remains local and does not propagate to neighboring regions.},
	number = {1},
	journal = {Journal of mathematical neuroscience},
	author = {Cowan, Jack D and Neuman, Jeremy and van Drongelen, Wim},
	year = {2016},
	pmid = {26728012},
	pages = {1},
	file = {Attachment:/Users/tito/Zotero/storage/3EB4U7E2/Cowan, Neuman, van Drongelen - 2016 - Wilson-Cowan Equations for Neocortical Dynamics.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/A3QD9VAA/Cowan, Neuman, van Drongelen - 2016 - Wilson-Cowan Equations for Neocortical Dynamics.pdf:application/pdf},
}

@article{wang_parcellating_2015,
	title = {Parcellating cortical functional networks in individuals.},
	volume = {18},
	issn = {1546-1726},
	url = {http://www.nature.com/doifinder/10.1038/nn.4164%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26551545%5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4661084},
	doi = {10.1038/nn.4164},
	abstract = {The capacity to identify the unique functional architecture of an individual's brain is a crucial step toward personalized medicine and understanding the neural basis of variation in human cognition and behavior. Here we developed a cortical parcellation approach to accurately map functional organization at the individual level using resting-state functional magnetic resonance imaging (fMRI). A population-based functional atlas and a map of inter-individual variability were employed to guide the iterative search for functional networks in individual subjects. Functional networks mapped by this approach were highly reproducible within subjects and effectively captured the variability across subjects, including individual differences in brain lateralization. The algorithm performed well across different subject populations and data types, including task fMRI data. The approach was then validated by invasive cortical stimulation mapping in surgical patients, suggesting potential for use in clinical applications.},
	number = {12},
	journal = {Nature neuroscience},
	author = {Wang, Danhong and Buckner, Randy L and Fox, Michael D and Holt, Daphne J and Holmes, Avram J and Stoecklein, Sophia and Langs, Georg and Pan, Ruiqi and Qian, Tianyi and Li, Kuncheng and Baker, Justin T and Stufflebeam, Steven M and Wang, Kai and Wang, Xiaomin and Hong, Bo and Liu, Hesheng},
	year = {2015},
	pmid = {26551545},
	pages = {1853--60},
	file = {Attachment:/Users/tito/Zotero/storage/E9MW48SX/Wang et al. - 2015 - Parcellating cortical functional networks in individuals.pdf:application/pdf},
}

@article{fusi_why_2016,
	title = {Why neurons mix: high dimensionality for higher cognition},
	volume = {37},
	issn = {09594388},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438816000118},
	doi = {10.1016/j.conb.2016.01.010},
	journal = {Current Opinion in Neurobiology},
	author = {Fusi, Stefano and Miller, Earl K and Rigotti, Mattia},
	year = {2016},
	pmid = {26851755},
	pages = {66--74},
	file = {Attachment:/Users/tito/Zotero/storage/G38XCHUG/Fusi, Miller, Rigotti - 2016 - Why neurons mix high dimensionality for higher cognition.pdf:application/pdf},
}

@article{vargas_gateway_2014,
	title = {The gateway coefficient: {A} novel metric for identifying critical connections in modular networks},
	volume = {87},
	issn = {14346036},
	doi = {10.1140/epjb/e2014-40800-7},
	abstract = {The modular structure of a complex network is an important and well-studied topological property. Within this modular framework, particular nodes which play key roles have been previously identified based on the node's degree, and on the node's participation coefficient, a measure of the diversity of a node's intermodular connections. In this contribution, we develop a generalization of the participation coefficient, called the gateway coefficient, which measures not only the diversity of the intermodular connections, but also how critical these connections are to intermodular connectivity; in brief, nodes which form rare or unique “gateways” between sparsely connected modules rank highly in this measure. We illustrate the use of the gateway coefficient with simulated networks with defined modular structure, as well as networks obtained from air transportation data and functional neuroimaging.},
	number = {7},
	journal = {European Physical Journal B},
	author = {Vargas, Estefania Ruiz and Wahl, Lindi M.},
	year = {2014},
	file = {Attachment:/Users/tito/Zotero/storage/Y3TET2XS/Vargas, Wahl - 2014 - The gateway coefficient A novel metric for identifying critical connections in modular networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/632Z6LSP/Vargas, Wahl - 2014 - The gateway coefficient A novel metric for identifying critical connections in modular networks.pdf:application/pdf},
}

@article{silva_need_2011,
	title = {The {Need} for the {Emergence} of {Mathematical} {Neuroscience}: {Beyond} {Computation} and {Simulation}},
	volume = {5},
	issn = {1662-5188},
	doi = {10.3389/fncom.2011.00051},
	number = {November},
	journal = {Frontiers in Computational Neuroscience},
	author = {Silva, Gabriel a.},
	year = {2011},
	pmid = {22131972},
	pages = {1--3},
	file = {Attachment:/Users/tito/Zotero/storage/E27M8QDH/Silva - 2011 - The Need for the Emergence of Mathematical Neuroscience Beyond Computation and Simulation.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/N4YBXEFR/Silva - 2011 - The Need for the Emergence of Mathematical Neuroscience Beyond Computation and Simulation.pdf:application/pdf},
}

@article{di_modulatory_2013,
	title = {Modulatory {Interactions} of {Resting}-{State} {Brain} {Functional} {Connectivity}},
	volume = {8},
	issn = {19326203},
	doi = {10.1371/journal.pone.0071163},
	abstract = {The functional brain connectivity studies are generally based on the synchronization of the resting-state functional magnetic resonance imaging (fMRI) signals. Functional connectivity measures usually assume a stable relationship over time; however, accumulating studies have reported time-varying properties of strength and spatial distribution of functional connectivity. The present study explored the modulation of functional connectivity between two regions by a third region using the physiophysiological interaction (PPI) technique. We first identified eight brain networks and two regions of interest (ROIs) representing each of the networks using a spatial independent component analysis. A voxel-wise analysis was conducted to identify regions that showed modulatory interactions (PPI) with the two ROIs of each network. Mostly, positive modulatory interactions were observed within regions involved in the same system. For example, the two regions of the dorsal attention network revealed modulatory interactions with the regions related to attention, while the two regions of the extrastriate network revealed modulatory interactions with the regions in the visual cortex. In contrast, the two regions of the default mode network (DMN) revealed negative modulatory interactions with the regions in the executive network, and vice versa, suggesting that the activities of one network may be associated with smaller within network connectivity of the competing network. These results validate the use of PPI analysis to study modulation of resting-state functional connectivity by a third region. The modulatory effects may provide a better understanding of complex brain functions.},
	number = {8},
	journal = {PLoS ONE},
	author = {Di, Xin and Biswal, Bharat B.},
	year = {2013},
	pmid = {24023609},
	file = {Attachment:/Users/tito/Zotero/storage/DWT8A32H/Di, Biswal - 2013 - Modulatory Interactions of Resting-State Brain Functional Connectivity.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/GCSHM8TA/Di, Biswal - 2013 - Modulatory Interactions of Resting-State Brain Functional Connectivity.pdf:application/pdf},
}

@article{ferenczi_prefrontal_2016,
	title = {Prefrontal cortical regulation of brainwide circuit dynamics and reward-related behavior},
	volume = {351},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aac9698},
	doi = {10.1126/science.aac9698},
	abstract = {Motivation for reward drives adaptive behaviors,whereas impairment of reward perception and experience (anhedonia) can contribute to psychiatric diseases, including depression and schizophrenia.Wesought to test thehypothesis that themedial prefrontal cortex(mPFC)controls interactions among specific subcortical regions that govern hedonic responses. By using optogenetic functionalmagnetic resonance imaging to locallymanipulate but globally visualize neural activity in rats,we found that dopamine neuron stimulation drives striatal activity, whereas locally increased mPFC excitability reduces this striatal response and inhibits the behavioral drive for dopaminergic stimulation. This chronicmPFC overactivity also stably suppresses natural reward-motivated behaviors and induces specific new brainwide functional interactions, which predict the degree of anhedonia in individuals.These findings describe amechanism by which mPFC modulates expression of reward-seeking behavior, by regulating the dynamical interactions between specific distant subcortical regions. T},
	number = {6268},
	journal = {Science},
	author = {Ferenczi, E. a. and Zalocusky, K. a. and Liston, C. and Grosenick, L. and Warden, M. R. and Amatya, D. and Katovich, K. and Mehta, H. and Patenaude, B. and Ramakrishnan, C. and Kalanithi, P. and Etkin, a. and Knutson, B. and Glover, G. H. and Deisseroth, K.},
	year = {2016},
	pmid = {26722001},
	pages = {aac9698--aac9698},
	file = {Attachment:/Users/tito/Zotero/storage/JPYTLJG6/Ferenczi et al. - 2016 - Prefrontal cortical regulation of brainwide circuit dynamics and reward-related behavior.pdf:application/pdf},
}

@article{afraz_optogenetic_2015,
	title = {Optogenetic and pharmacological suppression of spatial clusters of face neurons reveal their causal role in face gender discrimination.},
	volume = {112},
	issn = {1091-6490},
	url = {http://www.pnas.org/content/112/21/6730.short},
	doi = {10.1073/pnas.1423328112},
	abstract = {Neurons that respond more to images of faces over nonface objects were identified in the inferior temporal (IT) cortex of primates three decades ago. Although it is hypothesized that perceptual discrimination between faces depends on the neural activity of IT subregions enriched with "face neurons," such a causal link has not been directly established. Here, using optogenetic and pharmacological methods, we reversibly suppressed the neural activity in small subregions of IT cortex of macaque monkeys performing a facial gender-discrimination task. Each type of intervention independently demonstrated that suppression of IT subregions enriched in face neurons induced a contralateral deficit in face gender-discrimination behavior. The same neural suppression of other IT subregions produced no detectable change in behavior. These results establish a causal link between the neural activity in IT face neuron subregions and face gender-discrimination behavior. Also, the demonstration that brief neural suppression of specific spatial subregions of IT induces behavioral effects opens the door for applying the technical advantages of optogenetics to a systematic attack on the causal relationship between IT cortex and high-level visual perception.},
	number = {21},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Afraz, Arash and Boyden, Edward S and DiCarlo, James J},
	year = {2015},
	pmid = {25953336},
	keywords = {Female, Male, Animals, Visual Perception, Visual Perception: physiology, Macaca mulatta, Temporal Lobe, Temporal Lobe: physiology, Electrophysiological Phenomena, Face, Face: anatomy \& histology, GABA-A Receptor Agonists, GABA-A Receptor Agonists: administration \& dosage, Macaca mulatta: anatomy \& histology, Macaca mulatta: physiology, Muscimol, Muscimol: administration \& dosage, Optogenetics, Sex Characteristics, Temporal Lobe: cytology, Temporal Lobe: drug effects, Visual Perception: drug effects},
	pages = {6730--5},
	file = {Attachment:/Users/tito/Zotero/storage/RVUV2TJF/Afraz, Boyden, DiCarlo - 2015 - Optogenetic and pharmacological suppression of spatial clusters of face neurons reveal their causal role.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/ZFQS6R68/Afraz, Boyden, DiCarlo - 2015 - Optogenetic and pharmacological suppression of spatial clusters of face neurons reveal their causal role.pdf:application/pdf},
}

@article{nilsson_physics_2001,
	title = {The physics of},
	number = {November},
	journal = {Physics},
	author = {Nilsson, Ch and Nilsson, Ch},
	year = {2001},
	keywords = {November 2008, p 33-38, Physics Today},
	pages = {33--38},
	file = {Attachment:/Users/tito/Zotero/storage/L6SR74L4/Nilsson, Nilsson - 2001 - The physics of.pdf:application/pdf},
}

@article{betzel_dynamic_2016,
	title = {Dynamic fluctuations coincide with periods of high and low modularity in resting-state functional brain networks},
	volume = {127},
	issn = {10959572},
	doi = {10.1016/j.neuroimage.2015.12.001},
	abstract = {We investigate the relationship of resting-state fMRI functional connectivity estimated over long periods of time with time-varying functional connectivity estimated over shorter time intervals. We show that using Pearson's correlation to estimate functional connectivity implies that the range of fluctuations of functional connections over short time-scales is subject to statistical constraints imposed by their connectivity strength over longer scales. We present a method for estimating time-varying functional connectivity that is designed to mitigate this issue and allows us to identify episodes where functional connections are unexpectedly strong or weak. We apply this method to data recorded from N= 80 participants, and show that the number of unexpectedly strong/weak connections fluctuates over time, and that these variations coincide with intermittent periods of high and low modularity in time-varying functional connectivity. We also find that during periods of relative quiescence regions associated with default mode network tend to join communities with attentional, control, and primary sensory systems. In contrast, during periods where many connections are unexpectedly strong/weak, default mode regions dissociate and form distinct modules. Finally, we go on to show that, while all functional connections can at times manifest stronger (more positively correlated) or weaker (more negatively correlated) than expected, a small number of connections, mostly within the visual and somatomotor networks, do so a disproportional number of times. Our statistical approach allows the detection of functional connections that fluctuate more or less than expected based on their long-time averages and may be of use in future studies characterizing the spatio-temporal patterns of time-varying functional connectivity.},
	journal = {NeuroImage},
	author = {Betzel, Richard F. and Fukushima, Makoto and He, Ye and Zuo, Xi Nian and Sporns, Olaf},
	year = {2016},
	keywords = {Networks, Dynamic functional connectivity, Modularity},
	pages = {287--297},
	file = {Attachment:/Users/tito/Zotero/storage/I6NSZ2MR/Betzel et al. - 2016 - Dynamic fluctuations coincide with periods of high and low modularity in resting-state functional brain networks.pdf:application/pdf},
}

@article{bertolero_modular_2015,
	title = {The modular and integrative functional architecture of the human brain},
	issn = {0027-8424},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1510619112},
	doi = {10.1073/pnas.1510619112},
	abstract = {Network-based analyses of brain imaging data consistently reveal distinct modules and connector nodes with diverse global connectivity across the modules. How discrete the functions of modules are, how dependent the computational load of each module is to the other modules' processing, and what the precise role of connector nodes is for between-module communication remains underspecified. Here, we use a network model of the brain derived from resting-state functional MRI (rs-fMRI) data and investigate the modular functional architecture of the human brain by analyzing activity at different types of nodes in the network across 9,208 experiments of 77 cognitive tasks in the BrainMap database. Using an author– topic model of cognitive functions, we find a strong spatial correspondence between the cognitive functions and the network's modules, suggesting that each module performs a discrete cognitive function. Crucially, activity at local nodes within the modules does not increase in tasks that require more cognitive functions, demonstrating the autonomy of modules' functions. However, connector nodes do exhibit increased activity when more cognitive functions are engaged in a task. Moreover, connector nodes are located where brain activity is associated with many different cognitive functions. Connector nodes potentially play a role in betweenmodule communication that maintains the modular function of the brain. Together, these findings provide a network account of the brain's modular yet integrated implementation of cognitive functions.},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bertolero, Maxwell a. and Yeo, B. T. Thomas and D'Esposito, Mark},
	year = {2015},
	pmid = {26598686},
	pages = {201510619},
}

@article{yeo_functional_2015,
	title = {Functional specialization and flexibility in human association cortex},
	volume = {25},
	issn = {14602199},
	doi = {10.1093/cercor/bhu217},
	abstract = {The association cortex supports cognitive functions enabling flexible behavior. Here, we explored the organization of human association cortex by mathematically formalizing the notion that a behavioral task engages multiple cognitive components, which are in turn supported by multiple overlapping brain regions. Application of the model to a large data set of neuroimaging experiments (N = 10 449) identified complex zones of frontal and parietal regions that ranged from being highly specialized to highly flexible. The network organization of the specialized and flexible regions was explored with an independent resting-state fMRI data set (N = 1000). Cortical regions specialized for the same components were strongly coupled, suggesting that components function as partially isolated networks. Functionally flexible regions participated in multiple components to different degrees. This heterogeneous selectivity was predicted by the connectivity between flexible and specialized regions. Functionally flexible regions might support binding or integrating specialized brain networks that, in turn, contribute to the ability to execute multiple and varied tasks.},
	number = {10},
	journal = {Cerebral Cortex},
	author = {Yeo, B. T. Thomas and Krienen, Fenna M. and Eickhoff, Simon B. and Yaakub, Siti N. and Fox, Peter T. and Buckner, Randy L. and Asplund, Christopher L. and Chee, Michael W L},
	year = {2015},
	pmid = {25249407},
	keywords = {Functional connectivity, Meta-analysis, Prefrontal cortex, Cognitive ontology, Parietal cortex},
	pages = {3654--3672},
	file = {Attachment:/Users/tito/Zotero/storage/A5NJWCWS/Yeo et al. - 2015 - Functional specialization and flexibility in human association cortex.pdf:application/pdf},
}

@article{ashwin_mathematical_2016,
	title = {Mathematical {Frameworks} for {Oscillatory} {Network} {Dynamics} in {Neuroscience}},
	volume = {6},
	issn = {2190-8567},
	url = {http://www.mathematical-neuroscience.com/content/6/1/2},
	doi = {10.1186/s13408-015-0033-6},
	abstract = {The tools of weakly coupled phase oscillator theory have had a profound impact on the neuroscience community, providing insight into a variety of network behaviours ranging from central pattern generation to synchronisation, as well as predicting novel network states such as chimeras. However, there are many instances where this theory is expected to break down, say in the presence of strong coupling, or must be carefully interpreted, as in the presence of stochastic forcing. There are also surprises in the dynamical complexity of the attractors that can robustly appear-for example, heteroclinic network attractors. In this review we present a set of mathematical tools that are suitable for addressing the dynamics of oscillatory neural networks, broadening from a standard phase oscillator perspective to provide a practical framework for further successful applications of mathematics to understanding network dynamics in neuroscience.},
	number = {1},
	journal = {The Journal of Mathematical Neuroscience},
	author = {Ashwin, Peter and Coombes, Stephen and Nicks, Rachel},
	year = {2016},
	pmid = {26739133},
	keywords = {amplitude coordinates, central pattern generator, chimera state, coupled oscillator network, groupoid formalism, heteroclinic cycle, isochrons, master stability function, network motif, perceptual rivalry, phase, phase oscillator, stochastic oscillator, strongly coupled integrate-and-fire network, symmetric},
	pages = {2},
	file = {Attachment:/Users/tito/Zotero/storage/MQMRC46A/Ashwin, Coombes, Nicks - 2016 - Mathematical Frameworks for Oscillatory Network Dynamics in Neuroscience.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/R4LD9QV6/Ashwin, Coombes, Nicks - 2015 - Mathematical frameworks for oscillatory network dynamics in neuroscience.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/GIMQS8CF/Ashwin, Coombes, Nicks - 2016 - Mathematical Frameworks for Oscillatory Network Dynamics in Neuroscience.pdf:application/pdf},
}

@article{li_brain_2009,
	title = {Brain anatomical network and intelligence},
	volume = {5},
	issn = {1553734X},
	doi = {10.1371/journal.pcbi.1000395},
	abstract = {Intuitively, higher intelligence might be assumed to correspond to more efficient information transfer in the brain, but no direct evidence has been reported from the perspective of brain networks. In this study, we performed extensive analyses to test the hypothesis that individual differences in intelligence are associated with brain structural organization, and in particular that higher scores on intelligence tests are related to greater global efficiency of the brain anatomical network. We constructed binary and weighted brain anatomical networks in each of 79 healthy young adults utilizing diffusion tensor tractography and calculated topological properties of the networks using a graph theoretical method. Based on their IQ test scores, all subjects were divided into general and high intelligence groups and significantly higher global efficiencies were found in the networks of the latter group. Moreover, we showed significant correlations between IQ scores and network properties across all subjects while controlling for age and gender. Specifically, higher intelligence scores corresponded to a shorter characteristic path length and a higher global efficiency of the networks, indicating a more efficient parallel information transfer in the brain. The results were consistently observed not only in the binary but also in the weighted networks, which together provide convergent evidence for our hypothesis. Our findings suggest that the efficiency of brain structural organization may be an important biological basis for intelligence.},
	number = {5},
	journal = {PLoS Computational Biology},
	author = {Li, Yonghui and Liu, Yong and Li, Jun and Qin, Wen and Li, Kuncheng and Yu, Chunshui and Jiang, Tianzi},
	year = {2009},
	pmid = {19492086},
	file = {Attachment:/Users/tito/Zotero/storage/8LMN424P/Li et al. - 2009 - Brain anatomical network and intelligence.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/VJFQKVFQ/Li et al. - 2009 - Brain anatomical network and intelligence.pdf:application/pdf},
}

@article{paukert_norepinephrine_2014,
	title = {Norepinephrine {Controls} {Astroglial} {Responsiveness} to {Local} {Circuit} {Activity}},
	volume = {82},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627314003535},
	doi = {10.1016/j.neuron.2014.04.038},
	number = {6},
	journal = {Neuron},
	author = {Paukert, Martin and Agarwal, Amit and Cha, Jaepyeong and Doze, Van A. and Kang, Jin U. and Bergles, Dwight E.},
	year = {2014},
	pages = {1263--1270},
	file = {Attachment:/Users/tito/Zotero/storage/ZUHQY5GG/Paukert et al. - 2014 - Norepinephrine Controls Astroglial Responsiveness to Local Circuit Activity.pdf:application/pdf},
}

@article{aston-jones_integrative_2005,
	title = {{AN} {INTEGRATIVE} {THEORY} {OF} {LOCUS} {COERULEUS}-{NOREPINEPHRINE} {FUNCTION}: {Adaptive} {Gain} and {Optimal} {Performance}},
	volume = {28},
	issn = {0147-006X},
	url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.neuro.28.061604.135709},
	doi = {10.1146/annurev.neuro.28.061604.135709},
	number = {1},
	journal = {Annual Review of Neuroscience},
	author = {Aston-Jones, Gary and Cohen, Jonathan D.},
	year = {2005},
	keywords = {decision making, orbitofrontal cortex, anterior cingulate cortex, neuromodulation, optimization, utility},
	pages = {403--450},
	file = {Attachment:/Users/tito/Zotero/storage/MXCINZWM/Aston-Jones, Cohen - 2005 - AN INTEGRATIVE THEORY OF LOCUS COERULEUS-NOREPINEPHRINE FUNCTION Adaptive Gain and Optimal Performance.pdf:application/pdf},
}

@article{cole_frontoparietal_2014,
	title = {The {Frontoparietal} {Control} {System}: {A} {Central} {Role} in {Mental} {Health}},
	volume = {20},
	issn = {1073-8584},
	url = {http://nro.sagepub.com/cgi/doi/10.1177/1073858414525995},
	doi = {10.1177/1073858414525995},
	number = {6},
	journal = {The Neuroscientist},
	author = {Cole, M. W. and Repov, G. and Anticevic, A.},
	year = {2014},
	keywords = {brain networks, cognitive control, executive functions, prefrontal cortex, a fundamental mystery of, better outcomes despite similar, clinical neuroscience is why, psychiatric disease, some patients have much},
	pages = {652--664},
	file = {Attachment:/Users/tito/Zotero/storage/C9FBQX9X/Cole, Repov , Anticevic - 2014 - The Frontoparietal Control System A Central Role in Mental Health.pdf:application/pdf},
}

@article{wikenheiser_hippocampal_2015,
	title = {Hippocampal theta sequences reflect current goals},
	volume = {18},
	issn = {1097-6256},
	url = {http://dx.doi.org/10.1038/nn.3909%5Cnpapers3://publication/doi/10.1038/nn.3909},
	doi = {10.1038/nn.3909},
	abstract = {Nature Neuroscience, (2014). doi:10.1038/nn.3909},
	number = {2},
	journal = {Nature Neuroscience},
	author = {Wikenheiser, Andrew M and Redish, A David},
	year = {2015},
	pmid = {25559082},
	pages = {1--8},
	file = {Attachment:/Users/tito/Zotero/storage/SAKZKZ7S/Wikenheiser, Redish - 2015 - Hippocampal theta sequences reflect current goals.pdf:application/pdf},
}

@article{steiner_behavioral_2014,
	title = {Behavioral and neurophysiological correlates of regret in rat decision-making on a neuroeconomic task},
	volume = {17},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3740},
	doi = {10.1038/nn.3740},
	number = {7},
	journal = {Nature Neuroscience},
	author = {Steiner, Adam P and Redish, A David},
	year = {2014},
	pages = {995--1002},
	file = {Attachment:/Users/tito/Zotero/storage/USXHW2AG/Steiner, Redish - 2014 - Behavioral and neurophysiological correlates of regret in rat decision-making on a neuroeconomic task.pdf:application/pdf},
}

@article{brandwein_development_2011,
	title = {The development of audiovisual multisensory integration across childhood and early adolescence: {A} high-density electrical mapping study.},
	volume = {21},
	issn = {10473211},
	doi = {10.1093/cercor/bhq170},
	abstract = {The integration of multisensory information is essential to forming meaningful representations of the environment. Adults benefit from related multisensory stimuli but the extent to which the ability to optimally integrate multisensory inputs for functional purposes is present in children has not been extensively examined. Using a cross-sectional approach, high-density electrical mapping of event-related potentials (ERPs) was combined with behavioral measures to characterize neurodevelopmental changes in basic audiovisual (AV) integration from middle childhood through early adulthood. The data indicated a gradual fine-tuning of multisensory facilitation of performance on an AV simple reaction time task (as indexed by race model violation), which reaches mature levels by about 14 years of age. They also revealed a systematic relationship between age and the brain processes underlying multisensory integration (MSI) in the time frame of the auditory N1 ERP component (∼120 ms). A significant positive correlation between behavioral and neurophysiological measures of MSI suggested that the underlying brain processes contributed to the fine-tuning of multisensory facilitation of behavior that was observed over middle childhood. These findings are consistent with protracted plasticity in a dynamic system and provide a starting point from which future studies can begin to examine the developmental course of multisensory processing in clinical populations.},
	number = {May},
	journal = {Cerebral Cortex},
	author = {Brandwein, Alice B. and Foxe, John J. and Russo, Natalie N. and Altschuler, Ted S. and Gomes, Hilary and Molholm, Sophie},
	year = {2011},
	pmid = {20847153},
	keywords = {Development, Electrophysiology, Children, Cross-modal, ERP, Multisensory integration},
	pages = {1042--1055},
	file = {Attachment:/Users/tito/Zotero/storage/MTP8VWBH/Brandwein et al. - 2011 - The development of audiovisual multisensory integration across childhood and early adolescence A high-density.pdf:application/pdf},
}

@article{eichenbaum_towards_2008,
	title = {Towards a functional organization of the medial temporal lobe memory system: {Role} of the parahippocampal and medial entorhinal cortical areas},
	volume = {18},
	issn = {10509631},
	url = {http://doi.wiley.com/10.1002/hipo.20500},
	doi = {10.1002/hipo.20500},
	number = {12},
	journal = {Hippocampus},
	author = {Eichenbaum, Howard and Lipton, Paul A.},
	year = {2008},
	keywords = {hippocampus, the, areas will be highlighted, episodic memory, spatial navigation, t-maze, temporal context, we then briefly review},
	pages = {1314--1324},
	file = {Attachment:/Users/tito/Zotero/storage/9DY2ZVBV/Eichenbaum, Lipton - 2008 - Towards a functional organization of the medial temporal lobe memory system Role of the parahippocampal and.pdf:application/pdf},
}

@article{yang_electrophysiological_1996,
	title = {Electrophysiological and morphological properties of layers {V}-{VI} principal pyramidal cells in rat prefrontal cortex in vitro.},
	volume = {16},
	issn = {0270-6474},
	abstract = {This study examined the electrophysiological and morphological characteristics of layers V-VI pyramidal prefrontal cortex (PFC) neurons. In vitro intracellular recordings coupled with biocytin injections that preserved some of the PFC efferents to the nucleus accumbens (NAc) were made in brain slices. Four principal pyramidal cell types were identified and classified as regular spiking (RS) (19\%), intrinsic bursting (IB) (64\%), repetitive oscillatory bursting (ROB) (13\%), and intermediate (IM) (4\%) types. All PFC cells exhibited either subthreshold oscillation in membrane voltage or pacemaker-like rhythmic firing. IB neurons were demonstrated electrophysiologically and cytochemically to be PFC–{\textbackslash}textgreaterNAc neurons. In all IB and some RS neurons, a tetrodotoxin-sensitive, slowly inactivating Na+ current and a transient Ni(2+)-sensitive, low-threshold Ca2+ current mediated subthreshold inward rectification. During sustained membrane depolarization, the Na+ current was opposed by a 4-aminopyridine-sensitive, outwardly rectifying, slowly inactivating K+ current. Together, these three currents controlled the firing threshold of the PFC neurons. All IB and ROB cells also had postspike Ca(2+)-mediated depolarizing afterpotentials, postburst Ca(2+)-dependent after hyperpolarizations, and low- and high-threshold Ca2+ spikes. In addition, ROB cells had a hyperpolarizing "sag" mediated by the cationic conductance, Ih. IB and ROB neurons had extensive dendritic trees and radially ascending or tangentially projecting axon collaterals. RS and IM cells had comparatively simpler morphological profiles. These electrophysiological and morphological properties of the four principal pyramidal PFC cell types have provided valuable details for understanding further how PFC processes input and transmit outputs to regions such as the NAc.},
	number = {5},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Yang, C R and Seamans, J K and Gorelova, N},
	year = {1996},
	pmid = {8774458},
	keywords = {prefrontal cortex, electrophysiology},
	pages = {1904--1921},
	file = {Attachment:/Users/tito/Zotero/storage/ACL24RNS/Yang, Seamans, Gorelova - 1996 - Electrophysiological and morphological properties of layers V-VI principal pyramidal cells in rat prefr.pdf:application/pdf},
}

@article{yuan_spatiotemporal_2012,
	title = {Spatiotemporal dynamics of the brain at rest - {Exploring} {EEG} microstates as electrophysiological signatures of {BOLD} resting state networks},
	volume = {60},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2012.02.031},
	doi = {10.1016/j.neuroimage.2012.02.031},
	abstract = {Neuroimaging research suggests that the resting cerebral physiology is characterized by complex patterns of neuronal activity in widely distributed functional networks. As studied using functional magnetic resonance imaging (fMRI) of the blood-oxygenation-level dependent (BOLD) signal, the resting brain activity is associated with slowly fluctuating hemodynamic signals (∼. 10. s). More recently, multimodal functional imaging studies involving simultaneous acquisition of BOLD-fMRI and electroencephalography (EEG) data have suggested that the relatively slow hemodynamic fluctuations of some resting state networks (RSNs) evinced in the BOLD data are related to much faster (∼. 100. ms) transient brain states reflected in EEG signals, that are referred to as "microstates". To further elucidate the relationship between microstates and RSNs, we developed a fully data-driven approach that combines information from simultaneously recorded, high-density EEG and BOLD-fMRI data. Using independent component analysis (ICA) of the combined EEG and fMRI data, we identified thirteen microstates and ten RSNs that are organized independently in their temporal and spatial characteristics, respectively. We hypothesized that the intrinsic brain networks that are active at rest would be reflected in both the EEG data and the fMRI data. To test this hypothesis, the rapid fluctuations associated with each microstate were correlated with the BOLD-fMRI signal associated with each RSN.We found that each RSN was characterized further by a specific electrophysiological signature involving from one to a combination of several microstates. Moreover, by comparing the time course of EEG microstates to that of the whole-brain BOLD signal, on a multi-subject group level, we unraveled for the first time a set of microstate-associated networks that correspond to a range of previously described RSNs, including visual, sensorimotor, auditory, attention, frontal, visceromotor and default mode networks. These results extend our understanding of the electrophysiological signature of BOLD RSNs and demonstrate the intrinsic connection between the fast neuronal activity and slow hemodynamic fluctuations. ?? 2012 Elsevier Inc..},
	number = {4},
	journal = {NeuroImage},
	author = {Yuan, Han and Zotev, Vadim and Phillips, Raquel and Drevets, Wayne C. and Bodurka, Jerzy},
	year = {2012},
	pmid = {22381593},
	keywords = {EEG, BOLD fMRI, ICA, Microstates, Resting state networks},
	pages = {2062--2072},
	file = {Attachment:/Users/tito/Zotero/storage/9NWKQ787/Yuan et al. - 2012 - Spatiotemporal dynamics of the brain at rest - Exploring EEG microstates as electrophysiological signatures of BOLD.pdf:application/pdf},
}

@article{martanez-sanchis_neurobiological_2014,
	title = {Neurobiological foundations of multisensory integration in people with autism spectrum disorders: the role of the medial prefrontal cortex},
	volume = {8},
	issn = {1662-5161},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00970/abstract},
	doi = {10.3389/fnhum.2014.00970},
	number = {December},
	journal = {Frontiers in Human Neuroscience},
	author = {MartÃ­nez-Sanchis, Sonia},
	year = {2014},
	keywords = {network, asd, autism spectrum disorders, autism spectrum disorders (ASD), default, medial prefrontal cortex, mpfc, multisensory inte, multisensory integration, temporal multisensory binding},
	pages = {1--6},
}

@article{opris_closing_2012,
	title = {Closing the loop in primate prefrontal cortex: inter-laminar processing},
	volume = {6},
	issn = {1662-5110},
	url = {http://journal.frontiersin.org/article/10.3389/fncir.2012.00088/abstract},
	doi = {10.3389/fncir.2012.00088},
	number = {November},
	journal = {Frontiers in Neural Circuits},
	author = {Opris, Ioan and Fuqua, Joshua L. and Huettl, Peter F. and Gerhardt, Greg A. and Berger, Theodore W. and Hampson, Robert E. and Deadwyler, Sam A.},
	year = {2012},
	keywords = {selection, prefrontal cortex, columnar correlates of target, columnar correlates of task, difficulty, inter-laminar correlated firing, nonhuman primates, object tuning, spatial vs},
	pages = {1--13},
	file = {Attachment:/Users/tito/Zotero/storage/HEEMRYK6/Opris et al. - 2012 - Closing the loop in primate prefrontal cortex inter-laminar processing.pdf:application/pdf},
}

@article{pinto_fast_2013,
	title = {Fast modulation of visual perception by basal forebrain cholinergic neurons},
	volume = {16},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3552},
	doi = {10.1038/nn.3552},
	number = {12},
	journal = {Nature Neuroscience},
	author = {Pinto, Lucas and Goard, Michael J and Estandian, Daniel and Xu, Min and Kwan, Alex C and Lee, Seung-Hee and Harrison, Thomas C and Feng, Guoping and Dan, Yang},
	year = {2013},
	pages = {1857--1863},
	file = {Attachment:/Users/tito/Zotero/storage/CX69C7EP/Pinto et al. - 2013 - Fast modulation of visual perception by basal forebrain cholinergic neurons.pdf:application/pdf},
}

@book{corkin_lasting_1984,
	title = {Lasting {Consequences} of {Bilateral} {Medial} {Temporal} {Lobectomy}: {Clinical} {Course} and {Experimental} {Findings} in {H}.{M}.},
	volume = {4},
	isbn = {0271-8235},
	abstract = {Interspecific pollen transfer (IPT) is one of the mechanisms underlying potential competition among plants for pollinators, and it refers to movement of pollen between different plant species by pollinators that visit their flowers simultaneously. Two components of IPT, related to each other, are distinguished: (a) heterospecific pollen deposition (HPD) on conspecific stigmas, which may interfere with fertilization by conspecific pollen; and (b) conspecific pollen loss (CPL) on heterospecific flowers, which may reduce the amount of pollen transferred between conspecific flowers. Thus, IPT may lead to reciprocal losses for male and female functions of the plant, with potentially important ecological and evolutionary consequences. In this review, we explore the magnitude and prevalence of IPT, examining documented mechanisms and evaluating such potential ecological and evolutionary consequences. We compiled existing evidence of interspecific pollinator sharing and interspecific pollinator switching between flowers of different species in natural communities. We evaluated the relative importance of both HPD and CPL from studies comparing these variables in pure vs. mixed floral neighborhoods, analyzing evidence for the claim that IPT is an evolutionary force promoting character displacement in habitat affinity, flowering times, and floral morphology. We also examined the findings of hand-pollination experiments carried out to reveal different mechanisms by which heterospecific pollen can affect performance of native pollen. Finally, we review evidence for impacts of alien plant species on native species' reproduction, and briefly comment on risks of crop-to-wild gene flow imposed by the release of genetically modified (transgenic) crops through IPT.},
	number = {02},
	author = {Corkin, Suzanne},
	year = {1984},
	doi = {10.1055/s-2008-1041556},
	pmid = {809},
	file = {Attachment:/Users/tito/Zotero/storage/Q5DV5UTF/Corkin - 1984 - Lasting Consequences of Bilateral Medial Temporal Lobectomy Clinical Course and Experimental Findings in H.M.pdf:application/pdf},
}

@article{brandwein_development_2013,
	title = {The {Development} of {Multisensory} {Integration} in {High}-{Functioning} {Autism}: {High}-{Density} {Electrical} {Mapping} and {Psychophysical} {Measures} {Reveal} {Impairments} in the {Processing} of {Audiovisual} {Inputs}},
	volume = {23},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/cgi/doi/10.1093/cercor/bhs109},
	doi = {10.1093/cercor/bhs109},
	number = {6},
	journal = {Cerebral Cortex},
	author = {Brandwein, A. B. and Foxe, J. J. and Butler, J. S. and Russo, N. N. and Altschuler, T. S. and Gomes, H. and Molholm, S.},
	year = {2013},
	keywords = {electrophysiology, multimodal, auditory, erps, visual},
	pages = {1329--1341},
	file = {Attachment:/Users/tito/Zotero/storage/L88PVXNX/Brandwein et al. - 2013 - The Development of Multisensory Integration in High-Functioning Autism High-Density Electrical Mapping and Psy.pdf:application/pdf},
}

@article{eliasmith_large-scale_2012,
	title = {A {Large}-{Scale} {Model} of the {Functioning} {Brain}},
	volume = {338},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1225266},
	doi = {10.1126/science.1225266},
	number = {NOVEMBER},
	journal = {Science},
	author = {Eliasmith, Chris and Stewart, Terrence C. and Choo, Xuan and Bekolay, Trevor and Dewolf, Travis and Tang, Yichuan and Rasmussen, Daniel},
	year = {2012},
	pages = {1202--1205},
	file = {Attachment:/Users/tito/Zotero/storage/FZB52P3B/Eliasmith et al. - 2012 - A Large-Scale Model of the Functioning Brain.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/LSBV7JXE/Eliasmith et al. - 2012 - Functioning Brain.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/LPINFSAW/Eliasmith et al. - 2012 - A Large-Scale Model of the Functioning Brain.pdf:application/pdf},
}

@article{berridge_parsing_2003,
	title = {Parsing reward},
	volume = {26},
	issn = {01662236},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0166223603002339},
	doi = {10.1016/S0166-2236(03)00233-9},
	number = {9},
	journal = {Trends in Neurosciences},
	author = {Berridge, Kent C. and Robinson, Terry E.},
	year = {2003},
	pages = {507--513},
	file = {Attachment:/Users/tito/Zotero/storage/9KI725AA/Berridge, Robinson - 2003 - Parsing reward.pdf:application/pdf},
}

@book{abernathy_alcohol_2010,
	title = {Alcohol and the prefrontal cortex.},
	volume = {91},
	isbn = {978-0-12-381276-6},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3593065&tool=pmcentrez&rendertype=abstract},
	abstract = {The prefrontal cortex occupies the anterior portion of the frontal lobes and is thought to be one of the most complex anatomical and functional structures of the mammalian brain. Its major role is to integrate and interpret inputs from cortical and sub-cortical structures and use this information to develop purposeful responses that reflect both present and future circumstances. This includes both action-oriented sequences involved in obtaining rewards and inhibition of behaviors that pose undue risk or harm to the individual. Given the central role in initiating and regulating these often complex cognitive and behavioral responses, it is no surprise that alcohol has profound effects on the function of the prefrontal cortex. In this chapter, we review the basic anatomy and physiology of the prefrontal cortex and discuss what is known about the actions of alcohol on the function of this brain region. This includes a review of both the human and animal literature including information on the electrophysiological and behavioral effects that follow acute and chronic exposure to alcohol. The chapter concludes with a discussion of unanswered questions and areas needing further investigation.},
	number = {10},
	author = {Abernathy, Kenneth and Chandler, L Judson and Woodward, John J},
	year = {2010},
	doi = {10.1016/S0074-7742(10)91009-X},
	pmid = {20813246},
	keywords = {Humans, Prefrontal Cortex, Executive Function, Animals, Neurons, Neurons: physiology, Memory, Prefrontal Cortex: physiology, Neurons: classification, Neurons: drug effects, Short-Term, Alcohols, Alcohols: pharmacology, Executive Function: drug effects, Neurotransmitter Agents, Neurotransmitter Agents: metabolism, Prefrontal Cortex: anatomy \& histology, Prefrontal Cortex: drug effects, Short-Term: drug effects},
	file = {Attachment:/Users/tito/Zotero/storage/7EZNTVBF/Abernathy, Chandler, Woodward - 2010 - Alcohol and the prefrontal cortex.pdf:application/pdf},
}

@article{kang_boosting_2014,
	title = {Boosting visual cortex function and plasticity with acetylcholine to enhance visual perception},
	volume = {8},
	issn = {1662-5137},
	url = {http://journal.frontiersin.org/article/10.3389/fnsys.2014.00172/abstract},
	doi = {10.3389/fnsys.2014.00172},
	number = {September},
	journal = {Frontiers in Systems Neuroscience},
	author = {Kang, Jun Il and HuppÃ©-Gourgues, FrÃ©dÃ©ric and Vaucher, Elvire},
	year = {2014},
	keywords = {attention, cortical plasticity, perceptual learning, visual cortex, cholinergic system, cognitive enhanceme, cognitive enhancement, muscarinic, nicotinic receptors, receptors},
	pages = {1--14},
}

@article{wang_heterogeneity_2006,
	title = {Heterogeneity in the pyramidal network of the medial prefrontal cortex},
	volume = {9},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn1670},
	doi = {10.1038/nn1670},
	number = {4},
	journal = {Nature Neuroscience},
	author = {Wang, Yun and Markram, Henry and Goodman, Philip H and Berger, Thomas K and Ma, Junying and Goldman-Rakic, Patricia S},
	year = {2006},
	pages = {534--542},
	file = {Attachment:/Users/tito/Zotero/storage/AIWEST74/Wang et al. - 2006 - Heterogeneity in the pyramidal network of the medial prefrontal cortex.pdf:application/pdf},
}

@article{javitt_when_2009,
	title = {When {Doors} of {Perception} {Close}: {Bottom}-up {Models} of {Disrupted} {Cognition} in {Schizophrenia}},
	volume = {5},
	issn = {1548-5943},
	url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.clinpsy.032408.153502},
	doi = {10.1146/annurev.clinpsy.032408.153502},
	number = {1},
	journal = {Annual Review of Clinical Psychology},
	author = {Javitt, Daniel C.},
	year = {2009},
	keywords = {glutamate, auditory, visual, event-related potentials, nmda receptors},
	pages = {249--275},
	file = {Attachment:/Users/tito/Zotero/storage/ZMXRFRVU/Javitt - 2009 - When Doors of Perception Close Bottom-up Models of Disrupted Cognition in Schizophrenia.pdf:application/pdf},
}

@article{elston_cortex_2003,
	title = {Cortex, {Cognition} and the {Cell}: {New} {Insights} into the {Pyramidal} {Neuron} and {Prefrontal} {Function}},
	volume = {13},
	issn = {1460-2199},
	url = {http://www.cercor.oupjournals.org/cgi/doi/10.1093/cercor/bhg093},
	doi = {10.1093/cercor/bhg093},
	number = {11},
	journal = {Cerebral Cortex},
	author = {Elston, G. N.},
	year = {2003},
	pages = {1124--1138},
	file = {Attachment:/Users/tito/Zotero/storage/VPKKH9HF/Elston - 2003 - Cortex, Cognition and the Cell New Insights into the Pyramidal Neuron and Prefrontal Function.pdf:application/pdf},
}

@article{mumford_bayesian_2014,
	title = {Bayesian networks for {fMRI}: {A} primer},
	volume = {86},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2013.10.020},
	doi = {10.1016/j.neuroimage.2013.10.020},
	abstract = {Bayesian network analysis is an attractive approach for studying the functional integration of brain networks, as it includes both the locations of connections between regions of the brain (functional connectivity) and more importantly the direction of the causal relationship between the regions (directed functional connectivity). Further, these approaches are more attractive than other functional connectivity analyses in that they can often operate on larger sets of nodes and run searches over a wide range of candidate networks. An important study by Smith et al. (2011) illustrated that many Bayesian network approaches did not perform well in identifying the directionality of connections in simulated single-subject data. Since then, new Bayesian network approaches have been developed that have overcome the failures in the Smith work. Additionally, an important discovery was made that shows a preprocessing step used in the Smith data puts some of the Bayesian network methods at a disadvantage. This work provides a review of Bayesian network analyses, focusing on the methods used in the Smith work as well as methods developed since 2011 that have improved estimation performance. Importantly, only approaches that have been specifically designed for fMRI data perform well, as they have been tailored to meet the challenges of fMRI data. Although this work does not suggest a single best model, it describes the class of models that perform best and highlights the features of these models that allow them to perform well on fMRI data. Specifically, methods that rely on non-Gaussianity to direct causal relationships in the network perform well. ?? 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Mumford, Jeanette a. and Ramsey, Joseph D.},
	year = {2014},
	pmid = {24140939},
	keywords = {Causality, Connectivity, Resting state, Functional magnetic resonance imaging, Bayesian networks, Network analysis, Single subject},
	pages = {573--582},
	file = {Attachment:/Users/tito/Zotero/storage/LLAH5J2A/Mumford, Ramsey - 2014 - Bayesian networks for fMRI A primer.pdf:application/pdf},
}

@article{garces_multimodal_2015,
	title = {Multimodal description of whole brain connectivity: {\textbackslash}textlessi{\textbackslash}{textgreaterA} comparison of resting state {MEG}, {fMRI}, and {DWI}{\textbackslash}textless/i{\textbackslash}textgreater},
	volume = {00},
	issn = {10659471},
	url = {http://doi.wiley.com/10.1002/hbm.22995},
	doi = {10.1002/hbm.22995},
	journal = {Human Brain Mapping},
	author = {Garcés, Pilar and Pereda, Ernesto and Hernández-Tamames, Juan A. and Del-Pozo, Francisco and Maestú, Fernando and Ángel Pineda-Pardo, José},
	year = {2015},
	pmid = {26503502},
	pages = {n/a--n/a},
}

@article{eshel_opening_2013,
	title = {Opening the black box: {Dopamine}, predictions, and learning},
	volume = {17},
	issn = {13646613},
	url = {http://dx.doi.org/10.1016/j.tics.2013.06.010},
	doi = {10.1016/j.tics.2013.06.010},
	abstract = {Dopamine neurons are thought to promote learning by signaling prediction errors, that is, the difference between actual and expected outcomes. Whether these signals are sufficient for associative learning, however, remains untested. A recent study used optogenetics in a classic behavioral paradigm to confirm the role of dopamine prediction errors in learning. © 2013 Elsevier Ltd.},
	number = {9},
	journal = {Trends in Cognitive Sciences},
	author = {Eshel, Neir and Tian, Ju and Uchida, Naoshige},
	year = {2013},
	pmid = {23830895},
	keywords = {Brain, Humans, Animals, Brain: physiology, Brain: cytology, Association Learning, Association Learning: physiology, Optogenetics, Dopaminergic Neurons, Dopaminergic Neurons: physiology},
	pages = {430--431},
	file = {Attachment:/Users/tito/Zotero/storage/L3SGKDTX/Eshel, Tian, Uchida - 2013 - Opening the black box dopamine, predictions, and learning.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/WHIDUDFP/Eshel, Tian, Uchida - 2013 - Opening the black box dopamine, predictions, and learning.pdf:application/pdf},
}

@article{hutchison_dynamic_2013,
	title = {Dynamic functional connectivity: {Promise}, issues, and interpretations},
	volume = {80},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2013.05.079},
	doi = {10.1016/j.neuroimage.2013.05.079},
	abstract = {The brain must dynamically integrate, coordinate, and respond to internal and external stimuli across multiple time scales. Non-invasive measurements of brain activity with fMRI have greatly advanced our understanding of the large-scale functional organization supporting these fundamental features of brain function. Conclusions from previous resting-state fMRI investigations were based upon static descriptions of functional connectivity (FC), and only recently studies have begun to capitalize on the wealth of information contained within the temporal features of spontaneous BOLD FC. Emerging evidence suggests that dynamic FC metrics may index changes in macroscopic neural activity patterns underlying critical aspects of cognition and behavior, though limitations with regard to analysis and interpretation remain. Here, we review recent findings, methodological considerations, neural and behavioral correlates, and future directions in the emerging field of dynamic FC investigations. © 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Hutchison, R. Matthew and Womelsdorf, Thilo and Allen, Elena a. and Bandettini, Peter a. and Calhoun, Vince D. and Corbetta, Maurizio and Della Penna, Stefania and Duyn, Jeff H. and Glover, Gary H. and Gonzalez-Castillo, Javier and Handwerker, Daniel a. and Keilholz, Shella and Kiviniemi, Vesa and Leopold, David a. and de Pasquale, Francesco and Sporns, Olaf and Walter, Martin and Chang, Catie},
	year = {2013},
	pmid = {23707587},
	keywords = {Functional connectivity, Resting state, Spontaneous activity, Fluctuations, Dynamics, Functional MRI (fMRI)},
	pages = {360--378},
	file = {Attachment:/Users/tito/Zotero/storage/JNNM3D6D/Hutchison et al. - 2013 - Dynamic functional connectivity Promise, issues, and interpretations.pdf:application/pdf},
}

@article{petersen_brain_2015,
	title = {Brain {Networks} and {Cognitive} {Architectures}},
	volume = {88},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008168},
	doi = {10.1016/j.neuron.2015.09.027},
	number = {1},
	journal = {Neuron},
	author = {Petersen, Steven E. and Sporns, Olaf},
	year = {2015},
	pages = {207--219},
	file = {Attachment:/Users/tito/Zotero/storage/XDEAXAXK/Petersen, Sporns - 2015 - Brain Networks and Cognitive Architectures.pdf:application/pdf},
}

@article{herrero_acetylcholine_2008,
	title = {Acetylcholine contributes through muscarinic receptors to attentional modulation in {V1}.},
	volume = {454},
	issn = {1476-4687},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2666819&tool=pmcentrez&rendertype=abstract},
	doi = {10.1038/nature07141},
	abstract = {Attention exerts a strong influence over neuronal processing in cortical areas. It selectively increases firing rates and affects tuning properties, including changing receptive field locations and sizes. Although these effects are well studied, their cellular mechanisms are poorly understood. To study the cellular mechanisms, we combined iontophoretic pharmacological analysis of cholinergic receptors with single cell recordings in V1 while rhesus macaque monkeys (Macaca mulatta) performed a task that demanded top-down spatial attention. Attending to the receptive field of the V1 neuron under study caused an increase in firing rates. Here we show that this attentional modulation was enhanced by low doses of acetylcholine. Furthermore, applying the muscarinic antagonist scopolamine reduced attentional modulation, whereas the nicotinic antagonist mecamylamine had no systematic effect. These results demonstrate that muscarinic cholinergic mechanisms play a central part in mediating the effects of attention in V1.},
	number = {7208},
	journal = {Nature},
	author = {Herrero, J L and Roberts, M J and Delicato, L S and Gieselmann, M A and Dayan, P and Thiele, A},
	year = {2008},
	pmid = {18633352},
	keywords = {Attention, Magnetic Resonance Imaging, Male, Animals, Macaca mulatta, Attention: drug effects, Cholinergic, Cholinergic: metabolism, Receptors, Macaca mulatta: physiology, Acetylcholine, Acetylcholine: metabolism, Acetylcholine: pharmacology, Cholinergic Antagonists, Cholinergic Antagonists: pharmacology, Mecamylamine, Mecamylamine: pharmacology, Muscarinic, Muscarinic Antagonists, Muscarinic Antagonists: pharmacology, Muscarinic: metabolism, Nicotinic Antagonists, Nicotinic Antagonists: pharmacology, Scopolamine Hydrobromide, Scopolamine Hydrobromide: pharmacology},
	pages = {1110--4},
	file = {Attachment:/Users/tito/Zotero/storage/R27HUPUV/Herrero et al. - 2008 - Acetylcholine contributes through muscarinic receptors to attentional modulation in V1.pdf:application/pdf},
}

@article{pinker_why_2004,
	title = {Why nature \& nurture won't go away},
	volume = {133},
	issn = {00115266},
	doi = {10.1016/S0262-4079(06)61106-8},
	abstract = {People's beliefs about the relative importance of heredity and environment affect their opinions on an astonishing range of topics. It is even no surprise that debates over nature and nurture evoke more rancor than just about any issue in the world of ideas. Pinker asserts that discoveries not only have shown that the innate organization of the brain cannot be ignored, but have also helped to reframe the very conception of nature and nurture.},
	number = {4},
	journal = {Daedalus},
	author = {Pinker, Steven},
	year = {2004},
	pmid = {15530376},
	keywords = {Behavior, Biology, Genes, Nature, Psychology, Sciences: Comprehensive Works},
	pages = {5--17},
}

@article{robleto_brain_2004,
	title = {Brain mechanisms of extinction of the classically conditioned eyeblink response.},
	volume = {11},
	issn = {1072-0502},
	doi = {10.1101/lm.80004},
	abstract = {It is well established that the cerebellum and its associated circuitry are essential for classical conditioning of the eyeblink response and other discrete motor responses (e.g., limb flexion, head turn, etc.) learned with an aversive unconditioned stimulus (US). However, brain mechanisms underlying extinction of these responses are still relatively unclear. Behavioral studies have demonstrated extinction as an active learning process distinct from acquisition. Experimental data in eyeblink conditioning suggest that plastic changes specific to extinction may play an important role in this process. Both cerebellar and hippocampal systems may be involved in extinction of these memories. The nature of this phenomenon and identification of the neural substrates necessary for extinction of originally learned responses is the topic of this review.},
	number = {5},
	journal = {Learning \& memory (Cold Spring Harbor, N.Y.)},
	author = {Robleto, Karla and Poulos, Andrew M and Thompson, Richard F},
	year = {2004},
	pmid = {15466302},
	pages = {517--524},
	file = {Attachment:/Users/tito/Zotero/storage/G848JUM2/Robleto, Poulos, Thompson - 2004 - Brain mechanisms of extinction of the classically conditioned eyeblink response.pdf:application/pdf},
}

@article{smith_network_2011,
	title = {Network modelling methods for {FMRI}},
	volume = {54},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2010.08.063},
	doi = {10.1016/j.neuroimage.2010.08.063},
	abstract = {There is great interest in estimating brain "networks" from FMRI data. This is often attempted by identifying a set of functional "nodes" (e.g., spatial ROIs or ICA maps) and then conducting a connectivity analysis between the nodes, based on the FMRI timeseries associated with the nodes. Analysis methods range from very simple measures that consider just two nodes at a time (e.g., correlation between two nodes' timeseries) to sophisticated approaches that consider all nodes simultaneously and estimate one global network model (e.g., Bayes net models). Many different methods are being used in the literature, but almost none has been carefully validated or compared for use on FMRI timeseries data. In this work we generate rich, realistic simulated FMRI data for a wide range of underlying networks, experimental protocols and problematic confounds in the data, in order to compare different connectivity estimation approaches. Our results show that in general correlation-based approaches can be quite successful, methods based on higher-order statistics are less sensitive, and lag-based approaches perform very poorly. More specifically: there are several methods that can give high sensitivity to network connection detection on good quality FMRI data, in particular, partial correlation, regularised inverse covariance estimation and several Bayes net methods; however, accurate estimation of connection directionality is more difficult to achieve, though Patel's τcan be reasonably successful. With respect to the various confounds added to the data, the most striking result was that the use of functionally inaccurate ROIs (when defining the network nodes and extracting their associated timeseries) is extremely damaging to network estimation; hence, results derived from inappropriate ROI definition (such as via structural atlases) should be regarded with great caution. © 2010 Elsevier Inc.},
	number = {2},
	journal = {NeuroImage},
	author = {Smith, Stephen M. and Miller, Karla L. and Salimi-Khorshidi, Gholamreza and Webster, Matthew and Beckmann, Christian F. and Nichols, Thomas E. and Ramsey, Joseph D. and Woolrich, Mark W.},
	year = {2011},
	pmid = {20817103},
	keywords = {Causality, FMRI, Network modelling},
	pages = {875--891},
	file = {Attachment:/Users/tito/Zotero/storage/TMCUFQUX/Smith et al. - 2011 - Network modelling methods for FMRI.pdf:application/pdf},
}

@article{siegel_widespread_1996,
	title = {The widespread influence of the {Rescorla}-{Wagner} model.},
	volume = {3},
	issn = {1069-9384},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/24213932},
	doi = {10.3758/BF03210755},
	abstract = {The theory of Pavlovian conditioning presented by Robert Rescorla and Allan Wagner in 1972 (the Rescorla-Wagner model) has been enormously important in animal learning research. It also has been applied in a variety of areas other than animal learning. We summarize the contribution of the Rescorla-Wagner model to research in verbal learning, social psychology, human category learning, human judgments of correlational relationships, transitive inference, color aftereffects, and physiological regulation. We conclude that there have been few models in experimental psychology as influential as the Rescorla-Wagner model.},
	number = {3},
	journal = {Psychonomic bulletin \& review},
	author = {Siegel, S and Allan, L G},
	year = {1996},
	pmid = {24213932},
	pages = {314--21},
	file = {Attachment:/Users/tito/Zotero/storage/QPLFFMDQ/Siegel, Allan - 1996 - The widespread influence of the Rescorla-Wagner model.pdf:application/pdf},
}

@article{geerligs_state_2015,
	title = {State and {Trait} {Components} of {Functional} {Connectivity}: {Individual} {Differences} {Vary} with {Mental} {State}},
	volume = {35},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1324-15.2015},
	doi = {10.1523/JNEUROSCI.1324-15.2015},
	number = {41},
	journal = {Journal of Neuroscience},
	author = {Geerligs, L. and Rubinov, M. and {Cam-CAN} and Henson, R. N.},
	year = {2015},
	keywords = {resting state, fmri, significance statement, network, brain connectivity, the brain, aging, despite these trait-like aspects, functional connectivity as a, functional connectivity varies, individuals and across different, mental states, remarkably similar across different, s functional architecture is, trait measure, which is, why many studies use},
	pages = {13949--13961},
	file = {Attachment:/Users/tito/Zotero/storage/R6DPCVMM/Geerligs et al. - 2015 - State and Trait Components of Functional Connectivity Individual Differences Vary with Mental State.pdf:application/pdf},
}

@article{motter_networkcontrology_2015,
	title = {Networkcontrology},
	volume = {25},
	issn = {1054-1500},
	url = {http://scitation.aip.org/content/aip/journal/chaos/25/9/10.1063/1.4931570},
	doi = {10.1063/1.4931570},
	number = {9},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Motter, Adilson E.},
	year = {2015},
	pages = {097621},
	file = {Attachment:/Users/tito/Zotero/storage/LS7RU88P/Motter - 2015 - Networkcontrology.pdf:application/pdf},
}

@article{noudoost_control_2011,
	title = {Control of visual cortical signals by prefrontal dopamine},
	volume = {474},
	issn = {0028-0836},
	url = {http://www.nature.com/doifinder/10.1038/nature09995},
	doi = {10.1038/nature09995},
	number = {7351},
	journal = {Nature},
	author = {Noudoost, Behrad and Moore, Tirin},
	year = {2011},
	pages = {372--375},
	file = {Attachment:/Users/tito/Zotero/storage/CJTGEL5B/Noudoost, Moore - 2011 - Control of visual cortical signals by prefrontal dopamine(2).pdf:application/pdf},
}

@article{xu_learning_2014,
	title = {Learning enhances the relative impact of top-down processing in the visual cortex},
	volume = {2015},
	issn = {1546-170X},
	url = {http://www.nature.com/doifinder/10.1038/nn.4061%5Cnhttp://dx.doi.org/10.1038/nm.2146%5Cnhttp://dx.doi.org/10.1016/j.cognition.2014.01.002},
	doi = {10.1038/nn.4061},
	abstract = {People suffering from the hot-hand fallacy unreasonably expect winning streaks to continue whereas those suffering from the gamblers' fallacy unreasonably expect losing streaks to reverse. We took 565,915 sports bets made by 776 online gamblers in 2010 and analyzed all winning and losing streaks up to a maximum length of six. People who won were more likely to win again (apparently because they chose safer odds than before) whereas those who lost were more likely to lose again (apparently because they chose riskier odds than before). However, selection of safer odds after winning and riskier ones after losing indicates that online sports gamblers expected their luck to reverse: they suffered from the gamblers' fallacy. By believing in the gamblers' fallacy, they created their own hot hands. ?? 2014 The Authors.},
	number = {6},
	journal = {Cognition},
	author = {Xu, Juemin and Harvey, Nigel and Saito, Taku and Fukai, Atsushi and Mabuchi, Akihiko and Ikeda, Toshiyuki and Yano, Fumiko and Ohba, Shinsuke and Nishida, Nao and Akune, Toru and Yoshimura, Noriko and Nakagawa, Takumi and Nakamura, Kozo and Tokunaga, Katsushi and Chung, Ung-Il and Kawaguchi, Hiroshi and Makino, Hiroshi and Komiyama, Takaki},
	year = {2014},
	pmid = {24549140},
	keywords = {Gamblers' fallacy, Hot-hand fallacy, Sports betting},
	pages = {173--180},
	file = {Attachment:/Users/tito/Zotero/storage/2797Y7BV/Xu et al. - 2014 - Learning enhances the relative impact of top-down processing in the visual cortex(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/5USNSYY6/Xu et al. - 2014 - Learning enhances the relative impact of top-down processing in the visual cortex.pdf:application/pdf},
}

@article{khorsand_combined_2015,
	title = {Combined contributions of feedforward and feedback inputs to bottom-up attention},
	volume = {6},
	issn = {1664-1078},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4345765&tool=pmcentrez&rendertype=abstract},
	doi = {10.3389/fpsyg.2015.00155},
	abstract = {In order to deal with a large amount of information carried by visual inputs entering the brain at any given point in time, the brain swiftly uses the same inputs to enhance processing in one part of visual field at the expense of the others. These processes, collectively called bottom-up attentional selection, are assumed to solely rely on feedforward processing of the external inputs, as it is implied by the nomenclature. Nevertheless, evidence from recent experimental and modeling studies points to the role of feedback in bottom-up attention. Here, we review behavioral and neural evidence that feedback inputs are important for the formation of signals that could guide attentional selection based on exogenous inputs. Moreover, we review results from a modeling study elucidating mechanisms underlying the emergence of these signals in successive layers of neural populations and how they depend on feedback from higher visual areas. We use these results to interpret and discuss more recent findings that can further unravel feedforward and feedback neural mechanisms underlying bottom-up attention. We argue that while it is descriptively useful to separate feedforward and feedback processes underlying bottom-up attention, these processes cannot be mechanistically separated into two successive stages as they occur at almost the same time and affect neural activity within the same brain areas using similar neural mechanisms. Therefore, understanding the interaction and integration of feedforward and feedback inputs is crucial for better understanding of bottom-up attention.},
	number = {March},
	journal = {Frontiers in Psychology},
	author = {Khorsand, Peyman and Moore, Tirin and Soltani, Alireza},
	year = {2015},
	pmid = {25784883},
	keywords = {computational modeling, nmda, feedback, feedforward, lateral interaction, saliency computation, saliency map, top-down atten, top-down attention},
	pages = {155},
	file = {Attachment:/Users/tito/Zotero/storage/JMHZVAR5/Khorsand, Moore, Soltani - 2015 - Combined contributions of feedforward and feedback inputs to bottom-up attention.pdf:application/pdf},
}

@article{ermentrout_foundations_2008,
	title = {Foundations of {Mathematical} {Neuroscience}},
	doi = {10.1007/978-0-387-87708-2},
	author = {Ermentrout, Bard and Terman, David},
	year = {2008},
	pages = {440},
	file = {Attachment:/Users/tito/Zotero/storage/5ESY79NJ/Ermentrout, Terman - 2008 - Foundations of Mathematical Neuroscience.pdf:application/pdf},
}

@article{kriegeskorte_pattern-information_2011,
	title = {Pattern-information analysis: {From} stimulus decoding to computational-model testing},
	volume = {56},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2011.01.061},
	doi = {10.1016/j.neuroimage.2011.01.061},
	abstract = {Pattern-information analysis has become an important new paradigm in functional imaging. Here I review and compare existing approaches with a focus on the question of what we can learn from them in terms of brain theory. The most popular and widespread method is stimulus decoding by response-pattern classification. This approach addresses the question whether activity patterns in a given region carry information about the stimulus category. Pattern classification uses generic models of the stimulus-response relationship that do not mimic brain information processing and treats the stimulus space as categorical-a simplification that is often helpful, but also limiting in terms of the questions that can be addressed. We can address the question whether representations are consistent across different stimulus sets or tasks by cross-decoding, where the classifier is trained with one set of stimuli (or task) and tested with another. Beyond pattern classification, a major new direction is the integration of computational models of brain information processing into pattern-information analysis. This approach enables us to address the question to what extent competing computational models are consistent with the stimulus representations in a brain region. Two methods that test computational models are voxel receptive-field modeling and representational similarity analysis. These methods sample the stimulus (or mental-state) space more richly, estimate a separate response pattern for each stimulus, and can generalize from the stimulus sample to a stimulus population. Computational models that mimic brain information processing predict responses from stimuli. The reverse transform can be modeled to reconstruct stimuli from responses. Stimulus reconstruction is a challenging feat of engineering, but the implications of the results for brain theory are not always clear. Exploratory pattern analyses complement the confirmatory approaches mentioned so far and can reveal strong, unexpected effects that might be missed when testing only a restricted set of predefined hypotheses. ?? 2011 Elsevier Inc.},
	number = {2},
	journal = {NeuroImage},
	author = {Kriegeskorte, Nikolaus},
	year = {2011},
	pmid = {21281719},
	pages = {411--421},
	file = {Attachment:/Users/tito/Zotero/storage/IIRFTMAX/Kriegeskorte - 2011 - Pattern-information analysis From stimulus decoding to computational-model testing.pdf:application/pdf},
}

@article{mccarthy_sex_2012,
	title = {Sex {Differences} in the {Brain}: {The} {Not} {So} {Inconvenient} {Truth}},
	volume = {32},
	issn = {0270-6474},
	doi = {10.1523/JNEUROSCI.5372-11.2012},
	abstract = {The arguments for studying sex differences in the brain are as follows. (1) There is compelling evidence of pervasive and robust differences between males and females in both normal and pathological conditions. (2) The number of published studies limited to males remains stunningly and stubbornly high (Zucker and Beery, 2010). Scientific conclusions based on the study of one sex could have limited value in understanding some phenomena in the other sex. Thus, females deserve more study. (3) In addition, direct comparison of the two sexes is beneficial because of the unique perspective it offers. Indeed, it is seldom acknowledged that comparison of males and females has provided the critical spark to igniting widespread investigation of fundamental phenomenon. This is true for the field of adult neurogenesis, which arguably began with the study of sex differences in the song bird brain (Nottebohm and Liu, 2010); hormonal modulation of programmed neuronal cell death, which began with the discovery of the androgen-sensitive spinal nucleus of the bulbocavernosus of the spinal cord (Nordeen et al., 1985); neurosteroidogenesis, which started with the Aromatization Hypothesis (Naftolin et al., 1975); prostaglandin-mediated synaptogenesis which induces masculinization of sexual behavior (Amateau and McCarthy, 2004); and many more mechanisms likely waiting to be discovered. Moreover, in brain diseases that are sexually dimorphic, one sex is protected from disease more than the other. Thus, identifying the sex-specific protective agents could lead to better understanding of potential therapies, or identification of new drug targets. Our goal in presenting this Toolbox is to offer guidance and encouragement for those wishing to study sex differences.},
	number = {7},
	journal = {Journal of Neuroscience},
	author = {McCarthy, M. M. and Arnold, a. P. and Ball, G. F. and Blaustein, J. D. and De Vries, G. J.},
	year = {2012},
	pmid = {22396398},
	pages = {2241--2247},
	file = {Attachment:/Users/tito/Zotero/storage/64LY43HC/McCarthy et al. - 2012 - Sex Differences in the Brain The Not So Inconvenient Truth.pdf:application/pdf},
}

@article{kornblith_stimulus_2015,
	title = {Stimulus {Load} and {Oscillatory} {Activity} in {Higher} {Cortex}},
	issn = {1047-3211},
	url = {http://www.cercor.oxfordjournals.org/lookup/doi/10.1093/cercor/bhv182},
	doi = {10.1093/cercor/bhv182},
	journal = {Cerebral Cortex},
	author = {Kornblith, Simon and Buschman, Timothy J. and Miller, Earl K.},
	year = {2015},
	keywords = {prefrontal cortex, working memory, synchrony, frontal eye fi elds, lateral intraparietal area, power},
	pages = {bhv182},
	file = {Attachment:/Users/tito/Zotero/storage/S3UURSL8/Kornblith, Buschman, Miller - 2015 - Stimulus Load and Oscillatory Activity in Higher Cortex.pdf:application/pdf},
}

@article{haynes_primer_2015,
	title = {A {Primer} on {Pattern}-{Based} {Approaches} to {fMRI}: {Principles}, {Pitfalls}, and {Perspectives}},
	volume = {87},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2015.05.025%5Cnpapers3://publication/doi/10.1016/j.neuron.2015.05.025},
	doi = {10.1016/j.neuron.2015.05.025},
	abstract = {Neuron, 87 (2015) 257-270. doi:10.1016/j.neuron.2015.05.025},
	number = {2},
	journal = {Neuron},
	author = {Haynes, John-Dylan},
	year = {2015},
	pmid = {26182413},
	pages = {257--270},
	file = {Attachment:/Users/tito/Zotero/storage/TP8IQBCF/Haynes - 2015 - A Primer on Pattern-Based Approaches to fMRI Principles, Pitfalls, and Perspectives.pdf:application/pdf},
}

@article{vanhorn_functional_2009,
	title = {Functional {MRI} at the crossroads},
	volume = {73},
	issn = {01678760},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167876008008428},
	doi = {10.1016/j.ijpsycho.2008.11.003},
	number = {1},
	journal = {International Journal of Psychophysiology},
	author = {VANHORN, J},
	year = {2009},
	keywords = {functional neuroimaging},
	pages = {3--9},
	file = {Attachment:/Users/tito/Zotero/storage/RWN87E7E/VANHORN - 2009 - Functional MRI at the crossroads.pdf:application/pdf},
}

@article{gregoriou_lesions_2014,
	title = {Lesions of prefrontal cortex reduce attentional modulation of neuronal responses and synchrony in {V4}},
	volume = {17},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3742},
	doi = {10.1038/nn.3742},
	number = {7},
	journal = {Nature Neuroscience},
	author = {Gregoriou, Georgia G and Rossi, Andrew F and Ungerleider, Leslie G and Desimone, Robert},
	year = {2014},
	pages = {1003--1011},
	file = {Attachment:/Users/tito/Zotero/storage/VIYNCGEW/Gregoriou et al. - 2014 - Lesions of prefrontal cortex reduce attentional modulation of neuronal responses and synchrony in V4(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/E639D8RD/Gregoriou et al. - 2014 - Lesions of prefrontal cortex reduce attentional modulation of neuronal responses and synchrony in V4.pdf:application/pdf},
}

@article{fiorella_relative_2013,
	title = {The relative benefits of learning by teaching and teaching expectancy},
	volume = {38},
	issn = {0361476X},
	url = {http://dx.doi.org/10.1016/j.cedpsych.2013.06.001},
	doi = {10.1016/j.cedpsych.2013.06.001},
	abstract = {The purpose of this study was to explore the hypothesis that learning is enhanced through the act of teaching others. Specifically, two experiments aimed to disentangle the relative effects of teaching expectancy (i.e., preparing to teach) and actually teaching (i.e., explaining to others for instructional purposes) on learning. Some participants studied a lesson on the Doppler Effect without the expectation of later teaching the material and then took a comprehension test on the material (control group). Other students studied the same lesson with instructions that they would later teach the material; of those expecting to teach, some participants actually taught the material by presenting a brief video-recorded lecture before being tested (teaching group), whereas others only prepared to teach before being tested (preparation group). Results of Experiment 1 indicated that both the preparation group and teaching group significantly outperformed the control group on an immediate comprehension test (Teaching vs. Control: d= 0.82; Preparation vs. Control: d= 0.59). However, when the same test was given following a one-week delay (Experiment 2), only the teaching group significantly outperformed the control group (Teaching vs. Control: d= 0.79; Preparation vs. Control: d= 0.24). Overall, these findings suggest that when students actually teach the content of a lesson, they develop a deeper and more persistent understanding of the material than from solely preparing to teach. ?? 2013 Elsevier Inc.},
	number = {4},
	journal = {Contemporary Educational Psychology},
	author = {Fiorella, Logan and Mayer, Richard E.},
	year = {2013},
	keywords = {Explanation, Generative learning, Learning by teaching, Multimedia learning, Teaching expectancy},
	pages = {281--288},
	file = {Attachment:/Users/tito/Zotero/storage/F2BZL2P2/Fiorella, Mayer - 2013 - The relative benefits of learning by teaching and teaching expectancy.pdf:application/pdf},
}

@article{hochstein_view_2002,
	title = {View from the top: {Hierarchies} and reverse hierarchies in the visual system.},
	volume = {36},
	issn = {08966273},
	doi = {10.1016/S0896-6273(02)01091-7},
	abstract = {We propose that explicit vision advances in reverse hierarchical direction, as shown for perceptual learning. Processing along the feedforward hierarchy of areas, leading to increasingly complex representations, is automatic and implicit, while conscious perception begins at the hierarchy's top, gradually returning downward as needed. Thus, our initial conscious percept - vision at a glance - matches a high-level, generalized, categorical scene interpretation, identifying "forest before trees." For later vision with scrutiny, reverse hierarchy routines focus attention to specific, active, low-level units, incorporating into conscious perception detailed information available there. Reverse Hierarchy Theory dissociates between early explicit perception and implicit low-level vision, explaining a variety of phenomena. Feature search "pop-out" is attributed to high areas, where large receptive fields underlie spread attention detecting categorical differences. Search for conjunctions or fine discriminations depends on reentry to low-level specific receptive fields using serial focused attention, consistent with recently reported primary visual cortex effects.},
	number = {5},
	journal = {Neuron},
	author = {Hochstein, Shaul and Ahissar, Merav},
	year = {2002},
	pmid = {12467584},
	pages = {791--804},
	file = {Attachment:/Users/tito/Zotero/storage/2UP9IQED/Hochstein, Ahissar - 2002 - View from the top Hierarchies and reverse hierarchies in the visual system.pdf:application/pdf},
}

@article{barnett_granger_2009,
	title = {Granger causality and transfer entropy are equivalent for {Gaussian} variables},
	url = {http://arxiv.org/abs/0910.4514 http://dx.doi.org/10.1103/PhysRevLett.103.238701},
	doi = {10.1103/PhysRevLett.103.238701},
	abstract = {Granger causality is a statistical notion of causal influence based on prediction via vector autoregression. Developed originally in the field of econometrics, it has since found application in a broader arena, particularly in neuroscience. More recently transfer entropy, an information-theoretic measure of time-directed information transfer between jointly dependent processes, has gained traction in a similarly wide field. While it has been recognized that the two concepts must be related, the exact relationship has until now not been formally described. Here we show that for Gaussian variables, Granger causality and transfer entropy are entirely equivalent, thus bridging autoregressive and information-theoretic approaches to data-driven causal inference.},
	author = {Barnett, Lionel and Barrett, Adam B and Seth, Anil K.},
	year = {2009},
	keywords = {granger causality, causal inference, transfer entropy},
	pages = {1--10},
	file = {Attachment:/Users/tito/Zotero/storage/AXZEL5UY/Barnett, Barrett, Seth - 2009 - Granger causality and transfer entropy are equivalent for Gaussian variables.pdf:application/pdf},
}

@article{genovesio_context-dependent_2015,
	title = {Context-{Dependent} {Duration} {Signals} in the {Primate} {Prefrontal} {Cortex}},
	issn = {1047-3211},
	doi = {10.1093/cercor/bhv156},
	abstract = {The activity of some prefrontal (PF) cortex neurons distinguishes short from long time intervals. Here, we examined whether this property reflected a general timing mechanism or one dependent on behavioral context. In one task, monkeys discriminated the relative duration of 2 stimuli; in the other, they discriminated the relative distance of 2 stimuli from a fixed reference point. Both tasks had a pre-cue period (interval 1) and a delay period (interval 2) with no discriminant stimulus. Interval 1 elapsed before the presentation of the first discriminant stimulus, and interval 2 began after that stimulus. Both intervals had durations of either 400 or 800 ms. Most PF neurons distinguished short from long durations in one task or interval, but not in the others. When neurons did signal something about duration for both intervals, they did so in an uncorrelated or weakly correlated manner. These results demonstrate a high degree of context dependency in PF time processing. The PF, therefore, does not appear to signal durations abstractedly, as would be expected of a general temporal encoder, but instead does so in a highly context-dependent manner, both within and between tasks.},
	author = {Genovesio, Aldo and Seitz, Lucia K and Tsujimoto, Satoshi and Wise, Steven P},
	year = {2015},
	keywords = {dorsolateral prefrontal cortex, duration, executive function, monitoring, periprincipal prefrontal cortex, temporal processing, timing},
	pages = {1--12},
	file = {Attachment:/Users/tito/Zotero/storage/5XCGMDZW/Genovesio et al. - 2015 - Context-Dependent Duration Signals in the Primate Prefrontal Cortex.pdf:application/pdf},
}

@article{diamond_executive_2013,
	title = {Executive functions},
	volume = {64},
	issn = {1347-5215},
	doi = {10.1146/annurev-psych-113011-143750},
	abstract = {Executive Functions Adele Diamond Department of Psychiatry, University of British Columbia and BC Children's Hospital, Vancouver, BC V6T 2A1 Canada; email: adele.diamond@ubc.ca Keywords cognitive control, self-regulation, creativity, attention, reasoning, working memory, fluid intelligence, inhibitory control, task switching, mental flexibility Abstract Executive functions (EFs) make possible mentally playing with ideas; taking the time to think before acting; meeting novel, unanticipated challenges; resisting temptations; and staying focused. Core EFs are inhibition [response inhibition (self-control—resisting temptations and resisting acting impulsively) and interference control (selective attention and cognitive inhibition)], working memory, and cognitive flexibility (including creatively thinking “outside the box,” seeing anything from different perspectives, and quickly and flexibly adapting to changed circumstances). The developmental progression and repre- sentative measures of each are discussed. Controversies are addressed (e.g., the relation between EFs and fluid intelligence, self-regulation, executive attention, and effortful control, and the relation between working memory and inhibition and attention). The importance of social, emotional, and physical health for cognitive health is discussed because stress, lack of sleep, loneliness, or lack of exercise each impair EFs. That EFs are trainable and can be improved with practice is addressed, including diverse methods tried thus far.},
	journal = {Anual Reviews},
	author = {Diamond, Adele},
	year = {2013},
	pmid = {21881226},
	keywords = {cognitive control, fluid intelligence, attention, working memory, task switching, creativity, inhibitory control, mental flexibilit, reasoning, self-regulation},
	pages = {135--168},
	file = {Attachment:/Users/tito/Zotero/storage/BMRULRRH/Diamond - 2013 - Executive functions.pdf:application/pdf},
}

@article{gilbert_top-down_2013,
	title = {Top-down influences on visual processing.},
	volume = {14},
	issn = {1471-0048},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3864796&tool=pmcentrez&rendertype=abstract},
	doi = {10.1038/nrn3476},
	abstract = {Re-entrant or feedback pathways between cortical areas carry rich and varied information about behavioural context, including attention, expectation, perceptual tasks, working memory and motor commands. Neurons receiving such inputs effectively function as adaptive processors that are able to assume different functional states according to the task being executed. Recent data suggest that the selection of particular inputs, representing different components of an association field, enable neurons to take on different functional roles. In this Review, we discuss the various top-down influences exerted on the visual cortical pathways and highlight the dynamic nature of the receptive field, which allows neurons to carry information that is relevant to the current perceptual demands.},
	number = {5},
	journal = {Nature reviews. Neuroscience},
	author = {Gilbert, C. D. and Li, W.},
	year = {2013},
	pmid = {23595013},
	keywords = {Attention, Humans, Visual Cortex, Animals, Visual Perception, Visual Perception: physiology, Ocular, Ocular: physiology, Nonlinear Dynamics, Vision, Visual Cortex: cytology, Visual Cortex: physiology, Visual Pathways, Visual Pathways: physiology},
	pages = {350--63},
	file = {Attachment:/Users/tito/Zotero/storage/9Z5MMMTU/Gilbert, Li - 2013 - Top-down influences on visual processing.pdf:application/pdf},
}

@article{craddock_imaging_2013,
	title = {Imaging human connectomes at the macroscale},
	volume = {10},
	issn = {1548-7091},
	url = {http://www.nature.com/doifinder/10.1038/nmeth.2482},
	doi = {10.1038/nmeth.2482},
	number = {6},
	journal = {Nature Methods},
	author = {Craddock, R Cameron and Jbabdi, Saad and Yan, Chao-Gan and Vogelstein, Joshua T and Castellanos, F Xavier and Di Martino, Adriana and Kelly, Clare and Heberlein, Keith and Colcombe, Stan and Milham, Michael P},
	year = {2013},
	pages = {524--539},
	file = {Attachment:/Users/tito/Zotero/storage/FJAK55CT/Craddock et al. - 2013 - Imaging human connectomes at the macroscale.pdf:application/pdf},
}

@article{constantinople_effects_2011,
	title = {Effects and {Mechanisms} of {Wakefulness} on {Local} {Cortical} {Networks}},
	volume = {69},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627311001620},
	doi = {10.1016/j.neuron.2011.02.040},
	number = {6},
	journal = {Neuron},
	author = {Constantinople, Christine M. and Bruno, Randy M.},
	year = {2011},
	pages = {1061--1068},
	file = {Attachment:/Users/tito/Zotero/storage/QGNECHKZ/Constantinople, Bruno - 2011 - Effects and Mechanisms of Wakefulness on Local Cortical Networks.pdf:application/pdf},
}

@article{griffis_retinotopic_2015,
	title = {Retinotopic patterns of background connectivity between {V1} and fronto-parietal cortex are modulated by task demands.},
	volume = {9},
	issn = {1662-5161},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2015.00338/abstract},
	doi = {10.3389/fnhum.2015.00338},
	abstract = {Attention facilitates the processing of task-relevant visual information and suppresses interference from task-irrelevant information. Modulations of neural activity in visual cortex depend on attention, and likely result from signals originating in fronto-parietal and cingulo-opercular regions of cortex. Here, we tested the hypothesis that attentional facilitation of visual processing is accomplished in part by changes in how brain networks involved in attentional control interact with sectors of V1 that represent different retinal eccentricities. We measured the strength of background connectivity between fronto-parietal and cingulo-opercular regions with different eccentricity sectors in V1 using functional MRI data that were collected while participants performed tasks involving attention to either a centrally presented visual stimulus or a simultaneously presented auditory stimulus. We found that when the visual stimulus was attended, background connectivity between V1 and the left frontal eye fields (FEF), left intraparietal sulcus (IPS), and right IPS varied strongly across different eccentricity sectors in V1 so that foveal sectors were more strongly connected than peripheral sectors. This retinotopic gradient was weaker when the visual stimulus was ignored, indicating that it was driven by attentional effects. Greater task-driven differences between foveal and peripheral sectors in background connectivity to these regions were associated with better performance on the visual task and faster response times on correct trials. These findings are consistent with the notion that attention drives the configuration of task-specific functional pathways that enable the prioritized processing of task-relevant visual information, and show that the prioritization of visual information by attentional processes may be encoded in the retinotopic gradient of connectivty between V1 and fronto-parietal regions.},
	number = {June},
	journal = {Frontiers in human neuroscience},
	author = {Griffis, Joseph C and Elkhetali, Abdurahman S and Burge, Wesley K and Chen, Richard H and Visscher, Kristina M},
	year = {2015},
	pmid = {26106320},
	keywords = {background connectivity, Cognitive Control Mechanisms, fronto-parietal network, functional MRI, primary visual cortex, retinotopic specificity, task-dependent connectivity, visual attention},
	pages = {338},
	file = {Attachment:/Users/tito/Zotero/storage/99E2UL2P/Griffis et al. - 2015 - Retinotopic patterns of background connectivity between V1 and fronto-parietal cortex are modulated by task dema.pdf:application/pdf},
}

@article{buschman_synchronous_2012,
	title = {Synchronous {Oscillatory} {Neural} {Ensembles} for {Rules} in the {Prefrontal} {Cortex}},
	volume = {76},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2012.09.029},
	doi = {10.1016/j.neuron.2012.09.029},
	abstract = {Intelligent behavior requires acquiring and following rules. Rules define how our behavior should fit different situations. To understand its neural mechanisms, we simultaneously recorded from multiple electrodes in dorsolateral prefrontal cortex (PFC) while monkeys switched between two rules (respond to color versus orientation). We found evidence that oscillatory synchronization of local field potentials (LFPs) formed neural ensembles representing the rules: there were rule-specific increases in synchrony at " beta" (19-40 Hz) frequencies between electrodes. In addition, individual PFC neurons synchronized to the LFP ensemble corresponding to the current rule (color versus orientation). Furthermore, the ensemble encoding the behaviorally dominant orientation rule showed increased " alpha" (6-16 Hz) synchrony when preparing to apply the alternative (weaker) color rule. This suggests that beta-frequency synchrony selects the relevant rule ensemble, while alpha-frequency synchrony deselects a stronger, but currently irrelevant, ensemble. Synchrony may act to dynamically shape task-relevant neural ensembles out of larger, overlapping circuits.},
	number = {4},
	journal = {Neuron},
	author = {Buschman, Timothy J. and Denovellis, Eric L. and Diogo, Cinira and Bullock, Daniel and Miller, Earl K.},
	year = {2012},
	pmid = {23177967},
	pages = {838--846},
	file = {Attachment:/Users/tito/Zotero/storage/AUS6SRI8/Buschman et al. - 2012 - Synchronous Oscillatory Neural Ensembles for Rules in the Prefrontal Cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/CWVHWXJY/Buschman et al. - 2012 - Synchronous Oscillatory Neural Ensembles for Rules in the Prefrontal Cortex(2).pdf:application/pdf},
}

@article{cole_multi-task_2013,
	title = {Multi-task connectivity reveals flexible hubs for adaptive task control},
	volume = {16},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3470},
	doi = {10.1038/nn.3470},
	number = {9},
	journal = {Nature Neuroscience},
	author = {Cole, Michael W and Reynolds, Jeremy R and Power, Jonathan D and Repovs, Grega and Anticevic, Alan and Braver, Todd S},
	year = {2013},
	pages = {1348--1355},
	file = {Attachment:/Users/tito/Zotero/storage/J8HR66WZ/Cole et al. - 2013 - Multi-task connectivity reveals flexible hubs for adaptive task control(3).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/LCZSXBIV/Cole et al. - 2013 - Multi-task connectivity reveals flexible hubs for adaptive task control.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/BL79VT4R/Cole et al. - 2013 - Multi-task connectivity reveals flexible hubs for adaptive task control(3).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/V3HRD57B/Cole et al. - 2013 - Multi-task connectivity reveals flexible hubs for adaptive task control(3).pdf:application/pdf},
}

@article{cole_lateral_2015,
	title = {Lateral {Prefrontal} {Cortex} {Contributes} to {Fluid} {Intelligence} {Through} {Multinetwork} {Connectivity}},
	volume = {5},
	issn = {2158-0014},
	url = {http://online.liebertpub.com/doi/10.1089/brain.2015.0357},
	doi = {10.1089/brain.2015.0357},
	number = {8},
	journal = {Brain Connectivity},
	author = {Cole, Michael W. and Ito, Takuya and Braver, Todd S.},
	year = {2015},
	keywords = {functional connectivity, individual differences, fmri, intelligence, prefrontal cortex, resting-state functional connectivity, graph theory},
	pages = {497--504},
	file = {Attachment:/Users/tito/Zotero/storage/TQ9Z6YZF/Cole, Ito, Braver - 2015 - Lateral Prefrontal Cortex Contributes to Fluid Intelligence Through Multinetwork Connectivity.pdf:application/pdf},
}

@article{manuscript_control_2014,
	title = {Control},
	volume = {16},
	doi = {10.1038/nn.3470.Multi-task},
	number = {9},
	author = {Manuscript, Author},
	year = {2014},
	pages = {1348--1355},
	file = {Attachment:/Users/tito/Zotero/storage/R7CJT887/Manuscript - 2014 - Control.pdf:application/pdf},
}

@article{buschman_top-down_2007,
	title = {Top-{Down} {Versus} {Bottom}-{Up} {Control} of {Attention} in the {Prefrontal} and {Posterior} {Parietal} {Cortices}},
	volume = {315},
	issn = {0036-8075},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1138071},
	doi = {10.1126/science.1138071},
	number = {5820},
	journal = {Science},
	author = {Buschman, T. J. and Miller, E. K.},
	year = {2007},
	pages = {1860--1862},
	file = {Attachment:/Users/tito/Zotero/storage/4YT5IV8A/Buschman, Miller - 2007 - Top-Down Versus Bottom-Up Control of Attention in the Prefrontal and Posterior Parietal Cortices.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/3FCULMDC/Buschman, Miller - 2007 - of Attention in the Prefrontal and.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/ZC6E2R6K/Buschman, Miller - 2007 - Top-Down Versus Bottom-Up Control of Attention in the Prefrontal and Posterior Parietal Cortices.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/D4A39R6X/Buschman, Miller - 2007 - of Attention in the Prefrontal and(2).pdf:application/pdf},
}

@article{berenbaum_sexual_2011,
	title = {Sexual differentiation of human behavior: {Effects} of prenatal and pubertal organizational hormones},
	volume = {32},
	issn = {00913022},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S009130221100029X},
	doi = {10.1016/j.yfrne.2011.03.001},
	number = {2},
	journal = {Frontiers in Neuroendocrinology},
	author = {Berenbaum, Sheri A. and Beltz, Adriene M.},
	year = {2011},
	keywords = {sexual differentiation},
	pages = {183--200},
	file = {Attachment:/Users/tito/Zotero/storage/JX24JJQK/Berenbaum, Beltz - 2011 - Sexual differentiation of human behavior Effects of prenatal and pubertal organizational hormones.pdf:application/pdf},
}

@article{van_kerkoerle_alpha_2014,
	title = {Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex},
	volume = {111},
	issn = {0027-8424},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1402773111},
	doi = {10.1073/pnas.1402773111},
	number = {40},
	journal = {Proceedings of the National Academy of Sciences},
	author = {van Kerkoerle, Timo and Self, Matthew W. and Dagnino, Bruno and Gariel-Mathis, Marie-Alice and Poort, Jasper and van der Togt, Chris and Roelfsema, Pieter R.},
	year = {2014},
	pages = {14332--14341},
	file = {Attachment:/Users/tito/Zotero/storage/IV3NCC7B/van Kerkoerle et al. - 2014 - Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex.pdf:application/pdf},
}

@article{ardid_tweaking_2013,
	title = {A {Tweaking} {Principle} for {Executive} {Control}: {Neuronal} {Circuit} {Mechanism} for {Rule}-{Based} {Task} {Switching} and {Conflict} {Resolution}},
	volume = {33},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1356-13.2013},
	doi = {10.1523/JNEUROSCI.1356-13.2013},
	number = {50},
	journal = {Journal of Neuroscience},
	author = {Ardid, S. and Wang, X.-J.},
	year = {2013},
	keywords = {attractor dynamics, congruency effect, down control, flexible behavior, motor conflict, sensory, switch cost, top},
	pages = {19504--19517},
	file = {Attachment:/Users/tito/Zotero/storage/TIKVS8ER/Ardid, Wang - 2013 - A Tweaking Principle for Executive Control Neuronal Circuit Mechanism for Rule-Based Task Switching and Conflict Re.pdf:application/pdf},
}

@book{berthomieu_enumerative_1983,
	title = {An enumerative approach for analyzing time {Petri} nets},
	isbn = {0-9695338-5-3},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.4063},
	abstract = {This paper is concerned with specifying and proving correct systems in which time appears as a parameter. We model such systems via Merlin's Time Petri Nets. An enumerative analysis technique is introduced for these nets based on the computation of a set of state classes and a reachability relation on the set. State classes are de ned in the text and an algorithm is provided for their enumeration. This enumerative approach allows us to derive a nite representation of their behavior for a large family of Time Petri Nets. The analysis method is illustrated by the analysis of a communication protocol},
	author = {Berthomieu, B. and Menasche, M.},
	year = {1983},
	doi = {10.1007/3-540-45014-9},
	pmid = {12185262},
	file = {Attachment:/Users/tito/Zotero/storage/ILN2Q8SK/Berthomieu, Menasche - 1983 - An enumerative approach for analyzing time Petri nets.pdf:text/html;Attachment:/Users/tito/Zotero/storage/J5MQDC79/Berthomieu, Menasche - 1983 - An enumerative approach for analyzing time Petri nets.pdf:text/html},
}

@article{barch_function_2013,
	title = {Function in the human connectome: task-{fMRI} and individual differences in behavior.},
	volume = {80},
	issn = {1095-9572},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913005272},
	doi = {10.1016/j.neuroimage.2013.05.033},
	abstract = {The primary goal of the Human Connectome Project (HCP) is to delineate the typical patterns of structural and functional connectivity in the healthy adult human brain. However, we know that there are important individual differences in such patterns of connectivity, with evidence that this variability is associated with alterations in important cognitive and behavioral variables that affect real world function. The HCP data will be a critical stepping-off point for future studies that will examine how variation in human structural and functional connectivity play a role in adult and pediatric neurological and psychiatric disorders that account for a huge amount of public health resources. Thus, the HCP is collecting behavioral measures of a range of motor, sensory, cognitive and emotional processes that will delineate a core set of functions relevant to understanding the relationship between brain connectivity and human behavior. In addition, the HCP is using task-fMRI (tfMRI) to help delineate the relationships between individual differences in the neurobiological substrates of mental processing and both functional and structural connectivity, as well as to help characterize and validate the connectivity analyses to be conducted on the structural and functional connectivity data. This paper describes the logic and rationale behind the development of the behavioral, individual difference, and tfMRI batteries and provides preliminary data on the patterns of activation associated with each of the fMRI tasks, at both group and individual levels.},
	journal = {NeuroImage},
	author = {Barch, Deanna M and Burgess, Gregory C and Harms, Michael P and Petersen, Steven E and Schlaggar, Bradley L and Corbetta, Maurizio and Glasser, Matthew F and Curtiss, Sandra and Dixit, Sachin and Feldt, Cindy and Nolan, Dan and Bryant, Edward and Hartley, Tucker and Footer, Owen and Bjork, James M and Poldrack, Russ and Smith, Steve and Johansen-Berg, Heidi and Snyder, Abraham Z and Van Essen, David C},
	year = {2013},
	pmid = {23684877},
	keywords = {Connectome, Connectivity, Cognitive, Emotion, Individual differences, Personality, Sensory and motor function, Task-fMRI, Brain, Adult, Behavior, Female, Humans, Magnetic Resonance Imaging, Male, Nerve Net, Magnetic Resonance Imaging: methods, Models, Neurological, Young Adult, Brain: physiology, Nerve Net: physiology, Task Performance and Analysis, Brain: anatomy \& histology, Anatomic, Behavior: physiology, Connectome: methods, Nerve Net: anatomy \& histology},
	pages = {169--89},
	file = {Attachment:/Users/tito/Zotero/storage/G8KJGQHM/Barch et al. - 2013 - Function in the human connectome task-fMRI and individual differences in behavior.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/XKPNX7MM/Barch et al. - 2013 - Function in the human connectome task-fMRI and individual differences in behavior.pdf:application/pdf},
}

@article{ammonium_supplementary_2013,
	title = {Supplementary {Methods}},
	doi = {10.1038/nature10847},
	author = {Ammonium, Materials},
	year = {2013},
	pages = {28--30},
	file = {Attachment:/Users/tito/Zotero/storage/4BSK3RAG/Ammonium - 2013 - Supplementary Methods.pdf:application/pdf},
}

@article{anticevic_characterizing_2013,
	title = {Characterizing {Thalamo}-{Cortical} {Disturbances} in {Schizophrenia} and {Bipolar} {Illness}.},
	issn = {1460-2199},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23825317},
	doi = {10.1093/cercor/bht165},
	abstract = {Schizophrenia is a devastating neuropsychiatric syndrome associated with distributed brain dysconnectivity that may involve large-scale thalamo-cortical systems. Incomplete characterization of thalamic connectivity in schizophrenia limits our understanding of its relationship to symptoms and to diagnoses with shared clinical presentation, such as bipolar illness, which may exist on a spectrum. Using resting-state functional magnetic resonance imaging, we characterized thalamic connectivity in 90 schizophrenia patients versus 90 matched controls via: (1) Subject-specific anatomically defined thalamic seeds; (2) anatomical and data-driven clustering to assay within-thalamus dysconnectivity; and (3) machine learning to classify diagnostic membership via thalamic connectivity for schizophrenia and for 47 bipolar patients and 47 matched controls. Schizophrenia analyses revealed functionally related disturbances: Thalamic over-connectivity with bilateral sensory-motor cortices, which predicted symptoms, but thalamic under-connectivity with prefrontal-striatal-cerebellar regions relative to controls, possibly reflective of sensory gating and top-down control disturbances. Clustering revealed that this dysconnectivity was prominent for thalamic nuclei densely connected with the prefrontal cortex. Classification and cross-diagnostic results suggest that thalamic dysconnectivity may be a neural marker for disturbances across diagnoses. Present findings, using one of the largest schizophrenia and bipolar neuroimaging samples to date, inform basic understanding of large-scale thalamo-cortical systems and provide vital clues about the complex nature of its disturbances in severe mental illness.},
	number = {1},
	journal = {Cerebral cortex (New York, N.Y. : 1991)},
	author = {Anticevic, Alan and Cole, Michael W and Repovs, Grega and Murray, John D and Brumbaugh, Margaret S and Winkler, Anderson M and Savic, Aleksandar and Krystal, John H and Pearlson, Godfrey D and Glahn, David C},
	year = {2013},
	pmid = {23825317},
	keywords = {connectivity, resting state, schizophrenia, bipolar illness},
	pages = {1--15},
	file = {Attachment:/Users/tito/Zotero/storage/35XM7QXN/Anticevic et al. - 2013 - Characterizing Thalamo-Cortical Disturbances in Schizophrenia and Bipolar Illness.pdf:application/pdf},
}

@article{wang_full_2015,
	title = {Full correlation matrix analysis ({FCMA}): {An} unbiased method for task-related functional connectivity},
	volume = {251},
	issn = {01650270},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0165027015001910},
	doi = {10.1016/j.jneumeth.2015.05.012},
	journal = {Journal of Neuroscience Methods},
	author = {Wang, Yida and Cohen, Jonathan D. and Li, Kai and Turk-Browne, Nicholas B.},
	year = {2015},
	pages = {108--119},
}

@article{warden_task-dependent_2010,
	title = {Task-{Dependent} {Changes} in {Short}-{Term} {Memory} in the {Prefrontal} {Cortex}},
	volume = {30},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1569-10.2010},
	doi = {10.1523/JNEUROSCI.1569-10.2010},
	abstract = {The prefrontal cortex (PFC) is important for flexible, context-dependent behavioral control. It also plays a critical role in short-term memory maintenance. Though many studies have investigated these functions independently, it is unclear how these two very different processes are realized by a single brain area. To address this, we trained two monkeys on two variants of an object sequence memory task. These tasks had the same memory requirements but differed in how information was read out and used. For the "recognition" task, the monkeys had to remember two sequentially presented objects and then release a bar when a matching sequence was recognized. For the "recall" task, the monkeys had to remember the same sequence of objects but were instead required to recall the sequence and reproduce it with saccadic eye movements when presented with an array of objects. After training, we recorded the activity of PFC neurons during task performance. We recorded 222 neurons during the recognition task, 177 neurons during the recall task, and 248 neurons during the switching task (interleaved blocks of recognition and recall). Task context had a profound influence on neural selectivity for objects. During the recall task, the first object was encoded more strongly than the second object, while during the recognition task, the second object was encoded more strongly. In addition, most of the neurons encoded both the task and the objects, evidence for a single population responsible for these two critical prefrontal functions.},
	number = {47},
	journal = {Journal of Neuroscience},
	author = {Warden, Melissa R and Miller, Earl K},
	year = {2010},
	pmid = {21106819},
	pages = {15801--15810},
	file = {Attachment:/Users/tito/Zotero/storage/QUEPGNCV/Warden, Miller - 2010 - Task-Dependent Changes in Short-Term Memory in the Prefrontal Cortex.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/5Y534SCQ/Warden, Miller - 2010 - Task-Dependent Changes in Short-Term Memory in the Prefrontal Cortex.pdf:application/pdf},
}

@article{yu_assessing_2015,
	title = {Assessing dynamic brain graphs of time-varying connectivity in {fMRI} data: {Application} to healthy controls and patients with schizophrenia},
	volume = {107},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S105381191401012X},
	doi = {10.1016/j.neuroimage.2014.12.020},
	journal = {NeuroImage},
	author = {Yu, Qingbao and Erhardt, Erik B. and Sui, Jing and Du, Yuhui and He, Hao and Hjelm, Devon and Cetin, Mustafa S. and Rachakonda, Srinivas and Miller, Robyn L. and Pearlson, Godfrey and Calhoun, Vince D.},
	year = {2015},
	keywords = {R-fMRI, Schizophrenia, ICA, Brain graph, Dynamic, Time varying},
	pages = {345--355},
	file = {Attachment:/Users/tito/Zotero/storage/UXF83X2U/Yu et al. - 2015 - Assessing dynamic brain graphs of time-varying connectivity in fMRI data Application to healthy controls and patients.pdf:application/pdf},
}

@article{siegel_phase-dependent_2009,
	title = {Phase-dependent neuronal coding of objects in short-term memory.},
	volume = {106},
	issn = {0027-8424},
	doi = {10.1073/pnas.0908193106},
	abstract = {The ability to hold multiple objects in memory is fundamental to intelligent behavior, but its neural basis remains poorly understood. It has been suggested that multiple items may be held in memory by oscillatory activity across neuronal populations, but yet there is little direct evidence. Here, we show that neuronal information about two objects held in short-term memory is enhanced at specific phases of underlying oscillatory population activity. We recorded neuronal activity from the prefrontal cortices of monkeys remembering two visual objects over a brief interval. We found that during this memory interval prefrontal population activity was rhythmically synchronized at frequencies around 32 and 3 Hz and that spikes carried the most information about the memorized objects at specific phases. Further, according to their order of presentation, optimal encoding of the first presented object was significantly earlier in the 32 Hz cycle than that for the second object. Our results suggest that oscillatory neuronal synchronization mediates a phase-dependent coding of memorized objects in the prefrontal cortex. Encoding at distinct phases may play a role for disambiguating information about multiple objects in short-term memory.},
	number = {50},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Siegel, Markus and Warden, Melissa R and Miller, Earl K},
	year = {2009},
	pmid = {19926847},
	pages = {21341--21346},
	file = {Attachment:/Users/tito/Zotero/storage/JZDFRC88/Siegel, Warden, Miller - 2009 - Phase-dependent neuronal coding of objects in short-term memory.pdf:application/pdf},
}

@article{stark_inhibition-induced_2013,
	title = {Inhibition-{Induced} theta resonance in cortical circuits},
	volume = {80},
	issn = {08966273},
	doi = {10.1016/j.neuron.2013.09.033},
	abstract = {Both circuit and single-cell properties contribute to network rhythms. Invitro, pyramidal cells exhibit theta-band membrane potential (subthreshold) resonance, but whether and how subthreshold resonance translates into spiking resonance in freely behaving animals is unknown. Here, we used optogenetic activation to trigger spiking in pyramidal cells or parvalbumin immunoreactive interneurons (PV) in the hippocampus and neocortex of freely behaving rodents. Individual directly activated pyramidal cells exhibited narrow-band spiking centered on a wide range of frequencies. In contrast, PV photoactivation indirectly induced theta-band-limited, excess postinhibitory spiking in pyramidal cells (resonance). PV-inhibited pyramidal cells and interneurons spiked at PV-inhibition troughs, similar to CA1 cells during spontaneous theta oscillations. Pharmacological blockade of hyperpolarization-activated (Ih) currents abolished theta resonance. Inhibition-induced theta-band spiking was replicated in a pyramidal cell-interneuronmodel that included Ih. Thus, PV interneurons mediate pyramidal cell spiking resonance in intact cortical networks, favoring transmission at theta frequency.},
	number = {5},
	journal = {Neuron},
	author = {Stark, Eran and Eichler, Ronny and Roux, Lisa and Fujisawa, Shigeyoshi and Rotstein, Horacio G. and Buzsáki, György},
	year = {2013},
	pmid = {24314731},
	pages = {1263--1276},
	file = {Attachment:/Users/tito/Zotero/storage/K5637F3K/Stark et al. - 2013 - Inhibition-Induced theta resonance in cortical circuits.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/4IEICCR3/Stark et al. - 2013 - Inhibition-Induced Theta Resonance in Cortical Circuits(2).pdf:application/pdf},
}

@article{stelzer_deficient_2014,
	title = {Deficient approaches to human neuroimaging},
	volume = {8},
	issn = {1662-5161},
	url = {http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2014.00462/abstract},
	doi = {10.3389/fnhum.2014.00462},
	abstract = {Functional magnetic resonance imaging (fMRI) is the workhorse of imaging-based human cognitive neuroscience. The use of fMRI is ever-increasing; within the last 4 years more fMRI studies have been published than in the previous 17 years.This large body of research has mainly focused on the functional localization of condition- or stimulus-dependent changes in the blood-oxygenation-level dependent signal. In recent years, however, many aspects of the commonly practiced analysis frameworks and methodologies have been critically reassessed. Here we summarize these critiques, providing an overview of the major conceptual and practical deficiencies in widely used brain-mapping approaches, and exemplify some of these issues by the use of imaging data and simulations. In particular,we discuss the inherent pitfalls and shortcomings of methodologies for statistical parametric mapping. Our critique emphasizes recent reports of excessively high numbers of both false positive and false negative findings in fMRI brain mapping. We outline our view regarding the broader scientific implications of these methodological considerations and briefly discuss possible solutions.},
	number = {July},
	journal = {Frontiers in Human Neuroscience},
	author = {Stelzer, Johannes and Lohmann, Gabriele and Mueller, Karsten and Buschmann, Tilo and Turner, Robert},
	year = {2014},
	pmid = {25071503},
	keywords = {fMRI, fmri, cognitive neuroscience, brain mapping, critical neuroscience, funct, functional localization},
	pages = {462},
	file = {Attachment:/Users/tito/Zotero/storage/VH6N2PXF/Stelzer et al. - 2014 - Deficient approaches to human neuroimaging.pdf:application/pdf},
}

@article{hodgkin_quantitative_1990,
	title = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
	volume = {52},
	issn = {00928240},
	url = {http://www.springerlink.com/index/10.1016/S0092-8240(05)80004-7},
	doi = {10.1016/S0092-8240(05)80004-7},
	abstract = {This article concludes a series of papers concerned with the flow of electric current through the surface membrane of a giant nerve fibre (Hodgkinet al., 1952,J. Physiol.116, 424-448; Hodgkin and Huxley 1952,J. Physiol.116, 449-566). Its general object is to discuss the results of the preceding papers (Section 1), to put them into mathematical form (Section 2) and to whow that they will account for conduction and excitation in quantitative terms (Sections 3-6).},
	number = {1-2},
	journal = {Bulletin of Mathematical Biology},
	author = {HODGKIN, A and HUXLEY, A},
	year = {1990},
	pmid = {2185861},
	pages = {25--71},
	file = {Attachment:/Users/tito/Zotero/storage/7UVE2BSF/HODGKIN, HUXLEY - 1990 - A quantitative description of membrane current and its application to conduction and excitation in nerve.pdf:application/pdf},
}

@article{self_different_2012,
	title = {Different glutamate receptors convey feedforward and recurrent processing in macaque {V1}},
	volume = {109},
	issn = {0027-8424},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1119527109},
	doi = {10.1073/pnas.1119527109},
	number = {27},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Self, M. W. and Kooijmans, R. N. and Super, H. and Lamme, V. A. and Roelfsema, P. R.},
	year = {2012},
	pages = {11031--11036},
	file = {Attachment:/Users/tito/Zotero/storage/JDGUSV9K/Self et al. - 2012 - Different glutamate receptors convey feedforward and recurrent processing in macaque V1.pdf:application/pdf},
}

@article{rotstein_frequency_2014-1,
	title = {Frequency {Preference} {Response} to {Oscillatory} {Inputs} in {Two}-dimensional {Neural} {Models}: {A} {Geometric} {Approach} to {Subthreshold} {Amplitude} and {Phase} {Resonance}.},
	volume = {4},
	issn = {2190-8567},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4014472&tool=pmcentrez&rendertype=abstract},
	doi = {10.1186/2190-8567-4-11},
	abstract = {We investigate the dynamic mechanisms of generation of subthreshold and phase resonance in two-dimensional linear and linearized biophysical (conductance-based) models, and we extend our analysis to account for the effect of simple, but not necessarily weak, types of nonlinearities. Subthreshold resonance refers to the ability of neurons to exhibit a peak in their voltage amplitude response to oscillatory input currents at a preferred non-zero (resonant) frequency. Phase-resonance refers to the ability of neurons to exhibit a zero-phase (or zero-phase-shift) response to oscillatory input currents at a non-zero (phase-resonant) frequency. We adapt the classical phase-plane analysis approach to account for the dynamic effects of oscillatory inputs and develop a tool, the envelope-plane diagrams, that captures the role that conductances and time scales play in amplifying the voltage response at the resonant frequency band as compared to smaller and larger frequencies. We use envelope-plane diagrams in our analysis. We explain why the resonance phenomena do not necessarily arise from the presence of imaginary eigenvalues at rest, but rather they emerge from the interplay of the intrinsic and input time scales. We further explain why an increase in the time-scale separation causes an amplification of the voltage response in addition to shifting the resonant and phase-resonant frequencies. This is of fundamental importance for neural models since neurons typically exhibit a strong separation of time scales. We extend this approach to explain the effects of nonlinearities on both resonance and phase-resonance. We demonstrate that nonlinearities in the voltage equation cause amplifications of the voltage response and shifts in the resonant and phase-resonant frequencies that are not predicted by the corresponding linearized model. The differences between the nonlinear response and the linear prediction increase with increasing levels of the time scale separation between the voltage and the gating variable, and they almost disappear when both equations evolve at comparable rates. In contrast, voltage responses are almost insensitive to nonlinearities located in the gating variable equation. The method we develop provides a framework for the investigation of the preferred frequency responses in three-dimensional and nonlinear neuronal models as well as simple models of coupled neurons.},
	journal = {Journal of Mathematical Neuroscience},
	author = {Rotstein, Horacio G},
	year = {2014},
	pmid = {24872925},
	pages = {11},
	file = {Attachment:/Users/tito/Zotero/storage/G98W7UF7/Rotstein - 2014 - Frequency Preference Response to Oscillatory Inputs in Two-dimensional Neural Models A Geometric Approach to Subthresh.pdf:application/pdf},
}

@article{sadilek_physiologically_2015,
	title = {Physiologically motivated multiplex {Kuramoto} model describes phase diagram of cortical activity},
	volume = {5},
	issn = {2045-2322},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/25996547},
	doi = {10.1038/srep10015},
	abstract = {We derive a two-layer multiplex Kuramoto model from Wilson-Cowan type physiological equations that describe neural activity on a network of interconnected cortical regions. This is mathematically possible due to the existence of a unique, stable limit cycle, weak coupling, and inhibitory synaptic time delays. We study the phase diagram of this model numerically as a function of the inter-regional connection strength that is related to cerebral blood flow, and a phase shift parameter that is associated with synaptic GABA concentrations. We find three macroscopic phases of cortical activity: background activity (unsynchronized oscillations), epileptiform activity (highly synchronized oscillations) and resting-state activity (synchronized clusters/chaotic behaviour). Previous network models could hitherto not explain the existence of all three phases. We further observe a shift of the average oscillation frequency towards lower values together with the appearance of coherent slow oscillations at the transition from resting-state to epileptiform activity. This observation is fully in line with experimental data and could explain the influence of GABAergic drugs both on gamma oscillations and epileptic states. Compared to previous models for gamma oscillations and resting-state activity, the multiplex Kuramoto model not only provides a unifying framework, but also has a direct connection to measurable physiological parameters.},
	number = {May},
	journal = {Scientific Reports},
	author = {Sadilek, Maximilian and Thurner, Stefan},
	year = {2015},
	pmid = {25996547},
	pages = {10015},
	file = {Attachment:/Users/tito/Zotero/storage/G6T3KZ7P/Sadilek, Thurner - 2015 - Physiologically motivated multiplex Kuramoto model describes phase diagram of cortical activity.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/84QIMFDP/Sadilek, Thurner - 2015 - Physiologically motivated multiplex Kuramoto model describes phase diagram of cortical activity(2).pdf:application/pdf},
}

@article{power_supplemental_nodate,
	title = {Supplemental {Information} {Functional} {Network} {Organization} of the {Human} {Brain}},
	volume = {72},
	author = {Power, Jonathan D and Cohen, Alexander L and Nelson, Steven M and Wig, Gagan S},
	file = {Attachment:/Users/tito/Zotero/storage/LGVQ3YPT/Power et al. - Unknown - Supplemental Information Functional Network Organization of the Human Brain.pdf:application/pdf},
}

@article{polack_cellular_2013,
	title = {Cellular mechanisms of brain state–dependent gain modulation in visual cortex},
	volume = {16},
	issn = {1097-6256},
	url = {http://www.nature.com/doifinder/10.1038/nn.3464},
	doi = {10.1038/nn.3464},
	number = {9},
	journal = {Nature Neuroscience},
	author = {Polack, Pierre-Olivier and Friedman, Jonathan and Golshani, Peyman},
	year = {2013},
	pages = {1331--1339},
	file = {Attachment:/Users/tito/Zotero/storage/EMLG7K4K/Polack, Friedman, Golshani - 2013 - Cellular mechanisms of brain state–dependent gain modulation in visual cortex.pdf:application/pdf;polack_et_al_2013.pdf:/Users/tito/Zotero/storage/7JBL5LIS/polack_et_al_2013.pdf:application/pdf},
}

@article{rotstein_neurons_2002,
	title = {Neurons and {Neural} {Networks}: {Computational} {Models} {Horacio} {G}. {Rotstein} {Farzan} {Nadim}},
	doi = {10.1002/9780470015902.a0000089.pub3},
	abstract = {Neural networks produce electrical activity that is generated by the biophysical properties of the constituent neurons and synapses. Mathematical equations can be used to describe the electrical activity of neurons and neural networks and the underlying biophysical properties. These equations give rise to computational models of neurons and networks that can be analysed using mathematical techniques or numerically simulated with computers.},
	journal = {ENCYCLOPEDIA OF LIFE SCIENCES / \& 2002 Macmillan Publishers Ltd, Nature Publishing Group / www.els.net},
	author = {Rotstein, Horacio G},
	year = {2002},
	keywords = {synchrony, nonlinear dynamics, bifurcation, membrane biophysics, phase plane},
	pages = {1--15},
	file = {Attachment:/Users/tito/Zotero/storage/9MZ6W5SB/Rotstein - 2002 - Neurons and Neural Networks Computational Models Horacio G. Rotstein Farzan Nadim.pdf:application/pdf},
}

@article{power_control-related_2013,
	title = {Control-related systems in the human brain},
	volume = {23},
	issn = {09594388},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438813000135},
	doi = {10.1016/j.conb.2012.12.009},
	number = {2},
	journal = {Current Opinion in Neurobiology},
	author = {Power, Jonathan D and Petersen, Steven E},
	year = {2013},
	pages = {223--228},
	file = {Attachment:/Users/tito/Zotero/storage/SWK34UB3/Power, Petersen - 2013 - Control-related systems in the human brain.pdf:application/pdf},
}

@article{roediger_inexpensive_2012,
	title = {Inexpensive techniques to improve education: {Applying} cognitive psychology to enhance educational practice},
	volume = {1},
	issn = {22113681},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S2211368112000915},
	doi = {10.1016/j.jarmac.2012.09.002},
	number = {4},
	journal = {Journal of Applied Research in Memory and Cognition},
	author = {Roediger, Henry L. and Pyc, Mary A.},
	year = {2012},
	keywords = {inexpensive techniques to improve},
	pages = {242--248},
	file = {Attachment:/Users/tito/Zotero/storage/Q6AES9LG/Roediger, Pyc - 2012 - Inexpensive techniques to improve education Applying cognitive psychology to enhance educational practice.pdf:application/pdf},
}

@article{misic_cooperative_2015,
	title = {Cooperative and {Competitive} {Spreading} {Dynamics} on the {Human} {Connectome}},
	volume = {86},
	issn = {08966273},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315004742},
	doi = {10.1016/j.neuron.2015.05.035},
	abstract = {Increasingly detailed data on the network topology of neural circuits create a need for theoretical principles that explain how these networks shape neural communication. Here we use a model of cascade spreading to reveal architectural features of human brain networks that facilitate spreading. Using an anatomical brain network derived from high-resolu- tion diffusion spectrumimaging (DSI), we investigate scenarioswhereperturbations initiated atseednodes result in global cascades that interact either coopera- tively or competitively.We find that hub regions and a backbone of pathways facilitate early spreading, while the shortest path structure of the connectome enables cooperative effects, accelerating the spread ofcascades. Finally,competingcascadesbecomein- tegrated by converging on polysensory associative areas. These findings show that the organizational principles of brain networks shape global communication and facilitate integrative function.},
	number = {6},
	journal = {Neuron},
	author = {Mišić, Bratislav and Betzel, Richard F. and Nematzadeh, Azadeh and Goñi, Joaquin and Griffa, Alessandra and Hagmann, Patric and Flammini, Alessandro and Ahn, Yong-Yeol and Sporns, Olaf},
	year = {2015},
	pmid = {26087168},
	pages = {1518--1529},
}

@article{miller_integrative_2001,
	title = {An integrative theory of prefrontal cortex function},
	volume = {24},
	number = {1},
	journal = {Annual review of neuroscience},
	author = {Miller, Earl K and Cohen, Jonathan D},
	year = {2001},
	keywords = {cognition, executive control, attention, working memory, however, cortex has long been, frontal lobes, has remained a mystery, here, important role, in accordance with, in cognitive control, in the ability to, internal goals, its neural basis, orchestrate thought and action, s abstract the prefrontal, suspected to play an, we propose},
	pages = {167--202},
	file = {Attachment:/Users/tito/Zotero/storage/YJCM6LJU/Miller, Cohen - 2001 - A N I NTEGRATIVE T HEORY OF P REFRONTAL C ORTEX F UNCTION.pdf:application/pdf},
}

@article{odwyer_using_2012,
	title = {Using support vector machines with multiple indices of diffusion for automated classification of mild cognitive impairment.},
	volume = {7},
	issn = {1932-6203},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3285682&tool=pmcentrez&rendertype=abstract},
	doi = {10.1371/journal.pone.0032441},
	abstract = {Few studies have looked at the potential of using diffusion tensor imaging (DTI) in conjunction with machine learning algorithms in order to automate the classification of healthy older subjects and subjects with mild cognitive impairment (MCI). Here we apply DTI to 40 healthy older subjects and 33 MCI subjects in order to derive values for multiple indices of diffusion within the white matter voxels of each subject. DTI measures were then used together with support vector machines (SVMs) to classify control and MCI subjects. Greater than 90\% sensitivity and specificity was achieved using this method, demonstrating the potential of a joint DTI and SVM pipeline for fast, objective classification of healthy older and MCI subjects. Such tools may be useful for large scale drug trials in Alzheimer's disease where the early identification of subjects with MCI is critical.},
	number = {2},
	journal = {PloS one},
	author = {O'Dwyer, Laurence and Lamberton, Franck and Bokde, Arun L W and Ewers, Michael and Faluyi, Yetunde O and Tanner, Colby and Mazoyer, Bernard and O'Neill, Desmond and Bartley, Máiréad and Collins, D Rónán and Coughlan, Tara and Prvulovic, David and Hampel, Harald},
	year = {2012},
	pmid = {22384251},
	keywords = {Female, Humans, Magnetic Resonance Imaging, Male, Algorithms, Magnetic Resonance Imaging: methods, Computer-Assisted, Aged, Middle Aged, Diffusion, Computer-Assisted: methods, Alzheimer Disease, Alzheimer Disease: diagnosis, Alzheimer Disease: pathology, Automation, Cognition Disorders, Cognition Disorders: diagnosis, Cognition Disorders: pathology, Diagnosis, Diffusion Tensor Imaging, Diffusion Tensor Imaging: methods, Mild Cognitive Impairment, Mild Cognitive Impairment: diagnosis, Mild Cognitive Impairment: pathology, Sensitivity and Specificity, Signal Processing, Support Vector Machines},
	pages = {e32441},
	file = {Attachment:/Users/tito/Zotero/storage/W2MCUN5Z/O'Dwyer et al. - 2012 - Using support vector machines with multiple indices of diffusion for automated classification of mild cognitive.pdf:application/pdf},
}

@article{tononi_information_2004,
	title = {An information integration theory of consciousness.},
	volume = {5},
	issn = {1471-2202},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15522121},
	doi = {10.1186/1471-2202-5-42},
	abstract = {Consciousness is traditionally defined in mental or psychological terms. In trying to find its neural basis, introspective or behavioral observations are considered the gold standard, to which neural measures should be fitted. I argue that this poses serious problems for understanding the mind-brain relationship. To solve these problems, neural and behavioral measures should be put on an equal footing. I illustrate this by an example from visual neuroscience, in which both neural and behavioral arguments converge towards a coherent scientific definition of visual consciousness. However, to accept this definition, we need to let go of our intuitive or psychological notions of conscious experience and let the neuroscience arguments have their way. Only by moving our notion of mind towards that of brain can progress be made.},
	journal = {BMC neuroscience},
	author = {Tononi, Giulio and Tononi, Giulio},
	year = {2004},
	pmid = {15522121},
	keywords = {Brain, Humans, Information Theory, Brain: physiology, Consciousness, Neurons, Neurons: physiology, Thalamus, Afferent Pathways, Motor Activity, Systems Integration, Thalamus: physiology},
	pages = {42--64},
	file = {Attachment:/Users/tito/Zotero/storage/EH9IR3MC/Tononi, Tononi - 2004 - An information integration theory of consciousness.pdf:application/pdf},
}

@article{tononi_measuring_2003,
	title = {Measuring information integration.},
	volume = {4},
	issn = {1471-2202},
	doi = {10.1186/1471-2202-4-31},
	abstract = {BACKGROUND: To understand the functioning of distributed networks such as the brain, it is important to characterize their ability to integrate information. The paper considers a measure based on effective information, a quantity capturing all causal interactions that can occur between two parts of a system. RESULTS: The capacity to integrate information, or Phi, is given by the minimum amount of effective information that can be exchanged between two complementary parts of a subset. It is shown that this measure can be used to identify the subsets of a system that can integrate information, or complexes. The analysis is applied to idealized neural systems that differ in the organization of their connections. The results indicate that Phi is maximized by having each element develop a different connection pattern with the rest of the complex (functional specialization) while ensuring that a large amount of information can be exchanged across any bipartition of the network (functional integration). CONCLUSION: Based on this analysis, the connectional organization of certain neural architectures, such as the thalamocortical system, are well suited to information integration, while that of others, such as the cerebellum, are not, with significant functional consequences. The proposed analysis of information integration should be applicable to other systems and networks.},
	journal = {BMC neuroscience},
	author = {Tononi, Giulio and Sporns, Olaf},
	year = {2003},
	pmid = {14641936},
	pages = {31},
	file = {Attachment:/Users/tito/Zotero/storage/STFWZTN9/Tononi, Sporns - 2003 - Measuring information integration.pdf:application/pdf},
}

@article{cole_global_2012,
	title = {Global connectivity of prefrontal cortex predicts cognitive control and intelligence.},
	volume = {32},
	issn = {1529-2401},
	url = {http://www.mendeley.com/catalog/global-connectivity-prefrontal-cortex-predicts-cognitive-control-intelligence/},
	doi = {10.1523/JNEUROSCI.0536-12.2012},
	abstract = {Control of thought and behavior is fundamental to human intelligence. Evidence suggests a frontoparietal brain network implements such cognitive control across diverse contexts. We identify a mechanism–global connectivity–by which components of this network might coordinate control of other networks. A lateral prefrontal cortex (LPFC) region's activity was found to predict performance in a high control demand working memory task and also to exhibit high global connectivity. Critically, global connectivity in this LPFC region, involving connections both within and outside the frontoparietal network, showed a highly selective relationship with individual differences in fluid intelligence. These findings suggest LPFC is a global hub with a brainwide influence that facilitates the ability to implement control processes central to human intelligence.},
	number = {26},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Cole, Michael W and Yarkoni, Tal and Repovs, Grega and Anticevic, Alan and Braver, Todd S},
	month = jun,
	year = {2012},
	pmid = {22745498},
	keywords = {Intelligence, Adult, Brain Mapping, Cognition, Female, Functional Laterality, Humans, Magnetic Resonance Imaging, Male, Neural Pathways, Neuropsychological Tests, Prefrontal Cortex, Adolescent, Young Adult, Computer-Assisted, Image Processing, Oxygen, Oxygen: blood, Cognition: physiology, Prefrontal Cortex: physiology, Neural Pathways: physiology, Intelligence: physiology, Individuality, Intelligence Tests, Neural Pathways: blood supply, Predictive Value of Tests, Prefrontal Cortex: blood supply},
	pages = {8988--99},
	file = {Attachment:/Users/tito/Zotero/storage/PCSSFHYY/Cole et al. - 2012 - Global Connectivity of Prefrontal Cortex Predicts Cognitive Control and Intelligence(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/RLM69857/Cole et al. - 2012 - Global Connectivity of Prefrontal Cortex Predicts Cognitive Control and Intelligence(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/YN3BF3TJ/Cole et al. - 2012 - Global Connectivity of Prefrontal Cortex Predicts Cognitive Control and Intelligence.pdf:application/pdf},
}

@article{deco_resting-state_2013,
	title = {Resting-state functional connectivity emerges from structurally and dynamically shaped slow linear fluctuations.},
	volume = {33},
	issn = {1529-2401},
	url = {http://www.mendeley.com/catalog/restingstate-functional-connectivity-emerges-structurally-dynamically-shaped-slow-linear-fluctuation/},
	doi = {10.1523/JNEUROSCI.1091-13.2013},
	abstract = {Brain fluctuations at rest are not random but are structured in spatial patterns of correlated activity across different brain areas. The question of how resting-state functional connectivity (FC) emerges from the brain's anatomical connections has motivated several experimental and computational studies to understand structure-function relationships. However, the mechanistic origin of resting state is obscured by large-scale models' complexity, and a close structure-function relation is still an open problem. Thus, a realistic but simple enough description of relevant brain dynamics is needed. Here, we derived a dynamic mean field model that consistently summarizes the realistic dynamics of a detailed spiking and conductance-based synaptic large-scale network, in which connectivity is constrained by diffusion imaging data from human subjects. The dynamic mean field approximates the ensemble dynamics, whose temporal evolution is dominated by the longest time scale of the system. With this reduction, we demonstrated that FC emerges as structured linear fluctuations around a stable low firing activity state close to destabilization. Moreover, the model can be further and crucially simplified into a set of motion equations for statistical moments, providing a direct analytical link between anatomical structure, neural network dynamics, and FC. Our study suggests that FC arises from noise propagation and dynamical slowing down of fluctuations in an anatomically constrained dynamical system. Altogether, the reduction from spiking models to statistical moments presented here provides a new framework to explicitly understand the building up of FC through neuronal dynamics underpinned by anatomical connections and to drive hypotheses in task-evoked studies and for clinical applications.},
	number = {27},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Deco, Gustavo and Ponce-Alvarez, Adrián and Mantini, Dante and Romani, Gian Luca and Hagmann, Patric and Corbetta, Maurizio},
	month = jul,
	year = {2013},
	pmid = {23825427},
	keywords = {Adult, Brain Mapping, Cerebral Cortex, Female, Humans, Magnetic Resonance Imaging, Male, Nerve Net, Magnetic Resonance Imaging: methods, Young Adult, Rest, Rest: physiology, Action Potentials, Action Potentials: physiology, Nerve Net: physiology, Brain Mapping: methods, Cerebral Cortex: physiology, Linear Models},
	pages = {11239--52},
	file = {Attachment:/Users/tito/Zotero/storage/EJ4LXWPL/Deco et al. - 2013 - Resting-State Functional Connectivity Emerges from Structurally and Dynamically Shaped Slow Linear Fluctuations.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6YIWBNLB/Deco et al. - 2013 - Resting-State Functional Connectivity Emerges from Structurally and Dynamically Shaped Slow Linear Fluctuations.pdf:application/pdf},
}

@article{parkin_dynamic_2015,
	title = {Dynamic {Network} {Mechanisms} of {Relational} {Integration}},
	volume = {35},
	url = {http://dx.doi.org/10.1523/JNEUROSCI.4956-14.2015},
	doi = {10.1523/JNEUROSCI.4956-14.2015},
	number = {20},
	journal = {Journal of Neuroscience},
	author = {Parkin, B L and Hellyer, P J and Leech, R and Hampshire, A},
	year = {2015},
	pages = {7660--7673},
	file = {Attachment:/Users/tito/Zotero/storage/6HU9HWW8/Parkin et al. - 2015 - Dynamic Network Mechanisms of Relational Integration.pdf:application/pdf},
}

@article{schiller_overlapping_2010,
	title = {Overlapping neural systems mediating extinction, reversal and regulation of fear},
	volume = {14},
	url = {http://dx.doi.org/10.1016/j.tics.2010.04.002},
	doi = {10.1016/j.tics.2010.04.002},
	abstract = {Learned fear is a process allowing quick detection of associations between cues in the environment and prediction of imminent threat. Adaptive function in a changing environment, however, requires organisms to quickly update this learning and have the ability to hinder fear responses when predictions are no longer correct. Here we focus on three strategies that can modify conditioned fear, namely extinction, reversal and regulation of fear, and review their underlying neural mechanisms. By directly comparing neuroimaging data from three separate studies that employ each strategy, we highlight overlapping brain structures that comprise a general circuitry in the human brain. This circuitry potentially enables the flexible control of fear, regardless of the particular task demands. ?? 2010 Elsevier Ltd. All rights reserved.},
	number = {6},
	author = {Schiller, Daniela and Delgado, Mauricio},
	year = {2010},
	file = {Attachment:/Users/tito/Zotero/storage/3LZ6SFH7/Schiller, Delgado - 2010 - Overlapping neural systems mediating extinction, reversal and regulation of fear.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/G2N7I8ES/Schiller, Delgado - 2010 - Overlapping neural systems mediating extinction, reversal and regulation of fear.pdf:application/pdf},
}

@article{chen_cortical_2011,
	title = {Cortical surface-based searchlight decoding.},
	volume = {56},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2010.07.035},
	doi = {10.1016/j.neuroimage.2010.07.035},
	abstract = {Local voxel patterns of \{fMRI\} signals contain specific information about cognitive processes ranging from basic sensory processing to high level decision making. These patterns can be detected using multivariate pattern classification, and localization of these patterns can be achieved with searchlight methods in which the information content of spherical sub-volumes of the \{fMRI\} signal is assessed. The only assumption made by this approach is that the patterns are spatially local. We present a cortical surface-based searchlight approach to pattern localization. Voxels are grouped according to distance along the cortical surface-the intrinsic metric of cortical anatomy-rather than Euclidean distance as in volumetric searchlights. Using a paradigm in which the category of visually presented objects is decoded, we compare the surface-based method to a standard volumetric searchlight technique. Group analyses of accuracy maps produced by both methods show similar distributions of informative regions. The surface-based method achieves a finer spatial specificity with comparable peak values of significance, while the volumetric method appears to be more sensitive to small informative regions and might also capture information not located directly within the gray matter. Furthermore, our findings show that a surface centered in the middle of the gray matter contains more information than to the white-gray boundary or the pial surface.},
	number = {2},
	journal = {NeuroImage},
	author = {Chen, Yi and Namburi, Praneeth and Elliott, Lloyd T and Heinzle, Jakob and Soon, Chun S and Chee, Michael W and Haynes, John-Dylan D},
	year = {2011},
	pages = {582--592},
	file = {Attachment:/Users/tito/Zotero/storage/5PTE7FIP/Chen et al. - 2011 - Cortical surface-based searchlight decoding.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/KQJAUINR/Chen et al. - 2011 - Cortical surface-based searchlight decoding.pdf:application/pdf},
}

@article{meinzer_anodal_2013,
	title = {Anodal transcranial direct current stimulation temporarily reverses age-associated cognitive decline and functional brain activity changes.},
	volume = {33},
	url = {http://dx.doi.org/10.1523/JNEUROSCI.5743-12.2013},
	doi = {10.1523/JNEUROSCI.5743-12.2013},
	abstract = {The rising proportion of elderly people worldwide will yield an increased incidence of age-associated cognitive impairments, imposing major burdens on societies. Consequently, growing interest emerged to evaluate new strategies to delay or counteract cognitive decline in aging. Here, we assessed immediate effects of anodal transcranial direct current stimulation \{(atDCS)\} on cognition and previously described detrimental changes in brain activity attributable to aging. Twenty healthy elderly adults were assessed in a crossover sham-controlled design using functional magnetic resonance imaging \{(fMRI)\} and concurrent transcranial \{DCS\} administered to the left inferior frontal gyrus. Effects on performance and task-related brain activity were evaluated during overt semantic word generation, a task that is negatively affected by advanced age. Task-absent resting-state \{fMRI\} \{(RS-fMRI)\} assessed \{atDCS-induced\} changes at the network level independent of performance. Twenty matched younger adults served as controls. During sham stimulation, task-related \{fMRI\} demonstrated that enhanced bilateral prefrontal activity in older adults was associated with reduced performance. \{RS-fMRI\} revealed enhanced anterior and reduced posterior functional brain connectivity. \{atDCS\} significantly improved performance in older adults up to the level of younger controls; significantly reduced task-related hyperactivity in bilateral prefrontal cortices, the anterior cingulate gyrus, and the precuneus; and induced a more \{"\}youth-like\{"\} connectivity pattern during \{RS-fMRI.\} Our results provide converging evidence from behavioral analysis and two independent functional imaging paradigms that a single session of \{atDCS\} can temporarily reverse nonbeneficial effects of aging on cognition and brain activity and connectivity. These findings may translate into novel treatments to ameliorate cognitive decline in normal aging in the future.},
	number = {30},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Meinzer, Marcus and Lindenberg, Robert and Antonenko, Daria and Flaisch, Tobias and Fl"oel, Agnes},
	year = {2013},
	pages = {12470--12478},
	file = {Attachment:/Users/tito/Zotero/storage/64BSI67X/Meinzer et al. - 2013 - Anodal transcranial direct current stimulation temporarily reverses age-associated cognitive decline and functio.pdf:application/pdf},
}

@article{mcmenamin_discovering_2015,
	title = {Discovering networks altered by potential threat (\{"\}anxiety\{"\}) using {Quadratic} {Discriminant} {Analysis}.},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2015.05.002},
	doi = {10.1016/j.neuroimage.2015.05.002},
	abstract = {Researchers have only recently begun using functional neuroimaging to explore the human response to periods of sustained anxious anticipation, namely potential threat. Here, we investigated brain responses acquired with functional \{MRI\} during an instructed threat of shock paradigm used to create sustained periods of aversive anticipation. In this re-analysis of previously published data, we employed Quadratic Discriminant Analysis to classify the multivariate pattern of whole-brain functional connectivity and to identify connectivity changes during periods of potential threat. Our method identifies clusters with altered connectivity on a voxelwise basis, thus eschewing the need to define regions a priori. Classifier generalization was evaluated by testing on data from participants not used during training. Robust classification between threat and safe contexts was possible, and inspection of \{"\}diagnostic features\{"\} revealed altered functional connectivity involving the intraparietal sulcus, task-negative regions, striatum, and anterior cingulate cortex. We anticipate that the proposed method will prove useful to experimenters wishing to identify large-scale functional networks that distinguish between experimental conditions or groups.},
	journal = {NeuroImage},
	author = {McMenamin, Brenton W and Pessoa, Luiz},
	year = {2015},
}

@article{cocchi_dynamic_2013,
	title = {Dynamic cooperation and competition between brain systems during cognitive control},
	volume = {17},
	url = {http://dx.doi.org/10.1016/j.tics.2013.08.006},
	doi = {10.1016/j.tics.2013.08.006},
	abstract = {The human brain is characterized by a remarkable ability to adapt its information processing based on current goals. This ability, which is encompassed by the psychological construct of cognitive control, involves activity throughout large-scale, specialized brain systems that support segregated functions at rest and during active task performance. Based on recent research, we propose an account in which control functions rely on transitory changes in patterns of cooperation and competition between neural systems. This account challenges current conceptualizations of control as relying on segregated or antagonistic activity of specialized brain systems. Accordingly, we argue that the study of transitory task-based interactions between brain systems is critical to understanding the flexibility of normal cognitive control and its disruption in pathological conditions. \{\${\textbackslash}backslash\$textcopyright\} 2013 Elsevier Ltd.},
	number = {10},
	author = {Cocchi, Luca and Zalesky, Andrew and Fornito, Alex and Mattingley, Jason},
	year = {2013},
	file = {Attachment:/Users/tito/Zotero/storage/4FW4EIVB/Cocchi et al. - 2013 - Dynamic cooperation and competition between brain systems during cognitive control.pdf:application/pdf},
}

@article{song_spatial_2014,
	title = {Spatial embedding of structural similarity in the cerebral cortex},
	volume = {111},
	url = {http://dx.doi.org/10.1073/pnas.1414153111},
	doi = {10.1073/pnas.1414153111},
	number = {46},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Song, H Francis and Kennedy, Henry and Wang, Xiao-Jing},
	year = {2014},
	pages = {16580--16585},
	file = {Attachment:/Users/tito/Zotero/storage/AEBFPZCS/Song, Kennedy, Wang - 2014 - Spatial embedding of structural similarity in the cerebral cortex.pdf:application/pdf},
}

@article{cocchi_dissociable_2015,
	title = {Dissociable effects of local inhibitory and excitatory theta-burst stimulation on large-scale brain dynamics},
	volume = {113},
	url = {http://dx.doi.org/10.1152/jn.00850.2014},
	doi = {10.1152/jn.00850.2014},
	number = {9},
	journal = {Journal of Neurophysiology},
	author = {Cocchi, Luca and Sale, Martin V and Lord, Anton and Zalesky, Andrew and Breakspear, Michael and Mattingley, Jason B},
	year = {2015},
	pages = {3375--3385},
	file = {Attachment:/Users/tito/Zotero/storage/66KU5W24/Cocchi et al. - 2015 - Dissociable effects of local inhibitory and excitatory theta-burst stimulation on large-scale brain dynamics.pdf:application/pdf},
}

@article{rigotti_internal_2010,
	title = {Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses.},
	volume = {4},
	url = {http://dx.doi.org/10.3389/fncom.2010.00024},
	doi = {10.3389/fncom.2010.00024},
	abstract = {Neural activity of behaving animals, especially in the prefrontal cortex, is highly heterogeneous, with selective responses to diverse aspects of the executed task. We propose a general model of recurrent neural networks that perform complex rule-based tasks, and we show that the diversity of neuronal responses plays a fundamental role when the behavioral responses are context-dependent. Specifically, we found that when the inner mental states encoding the task rules are represented by stable patterns of neural activity (attractors of the neural dynamics), the neurons must be selective for combinations of sensory stimuli and inner mental states. Such mixed selectivity is easily obtained by neurons that connect with random synaptic strengths both to the recurrent network and to neurons encoding sensory inputs. The number of randomly connected neurons needed to solve a task is on average only three times as large as the number of neurons needed in a network designed ad hoc. Moreover, the number of needed neurons grows only linearly with the number of task-relevant events and mental states, provided that each neuron responds to a large proportion of events (dense/distributed coding). A biologically realistic implementation of the model captures several aspects of the activity recorded from monkeys performing context-dependent tasks. Our findings explain the importance of the diversity of neural responses and provide us with simple and general principles for designing attractor neural networks that perform complex computation.},
	author = {Rigotti, Mattia and Rubin, Daniel and Wang, Xiao-Jing and Fusi, Stefano},
	year = {2010},
	keywords = {computational modeling},
	file = {Attachment:/Users/tito/Zotero/storage/2M6YSW5R/Rigotti et al. - 2010 - Internal representation of task rules by recurrent dynamics the importance of the diversity of neural responses.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6KVHQJK3/Rigotti et al. - 2010 - Internal representation of task rules by recurrent dynamics the importance of the diversity of neural responses.pdf:application/pdf},
}

@article{marder_understanding_2015,
	title = {Understanding {Brains}: {Details}, {Intuition}, and {Big} {Data}},
	url = {http://dx.doi.org/10.1371/journal.pbio.1002147},
	doi = {10.1371/journal.pbio.1002147},
	abstract = {Understanding how the brain works requires a delicate balance between the appreciation of the importance of a multitude of biological details and the ability to see beyond those details to general principles. As technological innovations vastly increase the amount of data we collect, the importance of intuition into how to analyze and treat these data may, paradoxically, become more important.},
	journal = {\{PLOS\} Biology},
	author = {Marder, Eve},
	year = {2015},
	file = {Attachment:/Users/tito/Zotero/storage/XLSGYB9C/Marder - 2015 - Understanding Brains Details, Intuition, and Big Data.pdf:application/pdf},
}

@article{barnett_granger_2015,
	title = {Granger causality for state-space models},
	volume = {91},
	url = {http://dx.doi.org/10.1103/PhysRevE.91.040101},
	doi = {10.1103/PhysRevE.91.040101},
	number = {4},
	journal = {Physical Review E},
	author = {Barnett, Lionel and Seth, Anil K},
	year = {2015},
	file = {Attachment:/Users/tito/Zotero/storage/7BE3SBYK/Barnett, Seth - 2015 - Granger causality for state-space models.pdf:application/pdf},
}

@article{sporns_human_2005,
	title = {The human connectome: a structural description of the human brain},
	url = {http://dx.doi.org/10.1371/journal.pcbi.0010042},
	doi = {10.1371/journal.pcbi.0010042},
	author = {Sporns, O and Tononi, G and K"otter, R},
	year = {2005},
	file = {Attachment:/Users/tito/Zotero/storage/6QL8KHIK/Sporns, Tononi, Kotter - 2005 - The human connectome a structural description of the human brain.pdf:application/pdf},
}

@article{tononi_complexity_1998,
	title = {Complexity and coherency: integrating information in the brain},
	author = {Tononi, G and Edelman, G M and Sporns, O},
	year = {1998},
	file = {Attachment:/Users/tito/Zotero/storage/XELCCXKA/Tononi, Edelman, Sporns - 1998 - Complexity and coherency integrating information in the brain(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/U43I9NWE/Tononi, Edelman, Sporns - 1998 - Complexity and coherency integrating information in the brain.pdf:application/pdf},
}

@article{sheth_human_2012,
	title = {Human dorsal anterior cingulate cortex neurons mediate ongoing behavioural adaptation.},
	volume = {488},
	url = {http://dx.doi.org/10.1038/nature11239},
	doi = {10.1038/nature11239},
	abstract = {The ability to optimize behavioural performance when confronted with continuously evolving environmental demands is a key element of human cognition. The dorsal anterior cingulate cortex \{(dACC),\} which lies on the medial surface of the frontal lobes, is important in regulating cognitive control. Hypotheses about its function include guiding reward-based decision making, monitoring for conflict between competing responses and predicting task difficulty. Precise mechanisms of \{dACC\} function remain unknown, however, because of the limited number of human neurophysiological studies. Here we use functional imaging and human single-neuron recordings to show that the firing of individual \{dACC\} neurons encodes current and recent cognitive load. We demonstrate that the modulation of current \{dACC\} activity by previous activity produces a behavioural adaptation that accelerates reactions to cues of similar difficulty to previous ones, and retards reactions to cues of different difficulty. Furthermore, this conflict adaptation, or Gratton effect, is abolished after surgically targeted ablation of the \{dACC.\} Our results demonstrate that the \{dACC\} provides a continuously updated prediction of expected cognitive demand to optimize future behavioural responses. In situations with stable cognitive demands, this signal promotes efficiency by hastening responses, but in situations with changing demands it engenders accuracy by delaying responses.},
	number = {7410},
	journal = {Nature},
	author = {Sheth, Sameer A and Mian, Matthew K and Patel, Shaun R and Asaad, Wael F and Williams, Ziv M and Dougherty, Darin D and Bush, George and Eskandar, Emad N},
	year = {2012},
	pages = {218--221},
	file = {Attachment:/Users/tito/Zotero/storage/VJF4UJGC/Sheth et al. - 2012 - Human dorsal anterior cingulate cortex neurons mediate ongoing behavioural adaptation.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/GNFB5Q64/Sheth et al. - 2012 - Human dorsal anterior cingulate cortex neurons mediate ongoing behavioural adaptation(2).pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/FA8P3X4W/Sheth et al. - 2012 - Human dorsal anterior cingulate cortex neurons mediate ongoing behavioural adaptation.pdf:application/pdf},
}

@article{zalesky_network-based_2010,
	title = {Network-based statistic: {Identifying} differences in brain networks},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2010.06.041},
	doi = {10.1016/j.neuroimage.2010.06.041},
	abstract = {Large-scale functional or structural brain connectivity can be modeled as a network, or graph. This paper presents a statistical approach to identify connections in such a graph that may be associated with a diagnostic status in case-control studies, changing psychological contexts in task-based studies, or correlations with various cognitive and behavioral measures. The new approach, called the network-based statistic \{(NBS),\} is a method to control the family-wise error rate (in the weak sense) when mass-univariate testing is performed at every connection comprising the graph. To potentially offer a substantial gain in power, the \{NBS\} exploits the extent to which the connections comprising the contrast or effect of interest are interconnected. The \{NBS\} is based on the principles underpinning traditional cluster-based thresholding of statistical parametric maps. The purpose of this paper is to: (i) introduce the \{NBS\} for the first time; (ii) evaluate its power with the use of receiver operating characteristic \{(ROC)\} curves; and, (iii) demonstrate its utility with application to a real case-control study involving a group of people with schizophrenia for which resting-state functional \{MRI\} data were acquired. The \{NBS\} identified a expansive dysconnected subnetwork in the group with schizophrenia, primarily comprising fronto-temporal and occipito-temporal dysconnections, whereas a mass-univariate analysis controlled with the false discovery rate failed to identify a subnetwork.},
	journal = {NeuroImage},
	author = {Zalesky, Andrew and Fornito, Alex and Bullmore, Edward T},
	year = {2010},
	file = {Attachment:/Users/tito/Zotero/storage/J8IL5HWT/Zalesky, Fornito, Bullmore - 2010 - Network-based statistic Identifying differences in brain networks.pdf:application/pdf},
}

@article{oosterhof_comparison_2011,
	title = {A comparison of volume-based and surface-based multi-voxel pattern analysis.},
	volume = {56},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2010.04.270},
	doi = {10.1016/j.neuroimage.2010.04.270},
	abstract = {For functional magnetic resonance imaging \{(fMRI),\} multi-voxel pattern analysis \{(MVPA)\} has been shown to be a sensitive method to detect areas that encode certain stimulus dimensions. By moving a searchlight through the volume of the brain, one can continuously map the information content about the experimental conditions of interest to the brain. Traditionally, the searchlight is defined as a volume sphere that does not take into account the anatomy of the cortical surface. Here we present a method that uses a cortical surface reconstruction to guide voxel selection for information mapping. This approach differs in two important aspects from a volume-based searchlight definition. First, it uses only voxels that are classified as grey matter based on an anatomical scan. Second, it uses a surface-based geodesic distance metric to define neighbourhoods of voxels, and does not select voxels across a sulcus. We study here the influence of these two factors onto classification accuracy and onto the spatial specificity of the resulting information map. In our example data set, participants pressed one of four fingers while undergoing \{fMRI.\} We used \{MVPA\} to identify regions in which local \{fMRI\} patterns can successfully discriminate which finger was moved. We show that surface-based information mapping is a more sensitive measure of local information content, and provides better spatial selectivity. This makes surface-based information mapping a useful technique for a data-driven analysis of information representation in the cerebral cortex.},
	number = {2},
	journal = {NeuroImage},
	author = {Oosterhof, Nikolaas N and Wiestler, Tobias and Downing, Paul E and Diedrichsen, J"orn},
	year = {2011},
	pages = {593--600},
	file = {Attachment:/Users/tito/Zotero/storage/D6UD2LXS/Oosterhof et al. - 2011 - A comparison of volume-based and surface-based multi-voxel pattern analysis.pdf:application/pdf},
}

@article{zalesky_connectivity_2012,
	title = {Connectivity differences in brain networks.},
	volume = {60},
	issn = {1095-9572},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912000857},
	doi = {10.1016/j.neuroimage.2012.01.068},
	abstract = {The scenario considered here is one where brain connectivity is represented as a network and an experimenter wishes to assess the evidence for an experimental effect at each of the typically thousands of connections comprising the network. To do this, a univariate model is independently fitted to each connection. It would be unwise to declare significance based on an uncorrected threshold of α=0.05, since the expected number of false positives for a network comprising N=90 nodes and N(N-1)/2=4005 connections would be 200. Control of Type I errors over all connections is therefore necessary. The network-based statistic (NBS) and spatial pairwise clustering (SPC) are two distinct methods that have been used to control family-wise errors when assessing the evidence for an experimental effect with mass univariate testing. The basic principle of the NBS and SPC is the same as supra-threshold voxel clustering. Unlike voxel clustering, where the definition of a voxel cluster is unambiguous, 'clusters' formed among supra-threshold connections can be defined in different ways. The NBS defines clusters using the graph theoretical concept of connected components. SPC on the other hand uses a more stringent pairwise clustering concept. The purpose of this article is to compare the pros and cons of the NBS and SPC, provide some guidelines on their practical use and demonstrate their utility using a case study involving neuroimaging data.},
	number = {2},
	journal = {NeuroImage},
	author = {Zalesky, Andrew and Cocchi, Luca and Fornito, Alex and Murray, Micah M and Bullmore, Ed},
	month = apr,
	year = {2012},
	pmid = {22273567},
	keywords = {Brain, Brain Mapping, Humans, Nerve Net, Brain: physiology, Nerve Net: physiology, Brain: anatomy \& histology, Nerve Net: anatomy \& histology, Modality Control},
	pages = {1055--62},
	file = {Attachment:/Users/tito/Zotero/storage/MB687JCN/Zalesky et al. - 2012 - Connectivity differences in brain networks.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/UB4QUKE9/Zalesky et al. - 2012 - Connectivity differences in brain networks.pdf:application/pdf},
}

@article{rougier_prefrontal_2005,
	title = {Prefrontal cortex and flexible cognitive control: {Rules} without symbols},
	volume = {102},
	issn = {0027-8424},
	url = {http://www.pnas.org/content/102/20/7338.full},
	doi = {10.1073/pnas.0502455102},
	abstract = {Human cognitive control is uniquely flexible and has been shown to depend on prefrontal cortex (PFC). But exactly how the biological mechanisms of the PFC support flexible cognitive control remains a profound mystery. Existing theoretical models have posited powerful task-specific PFC representations, but not how these develop. We show how this can occur when a set of PFC-specific neural mechanisms interact with breadth of experience to self organize abstract rule-like PFC representations that support flexible generalization in novel tasks. The same model is shown to apply to benchmark PFC tasks (Stroop and Wisconsin card sorting), accurately simulating the behavior of neurologically intact and frontally damaged people.},
	number = {20},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Rougier, N. P. and Noelle, D. C. and Braver, T. S. and Cohen, J. D. and O'Reilly, R. C.},
	month = may,
	year = {2005},
	keywords = {computational modeling},
	pages = {7338--7343},
	file = {Attachment:/Users/tito/Zotero/storage/2K9R5YC5/Rougier et al. - 2005 - Prefrontal cortex and flexible cognitive control Rules without symbols.pdf:application/pdf},
}

@article{cole_behavioral_2015,
	title = {The {Behavioral} {Relevance} of {Task} {Information} in {Human} {Prefrontal} {Cortex}.},
	issn = {1460-2199},
	url = {http://cercor.oxfordjournals.org/content/early/2015/04/13/cercor.bhv072},
	doi = {10.1093/cercor/bhv072},
	abstract = {Human lateral prefrontal cortex (LPFC) is thought to play a critical role in enabling cognitive flexibility, particularly when performing novel tasks. However, it remains to be established whether LPFC representation of task-relevant information in such situations actually contributes to successful performance. We utilized pattern classification analyses of functional MRI activity to identify novelty-sensitive brain regions as participants rapidly switched between performance of 64 complex tasks, 60 of which were novel. In three of these novelty-sensitive regions-located within distinct areas of left anterior LPFC-trial-evoked activity patterns discriminated correct from error trials. Further, these regions also contained information regarding the task-relevant decision rule, but only for successfully performed trials. This suggests that left anterior LPFC may be particularly important for representing task information that contributes to the cognitive flexibility needed to perform successfully in novel task situations.},
	journal = {Cerebral cortex (New York, N.Y. : 1991)},
	author = {Cole, Michael W and Ito, Takuya and Braver, Todd S},
	month = apr,
	year = {2015},
	pmid = {25870233},
	pages = {bhv072--},
	file = {Attachment:/Users/tito/Zotero/storage/IZACCWV8/Cole, Ito, Braver - 2015 - The Behavioral Relevance of Task Information in Human Prefrontal Cortex.pdf:application/pdf},
}

@article{cole_flexible_2007,
	title = {Flexible hubs: {Global} brain connectivity correlates of human intelligence},
	author = {Cole, Michael W and Yarkoni, Tal and Repovs, Grega and Braver, Todd S},
	year = {2007},
	pages = {23},
	file = {Attachment:/Users/tito/Zotero/storage/I6853R9N/Cole et al. - 2007 - Flexible hubs Global brain connectivity correlates of human intelligence.pdf:application/pdf},
}

@article{whitcher_working_2011,
	title = {Working with the {DICOM} and {NIfTI} {Data} {Standards} in {R}},
	volume = {44},
	issn = {15487660},
	url = {http://www.jstatsoft.org/v44/i06/paper},
	abstract = {Two packages, oro.dicom and oro.nifti, are provided for the interaction with and manipulation of medical imaging data that conform to the DICOM standard or ANALYZE/ NIfTI formats. DICOM data, from a single le or directory tree, may be uploaded into R using basic data structures: a data frame for the header information and a matrix for the image data. A list structure is used to organize multiple DICOM les. The S4 class framework is used to develop basic ANALYZE and NIfTI classes, where NIfTI extensions may be used to extend the xed-byte NIfTI header. One example of this, that has been implemented, is an XML-based audit trail" tracking the history of operations applied to a data set. The conversion from DICOM to ANALYZE/NIfTI is straightforward using the capabilities of both packages. The S4 classes have been developed to provide a userfriendly interface to the ANALYZE/NIfTI data formats; allowing easy data input, data output, image processing and visualization.},
	number = {6},
	journal = {Journal Of Statistical Software},
	author = {Whitcher, Brandon and Schmid, Volker J and Thornton, Andrew},
	year = {2011},
	keywords = {export, imaging, import, medical, visualization},
	pages = {1--29},
	file = {Attachment:/Users/tito/Zotero/storage/G6F63RNN/Whitcher, Schmid, Thornton - 2011 - Working with the DICOM and NIfTI Data Standards in R.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Q2F6AJVK/Whitcher, Schmid, Thornton - 2011 - Working with the DICOM and NIfTI Data Standards in R.pdf:application/pdf},
}

@article{allefeld_searchlight-based_2014,
	title = {Searchlight-based multi-voxel pattern analysis of {fMRI} by cross-validated {MANOVA}},
	volume = {89},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2013.11.043},
	abstract = {Multi-voxel pattern analysis (MVPA) is a fruitful and increasingly popular complement to traditional univariate methods of analyzing neuroimaging data. We propose to replace the standard 'decoding' approach to searchlight-based MVPA, measuring the performance of a classifier by its accuracy, with a method based on the multivariate form of the general linear model. Following the well-established methodology of multivariate analysis of variance (MANOVA), we define a measure that directly characterizes the structure of multi-voxel data, the pattern distinctness D. Our measure is related to standard multivariate statistics, but we apply cross-validation to obtain an unbiased estimate of its population value, independent of the amount of data or its partitioning into 'training' and 'test' sets. The estimate D{\textasciicircum} can therefore serve not only as a test statistic, but also as an interpretable measure of multivariate effect size. The pattern distinctness generalizes the Mahalanobis distance to an arbitrary number of classes, but also the case where there are no classes of trials because the design is described by parametric regressors. It is defined for arbitrary estimable contrasts, including main effects (pattern differences) and interactions (pattern changes). In this way, our approach makes the full analytical power of complex factorial designs known from univariate fMRI analyses available to MVPA studies. Moreover, we show how the results of a factorial analysis can be used to obtain a measure of pattern stability, the equivalent of 'cross-decoding'. ?? 2013 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Allefeld, Carsten and Haynes, John Dylan},
	year = {2014},
	pmid = {24296330},
	keywords = {FMRI, Decoding, Multi-voxel pattern analysis, General linear model, Multivariate, MANOVA},
	pages = {345--357},
	file = {Attachment:/Users/tito/Zotero/storage/VWKVQ45Z/Allefeld, Haynes - 2014 - Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/5TI2IQAY/Allefeld, Haynes - 2014 - Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA.pdf:application/pdf},
}

@article{ritter_virtual_2013,
	title = {The virtual brain integrates computational modeling and multimodal neuroimaging.},
	volume = {3},
	issn = {2158-0022},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3696923&tool=pmcentrez&rendertype=abstract},
	doi = {10.1089/brain.2012.0120},
	abstract = {Brain function is thought to emerge from the interactions among neuronal populations. Apart from traditional efforts to reproduce brain dynamics from the micro- to macroscopic scales, complementary approaches develop phenomenological models of lower complexity. Such macroscopic models typically generate only a few selected-ideally functionally relevant-aspects of the brain dynamics. Importantly, they often allow an understanding of the underlying mechanisms beyond computational reproduction. Adding detail to these models will widen their ability to reproduce a broader range of dynamic features of the brain. For instance, such models allow for the exploration of consequences of focal and distributed pathological changes in the system, enabling us to identify and develop approaches to counteract those unfavorable processes. Toward this end, The Virtual Brain (TVB) ( www.thevirtualbrain.org ), a neuroinformatics platform with a brain simulator that incorporates a range of neuronal models and dynamics at its core, has been developed. This integrated framework allows the model-based simulation, analysis, and inference of neurophysiological mechanisms over several brain scales that underlie the generation of macroscopic neuroimaging signals. In this article, we describe how TVB works, and we present the first proof of concept.},
	number = {2},
	journal = {Brain connectivity},
	author = {Ritter, Petra and Schirner, Michael and McIntosh, Anthony R and Jirsa, Viktor K},
	year = {2013},
	pmid = {23442172},
	keywords = {Brain, Humans, Magnetic Resonance Imaging, Models, Neurological, Computer Simulation, Computer-Assisted, Image Processing, Brain: physiology, Stochastic Processes, Electroencephalography, Brain: blood supply, Time Factors, Nonlinear Dynamics, User-Computer Interface},
	pages = {121--45},
	file = {Attachment:/Users/tito/Zotero/storage/9XYR66DV/Ritter et al. - 2013 - The virtual brain integrates computational modeling and multimodal neuroimaging.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/QMY3X8FW/Ritter et al. - 2013 - The virtual brain integrates computational modeling and multimodal neuroimaging.pdf:application/pdf},
}

@article{wig_parcellating_2014,
	title = {Parcellating an individual subject's cortical and subcortical brain structures using snowball sampling of resting-state correlations},
	volume = {24},
	issn = {14602199},
	doi = {10.1093/cercor/bht056},
	abstract = {We describe methods for parcellating an individual subject's cortical and subcortical brain structures using resting-state functional correlations (RSFCs). Inspired by approaches from social network analysis, we first describe the application of snowball sampling on RSFC data (RSFC-Snowballing) to identify the centers of cortical areas, subdivisions of subcortical nuclei, and the cerebellum. RSFC-Snowballing parcellation is then compared with parcellation derived from identifying locations where RSFC maps exhibit abrupt transitions (RSFC-Boundary Mapping). RSFC-Snowballing and RSFC-Boundary Mapping largely complement one another, but also provide unique parcellation information; together, the methods identify independent entities with distinct functional correlations across many cortical and subcortical locations in the brain. RSFC parcellation is relatively reliable within a subject scanned across multiple days, and while the locations of many area centers and boundaries appear to exhibit considerable overlap across subjects, there is also cross-subject variability-reinforcing the motivation to parcellate brains at the level of individuals. Finally, examination of a large meta-analysis of task-evoked functional magnetic resonance imaging data reveals that area centers defined by task-evoked activity exhibit correspondence with area centers defined by RSFC-Snowballing. This observation provides important evidence for the ability of RSFC to parcellate broad expanses of an individual's brain into functionally meaningful units.},
	number = {8},
	journal = {Cerebral Cortex},
	author = {Wig, Gagan S. and Laumann, Timothy O. and Cohen, Alexander L. and Power, Jonathan D. and Nelson, Steven M. and Glasser, Matthew F. and Miezin, Francis M. and Snyder, Abraham Z. and Schlaggar, Bradley L. and Petersen, Steven E.},
	year = {2014},
	pmid = {23476025},
	keywords = {Brain networks, Individual differences, Boundary mapping, Brain area parcellation, Resting-state functional correlations, Snowball sampling},
	pages = {2036--2054},
	file = {Attachment:/Users/tito/Zotero/storage/8DMKZZZ5/Wig et al. - 2014 - Parcellating an individual subject's cortical and subcortical brain structures using snowball sampling of resting-st.pdf:application/pdf},
}

@article{rubinov_complex_2010,
	title = {Complex network measures of brain connectivity: {Uses} and interpretations},
	volume = {52},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2009.10.003},
	doi = {10.1016/j.neuroimage.2009.10.003},
	abstract = {Brain connectivity datasets comprise networks of brain regions connected by anatomical tracts or by functional associations. Complex network analysis-a new multidisciplinary approach to the study of complex systems-aims to characterize these brain networks with a small number of neurobiologically meaningful and easily computable measures. In this article, we discuss construction of brain networks from connectivity data and describe the most commonly used network measures of structural and functional connectivity. We describe measures that variously detect functional integration and segregation, quantify centrality of individual brain regions or pathways, characterize patterns of local anatomical circuitry, and test resilience of networks to insult. We discuss the issues surrounding comparison of structural and functional network connectivity, as well as comparison of networks across subjects. Finally, we describe a Matlab toolbox (http://www.brain-connectivity-toolbox.net) accompanying this article and containing a collection of complex network measures and large-scale neuroanatomical connectivity datasets. ?? 2009 Elsevier Inc.},
	number = {3},
	journal = {NeuroImage},
	author = {Rubinov, Mikail and Sporns, Olaf},
	year = {2010},
	pmid = {19819337},
	pages = {1059--1069},
	file = {Attachment:/Users/tito/Zotero/storage/M8VHDL9D/Rubinov, Sporns - 2010 - Complex network measures of brain connectivity Uses and interpretations.pdf:application/pdf},
}

@article{cole_identifying_2010,
	title = {Identifying the brain's most globally connected regions},
	volume = {49},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2009.11.001},
	doi = {10.1016/j.neuroimage.2009.11.001},
	abstract = {Recent advances in brain connectivity methods have made it possible to identify hubs-the brain's most globally connected regions. Such regions are essential for coordinating brain functions due to their connectivity with numerous regions with a variety of specializations. Current structural and functional connectivity methods generally agree that default mode network (DMN) regions have among the highest global brain connectivity (GBC). We developed two novel statistical approaches using resting state functional connectivity MRI-weighted and unweighted GBC (wGBC and uGBC)-to test the hypothesis that the highest global connectivity also occurs in the cognitive control network (CCN), a network anti-correlated with the DMN across a variety of tasks. High global connectivity was found in both CCN and DMN. The newly developed wGBC approach improves upon existing methods by quantifying inter-subject consistency, quantifying the highest GBC values by percentage, and avoiding arbitrarily connection strength thresholding. The uGBC approach is based on graph theory and includes many of these improvements, but still requires an arbitrary connection threshold. We found high GBC in several subcortical regions (e.g., hippocampus, basal ganglia) only with wGBC despite the regions' extensive anatomical connectivity. These results demonstrate the complementary utility of wGBC and uGBC analyses for the characterization of the most highly connected, and thus most functionally important, regions of the brain. Additionally, the high connectivity of both the CCN and the DMN demonstrates that brain regions outside primary sensory-motor networks are highly involved in coordinating information throughout the brain. © 2009 Elsevier Inc. All rights reserved.},
	number = {4},
	journal = {NeuroImage},
	author = {Cole, Michael W. and Pathak, Sudhir and Schneider, Walter},
	year = {2010},
	pmid = {19909818},
	pages = {3132--3148},
	file = {Attachment:/Users/tito/Zotero/storage/R97VHMZA/Cole, Pathak, Schneider - 2010 - Identifying the brain's most globally connected regions.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/RSL7PUTR/Cole, Pathak, Schneider - 2010 - Identifying the brain's most globally connected regions.pdf:application/pdf},
}

@article{tang_deep_2013,
	title = {Deep {Learning} using {Linear} {Support} {Vector} {Machines}},
	url = {http://deeplearning.net/wp-content/uploads/2013/03/dlsvm.pdf},
	abstract = {Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide vari-ety of tasks such as speech recognition, im-age classification, natural language process-ing, and bioinformatics. For classification tasks, most of these “deep learning” models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the soft-max layer with a linear support vector ma-chine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neu-ral nets and SVMs in prior art, our results using L2-SVMs show that by simply replac-ing softmax with linear SVMs gives signifi-cant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Rep-resentation LearningWorkshop's face expres-sion recognition challenge.},
	journal = {Deeplearning.Net},
	author = {Tang, Yichuan},
	year = {2013},
	file = {Attachment:/Users/tito/Zotero/storage/IBPHF4E4/Tang - 2013 - Deep Learning using Linear Support Vector Machines.pdf:application/pdf},
}

@article{dosenbach_distinct_2007,
	title = {Distinct brain networks for adaptive and stable task control in humans.},
	volume = {104},
	issn = {0027-8424},
	doi = {10.1073/pnas.0704320104},
	abstract = {Control regions in the brain are thought to provide signals that configure the brain's moment-to-moment information processing. Previously, we identified regions that carried signals related to task-control initiation, maintenance, and adjustment. Here we characterize the interactions of these regions by applying graph theory to resting state functional connectivity MRI data. In contrast to previous, more unitary models of control, this approach suggests the presence of two distinct task-control networks. A frontoparietal network included the dorsolateral prefrontal cortex and intraparietal sulcus. This network emphasized start-cue and error-related activity and may initiate and adapt control on a trial-by-trial basis. The second network included dorsal anterior cingulate/medial superior frontal cortex, anterior insula/frontal operculum, and anterior prefrontal cortex. Among other signals, these regions showed activity sustained across the entire task epoch, suggesting that this network may control goal-directed behavior through the stable maintenance of task sets. These two independent networks appear to operate on different time scales and affect downstream processing via dissociable mechanisms.},
	number = {26},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Dosenbach, Nico U F and Fair, Damien a and Miezin, Francis M and Cohen, Alexander L and Wenger, Kristin K and Dosenbach, Ronny a T and Fox, Michael D and Snyder, Abraham Z and Vincent, Justin L and Raichle, Marcus E and Schlaggar, Bradley L and Petersen, Steven E},
	year = {2007},
	pmid = {17576922},
	pages = {11073--11078},
	file = {Attachment:/Users/tito/Zotero/storage/E3IL8E69/Dosenbach et al. - 2007 - Distinct brain networks for adaptive and stable task control in humans.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Z8HZMSKX/Dosenbach et al. - 2007 - Distinct brain networks for adaptive and stable task control in humans.pdf:application/pdf},
}

@article{viswanathan_geometric_2012,
	title = {On the geometric structure of {fMRI} searchlight-based information maps},
	url = {http://arxiv.org/abs/1210.6317%5Cnpapers2://publication/uuid/935DD036-FF37-401B-AAEB-55932758E8EE},
	abstract = {Abstract: Information mapping is a popular application of Multivoxel Pattern Analysis (MVPA) to fMRI. Information maps are constructed using the so called searchlight method, where the spherical multivoxel neighborhood of every voxel (ie, a searchlight) in the brain is ... \${\textbackslash}backslash\$n},
	journal = {arXiv.org},
	author = {Viswanathan, Shivakumar and Cieslak, Matthew and Grafton, Scott T},
	year = {2012},
	keywords = {fmri, mvpa, pattern-classification, searchlight},
	file = {Attachment:/Users/tito/Zotero/storage/E3BLZ6R7/Viswanathan, Cieslak, Grafton - 2012 - On the geometric structure of fMRI searchlight-based information maps.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/C8KXVYDY/Viswanathan, Cieslak, Grafton - 2012 - On the geometric structure of fMRI searchlight-based information maps.pdf:application/pdf},
}

@article{raizada_pattern-information_2010,
	title = {Pattern-information {fMRI}: {New} questions which it opens up and challenges which face it},
	volume = {20},
	issn = {08999457},
	doi = {10.1002/ima.20225},
	abstract = {Recent years have seen a strong growth of interest in multivariate approaches for analysing brain activity patterns. The primary goal of these approaches is to reveal the information represented in neuronal population codes. Here, we review how these methods have been used to relate neural activity patterns both to stimulus input and to behavioural output and how they might help to explain individual differences in behavioural performance. We examine the neuroscientific interpretation of different types of pattern-information analysis and highlight current challenges and promising future directions for this emerging field. The open challenges that we discuss are as follows: inferring the causal role of pattern information, seeking diagnostic power for functional Magnetic Resonance Imaging (fMRI) at the level of individuals, determining whether observed patterns have real functional significance, finding the structure underlying high-dimensional activation spaces and relating one person's neural patterns to another's. (C) 2010 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 20, 31-41, 2010; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/ima.20225},
	number = {1},
	journal = {International Journal of Imaging Systems and Technology},
	author = {Raizada, Rajeev D S and Kriegeskorte, Nikolaus},
	year = {2010},
	keywords = {FMRI, Pattern-information},
	pages = {31--41},
	file = {Attachment:/Users/tito/Zotero/storage/XN93Z578/Raizada, Kriegeskorte - 2010 - Pattern-information fMRI New questions which it opens up and challenges which face it.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/HP6I894H/Raizada, Kriegeskorte - 2010 - Pattern-information fMRI New questions which it opens up and challenges which face it.pdf:application/pdf},
}

@article{bengio_deep_2011,
	title = {Deep {Learning} of {Representations} for {Unsupervised} and {Transfer} {Learning}},
	volume = {7},
	abstract = {Deep learning algorithms seek to exploit the unknown structure in the input distribution in order to discover good representations, often at multiple levels, with higher-level learned features defined in terms of lower-level features. The objective is to make these higher- level representations more abstract, with their individual features more invariant to most of the variations that are typically present in the training distribution, while collectively preserving as much as possible of the information in the input. Ideally, we would like these representations to disentangle the unknown factors of variation that underlie the training distribution. Such unsupervised learning of representations can be exploited usefully under the hypothesis that the input distribution P(x) is structurally related to some task of interest, say predicting P(y{\textbar}x). This paper focusses on why unsupervised pre-training of representations can be useful, and how it can be exploited in the transfer learning scenario, where we care about predictions on examples that are not from the same distribution as the training distribution},
	journal = {JMLR: Workshop and Conference Proceedings 7},
	author = {Bengio, Yoshua},
	year = {2011},
	keywords = {neural networks, unsupervised learning, deep learning, autoencoders, domain adaptation, ing, multi-task learning, re-, representation learning, self-taught learning, stricted boltzmann machines, transfer learn-},
	pages = {1--20},
	file = {Attachment:/Users/tito/Zotero/storage/DPZMBKYX/Bengio - 2011 - Deep Learning of Representations for Unsupervised and Transfer Learning.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6GNFZ47R/Bengio - 2011 - Deep Learning of Representations for Unsupervised and Transfer Learning.pdf:application/pdf},
}

@article{xue_greater_2010,
	title = {Greater neural pattern similarity across repetitions is associated with better memory.},
	volume = {330},
	issn = {0036-8075},
	doi = {10.1126/science.1193125},
	abstract = {Repeated study improves memory, but the underlying neural mechanisms of this improvement are not well understood. Using functional magnetic resonance imaging and representational similarity analysis of brain activity, we found that, compared with forgotten items, subsequently remembered faces and words showed greater similarity in neural activation across multiple study in many brain regions, including (but not limited to) the regions whose mean activities were correlated with subsequent memory. This result addresses a longstanding debate in the study of memory by showing that successful episodic memory encoding occurs when the same neural representations are more precisely reactivated across study episodes, rather than when patterns of activation are more variable across time.},
	number = {6000},
	journal = {Science (New York, N.Y.)},
	author = {Xue, Gui and Dong, Qi and Chen, Chuansheng and Lu, Zhonglin and Mumford, Jeanette a and Poldrack, Russell a},
	year = {2010},
	pmid = {20829453},
	pages = {97--101},
	file = {Attachment:/Users/tito/Zotero/storage/6ANHJ5AH/Xue et al. - 2010 - Greater neural pattern similarity across repetitions is associated with better memory.pdf:application/pdf},
}

@article{van_dijk_intrinsic_2010,
	title = {Intrinsic functional connectivity as a tool for human connectomics: theory, properties, and optimization.},
	volume = {103},
	issn = {0022-3077},
	doi = {10.1152/jn.00783.2009},
	abstract = {Resting state functional connectivity MRI (fcMRI) is widely used to investigate brain networks that exhibit correlated fluctuations. While fcMRI does not provide direct measurement of anatomic connectivity, accumulating evidence suggests it is sufficiently constrained by anatomy to allow the architecture of distinct brain systems to be characterized. fcMRI is particularly useful for characterizing large-scale systems that span distributed areas (e.g., polysynaptic cortical pathways, cerebro-cerebellar circuits, cortical-thalamic circuits) and has complementary strengths when contrasted with the other major tool available for human connectomics-high angular resolution diffusion imaging (HARDI). We review what is known about fcMRI and then explore fcMRI data reliability, effects of preprocessing, analysis procedures, and effects of different acquisition parameters across six studies (n = 98) to provide recommendations for optimization. Run length (2-12 min), run structure (1 12-min run or 2 6-min runs), temporal resolution (2.5 or 5.0 s), spatial resolution (2 or 3 mm), and the task (fixation, eyes closed rest, eyes open rest, continuous word-classification) were varied. Results revealed moderate to high test-retest reliability. Run structure, temporal resolution, and spatial resolution minimally influenced fcMRI results while fixation and eyes open rest yielded stronger correlations as contrasted to other task conditions. Commonly used preprocessing steps involving regression of nuisance signals minimized nonspecific (noise) correlations including those associated with respiration. The most surprising finding was that estimates of correlation strengths stabilized with acquisition times as brief as 5 min. The brevity and robustness of fcMRI positions it as a powerful tool for large-scale explorations of genetic influences on brain architecture. We conclude by discussing the strengths and limitations of fcMRI and how it can be combined with HARDI techniques to support the emerging field of human connectomics.},
	number = {1},
	journal = {Journal of neurophysiology},
	author = {Van Dijk, Koene R a and Hedden, Trey and Venkataraman, Archana and Evans, Karleyton C and Lazar, Sara W and Buckner, Randy L},
	year = {2010},
	pmid = {19889849},
	pages = {297--321},
	file = {Attachment:/Users/tito/Zotero/storage/DK6XUAHF/Van Dijk et al. - 2010 - Intrinsic functional connectivity as a tool for human connectomics theory, properties, and optimization.pdf:application/pdf},
}

@article{fair_method_2007,
	title = {A method for using blocked and event-related {fMRI} data to study "resting state" functional connectivity},
	volume = {35},
	issn = {10538119},
	doi = {10.1016/j.neuroimage.2006.11.051},
	abstract = {Resting state functional connectivity MRI (fcMRI) has become a particularly useful tool for studying regional relationships in typical and atypical populations. Because many investigators have already obtained large data sets of task-related fMRI, the ability to use this existing task data for resting state fcMRI is of considerable interest. Two classes of data sets could potentially be modified to emulate resting state data. These data sets include: (1) "interleaved" resting blocks from blocked or mixed blocked/event-related sets, and (2) residual timecourses from event-related sets that lack rest blocks. Using correlation analysis, we compared the functional connectivity of resting epochs taken from a mixed blocked/event-related design fMRI data set and the residuals derived from event-related data with standard continuous resting state data to determine which class of data can best emulate resting state data. We show that, despite some differences, the functional connectivity for the interleaved resting periods taken from blocked designs is both qualitatively and quantitatively very similar to that of "continuous" resting state data. In contrast, despite being qualitatively similar to "continuous" resting state data, residuals derived from event-related design data had several distinct quantitative differences. These results suggest that the interleaved resting state data such as those taken from blocked or mixed blocked/event-related fMRI designs are well-suited for resting state functional connectivity analyses. Although using event-related data residuals for resting state functional connectivity may still be useful, results should be interpreted with care. © 2006 Elsevier Inc. All rights reserved.},
	number = {1},
	journal = {NeuroImage},
	author = {Fair, Damien a. and Schlaggar, Bradley L. and Cohen, Alexander L. and Miezin, Francis M. and Dosenbach, Nico U F and Wenger, Kristin K. and Fox, Michael D. and Snyder, Abraham Z. and Raichle, Marcus E. and Petersen, Steven E.},
	year = {2007},
	pmid = {17239622},
	pages = {396--405},
	file = {Attachment:/Users/tito/Zotero/storage/IDX54IP5/Fair et al. - 2007 - A method for using blocked and event-related fMRI data to study resting state functional connectivity.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/LUWR9RXQ/Fair et al. - 2007 - A method for using blocked and event-related fMRI data to study resting state functional connectivity.pdf:application/pdf},
}

@article{sporns_small_2006,
	title = {Small worlds inside big brains.},
	volume = {103},
	issn = {0027-8424},
	doi = {10.1073/pnas.0609523103},
	abstract = {Existing functional brain MR imaging methods detect neuronal activity only indirectly via a surrogate signal such as deoxyhemoglobin concentration in the vascular bed of cerebral parenchyma. It has been recently proposed that neuronal currents may be measurable directly using MRI (ncMRI). However, limited success has been reported in neuronal current detection studies that used standard gradient or spin echo pulse sequences. The balanced steady-state free precession (bSSFP) pulse sequence is unique in that it can afford the highest known SNR efficiency and is exquisitely sensitive to perturbations in free precession phase. It is reported herein that when a spin phase-perturbing periodic current is locked to an RF pulse train, phase perturbations are accumulated across multiple RF excitations and the spin magnetization reaches an alternating balanced steady state (ABSS) that effectively amplifies the phase perturbations due to the current. The alternation of the ABSS signal therefore is highly sensitive to weak periodic currents. Current phantom experiments employing ABSS imaging resulted in detection of magnetic field variations as small as 0.15nT in scans lasting for 36 sec, which is more sensitive than using gradient-recalled echo imaging.},
	number = {51},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sporns, Olaf and Honey, Christopher J},
	year = {2006},
	pmid = {17159140},
	pages = {19219--19220},
	file = {Attachment:/Users/tito/Zotero/storage/GWZ7WU3Y/Sporns, Honey - 2006 - Small worlds inside big brains.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/HQGLYQB5/Sporns, Honey - 2006 - Small worlds inside big brains.pdf:application/pdf},
}

@article{kriegeskorte_representational_2008,
	title = {Representational similarity analysis - connecting the branches of systems neuroscience.},
	volume = {2},
	issn = {1662-5137},
	doi = {10.3389/neuro.06.004.2008},
	abstract = {A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
	number = {November},
	journal = {Frontiers in systems neuroscience},
	author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
	year = {2008},
	pmid = {19104670},
	keywords = {computational modeling, fmri, electrophysiology, population code, representation, similarity},
	pages = {4},
	file = {Attachment:/Users/tito/Zotero/storage/TCUMXZEB/Kriegeskorte, Mur, Bandettini - 2008 - Representational similarity analysis - connecting the branches of systems neuroscience.pdf:application/pdf},
}

@article{kragel_what_2012,
	title = {What makes a pattern? {Matching} decoding methods to data in multivariate pattern analysis},
	volume = {6},
	issn = {16624548},
	doi = {10.3389/fnins.2012.00162},
	abstract = {Research in neuroscience faces the challenge of integrating information across different spatial scales of brain function. A promising technique for harnessing information at a range of spatial scales is multivariate pattern analysis (MVPA) of functional magnetic resonance imaging (fMRI) data. While the prevalence of MVPA has increased dramatically in recent years, its typical implementations for classification of mental states utilize only a subset of the information encoded in local fMRI signals. We review published studies employing multivariate pattern classification since the technique's introduction, which reveal an extensive focus on the improved detection power that linear classifiers provide over traditional analysis techniques. We demonstrate using simulations and a searchlight approach, however, that non-linear classifiers are capable of extracting distinct information about interactions within a local region. We conclude that for spatially localized analyses, such as searchlight and region of interest, multiple classification approaches should be compared in order to match fMRI analyses to the properties of local circuits.},
	number = {NOV},
	journal = {Frontiers in Neuroscience},
	author = {Kragel, Philip A. and Carter, R. McKell and Huettel, Scott A.},
	year = {2012},
	pmid = {23189035},
	keywords = {fMRI, Classification, MVPA, Linear, Non-linear},
	pages = {1--9},
	file = {Attachment:/Users/tito/Zotero/storage/3SM2CKFB/Kragel, Carter, Huettel - 2012 - What makes a pattern Matching decoding methods to data in multivariate pattern analysis.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/TQQRXYC9/Kragel, Carter, Huettel - 2012 - What makes a pattern Matching decoding methods to data in multivariate pattern analysis.pdf:application/pdf},
}

@article{stelzer_statistical_2013,
	title = {Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis ({MVPA}): {Random} permutations and cluster size control},
	volume = {65},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2012.09.063},
	doi = {10.1016/j.neuroimage.2012.09.063},
	abstract = {An ever-increasing number of functional magnetic resonance imaging (fMRI) studies are now using information-based multi-voxel pattern analysis (MVPA) techniques to decode mental states. In doing so, they achieve a significantly greater sensitivity compared to when they use univariate frameworks. However, the new brain-decoding methods have also posed new challenges for analysis and statistical inference on the group level. We discuss why the usual procedure of performing t-tests on accuracy maps across subjects in order to produce a group statistic is inappropriate. We propose a solution to this problem for local MVPA approaches, which achieves higher sensitivity than other procedures. Our method uses random permutation tests on the single-subject level, and then combines the results on the group level with a bootstrap method. To preserve the spatial dependency induced by local MVPA methods, we generate a random permutation set and keep it fixed across all locations. This enables us to later apply a cluster size control for the multiple testing problem. More specifically, we explicitly compute the distribution of cluster sizes and use this to determine the p-values for each cluster. Using a volumetric searchlight decoding procedure, we demonstrate the validity and sensitivity of our approach using both simulated and real fMRI data sets. In comparison to the standard t-test procedure implemented in SPM8, our results showed a higher sensitivity. We discuss the theoretical applicability and the practical advantages of our approach, and outline its generalization to other local MVPA methods, such as surface decoding techniques. ?? 2012 Elsevier Inc.},
	journal = {NeuroImage},
	author = {Stelzer, Johannes and Chen, Yi and Turner, Robert},
	year = {2013},
	pmid = {23041526},
	keywords = {FMRI, MVPA, Cluster size control, Multiple testing, Second level analysis, Statistics},
	pages = {69--82},
	file = {Attachment:/Users/tito/Zotero/storage/TW6T6S53/Stelzer, Chen, Turner - 2013 - Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysi.pdf:application/pdf},
}

@article{oreilly_tools_2012,
	title = {Tools of the trade: {Psychophysiological} interactions and functional connectivity},
	volume = {7},
	issn = {17495016},
	doi = {10.1093/scan/nss055},
	abstract = {Psychophysiological interactions (PPIs) analysis is a method for investigating task-specific changes in the relationship between activity in different brain areas, using functional magnetic resonance imaging (fMRI) data. Specifically, PPI analyses identify voxels in which activity is more related to activity in a seed region of interest (seed ROI) in a given psychological context, such as during attention or in the presence of emotive stimuli. In this tutorial, we aim to give a simple conceptual explanation of how PPI analysis works, in order to assist readers in planning and interpreting their own PPI experiments.},
	number = {5},
	journal = {Social Cognitive and Affective Neuroscience},
	author = {O'Reilly, Jill X. and Woolrich, Mark W. and Behrens, Timothy E J and Smith, Stephen M. and Johansen-Berg, Heidi},
	year = {2012},
	pmid = {22569188},
	keywords = {Functional connectivity, Resting state, PPI, Psychophysiological interactions},
	pages = {604--609},
	file = {Attachment:/Users/tito/Zotero/storage/PYWMYDIE/O'Reilly et al. - 2012 - Tools of the trade Psychophysiological interactions and functional connectivity.pdf:application/pdf},
}

@article{fair_maturing_2008,
	title = {The maturing architecture of the brain's default network.},
	volume = {105},
	issn = {0027-8424},
	doi = {10.1073/pnas.0800376105},
	abstract = {In recent years, the brain's "default network," a set of regions characterized by decreased neural activity during goal-oriented tasks, has generated a significant amount of interest, as well as controversy. Much of the discussion has focused on the relationship of these regions to a "default mode" of brain function. In early studies, investigators suggested that, the brain's default mode supports "self-referential" or "introspective" mental activity. Subsequently, regions of the default network have been more specifically related to the "internal narrative," the "autobiographical self," "stimulus independent thought," "mentalizing," and most recently "self-projection." However, the extant literature on the function of the default network is limited to adults, i.e., after the system has reached maturity. We hypothesized that further insight into the network's functioning could be achieved by characterizing its development. In the current study, we used resting-state functional connectivity MRI (rs-fcMRI) to characterize the development of the brain's default network. We found that the default regions are only sparsely functionally connected at early school age (7-9 years old); over development, these regions integrate into a cohesive, interconnected network.},
	number = {10},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fair, Damien a and Cohen, Alexander L and Dosenbach, Nico U F and Church, Jessica a and Miezin, Francis M and Barch, Deanna M and Raichle, Marcus E and Petersen, Steven E and Schlaggar, Bradley L},
	year = {2008},
	pmid = {18322013},
	pages = {4028--4032},
	file = {Attachment:/Users/tito/Zotero/storage/32AMVWBN/Fair et al. - 2008 - The maturing architecture of the brain's default network.pdf:application/pdf},
}

@article{savoy_functional_2001,
	title = {Functional {Magnetic} {Resonance} {Imaging} ( {fMRI} ) resonance imaging ( {MRI} ) to detect the localized changes in blood flow and blood oxygenation that},
	journal = {Changes},
	author = {Savoy, Robert L and Ph, D},
	year = {2001},
	pages = {1--21},
	file = {Attachment:/Users/tito/Zotero/storage/T79LYRZG/Savoy, Ph - 2001 - Functional Magnetic Resonance Imaging ( fMRI ) resonance imaging ( MRI ) to detect the localized changes in blood flo.pdf:application/pdf},
}

@article{power_functional_2011,
	title = {Functional {Network} {Organization} of the {Human} {Brain}},
	volume = {72},
	issn = {08966273},
	url = {http://dx.doi.org/10.1016/j.neuron.2011.09.006},
	doi = {10.1016/j.neuron.2011.09.006},
	abstract = {Real-world complex systems may be mathematically modeled as graphs, revealing properties of the system. Here we study graphs of functional brain organization in healthy adults using resting state functional connectivity MRI. We propose two novel brain-wide graphs, one of 264 putative functional areas, the other a modification of voxelwise networks that eliminates potentially artificial short-distance relationships. These graphs contain many subgraphs in good agreement with known functional brain systems. Other subgraphs lack established functional identities; we suggest possible functional characteristics for these subgraphs. Further, graph measures of the areal network indicate that the default mode subgraph shares network properties with sensory and motor subgraphs: it is internally integrated but isolated from other subgraphs, much like a " processing" system. The modified voxelwise graph also reveals spatial motifs in the patterning of systems across the cortex. ?? 2011 Elsevier Inc.},
	number = {4},
	journal = {Neuron},
	author = {Power, Jonathan D. and Cohen, Alexander L. and Nelson, Steven M. and Wig, Gagan S. and Barnes, Kelly Anne and Church, Jessica a. and Vogel, Alecia C. and Laumann, Timothy O. and Miezin, Fran M. and Schlaggar, Bradley L. and Petersen, Steven E.},
	year = {2011},
	pmid = {22099467},
	pages = {665--678},
	file = {Attachment:/Users/tito/Zotero/storage/I3KBKVWW/Power et al. - 2011 - Functional Network Organization of the Human Brain.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/24YJZY3C/Power et al. - 2011 - Functional Network Organization of the Human Brain.pdf:application/pdf},
}

@article{deco_resting_2013,
	title = {Resting brains never rest: {Computational} insights into potential cognitive architectures},
	volume = {36},
	issn = {01662236},
	url = {http://dx.doi.org/10.1016/j.tins.2013.03.001},
	doi = {10.1016/j.tins.2013.03.001},
	abstract = {Resting-state networks (RSNs), which have become a main focus in neuroimaging research, can be best simulated by large-scale cortical models in which networks teeter on the edge of instability. In this state, the functional networks are in a low firing stable state while they are continuously pulled towards multiple other configurations. Small extrinsic perturbations can shape task-related network dynamics, whereas perturbations from intrinsic noise generate excursions reflecting the range of available functional networks. This is particularly advantageous for the efficiency and speed of network mobilization. Thus, the resting state reflects the dynamical capabilities of the brain, which emphasizes the vital interplay of time and space. In this article, we propose a new theoretical framework for RSNs that can serve as a fertile ground for empirical testing. ?? 2013 Elsevier Ltd.},
	number = {5},
	journal = {Trends in Neurosciences},
	author = {Deco, Gustavo and Jirsa, Viktor K. and McIntosh, Anthony R.},
	year = {2013},
	pmid = {23561718},
	pages = {268--274},
	file = {Attachment:/Users/tito/Zotero/storage/RKGCFBVW/Deco, Jirsa, McIntosh - 2013 - Resting brains never rest Computational insights into potential cognitive architectures.pdf:application/pdf},
}

@article{dosenbach_core_2006,
	title = {A {Core} {System} for the {Implementation} of {Task} {Sets}},
	volume = {50},
	issn = {08966273},
	doi = {10.1016/j.neuron.2006.04.031},
	abstract = {When performing tasks, humans are thought to adopt task sets that configure moment-to-moment data processing. Recently developed mixed blocked/event-related designs allow task set-related signals to be extracted in fMRI experiments, including activity related to cues that signal the beginning of a task block, "set-maintenance" activity sustained for the duration of a task block, and event-related signals for different trial types. Data were conjointly analyzed from mixed design experiments using ten different tasks and 183 subjects. Dorsal anterior cingulate cortex/medial superior frontal cortex (dACC/msFC) and bilateral anterior insula/frontal operculum (aI/fO) showed reliable start-cue and sustained activations across all or nearly all tasks. These regions also carried the most reliable error-related signals in a subset of tasks, suggesting that the regions form a "core" task-set system. Prefrontal regions commonly related to task control carried task-set signals in a smaller subset of tasks and lacked convergence across signal types. © 2006 Elsevier Inc. All rights reserved.},
	number = {5},
	journal = {Neuron},
	author = {Dosenbach, Nico U F and Visscher, Kristina M. and Palmer, Erica D. and Miezin, Francis M. and Wenger, Kristin K. and Kang, Hyunseon C. and Burgund, E. Darcy and Grimes, Ansley L. and Schlaggar, Bradley L. and Petersen, Steven E.},
	year = {2006},
	pmid = {16731517},
	keywords = {SYSNEURO},
	pages = {799--812},
	file = {Attachment:/Users/tito/Zotero/storage/QFBL6GFA/Dosenbach et al. - 2006 - A Core System for the Implementation of Task Sets.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/HI74KNS2/Dosenbach et al. - 2006 - A Core System for the Implementation of Task Sets.pdf:application/pdf},
}

@article{bengio_learning_2009,
	title = {Learning {Deep} {Architectures} for {AI}},
	volume = {2},
	issn = {1935-8237},
	doi = {10.1561/2200000006},
	abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.},
	number = {1},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Bengio, Yoshua},
	year = {2009},
	pmid = {17348934},
	pages = {1--127},
	file = {Attachment:/Users/tito/Zotero/storage/6YUL2WHW/Bengio - 2009 - Learning Deep Architectures for AI.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/Y9QJU3MJ/Bengio - 2009 - Learning Deep Architectures for AI.pdf:application/pdf},
}

@article{harmelech_day-after_2013,
	title = {The {Day}-{After} {Effect}: {Long} {Term}, {Hebbian}-{Like} {Restructuring} of {Resting}-{State} {fMRI} {Patterns} {Induced} by a {Single} {Epoch} of {Cortical} {Activation}},
	volume = {33},
	issn = {0270-6474},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5911-12.2013},
	doi = {10.1523/JNEUROSCI.5911-12.2013},
	number = {22},
	journal = {Journal of Neuroscience},
	author = {Harmelech, T. and Preminger, S. and Wertman, E. and Malach, R.},
	year = {2013},
	pages = {9488--9497},
	file = {Attachment:/Users/tito/Zotero/storage/BXQW8GHD/Harmelech et al. - 2013 - The Day-After Effect Long Term, Hebbian-Like Restructuring of Resting-State fMRI Patterns Induced by a Single.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/FNKZCLXH/Harmelech et al. - 2013 - The Day-After Effect Long Term, Hebbian-Like Restructuring of Resting-State fMRI Patterns Induced by a Single.pdf:application/pdf},
}

@article{gordon_generation_2014,
	title = {Generation and {Evaluation} of a {Cortical} {Area} {Parcellation} from {Resting}-{State} {Correlations}},
	issn = {1047-3211},
	doi = {10.1093/cercor/bhu239},
	journal = {Cerebral Cortex},
	author = {Gordon, E. M. and Laumann, T. O. and Adeyemo, B. and Huckins, J. F. and Kelley, W. M. and Petersen, S. E.},
	year = {2014},
	keywords = {functional connectivity, resting state, parcellation, cortical areas},
	file = {Attachment:/Users/tito/Zotero/storage/VHXZT9LI/Gordon et al. - 2014 - Generation and Evaluation of a Cortical Area Parcellation from Resting-State Correlations.pdf:application/pdf},
}

@article{zalesky_use_2012,
	title = {On the use of correlation as a measure of network connectivity},
	volume = {60},
	issn = {10538119},
	url = {http://dx.doi.org/10.1016/j.neuroimage.2012.02.001},
	doi = {10.1016/j.neuroimage.2012.02.001},
	abstract = {Numerous studies have demonstrated that brain networks derived from neuroimaging data have nontrivial topological features, such as small-world organization, modular structure and highly connected hubs. In these studies, the extent of connectivity between pairs of brain regions has often been measured using some form of statistical correlation. This article demonstrates that correlation as a measure of connectivity in and of itself gives rise to networks with non-random topological features. In particular, networks in which connectivity is measured using correlation are inherently more clustered than random networks, and as such are more likely to be small-world networks. Partial correlation as a measure of connectivity also gives rise to networks with non-random topological features. Partial correlation networks are inherently less clustered than random networks. Network measures in correlation networks should be benchmarked against null networks that respect the topological structure induced by correlation measurements. Prevalently used random rewiring algorithms do not yield appropriate null networks for some network measures. Null networks are proposed to explicitly normalize for the inherent topological structure found in correlation networks, resulting in more conservative estimates of small-world organization. A number of steps may be needed to normalize each network measure individually and control for distinct features (e.g. degree distribution). The main conclusion of this article is that correlation can and should be used to measure connectivity, however appropriate null networks should be used to benchmark network measures in correlation networks. ?? 2012 Elsevier Inc..},
	number = {4},
	journal = {NeuroImage},
	author = {Zalesky, Andrew and Fornito, Alex and Bullmore, Ed},
	year = {2012},
	pmid = {22343126},
	keywords = {Brain connectivity, Connectome, Correlation, Partial correlation, Small-world network, Transitivity},
	pages = {2096--2106},
	file = {Attachment:/Users/tito/Zotero/storage/PMD8CANV/Zalesky, Fornito, Bullmore - 2012 - On the use of correlation as a measure of network connectivity.pdf:application/pdf},
}

@article{investigator_novel_nodate,
	title = {novel task learning –},
	author = {Investigator, Principal},
	pages = {57--66},
	file = {Attachment:/Users/tito/Zotero/storage/DXR3X59J/Investigator - Unknown - novel task learning –.pdf:application/pdf},
}

@article{coutanche_informational_2013,
	title = {Informational connectivity: identifying synchronized discriminability of multi-voxel patterns across the brain.},
	volume = {7},
	issn = {1662-5161},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3566529&tool=pmcentrez&rendertype=abstract},
	doi = {10.3389/fnhum.2013.00015},
	abstract = {The fluctuations in a brain region's activation levels over a functional magnetic resonance imaging (fMRI) time-course are used in functional connectivity (FC) to identify networks with synchronous responses. It is increasingly recognized that multi-voxel activity patterns contain information that cannot be extracted from univariate activation levels. Here we present a novel analysis method that quantifies regions' synchrony in multi-voxel activity pattern discriminability, rather than univariate activation, across a timeseries. We introduce a measure of multi-voxel pattern discriminability at each time-point, which is then used to identify regions that share synchronous time-courses of condition-specific multi-voxel information. This method has the sensitivity and access to distributed information that multi-voxel pattern analysis enjoys, allowing it to be applied to data from conditions not separable by univariate responses. We demonstrate this by analyzing data collected while people viewed four different types of man-made objects (typically not separable by univariate analyses) using both FC and informational connectivity (IC) methods. IC reveals networks of object-processing regions that are not detectable using FC. The IC results support prior findings and hypotheses about object processing. This new method allows investigators to ask questions that are not addressable through typical FC, just as multi-voxel pattern analysis (MVPA) has added new research avenues to those addressable with the general linear model (GLM).},
	journal = {Frontiers in human neuroscience},
	author = {Coutanche, Marc N and Thompson-Schill, Sharon L},
	month = jan,
	year = {2013},
	pmid = {23403700},
	pages = {15},
	file = {Attachment:/Users/tito/Zotero/storage/DDEVQ89E/Coutanche, Thompson-Schill - 2013 - Informational connectivity identifying synchronized discriminability of multi-voxel patterns across.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/5GLEJGBF/Coutanche, Thompson-Schill - 2013 - Informational connectivity identifying synchronized discriminability of multi-voxel patterns across.pdf:application/pdf},
}

@article{delgado_regulating_2008,
	title = {Regulating the expectation of reward via cognitive strategies.},
	volume = {11},
	issn = {1097-6256},
	doi = {10.1038/nn.2141},
	abstract = {Previous emotion regulation research has been successful in altering aversive emotional reactions. It is unclear, however, whether such strategies can also efficiently regulate expectations of reward arising from conditioned stimuli, which can at times be maladaptive (for example, drug cravings). Using a monetary reward-conditioning procedure with cognitive strategies, we observed attenuation in both the physiological (skin conductance) and neural correlates (striatum) of reward expectation as participants engaged in emotion regulation.},
	number = {8},
	journal = {Nature neuroscience},
	author = {Delgado, Mauricio R and Gillis, M Meredith and Phelps, Elizabeth a},
	year = {2008},
	pmid = {18587392},
	pages = {880--881},
	file = {Attachment:/Users/tito/Zotero/storage/AV6NNJ84/Delgado, Gillis, Phelps - 2008 - Regulating the expectation of reward via cognitive strategies.pdf:application/pdf},
}

@article{cole_intrinsic_2014,
	title = {Intrinsic and task-evoked network architectures of the human brain},
	volume = {83},
	issn = {10974199},
	url = {http://dx.doi.org/10.1016/j.neuron.2014.05.014},
	doi = {10.1016/j.neuron.2014.05.014},
	abstract = {Many functional network properties of the human brain have been identified during rest and task states, yet it remains unclear how the two relate. We identified a whole-brain network architecture present across dozens of task states that was highly similar to the resting-state network architecture. The most frequent functional connectivity strengths across tasks closely matched the strengths observed at rest, suggesting this is an "intrinsic," standard architecture of functional brain organization. Furthermore, a set of small but consistent changes common across tasks suggests the existence of a task-general network architecture distinguishing task states from rest. These results indicate the brain's functional network architecture during task performance is shaped primarily by an intrinsic network architecture that is also present during rest, and secondarily by evoked task-general and task-specific network changes. This establishes astrong relationship between resting-state functional connectivity and task-evoked functional connectivity-areas of neuroscientific inquiry typically considered separately. © 2014 Elsevier Inc.},
	number = {1},
	journal = {Neuron},
	author = {Cole, Michael W. and Bassett, Danielle S. and Power, Jonathan D. and Braver, Todd S. and Petersen, Steven E.},
	year = {2014},
	pmid = {24991964},
	pages = {238--251},
	file = {Attachment:/Users/tito/Zotero/storage/C8LNFZ9N/Cole et al. - 2014 - Intrinsic and task-evoked network architectures of the human brain.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/SVL5ZEDX/Cole et al. - 2014 - Intrinsic and task-evoked network architectures of the human brain.pdf:application/pdf},
}

@article{botvinick_computational_2014,
	title = {The computational and neural basis of cognitive control: {Charted} territory and new frontiers},
	issn = {03640213},
	doi = {10.1111/cogs.12126},
	abstract = {Cognitive control has long been one of the most active areas of computational modeling work in cognitive science. The focus on computational models as a medium for specifying and developing theory predates the PDP books, and cognitive control was not one of the areas on which they focused. However, the framework they provided has injected work on cognitive control with new energy and new ideas. On the occasion of the books' anniversary, we review computational modeling in the study of cognitive control, with a focus on the influence that the PDP approach has brought to bear in this area. Rather than providing a comprehensive review, we offer a framework for thinking about past and future modeling efforts in this domain. We define control in terms of the optimal parameterization of task processing. From this vantage point, the development of control systems in the brain can be seen as responding to the structure of naturalistic tasks, through the filter of the brain systems with which control directly interfaces. This perspective lays open a set of fascinating but difficult research questions, which together define an important frontier for future computational research.},
	journal = {Cognitive Science},
	author = {Botvinick, Matthew M. and Cohen, Jonathan D.},
	year = {2014},
	pmid = {25079472},
	keywords = {Computational modeling, Cognitive control},
	pages = {1--37},
	file = {Attachment:/Users/tito/Zotero/storage/PYG9R7CV/Botvinick, Cohen - 2014 - The computational and neural basis of cognitive control Charted territory and new frontiers.pdf:application/pdf;Attachment:/Users/tito/Zotero/storage/6NPDDGEQ/Botvinick, Cohen - 2014 - The computational and neural basis of cognitive control Charted territory and new frontiers.pdf:application/pdf},
}

@article{mehler_lure_2018,
	title = {The lure of causal statements: {Rampant} mis-inference of causality in estimated connectivity},
	shorttitle = {The lure of causal statements},
	url = {http://arxiv.org/abs/1812.03363},
	abstract = {As neuroscientists we want to understand how causal interactions or mechanisms within the brain give rise to perception, cognition, and behavior. It is typical to estimate interaction effects from measured activity using statistical techniques such as functional connectivity, Granger Causality,or information flow, whose outcomes are often falsely treated as revealing mechanistic insight. Since these statistical techniques fit models to low-dimensional measurements from brains, they ignore the fact that brain activity is high-dimensional. Here we focus on the obvious confound of common inputs: the countless unobserved variables likely have more influence than the few observed ones. Any given observed correlation can be explained by an infinite set of causal models that take into account the unobserved variables. Therefore, correlations within massively undersampled measurements tell us little about mechanisms. We argue that these mis-inferences of causality from correlation are augmented by an implicit redefinition of words that suggest mechanisms, such as connectivity, causality, and flow.},
	urldate = {2018-12-12},
	journal = {arXiv:1812.03363 [q-bio]},
	author = {Mehler, David Marc Anton and Kording, Konrad Paul},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.03363},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 33 pages, 2 figures, code in appendix. Data and code available on: https://osf.io/9cs8p/},
	file = {arXiv\:1812.03363 PDF:/Users/tito/Zotero/storage/JTNZRSVX/Mehler and Kording - 2018 - The lure of causal statements Rampant mis-inferen.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/96TCXDMF/1812.html:text/html},
}

@article{huber_sub-millimeter_2018,
	title = {Sub-millimeter {fMRI} reveals multiple topographical digit representations that form action maps in human motor cortex},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This article is a US Government work. It is not subject to copyright under 17 USC 105 and is also made available for use under a CC0 license},
	url = {https://www.biorxiv.org/content/early/2018/10/30/457002},
	doi = {10.1101/457002},
	abstract = {The human brain coordinates a wide variety of motor activities. On a large scale, the cortical motor system is topographically organized such that neighboring body parts are represented by neighboring brain areas. This homunculus-like somatotopic organization along the central sulcus has been observed using neuroimaging for large body parts such as the face, hands and feet. However, on a finer scale, invasive electrical stimulation studies show deviations from this somatotopic organization that suggest an organizing principle based on motor action. It has not been clear how the action-map organization principle of the motor cortex in the mesoscopic (sub-millimeter) regime integrates into a body map organization principle on a macroscopic scale (cm). Here we developed and applied advanced mesoscopic (sub-millimeter) fMRI and analysis methodology to non-invasively investigate the functional organization topography across columnar and laminar structures in humans. We find that individual fingers have multiple mirrored representations in the primary motor cortex depending on the movements they are involved in. We find that individual digits have cortical representations up to 3 mm apart from each other arranged in a column-like fashion. These representations are differentially engaged depending on whether the digits' muscles are used for different motor actions such as flexion movements like grasping a ball or retraction movements like releasing a ball. This research provides a starting point for non-invasive investigation of mesoscale topography across layers and columns of the human cortex and bridges the gap between invasive electrophysiological investigations and large coverage non-invasive neuroimaging.},
	language = {en},
	urldate = {2018-12-18},
	journal = {bioRxiv},
	author = {Huber, Laurentius and Finn, Emily S. and Handwerker, Daniel A. and Boenstrup, Marlene and Glen, Daniel and Kashyap, Sriranga and Ivanov, Dimo and Petridou, Natalia and Marrett, Sean and Goense, Jozien and Poser, Benedikt and Bandettini, Peter A.},
	month = oct,
	year = {2018},
	pages = {457002},
	file = {Full Text PDF:/Users/tito/Zotero/storage/MHZRYA7A/Huber et al. - 2018 - Sub-millimeter fMRI reveals multiple topographical.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/REJSVN3K/457002.html:text/html},
}

@article{yokoi_parcellation_2018,
	title = {Parcellation of motor sequence representations in the human neocortex},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/early/2018/09/17/419754},
	doi = {10.1101/419754},
	abstract = {While previous studies have revealed an extended network of cortical regions associated with motor sequence production, the specific role of each of these areas is still elusive. To address this issue, we designed a novel behavioural paradigm that allowed us to experimentally manipulate the structure of motor sequences representations in individual participants. We then conducted fMRI while participants executed 8 trained sequences to examine how this structure is reflected in the associated activity patterns. Both model-based and model-free approaches revealed a clear distinction between primary and non-primary motor cortices in their representational contents, with M1 specifically representing individual finger movements, and premotor and parietal cortices showing a mixture of chunk, sequence and finger transition representations. Using model-free representational parcellation, we could divide these non-primary motor cortices into separate clusters, each with a unique representation along the stimulus-to-action gradient. These results provide new insights into how human neocortex organizes movement sequences.},
	language = {en},
	urldate = {2018-12-18},
	journal = {bioRxiv},
	author = {Yokoi, Atsushi and Diedrichsen, Joern},
	month = sep,
	year = {2018},
	pages = {419754},
	file = {Full Text PDF:/Users/tito/Zotero/storage/JZ4S5QAD/Yokoi and Diedrichsen - 2018 - Parcellation of motor sequence representations in .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9SJWA9UX/419754.html:text/html},
}

@article{van_loon_current_2018,
	title = {Current and future goals are represented in opposite patterns in object-selective cortex},
	volume = {7},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.38677},
	doi = {10.7554/eLife.38677},
	abstract = {Adaptive behavior requires the separation of current from future goals in working memory. We used fMRI of object-selective cortex to determine the representational (dis)similarities of memory representations serving current and prospective perceptual tasks. Participants remembered an object drawn from three possible categories as the target for one of two consecutive visual search tasks. A cue indicated whether the target object should be looked for first (currently relevant), second (prospectively relevant), or if it could be forgotten (irrelevant). Prior to the first search, representations of current, prospective and irrelevant objects were similar, with strongest decoding for current representations compared to prospective (Experiment 1) and irrelevant (Experiment 2). Remarkably, during the first search, prospective representations could also be decoded, but revealed anti-correlated voxel patterns compared to currently relevant representations of the same category. We propose that the brain separates current from prospective memories within the same neuronal ensembles through opposite representational patterns.},
	urldate = {2018-12-19},
	journal = {eLife},
	author = {van Loon, Anouk Mariette and Olmos-Solis, Katya and Fahrenfort, Johannes Jacobus and Olivers, Christian NL},
	editor = {de Lange, Floris and Frank, Michael J},
	month = nov,
	year = {2018},
	keywords = {cognitive control, working memory, visual attention, category representations, multivariate pattern decoding, prospective memory},
	pages = {e38677},
	file = {Full Text PDF:/Users/tito/Zotero/storage/ZVCH2TWA/van Loon et al. - 2018 - Current and future goals are represented in opposi.pdf:application/pdf},
}

@article{behrens_what_2018,
	title = {What {Is} a {Cognitive} {Map}? {Organizing} {Knowledge} for {Flexible} {Behavior}},
	volume = {100},
	issn = {0896-6273},
	shorttitle = {What {Is} a {Cognitive} {Map}?},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318308560},
	doi = {10.1016/j.neuron.2018.10.002},
	abstract = {It is proposed that a cognitive map encoding the relationships between entities in the world supports flexible behavior, but the majority of the neural evidence for such a system comes from studies of spatial navigation. Recent work describing neuronal parallels between spatial and non-spatial behaviors has rekindled the notion of a systematic organization of knowledge across multiple domains. We review experimental evidence and theoretical frameworks that point to principles unifying these apparently disparate functions. These principles describe how to learn and use abstract, generalizable knowledge and suggest that map-like representations observed in a spatial context may be an instance of general coding mechanisms capable of organizing knowledge of all kinds. We highlight how artificial agents endowed with such principles exhibit flexible behavior and learn map-like representations observed in the brain. Finally, we speculate on how these principles may offer insight into the extreme generalizations, abstractions, and inferences that characterize human cognition.},
	number = {2},
	urldate = {2019-01-02},
	journal = {Neuron},
	author = {Behrens, Timothy E. J. and Muller, Timothy H. and Whittington, James C. R. and Mark, Shirley and Baram, Alon B. and Stachenfeld, Kimberly L. and Kurth-Nelson, Zeb},
	month = oct,
	year = {2018},
	keywords = {Decision Making, Prefrontal Cortex, Cognitive Map, Generalization, Hippocampal Formation, Inference, Reinforcement Learning, Spatial Cognition, Statistical Learning, Structure Learning},
	pages = {490--509},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/6888M8WS/Behrens et al. - 2018 - What Is a Cognitive Map Organizing Knowledge for .pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/P7EVVMVW/S0896627318308560.html:text/html},
}

@article{banino_vector-based_2018,
	title = {Vector-based navigation using grid-like representations in artificial agents},
	volume = {557},
	copyright = {2018 Macmillan Publishers Ltd., part of Springer Nature},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0102-6},
	doi = {10.1038/s41586-018-0102-6},
	abstract = {Grid-like representations emerge spontaneously within a neural network trained to self-localize, enabling the agent to take shortcuts to destinations using vector-based navigation.},
	language = {En},
	number = {7705},
	urldate = {2019-01-02},
	journal = {Nature},
	author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J. and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
	month = may,
	year = {2018},
	pages = {429},
	file = {Full Text PDF:/Users/tito/Zotero/storage/SCDZYFUF/Banino et al. - 2018 - Vector-based navigation using grid-like representa.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/882DUD8M/s41586-018-0102-6.html:text/html},
}

@article{cueva_emergence_2018,
	title = {Emergence of grid-like representations by training recurrent neural networks to perform spatial localization},
	url = {https://openreview.net/forum?id=B17JTOe0-},
	abstract = {Decades of research on the neural code underlying spatial navigation have revealed a diverse set of neural response properties. The Entorhinal Cortex (EC) of the mammalian brain contains a rich set...},
	urldate = {2019-01-02},
	author = {Cueva, Christopher J. and Wei, Xue-Xin},
	month = feb,
	year = {2018},
	file = {Full Text PDF:/Users/tito/Zotero/storage/USCCI5DB/Cueva and Wei - 2018 - Emergence of grid-like representations by training.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/PTJWYJ49/forum.html:text/html},
}

@article{hubel_receptive_1962,
	title = {Receptive fields, binocular interaction and functional architecture in the cat's visual cortex},
	volume = {160},
	copyright = {© 1962 The Physiological Society},
	issn = {1469-7793},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1962.sp006837},
	doi = {10.1113/jphysiol.1962.sp006837},
	language = {en},
	number = {1},
	urldate = {2019-01-02},
	journal = {The Journal of Physiology},
	author = {Hubel, D. H. and Wiesel, T. N.},
	year = {1962},
	pages = {106--154},
	file = {Full Text PDF:/Users/tito/Zotero/storage/K565CKYE/Hubel and Wiesel - 1962 - Receptive fields, binocular interaction and functi.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/D7CUQXED/jphysiol.1962.html:text/html},
}

@article{yartsev_representation_2013,
	title = {Representation of {Three}-{Dimensional} {Space} in the {Hippocampus} of {Flying} {Bats}},
	volume = {340},
	copyright = {Copyright © 2013, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/340/6130/367},
	doi = {10.1126/science.1235338},
	abstract = {Bats, Grids, and Oscillations
Nearly all animals move around in a three-dimensional (3D) world; however, very little is known about the neural circuitry underlying the representation of 3D space (see the Perspective by Barry and Doeller). Using whole-cell patch recordings in slices of entorhinal cortex, Heys et al. (p. 363) found that bat entorhinal stellate cells must generate grid patterns without theta-frequency oscillatory mechanisms. In another study, Yartsev and Ulanovsky (p. 367) used telemetry to record activity from the hippocampus of bats while they were flying around. They found that active pyramidal cells—or place cells—in hippocampal area CA1 fired in positions, depending on where the animals were in the room.
Many animals, on air, water, or land, navigate in three-dimensional (3D) environments, yet it remains unclear how brain circuits encode the animal's 3D position. We recorded single neurons in freely flying bats, using a wireless neural-telemetry system, and studied how hippocampal place cells encode 3D volumetric space during flight. Individual place cells were active in confined 3D volumes, and in {\textgreater}90\% of the neurons, all three axes were encoded with similar resolution. The 3D place fields from different neurons spanned different locations and collectively represented uniformly the available space in the room. Theta rhythmicity was absent in the firing patterns of 3D place cells. These results suggest that the bat hippocampus represents 3D volumetric space by a uniform and nearly isotropic rate code.
The spatial firing properties of neurons were recorded in bats during flight using a wireless neural-telemetry system. [Also see Perspective by Barry and Doeller]
The spatial firing properties of neurons were recorded in bats during flight using a wireless neural-telemetry system. [Also see Perspective by Barry and Doeller]},
	language = {en},
	number = {6130},
	urldate = {2019-01-02},
	journal = {Science},
	author = {Yartsev, Michael M. and Ulanovsky, Nachum},
	month = apr,
	year = {2013},
	pmid = {23599496},
	pages = {367--372},
	file = {Full Text PDF:/Users/tito/Zotero/storage/4IBHIU7N/Yartsev and Ulanovsky - 2013 - Representation of Three-Dimensional Space in the H.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Z45GWNFN/367.html:text/html},
}

@article{wong_amplitude_2013,
	title = {The amplitude of the resting-state {fMRI} global signal is related to {EEG} vigilance measures},
	volume = {83},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913008264},
	doi = {10.1016/j.neuroimage.2013.07.057},
	abstract = {In resting-state functional magnetic resonance imaging (fMRI), functional connectivity measures can be influenced by the presence of a strong global component. A widely used pre-processing method for reducing the contribution of this component is global signal regression, in which a global mean time series signal is projected out of the fMRI time series data prior to the computation of connectivity measures. However, the use of global signal regression is controversial because the method can bias the correlation values to have an approximately zero mean and may in some instances create artifactual negative correlations. In addition, while many studies treat the global signal as a non-neural confound that needs to be removed, evidence from electrophysiological and fMRI measures in primates suggests that the global signal may contain significant neural correlates. In this study, we used simultaneously acquired fMRI and electroencephalographic (EEG) measures of resting-state activity to assess the relation between the fMRI global signal and EEG measures of vigilance in humans. We found that the amplitude of the global signal (defined as the standard deviation of the global signal) exhibited a significant negative correlation with EEG vigilance across subjects studied in the eyes-closed condition. In addition, increases in EEG vigilance due to the ingestion of caffeine were significantly associated with both a decrease in global signal amplitude and an increase in the average level of anti-correlation between the default mode network and the task-positive network.},
	urldate = {2019-01-02},
	journal = {NeuroImage},
	author = {Wong, Chi Wah and Olafsson, Valur and Tal, Omer and Liu, Thomas T.},
	month = dec,
	year = {2013},
	keywords = {Default mode network, Functional connectivity, Resting-state fMRI, Electroencephalography, Anti-correlation, Caffeine, Global signal, Task positive network, Vigilance},
	pages = {983--990},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/KK5ZEW64/Wong et al. - 2013 - The amplitude of the resting-state fMRI global sig.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/IFC6FW7M/S1053811913008264.html:text/html},
}

@article{constantinescu_organizing_2016,
	title = {Organizing conceptual knowledge in humans with a gridlike code},
	volume = {352},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/352/6292/1464},
	doi = {10.1126/science.aaf0941},
	abstract = {Coding abstract concepts in the brain
Grid cells are thought to provide the neuronal code that underlies spatial knowledge in the brain. Grid cells have mostly been studied in the context of path integration. However, recent theoretical studies have suggested that they may have a broader role in the organization of general knowledge. Constantinescu et al. investigated whether the neural representation of concepts follows a structure similar to the representation of space in the entorhinal cortex. Several brain regions, including the entorhinal cortex and the ventromedial prefrontal cortex, showed gridlike neural representation of conceptual space.
Science, this issue p. 1464
It has been hypothesized that the brain organizes concepts into a mental map, allowing conceptual relationships to be navigated in a manner similar to that of space. Grid cells use a hexagonally symmetric code to organize spatial representations and are the likely source of a precise hexagonal symmetry in the functional magnetic resonance imaging signal. Humans navigating conceptual two-dimensional knowledge showed the same hexagonal signal in a set of brain regions markedly similar to those activated during spatial navigation. This gridlike signal is consistent across sessions acquired within an hour and more than a week apart. Our findings suggest that global relational codes may be used to organize nonspatial conceptual representations and that these codes may have a hexagonal gridlike pattern when conceptual knowledge is laid out in two continuous dimensions.
Grid cells in the brain can also represent nonspatial knowledge.
Grid cells in the brain can also represent nonspatial knowledge.},
	language = {en},
	number = {6292},
	urldate = {2019-01-03},
	journal = {Science},
	author = {Constantinescu, Alexandra O. and O’Reilly, Jill X. and Behrens, Timothy E. J.},
	month = jun,
	year = {2016},
	pmid = {27313047},
	pages = {1464--1468},
	file = {Full Text PDF:/Users/tito/Zotero/storage/PED7THNR/Constantinescu et al. - 2016 - Organizing conceptual knowledge in humans with a g.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MVEBCN57/1464.html:text/html},
}

@article{dumoulin_feature-wise_2018,
	title = {Feature-wise transformations},
	volume = {3},
	issn = {2476-0757},
	url = {https://distill.pub/2018/feature-wise-transformations},
	doi = {10.23915/distill.00011},
	abstract = {A simple and surprisingly effective family of conditioning mechanisms.},
	language = {en},
	number = {7},
	urldate = {2019-01-04},
	journal = {Distill},
	author = {Dumoulin, Vincent and Perez, Ethan and Schucher, Nathan and Strub, Florian and Vries, Harm de and Courville, Aaron and Bengio, Yoshua},
	month = jul,
	year = {2018},
	pages = {e11},
	file = {Full Text:/Users/tito/Zotero/storage/T23A4IPC/Dumoulin et al. - 2018 - Feature-wise transformations.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/37MYNR8G/feature-wise-transformations.html:text/html},
}

@article{tolman_cognitive_1948,
	title = {Cognitive maps in rats and men},
	volume = {55},
	issn = {0033-295X},
	language = {eng},
	number = {4},
	journal = {Psychol Rev},
	author = {Tolman, E. C.},
	month = jul,
	year = {1948},
	pmid = {18870876},
	keywords = {Cognition, Humans, Male, Animals, Rats, Behavior Therapy, CONDITIONING THERAPY},
	pages = {189--208},
}

@article{finn_functional_2015,
	title = {Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity},
	volume = {18},
	copyright = {2015 Nature Publishing Group},
	issn = {1546-1726},
	shorttitle = {Functional connectome fingerprinting},
	url = {https://www.nature.com/articles/nn.4135},
	doi = {10.1038/nn.4135},
	abstract = {Functional magnetic resonance imaging (fMRI) studies typically collapse data from many subjects, but brain functional organization varies between individuals. Here we establish that this individual variability is both robust and reliable, using data from the Human Connectome Project to demonstrate that functional connectivity profiles act as a 'fingerprint' that can accurately identify subjects from a large group. Identification was successful across scan sessions and even between task and rest conditions, indicating that an individual's connectivity profile is intrinsic, and can be used to distinguish that individual regardless of how the brain is engaged during imaging. Characteristic connectivity patterns were distributed throughout the brain, but the frontoparietal network emerged as most distinctive. Furthermore, we show that connectivity profiles predict levels of fluid intelligence: the same networks that were most discriminating of individuals were also most predictive of cognitive behavior. Results indicate the potential to draw inferences about single subjects on the basis of functional connectivity fMRI.},
	language = {en},
	number = {11},
	urldate = {2019-01-04},
	journal = {Nature Neuroscience},
	author = {Finn, Emily S. and Shen, Xilin and Scheinost, Dustin and Rosenberg, Monica D. and Huang, Jessica and Chun, Marvin M. and Papademetris, Xenophon and Constable, R. Todd},
	month = nov,
	year = {2015},
	pages = {1664--1671},
	file = {Full Text PDF:/Users/tito/Zotero/storage/Z3KCQQ9X/Finn et al. - 2015 - Functional connectome fingerprinting identifying .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DVN9NEU6/nn.html:text/html},
}

@article{bertolero_mechanistic_2018,
	title = {A mechanistic model of connector hubs, modularity, and cognition},
	volume = {2},
	issn = {2397-3374},
	url = {http://arxiv.org/abs/1803.08109},
	doi = {10.1038/s41562-018-0420-6},
	abstract = {The human brain network is modular--comprised of communities of tightly interconnected nodes. This network contains local hubs, which have many connections within their own communities, and connector hubs, which have connections diversely distributed across communities. A mechanistic understanding of these hubs and how they support cognition has not been demonstrated. Here, we leveraged individual differences in hub connectivity and cognition. We show that a model of hub connectivity accurately predicts the cognitive performance of 476 individuals in four distinct tasks. Moreover, there is a general optimal network structure for cognitive performance--individuals with diversely connected hubs and consequent modular brain networks exhibit increased cognitive performance, regardless of the task. Critically, we find evidence consistent with a mechanistic model in which connector hubs tune the connectivity of their neighbors to be more modular while allowing for task appropriate information integration across communities, which increases global modularity and cognitive performance.},
	number = {10},
	urldate = {2019-01-04},
	journal = {Nature Human Behaviour},
	author = {Bertolero, Maxwell A. and Yeo, B. T. T. and Bassett, Danielle S. and D'Esposito, Mark},
	month = oct,
	year = {2018},
	note = {arXiv: 1803.08109},
	keywords = {Quantitative Biology - Neurons and Cognition, Quantitative Biology - Quantitative Methods},
	pages = {765--777},
	file = {arXiv\:1803.08109 PDF:/Users/tito/Zotero/storage/GWKJA5WM/Bertolero et al. - 2018 - A mechanistic model of connector hubs, modularity,.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/SFJLAJ5T/1803.html:text/html;Attachment:/Users/tito/Zotero/storage/727M3FK4/Bertolero et al. - 2018 - A mechanistic model of connector hubs, modularity, and cognition.pdf:application/pdf},
}

@article{hafting_microstructure_2005,
	title = {Microstructure of a spatial map in the entorhinal cortex},
	volume = {436},
	copyright = {2005 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature03721},
	doi = {10.1038/nature03721},
	abstract = {The ability to find one's way depends on neural algorithms that integrate information about place, distance and direction, but the implementation of these operations in cortical microcircuits is poorly understood. Here we show that the dorsocaudal medial entorhinal cortex (dMEC) contains a directionally oriented, topographically organized neural map of the spatial environment. Its key unit is the ‘grid cell’, which is activated whenever the animal's position coincides with any vertex of a regular grid of equilateral triangles spanning the surface of the environment. Grids of neighbouring cells share a common orientation and spacing, but their vertex locations (their phases) differ. The spacing and size of individual fields increase from dorsal to ventral dMEC. The map is anchored to external landmarks, but persists in their absence, suggesting that grid cells may be part of a generalized, path-integration-based map of the spatial environment.},
	language = {en},
	number = {7052},
	urldate = {2019-01-04},
	journal = {Nature},
	author = {Hafting, Torkel and Fyhn, Marianne and Molden, Sturla and Moser, May-Britt and Moser, Edvard I.},
	month = aug,
	year = {2005},
	pages = {801--806},
	file = {Full Text PDF:/Users/tito/Zotero/storage/YE9PDY9H/Hafting et al. - 2005 - Microstructure of a spatial map in the entorhinal .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TJAB4HUF/nature03721.html:text/html},
}

@article{mcnaughton_path_2006,
	title = {Path integration and the neural basis of the 'cognitive map'},
	volume = {7},
	copyright = {2006 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn1932},
	doi = {10.1038/nrn1932},
	abstract = {The hippocampal formation can encode relative spatial location, without reference to external cues, by the integration of linear and angular self-motion (path integration). Theoretical studies, in conjunction with recent empirical discoveries, suggest that the medial entorhinal cortex (MEC) might perform some of the essential underlying computations by means of a unique, periodic synaptic matrix that could be self-organized in early development through a simple, symmetry-breaking operation. The scale at which space is represented increases systematically along the dorsoventral axis in both the hippocampus and the MEC, apparently because of systematic variation in the gain of a movement-speed signal. Convergence of spatially periodic input at multiple scales, from so-called grid cells in the entorhinal cortex, might result in non-periodic spatial firing patterns (place fields) in the hippocampus.},
	language = {en},
	number = {8},
	urldate = {2019-01-04},
	journal = {Nature Reviews Neuroscience},
	author = {McNaughton, Bruce L. and Battaglia, Francesco P. and Jensen, Ole and Moser, Edvard I. and Moser, May-Britt},
	month = aug,
	year = {2006},
	pages = {663--678},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HUWYGIBS/McNaughton et al. - 2006 - Path integration and the neural basis of the 'cogn.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/S55MFXZB/nrn1932.html:text/html},
}

@article{saygin_anatomical_2012,
	title = {Anatomical connectivity patterns predict face selectivity in the fusiform gyrus},
	volume = {15},
	copyright = {2011 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3001},
	doi = {10.1038/nn.3001},
	abstract = {A fundamental assumption in neuroscience is that brain structure determines function. Accordingly, functionally distinct regions of cortex should be structurally distinct in their connections to other areas. We tested this hypothesis in relation to face selectivity in the fusiform gyrus. By using only structural connectivity, as measured through diffusion-weighted imaging, we were able to predict functional activation to faces in the fusiform gyrus. These predictions outperformed two control models and a standard group-average benchmark. The structure–function relationship discovered from the initial participants was highly robust in predicting activation in a second group of participants, despite differences in acquisition parameters and stimuli. This approach can thus reliably estimate activation in participants who cannot perform functional imaging tasks and is an alternative to group-activation maps. Additionally, we identified cortical regions whose connectivity was highly influential in predicting face selectivity within the fusiform, suggesting a possible mechanistic architecture underlying face processing in humans.},
	language = {en},
	number = {2},
	urldate = {2019-01-04},
	journal = {Nature Neuroscience},
	author = {Saygin, Zeynep M. and Osher, David E. and Koldewyn, Kami and Reynolds, Gretchen and Gabrieli, John D. E. and Saxe, Rebecca R.},
	month = feb,
	year = {2012},
	pages = {321--327},
	file = {Full Text PDF:/Users/tito/Zotero/storage/S7L7KMQV/Saygin et al. - 2012 - Anatomical connectivity patterns predict face sele.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/72DQZWC2/nn.html:text/html},
}

@article{moser_place_2008,
	title = {Place {Cells}, {Grid} {Cells}, and the {Brain}'s {Spatial} {Representation} {System}},
	volume = {31},
	url = {https://doi.org/10.1146/annurev.neuro.31.061307.090723},
	doi = {10.1146/annurev.neuro.31.061307.090723},
	abstract = {More than three decades of research have demonstrated a role for hippocampal place cells in representation of the spatial environment in the brain. New studies have shown that place cells are part of a broader circuit for dynamic representation of self-location. A key component of this network is the entorhinal grid cells, which, by virtue of their tessellating firing fields, may provide the elements of a path integration–based neural map. Here we review how place cells and grid cells may form the basis for quantitative spatiotemporal representation of places, routes, and associated experiences during behavior and in memory. Because these cell types have some of the most conspicuous behavioral correlates among neurons in nonsensory cortical systems, and because their spatial firing structure reflects computations internally in the system, studies of entorhinal-hippocampal representations may offer considerable insight into general principles of cortical network dynamics.},
	number = {1},
	urldate = {2019-01-04},
	journal = {Annual Review of Neuroscience},
	author = {Moser, Edvard I. and Kropff, Emilio and Moser, May-Britt},
	year = {2008},
	pmid = {18284371},
	pages = {69--89},
	file = {Full Text PDF:/Users/tito/Zotero/storage/VCDID5PC/Moser et al. - 2008 - Place Cells, Grid Cells, and the Brain's Spatial R.pdf:application/pdf},
}

@article{rumelhart_parallel_1986,
	title = {Parallel distributed processing: explorations in the microstructure of cognition. {Volume} 1. {Foundations}},
	shorttitle = {Parallel distributed processing},
	url = {https://www.osti.gov/biblio/5838709},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	urldate = {2019-01-04},
	author = {Rumelhart, D. E. and Mcclelland, J. L.},
	month = jan,
	year = {1986},
	file = {Snapshot:/Users/tito/Zotero/storage/IXXJ8S4M/5838709.html:text/html},
}

@techreport{elman_representation_1989,
	title = {Representation and {Structure} in {Connectionist} {Models}},
	url = {https://apps.dtic.mil/docs/citations/ADA259504},
	abstract = {This paper focuses on the nature of representations in connectionist models. It addresses two issues: Can connectionist models develop representations which possess internal structure and which provide the basis for productive and systematic behavior; and Can representations which are fundamentally context-sensitive support grammatical behavior which appears to be abstract and general? Results from two simulations are reported.. The simulations address problems in the distinction between type and token, the representation of lexical categories, and the representation of grammatical structure. The results suggest that connectionist representations can indeed possess internal structure and enable systematic behavior, and that a mechanism which is sensitive to context is capable of capturing generalizations of varying degrees of abstractness.},
	language = {en},
	number = {N00014-85-K-0076},
	urldate = {2019-01-04},
	institution = {CALIFORNIA UNIV SAN DIEGO LA JOLLA CENTER FOR RESEARCH IN LANGUAGE},
	author = {Elman, Jeffrey L.},
	month = aug,
	year = {1989},
	file = {Full Text PDF:/Users/tito/Zotero/storage/JNTG9ZQB/Elman - 1989 - Representation and Structure in Connectionist Mode.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ISUN93U9/ADA259504.html:text/html},
}

@article{bullmore_complex_2009,
	title = {Complex brain networks: graph theoretical analysis of structural and functional systems},
	volume = {10},
	copyright = {2009 Nature Publishing Group},
	issn = {1471-0048},
	shorttitle = {Complex brain networks},
	url = {https://www.nature.com/articles/nrn2575},
	doi = {10.1038/nrn2575},
	abstract = {Recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. The brain's structural and functional systems have features of complex networks — such as small-world topology, highly connected hubs and modularity — both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. In this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional MRI, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. We also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field.},
	language = {en},
	number = {3},
	urldate = {2019-01-04},
	journal = {Nature Reviews Neuroscience},
	author = {Bullmore, Ed and Sporns, Olaf},
	month = mar,
	year = {2009},
	pages = {186--198},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HPDAWQ83/Bullmore and Sporns - 2009 - Complex brain networks graph theoretical analysis.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GANL2E9F/nrn2575.html:text/html},
}

@article{wang_inversion_2019,
	title = {Inversion of a large-scale circuit model reveals a cortical hierarchy in the dynamic resting human brain},
	volume = {5},
	copyright = {Copyright © 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution License 4.0 (CC BY).. This is an open-access article distributed under the terms of the Creative Commons Attribution license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	issn = {2375-2548},
	url = {http://advances.sciencemag.org/content/5/1/eaat7854},
	doi = {10.1126/sciadv.aat7854},
	abstract = {We considered a large-scale dynamical circuit model of human cerebral cortex with region-specific microscale properties. The model was inverted using a stochastic optimization approach, yielding markedly better fit to new, out-of-sample resting functional magnetic resonance imaging (fMRI) data. Without assuming the existence of a hierarchy, the estimated model parameters revealed a large-scale cortical gradient. At one end, sensorimotor regions had strong recurrent connections and excitatory subcortical inputs, consistent with localized processing of external stimuli. At the opposing end, default network regions had weak recurrent connections and excitatory subcortical inputs, consistent with their role in internal thought. Furthermore, recurrent connection strength and subcortical inputs provided complementary information for differentiating the levels of the hierarchy, with only the former showing strong associations with other macroscale and microscale proxies of cortical hierarchies (meta-analysis of cognitive functions, principal resting fMRI gradient, myelin, and laminar-specific neuronal density). Overall, this study provides microscale insights into a macroscale cortical hierarchy in the dynamic resting brain.
Converging evidence from biophysical modeling, magnetic resonance imaging, and histology reveals a large-scale cortical gradient.
Converging evidence from biophysical modeling, magnetic resonance imaging, and histology reveals a large-scale cortical gradient.},
	language = {en},
	number = {1},
	urldate = {2019-01-10},
	journal = {Science Advances},
	author = {Wang, Peng and Kong, Ru and Kong, Xiaolu and Liégeois, Raphaël and Orban, Csaba and Deco, Gustavo and Heuvel, Martijn P. van den and Yeo, B. T. Thomas},
	month = jan,
	year = {2019},
	pages = {eaat7854},
	file = {Full Text PDF:/Users/tito/Zotero/storage/S5PFMH58/Wang et al. - 2019 - Inversion of a large-scale circuit model reveals a.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TEH39RSS/tab-pdf.html:text/html},
}

@article{marcus_atoms_2014,
	title = {The atoms of neural computation},
	volume = {346},
	copyright = {Copyright © 2014, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/346/6209/551},
	doi = {10.1126/science.1261661},
	abstract = {Does the brain depend on a set of elementary, reusable computations?
Does the brain depend on a set of elementary, reusable computations?},
	language = {en},
	number = {6209},
	urldate = {2019-01-10},
	journal = {Science},
	author = {Marcus, Gary and Marblestone, Adam and Dean, Thomas},
	month = oct,
	year = {2014},
	pmid = {25359953},
	pages = {551--552},
	file = {Full Text PDF:/Users/tito/Zotero/storage/DMJ5S3AG/Marcus et al. - 2014 - The atoms of neural computation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AUGZSFQH/551.html:text/html},
}

@article{olshausen_emergence_1996,
	title = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images},
	volume = {381},
	copyright = {1996 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/381607a0},
	doi = {10.1038/381607a0},
	abstract = {THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1–4 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7–12. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13–18, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
	language = {en},
	number = {6583},
	urldate = {2019-01-11},
	journal = {Nature},
	author = {Olshausen, Bruno A. and Field, David J.},
	month = jun,
	year = {1996},
	pages = {607--609},
	file = {Snapshot:/Users/tito/Zotero/storage/L5P2NDV8/381607a0.html:text/html},
}

@article{cole_task_2019,
	title = {Task activations produce spurious but systematic inflation of task functional connectivity estimates},
	volume = {189},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918322043},
	doi = {10.1016/j.neuroimage.2018.12.054},
	abstract = {Most neuroscientific studies have focused on task-evoked activations (activity amplitudes at specific brain locations), providing limited insight into the functional relationships between separate brain locations. Task-state functional connectivity (FC) – statistical association between brain activity time series during task performance – moves beyond task-evoked activations by quantifying functional interactions during tasks. However, many task-state FC studies do not remove the first-order effect of task-evoked activations prior to estimating task-state FC. It has been argued that this results in the ambiguous inference "likely active or interacting during the task", rather than the intended inference "likely interacting during the task". Utilizing a neural mass computational model, we verified that task-evoked activations substantially and inappropriately inflate task-state FC estimates, especially in functional MRI (fMRI) data. Various methods attempting to address this problem have been developed, yet the efficacies of these approaches have not been systematically assessed. We found that most standard approaches for fitting and removing mean task-evoked activations were unable to correct these inflated correlations. In contrast, methods that flexibly fit mean task-evoked response shapes effectively corrected the inflated correlations without reducing effects of interest. Results with empirical fMRI data confirmed the model's predictions, revealing activation-induced task-state FC inflation for both Pearson correlation and psychophysiological interaction (PPI) approaches. These results demonstrate that removal of mean task-evoked activations using an approach that flexibly models task-evoked response shape is an important preprocessing step for valid estimation of task-state FC.},
	urldate = {2019-01-11},
	journal = {NeuroImage},
	author = {Cole, Michael W. and Ito, Takuya and Schultz, Douglas and Mill, Ravi and Chen, Richard and Cocuzza, Carrisa},
	month = apr,
	year = {2019},
	keywords = {fMRI, Functional connectivity, Networks, Computational modeling, Method validation},
	pages = {1--18},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/UDZGZUDR/Cole et al. - 2019 - Task activations produce spurious but systematic i.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/SNV6KBZ5/S1053811918322043.html:text/html},
}

@article{spanne_questioning_2015,
	title = {Questioning the role of sparse coding in the brain},
	volume = {38},
	issn = {0166-2236},
	url = {http://www.sciencedirect.com/science/article/pii/S0166223615001198},
	doi = {10.1016/j.tins.2015.05.005},
	abstract = {Coding principles are central to understanding the organization of brain circuitry. Sparse coding offers several advantages, but a near-consensus has developed that it only has beneficial properties, and these are partially unique to sparse coding. We find that these advantages come at the cost of several trade-offs, with the lower capacity for generalization being especially problematic, and the value of sparse coding as a measure and its experimental support are both questionable. Furthermore, silent synapses and inhibitory interneurons can permit learning speed and memory capacity that was previously ascribed to sparse coding only. Combining these properties without exaggerated sparse coding improves the capacity for generalization and facilitates learning of models of a complex and high-dimensional reality.},
	number = {7},
	urldate = {2019-01-14},
	journal = {Trends in Neurosciences},
	author = {Spanne, Anton and Jörntell, Henrik},
	month = jul,
	year = {2015},
	pages = {417--427},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/8YQKCVTN/Spanne and Jörntell - 2015 - Questioning the role of sparse coding in the brain.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/WZPXWITQ/S0166223615001198.html:text/html},
}

@article{barak_sparseness_2013,
	title = {The {Sparseness} of {Mixed} {Selectivity} {Neurons} {Controls} the {Generalization}–{Discrimination} {Trade}-{Off}},
	volume = {33},
	copyright = {Copyright © 2013 the authors 0270-6474/13/333844-13\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/33/9/3844},
	doi = {10.1523/JNEUROSCI.2753-12.2013},
	abstract = {Intelligent behavior requires integrating several sources of information in a meaningful fashion—be it context with stimulus or shape with color and size. This requires the underlying neural mechanism to respond in a different manner to similar inputs (discrimination), while maintaining a consistent response for noisy variations of the same input (generalization). We show that neurons that mix information sources via random connectivity can form an easy to read representation of input combinations. Using analytical and numerical tools, we show that the coding level or sparseness of these neurons' activity controls a trade-off between generalization and discrimination, with the optimal level depending on the task at hand. In all realistic situations that we analyzed, the optimal fraction of inputs to which a neuron responds is close to 0.1. Finally, we predict a relation between a measurable property of the neural representation and task performance.},
	language = {en},
	number = {9},
	urldate = {2019-01-14},
	journal = {J. Neurosci.},
	author = {Barak, Omri and Rigotti, Mattia and Fusi, Stefano},
	month = feb,
	year = {2013},
	pmid = {23447596},
	pages = {3844--3856},
	file = {Full Text PDF:/Users/tito/Zotero/storage/L5X8CESE/Barak et al. - 2013 - The Sparseness of Mixed Selectivity Neurons Contro.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/CVATGRED/3844.html:text/html},
}

@article{tsodyks_linking_1999,
	title = {Linking {Spontaneous} {Activity} of {Single} {Cortical} {Neurons} and the {Underlying} {Functional} {Architecture}},
	volume = {286},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/286/5446/1943},
	doi = {10.1126/science.286.5446.1943},
	abstract = {The relation between the activity of a single neocortical neuron and the dynamics of the network in which it is embedded was explored by single-unit recordings and real-time optical imaging. The firing rate of a spontaneously active single neuron strongly depends on the instantaneous spatial pattern of ongoing population activity in a large cortical area. Very similar spatial patterns of population activity were observed both when the neuron fired spontaneously and when it was driven by its optimal stimulus. The evoked patterns could be used to reconstruct the spontaneous activity of single neurons.},
	language = {en},
	number = {5446},
	urldate = {2019-01-14},
	journal = {Science},
	author = {Tsodyks, M. and Kenet, T. and Grinvald, A. and Arieli, A.},
	month = dec,
	year = {1999},
	pmid = {10583955},
	pages = {1943--1946},
	file = {Full Text PDF:/Users/tito/Zotero/storage/SA5EHMV8/Tsodyks et al. - 1999 - Linking Spontaneous Activity of Single Cortical Ne.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/PI366FZD/1943.html:text/html},
}

@article{yang_task_2019,
	title = {Task representations in neural networks trained to perform many cognitive tasks},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0310-2},
	doi = {10.1038/s41593-018-0310-2},
	abstract = {Prefrontal cortex can be flexibly engaged in many different tasks. Yang et al. trained an artificial neural network to solve 20 cognitive tasks. Functionally specialized modules and compositional representations emerged in the network after training.},
	language = {En},
	urldate = {2019-01-14},
	journal = {Nature Neuroscience},
	author = {Yang, Guangyu Robert and Joglekar, Madhura R. and Song, H. Francis and Newsome, William T. and Wang, Xiao-Jing},
	month = jan,
	year = {2019},
	pages = {1},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HTD6USUW/Yang et al. - 2019 - Task representations in neural networks trained to.pdf:application/pdf;Full Text PDF:/Users/tito/Zotero/storage/Y8NZZREY/Yang et al. - 2019 - Task representations in neural networks trained to.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6KS3INIM/s41593-018-0310-2.html:text/html;Snapshot:/Users/tito/Zotero/storage/IATJ9E28/s41593-018-0310-2.html:text/html},
}

@article{gerchen_combining_2017,
	title = {Combining task-related activation and connectivity analysis of {fMRI} data reveals complex modulation of brain networks},
	volume = {38},
	copyright = {© 2017 Wiley Periodicals, Inc.},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23762},
	doi = {10.1002/hbm.23762},
	abstract = {Task-related effects in functional magnetic resonance imaging (fMRI) data are usually analyzed with local activation approaches or integrative connectivity approaches, for example, by psychophysiological interaction (PPI) analysis. While both approaches are often applied to the same data set, a systematic combination of the results with a whole-brain (WB) perspective is rarely conducted and the relationship between task-dependent activation and connectivity effects is relatively unexplored. Here, we combined brain activation and graph theoretical analysis of WB-PPI results in an exemplary episodic memory data set of N = 136 healthy human participants and found regions with congruent as well as incongruent activation and connectivity changes between task and control conditions. A comparison with large-scale resting state networks showed that in congruent as well as incongruent regions task-positively modulated connections were mainly between-network connections, especially with the default mode network, while task-negatively modulated connections were mainly found within resting state networks. Over all regions, the strength of absolute activation effects was associated with the tendency to exhibit task-positive connectivity changes, mainly driven by a strong relationship in negatively activated regions. These results demonstrate that task demands lead to a complex modulation of brain networks and provide evidence that task-evoked activation and connectivity effects reflect separable and complementary information on the macroscale brain level assessed by fMRI. Hum Brain Mapp 38:5726–5739, 2017. © 2017 Wiley Periodicals, Inc.},
	language = {en},
	number = {11},
	urldate = {2019-01-15},
	journal = {Human Brain Mapping},
	author = {Gerchen, Martin Fungisai and Kirsch, Peter},
	year = {2017},
	keywords = {functional magnetic resonance imaging, hippocampus, resting state, default mode network, graph theory, psychophysiological interaction, task},
	pages = {5726--5739},
	file = {Full Text PDF:/Users/tito/Zotero/storage/4W2TFJ3T/Gerchen and Kirsch - 2017 - Combining task-related activation and connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/UWNV5DJB/hbm.html:text/html},
}

@article{kashyap_individual-specific_2019,
	title = {Individual-{Specific} {fMRI}-{Subspaces} {Improve} {Functional} {Connectivity} {Prediction} of {Behavior}},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/early/2019/01/09/515742},
	doi = {10.1101/515742},
	abstract = {There is significant interest in using resting-state functional connectivity (RSFC) to predict human behavior. Good behavioral prediction should in theory require RSFC to be sufficiently distinct across participants; if RSFC were the same across participants, then behavioral prediction would obviously be poor. Therefore, we hypothesize that removing common resting-state functional magnetic resonance imaging (rs-fMRI) signals that are shared across participants would improve behavioral prediction. Here, we considered 803 participants from the human connectome project (HCP) with four rs-fMRI runs. We applied the common and orthogonal basis extraction (COBE) technique to decompose each HCP run into two subspaces: a common (group-level) subspace shared across all participants and a subject-specific subspace. We found that the first common COBE component of the first HCP run was localized to the visual cortex and was unique to the run. On the other hand, the second common COBE component of the first HCP run and the first common COBE component of the remaining HCP runs were highly similar and localized to regions within the default network, including the posterior cingulate cortex and precuneus. Overall, this suggests the presence of run-specific (state-specific) effects that were shared across participants. By removing the first and second common COBE components from the first HCP run, and the first common COBE component from the remaining HCP runs, the resulting RSFC improves behavioral prediction by an average of 11.7\% across 58 behavioral measures spanning cognition, emotion and personality.},
	language = {en},
	urldate = {2019-01-15},
	journal = {bioRxiv},
	author = {Kashyap, Rajan and Kong, Ru and Bhattacharjee, Sagarika and Li, Jingwei and Zhou, Juan and Yeo, B. T. Thomas},
	month = jan,
	year = {2019},
	pages = {515742},
	file = {Full Text PDF:/Users/tito/Zotero/storage/B7KR6LNE/Kashyap et al. - 2019 - Individual-Specific fMRI-Subspaces Improve Functio.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4NJUT4LJ/515742.html:text/html},
}

@article{hebart_deconstructing_2018,
	series = {New advances in encoding and decoding of brain signals},
	title = {Deconstructing multivariate decoding for the study of brain function},
	volume = {180},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917306523},
	doi = {10.1016/j.neuroimage.2017.08.005},
	abstract = {Multivariate decoding methods were developed originally as tools to enable accurate predictions in real-world applications. The realization that these methods can also be employed to study brain function has led to their widespread adoption in the neurosciences. However, prior to the rise of multivariate decoding, the study of brain function was firmly embedded in a statistical philosophy grounded on univariate methods of data analysis. In this way, multivariate decoding for brain interpretation grew out of two established frameworks: multivariate decoding for predictions in real-world applications, and classical univariate analysis based on the study and interpretation of brain activation. We argue that this led to two confusions, one reflecting a mixture of multivariate decoding for prediction or interpretation, and the other a mixture of the conceptual and statistical philosophies underlying multivariate decoding and classical univariate analysis. Here we attempt to systematically disambiguate multivariate decoding for the study of brain function from the frameworks it grew out of. After elaborating these confusions and their consequences, we describe six, often unappreciated, differences between classical univariate analysis and multivariate decoding. We then focus on how the common interpretation of what is signal and noise changes in multivariate decoding. Finally, we use four examples to illustrate where these confusions may impact the interpretation of neuroimaging data. We conclude with a discussion of potential strategies to help resolve these confusions in interpreting multivariate decoding results, including the potential departure from multivariate decoding methods for the study of brain function.},
	urldate = {2019-01-15},
	journal = {NeuroImage},
	author = {Hebart, Martin N. and Baker, Chris I.},
	month = oct,
	year = {2018},
	keywords = {fMRI, Multivariate analysis, Decoding, Multivariate pattern analysis, Encoding, Multivariate decoding, Prediction},
	pages = {4--18},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/LEE4YL4J/Hebart and Baker - 2018 - Deconstructing multivariate decoding for the study.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/YF2FFU32/S1053811917306523.html:text/html},
}

@article{hipp_oscillatory_2011,
	title = {Oscillatory {Synchronization} in {Large}-{Scale} {Cortical} {Networks} {Predicts} {Perception}},
	volume = {69},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(10)01075-5},
	doi = {10.1016/j.neuron.2010.12.027},
	language = {English},
	number = {2},
	urldate = {2019-01-22},
	journal = {Neuron},
	author = {Hipp, Joerg F. and Engel, Andreas K. and Siegel, Markus},
	month = jan,
	year = {2011},
	pmid = {21262474},
	pages = {387--396},
	file = {Full Text PDF:/Users/tito/Zotero/storage/6V98K6HK/Hipp et al. - 2011 - Oscillatory Synchronization in Large-Scale Cortica.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/QK8APNJU/S0896-6273(10)01075-5.html:text/html},
}

@article{mars_connectivity_2018,
	title = {Connectivity {Fingerprints}: {From} {Areal} {Descriptions} to {Abstract} {Spaces}},
	volume = {22},
	issn = {1364-6613, 1879-307X},
	shorttitle = {Connectivity {Fingerprints}},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(18)30209-2},
	doi = {10.1016/j.tics.2018.08.009},
	language = {English},
	number = {11},
	urldate = {2019-01-22},
	journal = {Trends in Cognitive Sciences},
	author = {Mars, Rogier B. and Passingham, Richard E. and Jbabdi, Saad},
	month = nov,
	year = {2018},
	pmid = {30241910},
	keywords = {individual differences, connectivity, brain organization, comparative anatomy, gradient},
	pages = {1026--1037},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HNYP3MRT/Mars et al. - 2018 - Connectivity Fingerprints From Areal Descriptions.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/YJSU4HZ7/S1364-6613(18)30209-2.html:text/html},
}

@article{haak_connectopic_2018,
	series = {Segmenting the {Brain}},
	title = {Connectopic mapping with resting-state {fMRI}},
	volume = {170},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305463},
	doi = {10.1016/j.neuroimage.2017.06.075},
	abstract = {Brain regions are often topographically connected: nearby locations within one brain area connect with nearby locations in another area. Mapping these connection topographies, or ‘connectopies’ in short, is crucial for understanding how information is processed in the brain. Here, we propose principled, fully data-driven methods for mapping connectopies using functional magnetic resonance imaging (fMRI) data acquired at rest by combining spectral embedding of voxel-wise connectivity ‘fingerprints’ with a novel approach to spatial statistical inference. We apply the approach in human primary motor and visual cortex, and show that it can trace biologically plausible, overlapping connectopies in individual subjects that follow these regions' somatotopic and retinotopic maps. As a generic mechanism to perform inference over connectopies, the new spatial statistics approach enables rigorous statistical testing of hypotheses regarding the fine-grained spatial profile of functional connectivity and whether that profile is different between subjects or between experimental conditions. The combined framework offers a fundamental alternative to existing approaches to investigating functional connectivity in the brain, from voxel- or seed-pair wise characterizations of functional association, towards a full, multivariate characterization of spatial topography.},
	urldate = {2019-01-23},
	journal = {NeuroImage},
	author = {Haak, Koen V. and Marquand, Andre F. and Beckmann, Christian F.},
	month = apr,
	year = {2018},
	keywords = {Functional connectivity, Resting-state fMRI, Manifold learning, Spatial statistics, Topographic maps},
	pages = {83--94},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/2U664DEH/Haak et al. - 2018 - Connectopic mapping with resting-state fMRI.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/ZTPTWNY4/S1053811917305463.html:text/html},
}

@article{passingham_anatomical_2002,
	title = {The anatomical basis of functional localization in the cortex},
	volume = {3},
	copyright = {2002 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn893},
	doi = {10.1038/nrn893},
	abstract = {The functions of a cortical area are determined by its extrinsic connections and intrinsic properties. Using the database CoCoMac, we show that each cortical area has a unique pattern of cortico-cortical connections — a 'connectional fingerprint'. We present examples of such fingerprints and use statistical analysis to show that no two areas share identical patterns. We suggest that the connectional fingerprint underlies the observed cell-firing differences between areas during different tasks. We refer to this pattern as a 'functional fingerprint' and present examples of such fingerprints. In addition to electrophysiological analysis, functional fingerprints can be determined by functional brain imaging. We argue that imaging provides a useful way to define such fingerprints because it is possible to compare activations across many cortical areas and across a wide range of tasks.},
	language = {en},
	number = {8},
	urldate = {2019-01-23},
	journal = {Nature Reviews Neuroscience},
	author = {Passingham, Richard E. and Stephan, Klaas E. and Kötter, Rolf},
	month = aug,
	year = {2002},
	pages = {606--616},
	file = {Full Text PDF:/Users/tito/Zotero/storage/TF437BTX/Passingham et al. - 2002 - The anatomical basis of functional localization in.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5Q4W7HHF/nrn893.html:text/html},
}

@article{saygin_connectivity_2016,
	title = {Connectivity precedes function in the development of the visual word form area},
	volume = {19},
	copyright = {2016 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.4354},
	doi = {10.1038/nn.4354},
	abstract = {What determines the cortical location at which a given functionally specific region will arise in development? We tested the hypothesis that functionally specific regions develop in their characteristic locations because of pre-existing differences in the extrinsic connectivity of that region to the rest of the brain. We exploited the visual word form area (VWFA) as a test case, scanning children with diffusion and functional imaging at age 5, before they learned to read, and at age 8, after they learned to read. We found the VWFA developed functionally in this interval and that its location in a particular child at age 8 could be predicted from that child's connectivity fingerprints (but not functional responses) at age 5. These results suggest that early connectivity instructs the functional development of the VWFA, possibly reflecting a general mechanism of cortical development.},
	language = {en},
	number = {9},
	urldate = {2019-01-23},
	journal = {Nature Neuroscience},
	author = {Saygin, Zeynep M. and Osher, David E. and Norton, Elizabeth S. and Youssoufian, Deanna A. and Beach, Sara D. and Feather, Jenelle and Gaab, Nadine and Gabrieli, John D. E. and Kanwisher, Nancy},
	month = sep,
	year = {2016},
	pages = {1250--1255},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WRDBGRZF/Saygin et al. - 2016 - Connectivity precedes function in the development .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/YESDZB5H/nn.html:text/html},
}

@article{olshausen_sparse_2004,
	title = {Sparse coding of sensory inputs},
	volume = {14},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438804001035},
	doi = {10.1016/j.conb.2004.07.007},
	abstract = {Several theoretical, computational, and experimental studies suggest that neurons encode sensory information using a small number of active neurons at any given point in time. This strategy, referred to as ‘sparse coding’, could possibly confer several advantages. First, it allows for increased storage capacity in associative memories; second, it makes the structure in natural signals explicit; third, it represents complex data in a way that is easier to read out at subsequent levels of processing; and fourth, it saves energy. Recent physiological recordings from sensory neurons have indicated that sparse coding could be a ubiquitous strategy employed in several different modalities across different organisms.},
	number = {4},
	urldate = {2019-01-23},
	journal = {Current Opinion in Neurobiology},
	author = {Olshausen, Bruno A and Field, David J},
	month = aug,
	year = {2004},
	pages = {481--487},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/QDUNMDKI/Olshausen and Field - 2004 - Sparse coding of sensory inputs.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3T5NPIDK/S0959438804001035.html:text/html},
}

@article{hedrick_megamap:_2016,
	title = {Megamap: flexible representation of a large space embedded with nonspatial information by a hippocampal attractor network},
	volume = {116},
	issn = {0022-3077},
	shorttitle = {Megamap},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00856.2015},
	doi = {10.1152/jn.00856.2015},
	abstract = {The problem of how the hippocampus encodes both spatial and nonspatial information at the cellular network level remains largely unresolved. Spatial memory is widely modeled through the theoretical framework of attractor networks, but standard computational models can only represent spaces that are much smaller than the natural habitat of an animal. We propose that hippocampal networks are built on a basic unit called a “megamap,” or a cognitive attractor map in which place cells are flexibly recombined to represent a large space. Its inherent flexibility gives the megamap a huge representational capacity and enables the hippocampus to simultaneously represent multiple learned memories and naturally carry nonspatial information at no additional cost. On the other hand, the megamap is dynamically stable, because the underlying network of place cells robustly encodes any location in a large environment given a weak or incomplete input signal from the upstream entorhinal cortex. Our results suggest a general computational strategy by which a hippocampal network enjoys the stability of attractor dynamics without sacrificing the flexibility needed to represent a complex, changing world.},
	number = {2},
	urldate = {2019-01-23},
	journal = {Journal of Neurophysiology},
	author = {Hedrick, Kathryn R. and Zhang, Kechen},
	month = may,
	year = {2016},
	pages = {868--891},
	file = {Snapshot:/Users/tito/Zotero/storage/X8FST69Q/jn.00856.html:text/html},
}

@article{jbabdi_topographic_2013,
	series = {Macrocircuits},
	title = {The topographic connectome},
	volume = {23},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438812001936},
	doi = {10.1016/j.conb.2012.12.004},
	abstract = {Central to macro-connectomics and much of systems neuroscience is the idea that we can summarise macroscopic brain connectivity using a network of ‘nodes’ and ‘edges’—functionally distinct brain regions and the connections between them. This is an approach that allows a deep understanding of brain dynamics and how they relate to brain circuitry. This approach, however, ignores key features of anatomical connections, such as spatial arrangement and topographic mappings. In this article, we suggest an alternative to this paradigm. We propose that connection topographies can inform us about brain networks in ways that are complementary to the concepts of ‘nodes’ and ‘edges’. We also show that current neuroimaging technology is capable of revealing details of connection topographies in vivo. These advances, we hope, will allow us to explore brain connectivity in novel ways in the immediate future.},
	number = {2},
	urldate = {2019-01-23},
	journal = {Current Opinion in Neurobiology},
	author = {Jbabdi, Saad and Sotiropoulos, Stamatios N and Behrens, Timothy E},
	month = apr,
	year = {2013},
	pages = {207--215},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/KCUSV4KL/Jbabdi et al. - 2013 - The topographic connectome.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/TBLB9Y5J/S0959438812001936.html:text/html},
}

@article{pesaran_investigating_2018,
	title = {Investigating large-scale brain dynamics using field potential recordings: analysis and interpretation},
	volume = {21},
	copyright = {2018 The Author(s)},
	issn = {1546-1726},
	shorttitle = {Investigating large-scale brain dynamics using field potential recordings},
	url = {https://www.nature.com/articles/s41593-018-0171-8},
	doi = {10.1038/s41593-018-0171-8},
	abstract = {This article presents best practices on how field potential recordings (EEG, MEG, ECoG and LFP) can be analyzed to identify large-scale brain dynamics, and highlights issues and limitations of interpretation.},
	language = {En},
	number = {7},
	urldate = {2019-01-23},
	journal = {Nature Neuroscience},
	author = {Pesaran, Bijan and Vinck, Martin and Einevoll, Gaute T. and Sirota, Anton and Fries, Pascal and Siegel, Markus and Truccolo, Wilson and Schroeder, Charles E. and Srinivasan, Ramesh},
	month = jul,
	year = {2018},
	pages = {903},
	file = {Full Text PDF:/Users/tito/Zotero/storage/SXL3T8LB/Pesaran et al. - 2018 - Investigating large-scale brain dynamics using fie.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DE4CHD42/s41593-018-0171-8.html:text/html},
}

@article{gershman_what_2019,
	title = {What does the free energy principle tell us about the brain?},
	url = {http://arxiv.org/abs/1901.07945},
	abstract = {The free energy principle has been proposed as a unifying theory of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.},
	urldate = {2019-01-24},
	journal = {arXiv:1901.07945 [q-bio]},
	author = {Gershman, Samuel J.},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.07945},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv\:1901.07945 PDF:/Users/tito/Zotero/storage/PAYNELG5/Gershman - 2019 - What does the free energy principle tell us about .pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/QPFP83PK/1901.html:text/html},
}

@article{huang_circuit_2019,
	title = {Circuit {Models} of {Low}-{Dimensional} {Shared} {Variability} in {Cortical} {Networks}},
	volume = {101},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(18)31043-2},
	doi = {10.1016/j.neuron.2018.11.034},
	language = {English},
	number = {2},
	urldate = {2019-01-26},
	journal = {Neuron},
	author = {Huang, Chengcheng and Ruff, Douglas A. and Pyle, Ryan and Rosenbaum, Robert and Cohen, Marlene R. and Doiron, Brent},
	month = jan,
	year = {2019},
	pmid = {30581012},
	keywords = {noise correlations, attention, cortical model, excitatory/inhibitory balance, low dimensional, neuronal variability},
	pages = {337--348.e4},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WSFFN8TG/Huang et al. - 2019 - Circuit Models of Low-Dimensional Shared Variabili.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/C7XBN6IF/S0896-6273(18)31043-2.html:text/html},
}

@article{lindquist_modular_nodate,
	title = {Modular preprocessing pipelines can reintroduce artifacts into {fMRI} data},
	volume = {0},
	copyright = {© 2019 Wiley Periodicals, Inc.},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24528},
	doi = {10.1002/hbm.24528},
	abstract = {The preprocessing pipelines typically used in both task and resting-state functional magnetic resonance imaging (rs-fMRI) analysis are modular in nature: They are composed of a number of separate filtering/regression steps, including removal of head motion covariates and band-pass filtering, performed sequentially and in a flexible order. In this article, we illustrate the shortcomings of this approach, as we show how later preprocessing steps can reintroduce artifacts previously removed from the data in prior preprocessing steps. We show that each regression step is a geometric projection of data onto a subspace, and that performing a sequence of projections can move the data into subspaces no longer orthogonal to those previously removed, reintroducing signal related to nuisance covariates. Thus, linear filtering operations are not commutative, and the order in which the preprocessing steps are performed is critical. These issues can arise in practice when any combination of standard preprocessing steps including motion regression, scrubbing, component-based correction, physiological correction, global signal regression, and temporal filtering are performed sequentially. In this work, we focus primarily on rs-fMRI. We illustrate the problem both theoretically and empirically through application to a test–retest rs-fMRI data set, and suggest remedies. These include (a) combining all steps into a single linear filter, or (b) sequential orthogonalization of covariates/linear filters performed in series.},
	language = {en},
	number = {0},
	urldate = {2019-01-28},
	journal = {Human Brain Mapping},
	author = {Lindquist, Martin A. and Geuter, Stephan and Wager, Tor D. and Caffo, Brian S.},
	keywords = {fMRI, preprocessing, artifacts, motion, resting-state},
	file = {Full Text PDF:/Users/tito/Zotero/storage/UUXR6A4C/Lindquist et al. - Modular preprocessing pipelines can reintroduce ar.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/V8WR3JAI/hbm.html:text/html},
}

@article{kietzmann_deep_2019,
	title = {Deep {Neural} {Networks} in {Computational} {Neuroscience}},
	url = {http://oxfordre.com/view/10.1093/acrefore/9780190264086.001.0001/acrefore-9780190264086-e-46},
	doi = {10.1093/acrefore/9780190264086.013.46},
	abstract = {The goal of computational neuroscience is to find mechanistic explanations of how the nervous system processes information to give rise to cognitive function and behavior. At the heart of the field are its models, that is, mathematical and computational descriptions of the system being studied, which map sensory stimuli to neural responses and/or neural to behavioral responses. These models range from simple to complex. Recently, deep neural networks (DNNs) have come to dominate several domains of artificial intelligence (AI). As the term “neural network” suggests, these models are inspired by biological brains. However, current DNNs neglect many details of biological neural networks. These simplifications contribute to their computational efficiency, enabling them to perform complex feats of intelligence, ranging from perceptual (e.g., visual object and auditory speech recognition) to cognitive tasks (e.g., machine translation), and on to motor control (e.g., playing computer games or controlling a robot arm). In addition to their ability to model complex intelligent behaviors, DNNs excel at predicting neural responses to novel sensory stimuli with accuracies well beyond any other currently available model type. DNNs can have millions of parameters, which are required to capture the domain knowledge needed for successful task performance. Contrary to the intuition that this renders them into impenetrable black boxes, the computational properties of the network units are the result of four directly manipulable elements: input statistics, network structure, functional objective, and learning algorithm. With full access to the activity and connectivity of all units, advanced visualization techniques, and analytic tools to map network representations to neural data, DNNs represent a powerful framework for building task-performing models and will drive substantial insights in computational neuroscience.},
	language = {en},
	urldate = {2019-01-28},
	journal = {Oxford Research Encyclopedia of Neuroscience},
	author = {Kietzmann, Tim C. and McClure, Patrick and Kriegeskorte, Nikolaus},
	month = jan,
	year = {2019},
	file = {Snapshot:/Users/tito/Zotero/storage/N2Y6XKDX/acrefore-9780190264086-e-46.html:text/html},
}

@article{kietzmann_deep_2018,
	title = {Deep {Neural} {Networks} {In} {Computational} {Neuroscience}},
	url = {http://biorxiv.org/lookup/doi/10.1101/133504},
	doi = {10.1101/133504},
	abstract = {The goal of computational neuroscience is to find mechanistic explanations of how the nervous system processes information to give rise to cognitive function and behaviour. At the heart of the field are its models, i.e. mathematical and computational descriptions of the system being studied, which map sensory stimuli to neural responses and/or neural to behavioural responses. These models range from simple to complex. Recently, deep neural networks (DNNs) have come to dominate several domains of artificial intelligence (AI). As the term 'neural network' suggests, these models are inspired by biological brains. However, current DNNs neglect many details of biological neural networks. These simplifications contribute to their computational efficiency, enabling them to perform complex feats of intelligence, ranging from perceptual (e.g. visual object and auditory speech recognition) to cognitive tasks (e.g. machine translation), and on to motor control (e.g. playing computer games or controlling a robot arm). In addition to their ability to model complex intelligent behaviours, DNNs excel at predicting neural responses to novel sensory stimuli with accuracies well beyond any other currently available model type. DNNs can have millions of parameters, which are required to capture the domain knowledge needed for successful task performance. Contrary to the intuition that this renders them into impenetrable black boxes, the computational properties of the network units are the result of four directly manipulable elements: input statistics, network structure, functional objective, and learning algorithm. With full access to the activity and connectivity of all units, advanced visualization techniques, and analytic tools to map network representations to neural data, DNNs represent a powerful framework for building task-performing models and will drive substantial insights in computational neuroscience.},
	language = {en},
	urldate = {2019-01-28},
	journal = {bioRxiv},
	author = {Kietzmann, Tim Christian and McClure, Patrick and Kriegeskorte, Nikolaus},
	month = jun,
	year = {2018},
	file = {Kietzmann et al. - 2018 - Deep Neural Networks In Computational Neuroscience.pdf:/Users/tito/Zotero/storage/GY66GSFH/Kietzmann et al. - 2018 - Deep Neural Networks In Computational Neuroscience.pdf:application/pdf},
}

@article{etzel_searchlight_2013,
	title = {Searchlight analysis: {Promise}, pitfalls, and potential},
	volume = {78},
	issn = {1053-8119},
	shorttitle = {Searchlight analysis},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913002917},
	doi = {10.1016/j.neuroimage.2013.03.041},
	abstract = {Multivariate pattern analysis (MVPA) is an increasingly popular approach for characterizing the information present in neural activity as measured by fMRI. For neuroimaging researchers, the searchlight technique serves as the most intuitively appealing means of implementing MVPA with fMRI data. However, searchlight approaches carry with them a number of special concerns and limitations that can lead to serious interpretation errors in practice, such as misidentifying a cluster as informative, or failing to detect truly informative voxels. Here we describe how such distorted results can occur, using both schematic illustrations and examples from actual fMRI datasets. We recommend that confirmatory and sensitivity tests, such as the ones prescribed here, should be considered a necessary stage of searchlight analysis interpretation, and that their adoption will allow the full potential of searchlight analysis to be realized.},
	urldate = {2019-01-28},
	journal = {NeuroImage},
	author = {Etzel, Joset A. and Zacks, Jeffrey M. and Braver, Todd S.},
	month = sep,
	year = {2013},
	keywords = {Classification, Functional magnetic resonance imaging (fMRI), Information mapping, Multivariate pattern analysis (MVPA), Searchlight analysis, Support vector machines (SVM)},
	pages = {261--269},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/JXJ9HJQX/Etzel et al. - 2013 - Searchlight analysis Promise, pitfalls, and poten.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/TCXWZPPY/S1053811913002917.html:text/html},
}

@article{ruff_attention_2014,
	title = {Attention can either increase or decrease spike count correlations in visual cortex},
	volume = {17},
	copyright = {2014 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3835},
	doi = {10.1038/nn.3835},
	abstract = {Visual attention enhances the responses of visual neurons that encode the attended location. Several recent studies have shown that attention also decreases correlations between fluctuations in the responses of pairs of neurons (termed spike count correlation or rSC). These results are consistent with two hypotheses. First, attention-related changes in rate and rSC might be linked (perhaps through a common mechanism), with attention always decreasing rSC. Second, attention might either increase or decrease rSC, possibly depending on the role of the neurons in the behavioral task. We recorded simultaneously from dozens of neurons in area V4 while monkeys performed a discrimination task. We found strong evidence in favor of the second hypothesis, showing that attention can flexibly increase or decrease correlations depending on whether the neurons provide evidence for the same or opposite choices. These results place important constraints on models of the neuronal mechanisms underlying cognitive factors.},
	language = {en},
	number = {11},
	urldate = {2019-01-29},
	journal = {Nature Neuroscience},
	author = {Ruff, Douglas A. and Cohen, Marlene R.},
	month = nov,
	year = {2014},
	pages = {1591--1597},
	file = {Full Text PDF:/Users/tito/Zotero/storage/JD4ICTBV/Ruff and Cohen - 2014 - Attention can either increase or decrease spike co.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/STAJF2ID/nn.html:text/html},
}

@article{ruff_attention_2016,
	title = {Attention {Increases} {Spike} {Count} {Correlations} between {Visual} {Cortical} {Areas}},
	volume = {36},
	copyright = {Copyright © 2016 the authors 0270-6474/16/367523-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/36/28/7523},
	doi = {10.1523/JNEUROSCI.0610-16.2016},
	abstract = {Visual attention, which improves perception of attended locations or objects, has long been known to affect many aspects of the responses of neuronal populations in visual cortex. There are two nonmutually exclusive hypotheses concerning the neuronal mechanisms that underlie these perceptual improvements. The first hypothesis, that attention improves the information encoded by a population of neurons in a particular cortical area, has considerable physiological support. The second hypothesis is that attention improves perception by selectively communicating relevant visual information. This idea has been tested primarily by measuring interactions between neurons on very short timescales, which are mathematically nearly independent of neuronal interactions on longer timescales. We tested the hypothesis that attention changes the way visual information is communicated between cortical areas on longer timescales by recording simultaneously from neurons in primary visual cortex (V1) and the middle temporal area (MT) in rhesus monkeys. We used two independent and complementary approaches. Our correlative experiment showed that attention increases the trial-to-trial response variability that is shared between the two areas. In our causal experiment, we electrically microstimulated V1 and found that attention increased the effect of stimulation on MT responses. Together, our results suggest that attention affects both the way visual stimuli are encoded within a cortical area and the extent to which visual information is communicated between areas on behaviorally relevant timescales.
SIGNIFICANCE STATEMENT Visual attention dramatically improves the perception of attended stimuli. Attention has long been thought to act by selecting relevant visual information for further processing. It has been hypothesized that this selection is accomplished by increasing communication between neurons that encode attended information in different cortical areas. We recorded simultaneously from neurons in primary visual cortex and the middle temporal area while rhesus monkeys performed an attention task. We found that attention increased shared variability between neurons in the two areas and that attention increased the effect of microstimulation in V1 on the firing rates of MT neurons. Our results provide support for the hypothesis that attention increases communication between neurons in different brain areas on behaviorally relevant timescales.},
	language = {en},
	number = {28},
	urldate = {2019-01-29},
	journal = {J. Neurosci.},
	author = {Ruff, Douglas A. and Cohen, Marlene R.},
	month = jul,
	year = {2016},
	pmid = {27413161},
	keywords = {attention, variability, primary visual cortex, middle temporal area},
	pages = {7523--7534},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HHDI6QRA/Ruff and Cohen - 2016 - Attention Increases Spike Count Correlations betwe.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/2P2M3AXM/7523.html:text/html},
}

@article{ruff_stimulus_2016,
	title = {Stimulus {Dependence} of {Correlated} {Variability} across {Cortical} {Areas}},
	volume = {36},
	copyright = {Copyright © 2016 the authors 0270-6474/16/367546-11\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/36/28/7546},
	doi = {10.1523/JNEUROSCI.0504-16.2016},
	abstract = {The way that correlated trial-to-trial variability between pairs of neurons in the same brain area (termed spike count or noise correlation, rSC) depends on stimulus or task conditions can constrain models of cortical circuits and of the computations performed by networks of neurons (Cohen and Kohn, 2011). In visual cortex, rSC tends not to depend on stimulus properties (Kohn and Smith, 2005; Huang and Lisberger, 2009) but does depend on cognitive factors like visual attention (Cohen and Maunsell, 2009; Mitchell et al., 2009). However, neurons across visual areas respond to any visual stimulus or contribute to any perceptual decision, and the way that information from multiple areas is combined to guide perception is unknown. To gain insight into these issues, we recorded simultaneously from neurons in two areas of visual cortex (primary visual cortex, V1, and the middle temporal area, MT) while rhesus monkeys viewed different visual stimuli in different attention conditions. We found that correlations between neurons in different areas depend on stimulus and attention conditions in very different ways than do correlations within an area. Correlations across, but not within, areas depend on stimulus direction and the presence of a second stimulus, and attention has opposite effects on correlations within and across areas. This observed pattern of cross-area correlations is predicted by a normalization model where MT units sum V1 inputs that are passed through a divisive nonlinearity. Together, our results provide insight into how neurons in different areas interact and constrain models of the neural computations performed across cortical areas.
SIGNIFICANCE STATEMENT Correlations in the responses of pairs of neurons within the same cortical area have been a subject of growing interest in systems neuroscience. However, correlated variability between different cortical areas is likely just as important. We recorded simultaneously from neurons in primary visual cortex and the middle temporal area while rhesus monkeys viewed different visual stimuli in different attention conditions. We found that correlations between neurons in different areas depend on stimulus and attention conditions in very different ways than do correlations within an area. The observed pattern of cross-area correlations was predicted by a simple normalization model. Our results provide insight into how neurons in different areas interact and constrain models of the neural computations performed across cortical areas.},
	language = {en},
	number = {28},
	urldate = {2019-01-29},
	journal = {J. Neurosci.},
	author = {Ruff, Douglas A. and Cohen, Marlene R.},
	month = jul,
	year = {2016},
	pmid = {27413163},
	keywords = {MT, V1, attention, variability, normalization, population coding},
	pages = {7546--7556},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WHP9GRYG/Ruff and Cohen - 2016 - Stimulus Dependence of Correlated Variability acro.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VNJ8UBZJ/7546.html:text/html},
}

@article{mattar_functional_2015,
	title = {A {Functional} {Cartography} of {Cognitive} {Systems}},
	volume = {11},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004533},
	doi = {10.1371/journal.pcbi.1004533},
	abstract = {One of the most remarkable features of the human brain is its ability to adapt rapidly and efficiently to external task demands. Novel and non-routine tasks, for example, are implemented faster than structural connections can be formed. The neural underpinnings of these dynamics are far from understood. Here we develop and apply novel methods in network science to quantify how patterns of functional connectivity between brain regions reconfigure as human subjects perform 64 different tasks. By applying dynamic community detection algorithms, we identify groups of brain regions that form putative functional communities, and we uncover changes in these groups across the 64-task battery. We summarize these reconfiguration patterns by quantifying the probability that two brain regions engage in the same network community (or putative functional module) across tasks. These tools enable us to demonstrate that classically defined cognitive systems—including visual, sensorimotor, auditory, default mode, fronto-parietal, cingulo-opercular and salience systems—engage dynamically in cohesive network communities across tasks. We define the network role that a cognitive system plays in these dynamics along the following two dimensions: (i) stability vs. flexibility and (ii) connected vs. isolated. The role of each system is therefore summarized by how stably that system is recruited over the 64 tasks, and how consistently that system interacts with other systems. Using this cartography, classically defined cognitive systems can be categorized as ephemeral integrators, stable loners, and anything in between. Our results provide a new conceptual framework for understanding the dynamic integration and recruitment of cognitive systems in enabling behavioral adaptability across both task and rest conditions. This work has important implications for understanding cognitive network reconfiguration during different task sets and its relationship to cognitive effort, individual variation in cognitive performance, and fatigue.},
	language = {en},
	number = {12},
	urldate = {2019-02-05},
	journal = {PLOS Computational Biology},
	author = {Mattar, Marcelo G. and Cole, Michael W. and Thompson-Schill, Sharon L. and Bassett, Danielle S.},
	month = dec,
	year = {2015},
	keywords = {Attention, Behavior, Cognition, Memory, Vision, Community structure, Mathematical models, Neural networks},
	pages = {e1004533},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HTXN6HKE/Mattar et al. - 2015 - A Functional Cartography of Cognitive Systems.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/8QFC8E5L/article.html:text/html},
}

@article{shine_human_2019,
	title = {Human cognition involves the dynamic integration of neural activity and neuromodulatory systems},
	volume = {22},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0312-0},
	doi = {10.1038/s41593-018-0312-0},
	abstract = {Neuronal activity across task states converges onto a low-dimensional manifold. Flow within this attractor space covaries with network-level topology, fluid intelligence, and regional differences in the density of neuromodulatory receptors.},
	language = {En},
	number = {2},
	urldate = {2019-02-06},
	journal = {Nature Neuroscience},
	author = {Shine, James M. and Breakspear, Michael and Bell, Peter T. and Martens, Kayla Ehgoetz and Shine, Richard and Koyejo, Oluwasanmi and Sporns, Olaf and Poldrack, Russell A.},
	month = feb,
	year = {2019},
	pages = {289},
	file = {Full Text PDF:/Users/tito/Zotero/storage/6XMLYBZS/Shine et al. - 2019 - Human cognition involves the dynamic integration o.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JKKL94L4/s41593-018-0312-0.html:text/html},
}

@article{deco_hierarchy_2017,
	title = {Hierarchy of {Information} {Processing} in the {Brain}: {A} {Novel} ‘{Intrinsic} {Ignition}’ {Framework}},
	volume = {94},
	issn = {0896-6273},
	shorttitle = {Hierarchy of {Information} {Processing} in the {Brain}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627317302404},
	doi = {10.1016/j.neuron.2017.03.028},
	abstract = {A general theory of brain function has to be able to explain local and non-local network computations over space and time. We propose a new framework to capture the key principles of how local activity influences global computation, i.e., describing the propagation of information and thus the broadness of communication driven by local activity. More specifically, we consider the diversity in space (nodes or brain regions) over time using the concept of intrinsic ignition, which are naturally occurring intrinsic perturbations reflecting the capability of a given brain area to propagate neuronal activity to other regions in a given brain state. Characterizing the profile of intrinsic ignition for a given brain state provides insight into the precise nature of hierarchical information processing. Combining this data-driven method with a causal whole-brain computational model can provide novel insights into the imbalance of brain states found in neuropsychiatric disorders.},
	number = {5},
	urldate = {2019-02-06},
	journal = {Neuron},
	author = {Deco, Gustavo and Kringelbach, Morten L.},
	month = jun,
	year = {2017},
	keywords = {computational modeling, binding, brain function, brain state, ignition, perturbation, whole-brain modeling},
	pages = {961--968},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/ADBUA7GW/Deco and Kringelbach - 2017 - Hierarchy of Information Processing in the Brain .pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/M7M4P8VF/S0896627317302404.html:text/html},
}

@article{muthukrishna_problem_2019,
	title = {A problem in theory},
	copyright = {2019 Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-018-0522-1},
	doi = {10.1038/s41562-018-0522-1},
	abstract = {Muthukrishna \&amp; Henrich argue that solving the replication crisis in psychology partly requires well-specified, overarching theoretical frameworks. They outline how dual inheritance theory provides one such example that could be adopted by the field.},
	language = {En},
	urldate = {2019-02-12},
	journal = {Nature Human Behaviour},
	author = {Muthukrishna, Michael and Henrich, Joseph},
	month = feb,
	year = {2019},
	pages = {1},
	file = {Muthukrishna and Henrich - 2019 - A problem in theory.pdf:/Users/tito/Zotero/storage/CQU47LW5/Muthukrishna and Henrich - 2019 - A problem in theory.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9Z96U762/s41562-018-0522-1.html:text/html},
}

@article{cole_task_2017,
	series = {The power of instructions: the influence of instructions on cognition, behaviour and physical states},
	title = {The task novelty paradox: {Flexible} control of inflexible neural pathways during rapid instructed task learning},
	volume = {81},
	issn = {0149-7634},
	shorttitle = {The task novelty paradox},
	url = {http://www.sciencedirect.com/science/article/pii/S0149763416306637},
	doi = {10.1016/j.neubiorev.2017.02.009},
	abstract = {Rapid instructed task learning (RITL) is one of the most remarkable human abilities, when considered from both computational and evolutionary perspectives. A key feature of RITL is that it enables new goals to be immediately pursued (and shared) following formation of task representations. Although RITL is a form of cognitive control that engenders immense flexibility, it also seems to produce inflexible activation of action plans in inappropriate contexts. We argue that this “prepared reflex” effect arises because RITL is implemented in the brain via a “flexible hub” mechanism, in which top-down influences from the frontoparietal control network reroute pathways among procedure-implementing brain areas (e.g., perceptual and motor areas). Specifically, we suggest that RITL-based proactive control – the preparatory biasing of task-relevant functional network routes – results in inflexible associative processing, demanding compensation in the form of increased reactive (in-the-moment) control. Thus, RITL produces a computational trade-off, in which the top-down influences of flexible hubs increase overall cognitive flexibility, but at the cost of temporally localized inflexibility (the prepared reflex effect).},
	urldate = {2019-02-12},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Cole, Michael W. and Braver, Todd S. and Meiran, Nachshon},
	month = oct,
	year = {2017},
	keywords = {Functional connectivity, Neuroimaging, Executive functions, Cognitive control, Automaticity, Instructed learning, Network science},
	pages = {4--15},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/YJKEH6VR/Cole et al. - 2017 - The task novelty paradox Flexible control of infl.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/I3HQ9H2F/S0149763416306637.html:text/html},
}

@article{bassett_nature_2018,
	title = {On the nature and use of models in network neuroscience},
	volume = {19},
	copyright = {2018 Macmillan Publishers Ltd., part of Springer Nature},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-018-0038-8},
	doi = {10.1038/s41583-018-0038-8},
	abstract = {Modern network neuroscience involves the use of various types of models to understand the brain. In this Review, Bassett, Zurn and Gold discuss the aims of this approach before examining how network models may be categorized and validated.},
	language = {En},
	number = {9},
	urldate = {2019-02-14},
	journal = {Nature Reviews Neuroscience},
	author = {Bassett, Danielle S. and Zurn, Perry and Gold, Joshua I.},
	month = sep,
	year = {2018},
	pages = {566},
	file = {Full Text PDF:/Users/tito/Zotero/storage/A46A658T/Bassett et al. - 2018 - On the nature and use of models in network neurosc.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/EE48YJ5T/s41583-018-0038-8.html:text/html},
}

@article{duncan_multiple-demand_2010,
	title = {The multiple-demand ({MD}) system of the primate brain: mental programs for intelligent behaviour},
	volume = {14},
	issn = {1364-6613},
	shorttitle = {The multiple-demand ({MD}) system of the primate brain},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661310000057},
	doi = {10.1016/j.tics.2010.01.004},
	abstract = {A common or multiple-demand (MD) pattern of frontal and parietal activity is associated with diverse cognitive demands, and with standard tests of fluid intelligence. In intelligent behaviour, goals are achieved by assembling a series of sub-tasks, creating structured mental programs. Single cell and functional magnetic resonance imaging (fMRI) data indicate a key role for MD cortex in defining and controlling the parts of such programs, with focus on the specific content of a current cognitive operation, rapid reorganization as mental focus is changed, and robust separation of successive task steps. Resembling the structured problem-solving of symbolic artificial intelligence, the mental programs of MD cortex appear central to intelligent thought and action.},
	number = {4},
	urldate = {2019-02-14},
	journal = {Trends in Cognitive Sciences},
	author = {Duncan, John},
	month = apr,
	year = {2010},
	pages = {172--179},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/W44K8KYR/Duncan - 2010 - The multiple-demand (MD) system of the primate bra.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/EPR2CG8W/S1364661310000057.html:text/html},
}

@article{fedorenko_broad_2013,
	title = {Broad domain generality in focal regions of frontal and parietal cortex},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2013/09/20/1315235110},
	doi = {10.1073/pnas.1315235110},
	abstract = {Unlike brain regions that respond selectively to specific kinds of information content, a number of frontal and parietal regions are thought to be domain- and process-general: that is, active during a wide variety of demanding cognitive tasks. However, most previous evidence for this functional generality in humans comes from methods that overestimate activation overlap across tasks. Here we present functional MRI evidence from single-subject analyses for broad functional generality of a specific set of brain regions: the same sets of voxels are engaged across tasks ranging from arithmetic to storing information in working memory, to inhibiting irrelevant information. These regions have a specific topography, often lying directly adjacent to domain-specific regions. Thus, in addition to domain-specific brain regions tailored to solve particular problems of longstanding importance to our species, the human brain also contains a set of functionally general regions that plausibly endow us with the cognitive flexibility necessary to solve novel problems.},
	language = {en},
	urldate = {2019-02-14},
	journal = {PNAS},
	author = {Fedorenko, Evelina and Duncan, John and Kanwisher, Nancy},
	month = sep,
	year = {2013},
	pmid = {24062451},
	keywords = {cognitive control, Multiple-demand system},
	pages = {201315235},
	file = {Full Text PDF:/Users/tito/Zotero/storage/JSR69DJ2/Fedorenko et al. - 2013 - Broad domain generality in focal regions of fronta.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/59FL9HJA/1315235110.html:text/html},
}

@article{kass_computational_2018,
	title = {Computational {Neuroscience}: {Mathematical} and {Statistical} {Perspectives}},
	volume = {5},
	shorttitle = {Computational {Neuroscience}},
	url = {https://doi.org/10.1146/annurev-statistics-041715-033733},
	doi = {10.1146/annurev-statistics-041715-033733},
	abstract = {Mathematical and statistical models have played important roles in neuroscience, especially by describing the electrical activity of neurons recorded individually, or collectively across large networks. As the field moves forward rapidly, new challenges are emerging. For maximal effectiveness, those working to advance computational neuroscience will need to appreciate and exploit the complementary strengths of mechanistic theory and the statistical paradigm.},
	number = {1},
	urldate = {2019-02-24},
	journal = {Annual Review of Statistics and Its Application},
	author = {Kass, Robert E. and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N. and Diekman, Casey O. and Diesmann, Markus and Doiron, Brent and Eden, Uri T. and Fairhall, Adrienne L. and Fiddyment, Grant M. and Fukai, Tomoki and Grün, Sonja and Harrison, Matthew T. and Helias, Moritz and Nakahara, Hiroyuki and Teramae, Jun-nosuke and Thomas, Peter J. and Reimers, Mark and Rodu, Jordan and Rotstein, Horacio G. and Shea-Brown, Eric and Shimazaki, Hideaki and Shinomoto, Shigeru and Yu, Byron M. and Kramer, Mark A.},
	year = {2018},
	pages = {183--214},
}

@article{golub_learning_2018,
	title = {Learning by neural reassociation},
	volume = {21},
	copyright = {2018 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0095-3},
	doi = {10.1038/s41593-018-0095-3},
	abstract = {Learning is ubiquitous in everyday life, yet it is unclear how neurons change their activity together during learning. Golub and colleagues show that short-term learning relies on a fixed neural repertoire, which limits behavioral improvement.},
	language = {En},
	number = {4},
	urldate = {2019-02-26},
	journal = {Nature Neuroscience},
	author = {Golub, Matthew D. and Sadtler, Patrick T. and Oby, Emily R. and Quick, Kristin M. and Ryu, Stephen I. and Tyler-Kabara, Elizabeth C. and Batista, Aaron P. and Chase, Steven M. and Yu, Byron M.},
	month = apr,
	year = {2018},
	pages = {607},
	file = {Full Text PDF:/Users/tito/Zotero/storage/C7DU2QUQ/Golub et al. - 2018 - Learning by neural reassociation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/U3D5KT5V/s41593-018-0095-3.html:text/html},
}

@article{dinstein_neural_2015,
	title = {Neural variability: friend or foe?},
	volume = {19},
	issn = {1364-6613},
	shorttitle = {Neural variability},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661315000911},
	doi = {10.1016/j.tics.2015.04.005},
	abstract = {Although we may not realize it, our brain function varies markedly from moment to moment such that our brain responses exhibit substantial variability across trials even in response to a simple repeating stimulus. Should we care about such within-subject variability? Are there developmental, cognitive, and clinical consequences to having a brain that is more or less variable/noisy? Although neural variability seems to be beneficial for learning, excessive levels of neural variability are apparent in individuals with different clinical disorders. We propose that measuring distinct types of neural variability in autism and other disorders is likely to reveal crucial insights regarding their neuropathology. We further discuss the importance of studying neural variability more generally across development and aging in humans.},
	number = {6},
	urldate = {2019-02-27},
	journal = {Trends in Cognitive Sciences},
	author = {Dinstein, Ilan and Heeger, David J. and Behrmann, Marlene},
	month = jun,
	year = {2015},
	pages = {322--328},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/8YCMJ7EB/Dinstein et al. - 2015 - Neural variability friend or foe.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/MLCVEXNL/S1364661315000911.html:text/html},
}

@article{eberhardt_introduction_2017,
	title = {Introduction to the foundations of causal discovery},
	volume = {3},
	issn = {2364-415X, 2364-4168},
	url = {http://link.springer.com/10.1007/s41060-016-0038-6},
	doi = {10.1007/s41060-016-0038-6},
	abstract = {This article presents an overview of several known approaches to causal discovery. It is organized by relating the different fundamental assumptions that the methods depend on. The goal is to indicate that for a large variety of different settings the assumptions necessary and sufﬁcient for causal discovery are now well understood.},
	language = {en},
	number = {2},
	urldate = {2019-03-05},
	journal = {International Journal of Data Science and Analytics},
	author = {Eberhardt, Frederick},
	month = mar,
	year = {2017},
	pages = {81--91},
	file = {Eberhardt - 2017 - Introduction to the foundations of causal discover.pdf:/Users/tito/Zotero/storage/WK9DFSVN/Eberhardt - 2017 - Introduction to the foundations of causal discover.pdf:application/pdf},
}

@article{lakens_equivalence_2017,
	title = {Equivalence {Tests}: {A} {Practical} {Primer} for t {Tests}, {Correlations}, and {Meta}-{Analyses}},
	volume = {8},
	issn = {1948-5506},
	shorttitle = {Equivalence {Tests}},
	url = {https://doi.org/10.1177/1948550617697177},
	doi = {10.1177/1948550617697177},
	abstract = {Scientists should be able to provide support for the absence of a meaningful effect. Currently, researchers often incorrectly conclude an effect is absent based a nonsignificant result. A widely recommended approach within a frequentist framework is to test for equivalence. In equivalence tests, such as the two one-sided tests (TOST) procedure discussed in this article, an upper and lower equivalence bound is specified based on the smallest effect size of interest. The TOST procedure can be used to statistically reject the presence of effects large enough to be considered worthwhile. This practical primer with accompanying spreadsheet and R package enables psychologists to easily perform equivalence tests (and power analyses) by setting equivalence bounds based on standardized effect sizes and provides recommendations to prespecify equivalence bounds. Extending your statistical tool kit with equivalence tests is an easy way to improve your statistical and theoretical inferences.},
	language = {en},
	number = {4},
	urldate = {2019-03-05},
	journal = {Social Psychological and Personality Science},
	author = {Lakens, Daniël},
	month = may,
	year = {2017},
	pages = {355--362},
	file = {SAGE PDF Full Text:/Users/tito/Zotero/storage/6XZTNHCQ/Lakens - 2017 - Equivalence Tests A Practical Primer for t Tests,.pdf:application/pdf},
}

@article{grady_brain_2018,
	title = {Brain signal variability is modulated as a function of internal and external demand in younger and older adults},
	volume = {169},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917310534},
	doi = {10.1016/j.neuroimage.2017.12.031},
	abstract = {Variability in the Blood Oxygen-Level Dependent (BOLD) signal from fMRI is often associated with better cognitive performance and younger age. It has been proposed that neural variability enables flexible responding to uncertainty in a changing environment. However, signal variability reflecting environmental uncertainty may reduce to the extent that a task depends on internally-directed attention and is supported by neural “solutions” that are schematic and relatively stable within each individual. Accordingly, we examined the hypothesis that BOLD variability will be low at rest, higher during internally-directed tasks, and higher still during externally-directed tasks, and that this effect will be reduced with aging. Modulation of BOLD variability across conditions was consistent with these hypotheses, and was associated with faster and more stable behavioral performance in both young and older adults. These data support the idea that brain signal variability may modulate in response to environmental uncertainty, which is presumed to be greater in the external environment than in the internal milieu. Reduced flexibility of signal variability with age may indicate less ability to switch between internal and external brain states.},
	urldate = {2019-03-05},
	journal = {NeuroImage},
	author = {Grady, Cheryl L. and Garrett, Douglas D.},
	month = apr,
	year = {2018},
	keywords = {fMRI, Default mode network, Variability, Aging, Reaction time},
	pages = {510--523},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/74MY2D7J/Grady and Garrett - 2018 - Brain signal variability is modulated as a functio.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3PVF368V/S1053811917310534.html:text/html},
}

@article{garrett_brain_2014,
	title = {Brain {Signal} {Variability} is {Parametrically} {Modifiable}},
	volume = {24},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/24/11/2931/299670},
	doi = {10.1093/cercor/bht150},
	abstract = {Abstract.  Moment-to-moment brain signal variability is a ubiquitous neural characteristic, yet remains poorly understood. Evidence indicates that heightened si},
	language = {en},
	number = {11},
	urldate = {2019-03-05},
	journal = {Cereb Cortex},
	author = {Garrett, Douglas D. and McIntosh, Anthony R. and Grady, Cheryl L.},
	month = nov,
	year = {2014},
	pages = {2931--2940},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WUVC4FFR/Garrett et al. - 2014 - Brain Signal Variability is Parametrically Modifia.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/J8SQVFEG/299670.html:text/html},
}

@article{pfeffer_catecholamines_2018,
	title = {Catecholamines alter the intrinsic variability of cortical population activity and perception},
	volume = {16},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2003453},
	doi = {10.1371/journal.pbio.2003453},
	abstract = {The ascending modulatory systems of the brain stem are powerful regulators of global brain state. Disturbances of these systems are implicated in several major neuropsychiatric disorders. Yet, how these systems interact with specific neural computations in the cerebral cortex to shape perception, cognition, and behavior remains poorly understood. Here, we probed into the effect of two such systems, the catecholaminergic (dopaminergic and noradrenergic) and cholinergic systems, on an important aspect of cortical computation: its intrinsic variability. To this end, we combined placebo-controlled pharmacological intervention in humans, recordings of cortical population activity using magnetoencephalography (MEG), and psychophysical measurements of the perception of ambiguous visual input. A low-dose catecholaminergic, but not cholinergic, manipulation altered the rate of spontaneous perceptual fluctuations as well as the temporal structure of “scale-free” population activity of large swaths of the visual and parietal cortices. Computational analyses indicate that both effects were consistent with an increase in excitatory relative to inhibitory activity in the cortical areas underlying visual perceptual inference. We propose that catecholamines regulate the variability of perception and cognition through dynamically changing the cortical excitation–inhibition ratio. The combined readout of fluctuations in perception and cortical activity we established here may prove useful as an efficient and easily accessible marker of altered cortical computation in neuropsychiatric disorders.},
	language = {en},
	number = {2},
	urldate = {2019-03-07},
	journal = {PLOS Biology},
	author = {Pfeffer, Thomas and Avramiea, Arthur-Ervin and Nolte, Guido and Engel, Andreas K. and Linkenkaer-Hansen, Klaus and Donner, Tobias H.},
	month = feb,
	year = {2018},
	keywords = {Acetylcholine, Vision, Catecholamines, Eye movements, Magnetoencephalography, Neuromodulation, Permutation, Sensory perception},
	pages = {e2003453},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WH2D7CGX/Pfeffer et al. - 2018 - Catecholamines alter the intrinsic variability of .pdf:application/pdf;Pfeffer et al. - 2018 - Catecholamines alter the intrinsic variability of .pdf:/Users/tito/Zotero/storage/CPSQIFK7/Pfeffer et al. - 2018 - Catecholamines alter the intrinsic variability of .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3VRWG6VX/article.html:text/html},
}

@article{schiefer_correlation_2018,
	title = {From correlation to causation: {Estimating} effective connectivity from zero-lag covariances of brain signals},
	volume = {14},
	issn = {1553-7358},
	shorttitle = {From correlation to causation},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006056},
	doi = {10.1371/journal.pcbi.1006056},
	abstract = {Knowing brain connectivity is of great importance both in basic research and for clinical applications. We are proposing a method to infer directed connectivity from zero-lag covariances of neuronal activity recorded at multiple sites. This allows us to identify causal relations that are reflected in neuronal population activity. To derive our strategy, we assume a generic linear model of interacting continuous variables, the components of which represent the activity of local neuronal populations. The suggested method for inferring connectivity from recorded signals exploits the fact that the covariance matrix derived from the observed activity contains information about the existence, the direction and the sign of connections. Assuming a sparsely coupled network, we disambiguate the underlying causal structure via L1-minimization, which is known to prefer sparse solutions. In general, this method is suited to infer effective connectivity from resting state data of various types. We show that our method is applicable over a broad range of structural parameters regarding network size and connection probability of the network. We also explored parameters affecting its activity dynamics, like the eigenvalue spectrum. Also, based on the simulation of suitable Ornstein-Uhlenbeck processes to model BOLD dynamics, we show that with our method it is possible to estimate directed connectivity from zero-lag covariances derived from such signals. In this study, we consider measurement noise and unobserved nodes as additional confounding factors. Furthermore, we investigate the amount of data required for a reliable estimate. Additionally, we apply the proposed method on full-brain resting-state fast fMRI datasets. The resulting network exhibits a tendency for close-by areas being connected as well as inter-hemispheric connections between corresponding areas. In addition, we found that a surprisingly large fraction of more than one third of all identified connections were of inhibitory nature.},
	language = {en},
	number = {3},
	urldate = {2019-03-07},
	journal = {PLOS Computational Biology},
	author = {Schiefer, Jonathan and Niederbühl, Alexander and Pernice, Volker and Lennartz, Carolin and Hennig, Jürgen and LeVan, Pierre and Rotter, Stefan},
	month = mar,
	year = {2018},
	keywords = {Functional magnetic resonance imaging, Network analysis, Neural networks, Colliders, Covariance, Eigenvalues, Operator theory, Simulation and modeling},
	pages = {e1006056},
	file = {Full Text PDF:/Users/tito/Zotero/storage/4WZNXIDC/Schiefer et al. - 2018 - From correlation to causation Estimating effectiv.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/K9YJ2MNF/article.html:text/html},
}

@article{marinescu_quasi-experimental_2018,
	title = {Quasi-experimental causality in neuroscience and behavioural research},
	volume = {2},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-018-0466-5},
	doi = {10.1038/s41562-018-0466-5},
	language = {en},
	number = {12},
	urldate = {2019-03-11},
	journal = {Nature Human Behaviour},
	author = {Marinescu, Ioana E. and Lawlor, Patrick N. and Kording, Konrad P.},
	month = dec,
	year = {2018},
	pages = {891--898},
	file = {Marinescu et al. - 2018 - Quasi-experimental causality in neuroscience and b.pdf:/Users/tito/Zotero/storage/XFWENNR9/Marinescu et al. - 2018 - Quasi-experimental causality in neuroscience and b.pdf:application/pdf},
}

@article{sejnowski_putting_2014,
	title = {Putting big data to good use in neuroscience},
	volume = {17},
	copyright = {2014 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3839},
	doi = {10.1038/nn.3839},
	abstract = {Big data has transformed fields such as physics and genomics. Neuroscience is set to collect its own big data sets, but to exploit its full potential, there need to be ways to standardize, integrate and synthesize diverse types of data from different levels of analysis and across species. This will require a cultural shift in sharing data across labs, as well as to a central role for theorists in neuroscience research.},
	language = {en},
	urldate = {2019-03-12},
	journal = {Nature Neuroscience},
	author = {Sejnowski, Terrence J. and Churchland, Patricia S. and Movshon, J. Anthony},
	month = oct,
	year = {2014},
	pages = {1440--1441},
	file = {Full Text PDF:/Users/tito/Zotero/storage/CRZNVFJ4/Sejnowski et al. - 2014 - Putting big data to good use in neuroscience.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TV86CJF7/nn.html:text/html},
}

@article{forscher_chaos_1963,
	title = {Chaos in the {Brickyard}},
	volume = {142},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.142.3590.339},
	doi = {10.1126/science.142.3590.339},
	language = {en},
	number = {3590},
	urldate = {2019-03-14},
	journal = {Science},
	author = {Forscher, B. K.},
	month = oct,
	year = {1963},
	pages = {339--339},
	file = {Forscher - 1963 - Chaos in the Brickyard.pdf:/Users/tito/Zotero/storage/HM93SSL2/Forscher - 1963 - Chaos in the Brickyard.pdf:application/pdf},
}

@article{cichy_deep_2019,
	title = {Deep {Neural} {Networks} as {Scientific} {Models}},
	volume = {23},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(19)30034-8},
	doi = {10.1016/j.tics.2019.01.009},
	language = {English},
	number = {4},
	urldate = {2019-03-15},
	journal = {Trends in Cognitive Sciences},
	author = {Cichy, Radoslaw M. and Kaiser, Daniel},
	month = apr,
	year = {2019},
	pmid = {30795896},
	keywords = {neural network, deep learning, explanation, exploration, prediction, scientific model},
	pages = {305--317},
	file = {Cichy and Kaiser - 2019 - Deep Neural Networks as Scientific Models.pdf:/Users/tito/Zotero/storage/A3J9XT28/Cichy and Kaiser - 2019 - Deep Neural Networks as Scientific Models.pdf:application/pdf;Full Text PDF:/Users/tito/Zotero/storage/PI9IW54X/Cichy and Kaiser - 2019 - Deep Neural Networks as Scientific Models.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/D3BU8ZSU/S1364-6613(19)30034-8.html:text/html},
}

@article{bastos_laminar_2018,
	title = {Laminar recordings in frontal cortex suggest distinct layers for maintenance and control of working memory},
	volume = {115},
	copyright = {Copyright © 2018 the Author(s). Published by PNAS.. This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/5/1117},
	doi = {10.1073/pnas.1710323115},
	abstract = {All of the cerebral cortex has some degree of laminar organization. These different layers are composed of neurons with distinct connectivity patterns, embryonic origins, and molecular profiles. There are little data on the laminar specificity of cognitive functions in the frontal cortex, however. We recorded neuronal spiking/local field potentials (LFPs) using laminar probes in the frontal cortex (PMd, 8A, 8B, SMA/ACC, DLPFC, and VLPFC) of monkeys performing working memory (WM) tasks. LFP power in the gamma band (50–250 Hz) was strongest in superficial layers, and LFP power in the alpha/beta band (4–22 Hz) was strongest in deep layers. Memory delay activity, including spiking and stimulus-specific gamma bursting, was predominately in superficial layers. LFPs from superficial and deep layers were synchronized in the alpha/beta bands. This was primarily unidirectional, with alpha/beta bands in deep layers driving superficial layer activity. The phase of deep layer alpha/beta modulated superficial gamma bursting associated with WM encoding. Thus, alpha/beta rhythms in deep layers may regulate the superficial layer gamma bands and hence maintenance of the contents of WM.},
	language = {en},
	number = {5},
	urldate = {2019-03-25},
	journal = {PNAS},
	author = {Bastos, André M. and Loonis, Roman and Kornblith, Simon and Lundqvist, Mikael and Miller, Earl K.},
	month = jan,
	year = {2018},
	pmid = {29339471},
	keywords = {frontal cortex, working memory, oscillations, cortical layers},
	pages = {1117--1122},
	file = {Full Text PDF:/Users/tito/Zotero/storage/9RH38WSV/Bastos et al. - 2018 - Laminar recordings in frontal cortex suggest disti.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/U4RTLLKB/1117.html:text/html},
}

@article{duncker_learning_2019,
	title = {Learning interpretable continuous-time models of latent stochastic dynamical systems},
	url = {http://arxiv.org/abs/1902.04420},
	abstract = {We develop an approach to learn an interpretable semi-parametric model of a latent continuous-time stochastic dynamical system, assuming noisy high-dimensional outputs sampled at uneven times. The dynamics are described by a nonlinear stochastic differential equation (SDE) driven by a Wiener process, with a drift evolution function drawn from a Gaussian process (GP) conditioned on a set of learnt fixed points and corresponding local Jacobian matrices. This form yields a flexible nonparametric model of the dynamics, with a representation corresponding directly to the interpretable portraits routinely employed in the study of nonlinear dynamical systems. The learning algorithm combines inference of continuous latent paths underlying observed data with a sparse variational description of the dynamical process. We demonstrate our approach on simulated data from different nonlinear dynamical systems.},
	urldate = {2019-03-25},
	journal = {arXiv:1902.04420 [cs, math, stat]},
	author = {Duncker, Lea and Bohner, Gergo and Boussard, Julien and Sahani, Maneesh},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.04420},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems},
	file = {arXiv\:1902.04420 PDF:/Users/tito/Zotero/storage/Z79PLT5F/Duncker et al. - 2019 - Learning interpretable continuous-time models of l.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/V36S5HEQ/1902.html:text/html},
}

@article{gavish_optimal_2014,
	title = {The {Optimal} {Hard} {Threshold} for {Singular} {Values} is \$4/{\textbackslash}sqrt 3\$},
	volume = {60},
	issn = {0018-9448},
	doi = {10.1109/TIT.2014.2323359},
	abstract = {We consider recovery of low-rank matrices from noisy data by hard thresholding of singular values, in which empirical singular values below a threshold λ are set to 0. We study the asymptotic mean squared error (AMSE) in a framework, where the matrix size is large compared with the rank of the matrix to be recovered, and the signal-to-noise ratio of the low-rank piece stays constant. The AMSE-optimal choice of hard threshold, in the case of n-by-n matrix in white noise of level σ, is simply (4/√3)√nσ ≈ 2.309√nσ when σ is known, or simply 2.858 · ymed when σ is unknown, where ymed is the median empirical singular value. For nonsquare, m by n matrices with m ≠ n the thresholding coefficients 4/√3 and 2.858 are replaced with different provided constants that depend on m/n. Asymptotically, this thresholding rule adapts to unknown rank and unknown noise level in an optimal manner: it is always better than hard thresholding at any other value, and is always better than ideal truncated singular value decomposition (TSVD), which truncates at the true rank of the low-rank matrix we are trying to recover. Hard thresholding at the recommended value to recover an n-by-n matrix of rank r guarantees an AMSE at most 3 nrσ2. In comparison, the guarantees provided by TSVD, optimally tuned singular value soft thresholding and the best guarantee achievable by any shrinkage of the data singular values are 5 nrσ2, 6 nrσ2, and 2 nrσ2, respectively. The recommended value for hard threshold also offers, among hard thresholds, the best possible AMSE guarantees for recovering matrices with bounded nuclear norm. Empirical evidence suggests that performance improvement over TSVD and other popular shrinkage rules can be substantial, for different noise distributions, even in relatively small n.},
	number = {8},
	journal = {IEEE Transactions on Information Theory},
	author = {Gavish, M. and Donoho, D. L.},
	month = aug,
	year = {2014},
	keywords = {AMSE-optimal choice, Approximation methods, asymptotic mean squared error, bulk edge, data singular value shrinkage, Information theory, low-rank matrix denoising, low-rank matrix recovery, mean square error methods, median empirical singular value, n-by-n matrix, noise distribution, Noise level, Noise reduction, noisy data, optimal hard threshold, optimal threshold, optimally tuned singular value soft thresholding, quarter circle law, scree plot elbow truncation, Signal to noise ratio, signal-to-noise ratio, singular value decomposition, Singular values shrinkage, thresholding coefficient, truncated singular value decomposition, TSVD, unique admissible, unknown noise level, Vectors, white noise, White noise},
	pages = {5040--5053},
	file = {IEEE Xplore Abstract Record:/Users/tito/Zotero/storage/JKJFKCQ9/6846297.html:text/html;IEEE Xplore Full Text PDF:/Users/tito/Zotero/storage/298XAVS6/Gavish and Donoho - 2014 - The Optimal Hard Threshold for Singular Values is .pdf:application/pdf},
}

@article{guntupalli_computational_2018,
	title = {A computational model of shared fine-scale structure in the human connectome},
	volume = {14},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006120},
	doi = {10.1371/journal.pcbi.1006120},
	abstract = {Variation in cortical connectivity profiles is typically modeled as having a coarse spatial scale parcellated into interconnected brain areas. We created a high-dimensional common model of the human connectome to search for fine-scale structure that is shared across brains. Projecting individual connectivity data into this new common model connectome accounts for substantially more variance in the human connectome than do previous models. This newly discovered shared structure is closely related to fine-scale distinctions in representations of information. These results reveal a shared fine-scale structure that is a major component of the human connectome that coexists with coarse-scale, areal structure. This shared fine-scale structure was not captured in previous models and was, therefore, inaccessible to analysis and study.},
	language = {en},
	number = {4},
	urldate = {2019-03-26},
	journal = {PLOS Computational Biology},
	author = {Guntupalli, J. Swaroop and Feilong, Ma and Haxby, James V.},
	month = apr,
	year = {2018},
	keywords = {Neuroimaging, Functional magnetic resonance imaging, Connectomics, Brain mapping, Central nervous system, Data visualization, Resting state functional magnetic resonance imaging, Vector spaces},
	pages = {e1006120},
	file = {Full Text PDF:/Users/tito/Zotero/storage/SMJLQU9T/Guntupalli et al. - 2018 - A computational model of shared fine-scale structu.pdf:application/pdf},
}

@article{linderman_using_2017,
	series = {Computational {Neuroscience}},
	title = {Using computational theory to constrain statistical models of neural data},
	volume = {46},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438816302641},
	doi = {10.1016/j.conb.2017.06.004},
	abstract = {Computational neuroscience is, to first order, dominated by two approaches: the ‘bottom-up’ approach, which searches for statistical patterns in large-scale neural recordings, and the ‘top-down’ approach, which begins with a theory of computation and considers plausible neural implementations. While this division is not clear-cut, we argue that these approaches should be much more intimately linked. From a Bayesian perspective, computational theories provide constrained prior distributions on neural data—albeit highly sophisticated ones. By connecting theory to observation via a probabilistic model, we provide the link necessary to test, evaluate, and revise our theories in a data-driven and statistically rigorous fashion. This review highlights examples of this theory-driven pipeline for neural data analysis in recent literature and illustrates it with a worked example based on the temporal difference learning model of dopamine.},
	urldate = {2019-03-26},
	journal = {Current Opinion in Neurobiology},
	author = {Linderman, Scott W and Gershman, Samuel J},
	month = oct,
	year = {2017},
	pages = {14--24},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/HZB43LP8/Linderman and Gershman - 2017 - Using computational theory to constrain statistica.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/PPL4GUNP/S0959438816302641.html:text/html},
}

@article{saxena_towards_2019,
	series = {Machine {Learning}, {Big} {Data}, and {Neuroscience}},
	title = {Towards the neural population doctrine},
	volume = {55},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438818300990},
	doi = {10.1016/j.conb.2019.02.002},
	abstract = {Across neuroscience, large-scale data recording and population-level analysis methods have experienced explosive growth. While the underlying hardware and computational techniques have been well reviewed, we focus here on the novel science that these technologies have enabled. We detail four areas of the field where the joint analysis of neural populations has significantly furthered our understanding of computation in the brain: correlated variability, decoding, neural dynamics, and artificial neural networks. Together, these findings suggest an exciting trend towards a new era where neural populations are understood to be the essential unit of computation in many brain regions, a classic idea that has been given new life.},
	urldate = {2019-03-26},
	journal = {Current Opinion in Neurobiology},
	author = {Saxena, Shreya and Cunningham, John P},
	month = apr,
	year = {2019},
	pages = {103--111},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/FHZQGHTF/Saxena and Cunningham - 2019 - Towards the neural population doctrine.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/VC659EU7/S0959438818300990.html:text/html},
}

@article{bro_fast_1997,
	title = {A fast non-negativity-constrained least squares algorithm},
	volume = {11},
	issn = {1099-128X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-128X%28199709/10%2911%3A5%3C393%3A%3AAID-CEM483%3E3.0.CO%3B2-L},
	doi = {10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L},
	abstract = {In this paper a modification of the standard algorithm for non-negativity-constrained linear least squares regression is proposed. The algorithm is specifically designed for use in multiway decomposition methods such as PARAFAC and N-mode principal component analysis. In those methods the typical situation is that there is a high ratio between the numbers of objects and variables in the regression problems solved. Furthermore, very similar regression problems are solved many times during the iterative procedures used. The algorithm proposed is based on the de facto standard algorithm NNLS by Lawson and Hanson, but modified to take advantage of the special characteristics of iterative algorithms involving repeated use of non-negativity constraints. The principle behind the NNLS algorithm is described in detail and a comparison is made between this standard algorithm and the new algorithm called FNNLS (fast NNLS). © 1997 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {5},
	urldate = {2019-03-26},
	journal = {Journal of Chemometrics},
	author = {Bro, Rasmus and Jong, Sijmen De},
	year = {1997},
	keywords = {multiway, NNLS, non-negativity, PARAFAC},
	pages = {393--401},
	file = {Full Text PDF:/Users/tito/Zotero/storage/M4BFQBJ5/Bro and Jong - 1997 - A fast non-negativity-constrained least squares al.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BVVUIXXW/10)115393AID-CEM4833.0.html:text/html},
}

@article{weichwald_causal_2015,
	title = {Causal interpretation rules for encoding and decoding models in neuroimaging},
	volume = {110},
	issn = {10538119},
	url = {http://arxiv.org/abs/1511.04780},
	doi = {10.1016/j.neuroimage.2015.01.036},
	abstract = {Causal terminology is often introduced in the interpretation of encoding and decoding models trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between encoding and decoding models is not sufficient for this purpose: relevant features in encoding and decoding models carry a different meaning in stimulus- and in response-based experimental paradigms. We show that only encoding models in the stimulus-based setting support unambiguous causal interpretations. By combining encoding and decoding models trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task.},
	urldate = {2019-04-01},
	journal = {NeuroImage},
	author = {Weichwald, Sebastian and Meyer, Timm and Özdenizci, Ozan and Schölkopf, Bernhard and Ball, Tonio and Grosse-Wentrup, Moritz},
	month = apr,
	year = {2015},
	note = {arXiv: 1511.04780},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Applications},
	pages = {48--59},
	annote = {Comment: accepted manuscript},
	file = {arXiv\:1511.04780 PDF:/Users/tito/Zotero/storage/RD796SR3/Weichwald et al. - 2015 - Causal interpretation rules for encoding and decod.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/LQWFMYK8/1511.html:text/html},
}

@article{kriegeskorte_neural_2019,
	title = {Neural network models and deep learning},
	volume = {29},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982219302040},
	doi = {10.1016/j.cub.2019.02.034},
	language = {en},
	number = {7},
	urldate = {2019-04-08},
	journal = {Current Biology},
	author = {Kriegeskorte, Nikolaus and Golan, Tal},
	month = apr,
	year = {2019},
	pages = {R231--R236},
	file = {Kriegeskorte and Golan - 2019 - Neural network models and deep learning.pdf:/Users/tito/Zotero/storage/XJU23PUE/Kriegeskorte and Golan - 2019 - Neural network models and deep learning.pdf:application/pdf},
}

@article{gamanut_mouse_2018,
	title = {The {Mouse} {Cortical} {Connectome}, {Characterized} by an {Ultra}-{Dense} {Cortical} {Graph}, {Maintains} {Specificity} by {Distinct} {Connectivity} {Profiles}},
	volume = {97},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627317311856},
	doi = {10.1016/j.neuron.2017.12.037},
	abstract = {Summary
The inter-areal wiring pattern of the mouse cerebral cortex was analyzed in relation to a refined parcellation of cortical areas. Twenty-seven retrograde tracer injections were made in 19 areas of a 47-area parcellation of the mouse neocortex. Flat mounts of the cortex and multiple histological markers enabled detailed counts of labeled neurons in individual areas. The observed log-normal distribution of connection weights to each cortical area spans 5 orders of magnitude and reveals a distinct connectivity profile for each area, analogous to that observed in macaques. The cortical network has a density of 97\%, considerably higher than the 66\% density reported in macaques. A weighted graph analysis reveals a similar global efficiency but weaker spatial clustering compared with that reported in macaques. The consistency, precision of the connectivity profile, density, and weighted graph analysis of the present data differ significantly from those obtained in earlier studies in the mouse.},
	number = {3},
	urldate = {2019-04-09},
	journal = {Neuron},
	author = {Gămănuţ, Răzvan and Kennedy, Henry and Toroczkai, Zoltán and Ercsey-Ravasz, Mária and Van Essen, David C. and Knoblauch, Kenneth and Burkhalter, Andreas},
	month = feb,
	year = {2018},
	keywords = {connectivity, anatomy, log-normal, neocortex, retrograde, rodent, tract-tracing},
	pages = {698--715.e10},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/5FW6REEC/Gămănuţ et al. - 2018 - The Mouse Cortical Connectome, Characterized by an.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/6Z9WKMXP/S0896627317311856.html:text/html},
}

@article{xie_equivalence_2003,
	title = {Equivalence of {Backpropagation} and {Contrastive} {Hebbian} {Learning} in a {Layered} {Network}},
	volume = {15},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976603762552988},
	doi = {10.1162/089976603762552988},
	abstract = {Backpropagation and contrastive Hebbian learning are two methods of training networks with hidden neurons. Backpropagation computes an error signal for the output neurons and spreads it over the hidden neurons. Contrastive Hebbian learning involves clamping the output neurons at desired values and letting the effect spread through feedback connections over the entire network. To investigate the relationship between these two forms of learning, we consider a special case in which they are identical: a multilayer perceptron with linear output units, to which weak feedback connections have been added. In this case, the change in network state caused by clamping the output neurons turns out to be the same as the error signal spread by backpropagation, except for a scalar prefactor. This suggests that the functionality of backpropagation can be realized alternatively by a Hebbian-type learning algorithm, which is suitable for implementation in biological networks.},
	number = {2},
	urldate = {2019-04-12},
	journal = {Neural Computation},
	author = {Xie, Xiaohui and Seung, H. Sebastian},
	month = feb,
	year = {2003},
	pages = {441--454},
	file = {Full Text PDF:/Users/tito/Zotero/storage/24V83AFA/Xie and Seung - 2003 - Equivalence of Backpropagation and Contrastive Heb.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6C2SHGHE/089976603762552988.html:text/html},
}

@book{shepherd_foundations_2015,
	title = {Foundations of the {Neuron} {Doctrine}: 25th {Anniversary} {Edition}},
	isbn = {978-0-19-025939-6},
	shorttitle = {Foundations of the {Neuron} {Doctrine}},
	abstract = {The neuron doctrine, first formulated in 1891, states that the brain is constructed of individual neurons, organized into functioning circuits that mediate behavior. It is the fundamental principal that underlies all of neuroscience and clinical neurology. Foundations of the Neuron Doctrine gives an authoritative account of how this theory was the product of an explosion of histological studies and vigorous debates near the end of the nineteenth century by an extraordinary group of scientists, led by Santiago Ramon y Cajal of Spain, using a selective stain discovered by Camillo Golgi of Italy. They were the first to describe the distinctive branching patterns of nerve cells, providing evidence that the cells interact as individual units to form circuits, opposed however by Golgi, who held out for a view that the nerve cells form syncytial networks. Studies in the 1950s appeared to confirm the nerve cell as an individual unit, as embodied in the neuron doctrine, which became the basis for the rise of concepts of normal and disordered neural function since then. This 25th Anniversary Edition is timely. Recent studies are showing a much greater degree of complexity in neuronal organization, so that the debate of neuron versus network is again coming to the fore in neuroscience research. Unique to this Anniversary Edition is the inclusion of commentaries by distinguished international leaders - Marina Bentivoglio, Xavier De Felipe, Sten Grillner, Paolo Mazzarello, Larry Swanson, and Rafael Yuste - on the continuing relevance of the neuron doctrine for modern studies of the brain at all levels, from genes and molecules to microcircuits, neural networks, and behavior. As this new wave of modern studies expands our concepts of nervous function as the basis of behavior, Foundations of the Neuron Doctrine will be a unique source providing conceptual continuity from classical times to the present and into the future. With commentaries from Marina Bentivoglio Paolo Mazzarello Javier DeFelipe Larry Swanson Sten Grillner Rafael Yuste},
	language = {en},
	publisher = {Oxford University Press},
	author = {Shepherd, Gordon M.},
	month = oct,
	year = {2015},
	note = {Google-Books-ID: kJOFCgAAQBAJ},
	keywords = {Medical / History, Medical / Neuroscience},
}

@article{yuste_neuron_2015,
	title = {From the neuron doctrine to neural networks},
	volume = {16},
	copyright = {2015 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn3962},
	doi = {10.1038/nrn3962},
	abstract = {For over a century, the neuron doctrine — which states that the neuron is the structural and functional unit of the nervous system — has provided a conceptual foundation for neuroscience. This viewpoint reflects its origins in a time when the use of single-neuron anatomical and physiological techniques was prominent. However, newer multineuronal recording methods have revealed that ensembles of neurons, rather than individual cells, can form physiological units and generate emergent functional properties and states. As a new paradigm for neuroscience, neural network models have the potential to incorporate knowledge acquired with single-neuron approaches to help us understand how emergent functional states generate behaviour, cognition and mental disease.},
	language = {en},
	number = {8},
	urldate = {2019-04-15},
	journal = {Nature Reviews Neuroscience},
	author = {Yuste, Rafael},
	month = aug,
	year = {2015},
	pages = {487--497},
	file = {Full Text PDF:/Users/tito/Zotero/storage/UG278YTA/Yuste - 2015 - From the neuron doctrine to neural networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/LANMZI3M/nrn3962.html:text/html},
}

@book{ramon_y_cajal_estructura_1888,
	title = {Estructura de los centros nerviosos de las aves},
	author = {Ramón y Cajal, Santiago},
	year = {1888},
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
	language = {en},
	number = {4},
	urldate = {2019-04-15},
	journal = {Bulletin of Mathematical Biophysics},
	author = {McCulloch, Warren S. and Pitts, Walter},
	month = dec,
	year = {1943},
	keywords = {Excitatory Synapse, Inhibitory Synapse, Nervous Activity, Spatial Summation, Temporal Summation},
	pages = {115--133},
	file = {Springer Full Text PDF:/Users/tito/Zotero/storage/NFR6JLDC/McCulloch and Pitts - 1943 - A logical calculus of the ideas immanent in nervou.pdf:application/pdf},
}

@book{hebb_organization_2005,
	title = {The {Organization} of {Behavior}: {A} {Neuropsychological} {Theory}},
	isbn = {978-1-135-63191-8},
	shorttitle = {The {Organization} of {Behavior}},
	abstract = {Since its publication in 1949, D.O. Hebb's, The Organization of Behavior has been one of the most influential books in the fields of psychology and neuroscience. However, the original edition has been unavailable since 1966, ensuring that Hebb's comment that a classic normally means "cited but not read" is true in his case. This new edition rectifies a long-standing problem for behavioral neuroscientists--the inability to obtain one of the most cited publications in the field.   The Organization of Behavior played a significant part in stimulating the investigation of the neural foundations of behavior and continues to be inspiring because it provides a general framework for relating behavior to synaptic organization through the dynamics of neural networks.   D.O. Hebb was also the first to examine the mechanisms by which environment and experience can influence brain structure and function, and his ideas formed the basis for work on enriched environments as stimulants for behavioral development.   References to Hebb, the Hebbian cell assembly, the Hebb synapse, and the Hebb rule increase each year. These forceful ideas of 1949 are now applied in engineering, robotics, and computer science, as well as neurophysiology, neuroscience, and psychology--a tribute to Hebb's foresight in developing a foundational neuropsychological theory of the organization of behavior.},
	language = {en},
	publisher = {Psychology Press},
	author = {Hebb, D. O.},
	month = apr,
	year = {2005},
	note = {Google-Books-ID: uyV5AgAAQBAJ},
	keywords = {Psychology / Cognitive Psychology \& Cognition, Psychology / General, Psychology / Neuropsychology, Psychology / Physiological Psychology},
}

@book{de_pitta_computational_2019,
	title = {Computational {Glioscience}},
	publisher = {Springer},
	author = {De Pittà, Maurizio and Berry, Hugues},
	year = {2019},
}

@article{servan-schreiber_network_1990,
	title = {A network model of catecholamine effects: gain, signal-to-noise ratio, and behavior},
	volume = {249},
	issn = {0036-8075},
	shorttitle = {A network model of catecholamine effects},
	abstract = {At the level of individual neurons, catecholamine release increases the responsivity of cells to excitatory and inhibitory inputs. A model of catecholamine effects in a network of neural-like elements is presented, which shows that (i) changes in the responsivity of individual elements do not affect their ability to detect a signal and ignore noise but (ii) the same changes in cell responsivity in a network of such elements do improve the signal detection performance of the network as a whole. The second result is used in a computer simulation based on principles of parallel distributed processing to account for the effect of central nervous system stimulants on the signal detection performance of human subjects.},
	language = {eng},
	number = {4971},
	journal = {Science},
	author = {Servan-Schreiber, D. and Printz, H. and Cohen, J. D.},
	month = aug,
	year = {1990},
	pmid = {2392679},
	keywords = {Behavior, Humans, Neurons, Dopamine, Catecholamines, Central Nervous System, Methylphenidate, Models, Neurological, Norepinephrine},
	pages = {892--895},
}

@article{rubin_balanced_2017,
	title = {Balanced excitation and inhibition are required for high-capacity, noise-robust neuronal selectivity},
	volume = {114},
	copyright = {© 2017 . Published under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/114/44/E9366},
	doi = {10.1073/pnas.1705841114},
	abstract = {Neurons and networks in the cerebral cortex must operate reliably despite multiple sources of noise. To evaluate the impact of both input and output noise, we determine the robustness of single-neuron stimulus selective responses, as well as the robustness of attractor states of networks of neurons performing memory tasks. We find that robustness to output noise requires synaptic connections to be in a balanced regime in which excitation and inhibition are strong and largely cancel each other. We evaluate the conditions required for this regime to exist and determine the properties of networks operating within it. A plausible synaptic plasticity rule for learning that balances weight configurations is presented. Our theory predicts an optimal ratio of the number of excitatory and inhibitory synapses for maximizing the encoding capacity of balanced networks for given statistics of afferent activations. Previous work has shown that balanced networks amplify spatiotemporal variability and account for observed asynchronous irregular states. Here we present a distinct type of balanced network that amplifies small changes in the impinging signals and emerges automatically from learning to perform neuronal and network functions robustly.},
	language = {en},
	number = {44},
	urldate = {2019-04-16},
	journal = {PNAS},
	author = {Rubin, Ran and Abbott, L. F. and Sompolinsky, Haim},
	month = oct,
	year = {2017},
	pmid = {29042519},
	keywords = {associative memory, E/I balance, synaptic learning},
	pages = {E9366--E9375},
	file = {Full Text PDF:/Users/tito/Zotero/storage/ZQITTADX/Rubin et al. - 2017 - Balanced excitation and inhibition are required fo.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GUW8JS4W/E9366.html:text/html},
}

@article{toker_information_2019,
	title = {Information integration in large brain networks},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006807},
	doi = {10.1371/journal.pcbi.1006807},
	abstract = {An outstanding problem in neuroscience is to understand how information is integrated across the many modules of the brain. While classic information-theoretic measures have transformed our understanding of feedforward information processing in the brain’s sensory periphery, comparable measures for information flow in the massively recurrent networks of the rest of the brain have been lacking. To address this, recent work in information theory has produced a sound measure of network-wide “integrated information”, which can be estimated from time-series data. But, a computational hurdle has stymied attempts to measure large-scale information integration in real brains. Specifically, the measurement of integrated information involves a combinatorial search for the informational “weakest link” of a network, a process whose computation time explodes super-exponentially with network size. Here, we show that spectral clustering, applied on the correlation matrix of time-series data, provides an approximate but robust solution to the search for the informational weakest link of large networks. This reduces the computation time for integrated information in large systems from longer than the lifespan of the universe to just minutes. We evaluate this solution in brain-like systems of coupled oscillators as well as in high-density electrocortigraphy data from two macaque monkeys, and show that the informational “weakest link” of the monkey cortex splits posterior sensory areas from anterior association areas. Finally, we use our solution to provide evidence in support of the long-standing hypothesis that information integration is maximized by networks with a high global efficiency, and that modular network structures promote the segregation of information.},
	language = {en},
	number = {2},
	urldate = {2019-04-18},
	journal = {PLOS Computational Biology},
	author = {Toker, Daniel and Sommer, Friedrich T.},
	month = feb,
	year = {2019},
	keywords = {Algorithms, Connectomics, Network analysis, Neural networks, Information theory, Macaque, Monkeys, Spectral clustering},
	pages = {e1006807},
	file = {Full Text PDF:/Users/tito/Zotero/storage/H2WVQFJS/Toker and Sommer - 2019 - Information integration in large brain networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IMDK8D59/article.html:text/html},
}

@article{chalk_inferring_2019,
	title = {Inferring the function performed by a recurrent neural network},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/598086v2},
	doi = {10.1101/598086},
	abstract = {{\textless}p{\textgreater}A central goal in systems neuroscience is to understand the functions performed by neural circuits. Previous top-down models addressed this question by comparing the behaviour of an ideal model circuit, optimised to perform a given function, with neural recordings. However, this requires guessing in advance what function is being performed, which may not be possible for many neural systems. Here, we propose an alternative approach that uses recorded neural responses to directly infer the function performed by a neural network. We assume that the goal of the network can be expressed via a reward function, which describes how desirable each state of the network is for carrying out a given objective. This allows us to frame the problem of optimising each neuron9s responses by viewing neurons as agents in a reinforcement learning (RL) paradigm; likewise the problem of inferring the reward function from the observed dynamics can be treated using inverse RL. Our framework encompasses previous influential theories of neural coding, such as efficient coding and attractor network models, as special cases, given specific choices of reward function. Finally, we can use the reward function inferred from recorded neural responses to make testable predictions about how the network dynamics will adapt depending on contextual changes, such as cell death and/or varying input statistics, so as to carry out the same underlying function with different constraints.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-04-29},
	journal = {bioRxiv},
	author = {Chalk, Matthew and Tkačik, Gašper and Marre, Olivier},
	month = apr,
	year = {2019},
	pages = {598086},
	file = {Full Text PDF:/Users/tito/Zotero/storage/YQRC6MJF/Chalk et al. - 2019 - Inferring the function performed by a recurrent ne.pdf:application/pdf},
}

@article{sanchez-vives_inhibitory_2010,
	title = {Inhibitory {Modulation} of {Cortical} {Up} {States}},
	volume = {104},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00178.2010},
	doi = {10.1152/jn.00178.2010},
	abstract = {The balance between excitation and inhibition is critical in the physiology of the cerebral cortex. To understand the influence of inhibitory control on the emergent activity of the cortical network, inhibition was progressively blocked in a slice preparation that generates spontaneous rhythmic up states at a similar frequency to those occurring in vivo during slow-wave sleep or anesthesia. Progressive removal of inhibition induced a parametric shortening of up state duration and elongation of the down states, the frequency of oscillations decaying. Concurrently, a gradual increase in the network firing rate during up states occurred. The slope of transitions between up and down states was quantified for different levels of inhibition. The slope of upward transitions reflects the recruitment of the local network and was progressively increased when inhibition was decreased, whereas the speed of activity propagation became faster. Removal of inhibition eventually resulted in epileptiform activity. Whereas gradual reduction of inhibition induced linear changes in up/down states and their propagation, epileptiform activity was the result of a nonlinear transformation. A computational network model showed that strong recurrence plus activity-dependent hyperpolarizing currents were sufficient to account for the observed up state modulations and predicted an increase in activity-dependent hyperpolarization following up states when inhibition was decreased, which was confirmed experimentally.},
	number = {3},
	urldate = {2019-04-29},
	journal = {Journal of Neurophysiology},
	author = {Sanchez-Vives, Maria V. and Mattia, Maurizio and Compte, Albert and Perez-Zabalza, Maria and Winograd, Milena and Descalzo, Vanessa F. and Reig, Ramon},
	month = jun,
	year = {2010},
	pages = {1314--1324},
	file = {Full Text PDF:/Users/tito/Zotero/storage/54HBAVCA/Sanchez-Vives et al. - 2010 - Inhibitory Modulation of Cortical Up States.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/EN9GBS6Z/jn.00178.html:text/html},
}

@article{harris_cortical_2011-1,
	title = {Cortical {State} and {Attention}},
	volume = {12},
	issn = {1471-003X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3324821/},
	doi = {10.1038/nrn3084},
	abstract = {The brain continuously adapts its processing machinery to behavioural demands. To achieve this it rapidly modulates the operating mode of cortical circuits, controlling the way information is transformed and routed. This article will focus on two experimental approaches by which the control of cortical information processing has been investigated: the study of state-dependent cortical processing in rodents, and attention in the primate visual system. Both processes involve a modulation of low-frequency activity fluctuations and spiking correlation, and are mediated by common receptor systems. We suggest that selective attention involves processes similar to state change, operating at a local columnar level to enhance the representation of otherwise nonsalient features while suppressing internally generated activity patterns.},
	number = {9},
	urldate = {2019-04-29},
	journal = {Nat Rev Neurosci},
	author = {Harris, Kenneth D. and Thiele, Alexander},
	month = aug,
	year = {2011},
	pmid = {21829219},
	pmcid = {PMC3324821},
	pages = {509--523},
	file = {PubMed Central Full Text PDF:/Users/tito/Zotero/storage/4I4ERLPN/Harris and Thiele - 2011 - Cortical State and Attention.pdf:application/pdf},
}

@article{deco_how_2014-1,
	title = {How {Local} {Excitation}–{Inhibition} {Ratio} {Impacts} the {Whole} {Brain} {Dynamics}},
	volume = {34},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4044249/},
	doi = {10.1523/JNEUROSCI.5068-13.2014},
	abstract = {The spontaneous activity of the brain shows different features at different scales. On one hand, neuroimaging studies show that long-range correlations are highly structured in spatiotemporal patterns, known as resting-state networks, on the other hand, neurophysiological reports show that short-range correlations between neighboring neurons are low, despite a large amount of shared presynaptic inputs. Different dynamical mechanisms of local decorrelation have been proposed, among which is feedback inhibition. Here, we investigated the effect of locally regulating the feedback inhibition on the global dynamics of a large-scale brain model, in which the long-range connections are given by diffusion imaging data of human subjects. We used simulations and analytical methods to show that locally constraining the feedback inhibition to compensate for the excess of long-range excitatory connectivity, to preserve the asynchronous state, crucially changes the characteristics of the emergent resting and evoked activity. First, it significantly improves the model's prediction of the empirical human functional connectivity. Second, relaxing this constraint leads to an unrealistic network evoked activity, with systematic coactivation of cortical areas which are components of the default-mode network, whereas regulation of feedback inhibition prevents this. Finally, information theoretic analysis shows that regulation of the local feedback inhibition increases both the entropy and the Fisher information of the network evoked responses. Hence, it enhances the information capacity and the discrimination accuracy of the global network. In conclusion, the local excitation–inhibition ratio impacts the structure of the spontaneous activity and the information transmission at the large-scale brain level.},
	number = {23},
	urldate = {2019-04-29},
	journal = {J Neurosci},
	author = {Deco, Gustavo and Ponce-Alvarez, Adrián and Hagmann, Patric and Romani, Gian Luca and Mantini, Dante and Corbetta, Maurizio},
	month = jun,
	year = {2014},
	pmid = {24899711},
	pmcid = {PMC4044249},
	pages = {7886--7898},
	file = {PubMed Central Full Text PDF:/Users/tito/Zotero/storage/XKN8RZ9V/Deco et al. - 2014 - How Local Excitation–Inhibition Ratio Impacts the .pdf:application/pdf},
}

@article{kriegeskorte_inferring_2016,
	title = {Inferring brain-computational mechanisms with models of activity measurements},
	volume = {371},
	issn = {0962-8436, 1471-2970},
	url = {http://rstb.royalsocietypublishing.org/lookup/doi/10.1098/rstb.2016.0278},
	doi = {10.1098/rstb.2016.0278},
	language = {en},
	number = {1705},
	urldate = {2019-04-30},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Kriegeskorte, Nikolaus and Diedrichsen, Jörn},
	month = oct,
	year = {2016},
	pages = {20160278},
	file = {Kriegeskorte and Diedrichsen - 2016 - Inferring brain-computational mechanisms with mode.pdf:/Users/tito/Zotero/storage/WGEB437Q/Kriegeskorte and Diedrichsen - 2016 - Inferring brain-computational mechanisms with mode.pdf:application/pdf},
}

@article{tegmark_improved_2016,
	title = {Improved {Measures} of {Integrated} {Information}},
	volume = {12},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005123},
	doi = {10.1371/journal.pcbi.1005123},
	abstract = {Although there is growing interest in measuring integrated information in computational and cognitive systems, current methods for doing so in practice are computationally unfeasible. Existing and novel integration measures are investigated and classified by various desirable properties. A simple taxonomy of Φ-measures is presented where they are each characterized by their choice of factorization method (5 options), choice of probability distributions to compare (3 × 4 options) and choice of measure for comparing probability distributions (7 options). When requiring the Φ-measures to satisfy a minimum of attractive properties, these hundreds of options reduce to a mere handful, some of which turn out to be identical. Useful exact and approximate formulas are derived that can be applied to real-world data from laboratory experiments without posing unreasonable computational demands.},
	language = {en},
	number = {11},
	urldate = {2019-04-30},
	journal = {PLOS Computational Biology},
	author = {Tegmark, Max},
	month = nov,
	year = {2016},
	keywords = {Markov processes, Consciousness, Entropy, Covariance, Distance measurement, Probability distribution, Taxonomy, Theories of consciousness},
	pages = {e1005123},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HJDY38UF/Tegmark - 2016 - Improved Measures of Integrated Information.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/UURAQF6Z/article.html:text/html},
}

@article{mcavoy_dissociated_2012,
	title = {Dissociated mean and functional connectivity {BOLD} signals in visual cortex during eyes closed and fixation},
	volume = {108},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00900.2011},
	doi = {10.1152/jn.00900.2011},
	abstract = {We investigated the effects of resting state type on blood oxygen level-dependent (BOLD) signal and functional connectivity in two paradigms: participants either alternated between fixation and eyes closed or maintained fixation or eyes closed throughout each scan. The BOLD signal and functional connectivity of lower and higher tiers of the visual cortical hierarchy were found to be differentially modulated during eyes closed versus fixation. Fixation was associated with greater mean BOLD signals in primary visual cortex and lower mean BOLD signals in extrastriate visual areas than periods of eyes closed. In addition, analysis of thalamocortical functional connectivity during scans in which participants maintained fixation showed synchronized BOLD fluctuations between those thalamic nuclei whose mean BOLD signal was systematically modulated during alternating epochs of eyes closed and fixation, primary visual cortex and the attention network, while during eyes closed negatively correlated fluctuations were seen between the same thalamic nuclei and extrastriate visual areas. Finally, in all visual areas the amplitude of spontaneous BOLD fluctuations was greater during eyes closed than during fixation. The dissociation between early and late tiers of visual cortex, which characterizes both mean and functionally connected components of the BOLD signal, may depend on the reorganization of thalamocortical networks. Since dissociated changes in local blood flow also characterize transitions between different stages of sleep and wakefulness (Braun AR, Balkin TJ, Wesenten NJ, Gwadry F, Carson RE, Varga M, Baldwin P, Belenky G, Herscovitch P. Science 279: 91–95, 1998), our results suggest that dissociated endogenous neural activity in primary and extrastriate cortex may represent a general aspect of brain function.},
	number = {9},
	urldate = {2019-04-30},
	journal = {Journal of Neurophysiology},
	author = {McAvoy, Mark and Larson-Prior, Linda and Ludwikow, Marek and Zhang, Dongyang and Snyder, Abraham Z. and Gusnard, Debra L. and Raichle, Marcus E. and d'Avossa, Giovanni},
	month = aug,
	year = {2012},
	pages = {2363--2372},
	file = {Full Text PDF:/Users/tito/Zotero/storage/S5KZHIUZ/McAvoy et al. - 2012 - Dissociated mean and functional connectivity BOLD .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5MGJDUGX/jn.00900.html:text/html},
}

@article{snyder_brief_2012,
	series = {20 {YEARS} {OF} {fMRI}},
	title = {A brief history of the resting state: {The} {Washington} {University} perspective},
	volume = {62},
	issn = {1053-8119},
	shorttitle = {A brief history of the resting state},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912000614},
	doi = {10.1016/j.neuroimage.2012.01.044},
	abstract = {We present a history of the concepts and developments that have led us to focus on the resting state as an object of study. We then discuss resting state research performed in our laboratory since 2005 with an emphasis on papers of particular interest.},
	number = {2},
	urldate = {2019-04-30},
	journal = {NeuroImage},
	author = {Snyder, Abraham Z. and Raichle, Marcus E.},
	month = aug,
	year = {2012},
	pages = {902--910},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/FULGEA6Q/Snyder and Raichle - 2012 - A brief history of the resting state The Washingt.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/II6E5GUE/S1053811912000614.html:text/html},
}

@article{spoerer_recurrent_2017,
	title = {Recurrent {Convolutional} {Neural} {Networks}: {A} {Better} {Model} of {Biological} {Object} {Recognition}},
	volume = {8},
	issn = {1664-1078},
	shorttitle = {Recurrent {Convolutional} {Neural} {Networks}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2017.01551/full},
	doi = {10.3389/fpsyg.2017.01551},
	abstract = {Feedforward neural networks provide the dominant model of how the brain performs visual object recognition. However, these networks lack the lateral and feedback connections, and the resulting recurrent neuronal dynamics, of the ventral visual pathway in the human and nonhuman primate brain. Here we investigate recurrent convolutional neural networks with bottom-up (B), lateral (L), and top-down (T) connections. Combining these types of connections yields four architectures (B, BT, BL, and BLT), which we systematically test and compare. We hypothesized that recurrent dynamics might improve recognition performance in the challenging scenario of partial occlusion. We introduce two novel occluded object recognition tasks to test the efficacy of the models, {\textbackslash}emph\{digit clutter\} (where multiple target digits occlude one another) and {\textbackslash}emph\{digit debris\} (where target digits are occluded by digit fragments). We find that recurrent neural networks outperform feedforward control models (approximately matched in parametric complexity) at recognising objects, both in the absence of occlusion and in all occlusion conditions. Recurrent networks were also found to be more robust to the inclusion of additive Gaussian noise. Recurrent neural networks are better in two respects: (1) they are more neurobiologically realistic than their feedforward counterparts; (2) they are better in terms of their ability to recognise objects, especially under challenging conditions. This work shows that computer vision can benefit from using recurrent convolutional architectures and suggests that the ubiquitous recurrent connections in biological brains are essential for task performance.},
	language = {English},
	urldate = {2019-05-02},
	journal = {Front. Psychol.},
	author = {Spoerer, Courtney J. and McClure, Patrick and Kriegeskorte, Nikolaus},
	year = {2017},
	keywords = {recurrent neural network, object recognition, Convolutional Neural Network, occlusion, top-down processing},
	file = {Full Text PDF:/Users/tito/Zotero/storage/XLT5ZGK9/Spoerer et al. - 2017 - Recurrent Convolutional Neural Networks A Better .pdf:application/pdf},
}

@article{bijsterbosch_relationship_2019,
	title = {The relationship between spatial configuration and functional connectivity of brain regions revisited},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.44890},
	doi = {10.7554/eLife.44890},
	abstract = {In our previous paper (Bijsterbosch et al., 2018), we showed that network-based modelling of brain connectivity interacts strongly with the shape and exact location of brain regions, such that cross-subject variations in the spatial configuration of functional brain regions are being interpreted as changes in functional connectivity. Here we show that these spatial effects on connectivity estimates actually occur as a result of spatial overlap between brain networks. This is shown to systematically bias connectivity estimates obtained from group spatial ICA followed by dual regression. We introduce an extended method that addresses the bias and achieves more accurate connectivity estimates.},
	urldate = {2019-05-08},
	journal = {eLife},
	author = {Bijsterbosch, Janine Diane and Beckmann, Christian F and Woolrich, Mark W and Smith, Stephen M and Harrison, Samuel J},
	editor = {Honey, Chris},
	month = may,
	year = {2019},
	pages = {e44890},
	file = {Full Text PDF:/Users/tito/Zotero/storage/VU9W6ACY/Bijsterbosch et al. - 2019 - The relationship between spatial configuration and.pdf:application/pdf},
}

@article{shine_neuromodulatory_2019,
	title = {Neuromodulatory {Influences} on {Integration} and {Segregation} in the {Brain}},
	volume = {0},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(19)30094-4},
	doi = {10.1016/j.tics.2019.04.002},
	language = {English},
	number = {0},
	urldate = {2019-05-08},
	journal = {Trends in Cognitive Sciences},
	author = {Shine, James M.},
	month = may,
	year = {2019},
	keywords = {integration, neural gain, noradrenaline, neuromodulation, acetyl choline, segregation},
	file = {Full Text PDF:/Users/tito/Zotero/storage/YPLNYEXP/Shine - 2019 - Neuromodulatory Influences on Integration and Segr.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/QIDGHKQW/S1364-6613(19)30094-4.html:text/html},
}

@article{ashourvan_dynamical_2019,
	title = {A dynamical systems framework to uncover the drivers of large-scale cortical activity},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/638718v1},
	doi = {10.1101/638718},
	abstract = {{\textless}p{\textgreater}A fundamental challenge in neuroscience is to uncover the principles governing complex interactions between the brain and its external environment. Over the past few decades, the development of functional neuroimaging techniques and tools from graph theory, network science, and computational neuroscience have markedly expanded opportunities to study the intrinsic organization of brain activity. However, many current computational models are fundamentally limited by little to no explicit assessment of the brain9s interactions with external stimuli. To address this limitation, we propose a simple scheme that jointly estimates the intrinsic organization of brain activity and extrinsic stimuli. Specifically, we adopt a linear dynamical model (intrinsic activity) under unknown exogenous inputs (e.g., sensory stimuli), and jointly estimate the model parameters and exogenous inputs. First, we demonstrate the utility of this scheme by accurately estimating unknown external stimuli in a synthetic example. Next, we examine brain activity at rest and task for 99 subjects from the Human Connectome Project, and find significant task-related changes in the identified system, and task-related increases in the estimated external inputs showing high similarity to known task regressors. Finally, through detailed examination of fluctuations in the spatial distribution of the oscillatory modes of the estimated system during the resting state, we find an apparent non-stationarity in the profile of modes that span several brain regions including the visual and the dorsal attention systems. The results suggest that these brain structures display a time-varying relationship, or alternatively, receive non-stationary exogenous inputs that can lead to apparent system non-stationarities. Together, our embodied model of brain activity provides an avenue to gain deeper insight into the relationship between cortical functional dynamics and their drivers.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-05-21},
	journal = {bioRxiv},
	author = {Ashourvan, Arian and Pequito, Sérgio and Bertolero, Maxwell and Kim, Jason Z. and Bassett, Danielle S. and Litt, Brian},
	month = may,
	year = {2019},
	pages = {638718},
	file = {Full Text PDF:/Users/tito/Zotero/storage/BEDITENE/Ashourvan et al. - 2019 - A dynamical systems framework to uncover the drive.pdf:application/pdf},
}

@article{ashourvan_dynamical_2019-1,
	title = {A dynamical systems framework to uncover the drivers of large-scale cortical activity},
	url = {http://biorxiv.org/lookup/doi/10.1101/638718},
	doi = {10.1101/638718},
	abstract = {A fundamental challenge in neuroscience is to uncover the principles governing complex interactions between the brain and its external environment. Over the past few decades, the development of functional neuroimaging techniques and tools from graph theory, network science, and computational neuroscience have markedly expanded opportunities to study the intrinsic organization of brain activity. However, many current computational models are fundamentally limited by little to no explicit assessment of the brain’s interactions with external stimuli. To address this limitation, we propose a simple scheme that jointly estimates the intrinsic organization of brain activity and extrinsic stimuli. Speciﬁcally, we adopt a linear dynamical model (intrinsic activity) under unknown exogenous inputs (e.g., sensory stimuli), and jointly estimate the model parameters and exogenous inputs. First, we demonstrate the utility of this scheme by accurately estimating unknown external stimuli in a synthetic example. Next, we examine brain activity at rest and task for 99 subjects from the Human Connectome Project, and ﬁnd signiﬁcant task-related changes in the identiﬁed system, and task-related increases in the estimated external inputs showing high similarity to known task regressors. Finally, through detailed examination of ﬂuctuations in the spatial distribution of the oscillatory modes of the estimated system during the resting state, we ﬁnd an apparent non-stationarity in the proﬁle of modes that span several brain regions including the visual and the dorsal attention systems. The results suggest that these brain structures display a time-varying relationship, or alternatively, receive non-stationary exogenous inputs that can lead to apparent system non-stationarities. Together, our embodied model of brain activity provides an avenue to gain deeper insight into the relationship between cortical functional dynamics and their drivers.},
	language = {en},
	urldate = {2019-05-21},
	journal = {bioRxiv},
	author = {Ashourvan, Arian and Pequito, Sérgio and Bertolero, Maxwell and Kim, Jason Z. and Bassett, Danielle S. and Litt, Brian},
	month = may,
	year = {2019},
	file = {Ashourvan et al. - 2019 - A dynamical systems framework to uncover the drive.pdf:/Users/tito/Zotero/storage/M8LKM82L/Ashourvan et al. - 2019 - A dynamical systems framework to uncover the drive.pdf:application/pdf},
}

@incollection{wu_multiplicative_2016,
	title = {On {Multiplicative} {Integration} with {Recurrent} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/6215-on-multiplicative-integration-with-recurrent-neural-networks.pdf},
	urldate = {2019-05-28},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Wu, Yuhuai and Zhang, Saizheng and Zhang, Ying and Bengio, Yoshua and Salakhutdinov, Ruslan R},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {2856--2864},
	file = {NIPS Full Text PDF:/Users/tito/Zotero/storage/TX5IKPFE/Wu et al. - 2016 - On Multiplicative Integration with Recurrent Neura.pdf:application/pdf;NIPS Snapshot:/Users/tito/Zotero/storage/R4AFW847/6215-on-multiplicative-integration-with-recurrent-neural-networks.html:text/html},
}

@article{young_global_2000,
	title = {Global relationship between anatomical connectivity and activity propagation in the cerebral cortex},
	volume = {355},
	issn = {1471-2970},
	url = {http://www.royalsocietypublishing.org/doi/10.1098/rstb.2000.0553},
	doi = {10.1098/rstb.2000.0553},
	language = {en},
	number = {1393},
	urldate = {2019-06-06},
	journal = {Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
	author = {Kotter, Rolf and Sommer, Friedrich T.},
	editor = {Young, M. P.},
	month = jan,
	year = {2000},
	pages = {127--134},
	file = {Kotter and Sommer - 2000 - Global relationship between anatomical connectivit.pdf:/Users/tito/Zotero/storage/5RU3IHRB/Kotter and Sommer - 2000 - Global relationship between anatomical connectivit.pdf:application/pdf},
}

@article{kashyap_individual-specific_2019-1,
	title = {Individual-specific {fMRI}-{Subspaces} improve functional connectivity prediction of behavior},
	volume = {189},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919300758},
	doi = {10.1016/j.neuroimage.2019.01.069},
	abstract = {There is significant interest in using resting-state functional connectivity (RSFC) to predict human behavior. Good behavioral prediction should in theory require RSFC to be sufficiently distinct across participants; if RSFC were the same across participants, then behavioral prediction would obviously be poor. Therefore, we hypothesize that removing common resting-state functional magnetic resonance imaging (rs-fMRI) signals that are shared across participants would improve behavioral prediction. Here, we considered 803 participants from the human connectome project (HCP) with four rs-fMRI runs. We applied the common and orthogonal basis extraction (COBE) technique to decompose each HCP run into two subspaces: a common (group-level) subspace shared across all participants and a subject-specific subspace. We found that the first common COBE component of the first HCP run was localized to the visual cortex and was unique to the run. On the other hand, the second common COBE component of the first HCP run and the first common COBE component of the remaining HCP runs were highly similar and localized to regions within the default network, including the posterior cingulate cortex and precuneus. Overall, this suggests the presence of run-specific (state-specific) effects that were shared across participants. By removing the first and second common COBE components from the first HCP run, and the first common COBE component from the remaining HCP runs, the resulting RSFC improves behavioral prediction by an average of 11.7\% across 58 behavioral measures spanning cognition, emotion and personality.},
	urldate = {2019-06-06},
	journal = {NeuroImage},
	author = {Kashyap, Rajan and Kong, Ru and Bhattacharjee, Sagarika and Li, Jingwei and Zhou, Juan and Thomas Yeo, B. T.},
	month = apr,
	year = {2019},
	keywords = {Cross-validation, Elastic net, Functional connectivity fingerprint, State, Trait},
	pages = {804--812},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/SE9A2CKQ/Kashyap et al. - 2019 - Individual-specific fMRI-Subspaces improve functio.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/VQSIB2WP/S1053811919300758.html:text/html},
}

@article{li_global_2019,
	title = {Global signal regression strengthens association between resting-state functional connectivity and behavior},
	volume = {196},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919303027},
	doi = {10.1016/j.neuroimage.2019.04.016},
	abstract = {Global signal regression (GSR) is one of the most debated preprocessing strategies for resting-state functional MRI. GSR effectively removes global artifacts driven by motion and respiration, but also discards globally distributed neural information and introduces negative correlations between certain brain regions. The vast majority of previous studies have focused on the effectiveness of GSR in removing imaging artifacts, as well as its potential biases. Given the growing interest in functional connectivity fingerprinting, here we considered the utilitarian question of whether GSR strengthens or weakens associations between resting-state functional connectivity (RSFC) and multiple behavioral measures across cognition, personality and emotion. By applying the variance component model to the Brain Genomics Superstruct Project (GSP), we found that behavioral variance explained by whole-brain RSFC increased by an average of 47\% across 23 behavioral measures after GSR. In the Human Connectome Project (HCP), we found that behavioral variance explained by whole-brain RSFC increased by an average of 40\% across 58 behavioral measures, when GSR was applied after ICA-FIX de-noising. To ensure generalizability, we repeated our analyses using kernel regression. GSR improved behavioral prediction accuracies by an average of 64\% and 12\% in the GSP and HCP datasets respectively. Importantly, the results were consistent across methods. A behavioral measure with greater RSFC-explained variance (using the variance component model) also exhibited greater prediction accuracy (using kernel regression). A behavioral measure with greater improvement in behavioral variance explained after GSR (using the variance component model) also enjoyed greater improvement in prediction accuracy after GSR (using kernel regression). Furthermore, GSR appeared to benefit task performance measures more than self-reported measures. Since GSR was more effective at removing motion-related and respiratory-related artifacts, GSR-related increases in variance explained and prediction accuracies were unlikely the result of motion-related or respiratory-related artifacts. However, it is worth emphasizing that the current study focused on whole-brain RSFC, so it remains unclear whether GSR improves RSFC-behavioral associations for specific connections or networks. Overall, our results suggest that at least in the case for young healthy adults, GSR strengthens the associations between RSFC and most (although not all) behavioral measures. Code for the variance component model and ridge regression can be found here: https://github.com/ThomasYeoLab/CBIG/tree/master/stable\_projects/preprocessing/Li2019\_GSR.},
	urldate = {2019-06-06},
	journal = {NeuroImage},
	author = {Li, Jingwei and Kong, Ru and Liégeois, Raphaël and Orban, Csaba and Tan, Yanrui and Sun, Nanbo and Holmes, Avram J. and Sabuncu, Mert R. and Ge, Tian and Yeo, B. T. Thomas},
	month = aug,
	year = {2019},
	keywords = {Resting-state functional MRI, Big five personality, Fingerprinting, Fluid intelligence, Human connectome project, Inter-subject variability},
	pages = {126--141},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/QTRP2VX7/Li et al. - 2019 - Global signal regression strengthens association b.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/LQQNTWMB/S1053811919303027.html:text/html},
}

@article{mul_siamese_2019,
	title = {Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization},
	url = {http://arxiv.org/abs/1906.00180},
	abstract = {Can neural nets learn logic? We approach this classic question with current methods, and demonstrate that recurrent neural networks can learn to recognize first order logical entailment relations between expressions. We define an artificial language in first-order predicate logic, generate a large dataset of sample 'sentences', and use an automatic theorem prover to infer the relation between random pairs of such sentences. We describe a Siamese neural architecture trained to predict the logical relation, and experiment with recurrent and recursive networks. Siamese Recurrent Networks are surprisingly successful at the entailment recognition task, reaching near perfect performance on novel sentences (consisting of known words), and even outperforming recursive networks. We report a series of experiments to test the ability of the models to perform compositional generalization. In particular, we study how they deal with sentences of unseen length, and sentences containing unseen words. We show that set-ups using LSTMs and GRUs obtain high scores on these tests, demonstrating a form of compositionality.},
	urldate = {2019-06-09},
	journal = {arXiv:1906.00180 [cs]},
	author = {Mul, Mathijs and Zuidema, Willem},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00180},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: 12 pages, 5 figures},
	file = {arXiv\:1906.00180 PDF:/Users/tito/Zotero/storage/IHMQHE4X/Mul and Zuidema - 2019 - Siamese recurrent networks learn first-order logic.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/VC9IPUSH/1906.html:text/html},
}

@article{margulies_situating_2016,
	title = {Situating the default-mode network along a principal gradient of macroscale cortical organization},
	volume = {113},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/113/44/12574},
	doi = {10.1073/pnas.1608282113},
	abstract = {Understanding how the structure of cognition arises from the topographical organization of the cortex is a primary goal in neuroscience. Previous work has described local functional gradients extending from perceptual and motor regions to cortical areas representing more abstract functions, but an overarching framework for the association between structure and function is still lacking. Here, we show that the principal gradient revealed by the decomposition of connectivity data in humans and the macaque monkey is anchored by, at one end, regions serving primary sensory/motor functions and at the other end, transmodal regions that, in humans, are known as the default-mode network (DMN). These DMN regions exhibit the greatest geodesic distance along the cortical surface—and are precisely equidistant—from primary sensory/motor morphological landmarks. The principal gradient also provides an organizing spatial framework for multiple large-scale networks and characterizes a spectrum from unimodal to heteromodal activity in a functional metaanalysis. Together, these observations provide a characterization of the topographical organization of cortex and indicate that the role of the DMN in cognition might arise from its position at one extreme of a hierarchy, allowing it to process transmodal information that is unrelated to immediate sensory input.},
	language = {en},
	number = {44},
	urldate = {2019-06-17},
	journal = {PNAS},
	author = {Margulies, Daniel S. and Ghosh, Satrajit S. and Goulas, Alexandros and Falkiewicz, Marcel and Huntenburg, Julia M. and Langs, Georg and Bezgin, Gleb and Eickhoff, Simon B. and Castellanos, F. Xavier and Petrides, Michael and Jefferies, Elizabeth and Smallwood, Jonathan},
	month = nov,
	year = {2016},
	pmid = {27791099},
	keywords = {connectivity, topography, default-mode network, cortical organization, gradients},
	pages = {12574--12579},
	file = {Full Text PDF:/Users/tito/Zotero/storage/8PAWE8GR/Margulies et al. - 2016 - Situating the default-mode network along a princip.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JHB8YXUS/12574.html:text/html},
}

@article{huntenburg_large-scale_2018,
	title = {Large-{Scale} {Gradients} in {Human} {Cortical} {Organization}},
	volume = {22},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661317302401},
	doi = {10.1016/j.tics.2017.11.002},
	abstract = {Recent advances in mapping cortical areas in the human brain provide a basis for investigating the significance of their spatial arrangement. Here we describe a dominant gradient in cortical features that spans between sensorimotor and transmodal areas. We propose that this gradient constitutes a core organizing axis of the human cerebral cortex, and describe an intrinsic coordinate system on its basis. Studying the cortex with respect to these intrinsic dimensions can inform our understanding of how the spectrum of cortical function emerges from structural constraints.},
	number = {1},
	urldate = {2019-06-17},
	journal = {Trends in Cognitive Sciences},
	author = {Huntenburg, Julia M. and Bazin, Pierre-Louis and Margulies, Daniel S.},
	month = jan,
	year = {2018},
	keywords = {gradient, cortical organization, functional hierarchy, intrinsic coordinate system, spatial arrangement},
	pages = {21--31},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/V35RZBRF/Huntenburg et al. - 2018 - Large-Scale Gradients in Human Cortical Organizati.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/GA8U39Z6/S1364661317302401.html:text/html},
}

@article{churchland_preparatory_2006,
	title = {Preparatory {Activity} in {Premotor} and {Motor} {Cortex} {Reflects} the {Speed} of the {Upcoming} {Reach}},
	volume = {96},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00307.2006},
	doi = {10.1152/jn.00307.2006},
	abstract = {Neurons in premotor and motor cortex show preparatory activity during an instructed-delay task. It has been suggested that such activity primarily reflects visuospatial aspects of the movement, such as target location or reach direction and extent. We asked whether a more dynamic feature, movement speed, is also reflected. Two monkeys were trained to reach at different speeds (“slow” or “fast,” peak speed being ∼50–100\% higher for the latter) depending on target color. Targets were presented in seven directions and at two distances. Of 95 neurons with tuned delay-period activity, 95, 78, and 94\% showed a significant influence of direction, distance, and instructed speed, respectively. Average peak modulations with respect to direction, distance and speed were 18, 10, and 11 spikes/s. Although robust, modulations of firing rate with target direction were not necessarily invariant: for 45\% of neurons, the preferred direction depended significantly on target distance and/or instructed speed. We collected an additional dataset, examining in more detail the effect of target distance (5 distances from 3 to 12 cm in 2 directions). Of 41 neurons with tuned delay-period activity, 85, 83, and 98\% showed a significant impact of direction, distance, and instructed speed. Statistical interactions between the effects of distance and instructed speed were common, but it was nevertheless clear that distance “tuning” was not in general a simple consequence of speed tuning. We conclude that delay-period preparatory activity robustly reflects a nonspatial aspect of the upcoming reach. However, it is unclear whether the recorded neural responses conform to any simple reference frame, intrinsic or extrinsic.},
	number = {6},
	urldate = {2019-06-18},
	journal = {Journal of Neurophysiology},
	author = {Churchland, Mark M. and Santhanam, Gopal and Shenoy, Krishna V.},
	month = dec,
	year = {2006},
	pages = {3130--3146},
	file = {Full Text PDF:/Users/tito/Zotero/storage/4AL2C5VA/Churchland et al. - 2006 - Preparatory Activity in Premotor and Motor Cortex .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Z5TSLL3K/jn.00307.html:text/html},
}

@article{rolnick_tackling_2019,
	title = {Tackling {Climate} {Change} with {Machine} {Learning}},
	url = {http://arxiv.org/abs/1906.05433},
	abstract = {Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by machine learning, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the machine learning community to join the global effort against climate change.},
	urldate = {2019-06-19},
	journal = {arXiv:1906.05433 [cs, stat]},
	author = {Rolnick, David and Donti, Priya L. and Kaack, Lynn H. and Kochanski, Kelly and Lacoste, Alexandre and Sankaran, Kris and Ross, Andrew Slavin and Milojevic-Dupont, Nikola and Jaques, Natasha and Waldman-Brown, Anna and Luccioni, Alexandra and Maharaj, Tegan and Sherwin, Evan D. and Mukkavilli, S. Karthik and Kording, Konrad P. and Gomes, Carla and Ng, Andrew Y. and Hassabis, Demis and Platt, John C. and Creutzig, Felix and Chayes, Jennifer and Bengio, Yoshua},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.05433},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computers and Society},
	file = {arXiv\:1906.05433 PDF:/Users/tito/Zotero/storage/J8Y6HG2V/Rolnick et al. - 2019 - Tackling Climate Change with Machine Learning.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/V24XEVMD/1906.html:text/html},
}

@article{liegeois_interpreting_2017,
	title = {Interpreting temporal fluctuations in resting-state functional connectivity {MRI}},
	volume = {163},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917307516},
	doi = {10.1016/j.neuroimage.2017.09.012},
	abstract = {Resting-state functional connectivity is a powerful tool for studying human functional brain networks. Temporal fluctuations in functional connectivity, i.e., dynamic functional connectivity (dFC), are thought to reflect dynamic changes in brain organization and non-stationary switching of discrete brain states. However, recent studies have suggested that dFC might be attributed to sampling variability of static FC. Despite this controversy, a detailed exposition of stationarity and statistical testing of dFC is lacking in the literature. This article seeks an in-depth exploration of these statistical issues at a level appealing to both neuroscientists and statisticians. We first review the statistical notion of stationarity, emphasizing its reliance on ensemble statistics. In contrast, all FC measures depend on sample statistics. An important consequence is that the space of stationary signals is much broader than expected, e.g., encompassing hidden markov models (HMM) widely used to extract discrete brain states. In other words, stationarity does not imply the absence of brain states. We then expound the assumptions underlying the statistical testing of dFC. It turns out that the two popular frameworks - phase randomization (PR) and autoregressive randomization (ARR) - generate stationary, linear, Gaussian null data. Therefore, statistical rejection can be due to non-stationarity, nonlinearity and/or non-Gaussianity. For example, the null hypothesis can be rejected for the stationary HMM due to nonlinearity and non-Gaussianity. Finally, we show that a common form of ARR (bivariate ARR) is susceptible to false positives compared with PR and an adapted version of ARR (multivariate ARR). Application of PR and multivariate ARR to Human Connectome Project data suggests that the stationary, linear, Gaussian null hypothesis cannot be rejected for most participants. However, failure to reject the null hypothesis does not imply that static FC can fully explain dFC. We find that first order AR models explain temporal FC fluctuations significantly better than static FC models. Since first order AR models encode both static FC and one-lag FC, this suggests the presence of dynamical information beyond static FC. Furthermore, even in subjects where the null hypothesis was rejected, AR models explain temporal FC fluctuations significantly better than a popular HMM, suggesting the lack of discrete states (as measured by resting-state fMRI). Overall, our results suggest that AR models are not only useful as a means for generating null data, but may be a powerful tool for exploring the dynamical properties of resting-state fMRI. Finally, we discuss how apparent contradictions in the growing dFC literature might be reconciled.},
	urldate = {2019-06-19},
	journal = {NeuroImage},
	author = {Liégeois, Raphaël and Laumann, Timothy O. and Snyder, Abraham Z. and Zhou, Juan and Yeo, B. T. Thomas},
	month = dec,
	year = {2017},
	keywords = {Autoregressive model, Brain states, Dynamic FC, Linear dynamical systems, Stationarity, Surrogate data},
	pages = {437--455},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/VHMLSWWG/Liégeois et al. - 2017 - Interpreting temporal fluctuations in resting-stat.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/MJL3AFNQ/S1053811917307516.html:text/html},
}

@article{gouwens_classification_2019,
	title = {Classification of electrophysiological and morphological neuron types in the mouse visual cortex},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0417-0},
	doi = {10.1038/s41593-019-0417-0},
	abstract = {Gouwens et al. established a morpho-electrical taxonomy of cell types for the mouse visual cortex via unsupervised clustering analysis of multiple quantitative features from 1,938 neurons available online at the Allen Cell Types Database.},
	language = {En},
	urldate = {2019-06-19},
	journal = {Nature Neuroscience},
	author = {Gouwens, Nathan W. and Sorensen, Staci A. and Berg, Jim and Lee, Changkyu and Jarsky, Tim and Ting, Jonathan and Sunkin, Susan M. and Feng, David and Anastassiou, Costas A. and Barkan, Eliza and Bickley, Kris and Blesie, Nicole and Braun, Thomas and Brouner, Krissy and Budzillo, Agata and Caldejon, Shiella and Casper, Tamara and Castelli, Dan and Chong, Peter and Crichton, Kirsten and Cuhaciyan, Christine and Daigle, Tanya L. and Dalley, Rachel and Dee, Nick and Desta, Tsega and Ding, Song-Lin and Dingman, Samuel and Doperalski, Alyse and Dotson, Nadezhda and Egdorf, Tom and Fisher, Michael and Frates, Rebecca A. de and Garren, Emma and Garwood, Marissa and Gary, Amanda and Gaudreault, Nathalie and Godfrey, Keith and Gorham, Melissa and Gu, Hong and Habel, Caroline and Hadley, Kristen and Harrington, James and Harris, Julie A. and Henry, Alex and Hill, DiJon and Josephsen, Sam and Kebede, Sara and Kim, Lisa and Kroll, Matthew and Lee, Brian and Lemon, Tracy and Link, Katherine E. and Liu, Xiaoxiao and Long, Brian and Mann, Rusty and McGraw, Medea and Mihalas, Stefan and Mukora, Alice and Murphy, Gabe J. and Ng, Lindsay and Ngo, Kiet and Nguyen, Thuc Nghi and Nicovich, Philip R. and Oldre, Aaron and Park, Daniel and Parry, Sheana and Perkins, Jed and Potekhina, Lydia and Reid, David and Robertson, Miranda and Sandman, David and Schroedter, Martin and Slaughterbeck, Cliff and Soler-Llavina, Gilberto and Sulc, Josef and Szafer, Aaron and Tasic, Bosiljka and Taskin, Naz and Teeter, Corinne and Thatra, Nivretta and Tung, Herman and Wakeman, Wayne and Williams, Grace and Young, Rob and Zhou, Zhi and Farrell, Colin and Peng, Hanchuan and Hawrylycz, Michael J. and Lein, Ed and Ng, Lydia and Arkhipov, Anton and Bernard, Amy and Phillips, John W. and Zeng, Hongkui and Koch, Christof},
	month = jun,
	year = {2019},
	pages = {1},
	file = {Full Text PDF:/Users/tito/Zotero/storage/RC9687SF/Gouwens et al. - 2019 - Classification of electrophysiological and morphol.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4TQ3C3RM/s41593-019-0417-0.html:text/html},
}

@article{wang_heterogeneity_2006-1,
	title = {Heterogeneity in the pyramidal network of the medial prefrontal cortex},
	volume = {9},
	copyright = {2006 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn1670},
	doi = {10.1038/nn1670},
	abstract = {The prefrontal cortex is specially adapted to generate persistent activity that outlasts stimuli and is resistant to distractors, presumed to be the basis of working memory. The pyramidal network that supports this activity is unknown. Multineuron patch-clamp recordings in the ferret medial prefrontal cortex showed a heterogeneity of synapses interconnecting distinct subnetworks of different pyramidal cells. One subnetwork was similar to the pyramidal network commonly found in primary sensory areas, consisting of accommodating pyramidal cells interconnected with depressing synapses. The other subnetwork contained complex pyramidal cells with dual apical dendrites displaying nonaccommodating discharge patterns; these cells were hyper-reciprocally connected with facilitating synapses displaying pronounced synaptic augmentation and post-tetanic potentiation. These cellular, synaptic and network properties could amplify recurrent interactions between pyramidal neurons and support persistent activity in the prefrontal cortex.},
	language = {En},
	number = {4},
	urldate = {2019-06-19},
	journal = {Nature Neuroscience},
	author = {Wang, Yun and Markram, Henry and Goodman, Philip H. and Berger, Thomas K. and Ma, Junying and Goldman-Rakic, Patricia S.},
	month = apr,
	year = {2006},
	pages = {534},
	file = {Full Text PDF:/Users/tito/Zotero/storage/8WC4Q3AG/Wang et al. - 2006 - Heterogeneity in the pyramidal network of the medi.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JYA2W4T8/nn1670.html:text/html},
}

@article{markram_interneurons_2004,
	title = {Interneurons of the neocortical inhibitory system},
	volume = {5},
	copyright = {2004 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn1519},
	doi = {10.1038/nrn1519},
	abstract = {The cortical microcircuit seems to be a stereotyped unit that has been replicated and adapted to serve specific computational functions in different regions of the neocortex. An important element of this microcircuit is the wide variety of interneurons, most of which are inhibitory. Interneurons share several common features, but also show considerable diversity.
                  
                  
                    Morphologically, interneurons can be divided into several groups: basket cells (large, small or nest basket cells); chandelier cells; Martinotti cells; bipolar cells; double bouquet cells; bitufted cells; neurogliaform cells; and layer I interneurons. However, the morphology of an interneuron does not define it; within a given morphological type, interneurons can show widely varying electrical or molecular properties.
                  
                  
                    Interneurons can also be divided according to their steady-state or initial responses to stimuli. The main divisions are accommodating, non-accommodating, stuttering, irregular spiking and bursting, and each of these types is subdivided into three classes depending on the characteristics of the initial firing pattern (delayed, bursting or classical). These response types are useful markers, regardless of whether they define discrete classes (as opposed to a continuum).
                  
                  
                    This electrical diversity arises from active properties (ion-channel combinations) and passive properties (the morphology of the neuron). The ion-channel genes that are expressed by an interneuron correlate with its electrophysiological properties. Ion-channel expression seems to fall into three clusters, which map around the three calcium-binding proteins (parvalbumin, calbindin and calretinin) that are expressed in separate populations of interneuron.
                  
                  
                    Other markers that can be used to define interneurons include neuropeptides. Although no one neuropeptide defines a specific interneuron type, some interneuron types tend to express specific combinations of neuropeptides.
                  
                  
                    Excitatory synapses formed by pyramidal neurons onto inhibitory interneurons differ from those formed onto excitatory neurons in terms of receptor subtypes and facilitation. In return, interneurons make inhibitory synapses onto pyramidal neurons that are targeted to specific cellular domains (the dendrites, cell body or axon). Interneurons also receive inhibitory synapses from other interneurons. However, such connections seem to be sparse.
                  
                  
                    The diversity of interneurons might be required to achieve a balance between inhibition and excitation in the neocortex. It is not yet clear whether this diversity represents a continuum or distinct classes of interneuron, although anatomical classes seem to be clear. Gene-expression studies should help to clarify this issue.
                  
                
               The cortical microcircuit seems to be a stereotyped unit that has been replicated and adapted to serve specific computational functions in different regions of the neocortex. An important element of this microcircuit is the wide variety of interneurons, most of which are inhibitory. Interneurons share several common features, but also show considerable diversity. Morphologically, interneurons can be divided into several groups: basket cells (large, small or nest basket cells); chandelier cells; Martinotti cells; bipolar cells; double bouquet cells; bitufted cells; neurogliaform cells; and layer I interneurons. However, the morphology of an interneuron does not define it; within a given morphological type, interneurons can show widely varying electrical or molecular properties. Interneurons can also be divided according to their steady-state or initial responses to stimuli. The main divisions are accommodating, non-accommodating, stuttering, irregular spiking and bursting, and each of these types is subdivided into three classes depending on the characteristics of the initial firing pattern (delayed, bursting or classical). These response types are useful markers, regardless of whether they define discrete classes (as opposed to a continuum). This electrical diversity arises from active properties (ion-channel combinations) and passive properties (the morphology of the neuron). The ion-channel genes that are expressed by an interneuron correlate with its electrophysiological properties. Ion-channel expression seems to fall into three clusters, which map around the three calcium-binding proteins (parvalbumin, calbindin and calretinin) that are expressed in separate populations of interneuron. Other markers that can be used to define interneurons include neuropeptides. Although no one neuropeptide defines a specific interneuron type, some interneuron types tend to express specific combinations of neuropeptides. Excitatory synapses formed by pyramidal neurons onto inhibitory interneurons differ from those formed onto excitatory neurons in terms of receptor subtypes and facilitation. In return, interneurons make inhibitory synapses onto pyramidal neurons that are targeted to specific cellular domains (the dendrites, cell body or axon). Interneurons also receive inhibitory synapses from other interneurons. However, such connections seem to be sparse. The diversity of interneurons might be required to achieve a balance between inhibition and excitation in the neocortex. It is not yet clear whether this diversity represents a continuum or distinct classes of interneuron, although anatomical classes seem to be clear. Gene-expression studies should help to clarify this issue.},
	language = {En},
	number = {10},
	urldate = {2019-06-19},
	journal = {Nature Reviews Neuroscience},
	author = {Markram, Henry and Toledo-Rodriguez, Maria and Wang, Yun and Gupta, Anirudh and Silberberg, Gilad and Wu, Caizhi},
	month = oct,
	year = {2004},
	pages = {793},
	file = {Full Text PDF:/Users/tito/Zotero/storage/E265M3IH/Markram et al. - 2004 - Interneurons of the neocortical inhibitory system.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/C787PYIH/nrn1519.html:text/html},
}

@article{bashivan_neural_2019,
	title = {Neural population control via deep image synthesis},
	volume = {364},
	copyright = {Copyright © 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/364/6439/eaav9436},
	doi = {10.1126/science.aav9436},
	abstract = {Predicting behavior of visual neurons
To what extent are predictive deep learning models of neural responses useful for generating experimental hypotheses? Bashivan et al. took an artificial neural network built to model the behavior of the target visual system and used it to construct images predicted to either broadly activate large populations of neurons or selectively activate one population while keeping the others unchanged. They then analyzed the effectiveness of these images in producing the desired effects in the macaque visual cortex. The manipulations showed very strong effects and achieved considerable and highly selective influence over the neuronal populations. Using novel and non-naturalistic images, the neural network was shown to reproduce the overall behavior of the animals' neural responses.
Science, this issue p. eaav9436
Structured Abstract
INTRODUCTIONThe pattern of light that strikes the eyes is processed and re-represented via patterns of neural activity in a “deep” series of six interconnected cortical brain areas called the ventral visual stream. Visual neuroscience research has revealed that these patterns of neural activity underlie our ability to recognize objects and their relationships in the world. Recent advances have enabled neuroscientists to build ever more precise models of this complex visual processing. Currently, the best such models are particular deep artificial neural network (ANN) models in which each brain area has a corresponding model layer and each brain neuron has a corresponding model neuron. Such models are quite good at predicting the responses of brain neurons, but their contribution to an understanding of primate visual processing remains controversial.
RATIONALEThese ANN models have at least two potential limitations. First, because they aim to be high-fidelity computerized copies of the brain, the total set of computations performed by these models is difficult for humans to comprehend in detail. In that sense, each model seems like a “black box,” and it is unclear what form of understanding has been achieved. Second, the generalization ability of these models has been questioned because they have only been tested on visual stimuli that are similar to those used to “teach” the models. Our goal was to assess both of these potential limitations through nonhuman primate neurophysiology experiments in a mid-level visual brain area. We sought to answer two questions: (i) Despite these ANN models’ opacity to simple “understanding,” is the knowledge embedded in them already useful for a potential application (i.e., neural activity control)? (ii) Do these models accurately predict brain responses to novel images?
RESULTSWe conducted several closed-loop neurophysiology experiments: After matching model neurons to each of the recorded brain neural sites, we used the model to synthesize entirely novel “controller” images based on the model’s implicit knowledge of how the ventral visual stream works. We then presented those images to each subject to test the model’s ability to control the subject’s neurons. In one test, we asked the model to try to control each brain neuron so strongly as to activate it beyond its typically observed maximal activation level. We found that the model-generated synthetic stimuli successfully drove 68\% of neural sites beyond their naturally observed activation levels (chance level is 1\%). In an even more stringent test, the model revealed that it is capable of selectively controlling an entire neural subpopulation, activating a particular neuron while simultaneously inactivating the other recorded neurons (76\% success rate; chance is 1\%).Next, we used these non-natural synthetic controller images to ask whether the model’s ability to predict the brain responses would hold up for these highly novel images. We found that the model was indeed quite accurate, predicting 54\% of the image-evoked patterns of brain response (chance level is 0\%), but it is clearly not yet perfect.
CONCLUSIONEven though the nonlinear computations of deep ANN models of visual processing are difficult to accurately summarize in a few words, they nonetheless provide a shareable way to embed collective knowledge of visual processing, and they can be refined by new knowledge. Our results demonstrate that the currently embedded knowledge already has potential application value (neural control) and that these models can partially generalize outside the world in which they “grew up.” Our results also show that these models are not yet perfect and that more accurate ANN models would produce even more precise neural control. Such noninvasive neural control is not only a potentially powerful tool in the hands of neuroscientists but also could lead to a new class of therapeutic applications. {\textless}img class="fragment-image" aria-describedby="F1-caption" src="https://science.sciencemag.org/content/sci/364/6439/eaav9436/F1.medium.gif"/{\textgreater} Download high-res image Open in new tab Download Powerpoint Collection of images synthesized by a deep neural network model to control the activity of neural populations in primate cortical area V4.We used a deep artificial neural network to control the activity pattern of a population of neurons in cortical area V4 of macaque monkeys by synthesizing visual stimuli that, when applied to the subject’s retinae, successfully induced the experimenter-desired neural response patterns.
Particular deep artificial neural networks (ANNs) are today’s most accurate models of the primate brain’s ventral visual stream. Using an ANN-driven image synthesis method, we found that luminous power patterns (i.e., images) can be applied to primate retinae to predictably push the spiking activity of targeted V4 neural sites beyond naturally occurring levels. This method, although not yet perfect, achieves unprecedented independent control of the activity state of entire populations of V4 neural sites, even those with overlapping receptive fields. These results show how the knowledge embedded in today’s ANN models might be used to noninvasively set desired internal brain states at neuron-level resolution, and suggest that more accurate ANN models would produce even more accurate control.
A deep artificial neural network can model primate vision.
A deep artificial neural network can model primate vision.},
	language = {en},
	number = {6439},
	urldate = {2019-06-19},
	journal = {Science},
	author = {Bashivan, Pouya and Kar, Kohitij and DiCarlo, James J.},
	month = may,
	year = {2019},
	pmid = {31048462},
	pages = {eaav9436},
	file = {Full Text PDF:/Users/tito/Zotero/storage/DBNBFRRX/Bashivan et al. - 2019 - Neural population control via deep image synthesis.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/8JS62GDN/eaav9436.html:text/html},
}

@article{hearne_reconfiguration_2017,
	title = {Reconfiguration of {Brain} {Network} {Architectures} between {Resting}-{State} and {Complexity}-{Dependent} {Cognitive} {Reasoning}},
	volume = {37},
	copyright = {Copyright © 2017 the authors 0270-6474/17/378399-13\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/37/35/8399},
	doi = {10.1523/JNEUROSCI.0485-17.2017},
	abstract = {Our capacity for higher cognitive reasoning has a measurable limit. This limit is thought to arise from the brain's capacity to flexibly reconfigure interactions between spatially distributed networks. Recent work, however, has suggested that reconfigurations of task-related networks are modest when compared with intrinsic “resting-state” network architecture. Here we combined resting-state and task-driven functional magnetic resonance imaging to examine how flexible, task-specific reconfigurations associated with increasing reasoning demands are integrated within a stable intrinsic brain topology. Human participants (21 males and 28 females) underwent an initial resting-state scan, followed by a cognitive reasoning task involving different levels of complexity, followed by a second resting-state scan. The reasoning task required participants to deduce the identity of a missing element in a 4 × 4 matrix, and item difficulty was scaled parametrically as determined by relational complexity theory. Analyses revealed that external task engagement was characterized by a significant change in functional brain modules. Specifically, resting-state and null-task demand conditions were associated with more segregated brain-network topology, whereas increases in reasoning complexity resulted in merging of resting-state modules. Further increments in task complexity did not change the established modular architecture, but affected selective patterns of connectivity between frontoparietal, subcortical, cingulo-opercular, and default-mode networks. Larger increases in network efficiency within the newly established task modules were associated with higher reasoning accuracy. Our results shed light on the network architectures that underlie external task engagement, and highlight selective changes in brain connectivity supporting increases in task complexity.
SIGNIFICANCE STATEMENT Humans have clear limits in their ability to solve complex reasoning problems. It is thought that such limitations arise from flexible, moment-to-moment reconfigurations of functional brain networks. It is less clear how such task-driven adaptive changes in connectivity relate to stable, intrinsic networks of the brain and behavioral performance. We found that increased reasoning demands rely on selective patterns of connectivity within cortical networks that emerged in addition to a more general, task-induced modular architecture. This task-driven architecture reverted to a more segregated resting-state architecture both immediately before and after the task. These findings reveal how flexibility in human brain networks is integral to achieving successful reasoning performance across different levels of cognitive demand.},
	language = {en},
	number = {35},
	urldate = {2019-06-19},
	journal = {J. Neurosci.},
	author = {Hearne, Luke J. and Cocchi, Luca and Zalesky, Andrew and Mattingley, Jason B.},
	month = aug,
	year = {2017},
	pmid = {28760864},
	keywords = {fMRI, connectivity, network, complexity, reasoning, modularity},
	pages = {8399--8411},
	file = {Full Text PDF:/Users/tito/Zotero/storage/H5V26DRY/Hearne et al. - 2017 - Reconfiguration of Brain Network Architectures bet.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VUNQ9KDL/8399.html:text/html},
}

@article{hearne_interactions_2015,
	title = {Interactions between default mode and control networks as a function of increasing cognitive reasoning complexity},
	volume = {36},
	copyright = {© 2015 Wiley Periodicals, Inc.},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.22802},
	doi = {10.1002/hbm.22802},
	abstract = {Successful performance of challenging cognitive tasks depends on a consistent functional segregation of activity within the default-mode network, on the one hand, and control networks encompassing frontoparietal and cingulo-opercular areas on the other. Recent work, however, has suggested that in some cognitive control contexts nodes within the default-mode and control networks may actually cooperate to achieve optimal task performance. Here, we used functional magnetic resonance imaging to examine whether the ability to relate variables while solving a cognitive reasoning problem involves transient increases in connectivity between default-mode and control regions. Participants performed a modified version of the classic Wason selection task, in which the number of variables to be related is systematically varied across trials. As expected, areas within the default-mode network showed a parametric deactivation with increases in relational complexity, compared with neural activity in null trials. Critically, some of these areas also showed enhanced connectivity with task-positive control regions. Specifically, task-based connectivity between the striatum and the angular gyri, and between the thalamus and right temporal pole, increased as a function of relational complexity. These findings challenge the notion that functional segregation between regions within default-mode and control networks invariably support cognitive task performance, and reveal previously unknown roles for the striatum and thalamus in managing network dynamics during cognitive reasoning. Hum Brain Mapp 36:2719–2731, 2015. © 2015 Wiley Periodicals, Inc.},
	language = {en},
	number = {7},
	urldate = {2019-06-19},
	journal = {Human Brain Mapping},
	author = {Hearne, Luke and Cocchi, Luca and Zalesky, Andrew and Mattingley, Jason B.},
	year = {2015},
	keywords = {connectivity, networks, cognitive control, reasoning, default-mode, relational complexity},
	pages = {2719--2731},
	file = {Full Text PDF:/Users/tito/Zotero/storage/8BH7YKLN/Hearne et al. - 2015 - Interactions between default mode and control netw.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MNLXQI2B/hbm.html:text/html},
}

@article{wen_neural_2018,
	title = {Neural {Encoding} and {Decoding} with {Deep} {Learning} for {Dynamic} {Natural} {Vision}},
	volume = {28},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/28/12/4136/4560155},
	doi = {10.1093/cercor/bhx268},
	abstract = {Abstract.  Convolutional neural network (CNN) driven by image recognition has been shown to be able to explain cortical responses to static pictures at ventral-},
	language = {en},
	number = {12},
	urldate = {2019-06-20},
	journal = {Cereb Cortex},
	author = {Wen, Haiguang and Shi, Junxing and Zhang, Yizhen and Lu, Kun-Han and Cao, Jiayue and Liu, Zhongming},
	month = dec,
	year = {2018},
	pages = {4136--4160},
	file = {Full Text PDF:/Users/tito/Zotero/storage/TXA48FJN/Wen et al. - 2018 - Neural Encoding and Decoding with Deep Learning fo.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/T8I69DRV/4560155.html:text/html},
}

@article{zhang_relationship_2019,
	title = {The {Relationship} between {BOLD} and {Neural} {Activity} {Arises} from {Temporally} {Sparse} {Events}},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/644419v1},
	doi = {10.1101/644419},
	abstract = {{\textless}p{\textgreater}Resting state functional magnetic resonance (rs-fMRI) imaging offers insights into how different brain regions are connected into functional networks. It was recently shown that networks that are almost identical to the ones created from conventional correlation analysis can be obtained from a subset of high-amplitude data, suggesting that the functional networks may be driven by instantaneous co-activations of multiple brain regions rather than ongoing oscillatory processes. The rs-fMRI studies, however, rely on the blood oxygen level dependent (BOLD) signal, which is only indirectly sensitive to neural activity through neurovascular coupling. To provide more direct evidence that the neuronal co-activation events produce the time-varying network patterns seen in rs-fMRI studies, we examined the simultaneous rs-fMRI and local field potential (LFP) recordings in rats performed in our lab over the past several years. We developed complementary analysis methods that focus on either the temporal or spatial domain, and found evidence that the interaction between LFP and BOLD may be driven by instantaneous co-activation events as well. BOLD maps triggered on high-amplitude LFP events resemble co-activation patterns created from rs-fMRI data alone, though the co-activation time points are defined differently in the two cases. Moreover, only LFP events that fall into the highest or lowest thirds of the amplitude distribution result in a BOLD signal that can be distinguished from noise. These findings provide evidence of an electrophysiological basis for the time-varying co-activation patterns observed in previous studies.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-06-25},
	journal = {bioRxiv},
	author = {Zhang, Xiaodi and Pan, Wen-Ju and Keilholz, Shella Dawn},
	month = may,
	year = {2019},
	pages = {644419},
	file = {Full Text PDF:/Users/tito/Zotero/storage/6G922SRK/Zhang et al. - 2019 - The Relationship between BOLD and Neural Activity .pdf:application/pdf},
}

@article{recanatesi_dimensionality_2019,
	title = {Dimensionality compression and expansion in {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1906.00443},
	abstract = {Datasets such as images, text, or movies are embedded in high-dimensional spaces. However, in important cases such as images of objects, the statistical structure in the data constrains samples to a manifold of dramatically lower dimensionality. Learning to identify and extract task-relevant variables from this embedded manifold is crucial when dealing with high-dimensional problems. We find that neural networks are often very effective at solving this task and investigate why. To this end, we apply state-of-the-art techniques for intrinsic dimensionality estimation to show that neural networks learn low-dimensional manifolds in two phases: first, dimensionality expansion driven by feature generation in initial layers, and second, dimensionality compression driven by the selection of task-relevant features in later layers. We model noise generated by Stochastic Gradient Descent and show how this noise balances the dimensionality of neural representations by inducing an effective regularization term in the loss. We highlight the important relationship between low-dimensional compressed representations and generalization properties of the network. Our work contributes by shedding light on the success of deep neural networks in disentangling data in high-dimensional space while achieving good generalization. Furthermore, it invites new learning strategies focused on optimizing measurable geometric properties of learned representations, beginning with their intrinsic dimensionality.},
	urldate = {2019-06-25},
	journal = {arXiv:1906.00443 [cs, stat]},
	author = {Recanatesi, Stefano and Farrell, Matthew and Advani, Madhu and Moore, Timothy and Lajoie, Guillaume and Shea-Brown, Eric},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00443},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Submitted to NeurIPS 2019. First two authors contributed equally},
	file = {arXiv\:1906.00443 PDF:/Users/tito/Zotero/storage/78FT9RZ6/Recanatesi et al. - 2019 - Dimensionality compression and expansion in Deep N.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/QHM2VHGD/1906.html:text/html},
}

@article{mill_predicting_2019,
	title = {Predicting dysfunctional age-related task activations from resting-state network alterations},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/678086v1},
	doi = {10.1101/678086},
	abstract = {{\textless}p{\textgreater}Alzheimer9s disease (AD) is linked to changes in fMRI task activations and fMRI resting-state functional connectivity (restFC), which can emerge early in the timecourse of illness. Study of these fMRI correlates of unhealthy aging has been conducted in largely separate subfields. Taking inspiration from neural network simulations, we propose a unifying mechanism wherein restFC network alterations associated with Alzheimer9s disease disrupt the ability for activations to flow between brain regions, leading to aberrant task activations. We apply this activity flow modeling framework in a large sample of clinically unimpaired older adults, which was segregated into healthy (low-risk) and at-risk subgroups based on established imaging (positron emission tomography amyloid) and genetic (apolipoprotein) risk factors for AD. We identified healthy task activations in individuals at low risk for AD, and then by estimating activity flow using at-risk AD restFC data we were able to predict the altered at-risk AD task activations. Thus, modeling the flow of healthy activations over at-risk AD connectivity effectively transformed the healthy aged activations into unhealthy aged activations. These results provide evidence that activity flow over altered intrinsic functional connections may act as a mechanism underlying Alzheimer9s-related dysfunction, even in very early stages of the illness. Beyond these mechanistic insights linking restFC with cognitive task activations, this approach has potential clinical utility as it enables prediction of task activations and associated cognitive dysfunction in individuals without requiring them to perform in-scanner cognitive tasks.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-06-26},
	journal = {bioRxiv},
	author = {Mill, Ravi D. and Gordon, Brian A. and Balota, David A. and Zacks, Jeffrey M. and Cole, Michael W.},
	month = jun,
	year = {2019},
	pages = {678086},
	file = {Full Text PDF:/Users/tito/Zotero/storage/8BTVS9JM/Mill et al. - 2019 - Predicting dysfunctional age-related task activati.pdf:application/pdf},
}

@book{poldrack_handbook_2011,
	title = {Handbook of functional {MRI} data analysis},
	isbn = {1-139-49836-3},
	publisher = {Cambridge University Press},
	author = {Poldrack, Russell A and Mumford, Jeanette A and Nichols, Thomas E},
	year = {2011},
}

@book{luck_introduction_2014,
	title = {An introduction to the event-related potential technique},
	isbn = {0-262-32406-7},
	publisher = {MIT press},
	author = {Luck, Steven J},
	year = {2014},
}

@article{mcgaugh_involvement_1989,
	title = {Involvement of {Hormonal} and {Neuromodulatory} {Systems} in the {Regulation} of {Memory} {Storage}},
	volume = {12},
	url = {https://doi.org/10.1146/annurev.ne.12.030189.001351},
	doi = {10.1146/annurev.ne.12.030189.001351},
	number = {1},
	urldate = {2019-06-27},
	journal = {Annual Review of Neuroscience},
	author = {McGaugh, J L},
	year = {1989},
	pmid = {2564756},
	pages = {255--287},
}

@article{izquierdo_biochemistry_1997,
	title = {The biochemistry of memory formation and its regulation by hormones and neuromodulators},
	volume = {25},
	issn = {0889-6313},
	url = {https://doi.org/10.3758/BF03327022},
	doi = {10.3758/BF03327022},
	abstract = {Recent findings have shown that the biochemistry of declarative memory in the areas of the brain involved with its formation and retrieval is strikingly similar to that of long-term potentiation. The memory process, like long-term potentiation, involves a sequence of events that starts by the activation of glutamate receptors, is followed by a variety of enzymatic changes, and involves, some hours after its initiation, gene transcription and protein synthesis. This sequence of events takes place in the hippocampus and, depending on the task, also in amygdala and medial septum and, minutes later, probably in cortical areas of the brain. Peripheral hormones and a variety of brain neuromodulatory systems may enhance or depress different steps of the biochemical sequence. The hormones act in some cases directly on the hippocampus and amygdala (glucocorticoids), and in others (corticotropin, epinephrine) indirectly, through reflex actions on brain neuromodulatory systems (noradrenergic, cholinergic, endorphinergic). The best studied modulatory systems are those related to stress. However, many findings demonstrate a key role in memory modulation of dopaminergic synapses, of brain benzodiazepine-like substances, and perhaps of serotonin acting at specific steps of the biochemistry of memory processes in the hippocampus, amygdala, or elsewhere. Since these systems are involved in the regulation of anxiety and mood, the findings suggest a strong relation between anxiety, mood, and memory, both in normal and in pathological conditions.},
	language = {en},
	number = {1},
	urldate = {2019-06-27},
	journal = {Psychobiology},
	author = {Izquierdo, Ivan and Medina, Jorge H.},
	month = mar,
	year = {1997},
	keywords = {Entorhinal Cortex, Flumazenil, Medial Septum, Memory Consolidation, Memory Formation},
	pages = {1--9},
	file = {Springer Full Text PDF:/Users/tito/Zotero/storage/TNQQBDEE/Izquierdo and Medina - 1997 - The biochemistry of memory formation and its regul.pdf:application/pdf},
}

@article{kay_principles_2018,
	series = {New advances in encoding and decoding of brain signals},
	title = {Principles for models of neural information processing},
	volume = {180},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917306638},
	doi = {10.1016/j.neuroimage.2017.08.016},
	abstract = {The goal of cognitive neuroscience is to understand how mental operations are performed by the brain. Given the complexity of the brain, this is a challenging endeavor that requires the development of formal models. Here, I provide a perspective on models of neural information processing in cognitive neuroscience. I define what these models are, explain why they are useful, and specify criteria for evaluating models. I also highlight the difference between functional and mechanistic models, and call attention to the value that neuroanatomy has for understanding brain function. Based on the principles I propose, I proceed to evaluate the merit of recently touted deep neural network models. I contend that these models are promising, but substantial work is necessary (i) to clarify what type of explanation these models provide, (ii) to determine what specific effects they accurately explain, and (iii) to improve our understanding of how they work.},
	urldate = {2019-06-27},
	journal = {NeuroImage},
	author = {Kay, Kendrick N.},
	month = oct,
	year = {2018},
	pages = {101--109},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/9IH25TGZ/Kay - 2018 - Principles for models of neural information proces.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/C99EESLD/S1053811917306638.html:text/html},
}

@article{song_highly_2005,
	title = {Highly {Nonrandom} {Features} of {Synaptic} {Connectivity} in {Local} {Cortical} {Circuits}},
	volume = {3},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.0030068},
	doi = {10.1371/journal.pbio.0030068},
	language = {en},
	number = {3},
	urldate = {2019-07-02},
	journal = {PLoS Biology},
	author = {Song, Sen and Sjöström, Per Jesper and Reigl, Markus and Nelson, Sacha and Chklovskii, Dmitri B},
	editor = {Friston, Karl J.},
	month = mar,
	year = {2005},
	pages = {e68},
	file = {Song et al. - 2005 - Highly Nonrandom Features of Synaptic Connectivity.pdf:/Users/tito/Zotero/storage/FUEZ73JU/Song et al. - 2005 - Highly Nonrandom Features of Synaptic Connectivity.pdf:application/pdf},
}

@article{sheffield_accelerated_2019,
	title = {Accelerated {Aging} of {Functional} {Brain} {Networks} {Supporting} {Cognitive} {Function} in {Psychotic} {Disorders}},
	issn = {0006-3223},
	url = {http://www.sciencedirect.com/science/article/pii/S0006322318321206},
	doi = {10.1016/j.biopsych.2018.12.016},
	abstract = {Background
Across networks, connectivity within the frontoparietal network (FPN) and cingulo-opercular network (CON) exhibits reductions earliest during healthy aging, contributing to cognitive impairment. Individuals with psychotic disorders demonstrate evidence of accelerated aging across multiple biological systems. By leveraging a large sample of patients with psychosis from early to chronic illness stages, this study sought to determine whether the CON and FPN exhibit evidence of accelerated aging in psychotic disorders, confirm associations between network efficiency and cognition, and determine whether reduced network efficiency is observed in early-stage psychosis.
Methods
Resting-state functional magnetic resonance imaging and cognitive data were obtained on 240 patients with psychotic disorder and 178 healthy control participants (HCs). Global efficiency, a measure of functional integration, was calculated for the CON, FPN, subcortical network, and visual network. Associations with age and cognition were assessed and compared between groups.
Results
Consistent with accelerated aging, significant group by age interactions reflected significantly stronger relationships between efficiency and age in patients with psychosis than in HCs for both the CON (psychosis: r = −.37; HC: r = −.16) and FPN (psychosis: r = −.31; HC: r = −.05). Accelerated aging was not observed in either the subcortical or visual network, suggesting specificity for cognitive networks that decline earliest in healthy aging. Replicating prior findings, efficiency of both the CON and FPN correlated with cognitive function across all participants (rs {\textgreater} .11, ps {\textless} .031). Furthermore, patients with chronic psychosis (p = .004), but not patients with early psychosis (p = .553), exhibited significantly lower FPN efficiency compared with HCs.
Conclusions
Functional integration of higher-order cognitive networks is intact in early psychosis but exhibits evidence of accelerated aging, suggesting the potential for intervention targeting cognition within the early psychosis period.},
	urldate = {2019-07-02},
	journal = {Biological Psychiatry},
	author = {Sheffield, Julia M. and Rogers, Baxter P. and Blackford, Jennifer U. and Heckers, Stephan and Woodward, Neil D.},
	month = jan,
	year = {2019},
	keywords = {Cognition, Accelerated aging, Cingulo-opercular network, Early psychosis, Fronto-parietal network, Global efficiency},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/ZVPHZP8W/Sheffield et al. - 2019 - Accelerated Aging of Functional Brain Networks Sup.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/Y5N3NCMK/S0006322318321206.html:text/html},
}

@article{rubinov_constraints_2016,
	title = {Constraints and spandrels of interareal connectomes},
	volume = {7},
	copyright = {2016 Nature Publishing Group},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms13812},
	doi = {10.1038/ncomms13812},
	abstract = {Interareal connectomes are whole-brain wiring diagrams of white-matter pathways. Recent studies have identified modules, hubs, module hierarchies and rich clubs as structural hallmarks of these wiring diagrams. An influential current theory postulates that connectome modules are adequately explained by evolutionary pressures for wiring economy, but that the other hallmarks are not explained by such pressures and are therefore less trivial. Here, we use constraint network models to test these postulates in current gold-standard vertebrate and invertebrate interareal-connectome reconstructions. We show that empirical wiring-cost constraints inadequately explain connectome module organization, and that simultaneous module and hub constraints induce the structural byproducts of hierarchies and rich clubs. These byproducts, known as spandrels in evolutionary biology, include the structural substrate of the default-mode network. Our results imply that currently standard connectome characterizations are based on circular analyses or double dipping, and we emphasize an integrative approach to future connectome analyses for avoiding such pitfalls.},
	language = {en},
	urldate = {2019-07-02},
	journal = {Nature Communications},
	author = {Rubinov, Mikail},
	month = dec,
	year = {2016},
	pages = {13812},
	file = {Full Text PDF:/Users/tito/Zotero/storage/GX2YU8QE/Rubinov - 2016 - Constraints and spandrels of interareal connectome.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/K82AJ8JB/ncomms13812.html:text/html},
}

@article{echeveste_cortical-like_2019,
	title = {Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/696088v1},
	doi = {10.1101/696088},
	abstract = {{\textless}p{\textgreater}Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots, and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory-inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization, as well as stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset, and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of awake monkey recordings. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function -fast sampling-based inference- and predict further properties of these motifs that can be tested in future experiments.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-07-12},
	journal = {bioRxiv},
	author = {Echeveste, Rodrigo and Aitchison, Laurence and Hennequin, Guillaume and Lengyel, Máté},
	month = jul,
	year = {2019},
	pages = {696088},
	file = {Echeveste et al_2019_Cortical-like dynamics in recurrent circuits optimized for sampling-based.pdf:/Users/tito/Zotero/storage/WDZEBN84/Echeveste et al_2019_Cortical-like dynamics in recurrent circuits optimized for sampling-based.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6EA8324B/696088v1.html:text/html},
}

@article{kriegeskorte_peeling_2019,
	title = {Peeling the {Onion} of {Brain} {Representations}},
	volume = {42},
	url = {https://doi.org/10.1146/annurev-neuro-080317-061906},
	doi = {10.1146/annurev-neuro-080317-061906},
	abstract = {The brain's function is to enable adaptive behavior in the world. To this end, the brain processes information about the world. The concept of representation links the information processed by the brain back to the world and enables us to understand what the brain does at a functional level. The appeal of making the connection between brain activity and what it represents has been irresistible to neuroscience, despite the fact that representational interpretations pose several challenges: We must define which aspects of brain activity matter, how the code works, and how it supports computations that contribute to adaptive behavior. It has been suggested that we might drop representational language altogether and seek to understand the brain, more simply, as a dynamical system. In this review, we argue that the concept of representation provides a useful link between dynamics and computational function and ask which aspects of brain activity should be analyzed to achieve a representational understanding. We peel the onion of brain representations in search of the layers (the aspects of brain activity) that matter to computation. The article provides an introduction to the motivation and mathematics of representational models, a critical discussion of their assumptions and limitations, and a preview of future directions in this area.},
	number = {1},
	urldate = {2019-07-15},
	journal = {Annual Review of Neuroscience},
	author = {Kriegeskorte, Nikolaus and Diedrichsen, Jörn},
	year = {2019},
	pmid = {31283895},
	pages = {407--432},
	file = {Kriegeskorte_Diedrichsen_2019_Peeling the Onion of Brain Representations.pdf:/Users/tito/Zotero/storage/NXLINYQX/Kriegeskorte_Diedrichsen_2019_Peeling the Onion of Brain Representations.pdf:application/pdf},
}

@article{pandarinath_inferring_2018,
	title = {Inferring single-trial neural population dynamics using sequential auto-encoders},
	volume = {15},
	issn = {1548-7091, 1548-7105},
	url = {http://www.nature.com/articles/s41592-018-0109-9},
	doi = {10.1038/s41592-018-0109-9},
	language = {en},
	number = {10},
	urldate = {2019-07-15},
	journal = {Nature Methods},
	author = {Pandarinath, Chethan and O’Shea, Daniel J. and Collins, Jasmine and Jozefowicz, Rafal and Stavisky, Sergey D. and Kao, Jonathan C. and Trautmann, Eric M. and Kaufman, Matthew T. and Ryu, Stephen I. and Hochberg, Leigh R. and Henderson, Jaimie M. and Shenoy, Krishna V. and Abbott, L. F. and Sussillo, David},
	month = oct,
	year = {2018},
	pages = {805--815},
	file = {Pandarinath et al. - 2018 - Inferring single-trial neural population dynamics .pdf:/Users/tito/Zotero/storage/XMM67XE3/Pandarinath et al. - 2018 - Inferring single-trial neural population dynamics .pdf:application/pdf},
}

@article{vogels_gating_2009-1,
	title = {Gating multiple signals through detailed balance of excitation and inhibition in spiking networks},
	volume = {12},
	copyright = {2009 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2276},
	doi = {10.1038/nn.2276},
	abstract = {Recent theoretical work has provided a basic understanding of signal propagation in networks of spiking neurons, but mechanisms for gating and controlling these signals have not been investigated previously. Here we introduce an idea for the gating of multiple signals in cortical networks that combines principles of signal propagation with aspects of balanced networks. Specifically, we studied networks in which incoming excitatory signals are normally cancelled by locally evoked inhibition, leaving the targeted layer unresponsive. Transmission can be gated 'on' by modulating excitatory and inhibitory gains to upset this detailed balance. We illustrate gating through detailed balance in large networks of integrate-and-fire neurons. We show successful gating of multiple signals and study failure modes that produce effects reminiscent of clinically observed pathologies. Provided that the individual signals are detectable, detailed balance has a large capacity for gating multiple signals.},
	language = {en},
	number = {4},
	urldate = {2019-07-17},
	journal = {Nature Neuroscience},
	author = {Vogels, Tim P. and Abbott, L. F.},
	month = apr,
	year = {2009},
	pages = {483--491},
	file = {Snapshot:/Users/tito/Zotero/storage/2JAZ7UIC/nn.html:text/html;Vogels_Abbott_2009_Gating multiple signals through detailed balance of excitation and inhibition.pdf:/Users/tito/Zotero/storage/EQ8THZ76/Vogels_Abbott_2009_Gating multiple signals through detailed balance of excitation and inhibition.pdf:application/pdf},
}

@article{lillicrap_what_2019,
	title = {What does it mean to understand a neural network?},
	url = {http://arxiv.org/abs/1907.06374},
	abstract = {We can define a neural network that can learn to recognize objects in less than 100 lines of code. However, after training, it is characterized by millions of weights that contain the knowledge about many object types across visual scenes. Such networks are thus dramatically easier to understand in terms of the code that makes them than the resulting properties, such as tuning or connections. In analogy, we conjecture that rules for development and learning in brains may be far easier to understand than their resulting properties. The analogy suggests that neuroscience would benefit from a focus on learning and development.},
	urldate = {2019-07-17},
	journal = {arXiv:1907.06374 [cs, q-bio, stat]},
	author = {Lillicrap, Timothy P. and Kording, Konrad P.},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.06374},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 9 pages, 2 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/IP33ALKC/1907.html:text/html;Lillicrap_Kording_2019_What does it mean to understand a neural network.pdf:/Users/tito/Zotero/storage/GUV4878T/Lillicrap_Kording_2019_What does it mean to understand a neural network.pdf:application/pdf},
}

@article{chaudhuri_population_2019,
	title = {The population dynamics of a canonical cognitive circuit},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/516021v1},
	doi = {10.1101/516021},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}The brain constructs distributed representations of key low-dimensional variables. These variables may be external stimuli or internal constructs of quantities relevant for survival, such as a sense of one’s location in the world. We consider that the high-dimensional population-level activity vectors are the fundamental representational currency of a neural circuit, and these vectors trace out a low-dimensional manifold whose dimension and topology matches those of the represented variable. This manifold perspective — applied to the mammalian head direction circuit across rich waking behaviors and sleep — enables powerful inferences about circuit representation and mechanism, including: Direct visualization and blind discovery that the network represents a one-dimensional circular variable across waking and REM sleep; fully unsupervised decoding of the coded variable; stability and attractor dynamics in the representation; the discovery of new dynamical trajectories during sleep; the limiting role of external rather than internal noise in the fidelity of memory states; and the conclusion that the circuit is set up to integrate velocity inputs according to classical continuous attractor models.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-07-29},
	journal = {bioRxiv},
	author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
	month = jan,
	year = {2019},
	pages = {516021},
	file = {Chaudhuri et al_2019_The population dynamics of a canonical cognitive circuit.pdf:/Users/tito/Zotero/storage/KXQQVYM7/Chaudhuri et al_2019_The population dynamics of a canonical cognitive circuit.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/KQIWTLHL/516021v1.html:text/html},
}

@article{maheswaranathan_universality_2019,
	title = {Universality and individuality in neural dynamics across large populations of recurrent networks},
	url = {http://arxiv.org/abs/1907.08549},
	abstract = {Task-based modeling with recurrent neural networks (RNNs) has emerged as a popular way to infer the computational function of different brain regions. These models are quantitatively assessed by comparing the low-dimensional neural representations of the model with the brain, for example using canonical correlation analysis (CCA). However, the nature of the detailed neurobiological inferences one can draw from such efforts remains elusive. For example, to what extent does training neural networks to solve common tasks uniquely determine the network dynamics, independent of modeling architectural choices? Or alternatively, are the learned dynamics highly sensitive to different model choices? Knowing the answer to these questions has strong implications for whether and how we should use task-based RNN modeling to understand brain dynamics. To address these foundational questions, we study populations of thousands of networks, with commonly used RNN architectures, trained to solve neuroscientifically motivated tasks and characterize their nonlinear dynamics. We find the geometry of the RNN representations can be highly sensitive to different network architectures, yielding a cautionary tale for measures of similarity that rely representational geometry, such as CCA. Moreover, we find that while the geometry of neural dynamics can vary greatly across architectures, the underlying computational scaffold---the topological structure of fixed points, transitions between them, limit cycles, and linearized dynamics---often appears universal across all architectures.},
	urldate = {2019-07-30},
	journal = {arXiv:1907.08549 [cs, q-bio]},
	author = {Maheswaranathan, Niru and Williams, Alex H. and Golub, Matthew D. and Ganguli, Surya and Sussillo, David},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.08549},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/MIUGCU73/1907.html:text/html;Maheswaranathan et al_2019_Universality and individuality in neural dynamics across large populations of.pdf:/Users/tito/Zotero/storage/EENXCV6P/Maheswaranathan et al_2019_Universality and individuality in neural dynamics across large populations of.pdf:application/pdf},
}

@article{mulliken_decoding_2008,
	title = {Decoding {Trajectories} from {Posterior} {Parietal} {Cortex} {Ensembles}},
	volume = {28},
	url = {http://www.jneurosci.org/content/28/48/12913.abstract},
	doi = {10.1523/JNEUROSCI.1463-08.2008},
	abstract = {High-level cognitive signals in the posterior parietal cortex (PPC) have previously been used to decode the intended endpoint of a reach, providing the first evidence that PPC can be used for direct control of a neural prosthesis (Musallam et al., 2004). Here we expand on this work by showing that PPC neural activity can be harnessed to estimate not only the endpoint but also to continuously control the trajectory of an end effector. Specifically, we trained two monkeys to use a joystick to guide a cursor on a computer screen to peripheral target locations while maintaining central ocular fixation. We found that we could accurately reconstruct the trajectory of the cursor using a relatively small ensemble of simultaneously recorded PPC neurons. Using a goal-based Kalman filter that incorporates target information into the state-space, we showed that the decoded estimate of cursor position could be significantly improved. Finally, we tested whether we could decode trajectories during closed-loop brain control sessions, in which the real-time position of the cursor was determined solely by a monkey's neural activity in PPC. The monkey learned to perform brain control trajectories at 80\% success rate (for 8 targets) after just 4–5 sessions. This improvement in behavioral performance was accompanied by a corresponding enhancement in neural tuning properties (i.e., increased tuning depth and coverage of encoding parameter space) as well as an increase in off-line decoding performance of the PPC ensemble.},
	number = {48},
	journal = {J. Neurosci.},
	author = {Mulliken, Grant H. and Musallam, Sam and Andersen, Richard A.},
	month = nov,
	year = {2008},
	pages = {12913},
	file = {Mulliken et al_2008_Decoding Trajectories from Posterior Parietal Cortex Ensembles.pdf:/Users/tito/Zotero/storage/4S4JU7UV/Mulliken et al_2008_Decoding Trajectories from Posterior Parietal Cortex Ensembles.pdf:application/pdf},
}

@article{golub_fixedpointfinder:_2018,
	title = {{FixedPointFinder}: {A} {Tensorflow} toolbox for identifying and characterizing fixed points in recurrent neural networks},
	volume = {3},
	issn = {2475-9066},
	shorttitle = {{FixedPointFinder}},
	url = {http://joss.theoj.org/papers/10.21105/joss.01003},
	doi = {10.21105/joss.01003},
	abstract = {Recurrent neural networks (RNNs) are powerful function approximators that can be designed or trained to solve a variety of computational tasks. Such tasks require the transformation of a set of time-varying input signals into a set of time-varying output signals. Neuroscientists are increasingly interested in using RNNs to explain complex relationships present in recorded neural activity (Pandarinath et al., 2018) and to propose dynamical mechanisms through which a population of neurons might implement a computation (Mante, Sussillo, Shenoy, \& Newsome, 2013; Remington, Narain, Hosseini, \& Jazayeri, 2018). Once fit to neural recordings or trained to solve a task of interest, an RNN can be reverse-engineered to understand how a computation is implemented in a high-dimensional recurrent neural system, which can suggest hypotheses for how the task might be solved by the brain.},
	language = {en},
	number = {31},
	urldate = {2019-08-12},
	journal = {Journal of Open Source Software},
	author = {Golub, Matthew and Sussillo, David},
	month = nov,
	year = {2018},
	pages = {1003},
	file = {Golub and Sussillo - 2018 - FixedPointFinder A Tensorflow toolbox for identif.pdf:/Users/tito/Zotero/storage/2G27JMB7/Golub and Sussillo - 2018 - FixedPointFinder A Tensorflow toolbox for identif.pdf:application/pdf},
}

@article{runge_causal_2018,
	title = {Causal network reconstruction from time series: {From} theoretical assumptions to practical estimation},
	volume = {28},
	issn = {1054-1500, 1089-7682},
	shorttitle = {Causal network reconstruction from time series},
	url = {http://aip.scitation.org/doi/10.1063/1.5025050},
	doi = {10.1063/1.5025050},
	language = {en},
	number = {7},
	urldate = {2019-08-13},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Runge, J.},
	month = jul,
	year = {2018},
	pages = {075310},
	file = {Runge - 2018 - Causal network reconstruction from time series Fr.pdf:/Users/tito/Zotero/storage/K4DNBEU2/Runge - 2018 - Causal network reconstruction from time series Fr.pdf:application/pdf},
}

@article{varoquaux_cross-validation_2018,
	series = {New advances in encoding and decoding of brain signals},
	title = {Cross-validation failure: {Small} sample sizes lead to large error bars},
	volume = {180},
	issn = {1053-8119},
	shorttitle = {Cross-validation failure},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305311},
	doi = {10.1016/j.neuroimage.2017.06.061},
	abstract = {Predictive models ground many state-of-the-art developments in statistical brain image analysis: decoding, MVPA, searchlight, or extraction of biomarkers. The principled approach to establish their validity and usefulness is cross-validation, testing prediction on unseen data. Here, I would like to raise awareness on error bars of cross-validation, which are often underestimated. Simple experiments show that sample sizes of many neuroimaging studies inherently lead to large error bars, eg ±10\% for 100 samples. The standard error across folds strongly underestimates them. These large error bars compromise the reliability of conclusions drawn with predictive models, such as biomarkers or methods developments where, unlike with cognitive neuroimaging MVPA approaches, more samples cannot be acquired by repeating the experiment across many subjects. Solutions to increase sample size must be investigated, tackling possible increases in heterogeneity of the data.},
	urldate = {2019-08-13},
	journal = {NeuroImage},
	author = {Varoquaux, Gaël},
	month = oct,
	year = {2018},
	keywords = {fMRI, Decoding, Cross-validation, Model selection, MVPA, Statistics, Biomarkers},
	pages = {68--77},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/RSN8DNEG/S1053811917305311.html:text/html;Varoquaux_2018_Cross-validation failure.pdf:/Users/tito/Zotero/storage/TDBTWSTX/Varoquaux_2018_Cross-validation failure.pdf:application/pdf},
}

@article{chaudhuri_intrinsic_2019,
	title = {The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/s41593-019-0460-x},
	doi = {10.1038/s41593-019-0460-x},
	language = {en},
	urldate = {2019-08-15},
	journal = {Nature Neuroscience},
	author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
	month = aug,
	year = {2019},
	file = {Chaudhuri et al. - 2019 - The intrinsic attractor manifold and population dy.pdf:/Users/tito/Zotero/storage/64SFNUDE/Chaudhuri et al. - 2019 - The intrinsic attractor manifold and population dy.pdf:application/pdf},
}

@article{runge_inferring_2019,
	title = {Inferring causation from time series in {Earth} system sciences},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-10105-3},
	doi = {10.1038/s41467-019-10105-3},
	abstract = {Questions of causality are ubiquitous in Earth system sciences and beyond, yet correlation techniques still prevail. This Perspective provides an overview of causal inference methods, identifies promising applications and methodological challenges, and initiates a causality benchmark platform.},
	language = {en},
	number = {1},
	urldate = {2019-08-16},
	journal = {Nat Commun},
	author = {Runge, Jakob and Bathiany, Sebastian and Bollt, Erik and Camps-Valls, Gustau and Coumou, Dim and Deyle, Ethan and Glymour, Clark and Kretschmer, Marlene and Mahecha, Miguel D. and Muñoz-Marí, Jordi and Nes, Egbert H. van and Peters, Jonas and Quax, Rick and Reichstein, Markus and Scheffer, Marten and Schölkopf, Bernhard and Spirtes, Peter and Sugihara, George and Sun, Jie and Zhang, Kun and Zscheischler, Jakob},
	month = jun,
	year = {2019},
	pages = {1--13},
	file = {Runge et al_2019_Inferring causation from time series in Earth system sciences.pdf:/Users/tito/Zotero/storage/GQN9WWEF/Runge et al_2019_Inferring causation from time series in Earth system sciences.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MZ27QFAF/s41467-019-10105-3.html:text/html},
}

@article{yin_graph_nodate,
	title = {A graph representation of functional diversity of brain regions},
	volume = {0},
	copyright = {© 2019 The Authors. Brain and Behavior published by Wiley Periodicals, Inc.},
	issn = {2162-3279},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/brb3.1358},
	doi = {10.1002/brb3.1358},
	abstract = {Introduction Modern network science techniques are popularly used to characterize the functional organization of the brain. A major challenge in network neuroscience is to understand how functional characteristics and topological architecture are related in the brain. Previous task-based functional neuroimaging studies have uncovered a core set of brain regions (e.g., frontal and parietal) supporting diverse cognitive tasks. However, the graph representation of functional diversity of brain regions remains to be understood. Methods Here, we present a novel graph measure, the neighbor dispersion index, to test the hypothesis that the functional diversity of a brain region is embodied by the topological dissimilarity of its immediate neighbors in the large-scale functional brain network. Results We consistently identified in two independent and publicly accessible resting-state functional magnetic resonance imaging datasets that brain regions in the frontoparietal and salience networks showed higher neighbor dispersion index, whereas those in the visual, auditory, and sensorimotor networks showed lower neighbor dispersion index. Moreover, we observed that human fluid intelligence was associated with the neighbor dispersion index of dorsolateral prefrontal cortex, while no such association for the other metrics commonly used for characterizing network hubs was noticed even with an uncorrected p {\textless} .05. Conclusions This newly developed graph theoretical method offers fresh insight into the topological organization of functional brain networks and also sheds light on individual differences in human intelligence.},
	language = {en},
	number = {0},
	urldate = {2019-08-20},
	journal = {Brain and Behavior},
	author = {Yin, Dazhi and Chen, Xiaoyu and Zeljic, Kristina and Zhan, Yafeng and Shen, Xiangyu and Yan, Gang and Wang, Zheng},
	keywords = {graph theory, resting-state fMRI, functional brain networks, functional diversity, human intelligence, neighbor dispersion index, topological architecture},
	pages = {e01358},
	file = {Snapshot:/Users/tito/Zotero/storage/LKRMZ5FX/brb3.html:text/html;Yin et al_A graph representation of functional diversity of brain regions.pdf:/Users/tito/Zotero/storage/MUSGIZT4/Yin et al_A graph representation of functional diversity of brain regions.pdf:application/pdf},
}

@article{zador_critique_2019,
	title = {A critique of pure learning and what artificial neural networks can learn from animal brains},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-11786-6},
	doi = {10.1038/s41467-019-11786-6},
	abstract = {Recent gains in artificial neural networks rely heavily on large amounts of training data. Here, the author suggests that for AI to learn from animal brains, it is important to consider that animal behaviour results from brain connectivity specified in the genome through evolution, and not due to unique learning algorithms.},
	language = {en},
	number = {1},
	urldate = {2019-08-22},
	journal = {Nat Commun},
	author = {Zador, Anthony M.},
	month = aug,
	year = {2019},
	pages = {1--7},
	file = {Snapshot:/Users/tito/Zotero/storage/RVF5GEMA/s41467-019-11786-6.html:text/html;Zador_2019_A critique of pure learning and what artificial neural networks can learn from.pdf:/Users/tito/Zotero/storage/HZXSBZX5/Zador_2019_A critique of pure learning and what artificial neural networks can learn from.pdf:application/pdf},
}

@article{seeliger_neural_2019,
	title = {Neural {System} {Identification} with {Neural} {Information} {Flow}},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/553255v2},
	doi = {10.1101/553255},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Neural information flow (NIF) is a new framework for system identification in neuroscience. NIF subsumes population receptive field estimation, neural encoding, effective connectivity analysis and hemodynamic response estimation in a single differentiable model that can be trained end-to-end via stochastic gradient descent. NIF models represent neural information processing systems as a network of coupled tensors, each encoding the representation of the sensory input contained in a brain region. The elements of these tensors can be interpreted as cortical columns whose activity encodes the presence of a specific feature in a spatio-temporal location. Each tensor is coupled to the measured data specific to a brain region via low-rank observation models that can be decomposed into the spatial, temporal and feature receptive fields of a localized neuronal population. Both these observation models and the convolutional weights defining the information processing within regions and effective connectivity between regions are learned end-to-end by predicting the neural signal during sensory stimulation. We trained a NIF model on the activity of early visual areas using a large-scale fMRI dataset. We show that we can recover plausible visual representations and population receptive fields that are consistent with the existing literature. Trained NIF models are accessible for \textit{in silico} analyses.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-08-22},
	journal = {bioRxiv},
	author = {Seeliger, Katja and Ambrogioni, Luca and Güçlütürk, Yağmur and Güçlü, Umut and Gerven, Marcel A. J. van},
	month = may,
	year = {2019},
	pages = {553255},
	file = {Seeliger et al_2019_Neural System Identification with Neural Information Flow.pdf:/Users/tito/Zotero/storage/3TB5E5C4/Seeliger et al_2019_Neural System Identification with Neural Information Flow.pdf:application/pdf},
}

@article{douglas_canonical_1989,
	title = {A {Canonical} {Microcircuit} for {Neocortex}},
	volume = {1},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1989.1.4.480},
	doi = {10.1162/neco.1989.1.4.480},
	abstract = {We have used microanatomy derived from single neurons, and in vivo intracellular recordings to develop a simplified circuit of the visual cortex. The circuit explains the intracellular responses to pulse stimulation in terms of the interactions between three basic populations of neurons, and reveals the following features of cortical processing that are important to computational theories of neocortex. First, inhibition and excitation are not separable events. Activation of the cortex inevitably sets in motion a sequence of excitation and inhibition in every neuron. Second, the thalamic input does not provide the major excitation arriving at any neuron. Instead the intracortical excitatory connections provide most of the excitation. Third, the time evolution of excitation and inhibition is far longer than the synaptic delays of the circuits involved. This means that cortical processing cannot rely on precise timing between individual synaptic inputs.},
	number = {4},
	urldate = {2019-08-23},
	journal = {Neural Computation},
	author = {Douglas, Rodney J. and Martin, Kevan A.C. and Whitteridge, David},
	month = dec,
	year = {1989},
	pages = {480--488},
	file = {Douglas et al_1989_A Canonical Microcircuit for Neocortex.pdf:/Users/tito/Zotero/storage/7JNBMABM/Douglas et al_1989_A Canonical Microcircuit for Neocortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4NBCKMWR/neco.1989.1.4.html:text/html},
}

@article{harris_neocortical_2015,
	title = {The neocortical circuit: themes and variations},
	volume = {18},
	copyright = {2015 Nature Publishing Group},
	issn = {1546-1726},
	shorttitle = {The neocortical circuit},
	url = {https://www.nature.com/articles/nn.3917},
	doi = {10.1038/nn.3917},
	abstract = {Similarities in neocortical circuit organization across areas and species suggest a common strategy to process diverse types of information, including sensation from diverse modalities, motor control and higher cognitive processes. Cortical neurons belong to a small number of main classes. The properties of these classes, including their local and long-range connectivity, developmental history, gene expression, intrinsic physiology and in vivo activity patterns, are remarkably similar across areas. Each class contains subclasses; for a rapidly growing number of these, conserved patterns of input and output connections are also becoming evident. The ensemble of circuit connections constitutes a basic circuit pattern that appears to be repeated across neocortical areas, with area- and species-specific modifications. Such 'serially homologous' organization may adapt individual neocortical regions to the type of information each must process.},
	language = {en},
	number = {2},
	urldate = {2019-08-23},
	journal = {Nature Neuroscience},
	author = {Harris, Kenneth D. and Shepherd, Gordon M. G.},
	month = feb,
	year = {2015},
	pages = {170--181},
	file = {Harris_Shepherd_2015_The neocortical circuit.pdf:/Users/tito/Zotero/storage/LANEI54N/Harris_Shepherd_2015_The neocortical circuit.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BSMNI423/nn.html:text/html},
}

@article{deco_awakening:_2019,
	title = {Awakening: {Predicting} external stimulation to force transitions between different brain states},
	url = {http://www.pnas.org/content/early/2019/08/16/1905534116.abstract},
	doi = {10.1073/pnas.1905534116},
	abstract = {We describe a quantitative and robust definition of a brain state as an ensemble of “metastable substates,” each with a probabilistic stability and occurrence frequency. Fitting this to a generative whole-brain model provides an innovative avenue for predicting where simulated brain stimulation can force transitions between different brain states. We provide proof-of-concept by systematically applying this model framework to neuroimaging data of the human sleep cycle and show where to stimulate to awaken the human sleeping brain and vice versa. These results suggest an avenue for using causal whole-brain models to discover in silico where to force a transition between brain states, which may potentially support recovery in disease.A fundamental problem in systems neuroscience is how to force a transition from one brain state to another by external driven stimulation in, for example, wakefulness, sleep, coma, or neuropsychiatric diseases. This requires a quantitative and robust definition of a brain state, which has so far proven elusive. Here, we provide such a definition, which, together with whole-brain modeling, permits the systematic study in silico of how simulated brain stimulation can force transitions between different brain states in humans. Specifically, we use a unique neuroimaging dataset of human sleep to systematically investigate where to stimulate the brain to force an awakening of the human sleeping brain and vice versa. We show where this is possible using a definition of a brain state as an ensemble of “metastable substates,” each with a probabilistic stability and occurrence frequency fitted by a generative whole-brain model, fine-tuned on the basis of the effective connectivity. Given the biophysical limitations of direct electrical stimulation (DES) of microcircuits, this opens exciting possibilities for discovering stimulation targets and selecting connectivity patterns that can ensure propagation of DES-induced neural excitation, potentially making it possible to create awakenings from complex cases of brain injury.},
	journal = {Proc Natl Acad Sci USA},
	author = {Deco, Gustavo and Cruzat, Josephine and Cabral, Joana and Tagliazucchi, Enzo and Laufs, Helmut and Logothetis, Nikos K. and Kringelbach, Morten L.},
	month = aug,
	year = {2019},
	pages = {201905534},
	file = {Deco et al_2019_Awakening.pdf:/Users/tito/Zotero/storage/845J5KAQ/Deco et al_2019_Awakening.pdf:application/pdf},
}

@article{ahmadian_what_2019,
	title = {What is the dynamical regime of cerebral cortex?},
	url = {http://arxiv.org/abs/1908.10101},
	abstract = {Many studies have shown that the excitation and inhibition received by cortical neurons remain roughly balanced across many conditions. A key question for understanding the dynamical regime of cortex is the nature of this balancing. Theorists have shown that network dynamics can yield systematic cancellation of most of a neuron's excitatory input by inhibition. We review a wide range of evidence pointing to this cancellation occurring in a regime in which the balance is loose, meaning that the net input remaining after cancellation of excitation and inhibition is comparable in size to the factors that cancel, rather than tight, meaning that the net input is very small relative to the cancelling factors. This choice of regime has important implications for cortical functional responses, as we describe: loose balance, but not tight balance, can yield many nonlinear population behaviors seen in sensory cortical neurons, allow the presence of correlated variability, and yield decrease of that variability with increasing external stimulus drive as observed across multiple cortical areas.},
	urldate = {2019-08-29},
	journal = {arXiv:1908.10101 [q-bio]},
	author = {Ahmadian, Yashar and Miller, Kenneth D.},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.10101},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 21 pages, 2 figures},
	file = {Ahmadian_Miller_2019_What is the dynamical regime of cerebral cortex.pdf:/Users/tito/Zotero/storage/VSRLYNZY/Ahmadian_Miller_2019_What is the dynamical regime of cerebral cortex.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/HAY9PNQ6/1908.html:text/html},
}

@article{carandini_normalization_2012,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn3136},
	doi = {10.1038/nrn3136},
	abstract = {There is increasing evidence that the brain relies on a set of canonical neural computations, repeating them across brain regions and modalities to apply similar operations to different problems. A promising candidate for such a computation is normalization, in which the responses of neurons are divided by a common factor that typically includes the summed activity of a pool of neurons. Normalization was developed to explain responses in the primary visual cortex and is now thought to operate throughout the visual system, and in many other sensory modalities and brain regions. Normalization may underlie operations such as the representation of odours, the modulatory effects of visual attention, the encoding of value and the integration of multisensory information. Its presence in such a diversity of neural systems in multiple species, from invertebrates to mammals, suggests that it serves as a canonical neural computation.},
	language = {en},
	number = {1},
	urldate = {2019-08-29},
	journal = {Nature Reviews Neuroscience},
	author = {Carandini, Matteo and Heeger, David J.},
	month = jan,
	year = {2012},
	pages = {51--62},
	file = {Carandini and Heeger - 2012 - Normalization as a canonical neural computation.pdf:/Users/tito/Zotero/storage/JXHXMRT7/Carandini and Heeger - 2012 - Normalization as a canonical neural computation.pdf:application/pdf},
}

@article{carandini_normalization_2011-1,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	url = {https://doi.org/10.1038/nrn3136},
	journal = {Nature Reviews Neuroscience},
	author = {Carandini, Matteo and Heeger, David J.},
	month = nov,
	year = {2011},
	pages = {51},
	file = {nrn3136.pdf:/Users/tito/Downloads/nrn3136.pdf:application/pdf},
}

@article{petersen_brain_2015-1,
	title = {Brain {Networks} and {Cognitive} {Architectures}},
	volume = {88},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627315008168},
	doi = {10.1016/j.neuron.2015.09.027},
	abstract = {Most accounts of human cognitive architectures have focused on computational accounts of cognition while making little contact with the study of anatomical structures and physiological processes. A renewed convergence between neurobiology and cognition is well under way. A promising area arises from the overlap between systems/cognitive neuroscience on the one side and the discipline of network science on the other. Neuroscience increasingly adopts network tools and concepts to describe the operation of collections of brain regions. Beyond just providing illustrative metaphors, network science offers a theoretical framework for approaching brain structure and function as a multi-scale system composed of networks of neurons, circuits, nuclei, cortical areas, and systems of areas. This paper views large-scale networks at the level of areas and systems, mostly on the basis of data from human neuroimaging, and how this view of network structure and function has begun to illuminate our understanding of the biological basis of cognitive architectures.},
	number = {1},
	urldate = {2019-08-29},
	journal = {Neuron},
	author = {Petersen, Steven E. and Sporns, Olaf},
	month = oct,
	year = {2015},
	pages = {207--219},
	file = {Petersen_Sporns_2015_Brain Networks and Cognitive Architectures.pdf:/Users/tito/Zotero/storage/YMQNC2YU/Petersen_Sporns_2015_Brain Networks and Cognitive Architectures.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3ZA98H3B/S0896627315008168.html:text/html},
}

@article{rosenblatt_perceptron:_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain.},
	volume = {65},
	issn = {1939-1471, 0033-295X},
	shorttitle = {The perceptron},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
	doi = {10.1037/h0042519},
	language = {en},
	number = {6},
	urldate = {2019-08-29},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	pages = {386--408},
	file = {Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf:/Users/tito/Zotero/storage/NIHPB73Q/Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf:application/pdf},
}

@article{rosenblatt_perceptron:_1958-1,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain.},
	volume = {65},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/h0042519},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	keywords = {*Brain, *Cognition, *Memory, Nervous System},
	pages = {386--408},
	file = {Rosenblatt1958.pdf:/Users/tito/Downloads/Rosenblatt1958.pdf:application/pdf},
}

@article{gardner_artificial_1998,
	title = {Artificial neural networks (the multilayer perceptron)—a review of applications in the atmospheric sciences},
	volume = {32},
	issn = {1352-2310},
	url = {http://www.sciencedirect.com/science/article/pii/S1352231097004470},
	doi = {10.1016/S1352-2310(97)00447-0},
	abstract = {Artificial neural networks are appearing as useful alternatives to traditional statistical modelling techniques in many scientific disciplines. This paper presents a general introduction and discussion of recent applications of the multilayer perceptron, one type of artificial neural network, in the atmospheric sciences.},
	number = {14},
	urldate = {2019-08-29},
	journal = {Atmospheric Environment},
	author = {Gardner, M. W and Dorling, S. R},
	month = aug,
	year = {1998},
	keywords = {artificial intelligence, neural network, backpropagation, Statistical modelling},
	pages = {2627--2636},
	file = {Gardner_Dorling_1998_Artificial neural networks (the multilayer perceptron)—a review of applications.pdf:/Users/tito/Zotero/storage/LVUTIM8U/Gardner_Dorling_1998_Artificial neural networks (the multilayer perceptron)—a review of applications.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/VRVRNBP2/S1352231097004470.html:text/html},
}

@article{churchland_neural_2006,
	title = {Neural {Variability} in {Premotor} {Cortex} {Provides} a {Signature} of {Motor} {Preparation}},
	volume = {26},
	copyright = {Copyright © 2006 Society for Neuroscience 0270-6474/06/263697-16\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/26/14/3697},
	doi = {10.1523/JNEUROSCI.3762-05.2006},
	abstract = {We present experiments and analyses designed to test the idea that firing rates in premotor cortex become optimized during motor preparation, approaching their ideal values over time. We measured the across-trial variability of neural responses in dorsal premotor cortex of three monkeys performing a delayed-reach task. Such variability was initially high, but declined after target onset, and was maintained at a rough plateau during the delay. An additional decline was observed after the go cue. Between target onset and movement onset, variability declined by an average of 34\%. This decline in variability was observed even when mean firing rate changed little. We hypothesize that this effect is related to the progress of motor preparation. In this interpretation, firing rates are initially variable across trials but are brought, over time, to their “appropriate” values, becoming consistent in the process. Consistent with this hypothesis, reaction times were longer if the go cue was presented shortly after target onset, when variability was still high, and were shorter if the go cue was presented well after target onset, when variability had fallen to its plateau. A similar effect was observed for the natural variability in reaction time: longer (shorter) reaction times tended to occur on trials in which firing rates were more (less) variable. These results reveal a remarkable degree of temporal structure in the variability of cortical neurons. The relationship with reaction time argues that the changes in variability approximately track the progress of motor preparation.},
	language = {en},
	number = {14},
	urldate = {2019-08-30},
	journal = {J. Neurosci.},
	author = {Churchland, Mark M. and Yu, Byron M. and Ryu, Stephen I. and Santhanam, Gopal and Shenoy, Krishna V.},
	month = apr,
	year = {2006},
	pmid = {16597724},
	keywords = {cortex, variability, reaction time, motor control, motor planning, motor preparation, premotor},
	pages = {3697--3712},
	file = {Churchland et al_2006_Neural Variability in Premotor Cortex Provides a Signature of Motor Preparation.pdf:/Users/tito/Zotero/storage/YTIR64CM/Churchland et al_2006_Neural Variability in Premotor Cortex Provides a Signature of Motor Preparation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HRRN3N8U/3697.html:text/html},
}

@article{koppe_identifying_2019,
	title = {Identifying nonlinear dynamical systems via generative recurrent neural networks with applications to {fMRI}},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007263},
	doi = {10.1371/journal.pcbi.1007263},
	abstract = {A major tenet in theoretical neuroscience is that cognitive and behavioral processes are ultimately implemented in terms of the neural system dynamics. Accordingly, a major aim for the analysis of neurophysiological measurements should lie in the identification of the computational dynamics underlying task processing. Here we advance a state space model (SSM) based on generative piecewise-linear recurrent neural networks (PLRNN) to assess dynamics from neuroimaging data. In contrast to many other nonlinear time series models which have been proposed for reconstructing latent dynamics, our model is easily interpretable in neural terms, amenable to systematic dynamical systems analysis of the resulting set of equations, and can straightforwardly be transformed into an equivalent continuous-time dynamical system. The major contributions of this paper are the introduction of a new observation model suitable for functional magnetic resonance imaging (fMRI) coupled to the latent PLRNN, an efficient stepwise training procedure that forces the latent model to capture the ‘true’ underlying dynamics rather than just fitting (or predicting) the observations, and of an empirical measure based on the Kullback-Leibler divergence to evaluate from empirical time series how well this goal of approximating the underlying dynamics has been achieved. We validate and illustrate the power of our approach on simulated ‘ground-truth’ dynamical systems as well as on experimental fMRI time series, and demonstrate that the learnt dynamics harbors task-related nonlinear structure that a linear dynamical model fails to capture. Given that fMRI is one of the most common techniques for measuring brain activity non-invasively in human subjects, this approach may provide a novel step toward analyzing aberrant (nonlinear) dynamics for clinical assessment or neuroscientific research.},
	language = {en},
	number = {8},
	urldate = {2019-09-05},
	journal = {PLOS Computational Biology},
	author = {Koppe, Georgia and Toutounji, Hazem and Kirsch, Peter and Lis, Stefanie and Durstewitz, Daniel},
	month = aug,
	year = {2019},
	keywords = {Dynamical systems, Functional magnetic resonance imaging, Cognition, Algorithms, Covariance, Nonlinear dynamics, Nonlinear systems, System instability},
	pages = {e1007263},
	file = {Koppe et al_2019_Identifying nonlinear dynamical systems via generative recurrent neural.pdf:/Users/tito/Zotero/storage/96LS8UIH/Koppe et al_2019_Identifying nonlinear dynamical systems via generative recurrent neural.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/239B65DL/article.html:text/html},
}

@article{aron_climate_2019,
	title = {The {Climate} {Crisis} {Needs} {Attention} from {Cognitive} {Scientists}},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661319302025},
	doi = {10.1016/j.tics.2019.08.001},
	abstract = {To prevent the devastating consequences of anthropogenic global heating, immediate collective action is needed to reduce fossil fuel emissions. Cognitive scientists are in a special position to facilitate collective action by researching the factors underlying belief and action, and by teaching students how to think about the biggest problem of their lives.},
	urldate = {2019-09-05},
	journal = {Trends in Cognitive Sciences},
	author = {Aron, Adam R.},
	month = sep,
	year = {2019},
	keywords = {belief, collective action, uncertainty},
	file = {Aron_2019_The Climate Crisis Needs Attention from Cognitive Scientists.pdf:/Users/tito/Zotero/storage/WBR4HRSW/Aron_2019_The Climate Crisis Needs Attention from Cognitive Scientists.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/AZHGJWMU/S1364661319302025.html:text/html},
}

@article{raut_organization_nodate,
	title = {Organization of {Propagated} {Intrinsic} {Brain} {Activity} in {Individual} {Humans}},
	url = {https://academic.oup.com/cercor/advance-article/doi/10.1093/cercor/bhz198/5559315},
	doi = {10.1093/cercor/bhz198},
	abstract = {Abstract.  Spontaneous infra-slow (\&lt;0.1 Hz) fluctuations in functional magnetic resonance imaging (fMRI) signals are temporally correlated within large-scale},
	language = {en},
	urldate = {2019-09-10},
	journal = {Cereb Cortex},
	author = {Raut, Ryan V. and Mitra, Anish and Marek, Scott and Ortega, Mario and Snyder, Abraham Z. and Tanenbaum, Aaron and Laumann, Timothy O. and Dosenbach, Nico U. F. and Raichle, Marcus E.},
	file = {Raut et al_Organization of Propagated Intrinsic Brain Activity in Individual Humans.pdf:/Users/tito/Zotero/storage/5DMKXQYQ/Raut et al_Organization of Propagated Intrinsic Brain Activity in Individual Humans.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3THQP2HQ/5559315.html:text/html},
}

@article{tommasin_scale-invariant_2018-1,
	title = {Scale-invariant rearrangement of resting state networks in the human brain under sustained stimulation},
	volume = {179},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918305135},
	doi = {10.1016/j.neuroimage.2018.06.006},
	abstract = {Brain activity at rest is characterized by widely distributed and spatially specific patterns of synchronized low-frequency blood-oxygenation level-dependent (BOLD) fluctuations, which correspond to physiologically relevant brain networks. This network behaviour is known to persist also during task execution, yet the details underlying task-associated modulations of within- and between-network connectivity are largely unknown. In this study we exploited a multi-parametric and multi-scale approach to investigate how low-frequency fluctuations adapt to a sustained n-back working memory task. We found that the transition from the resting state to the task state involves a behaviourally relevant and scale-invariant modulation of synchronization patterns within both task-positive and default mode networks. Specifically, decreases of connectivity within networks are accompanied by increases of connectivity between networks. In spite of large and widespread changes of connectivity strength, the overall topology of brain networks is remarkably preserved. We show that these findings are strongly influenced by connectivity at rest, suggesting that the absolute change of connectivity (i.e., disregarding the baseline) may not be the most suitable metric to study dynamic modulations of functional connectivity. Our results indicate that a task can evoke scale-invariant, distributed changes of BOLD fluctuations, further confirming that low frequency BOLD oscillations show a specialized response and are tightly bound to task-evoked activation.},
	urldate = {2019-09-15},
	journal = {NeuroImage},
	author = {Tommasin, Silvia and Mascali, Daniele and Moraschi, Marta and Gili, Tommaso and Hassan, Ibrahim Eid and Fratini, Michela and DiNuzzo, Mauro and Wise, Richard G. and Mangia, Silvia and Macaluso, Emiliano and Giove, Federico},
	month = oct,
	year = {2018},
	keywords = {Functional connectivity, Connectivity dynamics, Steady-state networks, Working memory},
	pages = {570--581},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/3TXJH5NN/S1053811918305135.html:text/html;Tommasin et al_2018_Scale-invariant rearrangement of resting state networks in the human brain.pdf:/Users/tito/Zotero/storage/R4YU2JLV/Tommasin et al_2018_Scale-invariant rearrangement of resting state networks in the human brain.pdf:application/pdf},
}

@article{musall_single-trial_2019,
	title = {Single-trial neural dynamics are dominated by richly varied movements},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/308288v3},
	doi = {10.1101/308288},
	abstract = {{\textless}p{\textgreater}When experts are immersed in a task, do their brains prioritize task-related activity? Most efforts to understand neural activity during well-learned tasks focus on cognitive computations and specific task-related movements. We wondered whether task-performing animals explore a broader movement landscape, and how this impacts neural activity. We characterized movements using video and other sensors and measured neural activity using widefield and two-photon imaging. Cortex-wide activity was dominated by movements, especially uninstructed movements, reflecting unknown priorities of the animal. Some uninstructed movements were aligned to trial events. Accounting for them revealed that neurons with similar trial-averaged activity often reflected utterly different combinations of cognitive and movement variables. Other movements occurred idiosyncratically, accounting for trial-by-trial fluctuations that are often considered “noise”. This held true for extracellular Neuropixels recordings in cortical and subcortical areas. Our observations argue that animals execute expert decisions while performing richly varied, uninstructed movements that profoundly shape neural activity.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-09-17},
	journal = {bioRxiv},
	author = {Musall, Simon and Kaufman, Matthew T. and Juavinett, Ashley L. and Gluf, Steven and Churchland, Anne K.},
	month = apr,
	year = {2019},
	pages = {308288},
	file = {Musall et al_2019_Single-trial neural dynamics are dominated by richly varied movements.pdf:/Users/tito/Zotero/storage/7WXTH3IU/Musall et al_2019_Single-trial neural dynamics are dominated by richly varied movements.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/KDXVMD44/308288v3.html:text/html},
}

@book{ashby_design_2013,
	title = {Design for a {Brain}: {The} origin of adaptive behaviour},
	isbn = {978-94-015-1320-3},
	shorttitle = {Design for a {Brain}},
	abstract = {THE book is not a treatise on aIl cerebral mechanisms but a pro poscd solution of a specific problem: the origin of the nervous system's unique ability to produce adaptive behaviour. The work has as basis the fact that the nervous system behaves adap tively and the hypothesis that it is essentiaIly mechanistic; it proceeds on the assumption that these two data are not irrecon cilable. It attempts to deduce from the observed facts what sort of a mechanism it must be that behaves so differently from any machinc made so far. Other proposed solutions have usuaIly left open the question whether so me different theory might not fit the facts equaIly weIl: I have attempted to deduce what is necessary, what properties the nervous system must have if it is to behave at once mechanisticaIly and adaptively. For the deduction to be rigorous, an adequately developed logic of mechanism is essential. Until recently, discussions of mechan ism were carried on almost entirely in terms of so me particular embodiment-the mechanical, the electronic, the neuronie, and so on. Those days are past. There now exists a weIl-developed logic of pure mechanism, rigorous as geometry, and likely to play the same fundamental part, in our understanding of the complex systems of biology, that geometry does in astronomy. Only by the dcvelopment of this basic logic has thc work in this book been made possible.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Ashby, W.},
	month = mar,
	year = {2013},
	note = {Google-Books-ID: Dc4hBQAAQBAJ},
	keywords = {Juvenile Nonfiction / Science \& Nature / General, Philosophy / General, Science / General},
}

@book{ross_ashby_design_1952,
	title = {Design for a {Brain}},
	publisher = {Chapman \& Hall, London},
	author = {Ross Ashby, William},
	year = {1952},
}

@book{hayek_sensory_1952,
	title = {The sensory order: {An} inquiry into the foundations of theoretical psychology},
	shorttitle = {The sensory order},
	publisher = {University of Chicago Press},
	author = {Hayek, Friedrich August},
	year = {1952},
	file = {Snapshot:/Users/tito/Zotero/storage/3Z5XH8QA/books.html:text/html},
}

@book{hebb_organization_2005-1,
	title = {The organization of behavior: {A} neuropsychological theory},
	shorttitle = {The organization of behavior},
	publisher = {Psychology Press},
	author = {Hebb, Donald Olding},
	year = {2005},
	file = {Snapshot:/Users/tito/Zotero/storage/UA7QJZNY/books.html:text/html},
}

@article{uttley_conditional_2016,
	title = {Conditional probability machines and conditioned reflexes},
	number = {34},
	journal = {Automata Studies," CE Shannon and J. McCarthy, eds., Princeton University Press. Princeton, NJ, Annals of Mathematics Study},
	author = {Uttley, Albert M.},
	year = {2016},
	pages = {253--275},
	file = {Snapshot:/Users/tito/Zotero/storage/CY2LPHMI/books.html:text/html},
}

@techreport{rumelhart_learning_1985,
	title = {Learning internal representations by error propagation},
	institution = {California Univ San Diego La Jolla Inst for Cognitive Science},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	year = {1985},
	file = {Rumelhart et al_1985_Learning internal representations by error propagation.pdf:/Users/tito/Zotero/storage/S2WYTRDG/Rumelhart et al_1985_Learning internal representations by error propagation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/U36PA9VL/ADA164453.html:text/html},
}

@inproceedings{lecun_theoretical_1988,
	title = {A theoretical framework for back-propagation},
	volume = {1},
	booktitle = {Proceedings of the 1988 connectionist models summer school},
	publisher = {CMU, Pittsburgh, Pa: Morgan Kaufmann},
	author = {LeCun, Yann and Touresky, D. and Hinton, G. and Sejnowski, T.},
	year = {1988},
	pages = {21--28},
	file = {LeCun et al_1988_A theoretical framework for back-propagation.pdf:/Users/tito/Zotero/storage/L62XD5YV/LeCun et al_1988_A theoretical framework for back-propagation.pdf:application/pdf},
}

@article{werbos_beyond_1974,
	title = {Beyond {Regression}:" {New} {Tools} for {Prediction} and {Analysis} in the {Behavioral} {Sciences}},
	shorttitle = {Beyond {Regression}},
	journal = {Ph. D. dissertation, Harvard University},
	author = {Werbos, Paul},
	year = {1974},
	file = {Snapshot:/Users/tito/Zotero/storage/YBYUJ7E8/10004070196.html:text/html},
}

@article{anderson_spreading_1983,
	title = {A spreading activation theory of memory},
	volume = {22},
	issn = {0022-5371},
	url = {http://www.sciencedirect.com/science/article/pii/S0022537183902013},
	doi = {10.1016/S0022-5371(83)90201-3},
	abstract = {The ACT theory of factual memory is presented. According to this theory, information is encoded in an all-or-none manner into cognitive units and the strength of these units increases with practice and decays with delay. The essential process to memory performance is the retrieval operation. It is proposed that the cognitive units form an interconnected network and that retrieval is performed by spreading activation throughout the network. Level of activation in the network determines rate and probability of recall. With these assumptions in place, the ACT theory is shown to predict interference results in memory, judgements of associative relatedness, impact of extensive practice on memory, the differences between recognition and recall, effects of elaborative processing, and effects of reconstructive recall.},
	number = {3},
	urldate = {2019-09-18},
	journal = {Journal of Verbal Learning and Verbal Behavior},
	author = {Anderson, John R.},
	month = jun,
	year = {1983},
	pages = {261--295},
	file = {Anderson_1983_A spreading activation theory of memory.pdf:/Users/tito/Zotero/storage/8P86AYLV/Anderson_1983_A spreading activation theory of memory.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/JNJMATBD/S0022537183902013.html:text/html},
}

@article{collins_spreading-activation_1975,
	title = {A spreading-activation theory of semantic processing.},
	volume = {82},
	number = {6},
	journal = {Psychological review},
	author = {Collins, Allan M. and Loftus, Elizabeth F.},
	year = {1975},
	pages = {407},
	file = {Collins_Loftus_1975_A spreading-activation theory of semantic processing.pdf:/Users/tito/Zotero/storage/I4KAAJ76/Collins_Loftus_1975_A spreading-activation theory of semantic processing.pdf:application/pdf},
}

@misc{pdf_weight_nodate,
	title = {Weight {Agnostic} {Neural} {Networks}},
	url = {https://weightagnostic.github.io/},
	abstract = {Networks that can already (sort of) perform tasks with random weights.},
	language = {en},
	urldate = {2019-09-19},
	journal = {Weight Agnostic Neural Networks},
	author = {PDF, Adam Gaier Google Brain David Ha Google Brain June 12 2019 Download},
	file = {Snapshot:/Users/tito/Zotero/storage/WME6R8EQ/weightagnostic.github.io.html:text/html},
}

@article{gaier_weight_2019,
	title = {Weight {Agnostic} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1906.04358},
	abstract = {Not all neural network architectures are created equal, some perform much better than others for certain tasks. But how important are the weight parameters of a neural network compared to its architecture? In this work, we question to what extent neural network architectures alone, without learning any weight parameters, can encode solutions for a given task. We propose a search method for neural network architectures that can already perform a task without any explicit weight training. To evaluate these networks, we populate the connections with a single shared weight parameter sampled from a uniform random distribution, and measure the expected performance. We demonstrate that our method can find minimal neural network architectures that can perform several reinforcement learning tasks without weight training. On a supervised learning domain, we find network architectures that achieve much higher than chance accuracy on MNIST using random weights. Interactive version of this paper at https://weightagnostic.github.io/},
	urldate = {2019-09-19},
	journal = {arXiv:1906.04358 [cs, stat]},
	author = {Gaier, Adam and Ha, David},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.04358},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: To appear at NeurIPS 2019, selected for a spotlight presentation},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/6TDYVSQY/1906.html:text/html;Gaier_Ha_2019_Weight Agnostic Neural Networks.pdf:/Users/tito/Zotero/storage/AMLMSIGM/Gaier_Ha_2019_Weight Agnostic Neural Networks.pdf:application/pdf},
}

@article{sinz_engineering_2019,
	title = {Engineering a {Less} {Artificial} {Intelligence}},
	volume = {103},
	issn = {08966273},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627319307408},
	doi = {10.1016/j.neuron.2019.08.034},
	language = {en},
	number = {6},
	urldate = {2019-09-26},
	journal = {Neuron},
	author = {Sinz, Fabian H. and Pitkow, Xaq and Reimer, Jacob and Bethge, Matthias and Tolias, Andreas S.},
	month = sep,
	year = {2019},
	pages = {967--979},
	file = {Sinz et al. - 2019 - Engineering a Less Artificial Intelligence.pdf:/Users/tito/Zotero/storage/GDN6HNYG/Sinz et al. - 2019 - Engineering a Less Artificial Intelligence.pdf:application/pdf},
}

@article{williamson_bridging_2019,
	series = {Machine {Learning}, {Big} {Data}, and {Neuroscience}},
	title = {Bridging large-scale neuronal recordings and large-scale network models using dimensionality reduction},
	volume = {55},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S095943881830134X},
	doi = {10.1016/j.conb.2018.12.009},
	abstract = {A long-standing goal in neuroscience has been to bring together neuronal recordings and neural network modeling to understand brain function. Neuronal recordings can inform the development of network models, and network models can in turn provide predictions for subsequent experiments. Traditionally, neuronal recordings and network models have been related using single-neuron and pairwise spike train statistics. We review here recent studies that have begun to relate neuronal recordings and network models based on the multi-dimensional structure of neuronal population activity, as identified using dimensionality reduction. This approach has been used to study working memory, decision making, motor control, and more. Dimensionality reduction has provided common ground for incisive comparisons and tight interplay between neuronal recordings and network models.},
	urldate = {2019-09-26},
	journal = {Current Opinion in Neurobiology},
	author = {Williamson, Ryan C. and Doiron, Brent and Smith, Matthew A. and Yu, Byron M.},
	month = apr,
	year = {2019},
	pages = {40--47},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/EN2F76S4/S095943881830134X.html:text/html;Williamson et al_2019_Bridging large-scale neuronal recordings and large-scale network models using.pdf:/Users/tito/Zotero/storage/TKC6XUHK/Williamson et al_2019_Bridging large-scale neuronal recordings and large-scale network models using.pdf:application/pdf},
}

@article{pinto_task-dependent_2019,
	title = {Task-{Dependent} {Changes} in the {Large}-{Scale} {Dynamics} and {Necessity} of {Cortical} {Regions}},
	volume = {0},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(19)30731-7},
	doi = {10.1016/j.neuron.2019.08.025},
	language = {English},
	number = {0},
	urldate = {2019-09-26},
	journal = {Neuron},
	author = {Pinto, Lucas and Rajan, Kanaka and DePasquale, Brian and Thiberge, Stephan Y. and Tank, David W. and Brody, Carlos D.},
	month = sep,
	year = {2019},
	keywords = {decision making, cortex, working memory, optogenetics, evidence accumulation, mouse behavior, RNN, virtual reality, widefield Ca2+ imaging},
	file = {Pinto et al_2019_Task-Dependent Changes in the Large-Scale Dynamics and Necessity of Cortical.pdf:/Users/tito/Zotero/storage/QM7VTX29/Pinto et al_2019_Task-Dependent Changes in the Large-Scale Dynamics and Necessity of Cortical.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/H4WDUVPC/S0896-6273(19)30731-7.html:text/html},
}

@article{kar_evidence_2019,
	title = {Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior},
	volume = {22},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0392-5},
	doi = {10.1038/s41593-019-0392-5},
	abstract = {Using model- and primate behavior-driven image selection with large-scale electrophysiology in monkeys performing core recognition tasks, Kar et al. provide evidence that automatically engaged recurrent circuits are critical for rapid object identification.},
	language = {en},
	number = {6},
	urldate = {2019-09-30},
	journal = {Nat Neurosci},
	author = {Kar, Kohitij and Kubilius, Jonas and Schmidt, Kailyn and Issa, Elias B. and DiCarlo, James J.},
	month = jun,
	year = {2019},
	pages = {974--983},
	file = {Kar et al_2019_Evidence that recurrent circuits are critical to the ventral stream’s execution.pdf:/Users/tito/Zotero/storage/8P3SVUBX/Kar et al_2019_Evidence that recurrent circuits are critical to the ventral stream’s execution.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/I83KY7UV/s41593-019-0392-5.html:text/html},
}

@article{salehi_individualized_2019,
	title = {Individualized functional networks reconfigure with cognitive state},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919308249},
	doi = {10.1016/j.neuroimage.2019.116233},
	abstract = {There is extensive evidence that functional organization of the human brain varies dynamically as the brain switches between task demands, or cognitive states. This functional organization also varies across subjects, even when engaged in similar tasks. To date, the functional network organization of the brain has been considered static. In this work we use fMRI data obtained across multiple cognitive states (task-evoked and rest conditions) and across multiple subjects, to measure state- and subject-specific functional network parcellation (the assignment of nodes to networks). Our parcellation approach provides a measure of how node-to-network assignment (NNA) changes across states and across subjects. We demonstrate that the brain's functional networks are not spatially fixed, but that many nodes change their network membership as a function of cognitive state. Such reconfigurations are highly robust and reliable to the extent that they can be used to predict cognitive state with up to 97\% accuracy. Our findings suggest that if functional networks are to be defined via functional clustering of nodes, then it is essential to consider that such definitions may be fluid and cognitive-state dependent.},
	urldate = {2019-10-01},
	journal = {NeuroImage},
	author = {Salehi, Mehraveh and Karbasi, Amin and Barron, Daniel S. and Scheinost, Dustin and Constable, R. Todd},
	month = sep,
	year = {2019},
	keywords = {fMRI, Functional connectivity, Functional parcellation, Individual variability, Task variability},
	pages = {116233},
	file = {Salehi et al_2019_Individualized functional networks reconfigure with cognitive state.pdf:/Users/tito/Zotero/storage/PFGWDKGS/Salehi et al_2019_Individualized functional networks reconfigure with cognitive state.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3UY3IDY3/S1053811919308249.html:text/html},
}

@article{oreilly_biologically_1996,
	title = {Biologically plausible error-driven learning using local activation differences: {The} generalized recirculation algorithm},
	volume = {8},
	shorttitle = {Biologically plausible error-driven learning using local activation differences},
	number = {5},
	journal = {Neural computation},
	author = {O'Reilly, Randall C.},
	year = {1996},
	pages = {895--938},
	file = {O'Reilly_1996_Biologically plausible error-driven learning using local activation differences.pdf:/Users/tito/Zotero/storage/MH5JQH2N/O'Reilly_1996_Biologically plausible error-driven learning using local activation differences.pdf:application/pdf},
}

@article{kay_compressive_2013,
	title = {Compressive spatial summation in human visual cortex},
	volume = {110},
	issn = {1522-1598},
	doi = {10.1152/jn.00105.2013},
	abstract = {Neurons within a small (a few cubic millimeters) region of visual cortex respond to stimuli within a restricted region of the visual field. Previous studies have characterized the population response of such neurons using a model that sums contrast linearly across the visual field. In this study, we tested linear spatial summation of population responses using blood oxygenation level-dependent (BOLD) functional MRI. We measured BOLD responses to a systematic set of contrast patterns and discovered systematic deviation from linearity: the data are more accurately explained by a model in which a compressive static nonlinearity is applied after linear spatial summation. We found that the nonlinearity is present in early visual areas (e.g., V1, V2) and grows more pronounced in relatively anterior extrastriate areas (e.g., LO-2, VO-2). We then analyzed the effect of compressive spatial summation in terms of changes in the position and size of a viewed object. Compressive spatial summation is consistent with tolerance to changes in position and size, an important characteristic of object representation.},
	language = {eng},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Kay, Kendrick N. and Winawer, Jonathan and Mezer, Aviv and Wandell, Brian A.},
	month = jul,
	year = {2013},
	pmid = {23615546},
	pmcid = {PMC3727075},
	keywords = {fMRI, Adult, Humans, Magnetic Resonance Imaging, Male, Photic Stimulation, Visual Cortex, Neurons, Models, Neurological, human visual cortex, population receptive field, spatial nonlinearity, spatial summation},
	pages = {481--494},
}

@article{reynolds_normalization_2009,
	title = {The normalization model of attention},
	volume = {61},
	issn = {1097-4199},
	doi = {10.1016/j.neuron.2009.01.002},
	abstract = {Attention has been found to have a wide variety of effects on the responses of neurons in visual cortex. We describe a model of attention that exhibits each of these different forms of attentional modulation, depending on the stimulus conditions and the spread (or selectivity) of the attention field in the model. The model helps reconcile proposals that have been taken to represent alternative theories of attention. We argue that the variety and complexity of the results reported in the literature emerge from the variety of empirical protocols that were used, such that the results observed in any one experiment depended on the stimulus conditions and the subject's attentional strategy, a notion that we define precisely in terms of the attention field in the model, but that has not typically been completely under experimental control.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Reynolds, John H. and Heeger, David J.},
	month = jan,
	year = {2009},
	pmid = {19186161},
	pmcid = {PMC2752446},
	keywords = {Attention, Humans, Visual Cortex, Computer Simulation, Animals, Visual Perception, Action Potentials, Neurons, Visual Fields, Models, Neurological, Contrast Sensitivity},
	pages = {168--185},
	file = {Reynolds_Heeger_2009_The normalization model of attention.pdf:/Users/tito/Zotero/storage/YP24JJIG/Reynolds_Heeger_2009_The normalization model of attention.pdf:application/pdf},
}

@article{arcaro_widespread_2015,
	title = {Widespread correlation patterns of {fMRI} signal across visual cortex reflect eccentricity organization},
	volume = {4},
	issn = {2050-084X},
	doi = {10.7554/eLife.03952},
	abstract = {The human visual system can be divided into over two-dozen distinct areas, each of which contains a topographic map of the visual field. A fundamental question in vision neuroscience is how the visual system integrates information from the environment across different areas. Using neuroimaging, we investigated the spatial pattern of correlated BOLD signal across eight visual areas on data collected during rest conditions and during naturalistic movie viewing. The correlation pattern between areas reflected the underlying receptive field organization with higher correlations between cortical sites containing overlapping representations of visual space. In addition, the correlation pattern reflected the underlying widespread eccentricity organization of visual cortex, in which the highest correlations were observed for cortical sites with iso-eccentricity representations including regions with non-overlapping representations of visual space. This eccentricity-based correlation pattern appears to be part of an intrinsic functional architecture that supports the integration of information across functionally specialized visual areas.},
	language = {eng},
	journal = {Elife},
	author = {Arcaro, Michael J. and Honey, Christopher J. and Mruczek, Ryan E. B. and Kastner, Sabine and Hasson, Uri},
	month = feb,
	year = {2015},
	pmid = {25695154},
	pmcid = {PMC4337732},
	keywords = {fMRI, connectivity, neuroscience, Adult, Brain Mapping, Female, Humans, Magnetic Resonance Imaging, Male, Photic Stimulation, Visual Cortex, topography, Algorithms, Young Adult, Rest, visual cortex, Visual Fields, Models, Neurological, eccentricity, human, Regression Analysis, Vision, Ocular},
	file = {Arcaro et al_2015_Widespread correlation patterns of fMRI signal across visual cortex reflect.pdf:/Users/tito/Zotero/storage/8LXITE4F/Arcaro et al_2015_Widespread correlation patterns of fMRI signal across visual cortex reflect.pdf:application/pdf},
}

@article{genon_how_2018,
	title = {How to {Characterize} the {Function} of a {Brain} {Region}},
	volume = {22},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661318300238},
	doi = {10.1016/j.tics.2018.01.010},
	abstract = {Many brain regions have been defined, but a comprehensive formalization of each region’s function in relation to human behavior is still lacking. Current knowledge comes from various fields, which have diverse conceptions of ‘functions’. We briefly review these fields and outline how the heterogeneity of associations could be harnessed to disclose the computational function of any region. Aggregating activation data from neuroimaging studies allows us to characterize the functional engagement of a region across a range of experimental conditions. Furthermore, large-sample data can disclose covariation between brain region features and ecological behavioral phenotyping. Combining these two approaches opens a new perspective to determine the behavioral associations of a brain region, and hence its function and broader role within large-scale functional networks.},
	number = {4},
	urldate = {2019-10-05},
	journal = {Trends in Cognitive Sciences},
	author = {Genon, Sarah and Reid, Andrew and Langner, Robert and Amunts, Katrin and Eickhoff, Simon B.},
	month = apr,
	year = {2018},
	keywords = {MRI, brain mapping, BrainMap, data-driven, Functional specialization, Neurosynth},
	pages = {350--364},
	file = {Genon et al_2018_How to Characterize the Function of a Brain Region.pdf:/Users/tito/Zotero/storage/8IYUP2HI/Genon et al_2018_How to Characterize the Function of a Brain Region.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/GUE48D9B/S1364661318300238.html:text/html},
}

@article{power_sources_2017,
	title = {Sources and implications of whole-brain {fMRI} signals in humans},
	volume = {146},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811916305158},
	doi = {10.1016/j.neuroimage.2016.09.038},
	abstract = {Whole-brain fMRI signals are a subject of intense interest: variance in the global fMRI signal (the spatial mean of all signals in the brain) indexes subject arousal, and psychiatric conditions such as schizophrenia and autism have been characterized by differences in the global fMRI signal. Further, vigorous debates exist on whether global signals ought to be removed from fMRI data. However, surprisingly little research has focused on the empirical properties of whole-brain fMRI signals. Here we map the spatial and temporal properties of the global signal, individually, in 1000+ fMRI scans. Variance in the global fMRI signal is strongly linked to head motion, to hardware artifacts, and to respiratory patterns and their attendant physiologic changes. Many techniques used to prepare fMRI data for analysis fail to remove these uninteresting kinds of global signal fluctuations. Thus, many studies include, at the time of analysis, prominent global effects of yawns, breathing changes, and head motion, among other signals. Such artifacts will mimic dynamic neural activity and will spuriously alter signal covariance throughout the brain. Methods capable of isolating and removing global artifactual variance while preserving putative “neural” variance are needed; this paper adopts no position on the topic of global signal regression.},
	urldate = {2019-10-06},
	journal = {NeuroImage},
	author = {Power, Jonathan D. and Plitt, Mark and Laumann, Timothy O. and Martin, Alex},
	month = feb,
	year = {2017},
	pages = {609--625},
	file = {Power et al_2017_Sources and implications of whole-brain fMRI signals in humans.pdf:/Users/tito/Zotero/storage/6YH2NXNV/Power et al_2017_Sources and implications of whole-brain fMRI signals in humans.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/RJW4UHWV/S1053811916305158.html:text/html},
}

@article{betzel_high-amplitude_2019,
	title = {High-amplitude co-fluctuations in cortical activity drive resting-state functional connectivity},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/800045v1},
	doi = {10.1101/800045},
	abstract = {{\textless}p{\textgreater}Resting-state functional connectivity is used throughout neuroscience to study brain organization and to generate biomarkers of development, disease, and cognition. The processes that give rise to correlated activity are, however, poorly understood. Here, we decompose resting-state functional connectivity using a 99temporal unwrapping99 procedure to assess the contributions of moment-to-moment activity co-fluctuations to the overall connectivity pattern. This approach temporally resolves functional connectivity at a timescale of single frames, which enables us to make direct comparisons of co-fluctuations of network organization with fluctuations in the BOLD time series. We show that, surprisingly, only a small fraction of frames exhibiting the strongest co-fluctuation amplitude are required to explain a significant fraction of variance in the overall pattern of connection weights as well as the network9s modular structure. These frames coincide with frames of high BOLD activity amplitude, corresponding to activity patterns that are remarkably consistent across individuals and identify fluctuations in default mode and control network activity as the primary driver of resting-state functional connectivity. Our approach reveals fine-scale temporal structure of resting-state functional connectivity, and discloses that frame-wise contributions vary across time. These observations illuminate the relation of brain activity to functional connectivity and open a number of new directions for future research.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-10-14},
	journal = {bioRxiv},
	author = {Betzel, Richard and Faskowitz, Joshua and Sporns, Olaf},
	month = oct,
	year = {2019},
	pages = {800045},
	file = {Betzel et al_2019_High-amplitude co-fluctuations in cortical activity drive resting-state.pdf:/Users/tito/Zotero/storage/6SC388XQ/Betzel et al_2019_High-amplitude co-fluctuations in cortical activity drive resting-state.pdf:application/pdf},
}

@article{miller_itinerancy_2016,
	series = {Systems neuroscience},
	title = {Itinerancy between attractor states in neural systems},
	volume = {40},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438816300642},
	doi = {10.1016/j.conb.2016.05.005},
	abstract = {Converging evidence from neural, perceptual and simulated data suggests that discrete attractor states form within neural circuits through learning and development. External stimuli may bias neural activity to one attractor state or cause activity to transition between several discrete states. Evidence for such transitions, whose timing can vary across trials, is best accrued through analyses that avoid any trial-averaging of data. One such method, hidden Markov modeling, has been effective in this context, revealing state transitions in many neural circuits during many tasks. Concurrently, modeling efforts have revealed computational benefits of stimulus processing via transitions between attractor states. This review describes the current state of the field, with comments on how its perceived limitations have been addressed.},
	language = {en},
	urldate = {2019-10-17},
	journal = {Current Opinion in Neurobiology},
	author = {Miller, Paul},
	month = oct,
	year = {2016},
	pages = {14--22},
	file = {Miller_2016_Itinerancy between attractor states in neural systems.pdf:/Users/tito/Zotero/storage/4L42PLA6/Miller_2016_Itinerancy between attractor states in neural systems.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/GFYSHIFE/S0959438816300642.html:text/html},
}

@article{lawlor_linear-nonlinear-time-warp-poisson_2018,
	title = {Linear-nonlinear-time-warp-poisson models of neural activity},
	volume = {45},
	issn = {1573-6873},
	url = {https://doi.org/10.1007/s10827-018-0696-6},
	doi = {10.1007/s10827-018-0696-6},
	abstract = {Prominent models of spike trains assume only one source of variability – stochastic (Poisson) spiking – when stimuli and behavior are fixed. However, spike trains may also reflect variability due to internal processes such as planning. For example, we can plan a movement at one point in time and execute it at some arbitrary later time. Neurons involved in planning may thus share an underlying time course that is not precisely locked to the actual movement. Here we combine the standard Linear-Nonlinear-Poisson (LNP) model with Dynamic Time Warping (DTW) to account for shared temporal variability. When applied to recordings from macaque premotor cortex, we find that time warping considerably improves predictions of neural activity. We suggest that such temporal variability is a widespread phenomenon in the brain which should be modeled.},
	language = {en},
	number = {3},
	urldate = {2019-10-17},
	journal = {J Comput Neurosci},
	author = {Lawlor, Patrick N. and Perich, Matthew G. and Miller, Lee E. and Kording, Konrad P.},
	month = dec,
	year = {2018},
	keywords = {Modeling, Generalized linear model, Poisson process, Reaching movements, Spike trains},
	pages = {173--191},
	file = {Lawlor et al_2018_Linear-nonlinear-time-warp-poisson models of neural activity.pdf:/Users/tito/Zotero/storage/EBB98XXT/Lawlor et al_2018_Linear-nonlinear-time-warp-poisson models of neural activity.pdf:application/pdf},
}

@article{kopell_gamma_2000-1,
	title = {Gamma rhythms and beta rhythms have different synchronization properties},
	volume = {97},
	copyright = {Copyright © 2000, The National Academy of Sciences},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/97/4/1867},
	doi = {10.1073/pnas.97.4.1867},
	abstract = {Experimental and modeling efforts suggest that rhythms in the CA1 region of the hippocampus that are in the beta range (12–29 Hz) have a different dynamical structure than that of gamma (30–70 Hz). We use a simplified model to show that the different rhythms employ different dynamical mechanisms to synchronize, based on different ionic currents. The beta frequency is able to synchronize over long conduction delays (corresponding to signals traveling a significant distance in the brain) that apparently cannot be tolerated by gamma rhythms. The synchronization properties are consistent with data suggesting that gamma rhythms are used for relatively local computations whereas beta rhythms are used for higher level interactions involving more distant structures.},
	language = {en},
	number = {4},
	urldate = {2019-10-21},
	journal = {PNAS},
	author = {Kopell, N. and Ermentrout, G. B. and Whittington, M. A. and Traub, R. D.},
	month = feb,
	year = {2000},
	pmid = {10677548},
	pages = {1867--1872},
	file = {Kopell et al_2000_Gamma rhythms and beta rhythms have different synchronization properties.pdf:/Users/tito/Zotero/storage/HEWAW758/Kopell et al_2000_Gamma rhythms and beta rhythms have different synchronization properties.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/X4PJLUNB/1867.html:text/html},
}

@article{pillow_spatio-temporal_2008,
	title = {Spatio-temporal correlations and visual signalling in a complete neuronal population},
	volume = {454},
	copyright = {2008 Macmillan Publishers Limited. All rights reserved},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature07140},
	doi = {10.1038/nature07140},
	abstract = {The functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses is analysed. Fitting the physiological data to a model of multi-neuron spike responses, it is found that a significant fraction of what is usually considered single-cell noise in trial-to-trial response variability can be explained by correlations, and that a significant amount of sensory information can be decoded from the correlation structure.},
	language = {en},
	number = {7207},
	urldate = {2019-10-21},
	journal = {Nature},
	author = {Pillow, Jonathan W. and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M. and Chichilnisky, E. J. and Simoncelli, Eero P.},
	month = aug,
	year = {2008},
	pages = {995--999},
	file = {Pillow et al_2008_Spatio-temporal correlations and visual signalling in a complete neuronal.pdf:/Users/tito/Zotero/storage/9ETMQL8U/Pillow et al_2008_Spatio-temporal correlations and visual signalling in a complete neuronal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/XDW72C9K/nature07140.html:text/html},
}

@article{gao_inferring_2017,
	title = {Inferring synaptic excitation/inhibition balance from field potentials},
	volume = {158},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305621},
	doi = {10.1016/j.neuroimage.2017.06.078},
	abstract = {Neural circuits sit in a dynamic balance between excitation (E) and inhibition (I). Fluctuations in E:I balance have been shown to influence neural computation, working memory, and information flow, while more drastic shifts and aberrant E:I patterns are implicated in numerous neurological and psychiatric disorders. Current methods for measuring E:I dynamics require invasive procedures that are difficult to perform in behaving animals, and nearly impossible in humans. This has limited the ability to examine the full impact that E:I shifts have in cognition and disease. In this study, we develop a computational model to show that E:I changes can be estimated from the power law exponent (slope) of the electrophysiological power spectrum. Predictions from the model are validated in published data from two species (rats and macaques). We find that reducing E:I ratio via the administration of general anesthetic in macaques results in steeper power spectra, tracking conscious state over time. This causal result is supported by inference from known anatomical E:I changes across the depth of rat hippocampus, as well as oscillatory theta-modulated dynamic shifts in E:I. Our results provide evidence that E:I ratio may be inferred from electrophysiological recordings at many spatial scales, ranging from the local field potential to surface electrocorticography. This simple method for estimating E:I ratio—one that can be applied retrospectively to existing data—removes a major hurdle in understanding a currently difficult to measure, yet fundamental, aspect of neural computation.},
	language = {en},
	urldate = {2019-10-22},
	journal = {NeuroImage},
	author = {Gao, Richard and Peterson, Erik J. and Voytek, Bradley},
	month = sep,
	year = {2017},
	keywords = {Electrocorticography, Excitation-inhibition balance, Local field potential, Power law, Power spectral density},
	pages = {70--78},
	file = {Gao et al_2017_Inferring synaptic excitation-inhibition balance from field potentials.pdf:/Users/tito/Zotero/storage/7VVMU9RI/Gao et al_2017_Inferring synaptic excitation-inhibition balance from field potentials.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/TIB6GUIA/S1053811917305621.html:text/html},
}

@article{richards_deep_2019,
	title = {A deep learning framework for neuroscience},
	volume = {22},
	copyright = {2019 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0520-2},
	doi = {10.1038/s41593-019-0520-2},
	abstract = {A deep network is best understood in terms of components used to design it—objective functions, architecture and learning rules—rather than unit-by-unit computation. Richards et al. argue that this inspires fruitful approaches to systems neuroscience.},
	language = {en},
	number = {11},
	urldate = {2019-10-28},
	journal = {Nat Neurosci},
	author = {Richards, Blake A. and Lillicrap, Timothy P. and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and Berker, Archy de and Ganguli, Surya and Gillon, Colleen J. and Hafner, Danijar and Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and Lindsay, Grace W. and Miller, Kenneth D. and Naud, Richard and Pack, Christopher C. and Poirazi, Panayiota and Roelfsema, Pieter and Sacramento, João and Saxe, Andrew and Scellier, Benjamin and Schapiro, Anna C. and Senn, Walter and Wayne, Greg and Yamins, Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien, Denis and Kording, Konrad P.},
	month = nov,
	year = {2019},
	pages = {1761--1770},
	file = {Richards et al_2019_A deep learning framework for neuroscience.pdf:/Users/tito/Zotero/storage/HR9EUQ3U/Richards et al_2019_A deep learning framework for neuroscience.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MSXF4MQG/s41593-019-0520-2.html:text/html},
}

@article{brette_is_2019,
	title = {Is coding a relevant metaphor for the brain?},
	journal = {Behavioral and Brain Sciences},
	author = {Brette, Romain},
	year = {2019},
	pages = {1--44},
	file = {Brette_2019_Is coding a relevant metaphor for the brain.pdf:/Users/tito/Zotero/storage/I8PVDFBJ/Brette_2019_Is coding a relevant metaphor for the brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/LM87ZF8A/D578626E4888193FFFAE5B6E2C37E052.html:text/html},
}

@article{lillicrap_what_2019-1,
	title = {What does it mean to understand a neural network?},
	url = {http://arxiv.org/abs/1907.06374},
	abstract = {We can define a neural network that can learn to recognize objects in less than 100 lines of code. However, after training, it is characterized by millions of weights that contain the knowledge about many object types across visual scenes. Such networks are thus dramatically easier to understand in terms of the code that makes them than the resulting properties, such as tuning or connections. In analogy, we conjecture that rules for development and learning in brains may be far easier to understand than their resulting properties. The analogy suggests that neuroscience would benefit from a focus on learning and development.},
	urldate = {2019-10-30},
	journal = {arXiv:1907.06374 [cs, q-bio, stat]},
	author = {Lillicrap, Timothy P. and Kording, Konrad P.},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.06374},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 9 pages, 2 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/6XXBRG65/1907.html:text/html;Lillicrap_Kording_2019_What does it mean to understand a neural network.pdf:/Users/tito/Zotero/storage/7MPYWKK6/Lillicrap_Kording_2019_What does it mean to understand a neural network.pdf:application/pdf},
}

@article{seitzman_set_2019,
	title = {A set of functionally-defined brain regions with improved representation of the subcortex and cerebellum},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191930881X},
	doi = {10.1016/j.neuroimage.2019.116290},
	abstract = {An important aspect of network-based analysis is robust node definition. This issue is critical for functional brain network analyses, as poor node choice can lead to spurious findings and misleading inferences about functional brain organization. Two sets of functional brain nodes from our group are well represented in the literature: (1) 264 volumetric regions of interest (ROIs) reported in Power et al., 2011) and (2) 333 cortical surface parcels reported in Gordon et al., 2016). However, subcortical and cerebellar structures are either incompletely captured or missing from these ROI sets. Therefore, properties of functional network organization involving the subcortex and cerebellum may be underappreciated thus far. Here, we apply a winner-take-all partitioning method to resting-state fMRI data to generate novel functionally-constrained ROIs in the thalamus, basal ganglia, amygdala, hippocampus, and cerebellum. We validate these ROIs in three datasets using several criteria, including agreement with existing literature and anatomical atlases. Further, we demonstrate that combining these ROIs with established cortical ROIs recapitulates and extends previously described functional network organization. This new set of ROIs is made publicly available for general use, including a full list of MNI coordinates and functional network labels.},
	language = {en},
	urldate = {2019-10-31},
	journal = {NeuroImage},
	author = {Seitzman, Benjamin A. and Gratton, Caterina and Marek, Scott and Raut, Ryan V. and Dosenbach, Nico U. F. and Schlaggar, Bradley L. and Petersen, Steven E. and Greene, Deanna J.},
	month = oct,
	year = {2019},
	keywords = {Resting-state, Functional connectivity, Networks, Cerebellum, Subcortical},
	pages = {116290},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/PWS2MHYL/S105381191930881X.html:text/html;Seitzman et al_2019_A set of functionally-defined brain regions with improved representation of the.pdf:/Users/tito/Zotero/storage/4WPA9JGE/Seitzman et al_2019_A set of functionally-defined brain regions with improved representation of the.pdf:application/pdf},
}

@misc{noauthor_chaos_nodate,
	title = {Chaos in {Neuronal} {Networks} with {Balanced} {Excitatory} and {Inhibitory} {Activity} {\textbar} {Science}},
	url = {https://science.sciencemag.org/content/274/5293/1724},
	urldate = {2019-10-31},
	file = {Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity | Science:/Users/tito/Zotero/storage/IA76DD8I/1724.html:text/html},
}

@article{gu_regional_2019,
	title = {Regional excitation-inhibition balance predicts default-mode network deactivation via functional connectivity},
	volume = {185},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918320275},
	doi = {10.1016/j.neuroimage.2018.10.055},
	abstract = {Deactivation of the default mode network (DMN) is one of the most reliable observations from neuroimaging and has significant implications in development, aging, and various neuropsychiatric disorders. However, the neural mechanism underlying DMN deactivation remains elusive. As the coordination of regional neurochemical substrates and interregional neural interactions are both essential in support of brain functions, a quantitative description of how they impact DMN deactivation may provide new insights into the mechanism. Using an n-back working memory task fMRI and magnetic resonance spectroscopy, we probed the pairwise relationship between task-induced deactivation, interregional functional connectivity and regional excitation-inhibition balance (evaluated by glutamate/GABA ratio) in the posterior cingulate cortex/precuneus (PCC/PCu). Task-induced PCC/PCu deactivation correlated with its excitation-inhibition balance and interregional functional connectivity, where participants with lower glutamate/GABA ratio, stronger intra-DMN connections and stronger antagonistic DMN-SN (salience network)/ECN (executive control network) inter-network connections had greater PCC/PCu deactivation. Mediation analyses revealed that the DMN-SN functional interactions partially mediated the relationship between task-induced deactivation and the excitation-inhibition balance at the PCC/PCu. The triple-relationship discovered in the present study has the potential to bridge DMN-deactivation related findings from various neuroimaging modalities and may provide new insights into the neural mechanism of DMN deactivation. Moreover, this finding may have significant implications for neuropsychiatric disorders related to the DMN dysfunction and suggests an integrated application of pharmacological and neuromodulation-based strategies for rescuing DMN deactivation deficits.},
	language = {en},
	urldate = {2019-10-31},
	journal = {NeuroImage},
	author = {Gu, Hong and Hu, Yuzheng and Chen, Xi and He, Yong and Yang, Yihong},
	month = jan,
	year = {2019},
	keywords = {fMRI, Default mode network, Functional connectivity, Magnetic resonance spectroscopy, Task-based deactivation},
	pages = {388--397},
	file = {Gu et al_2019_Regional excitation-inhibition balance predicts default-mode network.pdf:/Users/tito/Zotero/storage/FULL7AE6/Gu et al_2019_Regional excitation-inhibition balance predicts default-mode network.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/R3SGMP8X/S1053811918320275.html:text/html},
}

@article{rolnick_identifying_2019,
	title = {Identifying {Weights} and {Architectures} of {Unknown} {ReLU} {Networks}},
	url = {http://arxiv.org/abs/1910.00744},
	abstract = {The output of a neural network depends on its parameters in a highly nonlinear way, and it is widely assumed that a network's parameters cannot be identified from its outputs. Here, we show that in many cases it is possible to reconstruct the architecture, weights, and biases of a deep ReLU network given the ability to query the network. ReLU networks are piecewise linear and the boundaries between pieces correspond to inputs for which one of the ReLUs switches between inactive and active states. Thus, first-layer ReLUs can be identified (up to sign and scaling) based on the orientation of their associated hyperplanes. Later-layer ReLU boundaries bend when they cross earlier-layer boundaries and the extent of bending reveals the weights between them. Our algorithm uses this to identify the units in the network and weights connecting them (up to isomorphism). The fact that considerable parts of deep networks can be identified from their outputs has implications for security, neuroscience, and our understanding of neural networks.},
	urldate = {2019-10-31},
	journal = {arXiv:1910.00744 [cs, stat]},
	author = {Rolnick, David and Kording, Konrad P.},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.00744},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 15 pages, 4 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/HPU7IQIK/1910.html:text/html;Rolnick_Kording_2019_Identifying Weights and Architectures of Unknown ReLU Networks.pdf:/Users/tito/Zotero/storage/NWKDU3XZ/Rolnick_Kording_2019_Identifying Weights and Architectures of Unknown ReLU Networks.pdf:application/pdf},
}

@article{wang_generalized_2018,
	title = {Generalized {Recurrent} {Neural} {Network} accommodating {Dynamic} {Causal} {Modeling} for functional {MRI} analysis},
	volume = {178},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191830449X},
	doi = {10.1016/j.neuroimage.2018.05.042},
	abstract = {Dynamic Causal Modeling (DCM) is an advanced biophysical model which explicitly describes the entire process from experimental stimuli to functional magnetic resonance imaging (fMRI) signals via neural activity and cerebral hemodynamics. To conduct a DCM study, one needs to represent the experimental stimuli as a compact vector-valued function of time, which is hard in complex tasks such as book reading and natural movie watching. Deep learning provides the state-of-the-art signal representation solution, encoding complex signals into compact dense vectors while preserving the essence of the original signals. There is growing interest in using Recurrent Neural Networks (RNNs), a major family of deep learning techniques, in fMRI modeling. However, the generic RNNs used in existing studies work as black boxes, making the interpretation of results in a neuroscience context difficult and obscure. In this paper, we propose a new biophysically interpretable RNN built on DCM, DCM-RNN. We generalize the vanilla RNN and show that DCM can be cast faithfully as a special form of the generalized RNN. DCM-RNN uses back propagation for parameter estimation. We believe DCM-RNN is a promising tool for neuroscience. It can fit seamlessly into classical DCM studies. We demonstrate face validity of DCM-RNN in two principal applications of DCM: causal brain architecture hypotheses testing and effective connectivity estimation. We also demonstrate construct validity of DCM-RNN in an attention-visual experiment. Moreover, DCM-RNN enables end-to-end training of DCM and representation learning deep neural networks, extending DCM studies to complex tasks.},
	language = {en},
	urldate = {2019-10-31},
	journal = {NeuroImage},
	author = {Wang, Yuan and Wang, Yao and Lui, Yvonne W.},
	month = sep,
	year = {2018},
	keywords = {Effective connectivity, Functional magnetic resonance imaging, Causal architecture, Dynamic Causal Modeling, Recurrent Neural Network},
	pages = {385--402},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/GP5LB4PH/S105381191830449X.html:text/html;Wang et al_2018_Generalized Recurrent Neural Network accommodating Dynamic Causal Modeling for.pdf:/Users/tito/Zotero/storage/BH8Z3H2Z/Wang et al_2018_Generalized Recurrent Neural Network accommodating Dynamic Causal Modeling for.pdf:application/pdf},
}

@article{genkin_beyond_2019,
	title = {Beyond generalization: {Enhancing} accurate interpretation of flexible models},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {Beyond generalization},
	url = {https://www.biorxiv.org/content/10.1101/808261v1},
	doi = {10.1101/808261},
	abstract = {{\textless}p{\textgreater}Machine learning optimizes flexible models to predict data. In scientific applications, there is a rising interest in interpreting these flexible models to derive hypotheses from data. However, it is unknown whether good data prediction guarantees accurate interpretation of flexible models. We test this connection using a flexible, yet intrinsically interpretable framework for modeling neural dynamics. We find that many models discovered during optimization predict data equally well, yet they fail to match the correct hypothesis. We develop an alternative approach that identifies models with correct interpretation by comparing model features across data samples to separate true features from noise. Our results reveal that good predictions cannot substitute for accurate interpretation of flexible models and offer a principled approach to identify models with correct interpretation.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-10-31},
	journal = {bioRxiv},
	author = {Genkin, Mikhail and Engel, Tatiana A.},
	month = oct,
	year = {2019},
	pages = {808261},
	file = {Genkin_Engel_2019_Beyond generalization.pdf:/Users/tito/Zotero/storage/SSZSA83Z/Genkin_Engel_2019_Beyond generalization.pdf:application/pdf},
}

@article{engel_new_2019,
	title = {New perspectives on dimensionality and variability from large-scale cortical dynamics},
	volume = {58},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438819300388},
	doi = {10.1016/j.conb.2019.09.003},
	abstract = {The neocortex is a multi-scale network, with intricate local circuitry interwoven into a global mesh of long-range connections. Neural activity propagates within this network on a wide range of temporal and spatial scales. At the micro scale, neurophysiological recordings reveal coordinated dynamics in local neural populations, which support behaviorally relevant computations. At the macro scale, neuroimaging modalities measure global activity fluctuations organized into spatiotemporal patterns across the entire brain. Here we review recent advances linking the local and global scales of cortical dynamics and their relationship to behavior. We argue that diverse experimental observations on the dimensionality and variability of neural activity can be reconciled by considering how activity propagates in space and time on multiple spatial scales.},
	language = {en},
	urldate = {2019-10-31},
	journal = {Current Opinion in Neurobiology},
	author = {Engel, Tatiana A and Steinmetz, Nicholas A},
	month = oct,
	year = {2019},
	pages = {181--190},
	file = {Engel_Steinmetz_2019_New perspectives on dimensionality and variability from large-scale cortical.pdf:/Users/tito/Zotero/storage/LPZA99Z5/Engel_Steinmetz_2019_New perspectives on dimensionality and variability from large-scale cortical.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/Q2Q3ZUZV/S0959438819300388.html:text/html},
}

@article{heeger_oscillatory_2019,
	title = {Oscillatory recurrent gated neural integrator circuits ({ORGaNICs}), a unifying theoretical framework for neural dynamics},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2019/10/18/1911633116},
	doi = {10.1073/pnas.1911633116},
	abstract = {Working memory is an example of a cognitive and neural process that is not static but evolves dynamically with changing sensory inputs; another example is motor preparation and execution. We introduce a theoretical framework for neural dynamics, based on oscillatory recurrent gated neural integrator circuits (ORGaNICs), and apply it to simulate key phenomena of working memory and motor control. The model circuits simulate neural activity with complex dynamics, including sequential activity and traveling waves of activity, that manipulate (as well as maintain) information during working memory. The same circuits convert spatial patterns of premotor activity to temporal profiles of motor control activity and manipulate (e.g., time warp) the dynamics. Derivative-like recurrent connectivity, in particular, serves to manipulate and update internal models, an essential feature of working memory and motor execution. In addition, these circuits incorporate recurrent normalization, to ensure stability over time and robustness with respect to perturbations of synaptic weights.},
	language = {en},
	urldate = {2019-10-31},
	journal = {PNAS},
	author = {Heeger, David J. and Mackey, Wayne E.},
	month = oct,
	year = {2019},
	pmid = {31636212},
	keywords = {computational neuroscience, recurrent neural network, working memory, normalization, motor control},
	pages = {201911633},
	file = {Heeger_Mackey_2019_Oscillatory recurrent gated neural integrator circuits (ORGaNICs), a unifying.pdf:/Users/tito/Zotero/storage/ANUIH2HH/Heeger_Mackey_2019_Oscillatory recurrent gated neural integrator circuits (ORGaNICs), a unifying.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/CHVEWBFB/1911633116.html:text/html},
}

@article{bogacz_parameterization_2004,
	title = {Parameterization of connectionist models},
	volume = {36},
	issn = {1532-5970},
	url = {https://doi.org/10.3758/BF03206554},
	doi = {10.3758/BF03206554},
	abstract = {We present a method for estimating parameters of connectionist models that allows the model’s output to fit as closely as possible to empirical data. The method minimizes a cost function that measures the difference between statistics computed from the model’s output and statistics computed from the subjects’ performance. An optimization algorithm finds the values of the parameters that minimize the value of this cost function. The cost function also indicates whether the model’s statistics are significantly different from the data’s. In some cases, the method can find the optimal parameters automatically. In others, the method may facilitate the manual search for optimal parameters. The method has been implemented in Matlab, is fully documented, and is available for free download from the Psychonomic Society Web archive atwww.psychonomic.org/archive/.},
	language = {en},
	number = {4},
	urldate = {2019-11-03},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Bogacz, Rafal and Cohen, Jonathan D.},
	month = nov,
	year = {2004},
	keywords = {Connectionist Model, Cost Function, Lateralized Readiness Potential, Parameterization Procedure, Rameter Space},
	pages = {732--741},
	file = {Bogacz_Cohen_2004_Parameterization of connectionist models.pdf:/Users/tito/Zotero/storage/94MNX62S/Bogacz_Cohen_2004_Parameterization of connectionist models.pdf:application/pdf},
}

@article{bejjanki_noise_2017,
	title = {Noise correlations in the human brain and their impact on pattern classification},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005674},
	doi = {10.1371/journal.pcbi.1005674},
	abstract = {Multivariate decoding methods, such as multivoxel pattern analysis (MVPA), are highly effective at extracting information from brain imaging data. Yet, the precise nature of the information that MVPA draws upon remains controversial. Most current theories emphasize the enhanced sensitivity imparted by aggregating across voxels that have mixed and weak selectivity. However, beyond the selectivity of individual voxels, neural variability is correlated across voxels, and such noise correlations may contribute importantly to accurate decoding. Indeed, a recent computational theory proposed that noise correlations enhance multivariate decoding from heterogeneous neural populations. Here we extend this theory from the scale of neurons to functional magnetic resonance imaging (fMRI) and show that noise correlations between heterogeneous populations of voxels (i.e., voxels selective for different stimulus variables) contribute to the success of MVPA. Specifically, decoding performance is enhanced when voxels with high vs. low noise correlations (measured during rest or in the background of the task) are selected during classifier training. Conversely, voxels that are strongly selective for one class in a GLM or that receive high classification weights in MVPA tend to exhibit high noise correlations with voxels selective for the other class being discriminated against. Furthermore, we use simulations to show that this is a general property of fMRI data and that selectivity and noise correlations can have distinguishable influences on decoding. Taken together, our findings demonstrate that if there is signal in the data, the resulting above-chance classification accuracy is modulated by the magnitude of noise correlations.},
	language = {en},
	number = {8},
	urldate = {2019-11-03},
	journal = {PLOS Computational Biology},
	author = {Bejjanki, Vikranth R. and Silveira, Rava Azeredo da and Cohen, Jonathan D. and Turk-Browne, Nicholas B.},
	month = aug,
	year = {2017},
	keywords = {Neuroimaging, Functional magnetic resonance imaging, Neurons, Simulation and modeling, Hemodynamics, Background signal noise, Preprocessing, Statistical noise},
	pages = {e1005674},
	file = {Bejjanki et al_2017_Noise correlations in the human brain and their impact on pattern classification.pdf:/Users/tito/Zotero/storage/Z3YAS5RC/Bejjanki et al_2017_Noise correlations in the human brain and their impact on pattern classification.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JY3AF5AX/article.html:text/html},
}

@article{brosch_implicit_2013,
	title = {Implicit {Race} {Bias} {Decreases} the {Similarity} of {Neural} {Representations} of {Black} and {White} {Faces}},
	volume = {24},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/0956797612451465},
	doi = {10.1177/0956797612451465},
	abstract = {Implicit race bias has been shown to affect decisions and behaviors. It may also change perceptual experience by increasing perceived differences between social groups. We investigated how this phenomenon may be expressed at the neural level by testing whether the distributed blood-oxygenation-level-dependent (BOLD) patterns representing Black and White faces are more dissimilar in participants with higher implicit race bias. We used multivoxel pattern analysis to predict the race of faces participants were viewing. We successfully predicted the race of the faces on the basis of BOLD activation patterns in early occipital visual cortex, occipital face area, and fusiform face area (FFA). Whereas BOLD activation patterns in early visual regions, likely reflecting different perceptual features, allowed successful prediction for all participants, successful prediction on the basis of BOLD activation patterns in FFA, a high-level face-processing region, was restricted to participants with high pro-White bias. These findings suggest that stronger implicit pro-White bias decreases the similarity of neural representations of Black and White faces.},
	language = {en},
	number = {2},
	urldate = {2019-11-04},
	journal = {Psychol Sci},
	author = {Brosch, Tobias and Bar-David, Eyal and Phelps, Elizabeth A.},
	month = feb,
	year = {2013},
	pages = {160--166},
	file = {Brosch et al_2013_Implicit Race Bias Decreases the Similarity of Neural Representations of Black.pdf:/Users/tito/Zotero/storage/Y4EWX8WT/Brosch et al_2013_Implicit Race Bias Decreases the Similarity of Neural Representations of Black.pdf:application/pdf},
}

@article{kriegeskorte_interpreting_2019,
	series = {Machine {Learning}, {Big} {Data}, and {Neuroscience}},
	title = {Interpreting encoding and decoding models},
	volume = {55},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438818301004},
	doi = {10.1016/j.conb.2019.04.002},
	abstract = {Encoding and decoding models are widely used in systems, cognitive, and computational neuroscience to make sense of brain-activity data. However, the interpretation of their results requires care. Decoding models can help reveal whether particular information is present in a brain region in a format the decoder can exploit. Encoding models make comprehensive predictions about representational spaces. In the context of sensory experiments, where stimuli are experimentally controlled, encoding models enable us to test and compare brain-computational theories. Encoding and decoding models typically include fitted linear-model components. Sometimes the weights of the fitted linear combinations are interpreted as reflecting, in an encoding model, the contribution of different sensory features to the representation or, in a decoding model, the contribution of different measured brain responses to a decoded feature. Such interpretations can be problematic when the predictor variables or their noise components are correlated and when priors (or penalties) are used to regularize the fit. Encoding and decoding models are evaluated in terms of their generalization performance. The correct interpretation depends on the level of generalization a model achieves (e.g. to new response measurements for the same stimuli, to new stimuli from the same population, or to stimuli from a different population). Significant decoding or encoding performance of a single model (at whatever level of generality) does not provide strong constraints for theory. Many models must be tested and inferentially compared for analyses to drive theoretical progress.},
	language = {en},
	urldate = {2019-11-04},
	journal = {Current Opinion in Neurobiology},
	author = {Kriegeskorte, Nikolaus and Douglas, Pamela K},
	month = apr,
	year = {2019},
	pages = {167--179},
	file = {Kriegeskorte_Douglas_2019_Interpreting encoding and decoding models.pdf:/Users/tito/Zotero/storage/Z2QF6RUG/Kriegeskorte_Douglas_2019_Interpreting encoding and decoding models.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/AM4VE4N3/S0959438818301004.html:text/html},
}

@article{abbott_effect_1999,
	title = {The {Effect} of {Correlated} {Variability} on the {Accuracy} of a {Population} {Code}},
	volume = {11},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/089976699300016827},
	doi = {10.1162/089976699300016827},
	abstract = {We study the impact of correlated neuronal firing rate variability on the accuracy with which an encoded quantity can be extracted from a population of neurons. Contrary to widespread belief, correlations in the variabilities of neuronal firing rates do not, in general, limit the increase in coding accuracy provided by using large populations of encoding neurons. Furthermore, in some cases, but not all, correlations improve the accuracy of a population code.},
	number = {1},
	urldate = {2019-11-04},
	journal = {Neural Computation},
	author = {Abbott, L. F. and Dayan, Peter},
	month = jan,
	year = {1999},
	pages = {91--101},
	file = {Abbott_Dayan_1999_The Effect of Correlated Variability on the Accuracy of a Population Code.pdf:/Users/tito/Zotero/storage/8KSX5FIJ/Abbott_Dayan_1999_The Effect of Correlated Variability on the Accuracy of a Population Code.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/YYW4UC8J/089976699300016827.html:text/html},
}

@misc{noauthor_high-fidelity_nodate,
	title = {High-{Fidelity} {Coding} with {Correlated} {Neurons}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003970},
	urldate = {2019-11-04},
	file = {High-Fidelity Coding with Correlated Neurons:/Users/tito/Zotero/storage/7W9ANK5G/article.html:text/html},
}

@misc{noauthor_high-fidelity_nodate-1,
	title = {High-{Fidelity} {Coding} with {Correlated} {Neurons}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003970},
	urldate = {2019-11-04},
	file = {High-Fidelity Coding with Correlated Neurons:/Users/tito/Zotero/storage/72KDVRY8/article.html:text/html},
}

@article{da_silveira_high-fidelity_2014,
	title = {High-{Fidelity} {Coding} with {Correlated} {Neurons}},
	volume = {10},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1003970},
	doi = {10.1371/journal.pcbi.1003970},
	abstract = {Positive correlations in the activity of neurons are widely observed in the brain. Previous studies have shown these correlations to be detrimental to the fidelity of population codes, or at best marginally favorable compared to independent codes. Here, we show that positive correlations can enhance coding performance by astronomical factors. Specifically, the probability of discrimination error can be suppressed by many orders of magnitude. Likewise, the number of stimuli encoded—the capacity—can be enhanced more than tenfold. These effects do not necessitate unrealistic correlation values, and can occur for populations with a few tens of neurons. We further show that both effects benefit from heterogeneity commonly seen in population activity. Error suppression and capacity enhancement rest upon a pattern of correlation. Tuning of one or several effective parameters can yield a limit of perfect coding: the corresponding pattern of positive correlation leads to a ‘lock-in’ of response probabilities that eliminates variability in the subspace relevant for stimulus discrimination. We discuss the nature of this pattern and we suggest experimental tests to identify it.},
	language = {en},
	number = {11},
	urldate = {2019-11-04},
	journal = {PLoS Computational Biology},
	author = {da Silveira, Rava Azeredo and Berry, Michael J.},
	editor = {Graham, Lyle J.},
	month = nov,
	year = {2014},
	pages = {e1003970},
	file = {da Silveira and Berry - 2014 - High-Fidelity Coding with Correlated Neurons.pdf:/Users/tito/Zotero/storage/RY9LSN7W/da Silveira and Berry - 2014 - High-Fidelity Coding with Correlated Neurons.pdf:application/pdf},
}

@article{zhang_intrinsic_2019,
	title = {Intrinsic {Functional} {Connectivity} is {Organized} as {Three} {Interdependent} {Gradients}},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-019-51793-7},
	doi = {10.1038/s41598-019-51793-7},
	abstract = {The intrinsic functional architecture of the brain supports moment-to-moment maintenance of an internal model of the world. We hypothesized and found three interdependent architectural gradients underlying the organization of intrinsic functional connectivity within the human cerebral cortex. We used resting state fMRI data from two samples of healthy young adults (N’s = 280 and 270) to generate functional connectivity maps of 109 seeds culled from published research, estimated their pairwise similarities, and multidimensionally scaled the resulting similarity matrix. We discovered an optimal three-dimensional solution, accounting for 98\% of the variance within the similarity matrix. The three dimensions corresponded to three gradients, which spatially correlate with two functional features (external vs. internal sources of information; content representation vs. attentional modulation) and one structural feature (anatomically central vs. peripheral) of the brain. Remapping the three dimensions into coordinate space revealed that the connectivity maps were organized in a circumplex structure, indicating that the organization of intrinsic connectivity is jointly guided by graded changes along all three dimensions. Our findings emphasize coordination between multiple, continuous functional and anatomical gradients, and are consistent with the emerging predictive coding perspective.},
	language = {en},
	number = {1},
	urldate = {2019-11-07},
	journal = {Sci Rep},
	author = {Zhang, Jiahe and Abiose, Olamide and Katsumi, Yuta and Touroutoglou, Alexandra and Dickerson, Bradford C. and Barrett, Lisa Feldman},
	month = nov,
	year = {2019},
	pages = {1--14},
	file = {Snapshot:/Users/tito/Zotero/storage/8D5GFP72/s41598-019-51793-7.html:text/html;Zhang et al_2019_Intrinsic Functional Connectivity is Organized as Three Interdependent Gradients.pdf:/Users/tito/Zotero/storage/KWWYIPIC/Zhang et al_2019_Intrinsic Functional Connectivity is Organized as Three Interdependent Gradients.pdf:application/pdf},
}

@article{abbott_effect_1999-1,
	title = {The {Effect} of {Correlated} {Variability} on the {Accuracy} of a {Population} {Code}},
	volume = {11},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/089976699300016827},
	doi = {10.1162/089976699300016827},
	language = {en},
	number = {1},
	urldate = {2019-11-09},
	journal = {Neural Computation},
	author = {Abbott, L. F. and Dayan, Peter},
	month = jan,
	year = {1999},
	pages = {91--101},
	file = {Abbott and Dayan - 1999 - The Effect of Correlated Variability on the Accura.pdf:/Users/tito/Zotero/storage/YUM87RGU/Abbott and Dayan - 1999 - The Effect of Correlated Variability on the Accura.pdf:application/pdf},
}

@article{advani_high-dimensional_2017,
	title = {High-dimensional dynamics of generalization error in neural networks},
	url = {http://arxiv.org/abs/1710.03667},
	abstract = {We perform an average case analysis of the generalization dynamics of large neural networks trained using gradient descent. We study the practically-relevant "high-dimensional" regime where the number of free parameters in the network is on the order of or even larger than the number of examples in the dataset. Using random matrix theory and exact solutions in linear models, we derive the generalization error and training error dynamics of learning and analyze how they depend on the dimensionality of data and signal to noise ratio of the learning problem. We find that the dynamics of gradient descent learning naturally protect against overtraining and overfitting in large networks. Overtraining is worst at intermediate network sizes, when the effective number of free parameters equals the number of samples, and thus can be reduced by making a network smaller or larger. Additionally, in the high-dimensional regime, low generalization error requires starting with small initial weights. We then turn to non-linear neural networks, and show that making networks very large does not harm their generalization performance. On the contrary, it can in fact reduce overtraining, even without early stopping or regularization of any sort. We identify two novel phenomena underlying this behavior in overcomplete models: first, there is a frozen subspace of the weights in which no learning occurs under gradient descent; and second, the statistical properties of the high-dimensional regime yield better-conditioned input correlations which protect against overtraining. We demonstrate that naive application of worst-case theories such as Rademacher complexity are inaccurate in predicting the generalization performance of deep neural networks, and derive an alternative bound which incorporates the frozen subspace and conditioning effects and qualitatively matches the behavior observed in simulation.},
	urldate = {2019-11-11},
	journal = {arXiv:1710.03667 [physics, q-bio, stat]},
	author = {Advani, Madhu S. and Saxe, Andrew M.},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.03667},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Statistics - Machine Learning, Physics - Data Analysis, Statistics and Probability},
	file = {Advani_Saxe_2017_High-dimensional dynamics of generalization error in neural networks.pdf:/Users/tito/Zotero/storage/PHNFA3TQ/Advani_Saxe_2017_High-dimensional dynamics of generalization error in neural networks.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/KUDWM5WH/1710.html:text/html},
}

@article{uddin_towards_2019,
	title = {Towards a {Universal} {Taxonomy} of {Macro}-scale {Functional} {Human} {Brain} {Networks}},
	issn = {1573-6792},
	url = {https://doi.org/10.1007/s10548-019-00744-6},
	doi = {10.1007/s10548-019-00744-6},
	abstract = {The past decade has witnessed a proliferation of studies aimed at characterizing the human connectome. These projects map the brain regions comprising large-scale systems underlying cognition using non-invasive neuroimaging approaches and advanced analytic techniques adopted from network science. While the idea that the human brain is composed of multiple macro-scale functional networks has been gaining traction in cognitive neuroscience, the field has yet to reach consensus on several key issues regarding terminology. What constitutes a functional brain network? Are there “core” functional networks, and if so, what are their spatial topographies? What naming conventions, if universally adopted, will provide the most utility and facilitate communication amongst researchers? Can a taxonomy of functional brain networks be delineated? Here we survey the current landscape to identify six common macro-scale brain network naming schemes and conventions utilized in the literature, highlighting inconsistencies and points of confusion where appropriate. As a minimum recommendation upon which to build, we propose that a scheme incorporating anatomical terminology should provide the foundation for a taxonomy of functional brain networks. A logical starting point in this endeavor might delineate systems that we refer to here as “occipital”, “pericentral”, “dorsal frontoparietal”, “lateral frontoparietal”, “midcingulo-insular”, and “medial frontoparietal” networks. We posit that as the field of network neuroscience matures, it will become increasingly imperative to arrive at a taxonomy such as that proposed here, that can be consistently referenced across research groups.},
	language = {en},
	urldate = {2019-11-11},
	journal = {Brain Topogr},
	author = {Uddin, Lucina Q. and Yeo, B. T. Thomas and Spreng, R. Nathan},
	month = nov,
	year = {2019},
	keywords = {Functional connectivity, Coactivation, Human connectome, Network neuroscience},
	file = {Uddin et al_2019_Towards a Universal Taxonomy of Macro-scale Functional Human Brain Networks.pdf:/Users/tito/Zotero/storage/JGZ6YHCA/Uddin et al_2019_Towards a Universal Taxonomy of Macro-scale Functional Human Brain Networks.pdf:application/pdf},
}

@article{mcintosh_contexts_2004,
	title = {Contexts and catalysts},
	volume = {2},
	issn = {1559-0089},
	url = {https://doi.org/10.1385/NI:2:2:175},
	doi = {10.1385/NI:2:2:175},
	abstract = {There has been a historical tension between theories of brain function emphasizing regional specialization and those focusing on integration across regions. This tension continues despite the pervasive use of functional neuroimaging, which enables testing of these theories in the human brain. There are instances of agreement, where regions thought to be critical for a given behavior (e.g., Broca’s area and language production) do become more active when a person engages in that behavior. However, a number of disconcerting results have also been found. These include activation in areas not thought to be important for the behavior, and lack of activation in regions thought to be critical for particular behaviors based on studies of the damaged brain. A recently proposed Neural Context hypothesis of brain function provides a mechanism that can reconcile these apparently disparate findings. The hypothesis states that the functional relevance of a brain area depends on the status of other connected areas—i.e., the context within which the region is operating. A region can participate in several behaviors through variations in its interactions with other areas. It is possible that certain critical nodes serve as Behavioural Catalysts, enabling the transition between behavioral states, without differential alterations in the measured activity. By virtue of its anatomical connections, an area could facilitate a shift in functional connectivity between one set of regions to another. An imaging study on the changing interregional interactions involving the hippocampus in learning and awareness serves as an example of neural context. In this case, the hippocampus may serve to catalyze the transition to awareness.},
	language = {en},
	number = {2},
	urldate = {2019-11-11},
	journal = {Neuroinform},
	author = {McIntosh, Anthony Randal},
	month = jun,
	year = {2004},
	keywords = {Neuroimaging, neural networks, cognition, learning, awareness},
	pages = {175--181},
	file = {McIntosh_2004_Contexts and catalysts.pdf:/Users/tito/Zotero/storage/XTYRBATQ/McIntosh_2004_Contexts and catalysts.pdf:application/pdf},
}

@article{zhang_understanding_2019,
	title = {Understanding multivariate brain activity: evaluating the effect of voxelwise noise correlations on population codes in functional magnetic resonance imaging},
	shorttitle = {Understanding multivariate brain activity},
	url = {http://biorxiv.org/lookup/doi/10.1101/592618},
	doi = {10.1101/592618},
	abstract = {Previous studies have shown that neurons exhibit trial-by-trial correlated activity and that such noise correlations (NCs) greatly impact the accuracy of population codes. Meanwhile, multivariate pattern analysis (MVPA) has become a mainstream approach in functional magnetic resonance imaging (fMRI), but it remains unclear how NCs between voxels influence MVPA performance. Here, we tackle this issue by combining voxel-encoding modeling and MVPA. We focus on a well-established form of NC, tuning-compatible noise correlation (TCNC), whose sign and magnitude are systematically related to the tuning similarity between two units. We first replicate the classical finding that TCNCs impair population codes in a standard neuronal population. We then extend our analysis to fMRI data, and show that voxelwise TCNCs do not impair and can even improve MVPA performance when TCNCs are strong or the number of voxels is large. We also confirm these results using standard information-theoretic analyses in computational neuroscience. Further computational analyses demonstrate that the discrepancy between the effect of TCNCs in neuronal and voxel populations can be explained by tuning heterogeneity and pool sizes. Our results provide a theoretical foundation to understand the effect of correlated activity on population codes in macroscopic fMRI data. Our results also suggest that future fMRI research could benefit from a closer examination of the correlational structure of multivariate responses, which is not directly revealed by conventional MVPA approaches.},
	language = {en},
	urldate = {2019-11-11},
	journal = {bioRxiv},
	author = {Zhang, Ru-Yuan and Wei, Xue-Xin and Kay, Kendrick},
	month = apr,
	year = {2019},
	file = {Zhang et al. - 2019 - Understanding multivariate brain activity evaluat.pdf:/Users/tito/Zotero/storage/KVJGS8SJ/Zhang et al. - 2019 - Understanding multivariate brain activity evaluat.pdf:application/pdf},
}

@article{power_sources_2017-1,
	title = {Sources and implications of whole-brain {fMRI} signals in humans},
	volume = {146},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811916305158},
	doi = {10.1016/j.neuroimage.2016.09.038},
	abstract = {Whole-brain fMRI signals are a subject of intense interest: variance in the global fMRI signal (the spatial mean of all signals in the brain) indexes subject arousal, and psychiatric conditions such as schizophrenia and autism have been characterized by differences in the global fMRI signal. Further, vigorous debates exist on whether global signals ought to be removed from fMRI data. However, surprisingly little research has focused on the empirical properties of whole-brain fMRI signals. Here we map the spatial and temporal properties of the global signal, individually, in 1000+ fMRI scans. Variance in the global fMRI signal is strongly linked to head motion, to hardware artifacts, and to respiratory patterns and their attendant physiologic changes. Many techniques used to prepare fMRI data for analysis fail to remove these uninteresting kinds of global signal fluctuations. Thus, many studies include, at the time of analysis, prominent global effects of yawns, breathing changes, and head motion, among other signals. Such artifacts will mimic dynamic neural activity and will spuriously alter signal covariance throughout the brain. Methods capable of isolating and removing global artifactual variance while preserving putative “neural” variance are needed; this paper adopts no position on the topic of global signal regression.},
	language = {en},
	urldate = {2019-11-15},
	journal = {NeuroImage},
	author = {Power, Jonathan D. and Plitt, Mark and Laumann, Timothy O. and Martin, Alex},
	month = feb,
	year = {2017},
	pages = {609--625},
	file = {Power et al_2017_Sources and implications of whole-brain fMRI signals in humans.pdf:/Users/tito/Zotero/storage/3UK7DZF2/Power et al_2017_Sources and implications of whole-brain fMRI signals in humans.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/7SZ9PCKZ/S1053811916305158.html:text/html},
}

@article{schultz_global_2019,
	title = {Global connectivity of the fronto-parietal cognitive control network is related to depression symptoms in the general population},
	volume = {3},
	issn = {2472-1751},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/netn_a_00056},
	doi = {10.1162/netn_a_00056},
	abstract = {We all vary in our mental health, even among people not meeting diagnostic criteria for mental illness. Understanding this individual variability may reveal factors driving the risk for mental illness, as well as factors driving subclinical problems that still adversely affect quality of life. To better understand the large-scale brain network mechanisms underlying this variability, we examined the relationship between mental health symptoms and resting-state functional connectivity patterns in cognitive control systems. One such system is the fronto-parietal cognitive control network (FPN). Changes in FPN connectivity may impact mental health by disrupting the ability to regulate symptoms in a goal-directed manner. Here we test the hypothesis that FPN dysconnectivity relates to mental health symptoms even among individuals who do not meet formal diagnostic criteria but may exhibit meaningful symptom variation. We found that depression symptoms severity negatively correlated with between-network global connectivity (BGC) of the FPN. This suggests that decreased connectivity between the FPN and the rest of the brain is related to increased depression symptoms in the general population. These ﬁndings complement previous clinical studies to support the hypothesis that global FPN connectivity contributes to the regulation of mental health symptoms across both health and disease.},
	language = {en},
	number = {1},
	urldate = {2019-11-18},
	journal = {Network Neuroscience},
	author = {Schultz, Douglas H. and Ito, Takuya and Solomyak, Levi I. and Chen, Richard H. and Mill, Ravi D. and Anticevic, Alan and Cole, Michael W.},
	month = jan,
	year = {2019},
	pages = {107--123},
	file = {Schultz et al. - 2019 - Global connectivity of the fronto-parietal cogniti.pdf:/Users/tito/Zotero/storage/KS2L7KNT/Schultz et al. - 2019 - Global connectivity of the fronto-parietal cogniti.pdf:application/pdf},
}

@article{vinyals_grandmaster_2019,
	title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
	volume = {575},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1724-z},
	doi = {10.1038/s41586-019-1724-z},
	abstract = {AlphaStar uses a multi-agent reinforcement learning algorithm and has reached Grandmaster level, ranking among the top 0.2\% of human players for the real-time strategy game StarCraft II.},
	language = {en},
	number = {7782},
	urldate = {2019-11-19},
	journal = {Nature},
	author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, Rémi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and Wünsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
	month = nov,
	year = {2019},
	pages = {350--354},
	file = {Snapshot:/Users/tito/Zotero/storage/AADMS72L/s41586-019-1724-z.html:text/html;Vinyals et al_2019_Grandmaster level in StarCraft II using multi-agent reinforcement learning.pdf:/Users/tito/Zotero/storage/YZBY2Q8Z/Vinyals et al_2019_Grandmaster level in StarCraft II using multi-agent reinforcement learning.pdf:application/pdf},
}

@article{manor_network_1999,
	title = {Network {Oscillations} {Generated} by {Balancing} {Graded} {Asymmetric} {Reciprocal} {Inhibition} in {Passive} {Neurons}},
	volume = {19},
	copyright = {Copyright © 1999 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/19/7/2765},
	doi = {10.1523/JNEUROSCI.19-07-02765.1999},
	abstract = {We describe a novel mechanism by which network oscillations can arise from reciprocal inhibitory connections between two entirely passive neurons. The model was inspired by the activation of the gastric mill rhythm in the crab stomatogastric ganglion by the modulatory commissural ganglion neuron 1 (MCN1), but it is studied here in general terms. One model neuron has a linear current–voltage (I–V) curve with a low (L) resting potential, and the second model neuron has a linear current–voltage curve with a high (H) resting potential. The inhibitory connections between them are graded. There is an extrinsic modulatory excitatory input to the L neuron, and the L neuron presynaptically inhibits the modulatory neuron. Activation of the extrinsic modulatory neuron elicits stable network oscillations in which the L and H neurons are active in alternation. The oscillations arise because the graded reciprocal synapses create the equivalent of a negative-slope conductance region in theI–V curves for the cells. Geometrical methods are used to analyze the properties of and the mechanism underlying these network oscillations.},
	language = {en},
	number = {7},
	urldate = {2019-11-20},
	journal = {J. Neurosci.},
	author = {Manor, Yair and Nadim, Farzan and Epstein, Steven and Ritt, Jason and Marder, Eve and Kopell, Nancy},
	month = apr,
	year = {1999},
	pmid = {10087088},
	keywords = {central pattern generators, coupled oscillators, crustaceans, neural oscillators, phase plane analysis, mathematical model},
	pages = {2765--2779},
	file = {Manor et al_1999_Network Oscillations Generated by Balancing Graded Asymmetric Reciprocal.pdf:/Users/tito/Zotero/storage/HF6GN6HD/Manor et al_1999_Network Oscillations Generated by Balancing Graded Asymmetric Reciprocal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SHA5TWYY/2765.html:text/html},
}

@article{bittner_interrogating_2019,
	title = {Interrogating theoretical models of neural computation with deep inference},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/837567v2},
	doi = {10.1101/837567},
	abstract = {{\textless}p{\textgreater}A cornerstone of theoretical neuroscience is the circuit model: a system of equations that captures a hypothesized neural mechanism. Such models are valuable when they give rise to an experimentally observed phenomenon -- whether behavioral or in terms of neural activity -- and thus can offer insights into neural computation. The operation of these circuits, like all models, critically depends on the choices of model parameters. Historically, the gold standard has been to analytically derive the relationship between model parameters and computational properties. However, this enterprise quickly becomes infeasible as biologically realistic constraints are included into the model increasing its complexity, often resulting in ad hoc approaches to understanding the relationship between model and computation. We bring recent machine learning techniques -- the use of deep generative models for probabilistic inference -- to bear on this problem, learning distributions of parameters that produce the specified properties of computation. Importantly, the techniques we introduce offer a principled means to understand the implications of model parameter choices on computational properties of interest. We motivate this methodology with a worked example analyzing sensitivity in the stomatogastric ganglion. We then use it to go beyond linear theory of neuron-type input-responsivity in a model of primary visual cortex, gain a mechanistic understanding of rapid task switching in superior colliculus models, and attribute error to connectivity properties in recurrent neural networks solving a simple mathematical task. More generally, this work suggests a departure from realism vs tractability considerations, towards the use of modern machine learning for sophisticated interrogation of biologically relevant models.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-11-20},
	journal = {bioRxiv},
	author = {Bittner, Sean R. and Palmigiano, Agostina and Piet, Alex T. and Duan, Chunyu A. and Brody, Carlos D. and Miller, Kenneth D. and Cunningham, John P.},
	month = nov,
	year = {2019},
	pages = {837567},
	file = {Bittner et al_2019_Interrogating theoretical models of neural computation with deep inference.pdf:/Users/tito/Zotero/storage/RGEHMJM7/Bittner et al_2019_Interrogating theoretical models of neural computation with deep inference.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/94WCYBTJ/837567v2.html:text/html},
}

@article{litwin-kumar_constraining_2019,
	series = {Computational {Neuroscience}},
	title = {Constraining computational models using electron microscopy wiring diagrams},
	volume = {58},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438818302174},
	doi = {10.1016/j.conb.2019.07.007},
	abstract = {Numerous efforts to generate “connectomes,” or synaptic wiring diagrams, of large neural circuits or entire nervous systems are currently underway. These efforts promise an abundance of data to guide theoretical models of neural computation and test their predictions. However, there is not yet a standard set of tools for incorporating the connectivity constraints that these datasets provide into the models typically studied in theoretical neuroscience. This article surveys recent approaches to building models with constrained wiring diagrams and the insights they have provided. It also describes challenges and the need for new techniques to scale these approaches to ever more complex datasets.},
	language = {en},
	urldate = {2019-11-20},
	journal = {Current Opinion in Neurobiology},
	author = {Litwin-Kumar, Ashok and Turaga, Srinivas C},
	month = oct,
	year = {2019},
	pages = {94--100},
	file = {Litwin-Kumar_Turaga_2019_Constraining computational models using electron microscopy wiring diagrams.pdf:/Users/tito/Zotero/storage/P7YHFFIN/Litwin-Kumar_Turaga_2019_Constraining computational models using electron microscopy wiring diagrams.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/LGVFCHDY/S0959438818302174.html:text/html},
}

@misc{noauthor_human_nodate,
	title = {The {Human} {Brain} {Traverses} a {Common} {Activation}-{Pattern} {State} {Space} {Across} {Task} and {Rest} {\textbar} {Brain} {Connectivity}},
	url = {https://www.liebertpub.com/doi/10.1089/brain.2018.0586},
	urldate = {2019-11-27},
	file = {The Human Brain Traverses a Common Activation-Pattern State Space Across Task and Rest | Brain Connectivity:/Users/tito/Zotero/storage/ARFN3C8Z/brain.2018.html:text/html},
}

@article{chen_human_2018,
	title = {The {Human} {Brain} {Traverses} a {Common} {Activation}-{Pattern} {State} {Space} {Across} {Task} and {Rest}},
	volume = {8},
	issn = {2158-0014, 2158-0022},
	url = {https://www.liebertpub.com/doi/10.1089/brain.2018.0586},
	doi = {10.1089/brain.2018.0586},
	abstract = {Much of our lives are spent in unconstrained rest states, yet cognitive brain processes are primarily investigated using task-constrained states. It may be possible to utilize the insights gained from experimental control of task processes as reference points for investigating unconstrained rest. To facilitate comparison of rest and task functional magnetic resonance imaging data, we focused on activation amplitude patterns, commonly used for task but not rest analyses. During rest, we identiﬁed spontaneous changes in temporally extended whole-brain activation-pattern states. This revealed a hierarchical organization of rest states. The top consisted of two competing states consistent with previously identiﬁed ‘‘task-positive’’ and ‘‘task-negative’’ activation patterns. These states were composed of more speciﬁc states that repeated over time and across individuals. Contrasting with the view that rest consists of only task-negative states, task-positive states occurred 40\% of the time while individuals ‘‘rested,’’ suggesting task-focused activity may occur during rest. Together our results suggest that brain activation dynamics form a general hierarchy across task and rest, with a small number of dominant general states reﬂecting basic functional modes and a variety of speciﬁc states potentially reﬂecting a wide variety of cognitive processes.},
	language = {en},
	number = {7},
	urldate = {2019-11-27},
	journal = {Brain Connectivity},
	author = {Chen, Richard H. and Ito, Takuya and Kulkarni, Kaustubh R. and Cole, Michael W.},
	month = sep,
	year = {2018},
	pages = {429--443},
	file = {Chen et al. - 2018 - The Human Brain Traverses a Common Activation-Patt.pdf:/Users/tito/Zotero/storage/K3ITX9Q3/Chen et al. - 2018 - The Human Brain Traverses a Common Activation-Patt.pdf:application/pdf},
}

@article{steinmetz_distributed_2019,
	title = {Distributed coding of choice, action and engagement across the mouse brain},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1787-x},
	doi = {10.1038/s41586-019-1787-x},
	abstract = {Recordings from 30,000 neurons in 42 brain regions are used to delineate the spatial distribution of neuronal activity underlying vision, choice, action and behavioural engagement in mice.},
	language = {en},
	urldate = {2019-11-28},
	journal = {Nature},
	author = {Steinmetz, Nicholas A. and Zatka-Haas, Peter and Carandini, Matteo and Harris, Kenneth D.},
	month = nov,
	year = {2019},
	pages = {1--8},
	file = {Snapshot:/Users/tito/Zotero/storage/2RZSFDC4/s41586-019-1787-x.html:text/html;Steinmetz et al_2019_Distributed coding of choice, action and engagement across the mouse brain.pdf:/Users/tito/Zotero/storage/THA4XMV4/Steinmetz et al_2019_Distributed coding of choice, action and engagement across the mouse brain.pdf:application/pdf},
}

@article{vatansever_default_2015,
	title = {Default {Mode} {Dynamics} for {Global} {Functional} {Integration}},
	volume = {35},
	copyright = {Copyright © 2015 Vatansever et al.. This article is freely available online through the J Neurosci Author Open Choice option.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/35/46/15254},
	doi = {10.1523/JNEUROSCI.2135-15.2015},
	abstract = {The default mode network (DMN) has been traditionally assumed to hinder behavioral performance in externally focused, goal-directed paradigms and to provide no active contribution to human cognition. However, recent evidence suggests greater DMN activity in an array of tasks, especially those that involve self-referential and memory-based processing. Although data that robustly demonstrate a comprehensive functional role for DMN remains relatively scarce, the global workspace framework, which implicates the DMN in global information integration for conscious processing, can potentially provide an explanation for the broad range of higher-order paradigms that report DMN involvement. We used graph theoretical measures to assess the contribution of the DMN to global functional connectivity dynamics in 22 healthy volunteers during an fMRI-based n-back working-memory paradigm with parametric increases in difficulty. Our predominant finding is that brain modularity decreases with greater task demands, thus adapting a more global workspace configuration, in direct relation to increases in reaction times to correct responses. Flexible default mode regions dynamically switch community memberships and display significant changes in their nodal participation coefficient and strength, which may reflect the observed whole-brain changes in functional connectivity architecture. These findings have important implications for our understanding of healthy brain function, as they suggest a central role for the DMN in higher cognitive processing.
SIGNIFICANCE STATEMENT The default mode network (DMN) has been shown to increase its activity during the absence of external stimulation, and hence was historically assumed to disengage during goal-directed tasks. Recent evidence, however, implicates the DMN in self-referential and memory-based processing. We provide robust evidence for this network's active contribution to working memory by revealing dynamic reconfiguration in its interactions with other networks and offer an explanation within the global workspace theoretical framework. These promising findings may help redefine our understanding of the exact DMN role in human cognition.},
	language = {en},
	number = {46},
	urldate = {2019-11-28},
	journal = {J. Neurosci.},
	author = {Vatansever, Deniz and Menon, David K. and Manktelow, Anne E. and Sahakian, Barbara J. and Stamatakis, Emmanuel A.},
	month = nov,
	year = {2015},
	pmid = {26586814},
	keywords = {functional connectivity, default mode network, graph theory, alluvial diagram, flexibility, large-scale brain network},
	pages = {15254--15262},
	file = {Snapshot:/Users/tito/Zotero/storage/UAULIH2X/15254.html:text/html;Vatansever et al_2015_Default Mode Dynamics for Global Functional Integration.pdf:/Users/tito/Zotero/storage/GPFGRADX/Vatansever et al_2015_Default Mode Dynamics for Global Functional Integration.pdf:application/pdf},
}

@article{basti_analysing_2019,
	title = {Analysing linear multivariate pattern transformations in neuroimaging data},
	volume = {14},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6793861/},
	doi = {10.1371/journal.pone.0223660},
	abstract = {Most connectivity metrics in neuroimaging research reduce multivariate activity patterns in regions-of-interests (ROIs) to one dimension, which leads to a loss of information. Importantly, it prevents us from investigating the transformations between patterns in different ROIs. Here, we applied linear estimation theory in order to robustly estimate the linear transformations between multivariate fMRI patterns with a cross-validated ridge regression approach. We used three functional connectivity metrics that describe different features of these voxel-by-voxel mappings: goodness-of-fit, sparsity and pattern deformation. The goodness-of-fit describes the degree to which the patterns in an input region can be described as a linear transformation of patterns in an output region. The sparsity metric, which relies on a Monte Carlo procedure, was introduced in order to test whether the transformation mostly consists of one-to-one mappings between voxels in different regions. Furthermore, we defined a metric for pattern deformation, i.e. the degree to which the transformation rotates or rescales the input patterns. As a proof of concept, we applied these metrics to an event-related fMRI data set consisting of four subjects that has been used in previous studies. We focused on the transformations from early visual cortex (EVC) to inferior temporal cortex (ITC), fusiform face area (FFA) and parahippocampal place area (PPA). Our results suggest that the estimated linear mappings explain a significant amount of response variance in the three output ROIs. The transformation from EVC to ITC shows the highest goodness-of-fit, and those from EVC to FFA and PPA show the expected preference for faces and places as well as animate and inanimate objects, respectively. The pattern transformations are sparse, but sparsity is lower than would have been expected for one-to-one mappings, thus suggesting the presence of one-to-few voxel mappings. The mappings are also characterised by different levels of pattern deformations, thus indicating that the transformations differentially amplify or dampen certain dimensions of the input patterns. While our results are only based on a small number of subjects, they show that our pattern transformation metrics can describe novel aspects of multivariate functional connectivity in neuroimaging data.},
	number = {10},
	urldate = {2019-11-28},
	journal = {PLoS One},
	author = {Basti, Alessio and Mur, Marieke and Kriegeskorte, Nikolaus and Pizzella, Vittorio and Marzetti, Laura and Hauk, Olaf},
	month = oct,
	year = {2019},
	pmid = {31613918},
	pmcid = {PMC6793861},
	file = {Basti et al_2019_Analysing linear multivariate pattern transformations in neuroimaging data.pdf:/Users/tito/Zotero/storage/P742VLEW/Basti et al_2019_Analysing linear multivariate pattern transformations in neuroimaging data.pdf:application/pdf},
}

@article{reid_advancing_2019,
	title = {Advancing functional connectivity research from association to causation},
	volume = {22},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/s41593-019-0510-4},
	doi = {10.1038/s41593-019-0510-4},
	language = {en},
	number = {11},
	urldate = {2019-11-28},
	journal = {Nature Neuroscience},
	author = {Reid, Andrew T. and Headley, Drew B. and Mill, Ravi D. and Sanchez-Romero, Ruben and Uddin, Lucina Q. and Marinazzo, Daniele and Lurie, Daniel J. and Valdés-Sosa, Pedro A. and Hanson, Stephen José and Biswal, Bharat B. and Calhoun, Vince and Poldrack, Russell A. and Cole, Michael W.},
	month = nov,
	year = {2019},
	pages = {1751--1760},
	file = {Reid et al. - 2019 - Advancing functional connectivity research from as.pdf:/Users/tito/Zotero/storage/V7A4W7JE/Reid et al. - 2019 - Advancing functional connectivity research from as.pdf:application/pdf},
}

@article{shen_deep_2019,
	title = {Deep image reconstruction from human brain activity},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006633},
	doi = {10.1371/journal.pcbi.1006633},
	abstract = {The mental contents of perception and imagery are thought to be encoded in hierarchical representations in the brain, but previous attempts to visualize perceptual contents have failed to capitalize on multiple levels of the hierarchy, leaving it challenging to reconstruct internal imagery. Recent work showed that visual cortical activity measured by functional magnetic resonance imaging (fMRI) can be decoded (translated) into the hierarchical features of a pre-trained deep neural network (DNN) for the same input image, providing a way to make use of the information from hierarchical visual features. Here, we present a novel image reconstruction method, in which the pixel values of an image are optimized to make its DNN features similar to those decoded from human brain activity at multiple layers. We found that our method was able to reliably produce reconstructions that resembled the viewed natural images. A natural image prior introduced by a deep generator neural network effectively rendered semantically meaningful details to the reconstructions. Human judgment of the reconstructions supported the effectiveness of combining multiple DNN layers to enhance the visual quality of generated images. While our model was solely trained with natural images, it successfully generalized to artificial shapes, indicating that our model was not simply matching to exemplars. The same analysis applied to mental imagery demonstrated rudimentary reconstructions of the subjective content. Our results suggest that our method can effectively combine hierarchical neural representations to reconstruct perceptual and subjective images, providing a new window into the internal contents of the brain.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {PLOS Computational Biology},
	author = {Shen, Guohua and Horikawa, Tomoyasu and Majima, Kei and Kamitani, Yukiyasu},
	month = jan,
	year = {2019},
	keywords = {Functional magnetic resonance imaging, Algorithms, Vision, Neural networks, Sensory perception, Imaging techniques, Luminance, Optimization},
	pages = {e1006633},
	file = {Shen et al_2019_Deep image reconstruction from human brain activity.pdf:/Users/tito/Zotero/storage/GVIM7ZAG/Shen et al_2019_Deep image reconstruction from human brain activity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/98E3JGZH/article.html:text/html},
}

@article{horikawa_generic_2017,
	title = {Generic decoding of seen and imagined objects using hierarchical visual features},
	volume = {8},
	copyright = {2017 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms15037},
	doi = {10.1038/ncomms15037},
	abstract = {Machine learning algorithms can decode objects that people see or imagine from their brain activity. Here the authors present a predictive decoder combined with deep neural network representations that generalizes beyond the training set and correctly identifies novel objects that it has never been trained on.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Nature Communications},
	author = {Horikawa, Tomoyasu and Kamitani, Yukiyasu},
	month = may,
	year = {2017},
	pages = {1--15},
	file = {Horikawa_Kamitani_2017_Generic decoding of seen and imagined objects using hierarchical visual features.pdf:/Users/tito/Zotero/storage/Y82XHS8E/Horikawa_Kamitani_2017_Generic decoding of seen and imagined objects using hierarchical visual features.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/QFW3VFA8/ncomms15037.html:text/html},
}

@article{kamitani_decoding_2005,
	title = {Decoding the visual and subjective contents of the human brain},
	volume = {8},
	copyright = {2005 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn1444},
	doi = {10.1038/nn1444},
	abstract = {The potential for human neuroimaging to read out the detailed contents of a person's mental state has yet to be fully explored. We investigated whether the perception of edge orientation, a fundamental visual feature, can be decoded from human brain activity measured with functional magnetic resonance imaging (fMRI). Using statistical algorithms to classify brain states, we found that ensemble fMRI signals in early visual areas could reliably predict on individual trials which of eight stimulus orientations the subject was seeing. Moreover, when subjects had to attend to one of two overlapping orthogonal gratings, feature-based attention strongly biased ensemble activity toward the attended orientation. These results demonstrate that fMRI activity patterns in early visual areas, including primary visual cortex (V1), contain detailed orientation information that can reliably predict subjective perception. Our approach provides a framework for the readout of fine-tuned representations in the human brain and their subjective contents.},
	language = {en},
	number = {5},
	urldate = {2019-12-05},
	journal = {Nature Neuroscience},
	author = {Kamitani, Yukiyasu and Tong, Frank},
	month = may,
	year = {2005},
	pages = {679--685},
	file = {Full Text PDF:/Users/tito/Zotero/storage/GZC7888X/Kamitani and Tong - 2005 - Decoding the visual and subjective contents of the.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Q6H6N7L9/nn1444.html:text/html},
}

@article{norman-haignere_category-selective_2012,
	title = {Category-{Selective} {Background} {Connectivity} in {Ventral} {Visual} {Cortex}},
	volume = {22},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/22/2/391/338898},
	doi = {10.1093/cercor/bhr118},
	abstract = {Abstract.  Ventral visual cortex contains specialized regions for particular object categories, but little is known about how these regions interact during obje},
	language = {en},
	number = {2},
	urldate = {2019-12-05},
	journal = {Cereb Cortex},
	author = {Norman-Haignere, Samuel V. and McCarthy, Gregory and Chun, Marvin M. and Turk-Browne, Nicholas B.},
	month = feb,
	year = {2012},
	pages = {391--402},
	file = {Norman-Haignere et al_2012_Category-Selective Background Connectivity in Ventral Visual Cortex.pdf:/Users/tito/Zotero/storage/VATIT3MS/Norman-Haignere et al_2012_Category-Selective Background Connectivity in Ventral Visual Cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/7LUZIVB7/338898.html:text/html},
}

@article{burt_hierarchy_2018,
	title = {Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography},
	volume = {21},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/s41593-018-0195-0},
	doi = {10.1038/s41593-018-0195-0},
	language = {en},
	number = {9},
	urldate = {2019-12-17},
	journal = {Nature Neuroscience},
	author = {Burt, Joshua B. and Demirtaş, Murat and Eckner, William J. and Navejar, Natasha M. and Ji, Jie Lisa and Martin, William J. and Bernacchia, Alberto and Anticevic, Alan and Murray, John D.},
	month = sep,
	year = {2018},
	pages = {1251--1259},
	file = {Burt et al. - 2018 - Hierarchy of transcriptomic specialization across .pdf:/Users/tito/Zotero/storage/UT5MSWKC/Burt et al. - 2018 - Hierarchy of transcriptomic specialization across .pdf:application/pdf},
}

@article{marques_internal_2019,
	title = {Internal state dynamics shape brainwide activity and foraging behaviour},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1858-z},
	doi = {10.1038/s41586-019-1858-z},
	abstract = {During foraging for live prey, zebrafish larvae alternate between persistent exploitation and exploration behavioural states that correlate with distinct patterns of neuronal activation.},
	language = {en},
	urldate = {2019-12-19},
	journal = {Nature},
	author = {Marques, João C. and Li, Meng and Schaak, Diane and Robson, Drew N. and Li, Jennifer M.},
	month = dec,
	year = {2019},
	pages = {1--5},
	file = {Marques et al_2019_Internal state dynamics shape brainwide activity and foraging behaviour.pdf:/Users/tito/Zotero/storage/RLAK4A6H/Marques et al_2019_Internal state dynamics shape brainwide activity and foraging behaviour.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9CWEXIC8/s41586-019-1858-z.html:text/html},
}

@article{stewart_label-free_2016,
	title = {Label-{Free} {Supervision} of {Neural} {Networks} with {Physics} and {Domain} {Knowledge}},
	url = {http://arxiv.org/abs/1609.05566},
	abstract = {In many machine learning applications, labeled data is scarce and obtaining more labels is expensive. We introduce a new approach to supervising neural networks by specifying constraints that should hold over the output space, rather than direct examples of input-output pairs. These constraints are derived from prior domain knowledge, e.g., from known laws of physics. We demonstrate the effectiveness of this approach on real world and simulated computer vision tasks. We are able to train a convolutional neural network to detect and track objects without any labeled examples. Our approach can significantly reduce the need for labeled training data, but introduces new challenges for encoding prior knowledge into appropriate loss functions.},
	urldate = {2019-12-28},
	journal = {arXiv:1609.05566 [cs]},
	author = {Stewart, Russell and Ermon, Stefano},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.05566},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/P4A6RVR6/1609.html:text/html;Stewart_Ermon_2016_Label-Free Supervision of Neural Networks with Physics and Domain Knowledge.pdf:/Users/tito/Zotero/storage/UDDUW7JV/Stewart_Ermon_2016_Label-Free Supervision of Neural Networks with Physics and Domain Knowledge.pdf:application/pdf},
}

@article{shen_end--end_2019,
	title = {End-to-{End} {Deep} {Image} {Reconstruction} {From} {Human} {Brain} {Activity}},
	volume = {13},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2019.00021/full},
	doi = {10.3389/fncom.2019.00021},
	abstract = {Deep neural networks (DNNs) have recently been applied successfully to brain decoding and image reconstruction from functional magnetic resonance imaging (fMRI) activity. However, direct training of a DNN with fMRI data is often avoided because the size of available data is thought to be insufficient for training a complex network with numerous parameters. Instead, a pre-trained DNN usually serves as a proxy for hierarchical visual representations, and fMRI data are used to decode individual DNN features of a stimulus image using a simple linear model, which are then passed to a reconstruction module. Here, we directly trained a DNN model with fMRI data and the corresponding stimulus images to build an end-to-end reconstruction model. We accomplished this by training a generative adversarial network with an additional loss term that was defined in high-level feature space (feature loss) using up to 6,000 training data samples (natural images and fMRI responses). The above model was tested on independent datasets and directly reconstructed image using an fMRI pattern as the input. Reconstructions obtained from our proposed method resembled the test stimuli (natural and artificial images) and reconstruction accuracy increased as a function of training-data size. Ablation analyses indicated that the feature loss that we employed played a critical role in achieving accurate reconstruction. Our results show that the end-to-end model can learn a direct mapping between brain activity and perception.},
	language = {English},
	urldate = {2020-01-06},
	journal = {Front. Comput. Neurosci.},
	author = {Shen, Guohua and Dwivedi, Kshitij and Majima, Kei and Horikawa, Tomoyasu and Kamitani, Yukiyasu},
	year = {2019},
	keywords = {fMRI, deep learning, Vision, Brain decoding, Deep neural network (DNN), visual image reconstruction},
	file = {Shen et al_2019_End-to-End Deep Image Reconstruction From Human Brain Activity.pdf:/Users/tito/Zotero/storage/ICJZ44H2/Shen et al_2019_End-to-End Deep Image Reconstruction From Human Brain Activity.pdf:application/pdf},
}

@article{majima_decoding_2014,
	title = {Decoding visual object categories from temporal correlations of {ECoG} signals},
	volume = {90},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191301224X},
	doi = {10.1016/j.neuroimage.2013.12.020},
	abstract = {How visual object categories are represented in the brain is one of the key questions in neuroscience. Studies on low-level visual features have shown that relative timings or phases of neural activity between multiple brain locations encode information. However, whether such temporal patterns of neural activity are used in the representation of visual objects is unknown. Here, we examined whether and how visual object categories could be predicted (or decoded) from temporal patterns of electrocorticographic (ECoG) signals from the temporal cortex in five patients with epilepsy. We used temporal correlations between electrodes as input features, and compared the decoding performance with features defined by spectral power and phase from individual electrodes. While using power or phase alone, the decoding accuracy was significantly better than chance, correlations alone or those combined with power outperformed other features. Decoding performance with correlations was degraded by shuffling the order of trials of the same category in each electrode, indicating that the relative time series between electrodes in each trial is critical. Analysis using a sliding time window revealed that decoding performance with correlations began to rise earlier than that with power. This earlier increase in performance was replicated by a model using phase differences to encode categories. These results suggest that activity patterns arising from interactions between multiple neuronal units carry additional information on visual object categories.},
	language = {en},
	urldate = {2020-01-07},
	journal = {NeuroImage},
	author = {Majima, Kei and Matsuo, Takeshi and Kawasaki, Keisuke and Kawai, Kensuke and Saito, Nobuhito and Hasegawa, Isao and Kamitani, Yukiyasu},
	month = apr,
	year = {2014},
	keywords = {Decoding, ECoG, IT cortex, Object category, Temporal coding},
	pages = {74--83},
	file = {Majima et al_2014_Decoding visual object categories from temporal correlations of ECoG signals.pdf:/Users/tito/Zotero/storage/HE7FGCEE/Majima et al_2014_Decoding visual object categories from temporal correlations of ECoG signals.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/V6YTD4XE/S105381191301224X.html:text/html},
}

@article{gallego_long-term_2020,
	title = {Long-term stability of cortical population dynamics underlying consistent behavior},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0555-4},
	doi = {10.1038/s41593-019-0555-4},
	abstract = {Gallego, Perich et al. report that latent dynamics in the neural manifold across three cortical areas are stable throughout years of consistent behavior. The authors posit that these dynamics are fundamental building blocks of learned behavior.},
	language = {en},
	urldate = {2020-01-08},
	journal = {Nat Neurosci},
	author = {Gallego, Juan A. and Perich, Matthew G. and Chowdhury, Raeed H. and Solla, Sara A. and Miller, Lee E.},
	month = jan,
	year = {2020},
	pages = {1--11},
	file = {Gallego et al_2020_Long-term stability of cortical population dynamics underlying consistent.pdf:/Users/tito/Zotero/storage/X2KLH7DY/Gallego et al_2020_Long-term stability of cortical population dynamics underlying consistent.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SBEJWPCD/s41593-019-0555-4.html:text/html},
}

@article{hasson_hierarchy_2008,
	title = {A {Hierarchy} of {Temporal} {Receptive} {Windows} in {Human} {Cortex}},
	volume = {28},
	copyright = {Copyright © 2008 Society for Neuroscience 0270-6474/08/282539-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/28/10/2539},
	doi = {10.1523/JNEUROSCI.5487-07.2008},
	abstract = {Real-world events unfold at different time scales and, therefore, cognitive and neuronal processes must likewise occur at different time scales. We present a novel procedure that identifies brain regions responsive to sensory information accumulated over different time scales. We measured functional magnetic resonance imaging activity while observers viewed silent films presented forward, backward, or piecewise-scrambled in time. Early visual areas (e.g., primary visual cortex and the motion-sensitive area MT+) exhibited high response reliability regardless of disruptions in temporal structure. In contrast, the reliability of responses in several higher brain areas, including the superior temporal sulcus (STS), precuneus, posterior lateral sulcus (LS), temporal parietal junction (TPJ), and frontal eye field (FEF), was affected by information accumulated over longer time scales. These regions showed highly reproducible responses for repeated forward, but not for backward or piecewise-scrambled presentations. Moreover, these regions exhibited marked differences in temporal characteristics, with LS, TPJ, and FEF responses depending on information accumulated over longer durations (∼36 s) than STS and precuneus (∼12 s). We conclude that, similar to the known cortical hierarchy of spatial receptive fields, there is a hierarchy of progressively longer temporal receptive windows in the human brain.},
	language = {en},
	number = {10},
	urldate = {2020-01-10},
	journal = {J. Neurosci.},
	author = {Hasson, Uri and Yang, Eunice and Vallines, Ignacio and Heeger, David J. and Rubin, Nava},
	month = mar,
	year = {2008},
	pmid = {18322098},
	keywords = {fMRI, cortex, functional organization, receptive fields, temporal coding, time},
	pages = {2539--2550},
	file = {Hasson et al_2008_A Hierarchy of Temporal Receptive Windows in Human Cortex.pdf:/Users/tito/Zotero/storage/P548HYG4/Hasson et al_2008_A Hierarchy of Temporal Receptive Windows in Human Cortex.pdf:application/pdf},
}

@article{honey_slow_2012,
	title = {Slow {Cortical} {Dynamics} and the {Accumulation} of {Information} over {Long} {Timescales}},
	volume = {76},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627312007179},
	doi = {10.1016/j.neuron.2012.08.011},
	abstract = {Making sense of the world requires us to process information over multiple timescales. We sought to identify brain regions that accumulate information over short and long timescales and to characterize the distinguishing features of their dynamics. We recorded electrocorticographic (ECoG) signals from individuals watching intact and scrambled movies. Within sensory regions, fluctuations of high-frequency (64–200 Hz) power reliably tracked instantaneous low-level properties of the intact and scrambled movies. Within higher order regions, the power fluctuations were more reliable for the intact movie than the scrambled movie, indicating that these regions accumulate information over relatively long time periods (several seconds or longer). Slow ({\textless}0.1 Hz) fluctuations of high-frequency power with time courses locked to the movies were observed throughout the cortex. Slow fluctuations were relatively larger in regions that accumulated information over longer time periods, suggesting a connection between slow neuronal population dynamics and temporally extended information processing.},
	language = {en},
	number = {2},
	urldate = {2020-01-10},
	journal = {Neuron},
	author = {Honey, Christopher J. and Thesen, Thomas and Donner, Tobias H. and Silbert, Lauren J. and Carlson, Chad E. and Devinsky, Orrin and Doyle, Werner K. and Rubin, Nava and Heeger, David J. and Hasson, Uri},
	month = oct,
	year = {2012},
	pages = {423--434},
	file = {Honey et al_2012_Slow Cortical Dynamics and the Accumulation of Information over Long Timescales.pdf:/Users/tito/Zotero/storage/UMQF3J6R/Honey et al_2012_Slow Cortical Dynamics and the Accumulation of Information over Long Timescales.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/RECHG4QT/S0896627312007179.html:text/html},
}

@article{baum_development_2020,
	title = {Development of structure–function coupling in human brain networks during youth},
	volume = {117},
	copyright = {Copyright © 2020 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/117/1/771},
	doi = {10.1073/pnas.1912034117},
	abstract = {The protracted development of structural and functional brain connectivity within distributed association networks coincides with improvements in higher-order cognitive processes such as executive function. However, it remains unclear how white-matter architecture develops during youth to directly support coordinated neural activity. Here, we characterize the development of structure–function coupling using diffusion-weighted imaging and n-back functional MRI data in a sample of 727 individuals (ages 8 to 23 y). We found that spatial variability in structure–function coupling aligned with cortical hierarchies of functional specialization and evolutionary expansion. Furthermore, hierarchy-dependent age effects on structure–function coupling localized to transmodal cortex in both cross-sectional data and a subset of participants with longitudinal data (n = 294). Moreover, structure–function coupling in rostrolateral prefrontal cortex was associated with executive performance and partially mediated age-related improvements in executive function. Together, these findings delineate a critical dimension of adolescent brain development, whereby the coupling between structural and functional connectivity remodels to support functional specialization and cognition.},
	language = {en},
	number = {1},
	urldate = {2020-01-11},
	journal = {PNAS},
	author = {Baum, Graham L. and Cui, Zaixu and Roalf, David R. and Ciric, Rastko and Betzel, Richard F. and Larsen, Bart and Cieslak, Matthew and Cook, Philip A. and Xia, Cedric H. and Moore, Tyler M. and Ruparel, Kosha and Oathes, Desmond J. and Alexander-Bloch, Aaron F. and Shinohara, Russell T. and Raznahan, Armin and Gur, Raquel E. and Gur, Ruben C. and Bassett, Danielle S. and Satterthwaite, Theodore D.},
	month = jan,
	year = {2020},
	pmid = {31874926},
	keywords = {MRI, connectome, cortical organization, structure–function, brain development},
	pages = {771--778},
	file = {Baum et al_2020_Development of structure–function coupling in human brain networks during youth.pdf:/Users/tito/Zotero/storage/7SITXV7B/Baum et al_2020_Development of structure–function coupling in human brain networks during youth.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GKDPC2AZ/771.html:text/html},
}

@article{stiso_white_2019,
	title = {White {Matter} {Network} {Architecture} {Guides} {Direct} {Electrical} {Stimulation} through {Optimal} {State} {Transitions}},
	volume = {28},
	issn = {2211-1247},
	url = {http://www.sciencedirect.com/science/article/pii/S2211124719310411},
	doi = {10.1016/j.celrep.2019.08.008},
	abstract = {Optimizing direct electrical stimulation for the treatment of neurological disease remains difficult due to an incomplete understanding of its physical propagation through brain tissue. Here, we use network control theory to predict how stimulation spreads through white matter to influence spatially distributed dynamics. We test the theory’s predictions using a unique dataset comprising diffusion weighted imaging and electrocorticography in epilepsy patients undergoing grid stimulation. We find statistically significant shared variance between the predicted activity state transitions and the observed activity state transitions. We then use an optimal control framework to posit testable hypotheses regarding which brain states and structural properties will efficiently improve memory encoding when stimulated. Our work quantifies the role that white matter architecture plays in guiding the dynamics of direct electrical stimulation and offers empirical support for the utility of network control theory in explaining the brain’s response to stimulation.},
	language = {en},
	number = {10},
	urldate = {2020-01-14},
	journal = {Cell Reports},
	author = {Stiso, Jennifer and Khambhati, Ankit N. and Menara, Tommaso and Kahn, Ari E. and Stein, Joel M. and Das, Sandihitsu R. and Gorniak, Richard and Tracy, Joseph and Litt, Brian and Davis, Kathryn A. and Pasqualetti, Fabio and Lucas, Timothy H. and Bassett, Danielle S.},
	month = sep,
	year = {2019},
	keywords = {brain stimulation, brain network, network control theory},
	pages = {2554--2566.e7},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/PIFUTLSI/Stiso et al. - 2019 - White Matter Network Architecture Guides Direct El.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/AIF47CLC/S2211124719310411.html:text/html},
}

@article{mnih_human-level_2015-1,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	abstract = {An artificial agent is developed that learns to play\&nbsp;a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a\&nbsp;performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
	language = {en},
	number = {7540},
	urldate = {2020-01-17},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	month = feb,
	year = {2015},
	pages = {529--533},
	file = {Full Text PDF:/Users/tito/Zotero/storage/USJZ3FTC/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AEVKX8WA/nature14236.html:text/html},
}

@article{silver_mastering_2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	abstract = {Starting from zero knowledge and without human data, AlphaGo Zero was able to teach itself to play Go and to develop novel strategies that provide new insights into the oldest of games.},
	language = {en},
	number = {7676},
	urldate = {2020-01-17},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Driessche, George van den and Graepel, Thore and Hassabis, Demis},
	month = oct,
	year = {2017},
	pages = {354--359},
	file = {Full Text PDF:/Users/tito/Zotero/storage/EU3AQCIT/Silver et al. - 2017 - Mastering the game of Go without human knowledge.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FQLJRS3Z/nature24270.html:text/html},
}

@article{poldrack_establishment_2019,
	title = {Establishment of {Best} {Practices} for {Evidence} for {Prediction}: {A} {Review}},
	shorttitle = {Establishment of {Best} {Practices} for {Evidence} for {Prediction}},
	url = {https://jamanetwork.com/journals/jamapsychiatry/fullarticle/2756204},
	doi = {10.1001/jamapsychiatry.2019.3671},
	abstract = {{\textless}h3{\textgreater}Importance{\textless}/h3{\textgreater}{\textless}p{\textgreater}Great interest exists in identifying methods to predict neuropsychiatric disease states and treatment outcomes from high-dimensional data, including neuroimaging and genomics data. The goal of this review is to highlight several potential problems that can arise in studies that aim to establish prediction.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Observations{\textless}/h3{\textgreater}{\textless}p{\textgreater}A number of neuroimaging studies have claimed to establish prediction while establishing only correlation, which is an inappropriate use of the statistical meaning of prediction. Statistical associations do not necessarily imply the ability to make predictions in a generalized manner; establishing evidence for prediction thus requires testing of the model on data separate from those used to estimate the model’s parameters. This article discusses various measures of predictive performance and the limitations of some commonly used measures, with a focus on the importance of using multiple measures when assessing performance. For classification, the area under the receiver operating characteristic curve is an appropriate measure; for regression analysis, correlation should be avoided, and median absolute error is preferred.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Conclusions and Relevance{\textless}/h3{\textgreater}{\textless}p{\textgreater}To ensure accurate estimates of predictive validity, the recommended best practices for predictive modeling include the following: (1) in-sample model fit indices should not be reported as evidence for predictive accuracy, (2) the cross-validation procedure should encompass all operations applied to the data, (3) prediction analyses should not be performed with samples smaller than several hundred observations, (4) multiple measures of prediction accuracy should be examined and reported, (5) the coefficient of determination should be computed using the sums of squares formulation and not the correlation coefficient, and (6) k-fold cross-validation rather than leave-one-out cross-validation should be used.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-01-17},
	journal = {JAMA Psychiatry},
	author = {Poldrack, Russell A. and Huckins, Grace and Varoquaux, Gael},
	month = nov,
	year = {2019},
	file = {Full Text PDF:/Users/tito/Zotero/storage/HIVUDBY7/Poldrack et al. - 2019 - Establishment of Best Practices for Evidence for P.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3WRUIBZ2/2756204.html:text/html},
}

@article{kar_transcranial_2019,
	title = {Transcranial alternating current stimulation attenuates {BOLD} adaptation and increases functional connectivity},
	volume = {123},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00376.2019},
	doi = {10.1152/jn.00376.2019},
	abstract = {Transcranial alternating current stimulation (tACS) is used as a noninvasive tool for cognitive enhancement and clinical applications. The physiological effects of tACS, however, are complex and poorly understood. Most studies of tACS focus on its ability to entrain brain oscillations, but our behavioral results in humans and extracellular recordings in nonhuman primates support the view that tACS at 10 Hz also affects brain function by reducing sensory adaptation. Our primary goal in the present study is to test this hypothesis using blood oxygen level-dependent (BOLD) imaging in human subjects. Using concurrent functional magnetic resonance imaging (fMRI) and tACS, and a motion adaptation paradigm developed to quantify BOLD adaptation, we show that tACS significantly attenuates adaptation in the human motion area (hMT+). In addition, an exploratory analysis shows that tACS increases functional connectivity of the stimulated hMT+ with the rest of the brain and the dorsal attention network in particular. Based on field estimates from individualized head models, we relate these changes to the strength of tACS-induced electric fields. Specifically, we report that functional connectivity (between hMT+ and any other region of interest) increases in proportion to the field strength in the region of interest. These findings add support for the claim that weak 10-Hz currents applied to the scalp modulate both local and global measures of brain activity.NEW \& NOTEWORTHY Concurrent transcranial alternating current stimulation (tACS) and functional MRI show that tACS affects the human brain by attenuating adaptation and increasing functional connectivity in a dose-dependent manner. This work is important for our basic understanding of what tACS does, but also for therapeutic applications, which need insight into the full range of ways in which tACS affects the brain.},
	number = {1},
	urldate = {2020-01-19},
	journal = {Journal of Neurophysiology},
	author = {Kar, Kohitij and Ito, Takuya and Cole, Michael W. and Krekelberg, Bart},
	month = dec,
	year = {2019},
	pages = {428--438},
	file = {Full Text PDF:/Users/tito/Zotero/storage/JGZFTDZE/Kar et al. - 2019 - Transcranial alternating current stimulation atten.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/I428DGMS/jn.00376.html:text/html},
}

@article{eichenbaum_dissociable_2020,
	title = {Dissociable {Neural} {Systems} {Support} the {Learning} and {Transfer} of {Hierarchical} {Control} {Structure}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.01.16.909978v1},
	doi = {10.1101/2020.01.16.909978},
	abstract = {{\textless}p{\textgreater}Humans can draw insight from previous experiences in order to quickly adapt to novel environments that share a common underlying structure. Here we combine functional imaging and computational modeling to identify the neural systems that support the discovery and transfer of hierarchical task structure. Human subjects completed multiple blocks of a reinforcement learning task that contained a global hierarchical structure governing stimulus-response action mapping. First, behavioral and computational evidence showed that humans successfully discover and transfer the hierarchical rule structure embedded within the task. Next, analysis of fMRI BOLD data revealed activity across a frontal-parietal network that was specifically associated with the discovery of this embedded structure. Finally, activity throughout a cingulo-opercular network and in caudal frontal cortex supported the transfer and implementation of this discovered structure. Together, these results reveal a division of labor in which dissociable neural systems support the learning and transfer of abstract control structures.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-01-20},
	journal = {bioRxiv},
	author = {Eichenbaum, Adam and Scimeca, Jason M. and D’Esposito, Mark},
	month = jan,
	year = {2020},
	pages = {2020.01.16.909978},
	file = {Full Text PDF:/Users/tito/Zotero/storage/9BMEMP4R/Eichenbaum et al. - 2020 - Dissociable Neural Systems Support the Learning an.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4AG8IJS2/2020.01.16.html:text/html},
}

@article{pollock_engineering_2019,
	title = {Engineering recurrent neural networks from task-relevant manifolds and dynamics},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2019.12.19.883207v1},
	doi = {10.1101/2019.12.19.883207},
	abstract = {{\textless}p{\textgreater}Many cognitive processes involve transformations of distributed representations in neural populations, creating a need for population-level models. Recurrent neural network models fulfill this need, but there are many open questions about how their connectivity gives rise to dynamics that solve a task. Here, we present a method for finding the connectivity of networks for which the dynamics are specified to solve a task in an interpretable way. We apply our method to a working memory task by synthesizing a network that implements a drift-diffusion process over a ring-shaped manifold. We also use our method to demonstrate how inputs can be used to control network dynamics for cognitive flexibility and explore the relationship between representation geometry and network capacity. Our work fits within the broader context of understanding neural computations as dynamics over relatively low-dimensional manifolds formed by correlated patterns of neurons.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-01-20},
	journal = {bioRxiv},
	author = {Pollock, Eli and Jazayeri, Mehrdad},
	month = dec,
	year = {2019},
	pages = {2019.12.19.883207},
	file = {Full Text PDF:/Users/tito/Zotero/storage/SRVJCUPZ/Pollock and Jazayeri - 2019 - Engineering recurrent neural networks from task-re.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4LRNHA2R/2019.12.19.html:text/html},
}

@article{cocchi_hierarchy_2016,
	title = {A hierarchy of timescales explains distinct effects of local inhibition of primary visual cortex and frontal eye fields},
	volume = {5},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.15252},
	doi = {10.7554/eLife.15252},
	abstract = {Within the primate visual system, areas at lower levels of the cortical hierarchy process basic visual features, whereas those at higher levels, such as the frontal eye fields (FEF), are thought to modulate sensory processes via feedback connections. Despite these functional exchanges during perception, there is little shared activity between early and late visual regions at rest. How interactions emerge between regions encompassing distinct levels of the visual hierarchy remains unknown. Here we combined neuroimaging, non-invasive cortical stimulation and computational modelling to characterize changes in functional interactions across widespread neural networks before and after local inhibition of primary visual cortex or FEF. We found that stimulation of early visual cortex selectively increased feedforward interactions with FEF and extrastriate visual areas, whereas identical stimulation of the FEF decreased feedback interactions with early visual areas. Computational modelling suggests that these opposing effects reflect a fast-slow timescale hierarchy from sensory to association areas.},
	urldate = {2020-01-21},
	journal = {eLife},
	author = {Cocchi, Luca and Sale, Martin V and L Gollo, Leonardo and Bell, Peter T and Nguyen, Vinh T and Zalesky, Andrew and Breakspear, Michael and Mattingley, Jason B},
	editor = {Culham, Jody C},
	month = sep,
	year = {2016},
	keywords = {connectivity, cortical hierarchy, functional magnetic resonance imaging (fMRI), modelling, temporal hierarchy, transcranial magnetic stimulation (TMS)},
	pages = {e15252},
}

@article{gonzalez-castillo_imaging_2019,
	title = {Imaging the spontaneous flow of thought: {Distinct} periods of cognition contribute to dynamic functional connectivity during rest},
	volume = {202},
	issn = {1053-8119},
	shorttitle = {Imaging the spontaneous flow of thought},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919307207},
	doi = {10.1016/j.neuroimage.2019.116129},
	abstract = {Brain functional connectivity (FC) changes have been measured across seconds using fMRI. This is true for both rest and task scenarios. Moreover, it is well accepted that task engagement alters FC, and that dynamic estimates of FC during and before task events can help predict their nature and performance. Yet, when it comes to dynamic FC (dFC) during rest, there is no consensus about its origin or significance. Some argue that rest dFC reflects fluctuations in on-going cognition, or is a manifestation of intrinsic brain maintenance mechanisms, which could have predictive clinical value. Conversely, others have concluded that rest dFC is mostly the result of sampling variability, head motion or fluctuating sleep states. Here, we present novel analyses suggesting that rest dFC is influenced by short periods of spontaneous cognitive-task-like processes, and that the cognitive nature of such mental processes can be inferred blindly from the data. As such, several different behaviorally relevant whole-brain FC configurations may occur during a single rest scan even when subjects were continuously awake and displayed minimal motion. In addition, using low dimensional embeddings as visualization aids, we show how FC states—commonly used to summarize and interpret resting dFC—can accurately and robustly reveal periods of externally imposed tasks; however, they may be less effective in capturing periods of distinct cognition during rest.},
	language = {en},
	urldate = {2020-01-23},
	journal = {NeuroImage},
	author = {Gonzalez-Castillo, Javier and Caballero-Gaudes, César and Topolski, Natasha and Handwerker, Daniel A. and Pereira, Francisco and Bandettini, Peter A.},
	month = nov,
	year = {2019},
	pages = {116129},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/LFYSYCM4/Gonzalez-Castillo et al. - 2019 - Imaging the spontaneous flow of thought Distinct .pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/5CZM4BAV/S1053811919307207.html:text/html},
}

@misc{noauthor_ohbm_nodate,
	title = {{OHBM} - {Rome} 2019 - {View} {Posters}},
	url = {https://ww5.aievolution.com/hbm1901/index.cfm?do=abs.pubSearchAbstracts},
	urldate = {2020-01-24},
	file = {OHBM - Rome 2019 - View Posters:/Users/tito/Zotero/storage/KPQ5GTXU/index.html:text/html},
}

@inproceedings{lurie_network_2019,
	title = {Network connectivity explains regional differences in intrinsic activity dynamics},
	url = {https://ww5.aievolution.com/hbm1901/index.cfm?do=abs.viewAbs&abs=4488},
	author = {Lurie, Daniel and D'Esposito, Mark},
	month = jun,
	year = {2019},
}

@article{waskom_decision_2018,
	title = {Decision {Making} through {Integration} of {Sensory} {Evidence} at {Prolonged} {Timescales}},
	volume = {28},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982218313502},
	doi = {10.1016/j.cub.2018.10.021},
	abstract = {When multiple pieces of information bear on a decision, the best approach is to combine the evidence provided by each one. Evidence integration models formalize the computations underlying this process [1, 2, 3], explain human perceptual discrimination behavior [4, 5, 6, 7, 8, 9], and correspond to neuronal responses elicited by discrimination tasks [10, 11, 12, 13, 14]. These findings suggest that evidence integration is key to understanding the neural basis of decision making [15, 16, 17, 18]. But while evidence integration has most often been studied with simple tasks that limit deliberation to relatively brief periods, many natural decisions unfold over much longer durations. Neural network models imply acute limitations on the timescale of evidence integration [19, 20, 21, 22, 23], and it is currently unknown whether existing computational insights can generalize beyond rapid judgments. Here, we introduce a new psychophysical task and report model-based analyses of human behavior that demonstrate evidence integration at long timescales. Our task requires probabilistic inference using brief samples of visual evidence that are separated in time by long and unpredictable gaps. We show through several quantitative assays how decision making can approximate a normative integration process that extends over tens of seconds without accruing significant memory leak or noise. These results support the generalization of evidence integration models to a broader class of behaviors while posing new challenges for models of how these computations are implemented in biological networks.},
	language = {en},
	number = {23},
	urldate = {2020-01-27},
	journal = {Current Biology},
	author = {Waskom, Michael L. and Kiani, Roozbeh},
	month = dec,
	year = {2018},
	keywords = {decision making, computational modeling, working memory, integration time constant, probabilistic inference, psychophysics, sequential sampling},
	pages = {3850--3856.e9},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/94LZRBPX/S0960982218313502.html:text/html;Waskom_Kiani_2018_Decision Making through Integration of Sensory Evidence at Prolonged Timescales.pdf:/Users/tito/Zotero/storage/CXFP9ZY6/Waskom_Kiani_2018_Decision Making through Integration of Sensory Evidence at Prolonged Timescales.pdf:application/pdf},
}

@article{glasser_using_2018,
	title = {Using temporal {ICA} to selectively remove global noise while preserving global signal in functional {MRI} data},
	volume = {181},
	journal = {NeuroImage},
	author = {Glasser, Matthew F. and Coalson, Timothy S. and Bijsterbosch, Janine D. and Harrison, Samuel J. and Harms, Michael P. and Anticevic, Alan and Van Essen, David C. and Smith, Stephen M.},
	year = {2018},
	pages = {692--717},
	file = {Full Text:/Users/tito/Zotero/storage/G42BG9PZ/PMC6237431.html:text/html;Snapshot:/Users/tito/Zotero/storage/GBMBBWSQ/S1053811918303963.html:text/html},
}

@article{glasser_mapping_2011,
	title = {Mapping human cortical areas in vivo based on myelin content as revealed by {T1}-and {T2}-weighted {MRI}},
	volume = {31},
	number = {32},
	journal = {Journal of Neuroscience},
	author = {Glasser, Matthew F. and Van Essen, David C.},
	year = {2011},
	pages = {11597--11616},
	file = {Glasser_Van Essen_2011_Mapping human cortical areas in vivo based on myelin content as revealed by.pdf:/Users/tito/Zotero/storage/IY6EWZJK/Glasser_Van Essen_2011_Mapping human cortical areas in vivo based on myelin content as revealed by.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DVR5RQLE/11597.html:text/html},
}

@article{felleman_distributed_1991,
	title = {Distributed {Hierarchical} {Processing} in the {Primate} {Cerebral} {Cortex}},
	volume = {1},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/1/1/1/408896},
	doi = {10.1093/cercor/1.1.1-a},
	abstract = {Abstract.  In recent years, many new cortical areas have been identified in the macaque monkey. The number of iden tified connections hetween areas has increase},
	language = {en},
	number = {1},
	urldate = {2020-01-30},
	journal = {Cereb Cortex},
	author = {Felleman, Daniel J. and Van Essen, David C.},
	month = jan,
	year = {1991},
	pages = {1--47},
	file = {Felleman_Van Essen_1991_Distributed Hierarchical Processing in the Primate Cerebral Cortex.pdf:/Users/tito/Zotero/storage/XD63KQRL/Felleman_Van Essen_1991_Distributed Hierarchical Processing in the Primate Cerebral Cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MAV7SCYV/408896.html:text/html},
}

@article{simony_analysis_2019,
	title = {Analysis of stimulus-induced brain dynamics during naturalistic paradigms},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919310523},
	doi = {10.1016/j.neuroimage.2019.116461},
	abstract = {Naturalistic stimuli offer promising avenues for investigating brain function across the rich, realistic spectrum of human experiences. Functional magnetic resonance imaging (fMRI) studies of brain activity during naturalistic paradigms have provided new information about dynamic neural processing in ecologically valid contexts. Yet, the complex, uncontrolled nature of such stimuli -- and the resulting mixture of neuronal and physiological responses embedded within the fMRI signals -- present challenges with respect to data analysis and interpretation. In this brief commentary, we discuss methods and open challenges in naturalistic fMRI investigations, with a focus on extracting and interpreting stimulus-induced fMRI signals.},
	language = {en},
	urldate = {2020-01-31},
	journal = {NeuroImage},
	author = {Simony, Erez and Chang, Catie},
	month = dec,
	year = {2019},
	pages = {116461},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/QQMEHLKL/S1053811919310523.html:text/html;Simony_Chang_2019_Analysis of stimulus-induced brain dynamics during naturalistic paradigms.pdf:/Users/tito/Zotero/storage/6JEJDS4R/Simony_Chang_2019_Analysis of stimulus-induced brain dynamics during naturalistic paradigms.pdf:application/pdf},
}

@article{murphy_impact_2009,
	title = {The impact of global signal regression on resting state correlations: are anti-correlated networks introduced?},
	volume = {44},
	shorttitle = {The impact of global signal regression on resting state correlations},
	number = {3},
	journal = {Neuroimage},
	author = {Murphy, Kevin and Birn, Rasmus M. and Handwerker, Daniel A. and Jones, Tyler B. and Bandettini, Peter A.},
	year = {2009},
	pages = {893--905},
	file = {Full Text:/Users/tito/Zotero/storage/9TMA46YI/S1053811908010264.html:text/html},
}

@article{preller_changes_2018,
	title = {Changes in global and thalamic brain connectivity in {LSD}-induced altered states of consciousness are attributable to the 5-{HT2A} receptor},
	volume = {7},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.35082},
	doi = {10.7554/eLife.35082},
	abstract = {Background:Lysergic acid diethylamide (LSD) has agonist activity at various serotonin (5-HT) and dopamine receptors. Despite the therapeutic and scientific interest in LSD, specific receptor contributions to its neurobiological effects remain unknown. Methods: We therefore conducted a double-blind, randomized, counterbalanced, cross-over study (ClinicalTrials.gov, NCT02451072) during which 24 healthy human participants received either (i) placebo+placebo, (ii) placebo+LSD (100 µg po), or (iii) Ketanserin, a selective 5-HT2A receptor antagonist,+LSD. We quantified resting-state functional connectivity via a data-driven global brain connectivity method and compared it to cortical gene expression maps. Findings: LSD reduced associative, but concurrently increased sensory-somatomotor brain-wide and thalamic connectivity. Ketanserin fully blocked the subjective and neural LSD effects. Whole-brain spatial patterns of LSD effects matched 5-HT2A receptor cortical gene expression in humans. Conclusion: Together, these results strongly implicate the 5-HT2A receptor in LSD’s neuropharmacology. This study therefore pinpoints the critical role of 5-HT2A in LSD’s mechanism, which informs its neurobiology and guides rational development of psychedelic-based therapeutics. Funding: Swiss National Science Foundation (SNSF, P2ZHP1\_161626, KHP), the Swiss Neuromatrix Foundation (2015 – 0103, FXV), the Usona Institute (2015 – 2056, FXV), the NIH (R01MH112746, JDM; DP5OD012109, AA; R01MH108590, AA), the NIAA ( P50AA012870-16, AA \& JHK), the NARSAD Independent Investigator Grant (AA), the Yale CTSA grant (UL1TR000142 Pilot Award, AA), and the Slovenian Research Agency (ARRS J7-6829 \& ARRS J7-8275, GR).},
	urldate = {2020-02-08},
	journal = {eLife},
	author = {Preller, Katrin H and Burt, Joshua B and Ji, Jie Lisa and Schleifer, Charles H and Adkinson, Brendan D and Stämpfli, Philipp and Seifritz, Erich and Repovs, Grega and Krystal, John H and Murray, John D and Vollenweider, Franz X and Anticevic, Alan},
	editor = {Hunt, Laurence Tudor and Behrens, Timothy E},
	month = oct,
	year = {2018},
	keywords = {fMRI, functional connectivity, brain, LSD, psychedelics, serotonin},
	pages = {e35082},
	file = {Preller et al_2018_Changes in global and thalamic brain connectivity in LSD-induced altered states.pdf:/Users/tito/Zotero/storage/GSWW7X2Z/Preller et al_2018_Changes in global and thalamic brain connectivity in LSD-induced altered states.pdf:application/pdf},
}

@article{bolt_correspondence_2017,
	title = {Correspondence between evoked and intrinsic functional brain network configurations},
	volume = {38},
	copyright = {© 2017 Wiley Periodicals, Inc.},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23500},
	doi = {10.1002/hbm.23500},
	abstract = {Much of the literature exploring differences between intrinsic and task-evoked brain architectures has examined changes in functional connectivity patterns between specific brain regions. While informative, this approach overlooks important overall functional changes in hub organization and network topology that may provide insights about differences in integration between intrinsic and task-evoked states. Examination of changes in overall network organization, such as a change in the concentration of hub nodes or a quantitative change in network organization, is important for understanding the underlying processes that differ between intrinsic and task-evoked brain architectures. The present study used graph-theoretical techniques applied to publicly available neuroimaging data collected from a large sample of individuals (N = 202), and a within-subject design where resting-state and several task scans were collected from each participant as part of the Human Connectome Project. We demonstrate that differences between intrinsic and task-evoked brain networks are characterized by a task-general shift in high-connectivity hubs from primarily sensorimotor/auditory processing areas during the intrinsic state to executive control/salience network areas during task performance. In addition, we demonstrate that differences between intrinsic and task-evoked architectures are associated with changes in overall network organization, such as increases in network clustering, global efficiency and integration between modules. These findings offer a new perspective on the principles guiding functional brain organization by identifying unique and divergent properties of overall network organization between the resting-state and task performance. Hum Brain Mapp 38:1992–2007, 2017. © 2017 Wiley Periodicals, Inc.},
	language = {en},
	number = {4},
	urldate = {2020-02-10},
	journal = {Human Brain Mapping},
	author = {Bolt, Taylor and Nomi, Jason S. and Rubinov, Mikail and Uddin, Lucina Q.},
	year = {2017},
	keywords = {graph theory, Human Connectome Project, salience network, intrinsic connectivity, resting state fMRI},
	pages = {1992--2007},
	file = {Bolt et al_2017_Correspondence between evoked and intrinsic functional brain network.pdf:/Users/tito/Zotero/storage/RT2DPFKT/Bolt et al_2017_Correspondence between evoked and intrinsic functional brain network.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/U72HS3E4/hbm.html:text/html},
}

@article{he_deep_2020,
	title = {Deep neural networks and kernel regression achieve comparable accuracies for functional connectivity prediction of behavior and demographics},
	volume = {206},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919308675},
	doi = {10.1016/j.neuroimage.2019.116276},
	abstract = {There is significant interest in the development and application of deep neural networks (DNNs) to neuroimaging data. A growing literature suggests that DNNs outperform their classical counterparts in a variety of neuroimaging applications, yet there are few direct comparisons of relative utility. Here, we compared the performance of three DNN architectures and a classical machine learning algorithm (kernel regression) in predicting individual phenotypes from whole-brain resting-state functional connectivity (RSFC) patterns. One of the DNNs was a generic fully-connected feedforward neural network, while the other two DNNs were recently published approaches specifically designed to exploit the structure of connectome data. By using a combined sample of almost 10,000 participants from the Human Connectome Project (HCP) and UK Biobank, we showed that the three DNNs and kernel regression achieved similar performance across a wide range of behavioral and demographic measures. Furthermore, the generic feedforward neural network exhibited similar performance to the two state-of-the-art connectome-specific DNNs. When predicting fluid intelligence in the UK Biobank, performance of all algorithms dramatically improved when sample size increased from 100 to 1000 subjects. Improvement was smaller, but still significant, when sample size increased from 1000 to 5000 subjects. Importantly, kernel regression was competitive across all sample sizes. Overall, our study suggests that kernel regression is as effective as DNNs for RSFC-based behavioral prediction, while incurring significantly lower computational costs. Therefore, kernel regression might serve as a useful baseline algorithm for future studies.},
	language = {en},
	urldate = {2020-02-10},
	journal = {NeuroImage},
	author = {He, Tong and Kong, Ru and Holmes, Avram J. and Nguyen, Minh and Sabuncu, Mert R. and Eickhoff, Simon B. and Bzdok, Danilo and Feng, Jiashi and Yeo, B. T. Thomas},
	month = feb,
	year = {2020},
	keywords = {Resting-state fMRI, Fingerprinting, Deep learning, Graph convolutional neural network, Kernel ridge regression},
	pages = {116276},
	file = {He et al_2020_Deep neural networks and kernel regression achieve comparable accuracies for.pdf:/Users/tito/Zotero/storage/4BP2P9LL/He et al_2020_Deep neural networks and kernel regression achieve comparable accuracies for.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/RG5URNP9/S1053811919308675.html:text/html},
}

@phdthesis{fegen_cortical_2012,
	title = {Cortical mechanisms underlying verbal working memory},
	url = {https://escholarship.org/uc/item/6zp350v9},
	abstract = {Verbal working memory refers to the limited-capacity store responsible for maintaining and manipulating task-relevant information in a verbal form over short time-periods. The cortical regions that underlie this type of memory can be dissociated into control and storage regions. Control processes may involve operations such as the identification and selection of relevant information and the assembly and initial execution of articulatory rehearsal programs. In contrast, storage regions are where the actual task-relevant information is rehearsed. Presumably, control and storage regions transfer information among each other within a functionally connected network.To study the cortical network formed during the delay period of a verbal working memory task, the first study was specifically designed to investigate functional connectivity. While the functional connectivity results counterintuitively led to a null result, it was demonstrated that middle frontal gyrus (MFG) and superior parietal lobule (SPL) were active during encoding and the start of the delay period, as well as at the end of the delay period, suggesting they were involved in control processes. In contrast, it was demonstrated that inferior frontal gyrus (IFG), premotor (PM) and Sylvian-parietal-temporal junction (area Spt) were active throughout encoding and the entire delay period, suggesting they were involved in storage/rehearsal processes. In a second follow-up study, results demonstrated that control regions MFG and SPL were not sensitive to manipulations in rehearsal rate, but exhibited non-linear memory load effects. Conversely, storage/rehearsal regions IFG, PM and area Spt demonstrated approximately linear rehearsal rate and memory load effects. Additionally, memory load effects were found to diminish through time in all areas, while rehearsal rate effects persisted through the entire delay period in storage/rehearsal areas. It was also revealed that rehearsal rate and memory load were confounded behaviorally as subjects strategically increased their rehearsal rate to manage an increased memory load, until the load became so great that their rehearsal rate began to decrease. It was also discovered that high capacity individuals have less activity in MFG, IFG and SPL, but more activity in PM. In a third study, substitute tasks were made for the encoding period (listen word) and delay period (subvocal rehearsal) of standard verbal working memory tasks and the timing and network properties of the active cortical regions were investigated. Results demonstrated that during the listen word condition activity in primary auditory cortex preceded area Spt, and that primary auditory cortex and area Spt formed a functional network. In contrast, during the subvocal rehearsal condition activity occurred first in PM, then in area Spt, followed by IFG. These three regions also formed a functional network in the subvocal rehearsal condition. Together these experiments provide novel insights into the cortical mechanisms underlying verbal working memory.},
	language = {en},
	urldate = {2020-02-11},
	school = {UC Berkeley},
	author = {Fegen, David},
	year = {2012},
	file = {Fegen_2012_Cortical mechanisms underlying verbal working memory.pdf:/Users/tito/Zotero/storage/DSNPU4WP/Fegen_2012_Cortical mechanisms underlying verbal working memory.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MYLQSHWM/6zp350v9.html:text/html},
}

@article{chauvin_disentangling_2019,
	title = {Disentangling common from specific processing across tasks using task potency},
	volume = {184},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918318615},
	doi = {10.1016/j.neuroimage.2018.09.059},
	abstract = {When an individual engages in a task, the associated evoked activities build upon already ongoing activity, shaped by an underlying functional connectivity baseline (Fox et al., 2009; Smith et al., 2009; Tavor et al., 2016). Building on the idea that rest represents the brain's full functional repertoire, we here incorporate the idea that task-induced functional connectivity modulations ought to be task-specific with respect to their underlying resting state functional connectivity. Various metrics such as clustering coefficient or average path length have been proposed to index processing efficiency, typically from single fMRI session data. We introduce a framework incorporating task potency, which provides direct access to task-specificity by enabling direct comparison between task paradigms. In particular, to study functional connectivity modulations related to cognitive involvement in a task we define task potency as the amplitude of a connectivity modulation away from its baseline functional connectivity architecture as observed during a resting state acquisition. We demonstrate the use of our framework by comparing three tasks (visuo-spatial working memory, reward processing, and stop signal task) available within a large cohort. Using task potency, we demonstrate that cognitive operations are supported by a set of common within-network interactions, supplemented by connections between large-scale networks in order to solve a specific task.},
	language = {en},
	urldate = {2020-02-11},
	journal = {NeuroImage},
	author = {Chauvin, Roselyne J. and Mennes, Maarten and Llera, Alberto and Buitelaar, Jan K. and Beckmann, Christian F.},
	month = jan,
	year = {2019},
	keywords = {Resting state, Task modulation, Baseline, Effect size, Potentiation, Reverse inference, Task-based fmri},
	pages = {632--645},
	file = {Chauvin et al_2019_Disentangling common from specific processing across tasks using task potency.pdf:/Users/tito/Zotero/storage/SI5A2GSP/Chauvin et al_2019_Disentangling common from specific processing across tasks using task potency.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/WGW3SMYT/S1053811918318615.html:text/html},
}

@misc{poldrack_physics_2020,
	type = {Preprint},
	title = {The physics of representation},
	copyright = {cc\_by\_4},
	url = {http://philsci-archive.pitt.edu/16916/},
	abstract = {The concept of “representation” is used broadly and uncontroversially throughout neuroscience, in contrast to its highly controversial status within the philosophy of mind and cognitive science. In this paper I first discuss the way that the term is used within neuroscience, in particular describing the strategies by which representations are characterized empirically. I then relate the concept of representation within neuroscience to one that has developed within the field of machine learning (in particular through recent work in deep learning or “representation learning”). I argue that the recent success of artificial neural networks on certain tasks such as visual object recognition reflects the degree to which those systems (like biological brains) exhibit inherent inductive biases that reflect on the structure of the physical world. I further argue that any system that is going to behave intelligently in the world must contain representations that reflect the structure of the world; otherwise, the system must perform unconstrained function approximation which is destined to fail due to the curse of dimensionality, in which the number of possible states of the world grows exponentially with the number of dimensions in the space of possible inputs. An analysis of these concepts in light of philosophical debates regarding the ontological status of representations suggests that the representations identified within both biological and artificial neural networks qualify as first-class representations.},
	language = {en},
	urldate = {2020-02-18},
	author = {Poldrack, Russell A.},
	year = {2020},
	file = {Poldrack_2020_The physics of representation.pdf:/Users/tito/Zotero/storage/Q88FJQZR/Poldrack_2020_The physics of representation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JU253X6W/16916.html:text/html},
}

@article{wang_macroscopic_2020,
	title = {Macroscopic gradients of synaptic excitation and inhibition in the neocortex},
	volume = {21},
	copyright = {2020 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-020-0262-x},
	doi = {10.1038/s41583-020-0262-x},
	abstract = {Certain biological properties vary across different areas of the cerebral cortex. In this Perspective, Xiao-Jing Wang proposes that macroscopic gradients in some properties align with functional hierarchy and can lead to qualitative differences in function.},
	language = {en},
	number = {3},
	urldate = {2020-02-19},
	journal = {Nature Reviews Neuroscience},
	author = {Wang, Xiao-Jing},
	month = mar,
	year = {2020},
	pages = {169--178},
	file = {Snapshot:/Users/tito/Zotero/storage/2Y3XPBBQ/s41583-020-0262-x.html:text/html;Wang_2020_Macroscopic gradients of synaptic excitation and inhibition in the neocortex.pdf:/Users/tito/Zotero/storage/R8UKAILZ/Wang_2020_Macroscopic gradients of synaptic excitation and inhibition in the neocortex.pdf:application/pdf},
}

@article{achille_task2vec_2019,
	title = {{Task2Vec}: {Task} {Embedding} for {Meta}-{Learning}},
	shorttitle = {{Task2Vec}},
	url = {http://arxiv.org/abs/1902.03545},
	abstract = {We introduce a method to provide vectorial representations of visual classification tasks which can be used to reason about the nature of those tasks and their relations. Given a dataset with ground-truth labels and a loss function defined over those labels, we process images through a "probe network" and compute an embedding based on estimates of the Fisher information matrix associated with the probe network parameters. This provides a fixed-dimensional embedding of the task that is independent of details such as the number of classes and does not require any understanding of the class label semantics. We demonstrate that this embedding is capable of predicting task similarities that match our intuition about semantic and taxonomic relations between different visual tasks (e.g., tasks based on classifying different types of plants are similar) We also demonstrate the practical value of this framework for the meta-task of selecting a pre-trained feature extractor for a new task. We present a simple meta-learning framework for learning a metric on embeddings that is capable of predicting which feature extractors will perform well. Selecting a feature extractor with task embedding obtains a performance close to the best available feature extractor, while costing substantially less than exhaustively training and evaluating on all available feature extractors.},
	urldate = {2020-02-19},
	journal = {arXiv:1902.03545 [cs, stat]},
	author = {Achille, Alessandro and Lam, Michael and Tewari, Rahul and Ravichandran, Avinash and Maji, Subhransu and Fowlkes, Charless and Soatto, Stefano and Perona, Pietro},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.03545},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Achille et al_2019_Task2Vec.pdf:/Users/tito/Zotero/storage/8883AKPE/Achille et al_2019_Task2Vec.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/ZHPKTAQK/1902.html:text/html},
}

@article{hudson_gqa_2019,
	title = {{GQA}: {A} {New} {Dataset} for {Real}-{World} {Visual} {Reasoning} and {Compositional} {Question} {Answering}},
	shorttitle = {{GQA}},
	url = {http://arxiv.org/abs/1902.09506},
	abstract = {We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages scene graph structures to create 22M diverse reasoning questions, all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate question biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. An extensive analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains mere 42.1\%, and strong VQA models achieve 54.1\%, human performance tops at 89.3\%, offering ample opportunity for new research to explore. We strongly hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding for images and language.},
	urldate = {2020-02-19},
	journal = {arXiv:1902.09506 [cs]},
	author = {Hudson, Drew A. and Manning, Christopher D.},
	month = may,
	year = {2019},
	note = {arXiv: 1902.09506},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: Published as a conference paper at CVPR 2019 (oral)},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/RL379PWW/1902.html:text/html;Hudson_Manning_2019_GQA.pdf:/Users/tito/Zotero/storage/KTGBTD2E/Hudson_Manning_2019_GQA.pdf:application/pdf},
}

@article{hudson_learning_2019,
	title = {Learning by {Abstraction}: {The} {Neural} {State} {Machine}},
	shorttitle = {Learning by {Abstraction}},
	url = {http://arxiv.org/abs/1907.03950},
	abstract = {We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.},
	urldate = {2020-02-19},
	journal = {arXiv:1907.03950 [cs]},
	author = {Hudson, Drew A. and Manning, Christopher D.},
	month = nov,
	year = {2019},
	note = {arXiv: 1907.03950},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: Published as a conference paper at NeurIPS 2019 (spotlight)},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/KUK6Z7HS/1907.html:text/html;Hudson_Manning_2019_Learning by Abstraction.pdf:/Users/tito/Zotero/storage/HY2JL3Q9/Hudson_Manning_2019_Learning by Abstraction.pdf:application/pdf},
}

@article{kim_learning_2019,
	title = {Learning {Dynamics} of {Attention}: {Human} {Prior} for {Interpretable} {Machine} {Reasoning}},
	shorttitle = {Learning {Dynamics} of {Attention}},
	url = {http://arxiv.org/abs/1905.11666},
	abstract = {Without relevant human priors, neural networks may learn uninterpretable features. We propose Dynamics of Attention for Focus Transition (DAFT) as a human prior for machine reasoning. DAFT is a novel method that regularizes attention-based reasoning by modelling it as a continuous dynamical system using neural ordinary differential equations. As a proof of concept, we augment a state-of-the-art visual reasoning model with DAFT. Our experiments reveal that applying DAFT yields similar performance to the original model while using fewer reasoning steps, showing that it implicitly learns to skip unnecessary steps. We also propose a new metric, Total Length of Transition (TLT), which represents the effective reasoning step size by quantifying how much a given model's focus drifts while reasoning about a question. We show that adding DAFT results in lower TLT, demonstrating that our method indeed obeys the human prior towards shorter reasoning paths in addition to producing more interpretable attention maps. Our code is available at https://github.com/kakao/DAFT.},
	urldate = {2020-02-19},
	journal = {arXiv:1905.11666 [cs, stat]},
	author = {Kim, Wonjae and Lee, Yoonho},
	month = dec,
	year = {2019},
	note = {arXiv: 1905.11666},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 20 pages, 18 figures, 2 tables},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/6DMR568I/1905.html:text/html;Kim_Lee_2019_Learning Dynamics of Attention.pdf:/Users/tito/Zotero/storage/RCS6S89I/Kim_Lee_2019_Learning Dynamics of Attention.pdf:application/pdf},
}

@article{han_visual_2020,
	title = {Visual {Concept}-{Metaconcept} {Learning}},
	url = {http://arxiv.org/abs/2002.01464},
	abstract = {Humans reason with concepts and metaconcepts: we recognize red and green from visual input; we also understand that they describe the same property of objects (i.e., the color). In this paper, we propose the visual concept-metaconcept learner (VCML) for joint learning of concepts and metaconcepts from images and associated question-answer pairs. The key is to exploit the bidirectional connection between visual concepts and metaconcepts. Visual representations provide grounding cues for predicting relations between unseen pairs of concepts. Knowing that red and green describe the same property of objects, we generalize to the fact that cube and sphere also describe the same property of objects, since they both categorize the shape of objects. Meanwhile, knowledge about metaconcepts empowers visual concept learning from limited, noisy, and even biased data. From just a few examples of purple cubes we can understand a new color purple, which resembles the hue of the cubes instead of the shape of them. Evaluation on both synthetic and real-world datasets validates our claims.},
	urldate = {2020-02-19},
	journal = {arXiv:2002.01464 [cs, stat]},
	author = {Han, Chi and Mao, Jiayuan and Gan, Chuang and Tenenbaum, Joshua B. and Wu, Jiajun},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.01464},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: NeurIPS 2019. First two authors contributed equally. Project page: http://vcml.csail.mit.edu/},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/MYAQHB2N/2002.html:text/html;Han et al_2020_Visual Concept-Metaconcept Learning.pdf:/Users/tito/Zotero/storage/ZU67JF32/Han et al_2020_Visual Concept-Metaconcept Learning.pdf:application/pdf},
}

@article{bertolero_deep_nodate,
	title = {Deep {Neural} {Networks} {Carve} the {Brain} at its {Joints}},
	abstract = {How an individual’s unique brain connectivity determines that individual’s cognition, behavior, and risk for pathology is a fundamental question in basic and clinical neuroscience. In seeking answers, many have turned to machine learning, with some noting the particular promise of deep neural networks in modelling complex non-linear functions. However, it is not clear that complex functions actually exist between brain connectivity and behavior, and thus if deep neural networks necessarily outperform simpler linear models, or if their results would be interpretable. Here we show that, across 52 subject measures of cognition and behavior, deep neural networks fit to each brain region’s connectivity outperform linear regression, particularly for the brain’s connector hubs—regions with diverse brain connectivity—whereas the two approaches perform similarly when fit to brain systems. Critically, averaging deep neural network predictions across brain regions results in the most accurate predictions, demonstrating the ability of deep neural networks to easily model the various functions that exists between regional brain connectivity and behavior, carving the brain at its joints. Finally, we shine light into the black box of deep neural networks using multislice network models. We determined that the relationship between connector hubs and behavior is best captured by modular deep neural networks. Our results demonstrate that both simple and complex relationships exist between brain connectivity and behavior, and that deep neural networks can fit both. Moreover, deep neural networks are particularly powerful when they are first fit to the various functions of a system independently and then combined. Finally, deep neural networks are interpretable when their architectures are structurally characterized using multislice network models.},
	language = {en},
	author = {Bertolero, Maxwell A and Bassett, Danielle S},
	pages = {23},
	file = {Bertolero and Bassett - Deep Neural Networks Carve the Brain at its Joints.pdf:/Users/tito/Zotero/storage/FARE9FG4/Bertolero and Bassett - Deep Neural Networks Carve the Brain at its Joints.pdf:application/pdf},
}

@article{logothetis_neurophysiological_2001,
	title = {Neurophysiological investigation of the basis of the {fMRI} signal},
	volume = {412},
	copyright = {2001 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/35084005},
	doi = {10.1038/35084005},
	abstract = {Functional magnetic resonance imaging (fMRI) is widely used to study the operational organization of the human brain, but the exact relationship between the measured fMRI signal and the underlying neural activity is unclear. Here we present simultaneous intracortical recordings of neural signals and fMRI responses. We compared local field potentials (LFPs), single- and multi-unit spiking activity with highly spatio-temporally resolved blood-oxygen-level-dependent (BOLD) fMRI responses from the visual cortex of monkeys. The largest magnitude changes were observed in LFPs, which at recording sites characterized by transient responses were the only signal that significantly correlated with the haemodynamic response. Linear systems analysis on a trial-by-trial basis showed that the impulse response of the neurovascular system is both animal- and site-specific, and that LFPs yield a better estimate of BOLD responses than the multi-unit responses. These findings suggest that the BOLD contrast mechanism reflects the input and intracortical processing of a given area rather than its spiking output.},
	language = {en},
	number = {6843},
	urldate = {2020-03-02},
	journal = {Nature},
	author = {Logothetis, Nikos K. and Pauls, Jon and Augath, Mark and Trinath, Torsten and Oeltermann, Axel},
	month = jul,
	year = {2001},
	pages = {150--157},
	file = {Logothetis et al_2001_Neurophysiological investigation of the basis of the fMRI signal.pdf:/Users/tito/Zotero/storage/8I3BFC5Y/Logothetis et al_2001_Neurophysiological investigation of the basis of the fMRI signal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/UCFU6EPS/35084005.html:text/html},
}

@article{laumann_functional_2015,
	title = {Functional {System} and {Areal} {Organization} of a {Highly} {Sampled} {Individual} {Human} {Brain}},
	volume = {87},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627315006005},
	doi = {10.1016/j.neuron.2015.06.037},
	abstract = {Resting state functional MRI (fMRI) has enabled description of group-level functional brain organization at multiple spatial scales. However, cross-subject averaging may obscure patterns of brain organization specific to each individual. Here, we characterized the brain organization of a single individual repeatedly measured over more than a year. We report a reproducible and internally valid subject-specific areal-level parcellation that corresponds with subject-specific task activations. Highly convergent correlation network estimates can be derived from this parcellation if sufficient data are collected—considerably more than typically acquired. Notably, within-subject correlation variability across sessions exhibited a heterogeneous distribution across the cortex concentrated in visual and somato-motor regions, distinct from the pattern of intersubject variability. Further, although the individual’s systems-level organization is broadly similar to the group, it demonstrates distinct topological features. These results provide a foundation for studies of individual differences in cortical organization and function, especially for special or rare individuals.
Video Abstract},
	language = {en},
	number = {3},
	urldate = {2020-03-02},
	journal = {Neuron},
	author = {Laumann, Timothy O. and Gordon, Evan M. and Adeyemo, Babatunde and Snyder, Abraham Z. and Joo, Sung Jun and Chen, Mei-Yen and Gilmore, Adrian W. and McDermott, Kathleen B. and Nelson, Steven M. and Dosenbach, Nico U. F. and Schlaggar, Bradley L. and Mumford, Jeanette A. and Poldrack, Russell A. and Petersen, Steven E.},
	month = aug,
	year = {2015},
	pages = {657--670},
	file = {Laumann et al_2015_Functional System and Areal Organization of a Highly Sampled Individual Human.pdf:/Users/tito/Zotero/storage/L6LV364Y/Laumann et al_2015_Functional System and Areal Organization of a Highly Sampled Individual Human.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/ZM5QPEA5/S0896627315006005.html:text/html},
}

@article{mitchell_spatial_2009,
	title = {Spatial {Attention} {Decorrelates} {Intrinsic} {Activity} {Fluctuations} in {Macaque} {Area} {V4}},
	volume = {63},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627309006953},
	doi = {10.1016/j.neuron.2009.09.013},
	abstract = {Attention typically amplifies neuronal responses evoked by task-relevant stimuli while attenuating responses to task-irrelevant distracters. In this context, visual distracters constitute an external source of noise that is diminished to improve attended signal quality. Activity that is internal to the cortex itself, stimulus-independent ongoing correlated fluctuations in firing, might also act as task-irrelevant noise. To examine this, we recorded from area V4 of macaques performing an attention-demanding task. The firing of neurons to identically repeated stimuli was highly variable. Much of this variability originates from ongoing low-frequency ({\textless}5 Hz) fluctuations in rate correlated across the neuronal population. When attention is directed to a stimulus inside a neuron's receptive field, these correlated fluctuations in rate are reduced. This attention-dependent reduction of ongoing cortical activity improves the signal-to-noise ratio of pooled neural signals substantially more than attention-dependent increases in firing rate.},
	language = {en},
	number = {6},
	urldate = {2020-03-03},
	journal = {Neuron},
	author = {Mitchell, Jude F. and Sundberg, Kristy A. and Reynolds, John H.},
	month = sep,
	year = {2009},
	keywords = {SYSNEURO, SYSBIO, SIGNALING},
	pages = {879--888},
	file = {Mitchell et al_2009_Spatial Attention Decorrelates Intrinsic Activity Fluctuations in Macaque Area.pdf:/Users/tito/Zotero/storage/PSYP86RN/Mitchell et al_2009_Spatial Attention Decorrelates Intrinsic Activity Fluctuations in Macaque Area.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3DEHEU7T/S0896627309006953.html:text/html},
}

@book{miller_introductory_2018,
	title = {An {Introductory} {Course} in {Computational} {Neuroscience}},
	publisher = {MIT Press},
	author = {Miller, Paul},
	year = {2018},
	file = {Snapshot:/Users/tito/Zotero/storage/SYP7RM2K/books.html:text/html},
}

@article{bujan_role_2015,
	title = {Role of {Input} {Correlations} in {Shaping} the {Variability} and {Noise} {Correlations} of {Evoked} {Activity} in the {Neocortex}},
	volume = {35},
	copyright = {Copyright © 2015 the authors 0270-6474/15/358611-15\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/35/22/8611},
	doi = {10.1523/JNEUROSCI.4536-14.2015},
	abstract = {Recent analysis of evoked activity recorded across different brain regions and tasks revealed a marked decrease in noise correlations and trial-by-trial variability. Given the importance of correlations and variability for information processing within the rate coding paradigm, several mechanisms have been proposed to explain the reduction in these quantities despite an increase in firing rates. These models suggest that anatomical clusters and/or tightly balanced excitation–inhibition can generate intrinsic network dynamics that may exhibit a reduction in noise correlations and trial-by-trial variability when perturbed by an external input. Such mechanisms based on the recurrent feedback crucially ignore the contribution of feedforward input to the statistics of the evoked activity. Therefore, we investigated how statistical properties of the feedforward input shape the statistics of the evoked activity. Specifically, we focused on the effect of input correlation structure on the noise correlations and trial-by-trial variability. We show that the ability of neurons to transfer the input firing rate, correlation, and variability to the output depends on the correlations within the presynaptic pool of a neuron, and that an input with even weak within-correlations can be sufficient to reduce noise correlations and trial-by-trial variability, without requiring any specific recurrent connectivity structure. In general, depending on the ongoing activity state, feedforward input could either increase or decrease noise correlation and trial-by-trial variability. Thus, we propose that evoked activity statistics are jointly determined by the feedforward and feedback inputs.},
	language = {en},
	number = {22},
	urldate = {2020-03-10},
	journal = {J. Neurosci.},
	author = {Bujan, Alejandro F. and Aertsen, Ad and Kumar, Arvind},
	month = jun,
	year = {2015},
	pmid = {26041927},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {noise correlations, trial-by-trial variability, attention, network dynamics, evoked activity, feedforward inputs},
	pages = {8611--8625},
	file = {Bujan et al_2015_Role of Input Correlations in Shaping the Variability and Noise Correlations of.pdf:/Users/tito/Zotero/storage/2SWYRN6F/Bujan et al_2015_Role of Input Correlations in Shaping the Variability and Noise Correlations of.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BMT3SBYU/8611.html:text/html},
}

@article{nakai_quantitative_2020,
	title = {Quantitative models reveal the organization of diverse cognitive functions in the brain},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-14913-w},
	doi = {10.1038/s41467-020-14913-w},
	abstract = {The authors construct quantitative models of human brain activity evoked by 103 cognitive tasks and reveal the organization of diverse cognitive functions in the brain. Their model, which uses latent cognitive features, predicts brain activity and decodes tasks, even under novel task conditions.},
	language = {en},
	number = {1},
	urldate = {2020-03-11},
	journal = {Nature Communications},
	author = {Nakai, Tomoya and Nishimoto, Shinji},
	month = mar,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--12},
	file = {Nakai_Nishimoto_2020_Quantitative models reveal the organization of diverse cognitive functions in.pdf:/Users/tito/Zotero/storage/E224PZQI/Nakai_Nishimoto_2020_Quantitative models reveal the organization of diverse cognitive functions in.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/55CCXPC9/s41467-020-14913-w.html:text/html},
}

@article{schwettmann_invariant_2019,
	title = {Invariant representations of mass in the human brain},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.46619},
	doi = {10.7554/eLife.46619},
	abstract = {An intuitive understanding of physical objects and events is critical for successfully interacting with the world. Does the brain achieve this understanding by running simulations in a mental physics engine, which represents variables such as force and mass, or by analyzing patterns of motion without encoding underlying physical quantities? To investigate, we scanned participants with fMRI while they viewed videos of objects interacting in scenarios indicating their mass. Decoding analyses in brain regions previously implicated in intuitive physical inference revealed mass representations that generalized across variations in scenario, material, friction, and motion energy. These invariant representations were found during tasks without action planning, and tasks focusing on an orthogonal dimension (object color). Our results support an account of physical reasoning where abstract physical variables serve as inputs to a forward model of dynamics, akin to a physics engine, in parietal and frontal cortex.},
	urldate = {2020-03-11},
	journal = {eLife},
	author = {Schwettmann, Sarah and Tenenbaum, Joshua B and Kanwisher, Nancy},
	editor = {Yeo, Thomas and Frank, Michael J and Snow, Jaqueline and Gallivan, Jason},
	month = dec,
	year = {2019},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {fMRI, intuitive physics, visual scene understanding},
	pages = {e46619},
	file = {Schwettmann et al_2019_Invariant representations of mass in the human brain.pdf:/Users/tito/Zotero/storage/Y6MPPSK2/Schwettmann et al_2019_Invariant representations of mass in the human brain.pdf:application/pdf},
}

@article{chang_compositional_2017,
	title = {A {Compositional} {Object}-{Based} {Approach} to {Learning} {Physical} {Dynamics}},
	url = {http://arxiv.org/abs/1612.00341},
	abstract = {We present the Neural Physics Engine (NPE), a framework for learning simulators of intuitive physics that naturally generalize across variable object count and different scene configurations. We propose a factorization of a physical scene into composable object-based representations and a neural network architecture whose compositional structure factorizes object dynamics into pairwise interactions. Like a symbolic physics engine, the NPE is endowed with generic notions of objects and their interactions; realized as a neural network, it can be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the efficacy of our approach on simple rigid body dynamics in two-dimensional worlds. By comparing to less structured architectures, we show that the NPE's compositional representation of the structure in physical interactions improves its ability to predict movement, generalize across variable object count and different scene configurations, and infer latent properties of objects such as mass.},
	urldate = {2020-03-11},
	journal = {arXiv:1612.00341 [cs]},
	author = {Chang, Michael B. and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B.},
	month = mar,
	year = {2017},
	note = {arXiv: 1612.00341},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper for ICLR 2017. 15 pages, 6 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/M5SPM4M3/1612.html:text/html;Chang et al_2017_A Compositional Object-Based Approach to Learning Physical Dynamics.pdf:/Users/tito/Zotero/storage/WMWQVVJU/Chang et al_2017_A Compositional Object-Based Approach to Learning Physical Dynamics.pdf:application/pdf},
}

@article{sanchez-gonzalez_learning_2020,
	title = {Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}},
	url = {http://arxiv.org/abs/2002.09405},
	abstract = {Here we present a general framework for learning simulation, and provide a single model implementation that yields state-of-the-art performance across a variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term "Graph Network-based Simulators" (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework is the most accurate general-purpose learned physics simulator to date, and holds promise for solving a wide range of complex forward and inverse problems.},
	urldate = {2020-03-11},
	journal = {arXiv:2002.09405 [physics, stat]},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W.},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.09405},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Physics - Computational Physics},
	annote = {Comment: Submitted to ICML 2020},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/TTVNSTJ9/2002.html:text/html;Sanchez-Gonzalez et al_2020_Learning to Simulate Complex Physics with Graph Networks.pdf:/Users/tito/Zotero/storage/2H4YM5AR/Sanchez-Gonzalez et al_2020_Learning to Simulate Complex Physics with Graph Networks.pdf:application/pdf},
}

@article{johnson_clevr_2016,
	title = {{CLEVR}: {A} {Diagnostic} {Dataset} for {Compositional} {Language} and {Elementary} {Visual} {Reasoning}},
	shorttitle = {{CLEVR}},
	url = {http://arxiv.org/abs/1612.06890},
	abstract = {When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.},
	urldate = {2020-03-11},
	journal = {arXiv:1612.06890 [cs]},
	author = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.06890},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/IVAFWCPI/1612.html:text/html;Johnson et al_2016_CLEVR.pdf:/Users/tito/Zotero/storage/5YKJTRHN/Johnson et al_2016_CLEVR.pdf:application/pdf},
}

@article{chien_constructing_2020,
	title = {Constructing and {Forgetting} {Temporal} {Context} in the {Human} {Cerebral} {Cortex}},
	volume = {0},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30136-7},
	doi = {10.1016/j.neuron.2020.02.013},
	language = {English},
	number = {0},
	urldate = {2020-03-12},
	journal = {Neuron},
	author = {Chien, Hsiang-Yun Sherry and Honey, Christopher J.},
	month = mar,
	year = {2020},
	note = {Publisher: Elsevier},
	keywords = {fMRI, computational modeling, prediction error, temporal context, event boundary, hierarchy, inter-subject correlation, sequence processing, temporal integration, timescales},
	file = {Chien_Honey_2020_Constructing and Forgetting Temporal Context in the Human Cerebral Cortex.pdf:/Users/tito/Zotero/storage/6FHCCR9S/Chien_Honey_2020_Constructing and Forgetting Temporal Context in the Human Cerebral Cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/KGUR27HH/S0896-6273(20)30136-7.html:text/html},
}

@article{zerbi_rapid_2019,
	title = {Rapid {Reconfiguration} of the {Functional} {Connectome} after {Chemogenetic} {Locus} {Coeruleus} {Activation}},
	volume = {103},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627319304878},
	doi = {10.1016/j.neuron.2019.05.034},
	abstract = {The locus coeruleus (LC) supplies norepinephrine (NE) to the entire forebrain and regulates many fundamental brain functions. Studies in humans have suggested that strong LC activation might shift network connectivity to favor salience processing. To causally test this hypothesis, we use a mouse model to study the effect of LC stimulation on large-scale functional connectivity by combining chemogenetic activation of the LC with resting-state fMRI, an approach we term “chemo-connectomics.” We show that LC activation rapidly interrupts ongoing behavior and strongly increases brain-wide connectivity, with the most profound effects in the salience and amygdala networks. Functional connectivity changes strongly correlate with transcript levels of alpha-1 and beta-1 adrenergic receptors across the brain, and functional network connectivity correlates with NE turnover within select brain regions. We propose that these changes in large-scale network connectivity are critical for optimizing neural processing in the context of increased vigilance and threat detection.},
	language = {en},
	number = {4},
	urldate = {2020-03-16},
	journal = {Neuron},
	author = {Zerbi, Valerio and Floriou-Servou, Amalia and Markicevic, Marija and Vermeiren, Yannick and Sturman, Oliver and Privitera, Mattia and von Ziegler, Lukas and Ferrari, Kim David and Weber, Bruno and De Deyn, Peter Paul and Wenderoth, Nicole and Bohacek, Johannes},
	month = aug,
	year = {2019},
	keywords = {noradrenaline, functional connectivity, anxiety, chemogenetics, DREADDs, resting-state functional magnetic resonance imaging, rs-fMRI, salience, stress},
	pages = {702--718.e5},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/85KTMSTU/S0896627319304878.html:text/html;Zerbi et al_2019_Rapid Reconfiguration of the Functional Connectome after Chemogenetic Locus.pdf:/Users/tito/Zotero/storage/FDQVSRFB/Zerbi et al_2019_Rapid Reconfiguration of the Functional Connectome after Chemogenetic Locus.pdf:application/pdf},
}

@article{majeed_spatiotemporal_2011,
	title = {Spatiotemporal dynamics of low frequency {BOLD} fluctuations in rats and humans},
	volume = {54},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910011122},
	doi = {10.1016/j.neuroimage.2010.08.030},
	abstract = {Most studies involving spontaneous fluctuations in the BOLD signal extract connectivity patterns that show relationships between brain areas that are maintained over the length of the scanning session. In this study, however, we examine the spatiotemporal dynamics of the BOLD fluctuations to identify common patterns of propagation within a scan. A novel pattern finding algorithm was developed for detecting repeated spatiotemporal patterns in BOLD fMRI data. The algorithm was applied to high temporal resolution T2*-weighted multislice images obtained from rats and humans in the absence of any task or stimulation. In rats, the primary pattern consisted of waves of high signal intensity, propagating in a lateral to medial direction across the cortex, replicating our previous findings (Majeed et al., 2009a). These waves were observed primarily in sensorimotor cortex, but also extended to visual and parietal association areas. A secondary pattern, confined to subcortical regions consisted of an initial increase and subsequent decrease in signal intensity in the caudate–putamen. In humans, the most common spatiotemporal pattern consisted of an alteration between activation of areas comprising the “default-mode” (e.g., posterior cingulate and anterior medial prefrontal cortices) and the “task-positive” (e.g., superior parietal and premotor cortices) networks. Signal propagation from focal starting points was also observed. The pattern finding algorithm was shown to be reasonably insensitive to the variation in user-defined parameters, and the results were consistent within and between subjects. This novel approach for probing the spontaneous network activity of the brain has implications for the interpretation of conventional functional connectivity studies, and may increase the amount of information that can be obtained from neuroimaging data.},
	language = {en},
	number = {2},
	urldate = {2020-03-16},
	journal = {NeuroImage},
	author = {Majeed, Waqas and Magnuson, Matthew and Hasenkamp, Wendy and Schwarb, Hillary and Schumacher, Eric H. and Barsalou, Lawrence and Keilholz, Shella D.},
	month = jan,
	year = {2011},
	keywords = {Functional connectivity, Low frequency fluctuations, Spatiotemporal dynamics, Spontaneous neural activity},
	pages = {1140--1150},
	file = {Majeed et al_2011_Spatiotemporal dynamics of low frequency BOLD fluctuations in rats and humans.pdf:/Users/tito/Zotero/storage/SGML382R/Majeed et al_2011_Spatiotemporal dynamics of low frequency BOLD fluctuations in rats and humans.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/U7SGSR4S/S1053811910011122.html:text/html},
}

@article{schaefer_local-global_2018,
	title = {Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity {MRI}},
	volume = {28},
	number = {9},
	journal = {Cerebral Cortex},
	author = {Schaefer, Alexander and Kong, Ru and Gordon, Evan M. and Laumann, Timothy O. and Zuo, Xi-Nian and Holmes, Avram J. and Eickhoff, Simon B. and Yeo, BT Thomas},
	year = {2018},
	note = {Publisher: Oxford University Press},
	pages = {3095--3114},
	file = {bhx179.pdf:/Users/tito/Downloads/bhx179.pdf:application/pdf;Full Text:/Users/tito/Zotero/storage/WM9SZGL6/3978804.html:text/html;Snapshot:/Users/tito/Zotero/storage/DTKLDIGJ/3978804.html:text/html},
}

@article{kong_spatial_2019,
	title = {Spatial {Topography} of {Individual}-{Specific} {Cortical} {Networks} {Predicts} {Human} {Cognition}, {Personality}, and {Emotion}},
	volume = {29},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/29/6/2533/5033556},
	doi = {10.1093/cercor/bhy123},
	abstract = {Abstract.  Resting-state functional magnetic resonance imaging (rs-fMRI) offers the opportunity to delineate individual-specific brain networks. A major questio},
	language = {en},
	number = {6},
	urldate = {2020-03-23},
	journal = {Cereb Cortex},
	author = {Kong, Ru and Li, Jingwei and Orban, Csaba and Sabuncu, Mert R. and Liu, Hesheng and Schaefer, Alexander and Sun, Nanbo and Zuo, Xi-Nian and Holmes, Avram J. and Eickhoff, Simon B. and Yeo, B. T. Thomas},
	month = jun,
	year = {2019},
	note = {Publisher: Oxford Academic},
	pages = {2533--2551},
	file = {Kong et al_2019_Spatial Topography of Individual-Specific Cortical Networks Predicts Human.pdf:/Users/tito/Zotero/storage/JHTNZEPM/Kong et al_2019_Spatial Topography of Individual-Specific Cortical Networks Predicts Human.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZE7345MQ/5033556.html:text/html},
}

@article{bartolo_information-limiting_2020,
	title = {Information-{Limiting} {Correlations} in {Large} {Neural} {Populations}},
	volume = {40},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2072-19.2019},
	doi = {10.1523/JNEUROSCI.2072-19.2019},
	language = {en},
	number = {8},
	urldate = {2020-03-25},
	journal = {The Journal of Neuroscience},
	author = {Bartolo, Ramon and Saunders, Richard C. and Mitz, Andrew R. and Averbeck, Bruno B.},
	month = feb,
	year = {2020},
	pages = {1668--1678},
	file = {Bartolo et al. - 2020 - Information-Limiting Correlations in Large Neural .pdf:/Users/tito/Zotero/storage/MJT4WS2I/Bartolo et al. - 2020 - Information-Limiting Correlations in Large Neural .pdf:application/pdf},
}

@article{lundqvist_gamma_2018,
	title = {Gamma and beta bursts during working memory readout suggest roles in its volitional control},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-017-02791-8/},
	doi = {10.1038/s41467-017-02791-8},
	abstract = {Previously, the authors have shown that working memory can be maintained by brief gamma oscillation bursts. Here, the authors use a new task to further demonstrate the dynamics of gamma and beta oscillations in working memory readout, independent of behavioral response.},
	language = {en},
	number = {1},
	urldate = {2020-03-27},
	journal = {Nature Communications},
	author = {Lundqvist, Mikael and Herman, Pawel and Warden, Melissa R. and Brincat, Scott L. and Miller, Earl K.},
	month = jan,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--12},
	file = {Lundqvist et al_2018_Gamma and beta bursts during working memory readout suggest roles in its.pdf:/Users/tito/Zotero/storage/6GHILLAV/Lundqvist et al_2018_Gamma and beta bursts during working memory readout suggest roles in its.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZGCLBL4R/s41467-017-02791-8.html:text/html},
}

@article{cornblath_temporal_2019,
	title = {Temporal sequences of brain activity at rest are constrained by white matter structure and modulated by cognitive demands},
	url = {http://arxiv.org/abs/1809.02849},
	abstract = {A diverse white matter network and finely tuned neuronal membrane properties allow the brain to transition seamlessly between cognitive states. However, it remains unclear how static structural connections guide the temporal progression of large-scale brain activity patterns in different cognitive states. Here, we analyze the brain's trajectories through a high-dimensional activity space at the level of single time point activity patterns from functional magnetic resonance imaging data acquired during passive visual fixation (rest) and an n-back working memory task. We find that specific state space trajectories, which represent temporal sequences of brain activity, are modulated by cognitive load and related to task performance. Using diffusion-weighted imaging acquired from the same subjects, we use tools from network control theory to show that linear spread of activity along white matter connections constrains the brain's state space trajectories at rest. Additionally, accounting for stimulus-driven visual inputs explains the different trajectories taken during the n-back task. We also used models of network rewiring to show that these findings are the result of non-trivial geometric and topological properties of white matter architecture. Finally, we examine associations between age and time-resolved brain state dynamics, revealing new insights into functional changes in the default mode and executive control networks. Overall, these results elucidate the structural underpinnings of cognitively and developmentally relevant spatiotemporal brain dynamics.},
	urldate = {2020-03-30},
	journal = {arXiv:1809.02849 [q-bio]},
	author = {Cornblath, Eli J. and Ashourvan, Arian and Kim, Jason Z. and Betzel, Richard F. and Ciric, Rastko and Adebimpe, Azeez and Baum, Graham L. and He, Xiaosong and Ruparel, Kosha and Moore, Tyler M. and Gur, Ruben C. and Gur, Raquel E. and Shinohara, Russell T. and Roalf, David R. and Satterthwaite, Theodore D. and Bassett, Danielle S.},
	month = sep,
	year = {2019},
	note = {arXiv: 1809.02849},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/4RVBR7DS/1809.html:text/html;Cornblath et al_2019_Temporal sequences of brain activity at rest are constrained by white matter.pdf:/Users/tito/Zotero/storage/AZJKJSPD/Cornblath et al_2019_Temporal sequences of brain activity at rest are constrained by white matter.pdf:application/pdf},
}

@article{peer_brain_2015,
	title = {Brain system for mental orientation in space, time, and person},
	volume = {112},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1504242112},
	doi = {10.1073/pnas.1504242112},
	language = {en},
	number = {35},
	urldate = {2020-03-30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Peer, Michael and Salomon, Roy and Goldberg, Ilan and Blanke, Olaf and Arzy, Shahar},
	month = sep,
	year = {2015},
	pages = {11072--11077},
	file = {Peer et al. - 2015 - Brain system for mental orientation in space, time.pdf:/Users/tito/Zotero/storage/4RZZMCGU/Peer et al. - 2015 - Brain system for mental orientation in space, time.pdf:application/pdf},
}

@article{peer_evidence_2017,
	title = {Evidence for {Functional} {Networks} within the {Human} {Brain}'s {White} {Matter}},
	volume = {37},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3872-16.2017},
	doi = {10.1523/JNEUROSCI.3872-16.2017},
	language = {en},
	number = {27},
	urldate = {2020-03-30},
	journal = {The Journal of Neuroscience},
	author = {Peer, Michael and Nitzan, Mor and Bick, Atira S. and Levin, Netta and Arzy, Shahar},
	month = jul,
	year = {2017},
	pages = {6394--6407},
	file = {Peer et al. - 2017 - Evidence for Functional Networks within the Human .pdf:/Users/tito/Zotero/storage/AJDXDXPM/Peer et al. - 2017 - Evidence for Functional Networks within the Human .pdf:application/pdf},
}

@article{saxe_mathematical_2019,
	title = {A mathematical theory of semantic development in deep neural networks},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/23/11537},
	doi = {10.1073/pnas.1820226116},
	abstract = {An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: What are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep-learning dynamics to give rise to these regularities.},
	language = {en},
	number = {23},
	urldate = {2020-03-31},
	journal = {PNAS},
	author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
	month = jun,
	year = {2019},
	pmid = {31101713},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {neural networks, deep learning, generative models, semantic cognition},
	pages = {11537--11546},
	file = {Saxe et al_2019_A mathematical theory of semantic development in deep neural networks.pdf:/Users/tito/Zotero/storage/EXVIZN7W/Saxe et al_2019_A mathematical theory of semantic development in deep neural networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/D7VEKDPT/11537.html:text/html},
}

@article{mcclelland_parallel-distributed_2016,
	title = {A parallel-distributed processing approach to mathematical cognition},
	journal = {Manuscript, Stanford University},
	author = {McClelland, James L. and Mickey, Kevin and Hansen, Steven and Yuan, Arianna and Lu, Qihong},
	year = {2016},
	file = {McClelland et al_2016_A parallel-distributed processing approach to mathematical cognition.pdf:/Users/tito/Zotero/storage/7QWD3JRW/McClelland et al_2016_A parallel-distributed processing approach to mathematical cognition.pdf:application/pdf},
}

@article{pinheiro-chagas_decoding_2019,
	series = {Architecture of mathematical cognition},
	title = {Decoding the processing stages of mental arithmetic with magnetoencephalography},
	volume = {114},
	issn = {0010-9452},
	url = {http://www.sciencedirect.com/science/article/pii/S0010945218302351},
	doi = {10.1016/j.cortex.2018.07.018},
	abstract = {Elementary arithmetic is highly prevalent in our daily lives. However, despite decades of research, we are only beginning to understand how the brain solves simple calculations. Here, we applied machine learning techniques to magnetoencephalography (MEG) signals in an effort to decompose the successive processing stages and mental transformations underlying elementary arithmetic. Adults subjects verified single-digit addition and subtraction problems such as 3 + 2 = 9 in which each successive symbol was presented sequentially. MEG signals revealed a cascade of partially overlapping brain states. While the first operand could be transiently decoded above chance level, primarily based on its visual properties, the decoding of the second operand was more accurate and lasted longer. Representational similarity analyses suggested that this decoding rested on both visual and magnitude codes. We were also able to decode the operation type (additions vs. subtraction) during practically the entire trial after the presentation of the operation sign. At the decision stage, MEG indicated a fast and highly overlapping temporal dynamics for (1) identifying the proposed result, (2) judging whether it was correct or incorrect, and (3) pressing the response button. Surprisingly, however, the internally computed result could not be decoded. Our results provide a first comprehensive picture of the unfolding processing stages underlying arithmetic calculations at a single-trial level, and suggest that externally and internally generated neural codes may have different neural substrates.},
	language = {en},
	urldate = {2020-03-31},
	journal = {Cortex},
	author = {Pinheiro-Chagas, Pedro and Piazza, Manuela and Dehaene, Stanislas},
	month = may,
	year = {2019},
	keywords = {Representational similarity analysis, Decoding, Magnetoencephalography, Mental arithmetic},
	pages = {124--139},
	file = {Pinheiro-Chagas et al_2019_Decoding the processing stages of mental arithmetic with magnetoencephalography.pdf:/Users/tito/Zotero/storage/MAVBQKV4/Pinheiro-Chagas et al_2019_Decoding the processing stages of mental arithmetic with magnetoencephalography.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/CWY43UFE/S0010945218302351.html:text/html},
}

@article{macevoy_constructing_2011,
	title = {Constructing scenes from objects in human occipitotemporal cortex},
	volume = {14},
	copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2903},
	doi = {10.1038/nn.2903},
	abstract = {The authors use multivoxel pattern analysis of fMRI data to examine the role of lateral occipital (LO) cortex in the recognition of real-world visual scenes. They find that LO may support an object-based channel for scene recognition by combining information about multiple objects within a scene.},
	language = {en},
	number = {10},
	urldate = {2020-04-03},
	journal = {Nature Neuroscience},
	author = {MacEvoy, Sean P. and Epstein, Russell A.},
	month = oct,
	year = {2011},
	note = {Number: 10
Publisher: Nature Publishing Group},
	pages = {1323--1329},
	file = {MacEvoy_Epstein_2011_Constructing scenes from objects in human occipitotemporal cortex.pdf:/Users/tito/Zotero/storage/3VIP5V3W/MacEvoy_Epstein_2011_Constructing scenes from objects in human occipitotemporal cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/A4LSKSVB/nn.html:text/html},
}

@techreport{miller_new_2020,
	type = {preprint},
	title = {A new sulcal landmark identifying anatomical and functional gradients in human lateral prefrontal cortex},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.03.24.006577},
	abstract = {Understanding the relationship between anatomy and function in portions of human cortex that are expanded compared to other mammals such as lateral prefrontal cortex (LPFC) is of major interest in cognitive neuroscience. Implementing a multi-modal approach and the manual definition of nearly 800 cortical indentations, or sulci, in 72 hemispheres, we report a new sulcal landmark in human LPFC: the posterior middle frontal sulcus (pmfs). The pmfs is a shallow tertiary sulcus with three components that differ in their myelin content, resting state connectivity profiles, and engagement across meta-analyses of 83 cognitive tasks. These findings support a classic, largely unconsidered anatomical theory that tertiary sulci serve as landmarks in association cortices, as well as a modern cognitive neuroscience theory proposing a functional hierarchy in LPFC. As there is a growing need for computational tools that automatically define tertiary sulci throughout cortex, we share pmfs probabilistic sulcal maps with the field.},
	language = {en},
	urldate = {2020-04-07},
	institution = {Neuroscience},
	author = {Miller, Jacob A. and Voorhies, Willa I. and Lurie, Daniel J. and D’Esposito, Mark and Weiner, Kevin S.},
	month = mar,
	year = {2020},
	doi = {10.1101/2020.03.24.006577},
	file = {Miller et al. - 2020 - A new sulcal landmark identifying anatomical and f.pdf:/Users/tito/Zotero/storage/CNYVTWU6/Miller et al. - 2020 - A new sulcal landmark identifying anatomical and f.pdf:application/pdf},
}

@article{dhamala_sex_2019,
	title = {Sex classification using long-range temporal dependence of resting-state functional {MRI} time series},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/809954v1},
	doi = {10.1101/809954},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}A thorough understanding of sex differences, if any, that exist in the brains of healthy individuals is crucial for the study of neurological illnesses that exhibit differences in clinical and behavioural phenotypes between males and females. In this work, we evaluate sex differences in regional temporal dependence of resting-state brain activity using 195 male-female pairs (aged 22-37) from the Human Connectome Project. Male-female pairs are strictly matched for total grey matter volume. We find that males have more persistent long-range temporal dependence than females in regions within temporal, parietal, and occipital cortices. Machine learning algorithms trained on regional temporal dependence measures achieve sex classification accuracies of up to 81\%. Regions with the strongest feature importance in the sex classification task included cerebellum, amygdala, frontal cortex, and occipital cortex. Additionally, we find that even after males and females are strictly matched on total grey matter volume, significant regional volumetric sex differences persist in many cortical and subcortical regions. Our results indicate males have larger cerebella, hippocampi, parahippocampi, thalami, caudates, and amygdalae while females have larger cingulates, precunei, frontal cortices, and parietal cortices. Sex classification based on regional volume achieves accuracies of up to 85\%; cerebellum, cingulate cortex, and temporal cortex are the most important features. These findings highlight the important role of strict volume matching when studying brain-based sex differences. Differential patterns in regional temporal dependence between males and females identifies a potential neurobiological substrate underlying sex differences in functional brain activation patterns and the behaviours with which they correlate.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-04-07},
	journal = {bioRxiv},
	author = {Dhamala, Elvisha and Jamison, Keith W. and Sabuncu, Mert R. and Kuceyeski, Amy},
	month = oct,
	year = {2019},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {809954},
	file = {Dhamala et al_2019_Sex classification using long-range temporal dependence of resting-state.pdf:/Users/tito/Zotero/storage/5IWZE9DT/Dhamala et al_2019_Sex classification using long-range temporal dependence of resting-state.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/74PW6JIV/809954v1.html:text/html},
}

@article{goyal_recurrent_2019,
	title = {Recurrent {Independent} {Mechanisms}},
	url = {http://arxiv.org/abs/1909.10893},
	abstract = {Learning modular structures which reflect the dynamics of the environment can lead to better generalization and robustness to changes which only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and are only updated at time steps where they are most relevant. We show that this leads to specialization amongst the RIMs, which in turn allows for dramatically improved generalization on tasks where some factors of variation differ systematically between training and evaluation.},
	urldate = {2020-04-08},
	journal = {arXiv:1909.10893 [cs, stat]},
	author = {Goyal, Anirudh and Lamb, Alex and Hoffmann, Jordan and Sodhani, Shagun and Levine, Sergey and Bengio, Yoshua and Schölkopf, Bernhard},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.10893},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/IRH949GY/1909.html:text/html;Goyal et al_2019_Recurrent Independent Mechanisms.pdf:/Users/tito/Zotero/storage/SWSJ7AC4/Goyal et al_2019_Recurrent Independent Mechanisms.pdf:application/pdf},
}

@inproceedings{bengio_deep_2012,
	title = {Deep learning of representations for unsupervised and transfer learning},
	booktitle = {Proceedings of {ICML} workshop on unsupervised and transfer learning},
	author = {Bengio, Yoshua},
	year = {2012},
	pages = {17--36},
	file = {Bengio_2012_Deep learning of representations for unsupervised and transfer learning.pdf:/Users/tito/Zotero/storage/C4JRF8LM/Bengio_2012_Deep learning of representations for unsupervised and transfer learning.pdf:application/pdf},
}

@misc{noauthor_partial_nodate,
	title = {Partial covariance based functional connectivity computation using {Ledoit}–{Wolf} covariance regularization - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811915006503},
	urldate = {2020-04-15},
}

@article{lashley_mass_1931,
	title = {Mass {Action} in {Cerebral} {Function}},
	volume = {73},
	copyright = {© 1931},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/73/1888/245},
	doi = {10.1126/science.73.1888.245},
	language = {en},
	number = {1888},
	urldate = {2020-04-16},
	journal = {Science},
	author = {Lashley, K. S.},
	month = mar,
	year = {1931},
	pmid = {17755301},
	note = {Publisher: American Association for the Advancement of Science
Section: Articles},
	pages = {245--254},
	file = {Lashley_1931_Mass Action in Cerebral Function.pdf:/Users/tito/Zotero/storage/VQSHVXCK/Lashley_1931_Mass Action in Cerebral Function.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VIAFIS4F/245.html:text/html},
}

@article{castrillon_physiological_2020,
	title = {The physiological effects of noninvasive brain stimulation fundamentally differ across the human cortex},
	volume = {6},
	copyright = {Copyright © 2020 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/6/5/eaay2739},
	doi = {10.1126/sciadv.aay2739},
	abstract = {Transcranial magnetic stimulation (TMS) is a noninvasive method to modulate brain activity and behavior in humans. Still, stimulation effects substantially vary across studies and individuals, thereby restricting the large-scale application of TMS in research or clinical settings. We revealed that low-frequency stimulation had opposite impact on the functional connectivity of sensory and cognitive brain regions. Biophysical modeling then identified a neuronal mechanism underlying these region-specific effects. Stimulation of the frontal cortex decreased local inhibition and disrupted feedforward and feedback connections. Conversely, identical stimulation increased local inhibition and enhanced forward signaling in the occipital cortex. Last, we identified functional integration as a macroscale network parameter to predict the region-specific effect of stimulation in individual subjects. In summary, we revealed how TMS modulation critically depends on the connectivity profile of target regions and propose an imaging marker to improve sensitivity of noninvasive brain stimulation for research and clinical applications.
Signaling pathways along the human cortex shape the effect of noninvasive brain stimulation.
Signaling pathways along the human cortex shape the effect of noninvasive brain stimulation.},
	language = {en},
	number = {5},
	urldate = {2020-04-20},
	journal = {Science Advances},
	author = {Castrillon, Gabriel and Sollmann, Nico and Kurcyus, Katarzyna and Razi, Adeel and Krieg, Sandro M. and Riedl, Valentin},
	month = jan,
	year = {2020},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eaay2739},
	file = {Castrillon et al_2020_The physiological effects of noninvasive brain stimulation fundamentally differ.pdf:/Users/tito/Zotero/storage/BV3HNB5K/Castrillon et al_2020_The physiological effects of noninvasive brain stimulation fundamentally differ.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/PG2LE7YB/eaay2739.html:text/html},
}

@article{lindsay_attention_2020,
	title = {Attention in {Psychology}, {Neuroscience}, and {Machine} {Learning}},
	volume = {14},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full},
	doi = {10.3389/fncom.2020.00029},
	abstract = {Attention is the important ability to flexibly control limited computational resources. It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning. It has also recently been applied in several domains in machine learning. The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear. This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature. It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist. Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored.},
	language = {English},
	urldate = {2020-04-24},
	journal = {Front. Comput. Neurosci.},
	author = {Lindsay, Grace W.},
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {machine learning, Attention, Awareness, Memory, Vision, artificial neural networks},
	file = {Lindsay_2020_Attention in Psychology, Neuroscience, and Machine Learning.pdf:/Users/tito/Zotero/storage/TBPEXMZV/Lindsay_2020_Attention in Psychology, Neuroscience, and Machine Learning.pdf:application/pdf},
}

@article{yeh_population-averaged_2018,
	title = {Population-averaged atlas of the macroscale human structural connectome and its network topology},
	volume = {178},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918304324},
	doi = {10.1016/j.neuroimage.2018.05.027},
	abstract = {A comprehensive map of the structural connectome in the human brain has been a coveted resource for understanding macroscopic brain networks. Here we report an expert-vetted, population-averaged atlas of the structural connectome derived from diffusion MRI data (N = 842). This was achieved by creating a high-resolution template of diffusion patterns averaged across individual subjects and using tractography to generate 550,000 trajectories of representative white matter fascicles annotated by 80 anatomical labels. The trajectories were subsequently clustered and labeled by a team of experienced neuroanatomists in order to conform to prior neuroanatomical knowledge. A multi-level network topology was then described using whole-brain connectograms, with subdivisions of the association pathways showing small-worldness in intra-hemisphere connections, projection pathways showing hub structures at thalamus, putamen, and brainstem, and commissural pathways showing bridges connecting cerebral hemispheres to provide global efficiency. This atlas of the structural connectome provides representative organization of human brain white matter, complementary to traditional histologically-derived and voxel-based white matter atlases, allowing for better modeling and simulation of brain connectivity for future connectome studies.},
	language = {en},
	urldate = {2020-04-27},
	journal = {NeuroImage},
	author = {Yeh, Fang-Cheng and Panesar, Sandip and Fernandes, David and Meola, Antonio and Yoshino, Masanori and Fernandez-Miranda, Juan C. and Vettel, Jean M. and Verstynen, Timothy},
	month = sep,
	year = {2018},
	keywords = {Connectogram, Diffusion MRI, Structural connectome, Tractography atlas},
	pages = {57--68},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/Y5JM6YK7/S1053811918304324.html:text/html;Yeh et al_2018_Population-averaged atlas of the macroscale human structural connectome and its.pdf:/Users/tito/Zotero/storage/WDY7HFU2/Yeh et al_2018_Population-averaged atlas of the macroscale human structural connectome and its.pdf:application/pdf},
}

@article{bartolo_dimensionality_2020,
	title = {Dimensionality, information and learning in prefrontal cortex},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007514},
	doi = {10.1371/journal.pcbi.1007514},
	abstract = {Learning leads to changes in population patterns of neural activity. In this study we wanted to examine how these changes in patterns of activity affect the dimensionality of neural responses and information about choices. We addressed these questions by carrying out high channel count recordings in dorsal-lateral prefrontal cortex (dlPFC; 768 electrodes) while monkeys performed a two-armed bandit reinforcement learning task. The high channel count recordings allowed us to study population coding while monkeys learned choices between actions or objects. We found that the dimensionality of neural population activity was higher across blocks in which animals learned the values of novel pairs of objects, than across blocks in which they learned the values of actions. The increase in dimensionality with learning in object blocks was related to less shared information across blocks, and therefore patterns of neural activity that were less similar, when compared to learning in action blocks. Furthermore, these differences emerged with learning, and were not a simple function of the choice of a visual image or action. Therefore, learning the values of novel objects increases the dimensionality of neural representations in dlPFC.},
	language = {en},
	number = {4},
	urldate = {2020-04-28},
	journal = {PLOS Computational Biology},
	author = {Bartolo, Ramon and Saunders, Richard C. and Mitz, Andrew R. and Averbeck, Bruno B.},
	month = apr,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Learning, Neurons, Prefrontal cortex, Eye movements, Monkeys, Coding mechanisms, Decision making, Single neuron function},
	pages = {e1007514},
	file = {Bartolo et al_2020_Dimensionality, information and learning in prefrontal cortex.pdf:/Users/tito/Zotero/storage/IJ3T9I3I/Bartolo et al_2020_Dimensionality, information and learning in prefrontal cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FSPAUJQH/article.html:text/html},
}

@article{friston_smooth_2000,
	title = {To {Smooth} or {Not} to {Smooth}?: {Bias} and {Efficiency} in {fMRI} {Time}-{Series} {Analysis}},
	volume = {12},
	issn = {1053-8119},
	shorttitle = {To {Smooth} or {Not} to {Smooth}?},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811900906098},
	doi = {10.1006/nimg.2000.0609},
	abstract = {This paper concerns temporal filtering in fMRI time-series analysis. Whitening serially correlated data is the most efficient approach to parameter estimation. However, if there is a discrepancy between the assumed and the actual correlations, whitening can render the analysis exquisitely sensitive to bias when estimating the standard error of the ensuing parameter estimates. This bias, although not expressed in terms of the estimated responses, has profound effects on any statistic used for inference. The special constraints of fMRI analysis ensure that there will always be a misspecification of the assumed serial correlations. One resolution of this problem is to filter the data to minimize bias, while maintaining a reasonable degree of efficiency. In this paper we present expressions for efficiency (of parameter estimation) and bias (in estimating standard error) in terms of assumed and actual correlation structures in the context of the general linear model. We show that: (i) Whitening strategies can result in profound bias and are therefore probably precluded in parametric fMRI data analyses. (ii) Band-pass filtering, and implicitly smoothing, has an important role in protecting against inferential bias.},
	language = {en},
	number = {2},
	urldate = {2020-05-06},
	journal = {NeuroImage},
	author = {Friston, K. J. and Josephs, O. and Zarahn, E. and Holmes, A. P. and Rouquette, S. and Poline, J. -B.},
	month = aug,
	year = {2000},
	keywords = {fMRI, functional neuroimaging, bias, convolution, efficiency, filtering, inference},
	pages = {196--208},
	file = {Friston et al_2000_To Smooth or Not to Smooth.pdf:/Users/tito/Zotero/storage/8Q3WCLWI/Friston et al_2000_To Smooth or Not to Smooth.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3ANN78RK/S1053811900906098.html:text/html},
}

@article{gohel_functional_2014,
	title = {Functional {Integration} {Between} {Brain} {Regions} at {Rest} {Occurs} in {Multiple}-{Frequency} {Bands}},
	volume = {5},
	issn = {2158-0014},
	url = {https://www.liebertpub.com/doi/full/10.1089/brain.2013.0210},
	doi = {10.1089/brain.2013.0210},
	abstract = {Studies of resting-state fMRI have shown that blood oxygen level dependent (BOLD) signals giving rise to temporal correlation across voxels (or regions) are dominated by low-frequency fluctuations in the range of ∼0.01–0.1 Hz. These low-frequency fluctuations have been further divided into multiple distinct frequency bands (slow-5 and -4) based on earlier neurophysiological studies, though low sampling frequency of fMRI (∼0.5 Hz) has substantially limited the exploration of other known frequency bands of neurophysiological origins (slow-3, -2, and -1). In this study, we used resting-state fMRI data acquired from 21 healthy subjects at a higher sampling frequency of 1.5 Hz to assess the presence of resting-state functional connectivity (RSFC) across multiple frequency bands: slow-5 to slow-1. The effect of different frequency bands on spatial extent and connectivity strength for known resting-state networks (RSNs) was also evaluated. RSNs were derived using independent component analysis and seed-based correlation. Commonly known RSNs, such as the default mode, the fronto-parietal, the dorsal attention, and the visual networks, were consistently observed at multiple frequency bands. Significant inter-hemispheric connectivity was observed between each seed and its contra lateral brain region across all frequency bands, though overall spatial extent of seed-based correlation maps decreased in slow-2 and slow-1 frequency bands. These results suggest that functional integration between brain regions at rest occurs over multiple frequency bands and RSFC is a multiband phenomenon. These results also suggest that further investigation of BOLD signal in multiple frequency bands for related cognitive processes should be undertaken.},
	number = {1},
	urldate = {2020-05-06},
	journal = {Brain Connectivity},
	author = {Gohel, Suril R. and Biswal, Bharat B.},
	month = apr,
	year = {2014},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	pages = {23--34},
	file = {Gohel_Biswal_2014_Functional Integration Between Brain Regions at Rest Occurs in.pdf:/Users/tito/Zotero/storage/P7IA8E48/Gohel_Biswal_2014_Functional Integration Between Brain Regions at Rest Occurs in.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/L6HGKEQB/brain.2013.html:text/html},
}

@article{bright_potential_2017,
	series = {Cleaning up the {fMRI} time series: {Mitigating} noise with advanced acquisition and correction strategies},
	title = {Potential pitfalls when denoising resting state {fMRI} data using nuisance regression},
	volume = {154},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811916307480},
	doi = {10.1016/j.neuroimage.2016.12.027},
	abstract = {In resting state fMRI, it is necessary to remove signal variance associated with noise sources, leaving cleaned fMRI time-series that more accurately reflect the underlying intrinsic brain fluctuations of interest. This is commonly achieved through nuisance regression, in which the fit is calculated of a noise model of head motion and physiological processes to the fMRI data in a General Linear Model, and the “cleaned” residuals of this fit are used in further analysis. We examine the statistical assumptions and requirements of the General Linear Model, and whether these are met during nuisance regression of resting state fMRI data. Using toy examples and real data we show how pre-whitening, temporal filtering and temporal shifting of regressors impact model fit. Based on our own observations, existing literature, and statistical theory, we make the following recommendations when employing nuisance regression: pre-whitening should be applied to achieve valid statistical inference of the noise model fit parameters; temporal filtering should be incorporated into the noise model to best account for changes in degrees of freedom; temporal shifting of regressors, although merited, should be achieved via optimisation and validation of a single temporal shift. We encourage all readers to make simple, practical changes to their fMRI denoising pipeline, and to regularly assess the appropriateness of the noise model used. By negotiating the potential pitfalls described in this paper, and by clearly reporting the details of nuisance regression in future manuscripts, we hope that the field will achieve more accurate and precise noise models for cleaning the resting state fMRI time-series.},
	language = {en},
	urldate = {2020-05-06},
	journal = {NeuroImage},
	author = {Bright, Molly G. and Tench, Christopher R. and Murphy, Kevin},
	month = jul,
	year = {2017},
	keywords = {fMRI, Nuisance regression, Connectivity, Resting state, Noise correction},
	pages = {159--168},
	file = {Bright et al_2017_Potential pitfalls when denoising resting state fMRI data using nuisance.pdf:/Users/tito/Zotero/storage/ICFRSBBS/Bright et al_2017_Potential pitfalls when denoising resting state fMRI data using nuisance.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/BF6UFC7J/S1053811916307480.html:text/html},
}

@article{kikumoto_conjunctive_2020,
	title = {Conjunctive representations that integrate stimuli, responses, and rules are critical for action selection},
	copyright = {Copyright © 2020 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2020/04/24/1922166117},
	doi = {10.1073/pnas.1922166117},
	abstract = {People can use abstract rules to flexibly configure and select actions for specific situations, yet how exactly rules shape actions toward specific sensory and/or motor requirements remains unclear. Both research from animal models and human-level theories of action control point to the role of highly integrated, conjunctive representations, sometimes referred to as event files. These representations are thought to combine rules with other, goal-relevant sensory and motor features in a nonlinear manner and represent a necessary condition for action selection. However, so far, no methods exist to track such representations in humans during action selection with adequate temporal resolution. Here, we applied time-resolved representational similarity analysis to the spectral-temporal profiles of electroencephalography signals while participants performed a cued, rule-based action selection task. In two experiments, we found that conjunctive representations were active throughout the entire selection period and were functionally dissociable from the representation of constituent features. Specifically, the strength of conjunctions was a highly robust predictor of trial-by-trial variability in response times and was selectively related to an important behavioral indicator of conjunctive representations, the so-called partial-overlap priming pattern. These results provide direct evidence for conjunctive representations as critical precursors of action selection in humans.},
	language = {en},
	urldate = {2020-05-08},
	journal = {PNAS},
	author = {Kikumoto, Atsushi and Mayr, Ulrich},
	month = apr,
	year = {2020},
	pmid = {32341161},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {conjunctive representations, EEG decoding, rule-based action},
	file = {Kikumoto_Mayr_2020_Conjunctive representations that integrate stimuli, responses, and rules are.pdf:/Users/tito/Zotero/storage/STSRYK79/Kikumoto_Mayr_2020_Conjunctive representations that integrate stimuli, responses, and rules are.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/952G9X6N/1922166117.html:text/html},
}

@inproceedings{barlow_single_1992,
	address = {Berlin, Heidelberg},
	title = {Single {Cells} versus {Neuronal} {Assemblies}},
	isbn = {978-3-642-49967-8},
	doi = {10.1007/978-3-642-49967-8_10},
	abstract = {I wrote a paper almost 20 years ago (Barlow 1972) that was intended to promote the approach to brain function at the level of single neurons, and to act as an antidote to the view that, since there are so many cells in the brain, it is useless to consider what a single one of them does. Though it was aimed at those who advocated the “mass action” approach, in which one records evoked potentials in the hope that the averaged activity of many cells will be meaningful, quite a lot of what I said still seems to me correct and relevant, though what I then regarded as the unenlightened opposition now tends to put its faith in “neuronal assemblies” and “synfire groups” instead of “mass action”. Perhaps its therefore worth raising some of the points again.},
	language = {en},
	booktitle = {Information {Processing} in the {Cortex}},
	publisher = {Springer},
	author = {Barlow, Horace B.},
	editor = {Aertsen, Ad and Braitenberg, Valentino},
	year = {1992},
	keywords = {Mass Action, Neuronal Assembly, Receptive Field, Sparse Code, Subcellular Level},
	pages = {169--173},
	file = {Barlow_1992_Single Cells versus Neuronal Assemblies.pdf:/Users/tito/Zotero/storage/NTZK62TE/Barlow_1992_Single Cells versus Neuronal Assemblies.pdf:application/pdf},
}

@article{van_gelder_what_1995,
	title = {What {Might} {Cognition} {Be}, {If} {Not} {Computation}?},
	volume = {92},
	issn = {0022-362X},
	url = {https://www.jstor.org/stable/2941061},
	doi = {10.2307/2941061},
	number = {7},
	urldate = {2020-05-15},
	journal = {The Journal of Philosophy},
	author = {Van Gelder, Tim},
	year = {1995},
	note = {Publisher: Journal of Philosophy, Inc.},
	pages = {345--381},
	file = {Van Gelder_1995_What Might Cognition Be, If Not Computation.pdf:/Users/tito/Zotero/storage/YEKM532G/Van Gelder_1995_What Might Cognition Be, If Not Computation.pdf:application/pdf},
}

@article{alexander-bloch_testing_2018,
	title = {On testing for spatial correspondence between maps of human brain structure and function},
	volume = {178},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918304968},
	doi = {10.1016/j.neuroimage.2018.05.070},
	abstract = {A critical issue in many neuroimaging studies is the comparison between brain maps. Nonetheless, it remains unclear how one should test hypotheses focused on the overlap or spatial correspondence between two or more brain maps. This “correspondence problem” affects, for example, the interpretation of comparisons between task-based patterns of functional activation, resting-state networks or modules, and neuroanatomical landmarks. To date, this problem has been addressed with remarkable variability in terms of methodological approaches and statistical rigor. In this paper, we address the correspondence problem using a spatial permutation framework to generate null models of overlap by applying random rotations to spherical representations of the cortical surface, an approach for which we also provide a theoretical statistical foundation. We use this method to derive clusters of cognitive functions that are correlated in terms of their functional neuroatomical substrates. In addition, using publicly available data, we formally demonstrate the correspondence between maps of task-based functional activity, resting-state fMRI networks and gyral-based anatomical landmarks. We provide open-access code to implement the methods presented for two commonly-used tools for surface based cortical analysis (https://www.github.com/spin-test). This spatial permutation approach constitutes a useful advance over widely-used methods for the comparison of cortical maps, thereby opening new possibilities for the integration of diverse neuroimaging data.},
	language = {en},
	urldate = {2020-05-15},
	journal = {NeuroImage},
	author = {Alexander-Bloch, Aaron F. and Shou, Haochang and Liu, Siyuan and Satterthwaite, Theodore D. and Glahn, David C. and Shinohara, Russell T. and Vandekar, Simon N. and Raznahan, Armin},
	month = sep,
	year = {2018},
	pages = {540--551},
	file = {Alexander-Bloch et al_2018_On testing for spatial correspondence between maps of human brain structure and.pdf:/Users/tito/Zotero/storage/5AD9N9L3/Alexander-Bloch et al_2018_On testing for spatial correspondence between maps of human brain structure and.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/UHH7EAZH/S1053811918304968.html:text/html},
}

@article{hermundstad_structural_2013,
	title = {Structural foundations of resting-state and task-based functional connectivity in the human brain},
	volume = {110},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/110/15/6169},
	doi = {10.1073/pnas.1219562110},
	abstract = {Magnetic resonance imaging enables the noninvasive mapping of both anatomical white matter connectivity and dynamic patterns of neural activity in the human brain. We examine the relationship between the structural properties of white matter streamlines (structural connectivity) and the functional properties of correlations in neural activity (functional connectivity) within 84 healthy human subjects both at rest and during the performance of attention- and memory-demanding tasks. We show that structural properties, including the length, number, and spatial location of white matter streamlines, are indicative of and can be inferred from the strength of resting-state and task-based functional correlations between brain regions. These results, which are both representative of the entire set of subjects and consistently observed within individual subjects, uncover robust links between structural and functional connectivity in the human brain.},
	language = {en},
	number = {15},
	urldate = {2020-05-19},
	journal = {PNAS},
	author = {Hermundstad, Ann M. and Bassett, Danielle S. and Brown, Kevin S. and Aminoff, Elissa M. and Clewett, David and Freeman, Scott and Frithsen, Amy and Johnson, Arianne and Tipper, Christine M. and Miller, Michael B. and Grafton, Scott T. and Carlson, Jean M.},
	month = apr,
	year = {2013},
	pmid = {23530246},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {cortical networks, functional MRI, diffusion MRI},
	pages = {6169--6174},
	file = {Hermundstad et al_2013_Structural foundations of resting-state and task-based functional connectivity.pdf:/Users/tito/Zotero/storage/ILS2YKCV/Hermundstad et al_2013_Structural foundations of resting-state and task-based functional connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HAE358EV/6169.html:text/html},
}

@article{amico_centralized_2019,
	title = {Centralized and distributed cognitive task processing in the human connectome},
	volume = {3},
	issn = {2472-1751},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/netn_a_00072},
	doi = {10.1162/netn_a_00072},
	abstract = {A key question in modern neuroscience is how cognitive changes in a human brain can be quantiﬁed and captured by functional connectivity (FC). A systematic approach to measure pairwise functional distance at different brain states is lacking. This would provide a straightforward way to quantify differences in cognitive processing across tasks; also, it would help in relating these differences in task-based FCs to the underlying structural network. Here we propose a framework, based on the concept of Jensen-Shannon divergence, to map the task-rest connectivity distance between tasks and resting-state FC. We show how this information theoretical measure allows for quantifying connectivity changes in distributed and centralized processing in functional networks. We study resting state and seven tasks from the Human Connectome Project dataset to obtain the most distant links across tasks. We investigate how these changes are associated with different functional brain networks, and use the proposed measure to infer changes in the information-processing regimes.},
	language = {en},
	number = {2},
	urldate = {2020-05-19},
	journal = {Network Neuroscience},
	author = {Amico, Enrico and Arenas, Alex and Goñi, Joaquín},
	month = jan,
	year = {2019},
	pages = {455--474},
	file = {Amico et al. - 2019 - Centralized and distributed cognitive task process.pdf:/Users/tito/Zotero/storage/ZBQ6LF4N/Amico et al. - 2019 - Centralized and distributed cognitive task process.pdf:application/pdf},
}

@article{tetzlaff_decorrelation_2012,
	title = {Decorrelation of {Neural}-{Network} {Activity} by {Inhibitory} {Feedback}},
	volume = {8},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1002596},
	doi = {10.1371/journal.pcbi.1002596},
	abstract = {Correlations in spike-train ensembles can seriously impair the encoding of information by their spatio-temporal structure. An inevitable source of correlation in finite neural networks is common presynaptic input to pairs of neurons. Recent studies demonstrate that spike correlations in recurrent neural networks are considerably smaller than expected based on the amount of shared presynaptic input. Here, we explain this observation by means of a linear network model and simulations of networks of leaky integrate-and-fire neurons. We show that inhibitory feedback efficiently suppresses pairwise correlations and, hence, population-rate fluctuations, thereby assigning inhibitory neurons the new role of active decorrelation. We quantify this decorrelation by comparing the responses of the intact recurrent network (feedback system) and systems where the statistics of the feedback channel is perturbed (feedforward system). Manipulations of the feedback statistics can lead to a significant increase in the power and coherence of the population response. In particular, neglecting correlations within the ensemble of feedback channels or between the external stimulus and the feedback amplifies population-rate fluctuations by orders of magnitude. The fluctuation suppression in homogeneous inhibitory networks is explained by a negative feedback loop in the one-dimensional dynamics of the compound activity. Similarly, a change of coordinates exposes an effective negative feedback loop in the compound dynamics of stable excitatory-inhibitory networks. The suppression of input correlations in finite networks is explained by the population averaged correlations in the linear network model: In purely inhibitory networks, shared-input correlations are canceled by negative spike-train correlations. In excitatory-inhibitory networks, spike-train correlations are typically positive. Here, the suppression of input correlations is not a result of the mere existence of correlations between excitatory (E) and inhibitory (I) neurons, but a consequence of a particular structure of correlations among the three possible pairings (EE, EI, II).},
	language = {en},
	number = {8},
	urldate = {2020-05-20},
	journal = {PLoS Computational Biology},
	author = {Tetzlaff, Tom and Helias, Moritz and Einevoll, Gaute T. and Diesmann, Markus},
	editor = {Brunel, Nicolas},
	month = aug,
	year = {2012},
	pages = {e1002596},
	file = {Tetzlaff et al. - 2012 - Decorrelation of Neural-Network Activity by Inhibi.pdf:/Users/tito/Zotero/storage/RIQF7BG5/Tetzlaff et al. - 2012 - Decorrelation of Neural-Network Activity by Inhibi.pdf:application/pdf},
}

@article{shea-brown_correlation_2008,
	title = {Correlation and {Synchrony} {Transfer} in {Integrate}-and-{Fire} {Neurons}: {Basic} {Properties} and {Consequences} for {Coding}},
	volume = {100},
	shorttitle = {Correlation and {Synchrony} {Transfer} in {Integrate}-and-{Fire} {Neurons}},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.100.108102},
	doi = {10.1103/PhysRevLett.100.108102},
	abstract = {We study how pairs of neurons transfer correlated input currents into correlated spikes. Over rapid time scales, correlation transfer increases with both spike time variability and rate; the dependence on variability disappears at large time scales. This persists for a nonlinear membrane model and for heterogeneous cell pairs, but strong nonmonotonicities follow from refractory effects. We present consequences for population coding and for the encoding of time-varying stimuli.},
	number = {10},
	urldate = {2020-05-20},
	journal = {Phys. Rev. Lett.},
	author = {Shea-Brown, Eric and Josić, Krešimir and de la Rocha, Jaime and Doiron, Brent},
	month = mar,
	year = {2008},
	note = {Publisher: American Physical Society},
	pages = {108102},
	file = {APS Snapshot:/Users/tito/Zotero/storage/M9DCIVZF/PhysRevLett.100.html:text/html},
}

@article{varoquaux_atlases_2018,
	title = {Atlases of cognition with large-scale human brain mapping},
	volume = {14},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006565},
	doi = {10.1371/journal.pcbi.1006565},
	abstract = {To map the neural substrate of mental function, cognitive neuroimaging relies on controlled psychological manipulations that engage brain systems associated with specific cognitive processes. In order to build comprehensive atlases of cognitive function in the brain, it must assemble maps for many different cognitive processes, which often evoke overlapping patterns of activation. Such data aggregation faces contrasting goals: on the one hand finding correspondences across vastly different cognitive experiments, while on the other hand precisely describing the function of any given brain region. Here we introduce a new analysis framework that tackles these difficulties and thereby enables the generation of brain atlases for cognitive function. The approach leverages ontologies of cognitive concepts and multi-label brain decoding to map the neural substrate of these concepts. We demonstrate the approach by building an atlas of functional brain organization based on 30 diverse functional neuroimaging studies, totaling 196 different experimental conditions. Unlike conventional brain mapping, this functional atlas supports robust reverse inference: predicting the mental processes from brain activity in the regions delineated by the atlas. To establish that this reverse inference is indeed governed by the corresponding concepts, and not idiosyncrasies of experimental designs, we show that it can accurately decode the cognitive concepts recruited in new tasks. These results demonstrate that aggregating independent task-fMRI studies can provide a more precise global atlas of selective associations between brain and cognition.},
	language = {en},
	number = {11},
	urldate = {2020-05-21},
	journal = {PLOS Computational Biology},
	author = {Varoquaux, Gaël and Schwartz, Yannick and Poldrack, Russell A. and Gauthier, Baptiste and Bzdok, Danilo and Poline, Jean-Baptiste and Thirion, Bertrand},
	month = nov,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Neuroimaging, Language, Cognition, Vision, Brain mapping, Cognitive neurology, Face recognition, Ontologies},
	pages = {e1006565},
	file = {Snapshot:/Users/tito/Zotero/storage/CEEMZMN3/article.html:text/html;Varoquaux et al_2018_Atlases of cognition with large-scale human brain mapping.pdf:/Users/tito/Zotero/storage/23MZE24Z/Varoquaux et al_2018_Atlases of cognition with large-scale human brain mapping.pdf:application/pdf},
}

@article{haxby_hyperalignment_2020,
	title = {Hyperalignment: {Modeling} shared information encoded in idiosyncratic cortical topographies},
	volume = {9},
	issn = {2050-084X},
	shorttitle = {Hyperalignment},
	url = {https://doi.org/10.7554/eLife.56601},
	doi = {10.7554/eLife.56601},
	abstract = {Information that is shared across brains is encoded in idiosyncratic fine-scale functional topographies. Hyperalignment captures shared information by projecting pattern vectors for neural responses and connectivities into a common, high-dimensional information space, rather than by aligning topographies in a canonical anatomical space. Individual transformation matrices project information from individual anatomical spaces into the common model information space, preserving the geometry of pairwise dissimilarities between pattern vectors, and model cortical topography as mixtures of overlapping, individual-specific topographic basis functions, rather than as contiguous functional areas. The fundamental property of brain function that is preserved across brains is information content, rather than the functional properties of local features that support that content. In this Perspective, we present the conceptual framework that motivates hyperalignment, its computational underpinnings for joint modeling of a common information space and idiosyncratic cortical topographies, and discuss implications for understanding the structure of cortical functional architecture.},
	urldate = {2020-06-02},
	journal = {eLife},
	author = {Haxby, James V and Guntupalli, J Swaroop and Nastase, Samuel A and Feilong, Ma},
	editor = {Baker, Chris I and de Lange, Floris P},
	month = jun,
	year = {2020},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {functional connectivity, individual differences, cortex, topography, hyperalignment, population response},
	pages = {e56601},
	file = {Haxby et al_2020_Hyperalignment.pdf:/Users/tito/Zotero/storage/4WIANUIL/Haxby et al_2020_Hyperalignment.pdf:application/pdf},
}

@article{stern_cognitive_2012,
	title = {Cognitive reserve in ageing and {Alzheimer}'s disease},
	volume = {11},
	issn = {1474-4422},
	url = {http://www.sciencedirect.com/science/article/pii/S1474442212701916},
	doi = {10.1016/S1474-4422(12)70191-6},
	abstract = {The concept of cognitive reserve provides an explanation for differences between individuals in susceptibility to age-related brain changes or pathology related to Alzheimer's disease, whereby some people can tolerate more of these changes than others and maintain function. Epidemiological studies suggest that lifelong experiences, including educational and occupational attainment, and leisure activities in later life, can increase this reserve. For example, the risk of developing Alzheimer's disease is reduced in individuals with higher educational or occupational attainment. Reserve can conveniently be divided into two types: brain reserve, which refers to differences in the brain structure that may increase tolerance to pathology, and cognitive reserve, which refers to differences between individuals in how tasks are performed that might enable some people to be more resilient to brain changes than others. Greater understanding of the concept of cognitive reserve could lead to interventions to slow cognitive ageing or reduce the risk of dementia.},
	language = {en},
	number = {11},
	urldate = {2020-06-03},
	journal = {The Lancet Neurology},
	author = {Stern, Yaakov},
	month = nov,
	year = {2012},
	pages = {1006--1012},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/54LHQ4JA/S1474442212701916.html:text/html;Stern_2012_Cognitive reserve in ageing and Alzheimer's disease.pdf:/Users/tito/Zotero/storage/NWB33XP6/Stern_2012_Cognitive reserve in ageing and Alzheimer's disease.pdf:application/pdf},
}

@article{stern_task-invariant_2018,
	title = {A task-invariant cognitive reserve network},
	volume = {178},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918304403},
	doi = {10.1016/j.neuroimage.2018.05.033},
	abstract = {The concept of cognitive reserve (CR) can explain individual differences in susceptibility to cognitive or functional impairment in the presence of age or disease-related brain changes. Epidemiologic evidence indicates that CR helps maintain performance in the face of pathology across multiple cognitive domains. We therefore tried to identify a single, “task-invariant” CR network that is active during the performance of many disparate tasks. In imaging data acquired from 255 individuals age 20–80 while performing 12 different cognitive tasks, we used an iterative approach to derive a multivariate network that was expressed during the performance of all tasks, and whose degree of expression correlated with IQ, a proxy for CR. When applied to held out data or forward applied to fMRI data from an entirely different activation task, network expression correlated with IQ. Expression of the CR pattern accounted for additional variance in fluid reasoning performance over and above the influence of cortical thickness, and also moderated between cortical thickness and reasoning performance, consistent with the behavior of a CR network. The identification of a task-invariant CR network supports the idea that life experiences may result in brain processing differences that might provide reserve against age- or disease-related changes across multiple tasks.},
	language = {en},
	urldate = {2020-06-04},
	journal = {NeuroImage},
	author = {Stern, Yaakov and Gazes, Yunglin and Razlighi, Qolomreza and Steffener, Jason and Habeck, Christian},
	month = sep,
	year = {2018},
	keywords = {fMRI, IQ, Cognitive aging, Cortical thickness, Multivariate imaging analysis},
	pages = {36--45},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/4DN2LK9S/S1053811918304403.html:text/html;Stern et al_2018_A task-invariant cognitive reserve network.pdf:/Users/tito/Zotero/storage/JLDT7WZY/Stern et al_2018_A task-invariant cognitive reserve network.pdf:application/pdf},
}

@article{van_loenhoud_identifying_2020,
	title = {Identifying a task-invariant cognitive reserve network using task potency},
	volume = {210},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381192030080X},
	doi = {10.1016/j.neuroimage.2020.116593},
	abstract = {Cognitive reserve (CR) is thought to protect against the consequence of age- or disease-related structural brain changes across multiple cognitive domains. The neural basis of CR may therefore comprise a functional network that is actively involved in many different cognitive processes. To investigate the existence of such a “task-invariant” CR network, we measured functional connectivity in a cognitively normal sample between 20 and 80 years old (N ​= ​265), both at rest and during the performance of 11 separate tasks that aim to capture four latent cognitive abilities (i.e. vocabulary, episodic memory, processing speed, and fluid reasoning). For each individual, we determined the change in functional connectivity from the resting state to each task state, which is referred to as “task potency” (Chauvin et al., 2018, 2019). Task potency was calculated for each pair among 264 nodes (Power et al., 2012) and then summarized across tasks reflecting the same cognitive ability. Subsequently, we established the correlation between task potency and IQ or education (i.e. CR factors). We identified a set of 57 pairs in which task potency showed significant correlations with IQ, but not education, across all four cognitive abilities. These pairs were included in a principal component analysis, from which we extracted the first component to obtain a latent variable reflecting task potency in this task-invariant CR network. This task potency variable was associated with better episodic memory (β ​= ​0.19, p ​{\textless} ​.01) and fluid reasoning performance (β ​= ​0.17, p ​{\textless} ​.01) above and beyond the effects of cortical thickness (range [absolute] β ​= ​0.28-0.32, p ​{\textless} ​.001). Our identification of this task-invariant network contributes to a better understanding of the mechanism underlying CR, which may facilitate the development of CR-enhancing treatments. Our work also offers a useful alternative operational measure of CR for future studies.},
	language = {en},
	urldate = {2020-06-04},
	journal = {NeuroImage},
	author = {van Loenhoud, A. C. and Habeck, C. and van der Flier, W. M. and Ossenkoppele, R. and Stern, Y.},
	month = apr,
	year = {2020},
	keywords = {fMRI, IQ, Cognitive aging, Cortical thickness, Cognitive reserve},
	pages = {116593},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/B7W7QQ6Z/S105381192030080X.html:text/html;van Loenhoud et al_2020_Identifying a task-invariant cognitive reserve network using task potency.pdf:/Users/tito/Zotero/storage/LXTTDITA/van Loenhoud et al_2020_Identifying a task-invariant cognitive reserve network using task potency.pdf:application/pdf},
}

@article{dasgupta_meta-reinforcement_nodate,
	title = {Meta-reinforcement learning of causal strategies},
	abstract = {Discovering and exploiting the causal structure in the environment is a crucial challenge for intelligent agents. However, it is not understood how such reasoning comes about, even in natural intelligence. Here, we investigate the emergence of causal reasoning and intervention strategies from simpler reinforcement learning algorithms using a meta-reinforcement learning framework. We ﬁnd that, after training on distributions of environments having causal structure, meta-learning agents learn to perform a form of causal reasoning in related, held-out tasks. In particular, we ﬁnd that the form of causal reasoning learned relates to the information encountered during learning, ranging from causal inference from observations, to resolving confounders, selecting informative interventions, and making counterfactual predictions. Empirical ﬁndings in human behavioral research suggest promising connections between our model and the development and implementation of causal reasoning in humans.},
	language = {en},
	author = {Dasgupta, Ishita and Kurth-Nelson, Zeb and Chiappa, Silvia and Mitrovic, Jovana and Ortega, Pedro and Hughes, Edward and Botvinick, Matthew and Wang, Jane},
	pages = {16},
	file = {Dasgupta et al. - Meta-reinforcement learning of causal strategies.pdf:/Users/tito/Zotero/storage/TI72IMM4/Dasgupta et al. - Meta-reinforcement learning of causal strategies.pdf:application/pdf},
}

@article{elliott_what_2020,
	title = {What {Is} the {Test}-{Retest} {Reliability} of {Common} {Task}-{Functional} {MRI} {Measures}? {New} {Empirical} {Evidence} and a {Meta}-{Analysis}},
	issn = {0956-7976},
	shorttitle = {What {Is} the {Test}-{Retest} {Reliability} of {Common} {Task}-{Functional} {MRI} {Measures}?},
	url = {https://doi.org/10.1177/0956797620916786},
	doi = {10.1177/0956797620916786},
	abstract = {Identifying brain biomarkers of disease risk is a growing priority in neuroscience. The ability to identify meaningful biomarkers is limited by measurement reliability; unreliable measures are unsuitable for predicting clinical outcomes. Measuring brain activity using task functional MRI (fMRI) is a major focus of biomarker development; however, the reliability of task fMRI has not been systematically evaluated. We present converging evidence demonstrating poor reliability of task-fMRI measures. First, a meta-analysis of 90 experiments (N = 1,008) revealed poor overall reliability?mean intraclass correlation coefficient (ICC) = .397. Second, the test-retest reliabilities of activity in a priori regions of interest across 11 common fMRI tasks collected by the Human Connectome Project (N = 45) and the Dunedin Study (N = 20) were poor (ICCs = .067?.485). Collectively, these findings demonstrate that common task-fMRI measures are not currently suitable for brain biomarker discovery or for individual-differences research. We review how this state of affairs came to be and highlight avenues for improving task-fMRI reliability.},
	urldate = {2020-06-05},
	journal = {Psychol Sci},
	author = {Elliott, Maxwell L. and Knodt, Annchen R. and Ireland, David and Morris, Meriwether L. and Poulton, Richie and Ramrakha, Sandhya and Sison, Maria L. and Moffitt, Terrie E. and Caspi, Avshalom and Hariri, Ahmad R.},
	month = jun,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {0956797620916786},
	file = {Elliott et al_2020_What Is the Test-Retest Reliability of Common Task-Functional MRI Measures.pdf:/Users/tito/Zotero/storage/LKKW4W4S/Elliott et al_2020_What Is the Test-Retest Reliability of Common Task-Functional MRI Measures.pdf:application/pdf},
}

@article{dasgupta_meta-reinforcement_nodate-1,
	title = {Meta-reinforcement learning of causal strategies},
	author = {Dasgupta, Ishita and Kurth-Nelson, Zeb and Chiappa, Silvia and Mitrovic, Jovana and Ortega, Pedro and Hughes, Edward and Botvinick, Matthew and Wang, Jane},
	file = {Dasgupta et al_Meta-reinforcement learning of causal strategies.pdf:/Users/tito/Zotero/storage/42TIGXPD/Dasgupta et al_Meta-reinforcement learning of causal strategies.pdf:application/pdf},
}

@article{dasgupta_causal_2019,
	title = {Causal {Reasoning} from {Meta}-reinforcement {Learning}},
	url = {http://arxiv.org/abs/1901.08162},
	abstract = {Discovering and exploiting the causal structure in the environment is a crucial challenge for intelligent agents. Here we explore whether causal reasoning can emerge via meta-reinforcement learning. We train a recurrent network with model-free reinforcement learning to solve a range of problems that each contain causal structure. We find that the trained agent can perform causal reasoning in novel situations in order to obtain rewards. The agent can select informative interventions, draw causal inferences from observational data, and make counterfactual predictions. Although established formal causal reasoning algorithms also exist, in this paper we show that such reasoning can arise from model-free reinforcement learning, and suggest that causal reasoning in complex settings may benefit from the more end-to-end learning-based approaches presented here. This work also offers new strategies for structured exploration in reinforcement learning, by providing agents with the ability to perform -- and interpret -- experiments.},
	urldate = {2020-06-05},
	journal = {arXiv:1901.08162 [cs, stat]},
	author = {Dasgupta, Ishita and Wang, Jane and Chiappa, Silvia and Mitrovic, Jovana and Ortega, Pedro and Raposo, David and Hughes, Edward and Battaglia, Peter and Botvinick, Matthew and Kurth-Nelson, Zeb},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.08162},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/LC36VYN6/1901.html:text/html;Dasgupta et al_2019_Causal Reasoning from Meta-reinforcement Learning.pdf:/Users/tito/Zotero/storage/8I6L73QC/Dasgupta et al_2019_Causal Reasoning from Meta-reinforcement Learning.pdf:application/pdf},
}

@article{lin_equations_2020,
	title = {Equations governing dynamics of excitation and inhibition in the mouse corticothalamic network},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.06.03.132688v1},
	doi = {10.1101/2020.06.03.132688},
	abstract = {{\textless}p{\textgreater}Although cortical circuits are complex and interconnected with the rest of the brain, their macroscopic dynamics are often approximated by modeling the averaged activities of excitatory and inhibitory cortical neurons, without interactions with other brain circuits. To verify the validity of such mean-field models, we optogenetically stimulated populations of excitatory and parvalbumin-expressing inhibitory neurons in awake mouse visual cortex, while recording population activity in cortex and in its thalamic correspondent, the lateral geniculate nucleus. The cortical responses to brief test pulses could not be explained by a mean-field model including only cortical excitatory and inhibitory populations. However, these responses could be predicted by extending the model to include thalamic interactions that cause net cortical suppression following activation of cortical excitatory neurons. We conclude that mean-field models can accurately summarize cortical dynamics, but only when the cortex is considered as part of a dynamic corticothalamic network.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-06-05},
	journal = {bioRxiv},
	author = {Lin, I.-Chun and Okun, Michael and Carandini, Matteo and Harris, Kenneth D.},
	month = jun,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.06.03.132688},
	file = {Lin et al_2020_Equations governing dynamics of excitation and inhibition in the mouse.pdf:/Users/tito/Zotero/storage/SEVNK58H/Lin et al_2020_Equations governing dynamics of excitation and inhibition in the mouse.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/RVKAJUXV/2020.06.03.html:text/html},
}

@article{spreng_shifting_2019,
	title = {The {Shifting} {Architecture} of {Cognition} and {Brain} {Function} in {Older} {Adulthood}},
	volume = {14},
	issn = {1745-6916},
	url = {https://doi.org/10.1177/1745691619827511},
	doi = {10.1177/1745691619827511},
	abstract = {Cognitive aging is often described in the context of loss or decline. Emerging research suggests that the story is more complex, with older adults showing both losses and gains in cognitive ability. With increasing age, declines in controlled, or fluid, cognition occur in the context of gains in crystallized knowledge of oneself and the world. This inversion in cognitive capacities, from greater reliance on fluid abilities in young adulthood to increasingly crystallized or semanticized cognition in older adulthood, has profound implications for cognitive and real-world functioning in later life. The shift in cognitive architecture parallels changes in the functional network architecture of the brain. Observations of greater functional connectivity between lateral prefrontal brain regions, implicated in cognitive control, and the default network, implicated in memory and semantic processing, led us to propose the default-executive coupling hypothesis of aging. In this review we provide evidence that these changes in the functional architecture of the brain serve as a neural mechanism underlying the shifting cognitive architecture from younger to older adulthood. We incorporate findings spanning cognitive aging and cognitive neuroscience to present an integrative model of cognitive and brain aging, describing its antecedents, determinants, and implications for real-world functioning.},
	language = {en},
	number = {4},
	urldate = {2020-06-08},
	journal = {Perspect Psychol Sci},
	author = {Spreng, R. Nathan and Turner, Gary R.},
	month = jul,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	pages = {523--542},
	file = {Spreng_Turner_2019_The Shifting Architecture of Cognition and Brain Function in Older Adulthood.pdf:/Users/tito/Zotero/storage/S4BE67GM/Spreng_Turner_2019_The Shifting Architecture of Cognition and Brain Function in Older Adulthood.pdf:application/pdf},
}

@article{betzel_non-assortative_2018,
	title = {Non-assortative community structure in resting and task-evoked functional brain networks},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/355016v1},
	doi = {10.1101/355016},
	abstract = {{\textless}p{\textgreater}Brain networks exhibit community structure that reconfigures during cognitively demanding tasks. Extant work has emphasized a single class of communities: those that are assortative, or internally dense and externally sparse. Other classes that may play key functional roles in brain function have largely been ignored, leading to an impoverished view in the best case and a mischaracterization in the worst case. Here, we leverage weighted stochastic blockmodeling, a community detection method capable of detecting diverse classes of communities, to study the community structure of functional brain networks while subjects either rest or perform cognitively demanding tasks. We find evidence that the resting brain is largely assortative, although higher order association areas exhibit non-assortative organization, forming cores and peripheries. Surprisingly, this assortative structure breaks down during tasks and is supplanted by core, periphery, and disassortative communities. Using measures derived from the community structure, we show that it is possible to classify an individual’s task state with an accuracy that is well above average. Finally, we show that inter-individual differences in the composition of assortative and non-assortative communities is correlated with subject performance on in-scanner cognitive tasks. These findings offer a new perspective on the community organization of functional brain networks and its relation to cognition.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-06-09},
	journal = {bioRxiv},
	author = {Betzel, Richard F. and Bertolero, Maxwell A. and Bassett, Danielle S.},
	month = jun,
	year = {2018},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {355016},
	file = {Betzel et al_2018_Non-assortative community structure in resting and task-evoked functional brain.pdf:/Users/tito/Zotero/storage/TJHX346T/Betzel et al_2018_Non-assortative community structure in resting and task-evoked functional brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WB9TZP7E/355016v1.html:text/html},
}

@article{sanchez-romero_combining_2020,
	title = {Combining {Multiple} {Functional} {Connectivity} {Methods} to {Improve} {Causal} {Inferences}},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/jocn_a_01580},
	doi = {10.1162/jocn_a_01580},
	abstract = {Cognition and behavior emerge from brain network interactions, suggesting that causal interactions should be central to the study of brain function. Yet, approaches that characterize relationships among neural time series—functional connectivity (FC) methods—are dominated by methods that assess bivariate statistical associations rather than causal interactions. Such bivariate approaches result in substantial false positives because they do not account for confounders (common causes) among neural populations. A major reason for the dominance of methods such as bivariate Pearson correlation (with functional MRI) and coherence (with electrophysiological methods) may be their simplicity. Thus, we sought to identify an FC method that was both simple and improved causal inferences relative to the most popular methods. We started with partial correlation, showing with neural network simulations that this substantially improves causal inferences relative to bivariate correlation. However, the presence of colliders (common effects) in a network resulted in false positives with partial correlation, although this was not a problem for bivariate correlations. This led us to propose a new combined FC method (combinedFC) that incorporates simple bivariate and partial correlation FC measures to make more valid causal inferences than either alone. We release a toolbox for implementing this new combinedFC method to facilitate improvement of FC-based causal inferences. CombinedFC is a general method for FC and can be applied equally to resting-state and task-based paradigms.},
	urldate = {2020-06-09},
	journal = {Journal of Cognitive Neuroscience},
	author = {Sanchez-Romero, Ruben and Cole, Michael W.},
	month = may,
	year = {2020},
	note = {Publisher: MIT Press},
	pages = {1--15},
	file = {Sanchez-Romero_Cole_2020_Combining Multiple Functional Connectivity Methods to Improve Causal Inferences.pdf:/Users/tito/Zotero/storage/4V6NHH5W/Sanchez-Romero_Cole_2020_Combining Multiple Functional Connectivity Methods to Improve Causal Inferences.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GYSMISZJ/jocn_a_01580.html:text/html},
}

@article{ritter_rapid_2020,
	title = {Rapid {Task}-{Solving} in {Novel} {Environments}},
	url = {http://arxiv.org/abs/2006.03662},
	abstract = {When thrust into an unfamiliar environment and charged with solving a series of tasks, an effective agent should (1) leverage prior knowledge to solve its current task while (2) efficiently exploring to gather knowledge for use in future tasks, and then (3) plan using that knowledge when faced with new tasks in that same environment. We introduce two domains for conducting research on this challenge, and find that state-of-the-art deep reinforcement learning (RL) agents fail to plan in novel environments. We develop a recursive implicit planning module that operates over episodic memories, and show that the resulting deep-RL agent is able to explore and plan in novel environments, outperforming the nearest baseline by factors of 2-3 across the two domains. We find evidence that our module (1) learned to execute a sensible information-propagating algorithm and (2) generalizes to situations beyond its training experience.},
	urldate = {2020-06-15},
	journal = {arXiv:2006.03662 [cs, stat]},
	author = {Ritter, Sam and Faulkner, Ryan and Sartran, Laurent and Santoro, Adam and Botvinick, Matt and Raposo, David},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.03662},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/39C8AUQW/2006.html:text/html;Ritter et al_2020_Rapid Task-Solving in Novel Environments.pdf:/Users/tito/Zotero/storage/FCG5MNMW/Ritter et al_2020_Rapid Task-Solving in Novel Environments.pdf:application/pdf},
}

@article{yu_prediction_2020,
	title = {Prediction with directed transitions: complex eigenstructure, grid cells and phase coding},
	shorttitle = {Prediction with directed transitions},
	url = {http://arxiv.org/abs/2006.03355},
	abstract = {Markovian tasks can be characterised by a state space and a transition matrix. In mammals, the firing of populations of place or grid cells in the hippocampal formation are thought to represent the probability distribution over state space. Grid firing patterns are suggested to be eigenvectors of a transition matrix reflecting diffusion across states, allowing simple prediction of future state distributions, by replacing matrix multiplication with elementwise multiplication by eigenvalues. Here we extend this analysis to any translation-invariant directed transition structure (displacement and diffusion), showing that a single set of eigenvectors supports prediction via displacement-specific eigenvalues. This unifies the prediction framework with traditional models of grid cells firing driven by self-motion to perform path integration. We show that the complex eigenstructure of directed transitions corresponds to the Discrete Fourier Transform, the eigenvalues encode displacement via the Fourier Shift Theorem, and the Fourier components are analogous to "velocity-controlled oscillators" in oscillatory interference models. The resulting model supports computationally efficient prediction with directed transitions in spatial and non-spatial tasks and provides an explanation for theta phase precession and path integration in grid cell firing. We also discuss the efficient generalisation of our approach to deal with local changes in transition structure and its contribution to behavioural policy via a "sense of direction" corresponding to prediction of the effects of fixed ratios of actions.},
	urldate = {2020-06-15},
	journal = {arXiv:2006.03355 [cs, q-bio]},
	author = {Yu, Changmin and Behrens, Timothy E. J. and Burgess, Neil},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.03355},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning},
	annote = {Comment: 19 pages, 11 figures; submitted to the Thirty-fourth Conference on Neural Information Processing Systems},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/F4LXDRTA/2006.html:text/html;Yu et al_2020_Prediction with directed transitions.pdf:/Users/tito/Zotero/storage/7CNPDIHU/Yu et al_2020_Prediction with directed transitions.pdf:application/pdf},
}

@article{ju_dynamic_2020,
	title = {Dynamic representations in networked neural systems},
	copyright = {2020 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-020-0653-3},
	doi = {10.1038/s41593-020-0653-3},
	abstract = {A group of neurons can generate patterns of activity that represent information about stimuli; subsequently, the group can transform and transmit activity patterns across synapses to spatially distributed areas. Recent studies in neuroscience have begun to independently address the two components of information processing: the representation of stimuli in neural activity and the transmission of information in networks that model neural interactions. Yet only recently are studies seeking to link these two types of approaches. Here we briefly review the two separate bodies of literature; we then review the recent strides made to address this gap. We continue with a discussion of how patterns of activity evolve from one representation to another, forming dynamic representations that unfold on the underlying network. Our goal is to offer a holistic framework for understanding and describing neural information representation and transmission while revealing exciting frontiers for future research.},
	language = {en},
	urldate = {2020-06-15},
	journal = {Nature Neuroscience},
	author = {Ju, Harang and Bassett, Danielle S.},
	month = jun,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--10},
	file = {Ju_Bassett_2020_Dynamic representations in networked neural systems.pdf:/Users/tito/Zotero/storage/W29ZRXY4/Ju_Bassett_2020_Dynamic representations in networked neural systems.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/W9LLLASH/s41593-020-0653-3.html:text/html},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2020-06-17},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DNSYFWRS/1412.html:text/html;Kingma_Ba_2017_Adam.pdf:/Users/tito/Zotero/storage/4LHVAADA/Kingma_Ba_2017_Adam.pdf:application/pdf},
}

@article{hasson_direct_2020,
	title = {Direct {Fit} to {Nature}: {An} {Evolutionary} {Perspective} on {Biological} and {Artificial} {Neural} {Networks}},
	volume = {105},
	issn = {0896-6273},
	shorttitle = {Direct {Fit} to {Nature}},
	url = {http://www.sciencedirect.com/science/article/pii/S089662731931044X},
	doi = {10.1016/j.neuron.2019.12.002},
	abstract = {Evolution is a blind fitting process by which organisms become adapted to their environment. Does the brain use similar brute-force fitting processes to learn how to perceive and act upon the world? Recent advances in artificial neural networks have exposed the power of optimizing millions of synaptic weights over millions of observations to operate robustly in real-world contexts. These models do not learn simple, human-interpretable rules or representations of the world; rather, they use local computations to interpolate over task-relevant manifolds in a high-dimensional parameter space. Counterintuitively, similar to evolutionary processes, over-parameterized models can be simple and parsimonious, as they provide a versatile, robust solution for learning a diverse set of functions. This new family of direct-fit models present a radical challenge to many of the theoretical assumptions in psychology and neuroscience. At the same time, this shift in perspective establishes unexpected links with developmental and ecological psychology.},
	language = {en},
	number = {3},
	urldate = {2020-06-18},
	journal = {Neuron},
	author = {Hasson, Uri and Nastase, Samuel A. and Goldstein, Ariel},
	month = feb,
	year = {2020},
	keywords = {neural networks, learning, evolution, experimental design, interpolation},
	pages = {416--434},
	file = {Hasson et al_2020_Direct Fit to Nature.pdf:/Users/tito/Zotero/storage/P4T28PKN/Hasson et al_2020_Direct Fit to Nature.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/DEM4ZU4H/S089662731931044X.html:text/html},
}

@article{mur_revealing_2009,
	title = {Revealing representational content with pattern-information {fMRI}—an introductory guide},
	volume = {4},
	issn = {1749-5016},
	url = {https://academic.oup.com/scan/article/4/1/101/1613450},
	doi = {10.1093/scan/nsn044},
	abstract = {Abstract.  Conventional statistical analysis methods for functional magnetic resonance imaging (fMRI) data are very successful at detecting brain regions that a},
	language = {en},
	number = {1},
	urldate = {2020-06-18},
	journal = {Soc Cogn Affect Neurosci},
	author = {Mur, Marieke and Bandettini, Peter A. and Kriegeskorte, Nikolaus},
	month = mar,
	year = {2009},
	note = {Publisher: Oxford Academic},
	pages = {101--109},
	file = {Mur et al_2009_Revealing representational content with pattern-information fMRI—an.pdf:/Users/tito/Zotero/storage/ZVHZQTTV/Mur et al_2009_Revealing representational content with pattern-information fMRI—an.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6WGSX38X/1613450.html:text/html},
}

@article{yang_artificial_2020,
	title = {Artificial neural networks for neuroscientists: {A} primer},
	shorttitle = {Artificial neural networks for neuroscientists},
	url = {http://arxiv.org/abs/2006.01001},
	abstract = {Artificial neural networks (ANNs) are essential tools in machine learning that are increasingly used for building computational models in neuroscience. Besides being powerful techniques for data analysis, ANNs provide a new approach for neuroscientists to build models that capture complex behaviors, neural activity and connectivity, as well as to explore optimization in neural systems. In this pedagogical Primer, we introduce conventional ANNs and demonstrate how they have been deployed to study neuroscience questions. Next, we detail how to customize the analysis, structure, and learning of ANNs to better address a wide range of challenges in brain research. To help the readers garner hands-on experience, this Primer is accompanied with tutorial-style code in PyTorch and Jupyter Notebook, covering major topics.},
	urldate = {2020-06-22},
	journal = {arXiv:2006.01001 [cs, q-bio]},
	author = {Yang, Guangyu Robert and Wang, Xiao-Jing},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.01001},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/I938MIWG/2006.html:text/html;Yang_Wang_2020_Artificial neural networks for neuroscientists.pdf:/Users/tito/Zotero/storage/UZ9WQLQL/Yang_Wang_2020_Artificial neural networks for neuroscientists.pdf:application/pdf},
}

@article{bengio_meta-transfer_2019,
	title = {A {Meta}-{Transfer} {Objective} for {Learning} to {Disentangle} {Causal} {Mechanisms}},
	url = {http://arxiv.org/abs/1901.10912},
	abstract = {We propose to meta-learn causal structures based on how fast a learner adapts to new distributions arising from sparse distributional changes, e.g. due to interventions, actions of agents and other sources of non-stationarities. We show that under this assumption, the correct causal structural choices lead to faster adaptation to modified distributions because the changes are concentrated in one or just a few mechanisms when the learned knowledge is modularized appropriately. This leads to sparse expected gradients and a lower effective number of degrees of freedom needing to be relearned while adapting to the change. It motivates using the speed of adaptation to a modified distribution as a meta-learning objective. We demonstrate how this can be used to determine the cause-effect relationship between two observed variables. The distributional changes do not need to correspond to standard interventions (clamping a variable), and the learner has no direct knowledge of these interventions. We show that causal structures can be parameterized via continuous variables and learned end-to-end. We then explore how these ideas could be used to also learn an encoder that would map low-level observed variables to unobserved causal variables leading to faster adaptation out-of-distribution, learning a representation space where one can satisfy the assumptions of independent mechanisms and of small and sparse changes in these mechanisms due to actions and non-stationarities.},
	urldate = {2020-06-23},
	journal = {arXiv:1901.10912 [cs, stat]},
	author = {Bengio, Yoshua and Deleu, Tristan and Rahaman, Nasim and Ke, Rosemary and Lachapelle, Sébastien and Bilaniuk, Olexa and Goyal, Anirudh and Pal, Christopher},
	month = feb,
	year = {2019},
	note = {arXiv: 1901.10912},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/TTSYM77J/1901.html:text/html;Bengio et al_2019_A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms.pdf:/Users/tito/Zotero/storage/BSHENN98/Bengio et al_2019_A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms.pdf:application/pdf},
}

@article{oreilly_computational_2010,
	series = {Cognitive neuroscience},
	title = {Computational models of cognitive control},
	volume = {20},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438810000097},
	doi = {10.1016/j.conb.2010.01.008},
	abstract = {Cognitive control refers to the ability to perform task-relevant processing in the face of other distractions or other forms of interference, in the absence of strong environmental support. It depends on the integrity of the prefrontal cortex and associated biological structures (e.g., the basal ganglia). Computational models have played an influential role in developing our understanding of this system, and we review current developments in three major areas: dynamic gating of prefrontal representations, hierarchies in the prefrontal cortex, and reward, motivation, and goal-related processing in prefrontal cortex. Models in these and other areas are advancing the field further forward.},
	language = {en},
	number = {2},
	urldate = {2020-06-26},
	journal = {Current Opinion in Neurobiology},
	author = {O’Reilly, Randall C and Herd, Seth A and Pauli, Wolfgang M},
	month = apr,
	year = {2010},
	pages = {257--261},
	file = {O’Reilly et al_2010_Computational models of cognitive control.pdf:/Users/tito/Zotero/storage/59EKNALD/O’Reilly et al_2010_Computational models of cognitive control.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/MGNHEMGT/S0959438810000097.html:text/html},
}

@article{uddin_bring_2020,
	title = {Bring the {Noise}: {Reconceptualizing} {Spontaneous} {Neural} {Activity}},
	issn = {1364-6613},
	shorttitle = {Bring the {Noise}},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661320301443},
	doi = {10.1016/j.tics.2020.06.003},
	abstract = {Definitions of what constitutes the ‘signal of interest’ in neuroscience can be controversial, due in part to continuously evolving notions regarding the significance of spontaneous neural activity. This review highlights how the challenge of separating brain signal from noise has led to new conceptualizations of brain functional organization at both the micro- and macroscopic level. Recent debates in the functional neuroimaging community surrounding artifact removal processes have revived earlier discussions surrounding how to appropriately isolate and measure neuronal signals against a background of noise from various sources. Insights from electrophysiological studies and computational modeling can inform current theory and data analytic practices in human functional neuroimaging, given that signal and noise may be inextricably linked in the brain.},
	language = {en},
	urldate = {2020-06-27},
	journal = {Trends in Cognitive Sciences},
	author = {Uddin, Lucina Q.},
	month = jun,
	year = {2020},
	keywords = {dynamical system, global signal regression, resting state fMRI, artifact removal, brain signal variability, spontaneous neural activity},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/TKT2U8GF/S1364661320301443.html:text/html;Uddin_2020_Bring the Noise.pdf:/Users/tito/Zotero/storage/PN9YLLWF/Uddin_2020_Bring the Noise.pdf:application/pdf},
}

@article{kleinfeld_can_2019,
	title = {Can {One} {Concurrently} {Record} {Electrical} {Spikes} from {Every} {Neuron} in a {Mammalian} {Brain}?},
	volume = {103},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(19)30695-6},
	doi = {10.1016/j.neuron.2019.08.011},
	language = {English},
	number = {6},
	urldate = {2020-06-30},
	journal = {Neuron},
	author = {Kleinfeld, David and Luan, Lan and Mitra, Partha P. and Robinson, Jacob T. and Sarpeshkar, Rahul and Shepard, Kenneth and Xie, Chong and Harris, Timothy D.},
	month = sep,
	year = {2019},
	pmid = {31495645},
	note = {Publisher: Elsevier},
	keywords = {cortex, connectomics, action potentials, electrodes, multisite recording, neurocomputation},
	pages = {1005--1015},
	file = {Kleinfeld et al_2019_Can One Concurrently Record Electrical Spikes from Every Neuron in a Mammalian.pdf:/Users/tito/Zotero/storage/H5N7XC6L/Kleinfeld et al_2019_Can One Concurrently Record Electrical Spikes from Every Neuron in a Mammalian.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/K5S5PRQS/S0896-6273(19)30695-6.html:text/html},
}

@misc{noauthor_toward_nodate,
	title = {{TOWARD} {A} {CONNECTIVITY} {GRADIENT}-{BASED} {FRAMEWORK} {FOR} {REPRODUCIBLE} {BIOMARKER} {DISCOVERY} {\textbar} {bioRxiv}},
	url = {https://www.biorxiv.org/content/10.1101/2020.04.15.043315v1.full},
	urldate = {2020-07-01},
	file = {TOWARD A CONNECTIVITY GRADIENT-BASED FRAMEWORK FOR REPRODUCIBLE BIOMARKER DISCOVERY | bioRxiv:/Users/tito/Zotero/storage/CXJWARJF/2020.04.15.043315v1.html:text/html},
}

@article{russo_neural_2020,
	title = {Neural {Trajectories} in the {Supplementary} {Motor} {Area} and {Motor} {Cortex} {Exhibit} {Distinct} {Geometries}, {Compatible} with {Different} {Classes} of {Computation}},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627320303664},
	doi = {10.1016/j.neuron.2020.05.020},
	abstract = {The supplementary motor area (SMA) is believed to contribute to higher order aspects of motor control. We considered a key higher order role: tracking progress throughout an action. We propose that doing so requires population activity to display low "trajectory divergence": situations with different future motor outputs should be distinct, even when present motor output is identical. We examined neural activity in SMA and primary motor cortex (M1) as monkeys cycled various distances through a virtual environment. SMA exhibited multiple response features that were absent in M1. At the single-neuron level, these included ramping firing rates and cycle-specific responses. At the population level, they included a helical population-trajectory geometry with shifts in the occupied subspace as movement unfolded. These diverse features all served to reduce trajectory divergence, which was much lower in SMA versus M1. Analogous population-trajectory geometry, also with low divergence, naturally arose in networks trained to internally guide multi-cycle movement.},
	language = {en},
	urldate = {2020-07-01},
	journal = {Neuron},
	author = {Russo, Abigail A. and Khajeh, Ramin and Bittner, Sean R. and Perkins, Sean M. and Cunningham, John P. and Abbott, L. F. and Churchland, Mark M.},
	month = jun,
	year = {2020},
	keywords = {recurrent neural network, population coding, motor control, neural dynamics, motor cortex, neural computation, population geometry, supplementary motor area},
	file = {Russo et al_2020_Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit.pdf:/Users/tito/Zotero/storage/SV3QV3DI/Russo et al_2020_Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/4L94ERL2/S0896627320303664.html:text/html},
}

@article{pervaiz_optimising_2020,
	title = {Optimising network modelling methods for {fMRI}},
	volume = {211},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920300914},
	doi = {10.1016/j.neuroimage.2020.116604},
	abstract = {A major goal of neuroimaging studies is to develop predictive models to analyze the relationship between whole brain functional connectivity patterns and behavioural traits. However, there is no single widely-accepted standard pipeline for analyzing functional connectivity. The common procedure for designing functional connectivity based predictive models entails three main steps: parcellating the brain, estimating the interaction between defined parcels, and lastly, using these integrated associations between brain parcels as features fed to a classifier for predicting non-imaging variables e.g., behavioural traits, demographics, emotional measures, etc. There are also additional considerations when using correlation-based measures of functional connectivity, resulting in three supplementary steps: utilising Riemannian geometry tangent space parameterization to preserve the geometry of functional connectivity; penalizing the connectivity estimates with shrinkage approaches to handle challenges related to short time-series (and noisy) data; and removing confounding variables from brain-behaviour data. These six steps are contingent on each-other, and to optimise a general framework one should ideally examine these various methods simultaneously. In this paper, we investigated strengths and short-comings, both independently and jointly, of the following measures: parcellation techniques of four kinds (categorized further depending upon number of parcels), five measures of functional connectivity, the decision of staying in the ambient space of connectivity matrices or in tangent space, the choice of applying shrinkage estimators, six alternative techniques for handling confounds and finally four novel classifiers/predictors. For performance evaluation, we have selected two of the largest datasets, UK Biobank and the Human Connectome Project resting state fMRI data, and have run more than 9000 different pipeline variants on a total of ∼14000 individuals to determine the optimum pipeline. For independent performance validation, we have run some best-performing pipeline variants on ABIDE and ACPI datasets (∼1000 subjects) to evaluate the generalisability of proposed network modelling methods.},
	language = {en},
	urldate = {2020-07-01},
	journal = {NeuroImage},
	author = {Pervaiz, Usama and Vidaurre, Diego and Woolrich, Mark W. and Smith, Stephen M.},
	month = may,
	year = {2020},
	keywords = {Connectome, Deep learning, Convolutional neural networks, Functional Connectivity, Netmat, Riemannian geometry},
	pages = {116604},
	file = {Pervaiz et al_2020_Optimising network modelling methods for fMRI.pdf:/Users/tito/Zotero/storage/3QSUSZTN/Pervaiz et al_2020_Optimising network modelling methods for fMRI.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/YHB3GAVT/S1053811920300914.html:text/html},
}

@article{eliasmith_computation_1997,
	title = {Computation and {Dynamical} {Models} of {Mind}},
	volume = {7},
	issn = {1572-8641},
	url = {https://doi.org/10.1023/A:1008296514437},
	doi = {10.1023/A:1008296514437},
	abstract = {Van Gelder (1995) has recently spearheaded a movement to challenge the dominance of connectionist and classicist models in cognitive science. The dynamical conception of cognition is van Gelder's replacement for the computation bound paradigms provided by connectionism and classicism. He relies on the Watt governor to fulfill the role of a dynamicist Turing machine and claims that the Motivational Oscillatory Theory (MOT) provides a sound empirical basis for dynamicism. In other words, the Watt governor is to be the theoretical exemplar of the class of systems necessary for cognition and MOT is an empirical instantiation of that class. However, I shall argue that neither the Watt governor nor MOT successfully fulfill these prescribed roles. This failure, along with van Gelder's peculiar use of the concept of computation and his struggle with representationalism, prevent him from providing a convincing alternative to current cognitive theories.},
	language = {en},
	number = {4},
	urldate = {2020-07-01},
	journal = {Minds and Machines},
	author = {Eliasmith, Chris},
	month = nov,
	year = {1997},
	pages = {531--541},
	file = {Eliasmith_1997_Computation and Dynamical Models of Mind.pdf:/Users/tito/Zotero/storage/24QIILKB/Eliasmith_1997_Computation and Dynamical Models of Mind.pdf:application/pdf},
}

@article{conklin_organization_2020,
	title = {Organization of {Areal} {Connectivity} in the {Monkey} {Frontoparietal} {Network}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.06.30.178244v1},
	doi = {10.1101/2020.06.30.178244},
	abstract = {{\textless}p{\textgreater}Anatomical connectivity between cortical areas condition the set of observable functional activity in a neural network. The large-scale cortical monkey frontoparietal network (FPN) has been shown to facilitate complex cognitive functions. However, the organization of anatomical connectivity between areas in the FPN supporting such function is unknown. Here, a new connectivity matrix is proposed which shows the FPN utilizes a small-world architecture with an over-reliance on the M9 dynamical relay 3-node motif and degree distributions which can be characterized as single scale. The FPN uses its small-world architecture to achieve the kind of simultaneous integration and specialization of function which cognitive functions like attention and working memory require. Contrary to many real-world networks, the in and out single scale degree distributions illustrate the relatively homogeneous connectivity of each area in the FPN, suggesting an absence of hubs. Crucially, the M9 dynamical relay motif is the optimal arrangement for previously reported near-zero and non-zero phase synchrony to propagate through the network, serving as a candidate topological mechanism. These results signify the impact of the organization of anatomical connectivity in the FPN. They can serve as a benchmark to be used in the network-level treatment of neurological disorders where the types of cognition the FPN supports are impaired. Additionally, they can inform future neuromorphic circuit designs which aim to perform aspects of cognition.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-07-02},
	journal = {bioRxiv},
	author = {Conklin, Bryan D.},
	month = jul,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.06.30.178244},
	file = {Conklin_2020_Organization of Areal Connectivity in the Monkey Frontoparietal Network.pdf:/Users/tito/Zotero/storage/DWKTQNTY/Conklin_2020_Organization of Areal Connectivity in the Monkey Frontoparietal Network.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VCTFQENW/2020.06.30.html:text/html},
}

@article{mandt_stochastic_2017,
	title = {Stochastic gradient descent as approximate {Bayesian} inference},
	volume = {18},
	issn = {1532-4435},
	abstract = {Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also show how to tune SGD with momentum for approximate sampling. (4)We analyze stochastic-gradient MCMC algorithms. For Stochastic-Gradient Langevin Dynamics and Stochastic-Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Mandt, Stephan and Hoffman, Matthew D. and Blei, David M.},
	month = jan,
	year = {2017},
	keywords = {approximate Bayesian inference, stochastic differential equations, stochastic gradient MCMC, stochastic optimization, variational inference},
	pages = {4873--4907},
	file = {Mandt et al_2017_Stochastic gradient descent as approximate Bayesian inference.pdf:/Users/tito/Zotero/storage/DAFYURTR/Mandt et al_2017_Stochastic gradient descent as approximate Bayesian inference.pdf:application/pdf},
}

@article{dubreuil_complementary_2020,
	title = {Complementary roles of dimensionality and population structure in neural computations},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.07.03.185942v1},
	doi = {10.1101/2020.07.03.185942},
	abstract = {{\textless}p{\textgreater}Neural computations are currently investigated using two competing approaches: sorting neurons into functional classes, or examining the low-dimensional dynamics of collective activity. Whether and how these two aspects interact to shape computations is currently unclear. Using a novel approach to extract computational mechanisms from networks trained with machine-learning tools on neuroscience tasks, here we show that the dimensionality of the dynamics and cell-class structure play fundamentally complementary roles. While various tasks can be implemented by increasing the dimensionality in networks consisting of a single global population, flexible input-output mappings instead required networks to be organized into several sub-populations. Our analyses revealed that the subpopulation structure enabled flexible computations through a mechanism based on gain-controlled modulations that flexibly shape the dynamical landscape of collective dynamics. Our results lead to task-specific predictions for the structure of neural selectivity and inactivation experiments.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-07-07},
	journal = {bioRxiv},
	author = {Dubreuil, Alexis M. and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
	month = jul,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.07.03.185942},
	file = {Dubreuil et al_2020_Complementary roles of dimensionality and population structure in neural.pdf:/Users/tito/Zotero/storage/H7JE59WM/Dubreuil et al_2020_Complementary roles of dimensionality and population structure in neural.pdf:application/pdf},
}

@article{schuessler_interplay_2020,
	title = {The interplay between randomness and structure during learning in {RNNs}},
	url = {http://arxiv.org/abs/2006.11036},
	abstract = {Recurrent neural networks (RNNs) trained on low-dimensional tasks have been widely used to model functional biological networks. However, the solutions found by learning and the effect of initial connectivity are not well understood. Here, we examine RNNs trained using gradient descent on different tasks inspired by the neuroscience literature. We find that the changes in recurrent connectivity can be described by low-rank matrices, despite the unconstrained nature of the learning algorithm. To identify the origin of the low-rank structure, we turn to an analytically tractable setting: training a linear RNN on a simplified task. We show how the low-dimensional task structure leads to low-rank changes to connectivity. This low-rank structure allows us to explain and quantify the phenomenon of accelerated learning in the presence of random initial connectivity. Altogether, our study opens a new perspective to understanding trained RNNs in terms of both the learning process and the resulting network structure.},
	urldate = {2020-07-07},
	journal = {arXiv:2006.11036 [q-bio]},
	author = {Schuessler, Friedrich and Mastrogiuseppe, Francesca and Dubreuil, Alexis and Ostojic, Srdjan and Barak, Omri},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.11036},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 28 pages (10 main text, 18 supplementary information). 9 figures (4 main, 5 supplement). Submission to conference Neurips 2020},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/YEC3HWKN/2006.html:text/html;Schuessler et al_2020_The interplay between randomness and structure during learning in RNNs.pdf:/Users/tito/Zotero/storage/ZHDMR6TG/Schuessler et al_2020_The interplay between randomness and structure during learning in RNNs.pdf:application/pdf},
}

@article{beiran_shaping_2020,
	title = {Shaping dynamics with multiple populations in low-rank recurrent networks},
	url = {http://arxiv.org/abs/2007.02062},
	abstract = {An emerging paradigm proposes that neural computations can be understood at the level of dynamical systems that govern low-dimensional trajectories of collective neural activity. How the connectivity structure of a network determines the emergent dynamical system however remains to be clarified. Here we consider a novel class of models, Gaussian-mixture low-rank recurrent networks, in which the rank of the connectivity matrix and the number of statistically-defined populations are independent hyper-parameters. We show that the resulting collective dynamics form a dynamical system, where the rank sets the dimensionality and the population structure shapes the dynamics. In particular, the collective dynamics can be described in terms of a simplified effective circuit of interacting latent variables. While having a single, global population strongly restricts the possible dynamics, we demonstrate that if the number of populations is large enough, a rank \$R\$ network can approximate any \$R\$-dimensional dynamical system.},
	urldate = {2020-07-07},
	journal = {arXiv:2007.02062 [q-bio]},
	author = {Beiran, Manuel and Dubreuil, Alexis and Valente, Adrian and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.02062},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 29 pages, 7 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/S53D7UXF/2007.html:text/html;Beiran et al_2020_Shaping dynamics with multiple populations in low-rank recurrent networks.pdf:/Users/tito/Zotero/storage/UB8EZRCQ/Beiran et al_2020_Shaping dynamics with multiple populations in low-rank recurrent networks.pdf:application/pdf},
}

@article{huang_internally_2020,
	title = {Internally generated population activity in cortical networks hinders information transmission},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.02.03.932723v1},
	doi = {10.1101/2020.02.03.932723},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}How neuronal variability impacts neuronal codes is a central question in systems neuroscience, often with complex and model dependent answers. Most population models are parametric, with a tacitly assumed structure of neuronal tuning and population-wide variability. While these models provide key insights, they purposely divorce any mechanistic relationship between trial average and trial variable neuronal activity. By contrast, circuit based models produce activity with response statistics that are reflection of the underlying circuit structure, and thus any relations between trial averaged and trial variable activity are emergent rather than assumed. In this work, we study information transfer in networks of spatially ordered spiking neuron models with strong excitatory and inhibitory interactions, capable of producing rich population-wide neuronal variability. Motivated by work in the visual system we embed a columnar stimulus orientation map in the network and measure the population estimation of an orientated input. We show that the spatial structure of feedforward and recurrent connectivity are critical determinants for population code performance. In particular, when network wiring supports stable firing rate activity then with a sufficiently large number of decoded neurons all available stimulus information is transmitted. However, if the inhibitory projections place network activity in a pattern forming regime then the population-wide dynamics compromise information flow. In total, network connectivity determines both the stimulus tuning as well as internally generated population-wide fluctuations and thereby dictates population code performance in complicated ways where modeling efforts provide essential understanding.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-07-08},
	journal = {bioRxiv},
	author = {Huang, Chengcheng and Pouget, Alexandre and Doiron, Brent},
	month = feb,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.02.03.932723},
	file = {Huang et al_2020_Internally generated population activity in cortical networks hinders.pdf:/Users/tito/Zotero/storage/ZEN42NPP/Huang et al_2020_Internally generated population activity in cortical networks hinders.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FF7BWTNB/2020.02.03.932723v1.html:text/html},
}

@article{burt_generative_2020,
	title = {Generative modeling of brain maps with spatial autocorrelation},
	volume = {220},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920305243},
	doi = {10.1016/j.neuroimage.2020.117038},
	abstract = {Studies of large-scale brain organization have revealed interesting relationships between spatial gradients in brain maps across multiple modalities. Evaluating the significance of these findings requires establishing statistical expectations under a null hypothesis of interest. Through generative modeling of synthetic data that instantiate a specific null hypothesis, quantitative benchmarks can be derived for arbitrarily complex statistical measures. Here, we present a generative null model, provided as an open-access software platform, that generates surrogate maps with spatial autocorrelation (SA) matched to SA of a target brain map. SA is a prominent and ubiquitous property of brain maps that violates assumptions of independence in conventional statistical tests. Our method can simulate surrogate brain maps, constrained by empirical data, that preserve the SA of cortical, subcortical, parcellated, and dense brain maps. We characterize how SA impacts p-values in pairwise brain map comparisons. Furthermore, we demonstrate how SA-preserving surrogate maps can be used in gene set enrichment analyses to test hypotheses of interest related to brain map topography. Our findings demonstrate the utility of SA-preserving surrogate maps for hypothesis testing in complex statistical analyses, and underscore the need to disambiguate meaningful relationships from chance associations in studies of large-scale brain organization.},
	language = {en},
	urldate = {2020-07-13},
	journal = {NeuroImage},
	author = {Burt, Joshua B. and Helmer, Markus and Shinn, Maxwell and Anticevic, Alan and Murray, John D.},
	month = oct,
	year = {2020},
	keywords = {Gene set enrichment analysis, Generative null modeling, Large-scale gradients, Spatial autocorrelation},
	pages = {117038},
	file = {Burt et al_2020_Generative modeling of brain maps with spatial autocorrelation.pdf:/Users/tito/Zotero/storage/T4LW5K4Z/Burt et al_2020_Generative modeling of brain maps with spatial autocorrelation.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/HZJAHKDB/S1053811920305243.html:text/html},
}

@article{friston_movement-related_1996,
	title = {Movement-{Related} effects in {fMRI} time-series},
	volume = {35},
	copyright = {Copyright © 1996 Wiley‐Liss, Inc., A Wiley Company},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1910350312},
	doi = {10.1002/mrm.1910350312},
	abstract = {This paper concerns the spatial and intensity transformations that are required to adjust for the confounding effects of subject movement during functional MRI (fMRI) activation studies. An approach is presented that models, and removes, movement-related artifacts from fMRI time-series. This approach is predicated on the observation that movement-related effects are extant even after perfect realignment. Movement-related effects can be divided into those that are a function of position of the object in the frame of reference of the scanner and those that are due to movement in previous scans. This second component depends on the history of excitation experienced by spins in a small volume and consequent differences in local saturation. The spin excitation history thus will itself be a function of previous positions, suggesting an autoregression-moving average model for the effects of previous displacements on the current signal. A model is described as well as the adjustments for movement-related components that ensue. The empirical analyses suggest that (in extreme situations) over 90\% of fMRI signal can be attributed to movement, and that this artifactual component can be successfully removed.},
	language = {en},
	number = {3},
	urldate = {2020-07-13},
	journal = {Magnetic Resonance in Medicine},
	author = {Friston, Karl J. and Williams, Steven and Howard, Robert and Frackowiak, Richard S. J. and Turner, Robert},
	year = {1996},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.1910350312},
	keywords = {fMRI, autoregression-moving average models, movement artifacts, realignment},
	pages = {346--355},
	file = {Friston et al_1996_Movement-Related effects in fMRI time-series.pdf:/Users/tito/Zotero/storage/5KPYE9Y7/Friston et al_1996_Movement-Related effects in fMRI time-series.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6AYK5ZHH/mrm.html:text/html},
}

@article{demirtas_hierarchical_2019,
	title = {Hierarchical {Heterogeneity} across {Human} {Cortex} {Shapes} {Large}-{Scale} {Neural} {Dynamics}},
	volume = {101},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627319300443},
	doi = {10.1016/j.neuron.2019.01.017},
	abstract = {The large-scale organization of dynamical neural activity across cortex emerges through long-range interactions among local circuits. We hypothesized that large-scale dynamics are also shaped by heterogeneity of intrinsic local properties across cortical areas. One key axis along which microcircuit properties are specialized relates to hierarchical levels of cortical organization. We developed a large-scale dynamical circuit model of human cortex that incorporates heterogeneity of local synaptic strengths, following a hierarchical axis inferred from magnetic resonance imaging (MRI)-derived T1- to T2-weighted (T1w/T2w) mapping and fit the model using multimodal neuroimaging data. We found that incorporating hierarchical heterogeneity substantially improves the model fit to functional MRI (fMRI)-measured resting-state functional connectivity and captures sensory-association organization of multiple fMRI features. The model predicts hierarchically organized higher-frequency spectral power, which we tested with resting-state magnetoencephalography. These findings suggest circuit-level mechanisms linking spatiotemporal levels of analysis and highlight the importance of local properties and their hierarchical specialization on the large-scale organization of human cortical dynamics.},
	language = {en},
	number = {6},
	urldate = {2020-07-13},
	journal = {Neuron},
	author = {Demirtaş, Murat and Burt, Joshua B. and Helmer, Markus and Ji, Jie Lisa and Adkinson, Brendan D. and Glasser, Matthew F. and Van Essen, David C. and Sotiropoulos, Stamatios N. and Anticevic, Alan and Murray, John D.},
	month = mar,
	year = {2019},
	keywords = {brain networks, functional connectivity, computational model, structural connectivity, resting-state fMRI, magnetoencephalography, cortical gradients, cortical hierarchy, large-scale modeling},
	pages = {1181--1194.e13},
	file = {Demirtaş et al_2019_Hierarchical Heterogeneity across Human Cortex Shapes Large-Scale Neural.pdf:/Users/tito/Zotero/storage/W98TPUHC/Demirtaş et al_2019_Hierarchical Heterogeneity across Human Cortex Shapes Large-Scale Neural.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/LN2YR4B2/S0896627319300443.html:text/html},
}

@article{hwang_frontoparietal_2019,
	title = {Frontoparietal {Activity} {Interacts} {With} {Task}-{Evoked} {Changes} in {Functional} {Connectivity}},
	volume = {29},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/29/2/802/4836785},
	doi = {10.1093/cercor/bhy011},
	abstract = {Abstract.  Flexible interactions between brain regions enable neural systems to adaptively transfer and process information. However, the neural substrates that},
	language = {en},
	number = {2},
	urldate = {2020-07-13},
	journal = {Cereb Cortex},
	author = {Hwang, Kai and Shine, James M. and D’Esposito, Mark},
	month = feb,
	year = {2019},
	note = {Publisher: Oxford Academic},
	pages = {802--813},
	file = {Hwang et al_2019_Frontoparietal Activity Interacts With Task-Evoked Changes in Functional.pdf:/Users/tito/Zotero/storage/YD76Z4ZV/Hwang et al_2019_Frontoparietal Activity Interacts With Task-Evoked Changes in Functional.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6M86NVW5/4836785.html:text/html},
}

@article{ito_discovering_2020,
	title = {Discovering the {Computational} {Relevance} of {Brain} {Network} {Organization}},
	volume = {24},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661319302402},
	doi = {10.1016/j.tics.2019.10.005},
	abstract = {Understanding neurocognitive computations will require not just localizing cognitive information distributed throughout the brain but also determining how that information got there. We review recent advances in linking empirical and simulated brain network organization with cognitive information processing. Building on these advances, we offer a new framework for understanding the role of connectivity in cognition: network coding (encoding/decoding) models. These models utilize connectivity to specify the transfer of information via neural activity flow processes, successfully predicting the formation of cognitive representations in empirical neural data. The success of these models supports the possibility that localized neural functions mechanistically emerge (are computed) from distributed activity flow processes that are specified primarily by connectivity patterns.},
	language = {en},
	number = {1},
	urldate = {2020-07-13},
	journal = {Trends in Cognitive Sciences},
	author = {Ito, Takuya and Hearne, Luke and Mill, Ravi and Cocuzza, Carrisa and Cole, Michael W.},
	month = jan,
	year = {2020},
	keywords = {artificial intelligence, machine learning, neural networks, connectivity, connectome, neural encoding/decoding, representations},
	pages = {25--38},
	file = {Ito et al_2020_Discovering the Computational Relevance of Brain Network Organization.pdf:/Users/tito/Zotero/storage/GKD9A4KK/Ito et al_2020_Discovering the Computational Relevance of Brain Network Organization.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/GA34BL9N/S1364661319302402.html:text/html},
}

@article{ito_cognitive_2017,
	title = {Cognitive task information is transferred between brain regions via resting-state network topology},
	volume = {8},
	issn = {2041-1723},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5715061/},
	doi = {10.1038/s41467-017-01000-w},
	abstract = {Resting-state network connectivity has been associated with a variety of cognitive abilities, yet it remains unclear how these connectivity properties might contribute to the neurocognitive computations underlying these abilities. We developed a new approach—information transfer mapping—to test the hypothesis that resting-state functional network topology describes the computational mappings between brain regions that carry cognitive task information. Here, we report that the transfer of diverse, task-rule information in distributed brain regions can be predicted based on estimated activity flow through resting-state network connections. Further, we find that these task-rule information transfers are coordinated by global hub regions within cognitive control networks. Activity flow over resting-state connections thus provides a large-scale network mechanism for cognitive task information transfer and global information coordination in the human brain, demonstrating the cognitive relevance of resting-state network topology., Resting-state functional connections have been associated with cognitive abilities but it is unclear how these connections contribute to cognition. Here Ito et al present a new approach, information transfer mapping, showing that task-relevant information can be predicted by estimated activity flow through resting-state networks.},
	urldate = {2020-07-13},
	journal = {Nat Commun},
	author = {Ito, Takuya and Kulkarni, Kaustubh R. and Schultz, Douglas H. and Mill, Ravi D. and Chen, Richard H. and Solomyak, Levi I. and Cole, Michael W.},
	month = oct,
	year = {2017},
	pmid = {29044112},
	pmcid = {PMC5715061},
	file = {Ito et al_2017_Cognitive task information is transferred between brain regions via.pdf:/Users/tito/Zotero/storage/V4DMP4UC/Ito et al_2017_Cognitive task information is transferred between brain regions via.pdf:application/pdf},
}

@article{ma_resting-state_2016,
	title = {Resting-state hemodynamics are spatiotemporally coupled to synchronized and symmetric neural activity in excitatory neurons},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1525369113},
	doi = {10.1073/pnas.1525369113},
	language = {en},
	number = {52},
	urldate = {2020-07-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ma, Ying and Shaik, Mohammed A. and Kozberg, Mariel G. and Kim, Sharon H. and Portes, Jacob P. and Timerman, Dmitriy and Hillman, Elizabeth M. C.},
	month = dec,
	year = {2016},
	pages = {E8463--E8471},
	file = {Ma et al. - 2016 - Resting-state hemodynamics are spatiotemporally co.pdf:/Users/tito/Zotero/storage/6UHICDHC/Ma et al. - 2016 - Resting-state hemodynamics are spatiotemporally co.pdf:application/pdf},
}

@article{power_ridding_2018,
	title = {Ridding {fMRI} data of motion-related influences: {Removal} of signals with distinct spatial and physical bases in multiecho data},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Ridding {fMRI} data of motion-related influences},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1720985115},
	doi = {10.1073/pnas.1720985115},
	language = {en},
	number = {9},
	urldate = {2020-07-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Power, Jonathan D. and Plitt, Mark and Gotts, Stephen J. and Kundu, Prantik and Voon, Valerie and Bandettini, Peter A. and Martin, Alex},
	month = feb,
	year = {2018},
	pages = {E2105--E2114},
	file = {Power et al. - 2018 - Ridding fMRI data of motion-related influences Re.pdf:/Users/tito/Zotero/storage/HDSYKWJP/Power et al. - 2018 - Ridding fMRI data of motion-related influences Re.pdf:application/pdf},
}

@article{vazquez-rodriguez_gradients_2019,
	title = {Gradients of structure–function tethering across neocortex},
	volume = {116},
	copyright = {Copyright © 2019 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/42/21219},
	doi = {10.1073/pnas.1903403116},
	abstract = {The white matter architecture of the brain imparts a distinct signature on neuronal coactivation patterns. Interregional projections promote synchrony among distant neuronal populations, giving rise to richly patterned functional networks. A variety of statistical, communication, and biophysical models have been proposed to study the relationship between brain structure and function, but the link is not yet known. In the present report we seek to relate the structural and functional connection profiles of individual brain areas. We apply a simple multilinear model that incorporates information about spatial proximity, routing, and diffusion between brain regions to predict their functional connectivity. We find that structure–function relationships vary markedly across the neocortex. Structure and function correspond closely in unimodal, primary sensory, and motor regions, but diverge in transmodal cortex, particularly the default mode and salience networks. The divergence between structure and function systematically follows functional and cytoarchitectonic hierarchies. Altogether, the present results demonstrate that structural and functional networks do not align uniformly across the brain, but gradually uncouple in higher-order polysensory areas.},
	language = {en},
	number = {42},
	urldate = {2020-07-13},
	journal = {PNAS},
	author = {Vázquez-Rodríguez, Bertha and Suárez, Laura E. and Markello, Ross D. and Shafiei, Golia and Paquola, Casey and Hagmann, Patric and Heuvel, Martijn P. van den and Bernhardt, Boris C. and Spreng, R. Nathan and Misic, Bratislav},
	month = oct,
	year = {2019},
	pmid = {31570622},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {connectome, cortical gradient, structure–function},
	pages = {21219--21227},
	file = {Snapshot:/Users/tito/Zotero/storage/I9TAJ3WN/21219.html:text/html;Vázquez-Rodríguez et al_2019_Gradients of structure–function tethering across neocortex.pdf:/Users/tito/Zotero/storage/FFARXNMF/Vázquez-Rodríguez et al_2019_Gradients of structure–function tethering across neocortex.pdf:application/pdf},
}

@article{wallis_decoding_2018,
	title = {Decoding {Cognitive} {Processes} from {Neural} {Ensembles}},
	volume = {22},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661318302201},
	doi = {10.1016/j.tics.2018.09.002},
	abstract = {An intrinsic difficulty in studying cognitive processes is that they are unobservable states that exist in between observable responses to the sensory environment. Cognitive states must be inferred from indirect behavioral measures. Neuroscience potentially provides the tools necessary to measure cognitive processes directly, but it is challenged on two fronts. First, neuroscientific measures often lack the spatiotemporal resolution to identify the neural computations that underlie a cognitive process. Second, the activity of a single neuron, which is the fundamental building block of neural computation, is too noisy to provide accurate measurements of a cognitive process. In this paper, I examine recent developments in neurophysiological recording and analysis methods that provide a potential solution to these problems.},
	language = {en},
	number = {12},
	urldate = {2020-07-13},
	journal = {Trends in Cognitive Sciences},
	author = {Wallis, Joni D.},
	month = dec,
	year = {2018},
	keywords = {decision making, high-level cognition, neural decoding, neurophysiology, orbitofrontal cortex},
	pages = {1091--1102},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/QJR9NW3T/S1364661318302201.html:text/html;Wallis_2018_Decoding Cognitive Processes from Neural Ensembles.pdf:/Users/tito/Zotero/storage/XXTTGPA8/Wallis_2018_Decoding Cognitive Processes from Neural Ensembles.pdf:application/pdf},
}

@article{fallon_timescales_2020,
	title = {Timescales of spontaneous {fMRI} fluctuations relate to structural connectivity in the brain},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/655050v2},
	doi = {10.1101/655050},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Intrinsic timescales of activity fluctuations vary hierarchically across the brain. This variation reflects a broad gradient of functional specialization in information storage and processing, with integrative association areas displaying slower timescales that are thought to reflect longer temporal processing windows. The organization of timescales is associated with cognitive function, distinctive between individuals, and disrupted in disease, but we do not yet understand how the temporal properties of activity dynamics are shaped by the brain’s underlying structural-connectivity network. Using resting-state fMRI and diffusion MRI data from 100 healthy individuals from the Human Connectome Project, here we show that the timescale of resting-state fMRI dynamics increases with structural-connectivity strength, matching recent results in the mouse brain. Our results hold at the level of individuals, are robust to parcellation schemes, and are conserved across a range of different timescale-related statistics. We establish a comprehensive BOLD dynamical signature of structural connectivity strength by comparing over 6000 time-series features, highlighting a range of new temporal features for characterizing BOLD dynamics, including measures of stationarity and symbolic motif frequencies. Our findings indicate a conserved property of mouse and human brain organization in which a brain region’s spontaneous activity fluctuations are closely related to their surrounding structural scaffold.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-07-13},
	journal = {bioRxiv},
	author = {Fallon, John and Ward, Phil and Parkes, Linden and Oldham, Stuart and Arnatkevic̆iūtė, Aurina and Fornito, Alex and Fulcher, Ben D.},
	month = may,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {655050},
	file = {Fallon et al_2020_Timescales of spontaneous fMRI fluctuations relate to structural connectivity.pdf:/Users/tito/Zotero/storage/42JGHQGJ/Fallon et al_2020_Timescales of spontaneous fMRI fluctuations relate to structural connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/7FRQ56SX/655050v2.html:text/html},
}

@article{fiebach_modulation_2006,
	title = {Modulation of {Inferotemporal} {Cortex} {Activation} during {Verbal} {Working} {Memory} {Maintenance}},
	volume = {51},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627306004600},
	doi = {10.1016/j.neuron.2006.06.007},
	abstract = {Regions of the left inferotemporal cortex are involved in visual word recognition and semantics. We utilized functional magnetic resonance imaging to localize an inferotemporal language area and to demonstrate that this area is involved in the active maintenance of visually presented words in working memory. Maintenance activity in this inferotemporal area showed an effect of memory load for words, but not pseudowords. In the absence of visual input, the selective modulation of this language-related inferotemporal area for the maintenance of words is accompanied by an increased functional connectivity with left prefrontal cortex. These results demonstrate an involvement of inferotemporal cortex in verbal working memory and provide neurophysiological support for the notion that nonphonological language representations can be recruited in the service of verbal working memory. More generally, they suggest that verbal working memory should be conceptualized as the frontally guided, sustained activation of pre-existing cortical language representations.},
	language = {en},
	number = {2},
	urldate = {2020-07-14},
	journal = {Neuron},
	author = {Fiebach, Christian J. and Rissman, Jesse and D'Esposito, Mark},
	month = jul,
	year = {2006},
	keywords = {SYSNEURO},
	pages = {251--261},
	file = {Fiebach et al_2006_Modulation of Inferotemporal Cortex Activation during Verbal Working Memory.pdf:/Users/tito/Zotero/storage/DBB9VJQY/Fiebach et al_2006_Modulation of Inferotemporal Cortex Activation during Verbal Working Memory.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/ESH53YRT/S0896627306004600.html:text/html},
}

@article{kahn_optogenetic_2013,
	title = {Optogenetic drive of neocortical pyramidal neurons generates {fMRI} signals that are correlated with spiking activity},
	volume = {1511},
	journal = {Brain research},
	author = {Kahn, I. and Knoblich, U. and Desai, M. and Bernstein, J. and Graybiel, A. M. and Boyden, E. S. and Buckner, R. L. and Moore, C. I.},
	year = {2013},
	note = {Publisher: Elsevier},
	pages = {33--45},
	file = {Full Text:/Users/tito/Zotero/storage/2M4S3H6L/S0006899313003922.html:text/html},
}

@article{fox_global_2009,
	title = {The global signal and observed anticorrelated resting state brain networks},
	volume = {101},
	number = {6},
	journal = {Journal of neurophysiology},
	author = {Fox, Michael D. and Zhang, Dongyang and Snyder, Abraham Z. and Raichle, Marcus E.},
	year = {2009},
	note = {Publisher: American Physiological Society},
	pages = {3270--3283},
	file = {Full Text:/Users/tito/Zotero/storage/26YTWK2U/jn.90777.html:text/html;Snapshot:/Users/tito/Zotero/storage/WYK5MHE4/jn.90777.html:text/html},
}

@article{power_methods_2014,
	title = {Methods to detect, characterize, and remove motion artifact in resting state {fMRI}},
	volume = {84},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913009117},
	doi = {10.1016/j.neuroimage.2013.08.048},
	abstract = {Head motion systematically alters correlations in resting state functional connectivity fMRI (RSFC). In this report we examine impact of motion on signal intensity and RSFC correlations. We find that motion-induced signal changes (1) are often complex and variable waveforms, (2) are often shared across nearly all brain voxels, and (3) often persist more than 10s after motion ceases. These signal changes, both during and after motion, increase observed RSFC correlations in a distance-dependent manner. Motion-related signal changes are not removed by a variety of motion-based regressors, but are effectively reduced by global signal regression. We link several measures of data quality to motion, changes in signal intensity, and changes in RSFC correlations. We demonstrate that improvements in data quality measures during processing may represent cosmetic improvements rather than true correction of the data. We demonstrate a within-subject, censoring-based artifact removal strategy based on volume censoring that reduces group differences due to motion to chance levels. We note conditions under which group-level regressions do and do not correct motion-related effects.},
	language = {en},
	urldate = {2020-07-14},
	journal = {NeuroImage},
	author = {Power, Jonathan D. and Mitra, Anish and Laumann, Timothy O. and Snyder, Abraham Z. and Schlaggar, Bradley L. and Petersen, Steven E.},
	month = jan,
	year = {2014},
	keywords = {MRI, Movement, Functional connectivity, Artifact, Motion, Resting state},
	pages = {320--341},
	file = {Power et al_2014_Methods to detect, characterize, and remove motion artifact in resting state.pdf:/Users/tito/Zotero/storage/STT6C6NK/Power et al_2014_Methods to detect, characterize, and remove motion artifact in resting state.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/I2PFWVSM/S1053811913009117.html:text/html},
}

@article{glasser_using_2018-1,
	title = {Using temporal {ICA} to selectively remove global noise while preserving global signal in functional {MRI} data},
	volume = {181},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918303963},
	doi = {10.1016/j.neuroimage.2018.04.076},
	abstract = {Temporal fluctuations in functional Magnetic Resonance Imaging (fMRI) have been profitably used to study brain activity and connectivity for over two decades. Unfortunately, fMRI data also contain structured temporal “noise” from a variety of sources, including subject motion, subject physiology, and the MRI equipment. Recently, methods have been developed to automatically and selectively remove spatially specific structured noise from fMRI data using spatial Independent Components Analysis (ICA) and machine learning classifiers. Spatial ICA is particularly effective at removing spatially specific structured noise from high temporal and spatial resolution fMRI data of the type acquired by the Human Connectome Project and similar studies. However, spatial ICA is mathematically, by design, unable to separate spatially widespread “global” structured noise from fMRI data (e.g., blood flow modulations from subject respiration). No methods currently exist to selectively and completely remove global structured noise while retaining the global signal from neural activity. This has left the field in a quandary—to do or not to do global signal regression—given that both choices have substantial downsides. Here we show that temporal ICA can selectively segregate and remove global structured noise while retaining global neural signal in both task-based and resting state fMRI data. We compare the results before and after temporal ICA cleanup to those from global signal regression and show that temporal ICA cleanup removes the global positive biases caused by global physiological noise without inducing the network-specific negative biases of global signal regression. We believe that temporal ICA cleanup provides a “best of both worlds” solution to the global signal and global noise dilemma and that temporal ICA itself unlocks interesting neurobiological insights from fMRI data.},
	language = {en},
	urldate = {2020-07-14},
	journal = {NeuroImage},
	author = {Glasser, Matthew F. and Coalson, Timothy S. and Bijsterbosch, Janine D. and Harrison, Samuel J. and Harms, Michael P. and Anticevic, Alan and Van Essen, David C. and Smith, Stephen M.},
	month = nov,
	year = {2018},
	pages = {692--717},
	file = {Glasser et al_2018_Using temporal ICA to selectively remove global noise while preserving global.pdf:/Users/tito/Zotero/storage/ZGTZVMF3/Glasser et al_2018_Using temporal ICA to selectively remove global noise while preserving global.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/RI8PWWYV/S1053811918303963.html:text/html},
}

@article{mcclure_evaluating_2020,
	title = {Evaluating {Adversarial} {Robustness} for {Deep} {Neural} {Network} {Interpretability} in {fMRI} {Decoding}},
	url = {http://arxiv.org/abs/2004.11114},
	abstract = {While deep neural networks (DNNs) are being increasingly used to make predictions from high-dimensional, complex data, they are widely seen as uninterpretable "black boxes", since it can be difficult to discover what input information is used to make predictions. This ability is particularly important for applications in cognitive neuroscience and neuroinformatics. A saliency map is a common approach for producing interpretable visualizations of the relative importance of input features for a prediction. However, many methods for creating these maps fail due to focusing too much on the input or being extremely sensitive to small input noise. It is also challenging to quantitatively evaluate how well saliency maps correspond to the truly relevant input information. In this paper, we develop two quantitative evaluation procedures for saliency methods, using the fact that the Human Connectome Project (HCP) dataset contains functional magnetic resonance imaging (fMRI) data from multiple tasks per subject to create ground truth saliency maps. We then introduce an adversarial training method that makes DNNs robust to small input noise, and demonstrate that it measurably improves interpretability.},
	urldate = {2020-07-15},
	journal = {arXiv:2004.11114 [cs, q-bio, stat]},
	author = {McClure, Patrick and Moraczewski, Dustin and Lam, Ka Chun and Thomas, Adam and Pereira, Francisco},
	month = jun,
	year = {2020},
	note = {arXiv: 2004.11114},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/UQCDNZD7/2004.html:text/html;McClure et al_2020_Evaluating Adversarial Robustness for Deep Neural Network Interpretability in.pdf:/Users/tito/Zotero/storage/3PG6RT3E/McClure et al_2020_Evaluating Adversarial Robustness for Deep Neural Network Interpretability in.pdf:application/pdf},
}

@article{lam_understanding_2020,
	title = {Understanding {Object} {Affordances} {Through} {Verb} {Usage} {Patterns}},
	url = {http://arxiv.org/abs/2007.04245},
	abstract = {In order to interact with objects in our environment, we rely on an understanding of the actions that can be performed on them, and the extent to which they rely or have an effect on the properties of the object. This knowledge is called the object "affordance". We propose an approach for creating an embedding of objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance. We show that the dimensions learned are interpretable, and that they correspond to patterns of interaction with objects. Finally, we show that they can be used to predict other dimensions of object representation that have been shown to underpin human judgments of object similarity.},
	urldate = {2020-07-15},
	journal = {arXiv:2007.04245 [cs, q-bio]},
	author = {Lam, Ka Chun and Pereira, Francisco and Vaziri-Pashkam, Maryam and Woodard, Kristin and McMahon, Emalie},
	month = jun,
	year = {2020},
	note = {arXiv: 2007.04245},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language, 68U15, I.2.7, I.5.4, J.4},
	annote = {Comment: 10 pages, 3 figures, 2 tables,},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/R4EKBHQU/2007.html:text/html;Lam et al_2020_Understanding Object Affordances Through Verb Usage Patterns.pdf:/Users/tito/Zotero/storage/PEIWDF9I/Lam et al_2020_Understanding Object Affordances Through Verb Usage Patterns.pdf:application/pdf},
}

@article{wu_hierarchy_2020,
	title = {Hierarchy of {Connectivity}–{Function} {Relationship} of the {Human} {Cortex} {Revealed} through {Predicting} {Activity} across {Functional} {Domains}},
	volume = {30},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/30/8/4607/5809063},
	doi = {10.1093/cercor/bhaa063},
	abstract = {Abstract.  Many studies showed that anatomical connectivity supports both anatomical and functional hierarchies that span across the primary and association cor},
	language = {en},
	number = {8},
	urldate = {2020-07-15},
	journal = {Cereb Cortex},
	author = {Wu, Dongya and Fan, Lingzhong and Song, Ming and Wang, Haiyan and Chu, Congying and Yu, Shan and Jiang, Tianzi},
	month = jun,
	year = {2020},
	note = {Publisher: Oxford Academic},
	pages = {4607--4616},
	file = {Snapshot:/Users/tito/Zotero/storage/QKF9ME4J/5809063.html:text/html;Wu et al_2020_Hierarchy of Connectivity–Function Relationship of the Human Cortex Revealed.pdf:/Users/tito/Zotero/storage/DBGFMVYG/Wu et al_2020_Hierarchy of Connectivity–Function Relationship of the Human Cortex Revealed.pdf:application/pdf},
}

@article{ito_cortical_2020,
	title = {A cortical hierarchy of localized and distributed processes revealed via dissociation of task activations, connectivity changes, and intrinsic timescales},
	volume = {221},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920306273},
	doi = {10.1016/j.neuroimage.2020.117141},
	abstract = {Many studies have identified the role of localized and distributed cognitive functionality by mapping either local task-related activity or distributed functional connectivity (FC). However, few studies have directly explored the relationship between a brain region’s localized task activity and its distributed task FC. Here we systematically evaluated the differential contributions of task-related activity and FC changes to identify a relationship between localized and distributed processes across the cortical hierarchy. We found that across multiple tasks, the magnitude of regional task-evoked activity was high in unimodal areas, but low in transmodal areas. In contrast, we found that task-state FC was significantly reduced in unimodal areas relative to transmodal areas. This revealed a strong negative relationship between localized task activity and distributed FC across cortical regions that was associated with the previously reported principal gradient of macroscale organization. Moreover, this dissociation corresponded to hierarchical cortical differences in the intrinsic timescale estimated from resting-state fMRI and region myelin content estimated from structural MRI. Together, our results contribute to a growing literature illustrating the differential contributions of a hierarchical cortical gradient representing localized and distributed cognitive processes.},
	language = {en},
	urldate = {2020-07-17},
	journal = {NeuroImage},
	author = {Ito, Takuya and Hearne, Luke J. and Cole, Michael W.},
	month = nov,
	year = {2020},
	keywords = {fMRI, Functional connectivity, Cortical gradients, Cortical hierarchy, Myelin mapping, Task activations, Timescales},
	pages = {117141},
	file = {Ito et al_2020_A cortical hierarchy of localized and distributed processes revealed via.pdf:/Users/tito/Zotero/storage/N8AXLPN8/Ito et al_2020_A cortical hierarchy of localized and distributed processes revealed via.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/XPW28TDQ/S1053811920306273.html:text/html},
}

@article{reverberi_distributed_2012,
	title = {Distributed representations of rule identity and rule order in human frontal cortex and striatum},
	volume = {32},
	number = {48},
	journal = {Journal of Neuroscience},
	author = {Reverberi, Carlo and Görgen, Kai and Haynes, John-Dylan},
	year = {2012},
	note = {Publisher: Soc Neuroscience},
	pages = {17420--17430},
	file = {Reverberi et al_2012_Distributed representations of rule identity and rule order in human frontal.pdf:/Users/tito/Zotero/storage/8TJ629DY/Reverberi et al_2012_Distributed representations of rule identity and rule order in human frontal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FDDUX6A4/17420.html:text/html},
}

@article{vaidya_neural_2020,
	title = {Neural representation of abstract task structure during generalization},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.07.21.213009v1},
	doi = {10.1101/2020.07.21.213009},
	abstract = {{\textless}p{\textgreater}Abstract task representations enable generalization, including inferring new behaviors based on prior knowledge without additional training. However, evidence for a neural representation that meets this benchmark is surprisingly limited. Here, using functional MRI (fMRI), we observed that abstract task structure was represented within frontoparietal networks during generalization. These results reveal the neural systems supporting a vital feature of human cognition: the abstraction of task knowledge to infer novel behaviors.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-07-22},
	journal = {bioRxiv},
	author = {Vaidya, Avinash Rao and Jones, Henry M. and Castillo, Johanny and Badre, David},
	month = jul,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.07.21.213009},
	file = {Snapshot:/Users/tito/Zotero/storage/2A5SXZAL/2020.07.21.html:text/html;Vaidya et al_2020_Neural representation of abstract task structure during generalization.pdf:/Users/tito/Zotero/storage/RFKQXXUY/Vaidya et al_2020_Neural representation of abstract task structure during generalization.pdf:application/pdf},
}

@article{tschopp_connectome_2018,
	title = {A {Connectome} {Based} {Hexagonal} {Lattice} {Convolutional} {Network} {Model} of the {Drosophila} {Visual} {System}},
	url = {http://arxiv.org/abs/1806.04793},
	abstract = {What can we learn from a connectome? We constructed a simplified model of the first two stages of the fly visual system, the lamina and medulla. The resulting hexagonal lattice convolutional network was trained using backpropagation through time to perform object tracking in natural scene videos. Networks initialized with weights from connectome reconstructions automatically discovered well-known orientation and direction selectivity properties in T4 neurons and their inputs, while networks initialized at random did not. Our work is the first demonstration, that knowledge of the connectome can enable in silico predictions of the functional properties of individual neurons in a circuit, leading to an understanding of circuit function from structure alone.},
	urldate = {2020-07-23},
	journal = {arXiv:1806.04793 [cs, q-bio]},
	author = {Tschopp, Fabian David and Reiser, Michael B. and Turaga, Srinivas C.},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.04793},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Work in progress. Final paper with results from an updated model with new connectome data will be coming soon},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/F74NGWEN/1806.html:text/html;Tschopp et al_2018_A Connectome Based Hexagonal Lattice Convolutional Network Model of the.pdf:/Users/tito/Zotero/storage/3NW324S7/Tschopp et al_2018_A Connectome Based Hexagonal Lattice Convolutional Network Model of the.pdf:application/pdf},
}

@article{singh_estimation_2020,
	title = {Estimation and validation of individualized dynamic brain models with resting state {fMRI}},
	volume = {221},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920305322},
	doi = {10.1016/j.neuroimage.2020.117046},
	abstract = {A key challenge for neuroscience is to develop generative, causal models of the human nervous system in an individualized, data-driven manner. Previous initiatives have either constructed biologically-plausible models that are not constrained by individual-level human brain activity or used data-driven statistical characterizations of individuals that are not mechanistic. We aim to bridge this gap through the development of a new modeling approach termed Mesoscale Individualized Neurodynamic (MINDy) modeling, wherein we fit nonlinear dynamical systems models directly to human brain imaging data. The MINDy framework is able to produce these data-driven network models for hundreds to thousands of interacting brain regions in just 1–3 ​min per subject. We demonstrate that the models are valid, reliable, and robust. We show that MINDy models are predictive of individualized patterns of resting-state brain dynamical activity. Furthermore, MINDy is better able to uncover the mechanisms underlying individual differences in resting state activity than functional connectivity methods.},
	language = {en},
	urldate = {2020-07-23},
	journal = {NeuroImage},
	author = {Singh, Matthew F. and Braver, Todd S. and Cole, Michael W. and Ching, ShiNung},
	month = nov,
	year = {2020},
	keywords = {Neural dynamics, Resting state fMRI, Dynamic functional connectivity, Causal modeling, Recurrent neural networks},
	pages = {117046},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/HGVP7RPF/S1053811920305322.html:text/html;Singh et al_2020_Estimation and validation of individualized dynamic brain models with resting.pdf:/Users/tito/Zotero/storage/WMBKFCWK/Singh et al_2020_Estimation and validation of individualized dynamic brain models with resting.pdf:application/pdf},
}

@article{hubel_way_2009,
	title = {The {Way} {Biomedical} {Research} {Is} {Organized} {Has} {Dramatically} {Changed} {Over} the {Past} {Half}-{Century}: {Are} the {Changes} for the {Better}?},
	volume = {64},
	issn = {0896-6273},
	shorttitle = {The {Way} {Biomedical} {Research} {Is} {Organized} {Has} {Dramatically} {Changed} {Over} the {Past} {Half}-{Century}},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(09)00733-8},
	doi = {10.1016/j.neuron.2009.09.022},
	language = {English},
	number = {2},
	urldate = {2020-07-27},
	journal = {Neuron},
	author = {Hubel, David H.},
	month = oct,
	year = {2009},
	pmid = {19874784},
	note = {Publisher: Elsevier},
	pages = {161--163},
	file = {Hubel_2009_The Way Biomedical Research Is Organized Has Dramatically Changed Over the Past.pdf:/Users/tito/Zotero/storage/Y8B57ZDG/Hubel_2009_The Way Biomedical Research Is Organized Has Dramatically Changed Over the Past.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/2UTBCN38/S0896-6273(09)00733-8.html:text/html},
}

@article{vazquez-rodriguez_signal_2020,
	title = {Signal propagation via cortical hierarchies},
	journal = {BioRxiv},
	author = {Vazquez-Rodriguez, Bertha and Liu, Zhen-Qi and Hagmann, Patric and Misic, Bratislav},
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory},
}

@article{bouchacourt_temporal_2020,
	title = {Temporal chunking as a mechanism for unsupervised learning of task-sets},
	volume = {9},
	journal = {Elife},
	author = {Bouchacourt, Flora and Palminteri, Stefano and Koechlin, Etienne and Ostojic, Srdjan},
	year = {2020},
	note = {Publisher: eLife Sciences Publications Limited},
	pages = {e50469},
	file = {Full Text:/Users/tito/Zotero/storage/W52QKSRX/50469.html:text/html},
}

@article{dubreuil_complementary_2020-1,
	title = {Complementary roles of dimensionality and population structure in neural computations},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.07.03.185942v1},
	doi = {10.1101/2020.07.03.185942},
	abstract = {{\textless}p{\textgreater}Neural computations are currently investigated using two competing approaches: sorting neurons into functional classes, or examining the low-dimensional dynamics of collective activity. Whether and how these two aspects interact to shape computations is currently unclear. Using a novel approach to extract computational mechanisms from networks trained with machine-learning tools on neuroscience tasks, here we show that the dimensionality of the dynamics and cell-class structure play fundamentally complementary roles. While various tasks can be implemented by increasing the dimensionality in networks consisting of a single global population, flexible input-output mappings instead required networks to be organized into several sub-populations. Our analyses revealed that the subpopulation structure enabled flexible computations through a mechanism based on gain-controlled modulations that flexibly shape the dynamical landscape of collective dynamics. Our results lead to task-specific predictions for the structure of neural selectivity and inactivation experiments.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-07-29},
	journal = {bioRxiv},
	author = {Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
	month = jul,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.07.03.185942},
	file = {Dubreuil et al_2020_Complementary roles of dimensionality and population structure in neural.pdf:/Users/tito/Zotero/storage/ZAJUXJRV/Dubreuil et al_2020_Complementary roles of dimensionality and population structure in neural.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9NER979J/2020.07.03.185942v1.html:text/html},
}

@article{zhang_rest-task_2020,
	title = {Rest-task modulation of {fMRI}-derived global signal topography is mediated by transient coactivation patterns},
	volume = {18},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000733},
	doi = {10.1371/journal.pbio.3000733},
	abstract = {Recent resting-state functional MRI (fMRI) studies have revealed that the global signal (GS) exhibits a nonuniform spatial distribution across the gray matter. Whether this topography is informative remains largely unknown. We therefore tested rest-task modulation of GS topography by analyzing static GS correlation and dynamic coactivation patterns in a large sample of an fMRI dataset (n = 837) from the Human Connectome Project. The GS topography in the resting state and in seven different tasks was first measured by correlating the GS with the local time series (GSCORR). In the resting state, high GSCORR was observed mainly in the primary sensory and motor regions, whereas low GSCORR was seen in the association brain areas. This pattern changed during the seven tasks, with mainly decreased GSCORR in sensorimotor cortex. Importantly, this rest-task modulation of GSCORR could be traced to transient coactivation patterns at the peak period of GS (GS-peak). By comparing the topography of GSCORR and respiration effects, we observed that the topography of respiration mimicked the topography of GS in the resting state, whereas both differed during the task states; because of such partial dissociation, we assume that GSCORR could not be equated with a respiration effect. Finally, rest-task modulation of GS topography could not be exclusively explained by other sources of physiological noise. Together, we here demonstrate the informative nature of GS topography by showing its rest-task modulation, the underlying dynamic coactivation patterns, and its partial dissociation from respiration effects during task states.},
	language = {en},
	number = {7},
	urldate = {2020-07-30},
	journal = {PLOS Biology},
	author = {Zhang, Jianfeng and Huang, Zirui and Tumati, Shankar and Northoff, Georg},
	month = jul,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Working memory, Functional magnetic resonance imaging, Sensory perception, Brain mapping, Central nervous system, Preprocessing, Modulation, Respiratory physiology},
	pages = {e3000733},
	file = {Snapshot:/Users/tito/Zotero/storage/JZZ52HU2/article.html:text/html;Zhang et al_2020_Rest-task modulation of fMRI-derived global signal topography is mediated by.pdf:/Users/tito/Zotero/storage/YAMUEI92/Zhang et al_2020_Rest-task modulation of fMRI-derived global signal topography is mediated by.pdf:application/pdf},
}

@incollection{cohen_systems-level_2004,
	address = {New York, NY, US},
	title = {A {Systems}-{Level} {Perspective} on {Attention} and {Cognitive} {Control}: {Guided} {Activation}, {Adaptive} {Gating}, {Conflict} {Monitoring}, and {Exploitation} versus {Exploration}},
	isbn = {978-1-59385-048-7},
	shorttitle = {A {Systems}-{Level} {Perspective} on {Attention} and {Cognitive} {Control}},
	abstract = {In this chapter, we address a particular type of attentional phenomenon--that associated with cognitive control. Furthermore, we focus on an account that addresses not only the functional characteristics of this form of attention but also how it is implemented in neural machinery. This neurally oriented approach is attractive not only because it is intrinsically interesting to understand how the mechanisms of the brain give rise to the processes of the mind but more specifically because this exercise has proven useful in generating insights into how controlled attention operates at the systems level. By assuming that information is represented as patterns of activity, and information processing occurs as the flow of activity, it becomes possible to understand how information represented in one part of the system can influence the processing of information in other parts of the system--that is, how attention and control operate at the systems level. The sections that follow develop this idea in greater detail, first by providing a particular example of controlled attention and how it can be modeled in terms of explicit processing mechanisms, then by showing how it can explain some of the most important observations that have been made about attention and control, and finally by reviewing recent elaborations of the basic model that have begun to address broader questions about the psychological and neural mechanisms that underlie cognitive control. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	booktitle = {Cognitive neuroscience of attention},
	publisher = {The Guilford Press},
	author = {Cohen, Jonathan D. and Aston-Jones, Gary and Gilzenrat, Mark S.},
	year = {2004},
	keywords = {Attention, Neurophysiology, Cognitive Control, Cognitive Processes, Monitoring, Selective Attention, Sensory Gating, Systems Theory},
	pages = {71--90},
	file = {Cohen et al_2004_A Systems-Level Perspective on Attention and Cognitive Control.pdf:/Users/tito/Zotero/storage/DTVS4E5I/Cohen et al_2004_A Systems-Level Perspective on Attention and Cognitive Control.pdf:application/pdf},
}

@article{reinhart_working_2019,
	title = {Working memory revived in older adults by synchronizing rhythmic brain circuits},
	volume = {22},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0371-x},
	doi = {10.1038/s41593-019-0371-x},
	abstract = {Understanding normal brain aging and developing methods to maintain or improve cognition in older adults are major goals of fundamental and translational neuroscience. Here we show a core feature of cognitive decline—working-memory deficits—emerges from disconnected local and long-range circuits instantiated by theta–gamma phase–amplitude coupling in temporal cortex and theta phase synchronization across frontotemporal cortex. We developed a noninvasive stimulation procedure for modulating long-range theta interactions in adults aged 60–76 years. After 25 min of stimulation, frequency-tuned to individual brain network dynamics, we observed a preferential increase in neural synchronization patterns and the return of sender–receiver relationships of information flow within and between frontotemporal regions. The end result was rapid improvement in working-memory performance that outlasted a 50 min post-stimulation period. The results provide insight into the physiological foundations of age-related cognitive impairment and contribute to groundwork for future non-pharmacological interventions targeting aspects of cognitive decline.},
	language = {en},
	number = {5},
	urldate = {2020-08-03},
	journal = {Nature Neuroscience},
	author = {Reinhart, Robert M. G. and Nguyen, John A.},
	month = may,
	year = {2019},
	note = {Number: 5
Publisher: Nature Publishing Group},
	pages = {820--827},
	file = {Reinhart_Nguyen_2019_Working memory revived in older adults by synchronizing rhythmic brain circuits.pdf:/Users/tito/Zotero/storage/D3LYGME2/Reinhart_Nguyen_2019_Working memory revived in older adults by synchronizing rhythmic brain circuits.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DM3GZC84/s41593-019-0371-x.html:text/html},
}

@article{arazi_neural_2017,
	title = {Neural {Variability} {Quenching} {Predicts} {Individual} {Perceptual} {Abilities}},
	volume = {37},
	copyright = {Copyright © 2017 the authors 0270-6474/17/370097-13\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/37/1/97},
	doi = {10.1523/JNEUROSCI.1671-16.2016},
	abstract = {Neural activity during repeated presentations of a sensory stimulus exhibits considerable trial-by-trial variability. Previous studies have reported that trial-by-trial neural variability is reduced (quenched) by the presentation of a stimulus. However, the functional significance and behavioral relevance of variability quenching and the potential physiological mechanisms that may drive it have been studied only rarely. Here, we recorded neural activity with EEG as subjects performed a two-interval forced-choice contrast discrimination task. Trial-by-trial neural variability was quenched by ∼40\% after the presentation of the stimulus relative to the variability apparent before stimulus presentation, yet there were large differences in the magnitude of variability quenching across subjects. Individual magnitudes of quenching predicted individual discrimination capabilities such that subjects who exhibited larger quenching had smaller contrast discrimination thresholds and steeper psychometric function slopes. Furthermore, the magnitude of variability quenching was strongly correlated with a reduction in broadband EEG power after stimulus presentation. Our results suggest that neural variability quenching is achieved by reducing the amplitude of broadband neural oscillations after sensory input, which yields relatively more reproducible cortical activity across trials and enables superior perceptual abilities in individuals who quench more.
SIGNIFICANCE STATEMENT Variability quenching is a phenomenon in which neural variability across trials is reduced by the presentation of a stimulus. Although this phenomenon has been reported across a variety of animal and human studies, its functional significance and behavioral relevance have been examined only rarely. Here, we report novel empirical evidence from humans revealing that variability quenching differs dramatically across individual subjects and explains to a certain degree why some individuals exhibit better perceptual abilities than others. In addition, we found a strong relationship between variability quenching and suppression of broadband neural oscillations. Together, our results reveal the importance of reproducible cortical activity for enabling better perceptual abilities and suggest a potential underlying mechanism that may explain why variability quenching occurs.},
	language = {en},
	number = {1},
	urldate = {2020-08-04},
	journal = {J. Neurosci.},
	author = {Arazi, Ayelet and Censor, Nitzan and Dinstein, Ilan},
	month = jan,
	year = {2017},
	pmid = {28053033},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {EEG, variability quenching, trial by trial neural variability, visual perception},
	pages = {97--109},
	file = {Arazi et al_2017_Neural Variability Quenching Predicts Individual Perceptual Abilities.pdf:/Users/tito/Zotero/storage/ADNP7CE9/Arazi et al_2017_Neural Variability Quenching Predicts Individual Perceptual Abilities.pdf:application/pdf},
}

@techreport{rmus_role_2020,
	type = {preprint},
	title = {The {Role} of {Executive} {Function} in {Shaping} {Reinforcement} {Learning}},
	url = {https://osf.io/9cvw3},
	abstract = {Reinforcement learning (RL) models have advanced our understanding of how animals learn and make decisions, and how the brain supports some aspects of learning. However, the neural computations that are explained by RL algorithms fall short of explaining many sophisticated aspects of human decision making, including the generalization of learned information, one-shot learning, and the synthesis of task information in complex environments. Instead, these aspects of instrumental behavior are assumed to be supported by the brain’s executive functions (EF). We review recent findings that highlight the importance of EF in learning. Specifically, we advance the theory that EF sets the stage for canonical RL computations in the brain, providing inputs that broaden their flexibility and applicability. Our theory has important implications for how to interpret RL computations in the brain and behavior.},
	urldate = {2020-08-05},
	institution = {PsyArXiv},
	author = {Rmus, Milena and McDougle, Samuel and Collins, Anne},
	month = jun,
	year = {2020},
	doi = {10.31234/osf.io/9cvw3},
	file = {Rmus et al_2020_The Role of Executive Function in Shaping Reinforcement Learning.pdf:/Users/tito/Zotero/storage/CJWV5SXV/Rmus et al_2020_The Role of Executive Function in Shaping Reinforcement Learning.pdf:application/pdf},
}

@article{assem_domain-general_2020,
	title = {A {Domain}-{General} {Cognitive} {Core} {Defined} in {Multimodally} {Parcellated} {Human} {Cortex}},
	volume = {30},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/30/8/4361/5815289},
	doi = {10.1093/cercor/bhaa023},
	abstract = {Abstract.  Numerous brain imaging studies identified a domain-general or “multiple-demand” (MD) activation pattern accompanying many tasks and may play a core r},
	language = {en},
	number = {8},
	urldate = {2020-08-07},
	journal = {Cereb Cortex},
	author = {Assem, Moataz and Glasser, Matthew F. and Van Essen, David C. and Duncan, John},
	month = jun,
	year = {2020},
	note = {Publisher: Oxford Academic},
	pages = {4361--4380},
	file = {Assem et al_2020_A Domain-General Cognitive Core Defined in Multimodally Parcellated Human Cortex.pdf:/Users/tito/Zotero/storage/87FX5RAE/Assem et al_2020_A Domain-General Cognitive Core Defined in Multimodally Parcellated Human Cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/UZLG2J4A/5815289.html:text/html},
}

@article{cocuzza_flexible_2020,
	title = {Flexible coordinator and switcher hubs for adaptive task control},
	copyright = {Copyright © 2020 the authors. SfN exclusive license.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/early/2020/07/30/JNEUROSCI.2559-19.2020},
	doi = {10.1523/JNEUROSCI.2559-19.2020},
	abstract = {Functional connectivity studies have identified at least two large-scale neural systems that constitute cognitive control networks – the frontoparietal network (FPN) and cingulo-opercular network (CON). Control networks are thought to support goal-directed cognition and behavior. It was previously shown that the FPN flexibly shifts its global connectivity pattern according to task goal, consistent with a “flexible hub” mechanism for cognitive control. Our aim was to build on this finding to develop a functional cartography (a multi-metric profile) of control networks in terms of dynamic network properties. We quantified network properties in (male and female) humans using a high-control-demand cognitive paradigm involving switching among 64 task sets. We hypothesized that cognitive control is enacted by the FPN and CON via distinct but complementary roles reflected in network dynamics. Consistent with a flexible “coordinator” mechanism, FPN connections were varied across tasks, while maintaining within-network connectivity to aid cross-region coordination. Consistent with a flexible “switcher” mechanism, CON regions switched to other networks in a task-dependent manner, driven primarily by reduced within-network connections to other CON regions. This pattern of results suggests FPN acts as a dynamic, global coordinator of goal-relevant information, while CON transiently disbands to lend processing resources to other goal-relevant networks. This cartography of network dynamics reveals a dissociation between two prominent cognitive control networks, suggesting complementary mechanisms underlying goal-directed cognition.
Significance statement
Cognitive control supports a variety of behaviors requiring flexible cognition, such as rapidly switching between tasks. Furthermore, cognitive control is negatively impacted in a variety of mental illnesses. We used tools from network science to characterize the implementation of cognitive control by large-scale brain systems. This revealed that two systems – the frontoparietal (FPN) and cingulo-opercular (CON) networks – have distinct but complementary roles in controlling global network reconfigurations. The FPN exhibited properties of a flexible coordinator (orchestrating task changes), while CON acted as a flexible switcher (switching specific regions to other systems to lend processing resources). These findings reveal an underlying distinction in cognitive processes that may be applicable to clinical, educational, and machine learning work targeting cognitive flexibility.},
	language = {en},
	urldate = {2020-08-07},
	journal = {J. Neurosci.},
	author = {Cocuzza, Carrisa V. and Ito, Takuya and Schultz, Douglas and Bassett, Danielle S. and Cole, Michael W.},
	month = jul,
	year = {2020},
	pmid = {32732324},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	file = {Cocuzza et al_2020_Flexible coordinator and switcher hubs for adaptive task control.pdf:/Users/tito/Zotero/storage/JYNCF9YI/Cocuzza et al_2020_Flexible coordinator and switcher hubs for adaptive task control.pdf:application/pdf},
}

@article{buzsaki_braincognitive_2020,
	title = {The {Brain}–{Cognitive} {Behavior} {Problem}: {A} {Retrospective}},
	volume = {7},
	copyright = {Copyright © 2020 Buzsáki. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
	issn = {2373-2822},
	shorttitle = {The {Brain}–{Cognitive} {Behavior} {Problem}},
	url = {https://www.eneuro.org/content/7/4/ENEURO.0069-20.2020},
	doi = {10.1523/ENEURO.0069-20.2020},
	abstract = {{\textless}h3{\textgreater}ABSTRACT{\textless}/h3{\textgreater} {\textless}p{\textgreater}Cross-reactive responses elicited by exposure to nontuberculous mycobacteria often confound the interpretation of antemortem tests for \textit{Mycobacterium bovis} infection of cattle. The use of specific proteins (e.g., ESAT-6, CFP-10, and MPB83), however, generally enhances the specificity of bovine tuberculosis tests. While genes for these proteins are absent from many nontuberculous mycobacteria, they are present in \textit{M. kansasii}. Instillation of \textit{M. kansasii} into the tonsillar crypts of calves elicited delayed-type hypersensitivity and in vitro gamma interferon and nitrite concentration responses of leukocytes to \textit{M. avium} and \textit{M. bovis} purified protein derivatives (PPDs). While the responses of \textit{M. kansasii}-inoculated calves to \textit{M. avium} and \textit{M. bovis} PPDs were approximately equivalent, the responses of \textit{M. bovis}-inoculated calves to \textit{M. bovis} PPD exceeded their respective responses to \textit{M. avium} PPD. The gamma interferon and nitrite responses of \textit{M. kansasii}-inoculated calves to recombinant ESAT-6-CFP-10 (rESAT-6-CFP-10) exceeded corresponding responses of noninoculated calves as early as 15 and 30 days after inoculation, respectively, and persisted throughout the study. The gamma interferon and nitrite responses of \textit{M. bovis}-inoculated calves to rESAT-6-CFP-10 exceeded the corresponding responses of \textit{M. kansasii}-inoculated calves beginning 30 days after inoculation. By using a lipoarabinomannan-based enzyme-linked immunosorbent assay, specific serum antibodies were detected as early as 50 days after challenge with \textit{M. kansasii}. By a multiantigen print immunoassay and immunoblotting, serum antibodies to MPB83, but not ESAT-6 or CFP-10, were detected in \textit{M. kansasii}-inoculated calves; however, responses to MPB83 were notably weaker than those elicited by \textit{M. bovis} infection. These findings indicate that \textit{M. kansasii} infection of calves elicits specific responses that may confound the interpretation of bovine tuberculosis tests.{\textless}/p{\textgreater}},
	language = {en},
	number = {4},
	urldate = {2020-08-10},
	journal = {eNeuro},
	author = {Buzsáki, György},
	month = jul,
	year = {2020},
	pmid = {32769166},
	note = {Publisher: Society for Neuroscience
Section: Opinion},
	keywords = {memory, perception, action, folk psychology, internalization, subjective terms},
	file = {Buzsáki_2020_The Brain–Cognitive Behavior Problem.pdf:/Users/tito/Zotero/storage/LACKZMI6/Buzsáki_2020_The Brain–Cognitive Behavior Problem.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/LITM2EJA/ENEURO.0069-20.html:text/html},
}

@article{poeppel_against_2020,
	title = {Against the {Epistemological} {Primacy} of the {Hardware}: {The} {Brain} from {Inside} {Out}, {Turned} {Upside} {Down}},
	volume = {7},
	copyright = {Copyright © 2020 Poeppel and Adolfi. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
	issn = {2373-2822},
	shorttitle = {Against the {Epistemological} {Primacy} of the {Hardware}},
	url = {https://www.eneuro.org/content/7/4/ENEURO.0215-20.2020},
	doi = {10.1523/ENEURO.0215-20.2020},
	abstract = {Before he wrote the recent book The Brain from Inside Out, the neuroscientist György Buzsáki previewed some of the arguments in a paper written 20 years ago (“The brain-cognitive behavior problem: a retrospective”), now finally published. The principal focus of the paper is the relationship between neuroscience and psychology. The direction in which that research had proceeded, and continues now, is, in his view, fundamentally misguided. Building on the critique, Buzsáki presents arguments for an “inside-out” approach, wherein the study of neurobiological objects has primacy over using psychological concepts to study the brain, and should, in fact, give rise to them. We argue that he is too pessimistic, and actually not quite right, about how the relation between cognition and neuroscience can be studied. Second, we are not in agreement with the normative recommendation of how to proceed: a predominantly brain first, implementation-driven research agenda. Finally, we raise concerns about the philosophical underpinning of the research program he advances. Buzsáki’s perspective merits careful examination, and we suggest that it can be linked in a productive way to ongoing research, aligning his inside-out approach with current work that yields convincing accounts of mind and brain.},
	language = {en},
	number = {4},
	urldate = {2020-08-10},
	journal = {eNeuro},
	author = {Poeppel, David and Adolfi, Federico},
	month = jul,
	year = {2020},
	pmid = {32769167},
	note = {Publisher: Society for Neuroscience
Section: Commentary},
	file = {Poeppel_Adolfi_2020_Against the Epistemological Primacy of the Hardware.pdf:/Users/tito/Zotero/storage/UD5PWPBQ/Poeppel_Adolfi_2020_Against the Epistemological Primacy of the Hardware.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5A7U5RN9/ENEURO.0215-20.html:text/html},
}

@article{kozachkov_achieving_2020,
	title = {Achieving stable dynamics in neural circuits},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007659},
	doi = {10.1371/journal.pcbi.1007659},
	abstract = {The brain consists of many interconnected networks with time-varying, partially autonomous activity. There are multiple sources of noise and variation yet activity has to eventually converge to a stable, reproducible state (or sequence of states) for its computations to make sense. We approached this problem from a control-theory perspective by applying contraction analysis to recurrent neural networks. This allowed us to find mechanisms for achieving stability in multiple connected networks with biologically realistic dynamics, including synaptic plasticity and time-varying inputs. These mechanisms included inhibitory Hebbian plasticity, excitatory anti-Hebbian plasticity, synaptic sparsity and excitatory-inhibitory balance. Our findings shed light on how stable computations might be achieved despite biological complexity. Crucially, our analysis is not limited to analyzing the stability of fixed geometric objects in state space (e.g points, lines, planes), but rather the stability of state trajectories which may be complex and time-varying.},
	language = {en},
	number = {8},
	urldate = {2020-08-11},
	journal = {PLOS Computational Biology},
	author = {Kozachkov, Leo and Lundqvist, Mikael and Slotine, Jean-Jacques and Miller, Earl K.},
	month = aug,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Dynamical systems, Neurons, Neural networks, Eigenvalues, Neural pathways, Neuronal plasticity, Synapses, Synaptic plasticity},
	pages = {e1007659},
	file = {Kozachkov et al_2020_Achieving stable dynamics in neural circuits.pdf:/Users/tito/Zotero/storage/XNTY9IBL/Kozachkov et al_2020_Achieving stable dynamics in neural circuits.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZG5YCQ97/peerReview.html:text/html},
}

@article{olsen_gain_2012,
	title = {Gain control by layer six in cortical circuits of vision},
	volume = {483},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature10835},
	doi = {10.1038/nature10835},
	abstract = {After entering the cerebral cortex, sensory information spreads through six different horizontal neuronal layers that are interconnected by vertical axonal projections. It is believed that through these projections layers can influence each other's response to sensory stimuli, but the specific role that each layer has in cortical processing is still poorly understood. Here we show that layer six in the primary visual cortex of the mouse has a crucial role in controlling the gain of visually evoked activity in neurons of the upper layers without changing their tuning to orientation. This gain modulation results from the coordinated action of layer six intracortical projections to superficial layers and deep projections to the thalamus, with a substantial role of the intracortical circuit. This study establishes layer six as a major mediator of cortical gain modulation and suggests that it could be a node through which convergent inputs from several brain areas can regulate the earliest steps of cortical visual processing.},
	language = {en},
	number = {7387},
	urldate = {2020-08-11},
	journal = {Nature},
	author = {Olsen, Shawn R. and Bortone, Dante S. and Adesnik, Hillel and Scanziani, Massimo},
	month = mar,
	year = {2012},
	note = {Number: 7387
Publisher: Nature Publishing Group},
	pages = {47--52},
	file = {Olsen et al_2012_Gain control by layer six in cortical circuits of vision.pdf:/Users/tito/Zotero/storage/HEISMBBN/Olsen et al_2012_Gain control by layer six in cortical circuits of vision.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Q4HJ76AX/nature10835.html:text/html},
}

@article{brown_intrinsic_2020,
	title = {Intrinsic brain activity gradients dynamically coordinate functional connectivity states},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.08.12.248112v1},
	doi = {10.1101/2020.08.12.248112},
	abstract = {{\textless}p{\textgreater}Brain areas are organized into functionally connected networks though the mechanism underlying this widespread coordination remains unclear. Here we apply deep learning-based dimensionality reduction to task-free functional magnetic resonance images to discover the principal latent dimensions of human brain functional activity. We find that each dimension corresponds to a distinct and stable spatial activity gradient. Brain areas are distributed non-uniformly along each gradient, reflecting modular boundaries and hub properties. Gradients appear to dynamically steepen or flatten to produce task-specific activation patterns. Dynamical systems modelling reveals that gradients can interact via state-specific coupling parameters, allowing accurate forecasts and simulations of brain activity during different tasks. Together, these findings indicate that a small set of overlapping global activity gradients determine the repertoire of possible functional connectivity states.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-08-14},
	journal = {bioRxiv},
	author = {Brown, Jesse A. and Lee, Alex J. and Pasquini, Lorenzo and Seeley, William W.},
	month = aug,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.08.12.248112},
	file = {Brown et al_2020_Intrinsic brain activity gradients dynamically coordinate functional.pdf:/Users/tito/Zotero/storage/YQIXTZDT/Brown et al_2020_Intrinsic brain activity gradients dynamically coordinate functional.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Q8AG9UUZ/2020.08.12.html:text/html},
}

@article{ito_task-evoked_2020,
	title = {Task-evoked activity quenches neural correlations and variability across cortical areas},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007983},
	doi = {10.1371/journal.pcbi.1007983},
	abstract = {Many large-scale functional connectivity studies have emphasized the importance of communication through increased inter-region correlations during task states. In contrast, local circuit studies have demonstrated that task states primarily reduce correlations among pairs of neurons, likely enhancing their information coding by suppressing shared spontaneous activity. Here we sought to adjudicate between these conflicting perspectives, assessing whether co-active brain regions during task states tend to increase or decrease their correlations. We found that variability and correlations primarily decrease across a variety of cortical regions in two highly distinct data sets: non-human primate spiking data and human functional magnetic resonance imaging data. Moreover, this observed variability and correlation reduction was accompanied by an overall increase in dimensionality (reflecting less information redundancy) during task states, suggesting that decreased correlations increased information coding capacity. We further found in both spiking and neural mass computational models that task-evoked activity increased the stability around a stable attractor, globally quenching neural variability and correlations. Together, our results provide an integrative mechanistic account that encompasses measures of large-scale neural activity, variability, and correlations during resting and task states.},
	language = {en},
	number = {8},
	urldate = {2020-08-14},
	journal = {PLOS Computational Biology},
	author = {Ito, Takuya and Brincat, Scott L. and Siegel, Markus and Mill, Ravi D. and He, Biyu J. and Miller, Earl K. and Rotstein, Horacio G. and Cole, Michael W.},
	month = aug,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Dynamical systems, Functional magnetic resonance imaging, Neurons, Network analysis, Vision, Covariance, Action potentials, Transfer functions},
	pages = {e1007983},
	file = {Ito et al_2020_Task-evoked activity quenches neural correlations and variability across.pdf:/Users/tito/Zotero/storage/PWY9FU3B/Ito et al_2020_Task-evoked activity quenches neural correlations and variability across.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/79RCBL9C/article.html:text/html},
}

@article{echeveste_cortical-like_2020,
	title = {Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-020-0671-1},
	doi = {10.1038/s41593-020-0671-1},
	abstract = {Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory–inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization and stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of recordings from awake monkeys. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function—fast sampling-based inference—and predict further properties of these motifs that can be tested in future experiments.},
	language = {en},
	urldate = {2020-08-14},
	journal = {Nature Neuroscience},
	author = {Echeveste, Rodrigo and Aitchison, Laurence and Hennequin, Guillaume and Lengyel, Máté},
	month = aug,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--12},
	file = {Echeveste et al_2020_Cortical-like dynamics in recurrent circuits optimized for sampling-based.pdf:/Users/tito/Zotero/storage/ZRSIMSSD/Echeveste et al_2020_Cortical-like dynamics in recurrent circuits optimized for sampling-based.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AQTCMDIE/s41593-020-0671-1.html:text/html},
}

@article{pollock_engineering_2020,
	title = {Engineering recurrent neural networks from task-relevant manifolds and dynamics},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008128},
	doi = {10.1371/journal.pcbi.1008128},
	abstract = {Many cognitive processes involve transformations of distributed representations in neural populations, creating a need for population-level models. Recurrent neural network models fulfill this need, but there are many open questions about how their connectivity gives rise to dynamics that solve a task. Here, we present a method for finding the connectivity of networks for which the dynamics are specified to solve a task in an interpretable way. We apply our method to a working memory task by synthesizing a network that implements a drift-diffusion process over a ring-shaped manifold. We also use our method to demonstrate how inputs can be used to control network dynamics for cognitive flexibility and explore the relationship between representation geometry and network capacity. Our work fits within the broader context of understanding neural computations as dynamics over relatively low-dimensional manifolds formed by correlated patterns of neurons.},
	language = {en},
	number = {8},
	urldate = {2020-08-14},
	journal = {PLOS Computational Biology},
	author = {Pollock, Eli and Jazayeri, Mehrdad},
	month = aug,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Dynamical systems, Behavior, Neurons, Eigenvalues, Recurrent neural networks, Eigenvectors, Manifolds, Non-Euclidean geometry},
	pages = {e1008128},
	file = {Pollock_Jazayeri_2020_Engineering recurrent neural networks from task-relevant manifolds and dynamics.pdf:/Users/tito/Zotero/storage/SCNWSXQ9/Pollock_Jazayeri_2020_Engineering recurrent neural networks from task-relevant manifolds and dynamics.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IXR3UQJQ/article.html:text/html},
}

@article{raut_hierarchical_2020,
	title = {Hierarchical dynamics as a macroscopic organizing principle of the human brain},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2020/08/11/2003383117},
	doi = {10.1073/pnas.2003383117},
	abstract = {Multimodal evidence suggests that brain regions accumulate information over timescales that vary according to anatomical hierarchy. Thus, these experimentally defined “temporal receptive windows” are longest in cortical regions that are distant from sensory input. Interestingly, spontaneous activity in these regions also plays out over relatively slow timescales (i.e., exhibits slower temporal autocorrelation decay). These findings raise the possibility that hierarchical timescales represent an intrinsic organizing principle of brain function. Here, using resting-state functional MRI, we show that the timescale of ongoing dynamics follows hierarchical spatial gradients throughout human cerebral cortex. These intrinsic timescale gradients give rise to systematic frequency differences among large-scale cortical networks and predict individual-specific features of functional connectivity. Whole-brain coverage permitted us to further investigate the large-scale organization of subcortical dynamics. We show that cortical timescale gradients are topographically mirrored in striatum, thalamus, and cerebellum. Finally, timescales in the hippocampus followed a posterior-to-anterior gradient, corresponding to the longitudinal axis of increasing representational scale. Thus, hierarchical dynamics emerge as a global organizing principle of mammalian brains.},
	language = {en},
	urldate = {2020-08-17},
	journal = {PNAS},
	author = {Raut, Ryan V. and Snyder, Abraham Z. and Raichle, Marcus E.},
	month = aug,
	year = {2020},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {fMRI, functional connectivity, frequency, intrinsic, subcortex},
	file = {Raut et al_2020_Hierarchical dynamics as a macroscopic organizing principle of the human brain.pdf:/Users/tito/Zotero/storage/XZVPFI44/Raut et al_2020_Hierarchical dynamics as a macroscopic organizing principle of the human brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Z7GG4MEC/2003383117.html:text/html},
}

@article{reverberi_compositionality_2012,
	title = {Compositionality of {Rule} {Representations} in {Human} {Prefrontal} {Cortex}},
	volume = {22},
	issn = {1460-2199, 1047-3211},
	url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhr200},
	doi = {10.1093/cercor/bhr200},
	abstract = {Rules are widely used in everyday life to organize actions and thoughts in accordance with our internal goals. At the simplest level, single rules can be used to link individual sensory stimuli to their appropriate responses. However, most tasks are more complex and require the concurrent application of multiple rules. Experiments on humans and monkeys have shown the involvement of a frontoparietal network in rule representation. Yet, a fundamental issue still needs to be clariﬁed: Is the neural representation of multiple rules compositional, that is, built on the neural representation of their simple constituent rules? Subjects were asked to remember and apply either simple or compound rules. Multivariate decoding analyses were applied to functional magnetic resonance imaging data. Both ventrolateral frontal and lateral parietal cortex were involved in compound representation. Most importantly, we were able to decode the compound rules by training classiﬁers only on the simple rules they were composed of. This shows that the code used to store rule information in prefrontal cortex is compositional. Compositional coding in rule representation suggests that it might be possible to decode other complex action plans by learning the neural patterns of the known composing elements.},
	language = {en},
	number = {6},
	urldate = {2020-08-18},
	journal = {Cerebral Cortex},
	author = {Reverberi, Carlo and Görgen, Kai and Haynes, John-Dylan},
	month = jun,
	year = {2012},
	pages = {1237--1246},
	file = {Reverberi et al. - 2012 - Compositionality of Rule Representations in Human .pdf:/Users/tito/Zotero/storage/G7UVRIUP/Reverberi et al. - 2012 - Compositionality of Rule Representations in Human .pdf:application/pdf},
}

@article{tang_effective_2019,
	title = {Effective learning is accompanied by high-dimensional and efficient representations of neural activity},
	volume = {22},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0400-9},
	doi = {10.1038/s41593-019-0400-9},
	abstract = {A fundamental cognitive process is to map value and identity onto the objects we learn about. However, what space best embeds this mapping is not completely understood. Here we develop tools to quantify the space and organization of such a mapping in neural responses as reflected in functional MRI, to show that quick learners have a higher dimensional representation than slow learners, and hence more easily distinguishable whole-brain responses to objects of different value. Furthermore, we find that quick learners display more compact embedding of their neural responses, and hence have higher ratios of their stimuli dimension to their embedding dimension, which is consistent with greater efficiency of cognitive coding. Lastly, we investigate the neurophysiological drivers at smaller scales and study the complementary distinguishability of whole-brain responses. Our results demonstrate a spatial organization of neural responses characteristic of learning and offer geometric measures applicable to identifying efficient coding in higher-order cognitive processes.},
	language = {en},
	number = {6},
	urldate = {2020-08-21},
	journal = {Nature Neuroscience},
	author = {Tang, Evelyn and Mattar, Marcelo G. and Giusti, Chad and Lydon-Staley, David M. and Thompson-Schill, Sharon L. and Bassett, Danielle S.},
	month = jun,
	year = {2019},
	note = {Number: 6
Publisher: Nature Publishing Group},
	pages = {1000--1009},
	file = {Snapshot:/Users/tito/Zotero/storage/MQ9DEZD7/s41593-019-0400-9.html:text/html;Tang et al_2019_Effective learning is accompanied by high-dimensional and efficient.pdf:/Users/tito/Zotero/storage/LWV27YI9/Tang et al_2019_Effective learning is accompanied by high-dimensional and efficient.pdf:application/pdf},
}

@misc{noauthor_at_nodate,
	title = {At the {Leading} {Front} of {Neuroscience}: {A} {Bibliometric} {Study} of the 100 {Most}-{Cited} {Articles}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5520389/#!po=28.1250},
	urldate = {2020-08-21},
	file = {At the Leading Front of Neuroscience\: A Bibliometric Study of the 100 Most-Cited Articles:/Users/tito/Zotero/storage/3VDBHR3I/PMC5520389.html:text/html},
}

@article{recanatesi_dimensionality_2019-1,
	title = {Dimensionality in recurrent spiking networks: {Global} trends in activity and local origins in connectivity},
	volume = {15},
	issn = {1553-7358},
	shorttitle = {Dimensionality in recurrent spiking networks},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006446},
	doi = {10.1371/journal.pcbi.1006446},
	abstract = {The dimensionality of a network’s collective activity is of increasing interest in neuroscience. This is because dimensionality provides a compact measure of how coordinated network-wide activity is, in terms of the number of modes (or degrees of freedom) that it can independently explore. A low number of modes suggests a compressed low dimensional neural code and reveals interpretable dynamics [1], while findings of high dimension may suggest flexible computations [2, 3]. Here, we address the fundamental question of how dimensionality is related to connectivity, in both autonomous and stimulus-driven networks. Working with a simple spiking network model, we derive three main findings. First, the dimensionality of global activity patterns can be strongly, and systematically, regulated by local connectivity structures. Second, the dimensionality is a better indicator than average correlations in determining how constrained neural activity is. Third, stimulus evoked neural activity interacts systematically with neural connectivity patterns, leading to network responses of either greater or lesser dimensionality than the stimulus.},
	language = {en},
	number = {7},
	urldate = {2020-08-25},
	journal = {PLOS Computational Biology},
	author = {Recanatesi, Stefano and Ocker, Gabriel Koch and Buice, Michael A. and Shea-Brown, Eric},
	month = jul,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Network analysis, Neural networks, Covariance, Action potentials, Network motifs, Network reciprocity, Scale-free networks},
	pages = {e1006446},
	file = {Recanatesi et al_2019_Dimensionality in recurrent spiking networks.pdf:/Users/tito/Zotero/storage/7ICDHGB8/Recanatesi et al_2019_Dimensionality in recurrent spiking networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MNN3SNPH/article.html:text/html},
}

@article{spitmaan_multiple_2020,
	title = {Multiple timescales of neural dynamics and integration of task-relevant signals across cortex},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.02.18.955427v1},
	doi = {10.1101/2020.02.18.955427},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Recent studies have proposed the orderly progression in the time constants of neural dynamics as an organizational principle of cortical computations. However, relationships between these timescales and their dependence on response properties of individual neurons are unknown. We developed a comprehensive method to simultaneously estimate multiple timescales in neuronal dynamics and integration of task-relevant signals along with selectivity to those signals. We found that most neurons exhibited multiple timescales in their response, which consistently increased from parietal to prefrontal to cingulate cortex. While predicting rates of behavioral adjustments, these timescales were not correlated across individual neurons in any cortical area, resulting in independent parallel hierarchies of timescales. Additionally, none of these timescales depended on selectivity to task-relevant signals. Our results not only suggest multiple canonical mechanisms for increasing timescales of neural dynamics across cortex but also point to additional mechanisms that allow decorrelation of these timescales to enable more flexibility.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-08-25},
	journal = {bioRxiv},
	author = {Spitmaan, Mehran and Seo, Hyojung and Lee, Daeyeol and Soltani, Alireza},
	month = feb,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.02.18.955427},
	file = {Snapshot:/Users/tito/Zotero/storage/TWC6WKMD/2020.02.18.955427v1.html:text/html;Spitmaan et al_2020_Multiple timescales of neural dynamics and integration of task-relevant signals.pdf:/Users/tito/Zotero/storage/Z4DKPZNR/Spitmaan et al_2020_Multiple timescales of neural dynamics and integration of task-relevant signals.pdf:application/pdf},
}

@article{cueva_low-dimensional_2020,
	title = {Low-dimensional dynamics for working memory and time encoding},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2020/08/27/1915984117},
	doi = {10.1073/pnas.1915984117},
	abstract = {Our decisions often depend on multiple sensory experiences separated by time delays. The brain can remember these experiences and, simultaneously, estimate the timing between events. To understand the mechanisms underlying working memory and time encoding, we analyze neural activity recorded during delays in four experiments on nonhuman primates. To disambiguate potential mechanisms, we propose two analyses, namely, decoding the passage of time from neural data and computing the cumulative dimensionality of the neural trajectory over time. Time can be decoded with high precision in tasks where timing information is relevant and with lower precision when irrelevant for performing the task. Neural trajectories are always observed to be low-dimensional. In addition, our results further constrain the mechanisms underlying time encoding as we find that the linear “ramping” component of each neuron’s firing rate strongly contributes to the slow timescale variations that make decoding time possible. These constraints rule out working memory models that rely on constant, sustained activity and neural networks with high-dimensional trajectories, like reservoir networks. Instead, recurrent networks trained with backpropagation capture the time-encoding properties and the dimensionality observed in the data.},
	language = {en},
	urldate = {2020-08-28},
	journal = {PNAS},
	author = {Cueva, Christopher J. and Saez, Alex and Marcos, Encarni and Genovesio, Aldo and Jazayeri, Mehrdad and Romo, Ranulfo and Salzman, C. Daniel and Shadlen, Michael N. and Fusi, Stefano},
	month = aug,
	year = {2020},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {recurrent networks, working memory, neural dynamics, reservoir computing, time decoding},
	file = {Cueva et al_2020_Low-dimensional dynamics for working memory and time encoding.pdf:/Users/tito/Zotero/storage/D8GK4QH8/Cueva et al_2020_Low-dimensional dynamics for working memory and time encoding.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/K33ZENQ7/1915984117.html:text/html},
}

@article{champion_data-driven_2019,
	title = {Data-driven discovery of coordinates and governing equations},
	volume = {116},
	copyright = {Copyright © 2019 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/45/22445},
	doi = {10.1073/pnas.1906995116},
	abstract = {The discovery of governing equations from scientific data has the potential to transform data-rich fields that lack well-characterized quantitative descriptions. Advances in sparse regression are currently enabling the tractable identification of both the structure and parameters of a nonlinear dynamical system from data. The resulting models have the fewest terms necessary to describe the dynamics, balancing model complexity with descriptive ability, and thus promoting interpretability and generalizability. This provides an algorithmic approach to Occam’s razor for model discovery. However, this approach fundamentally relies on an effective coordinate system in which the dynamics have a simple representation. In this work, we design a custom deep autoencoder network to discover a coordinate transformation into a reduced space where the dynamics may be sparsely represented. Thus, we simultaneously learn the governing equations and the associated coordinate system. We demonstrate this approach on several example high-dimensional systems with low-dimensional behavior. The resulting modeling framework combines the strengths of deep neural networks for flexible representation and sparse identification of nonlinear dynamics (SINDy) for parsimonious models. This method places the discovery of coordinates and models on an equal footing.},
	language = {en},
	number = {45},
	urldate = {2020-08-29},
	journal = {PNAS},
	author = {Champion, Kathleen and Lusch, Bethany and Kutz, J. Nathan and Brunton, Steven L.},
	month = nov,
	year = {2019},
	pmid = {31636218},
	note = {Publisher: National Academy of Sciences
Section: Physical Sciences},
	keywords = {machine learning, dynamical systems, deep learning, model discovery},
	pages = {22445--22451},
	file = {Champion et al_2019_Data-driven discovery of coordinates and governing equations.pdf:/Users/tito/Zotero/storage/SJDVN8WR/Champion et al_2019_Data-driven discovery of coordinates and governing equations.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/27TWZY8K/22445.html:text/html},
}

@article{li_representation_1993,
	title = {The representation of stimulus familiarity in anterior inferior temporal cortex},
	volume = {69},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/abs/10.1152/jn.1993.69.6.1918},
	doi = {10.1152/jn.1993.69.6.1918},
	abstract = {1. The inferior temporal (IT) cortex plays an important role in both short- and long-term memory for visual patterns. Most previous studies of IT neurons have tested their responses in recency memory tasks, which require that the memory lasts only the length of a single behavioral trial, which may be {\textless} 1 s. To determine the role of IT neurons in longer lasting memories, we measured their responses to initially novel stimuli as the stimuli gradually became familiar to the animal. 2. Two rhesus monkeys were trained on a delayed matching to sample (DMS) task with several intervening stimuli between the sample and the final matching stimulus on each trial. The purpose of the task was to ensure that the animal attended to the stimuli and held them in memory, at least temporarily. Unlike in several previous studies, the focus was not on within-trial effects but rather on the incidental memories that built up across trials as the stimuli became familiar. Each cell was tested with a set of 20 novel stimuli (digitized pictures of objects) that the monkey had not seen before. These stimuli were used in a fixed order over the course of an hour-long recording session, and the number of intervening trials between repetitions of a given sample stimulus was varied. 3. The responses of about one-third of the cells recorded in anterior-ventral IT cortex declined systematically as the novel stimuli became familiar. After six to eight repetitions, responses reached a plateau that was approximately 40\% of the peak response. Virtually all of these cells also showed selectivity for particular visual stimuli and thus were not "novelty detectors" in the sense of cells that respond to any novel stimulus. Rather, the responses of these cells were a joint function of familiarity and specific object features such as shape and color. A few cells showed increasing responses with repetition over the recording session, but these changes were accompanied by changes in baseline firing rate, suggesting that they were caused by nonspecific effects. 4. The decrement in response with familiarity was stimulus specific and bridged {\textgreater} 150 presentations of other stimuli, the maximum tested. For some cells the maximum decrement in response occurred for those stimuli that initially elicited the largest response. There was no significant change in response to stimuli that were already familiar. 5. The same cells that showed familiarity effects also showed reduced responses to the matching stimuli at the end of each trial, compared with the responses to the samples.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {6},
	urldate = {2020-09-04},
	journal = {Journal of Neurophysiology},
	author = {Li, L. and Miller, E. K. and Desimone, R.},
	month = jun,
	year = {1993},
	note = {Publisher: American Physiological Society},
	pages = {1918--1929},
	file = {Li et al_1993_The representation of stimulus familiarity in anterior inferior temporal cortex.pdf:/Users/tito/Zotero/storage/LGZCZNPK/Li et al_1993_The representation of stimulus familiarity in anterior inferior temporal cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5L2NP8PK/jn.1993.69.6.html:text/html},
}

@article{veness_gated_2020,
	title = {Gated {Linear} {Networks}},
	url = {http://arxiv.org/abs/1910.01526},
	abstract = {This paper presents a new family of backpropagation-free neural architectures, Gated Linear Networks (GLNs). What distinguishes GLNs from contemporary neural networks is the distributed and local nature of their credit assignment mechanism; each neuron directly predicts the target, forgoing the ability to learn feature representations in favor of rapid online learning. Individual neurons can model nonlinear functions via the use of data-dependent gating in conjunction with online convex optimization. We show that this architecture gives rise to universal learning capabilities in the limit, with effective model capacity increasing as a function of network size in a manner comparable with deep ReLU networks. Furthermore, we demonstrate that the GLN learning mechanism possesses extraordinary resilience to catastrophic forgetting, performing comparably to a MLP with dropout and Elastic Weight Consolidation on standard benchmarks. These desirable theoretical and empirical properties position GLNs as a complementary technique to contemporary offline deep learning methods.},
	urldate = {2020-09-10},
	journal = {arXiv:1910.01526 [cs, math, stat]},
	author = {Veness, Joel and Lattimore, Tor and Budden, David and Bhoopchand, Avishkar and Mattern, Christopher and Grabska-Barwinska, Agnieszka and Sezener, Eren and Wang, Jianan and Toth, Peter and Schmitt, Simon and Hutter, Marcus},
	month = jun,
	year = {2020},
	note = {arXiv: 1910.01526},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory},
	annote = {Comment: arXiv admin note: substantial text overlap with arXiv:1712.01897},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/KG5PZP52/1910.html:text/html;Veness et al_2020_Gated Linear Networks.pdf:/Users/tito/Zotero/storage/8UCVXDIP/Veness et al_2020_Gated Linear Networks.pdf:application/pdf},
}

@article{sezener_online_2020,
	title = {Online {Learning} in {Contextual} {Bandits} using {Gated} {Linear} {Networks}},
	url = {http://arxiv.org/abs/2002.11611},
	abstract = {We introduce a new and completely online contextual bandit algorithm called Gated Linear Contextual Bandits (GLCB). This algorithm is based on Gated Linear Networks (GLNs), a recently introduced deep learning architecture with properties well-suited to the online setting. Leveraging data-dependent gating properties of the GLN we are able to estimate prediction uncertainty with effectively zero algorithmic overhead. We empirically evaluate GLCB compared to 9 state-of-the-art algorithms that leverage deep neural networks, on a standard benchmark suite of discrete and continuous contextual bandit problems. GLCB obtains median first-place despite being the only online method, and we further support these results with a theoretical study of its convergence properties.},
	urldate = {2020-09-10},
	journal = {arXiv:2002.11611 [cs, stat]},
	author = {Sezener, Eren and Hutter, Marcus and Budden, David and Wang, Jianan and Veness, Joel},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.11611},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/BCGWN6HN/2002.html:text/html;Sezener et al_2020_Online Learning in Contextual Bandits using Gated Linear Networks.pdf:/Users/tito/Zotero/storage/CQ4Z96EZ/Sezener et al_2020_Online Learning in Contextual Bandits using Gated Linear Networks.pdf:application/pdf},
}

@inproceedings{zenke_continual_2017,
	address = {Sydney, NSW, Australia},
	series = {{ICML}'17},
	title = {Continual learning through synaptic intelligence},
	abstract = {While deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning. In stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously. In this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks. Each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones. We evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.},
	urldate = {2020-09-11},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning} - {Volume} 70},
	publisher = {JMLR.org},
	author = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
	month = aug,
	year = {2017},
	pages = {3987--3995},
	file = {Zenke et al_2017_Continual learning through synaptic intelligence.pdf:/Users/tito/Zotero/storage/V4YYX5EW/Zenke et al_2017_Continual learning through synaptic intelligence.pdf:application/pdf},
}

@article{kirkpatrick_overcoming_2017,
	title = {Overcoming catastrophic forgetting in neural networks},
	url = {http://arxiv.org/abs/1612.00796},
	abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
	urldate = {2020-09-11},
	journal = {arXiv:1612.00796 [cs, stat]},
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	month = jan,
	year = {2017},
	note = {arXiv: 1612.00796},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/NEQTTGPD/1612.html:text/html;Kirkpatrick et al_2017_Overcoming catastrophic forgetting in neural networks.pdf:/Users/tito/Zotero/storage/U3VK8CU7/Kirkpatrick et al_2017_Overcoming catastrophic forgetting in neural networks.pdf:application/pdf},
}

@article{liegeois_revisiting_2020,
	title = {Revisiting correlation-based functional connectivity and its relationship with structural connectivity},
	issn = {2472-1751},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/netn_a_00166},
	doi = {10.1162/netn_a_00166},
	abstract = {Patterns of brain structural connectivity (SC) and functional connectivity (FC) are known to be related. In SC-FC comparisons, FC has classically been evaluated from correlations between functional time series, and more recently from partial correlations or their unnormalized version encoded in the precision matrix. The latter FC metrics yields more meaningful comparisons to SC because they capture ‘direct’ statistical dependencies, i.e., discarding the effects of mediators, but their use has been limited because of estimation issues. With the rise of high-quality and large neuroimaging datasets, we revisit relevance of different FC metrics in the context of SC-FC comparisons. Using data from 100 unrelated HCP subjects, we ﬁrst explore the amount of functional data required to reliably estimate various FC metrics. We ﬁnd that precision-based FC yields a better match to SC than correlation-based FC when using 5 minutes of functional data or more. Finally, using a linear model linking SC and FC, we show that the SC-FC match can be used to further interrogate various aspects of brain structure and function such as the timescales of functional dynamics in different resting-state networks or the intensity of anatomical self-connections.},
	language = {en},
	urldate = {2020-09-14},
	journal = {Network Neuroscience},
	author = {Liégeois, Raphaël and Santos, Augusto and Matta, Vincenzo and Van De Ville, Dimitri and Sayed, Ali H.},
	month = aug,
	year = {2020},
	pages = {1--25},
	file = {Liégeois et al. - 2020 - Revisiting correlation-based functional connectivi.pdf:/Users/tito/Zotero/storage/3RR6SCXE/Liégeois et al. - 2020 - Revisiting correlation-based functional connectivi.pdf:application/pdf},
}

@article{duchi_adaptive_2011,
	title = {Adaptive {Subgradient} {Methods} for {Online} {Learning} and {Stochastic} {Optimization}},
	volume = {12},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v12/duchi11a.html},
	number = {61},
	urldate = {2020-09-14},
	journal = {Journal of Machine Learning Research},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	year = {2011},
	pages = {2121--2159},
	file = {Duchi et al_2011_Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.pdf:/Users/tito/Zotero/storage/M8DKT9XZ/Duchi et al_2011_Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/G8J89HHL/duchi11a.html:text/html},
}

@article{barreto_fast_2020,
	title = {Fast reinforcement learning with generalized policy updates},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2020/08/13/1907370117},
	doi = {10.1073/pnas.1907370117},
	abstract = {The combination of reinforcement learning with deep learning is a promising approach to tackle important sequential decision-making problems that are currently intractable. One obstacle to overcome is the amount of data needed by learning systems of this type. In this article, we propose to address this issue through a divide-and-conquer approach. We argue that complex decision problems can be naturally decomposed into multiple tasks that unfold in sequence or in parallel. By associating each task with a reward function, this problem decomposition can be seamlessly accommodated within the standard reinforcement-learning formalism. The specific way we do so is through a generalization of two fundamental operations in reinforcement learning: policy improvement and policy evaluation. The generalized version of these operations allow one to leverage the solution of some tasks to speed up the solution of others. If the reward function of a task can be well approximated as a linear combination of the reward functions of tasks previously solved, we can reduce a reinforcement-learning problem to a simpler linear regression. When this is not the case, the agent can still exploit the task solutions by using them to interact with and learn about the environment. Both strategies considerably reduce the amount of data needed to solve a reinforcement-learning problem.},
	language = {en},
	urldate = {2020-09-14},
	journal = {PNAS},
	author = {Barreto, André and Hou, Shaobo and Borsa, Diana and Silver, David and Precup, Doina},
	month = aug,
	year = {2020},
	pmid = {32817541},
	note = {Publisher: National Academy of Sciences
Section: Physical Sciences},
	keywords = {artificial intelligence, reinforcement learning, generalized policy evaluation, generalized policy improvement, successor features},
	file = {Barreto et al_2020_Fast reinforcement learning with generalized policy updates.pdf:/Users/tito/Zotero/storage/A64QZVJU/Barreto et al_2020_Fast reinforcement learning with generalized policy updates.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/7GTEGI8R/1907370117.html:text/html},
}

@article{van_de_ven_three_2019,
	title = {Three scenarios for continual learning},
	url = {http://arxiv.org/abs/1904.07734},
	abstract = {Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and--in case it is not--whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted MNIST task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.},
	urldate = {2020-09-14},
	journal = {arXiv:1904.07734 [cs, stat]},
	author = {van de Ven, Gido M. and Tolias, Andreas S.},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.07734},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Extended version of work presented at the NeurIPS Continual Learning workshop (2018); 18 pages, 5 figures, 6 tables. Related to arXiv:1809.10635},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/FUQETIYS/1904.html:text/html;van de Ven_Tolias_2019_Three scenarios for continual learning.pdf:/Users/tito/Zotero/storage/VUV2ZYS2/van de Ven_Tolias_2019_Three scenarios for continual learning.pdf:application/pdf},
}

@article{benna_computational_2016,
	title = {Computational principles of synaptic memory consolidation},
	volume = {19},
	copyright = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.4401},
	doi = {10.1038/nn.4401},
	abstract = {The biological mechanisms underlying memory are complex and typically involve multiple molecular processes operating on timescales ranging from fractions of a second to years. The authors show using a mathematical model of synaptic plasticity and consolidation that this complexity can help explain the formidable memory capacity of biological systems.},
	language = {en},
	number = {12},
	urldate = {2020-09-15},
	journal = {Nature Neuroscience},
	author = {Benna, Marcus K. and Fusi, Stefano},
	month = dec,
	year = {2016},
	note = {Number: 12
Publisher: Nature Publishing Group},
	pages = {1697--1706},
	file = {Benna_Fusi_2016_Computational principles of synaptic memory consolidation.pdf:/Users/tito/Zotero/storage/8RLRAUQW/Benna_Fusi_2016_Computational principles of synaptic memory consolidation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/57LH2JT9/nn.html:text/html},
}

@article{masse_alleviating_2018,
	title = {Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization},
	volume = {115},
	copyright = {© 2018 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/44/E10467},
	doi = {10.1073/pnas.1803839115},
	abstract = {Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks (ANNs) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of “catastrophic forgetting,” in which training an ANN disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of ANNs that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows ANNs to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.},
	language = {en},
	number = {44},
	urldate = {2020-09-15},
	journal = {PNAS},
	author = {Masse, Nicolas Y. and Grant, Gregory D. and Freedman, David J.},
	month = oct,
	year = {2018},
	pmid = {30315147},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {artificial intelligence, catastrophic forgetting, context-dependent gating, continual learning, synaptic stabilization},
	pages = {E10467--E10475},
	file = {Masse et al_2018_Alleviating catastrophic forgetting using context-dependent gating and synaptic.pdf:/Users/tito/Zotero/storage/KYJXTPFD/Masse et al_2018_Alleviating catastrophic forgetting using context-dependent gating and synaptic.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DWCP29I5/E10467.html:text/html},
}

@incollection{shin_continual_2017,
	title = {Continual {Learning} with {Deep} {Generative} {Replay}},
	url = {http://papers.nips.cc/paper/6892-continual-learning-with-deep-generative-replay.pdf},
	urldate = {2020-09-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {2990--2999},
	file = {NIPS Snapshot:/Users/tito/Zotero/storage/T9DPP57R/6892-continual-learning-with-deep-generative-replay.html:text/html;Shin et al_2017_Continual Learning with Deep Generative Replay.pdf:/Users/tito/Zotero/storage/T6XI8I8X/Shin et al_2017_Continual Learning with Deep Generative Replay.pdf:application/pdf},
}

@article{wen_batchensemble_2020,
	title = {{BatchEnsemble}: {An} {Alternative} {Approach} to {Efficient} {Ensemble} and {Lifelong} {Learning}},
	shorttitle = {{BatchEnsemble}},
	url = {http://arxiv.org/abs/2002.06715},
	abstract = {Ensembles, where multiple neural networks are trained individually and their predictions are averaged, have been shown to be widely successful for improving both the accuracy and predictive uncertainty of single neural networks. However, an ensemble's cost for both training and testing increases linearly with the number of networks, which quickly becomes untenable. In this paper, we propose BatchEnsemble, an ensemble method whose computational and memory costs are significantly lower than typical ensembles. BatchEnsemble achieves this by defining each weight matrix to be the Hadamard product of a shared weight among all ensemble members and a rank-one matrix per member. Unlike ensembles, BatchEnsemble is not only parallelizable across devices, where one device trains one member, but also parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks, BatchEnsemble yields competitive accuracy and uncertainties as typical ensembles; the speedup at test time is 3X and memory reduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to lifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable performance to progressive neural networks while having a much lower computational and memory costs. We further show that BatchEnsemble can easily scale up to lifelong learning on Split-ImageNet which involves 100 sequential learning tasks.},
	urldate = {2020-09-15},
	journal = {arXiv:2002.06715 [cs, stat]},
	author = {Wen, Yeming and Tran, Dustin and Ba, Jimmy},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.06715},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/9IFKNBI5/2002.html:text/html;Wen et al_2020_BatchEnsemble.pdf:/Users/tito/Zotero/storage/I6U2TZB4/Wen et al_2020_BatchEnsemble.pdf:application/pdf},
}

@article{riemer_learning_2019,
	title = {Learning to {Learn} without {Forgetting} by {Maximizing} {Transfer} and {Minimizing} {Interference}},
	url = {http://arxiv.org/abs/1810.11910},
	abstract = {Lack of performance when it comes to continual learning over non-stationary distributions of data remains a major challenge in scaling neural network learning to more human realistic settings. In this work we propose a new conceptualization of the continual learning problem in terms of a temporally symmetric trade-off between transfer and interference that can be optimized by enforcing gradient alignment across examples. We then propose a new algorithm, Meta-Experience Replay (MER), that directly exploits this view by combining experience replay with optimization based meta-learning. This method learns parameters that make interference based on future gradients less likely and transfer based on future gradients more likely. We conduct experiments across continual lifelong supervised learning benchmarks and non-stationary reinforcement learning environments demonstrating that our approach consistently outperforms recently proposed baselines for continual learning. Our experiments show that the gap between the performance of MER and baseline algorithms grows both as the environment gets more non-stationary and as the fraction of the total experiences stored gets smaller.},
	urldate = {2020-09-15},
	journal = {arXiv:1810.11910 [cs, stat]},
	author = {Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
	month = may,
	year = {2019},
	note = {arXiv: 1810.11910},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR 2019},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/63CEKNEP/1810.html:text/html;Riemer et al_2019_Learning to Learn without Forgetting by Maximizing Transfer and Minimizing.pdf:/Users/tito/Zotero/storage/8PJCW6XQ/Riemer et al_2019_Learning to Learn without Forgetting by Maximizing Transfer and Minimizing.pdf:application/pdf},
}

@article{bertolero_learning_2020,
	title = {Learning differentially reorganizes brain activity and connectivity},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.02.23.961623v1},
	doi = {10.1101/2020.02.23.961623},
	abstract = {{\textless}p{\textgreater}Human learning is a complex process in which future behavior is altered via the reorganization of brain activity and connectivity. It remains unknown whether activity and connectivity differentially reorganize during learning, and, if so, how that differential reorganization tracks stages of learning across distinct brain areas. Here, we address this gap in knowledge by measuring brain activity and functional connectivity in a longitudinal fMRI experiment in which healthy adult human participants learn the values of novel objects over the course of four days. An increasing similarity in activity or functional connectivity across subjects during learning reflects reorganization toward a common functional architecture. We assessed the presence of reorganization in activity and connectivity both during value learning and during the resting-state, allowing us to differentiate common elicited processes from intrinsic processes. We found a complex and dynamic reorganization of brain connectivity and activity—as a function of time, space, and performance—that occurs while subjects learn. Spatially localized brain activity reorganizes across the brain to a common functional architecture early in learning, and this reorganization tracks early learning performance. In contrast, spatially distributed connectivity reorganizes across the brain to a common functional architecture as training progresses, and this reorganization tracks later learning performance. Particularly good performance is associated with a sticky connectivity, that persists into the resting state. Broadly, our work uncovers distinct principles of reorganization in activity and connectivity at different phases of value learning, which inform the ongoing study of learning processes more generally.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-09-15},
	journal = {bioRxiv},
	author = {Bertolero, Maxwell A. and Adebimpe, Azeez and Khambhati, Ankit N. and Mattar, Marcelo G. and Romer, Daniel and Thompson-Schill, Sharon L. and Bassett, Danielle S.},
	month = feb,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.02.23.961623},
	file = {Bertolero et al_2020_Learning differentially reorganizes brain activity and connectivity.pdf:/Users/tito/Zotero/storage/TCQA3ZA9/Bertolero et al_2020_Learning differentially reorganizes brain activity and connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VHDGQLVT/2020.02.23.html:text/html},
}

@article{chen_simple_2020,
	title = {A {Simple} {Framework} for {Contrastive} {Learning} of {Visual} {Representations}},
	url = {http://arxiv.org/abs/2002.05709},
	abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming AlexNet with 100X fewer labels.},
	urldate = {2020-09-17},
	journal = {arXiv:2002.05709 [cs, stat]},
	author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	month = jun,
	year = {2020},
	note = {arXiv: 2002.05709},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICML'2020. Code and pretrained models at https://github.com/google-research/simclr},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/RPH9F5SD/2002.html:text/html;Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:/Users/tito/Zotero/storage/X6W3NHQU/Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:application/pdf},
}

@article{nakkiran_distributional_2020,
	title = {Distributional {Generalization}: {A} {New} {Kind} of {Generalization}},
	shorttitle = {Distributional {Generalization}},
	url = {http://arxiv.org/abs/2009.08092},
	abstract = {We introduce a new notion of generalization-- Distributional Generalization-- which roughly states that outputs of a classifier at train and test time are close *as distributions*, as opposed to close in just their average error. For example, if we mislabel 30\% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30\% of dogs as cats on the *test set* as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. This example is a specific instance of our much more general conjectures which apply even on distributions where the Bayes risk is zero. Our conjectures characterize the form of distributional generalization that can be expected, in terms of problem parameters (model architecture, training procedure, number of samples, data distribution). We verify the quantitative predictions of these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. These empirical observations are independently interesting, and form a more fine-grained characterization of interpolating classifiers beyond just their test error.},
	urldate = {2020-09-18},
	journal = {arXiv:2009.08092 [cs, math, stat]},
	author = {Nakkiran, Preetum and Bansal, Yamini},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.08092},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Statistics Theory},
	annote = {Comment: PN, YB co-first authors},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/5SHAFBEQ/2009.html:text/html;Nakkiran_Bansal_2020_Distributional Generalization.pdf:/Users/tito/Zotero/storage/SR6EB8R9/Nakkiran_Bansal_2020_Distributional Generalization.pdf:application/pdf},
}

@article{rosenbaum_routing_2019,
	title = {Routing {Networks} and the {Challenges} of {Modular} and {Compositional} {Computation}},
	url = {http://arxiv.org/abs/1904.12774},
	abstract = {Compositionality is a key strategy for addressing combinatorial complexity and the curse of dimensionality. Recent work has shown that compositional solutions can be learned and offer substantial gains across a variety of domains, including multi-task learning, language modeling, visual question answering, machine comprehension, and others. However, such models present unique challenges during training when both the module parameters and their composition must be learned jointly. In this paper, we identify several of these issues and analyze their underlying causes. Our discussion focuses on routing networks, a general approach to this problem, and examines empirically the interplay of these challenges and a variety of design decisions. In particular, we consider the effect of how the algorithm decides on module composition, how the algorithm updates the modules, and if the algorithm uses regularization.},
	urldate = {2020-09-21},
	journal = {arXiv:1904.12774 [cs, stat]},
	author = {Rosenbaum, Clemens and Cases, Ignacio and Riemer, Matthew and Klinger, Tim},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.12774
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/PRPYQBH2/1904.html:text/html;Rosenbaum et al_2019_Routing Networks and the Challenges of Modular and Compositional Computation.pdf:/Users/tito/Zotero/storage/B7BRE22R/Rosenbaum et al_2019_Routing Networks and the Challenges of Modular and Compositional Computation.pdf:application/pdf},
}

@article{scheeringa_relating_2020,
	title = {Relating neural oscillations to laminar {fMRI} connectivity},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.09.18.303263v1},
	doi = {10.1101/2020.09.18.303263},
	abstract = {{\textless}p{\textgreater}Laminar fMRI can non-invasively study brain activation and potentially connectivity at the laminar level in humans. In a previous simultaneous laminar fMRI/EEG experiment, we observed that attention effects in alpha, beta and gamma band EEG power relate to attention effects in fMRI activation in V1/V2/V3 at distinct cortical depths: alpha and gamma band EEG attention effects related to fMRI effects in superficial layers, whereas beta attention effects related to deep layers. Here we reanalyzed these data to investigate how EEG-attention effects relate to changes in connectivity between regions. We computed the fMRI-based attention effect on laminar connectivity between regions within a hemisphere and connectivity between layers within brain regions. We observed that the beta band strongly relates to laminar specific changes in connectivity. Our results indicate that the attention-related decrease in beta power relates to an increase in deep-to-deep layer connectivity between regions and deep/middle to superficial layer connectivity within brain regions. The attention related alpha power increase predominantly relates to increases in connectivity between deep and superficial layers within brain regions. We observed no strong relation between laminar connectivity and gamma band oscillations. These results indicate that especially beta band oscillations, and to a lesser extent alpha band oscillations relate to laminar specific changes in connectivity as measured by laminar fMRI. Together, the effects for the alpha and beta bands suggest a complex picture of possibly co-occurring neural processes that can differentially affect laminar connectivity.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-09-22},
	journal = {bioRxiv},
	author = {Scheeringa, René and Bonnefond, Mathilde and Mourik, Tim van and Jensen, Ole and Norris, David G. and Koopmans, Peter J.},
	month = sep,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.09.18.303263},
	file = {Scheeringa et al_2020_Relating neural oscillations to laminar fMRI connectivity.pdf:/Users/tito/Zotero/storage/NJDMC6NT/Scheeringa et al_2020_Relating neural oscillations to laminar fMRI connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/XHT7ZH3E/2020.09.18.html:text/html},
}

@article{zhuang_comprehensive_2020,
	title = {A {Comprehensive} {Survey} on {Transfer} {Learning}},
	issn = {1558-2256},
	doi = {10.1109/JPROC.2020.3004555},
	abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target-domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning research studies, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey article reviews more than 40 representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over 20 representative transfer learning models are used for experiments. The models are performed on three different data sets, that is, Amazon Reviews, Reuters-21578, and Office-31, and the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
	journal = {Proceedings of the IEEE},
	author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
	year = {2020},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Machine learning, machine learning, Adaptation models, Covariance matrices, Data models, Domain adaptation, interpretation, Kernel, Semisupervised learning, Task analysis, transfer learning.},
	pages = {1--34},
	file = {IEEE Xplore Abstract Record:/Users/tito/Zotero/storage/CDSXW276/9134370.html:text/html;Zhuang et al_2020_A Comprehensive Survey on Transfer Learning.pdf:/Users/tito/Zotero/storage/VMCIWUQ5/Zhuang et al_2020_A Comprehensive Survey on Transfer Learning.pdf:application/pdf},
}

@article{bruce_conditions_1933,
	title = {Conditions of transfer of training},
	volume = {16},
	issn = {0022-1015(Print)},
	doi = {10.1037/h0074550},
	abstract = {An investigation of some of the conditions of transfer of training. The results of the study are formulated in a set of laws which have predictive value, since they state some of the main objective conditions under which positive and negative transfer may be expected to occur. The laws concerning the conditions of transfer of training are as follows: (1) Learning to make an old response to a new stimulus results in a marked degree of positive transfer. (2) Learning to make a new response to a new stimulus results in a slight degree of positive transfer. (3) Learning to make a new response to an old stimulus results in a slight degree of negative transfer. (4) Introducing similarities between two or more of the S1R1S2R2 terms increases positive transfer, and decreases negative transfer. (5) With increasing degrees of integration of the initial learning, there is an increase in the amount of positive transfer, and a decrease in the amount of negative transfer; where the amount of negative transfer is slight, it shifts to positive transfer. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Journal of Experimental Psychology},
	author = {Bruce, R. W.},
	year = {1933},
	note = {Place: US
Publisher: Psychological Review Company},
	keywords = {Learning, Negative Transfer, Positive Transfer, Training},
	pages = {343--361},
	file = {Snapshot:/Users/tito/Zotero/storage/7PHGQFHS/1933-03736-001.html:text/html},
}

@article{gonthier_dissociating_2016,
	title = {Dissociating proactive and reactive control in the {Stroop} task},
	volume = {44},
	issn = {1532-5946},
	url = {https://doi.org/10.3758/s13421-016-0591-1},
	doi = {10.3758/s13421-016-0591-1},
	abstract = {The Dual Mechanisms of Control framework posits the existence of two distinct control mechanisms, proactive and reactive, which may operate independently. However, this independence has been difficult to study with most experimental paradigms. The Stroop task may provide a useful way of assessing the independence of control mechanisms because the task elicits two types of proportion congruency effects, list-wide and item-specific, thought to reflect proactive and reactive control respectively. The present research tested whether these two proportion congruency effects can be used to dissociate proactive and reactive control. In 2 separate participant samples, we demonstrate that list-wide and item-specific proportion congruency effects are stable, exist in the same participants, and appear in different task conditions. Moreover, we identify two distinct behavioral signatures, the congruency cost and the transfer cost, which doubly dissociate the two effects. Together, the results are consistent with the view that proactive and reactive control reflect independent mechanisms.},
	language = {en},
	number = {5},
	urldate = {2020-09-23},
	journal = {Mem Cogn},
	author = {Gonthier, Corentin and Braver, Todd S. and Bugg, Julie M.},
	month = jul,
	year = {2016},
	pages = {778--788},
	file = {Gonthier et al_2016_Dissociating proactive and reactive control in the Stroop task.pdf:/Users/tito/Zotero/storage/MD5M3D7R/Gonthier et al_2016_Dissociating proactive and reactive control in the Stroop task.pdf:application/pdf},
}

@article{golesorkhi_temporal_2020,
	title = {Temporal hierarchy converges with spatial hierarchy: {Intrinsic} neural timescales follow core-periphery organization},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	shorttitle = {Temporal hierarchy converges with spatial hierarchy},
	url = {https://www.biorxiv.org/content/10.1101/2020.06.12.148866v1},
	doi = {10.1101/2020.06.12.148866},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}The human cortex exhibits a temporal hierarchy during task states as evidenced by intrinsic neural timescale. How the task-based intrinsic neural timescale is shaped by resting state’s spatial topography especially the recently established core-periphery hierarchy (with the default-mode network (DMN) at the core and sensory networks at the periphery) remains an open issue. Using MEG data from the Human Connectome Project (HCP), we investigated the intrinsic neural timescales by measuring the autocorrelation window in short (ACW-50) and, introducing a novel variant, long (ACW-0) windows in various networks following core-periphery hierarchy. We demonstrate longer ACW-50 and ACW-0 in networks located at the core, i.e., DMN, frontoparietal network, and cingulum-operculum network, during both rest and task states. While networks at the periphery, i.e., auditory, visual, and somatomotor networks, exhibit shorter ACW-50 and ACW-0. Comparing both ACW scales during rest and task, i.e., rest-task difference revealed task- and network-specific effects. That is complemented by strong correlation of both ACW scales in rest with their counterpart during task states, following again the core-periphery hierarchy. Finally, we demonstrate that the longer window (ACW-0) exhibits better prediction in classifying a region’s time window as belonging to either core or periphery. Overall, our findings provide fundamental insight into how the human cortex’s temporal hierarchy of intrinsic neural timescales converges with spatial topography, the core-periphery hierarchy.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-09-28},
	journal = {bioRxiv},
	author = {Golesorkhi, Mehrshad and Gomez-Pilar, Javier and Tumati, Shankar and Fraser, Maia and Northoff, Georg},
	month = jun,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.06.12.148866},
	file = {Full Text PDF:/Users/tito/Zotero/storage/SWDJLJNM/Golesorkhi et al. - 2020 - Temporal hierarchy converges with spatial hierarch.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DZJLLZJI/2020.06.12.html:text/html},
}

@article{hupkes_compositionality_2020,
	title = {Compositionality {Decomposed}: {How} do {Neural} {Networks} {Generalise}?},
	volume = {67},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	shorttitle = {Compositionality {Decomposed}},
	url = {https://www.jair.org/index.php/jair/article/view/11674},
	doi = {10.1613/jair.1.11674},
	language = {en},
	urldate = {2020-09-30},
	journal = {Journal of Artificial Intelligence Research},
	author = {Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
	month = apr,
	year = {2020},
	keywords = {machine learning, neural networks, natural language, rule learning},
	pages = {757--795},
	file = {Full Text PDF:/Users/tito/Zotero/storage/KA44QJJS/Hupkes et al. - 2020 - Compositionality Decomposed How do Neural Network.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SRJ7FAES/11674.html:text/html},
}

@article{dworetsky_probabilistic_2020,
	title = {Probabilistic mapping of human functional brain networks identifies regions of high group consensus},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.09.28.313791v1},
	doi = {10.1101/2020.09.28.313791},
	abstract = {{\textless}p{\textgreater}Many recent developments surrounding the functional network organization of the human brain have focused on data that have been averaged across groups of individuals. While such group-level approaches have shed considerable light on the brain9s large-scale distributed systems, they conceal individual differences in network organization, which recent work has demonstrated to be common and widespread. Here our goal was to leverage information about individual-level brain organization to identify locations of high inter-subject consensus. We probabilistically mapped 14 functional networks in multiple datasets with relatively high amounts of data. All networks show "core" (high-probability) regions, but differ from one another in the extent of their higher-variability components. These patterns replicate well across datasets with different scanning parameters. We produced a set of high-probability regions of interest (ROIs) from these probabilistic maps; these and the probabilistic maps are made publicly available, allowing researchers to apply information about group consistency to their own work in rest- or task-based studies.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-09-30},
	journal = {bioRxiv},
	author = {Dworetsky, Ally and Seitzman, Benjamin A. and Adeyemo, Babatunde and Neta, Maital and Coalson, Rebecca S. and Petersen, Steven E. and Gratton, Caterina},
	month = sep,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.09.28.313791},
	file = {Full Text PDF:/Users/tito/Zotero/storage/LY7KFCUC/Dworetsky et al. - 2020 - Probabilistic mapping of human functional brain ne.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Z9HXPKNM/2020.09.28.html:text/html},
}

@article{mclaren_generalized_2012,
	title = {A generalized form of context-dependent psychophysiological interactions ({gPPI}): {A} comparison to standard approaches},
	volume = {61},
	issn = {1053-8119},
	shorttitle = {A generalized form of context-dependent psychophysiological interactions ({gPPI})},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912003497},
	doi = {10.1016/j.neuroimage.2012.03.068},
	abstract = {Functional MRI (fMRI) allows one to study task-related regional responses and task-dependent connectivity analysis using psychophysiological interaction (PPI) methods. The latter affords the additional opportunity to understand how brain regions interact in a task-dependent manner. The current implementation of PPI in Statistical Parametric Mapping (SPM8) is configured primarily to assess connectivity differences between two task conditions, when in practice fMRI tasks frequently employ more than two conditions. Here we evaluate how a generalized form of context-dependent PPI (gPPI; http://www.nitrc.org/projects/gppi), which is configured to automatically accommodate more than two task conditions in the same PPI model by spanning the entire experimental space, compares to the standard implementation in SPM8. These comparisons are made using both simulations and an empirical dataset. In the simulated dataset, we compare the interaction beta estimates to their expected values and model fit using the Akaike information criterion (AIC). We found that interaction beta estimates in gPPI were robust to different simulated data models, were not different from the expected beta value, and had better model fits than when using standard PPI (sPPI) methods. In the empirical dataset, we compare the model fit of the gPPI approach to sPPI. We found that the gPPI approach improved model fit compared to sPPI. There were several regions that became non-significant with gPPI. These regions all showed significantly better model fits with gPPI. Also, there were several regions where task-dependent connectivity was only detected using gPPI methods, also with improved model fit. Regions that were detected with all methods had more similar model fits. These results suggest that gPPI may have greater sensitivity and specificity than standard implementation in SPM. This notion is tempered slightly as there is no gold standard; however, data simulations with a known outcome support our conclusions about gPPI. In sum, the generalized form of context-dependent PPI approach has increased flexibility of statistical modeling, and potentially improves model fit, specificity to true negative findings, and sensitivity to true positive findings.},
	language = {en},
	number = {4},
	urldate = {2020-09-30},
	journal = {NeuroImage},
	author = {McLaren, Donald G. and Ries, Michele L. and Xu, Guofan and Johnson, Sterling C.},
	month = jul,
	year = {2012},
	keywords = {fMRI, Functional connectivity, Effective connectivity, PPI, Psychophysiological interactions, Brain mapping, Context-dependent connectivity},
	pages = {1277--1286},
	file = {Accepted Version:/Users/tito/Zotero/storage/8H9ZJPQL/McLaren et al. - 2012 - A generalized form of context-dependent psychophys.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/KRHUJHBD/authorization.html:text/html},
}

@article{al-aidroos_top-down_2012,
	title = {Top-down attention switches coupling between low-level and high-level areas of human visual cortex},
	volume = {109},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/109/36/14675},
	doi = {10.1073/pnas.1202095109},
	abstract = {Top-down attention is an essential cognitive ability, allowing our finite brains to process complex natural environments by prioritizing information relevant to our goals. Previous evidence suggests that top-down attention operates by modulating stimulus-evoked neural activity within visual areas specialized for processing goal-relevant information. We show that top-down attention also has a separate influence on the background coupling between visual areas: adopting different attentional goals resulted in specific patterns of noise correlations in the visual system, whereby intrinsic activity in the same set of low-level areas was shared with only those high-level areas relevant to the current goal. These changes occurred independently of evoked activity, persisted without visual stimulation, and predicted behavioral success in deploying attention better than the modulation of evoked activity. This attentional switching of background connectivity suggests that attention may help synchronize different levels of the visual processing hierarchy, forming state-dependent functional pathways in human visual cortex to prioritize goal-relevant information.},
	language = {en},
	number = {36},
	urldate = {2020-09-30},
	journal = {PNAS},
	author = {Al-Aidroos, Naseem and Said, Christopher P. and Turk-Browne, Nicholas B.},
	month = sep,
	year = {2012},
	pmid = {22908274},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {functional MRI, category selectivity, goal-directed attention, retinotopic occipital cortex, ventral temporal cortex},
	pages = {14675--14680},
	file = {Full Text PDF:/Users/tito/Zotero/storage/2D8FANIV/Al-Aidroos et al. - 2012 - Top-down attention switches coupling between low-l.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JTMWJF7K/14675.html:text/html},
}

@article{sanzeni_response_2020,
	title = {Response nonlinearities in networks of spiking neurons},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008165},
	doi = {10.1371/journal.pcbi.1008165},
	abstract = {Combining information from multiple sources is a fundamental operation performed by networks of neurons in the brain, whose general principles are still largely unknown. Experimental evidence suggests that combination of inputs in cortex relies on nonlinear summation. Such nonlinearities are thought to be fundamental to perform complex computations. However, these non-linearities are inconsistent with the balanced-state model, one of the most popular models of cortical dynamics, which predicts networks have a linear response. This linearity is obtained in the limit of very large recurrent coupling strength. We investigate the stationary response of networks of spiking neurons as a function of coupling strength. We show that, while a linear transfer function emerges at strong coupling, nonlinearities are prominent at finite coupling, both at response onset and close to saturation. We derive a general framework to classify nonlinear responses in these networks and discuss which of them can be captured by rate models. This framework could help to understand the diversity of non-linearities observed in cortical networks.},
	language = {en},
	number = {9},
	urldate = {2020-10-01},
	journal = {PLOS Computational Biology},
	author = {Sanzeni, Alessandro and Histed, Mark H. and Brunel, Nicolas},
	month = sep,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Network analysis, Neural networks, Simulation and modeling, Single neuron function, Action potentials, Transfer functions, Synapses},
	pages = {e1008165},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WYU2ZMNL/Sanzeni et al. - 2020 - Response nonlinearities in networks of spiking neu.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3LCDAMFE/article.html:text/html},
}

@article{marek_towards_2020,
	title = {Towards {Reproducible} {Brain}-{Wide} {Association} {Studies}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.08.21.257758v1},
	doi = {10.1101/2020.08.21.257758},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Magnetic resonance imaging (MRI) continues to drive many important neuroscientific advances. However, progress in uncovering reproducible associations between individual differences in brain structure/function and behavioral phenotypes (e.g., cognition, mental health) may have been undermined by typical neuroimaging sample sizes (median N=25)$^{\textrm{1,2}}$. Leveraging the Adolescent Brain Cognitive Development (ABCD) Study$^{\textrm{3}}$ (N=11,878), we estimated the effect sizes and reproducibility of these brain-wide associations studies (BWAS) as a function of sample size. The very largest, replicable brain-wide associations for univariate and multivariate methods were r=0.14 and r=0.34, respectively. In smaller samples, typical for brain-wide association studies (BWAS), irreproducible, inflated effect sizes were ubiquitous, no matter the method (univariate, multivariate). Until sample sizes started to approach consortium-levels, BWAS were underpowered and statistical errors assured. Multiple factors contribute to replication failures$^{\textrm{4–6}}$; here, we show that the pairing of small brain-behavioral phenotype effect sizes with sampling variability is a key element in wide-spread BWAS replication failure. Brain-behavioral phenotype associations stabilize and become more reproducible with sample sizes of N⪆2,000. While investigator-initiated brain-behavior research continues to generate hypotheses and propel innovation, large consortia are needed to usher in a new era of reproducible human brain-wide association studies.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-10-02},
	journal = {bioRxiv},
	author = {Marek, Scott and Tervo-Clemmens, Brenden and Calabro, Finnegan J. and Montez, David F. and Kay, Benjamin P. and Hatoum, Alexander S. and Donohue, Meghan Rose and Foran, William and Miller, Ryland L. and Feczko, Eric and Miranda-Dominguez, Oscar and Graham, Alice M. and Earl, Eric A. and Perrone, Anders J. and Cordova, Michaela and Doyle, Olivia and Moore, Lucille A. and Conan, Greg and Uriarte, Johnny and Snider, Kathy and Tam, Angela and Chen, Jianzhong and Newbold, Dillan J. and Zheng, Annie and Seider, Nicole A. and Van, Andrew N. and Laumann, Timothy O. and Thompson, Wesley K. and Greene, Deanna J. and Petersen, Steven E. and Nichols, Thomas E. and Yeo, B. T. Thomas and Barch, Deanna M. and Garavan, Hugh and Luna, Beatriz and Fair, Damien A. and Dosenbach, Nico U. F.},
	month = aug,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.08.21.257758},
	file = {Full Text PDF:/Users/tito/Zotero/storage/PQVSANXE/Marek et al. - 2020 - Towards Reproducible Brain-Wide Association Studie.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/RGXA6K8N/2020.08.21.html:text/html},
}

@book{von_neumann_computer_2012,
	title = {The computer and the brain},
	publisher = {Yale University Press},
	author = {Von Neumann, John and Kurzweil, Ray},
	year = {2012},
	file = {Full Text:/Users/tito/Zotero/storage/MDUC5CMP/Von Neumann and Kurzweil - 2012 - The computer and the brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VXRTEBZ2/books.html:text/html},
}

@inproceedings{searle_is_1990,
	title = {Is the brain a digital computer?},
	volume = {64},
	booktitle = {Proceedings and addresses of the {American} {Philosophical} {Association}},
	publisher = {JSTOR},
	author = {Searle, John R.},
	year = {1990},
	note = {Issue: 3},
	pages = {21--37},
	file = {Full Text:/Users/tito/Zotero/storage/2QX8YMTC/Searle - 1990 - Is the brain a digital computer.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MGAFLRTA/3130074.html:text/html},
}

@book{turing_intelligent_1948,
	title = {Intelligent machinery},
	publisher = {NPL. Mathematics Division},
	author = {Turing, Alan Mathison},
	year = {1948},
	file = {Full Text:/Users/tito/Zotero/storage/WEPJRFS3/Turing - 1948 - Intelligent machinery.pdf:application/pdf},
}

@article{fodor_connectionism_1988,
	title = {Connectionism and cognitive architecture: {A} critical analysis},
	volume = {28},
	shorttitle = {Connectionism and cognitive architecture},
	number = {1-2},
	journal = {Cognition},
	author = {Fodor, Jerry A. and Pylyshyn, Zenon W.},
	year = {1988},
	pages = {3--71},
	file = {Full Text:/Users/tito/Zotero/storage/8Q7V7MH8/Fodor and Pylyshyn - 1988 - Connectionism and cognitive architecture A critic.pdf:application/pdf},
}

@article{chalmers_connectionism_1993,
	title = {Connectionism and compositionality: {Why} {Fodor} and {Pylyshyn} were wrong},
	shorttitle = {Connectionism and compositionality},
	author = {Chalmers, David J.},
	year = {1993},
	note = {Publisher: Taylor \& Francis},
	file = {Full Text:/Users/tito/Zotero/storage/BN8ZJN8G/Chalmers - 1993 - Connectionism and compositionality Why Fodor and .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BA8LUW6I/09515089308573094.html:text/html},
}

@article{friston_beyond_2002,
	title = {Beyond {Phrenology}: {What} {Can} {Neuroimaging} {Tell} {Us} {About} {Distributed} {Circuitry}?},
	volume = {25},
	shorttitle = {Beyond {Phrenology}},
	url = {https://doi.org/10.1146/annurev.neuro.25.112701.142846},
	doi = {10.1146/annurev.neuro.25.112701.142846},
	abstract = {Unsupervised models of how the brain identifies and categorizes the causes of its sensory input can be divided into two classes: those that minimize the mutual information (i.e., redundancy) among evoked responses and those that minimize the prediction error. Although these models have the same goal, the way that goal is attained, and the functional architectures required, are fundamentally different. This review describes the differences, in the functional anatomy of sensory cortical hierarchies, implied by the two models. We then consider how neuroimaging can be used to disambiguate between them. The key distinction reduces to whether backward connections are employed by the brain to generate a prediction of sensory inputs. To ascertain whether backward influences are evident empirically requires a characterization of functional integration among brain systems. This review summarizes the approaches to measuring functional integration in terms of effective connectivity and proceeds to address the question posed by the theoretical considerations. In short, it will be shown that the conjoint manipulation of bottom-up and top-down inputs to an area can be used to test for interactions between them, in elaborating cortical responses. The conclusion, from these sorts of neuroimaging studies, points to the prevalence of top-down influences and the plausibility of generative models of sensory brain function.},
	number = {1},
	urldate = {2020-10-06},
	journal = {Annual Review of Neuroscience},
	author = {Friston, Karl},
	year = {2002},
	pmid = {12052909},
	note = {\_eprint: https://doi.org/10.1146/annurev.neuro.25.112701.142846},
	pages = {221--250},
	file = {Full Text PDF:/Users/tito/Zotero/storage/4WCAFSMM/Friston - 2002 - Beyond Phrenology What Can Neuroimaging Tell Us A.pdf:application/pdf},
}

@article{zola-morgan_localization_1995,
	title = {Localization of {Brain} {Function}: {The} {Legacy} of {Franz} {Joseph} {Gall} (1758-1828)},
	volume = {18},
	shorttitle = {Localization of {Brain} {Function}},
	url = {https://doi.org/10.1146/annurev.ne.18.030195.002043},
	doi = {10.1146/annurev.ne.18.030195.002043},
	number = {1},
	urldate = {2020-10-06},
	journal = {Annual Review of Neuroscience},
	author = {Zola-Morgan, S},
	year = {1995},
	pmid = {7605066},
	note = {\_eprint: https://doi.org/10.1146/annurev.ne.18.030195.002043},
	pages = {359--383},
	file = {Full Text PDF:/Users/tito/Zotero/storage/WSDSR3Y4/Zola-Morgan - 1995 - Localization of Brain Function The Legacy of Fran.pdf:application/pdf},
}

@article{henson_what_2005,
	title = {What can functional neuroimaging tell the experimental psychologist?},
	volume = {58},
	number = {2},
	journal = {The Quarterly Journal of Experimental Psychology Section A},
	author = {Henson, Richard},
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	pages = {193--233},
	file = {Full Text:/Users/tito/Zotero/storage/RJZRDPQY/Henson - 2005 - What can functional neuroimaging tell the experime.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3RJSV9RZ/02724980443000502.html:text/html},
}

@article{klinger_study_2020,
	title = {A {Study} of {Compositional} {Generalization} in {Neural} {Models}},
	url = {http://arxiv.org/abs/2006.09437},
	abstract = {Compositional and relational learning is a hallmark of human intelligence, but one which presents challenges for neural models. One difficulty in the development of such models is the lack of benchmarks with clear compositional and relational task structure on which to systematically evaluate them. In this paper, we introduce an environment called ConceptWorld, which enables the generation of images from compositional and relational concepts, defined using a logical domain specific language. We use it to generate images for a variety of compositional structures: 2x2 squares, pentominoes, sequences, scenes involving these objects, and other more complex concepts. We perform experiments to test the ability of standard neural architectures to generalize on relations with compositional arguments as the compositional depth of those arguments increases and under substitution. We compare standard neural networks such as MLP, CNN and ResNet, as well as state-of-the-art relational networks including WReN and PrediNet in a multi-class image classification setting. For simple problems, all models generalize well to close concepts but struggle with longer compositional chains. For more complex tests involving substitutivity, all models struggle, even with short chains. In highlighting these difficulties and providing an environment for further experimentation, we hope to encourage the development of models which are able to generalize effectively in compositional, relational domains.},
	urldate = {2020-10-07},
	journal = {arXiv:2006.09437 [cs, stat]},
	author = {Klinger, Tim and Adjodah, Dhaval and Marois, Vincent and Joseph, Josh and Riemer, Matthew and Pentland, Alex 'Sandy' and Campbell, Murray},
	month = jul,
	year = {2020},
	note = {arXiv: 2006.09437},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 28 pages},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/QYCQI7K7/2006.html:text/html;Klinger et al_2020_A Study of Compositional Generalization in Neural Models.pdf:/Users/tito/Zotero/storage/S7JXDUPL/Klinger et al_2020_A Study of Compositional Generalization in Neural Models.pdf:application/pdf},
}

@inproceedings{lake_generalization_2018,
	title = {Generalization without {Systematicity}: {On} the {Compositional} {Skills} of {Sequence}-to-{Sequence} {Recurrent} {Networks}},
	shorttitle = {Generalization without {Systematicity}},
	url = {http://proceedings.mlr.press/v80/lake18a.html},
	abstract = {Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb},
	language = {en},
	urldate = {2020-10-08},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Lake, Brenden and Baroni, Marco},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {2873--2882},
	file = {Lake_Baroni_2018_Generalization without Systematicity.pdf:/Users/tito/Zotero/storage/3MV7T5S3/Lake_Baroni_2018_Generalization without Systematicity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GZLK58RZ/lake18a.html:text/html},
}

@article{barrett_measuring_nodate,
	title = {Measuring abstract reasoning in neural networks},
	abstract = {Whether neural networks can learn abstract reasoning or whether they merely rely on superﬁcial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation ‘regimes’ in which the training and test data differ in clearlydeﬁned ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with a structure designed to encourage reasoning, that does signiﬁcantly better. When we vary the way in which the test questions and training data differ, we ﬁnd that our model is notably proﬁcient at certain forms of generalisation, but notably weak at others. We further show that the model’s ability to generalise improves markedly if it is trained to predict symbolic explanations for its answers. Altogether, we introduce and explore ways to both measure and induce stronger abstract reasoning in neural networks. Our freely-available dataset should motivate further progress in this direction.},
	language = {en},
	author = {Barrett, David G T and Hill, Felix and Santoro, Adam and Morcos, Ari S and Lillicrap, Timothy},
	pages = {10},
	file = {Barrett et al. - Measuring abstract reasoning in neural networks.pdf:/Users/tito/Zotero/storage/5GLHI4P3/Barrett et al. - Measuring abstract reasoning in neural networks.pdf:application/pdf},
}

@article{shanahan_artificial_2020,
	title = {Artificial {Intelligence} and the {Common} {Sense} of {Animals}},
	volume = {0},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(20)30216-3},
	doi = {10.1016/j.tics.2020.09.002},
	language = {English},
	number = {0},
	urldate = {2020-10-09},
	journal = {Trends in Cognitive Sciences},
	author = {Shanahan, Murray and Crosby, Matthew and Beyret, Benjamin and Cheke, Lucy},
	month = oct,
	year = {2020},
	note = {Publisher: Elsevier},
	file = {Shanahan et al_2020_Artificial Intelligence and the Common Sense of Animals.pdf:/Users/tito/Zotero/storage/2DXV42LV/Shanahan et al_2020_Artificial Intelligence and the Common Sense of Animals.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6S2LTBEJ/S1364-6613(20)30216-3.html:text/html},
}

@article{rosenbaum_routing_2017,
	title = {Routing {Networks}: {Adaptive} {Selection} of {Non}-linear {Functions} for {Multi}-{Task} {Learning}},
	shorttitle = {Routing {Networks}},
	url = {http://arxiv.org/abs/1711.01239},
	abstract = {Multi-task learning (MTL) with neural networks leverages commonalities in tasks to improve performance, but often suffers from task interference which reduces the benefits of transfer. To address this issue we introduce the routing network paradigm, a novel neural network and training algorithm. A routing network is a kind of self-organizing neural network consisting of two components: a router and a set of one or more function blocks. A function block may be any neural network - for example a fully-connected or a convolutional layer. Given an input the router makes a routing decision, choosing a function block to apply and passing the output back to the router recursively, terminating when a fixed recursion depth is reached. In this way the routing network dynamically composes different function blocks for each input. We employ a collaborative multi-agent reinforcement learning (MARL) approach to jointly train the router and function blocks. We evaluate our model against cross-stitch networks and shared-layer baselines on multi-task settings of the MNIST, mini-imagenet, and CIFAR-100 datasets. Our experiments demonstrate a significant improvement in accuracy, with sharper convergence. In addition, routing networks have nearly constant per-task training cost while cross-stitch networks scale linearly with the number of tasks. On CIFAR-100 (20 tasks) we obtain cross-stitch performance levels with an 85\% reduction in training time.},
	urldate = {2020-10-09},
	journal = {arXiv:1711.01239 [cs]},
	author = {Rosenbaum, Clemens and Klinger, Tim and Riemer, Matthew},
	month = dec,
	year = {2017},
	note = {arXiv: 1711.01239},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Under Review at ICLR 2018},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/BSPDWKM3/1711.html:text/html;Rosenbaum et al_2017_Routing Networks.pdf:/Users/tito/Zotero/storage/MW6BFHXB/Rosenbaum et al_2017_Routing Networks.pdf:application/pdf},
}

@inproceedings{yang_dataset_2018-1,
	title = {A {Dataset} and {Architecture} for {Visual} {Reasoning} with a {Working} {Memory}},
	url = {https://openaccess.thecvf.com/content_ECCV_2018/html/Guangyu_Robert_Yang_A_dataset_and_ECCV_2018_paper.html},
	urldate = {2020-10-09},
	author = {Yang, Guangyu Robert and Ganichev, Igor and Wang, Xiao-Jing and Shlens, Jonathon and Sussillo, David},
	year = {2018},
	pages = {714--731},
	file = {Snapshot:/Users/tito/Zotero/storage/MHSMLNFS/Guangyu_Robert_Yang_A_dataset_and_ECCV_2018_paper.html:text/html;Yang et al_2018_A Dataset and Architecture for Visual Reasoning with a Working Memory.pdf:/Users/tito/Zotero/storage/DYIIVN84/Yang et al_2018_A Dataset and Architecture for Visual Reasoning with a Working Memory.pdf:application/pdf},
}

@inproceedings{misra_cross-stitch_2016,
	title = {Cross-{Stitch} {Networks} for {Multi}-{Task} {Learning}},
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Misra_Cross-Stitch_Networks_for_CVPR_2016_paper.html},
	urldate = {2020-10-12},
	author = {Misra, Ishan and Shrivastava, Abhinav and Gupta, Abhinav and Hebert, Martial},
	year = {2016},
	pages = {3994--4003},
	file = {Misra et al_2016_Cross-Stitch Networks for Multi-Task Learning.pdf:/Users/tito/Zotero/storage/JAYMICAY/Misra et al_2016_Cross-Stitch Networks for Multi-Task Learning.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3UQWV83T/Misra_Cross-Stitch_Networks_for_CVPR_2016_paper.html:text/html},
}

@article{lake_compositional_2019,
	title = {Compositional generalization through meta sequence-to-sequence learning},
	url = {http://arxiv.org/abs/1906.05381},
	abstract = {People can learn a new concept and use it compositionally, understanding how to "blicket twice" after learning how to "blicket." In contrast, powerful sequence-to-sequence (seq2seq) neural networks fail such tests of compositionality, especially when composing new concepts together with existing concepts. In this paper, I show how memory-augmented neural networks can be trained to generalize compositionally through meta seq2seq learning. In this approach, models train on a series of seq2seq problems to acquire the compositional skills needed to solve new seq2seq problems. Meta se2seq learning solves several of the SCAN tests for compositional learning and can learn to apply implicit rules to variables.},
	urldate = {2020-10-13},
	journal = {arXiv:1906.05381 [cs]},
	author = {Lake, Brenden M.},
	month = oct,
	year = {2019},
	note = {arXiv: 1906.05381},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: This paper appears in the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/KJNIEKQJ/1906.html:text/html;Lake_2019_Compositional generalization through meta sequence-to-sequence learning.pdf:/Users/tito/Zotero/storage/449QN7VW/Lake_2019_Compositional generalization through meta sequence-to-sequence learning.pdf:application/pdf},
}

@article{bernardi_geometry_2020,
	title = {The {Geometry} of {Abstraction} in the {Hippocampus} and {Prefrontal} {Cortex}},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867420312289},
	doi = {10.1016/j.cell.2020.09.031},
	abstract = {The curse of dimensionality plagues models of reinforcement learning and decision making. The process of abstraction solves this by constructing variables describing features shared by different instances, reducing dimensionality and enabling generalization in novel situations. Here, we characterized neural representations in monkeys performing a task described by different hidden and explicit variables. Abstraction was deﬁned operationally using the generalization performance of neural decoders across task conditions not used for training, which requires a particular geometry of neural representations. Neural ensembles in prefrontal cortex, hippocampus, and simulated neural networks simultaneously represented multiple variables in a geometry reﬂecting abstraction but that still allowed a linear classiﬁer to decode a large number of other variables (high shattering dimensionality). Furthermore, this geometry changed in relation to task events and performance. These ﬁndings elucidate how the brain and artiﬁcial systems represent variables in an abstract format while preserving the advantages conferred by high shattering dimensionality.},
	language = {en},
	urldate = {2020-10-14},
	journal = {Cell},
	author = {Bernardi, Silvia and Benna, Marcus K. and Rigotti, Mattia and Munuera, Jérôme and Fusi, Stefano and Salzman, C. Daniel},
	month = oct,
	year = {2020},
	file = {Bernardi et al. - 2020 - The Geometry of Abstraction in the Hippocampus and.pdf:/Users/tito/Zotero/storage/VGXQKPWV/Bernardi et al. - 2020 - The Geometry of Abstraction in the Hippocampus and.pdf:application/pdf},
}

@article{bargmann_connectome_2013,
	title = {From the connectome to brain function},
	volume = {10},
	issn = {1548-7091, 1548-7105},
	url = {http://www.nature.com/articles/nmeth.2451},
	doi = {10.1038/nmeth.2451},
	language = {en},
	number = {6},
	urldate = {2020-10-18},
	journal = {Nature Methods},
	author = {Bargmann, Cornelia I and Marder, Eve},
	month = jun,
	year = {2013},
	pages = {483--490},
	file = {Bargmann and Marder - 2013 - From the connectome to brain function.pdf:/Users/tito/Zotero/storage/4E6BG9AZ/Bargmann and Marder - 2013 - From the connectome to brain function.pdf:application/pdf},
}

@inproceedings{kim_compound_2019,
	address = {Florence, Italy},
	title = {Compound {Probabilistic} {Context}-{Free} {Grammars} for {Grammar} {Induction}},
	url = {https://www.aclweb.org/anthology/P19-1228},
	doi = {10.18653/v1/P19-1228},
	abstract = {We study a formalization of the grammar induction problem that models sentences as being generated by a compound probabilistic context free grammar. In contrast to traditional formulations which learn a single stochastic grammar, our context-free rule probabilities are modulated by a per-sentence continuous latent variable, which induces marginal dependencies beyond the traditional context-free assumptions. Inference in this context-dependent grammar is performed by collapsed variational inference, in which an amortized variational posterior is placed on the continuous variable, and the latent trees are marginalized with dynamic programming. Experiments on English and Chinese show the effectiveness of our approach compared to recent state-of-the-art methods for grammar induction from words with neural language models.},
	urldate = {2020-10-19},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Kim, Yoon and Dyer, Chris and Rush, Alexander},
	month = jul,
	year = {2019},
	pages = {2369--2385},
	file = {Kim et al_2019_Compound Probabilistic Context-Free Grammars for Grammar Induction.pdf:/Users/tito/Zotero/storage/NLYC8HWB/Kim et al_2019_Compound Probabilistic Context-Free Grammars for Grammar Induction.pdf:application/pdf},
}

@article{faskowitz_edge-centric_2020,
	title = {Edge-centric functional network representations of human cerebral cortex reveal overlapping system-level architecture},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-020-00719-y},
	doi = {10.1038/s41593-020-00719-y},
	abstract = {Network neuroscience has relied on a node-centric network model in which cells, populations and regions are linked to one another via anatomical or functional connections. This model cannot account for interactions of edges with one another. In this study, we developed an edge-centric network model that generates constructs ‘edge time series’ and ‘edge functional connectivity’ (eFC). Using network analysis, we show that, at rest, eFC is consistent across datasets and reproducible within the same individual over multiple scan sessions. We demonstrate that clustering eFC yields communities of edges that naturally divide the brain into overlapping clusters, with regions in sensorimotor and attentional networks exhibiting the greatest levels of overlap. We show that eFC is systematically modulated by variation in sensory input. In future work, the edge-centric approach could be useful for identifying novel biomarkers of disease, characterizing individual variation and mapping the architecture of highly resolved neural circuits.},
	language = {en},
	urldate = {2020-10-19},
	journal = {Nature Neuroscience},
	author = {Faskowitz, Joshua and Esfahlani, Farnaz Zamani and Jo, Youngheun and Sporns, Olaf and Betzel, Richard F.},
	month = oct,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--11},
	file = {Faskowitz et al_2020_Edge-centric functional network representations of human cerebral cortex reveal.pdf:/Users/tito/Zotero/storage/X4JNCY5S/Faskowitz et al_2020_Edge-centric functional network representations of human cerebral cortex reveal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JI4RZLXF/s41593-020-00719-y.html:text/html},
}

@article{kotter_global_2000,
	title = {Global relationship between anatomical connectivity and activity propagation in the cerebral cortex},
	volume = {355},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2000.0553},
	doi = {10.1098/rstb.2000.0553},
	abstract = {Anatomical connectivity is a prerequisite for cooperative interactions between cortical areas, but it has yet to be demonstrated that association fibre networks determine the macroscopical flow of activity in the cerebral cortex. T o test this notion, we constructed a large–scale model of cortical areas whose interconnections were based on published anatomical data from tracing studies. Using this model we simulated the propagation of activity in response to activation of individual cortical areas and compared the resulting topographic activation patterns to electrophysiological observations on the global spread of epileptic activity following intracortical stimulation. Here we show that a neural network with connectivity derived from experimental data reproduces cortical propagation of activity significantly better than networks with different types of neighbourhood–based connectivity or random connections. Our results indicate that association fibres and their relative connection strengths are useful predictors of global topographic activation patterns in the cerebral cortex. This global structure–function relationship may open a door to explicit interpretation of cortical activation data in terms of underlying anatomical connectivity.},
	number = {1393},
	urldate = {2020-10-20},
	journal = {Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
	author = {Kotter, Rolf and Sommer, Friedrich T.},
	month = jan,
	year = {2000},
	note = {Publisher: Royal Society},
	pages = {127--134},
	file = {Snapshot:/Users/tito/Zotero/storage/WS7L35IQ/rstb.2000.html:text/html;Young et al_2000_Global relationship between anatomical connectivity and activity propagation in.pdf:/Users/tito/Zotero/storage/3V8UUMUZ/Young et al_2000_Global relationship between anatomical connectivity and activity propagation in.pdf:application/pdf},
}

@article{honey_predicting_2009,
	title = {Predicting human resting-state functional connectivity from structural connectivity},
	volume = {106},
	copyright = {© 2009 by The National Academy of Sciences of the USA. Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/106/6/2035},
	doi = {10.1073/pnas.0811168106},
	abstract = {In the cerebral cortex, the activity levels of neuronal populations are continuously fluctuating. When neuronal activity, as measured using functional MRI (fMRI), is temporally coherent across 2 populations, those populations are said to be functionally connected. Functional connectivity has previously been shown to correlate with structural (anatomical) connectivity patterns at an aggregate level. In the present study we investigate, with the aid of computational modeling, whether systems-level properties of functional networks—including their spatial statistics and their persistence across time—can be accounted for by properties of the underlying anatomical network. We measured resting state functional connectivity (using fMRI) and structural connectivity (using diffusion spectrum imaging tractography) in the same individuals at high resolution. Structural connectivity then provided the couplings for a model of macroscopic cortical dynamics. In both model and data, we observed (i) that strong functional connections commonly exist between regions with no direct structural connection, rendering the inference of structural connectivity from functional connectivity impractical; (ii) that indirect connections and interregional distance accounted for some of the variance in functional connectivity that was unexplained by direct structural connectivity; and (iii) that resting-state functional connectivity exhibits variability within and across both scanning sessions and model runs. These empirical and modeling results demonstrate that although resting state functional connectivity is variable and is frequently present between regions without direct structural linkage, its strength, persistence, and spatial statistics are nevertheless constrained by the large-scale anatomical structure of the human cerebral cortex.},
	language = {en},
	number = {6},
	urldate = {2020-10-20},
	journal = {PNAS},
	author = {Honey, C. J. and Sporns, O. and Cammoun, L. and Gigandet, X. and Thiran, J. P. and Meuli, R. and Hagmann, P.},
	month = feb,
	year = {2009},
	pmid = {19188601},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {brain networks, computational model, cerebral cortex, diffusion MRI, neuroanatomy},
	pages = {2035--2040},
	file = {Honey et al_2009_Predicting human resting-state functional connectivity from structural.pdf:/Users/tito/Zotero/storage/9ADZQPL7/Honey et al_2009_Predicting human resting-state functional connectivity from structural.pdf:application/pdf},
}

@article{caruana_multitask_1997,
	title = {Multitask {Learning}},
	volume = {28},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1007379606734},
	doi = {10.1023/A:1007379606734},
	abstract = {Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.},
	language = {en},
	number = {1},
	urldate = {2020-10-20},
	journal = {Machine Learning},
	author = {Caruana, Rich},
	month = jul,
	year = {1997},
	pages = {41--75},
	file = {Caruana_1997_Multitask Learning.pdf:/Users/tito/Zotero/storage/SSFQY66Q/Caruana_1997_Multitask Learning.pdf:application/pdf},
}

@article{lowet_distributional_2020,
	title = {Distributional {Reinforcement} {Learning} in the {Brain}},
	issn = {0166-2236},
	url = {http://www.sciencedirect.com/science/article/pii/S0166223620301983},
	doi = {10.1016/j.tins.2020.09.004},
	abstract = {Learning about rewards and punishments is critical for survival. Classical studies have demonstrated an impressive correspondence between the firing of dopamine neurons in the mammalian midbrain and the reward prediction errors of reinforcement learning algorithms, which express the difference between actual reward and predicted mean reward. However, it may be advantageous to learn not only the mean but also the complete distribution of potential rewards. Recent advances in machine learning have revealed a biologically plausible set of algorithms for reconstructing this reward distribution from experience. Here, we review the mathematical foundations of these algorithms as well as initial evidence for their neurobiological implementation. We conclude by highlighting outstanding questions regarding the circuit computation and behavioral readout of these distributional codes.},
	language = {en},
	urldate = {2020-10-21},
	journal = {Trends in Neurosciences},
	author = {Lowet, Adam S. and Zheng, Qiao and Matias, Sara and Drugowitsch, Jan and Uchida, Naoshige},
	month = oct,
	year = {2020},
	keywords = {artificial intelligence, machine learning, dopamine, deep neural networks, population coding, reward},
	file = {Lowet et al_2020_Distributional Reinforcement Learning in the Brain.pdf:/Users/tito/Zotero/storage/EVLEV5LV/Lowet et al_2020_Distributional Reinforcement Learning in the Brain.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/K8CJ5APG/S0166223620301983.html:text/html},
}

@article{momennejad_learning_2020,
	series = {Understanding memory: {Which} level of analysis?},
	title = {Learning {Structures}: {Predictive} {Representations}, {Replay}, and {Generalization}},
	volume = {32},
	issn = {2352-1546},
	shorttitle = {Learning {Structures}},
	url = {http://www.sciencedirect.com/science/article/pii/S2352154620300371},
	doi = {10.1016/j.cobeha.2020.02.017},
	abstract = {Memory and planning rely on learning the structure of relationships among experiences. Compact representations of these structures guide flexible behavior in humans and animals. A century after ‘latent learning’ experiments summarized by Tolman, the larger puzzle of cognitive maps remains elusive: how does the brain learn and generalize relational structures? This review focuses on a reinforcement learning (RL) approach to learning compact representations of the structure of states. We review evidence showing that capturing structures as predictive representations updated via replay offers a neurally plausible account of human behavior and the neural representations of predictive cognitive maps. We highlight multi-scale successor representations, prioritized replay, and policy-dependence. These advances call for new directions in studying the entanglement of learning and memory with prediction and planning.},
	language = {en},
	urldate = {2020-10-21},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Momennejad, Ida},
	month = apr,
	year = {2020},
	pages = {155--166},
	file = {Momennejad_2020_Learning Structures.pdf:/Users/tito/Zotero/storage/3QSH3GZ4/Momennejad_2020_Learning Structures.pdf:application/pdf},
}

@article{burden_numerical_2001,
	title = {Numerical {Analysis} (seven edition)},
	journal = {PWS. Boston},
	author = {Burden, R. L. and Faires, J. D.},
	year = {2001},
}

@article{nye_learning_2020,
	title = {Learning {Compositional} {Rules} via {Neural} {Program} {Synthesis}},
	url = {http://arxiv.org/abs/2003.05562},
	abstract = {Many aspects of human reasoning, including language, require learning rules from very little data. Humans can do this, often learning systematic rules from very few examples, and combining these rules to form compositional rule-based systems. Current neural architectures, on the other hand, often fail to generalize in a compositional manner, especially when evaluated in ways that vary systematically from training. In this work, we present a neuro-symbolic model which learns entire rule systems from a small set of examples. Instead of directly predicting outputs from inputs, we train our model to induce the explicit system of rules governing a set of previously seen examples, drawing upon techniques from the neural program synthesis literature. Our rule-synthesis approach outperforms neural meta-learning techniques in three domains: an artificial instruction-learning domain used to evaluate human learning, the SCAN challenge datasets, and learning rule-based translations of number words into integers for a wide range of human languages.},
	urldate = {2020-10-22},
	journal = {arXiv:2003.05562 [cs]},
	author = {Nye, Maxwell I. and Solar-Lezama, Armando and Tenenbaum, Joshua B. and Lake, Brenden M.},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.05562},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/7X6FCIBQ/2003.html:text/html;Nye et al_2020_Learning Compositional Rules via Neural Program Synthesis.pdf:/Users/tito/Zotero/storage/I5FQ4XMY/Nye et al_2020_Learning Compositional Rules via Neural Program Synthesis.pdf:application/pdf},
}

@article{tang_training-induced_2020,
	title = {Training-induced prefrontal neuronal changes transfer between tasks},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.10.22.351197v1},
	doi = {10.1101/2020.10.22.351197},
	abstract = {{\textless}p{\textgreater}Training to improve working memory is associated with changes in prefrontal activation and confers lasting benefits, some of which generalize to untrained tasks, though the issue remains contentious and the neural substrate underlying such transfer are unknown. To assess how neural activity changes induced by training transfer across tasks, we recorded single units, multi-unit activity (MUA) and local field potentials (LFP) with chronic electrode arrays implanted in the prefrontal cortex of two monkeys, as they were trained to perform cognitive tasks. Mastering different tasks was associated with distinct changes in neural activity, which included redistribution of power across frequency bands in the LFP, recruitment of larger numbers of MUA sites, and increase or decrease of mean neural activity across single units. In every training phase, changes induced by the actively learned task transferred to an untrained control task, which remained the same across the training period. The results explicate the neural basis through which training can transfer across cognitive tasks.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-10-23},
	journal = {bioRxiv},
	author = {Tang, Hua and Riley, Mitchell R. and Singh, Balbir and Qi, Xuelian and Blake, David T. and Constantinidis, Christos},
	month = oct,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.10.22.351197},
	file = {Snapshot:/Users/tito/Zotero/storage/WLLFUK7N/2020.10.22.html:text/html;Snapshot:/Users/tito/Zotero/storage/Q37DQ4SC/2020.10.22.html:text/html;Tang et al_2020_Training-induced prefrontal neuronal changes transfer between tasks.pdf:/Users/tito/Zotero/storage/JPSAJ6TP/Tang et al_2020_Training-induced prefrontal neuronal changes transfer between tasks.pdf:application/pdf},
}

@article{tenenbaum_theory-based_2006,
	series = {Special issue: {Probabilistic} models of cognition},
	title = {Theory-based {Bayesian} models of inductive learning and reasoning},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661306001343},
	doi = {10.1016/j.tics.2006.05.009},
	abstract = {Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.},
	language = {en},
	number = {7},
	urldate = {2020-10-23},
	journal = {Trends in Cognitive Sciences},
	author = {Tenenbaum, Joshua B. and Griffiths, Thomas L. and Kemp, Charles},
	month = jul,
	year = {2006},
	pages = {309--318},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/FYH9JMPZ/S1364661306001343.html:text/html;Tenenbaum et al_2006_Theory-based Bayesian models of inductive learning and reasoning.pdf:/Users/tito/Zotero/storage/V2EM5WZN/Tenenbaum et al_2006_Theory-based Bayesian models of inductive learning and reasoning.pdf:application/pdf},
}

@article{buxton_dynamics_1998,
	title = {Dynamics of blood flow and oxygenation changes during brain activation: the balloon model},
	volume = {39},
	shorttitle = {Dynamics of blood flow and oxygenation changes during brain activation},
	number = {6},
	journal = {Magnetic resonance in medicine},
	author = {Buxton, Richard B. and Wong, Eric C. and Frank, Lawrence R.},
	year = {1998},
	note = {Publisher: Wiley Online Library},
	pages = {855--864},
	file = {Snapshot:/Users/tito/Zotero/storage/8W5ZUDLM/mrm.html:text/html},
}

@article{diedrichsen_comparing_2020,
	title = {Comparing representational geometries using the unbiased distance correlation},
	url = {http://arxiv.org/abs/2007.02789},
	abstract = {Representational similarity analysis (RSA) tests models of brain computation by investigating how neural activity patterns change in response to different experimental conditions. Instead of predicting activity patterns directly, the models predict the geometry of the representation, i.e. to what extent experimental conditions are associated with similar or dissimilar activity patterns. RSA therefore first quantifies the representational geometry by calculating a dissimilarity measure for all pairs of conditions, and then compares the estimated representational dissimilarities to those predicted by the model. Here we address two central challenges of RSA: First, dissimilarity measures such as the Euclidean, Mahalanobis, and correlation distance, are biased by measurement noise, which can lead to incorrect inferences. Unbiased dissimilarity estimates can be obtained by crossvalidation, at the price of increased variance. Second, the pairwise dissimilarity estimates are not statistically independent. Ignoring the dependency makes model comparison with RSA statistically suboptimal. We present an analytical expression for the mean and (co-)variance of both biased and unbiased estimators of Euclidean and Mahalanobis distance, allowing us to exactly quantify the bias-variance trade-off. We then use the analytical expression of the co-variance of the dissimilarity estimates to derive a simple method correcting for this covariance. Combining unbiased distance estimates with this correction leads to a novel criterion for comparing representational geometries, the unbiased distance correlation, which, as we show, allows for near optimal model comparison.},
	urldate = {2020-10-26},
	journal = {arXiv:2007.02789 [stat]},
	author = {Diedrichsen, Jörn and Berlot, Eva and Mur, Marieke and Schütt, Heiko H. and Kriegeskorte, Nikolaus},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.02789},
	keywords = {Statistics - Applications},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/V5GQ5QBR/2007.html:text/html;Diedrichsen et al_2020_Comparing representational geometries using the unbiased distance correlation.pdf:/Users/tito/Zotero/storage/P9RHM9VQ/Diedrichsen et al_2020_Comparing representational geometries using the unbiased distance correlation.pdf:application/pdf},
}

@article{esfahlani_high-amplitude_2020,
	title = {High-amplitude cofluctuations in cortical activity drive functional connectivity},
	copyright = {Copyright © 2020 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2020/10/21/2005531117},
	doi = {10.1073/pnas.2005531117},
	abstract = {Resting-state functional connectivity is used throughout neuroscience to study brain organization and to generate biomarkers of development, disease, and cognition. The processes that give rise to correlated activity are, however, poorly understood. Here we decompose resting-state functional connectivity using a temporal unwrapping procedure to assess the contributions of moment-to-moment activity cofluctuations to the overall connectivity pattern. This approach temporally resolves functional connectivity at a timescale of single frames, which enables us to make direct comparisons of cofluctuations of network organization with fluctuations in the blood oxygen level-dependent (BOLD) time series. We show that surprisingly, only a small fraction of frames exhibiting the strongest cofluctuation amplitude are required to explain a significant fraction of variance in the overall pattern of connection weights as well as the network’s modular structure. These frames coincide with frames of high BOLD activity amplitude, corresponding to activity patterns that are remarkably consistent across individuals and identify fluctuations in default mode and control network activity as the primary driver of resting-state functional connectivity. Finally, we demonstrate that cofluctuation amplitude synchronizes across subjects during movie watching and that high-amplitude frames carry detailed information about individual subjects (whereas low-amplitude frames carry little). Our approach reveals fine-scale temporal structure of resting-state functional connectivity and discloses that frame-wise contributions vary across time. These observations illuminate the relation of brain activity to functional connectivity and open a number of directions for future research.},
	language = {en},
	urldate = {2020-10-26},
	journal = {PNAS},
	author = {Esfahlani, Farnaz Zamani and Jo, Youngheun and Faskowitz, Joshua and Byrge, Lisa and Kennedy, Daniel P. and Sporns, Olaf and Betzel, Richard F.},
	month = oct,
	year = {2020},
	pmid = {33093200},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {functional connectivity, dynamics, naturalistic stimuli, time-varying connectivity},
	file = {Esfahlani et al_2020_High-amplitude cofluctuations in cortical activity drive functional connectivity.pdf:/Users/tito/Zotero/storage/CCIZX5DB/Esfahlani et al_2020_High-amplitude cofluctuations in cortical activity drive functional connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/39T7KKLI/2005531117.html:text/html},
}

@article{mattsson_examining_2020,
	title = {Examining the causal structures of deep neural networks using information theory},
	url = {http://arxiv.org/abs/2010.13871},
	abstract = {Deep Neural Networks (DNNs) are often examined at the level of their response to input, such as analyzing the mutual information between nodes and data sets. Yet DNNs can also be examined at the level of causation, exploring "what does what" within the layers of the network itself. Historically, analyzing the causal structure of DNNs has received less attention than understanding their responses to input. Yet definitionally, generalizability must be a function of a DNN's causal structure since it reflects how the DNN responds to unseen or even not-yet-defined future inputs. Here, we introduce a suite of metrics based on information theory to quantify and track changes in the causal structure of DNNs during training. Specifically, we introduce the effective information (EI) of a feedforward DNN, which is the mutual information between layer input and output following a maximum-entropy perturbation. The EI can be used to assess the degree of causal influence nodes and edges have over their downstream targets in each layer. We show that the EI can be further decomposed in order to examine the sensitivity of a layer (measured by how well edges transmit perturbations) and the degeneracy of a layer (measured by how edge overlap interferes with transmission), along with estimates of the amount of integrated information of a layer. Together, these properties define where each layer lies in the "causal plane" which can be used to visualize how layer connectivity becomes more sensitive or degenerate over time, and how integration changes during training, revealing how the layer-by-layer causal structure differentiates. These results may help in understanding the generalization capabilities of DNNs and provide foundational tools for making DNNs both more generalizable and more explainable.},
	urldate = {2020-10-28},
	journal = {arXiv:2010.13871 [cs]},
	author = {Mattsson, Simon and Michaud, Eric J. and Hoel, Erik},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.13871},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 14 pages, 8 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/R5P424H4/2010.html:text/html;Mattsson et al_2020_Examining the causal structures of deep neural networks using information theory.pdf:/Users/tito/Zotero/storage/BV2WDBDC/Mattsson et al_2020_Examining the causal structures of deep neural networks using information theory.pdf:application/pdf},
}

@article{russo_motor_2018,
	title = {Motor {Cortex} {Embeds} {Muscle}-like {Commands} in an {Untangled} {Population} {Response}},
	volume = {97},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627318300072},
	doi = {10.1016/j.neuron.2018.01.004},
	abstract = {Primate motor cortex projects to spinal interneurons and motoneurons, suggesting that motor cortex activity may be dominated by muscle-like commands. Observations during reaching lend support to this view, but evidence remains ambiguous and much debated. To provide a different perspective, we employed a novel behavioral paradigm that facilitates comparison between time-evolving neural and muscle activity. We found that single motor cortex neurons displayed many muscle-like properties, but the structure of population activity was not muscle-like. Unlike muscle activity, neural activity was structured to avoid “tangling”: moments where similar activity patterns led to dissimilar future patterns. Avoidance of tangling was present across tasks and species. Network models revealed a potential reason for this consistent feature: low tangling confers noise robustness. Finally, we were able to predict motor cortex activity from muscle activity by leveraging the hypothesis that muscle-like commands are embedded in additional structure that yields low tangling.},
	language = {en},
	number = {4},
	urldate = {2020-10-30},
	journal = {Neuron},
	author = {Russo, Abigail A. and Bittner, Sean R. and Perkins, Sean M. and Seely, Jeffrey S. and London, Brian M. and Lara, Antonio H. and Miri, Andrew and Marshall, Najja J. and Kohn, Adam and Jessell, Thomas M. and Abbott, Laurence F. and Cunningham, John P. and Churchland, Mark M.},
	month = feb,
	year = {2018},
	keywords = {neural network, pattern generation, motor control, neural dynamics, motor cortex, movement generation, rhythmic movement},
	pages = {953--966.e8},
	file = {Russo et al_2018_Motor Cortex Embeds Muscle-like Commands in an Untangled Population Response.pdf:/Users/tito/Zotero/storage/2BDGUJBT/Russo et al_2018_Motor Cortex Embeds Muscle-like Commands in an Untangled Population Response.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/SDE7HN3B/S0896627318300072.html:text/html},
}

@article{schuessler_interplay_2020-1,
	title = {The interplay between randomness and structure during learning in {RNNs}},
	url = {http://arxiv.org/abs/2006.11036},
	abstract = {Recurrent neural networks (RNNs) trained on low-dimensional tasks have been widely used to model functional biological networks. However, the solutions found by learning and the effect of initial connectivity are not well understood. Here, we examine RNNs trained using gradient descent on different tasks inspired by the neuroscience literature. We find that the changes in recurrent connectivity can be described by low-rank matrices, despite the unconstrained nature of the learning algorithm. To identify the origin of the low-rank structure, we turn to an analytically tractable setting: training a linear RNN on a simplified task. We show how the low-dimensional task structure leads to low-rank changes to connectivity. This low-rank structure allows us to explain and quantify the phenomenon of accelerated learning in the presence of random initial connectivity. Altogether, our study opens a new perspective to understanding trained RNNs in terms of both the learning process and the resulting network structure.},
	urldate = {2020-10-30},
	journal = {arXiv:2006.11036 [q-bio]},
	author = {Schuessler, Friedrich and Mastrogiuseppe, Francesca and Dubreuil, Alexis and Ostojic, Srdjan and Barak, Omri},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.11036},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 28 pages (10 main text, 18 supplementary information). 9 figures (4 main, 5 supplement). Submission to conference Neurips 2020},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/YEDBJESN/2006.html:text/html;Schuessler et al_2020_The interplay between randomness and structure during learning in RNNs.pdf:/Users/tito/Zotero/storage/2Y9PRFFJ/Schuessler et al_2020_The interplay between randomness and structure during learning in RNNs.pdf:application/pdf},
}

@article{bishop_training_1995,
	title = {Training with {Noise} is {Equivalent} to {Tikhonov} {Regularization}},
	volume = {7},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1995.7.1.108},
	doi = {10.1162/neco.1995.7.1.108},
	abstract = {It is well known that the addition of noise to the input data of a neural network during training can, in some circumstances, lead to significant improvements in generalization performance. Previous work has shown that such training with noise is equivalent to a form of regularization in which an extra term is added to the error function. However, the regularization term, which involves second derivatives of the error function, is not bounded below, and so can lead to difficulties if used directly in a learning algorithm based on error minimization. In this paper we show that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping. For a sum-of-squares error function, the regularization term belongs to the class of generalized Tikhonov regularizers. Direct minimization of the regularized error function provides a practical alternative to training with noise.},
	number = {1},
	urldate = {2020-11-03},
	journal = {Neural Computation},
	author = {Bishop, Chris M.},
	month = jan,
	year = {1995},
	note = {Publisher: MIT Press},
	pages = {108--116},
	file = {Bishop_1995_Training with Noise is Equivalent to Tikhonov Regularization.pdf:/Users/tito/Zotero/storage/3KTT2JSZ/Bishop_1995_Training with Noise is Equivalent to Tikhonov Regularization.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/KAELKFII/neco.1995.7.1.html:text/html},
}

@article{atzmon_causal_2020,
	title = {A causal view of compositional zero-shot recognition},
	url = {http://arxiv.org/abs/2006.14610},
	abstract = {People easily recognize new visual categories that are new combinations of known components. This compositional generalization capacity is critical for learning in real-world domains like vision and language because the long tail of new combinations dominates the distribution. Unfortunately, learning systems struggle with compositional generalization because they often build on features that are correlated with class labels even if they are not "essential" for the class. This leads to consistent misclassification of samples from a new distribution, like new combinations of known components. Here we describe an approach for compositional generalization that builds on causal ideas. First, we describe compositional zero-shot learning from a causal perspective, and propose to view zero-shot inference as finding "which intervention caused the image?". Second, we present a causal-inspired embedding model that learns disentangled representations of elementary components of visual objects from correlated (confounded) training data. We evaluate this approach on two datasets for predicting new combinations of attribute-object pairs: A well-controlled synthesized images dataset and a real-world dataset which consists of fine-grained types of shoes. We show improvements compared to strong baselines.},
	urldate = {2020-11-06},
	journal = {arXiv:2006.14610 [cs]},
	author = {Atzmon, Yuval and Kreuk, Felix and Shalit, Uri and Chechik, Gal},
	month = nov,
	year = {2020},
	note = {arXiv: 2006.14610},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: (1) Accepted to NeurIPS 2020 (Spotlight) (2) Project page is at https://github.com/nv-research-israel/causal\_comp (3) A video of our spotlight talk is at https://www.youtube.com/watch?v=IUAmwBylvyc},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/ETT5N9J6/2006.html:text/html;Atzmon et al_2020_A causal view of compositional zero-shot recognition.pdf:/Users/tito/Zotero/storage/IHQ856CC/Atzmon et al_2020_A causal view of compositional zero-shot recognition.pdf:application/pdf},
}

@article{riemer_learning_2019-1,
	title = {Learning to {Learn} without {Forgetting} by {Maximizing} {Transfer} and {Minimizing} {Interference}},
	url = {http://arxiv.org/abs/1810.11910},
	abstract = {Lack of performance when it comes to continual learning over non-stationary distributions of data remains a major challenge in scaling neural network learning to more human realistic settings. In this work we propose a new conceptualization of the continual learning problem in terms of a temporally symmetric trade-off between transfer and interference that can be optimized by enforcing gradient alignment across examples. We then propose a new algorithm, Meta-Experience Replay (MER), that directly exploits this view by combining experience replay with optimization based meta-learning. This method learns parameters that make interference based on future gradients less likely and transfer based on future gradients more likely. We conduct experiments across continual lifelong supervised learning benchmarks and non-stationary reinforcement learning environments demonstrating that our approach consistently outperforms recently proposed baselines for continual learning. Our experiments show that the gap between the performance of MER and baseline algorithms grows both as the environment gets more non-stationary and as the fraction of the total experiences stored gets smaller.},
	urldate = {2020-11-06},
	journal = {arXiv:1810.11910 [cs, stat]},
	author = {Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
	month = may,
	year = {2019},
	note = {arXiv: 1810.11910},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR 2019},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/EHW3RHJ7/1810.html:text/html;Riemer et al_2019_Learning to Learn without Forgetting by Maximizing Transfer and Minimizing.pdf:/Users/tito/Zotero/storage/E39T5FYR/Riemer et al_2019_Learning to Learn without Forgetting by Maximizing Transfer and Minimizing.pdf:application/pdf},
}

@article{piantadosi_computational_2020,
	title = {The {Computational} {Origin} of {Representation}},
	issn = {1572-8641},
	url = {https://doi.org/10.1007/s11023-020-09540-9},
	doi = {10.1007/s11023-020-09540-9},
	abstract = {Each of our theories of mental representation provides some insight into how the mind works. However, these insights often seem incompatible, as the debates between symbolic, dynamical, emergentist, sub-symbolic, and grounded approaches to cognition attest. Mental representations—whatever they are—must share many features with each of our theories of representation, and yet there are few hypotheses about how a synthesis could be possible. Here, I develop a theory of the underpinnings of symbolic cognition that shows how sub-symbolic dynamics may give rise to higher-level cognitive representations of structures, systems of knowledge, and algorithmic processes. This theory implements a version of conceptual role semantics by positing an internal universal representation language in which learners may create mental models to capture dynamics they observe in the world. The theory formalizes one account of how truly novel conceptual content may arise, allowing us to explain how even elementary logical and computational operations may be learned from a more primitive basis. I provide an implementation that learns to represent a variety of structures, including logic, number, kinship trees, regular languages, context-free languages, domains of theories like magnetism, dominance hierarchies, list structures, quantification, and computational primitives like repetition, reversal, and recursion. This account is based on simple discrete dynamical processes that could be implemented in a variety of different physical or biological systems. In particular, I describe how the required dynamics can be directly implemented in a connectionist framework. The resulting theory provides an “assembly language” for cognition, where high-level theories of symbolic computation can be implemented in simple dynamics that themselves could be encoded in biologically plausible systems.},
	language = {en},
	urldate = {2020-11-10},
	journal = {Minds \& Machines},
	author = {Piantadosi, Steven T.},
	month = nov,
	year = {2020},
	file = {Piantadosi_2020_The Computational Origin of Representation.pdf:/Users/tito/Zotero/storage/AIGVZ29F/Piantadosi_2020_The Computational Origin of Representation.pdf:application/pdf},
}

@inproceedings{ben-david_exploiting_2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Exploiting {Task} {Relatedness} for {Multiple} {Task} {Learning}},
	isbn = {978-3-540-45167-9},
	doi = {10.1007/978-3-540-45167-9_41},
	abstract = {The approach of learning of multiple “related” tasks simultaneously has proven quite successful in practice; however, theoretical justification for this success has remained elusive. The starting point for previous work on multiple task learning has been that the tasks to be learned jointly are somehow “algorithmically related”, in the sense that the results of applying a specific learning algorithm to these tasks are assumed to be similar. We offer an alternative approach, defining relatedness of tasks on the basis of similarity between the example generating distributions that underline these task.We provide a formal framework for this notion of task relatedness, which captures a sub-domain of the wide scope of issues in which one may apply a multiple task learning approach. Our notion of task similarity is relevant to a variety of real life multitask learning scenarios and allows the formal derivation of generalization bounds that are strictly stronger than the previously known bounds for both the learning-to-learn and the multitask learning scenarios. We give precise conditions under which our bounds guarantee generalization on the basis of smaller sample sizes than the standard single-task approach.},
	language = {en},
	booktitle = {Learning {Theory} and {Kernel} {Machines}},
	publisher = {Springer},
	author = {Ben-David, Shai and Schuller, Reba},
	editor = {Schölkopf, Bernhard and Warmuth, Manfred K.},
	year = {2003},
	pages = {567--580},
	file = {Ben-David_Schuller_2003_Exploiting Task Relatedness for Multiple Task Learning.pdf:/Users/tito/Zotero/storage/C3ZLRV96/Ben-David_Schuller_2003_Exploiting Task Relatedness for Multiple Task Learning.pdf:application/pdf},
}

@article{semedo_cortical_2019,
	title = {Cortical {Areas} {Interact} through a {Communication} {Subspace}},
	volume = {102},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627319300534},
	doi = {10.1016/j.neuron.2019.01.026},
	abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
	language = {en},
	number = {1},
	urldate = {2020-11-11},
	journal = {Neuron},
	author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
	month = apr,
	year = {2019},
	keywords = {visual cortex, primary visual cortex, vision, macaque, area V2, corticocortical, dimensionality reduction, inter-areal communication, neural population, neural variability},
	pages = {249--259.e4},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/RK6J4S5H/S0896627319300534.html:text/html;Semedo et al_2019_Cortical Areas Interact through a Communication Subspace.pdf:/Users/tito/Zotero/storage/8JP6RJ6Q/Semedo et al_2019_Cortical Areas Interact through a Communication Subspace.pdf:application/pdf},
}

@article{kohn_principles_2020,
	title = {Principles of {Corticocortical} {Communication}: {Proposed} {Schemes} and {Design} {Considerations}},
	volume = {43},
	issn = {01662236},
	shorttitle = {Principles of {Corticocortical} {Communication}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016622362030165X},
	doi = {10.1016/j.tins.2020.07.001},
	language = {en},
	number = {9},
	urldate = {2020-11-11},
	journal = {Trends in Neurosciences},
	author = {Kohn, Adam and Jasper, Anna I. and Semedo, João D. and Gokcen, Evren and Machens, Christian K. and Yu, Byron M.},
	month = sep,
	year = {2020},
	pages = {725--737},
	file = {Kohn et al. - 2020 - Principles of Corticocortical Communication Propo.pdf:/Users/tito/Zotero/storage/GMTVXBDF/Kohn et al. - 2020 - Principles of Corticocortical Communication Propo.pdf:application/pdf},
}

@article{roth_task-related_2020,
	title = {Task-related activity in human visual cortex},
	volume = {18},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000921},
	doi = {10.1371/journal.pbio.3000921},
	abstract = {The brain exhibits widespread endogenous responses in the absence of visual stimuli, even at the earliest stages of visual cortical processing. Such responses have been studied in monkeys using optical imaging with a limited field of view over visual cortex. Here, we used functional MRI (fMRI) in human participants to study the link between arousal and endogenous responses in visual cortex. The response that we observed was tightly entrained to task timing, was spatially extensive, and was independent of visual stimulation. We found that this response follows dynamics similar to that of pupil size and heart rate, suggesting that task-related activity is related to arousal. Finally, we found that higher reward increased response amplitude while decreasing its trial-to-trial variability (i.e., the noise). Computational simulations suggest that increased temporal precision underlies both of these observations. Our findings are consistent with optical imaging studies in monkeys and support the notion that arousal increases precision of neural activity.},
	language = {en},
	number = {11},
	urldate = {2020-11-11},
	journal = {PLOS Biology},
	author = {Roth, Zvi N. and Ryoo, Minyoung and Merriam, Elisha P.},
	month = nov,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Functional magnetic resonance imaging, Attention, Visual cortex, Vision, Hemodynamics, Fovea centralis, Heart rate, Visual system},
	pages = {e3000921},
	file = {Roth et al_2020_Task-related activity in human visual cortex.pdf:/Users/tito/Zotero/storage/NUQNILUX/Roth et al_2020_Task-related activity in human visual cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HPMGAJJT/article.html:text/html},
}

@article{suarez_learning_2020,
	title = {Learning function from structure in neuromorphic networks},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.11.10.350876v1},
	doi = {10.1101/2020.11.10.350876},
	abstract = {{\textless}p{\textgreater}The connection patterns of neural circuits in the brain form a complex network. Collective signaling within the network manifests as patterned neural activity, and is thought to support human cognition and adaptive behavior. Recent technological advances permit macro-scale reconstructions of biological brain networks. These maps, termed connectomes, display multiple non-random architectural features, including heavy-tailed degree distributions, segregated communities and a densely interconnected core. Yet, how computation and functional specialization emerge from network architecture remains unknown. Here we reconstruct human brain connectomes using \textit{in vivo} diffusion-weighted imaging, and use reservoir computing to implement these connectomes as artificial neural networks. We then train these neuromorphic networks to learn a cognitive task. We show that biologically realistic neural architectures perform optimally when they display critical dynamics. We find that performance is driven by network topology, and that the modular organization of large-scale functional systems is computationally relevant. Throughout, we observe a prominent interaction between network structure and dynamics, such that the same underlying architecture can support a wide range of learning capacities across dynamical regimes. This work opens new opportunities to discover how the network organization of the brain optimizes cognitive capacity, conceptually bridging neuroscience and artificial intelligence.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-11-12},
	journal = {bioRxiv},
	author = {Suarez, Laura E. and Richards, Blake A. and Lajoie, Guillaume and Misic, Bratislav},
	month = nov,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.11.10.350876},
	file = {Snapshot:/Users/tito/Zotero/storage/CL5IA5JS/2020.11.10.html:text/html;Suarez et al_2020_Learning function from structure in neuromorphic networks.pdf:/Users/tito/Zotero/storage/HWSV6GLD/Suarez et al_2020_Learning function from structure in neuromorphic networks.pdf:application/pdf},
}

@article{qin_optimal_2019,
	title = {Optimal compressed sensing strategies for an array of nonlinear olfactory receptor neurons with and without spontaneous activity},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/41/20286},
	doi = {10.1073/pnas.1906571116},
	abstract = {There are numerous different odorant molecules in nature but only a relatively small number of olfactory receptor neurons (ORNs) in brains. This “compressed sensing” challenge is compounded by the constraint that ORNs are nonlinear sensors with a finite dynamic range. Here, we investigate possible optimal olfactory coding strategies by maximizing mutual information between odor mixtures and ORNs’ responses with respect to the bipartite odor-receptor interaction network (ORIN) characterized by sensitivities between all odorant–ORN pairs. For ORNs without spontaneous (basal) activity, we find that the optimal ORIN is sparse—a finite fraction of sensitives are zero, and the nonzero sensitivities follow a broad distribution that depends on the odor statistics. We show analytically that sparsity in the optimal ORIN originates from a trade-off between the broad tuning of ORNs and possible interference. Furthermore, we show that the optimal ORIN enhances performances of downstream learning tasks (reconstruction and classification). For ORNs with a finite basal activity, we find that having inhibitory odor–receptor interactions increases the coding capacity and the fraction of inhibitory interactions increases with the ORN basal activity. We argue that basal activities in sensory receptors in different organisms are due to the trade-off between the increase in coding capacity and the cost of maintaining the spontaneous basal activity. Our theoretical findings are consistent with existing experiments and predictions are made to further test our theory. The optimal coding model provides a unifying framework to understand the peripheral olfactory systems across different organisms.},
	language = {en},
	number = {41},
	urldate = {2020-11-13},
	journal = {PNAS},
	author = {Qin, Shanshan and Li, Qianyi and Tang, Chao and Tu, Yuhai},
	month = oct,
	year = {2019},
	pmid = {31548382},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {information theory, coding, olfaction, olfactory receptor neurons},
	pages = {20286--20295},
	file = {Qin et al_2019_Optimal compressed sensing strategies for an array of nonlinear olfactory.pdf:/Users/tito/Zotero/storage/4INB9A2J/Qin et al_2019_Optimal compressed sensing strategies for an array of nonlinear olfactory.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/T2PDF5SM/20286.html:text/html;Snapshot:/Users/tito/Zotero/storage/SJXJYPBM/20286.html:text/html},
}

@article{bashivan_continual_2019,
	title = {Continual {Learning} with {Self}-{Organizing} {Maps}},
	url = {http://arxiv.org/abs/1904.09330},
	abstract = {Despite remarkable successes achieved by modern neural networks in a wide range of applications, these networks perform best in domain-specific stationary environments where they are trained only once on large-scale controlled data repositories. When exposed to non-stationary learning environments, current neural networks tend to forget what they had previously learned, a phenomena known as catastrophic forgetting. Most previous approaches to this problem rely on memory replay buffers which store samples from previously learned tasks, and use them to regularize the learning on new ones. This approach suffers from the important disadvantage of not scaling well to real-life problems in which the memory requirements become enormous. We propose a memoryless method that combines standard supervised neural networks with self-organizing maps to solve the continual learning problem. The role of the self-organizing map is to adaptively cluster the inputs into appropriate task contexts - without explicit labels - and allocate network resources accordingly. Thus, it selectively routes the inputs in accord with previous experience, ensuring that past learning is maintained and does not interfere with current learning. Out method is intuitive, memoryless, and performs on par with current state-of-the-art approaches on standard benchmarks.},
	urldate = {2020-11-13},
	journal = {arXiv:1904.09330 [cs]},
	author = {Bashivan, Pouya and Schrimpf, Martin and Ajemian, Robert and Rish, Irina and Riemer, Matthew and Tu, Yuhai},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.09330},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Continual Learning Workshop - NeurIPS 2018},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DZA33AZZ/1904.html:text/html;Bashivan et al_2019_Continual Learning with Self-Organizing Maps.pdf:/Users/tito/Zotero/storage/V3DDV52T/Bashivan et al_2019_Continual Learning with Self-Organizing Maps.pdf:application/pdf},
}

@article{craver_top-down_2007,
	title = {Top-down causation without top-down causes},
	volume = {22},
	number = {4},
	journal = {Biology \& philosophy},
	author = {Craver, Carl F. and Bechtel, William},
	year = {2007},
	note = {Publisher: Springer},
	pages = {547--563},
	file = {Craver_Bechtel_2007_Top-down causation without top-down causes.pdf:/Users/tito/Zotero/storage/7UUQSENK/Craver_Bechtel_2007_Top-down causation without top-down causes.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SL5Z9IKJ/s10539-006-9028-8.html:text/html},
}

@article{lake_simultaneous_2020,
	title = {Simultaneous cortex-wide fluorescence {Ca} 2+ imaging and whole-brain {fMRI}},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-020-00984-6},
	doi = {10.1038/s41592-020-00984-6},
	abstract = {Achieving a comprehensive understanding of brain function requires multiple imaging modalities with complementary strengths. We present an approach for concurrent widefield optical and functional magnetic resonance imaging. By merging these modalities, we can simultaneously acquire whole-brain blood-oxygen-level-dependent (BOLD) and whole-cortex calcium-sensitive fluorescent measures of brain activity. In a transgenic murine model, we show that calcium predicts the BOLD signal, using a model that optimizes a gamma-variant transfer function. We find consistent predictions across the cortex, which are best at low frequency (0.009–0.08 Hz). Furthermore, we show that the relationship between modality connectivity strengths varies by region. Our approach links cell-type-specific optical measurements of activity to the most widely used method for assessing human brain function.},
	language = {en},
	urldate = {2020-11-13},
	journal = {Nature Methods},
	author = {Lake, Evelyn M. R. and Ge, Xinxin and Shen, Xilin and Herman, Peter and Hyder, Fahmeed and Cardin, Jessica A. and Higley, Michael J. and Scheinost, Dustin and Papademetris, Xenophon and Crair, Michael C. and Constable, R. Todd},
	month = nov,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--10},
	file = {Lake et al_2020_Simultaneous cortex-wide fluorescence Ca 2+ imaging and whole-brain fMRI.pdf:/Users/tito/Zotero/storage/WHM6NQ32/Lake et al_2020_Simultaneous cortex-wide fluorescence Ca 2+ imaging and whole-brain fMRI.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/RF78FIH7/s41592-020-00984-6.html:text/html;Snapshot:/Users/tito/Zotero/storage/45JZMSNR/s41592-020-00984-6.html:text/html},
}

@article{steinmetz_challenges_2018,
	title = {Challenges and opportunities for large-scale electrophysiology with {Neuropixels} probes},
	volume = {50},
	journal = {Current opinion in neurobiology},
	author = {Steinmetz, Nicholas A. and Koch, Christof and Harris, Kenneth D. and Carandini, Matteo},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {92--100},
	file = {Full Text:/Users/tito/Zotero/storage/7X5LFWBN/S0959438817303161.html:text/html},
}

@article{liu_compositional_2020,
	title = {Compositional {Generalization} by {Learning} {Analytical} {Expressions}},
	url = {http://arxiv.org/abs/2006.10627},
	abstract = {Compositional generalization is a basic and essential intellective capability of human beings, which allows us to recombine known parts readily. However, existing neural network based models have been proven to be extremely deficient in such a capability. Inspired by work in cognition which argues compositionality can be captured by variable slots with symbolic functions, we present a refreshing view that connects a memory-augmented neural model with analytical expressions, to achieve compositional generalization. Our model consists of two cooperative neural modules, Composer and Solver, fitting well with the cognitive argument while being able to be trained in an end-to-end manner via a hierarchical reinforcement learning algorithm. Experiments on the well-known benchmark SCAN demonstrate that our model seizes a great ability of compositional generalization, solving all challenges addressed by previous works with 100\% accuracies.},
	urldate = {2020-11-16},
	journal = {arXiv:2006.10627 [cs]},
	author = {Liu, Qian and An, Shengnan and Lou, Jian-Guang and Chen, Bei and Lin, Zeqi and Gao, Yan and Zhou, Bin and Zheng, Nanning and Zhang, Dongmei},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.10627},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: To appear in NeurIPS 2020 (Spotlight)},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/6RXAIGBY/2006.html:text/html;Liu et al_2020_Compositional Generalization by Learning Analytical Expressions.pdf:/Users/tito/Zotero/storage/GARF85J2/Liu et al_2020_Compositional Generalization by Learning Analytical Expressions.pdf:application/pdf},
}

@article{greene_task-induced_2018,
	title = {Task-induced brain state manipulation improves prediction of individual traits},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-04920-3},
	doi = {10.1038/s41467-018-04920-3},
	abstract = {Recent work has begun to relate individual differences in brain functional organization to human behaviors and cognition, but the best brain state to reveal such relationships remains an open question. In two large, independent data sets, we here show that cognitive tasks amplify trait-relevant individual differences in patterns of functional connectivity, such that predictive models built from task fMRI data outperform models built from resting-state fMRI data. Further, certain tasks consistently yield better predictions of fluid intelligence than others, and the task that generates the best-performing models varies by sex. By considering task-induced brain state and sex, the best-performing model explains over 20\% of the variance in fluid intelligence scores, as compared to {\textless}6\% of variance explained by rest-based models. This suggests that identifying and inducing the right brain state in a given group can better reveal brain-behavior relationships, motivating a paradigm shift from rest- to task-based functional connectivity analyses.},
	language = {en},
	number = {1},
	urldate = {2020-11-17},
	journal = {Nature Communications},
	author = {Greene, Abigail S. and Gao, Siyuan and Scheinost, Dustin and Constable, R. Todd},
	month = jul,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2807},
	file = {Greene et al_2018_Task-induced brain state manipulation improves prediction of individual traits.pdf:/Users/tito/Zotero/storage/T79W9YZL/Greene et al_2018_Task-induced brain state manipulation improves prediction of individual traits.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/NNKN7B6I/s41467-018-04920-3.html:text/html},
}

@article{gonzalez-garcia_gradient_2020,
	title = {A {Gradient} of {Sharpening} {Effects} by {Perceptual} {Prior} across the {Human} {Cortical} {Hierarchy}},
	copyright = {Copyright © 2020 the authors. SfN exclusive license.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/early/2020/11/16/JNEUROSCI.2023-20.2020},
	doi = {10.1523/JNEUROSCI.2023-20.2020},
	abstract = {Prior knowledge profoundly influences perceptual processing. Previous studies have revealed consistent suppression of predicted stimulus information in sensory areas, but how prior knowledge modulates processing higher up in the cortical hierarchy remains poorly understood. In addition, the mechanism leading to suppression of predicted sensory information remains unclear, and studies thus far have revealed a mixed pattern of results in support of either the ‘sharpening’ or ‘dampening’ model. Here, using 7T fMRI in humans (both sexes), we observed that prior knowledge acquired from fast, one-shot perceptual learning sharpens neural representation throughout the ventral visual stream, generating suppressed sensory responses. In contrast, the frontoparietal (FPN) and default-mode (DMN) networks exhibit similar sharpening of content-specific neural representation but in the context of unchanged and enhanced activity magnitudes, respectively—a pattern we refer to as ‘selective enhancement’. Together, these results reveal a heretofore unknown macroscopic gradient of prior knowledge’s sharpening effect on neural representations across the cortical hierarchy.
SIGNIFICANCE STATEMENT:
A fundamental question in neuroscience is how prior knowledge shapes perceptual processing. Perception is constantly informed by internal priors in the brain acquired from past experiences, but the neural mechanisms underlying this process are poorly understood. To date, research on this question has focused on early visual regions, reporting a consistent downregulation when predicted stimuli are encountered. Here, using a dramatic one-shot perceptual learning paradigm, we observed that prior knowledge results in sharper neural representations across the cortical hierarchy of the human brain through a gradient of mechanisms. In visual regions, neural responses tuned away from internal predictions are suppressed. In frontoparietal regions, neural activity consistent with priors is selectively enhanced. These results deepen our understanding of how prior knowledge informs perception.},
	language = {en},
	urldate = {2020-11-19},
	journal = {J. Neurosci.},
	author = {González-García, Carlos and He, Biyu Jade},
	month = nov,
	year = {2020},
	pmid = {33208472},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	file = {Snapshot:/Users/tito/Zotero/storage/TE6CJDGS/JNEUROSCI.2023-20.html:text/html},
}

@article{fodor_jerry_1999,
	title = {Jerry {Fodor} · {Diary}: why the brain? · {LRB} 30 {September} 1999},
	volume = {21},
	issn = {0260-9592},
	shorttitle = {Jerry {Fodor} · {Diary}},
	url = {https://www.lrb.co.uk/the-paper/v21/n19/jerry-fodor/diary},
	language = {en},
	number = {19},
	urldate = {2020-11-22},
	journal = {London Review of Books},
	author = {Fodor, Jerry},
	month = sep,
	year = {1999},
	keywords = {Mind and cognitive science, Neuroscience},
	file = {Snapshot:/Users/tito/Zotero/storage/D7P22DDW/diary.html:text/html},
}

@article{duncker_organizing_2020,
	title = {Organizing recurrent network dynamics by task-computation to enable continual learning},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/a576eafbce762079f7d1f77fca1c5cc2-Abstract.html?s=03},
	language = {en},
	urldate = {2020-11-24},
	journal = {Advances in Neural Information Processing Systems},
	author = {Duncker, Lea and Driscoll, Laura and Shenoy, Krishna V. and Sahani, Maneesh and Sussillo, David},
	year = {2020},
	file = {Duncker et al_2020_Organizing recurrent network dynamics by task-computation to enable continual.pdf:/Users/tito/Zotero/storage/SNLC7YDF/Duncker et al_2020_Organizing recurrent network dynamics by task-computation to enable continual.pdf:application/pdf},
}

@article{bahg_gaussian_2020,
	title = {Gaussian process linking functions for mind, brain, and behavior},
	volume = {117},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/117/47/29398},
	doi = {10.1073/pnas.1912342117},
	abstract = {The link between mind, brain, and behavior has mystified philosophers and scientists for millennia. Recent progress has been made by forming statistical associations between manifest variables of the brain (e.g., electroencephalogram [EEG], functional MRI [fMRI]) and manifest variables of behavior (e.g., response times, accuracy) through hierarchical latent variable models. Within this framework, one can make inferences about the mind in a statistically principled way, such that complex patterns of brain–behavior associations drive the inference procedure. However, previous approaches were limited in the flexibility of the linking function, which has proved prohibitive for understanding the complex dynamics exhibited by the brain. In this article, we propose a data-driven, nonparametric approach that allows complex linking functions to emerge from fitting a hierarchical latent representation of the mind to multivariate, multimodal data. Furthermore, to enforce biological plausibility, we impose both spatial and temporal structure so that the types of realizable system dynamics are constrained. To illustrate the benefits of our approach, we investigate the model’s performance in a simulation study and apply it to experimental data. In the simulation study, we verify that the model can be accurately fitted to simulated data, and latent dynamics can be well recovered. In an experimental application, we simultaneously fit the model to fMRI and behavioral data from a continuous motion tracking task. We show that the model accurately recovers both neural and behavioral data and reveals interesting latent cognitive dynamics, the topology of which can be contrasted with several aspects of the experiment.},
	language = {en},
	number = {47},
	urldate = {2020-11-25},
	journal = {PNAS},
	author = {Bahg, Giwon and Evans, Daniel G. and Galdo, Matthew and Turner, Brandon M.},
	month = nov,
	year = {2020},
	pmid = {33229563},
	note = {Publisher: National Academy of Sciences
Section: Colloquium Paper},
	keywords = {dimensionality reduction, Gaussian process, joint modeling, model-based cognitive neuroscience},
	pages = {29398--29406},
	file = {Bahg et al_2020_Gaussian process linking functions for mind, brain, and behavior.pdf:/Users/tito/Zotero/storage/N8493V33/Bahg et al_2020_Gaussian process linking functions for mind, brain, and behavior.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3CBKZ6FP/29398.html:text/html},
}

@book{hebb_organization_2002,
	address = {Mahwah, N.J},
	title = {The organization of behavior: a neuropsychological theory},
	isbn = {978-0-8058-4300-2},
	shorttitle = {The organization of behavior},
	language = {en},
	publisher = {L. Erlbaum Associates},
	author = {Hebb, D. O.},
	year = {2002},
	keywords = {Neuropsychology},
	file = {Hebb - 2002 - The organization of behavior a neuropsychological.pdf:/Users/tito/Zotero/storage/6ZRAIM8P/Hebb - 2002 - The organization of behavior a neuropsychological.pdf:application/pdf},
}

@article{kim_granger_2011,
	title = {A {Granger} {Causality} {Measure} for {Point} {Process} {Models} of {Ensemble} {Neural} {Spiking} {Activity}},
	volume = {7},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1001110},
	doi = {10.1371/journal.pcbi.1001110},
	abstract = {The ability to identify directional interactions that occur among multiple neurons in the brain is crucial to an understanding of how groups of neurons cooperate in order to generate specific brain functions. However, an optimal method of assessing these interactions has not been established. Granger causality has proven to be an effective method for the analysis of the directional interactions between multiple sets of continuous-valued data, but cannot be applied to neural spike train recordings due to their discrete nature. This paper proposes a point process framework that enables Granger causality to be applied to point process data such as neural spike trains. The proposed framework uses the point process likelihood function to relate a neuron's spiking probability to possible covariates, such as its own spiking history and the concurrent activity of simultaneously recorded neurons. Granger causality is assessed based on the relative reduction of the point process likelihood of one neuron obtained excluding one of its covariates compared to the likelihood obtained using all of its covariates. The method was tested on simulated data, and then applied to neural activity recorded from the primary motor cortex (MI) of a Felis catus subject. The interactions present in the simulated data were predicted with a high degree of accuracy, and when applied to the real neural data, the proposed method identified causal relationships between many of the recorded neurons. This paper proposes a novel method that successfully applies Granger causality to point process data, and has the potential to provide unique physiological insights when applied to neural spike trains.},
	language = {en},
	number = {3},
	urldate = {2020-12-04},
	journal = {PLOS Computational Biology},
	author = {Kim, Sanggyun and Putrino, David and Ghosh, Soumya and Brown, Emery N.},
	month = mar,
	year = {2011},
	note = {Publisher: Public Library of Science},
	keywords = {Statistical models, Neurons, Network analysis, Neural networks, Simulation and modeling, Action potentials, Artificial neural networks, Test statistics},
	pages = {e1001110},
	file = {Kim et al_2011_A Granger Causality Measure for Point Process Models of Ensemble Neural Spiking.pdf:/Users/tito/Zotero/storage/LF6KU89J/Kim et al_2011_A Granger Causality Measure for Point Process Models of Ensemble Neural Spiking.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/RC2UZB54/article.html:text/html},
}

@article{das_systematic_2020,
	title = {Systematic errors in connectivity inferred from activity in strongly recurrent networks},
	volume = {23},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-020-0699-2},
	doi = {10.1038/s41593-020-0699-2},
	abstract = {Understanding the mechanisms of neural computation and learning will require knowledge of the underlying circuitry. Because it is difficult to directly measure the wiring diagrams of neural circuits, there has long been an interest in estimating them algorithmically from multicell activity recordings. We show that even sophisticated methods, applied to unlimited data from every cell in the circuit, are biased toward inferring connections between unconnected but highly correlated neurons. This failure to ‘explain away’ connections occurs when there is a mismatch between the true network dynamics and the model used for inference, which is inevitable when modeling the real world. Thus, causal inference suffers when variables are highly correlated, and activity-based estimates of connectivity should be treated with special caution in strongly connected networks. Finally, performing inference on the activity of circuits pushed far out of equilibrium by a simple low-dimensional suppressive drive might ameliorate inference bias.},
	language = {en},
	number = {10},
	urldate = {2020-12-07},
	journal = {Nature Neuroscience},
	author = {Das, Abhranil and Fiete, Ila R.},
	month = oct,
	year = {2020},
	note = {Number: 10
Publisher: Nature Publishing Group},
	pages = {1286--1296},
	file = {Das_Fiete_2020_Systematic errors in connectivity inferred from activity in strongly recurrent.pdf:/Users/tito/Zotero/storage/NYDDPSPK/Das_Fiete_2020_Systematic errors in connectivity inferred from activity in strongly recurrent.pdf:application/pdf},
}

@article{suarez_learning_2020-1,
	title = {Learning function from structure in neuromorphic networks},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.11.10.350876v1},
	doi = {10.1101/2020.11.10.350876},
	abstract = {{\textless}p{\textgreater}The connection patterns of neural circuits in the brain form a complex network. Collective signaling within the network manifests as patterned neural activity, and is thought to support human cognition and adaptive behavior. Recent technological advances permit macro-scale reconstructions of biological brain networks. These maps, termed connectomes, display multiple non-random architectural features, including heavy-tailed degree distributions, segregated communities and a densely interconnected core. Yet, how computation and functional specialization emerge from network architecture remains unknown. Here we reconstruct human brain connectomes using \textit{in vivo} diffusion-weighted imaging, and use reservoir computing to implement these connectomes as artificial neural networks. We then train these neuromorphic networks to learn a cognitive task. We show that biologically realistic neural architectures perform optimally when they display critical dynamics. We find that performance is driven by network topology, and that the modular organization of large-scale functional systems is computationally relevant. Throughout, we observe a prominent interaction between network structure and dynamics, such that the same underlying architecture can support a wide range of learning capacities across dynamical regimes. This work opens new opportunities to discover how the network organization of the brain optimizes cognitive capacity, conceptually bridging neuroscience and artificial intelligence.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-12-09},
	journal = {bioRxiv},
	author = {Suárez, Laura E. and Richards, Blake A. and Lajoie, Guillaume and Misic, Bratislav},
	month = nov,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.11.10.350876},
	file = {Snapshot:/Users/tito/Zotero/storage/WGBVBRP9/2020.11.10.350876v1.html:text/html;Suárez et al_2020_Learning function from structure in neuromorphic networks.pdf:/Users/tito/Zotero/storage/5FC8JAJV/Suárez et al_2020_Learning function from structure in neuromorphic networks.pdf:application/pdf},
}

@article{hu_changes_2012,
	title = {Changes in the default mode network in the prefrontal lobe, posterior cingulated cortex and hippocampus of heroin users},
	volume = {7},
	issn = {1673-5374},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4308788/},
	doi = {10.3969/j.issn.1673-5374.2012.18.004},
	abstract = {The default mode network is associated with senior cognitive functions in humans. In this study, we performed independent component analysis of blood oxygenation signals from 14 heroin users and 13 matched normal controls in the resting state through functional MRI scans. Results showed that the default mode network was significantly activated in the prefrontal lobe, posterior cingulated cortex and hippocampus of heroin users, and an enhanced activation signal was observed in the right inferior parietal lobule (P {\textless} 0.05, corrected for false discovery rate). Experimental findings indicate that the default mode network is altered in heroin users.},
	number = {18},
	urldate = {2020-12-09},
	journal = {Neural Regen Res},
	author = {Hu, Wenfu and Fu, Xiangming and Qian, Ruobing and Wei, Xiangpin and Ji, Xuebing and Niu, Chaoshi},
	month = jun,
	year = {2012},
	pmid = {25657671},
	pmcid = {PMC4308788},
	pages = {1386--1391},
}

@article{umakantha_bridging_2020,
	title = {Bridging neuronal correlations and dimensionality reduction},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.12.04.383604v1},
	doi = {10.1101/2020.12.04.383604},
	abstract = {{\textless}p{\textgreater}Two commonly used approaches to study interactions among neurons are spike count correlation, which describes pairs of neurons, and dimensionality reduction, applied to a population of neurons. While both approaches have been used to study trial-to-trial correlated neuronal variability, they are often used in isolation and have not been directly related. We first established concrete mathematical and empirical relationships between pairwise correlation and metrics of population-wide covariability based on dimensionality reduction. Applying these insights to macaque V4 population recordings, we found that the previously reported decrease in mean pairwise correlation associated with attention stemmed from three distinct changes in population-wide covariability. Overall, our work builds the intuition and formalism to bridge between pairwise correlation and population-wide covariability and presents a cautionary tale about the inferences one can make about population activity by using a single statistic, whether it be mean pairwise correlation or dimensionality.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-12-10},
	journal = {bioRxiv},
	author = {Umakantha, Akash and Morina, Rudina and Cowley, Benjamin R. and Snyder, Adam C. and Smith, Matthew A. and Yu, Byron M.},
	month = dec,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.12.04.383604},
	file = {Umakantha et al_2020_Bridging neuronal correlations and dimensionality reduction.pdf:/Users/tito/Zotero/storage/WQC32EWQ/Umakantha et al_2020_Bridging neuronal correlations and dimensionality reduction.pdf:application/pdf},
}

@article{wen_hierarchical_2020,
	title = {Hierarchical {Representation} of {Multistep} {Tasks} in {Multiple}-{Demand} and {Default} {Mode} {Networks}},
	volume = {40},
	copyright = {Copyright © 2020 Wen et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution License Creative Commons Attribution 4.0 International, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/40/40/7724},
	doi = {10.1523/JNEUROSCI.0594-20.2020},
	abstract = {Task episodes consist of sequences of steps that are performed to achieve a goal. We used fMRI to examine neural representation of task identity, component items, and sequential position, focusing on two major cortical systems—the multiple-demand (MD) and default mode networks (DMN). Human participants (20 males, 22 females) learned six tasks each consisting of four steps. Inside the scanner, participants were cued which task to perform and then sequentially identified the target item of each step in the correct order. Univariate time course analyses indicated that intra-episode progress was tracked by a tonically increasing global response, plus an increasing phasic step response specific to MD regions. Inter-episode boundaries evoked a widespread response at episode onset, plus a marked offset response specific to DMN regions. Representational similarity analysis (RSA) was used to examine representation of task identity and component steps. Both networks represented the content and position of individual steps, however the DMN preferentially represented task identity while the MD network preferentially represented step-level information. Thus, although both MD and DMN networks are sensitive to step-level and episode-level information in the context of hierarchical task performance, they exhibit dissociable profiles in terms of both temporal dynamics and representational content. The results suggest collaboration of multiple brain regions in control of multistep behavior, with MD regions particularly involved in processing the detail of individual steps, and DMN adding representation of broad task context.
SIGNIFICANCE STATEMENT Achieving one's goals requires knowing what to do and when. Tasks are typically hierarchical, with smaller steps nested within overarching goals. For effective, flexible behavior, the brain must represent both levels. We contrast response time courses and information content of two major cortical systems—the multiple-demand (MD) and default mode networks (DMN)—during multistep task episodes. Both networks are sensitive to step-level and episode-level information, but with dissociable profiles. Intra-episode progress is tracked by tonically increasing global responses, plus MD-specific increasing phasic step responses. Inter-episode boundaries evoke widespread responses at episode onset, plus DMN-specific offset responses. Both networks represent content and position of individual steps; however, the DMN and MD networks favor task identity and step-level information, respectively.},
	language = {en},
	number = {40},
	urldate = {2020-12-10},
	journal = {J. Neurosci.},
	author = {Wen, Tanya and Duncan, John and Mitchell, Daniel J.},
	month = sep,
	year = {2020},
	pmid = {32868460},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {fMRI, default mode network, representational similarity analysis, hierarchy, multiple-demand network, task episodes},
	pages = {7724--7738},
	file = {Wen et al_2020_Hierarchical Representation of Multistep Tasks in Multiple-Demand and Default.pdf:/Users/tito/Zotero/storage/A674J4PU/Wen et al_2020_Hierarchical Representation of Multistep Tasks in Multiple-Demand and Default.pdf:application/pdf},
}

@article{smith_future_2012,
	series = {20 {YEARS} {OF} {fMRI}},
	title = {The future of {FMRI} connectivity},
	volume = {62},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912000390},
	doi = {10.1016/j.neuroimage.2012.01.022},
	abstract = {“FMRI connectivity” encompasses many areas of research, including resting-state networks, biophysical modelling of task-FMRI data and bottom-up simulation of multiple individual neurons interacting with each other. In this brief paper I discuss several outstanding areas that I believe will see exciting developments in the next few years, in particular concentrating on how I think the currently separate approaches will increasingly need to take advantage of each others' respective complementarities.},
	language = {en},
	number = {2},
	urldate = {2020-12-14},
	journal = {NeuroImage},
	author = {Smith, Stephen M.},
	month = aug,
	year = {2012},
	keywords = {Functional connectivity, Causality, Effective connectivity, FMRI, DCM, ICA, Bayes nets, Dual-regression, Resting-state networks, SEM},
	pages = {1257--1266},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/UZ6J4GK7/S1053811912000390.html:text/html;Smith_2012_The future of FMRI connectivity.pdf:/Users/tito/Zotero/storage/ZMLXNLD6/Smith_2012_The future of FMRI connectivity.pdf:application/pdf},
}

@article{friston_functional_2011,
	title = {Functional and {Effective} {Connectivity}: {A} {Review}},
	volume = {1},
	issn = {2158-0014},
	shorttitle = {Functional and {Effective} {Connectivity}},
	url = {https://www.liebertpub.com/doi/full/10.1089/brain.2011.0008},
	doi = {10.1089/brain.2011.0008},
	abstract = {Over the past 20 years, neuroimaging has become a predominant technique in systems neuroscience. One might envisage that over the next 20 years the neuroimaging of distributed processing and connectivity will play a major role in disclosing the brain's functional architecture and operational principles. The inception of this journal has been foreshadowed by an ever-increasing number of publications on functional connectivity, causal modeling, connectomics, and multivariate analyses of distributed patterns of brain responses. I accepted the invitation to write this review with great pleasure and hope to celebrate and critique the achievements to date, while addressing the challenges ahead.},
	number = {1},
	urldate = {2020-12-14},
	journal = {Brain Connectivity},
	author = {Friston, Karl J.},
	month = jan,
	year = {2011},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	pages = {13--36},
	file = {Friston_2011_Functional and Effective Connectivity.pdf:/Users/tito/Zotero/storage/LVW2EHJL/Friston_2011_Functional and Effective Connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/QPGNEQ9X/brain.2011.html:text/html},
}

@article{sporns_network_2013,
	series = {Macrocircuits},
	title = {Network attributes for segregation and integration in the human brain},
	volume = {23},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438812001894},
	doi = {10.1016/j.conb.2012.11.015},
	abstract = {Network studies of large-scale brain connectivity have begun to reveal attributes that promote the segregation and integration of neural information: communities and hubs. Network communities are sets of regions that are strongly interconnected among each other while connections between members of different communities are less dense. The clustered connectivity of network communities supports functional segregation and specialization. Network hubs link communities to one another and ensure efficient communication and information integration. This review surveys a number of recent reports on network communities and hubs, and their role in integrative processes. An emerging focus is the shifting balance between segregation and integration over time, which manifest in continuously changing patterns of functional interactions between regions, circuits and systems.},
	language = {en},
	number = {2},
	urldate = {2020-12-14},
	journal = {Current Opinion in Neurobiology},
	author = {Sporns, Olaf},
	month = apr,
	year = {2013},
	pages = {162--171},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/2IU43XFT/S0959438812001894.html:text/html},
}

@article{nejatbakhsh_predicting_nodate,
	title = {Predicting perturbation effects from resting state activity using functional causal flow},
	abstract = {Targeted manipulation of neural activity will be greatly facilitated by understanding causal interactions within neural ensembles. Here, we introduce a novel statistical method to infer a network’s “functional causal ﬂow” (FCF) from ensemble neural recordings. Using ground truth data from models of cortical circuits, we show that FCF captures functional hierarchies in the ensemble and reliably predicts the eﬀects of perturbing individual neurons or neural clusters. Critically, FCF is robust to noise and can be inferred from the activity of even a small fraction of neurons in the circuit. It thereby permits accurate prediction of circuit perturbation eﬀects with existing recording technologies for the primate brain. We conﬁrm this prediction by recording changes in the prefrontal ensemble spiking activity of alert monkeys in response to single-electrode microstimulation. Our results provide a foundation for using targeted circuit manipulations to develop new brain-machine interfaces or ameliorate cognitive dysfunctions in the human brain.},
	language = {en},
	author = {Nejatbakhsh, Amin and Fumarola, Francesco and Esteki, Saleh and Toyoizumi, Taro and Kiani, Roozbeh and Mazzucato, Luca},
	pages = {40},
	file = {Nejatbakhsh et al. - Predicting perturbation effects from resting state.pdf:/Users/tito/Zotero/storage/HU64FYEZ/Nejatbakhsh et al. - Predicting perturbation effects from resting state.pdf:application/pdf},
}

@article{bertolero_diverse_2017-2,
	title = {The diverse club},
	volume = {8},
	copyright = {2017 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-017-01189-w},
	doi = {10.1038/s41467-017-01189-w},
	abstract = {A complex system can be represented and analyzed as a network, where nodes represent the units of the network and edges represent connections between those units. For example, a brain network represents neurons as nodes and axons between neurons as edges. In many networks, some nodes have a disproportionately high number of edges as well as many edges between each other and are referred to as the “rich club”. In many different networks, the nodes of this club are assumed to support global network integration. Here we show that another set of nodes, which have edges diversely distributed across the network, form a “diverse club”. The diverse club exhibits, to a greater extent than the rich club, properties consistent with an integrative network function—these nodes are more highly interconnected and their edges are more critical for efficient global integration. Finally, these two clubs potentially evolved via distinct selection pressures.},
	language = {en},
	number = {1},
	urldate = {2020-12-17},
	journal = {Nature Communications},
	author = {Bertolero, M. A. and Yeo, B. T. T. and D’Esposito, M.},
	month = nov,
	year = {2017},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1277},
	file = {Bertolero et al_2017_The diverse club.pdf:/Users/tito/Zotero/storage/I4SHS4GY/Bertolero et al_2017_The diverse club.pdf:application/pdf},
}

@article{vyas_computation_2020,
	title = {Computation {Through} {Neural} {Population} {Dynamics}},
	volume = {43},
	issn = {0147-006X},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-neuro-092619-094115},
	doi = {10.1146/annurev-neuro-092619-094115},
	abstract = {Significant experimental, computational, and theoretical work has identified rich structure within the coordinated activity of interconnected neural populations. An emerging challenge now is to uncover the nature of the associated computations, how they are implemented, and what role they play in driving behavior. We term this computation through neural population dynamics. If successful, this framework will reveal general motifs of neural population activity and quantitatively describe how neural population dynamics implement computations necessary for driving goal-directed behavior. Here, we start with a mathematical primer on dynamical systems theory and analytical tools necessary to apply this perspective to experimental data. Next, we highlight some recent discoveries resulting from successful application of dynamical systems. We focus on studies spanning motor control, timing, decision-making, and working memory. Finally, we briefly discuss promising recent lines of investigation and future directions for the computation through neural population dynamics framework.},
	number = {1},
	urldate = {2020-12-18},
	journal = {Annu. Rev. Neurosci.},
	author = {Vyas, Saurabh and Golub, Matthew D. and Sussillo, David and Shenoy, Krishna V.},
	month = jul,
	year = {2020},
	note = {Publisher: Annual Reviews},
	pages = {249--275},
	file = {Full Text PDF:/Users/tito/Zotero/storage/THAI95F3/Vyas et al. - 2020 - Computation Through Neural Population Dynamics.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/A9FYLNW7/annurev-neuro-092619-094115.html:text/html;Snapshot:/Users/tito/Zotero/storage/6BMDNPCM/annurev-neuro-092619-094115.html:text/html;Vyas et al_2020_Computation Through Neural Population Dynamics.pdf:/Users/tito/Zotero/storage/A8RBB5RP/Vyas et al_2020_Computation Through Neural Population Dynamics.pdf:application/pdf},
}

@article{hearne_activity_2020,
	title = {Activity flow underlying abnormalities in brain activations and cognition in schizophrenia},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.12.16.423109v1},
	doi = {10.1101/2020.12.16.423109},
	abstract = {{\textless}p{\textgreater}Cognitive dysfunction is a core feature of many brain disorders such as schizophrenia (SZ), and has been linked to both aberrant brain functional connectivity (FC) and aberrant cognitive brain activations. We propose that aberrant network activity flow over FC pathways leads to altered cognitive activations that produce cognitive dysfunction in SZ. We tested this hypothesis using activity flow mapping - an approach that models the movement of task-related activity between brain regions as a function of FC. Using fMRI data from SZ individuals and healthy controls during a working memory task, we found that activity flow models accurately predict aberrant cognitive activations across multiple brain networks. Within the same framework, we simulated a connectivity-based clinical intervention, predicting specific treatments that normalized brain activations and behavior in independent patients. Our results suggest that dysfunctional task-evoked activity flow is a large-scale network mechanism contributing to the emergence of cognitive dysfunction in SZ.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-12-19},
	journal = {bioRxiv},
	author = {Hearne, Luke J. and Mill, Ravi D. and Keane, Brian P. and Repovs, Grega and Anticevic, Alan and Cole, Michael W.},
	month = dec,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.12.16.423109},
	file = {Hearne et al_2020_Activity flow underlying abnormalities in brain activations and cognition in.pdf:/Users/tito/Zotero/storage/EW6NT65M/Hearne et al_2020_Activity flow underlying abnormalities in brain activations and cognition in.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/8FCWG7YI/2020.12.16.423109v1.html:text/html},
}

@article{sarwar_structure-function_2021,
	title = {Structure-function coupling in the human connectome: {A} machine learning approach},
	volume = {226},
	issn = {1053-8119},
	shorttitle = {Structure-function coupling in the human connectome},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920310946},
	doi = {10.1016/j.neuroimage.2020.117609},
	abstract = {While the function of most biological systems is tightly constrained by their structure, current evidence suggests that coupling between the structure and function of brain networks is relatively modest. We aimed to investigate whether the modest coupling between connectome structure and function is a fundamental property of nervous systems or a limitation of current brain network models. We developed a new deep learning framework to predict an individual's brain function from their structural connectome, achieving prediction accuracies that substantially exceeded state-of-the-art biophysical models (group: R=0.9±0.1, individual: R=0.55±0.1). Crucially, brain function predicted from an individual's structural connectome explained significant inter-individual variation in cognitive performance. Our results suggest that structure-function coupling in human brain networks is substantially tighter than previously suggested. We establish the margin by which current brain network models can be improved and demonstrate how deep learning can facilitate investigation of relations between brain function and behavior.},
	language = {en},
	urldate = {2020-12-21},
	journal = {NeuroImage},
	author = {Sarwar, T. and Tian, Y. and Yeo, B. T. T. and Ramamohanarao, K. and Zalesky, A.},
	month = feb,
	year = {2021},
	pages = {117609},
	file = {Sarwar et al_2021_Structure-function coupling in the human connectome.pdf:/Users/tito/Zotero/storage/ELN8KBV2/Sarwar et al_2021_Structure-function coupling in the human connectome.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/K6Z72NHD/S1053811920310946.html:text/html},
}

@article{lacosse_jumping_2020,
	title = {Jumping over {Baselines} with {New} {Methods} to {Predict} {Activation} {Maps} from {Resting}-state {fMRI}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.12.15.417675v1},
	doi = {10.1101/2020.12.15.417675},
	abstract = {{\textless}p{\textgreater}Cognitive fMRI research primarily relies on task-averaged responses over many subjects to describe general principles of brain function. Nonetheless, there exists a large variability between subjects that is also reflected in spontaneous brain activity as measured by resting state fMRI (rsfMRI). Leveraging this fact, several recent studies have therefore aimed at predicting task activation from rsfMRI using various machine learning methods within a growing literature on 9connectome fingerprinting9. In reviewing these results, we found lack of an evaluation against robust baselines that reliably supports a novelty of predictions for this task. On closer examination to reported methods, we found most underperform against trivial baseline model performances based on massive group averaging when whole-cortex prediction is considered. Here we present a modification to published methods that remedies this problem to large extent. Our proposed modification is based on a single-vertex approach that replaces commonly used brain parcellations. We further provide a summary of this model evaluation by characterizing empirical properties of where prediction for this task appears possible, explaining why some predictions largely fail for certain targets. Finally, with these empirical observations we investigate whether individual prediction scores explain individual behavioral differences in a task.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-12-29},
	journal = {bioRxiv},
	author = {Lacosse, Eric and Scheffler, Klaus and Lohmann, Gabriele and Martius, Georg},
	month = dec,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.12.15.417675},
	file = {Lacosse et al_2020_Jumping over Baselines with New Methods to Predict Activation Maps from.pdf:/Users/tito/Zotero/storage/D7JMJW8S/Lacosse et al_2020_Jumping over Baselines with New Methods to Predict Activation Maps from.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3S2TB9JA/2020.12.15.html:text/html},
}

@article{frankland_concepts_2020,
	title = {Concepts and {Compositionality}: {In} {Search} of the {Brain}'s {Language} of {Thought}},
	volume = {71},
	issn = {0066-4308, 1545-2085},
	shorttitle = {Concepts and {Compositionality}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-psych-122216-011829},
	doi = {10.1146/annurev-psych-122216-011829},
	abstract = {Imagine Genghis Khan, Aretha Franklin, and the Cleveland Cavaliers performing an opera on Maui. This silly sentence makes a serious point: As humans, we can flexibly generate and comprehend an unbounded number of complex ideas. Little is known, however, about how our brains accomplish this. Here we assemble clues from disparate areas of cognitive neuroscience, integrating recent research on language, memory, episodic simulation, and computational models of high-level cognition. Our review is framed by Fodor’s classic language of thought hypothesis, according to which our minds employ an amodal, language-like system for combining and recombining simple concepts to form more complex thoughts. Here, we highlight emerging work on combinatorial processes in the brain and consider this work’s relation to the language of thought. We review evidence for distinct, but complementary, contributions of map-like representations in subregions of the default mode network and sentence-like representations of conceptual relations in regions of the temporal and prefrontal cortex.},
	language = {en},
	number = {1},
	urldate = {2020-12-29},
	journal = {Annual Review of Psychology},
	author = {Frankland, Steven M. and Greene, Joshua D.},
	month = jan,
	year = {2020},
	pages = {273--303},
	file = {Frankland and Greene - 2020 - Concepts and Compositionality In Search of the Br.pdf:/Users/tito/Zotero/storage/5Y6Q2NNJ/Frankland and Greene - 2020 - Concepts and Compositionality In Search of the Br.pdf:application/pdf},
}

@article{perich_inferring_2020,
	title = {Inferring brain-wide interactions using data-constrained recurrent neural network models},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.12.18.423348v1},
	doi = {10.1101/2020.12.18.423348},
	abstract = {{\textless}p{\textgreater}Behavior arises from the coordinated activity of numerous anatomically and functionally distinct brain regions. Modern experimental tools allow unprecedented access to large neural populations spanning many interacting regions brain-wide. Yet, understanding such large-scale datasets necessitates both scalable computational models to extract meaningful features of inter-region communication and principled theories to interpret those features. Here, we introduce Current-Based Decomposition (CURBD), an approach for inferring brain-wide interactions using data-constrained recurrent neural network models that directly reproduce experimentally-obtained neural data. CURBD leverages the functional interactions inferred by such models to reveal directional currents between multiple brain regions. We first show that CURBD accurately isolates inter-region currents in simulated networks with known dynamics. We then apply CURBD to multi-region neural recordings obtained from mice during running, macaques during Pavlovian conditioning, and humans during memory retrieval to demonstrate the widespread applicability of CURBD to untangle brain-wide interactions underlying behavior from a variety of neural datasets.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-12-29},
	journal = {bioRxiv},
	author = {Perich, Matthew G. and Arlt, Charlotte and Soares, Sofia and Young, Megan E. and Mosher, Clayton P. and Minxha, Juri and Carter, Eugene and Rutishauser, Ueli and Rudebeck, Peter H. and Harvey, Christopher D. and Rajan, Kanaka},
	month = dec,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.12.18.423348},
	file = {Perich et al_2020_Inferring brain-wide interactions using data-constrained recurrent neural.pdf:/Users/tito/Zotero/storage/BS4JTJYM/Perich et al_2020_Inferring brain-wide interactions using data-constrained recurrent neural.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3U852TXF/2020.12.18.423348v1.html:text/html;Snapshot:/Users/tito/Zotero/storage/JP6XV7F8/2020.12.18.423348v1.html:text/html},
}

@article{baron_evidence_2011,
	title = {Evidence for conceptual combination in the left anterior temporal lobe},
	volume = {55},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811911001029},
	doi = {10.1016/j.neuroimage.2011.01.066},
	abstract = {Conceptual combination allows for the construction of an infinite number of complex ideas from a finite base. The anterior temporal lobes appear to be important for the process of conceptual combination. In a previous study (Baron et al., 2010) we showed that the neural representation of complex concepts (e.g., young man) in the left anterior temporal lobe is additive. Specifically, in that region, the representation of a complex concept can be predicted by the superimposition of the voxel-wise neural representations of its constituent concepts (e.g., young+man). However, this finding could be the result of phonological similarity or the simple co-activation of constituent concepts. Here we use concepts that are only related semantically: boy, girl, woman, man, female, male, child, and adult. The neural representation for each concept was evoked through a visual categorization task. Subsequent brain maps were then analyzed using a searchlight analysis meant to show areas of the cortex where multiplicative (as well as additive) conceptual combination occurred (e.g., areas in which activations for boy correlated with the product of the activations for male and child). Across all participants, the left anterior temporal lobe showed such an effect.},
	language = {en},
	number = {4},
	urldate = {2020-12-31},
	journal = {NeuroImage},
	author = {Baron, Sean G. and Osherson, Daniel},
	month = apr,
	year = {2011},
	keywords = {fMRI, Face, Conceptual combination, Pattern analysis, Searchlight, Semantic},
	pages = {1847--1852},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/2EA57DL2/S1053811911001029.html:text/html},
}

@book{eliasmith_how_2013,
	title = {How to build a brain: {A} neural architecture for biological cognition},
	shorttitle = {How to build a brain},
	publisher = {Oxford University Press},
	author = {Eliasmith, Chris},
	year = {2013},
	file = {Eliasmith_2013_How to build a brain.pdf:/Users/tito/Zotero/storage/4D3LWP3C/Eliasmith_2013_How to build a brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MLZCXQ2H/books.html:text/html},
}

@article{ju_network_2020,
	title = {Network structure of cascading neural systems predicts stimulus propagation and recovery},
	volume = {17},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2552/abbff1},
	doi = {10.1088/1741-2552/abbff1},
	abstract = {Objective. Many neural systems display spontaneous, spatiotemporal patterns of neural activity that are crucial for information processing. While these cascading patterns presumably arise from the underlying network of synaptic connections between neurons, the precise contribution of the network’s local and global connectivity to these patterns and information processing remains largely unknown. Approach. Here, we demonstrate how network structure supports information processing through network dynamics in empirical and simulated spiking neurons using mathematical tools from linear systems theory, network control theory, and information theory. Main results. In particular, we show that activity, and the information that it contains, travels through cycles in real and simulated networks. Significance. Broadly, our results demonstrate how cascading neural networks could contribute to cognitive faculties that require lasting activation of neuronal patterns, such as working memory or attention.},
	language = {en},
	number = {5},
	urldate = {2021-01-04},
	journal = {J. Neural Eng.},
	author = {Ju, Harang and Kim, Jason Z. and Beggs, John M. and Bassett, Danielle S.},
	month = nov,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {056045},
	file = {Ju et al_2020_Network structure of cascading neural systems predicts stimulus propagation and.pdf:/Users/tito/Zotero/storage/WJ8U5HVB/Ju et al_2020_Network structure of cascading neural systems predicts stimulus propagation and.pdf:application/pdf},
}

@article{king_functional_2019,
	title = {Functional boundaries in the human cerebellum revealed by a multi-domain task battery},
	volume = {22},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0436-x},
	doi = {10.1038/s41593-019-0436-x},
	abstract = {There is compelling evidence that the human cerebellum is engaged in a wide array of motor and cognitive tasks. A fundamental question centers on whether the cerebellum is organized into distinct functional subregions. To address this question, we employed a rich task battery designed to tap into a broad range of cognitive processes. During four functional MRI sessions, participants performed a battery of 26 diverse tasks comprising 47 unique conditions. Using the data from this multi-domain task battery, we derived a comprehensive functional parcellation of the cerebellar cortex and evaluated it by predicting functional boundaries in a novel set of tasks. The new parcellation successfully identified distinct functional subregions, providing significant improvements over existing parcellations derived from task-free data. Lobular boundaries, commonly used to summarize functional data, did not coincide with functional subdivisions. The new parcellation provides a functional atlas to guide future neuroimaging studies.},
	language = {en},
	number = {8},
	urldate = {2021-01-04},
	journal = {Nature Neuroscience},
	author = {King, Maedbh and Hernandez-Castillo, Carlos R. and Poldrack, Russell A. and Ivry, Richard B. and Diedrichsen, Jörn},
	month = aug,
	year = {2019},
	note = {Number: 8
Publisher: Nature Publishing Group},
	pages = {1371--1378},
	file = {King et al_2019_Functional boundaries in the human cerebellum revealed by a multi-domain task.pdf:/Users/tito/Zotero/storage/3ZUGVMKS/King et al_2019_Functional boundaries in the human cerebellum revealed by a multi-domain task.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BDTQV3BT/s41593-019-0436-x.html:text/html;Snapshot:/Users/tito/Zotero/storage/ISNDGPE2/s41593-019-0436-x.html:text/html},
}

@article{lin_differential_2020,
	title = {Differential {Covariance}: {A} {New} {Method} to {Estimate} {Functional} {Connectivity} in {fMRI}},
	volume = {32},
	issn = {0899-7667},
	shorttitle = {Differential {Covariance}},
	url = {https://doi.org/10.1162/neco_a_01323},
	doi = {10.1162/neco_a_01323},
	abstract = {Measuring functional connectivity from fMRI recordings is important in understanding processing in cortical networks. However, because the brain's connection pattern is complex, currently used methods are prone to producing false functional connections. We introduce differential covariance analysis, a new method that uses derivatives of the signal for estimating functional connectivity. We generated neural activities from dynamical causal modeling and a neural network of Hodgkin-Huxley neurons and then converted them to hemodynamic signals using the forward balloon model. The simulated fMRI signals, together with the ground-truth connectivity pattern, were used to benchmark our method with other commonly used methods. Differential covariance achieved better results in complex network simulations. This new method opens an alternative way to estimate functional connectivity.},
	number = {12},
	urldate = {2021-01-05},
	journal = {Neural Computation},
	author = {Lin, Tiger W. and Chen, Yusi and Bukhari, Qasim and Krishnan, Giri P. and Bazhenov, Maxim and Sejnowski, Terrence J.},
	month = sep,
	year = {2020},
	note = {Publisher: MIT Press},
	pages = {2389--2421},
	file = {Lin et al_2020_Differential Covariance.pdf:/Users/tito/Zotero/storage/SVJXJ7WW/Lin et al_2020_Differential Covariance.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/YVN5J4LZ/neco_a_01323.html:text/html},
}

@article{nozari_is_2020,
	title = {Is the brain macroscopically linear? {A} system identification of resting state dynamics},
	shorttitle = {Is the brain macroscopically linear?},
	url = {http://arxiv.org/abs/2012.12351},
	abstract = {A central challenge in the computational modeling of neural dynamics is the trade-off between accuracy and simplicity. At the level of individual neurons, nonlinear dynamics are both experimentally established and essential for neuronal functioning. An implicit assumption has thus formed that an accurate computational model of whole-brain dynamics must also be highly nonlinear, whereas linear models may provide a first-order approximation. Here, we provide a rigorous and data-driven investigation of this hypothesis at the level of whole-brain blood-oxygen-level-dependent (BOLD) and macroscopic field potential dynamics by leveraging the theory of system identification. Using functional MRI (fMRI) and intracranial EEG (iEEG), we model the resting state activity of 700 subjects in the Human Connectome Project (HCP) and 122 subjects from the Restoring Active Memory (RAM) project using state-of-the-art linear and nonlinear model families. We assess relative model fit using predictive power, computational complexity, and the extent of residual dynamics unexplained by the model. Contrary to our expectations, linear auto-regressive models achieve the best measures across all three metrics, eliminating the trade-off between accuracy and simplicity. To understand and explain this linearity, we highlight four properties of macroscopic neurodynamics which can counteract or mask microscopic nonlinear dynamics: averaging over space, averaging over time, observation noise, and limited data samples. Whereas the latter two are technological limitations and can improve in the future, the former two are inherent to aggregated macroscopic brain activity. Our results, together with the unparalleled interpretability of linear models, can greatly facilitate our understanding of macroscopic neural dynamics and the principled design of model-based interventions for the treatment of neuropsychiatric disorders.},
	urldate = {2021-01-07},
	journal = {arXiv:2012.12351 [cs, eess, math, q-bio]},
	author = {Nozari, Erfan and Stiso, Jennifer and Caciagli, Lorenzo and Cornblath, Eli J. and He, Xiaosong and Bertolero, Maxwell A. and Mahadevan, Arun S. and Pappas, George J. and Bassett, Danielle S.},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.12351},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Mathematics - Dynamical Systems, Electrical Engineering and Systems Science - Signal Processing, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/MF3WX9MZ/2012.html:text/html;Nozari et al_2020_Is the brain macroscopically linear.pdf:/Users/tito/Zotero/storage/6XVJ8PSB/Nozari et al_2020_Is the brain macroscopically linear.pdf:application/pdf},
}

@article{yang_artificial_2020-1,
	title = {Artificial {Neural} {Networks} for {Neuroscientists}: {A} {Primer}},
	volume = {107},
	issn = {0896-6273},
	shorttitle = {Artificial {Neural} {Networks} for {Neuroscientists}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627320307054},
	doi = {10.1016/j.neuron.2020.09.005},
	abstract = {Artificial neural networks (ANNs) are essential tools in machine learning that have drawn increasing attention in neuroscience. Besides offering powerful techniques for data analysis, ANNs provide a new approach for neuroscientists to build models for complex behaviors, heterogeneous neural activity, and circuit connectivity, as well as to explore optimization in neural systems, in ways that traditional models are not designed for. In this pedagogical Primer, we introduce ANNs and demonstrate how they have been fruitfully deployed to study neuroscientific questions. We first discuss basic concepts and methods of ANNs. Then, with a focus on bringing this mathematical framework closer to neurobiology, we detail how to customize the analysis, structure, and learning of ANNs to better address a wide range of challenges in brain research. To help readers garner hands-on experience, this Primer is accompanied with tutorial-style code in PyTorch and Jupyter Notebook, covering major topics.},
	language = {en},
	number = {6},
	urldate = {2021-01-07},
	journal = {Neuron},
	author = {Yang, Guangyu Robert and Wang, Xiao-Jing},
	month = sep,
	year = {2020},
	pages = {1048--1070},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/SNBAMIC4/S0896627320307054.html:text/html;Yang_Wang_2020_Artificial Neural Networks for Neuroscientists.pdf:/Users/tito/Zotero/storage/N84UUHSY/Yang_Wang_2020_Artificial Neural Networks for Neuroscientists.pdf:application/pdf},
}

@article{ehrlich_psychrnn_2020,
	title = {{PsychRNN}: {An} {Accessible} and {Flexible} {Python} {Package} for {Training} {Recurrent} {Neural} {Network} {Models} on {Cognitive} {Tasks}},
	copyright = {Copyright © 2020 Ehrlich et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
	issn = {2373-2822},
	shorttitle = {{PsychRNN}},
	url = {https://www.eneuro.org/content/early/2020/12/10/ENEURO.0427-20.2020},
	doi = {10.1523/ENEURO.0427-20.2020},
	abstract = {Task-trained artificial recurrent neural networks (RNNs) provide a computational modeling framework of increasing interest and application in computational, systems, and cognitive neuroscience. RNNs can be trained, using deep learning methods, to perform cognitive tasks used in animal and human experiments, and can be studied to investigate potential neural representations and circuit mechanisms underlying cognitive computations and behavior. Widespread application of these approaches within neuroscience has been limited by technical barriers in use of deep learning software packages to train network models. Here we introduce PsychRNN, an accessible, flexible, and extensible Python package for training RNNs on cognitive tasks. Our package is designed for accessibility, for researchers to define tasks and train RNN models using only Python and NumPy without requiring knowledge of deep learning software. The training backend is based on TensorFlow and is readily extensible for researchers with TensorFlow knowledge to develop projects with additional customization. PsychRNN implements a number of specialized features to support applications in systems and cognitive neuroscience. Users can impose neurobiologically relevant constraints on synaptic connectivity patterns. Furthermore, specification of cognitive tasks has a modular structure, which facilitates parametric variation of task demands to examine their impact on model solutions. PsychRNN also enables task shaping during training, or curriculum learning, in which tasks are adjusted in closed-loop based on performance. Shaping is ubiquitous in training of animals in cognitive tasks, and PsychRNN allows investigation of how shaping trajectories impact learning and model solutions. Overall, the PsychRNN framework facilitates application of trained RNNs in neuroscience research.
Significance Statement Artificial recurrent neural network (RNN) modeling is of increasing interest within computational, systems, and cognitive neuroscience, yet its proliferation as a computational tool within the field has been limited due to technical barriers in use of specialized deep-learning software. PsychRNN provides an accessible, flexible, and powerful framework for training RNN models on cognitive tasks. Users can define tasks and train models using the Python-based interface which enables RNN modeling studies without requiring user knowledge of deep learning software or comprehensive understanding of RNN training. PsychRNN’s modular structure facilitates task specification and incorporation of neurobiological constraints, and supports extensibility for users with deep learning expertise. PsychRNN’s framework for RNN modeling will increase accessibility and reproducibility of this approach across neuroscience subfields.},
	language = {en},
	urldate = {2021-01-07},
	journal = {eNeuro},
	author = {Ehrlich, Daniel B. and Stone, Jasmine T. and Brandfonbrener, David and Atanasov, Alexander and Murray, John D.},
	month = dec,
	year = {2020},
	pmid = {33328247},
	note = {Publisher: Society for Neuroscience
Section: Open Source Tools and Methods},
	keywords = {Deep learning, Training, Cognitive task, Computational model, Recurrent neural network},
	file = {Ehrlich et al_2020_PsychRNN.pdf:/Users/tito/Zotero/storage/8FXYKVF6/Ehrlich et al_2020_PsychRNN.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HHU5HLUC/ENEURO.0427-20.html:text/html},
}

@article{murray_biophysical_2018,
	series = {Computational {Methods} and {Modeling} in {Psychiatry}},
	title = {Biophysical {Modeling} of {Large}-{Scale} {Brain} {Dynamics} and {Applications} for {Computational} {Psychiatry}},
	volume = {3},
	issn = {2451-9022},
	url = {http://www.sciencedirect.com/science/article/pii/S2451902218301782},
	doi = {10.1016/j.bpsc.2018.07.004},
	abstract = {Noninvasive neuroimaging has revolutionized the study of the organization of the human brain and how its structure and function are altered in psychiatric disorders. A critical explanatory gap lies in our mechanistic understanding of how systems-level neuroimaging biomarkers emerge from underlying synaptic-level perturbations associated with a disease state. We describe an emerging computational psychiatry approach leveraging biophysically based computational models of large-scale brain dynamics and their potential integration with clinical and pharmacological neuroimaging. In particular, we focus on neural circuit models, which describe how patterns of functional connectivity observed in resting-state functional magnetic resonance imaging emerge from neural dynamics shaped by inter-areal interactions through underlying structural connectivity defining long-range projections. We highlight the importance of local circuit physiological dynamics, in combination with structural connectivity, in shaping the emergent functional connectivity. Furthermore, heterogeneity of local circuit properties across brain areas, which impacts large-scale dynamics, may be critical for modeling whole-brain phenomena and alterations in psychiatric disorders and pharmacological manipulation. Finally, we discuss important directions for future model development and biophysical extensions, which will expand their utility to link clinical neuroimaging to neurobiological mechanisms.},
	language = {en},
	number = {9},
	urldate = {2021-01-08},
	journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	author = {Murray, John D. and Demirtaş, Murat and Anticevic, Alan},
	month = sep,
	year = {2018},
	keywords = {Resting-state, Functional connectivity, Neuroimaging, Schizophrenia, Computational model, Transcriptomics},
	pages = {777--787},
	file = {Murray et al_2018_Biophysical Modeling of Large-Scale Brain Dynamics and Applications for.pdf:/Users/tito/Zotero/storage/KUM8V444/Murray et al_2018_Biophysical Modeling of Large-Scale Brain Dynamics and Applications for.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/ELK8KXCU/S2451902218301782.html:text/html},
}

@article{kikumoto_role_2020,
	title = {The {Role} of {Conjunctive} {Representations} in {Regulating} {Actions}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.04.30.070227v2},
	doi = {10.1101/2020.04.30.070227},
	abstract = {{\textless}p{\textgreater}Action selection appears to rely on conjunctive representations that nonlinearly integrate task- relevant features (Kikumoto \&amp; Mayr, 2020). We test here the corollary hypothesis that such representations are also intricately involved during attempts to stop an action: a key aspect of action regulation. We tracked both conjunctive representations and those of constituent rule, stimulus, or response features through trial-by-trial representational similarity analysis of the EEG signal in a combined, rule-selection and stop-signal paradigm. Across two experiments with student participants (N = 57), we found (a) that the strength of decoded conjunctive representations prior to the stop signal uniquely predicted trial-by-trial stopping success (Exp. 1) and (b) that these representations were selectively suppressed following the onset of the stop signal (Exp. 1 and 2). We conclude that conjunctive representations are key to successful action execution and therefore need to be suppressed when an intended action is no longer appropriate.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-11},
	journal = {bioRxiv},
	author = {Kikumoto, Atsushi and Mayr, Ulrich},
	month = dec,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.04.30.070227},
	file = {Kikumoto_Mayr_2020_The Role of Conjunctive Representations in Regulating Actions.pdf:/Users/tito/Zotero/storage/WK4RTT8S/Kikumoto_Mayr_2020_The Role of Conjunctive Representations in Regulating Actions.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MNEGJ9R5/2020.04.30.html:text/html},
}

@article{gong_phenotype_2020,
	title = {Phenotype {Discovery} from {Population} {Brain} {Imaging}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.03.05.973172v1},
	doi = {10.1101/2020.03.05.973172},
	abstract = {{\textless}p{\textgreater}Neuroimaging allows for the non-invasive study of the brain in rich detail. Data-driven discovery of patterns of population variability in the brain has the potential to be extremely valuable for early disease diagnosis and understanding the brain. The resulting patterns can be used as imaging-derived phenotypes (IDPs), and may complement existing expert-curated IDPs. However, population datasets, comprising many different structural and functional imaging modalities from thousands of subjects, provide a computational challenge not previously addressed. Here, for the first time, a multimodal independent component analysis approach is presented that is scalable for data fusion of voxel-level neuroimaging data in the full UK Biobank (UKB) dataset, that will soon reach 100,000 imaged subjects. This new computational approach can estimate modes of population variability that enhance the ability to predict thousands of phenotypic and behavioural variables using data from UKB and the Human Connectome Project. A high-dimensional decomposition achieved improved predictive power compared with widely-used analysis strategies, single-modality decompositions and existing IDPs. In UKB data (14,503 subjects with 47 different data modalities), many interpretable associations with non-imaging phenotypes were identified, including multimodal spatial maps related to fluid intelligence, handedness and disease, in some cases where IDP-based approaches failed.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-12},
	journal = {bioRxiv},
	author = {Gong, Weikang and Beckmann, Christian F. and Smith, Stephen M.},
	month = mar,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.03.05.973172},
	file = {Gong et al_2020_Phenotype Discovery from Population Brain Imaging.pdf:/Users/tito/Zotero/storage/P7UA8FVL/Gong et al_2020_Phenotype Discovery from Population Brain Imaging.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GDTLP9HI/2020.03.05.973172v1.html:text/html;Snapshot:/Users/tito/Zotero/storage/MF4WWD7I/2020.03.05.973172v1.html:text/html},
}

@article{helmer_stability_2020,
	title = {On stability of {Canonical} {Correlation} {Analysis} and {Partial} {Least} {Squares} with application to brain-behavior associations},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.08.25.265546v1},
	doi = {10.1101/2020.08.25.265546},
	abstract = {{\textless}p{\textgreater}Associations between high-dimensional datasets, each comprising many features, can be discovered through multivariate statistical methods, like Canonical Correlation Analysis (CCA) or Partial Least Squares (PLS). CCA and PLS are widely used methods which reveal which features carry the association. Despite the longevity and popularity of CCA/PLS approaches, their application to high-dimensional datasets raises critical questions about the reliability of CCA/PLS solutions. In particular, overfitting can produce solutions that are not stable across datasets, which severely hinders their interpretability and generalizability. To study these issues, we developed a generative model to simulate synthetic datasets with multivariate associations, parameterized by feature dimensionality, data variance structure, and assumed latent association strength. We found that resulting CCA/PLS associations could be highly inaccurate when the number of samples per feature is relatively small. For PLS, the profiles of feature weights exhibit detrimental bias toward leading principal component axes. We confirmed these model trends in state-ofthe-art datasets containing neuroimaging and behavioral measurements in large numbers of subjects, namely the Human Connectome Project (\textit{n} ≈ 1000) and UK Biobank (\textit{n} = 20000), where we found that only the latter comprised enough samples to obtain stable estimates. Analysis of the neuroimaging literature using CCA to map brain-behavior relationships revealed that the commonly employed sample sizes yield unstable CCA solutions. Our generative modeling framework provides a calculator of dataset properties required for stable estimates. Collectively, our study characterizes dataset properties needed to limit the potentially detrimental effects of overfitting on stability of CCA/PLS solutions, and provides practical recommendations for future studies.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Significance Statement{\textless}/h3{\textgreater} {\textless}p{\textgreater}Scientific studies often begin with an observed association between different types of measures. When datasets comprise large numbers of features, multivariate approaches such as canonical correlation analysis (CCA) and partial least squares (PLS) are often used. These methods can reveal the profiles of features that carry the optimal association. We developed a generative model to simulate data, and characterized how obtained feature profiles can be unstable, which hinders interpretability and generalizability, unless a sufficient number of samples is available to estimate them. We determine sufficient sample sizes, depending on properties of datasets. We also show that these issues arise in neuroimaging studies of brain-behavior relationships. We provide practical guidelines and computational tools for future CCA and PLS studies.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-12},
	journal = {bioRxiv},
	author = {Helmer, Markus and Warrington, Shaun and Mohammadi-Nejad, Ali-Reza and Ji, Jie Lisa and Howell, Amber and Rosand, Benjamin and Anticevic, Alan and Sotiropoulos, Stamatios N. and Murray, John D.},
	month = aug,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.08.25.265546},
	file = {Helmer et al_2020_On stability of Canonical Correlation Analysis and Partial Least Squares with.pdf:/Users/tito/Zotero/storage/NZ7INZJD/Helmer et al_2020_On stability of Canonical Correlation Analysis and Partial Least Squares with.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/S35BELY9/2020.08.25.265546v1.html:text/html},
}

@misc{noauthor_conjunctive_nodate,
	title = {Conjunctive representations in learning and memory: {Principles} of cortical and hippocampal function. - {PsycNET}},
	shorttitle = {Conjunctive representations in learning and memory},
	url = {/doiLanding?doi=10.1037%2F0033-295X.108.2.311},
	abstract = {APA PsycNet DoiLanding page},
	language = {en},
	urldate = {2021-01-12},
	file = {Snapshot:/Users/tito/Zotero/storage/R53KLL4T/doiLanding.html:text/html},
}

@article{frank_interactions_2001,
	title = {Interactions between frontal cortex and basal ganglia in working memory: {A} computational model},
	volume = {1},
	issn = {1531-135X},
	shorttitle = {Interactions between frontal cortex and basal ganglia in working memory},
	url = {https://doi.org/10.3758/CABN.1.2.137},
	doi = {10.3758/CABN.1.2.137},
	abstract = {The frontal cortex and the basal ganglia interact via a relatively well understood and elaborate system of interconnections. In the context of motor function, these interconnections can be understood as disinhibiting, or “releasing the brakes,” on frontal motor action plans: The basal ganglia detect appropriate contexts for performing motor actions and enable the frontal cortex to execute such actions at the appropriate time. We build on this idea in the domain of working memory through the use of computational neural network models of this circuit. In our model, the frontal cortex exhibits robust active maintenance, whereas the basal ganglia contribute a selective, dynamic gating function that enables frontal memory representations to be rapidly updated in a task-relevant manner. We apply the model to a novel version of the continuous performance task that requires subroutine-like selective working memory updating and compare and contrast our model with other existing models and theories of frontal-cortex-basal-ganglia interactions.},
	language = {en},
	number = {2},
	urldate = {2021-01-12},
	journal = {Cognitive, Affective, \& Behavioral Neuroscience},
	author = {Frank, Michael J. and Loughry, Bryan and O’Reilly, Randall C.},
	month = jun,
	year = {2001},
	pages = {137--160},
	file = {Frank et al_2001_Interactions between frontal cortex and basal ganglia in working memory.pdf:/Users/tito/Zotero/storage/WVMA4S8M/Frank et al_2001_Interactions between frontal cortex and basal ganglia in working memory.pdf:application/pdf},
}

@article{hazy_towards_2007,
	title = {Towards an executive without a homunculus: computational models of the prefrontal cortex/basal ganglia system},
	volume = {362},
	shorttitle = {Towards an executive without a homunculus},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2007.2055},
	doi = {10.1098/rstb.2007.2055},
	abstract = {The prefrontal cortex (PFC) has long been thought to serve as an ‘executive’ that controls the selection of actions and cognitive functions more generally. However, the mechanistic basis of this executive function has not been clearly specified often amounting to a homunculus. This paper reviews recent attempts to deconstruct this homunculus by elucidating the precise computational and neural mechanisms underlying the executive functions of the PFC. The overall approach builds upon existing mechanistic models of the basal ganglia (BG) and frontal systems known to play a critical role in motor control and action selection, where the BG provide a ‘Go’ versus ‘NoGo’ modulation of frontal action representations. In our model, the BG modulate working memory representations in prefrontal areas to support more abstract executive functions. We have developed a computational model of this system that is capable of developing human-like performance on working memory and executive control tasks through trial-and-error learning. This learning is based on reinforcement learning mechanisms associated with the midbrain dopaminergic system and its activation via the BG and amygdala. Finally, we briefly describe various empirical tests of this framework.},
	number = {1485},
	urldate = {2021-01-12},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Hazy, Thomas E and Frank, Michael J and O'Reilly, Randall C},
	month = sep,
	year = {2007},
	note = {Publisher: Royal Society},
	pages = {1601--1613},
	file = {Hazy et al_2007_Towards an executive without a homunculus.pdf:/Users/tito/Zotero/storage/J2FXG8Q4/Hazy et al_2007_Towards an executive without a homunculus.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/X7HTED9E/rstb.2007.html:text/html},
}

@article{van_de_schoot_bayesian_2021,
	title = {Bayesian statistics and modelling},
	volume = {1},
	copyright = {2021 Springer Nature Limited},
	issn = {2662-8449},
	url = {https://www.nature.com/articles/s43586-020-00001-2},
	doi = {10.1038/s43586-020-00001-2},
	abstract = {Bayesian statistics is an approach to data analysis based on Bayes’ theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
	language = {en},
	number = {1},
	urldate = {2021-01-18},
	journal = {Nature Reviews Methods Primers},
	author = {van de Schoot, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and Märtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
	month = jan,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--26},
	file = {Snapshot:/Users/tito/Zotero/storage/343QVX9H/s43586-020-00001-2.html:text/html;van de Schoot et al_2021_Bayesian statistics and modelling.pdf:/Users/tito/Zotero/storage/SV4KECZP/van de Schoot et al_2021_Bayesian statistics and modelling.pdf:application/pdf},
}

@article{keshtkaran_large-scale_2021,
	title = {A large-scale neural network training framework for generalized estimation of single-trial population dynamics},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.01.13.426570v1},
	doi = {10.1101/2021.01.13.426570},
	abstract = {{\textless}p{\textgreater}Large-scale recordings of neural activity are providing new opportunities to study network-level dynamics. However, the sheer volume of data and its dynamical complexity are critical barriers to uncovering and interpreting these dynamics. Deep learning methods are a promising approach due to their ability to uncover meaningful relationships from large, complex, and noisy datasets. When applied to high-D spiking data from motor cortex (M1) during stereotyped behaviors, they offer improvements in the ability to uncover dynamics and their relation to subjects9 behaviors on a millisecond timescale. However, applying such methods to less-structured behaviors, or in brain areas that are not well-modeled by autonomous dynamics, is far more challenging, because deep learning methods often require careful hand-tuning of complex model hyperparameters (HPs). Here we demonstrate AutoLFADS, a large-scale, automated model-tuning framework that can characterize dynamics in diverse brain areas without regard to behavior. AutoLFADS uses distributed computing to train dozens of models simultaneously while using evolutionary algorithms to tune HPs in a completely unsupervised way. This enables accurate inference of dynamics out-of-the-box on a variety of datasets, including data from M1 during stereotyped and free-paced reaching, somatosensory cortex during reaching with perturbations, and frontal cortex during cognitive timing tasks. We present a cloud software package and comprehensive tutorials that enable new users to apply the method without needing dedicated computing resources.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-19},
	journal = {bioRxiv},
	author = {Keshtkaran, Mohammad Reza and Sedler, Andrew R. and Chowdhury, Raeed H. and Tandon, Raghav and Basrai, Diya and Nguyen, Sarah L. and Sohn, Hansem and Jazayeri, Mehrdad and Miller, Lee E. and Pandarinath, Chethan},
	month = jan,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.01.13.426570},
	file = {Keshtkaran et al_2021_A large-scale neural network training framework for generalized estimation of.pdf:/Users/tito/Zotero/storage/N37KDAD4/Keshtkaran et al_2021_A large-scale neural network training framework for generalized estimation of.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TUP9HYIE/2021.01.13.html:text/html},
}

@article{kucyi_intracranial_2018,
	title = {Intracranial {Electrophysiology} {Reveals} {Reproducible} {Intrinsic} {Functional} {Connectivity} within {Human} {Brain} {Networks}},
	volume = {38},
	copyright = {Copyright © 2018 the authors 0270-6474/18/384231-13\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/38/17/4230},
	doi = {10.1523/JNEUROSCI.0217-18.2018},
	abstract = {Evidence for intrinsic functional connectivity (FC) within the human brain is largely from neuroimaging studies of hemodynamic activity. Data are lacking from anatomically precise electrophysiological recordings in the most widely studied nodes of human brain networks. Here we used a combination of fMRI and electrocorticography (ECoG) in five human neurosurgical patients with electrodes in the canonical “default” (medial prefrontal and posteromedial cortex), “dorsal attention” (frontal eye fields and superior parietal lobule), and “frontoparietal control” (inferior parietal lobule and dorsolateral prefrontal cortex) networks. In this unique cohort, simultaneous intracranial recordings within these networks were anatomically matched across different individuals. Within each network and for each individual, we found a positive, and reproducible, spatial correlation for FC measures obtained from resting-state fMRI and separately recorded ECoG in the same brains. This relationship was reliably identified for electrophysiological FC based on slow ({\textless}1 Hz) fluctuations of high-frequency broadband (70–170 Hz) power, both during wakeful rest and sleep. A similar FC organization was often recovered when using lower-frequency (1–70 Hz) power, but anatomical specificity and consistency were greatest for the high-frequency broadband range. An interfrequency comparison of fluctuations in FC revealed that high and low-frequency ranges often temporally diverged from one another, suggesting that multiple neurophysiological sources may underlie variations in FC. Together, our work offers a generalizable electrophysiological basis for intrinsic FC and its dynamics across individuals, brain networks, and behavioral states.
SIGNIFICANCE STATEMENT The study of human brain networks during wakeful “rest”, largely with fMRI, is now a major focus in both cognitive and clinical neuroscience. However, little is known about the neurophysiology of these networks and their dynamics. We studied neural activity during wakeful rest and sleep within neurosurgical patients with directly implanted electrodes. We found that network activity patterns showed striking similarities between fMRI and direct recordings in the same brains. With improved resolution of direct recordings, we also found that networks were best characterized with specific activity frequencies and that different frequencies show different profiles of within-network activity over time. Our work clarifies how networks spontaneously organize themselves across individuals, brain networks, and behavioral states.},
	language = {en},
	number = {17},
	urldate = {2021-01-19},
	journal = {J. Neurosci.},
	author = {Kucyi, Aaron and Schrouff, Jessica and Bickel, Stephan and Foster, Brett L. and Shine, James M. and Parvizi, Josef},
	month = apr,
	year = {2018},
	pmid = {29626167},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {default mode network, dynamic functional connectivity, resting-state fMRI, dorsal attention network, electrocorticography},
	pages = {4230--4242},
	file = {Kucyi et al_2018_Intracranial Electrophysiology Reveals Reproducible Intrinsic Functional.pdf:/Users/tito/Zotero/storage/MSPDC7WL/Kucyi et al_2018_Intracranial Electrophysiology Reveals Reproducible Intrinsic Functional.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/I9CCS79I/4230.html:text/html},
}

@article{kucyi_electrophysiological_2020,
	title = {Electrophysiological dynamics of antagonistic brain networks reflect attentional fluctuations},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-14166-2},
	doi = {10.1038/s41467-019-14166-2},
	abstract = {Neuroimaging evidence suggests that the default mode network (DMN) exhibits antagonistic activity with dorsal attention (DAN) and salience (SN) networks. Here we use human intracranial electroencephalography to investigate the behavioral relevance of fine-grained dynamics within and between these networks. The three networks show dissociable profiles of task-evoked electrophysiological activity, best captured in the high-frequency broadband (HFB; 70–170 Hz) range. On the order of hundreds of milliseconds, HFB responses peak fastest in the DAN, at intermediate speed in the SN, and slowest in the DMN. Lapses of attention (behavioral errors) are marked by distinguishable patterns of both pre- and post-stimulus HFB activity within each network. Moreover, the magnitude of temporally lagged, negative HFB coupling between the DAN and DMN (but not SN and DMN) is associated with greater sustained attention performance and is reduced during wakeful rest. These findings underscore the behavioral relevance of temporally delayed coordination between antagonistic brain networks.},
	language = {en},
	number = {1},
	urldate = {2021-01-19},
	journal = {Nature Communications},
	author = {Kucyi, Aaron and Daitch, Amy and Raccah, Omri and Zhao, Baotian and Zhang, Chao and Esterman, Michael and Zeineh, Michael and Halpern, Casey H. and Zhang, Kai and Zhang, Jianguo and Parvizi, Josef},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {325},
	file = {Kucyi et al_2020_Electrophysiological dynamics of antagonistic brain networks reflect.pdf:/Users/tito/Zotero/storage/TGGDU8ZM/Kucyi et al_2020_Electrophysiological dynamics of antagonistic brain networks reflect.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TCB5ZK6D/s41467-019-14166-2.html:text/html},
}

@article{ye_representation_2021,
	title = {Representation learning for neural population activity with {Neural} {Data} {Transformers}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.01.16.426955v1},
	doi = {10.1101/2021.01.16.426955},
	abstract = {{\textless}p{\textgreater}Neural population activity is theorized to reflect an underlying dynamical structure. This structure can be accurately captured using state space models with explicit dynamics, such as those based on recurrent neural networks (RNNs). However, using recurrence to explicitly model dynamics necessitates sequential processing of data, slowing real-time applications such as brain-computer interfaces. Here we introduce the Neural Data Transformer (NDT), a non-recurrent alternative. We test the NDT9s ability to capture autonomous dynamical systems by applying it to synthetic datasets with known dynamics and data from monkey motor cortex during a reaching task well-modeled by RNNs. The NDT models these datasets as well as state-of-the-art recurrent models. Further, its non-recurrence enables 3.9ms inference, well within the loop time of real-time applications and more than 6 times faster than recurrent baselines on the monkey reaching dataset. These results suggest that an explicit dynamics model is not necessary to model autonomous neural population dynamics. Code: https://github.com/snel-repo/neural-data-transformers.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-20},
	journal = {bioRxiv},
	author = {Ye, Joel and Pandarinath, Chethan},
	month = jan,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.01.16.426955},
	file = {Ye_Pandarinath_2021_Representation learning for neural population activity with Neural Data.pdf:/Users/tito/Zotero/storage/Y5UHBS67/Ye_Pandarinath_2021_Representation learning for neural population activity with Neural Data.pdf:application/pdf},
}

@article{esfahlani_space-independent_2020,
	title = {Space-independent community and hub structure of functional brain networks},
	volume = {211},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920300999},
	doi = {10.1016/j.neuroimage.2020.116612},
	abstract = {Coordinated brain activity reflects underlying cognitive processes and can be modeled as a network of inter-regional functional connections. The most costly connections in the network are long-distance correlations that, in the absence of underlying structural connections, are maintained by sustained energetic inputs. Here, we present a spatial modeling approach that amplifies contributions made by long-distance functional connections to whole-brain network architecture, while simultaneously suppressing contributions made by short-range connections. We use this method to characterize the long-distance architecture of functional networks and to identify aspects of community and hub structure that are driven by long-distance correlations and that, we argue, are of greater functional significance. We find that based only on patterns of long-distance connectivity, primary sensory cortices occupy increasingly central positions and appear more “hub-like”. Additionally, we show that the community structure of long-distance connections spans multiple topological levels and differs from the community structure detected in networks that include both short-range and long-distance connections. In summary, these findings highlight the complex relationship between the brain’s physical layout and its functional architecture. The results presented here inform future analyses of community structure and network hubs in health, across development, and in the case of neuropsychiatric disorders.},
	language = {en},
	urldate = {2021-01-20},
	journal = {NeuroImage},
	author = {Esfahlani, Farnaz and Bertolero, Maxwell A. and Bassett, Danielle S. and Betzel, Richard F.},
	month = may,
	year = {2020},
	pages = {116612},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/KYXTWFAT/S1053811920300999.html:text/html;Zamani Esfahlani et al_2020_Space-independent community and hub structure of functional brain networks.pdf:/Users/tito/Zotero/storage/LWGKSFYV/Zamani Esfahlani et al_2020_Space-independent community and hub structure of functional brain networks.pdf:application/pdf},
}

@article{afyouni_effective_2019,
	title = {Effective degrees of freedom of the {Pearson}'s correlation coefficient under autocorrelation},
	volume = {199},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919303945},
	doi = {10.1016/j.neuroimage.2019.05.011},
	abstract = {The dependence between pairs of time series is commonly quantified by Pearson's correlation. However, if the time series are themselves dependent (i.e. exhibit temporal autocorrelation), the effective degrees of freedom (EDF) are reduced, the standard error of the sample correlation coefficient is biased, and Fisher's transformation fails to stabilise the variance. Since fMRI time series are notoriously autocorrelated, the issue of biased standard errors – before or after Fisher's transformation – becomes vital in individual-level analysis of resting-state functional connectivity (rsFC) and must be addressed anytime a standardised Z-score is computed. We find that the severity of autocorrelation is highly dependent on spatial characteristics of brain regions, such as the size of regions of interest and the spatial location of those regions. We further show that the available EDF estimators make restrictive assumptions that are not supported by the data, resulting in biased rsFC inferences that lead to distorted topological descriptions of the connectome on the individual level. We propose a practical “xDF” method that accounts not only for distinct autocorrelation in each time series, but instantaneous and lagged cross-correlation. We find the xDF correction varies substantially over node pairs, indicating the limitations of global EDF corrections used previously. In addition to extensive synthetic and real data validations, we investigate the impact of this correction on rsFC measures in data from the Young Adult Human Connectome Project, showing that accounting for autocorrelation dramatically changes fundamental graph theoretical measures relative to no correction.},
	language = {en},
	urldate = {2021-01-20},
	journal = {NeuroImage},
	author = {Afyouni, Soroosh and Smith, Stephen M. and Nichols, Thomas E.},
	month = oct,
	year = {2019},
	keywords = {fMRI, Functional connectivity, Resting state, Graph theory, Autocorrelation, Cross correlation, Pearson correlation coefficient, Quadratic covariance, Serial correlation, Time-series, Toeplitz matrix, Variance},
	pages = {609--625},
	file = {Afyouni et al_2019_Effective degrees of freedom of the Pearson's correlation coefficient under.pdf:/Users/tito/Zotero/storage/ZC9APTEB/Afyouni et al_2019_Effective degrees of freedom of the Pearson's correlation coefficient under.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/5EPQ49XV/S1053811919303945.html:text/html},
}

@article{dixon_heterogeneity_2018,
	title = {Heterogeneity within the frontoparietal control network and its relationship to the default and dorsal attention networks},
	volume = {115},
	copyright = {© 2018 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/7/E1598},
	doi = {10.1073/pnas.1715766115},
	abstract = {The frontoparietal control network (FPCN) plays a central role in executive control. It has been predominantly viewed as a unitary domain general system. Here, we examined patterns of FPCN functional connectivity (FC) across multiple conditions of varying cognitive demands, to test for FPCN heterogeneity. We identified two distinct subsystems within the FPCN based on hierarchical clustering and machine learning classification analyses of within-FPCN FC patterns. These two FPCN subsystems exhibited distinct patterns of FC with the default network (DN) and the dorsal attention network (DAN). FPCNA exhibited stronger connectivity with the DN than the DAN, whereas FPCNB exhibited the opposite pattern. This twofold FPCN differentiation was observed across four independent datasets, across nine different conditions (rest and eight tasks), at the level of individual-participant data, as well as in meta-analytic coactivation patterns. Notably, the extent of FPCN differentiation varied across conditions, suggesting flexible adaptation to task demands. Finally, we used meta-analytic tools to identify several functional domains associated with the DN and DAN that differentially predict activation in the FPCN subsystems. These findings reveal a flexible and heterogeneous FPCN organization that may in part emerge from separable DN and DAN processing streams. We propose that FPCNA may be preferentially involved in the regulation of introspective processes, whereas FPCNB may be preferentially involved in the regulation of visuospatial perceptual attention.},
	language = {en},
	number = {7},
	urldate = {2021-01-20},
	journal = {PNAS},
	author = {Dixon, Matthew L. and Vega, Alejandro De La and Mills, Caitlin and Andrews-Hanna, Jessica and Spreng, R. Nathan and Cole, Michael W. and Christoff, Kalina},
	month = feb,
	year = {2018},
	pmid = {29382744},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {functional connectivity, cognitive control, dorsal attention network, default network, frontoparietal control network},
	pages = {E1598--E1607},
	file = {Dixon et al_2018_Heterogeneity within the frontoparietal control network and its relationship to.pdf:/Users/tito/Zotero/storage/K5UWYCUK/Dixon et al_2018_Heterogeneity within the frontoparietal control network and its relationship to.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ALF9BQPU/E1598.html:text/html},
}

@article{thompson_intracranial_2021,
	title = {Intracranial electrical stimulation alters meso-scale network integration as a function of network topology},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.01.16.426941v1},
	doi = {10.1101/2021.01.16.426941},
	abstract = {{\textless}p{\textgreater}Human brain dynamics are organized into a multi-scale network structure that contains multiple tight-knit, meso-scale communities. Recent work has demonstrated that many psychological capacities, as well as impairments in cognitive function secondary to damage, can be mapped onto organizing principles at this mesoscopic scale. However, we still do not know the rules that govern the dynamic interactions between regions that are constrained by the topology of the broader network. In this preregistered study, we utilized a unique human dataset in which whole brain BOLD-fMRI activity was recorded simultaneously with intracranial electrical stimulation, to characterize the effects of direct neural stimulation on the dynamic reconfiguration of the broader network. Direct neural stimulation increased the extent to which the stimulation site9s own mesoscale community integrated with the rest of the brain. Further, we found that these network changes depended on the topological role of the stimulation site itself: stimulating regions with high participation coefficients led to global integration, whereas stimulating sites with low participation coefficients integrated that regions9 own community with the rest of the brain. These findings provide direct causal evidence for how network topology shapes and constrains inter-regional coordination, and suggest applications for targeted therapeutic interventions in patients with deep-brain stimulation.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-20},
	journal = {bioRxiv},
	author = {Thompson, William Hedley and Esteban, Oscar and Oya, Hiroyuki and Nair, Remya and Eberhardt, Frederick and Dubois, Julien and Poldrack, Russell A. and Adolphs, Ralph and Shine, James M.},
	month = jan,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.01.16.426941},
	file = {Snapshot:/Users/tito/Zotero/storage/G9RTHJFG/2021.01.16.426941v1.full.html:text/html;Thompson et al_2021_Intracranial electrical stimulation alters meso-scale network integration as a.pdf:/Users/tito/Zotero/storage/7MWXU56X/Thompson et al_2021_Intracranial electrical stimulation alters meso-scale network integration as a.pdf:application/pdf},
}

@article{ingrosso_optimal_2020,
	title = {Optimal learning with excitatory and inhibitory synapses},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008536},
	doi = {10.1371/journal.pcbi.1008536},
	abstract = {Characterizing the relation between weight structure and input/output statistics is fundamental for understanding the computational capabilities of neural circuits. In this work, I study the problem of storing associations between analog signals in the presence of correlations, using methods from statistical mechanics. I characterize the typical learning performance in terms of the power spectrum of random input and output processes. I show that optimal synaptic weight configurations reach a capacity of 0.5 for any fraction of excitatory to inhibitory weights and have a peculiar synaptic distribution with a finite fraction of silent synapses. I further provide a link between typical learning performance and principal components analysis in single cases. These results may shed light on the synaptic profile of brain circuits, such as cerebellar structures, that are thought to engage in processing time-dependent signals and performing on-line prediction.},
	language = {en},
	number = {12},
	urldate = {2021-01-21},
	journal = {PLOS Computational Biology},
	author = {Ingrosso, Alessandro},
	month = dec,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Covariance, Eigenvalues, Neural pathways, Synapses, Body weight, Free energy, Perceptrons},
	pages = {e1008536},
	file = {Ingrosso_2020_Optimal learning with excitatory and inhibitory synapses.pdf:/Users/tito/Zotero/storage/ZXE7M6BN/Ingrosso_2020_Optimal learning with excitatory and inhibitory synapses.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/S6G9V2KX/article.html:text/html},
}

@article{dickie_ciftify_2019,
	title = {Ciftify: {A} framework for surface-based analysis of legacy {MR} acquisitions},
	volume = {197},
	issn = {1053-8119},
	shorttitle = {Ciftify},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811919303714},
	doi = {10.1016/j.neuroimage.2019.04.078},
	abstract = {The preprocessing pipelines of the Human Connectome Project (HCP) were made publicly available for the neuroimaging community to apply the HCP analytic approach to data from non-HCP sources. The HCP analytic approach is surface-based for the cerebral cortex, uses the CIFTI “grayordinate” file format, provides greater statistical sensitivity than traditional volume-based analysis approaches, and allows for a more neuroanatomically-faithful representation of data. However, the HCP pipelines require the acquisition of specific images (namely T2w and field map) that historically have often not been acquired. Massive amounts of this ‘legacy’ data could benefit from the adoption of HCP-style methods. However, there is currently no published framework, to our knowledge, for adapting HCP preprocessing to “legacy” data. Here we present the ciftify project, a parsimonious analytic framework for adapting key modules from the HCP pipeline into existing structural workflows using FreeSurfer's recon\_all structural and existing functional preprocessing workflows. Within this framework, any functional dataset with an accompanying (i.e. T1w) anatomical data can be analyzed in CIFTI format. To simplify usage for new data, the workflow has been bundled with fMRIPrep following the BIDS-app framework. Finally, we present the package and comment on future neuroinformatics advances that may accelerate the movement to a CIFTI-based grayordinate framework.},
	language = {en},
	urldate = {2021-01-21},
	journal = {NeuroImage},
	author = {Dickie, Erin W. and Anticevic, Alan and Smith, Dawn E. and Coalson, Timothy S. and Manogaran, Mathuvanthi and Calarco, Navona and Viviano, Joseph D. and Glasser, Matthew F. and Van Essen, David C. and Voineskos, Aristotle N.},
	month = aug,
	year = {2019},
	pages = {818--826},
	file = {Dickie et al_2019_Ciftify.pdf:/Users/tito/Zotero/storage/8JV684W2/Dickie et al_2019_Ciftify.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/S2RHN9E4/S1053811919303714.html:text/html},
}

@article{mccormick_model-based_2019,
	title = {Model-based network discovery of developmental and performance-related differences during risky decision-making},
	volume = {188},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918321864},
	doi = {10.1016/j.neuroimage.2018.12.042},
	abstract = {Theories of adolescent neurodevelopment have largely focused on group-level descriptions of neural changes that help explain increases in risk behavior that are stereotypical of the teen years. However, because these models are concerned with describing the “average” individual, they can fail to account for important individual or within-group variability. New methodological developments now offer the possibility of accounting for both group trends and individual differences within the same modeling framework. Here we apply GIMME, a model-based approach which uses both group and individual-level information to construct functional connectivity maps, to investigate risky behavior and neural changes across development. Adolescents (N = 30, Mage = 13.22), young adults (N = 23, Mage = 19.19), and adults (N = 31, Mage = 43.93) completed a risky decision-making task during an fMRI scan, and functional networks were constructed for each individual. We took two subgrouping approaches: 1) a confirmatory approach where we searched for functional connections that distinguished between our a priori age categories, and 2) an exploratory approach where we allowed an unsupervised algorithm to sort individuals freely. Contrary to expectations, we show that age is not the most influence contributing to network configurations. The implications for developmental theories and methodologies are discussed.},
	language = {en},
	urldate = {2021-01-21},
	journal = {NeuroImage},
	author = {McCormick, Ethan M. and Gates, Kathleen M. and Telzer, Eva H.},
	month = mar,
	year = {2019},
	pages = {456--464},
	file = {McCormick et al_2019_Model-based network discovery of developmental and performance-related.pdf:/Users/tito/Zotero/storage/BBTNVTDS/McCormick et al_2019_Model-based network discovery of developmental and performance-related.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/BRV5BZ4H/S1053811918321864.html:text/html},
}

@article{dinga_controlling_2020,
	title = {Controlling for effects of confounding variables on machine learning predictions},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.08.17.255034v1},
	doi = {10.1101/2020.08.17.255034},
	abstract = {{\textless}h3{\textgreater}ABSTRACT{\textless}/h3{\textgreater} {\textless}p{\textgreater}Machine learning predictive models are being used in neuroimaging to predict information about the task or stimuli or to identify potentially clinically useful biomarkers. However, the predictions can be driven by confounding variables unrelated to the signal of interest, such as scanner effect or head motion, limiting the clinical usefulness and interpretation of machine learning models. The most common method to control for confounding effects is regressing out the confounding variables separately from each input variable before machine learning modeling. However, we show that this method is insufficient because machine learning models can learn information from the data that cannot be regressed out. Instead of regressing out confounding effects from each input variable, we propose controlling for confounds post-hoc on the level of machine learning predictions. This allows partitioning of the predictive performance into the performance that can be explained by confounds and performance independent of confounds. This approach is flexible and allows for parametric and non-parametric confound adjustment. We show in real and simulated data that this method correctly controls for confounding effects even when traditional input variable adjustment produces false-positive findings.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-01-27},
	journal = {bioRxiv},
	author = {Dinga, Richard and Schmaal, Lianne and Penninx, Brenda W. J. H. and Veltman, Dick J. and Marquand, Andre F.},
	month = aug,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.08.17.255034},
	file = {Dinga et al_2020_Controlling for effects of confounding variables on machine learning predictions.pdf:/Users/tito/Zotero/storage/PEIFBUVK/Dinga et al_2020_Controlling for effects of confounding variables on machine learning predictions.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WHR2GWAE/2020.08.17.255034v1.html:text/html},
}

@article{van_uden_modeling_2018-1,
	title = {Modeling {Semantic} {Encoding} in a {Common} {Neural} {Representational} {Space}},
	volume = {12},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00437/full},
	doi = {10.3389/fnins.2018.00437},
	abstract = {Encoding models for mapping voxelwise semantic tuning are typically estimated separately for each individual, limiting their generalizability. In the current report, we develop a method for estimating semantic encoding models that generalize across individuals. Functional MRI was used to measure brain responses while participants freely viewed a naturalistic audiovisual movie. Word embeddings capturing agent-, action-, object-, and scene-related semantic content were assigned to each imaging volume based on an annotation of the film. We constructed both conventional within-subject semantic encoding models and between-subject models where the model was trained on a subset of participants and validated on a left-out participant. Between-subject models were trained using cortical surface-based anatomical normalization or surface-based whole-cortex hyperalignment. We used hyperalignment to project group data into an individual’s unique anatomical space via a common representational space, thus leveraging a larger volume of data for out-of-sample prediction while preserving the individual’s fine-grained functional–anatomical idiosyncrasies. Our findings demonstrate that anatomical normalization degrades the spatial specificity of between-subject encoding models relative to within-subject models. Hyperalignment, on the other hand, recovers the spatial specificity of semantic tuning lost during anatomical normalization, and yields model performance exceeding that of within-subject models.},
	language = {English},
	urldate = {2021-01-28},
	journal = {Front. Neurosci.},
	author = {Van Uden, Cara E. and Nastase, Samuel A. and Connolly, Andrew C. and Feilong, Ma and Hansen, Isabella and Gobbini, M. Ida and Haxby, James V.},
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {natural vision, fMRI, Functional alignment, hyperalignment, individual variability, forward encoding models, Semantic Representation},
	file = {Van Uden et al_2018_Modeling Semantic Encoding in a Common Neural Representational Space.pdf:/Users/tito/Zotero/storage/ZP7G47CT/Van Uden et al_2018_Modeling Semantic Encoding in a Common Neural Representational Space.pdf:application/pdf},
}

@misc{noauthor_computational_nodate,
	title = {A computational model of shared fine-scale structure in the human connectome},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006120},
	urldate = {2021-01-28},
	file = {A computational model of shared fine-scale structure in the human connectome:/Users/tito/Zotero/storage/AK8HJU9M/article.html:text/html},
}

@article{greene_how_2020,
	title = {How {Tasks} {Change} {Whole}-{Brain} {Functional} {Organization} to {Reveal} {Brain}-{Phenotype} {Relationships}},
	volume = {32},
	issn = {2211-1247},
	url = {https://www.cell.com/cell-reports/abstract/S2211-1247(20)31051-2},
	doi = {10.1016/j.celrep.2020.108066},
	language = {English},
	number = {8},
	urldate = {2021-01-28},
	journal = {Cell Reports},
	author = {Greene, Abigail S. and Gao, Siyuan and Noble, Stephanie and Scheinost, Dustin and Constable, R. Todd},
	month = aug,
	year = {2020},
	pmid = {32846124},
	note = {Publisher: Elsevier},
	keywords = {fMRI, functional connectivity, individual differences, Human Connectome Project, brain state, brain-phenotype relationships, predictive modeling, tasks},
	file = {Greene et al_2020_How Tasks Change Whole-Brain Functional Organization to Reveal Brain-Phenotype.pdf:/Users/tito/Zotero/storage/5YSZ6EVX/Greene et al_2020_How Tasks Change Whole-Brain Functional Organization to Reveal Brain-Phenotype.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/98AFFDCH/S2211-1247(20)31051-2.html:text/html},
}

@article{gao_neuronal_2020,
	title = {Neuronal timescales are functionally dynamic and shaped by cortical microarchitecture},
	volume = {9},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.61277},
	doi = {10.7554/eLife.61277},
	abstract = {Complex cognitive functions such as working memory and decision-making require information maintenance over seconds to years, from transient sensory stimuli to long-term contextual cues. While theoretical accounts predict the emergence of a corresponding hierarchy of neuronal timescales, direct electrophysiological evidence across the human cortex is lacking. Here, we infer neuronal timescales from invasive intracranial recordings. Timescales increase along the principal sensorimotor-to-association axis across the entire human cortex, and scale with single-unit timescales within macaques. Cortex-wide transcriptomic analysis shows direct alignment between timescales and expression of excitation- and inhibition-related genes, as well as genes specific to voltage-gated transmembrane ion transporters. Finally, neuronal timescales are functionally dynamic: prefrontal cortex timescales expand during working memory maintenance and predict individual performance, while cortex-wide timescales compress with aging. Thus, neuronal timescales follow cytoarchitectonic gradients across the human cortex and are relevant for cognition in both short and long terms, bridging microcircuit physiology with macroscale dynamics and behavior.},
	urldate = {2021-01-28},
	journal = {eLife},
	author = {Gao, Richard and van den Brink, Ruud L and Pfeffer, Thomas and Voytek, Bradley},
	editor = {Vinck, Martin and Colgin, Laura L and Womelsdorf, Thilo},
	month = nov,
	year = {2020},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {cortical gradients, functional specialization, neuronal timescales, spectral analysis, transcriptomics},
	pages = {e61277},
	file = {Gao et al_2020_Neuronal timescales are functionally dynamic and shaped by cortical.pdf:/Users/tito/Zotero/storage/ENEKLGWQ/Gao et al_2020_Neuronal timescales are functionally dynamic and shaped by cortical.pdf:application/pdf},
}

@article{da_silveira_geometry_2021,
	title = {The {Geometry} of {Information} {Coding} in {Correlated} {Neural} {Populations}},
	url = {http://arxiv.org/abs/2102.00772},
	doi = {10.1146/annurev-neuro-120320-082744},
	abstract = {Neurons in the brain represent information in their collective activity. The fidelity of this neural population code depends on whether and how variability in the response of one neuron is shared with other neurons. Two decades of studies have investigated the influence of these noise correlations on the properties of neural coding. We provide an overview of the theoretical developments on the topic. Using simple, qualitative and general arguments, we discuss, categorize, and relate the various published results. We emphasize the relevance of the fine structure of noise correlation, and we present a new approach to the issue. Throughout we emphasize a geometrical picture of how noise correlations impact the neural code.},
	urldate = {2021-02-02},
	journal = {arXiv:2102.00772 [q-bio]},
	author = {da Silveira, Rava Azeredo and Rieke, Fred},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.00772},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 30 pages; 3 figures; review article},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/CV4BM36C/2102.html:text/html;da Silveira_Rieke_2021_The Geometry of Information Coding in Correlated Neural Populations.pdf:/Users/tito/Zotero/storage/ETG5E6V6/da Silveira_Rieke_2021_The Geometry of Information Coding in Correlated Neural Populations.pdf:application/pdf},
}

@article{ehrlich_geometry_2021,
	title = {Geometry of neural computation unifies working memory and planning},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.02.01.429156v1},
	doi = {10.1101/2021.02.01.429156},
	abstract = {{\textless}p{\textgreater}Real-world tasks require coordination of working memory, decision making, and planning, yet these cognitive functions have disproportionately been studied as independent modular processes in the brain. Here we propose that contingency representations, defined as mappings for how future behaviors depend on upcoming events, can unify working memory and planning computations. We designed a task capable of disambiguating distinct types of representations. Our experiments revealed that human behavior is consistent with contingency representations, and not with traditional sensory models of working memory. In task-optimized recurrent neural networks we investigated possible circuit mechanisms for contingency representations and found that these representations can explain neurophysiological observations from prefrontal cortex during working memory tasks. Finally, we generated falsifiable predictions for neural data to identify contingency representations in neural data and to dissociate different models of working memory. Our findings characterize a neural representational strategy that can unify working memory, planning, and context-dependent decision making.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-02-02},
	journal = {bioRxiv},
	author = {Ehrlich, Daniel B. and Murray, John D.},
	month = feb,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.02.01.429156},
	file = {Ehrlich_Murray_2021_Geometry of neural computation unifies working memory and planning.pdf:/Users/tito/Zotero/storage/5QFSC24G/Ehrlich_Murray_2021_Geometry of neural computation unifies working memory and planning.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HFPNWNEP/2021.02.01.429156v1.full.html:text/html},
}

@article{li_trial--trial_2021,
	title = {Trial-to-trial variability of spiking delay activity in prefrontal cortex constrains burst-coding models of working memory},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.01.30.428962v1},
	doi = {10.1101/2021.01.30.428962},
	abstract = {{\textless}p{\textgreater}A hallmark neuronal correlate of working memory (WM) is stimulus-selective spiking activity of neurons in prefrontal cortex (PFC) during mnemonic delays. These observations have motivated an influential computational modeling framework in which WM is supported by persistent activity. Recently this framework has been challenged by arguments that observed persistent activity may be an artifact of trial-averaging, which potentially masks high variability of delay activity at the single-trial level. In an alternative scenario, WM delay activity could be encoded in bursts of selective neuronal firing which occur intermittently across trials. However, this alternative proposal has not been tested on single-neuron spike-train data. Here, we developed a framework for addressing this issue by characterizing the trial-to-trial variability of neuronal spiking quantified by Fano factor (FF). By building a doubly stochastic Poisson spiking model, we first demonstrated that the burst-coding proposal implies a significant increase in FF positively correlated with firing rate, and thus loss of stability across trials during the delay. Simulation of spiking cortical circuit WM models further confirmed that FF is a sensitive measure that can well dissociate distinct WM mechanisms. We then tested these predictions on datasets of single-neuron recordings from macaque prefrontal cortex during three WM tasks. In sharp contrast to the burst-coding model predictions, we only found a small fraction of neurons showing increased WM-dependent burstiness, and stability across trials during delay was strengthened in empirical data. Therefore, reduced trial-to-trial variability during delay provides strong constraints on the contribution of single-neuron intermittent bursting to WM maintenance.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-02-02},
	journal = {bioRxiv},
	author = {Li, Daming and Constantinidis, Christos and Murray, John D.},
	month = feb,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.01.30.428962},
	file = {Li et al_2021_Trial-to-trial variability of spiking delay activity in prefrontal cortex.pdf:/Users/tito/Zotero/storage/ASWQUPBG/Li et al_2021_Trial-to-trial variability of spiking delay activity in prefrontal cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/J4W962NM/2021.01.30.428962v1.full.html:text/html},
}

@article{morgan_low-dimensional_2018,
	title = {Low-dimensional morphospace of topological motifs in human {fMRI} brain networks},
	volume = {2},
	url = {https://doi.org/10.1162/netn_a_00038},
	doi = {10.1162/netn_a_00038},
	abstract = {We present a low-dimensional morphospace of fMRI brain networks, where axes are defined in a data-driven manner based on the network motifs. The morphospace allows us to identify the key variations in healthy fMRI networks in terms of their underlying motifs, and we observe that two principal components (PCs) can account for 97\% of the motif variability. The first PC of the motif distribution is correlated with efficiency and inversely correlated with transitivity. Hence this axis approximately conforms to the well-known economical small-world trade-off between integration and segregation in brain networks. Finally, we show that the economical clustering generative model proposed by Vértes et al. (2012) can approximately reproduce the motif morphospace of the real fMRI brain networks, in contrast to other generative models. Overall, the motif morphospace provides a powerful way to visualize the relationships between network properties and to investigate generative or constraining factors in the formation of complex human brain functional networks.},
	number = {2},
	urldate = {2021-02-02},
	journal = {Network Neuroscience},
	author = {Morgan, Sarah E. and Achard, Sophie and Termenon, Maite and Bullmore, Edward T. and Vértes, Petra E.},
	month = jan,
	year = {2018},
	note = {Publisher: MIT Press},
	pages = {285--302},
	file = {Morgan et al_2018_Low-dimensional morphospace of topological motifs in human fMRI brain networks.pdf:/Users/tito/Zotero/storage/FNAKA6YH/Morgan et al_2018_Low-dimensional morphospace of topological motifs in human fMRI brain networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WYCCQFL8/netn_a_00038.html:text/html},
}

@article{phillips_theory_2015,
	title = {Theory in {Biology}: {Figure} 1 or {Figure} 7?},
	volume = {25},
	issn = {0962-8924, 1879-3088},
	shorttitle = {Theory in {Biology}},
	url = {https://www.cell.com/trends/cell-biology/abstract/S0962-8924(15)00194-4},
	doi = {10.1016/j.tcb.2015.10.007},
	language = {English},
	number = {12},
	urldate = {2021-02-03},
	journal = {Trends in Cell Biology},
	author = {Phillips, Rob},
	month = dec,
	year = {2015},
	pmid = {26584768},
	note = {Publisher: Elsevier},
	pages = {723--729},
	file = {Phillips_2015_Theory in Biology.pdf:/Users/tito/Zotero/storage/4DM7739U/Phillips_2015_Theory in Biology.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/82ZFZWP5/S0962-8924(15)00194-4.html:text/html},
}

@article{dohmatob_brain_2021,
	title = {Brain topography beyond parcellations: {Local} gradients of functional maps},
	volume = {229},
	issn = {1053-8119},
	shorttitle = {Brain topography beyond parcellations},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920311915},
	doi = {10.1016/j.neuroimage.2020.117706},
	abstract = {Functional neuroimaging provides the unique opportunity to characterize brain regions based on their response to tasks or ongoing activity. As such, it holds the premise to capture brain spatial organization. Yet, the conceptual framework to describe this organization has remained elusive: on the one hand, parcellations build implicitly on a piecewise constant organization, i.e. flat regions separated by sharp boundaries; on the other hand, the recently popularized concept of functional gradient hints instead at a smooth structure. Noting that both views converge to a topographic scheme that pieces together local variations of functional features, we perform a quantitative assessment of local gradient-based models. Using as a driving case the prediction of functional Magnetic Resonance Imaging (fMRI) data —concretely, the prediction of task-fMRI from rest-fMRI maps across subjects— we develop a parcel-wise linear regression model based on a dictionary of reference topographies. Our method uses multiple random parcellations —as opposed to a single fixed parcellation— and aggregates estimates across these parcellations to predict functional features in left-out subjects. Our experiments demonstrate the existence of an optimal cardinality of the parcellation to capture local gradients of functional maps.},
	language = {en},
	urldate = {2021-02-03},
	journal = {NeuroImage},
	author = {Dohmatob, Elvis and Richard, Hugo and Pinho, Ana Luísa and Thirion, Bertrand},
	month = apr,
	year = {2021},
	keywords = {Model selection, Prediction, Functional gradients, Functional mapping, Parcellation},
	pages = {117706},
	file = {Dohmatob et al_2021_Brain topography beyond parcellations.pdf:/Users/tito/Zotero/storage/ABWC8IMF/Dohmatob et al_2021_Brain topography beyond parcellations.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/E4Y298RK/S1053811920311915.html:text/html},
}

@article{scholl_cortical_2021,
	title = {Cortical response selectivity derives from strength in numbers of synapses},
	volume = {590},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-03044-3},
	doi = {10.1038/s41586-020-03044-3},
	abstract = {Single neocortical neurons are driven by populations of excitatory inputs, which form the basis of neuronal selectivity to features of sensory input. Excitatory connections are thought to mature during development through activity-dependent Hebbian plasticity1, whereby similarity between presynaptic and postsynaptic activity selectively strengthens some synapses and weakens others2. Evidence in support of this process includes measurements of synaptic ultrastructure and in vitro and in vivo physiology and imaging studies3–8. These corroborating lines of evidence lead to the prediction that a small number of strong synaptic inputs drive neuronal selectivity, whereas weak synaptic inputs are less correlated with the somatic output and modulate activity overall6,7. Supporting evidence from cortical circuits, however, has been limited to measurements of neighbouring, connected cell pairs, raising the question of whether this prediction holds for a broad range of synapses converging onto cortical neurons. Here we measure the strengths of functionally characterized excitatory inputs contacting single pyramidal neurons in ferret primary visual cortex (V1) by combining in vivo two-photon synaptic imaging and post hoc electron microscopy. Using electron microscopy reconstruction of individual synapses as a metric of strength, we find no evidence that strong synapses have a predominant role in the selectivity of cortical neuron responses to visual stimuli. Instead, selectivity appears to arise from the total number of synapses activated by different stimuli. Moreover, spatial clustering of co-active inputs appears to be reserved for weaker synapses, enhancing the contribution of weak synapses to somatic responses. Our results challenge the role of Hebbian mechanisms in shaping neuronal selectivity in cortical circuits, and suggest that selectivity reflects the co-activation of large populations of presynaptic neurons with similar properties and a mixture of strengths.},
	language = {en},
	number = {7844},
	urldate = {2021-02-08},
	journal = {Nature},
	author = {Scholl, Benjamin and Thomas, Connon I. and Ryan, Melissa A. and Kamasawa, Naomi and Fitzpatrick, David},
	month = feb,
	year = {2021},
	note = {Number: 7844
Publisher: Nature Publishing Group},
	pages = {111--114},
	file = {Scholl et al_2021_Cortical response selectivity derives from strength in numbers of synapses.pdf:/Users/tito/Zotero/storage/SXSSLCUZ/Scholl et al_2021_Cortical response selectivity derives from strength in numbers of synapses.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JZ6THZD7/s41586-020-03044-3.html:text/html},
}

@article{zhuang_unsupervised_2021,
	title = {Unsupervised neural network models of the ventral visual stream},
	volume = {118},
	copyright = {Copyright © 2021 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/3/e2014196118},
	doi = {10.1073/pnas.2014196118},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today’s best supervised methods and that the mapping of these neural network models’ hidden layers is neuroanatomically consistent across the ventral stream. Strikingly, we find that these methods produce brain-like representations even when trained solely with real human child developmental data collected from head-mounted cameras, despite the fact that these datasets are noisy and limited. We also find that semisupervised deep contrastive embeddings can leverage small numbers of labeled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results illustrate a use of unsupervised learning to provide a quantitative model of a multiarea cortical brain system and present a strong candidate for a biologically plausible computational theory of primate sensory learning.},
	language = {en},
	number = {3},
	urldate = {2021-02-08},
	journal = {PNAS},
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	month = jan,
	year = {2021},
	pmid = {33431673},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {deep neural networks, unsupervised algorithms, ventral visual stream},
	file = {Snapshot:/Users/tito/Zotero/storage/CFBKYF9C/e2014196118.html:text/html;Zhuang et al_2021_Unsupervised neural network models of the ventral visual stream.pdf:/Users/tito/Zotero/storage/G6RUU7LU/Zhuang et al_2021_Unsupervised neural network models of the ventral visual stream.pdf:application/pdf},
}

@article{curto_relating_2019,
	series = {Computational {Neuroscience}},
	title = {Relating network connectivity to dynamics: opportunities and challenges for theoretical neuroscience},
	volume = {58},
	issn = {0959-4388},
	shorttitle = {Relating network connectivity to dynamics},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438819300443},
	doi = {10.1016/j.conb.2019.06.003},
	abstract = {We review recent work relating network connectivity to the dynamics of neural activity. While concepts stemming from network science provide a valuable starting point, the interpretation of graph-theoretic structures and measures can be highly dependent on the dynamics associated to the network. Properties that are quite meaningful for linear dynamics, such as random walk and network flow models, may be of limited relevance in the neuroscience setting. Theoretical and computational neuroscience are playing a vital role in understanding the relationship between network connectivity and the nonlinear dynamics associated to neural networks.},
	language = {en},
	urldate = {2021-02-08},
	journal = {Current Opinion in Neurobiology},
	author = {Curto, Carina and Morrison, Katherine},
	month = oct,
	year = {2019},
	pages = {11--20},
	file = {Curto_Morrison_2019_Relating network connectivity to dynamics.pdf:/Users/tito/Zotero/storage/XVBFUIQN/Curto_Morrison_2019_Relating network connectivity to dynamics.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/XE36DZGL/S0959438819300443.html:text/html},
}

@article{santoro_symbolic_2021,
	title = {Symbolic {Behaviour} in {Artificial} {Intelligence}},
	url = {https://arxiv.org/abs/2102.03406v1},
	abstract = {The ability to use symbols is the pinnacle of human intelligence, but has yet
to be fully replicated in machines. Here we argue that the path towards
symbolically fluent artificial intelligence (AI) begins with a reinterpretation
of what symbols are, how they come to exist, and how a system behaves when it
uses them. We begin by offering an interpretation of symbols as entities whose
meaning is established by convention. But crucially, something is a symbol only
for those who demonstrably and actively participate in this convention. We then
outline how this interpretation thematically unifies the behavioural traits
humans exhibit when they use symbols. This motivates our proposal that the
field place a greater emphasis on symbolic behaviour rather than particular
computational mechanisms inspired by more restrictive interpretations of
symbols. Finally, we suggest that AI research explore social and cultural
engagement as a tool to develop the cognitive machinery necessary for symbolic
behaviour to emerge. This approach will allow for AI to interpret something as
symbolic on its own rather than simply manipulate things that are only symbols
to human onlookers, and thus will ultimately lead to AI with more human-like
symbolic fluency.},
	language = {en},
	urldate = {2021-02-09},
	author = {Santoro, Adam and Lampinen, Andrew and Mathewson, Kory and Lillicrap, Timothy and Raposo, David},
	month = feb,
	year = {2021},
	file = {Snapshot:/Users/tito/Zotero/storage/GIHFTWBZ/2102.html:text/html},
}

@article{forstmann_methodological_2007,
	title = {Methodological and empirical issues when dissociating cue-related from task-related processes in the explicit task-cuing procedure},
	volume = {71},
	issn = {1430-2772},
	url = {https://doi.org/10.1007/s00426-005-0040-4},
	doi = {10.1007/s00426-005-0040-4},
	abstract = {In the explicit cuing version of the task-switching paradigm, each individual task is indicated by a unique task cue. Consequently, a task switch is accompanied by a cue switch. Recently, it has been proposed that priming of cue encoding contributes to the empirically observed switch costs. This proposal was experimentally supported by using a 2:1 mapping of cues to tasks, so that a cue switch does not necessarily imply a task switch. The results indeed suggested a substantial contribution of “cue-switch costs” to task-switch costs. Here we argue that the 2:1 mapping potentially leads to an underestimation of “pure” task-switch costs. To support this argument, we report the results of a new study in which we used “transition cues” that indicate the identity of the current task based on the identity of the preceding task. This new type of cue allows a full factorial manipulation of cue switches and task switches because it includes the condition in which a cue repetition can also indicate a task switch (i.e., when the “switch” cue is repeated). We discuss the methodological implications and argue that the present approach has merits relative to the previously used 2:1 mapping of cues to tasks.},
	language = {en},
	number = {4},
	urldate = {2021-02-12},
	journal = {Psychological Research},
	author = {Forstmann, Birte U. and Brass, Marcel and Koch, Iring},
	month = jul,
	year = {2007},
	pages = {393--400},
	file = {Forstmann et al_2007_Methodological and empirical issues when dissociating cue-related from.pdf:/Users/tito/Zotero/storage/BHJRV6D3/Forstmann et al_2007_Methodological and empirical issues when dissociating cue-related from.pdf:application/pdf},
}

@article{mars_common_2021,
	title = {A {Common} {Space} {Approach} to {Comparative} {Neuroscience}},
	volume = {44},
	url = {https://doi.org/10.1146/annurev-neuro-100220-025942},
	doi = {10.1146/annurev-neuro-100220-025942},
	abstract = {Comparative neuroscience is entering the era of big data. New high-throughput methods and data-sharing initiatives have resulted in the availability of large, digital data sets containing many types of data from ever more species. Here, we present a framework for exploiting the new possibilities offered. The multimodality of the data allows vertical translations, which are comparisons of different aspects of brain organization within a single species and across scales. Horizontal translations compare particular aspects of brain organization across species, often by building abstract feature spaces. Combining vertical and horizontal translations allows for more sophisticated comparisons, including relating principles of brain organization across species by contrasting horizontal translations, and for making formal predictions of unobtainable data based on observed results in a model species. Expected final online publication date for the Annual Review of Neuroscience, Volume 44 is July 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	urldate = {2021-02-16},
	journal = {Annual Review of Neuroscience},
	author = {Mars, Rogier B. and Jbabdi, Saad and Rushworth, Matthew F.S.},
	year = {2021},
	pmid = {33534614},
	note = {\_eprint: https://doi.org/10.1146/annurev-neuro-100220-025942},
	pages = {null},
}

@article{akhlaghpour_rna-based_2020,
	title = {An {RNA}-{Based} {Theory} of {Natural} {Universal} {Computation}},
	url = {http://arxiv.org/abs/2008.08814},
	abstract = {Life is confronted with computation problems in a variety of domains including animal behavior, single-cell behavior, and embryonic development. Yet we currently have no biologically plausible model capable of universal computation, i.e., Turing-equivalent in scope. Network models (which include neural networks, intracellular signaling cascades, and gene regulatory networks) fall short of universal computation, but are assumed to be capable of explaining cognition and development. I present a class of models that bridge two concepts from distant fields: combinatory logic (or, equivalently, lambda calculus) and molecular biology. A set of basic RNA editing rules can make it possible to compute any computable function with identical algorithmic complexity to that of Turing machines. The models do not assume extraordinarily complex molecular machinery or any processes that radically differ from what we already know to occur in cells. Distinct independent enzymes can mediate each of the rules and RNA molecules solve the problem of parenthesis matching through their secondary structure. The most plausible of these models does not strictly mimic the operation rules of combinatory logic or lambda calculus; it relies on standard RNA transcription from static genomic templates and the editing rules can be implemented with merely cleavage and ligation operations. This demonstrates that universal computation is well within the reach of molecular biology. It is therefore reasonable to assume that life has evolved - or possibly began with - a universal computer that yet remains to be discovered. The variety of seemingly unrelated computational problems across many scales can potentially be solved using the same RNA-based computation system. Experimental validation of this theory may immensely impact our understanding of memory, cognition, development, disease, evolution, and the early stages of life.},
	urldate = {2021-02-16},
	journal = {arXiv:2008.08814 [q-bio]},
	author = {Akhlaghpour, Hessameddin},
	month = oct,
	year = {2020},
	note = {arXiv: 2008.08814},
	keywords = {Quantitative Biology - Other Quantitative Biology},
	annote = {Comment: 34 pages (main text), 56 pages total, 7 figures, appendices in the same document},
	file = {Akhlaghpour_2020_An RNA-Based Theory of Natural Universal Computation.pdf:/Users/tito/Zotero/storage/X7ZY2BI5/Akhlaghpour_2020_An RNA-Based Theory of Natural Universal Computation.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/K2N3C4AK/2008.html:text/html},
}

@article{wang_alchemy_2021,
	title = {Alchemy: {A} structured task distribution for meta-reinforcement learning},
	shorttitle = {Alchemy},
	url = {http://arxiv.org/abs/2102.02926},
	abstract = {There has been rapidly growing interest in meta-learning as a method for increasing the flexibility and sample efficiency of reinforcement learning. One problem in this area of research, however, has been a scarcity of adequate benchmark tasks. In general, the structure underlying past benchmarks has either been too simple to be inherently interesting, or too ill-defined to support principled analysis. In the present work, we introduce a new benchmark for meta-RL research, which combines structural richness with structural transparency. Alchemy is a 3D video game, implemented in Unity, which involves a latent causal structure that is resampled procedurally from episode to episode, affording structure learning, online inference, hypothesis testing and action sequencing based on abstract domain knowledge. We evaluate a pair of powerful RL agents on Alchemy and present an in-depth analysis of one of these agents. Results clearly indicate a frank and specific failure of meta-learning, providing validation for Alchemy as a challenging benchmark for meta-RL. Concurrent with this report, we are releasing Alchemy as public resource, together with a suite of analysis tools and sample agent trajectories.},
	urldate = {2021-02-16},
	journal = {arXiv:2102.02926 [cs]},
	author = {Wang, Jane X. and King, Michael and Porcel, Nicolas and Kurth-Nelson, Zeb and Zhu, Tina and Deck, Charlie and Choy, Peter and Cassin, Mary and Reynolds, Malcolm and Song, Francis and Buttimore, Gavin and Reichert, David P. and Rabinowitz, Neil and Matthey, Loic and Hassabis, Demis and Lerchner, Alexander and Botvinick, Matthew},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.02926},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 16 pages, 9 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/HKEVVGRX/2102.html:text/html;Wang et al_2021_Alchemy.pdf:/Users/tito/Zotero/storage/UHDUSWAT/Wang et al_2021_Alchemy.pdf:application/pdf},
}

@article{botvinick_deep_2020,
	title = {Deep {Reinforcement} {Learning} and its {Neuroscientific} {Implications}},
	url = {http://arxiv.org/abs/2007.03750},
	abstract = {The emergence of powerful artificial intelligence is defining new research directions in neuroscience. To date, this research has focused largely on deep neural networks trained using supervised learning, in tasks such as image classification. However, there is another area of recent AI work which has so far received less attention from neuroscientists, but which may have profound neuroscientific implications: deep reinforcement learning. Deep RL offers a comprehensive framework for studying the interplay among learning, representation and decision-making, offering to the brain sciences a new set of research tools and a wide range of novel hypotheses. In the present review, we provide a high-level introduction to deep RL, discuss some of its initial applications to neuroscience, and survey its wider implications for research on brain and behavior, concluding with a list of opportunities for next-stage research.},
	urldate = {2021-02-16},
	journal = {arXiv:2007.03750 [cs, q-bio]},
	author = {Botvinick, Matthew and Wang, Jane X. and Dabney, Will and Miller, Kevin J. and Kurth-Nelson, Zeb},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.03750},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 22 pages, 5 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DMDYN8EH/2007.html:text/html;Botvinick et al_2020_Deep Reinforcement Learning and its Neuroscientific Implications.pdf:/Users/tito/Zotero/storage/PXU8LKGP/Botvinick et al_2020_Deep Reinforcement Learning and its Neuroscientific Implications.pdf:application/pdf},
}

@article{minervini_learning_2020,
	title = {Learning {Reasoning} {Strategies} in {End}-to-{End} {Differentiable} {Proving}},
	url = {http://arxiv.org/abs/2007.06477},
	abstract = {Attempts to render deep learning models interpretable, data-efficient, and robust have seen some success through hybridisation with rule-based systems, for example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions. However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. We present Conditional Theorem Provers (CTPs), an extension to NTPs that learns an optimal rule selection strategy via gradient-based optimisation. We show that CTPs are scalable and yield state-of-the-art results on the CLUTRR dataset, which tests systematic generalisation of neural models by learning to reason over smaller graphs and evaluating on larger ones. Finally, CTPs show better link prediction results on standard benchmarks in comparison with other neural-symbolic models, while being explainable. All source code and datasets are available online, at https://github.com/uclnlp/ctp.},
	urldate = {2021-02-16},
	journal = {arXiv:2007.06477 [cs]},
	author = {Minervini, Pasquale and Riedel, Sebastian and Stenetorp, Pontus and Grefenstette, Edward and Rocktäschel, Tim},
	month = aug,
	year = {2020},
	note = {arXiv: 2007.06477},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Computer Science - Symbolic Computation},
	annote = {Comment: Proceedings of the 37th International Conference on Machine Learning (ICML 2020)},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/25VW48LC/2007.html:text/html;Minervini et al_2020_Learning Reasoning Strategies in End-to-End Differentiable Proving.pdf:/Users/tito/Zotero/storage/KGRKHSEH/Minervini et al_2020_Learning Reasoning Strategies in End-to-End Differentiable Proving.pdf:application/pdf},
}

@article{waschke_behavior_2021,
	title = {Behavior needs neural variability},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627321000453},
	doi = {10.1016/j.neuron.2021.01.023},
	abstract = {Human and non-human animal behavior is highly malleable and adapts successfully to internal and external demands. Such behavioral success stands in striking contrast to the apparent instability in neural activity (i.e., variability) from which it arises. Here, we summon the considerable evidence across scales, species, and imaging modalities that neural variability represents a key, undervalued dimension for understanding brain-behavior relationships at inter- and intra-individual levels. We believe that only by incorporating a specific focus on variability will the neural foundation of behavior be comprehensively understood.},
	language = {en},
	urldate = {2021-02-16},
	journal = {Neuron},
	author = {Waschke, Leonhard and Kloosterman, Niels A. and Obleser, Jonas and Garrett, Douglas D.},
	month = feb,
	year = {2021},
	keywords = {BOLD, electrophysiology, aging, neural variability, behavior, brain states, desynchronization, inter-individual differences, traits},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/DK83BBC8/S0896627321000453.html:text/html;Waschke et al_2021_Behavior needs neural variability.pdf:/Users/tito/Zotero/storage/SYPXQRNS/Waschke et al_2021_Behavior needs neural variability.pdf:application/pdf},
}

@article{renart_variability_2014,
	series = {Theoretical and computational neuroscience},
	title = {Variability in neural activity and behavior},
	volume = {25},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438814000488},
	doi = {10.1016/j.conb.2014.02.013},
	abstract = {Neural activity and behavior in laboratory experiments are surprisingly variable across trials. This variability and its potential causes have been the focus of a spirited debate. Here we review recent research that has shed light on the sources of neural variability and its impact on behavior. We explain how variability may arise from incomplete knowledge about an animal's internal states and its environment. We discuss the problem of incomplete knowledge both from the experimenter's point of view and from the animal's point of view. Both view points are illustrated through several examples from the literature. We furthermore consider both mechanistic and normative models that explain how neural and behavioral variability may be linked. Finally, we review why variability may confer an adaptive advantage to organisms.},
	language = {en},
	urldate = {2021-02-17},
	journal = {Current Opinion in Neurobiology},
	author = {Renart, Alfonso and Machens, Christian K},
	month = apr,
	year = {2014},
	pages = {211--220},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/R2758QVL/S0959438814000488.html:text/html},
}

@article{zhang_theta_2018,
	title = {Theta and {Alpha} {Oscillations} {Are} {Traveling} {Waves} in the {Human} {Neocortex}},
	volume = {98},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627318304173},
	doi = {10.1016/j.neuron.2018.05.019},
	abstract = {Human cognition requires the coordination of neural activity across widespread brain networks. Here, we describe a new mechanism for large-scale coordination in the human brain: traveling waves of theta and alpha oscillations. Examining direct brain recordings from neurosurgical patients performing a memory task, we found contiguous clusters of cortex in individual patients with oscillations at specific frequencies within 2 to 15 Hz. These oscillatory clusters displayed spatial phase gradients, indicating that they formed traveling waves that propagated at ∼0.25–0.75 m/s. Traveling waves were relevant behaviorally because their propagation correlated with task events and was more consistent when subjects performed the task well. Human traveling theta and alpha waves can be modeled by a network of coupled oscillators because the direction of wave propagation correlated with the spatial orientation of local frequency gradients. Our findings suggest that oscillations support brain connectivity by organizing neural processes across space and time.},
	language = {en},
	number = {6},
	urldate = {2021-02-17},
	journal = {Neuron},
	author = {Zhang, Honghui and Watrous, Andrew J. and Patel, Ansh and Jacobs, Joshua},
	month = jun,
	year = {2018},
	keywords = {oscillation, memory, electroencephalography, theta, electrocorticography, alpha, traveling wave},
	pages = {1269--1281.e4},
	file = {Zhang et al_2018_Theta and Alpha Oscillations Are Traveling Waves in the Human Neocortex.pdf:/Users/tito/Zotero/storage/5RAKJ9KV/Zhang et al_2018_Theta and Alpha Oscillations Are Traveling Waves in the Human Neocortex.pdf:application/pdf},
}

@article{yousefi_propagating_2021,
	title = {Propagating patterns of intrinsic activity along macroscale gradients coordinate functional connections across the whole brain},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381192100104X},
	doi = {10.1016/j.neuroimage.2021.117827},
	abstract = {The intrinsic activity of the human brain, observed with resting-state fMRI (rsfMRI) and functional connectivity, exhibits macroscale spatial organization such as functional networks and gradients. Dynamic analysis techniques have shown that functional connectivity is a mere summary of time-varying patterns with distinct spatial and temporal characteristics. A better understanding of these patterns might provide insight into aspects of the brain's intrinsic activity that cannot be inferred by functional connectivity or the spatial maps derived from it, such as functional networks and gradients. Here, we describe three spatiotemporal patterns of coordinated activity across the whole brain obtained by averaging similar ∼20-second-long segments of rsfMRI timeseries. In each of these patterns, activity propagates along a particular macroscale functional gradient, simultaneously across the cerebral cortex and in most other brain regions. In some regions, like the thalamus, the propagation suggests previously-undescribed gradients. The coordinated activity across areas is consistent with known tract-based connections, and nuanced differences in the timing of peak activity between regions point to plausible driving mechanisms. The magnitude of correlation within and particularly between functional networks is remarkably diminished when these patterns are regressed from the rsfMRI timeseries, a quantitative demonstration of their significant role in functional connectivity. Taken together, our results suggest that a few recurring patterns of propagating intrinsic activity along macroscale gradients give rise to and coordinate functional connections across the whole brain.},
	language = {en},
	urldate = {2021-02-17},
	journal = {NeuroImage},
	author = {Yousefi, Behnaz and Keilholz, Shella},
	month = feb,
	year = {2021},
	pages = {117827},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/87QIYFY3/S105381192100104X.html:text/html;Yousefi_Keilholz_2021_Propagating patterns of intrinsic activity along macroscale gradients.pdf:/Users/tito/Zotero/storage/D7LAQ8CK/Yousefi_Keilholz_2021_Propagating patterns of intrinsic activity along macroscale gradients.pdf:application/pdf},
}

@article{sheahan_neural_2021,
	title = {Neural state space alignment for magnitude generalization in humans and recurrent networks},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627321000787},
	doi = {10.1016/j.neuron.2021.02.004},
	abstract = {A prerequisite for intelligent behavior is to understand how stimuli are related and to generalize this knowledge across contexts. Generalization can be challenging when relational patterns are shared across contexts but exist on different physical scales. Here, we studied neural representations in humans and recurrent neural networks performing a magnitude comparison task, for which it was advantageous to generalize concepts of “more” or “less” between contexts. Using multivariate analysis of human brain signals and of neural network hidden unit activity, we observed that both systems developed parallel neural “number lines” for each context. In both model systems, these number state spaces were aligned in a way that explicitly facilitated generalization of relational concepts (more and less). These findings suggest a previously overlooked role for neural normalization in supporting transfer of a simple form of abstract relational knowledge (magnitude) in humans and machine learning systems.},
	language = {en},
	urldate = {2021-02-23},
	journal = {Neuron},
	author = {Sheahan, Hannah and Luyckx, Fabrice and Nelli, Stephanie and Teupe, Clemens and Summerfield, Christopher},
	month = feb,
	year = {2021},
	keywords = {parietal cortex, neural network, representation, normalization, alignment, generalization, magnitude, number},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/ZV6CYBGY/S0896627321000787.html:text/html},
}

@article{sohn_network_2021,
	title = {A {Network} {Perspective} on {Sensorimotor} {Learning}},
	volume = {44},
	issn = {0166-2236, 1878-108X},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(20)30272-1},
	doi = {10.1016/j.tins.2020.11.007},
	language = {English},
	number = {3},
	urldate = {2021-02-24},
	journal = {Trends in Neurosciences},
	author = {Sohn, Hansem and Meirhaeghe, Nicolas and Rajalingham, Rishi and Jazayeri, Mehrdad},
	month = mar,
	year = {2021},
	pmid = {33349476},
	note = {Publisher: Elsevier},
	keywords = {neural population, dimensionality, internal models, neural plasticity, sensorimotor learning, state space framework},
	pages = {170--181},
	file = {Snapshot:/Users/tito/Zotero/storage/C9D4Z2TD/S0166-2236(20)30272-1.html:text/html;Sohn et al_2021_A Network Perspective on Sensorimotor Learning.pdf:/Users/tito/Zotero/storage/A2T6C578/Sohn et al_2021_A Network Perspective on Sensorimotor Learning.pdf:application/pdf},
}

@inproceedings{montero_role_2020,
	title = {The role of {Disentanglement} in {Generalisation}},
	url = {https://openreview.net/forum?id=qbH974jKUVy},
	abstract = {Combinatorial generalisation — the ability to understand and produce novel combinations of familiar elements — is a core capacity of human intelligence that current AI systems struggle with....},
	language = {en},
	urldate = {2021-02-24},
	author = {Montero, Milton Llera and Ludwig, Casimir JH and Costa, Rui Ponte and Malhotra, Gaurav and Bowers, Jeffrey},
	month = sep,
	year = {2020},
	file = {Montero et al_2020_The role of Disentanglement in Generalisation.pdf:/Users/tito/Zotero/storage/3PB7PEV7/Montero et al_2020_The role of Disentanglement in Generalisation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/NMILFDBP/forum.html:text/html},
}

@article{valente_correlations_2020,
	title = {Correlations enhance the behavioral readout of neural population activity in association cortex},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.04.03.024133v1},
	doi = {10.1101/2020.04.03.024133},
	abstract = {{\textless}p{\textgreater}The spatiotemporal structure of activity in populations of neurons is critical for accurate perception and behavior. Experimental and theoretical studies have focused on “noise” correlations – trial-to-trial covariations in neural activity for a given stimulus – as a key feature of population activity structure. Much work has shown that these correlations limit the stimulus information encoded by a population of neurons, leading to the widely-held prediction that correlations are detrimental for perceptual discrimination behaviors. However, this prediction relies on an untested assumption: that the neural mechanisms that read out sensory information to inform behavior depend only on a population’s total stimulus information independently of how correlations constrain this information across neurons or time. Here we make the critical advance of simultaneously studying how correlations affect both the encoding and the readout of sensory information. We analyzed calcium imaging data from mouse posterior parietal cortex during two perceptual discrimination tasks. Correlations limited the ability to encode stimulus information, but (seemingly paradoxically) correlations were higher when mice made correct choices than when they made errors. On a single-trial basis, a mouse’s behavioral choice depended not only on the stimulus information in the activity of the population as a whole, but unexpectedly also on the consistency of information across neurons and time. Because correlations increased information consistency, sensory information was more efficiently converted into a behavioral choice in the presence of correlations. Given this enhanced-by-consistency readout, we estimated that correlations produced a behavioral benefit that compensated or overcame their detrimental information-limiting effects. These results call for a re-evaluation of the role of correlated neural activity, and suggest that correlations in association cortex can benefit task performance even if they decrease sensory information.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-02-24},
	journal = {bioRxiv},
	author = {Valente, Martina and Pica, Giuseppe and Runyan, Caroline A. and Morcos, Ari S. and Harvey, Christopher D. and Panzeri, Stefano},
	month = apr,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.04.03.024133},
	file = {Snapshot:/Users/tito/Zotero/storage/XG3PWD2U/2020.04.03.html:text/html;Valente et al_2020_Correlations enhance the behavioral readout of neural population activity in.pdf:/Users/tito/Zotero/storage/AWMNMHYZ/Valente et al_2020_Correlations enhance the behavioral readout of neural population activity in.pdf:application/pdf},
}

@article{tavor_task-free_2016,
	title = {Task-free {MRI} predicts individual differences in brain activity during task performance},
	volume = {352},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/352/6282/216},
	doi = {10.1126/science.aad8127},
	abstract = {Every brain is different
We all differ in how we perceive, think, and act. What drives individual differences in evoked brain activity? Tavor et al. applied computational models to functional magnetic resonance imaging (fMRI) data from the Human Connectome Project. Brain activity in the “resting” state when subjects were not performing any explicit task predicted differences in fMRI activation across a range of cognitive paradigms. This suggests that individual differences in many cognitive tasks are a stable trait marker. Resting-state functional connectivity thus already contains the repertoire that is then expressed during task-based fMRI.
Science, this issue p. 216
When asked to perform the same task, different individuals exhibit markedly different patterns of brain activity. This variability is often attributed to volatile factors, such as task strategy or compliance. We propose that individual differences in brain responses are, to a large degree, inherent to the brain and can be predicted from task-independent measurements collected at rest. Using a large set of task conditions, spanning several behavioral domains, we train a simple model that relates task-independent measurements to task activity and evaluate the model by predicting task activation maps for unseen subjects using magnetic resonance imaging. Our model can accurately predict individual differences in brain activity and highlights a coupling between brain connectivity and function that can be captured at the level of individual subjects.
Brain activation when performing activities can largely be understood from its distinctive anatomy and connectivity.
Brain activation when performing activities can largely be understood from its distinctive anatomy and connectivity.},
	language = {en},
	number = {6282},
	urldate = {2021-03-02},
	journal = {Science},
	author = {Tavor, I. and Jones, O. Parker and Mars, R. B. and Smith, S. M. and Behrens, T. E. and Jbabdi, S.},
	month = apr,
	year = {2016},
	pmid = {27124457},
	note = {Publisher: American Association for the Advancement of Science
Section: Report},
	pages = {216--220},
	file = {aad8127_Tavor_SM_revision1.pdf:/Users/tito/Zotero/storage/8XMZDWGU/aad8127_Tavor_SM_revision1.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MHV9N8GN/216.html:text/html;Tavor et al_2016_Task-free MRI predicts individual differences in brain activity during task.pdf:/Users/tito/Zotero/storage/XB6PP58K/Tavor et al_2016_Task-free MRI predicts individual differences in brain activity during task.pdf:application/pdf},
}

@article{xia_temporal_2020,
	title = {Temporal and state abstractions for efficient learning, transfer and composition in humans},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.02.20.958587v1},
	doi = {10.1101/2020.02.20.958587},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Humans use prior knowledge to efficiently solve novel tasks, but how they structure past knowledge to enable such fast generalization is not well understood. We recently proposed that hierarchical state abstraction enabled generalization of simple one-step rules, by inferring context clusters for each rule. However, humans’ daily tasks are often temporally extended, and necessitate more complex multi-step, hierarchically structured strategies. The options framework in hierarchical reinforcement learning provides a theoretical framework for representing such transferable strategies. Options are abstract multi-step policies, assembled from simpler one-step actions or other options, that can represent meaningful reusable strategies as temporal abstractions. We developed a novel sequential decision making protocol to test if humans learn and transfer multi-step options. In a series of four experiments, we found transfer effects at multiple hierarchical levels of abstraction that could not be explained by flat reinforcement learning models or hierarchical models lacking temporal abstraction. We extended the options framework to develop a quantitative model that blends temporal and state abstractions. Our model captures the transfer effects observed in human participants. Our results provide evidence that humans create and compose hierarchical options, and use them to explore in novel contexts, consequently transferring past knowledge and speeding up learning.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-03-02},
	journal = {bioRxiv},
	author = {Xia, Liyu and Collins, Anne G. E.},
	month = feb,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.02.20.958587},
	file = {Snapshot:/Users/tito/Zotero/storage/5TI56QIZ/2020.02.20.958587v1.html:text/html;Xia_Collins_2020_Temporal and state abstractions for efficient learning, transfer and.pdf:/Users/tito/Zotero/storage/8TEK3JVF/Xia_Collins_2020_Temporal and state abstractions for efficient learning, transfer and.pdf:application/pdf},
}

@article{barreiro_when_2017,
	title = {When do correlations increase with firing rates in recurrent networks?},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005506},
	doi = {10.1371/journal.pcbi.1005506},
	abstract = {A central question in neuroscience is to understand how noisy firing patterns are used to transmit information. Because neural spiking is noisy, spiking patterns are often quantified via pairwise correlations, or the probability that two cells will spike coincidentally, above and beyond their baseline firing rate. One observation frequently made in experiments, is that correlations can increase systematically with firing rate. Theoretical studies have determined that stimulus-dependent correlations that increase with firing rate can have beneficial effects on information coding; however, we still have an incomplete understanding of what circuit mechanisms do, or do not, produce this correlation-firing rate relationship. Here, we studied the relationship between pairwise correlations and firing rates in recurrently coupled excitatory-inhibitory spiking networks with conductance-based synapses. We found that with stronger excitatory coupling, a positive relationship emerged between pairwise correlations and firing rates. To explain these findings, we used linear response theory to predict the full correlation matrix and to decompose correlations in terms of graph motifs. We then used this decomposition to explain why covariation of correlations with firing rate—a relationship previously explained in feedforward networks driven by correlated input—emerges in some recurrent networks but not in others. Furthermore, when correlations covary with firing rate, this relationship is reflected in low-rank structure in the correlation matrix.},
	language = {en},
	number = {4},
	urldate = {2021-03-03},
	journal = {PLOS Computational Biology},
	author = {Barreiro, Andrea K. and Ly, Cheng},
	month = apr,
	year = {2017},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Network analysis, Neural networks, Information theory, Coding mechanisms, Action potentials, Network motifs, Monte Carlo method},
	pages = {e1005506},
	file = {Barreiro_Ly_2017_When do correlations increase with firing rates in recurrent networks.pdf:/Users/tito/Zotero/storage/QLDSC5KG/Barreiro_Ly_2017_When do correlations increase with firing rates in recurrent networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MTKI9WPW/article.html:text/html},
}

@article{queralt_connectome_2021,
	title = {The connectome spectrum as a canonical basis for a sparse representation of fast brain activity},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.03.433561v1},
	doi = {10.1101/2021.03.03.433561},
	abstract = {{\textless}p{\textgreater}The functional organization of neural processes is constrained by the brain9s intrinsic structural connectivity. Here, we explore the potential of exploiting this structure in order to improve the signal representation properties of brain activity and its dynamics. Using a multi-modal imaging dataset (electroencephalography, structural MRI and diffusion MRI), we represent electrical brain activity at the cortical surface as a time-varying composition of harmonic modes of structural connectivity. The harmonic modes are termed connectome harmonics, and their representation is known as the connectome spectrum of the signal. We found that: first, the brain activity signal is more compactly represented by the connectome spectrum than by the traditional area-based representation; second, the connectome spectrum characterizes fast brain dynamics in terms of signal broadcasting profile, revealing different temporal regimes of integration and segregation that are consistent across participants. And last, the connectome spectrum characterises fast brain dynamics with fewer degrees of freedom than area-based signal representations. Specifically, we show that with the connectome spectrum representation, fewer dimensions are needed to capture the differences between low-level and high-level visual processing, and the topological properties of the signal. In summary, this work provides statistical, functional and topological evidence supporting that by accounting for the brain9s structural connectivity fosters a more comprehensive understanding of large-scale dynamic neural functioning.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-03-04},
	journal = {bioRxiv},
	author = {Queralt, Joan Rue and Glomb, Katharina and Pascucci, David and Tourbier, Sebastien and Carboni, Margherita and Vulliemoz, Serge and Plomp, Gijs and Hagmann, Patric},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.03.433561},
	file = {Queralt et al_2021_The connectome spectrum as a canonical basis for a sparse representation of.pdf:/Users/tito/Zotero/storage/J7PRVG62/Queralt et al_2021_The connectome spectrum as a canonical basis for a sparse representation of.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4FZXHNQN/2021.03.03.html:text/html},
}

@article{li_tuning_2020,
	title = {Tuning network dynamics from criticality to an asynchronous state},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008268},
	doi = {10.1371/journal.pcbi.1008268},
	abstract = {According to many experimental observations, neurons in cerebral cortex tend to operate in an asynchronous regime, firing independently of each other. In contrast, many other experimental observations reveal cortical population firing dynamics that are relatively coordinated and occasionally synchronous. These discrepant observations have naturally led to competing hypotheses. A commonly hypothesized explanation of asynchronous firing is that excitatory and inhibitory synaptic inputs are precisely correlated, nearly canceling each other, sometimes referred to as ‘balanced’ excitation and inhibition. On the other hand, the ‘criticality’ hypothesis posits an explanation of the more coordinated state that also requires a certain balance of excitatory and inhibitory interactions. Both hypotheses claim the same qualitative mechanism—properly balanced excitation and inhibition. Thus, a natural question arises: how are asynchronous population dynamics and critical dynamics related, how do they differ? Here we propose an answer to this question based on investigation of a simple, network-level computational model. We show that the strength of inhibitory synapses relative to excitatory synapses can be tuned from weak to strong to generate a family of models that spans a continuum from critical dynamics to asynchronous dynamics. Our results demonstrate that the coordinated dynamics of criticality and asynchronous dynamics can be generated by the same neural system if excitatory and inhibitory synapses are tuned appropriately.},
	language = {en},
	number = {9},
	urldate = {2021-03-05},
	journal = {PLOS Computational Biology},
	author = {Li, Jingwen and Shew, Woodrow L.},
	month = sep,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Neurons, Cerebral cortex, Neural networks, Eigenvalues, Action potentials, Synapses, Neuronal tuning, Population dynamics},
	pages = {e1008268},
	file = {Li_Shew_2020_Tuning network dynamics from criticality to an asynchronous state.pdf:/Users/tito/Zotero/storage/FNJ2PCX4/Li_Shew_2020_Tuning network dynamics from criticality to an asynchronous state.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IXSZL56R/article.html:text/html},
}

@article{petri_topological_2021,
	title = {Topological limits to the parallel processing capability of network architectures},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1745-2481},
	url = {https://www.nature.com/articles/s41567-021-01170-x},
	doi = {10.1038/s41567-021-01170-x},
	abstract = {The ability to learn new tasks and generalize to others is a remarkable characteristic of both human brains and recent artificial intelligence systems. The ability to perform multiple tasks simultaneously is also a key characteristic of parallel architectures, as is evident in the human brain and exploited in traditional parallel architectures. Here we show that these two characteristics reflect a fundamental tradeoff between interactive parallelism, which supports learning and generalization, and independent parallelism, which supports processing efficiency through concurrent multitasking. Although the maximum number of possible parallel tasks grows linearly with network size, under realistic scenarios their expected number grows sublinearly. Hence, even modest reliance on shared representations, which support learning and generalization, constrains the number of parallel tasks. This has profound consequences for understanding the human brain’s mix of sequential and parallel capabilities, as well as for the development of artificial intelligence systems that can optimally manage the tradeoff between learning and processing efficiency.},
	language = {en},
	urldate = {2021-03-05},
	journal = {Nature Physics},
	author = {Petri, Giovanni and Musslick, Sebastian and Dey, Biswadip and Özcimder, Kayhan and Turner, David and Ahmed, Nesreen K. and Willke, Theodore L. and Cohen, Jonathan D.},
	month = feb,
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	pages = {1--6},
	file = {Petri et al_2021_Topological limits to the parallel processing capability of network.pdf:/Users/tito/Zotero/storage/2Q3ECXJW/Petri et al_2021_Topological limits to the parallel processing capability of network.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/W469SAZH/s41567-021-01170-x.html:text/html},
}

@article{sigala_hierarchical_2008,
	title = {Hierarchical coding for sequential task events in the monkey prefrontal cortex},
	volume = {105},
	copyright = {© 2008 by The National Academy of Sciences of the USA.  Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/105/33/11969},
	doi = {10.1073/pnas.0802569105},
	abstract = {The frontal lobes play a key role in sequential organization of behavior. Little is known, however, of the way frontal neurons code successive phases of a structured task plan. Using correlational analysis, we asked how a population of frontal cells represents the multiple events of a complex sequential task. Monkeys performed a conventional cue–target association task, with distinct cue, delay, and target phases. Across the population of recorded cells, we examined patterns of activity for different task phases, and in the same phase, for different stimulus objects. The results show hierarchical representation of task events. For different task phases, there were different, approximately orthogonal patterns of activity across the population of neurons. Modulations of each basic pattern encoded stimulus information within each phase. By orthogonal coding, the frontal lobe may control transitions between the discrete steps of a mental program; by correlated coding within each step, similar operations may be applied to different stimulus content.},
	language = {en},
	number = {33},
	urldate = {2021-03-10},
	journal = {PNAS},
	author = {Sigala, Natasha and Kusunoki, Makoto and Nimmo-Smith, Ian and Gaffan, David and Duncan, John},
	month = aug,
	year = {2008},
	pmid = {18689686},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {correlated coding, orthogonal coding, pair associative task, sequence representation},
	pages = {11969--11974},
	file = {Sigala et al_2008_Hierarchical coding for sequential task events in the monkey prefrontal cortex.pdf:/Users/tito/Zotero/storage/UI4LEIFB/Sigala et al_2008_Hierarchical coding for sequential task events in the monkey prefrontal cortex.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/PM6PUDDP/11969.html:text/html},
}

@article{huang_relationship_2021,
	title = {Relationship between simultaneously recorded spiking activity and fluorescence signal in {GCaMP6} transgenic mice},
	volume = {10},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.51675},
	doi = {10.7554/eLife.51675},
	abstract = {Fluorescent calcium indicators are often used to investigate neural dynamics, but the relationship between fluorescence and action potentials (APs) remains unclear. Most APs can be detected when the soma almost fills the microscope's field of view, but calcium indicators are often used to image populations of neurons, necessitating a large field of view, generating fewer photons per neuron, and compromising AP detection. Here we characterized the AP-fluorescence transfer function in vivo for 48 layer 2/3 pyramidal neurons in primary visual cortex, with simultaneous calcium imaging and cell-attached recordings from transgenic mice expressing GCaMP6s or GCaMP6f. While most APs were detected under optimal conditions, under conditions typical of population imaging studies only a minority of 1AP and 2AP events were detected (often {\textless}10\% and {\textasciitilde}20-30\%, respectively), emphasizing the limits of AP detection under more realistic imaging conditions.},
	urldate = {2021-03-10},
	journal = {eLife},
	author = {Huang, Lawrence and Ledochowitsch, Peter and Knoblich, Ulf and Lecoq, Jérôme and Murphy, Gabe J and Reid, Clay and de Vries, Saskia E J and Koch, Christof and Zeng, Hongkui and Buice, Michael A and Waters, Jack and Li, Lu},
	editor = {Westbrook, Gary L},
	month = mar,
	year = {2021},
	note = {Publisher: eLife Sciences Publications, Ltd},
	pages = {e51675},
	file = {Huang et al_2021_Relationship between simultaneously recorded spiking activity and fluorescence.pdf:/Users/tito/Zotero/storage/X6WVPN7R/Huang et al_2021_Relationship between simultaneously recorded spiking activity and fluorescence.pdf:application/pdf},
}

@article{ilse_efficient_2021,
	title = {Efficient {Causal} {Inference} from {Combined} {Observational} and {Interventional} {Data} through {Causal} {Reductions}},
	url = {http://arxiv.org/abs/2103.04786},
	abstract = {Unobserved confounding is one of the main challenges when estimating causal effects. We propose a novel causal reduction method that replaces an arbitrary number of possibly high-dimensional latent confounders with a single latent confounder that lives in the same space as the treatment variable without changing the observational and interventional distributions entailed by the causal model. After the reduction, we parameterize the reduced causal model using a flexible class of transformations, so-called normalizing flows. We propose a learning algorithm to estimate the parameterized reduced model jointly from observational and interventional data. This allows us to estimate the causal effect in a principled way from combined data. We perform a series of experiments on data simulated using nonlinear causal mechanisms and find that we can often substantially reduce the number of interventional samples when adding observational training samples without sacrificing accuracy. Thus, adding observational data may help to more accurately estimate causal effects even in the presence of unobserved confounders.},
	urldate = {2021-03-10},
	journal = {arXiv:2103.04786 [cs, stat]},
	author = {Ilse, Maximilian and Forré, Patrick and Welling, Max and Mooij, Joris M.},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.04786},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/tito/Zotero/storage/R54CX62X/Ilse et al. - 2021 - Efficient Causal Inference from Combined Observati.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/QVKIN2GX/2103.html:text/html},
}

@article{santoro_symbolic_2021-1,
	title = {Symbolic {Behaviour} in {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2102.03406},
	abstract = {The ability to use symbols is the pinnacle of human intelligence, but has yet to be fully replicated in machines. Here we argue that the path towards symbolically fluent artificial intelligence (AI) begins with a reinterpretation of what symbols are, how they come to exist, and how a system behaves when it uses them. We begin by offering an interpretation of symbols as entities whose meaning is established by convention. But crucially, something is a symbol only for those who demonstrably and actively participate in this convention. We then outline how this interpretation thematically unifies the behavioural traits humans exhibit when they use symbols. This motivates our proposal that the field place a greater emphasis on symbolic behaviour rather than particular computational mechanisms inspired by more restrictive interpretations of symbols. Finally, we suggest that AI research explore social and cultural engagement as a tool to develop the cognitive machinery necessary for symbolic behaviour to emerge. This approach will allow for AI to interpret something as symbolic on its own rather than simply manipulate things that are only symbols to human onlookers, and thus will ultimately lead to AI with more human-like symbolic fluency.},
	urldate = {2021-03-11},
	journal = {arXiv:2102.03406 [cs]},
	author = {Santoro, Adam and Lampinen, Andrew and Mathewson, Kory and Lillicrap, Timothy and Raposo, David},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.03406},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tito/Zotero/storage/MZDLDPLT/Santoro et al. - 2021 - Symbolic Behaviour in Artificial Intelligence.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/SGIF5KNN/2102.html:text/html},
}

@article{nogueira_effects_2020,
	title = {The {Effects} of {Population} {Tuning} and {Trial}-by-{Trial} {Variability} on {Information} {Encoding} and {Behavior}},
	volume = {40},
	copyright = {Copyright © 2020 the authors},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/40/5/1066},
	doi = {10.1523/JNEUROSCI.0859-19.2019},
	abstract = {Identifying the features of population responses that are relevant to the amount of information encoded by neuronal populations is a crucial step toward understanding population coding. Statistical features, such as tuning properties, individual and shared response variability, and global activity modulations, could all affect the amount of information encoded and modulate behavioral performance. We show that two features in particular affect information: the modulation of population responses across conditions (population signal) and the inverse population covariability along the modulation axis (projected precision). We demonstrate that fluctuations of these two quantities are correlated with fluctuations of behavioral performance in various tasks and brain regions consistently across 4 monkeys (1 female and 1 male Macaca mulatta; and 2 male Macaca fascicularis). In contrast, fluctuations in mean correlations among neurons and global activity have negligible or inconsistent effects on the amount of information encoded and behavioral performance. We also show that differential correlations reduce the amount of information encoded in finite populations by reducing projected precision. Our results are consistent with predictions of a model that optimally decodes population responses to produce behavior.
SIGNIFICANCE STATEMENT The last two or three decades of research have seen hot debates about what features of population tuning and trial-by-trial variability influence the information carried by a population of neurons, with some camps arguing, for instance, that mean pairwise correlations or global fluctuations are important while other camps report opposite results. In this study, we identify the most important features of neural population responses that determine the amount of encoded information and behavioral performance by combining analytic calculations with a novel nonparametric method that allows us to isolate the effects of different statistical features. We tested our hypothesis on 4 macaques, three decision-making tasks, and two brain areas. The predictions of our theory were in agreement with the experimental data.},
	language = {en},
	number = {5},
	urldate = {2021-03-12},
	journal = {J. Neurosci.},
	author = {Nogueira, Ramon and Peltier, Nicole E. and Anzai, Akiyuki and DeAngelis, Gregory C. and Martínez-Trujillo, Julio and Moreno-Bote, Rubén},
	month = jan,
	year = {2020},
	pmid = {31754013},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {noise correlations, attention, sensory processing, PFC, global activity, MT/V5},
	pages = {1066--1083},
	file = {Full Text PDF:/Users/tito/Zotero/storage/Q8UFJG4Z/Nogueira et al. - 2020 - The Effects of Population Tuning and Trial-by-Tria.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AQ3WI5XG/1066.html:text/html},
}

@article{rafeh_information-limiting_2020,
	title = {Information-{Limiting} {Correlations} in {Neural} {Populations}: {The} {Devil} {Is} in the {Details}},
	volume = {40},
	issn = {0270-6474, 1529-2401},
	shorttitle = {Information-{Limiting} {Correlations} in {Neural} {Populations}},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0917-20.2020},
	doi = {10.1523/JNEUROSCI.0917-20.2020},
	language = {en},
	number = {41},
	urldate = {2021-03-12},
	journal = {J. Neurosci.},
	author = {Rafeh, Reebal and Gupta, Geetika},
	month = oct,
	year = {2020},
	pages = {7782--7784},
	file = {Rafeh and Gupta - 2020 - Information-Limiting Correlations in Neural Popula.pdf:/Users/tito/Zotero/storage/AG8EEMXN/Rafeh and Gupta - 2020 - Information-Limiting Correlations in Neural Popula.pdf:application/pdf},
}

@article{vreeswijk_chaos_1996-1,
	title = {Chaos in {Neuronal} {Networks} with {Balanced} {Excitatory} and {Inhibitory} {Activity}},
	volume = {274},
	copyright = {© 1996 American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/274/5293/1724},
	doi = {10.1126/science.274.5293.1724},
	abstract = {Neurons in the cortex of behaving animals show temporally irregular spiking patterns. The origin of this irregularity and its implications for neural processing are unknown. The hypothesis that the temporal variability in the firing of a neuron results from an approximate balance between its excitatory and inhibitory inputs was investigated theoretically. Such a balance emerges naturally in large networks of excitatory and inhibitory neuronal populations that are sparsely connected by relatively strong synapses. The resulting state is characterized by strongly chaotic dynamics, even when the external inputs to the network are constant in time. Such a network exhibits a linear response, despite the highly nonlinear dynamics of single neurons, and reacts to changing external stimuli on time scales much smaller than the integration time constant of a single neuron.},
	language = {en},
	number = {5293},
	urldate = {2021-03-15},
	journal = {Science},
	author = {Vreeswijk, C. van and Sompolinsky, H.},
	month = dec,
	year = {1996},
	pmid = {8939866},
	note = {Publisher: American Association for the Advancement of Science
Section: Reports},
	pages = {1724--1726},
	file = {Full Text PDF:/Users/tito/Zotero/storage/4TCHEXK4/Vreeswijk and Sompolinsky - 1996 - Chaos in Neuronal Networks with Balanced Excitator.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/B7B3LNUJ/1724.html:text/html},
}

@article{sompolinsky_chaos_1988,
	title = {Chaos in {Random} {Neural} {Networks}},
	volume = {61},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.61.259},
	doi = {10.1103/PhysRevLett.61.259},
	abstract = {A continuous-time dynamic model of a network of N nonlinear elements interacting via random asymmetric couplings is studied. A self-consistent mean-field theory, exact in the N→∞ limit, predicts a transition from a stationary phase to a chaotic phase occurring at a critical value of the gain parameter. The autocorrelations of the chaotic flow as well as the maximal Lyapunov exponent are calculated.},
	number = {3},
	urldate = {2021-03-15},
	journal = {Phys. Rev. Lett.},
	author = {Sompolinsky, H. and Crisanti, A. and Sommers, H. J.},
	month = jul,
	year = {1988},
	note = {Publisher: American Physical Society},
	pages = {259--262},
	file = {APS Snapshot:/Users/tito/Zotero/storage/7QTLTDMA/PhysRevLett.61.html:text/html;Full Text PDF:/Users/tito/Zotero/storage/MT4GQNAW/Sompolinsky et al. - 1988 - Chaos in Random Neural Networks.pdf:application/pdf},
}

@article{sanchez-romero_combining_2021,
	title = {Combining {Multiple} {Functional} {Connectivity} {Methods} to {Improve} {Causal} {Inferences}},
	volume = {33},
	issn = {0898-929X, 1530-8898},
	url = {https://direct.mit.edu/jocn/article/33/2/180-194/95537},
	doi = {10.1162/jocn_a_01580},
	abstract = {Cognition and behavior emerge from brain network interactions, suggesting that causal interactions should be central to the study of brain function. Yet, approaches that characterize relationships among neural time series—functional connectivity (FC) methods—are dominated by methods that assess bivariate statistical associations rather than causal interactions. Such bivariate approaches result in substantial false positives because they do not account for confounders (common causes) among neural populations. A major reason for the dominance of methods such as bivariate Pearson correlation (with functional MRI) and coherence (with electrophysiological methods) may be their simplicity. Thus, we sought to identify an FC method that was both simple and improved causal inferences relative to the most popular methods. We started with partial correlation, showing with neural network simulations that this substantially improves causal inferences relative to bivariate correlation. However, the presence of colliders (common effects) in a network resulted in false positives with partial correlation, although this was not a problem for bivariate correlations. This led us to propose a new combined FC method (combinedFC) that incorporates simple bivariate and partial correlation FC measures to make more valid causal inferences than either alone. We release a toolbox for implementing this new combinedFC method to facilitate improvement of FC-based causal inferences. CombinedFC is a general method for FC and can be applied equally to resting-state and task-based paradigms.},
	language = {en},
	number = {2},
	urldate = {2021-03-16},
	journal = {Journal of Cognitive Neuroscience},
	author = {Sanchez-Romero, Ruben and Cole, Michael W.},
	month = feb,
	year = {2021},
	pages = {180--194},
	file = {Sanchez-Romero and Cole - 2021 - Combining Multiple Functional Connectivity Methods.pdf:/Users/tito/Zotero/storage/UPUNW6QP/Sanchez-Romero and Cole - 2021 - Combining Multiple Functional Connectivity Methods.pdf:application/pdf},
}

@article{handwerker_continuing_2012,
	series = {20 {YEARS} {OF} {fMRI}},
	title = {The continuing challenge of understanding and modeling hemodynamic variation in {fMRI}},
	volume = {62},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811912001929},
	doi = {10.1016/j.neuroimage.2012.02.015},
	abstract = {Interpretation of fMRI data depends on our ability to understand or model the shape of the hemodynamic response (HR) to a neural event. Although the HR has been studied almost since the beginning of fMRI, we are still far from having robust methods to account for the full range of known HR variation in typical fMRI analyses. This paper reviews how the authors and others contributed to our understanding of HR variation. We present an overview of studies that describe HR variation across voxels, healthy volunteers, populations, and dietary or pharmaceutical modulations. We also describe efforts to minimize the effects of HR variation in intrasubject, group, population, and connectivity analyses and the limits of these methods.},
	language = {en},
	number = {2},
	urldate = {2021-03-17},
	journal = {NeuroImage},
	author = {Handwerker, Daniel A. and Gonzalez-Castillo, Javier and D'Esposito, Mark and Bandettini, Peter A.},
	month = aug,
	year = {2012},
	keywords = {fMRI, BOLD, Blood vessels, Hemodynamic response, Population studies, Regional variation},
	pages = {1017--1023},
	file = {Accepted Version:/Users/tito/Zotero/storage/R597P9W8/Handwerker et al. - 2012 - The continuing challenge of understanding and mode.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3VIP6ZNZ/S1053811912001929.html:text/html},
}

@article{kemp_discovery_2008,
	title = {The discovery of structural form},
	volume = {105},
	copyright = {© 2008 by The National Academy of Sciences of the USA.                          Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/105/31/10687},
	doi = {10.1073/pnas.0802631105},
	abstract = {Algorithms for finding structure in data have become increasingly important both as tools for scientific data analysis and as models of human learning, yet they suffer from a critical limitation. Scientists discover qualitatively new forms of structure in observed data: For instance, Linnaeus recognized the hierarchical organization of biological species, and Mendeleev recognized the periodic structure of the chemical elements. Analogous insights play a pivotal role in cognitive development: Children discover that object category labels can be organized into hierarchies, friendship networks are organized into cliques, and comparative relations (e.g., “bigger than” or “better than”) respect a transitive order. Standard algorithms, however, can only learn structures of a single form that must be specified in advance: For instance, algorithms for hierarchical clustering create tree structures, whereas algorithms for dimensionality-reduction create low-dimensional spaces. Here, we present a computational model that learns structures of many different forms and that discovers which form is best for a given dataset. The model makes probabilistic inferences over a space of graph grammars representing trees, linear orders, multidimensional spaces, rings, dominance hierarchies, cliques, and other forms and successfully discovers the underlying structure of a variety of physical, biological, and social domains. Our approach brings structure learning methods closer to human abilities and may lead to a deeper computational understanding of cognitive development.},
	language = {en},
	number = {31},
	urldate = {2021-03-18},
	journal = {PNAS},
	author = {Kemp, Charles and Tenenbaum, Joshua B.},
	month = aug,
	year = {2008},
	pmid = {18669663},
	note = {Publisher: National Academy of Sciences
Section: Physical Sciences},
	keywords = {unsupervised learning, cognitive development, structure discovery},
	pages = {10687--10692},
	file = {Full Text PDF:/Users/tito/Zotero/storage/84CM46XA/Kemp and Tenenbaum - 2008 - The discovery of structural form.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IW5MLLPF/10687.html:text/html},
}

@article{lu_pretrained_2021,
	title = {Pretrained {Transformers} as {Universal} {Computation} {Engines}},
	url = {http://arxiv.org/abs/2103.05247},
	abstract = {We investigate the capability of a transformer pretrained on natural language to generalize to other modalities with minimal finetuning -- in particular, without finetuning of the self-attention and feedforward layers of the residual blocks. We consider such a model, which we call a Frozen Pretrained Transformer (FPT), and study finetuning it on a variety of sequence classification tasks spanning numerical computation, vision, and protein fold prediction. In contrast to prior works which investigate finetuning on the same modality as the pretraining dataset, we show that pretraining on natural language improves performance and compute efficiency on non-language downstream tasks. In particular, we find that such pretraining enables FPT to generalize in zero-shot to these modalities, matching the performance of a transformer fully trained on these tasks.},
	urldate = {2021-03-19},
	journal = {arXiv:2103.05247 [cs]},
	author = {Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.05247},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tito/Zotero/storage/44KDURT6/Lu et al. - 2021 - Pretrained Transformers as Universal Computation E.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/TNF7LYWW/2103.html:text/html},
}

@article{wu_brain_2021,
	title = {Brain kernel: a new spatial covariance function for {fMRI} data},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Brain kernel},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.22.436524v1},
	doi = {10.1101/2021.03.22.436524},
	abstract = {{\textless}p{\textgreater}A key problem in functional magnetic resonance imaging (fMRI) is to estimate spatial activity patterns from noisy high-dimensional signals. Spatial smoothing provides one approach to regularizing such estimates. However, standard smoothing methods ignore the fact that correlations in neural activity may fall off at different rates in different brain areas, or exhibit discontinuities across anatomical or functional boundaries. Moreover, such methods do not exploit the fact that widely separated brain regions may exhibit strong correlations due to bilateral symmetry or the network organization of brain regions. To capture this non-stationary spatial correlation structure, we introduce the brain kernel, a continuous covariance function for whole-brain activity patterns. We define the brain kernel in terms of a continuous nonlinear mapping from 3D brain coordinates to a latent embedding space, parametrized with a Gaussian process (GP). The brain kernel specifies the prior covariance between voxels as a function of the distance between their locations in embedding space. The GP mapping warps the brain nonlinearly so that highly correlated voxels are close together in latent space, and uncorrelated voxels are far apart. We estimate the brain kernel using resting-state fMRI data, and we develop an exact, scalable inference method based on block coordinate descent to overcome the challenges of high dimensionality (10-100K voxels). Finally, we illustrate the brain kernel9s usefulness with applications to brain decoding and factor analysis with multiple task-based fMRI datasets.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-03-24},
	journal = {bioRxiv},
	author = {Wu, Anqi and Nastase, Samuel A. and Baldassano, Christopher A. and Turk-Browne, Nicholas B. and Norman, Kenneth A. and Engelhardt, Barbara E. and Pillow, Jonathan W.},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.22.436524},
	file = {Full Text PDF:/Users/tito/Zotero/storage/8F7IZPWV/Wu et al. - 2021 - Brain kernel a new spatial covariance function fo.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IFHI7QU7/2021.03.22.html:text/html},
}

@article{cole_functional_2021,
	title = {The {Functional} {Relevance} of {Task}-{State} {Functional} {Connectivity}},
	volume = {41},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1713-20.2021},
	doi = {10.1523/JNEUROSCI.1713-20.2021},
	language = {en},
	number = {12},
	urldate = {2021-03-25},
	journal = {J. Neurosci.},
	author = {Cole, Michael W. and Ito, Takuya and Cocuzza, Carrisa and Sanchez-Romero, Ruben},
	month = mar,
	year = {2021},
	pages = {2684--2702},
	file = {Cole et al. - 2021 - The Functional Relevance of Task-State Functional .pdf:/Users/tito/Zotero/storage/MRWVKN7T/Cole et al. - 2021 - The Functional Relevance of Task-State Functional .pdf:application/pdf},
}

@article{dehaene_investigating_2021,
	title = {Investigating the representation of uncertainty in neuronal circuits},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008138},
	doi = {10.1371/journal.pcbi.1008138},
	abstract = {Skilled behavior often displays signatures of Bayesian inference. In order for the brain to implement the required computations, neuronal activity must carry accurate information about the uncertainty of sensory inputs. Two major approaches have been proposed to study neuronal representations of uncertainty. The first one, the Bayesian decoding approach, aims primarily at decoding the posterior probability distribution of the stimulus from population activity using Bayes’ rule, and indirectly yields uncertainty estimates as a by-product. The second one, which we call the correlational approach, searches for specific features of neuronal activity (such as tuning-curve width and maximum firing-rate) which correlate with uncertainty. To compare these two approaches, we derived a new normative model of sound source localization by Interaural Time Difference (ITD), that reproduces a wealth of behavioral and neural observations. We found that several features of neuronal activity correlated with uncertainty on average, but none provided an accurate estimate of uncertainty on a trial-by-trial basis, indicating that the correlational approach may not reliably identify which aspects of neuronal responses represent uncertainty. In contrast, the Bayesian decoding approach reveals that the activity pattern of the entire population was required to reconstruct the trial-to-trial posterior distribution with Bayes’ rule. These results suggest that uncertainty is unlikely to be represented in a single feature of neuronal activity, and highlight the importance of using a Bayesian decoding approach when exploring the neural basis of uncertainty.},
	language = {en},
	number = {2},
	urldate = {2021-03-25},
	journal = {PLOS Computational Biology},
	author = {Dehaene, Guillaume P. and Coen-Cagli, Ruben and Pouget, Alexandre},
	month = feb,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Behavior, Neurons, Sensory perception, White noise, Single neuron function, Neuronal tuning, Ears, Signal filtering},
	pages = {e1008138},
	file = {Dehaene et al_2021_Investigating the representation of uncertainty in neuronal circuits.pdf:/Users/tito/Zotero/storage/XWC3B5J6/Dehaene et al_2021_Investigating the representation of uncertainty in neuronal circuits.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IGE2C9UZ/article.html:text/html},
}

@article{yan_task-induced_2021,
	title = {Task-induced activation transmitted by structural connectivity is associated with behavioral performance},
	issn = {1863-2661},
	url = {https://doi.org/10.1007/s00429-021-02249-0},
	doi = {10.1007/s00429-021-02249-0},
	abstract = {It is thought that brain structure is the primary determinant of functions of brain regions. For example, cortical areas with functional differences also have different structural connectivity (SC) patterns. We used SCs derived from diffusion tensor imaging (DTI) data in 100 healthy adults included in the Human Connectome Project (HCP) to successfully predict cortical activation responses across distinct cognitive tasks and found that predictive performance varied among tasks. We also observed that predictive performance could be used to characterize task load in both relational reasoning and N-back working memory tasks and was significantly positively associated with behavioral performance. Moreover, we found that the default mode network (DMN) played a more dominant role in both activation prediction and behavioral performance than was found for other functional networks. These results support our hypothesis that individuals who performed tasks better might exhibit a more accurate predicted activation pattern as task-evoked activities are more inclined to flow over inherent structural networks than over more flexible paths. In the high difficulty condition, the decreased correlation between predicted and empirical activation may be associated with the more random brain activity in these conditions/participants due to the lack of engagement. Together, our findings highlight the feasibility of using SCs to estimate various cognitive task activations and thus further facilitate the exploration of the relationship between the brain and behavior by providing strong evidence for the relevance of structure to function in the human brain.},
	language = {en},
	urldate = {2021-03-26},
	journal = {Brain Struct Funct},
	author = {Yan, Tianyi and Liu, Tiantian and Ai, Jing and Shi, Zhongyan and Zhang, Jian and Pei, Guangying and Wu, Jinglong},
	month = mar,
	year = {2021},
	file = {Yan et al_2021_Task-induced activation transmitted by structural connectivity is associated.pdf:/Users/tito/Zotero/storage/EVCIJMHB/Yan et al_2021_Task-induced activation transmitted by structural connectivity is associated.pdf:application/pdf},
}

@article{leavitt_towards_2020,
	title = {Towards falsifiable interpretability research},
	url = {http://arxiv.org/abs/2010.12016},
	abstract = {Methods for understanding the decisions of and mechanisms underlying deep neural networks (DNNs) typically rely on building intuition by emphasizing sensory or semantic features of individual examples. For instance, methods aim to visualize the components of an input which are "important" to a network's decision, or to measure the semantic properties of single neurons. Here, we argue that interpretability research suffers from an over-reliance on intuition-based approaches that risk-and in some cases have caused-illusory progress and misleading conclusions. We identify a set of limitations that we argue impede meaningful progress in interpretability research, and examine two popular classes of interpretability methods-saliency and single-neuron-based approaches-that serve as case studies for how overreliance on intuition and lack of falsifiability can undermine interpretability research. To address these concerns, we propose a strategy to address these impediments in the form of a framework for strongly falsifiable interpretability research. We encourage researchers to use their intuitions as a starting point to develop and test clear, falsifiable hypotheses, and hope that our framework yields robust, evidence-based interpretability methods that generate meaningful advances in our understanding of DNNs.},
	urldate = {2021-03-29},
	journal = {arXiv:2010.12016 [cs, stat]},
	author = {Leavitt, Matthew L. and Morcos, Ari},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.12016},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computers and Society},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/W4AVID2N/2010.html:text/html;Leavitt_Morcos_2020_Towards falsifiable interpretability research.pdf:/Users/tito/Zotero/storage/J3XZD5FC/Leavitt_Morcos_2020_Towards falsifiable interpretability research.pdf:application/pdf},
}

@article{sorscher_geometry_2021,
	title = {The {Geometry} of {Concept} {Learning}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.21.436284v1},
	doi = {10.1101/2021.03.21.436284},
	abstract = {{\textless}p{\textgreater}Understanding the neural basis of our remarkable cognitive capacity to accurately learn novel high-dimensional naturalistic concepts from just one or a few sensory experiences constitutes a fundamental problem. We propose a simple, biologically plausible, mathematically tractable, and computationally powerful neural mechanism for few-shot learning of naturalistic concepts. We posit that the concepts we can learn given few examples are defined by tightly circumscribed manifolds in the neural firing rate space of higher order sensory areas. We further posit that a single plastic downstream neuron can learn such concepts from few examples using a simple plasticity rule. We demonstrate the computational power of our simple proposal by showing it can achieve high few-shot learning accuracy on natural visual concepts using both macaque inferotemporal cortex representations and deep neural network models of these representations, and can even learn novel visual concepts specified only through language descriptions. Moreover, we develop a mathematical theory of few-shot learning that links neurophysiology to behavior by delineating several fundamental and measurable geometric properties of high-dimensional neural representations that can accurately predict the few-shot learning performance of naturalistic concepts across all our experiments. We discuss several implications of our theory for past and future studies in neuroscience, psychology and machine learning.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-03-29},
	journal = {bioRxiv},
	author = {Sorscher, Ben and Ganguli, Surya and Sompolinsky, Haim},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.21.436284},
	file = {Sorscher et al_2021_The Geometry of Concept Learning.pdf:/Users/tito/Zotero/storage/7JXEARDU/Sorscher et al_2021_The Geometry of Concept Learning.pdf:application/pdf},
}

@article{urai_large-scale_2021,
	title = {Large-scale neural recordings call for new insights to link brain and behavior},
	url = {http://arxiv.org/abs/2103.14662},
	abstract = {Neuroscientists today can measure activity from more neurons than ever before, and are facing the challenge of connecting these brain-wide neural recordings to computation and behavior. Here, we first describe emerging tools and technologies being used to probe large-scale brain activity and new approaches to characterize behavior in the context of such measurements. We next highlight insights obtained from large-scale neural recordings in diverse model systems, and argue that some of these pose a challenge to traditional theoretical frameworks. Finally, we elaborate on existing modelling frameworks to interpret these data, and argue that interpreting brain-wide neural recordings calls for new theoretical approaches that may depend on the desired level of understanding at stake. These advances in both neural recordings and theory development will pave the way for critical advances in our understanding of the brain.},
	urldate = {2021-03-31},
	journal = {arXiv:2103.14662 [q-bio]},
	author = {Urai, Anne E. and Doiron, Brent and Leifer, Andrew M. and Churchland, Anne K.},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.14662},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/NXG75DRV/2103.html:text/html;Urai et al_2021_Large-scale neural recordings call for new insights to link brain and behavior.pdf:/Users/tito/Zotero/storage/CVLPR8AD/Urai et al_2021_Large-scale neural recordings call for new insights to link brain and behavior.pdf:application/pdf},
}

@article{munn_ascending_2021,
	title = {The ascending arousal system shapes low-dimensional brain dynamics to mediate awareness of changes in intrinsic cognitive states},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.30.437635v1},
	doi = {10.1101/2021.03.30.437635},
	abstract = {{\textless}p{\textgreater}Models of cognitive function typically focus on the cerebral cortex, ignoring functional links to subcortical structures. This view neglects the highly-conserved ascending arousal system9s role and the computational capacities it provides the brain. In this study, we test the hypothesis that the ascending arousal system modulates cortical neural gain to alter brain dynamics9 low-dimensional attractor landscape. Our analyses of spontaneous functional magnetic resonance imaging data and phasic bursts in both locus coeruleus and basal forebrain demonstrate precise time-locked relationships between brainstem activity, low-dimensional energy landscapes, network topology, and spatiotemporal travelling waves. We extend our analysis to a cohort of experienced meditators and demonstrate locus coeruleus-mediated network dynamics were associated with internal shifts in conscious awareness. Together, these results present a novel view of brain organization that highlights the ascending arousal system9s role in shaping both the dynamics of the cerebral cortex and conscious awareness.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-01},
	journal = {bioRxiv},
	author = {Munn, Brandon and Müller, Eli J. and Wainstein, Gabriel and Shine, James M.},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.30.437635},
	file = {Munn et al_2021_The ascending arousal system shapes low-dimensional brain dynamics to mediate.pdf:/Users/tito/Zotero/storage/7Y9CWUD3/Munn et al_2021_The ascending arousal system shapes low-dimensional brain dynamics to mediate.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZUQN6ICZ/2021.03.30.html:text/html},
}

@article{srinath_attention_2021,
	title = {Attention improves information flow between neuronal populations without changing the communication subspace},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.31.437940v1},
	doi = {10.1101/2021.03.31.437940},
	abstract = {{\textless}p{\textgreater}Visual attention allows observers to flexibly use or ignore visual information, suggesting that information can be flexibly routed between visual cortex and neurons involved in decision-making. We investigated the neural substrate of flexible information routing by analyzing the activity of populations of visual neurons in the medial temporal area (MT) and oculomotor neurons in the superior colliculus (SC) while rhesus monkeys switched spatial attention. We demonstrated that attention increases the efficacy of visuomotor communication: trial-to-trial variability of the population of SC neurons was better predicted by the activity of MT neurons (and vice versa) when attention was directed toward their joint receptive fields. Surprisingly, this improvement in prediction was not explained or accompanied by changes in the dimensionality of the shared subspace or in local or shared pairwise noise correlations. These results suggest a mechanism by which visual attention can affect perceptual decision-making without altering local neuronal representations.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-01},
	journal = {bioRxiv},
	author = {Srinath, Ramanujan and Ruff, Douglas A. and Cohen, Marlene R.},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.31.437940},
	file = {Snapshot:/Users/tito/Zotero/storage/8SDLWVUB/2021.03.31.html:text/html;Srinath et al_2021_Attention improves information flow between neuronal populations without.pdf:/Users/tito/Zotero/storage/KH694HCG/Srinath et al_2021_Attention improves information flow between neuronal populations without.pdf:application/pdf},
}

@article{bordelon_population_2021,
	title = {Population {Codes} {Enable} {Learning} from {Few} {Examples} {By} {Shaping} {Inductive} {Bias}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.30.437743v1},
	doi = {10.1101/2021.03.30.437743},
	abstract = {{\textless}p{\textgreater}The brain can learn from a limited number of experiences, an ability which requires suitable built in assumptions about the nature of the tasks which must be learned, or inductive biases. While inductive biases are central components of intelligence, how they are reflected in and shaped by population codes are not well-understood. To address this question, we consider biologically-plausible reading out of an arbitrary stimulus-response pattern from an arbitrary population code, and develop an analytical theory that predicts the generalization error of the readout as a function of the number of samples. We find that learning performance is controlled by the eigenspectrum of the population code9s inner-product kernel, which measures the similarity of neural responses to two different input stimuli. Many different codes can realize the same kernel; by analyzing recordings from the mouse primary visual cortex, we demonstrate that biological codes are metabolically more efficient than other codes with identical kernels. We demonstrate that the spectral properties of the kernel introduce an inductive bias toward explaining stimulus-response samples with simple functions and determine compatibility of the population code with learning task, and hence the sample-efficiency of learning. While the tail of the spectrum is important for large sample size behavior of learning, for small sample sizes, the bulk of the spectrum governs generalization. We apply our theory to experimental recordings of mouse primary visual cortex neural responses, elucidating a bias towards sample-efficient learning of low frequency orientation discrimination tasks. We demonstrate this emergence of this bias in a simple model of primary visual cortex, and further show how invariances in the code to stimulus variations affect learning performance. Finally, we demonstrate that our methods are applicable to time-dependent neural codes. Overall, our study suggests sample-efficient learning as a general normative coding principle.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-01},
	journal = {bioRxiv},
	author = {Bordelon, Blake and Pehlevan, Cengiz},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.30.437743},
	file = {Bordelon_Pehlevan_2021_Population Codes Enable Learning from Few Examples By Shaping Inductive Bias.pdf:/Users/tito/Zotero/storage/QW4FXHHK/Bordelon_Pehlevan_2021_Population Codes Enable Learning from Few Examples By Shaping Inductive Bias.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FID7MJSD/2021.03.30.html:text/html},
}

@article{panichello_shared_2021,
	title = {Shared mechanisms underlie the control of working memory and attention},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03390-w},
	doi = {10.1038/s41586-021-03390-w},
	abstract = {Cognitive control guides behaviour by controlling what, when, and how information is represented in the brain1. For example, attention controls sensory processing; top-down signals from prefrontal and parietal cortex strengthen the representation of task-relevant stimuli2–4. A similar ‘selection’ mechanism is thought to control the representations held ‘in mind’—in working memory5–10. Here we show that shared neural mechanisms underlie the selection of items from working memory and attention to sensory stimuli. We trained rhesus monkeys to switch between two tasks, either selecting one item from a set of items held in working memory or attending to one stimulus from a set of visual stimuli. Neural recordings showed that similar representations in prefrontal cortex encoded the control of both selection and attention, suggesting that prefrontal cortex acts as a domain-general controller. By contrast, both attention and selection were represented independently in parietal and visual cortex. Both selection and attention facilitated behaviour by enhancing and transforming the representation of the selected memory or attended stimulus. Specifically, during the selection task, memory items were initially represented in independent subspaces of neural activity in prefrontal cortex. Selecting an item caused its representation to transform from its own subspace to a new subspace used to guide behaviour. A similar transformation occurred for attention. Our results suggest that prefrontal cortex controls cognition by dynamically transforming representations to control what and when cognitive computations are engaged.},
	language = {en},
	urldate = {2021-04-02},
	journal = {Nature},
	author = {Panichello, Matthew F. and Buschman, Timothy J.},
	month = mar,
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	pages = {1--5},
	file = {Panichello_Buschman_2021_Shared mechanisms underlie the control of working memory and attention.pdf:/Users/tito/Zotero/storage/C72BQWLB/Panichello_Buschman_2021_Shared mechanisms underlie the control of working memory and attention.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IZHSCZPW/s41586-021-03390-w.html:text/html},
}

@article{sejnowski_unreasonable_2020,
	title = {The unreasonable effectiveness of deep learning in artificial intelligence},
	volume = {117},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/117/48/30033},
	doi = {10.1073/pnas.1907373117},
	abstract = {Deep learning networks have been trained to recognize speech, caption photographs, and translate text between languages at high levels of performance. Although applications of deep learning networks to real-world problems have become ubiquitous, our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces. A mathematical theory of deep learning would illuminate how they function, allow us to assess the strengths and weaknesses of different network architectures, and lead to major improvements. Deep learning has provided natural ways for humans to communicate with digital devices and is foundational for building artificial general intelligence. Deep learning was inspired by the architecture of the cerebral cortex and insights into autonomy and general intelligence may be found in other brain regions that are essential for planning and survival, but major breakthroughs will be needed to achieve these goals.},
	language = {en},
	number = {48},
	urldate = {2021-04-05},
	journal = {PNAS},
	author = {Sejnowski, Terrence J.},
	month = dec,
	year = {2020},
	pmid = {31992643},
	note = {Publisher: National Academy of Sciences
Section: Colloquium Paper},
	keywords = {artificial intelligence, neural networks, deep learning},
	pages = {30033--30038},
	file = {Sejnowski_2020_The unreasonable effectiveness of deep learning in artificial intelligence.pdf:/Users/tito/Zotero/storage/RFX82QEI/Sejnowski_2020_The unreasonable effectiveness of deep learning in artificial intelligence.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FKDJ8HEG/30033.html:text/html},
}

@article{rue-queralt_decoding_2021,
	title = {Decoding brain states on the intrinsic manifold of human brain dynamics across wakefulness and sleep},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.23.436551v1},
	doi = {10.1101/2021.03.23.436551},
	abstract = {{\textless}p{\textgreater}Current state-of-the-art functional magnetic resonance imaging (fMRI) offers remarkable imaging quality and resolution, yet, the intrinsic dimensionality of brain dynamics in different states (wakefulness, light and deep sleep) remains unknown. Here we present a novel method to reveal the low dimensional intrinsic manifold underlying human brain dynamics, which is invariant of the high dimensional spatio-temporal representation of the neuroimaging technology. By applying this novel intrinsic manifold framework to fMRI data acquired in wakefulness and sleep, we reveal the nonlinear differences between wakefulness and three different sleep stages, and successfully decode these different brain states with an average accuracy of 96\%. Remarkably, a further group analysis shows that the intrinsic manifolds of all participants share a common topology. Overall, our results reveal the intrinsic manifold underlying the spatiotemporal dynamics of brain activity and demonstrate how this manifold enables the decoding of different brain states such as wakefulness and various sleep stages.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-07},
	journal = {bioRxiv},
	author = {Rué-Queralt, J. and Stevner, A. and Tagliazucchi, E. and Laufs, H. and Kringelbach, M. L. and Deco, G. and Atasoy, S.},
	month = mar,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.03.23.436551},
	file = {Rué-Queralt et al_2021_Decoding brain states on the intrinsic manifold of human brain dynamics across.pdf:/Users/tito/Zotero/storage/9HZJ6RVW/Rué-Queralt et al_2021_Decoding brain states on the intrinsic manifold of human brain dynamics across.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/B4JH476D/2021.03.23.html:text/html},
}

@article{knight_dynamics_1972,
	title = {Dynamics of {Encoding} in a {Population} of {Neurons}},
	volume = {59},
	issn = {1540-7748, 0022-1295},
	url = {https://rupress.org/jgp/article/59/6/734/31064/Dynamics-of-Encoding-in-a-Population-of-Neurons},
	doi = {10.1085/jgp.59.6.734},
	abstract = {A simple encoder model, which is a reasonable idealization from known electrophysiological properties, yields a population in which the variation of the firing rate with time is a perfect replica of the shape of the input stimulus. A population of noise-free encoders which depart even slightly from the simple model yield a very much degraded copy of the input stimulus. The presence of noise improves the performance of such a population. The firing rate of a population of neurons is related to the firing rate of a single member in a subtle way.},
	language = {en},
	number = {6},
	urldate = {2021-04-07},
	journal = {Journal of General Physiology},
	author = {Knight, Bruce W.},
	month = jun,
	year = {1972},
	pages = {734--766},
	file = {Knight - 1972 - Dynamics of Encoding in a Population of Neurons.pdf:/Users/tito/Zotero/storage/IM5I8MTT/Knight - 1972 - Dynamics of Encoding in a Population of Neurons.pdf:application/pdf},
}

@article{mccormick_latent_2021,
	title = {Latent functional connectivity underlying multiple brain states},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.05.438534v1},
	doi = {10.1101/2021.04.05.438534},
	abstract = {{\textless}p{\textgreater}Functional connectivity (FC) studies have predominantly focused on resting state, where ongoing dynamics are thought to primarily reflect the brain9s intrinsic network architecture, which is thought to be broadly relevant to brain function because it persists across brain states. However, it is unknown whether resting state is the optimal state for measuring intrinsic FC. We propose that latent FC, reflecting patterns of connectivity shared across many brain states, may better capture intrinsic FC relative to measures derived from resting state alone. We estimated latent FC in relation to 7 highly distinct task states (24 task conditions) and resting state using fMRI data from 352 participants from the Human Connectome Project. Latent FC was estimated independently for each connection by applying leave-one-task-out factor analysis on the state FC estimates. Compared to resting-state connectivity, we found that latent connectivity improves generalization to held-out brain states, better explaining patterns of both connectivity and task-evoked brain activity. We also found that latent connectivity improved prediction of behavior, measured by the general intelligence factor psychometric g. Our results suggest that patterns of FC shared across many brain states, rather than just resting state, better reflects general, state-independent connectivity. This affirms the notion of "intrinsic" brain network architecture as a set of connectivity properties persistent across brain states, providing an updated conceptual and mathematical framework of intrinsic connectivity as a latent factor.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-07},
	journal = {bioRxiv},
	author = {McCormick, Ethan M. and Arnemann, Katelyn L. and Ito, Takuya and Hanson, Stephen Jose and Cole, Michael W.},
	month = apr,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.04.05.438534},
	file = {McCormick et al_2021_Latent functional connectivity underlying multiple brain states.pdf:/Users/tito/Zotero/storage/IRI8ZY6Z/McCormick et al_2021_Latent functional connectivity underlying multiple brain states.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/LXLZUVKX/2021.04.05.438534v1.full.html:text/html},
}

@article{leavitt_correlated_2017,
	title = {Correlated variability modifies working memory fidelity in primate prefrontal neuronal ensembles},
	volume = {114},
	copyright = {©  . http://www.pnas.org/site/misc/userlicense.xhtml},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/114/12/E2494},
	doi = {10.1073/pnas.1619949114},
	abstract = {Neurons in the primate lateral prefrontal cortex (LPFC) encode working memory (WM) representations via sustained firing, a phenomenon hypothesized to arise from recurrent dynamics within ensembles of interconnected neurons. Here, we tested this hypothesis by using microelectrode arrays to examine spike count correlations (rsc) in LPFC neuronal ensembles during a spatial WM task. We found a pattern of pairwise rsc during WM maintenance indicative of stronger coupling between similarly tuned neurons and increased inhibition between dissimilarly tuned neurons. We then used a linear decoder to quantify the effects of the high-dimensional rsc structure on information coding in the neuronal ensembles. We found that the rsc structure could facilitate or impair coding, depending on the size of the ensemble and tuning properties of its constituent neurons. A simple optimization procedure demonstrated that near-maximum decoding performance could be achieved using a relatively small number of neurons. These WM-optimized subensembles were more signal correlation (rsignal)-diverse and anatomically dispersed than predicted by the statistics of the full recorded population of neurons, and they often contained neurons that were poorly WM-selective, yet enhanced coding fidelity by shaping the ensemble’s rsc structure. We observed a pattern of rsc between LPFC neurons indicative of recurrent dynamics as a mechanism for WM-related activity and that the rsc structure can increase the fidelity of WM representations. Thus, WM coding in LPFC neuronal ensembles arises from a complex synergy between single neuron coding properties and multidimensional, ensemble-level phenomena.},
	language = {en},
	number = {12},
	urldate = {2021-04-08},
	journal = {PNAS},
	author = {Leavitt, Matthew L. and Pieper, Florian and Sachs, Adam J. and Martinez-Trujillo, Julio C.},
	month = mar,
	year = {2017},
	pmid = {28275096},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {noise correlations, prefrontal cortex, working memory, decoding, macaque},
	pages = {E2494--E2503},
	file = {Leavitt et al_2017_Correlated variability modifies working memory fidelity in primate prefrontal.pdf:/Users/tito/Zotero/storage/GKRMZUZU/Leavitt et al_2017_Correlated variability modifies working memory fidelity in primate prefrontal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WYXYPKKF/E2494.html:text/html},
}

@article{hong_toward_2020,
	title = {Toward a connectivity gradient-based framework for reproducible biomarker discovery},
	volume = {223},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920308089},
	doi = {10.1016/j.neuroimage.2020.117322},
	abstract = {Despite myriad demonstrations of feasibility, the high dimensionality of fMRI data remains a critical barrier to its utility for reproducible biomarker discovery. Recent efforts to address this challenge have capitalized on dimensionality reduction techniques applied to resting-state fMRI, identifying principal components of intrinsic connectivity which describe smooth transitions across different cortical systems, so called “connectivity gradients”. These gradients recapitulate neurocognitively meaningful organizational principles that are present in both human and primate brains, and also appear to differ among individuals and clinical populations. Here, we provide a critical assessment of the suitability of connectivity gradients for biomarker discovery. Using the Human Connectome Project (discovery subsample=209; two replication subsamples= 209 × 2) and the Midnight scan club (n = 9), we tested the following key biomarker traits – reliability, reproducibility and predictive validity – of functional gradients. In doing so, we systematically assessed the effects of three analytical settings, including i) dimensionality reduction algorithms (i.e., linear vs. non-linear methods), ii) input data types (i.e., raw time series, [un-]thresholded functional connectivity), and iii) amount of the data (resting-state fMRI time-series lengths). We found that the reproducibility of functional gradients across algorithms and subsamples is generally higher for those explaining more variances of whole-brain connectivity data, as well as those having higher reliability. Notably, among different analytical settings, a linear dimensionality reduction (principal component analysis in our study), more conservatively thresholded functional connectivity (e.g., 95–97\%) and longer time-series data (at least ≥20mins) was found to be preferential conditions to obtain higher reliability. Those gradients with higher reliability were able to predict unseen phenotypic scores with a higher accuracy, highlighting reliability as a critical prerequisite for validity. Importantly, prediction accuracy with connectivity gradients exceeded that observed with more traditional edge-based connectivity measures, suggesting the added value of a low-dimensional and multivariate gradient approach. Finally, the present work highlights the importance and benefits of systematically exploring the parameter space for new imaging methods before widespread deployment.},
	language = {en},
	urldate = {2021-04-08},
	journal = {NeuroImage},
	author = {Hong, Seok-Jun and Xu, Ting and Nikolaidis, Aki and Smallwood, Jonathan and Margulies, Daniel S. and Bernhardt, Boris and Vogelstein, Joshua and Milham, Michael P.},
	month = dec,
	year = {2020},
	keywords = {Dimensionality reduction, Reliability, Imaging biomarker, Phenotype prediction, CCA, Reproducibility},
	pages = {117322},
	file = {Hong et al_2020_Toward a connectivity gradient-based framework for reproducible biomarker.pdf:/Users/tito/Zotero/storage/7KQA6AWC/Hong et al_2020_Toward a connectivity gradient-based framework for reproducible biomarker.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/X5C6YCVM/S1053811920308089.html:text/html},
}

@article{cao_explanatory_2021,
	title = {Explanatory models in neuroscience: {Part} 1 -- taking mechanistic abstraction seriously},
	shorttitle = {Explanatory models in neuroscience},
	url = {http://arxiv.org/abs/2104.01490},
	abstract = {Despite the recent success of neural network models in mimicking animal performance on visual perceptual tasks, critics worry that these models fail to illuminate brain function. We take it that a central approach to explanation in systems neuroscience is that of mechanistic modeling, where understanding the system is taken to require fleshing out the parts, organization, and activities of a system, and how those give rise to behaviors of interest. However, it remains somewhat controversial what it means for a model to describe a mechanism, and whether neural network models qualify as explanatory. We argue that certain kinds of neural network models are actually good examples of mechanistic models, when the right notion of mechanistic mapping is deployed. Building on existing work on model-to-mechanism mapping (3M), we describe criteria delineating such a notion, which we call 3M++. These criteria require us, first, to identify a level of description that is both abstract but detailed enough to be "runnable", and then, to construct model-to-brain mappings using the same principles as those employed for brain-to-brain mapping across individuals. Perhaps surprisingly, the abstractions required are those already in use in experimental neuroscience, and are of the kind deployed in the construction of more familiar computational models, just as the principles of inter-brain mappings are very much in the spirit of those already employed in the collection and analysis of data across animals. In a companion paper, we address the relationship between optimization and intelligibility, in the context of functional evolutionary explanations. Taken together, mechanistic interpretations of computational models and the dependencies between form and function illuminated by optimization processes can help us to understand why brain systems are built they way they are.},
	urldate = {2021-04-12},
	journal = {arXiv:2104.01490 [cs, q-bio]},
	author = {Cao, Rosa and Yamins, Daniel},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.01490},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DA4B86T9/2104.html:text/html;Cao_Yamins_2021_Explanatory models in neuroscience.pdf:/Users/tito/Zotero/storage/FGE7P9B9/Cao_Yamins_2021_Explanatory models in neuroscience.pdf:application/pdf},
}

@article{cao_explanatory_2021-1,
	title = {Explanatory models in neuroscience: {Part} 2 -- constraint-based intelligibility},
	shorttitle = {Explanatory models in neuroscience},
	url = {http://arxiv.org/abs/2104.01489},
	abstract = {Computational modeling plays an increasingly important role in neuroscience, highlighting the philosophical question of how computational models explain. In the context of neural network models for neuroscience, concerns have been raised about model intelligibility, and how they relate (if at all) to what is found in the brain. We claim that what makes a system intelligible is an understanding of the dependencies between its behavior and the factors that are causally responsible for that behavior. In biological systems, many of these dependencies are naturally "top-down": ethological imperatives interact with evolutionary and developmental constraints under natural selection. We describe how the optimization techniques used to construct NN models capture some key aspects of these dependencies, and thus help explain *why* brain systems are as they are -- because when a challenging ecologically-relevant goal is shared by a NN and the brain, it places tight constraints on the possible mechanisms exhibited in both kinds of systems. By combining two familiar modes of explanation -- one based on bottom-up mechanism (whose relation to neural network models we address in a companion paper) and the other on top-down constraints, these models illuminate brain function.},
	urldate = {2021-04-12},
	journal = {arXiv:2104.01489 [cs, q-bio]},
	author = {Cao, Rosa and Yamins, Daniel},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.01489},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/FT4V7ZBH/2104.html:text/html;Cao_Yamins_2021_Explanatory models in neuroscience.pdf:/Users/tito/Zotero/storage/Y8AESUE6/Cao_Yamins_2021_Explanatory models in neuroscience.pdf:application/pdf},
}

@article{uddin_towards_2019-1,
	title = {Towards a {Universal} {Taxonomy} of {Macro}-scale {Functional} {Human} {Brain} {Networks}},
	volume = {32},
	issn = {1573-6792},
	url = {https://doi.org/10.1007/s10548-019-00744-6},
	doi = {10.1007/s10548-019-00744-6},
	abstract = {The past decade has witnessed a proliferation of studies aimed at characterizing the human connectome. These projects map the brain regions comprising large-scale systems underlying cognition using non-invasive neuroimaging approaches and advanced analytic techniques adopted from network science. While the idea that the human brain is composed of multiple macro-scale functional networks has been gaining traction in cognitive neuroscience, the field has yet to reach consensus on several key issues regarding terminology. What constitutes a functional brain network? Are there “core” functional networks, and if so, what are their spatial topographies? What naming conventions, if universally adopted, will provide the most utility and facilitate communication amongst researchers? Can a taxonomy of functional brain networks be delineated? Here we survey the current landscape to identify six common macro-scale brain network naming schemes and conventions utilized in the literature, highlighting inconsistencies and points of confusion where appropriate. As a minimum recommendation upon which to build, we propose that a scheme incorporating anatomical terminology should provide the foundation for a taxonomy of functional brain networks. A logical starting point in this endeavor might delineate systems that we refer to here as “occipital”, “pericentral”, “dorsal frontoparietal”, “lateral frontoparietal”, “midcingulo-insular”, and “medial frontoparietal” networks. We posit that as the field of network neuroscience matures, it will become increasingly imperative to arrive at a taxonomy such as that proposed here, that can be consistently referenced across research groups.},
	language = {en},
	number = {6},
	urldate = {2021-04-12},
	journal = {Brain Topogr},
	author = {Uddin, Lucina Q. and Yeo, B. T. Thomas and Spreng, R. Nathan},
	month = nov,
	year = {2019},
	pages = {926--942},
	file = {Uddin et al_2019_Towards a Universal Taxonomy of Macro-scale Functional Human Brain Networks.pdf:/Users/tito/Zotero/storage/NJUR6DJ5/Uddin et al_2019_Towards a Universal Taxonomy of Macro-scale Functional Human Brain Networks.pdf:application/pdf},
}

@article{wang_parcellating_2015-1,
	title = {Parcellating cortical functional networks in individuals},
	volume = {18},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.4164},
	doi = {10.1038/nn.4164},
	abstract = {A cortical parcellation technique accurately maps functional organization in individual brains. Functional networks mapped by this approach are highly reproducible and effectively capture individual variability. The algorithm performs well across different populations and data types and is validated by invasive cortical stimulation mapping in surgical patients.},
	language = {en},
	number = {12},
	urldate = {2021-04-12},
	journal = {Nature Neuroscience},
	author = {Wang, Danhong and Buckner, Randy L. and Fox, Michael D. and Holt, Daphne J. and Holmes, Avram J. and Stoecklein, Sophia and Langs, Georg and Pan, Ruiqi and Qian, Tianyi and Li, Kuncheng and Baker, Justin T. and Stufflebeam, Steven M. and Wang, Kai and Wang, Xiaomin and Hong, Bo and Liu, Hesheng},
	month = dec,
	year = {2015},
	note = {Number: 12
Publisher: Nature Publishing Group},
	pages = {1853--1860},
	file = {Snapshot:/Users/tito/Zotero/storage/79J8IJFP/nn.html:text/html;Wang et al_2015_Parcellating cortical functional networks in individuals.pdf:/Users/tito/Zotero/storage/L438BD5A/Wang et al_2015_Parcellating cortical functional networks in individuals.pdf:application/pdf},
}

@article{cui_individual_2020,
	title = {Individual {Variation} in {Functional} {Topography} of {Association} {Networks} in {Youth}},
	volume = {106},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627320300556},
	doi = {10.1016/j.neuron.2020.01.029},
	abstract = {The spatial distribution of large-scale functional networks on the cerebral cortex differs between individuals and is particularly variable in association networks that are responsible for higher-order cognition. However, it remains unknown how this functional topography evolves in development and supports cognition. Capitalizing on advances in machine learning and a large sample imaged with 27 min of high-quality functional MRI (fMRI) data (n = 693, ages 8–23 years), we delineate how functional topography evolves during youth. We found that the functional topography of association networks is refined with age, allowing accurate prediction of unseen individuals’ brain maturity. The cortical representation of association networks predicts individual differences in executive function. Finally, variability of functional topography is associated with fundamental properties of brain organization, including evolutionary expansion, cortical myelination, and cerebral blood flow. Our results emphasize the importance of considering the plasticity and diversity of functional neuroanatomy during development and suggest advances in personalized therapeutics.},
	language = {en},
	number = {2},
	urldate = {2021-04-13},
	journal = {Neuron},
	author = {Cui, Zaixu and Li, Hongming and Xia, Cedric H. and Larsen, Bart and Adebimpe, Azeez and Baum, Graham L. and Cieslak, Matt and Gur, Raquel E. and Gur, Ruben C. and Moore, Tyler M. and Oathes, Desmond J. and Alexander-Bloch, Aaron F. and Raznahan, Armin and Roalf, David R. and Shinohara, Russell T. and Wolf, Daniel H. and Davatzikos, Christos and Bassett, Danielle S. and Fair, Damien A. and Fan, Yong and Satterthwaite, Theodore D.},
	month = apr,
	year = {2020},
	keywords = {MRI, parcellation, cognition, cognitive control, network, topography, executive function, functional MRI, adolescence, development},
	pages = {340--353.e8},
	file = {Cui et al_2020_Individual Variation in Functional Topography of Association Networks in Youth.pdf:/Users/tito/Zotero/storage/GITJ7R4H/Cui et al_2020_Individual Variation in Functional Topography of Association Networks in Youth.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/W7MDK292/S0896627320300556.html:text/html},
}

@article{lake_human-level_2015,
	title = {Human-level concept learning through probabilistic program induction},
	volume = {350},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/350/6266/1332},
	doi = {10.1126/science.aab3050},
	abstract = {Handwritten characters drawn by a model
Not only do children learn effortlessly, they do so quickly and with a remarkable ability to use what they have learned as the raw material for creating new stuff. Lake et al. describe a computational model that learns in a similar fashion and does so better than current deep learning algorithms. The model classifies, parses, and recreates handwritten characters, and can generate new letters of the alphabet that look “right” as judged by Turing-like tests of the model's output in comparison to what real humans produce.
Science, this issue p. 1332
People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world’s alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several “visual Turing tests” probing the model’s creative generalization abilities, which in many cases are indistinguishable from human behavior.
Combining the capacity to handle noise with probabilistic learning yields humanlike performance in a computational model.
Combining the capacity to handle noise with probabilistic learning yields humanlike performance in a computational model.},
	language = {en},
	number = {6266},
	urldate = {2021-04-14},
	journal = {Science},
	author = {Lake, Brenden M. and Salakhutdinov, Ruslan and Tenenbaum, Joshua B.},
	month = dec,
	year = {2015},
	pmid = {26659050},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {1332--1338},
	file = {Lake et al_2015_Human-level concept learning through probabilistic program induction.pdf:/Users/tito/Zotero/storage/PUFYRDKD/Lake et al_2015_Human-level concept learning through probabilistic program induction.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SZSKNV5G/1332.html:text/html},
}

@article{lake_building_2017,
	title = {Building machines that learn and think like people},
	volume = {40},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/building-machines-that-learn-and-think-like-people/A9535B1D745A0377E16C590E14B94993},
	doi = {10.1017/S0140525X16001837},
	abstract = {Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
	language = {en},
	urldate = {2021-04-14},
	journal = {Behavioral and Brain Sciences},
	author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
	year = {2017},
	note = {Publisher: Cambridge University Press},
	file = {Lake et al_2017_Building machines that learn and think like people.pdf:/Users/tito/Zotero/storage/GTBUN6LY/Lake et al_2017_Building machines that learn and think like people.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/82EDAADX/A9535B1D745A0377E16C590E14B94993.html:text/html},
}

@article{chung_neural_2021,
	title = {Neural population geometry: {An} approach for understanding biological and artificial neural networks},
	shorttitle = {Neural population geometry},
	url = {https://arxiv.org/abs/2104.07059v1},
	abstract = {Advances in experimental neuroscience have transformed our ability to explore the structure and function of neural circuits. At the same time, advances in machine learning have unleashed the remarkable computational power of artificial neural networks (ANNs). While these two fields have different tools and applications, they present a similar challenge: namely, understanding how information is embedded and processed through high-dimensional representations to solve complex tasks. One approach to addressing this challenge is to utilize mathematical and computational tools to analyze the geometry of these high-dimensional representations, i.e., neural population geometry. We review examples of geometrical approaches providing insight into the function of biological and artificial neural networks: representation untangling in perception, a geometric theory of classification capacity, disentanglement and abstraction in cognitive systems, topological representations underlying cognitive maps, dynamic untangling in motor systems, and a dynamical approach to cognition. Together, these findings illustrate an exciting trend at the intersection of machine learning, neuroscience, and geometry, in which neural population geometry provides a useful population-level mechanistic descriptor underlying task implementation. Importantly, geometric descriptions are applicable across sensory modalities, brain regions, network architectures and timescales. Thus, neural population geometry has the potential to unify our understanding of structure and function in biological and artificial neural networks, bridging the gap between single neurons, populations and behavior.},
	language = {en},
	urldate = {2021-04-16},
	author = {Chung, SueYeon and Abbott, L. F.},
	month = apr,
	year = {2021},
	file = {Chung_Abbott_2021_Neural population geometry.pdf:/Users/tito/Zotero/storage/U8YRNT38/Chung_Abbott_2021_Neural population geometry.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/D8U9TEQS/2104.html:text/html},
}

@article{kobayashi_reconstructing_2019,
	title = {Reconstructing neuronal circuitry from parallel spike trains},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-12225-2},
	doi = {10.1038/s41467-019-12225-2},
	abstract = {State-of-the-art techniques allow researchers to record large numbers of spike trains in parallel for many hours. With enough such data, we should be able to infer the connectivity among neurons. Here we develop a method for reconstructing neuronal circuitry by applying a generalized linear model (GLM) to spike cross-correlations. Our method estimates connections between neurons in units of postsynaptic potentials and the amount of spike recordings needed to verify connections. The performance of inference is optimized by counting the estimation errors using synthetic data. This method is superior to other established methods in correctly estimating connectivity. By applying our method to rat hippocampal data, we show that the types of estimated connections match the results inferred from other physiological cues. Thus our method provides the means to build a circuit diagram from recorded spike trains, thereby providing a basis for elucidating the differences in information processing in different brain regions.},
	language = {en},
	number = {1},
	urldate = {2021-04-16},
	journal = {Nature Communications},
	author = {Kobayashi, Ryota and Kurita, Shuhei and Kurth, Anno and Kitano, Katsunori and Mizuseki, Kenji and Diesmann, Markus and Richmond, Barry J. and Shinomoto, Shigeru},
	month = oct,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {4468},
	file = {Kobayashi et al_2019_Reconstructing neuronal circuitry from parallel spike trains.pdf:/Users/tito/Zotero/storage/8V8JILKH/Kobayashi et al_2019_Reconstructing neuronal circuitry from parallel spike trains.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9HI2WZXM/s41467-019-12225-2.html:text/html},
}

@article{sanchez-romero_causally_2021,
	title = {Causally informed activity flow models provide mechanistic insight into the emergence of cognitive processes from brain network interactions},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.16.440226v1},
	doi = {10.1101/2021.04.16.440226},
	abstract = {{\textless}p{\textgreater}Brain activity flow models estimate the movement of task-evoked activity over brain connections to help explain the emergence of task-related functionality. Activity flow estimates have been shown to accurately predict task-evoked brain activations across a wide variety of brain regions and task conditions. However, these predictions have had limited explanatory power, given known issues with causal interpretations of the standard functional connectivity measures used to parameterize activity flow models. We show here that functional/effective connectivity (FC) measures grounded in causal principles facilitate mechanistic interpretation of activity flow models. Starting from Pearson correlation (the current field standard), we progress from FC measures with poor to excellent causal grounding, demonstrating a continuum of causal validity using simulations and empirical fMRI data. Finally, we apply a causal FC method to a dorsolateral prefrontal cortex region, demonstrating causal network mechanisms contributing to its strong activation during a 2-back (relative to a 0-back) working memory task. Together, these results reveal the promise of parameterizing activity flow models using causal FC methods to identify network mechanisms underlying cognitive computations in the human brain.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-19},
	journal = {bioRxiv},
	author = {Sanchez-Romero, Ruben and Ito, Takuya and Mill, Ravi D. and Hanson, Stephen José and Cole, Michael W.},
	month = apr,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.04.16.440226},
	file = {Sanchez-Romero et al_2021_Causally informed activity flow models provide mechanistic insight into the.pdf:/Users/tito/Zotero/storage/6CK397XB/Sanchez-Romero et al_2021_Causally informed activity flow models provide mechanistic insight into the.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/XUNXKL5P/2021.04.16.html:text/html},
}

@article{mesulam_sensation_1998,
	title = {From sensation to cognition.},
	volume = {121},
	issn = {0006-8950},
	url = {https://doi.org/10.1093/brain/121.6.1013},
	doi = {10.1093/brain/121.6.1013},
	abstract = {Sensory information undergoes extensive associative elaboration and attentional modulation as it becomes incorporated into the texture of cognition. This process occurs along a core synaptic hierarchy which includes the primary sensory, upstream unimodal, downstream unimodal, heteromodal, paralimbic and limbic zones of the cerebral cortex. Connections from one zone to another are reciprocal and allow higher synaptic levels to exert a feedback (top-down) influence upon earlier levels of processing. Each cortical area provides a nexus for the convergence of afferents and divergence of efferents. The resultant synaptic organization supports parallel as well as serial processing, and allows each sensory event to initiate multiple cognitive and behavioural outcomes. Upstream sectors of unimodal association areas encode basic features of sensation such as colour, motion, form and pitch. More complex contents of sensory experience such as objects, faces, word-forms, spatial locations and sound sequences become encoded within downstream sectors of unimodal areas by groups of coarsely tuned neurons. The highest synaptic levels of sensory-fugal processing are occupied by heteromodal, paralimbic and limbic cortices, collectively known as transmodal areas. The unique role of these areas is to bind multiple unimodal and other transmodal areas into distributed but integrated multimodal representations. Transmodal areas in the midtemporal cortex, Wernicke's area, the hippocampal-entorhinal complex and the posterior parietal cortex provide critical gateways for transforming perception into recognition, word-forms into meaning, scenes and events into experiences, and spatial locations into targets for exploration. All cognitive processes arise from analogous associative transformations of similar sets of sensory inputs. The differences in the resultant cognitive operation are determined by the anatomical and physiological properties of the transmodal node that acts as the critical gateway for the dominant transformation. Interconnected sets of transmodal nodes provide anatomical and computational epicentres for large-scale neurocognitive networks. In keeping with the principles of selectively distributed processing, each epicentre of a large-scale network displays a relative specialization for a specific behavioural component of its principal neurospychological domain. The destruction of transmodal epicentres causes global impairments such as multimodal anomia, neglect and amnesia, whereas their selective disconnection from relevant unimodal areas elicits modality-specific impairments such as prosopagnosia, pure word blindness and category-specific anomias. The human brain contains at least five anatomically distinct networks. The network for spatial awareness is based on transmodal epicentres in the posterior parietal cortex and the frontal eye fields; the language network on epicentres in Wernicke's and Broca's areas; the explicit memory/emotion network on epicentres in the hippocampal-entorhinal complex and the amygdala; the face-object recognition network on epicentres in the midtemporal and temporopolar cortices; and the working memory-executive function network on epicentres in the lateral prefrontal cortex and perhaps the posterior parietal cortex. Individual sensory modalities give rise to streams of processing directed to transmodal nodes belonging to each of these networks. The fidelity of sensory channels is actively protected through approximately four synaptic levels of sensory-fugal processing. The modality-specific cortices at these four synaptic levels encode the most veridical representations of experience. Attentional, motivational and emotional modulations, including those related to working memory, novelty-seeking and mental imagery, become increasingly more pronounced within downstream components of unimodal areas, where they help to create a highly edited subjective version of the world. (ABSTRACT TRUNCATED)},
	number = {6},
	urldate = {2021-04-19},
	journal = {Brain},
	author = {Mesulam, M M},
	month = jun,
	year = {1998},
	pages = {1013--1052},
	file = {Mesulam_1998_From sensation to cognition.pdf:/Users/tito/Zotero/storage/GI75DDYY/Mesulam_1998_From sensation to cognition.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GI6B7KCI/280347.html:text/html},
}

@article{barack_two_2021,
	title = {Two views on the cognitive brain},
	copyright = {2021 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-021-00448-6},
	doi = {10.1038/s41583-021-00448-6},
	abstract = {Cognition can be defined as computation over meaningful representations in the brain to produce adaptive behaviour. There are two views on the relationship between cognition and the brain that are largely implicit in the literature. The Sherringtonian view seeks to explain cognition as the result of operations on signals performed at nodes in a network and passed between them that are implemented by specific neurons and their connections in circuits in the brain. The contrasting Hopfieldian view explains cognition as the result of transformations between or movement within representational spaces that are implemented by neural populations. Thus, the Hopfieldian view relegates details regarding the identity of and connections between specific neurons to the status of secondary explainers. Only the Hopfieldian approach has the representational and computational resources needed to develop novel neurofunctional objects that can serve as primary explainers of cognition.},
	language = {en},
	urldate = {2021-04-20},
	journal = {Nature Reviews Neuroscience},
	author = {Barack, David L. and Krakauer, John W.},
	month = apr,
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	pages = {1--13},
	file = {Barack_Krakauer_2021_Two views on the cognitive brain.pdf:/Users/tito/Zotero/storage/RP5BPRMK/Barack_Krakauer_2021_Two views on the cognitive brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Q2W24JPR/s41583-021-00448-6.html:text/html},
}

@article{guyon_network_2021,
	title = {Network {Asynchrony} {Underlying} {Increased} {Broadband} {Gamma} {Power}},
	volume = {41},
	copyright = {Copyright © 2021 the authors. SfN exclusive license.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/41/13/2944},
	doi = {10.1523/JNEUROSCI.2250-20.2021},
	abstract = {Synchronous activity of cortical inhibitory interneurons expressing parvalbumin (PV) underlies expression of cortical γ rhythms. Paradoxically, deficient PV inhibition is associated with increased broadband γ power in the local field potential. Increased baseline broadband γ is also a prominent characteristic in schizophrenia and a hallmark of network alterations induced by NMDAR antagonists, such as ketamine. Whether enhanced broadband γ is a true rhythm, and if so, whether rhythmic PV inhibition is involved or not, is debated. Asynchronous and increased firing activities are thought to contribute to broadband power increases spanning the γ band. Using male and female mice lacking NMDAR activity specifically in PV neurons to model deficient PV inhibition, we here show that neuronal activity with decreased synchronicity is associated with increased prefrontal broadband γ power. Specifically, reduced spike time precision and spectral leakage of spiking activity because of higher firing rates (spike “contamination”) affect the broadband γ band. Desynchronization was evident at multiple time scales, with reduced spike entrainment to the local field potential, reduced cross-frequency coupling, and fragmentation of brain states. Local application of S(+)-ketamine in (control) mice with intact NMDAR activity in PV neurons triggered network desynchronization and enhanced broadband γ power. However, our investigations suggest that disparate mechanisms underlie increased broadband γ power caused by genetic alteration of PV interneurons and ketamine-induced power increases in broadband γ. Our study confirms that enhanced broadband γ power can arise from asynchronous activities and demonstrates that long-term deficiency of PV inhibition can be a contributor.
SIGNIFICANCE STATEMENT Brain oscillations are fundamental to the coordination of neuronal activity across neurons and structures. γ oscillations (30-80 Hz) have received particular attention through their association with perceptual and cognitive processes. Synchronous activity of inhibitory parvalbumin (PV) interneurons generates cortical γ oscillation, but, paradoxically, PV neuron deficiency is associated with increases in γ oscillations. We here reconcile this conundrum and show how deficient PV inhibition can lead to increased and asynchronous excitatory firing, contaminating the local field potential and manifesting as increased γ power. Thus, increased γ power does not always reflect a genuine rhythm. Further, we show that ketamine-induced γ increases are caused by separate network mechanisms.},
	language = {en},
	number = {13},
	urldate = {2021-04-20},
	journal = {J. Neurosci.},
	author = {Guyon, Nicolas and Zacharias, Leonardo Rakauskas and Oliveira, Eliezyer Fermino de and Kim, Hoseok and Leite, João Pereira and Lopes-Aguiar, Cleiton and Carlén, Marie},
	month = mar,
	year = {2021},
	pmid = {33593859},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {PFC, asynchrony, broadband gamma, DOWN and UP states, NMDAR, parvalbumin},
	pages = {2944--2963},
	file = {Guyon et al_2021_Network Asynchrony Underlying Increased Broadband Gamma Power.pdf:/Users/tito/Zotero/storage/BHKE6DE8/Guyon et al_2021_Network Asynchrony Underlying Increased Broadband Gamma Power.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WLJ34WI4/2944.html:text/html},
}

@article{millidge_predictive_2020,
	title = {Predictive {Coding} {Approximates} {Backprop} along {Arbitrary} {Computation} {Graphs}},
	url = {http://arxiv.org/abs/2006.04182},
	abstract = {Backpropagation of error (backprop) is a powerful algorithm for training machine learning architectures through end-to-end differentiation. Recently it has been shown that backprop in multilayerperceptrons (MLPs) can be approximated using predictive coding, a biologically-plausible process theory of cortical computation which relies solely on local and Hebbian updates. The power of backprop, however, lies not in its instantiation in MLPs, but rather in the concept of automatic differentiation which allows for the optimisation of any differentiable program expressed as a computation graph. Here, we demonstrate that predictive coding converges asymptotically (and in practice rapidly) to exact backprop gradients on arbitrary computation graphs using only local learning rules. We apply this result to develop a straightforward strategy to translate core machine learning architectures into their predictive coding equivalents. We construct predictive coding CNNs, RNNs, and the more complex LSTMs, which include a non-layer-like branching internal graph structure and multiplicative interactions. Our models perform equivalently to backprop on challenging machine learning benchmarks, while utilising only local and (mostly) Hebbian plasticity. Our method raises the potential that standard machine learning algorithms could in principle be directly implemented in neural circuitry, and may also contribute to the development of completely distributed neuromorphic architectures.},
	language = {en},
	urldate = {2021-04-21},
	journal = {arXiv:2006.04182 [cs]},
	author = {Millidge, Beren and Tschantz, Alexander and Buckley, Christopher L.},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.04182},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Submitted to NeurIPS 2020. Updated Acknowledgements. 11/06/20: fixed typos in maths -- 11/07/20: minor corrections; 05/10/20: major rewrite for ICLR},
	file = {Millidge et al. - 2020 - Predictive Coding Approximates Backprop along Arbi.pdf:/Users/tito/Zotero/storage/9HHFQT4E/Millidge et al. - 2020 - Predictive Coding Approximates Backprop along Arbi.pdf:application/pdf},
}

@article{seeber_subcortical_2019,
	title = {Subcortical electrophysiological activity is detectable with high-density {EEG} source imaging},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-08725-w},
	doi = {10.1038/s41467-019-08725-w},
	abstract = {Subcortical neuronal activity is highly relevant for mediating communication in large-scale brain networks. While electroencephalographic (EEG) recordings provide appropriate temporal resolution and coverage to study whole brain dynamics, the feasibility to detect subcortical signals is a matter of debate. Here, we investigate if scalp EEG can detect and correctly localize signals recorded with intracranial electrodes placed in the centromedial thalamus, and in the nucleus accumbens. Externalization of deep brain stimulation (DBS) electrodes, placed in these regions, provides the unique opportunity to record subcortical activity simultaneously with high-density (256 channel) scalp EEG. In three patients during rest with eyes closed, we found significant correlation between alpha envelopes derived from intracranial and EEG source reconstructed signals. Highest correlation was found for source signals in close proximity to the actual recording sites, given by the DBS electrode locations. Therefore, we present direct evidence that scalp EEG indeed can sense subcortical signals.},
	language = {en},
	number = {1},
	urldate = {2021-04-22},
	journal = {Nature Communications},
	author = {Seeber, Martin and Cantonas, Lucia-Manuela and Hoevels, Mauritius and Sesia, Thibaut and Visser-Vandewalle, Veerle and Michel, Christoph M.},
	month = feb,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {753},
	file = {Seeber et al_2019_Subcortical electrophysiological activity is detectable with high-density EEG.pdf:/Users/tito/Zotero/storage/62S7TXDB/Seeber et al_2019_Subcortical electrophysiological activity is detectable with high-density EEG.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/2F6DDGBW/s41467-019-08725-w.html:text/html},
}

@article{pizzo_deep_2019,
	title = {Deep brain activities can be detected with magnetoencephalography},
	volume = {10},
	copyright = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-08665-5},
	doi = {10.1038/s41467-019-08665-5},
	abstract = {The hippocampus and amygdala are key brain structures of the medial temporal lobe, involved in cognitive and emotional processes as well as pathological states such as epilepsy. Despite their importance, it is still unclear whether their  neural activity can be recorded non-invasively. Here, using simultaneous intracerebral and magnetoencephalography (MEG) recordings in patients with focal drug-resistant epilepsy, we demonstrate a direct contribution of amygdala and hippocampal activity to surface MEG recordings. In particular, a method of blind source separation, independent component analysis, enabled activity arising from large neocortical networks to be disentangled from that of deeper structures, whose amplitude at the surface was small but significant. This finding is highly relevant for our understanding of hippocampal and amygdala brain activity as it implies that their activity could potentially be measured non-invasively.},
	language = {en},
	number = {1},
	urldate = {2021-04-22},
	journal = {Nature Communications},
	author = {Pizzo, F. and Roehri, N. and Medina Villalon, S. and Trébuchon, A. and Chen, S. and Lagarde, S. and Carron, R. and Gavaret, M. and Giusiano, B. and McGonigal, A. and Bartolomei, F. and Badier, J. M. and Bénar, C. G.},
	month = feb,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {971},
	file = {Pizzo et al_2019_Deep brain activities can be detected with magnetoencephalography.pdf:/Users/tito/Zotero/storage/FEELYFR8/Pizzo et al_2019_Deep brain activities can be detected with magnetoencephalography.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FVL8EG8Q/s41467-019-08665-5.html:text/html},
}

@book{thorpe_visual_2012,
	title = {Visual {Population} {Codes}: {Toward} a {Common} {Multivariate} {Framework} for {Cell} {Recording} and {Functional} {Imaging}},
	isbn = {978-0-262-01624-7},
	shorttitle = {Visual {Population} {Codes}},
	abstract = {How visual content is represented in neuronal population codes and how to analyze such codes with multivariate techniques. Vision is a massively parallel computational process, in which the retinal image is transformed over a sequence of stages so as to emphasize behaviorally relevant information (such as object category and identity) and deemphasize other information (such as viewpoint and lighting). The processes behind vision operate by concurrent computation and message passing among neurons within a visual area and between different areas. The theoretical concept of "population code" encapsulates the idea that visual content is represented at each stage by the pattern of activity across the local population of neurons. Understanding visual population codes ultimately requires multichannel measurement and multivariate analysis of activity patterns. Over the past decade, the multivariate approach has gained significant momentum in vision research. Functional imaging and cell recording measure brain activity in fundamentally different ways, but they now use similar theoretical concepts and mathematical tools in their modeling and analyses. With a focus on the ventral processing stream thought to underlie object recognition, this book presents recent advances in our understanding of visual population codes, novel multivariate pattern-information analysis techniques, and the beginnings of a unified perspective for cell recording and functional imaging. It serves as an introduction, overview, and reference for scientists and students across disciplines who are interested in human and primate vision and, more generally, in understanding how the brain represents and processes information.},
	language = {en},
	publisher = {MIT Press},
	author = {Thorpe, Simon J.},
	year = {2012},
	note = {Google-Books-ID: Gol5hxBEjooC},
	keywords = {Medical / Neuroscience, Psychology / Cognitive Psychology \& Cognition, Psychology / Neuropsychology, Science / Life Sciences / Neuroscience},
}

@article{kriegeskorte_neural_2021,
	title = {Neural tuning and representational geometry},
	url = {http://arxiv.org/abs/2104.09743},
	abstract = {A central goal of neuroscience is to understand the representations formed by brain activity patterns and their connection to behavior. The classical approach is to investigate how individual neurons encode the stimuli and how their tuning determines the fidelity of the neural representation. Tuning analyses often use the Fisher information to characterize the sensitivity of neural responses to small changes of the stimulus. In recent decades, measurements of large populations of neurons have motivated a complementary approach, which focuses on the information available to linear decoders. The decodable information is captured by the geometry of the representational patterns in the multivariate response space. Here we review neural tuning and representational geometry with the goal of clarifying the relationship between them. The tuning induces the geometry, but different sets of tuned neurons can induce the same geometry. The geometry determines the Fisher information, the mutual information, and the behavioral performance of an ideal observer in a range of psychophysical tasks. We argue that future studies can benefit from considering both tuning and geometry to understand neural codes and reveal the connections between stimulus, brain activity, and behavior.},
	urldate = {2021-04-23},
	journal = {arXiv:2104.09743 [q-bio]},
	author = {Kriegeskorte, Nikolaus and Wei, Xue-Xin},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.09743},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 42 pages, 6 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/GJEIQMQP/2104.html:text/html;Kriegeskorte_Wei_2021_Neural tuning and representational geometry.pdf:/Users/tito/Zotero/storage/4AQEDZEF/Kriegeskorte_Wei_2021_Neural tuning and representational geometry.pdf:application/pdf},
}

@article{beaty_network_2019,
	series = {Creativity},
	title = {Network neuroscience of creative cognition: mapping cognitive mechanisms and individual differences in the creative brain},
	volume = {27},
	issn = {2352-1546},
	shorttitle = {Network neuroscience of creative cognition},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154618301219},
	doi = {10.1016/j.cobeha.2018.08.013},
	abstract = {Network neuroscience research is providing increasing specificity on the contribution of large-scale brain networks to creative cognition. Here, we summarize recent experimental work examining cognitive mechanisms of network interactions and correlational studies assessing network dynamics associated with individual creative abilities. Our review identifies three cognitive processes related to network interactions during creative performance: goal-directed memory retrieval, prepotent-response inhibition, and internally-focused attention. Correlational work using prediction modeling indicates that functional connectivity between networks — particularly the executive control and default networks — can reliably predict an individual’s creative thinking ability. We discuss potential directions for future network neuroscience, including assessing creative performance in specific domains and using brain stimulation to test causal hypotheses regarding network interactions and cognitive mechanisms of creative thought.},
	language = {en},
	urldate = {2021-04-23},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Beaty, Roger E and Seli, Paul and Schacter, Daniel L},
	month = jun,
	year = {2019},
	pages = {22--30},
	file = {Beaty et al_2019_Network neuroscience of creative cognition.pdf:/Users/tito/Zotero/storage/DTLPPIC3/Beaty et al_2019_Network neuroscience of creative cognition.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/D9S8QD2A/S2352154618301219.html:text/html},
}

@article{recanatesi_predictive_2021,
	title = {Predictive learning as a network mechanism for extracting low-dimensional latent space representations},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21696-1},
	doi = {10.1038/s41467-021-21696-1},
	abstract = {Artificial neural networks have recently achieved many successes in solving sequential processing and planning tasks. Their success is often ascribed to the emergence of the task’s low-dimensional latent structure in the network activity – i.e., in the learned neural representations. Here, we investigate the hypothesis that a means for generating representations with easily accessed low-dimensional latent structure, possibly reflecting an underlying semantic organization, is through learning to predict observations about the world. Specifically, we ask whether and when network mechanisms for sensory prediction coincide with those for extracting the underlying latent variables. Using a recurrent neural network model trained to predict a sequence of observations we show that network dynamics exhibit low-dimensional but nonlinearly transformed representations of sensory inputs that map the latent structure of the sensory environment. We quantify these results using nonlinear measures of intrinsic dimensionality and linear decodability of latent variables, and provide mathematical arguments for why such useful predictive representations emerge. We focus throughout on how our results can aid the analysis and interpretation of experimental data.},
	language = {en},
	number = {1},
	urldate = {2021-04-28},
	journal = {Nature Communications},
	author = {Recanatesi, Stefano and Farrell, Matthew and Lajoie, Guillaume and Deneve, Sophie and Rigotti, Mattia and Shea-Brown, Eric},
	month = mar,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1417},
	file = {Recanatesi et al_2021_Predictive learning as a network mechanism for extracting low-dimensional.pdf:/Users/tito/Zotero/storage/ILLKT89G/Recanatesi et al_2021_Predictive learning as a network mechanism for extracting low-dimensional.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FRRPJ4SG/s41467-021-21696-1.html:text/html},
}

@article{flesch_rich_2021,
	title = {Rich and lazy learning of task representations in brains and neural networks},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.23.441128v1},
	doi = {10.1101/2021.04.23.441128},
	abstract = {{\textless}p{\textgreater}How do neural populations code for multiple, potentially conflicting tasks? Here, we used computational simulations involving neural networks to define "lazy" and "rich" coding solutions to this multitasking problem, which trade off learning speed for robustness. During lazy learning the input dimensionality is expanded by random projections to the network hidden layer, whereas in rich learning hidden units acquire structured representations that privilege relevant over irrelevant features. For context-dependent decision-making, one rich solution is to project task representations onto low-dimensional and orthogonal manifolds. Using behavioural testing and neuroimaging in humans, and analysis of neural signals from macaque prefrontal cortex, we report evidence for neural coding patterns in biological brains whose dimensionality and neural geometry are consistent with the rich learning regime.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-04-28},
	journal = {bioRxiv},
	author = {Flesch, Timo and Juechems, Keno and Dumbalska, Tsvetomira and Saxe, Andrew and Summerfield, Christopher},
	month = apr,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.04.23.441128},
	file = {Flesch et al_2021_Rich and lazy learning of task representations in brains and neural networks.pdf:/Users/tito/Zotero/storage/GSD9YAE9/Flesch et al_2021_Rich and lazy learning of task representations in brains and neural networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6F45HGXZ/2021.04.23.html:text/html},
}

@article{ahlheim_estimating_2018-1,
	title = {Estimating the functional dimensionality of neural representations},
	volume = {179},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811918305226},
	doi = {10.1016/j.neuroimage.2018.06.015},
	abstract = {Recent advances in multivariate fMRI analysis stress the importance of information inherent to voxel patterns. Key to interpreting these patterns is estimating the underlying dimensionality of neural representations. Dimensions may correspond to psychological dimensions, such as length and orientation, or involve other coding schemes. Unfortunately, the noise structure of fMRI data inflates dimensionality estimates and thus makes it difficult to assess the true underlying dimensionality of a pattern. To address this challenge, we developed a novel approach to identify brain regions that carry reliable task-modulated signal and to derive an estimate of the signal's functional dimensionality. We combined singular value decomposition with cross-validation to find the best low-dimensional projection of a pattern of voxel-responses at a single-subject level. Goodness of the low-dimensional reconstruction is measured as Pearson correlation with a test set, which allows to test for significance of the low-dimensional reconstruction across participants. Using hierarchical Bayesian modeling, we derive the best estimate and associated uncertainty of underlying dimensionality across participants. We validated our method on simulated data of varying underlying dimensionality, showing that recovered dimensionalities match closely true dimensionalities. We then applied our method to three published fMRI data sets all involving processing of visual stimuli. The results highlight three possible applications of estimating the functional dimensionality of neural data. Firstly, it can aid evaluation of model-based analyses by revealing which areas express reliable, task-modulated signal that could be missed by specific models. Secondly, it can reveal functional differences across brain regions. Thirdly, knowing the functional dimensionality allows assessing task-related differences in the complexity of neural patterns.},
	language = {en},
	urldate = {2021-05-04},
	journal = {NeuroImage},
	author = {Ahlheim, Christiane and Love, Bradley C.},
	month = oct,
	year = {2018},
	keywords = {Dimensionality reduction, Multivariate analysis, Neural representations},
	pages = {51--62},
	file = {Ahlheim_Love_2018_Estimating the functional dimensionality of neural representations.pdf:/Users/tito/Zotero/storage/S9ZRZGGE/Ahlheim_Love_2018_Estimating the functional dimensionality of neural representations.pdf:application/pdf},
}

@article{kay_glmdenoise_2013,
	title = {{GLMdenoise}: a fast, automated technique for denoising task-based {fMRI} data},
	volume = {7},
	issn = {1662-453X},
	shorttitle = {{GLMdenoise}},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2013.00247/full},
	doi = {10.3389/fnins.2013.00247},
	abstract = {In task-based functional magnetic resonance imaging (fMRI), researchers seek to measure fMRI signals related to a given task or condition. In many circumstances, measuring this signal of interest is limited by noise. In this study, we present GLMdenoise, a technique that improves signal-to-noise ratio (SNR) by entering noise regressors into a general linear model (GLM) analysis of fMRI data. The noise regressors are derived by conducting an initial model fit to determine voxels unrelated to the experimental paradigm, performing principal components analysis (PCA) on the time-series of these voxels, and using cross-validation to select the optimal number of principal components to use as noise regressors. Due to the use of data resampling, GLMdenoise requires and is best suited for datasets involving multiple runs (where conditions repeat across runs). We show that GLMdenoise consistently improves cross-validation accuracy of GLM estimates on a variety of event-related experimental datasets and is accompanied by substantial gains in SNR. To promote practical application of methods, we provide MATLAB code implementing GLMdenoise. Furthermore, to help compare GLMdenoise to other denoising methods, we present the Denoise Benchmark (DNB), a public database and architecture for evaluating denoising methods. The DNB consists of the datasets described in this paper, a code framework that enables automatic evaluation of a denoising method, and implementations of several denoising methods, including GLMdenoise, the use of motion parameters as noise regressors, ICA-based denoising, and RETROICOR/RVHRCOR. Using the DNB, we find that GLMdenoise performs best out of all of the denoising methods we tested.},
	language = {English},
	urldate = {2021-05-04},
	journal = {Front. Neurosci.},
	author = {Kay, Kendrick and Rokem, Ariel and Winawer, Jonathan and Dougherty, Robert and Wandell, Brian},
	year = {2013},
	note = {Publisher: Frontiers},
	keywords = {Cross-validation, general linear model, BOLD fMRI, ICA, signal-to-noise ratio, correlated noise, physiological noise, RETROICOR},
	file = {Kay et al_2013_GLMdenoise.pdf:/Users/tito/Zotero/storage/IVXY3Y2T/Kay et al_2013_GLMdenoise.pdf:application/pdf},
}

@article{charest_glmdenoise_2018,
	title = {{GLMdenoise} improves multivariate pattern analysis of {fMRI} data},
	volume = {183},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811918307626},
	doi = {10.1016/j.neuroimage.2018.08.064},
	abstract = {GLMdenoise is a denoising technique for task-based fMRI. In GLMdenoise, estimates of spatially correlated noise (which may be physiological, instrumental, motion-related, or neural in origin) are derived from the data and incorporated as nuisance regressors in a general linear model (GLM) analysis. We previously showed that GLMdenoise outperforms a variety of other denoising techniques in terms of cross-validation accuracy of GLM estimates (Kay et al., 2013a). However, the practical impact of denoising for experimental studies remains unclear. Here we examine whether and to what extent GLMdenoise improves sensitivity in the context of multivariate pattern analysis of fMRI data. On a large number of participants (31 participants across 4 experiments; 3 T, gradient-echo, spatial resolution 2–3.75 mm, temporal resolution 1.3–2 s, number of conditions 32–75), we perform representational similarity analysis (Kriegeskorte et al., 2008a) as well as pattern classification (Haxby et al., 2001). We find that GLMdenoise substantially improves replicability of representational dissimilarity matrices (RDMs) across independent splits of each participant's dataset (average RDM replicability increases from r = 0.46 to r = 0.61). Additionally, we find that GLMdenoise substantially improves pairwise classification accuracy (average classification accuracy increases from 79\% correct to 84\% correct). We show that GLMdenoise often improves and never degrades performance for individual participants and that GLMdenoise also improves across-participant consistency. We conclude that GLMdenoise is a useful tool that can be routinely used to maximize the amount of information extracted from fMRI activity patterns.},
	language = {en},
	urldate = {2021-05-04},
	journal = {NeuroImage},
	author = {Charest, Ian and Kriegeskorte, Nikolaus and Kay, Kendrick N.},
	month = dec,
	year = {2018},
	keywords = {Representational similarity analysis, Classification, Decoding, Cross-validation, General linear model, BOLD fMRI, Multivariate pattern analysis, Correlated noise, Denoising},
	pages = {606--616},
	file = {Charest et al_2018_GLMdenoise improves multivariate pattern analysis of fMRI data.pdf:/Users/tito/Zotero/storage/WHXSIF4T/Charest et al_2018_GLMdenoise improves multivariate pattern analysis of fMRI data.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/22K7DYG4/S1053811918307626.html:text/html},
}

@article{bobadilla-suarez_measures_2020,
	title = {Measures of {Neural} {Similarity}},
	volume = {3},
	issn = {2522-087X},
	url = {https://doi.org/10.1007/s42113-019-00068-5},
	doi = {10.1007/s42113-019-00068-5},
	abstract = {One fundamental question is what makes two brain states similar. For example, what makes the activity in visual cortex elicited from viewing a robin similar to a sparrow? One common assumption in fMRI analysis is that neural similarity is described by Pearson correlation. However, there are a host of other possibilities, including Minkowski and Mahalanobis measures, with each differing in its mathematical, theoretical, and neural computational assumptions. Moreover, the operable measures may vary across brain regions and tasks. Here, we evaluated which of several competing similarity measures best captured neural similarity. Our technique uses a decoding approach to assess the information present in a brain region, and the similarity measures that best correspond to the classifier’s confusion matrix are preferred. Across two published fMRI datasets, we found the preferred neural similarity measures were common across brain regions but differed across tasks. Moreover, Pearson correlation was consistently surpassed by alternatives.},
	language = {en},
	number = {4},
	urldate = {2021-05-04},
	journal = {Comput Brain Behav},
	author = {Bobadilla-Suarez, S. and Ahlheim, C. and Mehrotra, A. and Panos, A. and Love, B. C.},
	month = dec,
	year = {2020},
	pages = {369--383},
	file = {Bobadilla-Suarez et al_2020_Measures of Neural Similarity.pdf:/Users/tito/Zotero/storage/42GQB3AU/Bobadilla-Suarez et al_2020_Measures of Neural Similarity.pdf:application/pdf},
}

@article{moon_contribution_2021,
	title = {Contribution of {Excitatory} and {Inhibitory} {Neuronal} {Activity} to {BOLD} {fMRI}},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhab068},
	doi = {10.1093/cercor/bhab068},
	abstract = {The BOLD fMRI response in the cortex is often assumed to reflect changes in excitatory neural activity. However, the contribution of inhibitory neurons to BOLD fMRI is unclear. Here, the role of inhibitory and excitatory activity was examined using multimodal approaches: electrophysiological recording, 15.2 T fMRI, optical intrinsic signal imaging, and modeling. Inhibitory and excitatory neuronal activity in the somatosensory cortex were selectively modulated by 20-s optogenetic stimulation of VGAT-ChR2 and CaMKII-ChR2 mice, respectively. Somatosensory stimulation and optogenetic stimulation of excitatory neurons induced positive BOLD responses in the somatosensory network, whereas stimulation of inhibitory neurons produced biphasic responses at the stimulation site, initial positive and later negative BOLD signals, and negative BOLD responses at downstream sites. When the stimulation duration was reduced to 5 s, the hemodynamic response of VGAT-ChR2 mice to optogenetic stimulation was only positive. Lastly, modeling performed from neuronal and hemodynamic data shows that the hemodynamic response function (HRF) of excitatory neurons is similar across different conditions, whereas the HRF of inhibitory neurons is highly sensitive to stimulation frequency and peaks earlier than that of excitatory neurons. Our study provides insights into the neurovascular coupling of excitatory and inhibitory neurons and the interpretation of BOLD fMRI signals.},
	number = {bhab068},
	urldate = {2021-05-04},
	journal = {Cerebral Cortex},
	author = {Moon, Hyun Seok and Jiang, Haiyan and Vo, Thanh Tan and Jung, Won Beom and Vazquez, Alberto L and Kim, Seong-Gi},
	month = apr,
	year = {2021},
	file = {Moon et al_2021_Contribution of Excitatory and Inhibitory Neuronal Activity to BOLD fMRI.pdf:/Users/tito/Zotero/storage/EYCPTWQ6/Moon et al_2021_Contribution of Excitatory and Inhibitory Neuronal Activity to BOLD fMRI.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/L5PAEUCD/6248484.html:text/html},
}

@article{park_differences_2021,
	title = {Differences in subcortico-cortical interactions identified from connectome and microcircuit models in autism},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21732-0},
	doi = {10.1038/s41467-021-21732-0},
	abstract = {The pathophysiology of autism has been suggested to involve a combination of both macroscale connectome miswiring and microcircuit anomalies. Here, we combine connectome-wide manifold learning with biophysical simulation models to understand associations between global network perturbations and microcircuit dysfunctions in autism. We studied neuroimaging and phenotypic data in 47 individuals with autism and 37 typically developing controls obtained from the Autism Brain Imaging Data Exchange initiative. Our analysis establishes significant differences in structural connectome organization in individuals with autism relative to controls, with strong between-group effects in low-level somatosensory regions and moderate effects in high-level association cortices. Computational models reveal that the degree of macroscale anomalies is related to atypical increases of recurrent excitation/inhibition, as well as subcortical inputs into cortical microcircuits, especially in sensory and motor areas. Transcriptomic association analysis based on postmortem datasets identifies genes expressed in cortical and thalamic areas from childhood to young adulthood. Finally, supervised machine learning finds that the macroscale perturbations are associated with symptom severity scores on the Autism Diagnostic Observation Schedule. Together, our analyses suggest that atypical subcortico-cortical interactions are associated with both microcircuit and macroscale connectome differences in autism.},
	language = {en},
	number = {1},
	urldate = {2021-05-10},
	journal = {Nature Communications},
	author = {Park, Bo-yong and Hong, Seok-Jun and Valk, Sofie L. and Paquola, Casey and Benkarim, Oualid and Bethlehem, Richard A. I. and Di Martino, Adriana and Milham, Michael P. and Gozzi, Alessandro and Yeo, B. T. Thomas and Smallwood, Jonathan and Bernhardt, Boris C.},
	month = apr,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2225},
	file = {Park et al_2021_Differences in subcortico-cortical interactions identified from connectome and.pdf:/Users/tito/Zotero/storage/FQHAYNEH/Park et al_2021_Differences in subcortico-cortical interactions identified from connectome and.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VVX7M8NI/s41467-021-21732-0.html:text/html},
}

@article{lim_balanced_2013,
	title = {Balanced cortical microcircuitry for maintaining information in working memory},
	volume = {16},
	copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3492},
	doi = {10.1038/nn.3492},
	abstract = {Persistent neural activity in the absence of a stimulus is a neural correlate of working memory, but the mechanism remains unknown. Here the authors use mathematical modeling to demonstrate a corrective-feedback mechanism for maintaining persistent activity based upon the inhibitory and excitatory microcircuitry of neocortical memory-storing regions.},
	language = {en},
	number = {9},
	urldate = {2021-05-12},
	journal = {Nature Neuroscience},
	author = {Lim, Sukbin and Goldman, Mark S.},
	month = sep,
	year = {2013},
	note = {Number: 9
Publisher: Nature Publishing Group},
	pages = {1306--1314},
	file = {Lim_Goldman_2013_Balanced cortical microcircuitry for maintaining information in working memory.pdf:/Users/tito/Zotero/storage/LVL3X9RF/Lim_Goldman_2013_Balanced cortical microcircuitry for maintaining information in working memory.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/2L2DJNR4/nn.html:text/html},
}

@article{penny_comparing_2004,
	title = {Comparing dynamic causal models},
	volume = {22},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811904001648},
	doi = {10.1016/j.neuroimage.2004.03.026},
	abstract = {This article describes the use of Bayes factors for comparing dynamic causal models (DCMs). DCMs are used to make inferences about effective connectivity from functional magnetic resonance imaging (fMRI) data. These inferences, however, are contingent upon assumptions about model structure, that is, the connectivity pattern between the regions included in the model. Given the current lack of detailed knowledge on anatomical connectivity in the human brain, there are often considerable degrees of freedom when defining the connectional structure of DCMs. In addition, many plausible scientific hypotheses may exist about which connections are changed by experimental manipulation, and a formal procedure for directly comparing these competing hypotheses is highly desirable. In this article, we show how Bayes factors can be used to guide choices about model structure, both concerning the intrinsic connectivity pattern and the contextual modulation of individual connections. The combined use of Bayes factors and DCM thus allows one to evaluate competing scientific theories about the architecture of large-scale neural networks and the neuronal interactions that mediate perception and cognition.},
	language = {en},
	number = {3},
	urldate = {2021-05-13},
	journal = {NeuroImage},
	author = {Penny, W. D. and Stephan, K. E. and Mechelli, A. and Friston, K. J.},
	month = jul,
	year = {2004},
	keywords = {fMRI, Dynamic causal models, Bayes factors},
	pages = {1157--1172},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/NFAR3GSZ/S1053811904001648.html:text/html},
}

@article{stephan_ten_2010,
	title = {Ten simple rules for dynamic causal modeling},
	volume = {49},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811909011999},
	doi = {10.1016/j.neuroimage.2009.11.015},
	abstract = {Dynamic causal modeling (DCM) is a generic Bayesian framework for inferring hidden neuronal states from measurements of brain activity. It provides posterior estimates of neurobiologically interpretable quantities such as the effective strength of synaptic connections among neuronal populations and their context-dependent modulation. DCM is increasingly used in the analysis of a wide range of neuroimaging and electrophysiological data. Given the relative complexity of DCM, compared to conventional analysis techniques, a good knowledge of its theoretical foundations is needed to avoid pitfalls in its application and interpretation of results. By providing good practice recommendations for DCM, in the form of ten simple rules, we hope that this article serves as a helpful tutorial for the growing community of DCM users.},
	language = {en},
	number = {4},
	urldate = {2021-05-13},
	journal = {NeuroImage},
	author = {Stephan, K. E. and Penny, W. D. and Moran, R. J. and den Ouden, H. E. M. and Daunizeau, J. and Friston, K. J.},
	month = feb,
	year = {2010},
	keywords = {fMRI, EEG, Effective connectivity, MEG, DCM, Nonlinear dynamics, Synaptic plasticity, Bayes factor, Bayesian model selection, BMS, Model comparison, Model evidence},
	pages = {3099--3109},
	file = {Stephan et al_2010_Ten simple rules for dynamic causal modeling.pdf:/Users/tito/Zotero/storage/HPGALZYQ/Stephan et al_2010_Ten simple rules for dynamic causal modeling.pdf:application/pdf},
}

@article{friston_dynamic_2003-1,
	title = {Dynamic causal modelling},
	volume = {19},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811903002027},
	doi = {10.1016/S1053-8119(03)00202-7},
	abstract = {In this paper we present an approach to the identification of nonlinear input–state–output systems. By using a bilinear approximation to the dynamics of interactions among states, the parameters of the implicit causal model reduce to three sets. These comprise (1) parameters that mediate the influence of extrinsic inputs on the states, (2) parameters that mediate intrinsic coupling among the states, and (3) [bilinear] parameters that allow the inputs to modulate that coupling. Identification proceeds in a Bayesian framework given known, deterministic inputs and the observed responses of the system. We developed this approach for the analysis of effective connectivity using experimentally designed inputs and fMRI responses. In this context, the coupling parameters correspond to effective connectivity and the bilinear parameters reflect the changes in connectivity induced by inputs. The ensuing framework allows one to characterise fMRI experiments, conceptually, as an experimental manipulation of integration among brain regions (by contextual or trial-free inputs, like time or attentional set) that is revealed using evoked responses (to perturbations or trial-bound inputs, like stimuli). As with previous analyses of effective connectivity, the focus is on experimentally induced changes in coupling (cf., psychophysiologic interactions). However, unlike previous approaches in neuroimaging, the causal model ascribes responses to designed deterministic inputs, as opposed to treating inputs as unknown and stochastic.},
	language = {en},
	number = {4},
	urldate = {2021-05-13},
	journal = {NeuroImage},
	author = {Friston, K. J. and Harrison, L. and Penny, W.},
	month = aug,
	year = {2003},
	keywords = {fMRI, Effective connectivity, Bilinear model, Functional neuroimaging, Hemodynamic response function, Nonlinear system identification},
	pages = {1273--1302},
	file = {Friston et al_2003_Dynamic causal modelling.pdf:/Users/tito/Zotero/storage/ABH89GTI/Friston et al_2003_Dynamic causal modelling.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3X7WVFRZ/S1053811903002027.html:text/html},
}

@article{vanrullen_deep_2021,
	title = {Deep learning and the {Global} {Workspace} {Theory}},
	volume = {0},
	issn = {0166-2236, 1878-108X},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00077-1},
	doi = {10.1016/j.tins.2021.04.005},
	language = {English},
	number = {0},
	urldate = {2021-05-17},
	journal = {Trends in Neurosciences},
	author = {VanRullen, Rufin and Kanai, Ryota},
	month = may,
	year = {2021},
	note = {Publisher: Elsevier},
	keywords = {attention, broadcast, consciousness, grounding, latent space, multimodal translation},
	file = {Snapshot:/Users/tito/Zotero/storage/PMFLLS4V/S0166-2236(21)00077-1.html:text/html},
}

@article{monfared_transformation_2020,
	title = {Transformation of {ReLU}-based recurrent neural networks from discrete-time to continuous-time},
	url = {http://arxiv.org/abs/2007.00321},
	abstract = {Recurrent neural networks (RNN) as used in machine learning are commonly formulated in discrete time, i.e. as recursive maps. This brings a lot of advantages for training models on data, e.g. for the purpose of time series prediction or dynamical systems identification, as powerful and efficient inference algorithms exist for discrete time systems and numerical integration of differential equations is not necessary. On the other hand, mathematical analysis of dynamical systems inferred from data is often more convenient and enables additional insights if these are formulated in continuous time, i.e. as systems of ordinary (or partial) differential equations (ODE). Here we show how to perform such a translation from discrete to continuous time for a particular class of ReLU-based RNN. We prove three theorems on the mathematical equivalence between the discrete and continuous time formulations under a variety of conditions, and illustrate how to use our mathematical results on different machine learning and nonlinear dynamical systems examples.},
	urldate = {2021-05-18},
	journal = {arXiv:2007.00321 [math]},
	author = {Monfared, Zahra and Durstewitz, Daniel},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.00321},
	keywords = {Mathematics - Dynamical Systems},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/2WL8EXQP/2007.html:text/html;Monfared_Durstewitz_2020_Transformation of ReLU-based recurrent neural networks from discrete-time to.pdf:/Users/tito/Zotero/storage/XC6M55AZ/Monfared_Durstewitz_2020_Transformation of ReLU-based recurrent neural networks from discrete-time to.pdf:application/pdf},
}

@article{diedrichsen_distribution_2016,
	title = {On the distribution of cross-validated {Mahalanobis} distances},
	url = {http://arxiv.org/abs/1607.01371},
	abstract = {We present analytical expressions for the means and covariances of the sample distribution of the cross-validated Mahalanobis distance. This measure has proven to be especially useful in the context of representational similarity analysis (RSA) of neural activity patterns as measured by means of functional magnetic resonance imaging (fMRI). These expressions allow us to construct a normal approximation to the estimated distances, which in turn enables powerful inference on the measured statistics. Using the results, the difference between two distances can be statistically assessed, and the measured structure of the distances can be efficiently compared to predictions from computational models.},
	urldate = {2021-05-18},
	journal = {arXiv:1607.01371 [stat]},
	author = {Diedrichsen, Jörn and Provost, Serge and Zareamoghaddam, Hossein},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.01371},
	keywords = {Statistics - Applications},
	annote = {Comment: 24 pages, 5 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/F86LQAYX/1607.html:text/html;Diedrichsen et al_2016_On the distribution of cross-validated Mahalanobis distances.pdf:/Users/tito/Zotero/storage/CHFV6USH/Diedrichsen et al_2016_On the distribution of cross-validated Mahalanobis distances.pdf:application/pdf},
}

@article{levinson_cortical_2021,
	title = {Cortical and subcortical signatures of conscious object recognition},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-23266-x},
	doi = {10.1038/s41467-021-23266-x},
	abstract = {The neural mechanisms underlying conscious recognition remain unclear, particularly the roles played by the prefrontal cortex, deactivated brain areas and subcortical regions. We investigated neural activity during conscious object recognition using 7 Tesla fMRI while human participants viewed object images presented at liminal contrasts. Here, we show both recognized and unrecognized images recruit widely distributed cortical and subcortical regions; however, recognized images elicit enhanced activation of visual, frontoparietal, and subcortical networks and stronger deactivation of the default-mode network. For recognized images, object category information can be decoded from all of the involved cortical networks but not from subcortical regions. Phase-scrambled images trigger strong involvement of inferior frontal junction, anterior cingulate cortex and default-mode network, implicating these regions in inferential processing under increased uncertainty. Our results indicate that content-specific activity in both activated and deactivated cortical networks and non-content-specific subcortical activity support conscious recognition.},
	language = {en},
	number = {1},
	urldate = {2021-05-18},
	journal = {Nature Communications},
	author = {Levinson, Max and Podvalny, Ella and Baete, Steven H. and He, Biyu J.},
	month = may,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {2930},
	file = {Levinson et al_2021_Cortical and subcortical signatures of conscious object recognition.pdf:/Users/tito/Zotero/storage/IGNV2J5A/Levinson et al_2021_Cortical and subcortical signatures of conscious object recognition.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4G7TWUMG/s41467-021-23266-x.html:text/html},
}

@article{zhi_evaluating_2021,
	title = {Evaluating brain parcellations using the distance controlled boundary coefficient},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.11.443151v1},
	doi = {10.1101/2021.05.11.443151},
	abstract = {{\textless}p{\textgreater}An important goal of human brain mapping is to define a set of distinct regions that can be linked to unique functions. Numerous brain parcellations have been proposed, using cytoarchitectonic data, structural or functional Magnetic Resonance Imaging (fMRI). The intrinsic smoothness of the brain data, however, poses a problem for current methods seeking to compare different parcellations to each other. For example, criteria that simply compare within-parcel to between-parcel similarity provide even random parcellations with a high value. Furthermore, the evaluation is biased by the spatial scale of the parcellation. To address this problem, we propose the Distance Controlled Boundary Coefficient (DCBC), an unbiased criterion to evaluate discrete parcellations. We employ this new criterion to evaluate whether existing parcellations of the human neocortex can predict functional boundaries on a rich multi-domain task battery. We find that common anatomical parcellations do not perform better than chance, suggesting that task-based functional boundaries do not align well with sulcal landmarks. Parcellations based on resting-state fMRI data perform well; in some cases, as well as a parcellation defined on the evaluation data itself. Finally, multi-modal parcellations that combine functional and anatomical criteria perform substantially worse than those based on functional data alone, indicating that functionally homogeneous regions often span major anatomical landmarks. Overall, the DCBC advances the field of functional brain mapping by providing an unbiased metric that compares the predictive ability of different brain parcellations to define functionally and anatomically homogeneous brain regions.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-05-18},
	journal = {bioRxiv},
	author = {Zhi, Da and King, Maedbh and Diedrichsen, Jörn},
	month = may,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.05.11.443151},
	file = {Zhi et al_2021_Evaluating brain parcellations using the distance controlled boundary.pdf:/Users/tito/Zotero/storage/IKH7JGP5/Zhi et al_2021_Evaluating brain parcellations using the distance controlled boundary.pdf:application/pdf},
}

@article{zeraati_attentional_2021,
	title = {Attentional modulation of intrinsic timescales in visual cortex and spatial networks},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.17.444537v1},
	doi = {10.1101/2021.05.17.444537},
	abstract = {{\textless}p{\textgreater}Neural activity fluctuates endogenously on timescales varying across the neocortex. The variation in these intrinsic timescales relates to the functional specialization of cortical areas and their involvement in the temporal integration of information. Yet, it is unknown whether the timescales can adjust rapidly and selectively to the demands of a cognitive task. We measured intrinsic timescales of local spiking activity within columns of area V4 while monkeys performed spatial attention tasks. The ongoing spiking activity unfolded across at least two distinct timescales---fast and slow---and the slow timescale increased when monkeys attended to the receptive fields location. A recurrent network model shows that multiple timescales in local dynamics arise from spatial connectivity mimicking vertical and horizontal interactions in visual cortex and that slow timescales increase with the efficacy of recurrent interactions. Our results reveal that targeted neural populations integrate information over variable timescales following the demands of a cognitive task and propose an underlying network mechanism.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-05-19},
	journal = {bioRxiv},
	author = {Zeraati, Roxana and Shi, Yan-Liang and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Levina, Anna and Engel, Tatiana A.},
	month = may,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.05.17.444537},
	file = {Snapshot:/Users/tito/Zotero/storage/4Z2AMJL5/2021.05.17.444537v1.full.html:text/html;Zeraati et al_2021_Attentional modulation of intrinsic timescales in visual cortex and spatial.pdf:/Users/tito/Zotero/storage/I2JZKYKV/Zeraati et al_2021_Attentional modulation of intrinsic timescales in visual cortex and spatial.pdf:application/pdf},
}

@article{canatar_spectral_2021,
	title = {Spectral {Bias} and {Task}-{Model} {Alignment} {Explain} {Generalization} in {Kernel} {Regression} and {Infinitely} {Wide} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2006.13198},
	abstract = {A theoretical understanding of generalization remains an open problem for many machine learning models, including deep networks where overparameterization leads to better performance, contradicting the conventional wisdom from classical statistics. Here, we investigate generalization error for kernel regression, which, besides being a popular machine learning method, also describes certain inﬁnitely overparameterized neural networks. We use techniques from statistical mechanics to derive an analytical expression for generalization error applicable to any kernel and data distribution. We present applications of our theory to real and synthetic datasets, and for many kernels including those that arise from training deep networks in the inﬁnite-width limit. We elucidate an inductive bias of kernel regression to explain data with simple functions, characterize whether a kernel is compatible with a learning task, and show that more data may impair generalization when noisy or not expressible by the kernel, leading to non-monotonic learning curves with possibly many peaks.},
	language = {en},
	urldate = {2021-05-20},
	journal = {arXiv:2006.13198 [cond-mat, stat]},
	author = {Canatar, Abdulkadir and Bordelon, Blake and Pehlevan, Cengiz},
	month = apr,
	year = {2021},
	note = {arXiv: 2006.13198},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks},
	annote = {Comment: Accepted for publication in Nature Communications},
	file = {Canatar et al. - 2021 - Spectral Bias and Task-Model Alignment Explain Gen.pdf:/Users/tito/Zotero/storage/NGTU95QS/Canatar et al. - 2021 - Spectral Bias and Task-Model Alignment Explain Gen.pdf:application/pdf},
}

@misc{noauthor_messages_nodate,
	title = {Messages},
	url = {https://messages.google.com/web/conversations/432ea79758d63355530fcb0b22cbc214},
	urldate = {2021-05-24},
	file = {Messages:/Users/tito/Zotero/storage/ET2FFR2E/432ea79758d63355530fcb0b22cbc214.html:text/html},
}

@article{cohen_improved_2021,
	title = {Improved resting state functional connectivity sensitivity and reproducibility using a multiband multi-echo acquisition},
	volume = {225},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920309460},
	doi = {10.1016/j.neuroimage.2020.117461},
	abstract = {Recent advances in functional MRI techniques include multiband (MB) imaging and multi-echo (ME) imaging. In MB imaging multiple slices are acquired simultaneously leading to significant increases in temporal and spatial resolution. Multi-echo imaging enables multiple echoes to be acquired in one shot, where the ME images can be used to denoise the BOLD time series and increase BOLD sensitivity. In this study, resting state fMRI (rs-fMRI) data were collected using a combined MBME sequence and compared to an MB single echo sequence. In total, 29 subjects were imaged, and 18 of them returned within two weeks for repeat imaging. Participants underwent one MBME scan with three echoes and one MB scan with one echo. Both datasets were processed using standard denoising and advanced denoising. Advanced denoising included multi-echo independent component analysis (ME-ICA) for the MBME data and ICA-AROMA for the MB data. Resting state functional connectivity (RSFC) was evaluated using both selective seed-based and whole grey matter (GM) region-of-interest (ROI) based approaches. The reproducibility of connectivity metrics was also analyzed in the repeat subjects. In addition, functional connectivity density (FCD), a data-driven approach that counts the number of significant connections, both within a local cluster and globally, with each voxel was analyzed. Regardless of the standard or advanced denoising technique, all seed-based RSFC was significantly higher for MBME compared to MB. Much more GM ROI combinations showed significantly higher RSFC for MBME vs. MB. Reproducibility, evaluated using the dice coefficient was significantly higher for MBME relative to MB data. Finally, FCD was also higher for MBME vs. MB data. This study showed higher RSFC for MBME vs. MB data using selected seed-based, whole GM ROI-based, and data-driven approaches. Reproducibility found also higher for MBME data. Taken together, these results indicate that MBME is a promising technique for rs-fMRI.},
	language = {en},
	urldate = {2021-05-24},
	journal = {NeuroImage},
	author = {Cohen, Alexander D. and Yang, Baolian and Fernandez, Brice and Banerjee, Suchandrima and Wang, Yang},
	month = jan,
	year = {2021},
	keywords = {Multi-echo, Reproducibility, Functional connectivity density, Multi-echo independent component analysis, Multiband, Resting state functional MRI},
	pages = {117461},
	file = {Cohen et al_2021_Improved resting state functional connectivity sensitivity and reproducibility.pdf:/Users/tito/Zotero/storage/ZJI4K9QM/Cohen et al_2021_Improved resting state functional connectivity sensitivity and reproducibility.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/4SU2BAGK/S1053811920309460.html:text/html},
}

@article{cohen_detecting_2021,
	title = {Detecting {Task} {Functional} {MRI} {Activation} {Using} the {Multiband} {Multiecho} ({MBME}) {Echo}-{Planar} {Imaging} ({EPI}) {Sequence}},
	volume = {53},
	copyright = {© 2020 International Society for Magnetic Resonance in Medicine},
	issn = {1522-2586},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.27448},
	doi = {https://doi.org/10.1002/jmri.27448},
	abstract = {Background Blood oxygen level-dependent (BOLD) functional MRI (fMRI) has been widely applied to detect brain activations. Recent advances in multiband (MB) and multiecho (ME) techniques have greatly improved fMRI methods. MB imaging improves temporal and/or spatial resolution, while ME imaging has been shown to improve BOLD sensitivity. This study aimed to evaluate the novel MBME echo planar imaging (EPI) sequence utilizing MB and ME simultaneously to determine if the MBME outperform the MB single echo (MBSE) sequence for task fMRI. Purpose To compare the performance of MBME with MBSE in a task fMRI study. Study Type Prospective. Population A total of 29 healthy volunteers aged 20–46 years (9 male, 20 female). Field Strength/Sequence MBSE and MBME gradient-echo EPI sequences were applied at 3T. Additional T1-weighted magnetization-prepared rapid acquisition with gradient echo (MPRAGE) was collected. Assessment A checkerboard visual task was presented during the functional MBSE and MBME scans. The MBME or MBSE signal was evaluated using the temporal signal-to-noise ratio (tSNR). Task activation was evaluated using the z-score, volume, sensitivity, and specificity. Test–retest metrics of task activation were examined with the Dice coefficient (DC) and intraclass correlation coefficient (ICC) on subjects with repeated scans. Statistical Tests A linear mixed-effects model was used to compared MBME and MBSE activation at the voxel base. The paired t-test was used to compare tSNR, activation z-score, and volume, along with sensitivity, specificity, and DC between MBSE and MBME. Results While similar task activation was detected in the visual cortex, MBME showed higher activation volume and higher sensitivity compared with MBSE (P {\textless} 0.05). ICC was higher for MBME than MBSE, while there was a trend of differences in DC (P = 0.08). Data Conclusion MBME resulted in higher task fMRI activation volume and sensitivity without losing specificity. Reliability was also higher for MBME scans compared with MBSE. Level of Evidence 1 Technical Efficacy Stage 1},
	language = {en},
	number = {5},
	urldate = {2021-05-24},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Cohen, Alexander D. and Jagra, Amritpal S. and Yang, Baolian and Fernandez, Brice and Banerjee, Suchandrima and Wang, Yang},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.27448},
	keywords = {functional MRI, blood oxygen level dependent, multiband, multiecho, visual checkerboard task},
	pages = {1366--1374},
	file = {Cohen et al_2021_Detecting Task Functional MRI Activation Using the Multiband Multiecho (MBME).pdf:/Users/tito/Zotero/storage/7EV6IZM2/Cohen et al_2021_Detecting Task Functional MRI Activation Using the Multiband Multiecho (MBME).pdf:application/pdf},
}

@article{belkin_reconciling_2019,
	title = {Reconciling modern machine-learning practice and the classical bias–variance trade-off},
	volume = {116},
	copyright = {© 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/32/15849},
	doi = {10.1073/pnas.1903070116},
	abstract = {Author Information
Mikhail Belkina,b,1, Daniel Hsuc, Siyuan Maa, and Soumik MandalaaDepartment of Computer Science and Engineering, The Ohio State University, Columbus, OH 43210;bDepartment of Statistics, The Ohio State University, Columbus, OH 43210;cComputer Science Department and Data Science Institute, Columbia University, New York, NY 10027Edited by Peter J. Bickel, University of California, Berkeley, CA, and approved July 2, 2019 (received for review February 21, 2019)
Footnotes↵1To whom correspondence may be addressed. Email: mbelkin@cse.ohio-state.edu.Author contributions: M.B., D.H., S. Ma, and S. Mandal designed research, performed research, analyzed data, and wrote the paper.The authors declare no conflict of interest.This article is a PNAS Direct Submission.This article contains supporting information online at www.pnas.org/lookup/suppl/doi:10.1073/pnas.1903070116/-/DCSupplemental.},
	language = {en},
	number = {32},
	urldate = {2021-05-25},
	journal = {PNAS},
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	month = aug,
	year = {2019},
	pmid = {31341078},
	note = {Publisher: National Academy of Sciences
Section: Physical Sciences},
	pages = {15849--15854},
	file = {Belkin et al_2019_Reconciling modern machine-learning practice and the classical bias–variance.pdf:/Users/tito/Zotero/storage/UCKJLUPB/Belkin et al_2019_Reconciling modern machine-learning practice and the classical bias–variance.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GVA43IBI/tab-article-info.html:text/html},
}

@article{loog_brief_2020,
	title = {A brief prehistory of double descent},
	volume = {117},
	copyright = {© 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/117/20/10625},
	doi = {10.1073/pnas.2001875117},
	abstract = {In their thought-provoking paper, Belkin et al. (1) illustrate and discuss the shape of risk curves in the context of modern high-complexity learners. Given a fixed training sample size n, such curves show the risk of a learner as a function of some (approximate) measure of its complexity N. With N the number of features, these curves are also referred to as feature curves. A salient observation in ref. 1 is that these curves can display what they call double descent: With increasing N, the risk initially decreases, attains a minimum, and then increases until N equals n, where the training data are fitted perfectly. Increasing N even further, the risk decreases a second and final time, creating a peak at {\textless}mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"{\textgreater}{\textless}mml:mi{\textgreater}N{\textless}/mml:mi{\textgreater}{\textless}mml:mo{\textgreater}= … {\textless}/mml:mo{\textgreater}{\textless}/mml:math{\textgreater}

[↵][1]1To whom correspondence may be addressed. Email: m.loog\{at\}tudelft.nl.

 [1]: \#xref-corresp-1-1},
	language = {en},
	number = {20},
	urldate = {2021-05-25},
	journal = {PNAS},
	author = {Loog, Marco and Viering, Tom and Mey, Alexander and Krijthe, Jesse H. and Tax, David M. J.},
	month = may,
	year = {2020},
	pmid = {32371495},
	note = {Publisher: National Academy of Sciences
Section: Letter},
	pages = {10625--10626},
	file = {Loog et al_2020_A brief prehistory of double descent.pdf:/Users/tito/Zotero/storage/TD7HTYUH/Loog et al_2020_A brief prehistory of double descent.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VGENBSXX/10625.html:text/html},
}

@article{aquino_intersection_2021,
	title = {On the intersection between data quality and dynamical modelling of large-scale {fMRI} signals},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.23.445373v1},
	doi = {10.1101/2021.05.23.445373},
	abstract = {{\textless}p{\textgreater}Large-scale dynamics of the brain are routinely modelled us- ing systems of nonlinear dynamical equations that describe the evolution of population-level activity, with distinct neural pop- ulations often coupled according to an empirically measured structural connection matrix. This modelling approach has been used to generate insights into the neural underpinnings of spontaneous brain dynamics, as recorded with techniques such as resting state functional MRI (fMRI). In fMRI, researchers have many degrees of freedom in the way that they can pro- cess the data and recent evidence indicates that the choice of pre-processing steps can have a major effect on empirical esti- mates of functional connectivity. However, the potential influ- ence of such variations on modelling results are seldom consid- ered. Here we show, using three popular whole-brain dynam- ical models, that different choices during fMRI preprocessing can dramatically affect model fits and interpretations of find- ings. Critically, we show that the ability of these models to ac- curately capture patterns in fMRI dynamics is mostly driven by the degree to which they fit global signals rather than inter- esting sources of coordinated neural dynamics. We show that widespread deflections can arise from simple global synchroni- sation. We introduce a simple two-parameter model that cap- tures these fluctuations and which performs just as well as more complex, multi-parameter biophysical models. From our com- bined analyses of data and simulations, we describe benchmarks to evaluate model fit and validity. Although most models are not resilient to denoising, we show that relaxing the approxima- tion of homogeneous neural populations by more explicitly modelling inter-regional effective connectivity can improve model accuracy at the expense of increased model complexity. Our results suggest that many complex biophysical models may be fitting relatively trivial properties of the data, and underscore a need for tighter integration between data quality assurance and model development.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-05-26},
	journal = {bioRxiv},
	author = {Aquino, Kevin M. and Fulcher, Ben D. and Oldham, Stuart and Parkes, Linden M. and Gollo, Leonardo and Deco, Gustavo and Fornito, Alex},
	month = may,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.05.23.445373},
	file = {Aquino et al_2021_On the intersection between data quality and dynamical modelling of large-scale.pdf:/Users/tito/Zotero/storage/RHCLCL4R/Aquino et al_2021_On the intersection between data quality and dynamical modelling of large-scale.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BMWTXZAL/2021.05.23.html:text/html},
}

@article{schulz_compositional_2017,
	title = {Compositional inductive biases in function learning},
	volume = {99},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/S0010028517301743},
	doi = {10.1016/j.cogpsych.2017.11.002},
	abstract = {How do people recognize and learn about complex functional structure? Taking inspiration from other areas of cognitive science, we propose that this is achieved by harnessing compositionality: complex structure is decomposed into simpler building blocks. We formalize this idea within the framework of Bayesian regression using a grammar over Gaussian process kernels, and compare this approach with other structure learning approaches. Participants consistently chose compositional (over non-compositional) extrapolations and interpolations of functions. Experiments designed to elicit priors over functional patterns revealed an inductive bias for compositional structure. Compositional functions were perceived as subjectively more predictable than non-compositional functions, and exhibited other signatures of predictability, such as enhanced memorability and reduced numerosity. Taken together, these results support the view that the human intuitive theory of functions is inherently compositional.},
	language = {en},
	urldate = {2021-05-28},
	journal = {Cognitive Psychology},
	author = {Schulz, Eric and Tenenbaum, Joshua B. and Duvenaud, David and Speekenbrink, Maarten and Gershman, Samuel J.},
	month = dec,
	year = {2017},
	keywords = {Gaussian process, Compositionality, Function learning, Pattern recognition, Structure search},
	pages = {44--79},
	file = {Schulz et al_2017_Compositional inductive biases in function learning.pdf:/Users/tito/Zotero/storage/I9D44BAP/Schulz et al_2017_Compositional inductive biases in function learning.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/8U6NSEB2/S0010028517301743.html:text/html},
}

@article{radulescu_human_2021,
	title = {Human {Representation} {Learning}},
	volume = {44},
	url = {https://doi.org/10.1146/annurev-neuro-092920-120559},
	doi = {10.1146/annurev-neuro-092920-120559},
	abstract = {The central theme of this review is the dynamic interaction between information selection and learning. We pose a fundamental question about this interaction: How do we learn what features of our experiences are worth learning about? In humans, this process depends on attention and memory, two cognitive functions that together constrain representations of the world to features that are relevant for goal attainment. Recent evidence suggests that the representations shaped by attention and memory are themselves inferred from experience with each task. We review this evidence and place it in the context of work that has explicitly characterized representation learning as statistical inference. We discuss how inference can be scaled to real-world decisions by approximating beliefs based on a small number of experiences. Finally, we highlight some implications of this inference process for human decision-making in social environments. Expected final online publication date for the Annual Review of Neuroscience, Volume 44 is July 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	urldate = {2021-06-01},
	journal = {Annual Review of Neuroscience},
	author = {Radulescu, Angela and Shin, Yeon Soon and Niv, Yael},
	year = {2021},
	pmid = {33730510},
	note = {\_eprint: https://doi.org/10.1146/annurev-neuro-092920-120559},
	pages = {null},
}

@article{shinn_spatial_2021,
	title = {Spatial and temporal autocorrelation weave human brain networks},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.06.01.446561v1},
	doi = {10.1101/2021.06.01.446561},
	abstract = {{\textless}p{\textgreater}Correlations are a basic object of analysis across neuroscience, but multivariate patterns of correlations can be difficult to interpret. For example, correlations are fundamental to understanding timeseries derived from resting-state functional magnetic resonance imaging (rs-fMRI), a proxy of brain activity. Networks constructed from regional correlations in rs-fMRI timeseries are often interpreted as brain connectivity, yet the links between brain networks and neurobiology have until now been largely speculative. Here, we show that the topology of rs-fMRI brain networks is caused by the spatial and temporal autocorrelation of the timeseries used to construct them. Spatial and temporal autocorrelation show high test-retest reliability, and are correlated with popular measures of network topology. A generative model of spatially and temporally autocorrelated timeseries exhibits similar network topology to brain networks, and when fit to individual subjects, it captures near the reliability limit of subject and regional variation. We demonstrate why spatial and temporal autocorrelation induce network structure, and highlight their ability to link graph properties to neurobiology during healthy aging. These results offer a reductionistic account of brain network complexity, explaining characteristic patterns in brain networks using timeseries statistics.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-02},
	journal = {bioRxiv},
	author = {Shinn, Maxwell and Hu, Amber and Turner, Laurel and Noble, Stephanie and Achard, Sophie and Anticevic, Alan and Scheinost, Dustin and Constable, R. Todd and Lee, Daeyeol and Bullmore, Edward T. and Murray, John D.},
	month = jun,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.06.01.446561},
	file = {Shinn et al_2021_Spatial and temporal autocorrelation weave human brain networks.pdf:/Users/tito/Zotero/storage/T73EQNK7/Shinn et al_2021_Spatial and temporal autocorrelation weave human brain networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/XIGZAV6F/2021.06.01.html:text/html},
}

@article{zimmermann_subject_2018,
	title = {Subject specificity of the correlation between large-scale structural and functional connectivity},
	volume = {3},
	issn = {2472-1751},
	url = {https://doi.org/10.1162/netn_a_00055},
	doi = {10.1162/netn_a_00055},
	abstract = {Structural connectivity (SC), the physical pathways connecting regions in the brain, and functional connectivity (FC), the temporal coactivations, are known to be tightly linked. However, the nature of this relationship is still not understood. In the present study, we examined this relation more closely in six separate human neuroimaging datasets with different acquisition and preprocessing methods. We show that using simple linear associations, the relation between an individual’s SC and FC is not subject specific for five of the datasets. Subject specificity of SC-FC fit is achieved only for one of the six datasets, the multimodal Glasser Human Connectome Project (HCP) parcellated dataset. We show that subject specificity of SC-FC correspondence is limited across datasets due to relatively small variability between subjects in SC compared with the larger variability in FC.We present evidence that, in most standard datasets, the subject variation in structural connectivity (SC) may be too weak to be reflected in the functional connectivity (FC) variability. However, subject specificity of SC-FC can be captured via fine, multimodally parcellated data because of greater SC variability across subjects. Nonetheless, SC and FC each show a large component that is common across subjects, which sets limitations on the extent of SC-FC subject specificity. Implications of these findings for personalized medicine should be considered. Namely, attention to the quality of processing and parcellation methods is critical for furthering our understanding of the relationship between individual SC and FC.},
	number = {1},
	urldate = {2021-06-02},
	journal = {Network Neuroscience},
	author = {Zimmermann, J. and Griffiths, J. and Schirner, M. and Ritter, P. and McIntosh, A. R.},
	month = dec,
	year = {2018},
	pages = {90--106},
	file = {Snapshot:/Users/tito/Zotero/storage/3NTP436X/Subject-specificity-of-the-correlation-between.html:text/html;Zimmermann et al_2018_Subject specificity of the correlation between large-scale structural and.pdf:/Users/tito/Zotero/storage/QSHP3AU4/Zimmermann et al_2018_Subject specificity of the correlation between large-scale structural and.pdf:application/pdf},
}

@article{chavlis_drawing_2021,
	title = {Drawing inspiration from biological dendrites to empower artificial neural networks},
	volume = {70},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438821000544},
	doi = {10.1016/j.conb.2021.04.007},
	abstract = {This article highlights specific features of biological neurons and their dendritic trees, whose adoption may help advance artificial neural networks used in various machine learning applications. Advancements could take the form of increased computational capabilities and/or reduced power consumption. Proposed features include dendritic anatomy, dendritic nonlinearities, and compartmentalized plasticity rules, all of which shape learning and information processing in biological networks. We discuss the computational benefits provided by these features in biological neurons and suggest ways to adopt them in artificial neurons in order to exploit the respective benefits in machine learning.},
	language = {en},
	urldate = {2021-06-02},
	journal = {Current Opinion in Neurobiology},
	author = {Chavlis, Spyridon and Poirazi, Panayiota},
	month = oct,
	year = {2021},
	pages = {1--10},
	file = {Chavlis_Poirazi_2021_Drawing inspiration from biological dendrites to empower artificial neural.pdf:/Users/tito/Zotero/storage/3I7QXTGG/Chavlis_Poirazi_2021_Drawing inspiration from biological dendrites to empower artificial neural.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/Y5UI8B2G/S0959438821000544.html:text/html},
}

@inproceedings{woodworth_kernel_2020,
	title = {Kernel and {Rich} {Regimes} in {Overparametrized} {Models}},
	url = {http://proceedings.mlr.press/v125/woodworth20a.html},
	abstract = {A recent line of work studies overparametrized neural networks in the “kernel regime,” i.e. when  during training the network behaves as a kernelized linear predictor, and thus, training with grad...},
	language = {en},
	urldate = {2021-06-03},
	booktitle = {Conference on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D. and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
	month = jul,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {3635--3673},
	file = {Snapshot:/Users/tito/Zotero/storage/SES6KV5J/woodworth20a.html:text/html;Woodworth et al_2020_Kernel and Rich Regimes in Overparametrized Models.pdf:/Users/tito/Zotero/storage/HZK2WYKS/Woodworth et al_2020_Kernel and Rich Regimes in Overparametrized Models.pdf:application/pdf},
}

@article{chizat_lazy_2020,
	title = {On {Lazy} {Training} in {Differentiable} {Programming}},
	url = {http://arxiv.org/abs/1812.07956},
	abstract = {In a series of recent theoretical works, it was shown that strongly over-parameterized neural networks trained with gradient-based methods could converge exponentially fast to zero training loss, with their parameters hardly varying. In this work, we show that this "lazy training" phenomenon is not specific to over-parameterized neural networks, and is due to a choice of scaling, often implicit, that makes the model behave as its linearization around the initialization, thus yielding a model equivalent to learning with positive-definite kernels. Through a theoretical analysis, we exhibit various situations where this phenomenon arises in non-convex optimization and we provide bounds on the distance between the lazy and linearized optimization paths. Our numerical experiments bring a critical note, as we observe that the performance of commonly used non-linear deep convolutional neural networks in computer vision degrades when trained in the lazy regime. This makes it unlikely that "lazy training" is behind the many successes of neural networks in difficult high dimensional tasks.},
	urldate = {2021-06-03},
	journal = {arXiv:1812.07956 [cs, math]},
	author = {Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
	month = jan,
	year = {2020},
	note = {arXiv: 1812.07956},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DPP8EG38/1812.html:text/html;Chizat et al_2020_On Lazy Training in Differentiable Programming.pdf:/Users/tito/Zotero/storage/5EXXR64G/Chizat et al_2020_On Lazy Training in Differentiable Programming.pdf:application/pdf},
}

@article{jacot_neural_2020,
	title = {Neural {Tangent} {Kernel}: {Convergence} and {Generalization} in {Neural} {Networks}},
	shorttitle = {Neural {Tangent} {Kernel}},
	url = {http://arxiv.org/abs/1806.07572},
	abstract = {At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function \$f\_{\textbackslash}theta\$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function \$f\_{\textbackslash}theta\$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.},
	urldate = {2021-06-03},
	journal = {arXiv:1806.07572 [cs, math, stat]},
	author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clément},
	month = feb,
	year = {2020},
	note = {arXiv: 1806.07572},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Probability},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/BSYPKKU7/1806.html:text/html;Jacot et al_2020_Neural Tangent Kernel.pdf:/Users/tito/Zotero/storage/9K86US2D/Jacot et al_2020_Neural Tangent Kernel.pdf:application/pdf},
}

@article{geiger_scaling_2020,
	title = {Scaling description of generalization with number of parameters in deep learning},
	volume = {2020},
	issn = {1742-5468},
	url = {https://doi.org/10.1088/1742-5468/ab633c},
	doi = {10.1088/1742-5468/ab633c},
	abstract = {Supervised deep learning involves the training of neural networks with a large number N of parameters. For large enough N, in the so-called over-parametrized regime, one can essentially fit the training data points. Sparsity-based arguments would suggest that the generalization error increases as N grows past a certain threshold N*. Instead, empirical studies have shown that in the over-parametrized regime, generalization error keeps decreasing with N. We resolve this paradox through a new framework. We rely on the so-called Neural Tangent Kernel, which connects large neural nets to kernel methods, to show that the initialization causes finite-size random fluctuations of the neural net output function f N around its expectation . These affect the generalization error for classification: under natural assumptions, it decays to a plateau value in a power-law fashion ∼N−1/2. This description breaks down at a so-called jamming transition N = N*. At this threshold, we argue that diverges. This result leads to a plausible explanation for the cusp in test error known to occur at N*. Our results are confirmed by extensive empirical observations on the MNIST and CIFAR image datasets. Our analysis finally suggests that, given a computational envelope, the smallest generalization error is obtained using several networks of intermediate sizes, just beyond N*, and averaging their outputs.},
	language = {en},
	number = {2},
	urldate = {2021-06-03},
	journal = {J. Stat. Mech.},
	author = {Geiger, Mario and Jacot, Arthur and Spigler, Stefano and Gabriel, Franck and Sagun, Levent and d'Ascoli, Stéphane and Biroli, Giulio and Hongler, Clément and Wyart, Matthieu},
	month = feb,
	year = {2020},
	note = {Publisher: IOP Publishing},
	pages = {023401},
	file = {Geiger et al_2020_Scaling description of generalization with number of parameters in deep learning.pdf:/Users/tito/Zotero/storage/DKQANW6F/Geiger et al_2020_Scaling description of generalization with number of parameters in deep learning.pdf:application/pdf},
}

@article{paccolat_geometric_2021,
	title = {Geometric compression of invariant manifolds in neural networks},
	volume = {2021},
	issn = {1742-5468},
	url = {https://doi.org/10.1088/1742-5468/abf1f3},
	doi = {10.1088/1742-5468/abf1f3},
	abstract = {We study how neural networks compress uninformative input space in models where data lie in d dimensions, but the labels of which only vary within a linear manifold of dimension d ∥ {\textless} d. We show that for a one-hidden-layer network initialized with infinitesimal weights (i.e. in the feature learning regime) trained with gradient descent, the first layer of weights evolves to become nearly insensitive to the d ⊥ = d − d ∥ uninformative directions. These are effectively compressed by a factor , where p is the size of the training set. We quantify the benefit of such a compression on the test error ϵ. For large initialization of the weights (the lazy training regime), no compression occurs and for regular boundaries separating labels we find that ϵ ∼ p −β , with β Lazy = d/(3d − 2). Compression improves the learning curves so that β Feature = (2d − 1)/(3d − 2) if d ∥ = 1 and β Feature = (d + d ⊥/2)/(3d − 2) if d ∥ {\textgreater} 1. We test these predictions for a stripe model where boundaries are parallel interfaces (d ∥ = 1) as well as for a cylindrical boundary (d ∥ = 2). Next, we show that compression shapes the neural tangent kernel (NTK) evolution in time, so that its top eigenvectors become more informative and display a larger projection on the labels. Consequently, kernel learning with the frozen NTK at the end of training outperforms the initial NTK. We confirm these predictions both for a one-hidden-layer fully connected network trained on the stripe model and for a 16-layer convolutional neural network trained on the Modified National Institute of Standards and Technology database (MNIST), for which we also find β Feature {\textgreater} β Lazy. The great similarities found in these two cases support the idea that compression is central to the training of MNIST, and puts forward kernel principal component analysis on the evolving NTK as a useful diagnostic of compression in deep networks.},
	language = {en},
	number = {4},
	urldate = {2021-06-03},
	journal = {J. Stat. Mech.},
	author = {Paccolat, Jonas and Petrini, Leonardo and Geiger, Mario and Tyloo, Kevin and Wyart, Matthieu},
	month = apr,
	year = {2021},
	note = {Publisher: IOP Publishing},
	pages = {044001},
	file = {Paccolat et al_2021_Geometric compression of invariant manifolds in neural networks.pdf:/Users/tito/Zotero/storage/VT9LCCY2/Paccolat et al_2021_Geometric compression of invariant manifolds in neural networks.pdf:application/pdf},
}

@article{logiaco_thalamic_2021,
	title = {Thalamic control of cortical dynamics in a model of flexible motor sequencing},
	volume = {35},
	issn = {2211-1247},
	url = {https://www.cell.com/cell-reports/abstract/S2211-1247(21)00424-1},
	doi = {10.1016/j.celrep.2021.109090},
	language = {English},
	number = {9},
	urldate = {2021-06-07},
	journal = {Cell Reports},
	author = {Logiaco, Laureline and Abbott, L. F. and Escola, Sean},
	month = jun,
	year = {2021},
	pmid = {34077721},
	note = {Publisher: Elsevier},
	keywords = {recurrent neural networks, control, motor cortex, hierarchical behaviors, low-rank connectivity perturbation, motor sequencing, switching linear dynamics, thalamocortical loops, thalamus},
	file = {Logiaco et al_2021_Thalamic control of cortical dynamics in a model of flexible motor sequencing.pdf:/Users/tito/Zotero/storage/FQJWU2L6/Logiaco et al_2021_Thalamic control of cortical dynamics in a model of flexible motor sequencing.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5ZWYPK6G/S2211-1247(21)00424-1.html:text/html},
}

@article{wang_segregation_2021,
	title = {Segregation, integration, and balance of large-scale resting brain networks configure different cognitive abilities},
	volume = {118},
	copyright = {Copyright © 2021 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/23/e2022288118},
	doi = {10.1073/pnas.2022288118},
	abstract = {Diverse cognitive processes set different demands on locally segregated and globally integrated brain activity. However, it remains an open question how resting brains configure their functional organization to balance the demands on network segregation and integration to best serve cognition. Here we use an eigenmode-based approach to identify hierarchical modules in functional brain networks and quantify the functional balance between network segregation and integration. In a large sample of healthy young adults (n = 991), we combine the whole-brain resting state functional magnetic resonance imaging (fMRI) data with a mean-filed model on the structural network derived from diffusion tensor imaging and demonstrate that resting brain networks are on average close to a balanced state. This state allows for a balanced time dwelling at segregated and integrated configurations and highly flexible switching between them. Furthermore, we employ structural equation modeling to estimate general and domain-specific cognitive phenotypes from nine tasks and demonstrate that network segregation, integration, and their balance in resting brains predict individual differences in diverse cognitive phenotypes. More specifically, stronger integration is associated with better general cognitive ability, stronger segregation fosters crystallized intelligence and processing speed, and an individual’s tendency toward balance supports better memory. Our findings provide a comprehensive and deep understanding of the brain’s functioning principles in supporting diverse functional demands and cognitive abilities and advance modern network neuroscience theories of human cognition.},
	language = {en},
	number = {23},
	urldate = {2021-06-08},
	journal = {PNAS},
	author = {Wang, Rong and Liu, Mianxin and Cheng, Xinhong and Wu, Ying and Hildebrandt, Andrea and Zhou, Changsong},
	month = jun,
	year = {2021},
	pmid = {34074762},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {functional brain network, hierarchical modules, human cognition, segregation–integration balance, structural equation modeling},
	file = {Wang et al_2021_Segregation, integration, and balance of large-scale resting brain networks.pdf:/Users/tito/Zotero/storage/DQJD2CGW/Wang et al_2021_Segregation, integration, and balance of large-scale resting brain networks.pdf:application/pdf},
}

@article{mensch_extracting_2021,
	title = {Extracting representations of cognition across neuroimaging studies improves brain decoding},
	volume = {17},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008795},
	doi = {10.1371/journal.pcbi.1008795},
	abstract = {Cognitive brain imaging is accumulating datasets about the neural substrate of many different mental processes. Yet, most studies are based on few subjects and have low statistical power. Analyzing data across studies could bring more statistical power; yet the current brain-imaging analytic framework cannot be used at scale as it requires casting all cognitive tasks in a unified theoretical framework. We introduce a new methodology to analyze brain responses across tasks without a joint model of the psychological processes. The method boosts statistical power in small studies with specific cognitive focus by analyzing them jointly with large studies that probe less focal mental processes. Our approach improves decoding performance for 80\% of 35 widely-different functional-imaging studies. It finds commonalities across tasks in a data-driven way, via common brain representations that predict mental processes. These are brain networks tuned to psychological manipulations. They outline interpretable and plausible brain structures. The extracted networks have been made available; they can be readily reused in new neuro-imaging studies. We provide a multi-study decoding tool to adapt to new data.},
	language = {en},
	number = {5},
	urldate = {2021-06-08},
	journal = {PLOS Computational Biology},
	author = {Mensch, Arthur and Mairal, Julien and Thirion, Bertrand and Varoquaux, Gaël},
	month = may,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Neuroimaging, Functional magnetic resonance imaging, Language, Cognition, Learning, Cognitive psychology, Face recognition, Hierarchical clustering},
	pages = {e1008795},
	file = {Mensch et al_2021_Extracting representations of cognition across neuroimaging studies improves.pdf:/Users/tito/Zotero/storage/RWKUI8LP/Mensch et al_2021_Extracting representations of cognition across neuroimaging studies improves.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MD78GWP2/article.html:text/html},
}

@article{hwang_human_2017,
	title = {The {Human} {Thalamus} {Is} an {Integrative} {Hub} for {Functional} {Brain} {Networks}},
	volume = {37},
	copyright = {Copyright © 2017 the authors 0270-6474/17/375594-14\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/37/23/5594},
	doi = {10.1523/JNEUROSCI.0067-17.2017},
	abstract = {The thalamus is globally connected with distributed cortical regions, yet the functional significance of this extensive thalamocortical connectivity remains largely unknown. By performing graph-theoretic analyses on thalamocortical functional connectivity data collected from human participants, we found that most thalamic subdivisions display network properties that are capable of integrating multimodal information across diverse cortical functional networks. From a meta-analysis of a large dataset of functional brain-imaging experiments, we further found that the thalamus is involved in multiple cognitive functions. Finally, we found that focal thalamic lesions in humans have widespread distal effects, disrupting the modular organization of cortical functional networks. This converging evidence suggests that the human thalamus is a critical hub region that could integrate diverse information being processed throughout the cerebral cortex as well as maintain the modular structure of cortical functional networks.
SIGNIFICANCE STATEMENT The thalamus is traditionally viewed as a passive relay station of information from sensory organs or subcortical structures to the cortex. However, the thalamus has extensive connections with the entire cerebral cortex, which can also serve to integrate information processing between cortical regions. In this study, we demonstrate that multiple thalamic subdivisions display network properties that are capable of integrating information across multiple functional brain networks. Moreover, the thalamus is engaged by tasks requiring multiple cognitive functions. These findings support the idea that the thalamus is involved in integrating information across cortical networks.},
	language = {en},
	number = {23},
	urldate = {2021-06-09},
	journal = {J. Neurosci.},
	author = {Hwang, Kai and Bertolero, Maxwell A. and Liu, William B. and D'Esposito, Mark},
	month = jun,
	year = {2017},
	pmid = {28450543},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {brain networks, functional connectivity, graph theory, thalamus, diaschisis},
	pages = {5594--5607},
	file = {Hwang et al_2017_The Human Thalamus Is an Integrative Hub for Functional Brain Networks.pdf:/Users/tito/Zotero/storage/P69PYUHT/Hwang et al_2017_The Human Thalamus Is an Integrative Hub for Functional Brain Networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SI2KFEE3/5594.html:text/html},
}

@article{hwang_neuropsychological_2021,
	title = {Neuropsychological evidence of multi-domain network hubs in the human thalamus},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.10.443403v1},
	doi = {10.1101/2021.05.10.443403},
	abstract = {{\textless}p{\textgreater}Hubs in the human brain support behaviors that arise from brain network interactions. Previous studies have identified hub regions in the human thalamus that are connected with multiple functional networks. However, the behavioral significance of thalamic hubs has yet to be established. Our framework predicts that thalamic subregions with strong hub properties are broadly involved in functions across multiple cognitive domains. To test this prediction, we studied human patients with focal thalamic lesions in conjunction with network analyses of the human thalamocortical functional connectome. In support of our prediction, lesions to thalamic subregions with stronger hub properties were associated with widespread deficits in executive, language, and memory functions, whereas lesions to thalamic subregions with weaker hub properties were associated with more limited deficits. These results highlight how a large-scale network model can broaden our understanding of thalamic function for human cognition.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-09},
	journal = {bioRxiv},
	author = {Hwang, Kai and Shine, James M. and Bruss, Joel and Tranel, Daniel and Boes, Aaron D.},
	month = may,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.05.10.443403},
	file = {Hwang et al_2021_Neuropsychological evidence of multi-domain network hubs in the human thalamus.pdf:/Users/tito/Zotero/storage/FV8N6FEP/Hwang et al_2021_Neuropsychological evidence of multi-domain network hubs in the human thalamus.pdf:application/pdf},
}

@article{shine_low-dimensional_2019,
	title = {The {Low}-{Dimensional} {Neural} {Architecture} of {Cognitive} {Complexity} {Is} {Related} to {Activity} in {Medial} {Thalamic} {Nuclei}},
	volume = {104},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627319307755},
	doi = {10.1016/j.neuron.2019.09.002},
	abstract = {Cognitive activity emerges from large-scale neuronal dynamics that are constrained to a low-dimensional manifold. How this low-dimensional manifold scales with cognitive complexity, and which brain regions regulate this process, are not well understood. We addressed this issue by analyzing sub-second high-field fMRI data acquired during performance of a task that systematically varied the complexity of cognitive reasoning. We show that task performance reconfigures the low-dimensional manifold and that deviations from these patterns relate to performance errors. We further demonstrate that individual differences in thalamic activity relate to reconfigurations of the low-dimensional architecture during task engagement.},
	language = {en},
	number = {5},
	urldate = {2021-06-09},
	journal = {Neuron},
	author = {Shine, James M. and Hearne, Luke J. and Breakspear, Michael and Hwang, Kai and Müller, Eli J. and Sporns, Olaf and Poldrack, Russell A. and Mattingley, Jason B. and Cocchi, Luca},
	month = dec,
	year = {2019},
	keywords = {fMRI, thalamus, cognitive complexity, low-dimensionality, state-space},
	pages = {849--855.e3},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/UQPQU6C2/S0896627319307755.html:text/html;Shine et al_2019_The Low-Dimensional Neural Architecture of Cognitive Complexity Is Related to.pdf:/Users/tito/Zotero/storage/HR6SSGMK/Shine et al_2019_The Low-Dimensional Neural Architecture of Cognitive Complexity Is Related to.pdf:application/pdf},
}

@article{muller_core_2020,
	title = {Core and matrix thalamic sub-populations relate to spatio-temporal cortical connectivity gradients},
	volume = {222},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920307102},
	doi = {10.1016/j.neuroimage.2020.117224},
	abstract = {Recent neuroimaging experiments have defined low-dimensional gradients of functional connectivity in the cerebral cortex that subserve a spectrum of capacities that span from sensation to cognition. Despite well-known anatomical connections to the cortex, the subcortical areas that support cortical functional organization have been relatively overlooked. One such structure is the thalamus, which maintains extensive anatomical and functional connections with the cerebral cortex across the cortical mantle. The thalamus has a heterogeneous cytoarchitecture, with at least two distinct cell classes that send differential projections to the cortex: granular-projecting ‘Core’ cells and supragranular-projecting ‘Matrix’ cells. Here we use high-resolution 7T resting-state fMRI data and the relative amount of two calcium-binding proteins, parvalbumin and calbindin, to infer the relative distribution of these two cell-types (Core and Matrix, respectively) in the thalamus. First, we demonstrate that thalamocortical connectivity recapitulates large-scale, low-dimensional connectivity gradients within the cerebral cortex. Next, we show that diffusely-projecting Matrix regions preferentially correlate with cortical regions with longer intrinsic fMRI timescales. We then show that the Core–Matrix architecture of the thalamus is important for understanding network topology in a manner that supports dynamic integration of signals distributed across the brain. Finally, we replicate our main results in a distinct 3T resting-state fMRI dataset. Linking molecular and functional neuroimaging data, our findings highlight the importance of the thalamic organization for understanding low-dimensional gradients of cortical connectivity.},
	language = {en},
	urldate = {2021-06-09},
	journal = {NeuroImage},
	author = {Müller, Eli J. and Munn, Brandon and Hearne, Luke J. and Smith, Jared B. and Fulcher, Ben and Arnatkevičiūtė, Aurina and Lurie, Daniel J. and Cocchi, Luca and Shine, James M.},
	month = nov,
	year = {2020},
	pages = {117224},
	file = {Müller et al_2020_Core and matrix thalamic sub-populations relate to spatio-temporal cortical.pdf:/Users/tito/Zotero/storage/CDWFBW8T/Müller et al_2020_Core and matrix thalamic sub-populations relate to spatio-temporal cortical.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/XH7WTSHT/S1053811920307102.html:text/html},
}

@article{marton_efficient_2021,
	title = {Efficient and robust multi-task learning in the brain with modular task primitives},
	url = {http://arxiv.org/abs/2105.14108},
	abstract = {In a real-world setting biological agents do not have infinite resources to learn new things. It is thus useful to recycle previously acquired knowledge in a way that allows for faster, less resource-intensive acquisition of multiple new skills. Neural networks in the brain are likely not entirely re-trained with new tasks, but how they leverage existing computations to learn new tasks is not well understood. In this work, we study this question in artificial neural networks trained on commonly used neuroscience paradigms. Building on recent work from the multi-task learning literature, we propose two ingredients: (1) network modularity, and (2) learning task primitives. Together, these ingredients form inductive biases we call structural and functional, respectively. Using a corpus of nine different tasks, we show that a modular network endowed with task primitives allows for learning multiple tasks well while keeping parameter counts, and updates, low. We also show that the skills acquired with our approach are more robust to a broad range of perturbations compared to those acquired with other multi-task learning strategies. This work offers a new perspective on achieving efficient multi-task learning in the brain, and makes predictions for novel neuroscience experiments in which targeted perturbations are employed to explore solution spaces.},
	urldate = {2021-06-09},
	journal = {arXiv:2105.14108 [cs, q-bio]},
	author = {Marton, Christian David and Lajoie, Guillaume and Rajan, Kanaka},
	month = may,
	year = {2021},
	note = {arXiv: 2105.14108},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/CJWW5ZLW/2105.html:text/html;Marton et al_2021_Efficient and robust multi-task learning in the brain with modular task.pdf:/Users/tito/Zotero/storage/7XNM6UXZ/Marton et al_2021_Efficient and robust multi-task learning in the brain with modular task.pdf:application/pdf},
}

@article{nguyen_wide_2021,
	title = {Do {Wide} and {Deep} {Networks} {Learn} the {Same} {Things}? {Uncovering} {How} {Neural} {Network} {Representations} {Vary} with {Width} and {Depth}},
	shorttitle = {Do {Wide} and {Deep} {Networks} {Learn} the {Same} {Things}?},
	url = {http://arxiv.org/abs/2010.15327},
	abstract = {A key factor in the success of deep neural networks is the ability to scale models to improve performance by varying the architecture depth and width. This simple property of neural network design has resulted in highly effective architectures for a variety of tasks. Nevertheless, there is limited understanding of effects of depth and width on the learned representations. In this paper, we study this fundamental question. We begin by investigating how varying depth and width affects model hidden representations, finding a characteristic block structure in the hidden representations of larger capacity (wider or deeper) models. We demonstrate that this block structure arises when model capacity is large relative to the size of the training set, and is indicative of the underlying layers preserving and propagating the dominant principal component of their representations. This discovery has important ramifications for features learned by different models, namely, representations outside the block structure are often similar across architectures with varying widths and depths, but the block structure is unique to each model. We analyze the output predictions of different model architectures, finding that even when the overall accuracy is similar, wide and deep models exhibit distinctive error patterns and variations across classes.},
	urldate = {2021-06-09},
	journal = {arXiv:2010.15327 [cs]},
	author = {Nguyen, Thao and Raghu, Maithra and Kornblith, Simon},
	month = apr,
	year = {2021},
	note = {arXiv: 2010.15327},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: ICLR 2021},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/RLTBI47M/2010.html:text/html;Nguyen et al_2021_Do Wide and Deep Networks Learn the Same Things.pdf:/Users/tito/Zotero/storage/H8GYJT2B/Nguyen et al_2021_Do Wide and Deep Networks Learn the Same Things.pdf:application/pdf},
}

@article{clark_credit_2021,
	title = {Credit {Assignment} {Through} {Broadcasting} a {Global} {Error} {Vector}},
	url = {http://arxiv.org/abs/2106.04089},
	abstract = {Backpropagation (BP) uses detailed, unit-specific feedback to train deep neural networks (DNNs) with remarkable success. That biological neural circuits appear to perform credit assignment, but cannot implement BP, implies the existence of other powerful learning algorithms. Here, we explore the extent to which a globally broadcast learning signal, coupled with local weight updates, enables training of DNNs. We present both a learning rule, called global error-vector broadcasting (GEVB), and a class of DNNs, called vectorized nonnegative networks (VNNs), in which this learning rule operates. VNNs have vector-valued units and nonnegative weights past the first layer. The GEVB learning rule generalizes three-factor Hebbian learning, updating each weight by an amount proportional to the inner product of the presynaptic activation and a globally broadcast error vector when the postsynaptic unit is active. We prove that these weight updates are matched in sign to the gradient, enabling accurate credit assignment. Moreover, at initialization, these updates are exactly proportional to the gradient in the limit of infinite network width. GEVB matches the performance of BP in VNNs, and in some cases outperforms direct feedback alignment (DFA) applied in conventional networks. Unlike DFA, GEVB successfully trains convolutional layers. Altogether, our theoretical and empirical results point to a surprisingly powerful role for a global learning signal in training DNNs.},
	urldate = {2021-06-10},
	journal = {arXiv:2106.04089 [cs, q-bio]},
	author = {Clark, David G. and Abbott, L. F. and Chung, SueYeon},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.04089},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 18 pages, 6 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/PPHIIT7U/2106.html:text/html;Clark et al_2021_Credit Assignment Through Broadcasting a Global Error Vector.pdf:/Users/tito/Zotero/storage/LFUBTSKA/Clark et al_2021_Credit Assignment Through Broadcasting a Global Error Vector.pdf:application/pdf},
}

@article{caucheteux_decomposing_2021,
	title = {Decomposing lexical and compositional syntax and semantics with deep language models},
	url = {http://arxiv.org/abs/2103.01620},
	abstract = {The activations of language transformers like GPT2 have been shown to linearly map onto brain activity during speech comprehension. However, the nature of these activations remains largely unknown and presumably conflate distinct linguistic classes. Here, we propose a taxonomy to factorize the high-dimensional activations of language models into four combinatorial classes: lexical, compositional, syntactic, and semantic representations. We then introduce a statistical method to decompose, through the lens of GPT2's activations, the brain activity of 345 subjects recorded with functional magnetic resonance imaging (fMRI) during the listening of {\textasciitilde}4.6 hours of narrated text. The results highlight two findings. First, compositional representations recruit a more widespread cortical network than lexical ones, and encompass the bilateral temporal, parietal and prefrontal cortices. Second, contrary to previous claims, syntax and semantics are not associated with separated modules, but, instead, appear to share a common and distributed neural substrate. Overall, this study introduces a general framework to isolate the distributed representations of linguistic constructs generated in naturalistic settings.},
	urldate = {2021-06-10},
	journal = {arXiv:2103.01620 [cs, q-bio]},
	author = {Caucheteux, Charlotte and Gramfort, Alexandre and King, Jean-Remi},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.01620},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/B3NKFEJ6/2103.html:text/html;Caucheteux et al_2021_Decomposing lexical and compositional syntax and semantics with deep language.pdf:/Users/tito/Zotero/storage/ZPPICSKZ/Caucheteux et al_2021_Decomposing lexical and compositional syntax and semantics with deep language.pdf:application/pdf},
}

@article{caucheteux_gpt-2s_2021,
	title = {{GPT}-2’s activations predict the degree of semantic comprehension in the human brain},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.20.440622v1},
	doi = {10.1101/2021.04.20.440622},
	abstract = {{\textless}p{\textgreater}Language transformers, like GPT-2, have demonstrated remarkable abilities to process text, and now constitute the backbone of deep translation, summarization and dialogue algorithms. However, whether these models actually understand language is highly controversial. Here, we show that the representations of GPT-2 not only map onto the brain responses to spoken stories, but also predict the extent to which subjects understand the narratives. To this end, we analyze 101 subjects recorded with functional Magnetic Resonance Imaging while listening to 70 min of short stories. We then fit a linear model to predict brain activity from GPT-2 activations, and correlate this mapping with subjects’ comprehension scores as assessed for each story. The results show that GPT-2’s brain predictions significantly correlate with semantic comprehension. These effects are bilaterally distributed in the language network and peak with a correlation above 30\% in the infero-frontal and medio-temporal gyri as well as in the superior frontal cortex, the planum temporale and the precuneus. Overall, this study provides an empirical framework to probe and dissect semantic comprehension in brains and deep learning algorithms.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-10},
	journal = {bioRxiv},
	author = {Caucheteux, Charlotte and Gramfort, Alexandre and King, Jean-Rémi},
	month = apr,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.04.20.440622},
	file = {Caucheteux et al_2021_GPT-2’s activations predict the degree of semantic comprehension in the human.pdf:/Users/tito/Zotero/storage/YQKXFGTU/Caucheteux et al_2021_GPT-2’s activations predict the degree of semantic comprehension in the human.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GH6NQCFH/2021.04.20.440622v1.html:text/html},
}

@article{papadimitriou_brain_2020,
	title = {Brain computation by assemblies of neurons},
	volume = {117},
	copyright = {Copyright © 2020 the Author(s). Published by PNAS.. This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/117/25/14464},
	doi = {10.1073/pnas.2001893117},
	abstract = {Assemblies are large populations of neurons believed to imprint memories, concepts, words, and other cognitive information. We identify a repertoire of operations on assemblies. These operations correspond to properties of assemblies observed in experiments, and can be shown, analytically and through simulations, to be realizable by generic, randomly connected populations of neurons with Hebbian plasticity and inhibition. Assemblies and their operations constitute a computational model of the brain which we call the Assembly Calculus, occupying a level of detail intermediate between the level of spiking neurons and synapses and that of the whole brain. The resulting computational system can be shown, under assumptions, to be, in principle, capable of carrying out arbitrary computations. We hypothesize that something like it may underlie higher human cognitive functions such as reasoning, planning, and language. In particular, we propose a plausible brain architecture based on assemblies for implementing the syntactic processing of language in cortex, which is consistent with recent experimental results.},
	language = {en},
	number = {25},
	urldate = {2021-06-10},
	journal = {PNAS},
	author = {Papadimitriou, Christos H. and Vempala, Santosh S. and Mitropolsky, Daniel and Collins, Michael and Maass, Wolfgang},
	month = jun,
	year = {2020},
	pmid = {32518114},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {Assembly Calculus, computation, language in the brain, neuronal assemblies, random graph},
	pages = {14464--14472},
	file = {Papadimitriou et al_2020_Brain computation by assemblies of neurons.pdf:/Users/tito/Zotero/storage/IU9ZA8VY/Papadimitriou et al_2020_Brain computation by assemblies of neurons.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/T39QD7E3/14464.html:text/html},
}

@article{monaco_brain_2021,
	title = {A brain basis of dynamical intelligence for {AI} and computational neuroscience},
	url = {http://arxiv.org/abs/2105.07284},
	abstract = {The deep neural nets of modern artificial intelligence (AI) have not achieved defining features of biological intelligence, including abstraction, causal learning, and energy-efficiency. While scaling to larger models has delivered performance improvements for current applications, more brain-like capacities may demand new theories, models, and methods for designing artificial learning systems. Here, we argue that this opportunity to reassess insights from the brain should stimulate cooperation between AI research and theory-driven computational neuroscience (CN). To motivate a brain basis of neural computation, we present a dynamical view of intelligence from which we elaborate concepts of sparsity in network structure, temporal dynamics, and interactive learning. In particular, we suggest that temporal dynamics, as expressed through neural synchrony, nested oscillations, and flexible sequences, provide a rich computational layer for reading and updating hierarchical models distributed in long-term memory networks. Moreover, embracing agent-centered paradigms in AI and CN will accelerate our understanding of the complex dynamics and behaviors that build useful world models. A convergence of AI/CN theories and objectives will reveal dynamical principles of intelligence for brains and engineered learning systems. This article was inspired by our symposium on dynamical neuroscience and machine learning at the 6th Annual US/NIH BRAIN Initiative Investigators Meeting.},
	urldate = {2021-06-10},
	journal = {arXiv:2105.07284 [cs, q-bio]},
	author = {Monaco, Joseph D. and Rajan, Kanaka and Hwang, Grace M.},
	month = may,
	year = {2021},
	note = {arXiv: 2105.07284},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence},
	annote = {Comment: Perspective article: 24 pages, 3 figures, 1 display box},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/5KRVJ87V/2105.html:text/html;Monaco et al_2021_A brain basis of dynamical intelligence for AI and computational neuroscience.pdf:/Users/tito/Zotero/storage/NEZX85NA/Monaco et al_2021_A brain basis of dynamical intelligence for AI and computational neuroscience.pdf:application/pdf},
}

@article{perich_rethinking_2020,
	series = {Whole-brain interactions between neural circuits},
	title = {Rethinking brain-wide interactions through multi-region ‘network of networks’ models},
	volume = {65},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438820301707},
	doi = {10.1016/j.conb.2020.11.003},
	abstract = {The neural control of behavior is distributed across many functionally and anatomically distinct brain regions even in small nervous systems. While classical neuroscience models treated these regions as a set of hierarchically isolated nodes, the brain comprises a recurrently interconnected network in which each region is intimately modulated by many others. Uncovering these interactions is now possible through experimental techniques that access large neural populations from many brain regions simultaneously. Harnessing these large-scale datasets, however, requires new theoretical approaches. Here, we review recent work to understand brain-wide interactions using multi-region ‘network of networks’ models and discuss how they can guide future experiments. We also emphasize the importance of multi-region recordings, and posit that studying individual components in isolation will be insufficient to understand the neural basis of behavior.},
	language = {en},
	urldate = {2021-06-10},
	journal = {Current Opinion in Neurobiology},
	author = {Perich, Matthew G and Rajan, Kanaka},
	month = dec,
	year = {2020},
	pages = {146--151},
	file = {Perich_Rajan_2020_Rethinking brain-wide interactions through multi-region ‘network of networks’.pdf:/Users/tito/Zotero/storage/I94HHSP2/Perich_Rajan_2020_Rethinking brain-wide interactions through multi-region ‘network of networks’.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/PKPFCZDA/S0959438820301707.html:text/html},
}

@article{hermans_recurrent_2012,
	title = {Recurrent {Kernel} {Machines}: {Computing} with {Infinite} {Echo} {State} {Networks}},
	volume = {24},
	issn = {0899-7667},
	shorttitle = {Recurrent {Kernel} {Machines}},
	url = {https://doi.org/10.1162/NECO_a_00200},
	doi = {10.1162/NECO_a_00200},
	abstract = {Echo state networks (ESNs) are large, random recurrent neural networks with a single trained linear readout layer. Despite the untrained nature of the recurrent weights, they are capable of performing universal computations on temporal input data, which makes them interesting for both theoretical research and practical applications. The key to their success lies in the fact that the network computes a broad set of nonlinear, spatiotemporal mappings of the input data, on which linear regression or classification can easily be performed. One could consider the reservoir as a spatiotemporal kernel, in which the mapping to a high-dimensional space is computed explicitly. In this letter, we build on this idea and extend the concept of ESNs to infinite-sized recurrent neural networks, which can be considered recursive kernels that subsequently can be used to create recursive support vector machines. We present the theoretical framework, provide several practical examples of recursive kernels, and apply them to typical temporal tasks.},
	number = {1},
	urldate = {2021-06-10},
	journal = {Neural Computation},
	author = {Hermans, Michiel and Schrauwen, Benjamin},
	month = jan,
	year = {2012},
	pages = {104--133},
	file = {Hermans_Schrauwen_2012_Recurrent Kernel Machines.pdf:/Users/tito/Zotero/storage/V8AAMXRB/Hermans_Schrauwen_2012_Recurrent Kernel Machines.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AVICLVMT/Recurrent-Kernel-Machines-Computing-with-Infinite.html:text/html},
}

@article{wu_nonlinear_2021,
	title = {Nonlinear transient amplification in recurrent neural networks with short-term plasticity},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.06.09.447718v1},
	doi = {10.1101/2021.06.09.447718},
	abstract = {{\textless}p{\textgreater}To rapidly process information, neural circuits have to amplify specific activity patterns transiently. How the brain performs this nonlinear operation remains elusive. Hebbian assemblies are one possibility whereby symmetric excitatory connections boost neuronal activity. However, such Hebbian amplification is often associated with dynamical slowing of network dynamics, non-transient attractor states, and pathological run-away activity. Feedback inhibition can alleviate these effects but typically linearizes responses and reduces amplification gain. At the same time, other alternative mechanisms rely on asymmetric connectivity, in conflict with the Hebbian doctrine. Here we propose nonlinear transient amplification (NTA), a plausible circuit mechanism that reconciles symmetric connectivity with rapid amplification while avoiding the above issues. NTA has two distinct temporal phases. Initially, positive feedback excitation selectively amplifies inputs that exceed a critical threshold. Subsequently, short-term plasticity quenches the run-away dynamics into an inhibition-stabilized network state. By characterizing NTA in supralinear network models, we establish that the resulting onset transients are stimulus selective and well-suited for speedy information processing. Further, we find that excitatory-inhibitory co-tuning widens the parameter regime in which NTA is possible. In summary, NTA provides a parsimonious explanation for how excitatory-inhibitory co-tuning and short-term plasticity collaborate in recurrent networks to achieve transient amplification.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-11},
	journal = {bioRxiv},
	author = {Wu, Yue Kris and Zenke, Friedemann},
	month = jun,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.06.09.447718},
	file = {Snapshot:/Users/tito/Zotero/storage/WFMAIG9M/2021.06.09.html:text/html;Wu_Zenke_2021_Nonlinear transient amplification in recurrent neural networks with short-term.pdf:/Users/tito/Zotero/storage/MSNHM2NA/Wu_Zenke_2021_Nonlinear transient amplification in recurrent neural networks with short-term.pdf:application/pdf},
}

@article{finn_beyond_2021,
	title = {Beyond fingerprinting: {Choosing} predictive connectomes over reliable connectomes},
	issn = {1053-8119},
	shorttitle = {Beyond fingerprinting},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921005310},
	doi = {10.1016/j.neuroimage.2021.118254},
	abstract = {Recent years have seen a surge of research on variability in functional brain connectivity within and between individuals, with encouraging progress toward understanding the consequences of this variability for cognition and behavior. At the same time, well-founded concerns over rigor and reproducibility in psychology and neuroscience have led many to question whether functional connectivity is sufficiently reliable, and call for methods to improve its reliability. The thesis of this opinion piece is that when studying variability in functional connectivity—both across individuals and within individuals over time—we should use behavior prediction as our benchmark rather than optimize reliability for its own sake. We discuss theoretical and empirical evidence to compel this perspective, both when the goal is to study stable, trait-level differences between people, as well as when the goal is to study state-related changes within individuals. We hope that this piece will be useful to the neuroimaging community as we continue efforts to characterize inter- and intra-subject variability in brain function and build predictive models with an eye toward eventual real-world applications.},
	language = {en},
	urldate = {2021-06-11},
	journal = {NeuroImage},
	author = {Finn, Emily S. and Rosenberg, Monica D.},
	month = jun,
	year = {2021},
	pages = {118254},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/IPLSAJCD/S1053811921005310.html:text/html},
}

@article{kabra_simone_2021,
	title = {{SIMONe}: {View}-{Invariant}, {Temporally}-{Abstracted} {Object} {Representations} via {Unsupervised} {Video} {Decomposition}},
	shorttitle = {{SIMONe}},
	url = {http://arxiv.org/abs/2106.03849},
	abstract = {To help agents reason about scenes in terms of their building blocks, we wish to extract the compositional structure of any given scene (in particular, the conﬁguration and characteristics of objects comprising the scene). This problem is especially difﬁcult when scene structure needs to be inferred while also estimating the agent’s location/viewpoint, as the two variables jointly give rise to the agent’s observations. We present an unsupervised variational approach to this problem. Leveraging the shared structure that exists across different scenes, our model learns to infer two sets of latent representations from RGB video input: a set of "object" latents, corresponding to the time-invariant, object-level contents of the scene, as well as a set of "frame" latents, corresponding to global time-varying elements such as viewpoint. This factorization of latents allows our model, SIMONe, to represent object attributes in an allocentric manner which does not depend on viewpoint. Moreover, it allows us to disentangle object dynamics and summarize their trajectories as time-abstracted, view-invariant, per-object properties. We demonstrate these capabilities, as well as the model’s performance in terms of view synthesis and instance segmentation, across three procedurally generated video datasets.},
	language = {en},
	urldate = {2021-06-14},
	journal = {arXiv:2106.03849 [cs]},
	author = {Kabra, Rishabh and Zoran, Daniel and Erdogan, Goker and Matthey, Loic and Creswell, Antonia and Botvinick, Matthew and Lerchner, Alexander and Burgess, Christopher P.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.03849},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: Animated figures are available at https://sites.google.com/view/simone-scene-understanding/},
	file = {Kabra et al. - 2021 - SIMONe View-Invariant, Temporally-Abstracted Obje.pdf:/Users/tito/Zotero/storage/D5JZYMQR/Kabra et al. - 2021 - SIMONe View-Invariant, Temporally-Abstracted Obje.pdf:application/pdf},
}

@article{berner_modern_2021,
	title = {The {Modern} {Mathematics} of {Deep} {Learning}},
	url = {http://arxiv.org/abs/2105.04026},
	abstract = {We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding what features are learned, why deep architectures perform exceptionally well in physical problems, and which fine aspects of an architecture affect the behavior of a learning task in which way. We present an overview of modern approaches that yield partial answers to these questions. For selected approaches, we describe the main ideas in more detail.},
	urldate = {2021-06-14},
	journal = {arXiv:2105.04026 [cs, stat]},
	author = {Berner, Julius and Grohs, Philipp and Kutyniok, Gitta and Petersen, Philipp},
	month = may,
	year = {2021},
	note = {arXiv: 2105.04026},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: This review paper will appear as a book chapter in the book "Theory of Deep Learning" by Cambridge University Press},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/VRJR2I4F/2105.html:text/html;Berner et al_2021_The Modern Mathematics of Deep Learning.pdf:/Users/tito/Zotero/storage/9NDKGGTC/Berner et al_2021_The Modern Mathematics of Deep Learning.pdf:application/pdf},
}

@article{wainio-theberge_dynamic_2021,
	title = {Dynamic relationships between spontaneous and evoked electrophysiological activity},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2399-3642},
	url = {https://www.nature.com/articles/s42003-021-02240-9},
	doi = {10.1038/s42003-021-02240-9},
	abstract = {Spontaneous neural activity fluctuations have been shown to influence trial-by-trial variation in perceptual, cognitive, and behavioral outcomes. However, the complex electrophysiological mechanisms by which these fluctuations shape stimulus-evoked neural activity remain largely to be explored. Employing a large-scale magnetoencephalographic dataset and an electroencephalographic replication dataset, we investigate the relationship between spontaneous and evoked neural activity across a range of electrophysiological variables. We observe that for high-frequency activity, high pre-stimulus amplitudes lead to greater evoked desynchronization, while for low frequencies, high pre-stimulus amplitudes induce larger degrees of event-related synchronization. We further decompose electrophysiological power into oscillatory and scale-free components, demonstrating different patterns of spontaneous-evoked correlation for each component. Finally, we find correlations between spontaneous and evoked time-domain electrophysiological signals. Overall, we demonstrate that the dynamics of multiple electrophysiological variables exhibit distinct relationships between their spontaneous and evoked activity, a result which carries implications for experimental design and analysis in non-invasive electrophysiology.},
	language = {en},
	number = {1},
	urldate = {2021-06-15},
	journal = {Commun Biol},
	author = {Wainio-Theberge, Soren and Wolff, Annemarie and Northoff, Georg},
	month = jun,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--17},
	file = {Snapshot:/Users/tito/Zotero/storage/EVKMEVWJ/s42003-021-02240-9.html:text/html;Wainio-Theberge et al_2021_Dynamic relationships between spontaneous and evoked electrophysiological.pdf:/Users/tito/Zotero/storage/8EY2VNM9/Wainio-Theberge et al_2021_Dynamic relationships between spontaneous and evoked electrophysiological.pdf:application/pdf},
}

@article{ebitz_population_2021,
	title = {The population doctrine revolution in cognitive neurophysiology},
	url = {http://arxiv.org/abs/2104.00145},
	abstract = {A major shift is happening within neurophysiology: a population doctrine is drawing level with the single-neuron doctrine that has long dominated the field. Population-level ideas have so far had their greatest impact in motor neurophysiology, but they hold incredible promise for resolving open questions in cognition. Here, we codify the population doctrine and survey recent work that leverages this view to probe cognition. Our discussion is organized around five core concepts that provide a foundation for population-level thinking: (1) state spaces, (2) manifolds, (3) coding dimensions, (4) subspaces, and (5) dynamics. The work we review illustrates the progress and promise that population neurophysiology holds for cognitive neuroscience\$-\$for delivering new insight into attention, working memory, decision-making, executive function, and learning.},
	urldate = {2021-06-15},
	journal = {arXiv:2104.00145 [q-bio]},
	author = {Ebitz, R. Becket and Hayden, Benjamin Y.},
	month = mar,
	year = {2021},
	note = {arXiv: 2104.00145},
	keywords = {Quantitative Biology - Neurons and Cognition},
	annote = {Comment: 29 pages, 3 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/JMQJ4SVF/2104.html:text/html;Ebitz_Hayden_2021_The population doctrine revolution in cognitive neurophysiology.pdf:/Users/tito/Zotero/storage/U9ES3BR9/Ebitz_Hayden_2021_The population doctrine revolution in cognitive neurophysiology.pdf:application/pdf},
}

@article{bietti_inductive_2019,
	title = {On the {Inductive} {Bias} of {Neural} {Tangent} {Kernels}},
	url = {http://arxiv.org/abs/1905.12173},
	abstract = {State-of-the-art neural networks are heavily over-parameterized, making the optimization algorithm a crucial ingredient for learning predictive models with good generalization properties. A recent line of work has shown that in a certain over-parameterized regime, the learning dynamics of gradient descent are governed by a certain kernel obtained at initialization, called the neural tangent kernel. We study the inductive bias of learning in such a regime by analyzing this kernel and the corresponding function space (RKHS). In particular, we study smoothness, approximation, and stability properties of functions with finite norm, including stability to image deformations in the case of convolutional networks, and compare to other known kernels for similar architectures.},
	urldate = {2021-06-15},
	journal = {arXiv:1905.12173 [cs, stat]},
	author = {Bietti, Alberto and Mairal, Julien},
	month = oct,
	year = {2019},
	note = {arXiv: 1905.12173},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: NeurIPS 2019},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/B6QB7NVC/1905.html:text/html;Bietti_Mairal_2019_On the Inductive Bias of Neural Tangent Kernels.pdf:/Users/tito/Zotero/storage/N5SKR7EV/Bietti_Mairal_2019_On the Inductive Bias of Neural Tangent Kernels.pdf:application/pdf},
}

@article{laumann_brain_2021,
	title = {Brain activity is not only for thinking},
	volume = {40},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154621000875},
	doi = {10.1016/j.cobeha.2021.04.002},
	abstract = {The human brain is a complex organ with multiple competing imperatives. It must perceive and interpret the world, incorporate new information, and maintain its functional integrity over the lifespan. Neural activity is associated with all of these processes. Spontaneous BOLD signals have been invoked as representing neural activity associated with all of these processes. However, their exact role in these processes remains controversial. Here, we review learning machine theory, molecular mechanisms of synaptic plasticity and homeostasis, and recent experimental evidence to suggest that spontaneous BOLD activity may be more closely aligned with off-line plasticity and homeostatic processes than on-line fluctuations in cognitive content.},
	language = {en},
	urldate = {2021-06-16},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Laumann, Timothy O and Snyder, Abraham Z},
	month = aug,
	year = {2021},
	pages = {130--136},
	file = {Laumann_Snyder_2021_Brain activity is not only for thinking.pdf:/Users/tito/Zotero/storage/M4JRNLIS/Laumann_Snyder_2021_Brain activity is not only for thinking.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/HELTKJNS/S2352154621000875.html:text/html},
}

@article{badre_dimensionality_2021,
	series = {Computational cognitive neuroscience},
	title = {The dimensionality of neural representations for control},
	volume = {38},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154620301042},
	doi = {10.1016/j.cobeha.2020.07.002},
	abstract = {Cognitive control allows us to think and behave flexibly based on our context and goals. At the heart of theories of cognitive control is a control representation that enables the same input to produce different outputs contingent on contextual factors. In this review, we focus on an important property of the control representation’s neural code: its representational dimensionality. Dimensionality of a neural representation balances a basic separability/generalizability trade-off in neural computation. We will discuss the implications of this trade-off for cognitive control. We will then briefly review current neuroscience findings regarding the dimensionality of control representations in the brain, particularly the prefrontal cortex. We conclude by highlighting open questions and crucial directions for future research.},
	language = {en},
	urldate = {2021-06-17},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Badre, David and Bhandari, Apoorva and Keglovits, Haley and Kikumoto, Atsushi},
	month = apr,
	year = {2021},
	pages = {20--28},
	file = {Badre et al_2021_The dimensionality of neural representations for control.pdf:/Users/tito/Zotero/storage/FNIDZMHU/Badre et al_2021_The dimensionality of neural representations for control.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/DPW784SA/S2352154620301042.html:text/html},
}

@article{mill_structural_2021,
	title = {Structural {MRI} and functional connectivity features predict current clinical status and persistence behavior in prescription opioid users},
	volume = {30},
	issn = {2213-1582},
	url = {https://www.sciencedirect.com/science/article/pii/S2213158221001078},
	doi = {10.1016/j.nicl.2021.102663},
	abstract = {Prescription opioid use disorder (POUD) has reached epidemic proportions in the United States, raising an urgent need for diagnostic biological tools that can improve predictions of disease characteristics. The use of neuroimaging methods to develop such biomarkers have yielded promising results when applied to neurodegenerative and psychiatric disorders, yet have not been extended to prescription opioid addiction. With this long-term goal in mind, we conducted a preliminary study in this understudied clinical group. Univariate and multivariate approaches to distinguishing between POUD (n = 26) and healthy controls (n = 21) were investigated, on the basis of structural MRI (sMRI) and resting-state functional connectivity (restFC) features. Univariate approaches revealed reduced structural integrity in the subcortical extent of a previously reported addiction-related network in POUD subjects. No reliable univariate between-group differences in cortical structure or edgewise restFC were observed. Contrasting these mixed univariate results, multivariate machine learning classification approaches recovered more statistically reliable group differences, especially when sMRI and restFC features were combined in a multi-modal model (classification accuracy = 66.7\%, p {\textless} .001). The same multivariate multi-modal approach also yielded reliable prediction of individual differences in a clinically relevant behavioral measure (persistence behavior; predicted-to-actual overlap r = 0.42, p = .009). Our findings suggest that sMRI and restFC measures can be used to reliably distinguish the neural effects of long-term opioid use, and that this endeavor numerically benefits from multivariate predictive approaches and multi-modal feature sets. This can serve as theoretical proof-of-concept for future longitudinal modeling of prognostic POUD characteristics from neuroimaging features, which would have clearer clinical utility.},
	language = {en},
	urldate = {2021-06-17},
	journal = {NeuroImage: Clinical},
	author = {Mill, Ravi D. and Winfield, Emily C. and Cole, Michael W. and Ray, Suchismita},
	month = jan,
	year = {2021},
	keywords = {Functional connectivity, Resting state, Machine learning, Addiction, Opioid, Structural MRI},
	pages = {102663},
	file = {Mill et al_2021_Structural MRI and functional connectivity features predict current clinical.pdf:/Users/tito/Zotero/storage/UCWBJRES/Mill et al_2021_Structural MRI and functional connectivity features predict current clinical.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/TJ5C2Y9S/S2213158221001078.html:text/html},
}

@article{soltani_timescales_2021,
	title = {Timescales of cognition in the brain},
	volume = {41},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154621000516},
	doi = {10.1016/j.cobeha.2021.03.003},
	abstract = {We live in a world that changes on many timescales. To learn and make decisions appropriately, the human brain has evolved to integrate various types of information, such as sensory evidence and reward feedback, on multiple timescales. This is reflected in cortical hierarchies of timescales consisting of heterogeneous neuronal activities and expression of genes related to neurotransmitters critical for learning. We review the recent findings on how timescales of sensory and reward integration are affected by the temporal properties of sensory and reward signals in the environment. Despite existing evidence linking behavioral and neuronal timescales, future studies must examine how neural computations at multiple timescales are adjusted and combined to influence behavior flexibly.},
	language = {en},
	urldate = {2021-06-18},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Soltani, Alireza and Murray, John D and Seo, Hyojung and Lee, Daeyeol},
	month = oct,
	year = {2021},
	pages = {30--37},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/2QX846HP/S2352154621000516.html:text/html;Soltani et al_2021_Timescales of cognition in the brain.pdf:/Users/tito/Zotero/storage/88EJDJEC/Soltani et al_2021_Timescales of cognition in the brain.pdf:application/pdf},
}

@article{shen_deep_2019-1,
	title = {Deep image reconstruction from human brain activity},
	volume = {15},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006633},
	doi = {10.1371/journal.pcbi.1006633},
	abstract = {The mental contents of perception and imagery are thought to be encoded in hierarchical representations in the brain, but previous attempts to visualize perceptual contents have failed to capitalize on multiple levels of the hierarchy, leaving it challenging to reconstruct internal imagery. Recent work showed that visual cortical activity measured by functional magnetic resonance imaging (fMRI) can be decoded (translated) into the hierarchical features of a pre-trained deep neural network (DNN) for the same input image, providing a way to make use of the information from hierarchical visual features. Here, we present a novel image reconstruction method, in which the pixel values of an image are optimized to make its DNN features similar to those decoded from human brain activity at multiple layers. We found that our method was able to reliably produce reconstructions that resembled the viewed natural images. A natural image prior introduced by a deep generator neural network effectively rendered semantically meaningful details to the reconstructions. Human judgment of the reconstructions supported the effectiveness of combining multiple DNN layers to enhance the visual quality of generated images. While our model was solely trained with natural images, it successfully generalized to artificial shapes, indicating that our model was not simply matching to exemplars. The same analysis applied to mental imagery demonstrated rudimentary reconstructions of the subjective content. Our results suggest that our method can effectively combine hierarchical neural representations to reconstruct perceptual and subjective images, providing a new window into the internal contents of the brain.},
	language = {en},
	number = {1},
	urldate = {2021-06-18},
	journal = {PLOS Computational Biology},
	author = {Shen, Guohua and Horikawa, Tomoyasu and Majima, Kei and Kamitani, Yukiyasu},
	month = jan,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Functional magnetic resonance imaging, Algorithms, Vision, Neural networks, Sensory perception, Imaging techniques, Luminance, Optimization},
	pages = {e1006633},
	file = {Shen et al_2019_Deep image reconstruction from human brain activity.pdf:/Users/tito/Zotero/storage/9SXVPUC5/Shen et al_2019_Deep image reconstruction from human brain activity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/KYPJJ8Q8/article.html:text/html},
}

@article{bolt_large-scale_2021,
	title = {Large-{Scale} {Intrinsic} {Functional} {Brain} {Organization} {Emerges} from {Three} {Canonical} {Spatiotemporal} {Patterns}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.06.20.448984v1},
	doi = {10.1101/2021.06.20.448984},
	abstract = {{\textless}p{\textgreater}The characterization of intrinsic functional brain organization has been approached from a multitude of analytic techniques and methods. We are still at a loss of a unifying conceptual framework for capturing common insights across this patchwork of empirical findings. By analyzing resting-state fMRI data from the Human Connectome Project using a large number of popular analytic techniques, we find that all results can be seamlessly reconciled by three fundamental low-frequency spatiotemporal patterns that we have identified via a novel time-varying complex pattern analysis. Overall, these three spatiotemporal patterns account for a wide variety of previously observed phenomena in the resting-state fMRI literature including the task-positive/task-negative anticorrelation, the global signal, the primary functional connectivity gradient and the network community structure of the functional connectome. The shared spatial and temporal properties of these three canonical patterns suggest that they arise from a single hemodynamic mechanism.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-21},
	journal = {bioRxiv},
	author = {Bolt, Taylor S. and Nomi, Jason and Bzdok, Danilo and Chang, Catie and Yeo, B. T. Thomas and Uddin, Lucina Q. and Keilholz, Shella},
	month = jun,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.06.20.448984},
	file = {Bolt et al_2021_Large-Scale Intrinsic Functional Brain Organization Emerges from Three.pdf:/Users/tito/Zotero/storage/UK2MFPLN/Bolt et al_2021_Large-Scale Intrinsic Functional Brain Organization Emerges from Three.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DSLHM6N4/2021.06.20.html:text/html},
}

@article{chen_dynamical_2021,
	title = {Dynamical differential covariance recovers directional network structure in multiscale neural systems},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.06.18.448901v1},
	doi = {10.1101/2021.06.18.448901},
	abstract = {{\textless}p{\textgreater}Investigating causal neural interactions are essential to understanding sub- sequent behaviors. Many statistical methods have been used for analyzing neural activity, but efficiently and correctly estimating the direction of net- work interactions remains difficult. Here, we derive dynamical differential covariance (DDC), a new method based on dynamical network models that detects directional interactions with low bias and high noise tolerance with- out the stationary assumption. The method is first validated on networks with false positive motifs and multiscale neural simulations where the ground truth connectivity is known. Then, applying DDC to recordings of resting-state functional magnetic resonance imaging (rs-fMRI) from over 1,000 individual subjects, DDC consistently detected regional interactions with strong structural connectivity. DDC can be generalized to a wide range of dynamical models and recording techniques.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-21},
	journal = {bioRxiv},
	author = {Chen, Yusi and Rosen, Burke Q. and Sejnowski, Terrence J.},
	month = jun,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.06.18.448901},
	file = {Chen et al_2021_Dynamical differential covariance recovers directional network structure in.pdf:/Users/tito/Zotero/storage/ZEDHLBH2/Chen et al_2021_Dynamical differential covariance recovers directional network structure in.pdf:application/pdf},
}

@article{pena_oscillations_2021,
	title = {Oscillations and variability in neuronal systems: interplay of autonomous transient dynamics and fast deterministic fluctuations},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Oscillations and variability in neuronal systems},
	url = {https://www.biorxiv.org/content/10.1101/2021.06.14.448371v1},
	doi = {10.1101/2021.06.14.448371},
	abstract = {{\textless}p{\textgreater}Neuronal systems are subject to rapidly fluctuations both intrinsically and externally. In mathematical models, these fluctuations are typically incorporated as stochastic noise (e.g., Gaussian white or colored noise). Noise can be both disruptive and constructive, for example, by creating irregularities and variability in otherwise regular patterns or by creating oscillatory patterns and increasing the signal coherence, respectively. The dynamic mechanisms underlying the interactions between rapidly fluctuating signals and the intrinsic properties of the target cells to produce variable and/or coherent responses are not fully understood. In particular, it is not clear what properties of the target cell9s intrinsic dynamics control these interactions and whether the generation of this phenomena requires stochasticity of the input signal and, if yes, to what degree. In this paper we investigate these issues by using linearized and non-linear conductance-based models and piecewise constant (PWC) inputs with short duration pieces and variable amplitudes, which are arbitrarily, but not necessarily stochastically distributed. The amplitude distributions of the constant pieces consist of arbitrary permutations of a baseline PWC function with monotonically increasing amplitudes. In each trial within a given protocol we use one of these permutations and each protocol consists of a subset of all possible permutations, which is the only source of uncertainty in the protocol. We show that sustained oscillatory behavior can be generated in response to additive and multiplicative PWC inputs in both linear and nonlinear systems, independently of whether the stable equilibria of the corresponding unperturbed systems are foci (exhibiting damped oscillations) or nodes (exhibiting overshoots). The oscillatory responses are amplified by the model nonlinearities and attenuated for conductance-based PWC inputs as compared to current-based PWC inputs, consistent with previous theoretical and experimental work. In addition, the responses to PWC inputs exhibited variability across trials, which is reminiscent of the variability generated by stochastic noise (e.g., Gaussian white noise). This variability was modulated by the model parameters and the type of cellular intrinsic dynamics. Our analysis demonstrates that both oscillations and variability are the result of the interaction between the PWC input and the autonomous transient dynamics with little to no contribution from the dynamics around the steady-state. The generation of oscillations and variability does not require input stochasticity, but rather the sequential activation of the transient responses to abrupt changes in constant inputs. Each piece with the same amplitude evokes different responses across trials due to the differences in initial conditions in the corresponding regime. These initial conditions are determined by the value of the voltage at the end of the previous regime, which is different for different trials.The predictions made in this papers are amenable for experimental testing both \textit{in vitro} and \textit{in vivo}.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-21},
	journal = {bioRxiv},
	author = {Pena, Rodrigo F. O. and Rotstein, Horacio G.},
	month = jun,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.06.14.448371},
	file = {Pena_Rotstein_2021_Oscillations and variability in neuronal systems.pdf:/Users/tito/Zotero/storage/GS7APLPF/Pena_Rotstein_2021_Oscillations and variability in neuronal systems.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/BB8FN9WB/2021.06.14.448371v1.full.html:text/html},
}

@article{baracchini_inter-regional_2021,
	title = {Inter-regional {BOLD} signal variability is an organizational feature of functional brain networks},
	volume = {237},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921004262},
	doi = {10.1016/j.neuroimage.2021.118149},
	abstract = {Neuronal variability patterns promote the formation and organization of neural circuits. Macroscale similarities in regional variability patterns may therefore be linked to the strength and topography of inter-regional functional connections. To assess this relationship, we used multi-echo resting-state fMRI and investigated macroscale connectivity-variability associations in 154 adult humans (86 women; mean age = 22yrs). We computed inter-regional measures of moment-to-moment BOLD signal variability and related them to inter-regional functional connectivity. Region pairs that showed stronger functional connectivity also showed similar BOLD signal variability patterns, independent of inter-regional distance and structural similarity. Connectivity-variability associations were predominant within all networks and followed a hierarchical spatial organization that separated sensory, motor and attention systems from limbic, default and frontoparietal control association networks. Results were replicated in a second held-out fMRI run. These findings suggest that macroscale BOLD signal variability is an organizational feature of large-scale functional networks, and shared inter-regional BOLD signal variability may underlie macroscale brain network dynamics.},
	language = {en},
	urldate = {2021-06-21},
	journal = {NeuroImage},
	author = {Baracchini, Giulia and Mišić, Bratislav and Setton, Roni and Mwilambwe-Tshilobo, Laetitia and Girn, Manesh and Nomi, Jason S. and Uddin, Lucina Q. and Turner, Gary R. and Spreng, R. Nathan},
	month = aug,
	year = {2021},
	pages = {118149},
	file = {Baracchini et al_2021_Inter-regional BOLD signal variability is an organizational feature of.pdf:/Users/tito/Zotero/storage/7HDY64SE/Baracchini et al_2021_Inter-regional BOLD signal variability is an organizational feature of.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/3Y3ZU826/S1053811921004262.html:text/html},
}

@article{canatar_spectral_2021-1,
	title = {Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-23103-1},
	doi = {10.1038/s41467-021-23103-1},
	abstract = {A theoretical understanding of generalization remains an open problem for many machine learning models, including deep networks where overparameterization leads to better performance, contradicting the conventional wisdom from classical statistics. Here, we investigate generalization error for kernel regression, which, besides being a popular machine learning method, also describes certain infinitely overparameterized neural networks. We use techniques from statistical mechanics to derive an analytical expression for generalization error applicable to any kernel and data distribution. We present applications of our theory to real and synthetic datasets, and for many kernels including those that arise from training deep networks in the infinite-width limit. We elucidate an inductive bias of kernel regression to explain data with simple functions, characterize whether a kernel is compatible with a learning task, and show that more data may impair generalization when noisy or not expressible by the kernel, leading to non-monotonic learning curves with possibly many peaks.},
	language = {en},
	number = {1},
	urldate = {2021-06-23},
	journal = {Nat Commun},
	author = {Canatar, Abdulkadir and Bordelon, Blake and Pehlevan, Cengiz},
	month = may,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Applied mathematics;Computer science
Subject\_term\_id: applied-mathematics;computer-science},
	pages = {2914},
	file = {Canatar et al_2021_Spectral bias and task-model alignment explain generalization in kernel.pdf:/Users/tito/Zotero/storage/YBRVMBVT/Canatar et al_2021_Spectral bias and task-model alignment explain generalization in kernel.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/MT7WVJ29/s41467-021-23103-1.html:text/html},
}

@article{arora_exact_2019,
	title = {On {Exact} {Computation} with an {Infinitely} {Wide} {Neural} {Net}},
	url = {http://arxiv.org/abs/1904.11955},
	abstract = {How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its “width”— namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers — is allowed to increase to inﬁnity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the inﬁnite width limit trained by gradient descent; this object was implicit in some other recent papers. An attraction of such ideas is that a pure kernel-based method is used to capture the power of a fully-trained deep net of inﬁnite width.},
	language = {en},
	urldate = {2021-06-23},
	journal = {arXiv:1904.11955 [cs, stat]},
	author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
	month = nov,
	year = {2019},
	note = {arXiv: 1904.11955},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: In NeurIPS 2019. Code available: https://github.com/ruosongwang/cntk},
	file = {Arora et al. - 2019 - On Exact Computation with an Infinitely Wide Neura.pdf:/Users/tito/Zotero/storage/3VQRF4ML/Arora et al. - 2019 - On Exact Computation with an Infinitely Wide Neura.pdf:application/pdf},
}

@article{saglietti_analytical_2021,
	title = {An {Analytical} {Theory} of {Curriculum} {Learning} in {Teacher}-{Student} {Networks}},
	url = {http://arxiv.org/abs/2106.08068},
	abstract = {In humans and animals, curriculum learning -- presenting data in a curated order - is critical to rapid learning and effective pedagogy. Yet in machine learning, curricula are not widely used and empirically often yield only moderate benefits. This stark difference in the importance of curriculum raises a fundamental theoretical question: when and why does curriculum learning help? In this work, we analyse a prototypical neural network model of curriculum learning in the high-dimensional limit, employing statistical physics methods. Curricula could in principle change both the learning speed and asymptotic performance of a model. To study the former, we provide an exact description of the online learning setting, confirming the long-standing experimental observation that curricula can modestly speed up learning. To study the latter, we derive performance in a batch learning setting, in which a network trains to convergence in successive phases of learning on dataset slices of varying difficulty. With standard training losses, curriculum does not provide generalisation benefit, in line with empirical observations. However, we show that by connecting different learning phases through simple Gaussian priors, curriculum can yield a large improvement in test performance. Taken together, our reduced analytical descriptions help reconcile apparently conflicting empirical results and trace regimes where curriculum learning yields the largest gains. More broadly, our results suggest that fully exploiting a curriculum may require explicit changes to the loss function at curriculum boundaries.},
	urldate = {2021-06-23},
	journal = {arXiv:2106.08068 [cond-mat, stat]},
	author = {Saglietti, Luca and Mannelli, Stefano Sarao and Saxe, Andrew},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.08068},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks},
	annote = {Comment: 10 pages + appendix},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/JHMQUIN9/2106.html:text/html;Saglietti et al_2021_An Analytical Theory of Curriculum Learning in Teacher-Student Networks.pdf:/Users/tito/Zotero/storage/23HTBUXC/Saglietti et al_2021_An Analytical Theory of Curriculum Learning in Teacher-Student Networks.pdf:application/pdf},
}

@article{liang_experience_2020,
	title = {Experience {Transforms} {Conjunctive} {Object} {Representations}: {Neural} {Evidence} for {Unitization} {After} {Visual} {Expertise}},
	volume = {30},
	issn = {1047-3211},
	shorttitle = {Experience {Transforms} {Conjunctive} {Object} {Representations}},
	url = {https://doi.org/10.1093/cercor/bhz250},
	doi = {10.1093/cercor/bhz250},
	abstract = {Certain transformations must occur within the brain to allow rapid processing of familiar experiences. Complex objects are thought to become unitized, whereby multifeature conjunctions are retrieved as rapidly as a single feature. Behavioral studies strongly support unitization theory, but a compelling neural mechanism is lacking. Here, we examined how unitization transforms conjunctive representations to become more “feature-like” by recruiting posterior regions of the ventral visual stream (VVS) whose architecture is specialized for processing single features. We used functional magnetic resonance imaging to scan humans before and after visual training with novel objects. We implemented a novel multivoxel pattern analysis to measure a conjunctive code, which represented a conjunction of object features above and beyond the sum of the parts. Importantly, a multivoxel searchlight showed that the strength of conjunctive coding in posterior VVS increased posttraining. Furthermore, multidimensional scaling revealed representational separation at the level of individual features in parallel to the changes at the level of feature conjunctions. Finally, functional connectivity between anterior and posterior VVS was higher for novel objects than for trained objects, consistent with early involvement of anterior VVS in unitizing feature conjunctions in response to novelty. These data demonstrate that the brain implements unitization as a mechanism to refine complex object representations over the course of multiple learning experiences.},
	number = {5},
	urldate = {2021-06-28},
	journal = {Cerebral Cortex},
	author = {Liang, Jackson C and Erez, Jonathan and Zhang, Felicia and Cusack, Rhodri and Barense, Morgan D},
	month = may,
	year = {2020},
	pages = {2721--2739},
	file = {Liang et al_2020_Experience Transforms Conjunctive Object Representations.pdf:/Users/tito/Zotero/storage/ZKSSNC8D/Liang et al_2020_Experience Transforms Conjunctive Object Representations.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HKWUY35G/5730339.html:text/html},
}

@techreport{broker_when_2021,
	title = {When unsupervised training benefits category learning},
	url = {https://psyarxiv.com/k5pzu/},
	abstract = {Humans continuously categorise inputs, but only rarely receive explicit feedback as to whether or not they are correct. This implies that they may be integrating unsupervised information together with their sparse supervised data -- a form of semi-supervised learning. However, experiments testing semi-supervised learning are rare, and are bedevilled with conflicting results about whether the unsupervised information affords any benefit. Here, we suggest that one important factor that has been paid insufficient attention is the alignment between subjects' internal representations of the stimulus material and the experimenter-defined representations that determine success in the tasks. Subjects' representations are shaped by prior biases and experience, and unsupervised learning can only be successful if the alignment suffices. Otherwise, unsupervised learning might harmfully strengthen incorrect assumptions. To test this hypothesis, we conducted an experiment in which subjects initially categorise items along a salient, but task-irrelevant, dimension, and only recover the correct categories when sufficient feedback draws their attention to the subtle, task-relevant, stimulus dimensions. By withdrawing feedback at different stages along this learning curve, we tested whether unsupervised learning improves or worsens performance when internal stimulus representations and task are sufficiently or insufficiently aligned, respectively. Our results demonstrate that unsupervised learning can indeed have opposing effects on subjects' learning. We also discuss factors limiting the degree to which such effects can be predicted from momentary performance. Our work implies that predicting and understanding human category learning in particular tasks requires assessment and consideration of the representational spaces that subjects entertain for the materials involved in those tasks. These considerations not only apply to studies in the lab, but could also help improve the design of tutoring systems and instruction.},
	urldate = {2021-06-28},
	institution = {PsyArXiv},
	author = {Bröker, Franziska and Love, Bradley C. and Dayan, Peter},
	month = apr,
	year = {2021},
	doi = {10.31234/osf.io/k5pzu},
	note = {type: article},
	keywords = {Learning, representation, categorization, Cognitive Psychology, Concepts and Categories, semi-supervised learning, Social and Behavioral Sciences},
	file = {Bröker et al_2021_When unsupervised training benefits category learning.pdf:/Users/tito/Zotero/storage/FKI8FMZV/Bröker et al_2021_When unsupervised training benefits category learning.pdf:application/pdf},
}

@article{fendler_177lu-psma_2017,
	title = {{177Lu}-{PSMA} {Radioligand} {Therapy} for {Prostate} {Cancer}},
	volume = {58},
	copyright = {© 2017 by the Society of Nuclear Medicine and Molecular Imaging.},
	issn = {0161-5505, 2159-662X},
	url = {https://jnm.snmjournals.org/content/58/8/1196},
	doi = {10.2967/jnumed.117.191023},
	abstract = {{\textless}p{\textgreater}$^{\textrm{177}}$Lu-prostate-specific membrane antigen (PSMA) radioligand therapy (RLT) using inhibitors of PSMA is a novel therapeutic option in patients with metastatic castration-resistant prostate cancer. The current literature suggests that this therapy is well tolerated and effective. On the basis of clinical need and current evidence, the therapy is being implemented in a growing number of centers worldwide. Here, we review important aspects of $^{\textrm{177}}$Lu-PSMA RLT, including patient stratification, the therapy protocol, concomitant medication, and follow-up, to inform medical staff involved in the RLT and care of patients with metastatic castration-resistant prostate cancer.{\textless}/p{\textgreater}},
	language = {en},
	number = {8},
	urldate = {2021-06-29},
	journal = {Journal of Nuclear Medicine},
	author = {Fendler, Wolfgang P. and Rahbar, Kambiz and Herrmann, Ken and Kratochwil, Clemens and Eiber, Matthias},
	month = aug,
	year = {2017},
	pmid = {28663195},
	note = {Publisher: Society of Nuclear Medicine
Section: Continuing Education},
	pages = {1196--1200},
	file = {Fendler et al_2017_177Lu-PSMA Radioligand Therapy for Prostate Cancer.pdf:/Users/tito/Zotero/storage/BNVL83PA/Fendler et al_2017_177Lu-PSMA Radioligand Therapy for Prostate Cancer.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5UC5DXZI/1196.html:text/html},
}

@article{karlaftis_functional_2021,
	title = {Functional {Interactions} between {Sensory} and {Memory} {Networks} for {Adaptive} {Behavior}},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhab160},
	doi = {10.1093/cercor/bhab160},
	abstract = {The brain’s capacity to adapt to sensory inputs is key for processing sensory information efficiently and interacting in new environments. Following repeated exposure to the same sensory input, brain activity in sensory areas is known to decrease as inputs become familiar, a process known as adaptation. Yet, the brain-wide mechanisms that mediate adaptive processing remain largely unknown. Here, we combine multimodal brain imaging (functional magnetic resonance imaging [fMRI], magnetic resonance spectroscopy) with behavioral measures of orientation-specific adaptation (i.e., tilt aftereffect) to investigate the functional and neurochemical mechanisms that support adaptive processing. Our results reveal two functional brain networks: 1) a sensory-adaptation network including occipital and dorsolateral prefrontal cortex regions that show decreased fMRI responses for repeated stimuli and 2) a perceptual-memory network including regions in the parietal memory network (PMN) and dorsomedial prefrontal cortex that relate to perceptual bias (i.e., tilt aftereffect). We demonstrate that adaptation relates to increased occipito-parietal connectivity, while decreased connectivity between sensory-adaptation and perceptual-memory networks relates to GABAergic inhibition in the PMN. Thus, our findings provide evidence that suppressive interactions between sensory-adaptation (i.e., occipito-parietal) and perceptual-memory (i.e., PMN) networks support adaptive processing and behavior, proposing a key role of memory systems in efficient sensory processing.},
	number = {bhab160},
	urldate = {2021-07-01},
	journal = {Cerebral Cortex},
	author = {Karlaftis, Vasilis M and Giorgio, Joseph and Zamboni, Elisa and Frangou, Polytimi and Rideaux, Reuben and Ziminski, Joseph J and Kourtzi, Zoe},
	month = jun,
	year = {2021},
	file = {Karlaftis et al_2021_Functional Interactions between Sensory and Memory Networks for Adaptive.pdf:/Users/tito/Zotero/storage/WFQNJZUT/Karlaftis et al_2021_Functional Interactions between Sensory and Memory Networks for Adaptive.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/97TFXAU6/6311001.html:text/html},
}

@article{gao_nonlinear_nodate,
	title = {Nonlinear manifold learning in functional magnetic resonance imaging uncovers a low-dimensional space of brain dynamics},
	volume = {n/a},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.25561},
	doi = {10.1002/hbm.25561},
	abstract = {Large-scale brain dynamics are believed to lie in a latent, low-dimensional space. Typically, the embeddings of brain scans are derived independently from different cognitive tasks or resting-state data, ignoring a potentially large—and shared—portion of this space. Here, we establish that a shared, robust, and interpretable low-dimensional space of brain dynamics can be recovered from a rich repertoire of task-based functional magnetic resonance imaging (fMRI) data. This occurs when relying on nonlinear approaches as opposed to traditional linear methods. The embedding maintains proper temporal progression of the tasks, revealing brain states and the dynamics of network integration. We demonstrate that resting-state data embeds fully onto the same task embedding, indicating similar brain states are present in both task and resting-state data. Our findings suggest analysis of fMRI data from multiple cognitive tasks in a low-dimensional space is possible and desirable.},
	language = {en},
	number = {n/a},
	urldate = {2021-07-13},
	journal = {Human Brain Mapping},
	author = {Gao, Siyuan and Mishne, Gal and Scheinost, Dustin},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25561},
	keywords = {integration, dynamic connectivity, segregation, diffusion maps, participation coefficient},
}

@article{sydnor_neurodevelopment_2021,
	title = {Neurodevelopment of the association cortices: {Patterns}, mechanisms, and implications for psychopathology},
	volume = {0},
	issn = {0896-6273},
	shorttitle = {Neurodevelopment of the association cortices},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(21)00457-8},
	doi = {10.1016/j.neuron.2021.06.016},
	language = {English},
	number = {0},
	urldate = {2021-07-16},
	journal = {Neuron},
	author = {Sydnor, Valerie J. and Larsen, Bart and Bassett, Danielle S. and Alexander-Bloch, Aaron and Fair, Damien A. and Liston, Conor and Mackey, Allyson P. and Milham, Michael P. and Pines, Adam and Roalf, David R. and Seidlitz, Jakob and Xu, Ting and Raznahan, Armin and Satterthwaite, Theodore D.},
	month = jul,
	year = {2021},
	note = {Publisher: Elsevier},
	keywords = {MRI, neuroimaging, psychopathology, gradient, evolution, adolescence, association cortex, axis, microscale, neurodevelopment},
	file = {Snapshot:/Users/tito/Zotero/storage/9EXIFM4N/S0896-6273(21)00457-8.html:text/html},
}

@article{hearne_activity_2021,
	title = {Activity flow underlying abnormalities in brain activations and cognition in schizophrenia},
	volume = {7},
	copyright = {Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. https://creativecommons.org/licenses/by-nc/4.0/This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/7/29/eabf2513},
	doi = {10.1126/sciadv.abf2513},
	abstract = {Cognitive dysfunction is a core feature of many brain disorders, including schizophrenia (SZ), and has been linked to aberrant brain activations. However, it is unclear how these activation abnormalities emerge. We propose that aberrant flow of brain activity across functional connectivity (FC) pathways leads to altered activations that produce cognitive dysfunction in SZ. We tested this hypothesis using activity flow mapping, an approach that models the movement of task-related activity between brain regions as a function of FC. Using functional magnetic resonance imaging data from SZ individuals and healthy controls during a working memory task, we found that activity flow models accurately predict aberrant cognitive activations across multiple brain networks. Within the same framework, we simulated a connectivity-based clinical intervention, predicting specific treatments that normalized brain activations and behavior in patients. Our results suggest that dysfunctional task-evoked activity flow is a large-scale network mechanism contributing to cognitive dysfunction in SZ.
The way that brain activity flows across brain wiring helps explain abnormal brain responses and behaviors in schizophrenia.
The way that brain activity flows across brain wiring helps explain abnormal brain responses and behaviors in schizophrenia.},
	language = {en},
	number = {29},
	urldate = {2021-07-16},
	journal = {Science Advances},
	author = {Hearne, Luke J. and Mill, Ravi D. and Keane, Brian P. and Repovš, Grega and Anticevic, Alan and Cole, Michael W.},
	month = jul,
	year = {2021},
	pmid = {34261649},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eabf2513},
	file = {Hearne et al_2021_Activity flow underlying abnormalities in brain activations and cognition in.pdf:/Users/tito/Zotero/storage/XCHQ23JR/Hearne et al_2021_Activity flow underlying abnormalities in brain activations and cognition in.pdf:application/pdf},
}

@article{muschelli_reduction_2014-1,
	title = {Reduction of motion-related artifacts in resting state {fMRI} using {aCompCor}},
	volume = {96},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381191400175X},
	doi = {10.1016/j.neuroimage.2014.03.028},
	abstract = {Recent studies have illustrated that motion-related artifacts remain in resting-state fMRI (rs-fMRI) data even after common corrective processing procedures have been applied, but the extent to which head motion distorts the data may be modulated by the corrective approach taken. We compare two different methods for estimating nuisance signals from tissues not expected to exhibit BOLD fMRI signals of neuronal origin: 1) the more commonly used mean signal method and 2) the principal components analysis approach (aCompCor: Behzadi et al., 2007). Further, we investigate the added benefit of “scrubbing” (Power et al., 2012) following both methods. We demonstrate that the use of aCompCor removes motion artifacts more effectively than tissue-mean signal regression. In addition, inclusion of more components from anatomically defined regions of no interest better mitigates motion-related artifacts and improves the specificity of functional connectivity estimates. While scrubbing further attenuates motion-related artifacts when mean signals are used, scrubbing provides no additional benefit in terms of motion artifact reduction or connectivity specificity when using aCompCor.},
	language = {en},
	urldate = {2021-07-21},
	journal = {NeuroImage},
	author = {Muschelli, John and Nebel, Mary Beth and Caffo, Brian S. and Barber, Anita D. and Pekar, James J. and Mostofsky, Stewart H.},
	month = aug,
	year = {2014},
	keywords = {Head motion, Nuisance regression, Resting state fMRI, Specificity},
	pages = {22--35},
	file = {Muschelli et al_2014_Reduction of motion-related artifacts in resting state fMRI using aCompCor.pdf:/Users/tito/Zotero/storage/JNVWTB7U/Muschelli et al_2014_Reduction of motion-related artifacts in resting state fMRI using aCompCor.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/PY8VZPJ6/S105381191400175X.html:text/html},
}

@article{yuan_spike_2021,
	title = {Spike signal transmission between modules and the predictability of spike activity in modular neuronal networks},
	volume = {526},
	issn = {0022-5193},
	url = {https://www.sciencedirect.com/science/article/pii/S0022519321002307},
	doi = {10.1016/j.jtbi.2021.110811},
	abstract = {Modularity is a common feature of the nervous system across species and scales. Although it has been qualitatively investigated in network science, very little is known about how it affects spike signal transmission in neuronal networks at the mesoscopic level. Here, a neuronal network model is built to simulate dynamic interactions among different modules of neuronal networks. This neuronal network model follows the organizational principle of modular structure. The neurons can generate spikes like biological neurons, and changes in the strength of synaptic connections conform to the STDP learning rule. Based on this neuronal network model, we first quantitatively studied whether and to what extent the connectivity within and between modules can affect spike signal transmission, and found that spike signal transmission heavily depends on the connectivity between modules, but has little to do with the connectivity within modules. More importantly, we further found that the spike activity of a module can be predicted according to the spike activities of its adjacent modules through building a resting-state functional connectivity matrix.},
	language = {en},
	urldate = {2021-07-21},
	journal = {Journal of Theoretical Biology},
	author = {Yuan, Ye and Liu, Jian and Zhao, Peng and Huo, Hong and Fang, Tao},
	month = oct,
	year = {2021},
	keywords = {Modularity, Modular neuronal networks, Resting-state functional connectivity matrix, Spike signal transmission, STDP learning rule},
	pages = {110811},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/FCJVSTMX/S0022519321002307.html:text/html;Yuan et al_2021_Spike signal transmission between modules and the predictability of spike.pdf:/Users/tito/Zotero/storage/B6H2T244/Yuan et al_2021_Spike signal transmission between modules and the predictability of spike.pdf:application/pdf},
}

@article{umakantha_bridging_2021,
	title = {Bridging neuronal correlations and dimensionality reduction},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627321004694},
	doi = {10.1016/j.neuron.2021.06.028},
	abstract = {Two commonly used approaches to study interactions among neurons are spike count correlation, which describes pairs of neurons, and dimensionality reduction, applied to a population of neurons. Although both approaches have been used to study trial-to-trial neuronal variability correlated among neurons, they are often used in isolation and have not been directly related. We first established concrete mathematical and empirical relationships between pairwise correlation and metrics of population-wide covariability based on dimensionality reduction. Applying these insights to macaque V4 population recordings, we found that the previously reported decrease in mean pairwise correlation associated with attention stemmed from three distinct changes in population-wide covariability. Overall, our work builds the intuition and formalism to bridge between pairwise correlation and population-wide covariability and presents a cautionary tale about the inferences one can make about population activity by using a single statistic, whether it be mean pairwise correlation or dimensionality.},
	language = {en},
	urldate = {2021-07-22},
	journal = {Neuron},
	author = {Umakantha, Akash and Morina, Rudina and Cowley, Benjamin R. and Snyder, Adam C. and Smith, Matthew A. and Yu, Byron M.},
	month = jul,
	year = {2021},
	keywords = {dimensionality reduction, neuronal population, spatial attention, spike count correlation, visual area V4},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/9THJPNQU/S0896627321004694.html:text/html;Umakantha et al_2021_Bridging neuronal correlations and dimensionality reduction.pdf:/Users/tito/Zotero/storage/5U2UTBBB/Umakantha et al_2021_Bridging neuronal correlations and dimensionality reduction.pdf:application/pdf},
}

@article{liu_hierarchical_2021,
	title = {Hierarchical clustering optimizes the tradeoff between compositionality and expressivity of task structures in reinforcement learning},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.07.20.453122v1},
	doi = {10.1101/2021.07.20.453122},
	abstract = {{\textless}p{\textgreater}A hallmark of human intelligence is our ability to compositionally generalise: that is, to recompose familiar knowledge components in novel ways to solve new problems. For instance, a talented musician can conceivably transfer her knowledge of flute fingerings and guitar songs to play guitar music on a piccolo for the first time. Yet there are also instances where it can be helpful to learn and transfer not just individual task components, but entire structures or substructures, particularly whenever these recur in natural tasks (e.g., in bluegrass music one might transfer the joint structure of finger movements and musical scales from one stringed instrument to another). Prior theoretical work has explored how agents can learn and generalize task components or entire latent structures, but a satisfactory account for how a single agent can simultaneously satisfy the two competing demands is still lacking. Here, we propose a hierarchical model-based agent that learns and transfers individual task components as well as entire structures by inferring both through a non-parametric Bayesian model of the task. It maintains a factorised representation of task components through a hierarchical Dirichlet process, but it also represents different possible covariances between these components through a standard Dirichlet process. We validate our approach on a variety of navigation tasks covering a wide range of statistical correlations between task components and show that this hierarchical framework can also be applied to improve generalisation and transfer in hierarchical tasks with goal/subgoal structures.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-07-22},
	journal = {bioRxiv},
	author = {Liu, Rex G. and Frank, Michael J.},
	month = jul,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.07.20.453122},
	file = {Liu_Frank_2021_Hierarchical clustering optimizes the tradeoff between compositionality and.pdf:/Users/tito/Zotero/storage/ZY8K7CGW/Liu_Frank_2021_Hierarchical clustering optimizes the tradeoff between compositionality and.pdf:application/pdf},
}

@article{chan_decreased_2014,
	title = {Decreased segregation of brain systems across the healthy adult lifespan},
	volume = {111},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/111/46/E4997},
	doi = {10.1073/pnas.1415122111},
	abstract = {Healthy aging has been associated with decreased specialization in brain function. This characterization has focused largely on describing age-accompanied differences in specialization at the level of neurons and brain areas. We expand this work to describe systems-level differences in specialization in a healthy adult lifespan sample (n = 210; 20–89 y). A graph-theoretic framework is used to guide analysis of functional MRI resting-state data and describe systems-level differences in connectivity of individual brain networks. Young adults’ brain systems exhibit a balance of within- and between-system correlations that is characteristic of segregated and specialized organization. Increasing age is accompanied by decreasing segregation of brain systems. Compared with systems involved in the processing of sensory input and motor output, systems mediating “associative” operations exhibit a distinct pattern of reductions in segregation across the adult lifespan. Of particular importance, the magnitude of association system segregation is predictive of long-term memory function, independent of an individual’s age.},
	language = {en},
	number = {46},
	urldate = {2021-07-23},
	journal = {PNAS},
	author = {Chan, Micaela Y. and Park, Denise C. and Savalia, Neil K. and Petersen, Steven E. and Wig, Gagan S.},
	month = nov,
	year = {2014},
	pmid = {25368199},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {brain networks, memory, connectome, aging, resting-state correlations},
	pages = {E4997--E5006},
	file = {Chan et al_2014_Decreased segregation of brain systems across the healthy adult lifespan.pdf:/Users/tito/Zotero/storage/6CMSIJ2A/Chan et al_2014_Decreased segregation of brain systems across the healthy adult lifespan.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/CRDPJL2R/E4997.html:text/html},
}

@article{pedersen_reducing_2020,
	title = {Reducing the influence of intramodular connectivity in participation coefficient},
	volume = {4},
	issn = {2472-1751},
	url = {https://doi.org/10.1162/netn_a_00127},
	doi = {10.1162/netn_a_00127},
	abstract = {Both natural and engineered networks are often modular. Whether a network node interacts with only nodes from its own module or nodes from multiple modules provides insight into its functional role. The participation coefficient (PC) is typically used to measure this attribute, although its value also depends on the size and connectedness of the module it belongs to and may lead to nonintuitive identification of highly connected nodes. Here, we develop a normalized PC that reduces the influence of intramodular connectivity compared with the conventional PC. Using brain, C. elegans, airport, and simulated networks, we show that our measure of participation is not influenced by the size or connectedness of modules, while preserving conceptual and mathematical properties, of the classic formulation of PC. Unlike the conventional PC, we identify London and New York as high participators in the air traffic network and demonstrate stronger associations with working memory in human brain networks, yielding new insights into nodal participation across network modules.It is challenging to reliably quantify how single elements (i.e., nodes) in a network are connected to different subcomponents (i.e., modules) of a network; this is important as intermodular connectivity contribute to efficient and distributed information processing. Participation coefficient (PC) calculates how distributed nodes are across modules. But PC is influenced by modularity algorithms that tend to favor large modules with strong intramodule connectivity, that in turn generate low PC values, even if a node has strong intermodule connectivity. We use a network randomization approach and show that by reducing the influence of intramodular connectivity, we obtain node participation results unaffected by size and connectedness of modules. This provides network scientists with new insights into the intermodular connectivity configurations of complex networks.},
	number = {2},
	urldate = {2021-07-23},
	journal = {Network Neuroscience},
	author = {Pedersen, Mangor and Omidvarnia, Amir and Shine, James M. and Jackson, Graeme D. and Zalesky, Andrew},
	month = apr,
	year = {2020},
	pages = {416--431},
	file = {Pedersen et al_2020_Reducing the influence of intramodular connectivity in participation coefficient.pdf:/Users/tito/Zotero/storage/FCHNJPJ5/Pedersen et al_2020_Reducing the influence of intramodular connectivity in participation coefficient.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/THBZNTZ4/Reducing-the-influence-of-intramodular.html:text/html},
}

@article{pinho_individual_2020,
	title = {Individual {Brain} {Charting} dataset extension, second release of high-resolution {fMRI} data for cognitive mapping},
	volume = {7},
	copyright = {2020 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-020-00670-4},
	doi = {10.1038/s41597-020-00670-4},
	abstract = {We present an extension of the Individual Brain Charting dataset –a high spatial-resolution, multi-task, functional Magnetic Resonance Imaging dataset, intended to support the investigation on the functional principles governing cognition in the human brain. The concomitant data acquisition from the same 12 participants, in the same environment, allows to obtain in the long run finer cognitive topographies, free from inter-subject and inter-site variability. This second release provides more data from psychological domains present in the first release, and also yields data featuring new ones. It includes tasks on e.g. mental time travel, reward, theory-of-mind, pain, numerosity, self-reference effect and speech recognition. In total, 13 tasks with 86 contrasts were added to the dataset and 63 new components were included in the cognitive description of the ensuing contrasts. As the dataset becomes larger, the collection of the corresponding topographies becomes more comprehensive, leading to better brain-atlasing frameworks. This dataset is an open-access facility; raw data and derivatives are publicly available in neuroimaging repositories.},
	language = {en},
	number = {1},
	urldate = {2021-07-23},
	journal = {Sci Data},
	author = {Pinho, Ana Luísa and Amadon, Alexis and Gauthier, Baptiste and Clairis, Nicolas and Knops, André and Genon, Sarah and Dohmatob, Elvis and Torre, Juan Jesús and Ginisty, Chantal and Becuwe-Desmidt, Séverine and Roger, Séverine and Lecomte, Yann and Berland, Valérie and Laurier, Laurence and Joly-Testault, Véronique and Médiouni-Cloarec, Gaëlle and Doublé, Christine and Martins, Bernadette and Salmon, Eric and Piazza, Manuela and Melcher, David and Pessiglione, Mathias and van Wassenhove, Virginie and Eger, Evelyn and Varoquaux, Gaël and Dehaene, Stanislas and Hertz-Pannier, Lucie and Thirion, Bertrand},
	month = oct,
	year = {2020},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_publicdomain
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Brain imaging;Cognitive neuroscience;Functional magnetic resonance imaging;Human behaviour
Subject\_term\_id: brain-imaging;cognitive-neuroscience;functional-magnetic-resonance-imaging;human-behaviour},
	pages = {353},
	file = {Pinho et al_2020_Individual Brain Charting dataset extension, second release of high-resolution.pdf:/Users/tito/Zotero/storage/FVFIU6AM/Pinho et al_2020_Individual Brain Charting dataset extension, second release of high-resolution.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6SWSQALW/s41597-020-00670-4.html:text/html},
}

@article{traud_comparing_2011-1,
	title = {Comparing {Community} {Structure} to {Characteristics} in {Online} {Collegiate} {Social} {Networks}},
	volume = {53},
	issn = {0036-1445},
	url = {https://www.jstor.org/stable/23070144},
	abstract = {We study the structure of social networks of students by examining the graphs of Facebook "friendships" at five U.S. universities at a single point in time. We investigate the community structure of each single-institution network and employ visual and quantitative tools, including standardized pair-counting methods, to measure the correlations between the network communities and a set of self-identified user characteristics (residence, class year, major, and high school). We review the basic properties and statistics of the employed pair-counting indices and recall, in simplified notation, a useful formula for the z-score of the Rand coefficient. Our study illustrates how to examine different instances of social networks constructed in similar environments, emphasizes the array of social forces that combine to form "communities," and leads to comparative observations about online social structures, which reflect offline social structures. We calculate the relative contributions of different characteristics to the community structure of individual universities and compare these relative contributions at different universities. For example, we examine the importance of common high school affiliation at large state universities and the varying degrees of influence that common major can have on the social structure at different universities. The heterogeneity of the communities that we observe indicates that university networks typically have multiple organizing factors rather than a single dominant one.},
	number = {3},
	urldate = {2021-07-26},
	journal = {SIAM Review},
	author = {Traud, Amanda L. and Kelsic, Eric D. and Mucha, Peter J. and Porter, Mason A.},
	year = {2011},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {526--543},
}

@article{red_comparing_2011,
	title = {Comparing {Community} {Structure} to {Characteristics} in {Online} {Collegiate} {Social} {Networks}},
	volume = {53},
	issn = {0036-1445},
	url = {https://epubs.siam.org/doi/10.1137/080734315},
	doi = {10.1137/080734315},
	abstract = {We study the structure of social networks of students by examining the graphs of Facebook “friendships” at five U.S. universities at a single point in time. We investigate the community structure of each single-institution network and employ visual and quantitative tools, including standardized pair-counting methods, to measure the correlations between the network communities and a set of self-identified user characteristics (residence, class year, major, and high school). We review the basic properties and statistics of the employed pair-counting indices and recall, in simplified notation, a useful formula for the z-score of the Rand coefficient. Our study illustrates how to examine different instances of social networks constructed in similar environments, emphasizes the array of social forces that combine to form “communities,” and leads to comparative observations about online social structures, which reflect offline social structures. We calculate the relative contributions of different characteristics to the community structure of individual universities and compare these relative contributions at different universities. For example, we examine the importance of common high school affiliation at large state universities and the varying degrees of influence that common major can have on the social structure at different universities. The heterogeneity of the communities that we observe indicates that university networks typically have multiple organizing factors rather than a single dominant one.},
	number = {3},
	urldate = {2021-07-26},
	journal = {SIAM Rev.},
	author = {Red, Veronica and Kelsic, Eric D. and Mucha, Peter J. and Porter, Mason A.},
	month = jan,
	year = {2011},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {networks, 82-08, 91-08, community structure, contingency tables, pair counting, 62H17, 91D30},
	pages = {526--543},
	file = {Red et al_2011_Comparing Community Structure to Characteristics in Online Collegiate Social.pdf:/Users/tito/Zotero/storage/AUDUEPJJ/Red et al_2011_Comparing Community Structure to Characteristics in Online Collegiate Social.pdf:application/pdf},
}

@article{sanzeni_inhibition_2020,
	title = {Inhibition stabilization is a widespread property of cortical networks},
	volume = {9},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.54875},
	doi = {10.7554/eLife.54875},
	abstract = {Many cortical network models use recurrent coupling strong enough to require inhibition for stabilization. Yet it has been experimentally unclear whether inhibition-stabilized network (ISN) models describe cortical function well across areas and states. Here, we test several ISN predictions, including the counterintuitive (paradoxical) suppression of inhibitory firing in response to optogenetic inhibitory stimulation. We find clear evidence for ISN operation in mouse visual, somatosensory, and motor cortex. Simple two-population ISN models describe the data well and let us quantify coupling strength. Although some models predict a non-ISN to ISN transition with increasingly strong sensory stimuli, we find ISN effects without sensory stimulation and even during light anesthesia. Additionally, average paradoxical effects result only with transgenic, not viral, opsin expression in parvalbumin (PV)-positive neurons; theory and expression data show this is consistent with ISN operation. Taken together, these results show strong coupling and inhibition stabilization are common features of the cortex.},
	urldate = {2021-07-26},
	journal = {eLife},
	author = {Sanzeni, Alessandro and Akitake, Bradley and Goldbach, Hannah C and Leedy, Caitlin E and Brunel, Nicolas and Histed, Mark H},
	editor = {O'Leary, Timothy and Huguenard, John and Adesnik, Hillel},
	month = jun,
	year = {2020},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {optogenetics, cortical models, inhibitory stabilized network, model inference, paradoxical, transgenic animals},
	pages = {e54875},
	file = {Sanzeni et al_2020_Inhibition stabilization is a widespread property of cortical networks.pdf:/Users/tito/Zotero/storage/FNCJ9TY8/Sanzeni et al_2020_Inhibition stabilization is a widespread property of cortical networks.pdf:application/pdf},
}

@article{ahrends_data_2021,
	title = {Data and model considerations for estimating time-varying functional connectivity in {fMRI}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.07.28.454017v1},
	doi = {10.1101/2021.07.28.454017},
	abstract = {{\textless}p{\textgreater}Functional connectivity (FC) in the brain has been shown to exhibit subtle but reliable modulations within a session. One way of estimating time-varying FC is by using state-based models that describe fMRI time series as temporal sequences of states, each with an associated, characteristic pattern of FC. However, the estimation of these models from data sometimes fails to capture changes in a meaningful way, such that the model estimation assigns entire sessions (or the largest part of them) to a single state, therefore failing to capture within-session state modulations effectively; we refer to this phenomenon as the model becoming static, or model stasis. Here, we aim to quantify how the nature of the data and the choice of model parameters affect the model9s ability to detect temporal changes in FC using both simulated fMRI time courses and resting state fMRI data. We show that large between-subject FC differences can overwhelm subtler within-session modulations, causing the model to become static. Further, the choice of parcellation can also affect the model9s ability to detect temporal changes. We finally show that the model often becomes static when the number of free parameters that need to be estimated is high and the number of observations available for this estimation is low in comparison. Based on these findings, we derive a set of practical recommendations for time-varying FC studies, in terms of preprocessing, parcellation and complexity of the model.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-07-29},
	journal = {bioRxiv},
	author = {Ahrends, Christine and Stevner, Angus and Pervaiz, Usama and Kringelbach, Morten L. and Vuust, Peter and Woolrich, Mark and Vidaurre, Diego},
	month = jul,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.07.28.454017},
	file = {Ahrends et al_2021_Data and model considerations for estimating time-varying functional.pdf:/Users/tito/Zotero/storage/FACI3TX2/Ahrends et al_2021_Data and model considerations for estimating time-varying functional.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/38GI73MH/2021.07.28.html:text/html},
}

@article{keramati_homeostatic_2014,
	title = {Homeostatic reinforcement learning for integrating reward collection and physiological stability},
	volume = {3},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.04811},
	doi = {10.7554/eLife.04811},
	abstract = {Efficient regulation of internal homeostasis and defending it against perturbations requires adaptive behavioral strategies. However, the computational principles mediating the interaction between homeostatic and associative learning processes remain undefined. Here we use a definition of primary rewards, as outcomes fulfilling physiological needs, to build a normative theory showing how learning motivated behaviors may be modulated by internal states. Within this framework, we mathematically prove that seeking rewards is equivalent to the fundamental objective of physiological stability, defining the notion of physiological rationality of behavior. We further suggest a formal basis for temporal discounting of rewards by showing that discounting motivates animals to follow the shortest path in the space of physiological variables toward the desired setpoint. We also explain how animals learn to act predictively to preclude prospective homeostatic challenges, and several other behavioral patterns. Finally, we suggest a computational role for interaction between hypothalamus and the brain reward system.},
	urldate = {2021-08-10},
	journal = {eLife},
	author = {Keramati, Mehdi and Gutkin, Boris},
	editor = {Marder, Eve},
	month = dec,
	year = {2014},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {reinforcement learning, anticipatory responding, cortico-basal ganglia, homeostatic regulation, hypothalamus, temporal discounting},
	pages = {e04811},
	file = {Keramati_Gutkin_2014_Homeostatic reinforcement learning for integrating reward collection and.pdf:/Users/tito/Zotero/storage/EQPBWBLV/Keramati_Gutkin_2014_Homeostatic reinforcement learning for integrating reward collection and.pdf:application/pdf},
}

@article{keramati_homeostatic_2014-1,
	title = {Homeostatic reinforcement learning for integrating reward collection and physiological stability},
	volume = {3},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.04811},
	doi = {10.7554/eLife.04811},
	abstract = {Efficient regulation of internal homeostasis and defending it against perturbations requires adaptive behavioral strategies. However, the computational principles mediating the interaction between homeostatic and associative learning processes remain undefined. Here we use a definition of primary rewards, as outcomes fulfilling physiological needs, to build a normative theory showing how learning motivated behaviors may be modulated by internal states. Within this framework, we mathematically prove that seeking rewards is equivalent to the fundamental objective of physiological stability, defining the notion of physiological rationality of behavior. We further suggest a formal basis for temporal discounting of rewards by showing that discounting motivates animals to follow the shortest path in the space of physiological variables toward the desired setpoint. We also explain how animals learn to act predictively to preclude prospective homeostatic challenges, and several other behavioral patterns. Finally, we suggest a computational role for interaction between hypothalamus and the brain reward system.},
	urldate = {2021-08-10},
	journal = {eLife},
	author = {Keramati, Mehdi and Gutkin, Boris},
	editor = {Marder, Eve},
	month = dec,
	year = {2014},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {reinforcement learning, anticipatory responding, cortico-basal ganglia, homeostatic regulation, hypothalamus, temporal discounting},
	pages = {e04811},
	file = {Keramati_Gutkin_2014_Homeostatic reinforcement learning for integrating reward collection and.pdf:/Users/tito/Zotero/storage/T4IY8ZE9/Keramati_Gutkin_2014_Homeostatic reinforcement learning for integrating reward collection and.pdf:application/pdf},
}

@article{alstott_powerlaw_2014,
	title = {powerlaw: {A} {Python} {Package} for {Analysis} of {Heavy}-{Tailed} {Distributions}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {powerlaw},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0085777},
	doi = {10.1371/journal.pone.0085777},
	abstract = {Power laws are theoretically interesting probability distributions that are also frequently used to describe empirical data. In recent years, effective statistical methods for fitting power laws have been developed, but appropriate use of these techniques requires significant programming and statistical insight. In order to greatly decrease the barriers to using good statistical methods for fitting power law distributions, we developed the powerlaw Python package. This software package provides easy commands for basic fitting and statistical analysis of distributions. Notably, it also seeks to support a variety of user needs by being exhaustive in the options available to the user. The source code is publicly available and easily extensible.},
	language = {en},
	number = {1},
	urldate = {2021-08-11},
	journal = {PLOS ONE},
	author = {Alstott, Jeff and Bullmore, Ed and Plenz, Dietmar},
	month = jan,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Semantics, Neurons, Simulation and modeling, Data visualization, Probability distribution, Software tools, Source code, Statistical distributions},
	pages = {e85777},
	file = {Alstott et al_2014_powerlaw.pdf:/Users/tito/Zotero/storage/5C7Q5KUB/Alstott et al_2014_powerlaw.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/KKZBTU5U/article.html:text/html},
}

@article{glorot_understanding_nodate,
	title = {Understanding the difﬁculty of training deep feedforward neural networks},
	abstract = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We ﬁrst observe the inﬂuence of the non-linear activations functions. We ﬁnd that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we ﬁnd that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We ﬁnd that a new non-linearity that saturates less can often be beneﬁcial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difﬁcult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
	language = {en},
	author = {Glorot, Xavier and Bengio, Yoshua},
	pages = {8},
	file = {Glorot and Bengio - Understanding the difﬁculty of training deep feedf.pdf:/Users/tito/Zotero/storage/EJUJLU5Q/Glorot and Bengio - Understanding the difﬁculty of training deep feedf.pdf:application/pdf},
}

@article{hanin_finite_2019,
	title = {Finite {Depth} and {Width} {Corrections} to the {Neural} {Tangent} {Kernel}},
	url = {http://arxiv.org/abs/1909.05989},
	abstract = {We prove the precise scaling, at finite depth and width, for the mean and variance of the neural tangent kernel (NTK) in a randomly initialized ReLU network. The standard deviation is exponential in the ratio of network depth to width. Thus, even in the limit of infinite overparameterization, the NTK is not deterministic if depth and width simultaneously tend to infinity. Moreover, we prove that for such deep and wide networks, the NTK has a non-trivial evolution during training by showing that the mean of its first SGD update is also exponential in the ratio of network depth to width. This is sharp contrast to the regime where depth is fixed and network width is very large. Our results suggest that, unlike relatively shallow and wide networks, deep and wide ReLU networks are capable of learning data-dependent features even in the so-called lazy training regime.},
	urldate = {2021-08-13},
	journal = {arXiv:1909.05989 [cs, math, stat]},
	author = {Hanin, Boris and Nica, Mihai},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.05989},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Probability},
	annote = {Comment: 27 pages, 2 figures, comments welcome},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/79I7IPMN/1909.html:text/html;Hanin_Nica_2019_Finite Depth and Width Corrections to the Neural Tangent Kernel.pdf:/Users/tito/Zotero/storage/ZU6BY7RI/Hanin_Nica_2019_Finite Depth and Width Corrections to the Neural Tangent Kernel.pdf:application/pdf},
}

@inproceedings{xiao_disentangling_2020,
	title = {Disentangling {Trainability} and {Generalization} in {Deep} {Neural} {Networks}},
	url = {http://proceedings.mlr.press/v119/xiao20b.html},
	language = {en},
	urldate = {2021-08-13},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Xiao, Lechao and Pennington, Jeffrey and Schoenholz, Samuel},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {10462--10472},
	file = {Supplementary PDF:/Users/tito/Zotero/storage/ZTVPW4D3/Xiao et al. - 2020 - Disentangling Trainability and Generalization in D.pdf:application/pdf;Xiao et al_2020_Disentangling Trainability and Generalization in Deep Neural Networks.pdf:/Users/tito/Zotero/storage/P2U37UHT/Xiao et al_2020_Disentangling Trainability and Generalization in Deep Neural Networks.pdf:application/pdf},
}

@techreport{karimi-rouzbahani_caveats_2021,
	title = {Caveats and nuances of model-based and model-free representational connectivity analysis},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.10.455841v1},
	abstract = {Brain connectivity analyses have conventionally relied on statistical relationship between one-dimensional summaries of activation in different brain areas. However, summarising activation patterns within each area to a single dimension ignores the potential statistical dependencies between their multi-dimensional activity patterns. Representational Connectivity Analyses (RCA) is a method that quantifies the relationship between multi-dimensional patterns of activity without reducing the dimensionality of the data. We consider two variants of RCA. In model-free RCA, the goal is to quantify the shared information for two brain regions. In model-based RCA, one tests whether two regions have shared information about a specific aspect of the stimuli/task, as defined by a model. However, this is a new approach and the potential caveats of model-free and model-based RCA are still understudied. We first explain how model-based RCA detects connectivity through the lens of models, and then present three scenarios where model-based and model-free RCA give discrepant results. These conflicting results complicate the interpretation of functional connectivity. We highlight the challenges in three scenarios: complex intermediate models, common patterns across regions and transformation of representational structure across brain regions. The paper is accompanied by scripts that reproduce the results. In each case, we suggest potential ways to mitigate the difficulties caused by inconsistent results. The results of this study shed light on some understudied aspects of RCA, and allow researchers to use the method more effectively.},
	language = {en},
	urldate = {2021-08-16},
	author = {Karimi-Rouzbahani, Hamid and Woolgar, Alexandra and Henson, Richard and Nili, Hamed},
	month = aug,
	year = {2021},
	doi = {10.1101/2021.08.10.455841},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.08.10.455841},
	file = {Karimi-Rouzbahani et al_2021_Caveats and nuances of model-based and model-free representational connectivity.pdf:/Users/tito/Zotero/storage/5C7ZLM7D/Karimi-Rouzbahani et al_2021_Caveats and nuances of model-based and model-free representational connectivity.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FACXD9PT/2021.08.10.html:text/html},
}

@article{roskies_representational_2021,
	title = {Representational similarity analysis in neuroimaging: proxy vehicles and provisional representations},
	issn = {1573-0964},
	shorttitle = {Representational similarity analysis in neuroimaging},
	url = {https://doi.org/10.1007/s11229-021-03052-4},
	doi = {10.1007/s11229-021-03052-4},
	abstract = {Functional neuroimaging is sometimes criticized as showing only where in the brain things happen, not how they happen, and thus being unable to inform us about questions of mental and neural representation. Novel analytical methods increasingly make clear that imaging can give us access to constructs of interest to psychology. In this paper I argue that neuroimaging can give us an important, if limited, window into the large-scale structure of neural representation. I describe Representational Similarity Analysis, increasingly used in neuroimaging studies, and lay out desiderata for representations in general. In that context I discuss what RSA can and cannot tell us about neural representation. I compare RSA with fMRI to a different experimental paradigm which has been embraced as being indicative of representation in psychology, and argue that it compares favorably.},
	language = {en},
	urldate = {2021-08-16},
	journal = {Synthese},
	author = {Roskies, Adina L.},
	month = feb,
	year = {2021},
	file = {Roskies_2021_Representational similarity analysis in neuroimaging.pdf:/Users/tito/Zotero/storage/A4JL8VB2/Roskies_2021_Representational similarity analysis in neuroimaging.pdf:application/pdf},
}

@article{gessell_multivariate_nodate,
	title = {Multivariate {Pattern} {Analysis} and the {Search} for {Neural} {Representations}},
	journal = {Synthese},
	author = {Gessell, Bryce and Geib, Benjamin and Brigard, Felipe De},
	file = {Gessell et al_Multivariate Pattern Analysis and the Search for Neural Representations.pdf:/Users/tito/Zotero/storage/8YJV3Z9Z/Gessell et al_Multivariate Pattern Analysis and the Search for Neural Representations.pdf:application/pdf},
}

@article{piray_linear_2021,
	title = {Linear reinforcement learning in planning, grid fields, and cognitive control},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-25123-3},
	doi = {10.1038/s41467-021-25123-3},
	abstract = {It is thought that the brain’s judicious reuse of previous computation underlies our ability to plan flexibly, but also that inappropriate reuse gives rise to inflexibilities like habits and compulsion. Yet we lack a complete, realistic account of either. Building on control engineering, here we introduce a model for decision making in the brain that reuses a temporally abstracted map of future events to enable biologically-realistic, flexible choice at the expense of specific, quantifiable biases. It replaces the classic nonlinear, model-based optimization with a linear approximation that softly maximizes around (and is weakly biased toward) a default policy. This solution demonstrates connections between seemingly disparate phenomena across behavioral neuroscience, notably flexible replanning with biases and cognitive control. It also provides insight into how the brain can represent maps of long-distance contingencies stably and componentially, as in entorhinal response fields, and exploit them to guide choice even under changing goals.},
	language = {en},
	number = {1},
	urldate = {2021-08-16},
	journal = {Nat Commun},
	author = {Piray, Payam and Daw, Nathaniel D.},
	month = aug,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Decision;Learning algorithms
Subject\_term\_id: decision;learning-algorithms},
	pages = {4942},
	file = {Piray_Daw_2021_Linear reinforcement learning in planning, grid fields, and cognitive control.pdf:/Users/tito/Zotero/storage/P6YQ5EHQ/Piray_Daw_2021_Linear reinforcement learning in planning, grid fields, and cognitive control.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Y7IAFAQK/s41467-021-25123-3.html:text/html},
}

@article{ji_qunex_nodate,
	title = {{QuNex} -- {A} {Scalable} {Platform} for {Integrative} {Multi}-{Modal} {Neuroimaging} {Data} {Processing} and {Analysis}},
	journal = {In prep.},
	author = {Ji, Jie Lisa and Demsar, J and Fonteneau, C and Warrington, Shaun and Tamayo, Z and Kraljiç, A and Matkovic, A and Purg, N and Helmer, Markus and Sotiropoulos, S N and Murray, John D and Anticevic, Alan and Repovs, Grega},
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {http://proceedings.mlr.press/v9/glorot10a.html},
	language = {en},
	urldate = {2021-08-18},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {Glorot, Xavier and Bengio, Yoshua},
	month = mar,
	year = {2010},
	note = {ISSN: 1938-7228},
	pages = {249--256},
	file = {Glorot_Bengio_2010_Understanding the difficulty of training deep feedforward neural networks.pdf:/Users/tito/Zotero/storage/XAX7MRGK/Glorot_Bengio_2010_Understanding the difficulty of training deep feedforward neural networks.pdf:application/pdf},
}

@article{saxe_exact_2014,
	title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	url = {http://arxiv.org/abs/1312.6120},
	abstract = {Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.},
	urldate = {2021-08-18},
	journal = {arXiv:1312.6120 [cond-mat, q-bio, stat]},
	author = {Saxe, Andrew M. and McClelland, James L. and Ganguli, Surya},
	month = feb,
	year = {2014},
	note = {arXiv: 1312.6120},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Condensed Matter - Disordered Systems and Neural Networks},
	annote = {Comment: Submission to ICLR2014. Revised based on reviewer feedback},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/VRC8WY63/1312.html:text/html;Saxe et al_2014_Exact solutions to the nonlinear dynamics of learning in deep linear neural.pdf:/Users/tito/Zotero/storage/XM782A24/Saxe et al_2014_Exact solutions to the nonlinear dynamics of learning in deep linear neural.pdf:application/pdf},
}

@article{golesorkhi_temporal_2021,
	title = {Temporal hierarchy of intrinsic neural timescales converges with spatial core-periphery organization},
	volume = {4},
	copyright = {2021 The Author(s)},
	issn = {2399-3642},
	url = {https://www.nature.com/articles/s42003-021-01785-z},
	doi = {10.1038/s42003-021-01785-z},
	abstract = {The human cortex exhibits intrinsic neural timescales that shape a temporal hierarchy. Whether this temporal hierarchy follows the spatial hierarchy of its topography, namely the core-periphery organization, remains an open issue. Using magnetoencephalography data, we investigate intrinsic neural timescales during rest and task states; we measure the autocorrelation window in short (ACW-50) and, introducing a novel variant, long (ACW-0) windows. We demonstrate longer ACW-50 and ACW-0 in networks located at the core compared to those at the periphery with rest and task states showing a high ACW correlation. Calculating rest-task differences, i.e., subtracting the shared core-periphery organization, reveals task-specific ACW changes in distinct networks. Finally, employing kernel density estimation, machine learning, and simulation, we demonstrate that ACW-0 exhibits better prediction in classifying a region’s time window as core or periphery. Overall, our findings provide fundamental insight into how the human cortex’s temporal hierarchy converges with its spatial core-periphery hierarchy.},
	language = {en},
	number = {1},
	urldate = {2021-08-20},
	journal = {Commun Biol},
	author = {Golesorkhi, Mehrshad and Gomez-Pilar, Javier and Tumati, Shankar and Fraser, Maia and Northoff, Georg},
	month = mar,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Cognitive neuroscience;Computational neuroscience
Subject\_term\_id: cognitive-neuroscience;computational-neuroscience},
	pages = {1--14},
	file = {Golesorkhi et al_2021_Temporal hierarchy of intrinsic neural timescales converges with spatial.pdf:/Users/tito/Zotero/storage/T94KID8P/Golesorkhi et al_2021_Temporal hierarchy of intrinsic neural timescales converges with spatial.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5V48UXBG/s42003-021-01785-z.html:text/html},
}

@article{zhang_what_2021,
	title = {What have we really learned from functional connectivity in clinical populations?},
	volume = {242},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921007394},
	doi = {10.1016/j.neuroimage.2021.118466},
	abstract = {Functional connectivity (FC), or the statistical interdependence of blood-oxygen dependent level (BOLD) signals between brain regions using fMRI, has emerged as a widely used tool for probing functional abnormalities in clinical populations due to the promise of the approach across conceptual, technical, and practical levels. With an already vast and steadily accumulating neuroimaging literature on neurodevelopmental, psychiatric, and neurological diseases and disorders in which FC is a primary measure, we aim here to provide a high-level synthesis of major concepts that have arisen from FC findings in a manner that cuts across different clinical conditions and sheds light on overarching principles. We highlight that FC has allowed us to discover the ubiquity of intrinsic functional networks across virtually all brains and clarify typical patterns of neurodevelopment over the lifespan. This understanding of typical FC maturation with age has provided important benchmarks against which to evaluate divergent maturation in early life and degeneration in late life. This in turn has led to the important insight that many clinical conditions are associated with complex, distributed, network-level changes in the brain, as opposed to solely focal abnormalities. We further emphasize the important role that FC studies have played in supporting a dimensional approach to studying transdiagnostic clinical symptoms and in enhancing the multimodal characterization and prediction of the trajectory of symptom progression across conditions. We highlight the unprecedented opportunity offered by FC to probe functional abnormalities in clinical conditions where brain function could not be easily studied otherwise, such as in disorders of consciousness. Lastly, we suggest high priority areas for future research and acknowledge critical barriers associated with the use of FC methods, particularly those related to artifact removal, data denoising and feasibility in clinical contexts.},
	language = {en},
	urldate = {2021-08-20},
	journal = {NeuroImage},
	author = {Zhang, Jiahe and Kucyi, Aaron and Raya, Jovicarole and Nielsen, Ashley N. and Nomi, Jason S. and Damoiseaux, Jessica S. and Greene, Deanna J. and Horovitz, Silvina G. and Uddin, Lucina Q. and Whitfield-Gabrieli, Susan},
	month = nov,
	year = {2021},
	keywords = {Brain networks, Resting state fMRI, Connectomics, Intrinsic functional connectivity, Mental health},
	pages = {118466},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/KGW8WA9N/S1053811921007394.html:text/html;Zhang et al_2021_What have we really learned from functional connectivity in clinical populations.pdf:/Users/tito/Zotero/storage/89EBGUK9/Zhang et al_2021_What have we really learned from functional connectivity in clinical populations.pdf:application/pdf},
}

@article{bhandari_just_2018,
	title = {Just above {Chance}: {Is} {It} {Harder} to {Decode} {Information} from {Prefrontal} {Cortex} {Hemodynamic} {Activity} {Patterns}?},
	volume = {30},
	issn = {0898-929X},
	shorttitle = {Just above {Chance}},
	url = {https://doi.org/10.1162/jocn_a_01291},
	doi = {10.1162/jocn_a_01291},
	abstract = {The prefrontal cortex (PFC) is central to flexible, goal-directed cognition, and understanding its representational code is an important problem in cognitive neuroscience. In humans, multivariate pattern analysis (MVPA) of fMRI blood oxygenation level-dependent (BOLD) measurements has emerged as an important approach for studying neural representations. Many previous studies have implicitly assumed that MVPA of fMRI BOLD is just as effective in decoding information encoded in PFC neural activity as it is in visual cortex. However, MVPA studies of PFC have had mixed success. Here we estimate the base rate of decoding information from PFC BOLD activity patterns from a meta-analysis of published MVPA studies. We show that PFC has a significantly lower base rate (55.4\%) than visual areas in occipital (66.6\%) and temporal (71.0\%) cortices and one that is close to chance levels. Our results have implications for the design and interpretation of MVPA studies of PFC and raise important questions about its functional organization.},
	number = {10},
	urldate = {2021-08-23},
	journal = {Journal of Cognitive Neuroscience},
	author = {Bhandari, Apoorva and Gagne, Christopher and Badre, David},
	month = oct,
	year = {2018},
	pages = {1473--1498},
	file = {Bhandari et al_2018_Just above Chance.pdf:/Users/tito/Zotero/storage/N3VVGBEC/Bhandari et al_2018_Just above Chance.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZKVKNXA2/Just-above-Chance-Is-It-Harder-to-Decode.html:text/html},
}

@article{stringer_high-dimensional_2019,
	title = {High-dimensional geometry of population responses in visual cortex},
	volume = {571},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1346-5},
	doi = {10.1038/s41586-019-1346-5},
	abstract = {A neuronal population encodes information most efficiently when its stimulus responses are high-dimensional and uncorrelated, and most robustly when they are lower-dimensional and correlated. Here we analysed the dimensionality of the encoding of natural images by large populations of neurons in the visual cortex of awake mice. The evoked population activity was high-dimensional, and correlations obeyed an unexpected power law: the nth principal component variance scaled as 1/n. This scaling was not inherited from the power law spectrum of natural images, because it persisted after stimulus whitening. We proved mathematically that if the variance spectrum was to decay more slowly then the population code could not be smooth, allowing small changes in input to dominate population activity. The theory also predicts larger power-law exponents for lower-dimensional stimulus ensembles, which we validated experimentally. These results suggest that coding smoothness may represent a fundamental constraint that determines correlations in neural population codes.},
	language = {en},
	number = {7765},
	urldate = {2021-08-23},
	journal = {Nature},
	author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
	month = jul,
	year = {2019},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 7765
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Neural encoding;Striate cortex
Subject\_term\_id: neural-encoding;striate-cortex},
	pages = {361--365},
	file = {Snapshot:/Users/tito/Zotero/storage/59KFXGBX/s41586-019-1346-5.html:text/html;Stringer et al_2019_High-dimensional geometry of population responses in visual cortex.pdf:/Users/tito/Zotero/storage/EUTPJ8VW/Stringer et al_2019_High-dimensional geometry of population responses in visual cortex.pdf:application/pdf},
}

@techreport{pinotsis_beyond_2021,
	title = {Beyond dimension reduction: {Stable} electric fields emerge from and allow representational drift},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Beyond dimension reduction},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.22.457247v1},
	abstract = {It is known that the exact neurons maintaining a given memory (the neural ensemble) change from trial to trial. This raises the question of how the brain achieves stability in the face of this representational drift. Here, we demonstrate that this stability emerges at the level of the electric fields that arise from neural activity. The electric fields, in turn, can act as 'guard rails' that funnel higher dimensional variable neural activity along stable lower dimensional routes. We show that electric fields carry information about working memory content. We obtained the latent space associated with each memory. We then confirmed the stability of the electric field by mapping the latent space to different cortical patches (that comprise a neural ensemble) and reconstructing information flow between patches. Stable electric fields can allow latent states to be transferred between brain areas, in accord with modern engram theory.},
	language = {en},
	urldate = {2021-08-23},
	author = {Pinotsis, Dimitris and Miller, Earl K.},
	month = aug,
	year = {2021},
	doi = {10.1101/2021.08.22.457247},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.08.22.457247},
	file = {Pinotsis_Miller_2021_Beyond dimension reduction.pdf:/Users/tito/Zotero/storage/L9C83PID/Pinotsis_Miller_2021_Beyond dimension reduction.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ADRBBF26/2021.08.22.html:text/html},
}

@article{basti_multi-dimensional_2020,
	title = {Multi-dimensional connectivity: a conceptual and mathematical review},
	volume = {221},
	issn = {1053-8119},
	shorttitle = {Multi-dimensional connectivity},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920306650},
	doi = {10.1016/j.neuroimage.2020.117179},
	abstract = {The estimation of functional connectivity between regions of the brain, for example based on statistical dependencies between the time series of activity in each region, has become increasingly important in neuroimaging. Typically, multiple time series (e.g. from each voxel in fMRI data) are first reduced to a single time series that summarises the activity in a region of interest, e.g. by averaging across voxels or by taking the first principal component; an approach we call one-dimensional connectivity. However, this summary approach ignores potential multi-dimensional connectivity between two regions, and a number of recent methods have been proposed to capture such complex dependencies. Here we review the most common multi-dimensional connectivity methods, from an intuitive perspective, from a formal (mathematical) point of view, and through a number of simulated and real (fMRI and MEG) data examples that illustrate the strengths and weaknesses of each method. The paper is accompanied with both functions and scripts, which implement each method and reproduce all the examples.},
	language = {en},
	urldate = {2021-08-23},
	journal = {NeuroImage},
	author = {Basti, Alessio and Nili, Hamed and Hauk, Olaf and Marzetti, Laura and Henson, Richard N.},
	month = nov,
	year = {2020},
	pages = {117179},
	file = {Basti et al_2020_Multi-dimensional connectivity.pdf:/Users/tito/Zotero/storage/B4729DZT/Basti et al_2020_Multi-dimensional connectivity.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/JWP3HWLD/S1053811920306650.html:text/html},
}

@article{bryce_brain_2021,
	title = {Brain parcellation selection: {An} overlooked decision point with meaningful effects on individual differences in resting-state functional connectivity},
	volume = {243},
	issn = {1053-8119},
	shorttitle = {Brain parcellation selection},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921007606},
	doi = {10.1016/j.neuroimage.2021.118487},
	abstract = {Over the past decade extensive research has examined the segregation of the human brain into large-scale functional networks. The resulting network maps, i.e. parcellations, are now commonly used for the a priori identification of functional networks. However, the use of these parcellations, particularly in developmental and clinical samples, hinges on four fundamental assumptions: (1) the various parcellations are equally able to recover the networks of interest; (2) adult-derived parcellations well represent the networks in children's brains; (3) network properties, such as within-network connectivity, are reliably measured across parcellations; and (4) parcellation selection does not impact the results with regard to individual differences in given network properties. In the present study we examined these assumptions using eight common parcellation schemes in two independent developmental samples. We found that the parcellations are equally able to capture networks of interest in both children and adults. However, networks bearing the same name across parcellations (e.g., default network) do not produce reliable within-network measures of functional connectivity. Critically, parcellation selection significantly impacted the magnitude of associations of functional connectivity with age, poverty, and cognitive ability, producing meaningful differences in interpretation of individual differences in functional connectivity based on parcellation choice. Our findings suggest that work employing parcellations may benefit from the use of multiple schemes to confirm the robustness and generalizability of results. Furthermore, researchers looking to gain insight into functional networks may benefit from employing more nuanced network identification approaches such as using densely-sampled data to produce individual-derived network parcellations. A transition towards precision neuroscience will provide new avenues in the characterization of functional brain organization across development and within clinical populations.},
	language = {en},
	urldate = {2021-08-24},
	journal = {NeuroImage},
	author = {Bryce, Nessa V. and Flournoy, John C. and Guassi Moreira, João F. and Rosen, Maya L. and Sambook, Kelly A. and Mair, Patrick and McLaughlin, Katie A.},
	month = nov,
	year = {2021},
	keywords = {Resting-state functional connectivity, Development, Individual differences, Brain parcellations, Consistency, Cortical networks},
	pages = {118487},
	file = {Bryce et al_2021_Brain parcellation selection.pdf:/Users/tito/Zotero/storage/65NVRXQT/Bryce et al_2021_Brain parcellation selection.pdf:application/pdf},
}

@article{tian_topographic_2020,
	title = {Topographic organization of the human subcortex unveiled with functional connectivity gradients},
	volume = {23},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-020-00711-6},
	doi = {10.1038/s41593-020-00711-6},
	abstract = {Brain atlases are fundamental to understanding the topographic organization of the human brain, yet many contemporary human atlases cover only the cerebral cortex, leaving the subcortex a terra incognita. We use functional MRI (fMRI) to map the complex topographic organization of the human subcortex, revealing large-scale connectivity gradients and new areal boundaries. We unveil four scales of subcortical organization that recapitulate well-known anatomical nuclei at the coarsest scale and delineate 27 new bilateral regions at the finest. Ultrahigh field strength fMRI corroborates and extends this organizational structure, enabling the delineation of finer subdivisions of the hippocampus and the amygdala, while task-evoked fMRI reveals a subtle subcortical reorganization in response to changing cognitive demands. A new subcortical atlas is delineated, personalized to represent individual differences and used to uncover reproducible brain–behavior relationships. Linking cortical networks to subcortical regions recapitulates a task-positive to task-negative axis. This new atlas enables holistic connectome mapping and characterization of cortico–subcortical connectivity.},
	language = {en},
	number = {11},
	urldate = {2021-08-25},
	journal = {Nat Neurosci},
	author = {Tian, Ye and Margulies, Daniel S. and Breakspear, Michael and Zalesky, Andrew},
	month = nov,
	year = {2020},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 11
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Functional magnetic resonance imaging;Neural circuits
Subject\_term\_id: functional-magnetic-resonance-imaging;neural-circuit},
	pages = {1421--1432},
	file = {Snapshot:/Users/tito/Zotero/storage/JHIIQUG6/s41593-020-00711-6.html:text/html;Tian et al_2020_Topographic organization of the human subcortex unveiled with functional.pdf:/Users/tito/Zotero/storage/F2GYU8SV/Tian et al_2020_Topographic organization of the human subcortex unveiled with functional.pdf:application/pdf},
}

@article{raut_global_2021,
	title = {Global waves synchronize the brain’s functional systems with fluctuating arousal},
	volume = {7},
	copyright = {Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. https://creativecommons.org/licenses/by-nc/4.0/This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/7/30/eabf2709},
	doi = {10.1126/sciadv.abf2709},
	abstract = {We propose and empirically support a parsimonious account of intrinsic, brain-wide spatiotemporal organization arising from traveling waves linked to arousal. We hypothesize that these waves are the predominant physiological process reflected in spontaneous functional magnetic resonance imaging (fMRI) signal fluctuations. The correlation structure (“functional connectivity”) of these fluctuations recapitulates the large-scale functional organization of the brain. However, a unifying physiological account of this structure has so far been lacking. Here, using fMRI in humans, we show that ongoing arousal fluctuations are associated with global waves of activity that slowly propagate in parallel throughout the neocortex, thalamus, striatum, and cerebellum. We show that these waves can parsimoniously account for many features of spontaneous fMRI signal fluctuations, including topographically organized functional connectivity. Last, we demonstrate similar, cortex-wide propagation of neural activity measured with electrocorticography in macaques. These findings suggest that traveling waves spatiotemporally pattern brain-wide excitability in relation to arousal.
Traveling waves spatiotemporally organize brain-wide activity in synchrony with ongoing arousal fluctuations.
Traveling waves spatiotemporally organize brain-wide activity in synchrony with ongoing arousal fluctuations.},
	language = {en},
	number = {30},
	urldate = {2021-08-25},
	journal = {Science Advances},
	author = {Raut, Ryan V. and Snyder, Abraham Z. and Mitra, Anish and Yellin, Dov and Fujii, Naotaka and Malach, Rafael and Raichle, Marcus E.},
	month = jul,
	year = {2021},
	pmid = {34290088},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eabf2709},
	file = {Raut et al_2021_Global waves synchronize the brain’s functional systems with fluctuating arousal.pdf:/Users/tito/Zotero/storage/2IDJXIXT/Raut et al_2021_Global waves synchronize the brain’s functional systems with fluctuating arousal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/QQ49ARSU/eabf2709.html:text/html},
}

@article{bassett_small-world_2006,
	title = {Small-{World} {Brain} {Networks}},
	volume = {12},
	issn = {1073-8584},
	url = {https://doi.org/10.1177/1073858406293182},
	doi = {10.1177/1073858406293182},
	abstract = {Many complex networks have a small-world topology characterized by dense local clustering or cliquishness of connections between neighboring nodes yet a short path length between any (distant) pair of nodes due to the existence of relatively few long-range connections. This is an attractive model for the organization of brain anatomical and functional networks because a small-world topology can support both segregated/specialized and distributed/integrated information processing. Moreover, small-world networks are economical, tending to minimize wiring costs while supporting high dynamical complexity. The authors introduce some of the key mathematical concepts in graph theory required for small-world analysis and review how these methods have been applied to quantification of cortical connectivity matrices derived from anatomical tract-tracing studies in the macaque monkey and the cat. The evolution of small-world networks is discussed in terms of a selection pressure to deliver cost-effective information-processing systems. The authors illustrate how these techniques and concepts are increasingly being applied to the analysis of human brain functional networks derived from electroencephalography/magnetoencephalography and fMRI experiments. Finally, the authors consider the relevance of small-world models for understanding the emergence of complex behaviors and the resilience of brain systems to pathological attack by disease or aberrant development. They conclude that small-world models provide a powerful and versatile approach to understanding the structure and function of human brain systems.},
	language = {en},
	number = {6},
	urldate = {2021-08-26},
	journal = {Neuroscientist},
	author = {Bassett, Danielle Smith and Bullmore, Ed},
	month = dec,
	year = {2006},
	note = {Publisher: SAGE Publications Inc STM},
	keywords = {Graph theory, Functional magnetic resonance imaging, Small-world network, Human brain functional networks},
	pages = {512--523},
	file = {Bassett_Bullmore_2006_Small-World Brain Networks.pdf:/Users/tito/Zotero/storage/46TVVH7I/Bassett_Bullmore_2006_Small-World Brain Networks.pdf:application/pdf},
}

@article{collins_advances_2021,
	title = {Advances in modeling learning and decision-making in neuroscience},
	copyright = {2021 The Author(s), under exclusive licence to American College of Neuropsychopharmacology},
	issn = {1740-634X},
	url = {https://www.nature.com/articles/s41386-021-01126-y},
	doi = {10.1038/s41386-021-01126-y},
	abstract = {An organism’s survival depends on its ability to learn about its environment and to make adaptive decisions in the service of achieving the best possible outcomes in that environment. To study the neural circuits that support these functions, researchers have increasingly relied on models that formalize the computations required to carry them out. Here, we review the recent history of computational modeling of learning and decision-making, and how these models have been used to advance understanding of prefrontal cortex function. We discuss how such models have advanced from their origins in basic algorithms of updating and action selection to increasingly account for complexities in the cognitive processes required for learning and decision-making, and the representations over which they operate. We further discuss how a deeper understanding of the real-world complexities in these computations has shed light on the fundamental constraints on optimal behavior, and on the complex interactions between corticostriatal pathways to determine such behavior. The continuing and rapid development of these models holds great promise for understanding the mechanisms by which animals adapt to their environments, and what leads to maladaptive forms of learning and decision-making within clinical populations.},
	language = {en},
	urldate = {2021-08-27},
	journal = {Neuropsychopharmacol.},
	author = {Collins, Anne G. E. and Shenhav, Amitai},
	month = aug,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Cortex;Decision
Subject\_term\_id: cortex;decision},
	pages = {1--15},
	file = {Collins_Shenhav_2021_Advances in modeling learning and decision-making in neuroscience.pdf:/Users/tito/Zotero/storage/EREUGFQA/Collins_Shenhav_2021_Advances in modeling learning and decision-making in neuroscience.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/T9P54U3Y/s41386-021-01126-y.html:text/html},
}

@article{hsu_myths_2021,
	title = {Myths and facts about getting an academic faculty position in neuroscience},
	volume = {7},
	copyright = {Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. https://creativecommons.org/licenses/by-nc/4.0/This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {https://advances.sciencemag.org/content/7/35/eabj2604},
	doi = {10.1126/sciadv.abj2604},
	abstract = {Prior funding and/or papers in high-profile journals are not necessary to obtain a tenure-track faculty position.
Prior funding and/or papers in high-profile journals are not necessary to obtain a tenure-track faculty position.},
	language = {en},
	number = {35},
	urldate = {2021-08-30},
	journal = {Science Advances},
	author = {Hsu, Nina S. and Rezai-zadeh, K. Paul and Tennekoon, Michael S. and Korn, Stephen J.},
	month = aug,
	year = {2021},
	pmid = {34452920},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	pages = {eabj2604},
	file = {Hsu et al_2021_Myths and facts about getting an academic faculty position in neuroscience.pdf:/Users/tito/Zotero/storage/9PB8PCFP/Hsu et al_2021_Myths and facts about getting an academic faculty position in neuroscience.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/NG43GCGN/tab-pdf.html:text/html},
}

@article{ahmadian_what_2021,
	title = {What is the dynamical regime of cerebral cortex?},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627321005754},
	doi = {10.1016/j.neuron.2021.07.031},
	abstract = {Many studies have shown that the excitation and inhibition received by cortical neurons remain roughly balanced across many conditions. A key question for understanding the dynamical regime of cortex is the nature of this balancing. Theorists have shown that network dynamics can yield systematic cancellation of most of a neuron’s excitatory input by inhibition. We review a wide range of evidence pointing to this cancellation occurring in a regime in which the balance is loose, meaning that the net input remaining after cancellation of excitation and inhibition is comparable in size with the factors that cancel, rather than tight, meaning that the net input is very small relative to the canceling factors. This choice of regime has important implications for cortical functional responses, as we describe: loose balance, but not tight balance, can yield many nonlinear population behaviors seen in sensory cortical neurons, allow the presence of correlated variability, and yield decrease of that variability with increasing external stimulus drive as observed across multiple cortical areas.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Neuron},
	author = {Ahmadian, Yashar and Miller, Kenneth D.},
	month = aug,
	year = {2021},
	file = {ScienceDirect Full Text PDF:/Users/tito/Zotero/storage/DJAG9LYD/Ahmadian and Miller - 2021 - What is the dynamical regime of cerebral cortex.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/N43STD99/S0896627321005754.html:text/html},
}

@article{seleznova_analyzing_2021,
	title = {Analyzing {Finite} {Neural} {Networks}: {Can} {We} {Trust} {Neural} {Tangent} {Kernel} {Theory}?},
	shorttitle = {Analyzing {Finite} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2012.04477},
	abstract = {Neural Tangent Kernel (NTK) theory is widely used to study the dynamics of infinitely-wide deep neural networks (DNNs) under gradient descent. But do the results for infinitely-wide networks give us hints about the behavior of real finite-width ones? In this paper, we study empirically when NTK theory is valid in practice for fully-connected ReLU and sigmoid DNNs. We find out that whether a network is in the NTK regime depends on the hyperparameters of random initialization and the network's depth. In particular, NTK theory does not explain the behavior of sufficiently deep networks initialized so that their gradients explode as they propagate through the network's layers: the kernel is random at initialization and changes significantly during training in this case, contrary to NTK theory. On the other hand, in the case of vanishing gradients, DNNs are in the the NTK regime but become untrainable rapidly with depth. We also describe a framework to study generalization properties of DNNs, in particular the variance of network's output function, by means of NTK theory and discuss its limits.},
	urldate = {2021-08-31},
	journal = {arXiv:2012.04477 [cs, stat]},
	author = {Seleznova, Mariia and Kutyniok, Gitta},
	month = mar,
	year = {2021},
	note = {arXiv: 2012.04477},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tito/Zotero/storage/6DRSHMFQ/Seleznova and Kutyniok - 2021 - Analyzing Finite Neural Networks Can We Trust Neu.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/2M4C89PI/2012.html:text/html},
}

@techreport{gokcen_disentangling_2021,
	title = {Disentangling the flow of signals between populations of neurons},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.30.458230v1},
	abstract = {Technological advances have granted the ability to record from large populations of neurons across multiple brain areas. These recordings may illuminate how communication between areas contributes to brain function, yet a substantial barrier remains: How do we disentangle the concurrent, bidirectional flow of signals between two populations of neurons? We therefore propose here a novel dimensionality reduction framework: Delayed Latents Across Groups (DLAG). DLAG disentangles signals relayed in both directions; identifies how these signals are represented by each population; and characterizes how they evolve over time and trial-to-trial. We demonstrate that DLAG performs well on synthetic datasets similar in scale to current neurophysiological recordings. Then we study simultaneously recorded populations in primate visual areas V1 and V2, where DLAG reveals signatures of concurrent yet selective communication. Our framework lays the foundation for dissecting the intricate flow of signals across populations of neurons, and how this signaling contributes to cortical computation.},
	language = {en},
	urldate = {2021-09-01},
	author = {Gokcen, Evren and Jasper, Anna I. and Jo\&amp and Semedo, atildeo D. and Zandvakili, Amin and Kohn, Adam and Machens, Christian K. and Yu, Byron M.},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.08.30.458230},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.08.30.458230},
	file = {Gokcen et al_2021_Disentangling the flow of signals between populations of neurons.pdf:/Users/tito/Zotero/storage/SLJRJYS2/Gokcen et al_2021_Disentangling the flow of signals between populations of neurons.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZSTB8UYQ/2021.08.30.html:text/html},
}

@incollection{churchland_reductive_1989,
	address = {Dordrecht},
	series = {Philosophical {Studies} {Series}},
	title = {Some {Reductive} {Strategies} in {Cognitive} {Neurobiology}},
	isbn = {978-94-009-2649-3},
	url = {https://doi.org/10.1007/978-94-009-2649-3_12},
	abstract = {A powerful conception of representation and computation — drawn from recent work in the neurosciences — is here outlined. Its virtues are explained and explored in three important areas: sensory representation, sensorimotor coordination, and microphysical implementation. It constitutes a highly general conception of cognitive activity that has significant reductive potential.},
	language = {en},
	urldate = {2021-09-02},
	booktitle = {Rerepresentation: {Readings} in the {Philosophy} of {Mental} {Representation}},
	publisher = {Springer Netherlands},
	author = {Churchland, Paul M.},
	editor = {Silvers, Stuart},
	year = {1989},
	doi = {10.1007/978-94-009-2649-3_12},
	keywords = {Coordinate Transformation, Gustatory System, Reductive Strategy, State Space, Superior Colliculus},
	pages = {223--253},
	file = {Churchland_1989_Some Reductive Strategies in Cognitive Neurobiology.pdf:/Users/tito/Zotero/storage/AQUW9K37/Churchland_1989_Some Reductive Strategies in Cognitive Neurobiology.pdf:application/pdf},
}

@techreport{goudar_elucidating_2021,
	title = {Elucidating the neural mechanisms of {Learning}-to-{Learn}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.02.455707v1},
	abstract = {Learning-to-learn, a progressive acceleration of learning while solving a series of similar problems, represents a core process of knowledge acquisition that draws attention in both neuroscience and artificial intelligence. To investigate its underlying brain mechanism, we trained a recurrent neural network model on arbitrary sensorimotor mappings. The network displayed an exponential speedup in learning. The neural substrate of a schema emerges within a low-dimensional subspace of population activity. Its reuse in new problems facilitates learning by limiting connection weight changes. Since the population trajectory of a recurrent network produces behavior, learning is determined by the vector field changes. We propose a novel analysis of weight-driven vector field changes, which showed that novel stimuli in new problems can distort the schema representation. Weight changes eliminate such distortions and improve the invariance of the reused representations in future learning. The accumulation of such weight changes across problems underlies the learning-to-learn dynamics.},
	language = {en},
	urldate = {2021-09-03},
	author = {Goudar, Vishwa and Peysakhovich, Barbara and Freedman, David J. and Buffalo, Elizabeth A. and Wang, Xiao-Jing},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.09.02.455707},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.09.02.455707},
	file = {Goudar et al_2021_Elucidating the neural mechanisms of Learning-to-Learn.pdf:/Users/tito/Zotero/storage/2DHX4N3T/Goudar et al_2021_Elucidating the neural mechanisms of Learning-to-Learn.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/PC5RYBVX/2021.09.02.html:text/html},
}

@article{tsimpoukelli_multimodal_2021,
	title = {Multimodal {Few}-{Shot} {Learning} with {Frozen} {Language} {Models}},
	url = {http://arxiv.org/abs/2106.13884},
	abstract = {When trained at sufficient scale, auto-regressive language models exhibit the notable ability to learn a new language task after being prompted with just a few examples. Here, we present a simple, yet effective, approach for transferring this few-shot learning ability to a multimodal setting (vision and language). Using aligned image and caption data, we train a vision encoder to represent each image as a sequence of continuous embeddings, such that a pre-trained, frozen language model prompted with this prefix generates the appropriate caption. The resulting system is a multimodal few-shot learner, with the surprising ability to learn a variety of new tasks when conditioned on examples, represented as a sequence of multiple interleaved image and text embeddings. We demonstrate that it can rapidly learn words for new objects and novel visual categories, do visual question-answering with only a handful of examples, and make use of outside knowledge, by measuring a single model on a variety of established and new benchmarks.},
	urldate = {2021-09-03},
	journal = {arXiv:2106.13884 [cs]},
	author = {Tsimpoukelli, Maria and Menick, Jacob and Cabi, Serkan and Eslami, S. M. Ali and Vinyals, Oriol and Hill, Felix},
	month = jul,
	year = {2021},
	note = {arXiv: 2106.13884},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/E9B8YAVG/2106.html:text/html;Tsimpoukelli et al_2021_Multimodal Few-Shot Learning with Frozen Language Models.pdf:/Users/tito/Zotero/storage/5GKFQ5ER/Tsimpoukelli et al_2021_Multimodal Few-Shot Learning with Frozen Language Models.pdf:application/pdf},
}

@article{luo_architectures_2021,
	title = {Architectures of neuronal circuits},
	copyright = {Copyright © 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works},
	url = {https://www.science.org/doi/abs/10.1126/science.abg7285},
	doi = {10.1126/science.abg7285},
	abstract = {A review explains that the brain’s cortical and subcortical neuronal circuits show general connectivity features.},
	language = {EN},
	urldate = {2021-09-03},
	journal = {Science},
	author = {Luo, Liqun},
	month = sep,
	year = {2021},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Luo_2021_Architectures of neuronal circuits.pdf:/Users/tito/Zotero/storage/DA93VLIH/Luo_2021_Architectures of neuronal circuits.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/RPBYXWAB/science.html:text/html},
}

@article{ahmed_optogenetic_2021,
	title = {Optogenetic study of central medial and paraventricular thalamic projections to the basolateral amygdala},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/abs/10.1152/jn.00253.2021},
	doi = {10.1152/jn.00253.2021},
	abstract = {The central medial (CMT) and paraventricular (PVT) thalamic nuclei project strongly to the basolateral amygdala (BL). Similarities between the responsiveness of CMT, PVT, and BL neurons suggest that these nuclei strongly influence BL activity. Supporting this possibility, an electron microscopic study reported that in contrast with other extrinsic afferents, CMT and PVT axon terminals form very few synapses with BL interneurons. However, since limited sampling is a concern in electron microscopic studies, the present investigation was undertaken to compare the impact of CMT and PVT thalamic inputs on principal and local-circuit BL neurons using optogenetic methods and whole-cell recordings in vitro. Optogenetic stimulation of CMT and PVT axons elicited glutamatergic EPSPs or EPSCs in principal cells and interneurons, but they generally had a longer latency in interneurons. Moreover, after blockade of polysynaptic interactions with tetrodotoxin (TTX), a lower proportion of interneurons (50\%) than principal cells (90\%) remained responsive to CMT and PVT inputs. While the presence of TTX-resistant responses in some interneurons indicates that CMT and PVT inputs directly contact some local-circuit cells, their lower incidence and amplitude after TTX suggest that CMT and PVT inputs form fewer synapses with them than with principal BL cells. Together, these results indicate that CMT and PVT inputs mainly contact principal BL neurons such that when CMT or PVT neurons fire, limited feed-forward inhibition counters their excitatory influence over principal BL cells. However, CMT and PVT axons can also recruit interneurons indirectly, via the activation of principal cells, thereby generating feedback inhibition.},
	urldate = {2021-09-07},
	journal = {Journal of Neurophysiology},
	author = {Ahmed, Nowrin and Headley, Drew B and Pare, Denis},
	month = sep,
	year = {2021},
	note = {Publisher: American Physiological Society},
	keywords = {anxiety, thalamus, amygdala, fear},
}

@inproceedings{dvornek_learning_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Learning {Generalizable} {Recurrent} {Neural} {Networks} from {Small} {Task}-{fMRI} {Datasets}},
	isbn = {978-3-030-00931-1},
	doi = {10.1007/978-3-030-00931-1_38},
	abstract = {Deep learning has become the new state-of-the-art for many problems in image analysis. However, large datasets are often required for such deep networks to learn effectively. This poses a difficult challenge for many medical image analysis problems in which only a small number of subjects are available, e.g., patients undergoing a new treatment. In this work, we propose a number of approaches for learning generalizable recurrent neural networks from smaller task-fMRI datasets: (1) a resampling method for ROI-based fMRI analysis to create augmented data; (2) inclusion of a small number of non-imaging variables to provide subject-specific initialization of the recurrent neural network; and (3) selection of the most generalizable model from multiple reinitialized training runs using criteria based on only training loss. Using cross-validation to assess model performance, we demonstrate the effectiveness of the proposed methods to train recurrent neural networks from small datasets to predict treatment outcome for children with autism spectrum disorder (𝑁=21N=21N=21) and classify autistic vs. typical control subjects (𝑁=40N=40N=40) from task-fMRI scans.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2018},
	publisher = {Springer International Publishing},
	author = {Dvornek, Nicha C. and Yang, Daniel and Ventola, Pamela and Duncan, James S.},
	editor = {Frangi, Alejandro F. and Schnabel, Julia A. and Davatzikos, Christos and Alberola-López, Carlos and Fichtinger, Gabor},
	year = {2018},
	pages = {329--337},
	file = {Dvornek et al_2018_Learning Generalizable Recurrent Neural Networks from Small Task-fMRI Datasets.pdf:/Users/tito/Zotero/storage/PBBCNF5N/Dvornek et al_2018_Learning Generalizable Recurrent Neural Networks from Small Task-fMRI Datasets.pdf:application/pdf},
}

@article{stroud_motor_2018,
	title = {Motor primitives in space and time via targeted gain modulation in cortical networks},
	volume = {21},
	copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0276-0},
	doi = {10.1038/s41593-018-0276-0},
	abstract = {Motor cortex (M1) exhibits a rich repertoire of neuronal activities to support the generation of complex movements. Although recent neuronal-network models capture many qualitative aspects of M1 dynamics, they can generate only a few distinct movements. Additionally, it is unclear how M1 efficiently controls movements over a wide range of shapes and speeds. We demonstrate that modulation of neuronal input–output gains in recurrent neuronal-network models with a fixed architecture can dramatically reorganize neuronal activity and thus downstream muscle outputs. Consistent with the observation of diffuse neuromodulatory projections to M1, a relatively small number of modulatory control units provide sufficient flexibility to adjust high-dimensional network activity using a simple reward-based learning rule. Furthermore, it is possible to assemble novel movements from previously learned primitives, and one can separately change movement speed while preserving movement shape. Our results provide a new perspective on the role of modulatory systems in controlling recurrent cortical activity.},
	language = {en},
	number = {12},
	urldate = {2021-09-13},
	journal = {Nat Neurosci},
	author = {Stroud, Jake P. and Porter, Mason A. and Hennequin, Guillaume and Vogels, Tim P.},
	month = dec,
	year = {2018},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 12
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Dynamical systems;Motor cortex;Network models;Neural circuits
Subject\_term\_id: dynamical-systems;motor-cortex;network-models;neural-circuit},
	pages = {1774--1783},
	file = {Snapshot:/Users/tito/Zotero/storage/GE93IS3Z/s41593-018-0276-0.html:text/html;Stroud et al_2018_Motor primitives in space and time via targeted gain modulation in cortical.pdf:/Users/tito/Zotero/storage/2IW6UV5S/Stroud et al_2018_Motor primitives in space and time via targeted gain modulation in cortical.pdf:application/pdf},
}

@article{kriegeskorte_neural_2021-1,
	title = {Neural tuning and representational geometry},
	copyright = {2021 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-021-00502-3},
	doi = {10.1038/s41583-021-00502-3},
	abstract = {A central goal of neuroscience is to understand the representations formed by brain activity patterns and their connection to behaviour. The classic approach is to investigate how individual neurons encode stimuli and how their tuning determines the fidelity of the neural representation. Tuning analyses often use the Fisher information to characterize the sensitivity of neural responses to small changes of the stimulus. In recent decades, measurements of large populations of neurons have motivated a complementary approach, which focuses on the information available to linear decoders. The decodable information is captured by the geometry of the representational patterns in the multivariate response space. Here we review neural tuning and representational geometry with the goal of clarifying the relationship between them. The tuning induces the geometry, but different sets of tuned neurons can induce the same geometry. The geometry determines the Fisher information, the mutual information and the behavioural performance of an ideal observer in a range of psychophysical tasks. We argue that future studies can benefit from considering both tuning and geometry to understand neural codes and reveal the connections between stimuli, brain activity and behaviour.},
	language = {en},
	urldate = {2021-09-15},
	journal = {Nat Rev Neurosci},
	author = {Kriegeskorte, Nikolaus and Wei, Xue-Xin},
	month = sep,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Neural decoding;Neural encoding
Subject\_term\_id: neural-decoding;neural-encoding},
	pages = {1--16},
	file = {Kriegeskorte_Wei_2021_Neural tuning and representational geometry.pdf:/Users/tito/Zotero/storage/HR6A66ZI/Kriegeskorte_Wei_2021_Neural tuning and representational geometry.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/JZBZNSPW/s41583-021-00502-3.html:text/html},
}

@techreport{qin_coordinated_2021,
	title = {Coordinated drift of receptive fields during noisy representation learning},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.30.458264v1},
	abstract = {Long-term memories and learned behavior are conventionally associated with stable neuronal representations. However, recent experiments showed that neural population codes in many brain areas continuously change even when animals have fully learned and stably perform their tasks. This representational “drift” naturally leads to questions about its causes, dynamics, and functions. Here, we explore the hypothesis that neural representations optimize a representational objective with a degenerate solution space, and noisy synaptic updates drive the network to explore this (near-)optimal space causing representational drift. We illustrate this idea in simple, biologically plausible Hebbian/anti-Hebbian network models of representation learning, which optimize similarity matching objectives, and, when neural outputs are constrained to be nonnegative, learn localized receptive fields (RFs) that tile the stimulus manifold. We find that the drifting RFs of individual neurons can be characterized by a coordinated random walk, with the effective diffusion constants depending on various parameters such as learning rate, noise amplitude, and input statistics. Despite such drift, the representational similarity of population codes is stable over time. Our model recapitulates recent experimental observations in hippocampus and posterior parietal cortex, and makes testable predictions that can be probed in future experiments.},
	language = {en},
	urldate = {2021-09-16},
	author = {Qin, Shanshan and Farashahi, Shiva and Lipshutz, David and Sengupta, Anirvan M. and Chklovskii, Dmitri B. and Pehlevan, Cengiz},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.08.30.458264},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.08.30.458264},
	file = {Qin et al_2021_Coordinated drift of receptive fields during noisy representation learning.pdf:/Users/tito/Zotero/storage/LS4I7AZL/Qin et al_2021_Coordinated drift of receptive fields during noisy representation learning.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6VWJ7Z3Q/2021.08.30.html:text/html},
}

@misc{noauthor_retinal_nodate,
	title = {Retinal waves prime visual motion detection by simulating future optic flow},
	url = {https://www.science.org/doi/10.1126/science.abd0830},
	urldate = {2021-09-22},
	file = {Retinal waves prime visual motion detection by simulating future optic flow:/Users/tito/Zotero/storage/IRUHFZRZ/science.html:text/html},
}

@article{uehara_rapidly_2021,
	title = {Rapidly spreading seizures arise from large-scale functional brain networks in focal epilepsy},
	volume = {237},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811921003815},
	doi = {10.1016/j.neuroimage.2021.118104},
	language = {en},
	urldate = {2021-09-22},
	journal = {NeuroImage},
	author = {Uehara, Taira and Shigeto, Hiroshi and Mukaino, Takahiko and Yokoyama, Jun and Okadome, Toshiki and Yamasaki, Ryo and Ogata, Katsuya and Mukae, Nobutaka and Sakata, Ayumi and Tobimatsu, Shozo and Kira, Jun-ichi},
	month = aug,
	year = {2021},
	pages = {118104},
	file = {Uehara et al. - 2021 - Rapidly spreading seizures arise from large-scale .pdf:/Users/tito/Zotero/storage/C3PLAIBX/Uehara et al. - 2021 - Rapidly spreading seizures arise from large-scale .pdf:application/pdf},
}

@article{russin_deep_2020,
	title = {{DEEP} {LEARNING} {NEEDS} {A} {PREFRONTAL} {CORTEX}},
	url = {https://baicsworkshop.github.io/pdf/BAICS_10.pdf},
	abstract = {Research seeking to build artificial systems capable of reproducing elements of human intelligence may benefit from a deeper consideration of the architecture and learning mechanisms of the human brain. In this brief review, we note a connection between many current challenges facing artificial intelligence and the functions of a particular brain area —the prefrontal cortex (PFC). This brain area is known to be involved in executive functions such as reasoning, rule-learning, deliberate or controlled processing, and abstract planning. Motivated by the hypothesis that these functions provide a form of out-of-distribution robustness currently not available in state-of-the-art AI systems, we elaborate on this connection and highlight some computational principles thought to be at work in PFC, with the goal of enhancing the synergy between neuroscience and machine learning.},
	language = {en},
	author = {Russin, Jacob and O’Reilly, Randall C and Bengio, Yoshua},
	year = {2020},
	pages = {11},
	file = {Russin et al. - 2020 - DEEP LEARNING NEEDS A PREFRONTAL CORTEX.pdf:/Users/tito/Zotero/storage/8K7HS6JC/Russin et al. - 2020 - DEEP LEARNING NEEDS A PREFRONTAL CORTEX.pdf:application/pdf},
}

@article{grasso_causal_2021,
	title = {Causal reductionism and causal structures},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-021-00911-8},
	doi = {10.1038/s41593-021-00911-8},
	abstract = {Causal reductionism is the widespread assumption that there is no room for additional causes once we have accounted for all elementary mechanisms within a system. Due to its intuitive appeal, causal reductionism is prevalent in neuroscience: once all neurons have been caused to fire or not to fire, it seems that causally there is nothing left to be accounted for. Here, we argue that these reductionist intuitions are based on an implicit, unexamined notion of causation that conflates causation with prediction. By means of a simple model organism, we demonstrate that causal reductionism cannot provide a complete and coherent account of ‘what caused what’. To that end, we outline an explicit, operational approach to analyzing causal structures.},
	language = {en},
	urldate = {2021-09-24},
	journal = {Nat Neurosci},
	author = {Grasso, Matteo and Albantakis, Larissa and Lang, Jonathan P. and Tononi, Giulio},
	month = sep,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Cognitive neuroscience;Emergence
Subject\_term\_id: cognitive-neuroscience;emergence},
	pages = {1--8},
	file = {Full Text PDF:/Users/tito/Zotero/storage/B4IHVB6E/Grasso et al. - 2021 - Causal reductionism and causal structures.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/4CDLIVWH/s41593-021-00911-8.html:text/html},
}

@article{zilio_are_2021,
	title = {Are intrinsic neural timescales related to sensory processing? {Evidence} from abnormal behavioral states},
	volume = {226},
	issn = {1053-8119},
	shorttitle = {Are intrinsic neural timescales related to sensory processing?},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920310648},
	doi = {10.1016/j.neuroimage.2020.117579},
	abstract = {The brain exhibits a complex temporal structure which translates into a hierarchy of distinct neural timescales. An open question is how these intrinsic timescales are related to sensory or motor information processing and whether these dynamics have common patterns in different behavioral states. We address these questions by investigating the brain's intrinsic timescales in healthy controls, motor (amyotrophic lateral sclerosis, locked-in syndrome), sensory (anesthesia, unresponsive wakefulness syndrome), and progressive reduction of sensory processing (from awake states over N1, N2, N3). We employed a combination of measures from EEG resting-state data: auto-correlation window (ACW), power spectral density (PSD), and power-law exponent (PLE). Prolonged neural timescales accompanied by a shift towards slower frequencies were observed in the conditions with sensory deficits, but not in conditions with motor deficits. Our results establish that the spontaneous activity's intrinsic neural timescale is related to the neural capacity that specifically supports sensory rather than motor information processing in the healthy brain.},
	language = {en},
	urldate = {2021-09-27},
	journal = {NeuroImage},
	author = {Zilio, Federico and Gomez-Pilar, Javier and Cao, Shumei and Zhang, Jun and Zang, Di and Qi, Zengxin and Tan, Jiaxing and Hiromi, Tanigawa and Wu, Xuehai and Fogel, Stuart and Huang, Zirui and Hohmann, Matthias R. and Fomina, Tatiana and Synofzik, Matthis and Grosse-Wentrup, Moritz and Owen, Adrian M. and Northoff, Georg},
	month = feb,
	year = {2021},
	keywords = {Anesthesia, Amyotrophic lateral sclerosis, Auto-correlation window, Intrinsic neural timescales, Unresponsive wakefulness syndrome},
	pages = {117579},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/5BNHLPLT/S1053811920310648.html:text/html},
}

@techreport{kaniuth_feature-reweighted_2021,
	title = {Feature-reweighted {RSA}: {A} method for improving the fit between computational models, brains, and behavior},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Feature-reweighted {RSA}},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.27.462005v1},
	abstract = {Representational Similarity Analysis (RSA) has emerged as a popular method for relating representational spaces from human brain activity, behavioral data, and computational models. RSA is based on the comparison of rep- resentational dissimilarity matrices (RDM), which characterize the pairwise dissimilarities of all conditions across all features (e.g. fMRI voxels or units of a model). However, classical RSA treats each feature as equally important. This 'equal weights' assumption contrasts with the flexibility of multivariate decoding, which reweights individual features for predicting a target variable. As a consequence, classical RSA may lead researchers to underestimate the correspondence between a model and a brain region and, for model comparison, it may lead to selecting the inferior model. While previous work has suggested that reweighting can improve model selection in RSA, it has remained unclear to what extent these results generalize across datasets and data modalities. To fill this gap, the aim of this work is twofold: First, utilizing a range of publicly available datasets and three popular deep neural networks (DNNs), we seek to broadly test feature-reweighted RSA (FR-RSA) applied to computational models and reveal the extent to which reweighting model features improves RDM correspondence and affects model selection. Second, we propose voxel-reweighted RSA, a novel use case of FR-RSA that reweights fMRI voxels, mirroring the rationale of multivariate decoding of optimally combining voxel activity patterns. We find that reweighting individual model units (1) markedly improves the fit between model RDMs and target RDMs derived from several fMRI and behavioral datasets and (2) affects model selection, highlighting the importance of considering FR-RSA. For voxel-reweighted RSA, improvements in RDM correspondence were even more pronounced, demonstrating the utility of this novel approach. We additionally demonstrate that classical noise ceilings can be exceeded when FR-RSA is applied and propose an updated approach for their computation. Taken together, our results broadly validate the use of FR-RSA for improving the fit between computational models, brain and behavioral data, possibly allowing us to better adjudicate between competing computational models. Further, our results suggest that FR-RSA applied to brain measurement channels could become an important new method to assess the match between representational spaces.},
	language = {en},
	urldate = {2021-09-29},
	author = {Kaniuth, Philipp and Hebart, Martin N.},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.09.27.462005},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.09.27.462005},
	file = {Kaniuth_Hebart_2021_Feature-reweighted RSA.pdf:/Users/tito/Zotero/storage/5AYWX6F6/Kaniuth_Hebart_2021_Feature-reweighted RSA.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/URE25KAI/2021.09.27.html:text/html},
}

@article{hebling_vieira_deep_nodate,
	title = {A deep learning based approach identifies regions more relevant than resting-state networks to the prediction of general intelligence from resting-state {fMRI}},
	volume = {n/a},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.25656},
	doi = {10.1002/hbm.25656},
	abstract = {Prediction of cognitive ability latent factors such as general intelligence from neuroimaging has elucidated questions pertaining to their neural origins. However, predicting general intelligence from functional connectivity limit hypotheses to that specific domain, being agnostic to time-distributed features and dynamics. We used an ensemble of recurrent neural networks to circumvent this limitation, bypassing feature extraction, to predict general intelligence from resting-state functional magnetic resonance imaging regional signals of a large sample (n = 873) of Human Connectome Project adult subjects. Ablating common resting-state networks (RSNs) and measuring degradation in performance, we show that model reliance can be mostly explained by network size. Using our approach based on the temporal variance of saliencies, that is, gradients of outputs with regards to inputs, we identify a candidate set of networks that more reliably affect performance in the prediction of general intelligence than similarly sized RSNs. Our approach allows us to further test the effect of local alterations on data and the expected changes in derived metrics such as functional connectivity and instantaneous innovations.},
	language = {en},
	number = {n/a},
	urldate = {2021-09-30},
	journal = {Human Brain Mapping},
	author = {Hebling Vieira, Bruno and Dubois, Julien and Calhoun, Vince D. and Garrido Salmon, Carlos Ernesto},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25656},
	keywords = {fMRI, intelligence, deep learning, resting-state, brain-behavior},
	file = {Hebling Vieira et al_A deep learning based approach identifies regions more relevant than.pdf:/Users/tito/Zotero/storage/ZHNTHN32/Hebling Vieira et al_A deep learning based approach identifies regions more relevant than.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/J5ZTJX2Z/hbm.html:text/html},
}

@article{ursino_transfer_2020,
	title = {Transfer {Entropy} as a {Measure} of {Brain} {Connectivity}: {A} {Critical} {Analysis} {With} the {Help} of {Neural} {Mass} {Models}},
	volume = {14},
	issn = {1662-5188},
	shorttitle = {Transfer {Entropy} as a {Measure} of {Brain} {Connectivity}},
	url = {https://www.frontiersin.org/article/10.3389/fncom.2020.00045},
	doi = {10.3389/fncom.2020.00045},
	abstract = {Objective: Assessing brain connectivity from electrophysiological signals is of great relevance in neuroscience, but results are still debated and depend crucially on how connectivity is defined and on mathematical instruments utilized. Aim of this work is to assess the capacity of bivariate Transfer Entropy (TE) to evaluate connectivity, using data generated from simple neural mass models of connected Regions of Interest (ROIs).Approach: Signals simulating mean field potentials were generated assuming two, three or four ROIs, connected via excitatory or by-synaptic inhibitory links. We investigated whether the presence of a statistically significant connection can be detected and if connection strength can be quantified.Main Results: Results suggest that TE can reliably estimate the strength of connectivity if neural populations work in their linear regions, and if the epoch lengths are longer than 10 s. In case of multivariate networks, some spurious connections can emerge (i.e., a statistically significant TE even in the absence of a true connection); however, quite a good correlation between TE and synaptic strength is still preserved. Moreover, TE appears more robust for distal regions (longer delays) compared with proximal regions (smaller delays): an approximate a priori knowledge on this delay can improve the procedure. Finally, non-linear phenomena affect the assessment of connectivity, since they may significantly reduce TE estimation: information transmission between two ROIs may be weak, due to non-linear phenomena, even if a strong causal connection is present.Significance: Changes in functional connectivity during different tasks or brain conditions, might not always reflect a true change in the connecting network, but rather a change in information transmission. A limitation of the work is the use of bivariate TE. In perspective, the use of multivariate TE can improve estimation and reduce some of the problems encountered in the present study.},
	urldate = {2021-09-30},
	journal = {Frontiers in Computational Neuroscience},
	author = {Ursino, Mauro and Ricci, Giulia and Magosso, Elisa},
	year = {2020},
	pages = {45},
	file = {Ursino et al_2020_Transfer Entropy as a Measure of Brain Connectivity.pdf:/Users/tito/Zotero/storage/RTYZP9DL/Ursino et al_2020_Transfer Entropy as a Measure of Brain Connectivity.pdf:application/pdf},
}

@article{brookes_multi-layer_2016,
	title = {A multi-layer network approach to {MEG} connectivity analysis},
	volume = {132},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811916001543},
	doi = {10.1016/j.neuroimage.2016.02.045},
	abstract = {Recent years have shown the critical importance of inter-regional neural network connectivity in supporting healthy brain function. Such connectivity is measurable using neuroimaging techniques such as MEG, however the richness of the electrophysiological signal makes gaining a complete picture challenging. Specifically, connectivity can be calculated as statistical interdependencies between neural oscillations within a large range of different frequency bands. Further, connectivity can be computed between frequency bands. This pan-spectral network hierarchy likely helps to mediate simultaneous formation of multiple brain networks, which support ongoing task demand. However, to date it has been largely overlooked, with many electrophysiological functional connectivity studies treating individual frequency bands in isolation. Here, we combine oscillatory envelope based functional connectivity metrics with a multi-layer network framework in order to derive a more complete picture of connectivity within and between frequencies. We test this methodology using MEG data recorded during a visuomotor task, highlighting simultaneous and transient formation of motor networks in the beta band, visual networks in the gamma band and a beta to gamma interaction. Having tested our method, we use it to demonstrate differences in occipital alpha band connectivity in patients with schizophrenia compared to healthy controls. We further show that these connectivity differences are predictive of the severity of persistent symptoms of the disease, highlighting their clinical relevance. Our findings demonstrate the unique potential of MEG to characterise neural network formation and dissolution. Further, we add weight to the argument that dysconnectivity is a core feature of the neuropathology underlying schizophrenia.},
	language = {en},
	urldate = {2021-09-30},
	journal = {NeuroImage},
	author = {Brookes, Matthew J. and Tewarie, Prejaas K. and Hunt, Benjamin A. E. and Robson, Sian E. and Gascoyne, Lauren E. and Liddle, Elizabeth B. and Liddle, Peter F. and Morris, Peter G.},
	month = may,
	year = {2016},
	keywords = {Functional connectivity, MEG, Visual cortex, Schizophrenia, Magnetoencephalography, Motor cortex, Multi-layer networks, Neural oscillations},
	pages = {425--438},
	file = {Brookes et al_2016_A multi-layer network approach to MEG connectivity analysis.pdf:/Users/tito/Zotero/storage/SKVF259S/Brookes et al_2016_A multi-layer network approach to MEG connectivity analysis.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/6L9GIP96/S1053811916001543.html:text/html},
}

@article{randi_nonequilibrium_2021,
	title = {Nonequilibrium {Green}'s {Functions} for {Functional} {Connectivity} in the {Brain}},
	volume = {126},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.126.118102},
	doi = {10.1103/PhysRevLett.126.118102},
	abstract = {A theoretical framework describing the set of interactions between neurons in the brain, or functional connectivity, should include dynamical functions representing the propagation of signal from one neuron to another. Green’s functions and response functions are natural candidates for this but, while they are conceptually very useful, they are usually defined only for linear time-translationally invariant systems. The brain, instead, behaves nonlinearly and in a time-dependent way. Here, we use nonequilibrium Green’s functions to describe the time-dependent functional connectivity of a continuous-variable network of neurons. We show how the connectivity is related to the measurable response functions, and provide two illustrative examples via numerical calculations, inspired from Caenorhabditis elegans.},
	number = {11},
	urldate = {2021-10-04},
	journal = {Phys. Rev. Lett.},
	author = {Randi, Francesco and Leifer, Andrew M.},
	month = mar,
	year = {2021},
	note = {Publisher: American Physical Society},
	pages = {118102},
	file = {APS Snapshot:/Users/tito/Zotero/storage/FAFNKY68/PhysRevLett.126.html:text/html;Randi_Leifer_2021_Nonequilibrium Green's Functions for Functional Connectivity in the Brain.pdf:/Users/tito/Zotero/storage/ATB67GMN/Randi_Leifer_2021_Nonequilibrium Green's Functions for Functional Connectivity in the Brain.pdf:application/pdf},
}

@article{finn_is_2021,
	title = {Is it time to put rest to rest?},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661321002345},
	doi = {10.1016/j.tics.2021.09.005},
	abstract = {The so-called resting state, in which participants lie quietly with no particular inputs or outputs, represented a paradigm shift from conventional task-based studies in human neuroimaging. Our foray into rest was fruitful from both a scientific and methodological perspective, but at this point, how much more can we learn from rest on its own? While rest still dominates in many subfields, data from tasks have empirically demonstrated benefits, as well as the potential to provide insights about the mind in addition to the brain. I argue that we can accelerate progress in human neuroscience by de-emphasizing rest in favor of more grounded experiments, including promising integrated designs that respect the prominence of self-generated activity while offering enhanced control and interpretability.},
	language = {en},
	urldate = {2021-10-06},
	journal = {Trends in Cognitive Sciences},
	author = {Finn, Emily S.},
	month = oct,
	year = {2021},
	keywords = {functional connectivity, resting state, brain–behavior prediction, naturalistic tasks, task-based},
	file = {Finn_2021_Is it time to put rest to rest.pdf:/Users/tito/Zotero/storage/Z66VMRGW/Finn_2021_Is it time to put rest to rest.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/FRR8B5Y8/S1364661321002345.html:text/html},
}

@article{li_statistical_2021,
	title = {Statistical {Mechanics} of {Deep} {Linear} {Neural} {Networks}: {The} {Backpropagating} {Kernel} {Renormalization}},
	volume = {11},
	shorttitle = {Statistical {Mechanics} of {Deep} {Linear} {Neural} {Networks}},
	url = {https://link.aps.org/doi/10.1103/PhysRevX.11.031059},
	doi = {10.1103/PhysRevX.11.031059},
	abstract = {The groundbreaking success of deep learning in many real-world tasks has triggered an intense effort to theoretically understand the power and limitations of deep learning in the training and generalization of complex tasks, so far with limited progress. In this work, we study the statistical mechanics of learning in deep linear neural networks (DLNNs) in which the input-output function of an individual unit is linear. Despite the linearity of the units, learning in DLNNs is highly nonlinear; hence, studying its properties reveals some of the essential features of nonlinear deep neural networks (DNNs). Importantly, we exactly solve the network properties following supervised learning using an equilibrium Gibbs distribution in the weight space. To do this, we introduce the backpropagating kernel renormalization (BPKR), which allows for the incremental integration of the network weights layer by layer starting from the network output layer and progressing backward until the first layer’s weights are integrated out. This procedure allows us to evaluate important network properties, such as its generalization error, the role of network width and depth, the impact of the size of the training set, and the effects of weight regularization and learning stochasticity. BPKR does not assume specific statistics of the input or the task’s output. Furthermore, by performing partial integration of the layers, the BPKR allows us to compute the emergent properties of the neural representations across the different hidden layers. We propose a heuristic extension of the BPKR to nonlinear DNNs with rectified linear units (ReLU). Surprisingly, our numerical simulations reveal that despite the nonlinearity, the predictions of our theory are largely shared by ReLU networks of modest depth, in a wide regime of parameters. Our work is the first exact statistical mechanical study of learning in a family of deep neural networks, and the first successful theory of learning through the successive integration of degrees of freedom in the learned weight space.},
	number = {3},
	urldate = {2021-10-06},
	journal = {Phys. Rev. X},
	author = {Li, Qianyi and Sompolinsky, Haim},
	month = sep,
	year = {2021},
	note = {Publisher: American Physical Society},
	pages = {031059},
	file = {APS Snapshot:/Users/tito/Zotero/storage/NLL6LZI9/PhysRevX.11.html:text/html;Li_Sompolinsky_2021_Statistical Mechanics of Deep Linear Neural Networks.pdf:/Users/tito/Zotero/storage/SEVW84ZW/Li_Sompolinsky_2021_Statistical Mechanics of Deep Linear Neural Networks.pdf:application/pdf},
}

@article{freyer_canonical_2012-1,
	title = {A {Canonical} {Model} of {Multistability} and {Scale}-{Invariance} in {Biological} {Systems}},
	volume = {8},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002634},
	doi = {10.1371/journal.pcbi.1002634},
	abstract = {Multistability and scale-invariant fluctuations occur in a wide variety of biological organisms from bacteria to humans as well as financial, chemical and complex physical systems. Multistability refers to noise driven switches between multiple weakly stable states. Scale-invariant fluctuations arise when there is an approximately constant ratio between the mean and standard deviation of a system's fluctuations. Both are an important property of human perception, movement, decision making and computation and they occur together in the human alpha rhythm, imparting it with complex dynamical behavior. Here, we elucidate their fundamental dynamical mechanisms in a canonical model of nonlinear bifurcations under stochastic fluctuations. We find that the co-occurrence of multistability and scale-invariant fluctuations mandates two important dynamical properties: Multistability arises in the presence of a subcritical Hopf bifurcation, which generates co-existing attractors, whilst the introduction of multiplicative (state-dependent) noise ensures that as the system jumps between these attractors, fluctuations remain in constant proportion to their mean and their temporal statistics become long-tailed. The simple algebraic construction of this model affords a systematic analysis of the contribution of stochastic and nonlinear processes to cortical rhythms, complementing a recently proposed biophysical model. Similar dynamics also occur in a kinetic model of gene regulation, suggesting universality across a broad class of biological phenomena.},
	language = {en},
	number = {8},
	urldate = {2021-10-06},
	journal = {PLOS Computational Biology},
	author = {Freyer, Frank and Roberts, James A. and Ritter, Petra and Breakspear, Michael},
	month = aug,
	year = {2012},
	note = {Publisher: Public Library of Science},
	keywords = {Dynamical systems, Electroencephalography, Sensory perception, Nonlinear dynamics, Biophysics, Bifurcation theory, Dwell time, Gene regulation},
	pages = {e1002634},
	file = {Freyer et al_2012_A Canonical Model of Multistability and Scale-Invariance in Biological Systems.pdf:/Users/tito/Zotero/storage/UCN5P6K5/Freyer et al_2012_A Canonical Model of Multistability and Scale-Invariance in Biological Systems.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HHJMK9IT/article.html:text/html},
}

@article{da_silva_castanheira_brief_2021,
	title = {Brief segments of neurophysiological activity enable individual differentiation},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-25895-8},
	doi = {10.1038/s41467-021-25895-8},
	abstract = {Large, openly available datasets and current analytic tools promise the emergence of population neuroscience. The considerable diversity in personality traits and behaviour between individuals is reflected in the statistical variability of neural data collected in such repositories. Recent studies with functional magnetic resonance imaging (fMRI) have concluded that patterns of resting-state functional connectivity can both successfully distinguish individual participants within a cohort and predict some individual traits, yielding the notion of an individual’s neural fingerprint. Here, we aim to clarify the neurophysiological foundations of individual differentiation from features of the rich and complex dynamics of resting-state brain activity using magnetoencephalography (MEG) in 158 participants. We show that akin to fMRI approaches, neurophysiological functional connectomes enable the differentiation of individuals, with rates similar to those seen with fMRI. We also show that individual differentiation is equally successful from simpler measures of the spatial distribution of neurophysiological spectral signal power. Our data further indicate that differentiation can be achieved from brain recordings as short as 30 seconds, and that it is robust over time: the neural fingerprint is present in recordings performed weeks after their baseline reference data was collected. This work, thus, extends the notion of a neural or brain fingerprint to fast and large-scale resting-state electrophysiological dynamics.},
	language = {en},
	number = {1},
	urldate = {2021-10-06},
	journal = {Nat Commun},
	author = {da Silva Castanheira, Jason and Orozco Perez, Hector Domingo and Misic, Bratislav and Baillet, Sylvain},
	month = sep,
	year = {2021},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Neurophysiology;Neuroscience
Subject\_term\_id: neurophysiology;neuroscience},
	pages = {5713},
	file = {da Silva Castanheira et al_2021_Brief segments of neurophysiological activity enable individual differentiation.pdf:/Users/tito/Zotero/storage/Y5TECFFI/da Silva Castanheira et al_2021_Brief segments of neurophysiological activity enable individual differentiation.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AH739UGQ/s41467-021-25895-8.html:text/html},
}

@article{whittington_tolman-eichenbaum_2020,
	title = {The {Tolman}-{Eichenbaum} {Machine}: {Unifying} {Space} and {Relational} {Memory} through {Generalization} in the {Hippocampal} {Formation}},
	volume = {183},
	issn = {0092-8674},
	shorttitle = {The {Tolman}-{Eichenbaum} {Machine}},
	url = {https://www.sciencedirect.com/science/article/pii/S009286742031388X},
	doi = {10.1016/j.cell.2020.10.024},
	abstract = {The hippocampal-entorhinal system is important for spatial and relational memory tasks. We formally link these domains, provide a mechanistic understanding of the hippocampal role in generalization, and offer unifying principles underlying many entorhinal and hippocampal cell types. We propose medial entorhinal cells form a basis describing structural knowledge, and hippocampal cells link this basis with sensory representations. Adopting these principles, we introduce the Tolman-Eichenbaum machine (TEM). After learning, TEM entorhinal cells display diverse properties resembling apparently bespoke spatial responses, such as grid, band, border, and object-vector cells. TEM hippocampal cells include place and landmark cells that remap between environments. Crucially, TEM also aligns with empirically recorded representations in complex non-spatial tasks. TEM also generates predictions that hippocampal remapping is not random as previously believed; rather, structural knowledge is preserved across environments. We confirm this structural transfer over remapping in simultaneously recorded place and grid cells.},
	language = {en},
	number = {5},
	urldate = {2021-10-08},
	journal = {Cell},
	author = {Whittington, James C. R. and Muller, Timothy H. and Mark, Shirley and Chen, Guifen and Barry, Caswell and Burgess, Neil and Behrens, Timothy E. J.},
	month = nov,
	year = {2020},
	keywords = {neural networks, hippocampus, representation learning, generalization, entorhinal cortex, grid cells, non-spatial reasoning, place cells},
	pages = {1249--1263.e23},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/EPD9E32U/S009286742031388X.html:text/html;Whittington et al_2020_The Tolman-Eichenbaum Machine.pdf:/Users/tito/Zotero/storage/2U3VW7BL/Whittington et al_2020_The Tolman-Eichenbaum Machine.pdf:application/pdf},
}

@techreport{manea_intrinsic_2021,
	title = {Intrinsic timescales as an organizational principle of neural processing across the whole rhesus macaque brain},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.05.463277v1},
	abstract = {Hierarchical temporal dynamics are a fundamental computational property of the brain; however, there are no whole-brain, noninvasive investigations into timescales of neural processing in animal models. To that end, we used the spatial resolution and sensitivity of ultra-high field fMRI to probe timescales across the whole macaque brain. We uncovered within-species consistency between timescales estimated from fMRI and electrophysiology. Crucially, we were not only able to demonstrate that we can replicate existing electrophysiological hierarchies, but we extended these to whole brain topographies. Our results validate the complementary use of hemodynamic and electrophysiological intrinsic timescales, establishing a basis for future translational work. Second, with those results in hand, we were able to show that one facet of the high-dimensional FC topography of any region in the brain is closely related to hierarchical temporal dynamics. We demonstrated that intrinsic timescales are organized along spatial gradients that closely match functional connectivity gradient topographies across the whole brain. We conclude that intrinsic timescales are an unifying organizational principle of neural processing across the whole brain.},
	language = {en},
	urldate = {2021-10-08},
	author = {Manea, Ana M. G. and Zilverstand, Anna and Ugurbil, Kamil and Heilbronner, Sarah R. and Zimmermann, Jan},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.10.05.463277},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.10.05.463277},
	file = {Manea et al_2021_Intrinsic timescales as an organizational principle of neural processing across.pdf:/Users/tito/Zotero/storage/GEM3VBFL/Manea et al_2021_Intrinsic timescales as an organizational principle of neural processing across.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/2GLLJ73Q/2021.10.05.html:text/html},
}

@article{hernandez_decoding_2010,
	title = {Decoding a {Perceptual} {Decision} {Process} across {Cortex}},
	volume = {66},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627310002345},
	doi = {10.1016/j.neuron.2010.03.031},
	abstract = {Perceptual decisions arise from the activity of neurons distributed across brain circuits. But, decoding the mechanisms behind this cognitive operation across brain circuits has long posed a difficult problem. We recorded the neuronal activity of diverse cortical areas, while monkeys performed a vibrotactile discrimination task. We find that the encoding of the stimuli during the stimulus periods, working memory, and comparison periods is widely distributed across cortical areas. Notably, during the comparison and postponed decision report periods the activity of frontal brain circuits encode both the result of the sensory evaluation that corresponds to the monkey's possible choices and past information on which the decision is based. These results suggest that frontal lobe circuits are more engaged in the readout of sensory information from working memory, when it is required to be compared with other sensory inputs, than simply engaged in motor responses during this task.},
	language = {en},
	number = {2},
	urldate = {2021-10-11},
	journal = {Neuron},
	author = {Hernández, Adrián and Nácher, Verónica and Luna, Rogelio and Zainos, Antonio and Lemus, Luis and Alvarez, Manuel and Vázquez, Yuriria and Camarillo, Liliana and Romo, Ranulfo},
	month = apr,
	year = {2010},
	keywords = {SYSNEURO},
	pages = {300--314},
	file = {Hernández et al_2010_Decoding a Perceptual Decision Process across Cortex.pdf:/Users/tito/Zotero/storage/JW3AMCKA/Hernández et al_2010_Decoding a Perceptual Decision Process across Cortex.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/N8XPV5YW/S0896627310002345.html:text/html},
}

@article{brown_superhuman_2019,
	title = {Superhuman {AI} for multiplayer poker},
	volume = {365},
	url = {https://www.science.org/doi/10.1126/science.aay2400},
	doi = {10.1126/science.aay2400},
	number = {6456},
	urldate = {2021-10-12},
	journal = {Science},
	author = {Brown, Noam and Sandholm, Tuomas},
	month = aug,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {885--890},
	file = {Brown_Sandholm_2019_Superhuman AI for multiplayer poker.pdf:/Users/tito/Zotero/storage/XRXN5GHV/Brown_Sandholm_2019_Superhuman AI for multiplayer poker.pdf:application/pdf},
}

@techreport{zheng_accurate_2021,
	title = {Accurate predictions of individual differences in task-evoked brain activity from resting-state {fMRI} using a sparse ensemble learner},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.08.19.456783v1},
	abstract = {Modelling and predicting individual differences in task-evoked FMRI activity can have a wide range of applications from basic to clinical neuroscience. It has been shown that models based on resting-state activity can have high predictive accuracy. Here we propose several improvements to such models. Using a sparse ensemble leaner, we show that (i) features extracted using Stochastic Probabilistic Functional Modes (sPROFUMO) outperform the previously proposed dual-regression approach, (ii) that the shape and overall intensity of individualised task activations can be modelled separately and explicitly, (iii) training the model on predicting residual differences in brain activity further boosts individualised predictions. These results hold for both surface-based analyses of the Human Connectome Project data as well as volumetric analyses of UK-biobank data. Overall, our model achieves state of the art prediction accuracy on par with the test-retest reliability of tfMRI scans, suggesting that it has potential to supplement traditional task localisers.},
	language = {en},
	urldate = {2021-10-12},
	author = {Zheng, Ying-Qiu and Farahibozorg, Seyedeh-Rezvan and Gong, Weikang and Rafipoor, Hossein and Jbabdi, Saad and Smith, Stephen},
	month = aug,
	year = {2021},
	doi = {10.1101/2021.08.19.456783},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.08.19.456783},
	file = {Snapshot:/Users/tito/Zotero/storage/3MYFHKZ4/2021.08.19.html:text/html;Zheng et al_2021_Accurate predictions of individual differences in task-evoked brain activity.pdf:/Users/tito/Zotero/storage/FS4ISSFB/Zheng et al_2021_Accurate predictions of individual differences in task-evoked brain activity.pdf:application/pdf},
}

@inproceedings{tsukada_analysis_2018,
	address = {Singapore},
	series = {Advances in {Cognitive} {Neurodynamics}},
	title = {Analysis of {Structure}-{Function} {Relationship} {Using} a {Whole}-{Brain} {Dynamic} {Model} {Based} on {MRI} {Images} of the {Common} {Marmoset}},
	isbn = {978-981-10-8854-4},
	doi = {10.1007/978-981-10-8854-4_12},
	abstract = {How brain functions emerge from anatomical networks of the brain is still an open fundamental question. One approach for understanding the structure-function relationship is computational modeling of structural and functional connectivity data from MRI and to explore the behavior of the dynamic model by computer simulation. Here we constructed a whole-brain model based on the structural connectivity between 96 anatomical regions of the marmoset brain estimated from diffusion MRI data. We compared the brain activity simulated by the model and the brain activity observed by resting state functional MRI. We found that the correlation between the simulated and empirical functional connectivities increases within balanced parameter regions of excitatory-inhibitory connections, although the models with shuffled weights break the correlation. This result suggests that these parameters are crucial factors for the relationship between anatomical and functional network in the resting state MRI.},
	language = {en},
	booktitle = {Advances in {Cognitive} {Neurodynamics} ({VI})},
	publisher = {Springer},
	author = {Tsukada, Hiromichi and Hamada, Hiroaki and Nakae, Ken and Ishii, Shin and Hata, Junichi and Okano, Hideyuki and Doya, Kenji},
	editor = {Delgado-García, José M. and Pan, Xiaochuan and Sánchez-Campusano, Raudel and Wang, Rubin},
	year = {2018},
	keywords = {MRI, Functional connectivity, Marmoset, Neural network model, Structural connectivity},
	pages = {97--102},
	file = {Tsukada et al_2018_Analysis of Structure-Function Relationship Using a Whole-Brain Dynamic Model.pdf:/Users/tito/Zotero/storage/6TDRNEYL/Tsukada et al_2018_Analysis of Structure-Function Relationship Using a Whole-Brain Dynamic Model.pdf:application/pdf},
}

@article{skibbe_marmonet_2019,
	title = {{MarmoNet}: a pipeline for automated projection mapping of the common marmoset brain from whole-brain serial two-photon tomography},
	shorttitle = {{MarmoNet}},
	url = {http://arxiv.org/abs/1908.00876},
	abstract = {Understanding the connectivity in the brain is an important prerequisite for understanding how the brain processes information. In the Brain/MINDS project, a connectivity study on marmoset brains uses two-photon microscopy ﬂuorescence images of axonal projections to collect the neuron connectivity from deﬁned brain regions at the mesoscopic scale. The processing of the images requires the detection and segmentation of the axonal tracer signal. The objective is to detect as much tracer signal as possible while not misclassifying other background structures as the signal. This can be challenging because of imaging noise, a cluttered image background, distortions or varying image contrast cause problems.},
	language = {en},
	urldate = {2021-10-12},
	journal = {arXiv:1908.00876 [cs, eess, q-bio, stat]},
	author = {Skibbe, Henrik and Watakabe, Akiya and Nakae, Ken and Gutierrez, Carlos Enrique and Tsukada, Hiromichi and Hata, Junichi and Kawase, Takashi and Gong, Rui and Woodward, Alexander and Doya, Kenji and Okano, Hideyuki and Yamamori, Tetsuo and Ishii, Shin},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.00876},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Statistics - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Skibbe et al. - 2019 - MarmoNet a pipeline for automated projection mapp.pdf:/Users/tito/Zotero/storage/U73A5KFN/Skibbe et al. - 2019 - MarmoNet a pipeline for automated projection mapp.pdf:application/pdf},
}

@article{hennig_how_2021,
	title = {How learning unfolds in the brain: toward an optimization view},
	issn = {0896-6273},
	shorttitle = {How learning unfolds in the brain},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627321006772},
	doi = {10.1016/j.neuron.2021.09.005},
	abstract = {How do changes in the brain lead to learning? To answer this question, consider an artificial neural network (ANN), where learning proceeds by optimizing a given objective or cost function. This “optimization framework” may provide new insights into how the brain learns, as many idiosyncratic features of neural activity can be recapitulated by an ANN trained to perform the same task. Nevertheless, there are key features of how neural population activity changes throughout learning that cannot be readily explained in terms of optimization and are not typically features of ANNs. Here we detail three of these features: (1) the inflexibility of neural variability throughout learning, (2) the use of multiple learning processes even during simple tasks, and (3) the presence of large task-nonspecific activity changes. We propose that understanding the role of these features in the brain will be key to describing biological learning using an optimization framework.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Neuron},
	author = {Hennig, Jay A. and Oby, Emily R. and Losey, Darby M. and Batista, Aaron P. and Yu, Byron M. and Chase, Steven M.},
	month = oct,
	year = {2021},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/QU7CCB8W/S0896627321006772.html:text/html},
}

@article{rossi-pool_invariant_2021,
	title = {Invariant timescale hierarchy across the cortical somatosensory network},
	volume = {118},
	copyright = {© 2021 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/3/e2021843118},
	doi = {10.1073/pnas.2021843118},
	abstract = {The ability of cortical networks to integrate information from different sources is essential for cognitive processes. On one hand, sensory areas exhibit fast dynamics often phase-locked to stimulation; on the other hand, frontal lobe areas with slow response latencies to stimuli must integrate and maintain information for longer periods. Thus, cortical areas may require different timescales depending on their functional role. Studying the cortical somatosensory network while monkeys discriminated between two vibrotactile stimulus patterns, we found that a hierarchical order could be established across cortical areas based on their intrinsic timescales. Further, even though subareas (areas 3b, 1, and 2) of the primary somatosensory (S1) cortex exhibit analogous firing rate responses, a clear differentiation was observed in their timescales. Importantly, we observed that this inherent timescale hierarchy was invariant between task contexts (demanding vs. nondemanding). Even if task context severely affected neural coding in cortical areas downstream to S1, their timescales remained unaffected. Moreover, we found that these time constants were invariant across neurons with different latencies or coding. Although neurons had completely different dynamics, they all exhibited comparable timescales within each cortical area. Our results suggest that this measure is demonstrative of an inherent characteristic of each cortical area, is not a dynamical feature of individual neurons, and does not depend on task demands.},
	language = {en},
	number = {3},
	urldate = {2021-10-15},
	journal = {PNAS},
	author = {Rossi-Pool, Román and Zainos, Antonio and Alvarez, Manuel and Parra, Sergio and Zizumbo, Jerónimo and Romo, Ranulfo},
	month = jan,
	year = {2021},
	pmid = {33431695},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {behaving monkeys, inherent time constants, primary somatosensory cortex, somatosensory network, timescale hierarchy},
	file = {Rossi-Pool et al_2021_Invariant timescale hierarchy across the cortical somatosensory network.pdf:/Users/tito/Zotero/storage/HX8YEBX7/Rossi-Pool et al_2021_Invariant timescale hierarchy across the cortical somatosensory network.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/7YLTS8QU/e2021843118.html:text/html},
}

@book{marcus_algebraic_2003,
	title = {The algebraic mind: {Integrating} connectionism and cognitive science},
	shorttitle = {The algebraic mind},
	publisher = {MIT press},
	author = {Marcus, Gary F.},
	year = {2003},
	file = {Snapshot:/Users/tito/Zotero/storage/729YDJPJ/books.html:text/html},
}

@article{holroyd_human_2018,
	title = {Human midcingulate cortex encodes distributed representations of task progress},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1803650115},
	doi = {10.1073/pnas.1803650115},
	abstract = {The function of midcingulate cortex (MCC) remains elusive despite decades of investigation and debate. Complicating matters, individual MCC neurons respond to highly diverse task-related events, and MCC activation is reported in most human neuroimaging studies employing a wide variety of task manipulations. Here we investigate this issue by applying a model-based cognitive neuroscience approach involving neural network simulations, functional magnetic resonance imaging, and representational similarity analysis. We demonstrate that human MCC encodes distributed, dynamically evolving representations of extended, goal-directed action sequences. These representations are uniquely sensitive to the stage and identity of each sequence, indicating that MCC sustains contextual information necessary for discriminating between task states. These results suggest that standard univariate approaches for analyzing MCC function overlook the major portion of task-related information encoded by this brain area and point to promising new avenues for investigation.},
	language = {en},
	number = {25},
	urldate = {2021-10-15},
	journal = {Proc Natl Acad Sci USA},
	author = {Holroyd, Clay B. and Ribas-Fernandes, José J. F. and Shahnazian, Danesh and Silvetti, Massimo and Verguts, Tom},
	month = jun,
	year = {2018},
	pages = {6398--6403},
	file = {Holroyd et al. - 2018 - Human midcingulate cortex encodes distributed repr.pdf:/Users/tito/Zotero/storage/T38EGQP3/Holroyd et al. - 2018 - Human midcingulate cortex encodes distributed repr.pdf:application/pdf},
}

@article{caldinelli_fronto-parietal_nodate,
	title = {The fronto-parietal network is not a flexible hub during naturalistic cognition},
	volume = {n/a},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.25684},
	doi = {10.1002/hbm.25684},
	abstract = {The fronto-parietal network (FPN) is crucial for cognitively demanding tasks as it selectively represents task-relevant information and controls other brain regions. To implement these functions, it has been argued that it is a flexible hub that reconfigures its functional connectivity with other networks. This was supported by a study in which a set of demanding tasks were presented, that varied in their sensory features, comparison rules, and response mappings, and the FPN showed greater reconfiguration of functional connectivity between tasks than any other network. However, this task set was designed to engage the FPN, and therefore it remains an open question whether the FPN is in a flexible hub in general or only for such task sets. Using two freely available datasets (Experiment 1, N = 15, Experiment 2, N = 644), we examined dynamic functional connectivity during naturalistic cognition, while participants watched a movie. Many differences in the flexibility were found across networks but the FPN was not the most flexible hub in the brain, during either movie for any of two measures, using a regression model or a correlation model and across five timescales. We, therefore, conclude that the FPN does not have the trait of being a flexible hub, although it may adopt this state for particular task sets.},
	language = {en},
	number = {n/a},
	urldate = {2021-10-18},
	journal = {Human Brain Mapping},
	author = {Caldinelli, Chiara and Cusack, Rhodri},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25684},
	keywords = {dynamic functional connectivity, fronto-parietal network, movie watching},
	file = {Caldinelli_Cusack_The fronto-parietal network is not a flexible hub during naturalistic cognition.pdf:/Users/tito/Zotero/storage/JXCD72V6/Caldinelli_Cusack_The fronto-parietal network is not a flexible hub during naturalistic cognition.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/U2HZHAHY/hbm.html:text/html},
}

@article{di_understanding_2021,
	title = {Understanding psychophysiological interaction and its relations to beta series correlation},
	volume = {15},
	issn = {1931-7565},
	url = {https://doi.org/10.1007/s11682-020-00304-8},
	doi = {10.1007/s11682-020-00304-8},
	abstract = {Psychophysiological interaction (PPI) was proposed 20 years ago for study of task modulated connectivity on functional MRI (fMRI) data. A few modifications have since been made, but there remain misunderstandings on the method, as well as on its relations to a similar method named beta series correlation (BSC). Here, we explain what PPI measures and its relations to BSC. We first clarify that the interpretation of a regressor in a general linear model depends on not only itself but also on how other effects are modeled. In terms of PPI, it always reflects differences in connectivity between conditions, when the physiological variable is included as a covariate. Secondly, when there are multiple conditions, we explain how PPI models calculated from direct contrast between conditions could generate identical results as contrasting separate PPIs of each condition (a.k.a. “generalized” PPI). Thirdly, we explicit the deconvolution process that is used for PPI calculation, and how is it related to the trial-by-trial modeling for BSC, and illustrate the relations between PPI and those based upon BSC. In particular, when context sensitive changes in effective connectivity are present, they manifest as changes in correlations of observed trial-by-trial activations or functional connectivity. Therefore, BSC and PPI can detect similar connectivity differences. Lastly, we report empirical analyses using PPI and BSC on fMRI data of an event-related stop signal task to illustrate our points.},
	language = {en},
	number = {2},
	urldate = {2021-10-19},
	journal = {Brain Imaging and Behavior},
	author = {Di, Xin and Zhang, Zhiguo and Biswal, Bharat B.},
	month = apr,
	year = {2021},
	pages = {958--973},
	file = {Di et al_2021_Understanding psychophysiological interaction and its relations to beta series.pdf:/Users/tito/Zotero/storage/FCYDE8IW/Di et al_2021_Understanding psychophysiological interaction and its relations to beta series.pdf:application/pdf},
}

@techreport{sun_organizing_2021,
	title = {Organizing memories for generalization in complementary learning systems},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.13.463791v1},
	abstract = {Our ability to remember the past is essential for guiding our future behavior. Psychological and neurobiological features of declarative memories are known to transform over time in a process known as systems consolidation. While many theories have sought to explain the time-varying role of hippocampal and neocortical brain areas, the computational principles that govern these transformations remain unclear. Here we propose a theory of systems consolidation in which hippocampal-cortical interactions serve to optimize generalizations that guide future adaptive behavior. We use mathematical analysis of neural network models to characterize fundamental performance tradeoffs in systems consolidation, revealing that memory components should be organized according to their predictability. The theory shows that multiple interacting memory systems can outperform just one, normatively unifying diverse experimental observations and making novel experimental predictions. Our results suggest that the psychological taxonomy and neurobiological organization of declarative memories reflect a system optimized for behaving well in an uncertain future.},
	language = {en},
	urldate = {2021-10-19},
	author = {Sun, Weinan and Advani, Madhu and Spruston, Nelson and Saxe, Andrew and Fitzgerald, James E.},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.10.13.463791},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.10.13.463791},
	file = {Sun et al_2021_Organizing memories for generalization in complementary learning systems.pdf:/Users/tito/Zotero/storage/E7RXQ5WM/Sun et al_2021_Organizing memories for generalization in complementary learning systems.pdf:application/pdf},
}

@article{mack_decoding_2013,
	title = {Decoding the {Brain}’s {Algorithm} for {Categorization} from {Its} {Neural} {Implementation}},
	volume = {23},
	issn = {0960-9822},
	url = {https://www.sciencedirect.com/science/article/pii/S0960982213010415},
	doi = {10.1016/j.cub.2013.08.035},
	abstract = {Acts of cognition can be described at different levels of analysis: what behavior should characterize the act, what algorithms and representations underlie the behavior, and how the algorithms are physically realized in neural activity [1]. Theories that bridge levels of analysis offer more complete explanations by leveraging the constraints present at each level [2, 3, 4]. Despite the great potential for theoretical advances, few studies of cognition bridge levels of analysis. For example, formal cognitive models of category decisions accurately predict human decision making [5, 6], but whether model algorithms and representations supporting category decisions are consistent with underlying neural implementation remains unknown. This uncertainty is largely due to the hurdle of forging links between theory and brain [7, 8, 9]. Here, we tackle this critical problem by using brain response to characterize the nature of mental computations that support category decisions to evaluate two dominant, and opposing, models of categorization. We found that brain states during category decisions were significantly more consistent with latent model representations from exemplar [5] rather than prototype theory [10, 11]. Representations of individual experiences, not the abstraction of experiences, are critical for category decision making. Holding models accountable for behavior and neural implementation provides a means for advancing more complete descriptions of the algorithms of cognition.},
	language = {en},
	number = {20},
	urldate = {2021-10-19},
	journal = {Current Biology},
	author = {Mack, Michael L. and Preston, Alison R. and Love, Bradley C.},
	month = oct,
	year = {2013},
	pages = {2023--2027},
	file = {Mack et al_2013_Decoding the Brain’s Algorithm for Categorization from Its Neural Implementation.pdf:/Users/tito/Zotero/storage/R55EJ4BA/Mack et al_2013_Decoding the Brain’s Algorithm for Categorization from Its Neural Implementation.pdf:application/pdf},
}

@techreport{johnston_abstract_2021,
	title = {Abstract representations emerge naturally in neural networks trained to perform multiple tasks},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.10.20.465187v2},
	abstract = {Humans and other animals demonstrate a remarkable ability to generalize knowledge across distinct contexts and objects during natural behavior. We posit that this ability depends on the geometry of the neural population representations of these objects and contexts. Specifically, abstract, or disentangled, neural representations -- in which neural population activity is a linear function of the variables important for making a decision -- are known to allow for this kind of generalization. Further, recent neurophysiological studies have shown that the brain has sufficiently abstract representations of some sensory and cognitive variables to enable generalization across distinct contexts. However, it is unknown how these abstract representations emerge. Here, using feedforward neural networks, we demonstrate a simple mechanism by which these abstract representations can be produced: The learning of multiple distinct classification tasks. We demonstrate that, despite heterogeneity in the task structure, abstract representations that enable reliable generalization can be produced from a variety of different inputs -- including standard nonlinearly mixed inputs, inputs that mimic putative representations from early sensory areas, and even simple image inputs from a standard machine learning data set. Thus, we conclude that abstract representations of sensory and cognitive variables emerge from the multiple behaviors that animals exhibit in the natural world, and may be pervasive in high-level brain regions. We make several specific predictions about which variables will be represented abstractly as well as show how these representations can be detected.},
	language = {en},
	urldate = {2021-10-21},
	author = {Johnston, W. Jeffrey and Fusi, Stefano},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.10.20.465187},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.10.20.465187},
	file = {Johnston_Fusi_2021_Abstract representations emerge naturally in neural networks trained to perform.pdf:/Users/tito/Zotero/storage/L5T4GCJC/Johnston_Fusi_2021_Abstract representations emerge naturally in neural networks trained to perform.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DFASEMNZ/2021.10.20.html:text/html},
}

@misc{noauthor_visual_nodate,
	title = {Visual attention mediated by biased competition in extrastriate visual cortex {\textbar} {Philosophical} {Transactions} of the {Royal} {Society} of {London}. {Series} {B}: {Biological} {Sciences}},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.1998.0280},
	urldate = {2021-10-22},
	file = {Visual attention mediated by biased competition in extrastriate visual cortex | Philosophical Transactions of the Royal Society of London. Series B\: Biological Sciences:/Users/tito/Zotero/storage/6XFTEIBY/rstb.1998.html:text/html},
}

@article{desimone_visual_1998,
	title = {Visual attention mediated by biased competition in extrastriate visual cortex},
	volume = {353},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.1998.0280},
	doi = {10.1098/rstb.1998.0280},
	abstract = {According to conventional neurobiological accounts of visual attention, attention serves to enhance extrastriate neuronal responses to a stimulus at one spatial location in the visual field. However, recent results from recordings in extrastriate cortex of monkeys suggest that any enhancing effect of attention is best understood in the context of competitive interactions among neurons representing all of the stimuli present in the visual field. These interactions can be biased in favour of behaviourally relevant stimuli as a result of many different processes, both spatial and non–spatial, and both bottom–up and top–down. The resolution of this competition results in the suppression of the neuronal representations of behaviourally irrelevant stimuli in extrastriate cortex. A main source of top–down influence may derive from neuronal systems underlying working memory.},
	number = {1373},
	urldate = {2021-10-22},
	journal = {Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
	author = {Desimone, Robert},
	month = aug,
	year = {1998},
	note = {Publisher: Royal Society},
	keywords = {attention, inferior temporal cortex, vision, primates, V4},
	pages = {1245--1255},
	file = {Humphreys et al_1998_Visual attention mediated by biased competition in extrastriate visual cortex.pdf:/Users/tito/Zotero/storage/USKMY82J/Humphreys et al_1998_Visual attention mediated by biased competition in extrastriate visual cortex.pdf:application/pdf},
}

@article{cherkaoui_multivariate_2021,
	title = {Multivariate semi-blind deconvolution of {fMRI} time series},
	volume = {241},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921006935},
	doi = {10.1016/j.neuroimage.2021.118418},
	abstract = {Whole brain estimation of the haemodynamic response function (HRF) in functional magnetic resonance imaging (fMRI) is critical to get insight on the global status of the neurovascular coupling of an individual in healthy or pathological condition. Most of existing approaches in the literature works on task-fMRI data and relies on the experimental paradigm as a surrogate of neural activity, hence remaining inoperative on resting-stage fMRI (rs-fMRI) data. To cope with this issue, recent works have performed either a two-step analysis to detect large neural events and then characterize the HRF shape or a joint estimation of both the neural and haemodynamic components in an univariate fashion. In this work, we express the neural activity signals as a combination of piece-wise constant temporal atoms associated with sparse spatial maps and introduce an haemodynamic parcellation of the brain featuring a temporally dilated version of a given HRF model in each parcel with unknown dilation parameters. We formulate the joint estimation of the HRF shapes and spatio-temporal neural representations as a multivariate semi-blind deconvolution problem in a paradigm-free setting and introduce constraints inspired from the dictionary learning literature to ease its identifiability. A fast alternating minimization algorithm, along with its efficient implementation, is proposed and validated on both synthetic and real rs-fMRI data at the subject level. To demonstrate its significance at the population level, we apply this new framework to the UK Biobank data set, first for the discrimination of haemodynamic territories between balanced groups (n=24 individuals in each) patients with an history of stroke and healthy controls and second, for the analysis of normal aging on the neurovascular coupling. Overall, we statistically demonstrate that a pathology like stroke or a condition like normal brain aging induce longer haemodynamic delays in certain brain areas (e.g. Willis polygon, occipital, temporal and frontal cortices) and that this haemodynamic feature may be predictive with an accuracy of 74 \% of the individual’s age in a supervised classification task performed on n=459 subjects.},
	language = {en},
	urldate = {2021-10-22},
	journal = {NeuroImage},
	author = {Cherkaoui, Hamza and Moreau, Thomas and Halimi, Abderrahim and Leroy, Claire and Ciuciu, Philippe},
	month = nov,
	year = {2021},
	keywords = {BOLD signal, Dictionary learning, HRF, Low-rank decomposition, Multivariate modeling, Sparsity, UK Biobank},
	pages = {118418},
	file = {Cherkaoui et al_2021_Multivariate semi-blind deconvolution of fMRI time series.pdf:/Users/tito/Zotero/storage/3P3KLMNY/Cherkaoui et al_2021_Multivariate semi-blind deconvolution of fMRI time series.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/E83CHGC9/S1053811921006935.html:text/html},
}

@article{ghavasieh_statistical_2020,
	title = {Statistical physics of complex information dynamics},
	volume = {102},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.102.052304},
	doi = {10.1103/PhysRevE.102.052304},
	abstract = {The constituents of a complex system exchange information to function properly. Their signaling dynamics often leads to the appearance of emergent phenomena, such as phase transitions and collective behaviors. While information exchange has been widely modeled by means of distinct spreading processes—such as continuous-time diffusion, random walks, synchronization and consensus—on top of complex networks, a unified and physically grounded framework to study information dynamics and gain insights about the macroscopic effects of microscopic interactions is still eluding us. In this paper, we present this framework in terms of a statistical field theory of information dynamics, unifying a range of dynamical processes governing the evolution of information on top of static or time-varying structures. We show that information operators form a meaningful statistical ensemble and their superposition defines a density matrix that can be used for the analysis of complex dynamics. As a direct application, we show that the von Neumann entropy of the ensemble can be a measure of the functional diversity of complex systems, defined in terms of the functional differentiation of higher-order interactions among their components. Our results suggest that modularity and hierarchy, two key features of empirical complex systems—from the human brain to social and urban networks—play a key role to guarantee functional diversity and, consequently, are favored.},
	number = {5},
	urldate = {2021-10-25},
	journal = {Phys. Rev. E},
	author = {Ghavasieh, Arsham and Nicolini, Carlo and De Domenico, Manlio},
	month = nov,
	year = {2020},
	note = {Publisher: American Physical Society},
	pages = {052304},
	file = {APS Snapshot:/Users/tito/Zotero/storage/SFRCJJES/PhysRevE.102.html:text/html;Ghavasieh et al_2020_Statistical physics of complex information dynamics.pdf:/Users/tito/Zotero/storage/SXNK6H8C/Ghavasieh et al_2020_Statistical physics of complex information dynamics.pdf:application/pdf},
}

@article{simon_neural_2021,
	title = {Neural {Tangent} {Kernel} {Eigenvalues} {Accurately} {Predict} {Generalization}},
	url = {http://arxiv.org/abs/2110.03922},
	abstract = {Finding a quantitative theory of neural network generalization has long been a central goal of deep learning research. We extend recent results to demonstrate that, by examining the eigensystem of a neural network's "neural tangent kernel", one can predict its generalization performance when learning arbitrary functions. Our theory accurately predicts not only test mean-squared-error but all first- and second-order statistics of the network's learned function. Furthermore, using a measure quantifying the "learnability" of a given target function, we prove a new "no-free-lunch" theorem characterizing a fundamental tradeoff in the inductive bias of wide neural networks: improving a network's generalization for a given target function must worsen its generalization for orthogonal functions. We further demonstrate the utility of our theory by analytically predicting two surprising phenomena - worse-than-chance generalization on hard-to-learn functions and nonmonotonic error curves in the small data regime - which we subsequently observe in experiments. Though our theory is derived for infinite-width architectures, we find it agrees with networks as narrow as width 20, suggesting it is predictive of generalization in practical neural networks. Code replicating our results is available at https://github.com/james-simon/eigenlearning.},
	urldate = {2021-10-25},
	journal = {arXiv:2110.03922 [cs, stat]},
	author = {Simon, James B. and Dickens, Madeline and DeWeese, Michael R.},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.03922},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages (main text), 24 pages (total), 10 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/88VD946S/2110.html:text/html;Simon et al_2021_Neural Tangent Kernel Eigenvalues Accurately Predict Generalization.pdf:/Users/tito/Zotero/storage/EVKSCHQN/Simon et al_2021_Neural Tangent Kernel Eigenvalues Accurately Predict Generalization.pdf:application/pdf},
}

@article{williams_generalized_2021,
	title = {Generalized {Shape} {Metrics} on {Neural} {Representations}},
	url = {http://arxiv.org/abs/2110.14739},
	abstract = {Understanding the operation of biological and artificial networks remains a difficult and important challenge. To identify general principles, researchers are increasingly interested in surveying large collections of networks that are trained on, or biologically adapted to, similar tasks. A standardized set of analysis tools is now needed to identify how network-level covariates -- such as architecture, anatomical brain region, and model organism -- impact neural representations (hidden layer activations). Here, we provide a rigorous foundation for these analyses by defining a broad family of metric spaces that quantify representational dissimilarity. Using this framework we modify existing representational similarity measures based on canonical correlation analysis to satisfy the triangle inequality, formulate a novel metric that respects the inductive biases in convolutional layers, and identify approximate Euclidean embeddings that enable network representations to be incorporated into essentially any off-the-shelf machine learning method. We demonstrate these methods on large-scale datasets from biology (Allen Institute Brain Observatory) and deep learning (NAS-Bench-101). In doing so, we identify relationships between neural representations that are interpretable in terms of anatomical features and model performance.},
	urldate = {2021-11-02},
	journal = {arXiv:2110.14739 [cs, stat]},
	author = {Williams, Alex H. and Kunz, Erin and Kornblith, Simon and Linderman, Scott W.},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.14739},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 26 pages, 7 figures, NeurIPS 2021},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/2V78MAW7/2110.html:text/html;Williams et al_2021_Generalized Shape Metrics on Neural Representations.pdf:/Users/tito/Zotero/storage/3B7KZRE9/Williams et al_2021_Generalized Shape Metrics on Neural Representations.pdf:application/pdf},
}

@article{shahbazi_using_2021,
	title = {Using distance on the {Riemannian} manifold to compare representations in brain and in models},
	volume = {239},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921005474},
	doi = {10.1016/j.neuroimage.2021.118271},
	abstract = {Representational similarity analysis (RSA) summarizes activity patterns for a set of experimental conditions into a matrix composed of pairwise comparisons between activity patterns. Two examples of such matrices are the condition-by-condition inner product and correlation matrix. These representational matrices reside on the manifold of positive semidefinite matrices, called the Riemannian manifold. We hypothesize that representational similarities would be more accurately quantified by considering the underlying manifold of the representational matrices. Thus, we introduce the distance on the Riemannian manifold as a metric for comparing representations. Analyzing simulated and real fMRI data and considering a wide range of metrics, we show that the Riemannian distance is least susceptible to sampling bias, results in larger intra-subject reliability, and affords searchlight mapping with high sensitivity and specificity. Furthermore, we show that the Riemannian distance can be used for measuring multi-dimensional connectivity. This measure captures both univariate and multivariate connectivity and is also more sensitive to nonlinear regional interactions compared to the state-of-the-art measures. Applying our proposed metric to neural network representations of natural images, we demonstrate that it also possesses outstanding performance in quantifying similarity in models. Taken together, our results lend credence to the proposition that RSA should consider the manifold of the representational matrices to summarize response patterns in the brain and in models.},
	language = {en},
	urldate = {2021-11-02},
	journal = {NeuroImage},
	author = {Shahbazi, Mahdiyar and Shirali, Ali and Aghajan, Hamid and Nili, Hamed},
	month = oct,
	year = {2021},
	pages = {118271},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/TFKN2YQU/S1053811921005474.html:text/html;Shahbazi et al_2021_Using distance on the Riemannian manifold to compare representations in brain.pdf:/Users/tito/Zotero/storage/7T3IEUR4/Shahbazi et al_2021_Using distance on the Riemannian manifold to compare representations in brain.pdf:application/pdf},
}

@article{tik_predicting_2021,
	title = {Predicting individual variability in task-evoked brain activity in schizophrenia},
	volume = {42},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.25534},
	doi = {10.1002/hbm.25534},
	abstract = {What goes wrong in a schizophrenia patient's brain that makes it so different from a healthy brain? In this study, we tested the hypothesis that the abnormal brain activity in schizophrenia is tightly related to alterations in brain connectivity. Using functional magnetic resonance imaging (fMRI), we demonstrated that both resting-state functional connectivity and brain activity during the well-validated N-back task differed significantly between schizophrenia patients and healthy controls. Nevertheless, using a machine-learning approach we were able to use resting-state functional connectivity measures extracted from healthy controls to accurately predict individual variability in the task-evoked brain activation in the schizophrenia patients. The predictions were highly accurate, sensitive, and specific, offering novel insights regarding the strong coupling between brain connectivity and activity in schizophrenia. On a practical perspective, these findings may allow to generate task activity maps for clinical populations without the need to actually perform any tasks, thereby reducing patients inconvenience while saving time and money.},
	language = {en},
	number = {12},
	urldate = {2021-11-02},
	journal = {Human Brain Mapping},
	author = {Tik, Niv and Livny, Abigail and Gal, Shachar and Gigi, Karny and Tsarfaty, Galia and Weiser, Mark and Tavor, Ido},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25534},
	keywords = {fMRI, Connectome, machine learning, schizophrenia, resting-state, cognitive function},
	pages = {3983--3992},
	file = {Snapshot:/Users/tito/Zotero/storage/PG7G5ECR/hbm.html:text/html;Tik et al_2021_Predicting individual variability in task-evoked brain activity in schizophrenia.pdf:/Users/tito/Zotero/storage/PHSAF2YL/Tik et al_2021_Predicting individual variability in task-evoked brain activity in schizophrenia.pdf:application/pdf},
}

@inproceedings{kornblith_similarity_2019,
	title = {Similarity of {Neural} {Network} {Representations} {Revisited}},
	url = {https://proceedings.mlr.press/v97/kornblith19a.html},
	abstract = {Recent work has sought to understand the behavior of neural networks by comparing representations between layers and between different trained models. We examine methods for comparing neural network representations based on canonical correlation analysis (CCA). We show that CCA belongs to a family of statistics for measuring multivariate similarity, but that neither CCA nor any other statistic that is invariant to invertible linear transformation can measure meaningful similarities between representations of higher dimension than the number of data points. We introduce a similarity index that measures the relationship between representational similarity matrices and does not suffer from this limitation. This similarity index is equivalent to centered kernel alignment (CKA) and is also closely connected to CCA. Unlike CCA, CKA can reliably identify correspondences between representations in networks trained from different initializations.},
	language = {en},
	urldate = {2021-11-04},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {3519--3529},
	file = {Kornblith et al_2019_Similarity of Neural Network Representations Revisited.pdf:/Users/tito/Zotero/storage/8HIRFA3U/Kornblith et al_2019_Similarity of Neural Network Representations Revisited.pdf:application/pdf;Supplementary PDF:/Users/tito/Zotero/storage/M24LNFV7/Kornblith et al. - 2019 - Similarity of Neural Network Representations Revis.pdf:application/pdf},
}

@article{nader_positive_2019,
	title = {On the positive semi-definite property of similarity matrices},
	volume = {755},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397518304687},
	doi = {10.1016/j.tcs.2018.06.052},
	abstract = {The notion of similarity is a fundamental concept in different scientific fields. Similarity measures aim at quantifying the extent to which objects resemble each other. This paper is concerned with the analysis of the properties of similarity matrices. More specifically, we focus on their positive semi-definite property, which is important to derive useful distances between data sets. Based on some general results, we show that most of classical similarity matrices have this property.},
	language = {en},
	urldate = {2021-11-05},
	journal = {Theoretical Computer Science},
	author = {Nader, Rafic and Bretto, Alain and Mourad, Bassam and Abbas, Hassan},
	month = jan,
	year = {2019},
	keywords = {Positive definite matrices, Positive semi-definite matrices, Similarity matrices, Similarity measures, Three-positive semi-definite matrices},
	pages = {13--28},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/J4854N3S/S0304397518304687.html:text/html},
}

@article{mukherjee_thalamic_2021,
	title = {Thalamic circuits for independent control of prefrontal signal and noise},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-021-04056-3},
	doi = {10.1038/s41586-021-04056-3},
	language = {en},
	urldate = {2021-11-05},
	journal = {Nature},
	author = {Mukherjee, Arghya and Lam, Norman H. and Wimmer, Ralf D. and Halassa, Michael M.},
	month = oct,
	year = {2021},
	file = {Mukherjee et al. - 2021 - Thalamic circuits for independent control of prefr.pdf:/Users/tito/Zotero/storage/CL6TRRD8/Mukherjee et al. - 2021 - Thalamic circuits for independent control of prefr.pdf:application/pdf},
}

@article{turchi_basal_2018,
	title = {The {Basal} {Forebrain} {Regulates} {Global} {Resting}-{State} {fMRI} {Fluctuations}},
	volume = {97},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(18)30057-6},
	doi = {10.1016/j.neuron.2018.01.032},
	language = {English},
	number = {4},
	urldate = {2021-11-09},
	journal = {Neuron},
	author = {Turchi, Janita and Chang, Catie and Ye, Frank Q. and Russ, Brian E. and Yu, David K. and Cortes, Carlos R. and Monosov, Ilya E. and Duyn, Jeff H. and Leopold, David A.},
	month = feb,
	year = {2018},
	pmid = {29398365},
	note = {Publisher: Elsevier},
	keywords = {fMRI, functional connectivity, resting-state networks, cerebral cortex, global signal, macaque, arousal, basal forebrain, nucleus basalis, ongoing activity},
	pages = {940--952.e4},
	file = {Snapshot:/Users/tito/Zotero/storage/BW73CP6Z/S0896-6273(18)30057-6.html:text/html;Turchi et al_2018_The Basal Forebrain Regulates Global Resting-State fMRI Fluctuations.pdf:/Users/tito/Zotero/storage/HNAPUSDI/Turchi et al_2018_The Basal Forebrain Regulates Global Resting-State fMRI Fluctuations.pdf:application/pdf},
}

@article{grossman_noisy_2019,
	title = {The {Noisy} {Brain}: {Power} of {Resting}-{State} {Fluctuations} {Predicts} {Individual} {Recognition} {Performance}},
	volume = {29},
	issn = {2211-1247},
	shorttitle = {The {Noisy} {Brain}},
	url = {https://www.cell.com/cell-reports/abstract/S2211-1247(19)31572-4},
	doi = {10.1016/j.celrep.2019.11.081},
	language = {English},
	number = {12},
	urldate = {2021-11-09},
	journal = {Cell Reports},
	author = {Grossman, Shany and Yeagle, Erin M. and Harel, Michal and Espinal, Elizabeth and Harpaz, Roy and Noy, Niv and Mégevand, Pierre and Groppe, David M. and Mehta, Ashesh D. and Malach, Rafael},
	month = dec,
	year = {2019},
	pmid = {31851911},
	note = {Publisher: Elsevier},
	keywords = {individual differences, resting state, neural noise, ECoG, neural variability, 1-back task, cognitive abilities, iEEG, spontaneous fluctuations},
	pages = {3775--3784.e4},
	file = {Grossman et al_2019_The Noisy Brain.pdf:/Users/tito/Zotero/storage/8KDCNFGU/Grossman et al_2019_The Noisy Brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/FK6QDCAP/S2211-1247(19)31572-4.html:text/html},
}

@article{pinho_individual_2018,
	title = {Individual {Brain} {Charting}, a high-resolution {fMRI} dataset for cognitive mapping},
	volume = {5},
	copyright = {2018 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata2018105},
	doi = {10.1038/sdata.2018.105},
	abstract = {Functional Magnetic Resonance Imaging (fMRI) has furthered brain mapping on perceptual, motor, as well as higher-level cognitive functions. However, to date, no data collection has systematically addressed the functional mapping of cognitive mechanisms at a fine spatial scale. The Individual Brain Charting (IBC) project stands for a high-resolution multi-task fMRI dataset that intends to provide the objective basis toward a comprehensive functional atlas of the human brain. The data refer to a cohort of 12 participants performing many different tasks. The large amount of task-fMRI data on the same subjects yields a precise mapping of the underlying functions, free from both inter-subject and inter-site variability. The present article gives a detailed description of the first release of the IBC dataset. It comprises a dozen of tasks, addressing both low- and high- level cognitive functions. This openly available dataset is thus intended to become a reference for cognitive brain mapping.},
	language = {en},
	number = {1},
	urldate = {2021-11-09},
	journal = {Sci Data},
	author = {Pinho, Ana Luísa and Amadon, Alexis and Ruest, Torsten and Fabre, Murielle and Dohmatob, Elvis and Denghien, Isabelle and Ginisty, Chantal and Becuwe-Desmidt, Séverine and Roger, Séverine and Laurier, Laurence and Joly-Testault, Véronique and Médiouni-Cloarec, Gaëlle and Doublé, Christine and Martins, Bernadette and Pinel, Philippe and Eger, Evelyn and Varoquaux, Gaël and Pallier, Christophe and Dehaene, Stanislas and Hertz-Pannier, Lucie and Thirion, Bertrand},
	month = jun,
	year = {2018},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_publicdomain
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Attention;Cognitive control;Decision;Language;Magnetic resonance imaging
Subject\_term\_id: attention;cognitive-control;decision;language;magnetic-resonance-imaging},
	keywords = {Language, Attention, Cognitive control, Magnetic resonance imaging, Decision},
	pages = {180105},
	file = {Pinho et al_2018_Individual Brain Charting, a high-resolution fMRI dataset for cognitive mapping.pdf:/Users/tito/Zotero/storage/2778R9EJ/Pinho et al_2018_Individual Brain Charting, a high-resolution fMRI dataset for cognitive mapping.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9NH8DLH8/sdata2018105.html:text/html},
}

@article{arbuckle_structure_2020,
	title = {Structure of {Population} {Activity} in {Primary} {Motor} {Cortex} for {Single} {Finger} {Flexion} and {Extension}},
	volume = {40},
	copyright = {Copyright © 2020 the authors. SfN exclusive license.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/40/48/9210},
	doi = {10.1523/JNEUROSCI.0999-20.2020},
	abstract = {How is the primary motor cortex (M1) organized to control fine finger movements? We investigated the population activity in M1 for single finger flexion and extension, using 7T functional magnetic resonance imaging (fMRI) in female and male human participants and compared these results to the neural spiking patterns recorded in two male monkeys performing the identical task. fMRI activity patterns were distinct for movements of different fingers, but were quite similar for flexion and extension of the same finger. In contrast, spiking patterns in monkeys were quite distinct for both fingers and directions, which is similar to what was found for muscular activity patterns. The discrepancy between fMRI and electrophysiological measurements can be explained by two (non-mutually exclusive) characteristics of the organization of finger flexion and extension movements. Given that fMRI reflects predominantly input and recurrent activity, the results can be explained by an architecture in which neural populations that control flexion or extension of the same finger produce distinct outputs, but interact tightly with each other and receive similar inputs. Additionally, neurons tuned to different movement directions for the same finger (or combination of fingers) may cluster closely together, while neurons that control different finger combinations may be more spatially separated. When measuring this organization with fMRI at a coarse spatial scale, the activity patterns for flexion and extension of the same finger would appear very similar. Overall, we suggest that the discrepancy between fMRI and electrophysiological measurements provides new insights into the general organization of fine finger movements in M1.
SIGNIFICANCE STATEMENT The primary motor cortex (M1) is important for producing individuated finger movements. Recent evidence shows that movements that commonly co-occur are associated with more similar activity patterns in M1. Flexion and extension of the same finger, which never co-occur, should therefore be associated with distinct representations. However, using carefully controlled experiments and multivariate analyses, we demonstrate that human fMRI activity patterns for flexion or extension of the same finger are highly similar. In contrast, spiking patterns measured in monkey M1 are clearly distinct. This suggests that populations controlling opposite movements of the same finger, while producing distinct outputs, may cluster together and share inputs and local processing. These results provide testable hypotheses about the organization of hand control in M1.},
	language = {en},
	number = {48},
	urldate = {2021-11-11},
	journal = {J. Neurosci.},
	author = {Arbuckle, Spencer A. and Weiler, Jeff and Kirk, Eric A. and Rice, Charles L. and Schieber, Marc and Pruszynski, J. Andrew and Ejaz, Naveed and Diedrichsen, Jörn},
	month = nov,
	year = {2020},
	pmid = {33087474},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {fMRI, electrophysiology, humans, fingers, hand control, monkeys, primary motor cortex},
	pages = {9210--9223},
	file = {Arbuckle et al_2020_Structure of Population Activity in Primary Motor Cortex for Single Finger.pdf:/Users/tito/Zotero/storage/ANDAPBNP/Arbuckle et al_2020_Structure of Population Activity in Primary Motor Cortex for Single Finger.pdf:application/pdf},
}

@techreport{beiran_parametric_2021,
	title = {Parametric control of flexible timing through low-dimensional neural manifolds},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.11.08.467806v1},
	abstract = {Biological brains possess an unparalleled ability to generalize adaptive behavioral responses from only a few examples. How neural processes enable this capacity to extrapolate is a fundamental open question. A prominent but underexplored hypothesis suggests that generalization is facilitated by a low-dimensional organization of collective neural activity. Here we tested this hypothesis in the framework of flexible timing tasks where dynamics play a key role. Examining trained recurrent neural networks we found that confining the dynamics to a low-dimensional subspace allowed tonic inputs to parametrically control the overall input-output transform and enabled smooth extrapolation to inputs well beyond the training range. Reverse-engineering and theoretical analyses demonstrated that this parametric control of extrapolation relies on a mechanism where tonic inputs modulate the dynamics along non-linear manifolds in activity space while preserving their geometry. Comparisons with neural data from behaving monkeys confirmed the geometric and dynamical signatures of this mechanism.},
	language = {en},
	urldate = {2021-11-11},
	author = {Beiran, Manuel and Meirhaeghe, Nicolas and Sohn, Hansem and Jazayeri, Mehrdad and Ostojic, Srdjan},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.08.467806},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.11.08.467806},
	file = {Beiran et al_2021_Parametric control of flexible timing through low-dimensional neural manifolds.pdf:/Users/tito/Zotero/storage/555W3TEN/Beiran et al_2021_Parametric control of flexible timing through low-dimensional neural manifolds.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/J7MIGVAK/2021.11.08.html:text/html},
}

@article{van_bergen_going_2020,
	series = {Whole-brain interactions between neural circuits},
	title = {Going in circles is the way forward: the role of recurrence in visual inference},
	volume = {65},
	issn = {0959-4388},
	shorttitle = {Going in circles is the way forward},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438820301768},
	doi = {10.1016/j.conb.2020.11.009},
	abstract = {Biological visual systems exhibit abundant recurrent connectivity. State-of-the-art neural network models for visual recognition, by contrast, rely heavily or exclusively on feedforward computation. Any finite-time recurrent neural network (RNN) can be unrolled along time to yield an equivalent feedforward neural network (FNN). This important insight suggests that computational neuroscientists may not need to engage recurrent computation, and that computer-vision engineers may be limiting themselves to a special case of FNN if they build recurrent models. Here we argue, to the contrary, that FNNs are a special case of RNNs and that computational neuroscientists and engineers should engage recurrence to understand how brains and machines can (1) achieve greater and more flexible computational depth (2) compress complex computations into limited hardware (3) integrate priors and priorities into visual inference through expectation and attention (4) exploit sequential dependencies in their data for better inference and prediction and (5) leverage the power of iterative computation.},
	language = {en},
	urldate = {2021-11-12},
	journal = {Current Opinion in Neurobiology},
	author = {van Bergen, Ruben S and Kriegeskorte, Nikolaus},
	month = dec,
	year = {2020},
	pages = {176--193},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/XMT4CL9G/S0959438820301768.html:text/html;van Bergen_Kriegeskorte_2020_Going in circles is the way forward.pdf:/Users/tito/Zotero/storage/B238RQPZ/van Bergen_Kriegeskorte_2020_Going in circles is the way forward.pdf:application/pdf},
}

@techreport{lin_predicting_2021,
	title = {Predicting human decision making in psychological tasks with recurrent neural networks},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.11.15.468588v1},
	abstract = {Unlike traditional time series, the action sequences of human decision making usually involve many cognitive processes such as beliefs, desires, intentions and theory of mind, i.e. what others are thinking. This makes predicting human decision making challenging to be treated agnostically to the underlying psychological mechanisms. We propose to use a recurrent neural network architecture based on long short-term memory networks (LSTM) to predict the time series of the actions taken by the human subjects at each step of their decision making, the first application of such methods in this research domain. In this study, we collate the human data from 8 published literature of the Iterated Prisoner's Dilemma comprising 168,386 individual decisions and postprocess them into 8,257 behavioral trajectories of 9 actions each for both players. Similarly, we collate 617 trajectories of 95 actions from 10 different published studies of Iowa Gambling Task experiments with healthy human subjects. We train our prediction networks on the behavioral data from these published psychological experiments of human decision making, and demonstrate a clear advantage over the state-of-the-art methods in predicting human decision making trajectories in both single-agent scenarios such as the Iowa Gambling Task and multi-agent scenarios such as the Iterated Prisoner's Dilemma. In the prediction, we observe that the weights of the top performers tends to have a wider distribution, and a bigger bias in the LSTM networks, which suggests possible interpretations for the distribution of strategies adopted by each group.},
	language = {en},
	urldate = {2021-11-16},
	author = {Lin, Baihan and Bouneffouf, Djallel and Cecchi, Guillermo},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.15.468588},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.11.15.468588},
	file = {Lin et al_2021_Predicting human decision making in psychological tasks with recurrent neural.pdf:/Users/tito/Zotero/storage/YSTGUVMI/Lin et al_2021_Predicting human decision making in psychological tasks with recurrent neural.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/9SMMV855/2021.11.15.html:text/html},
}

@article{barch_cognition_2012,
	series = {Special {Issue}: {Cognition} in {Neuropsychiatric} {Disorders}},
	title = {Cognition in schizophrenia: core psychological and neural mechanisms},
	volume = {16},
	issn = {1364-6613},
	shorttitle = {Cognition in schizophrenia},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661311002488},
	doi = {10.1016/j.tics.2011.11.015},
	abstract = {The challenge in understanding cognitive impairment in schizophrenia is that people with this illness have deficits in an array of domains. Here, we briefly review evidence regarding the pattern of deficits within three domains: context processing, working memory and episodic memory. We suggest that there may be a common mechanism driving deficits in these domains – an impairment in the ability to actively represent goal information in working memory to guide behavior, a function we refer to as proactive control. We suggest that such deficits in proactive control reflect impairments in dorsolateral prefrontal cortex, its interactions with other brain regions, such as parietal cortex, thalamus and striatum, and the influence of neurotransmitter systems, such as dopamine, GABA and glutamate.},
	language = {en},
	number = {1},
	urldate = {2021-11-17},
	journal = {Trends in Cognitive Sciences},
	author = {Barch, Deanna M. and Ceaser, Alan},
	month = jan,
	year = {2012},
	pages = {27--34},
	file = {Barch_Ceaser_2012_Cognition in schizophrenia.pdf:/Users/tito/Zotero/storage/E6IVZITN/Barch_Ceaser_2012_Cognition in schizophrenia.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/B7GQIMRP/S1364661311002488.html:text/html},
}

@article{spronk_whole-brain_2021,
	title = {A {Whole}-{Brain} and {Cross}-{Diagnostic} {Perspective} on {Functional} {Brain} {Network} {Dysfunction}},
	volume = {31},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhaa242},
	doi = {10.1093/cercor/bhaa242},
	abstract = {A wide variety of mental disorders have been associated with resting-state functional network alterations, which are thought to contribute to the cognitive changes underlying mental illness. These observations appear to support theories postulating large-scale disruptions of brain systems in mental illness. However, existing approaches isolate differences in network organization without putting those differences in a broad, whole-brain perspective. Using a graph distance approach—connectome-wide similarity—we found that whole-brain resting-state functional network organization is highly similar across groups of individuals with and without a variety of mental diseases. This similarity was observed across autism spectrum disorder, attention-deficit hyperactivity disorder, and schizophrenia. Nonetheless, subtle differences in network graph distance were predictive of diagnosis, suggesting that while functional connectomes differ little across health and disease, those differences are informative. These results suggest a need to reevaluate neurocognitive theories of mental illness, with a role for subtle functional brain network changes in the production of an array of mental diseases. Such small network alterations suggest the possibility that small, well-targeted alterations to brain network organization may provide meaningful improvements for a variety of mental disorders.},
	number = {1},
	urldate = {2021-11-17},
	journal = {Cerebral Cortex},
	author = {Spronk, Marjolein and Keane, Brian P and Ito, Takuya and Kulkarni, Kaustubh and Ji, Jie Lisa and Anticevic, Alan and Cole, Michael W},
	month = jan,
	year = {2021},
	pages = {547--561},
	file = {Spronk et al_2021_A Whole-Brain and Cross-Diagnostic Perspective on Functional Brain Network.pdf:/Users/tito/Zotero/storage/TN4EAAMQ/Spronk et al_2021_A Whole-Brain and Cross-Diagnostic Perspective on Functional Brain Network.pdf:application/pdf},
}

@article{chung_neural_2021-1,
	title = {Neural population geometry: {An} approach for understanding biological and artificial neural networks},
	volume = {70},
	issn = {0959-4388},
	shorttitle = {Neural population geometry},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438821001227},
	doi = {10.1016/j.conb.2021.10.010},
	abstract = {Advances in experimental neuroscience have transformed our ability to explore the structure and function of neural circuits. At the same time, advances in machine learning have unleashed the remarkable computational power of artificial neural networks (ANNs). While these two fields have different tools and applications, they present a similar challenge: namely, understanding how information is embedded and processed through high-dimensional representations to solve complex tasks. One approach to addressing this challenge is to utilize mathematical and computational tools to analyze the geometry of these high-dimensional representations, i.e., neural population geometry. We review examples of geometrical approaches providing insight into the function of biological and artificial neural networks: representation untangling in perception, a geometric theory of classification capacity, disentanglement, and abstraction in cognitive systems, topological representations underlying cognitive maps, dynamic untangling in motor systems, and a dynamical approach to cognition. Together, these findings illustrate an exciting trend at the intersection of machine learning, neuroscience, and geometry, in which neural population geometry provides a useful population-level mechanistic descriptor underlying task implementation. Importantly, geometric descriptions are applicable across sensory modalities, brain regions, network architectures, and timescales. Thus, neural population geometry has the potential to unify our understanding of structure and function in biological and artificial neural networks, bridging the gap between single neurons, population activities, and behavior.},
	language = {en},
	urldate = {2021-11-22},
	journal = {Current Opinion in Neurobiology},
	author = {Chung, SueYeon and Abbott, L. F.},
	month = oct,
	year = {2021},
	pages = {137--144},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/VVQBR9JL/S0959438821001227.html:text/html},
}

@article{frey_magnetic_2021,
	title = {Magnetic resonance-based eye tracking using deep neural networks},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-021-00947-w},
	doi = {10.1038/s41593-021-00947-w},
	abstract = {Viewing behavior provides a window into many central aspects of human cognition and health, and it is an important variable of interest or confound in many functional magnetic resonance imaging (fMRI) studies. To make eye tracking freely and widely available for MRI research, we developed DeepMReye, a convolutional neural network (CNN) that decodes gaze position from the magnetic resonance signal of the eyeballs. It performs cameraless eye tracking at subimaging temporal resolution in held-out participants with little training data and across a broad range of scanning protocols. Critically, it works even in existing datasets and when the eyes are closed. Decoded eye movements explain network-wide brain activity also in regions not associated with oculomotor function. This work emphasizes the importance of eye tracking for the interpretation of fMRI results and provides an open source software solution that is widely applicable in research and clinical settings.},
	language = {en},
	urldate = {2021-11-23},
	journal = {Nat Neurosci},
	author = {Frey, Markus and Nau, Matthias and Doeller, Christian F.},
	month = nov,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Cognitive neuroscience;Computational neuroscience;Oculomotor system;Visual system
Subject\_term\_id: cognitive-neuroscience;computational-neuroscience;oculomotor-system;visual-system},
	keywords = {Cognitive neuroscience, Visual system, Computational neuroscience, Oculomotor system},
	pages = {1--8},
	file = {Frey et al_2021_Magnetic resonance-based eye tracking using deep neural networks.pdf:/Users/tito/Zotero/storage/THKRTIRR/Frey et al_2021_Magnetic resonance-based eye tracking using deep neural networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/CP35ASK5/s41593-021-00947-w.html:text/html},
}

@article{doya_toward_2019,
	series = {Artificial {Intelligence}},
	title = {Toward evolutionary and developmental intelligence},
	volume = {29},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154618302225},
	doi = {10.1016/j.cobeha.2019.04.006},
	abstract = {Given the phenomenal advances in artificial intelligence in specific domains like visual object recognition and game playing by deep learning, expectations are rising for building artificial general intelligence (AGI) that can flexibly find solutions in unknown task domains. One approach to AGI is to set up a variety of tasks and design AI agents that perform well in many of them, including those the agent faces for the first time. One caveat for such an approach is that the best performing agent may be just a collection of domain-specific AI agents switched for a given domain. Here we propose an alternative approach of focusing on the process of acquisition of intelligence through active interactions in an environment. We call this approach evolutionary and developmental intelligence (EDI). We first review the current status of artificial intelligence, brain-inspired computing and developmental robotics and define the conceptual framework of EDI. We then explore how we can integrate advances in neuroscience, machine learning, and robotics to construct EDI systems and how building such systems can help us understand animal and human intelligence.},
	language = {en},
	urldate = {2021-11-24},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Doya, Kenji and Taniguchi, Tadahiro},
	month = oct,
	year = {2019},
	pages = {91--96},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/S43UKJL8/S2352154618302225.html:text/html},
}

@article{martin_state-related_2021,
	title = {State-related neural influences on {fMRI} connectivity estimation},
	volume = {244},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921008636},
	doi = {10.1016/j.neuroimage.2021.118590},
	abstract = {The spatiotemporal structure of functional magnetic resonance imaging (fMRI) signals has provided a valuable window into the network underpinnings of human brain function and dysfunction. Although some cross-regional temporal correlation patterns (functional connectivity; FC) exhibit a high degree of stability across individuals and species, there is growing acknowledgment that measures of FC can exhibit marked changes over a range of temporal scales. Further, FC can co-vary with experimental task demands and ongoing neural processes linked to arousal, consciousness and perception, cognitive and affective state, and brain-body interactions. The increased recognition that such interrelated neural processes modulate FC measurements has raised both challenges and new opportunities in using FC to investigate brain function. Here, we review recent advances in the quantification of neural effects that shape fMRI FC and discuss the broad implications of these findings in the design and analysis of fMRI studies. We also discuss how a more complete understanding of the neural factors that shape FC measurements can resolve apparent inconsistencies in the literature and lead to more interpretable conclusions from fMRI studies.},
	language = {en},
	urldate = {2021-11-25},
	journal = {NeuroImage},
	author = {Martin, Caroline G. and He, Biyu J. and Chang, Catie},
	month = dec,
	year = {2021},
	pages = {118590},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/SDYX9F43/S1053811921008636.html:text/html},
}

@article{yarkoni_large-scale_2011-1,
	title = {Large-scale automated synthesis of human functional neuroimaging data},
	volume = {8},
	copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.1635},
	doi = {10.1038/nmeth.1635},
	abstract = {A framework and web interface for the large-scale and automated synthesis of human neuroimaging data extracted from the literature is presented. It is used to generate a large database of mappings between neural and cognitive states and to address long-standing inferential problems in the neuroimaging literature.},
	language = {en},
	number = {8},
	urldate = {2021-11-26},
	journal = {Nat Methods},
	author = {Yarkoni, Tal and Poldrack, Russell A. and Nichols, Thomas E. and Van Essen, David C. and Wager, Tor D.},
	month = aug,
	year = {2011},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 8
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Bioinformatics;Imaging;Neuroscience
Subject\_term\_id: bioinformatics;imaging;neuroscience},
	keywords = {Neuroscience, Bioinformatics, Imaging},
	pages = {665--670},
	file = {Snapshot:/Users/tito/Zotero/storage/5L2MINLV/nmeth.html:text/html;Yarkoni et al_2011_Large-scale automated synthesis of human functional neuroimaging data.pdf:/Users/tito/Zotero/storage/HT83XXYR/Yarkoni et al_2011_Large-scale automated synthesis of human functional neuroimaging data.pdf:application/pdf},
}

@article{funahashi_mnemonic_1989,
	title = {Mnemonic coding of visual space in the monkey's dorsolateral prefrontal cortex},
	volume = {61},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/abs/10.1152/jn.1989.61.2.331},
	doi = {10.1152/jn.1989.61.2.331},
	abstract = {1. An oculomotor delayed-response task was used to examine the spatial memory functions of neurons in primate prefrontal cortex. Monkeys were trained to fixate a central spot during a brief presentation (0.5 s) of a peripheral cue and throughout a subsequent delay period (1-6 s), and then, upon the extinction of the fixation target, to make a saccadic eye movement to where the cue had been presented. Cues were usually presented in one of eight different locations separated by 45 degrees. This task thus requires monkeys to direct their gaze to the location of a remembered visual cue, controls the retinal coordinates of the visual cues, controls the monkey's oculomotor behavior during the delay period, and also allows precise measurement of the timing and direction of the relevant behavioral responses. 2. Recordings were obtained from 288 neurons in the prefrontal cortex within and surrounding the principal sulcus (PS) while monkeys performed this task. An additional 31 neurons in the frontal eye fields (FEF) region within and near the anterior bank of the arcuate sulcus were also studied. 3. Of the 288 PS neurons, 170 exhibited task-related activity during at least one phase of this task and, of these, 87 showed significant excitation or inhibition of activity during the delay period relative to activity during the intertrial interval. 4. Delay period activity was classified as directional for 79\% of these 87 neurons in that significant responses only occurred following cues located over a certain range of visual field directions and were weak or absent for other cue directions. The remaining 21\% were omnidirectional, i.e., showed comparable delay period activity for all visual field locations tested. Directional preferences, or lack thereof, were maintained across different delay intervals (1-6 s). 5. For 50 of the 87 PS neurons, activity during the delay period was significantly elevated above the neuron's spontaneous rate for at least one cue location; for the remaining 37 neurons only inhibitory delay period activity was seen. Nearly all (92\%) neurons with excitatory delay period activity were directional and few (8\%) were omnidirectional. Most (62\%) neurons with purely inhibitory delay period activity were directional, but a substantial minority (38\%) was omnidirectional. 6. Fifteen of the neurons with excitatory directional delay period activity also had significant inhibitory delay period activity for other cue directions. These inhibitory responses were usually strongest for, or centered about, cue directions roughly opposite those optimal for excitatory responses.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	urldate = {2021-11-26},
	journal = {Journal of Neurophysiology},
	author = {Funahashi, S. and Bruce, C. J. and Goldman-Rakic, P. S.},
	month = feb,
	year = {1989},
	note = {Publisher: American Physiological Society},
	pages = {331--349},
	file = {Funahashi et al_1989_Mnemonic coding of visual space in the monkey's dorsolateral prefrontal cortex.pdf:/Users/tito/Zotero/storage/AG4LRPAR/Funahashi et al_1989_Mnemonic coding of visual space in the monkey's dorsolateral prefrontal cortex.pdf:application/pdf},
}

@article{naselaris_extensive_2021,
	series = {Deep {Imaging} - {Personalized} {Neuroscience}},
	title = {Extensive sampling for complete models of individual brains},
	volume = {40},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154620301960},
	doi = {10.1016/j.cobeha.2020.12.008},
	abstract = {In designing cognitive neuroscience experiments, resource limitations induce a fundamental trade-off between sampling variation across individual brains and sampling variation across experimental conditions. Here, we argue that extensive sampling of experimental conditions is essential for understanding how human brains process complex stimuli, that a model of how any one brain does this is likely to generalize to most other brains, and that introducing large numbers of subjects into an analysis pool is likely to introduce unnecessary and undesirable variance. Thus, contrary to conventional wisdom, we believe that sampling many individuals provides relatively few benefits and that extensive sampling of a limited number of subjects is more productive for revealing general principles. Furthermore, an emphasis on depth in individual brains is well-suited for capitalizing on the improvements in resolution and signal-to-noise ratio that are being achieved in modern neuroscientific measurement techniques.},
	language = {en},
	urldate = {2021-11-27},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Naselaris, Thomas and Allen, Emily and Kay, Kendrick},
	month = aug,
	year = {2021},
	pages = {45--51},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/P3Z4QIRW/S2352154620301960.html:text/html},
}

@article{penfield_somatic_1937,
	title = {Somatic motor and sensory representation in the cerebral cortex of man as studied by electrical stimulation},
	volume = {60},
	number = {4},
	journal = {Brain},
	author = {Penfield, Wilder and Boldrey, Edwin},
	year = {1937},
	note = {Publisher: Citeseer},
	pages = {389--443},
	file = {Penfield_Boldrey_1937_Somatic motor and sensory representation in the cerebral cortex of man as.pdf:/Users/tito/Zotero/storage/GPKXVXN3/Penfield_Boldrey_1937_Somatic motor and sensory representation in the cerebral cortex of man as.pdf:application/pdf},
}

@article{curtis_persistent_2003,
	title = {Persistent activity in the prefrontal cortex during working memory},
	volume = {7},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661303001979},
	doi = {10.1016/S1364-6613(03)00197-9},
	abstract = {The dorsolateral prefrontal cortex (DLPFC) plays a crucial role in working memory. Notably, persistent activity in the DLPFC is often observed during the retention interval of delayed response tasks. The code carried by the persistent activity remains unclear, however. We critically evaluate how well recent findings from functional magnetic resonance imaging studies are compatible with current models of the role of the DLFPC in working memory. These new findings suggest that the DLPFC aids in the maintenance of information by directing attention to internal representations of sensory stimuli and motor plans that are stored in more posterior regions.},
	language = {en},
	number = {9},
	urldate = {2021-11-27},
	journal = {Trends in Cognitive Sciences},
	author = {Curtis, Clayton E. and D'Esposito, Mark},
	month = sep,
	year = {2003},
	pages = {415--423},
	file = {Curtis_D'Esposito_2003_Persistent activity in the prefrontal cortex during working memory.pdf:/Users/tito/Zotero/storage/VFNQMZRA/Curtis_D'Esposito_2003_Persistent activity in the prefrontal cortex during working memory.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/E2R5THBQ/S1364661303001979.html:text/html},
}

@article{kell_task-optimized_2018,
	title = {A {Task}-{Optimized} {Neural} {Network} {Replicates} {Human} {Auditory} {Behavior}, {Predicts} {Brain} {Responses}, and {Reveals} a {Cortical} {Processing} {Hierarchy}},
	volume = {98},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627318302502},
	doi = {10.1016/j.neuron.2018.03.044},
	abstract = {A core goal of auditory neuroscience is to build quantitative models that predict cortical responses to natural sounds. Reasoning that a complete model of auditory cortex must solve ecologically relevant tasks, we optimized hierarchical neural networks for speech and music recognition. The best-performing network contained separate music and speech pathways following early shared processing, potentially replicating human cortical organization. The network performed both tasks as well as humans and exhibited human-like errors despite not being optimized to do so, suggesting common constraints on network and human performance. The network predicted fMRI voxel responses substantially better than traditional spectrotemporal filter models throughout auditory cortex. It also provided a quantitative signature of cortical representational hierarchy—primary and non-primary responses were best predicted by intermediate and late network layers, respectively. The results suggest that task optimization provides a powerful set of tools for modeling sensory systems.},
	language = {en},
	number = {3},
	urldate = {2021-11-27},
	journal = {Neuron},
	author = {Kell, Alexander J. E. and Yamins, Daniel L. K. and Shook, Erica N. and Norman-Haignere, Sam V. and McDermott, Josh H.},
	month = may,
	year = {2018},
	keywords = {fMRI, deep learning, hierarchy, auditory cortex, convolutional neural network, deep neural network, encoding models, human auditory cortex, natural sounds, word recognition},
	pages = {630--644.e16},
	file = {Kell et al_2018_A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts.pdf:/Users/tito/Zotero/storage/PJTIENA8/Kell et al_2018_A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts.pdf:application/pdf},
}

@article{yang_how_2019,
	series = {Artificial {Intelligence}},
	title = {How to study the neural mechanisms of multiple tasks},
	volume = {29},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154619300695},
	doi = {10.1016/j.cobeha.2019.07.001},
	abstract = {Most biological and artificial neural systems are capable of completing multiple tasks. However, the neural mechanism by which multiple tasks are accomplished within the same system is largely unclear. We start by discussing how different tasks can be related, and methods to generate large sets of inter-related tasks to study how neural networks and animals perform multiple tasks. We then argue that there are mechanisms that emphasize either specialization or flexibility. We will review two such neural mechanisms underlying multiple tasks at the neuronal level (modularity and mixed selectivity), and discuss how different mechanisms can emerge depending on training methods in neural networks.},
	language = {en},
	urldate = {2021-11-27},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Yang, Guangyu Robert and Cole, Michael W and Rajan, Kanaka},
	month = oct,
	year = {2019},
	pages = {134--143},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/I8ZQ2K63/S2352154619300695.html:text/html;Yang et al_2019_How to study the neural mechanisms of multiple tasks.pdf:/Users/tito/Zotero/storage/AMXJFNQH/Yang et al_2019_How to study the neural mechanisms of multiple tasks.pdf:application/pdf},
}

@article{hadsell_embracing_2020,
	title = {Embracing {Change}: {Continual} {Learning} in {Deep} {Neural} {Networks}},
	volume = {24},
	issn = {1364-6613, 1879-307X},
	shorttitle = {Embracing {Change}},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(20)30219-9},
	doi = {10.1016/j.tics.2020.09.004},
	language = {English},
	number = {12},
	urldate = {2021-11-27},
	journal = {Trends in Cognitive Sciences},
	author = {Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A. and Pascanu, Razvan},
	month = dec,
	year = {2020},
	pmid = {33158755},
	note = {Publisher: Elsevier},
	keywords = {artificial intelligence, memory, lifelong, meta-learning, non-stationary},
	pages = {1028--1040},
	file = {Hadsell et al_2020_Embracing Change.pdf:/Users/tito/Zotero/storage/FBF7EYZ9/Hadsell et al_2020_Embracing Change.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/I5QXJ99S/S1364-66132030219-9.html:text/html},
}

@article{kriegeskorte_matching_2008-1,
	title = {Matching {Categorical} {Object} {Representations} in {Inferior} {Temporal} {Cortex} of {Man} and {Monkey}},
	volume = {60},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627308009434},
	doi = {10.1016/j.neuron.2008.10.043},
	abstract = {Inferior temporal (IT) object representations have been intensively studied in monkeys and humans, but representations of the same particular objects have never been compared between the species. Moreover, IT's role in categorization is not well understood. Here, we presented monkeys and humans with the same images of real-world objects and measured the IT response pattern elicited by each image. In order to relate the representations between the species and to computational models, we compare response-pattern dissimilarity matrices. IT response patterns form category clusters, which match between man and monkey. The clusters correspond to animate and inanimate objects; within the animate objects, faces and bodies form subclusters. Within each category, IT distinguishes individual exemplars, and the within-category exemplar similarities also match between the species. Our findings suggest that primate IT across species may host a common code, which combines a categorical and a continuous representation of objects.},
	language = {en},
	number = {6},
	urldate = {2021-11-27},
	journal = {Neuron},
	author = {Kriegeskorte, Nikolaus and Mur, Marieke and Ruff, Douglas A. and Kiani, Roozbeh and Bodurka, Jerzy and Esteky, Hossein and Tanaka, Keiji and Bandettini, Peter A.},
	month = dec,
	year = {2008},
	keywords = {SYSNEURO},
	pages = {1126--1141},
	file = {Kriegeskorte et al_2008_Matching Categorical Object Representations in Inferior Temporal Cortex of Man.pdf:/Users/tito/Zotero/storage/DSAACDFI/Kriegeskorte et al_2008_Matching Categorical Object Representations in Inferior Temporal Cortex of Man.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/WG3AH6JW/S0896627308009434.html:text/html},
}

@article{gao_simplicity_2015,
	series = {Large-{Scale} {Recording} {Technology} (32)},
	title = {On simplicity and complexity in the brave new world of large-scale neuroscience},
	volume = {32},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438815000768},
	doi = {10.1016/j.conb.2015.04.003},
	abstract = {Technological advances have dramatically expanded our ability to probe multi-neuronal dynamics and connectivity in the brain. However, our ability to extract a simple conceptual understanding from complex data is increasingly hampered by the lack of theoretically principled data analytic procedures, as well as theoretical frameworks for how circuit connectivity and dynamics can conspire to generate emergent behavioral and cognitive functions. We review and outline potential avenues for progress, including new theories of high dimensional data analysis, the need to analyze complex artificial networks, and methods for analyzing entire spaces of circuit models, rather than one model at a time. Such interplay between experiments, data analysis and theory will be indispensable in catalyzing conceptual advances in the age of large-scale neuroscience.},
	language = {en},
	urldate = {2021-11-28},
	journal = {Current Opinion in Neurobiology},
	author = {Gao, Peiran and Ganguli, Surya},
	month = jun,
	year = {2015},
	pages = {148--155},
	file = {Gao_Ganguli_2015_On simplicity and complexity in the brave new world of large-scale neuroscience.pdf:/Users/tito/Zotero/storage/786NNDYI/Gao_Ganguli_2015_On simplicity and complexity in the brave new world of large-scale neuroscience.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/W4ZYV56L/S0959438815000768.html:text/html},
}

@techreport{gao_theory_2017,
	title = {A theory of multineuronal dimensionality, dynamics and measurement},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/214262v2},
	abstract = {In many experiments, neuroscientists tightly control behavior, record many trials, and obtain trial-averaged firing rates from hundreds of neurons in circuits containing billions of behaviorally relevant neurons. Di-mensionality reduction methods reveal a striking simplicity underlying such multi-neuronal data: they can be reduced to a low-dimensional space, and the resulting neural trajectories in this space yield a remarkably insightful dynamical portrait of circuit computation. This simplicity raises profound and timely conceptual questions. What are its origins and its implications for the complexity of neural dynamics? How would the situation change if we recorded more neurons? When, if at all, can we trust dynamical portraits obtained from measuring an infinitesimal fraction of task relevant neurons? We present a theory that answers these questions, and test it using physiological recordings from reaching monkeys. This theory reveals conceptual insights into how task complexity governs both neural dimensionality and accurate recovery of dynamic portraits, thereby providing quantitative guidelines for future large-scale experimental design.},
	language = {en},
	urldate = {2021-11-28},
	author = {Gao, Peiran and Trautmann, Eric and Yu, Byron and Santhanam, Gopal and Ryu, Stephen and Shenoy, Krishna and Ganguli, Surya},
	month = nov,
	year = {2017},
	doi = {10.1101/214262},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {214262},
	file = {Gao et al_2017_A theory of multineuronal dimensionality, dynamics and measurement.pdf:/Users/tito/Zotero/storage/YHBNFIVI/Gao et al_2017_A theory of multineuronal dimensionality, dynamics and measurement.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/YUI7CJEF/214262v2.html:text/html},
}

@techreport{allen_massive_2021,
	title = {A massive {7T} {fMRI} dataset to bridge cognitive and computational neuroscience},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.02.22.432340v1},
	abstract = {Extensive sampling of neural activity during rich cognitive phenomena is critical for robust understanding of brain function. We present the Natural Scenes Dataset (NSD), in which high-resolution fMRI responses to tens of thousands of richly annotated natural scenes are measured while participants perform a continuous recognition task. To optimize data quality, we develop and apply novel estimation and denoising techniques. Simple visual inspections of the NSD data reveal clear representational transformations along the ventral visual pathway. Further exemplifying the inferential power of the dataset, we use NSD to build and train deep neural network models that predict brain activity more accurately than state-of-the-art models from computer vision. NSD also includes substantial resting-state and diffusion data, enabling network neuroscience perspectives to constrain and enhance models of perception and memory. Given its unprecedented scale, quality, and breadth, NSD opens new avenues of inquiry in cognitive and computational neuroscience.},
	language = {en},
	urldate = {2021-11-28},
	author = {Allen, Emily J. and St-Yves, Ghislain and Wu, Yihan and Breedlove, Jesse L. and Dowdle, Logan T. and Caron, Brad and Pestilli, Franco and Charest, Ian and Hutchinson, J. Benjamin and Naselaris, Thomas and Kay, Kendrick},
	month = feb,
	year = {2021},
	doi = {10.1101/2021.02.22.432340},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.02.22.432340},
	file = {Snapshot:/Users/tito/Zotero/storage/ZP24LFRW/2021.02.22.432340v1.html:text/html},
}

@article{saxe_if_2021,
	title = {If deep learning is the answer, what is the question?},
	volume = {22},
	copyright = {2020 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-020-00395-8},
	doi = {10.1038/s41583-020-00395-8},
	abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This approach has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, and not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterize computations or neural codes, or who wish to understand perception, attention, memory and executive functions? In this Perspective, our goal is to offer a road map for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics and neural representations in artificial and biological systems, and we highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.},
	language = {en},
	number = {1},
	urldate = {2021-11-28},
	journal = {Nat Rev Neurosci},
	author = {Saxe, Andrew and Nelli, Stephanie and Summerfield, Christopher},
	month = jan,
	year = {2021},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Learning algorithms;Network models
Subject\_term\_id: learning-algorithms;network-models},
	keywords = {Network models, Learning algorithms},
	pages = {55--67},
	file = {Saxe et al_2021_If deep learning is the answer, what is the question.pdf:/Users/tito/Zotero/storage/UCCGYBSR/Saxe et al_2021_If deep learning is the answer, what is the question.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/6FRNWEIW/s41583-020-00395-8.html:text/html},
}

@article{deco_rare_2021,
	title = {Rare long-range cortical connections enhance human information processing},
	volume = {31},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S096098222101054X},
	doi = {10.1016/j.cub.2021.07.064},
	abstract = {What are the key topological features of connectivity critically relevant for generating the dynamics underlying efﬁcient cortical function? A candidate feature that has recently emerged is that the connectivity of the mammalian cortex follows an exponential distance rule, which includes a small proportion of long-range high-weight anatomical exceptions to this rule. Whole-brain modeling of large-scale human neuroimaging data in 1,003 participants offers the unique opportunity to create two models, with and without long-range exceptions, and explicitly study their functional consequences. We found that rare long-range exceptions are crucial for signiﬁcantly improving information processing. Furthermore, modeling in a simpliﬁed ring architecture shows that this improvement is greatly enhanced by the turbulent regime found in empirical neuroimaging data. Overall, the results provide strong empirical evidence for the immense functional beneﬁts of long-range exceptions combined with turbulence for information processing.},
	language = {en},
	number = {20},
	urldate = {2021-11-28},
	journal = {Current Biology},
	author = {Deco, Gustavo and Sanz Perl, Yonathan and Vuust, Peter and Tagliazucchi, Enzo and Kennedy, Henry and Kringelbach, Morten L.},
	month = oct,
	year = {2021},
	pages = {4436--4448.e5},
	file = {Deco et al. - 2021 - Rare long-range cortical connections enhance human.pdf:/Users/tito/Zotero/storage/G5H99UJD/Deco et al. - 2021 - Rare long-range cortical connections enhance human.pdf:application/pdf},
}

@techreport{rasero_similarity_2021,
	title = {Similarity in evoked responses does not imply similarity in macroscopic network states across tasks},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.11.27.470015v1},
	abstract = {There is an ongoing debate as to whether cognitive processes arise from a group of functionally specialized brain modules (modularism) or as the result of a distributed nonlinear process (dynamical systems theory). The former predicts that tasks that recruit similar brain areas should have an equivalent degree of similarity in their connectivity. The latter allows for differential connectivity, even when the areas recruited are largely the same. Here we evaluated both views by comparing activation and connectivity patterns from a large sample of healthy subjects (N=242) that performed two executive control tasks, color-word Stroop task and Multi-Source Interference Task (MSIT), known to recruit similar brain areas. Using a measure of instantaneous connectivity based on edge time series as outcome variables, we estimated task-related network profiles as connectivity changes between incongruent and congruent information conditions. The degree of similarity of such profiles at the group level between both tasks was substantially smaller than their overlapping activation responses. A similar finding was observed at the subject level and when employing a different method for defining task-related connectivity. Our results are consistent with the perspective of the brain as a dynamical system, suggesting that task representations should be understood at both node and edge (connectivity) levels.},
	language = {en},
	urldate = {2021-11-28},
	author = {Rasero, Javier and Betzel, Richard and Sentis, Amy Isabella and Kraynak, Thomas E. and Gianaros, Peter J. and Verstynen, Timothy},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.27.470015},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.11.27.470015},
	file = {Rasero et al_2021_Similarity in evoked responses does not imply similarity in macroscopic network.pdf:/Users/tito/Zotero/storage/MSYVBWUP/Rasero et al_2021_Similarity in evoked responses does not imply similarity in macroscopic network.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5AN9N9RU/2021.11.27.html:text/html},
}

@article{do_neural_2021,
	title = {Neural circuits and symbolic processing},
	volume = {186},
	issn = {1074-7427},
	url = {https://www.sciencedirect.com/science/article/pii/S107474272100174X},
	doi = {10.1016/j.nlm.2021.107552},
	abstract = {The ability to use symbols is a defining feature of human intelligence. However, neuroscience has yet to explain the fundamental neural circuit mechanisms for flexibly representing and manipulating abstract concepts. This article will review the research on neural models for symbolic processing. The review first focuses on the question of how symbols could possibly be represented in neural circuits. The review then addresses how neural symbolic representations could be flexibly combined to meet a wide range of reasoning demands. Finally, the review assesses the research on program synthesis and proposes that the most flexible neural representation of symbolic processing would involve the capacity to rapidly synthesize neural operations analogous to lambda calculus to solve complex cognitive tasks.},
	language = {en},
	urldate = {2021-11-29},
	journal = {Neurobiology of Learning and Memory},
	author = {Do, Quan and Hasselmo, Michael E.},
	month = dec,
	year = {2021},
	keywords = {Reinforcement learning, Bayesian inference, Category theory, Conjunctive coding, Dynamic binding, Program synthesis},
	pages = {107552},
	file = {Do_Hasselmo_2021_Neural circuits and symbolic processing.pdf:/Users/tito/Zotero/storage/DFG6TD8D/Do_Hasselmo_2021_Neural circuits and symbolic processing.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/Z7KWMYSG/S107474272100174X.html:text/html},
}

@techreport{ito_multi-task_2021,
	title = {Multi-task representations in human cortex transform along a sensory-to-motor hierarchy},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.11.29.470432v1},
	abstract = {Human cognition recruits diverse neural processes, yet the organizing computational and functional architectures remain unclear. Here, we characterized the geometry and topography of multi-task representations across human cortex using functional MRI during 26 cognitive tasks in the same subjects. We measured the representational similarity across tasks within a region, and the alignment of representations between regions. We found a cortical topography of representational alignment following a hierarchical sensory-association-motor gradient, revealing compression-then-expansion of multi-task dimensionality along this gradient. To investigate computational principles of multi-task representations, we trained multi-layer neural network models to transform empirical visual to motor representations. Compression-then-expansion organization in models emerged exclusively in a training regime where internal representations are highly optimized for sensory-to-motor transformation, and not under generic signal propagation. This regime produces hierarchically structured representations similar to empirical cortical patterns. Together, these results reveal computational principles that organize multi-task representations across human cortex to support flexible cognition.},
	language = {en},
	urldate = {2021-11-30},
	author = {Ito, Takuya and Murray, John D.},
	month = nov,
	year = {2021},
	doi = {10.1101/2021.11.29.470432},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.11.29.470432},
	file = {Ito_Murray_2021_Multi-task representations in human cortex transform along a sensory-to-motor.pdf:/Users/tito/Zotero/storage/IPWYK5IT/Ito_Murray_2021_Multi-task representations in human cortex transform along a sensory-to-motor.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Z3DPKNPS/2021.11.29.html:text/html},
}

@book{purves_cognitive_2008,
	title = {Cognitive neuroscience},
	publisher = {Sunderland: Sinauer Associates, Inc},
	author = {Purves, Dale and Cabeza, Roberto and Huettel, Scott A. and LaBar, Kevin S. and Platt, Michael L. and Woldorff, Marty G. and Brannon, Elizabeth M.},
	year = {2008},
	file = {Purves et al_2008_Cognitive neuroscience.pdf:/Users/tito/Zotero/storage/MBQWU6AX/Purves et al_2008_Cognitive neuroscience.pdf:application/pdf},
}

@book{sporns_networks_2010,
	title = {Networks of the {Brain}},
	publisher = {MIT press},
	author = {Sporns, Olaf},
	year = {2010},
	file = {Snapshot:/Users/tito/Zotero/storage/T25CPXBN/books.html:text/html},
}

@book{fornito_fundamentals_2016,
	title = {Fundamentals of brain network analysis},
	publisher = {Academic Press},
	author = {Fornito, Alex and Zalesky, Andrew and Bullmore, Edward},
	year = {2016},
	file = {Snapshot:/Users/tito/Zotero/storage/3BRUBJA8/books.html:text/html},
}

@article{duncker_dynamics_2021,
	title = {Dynamics on the manifold: {Identifying} computational dynamical activity from neural population recordings},
	volume = {70},
	issn = {0959-4388},
	shorttitle = {Dynamics on the manifold},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438821001264},
	doi = {10.1016/j.conb.2021.10.014},
	abstract = {The question of how the collective activity of neural populations gives rise to complex behaviour is fundamental to neuroscience. At the core of this question lie considerations about how neural circuits can perform computations that enable sensory perception, decision making, and motor control. It is thought that such computations are implemented through the dynamical evolution of distributed activity in recurrent circuits. Thus, identifying dynamical structure in neural population activity is a key challenge towards a better understanding of neural computation. At the same time, interpreting this structure in light of the computation of interest is essential for linking the time-varying activity patterns of the neural population to ongoing computational processes. Here, we review methods that aim to quantify structure in neural population recordings through a dynamical system defined in a low-dimensional latent variable space. We discuss advantages and limitations of different modelling approaches and address future challenges for the field.},
	language = {en},
	urldate = {2021-12-01},
	journal = {Current Opinion in Neurobiology},
	author = {Duncker, Lea and Sahani, Maneesh},
	month = oct,
	year = {2021},
	pages = {163--170},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/XE6R3JAY/S0959438821001264.html:text/html},
}

@article{barbas_pathway_2018,
	title = {Pathway mechanism for excitatory and inhibitory control in working memory},
	volume = {120},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.00936.2017},
	doi = {10.1152/jn.00936.2017},
	abstract = {Humans engage in many daily activities that rely on working memory, the ability to hold and sequence information temporarily to accomplish a task. We focus on the process of working memory, based on circuit mechanisms for attending to relevant signals and suppressing irrelevant stimuli. We discuss that connections critically depend on the systematic variation in laminar structure across all cortical systems. Laminar structure is used to group areas into types regardless of their placement in the cortex, ranging from low-type agranular areas that lack layer IV to high-type areas that have six well-delineated layers. Connections vary in laminar distribution and strength based on the difference in type between linked areas, according to the “structural model” (Barbas H, Rempel-Clower N. Cereb Cortex 7: 635–646, 1997). The many possible pathways thus vary systematically by laminar distribution and strength, and they interface with excitatory neurons to select relevant stimuli and with functionally distinct inhibitory neurons that suppress activity at the site of termination. Using prefrontal pathways, we discuss how systematic architectonic variation gives rise to diverse pathways that can be recruited, along with amygdalar and hippocampal pathways that provide sensory, affective, and contextual information. The prefrontal cortex is also connected with thalamic nuclei that receive the output of the basal ganglia and cerebellum, which may facilitate fast sequencing of information. The complement of connections and their interface with distinct inhibitory neurons allows dynamic recruitment of areas and shifts in cortical rhythms to meet rapidly changing demands of sequential components of working memory tasks.},
	number = {5},
	urldate = {2021-12-01},
	journal = {Journal of Neurophysiology},
	author = {Barbas, Helen and Wang, Jingyi and Joyce, Mary Kate P. and García-Cabezas, Miguel Ángel},
	month = nov,
	year = {2018},
	note = {Publisher: American Physiological Society},
	keywords = {memory, oscillations, inhibitory neurons, prefrontal, structural model},
	pages = {2659--2678},
	file = {Barbas et al_2018_Pathway mechanism for excitatory and inhibitory control in working memory.pdf:/Users/tito/Zotero/storage/FVATHTZD/Barbas et al_2018_Pathway mechanism for excitatory and inhibitory control in working memory.pdf:application/pdf},
}

@article{taylor_characterization_2018,
	title = {Characterization of the hemodynamic response function across the majority of human cerebral cortex},
	volume = {173},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381191830168X},
	doi = {10.1016/j.neuroimage.2018.02.061},
	abstract = {A brief ({\textless}4 s) period of neural activation evokes a stereotypical sequence of vascular and metabolic events to create the hemodynamic response function (HRF) measured using functional magnetic resonance imaging (fMRI). Linear analysis of fMRI data requires that the HRF be treated as an impulse response, so the character and temporal stability of the HRF are critical issues. Here, a simple audiovisual stimulus combined with a fast-paced task was used to evoke a strong HRF across a majority, ∼77\%, of cortex during a single scanning session. High spatiotemporal resolution (2-mm voxels, 1.25-s acquisition time) was used to focus HRF measurements specifically on the gray matter for whole brain. The majority of activated cortex responds with positive HRFs, while ∼27\% responds with negative (inverted) HRFs. Spatial patterns of the HRF response amplitudes were found to be similar across subjects. Timing of the initial positive lobe of the HRF was relatively stable across the cortical surface with a mean of 6.1 ± 0.6 s across subjects, yet small but significant timing variations were also evident in specific regions of cortex. The results provide guidance for linear analysis of fMRI data. More importantly, this method provides a means to quantify neurovascular function across most of the brain, with potential clinical utility for the diagnosis of brain pathologies such as traumatic brain injury.},
	language = {en},
	urldate = {2021-12-02},
	journal = {NeuroImage},
	author = {Taylor, Amanda J. and Kim, Jung Hwan and Ress, David},
	month = jun,
	year = {2018},
	keywords = {fMRI, Cerebral hemodynamics, Cerebral pathology, Multisensory stimulation, Neurovascular coupling},
	pages = {322--331},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/IZER8SPV/S105381191830168X.html:text/html;Taylor et al_2018_Characterization of the hemodynamic response function across the majority of.pdf:/Users/tito/Zotero/storage/53YJFQUZ/Taylor et al_2018_Characterization of the hemodynamic response function across the majority of.pdf:application/pdf},
}

@article{veit_temporal_2021,
	title = {Temporal order of signal propagation within and across intrinsic brain networks},
	volume = {118},
	copyright = {© 2021 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/118/48/e2105031118},
	doi = {10.1073/pnas.2105031118},
	abstract = {We studied the temporal dynamics of activity within and across functional MRI (fMRI)–derived nodes of intrinsic resting-state networks of the human brain using intracranial electroencephalography (iEEG) and repeated single-pulse electrical stimulation (SPES) in neurosurgical subjects implanted with intracranial electrodes. We stimulated and recorded from 2,133 and 2,372 sites, respectively, in 29 subjects. We found that N1 and N2 segments of the evoked responses are associated with intra- and internetwork communications, respectively. In a separate cognitive experiment, evoked electrophysiological responses to visual target stimuli occurred with less temporal separation across pairs of electrodes that were located within the same fMRI-defined resting-state networks compared with those located across different resting-state networks. Our results suggest intranetwork prior to internetwork information processing at the subsecond timescale.},
	language = {en},
	number = {48},
	urldate = {2021-12-02},
	journal = {PNAS},
	author = {Veit, Mike J. and Kucyi, Aaron and Hu, Wenhan and Zhang, Chao and Zhao, Baotian and Guo, Zhihao and Yang, Bowen and Sava-Segal, Clara and Perry, Claire and Zhang, Jianguo and Zhang, Kai and Parvizi, Josef},
	month = nov,
	year = {2021},
	pmid = {34819365},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {human, CCEP, event related potentials, gradual-onset continuous performance task, intracranial EEG},
	file = {Snapshot:/Users/tito/Zotero/storage/AVP5RZAP/e2105031118.html:text/html},
}

@article{xu_cross-species_2020,
	title = {Cross-species functional alignment reveals evolutionary hierarchy within the connectome},
	volume = {223},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920308326},
	doi = {10.1016/j.neuroimage.2020.117346},
	abstract = {Evolution provides an important window into how cortical organization shapes function and vice versa. The complex mosaic of changes in brain morphology and functional organization that have shaped the mammalian cortex during evolution, complicates attempts to chart cortical differences across species. It limits our ability to fully appreciate how evolution has shaped our brain, especially in systems associated with unique human cognitive capabilities that lack anatomical homologues in other species. Here, we develop a function-based method for cross-species alignment that enables the quantification of homologous regions between humans and rhesus macaques, even when their location is decoupled from anatomical landmarks. Critically, we find cross-species similarity in functional organization reflects a gradient of evolutionary change that decreases from unimodal systems and culminates with the most pronounced changes in posterior regions of the default mode network (angular gyrus, posterior cingulate and middle temporal cortices). Our findings suggest that the establishment of the default mode network, as the apex of a cognitive hierarchy, has changed in a complex manner during human evolution – even within subnetworks.},
	language = {en},
	urldate = {2021-12-03},
	journal = {NeuroImage},
	author = {Xu, Ting and Nenning, Karl-Heinz and Schwartz, Ernst and Hong, Seok-Jun and Vogelstein, Joshua T. and Goulas, Alexandros and Fair, Damien A. and Schroeder, Charles E. and Margulies, Daniel S. and Smallwood, Jonny and Milham, Michael P. and Langs, Georg},
	month = dec,
	year = {2020},
	keywords = {Default mode network, Cross-species alignment, Evolution, Hierarchy, Joint embedding},
	pages = {117346},
	file = {1-s2.0-S1053811920308326-main.pdf:/Users/tito/Zotero/storage/HATD9HA9/1-s2.0-S1053811920308326-main.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/PJLENCSS/S1053811920308326.html:text/html},
}

@article{mantini_interspecies_2012,
	title = {Interspecies activity correlations reveal functional correspondence between monkey and human brain areas},
	volume = {9},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.1868},
	doi = {10.1038/nmeth.1868},
	abstract = {To examine functional correspondences between monkey and human brain areas, a method based on the temporal correlation of sensory-evoked functional magnetic resonance imaging responses is proposed. The study reveals putative homologous regions that have shifted to topologically unexpected locations during evolution.},
	language = {en},
	number = {3},
	urldate = {2021-12-03},
	journal = {Nat Methods},
	author = {Mantini, Dante and Hasson, Uri and Betti, Viviana and Perrucci, Mauro G. and Romani, Gian Luca and Corbetta, Maurizio and Orban, Guy A. and Vanduffel, Wim},
	month = mar,
	year = {2012},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 3
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Functional magnetic resonance imaging;Phylogenetics
Subject\_term\_id: functional-magnetic-resonance-imaging;phylogenetics},
	keywords = {Functional magnetic resonance imaging, Phylogenetics},
	pages = {277--282},
	file = {Mantini et al_2012_Interspecies activity correlations reveal functional correspondence between.pdf:/Users/tito/Zotero/storage/IF8XQSML/Mantini et al_2012_Interspecies activity correlations reveal functional correspondence between.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/7WQJ64SU/nmeth.html:text/html},
}

@techreport{nakai_preserved_2021,
	title = {Preserved representations and decodability of diverse cognitive functions across the cortex, cerebellum, and subcortex},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.12.09.471939v1},
	abstract = {Which part of the brain contributes to our complex cognitive processes? Studies have revealed contributions of the cerebellum and subcortex to higher-order cognitive functions; however it is unclear whether such functional representations are preserved across the cortex, cerebellum, and subcortex. In this study, we used functional magnetic resonance imaging data with 103 cognitive tasks and constructed three voxel-wise encoding and decoding models independently using cortical, cerebellar, and subcortical voxels. Representational similarity analysis revealed that the structure of task representations is preserved across the three brain parts. Principal component analysis visualized distinct organizations of abstract cognitive functions in each part of the cerebellum and subcortex. More than 90\% of the cognitive tasks were decodable from the cerebellum and subcortical activities, even for the novel tasks not included in model training. Furthermore, we discovered that the cerebellum and subcortex have sufficient information to reconstruct activity in the cerebral cortex.},
	language = {en},
	urldate = {2021-12-10},
	author = {Nakai, Tomoya and Nishimoto, Shinji},
	month = dec,
	year = {2021},
	doi = {10.1101/2021.12.09.471939},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.12.09.471939},
	file = {Nakai_Nishimoto_2021_Preserved representations and decodability of diverse cognitive functions.pdf:/Users/tito/Zotero/storage/VEZ4QN6P/Nakai_Nishimoto_2021_Preserved representations and decodability of diverse cognitive functions.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VPKKK4NM/2021.12.09.html:text/html},
}

@article{benna_place_2021,
	title = {Place cells may simply be memory cells: {Memory} compression leads to spatial tuning and history dependence},
	volume = {118},
	copyright = {© 2021 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Place cells may simply be memory cells},
	url = {https://www.pnas.org/content/118/51/e2018422118},
	doi = {10.1073/pnas.2018422118},
	abstract = {The observation of place cells has suggested that the hippocampus plays a special role in encoding spatial information. However, place cell responses are modulated by several nonspatial variables and reported to be rather unstable. Here, we propose a memory model of the hippocampus that provides an interpretation of place cells consistent with these observations. We hypothesize that the hippocampus is a memory device that takes advantage of the correlations between sensory experiences to generate compressed representations of the episodes that are stored in memory. A simple neural network model that can efficiently compress information naturally produces place cells that are similar to those observed in experiments. It predicts that the activity of these cells is variable and that the fluctuations of the place fields encode information about the recent history of sensory experiences. Place cells may simply be a consequence of a memory compression process implemented in the hippocampus.},
	language = {en},
	number = {51},
	urldate = {2021-12-17},
	journal = {PNAS},
	author = {Benna, Marcus K. and Fusi, Stefano},
	month = dec,
	year = {2021},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {hippocampus, memory, place cells, compression, sparse autoencoders},
	file = {Snapshot:/Users/tito/Zotero/storage/TEK7VXJ4/e2018422118.html:text/html},
}

@article{dahl_noradrenergic_2022,
	title = {Noradrenergic modulation of rhythmic neural activity shapes selective attention},
	volume = {26},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661321002643},
	doi = {10.1016/j.tics.2021.10.009},
	abstract = {During moments involving selective attention, the thalamus orchestrates the preferential processing of prioritized information by coordinating rhythmic neural activity within a distributed frontoparietal network. The timed release of neuromodulators from subcortical structures dynamically sculpts neural synchronization in thalamocortical networks to meet current attentional demands. In particular, noradrenaline modulates the balance of cortical excitation and inhibition, as reflected by thalamocortical alpha synchronization ({\textasciitilde}8–12 Hz). These neuromodulatory adjustments facilitate the selective processing of prioritized information. Thus, by disrupting effective rhythmic coordination in attention networks, age-related locus coeruleus (LC) degeneration can impair higher levels of neural processing. In sum, findings across different levels of analysis and modalities shed light on how the noradrenergic modulation of neural synchronization helps to shape selective attention.},
	language = {en},
	number = {1},
	urldate = {2021-12-17},
	journal = {Trends in Cognitive Sciences},
	author = {Dahl, Martin J. and Mather, Mara and Werkle-Bergner, Markus},
	month = jan,
	year = {2022},
	keywords = {noradrenaline, locus coeruleus, norepinephrine, cognitive aging, rhythmic neural activity, selective attention},
	pages = {38--52},
}

@article{frassle_generative_2018,
	title = {A generative model of whole-brain effective connectivity},
	volume = {179},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811918304762},
	doi = {10.1016/j.neuroimage.2018.05.058},
	abstract = {The development of whole-brain models that can infer effective (directed) connection strengths from fMRI data represents a central challenge for computational neuroimaging. A recently introduced generative model of fMRI data, regression dynamic causal modeling (rDCM), moves towards this goal as it scales gracefully to very large networks. However, large-scale networks with thousands of connections are difficult to interpret; additionally, one typically lacks information (data points per free parameter) for precise estimation of all model parameters. This paper introduces sparsity constraints to the variational Bayesian framework of rDCM as a solution to these problems in the domain of task-based fMRI. This sparse rDCM approach enables highly efficient effective connectivity analyses in whole-brain networks and does not require a priori assumptions about the network's connectivity structure but prunes fully (all-to-all) connected networks as part of model inversion. Following the derivation of the variational Bayesian update equations for sparse rDCM, we use both simulated and empirical data to assess the face validity of the model. In particular, we show that it is feasible to infer effective connection strengths from fMRI data using a network with more than 100 regions and 10,000 connections. This demonstrates the feasibility of whole-brain inference on effective connectivity from fMRI data – in single subjects and with a run-time below 1 min when using parallelized code. We anticipate that sparse rDCM may find useful application in connectomics and clinical neuromodeling – for example, for phenotyping individual patients in terms of whole-brain network structure.},
	language = {en},
	urldate = {2021-12-21},
	journal = {NeuroImage},
	author = {Frässle, Stefan and Lomakina, Ekaterina I. and Kasper, Lars and Manjaly, Zina M. and Leff, Alex and Pruessmann, Klaas P. and Buhmann, Joachim M. and Stephan, Klaas E.},
	month = oct,
	year = {2018},
	keywords = {Effective connectivity, Connectomics, Dynamic causal modeling, Sparsity, Bayesian regression, Generative model},
	pages = {505--529},
	file = {Frässle et al_2018_A generative model of whole-brain effective connectivity.pdf:/Users/tito/Zotero/storage/75D4AAJZ/Frässle et al_2018_A generative model of whole-brain effective connectivity.pdf:application/pdf},
}

@article{vazquez-rodriguez_signal_2020-1,
	title = {Signal propagation via cortical hierarchies},
	volume = {4},
	issn = {2472-1751},
	url = {https://doi.org/10.1162/netn_a_00153},
	doi = {10.1162/netn_a_00153},
	abstract = {The wiring of the brain is organized around a putative unimodal-transmodal
hierarchy. Here we investigate how this intrinsic hierarchical organization of
the brain shapes the transmission of information among regions. The hierarchical
positioning of individual regions was quantified by applying diffusion map
embedding to resting-state functional MRI networks. Structural networks were
reconstructed from diffusion spectrum imaging and topological shortest paths
among all brain regions were computed. Sequences of nodes encountered along a
path were then labeled by their hierarchical position, tracing out path motifs.
We find that the cortical hierarchy guides communication in the network.
Specifically, nodes are more likely to forward signals to nodes closer in the
hierarchy and cover a range of unimodal and transmodal regions, potentially
enriching or diversifying signals en route. We also find evidence of systematic
detours, particularly in attention networks, where communication is rerouted.
Altogether, the present work highlights how the cortical hierarchy shapes signal
exchange and imparts behaviorally relevant communication patterns in brain
networks.In the present report we asked how signals travel on brain networks and what
types of nodes they potentially visit en route. We traced individual path motifs
to investigate the propensity of communication paths to explore the putative
unimodal-transmodal cortical hierarchy. We find that the architecture of the
network promotes signaling via the hierarchy, suggesting a link between the
structure and function of the network. Importantly, we also find instances where
detours are promoted, particularly as paths traverse attention-related networks.
Finally, information about hierarchical position aids navigation in some parts
of the network, over and above spatial location. Altogether, the present results
touch on several emerging themes in network neuroscience, including the nature
of structure-function relationships, network communication and the role of
cortical hierarchies.},
	number = {4},
	urldate = {2021-12-22},
	journal = {Network Neuroscience},
	author = {Vazquez-Rodríguez, Bertha and Liu, Zhen-Qi and Hagmann, Patric and Misic, Bratislav},
	month = nov,
	year = {2020},
	pages = {1072--1090},
	file = {Vézquez-Rodríguez et al_2020_Signal propagation via cortical hierarchies.pdf:/Users/tito/Zotero/storage/4QL6VLTG/Vézquez-Rodríguez et al_2020_Signal propagation via cortical hierarchies.pdf:application/pdf},
}

@article{mill_empirical_2017,
	title = {Empirical validation of directed functional connectivity},
	volume = {146},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811916306553},
	doi = {10.1016/j.neuroimage.2016.11.037},
	abstract = {Mapping directions of influence in the human brain connectome represents the next phase in understanding its functional architecture. However, a host of methodological uncertainties have impeded the application of directed connectivity methods, which have primarily been validated via “ground truth” connectivity patterns embedded in simulated functional MRI (fMRI) and magneto-/electro-encephalography (MEG/EEG) datasets. Such simulations rely on many generative assumptions, and we hence utilized a different strategy involving empirical data in which a ground truth directed connectivity pattern could be anticipated with confidence. Specifically, we exploited the established “sensory reactivation” effect in episodic memory, in which retrieval of sensory information reactivates regions involved in perceiving that sensory modality. Subjects performed a paired associate task in separate fMRI and MEG sessions, in which a ground truth reversal in directed connectivity between auditory and visual sensory regions was instantiated across task conditions. This directed connectivity reversal was successfully recovered across different algorithms, including Granger causality and Bayes network (IMAGES) approaches, and across fMRI (“raw” and deconvolved) and source-modeled MEG. These results extend simulation studies of directed connectivity, and offer practical guidelines for the use of such methods in clarifying causal mechanisms of neural processing.},
	language = {en},
	urldate = {2021-12-22},
	journal = {NeuroImage},
	author = {Mill, Ravi D. and Bagic, Anto and Bostan, Andreea and Schneider, Walter and Cole, Michael W.},
	month = feb,
	year = {2017},
	keywords = {fMRI, Functional connectivity, Effective connectivity, Directed connectivity, MEG, Memory},
	pages = {275--287},
	file = {Mill et al_2017_Empirical validation of directed functional connectivity.pdf:/Users/tito/Zotero/storage/DCISUFQS/Mill et al_2017_Empirical validation of directed functional connectivity.pdf:application/pdf},
}

@article{deshpande_effect_2010-1,
	series = {Computational {Models} of the {Brain}},
	title = {Effect of hemodynamic variability on {Granger} causality analysis of {fMRI}},
	volume = {52},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811909012464},
	doi = {10.1016/j.neuroimage.2009.11.060},
	abstract = {In this work, we investigated the effect of the regional variability of the hemodynamic response on the sensitivity of Granger causality (GC) analysis of functional magnetic resonance imaging (fMRI) data to neuronal causal influences. We simulated fMRI data by convolving a standard canonical hemodynamic response function (HRF) with local field potentials (LFPs) acquired from the macaque cortex and manipulated the causal influence and neuronal delays between the LFPs, the hemodynamic delays between the HRFs, the signal-to-noise ratio (SNR), and the sampling period (TR) to assess the effect of each of these factors on the detectability of the neuronal delays from GC analysis of fMRI. In our first bivariate implementation, we assumed the worst-case scenario of the hemodynamic delay being at the empirical upper limit of its normal physiological range and opposing the direction of neuronal delay. We found that, in the absence of HRF confounds, even tens of milliseconds of neuronal delays can be inferred from fMRI. However, in the presence of HRF delays which opposed neuronal delays, the minimum detectable neuronal delay was hundreds of milliseconds. In our second multivariate simulation, we mimicked the real situation more closely by using a multivariate network of four time series and assumed the hemodynamic and neuronal delays to be unknown and drawn from a uniform random distribution. The resulting accuracy of detecting the correct multivariate network from fMRI was well above chance and was up to 90\% with faster sampling. Generically, under all conditions, faster sampling and low measurement noise improved the sensitivity of GC analysis of fMRI data to neuronal causality.},
	language = {en},
	number = {3},
	urldate = {2021-12-22},
	journal = {NeuroImage},
	author = {Deshpande, Gopikrishna and Sathian, K. and Hu, Xiaoping},
	month = sep,
	year = {2010},
	keywords = {Functional MRI, Granger causality, Hemodynamic variability, Minimum detectable neuronal delay},
	pages = {884--896},
	file = {Deshpande et al_2010_Effect of hemodynamic variability on Granger causality analysis of fMRI.pdf:/Users/tito/Zotero/storage/MM7W55GS/Deshpande et al_2010_Effect of hemodynamic variability on Granger causality analysis of fMRI.pdf:application/pdf},
}

@article{deshpande_investigating_2012,
	title = {Investigating {Effective} {Brain} {Connectivity} from {fMRI} {Data}: {Past} {Findings} and {Current} {Issues} with {Reference} to {Granger} {Causality} {Analysis}},
	volume = {2},
	issn = {2158-0014},
	shorttitle = {Investigating {Effective} {Brain} {Connectivity} from {fMRI} {Data}},
	url = {https://www.liebertpub.com/doi/full/10.1089/brain.2012.0091},
	doi = {10.1089/brain.2012.0091},
	abstract = {Interactions between brain regions have been recognized as a critical ingredient required to understand brain function. Two modes of interactions have held prominence—synchronization and causal influence. Efforts to ascertain causal influence from functional magnetic resonance imaging (fMRI) data have relied primarily on confirmatory model-driven approaches, such as dynamic causal modeling and structural equation modeling, and exploratory data-driven approaches such as Granger causality analysis. A slew of recent articles have focused on the relative merits and caveats of these approaches. The relevant studies can be classified into simulations, theoretical developments, and experimental results. In the first part of this review, we will consider each of these themes and critically evaluate their arguments, with regard to Granger causality analysis. Specifically, we argue that simulations are bounded by the assumptions and simplifications made by the simulator, and hence must be regarded only as a guide to experimental design and should not be viewed as the final word. On the theoretical front, we reason that each of the improvements to existing, yet disparate, methods brings them closer to each other with the hope of eventually leading to a unified framework specifically designed for fMRI. We then review latest experimental results that demonstrate the utility and validity of Granger causality analysis under certain experimental conditions. In the second part, we will consider current issues in causal connectivity analysis—hemodynamic variability, sampling, instantaneous versus causal relationship, and task versus resting states. We highlight some of our own work regarding these issues showing the effect of hemodynamic variability and sampling on Granger causality. Further, we discuss recent techniques such as the cubature Kalman filtering, which can perform blind deconvolution of the hemodynamic response robustly well, and hence enabling wider application of Granger causality analysis. Finally, we discuss our previous work on the less-appreciated interactions between instantaneous and causal relationships and the utility and interpretation of Granger causality results obtained from task versus resting state (e.g., ability of causal relationships to provide a mode of connectivity between regions that are instantaneously dissociated in resting state). We conclude by discussing future directions in this area.},
	number = {5},
	urldate = {2021-12-22},
	journal = {Brain Connectivity},
	author = {Deshpande, Gopikrishna and Hu, Xiaoping},
	month = oct,
	year = {2012},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	keywords = {brain networks, functional connectivity, Granger causality, blind hemodynamic deconvolution, effective connectivity},
	pages = {235--245},
	file = {Deshpande_Hu_2012_Investigating Effective Brain Connectivity from fMRI Data.pdf:/Users/tito/Zotero/storage/3C6QD4PF/Deshpande_Hu_2012_Investigating Effective Brain Connectivity from fMRI Data.pdf:application/pdf},
}

@article{webb_bold_2013,
	title = {{BOLD} {Granger} {Causality} {Reflects} {Vascular} {Anatomy}},
	volume = {8},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0084279},
	doi = {10.1371/journal.pone.0084279},
	abstract = {A number of studies have tried to exploit subtle phase differences in BOLD time series to resolve the order of sequential activation of brain regions, or more generally the ability of signal in one region to predict subsequent signal in another region. More recently, such lag-based measures have been applied to investigate directed functional connectivity, although this application has been controversial. We attempted to use large publicly available datasets (FCON 1000, ADHD 200, Human Connectome Project) to determine whether consistent spatial patterns of Granger Causality are observed in typical fMRI data. For BOLD datasets from 1,240 typically developing subjects ages 7–40, we measured Granger causality between time series for every pair of 7,266 spherical ROIs covering the gray matter and 264 seed ROIs at hubs of the brain’s functional network architecture. Granger causality estimates were strongly reproducible for connections in a test and replication sample (n=620 subjects for each group), as well as in data from a single subject scanned repeatedly, both during resting and passive video viewing. The same effect was even stronger in high temporal resolution fMRI data from the Human Connectome Project, and was observed independently in data collected during performance of 7 task paradigms. The spatial distribution of Granger causality reflected vascular anatomy with a progression from Granger causality sources, in Circle of Willis arterial inflow distributions, to sinks, near large venous vascular structures such as dural venous sinuses and at the periphery of the brain. Attempts to resolve BOLD phase differences with Granger causality should consider the possibility of reproducible vascular confounds, a problem that is independent of the known regional variability of the hemodynamic response.},
	language = {en},
	number = {12},
	urldate = {2021-12-22},
	journal = {PLOS ONE},
	author = {Webb, J. Taylor and Ferguson, Michael A. and Nielsen, Jared A. and Anderson, Jeffrey S.},
	month = dec,
	year = {2013},
	note = {Publisher: Public Library of Science},
	keywords = {Functional magnetic resonance imaging, Brain mapping, Central nervous system, Preprocessing, Magnetic resonance imaging, Angiography, Cerebral arteries, Statistical data},
	pages = {e84279},
	file = {Snapshot:/Users/tito/Zotero/storage/3V3DC86N/article.html:text/html;Webb et al_2013_BOLD Granger Causality Reflects Vascular Anatomy.pdf:/Users/tito/Zotero/storage/RNHDV6PF/Webb et al_2013_BOLD Granger Causality Reflects Vascular Anatomy.pdf:application/pdf},
}

@techreport{rowland_perception_2021,
	title = {Perception and propagation of activity through the cortical hierarchy is determined by neural variability},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.12.28.474343v1},
	abstract = {The brains of higher organisms are composed of anatomically and functionally distinct regions performing specialised tasks; but regions do not operate in isolation. Orchestration of complex behaviours requires communication between brain regions, but how neural activity dynamics are organised to facilitate reliable transmission is not well understood. We studied this process directly by generating neural activity that propagates between brain regions and drives behaviour, allowing us to assess how populations of neurons in sensory cortex cooperate to transmit information. We achieved this by imaging two hierarchically organised and densely interconnected regions, the primary and secondary somatosensory cortex (S1 and S2) in mice while performing two-photon photostimulation of S1 neurons and assigning behavioural salience to the photostimulation. We found that the probability of perception is determined not only by the strength of the photostimulation signal, but also by the variability of S1 neural activity. Therefore, maximising the signal-to-noise ratio of the stimulus representation in cortex is critical to its continued propagation downstream. Further, we show that propagated, behaviourally salient activity elicits balanced, persistent, and generalised activation of the downstream region. Hence, our work adds to existing understanding of cortical function by identifying how population activity is formatted to ensure robust transmission of information, allowing specialised brain regions to communicate and coordinate behaviour.},
	language = {en},
	urldate = {2021-12-31},
	author = {Rowland, James M. and Plas, Thijs L. van der and Loidolt, Matthias and Lees, Robert Michael and Keeling, Joshua and Dehning, Jonas and Akam, Thomas and Priesemann, Viola and Packer, Adam M.},
	month = dec,
	year = {2021},
	doi = {10.1101/2021.12.28.474343},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.12.28.474343},
	file = {Rowland et al_2021_Perception and propagation of activity through the cortical hierarchy is.pdf:/Users/tito/Zotero/storage/GTWPT6SD/Rowland et al_2021_Perception and propagation of activity through the cortical hierarchy is.pdf:application/pdf},
}

@article{sutton_learning_1988,
	title = {Learning to predict by the methods of temporal differences},
	volume = {3},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/BF00115009},
	doi = {10.1007/BF00115009},
	abstract = {This article introduces a class of incremental learning procedures specialized for prediction that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, tile new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference method{\textasciitilde} have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, telnporal-differenee methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporaldifference methods can be applied to advantage.},
	language = {en},
	number = {1},
	urldate = {2022-01-03},
	journal = {Mach Learn},
	author = {Sutton, Richard S.},
	month = aug,
	year = {1988},
	pages = {9--44},
	file = {Sutton - 1988 - Learning to predict by the methods of temporal dif.pdf:/Users/tito/Zotero/storage/L8HJBHPT/Sutton - 1988 - Learning to predict by the methods of temporal dif.pdf:application/pdf},
}

@article{cisek_neuroscience_2022,
	title = {Neuroscience needs evolution},
	volume = {377},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2020.0518},
	doi = {10.1098/rstb.2020.0518},
	abstract = {The nervous system is a product of evolution. That is, it was constructed through a long series of modifications, within the strong constraints of heredity, and continuously subjected to intense selection pressures. As a result, the organization and functions of the brain are shaped by its history. We believe that this fact, underappreciated in contemporary systems neuroscience, offers an invaluable aid for helping us resolve the brain's mysteries. Indeed, we think that the consideration of evolutionary history ought to take its place alongside other intellectual tools used to understand the brain, such as behavioural experiments, studies of anatomical structure and functional characterization based on recordings of neural activity. In this introduction, we argue for the importance of evolution by highlighting specific examples of ways that evolutionary theory can enhance neuroscience. The rest of the theme issue elaborates this point, emphasizing the conservative nature of neural evolution, the important consequences of specific transitions that occurred in our history, and the ways in which considerations of evolution can shed light on issues ranging from specific mechanisms to fundamental principles of brain organization.

This article is part of the theme issue ‘Systems neuroscience through the lens of evolutionary theory’.},
	number = {1844},
	urldate = {2022-01-03},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Cisek, Paul and Hayden, Benjamin Y.},
	month = feb,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {psychology, developmental neuroscience, evolutionary neuroscience, ontology, phylogenetic history},
	pages = {20200518},
	file = {Cisek_Hayden_2022_Neuroscience needs evolution.pdf:/Users/tito/Zotero/storage/EHV5ARZ4/Cisek_Hayden_2022_Neuroscience needs evolution.pdf:application/pdf},
}

@article{schutt_statistical_2021,
	title = {Statistical inference on representational geometries},
	url = {http://arxiv.org/abs/2112.09200},
	abstract = {Neuroscience has recently made much progress, expanding the complexity of both neural-activity measurements and brain-computational models. However, we lack robust methods for connecting theory and experiment by evaluating our new big models with our new big data. Here we introduce a new inferential methodology to evaluate models based on their predictions of representational geometries. The inference can handle flexible parametrized models and can treat both subjects and conditions as random effects, such that conclusions generalize to the respective populations of subjects and conditions. We validate the inference methods using extensive simulations with deep neural networks and resampling of calcium imaging and functional MRI data. Results demonstrate that the methods are valid and conclusions generalize correctly. These data analysis methods are available in an open-source Python toolbox.},
	urldate = {2022-01-03},
	journal = {arXiv:2112.09200 [q-bio]},
	author = {Schütt, Heiko H. and Kipnis, Alexander D. and Diedrichsen, Jörn and Kriegeskorte, Nikolaus},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.09200},
	keywords = {Quantitative Biology - Neurons and Cognition, Quantitative Biology - Quantitative Methods},
	annote = {Comment: 20 pages, 6 figures, 16 pages appendix},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/AKR46BVZ/2112.html:text/html;Schütt et al_2021_Statistical inference on representational geometries.pdf:/Users/tito/Zotero/storage/3II49EYI/Schütt et al_2021_Statistical inference on representational geometries.pdf:application/pdf},
}

@article{cisek_evolution_2022,
	title = {Evolution of behavioural control from chordates to primates},
	volume = {377},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2020.0522},
	doi = {10.1098/rstb.2020.0522},
	abstract = {This article outlines a hypothetical sequence of evolutionary innovations, along the lineage that produced humans, which extended behavioural control from simple feedback loops to sophisticated control of diverse species-typical actions. I begin with basic feedback mechanisms of ancient mobile animals and follow the major niche transitions from aquatic to terrestrial life, the retreat into nocturnality in early mammals, the transition to arboreal life and the return to diurnality. Along the way, I propose a sequence of elaboration and diversification of the behavioural repertoire and associated neuroanatomical substrates. This includes midbrain control of approach versus escape actions, telencephalic control of local versus long-range foraging, detection of affordances by the dorsal pallium, diversified control of nocturnal foraging in the mammalian neocortex and expansion of primate frontal, temporal and parietal cortex to support a wide variety of primate-specific behavioural strategies. The result is a proposed functional architecture consisting of parallel control systems, each dedicated to specifying the affordances for guiding particular species-typical actions, which compete against each other through a hierarchy of selection mechanisms.

This article is part of the theme issue ‘Systems neuroscience through the lens of evolutionary theory’.},
	number = {1844},
	urldate = {2022-01-03},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Cisek, Paul},
	month = feb,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {action maps, affordances, ethology, phylogenetic refinement, sensorimotor control, vertebrate evolution},
	pages = {20200522},
	file = {Cisek_2022_Evolution of behavioural control from chordates to primates.pdf:/Users/tito/Zotero/storage/D3QU47SF/Cisek_2022_Evolution of behavioural control from chordates to primates.pdf:application/pdf},
}

@article{pezzulo_evolution_2022,
	title = {The evolution of brain architectures for predictive coding and active inference},
	volume = {377},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2020.0531},
	doi = {10.1098/rstb.2020.0531},
	abstract = {This article considers the evolution of brain architectures for predictive processing. We argue that brain mechanisms for predictive perception and action are not late evolutionary additions of advanced creatures like us. Rather, they emerged gradually from simpler predictive loops (e.g. autonomic and motor reflexes) that were a legacy from our earlier evolutionary ancestors—and were key to solving their fundamental problems of adaptive regulation. We characterize simpler-to-more-complex brains formally, in terms of generative models that include predictive loops of increasing hierarchical breadth and depth. These may start from a simple homeostatic motif and be elaborated during evolution in four main ways: these include the multimodal expansion of predictive control into an allostatic loop; its duplication to form multiple sensorimotor loops that expand an animal's behavioural repertoire; and the gradual endowment of generative models with hierarchical depth (to deal with aspects of the world that unfold at different spatial scales) and temporal depth (to select plans in a future-oriented manner). In turn, these elaborations underwrite the solution to biological regulation problems faced by increasingly sophisticated animals. Our proposal aligns neuroscientific theorising—about predictive processing—with evolutionary and comparative data on brain architectures in different animal species.

This article is part of the theme issue ‘Systems neuroscience through the lens of evolutionary theory’.},
	number = {1844},
	urldate = {2022-01-03},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Pezzulo, Giovanni and Parr, Thomas and Friston, Karl},
	month = feb,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {active inference, brain architecture, brain evolution, model selection, natural selection, predictive processing},
	pages = {20200531},
	file = {Pezzulo et al_2022_The evolution of brain architectures for predictive coding and active inference.pdf:/Users/tito/Zotero/storage/2WYMCNDH/Pezzulo et al_2022_The evolution of brain architectures for predictive coding and active inference.pdf:application/pdf},
}

@article{schmitt_thalamic_2017,
	title = {Thalamic amplification of cortical connectivity sustains attentional control},
	volume = {545},
	copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature22073},
	doi = {10.1038/nature22073},
	abstract = {The mediodorsal nucleus of the thalamus amplifies the functional connectivity of the prefrontal cortex, thereby sustaining cortical representations of rule sets without relaying categorical information.},
	language = {en},
	number = {7653},
	urldate = {2022-01-04},
	journal = {Nature},
	author = {Schmitt, L. Ian and Wimmer, Ralf D. and Nakajima, Miho and Happ, Michael and Mofakham, Sima and Halassa, Michael M.},
	month = may,
	year = {2017},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 7653
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Attention;Cognitive control;Neural circuits
Subject\_term\_id: attention;cognitive-control;neural-circuit},
	keywords = {Attention, Cognitive control, Neural circuits},
	pages = {219--223},
	file = {Schmitt et al_2017_Thalamic amplification of cortical connectivity sustains attentional control.pdf:/Users/tito/Zotero/storage/2IIG8ERD/Schmitt et al_2017_Thalamic amplification of cortical connectivity sustains attentional control.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/SNIT9SZ8/nature22073.html:text/html},
}

@article{kennedy_temporal_2014,
	title = {A temporal basis for predicting the sensory consequences of motor commands in an electric fish},
	volume = {17},
	copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3650},
	doi = {10.1038/nn.3650},
	abstract = {To adaptively navigate their environments organisms need to predict and cancel out the sensory consequences of their actions. Here the authors show that granule cells within the cerebellum-like structure of weakly electric fish have delayed responses that closely match the timing of self-generated sensory inputs. This enables corollary discharges to be transformed into negative images that are well-tuned to the animal's own behavior.},
	language = {en},
	number = {3},
	urldate = {2022-01-06},
	journal = {Nat Neurosci},
	author = {Kennedy, Ann and Wayne, Greg and Kaifosh, Patrick and Alviña, Karina and Abbott, L. F. and Sawtell, Nathaniel B.},
	month = mar,
	year = {2014},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 3
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Neural encoding;Neurophysiology;Sensorimotor processing;Synaptic plasticity
Subject\_term\_id: neural-encoding;neurophysiology;sensorimotor-processing;synaptic-plasticity},
	keywords = {Neurophysiology, Synaptic plasticity, Sensorimotor processing, Neural encoding},
	pages = {416--422},
	file = {Kennedy et al_2014_A temporal basis for predicting the sensory consequences of motor commands in.pdf:/Users/tito/Zotero/storage/VPTLFNHH/Kennedy et al_2014_A temporal basis for predicting the sensory consequences of motor commands in.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/N28K3V4M/nn.html:text/html},
}

@article{leavitt_correlated_2017-1,
	title = {Correlated variability modifies working memory fidelity in primate prefrontal neuronal ensembles},
	volume = {114},
	copyright = {©  . http://www.pnas.org/site/misc/userlicense.xhtml},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/114/12/E2494},
	doi = {10.1073/pnas.1619949114},
	abstract = {Neurons in the primate lateral prefrontal cortex (LPFC) encode working memory (WM) representations via sustained firing, a phenomenon hypothesized to arise from recurrent dynamics within ensembles of interconnected neurons. Here, we tested this hypothesis by using microelectrode arrays to examine spike count correlations (rsc) in LPFC neuronal ensembles during a spatial WM task. We found a pattern of pairwise rsc during WM maintenance indicative of stronger coupling between similarly tuned neurons and increased inhibition between dissimilarly tuned neurons. We then used a linear decoder to quantify the effects of the high-dimensional rsc structure on information coding in the neuronal ensembles. We found that the rsc structure could facilitate or impair coding, depending on the size of the ensemble and tuning properties of its constituent neurons. A simple optimization procedure demonstrated that near-maximum decoding performance could be achieved using a relatively small number of neurons. These WM-optimized subensembles were more signal correlation (rsignal)-diverse and anatomically dispersed than predicted by the statistics of the full recorded population of neurons, and they often contained neurons that were poorly WM-selective, yet enhanced coding fidelity by shaping the ensemble’s rsc structure. We observed a pattern of rsc between LPFC neurons indicative of recurrent dynamics as a mechanism for WM-related activity and that the rsc structure can increase the fidelity of WM representations. Thus, WM coding in LPFC neuronal ensembles arises from a complex synergy between single neuron coding properties and multidimensional, ensemble-level phenomena.},
	language = {en},
	number = {12},
	urldate = {2022-01-06},
	journal = {PNAS},
	author = {Leavitt, Matthew L. and Pieper, Florian and Sachs, Adam J. and Martinez-Trujillo, Julio C.},
	month = mar,
	year = {2017},
	pmid = {28275096},
	note = {Publisher: National Academy of Sciences
Section: PNAS Plus},
	keywords = {noise correlations, prefrontal cortex, working memory, decoding, macaque},
	pages = {E2494--E2503},
	file = {Leavitt et al_2017_Correlated variability modifies working memory fidelity in primate prefrontal.pdf:/Users/tito/Zotero/storage/8S3F7IVJ/Leavitt et al_2017_Correlated variability modifies working memory fidelity in primate prefrontal.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TQHZU3PI/E2494.html:text/html},
}

@article{luo_within_2021,
	title = {Within node connectivity changes, not simply edge changes, influence graph theory measures in functional connectivity studies of the brain},
	volume = {240},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381192100608X},
	doi = {10.1016/j.neuroimage.2021.118332},
	abstract = {Interest in understanding the organization of the brain has led to the application of graph theory methods across a wide array of functional connectivity studies. The fundamental basis of a graph is the node. Recent work has shown that functional nodes reconfigure with brain state. To date, all graph theory studies of functional connectivity in the brain have used fixed nodes. Here, using fixed-, group-, state-specific, and individualized- parcellations for defining nodes, we demonstrate that functional connectivity changes within the nodes significantly influence the findings at the network level. In some cases, state- or group-dependent changes of the sort typically reported do not persist, while in others, changes are only observed when node reconfigurations are considered. The findings suggest that graph theory investigations into connectivity contrasts between brain states and/or groups should consider the influence of voxel-level changes that lead to node reconfigurations; the fundamental building block of a graph.},
	language = {en},
	urldate = {2022-01-06},
	journal = {NeuroImage},
	author = {Luo, Wenjing and Greene, Abigail S. and Constable, R. Todd},
	month = oct,
	year = {2021},
	keywords = {Functional connectivity, Graph theory, Functional parcellation, Network neuroscience, Brain, atlas},
	pages = {118332},
	file = {Luo et al_2021_Within node connectivity changes, not simply edge changes, influence graph.pdf:/Users/tito/Zotero/storage/L9K232WW/Luo et al_2021_Within node connectivity changes, not simply edge changes, influence graph.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/53TP4M66/S105381192100608X.html:text/html},
}

@techreport{kurzawski_influence_2021,
	title = {The influence of non-neural factors on {BOLD} signal magnitude},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.12.26.474185v1},
	abstract = {To what extent is the size of the blood-oxygen-level-dependent (BOLD) response influenced by factors other than neural activity? In a re-analysis of three neuroimaging datasets, we find large systematic inhomogeneities in the BOLD response magnitude in primary visual cortex (V1): stimulus-evoked BOLD responses, expressed in units of percent signal change, are up to 50\% larger along the representation of the horizontal meridian than the vertical meridian. To assess whether this surprising effect can be interpreted as differences in local neural activity, we quantified several factors that potentially contribute to the size of the BOLD response. We find strong relationships between BOLD response magnitude and cortical thickness, cortical curvature, and the presence of large veins. These relationships are consistently found across subjects and suggest that variation in BOLD response magnitudes across cortical locations reflects, in part, differences in anatomy and vascularization. To compensate for these factors, we implement a regression-based correction method and show that after correction, BOLD responses become more homogeneous across V1. The correction reduces the horizontal/vertical difference by about half, indicating that some of the difference is likely not due to neural activity differences. Additionally, we find that while the cerebral sinuses overlap with the vertical meridian representation in V1, they do not explain the observed horizontal/vertical difference. We conclude that interpretation of variation in BOLD response magnitude across cortical locations should consider the influence of the potential confounding factors of cortical thickness, curvature, and vascularization.
Significance statement The magnitude of the BOLD signal is often used as a surrogate of neural activity, but the exact factors that contribute to its strength have not been studied on a voxel-wise level. Here, we examined several anatomical and measurement-related factors to assess their relationship with BOLD magnitude. We find that BOLD magnitude correlates with cortical anatomy and macrovasculature. To remove the contribution of these factors, we propose a simple, data-driven model that can be used in any functional magnetic resonance imaging (fMRI) experiment. After accounting for the confounding factors, BOLD magnitude becomes more spatially homogenous. Our correction method improves the ability to make more accurate inferences about local neural activity from fMRI data.},
	language = {en},
	urldate = {2022-01-12},
	author = {Kurzawski, Jan W. and Gulban, Omer Faruk and Jamison, Keith and Winawer, Jonathan and Kay, Kendrick},
	month = dec,
	year = {2021},
	doi = {10.1101/2021.12.26.474185},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.12.26.474185},
	file = {Kurzawski et al_2021_The influence of non-neural factors on BOLD signal magnitude.pdf:/Users/tito/Zotero/storage/FUWFR7UJ/Kurzawski et al_2021_The influence of non-neural factors on BOLD signal magnitude.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/8F7TJCGE/2021.12.26.html:text/html},
}

@article{jazayeri_interpreting_2021,
	series = {Computational {Neuroscience}},
	title = {Interpreting neural computations by examining intrinsic and embedding dimensionality of neural activity},
	volume = {70},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438821000933},
	doi = {10.1016/j.conb.2021.08.002},
	abstract = {The ongoing exponential rise in recording capacity calls for new approaches for analysing and interpreting neural data. Effective dimensionality has emerged as an important property of neural activity across populations of neurons, yet different studies rely on different definitions and interpretations of this quantity. Here, we focus on intrinsic and embedding dimensionality, and discuss how they might reveal computational principles from data. Reviewing recent works, we propose that the intrinsic dimensionality reflects information about the latent variables encoded in collective activity while embedding dimensionality reveals the manner in which this information is processed. We conclude by highlighting the role of network models as an ideal substrate for testing more specifically various hypotheses on the computational principles reflected through intrinsic and embedding dimensionality.},
	language = {en},
	urldate = {2022-01-12},
	journal = {Current Opinion in Neurobiology},
	author = {Jazayeri, Mehrdad and Ostojic, Srdjan},
	month = oct,
	year = {2021},
	pages = {113--120},
	file = {Jazayeri_Ostojic_2021_Interpreting neural computations by examining intrinsic and embedding.pdf:/Users/tito/Zotero/storage/CG63THGC/Jazayeri_Ostojic_2021_Interpreting neural computations by examining intrinsic and embedding.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/KI2T2LAT/S0959438821000933.html:text/html},
}

@article{hinton_distilling_2015,
	title = {Distilling the {Knowledge} in a {Neural} {Network}},
	url = {http://arxiv.org/abs/1503.02531},
	abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
	urldate = {2022-01-12},
	journal = {arXiv:1503.02531 [cs, stat]},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.02531},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: NIPS 2014 Deep Learning Workshop},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/ZRYMW3TG/1503.html:text/html;Hinton et al_2015_Distilling the Knowledge in a Neural Network.pdf:/Users/tito/Zotero/storage/UKH2DMKJ/Hinton et al_2015_Distilling the Knowledge in a Neural Network.pdf:application/pdf},
}

@article{iyer_focal_2022,
	title = {Focal neural perturbations reshape low-dimensional trajectories of brain activity supporting cognitive performance},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-26978-2},
	doi = {10.1038/s41467-021-26978-2},
	abstract = {The emergence of distributed patterns of neural activity supporting brain functions and behavior can be understood by study of the brain’s low-dimensional topology. Functional neuroimaging demonstrates that brain activity linked to adaptive behavior is constrained to low-dimensional manifolds. In human participants, we tested whether these low-dimensional constraints preserve working memory performance following local neuronal perturbations. We combined multi-session functional magnetic resonance imaging, non-invasive transcranial magnetic stimulation (TMS), and methods translated from the fields of complex systems and computational biology to assess the functional link between changes in local neural activity and the reshaping of task-related low dimensional trajectories of brain activity. We show that specific reconfigurations of low-dimensional trajectories of brain activity sustain effective working memory performance following TMS manipulation of local activity on, but not off, the space traversed by these trajectories. We highlight an association between the multi-scale changes in brain activity underpinning cognitive function.},
	language = {en},
	number = {1},
	urldate = {2022-01-12},
	journal = {Nat Commun},
	author = {Iyer, Kartik K. and Hwang, Kai and Hearne, Luke J. and Muller, Eli and D’Esposito, Mark and Shine, James M. and Cocchi, Luca},
	month = jan,
	year = {2022},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Cognitive control;Dynamical systems
Subject\_term\_id: cognitive-control;dynamical-systems},
	keywords = {Dynamical systems, Cognitive control},
	pages = {4},
	file = {Iyer et al_2022_Focal neural perturbations reshape low-dimensional trajectories of brain.pdf:/Users/tito/Zotero/storage/XMLFKV53/Iyer et al_2022_Focal neural perturbations reshape low-dimensional trajectories of brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/EN9UWKV6/s41467-021-26978-2.html:text/html},
}

@article{gardner_toroidal_2022,
	title = {Toroidal topology of population activity in grid cells},
	copyright = {2022 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-04268-7},
	doi = {10.1038/s41586-021-04268-7},
	abstract = {The medial entorhinal cortex is part of a neural system for mapping the position of an individual within a physical environment1. Grid cells, a key component of this system, fire in a characteristic hexagonal pattern of locations2, and are organized in modules3 that collectively form a population code for the animal’s allocentric position1. The invariance of the correlation structure of this population code across environments4,5 and behavioural states6,7, independent of specific sensory inputs, has pointed to intrinsic, recurrently connected continuous attractor networks (CANs) as a possible substrate of the grid pattern1,8–11. However, whether grid cell networks show continuous attractor dynamics, and how they interface with inputs from the environment, has remained unclear owing to the small samples of cells obtained so far. Here, using simultaneous recordings from many hundreds of grid cells and subsequent topological data analysis, we show that the joint activity of grid cells from an individual module resides on a toroidal manifold, as expected in a two-dimensional CAN. Positions on the torus correspond to positions of the moving animal in the environment. Individual cells are preferentially active at singular positions on the torus. Their positions are maintained between environments and from wakefulness to sleep, as predicted by CAN models for grid cells but not by alternative feedforward models12. This demonstration of network dynamics on a toroidal manifold provides a population-level visualization of CAN dynamics in grid cells.},
	language = {en},
	urldate = {2022-01-12},
	journal = {Nature},
	author = {Gardner, Richard J. and Hermansen, Erik and Pachitariu, Marius and Burak, Yoram and Baas, Nils A. and Dunn, Benjamin A. and Moser, May-Britt and Moser, Edvard I.},
	month = jan,
	year = {2022},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Network models;Neural circuits
Subject\_term\_id: network-models;neural-circuit},
	keywords = {Network models, Neural circuits},
	pages = {1--6},
	file = {Gardner et al_2022_Toroidal topology of population activity in grid cells.pdf:/Users/tito/Zotero/storage/VZ93NVZQ/Gardner et al_2022_Toroidal topology of population activity in grid cells.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/QMMKB3JP/s41586-021-04268-7.html:text/html},
}

@article{chao_computing_2022,
	title = {Computing hemodynamic response functions from concurrent spectral fiber-photometry and {fMRI} data},
	volume = {9},
	issn = {2329-423X, 2329-4248},
	url = {https://www.spiedigitallibrary.org/journals/neurophotonics/volume-9/issue-3/032205/Computing-hemodynamic-response-functions-from-concurrent-spectral-fiber-photometry-and/10.1117/1.NPh.9.3.032205.full},
	doi = {10.1117/1.NPh.9.3.032205},
	abstract = {Significance: Although emerging evidence suggests that the hemodynamic response function (HRF) can vary by brain region and species, a single, canonical, human-based HRF is widely used in animal studies. Therefore, the development of flexible, accessible, brain-region specific HRF calculation approaches is paramount as hemodynamic animal studies become increasingly popular. Aim: To establish an fMRI-compatible, spectral, fiber-photometry platform for HRF calculation and validation in any rat brain region. Approach: We used our platform to simultaneously measure (a) neuronal activity via genetically encoded calcium indicators (GCaMP6f), (b) local cerebral blood volume (CBV) from intravenous Rhodamine B dye, and (c) whole brain CBV via fMRI with the Feraheme contrast agent. Empirical HRFs were calculated with GCaMP6f and Rhodamine B recordings from rat brain regions during resting-state and task-based paradigms. Results: We calculated empirical HRFs for the rat primary somatosensory, anterior cingulate, prelimbic, retrosplenial, and anterior insular cortical areas. Each HRF was faster and narrower than the canonical HRF and no significant difference was observed between these cortical regions. When used in general linear model analyses of corresponding fMRI data, the empirical HRFs showed better detection performance than the canonical HRF. Conclusions: Our findings demonstrate the viability and utility of fiber-photometry-based HRF calculations. This platform is readily scalable to multiple simultaneous recording sites, and adaptable to study transfer functions between stimulation events, neuronal activity, neurotransmitter release, and hemodynamic responses.},
	number = {3},
	urldate = {2022-01-12},
	journal = {NPh},
	author = {Chao, Tzu-Hao H. and Zhang, Wei-Ting and Hsu, Li-Ming and Cerri, Domenic H. and Wang, Tzu-Wen and Shih, Yen-Yu I.},
	month = jan,
	year = {2022},
	note = {Publisher: SPIE},
	pages = {032205},
	file = {Chao et al_2022_Computing hemodynamic response functions from concurrent spectral.pdf:/Users/tito/Zotero/storage/EB5MT5V9/Chao et al_2022_Computing hemodynamic response functions from concurrent spectral.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/43DGIE6V/1.NPh.9.3.032205.html:text/html},
}

@article{jiang_predictive_2021,
	title = {Predictive {Coding} {Theories} of {Cortical} {Function}},
	url = {http://arxiv.org/abs/2112.10048},
	abstract = {Predictive coding is a unifying framework for understanding perception, action and neocortical organization. In predictive coding, different areas of the neocortex implement a hierarchical generative model of the world that is learned from sensory inputs. Cortical circuits are hypothesized to perform Bayesian inference based on this generative model. Specifically, the Rao-Ballard hierarchical predictive coding model assumes that the top-down feedback connections from higher to lower order cortical areas convey predictions of lower-level activities. The bottom-up, feedforward connections in turn convey the errors between top-down predictions and actual activities. These errors are used to correct current estimates of the state of the world and generate new predictions. Through the objective of minimizing prediction errors, predictive coding provides a functional explanation for a wide range of neural responses and many aspects of brain organization.},
	urldate = {2022-01-12},
	journal = {arXiv:2112.10048 [q-bio]},
	author = {Jiang, Linxing Preston and Rao, Rajesh P. N.},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.10048},
	keywords = {Quantitative Biology - Neurons and Cognition},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/7579IF4P/2112.html:text/html;Jiang_Rao_2021_Predictive Coding Theories of Cortical Function.pdf:/Users/tito/Zotero/storage/69FUDEEU/Jiang_Rao_2021_Predictive Coding Theories of Cortical Function.pdf:application/pdf},
}

@article{hwang_human_2017-1,
	title = {The {Human} {Thalamus} {Is} an {Integrative} {Hub} for {Functional} {Brain} {Networks}},
	volume = {37},
	copyright = {Copyright © 2017 the authors 0270-6474/17/375594-14\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/37/23/5594},
	doi = {10.1523/JNEUROSCI.0067-17.2017},
	abstract = {The thalamus is globally connected with distributed cortical regions, yet the functional significance of this extensive thalamocortical connectivity remains largely unknown. By performing graph-theoretic analyses on thalamocortical functional connectivity data collected from human participants, we found that most thalamic subdivisions display network properties that are capable of integrating multimodal information across diverse cortical functional networks. From a meta-analysis of a large dataset of functional brain-imaging experiments, we further found that the thalamus is involved in multiple cognitive functions. Finally, we found that focal thalamic lesions in humans have widespread distal effects, disrupting the modular organization of cortical functional networks. This converging evidence suggests that the human thalamus is a critical hub region that could integrate diverse information being processed throughout the cerebral cortex as well as maintain the modular structure of cortical functional networks.
SIGNIFICANCE STATEMENT The thalamus is traditionally viewed as a passive relay station of information from sensory organs or subcortical structures to the cortex. However, the thalamus has extensive connections with the entire cerebral cortex, which can also serve to integrate information processing between cortical regions. In this study, we demonstrate that multiple thalamic subdivisions display network properties that are capable of integrating information across multiple functional brain networks. Moreover, the thalamus is engaged by tasks requiring multiple cognitive functions. These findings support the idea that the thalamus is involved in integrating information across cortical networks.},
	language = {en},
	number = {23},
	urldate = {2022-01-12},
	journal = {J. Neurosci.},
	author = {Hwang, Kai and Bertolero, Maxwell A. and Liu, William B. and D'Esposito, Mark},
	month = jun,
	year = {2017},
	pmid = {28450543},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {brain networks, functional connectivity, graph theory, thalamus, diaschisis},
	pages = {5594--5607},
	file = {Hwang et al_2017_The Human Thalamus Is an Integrative Hub for Functional Brain Networks.pdf:/Users/tito/Zotero/storage/AWC2DHPE/Hwang et al_2017_The Human Thalamus Is an Integrative Hub for Functional Brain Networks.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZXEM27EK/5594.html:text/html},
}

@article{dezfouli_models_2019,
	title = {Models that learn how humans learn: {The} case of decision-making and its disorders},
	volume = {15},
	issn = {1553-7358},
	shorttitle = {Models that learn how humans learn},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006903},
	doi = {10.1371/journal.pcbi.1006903},
	abstract = {Popular computational models of decision-making make specific assumptions about learning processes that may cause them to underfit observed behaviours. Here we suggest an alternative method using recurrent neural networks (RNNs) to generate a flexible family of models that have sufficient capacity to represent the complex learning and decision- making strategies used by humans. In this approach, an RNN is trained to predict the next action that a subject will take in a decision-making task and, in this way, learns to imitate the processes underlying subjects’ choices and their learning abilities. We demonstrate the benefits of this approach using a new dataset drawn from patients with either unipolar (n = 34) or bipolar (n = 33) depression and matched healthy controls (n = 34) making decisions on a two-armed bandit task. The results indicate that this new approach is better than baseline reinforcement-learning methods in terms of overall performance and its capacity to predict subjects’ choices. We show that the model can be interpreted using off-policy simulations and thereby provides a novel clustering of subjects’ learning processes—something that often eludes traditional approaches to modelling and behavioural analysis.},
	language = {en},
	number = {6},
	urldate = {2022-01-12},
	journal = {PLOS Computational Biology},
	author = {Dezfouli, Amir and Griffiths, Kristi and Ramos, Fabio and Dayan, Peter and Balleine, Bernard W.},
	month = jun,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Statistical models, Behavior, Learning, Human learning, Simulation and modeling, Decision making, Depression, Recurrent neural networks},
	pages = {e1006903},
	file = {Dezfouli et al_2019_Models that learn how humans learn.pdf:/Users/tito/Zotero/storage/YNH78DIR/Dezfouli et al_2019_Models that learn how humans learn.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/CJ5SHA3Y/article.html:text/html},
}

@article{ritchie_avoiding_2017-1,
	title = {Avoiding illusory effects in representational similarity analysis: {What} (not) to do with the diagonal},
	volume = {148},
	issn = {1053-8119},
	shorttitle = {Avoiding illusory effects in representational similarity analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811916308059},
	doi = {10.1016/j.neuroimage.2016.12.079},
	abstract = {Representational similarity analysis (RSA) is an important part of the methodological toolkit in neuroimaging research. The focus of the approach is the construction of representational dissimilarity matrices (RDMs), which provide a single format for making comparisons between different neural data types, computational models, and behavior. We highlight two issues for the construction and comparison of RDMs. First, the diagonal values of RDMs, which should reflect within condition reliability of neural patterns, are typically not estimated in RSA. However, without such an estimate, one lacks a measure of the reliability of an RDM as a whole. Thus, when carrying out RSA, one should calculate the diagonal values of RDMs and not take them for granted. Second, although diagonal values of a correlation matrix can be used to estimate the reliability of neural patterns, these values must nonetheless be excluded when comparing RDMs. Via a simple simulation we show that inclusion of these values can generate convincing looking, but entirely illusory, correlations between independent and entirely unrelated data sets. Both of these points are further illustrated by a critical discussion of Coggan et al. (2016), who investigated the extent to which category-selectivity in the ventral temporal cortex can be accounted for by low-level image properties of visual object stimuli. We observe that their results may depend on the improper inclusion of diagonal values in their analysis.},
	language = {en},
	urldate = {2022-01-12},
	journal = {NeuroImage},
	author = {Ritchie, J. Brendan and Bracci, Stefania and Op de Beeck, Hans},
	month = mar,
	year = {2017},
	keywords = {Neuroimaging, Object categorization, Representational similarity analysis, Ventral temporal cortex},
	pages = {197--200},
	file = {Ritchie et al_2017_Avoiding illusory effects in representational similarity analysis.pdf:/Users/tito/Zotero/storage/33HGSDN9/Ritchie et al_2017_Avoiding illusory effects in representational similarity analysis.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/VFWKGTSI/S1053811916308059.html:text/html},
}

@techreport{wang_critical-like_2022,
	type = {preprint},
	title = {Critical-like bistable dynamics in the resting-state human brain},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.01.09.475554},
	abstract = {Brain activity exhibits scale-free avalanche dynamics and power-law long-range temporal correlations (LRTCs) across the nervous system. This has been thought to reflect “brain criticality”, i.e., brains operating near a critical phase transition between disorder and excessive order. Neuronal activity is, however, metabolically costly and may be constrained by activitylimiting mechanisms and resource depletion, which could make the phase transition discontinuous and bistable. Observations of bistability in awake human brain activity have nonetheless remained scarce and its functional significance unclear. First, using computational modelling where bistable synchronization dynamics emerged through local positive feedback, we found bistability to occur exclusively in a regime of critical-like dynamics. We then assessed bistability in vivo with resting-state magnetoencephalography and stereo-encephalography. Bistability was a robust characteristic of cortical oscillations throughout frequency bands from  (3−7 Hz) to high- (100−225 Hz). As predicted by modelling, bistability and LRTCs were positively correlated. Importantly, while moderate levels of bistability were positively correlated with executive functioning, excessive bistability was associated with epileptic pathophysiology and predictive of local epileptogenicity. Critical bistability is thus a salient feature of spontaneous human brain dynamics in awake resting-state and is both functionally and clinically significant. These findings expand the framework of brain criticality and show that critical-like neuronal dynamics in vivo involves both continuous and discontinuous phase transitions in a frequency-, neuroanatomy-, and state-dependent manner.},
	language = {en},
	urldate = {2022-01-18},
	institution = {Neuroscience},
	author = {Wang, Sheng H. and Arnulfo, Gabriele and Myrov, Vladislav and Siebenhühner, Felix and Nobili, Lino and Breakspear, Michael and Palva, Satu and Palva, J. Matias},
	month = jan,
	year = {2022},
	doi = {10.1101/2022.01.09.475554},
	file = {Wang et al. - 2022 - Critical-like bistable dynamics in the resting-sta.pdf:/Users/tito/Zotero/storage/4NZLRRJ6/Wang et al. - 2022 - Critical-like bistable dynamics in the resting-sta.pdf:application/pdf},
}

@article{joshi_context-dependent_2022,
	title = {Context-dependent relationships between locus coeruleus firing patterns and coordinated neural activity in the anterior cingulate cortex},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.63490},
	doi = {10.7554/eLife.63490},
	abstract = {Ascending neuromodulatory projections from the locus coeruleus (LC) affect cortical neural networks via the release of norepinephrine (NE). However, the exact nature of these neuromodulatory effects on neural activity patterns in vivo is not well understood. Here, we show that in awake monkeys, LC activation is associated with changes in coordinated activity patterns in the anterior cingulate cortex (ACC). These relationships, which are largely independent of changes in firing rates of individual ACC neurons, depend on the type of LC activation: ACC pairwise correlations tend to be reduced when ongoing (baseline) LC activity increases but enhanced when external events evoke transient LC responses. Both relationships covary with pupil changes that reflect LC activation and arousal. These results suggest that modulations of information processing that reflect changes in coordinated activity patterns in cortical networks can result partly from ongoing, context-dependent, arousal-related changes in activation of the LC-NE system.},
	urldate = {2022-01-18},
	journal = {eLife},
	author = {Joshi, Siddhartha and Gold, Joshua I},
	editor = {Rich, Erin L and Moore, Tirin and Donner, Tobias H},
	month = jan,
	year = {2022},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {neuromodulation, locus coeruleus, pupil size, cingulate, correlations, pupillometry},
	pages = {e63490},
	file = {Joshi_Gold_2022_Context-dependent relationships between locus coeruleus firing patterns and.pdf:/Users/tito/Zotero/storage/ZHWU8QXE/Joshi_Gold_2022_Context-dependent relationships between locus coeruleus firing patterns and.pdf:application/pdf},
}

@article{krishnamurthy_theory_2022,
	title = {Theory of {Gating} in {Recurrent} {Neural} {Networks}},
	volume = {12},
	url = {https://link.aps.org/doi/10.1103/PhysRevX.12.011011},
	doi = {10.1103/PhysRevX.12.011011},
	abstract = {Recurrent neural networks (RNNs) are powerful dynamical models, widely used in machine learning (ML) and neuroscience. Prior theoretical work has focused on RNNs with additive interactions. However, gating, i.e., multiplicative, interactions are ubiquitous in real neurons and also the central feature of the best-performing RNNs in ML. Here, we show that gating offers flexible control of two salient features of the collective dynamics: (i) timescales and (ii) dimensionality. The gate controlling timescales leads to a novel, marginally stable state, where the network functions as a flexible integrator. Unlike previous approaches, gating permits this important function without parameter fine-tuning or special symmetries. Gates also provide a flexible, context-dependent mechanism to reset the memory trace, thus complementing the memory function. The gate modulating the dimensionality can induce a novel, discontinuous chaotic transition, where inputs push a stable system to strong chaotic activity, in contrast to the typically stabilizing effect of inputs. At this transition, unlike additive RNNs, the proliferation of critical points (topological complexity) is decoupled from the appearance of chaotic dynamics (dynamical complexity). The rich dynamics are summarized in phase diagrams, thus providing a map for principled parameter initialization choices to ML practitioners.},
	number = {1},
	urldate = {2022-01-19},
	journal = {Phys. Rev. X},
	author = {Krishnamurthy, Kamesh and Can, Tankut and Schwab, David J.},
	month = jan,
	year = {2022},
	note = {Publisher: American Physical Society},
	pages = {011011},
	file = {Krishnamurthy et al_2022_Theory of Gating in Recurrent Neural Networks.pdf:/Users/tito/Zotero/storage/FYGA49U2/Krishnamurthy et al_2022_Theory of Gating in Recurrent Neural Networks.pdf:application/pdf},
}

@article{fefferman_testing_2016,
	title = {Testing the manifold hypothesis},
	volume = {29},
	issn = {0894-0347, 1088-6834},
	url = {https://www.ams.org/jams/2016-29-04/S0894-0347-2016-00852-4/},
	doi = {10.1090/jams/852},
	abstract = {Abstract:},
	language = {en},
	number = {4},
	urldate = {2022-01-19},
	journal = {J. Amer. Math. Soc.},
	author = {Fefferman, Charles and Mitter, Sanjoy and Narayanan, Hariharan},
	month = oct,
	year = {2016},
	pages = {983--1049},
	file = {Fefferman et al_2016_Testing the manifold hypothesis.pdf:/Users/tito/Zotero/storage/W54NKJBQ/Fefferman et al_2016_Testing the manifold hypothesis.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/UGZW8D6N/S0894-0347-2016-00852-4.html:text/html},
}

@article{miconi_learning_2022,
	title = {Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning},
	url = {http://arxiv.org/abs/2112.08588},
	abstract = {In meta-learning, networks are trained with external algorithms to learn tasks that require acquiring, storing and exploiting unpredictable information for each new instance of the task. However, animals are able to pick up such cognitive tasks automatically, as a result of their evolved neural architecture and synaptic plasticity mechanisms. Here we evolve neural networks, endowed with plastic connections, over a sizeable set of simple meta-learning tasks based on a framework from computational neuroscience. The resulting evolved network can automatically acquire a novel simple cognitive task, never seen during training, through the spontaneous operation of its evolved neural organization and plasticity structure. We suggest that attending to the multiplicity of loops involved in natural learning may provide useful insight into the emergence of intelligent behavior},
	urldate = {2022-01-19},
	journal = {arXiv:2112.08588 [cs]},
	author = {Miconi, Thomas},
	month = jan,
	year = {2022},
	note = {arXiv: 2112.08588},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/EHX876JR/2112.html:text/html;Miconi_2022_Learning to acquire novel cognitive tasks with evolution, plasticity and.pdf:/Users/tito/Zotero/storage/85IY37WN/Miconi_2022_Learning to acquire novel cognitive tasks with evolution, plasticity and.pdf:application/pdf},
}

@article{tenenbaum_how_2011,
	title = {How to {Grow} a {Mind}: {Statistics}, {Structure}, and {Abstraction}},
	volume = {331},
	issn = {0036-8075, 1095-9203},
	shorttitle = {How to {Grow} a {Mind}},
	url = {https://www.science.org/doi/10.1126/science.1192788},
	doi = {10.1126/science.1192788},
	abstract = {In coming to understand the world—in learning concepts, acquiring language, and grasping causal relations—our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
	language = {en},
	number = {6022},
	urldate = {2022-01-19},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and Kemp, Charles and Griffiths, Thomas L. and Goodman, Noah D.},
	month = mar,
	year = {2011},
	pages = {1279--1285},
	file = {Tenenbaum et al. - 2011 - How to Grow a Mind Statistics, Structure, and Abs.pdf:/Users/tito/Zotero/storage/R6TYY2TD/Tenenbaum et al. - 2011 - How to Grow a Mind Statistics, Structure, and Abs.pdf:application/pdf},
}

@article{xu_cortical_2022,
	title = {The cortical connectome of primate lateral prefrontal cortex},
	volume = {110},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(21)00786-8},
	doi = {10.1016/j.neuron.2021.10.018},
	language = {English},
	number = {2},
	urldate = {2022-01-19},
	journal = {Neuron},
	author = {Xu, Rui and Bichot, Narcisse P. and Takahashi, Atsushi and Desimone, Robert},
	month = jan,
	year = {2022},
	pmid = {34739817},
	note = {Publisher: Elsevier},
	keywords = {fMRI, executive control, cortical organization, dense connectome, electrical microstimulation, topographic connectivity},
	pages = {312--327.e7},
	file = {Snapshot:/Users/tito/Zotero/storage/ZUMKYNUP/S0896-6273(21)00786-8.html:text/html;Xu et al_2022_The cortical connectome of primate lateral prefrontal cortex.pdf:/Users/tito/Zotero/storage/XLN3QSCL/Xu et al_2022_The cortical connectome of primate lateral prefrontal cortex.pdf:application/pdf},
}

@article{stern_reservoir_2021,
	title = {A reservoir of timescales in random neural networks},
	url = {http://arxiv.org/abs/2110.09165},
	abstract = {The temporal activity of many biological systems, including neural circuits, exhibits fluctuations simultaneously varying over a large range of timescales. The mechanisms leading to this temporal heterogeneity are yet unknown. Here we show that random neural networks endowed with a distribution of self-couplings, representing functional neural clusters of different sizes, generate multiple timescales activity spanning several orders of magnitude. When driven by a time-dependent broadband input, slow and fast neural clusters preferentially entrain slow and fast spectral components of the input, respectively, suggesting a potential mechanism for spectral demixing in cortical circuits.},
	urldate = {2022-01-21},
	journal = {arXiv:2110.09165 [cond-mat, physics:nlin, q-bio]},
	author = {Stern, Merav and Istrate, Nicolae and Mazzucato, Luca},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.09165},
	keywords = {Quantitative Biology - Neurons and Cognition, Condensed Matter - Disordered Systems and Neural Networks, Nonlinear Sciences - Chaotic Dynamics},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/QF3BHNKB/2110.html:text/html;Stern et al_2021_A reservoir of timescales in random neural networks.pdf:/Users/tito/Zotero/storage/722YZ5D8/Stern et al_2021_A reservoir of timescales in random neural networks.pdf:application/pdf},
}

@article{salimi-khorshidi_automatic_2014,
	title = {Automatic denoising of functional {MRI} data: combining independent component analysis and hierarchical fusion of classifiers},
	volume = {90},
	issn = {1095-9572},
	shorttitle = {Automatic denoising of functional {MRI} data},
	doi = {10.1016/j.neuroimage.2013.11.046},
	abstract = {Many sources of fluctuation contribute to the fMRI signal, and this makes identifying the effects that are truly related to the underlying neuronal activity difficult. Independent component analysis (ICA) - one of the most widely used techniques for the exploratory analysis of fMRI data - has shown to be a powerful technique in identifying various sources of neuronally-related and artefactual fluctuation in fMRI data (both with the application of external stimuli and with the subject "at rest"). ICA decomposes fMRI data into patterns of activity (a set of spatial maps and their corresponding time series) that are statistically independent and add linearly to explain voxel-wise time series. Given the set of ICA components, if the components representing "signal" (brain activity) can be distinguished form the "noise" components (effects of motion, non-neuronal physiology, scanner artefacts and other nuisance sources), the latter can then be removed from the data, providing an effective cleanup of structured noise. Manual classification of components is labour intensive and requires expertise; hence, a fully automatic noise detection algorithm that can reliably detect various types of noise sources (in both task and resting fMRI) is desirable. In this paper, we introduce FIX ("FMRIB's ICA-based X-noiseifier"), which provides an automatic solution for denoising fMRI data via accurate classification of ICA components. For each ICA component FIX generates a large number of distinct spatial and temporal features, each describing a different aspect of the data (e.g., what proportion of temporal fluctuations are at high frequencies). The set of features is then fed into a multi-level classifier (built around several different classifiers). Once trained through the hand-classification of a sufficient number of training datasets, the classifier can then automatically classify new datasets. The noise components can then be subtracted from (or regressed out of) the original data, to provide automated cleanup. On conventional resting-state fMRI (rfMRI) single-run datasets, FIX achieved about 95\% overall accuracy. On high-quality rfMRI data from the Human Connectome Project, FIX achieves over 99\% classification accuracy, and as a result is being used in the default rfMRI processing pipeline for generating HCP connectomes. FIX is publicly available as a plugin for FSL.},
	language = {eng},
	journal = {Neuroimage},
	author = {Salimi-Khorshidi, Gholamreza and Douaud, Gwenaëlle and Beckmann, Christian F. and Glasser, Matthew F. and Griffanti, Ludovica and Smith, Stephen M.},
	month = apr,
	year = {2014},
	pmid = {24389422},
	pmcid = {PMC4019210},
	keywords = {Brain, Brain Mapping, Humans, Magnetic Resonance Imaging, Algorithms, Artifacts, Image Processing, Computer-Assisted, Principal Component Analysis},
	pages = {449--468},
	file = {Accepted Version:/Users/tito/Zotero/storage/HAHK3GBK/Salimi-Khorshidi et al. - 2014 - Automatic denoising of functional MRI data combin.pdf:application/pdf},
}

@article{mei_informing_2022,
	title = {Informing deep neural networks by multiscale principles of neuromodulatory systems},
	issn = {0166-2236},
	url = {https://www.sciencedirect.com/science/article/pii/S0166223621002563},
	doi = {10.1016/j.tins.2021.12.008},
	abstract = {Our brains have evolved the ability to configure and adapt their processing states to match the unique challenges of acting and learning in diverse environments and behavioral contexts. In biological nervous systems, such state specification and adaptation arise in part from neuromodulators, including acetylcholine, noradrenaline, serotonin, and dopamine, whose diffuse release fine-tunes neuronal and synaptic dynamics and plasticity to complement the behavioral context in real-time. Despite the demonstrated effectiveness of deep neural networks for specific tasks, they remain relatively inflexible at generalizing across tasks or adapting to ever-changing behavioral demands. In this article, we provide an overview of neuromodulatory systems and their relationship to emerging pertinent principles in deep neural networks. We further outline opportunities for the integration of neuromodulatory principles into deep neural networks, towards endowing artificial intelligence with a key ingredient underlying the flexibility and learning capability of biological systems.},
	language = {en},
	urldate = {2022-01-24},
	journal = {Trends in Neurosciences},
	author = {Mei, Jie and Muller, Eilif and Ramaswamy, Srikanth},
	month = jan,
	year = {2022},
	keywords = {noradrenaline, dopamine, serotonin, acetylcholine, adaptive learning, multiscale organization},
	file = {Mei et al_2022_Informing deep neural networks by multiscale principles of neuromodulatory.pdf:/Users/tito/Zotero/storage/CAAA3LLA/Mei et al_2022_Informing deep neural networks by multiscale principles of neuromodulatory.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/UHBULMVB/S0166223621002563.html:text/html},
}

@techreport{volzhenin_multilevel_2022,
	title = {Multilevel {Development} of {Cognitive} {Abilities} in an {Artificial} {Neural} {Network}},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.01.24.477526v1},
	abstract = {Several neuronal mechanisms have been proposed to account for the formation of cognitive abilities through postnatal interactions with the physical and socio-cultural environment. Here, we introduce a three-level computational model of information processing and acquisition of cognitive abilities. We propose minimal architectural requirements to build these levels and how the parameters affect their performance and relationships. The first sensorimotor level handles local nonconscious processing, here during a visual classification task. The second level or cognitive level globally integrates the information from multiple local processors via long-ranged connections and synthesizes it in a global, but still nonconscious manner. The third and cognitively highest level handles the information globally and consciously. It is based on the Global Neuronal Workspace (GNW) theory and is referred to as conscious level. We use trace and delay conditioning tasks to, respectively, challenge the second and third levels. Results first highlight the necessity of epigenesis through selection and stabilization of synapses at both local and global scales to allow the network to solve the first two tasks. At the global scale, dopamine appears necessary to properly provide credit assignment despite the temporal delay between perception and reward. At the third level, the presence of interneurons becomes necessary to maintain a self-sustained representation within the GNW in the absence of sensory input. Finally, while balanced spontaneous intrinsic activity facilitates epigenesis at both local and global scales, the balanced excitatory-inhibitory ratio increases performance. Finally, we discuss the plausibility of the model in both neurodevelopmental and artificial intelligence terms.},
	language = {en},
	urldate = {2022-01-25},
	institution = {bioRxiv},
	author = {Volzhenin, Konstantin and Changeux, Jean-Pierre and Dumas, Guillaume},
	month = jan,
	year = {2022},
	doi = {10.1101/2022.01.24.477526},
	note = {Section: New Results
Type: article},
	pages = {2022.01.24.477526},
	file = {Snapshot:/Users/tito/Zotero/storage/935RYYJS/2022.01.24.html:text/html;Volzhenin et al_2022_Multilevel Development of Cognitive Abilities in an Artificial Neural Network.pdf:/Users/tito/Zotero/storage/T394NYB7/Volzhenin et al_2022_Multilevel Development of Cognitive Abilities in an Artificial Neural Network.pdf:application/pdf},
}

@article{khaligh-razavi_deep_2014,
	title = {Deep {Supervised}, but {Not} {Unsupervised}, {Models} {May} {Explain} {IT} {Cortical} {Representation}},
	volume = {10},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003915},
	doi = {10.1371/journal.pcbi.1003915},
	abstract = {Inferior temporal (IT) cortex in human and nonhuman primates serves visual object recognition. Computational object-vision models, although continually improving, do not yet reach human performance. It is unclear to what extent the internal representations of computational models can explain the IT representation. Here we investigate a wide range of computational model representations (37 in total), testing their categorization performance and their ability to account for the IT representational geometry. The models include well-known neuroscientific object-recognition models (e.g. HMAX, VisNet) along with several models from computer vision (e.g. SIFT, GIST, self-similarity features, and a deep convolutional neural network). We compared the representational dissimilarity matrices (RDMs) of the model representations with the RDMs obtained from human IT (measured with fMRI) and monkey IT (measured with cell recording) for the same set of stimuli (not used in training the models). Better performing models were more similar to IT in that they showed greater clustering of representational patterns by category. In addition, better performing models also more strongly resembled IT in terms of their within-category representational dissimilarities. Representational geometries were significantly correlated between IT and many of the models. However, the categorical clustering observed in IT was largely unexplained by the unsupervised models. The deep convolutional network, which was trained by supervision with over a million category-labeled images, reached the highest categorization performance and also best explained IT, although it did not fully explain the IT data. Combining the features of this model with appropriate weights and adding linear combinations that maximize the margin between animate and inanimate objects and between faces and other objects yielded a representation that fully explained our IT data. Overall, our results suggest that explaining IT requires computational features trained through supervised learning to emphasize the behaviorally important categorical divisions prominently reflected in IT.},
	language = {en},
	number = {11},
	urldate = {2022-01-26},
	journal = {PLOS Computational Biology},
	author = {Khaligh-Razavi, Seyed-Mahdi and Kriegeskorte, Nikolaus},
	month = nov,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Functional magnetic resonance imaging, Learning, Face, Vision, Neural networks, Permutation, Monkeys, Computer vision},
	pages = {e1003915},
	file = {Khaligh-Razavi_Kriegeskorte_2014_Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical.pdf:/Users/tito/Zotero/storage/RH2NZFWW/Khaligh-Razavi_Kriegeskorte_2014_Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical.pdf:application/pdf},
}

@article{brette_is_2019-1,
	title = {Is coding a relevant metaphor for the brain?},
	volume = {42},
	journal = {Behavioral and Brain Sciences},
	author = {Brette, Romain},
	year = {2019},
	note = {Publisher: Cambridge University Press},
	file = {Brette_2019_Is coding a relevant metaphor for the brain.pdf:/Users/tito/Zotero/storage/AYIF9QU4/Brette_2019_Is coding a relevant metaphor for the brain.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TGQREN8N/D578626E4888193FFFAE5B6E2C37E052.html:text/html},
}

@article{flesch_orthogonal_2022,
	title = {Orthogonal representations for robust context-dependent task performance in brains and neural networks},
	volume = {0},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(22)00005-8},
	doi = {10.1016/j.neuron.2022.01.005},
	language = {English},
	number = {0},
	urldate = {2022-01-26},
	journal = {Neuron},
	author = {Flesch, Timo and Juechems, Keno and Dumbalska, Tsvetomira and Saxe, Andrew and Summerfield, Christopher},
	month = jan,
	year = {2022},
	note = {Publisher: Elsevier},
	keywords = {functional magnetic resonance imaging, artificial neural networks, orthogonal manifolds, representational geometry, task learning},
	file = {Flesch et al_2022_Orthogonal representations for robust context-dependent task performance in.pdf:/Users/tito/Zotero/storage/CPNVUZ6H/Flesch et al_2022_Orthogonal representations for robust context-dependent task performance in.pdf:application/pdf},
}

@article{cocuzza_protocol_2022,
	title = {Protocol for activity flow mapping of neurocognitive computations using the {Brain} {Activity} {Flow} {Toolbox}},
	volume = {3},
	issn = {2666-1667},
	url = {https://www.sciencedirect.com/science/article/pii/S2666166721008005},
	doi = {10.1016/j.xpro.2021.101094},
	abstract = {Traditional cognitive neuroscience uses task-evoked activations to map neurocognitive processes (and information) to brain regions; however, how those processes are generated is unknown. We developed activity flow mapping to identify and empirically validate network mechanisms underlying the generation of neurocognitive processes. This approach models the movement of task-evoked activity over brain connections to predict task-evoked activations. We present a protocol for using the Brain Activity Flow Toolbox (https://colelab.github.io/ActflowToolbox/) to identify network mechanisms underlying neurocognitive processes of interest. For complete details on the use and execution of this protocol, please refer to Cole et al., 2021.},
	language = {en},
	number = {1},
	urldate = {2022-01-28},
	journal = {STAR Protocols},
	author = {Cocuzza, Carrisa V. and Sanchez-Romero, Ruben and Cole, Michael W.},
	month = mar,
	year = {2022},
	keywords = {Cognitive Neuroscience, Neuroscience, Bioinformatics, Computer sciences, Systems biology},
	pages = {101094},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/J5JIMPFA/S2666166721008005.html:text/html},
}

@article{higgins_towards_2018,
	title = {Towards a {Definition} of {Disentangled} {Representations}},
	url = {http://arxiv.org/abs/1812.02230},
	abstract = {How can intelligent agents solve a diverse set of tasks in a data-efficient manner? The disentangled representation learning approach posits that such an agent would benefit from separating out (disentangling) the underlying structure of the world into disjoint parts of its representation. However, there is no generally agreed-upon definition of disentangling, not least because it is unclear how to formalise the notion of world structure beyond toy datasets with a known ground truth generative process. Here we propose that a principled solution to characterising disentangled representations can be found by focusing on the transformation properties of the world. In particular, we suggest that those transformations that change only some properties of the underlying world state, while leaving all other properties invariant, are what gives exploitable structure to any kind of data. Similar ideas have already been successfully applied in physics, where the study of symmetry transformations has revolutionised the understanding of the world structure. By connecting symmetry transformations to vector representations using the formalism of group and representation theory we arrive at the first formal definition of disentangled representations. Our new definition is in agreement with many of the current intuitions about disentangling, while also providing principled resolutions to a number of previous points of contention. While this work focuses on formally defining disentangling - as opposed to solving the learning problem - we believe that the shift in perspective to studying data transformations can stimulate the development of better representation learning algorithms.},
	urldate = {2022-02-02},
	journal = {arXiv:1812.02230 [cs, stat]},
	author = {Higgins, Irina and Amos, David and Pfau, David and Racaniere, Sebastien and Matthey, Loic and Rezende, Danilo and Lerchner, Alexander},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.02230},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/GQVXNDBC/1812.html:text/html;Higgins et al_2018_Towards a Definition of Disentangled Representations.pdf:/Users/tito/Zotero/storage/DPX3GAKM/Higgins et al_2018_Towards a Definition of Disentangled Representations.pdf:application/pdf},
}

@article{roy_thalamic_2022,
	title = {Thalamic subnetworks as units of function},
	copyright = {2022 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-021-00996-1},
	doi = {10.1038/s41593-021-00996-1},
	abstract = {The thalamus engages in various functions including sensory processing, attention, decision making and memory. Classically, this diversity of function has been attributed to the nuclear organization of the thalamus, with each nucleus performing a well-defined function. Here, we highlight recent studies that used state-of-the-art expression profiling, which have revealed gene expression gradients at the single-cell level within and across thalamic nuclei. These gradients, combined with anatomical tracing and physiological analyses, point to previously unappreciated heterogeneity and redefine thalamic units of function on the basis of unique input–output connectivity patterns and gene expression. We propose that thalamic subnetworks, defined by the intersection of genetics, connectivity and computation, provide a more appropriate level of functional description; this notion is supported by behavioral phenotypes resulting from appropriately tailored perturbations. We provide several examples of thalamic subnetworks and suggest how this new perspective may both propel progress in basic neuroscience and reveal unique targets with therapeutic potential.},
	language = {en},
	urldate = {2022-02-02},
	journal = {Nat Neurosci},
	author = {Roy, Dheeraj S. and Zhang, Ying and Halassa, Michael M. and Feng, Guoping},
	month = jan,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Neural circuits, Molecular neuroscience},
	pages = {1--14},
	file = {Roy et al_2022_Thalamic subnetworks as units of function.pdf:/Users/tito/Zotero/storage/GYMJNLXW/Roy et al_2022_Thalamic subnetworks as units of function.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HSLWEUTZ/s41593-021-00996-1.html:text/html},
}

@article{tyulmankov_meta-learning_2022,
	title = {Meta-learning synaptic plasticity and memory addressing for continual familiarity detection},
	volume = {110},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627321009478},
	doi = {10.1016/j.neuron.2021.11.009},
	abstract = {Over the course of a lifetime, we process a continual stream of information. Extracted from this stream, memories must be efficiently encoded and stored in an addressable manner for retrieval. To explore potential mechanisms, we consider a familiarity detection task in which a subject reports whether an image has been previously encountered. We design a feedforward network endowed with synaptic plasticity and an addressing matrix, meta-learned to optimize familiarity detection over long intervals. We find that anti-Hebbian plasticity leads to better performance than Hebbian plasticity and replicates experimental results such as repetition suppression. A combinatorial addressing function emerges, selecting a unique neuron as an index into the synaptic memory matrix for storage or retrieval. Unlike previous models, this network operates continuously and generalizes to intervals it has not been trained on. Our work suggests a biologically plausible mechanism for continual learning and demonstrates an effective application of machine learning for neuroscience discovery.},
	language = {en},
	number = {3},
	urldate = {2022-02-02},
	journal = {Neuron},
	author = {Tyulmankov, Danil and Yang, Guangyu Robert and Abbott, L. F.},
	month = feb,
	year = {2022},
	keywords = {neural networks, memory, deep learning, continual learning, meta-learning, addressing, anti-Hebbian, familiarity, recognition, synaptic plasticity},
	pages = {544--557.e8},
	file = {Tyulmankov et al_2022_Meta-learning synaptic plasticity and memory addressing for continual.pdf:/Users/tito/Zotero/storage/8U4TNWNR/Tyulmankov et al_2022_Meta-learning synaptic plasticity and memory addressing for continual.pdf:application/pdf},
}

@article{ito_constructing_2022,
	title = {Constructing neural network models from brain data reveals representational transformations linked to adaptive behavior},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28323-7},
	doi = {10.1038/s41467-022-28323-7},
	abstract = {The human ability to adaptively implement a wide variety of tasks is thought to emerge from the dynamic transformation of cognitive information. We hypothesized that these transformations are implemented via conjunctive activations in “conjunction hubs”—brain regions that selectively integrate sensory, cognitive, and motor activations. We used recent advances in using functional connectivity to map the flow of activity between brain regions to construct a task-performing neural network model from fMRI data during a cognitive control task. We verified the importance of conjunction hubs in cognitive computations by simulating neural activity flow over this empirically-estimated functional connectivity model. These empirically-specified simulations produced above-chance task performance (motor responses) by integrating sensory and task rule activations in conjunction hubs. These findings reveal the role of conjunction hubs in supporting flexible cognitive computations, while demonstrating the feasibility of using empirically-estimated neural network models to gain insight into cognitive computations in the human brain.},
	language = {en},
	number = {1},
	urldate = {2022-02-03},
	journal = {Nat Commun},
	author = {Ito, Takuya and Yang, Guangyu Robert and Laurent, Patryk and Schultz, Douglas H. and Cole, Michael W.},
	month = feb,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Cognitive control, Network models},
	pages = {673},
	file = {Ito et al_2022_Constructing neural network models from brain data reveals representational.pdf:/Users/tito/Zotero/storage/55X3DY4Q/Ito et al_2022_Constructing neural network models from brain data reveals representational.pdf:application/pdf},
}

@article{mccormick_latent_2022,
	title = {Latent functional connectivity underlying multiple brain states},
	issn = {2472-1751},
	url = {https://doi.org/10.1162/netn_a_00234},
	doi = {10.1162/netn_a_00234},
	abstract = {Functional connectivity (FC) studies have predominantly focused on resting state, where ongoing dynamics are thought to reflect the brain’s intrinsic network architecture; thought to be broadly relevant because it persists across brain states (i.e., state-general). However, it is unknown whether resting state is the optimal state for measuring intrinsic FC. We propose that latent FC, reflecting shared connectivity patterns across many brain states, better captures state-general intrinsic FC relative to measures derived from resting state alone. We estimated latent FC independently for each connection using leave-one-task-out factor analysis in 7 highly distinct task states (24 conditions) and resting state using fMRI data from the Human Connectome Project. Compared to resting-state connectivity, latent FC improves generalization to held-out brain states, better explaining patterns of connectivity and task-evoked activation. We also found that latent connectivity improved prediction of behavior outside the scanner, indexed by the general intelligence factor (g). Our results suggest that FC patterns shared across many brain states, rather than just resting state, better reflects state-general connectivity. This affirms the notion of “intrinsic” brain network architecture as a set of connectivity properties persistent across brain states, providing an updated conceptual and mathematical framework of intrinsic connectivity as a latent factor.},
	urldate = {2022-02-03},
	journal = {Network Neuroscience},
	author = {McCormick, Ethan M. and Arnemann, Katelyn L. and Ito, Takuya and Hanson, Stephen José and Cole, Michael W.},
	month = jan,
	year = {2022},
	pages = {1--42},
	file = {McCormick et al_2022_Latent functional connectivity underlying multiple brain states.pdf:/Users/tito/Zotero/storage/XFJNBCEC/McCormick et al_2022_Latent functional connectivity underlying multiple brain states.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/N3AJCRFL/Latent-functional-connectivity-underlying-multiple.html:text/html},
}

@article{schultz_global_2022,
	title = {Global {Connectivity} {Fingerprints} {Predict} the {Domain} {Generality} of {Multiple}-{Demand} {Regions}},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhab495},
	doi = {10.1093/cercor/bhab495},
	abstract = {A set of distributed cognitive control networks are known to contribute to diverse cognitive demands, yet it is unclear how these networks gain this domain-general capacity. We hypothesized that this capacity is largely due to the particular organization of the human brain’s intrinsic network architecture. Specifically, we tested the possibility that each brain region’s domain generality is reflected in its level of global (hub-like) intrinsic connectivity as well as its particular global connectivity pattern (“connectivity fingerprint”). Consistent with prior work, we found that cognitive control networks exhibited domain generality as they represented diverse task context information covering sensory, motor response, and logic rule domains. Supporting our hypothesis, we found that the level of global intrinsic connectivity (estimated with resting-state functional magnetic resonance imaging [fMRI]) was correlated with domain generality during tasks. Further, using a novel information fingerprint mapping approach, we found that each cognitive control region's unique rule response profile(“information fingerprint”) could be predicted based on its unique intrinsic connectivity fingerprint and the information content in regions outside cognitive control networks. Together, these results suggest that the human brain’s intrinsic network architecture supports its ability to represent diverse cognitive task information largely via the location of multiple-demand regions within the brain’s global network organization.},
	urldate = {2022-02-03},
	journal = {Cerebral Cortex},
	author = {Schultz, Douglas H and Ito, Takuya and Cole, Michael W},
	month = jan,
	year = {2022},
	pages = {bhab495},
	file = {Snapshot:/Users/tito/Zotero/storage/6FKMMQRA/6514504.html:text/html},
}

@article{megemont_pupil_2022,
	title = {Pupil diameter is not an accurate real-time readout of locus coeruleus activity},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.70510},
	doi = {10.7554/eLife.70510},
	abstract = {Pupil diameter is often treated as a noninvasive readout of activity in the locus coeruleus (LC). However, how accurately it can be used to index LC activity is not known. To address this question, we established a graded relationship between pupil size changes and LC spiking activity in mice, where pupil dilation increased monotonically with the number of LC spikes. However, this relationship exists with substantial variability such that pupil diameter can only be used to accurately predict a small fraction of LC activity on a moment-by-moment basis. In addition, pupil exhibited large session-to-session fluctuations in response to identical optical stimulation in the LC. The variations in the pupil–LC relationship were strongly correlated with decision bias-related behavioral variables. Together, our data show that substantial variability exists in an overall graded relationship between pupil diameter and LC activity, and further suggest that the pupil–LC relationship is dynamically modulated by brain states, supporting and extending our previous findings (Yang et al., 2021).},
	urldate = {2022-02-03},
	journal = {eLife},
	author = {Megemont, Marine and McBurney-Lin, Jim and Yang, Hongdian},
	editor = {Reimer, Jacob and Gold, Joshua I},
	month = feb,
	year = {2022},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {brain state, locus coeruleus, pupil diameter},
	pages = {e70510},
	file = {Megemont et al_2022_Pupil diameter is not an accurate real-time readout of locus coeruleus activity.pdf:/Users/tito/Zotero/storage/6GL6LPT5/Megemont et al_2022_Pupil diameter is not an accurate real-time readout of locus coeruleus activity.pdf:application/pdf},
}

@article{ashwood_mice_2022,
	title = {Mice alternate between discrete strategies during perceptual decision-making},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-021-01007-z},
	doi = {10.1038/s41593-021-01007-z},
	abstract = {Classical models of perceptual decision-making assume that subjects use a single, consistent strategy to form decisions, or that decision-making strategies evolve slowly over time. Here we present new analyses suggesting that this common view is incorrect. We analyzed data from mouse and human decision-making experiments and found that choice behavior relies on an interplay among multiple interleaved strategies. These strategies, characterized by states in a hidden Markov model, persist for tens to hundreds of trials before switching, and often switch multiple times within a session. The identified decision-making strategies were highly consistent across mice and comprised a single ‘engaged’ state, in which decisions relied heavily on the sensory stimulus, and several biased states in which errors frequently occurred. These results provide a powerful alternate explanation for ‘lapses’ often observed in rodent behavioral experiments, and suggest that standard measures of performance mask the presence of major changes in strategy across trials.},
	language = {en},
	urldate = {2022-02-07},
	journal = {Nat Neurosci},
	author = {Ashwood, Zoe C. and Roy, Nicholas A. and Stone, Iris R. and Urai, Anne E. and Churchland, Anne K. and Pouget, Alexandre and Pillow, Jonathan W.},
	month = feb,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Decision, Computational neuroscience},
	pages = {1--12},
	file = {Ashwood et al_2022_Mice alternate between discrete strategies during perceptual decision-making.pdf:/Users/tito/Zotero/storage/V5Z952RF/Ashwood et al_2022_Mice alternate between discrete strategies during perceptual decision-making.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/AQ2IUDNJ/s41593-021-01007-z.html:text/html},
}

@article{thiele_multitask_2022,
	title = {Multitask {Brain} {Network} {Reconfiguration} {Is} {Inversely} {Associated} with {Human} {Intelligence}},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhab473},
	doi = {10.1093/cercor/bhab473},
	abstract = {Intelligence describes the general cognitive ability level of a person. It is one of the most fundamental concepts in psychological science and is crucial for the effective adaption of behavior to varying environmental demands. Changing external task demands have been shown to induce reconfiguration of functional brain networks. However, whether neural reconfiguration between different tasks is associated with intelligence has not yet been investigated. We used functional magnetic resonance imaging data from 812 subjects to show that higher scores of general intelligence are related to less brain network reconfiguration between resting state and seven different task states as well as to network reconfiguration between tasks. This association holds for all functional brain networks except the motor system and replicates in two independent samples (n = 138 and n = 184). Our findings suggest that the intrinsic network architecture of individuals with higher intelligence scores is closer to the network architecture as required by various cognitive demands. Multitask brain network reconfiguration may, therefore, represent a neural reflection of the behavioral positive manifold – the essence of the concept of general intelligence. Finally, our results support neural efficiency theories of cognitive ability and reveal insights into human intelligence as an emergent property from a distributed multitask brain network.},
	urldate = {2022-02-07},
	journal = {Cerebral Cortex},
	author = {Thiele, Jonas A and Faskowitz, Joshua and Sporns, Olaf and Hilger, Kirsten},
	month = feb,
	year = {2022},
	pages = {bhab473},
	file = {Snapshot:/Users/tito/Zotero/storage/ZVY6YMPU/6523266.html:text/html;Thiele et al_2022_Multitask Brain Network Reconfiguration Is Inversely Associated with Human.pdf:/Users/tito/Zotero/storage/62XGDYUS/Thiele et al_2022_Multitask Brain Network Reconfiguration Is Inversely Associated with Human.pdf:application/pdf},
}

@techreport{prince_glmsingle_2022,
	title = {{GLMsingle}: a toolbox for improving single-trial {fMRI} response estimates},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {{GLMsingle}},
	url = {https://www.biorxiv.org/content/10.1101/2022.01.31.478431v1},
	abstract = {Advances in modern artificial intelligence (AI) have inspired a paradigm shift in human neuroscience, yielding large-scale functional magnetic resonance imaging (fMRI) datasets that provide high-resolution brain responses to tens of thousands of naturalistic visual stimuli. Because such experiments necessarily involve brief stimulus durations and few repetitions of each stimulus, achieving sufficient signal-to-noise ratio can be a major challenge. We address this challenge by introducing GLMsingle, a scalable, user-friendly toolbox available in MATLAB and Python that enables accurate estimation of single-trial fMRI responses (glmsingle.org). Requiring only fMRI time-series data and a design matrix as inputs, GLMsingle integrates three techniques for improving the accuracy of trial-wise general linear model (GLM) beta estimates. First, for each voxel, a custom hemodynamic response function (HRF) is identified from a library of candidate functions. Second, cross-validation is used to derive a set of noise regressors from voxels unrelated to the experimental paradigm. Third, to improve the stability of beta estimates for closely spaced trials, betas are regularized on a voxel-wise basis using ridge regression. Applying GLMsingle to the Natural Scenes Dataset and BOLD5000, we find that GLMsingle substantially improves the reliability of beta estimates across visually-responsive cortex in all subjects. Furthermore, these improvements translate into tangible benefits for higher-level analyses relevant to systems and cognitive neuroscience. Specifically, we demonstrate that GLMsingle: (i) improves the decorrelation of response estimates between trials that are nearby in time; (ii) enhances representational similarity between subjects both within and across datasets; and (iii) boosts one-versus-many decoding of visual stimuli. GLMsingle is a publicly available tool that can significantly improve the quality of past, present, and future neuroimaging datasets that sample brain activity across many experimental conditions.},
	language = {en},
	urldate = {2022-02-09},
	institution = {bioRxiv},
	author = {Prince, Jacob S. and Charest, Ian and Kurzawski, Jan W. and Pyles, John A. and Tarr, Michael J. and Kay, Kendrick N.},
	month = feb,
	year = {2022},
	doi = {10.1101/2022.01.31.478431},
	note = {Section: New Results
Type: article},
	pages = {2022.01.31.478431},
	file = {Prince et al_2022_GLMsingle.pdf:/Users/tito/Zotero/storage/LV42YSJZ/Prince et al_2022_GLMsingle.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/J87DFYSE/2022.01.31.html:text/html},
}

@article{waskom_distributed_2017,
	title = {Distributed representation of context by intrinsic subnetworks in prefrontal cortex},
	volume = {114},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/114/8/2030},
	doi = {10.1073/pnas.1615269114},
	abstract = {Human prefrontal cortex supports goal-directed behavior by representing abstract information about task context. The organizational basis of these context representations, and of representations underlying other higher-order processes, is unknown. Here, we use multivariate decoding and analyses of spontaneous correlations to show that context representations are distributed across subnetworks within prefrontal cortex. Examining targeted prefrontal regions, we found that pairs of voxels with similar context preferences exhibited spontaneous correlations that were approximately twice as large as those between pairs with opposite context preferences. This subnetwork organization was stable across task-engaged and resting states, suggesting that abstract context representations are constrained by an intrinsic functional architecture. These results reveal a principle of fine-scaled functional organization in association cortex.},
	language = {en},
	number = {8},
	urldate = {2022-02-09},
	journal = {PNAS},
	author = {Waskom, Michael L. and Wagner, Anthony D.},
	month = feb,
	year = {2017},
	pmid = {28174269},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {fMRI, cognitive control, resting-state, functional organization, rule},
	pages = {2030--2035},
	file = {Snapshot:/Users/tito/Zotero/storage/DW8WJES3/2030.html:text/html;Waskom_Wagner_2017_Distributed representation of context by intrinsic subnetworks in prefrontal.pdf:/Users/tito/Zotero/storage/HG4XDARR/Waskom_Wagner_2017_Distributed representation of context by intrinsic subnetworks in prefrontal.pdf:application/pdf},
}

@article{waterhouse_locus_2019,
	series = {Behavioral {Consequences} of {Noradrenergic} {Actions} in {Sensory} {Networks}},
	title = {The locus coeruleus-norepinephrine system and sensory signal processing: {A} historical review and current perspectives},
	volume = {1709},
	issn = {0006-8993},
	shorttitle = {The locus coeruleus-norepinephrine system and sensory signal processing},
	url = {https://www.sciencedirect.com/science/article/pii/S0006899318304542},
	doi = {10.1016/j.brainres.2018.08.032},
	abstract = {Many studies in intact animals have shown that locally applied or synaptically released norepinephrine (NE) can enhance individual neuron and neural network responses to sensory inputs. However, a major unanswered question is how and when noradrenergically-mediated changes in sensory signal processing can influence downstream decision making, motor responding, and ultimately behavioral outcomes. Recent work using a variety of approaches in different sensory networks has started to consider this question. Evidence collected to date as reported in this Special Edition of Brain Research suggests that output from the brainstem locus coeruleus (LC)-NE system can modify task-related sensory signal processing and by so doing influence goal-directed behavioral responding. This report reviews the work leading to this most recent line of inquiry and at the same time identifies areas for future investigation.},
	language = {en},
	urldate = {2022-02-09},
	journal = {Brain Research},
	author = {Waterhouse, Barry D. and Navarra, Rachel L.},
	month = apr,
	year = {2019},
	keywords = {Norepinephrine, Locus coeruleus, Sensory processing, Behavioral outcomes},
	pages = {1--15},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/9E2TERYF/S0006899318304542.html:text/html;Waterhouse_Navarra_2019_The locus coeruleus-norepinephrine system and sensory signal processing.pdf:/Users/tito/Zotero/storage/62WYEDKT/Waterhouse_Navarra_2019_The locus coeruleus-norepinephrine system and sensory signal processing.pdf:application/pdf},
}

@techreport{molano-mazon_neurogym_2022,
	title = {{NeuroGym}: {An} open resource for developing and sharing neuroscience tasks},
	shorttitle = {{NeuroGym}},
	url = {https://psyarxiv.com/aqc9n/},
	abstract = {Artificial Neural Networks (ANNs) trained on specific cognitive tasks have re-emerged as a useful tool to study the brain. However, ANNs would better aid cognitive neuroscience if a given network could be easily trained on a wide range of tasks for which neural recordings are available. Moreover, unintentional divergent implementations of cognitive tasks can produce variable results, which limits their interpretability. Towards this goal, we present NeuroGym, an open-source Python package that provides a large collection of customizable neuroscience tasks to test and compare network models. Building upon the OpenAI Gym toolbox, NeuroGym tasks (1) are written in a high-level flexible Python framework; (2) possess a shared interface tailored to common needs of neuroscience tasks that facilitates their design and usage; (3) support the training of ANNs using both Reinforcement and Supervised Learning techniques. The toolbox allows easy assembly of new tasks by modifying existing ones in a hierarchical and modular fashion. These design features make it straightforward to take a network designed for one task and train it on many other tasks. NeuroGym is a community-driven effort that contributes to a rapidly evolving open ecosystem of neural network development, data analysis, and model-data comparison.},
	language = {en-us},
	urldate = {2022-02-10},
	institution = {PsyArXiv},
	author = {Molano-Mazón, Manuel and Barbosa, Joao and Pastor-Ciurana, Jordi and Fradera, Marta and Zhang, Ru-Yuan and Forest, Jeremy and Lerida, Jorge del Pozo and Ji-An, Li and Cueva, Christopher J. and Rocha, Jaime de la and Narain, Devika and Yang, Guangyu Robert},
	month = feb,
	year = {2022},
	doi = {10.31234/osf.io/aqc9n},
	note = {type: article},
	keywords = {cognition, reinforcement learning, cognitive neuroscience, Cognitive Neuroscience, artificial neural networks, Neuroscience, Computational Neuroscience, neuroscience tasks, open-source Python package, supervised learning, Systems Neuroscience, toolbox, training},
	file = {Molano-Mazón et al_2022_NeuroGym.pdf:/Users/tito/Zotero/storage/CYGX6ELS/Molano-Mazón et al_2022_NeuroGym.pdf:application/pdf},
}

@inproceedings{ito_role_2021,
	title = {The role of compositional abstraction in human and artificial neural networks},
	url = {https://ito-takuya.github.io/files/abstracts/2021Cosyne_ItoKlinger.png},
	booktitle = {Computational and {Systems} {Neuroscience} ({Cosyne})},
	author = {Ito, Takuya and Klinger, Tim and Schultz, Douglas H and Cole, Michael W and Rigotti, Mattia},
	year = {2021},
}

@article{leong_dynamic_2017,
	title = {Dynamic {Interaction} between {Reinforcement} {Learning} and {Attention} in {Multidimensional} {Environments}},
	volume = {93},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31039-X},
	doi = {10.1016/j.neuron.2016.12.040},
	language = {English},
	number = {2},
	urldate = {2022-02-15},
	journal = {Neuron},
	author = {Leong, Yuan Chang and Radulescu, Angela and Daniel, Reka and DeWoskin, Vivian and Niv, Yael},
	month = jan,
	year = {2017},
	pmid = {28103483},
	note = {Publisher: Elsevier},
	keywords = {fMRI, decision making, computational modeling, reinforcement learning, prediction error, striatum, attention, MVPA, value, vmPFC},
	pages = {451--463},
	file = {Leong et al_2017_Dynamic Interaction between Reinforcement Learning and Attention in.pdf:/Users/tito/Zotero/storage/JDRQK9FD/Leong et al_2017_Dynamic Interaction between Reinforcement Learning and Attention in.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/NXLK6CZK/S0896-6273(16)31039-X.html:text/html},
}

@article{jia_multi-regional_2022,
	title = {Multi-regional module-based signal transmission in mouse visual cortex},
	volume = {0},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(22)00084-8},
	doi = {10.1016/j.neuron.2022.01.027},
	language = {English},
	number = {0},
	urldate = {2022-02-16},
	journal = {Neuron},
	author = {Jia, Xiaoxuan and Siegle, Joshua H. and Durand, Séverine and Heller, Greggory and Ramirez, Tamina K. and Koch, Christof and Olsen, Shawn R.},
	month = feb,
	year = {2022},
	pmid = {35143752},
	note = {Publisher: Elsevier},
	keywords = {mouse, visual cortex, feedforward, functional network, modular, Neuropixels, processing stages, recurrent},
	file = {Jia et al_2022_Multi-regional module-based signal transmission in mouse visual cortex.pdf:/Users/tito/Zotero/storage/E2CW7NJK/Jia et al_2022_Multi-regional module-based signal transmission in mouse visual cortex.pdf:application/pdf},
}

@article{northoff_shorter_2022,
	title = {From {Shorter} to {Longer} {Timescales}: {Converging} {Integrated} {Information} {Theory} ({IIT}) with the {Temporo}-{Spatial} {Theory} of {Consciousness} ({TTC})},
	volume = {24},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1099-4300},
	shorttitle = {From {Shorter} to {Longer} {Timescales}},
	url = {https://www.mdpi.com/1099-4300/24/2/270},
	doi = {10.3390/e24020270},
	abstract = {Time is a key element of consciousness as it includes multiple timescales from shorter to longer ones. This is reflected in our experience of various short-term phenomenal contents at discrete points in time as part of an ongoing, more continuous, and long-term ‘stream of consciousness’. Can Integrated Information Theory (IIT) account for this multitude of timescales of consciousness? According to the theory, the relevant spatiotemporal scale for consciousness is the one in which the system reaches the maximum cause-effect power; IIT currently predicts that experience occurs on the order of short timescales, namely, between 100 and 300 ms (theta and alpha frequency range). This can well account for the integration of single inputs into a particular phenomenal content. However, such short timescales leave open the temporal relation of specific phenomenal contents to others during the course of the ongoing time, that is, the stream of consciousness. For that purpose, we converge the IIT with the Temporo-spatial Theory of Consciousness (TTC), which, assuming a multitude of different timescales, can take into view the temporal integration of specific phenomenal contents with other phenomenal contents over time. On the neuronal side, this is detailed by considering those neuronal mechanisms driving the non-additive interaction of pre-stimulus activity with the input resulting in stimulus-related activity. Due to their non-additive interaction, the single input is not only integrated with others in the short-term timescales of 100–300 ms (alpha and theta frequencies) (as predicted by IIT) but, at the same time, also virtually expanded in its temporal (and spatial) features; this is related to the longer timescales (delta and slower frequencies) that are carried over from pre-stimulus to stimulus-related activity. Such a non-additive pre-stimulus-input interaction amounts to temporo-spatial expansion as a key mechanism of TTC for the constitution of phenomenal contents including their embedding or nesting within the ongoing temporal dynamic, i.e., the stream of consciousness. In conclusion, we propose converging the short-term integration of inputs postulated in IIT (100–300 ms as in the alpha and theta frequency range) with the longer timescales (in delta and slower frequencies) of temporo-spatial expansion in TTC.},
	language = {en},
	number = {2},
	urldate = {2022-02-17},
	journal = {Entropy},
	author = {Northoff, Georg and Zilio, Federico},
	month = feb,
	year = {2022},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {resting state, temporal integration, contents of consciousness, integrated information theory, phenomenal content, pre-stimulus activity, stream of consciousness, task-related activity, temporo-spatial theory of consciousness},
	pages = {270},
	file = {Northoff_Zilio_2022_From Shorter to Longer Timescales.pdf:/Users/tito/Zotero/storage/UPBE8C6Q/Northoff_Zilio_2022_From Shorter to Longer Timescales.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/IC2MDNVX/270.html:text/html},
}

@article{arnatkeviciute_practical_2019,
	title = {A practical guide to linking brain-wide gene expression and neuroimaging data},
	volume = {189},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811919300114},
	doi = {10.1016/j.neuroimage.2019.01.011},
	abstract = {The recent availability of comprehensive, brain-wide gene expression atlases such as the Allen Human Brain Atlas (AHBA) has opened new opportunities for understanding how spatial variations on molecular scale relate to the macroscopic neuroimaging phenotypes. A rapidly growing body of literature is demonstrating relationships between gene expression and diverse properties of brain structure and function, but approaches for combining expression atlas data with neuroimaging are highly inconsistent, with substantial variations in how the expression data are processed. The degree to which these methodological variations affect findings is unclear. Here, we outline a seven-step analysis pipeline for relating brain-wide transcriptomic and neuroimaging data and compare how different processing choices influence the resulting data. We suggest that studies using the AHBA should work towards a unified data processing pipeline to ensure consistent and reproducible results in this burgeoning field.},
	language = {en},
	urldate = {2022-02-17},
	journal = {NeuroImage},
	author = {Arnatkevic̆iūtė, Aurina and Fulcher, Ben D. and Fornito, Alex},
	month = apr,
	year = {2019},
	keywords = {MRI, Connectome, Genetics, Allen human brain atlas, Gene expression, Genome, Transcriptome},
	pages = {353--367},
	file = {Arnatkevic̆iūtė et al_2019_A practical guide to linking brain-wide gene expression and neuroimaging data.pdf:/Users/tito/Zotero/storage/63JI7D2A/Arnatkevic̆iūtė et al_2019_A practical guide to linking brain-wide gene expression and neuroimaging data.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/VP475RD2/S1053811919300114.html:text/html},
}

@article{yan_episodic_2022,
	title = {Episodic {Memory} in {Aspects} of {Brain} {Information} {Transfer} by {Resting}-{State} {Network} {Topology}},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhab526},
	doi = {10.1093/cercor/bhab526},
	abstract = {Cognitive functionality emerges due to neural interactions. The interregional signal interactions underlying episodic memory are a complex process. Thus, we need to quantify this process more accurately to understand how brain regions receive information from other regions. Studies suggest that resting-state functional connectivity (FC) conveys cognitive information; additionally, activity flow estimates the contribution of the source region to the activation pattern of the target region, thus decoding the cognitive information transfer. Therefore, we performed a combined analysis of task-evoked activation and resting-state FC voxel-wise by activity flow mapping to estimate the information transfer pattern of episodic memory. We found that the cinguloopercular (CON), frontoparietal (FPN) and default mode networks (DMNs) were the most recruited structures in information transfer. The patterns and functions of information transfer differed between encoding and retrieval. Furthermore, we found that information transfer was a better predictor of memory ability than previous methods. Additional analysis indicated that structural connectivity (SC) had a transportive role in information transfer. Finally, we present the information transfer mechanism of episodic memory from multiple neural perspectives. These findings suggest that information transfer is a better biological indicator that accurately describes signal communication in the brain and strongly influences the function of episodic memory.},
	urldate = {2022-02-21},
	journal = {Cerebral Cortex},
	author = {Yan, Tianyi and Wang, Gongshu and Wang, Li and Liu, Tiantian and Li, Ting and Wang, Luyao and Chen, Duanduan and Funahashi, Shintaro and Wu, Jinglong and Wang, Bin and Suo, Dingjie},
	month = feb,
	year = {2022},
	pages = {bhab526},
	file = {Full Text PDF:/Users/tito/Zotero/storage/Y3U3KACR/Yan et al. - 2022 - Episodic Memory in Aspects of Brain Information Tr.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WUAT7UN3/6529888.html:text/html},
}

@techreport{poskanzer_computational_2021,
	title = {Computational {Fingerprints}: {Modeling} {Interactions} {Between} {Brain} {Regions} as {Points} in a {Function} {Space}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Computational {Fingerprints}},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.28.462195v1},
	abstract = {In this paper we propose a novel technique to investigate the nonlinear interactions between brain regions that captures both the strength and the type of the functional relationship. Inspired by the field of functional analysis, we propose that the relationship between activity in two different brain areas can be viewed as a point in function space, identified by coordinates along an infinite set of basis functions. Using Hermite Polynomials as basis functions, we estimate from fMRI data a truncated set of coordinates that serve as a “computational fingerprint,” characterizing the interaction between two brain areas. We provide a proof of the convergence of the estimates in the limit, and we validate the method with simulations in which the ground truth is known, additionally showing that computational fingerprints detect statistical dependence also when correlations (“functional connectivity”) is near zero. We then use computational fingerprints to examine the neural interactions with a seed region of choice: the Fusiform Face Area (FFA). Using k-means clustering across each voxel’s computational fingerprint, we illustrate that the addition of the nonlinear basis functions allows for the discrimination of inter-regional interactions that are otherwise grouped together when only linear dependence is used. Finally, we show that regions in V5 and medial occipital and temporal lobes exhibit significant nonlinear interactions with the FFA.},
	language = {en},
	urldate = {2022-02-22},
	institution = {bioRxiv},
	author = {Poskanzer, Craig and Anzellotti, Stefano},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.09.28.462195},
	note = {Section: New Results
Type: article},
	pages = {2021.09.28.462195},
	file = {Full Text PDF:/Users/tito/Zotero/storage/29IKDW4X/Poskanzer and Anzellotti - 2021 - Computational Fingerprints Modeling Interactions .pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/U8CQ78CJ/2021.09.28.html:text/html},
}

@article{rezaei_zero-shot_2020,
	title = {Zero-shot learning and its applications from autonomous vehicles to {COVID}-19 diagnosis: {A} review},
	volume = {3-4},
	issn = {2666-5212},
	shorttitle = {Zero-shot learning and its applications from autonomous vehicles to {COVID}-19 diagnosis},
	url = {https://www.sciencedirect.com/science/article/pii/S2666521220300053},
	doi = {10.1016/j.ibmed.2020.100005},
	abstract = {The challenge of learning a new concept, object, or a new medical disease recognition without receiving any examples beforehand is called Zero-Shot Learning (ZSL). One of the major issues in deep learning based methodologies such as in Medical Imaging and other real-world applications is the requirement of large annotated datasets prepared by clinicians or experts to train the model. ZSL is known for having minimal human intervention by relying only on previously known or trained concepts plus currently existing auxiliary information. This is ever-growing research for the cases where we have very limited or no annotated datasets available and the detection / recognition system has human-like characteristics in learning new concepts. This makes the ZSL applicable in many real-world scenarios, from unknown object detection in autonomous vehicles to medical imaging and unforeseen diseases such as COVID-19 Chest X-Ray (CXR) based diagnosis. In this review paper, we introduce a novel and broaden solution called Few / one-shot learning, and present the definition of the ZSL problem as an extreme case of the few-shot learning. We review over fundamentals and the challenging steps of Zero-Shot Learning, including state-of-the-art categories of solutions, as well as our recommended solution, motivations behind each approach, their advantages over each category to guide both clinicians and AI researchers to proceed with the best techniques and practices based on their applications. Inspired from different settings and extensions, we then review through different datasets inducing medical and non-medical images, the variety of splits, and the evaluation protocols proposed so far. Finally, we discuss the recent applications and future directions of ZSL. We aim to convey a useful intuition through this paper towards the goal of handling complex learning tasks more similar to the way humans learn. We mainly focus on two applications in the current modern yet challenging era: coping with an early and fast diagnosis of COVID-19 cases, and also encouraging the readers to develop other similar AI-based automated detection / recognition systems using ZSL.},
	language = {en},
	urldate = {2022-02-22},
	journal = {Intelligence-Based Medicine},
	author = {Rezaei, Mahdi and Shahidi, Mahsa},
	month = dec,
	year = {2020},
	keywords = {Machine learning, Deep learning, Autonomous vehicles, Chest X-Ray (CXR), COVID-19 pandemic, SARS-CoV-2, Semantic embedding, Supervised annotation, Zero-shot learning},
	pages = {100005},
	file = {Rezaei_Shahidi_2020_Zero-shot learning and its applications from autonomous vehicles to COVID-19.pdf:/Users/tito/Zotero/storage/DGCHKMZ9/Rezaei_Shahidi_2020_Zero-shot learning and its applications from autonomous vehicles to COVID-19.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/QGJ9FRWE/S2666521220300053.html:text/html},
}

@techreport{cocuzza_distributed_2022,
	title = {Distributed network processes account for the majority of variance in localized visual category selectivity},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.02.19.481103v1},
	abstract = {In seeking to understand processes fundamental to brain function, the debate between localized versus distributed processing has persisted for over a century. High category selectivity of some visual regions has provided evidence for localized (within-region) processing. However, given recent evidence that distributed connectivity patterns are predictive of localized task-evoked activations, we hypothesized that even highly localized category-selective brain activations are primarily determined by the connectivity-specified convergence of distributed brain processes. Consistent with this, we utilized fMRI data from N=352 human participants to find that distributed activity flow processes (specified by each region's unique "connectivity fingerprint") locally converge on visual cortex regions to confer the majority contribution to visual category selective responses to bodies, faces, places, and tools. This highlights a prominent role for functional network organization in the generation of localized visual category selectivity and provides evidence for a distributed convergence account of localized functionality in the human brain.},
	language = {en},
	urldate = {2022-02-22},
	institution = {bioRxiv},
	author = {Cocuzza, Carrisa V. and Sanchez-Romero, Ruben and Ito, Takuya and Mill, Ravi D. and Keane, Brian P. and Cole, Michael W.},
	month = feb,
	year = {2022},
	doi = {10.1101/2022.02.19.481103},
	note = {Section: New Results
Type: article},
	pages = {2022.02.19.481103},
	file = {Cocuzza et al_2022_Distributed network processes account for the majority of variance in localized.pdf:/Users/tito/Zotero/storage/IHI6GWFT/Cocuzza et al_2022_Distributed network processes account for the majority of variance in localized.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/WTWCP9ZI/2022.02.19.html:text/html},
}

@article{wang_prefrontal_2018,
	title = {Prefrontal cortex as a meta-reinforcement learning system},
	volume = {21},
	copyright = {2018 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-018-0147-8},
	doi = {10.1038/s41593-018-0147-8},
	abstract = {Over the past 20 years, neuroscience research on reward-based learning has converged on a canonical model, under which the neurotransmitter dopamine ‘stamps in’ associations between situations, actions and rewards by modulating the strength of synaptic connections between neurons. However, a growing number of recent findings have placed this standard model under strain. We now draw on recent advances in artificial intelligence to introduce a new theory of reward-based learning. Here, the dopamine system trains another part of the brain, the prefrontal cortex, to operate as its own free-standing learning system. This new perspective accommodates the findings that motivated the standard model, but also deals gracefully with a wider range of observations, providing a fresh foundation for future research.},
	language = {en},
	number = {6},
	urldate = {2022-02-22},
	journal = {Nat Neurosci},
	author = {Wang, Jane X. and Kurth-Nelson, Zeb and Kumaran, Dharshan and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Hassabis, Demis and Botvinick, Matthew},
	month = jun,
	year = {2018},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Cognitive control, Learning algorithms},
	pages = {860--868},
	file = {Snapshot:/Users/tito/Zotero/storage/93PB4G85/s41593-018-0147-8.html:text/html;Wang et al_2018_Prefrontal cortex as a meta-reinforcement learning system.pdf:/Users/tito/Zotero/storage/W2KZ5CVF/Wang et al_2018_Prefrontal cortex as a meta-reinforcement learning system.pdf:application/pdf},
}

@article{dadi_population_2021,
	title = {Population modeling with machine learning can enhance measures of mental health},
	volume = {10},
	issn = {2047-217X},
	url = {https://doi.org/10.1093/gigascience/giab071},
	doi = {10.1093/gigascience/giab071},
	abstract = {Biological aging is revealed by physical measures, e.g., DNA probes or brain scans. In contrast, individual differences in mental function are explained by psychological constructs, e.g., intelligence or neuroticism. These constructs are typically assessed by tailored neuropsychological tests that build on expert judgement and require careful interpretation. Could machine learning on large samples from the general population be used to build proxy measures of these constructs that do not require human intervention?Here, we built proxy measures by applying machine learning on multimodal MR images and rich sociodemographic information from the largest biomedical cohort to date: the UK Biobank. Objective model comparisons revealed that all proxies captured the target constructs and were as useful, and sometimes more useful, than the original measures for characterizing real-world health behavior (sleep, exercise, tobacco, alcohol consumption). We observed this complementarity of proxy measures and original measures at capturing multiple health-related constructs when modeling from, both, brain signals and sociodemographic data.Population modeling with machine learning can derive measures of mental health from heterogeneous inputs including brain signals and questionnaire data. This may complement or even substitute for psychometric assessments in clinical populations.},
	number = {10},
	urldate = {2022-02-23},
	journal = {GigaScience},
	author = {Dadi, Kamalaker and Varoquaux, Gaël and Houenou, Josselin and Bzdok, Danilo and Thirion, Bertrand and Engemann, Denis},
	month = oct,
	year = {2021},
	pages = {giab071},
	file = {Dadi et al_2021_Population modeling with machine learning can enhance measures of mental health.pdf:/Users/tito/Zotero/storage/QQGJ468K/Dadi et al_2021_Population modeling with machine learning can enhance measures of mental health.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/P2FWLMHK/6396189.html:text/html},
}

@inproceedings{kolesnikov_revisiting_2019,
	title = {Revisiting {Self}-{Supervised} {Visual} {Representation} {Learning}},
	url = {https://openaccess.thecvf.com/content_CVPR_2019/html/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.html},
	urldate = {2022-02-24},
	author = {Kolesnikov, Alexander and Zhai, Xiaohua and Beyer, Lucas},
	year = {2019},
	pages = {1920--1929},
	file = {Kolesnikov et al_2019_Revisiting Self-Supervised Visual Representation Learning.pdf:/Users/tito/Zotero/storage/64ULW66E/Kolesnikov et al_2019_Revisiting Self-Supervised Visual Representation Learning.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/D4MP4ZVQ/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.html:text/html},
}

@article{rocchi_increased_2022,
	title = {Increased {fMRI} connectivity upon chemogenetic inhibition of the mouse prefrontal cortex},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28591-3},
	doi = {10.1038/s41467-022-28591-3},
	abstract = {While shaped and constrained by axonal connections, fMRI-based functional connectivity reorganizes in response to varying interareal input or pathological perturbations. However, the causal contribution of regional brain activity to whole-brain fMRI network organization remains unclear. Here we combine neural manipulations, resting-state fMRI and in vivo electrophysiology to probe how inactivation of a cortical node causally affects brain-wide fMRI coupling in the mouse. We find that chronic inhibition of the medial prefrontal cortex (PFC) via overexpression of a potassium channel increases fMRI connectivity between the inhibited area and its direct thalamo-cortical targets. Acute chemogenetic inhibition of the PFC produces analogous patterns of fMRI overconnectivity. Using in vivo electrophysiology, we find that chemogenetic inhibition of the PFC enhances low frequency (0.1–4 Hz) oscillatory power via suppression of neural firing not phase-locked to slow rhythms, resulting in increased slow and δ band coherence between areas that exhibit fMRI overconnectivity. These results provide causal evidence that cortical inactivation can counterintuitively increase fMRI connectivity via enhanced, less-localized slow oscillatory processes.},
	language = {en},
	number = {1},
	urldate = {2022-02-25},
	journal = {Nat Commun},
	author = {Rocchi, Federico and Canella, Carola and Noei, Shahryar and Gutierrez-Barragan, Daniel and Coletta, Ludovico and Galbusera, Alberto and Stuefer, Alexia and Vassanelli, Stefano and Pasqualetti, Massimo and Iurilli, Giuliano and Panzeri, Stefano and Gozzi, Alessandro},
	month = feb,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Functional magnetic resonance imaging, Neural circuits},
	pages = {1056},
	file = {Rocchi et al_2022_Increased fMRI connectivity upon chemogenetic inhibition of the mouse.pdf:/Users/tito/Zotero/storage/EKZVUJEW/Rocchi et al_2022_Increased fMRI connectivity upon chemogenetic inhibition of the mouse.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/EW9SAYYE/s41467-022-28591-3.html:text/html},
}

@article{bakarji_discovering_2022,
	title = {Discovering {Governing} {Equations} from {Partial} {Measurements} with {Deep} {Delay} {Autoencoders}},
	url = {http://arxiv.org/abs/2201.05136},
	abstract = {A central challenge in data-driven model discovery is the presence of hidden, or latent, variables that are not directly measured but are dynamically important. Takens' theorem provides conditions for when it is possible to augment these partial measurements with time delayed information, resulting in an attractor that is diffeomorphic to that of the original full-state system. However, the coordinate transformation back to the original attractor is typically unknown, and learning the dynamics in the embedding space has remained an open challenge for decades. Here, we design a custom deep autoencoder network to learn a coordinate transformation from the delay embedded space into a new space where it is possible to represent the dynamics in a sparse, closed form. We demonstrate this approach on the Lorenz, R{\textbackslash}"ossler, and Lotka-Volterra systems, learning dynamics from a single measurement variable. As a challenging example, we learn a Lorenz analogue from a single scalar variable extracted from a video of a chaotic waterwheel experiment. The resulting modeling framework combines deep learning to uncover effective coordinates and the sparse identification of nonlinear dynamics (SINDy) for interpretable modeling. Thus, we show that it is possible to simultaneously learn a closed-form model and the associated coordinate system for partially observed dynamics.},
	urldate = {2022-03-01},
	journal = {arXiv:2201.05136 [cs, math]},
	author = {Bakarji, Joseph and Champion, Kathleen and Kutz, J. Nathan and Brunton, Steven L.},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.05136},
	keywords = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Computer Science - Computational Engineering, Finance, and Science},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/UCHPLY4R/2201.html:text/html;Bakarji et al_2022_Discovering Governing Equations from Partial Measurements with Deep Delay.pdf:/Users/tito/Zotero/storage/GKKNYFSL/Bakarji et al_2022_Discovering Governing Equations from Partial Measurements with Deep Delay.pdf:application/pdf},
}

@techreport{riveland_neural_2022,
	title = {A neural model of task compositionality with natural language instructions},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.02.22.481293v1},
	abstract = {We present neural models of one of humans’ most astonishing cognitive feats: the ability to interpret linguistic instructions in order to perform novel tasks with just a few practice trials. Models are trained on a set of commonly studied psychophysical tasks, and receive linguistic instructions embedded by transformer architectures pre-trained on natural language processing. Our best performing models can perform an unknown task with a performance of 80\% correct on average based solely on linguistic instructions (i.e. 0-shot learning), and 90\% after 3 learning updates. We found that the resulting neural representations capture the semantic structure of interrelated tasks even for novel tasks, allowing for the composition of practiced skills in unseen settings. Finally, we also demonstrate how this model can generate a linguistic description of a task it has identified using motor feedback, which, when communicated to another network, leads to near perfect performance (95\%). To our knowledge, this is the first experimentally testable model of how language can structure sensorimotor representations to allow for task compositionality.},
	language = {en},
	urldate = {2022-03-03},
	institution = {bioRxiv},
	author = {Riveland, Reidar and Pouget, Alexandre},
	month = feb,
	year = {2022},
	doi = {10.1101/2022.02.22.481293},
	note = {Section: New Results
Type: article},
	pages = {2022.02.22.481293},
	file = {Riveland_Pouget_2022_A neural model of task compositionality with natural language instructions.pdf:/Users/tito/Zotero/storage/K9CFRDRZ/Riveland_Pouget_2022_A neural model of task compositionality with natural language instructions.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/TZ36VMIU/2022.02.22.html:text/html},
}

@article{douaud_sars-cov-2_2022,
	title = {{SARS}-{CoV}-2 is associated with changes in brain structure in {UK} {Biobank}},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-04569-5},
	doi = {10.1038/s41586-022-04569-5},
	abstract = {There is strong evidence for brain-related abnormalities in COVID-191–13. It remains unknown however whether the impact of SARS-CoV-2 infection can be detected in milder cases, and whether this can reveal possible mechanisms contributing to brain pathology. Here, we investigated brain changes in 785 UK Biobank participants (aged 51–81) imaged twice, including 401 cases who tested positive for infection with SARS-CoV-2 between their two scans, with 141 days on average separating their diagnosis and second scan, and 384 controls. The availability of pre-infection imaging data reduces the likelihood of pre-existing risk factors being misinterpreted as disease effects. We identified significant longitudinal effects when comparing the two groups, including: (i) greater reduction in grey matter thickness and tissue-contrast in the orbitofrontal cortex and parahippocampal gyrus, (ii) greater changes in markers of tissue damage in regions functionally-connected to the primary olfactory cortex, and (iii) greater reduction in global brain size. The infected participants also showed on average larger cognitive decline between the two timepoints. Importantly, these imaging and cognitive longitudinal effects were still seen after excluding the 15 cases who had been hospitalised. These mainly limbic brain imaging results may be the in vivo hallmarks of a degenerative spread of the disease via olfactory pathways, of neuroinflammatory events, or of the loss of sensory input due to anosmia. Whether this deleterious impact can be partially reversed, or whether these effects will persist in the long term, remains to be investigated with additional follow up.},
	language = {en},
	urldate = {2022-03-07},
	journal = {Nature},
	author = {Douaud, Gwenaëlle and Lee, Soojin and Alfaro-Almagro, Fidel and Arthofer, Christoph and Wang, Chaoyue and McCarthy, Paul and Lange, Frederik and Andersson, Jesper L. R. and Griffanti, Ludovica and Duff, Eugene and Jbabdi, Saad and Taschler, Bernd and Keating, Peter and Winkler, Anderson M. and Collins, Rory and Matthews, Paul M. and Allen, Naomi and Miller, Karla L. and Nichols, Thomas E. and Smith, Stephen M.},
	month = mar,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Encephalopathy, Olfactory cortex},
	pages = {1--17},
}

@article{peixoto_decoding_2021,
	title = {Decoding and perturbing decision states in real time},
	volume = {591},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-03181-9},
	doi = {10.1038/s41586-020-03181-9},
	abstract = {In dynamic environments, subjects often integrate multiple samples of a signal and combine them to reach a categorical judgment1. The process of deliberation can be described by a time-varying decision variable (DV), decoded from neural population activity, that predicts a subject’s upcoming decision2. Within single trials, however, there are large moment-to-moment fluctuations in the DV, the behavioural significance of which is unclear. Here, using real-time, neural feedback control of stimulus duration, we show that within-trial DV fluctuations, decoded from motor cortex, are tightly linked to decision state in macaques, predicting behavioural choices substantially better than the condition-averaged DV or the visual stimulus alone. Furthermore, robust changes in DV sign have the statistical regularities expected from behavioural studies of changes of mind3. Probing the decision process on single trials with weak stimulus pulses, we find evidence for time-varying absorbing decision bounds, enabling us to distinguish between specific models of decision making.},
	language = {en},
	number = {7851},
	urldate = {2022-03-10},
	journal = {Nature},
	author = {Peixoto, Diogo and Verhein, Jessica R. and Kiani, Roozbeh and Kao, Jonathan C. and Nuyujukian, Paul and Chandrasekaran, Chandramouli and Brown, Julian and Fong, Sania and Ryu, Stephen I. and Shenoy, Krishna V. and Newsome, William T.},
	month = mar,
	year = {2021},
	note = {Number: 7851
Publisher: Nature Publishing Group},
	keywords = {Decision, Brain–machine interface, Neural decoding, Premotor cortex},
	pages = {604--609},
	file = {Peixoto et al_2021_Decoding and perturbing decision states in real time.pdf:/Users/tito/Zotero/storage/BQG6KF53/Peixoto et al_2021_Decoding and perturbing decision states in real time.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/8IDZXQ9P/s41586-020-03181-9.html:text/html},
}

@techreport{brink_large-scale_2022,
	title = {Large-{Scale} {Circuit} {Configuration} for {Flexible} {Sensory}-{Motor} {Decisions}},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.03.10.483758v1},
	abstract = {Humans and non-human primates can acquire, and rapidly switch between, arbitrary rules that govern the mapping from sensation to action. It has remained unknown if and how the brain configures large-scale sensory-motor circuits to establish such flexible information flow. Here, we developed an approach that elucidates the dynamic configuration of task-specific sensory-motor circuits in humans. Participants switched between arbitrary mapping rules for reporting visual orientation judgments during fMRI. Rule switches were either signaled explicitly or inferred by the participants from ambiguous cues, and we used behavioral modeling to reconstruct the time course of their belief about the active rule. In both contexts, patterns of correlations between ongoing fluctuations in feature-specific activity across visual and action-related brain regions tracked participants' belief about the active rule. These rule-specific, intrinsic correlation patterns broke down on error trials and predicted individuals' model-inferred internal noise. Our findings indicate that internal beliefs about task state are instantiated in specific large-scale patterns of selective, correlated neural variability.},
	language = {en},
	urldate = {2022-03-11},
	institution = {bioRxiv},
	author = {Brink, Ruud Lucas van den and Hagena, Keno and Wilming, Niklas and Murphy, Peter R. and Buechel, Christian and Donner, Tobias H.},
	month = mar,
	year = {2022},
	doi = {10.1101/2022.03.10.483758},
	note = {Section: New Results
Type: article},
	pages = {2022.03.10.483758},
	file = {Full Text PDF:/Users/tito/Zotero/storage/47KPHMIN/Brink et al. - 2022 - Large-Scale Circuit Configuration for Flexible Sen.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/HBYRW7Y8/2022.03.10.html:text/html},
}

@article{kim_neural_2022,
	title = {A {Neural} {Programming} {Language} for the {Reservoir} {Computer}},
	url = {http://arxiv.org/abs/2203.05032},
	abstract = {From logical reasoning to mental simulation, biological and artificial neural systems possess an incredible capacity for computation. Such neural computers offer a fundamentally novel computing paradigm by representing data continuously and processing information in a natively parallel and distributed manner. To harness this computation, prior work has developed extensive training techniques to understand existing neural networks. However, the lack of a concrete and low-level programming language for neural networks precludes us from taking full advantage of a neural computing framework. Here, we provide such a programming language using reservoir computing -- a simple recurrent neural network -- and close the gap between how we conceptualize and implement neural computers and silicon computers. By decomposing the reservoir's internal representation and dynamics into a symbolic basis of its inputs, we define a low-level neural machine code that we use to program the reservoir to solve complex equations and store chaotic dynamical systems as random access memory (dRAM). Using this representation, we provide a fully distributed neural implementation of software virtualization and logical circuits, and even program a playable game of pong inside of a reservoir computer. Taken together, we define a concrete, practical, and fully generalizable implementation of neural computation.},
	urldate = {2022-03-15},
	journal = {arXiv:2203.05032 [cond-mat, physics:nlin]},
	author = {Kim, Jason Z. and Bassett, Dani S.},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.05032},
	keywords = {Mathematics - Dynamical Systems, Condensed Matter - Disordered Systems and Neural Networks, Nonlinear Sciences - Chaotic Dynamics},
	annote = {Comment: 13 pages, 6 figures, with a supplement},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/9DIAK4AI/2203.html:text/html;Kim_Bassett_2022_A Neural Programming Language for the Reservoir Computer.pdf:/Users/tito/Zotero/storage/8UHWM9W3/Kim_Bassett_2022_A Neural Programming Language for the Reservoir Computer.pdf:application/pdf},
}

@article{kudithipudi_biological_2022,
	title = {Biological underpinnings for lifelong learning machines},
	volume = {4},
	copyright = {2022 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00452-0},
	doi = {10.1038/s42256-022-00452-0},
	abstract = {Biological organisms learn from interactions with their environment throughout their lifetime. For artificial systems to successfully act and adapt in the real world, it is desirable to similarly be able to learn on a continual basis. This challenge is known as lifelong learning, and remains to a large extent unsolved. In this Perspective article, we identify a set of key capabilities that artificial systems will need to achieve lifelong learning. We describe a number of biological mechanisms, both neuronal and non-neuronal, that help explain how organisms solve these challenges, and present examples of biologically inspired models and biologically plausible mechanisms that have been applied to artificial systems in the quest towards development of lifelong learning machines. We discuss opportunities to further our understanding and advance the state of the art in lifelong learning, aiming to bridge the gap between natural and artificial intelligence.},
	language = {en},
	number = {3},
	urldate = {2022-03-29},
	journal = {Nat Mach Intell},
	author = {Kudithipudi, Dhireesha and Aguilar-Simon, Mario and Babb, Jonathan and Bazhenov, Maxim and Blackiston, Douglas and Bongard, Josh and Brna, Andrew P. and Chakravarthi Raja, Suraj and Cheney, Nick and Clune, Jeff and Daram, Anurag and Fusi, Stefano and Helfer, Peter and Kay, Leslie and Ketz, Nicholas and Kira, Zsolt and Kolouri, Soheil and Krichmar, Jeffrey L. and Kriegman, Sam and Levin, Michael and Madireddy, Sandeep and Manicka, Santosh and Marjaninejad, Ali and McNaughton, Bruce and Miikkulainen, Risto and Navratilova, Zaneta and Pandit, Tej and Parker, Alice and Pilly, Praveen K. and Risi, Sebastian and Sejnowski, Terrence J. and Soltoggio, Andrea and Soures, Nicholas and Tolias, Andreas S. and Urbina-Meléndez, Darío and Valero-Cuevas, Francisco J. and van de Ven, Gido M. and Vogelstein, Joshua T. and Wang, Felix and Weiss, Ron and Yanguas-Gil, Angel and Zou, Xinyun and Siegelmann, Hava},
	month = mar,
	year = {2022},
	note = {Number: 3
Publisher: Nature Publishing Group},
	keywords = {Intelligence, Learning algorithms, Computer science},
	pages = {196--210},
	file = {Kudithipudi et al_2022_Biological underpinnings for lifelong learning machines.pdf:/Users/tito/Zotero/storage/ECGQE53Z/Kudithipudi et al_2022_Biological underpinnings for lifelong learning machines.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/GFR9A24V/s42256-022-00452-0.html:text/html},
}

@article{seider_accuracy_2022,
	title = {Accuracy and {Reliability} of {Diffusion} {Imaging} {Models}},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381192200266X},
	doi = {10.1016/j.neuroimage.2022.119138},
	abstract = {Diffusion imaging aims to non-invasively characterize the anatomy and integrity of the brain's white matter fibers. We evaluated the accuracy and reliability of commonly used diffusion imaging methods as a function of data quantity and analysis method, using both simulations and highly sampled individual-specific data (927-1442 diffusion weighted images [DWIs] per individual). Diffusion imaging methods that allow for crossing fibers (FSL's BedpostX [BPX], DSI Studio's Constant Solid Angle Q-Ball Imaging [CSA-QBI], MRtrix3’s Constrained Spherical Deconvolution [CSD]) estimated excess fibers when insufficient data were present and/or when the data did not match the model priors. To reduce such overfitting, we developed a novel Bayesian Multi-tensor Model-selection (BaMM) method and applied it to the popular ball-and-stick model used in BedpostX within the FSL software package. BaMM was robust to overfitting and showed high reliability and the relatively best crossing-fiber accuracy with increasing amounts of diffusion data. Thus, sufficient data and an overfitting resistant analysis method enhance precision diffusion imaging. For potential clinical applications of diffusion imaging, such as neurosurgical planning and deep brain stimulation (DBS), the quantities of data required to achieve diffusion imaging reliability are lower than those needed for functional MRI.},
	language = {en},
	urldate = {2022-03-29},
	journal = {NeuroImage},
	author = {Seider, Nicole A. and Adeyemo, Babatunde and Miller, Ryland and Newbold, Dillan J. and Hampton, Jacqueline M. and Scheidter, Kristen M. and Rutlin, Jerrel and Laumann, Timothy O. and Roland, Jarod L. and Montez, David F. and Van, Andrew N. and Zheng, Annie and Marek, Scott and Kay, Benjamin P. and Bretthorst, G. Larry and Schlaggar, Bradley L. and Greene, Deanna J. and Wang, Yong and Petersen, Steven E. and Barch, Deanna M. and Gordon, Evan M. and Snyder, Abraham Z. and Shimony, Joshua S. and Dosenbach, Nico U. F.},
	month = mar,
	year = {2022},
	pages = {119138},
}

@article{stocco_analysis_2021,
	title = {Analysis of the human connectome data supports the notion of a “{Common} {Model} of {Cognition}” for human and human-like intelligence across domains},
	volume = {235},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921003128},
	doi = {10.1016/j.neuroimage.2021.118035},
	abstract = {The Common Model of Cognition (CMC) is a recently proposed, consensus architecture intended to capture decades of progress in cognitive science on modeling human and human-like intelligence. Because of the broad agreement around it and preliminary mappings of its components to specific brain areas, we hypothesized that the CMC could be a candidate model of the large-scale functional architecture of the human brain. To test this hypothesis, we analyzed functional MRI data from 200 participants and seven different tasks that cover a broad range of cognitive domains. The CMC components were identified with functionally homologous brain regions through canonical fMRI analysis, and their communication pathways were translated into predicted patterns of effective connectivity between regions. The resulting dynamic linear model was implemented and fitted using Dynamic Causal Modeling, and compared against six alternative brain architectures that had been previously proposed in the field of neuroscience (three hierarchical architectures and three hub-and-spoke architectures) using a Bayesian approach. The results show that, in all cases, the CMC vastly outperforms all other architectures, both within each domain and across all tasks. These findings suggest that a common set of architectural principles that could be used for artificial intelligence also underpins human brain function across multiple cognitive domains.},
	language = {en},
	urldate = {2022-03-29},
	journal = {NeuroImage},
	author = {Stocco, Andrea and Sibert, Catherine and Steine-Hanson, Zoe and Koh, Natalie and Laird, John E. and Lebiere, Christian J. and Rosenbloom, Paul},
	month = jul,
	year = {2021},
	pages = {118035},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/YMPEA2J2/S1053811921003128.html:text/html;Stocco et al_2021_Analysis of the human connectome data supports the notion of a “Common Model of.pdf:/Users/tito/Zotero/storage/MI4A65WK/Stocco et al_2021_Analysis of the human connectome data supports the notion of a “Common Model of.pdf:application/pdf},
}

@article{newbold_cingulo-opercular_2021,
	title = {Cingulo-opercular control network and disused motor circuits joined in standby mode},
	volume = {118},
	url = {https://www.pnas.org/doi/10.1073/pnas.2019128118},
	doi = {10.1073/pnas.2019128118},
	number = {13},
	urldate = {2022-03-30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Newbold, Dillan J. and Gordon, Evan M. and Laumann, Timothy O. and Seider, Nicole A. and Montez, David F. and Gross, Sarah J. and Zheng, Annie and Nielsen, Ashley N. and Hoyt, Catherine R. and Hampton, Jacqueline M. and Ortega, Mario and Adeyemo, Babatunde and Miller, Derek B. and Van, Andrew N. and Marek, Scott and Schlaggar, Bradley L. and Carter, Alexandre R. and Kay, Benjamin P. and Greene, Deanna J. and Raichle, Marcus E. and Petersen, Steven E. and Snyder, Abraham Z. and Dosenbach, Nico U. F.},
	month = mar,
	year = {2021},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2019128118},
	file = {Newbold et al_2021_Cingulo-opercular control network and disused motor circuits joined in standby.pdf:/Users/tito/Zotero/storage/8JZJ6BWZ/Newbold et al_2021_Cingulo-opercular control network and disused motor circuits joined in standby.pdf:application/pdf},
}

@article{newbold_plasticity_2020,
	title = {Plasticity and {Spontaneous} {Activity} {Pulses} in {Disused} {Human} {Brain} {Circuits}},
	volume = {107},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627320303536},
	doi = {10.1016/j.neuron.2020.05.007},
	abstract = {To induce brain plasticity in humans, we casted the dominant upper extremity for 2 weeks and tracked changes in functional connectivity using daily 30-min scans of resting-state functional MRI (rs-fMRI). Casting caused cortical and cerebellar regions controlling the disused extremity to functionally disconnect from the rest of the somatomotor system, while internal connectivity within the disused sub-circuit was maintained. Functional disconnection was evident within 48 h, progressed throughout the cast period, and reversed after cast removal. During the cast period, large, spontaneous pulses of activity propagated through the disused somatomotor sub-circuit. The adult brain seems to rely on regular use to maintain its functional architecture. Disuse-driven spontaneous activity pulses may help preserve functionally disconnected sub-circuits.},
	language = {en},
	number = {3},
	urldate = {2022-03-30},
	journal = {Neuron},
	author = {Newbold, Dillan J. and Laumann, Timothy O. and Hoyt, Catherine R. and Hampton, Jacqueline M. and Montez, David F. and Raut, Ryan V. and Ortega, Mario and Mitra, Anish and Nielsen, Ashley N. and Miller, Derek B. and Adeyemo, Babatunde and Nguyen, Annie L. and Scheidter, Kristen M. and Tanenbaum, Aaron B. and Van, Andrew N. and Marek, Scott and Schlaggar, Bradley L. and Carter, Alexandre R. and Greene, Deanna J. and Gordon, Evan M. and Raichle, Marcus E. and Petersen, Steven E. and Snyder, Abraham Z. and Dosenbach, Nico U. F.},
	month = aug,
	year = {2020},
	keywords = {spontaneous activity, fMRI, functional connectivity, resting state, plasticity, supplementary motor area, primary motor cortex, ALFF, amplitude of low-frequency fluctuations, cerebellum, disuse},
	pages = {580--589.e6},
	file = {Newbold et al_2020_Plasticity and Spontaneous Activity Pulses in Disused Human Brain Circuits.pdf:/Users/tito/Zotero/storage/Q5H8R7W2/Newbold et al_2020_Plasticity and Spontaneous Activity Pulses in Disused Human Brain Circuits.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/GWY8S7QR/S0896627320303536.html:text/html},
}

@article{taylor_characterization_2018-1,
	title = {Characterization of the hemodynamic response function across the majority of human cerebral cortex},
	volume = {173},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381191830168X},
	doi = {10.1016/j.neuroimage.2018.02.061},
	abstract = {A brief ({\textless}4 s) period of neural activation evokes a stereotypical sequence of vascular and metabolic events to create the hemodynamic response function (HRF) measured using functional magnetic resonance imaging (fMRI). Linear analysis of fMRI data requires that the HRF be treated as an impulse response, so the character and temporal stability of the HRF are critical issues. Here, a simple audiovisual stimulus combined with a fast-paced task was used to evoke a strong HRF across a majority, ∼77\%, of cortex during a single scanning session. High spatiotemporal resolution (2-mm voxels, 1.25-s acquisition time) was used to focus HRF measurements specifically on the gray matter for whole brain. The majority of activated cortex responds with positive HRFs, while ∼27\% responds with negative (inverted) HRFs. Spatial patterns of the HRF response amplitudes were found to be similar across subjects. Timing of the initial positive lobe of the HRF was relatively stable across the cortical surface with a mean of 6.1 ± 0.6 s across subjects, yet small but significant timing variations were also evident in specific regions of cortex. The results provide guidance for linear analysis of fMRI data. More importantly, this method provides a means to quantify neurovascular function across most of the brain, with potential clinical utility for the diagnosis of brain pathologies such as traumatic brain injury.},
	language = {en},
	urldate = {2022-03-30},
	journal = {NeuroImage},
	author = {Taylor, Amanda J. and Kim, Jung Hwan and Ress, David},
	month = jun,
	year = {2018},
	keywords = {fMRI, Cerebral hemodynamics, Cerebral pathology, Multisensory stimulation, Neurovascular coupling},
	pages = {322--331},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/YHDZ74L6/S105381191830168X.html:text/html;Taylor et al_2018_Characterization of the hemodynamic response function across the majority of.pdf:/Users/tito/Zotero/storage/VYR9DMPL/Taylor et al_2018_Characterization of the hemodynamic response function across the majority of.pdf:application/pdf},
}

@article{krendl_social_2022,
	title = {Social cognitive network neuroscience},
	issn = {1749-5016},
	url = {https://doi.org/10.1093/scan/nsac020},
	doi = {10.1093/scan/nsac020},
	abstract = {Over the past three decades, research from the field of social neuroscience has identified a constellation of brain regions that relate to social cognition. Although these studies have provided important insights into the specific neural regions underlying social behavior, they may overlook the broader neural context in which those regions and the interactions between them are embedded. Network neuroscience is an emerging discipline that focuses on modeling and analyzing brain networks—collections of interacting neural elements. Because human cognition requires integrating information across multiple brain regions and systems, we argue that a novel social cognitive network neuroscience approach—which leverages methods from the field of network neuroscience and graph theory—can advance our understanding of how brain systems give rise to social behavior. This review provides an overview of the field of network neuroscience, discusses studies that have leveraged this approach to advance social neuroscience research, highlights the potential contributions of social cognitive network neuroscience to understanding social behavior and provides suggested tools and resources for conducting network neuroscience research.},
	urldate = {2022-03-30},
	journal = {Social Cognitive and Affective Neuroscience},
	author = {Krendl, Anne C and Betzel, Richard F},
	month = mar,
	year = {2022},
	pages = {nsac020},
	file = {Krendl_Betzel_2022_Social cognitive network neuroscience.pdf:/Users/tito/Zotero/storage/4U9F9TNI/Krendl_Betzel_2022_Social cognitive network neuroscience.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/K2IMIP3C/6549317.html:text/html},
}

@techreport{javadzadeh_dynamic_2021,
	title = {Dynamic causal communication channels between neocortical areas},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.06.28.449892v1},
	abstract = {Dynamic pathways of information flow between distributed brain regions underlie the diversity of behaviour. However, it remains unclear how neuronal activity in one area causally influences ongoing population activity in another, and how such interactions change over time. Here we introduce a causal approach to quantify cortical interactions by pairing simultaneous electrophysiological recordings with neural perturbations. We found that the influence visual cortical areas had on each other was surprisingly variable over time. Both feedforward and feedback pathways reliably affected different subpopulations of target neurons at different moments during processing of a visual stimulus, resulting in dynamically rotating communication dimensions between the two cortical areas. The influence of feedback on primary visual cortex (V1) became even more dynamic when visual stimuli were associated with a reward, impacting different subsets of V1 neurons within tens of milliseconds. This, in turn, controlled the geometry of V1 population activity in a behaviourally relevant manner. Thus, distributed neural populations interact through dynamically reorganizing and context-dependent communication channels to evaluate sensory information.},
	language = {en},
	urldate = {2022-03-30},
	institution = {bioRxiv},
	author = {Javadzadeh, Mitra and Hofer, Sonja B.},
	month = jun,
	year = {2021},
	doi = {10.1101/2021.06.28.449892},
	note = {Section: New Results
Type: article},
	pages = {2021.06.28.449892},
	file = {Javadzadeh_Hofer_2021_Dynamic causal communication channels between neocortical areas.pdf:/Users/tito/Zotero/storage/CVKCQDD2/Javadzadeh_Hofer_2021_Dynamic causal communication channels between neocortical areas.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/CZAUPTKH/2021.06.28.449892v1.html:text/html},
}

@techreport{dekker_determinants_2022,
	title = {Determinants of human compositional generalization},
	url = {https://psyarxiv.com/qnpw6/},
	abstract = {Generalisation (or transfer) is the ability to repurpose knowledge in novel settings. It is often asserted that generalisation is an important ingredient of human intelligence, but its extent, nature and determinants have proved controversial. Here, we re-examine this question with a new paradigm that formalises the transfer learning problem as one of recomposing existing functions to solve unseen problems. We find that people can generalise compositionally in ways that are elusive for standard neural networks, and that human generalisation benefits from training regimes in which items are axis-aligned and temporally correlated. We describe a neural network model based around a Hebbian gating process which can capture how human generalisation benefits from different training curricula. We additionally find that adult humans tend to learn composable functions asynchronously, exhibiting discontinuities in learning that resemble those seen in child development.},
	language = {en-us},
	urldate = {2022-03-31},
	institution = {PsyArXiv},
	author = {Dekker, Ronald Boris and Otto, Fabian and Summerfield, Christopher},
	month = mar,
	year = {2022},
	doi = {10.31234/osf.io/qnpw6},
	note = {type: article},
	keywords = {neural network, Learning, Neuroscience, Cognitive Psychology, Concepts and Categories, Social and Behavioral Sciences, Computational Neuroscience, generalisation},
	file = {Dekker et al_2022_Determinants of human compositional generalization.pdf:/Users/tito/Zotero/storage/BWU3XX4R/Dekker et al_2022_Determinants of human compositional generalization.pdf:application/pdf},
}

@article{wang_investigating_2022,
	title = {Investigating the {Properties} of {Neural} {Network} {Representations} in {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2203.15955},
	abstract = {In this paper we investigate the properties of representations learned by deep reinforcement learning systems. Much of the earlier work in representation learning for reinforcement learning focused on designing fixed-basis architectures to achieve properties thought to be desirable, such as orthogonality and sparsity. In contrast, the idea behind deep reinforcement learning methods is that the agent designer should not encode representational properties, but rather that the data stream should determine the properties of the representation -- good representations emerge under appropriate training schemes. In this paper we bring these two perspectives together, empirically investigating the properties of representations that support transfer in reinforcement learning. This analysis allows us to provide novel hypotheses regarding impact of auxiliary tasks in end-to-end training of non-linear reinforcement learning methods. We introduce and measure six representational properties over more than 25 thousand agent-task settings. We consider DQN agents with convolutional networks in a pixel-based navigation environment. We develop a method to better understand {\textbackslash}emph\{why\} some representations work better for transfer, through a systematic approach varying task similarity and measuring and correlating representation properties with transfer performance.},
	urldate = {2022-03-31},
	journal = {arXiv:2203.15955 [cs]},
	author = {Wang, Han and Miahi, Erfan and White, Martha and Machado, Marlos C. and Abbas, Zaheer and Kumaraswamy, Raksha and Liu, Vincent and White, Adam},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.15955},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/JPSBL4ZT/2203.html:text/html;Wang et al_2022_Investigating the Properties of Neural Network Representations in Reinforcement.pdf:/Users/tito/Zotero/storage/AEGR4GTK/Wang et al_2022_Investigating the Properties of Neural Network Representations in Reinforcement.pdf:application/pdf},
}

@article{noble_influences_2017,
	title = {Influences on the {Test}–{Retest} {Reliability} of {Functional} {Connectivity} {MRI} and its {Relationship} with {Behavioral} {Utility}},
	volume = {27},
	issn = {1047-3211},
	url = {https://doi.org/10.1093/cercor/bhx230},
	doi = {10.1093/cercor/bhx230},
	abstract = {Best practices are currently being developed for the acquisition and processing of resting-state magnetic resonance imaging data used to estimate brain functional organization—or “functional connectivity.” Standards have been proposed based on test–retest reliability, but open questions remain. These include how amount of data per subject influences whole-brain reliability, the influence of increasing runs versus sessions, the spatial distribution of reliability, the reliability of multivariate methods, and, crucially, how reliability maps onto prediction of behavior. We collected a dataset of 12 extensively sampled individuals (144 min data each across 2 identically configured scanners) to assess test–retest reliability of whole-brain connectivity within the generalizability theory framework. We used Human Connectome Project data to replicate these analyses and relate reliability to behavioral prediction. Overall, the historical 5-min scan produced poor reliability averaged across connections. Increasing the number of sessions was more beneficial than increasing runs. Reliability was lowest for subcortical connections and highest for within-network cortical connections. Multivariate reliability was greater than univariate. Finally, reliability could not be used to improve prediction; these findings are among the first to underscore this distinction for functional connectivity. A comprehensive understanding of test–retest reliability, including its limitations, supports the development of best practices in the field.},
	number = {11},
	urldate = {2022-03-31},
	journal = {Cerebral Cortex},
	author = {Noble, Stephanie and Spann, Marisa N and Tokoglu, Fuyuze and Shen, Xilin and Constable, R Todd and Scheinost, Dustin},
	month = nov,
	year = {2017},
	pages = {5415--5429},
	file = {Noble et al_2017_Influences on the Test–Retest Reliability of Functional Connectivity MRI and.pdf:/Users/tito/Zotero/storage/EUSEJ3YF/Noble et al_2017_Influences on the Test–Retest Reliability of Functional Connectivity MRI and.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5T5AUV5V/4139668.html:text/html},
}

@inproceedings{kepple_curriculum_2021,
	title = {Curriculum learning as a tool to uncover learning principles in the brain},
	url = {https://openreview.net/forum?id=TpJMvo0_pu-},
	abstract = {We present a novel approach to use curricula to identify principles by which a system learns. Previous work in curriculum learning has focused on how curricula can be designed to improve learning...},
	language = {en},
	urldate = {2022-03-31},
	author = {Kepple, Daniel R. and Engelken, Rainer and Rajan, Kanaka},
	month = sep,
	year = {2021},
	file = {Kepple et al_2021_Curriculum learning as a tool to uncover learning principles in the brain.pdf:/Users/tito/Zotero/storage/EVNDDXU5/Kepple et al_2021_Curriculum learning as a tool to uncover learning principles in the brain.pdf:application/pdf},
}

@article{wei_effects_2022,
	title = {Effects of virtual lesions on temporal dynamics in cortical networks based on personalized dynamic models},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811922002166},
	doi = {10.1016/j.neuroimage.2022.119087},
	abstract = {The human brain dynamically shifts between a predominantly integrated state and a predominantly segregated state, each with different roles in supporting cognition and behavior. However, no studies to date have investigated lesions placed in different regions of the cerebral cortex to determine the effects on the temporal balance of integration and segregation. Here, we used the integrated state occurrence rate to measure the temporal balance of integration and segregation in the resting brain. Based on dynamic mean-field models coupled through the individual's structural white matter connections, neural activity was modeled. By lesioning different individual nodes from the model, our results implied that the impact of lesions reaches far beyond focal damage and could impair cognition by affecting system-level dynamics. Lesions in a portion of the nodes in the visual, somatomotor, limbic, and default networks significantly compromised the temporal balance of integration and segregation. Crucially, the effects of lesions in different regions could be predicted based on the hierarchical axis inferred from the T1w/T2w map and specific graph measures of structural brain networks. Taken together, our findings indicate the possibility of significant contributions of anatomical heterogeneity to the dynamics of functional network topology. Although still in its infancy, computational modeling may provide an entry point for understanding brain disorders at a causal mechanistic level, possibly leading to novel, more effective therapeutic interventions.},
	language = {en},
	urldate = {2022-04-01},
	journal = {NeuroImage},
	author = {Wei, Jing and Wang, Bin and Yang, Yanli and Niu, Yan and Yang, Lan and Guo, Yuxiang and Xiang, Jie},
	month = mar,
	year = {2022},
	keywords = {Graph theory, Computational modeling, Anatomical hierarchy, Functional dynamics, Lesions},
	pages = {119087},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/PSG24NDP/S1053811922002166.html:text/html;Wei et al_2022_Effects of virtual lesions on temporal dynamics in cortical networks based on.pdf:/Users/tito/Zotero/storage/HTLT3Z22/Wei et al_2022_Effects of virtual lesions on temporal dynamics in cortical networks based on.pdf:application/pdf},
}

@article{flesch_modelling_2022,
	title = {Modelling continual learning in humans with {Hebbian} context gating and exponentially decaying task signals},
	url = {http://arxiv.org/abs/2203.11560},
	abstract = {Humans can learn several tasks in succession with minimal mutual interference but perform more poorly when trained on multiple tasks at once. The opposite is true for standard deep neural networks. Here, we propose novel computational constraints for artificial neural networks, inspired by earlier work on gating in the primate prefrontal cortex, that capture the cost of interleaved training and allow the network to learn two tasks in sequence without forgetting. We augment standard stochastic gradient descent with two algorithmic motifs, so-called "sluggish" task units and a Hebbian training step that strengthens connections between task units and hidden units that encode task-relevant information. We found that the "sluggish" units introduce a switch-cost during training, which biases representations under interleaved training towards a joint representation that ignores the contextual cue, while the Hebbian step promotes the formation of a gating scheme from task units to the hidden layer that produces orthogonal representations which are perfectly guarded against interference. Validating the model on previously published human behavioural data revealed that it matches performance of participants who had been trained on blocked or interleaved curricula, and that these performance differences were driven by misestimation of the true category boundary.},
	urldate = {2022-04-04},
	journal = {arXiv:2203.11560 [cs, q-bio]},
	author = {Flesch, Timo and Nagy, David G. and Saxe, Andrew and Summerfield, Christopher},
	month = mar,
	year = {2022},
	note = {arXiv: 2203.11560},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning},
	annote = {Comment: 29 pages, 7 figures},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DD2NM4US/2203.html:text/html;Flesch et al_2022_Modelling continual learning in humans with Hebbian context gating and.pdf:/Users/tito/Zotero/storage/9J8G97VK/Flesch et al_2022_Modelling continual learning in humans with Hebbian context gating and.pdf:application/pdf},
}

@article{kumar_disentangling_2022,
	title = {Disentangling {Abstraction} from {Statistical} {Pattern} {Matching} in {Human} and {Machine} {Learning}},
	url = {http://arxiv.org/abs/2204.01437},
	abstract = {The ability to acquire abstract knowledge is a hallmark of human intelligence and is believed by many to be one of the core differences between humans and neural network models. Agents can be endowed with an inductive bias towards abstraction through meta-learning, where they are trained on a distribution of tasks that share some abstract structure that can be learned and applied. However, because neural networks are hard to interpret, it can be difficult to tell whether agents have learned the underlying abstraction, or alternatively statistical patterns that are characteristic of that abstraction. In this work, we compare the performance of humans and agents in a meta-reinforcement learning paradigm in which tasks are generated from abstract rules. We define a novel methodology for building "task metamers" that closely match the statistics of the abstract tasks but use a different underlying generative process, and evaluate performance on both abstract and metamer tasks. In our first set of experiments, we found that humans perform better at abstract tasks than metamer tasks whereas a widely-used meta-reinforcement learning agent performs worse on the abstract tasks than the matched metamers. In a second set of experiments, we base the tasks on abstractions derived directly from empirically identified human priors. We utilize the same procedure to generate corresponding metamer tasks, and see the same double dissociation between humans and agents. This work provides a foundation for characterizing differences between humans and machine learning that can be used in future work towards developing machines with human-like behavior.},
	urldate = {2022-04-05},
	journal = {arXiv:2204.01437 [cs]},
	author = {Kumar, Sreejan and Dasgupta, Ishita and Marjieh, Raja and Daw, Nathaniel D. and Cohen, Jonathan D. and Griffiths, Thomas L.},
	month = apr,
	year = {2022},
	note = {arXiv: 2204.01437},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/RXQDAMXB/2204.html:text/html;Kumar et al_2022_Disentangling Abstraction from Statistical Pattern Matching in Human and.pdf:/Users/tito/Zotero/storage/C239Y3YW/Kumar et al_2022_Disentangling Abstraction from Statistical Pattern Matching in Human and.pdf:application/pdf},
}

@article{kumar_meta-learning_2021,
	title = {Meta-{Learning} of {Structured} {Task} {Distributions} in {Humans} and {Machines}},
	url = {http://arxiv.org/abs/2010.02317},
	abstract = {In recent years, meta-learning, in which a model is trained on a family of tasks (i.e. a task distribution), has emerged as an approach to training neural networks to perform tasks that were previously assumed to require structured representations, making strides toward closing the gap between humans and machines. However, we argue that evaluating meta-learning remains a challenge, and can miss whether meta-learning actually uses the structure embedded within the tasks. These metalearners might therefore still be signiﬁcantly different from humans learners. To demonstrate this difference, we ﬁrst deﬁne a new meta-reinforcement learning task in which a structured task distribution is generated using a compositional grammar. We then introduce a novel approach to constructing a “null task distribution” with the same statistical complexity as this structured task distribution but without the explicit rule-based structure used to generate the structured task. We train a standard meta-learning agent, a recurrent network trained with modelfree reinforcement learning, and compare it with human performance across the two task distributions. We ﬁnd a double dissociation in which humans do better in the structured task distribution whereas agents do better in the null task distribution – despite comparable statistical complexity. This work highlights that multiple strategies can achieve reasonable meta-test performance, and that careful construction of control task distributions is a valuable way to understand which strategies meta-learners acquire, and how they might differ from humans.},
	language = {en},
	urldate = {2022-04-05},
	journal = {arXiv:2010.02317 [cs]},
	author = {Kumar, Sreejan and Dasgupta, Ishita and Cohen, Jonathan D. and Daw, Nathaniel D. and Griffiths, Thomas L.},
	month = mar,
	year = {2021},
	note = {arXiv: 2010.02317},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: Accepted at ICLR 2021},
	file = {Kumar et al. - 2021 - Meta-Learning of Structured Task Distributions in .pdf:/Users/tito/Zotero/storage/ZN4B3Q8J/Kumar et al. - 2021 - Meta-Learning of Structured Task Distributions in .pdf:application/pdf},
}

@article{mccloskey_is_1988,
	title = {Is there a special flashbulb-memory mechanism?},
	volume = {117},
	issn = {1939-2222},
	doi = {10.1037/0096-3445.117.2.171},
	abstract = {Many people report vivid recollections of the circumstances in which they learned of major events, such as the assassination of President Kennedy, or the assassination attempt on President Reagan. Brown and Kulik (1977) argued that this phenomenon, which they labeled flashbulb memory, implies the existence of a special memory mechanism that creates a detailed, permanent record of the individual's experience when triggered by an event exceeding criterial levels of surprise and consequentiality. In this article we evaluate the special-mechanism hypothesis, arguing on empirical and logical grounds that the flashbulb-memory phenomenon does not motivate the postulation of a special flashbulb-memory mechanism. We suggest instead that flashbulb memories should be viewed as products of "ordinary" memory mechanisms, and hence as phenomena that may offer insights into the nature of these mechanisms. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Journal of Experimental Psychology: General},
	author = {McCloskey, Michael and Wible, Cynthia G. and Cohen, Neal J.},
	year = {1988},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Memory, Experiences (Events)},
	pages = {171--181},
	file = {Snapshot:/Users/tito/Zotero/storage/2SRR7K54/1988-28560-001.html:text/html},
}

@incollection{mccloskey_catastrophic_1989,
	title = {Catastrophic {Interference} in {Connectionist} {Networks}: {The} {Sequential} {Learning} {Problem}},
	volume = {24},
	shorttitle = {Catastrophic {Interference} in {Connectionist} {Networks}},
	url = {https://www.sciencedirect.com/science/article/pii/S0079742108605368},
	abstract = {Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.},
	language = {en},
	urldate = {2022-04-11},
	booktitle = {Psychology of {Learning} and {Motivation}},
	publisher = {Academic Press},
	author = {McCloskey, Michael and Cohen, Neal J.},
	editor = {Bower, Gordon H.},
	month = jan,
	year = {1989},
	doi = {10.1016/S0079-7421(08)60536-8},
	pages = {109--165},
}

@techreport{dujmovic_pitfalls_2022,
	title = {The pitfalls of measuring representational similarity using representational similarity analysis},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.04.05.487135v1},
	abstract = {A core challenge in neuroscience is to assess whether diverse systems represent the world similarly. Representational Similarity Analysis (RSA) is an innovative approach to address this problem and has become increasingly popular across disciplines from machine learning to computational neuroscience. Despite these successes, RSA regularly uncovers difficult-to-reconcile and contradictory findings. Here we demonstrate the pitfalls of using RSA to infer representational similarity and explain how contradictory findings arise and support false inferences when left unchecked. By comparing neural representations in primate, human and computational models, we reveal two problematic phenomena that are ubiquitous in current research: a “mimic” effect, where confounds in stimuli can lead to high RSA scores between provably dissimilar systems, and a “modulation effect”, where RSA-scores become dependent on stimuli used for testing. Since our results bear on existing findings and inferences, we provide recommendations to avoid these pitfalls and sketch a way forward.},
	language = {en},
	urldate = {2022-04-11},
	institution = {bioRxiv},
	author = {Dujmović, Marin and Bowers, Jeffrey S. and Adolfi, Federico and Malhotra, Gaurav},
	month = apr,
	year = {2022},
	doi = {10.1101/2022.04.05.487135},
	note = {Section: New Results
Type: article},
	pages = {2022.04.05.487135},
	file = {Dujmović et al_2022_The pitfalls of measuring representational similarity using representational.pdf:/Users/tito/Zotero/storage/85ZT3Q55/Dujmović et al_2022_The pitfalls of measuring representational similarity using representational.pdf:application/pdf},
}

@article{mcclelland_why_1995,
	title = {Why there are complementary learning systems in the hippocampus and neocortex: {Insights} from the successes and failures of connectionist models of learning and memory},
	volume = {102},
	issn = {1939-1471},
	shorttitle = {Why there are complementary learning systems in the hippocampus and neocortex},
	doi = {10.1037/0033-295X.102.3.419},
	abstract = {Damage to the hippocampal system disrupts recent memory but leaves remote memory intact. The account presented here suggests that memories are first stored via synaptic changes in the hippocampal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocortical changes. Models that learn via changes to connections help explain this organization. These models discover the structure in ensembles of items if learning of each item is gradual and interleaved with learning about other items. This suggests that the neocortex learns slowly to discover the structure in ensembles of experiences. The hippocampal system permits rapid learning of new items without disrupting this structure, and reinstatement of new memories interleaves them with others to integrate them into structured neocortical memory systems. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	number = {3},
	journal = {Psychological Review},
	author = {McClelland, James L. and McNaughton, Bruce L. and O'Reilly, Randall C.},
	year = {1995},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cerebral Cortex, Learning, Hippocampus, Neural Networks, Connectionism, Neocortex},
	pages = {419--457},
}

@techreport{singh_model_2022,
	title = {A model of autonomous interactions between hippocampus and neocortex driving sleep-dependent memory consolidation},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.01.31.478475v1},
	abstract = {How do we build up our knowledge of the world over time? Many theories of memory formation and consolidation have posited that the hippocampus stores new information, then “teaches” this information to neocortex over time, especially during sleep. But it is unclear, mechanistically, how this actually works — how are these systems able to interact during periods with virtually no environmental input to accomplish useful learning and shifts in representation? We provide a framework for thinking about this question, with neural network model simulations serving as demonstrations. The model contains hippocampus and neocortical areas, which replay memories and interact with one another completely autonomously during simulated sleep. Oscillations are leveraged to support error-driven learning that leads to useful changes in memory representation and behavior. The model has a non-Rapid Eye Movement (NREM) sleep stage, where dynamics between hippocampus and neocortex are tightly coupled, with hippocampus helping neocortex to reinstate high-fidelity versions of new attractors, and a REM sleep stage, where neocortex is able to more freely explore existing attractors. We find that alternating between NREM and REM sleep stages, which alternately focuses the model’s replay on recent and remote information, facilitates graceful continual learning. We thus provide an account of how the hippocampus and neocortex can interact without any external input during sleep to drive useful new cortical learning and to protect old knowledge as new information is integrated.},
	language = {en},
	urldate = {2022-04-11},
	institution = {bioRxiv},
	author = {Singh, Dhairyya and Norman, Kenneth A. and Schapiro, Anna C.},
	month = feb,
	year = {2022},
	doi = {10.1101/2022.01.31.478475},
	note = {Section: New Results
Type: article},
	pages = {2022.01.31.478475},
	file = {Singh et al_2022_A model of autonomous interactions between hippocampus and neocortex driving.pdf:/Users/tito/Zotero/storage/6336LIHD/Singh et al_2022_A model of autonomous interactions between hippocampus and neocortex driving.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5LHEYAP2/2022.01.31.478475v1.html:text/html},
}

@techreport{stockl_probabilistic_2021,
	title = {Probabilistic skeletons endow brain-like neural networks with innate computing capabilities},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.18.444689v2},
	abstract = {The genetic code endows neural networks of the brain with innate computing capabilities. But it has remained unknown how it achieves this. Experimental data show that the genome encodes the architecture of neocortical circuits through pairwise connection probabilities for a fairly large set of genetically different types of neurons. We build a mathematical model for this style of indirect encoding, a probabilistic skeleton, and show that it suffices for programming a repertoire of quite demanding computing capabilities into neural networks. These computing capabilities emerge without learning, but are likely to provide a powerful platform for subsequent rapid learning. They are engraved into neural networks through architectural features on the statistical level, rather than through synaptic weights. Hence they are specified in a much lower dimensional parameter space, thereby providing enhanced robustness and generalization capabilities as predicted by preceding work.},
	language = {en},
	urldate = {2022-04-11},
	institution = {bioRxiv},
	author = {Stöckl, Christoph and Lang, Dominik and Maass, Wolfgang},
	month = jul,
	year = {2021},
	doi = {10.1101/2021.05.18.444689},
	note = {Section: New Results
Type: article},
	pages = {2021.05.18.444689},
	file = {Stöckl et al_2021_Probabilistic skeletons endow brain-like neural networks with innate computing.pdf:/Users/tito/Zotero/storage/IBYD8UUG/Stöckl et al_2021_Probabilistic skeletons endow brain-like neural networks with innate computing.pdf:application/pdf},
}

@article{ha_collective_2022,
	title = {Collective {Intelligence} for {Deep} {Learning}: {A} {Survey} of {Recent} {Developments}},
	shorttitle = {Collective {Intelligence} for {Deep} {Learning}},
	url = {http://arxiv.org/abs/2111.14377},
	abstract = {In the past decade, we have witnessed the rise of deep learning to dominate the field of artificial intelligence. Advances in artificial neural networks alongside corresponding advances in hardware accelerators with large memory capacity, together with the availability of large datasets enabled practitioners to train and deploy sophisticated neural network models that achieve state-of-the-art performance on tasks across several fields spanning computer vision, natural language processing, and reinforcement learning. However, as these neural networks become bigger, more complex, and more widely used, fundamental problems with current deep learning models become more apparent. State-of-the-art deep learning models are known to suffer from issues that range from poor robustness, inability to adapt to novel task settings, to requiring rigid and inflexible configuration assumptions. Collective behavior, commonly observed in nature, tends to produce systems that are robust, adaptable, and have less rigid assumptions about the environment configuration. Collective intelligence, as a field, studies the group intelligence that emerges from the interactions of many individuals. Within this field, ideas such as self-organization, emergent behavior, swarm optimization, and cellular automata were developed to model and explain complex systems. It is therefore natural to see these ideas incorporated into newer deep learning methods. In this review, we will provide a historical context of neural network research's involvement with complex systems, and highlight several active areas in modern deep learning research that incorporate the principles of collective intelligence to advance its current capabilities. We hope this review can serve as a bridge between the complex systems and deep learning communities.},
	urldate = {2022-04-11},
	journal = {arXiv:2111.14377 [cs]},
	author = {Ha, David and Tang, Yujin},
	month = mar,
	year = {2022},
	note = {arXiv: 2111.14377},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/8LRGGUYY/2111.html:text/html;Ha_Tang_2022_Collective Intelligence for Deep Learning.pdf:/Users/tito/Zotero/storage/9F6JEBVQ/Ha_Tang_2022_Collective Intelligence for Deep Learning.pdf:application/pdf},
}

@article{traut_insights_2022,
	title = {Insights from an autism imaging biomarker challenge: promises and threats to biomarker discovery},
	issn = {1053-8119},
	shorttitle = {Insights from an autism imaging biomarker challenge},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811922002981},
	doi = {10.1016/j.neuroimage.2022.119171},
	abstract = {MRI has been extensively used to identify anatomical and functional differences in Autism Spectrum Disorder (ASD). Yet, many of these findings have proven difficult to replicate because studies rely on small cohorts and are built on many complex, undisclosed, analytic choices. We conducted an international challenge to predict ASD diagnosis from MRI data, where we provided preprocessed anatomical and functional MRI data from {\textgreater} 2,000 individuals. Evaluation of the predictions was rigorously blinded. 146 challengers submitted prediction algorithms, which were evaluated at the end of the challenge using unseen data and an additional acquisition site. On the best algorithms, we studied the importance of MRI modalities, brain regions, and sample size. We found evidence that MRI could predict ASD diagnosis: the 10 best algorithms reliably predicted diagnosis with AUC∼0.80 – far superior to what can be currently obtained using genotyping data in cohorts 20-times larger. We observed that functional MRI was more important for prediction than anatomical MRI, and that increasing sample size steadily increased prediction accuracy, providing an efficient strategy to improve biomarkers. We also observed that despite a strong incentive to generalise to unseen data, model development on a given dataset faces the risk of overfitting: performing well in cross-validation on the data at hand, but not generalising. Finally, we were able to predict ASD diagnosis on an external sample added after the end of the challenge (EU-AIMS), although with a lower prediction accuracy (AUC=0.72). This indicates that despite being based on a large multisite cohort, our challenge still produced biomarkers fragile in the face of dataset shifts.},
	language = {en},
	urldate = {2022-04-11},
	journal = {NeuroImage},
	author = {Traut, Nicolas and Heuer, Katja and Lemaître, Guillaume and Beggiato, Anita and Germanaud, David and Elmaleh, Monique and Bethegnies, Alban and Bonnasse-Gahot, Laurent and Cai, Weidong and Chambon, Stanislas and Cliquet, Freddy and Ghriss, Ayoub and Guigui, Nicolas and de Pierrefeu, Amicie and Wang, Meng and Zantedeschi, Valentina and Boucaud, Alexandre and Bossche, Joris van den and Kegl, Balázs and Delorme, Richard and Bourgeron, Thomas and Toro, Roberto and Varoquaux, Gaël},
	month = apr,
	year = {2022},
	pages = {119171},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/7BJ87JI9/S1053811922002981.html:text/html},
}

@inproceedings{antonello_low-dimensional_2021,
	title = {Low-dimensional {Structure} in the {Space} of {Language} {Representations} is {Reflected} in {Brain} {Responses}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/464074179972cbbd75a39abc6954cd12-Abstract.html},
	abstract = {How related are the representations learned by neural language models, translation models, and language tagging tasks? We answer this question by adapting an encoder-decoder transfer learning method from computer vision to investigate the structure among 100 different feature spaces extracted from hidden representations of various networks trained on language tasks.This method reveals a low-dimensional structure where language models and translation models smoothly interpolate between word embeddings, syntactic and semantic tasks, and future word embeddings. We call this low-dimensional structure a language representation embedding because it encodes the relationships between representations needed to process language for a variety of NLP tasks. We find that this representation embedding can predict how well each individual feature space maps to human brain responses to natural language stimuli recorded using fMRI. Additionally, we find that the principal dimension of this structure can be used to create a metric which highlights the brain's natural language processing hierarchy. This suggests that the embedding captures some part of the brain's natural language representation structure.},
	urldate = {2022-04-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Antonello, Richard and Turek, Javier S and Vo, Vy and Huth, Alexander},
	year = {2021},
	pages = {8332--8344},
	file = {Full Text PDF:/Users/tito/Zotero/storage/9VJ3U8GB/Antonello et al. - 2021 - Low-dimensional Structure in the Space of Language.pdf:application/pdf},
}

@article{chien_mapping_2021,
	title = {Mapping the {Timescale} {Organization} of {Neural} {Language} {Models}},
	url = {http://arxiv.org/abs/2012.06717},
	abstract = {In the human brain, sequences of language input are processed within a distributed and hierarchical architecture, in which higher stages of processing encode contextual information over longer timescales. In contrast, in recurrent neural networks which perform natural language processing, we know little about how the multiple timescales of contextual information are functionally organized. Therefore, we applied tools developed in neuroscience to map the "processing timescales" of individual units within a word-level LSTM language model. This timescale-mapping method assigned long timescales to units previously found to track long-range syntactic dependencies. Additionally, the mapping revealed a small subset of the network (less than 15\% of units) with long timescales and whose function had not previously been explored. We next probed the functional organization of the network by examining the relationship between the processing timescale of units and their network connectivity. We identified two classes of long-timescale units: "controller" units composed a densely interconnected subnetwork and strongly projected to the rest of the network, while "integrator" units showed the longest timescales in the network, and expressed projection profiles closer to the mean projection profile. Ablating integrator and controller units affected model performance at different positions within a sentence, suggesting distinctive functions of these two sets of units. Finally, we tested the generalization of these results to a character-level LSTM model and models with different architectures. In summary, we demonstrated a model-free technique for mapping the timescale organization in recurrent neural networks, and we applied this method to reveal the timescale and functional organization of neural language models.},
	language = {en},
	urldate = {2022-04-11},
	journal = {arXiv:2012.06717 [cs]},
	author = {Chien, Hsiang-Yun Sherry and Zhang, Jinhan and Honey, Christopher J.},
	month = mar,
	year = {2021},
	note = {arXiv: 2012.06717},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 23 pages, 4 main figures, 10 appendix figures; published as a conference paper at ICLR 2021},
	file = {Chien et al. - 2021 - Mapping the Timescale Organization of Neural Langu.pdf:/Users/tito/Zotero/storage/4JHAU85U/Chien et al. - 2021 - Mapping the Timescale Organization of Neural Langu.pdf:application/pdf},
}

@article{higgins_unsupervised_2021,
	title = {Unsupervised deep learning identifies semantic disentanglement in single inferotemporal face patch neurons},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-26751-5},
	doi = {10.1038/s41467-021-26751-5},
	abstract = {In order to better understand how the brain perceives faces, it is important to know what objective drives learning in the ventral visual stream. To answer this question, we model neural responses to faces in the macaque inferotemporal (IT) cortex with a deep self-supervised generative model, β-VAE, which disentangles sensory data into interpretable latent factors, such as gender or age. Our results demonstrate a strong correspondence between the generative factors discovered by β-VAE and those coded by single IT neurons, beyond that found for the baselines, including the handcrafted state-of-the-art model of face perception, the Active Appearance Model, and deep classifiers. Moreover, β-VAE is able to reconstruct novel face images using signals from just a handful of cells. Together our results imply that optimising the disentangling objective leads to representations that closely resemble those in the IT at the single unit level. This points at disentangling as a plausible learning objective for the visual brain.},
	language = {en},
	number = {1},
	urldate = {2022-04-11},
	journal = {Nat Commun},
	author = {Higgins, Irina and Chang, Le and Langston, Victoria and Hassabis, Demis and Summerfield, Christopher and Tsao, Doris and Botvinick, Matthew},
	month = nov,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Visual system, Neuroscience, Computational neuroscience, Object vision},
	pages = {6456},
	file = {Full Text PDF:/Users/tito/Zotero/storage/329A743Y/Higgins et al. - 2021 - Unsupervised deep learning identifies semantic dis.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/ZFJ6IHIR/s41467-021-26751-5.html:text/html},
}

@inproceedings{zamir_taskonomy_2018,
	title = {Taskonomy: {Disentangling} {Task} {Transfer} {Learning}},
	shorttitle = {Taskonomy},
	url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.html},
	urldate = {2022-04-11},
	author = {Zamir, Amir R. and Sax, Alexander and Shen, William and Guibas, Leonidas J. and Malik, Jitendra and Savarese, Silvio},
	year = {2018},
	pages = {3712--3722},
	file = {Snapshot:/Users/tito/Zotero/storage/PSV7ZNT2/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.html:text/html;Zamir et al_2018_Taskonomy.pdf:/Users/tito/Zotero/storage/SHN3J9RS/Zamir et al_2018_Taskonomy.pdf:application/pdf},
}

@article{pao_experimentally_2021,
	title = {Experimentally testable whole brain manifolds that recapitulate behavior},
	url = {http://arxiv.org/abs/2106.10627},
	abstract = {We propose an algorithm grounded in dynamical systems theory that generalizes manifold learning from a global state representation, to a network of local interacting manifolds termed a Generative Manifold Network (GMN). Manifolds are discovered using the convergent cross mapping (CCM) causal inference algorithm which are then compressed into a reduced redundancy network. The representation is a network of manifolds embedded from observational data where each orthogonal axis of a local manifold is an embedding of a individually identifiable neuron or brain area that has exact correspondence in the real world. As such these can be experimentally manipulated to test hypotheses derived from theory and data analysis. Here we demonstrate that this representation preserves the essential features of the brain of flies,larval zebrafish and humans. In addition to accurate near-term prediction, the GMN model can be used to synthesize realistic time series of whole brain neuronal activity and locomotion viewed over the long term. Thus, as a final validation of how well GMN captures essential dynamic information, we show that the artificially generated time series can be used as a training set to predict out-of-sample observed fly locomotion, as well as brain activity in out of sample withheld data not used in model building. Remarkably, the artificially generated time series show realistic novel behaviors that do not exist in the training data, but that do exist in the out-of-sample observational data. This suggests that GMN captures inherently emergent properties of the network. We suggest our approach may be a generic recipe for mapping time series observations of any complex nonlinear network into a model that is able to generate naturalistic system behaviors that identifies variables that have real world correspondence and can be experimentally manipulated.},
	urldate = {2022-04-13},
	journal = {arXiv:2106.10627 [math, q-bio]},
	author = {Pao, Gerald M. and Smith, Cameron and Park, Joseph and Takahashi, Keichi and Watanakeesuntorn, Wassapon and Natsukawa, Hiroaki and Chalasani, Sreekanth H. and Lorimer, Tom and Takano, Ryousei and Rungratsameetaweemana, Nuttida and Sugihara, George},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.10627},
	keywords = {Quantitative Biology - Neurons and Cognition, Mathematics - Dynamical Systems},
	annote = {Comment: 20 pages, 15 figures; corresponding author: Gerald Pao geraldpao@gmail.com},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/SJNFK4NL/2106.html:text/html;Pao et al_2021_Experimentally testable whole brain manifolds that recapitulate behavior.pdf:/Users/tito/Zotero/storage/TEFVXLH9/Pao et al_2021_Experimentally testable whole brain manifolds that recapitulate behavior.pdf:application/pdf},
}

@article{pao_experimentally_2021-1,
	title = {Experimentally testable whole brain manifolds that recapitulate behavior},
	url = {http://arxiv.org/abs/2106.10627},
	abstract = {We propose an algorithm grounded in dynamical systems theory that generalizes manifold learning from a global state representation, to a network of local interacting manifolds termed a Generative Manifold Network (GMN). Manifolds are discovered using the convergent cross mapping (CCM) causal inference algorithm which are then compressed into a reduced redundancy network. The representation is a network of manifolds embedded from observational data where each orthogonal axis of a local manifold is an embedding of a individually identifiable neuron or brain area that has exact correspondence in the real world. As such these can be experimentally manipulated to test hypotheses derived from theory and data analysis. Here we demonstrate that this representation preserves the essential features of the brain of flies,larval zebrafish and humans. In addition to accurate near-term prediction, the GMN model can be used to synthesize realistic time series of whole brain neuronal activity and locomotion viewed over the long term. Thus, as a final validation of how well GMN captures essential dynamic information, we show that the artificially generated time series can be used as a training set to predict out-of-sample observed fly locomotion, as well as brain activity in out of sample withheld data not used in model building. Remarkably, the artificially generated time series show realistic novel behaviors that do not exist in the training data, but that do exist in the out-of-sample observational data. This suggests that GMN captures inherently emergent properties of the network. We suggest our approach may be a generic recipe for mapping time series observations of any complex nonlinear network into a model that is able to generate naturalistic system behaviors that identifies variables that have real world correspondence and can be experimentally manipulated.},
	language = {en},
	urldate = {2022-04-13},
	journal = {arXiv:2106.10627 [math, q-bio]},
	author = {Pao, Gerald M. and Smith, Cameron and Park, Joseph and Takahashi, Keichi and Watanakeesuntorn, Wassapon and Natsukawa, Hiroaki and Chalasani, Sreekanth H. and Lorimer, Tom and Takano, Ryousei and Rungratsameetaweemana, Nuttida and Sugihara, George},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.10627},
	keywords = {Quantitative Biology - Neurons and Cognition, Mathematics - Dynamical Systems},
	annote = {Comment: 20 pages, 15 figures; corresponding author: Gerald Pao geraldpao@gmail.com},
	file = {Pao et al. - 2021 - Experimentally testable whole brain manifolds that.pdf:/Users/tito/Zotero/storage/4GPA98HX/Pao et al. - 2021 - Experimentally testable whole brain manifolds that.pdf:application/pdf},
}

@inproceedings{ansuini_intrinsic_2019,
	title = {Intrinsic dimension of data representations in deep neural networks},
	volume = {32},
	url = {https://papers.nips.cc/paper/2019/hash/cfcce0621b49c983991ead4c3d4d3b6b-Abstract.html},
	abstract = {Deep neural networks progressively transform their inputs across multiple processing layers. What are the geometrical properties of the representations learned by these networks? Here we study the intrinsic dimensionality (ID) of data
representations, i.e. the minimal number of parameters needed to describe a representation. We find that, in a trained network, the ID is orders of magnitude smaller than the number of units in each layer. Across layers, the ID first increases and then progressively decreases in the final layers. Remarkably, the ID of the last hidden layer predicts classification accuracy on the test set. These results can neither be found by linear dimensionality estimates (e.g., with principal component analysis), nor in representations that had been artificially linearized. They are neither found in untrained networks, nor in networks that are trained on randomized labels. This suggests that neural networks that can generalize are those that transform the data into low-dimensional, but not necessarily flat manifolds.},
	urldate = {2022-04-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ansuini, Alessio and Laio, Alessandro and Macke, Jakob H and Zoccolan, Davide},
	year = {2019},
	file = {Ansuini et al_2019_Intrinsic dimension of data representations in deep neural networks.pdf:/Users/tito/Zotero/storage/BRNLXW4L/Ansuini et al_2019_Intrinsic dimension of data representations in deep neural networks.pdf:application/pdf},
}

@article{hogeveen_neurocomputational_2022,
	title = {The neurocomputational bases of explore-exploit decision-making},
	volume = {0},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(22)00250-1},
	doi = {10.1016/j.neuron.2022.03.014},
	language = {English},
	number = {0},
	urldate = {2022-04-15},
	journal = {Neuron},
	author = {Hogeveen, Jeremy and Mullins, Teagan S. and Romero, John D. and Eversole, Elizabeth and Rogge-Obando, Kimberly and Mayer, Andrew R. and Costa, Vincent D.},
	month = apr,
	year = {2022},
	pmid = {35390278},
	note = {Publisher: Elsevier},
	keywords = {fMRI, computational modeling, reinforcement learning, striatum, exploration, reward, amygdala, decision-making, explore-exploit dilemma, frontopolar cortex},
	file = {Snapshot:/Users/tito/Zotero/storage/7EDKAK5H/S0896-6273(22)00250-1.html:text/html},
}

@book{marr_vision_2010,
	title = {Vision: {A} computational investigation into the human representation and processing of visual information},
	shorttitle = {Vision},
	publisher = {MIT press},
	author = {Marr, David},
	year = {2010},
	file = {Snapshot:/Users/tito/Zotero/storage/DL94LQ24/books.html:text/html},
}

@article{abdollahi_correspondences_2014,
	title = {Correspondences between retinotopic areas and myelin maps in human visual cortex},
	volume = {99},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811914005199},
	doi = {10.1016/j.neuroimage.2014.06.042},
	abstract = {We generated probabilistic area maps and maximum probability maps (MPMs) for a set of 18 retinotopic areas previously mapped in individual subjects (Georgieva et al., 2009 and Kolster et al., 2010) using four different inter-subject registration methods. The best results were obtained using a recently developed multimodal surface matching method. The best set of MPMs had relatively smooth borders between visual areas and group average area sizes that matched the typical size in individual subjects. Comparisons between retinotopic areas and maps of estimated cortical myelin content revealed the following correspondences: (i) areas V1, V2, and V3 are heavily myelinated; (ii) the MT cluster is heavily myelinated, with a peak near the MT/pMSTv border; (iii) a dorsal myelin density peak corresponds to area V3D; (iv) the phPIT cluster is lightly myelinated; and (v) myelin density differs across the four areas of the V3A complex. Comparison of the retinotopic MPM with cytoarchitectonic areas, including those previously mapped to the fs\_LR cortical surface atlas, revealed a correspondence between areas V1–3 and hOc1–3, respectively, but little correspondence beyond V3. These results indicate that architectonic and retinotopic areal boundaries are in agreement in some regions, and that retinotopy provides a finer-grained parcellation in other regions. The atlas datasets from this analysis are freely available as a resource for other studies that will benefit from retinotopic and myelin density map landmarks in human visual cortex.},
	language = {en},
	urldate = {2022-04-19},
	journal = {NeuroImage},
	author = {Abdollahi, Rouhollah O. and Kolster, Hauke and Glasser, Matthew F. and Robinson, Emma C. and Coalson, Timothy S. and Dierker, Donna and Jenkinson, Mark and Van Essen, David C. and Orban, Guy A.},
	month = oct,
	year = {2014},
	pages = {509--524},
	file = {Abdollahi et al_2014_Correspondences between retinotopic areas and myelin maps in human visual cortex.pdf:/Users/tito/Zotero/storage/L2C2HE7J/Abdollahi et al_2014_Correspondences between retinotopic areas and myelin maps in human visual cortex.pdf:application/pdf},
}

@article{ruis_improving_2022,
	title = {Improving {Systematic} {Generalization} {Through} {Modularity} and {Augmentation}},
	url = {http://arxiv.org/abs/2202.10745},
	abstract = {Systematic generalization is the ability to combine known parts into novel meaning; an important aspect of efficient human learning, but a weakness of neural network learning. In this work, we investigate how two well-known modeling principles -- modularity and data augmentation -- affect systematic generalization of neural networks in grounded language learning. We analyze how large the vocabulary needs to be to achieve systematic generalization and how similar the augmented data needs to be to the problem at hand. Our findings show that even in the controlled setting of a synthetic benchmark, achieving systematic generalization remains very difficult. After training on an augmented dataset with almost forty times more adverbs than the original problem, a non-modular baseline is not able to systematically generalize to a novel combination of a known verb and adverb. When separating the task into cognitive processes like perception and navigation, a modular neural network is able to utilize the augmented data and generalize more systematically, achieving 70\% and 40\% exact match increase over state-of-the-art on two gSCAN tests that have not previously been improved. We hope that this work gives insight into the drivers of systematic generalization, and what we still need to improve for neural networks to learn more like humans do.},
	urldate = {2022-04-19},
	journal = {arXiv:2202.10745 [cs]},
	author = {Ruis, Laura and Lake, Brenden},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.10745},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/MS5FB2MH/2202.html:text/html;Ruis_Lake_2022_Improving Systematic Generalization Through Modularity and Augmentation.pdf:/Users/tito/Zotero/storage/9CTL7KIU/Ruis_Lake_2022_Improving Systematic Generalization Through Modularity and Augmentation.pdf:application/pdf},
}

@article{casper_frivolous_nodate,
	title = {Frivolous {Units}: {Wider} {Networks} {Are} {Not} {Really} {That} {Wide}},
	abstract = {A remarkable characteristic of overparameterized deep neural networks (DNNs) is that their accuracy does not degrade when the network’s width is increased. Recent evidence suggests that developing compressible representations is key for adjusting the complexity of large networks to the learning task at hand [3, 62, 52]. However, these compressible representations are poorly understood. A promising strand of research inspired from biology is understanding representations at the unit level as it offers a more granular and intuitive interpretation of the neural mechanisms. In order to better understand what facilitates increases in width without decreases in accuracy, we ask: Are there mechanisms at the unit level by which networks control their effective complexity as their width is increased? If so, how do these depend on the architecture, dataset, and training parameters? We identify two distinct types of “frivolous” units that proliferate when the network’s width is increased: prunable units which can be dropped out of the network without signiﬁcant change to the output and redundant units whose activities can be expressed as a linear combination of others. These units imply complexity constraints as the function the network represents could be expressed by a network without them. We also identify how the development of these units can be inﬂuenced by architecture and a number of training factors. Together, these results help to explain why the accuracy of DNNs does not degrade when width is increased and highlight the importance of frivolous units toward understanding implicit regularization in DNNs.},
	language = {en},
	author = {Casper, Stephen and Boix, Xavier and D’Amario, Vanessa and Guo, Ling and Schrimpf, Martin and Vinken, Kasper and Kreiman, Gabriel},
	pages = {18},
	file = {Casper et al. - Frivolous Units Wider Networks Are Not Really Tha.pdf:/Users/tito/Zotero/storage/QQKMG6UR/Casper et al. - Frivolous Units Wider Networks Are Not Really Tha.pdf:application/pdf},
}

@article{doimo_representation_2021,
	title = {Representation mitosis in wide neural networks},
	url = {http://arxiv.org/abs/2106.03485},
	abstract = {Deep neural networks (DNNs) defy the classical bias-variance trade-off: adding parameters to a DNN that interpolates its training data will typically improve its generalization performance. Explaining the mechanism behind this ``benign overfitting'' in deep networks remains an outstanding challenge. Here, we study the last hidden layer representations of various state-of-the-art convolutional neural networks and find evidence for an underlying mechanism that we call "representation mitosis": if the last hidden representation is wide enough, its neurons tend to split into groups which carry identical information, and differ from each other only by a statistically independent noise. Like in a mitosis process, the number of such groups, or ``clones'', increases linearly with the width of the layer, but only if the width is above a critical value. We show that a key ingredient to activate mitosis is continuing the training process until the training error is zero.},
	urldate = {2022-04-19},
	journal = {arXiv:2106.03485 [cs, stat]},
	author = {Doimo, Diego and Glielmo, Aldo and Goldt, Sebastian and Laio, Alessandro},
	month = oct,
	year = {2021},
	note = {arXiv: 2106.03485},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/G88F26WR/2106.html:text/html;Doimo et al_2021_Representation mitosis in wide neural networks.pdf:/Users/tito/Zotero/storage/K4NQTJ42/Doimo et al_2021_Representation mitosis in wide neural networks.pdf:application/pdf},
}

@article{agarwala_geometry_2021,
	title = {Geometry and {Generalization}: {Eigenvalues} as predictors of where a network will fail to generalize},
	shorttitle = {Geometry and {Generalization}},
	url = {http://arxiv.org/abs/2107.06386},
	abstract = {We study the deformation of the input space by a trained autoencoder via the Jacobians of the trained weight matrices. In doing so, we prove bounds for the mean squared errors for points in the input space, under assumptions regarding the orthogonality of the eigenvectors. We also show that the trace and the product of the eigenvalues of the Jacobian matrices is a good predictor of the MSE on test points. This is a dataset independent means of testing an autoencoder's ability to generalize on new input. Namely, no knowledge of the dataset on which the network was trained is needed, only the parameters of the trained model.},
	urldate = {2022-04-19},
	journal = {arXiv:2107.06386 [cs, math]},
	author = {Agarwala, Susama and Dees, Benjamin and Gearhart, Andrew and Lowman, Corey},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.06386},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Differential Geometry},
	file = {Agarwala et al_2021_Geometry and Generalization.pdf:/Users/tito/Zotero/storage/HMAEWPPD/Agarwala et al_2021_Geometry and Generalization.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/8AMH7XT3/2107.html:text/html},
}

@inproceedings{kornblith_why_2021,
	title = {Why {Do} {Better} {Loss} {Functions} {Lead} to {Less} {Transferable} {Features}?},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/f0bf4a2da952528910047c31b6c2e951-Abstract.html},
	abstract = {Previous work has proposed many new loss functions and regularizers that improve test accuracy on image classification tasks. However, it is not clear whether these loss functions learn better representations for downstream tasks. This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. We show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks, and the choice of loss has little effect when networks are fully fine-tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations of networks, we find that differences among loss functions are apparent only in the last few layers of the network. We delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. Representations with higher class separation obtain higher accuracy on the original task, but their features are less useful for downstream tasks. Our results suggest there exists a trade-off between learning invariant features for the original task and features relevant for transfer tasks.},
	urldate = {2022-04-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Kornblith, Simon and Chen, Ting and Lee, Honglak and Norouzi, Mohammad},
	year = {2021},
	pages = {28648--28662},
	file = {Kornblith et al_2021_Why Do Better Loss Functions Lead to Less Transferable Features.pdf:/Users/tito/Zotero/storage/I37EPBWX/Kornblith et al_2021_Why Do Better Loss Functions Lead to Less Transferable Features.pdf:application/pdf},
}

@inproceedings{birdal_intrinsic_2021,
	title = {Intrinsic {Dimension}, {Persistent} {Homology} and {Generalization} in {Neural} {Networks}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/35a12c43227f217207d4e06ffefe39d3-Abstract.html},
	abstract = {Disobeying the classical wisdom of statistical learning theory, modern deep neural networks generalize well even though they typically contain millions of parameters. Recently, it has been shown that the trajectories of iterative optimization algorithms can possess {\textbackslash}emph\{fractal structures\}, and their generalization error can be formally linked to the complexity of such fractals. This complexity is measured by the fractal's {\textbackslash}emph\{intrinsic dimension\}, a quantity usually much smaller than the number of parameters in the network. Even though this perspective provides an explanation for why overparametrized networks would not overfit, computing the intrinsic dimension ({\textbackslash}eg, for monitoring generalization during training) is a notoriously difficult task,  where existing methods typically fail even in moderate ambient dimensions. In this study, we consider this problem from the lens of topological data analysis (TDA) and develop a generic computational tool that is built on rigorous mathematical foundations. By making a novel connection between learning theory and TDA, we first illustrate that the generalization error can be equivalently bounded in terms of a notion called the 'persistent homology dimension' (PHD), where, compared with prior work, our approach does not require any additional geometrical or statistical assumptions on the training dynamics. Then, by utilizing recently established theoretical results and TDA tools, we develop an efficient algorithm to estimate PHD in the scale of modern deep neural networks and further provide visualization tools to help understand generalization in deep learning. Our experiments show that the proposed approach can efficiently compute a network's intrinsic dimension in a variety of settings, which is predictive of the generalization error.},
	urldate = {2022-04-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Birdal, Tolga and Lou, Aaron and Guibas, Leonidas J and Simsekli, Umut},
	year = {2021},
	pages = {6776--6789},
	file = {Birdal et al_2021_Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks.pdf:/Users/tito/Zotero/storage/CQSJHBBP/Birdal et al_2021_Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks.pdf:application/pdf},
}

@inproceedings{nassar_1n_2020,
	title = {On 1/n neural representation and robustness},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/44bf89b63173d40fb39f9842e308b3f9-Abstract.html},
	abstract = {Understanding the nature of representation in neural networks is a goal shared by neuroscience and machine learning.
It is therefore exciting that both fields converge not only on shared questions but also on similar approaches.
A pressing question in these areas is understanding how the structure of the representation used by neural networks affects both their generalization, and robustness to perturbations.
In this work, we investigate the latter by juxtaposing experimental results regarding the covariance spectrum of neural representations in the mouse V1 (Stringer et al) with artificial neural networks.
We use adversarial robustness to probe Stringer et al’s theory regarding the causal role of a 1/n covariance spectrum.
We empirically investigate the benefits such a neural code confers in neural networks, and illuminate its role in multi-layer architectures.
Our results show that imposing the experimentally observed structure on artificial neural networks makes them more robust to adversarial attacks.
Moreover, our findings complement the existing theory relating wide neural networks to kernel methods, by showing the role of intermediate representations.},
	urldate = {2022-04-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Nassar, Josue and Sokol, Piotr and Chung, Sueyeon and Harris, Kenneth D and Park, Il Memming},
	year = {2020},
	pages = {6211--6222},
	file = {Nassar et al_2020_On 1-n neural representation and robustness.pdf:/Users/tito/Zotero/storage/QHGRV6ER/Nassar et al_2020_On 1-n neural representation and robustness.pdf:application/pdf},
}

@article{siddiqi_causal_2022,
	title = {Causal mapping of human brain function},
	copyright = {2022 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-022-00583-8},
	doi = {10.1038/s41583-022-00583-8},
	abstract = {Mapping human brain function is a long-standing goal of neuroscience that promises to inform the development of new treatments for brain disorders. Early maps of human brain function were based on locations of brain damage or brain stimulation that caused a functional change. Over time, this approach was largely replaced by technologies such as functional neuroimaging, which identify brain regions in which activity is correlated with behaviours or symptoms. Despite their advantages, these technologies reveal correlations, not causation. This creates challenges for interpreting the data generated from these tools and using them to develop treatments for brain disorders. A return to causal mapping of human brain function based on brain lesions and brain stimulation is underway. New approaches can combine these causal sources of information with modern neuroimaging and electrophysiology techniques to gain new insights into the functions of specific brain areas. In this Review, we provide a definition of causality for translational research, propose a continuum along which to assess the relative strength of causal information from human brain mapping studies and discuss recent advances in causal brain mapping and their relevance for developing treatments.},
	language = {en},
	urldate = {2022-04-20},
	journal = {Nat Rev Neurosci},
	author = {Siddiqi, Shan H. and Kording, Konrad P. and Parvizi, Josef and Fox, Michael D.},
	month = apr,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Network models, Neural circuits},
	pages = {1--15},
	file = {Siddiqi et al_2022_Causal mapping of human brain function.pdf:/Users/tito/Zotero/storage/NCMURUHJ/Siddiqi et al_2022_Causal mapping of human brain function.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/3CEEVRKZ/s41583-022-00583-8.html:text/html},
}

@article{ke_learning_2022,
	title = {Learning to {Induce} {Causal} {Structure}},
	url = {http://arxiv.org/abs/2204.04875},
	abstract = {The fundamental challenge in causal induction is to infer the underlying graph structure given observational and/or interventional data. Most existing causal induction algorithms operate by generating candidate graphs and then evaluating them using either score-based methods (including continuous optimization) or independence tests. In this work, instead of proposing scoring function or independence tests, we treat the inference process as a black box and design a neural network architecture that learns the mapping from both observational and interventional data to graph structures via supervised training on synthetic graphs. We show that the proposed model generalizes not only to new synthetic graphs but also to naturalistic graphs.},
	urldate = {2022-04-20},
	journal = {arXiv:2204.04875 [cs, stat]},
	author = {Ke, Nan Rosemary and Chiappa, Silvia and Wang, Jane and Bornschein, Jorg and Weber, Theophane and Goyal, Anirudh and Botvinic, Matthew and Mozer, Michael and Rezende, Danilo Jimenez},
	month = apr,
	year = {2022},
	note = {arXiv: 2204.04875},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/VHVEYETB/2204.html:text/html;Ke et al_2022_Learning to Induce Causal Structure.pdf:/Users/tito/Zotero/storage/HJ65YP48/Ke et al_2022_Learning to Induce Causal Structure.pdf:application/pdf},
}

@article{vaidya_abstract_2022,
	title = {Abstract task representations for inference and control},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661322000675},
	doi = {10.1016/j.tics.2022.03.009},
	abstract = {Behavioral flexibility depends on our capacity to build and leverage abstract knowledge about tasks. Recently, two separate lines of research have implicated distinct brain networks in representing abstract task information: a frontoparietal cortical network, and a network involving the medial temporal lobe (MTL), medial prefrontal, and orbitofrontal cortex (OMPFC). These observations have mostly been made in parallel, with little attempt to understand their relationship. Here, we hypothesize that abstract task representations in these networks differ primarily in format, not content. Namely, that the MTL–OMPFC network maintains task knowledge in a flexible cognitive map, while the frontoparietal network formats this knowledge as productions that facilitate action selection. We discuss novel implications and predictions for behavioral flexibility arising from this hypothesis.},
	language = {en},
	urldate = {2022-04-26},
	journal = {Trends in Cognitive Sciences},
	author = {Vaidya, Avinash R. and Badre, David},
	month = apr,
	year = {2022},
	keywords = {orbitofrontal cortex, hippocampus, memory, learning, cognitive control, reinforcement learning, frontoparietal cortex, dorsolateral prefrontal cortex, inference, generalization, entorhinal cortex, decision-making, abstraction, behavioral flexibility, cognitive map, medial temporal lobe, production rule, rostrolateral prefrontal cortex, ventromedial prefrontal cortex},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/JQT5G3CQ/S1364661322000675.html:text/html;Vaidya_Badre_2022_Abstract task representations for inference and control.pdf:/Users/tito/Zotero/storage/AXXEM83B/Vaidya_Badre_2022_Abstract task representations for inference and control.pdf:application/pdf},
}

@article{jaeger_echo_2001,
	title = {The “echo state” approach to analysing and training recurrent neural networks-with an erratum note},
	volume = {148},
	number = {34},
	journal = {Bonn, Germany: German National Research Center for Information Technology GMD Technical Report},
	author = {Jaeger, Herbert},
	year = {2001},
	note = {Publisher: Bonn},
	pages = {13},
}

@article{zhi_evaluating_2022,
	title = {Evaluating brain parcellations using the distance-controlled boundary coefficient},
	volume = {n/a},
	issn = {1065-9471},
	url = {https://doi.org/10.1002/hbm.25878},
	doi = {10.1002/hbm.25878},
	abstract = {Abstract One important approach to human brain mapping is to define a set of distinct regions that can be linked to unique functions. Numerous brain parcellations have been proposed, using cytoarchitectonic, structural, or functional magnetic resonance imaging (fMRI) data. The intrinsic smoothness of brain data, however, poses a problem for current methods seeking to compare different parcellations. For example, criteria that simply compare within-parcel to between-parcel similarity provide even random parcellations with a high value. Furthermore, the evaluation is biased by the spatial scale of the parcellation. To address this problem, we propose the distance-controlled boundary coefficient (DCBC), an unbiased criterion to evaluate discrete parcellations. We employ this new criterion to evaluate existing parcellations of the human neocortex in their power to predict functional boundaries for an fMRI data set with many different tasks, as well as for resting-state data. We find that common anatomical parcellations do not perform better than chance, suggesting that task-based functional boundaries do not align well with sulcal landmarks. Parcellations based on resting-state fMRI data perform well; in some cases, as well as a parcellation defined on the evaluation data itself. Finally, multi-modal parcellations that combine functional and anatomical criteria perform substantially worse than those based on functional data alone, indicating that functionally homogeneous regions often span major anatomical landmarks. Overall, the DCBC advances the field of functional brain mapping by providing an unbiased metric that compares the predictive ability of different brain parcellations to define brain regions that are functionally maximally distinct.},
	number = {n/a},
	urldate = {2022-04-27},
	journal = {Human Brain Mapping},
	author = {Zhi, Da and King, Maedbh and Hernandez-Castillo, Carlos R. and Diedrichsen, Jörn},
	month = apr,
	year = {2022},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {brain parcellation, parcellation evaluation criterion, resting-state connectivity, task-evoked functional MRI},
	annote = {https://doi.org/10.1002/hbm.25878},
	file = {Zhi et al_2022_Evaluating brain parcellations using the distance-controlled boundary.pdf:/Users/tito/Zotero/storage/V6A24SK7/Zhi et al_2022_Evaluating brain parcellations using the distance-controlled boundary.pdf:application/pdf},
}

@article{lu_neural_2022,
	title = {A neural network model of when to retrieve and encode episodic memories},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.74445},
	doi = {10.7554/eLife.74445},
	abstract = {Recent human behavioral and neuroimaging results suggest that people are selective in when they encode and retrieve episodic memories. To explain these findings, we trained a memory-augmented neural network to use its episodic memory to support prediction of upcoming states in an environment where past situations sometimes reoccur. We found that the network learned to retrieve selectively as a function of several factors, including its uncertainty about the upcoming state. Additionally, we found that selectively encoding episodic memories at the end of an event (but not mid-event) led to better subsequent prediction performance. In all of these cases, the benefits of selective retrieval and encoding can be explained in terms of reducing the risk of retrieving irrelevant memories. Overall, these modeling results provide a resource-rational account of why episodic retrieval and encoding should be selective and lead to several testable predictions.},
	urldate = {2022-04-28},
	journal = {eLife},
	author = {Lu, Qihong and Hasson, Uri and Norman, Kenneth A},
	editor = {Badre, David and Frank, Michael J and Rogers, Tim and Hasselmo, Michael E},
	month = feb,
	year = {2022},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {neural network, episodic memory, event cognition},
	pages = {e74445},
	file = {Lu et al_2022_A neural network model of when to retrieve and encode episodic memories.pdf:/Users/tito/Zotero/storage/QEEHAUAI/Lu et al_2022_A neural network model of when to retrieve and encode episodic memories.pdf:application/pdf},
}

@article{baggio_compositionality_2021,
	title = {Compositionality in a {Parallel} {Architecture} for {Language} {Processing}},
	volume = {45},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12949},
	doi = {10.1111/cogs.12949},
	abstract = {Compositionality has been a central concept in linguistics and philosophy for decades, and it is increasingly prominent in many other areas of cognitive science. Its status, however, remains contentious. Here, I reassess the nature and scope of the principle of compositionality (Partee, 1995) from the perspective of psycholinguistics and cognitive neuroscience. First, I review classic arguments for compositionality and conclude that they fail to establish compositionality as a property of human language. Next, I state a new competence argument, acknowledging the fact that any competent user of a language L can assign to most expressions in L at least one meaning which is a function only of the meanings of the expression's parts and of its syntactic structure. I then discuss selected results from cognitive neuroscience, indicating that the human brain possesses the processing capacities presupposed by the competence argument. Finally, I outline a language processing architecture consistent with the neuroscience results, where semantic representations may be generated by a syntax-driven stream and by an “asyntactic” processing stream, jointly or independently. Compositionality is viewed as a constraint on computation in the former stream only.},
	language = {en},
	number = {5},
	urldate = {2022-04-29},
	journal = {Cognitive Science},
	author = {Baggio, Giosuè},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12949},
	keywords = {Semantics, Compositionality, Language processing, Parallel architecture, Syntax},
	pages = {e12949},
	file = {Baggio_2021_Compositionality in a Parallel Architecture for Language Processing.pdf:/Users/tito/Zotero/storage/6E3EL632/Baggio_2021_Compositionality in a Parallel Architecture for Language Processing.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/DSLXRN3H/cogs.html:text/html},
}

@article{hogeveen_neurocomputational_2022-1,
	title = {The neurocomputational bases of explore-exploit decision-making},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627322002501},
	doi = {10.1016/j.neuron.2022.03.014},
	abstract = {Flexible decision-making requires animals to forego immediate rewards (exploitation) and try novel choice options (exploration) to discover if they are preferable to familiar alternatives. Using the same task and a partially observable Markov decision process (POMDP) model to quantify the value of choices, we first determined that the computational basis for managing explore-exploit tradeoffs is conserved across monkeys and humans. We then used fMRI to identify where in the human brain the immediate value of exploitative choices and relative uncertainty about the value of exploratory choices were encoded. Consistent with prior neurophysiological evidence in monkeys, we observed divergent encoding of reward value and uncertainty in prefrontal and parietal regions, including frontopolar cortex, and parallel encoding of these computations in motivational regions including the amygdala, ventral striatum, and orbitofrontal cortex. These results clarify the interplay between prefrontal and motivational circuits that supports adaptive explore-exploit decisions in humans and nonhuman primates.},
	language = {en},
	urldate = {2022-05-03},
	journal = {Neuron},
	author = {Hogeveen, Jeremy and Mullins, Teagan S. and Romero, John D. and Eversole, Elizabeth and Rogge-Obando, Kimberly and Mayer, Andrew R. and Costa, Vincent D.},
	month = apr,
	year = {2022},
	keywords = {fMRI, computational modeling, reinforcement learning, striatum, exploration, reward, amygdala, decision-making, explore-exploit dilemma, frontopolar cortex},
	file = {Hogeveen et al_2022_The neurocomputational bases of explore-exploit decision-making.pdf:/Users/tito/Zotero/storage/3A25QFLW/Hogeveen et al_2022_The neurocomputational bases of explore-exploit decision-making.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/JHEIQI2Y/S0896627322002501.html:text/html},
}

@article{smolensky_neurocompositional_2022,
	title = {Neurocompositional computing in human and machine intelligence: {A} tutorial},
	shorttitle = {Neurocompositional computing in human and machine intelligence},
	url = {https://www.microsoft.com/en-us/research/publication/neurocompositional-computing-in-human-and-machine-intelligence-a-tutorial/},
	abstract = {We argue that the unprecedented progress of 21st-century AI has resulted from the use of limited—first-generation—forms of what we call neurocompositional computing. We show that the new techniques now being deployed in second-generation neurocompositional computing create AI systems that are not only more robust and accurate than current systems, but also more comprehensible—making it possible to diagnose errors in, and exert human control over, artificial neural networks through interpretation of their internal states and direct intervention upon those states.},
	language = {en-US},
	urldate = {2022-05-05},
	author = {Smolensky, Paul and McCoy, R. Thomas and Fernandez, Roland and Goldrick, Matthew and Gao, Jianfeng},
	month = may,
	year = {2022},
	file = {Smolensky et al_2022_Neurocompositional computing in human and machine intelligence.pdf:/Users/tito/Zotero/storage/YPQRFHD6/Smolensky et al_2022_Neurocompositional computing in human and machine intelligence.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/S82AQUX6/neurocompositional-computing-in-human-and-machine-intelligence-a-tutorial.html:text/html},
}

@article{smolensky_neurocompositional_2022-1,
	title = {Neurocompositional computing: {From} the {Central} {Paradox} of {Cognition} to a new generation of {AI} systems},
	shorttitle = {Neurocompositional computing},
	url = {http://arxiv.org/abs/2205.01128},
	abstract = {What explains the dramatic progress from 20th-century to 21st-century AI, and how can the remaining limitations of current AI be overcome? The widely accepted narrative attributes this progress to massive increases in the quantity of computational and data resources available to support statistical learning in deep artificial neural networks. We show that an additional crucial factor is the development of a new type of computation. Neurocompositional computing adopts two principles that must be simultaneously respected to enable human-level cognition: the principles of Compositionality and Continuity. These have seemed irreconcilable until the recent mathematical discovery that compositionality can be realized not only through discrete methods of symbolic computing, but also through novel forms of continuous neural computing. The revolutionary recent progress in AI has resulted from the use of limited forms of neurocompositional computing. New, deeper forms of neurocompositional computing create AI systems that are more robust, accurate, and comprehensible.},
	urldate = {2022-05-05},
	journal = {arXiv:2205.01128 [cs]},
	author = {Smolensky, Paul and McCoy, R. Thomas and Fernandez, Roland and Goldrick, Matthew and Gao, Jianfeng},
	month = may,
	year = {2022},
	note = {arXiv: 2205.01128},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Symbolic Computation},
	annote = {Comment: 21 pages, 6 figures. For a general AI audience: to appear in AI Magazine. A more extensive presentation of this work is "Neurocompositional computing in human and machine intelligence: A tutorial", Microsoft Technical Report MSR-TR-2022-5; see https://www.microsoft.com/en-us/research/publication/neurocompositional-computing-in-human-and-machine-intelligence-a-tutorial/},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/4LIXHK7N/2205.html:text/html;Smolensky et al_2022_Neurocompositional computing.pdf:/Users/tito/Zotero/storage/QXBX2XBH/Smolensky et al_2022_Neurocompositional computing.pdf:application/pdf},
}

@article{hill_environmental_2020,
	title = {Environmental drivers of systematicity and generalization in a situated agent},
	url = {http://arxiv.org/abs/1910.00571},
	abstract = {The question of whether deep neural networks are good at generalising beyond their immediate training experience is of critical importance for learning-based approaches to AI. Here, we consider tests of out-of-sample generalisation that require an agent to respond to never-seen-before instructions by manipulating and positioning objects in a 3D Unity simulated room. We first describe a comparatively generic agent architecture that exhibits strong performance on these tests. We then identify three aspects of the training regime and environment that make a significant difference to its performance: (a) the number of object/word experiences in the training set; (b) the visual invariances afforded by the agent's perspective, or frame of reference; and (c) the variety of visual input inherent in the perceptual aspect of the agent's perception. Our findings indicate that the degree of generalisation that networks exhibit can depend critically on particulars of the environment in which a given task is instantiated. They further suggest that the propensity for neural networks to generalise in systematic ways may increase if, like human children, those networks have access to many frames of richly varying, multi-modal observations as they learn.},
	urldate = {2022-05-09},
	journal = {arXiv:1910.00571 [cs]},
	author = {Hill, Felix and Lampinen, Andrew and Schneider, Rosalia and Clark, Stephen and Botvinick, Matthew and McClelland, James L. and Santoro, Adam},
	month = feb,
	year = {2020},
	note = {arXiv: 1910.00571},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/G6XLPQ2A/1910.html:text/html;Hill et al_2020_Environmental drivers of systematicity and generalization in a situated agent.pdf:/Users/tito/Zotero/storage/BJZ34KSA/Hill et al_2020_Environmental drivers of systematicity and generalization in a situated agent.pdf:application/pdf},
}

@article{lampinen_transforming_2020,
	title = {Transforming task representations to perform novel tasks},
	volume = {117},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.2008852117},
	doi = {10.1073/pnas.2008852117},
	number = {52},
	urldate = {2022-05-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Lampinen, Andrew K. and McClelland, James L.},
	month = dec,
	year = {2020},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {32970--32981},
	file = {Lampinen_McClelland_2020_Transforming task representations to perform novel tasks.pdf:/Users/tito/Zotero/storage/IJTPJMN4/Lampinen_McClelland_2020_Transforming task representations to perform novel tasks.pdf:application/pdf},
}

@article{palombit_variability_2022,
	title = {Variability of regional glucose metabolism and the topology of functional networks in the human brain},
	volume = {257},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811922004013},
	doi = {10.1016/j.neuroimage.2022.119280},
	abstract = {The brain consumes the most energy per relative mass amongst the organs in the human body. Theoretical and empirical studies have shown that behavioral processes are relatively inexpensive metabolically, and that most energy goes to maintaining the status quo, i.e., the balance of cell membranes’ resting potentials and subthreshold spontaneous activity. Spontaneous activity fluctuates across brain regions in a correlated fashion that defines multi-scale hierarchical networks called resting-state networks (RSNs). Different regions of the brain display different metabolic consumption, but the relationship between regional brain metabolism and RSNs is still under investigation. Here, we examine the variability of glucose metabolism across brain regions, measured with the relative standard uptake value (SUVR) using 18F-FDG PET, and the topology of RSNs, measured through graph analysis applied to fMRI resting-state functional connectivity (FC). We found a moderate linear relationship between the strength (STR) of pairwise regional FC and metabolism. Moreover, the linear correlation between SUVR and STR grew stronger as we considered more connected regions (hubs). Regions connecting different RSNs, or connector hubs, showed higher SUVR than regions connecting nodes within the same RSN, or provincial hubs. Our results show that functional connections as probed by fMRI are related to glucose metabolism, especially in a system of provincial and connector hubs.},
	language = {en},
	urldate = {2022-05-10},
	journal = {NeuroImage},
	author = {Palombit, Alessandro and Silvestri, Erica and Volpi, Tommaso and Aiello, Marco and Cecchin, Diego and Bertoldo, Alessandra and Corbetta, Maurizio},
	month = aug,
	year = {2022},
	keywords = {Brain networks, Resting state, Brain metabolism, F-FDG, Functional connectivity (FC), Hubs},
	pages = {119280},
	file = {Palombit et al_2022_Variability of regional glucose metabolism and the topology of functional.pdf:/Users/tito/Zotero/storage/43SJY4QD/Palombit et al_2022_Variability of regional glucose metabolism and the topology of functional.pdf:application/pdf},
}

@article{fu_geometry_2022,
	title = {The geometry of domain-general performance monitoring in the human medial frontal cortex},
	volume = {376},
	url = {https://www.science.org/doi/10.1126/science.abm9922},
	doi = {10.1126/science.abm9922},
	number = {6593},
	urldate = {2022-05-12},
	journal = {Science},
	author = {Fu, Zhongzheng and Beam, Danielle and Chung, Jeffrey M. and Reed, Chrystal M. and Mamelak, Adam N. and Adolphs, Ralph and Rutishauser, Ueli},
	month = may,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eabm9922},
	file = {Fu et al_2022_The geometry of domain-general performance monitoring in the human medial.pdf:/Users/tito/Zotero/storage/KWCYCQ79/Fu et al_2022_The geometry of domain-general performance monitoring in the human medial.pdf:application/pdf},
}

@article{higgins_beta-vae_2016,
	title = {beta-{VAE}: {Learning} {Basic} {Visual} {Concepts} with a {Constrained} {Variational} {Framework}},
	shorttitle = {beta-{VAE}},
	url = {https://openreview.net/forum?id=Sy2fzU9gl},
	abstract = {We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner.},
	language = {en},
	urldate = {2022-05-13},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	month = nov,
	year = {2016},
	file = {Higgins et al_2016_beta-VAE.pdf:/Users/tito/Zotero/storage/RK7EEPLC/Higgins et al_2016_beta-VAE.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/Z5JKBR28/forum.html:text/html},
}

@inproceedings{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	volume = {26},
	url = {https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships.  In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly.  We show that by subsampling frequent words we obtain significant speedup,  and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax.   An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases.  For example, the meanings of Canada'' and "Air'' cannot be easily combined to obtain "Air Canada''.  Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model. "},
	urldate = {2022-05-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	year = {2013},
	file = {Mikolov et al_2013_Distributed Representations of Words and Phrases and their Compositionality.pdf:/Users/tito/Zotero/storage/GRXZBIJL/Mikolov et al_2013_Distributed Representations of Words and Phrases and their Compositionality.pdf:application/pdf},
}

@article{luppi_synergistic_2022,
	title = {A synergistic core for human brain evolution and cognition},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-022-01070-0},
	doi = {10.1038/s41593-022-01070-0},
	abstract = {How does the organization of neural information processing enable humans’ sophisticated cognition? Here we decompose functional interactions between brain regions into synergistic and redundant components, revealing their distinct information-processing roles. Combining functional and structural neuroimaging with meta-analytic results, we demonstrate that redundant interactions are predominantly associated with structurally coupled, modular sensorimotor processing. Synergistic interactions instead support integrative processes and complex cognition across higher-order brain networks. The human brain leverages synergistic information to a greater extent than nonhuman primates, with high-synergy association cortices exhibiting the highest degree of evolutionary cortical expansion. Synaptic density mapping from positron emission tomography and convergent molecular and metabolic evidence demonstrate that synergistic interactions are supported by receptor diversity and human-accelerated genes underpinning synaptic function. This information-resolved approach provides analytic tools to disentangle information integration from coupling, enabling richer, more accurate interpretations of functional connectivity, and illuminating how the human neurocognitive architecture navigates the trade-off between robustness and integration.},
	language = {en},
	urldate = {2022-05-26},
	journal = {Nat Neurosci},
	author = {Luppi, Andrea I. and Mediano, Pedro A. M. and Rosas, Fernando E. and Holland, Negin and Fryer, Tim D. and O’Brien, John T. and Rowe, James B. and Menon, David K. and Bor, Daniel and Stamatakis, Emmanuel A.},
	month = may,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Dynamical systems, Cognitive control, Network models, Genetics of the nervous system},
	pages = {1--12},
	file = {Luppi et al_2022_A synergistic core for human brain evolution and cognition.pdf:/Users/tito/Zotero/storage/7ZM288WS/Luppi et al_2022_A synergistic core for human brain evolution and cognition.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/LDIEUWXT/s41593-022-01070-0.html:text/html},
}

@article{cole_functional_2016-1,
	title = {Functional connectivity change as shared signal dynamics},
	volume = {259},
	issn = {0165-0270},
	url = {https://www.sciencedirect.com/science/article/pii/S0165027015004136},
	doi = {10.1016/j.jneumeth.2015.11.011},
	abstract = {Background
An increasing number of neuroscientific studies gain insights by focusing on differences in functional connectivity—between groups, individuals, temporal windows, or task conditions. We found using simulations that additional insights into such differences can be gained by forgoing variance normalization, a procedure used by most functional connectivity measures. Simulations indicated that these functional connectivity measures are sensitive to increases in independent fluctuations (unshared signal) in time series, consistently reducing functional connectivity estimates (e.g., correlations) even though such changes are unrelated to corresponding fluctuations (shared signal) between those time series. This is inconsistent with the common notion of functional connectivity as the amount of inter-region interaction.
New method
Simulations revealed that a version of correlation without variance normalization – covariance – was able to isolate differences in shared signal, increasing interpretability of observed functional connectivity change. Simulations also revealed cases problematic for non-normalized methods, leading to a “covariance conjunction” method combining the benefits of both normalized and non-normalized approaches.
Results
We found that covariance and covariance conjunction methods can detect functional connectivity changes across a variety of tasks and rest in both clinical and non-clinical functional MRI datasets.
Comparison with existing method(s)
We verified using a variety of tasks and rest in both clinical and non-clinical functional MRI datasets that it matters in practice whether correlation, covariance, or covariance conjunction methods are used.
Conclusions
These results demonstrate the practical and theoretical utility of isolating changes in shared signal, improving the ability to interpret observed functional connectivity change.},
	language = {en},
	urldate = {2022-06-01},
	journal = {Journal of Neuroscience Methods},
	author = {Cole, Michael W. and Yang, Genevieve J. and Murray, John D. and Repovš, Grega and Anticevic, Alan},
	month = feb,
	year = {2016},
	keywords = {Functional MRI, Resting-state functional connectivity, Functional connectivity, Schizophrenia, Task functional connectivity},
	pages = {22--39},
	file = {1-s2.0-S0165027015004136-main.pdf:/Users/tito/Zotero/storage/V6JK88JF/1-s2.0-S0165027015004136-main.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/DCICILJZ/S0165027015004136.html:text/html},
}

@article{dubreuil_role_2022,
	title = {The role of population structure in computations through neural dynamics},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-022-01088-4},
	doi = {10.1038/s41593-022-01088-4},
	abstract = {Neural computations are currently investigated using two separate approaches: sorting neurons into functional subpopulations or examining the low-dimensional dynamics of collective activity. Whether and how these two aspects interact to shape computations is currently unclear. Using a novel approach to extract computational mechanisms from networks trained on neuroscience tasks, here we show that the dimensionality of the dynamics and subpopulation structure play fundamentally complementary roles. Although various tasks can be implemented by increasing the dimensionality in networks with fully random population structure, flexible input–output mappings instead require a non-random population structure that can be described in terms of multiple subpopulations. Our analyses revealed that such a subpopulation structure enables flexible computations through a mechanism based on gain-controlled modulations that flexibly shape the collective dynamics. Our results lead to task-specific predictions for the structure of neural selectivity, for inactivation experiments and for the implication of different neurons in multi-tasking.},
	language = {en},
	urldate = {2022-06-06},
	journal = {Nat Neurosci},
	author = {Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
	month = jun,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Dynamical systems, Network models},
	pages = {1--12},
	file = {Dubreuil et al_2022_The role of population structure in computations through neural dynamics.pdf:/Users/tito/Zotero/storage/45D68PPW/Dubreuil et al_2022_The role of population structure in computations through neural dynamics.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/PZUZTZ6P/s41593-022-01088-4.html:text/html},
}

@article{naumann_invariant_2022,
	title = {Invariant neural subspaces maintained by feedback modulation},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.76096},
	doi = {10.7554/eLife.76096},
	abstract = {Sensory systems reliably process incoming stimuli in spite of changes in context. Most recent models accredit this context invariance to an extraction of increasingly complex sensory features in hierarchical feedforward networks. Here, we study how context-invariant representations can be established by feedback rather than feedforward processing. We show that feedforward neural networks modulated by feedback can dynamically generate invariant sensory representations. The required feedback can be implemented as a slow and spatially diffuse gain modulation. The invariance is not present on the level of individual neurons, but emerges only on the population level. Mechanistically, the feedback modulation dynamically reorients the manifold of neural activity and thereby maintains an invariant neural subspace in spite of contextual variations. Our results highlight the importance of population-level analyses for understanding the role of feedback in flexible sensory processing.},
	urldate = {2022-06-06},
	journal = {eLife},
	author = {Naumann, Laura B and Keijser, Joram and Sprekeler, Henning},
	editor = {Ostojic, Srdjan and King, Andrew J},
	month = apr,
	year = {2022},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {sensory processing, feedback, blind source separation, gain modulation, invariance, population analyses},
	pages = {e76096},
	file = {Naumann et al_2022_Invariant neural subspaces maintained by feedback modulation.pdf:/Users/tito/Zotero/storage/6EYBMN8Q/Naumann et al_2022_Invariant neural subspaces maintained by feedback modulation.pdf:application/pdf},
}

@article{oldham_modeling_2022,
	title = {Modeling spatial, developmental, physiological, and topological constraints on human brain connectivity},
	volume = {8},
	url = {https://www.science.org/doi/10.1126/sciadv.abm6127},
	doi = {10.1126/sciadv.abm6127},
	number = {22},
	urldate = {2022-06-06},
	journal = {Science Advances},
	author = {Oldham, Stuart and Fulcher, Ben D. and Aquino, Kevin and Arnatkevičiūtė, Aurina and Paquola, Casey and Shishegar, Rosita and Fornito, Alex},
	month = jun,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eabm6127},
	file = {Oldham et al_2022_Modeling spatial, developmental, physiological, and topological constraints on.pdf:/Users/tito/Zotero/storage/456PGYP4/Oldham et al_2022_Modeling spatial, developmental, physiological, and topological constraints on.pdf:application/pdf},
}

@techreport{ji_qunex_2022,
	title = {{QuNex} – {An} {Integrative} {Platform} for {Reproducible} {Neuroimaging} {Analytics}},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2022.06.03.494750v1},
	abstract = {Neuroimaging technology has experienced explosive growth and has transformed the study of neural mechanisms across health and disease. However, given the diversity of sophisticated tools for handling neuroimaging data, the field faces challenges around method integration (1-3). Specifically, researchers often have to rely on siloed approaches which limit reproducibility, with idiosyncratic data organization and limited software interoperability. To address these challenges, we developed Quantitative Neuroimaging Environment \& Toolbox (QuNex), a platform for consistent end-to-end processing and analytics. QuNex is engineered for reproducible deployment of custom workflows, from onboarding raw data to generating analytic features, in a single "turnkey" command. The platform enables inter-operable integration of multi-modal, community-developed neuroimaging software through an extension framework with a software development kit for seamless integration of community tools. Critically, it supports high-throughput, parallel processing in high-performance compute environments, either locally or in the cloud. Notably, QuNex has successfully processed over 10,000 scans across neuroimaging consortia (4), including multiple clinical datasets. Moreover, QuNex enables integration of non-human primate, rodent, and human workflows via a cohesive translational platform. Collectively, this effort stands to significantly impact neuroimaging method integration across acquisition approaches, pipelines, datasets, computational environments, and species. Building on this platform will enable more rapid, scalable, and reproducible impact of neuroimaging technology across health and disease.},
	language = {en},
	urldate = {2022-06-07},
	institution = {bioRxiv},
	author = {Ji, Jie Lisa and Demšar, Jure and Fonteneau, Clara and Tamayo, Zailyn and Pan, Lining and Kraljič, Aleksij and Matkovič, Andraž and Purg, Nina and Helmer, Markus and Warrington, Shaun and Harms, Michael and Sotiropoulos, Stamatios N. and Murray, John D. and Anticevic, Alan and Repovš, Grega},
	month = jun,
	year = {2022},
	doi = {10.1101/2022.06.03.494750},
	note = {Section: New Results
Type: article},
	pages = {2022.06.03.494750},
	file = {Ji et al_2022_QuNex – An Integrative Platform for Reproducible Neuroimaging Analytics.pdf:/Users/tito/Zotero/storage/MRAPVU99/Ji et al_2022_QuNex – An Integrative Platform for Reproducible Neuroimaging Analytics.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/P5KJENBW/2022.06.03.html:text/html},
}

@article{ni_general_2022,
	title = {A general decoding strategy explains the relationship between behavior and correlated variability},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.67258},
	doi = {10.7554/eLife.67258},
	abstract = {Improvements in perception are frequently accompanied by decreases in correlated variability in sensory cortex. This relationship is puzzling because overall changes in correlated variability should minimally affect optimal information coding. We hypothesize that this relationship arises because instead of using optimal strategies for decoding the specific stimuli at hand, observers prioritize generality: a single set of neuronal weights to decode any stimuli. We tested this using a combination of multineuron recordings in the visual cortex of behaving rhesus monkeys and a cortical circuit model. We found that general decoders optimized for broad rather than narrow sets of visual stimuli better matched the animals’ decoding strategy, and that their performance was more related to the magnitude of correlated variability. In conclusion, the inverse relationship between perceptual performance and correlated variability can be explained by observers using a general decoding strategy, capable of decoding neuronal responses to the variety of stimuli encountered in natural vision.},
	urldate = {2022-06-07},
	journal = {eLife},
	author = {Ni, Amy M and Huang, Chengcheng and Doiron, Brent and Cohen, Marlene R},
	editor = {Ostojic, Srdjan and Moore, Tirin},
	month = jun,
	year = {2022},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {noise correlations, perception, visual attention, neural coding},
	pages = {e67258},
	file = {Ni et al_2022_A general decoding strategy explains the relationship between behavior and.pdf:/Users/tito/Zotero/storage/VEF9EV5A/Ni et al_2022_A general decoding strategy explains the relationship between behavior and.pdf:application/pdf},
}

@article{suhaimi_representation_2022,
	title = {Representation learning in the artificial and biological neural networks underlying sensorimotor integration},
	volume = {8},
	url = {https://www.science.org/doi/10.1126/sciadv.abn0984},
	doi = {10.1126/sciadv.abn0984},
	number = {22},
	urldate = {2022-06-13},
	journal = {Science Advances},
	author = {Suhaimi, Ahmad and Lim, Amos W. H. and Chia, Xin Wei and Li, Chunyue and Makino, Hiroshi},
	month = jun,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eabn0984},
	file = {Suhaimi et al_2022_Representation learning in the artificial and biological neural networks.pdf:/Users/tito/Zotero/storage/E2C2ULJJ/Suhaimi et al_2022_Representation learning in the artificial and biological neural networks.pdf:application/pdf},
}

@article{javadzadeh_dynamic_2022,
	title = {Dynamic causal communication channels between neocortical areas},
	volume = {0},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(22)00452-4},
	doi = {10.1016/j.neuron.2022.05.011},
	language = {English},
	number = {0},
	urldate = {2022-06-13},
	journal = {Neuron},
	author = {Javadzadeh, Mitra and Hofer, Sonja B.},
	month = jun,
	year = {2022},
	note = {Publisher: Elsevier},
	keywords = {visual cortex, inter-areal communication, causal manipulation, communication subspace, neocortical interactions, population activity dynamics, visual processing},
	file = {Javadzadeh_Hofer_2022_Dynamic causal communication channels between neocortical areas.pdf:/Users/tito/Zotero/storage/YUC5L2BH/Javadzadeh_Hofer_2022_Dynamic causal communication channels between neocortical areas.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/RE86PG5W/S0896-6273(22)00452-4.html:text/html},
}

@article{rmus_role_2021,
	series = {Computational cognitive neuroscience},
	title = {The role of executive function in shaping reinforcement learning},
	volume = {38},
	issn = {2352-1546},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154620301480},
	doi = {10.1016/j.cobeha.2020.10.003},
	abstract = {Reinforcement learning (RL) models have advanced our understanding of how animals learn and make decisions, and how the brain supports learning. However, the neural computations that are explained by RL algorithms fall short of explaining many sophisticated aspects of human learning and decision making, including the generalization of behavior to novel contexts, one-shot learning, and the synthesis of task information in complex environments. Instead, these aspects of behavior are assumed to be supported by the brain’s executive functions (EF). We review recent findings that highlight the importance of EF in instrumental learning. Specifically, we advance the theory that EF sets the stage for canonical RL computations in the brain, providing inputs that broaden their flexibility and applicability. Our theory has important implications for how to interpret RL computations in both brain and behavior.},
	language = {en},
	urldate = {2022-06-14},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Rmus, Milena and McDougle, Samuel D and Collins, Anne GE},
	month = apr,
	year = {2021},
	pages = {66--73},
	file = {Rmus et al_2021_The role of executive function in shaping reinforcement learning.pdf:/Users/tito/Zotero/storage/ZXB8HVTC/Rmus et al_2021_The role of executive function in shaping reinforcement learning.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/QCSR6R63/S2352154620301480.html:text/html},
}

@misc{raffel_exploring_2020,
	title = {Exploring the {Limits} of {Transfer} {Learning} with a {Unified} {Text}-to-{Text} {Transformer}},
	url = {http://arxiv.org/abs/1910.10683},
	doi = {10.48550/arXiv.1910.10683},
	abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.},
	urldate = {2022-06-15},
	publisher = {arXiv},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
	month = jul,
	year = {2020},
	note = {arXiv:1910.10683 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: Final version as published in JMLR},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/9KLSXNMR/1910.html:text/html;Raffel et al_2020_Exploring the Limits of Transfer Learning with a Unified Text-to-Text.pdf:/Users/tito/Zotero/storage/8FGUHFKY/Raffel et al_2020_Exploring the Limits of Transfer Learning with a Unified Text-to-Text.pdf:application/pdf},
}

@article{panzeri_structures_2022,
	title = {The structures and functions of correlations in neural population codes},
	copyright = {2022 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-022-00606-4},
	doi = {10.1038/s41583-022-00606-4},
	abstract = {The collective activity of a population of neurons, beyond the properties of individual cells, is crucial for many brain functions. A fundamental question is how activity correlations between neurons affect how neural populations process information. Over the past 30 years, major progress has been made on how the levels and structures of correlations shape the encoding of information in population codes. Correlations influence population coding through the organization of pairwise-activity correlations with respect to the similarity of tuning of individual neurons, by their stimulus modulation and by the presence of higher-order correlations. Recent work has shown that correlations also profoundly shape other important functions performed by neural populations, including generating codes across multiple timescales and facilitating information transmission to, and readout by, downstream brain areas to guide behaviour. Here, we review this recent work and discuss how the structures of correlations can have opposite effects on the different functions of neural populations, thus creating trade-offs and constraints for the structure–function relationships of population codes. Further, we present ideas on how to combine large-scale simultaneous recordings of neural populations, computational models, analyses of behaviour, optogenetics and anatomy to unravel how the structures of correlations might be optimized to serve multiple functions.},
	language = {en},
	urldate = {2022-06-27},
	journal = {Nat Rev Neurosci},
	author = {Panzeri, Stefano and Moroni, Monica and Safaai, Houman and Harvey, Christopher D.},
	month = jun,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Sensory processing, Neural decoding},
	pages = {1--17},
	file = {Panzeri et al_2022_The structures and functions of correlations in neural population codes.pdf:/Users/tito/Zotero/storage/62LUBXHA/Panzeri et al_2022_The structures and functions of correlations in neural population codes.pdf:application/pdf},
}

@article{farrell_gradient-based_2022,
	title = {Gradient-based learning drives robust representations in recurrent neural networks by balancing compression and expansion},
	volume = {4},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00498-0},
	doi = {10.1038/s42256-022-00498-0},
	abstract = {Neural networks need the right representations of input data to learn. Here we ask how gradient-based learning shapes a fundamental property of representations in recurrent neural networks (RNNs)—their dimensionality. Through simulations and mathematical analysis, we show how gradient descent can lead RNNs to compress the dimensionality of their representations in a way that matches task demands during training while supporting generalization to unseen examples. This can require an expansion of dimensionality in early timesteps and compression in later ones, and strongly chaotic RNNs appear particularly adept at learning this balance. Beyond helping to elucidate the power of appropriately initialized artificial RNNs, this fact has implications for neurobiology as well. Neural circuits in the brain reveal both high variability associated with chaos and low-dimensional dynamical structures. Taken together, our findings show how simple gradient-based learning rules lead neural networks to solve tasks with robust representations that generalize to new cases.},
	language = {en},
	number = {6},
	urldate = {2022-06-27},
	journal = {Nat Mach Intell},
	author = {Farrell, Matthew and Recanatesi, Stefano and Moore, Timothy and Lajoie, Guillaume and Shea-Brown, Eric},
	month = jun,
	year = {2022},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Dynamical systems, Network models, Learning algorithms},
	pages = {564--573},
	file = {Farrell et al_2022_Gradient-based learning drives robust representations in recurrent neural.pdf:/Users/tito/Zotero/storage/TIP2DMBH/Farrell et al_2022_Gradient-based learning drives robust representations in recurrent neural.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/A2LSBL9F/s42256-022-00498-0.html:text/html},
}

@article{srinath_attention_2021-1,
	title = {Attention improves information flow between neuronal populations without changing the communication subspace},
	volume = {31},
	issn = {0960-9822},
	url = {https://www.sciencedirect.com/science/article/pii/S0960982221013440},
	doi = {10.1016/j.cub.2021.09.076},
	abstract = {Visual attention allows observers to change the influence of different parts of a visual scene on their behavior, suggesting that information can be flexibly shared between visual cortex and neurons involved in decision making. We investigated the neural substrate of flexible information routing by analyzing the activity of populations of visual neurons in the medial temporal area (MT) and oculo-motor neurons in the superior colliculus (SC) while rhesus monkeys switched spatial attention. We demonstrated that attention increases the efficacy of visuomotor communication: trial-to-trial variability in SC population activity could be better predicted by the activity of the MT population (and vice versa) when attention was directed toward their joint receptive fields. Surprisingly, this improvement in prediction was not explained by changes in the dimensionality of the shared subspace or in the magnitude of local or shared pairwise noise correlations. These results lay a foundation for future theoretical and experimental studies into how visual attention can flexibly change information flow between sensory and decision neurons.},
	language = {en},
	number = {23},
	urldate = {2022-06-28},
	journal = {Current Biology},
	author = {Srinath, Ramanujan and Ruff, Douglas A. and Cohen, Marlene R.},
	month = dec,
	year = {2021},
	keywords = {spatial attention, communication subspace, functional communication, visual representations},
	pages = {5299--5313.e4},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/42EENS6U/S0960982221013440.html:text/html;Srinath et al_2021_Attention improves information flow between neuronal populations without.pdf:/Users/tito/Zotero/storage/6SNR9EYF/Srinath et al_2021_Attention improves information flow between neuronal populations without.pdf:application/pdf},
}

@article{breton-provencher_spatiotemporal_2022,
	title = {Spatiotemporal dynamics of noradrenaline during learned behaviour},
	volume = {606},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-04782-2},
	doi = {10.1038/s41586-022-04782-2},
	abstract = {Noradrenaline released from the locus coeruleus (LC) is a ubiquitous neuromodulator1–4 that has been linked to multiple functions including arousal5–8, action and sensory gain9–11, and learning12–16. Whether and how activation of noradrenaline-expressing neurons in the LC (LC-NA) facilitates different components of specific behaviours is unknown. Here we show that LC-NA activity displays distinct spatiotemporal dynamics to enable two functions during learned behaviour: facilitating task execution and encoding reinforcement to improve performance accuracy. To examine these functions, we used a behavioural task in mice with graded auditory stimulus detection and task performance. Optogenetic inactivation of the LC demonstrated that LC-NA activity was causal for both task execution and optimization. Targeted recordings of LC-NA neurons using photo-tagging, two-photon micro-endoscopy and two-photon output monitoring showed that transient LC-NA activation preceded behavioural execution and followed reinforcement. These two components of phasic activity were heterogeneously represented in LC-NA cortical outputs, such that the behavioural response signal was higher in the motor cortex and facilitated task execution, whereas the negative reinforcement signal was widely distributed among cortical regions and improved response sensitivity on the subsequent trial. Modular targeting of LC outputs thus enables diverse functions, whereby some noradrenaline signals are segregated among targets, whereas others are broadly distributed.},
	language = {en},
	number = {7915},
	urldate = {2022-06-29},
	journal = {Nature},
	author = {Breton-Provencher, Vincent and Drummond, Gabrielle T. and Feng, Jiesi and Li, Yulong and Sur, Mriganka},
	month = jun,
	year = {2022},
	note = {Number: 7915
Publisher: Nature Publishing Group},
	keywords = {Reward, Operant learning, Decision, Neural circuits},
	pages = {732--738},
	file = {Breton-Provencher et al_2022_Spatiotemporal dynamics of noradrenaline during learned behaviour.pdf:/Users/tito/Zotero/storage/8E8PLQ8H/Breton-Provencher et al_2022_Spatiotemporal dynamics of noradrenaline during learned behaviour.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/VUU3KZFP/s41586-022-04782-2.html:text/html},
}

@article{luo_inside_2022,
	title = {Inside information: {Systematic} within-node functional connectivity changes observed across tasks or groups},
	volume = {247},
	issn = {1053-8119},
	shorttitle = {Inside information},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921010636},
	doi = {10.1016/j.neuroimage.2021.118792},
	abstract = {Mapping the human connectome and understanding its relationship to brain function holds tremendous clinical potential. The connectome has two fundamental components: the nodes and the sconnections between them. While much attention has been given to deriving atlases and measuring the connections between nodes, there have been no studies examining the networks within nodes. Here we demonstrate that each node contains significant connectivity information, that varies systematically across task-induced states and subjects, such that measures based on these variations can be used to classify tasks and identify subjects. The results are not specific for any particular atlas but hold across different atlas resolutions. To date, studies examining changes in connectivity have focused on edge changes and assumed there is no useful information within nodes. Our findings illustrate that for typical atlases, within-node changes can be significant and may account for a substantial fraction of the variance currently attributed to edge changes .},
	language = {en},
	urldate = {2022-06-30},
	journal = {NeuroImage},
	author = {Luo, Wenjing and Constable, R. Todd},
	month = feb,
	year = {2022},
	pages = {118792},
	file = {Luo_Constable_2022_Inside information.pdf:/Users/tito/Zotero/storage/RM35FSXL/Luo_Constable_2022_Inside information.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/UM2WGUXH/S1053811921010636.html:text/html},
}

@misc{russin_neural_2022,
	title = {A {Neural} {Network} {Model} of {Continual} {Learning} with {Cognitive} {Control}},
	url = {http://arxiv.org/abs/2202.04773},
	doi = {10.48550/arXiv.2202.04773},
	abstract = {Neural networks struggle in continual learning settings from catastrophic forgetting: when trials are blocked, new learning can overwrite the learning from previous blocks. Humans learn effectively in these settings, in some cases even showing an advantage of blocking, suggesting the brain contains mechanisms to overcome this problem. Here, we build on previous work and show that neural networks equipped with a mechanism for cognitive control do not exhibit catastrophic forgetting when trials are blocked. We further show an advantage of blocking over interleaving when there is a bias for active maintenance in the control signal, implying a tradeoff between maintenance and the strength of control. Analyses of map-like representations learned by the networks provided additional insights into these mechanisms. Our work highlights the potential of cognitive control to aid continual learning in neural networks, and offers an explanation for the advantage of blocking that has been observed in humans.},
	urldate = {2022-07-01},
	publisher = {arXiv},
	author = {Russin, Jacob and Zolfaghar, Maryam and Park, Seongmin A. and Boorman, Erie and O'Reilly, Randall C.},
	month = feb,
	year = {2022},
	note = {arXiv:2202.04773 [cs, q-bio]},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 7 pages, 5 figures, submitted to CogSci 2022},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/DTFMZEKD/2202.html:text/html;Russin et al_2022_A Neural Network Model of Continual Learning with Cognitive Control.pdf:/Users/tito/Zotero/storage/YCIITMED/Russin et al_2022_A Neural Network Model of Continual Learning with Cognitive Control.pdf:application/pdf},
}

@misc{aitken_neural_2022,
	title = {Neural {Population} {Dynamics} of {Computing} with {Synaptic} {Modulations}},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.06.27.497776v1},
	doi = {10.1101/2022.06.27.497776},
	abstract = {In addition to long-time scale rewiring, synapses in the brain are subject to significant modulation that occurs at much shorter time scales and allows them to process short-term information. Despite this, models of the brain like recurrent neural networks (RNNs) often have their weights frozen after training, relying on an internal state stored in neuron activity to process temporal information. Although networks with dynamical synapses have been explored previously, often said dynamics are added to networks that also have recurrent connections and thus the short-time scale computational capabilities of synapse modulation alone remain unclear. In this work, we analyze the dynamics of a network that relies solely on synaptic modulations to process short-time scale information, the multi-plasticity network (MPN). We thoroughly examine the neural population dynamics of the MPN trained on integration-based tasks and compare it to known RNN dynamics, findings the two to have fundamentally different behavior and attractor structure. We find said differences in dynamics allow the MPN to outperform its RNN counterparts on several neuroscience-relevant tasks. Of note, the MPN has a significantly simpler attractor structure that allows it to be more flexible in training and sequential-learning settings. Lastly, how the dynamics change for MPNs trained on contextual and continuous integration tasks is also investigated.},
	language = {en},
	urldate = {2022-07-01},
	publisher = {bioRxiv},
	author = {Aitken, Kyle and Mihalas, Stefan},
	month = jun,
	year = {2022},
	note = {Pages: 2022.06.27.497776
Section: New Results},
	file = {Aitken_Mihalas_2022_Neural Population Dynamics of Computing with Synaptic Modulations.pdf:/Users/tito/Zotero/storage/K273MA5B/Aitken_Mihalas_2022_Neural Population Dynamics of Computing with Synaptic Modulations.pdf:application/pdf},
}

@misc{sorenson_thalamocortical_2022,
	title = {Thalamocortical contribution to cognitive task activity},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.06.28.497905v1},
	doi = {10.1101/2022.06.28.497905},
	abstract = {Thalamocortical interaction is a ubiquitous functional motif in the mammalian brain. Previously (Hwang et al., 2021), we reported that lesions to network hubs in the human thalamus are associated with multi-domain behavioral impairments in language, memory, and executive functions. Here we show how task-evoked thalamic activity and thalamocortical interactions are organized to support these broad cognitive abilities. To address this question, we analyzed functional MRI data from human subjects that performed 127 tasks encompassing a broad range of cognitive representations. We first investigated the spatial organization of task-evoked activity and found that multi-task thalamic activity converged onto a low-dimensional structure, through which a basis set of activity patterns are evoked to support processing needs of each task. Specifically, the anterior, medial, and posterior-medial thalamus exhibit hub-like activity profiles that are suggestive of broad functional participation. These thalamic task hubs overlapped with network hubs interlinking cortical systems. To further determine the cognitive relevance of thalamocortical interactions, we built a data-driven thalamocortical interaction model to test whether thalamocortical functional connectivity transformed thalamic activity to cortical task activity. The thalamocortical model predicted task-specific cortical activity patterns, and outperformed comparison models built on cortical, hippocampal, and striatal regions. Simulated lesions to low-dimensional, multi-task thalamic hub regions impaired task activity prediction. This simulation result was further supported by profiles of neuropsychological impairments in human patients with focal thalamic lesions. In summary, our results suggest a general organizational principle of how thalamocortical interactions support cognitive task activity.},
	language = {en},
	urldate = {2022-07-01},
	publisher = {bioRxiv},
	author = {Sorenson, Evan and Shine, James M. and Cole, Michael W. and Hwang, Kai},
	month = jul,
	year = {2022},
	note = {Pages: 2022.06.28.497905
Section: New Results},
	file = {Snapshot:/Users/tito/Zotero/storage/U49JPBI2/2022.06.28.html:text/html;Sorenson et al_2022_Thalamocortical contribution to cognitive task activity.pdf:/Users/tito/Zotero/storage/YTKIUC77/Sorenson et al_2022_Thalamocortical contribution to cognitive task activity.pdf:application/pdf},
}

@article{singh_developing_2022,
	title = {Developing control-theoretic objectives for large-scale brain dynamics and cognitive enhancement},
	issn = {1367-5788},
	url = {https://www.sciencedirect.com/science/article/pii/S1367578822000773},
	doi = {10.1016/j.arcontrol.2022.05.001},
	abstract = {The development of technologies for brain stimulation provides a means for scientists and clinicians to directly actuate the brain and nervous system. Brain stimulation has shown intriguing potential in terms of modifying particular symptom clusters in patients and behavioral characteristics of subjects. The stage is thus set for optimization of these techniques and the pursuit of more nuanced stimulation objectives, including the modification of complex cognitive functions such as memory and attention. Control theory and engineering will play a key role in the development of these methods, guiding computational and algorithmic strategies for stimulation. In particular, realizing this goal will require new development of frameworks that allow for controlling not only brain activity, but also latent dynamics that underlie neural computation and information processing. In the current opinion, we review recent progress in brain stimulation and outline challenges and potential research pathways associated with exogenous control of cognitive function.},
	language = {en},
	urldate = {2022-07-06},
	journal = {Annual Reviews in Control},
	author = {Singh, Matthew F. and Cole, Michael W. and Braver, Todd S. and Ching, ShiNung},
	month = jul,
	year = {2022},
	keywords = {Brain dynamics, Brain stimulation, Neural reachability, Neurocontrol theory},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/79KM6S6Z/S1367578822000773.html:text/html;Singh et al_2022_Developing control-theoretic objectives for large-scale brain dynamics and.pdf:/Users/tito/Zotero/storage/H2AN37EG/Singh et al_2022_Developing control-theoretic objectives for large-scale brain dynamics and.pdf:application/pdf},
}

@article{hearne_latin_2020,
	title = {The {Latin} {Square} {Task} as a measure of relational reasoning: {A} replication and assessment of reliability.},
	volume = {36},
	shorttitle = {The {Latin} {Square} {Task} as a measure of relational reasoning},
	number = {2},
	journal = {European Journal of Psychological Assessment},
	author = {Hearne, Luke J. and Birney, Damian P. and Cocchi, Luca and Mattingley, Jason B.},
	year = {2020},
	note = {Publisher: Hogrefe Publishing},
	pages = {296},
	file = {Hearne et al_2020_The Latin Square Task as a measure of relational reasoning.pdf:/Users/tito/Zotero/storage/L7KD8RZH/Hearne et al_2020_The Latin Square Task as a measure of relational reasoning.pdf:application/pdf},
}

@article{cruz_cortical-subcortical_2022,
	title = {Cortical-{Subcortical} {Interactions} in {Goal}-directed {Behavior}},
	issn = {0031-9333},
	url = {https://journals.physiology.org/doi/abs/10.1152/physrev.00048.2021},
	doi = {10.1152/physrev.00048.2021},
	abstract = {Flexibly selecting appropriate actions in response to complex, ever-changing environments requires both cortical and subcortical regions, which are typically described as participating in a strict hierarchy. In this traditional view, highly specialized subcortical circuits allow for efficient responses to salient stimuli, at the cost of adaptability and context-specificity, which are attributed to the neocortex. Their interactions are often described as the cortex providing top-down command signals for subcortical structures to implement; however, as available technologies develop, studies increasingly demonstrate that behavior is represented by brain-wide activity and that even subcortical structures contain early signals of choice, suggesting that behavioral functions emerge as a result of different regions interacting as truly collaborative networks. In this review, we discuss the field's evolving understanding of how cortical and subcortical regions in placental mammals interact cooperatively- not only via top-down cortical-subcortical inputs, but through bottom-up interactions, especially via the thalamus. We describe our current understanding of the circuitry of both the cortex and two exemplar subcortical structures- the superior colliculus and striatum- to identify which information is prioritized by which regions. We then describe the functional circuits these regions form with one another- and the thalamus- to create parallel loops and complex networks for brain-wide information flow. Finally, we challenge the classic view that functional modules are contained within specific brain regions; instead, we propose that certain regions prioritize specific types of information over others, but the subnetworks they form- defined by their anatomical connections and functional dynamics- are the basis of true specialization.},
	urldate = {2022-07-11},
	journal = {Physiological Reviews},
	author = {Cruz, K. Guadalupe and Leow, Yi Ning and Le, Nhat Minh and Adam, Elie and Huda, Rafiq and Sur, Mriganka},
	month = jun,
	year = {2022},
	note = {Publisher: American Physiological Society},
	keywords = {striatum, attention, Cortical-subcortical interactions, sensorimotor transformation, superior colliculus},
}

@article{fakhar_systematic_2022,
	title = {Systematic perturbation of an artificial neural network: {A} step towards quantifying causal contributions in the brain},
	volume = {18},
	issn = {1553-7358},
	shorttitle = {Systematic perturbation of an artificial neural network},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010250},
	doi = {10.1371/journal.pcbi.1010250},
	abstract = {Lesion inference analysis is a fundamental approach for characterizing the causal contributions of neural elements to brain function. This approach has gained new prominence through the arrival of modern perturbation techniques with unprecedented levels of spatiotemporal precision. While inferences drawn from brain perturbations are conceptually powerful, they face methodological difficulties. Particularly, they are challenged to disentangle the true causal contributions of the involved elements, since often functions arise from coalitions of distributed, interacting elements, and localized perturbations have unknown global consequences. To elucidate these limitations, we systematically and exhaustively lesioned a small artificial neural network (ANN) playing a classic arcade game. We determined the functional contributions of all nodes and links, contrasting results from sequential single-element perturbations with simultaneous perturbations of multiple elements. We found that lesioning individual elements, one at a time, produced biased results. By contrast, multi-site lesion analysis captured crucial details that were missed by single-site lesions. We conclude that even small and seemingly simple ANNs show surprising complexity that needs to be addressed by multi-lesioning for a coherent causal characterization.},
	language = {en},
	number = {6},
	urldate = {2022-07-11},
	journal = {PLOS Computational Biology},
	author = {Fakhar, Kayson and Hilgetag, Claus C.},
	month = jun,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Behavior, Neurons, Cognitive neuroscience, Neural networks, Permutation, Brain mapping, Artificial neural networks, Chemical elements},
	pages = {e1010250},
	file = {Fakhar_Hilgetag_2022_Systematic perturbation of an artificial neural network.pdf:/Users/tito/Zotero/storage/HG8787CN/Fakhar_Hilgetag_2022_Systematic perturbation of an artificial neural network.pdf:application/pdf},
}

@misc{damian_neural_2022,
	title = {Neural {Networks} can {Learn} {Representations} with {Gradient} {Descent}},
	url = {http://arxiv.org/abs/2206.15144},
	doi = {10.48550/arXiv.2206.15144},
	abstract = {Significant theoretical work has established that in specific regimes, neural networks trained by gradient descent behave like kernel methods. However, in practice, it is known that neural networks strongly outperform their associated kernels. In this work, we explain this gap by demonstrating that there is a large class of functions which cannot be efficiently learned by kernel methods but can be easily learned with gradient descent on a two layer neural network outside the kernel regime by learning representations that are relevant to the target task. We also demonstrate that these representations allow for efficient transfer learning, which is impossible in the kernel regime. Specifically, we consider the problem of learning polynomials which depend on only a few relevant directions, i.e. of the form \$f{\textasciicircum}{\textbackslash}star(x) = g(Ux)\$ where \$U: {\textbackslash}R{\textasciicircum}d {\textbackslash}to {\textbackslash}R{\textasciicircum}r\$ with \$d {\textbackslash}gg r\$. When the degree of \$f{\textasciicircum}{\textbackslash}star\$ is \$p\$, it is known that \$n {\textbackslash}asymp d{\textasciicircum}p\$ samples are necessary to learn \$f{\textasciicircum}{\textbackslash}star\$ in the kernel regime. Our primary result is that gradient descent learns a representation of the data which depends only on the directions relevant to \$f{\textasciicircum}{\textbackslash}star\$. This results in an improved sample complexity of \$n{\textbackslash}asymp d{\textasciicircum}2 r + dr{\textasciicircum}p\$. Furthermore, in a transfer learning setup where the data distributions in the source and target domain share the same representation \$U\$ but have different polynomial heads we show that a popular heuristic for transfer learning has a target sample complexity independent of \$d\$.},
	urldate = {2022-07-11},
	publisher = {arXiv},
	author = {Damian, Alex and Lee, Jason D. and Soltanolkotabi, Mahdi},
	month = jun,
	year = {2022},
	note = {arXiv:2206.15144 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory},
	annote = {Comment: COLT 2022},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/V7HGPMLC/2206.html:text/html;Damian et al_2022_Neural Networks can Learn Representations with Gradient Descent.pdf:/Users/tito/Zotero/storage/JR9CFVQ5/Damian et al_2022_Neural Networks can Learn Representations with Gradient Descent.pdf:application/pdf},
}

@article{sibert_structured_2022,
	title = {The {Structured} {Mind} at {Rest}: {Low}-{Frequency} {Oscillations} {Reflect} {Interactive} {Dynamics} {Between} {Spontaneous} {Brain} {Activity} and a {Common} {Architecture} for {Task} {Control}},
	volume = {16},
	issn = {1662-453X},
	shorttitle = {The {Structured} {Mind} at {Rest}},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2022.832503},
	abstract = {The Common Model of Cognition (CMC) has been proposed as a high level framework through which functional neuroimaging data can be predicted and interpreted. Previous work has found the CMC is capable of predicting brain activity across a variety of tasks, but it has not been tested on resting state data. This paper adapts a previously used method for comparing theoretical models of brain structure, Dynamic Causal Modeling, for the task-free environment of resting state, and compares the CMC against six alternate architectural frameworks while also separately modeling spontaneous low-frequency oscillations. For a large sample of subjects from the Human Connectome Project, the CMC provides the best account of resting state brain activity, suggesting the presence of a general purpose structure of connections in the brain that drives activity when at rest and when performing directed task behavior. At the same time, spontaneous brain activity was found to be present and significant across all frequencies and in all regions. Together, these results suggest that, at rest, spontaneous low-frequency oscillations interact with the general cognitive architecture for task-based activity. The possible functional implications of these findings are discussed.},
	urldate = {2022-07-12},
	journal = {Frontiers in Neuroscience},
	author = {Sibert, Catherine and Hake, Holly Sue and Stocco, Andrea},
	year = {2022},
	file = {Sibert et al_2022_The Structured Mind at Rest.pdf:/Users/tito/Zotero/storage/CGNEDKB8/Sibert et al_2022_The Structured Mind at Rest.pdf:application/pdf},
}

@article{taylor_structural_2022,
	title = {Structural connections between the noradrenergic and cholinergic system shape the dynamics of functional brain networks},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811922005717},
	doi = {10.1016/j.neuroimage.2022.119455},
	abstract = {Complex cognitive abilities are thought to arise from the ability of the brain to adaptively reconfigure its internal network structure as a function of task demands. Recent work has suggested that this inherent flexibility may in part be conferred by the widespread projections of the ascending arousal systems. While the different components of the ascending arousal system are often studied in isolation, there are anatomical connections between neuromodulatory hubs that we hypothesize are crucial for mediating key features of adaptive network dynamics, such as the balance between integration and segregation. To test this hypothesis, we estimated the strength of structural connectivity between key hubs of the noradrenergic and cholinergic arousal systems (the locus coeruleus [LC] and nucleus basalis of Meynert [nbM], respectively). We then asked whether the strength of structural LC and nbM inter-connectivity was related to individual differences in the emergent, dynamical signatures of functional integration measured from resting state fMRI data, such as network and attractor topography. We observed a significant positive relationship between the strength of white-matter connections between the LC and nbM and the extent of network-level integration following BOLD signal peaks in LC relative to nbM activity. In addition, individuals with denser white-matter streamlines interconnecting neuromodulatory hubs also demonstrated a heightened ability to shift to novel brain states. These results suggest that individuals with stronger structural connectivity between the noradrenergic and cholinergic systems have a greater capacity to mediate the flexible network dynamics required to support complex, adaptive behaviour. Furthermore, our results highlight the underlying static features of the neuromodulatory hubs can impose some constraints on the dynamic features of the brain.},
	language = {en},
	urldate = {2022-07-12},
	journal = {NeuroImage},
	author = {Taylor, N. L. and D'Souza, A. and Munn, B. R. and Lv, J. and Zaborszky, L. and Müller, E. J. and Wainstein, G. and Calamante, F. and Shine, J. M.},
	month = jul,
	year = {2022},
	pages = {119455},
	file = {ScienceDirect Snapshot:/Users/tito/Zotero/storage/KG7I6CC4/S1053811922005717.html:text/html;Taylor et al_2022_Structural connections between the noradrenergic and cholinergic system shape.pdf:/Users/tito/Zotero/storage/82C26JTG/Taylor et al_2022_Structural connections between the noradrenergic and cholinergic system shape.pdf:application/pdf},
}

@article{wang_theory_2022,
	title = {Theory of the {Multiregional} {Neocortex}: {Large}-{Scale} {Neural} {Dynamics} and {Distributed} {Cognition}},
	volume = {45},
	shorttitle = {Theory of the {Multiregional} {Neocortex}},
	url = {https://doi.org/10.1146/annurev-neuro-110920-035434},
	doi = {10.1146/annurev-neuro-110920-035434},
	abstract = {The neocortex is a complex neurobiological system with many interacting regions. How these regions work together to subserve flexible behavior and cognition has become increasingly amenable to rigorous research. Here, I review recent experimental and theoretical work on the modus operandi of a multiregional cortex. These studies revealed several general principles for the neocortical interareal connectivity, low-dimensional macroscopic gradients of biological properties across cortical areas, and a hierarchy of timescales for information processing. Theoretical work suggests testable predictions regarding differential excitation and inhibition along feedforward and feedback pathways in the cortical hierarchy. Furthermore, modeling of distributed working memory and simple decision-making has given rise to a novel mathematical concept, dubbed bifurcation in space, that potentially explains how different cortical areas, with a canonical circuit organization but gradients of biological heterogeneities, are able to subserve their respective (e.g., sensory coding versus executive control) functions in a modularly organized brain.},
	number = {1},
	urldate = {2022-07-12},
	journal = {Annual Review of Neuroscience},
	author = {Wang, Xiao-Jing},
	year = {2022},
	pmid = {35803587},
	note = {\_eprint: https://doi.org/10.1146/annurev-neuro-110920-035434},
	keywords = {computational modeling, distributed cognition, global brain dynamics, hierarchy of timescales, macroscopic gradients, neocortical connectome},
	pages = {533--560},
	file = {Wang_2022_Theory of the Multiregional Neocortex.pdf:/Users/tito/Zotero/storage/PZQGD7JV/Wang_2022_Theory of the Multiregional Neocortex.pdf:application/pdf},
}

@article{markello_comparing_2021,
	title = {Comparing spatial null models for brain maps},
	volume = {236},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811921003293},
	doi = {10.1016/j.neuroimage.2021.118052},
	abstract = {Technological and data sharing advances have led to a proliferation of high-resolution structural and functional maps of the brain. Modern neuroimaging research increasingly depends on identifying correspondences between the topographies of these maps; however, most standard methods for statistical inference fail to account for their spatial properties. Recently, multiple methods have been developed to generate null distributions that preserve the spatial autocorrelation of brain maps and yield more accurate statistical estimates. Here, we comprehensively assess the performance of ten published null frameworks in statistical analyses of neuroimaging data. To test the efficacy of these frameworks in situations with a known ground truth, we first apply them to a series of controlled simulations and examine the impact of data resolution and spatial autocorrelation on their family-wise error rates. Next, we use each framework with two empirical neuroimaging datasets, investigating their performance when testing (1) the correspondence between brain maps (e.g., correlating two activation maps) and (2) the spatial distribution of a feature within a partition (e.g., quantifying the specificity of an activation map within an intrinsic functional network). Finally, we investigate how differences in the implementation of these null models may impact their performance. In agreement with previous reports, we find that naive null models that do not preserve spatial autocorrelation consistently yield elevated false positive rates and unrealistically liberal statistical estimates. While spatially-constrained null models yielded more realistic, conservative estimates, even these frameworks suffer from inflated false positive rates and variable performance across analyses. Throughout our results, we observe minimal impact of parcellation and resolution on null model performance. Altogether, our findings highlight the need for continued development of statistically-rigorous methods for comparing brain maps. The present report provides a harmonised framework for benchmarking and comparing future advancements.},
	language = {en},
	urldate = {2022-07-12},
	journal = {NeuroImage},
	author = {Markello, Ross D. and Misic, Bratislav},
	month = aug,
	year = {2021},
	keywords = {Spatial autocorrelation, Brain parcellations, Null models, Significance testing, Spin test},
	pages = {118052},
	file = {Markello_Misic_2021_Comparing spatial null models for brain maps.pdf:/Users/tito/Zotero/storage/NPE5PZ3W/Markello_Misic_2021_Comparing spatial null models for brain maps.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/IYFH6FYZ/S1053811921003293.html:text/html},
}

@inproceedings{saxe_neural_2022,
	title = {The {Neural} {Race} {Reduction}: {Dynamics} of {Abstraction} in {Gated} {Networks}},
	shorttitle = {The {Neural} {Race} {Reduction}},
	url = {https://proceedings.mlr.press/v162/saxe22a.html},
	abstract = {Our theoretical understanding of deep learning has not kept pace with its empirical success. While network architecture is known to be critical, we do not yet understand its effect on learned representations and network behavior, or how this architecture should reflect task structure.In this work, we begin to address this gap by introducing the Gated Deep Linear Network framework that schematizes how pathways of information flow impact learning dynamics within an architecture. Crucially, because of the gating, these networks can compute nonlinear functions of their input. We derive an exact reduction and, for certain cases, exact solutions to the dynamics of learning. Our analysis demonstrates that the learning dynamics in structured networks can be conceptualized as a neural race with an implicit bias towards shared representations, which then govern the model’s ability to systematically generalize, multi-task, and transfer. We validate our key insights on naturalistic datasets and with relaxed assumptions. Taken together, our work gives rise to general hypotheses relating neural architecture to learning and provides a mathematical approach towards understanding the design of more complex architectures and the role of modularity and compositionality in solving real-world problems. The code and results are available at https://www.saxelab.org/gated-dln.},
	language = {en},
	urldate = {2022-07-15},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Saxe, Andrew and Sodhani, Shagun and Lewallen, Sam Jay},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {19287--19309},
	file = {Saxe et al_2022_The Neural Race Reduction.pdf:/Users/tito/Zotero/storage/828X5SHM/Saxe et al_2022_The Neural Race Reduction.pdf:application/pdf},
}

@article{johnson_sensory_1980,
	title = {Sensory discrimination: neural processes preceding discrimination decision},
	volume = {43},
	issn = {0022-3077},
	shorttitle = {Sensory discrimination},
	url = {https://journals.physiology.org/doi/abs/10.1152/jn.1980.43.6.1793},
	doi = {10.1152/jn.1980.43.6.1793},
	number = {6},
	urldate = {2022-07-18},
	journal = {Journal of Neurophysiology},
	author = {Johnson, K. O.},
	month = jun,
	year = {1980},
	note = {Publisher: American Physiological Society},
	pages = {1793--1815},
}

@article{johnson_sensory_1980-1,
	title = {Sensory discrimination: neural processes preceding discrimination decision},
	volume = {43},
	issn = {0022-3077},
	shorttitle = {Sensory discrimination},
	doi = {10.1152/jn.1980.43.6.1793},
	language = {eng},
	number = {6},
	journal = {J Neurophysiol},
	author = {Johnson, K. O.},
	month = jun,
	year = {1980},
	pmid = {7411183},
	keywords = {Perception, Decision Making, Humans, Neurons, Discrimination Learning, Afferent Pathways, Models, Neurological, Psychophysics, Sensory Receptor Cells},
	pages = {1793--1815},
}

@article{rust_priority_2022,
	title = {Priority coding in the visual system},
	volume = {23},
	copyright = {2022 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-022-00582-9},
	doi = {10.1038/s41583-022-00582-9},
	abstract = {Although we are continuously bombarded with visual input, only a fraction of incoming visual events is perceived, remembered or acted on. The neural underpinnings of various forms of visual priority coding, including perceptual expertise, goal-directed attention, visual salience, image memorability and preferential looking, have been studied. Here, we synthesize information from these different examples to review recent developments in our understanding of visual priority coding and its neural correlates, with a focus on the role of behaviour to evaluate candidate correlates. We propose that the brain combines different types of priority into a unified priority signal while also retaining the ability to differentiate between them, and that this happens by leveraging partially overlapping low-dimensional neural subspaces for each type of priority that are shared with the downstream neural populations involved in decision-making. Finally, we describe the gulfs in understanding that have resulted from different research approaches, and we point towards future directions that will lead to fundamental insights about neural coding and how prioritization influences visually guided behaviours.},
	language = {en},
	number = {6},
	urldate = {2022-07-19},
	journal = {Nat Rev Neurosci},
	author = {Rust, Nicole C. and Cohen, Marlene R.},
	month = jun,
	year = {2022},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Neural encoding, Extrastriate cortex},
	pages = {376--388},
	file = {Rust_Cohen_2022_Priority coding in the visual system.pdf:/Users/tito/Zotero/storage/NCNH49IZ/Rust_Cohen_2022_Priority coding in the visual system.pdf:application/pdf},
}

@misc{miller_long-term_2022,
	title = {Long-term learning transforms prefrontal cortex selectivity during working memory},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.02.22.481537v1},
	doi = {10.1101/2022.02.22.481537},
	abstract = {The lateral prefrontal cortex (lPFC) is reliably active during working memory (WM) across human and animal models, but the role of lPFC in successful WM is under debate. For instance, non-human primate (NHP) electrophysiology research finds that lPFC circuitry stores WM representations. Human neuroimaging instead suggests that lPFC plays a control function over WM content that is stored in sensory cortices. These seemingly incompatible WM accounts are often confounded by differences in the amount of task training and stimulus exposure across studies (i.e., NHPs tend to be trained extensively). Here, we test the possibility that such long-term training may alter the role of lPFC in WM maintenance. We densely sampled WM-related activity across learning, in three human participants, using a longitudinal functional MRI (fMRI) protocol. Over three months, participants trained on (1) a serial reaction time (SRT) task, wherein complex fractal stimuli were embedded within probabilistic sequences, and (2) a delayed recognition task probing WM for trained or novel stimuli. Participants were scanned frequently throughout training, to track how WM activity patterns change with repeated stimulus exposure and long-term associative learning. WM task performance improved for trained (but not novel) fractals and, neurally, delay activity significantly increased in distributed lPFC voxels across learning. Pattern similarity analyses also found that item-level WM representations emerged within lPFC, but not in sensory cortices, and lPFC delay activity increasingly reflected sequence relationships from the SRT task, even though that information was task-irrelevant for WM. These findings demonstrate that human lPFC develops stimulus-selective WM responses with learning and WM representations are shaped by long-term experience. Influences from training and long-term memory may reconcile competing accounts of lPFC function during WM.},
	language = {en},
	urldate = {2022-07-20},
	publisher = {bioRxiv},
	author = {Miller, Jacob A. and Tambini, Arielle and Kiyonaga, Anastasia and D’Esposito, Mark},
	month = feb,
	year = {2022},
	note = {Pages: 2022.02.22.481537
Section: New Results},
	file = {Miller et al_2022_Long-term learning transforms prefrontal cortex selectivity during working.pdf:/Users/tito/Zotero/storage/46WQMYX4/Miller et al_2022_Long-term learning transforms prefrontal cortex selectivity during working.pdf:application/pdf},
}

@misc{cowley_one--one_2022,
	title = {One-to-one mapping between deep network units and real neurons uncovers a visual population code for social behavior},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.07.18.500505v1},
	doi = {10.1101/2022.07.18.500505},
	abstract = {The rich variety of behaviors observed in animals arises through the complex interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuron types. A key ingredient we introduce is "knockout training", which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformation of Drosophila melanogaster males during a complex, visually-guided social behavior. Contrary to prevailing views, our model suggests that visual projection neurons at the interface between the eye and brain form a distributed population code that collectively sculpts social behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a detailed map from stimulus to neuron to behavior.},
	language = {en},
	urldate = {2022-07-21},
	publisher = {bioRxiv},
	author = {Cowley, Benjamin R. and Calhoun, Adam J. and Rangarajan, Nivedita and Pillow, Jonathan W. and Murthy, Mala},
	month = jul,
	year = {2022},
	note = {Pages: 2022.07.18.500505
Section: New Results},
	file = {Cowley et al_2022_One-to-one mapping between deep network units and real neurons uncovers a.pdf:/Users/tito/Zotero/storage/6WN9RVGG/Cowley et al_2022_One-to-one mapping between deep network units and real neurons uncovers a.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/5T5AN5XA/2022.07.18.html:text/html},
}

@misc{noauthor_joint_nodate,
	title = {A {Joint} {Distribution} {Approach} on {Non}-linear {Functional} {Connectivity} {\textbar} {bioRxiv}},
	url = {https://www.biorxiv.org/content/10.1101/2022.07.16.500288v1},
	urldate = {2022-07-21},
	file = {A Joint Distribution Approach on Non-linear Functional Connectivity | bioRxiv:/Users/tito/Zotero/storage/FIYXGXQ6/2022.07.16.html:text/html},
}

@article{palla_uncovering_2005,
	title = {Uncovering the overlapping community structure of complex networks in nature and society},
	volume = {435},
	copyright = {2005 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature03607},
	doi = {10.1038/nature03607},
	abstract = {A network is a network — be it between words (those associated with ‘bright’ in this case) or protein structures.},
	language = {en},
	number = {7043},
	urldate = {2022-07-25},
	journal = {Nature},
	author = {Palla, Gergely and Derényi, Imre and Farkas, Illés and Vicsek, Tamás},
	month = jun,
	year = {2005},
	note = {Number: 7043
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {814--818},
	file = {Palla et al_2005_Uncovering the overlapping community structure of complex networks in nature.pdf:/Users/tito/Zotero/storage/BD3ZRUV5/Palla et al_2005_Uncovering the overlapping community structure of complex networks in nature.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/P99MRSB8/nature03607.html:text/html},
}

@article{bolt_parsimonious_2022,
	title = {A parsimonious description of global functional brain organization in three spatiotemporal patterns},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-022-01118-1},
	doi = {10.1038/s41593-022-01118-1},
	abstract = {Resting-state functional magnetic resonance imaging (MRI) has yielded seemingly disparate insights into large-scale organization of the human brain. The brain’s large-scale organization can be divided into two broad categories: zero-lag representations of functional connectivity structure and time-lag representations of traveling wave or propagation structure. In this study, we sought to unify observed phenomena across these two categories in the form of three low-frequency spatiotemporal patterns composed of a mixture of standing and traveling wave dynamics. We showed that a range of empirical phenomena, including functional connectivity gradients, the task-positive/task-negative anti-correlation pattern, the global signal, time-lag propagation patterns, the quasiperiodic pattern and the functional connectome network structure, are manifestations of these three spatiotemporal patterns. These patterns account for much of the global spatial structure that underlies functional connectivity analyses and unifies phenomena in resting-state functional MRI previously thought distinct.},
	language = {en},
	urldate = {2022-07-28},
	journal = {Nat Neurosci},
	author = {Bolt, Taylor and Nomi, Jason S. and Bzdok, Danilo and Salas, Jorge A. and Chang, Catie and Thomas Yeo, B. T. and Uddin, Lucina Q. and Keilholz, Shella D.},
	month = jul,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Functional magnetic resonance imaging, Network models, Neural encoding},
	pages = {1--11},
	file = {Bolt et al_2022_A parsimonious description of global functional brain organization in three.pdf:/Users/tito/Zotero/storage/WJRN2S3D/Bolt et al_2022_A parsimonious description of global functional brain organization in three.pdf:application/pdf;Snapshot:/Users/tito/Zotero/storage/65K8I7XL/s41593-022-01118-1.html:text/html},
}

@inproceedings{ruis_benchmark_2020,
	title = {A {Benchmark} for {Systematic} {Generalization} in {Grounded} {Language} {Understanding}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/e5a90182cc81e12ab5e72d66e0b46fe3-Abstract.html},
	abstract = {Humans easily interpret expressions that describe unfamiliar situations composed from familiar parts ("greet the pink brontosaurus by the ferris wheel"). Modern neural networks, by contrast, struggle to interpret novel compositions. In this paper, we introduce a new benchmark, gSCAN, for evaluating compositional generalization in situated language understanding. Going beyond a related benchmark that focused on syntactic aspects of generalization, gSCAN defines a language grounded in the states of a grid world, facilitating novel evaluations of acquiring linguistically motivated rules. For example, agents must understand how adjectives such as 'small' are interpreted relative to the current world state or how adverbs such as 'cautiously' combine with new verbs. We test a strong multi-modal baseline model and a state-of-the-art compositional method finding that, in most cases, they fail dramatically when generalization requires systematic compositional rules.},
	urldate = {2022-07-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ruis, Laura and Andreas, Jacob and Baroni, Marco and Bouchacourt, Diane and Lake, Brenden M},
	year = {2020},
	pages = {19861--19872},
	file = {Ruis et al_2020_A Benchmark for Systematic Generalization in Grounded Language Understanding.pdf:/Users/tito/Zotero/storage/YWXL8746/Ruis et al_2020_A Benchmark for Systematic Generalization in Grounded Language Understanding.pdf:application/pdf},
}

@article{dangelo_quest_2022,
	title = {The quest for multiscale brain modeling},
	issn = {0166-2236},
	url = {https://www.sciencedirect.com/science/article/pii/S0166223622001254},
	doi = {10.1016/j.tins.2022.06.007},
	abstract = {Addressing the multiscale organization of the brain, which is fundamental to the dynamic repertoire of the organ, remains challenging. In principle, it should be possible to model neurons and synapses in detail and then connect them into large neuronal assemblies to explain the relationship between microscopic phenomena, large-scale brain functions, and behavior. It is more difficult to infer neuronal functions from ensemble measurements such as those currently obtained with brain activity recordings. In this article we consider theories and strategies for combining bottom-up models, generated from principles of neuronal biophysics, with top-down models based on ensemble representations of network activity and on functional principles. These integrative approaches are hoped to provide effective multiscale simulations in virtual brains and neurorobots, and pave the way to future applications in medicine and information technologies.},
	language = {en},
	urldate = {2022-07-29},
	journal = {Trends in Neurosciences},
	author = {D’Angelo, Egidio and Jirsa, Viktor},
	month = jul,
	year = {2022},
	keywords = {brain scales, closed-loop controllers, digital twins, neuronal biophysics, virtual brains},
	file = {D’Angelo_Jirsa_2022_The quest for multiscale brain modeling.pdf:/Users/tito/Zotero/storage/9P4BT7GF/D’Angelo_Jirsa_2022_The quest for multiscale brain modeling.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/IUVV4MEJ/S0166223622001254.html:text/html},
}

@misc{andreas_good-enough_2020,
	title = {Good-{Enough} {Compositional} {Data} {Augmentation}},
	url = {http://arxiv.org/abs/1904.09545},
	doi = {10.48550/arXiv.1904.09545},
	abstract = {We propose a simple data augmentation protocol aimed at providing a compositional inductive bias in conditional and unconditional sequence models. Under this protocol, synthetic training examples are constructed by taking real training examples and replacing (possibly discontinuous) fragments with other fragments that appear in at least one similar environment. The protocol is model-agnostic and useful for a variety of tasks. Applied to neural sequence-to-sequence models, it reduces error rate by as much as 87\% on diagnostic tasks from the SCAN dataset and 16\% on a semantic parsing task. Applied to n-gram language models, it reduces perplexity by roughly 1\% on small corpora in several languages.},
	urldate = {2022-08-01},
	publisher = {arXiv},
	author = {Andreas, Jacob},
	month = may,
	year = {2020},
	note = {arXiv:1904.09545 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Andreas_2020_Good-Enough Compositional Data Augmentation.pdf:/Users/tito/Zotero/storage/4TXPVHFC/Andreas_2020_Good-Enough Compositional Data Augmentation.pdf:application/pdf;arXiv.org Snapshot:/Users/tito/Zotero/storage/GR6M5FPD/1904.html:text/html},
}

@article{stephan_comparing_2007,
	title = {Comparing hemodynamic models with {DCM}},
	volume = {38},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811907006489},
	doi = {10.1016/j.neuroimage.2007.07.040},
	abstract = {The classical model of blood oxygen level-dependent (BOLD) responses by Buxton et al. [Buxton, R.B., Wong, E.C., Frank, L.R., 1998. Dynamics of blood flow and oxygenation changes during brain activation: the Balloon model. Magn. Reson. Med. 39, 855–864] has been very important in providing a biophysically plausible framework for explaining different aspects of hemodynamic responses. It also plays an important role in the hemodynamic forward model for dynamic causal modeling (DCM) of fMRI data. A recent study by Obata et al. [Obata, T., Liu, T.T., Miller, K.L., Luh, W.M., Wong, E.C., Frank, L.R., Buxton, R.B., 2004. Discrepancies between BOLD and flow dynamics in primary and supplementary motor areas: application of the Balloon model to the interpretation of BOLD transients. NeuroImage 21, 144–153] linearized the BOLD signal equation and suggested a revised form for the model coefficients. In this paper, we show that the classical and revised models are special cases of a generalized model. The BOLD signal equation of this generalized model can be reduced to that of the classical Buxton model by simplifying the coefficients or can be linearized to give the Obata model. Given the importance of hemodynamic models for investigating BOLD responses and analyses of effective connectivity with DCM, the question arises which formulation is the best model for empirically measured BOLD responses. In this article, we address this question by embedding different variants of the BOLD signal equation in a well-established DCM of functional interactions among visual areas. This allows us to compare the ensuing models using Bayesian model selection. Our model comparison approach had a factorial structure, comparing eight different hemodynamic models based on (i) classical vs. revised forms for the coefficients, (ii) linear vs. non-linear output equations, and (iii) fixed vs. free parameters, ε, for region-specific ratios of intra- and extravascular signals. Using fMRI data from a group of twelve subjects, we demonstrate that the best model is a non-linear model with a revised form for the coefficients, in which ε is treated as a free parameter.},
	language = {en},
	number = {3},
	urldate = {2022-08-02},
	journal = {NeuroImage},
	author = {Stephan, Klaas Enno and Weiskopf, Nikolaus and Drysdale, Peter M. and Robinson, Peter A. and Friston, Karl J.},
	month = nov,
	year = {2007},
	keywords = {Effective connectivity, BOLD signal, System identification, Dynamic causal modeling, Bayesian model selection, Balloon model},
	pages = {387--401},
	file = {Stephan et al_2007_Comparing hemodynamic models with DCM.pdf:/Users/tito/Zotero/storage/PMF9JY9Z/Stephan et al_2007_Comparing hemodynamic models with DCM.pdf:application/pdf},
}

@misc{williams_behavior_2021,
	title = {Behavior measures are predicted by how information is encoded in an individual's brain},
	url = {http://arxiv.org/abs/2112.06048},
	doi = {10.48550/arXiv.2112.06048},
	abstract = {Similar to how differences in the proficiency of the cardiovascular and musculoskeletal system predict an individual's athletic ability, differences in how the same brain region encodes information across individuals may explain their behavior. However, when studying how the brain encodes information, researchers choose different neuroimaging tasks (e.g., language or motor tasks), which can rely on processing different types of information and can modulate different brain regions. We hypothesize that individual differences in how information is encoded in the brain are task-specific and predict different behavior measures. We propose a framework using encoding-models to identify individual differences in brain encoding and test if these differences can predict behavior. We evaluate our framework using task functional magnetic resonance imaging data. Our results indicate that individual differences revealed by encoding-models are a powerful tool for predicting behavior, and that researchers should optimize their choice of task and encoding-model for their behavior of interest.},
	urldate = {2022-08-03},
	publisher = {arXiv},
	author = {Williams, Jennifer and Wehbe, Leila},
	month = dec,
	year = {2021},
	note = {arXiv:2112.06048 [cs, eess, q-bio]},
	keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv.org Snapshot:/Users/tito/Zotero/storage/9EYECLWE/2112.html:text/html;Williams_Wehbe_2021_Behavior measures are predicted by how information is encoded in an.pdf:/Users/tito/Zotero/storage/WF6Y7WI2/Williams_Wehbe_2021_Behavior measures are predicted by how information is encoded in an.pdf:application/pdf},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	urldate = {2022-08-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
	file = {Vaswani et al_2017_Attention is All you Need.pdf:/Users/tito/Zotero/storage/3UBJ3ZEP/Vaswani et al_2017_Attention is All you Need.pdf:application/pdf},
}

@misc{santoro_simple_2017,
	title = {A simple neural network module for relational reasoning},
	url = {http://arxiv.org/abs/1706.01427},
	abstract = {Relational reasoning is a central component of generally intelligent behavior, but has proven diﬃcult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.},
	language = {en},
	urldate = {2022-08-04},
	publisher = {arXiv},
	author = {Santoro, Adam and Raposo, David and Barrett, David G. T. and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
	month = jun,
	year = {2017},
	note = {arXiv:1706.01427 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Santoro et al. - 2017 - A simple neural network module for relational reas.pdf:/Users/tito/Zotero/storage/PK99VBRR/Santoro et al. - 2017 - A simple neural network module for relational reas.pdf:application/pdf},
}

@article{drori_neural_2022,
	title = {A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level},
	volume = {119},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.2123433119},
	doi = {10.1073/pnas.2123433119},
	number = {32},
	urldate = {2022-08-08},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Drori, Iddo and Zhang, Sarah and Shuttleworth, Reece and Tang, Leonard and Lu, Albert and Ke, Elizabeth and Liu, Kevin and Chen, Linda and Tran, Sunny and Cheng, Newman and Wang, Roman and Singh, Nikhil and Patti, Taylor L. and Lynch, Jayson and Shporer, Avi and Verma, Nakul and Wu, Eugene and Strang, Gilbert},
	month = aug,
	year = {2022},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2123433119},
	file = {Drori et al_2022_A neural network solves, explains, and generates university math problems by.pdf:/Users/tito/Zotero/storage/Q7YG4RC8/Drori et al_2022_A neural network solves, explains, and generates university math problems by.pdf:application/pdf},
}

@article{dehaene_symbols_2022,
	title = {Symbols and mental programs: a hypothesis about human singularity},
	volume = {0},
	issn = {1364-6613, 1879-307X},
	shorttitle = {Symbols and mental programs},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(22)00141-3},
	doi = {10.1016/j.tics.2022.06.010},
	language = {English},
	number = {0},
	urldate = {2022-08-08},
	journal = {Trends in Cognitive Sciences},
	author = {Dehaene, Stanislas and Roumi, Fosca Al and Lakretz, Yair and Planton, Samuel and Sablé-Meyer, Mathias},
	month = aug,
	year = {2022},
	pmid = {35933289},
	note = {Publisher: Elsevier},
	keywords = {language, minimum description length, programs, sequences, symbols},
	file = {Snapshot:/Users/tito/Zotero/storage/HHZAX4LQ/S1364-6613(22)00141-3.html:text/html},
}

@article{fusi_neural_2007,
	title = {A {Neural} {Circuit} {Model} of {Flexible} {Sensorimotor} {Mapping}: {Learning} and {Forgetting} on {Multiple} {Timescales}},
	volume = {54},
	issn = {0896-6273},
	shorttitle = {A {Neural} {Circuit} {Model} of {Flexible} {Sensorimotor} {Mapping}},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627307002127},
	doi = {10.1016/j.neuron.2007.03.017},
	abstract = {Volitional behavior relies on the brain's ability to remap sensory flow to motor programs whenever demanded by a changed behavioral context. To investigate the circuit basis of such flexible behavior, we have developed a biophysically based decision-making network model of spiking neurons for arbitrary sensorimotor mapping. The model quantitatively reproduces behavioral and prefrontal single-cell data from an experiment in which monkeys learn visuomotor associations that are reversed unpredictably from time to time. We show that when synaptic modifications occur on multiple timescales, the model behavior becomes flexible only when needed: slow components of learning usually dominate the decision process. However, if behavioral contexts change frequently enough, fast components of plasticity take over, and the behavior exhibits a quick forget-and-learn pattern. This model prediction is confirmed by monkey data. Therefore, our work reveals a scenario for conditional associative learning that is distinct from instant switching between sets of well-established sensorimotor associations.},
	language = {en},
	number = {2},
	urldate = {2022-08-09},
	journal = {Neuron},
	author = {Fusi, Stefano and Asaad, Wael F. and Miller, Earl K. and Wang, Xiao-Jing},
	month = apr,
	year = {2007},
	keywords = {SYSNEURO},
	pages = {319--333},
	file = {Fusi et al_2007_A Neural Circuit Model of Flexible Sensorimotor Mapping.pdf:/Users/tito/Zotero/storage/LQKTXPPZ/Fusi et al_2007_A Neural Circuit Model of Flexible Sensorimotor Mapping.pdf:application/pdf;ScienceDirect Snapshot:/Users/tito/Zotero/storage/UVW7RE2F/S0896627307002127.html:text/html},
}

@article{flesch_comparing_2018,
	title = {Comparing continual task learning in minds and machines},
	volume = {115},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.1800755115},
	doi = {10.1073/pnas.1800755115},
	number = {44},
	urldate = {2022-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Flesch, Timo and Balaguer, Jan and Dekker, Ronald and Nili, Hamed and Summerfield, Christopher},
	month = oct,
	year = {2018},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {E10313--E10322},
	file = {Flesch et al_2018_Comparing continual task learning in minds and machines.pdf:/Users/tito/Zotero/storage/RQYPMCLY/Flesch et al_2018_Comparing continual task learning in minds and machines.pdf:application/pdf},
}
