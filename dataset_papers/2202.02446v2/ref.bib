
@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}


@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={6683--6694},
  year={2021}
}


@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}



% Stackelberg game and RL
@inproceedings{rajeswaran2020game,
  title={A game theoretic framework for model based reinforcement learning},
  author={Rajeswaran, Aravind and Mordatch, Igor and Kumar, Vikash},
  booktitle={International Conference on Machine Learning},
  pages={7953--7963},
  year={2020},
  organization={PMLR}
}


@article{zheng2021stackelberg,
  title={Stackelberg actor-critic: Game-theoretic reinforcement learning algorithms},
  author={Zheng, Liyuan and Fiez, Tanner and Alumbaugh, Zane and Chasnov, Benjamin and Ratliff, Lillian J},
  journal={arXiv preprint arXiv:2109.12286},
  year={2021}
}


@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={28954--28967},
  year={2021}
}

@inproceedings{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}


@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations},
  year      = {2015}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@article{wang2021convergent,
  title={A convergent and efficient deep q network algorithm},
  author={Wang, Zhikang T and Ueda, Masahito},
  journal={arXiv preprint arXiv:2106.15419},
  year={2021}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{hazan2016introduction,
  title={Introduction to Online Convex Optimization},
  author={Hazan, Elad},
  journal={Foundations and Trends in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@inproceedings{dai2018sbeed,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1125--1134},
  year={2018}
}

@book{sutton2018reinforcement,
	title        = {Reinforcement learning: An introduction},
	author       = {Sutton, Richard S and Barto, Andrew G},
	year         = 2018,
	publisher    = {MIT press}
}


@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}

@article{muller1997integral,
	title        = {Integral probability metrics and their generating classes of functions},
	author       = {M{\"u}ller, Alfred},
	year         = 1997,
	journal      = {Advances in Applied Probability}
}



@article{zhang2021towards,
  title={Towards Hyperparameter-free Policy Selection for Offline Reinforcement Learning},
  author={Zhang, Siyuan and Jiang, Nan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{paine2020hyperparameter,
	title        = {Hyperparameter Selection for Offline Reinforcement Learning},
	author       = {Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2007.09055}
}


@article{mnih2015human,
	title        = {Human-level control through deep reinforcement learning},
	author       = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	year         = 2015,
	journal      = {Nature},
	publisher    = {Nature Publishing Group},
	volume       = 518,
	number       = 7540,
	pages        = {529--533}
}

@article{silver2016mastering,
	title        = {Mastering the game of Go with deep neural networks and tree search},
	author       = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
	year         = 2016,
	journal      = {Nature},
	publisher    = {Nature Publishing Group},
	volume       = 529,
	number       = 7587,
	pages        = {484--489}
}


@article{antos2008learning,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}


@inproceedings{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{munos2008finite,
  title={Finite-Time Bounds for Fitted Value Iteration.},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={5},
  year={2008}
}


@article{liu2020provably,
  title={Provably Good Batch Reinforcement Learning Without Great Exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{xie2020q,
  title={Q* approximation schemes for batch reinforcement learning: A theoretical comparison},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={550--559},
  year={2020},
  organization={PMLR}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019}
}


@inproceedings{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014},
  organization={PMLR}
}

@inproceedings{chen2019information,
  title={Information-Theoretic Considerations in Batch Reinforcement Learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  volume={2},
  pages={267--274},
  year={2002}
}

@inproceedings{abbasi2019politex,
  title={Politex: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019}
}

@inproceedings{xie2021batch,
  title={Batch value-function approximation with only realizability},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={11404--11413},
  year={2021},
  organization={PMLR}
}

@inproceedings{daniely2011multiclass,
  title={Multiclass learnability and the erm principle},
  author={Daniely, Amit and Sabato, Sivan and Ben-David, Shai and Shalev-Shwartz, Shai},
  booktitle={Proceedings of the 24th Annual Conference on Learning Theory},
  pages={207--232},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{bendavid1995characterizations,
  title={Characterizations of learnability for classes of $\{0,\dotsc,n\}$-valued functions},
  author={Ben-David, Shai and Cesa-Bianchi, Nicolo and Haussler, David and Long, Philip M},
  journal={Journal of Computer and System Sciences},
  volume={50},
  number={1},
  pages={74--86},
  year={1995},
  publisher={Elsevier}
}

@article{haussler1995generalization,
  title={A generalization of Sauer's lemma},
  author={Haussler, David and Long, Philip M},
  journal={Journal of Combinatorial Theory, Series A},
  volume={71},
  number={2},
  pages={219--240},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@article{haussler1995sphere,
  title={Sphere packing numbers for subsets of the Boolean n-cube with bounded Vapnik-Chervonenkis dimension},
  author={Haussler, David},
  journal={Journal of Combinatorial Theory, Series A},
  volume={69},
  number={2},
  pages={217--232},
  year={1995},
  publisher={Elsevier}
}

@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018},
  publisher={MIT press}
}

@inproceedings{pires2012statistical,
  title={Statistical linear estimation with penalized estimators: an application to reinforcement learning},
  author={Pires, Bernardo {\'A}vila and Szepesv{\'a}ri, Csaba},
  booktitle={Proceedings of the 29th International Coference on International Conference on Machine Learning},
  pages={1755--1762},
  year={2012}
}

@article{lazaric2012finite,
  title={Finite-sample analysis of least-squares policy iteration},
  author={Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  journal={Journal of Machine Learning Research},
  volume={13},
  pages={3041--3074},
  year={2012}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@article{even2009online,
  title={Online Markov decision processes},
  author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
  journal={Mathematics of Operations Research},
  volume={34},
  number={3},
  pages={726--736},
  year={2009},
  publisher={INFORMS}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}


@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@inproceedings{rahimi2007random,
  title={Random features for large-scale kernel machines},
  author={Rahimi, Ali and Recht, Benjamin},
  booktitle={Proceedings of the 20th International Conference on Neural Information Processing Systems},
  pages={1177--1184},
  year={2007}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={The Journal of Machine Learning Research},
  volume={4},
  pages={1107--1149},
  year={2003},
  publisher={JMLR. org}
}

@inproceedings{szepesvari2005finite,
  title={Finite time bounds for sampling based fitted value iteration},
  author={Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={880--887},
  year={2005}
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir Massoud and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  year={2010}
}


@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11702--11716},
  year={2021}
}


@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{yu2020mopo,
  title={MOPO: Model-based Offline Policy Optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@inproceedings{agarwal2020optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{kumar2019stabilizing,
  title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={11784--11794},
  year={2019}
}

@inproceedings{munos2003error,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
  pages={560--567},
  year={2003}
}

@article{wang2020reinforcement,
  title={Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension},
  author={Wang, Ruosong and Salakhutdinov, Russ R and Yang, Lin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6123--6135},
  year={2020}
}

@inproceedings{precup2000eligibility,
  title={Eligibility Traces for Off-Policy Policy Evaluation},
  author={Precup, Doina and Sutton, Richard S and Singh, Satinder P},
  booktitle={Proceedings of the Seventeenth International Conference on Machine Learning},
  pages={759--766},
  year={2000}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}


@inproceedings{wang2020statistical,
  title={What are the Statistical Limits of Offline RL with Linear Function Approximation?},
  author={Wang, Ruosong and Foster, Dean and Kakade, Sham M},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@inproceedings{wang2021instabilities,
  title={Instabilities of offline rl with pre-trained neural representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham},
  booktitle={International Conference on Machine Learning},
  pages={10948--10960},
  year={2021},
  organization={PMLR}
}

@inproceedings{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={2160--2169},
  year={2019},
  organization={PMLR}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}
@book{bertsekas1996neuro,
    author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
    title = {Neuro-Dynamic Programming},
    year = {1996},
    isbn = {1886529108},
    publisher = {Athena Scientific},
    edition = {1st},
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000},
  organization={Citeseer}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{dann2014policy,
  title={Policy evaluation with temporal differences: A survey and comparison},
  author={Dann, Christoph and Neumann, Gerhard and Peters, Jan and others},
  journal={Journal of Machine Learning Research},
  volume={15},
  pages={809--883},
  year={2014},
  publisher={Massachusetts Institute of Technology Press (MIT Press)/Microtome Publishing}
}

@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}



@article{foster2020adapting,
  title={Adapting to misspecification in contextual bandits},
  author={Foster, Dylan J and Gentile, Claudio and Mohri, Mehryar and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11478--11489},
  year={2020}
}

@inproceedings{zanette2021exponential,
  title={Exponential lower bounds for batch reinforcement learning: Batch rl can be exponentially harder than online rl},
  author={Zanette, Andrea},
  booktitle={International Conference on Machine Learning},
  pages={12287--12297},
  year={2021},
  organization={PMLR}
}

@inproceedings{weisz2021exponential,
  title={Exponential lower bounds for planning in mdps with linearly-realizable optimal action-value functions},
  author={Weisz, Gell{\'e}rt and Amortila, Philip and Szepesv{\'a}ri, Csaba},
  booktitle={Algorithmic Learning Theory},
  pages={1237--1264},
  year={2021},
  organization={PMLR}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}


@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@article{uehara2021representation,
  title={Representation Learning for Online and Offline RL in Low-rank MDPs},
  author={Uehara, Masatoshi and Zhang, Xuezhou and Sun, Wen},
  journal={arXiv preprint arXiv:2110.04652},
  year={2021}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@article{neu2017unified,
  title={A unified view of entropy-regularized markov decision processes},
  author={Neu, Gergely and Jonsson, Anders and G{\'o}mez, Vicen{\c{c}}},
  journal={arXiv preprint arXiv:1705.07798},
  year={2017}
}

@article{simaan1973stackelberg,
  title={On the Stackelberg strategy in nonzero-sum games},
  author={Simaan, Marwaan and Cruz, Jose B},
  journal={Journal of Optimization Theory and Applications},
  volume={11},
  number={5},
  pages={533--555},
  year={1973},
  publisher={Springer}
}

@inproceedings{conitzer2006computing,
  title={Computing the optimal strategy to commit to},
  author={Conitzer, Vincent and Sandholm, Tuomas},
  booktitle={Proceedings of the 7th ACM conference on Electronic commerce},
  pages={82--90},
  year={2006}
}

@inproceedings{laroche2019safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning},
  pages={3652--3661},
  year={2019},
  organization={PMLR}
}

@book{von2010market,
  title={Market structure and equilibrium},
  author={Von Stackelberg, Heinrich},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@article{borkar1997stochastic,
  title={Stochastic approximation with two time scales},
  author={Borkar, Vivek S},
  journal={Systems \& Control Letters},
  volume={29},
  number={5},
  pages={291--294},
  year={1997},
  publisher={Elsevier}
}

@inproceedings{maei2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation.},
  author={Maei, Hamid Reza and Szepesvari, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S},
  booktitle={NIPS},
  pages={1204--1212},
  year={2009}
}

@inproceedings{swamy2021moments,
  title={Of moments and matching: A game-theoretic framework for closing the imitation gap},
  author={Swamy, Gokul and Choudhury, Sanjiban and Bagnell, J Andrew and Wu, Steven},
  booktitle={International Conference on Machine Learning},
  pages={10022--10032},
  year={2021},
  organization={PMLR}
}

@inproceedings{sun2017deeply,
  title={Deeply aggrevated: Differentiable imitation learning for sequential prediction},
  author={Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  booktitle={International Conference on Machine Learning},
  pages={3309--3318},
  year={2017},
  organization={PMLR}
}

@inproceedings{cheng2019predictor,
  title={Predictor-corrector policy optimization},
  author={Cheng, Ching-An and Yan, Xinyan and Ratliff, Nathan and Boots, Byron},
  booktitle={International Conference on Machine Learning},
  pages={1151--1161},
  year={2019},
  organization={PMLR}
}


@article{cheng2021heuristic,
  title={Heuristic-guided reinforcement learning},
  author={Cheng, Ching-An and Kolobov, Andrey and Swaminathan, Adith},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13550--13563},
  year={2021}
}

@inproceedings{schoknecht2003td,
  title={TD (0) converges provably faster than the residual gradient algorithm},
  author={Schoknecht, Ralf and Merke, Artur},
  booktitle={Proceedings of the 20th International Conference on Machine Learning (ICML-03)},
  pages={680--687},
  year={2003}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{cheng2020policy,
  title={Policy Improvement via Imitation of Multiple Oracles},
  author={Cheng, Ching-An and Kolobov, Andrey and Agarwal, Alekh},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}