\begin{thebibliography}{10}

\bibitem{karamcheti2023voltron}
Siddharth Karamcheti, Suraj Nair, Annie~S. Chen, Thomas Kollar, Chelsea Finn, Dorsa Sadigh, and Percy Liang.
\newblock Language-driven representation learning for robotics.
\newblock In {\em RSS}, 2023.

\bibitem{zeng2024learning}
Jia Zeng, Qingwen Bu, Bangjun Wang, Wenke Xia, Li~Chen, Hao Dong, Haoming Song, Dong Wang, Di~Hu, Ping Luo, Heming Cui, Bin Zhao, Xuelong Li, Yu~Qiao, and Hongyang Li.
\newblock Learning manipulation by predicting interaction.
\newblock {\em arXiv preprint arXiv:2406.00439}, 2024.

\bibitem{dasari2023unbiased}
Sudeep Dasari, Mohan~Kumar Srirama, Unnat Jain, and Abhinav Gupta.
\newblock An unbiased look at datasets for visuo-motor pre-training.
\newblock In {\em CoRL}, 2023.

\bibitem{wang2023robogen}
Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, Katerina Fragkiadaki, Zackory Erickson, David Held, and Chuang Gan.
\newblock {RoboGen}: Towards unleashing infinite data for automated robot learning via generative simulation.
\newblock {\em arXiv preprint arXiv:2311.01455}, 2023.

\bibitem{2023embodiedgpt}
Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin Wang, Jifeng Dai, Yu~Qiao, and Ping Luo.
\newblock {EmbodiedGPT}: Vision-language pre-training via embodied chain of thought.
\newblock In {\em NeurIPS}, 2023.

\bibitem{brohan2023rt2}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi~Chen, Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea Finn, et~al.
\newblock {RT-2}: Vision-language-action models transfer web knowledge to robotic control.
\newblock {\em arXiv preprint arXiv:2307.15818}, 2023.

\bibitem{reed2022generalist}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost~Tobias Springenberg, et~al.
\newblock A generalist agent.
\newblock {\em arXiv preprint arXiv:2205.06175}, 2022.

\bibitem{hafner2019dream}
Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi.
\newblock {Dream to Control}: Learning behaviors by latent imagination.
\newblock {\em arXiv preprint arXiv:1912.01603}, 2019.

\bibitem{haarnoja2018composable}
Tuomas Haarnoja, Vitchyr Pong, Aurick Zhou, Murtaza Dalal, Pieter Abbeel, and Sergey Levine.
\newblock Composable deep reinforcement learning for robotic manipulation.
\newblock In {\em ICRA}, 2018.

\bibitem{akkaya2019solving}
Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, et~al.
\newblock Solving rubik's cube with a robot hand.
\newblock {\em arXiv preprint arXiv:1910.07113}, 2019.

\bibitem{hu2023toward}
Yafei Hu, Quanting Xie, Vidhi Jain, Jonathan Francis, Jay Patrikar, Nikhil Keetha, Seungchan Kim, Yaqi Xie, Tianyi Zhang, Zhibo Zhao, et~al.
\newblock Toward general-purpose robots via foundation models: A survey and meta-analysis.
\newblock {\em arXiv preprint arXiv:2312.08782}, 2023.

\bibitem{li2024foundation}
Dingzhe Li, Yixiang Jin, Hongze Yu, Jun Shi, Xiaoshuai Hao, Peng Hao, Huaping Liu, Fuchun Sun, Bin Fang, et~al.
\newblock What foundation models can bring for robot learning in manipulation: A survey.
\newblock {\em arXiv preprint arXiv:2404.18201}, 2024.

\bibitem{driess2023palme}
Danny Driess, Fei Xia, Mehdi S.~M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, et~al.
\newblock {PaLM-E}: An embodied multimodal language model.
\newblock In {\em ICML}, 2023.

\bibitem{wang2024gensim}
Lirui Wang, Yiyang Ling, Zhecheng Yuan, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, and Xiaolong Wang.
\newblock {GenSim}: Generating robotic simulation tasks via large language models.
\newblock In {\em ICLR}, 2024.

\bibitem{du2024unipi}
Yilun Du, Sherry Yang, Bo~Dai, Hanjun Dai, Ofir Nachum, Josh Tenenbaum, Dale Schuurmans, and Pieter Abbeel.
\newblock Learning universal policies via text-guided video generation.
\newblock In {\em NeurIPS}, 2023.

\bibitem{black202susie}
Kevin Black, Mitsuhiko Nakamoto, Pranav Atreya, Homer~Rich Walke, Chelsea Finn, Aviral Kumar, and Sergey Levine.
\newblock Zero-shot robotic manipulation with pre-trained image-editing diffusion models.
\newblock In {\em ICLR}, 2024.

\bibitem{yang2023unisim}
Sherry Yang, Yilun Du, Seyed Kamyar~Seyed Ghasemipour, Jonathan Tompson, Leslie~Pack Kaelbling, Dale Schuurmans, and Pieter Abbeel.
\newblock Learning interactive real-world simulators.
\newblock In {\em ICLR}, 2024.

\bibitem{huang2022inner}
Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et~al.
\newblock {Inner Monologue}: Embodied reasoning through planning with language models.
\newblock In {\em CoRL}, 2022.

\bibitem{hawking1988ACS}
Kuo~B C and Golnaraghi~M F.
\newblock {\em Automatic control systems}.
\newblock Prentice hall, 1995.

\bibitem{ebert2018robustness}
Frederik Ebert, Sudeep Dasari, Alex~X Lee, Sergey Levine, and Chelsea Finn.
\newblock Robustness via retrying: Closed-loop robotic manipulation with self-supervised learning.
\newblock In {\em CoRL}, 2018.

\bibitem{schenck2017visual}
Connor Schenck and Dieter Fox.
\newblock Visual closed-loop control for pouring liquids.
\newblock In {\em ICRA}, 2017.

\bibitem{chen2021learning}
Annie~S Chen, Suraj Nair, and Chelsea Finn.
\newblock Learning generalizable robotic reward functions from" in-the-wild" human videos.
\newblock {\em arXiv preprint arXiv:2103.16817}, 2021.

\bibitem{radford2021clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em ICML}, 2021.

\bibitem{christiano2016transfer}
Paul Christiano, Zain Shah, Igor Mordatch, Jonas Schneider, Trevor Blackwell, Joshua Tobin, Pieter Abbeel, and Wojciech Zaremba.
\newblock Transfer from simulation to real world through learning deep inverse dynamics model.
\newblock {\em arXiv preprint arXiv:1610.03518}, 2016.

\bibitem{thananjeyan2020safety}
Brijen Thananjeyan, Ashwin Balakrishna, Ugo Rosolia, Felix Li, Rowan McAllister, Joseph~E Gonzalez, Sergey Levine, Francesco Borrelli, and Ken Goldberg.
\newblock Safety augmented value estimation from demonstrations (saved): Safe deep model-based rl for sparse cost robotic tasks.
\newblock {\em RA-L}, 2020.

\bibitem{erickson2018deep}
Zackory Erickson, Henry~M Clever, Greg Turk, C~Karen Liu, and Charles~C Kemp.
\newblock Deep haptic model predictive control for robot-assisted dressing.
\newblock In {\em ICRA}, 2018.

\bibitem{shin2019autonomous}
Changyeob Shin, Peter~Walker Ferguson, Sahba~Aghajani Pedram, Ji~Ma, Erik~P Dutson, and Jacob Rosen.
\newblock Autonomous tissue manipulation via surgical robot using learning based model predictive control.
\newblock In {\em ICRA}, 2019.

\bibitem{finn2017deep}
Chelsea Finn and Sergey Levine.
\newblock Deep visual foresight for planning robot motion.
\newblock In {\em ICRA}, 2017.

\bibitem{kennedy2017precise}
Monroe Kennedy, Kendall Queen, Dinesh Thakur, Kostas Daniilidis, and Vijay Kumar.
\newblock Precise dispensing of liquids using visual feedback.
\newblock In {\em IROS}, 2017.

\bibitem{ajay2024hip}
Anurag Ajay, Seungwook Han, Yilun Du, Shuang Li, Abhi Gupta, Tommi Jaakkola, Josh Tenenbaum, Leslie Kaelbling, Akash Srivastava, and Pulkit Agrawal.
\newblock Compositional foundation models for hierarchical planning.
\newblock In {\em NeurIPS}, 2023.

\bibitem{Ko2023Learning}
Po-Chen Ko, Jiayuan Mao, Yilun Du, Shao-Hua Sun, and Joshua~B. Tenenbaum.
\newblock {Learning to Act from Actionless Videos through Dense Correspondences}.
\newblock In {\em ICLR}, 2024.

\bibitem{singer2022make}
Uriel Singer, Adam Polyak, Thomas Hayes, Xi~Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et~al.
\newblock {Make-A-Video}: Text-to-video generation without text-video data.
\newblock In {\em ICLR}, 2023.

\bibitem{saharia2022imagen}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock In {\em NeurIPS}, 2022.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock {\em arXiv preprint arXiv:2207.12598}, 2022.

\bibitem{kent2020leveraging}
David Kent, Carl Saldanha, and Sonia Chernova.
\newblock Leveraging depth data in remote robot teleoperation interfaces for general object manipulation.
\newblock {\em IJRR}, 2020.

\bibitem{wang2022pretraining}
Tengfei Wang, Ting Zhang, Bo~Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, and Fang Wen.
\newblock Pretraining is all you need for image-to-image translation.
\newblock {\em arXiv preprint arXiv:2205.12952}, 2022.

\bibitem{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In {\em ICCV}, 2023.

\bibitem{padalkar2023open}
Abhishek Padalkar, Acorn Pooley, Ajinkya Jain, Alex Bewley, Alex Herzog, Alex Irpan, Alexander Khazatsky, Anant Rai, Anikait Singh, Anthony Brohan, et~al.
\newblock {Open X-Embodiment}: Robotic learning datasets and rt-x models.
\newblock {\em arXiv preprint arXiv:2310.08864}, 2023.

\bibitem{teed2020raft}
Zachary Teed and Jia Deng.
\newblock {RAFT}: Recurrent all-pairs field transforms for optical flow.
\newblock In {\em ECCV}, 2020.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em ICLR}, 2021.

\bibitem{hu2018squeeze}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In {\em ICCV}, 2018.

\bibitem{lee2019set}
Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee~Whye Teh.
\newblock {Set Transformer}: A framework for attention-based permutation-invariant neural networks.
\newblock In {\em ICML}, 2019.

\bibitem{cheon2015replacing}
Kangbeom Cheon, Jaehoon Kim, Moussa Hamadache, and Dongik Lee.
\newblock On replacing pid controller with deep learning controller for dc motor system.
\newblock {\em JOACE}, 2015.

\bibitem{pmlr-v70-pathak17a}
Deepak Pathak, Pulkit Agrawal, Alexei~A. Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In {\em ICML}, 2017.

\bibitem{lynch2020language}
Corey Lynch and Pierre Sermanet.
\newblock Language conditioned imitation learning over unstructured data.
\newblock In {\em RSS}, 2021.

\bibitem{mees2022hulc}
Oier Mees, Lukas Hermann, and Wolfram Burgard.
\newblock What matters in language conditioned robotic imitation learning over unstructured data.
\newblock {\em RA-L}, 2022.

\bibitem{brohan2022rt1}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, et~al.
\newblock {RT-1}: Robotics transformer for real-world control at scale.
\newblock {\em arXiv preprint arXiv:2212.06817}, 2022.

\bibitem{li2023roboflamingo}
Xinghang Li, Minghuan Liu, Hanbo Zhang, Cunjun Yu, Jie Xu, Hongtao Wu, Chilam Cheang, Ya~Jing, Weinan Zhang, Huaping Liu, Hang Li, and Tao Kong.
\newblock Vision-language foundation models as effective robot imitators.
\newblock In {\em ICLR}, 2024.

\bibitem{wu2023gr1}
Hongtao Wu, Ya~Jing, Chilam Cheang, Guangzeng Chen, Jiafeng Xu, Xinghang Li, Minghuan Liu, Hang Li, and Tao Kong.
\newblock Unleashing large-scale video generative pre-training for visual robot manipulation.
\newblock In {\em ICLR}, 2024.

\bibitem{ke2024_3DDiffuserActor}
Tsung-Wei Ke, Nikolaos Gkanatsios, and Katerina Fragkiadaki.
\newblock {3D Diffuser Actor}: Policy diffusion with 3d scene representations.
\newblock {\em arXiv preprint arXiv:2402.10885}, 2024.

\bibitem{zhao2023learning}
Tony~Z Zhao, Vikash Kumar, Sergey Levine, and Chelsea Finn.
\newblock Learning fine-grained bimanual manipulation with low-cost hardware.
\newblock In {\em RSS}, 2023.

\bibitem{nair2022r3m}
Suraj Nair, Aravind Rajeswaran, Vikash Kumar, Chelsea Finn, and Abhinav Gupta.
\newblock {R3M}: A universal visual representation for robot manipulation.
\newblock In {\em CoRL}, 2022.

\bibitem{mees2022calvin}
Oier Mees, Lukas Hermann, Erick Rosete-Beas, and Wolfram Burgard.
\newblock {CALVIN}: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks.
\newblock {\em RA-L}, 2022.

\bibitem{ma2023liv}
Yecheng~Jason Ma, Vikash Kumar, Amy Zhang, Osbert Bastani, and Dinesh Jayaraman.
\newblock {LIV}: Language-image representations and rewards for robotic control.
\newblock In {\em ICML}, 2023.

\bibitem{vc2023}
Arjun Majumdar, Karmesh Yadav, Sergio Arnaud, Jason Ma, Claire Chen, Sneha Silwal, Aryan Jain, Vincent-Pierre Berges, Tingfan Wu, Jay Vakil, et~al.
\newblock Where are we in the search for an artificial visual cortex for embodied intelligence?
\newblock In {\em NeurIPS}, 2023.

\bibitem{fan2019metrics}
Qiang Fan, Wang Luo, Yuan Xia, Guozhi Li, and Daojing He.
\newblock Metrics and methods of video quality assessment: a brief review.
\newblock {\em Multimedia Tools and Applications}, 2019.

\bibitem{walke2023bridgedata}
Homer~Rich Walke, Kevin Black, Tony~Z Zhao, Quan Vuong, Chongyi Zheng, Philippe Hansen-Estruch, Andre~Wang He, Vivek Myers, Moo~Jin Kim, Max Du, et~al.
\newblock {BridgeData} v2: A dataset for robot learning at scale.
\newblock In {\em CoRL}, 2023.

\bibitem{blattmann2023svd}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock {Stable Video Diffusion}: Scaling latent video diffusion models to large datasets.
\newblock {\em arXiv preprint arXiv:2311.15127}, 2023.

\bibitem{brandfonbrener2024inverse}
David Brandfonbrener, Ofir Nachum, and Joan Bruna.
\newblock Inverse dynamics pretraining learns good representations for multitask imitation.
\newblock In {\em NeurIPS}, 2024.

\bibitem{chi2023diffusion}
Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and Shuran Song.
\newblock {Diffusion Policy}: Visuomotor policy learning via action diffusion.
\newblock {\em arXiv preprint arXiv:2303.04137}, 2023.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{yang2024generalized}
Jiazhi Yang, Shenyuan Gao, Yihang Qiu, Li~Chen, Tianyu Li, Bo~Dai, Kashyap Chitta, Penghao Wu, Jia Zeng, Ping Luo, et~al.
\newblock Generalized predictive model for autonomous driving.
\newblock In {\em CVPR}, 2024.

\bibitem{sun2015human}
Lin Sun, Kui Jia, Dit-Yan Yeung, and Bertram~E Shi.
\newblock Human action recognition using factorized spatio-temporal convolutional networks.
\newblock In {\em ICCV}, 2015.

\bibitem{lai2018learning}
Wei-Sheng Lai, Jia-Bin Huang, Oliver Wang, Eli Shechtman, Ersin Yumer, and Ming-Hsuan Yang.
\newblock Learning blind video temporal consistency.
\newblock In {\em ECCV}, 2018.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timoth{\'e}e Darcet, Th{\'e}o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et~al.
\newblock {DINOv2}: Learning robust visual features without supervision.
\newblock {\em TMLR}, 2024.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In {\em NeurIPS}, 2020.

\bibitem{hang2023efficient}
Tiankai Hang, Shuyang Gu, Chen Li, Jianmin Bao, Dong Chen, Han Hu, Xin Geng, and Baining Guo.
\newblock Efficient diffusion training via min-snr weighting strategy.
\newblock In {\em ICCV}, 2023.

\bibitem{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In {\em ICLR}, 2021.

\end{thebibliography}
