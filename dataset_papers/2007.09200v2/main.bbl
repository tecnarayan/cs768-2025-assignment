\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
A.~Athalye, N.~Carlini, and D.~Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{ICML}, 2018.

\bibitem[Bengio(2019)]{bengio_consciousness_2019}
Y.~Bengio.
\newblock The consciousness prior.
\newblock \emph{arXiv:1709.08568}, 2019.

\bibitem[{Dodge} and {Karam}(2017)]{dodgedistortionperf}
S.~{Dodge} and L.~{Karam}.
\newblock A study and comparison of human and deep learning recognition
  performance under visual distortions.
\newblock In \emph{ICCCN}, 2017.

\bibitem[Eickenberg et~al.(2017)Eickenberg, Gramfort, Varoquaux, and
  Thirion]{eickenberg2017seeing}
M.~Eickenberg, A.~Gramfort, G.~Varoquaux, and B.~Thirion.
\newblock Seeing it all: Convolutional network layers map the function of the
  human visual system.
\newblock \emph{NeuroImage}, 2017.

\bibitem[Elsayed et~al.(2018)Elsayed, Shankar, Cheung, Papernot, Kurakin,
  Goodfellow, and Sohl-Dickstein]{elsayed2018adversarial}
G.~Elsayed, S.~Shankar, B.~Cheung, N.~Papernot, A.~Kurakin, I.~Goodfellow, and
  J.~Sohl-Dickstein.
\newblock Adversarial examples that fool both computer vision and time-limited
  humans.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Felleman and Van~Essen(1991)]{felleman_distributed_1991}
D.~J. Felleman and D.~C. Van~Essen.
\newblock Distributed hierarchical processing in the primate cerebral cortex.
\newblock \emph{Cerebral Cortex}, 1991.

\bibitem[George et~al.(2017)George, Lehrach, Kansky, Lázaro-Gredilla, Laan,
  Marthi, Lou, Meng, Liu, Wang, Lavin, and Phoenix]{george_generative_2017}
D.~George, W.~Lehrach, K.~Kansky, M.~Lázaro-Gredilla, C.~Laan, B.~Marthi,
  X.~Lou, Z.~Meng, Y.~Liu, H.~Wang, A.~Lavin, and D.~S. Phoenix.
\newblock A generative vision model that trains with high data efficiency and
  breaks text-based {CAPTCHAs}.
\newblock \emph{Science}, 2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{ICLR}, 2015.

\bibitem[Goyal et~al.(2019)Goyal, Lamb, Hoffmann, Sodhani, Levine, Bengio, and
  Schölkopf]{goyal2019recurrent}
A.~Goyal, A.~Lamb, J.~Hoffmann, S.~Sodhani, S.~Levine, Y.~Bengio, and
  B.~Schölkopf.
\newblock Recurrent independent mechanisms.
\newblock \emph{arXiv:1909.10893}, 2019.

\bibitem[Horikawa and Kamitani(2017)]{horikawa2017hierarchical}
T.~Horikawa and Y.~Kamitani.
\newblock Hierarchical neural representation of dreamed objects revealed by
  brain decoding with deep neural network features.
\newblock \emph{Front Comput Neurosci}, 2017.

\bibitem[Kar et~al.(2019)Kar, Kubilius, Schmidt, Issa, and
  DiCarlo]{kar2019evidence}
K.~Kar, J.~Kubilius, K.~Schmidt, E.~B. Issa, and J.~J. DiCarlo.
\newblock Evidence that recurrent circuits are critical to the ventral
  stream’s execution of core object recognition behavior.
\newblock \emph{Nature Neuroscience}, 2019.

\bibitem[Kietzmann et~al.(2019)Kietzmann, Spoerer, S{\"o}rensen, Cichy, Hauk,
  and Kriegeskorte]{kietzmann2019recurrence}
T.~C. Kietzmann, C.~J. Spoerer, L.~K. S{\"o}rensen, R.~M. Cichy, O.~Hauk, and
  N.~Kriegeskorte.
\newblock Recurrence is required to capture the representational dynamics of
  the human visual system.
\newblock \emph{PNAS}, 2019.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv:1412.6980}, 2014.

\bibitem[Knill and Richards(1996)]{knill1996perception}
D.~C. Knill and W.~Richards.
\newblock \emph{Perception as Bayesian inference}.
\newblock Cambridge University Press, 1996.

\bibitem[Kok et~al.(2012)Kok, Jehee, and De~Lange]{kok2012less}
P.~Kok, J.~F. Jehee, and F.~P. De~Lange.
\newblock Less is more: expectation sharpens representations in the primary
  visual cortex.
\newblock \emph{Neuron}, 2012.

\bibitem[Kubilius et~al.(2018)Kubilius, Schrimpf, Nayebi, Bear, Yamins, and
  DiCarlo]{kubilius_cornet_2018}
J.~Kubilius, M.~Schrimpf, A.~Nayebi, D.~Bear, D.~L. Yamins, and J.~J. DiCarlo.
\newblock Cornet: modeling the neural mechanisms of core object recognition.
\newblock \emph{bioRxiv preprint}, 2018.

\bibitem[Lamb et~al.(2019)Lamb, Binas, Goyal, Subramanian, Mitliagkas, Kazakov,
  Bengio, and Mozer]{lamb_state-reification_2019}
A.~Lamb, J.~Binas, A.~Goyal, S.~Subramanian, I.~Mitliagkas, D.~Kazakov,
  Y.~Bengio, and M.~C. Mozer.
\newblock State-reification networks: Improving generalization by modeling the
  distribution of hidden representations.
\newblock In \emph{ICML}, 2019.

\bibitem[Lee et~al.(2015)Lee, Zhang, Fischer, and Bengio]{lee2015difference}
D.-H. Lee, S.~Zhang, A.~Fischer, and Y.~Bengio.
\newblock Difference target propagation.
\newblock In \emph{ECML-PKDD}, 2015.

\bibitem[Linsley et~al.(2018)Linsley, Kim, Veerabadran, Windolf, and
  Serre]{linsley_learning_2018}
D.~Linsley, J.~Kim, V.~Veerabadran, C.~Windolf, and T.~Serre.
\newblock Learning long-range spatial dependencies with horizontal gated
  recurrent units.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv:1706.06083}, 2017.

\bibitem[Meng and Chen(2017)]{meng_magnet_2017}
D.~Meng and H.~Chen.
\newblock Magnet: a two-pronged defense against adversarial examples.
\newblock In \emph{CCS}, 2017.

\bibitem[Meulemans et~al.(2020)Meulemans, Carzaniga, Suykens, Sacramento, and
  Grewe]{meulemans2020theoretical}
A.~Meulemans, F.~S. Carzaniga, J.~A. Suykens, J.~Sacramento, and B.~F. Grewe.
\newblock A theoretical framework for target propagation.
\newblock \emph{arXiv:2006.14331}, 2020.

\bibitem[Mittal et~al.(2020)Mittal, Lamb, Goyal, Voleti, Shanahan, Lajoie,
  Mozer, and Bengio]{mittal2020learning}
S.~Mittal, A.~Lamb, A.~Goyal, V.~Voleti, M.~Shanahan, G.~Lajoie, M.~Mozer, and
  Y.~Bengio.
\newblock Learning to combine top-down and bottom-up signals in recurrent
  neural networks with attention over modules.
\newblock In \emph{ICML}, 2020.

\bibitem[Nayebi et~al.(2018)Nayebi, Bear, Kubilius, Kar, Ganguli, Sussillo,
  DiCarlo, and Yamins]{nayebi2018task}
A.~Nayebi, D.~Bear, J.~Kubilius, K.~Kar, S.~Ganguli, D.~Sussillo, J.~J.
  DiCarlo, and D.~L. Yamins.
\newblock Task-driven convolutional recurrent models of the visual system.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Nguyen et~al.(2018)Nguyen, Ho, Patel, Anandkumar, Jordan, and
  Baraniuk]{NRM}
T.~Nguyen, N.~Ho, A.~Patel, A.~Anandkumar, M.~I. Jordan, and R.~G. Baraniuk.
\newblock A bayesian perspective of convolutional neural networks through a
  deconvolutional generative model.
\newblock \emph{arXiv:1811.02657}, 2018.

\bibitem[Nimmagadda and Anandkumar(2015)]{nimmagadda2015multi}
T.~Nimmagadda and A.~Anandkumar.
\newblock Multi-object classification and unsupervised scene understanding
  using deep learning features and latent tree probabilistic models.
\newblock \emph{arXiv:1505.00308}, 2015.

\bibitem[Piekniewski et~al.(2016)Piekniewski, Laurent, Petre, Richert, Fisher,
  and Hylton]{piekniewski2016unsupervised}
F.~Piekniewski, P.~Laurent, C.~Petre, M.~Richert, D.~Fisher, and T.~Hylton.
\newblock Unsupervised learning from continuous video in a scalable predictive
  recurrent network.
\newblock \emph{arXiv:1607.06854}, 2016.

\bibitem[Rao and Ballard(1999)]{rao_predictive_1999}
R.~P.~N. Rao and D.~H. Ballard.
\newblock Predictive coding in the visual cortex: a functional interpretation
  of some extra-classical receptive-field effects.
\newblock \emph{Nature Neuroscience}, 1999.

\bibitem[Samangouei et~al.(2018)Samangouei, Kabkab, and
  Chellappa]{samangouei2018defense}
P.~Samangouei, M.~Kabkab, and R.~Chellappa.
\newblock Defense-gan: Protecting classifiers against adversarial attacks using
  generative models.
\newblock In \emph{ICLR}, 2018.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvaraju2017grad}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra.
\newblock {Grad-CAM}: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{ICCV}, 2017.

\bibitem[Sulam et~al.(2019)Sulam, Aberdam, Beck, and Elad]{sulam2019multi}
J.~Sulam, A.~Aberdam, A.~Beck, and M.~Elad.
\newblock On multi-layer basis pursuit, efficient algorithms and convolutional
  neural networks.
\newblock \emph{IEEE Trans. PAMI}, 2019.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{ICLR}, 2014.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy_rethinking_2015}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna.
\newblock Rethinking the inception archi-tecture for computer vision.
\newblock In \emph{CVPR}, 2016.

\bibitem[Uesato et~al.(2018)Uesato, O'Donoghue, Oord, and
  Kohli]{uesato2018adversarial}
J.~Uesato, B.~O'Donoghue, A.~v.~d. Oord, and P.~Kohli.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In \emph{ICML}, 2018.

\bibitem[Ulyanov et~al.(2016)Ulyanov, Vedaldi, and
  Lempitsky]{ulyanov2016instance}
D.~Ulyanov, A.~Vedaldi, and V.~Lempitsky.
\newblock Instance normalization: The missing ingredient for fast stylization.
\newblock \emph{arXiv:1607.08022}, 2016.

\bibitem[Wang et~al.(2018)Wang, Yamaguchi, and Ordonez]{wang2018feedback}
T.~Wang, K.~Yamaguchi, and V.~Ordonez.
\newblock Feedback-prop: Convolutional neural network inference under partial
  evidence.
\newblock In \emph{CVPR}, 2018.

\bibitem[Warde-Farley and Bengio(2017)]{warde-farley+al-2017-denoisegan-iclr}
D.~Warde-Farley and Y.~Bengio.
\newblock Improving generative adversarial networks with denoising feature
  matching.
\newblock In \emph{ICLR}, 2017.

\bibitem[Wen et~al.(2018)Wen, Han, Shi, Zhang, Culurciello, and
  Liu]{wen2018deep}
H.~Wen, K.~Han, J.~Shi, Y.~Zhang, E.~Culurciello, and Z.~Liu.
\newblock Deep predictive coding network for object recognition.
\newblock In \emph{ICML}, 2018.

\bibitem[Zagoruyko and Komodakis(2016)]{zagoruyko2016wide}
S.~Zagoruyko and N.~Komodakis.
\newblock Wide residual networks.
\newblock \emph{arXiv:1605.07146}, 2016.

\bibitem[Zamir et~al.(2017)Zamir, Wu, Sun, Shen, Shi, Malik, and
  Savarese]{zamir2017feedback}
A.~R. Zamir, T.-L. Wu, L.~Sun, W.~B. Shen, B.~E. Shi, J.~Malik, and
  S.~Savarese.
\newblock Feedback networks.
\newblock In \emph{CVPR}, 2017.

\end{thebibliography}
