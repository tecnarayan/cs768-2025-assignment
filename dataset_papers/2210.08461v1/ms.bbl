\begin{thebibliography}{10}

\bibitem{athey2016generalized}
Susan Athey, Julie Tibshirani, and Stefan Wager.
\newblock Generalized random forests.
\newblock {\em arXiv preprint: arXiv.1610.01271}, 2016.

\bibitem{bekker2020learning}
Jessa Bekker and Jesse Davis.
\newblock {Learning from positive and unlabeled data: A survey}.
\newblock {\em Machine Learning}, 109(4):719--760, 2020.

\bibitem{breiman2001random}
Leo Breiman.
\newblock Random forests.
\newblock {\em Machine learning}, 45(1):5--32, 2001.

\bibitem{CART}
Leo Breiman, Jerome~H Friedman, Richard~A Olshen, and Charles~J Stone.
\newblock {\em Classification and regression trees}.
\newblock Routledge, 2017.

\bibitem{libsvm}
Chih-Chung Chang and Chih-Jen Lin.
\newblock Libsvm: a library for support vector machines.
\newblock {\em ACM transactions on intelligent systems and technology (TIST)},
  2(3):1--27, 2011.

\bibitem{chen2020self}
Xuxi Chen, Wuyang Chen, Tianlong Chen, Ye~Yuan, Chen Gong, Kewei Chen, and
  Zhangyang Wang.
\newblock Self-pu: Self boosted and calibrated positive-unlabeled training.
\newblock In {\em International Conference on Machine Learning}, pages
  1510--1519. PMLR, 2020.

\bibitem{prior-estimation1}
Marthinus Christoffel, Gang Niu, and Masashi Sugiyama.
\newblock Class-prior estimation for learning from positive and unlabeled data.
\newblock In {\em Asian Conference on Machine Learning}, pages 221--236. PMLR,
  2016.

\bibitem{comite1999positive}
Francesco~De Comit{\'e}, Fran{\c{c}}ois Denis, R{\'e}mi Gilleron, and Fabien
  Letouzey.
\newblock {Positive and unlabeled examples help learning}.
\newblock In {\em International conference on algorithmic learning theory},
  pages 219--230. Springer, 1999.

\bibitem{denis1998pac}
Fran{\c{c}}ois Denis.
\newblock {PAC learning from positive statistical queries}.
\newblock In {\em International conference on algorithmic learning theory},
  pages 112--126. Springer, 1998.

\bibitem{du2015convex}
Marthinus Du~Plessis, Gang Niu, and Masashi Sugiyama.
\newblock Convex formulation for learning from positive and unlabeled data.
\newblock In {\em International conference on machine learning}, pages
  1386--1394. PMLR, 2015.

\bibitem{du2014analysis}
Marthinus~C Du~Plessis, Gang Niu, and Masashi Sugiyama.
\newblock Analysis of learning from positive and unlabeled data.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem{elkan2008learning}
Charles Elkan and Keith Noto.
\newblock Learning classifiers from only positive and unlabeled data.
\newblock In {\em Proceedings of the 14th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 213--220, 2008.

\bibitem{geurts2006extremely}
Pierre Geurts, Damien Ernst, and Louis Wehenkel.
\newblock Extremely randomized trees.
\newblock {\em Machine learning}, 63(1):3--42, 2006.

\bibitem{relu2}
Boris Hanin and Mark Sellke.
\newblock Approximating continuous functions by relu nets of minimal width.
\newblock {\em arXiv preprint arXiv:1710.11278}, 2017.

\bibitem{he2018instance}
Fengxiang He, Tongliang Liu, Geoffrey~I Webb, and Dacheng Tao.
\newblock {Instance-dependent pu learning by bayesian optimal relabeling}.
\newblock {\em arXiv preprint arXiv:1808.02180}, 2018.

\bibitem{kiryo2017positive}
Ryuichi Kiryo, Gang Niu, Marthinus C~du Plessis, and Masashi Sugiyama.
\newblock Positive-unlabeled learning with non-negative risk estimator.
\newblock {\em arXiv preprint arXiv:1703.00593}, 2017.

\bibitem{cifar-10}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{relu1}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{mnist}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lee2003learning}
Wee~Sun Lee and Bing Liu.
\newblock {Learning with positive and unlabeled examples using weighted
  logistic regression}.
\newblock In {\em ICML}, volume~3, pages 448--455, 2003.

\bibitem{letouzey2000learning}
Fabien Letouzey, Fran{\c{c}}ois Denis, and R{\'e}mi Gilleron.
\newblock {Learning from positive and unlabeled examples}.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  pages 71--85. Springer, 2000.

\bibitem{liu2003building}
Bing Liu, Yang Dai, Xiaoli Li, Wee~Sun Lee, and Philip~S Yu.
\newblock {Building text classifiers using positive and unlabeled examples}.
\newblock In {\em Third IEEE international conference on data mining}, pages
  179--186. IEEE, 2003.

\bibitem{mordelet2014bagging}
Fantine Mordelet and J-P Vert.
\newblock A bagging svm to learn from positive and unlabeled examples.
\newblock {\em Pattern Recognition Letters}, 37:201--209, 2014.

\bibitem{mordelet2011prodige}
Fantine Mordelet and Jean-Philippe Vert.
\newblock {Prodige: Prioritization of disease genes with multitask machine
  learning from positive and unlabeled examples}.
\newblock {\em BMC bioinformatics}, 12(1):1--15, 2011.

\bibitem{unsw1}
Nour Moustafa and Jill Slay.
\newblock Unsw-nb15: a comprehensive data set for network intrusion detection
  systems (unsw-nb15 network data set).
\newblock In {\em 2015 military communications and information systems
  conference (MilCIS)}, pages 1--6. IEEE, 2015.

\bibitem{sklearn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{glove}
Jeffrey Pennington, Richard Socher, and Christopher~D Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem{prior-estimation2}
Harish Ramaswamy, Clayton Scott, and Ambuj Tewari.
\newblock Mixture proportion estimation via kernel embeddings of distributions.
\newblock In {\em International conference on machine learning}, pages
  2052--2060. PMLR, 2016.

\bibitem{wu2021landslide}
Bangyu Wu, Weirong Qiu, Junxiong Jia, and Naihao Liu.
\newblock Landslide susceptibility modeling using bagging-based
  positive-unlabeled learning.
\newblock {\em IEEE Geoscience and Remote Sensing Letters}, 18(5):766--770,
  2021.

\bibitem{wu2018hpsd}
Zhiang Wu, Jie Cao, Yaqiong Wang, Youquan Wang, Lu~Zhang, and Junjie Wu.
\newblock hpsd: a hybrid pu-learning-based spammer detection model for product
  reviews.
\newblock {\em IEEE transactions on cybernetics}, 50(4):1595--1606, 2018.

\end{thebibliography}
