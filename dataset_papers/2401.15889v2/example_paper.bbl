\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.(2022)Bai, Schmitzer, Thorpe, and Kolouri]{bai2022sliced}
Bai, Y., Schmitzer, B., Thorpe, M., and Kolouri, S.
\newblock Sliced optimal partial transport.
\newblock \emph{arXiv preprint arXiv:2212.08049}, 2022.

\bibitem[Bai et~al.(2023)Bai, Tran, Damelin, and Kolouri]{bai2023partial}
Bai, Y., Tran, H., Damelin, S.~B., and Kolouri, S.
\newblock Partial transport for point-cloud registration.
\newblock \emph{arXiv preprint arXiv:2309.15787}, 2023.

\bibitem[Bonet et~al.(2022)Bonet, Courty, Septier, and
  Drumetz]{bonet2022efficient}
Bonet, C., Courty, N., Septier, F., and Drumetz, L.
\newblock Efficient gradient flows in sliced-{W}asserstein space.
\newblock \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Bonet et~al.(2023{\natexlab{a}})Bonet, Berg, Courty, Septier, Drumetz,
  and Pham]{bonet2022spherical}
Bonet, C., Berg, P., Courty, N., Septier, F., Drumetz, L., and Pham, M.-T.
\newblock Spherical sliced-{W}asserstein.
\newblock \emph{International Conference on Learning Representations},
  2023{\natexlab{a}}.

\bibitem[Bonet et~al.(2023{\natexlab{b}})Bonet, Chapel, Drumetz, and
  Courty]{bonet2023hyperbolic}
Bonet, C., Chapel, L., Drumetz, L., and Courty, N.
\newblock Hyperbolic sliced-wasserstein via geodesic and horospherical
  projections.
\newblock In \emph{Topological, Algebraic and Geometric Learning Workshops
  2023}, pp.\  334--370. PMLR, 2023{\natexlab{b}}.

\bibitem[Bonet et~al.(2023{\natexlab{c}})Bonet, Mal{\'e}zieux, Rakotomamonjy,
  Drumetz, Moreau, Kowalski, and Courty]{bonet2023sliced}
Bonet, C., Mal{\'e}zieux, B., Rakotomamonjy, A., Drumetz, L., Moreau, T.,
  Kowalski, M., and Courty, N.
\newblock Sliced-wasserstein on symmetric positive definite matrices for m/eeg
  signals.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2777--2805. PMLR, 2023{\natexlab{c}}.

\bibitem[Bonneel \& Coeurjolly(2019)Bonneel and Coeurjolly]{bonneel2019spot}
Bonneel, N. and Coeurjolly, D.
\newblock Spot: sliced partial optimal transport.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 38\penalty0 (4):\penalty0
  1--13, 2019.

\bibitem[Bonneel et~al.(2015)Bonneel, Rabin, Peyr{\'e}, and
  Pfister]{bonneel2015sliced}
Bonneel, N., Rabin, J., Peyr{\'e}, G., and Pfister, H.
\newblock Sliced and {R}adon {W}asserstein barycenters of measures.
\newblock \emph{Journal of Mathematical Imaging and Vision}, 1\penalty0
  (51):\penalty0 22--45, 2015.

\bibitem[Bonnotte(2013)]{bonnotte2013unidimensional}
Bonnotte, N.
\newblock \emph{Unidimensional and evolution methods for optimal
  transportation}.
\newblock PhD thesis, Paris 11, 2013.

\bibitem[Cao et~al.(2018)Cao, Ma, Long, and Wang]{cao2018partial}
Cao, Z., Ma, L., Long, M., and Wang, J.
\newblock Partial adversarial domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  135--150, 2018.

\bibitem[De~Cao \& Aziz(2020)De~Cao and Aziz]{de2020power}
De~Cao, N. and Aziz, W.
\newblock The power spherical distribution.
\newblock \emph{arXiv preprint arXiv:2006.04437}, 2020.

\bibitem[Deshpande et~al.(2018)Deshpande, Zhang, and
  Schwing]{deshpande2018generative}
Deshpande, I., Zhang, Z., and Schwing, A.~G.
\newblock Generative modeling using the sliced {W}asserstein distance.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3483--3491, 2018.

\bibitem[Deshpande et~al.(2019)Deshpande, Hu, Sun, Pyrros, Siddiqui, Koyejo,
  Zhao, Forsyth, and Schwing]{deshpande2019max}
Deshpande, I., Hu, Y.-T., Sun, R., Pyrros, A., Siddiqui, N., Koyejo, S., Zhao,
  Z., Forsyth, D., and Schwing, A.~G.
\newblock Max-sliced {W}asserstein distance and its use for {GAN}s.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  10648--10656, 2019.

\bibitem[Devroye et~al.(2013)Devroye, Gy{\"o}rfi, and
  Lugosi]{devroye2013probabilistic}
Devroye, L., Gy{\"o}rfi, L., and Lugosi, G.
\newblock \emph{A probabilistic theory of pattern recognition}, volume~31.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Du et~al.(2023)Du, Li, Pang, Yan, and Lin]{du2023nonparametric}
Du, C., Li, T., Pang, T., Yan, S., and Lin, M.
\newblock Nonparametric generative modeling with conditional sliced-wasserstein
  flows.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8565--8584. PMLR, 2023.

\bibitem[Feydy et~al.(2019)Feydy, S{\'e}journ{\'e}, Vialard, Amari, Trouve, and
  Peyr{\'e}]{feydy2019interpolating}
Feydy, J., S{\'e}journ{\'e}, T., Vialard, F.-X., Amari, S.-i., Trouve, A., and
  Peyr{\'e}, G.
\newblock Interpolating between optimal transport and {MMD} using {S}inkhorn
  divergences.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pp.\  2681--2690, 2019.

\bibitem[Flamary et~al.(2021)Flamary, Courty, Gramfort, Alaya, Boisbunon,
  Chambon, Chapel, Corenflos, Fatras, Fournier, Gautheron, Gayraud, Janati,
  Rakotomamonjy, Redko, Rolet, Schutz, Seguy, Sutherland, Tavenard, Tong, and
  Vayer]{flamary2021pot}
Flamary, R., Courty, N., Gramfort, A., Alaya, M.~Z., Boisbunon, A., Chambon,
  S., Chapel, L., Corenflos, A., Fatras, K., Fournier, N., Gautheron, L.,
  Gayraud, N.~T., Janati, H., Rakotomamonjy, A., Redko, I., Rolet, A., Schutz,
  A., Seguy, V., Sutherland, D.~J., Tavenard, R., Tong, A., and Vayer, T.
\newblock Pot: Python optimal transport.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (78):\penalty0 1--8, 2021.
\newblock URL \url{http://jmlr.org/papers/v22/20-451.html}.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2672--2680, 2014.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock {GAN}s trained by a two time-scale update rule converge to a local
  {N}ash equilibrium.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6626--6637, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Jupp \& Mardia(1979)Jupp and Mardia]{jupp1979maximum}
Jupp, P.~E. and Mardia, K.~V.
\newblock Maximum likelihood estimators for the matrix von {M}ises-{F}isher and
  bingham distributions.
\newblock \emph{The Annals of Statistics}, 7\penalty0 (3):\penalty0 599--606,
  1979.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kolouri et~al.(2018)Kolouri, Rohde, and
  Hoffmann]{kolouri2018slicedgmm}
Kolouri, S., Rohde, G.~K., and Hoffmann, H.
\newblock Sliced {W}asserstein distance for learning {G}aussian mixture models.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3427--3436, 2018.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Master's thesis, Department of Computer Science, University of
  Toronto}, 2009.

\bibitem[Le et~al.(2024{\natexlab{a}})Le, Nguyen, Sun, Ho, and
  Xie]{le2024integrating}
Le, T., Nguyen, K., Sun, S., Ho, N., and Xie, X.
\newblock Integrating efficient optimal transport and functional maps for
  unsupervised shape correspondence learning.
\newblock \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2024{\natexlab{a}}.

\bibitem[Le et~al.(2024{\natexlab{b}})Le, Nguyen, shanlin sun, Han, Ho, and
  Xie]{le2024diffeomorphic}
Le, T.~T., Nguyen, K., shanlin sun, Han, K., Ho, N., and Xie, X.
\newblock Diffeomorphic mesh deformation via efficient optimal transport for
  cortical surface reconstruction.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2024{\natexlab{b}}.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee et~al.(2019)Lee, Batra, Baig, and Ulbricht]{lee2019sliced}
Lee, C.-Y., Batra, T., Baig, M.~H., and Ulbricht, D.
\newblock Sliced {W}asserstein discrepancy for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10285--10295, 2019.

\bibitem[McCann(1997)]{mccann1997convexity}
McCann, R.~J.
\newblock A convexity principle for interacting gases.
\newblock \emph{Advances in mathematics}, 128\penalty0 (1):\penalty0 153--179,
  1997.

\bibitem[Nadjahi et~al.(2019)Nadjahi, Durmus, Simsekli, and
  Badeau]{nadjahi2019asymptotic}
Nadjahi, K., Durmus, A., Simsekli, U., and Badeau, R.
\newblock Asymptotic guarantees for learning generative models with the
  sliced-{W}asserstein distance.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  250--260, 2019.

\bibitem[Nadjahi et~al.(2020{\natexlab{a}})Nadjahi, De~Bortoli, Durmus, Badeau,
  and {\c{S}}im{\c{s}}ekli]{nadjahi2020approximate}
Nadjahi, K., De~Bortoli, V., Durmus, A., Badeau, R., and {\c{S}}im{\c{s}}ekli,
  U.
\newblock Approximate {B}ayesian computation with the sliced-{W}asserstein
  distance.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  5470--5474. IEEE,
  2020{\natexlab{a}}.

\bibitem[Nadjahi et~al.(2020{\natexlab{b}})Nadjahi, Durmus, Chizat, Kolouri,
  Shahrampour, and Simsekli]{nadjahi2020statistical}
Nadjahi, K., Durmus, A., Chizat, L., Kolouri, S., Shahrampour, S., and
  Simsekli, U.
\newblock Statistical and topological properties of sliced probability
  divergences.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 20802--20812, 2020{\natexlab{b}}.

\bibitem[Nguyen \& Ho(2022)Nguyen and Ho]{nguyen2022revisiting}
Nguyen, K. and Ho, N.
\newblock Revisiting sliced {W}asserstein on images: From vectorization to
  convolution.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Nguyen \& Ho(2023)Nguyen and Ho]{nguyen2023energy}
Nguyen, K. and Ho, N.
\newblock Energy-based sliced {W}asserstein distance.
\newblock \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Nguyen et~al.(2021)Nguyen, Ho, Pham, and
  Bui]{nguyen2021distributional}
Nguyen, K., Ho, N., Pham, T., and Bui, H.
\newblock Distributional sliced-{W}asserstein and applications to generative
  modeling.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Nguyen et~al.(2023)Nguyen, Ren, and Ho]{nguyen2023markovian}
Nguyen, K., Ren, T., and Ho, N.
\newblock Markovian sliced {W}asserstein distances: Beyond independent
  projections.
\newblock \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Nguyen et~al.(2024)Nguyen, Bariletto, and Ho]{nguyen2023quasi}
Nguyen, K., Bariletto, N., and Ho, N.
\newblock Quasi-monte carlo for 3d sliced wasserstein.
\newblock \emph{International Conference on Learning Representations}, 2024.

\bibitem[Nietert et~al.(2022)Nietert, Sadhu, Goldfeld, and
  Kato]{nietert2022statistical}
Nietert, S., Sadhu, R., Goldfeld, Z., and Kato, K.
\newblock Statistical, robustness, and computational guarantees for sliced
  {W}asserstein distances.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Paulin et~al.(2020)Paulin, Bonneel, Coeurjolly, Iehl, Webanck,
  Desbrun, and Ostromoukhov]{paulin2020sliced}
Paulin, L., Bonneel, N., Coeurjolly, D., Iehl, J.-C., Webanck, A., Desbrun, M.,
  and Ostromoukhov, V.
\newblock Sliced optimal transport sampling.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 39\penalty0 (4):\penalty0
  99--1, 2020.

\bibitem[Peyré \& Cuturi(2020)Peyré and Cuturi]{peyre2020computational}
Peyré, G. and Cuturi, M.
\newblock Computational optimal transport, 2020.

\bibitem[Salimans et~al.(2018)Salimans, Zhang, Radford, and
  Metaxas]{salimans2018improving}
Salimans, T., Zhang, H., Radford, A., and Metaxas, D.
\newblock Improving {GAN}s using optimal transport.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Santambrogio(2015)]{santambrogio2015optimal}
Santambrogio, F.
\newblock Optimal transport for applied mathematicians.
\newblock \emph{Birk{\"a}user, NY}, 55\penalty0 (58-63):\penalty0 94, 2015.

\bibitem[Savkin et~al.(2022)Savkin, Wang, Wirkert, Navab, and
  Tombari]{savkin2022lidar}
Savkin, A., Wang, Y., Wirkert, S., Navab, N., and Tombari, F.
\newblock Lidar upsampling with sliced {W}asserstein distance.
\newblock \emph{IEEE Robotics and Automation Letters}, 8\penalty0 (1):\penalty0
  392--399, 2022.

\bibitem[S{\'e}journ{\'e} et~al.(2023)S{\'e}journ{\'e}, Bonet, Fatras, Nadjahi,
  and Courty]{sejourne2023unbalanced}
S{\'e}journ{\'e}, T., Bonet, C., Fatras, K., Nadjahi, K., and Courty, N.
\newblock Unbalanced optimal transport meets sliced-{W}asserstein.
\newblock \emph{arXiv preprint arXiv:2306.07176}, 2023.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pp.\
  2256--2265. PMLR, 2015.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Meng, and
  Ermon]{song2020denoising}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{a}}.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Sohl-Dickstein, Kingma, Kumar,
  Ermon, and Poole]{song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{b}}.

\bibitem[Tanguy(2023)]{tanguy2023convergence}
Tanguy, E.
\newblock Convergence of sgd for training neural networks with sliced
  {W}asserstein losses.
\newblock \emph{arXiv preprint arXiv:2307.11714}, 2023.

\bibitem[Vahdat et~al.(2021)Vahdat, Kreis, and Kautz]{vahdat2021score}
Vahdat, A., Kreis, K., and Kautz, J.
\newblock Score-based generative modeling in latent space.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11287--11302, 2021.

\bibitem[Villani(2008)]{Villani-09}
Villani, C.
\newblock \emph{Optimal transport: Old and New}.
\newblock Springer, 2008.

\bibitem[Wainwright(2019)]{wainwrighthigh}
Wainwright, M.~J.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint}.
\newblock Cambridge University Press, 2019.

\bibitem[Xiao et~al.(2021)Xiao, Kreis, and Vahdat]{xiao2021tackling}
Xiao, Z., Kreis, K., and Vahdat, A.
\newblock Tackling the generative learning trilemma with denoising diffusion
  gans.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Yi \& Liu(2021)Yi and Liu]{yi2021sliced}
Yi, M. and Liu, S.
\newblock Sliced {W}asserstein variational inference.
\newblock In \emph{Fourth Symposium on Advances in Approximate Bayesian
  Inference}, 2021.

\end{thebibliography}
