\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahle et~al.(2020)Ahle, Kapralov, Knudsen, Pagh, Velingker, Woodruff,
  and Zandieh]{ahle_treesketch}
Thomas~D. Ahle, Michael Kapralov, Jakob B.~T. Knudsen, Rasmus Pagh, Ameya
  Velingker, David~P. Woodruff, and Amir Zandieh.
\newblock \emph{Oblivious Sketching of High-Degree Polynomial Kernels}, pages
  141--160.
\newblock Society for Industrial and Applied Mathematics, 2020.
\newblock \doi{10.1137/1.9781611975994.9}.

\bibitem[Ailon and Chazelle(2009)]{fjlt}
Nir Ailon and Bernard Chazelle.
\newblock The fast {J}ohnson--{L}indenstrauss transform and approximate nearest
  neighbors.
\newblock \emph{SIAM Journal on computing}, 39\penalty0 (1):\penalty0 302--322,
  2009.

\bibitem[Bader and Kolda(2008)]{ttoolbox_sparse}
Brett~W. Bader and Tamara~G. Kolda.
\newblock Efficient matlab computations with sparse and factored tensors.
\newblock \emph{SIAM Journal on Scientific Computing}, 30\penalty0
  (1):\penalty0 205--231, 2008.
\newblock \doi{10.1137/060676489}.

\bibitem[Battaglino et~al.(2018)Battaglino, Ballard, and
  Kolda]{battaglino_practical}
Casey Battaglino, Grey Ballard, and Tamara~G. Kolda.
\newblock A practical randomized {CP} tensor decomposition.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 39\penalty0
  (2):\penalty0 876--901, 2018.
\newblock \doi{10.1137/17M1112303}.

\bibitem[Chen et~al.(2020)Chen, Li, Newton, and Wright]{pde_inverse_sketching}
Ke~Chen, Qin Li, Kit Newton, and Stephen~J. Wright.
\newblock Structured random sketching for {PDE} inverse problems.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 41\penalty0
  (4):\penalty0 1742--1770, 2020.
\newblock \doi{10.1137/20M1310497}.

\bibitem[Cheng et~al.(2016)Cheng, Peng, Liu, and Perros]{cheng_spals_2016}
Dehua Cheng, Richard Peng, Yan Liu, and Ioakeim Perros.
\newblock {SPALS}: Fast alternating least squares via implicit leverage scores
  sampling.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  volume~29. Curran Associates, Inc., 2016.

\bibitem[Diao et~al.(2019)Diao, Jayaram, Song, Sun, and
  Woodruff]{woodruff_optimal_kronecker}
Huaian Diao, Rajesh Jayaram, Zhao Song, Wen Sun, and David Woodruff.
\newblock Optimal sketching for {K}ronecker product regression and low rank
  approximation.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32. Curran Associates, Inc., 2019.

\bibitem[Drineas et~al.(2012)Drineas, Magdon-Ismail, Mahoney, and
  Woodruff]{drines_fast_leverage_scores}
Petros Drineas, Malik Magdon-Ismail, Michael~W. Mahoney, and David~P. Woodruff.
\newblock Fast approximation of matrix coherence and statistical leverage.
\newblock \emph{J. Mach. Learn. Res.}, 13\penalty0 (1):\penalty0 3475–3506,
  dec 2012.
\newblock ISSN 1532-4435.

\bibitem[Fahrbach et~al.(2022)Fahrbach, Fu, and
  Ghadiri]{subquadratic_kronecker_regression}
Matthew Fahrbach, Gang Fu, and Mehrdad Ghadiri.
\newblock Subquadratic {K}ronecker regression with applications to tensor
  decomposition.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 28776--28789. Curran Associates, Inc., 2022.

\bibitem[Haidar et~al.(2015)Haidar, Dong, Tomov, Luszczek, and
  Dongarra]{magma_batched}
Azzam Haidar, Tingxing Dong, Stanimire Tomov, Piotr Luszczek, and Jack
  Dongarra.
\newblock Framework for batched and {GPU}-resident factorization algorithms to
  block {H}ouseholder transformations.
\newblock In \emph{ISC High Performance}, Frankfurt, Germany, 07-2015 2015.
  Springer, Springer.

\bibitem[Halko et~al.(2011)Halko, Martinsson, and Tropp]{halko_rrf}
N.~Halko, P.~G. Martinsson, and J.~A. Tropp.
\newblock Finding structure with randomness: Probabilistic algorithms for
  constructing approximate matrix decompositions.
\newblock \emph{SIAM Review}, 53\penalty0 (2):\penalty0 217--288, 2011.
\newblock \doi{10.1137/090771806}.

\bibitem[Jin et~al.(2020)Jin, Kolda, and Ward]{jin_faster_2020}
Ruhui Jin, Tamara~G Kolda, and Rachel Ward.
\newblock Faster {Johnson}–{Lindenstrauss} transforms via {Kronecker}
  products.
\newblock \emph{Information and Inference: A Journal of the IMA}, 10\penalty0
  (4):\penalty0 1533--1562, October 2020.
\newblock ISSN 2049-8772.
\newblock \doi{10.1093/imaiai/iaaa028}.

\bibitem[Kolda and Bader(2009)]{kolda_tensor_overview}
Tamara~G. Kolda and Brett~W. Bader.
\newblock Tensor decompositions and applications.
\newblock \emph{SIAM Review}, 51\penalty0 (3):\penalty0 455--500, August 2009.
\newblock ISSN 0036-1445.
\newblock \doi{10.1137/07070111X}.
\newblock Publisher: Society for Industrial and Applied Mathematics.

\bibitem[Kossaifi et~al.(2019)Kossaifi, Panagakis, Anandkumar, and
  Pantic]{tensorly}
Jean Kossaifi, Yannis Panagakis, Anima Anandkumar, and Maja Pantic.
\newblock Tensorly: Tensor learning in python.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 20\penalty0 (26),
  2019.

\bibitem[Larsen and Kolda(2022)]{larsen_practical_2022}
Brett~W. Larsen and Tamara~G. Kolda.
\newblock Practical leverage-based sampling for low-rank tensor decomposition.
\newblock \emph{SIAM J. Matrix Analysis and Applications}, 43\penalty0
  (3):\penalty0 1488--1517, August 2022.
\newblock \doi{10.1137/21M1441754}.

\bibitem[Liu and Trenkler(2008)]{krp_survey}
Shuangzhe Liu and G{\"o}tz Trenkler.
\newblock {H}adamard, {K}hatri-{R}ao, {K}ronecker and other matrix products.
\newblock \emph{International Journal of Information and Systems Sciences},
  4\penalty0 (1):\penalty0 160--177, 2008.

\bibitem[Ma and Solomonik(2022)]{ma_cost_efficient_embedding}
Linjian Ma and Edgar Solomonik.
\newblock Cost-efficient gaussian tensor network embeddings for
  tensor-structured inputs.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 38980--38993. Curran Associates, Inc., 2022.

\bibitem[Malik(2022)]{malik_efficient_2022}
Osman~Asif Malik.
\newblock More efficient sampling for tensor decomposition with worst-case
  guarantees.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, volume 162 of \emph{Proceedings of Machine Learning Research},
  pages 14887--14917. PMLR, 17--23 Jul 2022.

\bibitem[Malik et~al.(2022)Malik, Bharadwaj, and Murray]{malik_tns_cp}
Osman~Asif Malik, Vivek Bharadwaj, and Riley Murray.
\newblock Sampling-based decomposition algorithms for arbitrary tensor
  networks, October 2022.
\newblock arXiv:2210.03828 [cs, math].

\bibitem[Murray et~al.(2023)Murray, Demmel, Mahoney, Erichson, Melnichenko,
  Malik, Grigori, Luszczek, Dereziński, Lopes, Liang, Luo, and
  Dongarra]{murray2023randomized}
Riley Murray, James Demmel, Michael~W. Mahoney, N.~Benjamin Erichson, Maksim
  Melnichenko, Osman~Asif Malik, Laura Grigori, Piotr Luszczek, Michał
  Dereziński, Miles~E. Lopes, Tianyu Liang, Hengrui Luo, and Jack Dongarra.
\newblock Randomized numerical linear algebra : A perspective on the field with
  an eye to software, 2023.

\bibitem[Reddy et~al.(2022)Reddy, Song, and Zhang]{dynamic_kron_regression}
Aravind Reddy, Zhao Song, and Lichen Zhang.
\newblock Dynamic tensor product regression.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 4791--4804. Curran Associates, Inc., 2022.

\bibitem[Saad et~al.(2020)Saad, Freer, Rinard, and
  Mansinghka]{saad_optimal_2020}
Feras~A. Saad, Cameron~E. Freer, Martin~C. Rinard, and Vikash~K. Mansinghka.
\newblock Optimal approximate sampling from discrete probability distributions.
\newblock \emph{Proceedings of the ACM on Programming Languages}, 4\penalty0
  (POPL):\penalty0 1--31, January 2020.
\newblock ISSN 2475-1421.
\newblock \doi{10.1145/3371104}.

\bibitem[Sidiropoulos and Budampati(2002)]{krp_signal_processing}
N.D. Sidiropoulos and R.S. Budampati.
\newblock {K}hatri-{R}ao space-time codes.
\newblock \emph{IEEE Transactions on Signal Processing}, 50\penalty0
  (10):\penalty0 2396--2407, 2002.
\newblock \doi{10.1109/TSP.2002.803341}.

\bibitem[Smith and Karypis(2016)]{splattsoftware}
Shaden Smith and George Karypis.
\newblock {SPLATT: The Surprisingly ParalleL spArse Tensor Toolkit}.
\newblock \url{https://github.com/ShadenSmith/splatt}, 2016.

\bibitem[Smith et~al.(2017)Smith, Choi, Li, Vuduc, Park, Liu, and
  Karypis]{frosttdataset}
Shaden Smith, Jee~W. Choi, Jiajia Li, Richard Vuduc, Jongsoo Park, Xing Liu,
  and George Karypis.
\newblock {FROSTT}: The formidable repository of open sparse tensors and tools,
  2017.
\newblock URL \url{http://frostt.io/}.

\bibitem[Song et~al.(2022)Song, Chi, Sohrabizadeh, Choi, Lau, and
  Cong]{spmm_accelerator}
Linghao Song, Yuze Chi, Atefeh Sohrabizadeh, Young-kyu Choi, Jason Lau, and
  Jason Cong.
\newblock Sextans: A streaming accelerator for general-purpose sparse-matrix
  dense-matrix multiplication.
\newblock In \emph{Proceedings of the 2022 ACM/SIGDA International Symposium on
  Field-Programmable Gate Arrays}, FPGA '22, page 65–77, New York, NY, USA,
  2022. Association for Computing Machinery.
\newblock ISBN 9781450391498.
\newblock \doi{10.1145/3490422.3502357}.

\bibitem[Wang et~al.(2015)Wang, Tung, Smola, and Anandkumar]{wang2015fast}
Yining Wang, Hsiao-Yu Tung, Alexander~J Smola, and Anima Anandkumar.
\newblock Fast and guaranteed tensor decomposition via sketching.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Wijeratne et~al.(2023)Wijeratne, Wang, Kannan, and
  Prasanna]{spMTTKRP_accelerator}
Sasindu Wijeratne, Ta-Yang Wang, Rajgopal Kannan, and Viktor Prasanna.
\newblock Accelerating sparse {MTTKRP} for tensor decomposition on {FPGA}.
\newblock In \emph{Proceedings of the 2023 ACM/SIGDA International Symposium on
  Field Programmable Gate Arrays}, FPGA '23, page 259–269, New York, NY, USA,
  2023. Association for Computing Machinery.
\newblock ISBN 9781450394178.
\newblock \doi{10.1145/3543622.3573179}.

\bibitem[Woodruff and Zandieh(2022)]{woodruff_zandieh}
David Woodruff and Amir Zandieh.
\newblock Leverage score sampling for tensor product matrices in input sparsity
  time.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, volume 162 of \emph{Proceedings of Machine Learning Research},
  pages 23933--23964. PMLR, 17--23 Jul 2022.

\bibitem[Woodruff et~al.(2014)]{woodruff2014sketching}
David~P Woodruff et~al.
\newblock Sketching as a tool for numerical linear algebra.
\newblock \emph{Foundations and Trends{\textregistered} in Theoretical Computer
  Science}, 10\penalty0 (1--2):\penalty0 1--157, 2014.

\bibitem[{Yu} et~al.(2010){Yu}, {Petropulu}, and {Poor}]{mimo_radar_krp}
Yao {Yu}, Athina~P. {Petropulu}, and H.~Vincent {Poor}.
\newblock {MIMO} radar using compressive sampling.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  4\penalty0 (1):\penalty0 146--163, February 2010.
\newblock \doi{10.1109/JSTSP.2009.2038973}.

\end{thebibliography}
