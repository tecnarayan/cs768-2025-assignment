
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

@inproceedings{YangMSLS21,
  author    = {Antoine Yang and
               Antoine Miech and
               Josef Sivic and
               Ivan Laptev and
               Cordelia Schmid},
  title     = {Just Ask: Learning to Answer Questions from Millions of Narrated Videos},
  booktitle = {ICCV},
  pages     = {1666--1677},
  year      = {2021}
}

@inproceedings{LeLV020,
  title={Hierarchical conditional relation networks for video question answering},
  author={Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen},
  booktitle={CVPR},
  pages={9972--9981},
  year={2020}
}

@inproceedings{FanZZW0H19,
  author    = {Chenyou Fan and
               Xiaofan Zhang and
               Shu Zhang and
               Wensheng Wang and
               Chi Zhang and
               Heng Huang},
  title     = {Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering},
  booktitle = {CVPR},
  pages     = {1999--2007},
  year      = {2019},
}

@inproceedings{AmraniBRB21,
  author    = {Elad Amrani and
               Rami Ben{-}Ari and
               Daniel Rotman and
               Alex M. Bronstein},
  title     = {Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning},
  booktitle = {AAAI},
  pages     = {6644--6652},
  year      = {2021},
}

@article{fei2022wenlan,
  title={Towards artificial general intelligence via a multimodal foundation model},
  author={Fei, Nanyi and Lu, Zhiwu and Gao, Yizhao and Yang, Guoxing and Huo, Yuqi and Wen, Jingyuan and Lu, Haoyu and Song, Ruihua and Gao, Xin and Xiang, Tao and Sun, Hao and Wen, Ji-Rong},
  journal={Nature Communications},
  volume={13},
  pages={3094},
  year={2022},
}


@inproceedings{lu2022cots,
  title={{COTS}: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval},
  author={Lu, Haoyu and Fei, Nanyi and Huo, Yuqi and Gao, Yizhao and Lu, Zhiwu and Wen, Ji-Rong},
  booktitle={CVPR},
  pages={15692--15701},
  year={2022}
}

@article{luo2021clip4clip,
  title={{CLIP4Clip}: An empirical study of clip for end to end video clip retrieval},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={arXiv preprint arXiv:2104.08860},
  year={2021}
}

@inproceedings{XuZX0Z0Z17,
  author    = {Dejing Xu and
               Zhou Zhao and
               Jun Xiao and
               Fei Wu and
               Hanwang Zhang and
               Xiangnan He and
               Yueting Zhuang},
  title     = {Video Question Answering via Gradually Refined Attention over Appearance
               and Motion},
  booktitle = {ACMMM},
  pages     = {1645--1653},
  year      = {2017},
}

@inproceedings{vaswani2017transformer,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {NeurIPS},
  pages     = {5998--6008},
  year      = {2017}
}

%Entries
@article{distilbert,
  author    = {Victor Sanh and
               Lysandre Debut and
               Julien Chaumond and
               Thomas Wolf},
  title     = {{DistilBERT}, a distilled version of {BERT:} smaller, faster, cheaper
               and lighter},
  journal   = {arXiv preprint arXiv:1910.01108},
  url       = {http://arxiv.org/abs/1910.01108},
  year      = {2019}
}

@inproceedings{zhou2018towards,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={AAAI},
  pages={7590--7598},
  year={2018}
}

@inproceedings{Rohrbach_2015_CVPR,
author = {Rohrbach, Anna and Rohrbach, Marcus and Tandon, Niket and Schiele, Bernt},
title = {A Dataset for Movie Description},
booktitle = {CVPR},
pages = {3202--3212},
year = {2015}
}

@inproceedings{zhang2018cross,
  title={Cross-modal and hierarchical modeling of video and text},
  author={Zhang, Bowen and Hu, Hexiang and Sha, Fei},
  booktitle={ECCV},
  pages={385--401},
  year={2018}
}

@inproceedings{venugopalan2014translating,
  author    = {Subhashini Venugopalan and
               Huijuan Xu and
               Jeff Donahue and
               Marcus Rohrbach and
               Raymond J. Mooney and
               Kate Saenko},
  title     = {Translating Videos to Natural Language Using Deep Recurrent Neural Networks},
  booktitle = {NAACL-HLT},
  pages     = {1494--1504},
  year      = {2015}
}

@article{kiros2014unifying,
  title={Unifying visual-semantic embeddings with multimodal neural language models},
  author={Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S.},
  journal={arXiv preprint arXiv:1411.2539},
  url={http://arxiv.org/abs/1411.2539},
  year={2014}
}

@inproceedings{faghri2017vse++,
  author    = {Fartash Faghri and
               David J. Fleet and
               Jamie Ryan Kiros and
               Sanja Fidler},
  title     = {{VSE++:} Improving Visual-Semantic Embeddings with Hard Negatives},
  booktitle = {BMVC},
  pages     = {12},
  year      = {2018}
}

@inproceedings{mithun2018learning,
  title={Learning joint embedding with multimodal cues for cross-modal video-text retrieval},
  author={Mithun, Niluthpol Chowdhury and Li, Juncheng and Metze, Florian and Roy-Chowdhury, Amit K},
  booktitle={ICMR},
  pages={19--27},
  year={2018}
}

@article{chen20182,
  title={{A2-Nets}: Double Attention Networks},
  author={Chen, Yunpeng and Kalantidis, Yannis and Li, Jianshu and Yan, Shuicheng and Feng, Jiashi},
  journal={arXiv preprint arXiv:1810.11579},
  year={2018}
}

@inproceedings{girdhar2017actionvlad,
  title={{ActionVLAD}: Learning spatio-temporal aggregation for action classification},
  author={Girdhar, Rohit and Ramanan, Deva and Gupta, Abhinav and Sivic, Josef and Russell, Bryan},
  booktitle={CVPR},
  year={2017}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@article{cordonnier2019relationship,
  title={On the relationship between self-attention and convolutional layers},
  author={Cordonnier, Jean-Baptiste and Loukas, Andreas and Jaggi, Martin},
  journal={arXiv preprint arXiv:1911.03584},
  year={2019}
}

@article{ramachandran2019stand,
  title={Stand-alone self-attention in vision models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
  journal={arXiv preprint arXiv:1906.05909},
  year={2019}
}

@inproceedings{rohrbach2012database,
  title={A database for fine grained activity detection of cooking activities},
  author={Rohrbach, Marcus and Amin, Sikandar and Andriluka, Mykhaylo and Schiele, Bernt},
  booktitle={CVPR},
  year={2012},
}

@inproceedings{chen2011collecting,
  title={Collecting highly parallel data for paraphrase evaluation},
  author={Chen, David and Dolan, William B},
  booktitle={ACL},
  pages={190--200},
  year={2011}
}

@inproceedings{bain2020condensed,
  title={Condensed movies: Story based retrieval with contextual embeddings},
  author={Bain, Max and Nagrani, Arsha and Brown, Andrew and Zisserman, Andrew},
  booktitle={ACCV},
  pages={460--479},
  year={2020}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  pages={2556--2565},
  year={2018}
}

@inproceedings{krishna2017dense,
  title={Dense-captioning events in videos},
  author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
  booktitle={ICCV},
  pages={706--715},
  year={2017}
}

@inproceedings{anne2017localizing,
  title={Localizing moments in video with natural language},
  author={Hendricks, Anne Lisa and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle={ICCV},
  pages={5804--5813},
  year={2017}
}

@inproceedings{xu2016msr,
  title={{MSR-VTT}: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={CVPR},
  pages={5288--5296},
  year={2016}
}

@inproceedings{Zhai2019ClassificationIA,
  title={Classification is a Strong Baseline for Deep Metric Learning},
  author={Andrew Zhai and Hao-Yu Wu},
  booktitle={BMVC},
  year={2019}
}

@inproceedings{bertasius2021spacetime,
  author    = {Gedas Bertasius and
               Heng Wang and
               Lorenzo Torresani},
  title     = {Is Space-Time Attention All You Need for Video Understanding?},
  booktitle = {ICML},
  pages     = {813--824},
  year      = {2021},
}

@inproceedings{patrick2020support,
  author    = {Mandela Patrick and
               Po{-}Yao Huang and
               Yuki Markus Asano and
               Florian Metze and
               Alexander G. Hauptmann and
               Jo{\~{a}}o F. Henriques and
               Andrea Vedaldi},
  title     = {Support-set bottlenecks for video-text representation learning},
  booktitle = {ICLR},
  url       = {https://openreview.net/forum?id=EqoXe2zmhrh},
  year      = {2021}
}

@inproceedings{gabeur2020multi,
  title={Multi-modal transformer for video retrieval},
  author={Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
  booktitle={ECCV},
  pages={214--229},
  year={2020},
}



@article{rouditchenko2020avlnet,
  title={{AVLnet}: Learning audio-visual language representations from instructional videos},
  author={Rouditchenko, Andrew and Boggust, Angie and Harwath, David and Joshi, Dhiraj and Thomas, Samuel and Audhkhasi, Kartik and Feris, Rogerio and Kingsbury, Brian and Picheny, Michael and Torralba, Antonio and others},
  journal={arXiv preprint arXiv:2006.09199},
  url= {https://arxiv.org/abs/2006.09199},
  year={2020}
}

@article{luo2020univilm,
  title={{UniVL}: A unified video and language pre-training model for multimodal understanding and generation},
  author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Chen, Xilin and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.06353},
  url= {https://arxiv.org/abs/2002.06353},
  year={2020}
}

@inproceedings{amrani2020noise,
  author    = {Elad Amrani and
               Rami Ben{-}Ari and
               Daniel Rotman and
               Alex Bronstein},
  title     = {Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning},
  booktitle = {AAAI},
  pages     = {6644--6652},
  year      = {2021}
}

@article{korbar2020video,
  title={Video Understanding as Machine Translation},
  author={Korbar, Bruno and Petroni, Fabio and Girdhar, Rohit and Torresani, Lorenzo},
  journal={arXiv preprint arXiv:2006.07203},
  url= {https://arxiv.org/abs/2006.07203},
  year={2020}
}

@inproceedings{yu2018joint,
  title={A joint sequence fusion model for video question answering and retrieval},
  author={Yu, Youngjae and Kim, Jongseok and Kim, Gunhee},
  booktitle={ECCV},
  pages= {487--503},
  year={2018}
}

@inproceedings{miech2019howto100m,
  title={{HowTo100M}: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={ICCV},
  pages= {2630--2640},
  year={2019}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={CVPR},
  pages={9879--9889},
  year={2020}
}

%align
@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  pages = {4904--4916},
  year={2021}
}

@inproceedings{zhu2020actbert,
  title={{ActBERT}: Learning global-local video-text representations},
  author={Zhu, Linchao and Yang, Yi},
  booktitle={CVPR},
  pages= {8743--8752},
  year={2020}
}

@inproceedings{lei2021less,
  title={Less is More: {ClipBERT} for Video-and-Language Learning via Sparse Sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={CVPR},
  pages= {7331--7341},
  year={2021}
}

@article{li2020hero,
  title={{HERO}: Hierarchical encoder for video+ language omni-representation pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  journal={EMNLP},
  pages= {2046--2065},
  year={2020}
}

@inproceedings{xie2018rethinking,
  title={Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification}, 
  author={Saining Xie and Chen Sun and Jonathan Huang and Zhuowen Tu and Kevin Murphy},
  booktitle={ECCV},
  pages= {318--335},
  year={2018}
}

@inproceedings{Carreira2017,
  author = {Jo{\~{a}}o Carreira and Andrew Zisserman},
  title = {Quo Vadis, Action Recognition? {A} New Model and the {Kinetics} Dataset},
  booktitle = {CVPR},
  pages = {4724--4733},
  year = {2017}
}

@article{Kinetics,
    author = {Will Kay and Joao Carreira and Karen Simonyan and Brian Zhang and Chloe Hillier and Sudheendra Vijayanarasimhan and Fabio Viola and Tim Green and Trevor Back and Paul Natsev and Mustafa Suleyman and Andrew Zisserman},
    title = {The {Kinetics} Human Action Video Dataset},
    journal = {arXiv preprint arXiv:1705.06950},
    url = {http://arxiv.org/abs/1705.06950},
    year = {2017}
}

@inproceedings{HaraCVPR2018,
    author = {Hara, Kensho and Kataoka, Hirokatsu and Satoh, Yutaka},
    title = {Can Spatiotemporal {3D} {CNNs} Retrace the History of {2D} {CNNs} and {ImageNet}?},
    booktitle = {CVPR},
    pages = {6546--6555},
    year = {2018},
}

@inproceedings{Tran2018ACL,
  title={A Closer Look at Spatiotemporal Convolutions for Action Recognition},
  author={Du Tran and Heng Wang and L. Torresani and Jamie Ray and Y. LeCun and Manohar Paluri},
  booktitle={CVPR},
  pages={6450--6459},
  year={2018}
}

@inproceedings{carion2020endtoend,
  title={End-to-End Object Detection with Transformers},
  author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
  booktitle={ECCV},
  pages={213--229},
  year={2020},
}

@inproceedings{lin2014microsoft,
  title={Microsoft {COCO}: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C. Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014},
}

@inproceedings{Wu2020AMM,
  title={A Multigrid Method for Efficiently Training Video Models},
  author={Chao-Yuan Wu and Ross B. Girshick and Kaiming He and Christoph Feichtenhofer and Philipp Krahenbuhl},
  booktitle={CVPR},
  pages={150--159},
  year={2020},
}

@inproceedings{zhou2018end,
  title={End-to-end dense video captioning with masked transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={CVPR},
  pages={8739--8748},
  year={2018}
}

@article{mccarthy2010mtld,
  title={{MTLD}, {vocd-D}, and {HD-D}: A validation study of sophisticated approaches to lexical diversity assessment},
  author={McCarthy, Philip M and Jarvis, Scott},
  journal={Behavior Research Methods},
  volume={42},
  pages={381--392},
  year={2010}
}

@inproceedings{lei2018tvqa,
  author    = {Jie Lei and
               Licheng Yu and
               Mohit Bansal and
               Tamara L. Berg},
  title     = {{TVQA}: Localized, Compositional Video Question Answering},
  booktitle = {EMNLP},
  pages     = {1369--1379},
  year      = {2018}
}

@inproceedings{antol2015vqa,
  title={{VQA}: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={ICCV},
  pages={2425--2433},
  year={2015}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={IJCV},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
}

@inproceedings{liu2019use,
  author    = {Yang Liu and
               Samuel Albanie and
               Arsha Nagrani and
               Andrew Zisserman},
  title     = {Use What You Have: Video retrieval using representations from collaborative experts},
  booktitle = {BMVC},
  pages     = {279},
  year      = {2019}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={ICCV},
  pages={1728--1738},
  year={2021}
}

@inproceedings{jacob2019bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {NAACL-HLT},
  pages     = {4171--4186},
  year      = {2019}
}

@article{xu2021videoclip,
    title={{VideoCLIP}: Contrastive Pre-training for Zero-shot Video-Text Understanding}, 
    author={Hu Xu and Gargi Ghosh and Po-Yao Huang and Dmytro Okhonko and Armen Aghajanyan and Florian Metze Luke Zettlemoyer Christoph Feichtenhofer},
    journal={arXiv preprint arXiv:2109.14084},
    url={https://arxiv.org/abs/2109.14084},
    year={2021}
}

@inproceedings{he2020moco,
  author    = {Kaiming He and
               Haoqi Fan and
               Yuxin Wu and
               Saining Xie and
               Ross B. Girshick},
  title     = {Momentum Contrast for Unsupervised Visual Representation Learning},
  booktitle = {CVPR},
  pages     = {9726--9735},
  year      = {2020}
}

@inproceedings{yang2021taco,
  title={{TACo}: Token-aware cascade contrastive learning for video-text alignment},
  author={Yang, Jianwei and Bisk, Yonatan and Gao, Jianfeng},
  booktitle={ICCV},
  pages={11562--11572},
  year={2021}
}

@inproceedings{ordonez2011im2text,
  title={{Im2Text}: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  booktitle={NeurIPS},
  pages={1143--1151},
  year={2011}
}


@article{chen2015coco,
  author    = {Xinlei Chen and
               Hao Fang and
               Tsung{-}Yi Lin and
               Ramakrishna Vedantam and
               Saurabh Gupta and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO} Captions: Data Collection and Evaluation Server},
  journal   = {arXiv preprint arXiv:1504.00325},
  url       = {http://arxiv.org/abs/1504.00325},
  year      = {2015}
}

@inproceedings{bryan2015flickr,
  author    = {Bryan A. Plummer and
               Liwei Wang and
               Chris M. Cervantes and
               Juan C. Caicedo and
               Julia Hockenmaier and
               Svetlana Lazebnik},
  title     = {Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models},
  booktitle = {ICCV},
  pages     = {2641--2649},
  year      = {2015}
}

@inproceedings{TanB19,
  author    = {Hao Tan and
               Mohit Bansal},
  editor    = {Kentaro Inui and
               Jing Jiang and
               Vincent Ng and
               Xiaojun Wan},
  title     = {{LXMERT:} Learning Cross-Modality Encoder Representations from Transformers},
  booktitle = {EMNLP-IJCNLP},
  pages     = {5099--5110},
  year      = {2019},

}

%adamw
@inproceedings{LoshchilovH19,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Decoupled Weight Decay Regularization},
  booktitle = {ICLR},
  url       = {https://openreview.net/forum?id=Bkg6RiCqY7},
  year      = {2019},
}

@inproceedings{alexey2021vit,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  booktitle = {ICLR},
  url       = {https://openreview.net/forum?id=YicbFdNTTy},
  year      = {2021}
}

@inproceedings{wang2021vatex,
  author    = {Xin Wang and
               Jiawei Wu and
               Junkun Chen and
               Lei Li and
               Yuan{-}Fang Wang and
               William Yang Wang},
  title     = {{VaTeX}: {A} Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research},
  booktitle = {ICCV},
  pages     = {4580--4590},
  year      = {2019},
}

@inproceedings{chen2020fine,
  author    = {Shizhe Chen and
               Yida Zhao and
               Qin Jin and
               Qi Wu},
  title     = {Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning},
  booktitle = {CVPR},
  pages     = {10635--10644},
  year      = {2020}
}

@inproceedings{jang2017tgif,
  author    = {Yunseok Jang and
               Yale Song and
               Youngjae Yu and
               Youngjin Kim and
               Gunhee Kim},
  title     = {{TGIF-QA}: Toward Spatio-Temporal Reasoning in Visual Question Answering},
  booktitle = {CVPR},
  pages     = {1359--1367},
  year      = {2017}
}

@inproceedings{he2016resnet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {CVPR},
  pages     = {770--778},
  year      = {2016}
}

@inproceedings{radford2021learning,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {ICML},
  pages     = {8748--8763},
  year      = {2021}
}

@inproceedings{chefer2021transvisual,
  author    = {Hila Chefer and
               Shir Gur and
               Lior Wolf},
  title     = {Transformer Interpretability Beyond Attention Visualization},
  booktitle = {CVPR},
  pages     = {782--791},
  year      = {2021}
}

@inproceedings{liu2021hit,
  title={{HiT}: Hierarchical transformer with momentum contrast for video-text retrieval},
  author={Liu, Song and Fan, Haoqi and Qian, Shengsheng and Chen, Yiru and Ding, Wenkui and Wang, Zhongyuan},
  booktitle={ICCV},
  pages={11915--11925},
  year={2021}
}

@article{oord2018cpc,
  author    = {A{\"{a}}ron van den Oord and
               Yazhe Li and
               Oriol Vinyals},
  title     = {Representation Learning with Contrastive Predictive Coding},
  journal   = {arXiv preprint arXiv:1807.03748},
  url       = {http://arxiv.org/abs/1807.03748},
  year      = {2018}
}

@inproceedings{tian2019cmc,
  author    = {Yonglong Tian and
               Dilip Krishnan and
               Phillip Isola},
  title     = {Contrastive Multiview Coding},
  booktitle = {ECCV},
  pages     = {776--794},
  year      = {2020}
}

@inproceedings{ting2020CoRR,
  author    = {Ting Chen and
               Simon Kornblith and
               Mohammad Norouzi and
               Geoffrey E. Hinton},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  booktitle = {ICML},
  pages     = {1597--1607},
  year      = {2020}
}

@inproceedings{vaswani2017attention,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {NeurIPS},
  pages     = {5998--6008},
  year      = {2017}
}

@inproceedings{grill2020byol,
  author    = {Jean{-}Bastien Grill and
               Florian Strub and
               Florent Altch{\'{e}} and
               Corentin Tallec and
               Pierre H. Richemond and
               Elena Buchatskaya and
               Carl Doersch and
               Bernardo {\'{A}}vila Pires and
               Zhaohan Guo and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Koray Kavukcuoglu and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = {Bootstrap Your Own Latent - {A} New Approach to Self-Supervised Learning},
  booktitle = {NeurIPS},
  pages     = {21271--21284},
  year      = {2020}
}

@inproceedings{chen2021simsiam,
  author    = {Xinlei Chen and
               Kaiming He},
  title     = {Exploring Simple Siamese Representation Learning},
  booktitle = {CVPR},
  pages     = {15750--15758},
  year      = {2021}
}

@inproceedings{chen2020big,
  author    = {Ting Chen and
               Simon Kornblith and
               Kevin Swersky and
               Mohammad Norouzi and
               Geoffrey E. Hinton},
  title     = {Big Self-Supervised Models are Strong Semi-Supervised Learners},
  booktitle = {NeurIPS},
  pages     = {22243--22255},
  year      = {2020}
}

@inproceedings{chen2021v3,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={CVPR},
  pages={9640--9649},
  year={2021}
}



@inproceedings{tian2020con,
  author    = {Yonglong Tian and
               Dilip Krishnan and
               Phillip Isola},
  title     = {Contrastive Multiview Coding},
  booktitle = {ECCV},
  pages     = {776--794},
  year      = {2020}
}

@inproceedings{jin2021hierarchical,
  title={Hierarchical Cross-Modal Graph Consistency Learning for Video-Text Retrieval},
  author={Jin, Weike and Zhao, Zhou and Zhang, Pengcheng and Zhu, Jieming and He, Xiuqiang and Zhuang, Yueting},
  booktitle={SIGIR},
  pages={1114--1124},
  year={2021}
}

@inproceedings{li2021albef,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  booktitle={NeurIPS},
  pages={9694--9705},
  year={2021}
}

%cc12m
@inproceedings{changpinyo2021conceptual,
  title={{Conceptual 12M}: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={CVPR},
  pages={3558--3568},
  year={2021}
}

@inproceedings{khosla2020super,
  author    = {Prannay Khosla and
               Piotr Teterwak and
               Chen Wang and
               Aaron Sarna and
               Yonglong Tian and
               Phillip Isola and
               Aaron Maschinot and
               Ce Liu and
               Dilip Krishnan},
  title     = {Supervised Contrastive Learning},
  booktitle = {NeurIPS},
  pages     = {18661--18673},
  year      = {2020}
}

@inproceedings{tian2020what,
  author    = {Yonglong Tian and
               Chen Sun and
               Ben Poole and
               Dilip Krishnan and
               Cordelia Schmid and
               Phillip Isola},
  title     = {What Makes for Good Views for Contrastive Learning?},
  booktitle = {NeurIPS},
  pages     = {6827--6839},
  year      = {2020}
}

@inproceedings{wu2018unsuper,
  author    = {Zhirong Wu and
               Yuanjun Xiong and
               Stella X. Yu and
               Dahua Lin},
  title     = {Unsupervised Feature Learning via Non-Parametric Instance Discrimination},
  booktitle = {CVPR},
  pages     = {3733--3742},
  year      = {2018}
}

@inproceedings{feng2020exploit,
  author    = {Zerun Feng and
               Zhimin Zeng and
               Caili Guo and
               Zheng Li},
  title     = {Exploiting Visual Semantic Reasoning for Video-Text Retrieval},
  booktitle = {IJCAI},
  pages     = {1005--1011},
  year      = {2020}
}

@inproceedings{li2020anovel,
  author    = {Zheng Li and
               Caili Guo and
               Bo Yang and
               Zerun Feng and
               Hao Zhang},
  title     = {A Novel Convolutional Architecture For Video-Text Retrieval},
  booktitle = {{ICME}},
  pages     = {1--6},
  year      = {2020}
}

@inproceedings{wu2021hanet,
  author    = {Peng Wu and
               Xiangteng He and
               Mingqian Tang and
               Yiliang Lv and
               Jing Liu},
  title     = {{HANet}: Hierarchical Alignment Networks for Video-Text Retrieval},
  booktitle = {{ACM-MM}},
  pages     = {3518--3527},
  year      = {2021}
}


@inproceedings{wang2021t2vlad,
  title={{T}2{VLAD}: global-local sequence alignment for text-video retrieval},
  author={Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  booktitle={CVPR},
  pages={5079--5088},
  year={2021}
}

@article{yu2016snuvl,
  author    = {Youngjae Yu and
               Hyungjin Ko and
               Jongwook Choi and
               Gunhee Kim},
  title     = {Video Captioning and Retrieval Models with Semantic Attention},
  journal   = {arXiv preprint arXiv:1610.02947},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.02947}
}

@inproceedings{yu2017ete,
  author    = {Youngjae Yu and
               Hyungjin Ko and
               Jongwook Choi and
               Gunhee Kim},
  title     = {End-to-End Concept Word Detection for Video Captioning, Retrieval,
               and Question Answering},
  booktitle = {{CVPR}},
  pages     = {3261--3269},
  year      = {2017}
}

@inproceedings{kim2017hadamard,
  author    = {Jin{-}Hwa Kim and
               Kyoung Woon On and
               Woosang Lim and
               Jeonghee Kim and
               Jung{-}Woo Ha and
               Byoung{-}Tak Zhang},
  title     = {Hadamard Product for Low-rank Bilinear Pooling},
  booktitle = {{ICLR}},
  year      = {2017},
  url       = {https://openreview.net/forum?id=r1rhWnZkg}
}  

@inproceedings{sun2021lightningdot,
  title={{LightningDOT}: Pre-training Visual-Semantic Embeddings for Real-Time Image-Text Retrieval},
  author={Sun, Siqi and Chen, Yen-Chun and Li, Linjie and Wang, Shuohang and Fang, Yuwei and Liu, Jingjing},
  booktitle={NAACL-HLT},
  pages={982--997},
  year={2021}
}

@inproceedings{wen2021cookie,
  title={{COOKIE}: Contrastive Cross-Modal Knowledge Sharing Pre-Training for Vision-Language Representation},
  author={Wen, Keyu and Xia, Jin and Huang, Yuanyuan and Li, Linyang and Xu, Jiayan and Shao, Jie},
  booktitle={ICCV},
  pages={2208--2217},
  year={2021}
}

% memory bank
@inproceedings{wu2018unsupervised,
  title={Unsupervised feature learning via non-parametric instance discrimination},
  author={Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X and Lin, Dahua},
  booktitle={CVPR},
  pages={3733--3742},
  year={2018},
   
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  pages={1597--1607},
  year={2020},
  
}


@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  volume={},
  number={},
  pages={},
  year={2018}
}



@article{hermans2017defense,
  title={In defense of the triplet loss for person re-identification},
  author={Hermans, Alexander and Beyer, Lucas and Leibe, Bastian},
  journal={arXiv preprint arXiv:1703.07737},
  year={2017}
}


@inproceedings{zhang2021vinvl,
  title={{VinVL}: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={CVPR},
  pages={5579--5588},
  year={2021}
}

%wenlan
@article{huo2021wenlan,
  title={{WenLan}: Bridging vision and language by large-scale multi-modal pre-training},
  author={Huo, Yuqi and Zhang, Manli and Liu, Guangzhen and Lu, Haoyu and Gao, Yizhao and Yang, Guoxing and Wen, Jingyuan and Zhang, Heng and Xu, Baogui and Zheng, Weihao and others},
  journal={arXiv preprint arXiv:2103.06561},
  year={2021}
}

% ViLT
@inproceedings{kim2021vilt,
  title={{ViLT}: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={ICML},
  pages     = {5583--5594},
  year={2021}
}
 
 

@article{huang2020pixel,
  title={{Pixel-BERT}: Aligning image pixels with text by deep multi-modal transformers},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  journal={arXiv preprint arXiv:2004.00849},
  year={2020}
}

@inproceedings{li2020unicoder,
  title={{Unicoder-VL}: A universal encoder for vision and language by cross-modal pre-training},
  author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin},
  booktitle={AAAI},
  pages={11336--11344},
  year={2020}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={ECCV},
  pages={121--137},
  year={2020}
}

@inproceedings{chen2020uniter,
  title={{UNITER}: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={ECCV},
  pages={104--120},
  year={2020}
}

@article{dong2018predicting,
  title={Predicting visual features from text for image and video caption retrieval},
  author={Dong, Jianfeng and Li, Xirong and Snoek, Cees GM},
  journal={IEEE Transactions on Multimedia},
  volume={20},
  number={12},
  pages={3377--3388},
  year={2018},
}

@inproceedings{he2021improving,
  title={Improving Video Retrieval by Adaptive Margin},
  author={He, Feng and Wang, Qi and Feng, Zhifan and Jiang, Wenbin and Lu, Yajuan and Zhu, Yong and Tan, Xiao},
  booktitle={SIGIR},
  pages={1359--1368},
  year={2021}
}



@inproceedings{yu2021ernie,
  author    = {Fei Yu and
               Jiji Tang and
               Weichong Yin and
               Yu Sun and
               Hao Tian and
               Hua Wu and
               Haifeng Wang},
  title     = {ERNIE-ViL: Knowledge Enhanced Vision-Language Representations through
               Scene Graphs},
  booktitle = {AAAI},
  pages     = {3208--3216},
  publisher = {{AAAI} Press},
  year      = {2021},

}

@inproceedings{frome2013devise,
  title={{DeViSE}: a deep visual-semantic embedding model},
  author={Frome, Andrea and Corrado, Greg S and Shlens, Jonathon and Bengio, Samy and Dean, Jeffrey and Ranzato, Marc'Aurelio and Mikolov, Tomas},
  booktitle={NeurIPS},
  pages={2121--2129},
  year={2013}
}
