\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Bowman et~al.(2015)Bowman, Angeli, Potts, and
  Manning]{DBLP:conf/emnlp/BowmanAPM15}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
\newblock A large annotated corpus for learning natural language inference.
\newblock In \emph{Proceedings of the 2015 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2015, Lisbon, Portugal, September 17-21,
  2015}, pages 632--642, 2015.

\bibitem[Bradbury et~al.(2016)Bradbury, Merity, Xiong, and
  Socher]{DBLP:journals/corr/BradburyMXS16}
James Bradbury, Stephen Merity, Caiming Xiong, and Richard Socher.
\newblock Quasi-recurrent neural networks.
\newblock \emph{CoRR}, abs/1611.01576, 2016.

\bibitem[Chang et~al.(2017)Chang, Zhang, Han, Yu, Guo, Tan, Cui, Witbrock,
  Hasegawa-Johnson, and Huang]{chang2017dilated}
Shiyu Chang, Yang Zhang, Wei Han, Mo~Yu, Xiaoxiao Guo, Wei Tan, Xiaodong Cui,
  Michael Witbrock, Mark~A Hasegawa-Johnson, and Thomas~S Huang.
\newblock Dilated recurrent neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  76--86, 2017.

\bibitem[Chen et~al.(2017)Chen, Zhu, Ling, Wei, Jiang, and
  Inkpen]{DBLP:conf/acl/ChenZLWJI17}
Qian Chen, Xiaodan Zhu, Zhen{-}Hua Ling, Si~Wei, Hui Jiang, and Diana Inkpen.
\newblock Enhanced {LSTM} for natural language inference.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics, {ACL} 2017, Vancouver, Canada, July 30 -
  August 4, Volume 1: Long Papers}, pages 1657--1668, 2017.

\bibitem[Cho et~al.(2014)Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem[Choi et~al.(2017)Choi, Yoo, and Lee]{choi2017unsupervised}
Jihun Choi, Kang~Min Yoo, and Sang-goo Lee.
\newblock Unsupervised learning of task-specific tree structures with
  tree-lstms.
\newblock \emph{arXiv preprint arXiv:1707.02786}, 2017.

\bibitem[Chung et~al.(2016)Chung, Ahn, and Bengio]{chung2016hierarchical}
Junyoung Chung, Sungjin Ahn, and Yoshua Bengio.
\newblock Hierarchical multiscale recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1609.01704}, 2016.

\bibitem[Danihelka et~al.(2016)Danihelka, Wayne, Uria, Kalchbrenner, and
  Graves]{DBLP:conf/icml/DanihelkaWUKG16}
Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, and Alex Graves.
\newblock Associative long short-term memory.
\newblock In \emph{Proceedings of the 33nd International Conference on Machine
  Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016}, pages
  1986--1994, 2016.

\bibitem[Dieng et~al.(2016)Dieng, Wang, Gao, and Paisley]{dieng2016topicrnn}
Adji~B Dieng, Chong Wang, Jianfeng Gao, and John Paisley.
\newblock Topicrnn: A recurrent neural network with long-range semantic
  dependency.
\newblock \emph{arXiv preprint arXiv:1611.01702}, 2016.

\bibitem[Ding et~al.(2018)Ding, Xia, Yu, Li, and Yang]{ding2018densely}
Zixiang Ding, Rui Xia, Jianfei Yu, Xiang Li, and Jian Yang.
\newblock Densely connected bidirectional lstm with applications to sentence
  classification.
\newblock \emph{arXiv preprint arXiv:1802.00889}, 2018.

\bibitem[dos Santos et~al.(2016)dos Santos, Tan, Xiang, and
  Zhou]{DBLP:journals/corr/SantosTXZ16}
C{\'{\i}}cero~Nogueira dos Santos, Ming Tan, Bing Xiang, and Bowen Zhou.
\newblock Attentive pooling networks.
\newblock \emph{CoRR}, abs/1602.03609, 2016.

\bibitem[El~Hihi and Bengio(1996)]{el1996hierarchical}
Salah El~Hihi and Yoshua Bengio.
\newblock Hierarchical recurrent neural networks for long-term dependencies.
\newblock In \emph{Advances in neural information processing systems}, pages
  493--499, 1996.

\bibitem[Graves et~al.(2013)Graves, Mohamed, and Hinton]{graves2013speech}
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton.
\newblock Speech recognition with deep recurrent neural networks.
\newblock In \emph{Acoustics, speech and signal processing (icassp), 2013 ieee
  international conference on}, pages 6645--6649. IEEE, 2013.

\bibitem[Guo et~al.(2017)Guo, Cherry, and Su]{guo2017end}
Hongyu Guo, Colin Cherry, and Jiang Su.
\newblock End-to-end multi-view networks for text classification.
\newblock \emph{arXiv preprint arXiv:1704.05907}, 2017.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Huang et~al.(2017)Huang, Qian, and Zhu]{huang2017encoding}
Minlie Huang, Qiao Qian, and Xiaoyan Zhu.
\newblock Encoding syntactic knowledge in neural networks for sentiment
  classification.
\newblock \emph{ACM Transactions on Information Systems (TOIS)}, 35\penalty0
  (3):\penalty0 26, 2017.

\bibitem[Johnson and Zhang(2016)]{johnson2016supervised}
Rie Johnson and Tong Zhang.
\newblock Supervised and semi-supervised text categorization using lstm for
  region embeddings.
\newblock \emph{arXiv preprint arXiv:1602.02373}, 2016.

\bibitem[Khot et~al.(2018)Khot, Sabharwal, and Clark]{scitail}
Tushar Khot, Ashish Sabharwal, and Peter Clark.
\newblock Scitail: A textual entailment dataset from science question
  answering.
\newblock In \emph{AAAI}, 2018.

\bibitem[Kiela et~al.(2018)Kiela, Wang, and Cho]{kiela2018context}
Douwe Kiela, Changhan Wang, and Kyunghyun Cho.
\newblock Context-attentive embeddings for improved sentence representations.
\newblock \emph{arXiv preprint arXiv:1804.07983}, 2018.

\bibitem[Kim et~al.(2018)Kim, Hong, Kang, and Kwak]{kim2018semantic}
Seonhoon Kim, Jin-Hyuk Hong, Inho Kang, and Nojun Kwak.
\newblock Semantic sentence matching with densely-connected recurrent and
  co-attentive information.
\newblock \emph{arXiv preprint arXiv:1805.11360}, 2018.

\bibitem[Kim(2014)]{kim2014convolutional}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock \emph{arXiv preprint arXiv:1408.5882}, 2014.

\bibitem[Kingma and Ba(2014)]{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.

\bibitem[Ko{\v{c}}isk{\`y} et~al.(2017)Ko{\v{c}}isk{\`y}, Schwarz, Blunsom,
  Dyer, Hermann, Melis, and Grefenstette]{kovcisky2017narrativeqa}
Tom{\'a}{\v{s}} Ko{\v{c}}isk{\`y}, Jonathan Schwarz, Phil Blunsom, Chris Dyer,
  Karl~Moritz Hermann, G{\'a}bor Melis, and Edward Grefenstette.
\newblock The narrativeqa reading comprehension challenge.
\newblock \emph{arXiv preprint arXiv:1712.07040}, 2017.

\bibitem[Koutnik et~al.(2014)Koutnik, Greff, Gomez, and
  Schmidhuber]{koutnik2014clockwork}
Jan Koutnik, Klaus Greff, Faustino Gomez, and Juergen Schmidhuber.
\newblock A clockwork rnn.
\newblock \emph{arXiv preprint arXiv:1402.3511}, 2014.

\bibitem[Kumar et~al.(2016)Kumar, Irsoy, Ondruska, Iyyer, Bradbury, Gulrajani,
  Zhong, Paulus, and Socher]{kumar2016ask}
Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan
  Gulrajani, Victor Zhong, Romain Paulus, and Richard Socher.
\newblock Ask me anything: Dynamic memory networks for natural language
  processing.
\newblock In \emph{International Conference on Machine Learning}, pages
  1378--1387, 2016.

\bibitem[Lei and Zhang(2017)]{lei2017training}
Tao Lei and Yu~Zhang.
\newblock Training rnns as fast as cnns.
\newblock \emph{arXiv preprint arXiv:1709.02755}, 2017.

\bibitem[Liu et~al.(2017)Liu, Qiu, and Huang]{liu2017adversarial}
Pengfei Liu, Xipeng Qiu, and Xuanjing Huang.
\newblock Adversarial multi-task learning for text classification.
\newblock \emph{arXiv preprint arXiv:1704.05742}, 2017.

\bibitem[Longpre et~al.(2016)Longpre, Pradhan, Xiong, and
  Socher]{longpre2016way}
Shayne Longpre, Sabeek Pradhan, Caiming Xiong, and Richard Socher.
\newblock A way out of the odyssey: Analyzing and combining recent insights for
  lstms.
\newblock \emph{arXiv preprint arXiv:1611.05104}, 2016.

\bibitem[Looks et~al.(2017)Looks, Herreshoff, Hutchins, and
  Norvig]{looks2017deep}
Moshe Looks, Marcello Herreshoff, DeLesley Hutchins, and Peter Norvig.
\newblock Deep learning with dynamic computation graphs.
\newblock \emph{arXiv preprint arXiv:1702.02181}, 2017.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and
  Potts]{maas2011learning}
Andrew~L Maas, Raymond~E Daly, Peter~T Pham, Dan Huang, Andrew~Y Ng, and
  Christopher Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th annual meeting of the association
  for computational linguistics: Human language technologies-volume 1}, pages
  142--150. Association for Computational Linguistics, 2011.

\bibitem[McCann et~al.(2017)McCann, Bradbury, Xiong, and
  Socher]{mccann2017learned}
Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher.
\newblock Learned in translation: Contextualized word vectors.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6297--6308, 2017.

\bibitem[Miyato et~al.(2016)Miyato, Dai, and Goodfellow]{miyato2016adversarial}
Takeru Miyato, Andrew~M Dai, and Ian Goodfellow.
\newblock Adversarial training methods for semi-supervised text classification.
\newblock \emph{arXiv preprint arXiv:1605.07725}, 2016.

\bibitem[Munkhdalai and Yu(2016)]{munkhdalai2016neural}
Tsendsuren Munkhdalai and Hong Yu.
\newblock Neural semantic encoders. corr abs/1607.04315, 2016.

\bibitem[Nie and Bansal(2017)]{DBLP:conf/repeval/NieB17}
Yixin Nie and Mohit Bansal.
\newblock Shortcut-stacked sentence encoders for multi-domain inference.
\newblock In \emph{Proceedings of the 2nd Workshop on Evaluating Vector Space
  Representations for NLP, RepEval@EMNLP 2017, Copenhagen, Denmark, September
  8, 2017}, pages 41--45, 2017.

\bibitem[Parikh et~al.(2016)Parikh, T{\"{a}}ckstr{\"{o}}m, Das, and
  Uszkoreit]{DBLP:conf/emnlp/ParikhT0U16}
Ankur~P. Parikh, Oscar T{\"{a}}ckstr{\"{o}}m, Dipanjan Das, and Jakob
  Uszkoreit.
\newblock A decomposable attention model for natural language inference.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2016, Austin, Texas, USA, November 1-4,
  2016}, pages 2249--2255, 2016.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{DBLP:conf/emnlp/PenningtonSM14}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2014, October 25-29, 2014, Doha, Qatar,
  {A} meeting of SIGDAT, a Special Interest Group of the {ACL}}, pages
  1532--1543, 2014.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018deep}
Matthew~E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock \emph{arXiv preprint arXiv:1802.05365}, 2018.

\bibitem[Radford et~al.(2017)Radford, Jozefowicz, and
  Sutskever]{radford2017learning}
Alec Radford, Rafal Jozefowicz, and Ilya Sutskever.
\newblock Learning to generate reviews and discovering sentiment.
\newblock \emph{arXiv preprint arXiv:1704.01444}, 2017.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Rao et~al.(2016)Rao, He, and Lin]{DBLP:conf/cikm/RaoHL16}
Jinfeng Rao, Hua He, and Jimmy~J. Lin.
\newblock Noise-contrastive estimation for answer selection with deep neural
  networks.
\newblock In \emph{Proceedings of the 25th {ACM} International on Conference on
  Information and Knowledge Management, {CIKM} 2016, Indianapolis, IN, USA,
  October 24-28, 2016}, pages 1913--1916, 2016.

\bibitem[Rockt{\"a}schel et~al.(2015)Rockt{\"a}schel, Grefenstette, Hermann,
  Ko{\v{c}}isk{\`y}, and Blunsom]{rocktaschel2015reasoning}
Tim Rockt{\"a}schel, Edward Grefenstette, Karl~Moritz Hermann, Tom{\'a}{\v{s}}
  Ko{\v{c}}isk{\`y}, and Phil Blunsom.
\newblock Reasoning about entailment with neural attention.
\newblock \emph{arXiv preprint arXiv:1509.06664}, 2015.

\bibitem[Seo et~al.(2016)Seo, Kembhavi, Farhadi, and
  Hajishirzi]{seo2016bidirectional}
Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi.
\newblock Bidirectional attention flow for machine comprehension.
\newblock \emph{arXiv preprint arXiv:1611.01603}, 2016.

\bibitem[Shen et~al.(2017)Shen, Zhou, Long, Jiang, Pan, and
  Zhang]{shen2017disan}
Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan, and Chengqi Zhang.
\newblock Disan: Directional self-attention network for rnn/cnn-free language
  understanding.
\newblock \emph{arXiv preprint arXiv:1709.04696}, 2017.

\bibitem[Shen et~al.(2018)Shen, Zhou, Long, Jiang, and Zhang]{shen2018bi}
Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, and Chengqi Zhang.
\newblock Bi-directional block self-attention for fast and memory-efficient
  sequence modeling.
\newblock \emph{arXiv preprint arXiv:1804.00857}, 2018.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher2013recursive}
Richard Socher, Alex Perelygin, Jean~Y Wu, Jason Chuang, Christopher~D Manning,
  Andrew~Y Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock Citeseer, 2013.

\bibitem[Srivastava et~al.(2015)Srivastava, Greff, and
  Schmidhuber]{DBLP:journals/corr/SrivastavaGS15}
Rupesh~Kumar Srivastava, Klaus Greff, and J{\"{u}}rgen Schmidhuber.
\newblock Highway networks.
\newblock \emph{CoRR}, abs/1505.00387, 2015.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  3104--3112, 2014.

\bibitem[Tai et~al.(2015)Tai, Socher, and Manning]{tai2015improved}
Kai~Sheng Tai, Richard Socher, and Christopher~D Manning.
\newblock Improved semantic representations from tree-structured long
  short-term memory networks.
\newblock \emph{arXiv preprint arXiv:1503.00075}, 2015.

\bibitem[Tay et~al.(2017)Tay, Tuan, and Hui]{tay2017compare}
Yi~Tay, Luu~Anh Tuan, and Siu~Cheung Hui.
\newblock A compare-propagate architecture with alignment factorization for
  natural language inference.
\newblock \emph{arXiv preprint arXiv:1801.00102}, 2017.

\bibitem[Tay et~al.(2018{\natexlab{a}})Tay, Tuan, and Hui]{tay2018co}
Yi~Tay, Luu~Anh Tuan, and Siu~Cheung Hui.
\newblock Co-stack residual affinity networks with multi-level attention
  refinement for matching text sequences.
\newblock \emph{arXiv preprint arXiv:1810.02938}, 2018{\natexlab{a}}.

\bibitem[Tay et~al.(2018{\natexlab{b}})Tay, Tuan, and Hui]{tay2018multi}
Yi~Tay, Luu~Anh Tuan, and Siu~Cheung Hui.
\newblock Multi-range reasoning for machine comprehension.
\newblock \emph{arXiv preprint arXiv:1803.09074}, 2018{\natexlab{b}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6000--6010, 2017.

\bibitem[Voorhees et~al.(1999)]{voorhees1999trec}
Ellen~M Voorhees et~al.
\newblock The trec-8 question answering track report.
\newblock In \emph{Trec}, volume~99, pages 77--82, 1999.

\bibitem[Wang et~al.(2007)Wang, Smith, and Mitamura]{DBLP:conf/emnlp/WangSM07}
Mengqiu Wang, Noah~A. Smith, and Teruko Mitamura.
\newblock What is the jeopardy model? {A} quasi-synchronous grammar for {QA}.
\newblock In \emph{EMNLP-CoNLL 2007, Proceedings of the 2007 Joint Conference
  on Empirical Methods in Natural Language Processing and Computational Natural
  Language Learning, June 28-30, 2007, Prague, Czech Republic}, pages 22--32,
  2007.

\bibitem[Wang et~al.(2017)Wang, Yang, Wei, Chang, and Zhou]{wang2017gated}
Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang, and Ming Zhou.
\newblock Gated self-matching networks for reading comprehension and question
  answering.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  189--198, 2017.

\bibitem[Wieting et~al.(2015)Wieting, Bansal, Gimpel, and
  Livescu]{wieting2015towards}
John Wieting, Mohit Bansal, Kevin Gimpel, and Karen Livescu.
\newblock Towards universal paraphrastic sentence embeddings.
\newblock \emph{arXiv preprint arXiv:1511.08198}, 2015.

\bibitem[Xingjian et~al.(2015)Xingjian, Chen, Wang, Yeung, Wong, and
  Woo]{xingjian2015convolutional}
SHI Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and
  Wang-chun Woo.
\newblock Convolutional lstm network: A machine learning approach for
  precipitation nowcasting.
\newblock In \emph{Advances in neural information processing systems}, pages
  802--810, 2015.

\bibitem[Xiong et~al.(2016)Xiong, Zhong, and
  Socher]{DBLP:journals/corr/XiongZS16}
Caiming Xiong, Victor Zhong, and Richard Socher.
\newblock Dynamic coattention networks for question answering.
\newblock \emph{CoRR}, abs/1611.01604, 2016.

\bibitem[Yang et~al.(2015)Yang, Yih, and Meek]{DBLP:conf/emnlp/YangYM15}
Yi~Yang, Wen{-}tau Yih, and Christopher Meek.
\newblock Wikiqa: {A} challenge dataset for open-domain question answering.
\newblock In \emph{Proceedings of the 2015 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2015, Lisbon, Portugal, September 17-21,
  2015}, pages 2013--2018, 2015.

\bibitem[Yu and Munkhdalai(2017)]{DBLP:conf/eacl/YuM17}
Hong Yu and Tsendsuren Munkhdalai.
\newblock Neural tree indexers for text understanding.
\newblock In \emph{Proceedings of the 15th Conference of the European Chapter
  of the Association for Computational Linguistics, {EACL} 2017, Valencia,
  Spain, April 3-7, 2017, Volume 1: Long Papers}, pages 11--21, 2017.

\bibitem[Zeiler(2012)]{zeiler2012adadelta}
Matthew~D Zeiler.
\newblock Adadelta: an adaptive learning rate method.
\newblock \emph{arXiv preprint arXiv:1212.5701}, 2012.

\bibitem[Zhang et~al.(2016{\natexlab{a}})Zhang, Lee, and
  Radev]{zhang2016dependency}
Rui Zhang, Honglak Lee, and Dragomir Radev.
\newblock Dependency sensitive convolutional neural networks for modeling
  sentences and documents.
\newblock \emph{arXiv preprint arXiv:1611.02361}, 2016{\natexlab{a}}.

\bibitem[Zhang et~al.(2016{\natexlab{b}})Zhang, Chen, Yu, Yaco, Khudanpur, and
  Glass]{zhang2016highway}
Yu~Zhang, Guoguo Chen, Dong Yu, Kaisheng Yaco, Sanjeev Khudanpur, and James
  Glass.
\newblock Highway long short-term memory rnns for distant speech recognition.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
  International Conference on}, pages 5755--5759. IEEE, 2016{\natexlab{b}}.

\bibitem[Zhang et~al.(2018)Zhang, Liu, and Song]{zhang2018sentence}
Yue Zhang, Qi~Liu, and Linfeng Song.
\newblock Sentence-state lstm for text representation.
\newblock \emph{arXiv preprint arXiv:1805.02474}, 2018.

\bibitem[Zhou et~al.(2016)Zhou, Qi, Zheng, Xu, Bao, and Xu]{zhou2016text}
Peng Zhou, Zhenyu Qi, Suncong Zheng, Jiaming Xu, Hongyun Bao, and Bo~Xu.
\newblock Text classification improved by integrating bidirectional lstm with
  two-dimensional max pooling.
\newblock \emph{arXiv preprint arXiv:1611.06639}, 2016.

\end{thebibliography}
