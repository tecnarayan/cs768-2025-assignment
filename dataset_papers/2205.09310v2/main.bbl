\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bendale \& Boult(2016)Bendale and Boult]{bendale2016towards}
Bendale, A. and Boult, T.~E.
\newblock Towards open set deep networks.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  1563--1572, 2016.

\bibitem[Bevandi{\'c} et~al.(2018)Bevandi{\'c}, Kre{\v{s}}o, Or{\v{s}}i{\'c},
  and {\v{S}}egvi{\'c}]{bevandic2018discriminative}
Bevandi{\'c}, P., Kre{\v{s}}o, I., Or{\v{s}}i{\'c}, M., and {\v{S}}egvi{\'c},
  S.
\newblock Discriminative out-of-distribution detection for semantic
  segmentation.
\newblock \emph{arXiv preprint arXiv:1808.07703}, 2018.

\bibitem[Chen et~al.(2021)Chen, Li, Wu, Liang, and Jha]{chen2021atom}
Chen, J., Li, Y., Wu, X., Liang, Y., and Jha, S.
\newblock Atom: Robustifying out-of-distribution detection using outlier
  mining.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pp.\  430--445. Springer, 2021.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{arXiv preprint arXiv:2002.05709}, 2020.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and
  Vedaldi]{cimpoi2014describing}
Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., and Vedaldi, A.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3606--3613, 2014.

\bibitem[Deng et~al.(2019)Deng, Guo, Xue, and Zafeiriou]{deng2019arcface}
Deng, J., Guo, J., Xue, N., and Zafeiriou, S.
\newblock Arcface: Additive angular margin loss for deep face recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  4690--4699, 2019.

\bibitem[Du et~al.(2022{\natexlab{a}})Du, Wang, Gozum, and Li]{du2022unknown}
Du, X., Wang, X., Gozum, G., and Li, Y.
\newblock Unknown-aware object detection: Learning what you don’t know from
  videos in the wild.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022{\natexlab{a}}.

\bibitem[Du et~al.(2022{\natexlab{b}})Du, Wang, Cai, and Li]{du2022vos}
Du, X., Wang, Z., Cai, M., and Li, Y.
\newblock Vos: Learning what you don’t know by virtual outlier synthesis.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}, 2022{\natexlab{b}}.

\bibitem[Forst \& Hoffmann(2010)Forst and Hoffmann]{forst2010optimization}
Forst, W. and Hoffmann, D.
\newblock \emph{Optimization—Theory and Practice}.
\newblock Springer Science \& Business Media, 2010.

\bibitem[Geifman \& El-Yaniv(2019)Geifman and
  El-Yaniv]{geifman2019selectivenet}
Geifman, Y. and El-Yaniv, R.
\newblock Selectivenet: A deep neural network with an integrated reject option.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2151--2159. PMLR, 2019.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1321--1330, 2017.

\bibitem[Gupta \& Ramdas(2022)Gupta and Ramdas]{gupta2022toplabel}
Gupta, C. and Ramdas, A.
\newblock Top-label calibration and multiclass-to-binary reductions.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  770--778, 2016.

\bibitem[Hendrycks \& Gimpel(2016)Hendrycks and Gimpel]{hendrycks2016baseline}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock \emph{arXiv preprint arXiv:1610.02136}, 2016.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, and
  Dietterich]{hendrycks2019oe}
Hendrycks, D., Mazeika, M., and Dietterich, T.
\newblock Deep anomaly detection with outlier exposure.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations}, 2019.

\bibitem[Hsu et~al.(2020)Hsu, Shen, Jin, and Kira]{hsu2020generalized}
Hsu, Y.-C., Shen, Y., Jin, H., and Kira, Z.
\newblock Generalized odin: Detecting out-of-distribution image without
  learning from out-of-distribution data.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10951--10960, 2020.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  4700--4708, 2017.

\bibitem[Huang et~al.(2021)Huang, Geng, and Li]{huang2021importance}
Huang, R., Geng, A., and Li, Y.
\newblock On the importance of gradients for detecting distributional shifts in
  the wild.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~34, 2021.

\bibitem[Jeong \& Kim(2020)Jeong and Kim]{jeong2020ood}
Jeong, T. and Kim, H.
\newblock Ood-maml: Meta-learning for few-shot out-of-distribution detection
  and classification.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Katz-Samuels et~al.(2022)Katz-Samuels, Nakhleh, Nowak, and
  Li]{katzsamuels2022training}
Katz-Samuels, J., Nakhleh, J., Nowak, R., and Li, Y.
\newblock Training ood detectors in their natural habitats.
\newblock In \emph{International Conference on Machine Learning (ICML)}. PMLR,
  2022.

\bibitem[Kornblith et~al.(2021)Kornblith, Chen, Lee, and
  Norouzi]{kornblith2021why}
Kornblith, S., Chen, T., Lee, H., and Norouzi, M.
\newblock Why do better loss functions lead to less transferable features?
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Tech Report}, 2009.

\bibitem[Lee et~al.(2017)Lee, Lee, Lee, and Shin]{lee2017training}
Lee, K., Lee, H., Lee, K., and Shin, J.
\newblock Training confidence-calibrated classifiers for detecting
  out-of-distribution samples.
\newblock \emph{arXiv preprint arXiv:1711.09325}, 2017.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018simple}
Lee, K., Lee, K., Lee, H., and Shin, J.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Lei et~al.(2013)Lei, Robins, and Wasserman]{lei2013distribution}
Lei, J., Robins, J., and Wasserman, L.
\newblock Distribution-free prediction sets.
\newblock \emph{Journal of the American Statistical Association}, 108\penalty0
  (501):\penalty0 278--287, 2013.

\bibitem[Liang et~al.(2018)Liang, Li, and Srikant]{liang2018enhancing}
Liang, S., Li, Y., and Srikant, R.
\newblock Enhancing the reliability of out-of-distribution image detection in
  neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{Lin2017FocalLF}
Lin, T.-Y., Goyal, P., Girshick, R.~B., He, K., and Doll{\'a}r, P.
\newblock Focal loss for dense object detection.
\newblock \emph{2017 IEEE International Conference on Computer Vision (ICCV)},
  pp.\  2999--3007, 2017.

\bibitem[Liu et~al.(2017)Liu, Wen, Yu, Li, Raj, and Song]{liu2017sphereface}
Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., and Song, L.
\newblock Sphereface: Deep hypersphere embedding for face recognition.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  212--220, 2017.

\bibitem[Liu et~al.(2020)Liu, Wang, Owens, and Li]{liu2020energy}
Liu, W., Wang, X., Owens, J., and Li, Y.
\newblock Energy-based out-of-distribution detection.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem[Malinin \& Gales(2018)Malinin and Gales]{malinin2018predictive}
Malinin, A. and Gales, M.
\newblock Predictive uncertainty estimation via prior networks.
\newblock \emph{arXiv preprint arXiv:1802.10501}, 2018.

\bibitem[Ming et~al.(2022{\natexlab{a}})Ming, Fan, and Li]{ming2022posterior}
Ming, Y., Fan, Y., and Li, Y.
\newblock Poem: Out-of-distribution detection with posterior sampling.
\newblock In \emph{International Conference on Machine Learning (ICML)}. PMLR,
  2022{\natexlab{a}}.

\bibitem[Ming et~al.(2022{\natexlab{b}})Ming, Sun, Dia, and Li]{ming2022cider}
Ming, Y., Sun, Y., Dia, O., and Li, Y.
\newblock Cider: Exploiting hyperspherical embeddings for out-of-distribution
  detection.
\newblock \emph{arXiv preprint arXiv:2203.04450}, 2022{\natexlab{b}}.

\bibitem[Mohseni et~al.(2020)Mohseni, Pitale, Yadawa, and
  Wang]{mohseni2020self}
Mohseni, S., Pitale, M., Yadawa, J., and Wang, Z.
\newblock Self-supervised learning for generalizable out-of-distribution
  detection.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pp.\  5216--5223, 2020.

\bibitem[Morteza \& Li(2022)Morteza and Li]{morteza2022provable}
Morteza, P. and Li, Y.
\newblock Provable guarantees for understanding out-of-distribution detection.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2022.

\bibitem[Mukhoti et~al.(2020)Mukhoti, Kulharia, Sanyal, Golodetz, Torr, and
  Dokania]{mukhoti2020calibrating}
Mukhoti, J., Kulharia, V., Sanyal, A., Golodetz, S., Torr, P.~H., and Dokania,
  P.~K.
\newblock Calibrating deep neural networks using focal loss.
\newblock 2020.

\bibitem[M{\"u}ller et~al.(2019)M{\"u}ller, Kornblith, and
  Hinton]{Mller2019WhenDL}
M{\"u}ller, R., Kornblith, S., and Hinton, G.~E.
\newblock When does label smoothing help?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and
  Hauskrecht]{naeini2015obtaining}
Naeini, M.~P., Cooper, G., and Hauskrecht, M.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{Twenty-Ninth AAAI Conference on Artificial Intelligence},
  pp.\  2901--2907, 2015.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock \emph{NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Nguyen, A., Yosinski, J., and Clune, J.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  427--436, 2015.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8024--8035. 2019.

\bibitem[Platt et~al.(1999)]{platt1999probabilistic}
Platt, J. et~al.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock \emph{Advances in Large Margin Classifiers}, 10\penalty0
  (3):\penalty0 61--74, 1999.

\bibitem[Ranjan et~al.(2017)Ranjan, Castillo, and Chellappa]{ranjan2017l2}
Ranjan, R., Castillo, C.~D., and Chellappa, R.
\newblock L2-constrained softmax loss for discriminative face verification.
\newblock \emph{arXiv preprint arXiv:1703.09507}, 2017.

\bibitem[Sastry \& Oore(2020)Sastry and Oore]{sastry2020detecting}
Sastry, C.~S. and Oore, S.
\newblock Detecting out-of-distribution examples with gram matrices.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8491--8501, 2020.

\bibitem[Sehwag et~al.(2021)Sehwag, Chiang, and Mittal]{sehwag2021ssd}
Sehwag, V., Chiang, M., and Mittal, P.
\newblock Ssd: A unified framework for self-supervised outlier detection.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Sohn(2016)]{Sohn2016ImprovedDM}
Sohn, K.
\newblock Improved deep metric learning with multi-class n-pair loss objective.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Sun et~al.(2021)Sun, Guo, and Li]{sun2021react}
Sun, Y., Guo, C., and Li, Y.
\newblock React: Out-of-distribution detection with rectified activations.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Sun et~al.(2022)Sun, Ming, Zhu, and Li]{sun2022knn}
Sun, Y., Ming, Y., Zhu, X., and Li, Y.
\newblock Out-of-distribution detection with deep nearest neighbors.
\newblock In \emph{International Conference on Machine Learning (ICML)}. PMLR,
  2022.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{Szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  2818--2826, 2016.

\bibitem[Tack et~al.(2020)Tack, Mo, Jeong, and Shin]{tack2020csi}
Tack, J., Mo, S., Jeong, J., and Shin, J.
\newblock Csi: Novelty detection via contrastive learning on distributionally
  shifted instances.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Techapanurak \& Okatani(2019)Techapanurak and
  Okatani]{techapanurak2020hyperparameter}
Techapanurak, E. and Okatani, T.
\newblock Hyperparameter-free out-of-distribution detection using softmax of
  scaled cosine similarity.
\newblock \emph{arXiv:1905.10628}, 2019.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and
  Vinyals]{Oord2018RepresentationLW}
van~den Oord, A., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{ArXiv}, abs/1807.03748, 2018.

\bibitem[Van~der Maaten \& Hinton(2008)Van~der Maaten and
  Hinton]{van2008visualizing}
Van~der Maaten, L. and Hinton, G.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (11), 2008.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Feng, and Zhang]{neurips21dbwang}
Wang, D.-B., Feng, L., and Zhang, M.-L.
\newblock Rethinking calibration of deep neural networks: Do not be afraid of
  overconfidence.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2021{\natexlab{a}}.

\bibitem[Wang et~al.(2017)Wang, Xiang, Cheng, and Yuille]{wang2017normface}
Wang, F., Xiang, X., Cheng, J., and Yuille, A.~L.
\newblock Normface: L2 hypersphere embedding for face verification.
\newblock In \emph{Proceedings of the 25th ACM international conference on
  Multimedia}, pp.\  1041--1049, 2017.

\bibitem[Wang et~al.(2018)Wang, Wang, Zhou, Ji, Gong, Zhou, Li, and
  Liu]{wang2018cosface}
Wang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., Li, Z., and Liu, W.
\newblock Cosface: Large margin cosine loss for deep face recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  5265--5274, 2018.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Liu, Bocchieri, and
  Li]{wang2021can}
Wang, H., Liu, W., Bocchieri, A., and Li, Y.
\newblock Can multi-label classification networks know what they don’t know?
\newblock \emph{Advances in Neural Information Processing Systems}, 34,
  2021{\natexlab{b}}.

\bibitem[Wei et~al.(2021)Wei, Tao, Xie, and An]{wei2021odnl}
Wei, H., Tao, L., Xie, R., and An, B.
\newblock Open-set label noise can improve robustness against inherent label
  noise.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Wei et~al.(2022)Wei, Tao, Xie, Feng, and An]{wei@open}
Wei, H., Tao, L., Xie, R., Feng, L., and An, B.
\newblock Open-sampling: Exploring out-of-distribution data for re-balancing
  long-tailed datasets.
\newblock In \emph{International Conference on Machine Learning (ICML)}. PMLR,
  2022.

\bibitem[Wu et~al.(2018)Wu, Xiong, Stella, and Lin]{wu2018unsupervised}
Wu, Z., Xiong, Y., Stella, X.~Y., and Lin, D.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2018.

\bibitem[Xiao et~al.(2010)Xiao, Hays, Ehinger, Oliva, and
  Torralba]{xiao2010sun}
Xiao, J., Hays, J., Ehinger, K.~A., Oliva, A., and Torralba, A.
\newblock Sun database: Large-scale scene recognition from abbey to zoo.
\newblock In \emph{proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3485--3492, 2010.

\bibitem[Xu et~al.(2019)Xu, Sun, Zhang, Zhao, and Lin]{xu2019understanding}
Xu, J., Sun, X., Zhang, Z., Zhao, G., and Lin, J.
\newblock Understanding and improving layer normalization.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Xu et~al.(2015)Xu, Ehinger, Zhang, Finkelstein, Kulkarni, and
  Xiao]{xu2015turkergaze}
Xu, P., Ehinger, K.~A., Zhang, Y., Finkelstein, A., Kulkarni, S.~R., and Xiao,
  J.
\newblock Turkergaze: Crowdsourcing saliency with webcam based eye tracking.
\newblock \emph{arXiv preprint arXiv:1504.06755}, 2015.

\bibitem[Yu et~al.(2015)Yu, Seff, Zhang, Song, Funkhouser, and
  Xiao]{yu2015lsun}
Yu, F., Seff, A., Zhang, Y., Song, S., Funkhouser, T., and Xiao, J.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock \emph{arXiv preprint arXiv:1506.03365}, 2015.

\bibitem[Zadrozny \& Elkan(2001)Zadrozny and Elkan]{zadrozny2001obtaining}
Zadrozny, B. and Elkan, C.
\newblock Obtaining calibrated probability estimates from decision trees and
  naive bayesian classifiers.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  609--616, 2001.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Zhao, Qiao, Wang, and Li]{zhang2019adacos}
Zhang, X., Zhao, R., Qiao, Y., Wang, X., and Li, H.
\newblock Adacos: Adaptively scaling cosine logits for effectively learning
  deep face representations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10823--10832, 2019.

\bibitem[Zhou et~al.(2017)Zhou, Lapedriza, Khosla, Oliva, and
  Torralba]{zhou2017places}
Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A.
\newblock Places: A 10 million image database for scene recognition.
\newblock \emph{IEEE transactions on Pattern Analysis and Machine
  Intelligence}, 40\penalty0 (6):\penalty0 1452--1464, 2017.

\bibitem[Zhu et~al.(2022)Zhu, Dong, and Liu]{zhu@detect}
Zhu, Z., Dong, Z., and Liu, Y.
\newblock Detecting corrupted labels without training a model to predict.
\newblock In \emph{International Conference on Machine Learning (ICML)}. PMLR,
  2022.

\end{thebibliography}
