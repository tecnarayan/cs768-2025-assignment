
@article{zanette2020provably,
  title={Provably efficient reward-agnostic navigation with linear value iteration},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel J and Brunskill, Emma},
  journal={arXiv preprint arXiv:2008.07737},
  year={2020}
}

@inproceedings{lattimore2020learning,
  title={Learning with good feature representations in bandits and in rl with a generative model},
  author={Lattimore, Tor and Szepesvari, Csaba and Weisz, Gellert},
  booktitle={International Conference on Machine Learning},
  pages={5662--5670},
  year={2020},
  organization={PMLR}
}


@article{zhou2020nearly,
  title={Nearly Minimax Optimal Reinforcement Learning for Linear Mixture Markov Decision Processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  journal={arXiv preprint arXiv:2012.08507},
  year={2020}
}

@article{ayoub2020model,
  title={Model-Based Reinforcement Learning with Value-Targeted Regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin F},
  journal={arXiv preprint arXiv:2006.01107},
  year={2020}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@article{dani2008stochastic,
  title={Stochastic linear optimization under bandit feedback},
  author={Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
  year={2008}
}

@article{li2019tight,
  title={Tight regret bounds for infinite-armed linear contextual bandits},
  author={Li, Yingkai and Wang, Yining and Zhou, Yuan},
  journal={arXiv preprint arXiv:1905.01435},
  year={2019}
}

@article{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1902.04779},
  year={2019}
}

@article{li2019nearly,
  title={Nearly minimax-optimal regret for linearly parameterized bandits},
  author={Li, Yingkai and Wang, Yining and Zhou, Yuan},
  journal={arXiv preprint arXiv:1904.00242},
  year={2019}
}

@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011}
}

@article{rusmevichientong2010linearly,
  title={Linearly parameterized bandits},
  author={Rusmevichientong, Paat and Tsitsiklis, John N},
  journal={Mathematics of Operations Research},
  volume={35},
  number={2},
  pages={395--411},
  year={2010},
  publisher={INFORMS}
}

@article{auer2002using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={397--422},
  year={2002}
}

@article{baxter2000model,
  title={A model of inductive bias learning},
  author={Baxter, Jonathan},
  journal={Journal of artificial intelligence research},
  volume={12},
  pages={149--198},
  year={2000}
}

@incollection{thrun1998learning,
  title={Learning to learn: Introduction and overview},
  author={Thrun, Sebastian and Pratt, Lorien},
  booktitle={Learning to learn},
  pages={3--17},
  year={1998},
  publisher={Springer}
}



@inproceedings{liu2016decoding,
  title={Decoding multitask dqn in the world of minecraft},
  author={Liu, Lydia T and Dogan, Urun and Hofmann, Katja},
  booktitle={The 13th European Workshop on Reinforcement Learning (EWRL) 2016},
  year={2016}
}

@article{parisotto2015actor,
  title={Actor-mimic: Deep multitask and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}

@inproceedings{hessel2019multi,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3796--3803},
  year={2019}
}

@article{taylor2009transfer,
  title={Transfer learning for reinforcement learning domains: A survey.},
  author={Taylor, Matthew E and Stone, Peter},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={7},
  year={2009}
}

@article{arora2020provable,
  title={Provable Representation Learning for Imitation Learning via Bi-level Optimization},
  author={Arora, Sanjeev and Du, Simon S and Kakade, Sham and Luo, Yuping and Saunshi, Nikunj},
  journal={arXiv preprint arXiv:2002.10544},
  year={2020}
}


@article{tripuraneni2020provable,
  title={Provable Meta-Learning of Linear Representations},
  author={Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael I},
  journal={arXiv preprint arXiv:2002.11684},
  year={2020}
}

@article{du2020few,
  title={Few-shot learning via learning the representation, provably},
  author={Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi},
  journal={arXiv preprint arXiv:2002.09434},
  year={2020}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2853--2884},
  year={2016},
  publisher={JMLR. org}
}

@article{bengio2013representation,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}

@inproceedings{d2019sharing,
  title={Sharing knowledge in multi-task deep reinforcement learning},
  author={D'Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical Bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4496--4506},
  year={2017}
}

@article{ramsundar2015massively,
  title={Massively multitask networks for drug discovery},
  author={Ramsundar, Bharath and Kearnes, Steven and Riley, Patrick and Webster, Dale and Konerding, David and Pande, Vijay},
  journal={arXiv preprint arXiv:1502.02072},
  year={2015}
}

@article{li2014joint,
  title={Joint collaborative representation with multitask learning for hyperspectral image classification},
  author={Li, Jiayi and Zhang, Hongyan and Zhang, Liangpei and Huang, Xin and Zhang, Lefei},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={52},
  number={9},
  pages={5923--5936},
  year={2014},
  publisher={IEEE}
}

@article{ando2005framework,
  title={A framework for learning predictive structures from multiple tasks and unlabeled data},
  author={Ando, Rie Kubota and Zhang, Tong},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Nov},
  pages={1817--1853},
  year={2005}
}

@article{liu2019multi,
  title={Multi-task deep neural networks for natural language understanding},
  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
  journal={arXiv preprint arXiv:1901.11504},
  year={2019}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2312--2320},
  year={2011}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@book{kallenberg2006foundations,
  title={Foundations of modern probability},
  author={Kallenberg, Olav},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@inproceedings{carpentier2012bandit,
  title={Bandit theory meets compressed sensing for high dimensional stochastic linear bandit},
  author={Carpentier, Alexandra and Munos, R{\'e}mi},
  booktitle={Artificial Intelligence and Statistics},
  pages={190--198},
  year={2012},
  organization={PMLR}
}

@article{zhou2020provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2006.13165},
  year={2020}
}


@inproceedings{lattimore2015linear,
  title={Linear Multi-Resource Allocation with Semi-Bandit Feedback.},
  author={Lattimore, Tor and Crammer, Koby and Szepesv{\'a}ri, Csaba},
  booktitle={NIPS},
  pages={964--972},
  year={2015}
}

@inproceedings{abbasi2012online,
  title={Online-to-confidence-set conversions and application to sparse stochastic bandits},
  author={Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={1--9},
  year={2012},
  organization={PMLR}
}

@article{hao2020high,
  title={High-Dimensional Sparse Linear Bandits},
  author={Hao, Botao and Lattimore, Tor and Wang, Mengdi},
  journal={arXiv preprint arXiv:2011.04020},
  year={2020}
}

@article{lu2020low,
  title={Low-rank generalized linear bandit problems},
  author={Lu, Yangyi and Meisami, Amirhossein and Tewari, Ambuj},
  journal={arXiv preprint arXiv:2006.02948},
  year={2020}
}

@inproceedings{jun2019bilinear,
  title={Bilinear bandits with low-rank structure},
  author={Jun, Kwang-Sung and Willett, Rebecca and Wright, Stephen and Nowak, Robert},
  booktitle={International Conference on Machine Learning},
  pages={3163--3172},
  year={2019},
  organization={PMLR}
}

@misc{yang2020provable,
      title={Provable Benefits of Representation Learning in Linear Bandits}, 
      author={Jiaqi Yang and Wei Hu and Jason D. Lee and Simon S. Du},
      year={2020},
      eprint={2010.06531},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{zanette2020learning,
  title={Learning Near Optimal Policies with Low Inherent Bellman Error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  journal={arXiv preprint arXiv:2003.00153},
  year={2020}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}

@inproceedings{brunskill13mtrl,
  author = {Emma Brunskill and Lihong Li},
  title = {Sample Complexity of Multi-task Reinforcement Learning},
  booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence (UAI-13)},
  year = {2013},
  pages = {122--131}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={arXiv preprint arXiv:1807.03765},
  year={2018}
}

@article{zhang2020reinforcement,
  title={Is reinforcement learning more difficult than bandits? a near-optimal algorithm escaping the curse of horizon},
  author={Zhang, Zihan and Ji, Xiangyang and Du, Simon S},
  journal={arXiv preprint arXiv:2009.13503},
  year={2020}
}

@article{wang2020long,
  title={Is Long Horizon Reinforcement Learning More Difficult Than Short Horizon Reinforcement Learning?},
  author={Wang, Ruosong and Du, Simon S and Yang, Lin F and Kakade, Sham M},
  journal={arXiv preprint arXiv:2005.00527},
  year={2020}
}