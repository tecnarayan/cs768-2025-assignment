\begin{thebibliography}{10}

\bibitem{kim2024alfcl}
Byeonghwi Kim, Minhyuk Seo, and Jonghyun Choi.
\newblock Online continual learning for interactive instruction following agents.
\newblock In {\em The Twelfth International Conference on Learning Representations (ICLR)}, 2024.

\bibitem{belkhale2023dataquality}
Suneel Belkhale, Yuchen Cui, and Dorsa Sadigh.
\newblock Data quality in imitation learning.
\newblock In {\em Advances in neural information processing systems (NeurIPS)}, 2023.

\bibitem{liu2022clpu}
Bo~Liu, Qiang Liu, and Peter Stone.
\newblock Continual learning and private unlearning.
\newblock In {\em Conference on Lifelong Learning Agents (CoLLAs)}, 2022.

\bibitem{chen2021decision}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock {\em Advances in neural information processing systems (NeurIPS)}, 2021.

\bibitem{lee2022multi}
Kuang-Huei Lee, Ofir Nachum, Mengjiao~Sherry Yang, Lisa Lee, Daniel Freeman, Sergio Guadarrama, Ian Fischer, Winnie Xu, Eric Jang, Henryk Michalewski, et~al.
\newblock Multi-game decision transformers.
\newblock {\em Advances in neural information processing systems (NeurIPS)}, 2022.

\bibitem{l2m2023}
Thomas Schmied, Markus Hofmarcher, Fabian Paischer, Razvan Pascanu, and Sepp Hochreiter.
\newblock Learning to modulate pre-trained models in rl.
\newblock {\em Advances in neural information processing systems (NeurIPS)}, 36, 2024.

\bibitem{liu2024tail}
Zuxin Liu, Jesse Zhang, Kavosh Asadi, Yao Liu, Ding Zhao, Shoham Sabach, and Rasool Fakoor.
\newblock {TAIL}: Task-specific adapters for imitation learning with large pretrained models.
\newblock In {\em The Twelfth International Conference on Learning Representations (ICLR)}, 2024.

\bibitem{lotus2023}
Weikang Wan, Yifeng Zhu, Rutav Shah, and Yuke Zhu.
\newblock Lotus: Continual imitation learning for robot manipulation through unsupervised skill discovery.
\newblock In {\em 2024 IEEE International Conference on Robotics and Automation (ICRA)}, 2024.

\bibitem{schopf2022hypernetwork}
Philemon Schopf, Sayantan Auddy, Jakob Hollenstein, and Antonio Rodriguez-Sanchez.
\newblock Hypernetwork-ppo for continual reinforcement learning.
\newblock In {\em Deep RL Workshop at NeurIPS}, 2022.

\bibitem{cril2021}
Chongkai Gao, Haichuan Gao, Shangqi Guo, Tianren Zhang, and Feng Chen.
\newblock Cril: Continual robot imitation learning via generative and prediction model.
\newblock In {\em 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2021.

\bibitem{ghosh2021generalization}
Dibya Ghosh, Jad Rahme, Aviral Kumar, Amy Zhang, Ryan~P Adams, and Sergey Levine.
\newblock Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability.
\newblock {\em Advances in neural information processing systems (NeurIPS)}, 2021.

\bibitem{rusu2016progressive}
Andrei~A Rusu, Neil~C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell.
\newblock Progressive neural networks.
\newblock {\em arXiv preprint arXiv:1606.04671}, 2016.

\bibitem{mallya2018packnet}
Arun Mallya and Svetlana Lazebnik.
\newblock Packnet: Adding multiple tasks to a single network by iterative pruning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2018.

\bibitem{li2019learn2grow}
Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, and Caiming Xiong.
\newblock Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2019.

\bibitem{rao2019continual}
Dushyant Rao, Francesco Visin, Andrei Rusu, Razvan Pascanu, Yee~Whye Teh, and Raia Hadsell.
\newblock Continual unsupervised representation learning.
\newblock {\em Advances in neural information processing systems (NeurIPS)}, 2019.

\bibitem{dacorl2023}
Tiantian Zhang, Zichuan Lin, Yuxing Wang, Deheng Ye, Qiang Fu, Wei Yang, Xueqian Wang, Bin Liang, Bo~Yuan, and Xiu Li.
\newblock Dynamics-adaptive continual reinforcement learning via progressive contextualization.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, 2023.

\bibitem{wang2022dualprompt}
Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, et~al.
\newblock Dualprompt: Complementary prompting for rehearsal-free continual learning.
\newblock {\em European Conference on Computer Vision (ECCV)}, 2022.

\bibitem{l2p2022}
Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister.
\newblock Learning to prompt for continual learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem{lae2023}
Qiankun Gao, Chen Zhao, Yifan Sun, Teng Xi, Gang Zhang, Bernard Ghanem, and Jian Zhang.
\newblock A unified continual learning framework with general parameter-efficient tuning.
\newblock {\em International Conference on Computer Vision (ICCV)}, 2023.

\bibitem{codaprompt2023}
James~Seale Smith, Leonid Karlinsky, Vyshnavi Gutta, Paola Cascante-Bonilla, Donghyun Kim, Assaf Arbelle, Rameswar Panda, Rogerio Feris, and Zsolt Kira.
\newblock Coda-prompt: Continual decomposed attention-based prompting for rehearsal-free continual learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem{huang2024ovor}
Wei-Cheng Huang, Chun-Fu Chen, and Hsiang Hsu.
\newblock {OVOR}: Oneprompt with virtual outlier regularization for rehearsal-free class-incremental learning.
\newblock In {\em The Twelfth International Conference on Learning Representations (ICLR)}, 2024.

\bibitem{color2023}
Martin Wistuba, Prabhu~Teja Sivaprasad, Lukas Balles, and Giovanni Zappella.
\newblock Continual learning with low rank adaptation.
\newblock In {\em NeurIPS 2023 Workshop on Distribution Shifts (DistShifts)}, 2023.

\bibitem{csd2023park}
Seohong Park, Kimin Lee, Youngwoon Lee, and Pieter Abbeel.
\newblock Controllability-aware unsupervised skill discovery.
\newblock In {\em Proceedings of the 40th International Conference on Machine Learning (ICML)}, 2023.

\bibitem{pertsch2020spirl}
Karl Pertsch, Youngwoon Lee, and Joseph~J. Lim.
\newblock Accelerating reinforcement learning with learned skill priors.
\newblock In {\em Conference on robot learning (CoRL)}, 2020.

\bibitem{fist2022}
Kourosh Hakhamaneshi, Ruihan Zhao, Albert Zhan, Pieter Abbeel, and Michael Laskin.
\newblock Hierarchical few-shot imitation with skill transition models.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2022.

\bibitem{nasiriany2022sailor}
Soroush Nasiriany, Tian Gao, Ajay Mandlekar, and Yuke Zhu.
\newblock Learning and retrieval from prior data for skill-based imitation learning.
\newblock In {\em Conference on robot learning (CoRL)}, 2022.

\bibitem{lora2022}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2022.

\bibitem{kmeans}
S.~Lloyd.
\newblock Least squares quantization in pcm.
\newblock {\em IEEE Transactions on Information Theory}, 1982.

\bibitem{fu2020d4rl}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock {\em arXiv preprint arXiv:2004.07219}, 2020.

\bibitem{gupta2019relay}
Abhishek Gupta, Vikash Kumar, Corey Lynch, Sergey Levine, and Karol Hausman.
\newblock Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning.
\newblock {\em arXiv preprint arXiv:1910.11956}, 2019.

\bibitem{yu2020meta}
Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea Finn, and Sergey Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning.
\newblock In {\em Conference on robot learning (CoRL)}, 2020.

\bibitem{nair2022learning}
Suraj Nair, Eric Mitchell, Kevin Chen, Silvio Savarese, Chelsea Finn, et~al.
\newblock Learning language-conditioned robot behavior from offline data and crowd-sourced annotation.
\newblock In {\em Conference on robot learning (CoRL)}, 2022.

\bibitem{garg2022lisa}
Divyansh Garg, Skanda Vaidyanath, Kuno Kim, Jiaming Song, and Stefano Ermon.
\newblock Lisa: Learning interpretable skill abstractions from language.
\newblock {\em Advances in neural information processing systems (NeurIPS)}, 2022.

\bibitem{onis2023}
Sangwoo Shin, Daehee Lee, Minjong Yoo, Woo~Kyung Kim, and Honguk Woo.
\newblock One-shot imitation in a non-stationary environment via multi-modal skill.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2023.

\bibitem{ewc2017}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the national academy of sciences}, 2017.

\bibitem{2020ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In {\em Advances in neural information processing systems (NeurIPS)}, 2020.

\bibitem{wang2023diffusion}
Zhendong Wang, Jonathan~J Hunt, and Mingyuan Zhou.
\newblock Diffusion policies as an expressive policy class for offline reinforcement learning.
\newblock In {\em International Conference on Learning Representations (ICLR) 11}, 2023.

\bibitem{liu2023libero}
Bo~Liu, Yifeng Zhu, Chongkai Gao, Yihao Feng, qiang liu, Yuke Zhu, and Peter Stone.
\newblock {LIBERO}: Benchmarking knowledge transfer for lifelong robot learning.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2023.

\bibitem{shridhar2020alfred}
Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox.
\newblock Alfred: A benchmark for interpreting grounded instructions for everyday tasks.
\newblock In {\em Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition (CVPR)}, 2020.

\bibitem{chaudhry2019tiny}
Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet~K Dokania, Philip~HS Torr, and Marc'Aurelio Ranzato.
\newblock On tiny episodic memories in continual learning.
\newblock {\em arXiv preprint arXiv:1902.10486}, 2019.

\bibitem{kirkpatrick2017overcoming}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the national academy of sciences}, 2017.

\end{thebibliography}
