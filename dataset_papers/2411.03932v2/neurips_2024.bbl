\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and Szepesv{\'a}ri]{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 24:\penalty0 2312--2320, 2011.

\bibitem[Abeille and Lazaric(2017)]{abeille2017Linear}
Marc Abeille and Alessandro Lazaric.
\newblock {Linear Thompson Sampling Revisited}.
\newblock In \emph{Proceedings of the 20th International Conference on Artificial Intelligence and Statistics}, volume~54, pages 176--184. PMLR, PMLR, 2017.

\bibitem[Agrawal and Goyal(2012)]{agrawal2012analysis}
Shipra Agrawal and Navin Goyal.
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock In \emph{Conference on learning theory}, pages 39--1. JMLR Workshop and Conference Proceedings, 2012.

\bibitem[Agrawal and Goyal(2013)]{agrawal2013thompson}
Shipra Agrawal and Navin Goyal.
\newblock Thompson sampling for contextual bandits with linear payoffs.
\newblock In \emph{International conference on machine learning}, pages 127--135. PMLR, 2013.

\bibitem[Auer(2002)]{auer2002using}
Peter Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0 (Nov):\penalty0 397--422, 2002.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, and Kakade]{bubeck2012towards}
S{\'e}bastien Bubeck, Nicolo Cesa-Bianchi, and Sham~M Kakade.
\newblock Towards minimax policies for online linear optimization with bandit feedback.
\newblock In \emph{Conference on Learning Theory}, pages 41--1. JMLR Workshop and Conference Proceedings, 2012.

\bibitem[Chapelle and Li(2011)]{chapelle2011empirical}
Olivier Chapelle and Lihong Li.
\newblock An empirical evaluation of thompson sampling.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, pages 208--214. JMLR Workshop and Conference Proceedings, 2011.

\bibitem[Hamidi and Bayati(2020)]{hamidi2020frequentist}
Nima Hamidi and Mohsen Bayati.
\newblock On frequentist regret of linear thompson sampling.
\newblock \emph{arXiv preprint arXiv:2006.06790}, 2020.

\bibitem[Janz et~al.(2023)Janz, Litvak, and Szepesv{\'a}ri]{janz2023ensemble}
David Janz, Alexander~E Litvak, and Csaba Szepesv{\'a}ri.
\newblock Ensemble sampling for linear bandits: small ensembles suffice.
\newblock \emph{arXiv preprint arXiv:2311.08376}, 2023.

\bibitem[Kveton et~al.(2019)Kveton, Szepesvari, Ghavamzadeh, and Boutilier]{kveton2019perturbed}
Branislav Kveton, Csaba Szepesvari, Mohammad Ghavamzadeh, and Craig Boutilier.
\newblock Perturbed-history exploration in stochastic multi-armed bandits.
\newblock In \emph{International Joint Conference on Artificial Intelligence}, 2019.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:67856126}.

\bibitem[Kveton et~al.(2020{\natexlab{a}})Kveton, Szepesv{\'a}ri, Ghavamzadeh, and Boutilier]{kveton2020perturbed}
Branislav Kveton, Csaba Szepesv{\'a}ri, Mohammad Ghavamzadeh, and Craig Boutilier.
\newblock Perturbed-history exploration in stochastic linear bandits.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 530--540. PMLR, 2020{\natexlab{a}}.

\bibitem[Kveton et~al.(2020{\natexlab{b}})Kveton, Zaheer, Szepesvari, Li, Ghavamzadeh, and Boutilier]{kveton2020randomized}
Branislav Kveton, Manzil Zaheer, Csaba Szepesvari, Lihong Li, Mohammad Ghavamzadeh, and Craig Boutilier.
\newblock Randomized exploration in generalized linear bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 2066--2076. PMLR, 2020{\natexlab{b}}.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Laurent and Massart(2000)]{laurent2000adaptive}
Beatrice Laurent and Pascal Massart.
\newblock Adaptive estimation of a quadratic functional by model selection.
\newblock \emph{Annals of statistics}, pages 1302--1338, 2000.

\bibitem[Lu and Van~Roy(2017)]{lu2017ensemble}
Xiuyuan Lu and Benjamin Van~Roy.
\newblock Ensemble sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Lu et~al.(2018)Lu, Wen, and Kveton]{lu2018efficient}
Xiuyuan Lu, Zheng Wen, and Branislav Kveton.
\newblock Efficient online recommendation via low-rank ensemble sampling.
\newblock In \emph{Proceedings of the 12th ACM Conference on Recommender Systems}, pages 460--464, 2018.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and Van~Roy]{osband2016deep}
Ian Osband, Charles Blundell, Alexander Pritzel, and Benjamin Van~Roy.
\newblock Deep exploration via bootstrapped dqn.
\newblock \emph{Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem[Osband et~al.(2018)Osband, Aslanides, and Cassirer]{osband2018randomized}
Ian Osband, John Aslanides, and Albin Cassirer.
\newblock Randomized prior functions for deep reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Osband et~al.(2019)Osband, Van~Roy, Russo, Wen, et~al.]{osband2019deep}
Ian Osband, Benjamin Van~Roy, Daniel~J Russo, Zheng Wen, et~al.
\newblock Deep exploration via randomized value functions.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0 (124):\penalty0 1--62, 2019.

\bibitem[Qin et~al.(2022)Qin, Wen, Lu, and Van~Roy]{qin2022analysis}
Chao Qin, Zheng Wen, Xiuyuan Lu, and Benjamin Van~Roy.
\newblock An analysis of ensemble sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 21602--21614, 2022.

\bibitem[Russo and Van~Roy(2014)]{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via posterior sampling.
\newblock \emph{Mathematics of Operations Research}, 39\penalty0 (4):\penalty0 1221--1243, 2014.

\bibitem[Russo et~al.(2018)Russo, Van~Roy, Kazerouni, Osband, Wen, et~al.]{russo2018tutorial}
Daniel~J Russo, Benjamin Van~Roy, Abbas Kazerouni, Ian Osband, Zheng Wen, et~al.
\newblock A tutorial on thompson sampling.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning}, 11\penalty0 (1):\penalty0 1--96, 2018.

\bibitem[Thompson(1933)]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in view of the evidence of two samples.
\newblock \emph{Biometrika}, 25\penalty0 (3/4):\penalty0 285--294, 1933.

\bibitem[Wan et~al.(2023)Wan, Wei, Kveton, and Song]{wan2023multiplier}
Runzhe Wan, Haoyu Wei, Branislav Kveton, and Rui Song.
\newblock Multiplier bootstrap-based exploration.
\newblock In \emph{International Conference on Machine Learning}, pages 35444--35490. PMLR, 2023.

\bibitem[Zhou et~al.(2024)Zhou, Hao, Wen, Zhang, and Sun]{zhou2024stochastic}
Jie Zhou, Botao Hao, Zheng Wen, Jingfei Zhang, and Will~Wei Sun.
\newblock Stochastic low-rank tensor bandits for multi-dimensional online decision making.
\newblock \emph{Journal of the American Statistical Association}, pages 1--14, 2024.

\bibitem[Zhu and Van~Roy(2023)]{zhu2023deep}
Zheqing Zhu and Benjamin Van~Roy.
\newblock Deep exploration for recommendation systems.
\newblock In \emph{Proceedings of the 17th ACM Conference on Recommender Systems}, pages 963--970, 2023.

\end{thebibliography}
