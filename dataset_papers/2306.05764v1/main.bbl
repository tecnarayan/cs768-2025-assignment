\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agussurja et~al.(2022)Agussurja, Xu, and
  Low]{agussurja2022_bayesian_para}
Agussurja, L., Xu, X., and Low, B. K.~H.
\newblock On the convergence of the {Shapley} value in parametric {Bayesian}
  learning games.
\newblock In \emph{Proc. ICML}, 2022.

\bibitem[Bahir et~al.(1966)Bahir, And, Peleg, Maschler, and
  Peleg]{Bahir1966-desirability}
Bahir, M., And, M., Peleg, B., Maschler, M., and Peleg, B.
\newblock A characterization, existence proof and dimension bounds for the
  kernel of a game.
\newblock \emph{Pacific Journal of Mathematics}, 18\penalty0 (2), 1966.

\bibitem[Benczúr et~al.(2018)Benczúr, Kocsis, and Pálovics]{onlineml2018}
Benczúr, A.~A., Kocsis, L., and Pálovics, R.
\newblock Online machine learning in big data streams.
\newblock {arXiv}:802.05872, 2018.

\bibitem[Bifet \& Kirkby(2009)Bifet and Kirkby]{Bifet2009DATASM}
Bifet, A. and Kirkby, R.
\newblock Data stream mining: A practical approach.
\newblock Technical report, University of Waikato, 2009.

\bibitem[Blum et~al.(2021)Blum, Haghtalab, Phillips, and Shao]{blum2021one}
Blum, A., Haghtalab, N., Phillips, R.~L., and Shao, H.
\newblock One for one, or all for all: Equilibria and optimality of
  collaboration in federated learning.
\newblock In \emph{Proc. ICML}, 2021.

\bibitem[{Brendan McMahan} et~al.(2017){Brendan McMahan}, Moore, Ramage,
  Hampson, and {Ag{\"{u}}era y Arcas}]{BrendanMcMahan2017-FedAvg}
{Brendan McMahan}, H., Moore, E., Ramage, D., Hampson, S., and {Ag{\"{u}}era y
  Arcas}, B.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Proc. AISTATS}, 2017.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Ning, Slawski, and
  Rangwala]{chen2020asynchronous}
Chen, Y., Ning, Y., Slawski, M., and Rangwala, H.
\newblock Asynchronous online federated learning for edge devices with non-iid
  data.
\newblock In \emph{Proc. IEEE Big Data}, pp.\  15--24, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Liu, Ng, Yu, Liu, and
  Yang]{Chen2020-FL-incentive}
Chen, Z., Liu, Z., Ng, K.~L., Yu, H., Liu, Y., and Yang, Q.
\newblock A gamified research tool for incentive mechanism design in federated
  learning.
\newblock In Yang, Q., Fan, L., and Yu, H. (eds.), \emph{Federated Learning},
  volume 12500 of \emph{Lecture Notes in Computer Science}, pp.\  168--175.
  Springer, Cham, 2020{\natexlab{b}}.

\bibitem[Cong et~al.(2020)Cong, Yu, Weng, and Yiu]{Cong2020-FL-incentive}
Cong, M., Yu, H., Weng, X., and Yiu, S.
\newblock A game-theoretic framework for incentive mechanism design in
  federated learning.
\newblock In Yang, Q., Fan, L., and Yu, H. (eds.), \emph{Federated Learning},
  volume 12500 of \emph{Lecture Notes in Computer Science}, pp.\  205--222.
  Springer, Cham, 2020.

\bibitem[Donahue \& Kleinberg(2021)Donahue and Kleinberg]{donahue2021model}
Donahue, K. and Kleinberg, J.
\newblock Model-sharing games: Analyzing federated learning under voluntary
  participation.
\newblock In \emph{Proc. AAAI}, 2021.

\bibitem[Fan et~al.(2021)Fan, Ma, Dai, Jing, Tan, and
  Low]{fan2021faulttolerant}
Fan, F.~X., Ma, Y., Dai, Z., Jing, W., Tan, C., and Low, B. K.~H.
\newblock Fault-tolerant federated reinforcement learning with theoretical
  guarantee.
\newblock In \emph{Proc. NeurIPS}, 2021.

\bibitem[Fatima et~al.(2008)Fatima, Wooldridge, and
  Jennings]{Fatima2008-linear-SV-approximation}
Fatima, S.~S., Wooldridge, M., and Jennings, N.~R.
\newblock {A linear approximation method for the Shapley value}.
\newblock \emph{Artificial Intelligence}, 172\penalty0 (14):\penalty0
  1673--1699, 2008.
\newblock ISSN 00043702.

\bibitem[Flores(2020)]{Flores2020_nvidia_FL_medical}
Flores, M.
\newblock Medical institutions collaborate to improve mammogram assessment {AI}
  with {NVIDIA} {Clara} federated learning.
\newblock
  \url{https://blogs.nvidia.com/blog/2020/04/15/federated-learning-mammogram-assessment/},
  2020.

\bibitem[Ghorbani \& Zou(2019)Ghorbani and Zou]{data-shapley-Ghorbani2019}
Ghorbani, A. and Zou, J.~Y.
\newblock Data {Shapley}: Equitable valuation of data for machine learning.
\newblock In \emph{Proc. ICML}, 2019.

\bibitem[Hale(2019)]{Hale2019_mellody_FL}
Hale, C.
\newblock The {MELLODDY} project.
\newblock
  \url{https://www.fiercebiotech.com/special-report/top-ai-lighthouse-projects-to-keep-eye-biopharma},
  2019.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{He_2015_ICCV}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  {ImageNet} classification.
\newblock In \emph{Proc. ICCV}, 2015.

\bibitem[Henze \& Zirkler(1990)Henze and Zirkler]{Henze1990ACO}
Henze, N. and Zirkler, B.
\newblock A class of invariant consistent tests for multivariate normality.
\newblock \emph{Communications in Statistics - Theory and Methods}, 19\penalty0
  (10):\penalty0 3595--3617, 1990.

\bibitem[Hoang et~al.(2021)Hoang, Hong, Xiao, Low, and Sun]{Hoang2021_AID}
Hoang, T.~N., Hong, S., Xiao, C., Low, B. K.~H., and Sun, J.
\newblock Aid: Active distillation machine to leverage pre-trained black-box
  models in private data settings.
\newblock 2021.

\bibitem[Hotelling(1931)]{hotelling}
Hotelling, H.
\newblock The generalization of {Student's} ratio.
\newblock \emph{Annals of Mathematical Statistics}, 2\penalty0 (3):\penalty0
  360--378, 1931.

\bibitem[Jin et~al.(2021)Jin, Jiao, Qian, Zhang, and
  Lu]{Jin2021-streaming-data}
Jin, Y., Jiao, L., Qian, Z., Zhang, S., and Lu, S.
\newblock Budget-aware online control of edge federated learning on streaming
  data with stochastic inputs.
\newblock \emph{IEEE Journal on Selected Areas in Communications}, 39\penalty0
  (12):\penalty0 3704--3722, 2021.

\bibitem[Krause \& Guestrin(2007)Krause and
  Guestrin]{Krause2007-explore-vs-exploit}
Krause, A. and Guestrin, C.
\newblock Nonmyopic active learning of {G}aussian processes: An
  exploration-exploitation approach.
\newblock In \emph{Proc. ICML}, 2007.

\bibitem[Krizhevsky(2009)]{cifar10}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Master's thesis, Department of Computer Science, University of
  Toronto, 2009.

\bibitem[Lam et~al.(2021)Lam, Hoang, Low, and Jaillet]{Lam2021ModelFusion}
Lam, T.~C., Hoang, N., Low, B. K.~H., and Jaillet, P.
\newblock Model fusion for personalized learning.
\newblock In \emph{Proc. ICML}, 2021.

\bibitem[Le et~al.(2021)Le, Lei, Mu, Zhang, Zeng, and
  Liao]{Le2021_continuous_stream_fl}
Le, J., Lei, X., Mu, N., Zhang, H., Zeng, K., and Liao, X.
\newblock Federated continuous learning with broad network architecture.
\newblock \emph{IEEE Transactions on Cybernetics}, 51\penalty0 (8):\penalty0
  3874--3888, 2021.

\bibitem[LeCun et~al.(1990)LeCun, Boser, Denker, Henderson, Howard, Hubbard,
  and Jackel]{mnist}
LeCun, Y., Boser, B., Denker, J., Henderson, D., Howard, R., Hubbard, W., and
  Jackel, L.
\newblock Handwritten digit recognition with a back-propagation network.
\newblock In \emph{Proc. NeurIPS}, 1990.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Sahu, Zaheer, Sanjabi, Talwalkar, and
  Smith]{li2020-fl-sampling-with-replacement}
Li, T., Sahu, A.~K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V.
\newblock Federated optimization in heterogeneous networks.
\newblock In \emph{Proc. {MLSys}}, pp.\  429--450, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Sanjabi, Beirami, and
  Smith]{li2019-qFFL}
Li, T., Sanjabi, M., Beirami, A., and Smith, V.
\newblock Fair resource allocation in federated learning.
\newblock In \emph{Proc. ICLR}, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Beirami, Sanjabi, and
  Smith]{Li2021_TERM}
Li, T., Beirami, A., Sanjabi, M., and Smith, V.
\newblock Tilted empirical risk minimization.
\newblock In \emph{Proc. ICLR}, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Hu, Beirami, and Smith]{Li2021_ditto}
Li, T., Hu, S., Beirami, A., and Smith, V.
\newblock Ditto: Fair and robust federated learning through personalization.
\newblock In \emph{Proc. ICML}, pp.\  6357--6368, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2019)Li, Huang, Yang, Wang, and Zhang]{Li2019-fedavg-noniid}
Li, X., Huang, K., Yang, W., Wang, S., and Zhang, Z.
\newblock On the convergence of {FedAvg} on non-iid data.
\newblock In \emph{Proc. ICLR}, 2019.

\bibitem[Losing et~al.(2018)Losing, Hammer, and Wersing]{LOSING20181261}
Losing, V., Hammer, B., and Wersing, H.
\newblock Incremental on-line learning: A review and comparison of state of the
  art algorithms.
\newblock \emph{Neurocomputing}, 275:\penalty0 1261--1274, 2018.

\bibitem[Mathai \& Provost(1992)Mathai and Provost]{Mathai1994-non-normality}
Mathai, A.~M. and Provost, S.~B.
\newblock \emph{Quadratic Forms in Random Variables: Theory and Applications}.
\newblock Statistics: Textbooks and Monographs. Marcel Dekker, New York, 1992.

\bibitem[Miller \& Chin(1996)Miller and Chin]{Miller1996_finance_monthly}
Miller, P.~J. and Chin, D.~M.
\newblock Using monthly data to improve quarterly model forecasts.
\newblock \emph{Federal Reserve Bank of Minneapolis Quarterly Review},
  20\penalty0 (2), 1996.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2013playing}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Mohri et~al.(2019)Mohri, Sivek, and Suresh]{Mohri2019_afl}
Mohri, M., Sivek, G., and Suresh, A.~T.
\newblock Agnostic federated learning.
\newblock In \emph{Proc. ICML}, pp.\  4615--4625, 2019.

\bibitem[Muehlenpfordt(2020)]{electricity2020}
Muehlenpfordt, J.
\newblock Data package time series.
\newblock \url{https://doi.org/10.25832/time_series/2020-10-06}, 2020.

\bibitem[Nagalapatti \& Narayanam(2021)Nagalapatti and
  Narayanam]{Nagalapatti2021-game-of-gradients-fl}
Nagalapatti, L. and Narayanam, R.
\newblock Game of gradients : Mitigating irrelevant clients in federated
  learning.
\newblock In \emph{Proc. AAAI}, 2021.

\bibitem[Nguyen et~al.(2022)Nguyen, Low, and Jaillet]{Phong2022_CML}
Nguyen, Q.~P., Low, B. K.~H., and Jaillet, P.
\newblock Trade-off between payoff and model rewards in shapley-fair
  collaborative machine learning.
\newblock In \emph{Proc. NeurIPS}, 2022.

\bibitem[Ntakaris et~al.(2018)Ntakaris, Magris, Kanniainen, Gabbouj, and
  Iosifidis]{hft2018}
Ntakaris, A., Magris, M., Kanniainen, J., Gabbouj, M., and Iosifidis, A.
\newblock Benchmark dataset for mid-price forecasting of limit order book data
  with machine learning methods.
\newblock \emph{Journal of Forecasting}, 37\penalty0 (8):\penalty0 852–866,
  2018.

\bibitem[Qi et~al.(2021)Qi, Zhou, Lei, and Zheng]{qi2021federated}
Qi, J., Zhou, Q., Lei, L., and Zheng, K.
\newblock Federated reinforcement learning: Techniques, applications, and open
  challenges.
\newblock {arXiv}:2108.11887, 2021.

\bibitem[Qiao et~al.(2023)Qiao, Xu, and Low]{Qiao2023}
Qiao, R., Xu, X., and Low, B. K.~H.
\newblock Collaborative causal inference with fair incentives.
\newblock In \emph{Proc. ICML}, 2023.

\bibitem[Richardson et~al.(2020)Richardson, Filos{-}Ratsikas, and
  Faltings]{Richardson2020-FL-incentive}
Richardson, A., Filos{-}Ratsikas, A., and Faltings, B.
\newblock Budget-bounded incentives for federated learning.
\newblock In Yang, Q., Fan, L., and Yu, H. (eds.), \emph{Federated Learning},
  volume 12500 of \emph{Lecture Notes in Computer Science}, pp.\  176--188.
  Springer, Cham, 2020.

\bibitem[Rozemberczki \& Sarkar(2021)Rozemberczki and
  Sarkar]{Rozemberczki2021-ensemble-games}
Rozemberczki, B. and Sarkar, R.
\newblock The {Shapley} value of classifiers in ensemble games.
\newblock In \emph{Proc. CIKM}, pp.\  1558--1567, 2021.

\bibitem[Shapley(1953)]{shapley1953value}
Shapley, L.~S.
\newblock A value for $n$-person games.
\newblock In Kuhn, H.~W. and Tucker, A.~W. (eds.), \emph{Contributions to the
  Theory of Games}, volume~2, pp.\  307--317. Princeton Univ. Press, 1953.

\bibitem[Sim et~al.(2020)Sim, Zhang, Chan, and Low]{Sim2020}
Sim, R. H.~L., Zhang, Y., Chan, M.~C., and Low, B. K.~H.
\newblock Collaborative machine learning with incentive-aware model rewards.
\newblock In \emph{Proc. ICML}, 2020.

\bibitem[Sim et~al.(2022)Sim, Xu, and Low]{sim2022_ijcai}
Sim, R. H.~L., Xu, X., and Low, B. K.~H.
\newblock Data valuation in machine learning: "ingredients", strategies, and
  open challenges.
\newblock In \emph{Proc. IJCAI}, 2022.
\newblock Survey Track.

\bibitem[Song et~al.(2019)Song, Tong, and Wei]{profit-allocation-FL-Song2019}
Song, T., Tong, Y., and Wei, S.
\newblock Profit allocation for {Federated} learning.
\newblock In \emph{Proc. IEEE Big Data}, pp.\  2577--2586, 2019.

\bibitem[Tay et~al.(2022)Tay, Xu, Foo, and Low]{Seb2022-incentivizing}
Tay, S.~S., Xu, X., Foo, C.~S., and Low, K.~H.
\newblock Incentivizing collaboration in machine learning via synthetic data
  rewards.
\newblock In \emph{Proc. AAAI}, 2022.

\bibitem[{van Leersum} et~al.(2013){van Leersum}, Snijders, Henneman,
  Kolfschoten, Gooiker, {ten Berge}, Eddes, Wouters, {Tollenaar on behalf of
  the Dutch Surgical Colorectal Cancer Audit Group}, Bemelman, M., Elferink,
  Karsten, M., Lemmens, Rutten, Manusama, {van de Velde}, Meijerink, Wiggers,
  {van der Harst}, Dekker, and Boerma]{Leersum2013_medicine_weekly}
{van Leersum}, N.~J., Snijders, H.~S., Henneman, D., Kolfschoten, N.~E.,
  Gooiker, G.~A., {ten Berge}, M.~G., Eddes, E.~H., Wouters, M. W. J.~M.,
  {Tollenaar on behalf of the Dutch Surgical Colorectal Cancer Audit Group}, R.
  A. E.~M., Bemelman, W.~A., M., v.~R., Elferink, M.~A., Karsten, T.~M., M., v.
  J. H.~J., Lemmens, V. E. P.~P., Rutten, H. J.~T., Manusama, E.~R., {van de
  Velde}, C. J.~H., Meijerink, W., Wiggers, T., {van der Harst}, E., Dekker, J.
  W.~T., and Boerma, D.
\newblock The {D}utch surgical colorectal audit.
\newblock \emph{European Journal of Surgical Oncology}, 39\penalty0
  (10):\penalty0 1063--1070, 2013.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Charles, Xu, Joshi, McMahan,
  Arcas, Al-Shedivat, Andrew, Avestimehr, Daly, Data, Diggavi, Eichner,
  Gadhikar, Garrett, Girgis, Hanzely, Hard, He, Horvath, Huo, Ingerman, Jaggi,
  Javidi, Kairouz, Kale, Karimireddy, Konecny, Koyejo, Li, Liu, Mohri, Qi,
  Reddi, Richtarik, Singhal, Smith, Soltanolkotabi, Song, Suresh, Stich,
  Talwalkar, Wang, Woodworth, Wu, Yu, Yuan, Zaheer, Zhang, Zhang, Zheng, Zhu,
  and Zhu]{Wang2021_FL_field_guide}
Wang, J., Charles, Z., Xu, Z., Joshi, G., McMahan, H.~B., Arcas, B. A.~y.,
  Al-Shedivat, M., Andrew, G., Avestimehr, S., Daly, K., Data, D., Diggavi, S.,
  Eichner, H., Gadhikar, A., Garrett, Z., Girgis, A.~M., Hanzely, F., Hard, A.,
  He, C., Horvath, S., Huo, Z., Ingerman, A., Jaggi, M., Javidi, T., Kairouz,
  P., Kale, S., Karimireddy, S.~P., Konecny, J., Koyejo, S., Li, T., Liu, L.,
  Mohri, M., Qi, H., Reddi, S.~J., Richtarik, P., Singhal, K., Smith, V.,
  Soltanolkotabi, M., Song, W., Suresh, A.~T., Stich, S.~U., Talwalkar, A.,
  Wang, H., Woodworth, B., Wu, S., Yu, F.~X., Yuan, H., Zaheer, M., Zhang, M.,
  Zhang, T., Zheng, C., Zhu, C., and Zhu, W.
\newblock A field guide to federated optimization.
\newblock {arXiv}:2107.06917, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2020)Wang, Rausch, Zhang, Jia, and
  Song]{Wang2020-SV-in-FL}
Wang, T., Rausch, J., Zhang, C., Jia, R., and Song, D.
\newblock A principled approach to data valuation for federated learning.
\newblock In Yang, Q., Fan, L., and Yu, H. (eds.), \emph{Federated Learning},
  volume 12500 of \emph{Lecture Notes in Computer Science}, pp.\  153--167.
  Springer, Cham, 2020.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Yang, and
  Jia]{Wang2021-learnability}
Wang, T., Yang, Y., and Jia, R.
\newblock Learnability of learning performance and its application to data
  valuation.
\newblock {arXiv}:2107.06336, 2021{\natexlab{b}}.

\bibitem[Ward \& Clarkson(2004)Ward and Clarkson]{medicalerror2004}
Ward, J.~R. and Clarkson, P.~J.
\newblock An analysis of medical device-related errors: prevalence and possible
  solutions.
\newblock \emph{Journal of Medical Engineering \& Technology}, 28\penalty0
  (1):\penalty0 2--21, 2004.
\newblock \doi{10.1080/0309190031000123747}.
\newblock URL \url{https://doi.org/10.1080/0309190031000123747}.

\bibitem[Wu et~al.(2022)Wu, Shu, and Low]{Wu2022DAVINZDV}
Wu, Z., Shu, Y., and Low, B. K.~H.
\newblock Davinz: Data valuation using deep neural networks at initialization.
\newblock In \emph{Proc. ICML}, 2022.

\bibitem[Xu \& Wang(2021)Xu and Wang]{Xu2021_FL_repeated_game_long_term}
Xu, J. and Wang, H.
\newblock Client selection and bandwidth allocation in wireless federated
  learning networks: A long-term perspective.
\newblock \emph{IEEE Transactions on Wireless Communications}, 20\penalty0
  (2):\penalty0 1188--1200, 2021.

\bibitem[Xu et~al.(2021{\natexlab{a}})Xu, Lyu, Ma, Miao, Foo, and
  Low]{Xu2021-fair-CML}
Xu, X., Lyu, L., Ma, X., Miao, C., Foo, C.~S., and Low, B. K.~H.
\newblock Gradient-driven rewards to guarantee fairness in collaborative
  machine learning.
\newblock In \emph{Proc. NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Xu et~al.(2021{\natexlab{b}})Xu, Wu, Foo, and Low]{Xu2021ValidationFA}
Xu, X., Wu, Z., Foo, C.~S., and Low, B. K.~H.
\newblock Validation free and replication robust volume-based data valuation.
\newblock In \emph{Proc. NeurIPS}, 2021{\natexlab{b}}.

\bibitem[Xu et~al.(2023)Xu, Wu, Verma, Foo, and Low]{Xu2023ActiveLearning}
Xu, X., Wu, Z., Verma, A., Foo, C.~S., and Low, B. K.~H.
\newblock {FAIR}: Fair collaborative active learning with individual
  rationality for scientific discovery.
\newblock In \emph{Proc. AISTATS}, 2023.

\bibitem[Yang et~al.(2021)Yang, Shi, and Ni]{medmnistv1}
Yang, J., Shi, R., and Ni, B.
\newblock {MedMNIST} classification decathlon: A lightweight {AutoML} benchmark
  for medical image analysis.
\newblock In \emph{IEEE 18th International Symposium on Biomedical Imaging
  (ISBI)}, pp.\  191--195, 2021.

\bibitem[Yoon et~al.(2021)Yoon, Jeong, Lee, Yang, and
  Hwang]{yoon21-federated-continual-learning}
Yoon, J., Jeong, W., Lee, G., Yang, E., and Hwang, S.~J.
\newblock Federated continual learning with weighted inter-client transfer.
\newblock In \emph{Proc. ICML}, 2021.

\bibitem[Young(1985)]{Young1985-monotonicity}
Young, H.~P.
\newblock Monotonic solutions of cooperative games.
\newblock \emph{International Journal of Game Theory}, 14\penalty0
  (2):\penalty0 65--72, 1985.

\bibitem[Yu et~al.(2020)Yu, Liu, Liu, Chen, Cong, Weng, Niyato, and
  Yang]{Yu-et-al:2020AIES}
Yu, H., Liu, Z., Liu, Y., Chen, T., Cong, M., Weng, X., Niyato, D., and Yang,
  Q.
\newblock A fairness-aware incentive scheme for federated learning.
\newblock In \emph{Proc. AIES}, 2020.

\bibitem[Yuan et~al.(2021)Yuan, Jiao, Zhu, and
  Zhang]{Yuan2021_incentive_FL_long_term}
Yuan, Y., Jiao, L., Zhu, K., and Zhang, L.
\newblock Incentivizing federated learning under long-term energy constraint
  via online randomized auctions.
\newblock \emph{IEEE Transactions on Wireless Communications}, pp.\  1--14,
  2021.

\bibitem[Zhang et~al.(2021)Zhang, Wu, and Pan]{Zhang2021-FL-reverse-auction}
Zhang, J., Wu, Y., and Pan, R.
\newblock Incentive mechanism for horizontal federated learning based on
  reputation and reverse auction.
\newblock In \emph{Proc. WWW}, pp.\  947–956, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Ma, and Chen]{Zhang2022_FL_long_term}
Zhang, N., Ma, Q., and Chen, X.
\newblock Enabling long-term cooperation in cross-silo federated learning: A
  repeated game perspective.
\newblock \emph{IEEE Transactions on Mobile Computing}, 2022.

\bibitem[Zhang \& Sutton(2017)Zhang and Sutton]{zhang2018deeper}
Zhang, S. and Sutton, R.~S.
\newblock A deeper look at experience replay.
\newblock In \emph{Proc. NeurIPS Deep Reinforcement Learning Symposium}, 2017.

\bibitem[Zhao et~al.(2020)Zhao, Xu, Yan, Zhang, Fu, and
  Wang]{Zhao2020timeliness}
Zhao, Y., Xu, K., Yan, F., Zhang, Y., Fu, Y., and Wang, H.
\newblock Auction-based high timeliness data pricing under mobile and wireless
  networks.
\newblock In \emph{Proc. IEEE ICC}, 2020.

\bibitem[Zhou et~al.(2023)Zhou, Xu, Sim, Foo, and Low]{zhou2023}
Zhou, Z., Xu, X., Sim, R. H.~L., Foo, C.~S., and Low, B. K.~H.
\newblock Probably approximate {S}hapley fairness with applications in machine
  learning.
\newblock In \emph{Proc. AAAI}, 2023.

\end{thebibliography}
