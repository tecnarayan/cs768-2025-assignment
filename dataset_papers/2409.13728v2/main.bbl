\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahuja and Mansouri(2024)]{ahuja_provable_2024}
K.~Ahuja and A.~Mansouri.
\newblock On {Provable} {Length} and {Compositional} {Generalization}, Feb. 2024.
\newblock URL \url{http://arxiv.org/abs/2402.04875}.
\newblock arXiv:2402.04875 [cs, stat].

\bibitem[Beck et~al.(2024)Beck, Pöppel, Spanring, Auer, Prudnikova, Kopp, Klambauer, Brandstetter, and Hochreiter]{beck_xlstm_2024}
M.~Beck, K.~Pöppel, M.~Spanring, A.~Auer, O.~Prudnikova, M.~Kopp, G.~Klambauer, J.~Brandstetter, and S.~Hochreiter.
\newblock {xLSTM}: {Extended} {Long} {Short}-{Term} {Memory}, May 2024.
\newblock URL \url{http://arxiv.org/abs/2405.04517}.
\newblock arXiv:2405.04517 [cs, stat].

\bibitem[Brady et~al.(2023)Brady, Zimmermann, Sharma, Schölkopf, von Kügelgen, and Brendel]{brady_provably_2023}
J.~Brady, R.~S. Zimmermann, Y.~Sharma, B.~Schölkopf, J.~von Kügelgen, and W.~Brendel.
\newblock Provably {Learning} {Object}-{Centric} {Representations}, May 2023.
\newblock URL \url{http://arxiv.org/abs/2305.14229}.
\newblock arXiv:2305.14229 [cs].

\bibitem[Chan et~al.(2022)Chan, Santoro, Lampinen, Wang, Singh, Richemond, McClelland, and Hill]{chan2022data}
S.~Chan, A.~Santoro, A.~Lampinen, J.~Wang, A.~Singh, P.~Richemond, J.~McClelland, and F.~Hill.
\newblock Data distributional properties drive emergent in-context learning in transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 18878--18891, 2022.

\bibitem[Chen et~al.(2024)Chen, Shwartz-Ziv, Cho, Leavitt, and Saphra]{chen2024sudden}
A.~Chen, R.~Shwartz-Ziv, K.~Cho, M.~L. Leavitt, and N.~Saphra.
\newblock Sudden drops in the loss: Syntax acquisition, phase transitions, and simplicity bias in mlms, 2024.

\bibitem[Chomsky(1956)]{chomsky}
N.~Chomsky.
\newblock Three models for the description of language.
\newblock \emph{IRE Transactions on Information Theory}, 2\penalty0 (3):\penalty0 113--124, 1956.
\newblock \doi{10.1109/TIT.1956.1056813}.

\bibitem[Deletang et~al.(2022)Deletang, Ruoss, Grau-Moya, Genewein, Wenliang, Catt, Cundy, Hutter, Legg, Veness, and Ortega]{deletang_neural_2022}
G.~Deletang, A.~Ruoss, J.~Grau-Moya, T.~Genewein, L.~K. Wenliang, E.~Catt, C.~Cundy, M.~Hutter, S.~Legg, J.~Veness, and P.~A. Ortega.
\newblock Neural {Networks} and the {Chomsky} {Hierarchy}.
\newblock Sept. 2022.
\newblock URL \url{https://openreview.net/forum?id=WbxHAzkeQcn}.

\bibitem[Dingle et~al.(2018)Dingle, Camargo, and Louis]{dingle_inputoutput_2018}
K.~Dingle, C.~Q. Camargo, and A.~A. Louis.
\newblock Input–output maps are strongly biased towards simple outputs.
\newblock \emph{Nature Communications}, 9\penalty0 (1):\penalty0 761, Feb. 2018.
\newblock ISSN 2041-1723.
\newblock \doi{10.1038/s41467-018-03101-6}.
\newblock URL \url{https://www.nature.com/articles/s41467-018-03101-6}.
\newblock Number: 1 Publisher: Nature Publishing Group.

\bibitem[Dziri et~al.(2023)Dziri, Lu, Sclar, Li, Jiang, Lin, West, Bhagavatula, Bras, Hwang, Sanyal, Welleck, Ren, Ettinger, Harchaoui, and Choi]{dziri2023faith}
N.~Dziri, X.~Lu, M.~Sclar, X.~L. Li, L.~Jiang, B.~Y. Lin, P.~West, C.~Bhagavatula, R.~L. Bras, J.~D. Hwang, S.~Sanyal, S.~Welleck, X.~Ren, A.~Ettinger, Z.~Harchaoui, and Y.~Choi.
\newblock Faith and fate: Limits of transformers on compositionality, 2023.

\bibitem[Dziugaite and Roy(2017)]{dziugaite2017computing}
G.~K. Dziugaite and D.~M. Roy.
\newblock Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data, 2017.

\bibitem[Falcon(2019)]{falcon2019pytorch}
P.~L. Falcon.
\newblock Pytorch lightning: Accelerated research from prototypes to production.
\newblock \url{https://github.com/PyTorchLightning/pytorch-lightning}, 2019.

\bibitem[Goldblum et~al.(2023)Goldblum, Finzi, Rowan, and Wilson]{goldblum2023free}
M.~Goldblum, M.~Finzi, K.~Rowan, and A.~G. Wilson.
\newblock The no free lunch theorem, kolmogorov complexity, and the role of inductive biases in machine learning, 2023.

\bibitem[Grau-Moya et~al.(2024)Grau-Moya, Genewein, Hutter, Orseau, Delétang, Catt, Ruoss, Wenliang, Mattern, Aitchison, and Veness]{grau-moya_learning_2024}
J.~Grau-Moya, T.~Genewein, M.~Hutter, L.~Orseau, G.~Delétang, E.~Catt, A.~Ruoss, L.~K. Wenliang, C.~Mattern, M.~Aitchison, and J.~Veness.
\newblock Learning {Universal} {Predictors}, Jan. 2024.
\newblock URL \url{http://arxiv.org/abs/2401.14953}.
\newblock arXiv:2401.14953 [cs].

\bibitem[Gu and Dao(2023)]{gu_mamba_2023}
A.~Gu and T.~Dao.
\newblock Mamba: {Linear}-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}, Dec. 2023.
\newblock URL \url{http://arxiv.org/abs/2312.00752}.
\newblock arXiv:2312.00752 [cs].

\bibitem[Han and Padó(2024)]{han_towards_2024}
S.~Han and S.~Padó.
\newblock Towards {Understanding} the {Relationship} between {In}-context {Learning} and {Compositional} {Generalization}, Mar. 2024.
\newblock URL \url{http://arxiv.org/abs/2403.11834}.
\newblock arXiv:2403.11834 [cs].

\bibitem[Hochreiter and Schmidhuber(1997)]{lstm}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hutter(2005)]{Hutter_UAI}
M.~Hutter.
\newblock \emph{Universal Artificial Intelligence}.
\newblock Texts in Theoretical Computer Science. An EATCS Series. Springer, Berlin and Heidelberg, 2005.
\newblock ISBN 978-3-540-22139-5.
\newblock \doi{10.1007/b138233}.

\bibitem[Hutter(2011)]{Hutter_article}
M.~Hutter.
\newblock Universal learning theory.
\newblock 02 2011.
\newblock \doi{10.1007/978-0-387-30164-8_861}.

\bibitem[Lachapelle et~al.(2023)Lachapelle, Mahajan, Mitliagkas, and Lacoste-Julien]{lachapelle_additive_2023}
S.~Lachapelle, D.~Mahajan, I.~Mitliagkas, and S.~Lacoste-Julien.
\newblock Additive {Decoders} for {Latent} {Variables} {Identification} and {Cartesian}-{Product} {Extrapolation}, July 2023.
\newblock URL \url{http://arxiv.org/abs/2307.02598}.
\newblock arXiv:2307.02598 [cs, stat].

\bibitem[Lake and Baroni(2023)]{lake_human-like_2023}
B.~M. Lake and M.~Baroni.
\newblock Human-like systematic generalization through a meta-learning neural network.
\newblock \emph{Nature}, 623\penalty0 (7985):\penalty0 115--121, Nov. 2023.
\newblock ISSN 1476-4687.
\newblock \doi{10.1038/s41586-023-06668-3}.
\newblock URL \url{https://www.nature.com/articles/s41586-023-06668-3}.
\newblock Publisher: Nature Publishing Group.

\bibitem[LeGuet()]{mambarepo}
A.~T. LeGuet.
\newblock Mamba repository.
\newblock URL \url{https://github.com/alxndrTL/mamba.py}.

\bibitem[Li and Vit\'anyi(1997)]{li_vitanyi_1997}
M.~Li and P.~Vit\'anyi.
\newblock \emph{An Introduction to Kolmogorov Complexity and Its Applications}.
\newblock Springer, 1997.
\newblock URL \url{http://books.google.com/books?vid=ISBN0387948686}.

\bibitem[Li et~al.(2024)Li, Davies, and Nadeau]{li2024circuit}
M.~Li, X.~Davies, and M.~Nadeau.
\newblock Circuit breaking: Removing model behaviors with targeted ablation, 2024.

\bibitem[Liu et~al.(2023)Liu, Xie, Li, and Ma]{downstreamtask}
H.~Liu, S.~M. Xie, Z.~Li, and T.~Ma.
\newblock Same pre-training loss, better downstream: Implicit bias matters for language models.
\newblock In A.~Krause, E.~Brunskill, K.~Cho, B.~Engelhardt, S.~Sabato, and J.~Scarlett, editors, \emph{Proceedings of the 40th International Conference on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning Research}, pages 22188--22214. PMLR, 23--29 Jul 2023.
\newblock URL \url{https://proceedings.mlr.press/v202/liu23ao.html}.

\bibitem[McCoy et~al.(2020)McCoy, Frank, and Linzen]{mccoy-2020}
R.~T. McCoy, R.~Frank, and T.~Linzen.
\newblock Does syntax need to grow on trees? sources of hierarchical inductive bias in sequence-to-sequence networks.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 8:\penalty0 125--140, 2020.
\newblock \doi{10.1162/tacl_a_00304}.
\newblock URL \url{https://aclanthology.org/2020.tacl-1.9}.

\bibitem[Meng et~al.(2023)Meng, Bau, Andonian, and Belinkov]{meng2023locating}
K.~Meng, D.~Bau, A.~Andonian, and Y.~Belinkov.
\newblock Locating and editing factual associations in gpt, 2023.

\bibitem[Mingard et~al.(2020)Mingard, Valle-Pérez, Skalse, and Louis]{mingard_is_2020}
C.~Mingard, G.~Valle-Pérez, J.~Skalse, and A.~A. Louis.
\newblock Is {SGD} a {Bayesian} sampler? {Well}, almost, Oct. 2020.
\newblock URL \url{http://arxiv.org/abs/2006.15191}.
\newblock arXiv:2006.15191 [cs, stat].

\bibitem[Murty et~al.(2023)Murty, Sharma, Andreas, and Manning]{murty-2023}
S.~Murty, P.~Sharma, J.~Andreas, and C.~Manning.
\newblock Grokking of hierarchical structure in vanilla transformers.
\newblock In A.~Rogers, J.~Boyd-Graber, and N.~Okazaki, editors, \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}, pages 439--448, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-short.38}.
\newblock URL \url{https://aclanthology.org/2023.acl-short.38}.

\bibitem[Nogueira et~al.(2021)Nogueira, Jiang, and Lin]{nogueira2021investigating}
R.~Nogueira, Z.~Jiang, and J.~Lin.
\newblock Investigating the limitations of transformers with simple arithmetic tasks, 2021.

\bibitem[Olsson et~al.(2022)Olsson, Elhage, Nanda, Joseph, DasSarma, Henighan, Mann, Askell, Bai, Chen, Conerly, Drain, Ganguli, Hatfield-Dodds, Hernandez, Johnston, Jones, Kernion, Lovitt, Ndousse, Amodei, Brown, Clark, Kaplan, McCandlish, and Olah]{olsson2022incontext_induction}
C.~Olsson, N.~Elhage, N.~Nanda, N.~Joseph, N.~DasSarma, T.~Henighan, B.~Mann, A.~Askell, Y.~Bai, A.~Chen, T.~Conerly, D.~Drain, D.~Ganguli, Z.~Hatfield-Dodds, D.~Hernandez, S.~Johnston, A.~Jones, J.~Kernion, L.~Lovitt, K.~Ndousse, D.~Amodei, T.~Brown, J.~Clark, J.~Kaplan, S.~McCandlish, and C.~Olah.
\newblock In-context learning and induction heads, 2022.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, Desmaison, Köpf, Yang, DeVito, Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~Köpf, E.~Yang, Z.~DeVito, M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang, J.~Bai, and S.~Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library, 2019.

\bibitem[Press et~al.(2020)Press, Smith, and Levy]{press_improving_2020}
O.~Press, N.~A. Smith, and O.~Levy.
\newblock Improving {Transformer} {Models} by {Reordering} their {Sublayers}.
\newblock In D.~Jurafsky, J.~Chai, N.~Schluter, and J.~Tetreault, editors, \emph{Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}}, pages 2996--3005, Online, July 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.270}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.270}.

\bibitem[Pérez-Ortiz et~al.(2021)Pérez-Ortiz, Rivasplata, Shawe-Taylor, and Szepesvári]{pérezortiz2021tighter}
M.~Pérez-Ortiz, O.~Rivasplata, J.~Shawe-Taylor, and C.~Szepesvári.
\newblock Tighter risk certificates for neural networks, 2021.

\bibitem[Rajamanoharan et~al.(2024)Rajamanoharan, Conmy, Smith, Lieberum, Varma, Kramár, Shah, and Nanda]{rajamanoharan2024improving}
S.~Rajamanoharan, A.~Conmy, L.~Smith, T.~Lieberum, V.~Varma, J.~Kramár, R.~Shah, and N.~Nanda.
\newblock Improving dictionary learning with gated sparse autoencoders, 2024.

\bibitem[Ramesh et~al.(2024)Ramesh, Lubana, Khona, Dick, and Tanaka]{ramesh_compositional_2024}
R.~Ramesh, E.~S. Lubana, M.~Khona, R.~P. Dick, and H.~Tanaka.
\newblock Compositional {Capabilities} of {Autoregressive} {Transformers}: {A} {Study} on {Synthetic}, {Interpretable} {Tasks}, Feb. 2024.
\newblock URL \url{http://arxiv.org/abs/2311.12997}.
\newblock arXiv:2311.12997 [cs].

\bibitem[Reizinger et~al.()Reizinger, Ujváry, Mészáros, Kerekes, Brendel, and Huszár]{Reizinger_llm-non-identifiability}
P.~Reizinger, S.~Ujváry, A.~Mészáros, A.~Kerekes, W.~Brendel, and F.~Huszár.
\newblock Llm non-identifiability repository.
\newblock URL \url{https://github.com/rpatrik96/llm-non-identifiability}.

\bibitem[Reizinger et~al.(2024)Reizinger, Ujváry, Mészáros, Kerekes, Brendel, and Huszár]{reizinger2024understanding}
P.~Reizinger, S.~Ujváry, A.~Mészáros, A.~Kerekes, W.~Brendel, and F.~Huszár.
\newblock Understanding llms requires more than statistical generalization, 2024.

\bibitem[Ruoss et~al.(2023)Ruoss, Delétang, Genewein, Grau-Moya, Csordás, Bennani, Legg, and Veness]{ruoss_randomized_2023}
A.~Ruoss, G.~Delétang, T.~Genewein, J.~Grau-Moya, R.~Csordás, M.~Bennani, S.~Legg, and J.~Veness.
\newblock Randomized {Positional} {Encodings} {Boost} {Length} {Generalization} of {Transformers}, May 2023.
\newblock URL \url{http://arxiv.org/abs/2305.16843}.
\newblock arXiv:2305.16843 [cs, stat].

\bibitem[Saparov et~al.(2023)Saparov, Pang, Padmakumar, Joshi, Kazemi, Kim, and He]{saparov2023testing}
A.~Saparov, R.~Y. Pang, V.~Padmakumar, N.~Joshi, S.~M. Kazemi, N.~Kim, and H.~He.
\newblock Testing the general deductive reasoning capacity of large language models using ood examples, 2023.

\bibitem[Schott et~al.(2021)Schott, von Kügelgen, Träuble, Gehler, Russell, Bethge, Schölkopf, Locatello, and Brendel]{schott_visual_2021}
L.~Schott, J.~von Kügelgen, F.~Träuble, P.~Gehler, C.~Russell, M.~Bethge, B.~Schölkopf, F.~Locatello, and W.~Brendel.
\newblock Visual {Representation} {Learning} {Does} {Not} {Generalize} {Strongly} {Within} the {Same} {Domain}.
\newblock \emph{arXiv:2107.08221 [cs]}, July 2021.
\newblock URL \url{http://arxiv.org/abs/2107.08221}.
\newblock arXiv: 2107.08221.

\bibitem[Solomonoff(2001)]{Solomonoff2001}
R.~J. Solomonoff.
\newblock A preliminary report on a general theory of inductive inference.
\newblock 2001.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:17118014}.

\bibitem[Theis(2024)]{theis2024realism}
L.~Theis.
\newblock What makes an image realistic?, 2024.

\bibitem[Turing(1936)]{turing1936a}
A.~M. Turing.
\newblock On computable numbers, with an application to the {E}ntscheidungsproblem.
\newblock \emph{Proceedings of the London Mathematical Society}, 2\penalty0 (42):\penalty0 230--265, 1936.
\newblock URL \url{http://www.cs.helsinki.fi/u/gionis/cc05/OnComputableNumbers.pdf}.

\bibitem[Valle-Pérez et~al.(2019)Valle-Pérez, Camargo, and Louis]{valle-perez_deep_2019}
G.~Valle-Pérez, C.~Q. Camargo, and A.~A. Louis.
\newblock Deep learning generalizes because the parameter-function map is biased towards simple functions, Apr. 2019.
\newblock URL \url{http://arxiv.org/abs/1805.08522}.
\newblock arXiv:1805.08522 [cs, stat].

\bibitem[Vapnik and Chervonenkis(1971)]{Vapnik1971}
V.~Vapnik and A.~Y. Chervonenkis.
\newblock On the uniform convergence of relative frequencies of events to their probabilities.
\newblock \emph{Theory of Probability \& Its Applications}, 16\penalty0 (2):\penalty0 264, 1971.

\bibitem[Vaswani et~al.(2023)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{transformer}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need, 2023.

\bibitem[Weiss et~al.(2021)Weiss, Goldberg, and Yahav]{weiss_thinking_2021}
G.~Weiss, Y.~Goldberg, and E.~Yahav.
\newblock Thinking {Like} {Transformers}, July 2021.
\newblock URL \url{http://arxiv.org/abs/2106.06981}.
\newblock arXiv:2106.06981 [cs].

\bibitem[Wiedemer et~al.(2023{\natexlab{a}})Wiedemer, Brady, Panfilov, Juhos, Bethge, and Brendel]{wiedemer_provable_2023}
T.~Wiedemer, J.~Brady, A.~Panfilov, A.~Juhos, M.~Bethge, and W.~Brendel.
\newblock Provable {Compositional} {Generalization} for {Object}-{Centric} {Learning}, Oct. 2023{\natexlab{a}}.
\newblock URL \url{http://arxiv.org/abs/2310.05327}.
\newblock arXiv:2310.05327 [cs].

\bibitem[Wiedemer et~al.(2023{\natexlab{b}})Wiedemer, Mayilvahanan, Bethge, and Brendel]{wiedemer_compositional_2023}
T.~Wiedemer, P.~Mayilvahanan, M.~Bethge, and W.~Brendel.
\newblock Compositional {Generalization} from {First} {Principles}, July 2023{\natexlab{b}}.
\newblock URL \url{http://arxiv.org/abs/2307.05596}.
\newblock arXiv:2307.05596 [cs, stat].

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu, Scao, Gugger, Drame, Lhoest, and Rush]{wolf2020huggingfaces}
T.~Wolf, L.~Debut, V.~Sanh, J.~Chaumond, C.~Delangue, A.~Moi, P.~Cistac, T.~Rault, R.~Louf, M.~Funtowicz, J.~Davison, S.~Shleifer, P.~von Platen, C.~Ma, Y.~Jernite, J.~Plu, C.~Xu, T.~L. Scao, S.~Gugger, M.~Drame, Q.~Lhoest, and A.~M. Rush.
\newblock Huggingface's transformers: State-of-the-art natural language processing, 2020.

\bibitem[Yang et~al.(2023)Yang, Wang, Lan, Lu, and Zheng]{yang_vector-based_2023}
T.~Yang, Y.~Wang, C.~Lan, Y.~Lu, and N.~Zheng.
\newblock Vector-based {Representation} is the {Key}: {A} {Study} on {Disentanglement} and {Compositional} {Generalization}, May 2023.
\newblock URL \url{http://arxiv.org/abs/2305.18063}.
\newblock arXiv:2305.18063 [cs].

\bibitem[Zhou et~al.(2023)Zhou, Bradley, Littwin, Razin, Saremi, Susskind, Bengio, and Nakkiran]{zhou_what_2023}
H.~Zhou, A.~Bradley, E.~Littwin, N.~Razin, O.~Saremi, J.~Susskind, S.~Bengio, and P.~Nakkiran.
\newblock What {Algorithms} can {Transformers} {Learn}? {A} {Study} in {Length} {Generalization}, Oct. 2023.
\newblock URL \url{http://arxiv.org/abs/2310.16028}.
\newblock arXiv:2310.16028 [cs, stat].

\end{thebibliography}
