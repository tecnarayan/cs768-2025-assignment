\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{abadi16deep}
Abadi, M., Chu, A., Goodfellow, I.~J., McMahan, H.~B., Mironov, I., Talwar, K.,
  and Zhang, L.
\newblock Deep learning with differential privacy.
\newblock In \emph{CCS}, pp.\  308--318, 2016.

\bibitem[Altschuler \& Talwar(2022)Altschuler and Talwar]{altschuler22privacy}
Altschuler, J.~M. and Talwar, K.
\newblock Privacy of noisy stochastic gradient descent: More iterations without
  more privacy loss.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Anil et~al.(2022)Anil, Ghazi, Gupta, Kumar, and
  Manurangsi]{anil22dpbert}
Anil, R., Ghazi, B., Gupta, V., Kumar, R., and Manurangsi, P.
\newblock Large-scale differentially private {BERT}.
\newblock In \emph{EMNLP (Findings)}, pp.\  6481--6491, 2022.

\bibitem[Balle \& Wang(2018)Balle and Wang]{balle18improving}
Balle, B. and Wang, Y.
\newblock Improving the {G}aussian mechanism for differential privacy:
  Analytical calibration and optimal denoising.
\newblock In \emph{ICML}, pp.\  403--412, 2018.

\bibitem[Balle et~al.(2022)Balle, Berrada, De, Ghalebikesabi, Hayes, Pappu,
  Smith, and Stanforth]{jax-privacy2022github}
Balle, B., Berrada, L., De, S., Ghalebikesabi, S., Hayes, J., Pappu, A., Smith,
  S.~L., and Stanforth, R.
\newblock {JAX}-{P}rivacy: Algorithms for privacy-preserving machine learning
  in {JAX}, 2022.
\newblock URL \url{http://github.com/google-deepmind/jax_privacy}.

\bibitem[Bu et~al.(2022)Bu, Mao, and Xu]{bu2022scalable}
Bu, Z., Mao, J., and Xu, S.
\newblock Scalable and efficient training of large convolutional neural
  networks with differential privacy.
\newblock \emph{NeurIPS}, pp.\  38305--38318, 2022.

\bibitem[Chen et~al.(2020)Chen, Orekondy, and Fritz]{NEURIPS2020_9547ad6b}
Chen, D., Orekondy, T., and Fritz, M.
\newblock {GS-WGAN:} a gradient-sanitized approach for learning differentially
  private generators.
\newblock In \emph{NeurIPS}, pp.\  12673--12684, 2020.

\bibitem[Chourasia et~al.(2021)Chourasia, Ye, and Shokri]{chourasia21langevin}
Chourasia, R., Ye, J., and Shokri, R.
\newblock Differential privacy dynamics of {L}angevin diffusion and noisy
  gradient descent.
\newblock In \emph{NeurIPS}, pp.\  14771--14781, 2021.

\bibitem[De et~al.(2022)De, Berrada, Hayes, Smith, and Balle]{de22unlocking}
De, S., Berrada, L., Hayes, J., Smith, S.~L., and Balle, B.
\newblock Unlocking high-accuracy differentially private image classification
  through scale.
\newblock \emph{arXiv}, 2204.13650, 2022.

\bibitem[Denison et~al.(2023)Denison, Ghazi, Kamath, Kumar, Manurangsi, Narra,
  Sinha, Varadarajan, and Zhang]{denison23ad}
Denison, C., Ghazi, B., Kamath, P., Kumar, R., Manurangsi, P., Narra, K.~G.,
  Sinha, A., Varadarajan, A.~V., and Zhang, C.
\newblock Private ad modeling with {DP-SGD}.
\newblock In \emph{AdKDD}, 2023.

\bibitem[Dockhorn et~al.(2022)Dockhorn, Cao, Vahdat, and
  Kreis]{dockhorn2022differentially}
Dockhorn, T., Cao, T., Vahdat, A., and Kreis, K.
\newblock Differentially private diffusion models.
\newblock \emph{arXiv}, 2210.09929, 2022.

\bibitem[Doroshenko et~al.(2022)Doroshenko, Ghazi, Kamath, Kumar, and
  Manurangsi]{doroshenko22connect}
Doroshenko, V., Ghazi, B., Kamath, P., Kumar, R., and Manurangsi, P.
\newblock Connect the dots: Tighter discrete approximations of privacy loss
  distributions.
\newblock \emph{PoPETS}, 2022\penalty0 (4):\penalty0 552--570, 2022.

\bibitem[Erlingsson et~al.(2019)Erlingsson, Feldman, Mironov, Raghunathan,
  Talwar, and Thakurta]{erlingsson19amplification}
Erlingsson, {\'{U}}., Feldman, V., Mironov, I., Raghunathan, A., Talwar, K.,
  and Thakurta, A.
\newblock Amplification by shuffling: From local to central differential
  privacy via anonymity.
\newblock In \emph{SODA}, pp.\  2468--2479, 2019.

\bibitem[Fang et~al.(2022)Fang, Du, and Wu]{fang2022differentially}
Fang, L., Du, B., and Wu, C.
\newblock Differentially private recommender system with variational
  autoencoders.
\newblock \emph{Knowledge-Based Systems}, 250:\penalty0 109044, 2022.

\bibitem[Feldman et~al.(2018)Feldman, Mironov, Talwar, and
  Thakurta]{feldman18iteration}
Feldman, V., Mironov, I., Talwar, K., and Thakurta, A.
\newblock Privacy amplification by iteration.
\newblock In \emph{FOCS}, pp.\  521--532, 2018.

\bibitem[Feldman et~al.(2021)Feldman, McMillan, and Talwar]{feldman21hiding}
Feldman, V., McMillan, A., and Talwar, K.
\newblock Hiding among the clones: {A} simple and nearly optimal analysis of
  privacy amplification by shuffling.
\newblock In \emph{FOCS}, pp.\  954--964, 2021.

\bibitem[Feldman et~al.(2023)Feldman, McMillan, and Talwar]{feldman23stronger}
Feldman, V., McMillan, A., and Talwar, K.
\newblock Stronger privacy amplification by shuffling for {R{\'{e}}nyi} and
  approximate differential privacy.
\newblock In \emph{SODA}, pp.\  4966--4981, 2023.

\bibitem[Ghazi et~al.(2022)Ghazi, Kamath, Kumar, and Manurangsi]{ghazi22faster}
Ghazi, B., Kamath, P., Kumar, R., and Manurangsi, P.
\newblock Faster privacy accounting via evolving discretization.
\newblock In \emph{ICML}, pp.\  7470--7483, 2022.

\bibitem[Google Colab()]{googlecolab}
Google Colab.
\newblock URL \url{https://colab.research.google.com/}.

\bibitem[{Google's DP Library.}(2020)]{GoogleDP}
{Google's DP Library.}
\newblock D{P} {A}ccounting {L}ibrary.
\newblock
  \url{https://github.com/google/differential-privacy/tree/main/python/dp_accounting},
  2020.

\bibitem[Gopi et~al.(2021)Gopi, Lee, and Wutschitz]{gopi21numerical}
Gopi, S., Lee, Y.~T., and Wutschitz, L.
\newblock Numerical composition of differential privacy.
\newblock In \emph{NeurIPS}, pp.\  11631--11642, 2021.

\bibitem[He et~al.(2023)He, Li, Yu, Zhang, Kulkarni, Lee, Backurs, Yu, and
  Bian]{he2022exploring}
He, J., Li, X., Yu, D., Zhang, H., Kulkarni, J., Lee, Y.~T., Backurs, A., Yu,
  N., and Bian, J.
\newblock Exploring the limits of differentially private deep learning with
  group-wise clipping.
\newblock In \emph{ICLR}, 2023.

\bibitem[Kairouz et~al.(2021)Kairouz, McMahan, Song, Thakkar, Thakurta, and
  Xu]{kairouz21practical}
Kairouz, P., McMahan, B., Song, S., Thakkar, O., Thakurta, A., and Xu, Z.
\newblock Practical and private (deep) learning without sampling or shuffling.
\newblock In \emph{ICML}, pp.\  5213--5225, 2021.

\bibitem[Klause et~al.(2022)Klause, Ziller, Rueckert, Hammernik, and
  Kaissis]{klause2022differentially}
Klause, H., Ziller, A., Rueckert, D., Hammernik, K., and Kaissis, G.
\newblock Differentially private training of residual networks with scale
  normalisation.
\newblock \emph{arXiv}, 2203.00324, 2022.

\bibitem[Koskela et~al.(2020)Koskela, J{\"a}lk{\"o}, and
  Honkela]{koskela2020computing}
Koskela, A., J{\"a}lk{\"o}, J., and Honkela, A.
\newblock Computing tight differential privacy guarantees using {FFT}.
\newblock In \emph{AISTATS}, pp.\  2560--2569, 2020.

\bibitem[Lebeda et~al.(2024)Lebeda, Regehr, Kamath, and
  Steinke]{lebeda2024avoiding}
Lebeda, C.~J., Regehr, M., Kamath, G., and Steinke, T.
\newblock Avoiding pitfalls for privacy accounting of subsampled mechanisms
  under composition, 2024.
\newblock URL \url{https://arxiv.org/abs/2405.20769}.

\bibitem[Li et~al.(2022)Li, Tramer, Liang, and Hashimoto]{li2021large}
Li, X., Tramer, F., Liang, P., and Hashimoto, T.
\newblock Large language models can be strong differentially private learners.
\newblock In \emph{ICLR}, 2022.

\bibitem[McMahan et~al.(2022)McMahan, Rush, and Thakurta]{mcmahan22dpmf}
McMahan, B., Rush, K., and Thakurta, A.~G.
\newblock Private online prefix sums via optimal matrix factorizations.
\newblock \emph{arXiv}, 2202.08312, 2022.

\bibitem[Meiser \& Mohammadi(2018)Meiser and Mohammadi]{meiser2018tight}
Meiser, S. and Mohammadi, E.
\newblock Tight on budget? {T}ight bounds for $r$-fold approximate differential
  privacy.
\newblock In \emph{CCS}, pp.\  247--264, 2018.

\bibitem[Microsoft.(2021)]{MicrosoftDP}
Microsoft.
\newblock A fast algorithm to optimally compose privacy guarantees of
  differentially private ({DP}) mechanisms to arbitrary accuracy.
\newblock \url{https://github.com/microsoft/prv_accountant}, 2021.

\bibitem[Mironov(2017)]{mironov17renyi}
Mironov, I.
\newblock R{\'{e}}nyi differential privacy.
\newblock In \emph{CSF}, pp.\  263--275, 2017.

\bibitem[Papernot et~al.(2021)Papernot, Thakurta, Song, Chien, and
  Erlingsson]{papernot2021tempered}
Papernot, N., Thakurta, A., Song, S., Chien, S., and Erlingsson, {\'U}.
\newblock Tempered sigmoid activations for deep learning with differential
  privacy.
\newblock In \emph{AAAI}, pp.\  9312--9321, 2021.

\bibitem[Ponomareva et~al.(2023)Ponomareva, Hazimeh, Kurakin, Xu, Denison,
  McMahan, Vassilvitskii, Chien, and Thakurta]{ponomareva23dpfy}
Ponomareva, N., Hazimeh, H., Kurakin, A., Xu, Z., Denison, C., McMahan, H.~B.,
  Vassilvitskii, S., Chien, S., and Thakurta, A.~G.
\newblock How to dp-fy {ML:} {A} practical guide to machine learning with
  differential privacy.
\newblock \emph{J. Artif. Intell. Res.}, 77:\penalty0 1113--1201, 2023.

\bibitem[Prediger \& Koskela(2020)Prediger and Koskela]{DPBayes}
Prediger, L. and Koskela, A.
\newblock Code for computing tight guarantees for differential privacy.
\newblock \url{https://github.com/DPBayes/PLD-Accountant}, 2020.

\bibitem[Sommer et~al.(2019)Sommer, Meiser, and Mohammadi]{sommer2019privacy}
Sommer, D.~M., Meiser, S., and Mohammadi, E.
\newblock Privacy loss classes: The central limit theorem in differential
  privacy.
\newblock \emph{PoPETS}, 2019\penalty0 (2):\penalty0 245--269, 2019.

\bibitem[Tensorflow Privacy({\natexlab{a}})]{tf_privacy}
Tensorflow Privacy, {\natexlab{a}}.
\newblock URL
  \url{https://www.tensorflow.org/responsible_ai/privacy/api_docs/python/tf_privacy}.

\bibitem[Tensorflow Privacy({\natexlab{b}})]{tf_privacy_statement}
Tensorflow Privacy, {\natexlab{b}}.
\newblock URL
  \url{https://www.tensorflow.org/responsible_ai/privacy/api_docs/python/tf_privacy/compute_dp_sgd_privacy_statement}.
\newblock Note about compute\_dp\_sgd\_privacy\_statement.

\bibitem[Torkzadehmahani et~al.(2019)Torkzadehmahani, Kairouz, and
  Paten]{Torkzadehmahani_2019_CVPR_Workshops}
Torkzadehmahani, R., Kairouz, P., and Paten, B.
\newblock {DP-CGAN}: Differentially private synthetic data and label
  generation.
\newblock In \emph{CVPR Workshops}, 2019.

\bibitem[Tramer \& Boneh(2021)Tramer and Boneh]{tramer2020differentially}
Tramer, F. and Boneh, D.
\newblock Differentially private learning needs better features (or much more
  data).
\newblock In \emph{ICLR}, 2021.

\bibitem[Vadhan(2017)]{vadhan17complexity}
Vadhan, S.
\newblock \emph{The Complexity of Differential Privacy}.
\newblock Springer, 2017.

\bibitem[Wang et~al.(2023)Wang, Mahloujifar, Wu, Jia, and
  Mittal]{wang23randomized}
Wang, J.~T., Mahloujifar, S., Wu, T., Jia, R., and Mittal, P.
\newblock A randomized approach to tight privacy accounting.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Yousefpour et~al.(2021)Yousefpour, Shilov, Sablayrolles, Testuggine,
  Prasad, Malek, Nguyen, Ghosh, Bharadwaj, Zhao, Cormode, and
  Mironov]{yousefpour21opacus}
Yousefpour, A., Shilov, I., Sablayrolles, A., Testuggine, D., Prasad, K.,
  Malek, M., Nguyen, J., Ghosh, S., Bharadwaj, A., Zhao, J., Cormode, G., and
  Mironov, I.
\newblock Opacus: User-friendly differential privacy library in {PyTorch}.
\newblock \emph{arXiv}, 2109.12298, 2021.

\bibitem[Yu et~al.(2022)Yu, Naik, Backurs, Gopi, Inan, Kamath, Kulkarni, Lee,
  Manoel, Wutschitz, et~al.]{yu2021differentially}
Yu, D., Naik, S., Backurs, A., Gopi, S., Inan, H.~A., Kamath, G., Kulkarni, J.,
  Lee, Y.~T., Manoel, A., Wutschitz, L., et~al.
\newblock Differentially private fine-tuning of language models.
\newblock In \emph{ICLR}, 2022.

\bibitem[Zeighami et~al.(2022)Zeighami, Ahuja, Ghinita, and
  Shahabi]{zeighami2021neural}
Zeighami, S., Ahuja, R., Ghinita, G., and Shahabi, C.
\newblock A neural database for differentially private spatial range queries.
\newblock In \emph{VLDB}, pp.\  1066--1078, 2022.

\bibitem[Zhu et~al.(2022)Zhu, Dong, and Wang]{zhu22optimal}
Zhu, Y., Dong, J., and Wang, Y.
\newblock Optimal accounting of differential privacy via characteristic
  function.
\newblock In \emph{AISTATS}, pp.\  4782--4817, 2022.

\bibitem[Ziller et~al.(2021)Ziller, Usynin, Braren, Makowski, Rueckert, and
  Kaissis]{ziller2021medical}
Ziller, A., Usynin, D., Braren, R., Makowski, M., Rueckert, D., and Kaissis, G.
\newblock Medical imaging deep learning with differential privacy.
\newblock \emph{Scientific Reports}, 11\penalty0 (1):\penalty0 13524, 2021.

\end{thebibliography}
