\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{afouras2020self}
Triantafyllos Afouras, Andrew Owens, Joon~Son Chung, and Andrew Zisserman.
\newblock Self-supervised learning of audio-visual objects from video.
\newblock In {\em ECCV}, 2020.

\bibitem{akbari2021vatt}
Hassan Akbari, Linagzhe Yuan, Rui Qian, Wei-Hong Chuang, Shih-Fu Chang, Yin
  Cui, and Boqing Gong.
\newblock Vatt: Transformers for multimodal self-supervised learning from raw
  video, audio and text, 2021.

\bibitem{arnab2021vivit}
Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lučić, and
  Cordelia Schmid.
\newblock Vivit: A video vision transformer, 2021.

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E. Hinton.
\newblock Layer normalization, 2016.

\bibitem{wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock In {\em NeurIPS}, 2020.

\bibitem{bain2021frozen}
Max Bain, Arsha Nagrani, Gül Varol, and Andrew Zisserman.
\newblock Frozen in time: A joint video and image encoder for end-to-end
  retrieval, 2021.

\bibitem{Beltagy2020Longformer}
Iz Beltagy, Matthew~E. Peters, and Arman Cohan.
\newblock Longformer: The long-document transformer.
\newblock 2020.

\bibitem{bertasius2021spacetime}
Gedas Bertasius, Heng Wang, and Lorenzo Torresani.
\newblock Is space-time attention all you need for video understanding?
\newblock In {\em ICML}, 2021.

\bibitem{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{carion2020endtoend}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{I3D}
Joao Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em CVPR}, 2017.

\bibitem{chen2020generative}
Mark Chen, Alec Radford, Rewon Child, Jeff Wu, Heewoo Jun, Prafulla Dhariwal,
  David Luan, and Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em ICML}, 2020.

\bibitem{doubleattention}
Yunpeng Chen, Yannis Kalantidis, Jianshu Li, Shuicheng Yan, and Jiashi Feng.
\newblock $a^2$-nets: Double attention networks.
\newblock In {\em NeurIPS}, 2018.

\bibitem{child2019sparsetransformer}
Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever.
\newblock Generating long sequences with sparse transformers.
\newblock {\em URL https://openai.com/blog/sparse-transformers}, 2019.

\bibitem{choromanski2021rethinking}
Krzysztof~Marcin Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song,
  Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared~Quincy Davis, Afroz
  Mohiuddin, Lukasz Kaiser, David~Benjamin Belanger, Lucy~J Colwell, and Adrian
  Weller.
\newblock Rethinking attention with performers.
\newblock In {\em ICLR}, 2021.

\bibitem{Cubuk2019RandAugmentPD}
E. Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V. Le.
\newblock Randaugment: Practical data augmentation with no separate search.
\newblock In {\em CVPRW}, 2020.

\bibitem{damen2020rescaling}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Antonino Furnari,
  Evangelos Kazakos, Jian Ma, Davide Moltisanti, Jonathan Munro, Toby Perrett,
  Will Price, et~al.
\newblock Rescaling egocentric vision.
\newblock In {\em ECCV}, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{desai2021virtex}
Karan Desai and Justin Johnson.
\newblock {VirTex: Learning Visual Representations from Textual Annotations}.
\newblock In {\em CVPR}, 2021.

\bibitem{doersch2020crosstransformers}
Carl Doersch, Ankush Gupta, and Andrew Zisserman.
\newblock Crosstransformers: spatially-aware few-shot transfer.
\newblock In {\em NeurIPS}, 2020.

\bibitem{dosovitskiy2021an}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{fan2020pyslowfast}
Haoqi Fan, Yanghao Li, Bo Xiong, Wan-Yen Lo, and Christoph Feichtenhofer.
\newblock Pyslowfast.
\newblock \url{https://github.com/facebookresearch/slowfast}, 2020.

\bibitem{fan2021multiscale}
Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers, 2021.

\bibitem{fan2019blvnet}
Quanfu Fan, Chun-Fu~(Ricarhd) Chen, Hilde Kuehne, Marco Pistoia, and David Cox.
\newblock {More Is Less: Learning Efficient Video Representations by Temporal
  Aggregation Modules}.
\newblock In {\em NeurIPS}, 2019.

\bibitem{Feichtenhofer_2020}
Christoph Feichtenhofer.
\newblock X3d: Expanding architectures for efficient video recognition.
\newblock In {\em CVPR}, 2020.

\bibitem{slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{gabeur2020multimodal}
Valentin Gabeur, Chen Sun, Karteek Alahari, and Cordelia Schmid.
\newblock Multi-modal transformer for video retrieval.
\newblock In {\em ECCV}, 2020.

\bibitem{Goyal_2017}
Raghav Goyal, Samira~Ebrahimi Kahou, Vincent Michalski, Joanna Materzynska,
  Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos,
  Moritz Mueller-Freitag, and et al.
\newblock The “something something” video database for learning and
  evaluating visual common sense.
\newblock In {\em ICCV}, 2017.

\bibitem{KaimingHe16}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{henriques2014high}
Jo{\~a}o~F Henriques, Rui Caseiro, Pedro Martins, and Jorge Batista.
\newblock High-speed tracking with kernelized correlation filters.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  37(3):583--596, 2014.

\bibitem{huang2021multilingual}
Po-Yao Huang, Mandela Patrick, Junjie Hu, Graham Neubig, Florian Metze, and
  Alexander Hauptmann.
\newblock Multilingual multimodal pre-training for zero-shot cross-lingual
  transfer of vision-language models.
\newblock In {\em NAACL}, 2021.

\bibitem{ilg2016flownet}
Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy,
  and Thomas Brox.
\newblock Flownet 2.0: Evolution of optical flow estimation with deep networks.
\newblock In {\em CVPR}, 2016.

\bibitem{jabri_space_time}
Allan Jabri, Andrew Owens, and Alexei Efros.
\newblock Space-time correspondence as a contrastive random walk.
\newblock In {\em NeurIPS}, 2020.

\bibitem{bert18_naccl}
Kenton~Lee Jacob~Devlin, Ming-Wei~Chang and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL}, 2018.

\bibitem{jiang2019stm}
Boyuan Jiang, Mengmeng Wang, Weihao Gan, Wei Wu, and Junjie Yan.
\newblock Stm: Spatiotemporal and motion encoding for action recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{jiang2021learning}
Shihao Jiang, Dylan Campbell, Yao Lu, Hongdong Li, and Richard Hartley.
\newblock Learning to estimate hidden motions with global motion aggregation.
\newblock In {\em ICCV}, 2021.

\bibitem{kant2020spatially}
Yash Kant, Dhruv Batra, Peter Anderson, Alex Schwing, Devi Parikh, Jiasen Lu,
  and Harsh Agrawal.
\newblock Spatially aware multimodal transformers for textvqa.
\newblock In {\em ECCV}, 2020.

\bibitem{kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
  Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
\newblock The kinetics human action video dataset, 2017.

\bibitem{kazakos2019epic}
Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, and Dima Damen.
\newblock Epic-fusion: Audio-visual temporal binding for egocentric action
  recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{Kitaev2020Reformer}
Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya.
\newblock Reformer: The efficient transformer.
\newblock In {\em ICLR}, 2020.

\bibitem{klaser2008spatio}
Alexander Klaser, Marcin Marsza{\l}ek, and Cordelia Schmid.
\newblock A spatio-temporal descriptor based on 3d-gradients.
\newblock In {\em BMVC}, 2008.

\bibitem{Krizhevsky12}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NeurIPS}, 2012.

\bibitem{kwon2020motionsqueeze}
Heeseung Kwon, Manjin Kim, Suha Kwak, and Minsu Cho.
\newblock Motionsqueeze: Neural motion feature learning for video
  understanding.
\newblock In {\em ECCV}, 2020.

\bibitem{lai2020mast}
Zihang Lai, Erika Lu, and Weidi Xie.
\newblock Mast: A memory-augmented self-supervised tracker.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lee2021parameter}
Sangho Lee, Youngjae Yu, Gunhee Kim, Thomas Breuel, Jan Kautz, and Yale Song.
\newblock Parameter efficient multimodal transformers for video representation
  learning.
\newblock In {\em ICLR}, 2021.

\bibitem{li2019visualbert}
Liunian~Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang.
\newblock Visualbert: A simple and performant baseline for vision and language,
  2019.

\bibitem{li2021vidtr}
Xinyu Li, Yanyi Zhang, Chunhui Liu, Bing Shuai, Yi Zhu, Biagio Brattoli, Hao
  Chen, Ivan Marsic, and Joseph Tighe.
\newblock Vidtr: Video transformer without convolutions, 2021.

\bibitem{li2020tea}
Yan Li, Bin Ji, Xintian Shi, Jianguo Zhang, Bin Kang, and Limin Wang.
\newblock Tea: Temporal excitation and aggregation for action recognition.
\newblock In {\em {CVPR}}, 2020.

\bibitem{Lin_2019}
Ji Lin, Chuang Gan, and Song Han.
\newblock Tsm: Temporal shift module for efficient video understanding.
\newblock 2019.

\bibitem{locatello2020objectcentric}
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran,
  Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf.
\newblock Object-centric learning with slot attention.
\newblock In {\em NeurIPS}, 2020.

\bibitem{loshchilov2018fixing}
Ilya Loshchilov and Frank Hutter.
\newblock Fixing weight decay regularization in adam, 2018.

\bibitem{lu2019vilbert}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock In {\em NeurIPS}, 2019.

\bibitem{micikevicius2018mixed}
Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen,
  David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh
  Venkatesh, and Hao Wu.
\newblock Mixed precision training.
\newblock In {\em ICLR}, 2018.

\bibitem{neimark2021video}
Daniel Neimark, Omri Bar, Maya Zohar, and Dotan Asselmann.
\newblock Video transformer network, 2021.

\bibitem{oh2019video}
Seoung~Wug Oh, Joon-Young Lee, Ning Xu, and Seon~Joo Kim.
\newblock Video object segmentation using space-time memory networks.
\newblock In {\em Int. Conf. Comput. Vis.}, 2019.

\bibitem{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Łukasz Kaiser, Noam Shazeer,
  Alexander Ku, and Dustin Tran.
\newblock Image transformer.
\newblock In {\em ICML}, 2018.

\bibitem{patrick2021spacetime}
Mandela Patrick, Yuki~M. Asano, Bernie Huang, Ishan Misra, Florian Metze, Joao
  Henriques, and Andrea Vedaldi.
\newblock Space-time crop \& attend: Improving cross-modal video representation
  learning, 2021.

\bibitem{patrick2020supportset}
Mandela Patrick, Po-Yao Huang, Yuki Asano, Florian Metze, Alexander~G
  Hauptmann, Joao~F. Henriques, and Andrea Vedaldi.
\newblock Support-set bottlenecks for video-text representation learning.
\newblock In {\em ICLR}, 2021.

\bibitem{P3D}
Zhaofan Qiu, Ting Yao, and Tao Mei.
\newblock Learning spatio-temporal representation with pseudo-3d residual
  networks.
\newblock In {\em ICCV}, 2017.

\bibitem{Qiu_2019}
Zhaofan Qiu, Ting Yao, Chong-Wah Ngo, Xinmei Tian, and Tao Mei.
\newblock Learning spatio-temporal representation with local and global
  diffusion.
\newblock {\em CVPR}, 2019.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI Blog}, 1(8):9, 2019.

\bibitem{ramanan05strike}
Deva Ramanan, David~A. Forsyth, and Andrew Zisserman.
\newblock Strike a pose: Tracking people by finding stylized poses.
\newblock In {\em Proc. {CVPR}}, 2005.

\bibitem{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em IJCV}, 2015.

\bibitem{sariyildiz2020learning}
Mert~Bulent Sariyildiz, Julien Perez, and Diane Larlus.
\newblock Learning visual representations with caption annotations.
\newblock In {\em ECCV}, 2020.

\bibitem{Scovanner07}
P. Scovanner, S. Ali, and M. Shah.
\newblock A 3-dimensional sift descriptor and its application to action
  recognition.
\newblock In {\em ACM MM}, 2007.

\bibitem{shewry1987maximum}
Michael~C Shewry and Henry~P Wynn.
\newblock Maximum entropy sampling.
\newblock {\em Journal of Applied Statistics}, 14(2):165--170, 1987.

\bibitem{singh2017online}
Gurkirt Singh, Suman Saha, Michael Sapienza, Philip~HS Torr, and Fabio
  Cuzzolin.
\newblock Online real-time multiple spatiotemporal action localisation and
  prediction.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 3637--3646, 2017.

\bibitem{su2019vlbert}
Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
\newblock Vl-bert: Pre-training of generic visual-linguistic representations.
\newblock In {\em ICLR}, 2020.

\bibitem{sun2019contrastive_arxiv}
Chen Sun, Fabien Baradel, Kevin Murphy, and Cordelia Schmid.
\newblock Contrastive bidirectional transformer for temporal representation
  learning, 2019.

\bibitem{sun2019videobert}
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid.
\newblock Videobert: A joint model for video and language representation
  learning.
\newblock In {\em ICCV}, 2019.

\bibitem{sun2018pwcnet}
Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz.
\newblock Pwc-net: Cnns for optical flow using pyramid, warping, and cost
  volume.
\newblock In {\em CVPR}, 2018.

\bibitem{Inceptionv3}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and
  Zbigniew Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em CVPR}, 2016.

\bibitem{Tan_2019}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock In {\em EMNLP}, 2019.

\bibitem{tan2020vokenization}
Hao Tan and Mohit Bansal.
\newblock Vokenization: Improving language understanding with contextualized,
  visual-grounded supervision.
\newblock In {\em EMNLP}, 2020.

\bibitem{tay2021long}
Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham,
  Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler.
\newblock Long range arena : A benchmark for efficient transformers.
\newblock In {\em ICLR}, 2021.

\bibitem{teed20raft:}
Zachary Teed and Jia Deng.
\newblock {RAFT:} recurrent all-pairs field transforms for optical flow.
\newblock In {\em Proc. {ECCV}}, 2020.

\bibitem{touvron2020training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Hervé Jégou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{Tran15}
Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri.
\newblock Learning spatiotemporal features with 3d convolutional networks.
\newblock In {\em ICCV}, 2015.

\bibitem{Tran_2019}
Du Tran, Heng Wang, Matt Feiszli, and Lorenzo Torresani.
\newblock Video classification with channel-separated convolutional networks.
\newblock In {\em ICCV}, 2019.

\bibitem{tran2018closer}
Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, and Manohar
  Paluri.
\newblock A closer look at spatiotemporal convolutions for action recognition.
\newblock In {\em CVPR}, 2018.

\bibitem{vaswani17attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NIPS}, 2017.

\bibitem{wang2013action}
Heng Wang and Cordelia Schmid.
\newblock Action recognition with improved trajectories.
\newblock In {\em ICCV}, 2013.

\bibitem{wang16temporal}
Limin Wang, Yuanjun Xiong, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc Van~Gool.
\newblock Temporal segment networks: Towards good practices for deep action
  recognition.
\newblock In {\em ECCV}, 2016.

\bibitem{wang2020linformer}
Sinong Wang, Belinda Li, Madian Khabsa, Han Fang, and Hao Ma.
\newblock Linformer: Self-attention with linear complexity.
\newblock In {\em NeurIPS}, 2020.

\bibitem{XiaolongWang18}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, 2018.

\bibitem{wang2019learning_cvpr}
Xiaolong Wang, Allan Jabri, and Alexei~A Efros.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In {\em CVPR}, 2019.

\bibitem{wang2020attentionnas}
Xiaofang Wang, Xuehan Xiong, Maxim Neumann, AJ Piergiovanni, Michael~S Ryoo,
  Anelia Angelova, Kris~M Kitani, and Wei Hua.
\newblock Attentionnas: Spatiotemporal attention cell search for video
  classification.
\newblock In {\em ECCV}, 2020.

\bibitem{weinzaepfel2015learning}
Philippe Weinzaepfel, Zaid Harchaoui, and Cordelia Schmid.
\newblock Learning to track for spatio-temporal action localization.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 3164--3172, 2015.

\bibitem{rw2019timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem{wu2020visual}
Bichen Wu, Chenfeng Xu, Xiaoliang Dai, Alvin Wan, Peizhao Zhang, Masayoshi
  Tomizuka, Kurt Keutzer, and Peter Vajda.
\newblock Visual transformers: Token-based image representation and processing
  for computer vision, 2020.

\bibitem{wu2019long}
Chao-Yuan Wu, Christoph Feichtenhofer, Haoqi Fan, Kaiming He, Philipp
  Krahenbuhl, and Ross Girshick.
\newblock Long-term feature banks for detailed video understanding.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 284--293, 2019.

\bibitem{xie2018rethinking}
Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy.
\newblock Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs
  in video classification.
\newblock In {\em ECCV}, 2018.

\bibitem{xiong2021nystromformer}
Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung,
  Yin Li, and Vikas Singh.
\newblock Nystr{\"o}mformer: A nystr{\"o}m-based algorithm for approximating
  self-attention.
\newblock In {\em AAAI}, 2021.

\bibitem{xu2021long}
Mingze Xu, Yuanjun Xiong, Hao Chen, Xinyu Li, Wei Xia, Zhuowen Tu, and Stefano
  Soatto.
\newblock Long short-term transformer for online action detection.
\newblock {\em arXiv preprint arXiv:2107.03377}, 2021.

\bibitem{zhao2018trajectory}
Yue Zhao, Yuanjun Xiong, and Dahua Lin.
\newblock Trajectory convolution for action recognition.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 2208--2219, 2018.

\bibitem{Zhou_2018}
Bolei Zhou, Alex Andonian, Aude Oliva, and Antonio Torralba.
\newblock Temporal relational reasoning in videos.
\newblock In {\em ECCV}, 2018.

\bibitem{zhu2020actbert}
Linchao Zhu and Yi Yang.
\newblock Actbert: Learning global-local video-text representations.
\newblock In {\em CVPR}, 2020.

\end{thebibliography}
