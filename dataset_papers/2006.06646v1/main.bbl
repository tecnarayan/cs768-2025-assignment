\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmed \& Torresani(2018)Ahmed and Torresani]{ahmed2018maskconnect}
Ahmed, K. and Torresani, L.
\newblock Maskconnect: {C}onnectivity learning by gradient descent.
\newblock In \emph{European Conference on Computer Vision}, pp.\  362--378.
  Springer, 2018.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., and
  Man{\'e}, D.
\newblock Concrete problems in {AI} safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Ardywibowo et~al.(2018)Ardywibowo, Huang, Gui, Xiao, Cheng, Liu, and
  Qian]{ardywibowo2018switching}
Ardywibowo, R., Huang, S., Gui, S., Xiao, C., Cheng, Y., Liu, J., and Qian, X.
\newblock Switching-state dynamical modeling of daily behavioral data.
\newblock \emph{Journal of Healthcare Informatics Research}, 2\penalty0
  (3):\penalty0 228--247, 2018.

\bibitem[Ardywibowo et~al.(2019)Ardywibowo, Zhao, Wang, Mortazavi, Huang, and
  Qian]{ardywibowo2019adaptive}
Ardywibowo, R., Zhao, G., Wang, Z., Mortazavi, B., Huang, S., and Qian, X.
\newblock Adaptive activity monitoring with uncertainty quantification in
  switching {G}aussian process models.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pp.\  266--275, 2019.

\bibitem[Baker et~al.(2017)Baker, Gupta, Naik, and Raskar]{baker2016designing}
Baker, B., Gupta, O., Naik, N., and Raskar, R.
\newblock Designing neural network architectures using reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Boluki et~al.(2020)Boluki, Ardywibowo, Dadaneh, Zhou, and
  Qian]{boluki2020learnable}
Boluki, S., Ardywibowo, R., Dadaneh, S.~Z., Zhou, M., and Qian, X.
\newblock Learnable {B}ernoulli dropout for {B}ayesian deep learning.
\newblock \emph{arXiv preprint arXiv:2002.05155}, 2020.

\bibitem[Chang et~al.(2019)Chang, Zhang, Guo, Meng, Xiang, and
  Pan]{chang2019differentiable}
Chang, J., Zhang, X., Guo, Y., Meng, G., Xiang, S., and Pan, C.
\newblock Differentiable architecture search with ensemble {Gumbel-Softmax}.
\newblock \emph{arXiv preprint arXiv:1905.01786}, 2019.

\bibitem[Chen et~al.(2018)Chen, Collins, Zhu, Papandreou, Zoph, Schroff, Adam,
  and Shlens]{chen2018searching}
Chen, L.-C., Collins, M., Zhu, Y., Papandreou, G., Zoph, B., Schroff, F., Adam,
  H., and Shlens, J.
\newblock Searching for efficient multi-scale architectures for dense image
  prediction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8699--8710, 2018.

\bibitem[Choi \& Jang(2018)Choi and Jang]{choi2018generative}
Choi, H. and Jang, E.
\newblock Generative ensembles for robust anomaly detection.
\newblock \emph{arXiv preprint arXiv:1810.01392}, 2018.

\bibitem[Dadaneh et~al.(2020{\natexlab{a}})Dadaneh, Boluki, Yin, Zhou, and
  Qian]{dadaneh2020pairwise}
Dadaneh, S.~Z., Boluki, S., Yin, M., Zhou, M., and Qian, X.
\newblock Pairwise supervised hashing with {B}ernoulli variational auto-encoder
  and self-control gradient estimator.
\newblock \emph{arXiv preprint arXiv:2005.10477}, 2020{\natexlab{a}}.

\bibitem[Dadaneh et~al.(2020{\natexlab{b}})Dadaneh, Boluki, Zhou, and
  Qian]{icassp_arsm}
Dadaneh, S.~Z., Boluki, S., Zhou, M., and Qian, X.
\newblock Arsm gradient estimator for supervised learning to rank.
\newblock In \emph{ICASSP 2020 - 2020 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  3157--3161,
  2020{\natexlab{b}}.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Dinh, L., Sohl-Dickstein, J., and Bengio, S.
\newblock Density estimation using {Real NVP}.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Elsken et~al.(2018)Elsken, Metzen, and Hutter]{elsken2018neural}
Elsken, T., Metzen, J.~H., and Hutter, F.
\newblock Neural architecture search: A survey.
\newblock \emph{arXiv preprint arXiv:1808.05377}, 2018.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a {Bayesian} approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pp.\
  1050--1059, 2016.

\bibitem[Gal et~al.(2017)Gal, Hron, and Kendall]{gal2017concrete}
Gal, Y., Hron, J., and Kendall, A.
\newblock Concrete dropout.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3581--3590, 2017.

\bibitem[Gelman et~al.(2014)Gelman, Hwang, and
  Vehtari]{gelman2014understanding}
Gelman, A., Hwang, J., and Vehtari, A.
\newblock Understanding predictive information criteria for bayesian models.
\newblock \emph{Statistics and computing}, 24\penalty0 (6):\penalty0 997--1016,
  2014.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain2015made}
Germain, M., Gregor, K., Murray, I., and Larochelle, H.
\newblock {Made: M}asked autoencoder for distribution estimation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  881--889, 2015.

\bibitem[Ghiasi et~al.(2019)Ghiasi, Lin, and Le]{ghiasi2019fpn}
Ghiasi, G., Lin, T.-Y., and Le, Q.~V.
\newblock {NAS-FPN: Learning} scalable feature pyramid architecture for object
  detection.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  7036--7045, 2019.

\bibitem[Gong et~al.(2019)Gong, Chang, Jiang, and Wang]{Gong_2019_ICCV}
Gong, X., Chang, S., Jiang, Y., and Wang, Z.
\newblock {AutoGAN: Neural} architecture search for generative adversarial
  networks.
\newblock In \emph{The IEEE International Conference on Computer Vision
  (ICCV)}, Oct 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Gumbel(1954)]{gumbel1954statistical}
Gumbel, E.~J.
\newblock Statistical theory of extreme values and some practical applications.
\newblock \emph{NBS Applied Mathematics Series}, 33, 1954.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hendrycks \& Gimpel(2016)Hendrycks and Gimpel]{hendrycks2016baseline}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Hendrycks et~al.(2019{\natexlab{a}})Hendrycks, Lee, and
  Mazeika]{hendrycks2019using}
Hendrycks, D., Lee, K., and Mazeika, M.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock \emph{arXiv preprint arXiv:1901.09960}, 2019{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2019{\natexlab{b}})Hendrycks, Mazeika, and
  Dietterich]{hendrycks2018deep}
Hendrycks, D., Mazeika, M., and Dietterich, T.
\newblock Deep anomaly detection with outlier exposure.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[Hoeting et~al.(1999)Hoeting, Madigan, Raftery, and
  Volinsky]{hoeting1999bayesian}
Hoeting, J.~A., Madigan, D., Raftery, A.~E., and Volinsky, C.~T.
\newblock Bayesian model averaging: {A} tutorial.
\newblock \emph{Statistical science}, pp.\  382--401, 1999.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with {G}umbel-{S}oftmax.
\newblock \emph{arXiv preprint arXiv:1611.01144}, 2016.

\bibitem[Jin et~al.(2018)Jin, Song, and Hu]{jin2018auto}
Jin, H., Song, Q., and Hu, X.
\newblock Auto-keras: {E}fficient neural architecture search with network
  morphism.
\newblock \emph{arXiv preprint arXiv:1806.10282}, 2018.

\bibitem[Kendall \& Gal(2017)Kendall and Gal]{kendall2017uncertainties}
Kendall, A. and Gal, Y.
\newblock What uncertainties do we need in {B}ayesian deep learning for
  computer vision?
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5574--5584, 2017.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: {G}enerative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10215--10224, 2018.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational {B}ayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kingma et~al.(2015)Kingma, Salimans, and
  Welling]{kingma2015variational}
Kingma, D.~P., Salimans, T., and Welling, M.
\newblock Variational dropout and the local reparameterization trick.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2575--2583, 2015.

\bibitem[Krizhevsky et~al.(2009)]{krizhevsky2009learning}
Krizhevsky, A. et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6402--6413, 2017.

\bibitem[LeCun()]{lecun1998mnist}
LeCun, Y.
\newblock The {MNIST} database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018training}
Lee, K., Lee, H., Lee, K., and Shin, J.
\newblock Training confidence-calibrated classifiers for detecting
  out-of-distribution samples.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Liang et~al.(2017)Liang, Li, and Srikant]{liang2017enhancing}
Liang, S., Li, Y., and Srikant, R.
\newblock Enhancing the reliability of out-of-distribution image detection in
  neural networks.
\newblock \emph{arXiv preprint arXiv:1706.02690}, 2017.

\bibitem[Liu et~al.(2018{\natexlab{a}})Liu, Zoph, Neumann, Shlens, Hua, Li,
  Fei-Fei, Yuille, Huang, and Murphy]{liu2018progressive}
Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L.,
  Yuille, A., Huang, J., and Murphy, K.
\newblock Progressive neural architecture search.
\newblock In \emph{European Conference on Computer Vision}, pp.\  19--35.
  Springer, 2018{\natexlab{a}}.

\bibitem[Liu et~al.(2019)Liu, Chen, Schroff, Adam, Hua, Yuille, and
  Fei-Fei]{liu2019auto}
Liu, C., Chen, L.-C., Schroff, F., Adam, H., Hua, W., Yuille, A.~L., and
  Fei-Fei, L.
\newblock Auto-deeplab: {H}ierarchical neural architecture search for semantic
  image segmentation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  82--92, 2019.

\bibitem[Liu et~al.(2018{\natexlab{b}})Liu, Simonyan, and Yang]{liu2018darts}
Liu, H., Simonyan, K., and Yang, Y.
\newblock {DARTS: D}ifferentiable architecture search.
\newblock \emph{arXiv preprint arXiv:1806.09055}, 2018{\natexlab{b}}.

\bibitem[Liu et~al.()Liu, Luo, Wang, and Tang]{liu2018large}
Liu, Z., Luo, P., Wang, X., and Tang, X.
\newblock Large-scale celebfaces attributes (celeba) dataset.

\bibitem[Lowe(1999)]{lowe1999object}
Lowe, D.~G.
\newblock Object recognition from local scale-invariant features.
\newblock In \emph{Proceedings of the Seventh IEEE International Conference on
  Computer Vision}, volume~2, pp.\  1150--1157, 1999.

\bibitem[Maddison et~al.(2014)Maddison, Tarlow, and
  Minka]{maddison2014sampling}
Maddison, C.~J., Tarlow, D., and Minka, T.
\newblock A* sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3086--3094, 2014.

\bibitem[Nalisnick et~al.(2019{\natexlab{a}})Nalisnick, Matsukawa, Teh, Gorur,
  and Lakshminarayanan]{nalisnick2018do}
Nalisnick, E., Matsukawa, A., Teh, Y.~W., Gorur, D., and Lakshminarayanan, B.
\newblock Do deep generative models know what they don't know?
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{a}}.

\bibitem[Nalisnick et~al.(2019{\natexlab{b}})Nalisnick, Matsukawa, Teh, and
  Lakshminarayanan]{nalisnick2019detecting}
Nalisnick, E., Matsukawa, A., Teh, Y.~W., and Lakshminarayanan, B.
\newblock Detecting out-of-distribution inputs to deep generative models using
  a test for typicality.
\newblock \emph{arXiv preprint arXiv:1906.02994}, 2019{\natexlab{b}}.

\bibitem[Negrinho \& Gordon(2017)Negrinho and
  Gordon]{negrinho2017deeparchitect}
Negrinho, R. and Gordon, G.
\newblock Deeparchitect: Automatically designing and training deep
  architectures.
\newblock \emph{arXiv preprint arXiv:1704.08792}, 2017.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Nguyen, A., Yosinski, J., and Clune, J.
\newblock Deep neural networks are easily fooled: {H}igh confidence predictions
  for unrecognizable images.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  427--436, 2015.

\bibitem[NHTSA(2017)]{autonomous}
NHTSA.
\newblock Tesla crash preliminary evaluation report.
\newblock Technical report, U.S. Department of Transportation, National Highway
  Traffic Safety Administration, Jan 2017.

\bibitem[Oord et~al.(2016)Oord, Dieleman, Zen, Simonyan, Vinyals, Graves,
  Kalchbrenner, Senior, and Kavukcuoglu]{oord2016wavenet}
Oord, A. v.~d., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A.,
  Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.
\newblock Wavenet: A generative model for raw audio.
\newblock \emph{arXiv preprint arXiv:1609.03499}, 2016.

\bibitem[Pham et~al.(2018)Pham, Guan, Zoph, Le, and Dean]{pham2018efficient}
Pham, H., Guan, M., Zoph, B., Le, Q., and Dean, J.
\newblock Efficient neural architecture search via parameter sharing.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4092--4101, 2018.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2019regularized}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  4780--4789, 2019.

\bibitem[Shafaei et~al.()Shafaei, Schmidt, and Little]{shafaeiless}
Shafaei, A., Schmidt, M., and Little, J.~J.
\newblock A less biased evaluation of out-of-distribution sample detectors.

\bibitem[Watanabe(2013)]{watanabe2013widely}
Watanabe, S.
\newblock A widely applicable {B}ayesian information criterion.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (Mar):\penalty0 867--897, 2013.

\bibitem[Xie et~al.(2018)Xie, Zheng, Liu, and Lin]{xie2018snas}
Xie, S., Zheng, H., Liu, C., and Lin, L.
\newblock {SNAS: S}tochastic neural architecture search.
\newblock \emph{arXiv preprint arXiv:1812.09926}, 2018.

\bibitem[Yin et~al.(2019)Yin, Yue, and Zhou]{yin2019arsm}
Yin, M., Yue, Y., and Zhou, M.
\newblock Arsm: Augment-reinforce-swap-merge estimator for gradient
  backpropagation through categorical variables.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7095--7104, 2019.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{zeiler2014visualizing}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pp.\  818--833.
  Springer, 2014.

\bibitem[Zhong et~al.(2018)Zhong, Yan, Wu, Shao, and Liu]{zhong2018practical}
Zhong, Z., Yan, J., Wu, W., Shao, J., and Liu, C.-L.
\newblock Practical block-wise neural network architecture generation.
\newblock In \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  2423--2432. IEEE, 2018.

\bibitem[Zoph \& Le(2016)Zoph and Le]{zoph2016neural}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.01578}, 2016.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{zoph2018learning}
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q.~V.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  8697--8710. IEEE, 2018.

\end{thebibliography}
