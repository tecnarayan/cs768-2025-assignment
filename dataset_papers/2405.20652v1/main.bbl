\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Atay \& Tuncel(2014)Atay and Tuncel]{atay2014spectrum}
Atay, F.~M. and Tuncel, H.
\newblock On the spectrum of the normalized laplacian for signed graphs: Interlacing, contraction, and replication.
\newblock \emph{Linear Algebra and its Applications}, 442:\penalty0 165--177, 2014.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bo et~al.(2021)Bo, Wang, Shi, and Shen]{bo2021beyond}
Bo, D., Wang, X., Shi, C., and Shen, H.
\newblock Beyond low-frequency information in graph convolutional networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pp.\  3950--3957, 2021.

\bibitem[Brody et~al.(2021)Brody, Alon, and Yahav]{brody2021attentive}
Brody, S., Alon, U., and Yahav, E.
\newblock How attentive are graph attention networks?
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Chien et~al.(2020)Chien, Peng, Li, and Milenkovic]{chien2020adaptive}
Chien, E., Peng, J., Li, P., and Milenkovic, O.
\newblock Adaptive universal generalized pagerank graph neural network.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Choi et~al.(2023)Choi, Choi, Ko, and Kim]{choi2023signed}
Choi, Y., Choi, J., Ko, T., and Kim, C.-K.
\newblock Is signed message essential for graph neural networks?
\newblock \emph{arXiv preprint arXiv:2301.08918}, 2023.

\bibitem[Chung \& Lu(2006)Chung and Lu]{chung2006concentration}
Chung, F. and Lu, L.
\newblock Concentration inequalities and martingale inequalities: a survey.
\newblock \emph{Internet mathematics}, 3\penalty0 (1), 2006.

\bibitem[Dai et~al.(2022)Dai, Zhou, Guo, and Wang]{dai2022label}
Dai, E., Zhou, S., Guo, Z., and Wang, S.
\newblock Label-wise graph convolutional network for heterophilic graphs.
\newblock In \emph{Learning on Graphs Conference}, pp.\  26--1. PMLR, 2022.

\bibitem[Defferrard et~al.(2016)Defferrard, Bresson, and Vandergheynst]{defferrard2016convolutional}
Defferrard, M., Bresson, X., and Vandergheynst, P.
\newblock Convolutional neural networks on graphs with fast localized spectral filtering.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Deshpande et~al.(2018)Deshpande, Sen, Montanari, and Mossel]{deshpande2018contextual}
Deshpande, Y., Sen, S., Montanari, A., and Mossel, E.
\newblock Contextual stochastic block models.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Fey \& Lenssen(2019)Fey and Lenssen]{fey2019fast}
Fey, M. and Lenssen, J.~E.
\newblock Fast graph representation learning with pytorch geometric.
\newblock \emph{arXiv preprint arXiv:1903.02428}, 2019.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and Leskovec]{hamilton2017inductive}
Hamilton, W., Ying, Z., and Leskovec, J.
\newblock Inductive representation learning on large graphs.
\newblock \emph{Advances in neural information processing systems}, 30:\penalty0 1024--1034, 2017.

\bibitem[Keriven(2022)]{keriven2022not}
Keriven, N.
\newblock Not too little, not too much: a theoretical analysis of graph (over) smoothing.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 2268--2281, 2022.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kipf \& Welling(2016)Kipf and Welling]{kipf2016semi}
Kipf, T.~N. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Lee et~al.(2023)Lee, Bu, Yoo, and Shin]{DBLP:conf/icml/LeeBYS23}
Lee, S.~Y., Bu, F., Yoo, J., and Shin, K.
\newblock Towards deep attention in graph neural networks: Problems and remedies.
\newblock In \emph{International Conference on Machine Learning}, volume 202, pp.\  18774--18795. {PMLR}, 2023.

\bibitem[Lee et~al.(2024)Lee, Kim, Bu, Yoo, Tang, and Shin]{DBLP:journals/corr/abs-2402-04621}
Lee, S.~Y., Kim, S., Bu, F., Yoo, J., Tang, J., and Shin, K.
\newblock Feature distribution on graph topology mediates the effect of graph convolution: Homophily perspective.
\newblock \emph{CoRR}, abs/2402.04621, 2024.

\bibitem[Li et~al.(2018)Li, Han, and Wu]{li2018deeper}
Li, Q., Han, Z., and Wu, X.-M.
\newblock Deeper insights into graph convolutional networks for semi-supervised learning.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~32, 2018.

\bibitem[Liang et~al.(2023)Liang, Hu, Xu, Song, and King]{NEURIPS2023_23aa2163}
Liang, L., Hu, X., Xu, Z., Song, Z., and King, I.
\newblock Predicting global label relationship matrix for graph neural networks under heterophily.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 10909--10921, 2023.

\bibitem[Liang et~al.(2024)Liang, Xu, Song, King, Qi, and Ye]{DBLP:journals/tkde/LiangXSKQY24}
Liang, L., Xu, Z., Song, Z., King, I., Qi, Y., and Ye, J.
\newblock Tackling long-tailed distribution issue in graph neural networks via normalization.
\newblock \emph{{IEEE} Trans. Knowl. Data Eng.}, 36\penalty0 (5):\penalty0 2213--2223, 2024.

\bibitem[Lim et~al.(2021)Lim, Hohne, Li, Huang, Gupta, Bhalerao, and Lim]{lim2021large}
Lim, D., Hohne, F., Li, X., Huang, S.~L., Gupta, V., Bhalerao, O., and Lim, S.~N.
\newblock Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 20887--20902, 2021.

\bibitem[Lin et~al.(2020)Lin, Quan, Wang, Ma, and Zeng]{lin2020kgnn}
Lin, X., Quan, Z., Wang, Z.-J., Ma, T., and Zeng, X.
\newblock Kgnn: Knowledge graph neural network for drug-drug interaction prediction.
\newblock In \emph{IJCAI}, pp.\  2739--2745, 2020.

\bibitem[Luan et~al.(2022)Luan, Hua, Lu, Zhu, Zhao, Zhang, Chang, and Precup]{luan2022revisiting}
Luan, S., Hua, C., Lu, Q., Zhu, J., Zhao, M., Zhang, S., Chang, X.-W., and Precup, D.
\newblock Revisiting heterophily for graph neural networks.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 1362--1375, 2022.

\bibitem[Oliveira(2009)]{oliveira2009concentration}
Oliveira, R.~I.
\newblock Concentration of the adjacency matrix and of the laplacian in random graphs with independent edges.
\newblock \emph{arXiv preprint arXiv:0911.0600}, 2009.

\bibitem[Oono \& Suzuki(2019)Oono and Suzuki]{oono2019graph}
Oono, K. and Suzuki, T.
\newblock Graph neural networks exponentially lose expressive power for node classification.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Pei et~al.(2020)Pei, Wei, Chang, Lei, and Yang]{pei2020geom}
Pei, H., Wei, B., Chang, K. C.-C., Lei, Y., and Yang, B.
\newblock Geom-gcn: Geometric graph convolutional networks.
\newblock \emph{arXiv preprint arXiv:2002.05287}, 2020.

\bibitem[Platonov et~al.(2022)Platonov, Kuznedelev, Diskin, Babenko, and Prokhorenkova]{platonov2022critical}
Platonov, O., Kuznedelev, D., Diskin, M., Babenko, A., and Prokhorenkova, L.
\newblock A critical look at the evaluation of gnns under heterophily: Are we really making progress?
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Rozemberczki et~al.(2021)Rozemberczki, Allen, and Sarkar]{rozemberczki2021multi}
Rozemberczki, B., Allen, C., and Sarkar, R.
\newblock Multi-scale attributed node embedding.
\newblock \emph{Journal of Complex Networks}, 9\penalty0 (2):\penalty0 cnab014, 2021.

\bibitem[Song et~al.(2022)Song, Zhou, Wang, and Lin]{song2022ordered}
Song, Y., Zhou, C., Wang, X., and Lin, Z.
\newblock Ordered gnn: Ordering message passing to deal with heterophily and over-smoothing.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Tang et~al.(2013)Tang, Hu, Gao, and Liu]{DBLP:conf/ijcai/TangHGL13}
Tang, J., Hu, X., Gao, H., and Liu, H.
\newblock Exploiting local and global social context for recommendation.
\newblock In \emph{{IJCAI}}, pp.\  2712--2718, 2013.

\bibitem[Tsitsulin et~al.(2023)Tsitsulin, Palowitch, Perozzi, and M{\"u}ller]{tsitsulin2023graph}
Tsitsulin, A., Palowitch, J., Perozzi, B., and M{\"u}ller, E.
\newblock Graph clustering with graph neural networks.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (127):\penalty0 1--21, 2023.

\bibitem[Veli{\v{c}}kovi{\'c} et~al.(2018)Veli{\v{c}}kovi{\'c}, Cucurull, Casanova, Romero, Li{\`o}, and Bengio]{velivckovic2018graph}
Veli{\v{c}}kovi{\'c}, P., Cucurull, G., Casanova, A., Romero, A., Li{\`o}, P., and Bengio, Y.
\newblock Graph attention networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Wu et~al.(2022)Wu, Chen, Wang, and Jadbabaie]{wu2022non}
Wu, X., Chen, Z., Wang, W.~W., and Jadbabaie, A.
\newblock A non-asymptotic analysis of oversmoothing in graph neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Wu et~al.(2023)Wu, Ajorlou, Wu, and Jadbabaie]{wu2023demystifying}
Wu, X., Ajorlou, A., Wu, Z., and Jadbabaie, A.
\newblock Demystifying oversmoothing in attention-based graph neural networks.
\newblock \emph{arXiv preprint arXiv:2305.16102}, 2023.

\bibitem[Xu et~al.(2018{\natexlab{a}})Xu, Hu, Leskovec, and Jegelka]{xu2018powerful}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S.
\newblock How powerful are graph neural networks?
\newblock In \emph{International Conference on Learning Representations}, 2018{\natexlab{a}}.

\bibitem[Xu et~al.(2018{\natexlab{b}})Xu, Li, Tian, Sonobe, Kawarabayashi, and Jegelka]{xu2018representation}
Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K.-i., and Jegelka, S.
\newblock Representation learning on graphs with jumping knowledge networks.
\newblock In \emph{International conference on machine learning}, pp.\  5453--5462. PMLR, 2018{\natexlab{b}}.

\bibitem[Yan et~al.(2022)Yan, Hashemi, Swersky, Yang, and Koutra]{yan2022two}
Yan, Y., Hashemi, M., Swersky, K., Yang, Y., and Koutra, D.
\newblock Two sides of the same coin: Heterophily and oversmoothing in graph convolutional neural networks.
\newblock In \emph{2022 IEEE International Conference on Data Mining (ICDM)}, pp.\  1287--1292. IEEE, 2022.

\bibitem[Yang et~al.(2021)Yang, Li, Liu, Wang, Cao, Guo, et~al.]{yang2021diverse}
Yang, L., Li, M., Liu, L., Wang, C., Cao, X., Guo, Y., et~al.
\newblock Diverse message passing for attribute with heterophily.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 4751--4763, 2021.

\bibitem[Yang et~al.(2016)Yang, Cohen, and Salakhutdinov]{DBLP:conf/icml/YangCS16}
Yang, Z., Cohen, W.~W., and Salakhutdinov, R.
\newblock Revisiting semi-supervised learning with graph embeddings.
\newblock In \emph{International Conference on Machine Learning}, volume~48, pp.\  40--48. PMLR, 2016.

\bibitem[Zheng et~al.(2022)Zheng, Liu, Pan, Zhang, Jin, and Yu]{DBLP:journals/corr/abs-2202-07082}
Zheng, X., Liu, Y., Pan, S., Zhang, M., Jin, D., and Yu, P.~S.
\newblock Graph neural networks for graphs with heterophily: {A} survey.
\newblock \emph{CoRR}, abs/2202.07082, 2022.

\bibitem[Zheng et~al.(2023)Zheng, Zhang, Lee, Zheng, Wang, and Pan]{DBLP:conf/icml/ZhengZLZWP23}
Zheng, Y., Zhang, H., Lee, V.~C., Zheng, Y., Wang, X., and Pan, S.
\newblock Finding the missing-half: Graph complementary learning for homophily-prone and heterophily-prone graphs.
\newblock In \emph{International Conference on Machine Learning}, volume 202, pp.\  42492--42505. {PMLR}, 2023.

\bibitem[Zhou et~al.(2021)Zhou, Huang, Zha, Chen, Li, Choi, and Hu]{zhou2021dirichlet}
Zhou, K., Huang, X., Zha, D., Chen, R., Li, L., Choi, S.-H., and Hu, X.
\newblock Dirichlet energy constrained learning for deep graph neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 21834--21846, 2021.

\bibitem[Zhu et~al.(2020)Zhu, Yan, Zhao, Heimann, Akoglu, and Koutra]{zhu2020beyond}
Zhu, J., Yan, Y., Zhao, L., Heimann, M., Akoglu, L., and Koutra, D.
\newblock Beyond homophily in graph neural networks: Current limitations and effective designs.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 7793--7804, 2020.

\end{thebibliography}
