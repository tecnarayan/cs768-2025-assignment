@article{barto03,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, A. and Mahadevan, S.},
  journal={Discrete Event Dynamic Systems},
  volume={13},
  number={1-2},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@inproceedings{mirowski2016learning,
  title={Learning to navigate in complex environments},
  author={Mirowski, P. and Pascanu, R. and Viola, F. and Soyer, H. and Ballard, A. and Banino, A. and Denil, M. and Goroshin, R. and Sifre, L. and Kavukcuoglu, K. and others},
  booktitle = {International Conference on Learning Representations},
  year={2017}
}

@article{beattie16,
  title={{DeepMind} lab},
  author={Beattie, C. and Leibo, J. and Teplyashin, D. and Ward, T. and Wainwright, M. and K{\"u}ttler, H. and Lefrancq, A. and Green, S. and Vald{\'e}s, V. and Sadik, Amir and others},
  journal={arXiv preprint arXiv:1612.03801},
  year={2016}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, M. and Wolski, F. and Ray, A. and Schneider, J. and Fong, R. and Welinder, P. and McGrew, B. and Tobin, J. and Abbeel, P. and Zaremba, W.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}


@article{mnih15,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, V. and Kavukcuoglu, K. and Silver, D. and Rusu, A. and Veness, J. and Bellemare, M. and Graves, A. and Riedmiller, M. and Fidjeland, A. and Ostrovski, G. and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@phdthesis{watkins89,
    title    = {Learning from delayed rewards},
    school   = {King's College, Cambridge},
    author   = {Watkins, C.},
    year     = {1989}
}


@inproceedings{lillicrap16,
  author = {Lillicrap, T.. and Hunt, J. and Pritzel, A. and Heess, N. and Erez, T. and Tassa, Y. and Silver, D. and Wierstra, D.},
  booktitle = {International Conference on Learning Representations},
  title = {Continuous control with deep reinforcement learning.},
  year = 2016
}


@article{levine16,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@article{silver17,
  title={Mastering the game of go without human knowledge},
  author={Silver, D. and Schrittwieser, J. and Simonyan, K. and Antonoglou, I. and Huang, A. and Guez, A. and Hubert, T. and Baker, L. and Lai, M. and Bolton, A. and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{barreto17,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, A. and Dabney, W. and Munos, R. and Hunt, J. and Schaul, T. and van Hasselt, H. and Silver, D.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4055--4065},
  year={2017}
}


@InProceedings{hunt19,
  title = 	 {Composing Entropic Policies using Divergence Correction},
  author = 	 {Hunt, J. and Barreto, A. and Lillicrap, T. and Heess, N.},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2911--2920},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  publisher = 	 {PMLR},
}


@InProceedings{vanniekerk19,
  title = 	 {Composing Value Functions in Reinforcement Learning},
  author = 	 {Van Niekerk, B. and James, S. and Earle, A. and Rosman, B.},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6401--6409},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  publisher = 	 {PMLR}
}

@article{dayan93,
  title={Improving generalization for temporal difference learning: The successor representation},
  author={Dayan, P.},
  journal={Neural Computation},
  volume={5},
  number={4},
  pages={613--624},
  year={1993},
  publisher={MIT Press}
}

@article{hernandez92,
  title={Discrete-time {M}arkov control processes with discounted unbounded costs: optimality criteria},
  author={Hern{\'a}ndez-Lerma, O. and Mu{\~n}oz de Ozak, M.},
  journal={Kybernetika},
  volume={28},
  number={3},
  pages={191--212},
  year={1992}
}

@book{rudin87,
    author = {Rudin, W.},
    title = {Real and Complex Analysis},
    year = {1987},
    edition={3},
    isbn = {0070542341},
    publisher = {McGraw-Hill, Inc.},
    address = {New York, NY, USA},
}

@book{dupuis11,
    author = {Dupuis, P. and Ellis, R.},
    title = {A weak convergence approach to the theory of large deviations},
    year = {2011},
}

@article{schal74,
    author = {Sch{\"a}l, M.},
    title = {A selection theorem for optimization problems},
    journal = {Archiv der Mathematik},
    year = {1974},
    volume = {25},
    pages = {219--224}
}

@article{feinberg14,
    author = {Feinberg, E. A. and Kasyanov, P. O. and Zadoianchuk, N. V.},
    title = {Fatou's Lemma for Weakly Converging Probabilities},
    journal = {Theory of Probability \& Its Applications},
    volume = {58},
    pages = {683-689},
    year = {2014},
}

@incollection{hinderer70,
    author = {Hinderer, K.},
    booktitle = {Lecture Notes in Operations Research and Mathematical Systems},
    keywords = {imported},
    title = {Foundations of Non-Stationary Dynamic Programming with Discrete Time Parameter},
    volume = {33},
    year = {1970},
}

@article{taylor09,
    title = {Transfer learning for reinforcement learning domains: a survey},
    year = {2009},
    journal = {Journal of Machine Learning Research},
    author = {Taylor, M.E. and Stone, P.},
    pages = {1633--1685},
    volume = {10},
}

@book{klenke95,
    title = {Probability Theory: A Comprehensive Course},
    year = {1995},
    author = {Klenke, A.},
    pages = {145 - 158},
    volume = {158},
    isbn = {9781447153603}
}

@article{kappen05,
    title = {Linear Theory for Control of Nonlinear Stochastic Systems},
    year = {2005},
    journal = {Physical Review Letters},
    author = {Kappen, H.J.},
    number = {20},
    month = {11},
    pages = {200201},
    volume = {95},
    issn = {0031-9007},
    pmid = {16384034},
    arxivId = {physics/0411119}
}

@inproceedings{todorov07,
  title={Linearly-solvable {Markov} decision problems},
  author={Todorov, E.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1369--1376},
  year={2007}
}


@article{saxe17,
    title = {Hierarchy Through Composition with Multitask {LMDP}s},
    year = {2017},
    journal = {Proceedings of the 34th International Conference on Machine Learning},
    author = {Saxe, A.M. and Earle, A.C. and Rosman, B.S.},
    pages = {3017--3026},
    volume = {70},
}

@inproceedings{haarnoja17,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning},
  pages={1352--1361},
  year={2017}
}

@inproceedings{haarnoja18,
  title={Composable deep reinforcement learning for robotic manipulation},
  author={Haarnoja, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
  booktitle={2018 IEEE International Conference on Robotics and Automation},
  pages={6244--6251},
  year={2018},
  organization={IEEE}
}

@inproceedings{todorov09,
  title={Compositionality of optimal control laws},
  author={Todorov, E.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1856--1864},
  year={2009}
}


@article{schulman17,
    title = {Equivalence Between Policy Gradients and Soft {Q}-Learning},
    year = {2017},
    author = {Schulman, J. and Abbeel, P. and Chen, X.},
    pages = {1--15},
    arxivId = {1704.06440}
}

@inproceedings{silver13,
    title = {Lifelong Machine Learning Systems : Beyond Learning Algorithms},
    year = {2013},
  	booktitle={AAAI Spring Symposium: Lifelong Machine Learning},
    author = {Silver, D.L. and Yang, Q. and Li, L.},
  	volume={13},
  	pages={05},
  	year={2013}
}

@inproceedings{nachum17,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, O. and Norouzi, M. and Xu, K. and Schuurmans, D.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2772--2782},
  year={2017}
}

@article{sutton99,
  title={Between {MDP}s and semi-{MDP}s: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, R. and Precup, D. and Singh, S.},
  journal={Artificial Intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{bacon17,
  title={The option-critic architecture},
  author={Bacon, P. and Harb, J. and Precup, D.},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@article{dasilva09,
  title={Linear {B}ellman combination for control of character animation},
  author={Da Silva, M. and Durand, F. and Popovi{\'c}, J.},
  journal={ACM Transactions on Graphics},
  volume={28},
  number={3},
  pages={82},
  year={2009},
  publisher={ACM}
}

@InProceedings{schaul15,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Schaul, T. and Horgan, D. and Gregor, K. and Silver, D.},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  publisher = 	 {PMLR},
}

@inproceedings{kaelbling93,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={International Joint Conferences on Artificial Intelligence},
  pages={1094--1099},
  year={1993}
}

@article{veeriah2018many,
  title={Many-goals reinforcement learning},
  author={Veeriah, V. and Oh, J. and Singh, S.},
  journal={arXiv preprint arXiv:1806.09605},
  year={2018}
}

@article{jaksch10,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, T. and Ortner, R. and Auer, P.},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}
@inproceedings{sutton11,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, R. and Modayil, J. and Delp, M. and Degris, T. and Pilarski, P. and White, A. and Precup, D.},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@inproceedings{andrychowicz17,
  title={Hindsight experience replay},
  author={Andrychowicz, M. and Wolski, F. and Ray, A. and Schneider, J. and Fong, R. and Welinder, P. and McGrew, B. and Tobin, J. and Abbeel, P. and Zaremba, W.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}

@article{peng19,
  title={{MCP}: Learning Composable Hierarchical Control with Multiplicative Compositional Policies},
  author={Peng, X. and Chang, M. and Zhang, G. and Abbeel, P. and Levine, S.},
  journal={arXiv preprint arXiv:1905.09808},
  year={2019}
}

@article{bertsekas91,
  title={An analysis of stochastic shortest path problems},
  author={Bertsekas, D.P. and Tsitsiklis, J.N.},
  journal={Mathematics of Operations Research},
  volume={16},
  number={3},
  pages={580--595},
  year={1991}
}

@inproceedings{bertsekas95,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, D.P. and Tsitsiklis, J.N.},
  booktitle={Proceedings of the 34th IEEE Conference on Decision and Control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}


@article{james06,
  title={An analysis of transient {M}arkov decision processes},
  author={James, H.W. and Collins, E.J.},
  journal={Journal of Applied Probability},
  volume={43},
  number={3},
  pages={603--621},
  year={2006},
  publisher={Cambridge University Press}
}

@book{puterman14,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, M.L.},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{klenke13,
  title={Probability theory: a comprehensive course},
  author={Klenke, A.},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{ziebert10,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, B.D.},
  year={2010},
  publisher={Carnegie Mellon University}
}

@inproceedings{fox15,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, R. and Pakman, A. and Tishby, N.},
  booktitle={32nd Conference on Uncertainty in Artificial Intelligence},
  year={2016}
}
