\begin{thebibliography}{}

\bibitem[Daniusis et~al., 2012]{daniusis2012inferring}
Daniusis, P., Janzing, D., Mooij, J., Zscheischler, J., Steudel, B., Zhang, K.,
  and Sch{\"o}lkopf, B. (2012).
\newblock Inferring deterministic causal relations.
\newblock {\em arXiv preprint arXiv:1203.3475}.

\bibitem[Ester et~al., 1996]{ester1996density}
Ester, M., Kriegel, H.-P., Sander, J., and Xu, X. (1996).
\newblock A density-based algorithm for discovering clusters a density-based
  algorithm for discovering clusters in large spatial databases with noise.
\newblock In {\em Proceedings of the Second International Conference on
  Knowledge Discovery and Data Mining}, KDD'96, pages 226--231. AAAI Press.

\bibitem[Fukumizu et~al., 2004]{fukumizu2004dimensionality}
Fukumizu, K., Bach, F.~R., and Jordan, M.~I. (2004).
\newblock Dimensionality reduction for supervised learning with reproducing
  kernel hilbert spaces.
\newblock {\em Journal of Machine Learning Research}, 5(Jan):73--99.

\bibitem[Gretton et~al., 2005a]{gretton2005measuring}
Gretton, A., Bousquet, O., Smola, A., and Sch{\"o}lkopf, B. (2005a).
\newblock Measuring statistical dependence with hilbert-schmidt norms.
\newblock In {\em International conference on algorithmic learning theory},
  pages 63--77. Springer.

\bibitem[Gretton et~al., 2005b]{gretton2005kernel}
Gretton, A., Smola, A.~J., Bousquet, O., Herbrich, R., Belitski, A., Augath,
  M., Murayama, Y., Pauls, J., Sch{\"o}lkopf, B., and Logothetis, N.~K.
  (2005b).
\newblock Kernel constrained covariance for dependence measurement.
\newblock In {\em AISTATS}, volume~10, pages 112--119.

\bibitem[Hoyer et~al., 2009]{hoyer2009nonlinear}
Hoyer, P.~O., Janzing, D., Mooij, J.~M., Peters, J., and Sch{\"o}lkopf, B.
  (2009).
\newblock Nonlinear causal discovery with additive noise models.
\newblock In {\em Advances in neural information processing systems}, pages
  689--696.

\bibitem[Hubert and Arabie, 1985]{hubert1985comparing}
Hubert, L. and Arabie, P. (1985).
\newblock Comparing partitions.
\newblock {\em Journal of classification}, 2(1):193--218.

\bibitem[Janzing et~al., 2012]{janzing2012information}
Janzing, D., Mooij, J., Zhang, K., Lemeire, J., Zscheischler, J.,
  Daniu{\v{s}}is, P., Steudel, B., and Sch{\"o}lkopf, B. (2012).
\newblock Information-geometric approach to inferring causal directions.
\newblock {\em Artificial Intelligence}, 182:1--31.

\bibitem[Janzing and Scholkopf, 2010]{janzing2010causal}
Janzing, D. and Scholkopf, B. (2010).
\newblock Causal inference using the algorithmic markov condition.
\newblock {\em IEEE Transactions on Information Theory}, 56(10):5168--5194.

\bibitem[Lawrence, 2005]{lawrence2005probabilistic}
Lawrence, N. (2005).
\newblock Probabilistic non-linear principal component analysis with gaussian
  process latent variable models.
\newblock {\em Journal of machine learning research}, 6(Nov):1783--1816.

\bibitem[Lawrence, 2004]{lawrence2004gaussian}
Lawrence, N.~D. (2004).
\newblock Gaussian process latent variable models for visualisation of high
  dimensional data.
\newblock In {\em Advances in neural information processing systems}, pages
  329--336.

\bibitem[Liu and Chan, 2016]{liu2016causal}
Liu, F. and Chan, L. (2016).
\newblock Causal discovery on discrete data with extensions to mixture model.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  7(2):21.

\bibitem[MacQueen, 1967]{macqueen1967some}
MacQueen, J. (1967).
\newblock Some methods for classification and analysis of multivariate
  observations.
\newblock In {\em Proceedings of the Fifth Berkeley Symposium on Mathematical
  Statistics and Probability, Volume 1: Statistics}, pages 281--297, Berkeley,
  Calif. University of California Press.

\bibitem[M{\o}ller, 1993]{moller1993scaled}
M{\o}ller, M.~F. (1993).
\newblock A scaled conjugate gradient algorithm for fast supervised learning.
\newblock {\em Neural networks}, 6(4):525--533.

\bibitem[Mooij et~al., 2016]{mooij2016distinguishing}
Mooij, J.~M., Peters, J., Janzing, D., Zscheischler, J., and Sch{\"o}lkopf, B.
  (2016).
\newblock Distinguishing cause from effect using observational data: methods
  and benchmarks.
\newblock {\em The Journal of Machine Learning Research}, 17(1):1103--1204.

\bibitem[Rasmussen, 2000]{rasmussen2000infinite}
Rasmussen, C.~E. (2000).
\newblock The infinite gaussian mixture model.
\newblock In {\em Advances in neural information processing systems}, pages
  554--560.

\bibitem[Shi and Malik, 2000]{shi2000normalized}
Shi, J. and Malik, J. (2000).
\newblock Normalized cuts and image segmentation.
\newblock {\em IEEE Transactions on pattern analysis and machine intelligence},
  22(8):888--905.

\bibitem[Shimizu et~al., 2006]{shimizu2006linear}
Shimizu, S., Hoyer, P.~O., Hyv{\"a}rinen, A., and Kerminen, A. (2006).
\newblock A linear non-gaussian acyclic model for causal discovery.
\newblock {\em Journal of Machine Learning Research}, 7(Oct):2003--2030.

\bibitem[Williams, 1998]{williams1998prediction}
Williams, C.~K. (1998).
\newblock Prediction with gaussian processes: From linear regression to linear
  prediction and beyond.
\newblock In {\em Learning in graphical models}, pages 599--621. Springer.

\bibitem[Zhang et~al., 2015]{zhang2015discovery}
Zhang, K., Huang, B., Zhang, J., Sch{\"o}lkopf, B., and Glymour, C. (2015).
\newblock Discovery and visualization of nonstationary causal models.
\newblock {\em arXiv preprint arXiv:1509.08056}.

\bibitem[Zhang and Hyv{\"a}rinen, 2009]{zhang2009identifiability}
Zhang, K. and Hyv{\"a}rinen, A. (2009).
\newblock On the identifiability of the post-nonlinear causal model.
\newblock In {\em Proceedings of the twenty-fifth conference on uncertainty in
  artificial intelligence}, pages 647--655. AUAI Press.

\end{thebibliography}
