\newcommand{\etalchar}[1]{$^{#1}$}
\providecommand{\bysame}{\leavevmode\hbox to3em{\hrulefill}\thinspace}
\providecommand{\MR}{\relax\ifhmode\unskip\space\fi MR }
% \MRhref is called by the amsart/book/proc definition of \MR.
\providecommand{\MRhref}[2]{%
  \href{http://www.ams.org/mathscinet-getitem?mr=#1}{#2}
}
\providecommand{\href}[2]{#2}
\begin{thebibliography}{VDVW96}

\bibitem[Ace02]{acerbi2002spectral}
Carlo Acerbi, \emph{Spectral measures of risk: A coherent representation of
  subjective risk aversion}, Journal of Banking \& Finance \textbf{26} (2002),
  no.~7, 1505--1518.

\bibitem[ALW13]{alquier2013prediction}
Pierre Alquier, Xiaoyin Li, and Olivier Wintenberger, \emph{Prediction of time
  series by statistical learning: {G}eneral losses and fast rates}, Dependence
  Modeling \textbf{1} (2013), no.~2013, 65--93.

\bibitem[AV90]{aldous1990markovian}
David Aldous and Umesh Vazirani, \emph{A {M}arkovian extension of {V}aliant's
  learning model}, Proceedings [1990] 31st Annual Symposium on Foundations of
  Computer Science, IEEE, 1990, pp.~392--396.

\bibitem[AW12]{alquier2012model}
Pierre Alquier and Olivier Wintenberger, \emph{Model selection for weakly
  dependent time series forecasting}, Bernoulli \textbf{18} (2012), no.~3,
  883--913.

\bibitem[BBM05]{bartlett2005local}
Peter~L Bartlett, Olivier Bousquet, and Shahar Mendelson, \emph{Local
  {R}ademacher complexities}, The Annals of Statistics \textbf{33} (2005),
  no.~4, 1497--1537.

\bibitem[BF89]{boente1989robust}
Graciela Boente and Ricardo Fraiman, \emph{Robust nonparametric regression
  estimation for dependent observations}, The Annals of Statistics (1989),
  1242--1256.

\bibitem[BL97]{barve1997complexity}
Rakesh~D Barve and Philip~M Long, \emph{On the complexity of learning from
  drifting distributions}, Information and Computation \textbf{138} (1997),
  no.~2, 170--193.

\bibitem[BM21]{bartl2021monte}
Daniel Bartl and Shahar Mendelson, \emph{On {Monte-Carlo} methods in convex
  stochastic optimization}, arXiv preprint arXiv:2101.07794 (2021).

\bibitem[BMdlP20]{bakhshizadeh2020sharp}
Milad Bakhshizadeh, Arian Maleki, and Victor~H de~la Pena, \emph{Sharp
  concentration results for heavy-tailed distributions}, arXiv preprint
  arXiv:2003.13819 (2020).

\bibitem[BR97]{berti1997glivenko}
Patrizia Berti and Pietro Rigo, \emph{A {Glivenko-Cantelli} theorem for
  exchangeable random variables}, Statistics \& probability letters \textbf{32}
  (1997), no.~4, 385--391.

\bibitem[Bra05]{bradley2005basic}
Richard~C Bradley, \emph{Basic properties of strong mixing conditions. a survey
  and some open questions}, arXiv preprint math/0511078 (2005).

\bibitem[CG14]{chwialkowski2016kernel}
Kacper Chwialkowski and Arthur Gretton, \emph{A kernel independence test for
  random processes}, International Conference on Machine Learning, PMLR, 2014,
  pp.~1422--1430.

\bibitem[Che07]{chesneau2007tail}
Christophe Chesneau, \emph{A tail bound for sums of independent random
  variables: application to the symmetric pareto distribution}.

\bibitem[DDDJ19]{dagan2019learning}
Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, and Siddhartha Jayanti,
  \emph{Learning from weakly dependent data under {Dobrushin's} condition},
  Conference on Learning Theory, PMLR, 2019, pp.~914--928.

\bibitem[DKBR07]{dundar2007learning}
Murat Dundar, Balaji Krishnapuram, Jinbo Bi, and R~Bharat Rao, \emph{Learning
  classifiers when the training data is not {IID}.}, IJCAI, vol. 2007, 2007,
  pp.~756--61.

\bibitem[DP04]{dedecker2004coupling}
J{\'e}r{\^o}me Dedecker and Cl{\'e}mentine Prieur, \emph{Coupling for
  $\tau$-dependent sequences and applications}, Journal of Theoretical
  Probability \textbf{17} (2004), no.~4, 861--885.

\bibitem[DT20]{dawid2020learnability}
A~Philip Dawid and Ambuj Tewari, \emph{On learnability under general stochastic
  processes}, arXiv preprint arXiv:2005.07605 (2020).

\bibitem[FS12]{farahmand2012regularized}
Amir-massoud Farahmand and Csaba Szepesv{\'a}ri, \emph{Regularized
  least-squares regression: Learning from a $\beta$-mixing sequence}, Journal
  of Statistical Planning and Inference \textbf{142} (2012), no.~2, 493--505.

\bibitem[Gam03]{gamarnik2003extension}
David Gamarnik, \emph{Extension of the {PAC} framework to finite and countable
  markov chains}, IEEE Transactions on Information Theory \textbf{49} (2003),
  no.~1, 338--345.

\bibitem[GM20]{grunwald2020fast}
Peter~D Gr{\"u}nwald and Nishant~A Mehta, \emph{Fast rates for general
  unbounded loss functions: From {ERM} to {Generalized Bayes}.}, Journal of
  Machine Learning Research \textbf{21} (2020), no.~56, 1--80.

\bibitem[Han21]{hanneke2020learning}
Steve Hanneke, \emph{Learning whenever learning is possible: Universal learning
  under general stochastic processes}, Journal of Machine Learning Research (to
  appear) (2021).

\bibitem[HH21]{holland2021spectral}
Matthew~J Holland and El~Mehdi Haress, \emph{Spectral risk-based learning using
  unbounded losses}, arXiv preprint arXiv:2105.04816 (2021).

\bibitem[HS14]{hang2014fast}
Hanyuan Hang and Ingo Steinwart, \emph{Fast learning from $\alpha$-mixing
  observations}, Journal of Multivariate Analysis \textbf{127} (2014),
  184--199.

\bibitem[Hub92]{huber1992robust}
Peter~J Huber, \emph{Robust estimation of a location parameter}, Breakthroughs
  in statistics, Springer, 1992, pp.~492--518.

\bibitem[HW19]{han2019convergence}
Qiyang Han and Jon~A Wellner, \emph{Convergence rates of least squares
  regression estimators with heavy-tailed errors}, Annals of Statistics
  \textbf{47} (2019), no.~4, 2286--2319.

\bibitem[Irl97]{irle1997consistency}
A~Irle, \emph{On consistency in nonparametric estimation under mixing
  conditions}, Journal of multivariate analysis \textbf{60} (1997), no.~1,
  123--147.

\bibitem[JM01]{jiang2001robust}
Jiancheng Jiang and YP~Mack, \emph{Robust local polynomial regression for
  dependent data}, Statistica Sinica (2001), 705--722.

\bibitem[KDD{\etalchar{+}}21]{kandiros2021statistical}
Vardis Kandiros, Yuval Dagan, Nishanth Dikkala, Surbhi Goel, and Constantinos
  Daskalakis, \emph{Statistical estimation from dependent data}, International
  Conference on Machine Learning, PMLR, 2021, pp.~5269--5278.

\bibitem[KM17]{kuznetsov2017generalization}
Vitaly Kuznetsov and Mehryar Mohri, \emph{Generalization bounds for
  non-stationary mixing processes}, Machine Learning \textbf{106} (2017),
  no.~1, 93--117.

\bibitem[Kol06]{koltchinskii2006local}
Vladimir Koltchinskii, \emph{Local {R}ademacher complexities and oracle
  inequalities in risk minimization}, Annals of Statistics \textbf{34} (2006),
  no.~6, 2593--2656.

\bibitem[Kol11]{koltchinskii2011oracle}
\bysame, \emph{Oracle inequalities in empirical risk minimization and sparse
  recovery problems}, vol. 2033, Springer Science \& Business Media, 2011.

\bibitem[LL20]{lecue2020robust}
Guillaume Lecu{\'e} and Matthieu Lerasle, \emph{Robust machine learning by
  median-of-means: theory and practice}, Annals of Statistics \textbf{48}
  (2020), no.~2, 906--931.

\bibitem[LM18]{lecue2018regularization}
Guillaume Lecu{\'e} and Shahar Mendelson, \emph{Regularization and the
  small-ball method {I}: {S}parse recovery}, The Annals of Statistics
  \textbf{46} (2018), no.~2, 611--641.

\bibitem[LM19]{lugosi2019regularization}
G{\'a}bor Lugosi and Shahar Mendelson, \emph{Regularization, sparse recovery,
  and median-of-means tournaments}, Bernoulli \textbf{25} (2019), no.~3,
  2075--2106.

\bibitem[Loh17]{loh2017statistical}
Po-Ling Loh, \emph{Statistical consistency and asymptotic normality for
  high-dimensional robust $ m $-estimators}, The Annals of Statistics
  \textbf{45} (2017), no.~2, 866--896.

\bibitem[LRS15]{liang2015learning}
Tengyuan Liang, Alexander Rakhlin, and Karthik Sridharan, \emph{Learning with
  square loss: {L}ocalization through offset {R}ademacher complexity},
  Conference on Learning Theory, PMLR, 2015, pp.~1260--1285.

\bibitem[LT13]{ledoux2013probability}
Michel Ledoux and Michel Talagrand, \emph{Probability in banach spaces:
  isoperimetry and processes}, Springer Science \& Business Media, 2013.

\bibitem[Mei00]{meir2000nonparametric}
Ron Meir, \emph{Nonparametric time series prediction through adaptive model
  selection}, Machine learning \textbf{39} (2000), no.~1, 5--34.

\bibitem[Men15]{pmlr-v35-mendelson14}
Shahar Mendelson, \emph{Learning without concentration}, Journal of the ACM
  (JACM) \textbf{62} (2015), no.~3, 1--25.

\bibitem[Men17a]{mendelson2017local}
\bysame, \emph{Local vs. global parameters: {B}reaking the {G}aussian
  complexity barrier}, Annals of statistics \textbf{45} (2017), no.~5,
  1835--1862.

\bibitem[Men17b]{mendelson2017multiplier}
\bysame, \emph{On multiplier processes under weak moment assumptions},
  Geometric aspects of functional analysis, Springer, 2017, pp.~301--318.

\bibitem[Men18]{mendelson2018learning}
\bysame, \emph{Learning without concentration for general loss functions},
  Probability Theory and Related Fields \textbf{171} (2018), no.~1, 459--502.

\bibitem[MGW20]{mhammedi2020pac}
Zakaria Mhammedi, Benjamin Guedj, and Robert~C Williamson, \emph{Pac-bayesian
  bound for the conditional value at risk}, arXiv preprint arXiv:2006.14763
  (2020).

\bibitem[MM19]{minsker2019excess}
Stanislav Minsker and Timoth{\'e}e Mathieu, \emph{Excess risk bounds in robust
  empirical risk minimization}, arXiv preprint arXiv:1910.07485 (2019).

\bibitem[Mok88]{mokkadem1988mixing}
Abdelkader Mokkadem, \emph{Mixing properties of arma processes}, Stochastic
  processes and their applications \textbf{29} (1988), no.~2, 309--315.

\bibitem[MPR11]{merlevede2011bernstein}
Florence Merlev{\`e}de, Magda Peligrad, and Emmanuel Rio, \emph{A {B}ernstein
  type inequality and moderate deviations for weakly dependent sequences},
  Probability Theory and Related Fields \textbf{151} (2011), no.~3-4, 435--474.

\bibitem[MR08]{mohri2008rademacher}
Mehryar Mohri and Afshin Rostamizadeh, \emph{Rademacher complexity bounds for
  {Non-IID} processes}, Proceedings of the 21st International Conference on
  Neural Information Processing Systems, 2008, pp.~1097--1104.

\bibitem[MS11]{mcdonald2011rademacher}
Daniel~J McDonald and Cosma~Rohilla Shalizi, \emph{Rademacher complexity of
  stationary sequences}, arXiv preprint arXiv:1106.0730 (2011).

\bibitem[MZ20]{mendelson2020robust}
Shahar Mendelson and Nikita Zhivotovskiy, \emph{Robust covariance estimation
  under $ l_4$-$l_2$ norm equivalence}, Annals of Statistics \textbf{48}
  (2020), no.~3, 1648--1664.

\bibitem[Nob99]{nobel1999limits}
Andrew~B Nobel, \emph{Limits to classification and regression estimation from
  ergodic processes}, The Annals of Statistics \textbf{27} (1999), no.~1,
  262--273.

\bibitem[Pes10]{pestov2010predictive}
Vladimir Pestov, \emph{Predictive {PAC} learnability: {A} paradigm for learning
  from exchangeable input data}, 2010 IEEE International Conference on Granular
  Computing, IEEE, 2010, pp.~387--391.

\bibitem[Pil91]{pillai1991semi}
RN~Pillai, \emph{Semi-pareto processes}, Journal of applied probability (1991),
  461--465.

\bibitem[Ris08]{ristic2008generalized}
Miroslav~M Risti{\'c}, \emph{A generalized semi-pareto minification process},
  Statistical Papers \textbf{49} (2008), no.~2, 343--351.

\bibitem[RS06]{ruszczynski2006optimization}
Andrzej Ruszczy{\'n}ski and Alexander Shapiro, \emph{Optimization of convex
  risk functions}, Mathematics of operations research \textbf{31} (2006),
  no.~3, 433--452.

\bibitem[RS14]{rakhlin2014online}
Alexander Rakhlin and Karthik Sridharan, \emph{Online non-parametric
  regression}, Conference on Learning Theory, PMLR, 2014, pp.~1232--1264.

\bibitem[RSS10]{ralaivola2010chromatic}
Liva Ralaivola, Marie Szafranski, and Guillaume Stempfel, \emph{{Chromatic
  PAC-Bayes bounds for non-IID data: Applications to ranking and stationary
  $\beta$-mixing processes}}, The Journal of Machine Learning Research
  \textbf{11} (2010), 1927--1956.

\bibitem[RST15]{rakhlin2012empirical}
Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari, \emph{Sequential
  complexities and uniform martingale laws of large numbers}, Probability
  Theory and Related Fields \textbf{161} (2015), no.~1-2, 111--153.

\bibitem[RU02]{rockafellar2002conditional}
R~Tyrrell Rockafellar and Stanislav Uryasev, \emph{Conditional value-at-risk
  for general loss distributions}, Journal of banking \& finance \textbf{26}
  (2002), no.~7, 1443--1471.

\bibitem[SHS09]{steinwart2009learning}
Ingo Steinwart, Don Hush, and Clint Scovel, \emph{Learning from dependent
  observations}, Journal of Multivariate Analysis \textbf{100} (2009), no.~1,
  175--194.

\bibitem[SY20]{soma2020statistical}
Tasuku Soma and Yuichi Yoshida, \emph{Statistical learning with conditional
  value at risk}, arXiv preprint arXiv:2002.05826 (2020).

\bibitem[VC71]{vapnik1971uniform}
Vladimir Vapnik and Aleksei Chervonenkis, \emph{On uniform convergence of the
  frequencies of events to their probabilities}, Teoriya Veroyatnostei i ee
  Primeneniya \textbf{16} (1971), no.~2, 264--279.

\bibitem[vdG00]{geer2000empirical}
Sara van~de Geer, \emph{Empirical processes in m-estimation}, vol.~6, Cambridge
  university press, 2000.

\bibitem[VDVW96]{van1996weak}
Aad~W Van Der~Vaart and Jon~A Wellner, \emph{Weak convergence}, Weak
  convergence and empirical processes, Springer, 1996, pp.~16--28.

\bibitem[VGNA20]{vladimirova2020sub}
Mariia Vladimirova, St{\'e}phane Girard, Hien Nguyen, and Julyan Arbel,
  \emph{Sub-{W}eibull distributions: {G}eneralizing sub-{G}aussian and
  sub-{E}xponential properties to heavier tailed distributions}, Stat
  \textbf{9} (2020), no.~1, e318.

\bibitem[Vid13]{vidyasagar2013learning}
Mathukumalli Vidyasagar, \emph{Learning and generalisation: {W}ith applications
  to neural networks}, Springer Science \& Business Media, 2013.

\bibitem[VK06]{vidyasagar2006learning}
Mathukumalli Vidyasagar and Rajeeva~L Karandikar, \emph{A learning theory
  approach to system identification and stochastic adaptive control},
  Probabilistic and randomized methods for design under uncertainty, Springer,
  2006, pp.~265--302.

\bibitem[WLT20]{wong2020}
Kam~Chung Wong, Zifan Li, and Ambuj Tewari, \emph{Lasso guarantees for
  $\beta$-mixing heavy-tailed time series}, Annals of Statistics \textbf{48}
  (2020), no.~2, 1124--1142.

\bibitem[WZLL20]{wang2020highdimensional}
Di~Wang, Yao Zheng, Heng Lian, and Guodong Li, \emph{High-dimensional vector
  autoregressive time series modeling via tensor decomposition}, 2020.

\bibitem[Yu94]{yu1994rates}
Bin Yu, \emph{Rates of convergence for empirical processes of stationary mixing
  sequences}, The Annals of Probability (1994), 94--116.

\bibitem[ZCY12]{zhang2012learning}
Yongquan Zhang, Feilong Cao, and Canwei Yan, \emph{Learning rates of
  least-square regularized regression with strongly mixing observation},
  International Journal of Machine Learning and Cybernetics \textbf{3} (2012),
  no.~4, 277--283.

\bibitem[ZZ18]{zhang2018ell_1}
Lijun Zhang and Zhi-Hua Zhou, \emph{$\ell_1$-regression with heavy-tailed
  distributions}, Proceedings of the 32nd International Conference on Neural
  Information Processing Systems, 2018, pp.~1084--1094.

\end{thebibliography}
