\begin{thebibliography}{10}

\bibitem{pmlr-v139-acar21a}
Durmus Alp~Emre Acar, Yue Zhao, Ruizhao Zhu, Ramon Matas, Matthew Mattina, Paul
  Whatmough, and Venkatesh Saligrama.
\newblock Debiasing model updates for improving personalized federated
  training.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning}, volume 139 of {\em Proceedings of Machine Learning Research},
  pages 21--31. PMLR, 18--24 Jul 2021.

\bibitem{bai2018proxquant}
Yu~Bai, Yu-Xiang Wang, and Edo Liberty.
\newblock Proxquant: Quantized neural networks via proximal operators.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{basu2019qsparse}
Debraj Basu, Deepesh Data, Can Karakus, and Suhas~N. Diggavi.
\newblock Qsparse-local-sgd: Distributed {SGD} with quantization,
  sparsification and local computations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  14668--14679, 2019.

\bibitem{Bolte13}
J{\'{e}}r{\^{o}}me Bolte, Shoham Sabach, and Marc Teboulle.
\newblock Proximal alternating linearized minimization for nonconvex and
  nonsmooth problems.
\newblock {\em Math. Program.}, 146(1-2):459--494, 2014.

\bibitem{caldas2018leaf}
Sebastian Caldas, Sai Meher~Karthik Duddu, Peter Wu, Tian Li, Jakub
  Kone{\v{c}}n{\`y}, H~Brendan McMahan, Virginia Smith, and Ameet Talwalkar.
\newblock Leaf: A benchmark for federated settings.
\newblock {\em arXiv preprint arXiv:1812.01097}, 2018.

\bibitem{dbouk2020dbq}
Hassan Dbouk, Hetul Sanghvi, Mahesh Mehendale, and Naresh Shanbhag.
\newblock Dbq: A differentiable branch quantizer for lightweight deep neural
  networks.
\newblock In {\em European Conference on Computer Vision}, pages 90--106.
  Springer, 2020.

\bibitem{deng2020adaptive}
Yuyang Deng, Mohammad~Mahdi Kamani, and Mehrdad Mahdavi.
\newblock Adaptive personalized federated learning.
\newblock {\em arXiv preprint arXiv:2003.13461}, 2020.

\bibitem{dinh2020personalized}
Canh~T. Dinh, Nguyen~H. Tran, and Tuan~Dung Nguyen.
\newblock Personalized federated learning with moreau envelopes.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{fallah2020personalized}
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
\newblock Personalized federated learning: A meta-learning approach.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{ghosh2020efficient}
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran.
\newblock An efficient framework for clustered federated learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{gong2019differentiable}
Ruihao Gong, Xianglong Liu, Shenghu Jiang, Tianxiang Li, Peng Hu, Jiazhen Lin,
  Fengwei Yu, and Junjie Yan.
\newblock Differentiable soft quantization: Bridging full-precision and low-bit
  neural networks.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4852--4861, 2019.

\bibitem{han2016deep}
Song Han, Huizi Mao, and William~J. Dally.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding, 2016.

\bibitem{hanzely2020lower}
Filip Hanzely, Slavomír Hanzely, Samuel Horváth, and Peter Richtárik.
\newblock Lower bounds and optimal algorithms for personalized federated
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{hanzely2020federated}
Filip Hanzely and Peter Richtárik.
\newblock Federated learning of a mixture of global and local models.
\newblock {\em arXiv preprint arXiv:2002.05516}, 2020.

\bibitem{he2015deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2015.

\bibitem{hou2017loss}
Lu~Hou, Quanming Yao, and James~T. Kwok.
\newblock Loss-aware binarization of deep networks.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{karimireddy2019error}
Sai~Praneeth Karimireddy, Quentin Rebjock, Sebastian Stich, and Martin Jaggi.
\newblock Error feedback fixes signsgd and other gradient compression schemes.
\newblock In {\em International Conference on Machine Learning}, pages
  3252--3261. PMLR, 2019.

\bibitem{cifar10}
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock 2009.

\bibitem{leng2018extremely}
Cong Leng, Zesheng Dou, Hao Li, Shenghuo Zhu, and Rong Jin.
\newblock Extremely low bit neural network: Squeeze the last bit out with admm.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{li2019fedmd}
Daliang Li and Junpu Wang.
\newblock Fedmd: Heterogenous federated learning via model distillation.
\newblock {\em arXiv preprint arXiv:1910.03581}, 2019.

\bibitem{li2017training}
Hao Li, Soham De, Zheng Xu, Christoph Studer, Hanan Samet, and Tom Goldstein.
\newblock Training quantized nets: A deeper understanding.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5811--5821, 2017.

\bibitem{li2020federated}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock In {\em Proceedings of Machine Learning and Systems 2020, MLSys},
  2020.

\bibitem{lin2020ensemble}
Tao Lin, Lingjing Kong, Sebastian~U. Stich, and Martin Jaggi.
\newblock Ensemble distillation for robust model fusion in federated learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{louizos2018relaxed}
Christos Louizos, Matthias Reisser, Tijmen Blankevoort, Efstratios Gavves, and
  Max Welling.
\newblock Relaxed quantization for discretized neural networks.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{mansour2020approaches}
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda~Theertha Suresh.
\newblock Three approaches for personalization with applications to federated
  learning.
\newblock {\em arXiv preprint arXiv:2002.10619}, 2020.

\bibitem{mcmahan2017communicationefficient}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise~Aguera
  y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em Artificial Intelligence and Statistics}, pages 1273--1282.
  PMLR, 2017.

\bibitem{ozkara2021qupel}
Kaan Ozkara, Navjot Singh, Deepesh Data, and Suhas Diggavi.
\newblock Qupel: Quantized personalization with applications to federated
  learning.
\newblock {\em arXiv preprint arXiv:2102.11786}, 2021.

\bibitem{polino2018model}
Antonio Polino, Razvan Pascanu, and Dan Alistarh.
\newblock Model compression via distillation and quantization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{Bin_survey}
Haotong Qin, Ruihao Gong, Xianglong Liu, Xiao Bai, Jingkuan Song, and Nicu
  Sebe.
\newblock Binary neural networks: A survey.
\newblock {\em Pattern Recognition}, 105:107281, Sep 2020.

\bibitem{shen2020federated}
Tao Shen, Jie Zhang, Xinkang Jia, Fengda Zhang, Gang Huang, Pan Zhou, Kun
  Kuang, Fei Wu, and Chao Wu.
\newblock Federated mutual learning.
\newblock {\em arXiv preprint arXiv:2006.16765}, 2020.

\bibitem{smith2017federated}
Virginia Smith, Chao{-}Kai Chiang, Maziar Sanjabi, and Ameet~S. Talwalkar.
\newblock Federated multi-task learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4424--4434, 2017.

\bibitem{Yang_2019_CVPR}
Jiwei Yang, Xu~Shen, Jun Xing, Xinmei Tian, Houqiang Li, Bing Deng, Jianqiang
  Huang, and Xian-sheng Hua.
\newblock Quantization networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem{BinaryRelax}
Penghang Yin, Shuai Zhang, Jiancheng Lyu, Stanley~J. Osher, Yingyong Qi, and
  Jack Xin.
\newblock Binaryrelax: {A} relaxation approach for training deep neural
  networks with quantized weights.
\newblock {\em {SIAM} J. Imaging Sci.}, 11(4):2205--2223, 2018.

\bibitem{zhang2021personalized}
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose~M. Alvarez.
\newblock Personalized federated learning with first order model optimization.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{zhang2018deep}
Ying Zhang, Tao Xiang, Timothy~M Hospedales, and Huchuan Lu.
\newblock Deep mutual learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4320--4328, 2018.

\end{thebibliography}
