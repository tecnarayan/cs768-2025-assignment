\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam \& Sastry(2017)Achiam and Sastry]{josh_surprise}
Achiam, J. and Sastry, S.
\newblock Surprise-based intrinsic motivation for deep reinforcement learning.
\newblock \emph{arXiv:1703.01732}, 2017.

\bibitem[Amos et~al.(2018)Amos, Dinh, Cabi, Rothörl, Muldal, Erez, Tassa,
  de~Freitas, and Denil]{amos2018awareness}
Amos, B., Dinh, L., Cabi, S., Rothörl, T., Muldal, A., Erez, T., Tassa, Y.,
  de~Freitas, N., and Denil, M.
\newblock Learning awareness models.
\newblock In \emph{ICLR}, 2018.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{andrychowicz2017hindsight}
Andrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong, R., Welinder, P.,
  McGrew, B., Tobin, J., Abbeel, P., and Zaremba, W.
\newblock Hindsight experience replay.
\newblock In \emph{NIPS}, 2017.

\bibitem[Ball et~al.(2020)Ball, Parker-Holder, Pacchiano, Choromanski, and
  Roberts]{ball2020ready}
Ball, P., Parker-Holder, J., Pacchiano, A., Choromanski, K., and Roberts, S.
\newblock Ready policy one: World building through active learning.
\newblock \emph{arXiv preprint arXiv:2002.02693}, 2020.

\bibitem[Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos]{bellemare2016unifying}
Bellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., and
  Munos, R.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{NIPS}, 2016.

\bibitem[Breiman(1996)]{breiman1996bagging}
Breiman, L.
\newblock Bagging predictors.
\newblock \emph{Machine learning}, 24\penalty0 (2):\penalty0 123--140, 1996.

\bibitem[Buesing et~al.(2018)Buesing, Weber, Racaniere, Eslami, Rezende,
  Reichert, Viola, Besse, Gregor, Hassabis, et~al.]{buesing2018learning}
Buesing, L., Weber, T., Racaniere, S., Eslami, S., Rezende, D., Reichert,
  D.~P., Viola, F., Besse, F., Gregor, K., Hassabis, D., et~al.
\newblock Learning and querying fast generative models for reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1802.03006}, 2018.

\bibitem[Burda et~al.(2018)Burda, Edwards, Storkey, and Klimov]{burda2018rnd}
Burda, Y., Edwards, H., Storkey, A., and Klimov, O.
\newblock Exploration by random network distillation.
\newblock \emph{arXiv preprint arXiv:1810.12894}, 2018.

\bibitem[Burda et~al.(2019)Burda, Edwards, Pathak, Storkey, Darrell, and
  Efros]{burda2018large}
Burda, Y., Edwards, H., Pathak, D., Storkey, A., Darrell, T., and Efros, A.~A.
\newblock Large-scale study of curiosity-driven learning.
\newblock \emph{ICLR}, 2019.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{chua2018deep}
Chua, K., Calandra, R., McAllister, R., and Levine, S.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock \emph{arXiv preprint arXiv:1805.12114}, 2018.

\bibitem[Deisenroth \& Rasmussen(2011)Deisenroth and
  Rasmussen]{deisenroth2011pilco}
Deisenroth, M. and Rasmussen, C.~E.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In \emph{ICML}, 2011.

\bibitem[Duff \& Barto(2002)Duff and Barto]{duff2002optimal}
Duff, M.~O. and Barto, A.
\newblock \emph{Optimal Learning: Computational procedures for Bayes-adaptive
  Markov decision processes}.
\newblock PhD thesis, University of Massachusetts at Amherst, 2002.

\bibitem[Ebert et~al.(2018)Ebert, Finn, Dasari, Xie, Lee, and
  Levine]{ebert2018visual}
Ebert, F., Finn, C., Dasari, S., Xie, A., Lee, A., and Levine, S.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock \emph{arXiv:1812.00568}, 2018.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and
  Levine]{eysenbach2018diversity}
Eysenbach, B., Gupta, A., Ibarz, J., and Levine, S.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock \emph{arXiv:1802.06070}, 2018.

\bibitem[Gal(2016)]{gal2016uncertainty}
Gal, Y.
\newblock Uncertainty in deep learning.
\newblock \emph{University of Cambridge}, 1:\penalty0 3, 2016.

\bibitem[Ha \& Schmidhuber(2018)Ha and Schmidhuber]{ha2018world}
Ha, D. and Schmidhuber, J.
\newblock World models.
\newblock \emph{arXiv preprint arXiv:1803.10122}, 2018.

\bibitem[Haber et~al.(2018)Haber, Mrowca, Wang, Fei-Fei, and
  Yamins]{haber2018learning}
Haber, N., Mrowca, D., Wang, S., Fei-Fei, L.~F., and Yamins, D.~L.
\newblock Learning to play with intrinsically-motivated, self-aware agents.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner2018planet}
Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and
  Davidson, J.
\newblock Learning latent dynamics for planning from pixels.
\newblock \emph{ICML}, 2019.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Ba, and
  Norouzi]{hafner2019dreamer}
Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock \emph{ICLR}, 2020.

\bibitem[Henaff(2019)]{henaff2019explicit}
Henaff, M.
\newblock Explicit explore-exploit algorithms in continuous state spaces.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Jaksch et~al.(2010)Jaksch, Ortner, and Auer]{jaksch2010near}
Jaksch, T., Ortner, R., and Auer, P.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock \emph{JMLR}, 2010.

\bibitem[Kaelbling et~al.(1996)Kaelbling, Littman, and
  Moore]{kaelbling1996reinforcement}
Kaelbling, L.~P., Littman, M.~L., and Moore, A.~W.
\newblock Reinforcement learning: A survey.
\newblock \emph{Journal of artificial intelligence research}, 1996.

\bibitem[Kakade \& Langford(2002)Kakade and Langford]{kakade2002approximately}
Kakade, S. and Langford, J.
\newblock Approximately optimal approximate reinforcement learning.
\newblock In \emph{ICML}, volume~2, pp.\  267--274, 2002.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013vae}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Klyubin et~al.(2005)Klyubin, Polani, and
  Nehaniv]{klyubin2005empowerment}
Klyubin, A.~S., Polani, D., and Nehaniv, C.~L.
\newblock Empowerment: A universal agent-centric measure of control.
\newblock In \emph{Evolutionary Computation}, 2005.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{NIPS}, 2017.

\bibitem[Lehman \& Stanley(2011)Lehman and Stanley]{lehman2011evolving}
Lehman, J. and Stanley, K.~O.
\newblock Evolving a diversity of virtual creatures through novelty search and
  local competition.
\newblock In \emph{Proceedings of the 13th annual conference on Genetic and
  evolutionary computation}, 2011.

\bibitem[Levine \& Koltun(2013)Levine and Koltun]{levine2013guided}
Levine, S. and Koltun, V.
\newblock Guided policy search.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1--9,
  2013.

\bibitem[Lindley(1956)]{lindley1956expinfogain}
Lindley, D.~V.
\newblock On a measure of the information provided by an experiment.
\newblock \emph{The Annals of Mathematical Statistics}, pp.\  986--1005, 1956.

\bibitem[Lowrey et~al.(2018)Lowrey, Rajeswaran, Kakade, Todorov, and
  Mordatch]{lowrey2018plan}
Lowrey, K., Rajeswaran, A., Kakade, S., Todorov, E., and Mordatch, I.
\newblock Plan online, learn offline: Efficient learning and exploration via
  model-based control.
\newblock \emph{arXiv preprint arXiv:1811.01848}, 2018.

\bibitem[MacKay(1992)]{mackay1992infogain}
MacKay, D.~J.
\newblock Information-based objective functions for active data selection.
\newblock \emph{Neural computation}, 4\penalty0 (4):\penalty0 590--604, 1992.

\bibitem[McCallumzy \& Nigamy(1998)McCallumzy and
  Nigamy]{mccallumzy1998employing}
McCallumzy, A.~K. and Nigamy, K.
\newblock Employing em and pool-based active learning for text classification.
\newblock In \emph{ICML}, 1998.

\bibitem[Nagabandi et~al.(2019)Nagabandi, Konoglie, Levine, and
  Kumar]{nagabandi2019deep}
Nagabandi, A., Konoglie, K., Levine, S., and Kumar, V.
\newblock Deep dynamics models for learning dexterous manipulation.
\newblock \emph{arXiv preprint arXiv:1909.11652}, 2019.

\bibitem[Nair et~al.(2018)Nair, Pong, Dalal, Bahl, Lin, and
  Levine]{nair2018imagined}
Nair, A.~V., Pong, V., Dalal, M., Bahl, S., Lin, S., and Levine, S.
\newblock Visual reinforcement learning with imagined goals.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and
  Van~Roy]{osband2016deep}
Osband, I., Blundell, C., Pritzel, A., and Van~Roy, B.
\newblock Deep exploration via bootstrapped dqn.
\newblock In \emph{NIPS}, 2016.

\bibitem[Osband et~al.(2018)Osband, Aslanides, and
  Cassirer]{osband2018randomized}
Osband, I., Aslanides, J., and Cassirer, A.
\newblock Randomized prior functions for deep reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8617--8629, 2018.

\bibitem[Ostrovski et~al.(2018)Ostrovski, Bellemare, Oord, and
  Munos]{ostrovski2017count}
Ostrovski, G., Bellemare, M.~G., Oord, A. v.~d., and Munos, R.
\newblock Count-based exploration with neural density models.
\newblock \emph{ICML}, 2018.

\bibitem[Oudeyer \& Kaplan(2009)Oudeyer and Kaplan]{oudeyer2009intrinsic}
Oudeyer, P.-Y. and Kaplan, F.
\newblock What is intrinsic motivation? a typology of computational approaches.
\newblock \emph{Frontiers in neurorobotics}, 2009.

\bibitem[Oudeyer et~al.(2007)Oudeyer, Kaplan, and Hafner]{oudeyer2007intrinsic}
Oudeyer, P.-Y., Kaplan, F., and Hafner, V.~V.
\newblock Intrinsic motivation systems for autonomous mental development.
\newblock \emph{Evolutionary Computation}, 2007.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathakICMl17curiosity}
Pathak, D., Agrawal, P., Efros, A.~A., and Darrell, T.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{ICML}, 2017.

\bibitem[Pathak et~al.(2018)Pathak, Mahmoudieh, Luo, Agrawal, Chen, Shentu,
  Shelhamer, Malik, Efros, and Darrell]{pathak2018zero}
Pathak, D., Mahmoudieh, P., Luo, G., Agrawal, P., Chen, D., Shentu, Y.,
  Shelhamer, E., Malik, J., Efros, A.~A., and Darrell, T.
\newblock Zero-shot visual imitation.
\newblock In \emph{ICLR}, 2018.

\bibitem[Pathak et~al.(2019)Pathak, Gandhi, and Gupta]{pathak2019self}
Pathak, D., Gandhi, D., and Gupta, A.
\newblock Self-supervised exploration via disagreement.
\newblock \emph{ICML}, 2019.

\bibitem[Poupart et~al.(2006)Poupart, Vlassis, Hoey, and
  Regan]{poupart2006analytic}
Poupart, P., Vlassis, N., Hoey, J., and Regan, K.
\newblock An analytic solution to discrete bayesian reinforcement learning.
\newblock In \emph{ICML}, 2006.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and Wierstra]{rezende2014vae}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Schmidhuber(1991{\natexlab{a}})]{schmidhuber1991curious}
Schmidhuber, J.
\newblock Curious model-building control systems.
\newblock In \emph{Neural Networks, 1991. 1991 IEEE International Joint
  Conference on}, pp.\  1458--1463. IEEE, 1991{\natexlab{a}}.

\bibitem[Schmidhuber(1991{\natexlab{b}})]{schmidhuber1991possibility}
Schmidhuber, J.
\newblock A possibility for implementing curiosity and boredom in
  model-building neural controllers.
\newblock In \emph{From animals to animats: Proceedings of the first
  international conference on simulation of adaptive behavior},
  1991{\natexlab{b}}.

\bibitem[Seung et~al.(1992)Seung, Opper, and Sompolinsky]{Seung1992}
Seung, H., Opper, M., and Sompolinsky, H.
\newblock Query by committee.
\newblock \emph{COLT}, 1992.

\bibitem[Sharma et~al.(2019)Sharma, Gu, Levine, Kumar, and
  Hausman]{sharma2019dynamics}
Sharma, A., Gu, S., Levine, S., Kumar, V., and Hausman, K.
\newblock Dynamics-aware unsupervised discovery of skills.
\newblock \emph{arXiv preprint arXiv:1907.01657}, 2019.

\bibitem[Shyam et~al.(2019)Shyam, Ja\'{s}kowski, and Gomez]{shyam2019max}
Shyam, P., Ja\'{s}kowski, W., and Gomez, F.
\newblock {Model-Based Active Exploration}.
\newblock In \emph{ICML}, 2019.

\bibitem[Strehl \& Littman(2008)Strehl and Littman]{strehl08}
Strehl, A. and Littman, M.
\newblock An analysis of model-based interval estimation for markov decision
  processes.
\newblock \emph{Journal of Computer and System Sciences}, 2008.

\bibitem[Sun et~al.(2011)Sun, Gomez, and Schmidhuber]{sun2011planning}
Sun, Y., Gomez, F., and Schmidhuber, J.
\newblock Planning to be surprised: Optimal bayesian exploration in dynamic
  environments.
\newblock In \emph{AGI}, 2011.

\bibitem[Sutton(1991)]{sutton1991dyna}
Sutton, R.~S.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock \emph{ACM SIGART Bulletin}, 2\penalty0 (4):\penalty0 160--163, 1991.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, de~Las~Casas,
  Budden, Abdolmaleki, Merel, Lefrancq, Lillicrap, and
  Riedmiller]{deepmindcontrolsuite2018}
Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., de~Las~Casas, D., Budden,
  D., Abdolmaleki, A., Merel, J., Lefrancq, A., Lillicrap, T., and Riedmiller,
  M.
\newblock Deep{Mind} control suite.
\newblock Technical report, DeepMind, January 2018.
\newblock URL \url{https://arxiv.org/abs/1801.00690}.

\bibitem[Watter et~al.(2015)Watter, Springenberg, Boedecker, and
  Riedmiller]{watter2015embed}
Watter, M., Springenberg, J., Boedecker, J., and Riedmiller, M.
\newblock Embed to control: A locally linear latent dynamics model for control
  from raw images.
\newblock In \emph{NIPS}, 2015.

\bibitem[Zhang et~al.(2019)Zhang, Vikram, Smith, Abbeel, Johnson, and
  Levine]{zhang2018solar}
Zhang, M., Vikram, S., Smith, L., Abbeel, P., Johnson, M., and Levine, S.
\newblock Solar: deep structured representations for model-based reinforcement
  learning.
\newblock In \emph{ICML}, 2019.

\end{thebibliography}
