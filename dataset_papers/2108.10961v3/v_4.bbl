\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Altschuler et~al.(2017)Altschuler, Niles-Weed, and
  Rigollet]{altschuler2017near}
J.~Altschuler, J.~Niles-Weed, and P.~Rigollet.
\newblock Near-linear time approximation algorithms for optimal transport via
  {S}inkhorn iteration.
\newblock In \emph{Advances in neural information processing systems}, pages
  1964--1974, 2017.

\bibitem[Alvarez-Melis and Jaakkola(2018)]{Alvarez-2018-Gromov}
D.~Alvarez-Melis and T.~Jaakkola.
\newblock Gromov-{W}asserstein alignment of word embedding spaces.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1881--1890, 2018.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala, and L.~Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  214--223, 2017.

\bibitem[Bonneel et~al.(2015)Bonneel, Rabin, Peyr{\'e}, and
  Pfister]{bonneel2015sliced}
N.~Bonneel, J.~Rabin, G.~Peyr{\'e}, and H.~Pfister.
\newblock Sliced and {R}adon {W}asserstein barycenters of measures.
\newblock \emph{Journal of Mathematical Imaging and Vision}, 1\penalty0
  (51):\penalty0 22--45, 2015.

\bibitem[Bunne et~al.(2019)Bunne, Alvarez-Melis, Krause, and
  Jegelka]{bunne2019learning}
C.~Bunne, D.~Alvarez-Melis, A.~Krause, and S.~Jegelka.
\newblock Learning generative models across incomparable spaces.
\newblock In \emph{International Conference on Machine Learning}, pages
  851--861, 2019.

\bibitem[Chen et~al.(2020)Chen, Gan, Cheng, Li, Carin, and Liu]{chen2020graph}
L.~Chen, Z.~Gan, Y.~Cheng, L.~Li, L.~Carin, and J.~Liu.
\newblock Graph optimal transport for cross-domain alignment.
\newblock In \emph{International Conference on Machine Learning}, pages
  1542--1553. PMLR, 2020.

\bibitem[Chizat et~al.(2018)Chizat, Peyr{\'e}, Schmitzer, and
  Vialard]{chizat2018scaling}
L.~Chizat, G.~Peyr{\'e}, B.~Schmitzer, and F.-X. Vialard.
\newblock Scaling algorithms for unbalanced optimal transport problems.
\newblock \emph{Mathematics of Computation}, 87\penalty0 (314):\penalty0
  2563--2609, 2018.

\bibitem[Courty et~al.(2016)Courty, Flamary, Tuia, and
  Rakotomamonjy]{courty2016optimal}
N.~Courty, R.~Flamary, D.~Tuia, and A.~Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 39\penalty0 (9):\penalty0 1853--1865, 2016.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
M.~Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In \emph{Advances in neural information processing systems}, pages
  2292--2300, 2013.

\bibitem[Damodaran et~al.(2018)Damodaran, Kellenberger, Flamary, Tuia, and
  Courty]{damodaran2018deepjdot}
B.~B. Damodaran, B.~Kellenberger, R.~Flamary, D.~Tuia, and N.~Courty.
\newblock Deepjdot: Deep joint distribution optimal transport for unsupervised
  domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 447--463, 2018.

\bibitem[Deshpande et~al.(2019)Deshpande, Hu, Sun, Pyrros, Siddiqui, Koyejo,
  Zhao, Forsyth, and Schwing]{deshpande2019max}
I.~Deshpande, Y.-T. Hu, R.~Sun, A.~Pyrros, N.~Siddiqui, S.~Koyejo, Z.~Zhao,
  D.~Forsyth, and A.~G. Schwing.
\newblock Max-sliced {W}asserstein distance and its use for {GAN}s.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 10648--10656, 2019.

\bibitem[Dvurechensky et~al.(2018)Dvurechensky, Gasnikov, and
  Kroshnin]{Dvurechensky-2018-Computational}
P.~Dvurechensky, A.~Gasnikov, and A.~Kroshnin.
\newblock Computational optimal transport: {C}omplexity by accelerated gradient
  descent is better than by {S}inkhorn’s algorithm.
\newblock In \emph{ICML}, pages 1367--1376, 2018.

\bibitem[Fatras et~al.(2020)Fatras, Zine, Flamary, Gribonval, and
  Courty]{fatras2020learning}
K.~Fatras, Y.~Zine, R.~Flamary, R.~Gribonval, and N.~Courty.
\newblock Learning with minibatch {W}asserstein: asymptotic and gradient
  properties.
\newblock In \emph{AISTATS 2020-23nd International Conference on Artificial
  Intelligence and Statistics}, volume 108, pages 1--20, 2020.

\bibitem[Flamary and Courty(2017)]{flamary2017pot}
R.~Flamary and N.~Courty.
\newblock Pot python optimal transport library, 2017.
\newblock URL \url{https://pythonot.github.io/}.

\bibitem[Gelbrich(1990)]{Gelbrich1990}
M.~Gelbrich.
\newblock On a formula for the {L}2 wasserstein metric between measures on
  euclidean and hilbert spaces.
\newblock \emph{Mathematische Nachrichten}, 147:\penalty0 185--203, 1990.

\bibitem[Genevay et~al.(2018)Genevay, Peyre, and Cuturi]{genevay2018learning}
A.~Genevay, G.~Peyre, and M.~Cuturi.
\newblock Learning generative models with {S}inkhorn divergences.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1608--1617, 2018.

\bibitem[Grave et~al.(2019)Grave, Joulin, and Berthet]{grave2019unsupervised}
E.~Grave, A.~Joulin, and Q.~Berthet.
\newblock Unsupervised alignment of embeddings with {W}asserstein procrustes.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, pages 1880--1890, 2019.

\bibitem[Ho et~al.(2017)Ho, Nguyen, Yurochkin, Bui, Huynh, and
  Phung]{ho2017multilevel}
N.~Ho, X.~Nguyen, M.~Yurochkin, H.~H. Bui, V.~Huynh, and D.~Phung.
\newblock Multilevel clustering via {W}asserstein means.
\newblock In \emph{International Conference on Machine Learning}, pages
  1501--1509, 2017.

\bibitem[Ho et~al.(2019)Ho, Huynh, Phung, and Jordan]{Ho_Probabilistic}
N.~Ho, V.~Huynh, D.~Phung, and M.~I. Jordan.
\newblock Probabilistic multilevel clustering via composite transportation
  distance.
\newblock In \emph{AISTATS}, 2019.

\bibitem[Horn and Johnson(1991)]{horn_johnson_1991}
R.~A. Horn and C.~R. Johnson.
\newblock \emph{Topics in Matrix Analysis}.
\newblock Cambridge University Press, 1991.
\newblock \doi{10.1017/CBO9780511840371}.

\bibitem[Janati et~al.(2020)Janati, Muzellec, Peyr\'{e}, and
  Cuturi]{janati2020entropic}
H.~Janati, B.~Muzellec, G.~Peyr\'{e}, and M.~Cuturi.
\newblock Entropic optimal transport between unbalanced gaussian measures has a
  closed form.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 10468--10479, 2020.

\bibitem[Kolouri et~al.(2016)Kolouri, Zou, and Rohde]{kolouri2016sliced}
S.~Kolouri, Y.~Zou, and G.~K. Rohde.
\newblock Sliced {W}asserstein kernels for probability distributions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5258--5267, 2016.

\bibitem[Kristof(1969)]{kristof1969neumann}
W.~Kristof.
\newblock Generalization of a theorem by {J}ohn von {N}eumann on the trace of
  certain matrix products.
\newblock \emph{ETS Research Bulletin Series}, 1969:\penalty0 i--13, 12 1969.
\newblock \doi{10.1002/j.2333-8504.1969.tb00744.x}.

\bibitem[Le et~al.(2021)Le, Nguyen, Ho, Bui, and Phung]{ho2021lamda}
T.~Le, T.~Nguyen, N.~Ho, H.~Bui, and D.~Phung.
\newblock {LAMDA}: {L}abel matching deep domain adaptation.
\newblock In \emph{ICML}, 2021.

\bibitem[Lin et~al.(2019)Lin, Ho, and Jordan]{lin2019efficient}
T.~Lin, N.~Ho, and M.~Jordan.
\newblock On efficient optimal transport: An analysis of greedy and accelerated
  mirror descent algorithms.
\newblock In \emph{International Conference on Machine Learning}, pages
  3982--3991, 2019.

\bibitem[Liutkus et~al.(2019)Liutkus, Simsekli, Majewski, Durmus, and
  St{\"o}ter]{liutkus2019sliced}
A.~Liutkus, U.~Simsekli, S.~Majewski, A.~Durmus, and F.-R. St{\"o}ter.
\newblock Sliced-{W}asserstein flows: Nonparametric generative modeling via
  optimal transport and diffusions.
\newblock In \emph{International Conference on Machine Learning}, pages
  4104--4113. PMLR, 2019.

\bibitem[Nguyen et~al.(2021{\natexlab{a}})Nguyen, Ho, Pham, and
  Bui]{nguyen2021distributional}
K.~Nguyen, N.~Ho, T.~Pham, and H.~Bui.
\newblock Distributional sliced-{W}asserstein and applications to generative
  modeling.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Nguyen et~al.(2021{\natexlab{b}})Nguyen, Nguyen, Nguyen, Pham, Bui,
  Phung, Le, and Ho]{Nguyen_bomb}
K.~Nguyen, D.~Nguyen, Q.~Nguyen, T.~Pham, H.~Bui, D.~Phung, T.~Le, and N.~Ho.
\newblock On transportation of mini-batches: A hierarchical approach.
\newblock \emph{arXiv preprint arXiv:2102.05912}, 2021{\natexlab{b}}.

\bibitem[Nguyen et~al.(2021{\natexlab{c}})Nguyen, Pham, Le, Pham, Ho, and
  Hua]{Nguyen_3D}
T.~Nguyen, Q.-H. Pham, T.~Le, T.~Pham, N.~Ho, and B.-S. Hua.
\newblock Point-set distances for learning representations of {3D} point
  clouds.
\newblock In \emph{ICCV}, 2021{\natexlab{c}}.

\bibitem[Peyr{\'e} et~al.(2016)Peyr{\'e}, Cuturi, and Solomon]{peyre2016gromov}
G.~Peyr{\'e}, M.~Cuturi, and J.~Solomon.
\newblock Gromov-{W}asserstein averaging of kernel and distance matrices.
\newblock In \emph{International Conference on Machine Learning}, pages
  2664--2672, 2016.

\bibitem[Salimans et~al.(2018)Salimans, Zhang, Radford, and
  Metaxas]{salimans2018improving}
T.~Salimans, H.~Zhang, A.~Radford, and D.~Metaxas.
\newblock Improving {GAN}s using optimal transport.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Salmona et~al.(2021)Salmona, Delon, and Desolneux]{Salmona2021gromov}
A.~Salmona, J.~Delon, and A.~Desolneux.
\newblock Gromov-{W}asserstein distances between {G}aussian distributions.
\newblock \emph{Arxiv Preprint Arxiv: 2104.07970}, 2021.

\bibitem[S\'{e}journ\'{e} et~al.(2020)S\'{e}journ\'{e}, Vialard, and
  Peyr\'{e}]{Peyreunbalanced}
T.~S\'{e}journ\'{e}, F.-X. Vialard, and G.~Peyr\'{e}.
\newblock The unbalanced {G}romov {W}asserstein distance: {C}onic formulation
  and relaxation.
\newblock \emph{Arxiv Preprint Arxiv: 2009.04266}, 2020.

\bibitem[Solomon et~al.(2016)Solomon, Peyr{\'e}, Kim, and
  Sra]{solomon2016entropic}
J.~Solomon, G.~Peyr{\'e}, V.~G. Kim, and S.~Sra.
\newblock Entropic metric alignment for correspondence problems.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 35\penalty0 (4):\penalty0
  72, 2016.

\bibitem[Séjourné et~al.(2021)Séjourné, Vialard, and
  Peyré]{sejourne2021unbalanced}
T.~Séjourné, F.-X. Vialard, and G.~Peyré.
\newblock The unbalanced gromov wasserstein distance: Conic formulation and
  relaxation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Tolstikhin et~al.(2018)Tolstikhin, Bousquet, Gelly, and
  Schoelkopf]{tolstikhin2018wasserstein}
I.~Tolstikhin, O.~Bousquet, S.~Gelly, and B.~Schoelkopf.
\newblock Wasserstein auto-encoders.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Vayer(2020)]{vayer2020contribution}
T.~Vayer.
\newblock A contribution to optimal transport on incomparable spaces, 2020.

\bibitem[Vincent-Cuaz et~al.(2022)Vincent-Cuaz, Flamary, Corneli, Vayer, and
  Courty]{vincentcuaz2022semirelaxed}
C.~Vincent-Cuaz, R.~Flamary, M.~Corneli, T.~Vayer, and N.~Courty.
\newblock Semi-relaxed gromov-wasserstein divergence with applications on
  graphs, 2022.

\bibitem[Xu et~al.(2019)Xu, Luo, and Carin]{xu2019scalable}
H.~Xu, D.~Luo, and L.~Carin.
\newblock Scalable {G}romov-{W}asserstein learning for graph partitioning and
  matching.
\newblock In \emph{Advances in neural information processing systems}, pages
  3052--3062, 2019.

\end{thebibliography}
