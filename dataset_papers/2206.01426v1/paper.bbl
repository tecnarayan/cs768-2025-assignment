\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori and Szepesv{\'a}ri(2011)]{abbasi2011regret}
Y.~Abbasi-Yadkori and C.~Szepesv{\'a}ri.
\newblock Regret bounds for the adaptive control of linear quadratic systems.
\newblock In \emph{Proceedings of the 24th Annual Conference on Learning
  Theory}, pages 1--26, 2011.

\bibitem[Abbasi-Yadkori et~al.(2019)Abbasi-Yadkori, Lazic, and
  Szepesv{\'a}ri]{abbasi2019model}
Y.~Abbasi-Yadkori, N.~Lazic, and C.~Szepesv{\'a}ri.
\newblock Model-free linear quadratic control via reduction to expert
  prediction.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3108--3117. PMLR, 2019.

\bibitem[Abeille and Lazaric(2018)]{abeille2018improved}
M.~Abeille and A.~Lazaric.
\newblock Improved regret bounds for thompson sampling in linear quadratic
  control problems.
\newblock In \emph{International Conference on Machine Learning}, pages 1--9.
  PMLR, 2018.

\bibitem[Agarwal et~al.(2011)Agarwal, Foster, Hsu, Kakade, and
  Rakhlin]{agarwal2011stochastic}
A.~Agarwal, D.~P. Foster, D.~J. Hsu, S.~M. Kakade, and A.~Rakhlin.
\newblock Stochastic convex optimization with bandit feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 24, 2011.

\bibitem[Agarwal et~al.(2019{\natexlab{a}})Agarwal, Bullins, Hazan, Kakade, and
  Singh]{agarwal2019online}
N.~Agarwal, B.~Bullins, E.~Hazan, S.~Kakade, and K.~Singh.
\newblock Online control with adversarial disturbances.
\newblock In \emph{International Conference on Machine Learning}, pages
  111--119. PMLR, 2019{\natexlab{a}}.

\bibitem[Agarwal et~al.(2019{\natexlab{b}})Agarwal, Hazan, and
  Singh]{agarwal2019logarithmic}
N.~Agarwal, E.~Hazan, and K.~Singh.
\newblock Logarithmic regret for online control.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10175--10184, 2019{\natexlab{b}}.

\bibitem[Altschuler and Talwar(2018)]{altschuler2018online}
J.~Altschuler and K.~Talwar.
\newblock Online learning over a finite action set with limited switching.
\newblock In \emph{Conference On Learning Theory}, pages 1569--1573. PMLR,
  2018.

\bibitem[Arora et~al.(2012)Arora, Hazan, and Kale]{arora2012multiplicative}
S.~Arora, E.~Hazan, and S.~Kale.
\newblock The multiplicative weights update method: a meta-algorithm and
  applications.
\newblock \emph{Theory of computing}, 8\penalty0 (1):\penalty0 121--164, 2012.

\bibitem[Arora et~al.(2018)Arora, Hazan, Lee, Singh, Zhang, and
  Zhang]{arora2018towards}
S.~Arora, E.~Hazan, H.~Lee, K.~Singh, C.~Zhang, and Y.~Zhang.
\newblock Towards provable control for unknown linear dynamical systems.
\newblock 2018.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{auer2002finite}
P.~Auer, N.~Cesa-Bianchi, and P.~Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2):\penalty0 235--256, 2002.

\bibitem[Auer et~al.(2008)Auer, Jaksch, and Ortner]{auer2008near}
P.~Auer, T.~Jaksch, and R.~Ortner.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock \emph{Advances in neural information processing systems}, 21, 2008.

\bibitem[Bertsekas(1995)]{bertsekas1995dynamic}
D.~P. Bertsekas.
\newblock \emph{Dynamic programming and optimal control}, volume~1.
\newblock Athena scientific Belmont, MA, 1995.

\bibitem[Cassel and Koren(2020)]{cassel2020bandit}
A.~Cassel and T.~Koren.
\newblock Bandit linear control.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Cassel et~al.(2020)Cassel, Cohen, and Koren]{cassel2020logarithmic}
A.~Cassel, A.~Cohen, and T.~Koren.
\newblock Logarithmic regret for learning linear quadratic regulators
  efficiently.
\newblock In \emph{International Conference on Machine Learning}, pages
  1328--1337. PMLR, 2020.

\bibitem[Cassel et~al.(2022)Cassel, Cohen, and Koren]{cassel2022efficient}
A.~Cassel, A.~Cohen, and T.~Koren.
\newblock Efficient online linear control with stochastic convex costs and
  unknown dynamics.
\newblock \emph{arXiv preprint arXiv:2203.01170}, 2022.

\bibitem[Cassel and Koren(2021)]{cassel2021online}
A.~B. Cassel and T.~Koren.
\newblock Online policy gradient for model free learning of linear quadratic
  regulators with $\sqrt{T}$ regret.
\newblock In \emph{International Conference on Machine Learning}, pages
  1304--1313. PMLR, 2021.

\bibitem[Chen and Hazan(2021)]{chen2021black}
X.~Chen and E.~Hazan.
\newblock Black-box control for linear dynamical systems.
\newblock In \emph{Conference on Learning Theory}, pages 1114--1143. PMLR,
  2021.

\bibitem[Chernov and Zhdanov(2010)]{chernov2010prediction}
A.~Chernov and F.~Zhdanov.
\newblock Prediction with expert advice under discounted loss.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pages 255--269. Springer, 2010.

\bibitem[Cohen et~al.(2018)Cohen, Hasidim, Koren, Lazic, Mansour, and
  Talwar]{cohen2018online}
A.~Cohen, A.~Hasidim, T.~Koren, N.~Lazic, Y.~Mansour, and K.~Talwar.
\newblock Online linear quadratic control.
\newblock In \emph{International Conference on Machine Learning}, pages
  1029--1038, 2018.

\bibitem[Cohen et~al.(2019)Cohen, Koren, and Mansour]{cohen2019learning}
A.~Cohen, T.~Koren, and Y.~Mansour.
\newblock Learning linear-quadratic regulators efficiently with only $\sqrt{T}$
  regret.
\newblock In \emph{International Conference on Machine Learning}, pages
  1300--1309, 2019.

\bibitem[Dani et~al.(2008)Dani, Hayes, and Kakade]{dani2008stochastic}
V.~Dani, T.~P. Hayes, and S.~M. Kakade.
\newblock Stochastic linear optimization under bandit feedback.
\newblock 2008.

\bibitem[Dean et~al.(2018)Dean, Mania, Matni, Recht, and Tu]{dean2018regret}
S.~Dean, H.~Mania, N.~Matni, B.~Recht, and S.~Tu.
\newblock Regret bounds for robust adaptive control of the linear quadratic
  regulator.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Faradonbeh et~al.(2017)Faradonbeh, Tewari, and
  Michailidis]{faradonbeh2017finite}
M.~K.~S. Faradonbeh, A.~Tewari, and G.~Michailidis.
\newblock Finite time analysis of optimal adaptive policies for
  linear-quadratic systems.
\newblock \emph{arXiv preprint arXiv:1711.07230}, 2017.

\bibitem[Fazel et~al.(2018)Fazel, Ge, Kakade, and Mesbahi]{fazel2018global}
M.~Fazel, R.~Ge, S.~Kakade, and M.~Mesbahi.
\newblock Global convergence of policy gradient methods for the linear
  quadratic regulator.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80, 2018.

\bibitem[Gradu et~al.(2020)Gradu, Hallman, and Hazan]{gradu2020non}
P.~Gradu, J.~Hallman, and E.~Hazan.
\newblock Non-stochastic control with bandit feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 10764--10774, 2020.

\bibitem[Ibrahimi et~al.(2012)Ibrahimi, Javanmard, and
  Roy]{ibrahimi2012efficient}
M.~Ibrahimi, A.~Javanmard, and B.~Roy.
\newblock Efficient reinforcement learning for high dimensional linear
  quadratic systems.
\newblock \emph{Advances in Neural Information Processing Systems}, 25, 2012.

\bibitem[Kalai and Vempala(2005)]{kalai2005efficient}
A.~Kalai and S.~Vempala.
\newblock Efficient algorithms for online decision problems.
\newblock \emph{Journal of Computer and System Sciences}, 71\penalty0
  (3):\penalty0 291--307, 2005.

\bibitem[Lale et~al.(2020)Lale, Azizzadenesheli, Hassibi, and
  Anandkumar]{lale2020logarithmic}
S.~Lale, K.~Azizzadenesheli, B.~Hassibi, and A.~Anandkumar.
\newblock Logarithmic regret bound in partially observable linear dynamical
  systems.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 20876--20888, 2020.

\bibitem[Malik et~al.(2020)Malik, Pananjady, Bhatia, Khamaru, Bartlett, and
  Wainwright]{malik2019derivative}
D.~Malik, A.~Pananjady, K.~Bhatia, K.~Khamaru, P.~L. Bartlett, and M.~J.
  Wainwright.
\newblock Derivative-free methods for policy optimization: Guarantees for
  linear quadratic systems.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (21):\penalty0 1--51, 2020.

\bibitem[Mania et~al.(2019)Mania, Tu, and Recht]{mania2019certainty}
H.~Mania, S.~Tu, and B.~Recht.
\newblock Certainty equivalence is efficient for linear quadratic control.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pages 10154--10164, 2019.

\bibitem[Ouyang et~al.(2017)Ouyang, Gagrani, and Jain]{ouyang2017control}
Y.~Ouyang, M.~Gagrani, and R.~Jain.
\newblock Control of unknown linear systems with thompson sampling.
\newblock In \emph{2017 55th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pages 1198--1205. IEEE, 2017.

\bibitem[Plevrakis and Hazan(2020)]{NEURIPS2020_565e8a41}
O.~Plevrakis and E.~Hazan.
\newblock Geometric exploration for online control.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 7637--7647. Curran Associates, Inc., 2020.

\bibitem[Rosenberg et~al.(2020)Rosenberg, Cohen, Mansour, and
  Kaplan]{rosenberg2020near}
A.~Rosenberg, A.~Cohen, Y.~Mansour, and H.~Kaplan.
\newblock Near-optimal regret bounds for stochastic shortest path.
\newblock In \emph{International Conference on Machine Learning}, pages
  8210--8219. PMLR, 2020.

\bibitem[Simchowitz and Foster(2020)]{simchowitz2020naive}
M.~Simchowitz and D.~Foster.
\newblock Naive exploration is optimal for online lqr.
\newblock In \emph{International Conference on Machine Learning}, pages
  8937--8948. PMLR, 2020.

\bibitem[Simchowitz et~al.(2020)Simchowitz, Singh, and
  Hazan]{simchowitz2020improper}
M.~Simchowitz, K.~Singh, and E.~Hazan.
\newblock Improper learning for non-stochastic control.
\newblock In \emph{Conference on Learning Theory}, pages 3320--3436. PMLR,
  2020.

\bibitem[Tu and Recht(2019)]{tu2019gap}
S.~Tu and B.~Recht.
\newblock The gap between model-based and model-free methods on the linear
  quadratic regulator: An asymptotic viewpoint.
\newblock In \emph{Conference on Learning Theory}, pages 3036--3083. PMLR,
  2019.

\bibitem[Zinkevich(2003)]{zinkevich2003online}
M.~Zinkevich.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{Proceedings of the 20th international conference on machine
  learning (icml-03)}, pages 928--936, 2003.

\end{thebibliography}
