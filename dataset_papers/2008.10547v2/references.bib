######################
# Jackknife references

@article{wright:1999:optimization,
  title={Numerical optimization},
  author={Wright, S. and Nocedal, J.},
  journal={Springer Science},
  volume={35},
  number={67-68},
  pages={7},
  year={1999}
}

@article{agarwal:2016:lissa,
  title={Second-order stochastic optimization in linear time},
  author={Agarwal, N. and Bullins, B. and Hazan, E.},
  journal={Journal of Machine Learning Research},
  year={2017}
}

@book{barbe:2012:weighted,
  title={The weighted bootstrap},
  author={Barbe, P. and Bertail, P.},
  volume={98},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{maclaurin:2015:autograd,
  title={Autograd: Effortless gradients in numpy},
  author="D. Maclaurin and D. Duvenaud and R.~P. Adams",
  booktitle={International Conference on Machine Learning 2015 AutoML Workshop},
  year={2015}
}

#arXiv:1502.05767
@article{baydin:2015:automatic,
  title={Automatic differentiation in machine learning: a survey},
  author={A. G. Baydin and B. A. Pearlmutter and A. A. Radul and J. M. Siskind},
  journal={arXiv Preprint},
  year={2015}
}

@article{cook:1986:assessment,
  title={Assessment of local influence},
  author={D. R. Cook},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={133--169},
  year={1986},
  publisher={JSTOR}
}

@book{amari:2007:geom,
  title={Methods of Information Geometry},
  author={S. Amari and H. Nagaoka},
  volume={191},
  year={2007},
  publisher={American Mathematical Society}
}

@book{shao:2012:jackknife,
  title={The Jackknife and Bootstrap},
  author={J. Shao and D. Tu},
  year={2012},
  publisher={Springer Series in Statistics}
}


@article{shao:1993:jackknifemestimator,
  title={Differentiability of statistical functionals and consistency of the jackknife},
  author={J. Shao},
  journal={The Annals of Statistics},
  pages={61--75},
  year={1993},
  publisher={JSTOR}
}

@techreport{jaeckel:1972:infinitesimal,
  title={The infinitesimal jackknife, Memorandum},
  author={L. Jaeckel},
  year={1972},
  institution={MM 72-1215-11, Bell Lab. Murray Hill, NJ}
}

@book{efron:1982:jackknife,
  title={The Jackknife, the Bootstrap, and Other Resampling Plans},
  author={B. Efron},
  volume={38},
  year={1982},
  publisher={Society for Industrial and Applied Mathematics}
}

@article{hampel:1974:influence,
  title={The influence curve and its role in robust estimation},
  author={F. R. Hampel},
  journal={Journal of the american statistical association},
  volume={69},
  number={346},
  pages={383--393},
  year={1974},
  publisher={Taylor \& Francis}
}

@incollection{huber:2011:robust,
  title={Robust statistics},
  author={P. J. Huber},
  booktitle={International Encyclopedia of Statistical Science},
  pages={1248--1251},
  year={2011},
  publisher={Springer}
}

@article{wu:1990:asymptotic,
  title={On the asymptotic properties of the jackknife histogram},
  author={C. Wu},
  journal={The Annals of Statistics},
  pages={1438--1452},
  year={1990},
  publisher={JSTOR}
}



#####################
# CV references
#####################

@article{geisser:1975:earlyCV,
 author = {S. Geisser},
 title = {The Predictive Sample Reuse Method with Applications},
 journal = {Journal of the American Statistical Association},
 year = {1975},
 volume = {70},
 month = jun,
 pages = {320--328},
 number = {350}
}

@article{stone:1974:earlyCV,
 author = {M. Stone},
 title = {Cross-Validatory Choice and Assessment of Statistical Predictions},
 journal = {Journal of the American Statistical Association},
 year = {1974},
 volume = {36},
 pages = {111--147},
 number = {2},
} 

@article{shao:1993:CVBadModelSelection,
 author = {J. Shao},
 title = {Linear Model Selection by Cross-Validation},
 journal = {Journal of the American Statistical Association},
 year = {1993},
 volume = {88},
 month = jun,
 pages = {486--494},
 number = {422}
}

@article{leng:2006:CVBadLassoSelection,
 author = {C. Leng and Y. Lin and G. Wahba},
 title = {A Note on the {L}asso and Related Procedures in Model Selection},
 journal = {Statistica Sinca},
 year = {2006},
 volume = {16},
 pages = {1273--1284},
}

@article{celisse:2014:cvForDensityEstimation,
	author = {A. Celisse},
	title = {Optimal cross-validation in density estimation with the L2-loss},
	year = {2014},
	journal = {Annals of Statistics},
	volume = {42},
	number = {5},
	pages = {1879--1910}
}

@article{friedman:2009:glmnetPaper,
	author = {J. Friedman and T. Hastie and R. Tibshirani},
	title = {Regularization paths for generalized linear models via coordinate descent},
	year = {2009},
	journal = {Journal of Statistical Software},
	volume = {33},
	number = {1},
	pages = {1--22}
}

@inproceedings{moustafa:2018:cvWorks,
        author = {K. T. Abou-Moustafa and C. Szepesv\'ari},
        title = {An exponential tail bound for {L}q stable learning rules. {A}pplication to k-folds cross-validation},
        booktitle = {ISAIM},
        year = {2018}
}        

@article{powers:2019:cvExample,
	author = {A. Powers and M. Pinto and O. Tang and J. Chen and C. Doberstein and W. Asaad},
	title = {Predicting mortality in traumatic intracranial hemorrhage},
	journal = {Journal of Neurosurgery},
	year = {2019},
	month = {To Appear}
}

@article{saeb:2017:cvExample,
	author = {S. Saeb and L. Lonini and A. Jayaraman and D. Mohr and K. Kording},
	title = {The need to approximate the use-case in clinical machine learning},
	journal = {GigaScience},
	year = {2017},
	volume = {6},
	number = {5}
}

@article{chandrasekaran:2011:cvExample,
	author = {S. Chandrasekaran and S. Ament and J. Eddy and S. Rodriguez-Zas and B. Schatz and N. Price and G. Robinson},
	title = {Behavior-specific changes in transcriptional modules lead to distinct and predictable neurogenomic states},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	year = {2011},
	volume = {108},
	number = {44}
}

@article{carrera:2009:cvExample,
	author = {J. Carrera and G. Rodrigo and A. Jaramillo},
	title = {Model-based redesign of global transcription regulation},
	journal = {Nucleic Acids Research},
	year = {2009},
	volume = {39},
	number = {5}
}

@article{joshi:2009:cvExample,
	author = {A. Joshi and R. De Smet and K. Marchal and Y. Van de Peer and T. Michoel},
	title = {Module networks revisited: Computational assessment and prioritization of model predictions},
	journal = {Bioinformatics},
	year = {2009},
	volume = {25},
	number = {4}
}

@article{yamashita:2008:cvExample,
	author = {O. Yamashita and M. Sato and T. Yoshioka and F. Tong and Y. Kamitani},
	title = {Sparse estimation automatically selects voxels relevant for the decoding of f{MRI} activity patterns},
	journal = {NeuroImage},
	year = {2008},
	volume = {42},
	number = {4}
}

# Says using CV is gud
@article{musgrave:2020:realityCheck,
	author = {K. Musgrave and S. Belongie and S. N. Lim},
	title = {A machine learning reality check},
	year = {2020},
	journal = {arXiv Preprint},
	month = {March}
}

	
	


#####################
# Approx CV references
#####################

@inproceedings{beirami:2017:firstALOO,
  author    = {A. Beirami and
               M. Razaviyayn and
               S. Shahrampour and
               V. Tarokh},
  title     = {On Optimal Generalizability in Parametric Learning},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  pages     = {3458--3468},
  year      = {2017},
}

@inproceedings{koh:2017:influenceFunctions,
author = {P. W. Koh and P. Liang},
title = {Understanding Black-box Predictions via Influence Functions},
booktitle = {International Conference in Machine Learning (ICML)},
year = {2017}
}

@inproceedings{koh:2019:IJNSBounds,
  author    = {P. W. Koh and K. S. Ang and H. Teo and P. Liang},
  title     = {On the accuracy of influence functions for measuring group effects},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2019},
}

@article{rad:2018:detailedALOO,
   author = {K. R. Rad and A. Maleki},
    title = "{A scalable estimate of the extra-sample prediction error via approximate leave-one-out}",
  journal = {arXiv Preprint},
archivePrefix = "arXiv",
   eprint = {1801.10243},
 primaryClass = "stat.ME",
 keywords = {Statistics - Methodology},
     year = 2020,
    month = jan,
}

@article{xu:2019:ALOOAMP,
	author = {J. Xu and A. Maleki and K. R. Rad and D. Hsu},
	title = {Consistent risk estimation in high-dimensional linear regression},
	year = {2019},
	month = feb,
	journal = {arXiv Preprint}
}
	
@inproceedings{wang:2018:primalDualALOO,
  author = {S. Wang and W. Zhou and H. Lu and A. Maleki and V. Mirrokni},
  title = {Approximate leave-one-out for fast parameter tuning in high dimensions},
  booktitle = {International Conference in Machine Learning (ICML)},
  year = {2018}
}

@inproceedings{giordano:2018:ourALOO,
     author = {R. Giordano and W. T. Stephenson and R. Liu and M. I. Jordan and T. Broderick},
    title = {A {S}wiss army infinitesimal jackknife},
  booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
     year = 2019,
    month = apr,
}

@inproceedings{stephenson:2020:sparseALOO,
     author = {W. T. Stephenson and T. Broderick},
    title = {Approximate cross-validation in high dimensions with guarantees},
  booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
     year = 2020,
    month = jun,
}

@article{obuchi:2018:logisticALOO,
  title={Accelerating cross-validation in multinomial logistic regression with l1-Regularization},
  author={T. Obuchi and Y. Kabashima},
  journal={Journal of Machine Learning Research},
  year={2018},
  month = sep
}

@article{obuchi:2016:linearALOO,
	title = {Cross validation in {LASSO} and its acceleration},
	author = {T. Obuchi and Y. Kabashima},
	journal = {Journal of Statistical Mechanics},
	year = {2016},
	month = may
}

@inproceedings{wilson:2020:modelSelectionALOO,
	author = {A. Wilson and M. Kasy and L. Mackey},
	title = {Approximate cross-validation: guarantees for model assessment and selection},
	year = {2020},
	booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)}
}

@inproceedings{magnusson:2019:scalableAki,
       title = {Bayesian Leave-One-Out Cross-Validation for Large Data},
       author = {M. Magnusson and M. R. Andersen and J. Jonasson and A. Vehtari},
       booktitle = {International Conference in Machine Learning (ICML)},
       year = {2019}
}

@article{hansen:1943:subsampling,
      title = {On the theory of sampling from finite populations},
      author = {M. H. Hansen and W. N. Hurwitz},
      journal = {The Annals of Mathematical Statistics},
      year = {1943},
      volume = 14,
}

@article{bach:2010:concordantLogistic,
	title = {Self-concordant analysis for logistic regression},
	author = {F. Bach},
	journal = {Electronic Journal of Statistics},
	year = {2010},
	volume = 4
}

@article{giordano:2019:HOIJ,
   author = {R. Giordano and M. I. Jordan and T. Broderick},
    title = {A Higher-Order {S}wiss Army Infinitesimal Jackknife
},
  journal = {arXiv Preprint},
     year = 2019,
    month = jul,
}

	


############################
# Sparsity stuff
@inproceedings{li:2015:sparsistency,
	author = {Y. Li and J. Scarlett and P. Ravikumar and V. Cevher},
	title = {Sparsistency of l1-regularized {M}-Estimators},
	booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
	year = {2015}
}

@article{wainwright:2009:linearRegressionLasso,
	author = {M. J. Wainwright},
	title = {Sharp thresholds for high-dimensional and noisy sparsity recovery using l1-constrained quadratic programming ({L}asso)},
	journal = {IEEE Transactions on Information Theory},
	month = {05},
	volume = {55},
	number = {5},
	year = {2009}
}

@article{lee:2014:generalSparseRecovery,
       author = {J. D. Lee and Y. Sun and J. E. Taylor},
       title = {On model selection consistency of regularized {M}-estimators},
       year = {2014},
       month = oct,
       journal = {arXiv Preprint},
       eprint = {1305.7477v8}
}

@book{hastie:2015:sls,
  title={Statistical learning with sparsity: the {L}asso and generalizations},
  author={T. Hastie and R. Tibshirani and M. Wainwright},
  year={2015},
  publisher={Chapman and Hall / CRC},
}

@article{zhao:2006:incoherence,
  title = {On model selection consistency of {L}asso},
  author = {P. Zhao and B. Yu},
  year = {2006},
  journal = {Journal of Machine Learning Research},
  volume = {7},
  pages = {2541--2563}
}

@article{xu:2012:sparsityStability,
  title = {Sparse algorithms are not stable: a no-free-lunch theorem},
  author = {H. Xu and C. Caramanis and S. Mannor},
  year = {2012},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {34},
  number = {1}
}  

@article{negahban:2012:l1Consistency,
  title = {A unified framework for high-dimensional analysis of m-estimators with decomposable regularizers},
  author = {S. N. Negahban and P. Ravikumar and M. J. Wainwright and B. Yu},
  year = {2012},
  journal = {Statistical Science},
  volume = {27},
  number = {4},
  pages = {538--557}
}

@article{homrighausen:2014:l1LOO,
 author = {D. Homrighausen and D. J. Mc{D}onald},
 title = {Leave-one-out cross-validation is risk consistent for {L}asso},
 journal = {Machine Learning},
 year = {2014},
 volume = {97},
 number = {1-2},
 month = oct,
 pages = {65--78},
}

@inproceedings{homrighausen:2013:l1Kfold,
	author = {D. Homrighausen and D. J. Mc{D}onald},
	title = {The lasso, persistence, and cross-validation},
	booktitle = {International Conference in Machine Learning (ICML)},
	year = {2013}
}

@article{chetverikov:2019:l1Kfold,
	author = {D. Chetverikov and Z. Liao and V. Chernozhukov},
	title = {On cross-validated {L}asso in high dimensions},
	year = {2020},
	month = feb,
	journal = {arXiv Preprint}
}

@article{miolane:2018:uniformControl,
	author = {L. Miolane and A. Montanari},
	title = {The distribution of the {L}asso: Uniform control over sparse balls and adaptive parameter tuning},
	year = {2018},
	month = nov,
	journal = {arXiv Preprint}
}


############################
# Low rank stuff
############################
@article{udell:2019:bigDataLowRank,
	author = {M. Udell and A. Townsend},
	title = {Why are big data matrices approximately low rank?},
	journal = {SIAM Journal on Mathematics of Data Science (SIMODS)},
	year = {2019}
}

@inproceedings{tropp:2017:psdRandomizedApproximation,
	author = {J. Tropp and A. Yurtsever and M. Udell and V. Cevher},
	title = {Fixed-rank approximation of a positive-semidefinite matrix from streaming data},
	year = {2017},
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}
}

@article{martinsson:2020:randomizedLinearAlgebraReview, 
author={P. G. Martinsson and J. Tropp},
title={Randomized numerical linear algebra: foundations \& algorithms},
year={2020},
month={feb},
journal = {arXiv Preprint},
}

@article{bathe:1973:subspaceIteration,
	author = {K. J. Bathe and E. L. Wilson},
	title = {Solution methods for eigenvalue problems in structural mechanics},
	journal = {International Journal for Numerical Methods in Engineering},
	year = {1973},
	volume = {6},
	pages = {213--226}
}





	
############################

@book{handel:2016:lectureNotes,
	author = {R. van Handel},
	title = {Probability in High Dimensions},
	month = {December},
	year = {2016},
        publisher = {Lecture Notes},
}

@article{vershynin:2011:randomMatrices,
   author = {{Vershynin}, R.},
    title = "{Introduction to the non-asymptotic analysis of random matrices}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1011.3027},
 primaryClass = "math.PR",
 keywords = {Mathematics - Probability, Computer Science - Numerical Analysis, Mathematics - Functional Analysis, 60B20, 46B09},
     year = 2010,
    month = nov,
   adsurl = {http://adsabs.harvard.edu/abs/2010arXiv1011.3027V},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@book{vershynin:2017:hdpBook,
  author = {R. Vershynin},
  title = {High-dimensional probability: an introduction with applications in data science},
  year = {2018},
  month = {August},
  publisher = {Cambridge University Press}
}

@article{biggroup:2010:humanGenome,
  title={A map of human genome variation from population-scale sequencing},
  author={1000 Genomes Project Consortium and others},
  journal={Nature},
  volume={467},
  number={7319},
  pages={1061},
  year={2010},
  publisher={Nature Publishing Group}
}

@article{burman:1989:cvExperiments,
  title = {A comparative study of ordinary cross-validation, v-fold cross-validation and the repeated learning-testing methods},
  author = {P. Burman},
  journal = {Biometrika},
  volume = {76},
  month = {September},
  year = {1989}
}

@article{arlot:2010:cvOverview,
  title = {A survey of cross-validation procedures for model selection},
  author = {S. Arlot and A. Celisse},
  journal = {Statistics Surveys},
  volume = {4},
  year = {2010}
}

@inproceedings{kumar:2013:cvBounds,
title = {Near-optimal bounds for cross-validation via loss stability},
author = {R. Kumar and D. Lokshtanov and S. Vassilvitskii and A. Vattani},
year = {2013},
booktitle = {International Conference in Machine Learning (ICML)},
}

@article{steinberger:2018:cvIntervalsTheory, 
author={L. Steinberger and H. Leeb},
title={Conditional predictive inference for high-dimensional stable algorithms},
year={2018},
month={sep},
journal = {arXiv Preprint},
}



@article {Huang17,
	author = {M. Huang and J. Wang and E. Torre and H. Dueck and S. Shaffer and
  R. Bonasio and J. Murray and A. Raj and M. Li and N. R. Zhang},
	title = {Gene Expression Recovery For Single Cell RNA Sequencing},
	year = {2017},
  publisher = {Cold Spring Harbor Laboratory},
	journal = {bioRxiv}
}

@article{ChatterjeeB05,
author = "S. Chatterjee and A. Bose",
journal = "The Annals of Statistics",
month = "02",
number = "1",
pages = "414--436",
publisher = "The Institute of Mathematical Statistics",
title = "Generalized bootstrap for estimating equations",
volume = "33",
year = "2005"
}

@techreport{ChamandyMNN12,
title = {Estimating Uncertainty for Massive Data Streams},
author  = {N. Chamandy and O. Muralidharan and A. Najmi and S. Naidu},
year  = {2012},
institution = {Google}
}

@misc{autograd,
title = {autograd},
author = {D. Maclaurin and D. Duvenaud and M. Johnson},
year = 2017,
note = {GitHub repository \url{https://github.com/HIPS/autograd}},
}

@inproceedings{vapnik:1992:erm,
title = {Principles of Risk Minimization for Learning Theory},
author = {V. Vapnik},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {1992},
}

@book{hastie:2009:els,
	title = {The Elements of Statistical Learning},
	author  = {T. Hastie and R. Tibshirani and J. Friedman},
	year = {2009},
	publisher = {Springer-Verlag}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datasets
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Next 3 are P53 dataset from UCI: https://archive.ics.uci.edu/ml/datasets/p53+Mutants
@article{p53_1,
title = {Predicting positive p53 cancer rescue regions using most informative positive ({MIP}) active learning},
author = {S. A. Danziger and R. Baronio and L. Ho and L. Hall and K. Salmon and G. W. Hatfield and P. Kaiser and R. H. Lathrop},
journal = {PLOS computational biology},
volume = {5},
year = {2009},
}

@article{p53_2,
title = {Choosing where to look next in a mutation sequence space: active learning of informative p53 cancer rescue mutants},
author = {S. A. Danziger and J. Zeng and Y. Wang and R. K. Brachmann and R. H. Lathrop},
journal = {Bioinformatics},
volume = {23},
year = {2007},
}

@article{p53_3,
title = {Functional census of mutation sequence spaces: the example of p53 cancer rescue mutants},
author = {S. A. Danziger and S. J. Swamidass and J. Zeng and L. R. Dearth and Q. Lu and J. H. Chen and J. Cheng and V. P. Hoang and H. Saigo and R. Luo and P. Baldi and R. K. Brachmann and R. H. Lathrop},
journal = {IEEE/ACM transactions on computational biology and bioinformatics},
volume = {3},
year = {2006}
}


% Gisette dataset: https://archive.ics.uci.edu/ml/datasets/Gisette
@inproceedings{gisette,
title = {Result analysis of the {NIPS} 2003 feature selection challenge},
author = {I. Guyon and S. R. Gunn and A. Ben-Hur and G. Dror},
year = {2004},
booktitle = {Advances in Neural Information Processing Systems (NIPS)}
}

% RCV1 dataset:
@article{rcv1,
title = {{RCV1}: A new benchmark collection for text categorization research},
author = {D. D. Lewis and Y. Yang and T. G. Rose and F. Li},
journal = {Journal of Machine Learning Research},
volume = {5},
year = {2004}
}

@Manual{bcTCGA,
author = {bc{TCGA}},
title = {Breast cancer gene expression data},
Note = {Available at http://myweb.uiowa.edu/pbreheny/data/bcTCGA\\.html},
year = {2018},
month = {Nov}
}


@article{agarwal:2012:stochasticL1Convergence, 
author={A. Agarwal and S. N. Negahban and M. J. Wainwright}, 
title={Stochastic optimization and sparse statistical recovery: An optimal algorithm for high dimensions}, 
year={2012},
month={jul},
journal = {arXiv Preprint},
}

@inproceedings{lorraine:2020:hyperparamOpt,
	title = {Optimizing millions of hyperparameters by implicit differentiation},
	author = {J. Lorraine and P. Vicol and D. Duvenaud},
	year = {2020},
	booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)}
}

%BlogFeedback
@inproceedings{buza:2014:blogfeedback,
	title = {Feedback prediction for blogs},
	author = {Buza, K.},
	year = {2014},
	pages = {145--152},
	booktitle = {Data Analysis, Machine Learning and Knowledge Discovery},
	publisher = {Springer International Publishing}
}


######################
# Misc References
######################

@inproceedings{giordano:2015:LRVB,
     author = {R. Giordano and T. Broderick and M. I. Jordan},
    title = {Linear response methods for accurate covariance estimates from mean field variational {B}ayes},
  booktitle = {NIPS},
     year = 2015,
}

@article{bates:2015:lme4,
	author = {D. Bates and M. M\"{a}chler and B. Bolker and S. Walker},
	title = {Fitting Linear Mixed-Effects Models Using lme4},
	journal = {Journal of Statistical Software},
	year = {2015},
	volume = {67}
}
