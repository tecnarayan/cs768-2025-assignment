\begin{thebibliography}{10}

\bibitem{SayCan}
Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alexander Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario~Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil~Jayant Joshi, Ryan~C. Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka Rao, Jarek Rettinghouse, Diego~M Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, F.~Xia, Ted Xiao, Peng Xu, Sichun Xu, and Mengyuan Yan.
\newblock Do as i can, not as i say: Grounding language in robotic affordances.
\newblock In {\em Conference on Robot Learning}, 2022.

\bibitem{AutoGuide}
Yao Fu, Dong-Ki Kim, Jaekyeom Kim, Sungryull Sohn, Lajanugen Logeswaran, Kyunghoon Bae, and Honglak Lee.
\newblock Autoguide: Automated generation and selection of state-aware guidelines for large language model agents.
\newblock {\em ArXiv}, abs/2403.08978, 2024.

\bibitem{MetaGPT}
Sirui Hong, Xiawu Zheng, Jonathan~P. Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven Ka~Shing Yau, Zi~Hen Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, and Chenglin Wu.
\newblock Metagpt: Meta programming for multi-agent collaborative framework.
\newblock {\em ArXiv}, abs/2308.00352, 2023.

\bibitem{RAP}
Tomoyuki Kagaya, Thong~Jing Yuan, Yuxuan Lou, Jayashree Karlekar, Sugiri Pranata, Akira Kinose, Koki Oguri, Felix Wick, and Yang You.
\newblock Rap: Retrieval-augmented planning with contextual memory for multimodal llm agents.
\newblock {\em ArXiv}, abs/2402.03610, 2024.

\bibitem{RCI}
Geunwoo Kim, Pierre Baldi, and Stephen~Marcus McAleer.
\newblock Language models can solve computer tasks.
\newblock In {\em Neural Information Processing Systems}, 2023.

\bibitem{OfflineRL}
Sergey Levine, Aviral Kumar, G.~Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on open problems.
\newblock {\em ArXiv}, abs/2005.01643, 2020.

\bibitem{CodeAP}
Jacky Liang, Wenlong Huang, F.~Xia, Peng Xu, Karol Hausman, Brian Ichter, Peter~R. Florence, and Andy Zeng.
\newblock Code as policies: Language model programs for embodied control.
\newblock {\em 2023 IEEE International Conference on Robotics and Automation (ICRA)}, pages 9493--9500, 2022.

\bibitem{MiniWoB}
Evan~Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang.
\newblock Reinforcement learning on web interfaces using workflow-guided exploration.
\newblock In {\em International Conference on Learning Representations ({ICLR})}, 2018.

\bibitem{CLIN}
Bodhisattwa~Prasad Majumder, Bhavana Dalvi, Peter~Alexander Jansen, Oyvind Tafjord, Niket Tandon, Li~Zhang, Chris Callison-Burch, and Peter Clark.
\newblock Clin: A continually learning language agent for rapid task adaptation and generalization.
\newblock {\em ArXiv}, abs/2310.10134, 2023.

\bibitem{WebGPT}
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Ouyang Long, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu~Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman.
\newblock Webgpt: Browser-assisted question-answering with human feedback.
\newblock {\em ArXiv}, abs/2112.09332, 2021.

\bibitem{GPT4}
OpenAI.
\newblock Gpt-4 technical report.
\newblock {\em ArXiv}, abs/2303.08774, 2023.

\bibitem{ChatGPT}
Long Ouyang, Jeff Wu, Xu~Jiang, Diogo Almeida, Carroll~L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke~E. Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul~Francis Christiano, Jan Leike, and Ryan~J. Lowe.
\newblock Training language models to follow instructions with human feedback.
\newblock In {\em Neural Information Processing Systems}, 2022.

\bibitem{MemGPT}
Charles Packer, Vivian Fang, Shishir~G. Patil, Kevin Lin, Sarah Wooders, and Joseph~E. Gonzalez.
\newblock Memgpt: Towards llms as operating systems.
\newblock {\em ArXiv}, abs/2310.08560, 2023.

\bibitem{GenerativeAI}
Joon~Sung Park, Joseph~C. O'Brien, Carrie~J. Cai, Meredith~Ringel Morris, Percy Liang, and Michael~S. Bernstein.
\newblock Generative agents: Interactive simulacra of human behavior.
\newblock {\em Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology}, 2023.

\bibitem{ChatDev}
Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, and Wei Liu.
\newblock Communicative agents for software development.
\newblock {\em ArXiv}, abs/2307.07924, 2023.

\bibitem{Reflexion}
Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
\newblock Reflexion: language agents with verbal reinforcement learning.
\newblock In {\em Neural Information Processing Systems}, 2023.

\bibitem{ALFWorld}
Mohit Shridhar, Xingdi Yuan, Marc-Alexandre C\^ot\'e, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht.
\newblock Alfworld: Aligning text and embodied environments for interactive learning.
\newblock In {\em Proceedings of the International Conference on Learning Representations (ICLR)}, 2021.

\bibitem{ProgPrompt}
Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg.
\newblock Progprompt: Generating situated robot task plans using large language models.
\newblock {\em 2023 IEEE International Conference on Robotics and Automation (ICRA)}, pages 11523--11530, 2022.

\bibitem{SteP}
Paloma Sodhi, S.~R.~K. Branavan, Yoav Artzi, and Ryan McDonald.
\newblock Step: Stacked llm policies for web actions.
\newblock {\em arXiv}, abs/2310.03720, 2024.

\bibitem{LLM-Planner}
Chan~Hee Song, Jiaman Wu, Clay Washington, Brian~M. Sadler, Wei-Lun Chao, and Yu~Su.
\newblock Llm-planner: Few-shot grounded planning for embodied agents with large language models.
\newblock {\em 2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 2986--2997, 2022.

\bibitem{AdaPlanner}
Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo~Dai, and Chao Zhang.
\newblock Adaplanner: Adaptive planning from feedback with language models.
\newblock In {\em Neural Information Processing Systems}, 2023.

\bibitem{ChatGPTFR}
Sai Vemprala, Rogerio Bonatti, Arthur Fender~C. Bucker, and Ashish Kapoor.
\newblock Chatgpt for robotics: Design principles and model abilities.
\newblock {\em IEEE Access}, 12:55682--55696, 2023.

\bibitem{ChatGPTEL}
Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, and Katsushi Ikeuchi.
\newblock Chatgpt empowered long-step robot control in various environments: A case application.
\newblock {\em IEEE Access}, 11:95060--95078, 2023.

\bibitem{Voyager}
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi~(Jim) Fan, and Anima Anandkumar.
\newblock Voyager: An open-ended embodied agent with large language models.
\newblock {\em ArXiv}, abs/2305.16291, 2023.

\bibitem{CodeAct}
Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, and Heng Ji.
\newblock Executable code actions elicit better llm agents.
\newblock {\em ArXiv}, abs/2402.01030, 2024.

\bibitem{PromptAgent}
Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric~P. Xing, and Zhiting Hu.
\newblock Promptagent: Strategic planning with language models enables expert-level prompt optimization.
\newblock {\em ArXiv}, abs/2310.16427, 2023.

\bibitem{DEPS}
Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang.
\newblock Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.
\newblock In {\em Neural Information Processing Systems}, 2023.

\bibitem{CoT}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed~Huai hsin Chi, F.~Xia, Quoc Le, and Denny Zhou.
\newblock Chain of thought prompting elicits reasoning in large language models.
\newblock In {\em Neural Information Processing Systems}, 2022.

\bibitem{REINFORCE}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist reinforcement learning.
\newblock {\em Machine learning}, 8:229--256, 1992.

\bibitem{Survey}
Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Qin Liu, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi~Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huan, and Tao Gui.
\newblock The rise and potential of large language model based agents: A survey.
\newblock {\em ArXiv}, abs/2309.07864, 2023.

\bibitem{LLMOptim}
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc~V. Le, Denny Zhou, and Xinyun Chen.
\newblock Large language models as optimizers.
\newblock {\em ArXiv}, abs/2309.03409, 2023.

\bibitem{ToT}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas~L. Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.
\newblock In {\em Neural Information Processing Systems}, 2023.

\bibitem{ReAct}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
\newblock {ReAct}: Synergizing reasoning and acting in language models.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2023.

\bibitem{AgentPro}
Wenqi Zhang, Ke~Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yue~Ting Zhuang, and Weiming Lu.
\newblock Agent-pro: Learning to evolve via policy-level reflection and optimization.
\newblock {\em ArXiv}, abs/2402.17574, 2024.

\bibitem{ExpeL}
Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Y.~Liu, and Gao Huang.
\newblock Expel: Llm agents are experiential learners.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI)}, 2024.

\bibitem{LATS}
Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang.
\newblock Language agent tree search unifies reasoning acting and planning in language models.
\newblock {\em ArXiv}, abs/2310.04406, 2023.

\bibitem{WebArena}
Shuyan Zhou, Frank~F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham Neubig.
\newblock Webarena: A realistic web environment for building autonomous agents.
\newblock {\em ArXiv}, abs/2307.13854, 2023.

\bibitem{LLMPrompt}
Yongchao Zhou, Andrei~Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.
\newblock Large language models are human-level prompt engineers.
\newblock {\em ArXiv}, abs/2211.01910, 2022.

\bibitem{GITM}
Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Y.~Qiao, Zhaoxiang Zhang, and Jifeng Dai.
\newblock Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory.
\newblock {\em ArXiv}, abs/2305.17144, 2023.

\bibitem{LLMLR}
Zhaocheng Zhu, Yuan Xue, Xinyun Chen, Denny Zhou, Jian Tang, Dale Schuurmans, and Hanjun Dai.
\newblock Large language models can learn rules.
\newblock {\em ArXiv}, abs/2310.07064, 2023.

\end{thebibliography}
