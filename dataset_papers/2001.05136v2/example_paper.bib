%% NAT Work
@inproceedings{Gu2017NonAutoregressiveNM,
  title={Non-Autoregressive Neural Machine Translation},
  author={Jiatao Gu and James Bradbury and Caiming Xiong and Victor O. K. Li and Richard Socher},
  year={2018},
  url={https://arxiv.org/abs/1711.02281},
  booktitle={Proc. of ICLR},
}

@inproceedings{Ghazvininejad2019MaskPredictPD,
  title={Mask-Predict: Parallel Decoding of Conditional Masked Language Models.},
  author={Marjan Ghazvininejad and Omer Levy and Yinhan Liu and Luke S. Zettlemoyer},
  year={2019},
  booktitle={Proc. of EMNLP},
  url={https://arxiv.org/abs/1904.09324},
}

@inproceedings{Gu2019LevenshteinT,
  title={Levenshtein Transformer},
  author={Jiatao Gu and Changhan Wang and Jake Zhao},
  year={2019},
  booktitle={Proc. of NeurIPS},
  url={https://arxiv.org/abs/1905.11006},
}

@inproceedings{Li2019HintBasedTF,
  title={Hint-Based Training for Non-Autoregressive Machine Translation},
  author={Zhuohan Li and Zi Lin and Di He and Fei Tian and Tao Qin and Liwei Wang and Tie-Yan Liu},
  booktitle={Proc.\ of EMNLP},
  year={2019},
  url={https://arxiv.org/abs/1909.06708},
}


@inproceedings{Sun2019Fast,
  title={Fast Structured Decoding for Sequence Models},
  author={Zhiqing Sun and Zhuohan Li and Haoqing Wang and Di He and Zi Lin and Zhihong Deng},
  booktitle={Proc. of NeurIPS},
  year={2019},
  url={https://arxiv.org/abs/1910.11555},
}

@inproceedings{Lee2018DeterministicNN,
  title={Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement},
  author={Jason D. Lee and Elman Mansimov and Kyunghyun Cho},
  booktitle={Proc. of EMNLP},
  year={2018},
  url={https://arxiv.org/abs/1802.06901},
}

@inproceedings{Wang2019NonAutoregressiveMT,
  title={Non-Autoregressive Machine Translation with Auxiliary Regularization},
  author={Yiren Wang and Fei Tian and Di He and Tao Qin and ChengXiang Zhai and Tie-Yan Liu},
  booktitle={Proc.\ of AAAI},
  url={https://arxiv.org/abs/1902.10245},
  year={2019},
}

@inproceedings{MinBOW,
  title={Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural Machine Translation},
  author={Chenze Shao and Jinchao Zhang and Yang Feng and Fandong Meng and Jie Zhou},
  url={https://arxiv.org/abs/1911.09320},
  booktitle={Proc.\ of AAAI},
  year={2020},
}


@misc{ReorderNAT,
  title={Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information},
  author={Qiu Ran and Yankai Lin and Peng Li and Jie Zhou},
  url={https://arxiv.org/abs/1911.02215},
  year={2019},
}

%% Tranformer
@inproceedings{Vaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and \L{}ukasz Kaiser and Illia Polosukhin},
  booktitle={Proc. of NeurIPS},
  year={2017},
  url={https://arxiv.org/abs/1706.03762},
}

@inproceedings{Kaiser2018FastDI,
  title={Fast Decoding in Sequence Models Using Discrete Latent Variables},
  author={\L{}ukasz Kaiser and Aurko Roy and Ashish Vaswani and Niki Parmar and Samy Bengio and Jakob Uszkoreit and Noam Shazeer},
  booktitle={Proc.\ of ICML},
  year={2018},
  url={https://arxiv.org/abs/1803.03382},
 }
  
@inproceedings{Stern2019InsertionTF,
  title={Insertion Transformer: Flexible Sequence Generation via Insertion Operations},
  author={Mitchell Stern and William Chan and Jamie Ryan Kiros and Jakob Uszkoreit},
  booktitle={Proc.\ of ICML},
  year={2019},
  url={https://arxiv.org/abs/1902.03249},
}

@inproceedings{Stern2018BlockwisePD,
  title={Blockwise Parallel Decoding for Deep Autoregressive Models},
  author={Mitchell Stern and Noam Shazeer and Jakob Uszkoreit},
  booktitle={Proc. of NeurIPS},
  year={2018},
  url={https://arxiv.org/abs/1811.03115},
}

@inproceedings{Shu2019LatentVariableNN,
  title={Latent-Variable Non-Autoregressive Neural Machine Translation with Deterministic Inference using a Delta Posterior},
  author={Raphael Shu and Jason Lee and Hideki Nakayama and Kyunghyun Cho},
  year={2020},
  booktitle={Proc.\ of AAAI},
  url={https://arxiv.org/abs/1908.07181},
}

@inproceedings{Ma2019FlowSeqNC,
  title={{FlowSeq}: Non-Autoregressive Conditional Sequence Generation with Generative Flow},
  author={Xuezhe Ma and Chunting Zhou and Xian Li and Graham Neubig and Eduard H. Hovy},
  year={2019},
  booktitle={Proc.\ of EMNLP},
  url={https://arxiv.org/abs/1909.02480},
}

@inproceedings{Libovick2018EndtoEndNN,
  title={End-to-End Non-Autoregressive Neural Machine Translation with Connectionist Temporal Classification},
  author={Jindrich Libovick{\'y} and Jindrich Helcl},
  booktitle={Proc.\ of EMNLP},
  url={https://arxiv.org/abs/1811.04719},
  year={2018},
}

@inproceedings{UnderstandingKD,
  title={Understanding Knowledge Distillation in Non-autoregressive Machine Translation},
  author={Chunting Zhou and Graham Neubig and Jiatao Gu},
  url={https://arxiv.org/abs/1911.02727},
  year={2020},
  booktitle={Proc.\ of ICLR},
}



%% SOTA MT
@inproceedings{Bahdanau2014NeuralMT,
  title={Neural Machine Translation by Jointly Learning to Align and Translate},
  author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  year={2015},
  booktitle={Proc. of ICLR},
  url={https://arxiv.org/abs/1409.0473},
}

@inproceedings{Sutskever2014SequenceTS,
  title={Sequence to Sequence Learning with Neural Networks},
  author={Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  booktitle={Proc.\ of NeurIPS},
  year={2014},
  url={https://arxiv.org/abs/1409.3215},
}

@inproceedings{Ott2018ScalingNM,
  title={Scaling Neural Machine Translation},
  author={Myle Ott and Sergey Edunov and David Grangier and Michael Auli},
  booktitle={Proc.\ of WMT},
  year={2018},
  url={https://arxiv.org/abs/1806.00187},
}

@inproceedings{devlins2019bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year={2019},
  url={https://arxiv.org/abs/810.04805},
    _address = "Minneapolis, Minnesota",
    _publisher = "Association for Computational Linguistics",
  _pages = "4171--4186", 
  booktitle={Proc. of NAACL-HLT},
}

@misc{Liu2019RoBERTaAR,
  title={{RoBERTa}: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke S. Zettlemoyer and Veselin Stoyanov},
  url={https://arxiv.org/abs/1907.11692},
  year={2019},
}

@inproceedings{Yang2019XLNetGA,
  title={{XLNet}: Generalized Autoregressive Pretraining for Language Understanding},
  author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime G. Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
  booktitle={Proc. of NeurIPS},
  year={2019},
  url={https://arxiv.org/abs/1906.08237},
}

@misc{Baevski2019ClozedrivenPO,
  title={Cloze-driven Pretraining of Self-attention Networks},
  author={Alexei Baevski and Sergey Edunov and Yinhan Liu and Luke S. Zettlemoyer and Michael Auli},
  year={2019},
  url={https://arxiv.org/abs/1903.07785},
}

% BPE

@inproceedings{sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proc.\ of ACL",
    _month = aug,
    year = "2016",
    _address = "Berlin, Germany",
    _publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1162",
    _doi = "10.18653/v1/P16-1162",
    _pages = "1715--1725",
}

% EN-FR setup
@inproceedings{Gehring2017ConvolutionalST,
  title={Convolutional Sequence to Sequence Learning},
  author={Jonas Gehring and Michael Auli and David Grangier and Denis Yarats and Yann Dauphin},
  booktitle={Proc.\ of ICML},
  year={2017},
  url={https://arxiv.org/abs/1705.03122},
}

% EN-ZH setup

@misc{Hassan2018AchievingHP,
  title={Achieving Human Parity on Automatic {Chinese} to {English} News Translation},
  author={Hany Hassan and Anthony Aue and Chang Chen and Vishal Chowdhary and Jonathan Clark and Christian Federmann and Xuedong Huang and Marcin Junczys-Dowmunt and William Lewis and Mengnan Li and Shujie Liu and Tie-Yan Liu and Renqian Luo and Arul Menezes and Tao Qin and Frank Seide and Xu Tan and Fei Tian and Lijun Wu and Shuangzhi Wu and Yingce Xia and Dongdong Zhang and Zhirui Zhang and Ming Zhou},
  year={2018},
  url={https://arxiv.org/abs/1803.05567},
}

@inproceedings{wu2018pay,
  title = {Pay Less Attention with Lightweight and Dynamic Convolutions},
  author = {Felix Wu and Angela Fan and Alexei Baevski and Yann Dauphin and Michael Auli},
  booktitle = {Proc.\ of ICLR},
  year = {2019},
  url = {https://arxiv.org/abs/1901.10430},
}


@inproceedings{post-2018-call,
    title = "A Call for Clarity in Reporting {BLEU} Scores",
    author = "Post, Matt",
    booktitle = "Proc.\ of WMT",
    _month = oct,
    year = "2018",
    _address = "Brussels, Belgium",
    _publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6319",
    _doi = "10.18653/v1/W18-6319",
    _pages = "186--191",
    abstract = "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to {``}the{''} BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SACREBLEU, to facilitate this.",
}

@inproceedings{Papineni2001BleuAM,
  title={{BLEU}: a Method for Automatic Evaluation of Machine Translation},
  author={Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu},
  booktitle={Proc.\ of ACL},
  year={2002},
  url={https://www.aclweb.org/anthology/P02-1040/},
}

@inproceedings{Kingma2014AdamAM,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  year={2015},
  booktitle={Proc.\ of ICLR},
  url={https://arxiv.org/abs/1412.6980},
}  

@inproceedings{micikevicius2018mixed,
title={Mixed Precision Training},
author={Paulius Micikevicius and Sharan Narang and Jonah Alben and Gregory Diamos and Erich Elsen and David Garcia and Boris Ginsburg and Michael Houston and Oleksii Kuchaiev and Ganesh Venkatesh and Hao Wu},
booktitle={Proc.\ of ICLR},
year={2018},
url={https://arxiv.org/abs/1710.03740},
}

% KD 
@inproceedings{Kim2016SequenceLevelKD,
  title={Sequence-Level Knowledge Distillation},
  author={Yoon Kim and Alexander M. Rush},
  booktitle={Proc.\ of EMNLP},
  year={2016},
  url={https://arxiv.org/abs/1606.07947},
}

% compound split
@inproceedings{luong-etal-2015-effective,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proc.\ of EMNLP",
    month = sep,
    year = "2015",
    _address = "Lisbon, Portugal",
    _publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1166",
    _doi = "10.18653/v1/D15-1166",
    _pages = "1412--1421",
}


%% applications of CMLMs

@misc{Video2019,
  title={Non-Autoregressive Video Captioning with Iterative Refinement},
  author={Bang Yang and Fenglin Liu and Yuexian Zou},
  url={https://arxiv.org/abs/1911.12018},
  year={2019},
}

@inproceedings{Speech2019,
  title={Recognition and Translation of Code-switching Speech Utterances},
  author={Sahoko Nakayama and Takatomo Kano and Andros Tjandra and Sakriani Sakti and Satoshi Nakamura},
  url={https://ahcweb01.naist.jp/papers/conference/2019/201910\_OCOCOSDA\_sahoko-n/201910\_OCOCOSDA\_sahoko-n.paper.pdf},
  year={2019},
  booktitle={Proc.\ of Oriental COCOSDA},
}

@misc{Mansimov2019AGF,
  title={A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models},
  author={Elman Mansimov and Alex Wang and Kyunghyun Cho},
  year={2019},
  url={https://arxiv.org/abs/1905.12790},
}

@misc{Saharia2020,
  title={Non-Autoregressive Machine Translation with Latent Alignments
},
  author={Chitwan Saharia and William Chan and Saurabh Saxena and Mohammad Norouzi},
  year={2020},
  url={https://arxiv.org/abs/2004.07437}
}

@misc{Li2020LAVANA,
  title={{LAVA NAT}: A Non-Autoregressive Translation Model with Look-Around Decoding and Vocabulary Attention},
  author={Xiaoya Li and Yuxian Meng and Arianna Yuan and Fei Wu and Jiwei Li},
  year={2020},
  url={https://arxiv.org/abs/2002.03084},
}

@article{Gu2019InsertionbasedDW,
  title={Insertion-based Decoding with Automatically Inferred Generation Order},
  author={Jiatao Gu and Qi Liu and Kyunghyun Cho},
  journal={TACL},
  year={2019},
  _volume={7},
  _pages={661-676},
  url={https://arxiv.org/abs/1902.01370},
}

@inproceedings{Tu2020ENGINEEI,
  title={{ENGINE}: Energy-Based Inference Networks for Non-Autoregressive Machine Translation},
  author={Lifu Tu and Richard Yuanzhe Pang and Sam Wiseman and Kevin Gimpel},
  booktitle={Proc.\ of ACL},
  year={2020},
  url={https://arxiv.org/abs/2005.00850},
}


@misc{Chan2019KERMITGI,
  title={{KERMIT}: Generative Insertion-Based Modeling for Sequences},
  author={William Chan and Nikita Kitaev and Kelvin Guu and Mitchell Stern and Jakob Uszkoreit},
  year={2019},
  url={https://arxiv.org/abs/1906.01604},
}

@inproceedings{ott-etal-2019-fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle  and
      Edunov, Sergey  and
      Baevski, Alexei  and
      Fan, Angela  and
      Gross, Sam  and
      Ng, Nathan  and
      Grangier, David  and
      Auli, Michael",
    booktitle = "NAACL Demonstrations",
    _month = jun,
    year = "2019",
    _address = "Minneapolis, Minnesota",
    _publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1904.01038",
    _doi = "10.18653/v1/N19-4009",
    _pages = "48--53",
    _abstract = "fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at https://www.youtube.com/watch?v=OtgDdWtHvto",
}

@misc{Ghazvininejad2020AlignedCE,
  title={Aligned Cross Entropy for Non-Autoregressive Machine Translation},
  author={Marjan Ghazvininejad and Vladimir Karpukhin and Luke Zettlemoyer and Omer Levy},
  year={2020},
  url={https://arxiv.org/abs/2004.01655},
}

@misc{Ghazvininejad2020SemiAutoregressiveTI,
  title={Semi-Autoregressive Training Improves Mask-Predict Decoding},
  author={Marjan Ghazvininejad and Omer Levy and Luke Zettlemoyer},
  url={https://arxiv.org/abs/2001.08785},
  year={2020},
}


@inproceedings{Zhou2020ImprovingNN,
  title={Improving Non-autoregressive Neural Machine Translation with Monolingual Data},
  author={Jiawei Zhou and Phillip Keung},
  year={2020},
  booktitle={Proc.\ of ACL},
  url={https://arxiv.org/abs/2005.00932},
}

@misc{Graves2016AdaptiveCT,
  title={Adaptive Computation Time for Recurrent Neural Networks},
  author={Alex Graves},
  year={2016},
  url={https://arxiv.org/abs/1603.08983},
}

@inproceddings{Dehghani2019UniversalT,
  title={Universal Transformers},
  author={Mostafa Dehghani and Stephan Gouws and Oriol Vinyals and Jakob Uszkoreit and Lukasz Kaiser},
  year={2019},
  booktitle={Proc.\ of ICLR},
  url={https://arxiv.org/abs/1807.03819},
}

@misc{Chan2019AnES,
  title={An Empirical Study of Generation Order for Machine Translation},
  author={William Chan and Mitchell Stern and Jamie Ryan Kiros and Jakob Uszkoreit},
  year={2019},
  url={https://arxiv.org/abs/1910.13437},
}

@misc{Zhang2020POINTERCT,
  title={{POINTER}: Constrained Text Generation via Insertion-based Generative Pre-training},
  author={Yizhe Zhang and Guoyin Wang and Chunyuan Li and Zhe Gan and Chris Brockett and Bill Dolan},
  year={2020},
  url={https://arxiv.org/abs/2005.00558},
}