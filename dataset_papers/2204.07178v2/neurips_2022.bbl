\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alet et~al.(2021)Alet, Doblar, Zhou, Tenenbaum, Kawaguchi, and
  Finn]{alet2021noether}
Ferran Alet, Dylan Doblar, Allan Zhou, Josh Tenenbaum, Kenji Kawaguchi, and
  Chelsea Finn.
\newblock Noether networks: meta-learning useful conserved quantities.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Basri et~al.(2020)Basri, Galun, Geifman, Jacobs, Kasten, and
  Kritchman]{basri2020frequency}
Ronen Basri, Meirav Galun, Amnon Geifman, David Jacobs, Yoni Kasten, and Shira
  Kritchman.
\newblock Frequency bias in neural networks for input of non-uniform density.
\newblock In \emph{International Conference on Machine Learning}, pages
  685--694. PMLR, 2020.

\bibitem[Bekkers et~al.(2018)Bekkers, Lafarge, Veta, Eppenhof, Pluim, and
  Duits]{bekkers2018roto}
Erik~J Bekkers, Maxime~W Lafarge, Mitko Veta, Koen~AJ Eppenhof, Josien~PW
  Pluim, and Remco Duits.
\newblock Roto-translation covariant convolutional networks for medical image
  analysis.
\newblock In \emph{International conference on medical image computing and
  computer-assisted intervention}, pages 440--448. Springer, 2018.

\bibitem[Benton et~al.(2020)Benton, Finzi, Izmailov, and
  Wilson]{benton2020learning}
Gregory Benton, Marc Finzi, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Learning invariances in neural networks.
\newblock \emph{arXiv preprint arXiv:2010.11882}, 2020.

\bibitem[Cohen and Welling(2016)]{cohen2016group}
Taco Cohen and Max Welling.
\newblock Group equivariant convolutional networks.
\newblock In \emph{International conference on machine learning}, pages
  2990--2999. PMLR, 2016.

\bibitem[Cohen et~al.(2018)Cohen, Geiger, K{\"o}hler, and
  Welling]{cohen2018spherical}
Taco~S Cohen, Mario Geiger, Jonas K{\"o}hler, and Max Welling.
\newblock Spherical cnns.
\newblock \emph{arXiv preprint arXiv:1801.10130}, 2018.

\bibitem[Finzi et~al.(2020)Finzi, Stanton, Izmailov, and
  Wilson]{finzi2020generalizing}
Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Generalizing convolutional neural networks for equivariance to lie
  groups on arbitrary continuous data.
\newblock In \emph{International Conference on Machine Learning}, pages
  3165--3176. PMLR, 2020.

\bibitem[Finzi et~al.(2021{\natexlab{a}})Finzi, Benton, and
  Wilson]{finzi2021residual}
Marc Finzi, Gregory Benton, and Andrew~G Wilson.
\newblock Residual pathway priors for soft equivariance constraints.
\newblock \emph{Advances in Neural Information Processing Systems}, 34,
  2021{\natexlab{a}}.

\bibitem[Finzi et~al.(2021{\natexlab{b}})Finzi, Welling, and
  Wilson]{finzi2021practical}
Marc Finzi, Max Welling, and Andrew~Gordon Wilson.
\newblock A practical method for constructing equivariant multilayer
  perceptrons for arbitrary matrix groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  3318--3328. PMLR, 2021{\natexlab{b}}.

\bibitem[Fuchs et~al.(2020)Fuchs, Worrall, Fischer, and Welling]{fuchs2020se}
Fabian Fuchs, Daniel Worrall, Volker Fischer, and Max Welling.
\newblock Se (3)-transformers: 3d roto-translation equivariant attention
  networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1970--1981, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Immer et~al.(2022)Immer, van~der Ouderaa, Fortuin, Rätsch, and
  van~der Wilk]{immer2022invariance}
Alexander Immer, Tycho F.~A. van~der Ouderaa, Vincent Fortuin, Gunnar Rätsch,
  and Mark van~der Wilk.
\newblock Invariance learning in deep neural networks with differentiable
  laplace approximations, 2022.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International conference on machine learning}, pages
  448--456. PMLR, 2015.

\bibitem[Knigge et~al.(2022)Knigge, Romero, and Bekkers]{knigge2022exploiting}
David~M Knigge, David~W Romero, and Erik~J Bekkers.
\newblock Exploiting redundancy: Separable group convolutional networks on lie
  groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  11359--11386. PMLR, 2022.

\bibitem[Kondor and Trivedi(2018)]{kondor2018generalization}
Risi Kondor and Shubhendu Trivedi.
\newblock On the generalization of equivariance and convolution in neural
  networks to the action of compact groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  2747--2755. PMLR, 2018.

\bibitem[Kondor et~al.(2018)Kondor, Lin, and Trivedi]{kondor2018clebsch}
Risi Kondor, Zhen Lin, and Shubhendu Trivedi.
\newblock Clebsch--gordan nets: a fully fourier space spherical convolutional
  neural network.
\newblock \emph{Advances in Neural Information Processing Systems},
  31:\penalty0 10117--10126, 2018.

\bibitem[Liu et~al.(2018)Liu, Lehman, Molino, Such, Frank, Sergeev, and
  Yosinski]{liu2018intriguing}
Rosanne Liu, Joel Lehman, Piero Molino, Felipe~Petroski Such, Eric Frank, Alex
  Sergeev, and Jason Yosinski.
\newblock An intriguing failing of convolutional neural networks and the
  coordconv solution.
\newblock \emph{arXiv preprint arXiv:1807.03247}, 2018.

\bibitem[Lorraine et~al.(2020)Lorraine, Vicol, and Duvenaud]{lorraine2020}
Jonathan Lorraine, Paul Vicol, and David Duvenaud.
\newblock Optimizing millions of hyperparameters by implicit differentiation.
\newblock In Silvia Chiappa and Roberto Calandra, editors, \emph{Proceedings of
  the Twenty Third International Conference on Artificial Intelligence and
  Statistics}, volume 108 of \emph{Proceedings of Machine Learning Research},
  pages 1540--1552. PMLR, 26--28 Aug 2020.

\bibitem[Margrave(1998)]{margrave1998theory}
Gary~F Margrave.
\newblock Theory of nonstationary linear filtering in the fourier domain with
  application to time-variant filtering.
\newblock \emph{Geophysics}, 63\penalty0 (1):\penalty0 244--259, 1998.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{mildenhall2020nerf}
Ben Mildenhall, Pratul~P. Srinivasan, Matthew Tancik, Jonathan~T. Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In \emph{ECCV}, 2020.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Rahaman et~al.(2019)Rahaman, Baratin, Arpit, Draxler, Lin, Hamprecht,
  Bengio, and Courville]{rahaman2019spectral}
Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred
  Hamprecht, Yoshua Bengio, and Aaron Courville.
\newblock On the spectral bias of neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  5301--5310. PMLR, 2019.

\bibitem[Rahimi et~al.(2007)Rahimi, Recht, et~al.]{rahimi2007random}
Ali Rahimi, Benjamin Recht, et~al.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{NIPS}. Citeseer, 2007.

\bibitem[Romero and Lohit(2021)]{romero2021learning}
David~W Romero and Suhas Lohit.
\newblock Learning equivariances and partial equivariances from data.
\newblock \emph{arXiv preprint arXiv:2110.10211}, 2021.

\bibitem[Romero et~al.(2021{\natexlab{a}})Romero, Bruintjes, Tomczak, Bekkers,
  Hoogendoorn, and van Gemert]{romero2021flexconv}
David~W Romero, Robert-Jan Bruintjes, Jakub~M Tomczak, Erik~J Bekkers, Mark
  Hoogendoorn, and Jan~C van Gemert.
\newblock Flexconv: Continuous kernel convolutions with differentiable kernel
  sizes.
\newblock \emph{arXiv preprint arXiv:2110.08059}, 2021{\natexlab{a}}.

\bibitem[Romero et~al.(2021{\natexlab{b}})Romero, Kuzina, Bekkers, Tomczak, and
  Hoogendoorn]{romero2021ckconv}
David~W Romero, Anna Kuzina, Erik~J Bekkers, Jakub~M Tomczak, and Mark
  Hoogendoorn.
\newblock Ckconv: Continuous kernel convolution for sequential data.
\newblock \emph{arXiv preprint arXiv:2102.02611}, 2021{\natexlab{b}}.

\bibitem[Satorras et~al.(2021)Satorras, Hoogeboom, and Welling]{satorras2021n}
Victor~Garcia Satorras, Emiel Hoogeboom, and Max Welling.
\newblock E (n) equivariant graph neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  9323--9332. PMLR, 2021.

\bibitem[Sch{\"u}tt et~al.(2017)Sch{\"u}tt, Kindermans, Sauceda~Felix, Chmiela,
  Tkatchenko, and M{\"u}ller]{schutt2017schnet}
Kristof Sch{\"u}tt, Pieter-Jan Kindermans, Huziel~Enoc Sauceda~Felix, Stefan
  Chmiela, Alexandre Tkatchenko, and Klaus-Robert M{\"u}ller.
\newblock Schnet: A continuous-filter convolutional neural network for modeling
  quantum interactions.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Schw{\"o}bel et~al.(2021)Schw{\"o}bel, J{\o}rgensen, Ober, and van~der
  Wilk]{schwobel2021last}
Pola Schw{\"o}bel, Martin J{\o}rgensen, Sebastian~W Ober, and Mark van~der
  Wilk.
\newblock Last layer marginal likelihood for invariance learning.
\newblock \emph{arXiv preprint arXiv:2106.07512}, 2021.

\bibitem[Sitzmann et~al.(2020)Sitzmann, Martel, Bergman, Lindell, and
  Wetzstein]{sitzmann2020implicit}
Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon
  Wetzstein.
\newblock Implicit neural representations with periodic activation functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Sutherland and Schneider(2015)]{sutherland2015error}
Danica~J Sutherland and Jeff Schneider.
\newblock On the error of random fourier features.
\newblock \emph{arXiv preprint arXiv:1506.02785}, 2015.

\bibitem[Tancik et~al.(2020)Tancik, Srinivasan, Mildenhall, Fridovich-Keil,
  Raghavan, Singhal, Ramamoorthi, Barron, and Ng]{tancik2020fourier}
Matthew Tancik, Pratul~P Srinivasan, Ben Mildenhall, Sara Fridovich-Keil,
  Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan~T Barron, and
  Ren Ng.
\newblock Fourier features let networks learn high frequency functions in low
  dimensional domains.
\newblock \emph{arXiv preprint arXiv:2006.10739}, 2020.

\bibitem[van~der Ouderaa and van~der Wilk(2021)]{van2021learning}
Tycho~FA van~der Ouderaa and Mark van~der Wilk.
\newblock Learning invariant weights in neural networks.
\newblock In \emph{Workshop in Uncertainty \& Robustness in Deep Learning,
  ICML}, 2021.

\bibitem[van~der Wilk et~al.(2018)van~der Wilk, Bauer, John, and
  Hensman]{van2018learning}
Mark van~der Wilk, Matthias Bauer, ST~John, and James Hensman.
\newblock Learning invariances using the marginal likelihood.
\newblock \emph{arXiv preprint arXiv:1808.05563}, 2018.

\bibitem[Wang et~al.(2022)Wang, Walters, and Yu]{wang2022approximately}
Rui Wang, Robin Walters, and Rose Yu.
\newblock Approximately equivariant networks for imperfectly symmetric
  dynamics.
\newblock \emph{arXiv preprint arXiv:2201.11969}, 2022.

\bibitem[Weiler et~al.(2018)Weiler, Geiger, Welling, Boomsma, and
  Cohen]{weiler20183d}
Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco Cohen.
\newblock 3d steerable cnns: Learning rotationally equivariant features in
  volumetric data.
\newblock \emph{arXiv preprint arXiv:1807.02547}, 2018.

\bibitem[Worrall and Welling(2019)]{worrall2019deep}
Daniel~E Worrall and Max Welling.
\newblock Deep scale-spaces: Equivariance over scale.
\newblock \emph{arXiv preprint arXiv:1905.11697}, 2019.

\bibitem[Worrall et~al.(2017)Worrall, Garbin, Turmukhambetov, and
  Brostow]{worrall2017harmonic}
Daniel~E Worrall, Stephan~J Garbin, Daniyar Turmukhambetov, and Gabriel~J
  Brostow.
\newblock Harmonic networks: Deep translation and rotation equivariance.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5028--5037, 2017.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan
  Salakhutdinov, and Alexander Smola.
\newblock Deep sets.
\newblock \emph{arXiv preprint arXiv:1703.06114}, 2017.

\bibitem[Zhou et~al.(2020)Zhou, Knowles, and Finn]{zhou2020meta}
Allan Zhou, Tom Knowles, and Chelsea Finn.
\newblock Meta-learning symmetries by reparameterization.
\newblock \emph{arXiv preprint arXiv:2007.02933}, 2020.

\end{thebibliography}
