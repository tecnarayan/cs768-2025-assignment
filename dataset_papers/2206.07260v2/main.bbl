\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Al-Shedivat et~al.(2018)Al-Shedivat, Bansal, Burda, Sutskever,
  Mordatch, and Abbeel]{al2018_reinffsl}
Al-Shedivat, M., Bansal, T., Burda, Y., Sutskever, I., Mordatch, I., and
  Abbeel, P.
\newblock Continuous adaptation via meta-learning in nonstationary and
  competitive environments.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, Shillingford, and De~Freitas]{andrychowicz2016_learningtolearn}
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.~W., Pfau, D., Schaul, T.,
  Shillingford, B., and De~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Antoniou et~al.(2019)Antoniou, Edwards, and
  Storkey]{antoniou2018_mamlpp}
Antoniou, A., Edwards, H., and Storkey, A.
\newblock How to train your {MAML}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Balcan et~al.(2019)Balcan, Khodak, and Talwalkar]{balcan2019_provable}
Balcan, M.-F., Khodak, M., and Talwalkar, A.
\newblock Provable guarantees for gradient-based meta-learning.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2019.

\bibitem[Bertinetto et~al.(2019)Bertinetto, Henriques, Torr, and
  Vedaldi]{bertinetto2019_cifarfsl}
Bertinetto, L., Henriques, J.~F., Torr, P., and Vedaldi, A.
\newblock Meta-learning with differentiable closed-form solvers.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Chen et~al.(2019)Chen, Liu, Kira, Wang, and
  Huang]{chen2019closerfewshot}
Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C., and Huang, J.-B.
\newblock A closer look at few-shot classification.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017_maml}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2017.

\bibitem[Finn et~al.(2018)Finn, Xu, and Levine]{finn2018_probabilisticMAML}
Finn, C., Xu, K., and Levine, S.
\newblock Probabilistic model-agnostic meta-learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Flennerhag et~al.(2019)Flennerhag, Rusu, Pascanu, Visin, Yin, and
  Hadsell]{flennerhag2019_metawarpedgrad}
Flennerhag, S., Rusu, A.~A., Pascanu, R., Visin, F., Yin, H., and Hadsell, R.
\newblock Meta-learning with warped gradient descent.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016_deepbook}
Goodfellow, I., Bengio, Y., and Courville, A.
\newblock \emph{Deep learning}.
\newblock MIT press, 2016.

\bibitem[Grant et~al.(2018)Grant, Finn, Levine, Darrell, and
  Griffiths]{grant2018_recasting}
Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T.
\newblock Recasting gradient-based meta-learning as hierarchical {B}ayes.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gupta et~al.(2020)Gupta, Yadav, and Paull]{gupta2018_lamaml}
Gupta, G., Yadav, K., and Paull, L.
\newblock Look-ahead meta learning for continual learning.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem[Gupta et~al.(2018)Gupta, Koren, and Singer]{gupta2018_shampoo}
Gupta, V., Koren, T., and Singer, Y.
\newblock Shampoo: Preconditioned stochastic tensor optimization.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2018.

\bibitem[Li et~al.(2017)Li, Zhou, Chen, and Li]{li2017_metasgd}
Li, Z., Zhou, F., Chen, F., and Li, H.
\newblock Meta-sgd: Learning to learn quickly for few-shot learning.
\newblock \emph{arXiv preprint arXiv:1707.09835}, 2017.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and Schulman]{nichol2018_reptile}
Nichol, A., Achiam, J., and Schulman, J.
\newblock On first-order meta-learning algorithms.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Oreshkin et~al.(2018)Oreshkin, Rodr{\'\i}guez~L{\'o}pez, and
  Lacoste]{oreshkin2018_tadam}
Oreshkin, B., Rodr{\'\i}guez~L{\'o}pez, P., and Lacoste, A.
\newblock Tadam: Task dependent adaptive metric for improved few-shot learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Park \& Oliva(2019)Park and Oliva]{park2019_metacurvature}
Park, E. and Oliva, J.~B.
\newblock Meta-curvature.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Raghu et~al.(2019)Raghu, Raghu, Bengio, and
  Vinyals]{raghu2019_rapidanil}
Raghu, A., Raghu, M., Bengio, S., and Vinyals, O.
\newblock Rapid learning or feature reuse? {T}owards understanding the
  effectiveness of {MAML}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Rajeswaran et~al.(2019)Rajeswaran, Finn, Kakade, and
  Levine]{rajeswaran2019_implicitgrad}
Rajeswaran, A., Finn, C., Kakade, S.~M., and Levine, S.
\newblock Meta-learning with implicit gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{ravi2017_optfsl}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Ren et~al.(2018)Ren, Triantafillou, Ravi, Snell, Swersky, Tenenbaum,
  Larochelle, and Zemel]{ren2018_metasemisup}
Ren, M., Triantafillou, E., Ravi, S., Snell, J., Swersky, K., Tenenbaum, J.~B.,
  Larochelle, H., and Zemel, R.~S.
\newblock Meta-learning for semi-supervised few-shot classification.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Rusu et~al.(2018)Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero, and
  Hadsell]{rusu2018_leo}
Rusu, A.~A., Rao, D., Sygnowski, J., Vinyals, O., Pascanu, R., Osindero, S.,
  and Hadsell, R.
\newblock Meta-learning with latent embedding optimization.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Simon et~al.(2020)Simon, Koniusz, Nock, and
  Harandi]{simon2020_gradientPrecon}
Simon, C., Koniusz, P., Nock, R., and Harandi, M.
\newblock On modulating the gradient for meta-learning.
\newblock In \emph{European Conference on Computer Vision}. Springer, 2020.

\bibitem[Sun et~al.(2019)Sun, Liu, Chua, and Schiele]{sun2019_metatransfer}
Sun, Q., Liu, Y., Chua, T.-S., and Schiele, B.
\newblock Meta-transfer learning for few-shot learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2019.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016_matchingnet}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{WahCUB_200_2011}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock {T}he {C}altech-{UCSD} {B}irds-200-2011 {D}ataset.
\newblock Technical Report CNS-TR-2011-001, California Institute of Technology,
  2011.

\bibitem[Zhou et~al.(2018)Zhou, Wu, and Li]{zhou2018_conceptspace}
Zhou, F., Wu, B., and Li, Z.
\newblock Deep meta-learning: Learning to learn in the concept space.
\newblock \emph{arXiv preprint arXiv:1802.03596}, 2018.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarli, Kurin, Hofmann, and
  Whiteson]{zintgraf2019_cavia}
Zintgraf, L., Shiarli, K., Kurin, V., Hofmann, K., and Whiteson, S.
\newblock Fast context adaptation via meta-learning.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2019.

\bibitem[Zuo et~al.(2021)Zuo, Avraham, and Drummond]{zuo2021_improved}
Zuo, Y., Avraham, G., and Drummond, T.
\newblock Improved training of generative adversarial networks using decision
  forests.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, 2021.

\end{thebibliography}
