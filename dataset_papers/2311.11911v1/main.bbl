\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal \& Boyd(2020)Agrawal and Boyd]{agrawal2020disciplined}
Agrawal, A. and Boyd, S.
\newblock Disciplined quasiconvex programming.
\newblock \emph{Optimization Letters}, 14:\penalty0 1643--1657, 2020.

\bibitem[Alger(2020)]{MahaBound}
Alger, N.
\newblock Smallest axis-aligned bounding box of hyper-ellipsoid.
\newblock Mathematics Stack Exchange, 2020.
\newblock URL \url{https://math.stackexchange.com/q/3926885}.
\newblock URL:https://math.stackexchange.com/q/3926885 (version: 2020-11-29).

\bibitem[Barocas \& Selbst(2016)Barocas and Selbst]{barocas2016big}
Barocas, S. and Selbst, A.~D.
\newblock Big data's disparate impact.
\newblock \emph{Calif. L. Rev.}, 104:\penalty0 671, 2016.

\bibitem[Benussi et~al.(2022)Benussi, Patane, Wicker, Laurenti, and
  Kwiatkowska]{benussi2022individual}
Benussi, E., Patane, A., Wicker, M., Laurenti, L., and Kwiatkowska, M.
\newblock Individual fairness guarantees for neural networks.
\newblock \emph{arXiv preprint arXiv:2205.05763}, 2022.

\bibitem[Carbone et~al.(2020)Carbone, Wicker, Laurenti, Patane, Bortolussi, and
  Sanguinetti]{carbone2020robustness}
Carbone, G., Wicker, M., Laurenti, L., Patane, A., Bortolussi, L., and
  Sanguinetti, G.
\newblock Robustness of bayesian neural networks to gradient-based attacks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 15602--15613, 2020.

\bibitem[Davenport \& Kalakota(2019)Davenport and
  Kalakota]{davenport2019potential}
Davenport, T. and Kalakota, R.
\newblock The potential for artificial intelligence in healthcare.
\newblock \emph{Future healthcare journal}, 6\penalty0 (2):\penalty0 94, 2019.

\bibitem[Ding et~al.(2021)Ding, Hardt, Miller, and Schmidt]{ding2021retiring}
Ding, F., Hardt, M., Miller, J., and Schmidt, L.
\newblock Retiring adult: New datasets for fair machine learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 6478--6490, 2021.

\bibitem[Doherty et~al.(2023)Doherty, Wicker, Laurenti, and
  Patane]{doherty2023individual}
Doherty, A., Wicker, M., Laurenti, L., and Patane, A.
\newblock Individual fairness in bayesian neural networks.
\newblock \emph{Advances in Approximate Bayesian Inference}, 2023.

\bibitem[Dressel \& Farid(2018)Dressel and Farid]{dressel2018accuracy}
Dressel, J. and Farid, H.
\newblock The accuracy, fairness, and limits of predicting recidivism.
\newblock \emph{Science advances}, 4\penalty0 (1):\penalty0 eaao5580, 2018.

\bibitem[Dua \& Graff(2017)Dua and Graff]{uci}
Dua, D. and Graff, C.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012fairness}
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R.
\newblock Fairness through awareness.
\newblock In \emph{Proceedings of the 3rd innovations in theoretical computer
  science conference}, pp.\  214--226, 2012.

\bibitem[Emrich et~al.(2013)Emrich, Joss{\'e}, Kriegel, Mauder, Niedermayer,
  Renz, Schubert, and Z{\"u}fle]{emrich2013optimal}
Emrich, T., Joss{\'e}, G., Kriegel, H.-P., Mauder, M., Niedermayer, J., Renz,
  M., Schubert, M., and Z{\"u}fle, A.
\newblock Optimal distance bounds for the mahalanobis distance.
\newblock In \emph{International Conference on Similarity Search and
  Applications}, pp.\  175--181. Springer, 2013.

\bibitem[Fazelpour \& Lipton(2020)Fazelpour and
  Lipton]{fazelpour2020algorithmic}
Fazelpour, S. and Lipton, Z.~C.
\newblock Algorithmic fairness from a non-ideal perspective.
\newblock In \emph{Proceedings of the AAAI/ACM Conference on AI, Ethics, and
  Society}, pp.\  57--63, 2020.

\bibitem[Fazlyab et~al.(2019)Fazlyab, Robey, Hassani, Morari, and
  Pappas]{fazlyab2019efficient}
Fazlyab, M., Robey, A., Hassani, H., Morari, M., and Pappas, G.
\newblock Efficient and accurate estimation of lipschitz constants for deep
  neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Gehr et~al.(2018)Gehr, Mirman, Drachsler-Cohen, Tsankov, Chaudhuri,
  and Vechev]{gehr2018ai2}
Gehr, T., Mirman, M., Drachsler-Cohen, D., Tsankov, P., Chaudhuri, S., and
  Vechev, M.
\newblock Ai2: Safety and robustness certification of neural networks with
  abstract interpretation.
\newblock In \emph{2018 IEEE symposium on security and privacy (SP)}, pp.\
  3--18. IEEE, 2018.

\bibitem[Gowal et~al.(2018)Gowal, Dvijotham, Stanforth, Bunel, Qin, Uesato,
  Arandjelovic, Mann, and Kohli]{gowal2018effectiveness}
Gowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C., Uesato, J.,
  Arandjelovic, R., Mann, T., and Kohli, P.
\newblock On the effectiveness of interval bound propagation for training
  verifiably robust models.
\newblock \emph{arXiv preprint arXiv:1810.12715}, 2018.

\bibitem[Gupta \& Kamble(2021)Gupta and Kamble]{gupta2021individual}
Gupta, S. and Kamble, V.
\newblock Individual fairness in hindsight.
\newblock \emph{The Journal of Machine Learning Research}, 22\penalty0
  (1):\penalty0 6386--6420, 2021.

\bibitem[Hu et~al.(2020)Hu, Li, and Yu]{hu2020convergence}
Hu, Y., Li, J., and Yu, C. K.~W.
\newblock Convergence rates of subgradient methods for quasi-convex
  optimization problems.
\newblock \emph{Computational Optimization and Applications}, 77:\penalty0
  183--212, 2020.

\bibitem[Hu et~al.(2022)Hu, Li, Yu, and Yip]{hu2022quasi}
Hu, Y., Li, G., Yu, C. K.~W., and Yip, T.~L.
\newblock Quasi-convex feasibility problems: Subgradient methods and
  convergence rates.
\newblock \emph{European Journal of Operational Research}, 298\penalty0
  (1):\penalty0 45--58, 2022.

\bibitem[John et~al.(2020)John, Vijaykeerthy, and Saha]{john2020verifying}
John, P.~G., Vijaykeerthy, D., and Saha, D.
\newblock Verifying individual fairness in machine learning models.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pp.\
  749--758. PMLR, 2020.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
Katz, G., Barrett, C., Dill, D.~L., Julian, K., and Kochenderfer, M.~J.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In \emph{Computer Aided Verification: 29th International Conference,
  CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part I 30},
  pp.\  97--117. Springer, 2017.

\bibitem[Khedr \& Shoukry(2022)Khedr and Shoukry]{khedr2022certifair}
Khedr, H. and Shoukry, Y.
\newblock Certifair: A framework for certified global fairness of neural
  networks.
\newblock \emph{arXiv preprint arXiv:2205.09927}, 2022.

\bibitem[Madras et~al.(2018)Madras, Creager, Pitassi, and
  Zemel]{madras2018learning}
Madras, D., Creager, E., Pitassi, T., and Zemel, R.
\newblock Learning adversarially fair and transferable representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3384--3393. PMLR, 2018.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Mehrabi et~al.(2021)Mehrabi, Morstatter, Saxena, Lerman, and
  Galstyan]{mehrabi2021survey}
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{ACM Computing Surveys (CSUR)}, 54\penalty0 (6):\penalty0 1--35,
  2021.

\bibitem[Mirman et~al.(2018)Mirman, Gehr, and Vechev]{mirman2018differentiable}
Mirman, M., Gehr, T., and Vechev, M.
\newblock Differentiable abstract interpretation for provably robust neural
  networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3578--3586. PMLR, 2018.

\bibitem[Mukherjee et~al.(2020)Mukherjee, Yurochkin, Banerjee, and
  Sun]{mukherjee2020two}
Mukherjee, D., Yurochkin, M., Banerjee, M., and Sun, Y.
\newblock Two simple ways to learn individual fairness metrics from data.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7097--7107. PMLR, 2020.

\bibitem[Mukherjee et~al.(2022)Mukherjee, Petersen, Yurochkin, and
  Sun]{mukherjee2022domain}
Mukherjee, D., Petersen, F., Yurochkin, M., and Sun, Y.
\newblock Domain adaptation meets individual fairness. and they get along.
\newblock \emph{arXiv preprint arXiv:2205.00504}, 2022.

\bibitem[Peychev et~al.(2022)Peychev, Ruoss, Balunovi{\'c}, Baader, and
  Vechev]{peychev2022latent}
Peychev, M., Ruoss, A., Balunovi{\'c}, M., Baader, M., and Vechev, M.
\newblock Latent space smoothing for individually fair representations.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XIII}, pp.\  535--554.
  Springer, 2022.

\bibitem[Ruoss et~al.(2020)Ruoss, Balunovic, Fischer, and
  Vechev]{ruoss2020learning}
Ruoss, A., Balunovic, M., Fischer, M., and Vechev, M.
\newblock Learning certified individually fair representations.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 7584--7596, 2020.

\bibitem[Sagawa et~al.(2019)Sagawa, Koh, Hashimoto, and
  Liang]{sagawa2019distributionally}
Sagawa, S., Koh, P.~W., Hashimoto, T.~B., and Liang, P.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock \emph{arXiv preprint arXiv:1911.08731}, 2019.

\bibitem[Seyyed-Kalantari et~al.(2021)Seyyed-Kalantari, Zhang, McDermott, Chen,
  and Ghassemi]{seyyed2021underdiagnosis}
Seyyed-Kalantari, L., Zhang, H., McDermott, M.~B., Chen, I.~Y., and Ghassemi,
  M.
\newblock Underdiagnosis bias of artificial intelligence algorithms applied to
  chest radiographs in under-served patient populations.
\newblock \emph{Nature medicine}, 27\penalty0 (12):\penalty0 2176--2182, 2021.

\bibitem[Sharifi-Malvajerdi et~al.(2019)Sharifi-Malvajerdi, Kearns, and
  Roth]{sharifi2019average}
Sharifi-Malvajerdi, S., Kearns, M., and Roth, A.
\newblock Average individual fairness: Algorithms, generalization and
  experiments.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Sinha et~al.(2017)Sinha, Namkoong, Volpi, and
  Duchi]{sinha2017certifying}
Sinha, A., Namkoong, H., Volpi, R., and Duchi, J.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock \emph{arXiv preprint arXiv:1710.10571}, 2017.

\bibitem[Taskesen et~al.(2020)Taskesen, Nguyen, Kuhn, and
  Blanchet]{taskesen2020distributionally}
Taskesen, B., Nguyen, V.~A., Kuhn, D., and Blanchet, J.
\newblock A distributionally robust approach to fair classification.
\newblock \emph{arXiv preprint arXiv:2007.09530}, 2020.

\bibitem[Wicker et~al.(2021)Wicker, Laurenti, Patane, Chen, Zhang, and
  Kwiatkowska]{wicker2021bayesian}
Wicker, M., Laurenti, L., Patane, A., Chen, Z., Zhang, Z., and Kwiatkowska, M.
\newblock Bayesian inference with certifiable adversarial robustness.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  2431--2439. PMLR, 2021.

\bibitem[Xu et~al.()Xu, Zhou, An, Ai, and Huang]{xu2022gfairhint}
Xu, P., Zhou, Y., An, B., Ai, W., and Huang, F.
\newblock Gfairhint: Improving individual fairness for graph neural networks
  via fairness hint.
\newblock In \emph{Workshop on Trustworthy and Socially Responsible Machine
  Learning, NeurIPS 2022}.

\bibitem[Yeom \& Fredrikson(2020)Yeom and Fredrikson]{yeom2020individual}
Yeom, S. and Fredrikson, M.
\newblock Individual fairness revisited: Transferring techniques from
  adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2002.07738}, 2020.

\bibitem[Yurochkin \& Sun(2020)Yurochkin and Sun]{yurochkin2020sensei}
Yurochkin, M. and Sun, Y.
\newblock Sensei: Sensitive set invariance for enforcing individual fairness.
\newblock \emph{arXiv preprint arXiv:2006.14168}, 2020.

\bibitem[Yurochkin et~al.(2019)Yurochkin, Bower, and
  Sun]{yurochkin2019training}
Yurochkin, M., Bower, A., and Sun, Y.
\newblock Training individually fair ml models with sensitive subspace
  robustness.
\newblock \emph{arXiv preprint arXiv:1907.00020}, 2019.

\bibitem[Zilka et~al.(2022)Zilka, Butcher, and Weller]{zilka2022survey}
Zilka, M., Butcher, B., and Weller, A.
\newblock A survey and datasheet repository of publicly available us criminal
  justice datasets.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 28008--28022, 2022.

\end{thebibliography}
