\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahnert and Abel(2007)]{ahnert2007numerical}
Karsten Ahnert and Markus Abel.
\newblock Numerical differentiation of experimental data: local versus global
  methods.
\newblock \emph{Computer Physics Communications}, 177\penalty0 (10):\penalty0
  764--774, 2007.

\bibitem[Alexandari et~al.(2020)Alexandari, Kundaje, and
  Shrikumar]{alexandari2020maximum}
Amr Alexandari, Anshul Kundaje, and Avanti Shrikumar.
\newblock Maximum likelihood with bias-corrected calibration is hard-to-beat at
  label shift adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  222--232. PMLR, 2020.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and
  Dan Man{\'e}.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Azizzadenesheli et~al.(2019)Azizzadenesheli, Liu, Yang, and
  Anandkumar]{azizzadenesheli2019regularized}
Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Animashree Anandkumar.
\newblock Regularized learning for domain adaptation under label shifts.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Ben-David et~al.(2007)Ben-David, Blitzer, Crammer, Pereira,
  et~al.]{ben2007analysis}
Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et~al.
\newblock Analysis of representations for domain adaptation.
\newblock In \emph{Advances in neural information processing systems},
  volume~19, page 137. MIT; 1998, 2007.

\bibitem[Cao et~al.(2019)Cao, Wei, Gaidon, Arechiga, and
  Ma]{NEURIPS2019_621461af}
Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma.
\newblock Learning imbalanced datasets with label-distribution-aware margin
  loss.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32. Curran Associates, Inc., 2019.

\bibitem[Cortes and Vapnik(1995)]{cortes1995support}
Corinna Cortes and Vladimir Vapnik.
\newblock Support-vector networks.
\newblock \emph{Machine learning}, 20\penalty0 (3):\penalty0 273--297, 1995.

\bibitem[Cui et~al.(2019)Cui, Jia, Lin, Song, and Belongie]{cui2019class}
Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie.
\newblock Class-balanced loss based on effective number of samples.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9268--9277, 2019.

\bibitem[Damodaran et~al.(2018)Damodaran, Kellenberger, Flamary, Tuia, and
  Courty]{damodaran2018deepjdot}
Bharath~Bhushan Damodaran, Benjamin Kellenberger, R{\'e}mi Flamary, Devis Tuia,
  and Nicolas Courty.
\newblock Deepjdot: Deep joint distribution optimal transport for unsupervised
  domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 447--463, 2018.

\bibitem[Garg et~al.(2020)Garg, Wu, Balakrishnan, and Lipton]{garg2020unified}
Saurabh Garg, Yifan Wu, Sivaraman Balakrishnan, and Zachary~C Lipton.
\newblock A unified view of label shift estimation.
\newblock \emph{arXiv preprint arXiv:2003.07554}, 2020.

\bibitem[Gretton et~al.(2009)Gretton, Smola, Huang, Schmittfull, Borgwardt, and
  Sch{\"o}lkopf]{gretton2009covariate}
Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten
  Borgwardt, and Bernhard Sch{\"o}lkopf.
\newblock Covariate shift by kernel mean matching.
\newblock \emph{Dataset shift in machine learning}, 3\penalty0 (4):\penalty0 5,
  2009.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  1321--1330. PMLR, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Hoffman et~al.(2014)Hoffman, Darrell, and
  Saenko]{hoffman2014continuous}
Judy Hoffman, Trevor Darrell, and Kate Saenko.
\newblock Continuous manifold based adaptation for evolving visual domains.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 867--874, 2014.

\bibitem[Hoffman et~al.(2018)Hoffman, Mohri, and Zhang]{hoffman2018algorithms}
Judy Hoffman, Mehryar Mohri, and Ningshan Zhang.
\newblock Algorithms and theory for multiple-source adaptation.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 8256--8266, 2018.

\bibitem[Huang et~al.(2016)Huang, Li, Loy, and Tang]{huang2016learning}
Chen Huang, Yining Li, Chen~Change Loy, and Xiaoou Tang.
\newblock Learning deep representation for imbalanced classification.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5375--5384, 2016.

\bibitem[Huang et~al.(2006)Huang, Gretton, Borgwardt, Sch{\"o}lkopf, and
  Smola]{huang2006correcting}
Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Sch{\"o}lkopf, and
  Alex Smola.
\newblock Correcting sample selection bias by unlabeled data.
\newblock In \emph{Advances in neural information processing systems},
  volume~19, pages 601--608. Citeseer, 2006.

\bibitem[Jain and Learned-Miller(2011)]{jain2011online}
Vidit Jain and Erik Learned-Miller.
\newblock Online domain adaptation of a pre-trained cascade of classifiers.
\newblock In \emph{CVPR 2011}, pages 577--584. IEEE, 2011.

\bibitem[Kang et~al.(2019)Kang, Jiang, Yang, and
  Hauptmann]{kang2019contrastive}
Guoliang Kang, Lu~Jiang, Yi~Yang, and Alexander~G Hauptmann.
\newblock Contrastive adaptation network for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 4893--4902, 2019.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lin et~al.(2002)Lin, Lee, and Wahba]{lin2002support}
Yi~Lin, Yoonkyung Lee, and Grace Wahba.
\newblock Support vector machines for classification in nonstandard situations.
\newblock \emph{Machine learning}, 46\penalty0 (1):\penalty0 191--202, 2002.

\bibitem[Lipton et~al.(2018)Lipton, Wang, and Smola]{lipton2018detecting}
Zachary Lipton, Yu-Xiang Wang, and Alexander Smola.
\newblock Detecting and correcting for label shift with black box predictors.
\newblock In \emph{International conference on machine learning}, pages
  3122--3130. PMLR, 2018.

\bibitem[Mansour et~al.(2009)Mansour, Mohri, and
  Rostamizadeh]{mansour2009domain}
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
\newblock Domain adaptation: Learning bounds and algorithms.
\newblock In \emph{22nd Conference on Learning Theory, COLT 2009}, 2009.

\bibitem[Mullapudi et~al.(2019)Mullapudi, Chen, Zhang, Ramanan, and
  Fatahalian]{mullapudi2019online}
Ravi~Teja Mullapudi, Steven Chen, Keyi Zhang, Deva Ramanan, and Kayvon
  Fatahalian.
\newblock Online model distillation for efficient video inference.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 3573--3582, 2019.

\bibitem[Murphy(2012)]{murphy2012machine}
Kevin~P Murphy.
\newblock \emph{Machine learning: a probabilistic perspective}.
\newblock MIT press, 2012.

\bibitem[Niculescu-Mizil and Caruana(2005)]{niculescu2005predicting}
Alexandru Niculescu-Mizil and Rich Caruana.
\newblock Predicting good probabilities with supervised learning.
\newblock In \emph{Proceedings of the 22nd international conference on Machine
  learning}, pages 625--632, 2005.

\bibitem[Quinlan(1986)]{quinlan1986induction}
J.~Ross Quinlan.
\newblock Induction of decision trees.
\newblock \emph{Machine learning}, 1\penalty0 (1):\penalty0 81--106, 1986.

\bibitem[Qui{\~n}onero-Candela et~al.(2009)Qui{\~n}onero-Candela, Sugiyama,
  Lawrence, and Schwaighofer]{quinonero2009dataset}
Joaquin Qui{\~n}onero-Candela, Masashi Sugiyama, Neil~D Lawrence, and Anton
  Schwaighofer.
\newblock \emph{Dataset shift in machine learning}.
\newblock Mit Press, 2009.

\bibitem[Rozantsev et~al.(2019)Rozantsev, Salzmann, and
  Fua]{rozantsev2019beyond}
Artem Rozantsev, Mathieu Salzmann, and Pascal Fua.
\newblock Beyond sharing weights for deep domain adaptation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 41\penalty0 (4):\penalty0 801--814, 2019.

\bibitem[Saerens et~al.(2002)Saerens, Latinne, and
  Decaestecker]{saerens2002adjusting}
Marco Saerens, Patrice Latinne, and Christine Decaestecker.
\newblock Adjusting the outputs of a classifier to new a priori probabilities:
  a simple procedure.
\newblock \emph{Neural Computation}, 14\penalty0 (1):\penalty0 21--41, 2002.

\bibitem[Sch{\"o}lkopf et~al.(2012)Sch{\"o}lkopf, Janzing, Peters, Sgouritsa,
  Zhang, and Mooij]{scholkopf2012causal}
Bernhard Sch{\"o}lkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun
  Zhang, and Joris~M Mooij.
\newblock On causal and anticausal learning.
\newblock In \emph{ICML}, 2012.

\bibitem[Shalev-Shwartz et~al.(2011)]{shalev2011online}
Shai Shalev-Shwartz et~al.
\newblock Online learning and online convex optimization.
\newblock \emph{Foundations and trends in Machine Learning}, 4\penalty0
  (2):\penalty0 107--194, 2011.

\bibitem[Shen et~al.(2018)Shen, Qu, Zhang, and Yu]{shen2018wasserstein}
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu.
\newblock Wasserstein distance guided representation learning for domain
  adaptation.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Shimodaira(2000)]{shimodaira2000improving}
Hidetoshi Shimodaira.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock \emph{Journal of statistical planning and inference}, 90\penalty0
  (2):\penalty0 227--244, 2000.

\bibitem[Sun et~al.(2016)Sun, Feng, and Saenko]{sun2016return}
Baochen Sun, Jiashi Feng, and Kate Saenko.
\newblock Return of frustratingly easy domain adaptation.
\newblock In \emph{Proceedings of the Thirtieth AAAI Conference on Artificial
  Intelligence}, pages 2058--2065, 2016.

\bibitem[Sun et~al.(2020)Sun, Wang, Liu, Miller, Efros, and Hardt]{sun2020test}
Yu~Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under
  distribution shifts.
\newblock In \emph{International Conference on Machine Learning}, pages
  9229--9248. PMLR, 2020.

\bibitem[Tachet~des Combes et~al.(2020)Tachet~des Combes, Zhao, Wang, and
  Gordon]{combes2020domain}
Remi Tachet~des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey~J Gordon.
\newblock Domain adaptation with conditional distribution matching and
  generalized label shift.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem[Tewari and Bartlett(2007)]{tewari2007consistency}
Ambuj Tewari and Peter~L Bartlett.
\newblock On the consistency of multiclass classification methods.
\newblock \emph{Journal of Machine Learning Research}, 8\penalty0 (5), 2007.

\bibitem[Wang et~al.(2017)Wang, Ramanan, and Hebert]{wang2017learning}
Yu-Xiong Wang, Deva Ramanan, and Martial Hebert.
\newblock Learning to model the tail.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 7032--7042, 2017.

\bibitem[Zadrozny(2004)]{zadrozny2004learning}
Bianca Zadrozny.
\newblock Learning and evaluating classifiers under sample selection bias.
\newblock In \emph{Proceedings of the Twenty-First International Conference on
  Machine Learning}, page 114, 2004.

\bibitem[Zadrozny and Elkan(2001)]{zadrozny2001obtaining}
Bianca Zadrozny and Charles Elkan.
\newblock Obtaining calibrated probability estimates from decision trees and
  naive bayesian classifiers.
\newblock In \emph{International Conference on Machine Learning}, volume~1,
  pages 609--616, 2001.

\bibitem[Zhang et~al.(2013)Zhang, Sch{\"o}lkopf, Muandet, and
  Wang]{zhang2013domain}
Kun Zhang, Bernhard Sch{\"o}lkopf, Krikamol Muandet, and Zhikun Wang.
\newblock Domain adaptation under target and conditional shift.
\newblock In \emph{International Conference on Machine Learning}, pages
  819--827. PMLR, 2013.

\end{thebibliography}
