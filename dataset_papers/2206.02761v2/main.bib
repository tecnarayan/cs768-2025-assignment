@article{oktay2018attention,
  title={Attention u-net: Learning where to look for the pancreas},
  author={Oktay, Ozan and Schlemper, Jo and Folgoc, Loic Le and Lee, Matthew and Heinrich, Mattias and Misawa, Kazunari and Mori, Kensaku and McDonagh, Steven and Hammerla, Nils Y and Kainz, Bernhard and others},
  journal={arXiv preprint arXiv:1804.03999},
  year={2018}
}

@INPROCEEDINGS{gradcam,
  author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}, 
  year={2017},
  volume={},
  number={},
  pages={618-626},
  doi={10.1109/ICCV.2017.74}}
  
@InProceedings{deeplift, title = {Learning Important Features Through Propagating Activation Differences}, author = {Avanti Shrikumar and Peyton Greenside and Anshul Kundaje}, booktitle = {Proceedings of the 34th International Conference on Machine Learning}, pages = {3145--3153}, year = {2017}, editor = {Precup, Doina and Teh, Yee Whye}, volume = {70}, series = {Proceedings of Machine Learning Research}, month = {06--11 Aug}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v70/shrikumar17a/shrikumar17a.pdf}, url = { http://proceedings.mlr.press/v70/shrikumar17a.html }, abstract = {The purported “black box” nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its `reference activation’ and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. Video tutorial: http://goo.gl/qKb7pL code: http://goo.gl/RM8jvH} }

@inproceedings{domke,
 author = {Domke, Justin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Implicit Differentiation by Perturbation},
 url = {https://proceedings.neurips.cc/paper/2010/file/6ecbdd6ec859d284dc13885a37ce8d81-Paper.pdf},
 volume = {23},
 year = {2010}
}

@article{brats1,
  title={The multimodal brain tumor image segmentation benchmark (BRATS)},
  author={Menze, Bjoern H and Jakab, Andras and Bauer, Stefan and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Kirby, Justin and Burren, Yuliya and Porz, Nicole and Slotboom, Johannes and Wiest, Roland and others},
  journal={IEEE transactions on medical imaging},
  volume={34},
  number={10},
  pages={1993--2024},
  year={2014},
  publisher={IEEE}
}

@article{brats2,
  title={Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features},
  author={Bakas, Spyridon and Akbari, Hamed and Sotiras, Aristeidis and Bilello, Michel and Rozycki, Martin and Kirby, Justin S and Freymann, John B and Farahani, Keyvan and Davatzikos, Christos},
  journal={Scientific data},
  volume={4},
  number={1},
  pages={1--13},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{brats3,
  title={Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge},
  author={Bakas, Spyridon and Reyes, Mauricio and Jakab, Andras and Bauer, Stefan and Rempfler, Markus and Crimi, Alessandro and Shinohara, Russell Takeshi and Berger, Christoph and Ha, Sung Min and Rozycki, Martin and others},
  journal={arXiv preprint arXiv:1811.02629},
  year={2018}
}


@inproceedings{unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{lrp,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science}
}

@article{negperturb,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE}
}

@article{fdg,
title = {Altered Biodistribution on FDG-PET with Emphasis on Brown Fat and Insulin Effect},
journal = {Seminars in Nuclear Medicine},
volume = {40},
number = {4},
pages = {283-293},
year = {2010},
note = {Altered Biodistribution and Incidental Findings},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2010.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0001299810000048},
author = {Christian Cohade},
abstract = {18F-fluorodeoxyglucose (FDG) is the radiotracer used in the vast majority of positron emission tomography (PET) cancer studies. FDG is a powerful radiotracer that provides valuable data in many cancer types. Normal FDG biodistribution is easily identified. In the PET-only era, physiological uptake provided important anatomical landmarks. However, the normal biodistribution of FDG is often variable and can be altered by intrinsic or iatrogenic factors. Recognizing these patterns of altered biodistribution is important for optimal FDG-PET interpretation. Altered FDG uptake in muscles, brown adipose tissue, bone marrow, the urinary tract, and the bowel is demonstrated in a significant proportion of patients, which can hide underlying malignant foci or mimic malignant lesions. The introduction of PET/computed tomography revolutionized PET imaging, bringing much-needed anatomical information. This modality allowed better characterization of some types of uptake, particularly brown adipose tissue FDG uptake. Different approaches to minimize interference from altered FDG biodistribution should be considered when performing PET scans. Otherwise, careful review and correlation of metabolic (FDG-PET) and anatomical (computed tomography) data should be performed to accurately characterize the foci of increased FDG uptake.}
}

@article{chefer2020transformer,
  title={Transformer Interpretability Beyond Attention Visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  journal={arXiv preprint arXiv:2012.09838},
  year={2020}
}

@article{dtd,
  title={Explaining nonlinear classification decisions with deep taylor decomposition},
  author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Pattern Recognition},
  volume={65},
  pages={211--222},
  year={2017},
  publisher={Elsevier}
}

@ARTICLE{xairev1,
  author={Samek, Wojciech and Montavon, Grégoire and Lapuschkin, Sebastian and Anders, Christopher J. and Müller, Klaus-Robert},
  journal={Proceedings of the IEEE}, 
  title={Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications}, 
  year={2021},
  volume={109},
  number={3},
  pages={247-278},
  doi={10.1109/JPROC.2021.3060483}}
  
@inproceedings{intgrad,
title={Axiomatic attribution for deep networks},
author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
booktitle={International Conference on Machine Learning},
pages={3319--3328},
year={2017},
organization={PMLR}
}

@inproceedings{fullgrad,
 author = {Srinivas, Suraj and Fleuret, Fran\c{c}ois},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Full-Gradient Representation for Neural Network Visualization},
 url = {https://proceedings.neurips.cc/paper/2019/file/80537a945c7aaa788ccfcdf1b99b5d8f-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@inproceedings{lime,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{shap,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott and Lee, Su-In},
  journal={arXiv preprint arXiv:1705.07874},
  year={2017}
}


@InProceedings{l2x,
  title = 	 {Learning to Explain: An Information-Theoretic Perspective on Model Interpretation},
  author =       {Chen, Jianbo and Song, Le and Wainwright, Martin and Jordan, Michael},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {883--892},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/chen18j/chen18j.pdf},
  url = 	 {http://proceedings.mlr.press/v80/chen18j.html},
  abstract = 	 {We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show the effectiveness of our method on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.}
}

@inproceedings{saliency_gal,
 author = {Dabkowski, Piotr and Gal, Yarin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Real Time Image Saliency for Black Box Classifiers},
 url = {https://proceedings.neurips.cc/paper/2017/file/0060ef47b12160b9198302ebdb144dcf-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{saliency_simonyan,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  year={2014},
  publisher={Iclr}
}

@article{saliency_mahendran,
  title={Visualizing deep convolutional neural networks using natural pre-images},
  author={Mahendran, Aravindh and Vedaldi, Andrea},
  journal={International Journal of Computer Vision},
  volume={120},
  number={3},
  pages={233--255},
  year={2016},
  publisher={Springer}
}

@inproceedings{saliency_zhou,
  title={Learning deep features for discriminative localization},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2921--2929},
  year={2016}
}

@article{excit,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}

@inproceedings{saliency_zeiler,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@inproceedings{input_perturb,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2950--2958},
  year={2019}
}

@inproceedings{input_perturb2,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3429--3437},
  year={2017}
}

@inproceedings{sanity,
 author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sanity Checks for Saliency Maps},
 url = {https://proceedings.neurips.cc/paper/2018/file/294a8ed24b1ad22ec2e7efea049b8737-Paper.pdf},
 volume = {31},
 year = {2018}
}



@article{aiayn,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{attn_isnot,
  title={Attention is not explanation},
  author={Jain, Sarthak and Wallace, Byron C},
  journal={arXiv preprint arXiv:1902.10186},
  year={2019}
}

@article{attn_isnotnot,
  title={Attention is not not explanation},
  author={Wiegreffe, Sarah and Pinter, Yuval},
  journal={arXiv preprint arXiv:1908.04626},
  year={2019}
}

@article{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{mri_related,
  title={Visualizing deep neural network decisions: Prediction difference analysis},
  author={Zintgraf, Luisa M and Cohen, Taco S and Adel, Tameem and Welling, Max},
  journal={arXiv preprint arXiv:1702.04595},
  year={2017}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{trans_luke,
  title={LUKE: deep contextualized entity representations with entity-aware self-attention},
  author={Yamada, Ikuya and Asai, Akari and Shindo, Hiroyuki and Takeda, Hideaki and Matsumoto, Yuji},
  journal={arXiv preprint arXiv:2010.01057},
  year={2020}
}

@inproceedings{trans_wang,
  title={Improving neural language modeling via adversarial training},
  author={Wang, Dilin and Gong, Chengyue and Liu, Qiang},
  booktitle={International Conference on Machine Learning},
  pages={6555--6565},
  year={2019},
  organization={PMLR}
}

@article{trans_mehta,
  title={DeLighT: Very Deep and Light-weight Transformer},
  author={Mehta, Sachin and Ghazvininejad, Marjan and Iyer, Srinivasan and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2008.00623},
  year={2020}
}

@article{trans_jiang,
  title={Smart: Robust and efficient fine-tuning for pre-trained natural language models through principled regularized optimization},
  author={Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Zhao, Tuo},
  journal={arXiv preprint arXiv:1911.03437},
  year={2019}
}

@article{trans_raffel,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@article{trans_lan,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{fresh,
  title={Learning to faithfully rationalize by construction},
  author={Jain, Sarthak and Wiegreffe, Sarah and Pinter, Yuval and Wallace, Byron C},
  journal={arXiv preprint arXiv:2005.00115},
  year={2020}
}

@article{yu,
  title={Rethinking cooperative rationalization: Introspective extraction and complement control},
  author={Yu, Mo and Chang, Shiyu and Zhang, Yang and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1910.13294},
  year={2019}
}

@article{self_attn1,
  title={Stand-alone self-attention in vision models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
  journal={arXiv preprint arXiv:1906.05909},
  year={2019}
}

@inproceedings{self_attn2,
  title={Attention augmented convolutional networks},
  author={Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3286--3295},
  year={2019}
}

@inproceedings{self_attn3,
  title={Local relation networks for image recognition},
  author={Hu, Han and Zhang, Zheng and Xie, Zhenda and Lin, Stephen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3464--3473},
  year={2019}
}

@inproceedings{self_attn4,
  title={Psanet: Point-wise spatial attention network for scene parsing},
  author={Zhao, Hengshuang and Zhang, Yi and Liu, Shu and Shi, Jianping and Loy, Chen Change and Lin, Dahua and Jia, Jiaya},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={267--283},
  year={2018}
}

@inproceedings{self_attn5,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@inproceedings{self_attn6,
  title={Residual attention network for image classification},
  author={Wang, Fei and Jiang, Mengqing and Qian, Chen and Yang, Shuo and Li, Cheng and Zhang, Honggang and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3156--3164},
  year={2017}
}

@inproceedings{high_order,
 author = {Schwartz, Idan and Schwing, Alexander and Hazan, Tamir},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {High-Order Attention Models for Visual Question Answering},
 url = {https://proceedings.neurips.cc/paper/2017/file/051928341be67dcba03f0e04104d9047-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{vqa2,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{vqa3,
  title={Multi-level attention networks for visual question answering},
  author={Yu, Dongfei and Fu, Jianlong and Mei, Tao and Rui, Yong},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4709--4717},
  year={2017}
}

@inproceedings{fga,
  title={Factor graph attention},
  author={Schwartz, Idan and Yu, Seunghak and Hazan, Tamir and Schwing, Alexander G},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2039--2048},
  year={2019}
}

@inproceedings{aware,
  title={A simple baseline for audio-visual scene-aware dialog},
  author={Schwartz, Idan and Schwing, Alexander G and Hazan, Tamir},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12548--12558},
  year={2019}
}

@inproceedings{visdial,
    title = "Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog",
    author = "Gan, Zhe  and
      Cheng, Yu  and
      Kholy, Ahmed  and
      Li, Linjie  and
      Liu, Jingjing  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1648",
    doi = "10.18653/v1/P19-1648",
    pages = "6463--6474",
    abstract = "This paper presents a new model for visual dialog, Recurrent Dual Attention Network (ReDAN), using multi-step reasoning to answer a series of questions about an image. In each question-answering turn of a dialog, ReDAN infers the answer progressively through multiple reasoning steps. In each step of the reasoning process, the semantic representation of the question is updated based on the image and the previous dialog history, and the recurrently-refined representation is used for further reasoning in the subsequent step. On the VisDial v1.0 dataset, the proposed ReDAN model achieves a new state-of-the-art of 64.47{\%} NDCG score. Visualization on the reasoning process further demonstrates that ReDAN can locate context-relevant visual and textual clues via iterative refinement, which can lead to the correct answer step-by-step.",
}

@article{path,
  title={Pathologies of neural models make interpretations difficult},
  author={Feng, Shi and Wallace, Eric and Grissom II, Alvin and Iyyer, Mohit and Rodriguez, Pedro and Boyd-Graber, Jordan},
  journal={arXiv preprint arXiv:1804.07781},
  year={2018}
}

@article{towards,
  title={Towards better understanding of gradient-based attribution methods for deep neural networks},
  author={Ancona, Marco and Ceolini, Enea and {\"O}ztireli, Cengiz and Gross, Markus},
  journal={arXiv preprint arXiv:1711.06104},
  year={2017}
}

@article{ltpa,
  title={Learn to pay attention},
  author={Jetley, Saumya and Lord, Nicholas A and Lee, Namhoon and Torr, Philip HS},
  journal={arXiv preprint arXiv:1804.02391},
  year={2018}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{connor2004visual,
  title={Visual attention: bottom-up versus top-down},
  author={Connor, Charles E and Egeth, Howard E and Yantis, Steven},
  journal={Current biology},
  volume={14},
  number={19},
  pages={R850--R852},
  year={2004},
  publisher={Elsevier}
}

@article{gradishar2018breast,
  title={Breast cancer, version 4.2017, NCCN clinical practice guidelines in oncology},
  author={Gradishar, William J and Anderson, Benjamin O and Balassanian, Ron and Blair, Sarah L and Burstein, Harold J and Cyr, Amy and Elias, Anthony D and Farrar, William B and Forero, Andres and Giordano, Sharon H and others},
  journal={Journal of the National Comprehensive Cancer Network},
  volume={16},
  number={3},
  pages={310--320},
  year={2018},
  publisher={Harborside Press, LLC}
}

@article{jemal2009cancer,
  title={Cancer statistics, 2009},
  author={Jemal, Ahmedin and Siegel, Rebecca and Ward, Elizabeth and Hao, Yongping and Xu, Jiaquan and Thun, Michael J},
  journal={CA: a cancer journal for clinicians},
  volume={59},
  number={4},
  pages={225--249},
  year={2009},
  publisher={Wiley Online Library}
}

@article{groheux2011yield,
  title={The yield of 18F-FDG PET/CT in patients with clinical stage IIA, IIB, or IIIA breast cancer: a prospective study},
  author={Groheux, David and Giacchetti, Sylvie and Espi{\'e}, Marc and Vercellino, Laetitia and Hamy, Anne-Sophie and Delord, Marc and Berenger, Nathalie and Toubert, Marie-Elisabeth and Misset, Jean-Louis and Hindi{\'e}, Elif},
  journal={Journal of Nuclear Medicine},
  volume={52},
  number={10},
  pages={1526--1534},
  year={2011},
  publisher={Soc Nuclear Med}
}

@article{ben200918f,
  title={18F-FDG PET and PET/CT in the evaluation of cancer treatment response},
  author={Ben-Haim, Simona and Ell, Peter},
  journal={Journal of Nuclear Medicine},
  volume={50},
  number={1},
  pages={88--99},
  year={2009},
  publisher={Soc Nuclear Med}
}

@article{shammas2009pediatric,
  title={Pediatric FDG PET/CT: physiologic uptake, normal variants, and benign conditions},
  author={Shammas, Amer and Lim, Ruth and Charron, Martin},
  journal={Radiographics},
  volume={29},
  number={5},
  pages={1467--1486},
  year={2009},
  publisher={Radiological Society of North America}
}

@article{nakajo2007efficacy,
  title={The efficacy of whole-body FDG-PET or PET/CT for autoimmune pancreatitis and associated extrapancreatic autoimmune lesions},
  author={Nakajo, Masatoyo and Jinnouchi, Seishi and Fukukura, Yoshihiko and Tanabe, Hiroaki and Tateno, Rie and Nakajo, Masayuki},
  journal={European journal of nuclear medicine and molecular imaging},
  volume={34},
  number={12},
  pages={2088--2095},
  year={2007},
  publisher={Springer}
}

@inproceedings{cohade2010altered,
  title={Altered biodistribution on FDG-PET with emphasis on brown fat and insulin effect},
  author={Cohade, Christian},
  booktitle={Seminars in nuclear medicine},
  volume={40},
  number={4},
  pages={283--293},
  year={2010},
  organization={Elsevier}
}

@article{yeung2003patterns,
  title={Patterns of 18F-FDG uptake in adipose tissue and muscle: a potential source of false-positives for PET},
  author={Yeung, Henry WD and Grewal, Ravinder K and Gonen, Mithat and Sch{\"o}der, Heiko and Larson, Steven M},
  journal={Journal of Nuclear Medicine},
  volume={44},
  number={11},
  pages={1789--1796},
  year={2003},
  publisher={Soc Nuclear Med}
}

@book{vtk,
  author={Will Schroeder and Ken Martin and Bill Lorensen},
  title={{The Visualization Toolkit--An Object-Oriented Approach To 3D
                  Graphics}},
  publisher={Kitware, Inc.},
  edition={Fourth},
  year={2006}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@Book{berts,
 Author = {Dimitri P. {Bertsekas} and Angelia {Nedic} and Asuman E. {Ozdaglar}},
 Title = {{Convex analysis and optimization}},
 ISBN = {1-886529-45-0},
 Pages = {569},
 Year = {2003},
 Publisher = {Belmont, MA: Athena Scientific},
 Language = {English},
 MSC2010 = {90-00 90B25},
 Zbl = {1140.90001}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}


@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}

@book{pyomo,
title={Pyomo--optimization modeling in python},
author={Bynum, Michael L. and Hackebeil, Gabriel A. and Hart, William E. and Laird, Carl D. and Nicholson, Bethany L. and Siirola, John D. and Watson, Jean-Paul and Woodruff, David L.},
edition={Third},
volume={67},
year={2021},
publisher={Springer Science \& Business Media}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@misc{kokhlikyan2020captum,
    title={Captum: A unified and generic model interpretability library for PyTorch},
    author={Narine Kokhlikyan and Vivek Miglani and Miguel Martin and Edward Wang and Bilal Alsallakh and Jonathan Reynolds and Alexander Melnikov and Natalia Kliushkina and Carlos Araya and Siqi Yan and Orion Reblitz-Richardson},
    year={2020},
    eprint={2009.07896},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{fritz,
title = {The Fritz John necessary optimality conditions in the presence of equality and inequality constraints},
journal = {Journal of Mathematical Analysis and Applications},
volume = {17},
number = {1},
pages = {37-47},
year = {1967},
issn = {0022-247X},
doi = {https://doi.org/10.1016/0022-247X(67)90163-1},
url = {https://www.sciencedirect.com/science/article/pii/0022247X67901631},
author = {O.L Mangasarian and S Fromovitz}
}

@article{outperform1,
title = {Deep neural networks outperform human expert's capacity in characterizing bioleaching bacterial biofilm composition},
journal = {Biotechnology Reports},
volume = {22},
pages = {e00321},
year = {2019},
issn = {2215-017X},
doi = {https://doi.org/10.1016/j.btre.2019.e00321},
url = {https://www.sciencedirect.com/science/article/pii/S2215017X18301954},
author = {Antoine Buetti-Dinh and Vanni Galli and Sören Bellenberg and Olga Ilie and Malte Herold and Stephan Christel and Mariia Boretska and Igor V. Pivkin and Paul Wilmes and Wolfgang Sand and Mario Vera and Mark Dopson},
keywords = {Deep learning, Convolutional neural networks, Biomining, Acidophiles, Bacterial biofilm, Microscopy imaging},
abstract = {Background
Deep neural networks have been successfully applied to diverse fields of computer vision. However, they only outperform human capacities in a few cases.
Methods
The ability of deep neural networks versus human experts to classify microscopy images was tested on biofilm colonization patterns formed on sulfide minerals composed of up to three different bioleaching bacterial species attached to chalcopyrite sample particles.
Results
A low number of microscopy images per category (<600) was sufficient for highly efficient computational analysis of the biofilm's bacterial composition. The use of deep neural networks reached an accuracy of classification of ∼90\% compared to ∼50\% for human experts.
Conclusions
Deep neural networks outperform human experts’ capacity in characterizing bacterial biofilm composition involved in the degradation of chalcopyrite. This approach provides an alternative to standard, time-consuming biochemical methods.}
}

@inproceedings{shatt,
  title={The shattered gradients problem: If resnets are the answer, then what is the question?},
  author={Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian},
  booktitle={International Conference on Machine Learning},
  pages={342--350},
  year={2017},
  organization={PMLR}
}

@inproceedings{faith,
  author    = {Andrew Slavin Ross and Michael C. Hughes and Finale Doshi-Velez},
  title     = {Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI-17}},
  pages     = {2662--2670},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/371},
  url       = {https://doi.org/10.24963/ijcai.2017/371},
}

@inproceedings{convex_layer,
 author = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, J. Zico},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Differentiable Convex Optimization Layers},
 url = {https://proceedings.neurips.cc/paper/2019/file/9ce3c52fc54362e22053399d3181c638-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{berthet,
 author = {Berthet, Quentin and Blondel, Mathieu and Teboul, Olivier and Cuturi, Marco and Vert, Jean-Philippe and Bach, Francis},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {9508--9519},
 publisher = {Curran Associates, Inc.},
 title = {Learning with Differentiable Pertubed Optimizers},
 url = {https://proceedings.neurips.cc/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf},
 volume = {33},
 year = {2020}
}


@article{sst,
  title={Gradient estimation with stochastic softmax tricks},
  author={Paulus, Max B and Choi, Dami and Tarlow, Daniel and Krause, Andreas and Maddison, Chris J},
  journal={arXiv preprint arXiv:2006.08063},
  year={2020}
}


@InProceedings{amos,
  title = 	 {{O}pt{N}et: Differentiable Optimization as a Layer in Neural Networks},
  author =       {Brandon Amos and J. Zico Kolter},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {136--145},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/amos17a/amos17a.pdf},
  url = 	 {
http://proceedings.mlr.press/v70/amos17a.html
},
  abstract = 	 {This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers encode constraints and complex dependencies between the hidden states that traditional convolutional and fully-connected layers often cannot capture. In this paper, we explore the foundations for such an architecture: we show how techniques from sensitivity analysis, bilevel optimization, and implicit differentiation can be used to exactly differentiate through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one notable example, we show that the method is capable of learning to play mini-Sudoku (4x4) given just input and output games, with no a priori information about the rules of the game; this highlights the ability of our architecture to learn hard constraints better than other neural architectures.}
}


@article{rush2012tutorial,
  title={A tutorial on dual decomposition and lagrangian relaxation for inference in natural language processing},
  author={Rush, Alexander M and Collins, MJ},
  journal={Journal of Artificial Intelligence Research},
  volume={45},
  pages={305--362},
  year={2012}
}

@book{sra2012optimization,
  title={Optimization for machine learning},
  author={Sra, Suvrit and Nowozin, Sebastian and Wright, Stephen J},
  year={2012},
  publisher={Mit Press}
}