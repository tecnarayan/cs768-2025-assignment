\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achituve et~al.(2021)Achituve, Maron, and Chechik]{achituve2021self}
Achituve, I., Maron, H., and Chechik, G.
\newblock Self-supervised learning for domain adaptation on point clouds.
\newblock In \emph{Proceedings of the IEEE/CVF winter conference on applications of computer vision}, pp.\  123--133, 2021.

\bibitem[Ainsworth et~al.(2022)Ainsworth, Hayase, and Srinivasa]{ainsworth2022git}
Ainsworth, S.~K., Hayase, J., and Srinivasa, S.
\newblock Git re-basin: Merging models modulo permutation symmetries.
\newblock \emph{arXiv preprint arXiv:2209.04836}, 2022.

\bibitem[Andreis et~al.(2023)Andreis, Bedionita, and Hwang]{andreis2023set}
Andreis, B., Bedionita, S., and Hwang, S.~J.
\newblock Set-based neural network encoding.
\newblock \emph{arXiv preprint arXiv:2305.16625}, 2023.

\bibitem[Atzmon et~al.(2018)Atzmon, Maron, and Lipman]{atzmon2018point}
Atzmon, M., Maron, H., and Lipman, Y.
\newblock Point convolutional neural networks by extension operators.
\newblock \emph{arXiv preprint arXiv:1803.10091}, 2018.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International conference on machine learning}, pp.\  1597--1607. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Hu, Gavves, Mensink, Mettes, Yang, and Snoek]{chen2020pointMixUp}
Chen, Y., Hu, V.~T., Gavves, E., Mensink, T., Mettes, P., Yang, P., and Snoek, C.~G.
\newblock Pointmixup: Augmentation for point clouds.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16}, pp.\  330--345. Springer, 2020{\natexlab{b}}.

\bibitem[Corso et~al.(2020)Corso, Cavalleri, Beaini, Li{\`o}, and Veli{\v{c}}kovi{\'c}]{corso2020pna}
Corso, G., Cavalleri, L., Beaini, D., Li{\`o}, P., and Veli{\v{c}}kovi{\'c}, P.
\newblock Principal neighbourhood aggregation for graph nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Diao \& Loynd(2023)Diao and Loynd]{diao2023relational}
Diao, C. and Loynd, R.
\newblock Relational attention: Generalizing transformers for graph-structured tasks.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Eilertsen et~al.(2020)Eilertsen, J{\"o}nsson, Ropinski, Unger, and Ynnerman]{eilertsen2020classifying}
Eilertsen, G., J{\"o}nsson, D., Ropinski, T., Unger, J., and Ynnerman, A.
\newblock Classifying the classifier: dissecting the weight space of neural networks.
\newblock \emph{arXiv preprint arXiv:2002.05688}, 2020.

\bibitem[Entezari et~al.(2022)Entezari, Sedghi, Saukh, and Neyshabur]{entezari2022the}
Entezari, R., Sedghi, H., Saukh, O., and Neyshabur, B.
\newblock The role of permutation invariance in linear mode connectivity of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=dNigytemkL}.

\bibitem[Han et~al.(2022)Han, Jiang, Liu, and Hu]{han2022g}
Han, X., Jiang, Z., Liu, N., and Hu, X.
\newblock G-mixup: Graph data augmentation for graph classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\  8230--8248. PMLR, 2022.

\bibitem[Hecht-Nielsen(1990)]{hecht1990algebraic}
Hecht-Nielsen, R.
\newblock On the algebraic structure of feedforward network weight spaces.
\newblock In \emph{Advanced Neural Computers}, pp.\  129--135. Elsevier, 1990.

\bibitem[Herrmann et~al.(2023)Herrmann, Faccio, and Schmidhuber]{herrmann2023learning}
Herrmann, V., Faccio, F., and Schmidhuber, J.
\newblock Learning useful representations of recurrent neural network weight matrices.
\newblock In \emph{NeurIPS 2023 Workshop on Symmetry and Geometry in Neural Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=yqGoKziEvY}.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Langosco et~al.(2023)Langosco, Alex, Baker, Quarel, Bradley, and Krueger]{langosco2023detecting}
Langosco, L., Alex, N., Baker, W., Quarel, D., Bradley, H., and Krueger, D.
\newblock Detecting backdoors with meta-models.
\newblock In \emph{NeurIPS 2023 Workshop on Backdoors in Deep Learning-The Good, the Bad, and the Ugly}, 2023.

\bibitem[Lim et~al.(2023)Lim, Maron, Law, Lorraine, and Lucas]{lim2023graph}
Lim, D., Maron, H., Law, M.~T., Lorraine, J., and Lucas, J.
\newblock Graph metanetworks for processing diverse neural architectures.
\newblock \emph{arXiv preprint arXiv:2312.04501}, 2023.

\bibitem[Ling et~al.(2023)Ling, Jiang, Liu, Ji, and Zou]{ling2023graph}
Ling, H., Jiang, Z., Liu, M., Ji, S., and Zou, N.
\newblock Graph mixup with soft alignments.
\newblock \emph{arXiv preprint arXiv:2306.06788}, 2023.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{Loshchilov2017FixingWD}
Loshchilov, I. and Hutter, F.
\newblock Fixing weight decay regularization in adam.
\newblock \emph{ArXiv}, abs/1711.05101, 2017.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:3312944}.

\bibitem[McInnes et~al.(2018)McInnes, Healy, and Melville]{mcinnes2018umap}
McInnes, L., Healy, J., and Melville, J.
\newblock Umap: Uniform manifold approximation and projection for dimension reduction.
\newblock \emph{arXiv preprint arXiv:1802.03426}, 2018.

\bibitem[Mescheder et~al.(2019)Mescheder, Oechsle, Niemeyer, Nowozin, and Geiger]{mescheder2019occupancy}
Mescheder, L., Oechsle, M., Niemeyer, M., Nowozin, S., and Geiger, A.
\newblock Occupancy networks: Learning 3d reconstruction in function space.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  4460--4470, 2019.

\bibitem[Mildenhall et~al.(2021)Mildenhall, Srinivasan, Tancik, Barron, Ramamoorthi, and Ng]{mildenhall2021nerf}
Mildenhall, B., Srinivasan, P.~P., Tancik, M., Barron, J.~T., Ramamoorthi, R., and Ng, R.
\newblock Nerf: Representing scenes as neural radiance fields for view synthesis.
\newblock \emph{Communications of the ACM}, 65\penalty0 (1):\penalty0 99--106, 2021.

\bibitem[Navon et~al.(2023{\natexlab{a}})Navon, Shamsian, Achituve, Fetaya, Chechik, and Maron]{navon23dws}
Navon, A., Shamsian, A., Achituve, I., Fetaya, E., Chechik, G., and Maron, H.
\newblock Equivariant architectures for learning in deep weight spaces.
\newblock In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), \emph{Proceedings of the 40th International Conference on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning Research}, pp.\  25790--25816. PMLR, 23--29 Jul 2023{\natexlab{a}}.
\newblock URL \url{https://proceedings.mlr.press/v202/navon23a.html}.

\bibitem[Navon et~al.(2023{\natexlab{b}})Navon, Shamsian, Fetaya, Chechik, Dym, and Maron]{navon2023equivariant}
Navon, A., Shamsian, A., Fetaya, E., Chechik, G., Dym, N., and Maron, H.
\newblock Equivariant deep weight space alignment.
\newblock \emph{arXiv preprint arXiv:2310.13397}, 2023{\natexlab{b}}.

\bibitem[Park et~al.(2019)Park, Florence, Straub, Newcombe, and Lovegrove]{park2019deepsdf}
Park, J.~J., Florence, P., Straub, J., Newcombe, R., and Lovegrove, S.
\newblock Deepsdf: Learning continuous signed distance functions for shape representation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  165--174, 2019.

\bibitem[Pe{\~n}a et~al.(2023)Pe{\~n}a, Medeiros, Dubail, Aminbeidokhti, Granger, and Pedersoli]{pena2023re}
Pe{\~n}a, F. A.~G., Medeiros, H.~R., Dubail, T., Aminbeidokhti, M., Granger, E., and Pedersoli, M.
\newblock Re-basin via implicit sinkhorn differentiation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  20237--20246, 2023.

\bibitem[Sch{\"u}rholt et~al.(2021)Sch{\"u}rholt, Kostadinov, and Borth]{schurholt2021self}
Sch{\"u}rholt, K., Kostadinov, D., and Borth, D.
\newblock Self-supervised representation learning on neural network weights for model characteristic prediction.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 16481--16493, 2021.

\bibitem[Sch{\"u}rholt et~al.(2022)Sch{\"u}rholt, Knyazev, Gir{\'o}-i Nieto, and Borth]{schurholt2022hyper}
Sch{\"u}rholt, K., Knyazev, B., Gir{\'o}-i Nieto, X., and Borth, D.
\newblock Hyper-representations as generative models: Sampling unseen neural network weights.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27906--27920, 2022.

\bibitem[Sitzmann et~al.(2020)Sitzmann, Martel, Bergman, Lindell, and Wetzstein]{Sitzmann2020ImplicitNR}
Sitzmann, V., Martel, J. N.~P., Bergman, A.~W., Lindell, D.~B., and Wetzstein, G.
\newblock Implicit neural representations with periodic activation functions.
\newblock \emph{ArXiv}, abs/2006.09661, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:219720931}.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The journal of machine learning research}, 15\penalty0 (1):\penalty0 1929--1958, 2014.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  2818--2826, 2016.

\bibitem[Unterthiner et~al.(2020)Unterthiner, Keysers, Gelly, Bousquet, and Tolstikhin]{unterthiner2020predicting}
Unterthiner, T., Keysers, D., Gelly, S., Bousquet, O., and Tolstikhin, I.
\newblock Predicting neural network accuracy from weights.
\newblock \emph{arXiv preprint arXiv:2002.11448}, 2020.

\bibitem[Verma et~al.(2018)Verma, Lamb, Beckham, Najafi, Mitliagkas, Lopez-Paz, and Bengio]{Verma2018ManifoldMB}
Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Lopez-Paz, D., and Bengio, Y.
\newblock Manifold mixup: Better representations by interpolating hidden states.
\newblock In \emph{International Conference on Machine Learning}, 2018.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:59604501}.

\bibitem[Wang \& Golland(2022)Wang and Golland]{Wang2022DeepLO}
Wang, C.~J. and Golland, P.
\newblock Deep learning on implicit neural datasets.
\newblock \emph{ArXiv}, abs/2206.01178, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:249282347}.

\bibitem[Wang et~al.(2019)Wang, Sun, Liu, Sarma, Bronstein, and Solomon]{wang2019dynamic}
Wang, Y., Sun, Y., Liu, Z., Sarma, S.~E., Bronstein, M.~M., and Solomon, J.~M.
\newblock Dynamic graph cnn for learning on point clouds.
\newblock \emph{ACM Transactions on Graphics (tog)}, 38\penalty0 (5):\penalty0 1--12, 2019.

\bibitem[Wu et~al.(2015)Wu, Song, Khosla, Yu, Zhang, Tang, and Xiao]{wu20153d}
Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., and Xiao, J.
\newblock 3d shapenets: A deep representation for volumetric shapes.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  1912--1920, 2015.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{Xiao2017FashionMNISTAN}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.
\newblock \emph{ArXiv}, abs/1708.07747, 2017.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:702279}.

\bibitem[Xu et~al.(2022)Xu, Wang, Jiang, Fan, and Wang]{Xu2022SignalPF}
Xu, D., Wang, P., Jiang, Y., Fan, Z., and Wang, Z.
\newblock Signal processing for implicit neural representations.
\newblock \emph{ArXiv}, abs/2210.08772, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:252917872}.

\bibitem[Zhang et~al.(2023)Zhang, Kofinas, Zhang, Chen, Burghouts, and Snoek]{zhang2023neural}
Zhang, D.~W., Kofinas, M., Zhang, Y., Chen, Y., Burghouts, G.~J., and Snoek, C.~G.
\newblock Neural networks are graphs! graph neural networks for equivariant processing of neural networks.
\newblock \emph{2nd Annual Topology, Algebra, and Geometry in Machine Learning Workshop at ICML}, 2023.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhou et~al.(2023{\natexlab{a}})Zhou, Yang, Burns, Jiang, Sokota, Kolter, and Finn]{zhou2023permutation}
Zhou, A., Yang, K., Burns, K., Jiang, Y., Sokota, S., Kolter, J.~Z., and Finn, C.
\newblock Permutation equivariant neural functionals.
\newblock \emph{arXiv preprint arXiv:2302.14040}, 2023{\natexlab{a}}.

\bibitem[Zhou et~al.(2023{\natexlab{b}})Zhou, Yang, Jiang, Burns, Xu, Sokota, Kolter, and Finn]{zhou2023neural}
Zhou, A., Yang, K., Jiang, Y., Burns, K., Xu, W., Sokota, S., Kolter, J.~Z., and Finn, C.
\newblock Neural functional transformers.
\newblock \emph{arXiv preprint arXiv:2305.13546}, 2023{\natexlab{b}}.

\end{thebibliography}
