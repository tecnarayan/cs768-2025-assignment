\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bardenet et~al.(2013)Bardenet, Brendel, K\'egl, and
  Sebag]{remi2013collab}
Bardenet, R., Brendel, M., K\'egl, B., and Sebag, M.
\newblock Collaborative hyperparameter tuning.
\newblock In \emph{ICML}, 2013.

\bibitem[Bergstra \& Bengio(2012)Bergstra and Bengio]{bergstra-bengio-2012a}
Bergstra, J. and Bengio, Y.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 281--305,
  2012.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K\'egl]{BergstraJ2011}
Bergstra, J.~S., Bardenet, R., Bengio, Y., and K\'egl, B.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2011.

\bibitem[Bishop(2006)]{bishop-2006}
Bishop, C.~M.
\newblock \emph{Pattern Recognition and Machine Learning}.
\newblock Springer-Verlag New York, Inc., 2006.

\bibitem[Brochu et~al.(2010)Brochu, Brochu, and {de Freitas}]{Brochu2010}
Brochu, E., Brochu, T., and {de Freitas}, N.
\newblock {A {B}ayesian interactive optimization approach to procedural
  animation design}.
\newblock In \emph{ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
  2010.

\bibitem[Bull(2011)]{Bull2011}
Bull, A.~D.
\newblock {Convergence rates of efficient global optimization algorithms}.
\newblock \emph{Journal of Machine Learning Research}, \penalty0
  (3-4):\penalty0 2879--2904, 2011.

\bibitem[Buntine \& Weigend(1991)Buntine and Weigend]{buntine1991bayesian}
Buntine, W.~L. and Weigend, A.~S.
\newblock {B}ayesian back-propagation.
\newblock \emph{Complex systems}, 5\penalty0 (6):\penalty0 603--643, 1991.

\bibitem[Calandra et~al.(2014{\natexlab{a}})Calandra, Peters, Rasmussen, and
  Deisenroth]{calandra2014manifold}
Calandra, R., Peters, J., Rasmussen, C.~E., and Deisenroth, M.~P.
\newblock Manifold {G}aussian processes for regression.
\newblock \emph{preprint arXiv:1402.5876}, 2014{\natexlab{a}}.

\bibitem[Calandra et~al.(2014{\natexlab{b}})Calandra, Peters, Seyfarth, and
  Deisenroth]{calandra-etal-2014a}
Calandra, R., Peters, J., Seyfarth, A., and Deisenroth, M.~P.
\newblock An experimental evaluation of {B}ayesian optimization on bipedal
  locomotion.
\newblock In \emph{International Conference on Robotics and Automation},
  2014{\natexlab{b}}.

\bibitem[Carvalho et~al.(2009)Carvalho, Polson, and Scott]{carvalho-2009a}
Carvalho, C.~M., Polson, N.~G., and Scott, J.~G.
\newblock Handling sparsity via the horseshoe.
\newblock In \emph{Artificial Intelligence and Statistics}, 2009.

\bibitem[De~Freitas(2003)]{de2003bayesian}
De~Freitas, J.~F.
\newblock \emph{{B}ayesian methods for neural networks}.
\newblock PhD thesis, Trinity College, University of Cambridge, 2003.

\bibitem[de~Freitas et~al.(2012)de~Freitas, Smola, and
  Zoghi]{defreitas-etal-2013a}
de~Freitas, N., Smola, A.~J., and Zoghi, M.
\newblock Exponential regret bounds for {G}aussian process bandits with
  deterministic observations.
\newblock In \emph{ICML}, 2012.

\bibitem[Djolonga et~al.(2013)Djolonga, Krause, and Cevher]{djolonga13high}
Djolonga, J., Krause, A., and Cevher, V.
\newblock High dimensional {G}aussian process bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Eggensperger et~al.(2013)Eggensperger, Feurer, Hutter, Bergstra,
  Snoek, Hoos, and Leyton-Brown]{Eggensperger-etal-2013a}
Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H.,
  and Leyton-Brown, K.
\newblock Towards an empirical foundation for assessing {B}ayesian optimization
  of hyperparameters.
\newblock In \emph{NIPS Workshop on {B}ayesian Optimization in Theory and
  Practice}, 2013.

\bibitem[Feurer et~al.(2015)Feurer, Springenberg, and Hutter]{feurer-2015}
Feurer, M., Springenberg, T., and Hutter, F.
\newblock Initializing {B}ayesian hyperparameter optimization via
  meta-learning.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2015.

\bibitem[Garnett et~al.(2010)Garnett, Osborne, and Roberts]{garnett-etal-2010}
Garnett, R., Osborne, M.~A., and Roberts, S.~J.
\newblock {B}ayesian optimization for sensor set selection.
\newblock In \emph{International Conference on Information Processing in Sensor
  Networks}, 2010.

\bibitem[Gelbart et~al.(2014)Gelbart, Snoek, and Adams]{gelbart-etal-2014}
Gelbart, M.~A., Snoek, J., and Adams, R.~P.
\newblock {B}ayesian optimization with unknown constraints.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2014.

\bibitem[Ginsbourger \& Riche(2010)Ginsbourger and Riche]{Ginsbourger2010a}
Ginsbourger, D. and Riche, R.~L.
\newblock Dealing with asynchronicity in parallel {G}aussian process based
  global optimization.
\newblock \url{http://hal.archives-ouvertes.fr/hal-00507632}, 2010.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Warde{-}Farley, Mirza, Courville,
  and Bengio]{GoodfellowWMCB13}
Goodfellow, I.~J., Warde{-}Farley, D., Mirza, M., Courville, A.~C., and Bengio,
  Y.
\newblock Maxout networks.
\newblock In \emph{ICML}, 2013.

\bibitem[Gramacy \& Lee(2010)Gramacy and Lee]{gramacy2010}
Gramacy, R.~B. and Lee, H. K.~H.
\newblock Optimization under unknown constraints, 2010.
\newblock arXiv:1004.4027.

\bibitem[Hensman et~al.(2013)Hensman, Fusi, and Lawrence]{hensman2013bigdatagp}
Hensman, J., Fusi, N., and Lawrence, N.
\newblock {G}aussian processes for big data.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2013.

\bibitem[Hinton \& van Camp(1993)Hinton and van Camp]{hinton-camp-93}
Hinton, G.~E. and van Camp, D.
\newblock Keeping neural networks simple by minimizing the description length
  of the weights.
\newblock In \emph{ACM Conference on Computational Learning Theory}, 1993.

\bibitem[Hinton \& Salakhutdinov(2008)Hinton and
  Salakhutdinov]{hinton2008using}
Hinton, G.~E. and Salakhutdinov, R.
\newblock Using deep belief nets to learn covariance kernels for {G}aussian
  processes.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1249--1256, 2008.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, Krizhevsky, Sutskever, and
  Salakhutdinov]{hinton2012improving}
Hinton, G.~E., Srivastava, N., Krizhevsky, A., Sutskever, I., and
  Salakhutdinov, R.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock \emph{arXiv preprint arXiv:1207.0580}, 2012.

\bibitem[Hoffman et~al.(2011)Hoffman, Brochu, and
  de~Freitas]{hoffman-etal-2011}
Hoffman, M., Brochu, E., and de~Freitas, N.
\newblock Portfolio allocation for {B}ayesian optimization.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2011.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and Leyton-Brown]{hutter-2011a}
Hutter, F., Hoos, H.~H., and Leyton-Brown, K.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{Learning and Intelligent Optimization 5}, 2011.

\bibitem[Jones(2001)]{Jones2001}
Jones, D.~R.
\newblock {A taxonomy of global optimization methods based on response
  surfaces}.
\newblock \emph{Journal of Global Optimization}, 21, 2001.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational {B}ayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kiros et~al.(2014)Kiros, Salakhutdinov, and Zemel]{kiros-etal-2014a}
Kiros, R., Salakhutdinov, R., and Zemel, R.~S.
\newblock Multimodal neural language models.
\newblock In \emph{ICML}, 2014.

\bibitem[Krause \& Ong(2011)Krause and Ong]{krause-ong-2011}
Krause, A. and Ong, C.~S.
\newblock Contextual {G}aussian process bandit optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2011.

\bibitem[Kushner(1964)]{kushner-1964a}
Kushner, H.~J.
\newblock A new method for locating the maximum point of an arbitrary multipeak
  curve in the presence of noise.
\newblock \emph{Journal of Basic Engineering}, 86, 1964.

\bibitem[L{\'a}zaro-Gredilla \& Figueiras-Vidal(2010)L{\'a}zaro-Gredilla and
  Figueiras-Vidal]{lazaro2010marginalized}
L{\'a}zaro-Gredilla, M. and Figueiras-Vidal, A.~R.
\newblock Marginalized neural network mixtures for large-scale regression.
\newblock \emph{Neural Networks, IEEE Transactions on}, 21\penalty0
  (8):\penalty0 1345--1351, 2010.

\bibitem[Lee et~al.(2014)Lee, Xie, Gallagher, Zhang, and Tu]{Lee2014}
Lee, C.-Y., Xie, S., Gallagher, P., Zhang, Z., and Tu, Z.
\newblock Deeply supervised nets.
\newblock In \emph{Deep Learning and Representation Learning Workshop, {NIPS}},
  2014.

\bibitem[Lin et~al.(2013)Lin, Chen, and Yan]{LinCY13}
Lin, M., Chen, Q., and Yan, S.
\newblock Network in network.
\newblock \emph{CoRR}, abs/1312.4400, 2013.
\newblock URL \url{http://arxiv.org/abs/1312.4400}.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft {COCO}: Common objects in context.
\newblock In \emph{ECCV 2014}, pp.\  740--755. Springer, 2014.

\bibitem[Lizotte(2008)]{lizotte-thesis}
Lizotte, D.
\newblock \emph{Practical {B}ayesian Optimization}.
\newblock PhD thesis, University of Alberta, Edmonton, Alberta, 2008.

\bibitem[MacKay(1992)]{mackay1992practical}
MacKay, D.~J.
\newblock A practical {B}ayesian framework for backpropagation networks.
\newblock \emph{Neural computation}, 4\penalty0 (3):\penalty0 448--472, 1992.

\bibitem[Mahendran et~al.(2012)Mahendran, Wang, Hamze, and
  de~Freitas]{mahendran-2012a}
Mahendran, N., Wang, Z., Hamze, F., and de~Freitas, N.
\newblock Adaptive {MCMC} with {B}ayesian optimization.
\newblock In \emph{Artificial Intelligence and Statistics}, 2012.

\bibitem[Mnih \& Gregor(2014)Mnih and Gregor]{mnih2014neural}
Mnih, A. and Gregor, K.
\newblock Neural variational inference and learning in belief networks.
\newblock In \emph{ICML}, 2014.

\bibitem[Mockus et~al.(1978)Mockus, Tiesis, and Zilinskas]{Mockus1978}
Mockus, J., Tiesis, V., and Zilinskas, A.
\newblock {The application of {B}ayesian methods for seeking the extremum}.
\newblock \emph{Towards Global Optimization}, 2, 1978.

\bibitem[Neal(2000)]{Neal00slicesampling}
Neal, R.
\newblock Slice sampling.
\newblock \emph{Annals of Statistics}, 31:\penalty0 705--767, 2000.

\bibitem[Neal(1995)]{neal1995bayesian}
Neal, R.~M.
\newblock \emph{{B}ayesian learning for neural networks}.
\newblock PhD thesis, University of Toronto, 1995.

\bibitem[Nickson et~al.(2014)Nickson, Osborne, Reece, and
  Roberts]{nicksonautomated}
Nickson, T., Osborne, M.~A., Reece, S., and Roberts, S.
\newblock Automated machine learning using stochastic algorithm tuning.
\newblock \emph{NIPS Workshop on Bayesian Optimization}, 2014.

\bibitem[Osborne et~al.(2009)Osborne, Garnett, and Roberts]{osborne-2009a}
Osborne, M.~A., Garnett, R., and Roberts, S.~J.
\newblock {G}aussian processes for global optimization.
\newblock In \emph{Learning and Intelligent Optimization}, 2009.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic back-propagation and variational inference in deep latent
  {G}aussian models.
\newblock In \emph{ICML}, 2014.

\bibitem[Snelson \& Ghahramani(2005)Snelson and Ghahramani]{snelson2005sparse}
Snelson, E. and Ghahramani, Z.
\newblock Sparse {G}aussian processes using pseudo-inputs.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1257--1264, 2005.

\bibitem[Snoek(2013)]{snoek-2013a}
Snoek, J.
\newblock \emph{{B}ayesian Optimization and Semiparametric Models with
  Applications to Assistive Technology}.
\newblock PhD thesis, University of Toronto, Toronto, Canada, 2013.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek-etal-2012b}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2012.

\bibitem[Snoek et~al.(2014)Snoek, Swersky, Zemel, and Adams]{snoek-etal-2014a}
Snoek, J., Swersky, K., Zemel, R.~S., and Adams, R.~P.
\newblock Input warping for {B}ayesian optimization of non-stationary
  functions.
\newblock In \emph{ICML}, 2014.

\bibitem[Springenberg et~al.(2014)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{DBLP:journals/corr/SpringenbergDBR14}
Springenberg, J.~T., Dosovitskiy, A., Brox, T., and Riedmiller, M.~A.
\newblock Striving for simplicity: The all convolutional net.
\newblock \emph{CoRR}, abs/1412.6806, 2014.
\newblock URL \url{http://arxiv.org/abs/1412.6806}.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{Srinivas2010}
Srinivas, N., Krause, A., Kakade, S., and Seeger, M.
\newblock {G}aussian process optimization in the bandit setting: no regret and
  experimental design.
\newblock In \emph{ICML}, 2010.

\bibitem[Swersky et~al.(2013)Swersky, Snoek, and Adams]{swersky-etal-2013a}
Swersky, K., Snoek, J., and Adams, R.~P.
\newblock Multi-task {B}ayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Titsias(2009)]{titsias2009variational}
Titsias, M.~K.
\newblock Variational learning of inducing variables in sparse {G}aussian
  processes.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  567--574, 2009.

\bibitem[Wan et~al.(2013)Wan, Zeiler, Zhang, LeCun, and Fergus]{WanZZLF13}
Wan, L., Zeiler, M.~D., Zhang, S., LeCun, Y., and Fergus, R.
\newblock Regularization of neural networks using dropconnect.
\newblock In \emph{ICML}, 2013.

\bibitem[Wang et~al.(2013)Wang, Zoghi, Hutter, Matheson, and
  de~Freitas]{wang-etal-2013}
Wang, Z., Zoghi, M., Hutter, F., Matheson, D., and de~Freitas, N.
\newblock {B}ayesian optimization in high dimensions via random embeddings.
\newblock In \emph{IJCAI}, 2013.

\bibitem[Williams(1996)]{williams-96}
Williams, C. K.~I.
\newblock Computing with infinite networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 1996.

\bibitem[Xu et~al.(2015)Xu, Ba, Kiros, Cho, Courville, Salakhutdinov, Zemel,
  and Bengio]{xu-etal-2015a}
Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel,
  R., and Bengio, Y.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock \emph{arXiv preprint arXiv:1502.03044v2}, 2015.

\bibitem[Zaremba et~al.(2015)Zaremba, Sutskever, and
  Vinyals]{zaremba-etal-2015a}
Zaremba, W., Sutskever, I., and Vinyals, O.
\newblock Recurrent neural network regularization.
\newblock \emph{arXiv preprint arXiv:1207.0580}, 2015.

\end{thebibliography}
