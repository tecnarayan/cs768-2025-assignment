\begin{thebibliography}{10}

\bibitem{AntoniouICLR19}
Antreas Antoniou, Harrison Edwards, and Amos Storkey.
\newblock How to train your maml.
\newblock In {\em ICLR}, 2019.

\bibitem{Lee2013pseudo_label}
Lee Dong-Hyun.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In {\em ICML Workshops}, 2013.

\bibitem{FinnAL17}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em ICML}, 2017.

\bibitem{FinnNIPS2018}
Chelsea Finn, Kelvin Xu, and Sergey Levine.
\newblock Probabilistic model-agnostic meta-learning.
\newblock In {\em NeurIPS}, 2018.

\bibitem{FranceschiICML18}
Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and
  Massimiliano Pontil.
\newblock Bilevel programming for hyperparameter optimization and
  meta-learning.
\newblock In {\em ICML}, 2018.

\bibitem{GrandvaletNIPS04_entmin}
Yves Grandvalet and Yoshua Bengio.
\newblock Semi-supervised learning by entropy minimization.
\newblock In {\em NIPS}, 2004.

\bibitem{GrantICLR2018}
Erin Grant, Chelsea Finn, Sergey Levine, Trevor Darrell, and Thomas~L.
  Griffiths.
\newblock Recasting gradient-based meta-learning as hierarchical bayes.
\newblock In {\em ICLR}, 2018.

\bibitem{HeZRS16}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{LaineICLR2017pi_model}
Samuli Laine and Timo Aila.
\newblock Temporal ensembling for semi-supervised learning.
\newblock In {\em ICLR}, 2017.

\bibitem{LeeCVPR19svm}
Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto.
\newblock Meta-learning with differentiable convex optimization.
\newblock In {\em CVPR}, 2019.

\bibitem{LeeICML18}
Yoonho Lee and Seungjin Choi.
\newblock Gradient-based meta-learning with learned layerwise metric and
  subspace.
\newblock In {\em ICML}, 2018.

\bibitem{FeiFeiFP06}
Fei{-}Fei Li, Robert Fergus, and Pietro Perona.
\newblock One-shot learning of object categories.
\newblock {\em {IEEE} Trans. Pattern Anal. Mach. Intell.}, 28(4):594--611,
  2006.

\bibitem{Mehrotra2017}
Akshay Mehrotra and Ambedkar Dukkipati.
\newblock Generative adversarial residual pairwise networks for one shot
  learning.
\newblock {\em arXiv}, 1703.08033, 2017.

\bibitem{MishraICLR2018}
Nikhil Mishra, Mostafa Rohaninejad, Xi~Chen, and Pieter Abbeel.
\newblock Snail: A simple neural attentive meta-learner.
\newblock In {\em ICLR}, 2018.

\bibitem{MiyatoDG16VAT}
Takeru Miyato, Andrew~M. Dai, and Ian~J. Goodfellow.
\newblock Virtual adversarial training for semi-supervised text classification.
\newblock {\em arXiv}, 1605.07725, 2016.

\bibitem{MunkhdalaiICML2017}
Tsendsuren Munkhdalai and Hong Yu.
\newblock Meta networks.
\newblock In {\em ICML}, 2017.

\bibitem{MunkhdalaiICML18}
Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, and Adam Trischler.
\newblock Rapid adaptation with conditionally shifted neurons.
\newblock In {\em ICML}, 2018.

\bibitem{OliverNIPS18semi_survey}
Avital Oliver, Augustus Odena, Colin~A. Raffel, Ekin~Dogus Cubuk, and Ian~J.
  Goodfellow.
\newblock Realistic evaluation of deep semi-supervised learning algorithms.
\newblock In {\em NeurIPS}, 2018.

\bibitem{Chapelle2006semi_supervise}
Chapelle Olivier, Sch{\"{o}}lkopf Bernhard, and Zien Alexander.
\newblock {\em Semi-supervised learning}, volume ISBN 978-0-262-03358-9.
\newblock Cambridge, Mass.: MIT Press, 2006.

\bibitem{OreshkinNIPS18}
Boris~N. Oreshkin, Pau Rodr{\'{\i}}guez, and Alexandre Lacoste.
\newblock {TADAM:} task dependent adaptive metric for improved few-shot
  learning.
\newblock In {\em NeurIPS}, 2018.

\bibitem{RaviICLR2017}
Sachin Ravi and Hugo Larochelle.
\newblock Optimization as a model for few-shot learning.
\newblock In {\em ICLR}, 2017.

\bibitem{RenICLR2018_semisupervised}
Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin Swersky,
  Joshua~B. Tenenbaum, Hugo Larochelle, and Richard~S. Zemel.
\newblock Meta-learning for semi-supervised few-shot classification.
\newblock In {\em ICLR}, 2018.

\bibitem{RohrbachNIPS13transfer}
Marcus Rohrbach, Sandra Ebert, and Bernt Schiele.
\newblock Transfer learning in a transductive setting.
\newblock In {\em NIPS}, 2013.

\bibitem{Russakovsky2015}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{RusuICLR2019}
Andrei~A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,
  Simon Osindero, and Raia Hadsell.
\newblock Meta-learning with latent embedding optimization.
\newblock In {\em ICLR}, 2019.

\bibitem{SantoroBBWL16}
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy~P.
  Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In {\em ICML}, 2016.

\bibitem{SchwartzNIPS18}
Eli Schwartz, Leonid Karlinsky, Joseph Shtok, Sivan Harary, Mattias Marder,
  Rog{\'{e}}rio~Schmidt Feris, Abhishek Kumar, Raja Giryes, and Alexander~M.
  Bronstein.
\newblock Delta-encoder: an effective sample synthesis method for few-shot
  object recognition.
\newblock In {\em NeurIPS}, 2018.

\bibitem{ShelhamerLD17}
Evan Shelhamer, Jonathan Long, and Trevor Darrell.
\newblock Fully convolutional networks for semantic segmentation.
\newblock {\em {IEEE} Trans. Pattern Anal. Mach. Intell.}, 39(4):640--651,
  2017.

\bibitem{SnellSZ17}
Jake Snell, Kevin Swersky, and Richard~S. Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock In {\em NIPS}, 2017.

\bibitem{SunCVPR2019}
Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele.
\newblock Meta-transfer learning for few-shot learning.
\newblock In {\em CVPR}, 2019.

\bibitem{SungCVPR2018}
Flood Sung, Yongxin Yang, Li~Zhang, Tao Xiang, Philip H.~S. Torr, and
  Timothy~M. Hospedales.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In {\em CVPR}, 2018.

\bibitem{TarvainenNIPS17mean_teacher}
Antti Tarvainen and Harri Valpola.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock In {\em NIPS}, 2017.

\bibitem{TrigueroGH15self_labeled}
Isaac Triguero, Salvador Garc{\'{\i}}a, and Francisco Herrera.
\newblock Self-labeled techniques for semi-supervised learning: taxonomy,
  software and empirical study.
\newblock {\em Knowl. Inf. Syst.}, 42(2):245--284, 2015.

\bibitem{VinyalsBLKW16}
Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan
  Wierstra.
\newblock Matching networks for one shot learning.
\newblock In {\em NIPS}, 2016.

\bibitem{WangCVPR2018}
Yu{-}Xiong Wang, Ross~B. Girshick, Martial Hebert, and Bharath Hariharan.
\newblock Low-shot learning from imaginary data.
\newblock In {\em CVPR}, 2018.

\bibitem{XianCVPR2019a}
Yongqin Xian, Saurabh Sharma, Bernt Schiele, and Zeynep Akata.
\newblock {f-VAEGAN-D2}: {A} feature generating framework for any-shot
  learning.
\newblock In {\em CVPR}, 2019.

\bibitem{LiuICLR2019transductive}
Liu Yanbin, Juho Lee, Minseop Park, Saehoon Kim, and Yi~Yang.
\newblock Transductive propagation network for few-shot learning.
\newblock In {\em ICLR}, 2019.

\bibitem{Lecun2015}
LeCun Yann, Bengio Yoshua, and Hinton Geoffrey.
\newblock Deep learning.
\newblock {\em Nature}, 521(7553):436, 2015.

\bibitem{Yarowsky95self_training}
David Yarowsky.
\newblock Unsupervised word sense disambiguation rivaling supervised methods.
\newblock In {\em ACL}, 1995.

\bibitem{ZhangICLR2017noisy}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock In {\em ICLR}, 2017.

\bibitem{ZhangNIPS2018MetaGAN}
Ruixiang Zhang, Tong Che, Zoubin Grahahramani, Yoshua Bengio, and Yangqiu Song.
\newblock Metagan: An adversarial approach to few-shot learning.
\newblock In {\em NeurIPS}, 2018.

\end{thebibliography}
