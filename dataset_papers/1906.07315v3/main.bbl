\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agogino and Tumer(2004)]{agogino2004unifying}
A.~K. Agogino and K.~Tumer.
\newblock Unifying temporal and structural credit assignment problems.
\newblock In \emph{Proceedings of the Third International Joint Conference on
  Autonomous Agents and Multiagent Systems-Volume 2}, pages 980--987. IEEE
  Computer Society, 2004.

\bibitem[Colas et~al.(2018)Colas, Sigaud, and Oudeyer]{colas2018}
C.~Colas, O.~Sigaud, and P.-Y. Oudeyer.
\newblock Gep-pg: Decoupling exploration and exploitation in deep reinforcement
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1802.05054}, 2018.

\bibitem[Devlin et~al.(2011)Devlin, Grze{\'s}, and Kudenko]{devlin2011multi}
S.~Devlin, M.~Grze{\'s}, and D.~Kudenko.
\newblock Multi-agent, reward shaping for robocup keepaway.
\newblock In \emph{The 10th International Conference on Autonomous Agents and
  Multiagent Systems-Volume 3}, pages 1227--1228. International Foundation for
  Autonomous Agents and Multiagent Systems, 2011.

\bibitem[Floreano et~al.(2008)Floreano, D{\"u}rr, and Mattiussi]{floreano2008}
D.~Floreano, P.~D{\"u}rr, and C.~Mattiussi.
\newblock Neuroevolution: from architectures to learning.
\newblock \emph{Evolutionary Intelligence}, 1\penalty0 (1):\penalty0 47--62,
  2008.

\bibitem[Foerster et~al.(2018{\natexlab{a}})Foerster, Chen, Al-Shedivat,
  Whiteson, Abbeel, and Mordatch]{foerster2018learning}
J.~Foerster, R.~Y. Chen, M.~Al-Shedivat, S.~Whiteson, P.~Abbeel, and
  I.~Mordatch.
\newblock Learning with opponent-learning awareness.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 122--130. International
  Foundation for Autonomous Agents and Multiagent Systems, 2018{\natexlab{a}}.

\bibitem[Foerster et~al.(2018{\natexlab{b}})Foerster, Farquhar, Afouras,
  Nardelli, and Whiteson]{foerster2018counterfactual}
J.~N. Foerster, G.~Farquhar, T.~Afouras, N.~Nardelli, and S.~Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018{\natexlab{b}}.

\bibitem[Fogel(2006)]{fogel2006}
D.~B. Fogel.
\newblock \emph{Evolutionary computation: toward a new philosophy of machine
  intelligence}, volume~1.
\newblock John Wiley \& Sons, 2006.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and
  Meger]{fujimoto2018addressing}
S.~Fujimoto, H.~van Hoof, and D.~Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock \emph{arXiv preprint arXiv:1802.09477}, 2018.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Dalibard, Osindero, Czarnecki,
  Donahue, Razavi, Vinyals, Green, Dunning, Simonyan, et~al.]{jaderberg2017}
M.~Jaderberg, V.~Dalibard, S.~Osindero, W.~M. Czarnecki, J.~Donahue, A.~Razavi,
  O.~Vinyals, T.~Green, I.~Dunning, K.~Simonyan, et~al.
\newblock Population based training of neural networks.
\newblock \emph{arXiv preprint arXiv:1711.09846}, 2017.

\bibitem[Khadka and Tumer(2018)]{khadka2018evolution}
S.~Khadka and K.~Tumer.
\newblock Evolution-guided policy gradient in reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1196--1208, 2018.

\bibitem[Khadka et~al.(2019)Khadka, Majumdar, Nassar, Dwiel, Tumer, Miret, Liu,
  and Tumer]{khadka2019cerl}
S.~Khadka, S.~Majumdar, T.~Nassar, Z.~Dwiel, E.~Tumer, S.~Miret, Y.~Liu, and
  K.~Tumer.
\newblock Collaborative evolutionary reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1905.00976v2}, 2019.

\bibitem[Kitano et~al.(1995)Kitano, Asada, Kuniyoshi, Noda, and
  Osawa]{kitano1995robocup}
H.~Kitano, M.~Asada, Y.~Kuniyoshi, I.~Noda, and E.~Osawa.
\newblock Robocup: The robot world cup initiative, 1995.

\bibitem[Kurach et~al.(2019)Kurach, Raichuk, Sta{\'n}czyk, Zaj{\k{a}}c, Bachem,
  Espeholt, Riquelme, Vincent, Michalski, Bousquet, et~al.]{kurach2019google}
K.~Kurach, A.~Raichuk, P.~Sta{\'n}czyk, M.~Zaj{\k{a}}c, O.~Bachem, L.~Espeholt,
  C.~Riquelme, D.~Vincent, M.~Michalski, O.~Bousquet, et~al.
\newblock Google research football: A novel reinforcement learning environment.
\newblock \emph{arXiv preprint arXiv:1907.11180}, 2019.

\bibitem[Lazaridou et~al.(2016)Lazaridou, Peysakhovich, and
  Baroni]{lazaridou2016multi}
A.~Lazaridou, A.~Peysakhovich, and M.~Baroni.
\newblock Multi-agent cooperation and the emergence of (natural) language.
\newblock \emph{arXiv preprint arXiv:1612.07182}, 2016.

\bibitem[Li et~al.(2012)Li, Wu, He, and Chen]{li2012optimal}
F.-D. Li, M.~Wu, Y.~He, and X.~Chen.
\newblock Optimal control in microgrid using multi-agent reinforcement
  learning.
\newblock \emph{ISA transactions}, 51\penalty0 (6):\penalty0 743--751, 2012.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015}
T.~P. Lillicrap, J.~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa,
  D.~Silver, and D.~Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Littman(1994)]{littman1994markov}
M.~L. Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{Machine learning proceedings 1994}, pages 157--163.
  Elsevier, 1994.

\bibitem[Liu et~al.(2019)Liu, Lever, Merel, Tunyasuvunakool, Heess, and
  Graepel]{liu2019emergent}
S.~Liu, G.~Lever, J.~Merel, S.~Tunyasuvunakool, N.~Heess, and T.~Graepel.
\newblock Emergent coordination through competition.
\newblock \emph{arXiv preprint arXiv:1902.07151}, 2019.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
R.~Lowe, Y.~Wu, A.~Tamar, J.~Harb, O.~P. Abbeel, and I.~Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6379--6390, 2017.

\bibitem[L{\"u}ders et~al.(2017)L{\"u}ders, Schl{\"a}ger, Korach, and
  Risi]{luders2017}
B.~L{\"u}ders, M.~Schl{\"a}ger, A.~Korach, and S.~Risi.
\newblock Continual and one-shot learning through neural networks with dynamic
  external memory.
\newblock In \emph{European Conference on the Applications of Evolutionary
  Computation}, pages 886--901. Springer, 2017.

\bibitem[Miller and Goldberg(1995)]{miller1995genetic}
B.~L. Miller and D.~E. Goldberg.
\newblock Genetic algorithms, tournament selection, and the effects of noise.
\newblock In \emph{Complex Systems}. Citeseer, 1995.

\bibitem[Mordatch and Abbeel(2018)]{mordatch2018emergence}
I.~Mordatch and P.~Abbeel.
\newblock Emergence of grounded compositional language in multi-agent
  populations.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{ng1999policy}
A.~Y. Ng, D.~Harada, and S.~Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{ICML}, volume~99, pages 278--287, 1999.

\bibitem[Rahmattalabi et~al.(2016)Rahmattalabi, Chung, Colby, and
  Tumer]{rahmattalabi2016d++}
A.~Rahmattalabi, J.~J. Chung, M.~Colby, and K.~Tumer.
\newblock D++: Structural credit assignment in tightly coupled multiagent
  domains.
\newblock In \emph{2016 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 4424--4429. IEEE, 2016.

\bibitem[Resnick et~al.(2018)Resnick, Eldridge, Ha, Britz, Foerster, Togelius,
  Cho, and Bruna]{resnick2018pommerman}
C.~Resnick, W.~Eldridge, D.~Ha, D.~Britz, J.~Foerster, J.~Togelius, K.~Cho, and
  J.~Bruna.
\newblock Pommerman: A multi-agent playground.
\newblock \emph{arXiv preprint arXiv:1809.07124}, 2018.

\bibitem[Risi and Togelius(2017)]{risi2017}
S.~Risi and J.~Togelius.
\newblock Neuroevolution in games: State of the art and open challenges.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in
  Games}, 9\penalty0 (1):\penalty0 25--41, 2017.

\bibitem[Salimans et~al.(2017)Salimans, Ho, Chen, and Sutskever]{salimans2017}
T.~Salimans, J.~Ho, X.~Chen, and I.~Sutskever.
\newblock Evolution strategies as a scalable alternative to reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1703.03864}, 2017.

\bibitem[Shalev-Shwartz et~al.(2016)Shalev-Shwartz, Shammah, and
  Shashua]{shalev2016safe}
S.~Shalev-Shwartz, S.~Shammah, and A.~Shashua.
\newblock Safe, multi-agent, reinforcement learning for autonomous driving.
\newblock \emph{arXiv preprint arXiv:1610.03295}, 2016.

\bibitem[Sheng et~al.(2006)Sheng, Yang, Tan, and Xi]{sheng2006distributed}
W.~Sheng, Q.~Yang, J.~Tan, and N.~Xi.
\newblock Distributed multi-robot coordination in area exploration.
\newblock \emph{Robotics and Autonomous Systems}, 54\penalty0 (12):\penalty0
  945--955, 2006.

\bibitem[Silver et~al.(2017)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, et~al.]{silver2017mastering}
D.~Silver, T.~Hubert, J.~Schrittwieser, I.~Antonoglou, M.~Lai, A.~Guez,
  M.~Lanctot, L.~Sifre, D.~Kumaran, T.~Graepel, et~al.
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock \emph{arXiv preprint arXiv:1712.01815}, 2017.

\bibitem[Spears et~al.(1993)Spears, De~Jong, B{\"a}ck, Fogel, and
  De~Garis]{spears1993}
W.~M. Spears, K.~A. De~Jong, T.~B{\"a}ck, D.~B. Fogel, and H.~De~Garis.
\newblock An overview of evolutionary computation.
\newblock In \emph{European Conference on Machine Learning}, pages 442--459.
  Springer, 1993.

\bibitem[Sutton and Barto(1998)]{sutton1998}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge, 1998.

\bibitem[Thrun et~al.(2000)Thrun, Burgard, and Fox]{thrun2000real}
S.~Thrun, W.~Burgard, and D.~Fox.
\newblock A real-time algorithm for mobile robot mapping with applications to
  multi-robot and 3d mapping.
\newblock In \emph{ICRA}, volume~1, pages 321--328, 2000.

\bibitem[Tumer and Agogino(2007)]{tumer2007distributed}
K.~Tumer and A.~Agogino.
\newblock Distributed agent-based air traffic flow management.
\newblock In \emph{Proceedings of the 6th international joint conference on
  Autonomous agents and multiagent systems}, page 255. ACM, 2007.

\bibitem[Vinyals et~al.(2017)Vinyals, Ewalds, Bartunov, Georgiev, Vezhnevets,
  Yeo, Makhzani, K{\"u}ttler, Agapiou, Schrittwieser,
  et~al.]{vinyals2017starcraft}
O.~Vinyals, T.~Ewalds, S.~Bartunov, P.~Georgiev, A.~S. Vezhnevets, M.~Yeo,
  A.~Makhzani, H.~K{\"u}ttler, J.~Agapiou, J.~Schrittwieser, et~al.
\newblock Starcraft ii: A new challenge for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1708.04782}, 2017.

\bibitem[Williamson et~al.(2009)Williamson, Gerding, and
  Jennings]{williamson2009reward}
S.~A. Williamson, E.~H. Gerding, and N.~R. Jennings.
\newblock Reward shaping for valuing communications during multi-agent
  coordination.
\newblock In \emph{Proceedings of The 8th International Conference on
  Autonomous Agents and Multiagent Systems-Volume 1}, pages 641--648.
  International Foundation for Autonomous Agents and Multiagent Systems, 2009.

\bibitem[Yliniemi et~al.(2014)Yliniemi, Agogino, and
  Tumer]{yliniemi2014multirobot}
L.~Yliniemi, A.~K. Agogino, and K.~Tumer.
\newblock Multirobot coordination for space exploration.
\newblock \emph{AI Magazine}, 35\penalty0 (4):\penalty0 61--74, 2014.

\end{thebibliography}
