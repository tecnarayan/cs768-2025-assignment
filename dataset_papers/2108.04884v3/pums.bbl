\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abebe et~al.(2021)Abebe, Aruleba, Birhane, Kingsley, Obaido, Remy, and
  Sadagopan]{abebe2021narratives}
R.~Abebe, K.~Aruleba, A.~Birhane, S.~Kingsley, G.~Obaido, S.~L. Remy, and
  S.~Sadagopan.
\newblock Narratives and counternarratives on data sharing in africa.
\newblock In \emph{Proc.~of the ACM Conference on Fairness, Accountability, and
  Transparency}, pages 329--341, 2021.

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'\i}k, Langford, and
  Wallach]{agarwal2018reductions}
A.~Agarwal, A.~Beygelzimer, M.~Dud{\'\i}k, J.~Langford, and H.~Wallach.
\newblock A reductions approach to fair classification.
\newblock In \emph{International Conference on Machine Learning}, pages 60--69.
  PMLR, 2018.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
M.~Arjovsky, L.~Bottou, I.~Gulrajani, and D.~Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Bao et~al.(2021)Bao, Zhou, Zottola, Brubach, Desmarais, Horowitz, Lum,
  and Venkatasubramanian]{bao2021s}
M.~Bao, A.~Zhou, S.~Zottola, B.~Brubach, S.~Desmarais, A.~Horowitz, K.~Lum, and
  S.~Venkatasubramanian.
\newblock It's compaslicated: The messy relationship between rai datasets and
  algorithmic fairness benchmarks.
\newblock \emph{arXiv preprint arXiv:2106.05498}, 2021.

\bibitem[Barocas and Selbst(2016)]{barocas2016big}
S.~Barocas and A.~D. Selbst.
\newblock Big data's disparate impact.
\newblock \emph{California Law Review}, 104, 2016.

\bibitem[Barocas et~al.(2019)Barocas, Hardt, and
  Narayanan]{barocas-hardt-narayanan}
S.~Barocas, M.~Hardt, and A.~Narayanan.
\newblock \emph{Fairness and Machine Learning}.
\newblock fairmlbook.org, 2019.
\newblock \url{http://www.fairmlbook.org}.

\bibitem[Bellamy et~al.(2019)Bellamy, Dey, Hind, Hoffman, Houde, Kannan, Lohia,
  Martino, Mehta, Mojsilovi{\'c}, et~al.]{bellamy2019ai}
R.~K. Bellamy, K.~Dey, M.~Hind, S.~C. Hoffman, S.~Houde, K.~Kannan, P.~Lohia,
  J.~Martino, S.~Mehta, A.~Mojsilovi{\'c}, et~al.
\newblock Ai fairness 360: An extensible toolkit for detecting and mitigating
  algorithmic bias.
\newblock \emph{IBM Journal of Research and Development}, 63\penalty0
  (4/5):\penalty0 4--1, 2019.

\bibitem[Benjamin(2019)]{benjamin2019race}
R.~Benjamin.
\newblock \emph{Race after Technology}.
\newblock Polity, 2019.

\bibitem[Bird et~al.(2020)Bird, Dud{\'\i}k, Edgar, Horn, Lutz, Milan, Sameki,
  Wallach, and Walker]{bird2020fairlearn}
S.~Bird, M.~Dud{\'\i}k, R.~Edgar, B.~Horn, R.~Lutz, V.~Milan, M.~Sameki,
  H.~Wallach, and K.~Walker.
\newblock Fairlearn: A toolkit for assessing and improving fairness in ai.
\newblock \emph{Microsoft, Tech. Rep. MSR-TR-2020-32}, 2020.

\bibitem[Bolukbasi et~al.(2016)Bolukbasi, Chang, Zou, Saligrama, and
  Kalai]{bolukbasi2016man}
T.~Bolukbasi, K.-W. Chang, J.~Y. Zou, V.~Saligrama, and A.~T. Kalai.
\newblock Man is to computer programmer as woman is to homemaker? debiasing
  word embeddings.
\newblock \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Buolamwini and Gebru(2018)]{buolamwini2018gender}
J.~Buolamwini and T.~Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Fairness, Accountability and Transparency}, pages 77--91,
  2018.

\bibitem[Calders et~al.(2009)Calders, Kamiran, and
  Pechenizkiy]{calders2009building}
T.~Calders, F.~Kamiran, and M.~Pechenizkiy.
\newblock Building classifiers with independency constraints.
\newblock In \emph{In Proc.~{IEEE} {ICDMW}}, pages 13--18, 2009.

\bibitem[Caliskan et~al.(2017)Caliskan, Bryson, and
  Narayanan]{caliskan2017semantics}
A.~Caliskan, J.~J. Bryson, and A.~Narayanan.
\newblock Semantics derived automatically from language corpora contain
  human-like biases.
\newblock \emph{Science}, 356\penalty0 (6334):\penalty0 183--186, 2017.

\bibitem[Chouldechova(2017)]{chouldechova2017fair}
A.~Chouldechova.
\newblock Fair prediction with disparate impact: A study of bias in recidivism
  prediction instruments.
\newblock \emph{Big data}, 5\penalty0 (2):\penalty0 153--163, 2017.

\bibitem[Eubanks(2018)]{eubanks2018automating}
V.~Eubanks.
\newblock \emph{Automating inequality: How high-tech tools profile, police, and
  punish the poor}.
\newblock St. Martin's Press, 2018.

\bibitem[Flood et~al.(2020)Flood, King, Rodgers, Ruggles, and Warren]{ipums}
S.~Flood, M.~King, R.~Rodgers, S.~Ruggles, and J.~R. Warren.
\newblock {Integrated Public Use Microdata Series, Current Population Survey:
  Version 8.0 [dataset]}, 2020.
\newblock Minneapolis, MN: IPUMS, \url{https://doi.org/10.18128/D030.V8.0}.

\bibitem[Gebru et~al.(2018)Gebru, Morgenstern, Vecchione, Vaughan, Wallach,
  Daum{\'e}~III, and Crawford]{gebru2018datasheets}
T.~Gebru, J.~Morgenstern, B.~Vecchione, J.~W. Vaughan, H.~Wallach,
  H.~Daum{\'e}~III, and K.~Crawford.
\newblock Datasheets for datasets.
\newblock \emph{arXiv:1803.09010}, 2018.

\bibitem[Gray and Suri(2019)]{gray2019ghost}
M.~L. Gray and S.~Suri.
\newblock \emph{Ghost work: how to stop Silicon Valley from building a new
  global underclass}.
\newblock Eamon Dolan Books, 2019.

\bibitem[Hardt and Recht(2021)]{hardtrecht}
M.~Hardt and B.~Recht.
\newblock \emph{Patterns, predictions, and actions: A story about machine
  learning}.
\newblock \url{https://mlstory.org}, 2021.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equality}
M.~Hardt, E.~Price, and N.~Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Proc.~$29$th {NIPS}}, pages 3315--3323, 2016.

\bibitem[Jo and Gebru(2020)]{jo2020lessons}
E.~S. Jo and T.~Gebru.
\newblock Lessons from archives: strategies for collecting sociocultural data
  in machine learning.
\newblock In \emph{Fairness, Accountability, and Transparency}, pages 306--316,
  2020.

\bibitem[Kohavi and Becker(1996)]{kohavi1996uci}
R.~Kohavi and B.~Becker.
\newblock Uci adult data set.
\newblock \emph{UCI Meachine Learning Repository}, 5, 1996.

\bibitem[Langley(2011)]{langley2011changing}
P.~Langley.
\newblock The changing science of machine learning, 2011.

\bibitem[Levendowski(2018)]{levendowski2018copyright}
A.~Levendowski.
\newblock How copyright law can fix artificial intelligence's implicit bias
  problem.
\newblock \emph{Wash. L. Rev.}, 93:\penalty0 579, 2018.

\bibitem[Onuoha(2016)]{onuoha2016point}
M.~Onuoha.
\newblock The point of collection.
\newblock \emph{Data \& Society: Points}, 2016.

\bibitem[Pasquale(2015)]{pasquale2015black}
F.~Pasquale.
\newblock \emph{The black box society}.
\newblock Harvard University Press, 2015.

\bibitem[Paullada et~al.(2020)Paullada, Raji, Bender, Denton, and
  Hanna]{paullada2020data}
A.~Paullada, I.~D. Raji, E.~M. Bender, E.~Denton, and A.~Hanna.
\newblock Data and its (dis) contents: A survey of dataset development and use
  in machine learning research.
\newblock \emph{arXiv preprint arXiv:2012.05345}, 2020.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit_learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Pedreschi et~al.(2008)Pedreschi, Ruggieri, and
  Turini]{pedreschi2008discrimination}
D.~Pedreschi, S.~Ruggieri, and F.~Turini.
\newblock Discrimination-aware data mining.
\newblock In \emph{Proc.~$14$th {SIGKDD}}. ACM, 2008.

\bibitem[Prabhu and Birhane(2020)]{prabhu2020large}
V.~U. Prabhu and A.~Birhane.
\newblock Large image datasets: A pyrrhic win for computer vision?
\newblock \emph{arXiv preprint arXiv:2006.16923}, 2020.

\bibitem[Puri(2019)]{puri_2019}
R.~Puri.
\newblock Mitigating bias in artificial intelligence (ai) models -- ibm
  research, Feb 2019.
\newblock URL
  \url{https://www.ibm.com/blogs/research/2018/02/mitigating-bias-ai-models/}.

\bibitem[Torralba and Efros(2011)]{torralba2011unbiased}
A.~Torralba and A.~A. Efros.
\newblock Unbiased look at dataset bias.
\newblock In \emph{CVPR 2011}, pages 1521--1528. IEEE, 2011.

\bibitem[Yang et~al.(2020)Yang, Qinami, Fei-Fei, Deng, and
  Russakovsky]{yang2020towards}
K.~Yang, K.~Qinami, L.~Fei-Fei, J.~Deng, and O.~Russakovsky.
\newblock Towards fairer datasets: Filtering and balancing the distribution of
  the people subtree in the imagenet hierarchy.
\newblock In \emph{Proceedings of the 2020 Conference on Fairness,
  Accountability, and Transparency}, pages 547--558, 2020.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and
  Dwork]{zemel2013learning}
R.~Zemel, Y.~Wu, K.~Swersky, T.~Pitassi, and C.~Dwork.
\newblock Learning fair representations.
\newblock In \emph{Proceedings of the 30th International Conference on
  International Conference on Machine Learning}, pages III--325, 2013.

\end{thebibliography}
