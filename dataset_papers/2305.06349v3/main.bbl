\begin{thebibliography}{10}

\bibitem{abzianidze-2015-tableau}
Lasha Abzianidze.
\newblock A tableau prover for natural logic and language.
\newblock In {\em Proceedings of the 2015 Conference on Empirical Methods in
  Natural Language Processing}, pages 2492--2502, Lisbon, Portugal, September
  2015. Association for Computational Linguistics.

\bibitem{abzianidze-2017-langpro}
Lasha Abzianidze.
\newblock {L}ang{P}ro: Natural language theorem prover.
\newblock In {\em Proceedings of the 2017 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 115--120,
  Copenhagen, Denmark, September 2017. Association for Computational
  Linguistics.

\bibitem{antoniou2018how}
Antreas Antoniou, Harrison Edwards, and Amos Storkey.
\newblock How to train your {MAML}.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{ALFA}
Sungyong Baik, Myungsub Choi, Janghoon Choi, Heewon Kim, and Kyoung~Mu Lee.
\newblock Meta-learning with adaptive hyperparameters.
\newblock {\em ArXiv}, abs/2011.00209, 2020.

\bibitem{Bayazit2023DiscoveringKS}
Deniz Bayazit, Negar Foroutan, Zeming Chen, Gail Weiss, and Antoine Bosselut.
\newblock Discovering knowledge-critical subnetworks in pretrained language
  models.
\newblock {\em ArXiv}, abs/2310.03084, 2023.

\bibitem{bhagavatula2020abductive}
Chandra Bhagavatula, Ronan~Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari
  Holtzman, Hannah Rashkin, Doug Downey, Scott~Wen tau Yih, and Yejin Choi.
\newblock Abductive commonsense reasoning, 2020.

\bibitem{Bosselut2019DynamicKG}
Antoine Bosselut, Ronan~Le Bras, , and Yejin Choi.
\newblock Dynamic neuro-symbolic knowledge graph construction for zero-shot
  commonsense question answering.
\newblock In {\em Proceedings of the 35th AAAI Conference on Artificial
  Intelligence (AAAI)}, 2021.

\bibitem{bosselut2019comet}
Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli
  Celikyilmaz, and Yejin Choi.
\newblock Comet: Commonsense transformers for automatic knowledge graph
  construction.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 4762--4779, 2019.

\bibitem{bowman-etal-2015-recursive}
Samuel~R. Bowman, Christopher Potts, and Christopher~D. Manning.
\newblock Recursive neural networks can learn logical semantics.
\newblock In {\em Proceedings of the 3rd Workshop on Continuous Vector Space
  Models and their Compositionality}, pages 12--21, Beijing, China, July 2015.
  Association for Computational Linguistics.

\bibitem{carlini2023quantifying}
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian
  Tramer, and Chiyuan Zhang.
\newblock Quantifying memorization across neural language models.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{carlini2021extracting}
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel
  Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar
  Erlingsson, Alina Oprea, and Colin Raffel.
\newblock Extracting training data from large language models, 2021.

\bibitem{inference-blog}
Carol Chen.
\newblock Transformer inference arithmetic.
\newblock https://kipp.ly/blog/transformer-inference-arithmetic/, 2022.

\bibitem{chen-gao-2022-curriculum}
Zeming Chen and Qiyue Gao.
\newblock Curriculum: A broad-coverage benchmark for linguistic phenomena in
  natural language understanding.
\newblock In {\em Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 3204--3219, Seattle, United States, July 2022.
  Association for Computational Linguistics.

\bibitem{chen-etal-2021-neurallog}
Zeming Chen, Qiyue Gao, and Lawrence~S. Moss.
\newblock {N}eural{L}og: Natural language inference with joint neural and
  logical reasoning.
\newblock In {\em Proceedings of *SEM 2021: The Tenth Joint Conference on
  Lexical and Computational Semantics}, pages 78--88, Online, August 2021.
  Association for Computational Linguistics.

\bibitem{chowdhery2022palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
  Abhishek Rao, Parker Barnes, Yi~Tay, Noam Shazeer, Vinodkumar Prabhakaran,
  Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
  Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
  Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
  Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
  Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
  Dohan, Shivani Agrawal, Mark Omernick, Andrew~M. Dai,
  Thanumalayan~Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
  Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
  Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
  Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
\newblock Palm: Scaling language modeling with pathways, 2022.

\bibitem{ciosici-etal-2021-perhaps}
Manuel Ciosici, Joe Cecil, Dong-Ho Lee, Alex Hedges, Marjorie Freedman, and
  Ralph Weischedel.
\newblock Perhaps {PTLM}s should go to school {--} a task to assess open book
  and closed book {QA}.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 6104--6111, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.

\bibitem{RuleTaker}
Peter Clark, Oyvind Tafjord, and Kyle Richardson.
\newblock Transformers as soft reasoners over language.
\newblock In Christian Bessiere, editor, {\em Proceedings of the Twenty-Ninth
  International Joint Conference on Artificial Intelligence, {IJCAI-20}}, pages
  3882--3890. International Joint Conferences on Artificial Intelligence
  Organization, 7 2020.
\newblock Main track.

\bibitem{Da2020AnalyzingCE}
Jeff Da, Ronan~Le Bras, Ximing Lu, Yejin Choi, and Antoine Bosselut.
\newblock Analyzing commonsense emergence in few-shot knowledge models.
\newblock In {\em Proceedings of the Conference on Automated Knowledge Base
  Construction (AKBC)}, 2021.

\bibitem{dai-etal-2022-knowledge}
Damai Dai, Li~Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei.
\newblock Knowledge neurons in pretrained transformers.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 8493--8502, Dublin,
  Ireland, May 2022. Association for Computational Linguistics.

\bibitem{dalvi-etal-2021-explaining}
Bhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan Xie, Hannah Smith,
  Leighanna Pipatanangkura, and Peter Clark.
\newblock Explaining answers with entailment trees.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 7358--7370, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.

\bibitem{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

\bibitem{dunn2017searchqa}
Matthew Dunn, Levent Sagun, Mike Higgins, V.~Ugur Guney, Volkan Cirik, and
  Kyunghyun Cho.
\newblock Searchqa: A new q\&a dataset augmented with context from a search
  engine, 2017.

\bibitem{elazar-etal-2021-measuring}
Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard
  Hovy, Hinrich Sch{\"u}tze, and Yoav Goldberg.
\newblock Measuring and improving consistency in pretrained language models.
\newblock {\em Transactions of the Association for Computational Linguistics},
  9:1012--1031, 2021.

\bibitem{fifty2021measuring}
Christopher Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, Rohan Anil, and Chelsea
  Finn.
\newblock Measuring and harnessing transference in multi-task learning, 2021.

\bibitem{Flach2000}
Peter~A. Flach and Antonis~C. Kakas.
\newblock Abductive and inductive reasoning: Background and issues.
\newblock In {\em Applied Logic Series}, pages 1--27. Springer Netherlands,
  2000.

\bibitem{Gaskell2022}
Alexander Gaskell, Yishu Miao, Francesca Toni, and Lucia Specia.
\newblock Logically consistent adversarial attacks for soft theorem provers.
\newblock In {\em Proceedings of the Thirty-First International Joint
  Conference on Artificial Intelligence}. International Joint Conferences on
  Artificial Intelligence Organization, July 2022.

\bibitem{Goel2017}
Vinod Goel, Gorka Navarrete, Ira~A. Noveck, and J{\'{e}}r{\^{o}}me Prado.
\newblock Editorial: The reasoning brain: The interplay between cognitive
  neuroscience and theories of reasoning.
\newblock {\em Frontiers in Human Neuroscience}, 10, January 2017.

\bibitem{CLUTRR-SG}
Nicolas Gontier, Koustuv Sinha, Siva Reddy, and Christopher~Joseph Pal.
\newblock Measuring systematic generalization in neural proof generation with
  transformers.
\newblock {\em ArXiv}, abs/2009.14786, 2020.

\bibitem{folio}
Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Luke
  Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell, David Peng,
  Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan,
  Jungo Kasai, Tao Yu, Rui Zhang, Shafiq Joty, Alexander~R. Fabbri, Wojciech
  Kryscinski, Xi~Victoria Lin, Caiming Xiong, and Dragomir Radev.
\newblock Folio: Natural language reasoning with first-order logic, 2022.

\bibitem{hase2021language}
Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin
  Stoyanov, Mohit Bansal, and Srinivasan Iyer.
\newblock Do language models have beliefs? methods for detecting, updating, and
  visualizing model beliefs, 2021.

\bibitem{hendrycks2021measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
  Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding, 2021.

\bibitem{hong-etal-2022-metgen}
Ruixin Hong, Hongming Zhang, Xintong Yu, and Changshui Zhang.
\newblock {METGEN}: A module-based entailment tree generation framework for
  answer explanation.
\newblock In {\em Findings of the Association for Computational Linguistics:
  NAACL 2022}, pages 1887--1905, Seattle, United States, July 2022. Association
  for Computational Linguistics.

\bibitem{hu2022lora}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{hu-etal-2020-monalog}
Hai Hu, Qi~Chen, Kyle Richardson, Atreyee Mukherjee, Lawrence~S. Moss, and
  Sandra Kuebler.
\newblock {M}ona{L}og: a lightweight system for natural language inference
  based on monotonicity.
\newblock In {\em Proceedings of the Society for Computation in Linguistics
  2020}, pages 334--344, New York, New York, January 2020. Association for
  Computational Linguistics.

\bibitem{hu-etal-2016-harnessing}
Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing.
\newblock Harnessing deep neural networks with logic rules.
\newblock In {\em Proceedings of the 54th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 2410--2420, Berlin,
  Germany, August 2016. Association for Computational Linguistics.

\bibitem{hwang2021comet}
Jena~D Hwang, Chandra Bhagavatula, Ronan Le~Bras, Jeff Da, Keisuke Sakaguchi,
  Antoine Bosselut, and Yejin Choi.
\newblock (comet-) atomic 2020: On symbolic and neural commonsense knowledge
  graphs.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 6384--6392, 2021.

\bibitem{jiang-etal-2021-im}
Liwei Jiang, Antoine Bosselut, Chandra Bhagavatula, and Yejin Choi.
\newblock {``}{I}{'}m not mad{''}: Commonsense implications of negation and
  contradiction.
\newblock In {\em Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 4380--4397, Online, June 2021. Association for
  Computational Linguistics.

\bibitem{jiang-etal-2020-know}
Zhengbao Jiang, Frank~F. Xu, Jun Araki, and Graham Neubig.
\newblock How can we know what language models know?
\newblock {\em Transactions of the Association for Computational Linguistics},
  8:423--438, 2020.

\bibitem{joshi-etal-2017-triviaqa}
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer.
\newblock {T}rivia{QA}: A large scale distantly supervised challenge dataset
  for reading comprehension.
\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 1601--1611,
  Vancouver, Canada, July 2017. Association for Computational Linguistics.

\bibitem{jung-etal-2022-maieutic}
Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula,
  Ronan Le~Bras, and Yejin Choi.
\newblock Maieutic prompting: Logically consistent reasoning with recursive
  explanations.
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 1266--1279, Abu Dhabi, United Arab
  Emirates, December 2022. Association for Computational Linguistics.

\bibitem{kwiatkowski-etal-2019-natural}
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
  Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
  Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang,
  Andrew~M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.
\newblock Natural questions: A benchmark for question answering research.
\newblock {\em Transactions of the Association for Computational Linguistics},
  7:452--466, 2019.

\bibitem{Lenat_Prakash_Shepherd_1985}
Douglas~B. Lenat, Mayank Prakash, and Mary Shepherd.
\newblock Cyc: Using common sense knowledge to overcome brittleness and
  knowledge acquisition bottlenecks.
\newblock {\em AI Magazine}, 6(4):65, Mar. 1985.

\bibitem{li-etal-2019-logic}
Tao Li, Vivek Gupta, Maitrey Mehta, and Vivek Srikumar.
\newblock A logic-driven framework for consistency of neural models.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 3924--3935, Hong Kong,
  China, November 2019. Association for Computational Linguistics.

\bibitem{liang-etal-2021-explainable}
Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu.
\newblock Explainable multi-hop verbal reasoning through internal monologue.
\newblock In {\em Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1225--1250, Online, June 2021. Association for
  Computational Linguistics.

\bibitem{liu2023evaluating}
Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou, and Yue Zhang.
\newblock Evaluating the logical reasoning ability of chatgpt and gpt-4, 2023.

\bibitem{AdamW}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{maccartney-manning-2007-natural}
Bill MacCartney and Christopher~D. Manning.
\newblock Natural logic for textual inference.
\newblock In {\em Proceedings of the {ACL}-{PASCAL} Workshop on Textual
  Entailment and Paraphrasing}, pages 193--200, Prague, June 2007. Association
  for Computational Linguistics.

\bibitem{martinez-gomez-etal-2017-demand}
Pascual Mart{\'\i}nez-G{\'o}mez, Koji Mineshima, Yusuke Miyao, and Daisuke
  Bekki.
\newblock On-demand injection of lexical knowledge for recognising textual
  entailment.
\newblock In {\em Proceedings of the 15th Conference of the {E}uropean Chapter
  of the Association for Computational Linguistics: Volume 1, Long Papers},
  pages 710--720, Valencia, Spain, April 2017. Association for Computational
  Linguistics.

\bibitem{meng2022locating}
Kevin Meng, David Bau, Alex~J Andonian, and Yonatan Belinkov.
\newblock Locating and editing factual associations in {GPT}.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{meng2023massediting}
Kevin Meng, Arnab~Sen Sharma, Alex~J Andonian, Yonatan Belinkov, and David Bau.
\newblock Mass-editing memory in a transformer.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{Metaxiotis2002}
K.~S. Metaxiotis, Dimitris Askounis, and John Psarras.
\newblock Expert systems in production planning and scheduling: A
  state-of-the-art survey.
\newblock {\em Journal of Intelligent Manufacturing}, 13(4):253--260, 2002.

\bibitem{Metaxiotis2002ExpertSI}
Kostas~S. Metaxiotis, Dimitris Askounis, and John~E. Psarras.
\newblock Expert systems in production planning and scheduling: A
  state-of-the-art survey.
\newblock {\em Journal of Intelligent Manufacturing}, 13:253--260, 2002.

\bibitem{model_edit}
Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher~D.
  Manning.
\newblock Fast model editing at scale, 2021.

\bibitem{Muggleton1994}
Stephen Muggleton and Luc de~Raedt.
\newblock Inductive logic programming: Theory and methods.
\newblock {\em The Journal of Logic Programming}, 19-20:629--679, May 1994.

\bibitem{ouyang2022training}
Long Ouyang, Jeff Wu, Xu~Jiang, Diogo Almeida, Carroll~L. Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John
  Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
  Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.
\newblock Training language models to follow instructions with human feedback,
  2022.

\bibitem{petroni2020context}
Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu,
  Alexander~H. Miller, and Sebastian Riedel.
\newblock How context affects language models' factual predictions, 2020.

\bibitem{petroni-etal-2019-language}
Fabio Petroni, Tim Rockt{\"a}schel, Sebastian Riedel, Patrick Lewis, Anton
  Bakhtin, Yuxiang Wu, and Alexander Miller.
\newblock Language models as knowledge bases?
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 2463--2473, Hong Kong,
  China, November 2019. Association for Computational Linguistics.

\bibitem{qu-etal-2022-interpretable}
Hanhao Qu, Yu~Cao, Jun Gao, Liang Ding, and Ruifeng Xu.
\newblock Interpretable proof generation via iterative backward reasoning.
\newblock In {\em Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 2968--2981, Seattle, United States, July 2022.
  Association for Computational Linguistics.

\bibitem{gpt-2}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer, 2020.

\bibitem{Richardson2022}
Kyle Richardson and Ashish Sabharwal.
\newblock Pushing the limits of rule reasoning in transformers through natural
  language satisfiability.
\newblock {\em Proceedings of the {AAAI} Conference on Artificial
  Intelligence}, 36(10):11209--11219, June 2022.

\bibitem{roberts-etal-2020-much}
Adam Roberts, Colin Raffel, and Noam Shazeer.
\newblock How much knowledge can you pack into the parameters of a language
  model?
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 5418--5426, Online, November
  2020. Association for Computational Linguistics.

\bibitem{rogers-etal-2020-primer}
Anna Rogers, Olga Kovaleva, and Anna Rumshisky.
\newblock A primer in {BERT}ology: What we know about how {BERT} works.
\newblock {\em Transactions of the Association for Computational Linguistics},
  8:842--866, 2020.

\bibitem{Rudin2019}
Cynthia Rudin.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock {\em Nature Machine Intelligence}, 1(5):206--215, May 2019.

\bibitem{saeed-etal-2021-rulebert}
Mohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti.
\newblock {R}ule{BERT}: Teaching soft rules to pre-trained language models.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 1460--1476, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.

\bibitem{saha-etal-2021-multiprover}
Swarnadeep Saha, Prateek Yadav, and Mohit Bansal.
\newblock multi{PR}over: Generating multiple proofs for improved
  interpretability in rule reasoning.
\newblock In {\em Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 3662--3677, Online, June 2021. Association for
  Computational Linguistics.

\bibitem{sanyal-etal-2022-robustlr}
Soumya Sanyal, Zeyi Liao, and Xiang Ren.
\newblock {R}obust{LR}: A diagnostic benchmark for evaluating logical
  robustness of deductive reasoners.
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 9614--9631, Abu Dhabi, United Arab
  Emirates, December 2022. Association for Computational Linguistics.

\bibitem{sanyal-etal-2022-fairr}
Soumya Sanyal, Harman Singh, and Xiang Ren.
\newblock {F}ai{RR}: Faithful and robust deductive reasoning over natural
  language.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 1075--1093, Dublin,
  Ireland, May 2022. Association for Computational Linguistics.

\bibitem{shi-etal-2023-distractors}
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed~H. Chi,
  Nathanael Sch{\"{a}}rli, and Denny Zhou.
\newblock Large language models can be easily distracted by irrelevant context.
\newblock {\em CoRR}, abs/2302.00093, 2023.

\bibitem{shin-etal-2020-autoprompt}
Taylor Shin, Yasaman Razeghi, Robert~L. Logan~IV, Eric Wallace, and Sameer
  Singh.
\newblock {A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with
  {A}utomatically {G}enerated {P}rompts.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4222--4235, Online, November
  2020. Association for Computational Linguistics.

\bibitem{CLUTRR}
Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William~L.
  Hamilton.
\newblock {CLUTRR}: A diagnostic benchmark for inductive reasoning from text.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 4506--4515, Hong Kong,
  China, November 2019. Association for Computational Linguistics.

\bibitem{srivastava2022imitation}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal~Md Shoeb, Abubakar
  Abid, Adam Fisch, Adam~R. Brown, Adam Santoro, Aditya Gupta, Adrià
  Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea
  Power, Alex Ray, Alex Warstadt, Alexander~W. Kocurek, Ali Safaya, Ali Tazarv,
  Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda
  Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman~S. Iyer, Anders Andreassen,
  Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew Dai, Andrew La,
  Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh
  Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi,
  Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish
  Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakaş, B.~Ryan
  Roberts, Bao~Sheng Loe, Barret Zoph, Bartłomiej Bojanowski, Batuhan Özyurt,
  Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk
  Ekmekci, Bill~Yuchen Lin, Blake Howald, Cameron Diao, Cameron Dour, Catherine
  Stinson, Cedrick Argueta, César~Ferri Ramírez, Chandan Singh, Charles
  Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris
  Waites, Christian Voigt, Christopher~D. Manning, Christopher Potts, Cindy
  Ramirez, Clara~E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft,
  Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan
  Roth, Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel~Moseguí
  González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito,
  Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep
  Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam,
  Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri~Coelho Mollo, Diyi Yang,
  Dong-Ho Lee, Ekaterina Shutova, Ekin~Dogus Cubuk, Elad Segal, Eleanor
  Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele
  Rodola, Emma Lam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang, Ethan~A.
  Chi, Ethan Dyer, Ethan Jerzak, Ethan Kim, Eunice~Engefu Manyasi, Evgenii
  Zheltonozhskii, Fanyue Xia, Fatemeh Siar, Fernando Martínez-Plumed,
  Francesca Happé, Francois Chollet, Frieda Rong, Gaurav Mishra, Genta~Indra
  Winata, Gerard de~Melo, Germán Kruszewski, Giambattista Parascandolo,
  Giorgio Mariani, Gloria Wang, Gonzalo Jaimovitch-López, Gregor Betz, Guy
  Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi,
  Harsh Mehta, Hayden Bogar, Henry Shevlin, Hinrich Schütze, Hiromu Yakura,
  Hongming Zhang, Hugh~Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack
  Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime~Fernández
  Fisac, James~B. Simon, James Koppel, James Zheng, James Zou, Jan Kocoń, Jana
  Thompson, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang,
  Jason Wei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer
  Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu,
  Jiaming Song, Jillian Tang, Joan Waweru, John Burden, John Miller, John~U.
  Balis, Jonathan Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo,
  Joseph Boudeman, Joseph Jones, Joshua~B. Tenenbaum, Joshua~S. Rule, Joyce
  Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan,
  Katerina Ignatyeva, Katja Markert, Kaustubh~D. Dhole, Kevin Gimpel, Kevin
  Omondi, Kory Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar Shridhar,
  Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li~Zhang, Liam
  Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe Morency, Luca
  Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis~Oliveros
  Colón, Luke Metz, Lütfi~Kerem Şenel, Maarten Bosma, Maarten Sap, Maartje
  ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan,
  Marco Marelli, Marco Maru, Maria Jose~Ramírez Quintana, Marie Tolkiehn,
  Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew~L. Leavitt,
  Matthias Hagen, Mátyás Schubert, Medina~Orduna Baitemirova, Melody Arnaud,
  Melvin McElrath, Michael~A. Yee, Michael Cohen, Michael Gu, Michael
  Ivanitskiy, Michael Starritt, Michael Strube, Michał Swędrowski, Michele
  Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac
  Suzgun, Mo~Tiwari, Mohit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh Gheini,
  Mukund~Varma T, Nanyun Peng, Nathan Chi, Nayeon Lee, Neta Gur-Ari Krakover,
  Nicholas Cameron, Nicholas Roberts, Nick Doiron, Nikita Nangia, Niklas
  Deckers, Niklas Muennighoff, Nitish~Shirish Keskar, Niveditha~S. Iyer, Noah
  Constant, Noah Fiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi,
  Omer Levy, Owain Evans, Pablo Antonio~Moreno Casares, Parth Doshi, Pascale
  Fung, Paul~Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy
  Liang, Peter Chang, Peter Eckersley, Phu~Mon Htut, Pinyu Hwang, Piotr
  Miłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing
  Lyu, Qinlang Chen, Rabin Banjade, Rachel~Etta Rudolph, Raefer Gabriel, Rahel
  Habacker, Ramón~Risco Delgado, Raphaël Millière, Rhythm Garg, Richard
  Barnes, Rif~A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan
  Sikand, Roman Novak, Roman Sitelew, Ronan LeBras, Rosanne Liu, Rowan Jacobs,
  Rui Zhang, Ruslan Salakhutdinov, Ryan Chi, Ryan Lee, Ryan Stovall, Ryan
  Teehan, Rylan Yang, Sahib Singh, Saif~M. Mohammad, Sajant Anand, Sam
  Dillavou, Sam Shleifer, Sam Wiseman, Samuel Gruetter, Samuel~R. Bowman,
  Samuel~S. Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah~A. Rous, Sarik
  Ghazarian, Sayan Ghosh, Sean Casey, Sebastian Bischoff, Sebastian Gehrmann,
  Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon Zhou, Shashank
  Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang~Shane Gu, Shubh
  Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima, Debnath, Siamak
  Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha~Priscilla Makini,
  Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan
  Divic, Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad,
  Steven~T. Piantadosi, Stuart~M. Shieber, Summer Misherghi, Svetlana
  Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq
  Ali, Tatsu Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas
  Phan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Timothy
  Telleen-Lawton, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala
  Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg,
  Victoria Nyamai, Vikas Raunak, Vinay Ramasesh, Vinay~Uday Prabhu, Vishakh
  Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang,
  Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen,
  Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi,
  Yichi Yang, Yiding Hao, Yifu Chen, Yonatan Belinkov, Yu~Hou, Yufang Hou,
  Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie~J. Wang, Zirui
  Wang, and Ziyi Wu.
\newblock Beyond the imitation game: Quantifying and extrapolating the
  capabilities of language models, 2022.

\bibitem{ProofWriter}
Oyvind Tafjord, Bhavana Dalvi, and Peter Clark.
\newblock {P}roof{W}riter: Generating implications, proofs, and abductive
  statements over natural language.
\newblock In {\em Findings of the Association for Computational Linguistics:
  ACL-IJCNLP 2021}, pages 3621--3634, Online, August 2021. Association for
  Computational Linguistics.

\bibitem{tafjord-etal-2022-entailer}
Oyvind Tafjord, Bhavana Dalvi~Mishra, and Peter Clark.
\newblock Entailer: Answering questions with faithful and truthful chains of
  reasoning.
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 2078--2093, Abu Dhabi, United Arab
  Emirates, December 2022. Association for Computational Linguistics.

\bibitem{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in Neural Information
  Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem{wang-etal-2020-balancing}
Xinyi Wang, Yulia Tsvetkov, and Graham Neubig.
\newblock Balancing training for multilingual neural machine translation.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 8526--8537, Online, July 2020. Association
  for Computational Linguistics.

\bibitem{wang-etal-2020-negative}
Zirui Wang, Zachary~C. Lipton, and Yulia Tsvetkov.
\newblock On negative interference in multilingual models: Findings and a
  meta-learning treatment.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4438--4450, Online, November
  2020. Association for Computational Linguistics.

\bibitem{wolf2020huggingfaces}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander~M. Rush.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing, 2020.

\bibitem{yanaka-etal-2020-neural}
Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, and Kentaro Inui.
\newblock Do neural models learn systematicity of monotonicity inference in
  natural language?
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 6105--6117, Online, July 2020. Association
  for Computational Linguistics.

\bibitem{yanaka-etal-2018-acquisition}
Hitomi Yanaka, Koji Mineshima, Pascual Mart{\'\i}nez-G{\'o}mez, and Daisuke
  Bekki.
\newblock Acquisition of phrase correspondences using natural deduction proofs.
\newblock In {\em Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 756--766, New Orleans,
  Louisiana, June 2018. Association for Computational Linguistics.

\bibitem{yang-etal-2022-generating}
Kaiyu Yang, Jia Deng, and Danqi Chen.
\newblock Generating natural language proofs with verifier-guided search.
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 89--105, Abu Dhabi, United Arab Emirates,
  December 2022. Association for Computational Linguistics.

\bibitem{yang2022generating}
Kaiyu Yang, Jia Deng, and Danqi Chen.
\newblock Generating natural language proofs with verifier-guided search, 2022.

\bibitem{yang2023logical}
Zonglin Yang, Xinya Du, Rui Mao, Jinjie Ni, and Erik Cambria.
\newblock Logical reasoning over natural language as knowledge representation:
  A survey, 2023.

\bibitem{yao2022kformer}
Yunzhi Yao, Shaohan Huang, Li~Dong, Furu Wei, Huajun Chen, and Ningyu Zhang.
\newblock Kformer: Knowledge injection in transformer feed-forward layers,
  2022.

\bibitem{yu2023generate}
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal,
  Chenguang Zhu, Michael Zeng, and Meng Jiang.
\newblock Generate rather than retrieve: Large language models are strong
  context generators.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\end{thebibliography}
