\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aggarwal et~al.(2024)Aggarwal, Fikioris, and
  Zhao]{aggarwal2024noregret}
Gagan Aggarwal, Giannis Fikioris, and Mingfei Zhao.
\newblock No-regret algorithms in non-truthful auctions with budget and {ROI}
  constraints.
\newblock \emph{arXiv preprint}, abs/2404.09832, 2024.

\bibitem[Agrawal and Devanur(2014)]{agrawal2014bandits}
Shipra Agrawal and Nikhil~R. Devanur.
\newblock Bandits with concave rewards and convex knapsacks.
\newblock In \emph{{EC}}, pages 989--1006. {ACM}, 2014.

\bibitem[Agrawal and Devanur(2019)]{agrawal2019bandits}
Shipra Agrawal and Nikhil~R Devanur.
\newblock Bandits with global convex constraints and objective.
\newblock \emph{Operations Research}, 67\penalty0 (5):\penalty0 1486--1502,
  2019.

\bibitem[Auer and Chiang(2016)]{AuerC16}
Peter Auer and Chao{-}Kai Chiang.
\newblock An algorithm with nearly optimal pseudo-regret for both stochastic
  and adversarial bandits.
\newblock In \emph{{COLT}}, volume~49 of \emph{{JMLR} Workshop and Conference
  Proceedings}, pages 116--120. JMLR.org, 2016.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM journal on computing}, 32\penalty0 (1):\penalty0 48--77,
  2002.

\bibitem[Badanidiyuru et~al.(2013)Badanidiyuru, Kleinberg, and
  Slivkins]{badanidiyuru2013bandits}
Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins.
\newblock Bandits with knapsacks.
\newblock In \emph{2013 IEEE 54th Annual Symposium on Foundations of Computer
  Science, FOCS 2013}, pages 207--216. IEEE, 2013.

\bibitem[Badanidiyuru et~al.(2018)Badanidiyuru, Kleinberg, and
  Slivkins]{Badanidiyuru2018jacm}
Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins.
\newblock Bandits with knapsacks.
\newblock \emph{J. ACM}, 65\penalty0 (3), 2018.

\bibitem[Balseiro et~al.(2023)Balseiro, Kroer, and Kumar]{Balseiro2023}
Santiago Balseiro, Christian Kroer, and Rachitesh Kumar.
\newblock Online resource allocation under horizon uncertainty.
\newblock \emph{SIGMETRICS Perform. Eval. Rev.}, 51\penalty0 (1):\penalty0
  63â€“64, 2023.

\bibitem[Balseiro and Gur(2019)]{balseiro2019learning}
Santiago~R Balseiro and Yonatan Gur.
\newblock Learning in repeated auctions with budgets: Regret minimization and
  equilibrium.
\newblock \emph{Management Science}, 65\penalty0 (9):\penalty0 3952--3968,
  2019.

\bibitem[Balseiro et~al.(2022)Balseiro, Lu, and Mirrokni]{balseiro2022best}
Santiago~R Balseiro, Haihao Lu, and Vahab Mirrokni.
\newblock The best of many worlds: Dual mirror descent for online allocation
  problems.
\newblock \emph{Operations Research}, 2022.

\bibitem[Bernasconi et~al.(2024{\natexlab{a}})Bernasconi, Castiglioni, and
  Celli]{bernasconi2024noregret}
Martino Bernasconi, Matteo Castiglioni, and Andrea Celli.
\newblock No-regret is not enough! bandits with general constraints through
  adaptive regret minimization.
\newblock \emph{arXiv preprint}, abs/2405.06575, 2024{\natexlab{a}}.

\bibitem[Bernasconi et~al.(2024{\natexlab{b}})Bernasconi, Castiglioni, Celli,
  and Fusco]{BernasconiCCF2024}
Martino Bernasconi, Matteo Castiglioni, Andrea Celli, and Federico Fusco.
\newblock No-regret learning in bilateral trade via global budget balance.
\newblock In \emph{STOC}. ACM, 2024{\natexlab{b}}.

\bibitem[Bernasconi et~al.(2024{\natexlab{c}})Bernasconi, Castiglioni, Celli,
  and Fusco]{bernasconi2023bandits}
Martino Bernasconi, Matteo Castiglioni, Andrea Celli, and Federico Fusco.
\newblock Bandits with replenishable knapsacks: the best of both worlds.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2024{\natexlab{c}}.

\bibitem[Bubeck and Slivkins(2012)]{BubeckS12}
S{\'{e}}bastien Bubeck and Aleksandrs Slivkins.
\newblock The best of both worlds: Stochastic and adversarial bandits.
\newblock In \emph{{COLT}}, volume~23 of \emph{{JMLR} Proceedings}, pages
  42.1--42.23. JMLR.org, 2012.

\bibitem[Castiglioni et~al.(2022{\natexlab{a}})Castiglioni, Celli, and
  Kroer]{castiglioni2022online}
Matteo Castiglioni, Andrea Celli, and Christian Kroer.
\newblock Online learning with knapsacks: the best of both worlds.
\newblock In \emph{International Conference on Machine Learning}, pages
  2767--2783. PMLR, 2022{\natexlab{a}}.

\bibitem[Castiglioni et~al.(2022{\natexlab{b}})Castiglioni, Celli, Marchesi,
  Romano, and Gatti]{castiglioni2022unifying}
Matteo Castiglioni, Andrea Celli, Alberto Marchesi, Giulia Romano, and Nicola
  Gatti.
\newblock A unifying framework for online optimization with long-term
  constraints.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 33589--33602, 2022{\natexlab{b}}.

\bibitem[Castiglioni et~al.(2024)Castiglioni, Celli, and
  Kroer]{castiglioni2023online}
Matteo Castiglioni, Andrea Celli, and Christian Kroer.
\newblock Online learning under budget and roi constraints via weak adaptivity.
\newblock \emph{arXiv preprint arXiv:2302.01203}, 2024.

\bibitem[Fikioris and Tardos(2023)]{fikioris2023approximately}
Giannis Fikioris and {\'E}va Tardos.
\newblock Approximately stationary bandits with knapsacks.
\newblock In \emph{Proceedings of Thirty Sixth Conference on Learning Theory},
  volume 195, pages 3758--3782, 12--15 Jul 2023.

\bibitem[Hazan et~al.(2016)]{hazan2016introduction}
Elad Hazan et~al.
\newblock \emph{Introduction to online convex optimization}, volume~2.
\newblock Now Publishers, Inc., 2016.

\bibitem[Immorlica et~al.(2019)Immorlica, Sankararaman, Schapire, and
  Slivkins]{immorlica2019adversarial}
Nicole Immorlica, Karthik~Abinav Sankararaman, Robert Schapire, and Aleksandrs
  Slivkins.
\newblock Adversarial bandits with knapsacks.
\newblock In \emph{60th IEEE Annual Symposium on Foundations of Computer
  Science, FOCS 2019}, pages 202--219. IEEE Computer Society, 2019.

\bibitem[Immorlica et~al.(2022)Immorlica, Sankararaman, Schapire, and
  Slivkins]{immorlica2022jacm}
Nicole Immorlica, Karthik Sankararaman, Robert Schapire, and Aleksandrs
  Slivkins.
\newblock Adversarial bandits with knapsacks.
\newblock \emph{J. ACM}, 69\penalty0 (6), 2022.
\newblock ISSN 0004-5411.

\bibitem[Kesselheim and Singla(2020)]{kesselheim2020online}
Thomas Kesselheim and Sahil Singla.
\newblock Online learning with vector costs and bandits with knapsacks.
\newblock In \emph{Conference on Learning Theory}, pages 2286--2305. PMLR,
  2020.

\bibitem[Kumar and Kleinberg(2022)]{kumar2022non}
Raunak Kumar and Robert Kleinberg.
\newblock Non-monotonic resource utilization in the bandits with knapsacks
  problem.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Liu et~al.(2022)Liu, Jiang, and Li]{liu2022non}
Shang Liu, Jiashuo Jiang, and Xiaocheng Li.
\newblock Non-stationary bandits with knapsacks.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 16522--16532, 2022.

\bibitem[Neu(2015)]{neu2015explore}
Gergely Neu.
\newblock Explore no more: Improved high-probability regret bounds for
  non-stochastic bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 28, 2015.

\bibitem[Seldin and Lugosi(2017)]{SeldinL17}
Yevgeny Seldin and G{\'{a}}bor Lugosi.
\newblock An improved parametrization and analysis of the {EXP3++} algorithm
  for stochastic and adversarial bandits.
\newblock In \emph{{COLT}}, volume~65 of \emph{Proceedings of Machine Learning
  Research}, pages 1743--1759. {PMLR}, 2017.

\bibitem[Seldin and Slivkins(2014)]{SeldinS14}
Yevgeny Seldin and Aleksandrs Slivkins.
\newblock One practical algorithm for both stochastic and adversarial bandits.
\newblock In \emph{{ICML}}, volume~32 of \emph{{JMLR} Workshop and Conference
  Proceedings}, pages 1287--1295. JMLR.org, 2014.

\bibitem[Slivkins et~al.(2023)Slivkins, Sankararaman, and
  Foster]{slivkins2023contextual}
Aleksandrs Slivkins, Karthik~Abinav Sankararaman, and Dylan~J Foster.
\newblock Contextual bandits with packing and covering constraints: A modular
  lagrangian approach via regression.
\newblock In \emph{The Thirty Sixth Annual Conference on Learning Theory},
  pages 4633--4656. PMLR, 2023.

\bibitem[Wei and Luo(2018)]{WeiL18}
Chen{-}Yu Wei and Haipeng Luo.
\newblock More adaptive algorithms for adversarial bandits.
\newblock In \emph{{COLT}}, volume~75 of \emph{Proceedings of Machine Learning
  Research}, pages 1263--1291. {PMLR}, 2018.

\bibitem[Zimmert and Seldin(2021)]{ZimmertS21}
Julian Zimmert and Yevgeny Seldin.
\newblock Tsallis-inf: An optimal algorithm for stochastic and adversarial
  bandits.
\newblock \emph{J. Mach. Learn. Res.}, 22:\penalty0 28:1--28:49, 2021.

\end{thebibliography}
