\begin{thebibliography}{}

\bibitem[Adadi and Berrada, 2018]{adadi2018peeking}
Adadi, A. and Berrada, M. (2018).
\newblock Peeking inside the black-box: a survey on explainable artificial
  intelligence (xai).
\newblock {\em IEEE access}, 6:52138--52160.

\bibitem[Adebayo et~al., 2018]{adebayo2018sanity}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., and Kim, B.
  (2018).
\newblock Sanity checks for saliency maps.
\newblock {\em arXiv preprint arXiv:1810.03292}.

\bibitem[Allis, 1988]{allis1988knowledge}
Allis, L.~V. (1988).
\newblock A knowledge-based approach of connect-four.
\newblock {\em J. Int. Comput. Games Assoc.}, 11(4):165.

\bibitem[Anders et~al., 2020]{anders2020fairwashing}
Anders, C., Pasliev, P., Dombrowski, A.-K., M{\"u}ller, K.-R., and Kessel, P.
  (2020).
\newblock Fairwashing explanations with off-manifold detergent.
\newblock In {\em International Conference on Machine Learning}, pages
  314--323. PMLR.

\bibitem[Arrieta et~al., 2020]{arrieta2020explainable}
Arrieta, A.~B., D{\'\i}az-Rodr{\'\i}guez, N., Del~Ser, J., Bennetot, A., Tabik,
  S., Barbado, A., Garc{\'\i}a, S., Gil-L{\'o}pez, S., Molina, D., Benjamins,
  R., et~al. (2020).
\newblock Explainable artificial intelligence (xai): Concepts, taxonomies,
  opportunities and challenges toward responsible ai.
\newblock {\em Information Fusion}, 58:82--115.

\bibitem[Bach et~al., 2015]{bach-plos15}
Bach, S., Binder, A., Montavon, G., Klauschen, F., Müller, K.-R., and Samek,
  W. (2015).
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock {\em PLOS ONE}, 10(7):1--46.

\bibitem[Biessmann and Refiano, 2021]{biessmann2021quality}
Biessmann, F. and Refiano, D. (2021).
\newblock Quality metrics for transparent machine learning with and without
  humans in the loop are not correlated.
\newblock {\em arXiv preprint arXiv:2107.02033}.

\bibitem[Chalkiadakis et~al., 2011]{chalkiadakis2011computational}
Chalkiadakis, G., Elkind, E., and Wooldridge, M. (2011).
\newblock Computational aspects of cooperative game theory.
\newblock {\em Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 5(6):1--168.

\bibitem[Clausen et~al., 2021]{clausen2021improvements}
Clausen, C., Reichhuber, S., Thomsen, I., and Tomforde, S. (2021).
\newblock Improvements to increase the efficiency of the alphazero algorithm: A
  case study in the game'connect 4'.
\newblock In {\em ICAART (2)}, pages 803--811.

\bibitem[Crespo, 2019]{crespo2020master}
Crespo, J. (2019).
\newblock Reinforcement learning for two-player zero-sum games.
\newblock Master's thesis, Tecnico Lisboa,
  \url{https://fenix.tecnico.ulisboa.pt/downloadFile/1689244997260153/81811-joao-crespo_dissertacao.pdf}.

\bibitem[Dabas et~al., 2022]{dabas2022solving}
Dabas, M., Dahiya, N., and Pushparaj, P. (2022).
\newblock Solving connect 4 using artificial intelligence.
\newblock In {\em International Conference on Innovative Computing and
  Communications}, pages 727--735. Springer.

\bibitem[Deng and Papadimitriou, 1994]{deng1994complexity}
Deng, X. and Papadimitriou, C.~H. (1994).
\newblock On the complexity of cooperative solution concepts.
\newblock {\em Mathematics of operations research}, 19(2):257--266.

\bibitem[Dimanov et~al., 2020]{dimanov2020you}
Dimanov, B., Bhatt, U., Jamnik, M., and Weller, A. (2020).
\newblock You shouldn't trust me: Learning models which conceal unfairness from
  multiple explanation methods.
\newblock In {\em SafeAI@ AAAI}.

\bibitem[Dombrowski et~al., 2019]{dombrowski2019explanations}
Dombrowski, A.-K., Alber, M., Anders, C.~J., Ackermann, M., M{\"u}ller, K.-R.,
  and Kessel, P. (2019).
\newblock Explanations can be manipulated and geometry is to blame.
\newblock {\em arXiv preprint arXiv:1906.07983}.

\bibitem[Doshi-Velez and Kim, 2017]{doshi2017towards}
Doshi-Velez, F. and Kim, B. (2017).
\newblock Towards a rigorous science of interpretable machine learning.
\newblock {\em arXiv preprint arXiv:1702.08608}.

\bibitem[Fong and Vedaldi, 2017]{fong2017interpretable}
Fong, R.~C. and Vedaldi, A. (2017).
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 3429--3437.

\bibitem[Frye et~al., 2020]{frye2020shapley}
Frye, C., de~Mijolla, D., Begley, T., Cowton, L., Stanley, M., and Feige, I.
  (2020).
\newblock Shapley explainability on the data manifold.
\newblock {\em arXiv preprint arXiv:2006.01272}.

\bibitem[Heo et~al., 2019]{heo2019fooling}
Heo, J., Joo, S., and Moon, T. (2019).
\newblock Fooling neural network interpretations via adversarial model
  manipulation.
\newblock {\em Advances in Neural Information Processing Systems},
  32:2925--2936.

\bibitem[Hoeffding, 1994]{hoeffding1994probability}
Hoeffding, W. (1994).
\newblock Probability inequalities for sums of bounded random variables.
\newblock In {\em The collected works of Wassily Hoeffding}, pages 409--426.
  Springer.

\bibitem[Holzinger et~al., 2017]{holzinger2017we}
Holzinger, A., Biemann, C., Pattichis, C.~S., and Kell, D.~B. (2017).
\newblock What do we need to build explainable ai systems for the medical
  domain?
\newblock {\em arXiv preprint arXiv:1712.09923}.

\bibitem[Huber et~al., 2021]{huber2021benchmarking}
Huber, T., Limmer, B., and Andr{\'e}, E. (2021).
\newblock Benchmarking perturbation-based saliency maps for explaining deep
  reinforcement learning agents.
\newblock {\em arXiv preprint arXiv:2101.07312}.

\bibitem[Jia et~al., 2019]{jia2019towards}
Jia, R., Dao, D., Wang, B., Hubis, F.~A., Hynes, N., G{\"u}rel, N.~M., Li, B.,
  Zhang, C., Song, D., and Spanos, C.~J. (2019).
\newblock Towards efficient data valuation based on the shapley value.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 1167--1176. PMLR.

\bibitem[Lapuschkin et~al., 2019]{lapuschkin2019unmasking}
Lapuschkin, S., W{\"a}ldchen, S., Binder, A., Montavon, G., Samek, W., and
  M{\"u}ller, K.-R. (2019).
\newblock Unmasking clever hans predictors and assessing what machines really
  learn.
\newblock {\em Nature communications}, 10(1):1--8.

\bibitem[Li, 2017]{li2017deep}
Li, Y. (2017).
\newblock Deep reinforcement learning: An overview.
\newblock {\em arXiv preprint arXiv:1701.07274}.

\bibitem[Lipton, 2018]{lipton2018mythos}
Lipton, Z.~C. (2018).
\newblock The mythos of model interpretability: In machine learning, the
  concept of interpretability is both important and slippery.
\newblock {\em Queue}, 16(3):31--57.

\bibitem[Lundberg and Lee, 2017a]{NIPS2017_7062shap}
Lundberg, S.~M. and Lee, S.-I. (2017a).
\newblock A unified approach to interpreting model predictions.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R., editors, {\em Advances in Neural
  Information Processing Systems 30}, pages 4765--4774. Curran Associates, Inc.

\bibitem[Lundberg and Lee, 2017b]{lundberg2017unified}
Lundberg, S.~M. and Lee, S.-I. (2017b).
\newblock A unified approach to interpreting model predictions.
\newblock In {\em Proceedings of the 31st international conference on neural
  information processing systems}, pages 4768--4777.

\bibitem[Macdonald et~al., 2021]{macdonald2021interpretable}
Macdonald, J., Besan{\c{c}}on, M., and Pokutta, S. (2021).
\newblock Interpretable neural networks with frank-wolfe: Sparse relevance maps
  and relevance orderings.
\newblock {\em arXiv preprint arXiv:2110.08105}.

\bibitem[Macdonald et~al., 2019]{macdonald2019rate}
Macdonald, J., W{\"a}ldchen, S., Hauch, S., and Kutyniok, G. (2019).
\newblock A rate-distortion framework for explaining neural network decisions.
\newblock {\em arXiv preprint arXiv:1905.11092}.

\bibitem[Macdonald et~al., 2020]{macdonald2020explaining}
Macdonald, J., W{\"a}ldchen, S., Hauch, S., and Kutyniok, G. (2020).
\newblock Explaining neural network decisions is hard.
\newblock In {\em XXAI Workshop, 37th ICML}.

\bibitem[Mitchell et~al., 2021]{mitchell2021sampling}
Mitchell, R., Cooper, J., Frank, E., and Holmes, G. (2021).
\newblock Sampling permutations for shapley value estimation.
\newblock {\em arXiv preprint arXiv:2104.12199}.

\bibitem[Mnih et~al., 2015]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
  (2015).
\newblock Human-level control through deep reinforcement learning.
\newblock {\em nature}, 518(7540):529--533.

\bibitem[Mohseni et~al., 2021]{mohseni2021multidisciplinary}
Mohseni, S., Zarei, N., and Ragan, E.~D. (2021).
\newblock A multidisciplinary survey and framework for design and evaluation of
  explainable ai systems.
\newblock {\em ACM Transactions on Interactive Intelligent Systems (TiiS)},
  11(3-4):1--45.

\bibitem[Pokutta et~al., 2020]{pokutta2020deep}
Pokutta, S., Spiegel, C., and Zimmer, M. (2020).
\newblock Deep neural network training with frank-wolfe.
\newblock {\em arXiv preprint arXiv:2010.07243}.

\bibitem[Pons, 2019]{perfect_agent}
Pons, P. (2019).
\newblock Connect 4 game solver.

\bibitem[Ribeiro et~al., 2016]{ribeiro2016should}
Ribeiro, M.~T., Singh, S., and Guestrin, C. (2016).
\newblock " why should i trust you?" explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144.

\bibitem[Ribeiro et~al., 2018]{ribeiro2018anchors}
Ribeiro, M.~T., Singh, S., and Guestrin, C. (2018).
\newblock Anchors: High-precision model-agnostic explanations.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~32.

\bibitem[Rudin, 2019]{rudin2019stop}
Rudin, C. (2019).
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock {\em Nature Machine Intelligence}, 1(5):206--215.

\bibitem[Rudin and Ustun, 2018]{rudin2018optimized}
Rudin, C. and Ustun, B. (2018).
\newblock Optimized scoring systems: Toward trust in machine learning for
  healthcare and criminal justice.
\newblock {\em Interfaces}, 48(5):449--466.

\bibitem[Samek et~al., 2017]{WojBGM2017pixelflip}
Samek, W., Binder, A., Montavon, G., Lapuschkin, S., and Müller, K.-R. (2017).
\newblock Evaluating the visualization of what a deep neural network has
  learned.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  28(11):2660--2673.

\bibitem[Schraagen et~al., 2020]{schraagen2020trusting}
Schraagen, J.~M., Elsasser, P., Fricke, H., Hof, M., and Ragalmuto, F. (2020).
\newblock Trusting the x in xai: Effects of different types of explanations by
  a self-driving car on trust, explanation satisfaction and mental models.
\newblock In {\em Proceedings of the Human Factors and Ergonomics Society
  Annual Meeting}, volume~64, pages 339--343. SAGE Publications Sage CA: Los
  Angeles, CA.

\bibitem[Schulman et~al., 2017]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. (2017).
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}.

\bibitem[Shapley, 2016]{shapley201617}
Shapley, L.~S. (2016).
\newblock {\em 17. A value for n-person games}.
\newblock Princeton University Press.

\bibitem[Shih et~al., 2018]{shih2018symbolic}
Shih, A., Choi, A., and Darwiche, A. (2018).
\newblock A symbolic approach to explaining bayesian network classifiers.
\newblock {\em arXiv preprint arXiv:1805.03364}.

\bibitem[Shrikumar et~al., 2017]{shrikumar2017learning}
Shrikumar, A., Greenside, P., and Kundaje, A. (2017).
\newblock Learning important features through propagating activation
  differences.
\newblock In {\em International Conference on Machine Learning}, pages
  3145--3153. PMLR.

\bibitem[Silver et~al., 2017]{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., et~al. (2017).
\newblock Mastering the game of go without human knowledge.
\newblock {\em nature}, 550(7676):354--359.

\bibitem[Simonyan et~al., 2013]{simonyan2013deep}
Simonyan, K., Vedaldi, A., and Zisserman, A. (2013).
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock {\em arXiv preprint arXiv:1312.6034}.

\bibitem[Slack et~al., 2020]{slack2020fooling}
Slack, D., Hilgard, S., Jia, E., Singh, S., and Lakkaraju, H. (2020).
\newblock Fooling lime and shap: Adversarial attacks on post hoc explanation
  methods.
\newblock In {\em Proceedings of the AAAI/ACM Conference on AI, Ethics, and
  Society}, pages 180--186.

\bibitem[Slack et~al., 2021]{slack2021counterfactual}
Slack, D., Hilgard, S., Lakkaraju, H., and Singh, S. (2021).
\newblock Counterfactual explanations can be manipulated.
\newblock {\em arXiv preprint arXiv:2106.02666}.

\bibitem[Smilkov et~al., 2017]{smilkov2017smoothgrad}
Smilkov, D., Thorat, N., Kim, B., Vi{\'e}gas, F., and Wattenberg, M. (2017).
\newblock Smoothgrad: removing noise by adding noise.
\newblock {\em arXiv preprint arXiv:1706.03825}.

\bibitem[Springenberg et~al., 2015]{springenberg2014guidedbackprop}
Springenberg, J.~T., Dosovitskiy, A., Brox, T., and Riedmiller, M.~A. (2015).
\newblock Striving for simplicity: The all convolutional net.
\newblock In {\em {ICLR} (Workshop)}.

\bibitem[Sundararajan and Najmi, 2020]{sundararajan2020many}
Sundararajan, M. and Najmi, A. (2020).
\newblock The many shapley values for model explanation.
\newblock In {\em International Conference on Machine Learning}, pages
  9269--9278. PMLR.

\bibitem[Sutton and Barto, 2018]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G. (2018).
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press.

\bibitem[Vogt, 2019]{cpp_mcts}
Vogt, M. D. P.~T. (2019).
\newblock Carlo connect.

\bibitem[Wang et~al., 2021]{wang2021adaptive}
Wang, H., Preuss, M., and Plaat, A. (2021).
\newblock Adaptive warm-start mcts in alphazero-like deep reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:2105.06136}.

\bibitem[Zeiler and Fergus, 2014]{zeiler2014visualizing}
Zeiler, M.~D. and Fergus, R. (2014).
\newblock Visualizing and understanding convolutional networks.
\newblock In Fleet, D., Pajdla, T., Schiele, B., and Tuytelaars, T., editors,
  {\em Computer Vision -- ECCV 2014}, pages 818--833, Cham. Springer
  International Publishing.

\end{thebibliography}
