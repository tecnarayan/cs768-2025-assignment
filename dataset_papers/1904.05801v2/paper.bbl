\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anthony \& Bartlett(2009)Anthony and Bartlett]{thy:anthony2009neural}
Anthony, M. and Bartlett, P.~L.
\newblock \emph{Neural network learning: Theoretical foundations}.
\newblock cambridge university press, 2009.

\bibitem[Ben-David et~al.(2007)Ben-David, Blitzer, Crammer, and
  Pereira]{cite:NIPS07DAT}
Ben-David, S., Blitzer, J., Crammer, K., and Pereira, F.
\newblock Analysis of representations for domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2007.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{thy:shai10ad}
Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Vaughan,
  J.~W.
\newblock A theory of learning from different domains.
\newblock \emph{Machine Learning}, 79\penalty0 (1-2):\penalty0 151--175, 2010.

\bibitem[Blitzer et~al.(2008)Blitzer, Crammer, Kulesza, Pereira, and
  Wortman]{thy:blitzer2007LBDA}
Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Wortman, J.
\newblock Learning bounds for domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  129--136. 2008.

\bibitem[Cortes \& Mohri(2014)Cortes and Mohri]{thy:cortes2014reg}
Cortes, C. and Mohri, M.
\newblock Domain adaptation and sample bias correction theory and algorithm for
  regression.
\newblock \emph{Theoretical Computer Science}, 519:\penalty0 103--126, 2014.

\bibitem[Cortes et~al.(2015)Cortes, Mohri, and
  Mu{\~n}oz~Medina]{thy:cortes2015gd}
Cortes, C., Mohri, M., and Mu{\~n}oz~Medina, A.
\newblock Adaptation algorithm and theory based on generalized discrepancy.
\newblock In \emph{ACM SIGKDD International Conference on Knowledge Discovery
  and Data Mining (KDD)}, pp.\  169--178, 2015.

\bibitem[Courty et~al.(2017)Courty, Flamary, Habrard, and
  Rakotomamonjy]{cite:NIPS17JDOT}
Courty, N., Flamary, R., Habrard, A., and Rakotomamonjy, A.
\newblock Joint distribution optimal transportation for domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  3730--3739. 2017.

\bibitem[Crammer et~al.(2008)Crammer, Kearns, and Wortman]{thy:crammer2008lfms}
Crammer, K., Kearns, M., and Wortman, J.
\newblock Learning from multiple sources.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 9:\penalty0
  1757--1774, 2008.

\bibitem[Ganin \& Lempitsky(2015)Ganin and Lempitsky]{cite:ICML15RevGrad}
Ganin, Y. and Lempitsky, V.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{cite:JMLR16RevGrad}
Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette,
  F., Marchand, M., and Lempitsky, V.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 17:\penalty0
  2096--2030, 2016.

\bibitem[Germain et~al.(2013)Germain, Habrard, Laviolette, and
  Morvant]{thy:germain2013bayes}
Germain, P., Habrard, A., Laviolette, F., and Morvant, E.
\newblock A pac-bayesian approach for domain adaptation with specialization to
  linear classifiers.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  738--746, 2013.

\bibitem[Gong et~al.(2016)Gong, Zhang, Liu, Tao, Glymour, and
  Sch{\"o}lkopf]{cite:gong2016domain}
Gong, M., Zhang, K., Liu, T., Tao, D., Glymour, C., and Sch{\"o}lkopf, B.
\newblock Domain adaptation with conditional transferable components.
\newblock In \emph{International conference on machine learning (ICML)}, pp.\
  2839--2848, 2016.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{cite:NIPS14GAN}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2014.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{cite:JMLR12MMD}
Gretton, A., Borgwardt, K., Rasch, M., Sch{\"o}lkopf, B., and Smola, A.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 13:\penalty0
  723--773, 2012.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{cite:CVPR16DRL}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem[Hoffman et~al.(2018{\natexlab{a}})Hoffman, Mohri, and
  Zhang]{thy:judy18ms}
Hoffman, J., Mohri, M., and Zhang, N.
\newblock Algorithms and theory for multiple-source adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  8256--8266. 2018{\natexlab{a}}.

\bibitem[Hoffman et~al.(2018{\natexlab{b}})Hoffman, Tzeng, Park, Zhu, Isola,
  Saenko, Efros, and Darrell]{cite:ICML18CyCADA}
Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A.,
  and Darrell, T.
\newblock {C}y{CADA}: Cycle-consistent adversarial domain adaptation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  1989--1998, 2018{\natexlab{b}}.

\bibitem[Koltchinskii et~al.(2002)Koltchinskii, Panchenko,
  et~al.]{thy:koltchinskii2002empirical}
Koltchinskii, V., Panchenko, D., et~al.
\newblock Empirical margin distributions and bounding the generalization error
  of combined classifiers.
\newblock \emph{The Annals of Statistics}, 30\penalty0 (1):\penalty0 1--50,
  2002.

\bibitem[Kuroki et~al.(2019)Kuroki, Charonenphakdee, Bao, Honda, Sato, and
  Sugiyama]{thy:kuroki2018sdisc}
Kuroki, S., Charonenphakdee, N., Bao, H., Honda, J., Sato, I., and Sugiyama, M.
\newblock Unsupervised domain adaptation based on source-guided discrepancy.
\newblock In \emph{AAAI Conference on Artificial Intelligence (AAAI)}, 2019.

\bibitem[Long et~al.(2015)Long, Cao, Wang, and Jordan]{cite:ICML15DAN}
Long, M., Cao, Y., Wang, J., and Jordan, M.~I.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Long et~al.(2017)Long, Wang, and Jordan]{cite:ICML17JAN}
Long, M., Wang, J., and Jordan, M.~I.
\newblock Deep transfer learning with joint adaptation networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Long et~al.(2018)Long, Cao, Wang, and Jordan]{cite:NIPS18CDAN}
Long, M., Cao, Z., Wang, J., and Jordan, M.~I.
\newblock Conditional adversarial domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  1647--1657. 2018.

\bibitem[Mansour et~al.(2009{\natexlab{a}})Mansour, Mohri, and
  Rostamizadeh]{mansour2009multiple}
Mansour, Y., Mohri, M., and Rostamizadeh, A.
\newblock Multiple source adaptation and the r{\'e}nyi divergence.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pp.\
  367--374. AUAI Press, 2009{\natexlab{a}}.

\bibitem[Mansour et~al.(2009{\natexlab{b}})Mansour, Mohri, and
  Rostamizadeh]{thy:mansour2008msda}
Mansour, Y., Mohri, M., and Rostamizadeh, A.
\newblock Domain adaptation with multiple sources.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  1041--1048. 2009{\natexlab{b}}.

\bibitem[Mansour et~al.(2009{\natexlab{c}})Mansour, Mohri, and
  Rostamizadeh]{thy:mohri2009dd}
Mansour, Y., Mohri, M., and Rostamizadeh, A.
\newblock Domain adaptation: Learning bounds and algorithms.
\newblock In \emph{Conference on Learning Theory (COLT)}, 2009{\natexlab{c}}.

\bibitem[Mendelson \& Vershynin(2003)Mendelson and
  Vershynin]{thy:mendelson2003entropy}
Mendelson, S. and Vershynin, R.
\newblock Entropy and the combinatorial dimension.
\newblock \emph{Inventiones mathematicae}, 152\penalty0 (1):\penalty0 37--55,
  2003.

\bibitem[Mohri \& Medina(2012)Mohri and Medina]{thy:mohri2012ydsic}
Mohri, M. and Medina, A.~M.
\newblock New analysis and algorithm for learning with drifting distributions.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pp.\  124--138, 2012.

\bibitem[Mohri et~al.(2012)Mohri, Rostamizadeh, and
  Talwalkar]{thy:mohri2012foundations}
Mohri, M., Rostamizadeh, A., and Talwalkar, A.
\newblock Foundations of machine learning.
\newblock 2012.

\bibitem[Pan \& Yang(2010)Pan and Yang]{cite:TKDE10TLSurvey}
Pan, S.~J. and Yang, Q.
\newblock A survey on transfer learning.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering (TKDE)},
  22\penalty0 (10):\penalty0 1345--1359, 2010.

\bibitem[Pan et~al.(2011)Pan, Tsang, Kwok, and Yang]{cite:TNN11TCA}
Pan, S.~J., Tsang, I.~W., Kwok, J.~T., and Yang, Q.
\newblock Domain adaptation via transfer component analysis.
\newblock \emph{IEEE Transactions on Neural Networks (TNN)}, 22\penalty0
  (2):\penalty0 199--210, 2011.

\bibitem[Peng et~al.(2017)Peng, Usman, Kaushik, Hoffman, Wang, and
  Saenko]{cite:VISDA2017}
Peng, X., Usman, B., Kaushik, N., Hoffman, J., Wang, D., and Saenko, K.
\newblock Visda: The visual domain adaptation challenge.
\newblock \emph{CoRR}, abs/1710.06924, 2017.

\bibitem[Quionero-Candela et~al.(2009)Quionero-Candela, Sugiyama, Schwaighofer,
  and Lawrence]{cite:Book09DSS}
Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N.~D.
\newblock \emph{Dataset shift in machine learning}.
\newblock The MIT Press, 2009.

\bibitem[Rakhlin \& Sridharan(2014)Rakhlin and
  Sridharan]{thy:rakhlin2014statistical}
Rakhlin, A. and Sridharan, K.
\newblock Statistical learning and sequential prediction.
\newblock \emph{Book Draft}, 2014.

\bibitem[Russakovsky et~al.(2014)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{cite:Arxiv14ImageNet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock 2014.

\bibitem[Saenko et~al.(2010)Saenko, Kulis, Fritz, and
  Darrell]{cite:ECCV10Office}
Saenko, K., Kulis, B., Fritz, M., and Darrell, T.
\newblock Adapting visual category models to new domains.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2010.

\bibitem[Saito et~al.(2018)Saito, Watanabe, Ushiku, and Harada]{cite:CVPR18MCD}
Saito, K., Watanabe, K., Ushiku, Y., and Harada, T.
\newblock Maximum classifier discrepancy for unsupervised domain adaptation.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  3723--3732, 2018.

\bibitem[Sankaranarayanan et~al.(2018)Sankaranarayanan, Balaji, Castillo, and
  Chellappa]{cite:CVPR18GTA}
Sankaranarayanan, S., Balaji, Y., Castillo, C.~D., and Chellappa, R.
\newblock Generate to adapt: Aligning domains using generative adversarial
  networks.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2018.

\bibitem[Talagrand(2014)]{thy:talagrand2014upper}
Talagrand, M.
\newblock \emph{Upper and lower bounds for stochastic processes: modern methods
  and classical problems}, volume~60.
\newblock Springer Science \& Business Media, 2014.

\bibitem[Tzeng et~al.(2014)Tzeng, Hoffman, Zhang, Saenko, and
  Darrell]{cite:Arxiv14DDC}
Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., and Darrell, T.
\newblock Deep domain confusion: Maximizing for domain invariance.
\newblock \emph{CoRR}, abs/1412.3474, 2014.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{cite:CVPR17ADDA}
Tzeng, E., Hoffman, J., Saenko, K., and Darrell, T.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2017.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and
  Panchanathan]{cite:CVPR17DHN}
Venkateswara, H., Eusebio, J., Chakraborty, S., and Panchanathan, S.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2017.

\bibitem[Zhang et~al.(2012)Zhang, Zhang, and Ye]{thy:ye2012ydsic}
Zhang, C., Zhang, L., and Ye, J.
\newblock Generalization bounds for domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  3320--3328. 2012.

\bibitem[Zhang et~al.(2013)Zhang, Sch{\"o}lkopf, Muandet, and
  Wang]{cite:zhang2013domain}
Zhang, K., Sch{\"o}lkopf, B., Muandet, K., and Wang, Z.
\newblock Domain adaptation under target and conditional shift.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  819--827, 2013.

\bibitem[Zhou(2002)]{thy:zhou2002covering}
Zhou, D.-X.
\newblock The covering number in learning theory.
\newblock \emph{Journal of Complexity}, 18\penalty0 (3):\penalty0 739--767,
  2002.

\end{thebibliography}
