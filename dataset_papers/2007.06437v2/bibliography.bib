%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Alessandro Lazaric at 2020-06-01 21:30:48 +0200


%% Saved with string encoding Unicode (UTF-8)

@book{lattimore2019bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{szorenyi2014optimistic,
  title={Optimistic planning in Markov decision processes using a generative model},
  author={Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Kedenburg, Gunnar and Munos, R{\'e}mi},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  pages={1035--1043},
  year={2014}
}


@inproceedings{grill2016blazing,
  title={Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning},
  author={Grill, Jean-Bastien and Valko, Michal and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4680--4688},
  year={2016}
}


@inproceedings{bartlett2019scale-free,
  title={Scale-free adaptive planning for deterministic dynamics \& discounted rewards},
  author={Bartlett, Peter and Gabillon, Victor and Healey, Jennifer and Valko, Michal},
  booktitle={International Conference on Machine Learning},
  pages={495--504},
  year={2019},
  organization={PMLR}
}


@inproceedings{jin2018is-q-learning,
	  title={Is q-learning provably efficient?},
	  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
	  booktitle={Advances in Neural Information Processing Systems},
	  pages={4863--4873},
	  year={2018}
	}


@inproceedings{audibert2007tuning,
  title={Tuning bandit algorithms in stochastic environments},
  author={Audibert, Jean-Yves and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  booktitle={International conference on algorithmic learning theory},
  pages={150--165},
  year={2007},
  organization={Springer}
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for Markov decision processes},
  author={Strehl, Alexander L and Littman, Michael L},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Academic Press}
}

@article{jaksch2010near,
	Author = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
	Journal = {Journal of Machine Learning Research},
	Number = {Apr},
	Pages = {1563--1600},
	Title = {Near-optimal regret bounds for reinforcement learning},
	Volume = {11},
	Year = {2010}}

@inproceedings{fruit2018efficient,
	Author = {Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Ortner, Ronald},
	Booktitle = {ICML 2018-The 35th International Conference on Machine Learning},
	Pages = {1578--1586},
	Title = {Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning},
	Volume = {80},
	Year = {2018}}

@inproceedings{tarbouriech2019active,
	Author = {Tarbouriech, Jean and Lazaric, Alessandro},
	Booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics},
	Pages = {974--982},
	Title = {Active Exploration in Markov Decision Processes},
	Year = {2019}}

@article{maurer2009empirical,
	Author = {Maurer, Andreas and Pontil, Massimiliano},
	Journal = {arXiv preprint arXiv:0907.3740},
	Title = {Empirical Bernstein bounds and sample variance penalization},
	Year = {2009}}

@inproceedings{cheung2019regret,
	Author = {Cheung, Wang Chi},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {724--734},
	Title = {Regret Minimization for Reinforcement Learning with Vectorial Feedback and Complex Objectives},
	Year = {2019}}

@inproceedings{dann2015sample,
	Author = {Dann, Christoph and Brunskill, Emma},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2818--2826},
	Title = {Sample complexity of episodic fixed-horizon reinforcement learning},
	Year = {2015}}

@article{shekhar2019adaptive,
	Author = {Shekhar, Shubhanshu and Ghavamzadeh, Mohammad and Javidi, Tara},
	Journal = {arXiv preprint arXiv:1910.12406},
	Title = {Adaptive Sampling for Estimating Multiple Probability Distributions},
	Year = {2019}}

@article{hadiji2019polynomial,
	Author = {Hadiji, H{\'e}di},
	Journal = {arXiv preprint arXiv:1905.10221},
	Title = {Polynomial Cost of Adaptation for X-Armed Bandits},
	Year = {2019}}

@article{sinclair2019adaptive,
	Author = {Sinclair, Sean R and Banerjee, Siddhartha and Yu, Christina Lee},
	Journal = {arXiv preprint arXiv:1910.08151},
	Title = {Adaptive Discretization for Episodic Reinforcement Learning in Metric Spaces},
	Year = {2019}}

@inproceedings{berthet2017fast,
	Author = {Berthet, Quentin and Perchet, Vianney},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2225--2234},
	Title = {Fast rates for bandit optimization with upper-confidence frank-wolfe},
	Year = {2017}}

@inproceedings{tarbouriech2019no,
  title={No-regret exploration in goal-oriented reinforcement learning},
  author={Tarbouriech, Jean and Garcelon, Evrard and Valko, Michal and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Machine Learning},
  pages={9428--9437},
  year={2020},
  organization={PMLR}
}



@inproceedings{hazan2019provably,
	Author = {Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
	Booktitle = {International Conference on Machine Learning},
	Pages = {2681--2691},
	Title = {Provably Efficient Maximum Entropy Exploration},
	Year = {2019}}

@article{guiacsu1971weighted,
	Author = {Guia{\c{s}}u, Silviu},
	Journal = {Reports on Mathematical Physics},
	Number = {3},
	Pages = {165--179},
	Publisher = {Elsevier},
	Title = {Weighted entropy},
	Volume = {2},
	Year = {1971}}

@book{latouche1999introduction,
	Author = {Latouche, Guy and Ramaswami, Vaidyanathan},
	Publisher = {Siam},
	Title = {Introduction to matrix analytic methods in stochastic modeling},
	Volume = {5},
	Year = {1999}}

@inproceedings{kazerouni2017conservative,
	Author = {Kazerouni, Abbas and Ghavamzadeh, Mohammad and Abbasi, Yasin and Van Roy, Benjamin},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {3910--3919},
	Title = {Conservative contextual linear bandits},
	Year = {2017}}

@inproceedings{ortner2019variational,
	Author = {Ortner, Ronald and Gajane, Pratik and Auer, Peter},
	Booktitle = {Proceedings of the 35th Conference on Uncertainty in Artificial Intelligence},
	Title = {Variational Regret Bounds for Reinforcement Learning},
	Year = {2019}}

@inproceedings{hsu2015mixing,
	Author = {Hsu, Daniel J and Kontorovich, Aryeh and Szepesv{\'a}ri, Csaba},
	Booktitle = {Advances in neural information processing systems},
	Pages = {1459--1467},
	Title = {Mixing time estimation in reversible Markov chains from a single sample path},
	Year = {2015}}

@article{paulin2015concentration,
	Author = {Paulin, Daniel},
	Journal = {Electronic Journal of Probability},
	Publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
	Title = {Concentration inequalities for Markov chains by Marton couplings and spectral methods},
	Volume = {20},
	Year = {2015}}

@article{d1963probabilistic,
	Author = {d'Epenoux, Francois},
	Journal = {Management Science},
	Number = {1},
	Pages = {98--108},
	Publisher = {INFORMS},
	Title = {A probabilistic production and inventory problem},
	Volume = {10},
	Year = {1963}}

@inproceedings{trevizan2016heuristic,
	Author = {Trevizan, Felipe and Thi{\'e}baux, Sylvie and Santana, Pedro and Williams, Brian},
	Booktitle = {Twenty-Sixth International Conference on Automated Planning and Scheduling},
	Title = {Heuristic search in dual space for constrained stochastic shortest path problems},
	Year = {2016}}

@article{chen2016stochastic,
	Author = {Chen, Yichen and Wang, Mengdi},
	Journal = {arXiv preprint arXiv:1612.02516},
	Title = {Stochastic primal-dual methods and sample complexity of reinforcement learning},
	Year = {2016}}

@article{azar2012sample,
	Author = {Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Bert},
	Journal = {arXiv preprint arXiv:1206.6461},
	Title = {On the sample complexity of reinforcement learning with a generative model},
	Year = {2012}}

@article{chen2018scalable,
	Author = {Chen, Yichen and Li, Lihong and Wang, Mengdi},
	Journal = {arXiv preprint arXiv:1804.10328},
	Title = {Scalable Bilinear $\pi$ Learning Using State and Action Features},
	Year = {2018}}

@inproceedings{sidford2018near,
	Author = {Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {5186--5196},
	Title = {Near-optimal time and sample complexities for solving Markov decision processes with a generative model},
	Year = {2018}}

@phdthesis{kakade2003sample,
	Author = {Kakade, Sham Machandranath},
	School = {University of London London, England},
	Title = {On the sample complexity of reinforcement learning},
	Year = {2003}}

@article{kearns2002sparse,
	Author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
	Journal = {Machine learning},
	Number = {2-3},
	Pages = {193--208},
	Publisher = {Springer},
	Title = {A sparse sampling algorithm for near-optimal planning in large Markov decision processes},
	Volume = {49},
	Year = {2002}}

@article{kearns2002near,
	Author = {Kearns, Michael and Singh, Satinder},
	Journal = {Machine learning},
	Number = {2-3},
	Pages = {209--232},
	Publisher = {Springer},
	Title = {Near-optimal reinforcement learning in polynomial time},
	Volume = {49},
	Year = {2002}}

@inproceedings{kearns2000approximate,
	Author = {Kearns, Michael J and Mansour, Yishay and Ng, Andrew Y},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {1001--1007},
	Title = {Approximate planning in large POMDPs via reusable trajectories},
	Year = {2000}}

@article{audibert2009exploration,
	Author = {Audibert, Jean-Yves and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
	Journal = {Theoretical Computer Science},
	Number = {19},
	Pages = {1876--1902},
	Publisher = {Elsevier},
	Title = {Exploration--exploitation tradeoff using variance estimates in multi-armed bandits},
	Volume = {410},
	Year = {2009}}


@article{improved_analysis_UCRL2B,
  title={Improved analysis of ucrl2 with empirical bernstein inequality},
  author={Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro},
  journal={arXiv preprint arXiv:2007.05456},
  year={2020}
}

@article{cheung2019exploration,
	Author = {Cheung, Wang Chi},
	Journal = {arXiv preprint arXiv:1905.06466},
	Title = {Exploration-exploitation trade-off in reinforcement learning on online markov decision processes with global concave rewards},
	Year = {2019}}

@misc{wainwright,
	Author = {Wainwright, Martin},
	Title = {Course on Mathematical Statistics, chapter 2: Basic tail and concentration bounds. {U}niversity of {C}alifornia at {B}erkeley, {D}epartment of {S}tatistics},
	Year = {2015}}

@inproceedings{zanette2019almost,
	Author = {Zanette, Andrea and Kochenderfer, Mykel J and Brunskill, Emma},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {5626--5635},
	Title = {Almost Horizon-Free Structure-Aware Best Policy Identification with a Generative Model},
	Year = {2019}}

@book{bertsekas1995dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P},
  volume={1},
  number={2},
  year={1995},
  publisher={Athena scientific Belmont, MA}
}

@book{puterman2014markov,
	Author = {Puterman, Martin L},
	Publisher = {John Wiley \& Sons},
	Title = {Markov Decision Processes.: Discrete Stochastic Dynamic Programming},
	Year = {2014}}

@article{azar2013minimax,
	Author = {Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
	Journal = {Machine learning},
	Number = {3},
	Pages = {325--349},
	Publisher = {Springer},
	Title = {Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
	Volume = {91},
	Year = {2013}}

@InProceedings{agarwal2019optimality, title = {Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal}, author = {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.}, booktitle = {Proceedings of Thirty Third Conference on Learning Theory}, year = {2020}, volume = {125}, series = {Proceedings of Machine Learning Research}, publisher = {PMLR}}

@article{li2020breaking,
  title={Breaking the sample size barrier in model-based reinforcement learning with a generative model},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{du2019provably,
	Author = {Du, Simon and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Langford, John},
	Booktitle = {International Conference on Machine Learning},
	Pages = {1665--1674},
	Title = {Provably efficient RL with Rich Observations via Latent State Decoding},
	Year = {2019}}

@inproceedings{misra2019kinematic,
  title={Kinematic state abstraction and provably efficient rich-observation reinforcement learning},
  author={Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  booktitle={International conference on machine learning},
  pages={6961--6971},
  year={2020},
  organization={PMLR}
}

@inproceedings{jin2020reward,
  title={Reward-free exploration for reinforcement learning},
  author={Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4870--4879},
  year={2020},
  organization={PMLR}
}


@inproceedings{cohen2020near,
  title={Near-optimal Regret Bounds for Stochastic Shortest Path},
  author={Rosenberg, Aviv and Cohen, Alon and Mansour, Yishay and Kaplan, Haim},
  booktitle={International Conference on Machine Learning},
  pages={8210--8219},
  year={2020},
  organization={PMLR}
}


@article{brafman2002r,
	Author = {Brafman, Ronen I and Tennenholtz, Moshe},
	Journal = {Journal of Machine Learning Research},
	Number = {Oct},
	Pages = {213--231},
	Title = {R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
	Volume = {3},
	Year = {2002}}

@inproceedings{tarbouriech2020active,
  title={Active model estimation in markov decision processes},
  author={Tarbouriech, Jean and Shekhar, Shubhanshu and Pirotta, Matteo and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={1019--1028},
  year={2020},
  organization={PMLR}
}



@article{bertsekas1991analysis,
	Author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	Journal = {Mathematics of Operations Research},
	Number = {3},
	Pages = {580--595},
	Publisher = {INFORMS},
	Title = {An analysis of stochastic shortest path problems},
	Volume = {16},
	Year = {1991}}

@inproceedings{fruit2018near,
	Author = {Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2994--3004},
	Title = {Near optimal exploration-exploitation in non-communicating markov decision processes},
	Year = {2018}}

@inproceedings{kolobov2012theory,
	Author = {Kolobov, Andrey and Weld, Daniel S and others},
	Booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence},
	Organization = {AUAI Press},
	Pages = {438--447},
	Title = {A theory of goal-oriented MDPs with dead ends},
	Year = {2012}}

@inproceedings{azar2017minimax,
	Author = {Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
	Booktitle = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	Organization = {JMLR},
	Pages = {263--272},
	Title = {Minimax regret bounds for reinforcement learning},
	Year = {2017}}

@inproceedings{zanette2019tighter,
	Author = {Zanette, Andrea and Brunskill, Emma},
	Booktitle = {International Conference on Machine Learning},
	Pages = {7304--7312},
	Title = {Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds},
	Year = {2019}}

@article{wang2017primal,
	Author = {Wang, Mengdi},
	Journal = {arXiv preprint arXiv:1710.06100},
	Title = {Primal-Dual $\pi$ Learning: Sample Complexity and Sublinear Run Time for Ergodic Markov Decision Problems},
	Year = {2017}}

	
@inproceedings{audibert2010best,
  title={Best Arm Identification in Multi-Armed Bandits},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
  booktitle={COLT - 23th Conference on Learning Theory},
  year={2010}
}


@article{even2006action,
	Author = {Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
	Journal = {Journal of machine learning research},
	Number = {Jun},
	Pages = {1079--1105},
	Title = {Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems},
	Volume = {7},
	Year = {2006}}

@inproceedings{carpentier2011upper,
	Author = {Carpentier, Alexandra and Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi and Auer, Peter},
	Booktitle = {International Conference on Algorithmic Learning Theory},
	Title = {Upper-confidence-bound algorithms for active learning in multi-armed bandits},
	Year = {2011}}

@article{gajane2019autonomous,
	Author = {Gajane, Pratik and Ortner, Ronald and Auer, Peter and Szepesvari, Csaba},
	Journal = {arXiv preprint arXiv:1910.08446},
	Title = {Autonomous exploration for navigating in non-stationary CMPs},
	Year = {2019}}

@article{kaufmann2016complexity,
	Author = {Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
	Journal = {The Journal of Machine Learning Research},
	Number = {1},
	Pages = {1--42},
	Publisher = {JMLR. org},
	Title = {On the complexity of best-arm identification in multi-armed bandit models},
	Volume = {17},
	Year = {2016}}

@inproceedings{ok2018exploration,
	Author = {Ok, Jungseul and Proutiere, Alexandre and Tranos, Damianos},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {8874--8882},
	Title = {Exploration in structured reinforcement learning},
	Year = {2018}}

@inproceedings{dekel2014bandits,
	Author = {Dekel, Ofer and Ding, Jian and Koren, Tomer and Peres, Yuval},
	Booktitle = {Proceedings of the forty-sixth annual ACM symposium on Theory of computing},
	Pages = {459--467},
	Title = {Bandits with switching costs: ${T}^{2/3}$ regret},
	Year = {2014}}

@inproceedings{koren2017bandits,
  title={Bandits with movement costs and adaptive pricing},
  author={Koren, Tomer and Livni, Roi and Mansour, Yishay},
  booktitle={Conference on Learning Theory},
  pages={1242--1268},
  year={2017},
  organization={PMLR}
}


@article{bertsekas2013stochastic,
	Author = {Bertsekas, Dimitri P and Yu, Huizhen},
	Journal = {Lab. for Information and Decision Systems Report LIDS-P-2909, MIT},
	Title = {Stochastic shortest path problems under weak conditions},
	Year = {2013}}

@inproceedings{zhang2019regret,
	Author = {Zhang, Zihan and Ji, Xiangyang},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2823--2832},
	Title = {Regret minimization for reinforcement learning by evaluating the optimal bias function},
	Year = {2019}}

@inproceedings{maillard2011selecting,
	Author = {Maillard, Odalric-Ambrym and Ryabko, Daniil and Munos, R{\'e}mi},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2627--2635},
	Title = {Selecting the state-representation in reinforcement learning},
	Year = {2011}}

@inproceedings{jian2019exploration,
	Author = {Qian, Jian and Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {4891--4900},
	Title = {Exploration Bonus for Regret Minimization in Discrete and Continuous Average Reward MDPs},
	Year = {2019}}

	@inproceedings{bartlett2009regal,
	  title={REGAL: a regularization based algorithm for reinforcement learning in weakly communicating MDPs},
	  author={Bartlett, Peter L and Tewari, Ambuj},
	  booktitle={Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
	  year={2009}
	}

@article{strehl2009reinforcement,
	Author = {Strehl, Alexander L and Li, Lihong and Littman, Michael L},
	Journal = {Journal of Machine Learning Research},
	Number = {Nov},
	Pages = {2413--2444},
	Title = {Reinforcement learning in finite MDPs: PAC analysis},
	Volume = {10},
	Year = {2009}}

@book{bertsekas1996neuro,
	Author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	Publisher = {Athena Scientific},
	Title = {Neuro-dynamic programming},
	Year = {1996}}

@article{jin2019adversarial,
	Author = {{Jin}, Chi and {Jin}, Tiancheng and {Luo}, Haipeng and {Sra}, Suvrit and {Yu}, Tiancheng},
	Journal = {CoRR},
	Title = {{Learning Adversarial MDPs with Bandit Feedback and Unknown Transition}},
	Volume = {abs/1912.01192},
	Year = {2019}}

@inproceedings{lattimore2012pac,
	Author = {Lattimore, Tor and Hutter, Marcus},
	Booktitle = {International Conference on Algorithmic Learning Theory},
	Organization = {Springer},
	Pages = {320--334},
	Title = {PAC bounds for discounted MDPs},
	Year = {2012}}

@article{bhatnagar2009natural,
	Author = {Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
	Journal = {Automatica},
	Number = {11},
	Pages = {2471--2482},
	Publisher = {Elsevier},
	Title = {Natural actor--critic algorithms},
	Volume = {45},
	Year = {2009}}

@misc{cheung2019nonstationary,
	Archiveprefix = {arXiv},
	Author = {Wang Chi Cheung and David Simchi-Levi and Ruihao Zhu},
	Eprint = {1906.02922},
	Primaryclass = {cs.LG},
	Title = {Non-Stationary Reinforcement Learning: The Blessing of (More) Optimism},
	Year = {2019}}

@inproceedings{garcelon2020conservative,
  title={Conservative exploration in reinforcement learning},
  author={Garcelon, Evrard and Ghavamzadeh, Mohammad and Lazaric, Alessandro and Pirotta, Matteo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1431--1441},
  year={2020},
  organization={PMLR}
}


@inproceedings{abbasi2019politex,
  title={POLITEX: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019}
}

@article{ortner2020regret,
  title={Regret Bounds for Reinforcement Learning via Markov Chain Concentration},
  author={Ortner, Ronald},
  journal={Journal of Artificial Intelligence Research},
  volume={67},
  pages={115--128},
  year={2020}
}

@inproceedings{wei2019model,
  title={Model-free reinforcement learning in infinite-horizon average-reward markov decision processes},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul},
  booktitle={International Conference on Machine Learning},
  pages={10170--10180},
  year={2020},
  organization={PMLR}
}

@inproceedings{tarbouriech2020improved,
 author = {Tarbouriech, Jean and Pirotta, Matteo and Valko, Michal and Lazaric, Alessandro},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {11273--11284},
 title = {Improved Sample Complexity for Incremental Autonomous Exploration in MDPs},
 volume = {33},
 year = {2020}
}

@inproceedings{tarbou,
  title={Sample Complexity Bounds for Stochastic Shortest Path with a Generative Model},
  author={Tarbouriech, Jean and Pirotta, Matteo and Valko, Michal and Lazaric, Alessandro},
  booktitle={Algorithmic Learning Theory},
  pages={1157--1178},
  year={2021},
  organization={PMLR}
}

@inproceedings{menard2020fast,
  title={Fast active learning for pure exploration in reinforcement learning},
  author={M{\'e}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Kaufmann, Emilie and Leurent, Edouard and Valko, Michal},
  booktitle={International Conference on Machine Learning},
  pages={7599--7608},
  year={2021},
  organization={PMLR}
}


@article{zhang2020nearly,
  title={Nearly Minimax Optimal Reward-free Reinforcement Learning},
  author={Zhang, Zihan and Du, Simon S and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2010.05901},
  year={2020}
}

@inproceedings{zhang2020taskagnostic,
  title={Task-agnostic Exploration in Reinforcement Learning},
  author={Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish},
  booktitle={34th Conference on Neural Information Processing Systems},
  pages={11734--11743},
  year={2020}
}


@article{zhang2020model,
  title={Model-free reinforcement learning: from clipped pseudo-regret to sample complexity},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2006.03864},
  year={2020}
}

@inproceedings{wang2019q,
  title={Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP},
  author={Wang, Yuanhao and Dong, Kefan and Chen, Xiaoyu and Wang, Liwei},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{zhang2020almost,
  title={Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage Decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{pong2020skew,
  title={Skew-Fit: State-Covering Self-Supervised Reinforcement Learning},
  author={Pong, Vitchyr and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={7783--7792},
  year={2020},
  organization={PMLR}
}


@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={5055--5065},
  year={2017}
}

@inproceedings{kaufmann2021adaptive,
  title={Adaptive reward-free exploration},
  author={Kaufmann, Emilie and M{\'e}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Leurent, Edouard and Valko, Michal},
  booktitle={Algorithmic Learning Theory},
  pages={865--891},
  year={2021},
  organization={PMLR}
}

@article{vial2021regret,
  title={Regret Bounds for Stochastic Shortest Path Problems with Linear Function Approximation},
  author={Vial, Daniel and Parulekar, Advait and Shakkottai, Sanjay and Srikant, R},
  journal={arXiv preprint arXiv:2105.01593},
  year={2021}
}

