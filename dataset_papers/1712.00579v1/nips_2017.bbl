\begin{thebibliography}{10}

\bibitem{abbasi2013online}
Yasin Abbasi, Peter~L Bartlett, Varun Kanade, Yevgeny Seldin, and Csaba
  Szepesv{\'a}ri.
\newblock Online learning in markov decision processes with adversarially
  chosen transition probability distributions.
\newblock In {\em Advances in Neural Information Processing Systems}, 2013.

\bibitem{auer2007logarithmic}
Peter Auer and Ronald Ortner.
\newblock Logarithmic online regret bounds for undiscounted reinforcement
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2007.

\bibitem{bartlett2009regal}
Peter~L Bartlett and Ambuj Tewari.
\newblock Regal: A regularization based algorithm for reinforcement learning in
  weakly communicating mdps.
\newblock In {\em Proceedings of Conference on Uncertainty in Artificial
  Intelligence}. AUAI Press, 2009.

\bibitem{bowling2001rational}
Michael Bowling and Manuela Veloso.
\newblock Rational and convergent learning in stochastic games.
\newblock In {\em International Joint Conference on Artificial Intelligence},
  2001.

\bibitem{brafman2002r}
Ronen~I Brafman and Moshe Tennenholtz.
\newblock R-max-a general polynomial time algorithm for near-optimal
  reinforcement learning.
\newblock {\em Journal of Machine Learning Research}, 2002.

\bibitem{bubeck2012best}
S{\'e}bastien Bubeck and Aleksandrs Slivkins.
\newblock The best of both worlds: Stochastic and adversarial bandits.
\newblock In {\em Conference on Learning Theory}, 2012.

\bibitem{cho2000Markov}
Grace~E Cho and Carl~D Meyer.
\newblock Markov chain sensitivity measured by mean first passage times.
\newblock {\em Linear Algebra and Its Applications}, 2000.

\bibitem{conitzer2007awesome}
Vincent Conitzer and Tuomas Sandholm.
\newblock Awesome: A general multiagent learning algorithm that converges in
  self-play and learns a best response against stationary opponents.
\newblock {\em Machine Learning}, 2007.

\bibitem{dann2015sample}
Christoph Dann and Emma Brunskill.
\newblock Sample complexity of episodic fixed-horizon reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2015.

\bibitem{dick2014online}
Travis Dick, Andras Gyorgy, and Csaba Szepesvari.
\newblock Online learning in markov decision processes with changing cost
  sequences.
\newblock In {\em Proceedings of International Conference of Machine Learning},
  2014.

\bibitem{even2009online}
Eyal Even-Dar, Sham~M Kakade, and Yishay Mansour.
\newblock Online markov decision processes.
\newblock {\em Mathematics of Operations Research}, 2009.

\bibitem{federgruen1978Nperson}
Awi Federgruen.
\newblock On n-person stochastic games by denumerable state space.
\newblock {\em Advances in Applied Probability}, 1978.

\bibitem{garivier2016maximin}
Aur{\'e}lien Garivier, Emilie Kaufmann, and Wouter~M Koolen.
\newblock Maximin action identification: A new bandit framework for games.
\newblock In {\em Conference on Learning Theory}, pages 1028--1050, 2016.

\bibitem{hordijk1974dynamic}
Arie Hordijk.
\newblock Dynamic programming and markov potential theory.
\newblock {\em MC Tracts}, 1974.

\bibitem{hunter1982generalized}
Jeffrey~J Hunter.
\newblock Generalized inverses and their application to applied probability
  problems.
\newblock {\em Linear Algebra and Its Applications}, 1982.

\bibitem{hunter2005stationary}
Jeffrey~J Hunter.
\newblock Stationary distributions and mean first passage times of perturbed
  markov chains.
\newblock {\em Linear Algebra and Its Applications}, 2005.

\bibitem{Iyengar:2005robustdynamic}
Garud~N. Iyengar.
\newblock Robust dynamic programming.
\newblock {\em Math. Oper. Res.}, 30(2):257--280, 2005.

\bibitem{jaakkola1994convergence}
Tommi Jaakkola, Michael~I Jordan, and Satinder~P Singh.
\newblock On the convergence of stochastic iterative dynamic programming
  algorithms.
\newblock {\em Neural computation}, 1994.

\bibitem{jaksch2010near}
Thomas Jaksch, Ronald Ortner, and Peter Auer.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock {\em Journal of Machine Learning Research}, 2010.

\bibitem{kakade2003sample}
Sham~Machandranath Kakade et~al.
\newblock {\em On the sample complexity of reinforcement learning}.
\newblock PhD thesis, University of London London, England, 2003.

\bibitem{lagoudakis2002value}
Michail~G Lagoudakis and Ronald Parr.
\newblock Value function approximation in zero-sum markov games.
\newblock In {\em Proceedings of Conference on Uncertainty in Artificial
  Intelligence}. Morgan Kaufmann Publishers Inc., 2002.

\bibitem{lattimore2012pac}
Tor Lattimore and Marcus Hutter.
\newblock Pac bounds for discounted mdps.
\newblock In {\em International Conference on Algorithmic Learning Theory}.
  Springer, 2012.

\bibitem{lim2016robustMDP}
Shiau~Hong Lim, Huan Xu, and Shie Mannor.
\newblock Reinforcement learning in robust markov decision processes.
\newblock {\em Math. Oper. Res.}, 41(4):1325--1353, 2016.

\bibitem{littman1994markov}
Michael~L Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In {\em Proceedings of International Conference of Machine Learning},
  1994.

\bibitem{maurer2009empirical}
A~Maurer and M~Pontil.
\newblock Empirical bernstein bounds and sample variance penalization.
\newblock In {\em Conference on Learning Theory}, 2009.

\bibitem{mertens1981stochastic}
J-F Mertens and Abraham Neyman.
\newblock Stochastic games.
\newblock {\em International Journal of Game Theory}, 1981.

\bibitem{neu2010online}
Gergely Neu, Andras Antos, Andr{\'a}s Gy{\"o}rgy, and Csaba Szepesv{\'a}ri.
\newblock Online markov decision processes under bandit feedback.
\newblock In {\em Advances in Neural Information Processing Systems}, 2010.

\bibitem{neu2012adversarial}
Gergely Neu, Andr{\'a}s Gy{\"o}rgy, and Csaba Szepesv{\'a}ri.
\newblock The adversarial stochastic shortest path problem with unknown
  transition probabilities.
\newblock In {\em AISTATS}, 2012.

\bibitem{nilim2005robustcontrol}
Arnab Nilim and Laurent~El Ghaoui.
\newblock Robust control of markov decision processes with uncertain transition
  matrices.
\newblock {\em Math. Oper. Res.}, 53(5):780--798, 2005.

\bibitem{perolat2015approximate}
Julien Perolat, Bruno Scherrer, Bilal Piot, and Olivier Pietquin.
\newblock Approximate dynamic programming for two-player zero-sum markov games.
\newblock In {\em Proceedings of International Conference of Machine Learning},
  2015.

\bibitem{prasad2015two}
HL~Prasad, Prashanth LA, and Shalabh Bhatnagar.
\newblock Two-timescale algorithms for learning nash equilibria in general-sum
  stochastic games.
\newblock In {\em Proceedings of the 2015 International Conference on
  Autonomous Agents and Multiagent Systems}. International Foundation for
  Autonomous Agents and Multiagent Systems, 2015.

\bibitem{shapley1953stochastic}
Lloyd~S Shapley.
\newblock Stochastic games.
\newblock {\em Proceedings of the National Academy of Sciences}, 1953.

\bibitem{szepesvari1996generalized}
Csaba Szepesv{\'a}ri and Michael~L Littman.
\newblock Generalized markov decision processes: Dynamic-programming and
  reinforcement-learning algorithms.
\newblock In {\em Proceedings of International Conference of Machine Learning},
  1996.

\bibitem{van1980successive}
J~Van~der Wal.
\newblock Successive approximations for average reward markov games.
\newblock {\em International Journal of Game Theory}, 1980.

\bibitem{yu2009arbitrarily}
Jia~Yuan Yu and Shie Mannor.
\newblock Arbitrarily modulated markov decision processes.
\newblock In {\em Proceedings of Conference on Decision and Control}. IEEE,
  2009.

\end{thebibliography}
