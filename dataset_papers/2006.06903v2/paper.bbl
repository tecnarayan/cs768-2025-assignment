\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi and Plotkin(2020)]{AbadiP20}
M.~Abadi and G.~D. Plotkin.
\newblock A simple differentiable programming language.
\newblock \emph{Proceedings of the {ACM} on Programming Languages}, 4\penalty0
  ({POPL}):\penalty0 38:1--38:28, 2020.

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, Kudlur, Levenberg, Monga, Moore, Murray, Steiner,
  Tucker, Vasudevan, Warden, Wicke, Yu, and Zheng]{Tensorflow16}
M.~Abadi, P.~Barham, J.~Chen, Z.~Chen, A.~Davis, J.~Dean, M.~Devin,
  S.~Ghemawat, G.~Irving, M.~Isard, M.~Kudlur, J.~Levenberg, R.~Monga,
  S.~Moore, D.~G. Murray, B.~Steiner, P.~A. Tucker, V.~Vasudevan, P.~Warden,
  M.~Wicke, Y.~Yu, and X.~Zheng.
\newblock {TensorFlow:} {A} system for large-scale machine learning.
\newblock In \emph{Operating Systems Design and Implementation ({OSDI})}, pages
  265--283, 2016.

\bibitem[Baydin et~al.(2016)Baydin, Pearlmutter, and Siskind]{Diffsharp16}
A.~G. Baydin, B.~A. Pearlmutter, and J.~M. Siskind.
\newblock {Diffsharp:} {An} {AD} library for {.NET} languages.
\newblock In \emph{International Conference on Algorithmic Differentiation
  (AD)}, 2016.
\newblock Also arXiv preprint arXiv:1611.03423.

\bibitem[Baydin et~al.(2017)Baydin, Pearlmutter, Radul, and
  Siskind]{BaydinPRS17}
A.~G. Baydin, B.~A. Pearlmutter, A.~A. Radul, and J.~M. Siskind.
\newblock Automatic differentiation in machine learning: {A} survey.
\newblock \emph{Journal of Machine Learning Research}, 18:\penalty0
  153:1--153:43, 2017.

\bibitem[Bergstra et~al.(2010)Bergstra, Breuleux, Bastien, Lamblin, Pascanu,
  Desjardins, Turian, Warde-Farley, and Bengio]{Theano10}
J.~Bergstra, O.~Breuleux, F.~Bastien, P.~Lamblin, R.~Pascanu, G.~Desjardins,
  J.~Turian, D.~Warde-Farley, and Y.~Bengio.
\newblock {Theano:} {A} {CPU} and {GPU} math compiler in {Python}.
\newblock In \emph{Python in Science Conference (SciPy)}, pages 18--24, 2010.

\bibitem[Bolte and Pauwels(2020{\natexlab{a}})]{BolteP20a}
J.~Bolte and E.~Pauwels.
\newblock Conservative set valued fields, automatic differentiation, stochastic
  gradient method and deep learning.
\newblock \emph{Mathematical Programming}, 2020{\natexlab{a}}.

\bibitem[Bolte and Pauwels(2020{\natexlab{b}})]{BolteP20b}
J.~Bolte and E.~Pauwels.
\newblock \add{A mathematical model for automatic differentiation in machine
  learning}.
\newblock \emph{arXiv preprint arXiv:2006.02080}, 2020{\natexlab{b}}.

\bibitem[Boyarsky and Gora(1997)]{BoyarskyG12}
A.~Boyarsky and P.~Gora.
\newblock \emph{Laws of chaos: {Invariant} measures and dynamical systems in
  one dimension}.
\newblock Springer Science \& Business Media, 1997.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, and Wanderman-Milne]{Jax18a}
J.~Bradbury, R.~Frostig, P.~Hawkins, M.~J. Johnson, C.~Leary, D.~Maclaurin, and
  S.~Wanderman-Milne.
\newblock {JAX:} {Composable} transformations of {Python+NumPy} programs, 2018.
\newblock Refer to \url{http://github.com/google/jax} and~\cite{Jax18b}.

\bibitem[Bruckner et~al.(1997)Bruckner, Bruckner, and Thomson]{BrucknerBT97}
A.~M. Bruckner, J.~B. Bruckner, and B.~S. Thomson.
\newblock \emph{Real analysis}.
\newblock Prentice-Hall, first edition, 1997.

\bibitem[Cantor(1884)]{Cantor84}
G.~Cantor.
\newblock De la puissance des ensembles parfaits de points: {Extrait} d’une
  lettre adress{\'e}e {\`a} l’{\'e}diteur [{On} the power of perfect sets of
  points].
\newblock \emph{Acta Mathematica}, 4:\penalty0 381--392, 1884.
\newblock Translated in English, e.g., in~\cite[Section 2]{edgar19}.

\bibitem[Clarke(1990)]{Clarke90}
F.~H. Clarke.
\newblock \emph{Optimization and nonsmooth analysis}.
\newblock Classics in Applied Mathematics: Volume~5. {SIAM}, 1990.

\bibitem[Clarke et~al.(1998)Clarke, Ledyaev, Stern, and Wolenski]{ClarkeLSW98}
F.~H. Clarke, Y.~S. Ledyaev, R.~J. Stern, and P.~R. Wolenski.
\newblock \emph{Nonsmooth analysis and control theory}.
\newblock Graduate Texts in Mathematics: Volume~178. Springer Science \&
  Business Media, 1998.

\bibitem[Darst(1972)]{Darst72}
R.~B. Darst.
\newblock Some {Cantor} sets and {Cantor} functions.
\newblock \emph{Mathematics Magazine}, 45\penalty0 (1):\penalty0 2--7, 1972.

\bibitem[Davis et~al.(2020)Davis, Drusvyatskiy, Kakade, and Lee]{DavisDKL20}
D.~Davis, D.~Drusvyatskiy, S.~M. Kakade, and J.~D. Lee.
\newblock Stochastic subgradient method converges on tame functions.
\newblock \emph{Foundations of Computational Mathematics}, 20\penalty0
  (1):\penalty0 119--154, 2020.

\bibitem[Edgar(2019)]{edgar19}
G.~A. Edgar.
\newblock \emph{Classics on fractals}.
\newblock CRC Press, 2019.

\bibitem[Frostig et~al.(2018)Frostig, Johnson, and Leary]{Jax18b}
R.~Frostig, M.~Johnson, and C.~Leary.
\newblock Compiling machine learning programs via high-level tracing.
\newblock In \emph{SysML Conference}, 2018.

\bibitem[Gelbaum and Olmsted(2003)]{GelbaumO03}
B.~R. Gelbaum and J.~M.~H. Olmsted.
\newblock \emph{Counterexamples in analysis}.
\newblock Dover Publications, 2003.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{GoodfellowBC16}
I.~Goodfellow, Y.~Bengio, and A.~Courville.
\newblock \emph{Deep learning}.
\newblock MIT Press, 2016.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem[Griewank and Walther(2008)]{GriewankW08}
A.~Griewank and A.~Walther.
\newblock \emph{Evaluating derivatives: {Principles} and techniques of
  algorithmic differentiation}.
\newblock {SIAM}, second edition, 2008.

\bibitem[Griewank et~al.(2016)Griewank, Walther, Fiege, and
  Bosse]{GriewankWFB16}
A.~Griewank, A.~Walther, S.~Fiege, and T.~Bosse.
\newblock On {Lipschitz} optimization based on gray-box piecewise
  linearization.
\newblock \emph{Mathematical Programming}, 158\penalty0 (1-2):\penalty0
  383--415, 2016.

\bibitem[Hasco{\"{e}}t and Pascual(2013)]{Tapenade13}
L.~Hasco{\"{e}}t and V.~Pascual.
\newblock The {Tapenade} automatic differentiation tool: {Principles}, model,
  and specification.
\newblock \emph{{ACM} Transactions on Mathematical Software}, 39\penalty0
  (3):\penalty0 20:1--20:43, 2013.

\bibitem[Huot et~al.(2020)Huot, Staton, and V{\'{a}}k{\'{a}}r]{HuotSV20}
M.~Huot, S.~Staton, and M.~V{\'{a}}k{\'{a}}r.
\newblock \add{Correctness of automatic differentiation via diffeologies and
  categorical gluing}.
\newblock In \emph{Foundations of Software Science and Computation Structures
  ({FoSSaCS})}, pages 319--338, 2020.

\bibitem[Kakade and Lee(2018)]{KakadeL18}
S.~M. Kakade and J.~D. Lee.
\newblock Provably correct automatic sub-differentiation for qualified
  programs.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, pages
  7125--7135, 2018.

\bibitem[Krantz and Parks(2002)]{KrantzP02}
S.~G. Krantz and H.~R. Parks.
\newblock \emph{A primer of real analytic functions}.
\newblock Springer Science \& Business Media, second edition, 2002.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{LecunBH15}
Y.~LeCun, Y.~Bengio, and G.~Hinton.
\newblock Deep learning.
\newblock \emph{Nature}, 521\penalty0 (7553):\penalty0 436--444, 2015.

\bibitem[Maclaurin(2016)]{Maclaurin16}
D.~Maclaurin.
\newblock \emph{Modeling, inference and optimization with composable
  differentiable procedures}.
\newblock PhD thesis, Harvard University, 2016.

\bibitem[Maclaurin et~al.(2015)Maclaurin, Duvenaud, and Adams]{Autograd15}
D.~Maclaurin, D.~Duvenaud, and R.~P. Adams.
\newblock {Autograd:} {Effortless} gradients in {Numpy}.
\newblock In \emph{ICML AutoML Workshop}, 2015.

\bibitem[Majewski et~al.(2018)Majewski, Miasojedow, and Moulines]{Majewski18}
S.~Majewski, B.~Miasojedow, and E.~Moulines.
\newblock Analysis of nonsmooth stochastic approximation: {The} differential
  inclusion approach.
\newblock \emph{arXiv preprint arXiv:1805.01916}, 2018.

\bibitem[Mak et~al.(2020)Mak, Ong, Paquet, and Wagner]{MakOPW20}
C.~Mak, C.~L. Ong, H.~Paquet, and D.~Wagner.
\newblock Densities of almost-surely terminating probabilistic programs are
  differentiable almost everywhere.
\newblock \emph{arXiv preprint arXiv:2004.03924}, 2020.

\bibitem[Margossian(2019)]{Margossian19}
C.~C. Margossian.
\newblock A review of automatic differentiation and its efficient
  implementation.
\newblock \emph{Wiley Interdisciplinary Reviews: Data Mining and Knowledge
  Discovery}, 9\penalty0 (4), 2019.

\bibitem[Mityagin(2015)]{Mityagin15}
B.~Mityagin.
\newblock The zero set of a real analytic function.
\newblock \emph{arXiv preprint arXiv:1512.07276}, 2015.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, K{\"{o}}pf, Yang, DeVito,
  Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{Pytorch19}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~K{\"{o}}pf, E.~Yang,
  Z.~DeVito, M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang,
  J.~Bai, and S.~Chintala.
\newblock {PyTorch:} {An} imperative style, high-performance deep learning
  library.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, pages
  8024--8035, 2019.

\bibitem[Pearlmutter and Siskind(2008)]{PearlmutterS08}
B.~A. Pearlmutter and J.~M. Siskind.
\newblock Reverse-mode {AD} in a functional framework: {Lambda} the ultimate
  backpropagator.
\newblock \emph{{ACM} Transactions on Programming Languages and Systems},
  30\penalty0 (2):\penalty0 7:1--7:36, 2008.

\bibitem[Revels et~al.(2016)Revels, Lubin, and Papamarkou]{Juliadiff16}
J.~Revels, M.~Lubin, and T.~Papamarkou.
\newblock Forward-mode automatic differentiation in {Julia}.
\newblock \emph{arXiv preprint arXiv:1607.07892}, 2016.

\bibitem[Rockafellar and Wets(1998)]{RockafellarW98}
R.~T. Rockafellar and R.~J.-B. Wets.
\newblock \emph{Variational analysis}.
\newblock A Series of Comprehensive Studies in Mathematics: Volume~317.
  Springer Science \& Business Media, 1998.

\bibitem[Rudin(1976)]{Rudin76}
W.~Rudin.
\newblock \emph{Principles of mathematical analysis}.
\newblock McGraw-Hill, third edition, 1976.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and Williams]{RumelhartHW86}
D.~E. Rumelhart, G.~E. Hinton, and R.~J. Williams.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Nature}, 323\penalty0 (6088):\penalty0 533--536, 1986.

\bibitem[Schmidhuber(2015)]{Schmidhuber15-DL}
J.~Schmidhuber.
\newblock Deep learning in neural networks: {An} overview.
\newblock \emph{Neural Networks}, 61:\penalty0 85--117, 2015.

\bibitem[Seeger et~al.(2017)Seeger, Hetzel, Dai, and Lawrence]{SeegerHDL17}
M.~W. Seeger, A.~Hetzel, Z.~Dai, and N.~D. Lawrence.
\newblock Auto-differentiating linear algebra.
\newblock \emph{arXiv preprint arXiv:1710.08717}, 2017.

\bibitem[Tao(2011)]{Tao11}
T.~Tao.
\newblock \emph{An introduction to measure theory}.
\newblock Graduate Studies in Mathematics: Volume~126. American Mathematical
  Society, 2011.

\bibitem[Tokui et~al.(2019)Tokui, Okuta, Akiba, Niitani, Ogawa, Saito, Suzuki,
  Uenishi, Vogel, and Vincent]{Chainer19}
S.~Tokui, R.~Okuta, T.~Akiba, Y.~Niitani, T.~Ogawa, S.~Saito, S.~Suzuki,
  K.~Uenishi, B.~Vogel, and H.~Y. Vincent.
\newblock {Chainer:} {A} deep learning framework for accelerating the research
  cycle.
\newblock In \emph{International Conference on Knowledge Discovery {\&} Data
  Mining ({KDD})}, pages 2002--2011, 2019.

\bibitem[van~den Dries and Miller(1996)]{DriesM96}
L.~van~den Dries and C.~Miller.
\newblock Geometric categories and o-minimal structures.
\newblock \emph{Duke Mathematical Journal}, 84\penalty0 (2):\penalty0 497--540,
  1996.

\bibitem[van Merrienboer et~al.(2018)van Merrienboer, Moldovan, and
  Wiltschko]{Tangent18}
B.~van Merrienboer, D.~Moldovan, and A.~B. Wiltschko.
\newblock {Tangent:} {Automatic} differentiation using source-code
  transformation for dynamically typed array programming.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, pages
  6259--6268, 2018.

\bibitem[Walther and Griewank(2012)]{Adolc12}
A.~Walther and A.~Griewank.
\newblock Getting started with {ADOL-C}.
\newblock In \emph{Combinatorial Scientific Computing}, chapter~7, pages
  181--202. Chapman \& Hall/CRC Computational Science, 2012.

\bibitem[Wang et~al.(2019)Wang, Zheng, Decker, Wu, Essertel, and
  Rompf]{WangZDWER19}
F.~Wang, D.~Zheng, J.~M. Decker, X.~Wu, G.~M. Essertel, and T.~Rompf.
\newblock Demystifying differentiable programming: {Shift}/reset the
  penultimate backpropagator.
\newblock \emph{Proceedings of the {ACM} on Programming Languages}, 3\penalty0
  ({ICFP}):\penalty0 96:1--96:31, 2019.

\bibitem[Zhou et~al.(2019)Zhou, Gram{-}Hansen, Kohn, Rainforth, Yang, and
  Wood]{ZhouGKRYW19}
Y.~Zhou, B.~J. Gram{-}Hansen, T.~Kohn, T.~Rainforth, H.~Yang, and F.~Wood.
\newblock {LF-PPL:} {A} low-level first order probabilistic programming
  language for non-differentiable models.
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)}, pages
  148--157, 2019.

\end{thebibliography}
