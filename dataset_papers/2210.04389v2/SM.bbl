\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Chen et~al.(2022)Chen, Klivans, and Meka]{chen2022learning}
Sitan Chen, Adam~R Klivans, and Raghu Meka.
\newblock Learning deep {ReLU} networks is fixed-parameter tractable.
\newblock In \emph{2021 IEEE 62nd Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 696--707. IEEE, 2022.

\bibitem[Chen et~al.(2021)Chen, Lu, and Lu]{chen2021representation}
Ziang Chen, Jianfeng Lu, and Yulong Lu.
\newblock On the representation of solutions to elliptic {PDEs} in {Barron}
  spaces.
\newblock \emph{arXiv preprint arXiv:2106.07539}, 2021.

\bibitem[Chernozhukov et~al.(2018)Chernozhukov, Chetverikov, Demirer, Duflo,
  Hansen, Newey, and Robins]{chernozhukov2018double}
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian
  Hansen, Whitney Newey, and James Robins.
\newblock Double/debiased machine learning for treatment and structural
  parameters.
\newblock \emph{The Econometrics Journal}, 21\penalty0 (1):\penalty0 C1--C68,
  2018.

\bibitem[Cui and {Tchetgen Tchetgen}(2019)]{cui2019selective}
Yifan Cui and Eric {Tchetgen Tchetgen}.
\newblock Selective machine learning of doubly robust functionals.
\newblock \emph{arXiv preprint arXiv:1911.02029}, 2019.

\bibitem[Dukes et~al.(2021)Dukes, Shpitser, and Tchetgen]{dukes2021proximal}
Oliver Dukes, Ilya Shpitser, and Eric J~Tchetgen Tchetgen.
\newblock Proximal mediation analysis.
\newblock \emph{arXiv preprint arXiv:2109.11904}, 2021.

\bibitem[E et~al.(2021)E, Ma, and Wu]{e2021barron}
Weinan E, Chao Ma, and Lei Wu.
\newblock The {Barron} space and the flow-induced function spaces for neural
  network models.
\newblock \emph{Constructive Approximation}, pages 1--38, 2021.

\bibitem[Fr{\"o}lich and Huber(2017)]{frolich2017direct}
Markus Fr{\"o}lich and Martin Huber.
\newblock Direct and indirect treatment effects--causal chains and mediation
  analysis with instrumental variables.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 79\penalty0 (5):\penalty0 1645--1666, 2017.

\bibitem[Gin{\'e} and Nickl(2016)]{gine2016mathematical}
Evarist Gin{\'e} and Richard Nickl.
\newblock \emph{Mathematical foundations of infinite-dimensional statistical
  models}, volume~40.
\newblock Cambridge University Press, 2016.

\bibitem[Goel et~al.(2020)Goel, Gollakota, Jin, Karmalkar, and
  Klivans]{goel2020superpolynomial}
Surbhi Goel, Aravind Gollakota, Zhihan Jin, Sushrut Karmalkar, and Adam
  Klivans.
\newblock Superpolynomial lower bounds for learning one-layer neural networks
  using gradient descent.
\newblock In \emph{International Conference on Machine Learning}, pages
  3587--3596. PMLR, 2020.

\bibitem[Hu et~al.(2020)Hu, Xiao, Adlam, and Pennington]{hu2020surprising}
Wei Hu, Lechao Xiao, Ben Adlam, and Jeffrey Pennington.
\newblock The surprising simplicity of the early-time learning dynamics of
  neural networks.
\newblock \emph{arXiv preprint arXiv:2006.14599}, 2020.

\bibitem[Jiao et~al.(2021)Jiao, Shen, Lin, and Huang]{jiao2021deep}
Yuling Jiao, Guohao Shen, Yuanyuan Lin, and Jian Huang.
\newblock Deep nonparametric regression on approximately low-dimensional
  manifolds.
\newblock \emph{arXiv preprint arXiv:2104.06708}, 2021.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Kohavi(1996)]{kohavi1996scaling}
Ron Kohavi.
\newblock Scaling up the accuracy of {Naive}-{Bayes} classifiers: a
  decision-tree hybrid.
\newblock In \emph{Proceedings of the Second International Conference on
  Knowledge Discovery and Data Mining}, pages 202--207, 1996.

\bibitem[Liu(2018)]{liu2018contributions}
Lin Liu.
\newblock \emph{Contributions to Evolutionary Dynamics and Causal Inference}.
\newblock PhD thesis, 2018.

\bibitem[Liu et~al.(2020)Liu, Mukherjee, and Robins]{liu2020nearly}
Lin Liu, Rajarshi Mukherjee, and James~M Robins.
\newblock On nearly assumption-free tests of nominal confidence interval
  coverage for causal parameters estimated by machine learning.
\newblock \emph{Statistical Science}, 35\penalty0 (3):\penalty0 518--539, 2020.

\bibitem[Lu et~al.(2021)Lu, Shen, Yang, and Zhang]{lu2021deep}
Jianfeng Lu, Zuowei Shen, Haizhao Yang, and Shijun Zhang.
\newblock Deep network approximation for smooth functions.
\newblock \emph{SIAM Journal on Mathematical Analysis}, 53\penalty0
  (5):\penalty0 5465--5506, 2021.

\bibitem[Mukherjee et~al.(2017)Mukherjee, Newey, and
  Robins]{mukherjee2017semiparametric}
Rajarshi Mukherjee, Whitney~K Newey, and James~M Robins.
\newblock Semiparametric efficient empirical higher order influence function
  estimators.
\newblock \emph{arXiv preprint arXiv:1705.07577}, 2017.

\bibitem[Rahaman et~al.(2019)Rahaman, Baratin, Arpit, Draxler, Lin, Hamprecht,
  Bengio, and Courville]{rahaman2019spectral}
Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred
  Hamprecht, Yoshua Bengio, and Aaron Courville.
\newblock On the spectral bias of neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  5301--5310. PMLR, 2019.

\bibitem[Robins et~al.(2008)Robins, Li, Tchetgen~Tchetgen, and van~der
  Vaart]{robins2008higher}
James Robins, Lingling Li, Eric Tchetgen~Tchetgen, and Aad van~der Vaart.
\newblock Higher order influence functions and minimax estimation of nonlinear
  functionals.
\newblock In \emph{Probability and Statistics: Essays in Honor of David A.
  Freedman}, pages 335--421. Institute of Mathematical Statistics, 2008.

\bibitem[Robins et~al.(2020)Robins, Sued, Lei-Gomez, and
  Rotnitzky]{robins2020double}
James Robins, Mariela Sued, Quanhong Lei-Gomez, and Andrea Rotnitzky.
\newblock Double-robust and efficient methods for estimating the causal effects
  of a binary treatment.
\newblock \emph{arXiv preprint arXiv:2008.00507}, 2020.

\bibitem[Robins et~al.(2022)Robins, Richardson, and
  Shpitser]{robins2022interventionist}
James~M Robins, Thomas~S Richardson, and Ilya Shpitser.
\newblock An interventionist approach to mediation analysis.
\newblock In \emph{Probabilistic and Causal Inference: The Works of Judea
  Pearl}, pages 713--764. ACM, 2022.

\bibitem[Schmidt-Hieber(2020)]{schmidt2020nonparametric}
Johannes Schmidt-Hieber.
\newblock Nonparametric regression using deep neural networks with {R}e{LU}
  activation function.
\newblock \emph{Annals of Statistics}, 48\penalty0 (4):\penalty0 1875--1897,
  2020.

\bibitem[Siegel and Xu(2021)]{siegel2021sharp}
Jonathan~W Siegel and Jinchao Xu.
\newblock Sharp bounds on the approximation rates, metric entropy, and
  $n$-widths of shallow neural networks.
\newblock \emph{arXiv preprint arXiv:2101.12365}, 2021.

\bibitem[Stone(1982)]{stone1982optimal}
Charles~J Stone.
\newblock Optimal global rates of convergence for nonparametric regression.
\newblock \emph{The Annals of Statistics}, 10\penalty0 (4):\penalty0
  1040--1053, 1982.

\bibitem[Sun and Ye(2022)]{sun2022semiparametric}
BaoLuo Sun and Ting Ye.
\newblock Semiparametric causal mediation analysis with unmeasured
  mediator-outcome confounding.
\newblock \emph{Statistica Sinica}, 2022.

\bibitem[Suzuki(2019)]{suzuki2019adaptivity}
Taiji Suzuki.
\newblock Adaptivity of deep {R}e{LU} network for learning in {B}esov and mixed
  smooth {B}esov spaces: optimal rate and curse of dimensionality.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Triebel(2010)]{triebel2010theory}
Hans Triebel.
\newblock \emph{Theory of {F}unction {S}paces}.
\newblock Modern Birkh{\"a}user Classics. Springer Basel, 2010.

\bibitem[{van der Laan} and Gruber(2010)]{van2010collaborative}
Mark~J {van der Laan} and Susan Gruber.
\newblock Collaborative double robust targeted maximum likelihood estimation.
\newblock \emph{The International Journal of Biostatistics}, 6\penalty0 (1),
  2010.

\bibitem[{van der Vaart} and Wellner(1996)]{van1996weak}
Aad~W {van der Vaart} and Jon Wellner.
\newblock \emph{Weak Convergence and Empirical Processes: with Applications to
  Statistics}.
\newblock Springer Science \& Business Media, 1996.

\bibitem[VanderWeele et~al.(2014)VanderWeele, Vansteelandt, and
  Robins]{vanderweele2014effect}
Tyler~J VanderWeele, Stijn Vansteelandt, and James~M Robins.
\newblock Effect decomposition in the presence of an exposure-induced
  mediator-outcome confounder.
\newblock \emph{Epidemiology}, 25\penalty0 (2):\penalty0 300--306, 2014.

\bibitem[Xu et~al.(2020)Xu, Zhang, Luo, Xiao, and Ma]{xu2020frequency}
Zhi-Qin~John Xu, Yaoyu Zhang, Tao Luo, Yanyang Xiao, and Zheng Ma.
\newblock Frequency principle: Fourier analysis sheds light on deep neural
  networks.
\newblock \emph{Communications in Computational Physics}, 28\penalty0
  (5):\penalty0 1746--1767, 2020.

\end{thebibliography}
