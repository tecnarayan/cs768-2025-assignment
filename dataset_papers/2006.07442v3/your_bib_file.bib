@article{mnih2013,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@article{kapturowski2018recurrent,
  title={Recurrent experience replay in distributed reinforcement learning},
  author={Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
  year={2018}
}

@article{barth2018distributed,
  title={Distributed distributional deterministic policy gradients},
  author={Barth-Maron, Gabriel and Hoffman, Matthew W and Budden, David and Dabney, Will and Horgan, Dan and Tb, Dhruva and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:1804.08617},
  year={2018}
}

@article{oh2018self,
  title={Self-imitation learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  journal={arXiv preprint arXiv:1806.05635},
  year={2018}
}

@article{rowland2019adaptive,
  title={Adaptive Trade-Offs in Off-Policy Learning},
  author={Rowland, Mark and Dabney, Will and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1910.07478},
  year={2019}
}

@article{silver2016,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@inproceedings{khadka2018evolution,
  title={Evolution-guided policy gradient in reinforcement learning},
  author={Khadka, Shauharda and Tumer, Kagan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1188--1200},
  year={2018}
}

@inproceedings{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2775--2785},
  year={2017}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@misc{klimov2017roboschool,
  title={Roboschool},
  author={Klimov, Oleg and Schulman, John},
  year={2017}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

@article{coumans2010bullet,
  title={Bullet physics engine},
  author={Coumans, Erwin},
  journal={Open Source Software: http://bulletphysics. org},
  volume={1},
  number={3},
  pages={84},
  year={2010}
}

@article{bellman1957markovian,
  title={A Markovian decision process},
  author={Bellman, Richard},
  journal={Journal of mathematics and mechanics},
  pages={679--684},
  year={1957},
  publisher={JSTOR}
}

@article{pourchot2018cem,
  title={CEM-RL: Combining evolutionary and gradient-based methods for policy search},
  author={Pourchot, Alo{\"\i}s and Sigaud, Olivier},
  journal={arXiv preprint arXiv:1810.01222},
  year={2018}
}
@inproceedings{xu2018meta,
  title={Meta-gradient reinforcement learning},
  author={Xu, Zhongwen and van Hasselt, Hado P and Silver, David},
  booktitle={Advances in neural information processing systems},
  pages={2396--2407},
  year={2018}
}

@article{paul2019fast,
  title={Fast efficient hyperparameter tuning for policy gradients},
  author={Paul, Supratik and Kurin, Vitaly and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.06583},
  year={2019}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@article{achiam2018openai,
  title={Openai Spinning Up},
  author={Achiam, Joshua},
  journal={GitHub, GitHub repository},
  year={2018}
}


@article{horgan2018distributed,
  title={Distributed prioritized experience replay},
  author={Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and Van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1803.00933},
  year={2018}
}



@article{reddy2019sqil,
  title={SQIL: imitation learning via regularized behavioral cloning},
  author={Reddy, Siddharth and Dragan, Anca D and Levine, Sergey},
  journal={arXiv preprint arXiv:1905.11108},
  year={2019}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@article{glynn1989importance,
  title={Importance sampling for stochastic simulations},
  author={Glynn, Peter W and Iglehart, Donald L},
  journal={Management science},
  volume={35},
  number={11},
  pages={1367--1392},
  year={1989},
  publisher={INFORMS}
}

@article{tang2020taylor,
  title={Taylor expansion policy optimization},
  author={Tang, Yunhao and Valko, Michal and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:2003.06259},
  year={2020}
}

@article{guo2019efficient,
  title={Efficient Exploration with Self-Imitation Learning via Trajectory-Conditioned Policy},
  author={Guo, Yijie and Choi, Jongwook and Moczulski, Marcin and Bengio, Samy and Norouzi, Mohammad and Lee, Honglak},
  journal={arXiv preprint arXiv:1907.10247},
  year={2019}
}

@article{he2016learning,
  title={Learning to play in a day: Faster deep reinforcement learning by optimality tightening},
  author={He, Frank S and Liu, Yang and Schwing, Alexander G and Peng, Jian},
  journal={arXiv preprint arXiv:1611.01606},
  year={2016}
}

@inproceedings{asadi2017alternative,
  title={An alternative softmax operator for reinforcement learning},
  author={Asadi, Kavosh and Littman, Michael L},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={243--252},
  year={2017},
  organization={JMLR. org}
}

@article{fox2015taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  journal={arXiv preprint arXiv:1512.08562},
  year={2015}
}

@article{ziebart2010modeling,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}

@article{gangwani2018learning,
  title={Learning self-imitating diverse policies},
  author={Gangwani, Tanmay and Liu, Qiang and Peng, Jian},
  journal={arXiv preprint arXiv:1805.10309},
  year={2018}
}

@article{peng2019advantage,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@inproceedings{zinkevich2008regret,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  booktitle={Advances in neural information processing systems},
  pages={1729--1736},
  year={2008}
}

@inproceedings{heinrich2015fictitious,
  title={Fictitious self-play in extensive-form games},
  author={Heinrich, Johannes and Lanctot, Marc and Silver, David},
  booktitle={International Conference on Machine Learning},
  pages={805--813},
  year={2015}
}

@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2817--2826},
  year={2017},
  organization={JMLR. org}
}
 
 @article{yu2017preparing,
  title={Preparing for the unknown: Learning a universal policy with online system identification},
  author={Yu, Wenhao and Tan, Jie and Liu, C Karen and Turk, Greg},
  journal={arXiv preprint arXiv:1702.02453},
  year={2017}
}

 @article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
%rl for pomdp
@article{stone2017,
  title={Deep recurrent Q-learning for partially observable MDPs},
  author={Hausknecht, Matthew and Stone, Peter},
  journal={arXiv preprint arXiv:1507.06527v4},
  year={2017}
}

@article{jin2017,
  title={Regret minimization for partially observable deep reinforcement learning},
  author={Jin, Peter H and Levine, Sergey and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1710.11424},
  year={2017}
}

@inproceedings{jordan1995pomdp,
  title={Reinforcement learning algorithm for partially observable Markov decision problems},
  author={Jaakkola, Tommi and Singh, Satinder and Jordan, Michael},
  booktitle={Advances in neural information processing systems},
  pages={345--352},
  year={1995}
}

@inproceedings{variationalRL2018,
  title={Deep variational reinforcement learning for POMDPs},
  author={Igl, Maximilian and Zintgraf, Luisa and Le, Tuan Anh and Wood, Frank and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={2117--2126},
  year={2018}
}

@inproceedings{bartlett2000,
  title={Reinforcement learning in POMDP's via direct gradient ascent},
  author={Baxter, Jonathan and Bartlett, Peter},
  booktitle={International Conference on Machine Learning},
  pages={41--48},
  year={2000}
}
%%%%%%%%%%%%%%%%%%   
% infer 2 control
@inproceedings{Marc2011,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl},
  booktitle={International Conference on Machine Learning},
  pages={456--472},
  year={2011}
}

@inproceedings{Marc2009,
  title={Robot trajectory optimization using approximate inference},
  author={Toussaint, Marc},
  booktitle={International Conference on Machine Learning},
  pages={1049--1056},
  year={2009}
}


%%%%%%%%%%%%%%%%%

@inproceedings{duanxi2016,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}
    
@inproceedings{osband2016,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{osband2015,
  title={Bootstrapped thompson sampling and deep exploration},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1507.00300},
  year={2015}
}
    
@article{fortunato2017,
  title={Noisy networks for exploration},
  author={Fortunato, Meire and Azar, Mohammad Gheshlaghi and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier and others},
  journal={arXiv preprint arXiv:1706.10295},
  year={2017}
}
    
@article{timothy2016,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
    
@inproceedings{schulman2015,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}
       
@article{levine2016,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}
    
@article{osband2017,
  title={Deep exploration via randomized value functions},
  author={Osband, Ian and Russo, Daniel and Wen, Zheng and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1703.07608},
  year={2017}
}
    
@inproceedings{furmston2010,
  title={Variational methods for reinforcement learning},
  author={Furmston, Thomas and Barber, David},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={241--248},
  year={2010}
}
    
@article{schaul2016,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}
 
@inproceedings{silver2014,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}

@inproceedings{hasselt2016,
  title={Deep Reinforcement Learning with Double Q-Learning.},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI},
  volume={16},
  pages={2094--2100},
  year={2016}
}
    
@article{wang2016,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}
    
@inproceedings{todorov2008,
  title={General duality between optimal control and estimation},
  author={Todorov, Emanuel},
  booktitle={Decision and Control, 2008. CDC 2008. 47th IEEE Conference on},
  pages={4286--4292},
  year={2008},
  organization={IEEE}
}      
    
@book{sutton1998,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}
        
@incollection{williams1992,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  booktitle={Reinforcement Learning},
  pages={5--32},
  year={1992},
  publisher={Springer}
}   
       
@article{blei2017,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American Statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}
         
@inproceedings{blei2015,
  title={Black box variational inference},
  author={Ranganath, Rajesh and Gerrish, Sean and Blei, David},
  booktitle={Artificial Intelligence and Statistics},
  pages={814--822},
  year={2014}
}

@article{tran2016,
  title={Deep probabilistic programming},
  author={Tran, Dustin and Hoffman, Matthew D and Saurous, Rif A and Brevdo, Eugene and Murphy, Kevin and Blei, David M},
  journal={arXiv preprint arXiv:1701.03757},
  year={2017}
}  

@article{brockman2016,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}
     
@article{lipton2016,
  title={Efficient dialogue policy learning with bbq-networks},
  author={Lipton, Zachary C and Li, Xiujun and Gao, Jianfeng and Li, Lihong and Ahmed, Faisal and Deng, Li and Birnbaum, Tobias and Eldar, Yonina C and Needell, Deanna and Memon, Adnan and others},
  journal={arXiv preprint ArXiv:1608.05081},
  year={2016}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{harutyunyan2016q,
  title={Q (lambda) with Off-Policy Corrections},
  author={Harutyunyan, Anna and Bellemare, Marc G and Stepleton, Tom and Munos, R{\'e}mi},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={305--320},
  year={2016},
  organization={Springer}
}
    
@article{william1933,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  volume={25},
  number={3/4},
  pages={285--294},
  year={1933},
  publisher={JSTOR}
}

@article{kucukelbir2016automatic,
    Author = {Alp Kucukelbir, and Dustin Tran, and Rajesh Ranganath, and Andrew Gelman, and David M. Blei},
    Journal = {Journal of Machine Learning Research, 18(14):1-45},
    Title = {Automatic differentiation variational inference},
    Year = {2017}}  
        
@inproceedings{goodfellow2015,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}    
    
@article{li2018,
  title={Gradient Estimators for Implicit Models},
  author={Li, Yingzhen and Turner, Richard E},
  journal={arXiv preprint arXiv:1705.07107},
  year={2017}
}
    
@article{dustin2017,
  title={Hierarchical Implicit Models and Likelihood-Free Variational Inference},
  author={Tran, Dustin and Ranganath, Rajesh and Blei, David M},
  journal={arXiv preprint arXiv:1702.08896},
  year={2017}
}

@article{srivastava2014,
  title={Dropout: A simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{gal2016,
  title={Dropout as a Bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}   

@article{tuomas2017,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1702.08165},
  year={2017}
}

@article{plappert2018,
  title={Parameter space noise for exploration},
  author={Plappert, Matthias and Houthooft, Rein and Dhariwal, Prafulla and Sidor, Szymon and Chen, Richard Y and Chen, Xi and Asfour, Tamim and Abbeel, Pieter and Andrychowicz, Marcin},
  journal={arXiv preprint arXiv:1706.01905},
  year={2017}
}  
    
@article{tang2017,
  title={Variational Deep Q Network},
  author={Tang, Yunhao and Kucukelbir, Alp},
  journal={arXiv preprint arXiv:1711.11225},
  year={2017}
}  

@inproceedings{marian2017,
  title={Sobolev training for neural networks},
  author={Czarnecki, Wojciech M and Osindero, Simon and Jaderberg, Max and Swirszcz, Grzegorz and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4281--4290},
  year={2017}
}

@article{schulman2017chen,
  title={Equivalence between policy gradients and soft q-learning},
  author={Schulman, John and Chen, Xi and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.06440},
  year={2017}
}
    
@article{degris2012,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{donoghue2017,
  title={Pgq: Combining policy gradient and q-learning},
  author={O'Donoghue, Brendan and Munos, Remi and Kavukcuoglu, Koray and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1611.01626},
  year={2016}
}
      
@inproceedings{mnih2016,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}
    
@inproceedings{sutton1999,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}
 
@article{schulman2017,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
    
@article{rezende2015,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir},
  journal={arXiv preprint arXiv:1505.05770},
  year={2015}
} 
    
@article{dinh2017,
  title={Density estimation using Real NVP},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  journal={arXiv preprint arXiv:1605.08803},
  year={2016}
}
    
@article{dinh2015,
  title={NICE: Non-linear independent components estimation},
  author={Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1410.8516},
  year={2014}
}

@inproceedings{nachum2017,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2772--2782},
  year={2017}
}
    
@inproceedings{asadi2017,
  title={An Alternative Softmax Operator for Reinforcement Learning},
  author={Asadi, Kavosh and Littman, Michael L},
  booktitle={International Conference on Machine Learning},
  pages={243--252},
  year={2017}
}      
 
@inproceedings{ross2011,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}
 
@inproceedings{ho2016,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4565--4573},
  year={2016}
}
 
@article{finn2016,
  title={A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models},
  author={Finn, Chelsea and Christiano, Paul and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.03852},
  year={2016}
}

@book{ziebart2010,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010},
  publisher={Carnegie Mellon University}
}

@inproceedings{abbeel2010,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004},
  organization={ACM}
} 
 
@inproceedings{schulman2015gradient,
  title={Gradient estimation using stochastic computation graphs},
  author={Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3528--3536},
  year={2015}
}

@inproceedings{todorov2012,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
    
@article{tuomas2018,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@inproceedings{rajeswaran2017,
  title={Towards generalization and simplicity in continuous control},
  author={Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel V and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6553--6564},
  year={2017}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@article{kingma2013,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{liu2016,
  title={Stein variational gradient descent: A general purpose bayesian inference algorithm},
  author={Liu, Qiang and Wang, Dilin},
  booktitle={Advances In Neural Information Processing Systems},
  pages={2378--2386},
  year={2016}
}         

@article{tuomas2018b,
  title={Latent Space Policies for Hierarchical Reinforcement Learning},
  author={Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1804.02808},
  year={2018}
}

@article{levine2018,
  title={Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}
      
@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  volume={2},
  pages={267--274},
  year={2002}
}  

@article{mania2018simple,
  title={Simple random search provides a competitive approach to reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  journal={arXiv preprint arXiv:1803.07055},
  year={2018}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}   

@article{haarnoja2018composable,
  title={Composable Deep Reinforcement Learning for Robotic Manipulation},
  author={Haarnoja, Tuomas and Pong, Vitchyr and Zhou, Aurick and Dalal, Murtaza and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.06773},
  year={2018}
}

@article{haarnoja2018latent,
  title={Latent Space Policies for Hierarchical Reinforcement Learning},
  author={Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1804.02808},
  year={2018}
}
%@article{bellemare2016},
  %  Author = {Marc G. Bellemare, and Sriram Srinivasan, and Georg Ostrovski, and Tom Schaul, and David Saxton, and Remi Munos},
%    Journal = {Advances in Neural Information Processing Systems},
   % Title = {Unifying Count-Based Exploration and Intrinsic Motivation},
    %Year = {2016}}        
 
%@article{tang2016},
   % Author = {Haoran Tang, and Rein Houthooft, and Davis Foote, and Adam Stooke, and Xi Chen, and Yan Duan, and John Schulman, and Filip De Turck, and Pieter Abbeel},
    %Journal = {arXiv: 1611.04717},
    %Title = {$#$Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning},
    %Year = {2017}}       

@article{wainwright2008graphical,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael I and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={1},
  number={1--2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@inproceedings{levine2013variational,
  title={Variational policy search via trajectory optimization},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={207--215},
  year={2013}
}

@inproceedings{neumann2011variational,
  title={Variational inference for policy search in changing situations},
  author={Neumann, Gerhard and others},
  booktitle={Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
  pages={817--824},
  year={2011}
}

@article{tang2017variational,
  title={Variational Deep Q Network},
  author={Tang, Yunhao and Kucukelbir, Alp},
  journal={arXiv preprint arXiv:1711.11225},
  year={2017}
}

@article{lipton2016efficient,
  title={Efficient exploration for dialogue policy learning with BBQ networks \& replay buffer spiking},
  author={Lipton, Zachary C and Gao, Jianfeng and Li, Lihong and Li, Xiujun and Ahmed, Faisal and Deng, Li},
  journal={arXiv preprint arXiv:1608.05081},
  year={2016}
}

@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
 
@inproceedings{todorov2008general,
  title={General duality between optimal control and estimation},
  author={Todorov, Emanuel},
  booktitle={Decision and Control, 2008. CDC 2008. 47th IEEE Conference on},
  pages={4286--4292},
  year={2008},
  organization={IEEE}
}

@article{kalman1959general,
  title={On the general theory of control systems},
  author={Kalman, Rudolf},
  journal={IRE Transactions on Automatic Control},
  volume={4},
  number={3},
  pages={110--110},
  year={1959}
}

@inproceedings{ziebart2008maximum,
  title={Maximum Entropy Inverse Reinforcement Learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={AAAI},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@article{levine2018reinforcement,
  title={Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@article{abdolmaleki2018maximum,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}
 
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE Conference on Decision and Control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}


@inproceedings{lee2013bias,
  title={Bias-corrected Q-learning to control max-operator bias in Q-learning},
  author={Lee, Donghun and Defourny, Boris and Powell, Warren B},
  booktitle={2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
  pages={93--99},
  year={2013},
  organization={IEEE}
}

@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

@article{pritzel2017neural,
  title={Neural episodic control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Puigdomenech, Adria and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  journal={arXiv preprint arXiv:1703.01988},
  year={2017}
}

@article{blundell2016model,
  title={Model-free episodic control},
  author={Blundell, Charles and Uria, Benigno and Pritzel, Alexander and Li, Yazhe and Ruderman, Avraham and Leibo, Joel Z and Rae, Jack and Wierstra, Daan and Hassabis, Demis},
  journal={arXiv preprint arXiv:1606.04460},
  year={2016}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}


@article{dudik2014doubly,
  title={Doubly robust policy evaluation and optimization},
  author={Dud{\'\i}k, Miroslav and Erhan, Dumitru and Langford, John and Li, Lihong and others},
  journal={Statistical Science},
  volume={29},
  number={4},
  pages={485--511},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@article{mahmood2017multi,
  title={Multi-step off-policy learning without importance sampling ratios},
  author={Mahmood, Ashique Rupam and Yu, Huizhen and Sutton, Richard S},
  journal={arXiv preprint arXiv:1702.03006},
  year={2017}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{zhang2017weighted,
  title={Weighted Double Q-learning.},
  author={Zhang, Zongzhang and Pan, Zhiyuan and Kochenderfer, Mykel J},
  booktitle={IJCAI},
  pages={3455--3461},
  year={2017}
}

@article{lan2020maxmin,
  title={Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
  author={Lan, Qingfeng and Pan, Yangchen and Fyshe, Alona and White, Martha},
  journal={arXiv preprint arXiv:2002.06487},
  year={2020}
}

@inproceedings{anschel2017averaged,
  title={Averaged-dqn: Variance reduction and stabilization for deep reinforcement learning},
  author={Anschel, Oron and Baram, Nir and Shimkin, Nahum},
  booktitle={International Conference on Machine Learning},
  pages={176--185},
  year={2017},
  organization={PMLR}
}
    
    
       