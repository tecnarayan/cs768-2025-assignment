\begin{thebibliography}{10}

\bibitem{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock {\em Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem{bouneffouf2019survey}
Djallel Bouneffouf and Irina Rish.
\newblock A survey on practical applications of multi-armed and contextual
  bandits.
\newblock {\em arXiv preprint arXiv:1904.10040}, 2019.

\bibitem{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, 25(3/4):285--294, 1933.

\bibitem{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2312--2320, 2011.

\bibitem{agrawal2013thompson}
Shipra Agrawal and Navin Goyal.
\newblock Thompson sampling for contextual bandits with linear payoffs.
\newblock In {\em International Conference on Machine Learning}, pages
  127--135, 2013.

\bibitem{abeille2017linear}
Marc Abeille and Alessandro Lazaric.
\newblock Linear thompson sampling revisited.
\newblock In {\em {AISTATS}}, volume~54 of {\em Proceedings of Machine Learning
  Research}, pages 176--184. {PMLR}, 2017.

\bibitem{lattimore2017end}
Tor Lattimore and Csaba Szepesv{\'{a}}ri.
\newblock The end of optimism? an asymptotic analysis of finite-armed linear
  bandits.
\newblock In {\em {AISTATS}}, volume~54 of {\em Proceedings of Machine Learning
  Research}, pages 728--737. {PMLR}, 2017.

\bibitem{azar2013sequential}
Mohammad Azar, Alessandro Lazaric, and Emma Brunskill.
\newblock Sequential transfer in multi-armed bandit with finite set of models.
\newblock In C.~J.~C. Burges, L.~Bottou, M.~Welling, Z.~Ghahramani, and K.~Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems
  26}, pages 2220--2228. 2013.

\bibitem{lattimore2014bounded}
Tor Lattimore and R{\'e}mi Munos.
\newblock Bounded regret for finite-armed structured bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  550--558, 2014.

\bibitem{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via information-directed sampling.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1583--1591, 2014.

\bibitem{agrawal1988asymptotically}
Rajeev Agrawal, Demosthenis Teneketzis, and Venkatachalam Anantharam.
\newblock Asymptotically efficient adaptive allocation schemes for controlled
  markov chains: Finite parameter space.
\newblock In {\em Proceedings of the 27th IEEE Conference on Decision and
  Control}, pages 1198--1203. IEEE, 1988.

\bibitem{burnetas1996optimal}
Apostolos~N Burnetas and Michael~N Katehakis.
\newblock Optimal adaptive policies for sequential allocation problems.
\newblock {\em Advances in Applied Mathematics}, 17(2):122--142, 1996.

\bibitem{graves1997asymptotically}
Todd~L Graves and Tze~Leung Lai.
\newblock Asymptotically efficient adaptive choice of control laws incontrolled
  markov chains.
\newblock {\em SIAM journal on control and optimization}, 35(3):715--743, 1997.

\bibitem{garivier2016optimal}
Aur{\'e}lien Garivier and Emilie Kaufmann.
\newblock Optimal best arm identification with fixed confidence.
\newblock In {\em Conference on Learning Theory}, pages 998--1027, 2016.

\bibitem{combes2017minimal}
Richard Combes, Stefan Magureanu, and Alexandre Prouti{\`{e}}re.
\newblock Minimal exploration in structured stochastic bandits.
\newblock In {\em {NIPS}}, pages 1763--1771, 2017.

\bibitem{hao2019adaptive}
Botao Hao, Tor Lattimore, and Csaba Szepesvari.
\newblock Adaptive exploration in linear contextual bandit.
\newblock volume 108 of {\em Proceedings of Machine Learning Research}, pages
  3536--3545, Online, 26--28 Aug 2020. PMLR.

\bibitem{degenne2020structure}
R{\'e}my Degenne, Han Shao, and Wouter Koolen.
\newblock Structure adaptive algorithms for stochastic bandits.
\newblock In {\em {International Conference on Machine Learning}}, Vienna,
  Austria, 2020.
\newblock Virtual conference.

\bibitem{degenne2019non}
R{\'{e}}my Degenne, Wouter~M. Koolen, and Pierre M{\'{e}}nard.
\newblock Non-asymptotic pure exploration by solving games.
\newblock In {\em NeurIPS}, pages 14465--14474, 2019.

\bibitem{ok2018exploration}
Jungseul Ok, Alexandre Prouti{\`{e}}re, and Damianos Tranos.
\newblock Exploration in structured reinforcement learning.
\newblock In {\em NeurIPS}, pages 8874--8882, 2018.

\bibitem{lai1985asymptotically}
Tze~Leung Lai and Herbert Robbins.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock {\em Advances in applied mathematics}, 6(1):4--22, 1985.

\bibitem{degenne2020gamification}
R{\'e}my Degenne, Pierre M{\'e}nard, Xuedong Shang, and Michal Valko.
\newblock {Gamification of pure exploration for linear bandits}.
\newblock In {\em {International Conference on Machine Learning}}, Vienna,
  Austria, 2020.
\newblock Virtual conference.

\bibitem{nedic2009subgradient}
Angelia Nedi{\'c} and Asuman Ozdaglar.
\newblock Subgradient methods for saddle-point problems.
\newblock {\em Journal of optimization theory and applications},
  142(1):205--228, 2009.

\bibitem{efroni2020exploration}
Yonathan Efroni, Shie Mannor, and Matteo Pirotta.
\newblock Exploration-exploitation in constrained mdps.
\newblock {\em arXiv preprint arXiv:2003.02189}, 2020.

\bibitem{bastani2017mostly}
Hamsa Bastani, Mohsen Bayati, and Khashayar Khosravi.
\newblock Mostly exploration-free algorithms for contextual bandits.
\newblock {\em arXiv preprint arXiv:1704.09011}, 2017.

\bibitem{tirinzoni2020novel}
Andrea Tirinzoni, Alessandro Lazaric, and Marcello Restelli.
\newblock A novel confidence-based algorithm for structured bandits.
\newblock In {\em {AISTATS}}, volume 108 of {\em Proceedings of Machine
  Learning Research}, pages 3175--3185. {PMLR}, 2020.

\bibitem{jian2019exploration}
Jian Qian, Ronan Fruit, Matteo Pirotta, and Alessandro Lazaric.
\newblock Exploration bonus for regret minimization in discrete and continuous
  average reward mdps.
\newblock In {\em NeurIPS}, pages 4891--4900. 2019.

\bibitem{combes2014unimodal}
Richard Combes and Alexandre Prouti{\`{e}}re.
\newblock Unimodal bandits: Regret lower bounds and optimal algorithms.
\newblock In {\em {ICML}}, volume~32 of {\em {JMLR} Workshop and Conference
  Proceedings}, pages 521--529. JMLR.org, 2014.

\bibitem{orabona2019modern}
Francesco Orabona.
\newblock A modern introduction to online learning.
\newblock {\em arXiv preprint arXiv:1912.13213}, 2019.

\bibitem{beck2003mirror}
Amir Beck and Marc Teboulle.
\newblock Mirror descent and nonlinear projected subgradient methods for convex
  optimization.
\newblock {\em Operations Research Letters}, 31(3):167--175, 2003.

\bibitem{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock {\em Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem{fan2015exponential}
Xiequan Fan, Ion Grama, Quansheng Liu, et~al.
\newblock Exponential inequalities for martingales with applications.
\newblock {\em Electronic Journal of Probability}, 20, 2015.

\bibitem{khan2009p}
Rasul~A Khan.
\newblock L p-version of the dubins--savage inequality and some exponential
  inequalities.
\newblock {\em Journal of Theoretical Probability}, 22(2):348, 2009.

\bibitem{goldberg2001eigentaste}
Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins.
\newblock Eigentaste: A constant time collaborative filtering algorithm.
\newblock {\em information retrieval}, 4(2):133--151, 2001.

\end{thebibliography}
