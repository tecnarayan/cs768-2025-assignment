\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amanatidis et~al.(2021)Amanatidis, Fusco, Lazos, Leonardi,
  Marchetti{-}Spaccamela, and Reiffenh{\"{a}}user]{AmanatidisFLLMR21}
Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, Alberto
  Marchetti{-}Spaccamela, and Rebecca Reiffenh{\"{a}}user.
\newblock Submodular maximization subject to a knapsack constraint:
  Combinatorial algorithms with near-optimal adaptive complexity.
\newblock In \emph{{ICML}}, volume 139 of \emph{Proceedings of Machine Learning
  Research}, pages 231--242. {PMLR}, 2021.

\bibitem[Amanatidis et~al.(2022)Amanatidis, Fusco, Lazos, Leonardi, and
  Reiffenh{\"{a}}user]{AmanatidisFLLR22}
Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, and
  Rebecca Reiffenh{\"{a}}user.
\newblock Fast adaptive non-monotone submodular maximization subject to a
  knapsack constraint.
\newblock \emph{J. Artif. Intell. Res.}, 74:\penalty0 661--690, 2022.

\bibitem[Balkanski and Singer(2018)]{BalkanskiS18}
Eric Balkanski and Yaron Singer.
\newblock The adaptive complexity of maximizing a submodular function.
\newblock In \emph{{STOC}}, pages 1138--1151. {ACM}, 2018.

\bibitem[Balkanski et~al.(2018)Balkanski, Breuer, and Singer]{BalkanskiBS18}
Eric Balkanski, Adam Breuer, and Yaron Singer.
\newblock Non-monotone submodular maximization in exponentially fewer
  iterations.
\newblock In \emph{NeurIPS}, pages 2359--2370, 2018.

\bibitem[Balkanski et~al.(2019)Balkanski, Rubinstein, and
  Singer]{BalkanskiRS19}
Eric Balkanski, Aviad Rubinstein, and Yaron Singer.
\newblock An exponential speedup in parallel running time for submodular
  maximization without loss in approximation.
\newblock In \emph{{SODA}}, pages 283--302. {SIAM}, 2019.

\bibitem[Balkanski et~al.(2022)Balkanski, Rubinstein, and
  Singer]{BalkanskiRS19matroid}
Eric Balkanski, Aviad Rubinstein, and Yaron Singer.
\newblock An optimal approximation for submodular maximization under a matroid
  constraint in the adaptive complexity model.
\newblock \emph{Oper. Res.}, 70\penalty0 (5):\penalty0 2967--2981, 2022.

\bibitem[Breuer et~al.(2020)Breuer, Balkanski, and Singer]{BreuerBS20}
Adam Breuer, Eric Balkanski, and Yaron Singer.
\newblock The {FAST} algorithm for submodular maximization.
\newblock In \emph{{ICML}}, volume 119 of \emph{Proceedings of Machine Learning
  Research}, pages 1134--1143. {PMLR}, 2020.

\bibitem[Buchbinder and Feldman(2018)]{BuchbinderF18}
Niv Buchbinder and Moran Feldman.
\newblock Submodular functions maximization problems.
\newblock In \emph{Handbook of Approximation Algorithms and Metaheuristics
  {(1)}}, pages 753--788. Chapman and Hall/CRC, 2018.

\bibitem[Buchbinder et~al.(2014)Buchbinder, Feldman, Naor, and
  Schwartz]{BuchbinderFNS14}
Niv Buchbinder, Moran Feldman, Joseph Naor, and Roy Schwartz.
\newblock Submodular maximization with cardinality constraints.
\newblock In \emph{{SODA}}, pages 1433--1452. {SIAM}, 2014.

\bibitem[Chekuri and Quanrud(2019{\natexlab{a}})]{ChekuriQ19}
Chandra Chekuri and Kent Quanrud.
\newblock Submodular function maximization in parallel via the multilinear
  relaxation.
\newblock In \emph{{SODA}}, pages 303--322. {SIAM}, 2019{\natexlab{a}}.

\bibitem[Chekuri and Quanrud(2019{\natexlab{b}})]{ChekuriQ19matroid}
Chandra Chekuri and Kent Quanrud.
\newblock Parallelizing greedy for submodular set function maximization in
  matroids and beyond.
\newblock In \emph{{STOC}}, pages 78--89. {ACM}, 2019{\natexlab{b}}.

\bibitem[Chekuri et~al.(2014)Chekuri, Vondr{\'{a}}k, and
  Zenklusen]{ChekuriVZ14}
Chandra Chekuri, Jan Vondr{\'{a}}k, and Rico Zenklusen.
\newblock Submodular function maximization via the multilinear relaxation and
  contention resolution schemes.
\newblock \emph{{SIAM} J. Comput.}, 43\penalty0 (6):\penalty0 1831--1879, 2014.

\bibitem[Chen et~al.(2019)Chen, Feldman, and Karbasi]{FK19}
Lin Chen, Moran Feldman, and Amin Karbasi.
\newblock Unconstrained submodular maximization with constant adaptive
  complexity.
\newblock In \emph{{STOC}}, pages 102--113. {ACM}, 2019.

\bibitem[Chen et~al.(2021)Chen, Dey, and Kuhnle]{ChenDK21}
Yixin Chen, Tonmoy Dey, and Alan Kuhnle.
\newblock Best of both worlds: Practical and theoretically optimal submodular
  maximization in parallel.
\newblock In \emph{NeurIPS}, pages 25528--25539, 2021.

\bibitem[Cui et~al.(2023{\natexlab{a}})Cui, Han, Tang, Huang, Li, and
  Zhiyuli]{Cui000LZ23}
Shuang Cui, Kai Han, Jing Tang, He~Huang, Xueying Li, and Aakas Zhiyuli.
\newblock Practical parallel algorithms for submodular maximization subject to
  a knapsack constraint with nearly optimal adaptivity.
\newblock In \emph{{AAAI}}, pages 7261--7269. {AAAI} Press, 2023{\natexlab{a}}.

\bibitem[Cui et~al.(2023{\natexlab{b}})Cui, Han, Tang, Huang, Li, Zhiyuli, and
  Li]{CuiH23}
Shuang Cui, Kai Han, Jing Tang, He~Huang, Xueying Li, Aakas Zhiyuli, and
  Hanxiao Li.
\newblock Practical parallel algorithms for non-monotone submodular
  maximization.
\newblock \emph{CoRR}, abs/2308.10656, 2023{\natexlab{b}}.

\bibitem[Das and Kempe(2008)]{DasK08}
Abhimanyu Das and David Kempe.
\newblock Algorithms for subset selection in linear regression.
\newblock In \emph{{STOC}}, pages 45--54. {ACM}, 2008.

\bibitem[Das and Kempe(2018)]{DasK18}
Abhimanyu Das and David Kempe.
\newblock Approximate submodularity and its applications: Subset selection,
  sparse approximation and dictionary selection.
\newblock \emph{J. Mach. Learn. Res.}, 19:\penalty0 3:1--3:34, 2018.

\bibitem[Dueck and Frey(2007)]{DueckF07}
Delbert Dueck and Brendan~J. Frey.
\newblock Non-metric affinity propagation for unsupervised image
  categorization.
\newblock In \emph{{ICCV}}, pages 1--8. {IEEE} Computer Society, 2007.

\bibitem[Duetting et~al.(2022)Duetting, Fusco, Lattanzi, Norouzi{-}Fard, and
  Zadimoghaddam]{DuettingFLNZ22}
Paul Duetting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi{-}Fard, and
  Morteza Zadimoghaddam.
\newblock Deletion robust submodular maximization over matroids.
\newblock In \emph{{ICML}}, volume 162 of \emph{Proceedings of Machine Learning
  Research}, pages 5671--5693. {PMLR}, 2022.

\bibitem[Ene and Nguyen(2019)]{EneN19}
Alina Ene and Huy~L. Nguyen.
\newblock Submodular maximization with nearly-optimal approximation and
  adaptivity in nearly-linear time.
\newblock In \emph{{SODA}}, pages 274--282. {SIAM}, 2019.

\bibitem[Ene and Nguyen(2020)]{EneN20}
Alina Ene and Huy~L. Nguyen.
\newblock Parallel algorithm for non-monotone dr-submodular maximization.
\newblock In \emph{{ICML}}, volume 119 of \emph{Proceedings of Machine Learning
  Research}, pages 2902--2911. {PMLR}, 2020.

\bibitem[Ene et~al.(2018)Ene, Nguyen, and Vladu]{EneNV18}
Alina Ene, Huy~L. Nguyen, and Adrian Vladu.
\newblock A parallel double greedy algorithm for submodular maximization.
\newblock \emph{CoRR}, abs/1812.01591, 2018.

\bibitem[Ene et~al.(2019)Ene, Nguyen, and Vladu]{EneNV19}
Alina Ene, Huy~L. Nguyen, and Adrian Vladu.
\newblock Submodular maximization with matroid and packing constraints in
  parallel.
\newblock In \emph{{STOC}}, pages 90--101. {ACM}, 2019.

\bibitem[Esfandiari et~al.(2021)Esfandiari, Karbasi, and
  Mirrokni]{EsfandiariKM21}
Hossein Esfandiari, Amin Karbasi, and Vahab~S. Mirrokni.
\newblock Adaptivity in adaptive submodularity.
\newblock In \emph{{COLT}}, volume 134 of \emph{Proceedings of Machine Learning
  Research}, pages 1823--1846. {PMLR}, 2021.

\bibitem[Fahrbach et~al.(2019{\natexlab{a}})Fahrbach, Mirrokni, and
  Zadimoghaddam]{FahrbachMZ19}
Matthew Fahrbach, Vahab~S. Mirrokni, and Morteza Zadimoghaddam.
\newblock Submodular maximization with nearly optimal approximation, adaptivity
  and query complexity.
\newblock In \emph{{SODA}}, pages 255--273. {SIAM}, 2019{\natexlab{a}}.

\bibitem[Fahrbach et~al.(2019{\natexlab{b}})Fahrbach, Mirrokni, and
  Zadimoghaddam]{FahrbachMZ19nonmonotone}
Matthew Fahrbach, Vahab~S. Mirrokni, and Morteza Zadimoghaddam.
\newblock Non-monotone submodular maximization with nearly optimal adaptivity
  and query complexity.
\newblock In \emph{{ICML}}, volume~97 of \emph{Proceedings of Machine Learning
  Research}, pages 1833--1842. {PMLR}, 2019{\natexlab{b}}.

\bibitem[Feige(1998)]{Feige98}
Uriel Feige.
\newblock A threshold of ln \emph{n} for approximating set cover.
\newblock \emph{J. {ACM}}, 45\penalty0 (4):\penalty0 634--652, 1998.

\bibitem[Feige et~al.(2011)Feige, Mirrokni, and Vondr{\'{a}}k]{FeigeMV11}
Uriel Feige, Vahab~S. Mirrokni, and Jan Vondr{\'{a}}k.
\newblock Maximizing non-monotone submodular functions.
\newblock \emph{{SIAM} J. Comput.}, 40\penalty0 (4):\penalty0 1133--1153, 2011.

\bibitem[Feldman et~al.(2011)Feldman, Naor, and Schwartz]{FeldmanNS11}
Moran Feldman, Joseph Naor, and Roy Schwartz.
\newblock A unified continuous greedy algorithm for submodular maximization.
\newblock In \emph{{FOCS}}, pages 570--579. {IEEE} Computer Society, 2011.

\bibitem[Gupta et~al.(2010)Gupta, Roth, Schoenebeck, and Talwar]{GuptaRST10}
Anupam Gupta, Aaron Roth, Grant Schoenebeck, and Kunal Talwar.
\newblock Constrained non-monotone submodular maximization: Offline and
  secretary algorithms.
\newblock In \emph{{WINE}}, volume 6484 of \emph{Lecture Notes in Computer
  Science}, pages 246--257. Springer, 2010.

\bibitem[Hartline et~al.(2008)Hartline, Mirrokni, and
  Sundararajan]{HartlineMS08}
Jason~D. Hartline, Vahab~S. Mirrokni, and Mukund Sundararajan.
\newblock Optimal marketing strategies over social networks.
\newblock In \emph{{WWW}}, pages 189--198. {ACM}, 2008.

\bibitem[Kazemi et~al.(2018)Kazemi, Zadimoghaddam, and Karbasi]{KazemiZK18}
Ehsan Kazemi, Morteza Zadimoghaddam, and Amin Karbasi.
\newblock Scalable deletion-robust submodular maximization: Data summarization
  with privacy and fairness constraints.
\newblock In \emph{{ICML}}, volume~80 of \emph{Proceedings of Machine Learning
  Research}, pages 2549--2558. {PMLR}, 2018.

\bibitem[Kempe et~al.(2015)Kempe, Kleinberg, and Tardos]{KempeKT15}
David Kempe, Jon~M. Kleinberg, and {\'{E}}va Tardos.
\newblock Maximizing the spread of influence through a social network.
\newblock \emph{Theory Comput.}, 11:\penalty0 105--147, 2015.

\bibitem[Khanna et~al.(2017)Khanna, Elenberg, Dimakis, Negahban, and
  Ghosh]{KhannaEDNG17}
Rajiv Khanna, Ethan~R. Elenberg, Alexandros~G. Dimakis, Sahand~N. Negahban, and
  Joydeep Ghosh.
\newblock Scalable greedy feature selection via weak submodularity.
\newblock In \emph{{AISTATS}}, volume~54 of \emph{Proceedings of Machine
  Learning Research}, pages 1560--1568. {PMLR}, 2017.

\bibitem[Kuhnle(2021)]{Kuhnle21}
Alan Kuhnle.
\newblock Nearly linear-time, parallelizable algorithms for non-monotone
  submodular maximization.
\newblock In \emph{{AAAI}}, pages 8200--8208. {AAAI} Press, 2021.

\bibitem[Kulik et~al.(2013)Kulik, Shachnai, and Tamir]{KulikST13}
Ariel Kulik, Hadas Shachnai, and Tami Tamir.
\newblock Approximations for monotone and nonmonotone submodular maximization
  with knapsack constraints.
\newblock \emph{Math. Oper. Res.}, 38\penalty0 (4):\penalty0 729--739, 2013.

\bibitem[Lattanzi et~al.(2020)Lattanzi, Mitrovic, Norouzi{-}Fard, Tarnawski,
  and Zadimoghaddam]{LattanziMNTZ20}
Silvio Lattanzi, Slobodan Mitrovic, Ashkan Norouzi{-}Fard, Jakub Tarnawski, and
  Morteza Zadimoghaddam.
\newblock Fully dynamic algorithm for constrained submodular optimization.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Minoux(1978)]{Minoux78}
Michel Minoux.
\newblock Accelerated greedy algorithms for maximizing submodular set
  functions.
\newblock In \emph{Optimization Techniques}, pages 234--243, Berlin,
  Heidelberg, 1978. Springer Berlin Heidelberg.

\bibitem[Mirzasoleiman et~al.(2013)Mirzasoleiman, Karbasi, Sarkar, and
  Krause]{MirzasoleimanKSK13}
Baharan Mirzasoleiman, Amin Karbasi, Rik Sarkar, and Andreas Krause.
\newblock Distributed submodular maximization: Identifying representative
  elements in massive data.
\newblock In \emph{{NIPS}}, pages 2049--2057, 2013.

\bibitem[Mirzasoleiman et~al.(2016)Mirzasoleiman, Badanidiyuru, and
  Karbasi]{MirzasoleimanBK16}
Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, and Amin Karbasi.
\newblock Fast constrained submodular maximization: Personalized data
  summarization.
\newblock In \emph{{ICML}}, volume~48 of \emph{{JMLR} Workshop and Conference
  Proceedings}, pages 1358--1367. JMLR.org, 2016.

\bibitem[Mirzasoleiman et~al.(2020)Mirzasoleiman, Bilmes, and
  Leskovec]{MirzasoleimanBL20}
Baharan Mirzasoleiman, Jeff~A. Bilmes, and Jure Leskovec.
\newblock Coresets for data-efficient training of machine learning models.
\newblock In \emph{{ICML}}, volume 119 of \emph{Proceedings of Machine Learning
  Research}, pages 6950--6960. {PMLR}, 2020.

\bibitem[Nemhauser and Wolsey(1978)]{NemhauserW78}
George~L. Nemhauser and Laurence~A. Wolsey.
\newblock Best algorithms for approximating the maximum of a submodular set
  function.
\newblock \emph{Math. Oper. Res.}, 3\penalty0 (3):\penalty0 177--188, 1978.

\bibitem[Nemhauser et~al.(1978)Nemhauser, Wolsey, and Fisher]{NemhauserWF78}
George~L. Nemhauser, Laurence~A. Wolsey, and Marshall~L. Fisher.
\newblock An analysis of approximations for maximizing submodular set functions
  - {I}.
\newblock \emph{Math. Program.}, 14\penalty0 (1):\penalty0 265--294, 1978.

\bibitem[Schrijver(2003)]{Schrijver03}
Alexander Schrijver.
\newblock \emph{Combinatorial optimization: polyhedra and efficiency},
  volume~24.
\newblock Springer, 2003.

\bibitem[Sviridenko(2004)]{Sviridenko04}
Maxim Sviridenko.
\newblock A note on maximizing a submodular set function subject to a knapsack
  constraint.
\newblock \emph{Oper. Res. Lett.}, 32\penalty0 (1):\penalty0 41--43, 2004.

\bibitem[Tschiatschek et~al.(2014)Tschiatschek, Iyer, Wei, and
  Bilmes]{TschiatschekIWB14}
Sebastian Tschiatschek, Rishabh~K. Iyer, Haochen Wei, and Jeff~A. Bilmes.
\newblock Learning mixtures of submodular functions for image collection
  summarization.
\newblock In \emph{{NIPS}}, pages 1413--1421, 2014.

\end{thebibliography}
