\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arani et~al.(2022)Arani, Sarfraz, and Zonooz]{arani2022learning}
Arani, E., Sarfraz, F., and Zonooz, B.
\newblock Learning fast, learning slow: A general continual learning method
  based on complementary learning system.
\newblock \emph{arXiv preprint arXiv:2201.12604}, 2022.

\bibitem[Benjamin et~al.(2018)Benjamin, Rolnick, and
  Kording]{benjamin2018measuring}
Benjamin, A.~S., Rolnick, D., and Kording, K.
\newblock Measuring and regularizing networks in function space.
\newblock \emph{arXiv preprint arXiv:1805.08289}, 2018.

\bibitem[Buzzega et~al.(2020)Buzzega, Boschini, Porrello, Abati, and
  Calderara]{buzzega2020dark}
Buzzega, P., Boschini, M., Porrello, A., Abati, D., and Calderara, S.
\newblock Dark experience for general continual learning: a strong, simple
  baseline.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  15920--15930. Curran Associates, Inc., 2020.

\bibitem[Buzzega et~al.(2021)Buzzega, Boschini, Porrello, and
  Calderara]{buzzega2021rethinking}
Buzzega, P., Boschini, M., Porrello, A., and Calderara, S.
\newblock Rethinking experience replay: a bag of tricks for continual learning.
\newblock In \emph{2020 25th International Conference on Pattern Recognition
  (ICPR)}, pp.\  2180--2187. IEEE, 2021.

\bibitem[Caccia et~al.(2022)Caccia, Aljundi, Asadi, Tuytelaars, Pineau, and
  Belilovsky]{caccia2022new}
Caccia, L., Aljundi, R., Asadi, N., Tuytelaars, T., Pineau, J., and Belilovsky,
  E.
\newblock New insights on reducing abrupt representation change in online
  continual learning.
\newblock \emph{arXiv preprint arXiv:2203.03798}, 2022.

\bibitem[Cha et~al.(2021)Cha, Lee, and Shin]{cha2021co2l}
Cha, H., Lee, J., and Shin, J.
\newblock Co2l: Contrastive continual learning.
\newblock In \emph{Proceedings of the IEEE/CVF International conference on
  computer vision}, pp.\  9516--9525, 2021.

\bibitem[Chaudhry et~al.(2018)Chaudhry, Dokania, Ajanthan, and
  Torr]{chaudhry2018riemannian}
Chaudhry, A., Dokania, P.~K., Ajanthan, T., and Torr, P.~H.
\newblock Riemannian walk for incremental learning: Understanding forgetting
  and intransigence.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  532--547, 2018.

\bibitem[Chrysakis \& Moens(2023)Chrysakis and Moens]{chrysakis2023online}
Chrysakis, A. and Moens, M.-F.
\newblock Online bias correction for task-free continual learning.
\newblock In \emph{International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=18XzeuYZh_}.

\bibitem[Douillard et~al.(2022)Douillard, Ram{\'e}, Couairon, and
  Cord]{douillard2022dytox}
Douillard, A., Ram{\'e}, A., Couairon, G., and Cord, M.
\newblock Dytox: Transformers for continual learning with dynamic token
  expansion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9285--9295, 2022.

\bibitem[Farquhar \& Gal(2018)Farquhar and Gal]{farquhar2018towards}
Farquhar, S. and Gal, Y.
\newblock Towards robust evaluations of continual learning.
\newblock \emph{arXiv preprint arXiv:1805.09733}, 2018.

\bibitem[Fernando et~al.(2017)Fernando, Banarse, Blundell, Zwols, Ha, Rusu,
  Pritzel, and Wierstra]{fernando2017pathnet}
Fernando, C., Banarse, D., Blundell, C., Zwols, Y., Ha, D., Rusu, A.~A.,
  Pritzel, A., and Wierstra, D.
\newblock Pathnet: Evolution channels gradient descent in super neural
  networks.
\newblock \emph{arXiv preprint arXiv:1701.08734}, 2017.

\bibitem[Garg et~al.(2022)Garg, Saluja, Balasubramanian, Arora, Subramanian,
  and Jawahar]{garg2022multi}
Garg, P., Saluja, R., Balasubramanian, V.~N., Arora, C., Subramanian, A., and
  Jawahar, C.
\newblock Multi-domain incremental learning for semantic segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pp.\  761--771, 2022.

\bibitem[Gowda et~al.(2023)Gowda, Zonooz, and Arani]{gowda2023a}
Gowda, S., Zonooz, B., and Arani, E.
\newblock Dual cognitive architecture: Incorporating biases and multi-memory
  systems for lifelong learning.
\newblock \emph{Transactions on Machine Learning Research}, 2023.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=PEyVq0hlO3}.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International conference on machine learning}, pp.\
  1321--1330. PMLR, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hinton et~al.(2014)Hinton, Vinyals, and Dean]{hinton2014dark}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Dark knowledge.
\newblock \emph{Presented as the keynote in BayLearn}, 2\penalty0 (2), 2014.

\bibitem[Hou et~al.(2019)Hou, Pan, Loy, Wang, and Lin]{hou2019learning}
Hou, S., Pan, X., Loy, C.~C., Wang, Z., and Lin, D.
\newblock Learning a unified classifier incrementally via rebalancing.
\newblock In \emph{Proceedings of the IEEE/CVF conference on Computer Vision
  and Pattern Recognition}, pp.\  831--839, 2019.

\bibitem[Hu et~al.(2020)Hu, Zhang, Ding, and
  Zhu]{https://doi.org/10.48550/arxiv.2011.07801}
Hu, G., Zhang, W., Ding, H., and Zhu, W.
\newblock Gradient episodic memory with a soft constraint for continual
  learning, 2020.
\newblock URL \url{https://arxiv.org/abs/2011.07801}.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot,
  A., Liu, C., and Krishnan, D.
\newblock Supervised contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 18661--18673, 2020.

\bibitem[Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska,
  et~al.]{kirkpatrick2017overcoming}
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu,
  A.~A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{Proceedings of the national academy of sciences}, 114\penalty0
  (13):\penalty0 3521--3526, 2017.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Li \& Hoiem(2017)Li and Hoiem]{li2017learning}
Li, Z. and Hoiem, D.
\newblock Learning without forgetting.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 40\penalty0 (12):\penalty0 2935--2947, 2017.

\bibitem[Lv et~al.(2022)Lv, Liang, Li, Zang, Liu, Wang, and
  Liu]{lv2022causality}
Lv, F., Liang, J., Li, S., Zang, B., Liu, C.~H., Wang, Z., and Liu, D.
\newblock Causality inspired representation learning for domain generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8046--8056, 2022.

\bibitem[Masana et~al.(2022)Masana, Liu, Twardowski, Menta, Bagdanov, and
  van~de Weijer]{masana2022class}
Masana, M., Liu, X., Twardowski, B., Menta, M., Bagdanov, A.~D., and van~de
  Weijer, J.
\newblock Class-incremental learning: survey and performance evaluation on
  image classification.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2022.

\bibitem[McCloskey \& Cohen(1989)McCloskey and
  Cohen]{mccloskey1989catastrophic}
McCloskey, M. and Cohen, N.~J.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock In \emph{Psychology of learning and motivation}, volume~24, pp.\
  109--165. Elsevier, 1989.

\bibitem[Michieli \& Zanuttigh(2019)Michieli and
  Zanuttigh]{DBLP:journals/corr/abs-1911-03462}
Michieli, U. and Zanuttigh, P.
\newblock Knowledge distillation for incremental learning in semantic
  segmentation.
\newblock \emph{CoRR}, abs/1911.03462, 2019.
\newblock URL \url{http://arxiv.org/abs/1911.03462}.

\bibitem[Mirza et~al.(2022)Mirza, Masana, Possegger, and
  Bischof]{mirza2022efficient}
Mirza, M.~J., Masana, M., Possegger, H., and Bischof, H.
\newblock An efficient domain-incremental learning approach to drive in all
  weather conditions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3001--3011, 2022.

\bibitem[Murata et~al.(2020)Murata, Toyota, and Ohara]{murata2020happening}
Murata, K., Toyota, T., and Ohara, K.
\newblock What is happening inside a continual learning model? a
  representation-based evaluation of representational forgetting.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, pp.\  234--235, 2020.

\bibitem[Parisi et~al.(2019)Parisi, Kemker, Part, Kanan, and
  Wermter]{parisi2019continual}
Parisi, G.~I., Kemker, R., Part, J.~L., Kanan, C., and Wermter, S.
\newblock Continual lifelong learning with neural networks: A review.
\newblock \emph{Neural Networks}, 113:\penalty0 54--71, 2019.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and
  Wang]{peng2019moment}
Peng, X., Bai, Q., Xia, X., Huang, Z., Saenko, K., and Wang, B.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1406--1415, 2019.

\bibitem[Ratcliff(1990)]{ratcliff1990connectionist}
Ratcliff, R.
\newblock Connectionist models of recognition memory: constraints imposed by
  learning and forgetting functions.
\newblock \emph{Psychological review}, 97\penalty0 (2):\penalty0 285, 1990.

\bibitem[Rebuffi et~al.(2017)Rebuffi, Kolesnikov, Sperl, and
  Lampert]{rebuffi2017icarl}
Rebuffi, S.-A., Kolesnikov, A., Sperl, G., and Lampert, C.~H.
\newblock icarl: Incremental classifier and representation learning.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  2001--2010, 2017.

\bibitem[Riemer et~al.(2018)Riemer, Cases, Ajemian, Liu, Rish, Tu, and
  Tesauro]{riemer2018learning}
Riemer, M., Cases, I., Ajemian, R., Liu, M., Rish, I., Tu, Y., and Tesauro, G.
\newblock Learning to learn without forgetting by maximizing transfer and
  minimizing interference.
\newblock \emph{arXiv preprint arXiv:1810.11910}, 2018.

\bibitem[Rolnick et~al.(2019)Rolnick, Ahuja, Schwarz, Lillicrap, and
  Wayne]{rolnick2019experience}
Rolnick, D., Ahuja, A., Schwarz, J., Lillicrap, T., and Wayne, G.
\newblock Experience replay for continual learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Rusu et~al.(2016)Rusu, Rabinowitz, Desjardins, Soyer, Kirkpatrick,
  Kavukcuoglu, Pascanu, and Hadsell]{rusu2016progressive}
Rusu, A.~A., Rabinowitz, N.~C., Desjardins, G., Soyer, H., Kirkpatrick, J.,
  Kavukcuoglu, K., Pascanu, R., and Hadsell, R.
\newblock Progressive neural networks.
\newblock \emph{arXiv preprint arXiv:1606.04671}, 2016.

\bibitem[Saito et~al.(2018)Saito, Watanabe, Ushiku, and
  Harada]{saito2018maximum}
Saito, K., Watanabe, K., Ushiku, Y., and Harada, T.
\newblock Maximum classifier discrepancy for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3723--3732, 2018.

\bibitem[Schwarz et~al.(2018)Schwarz, Czarnecki, Luketina, Grabska-Barwinska,
  Teh, Pascanu, and Hadsell]{schwarz2018progress}
Schwarz, J., Czarnecki, W., Luketina, J., Grabska-Barwinska, A., Teh, Y.~W.,
  Pascanu, R., and Hadsell, R.
\newblock Progress \& compress: A scalable framework for continual learning.
\newblock In \emph{International conference on machine learning}, pp.\
  4528--4537. PMLR, 2018.

\bibitem[Tan et~al.(2022)Tan, Gao, Wu, Li, and Li]{tan2022hyperspherical}
Tan, C., Gao, Z., Wu, L., Li, S., and Li, S.~Z.
\newblock Hyperspherical consistency regularization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7244--7255, 2022.

\bibitem[Van~de Ven \& Tolias(2019)Van~de Ven and Tolias]{van2019three}
Van~de Ven, G.~M. and Tolias, A.~S.
\newblock Three scenarios for continual learning.
\newblock \emph{arXiv preprint arXiv:1904.07734}, 2019.

\bibitem[Vitter(1985)]{vitter1985random}
Vitter, J.~S.
\newblock Random sampling with a reservoir.
\newblock \emph{ACM Transactions on Mathematical Software (TOMS)}, 11\penalty0
  (1):\penalty0 37--57, 1985.

\bibitem[Wang et~al.(2022)Wang, Yang, Huang, Song, and
  Huang]{wang2022efficient}
Wang, C., Yang, Q., Huang, R., Song, S., and Huang, G.
\newblock Efficient knowledge distillation from model checkpoints.
\newblock \emph{arXiv preprint arXiv:2210.06458}, 2022.

\bibitem[Wu et~al.(2019)Wu, Chen, Wang, Ye, Liu, Guo, and Fu]{wu2019large}
Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., and Fu, Y.
\newblock Large scale incremental learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  374--382, 2019.

\bibitem[Xie et~al.(2022)Xie, Yan, and He]{xie2022general}
Xie, J., Yan, S., and He, X.
\newblock General incremental learning with domain-aware categorical
  representations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  14351--14360, 2022.

\bibitem[Yang et~al.(2021)Yang, Kim, and Wang]{yang2021multiple}
Yang, Y., Kim, T., and Wang, G.
\newblock Multiple classifiers based maximum classifier discrepancy for
  unsupervised domain adaptation.
\newblock \emph{arXiv preprint arXiv:2108.00610}, 2021.

\bibitem[Yu et~al.(2020)Yu, Twardowski, Liu, Herranz, Wang, Cheng, Jui, and
  Weijer]{yu2020semantic}
Yu, L., Twardowski, B., Liu, X., Herranz, L., Wang, K., Cheng, Y., Jui, S., and
  Weijer, J. v.~d.
\newblock Semantic drift compensation for class-incremental learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  6982--6991, 2020.

\bibitem[Zenke et~al.(2017)Zenke, Poole, and Ganguli]{zenke2017continual}
Zenke, F., Poole, B., and Ganguli, S.
\newblock Continual learning through synaptic intelligence.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3987--3995. PMLR, 2017.

\bibitem[Zhang et~al.(2022)Zhang, Dou, and Wu]{zhang2022feature}
Zhang, X., Dou, D., and Wu, J.
\newblock Feature forgetting in continual representation learning.
\newblock \emph{arXiv preprint arXiv:2205.13359}, 2022.

\end{thebibliography}
