\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{aytar2018playing}
Yusuf Aytar, Tobias Pfaff, David Budden, Thomas Paine, Ziyu Wang, and Nando de
  Freitas.
\newblock Playing hard exploration games by watching youtube.
\newblock In {\em NeurIPS}, 2018.

\bibitem{bambach2015lending}
Sven Bambach, Stefan Lee, David~J Crandall, and Chen Yu.
\newblock Lending a hand: Detecting hands and recognizing activities in complex
  egocentric interactions.
\newblock In {\em ICCV}, 2015.

\bibitem{batra2020rearrangement}
Dhruv Batra, Angel~X Chang, Sonia Chernova, Andrew~J Davison, Jia Deng, Vladlen
  Koltun, Sergey Levine, Jitendra Malik, Igor Mordatch, Roozbeh Mottaghi,
  et~al.
\newblock Rearrangement: A challenge for embodied ai.
\newblock {\em arXiv preprint arXiv:2011.01975}, 2020.

\bibitem{bellemare2016unifying}
Marc Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton,
  and Remi Munos.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In {\em NeurIPS}, 2016.

\bibitem{bertasius:2016}
Gedas Bertasius, Hyun~Soo Park, Stella~X. Yu, and Jianbo Shi.
\newblock First person action-object detection with egonet.
\newblock In {\em RSS}, 2017.

\bibitem{burda2018large}
Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, and
  Alexei~A Efros.
\newblock Large-scale study of curiosity-driven learning.
\newblock {\em ICLR}, 2019.

\bibitem{cao2020reconstructing}
Zhe Cao, Ilija Radosavovic, Angjoo Kanazawa, and Jitendra Malik.
\newblock Reconstructing hand-object interactions in the wild.
\newblock {\em arXiv preprint arXiv:2012.09856}, 2020.

\bibitem{carreira2017quo}
Joao Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em CVPR}, 2017.

\bibitem{chang2020semantic}
Matthew Chang, Arjun Gupta, and Saurabh Gupta.
\newblock Semantic visual navigation by watching youtube videos.
\newblock {\em NeurIPS}, 2020.

\bibitem{Chaplot2020Learning}
Devendra~Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, and Ruslan
  Salakhutdinov.
\newblock Learning to explore using active neural slam.
\newblock In {\em ICLR}, 2020.

\bibitem{chaplot2020object}
Devendra~Singh Chaplot, Dhiraj~Prakashchand Gandhi, Abhinav Gupta, and Russ~R
  Salakhutdinov.
\newblock Object goal navigation using goal-oriented semantic exploration.
\newblock {\em NeurIPS}, 2020.

\bibitem{chen2019learning}
Tao Chen, Saurabh Gupta, and Abhinav Gupta.
\newblock Learning exploration policies for navigation.
\newblock In {\em ICLR}, 2019.

\bibitem{damen2018scaling}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Sanja Fidler, Antonino
  Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett,
  Will Price, et~al.
\newblock Scaling egocentric vision: The epic-kitchens dataset.
\newblock In {\em ECCV}, 2018.
\newblock License available at:
  \url{https://github.com/epic-kitchens/epic-kitchens-55-annotations/blob/master/LICENSE.txt}.

\bibitem{damen2014you}
Dima Damen, Teesid Leelasawassuk, Osian Haines, Andrew Calway, and Walterio~W
  Mayol-Cuevas.
\newblock You-do, i-learn: Discovering task relevant objects and their modes of
  interaction from multi-user egocentric video.
\newblock In {\em BMVC}, 2014.

\bibitem{das2018embodied}
Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, and
  Dhruv Batra.
\newblock Embodied question answering.
\newblock In {\em ICCV-W}, 2018.

\bibitem{dwibedi2018learning}
Debidatta Dwibedi, Jonathan Tompson, Corey Lynch, and Pierre Sermanet.
\newblock Learning actionable representations from visual observations.
\newblock In {\em IROS}, 2018.

\bibitem{fang2019}
Kuan Fang, Alexander Toshev, Li Fei-Fei, and Silvio Savarese.
\newblock Scene memory transformer for embodied agents in long-horizon tasks.
\newblock In {\em CVPR}, 2019.

\bibitem{fang2018demo2vec}
Kuan Fang, Te-Lin Wu, Daniel Yang, Silvio Savarese, and Joseph~J Lim.
\newblock Demo2vec: Reasoning object affordances from online videos.
\newblock In {\em CVPR}, 2018.

\bibitem{feichtenhofer2019slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{nextactiveobject}
A. Furnari, S. Battiato, K. Grauman, and G.~Maria Farinella.
\newblock Next-active-object prediction from egocentric videos.
\newblock {\em JVCIR}, 2017.

\bibitem{furnari2019would}
Antonino Furnari and Giovanni~Maria Farinella.
\newblock What would you expect? anticipating egocentric actions with
  rolling-unrolling lstms and modality attention.
\newblock In {\em ICCV}, 2019.

\bibitem{gan2020threedworld}
Chuang Gan, Jeremy Schwartz, Seth Alter, Martin Schrimpf, James Traer, Julian
  De~Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano,
  et~al.
\newblock Threedworld: A platform for interactive multi-modal physical
  simulation.
\newblock {\em arXiv preprint arXiv:2007.04954}, 2020.

\bibitem{vrkitchen}
Z. Gao, R. Gong, T. Shu, X. Xie, S. Wang, and S.~C. Zhu.
\newblock Vrkitchen: an interactive 3d virtual environment for task-oriented
  learning.
\newblock {\em arXiv:1903.05757}, 2019.

\bibitem{garcia2018first}
Guillermo Garcia-Hernando, Shanxin Yuan, Seungryul Baek, and Tae-Kyun Kim.
\newblock First-person hand action benchmark with rgb-d videos and 3d hand pose
  annotations.
\newblock In {\em CVPR}, 2018.

\bibitem{gordon2018iqa}
Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter
  Fox, and Ali Farhadi.
\newblock Iqa: Visual question answering in interactive environments.
\newblock In {\em CVPR}, 2018.

\bibitem{haber2018learning}
Nick Haber, Damian Mrowca, Stephanie Wang, Li~F Fei-Fei, and Daniel~L Yamins.
\newblock Learning to play with intrinsically-motivated, self-aware agents.
\newblock In {\em NeurIPS}, 2018.

\bibitem{handa2019dexpilot}
Ankur Handa, Karl Van~Wyk, Wei Yang, Jacky Liang, Yu-Wei Chao, Qian Wan, Stan
  Birchfield, Nathan Ratliff, and Dieter Fox.
\newblock Dexpilot: Vision based teleoperation of dexterous robotic hand-arm
  system.
\newblock {\em ICRA}, 2020.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{jain2020cordial}
Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik, Aniruddha
  Kembhavi, and Alexander Schwing.
\newblock A cordial sync: Going beyond marginal policies for multi-agent
  embodied tasks.
\newblock In {\em ECCV}, 2020.

\bibitem{jain2019two}
Unnat Jain, Luca Weihs, Eric Kolve, Mohammad Rastegari, Svetlana Lazebnik, Ali
  Farhadi, Alexander~G Schwing, and Aniruddha Kembhavi.
\newblock Two body problem: Collaborative visual task completion.
\newblock In {\em CVPR}, 2019.

\bibitem{jiang2017seeing}
Hao Jiang and Kristen Grauman.
\newblock Seeing invisible poses: Estimating 3d body pose from egocentric
  video.
\newblock In {\em CVPR}, 2017.

\bibitem{kolve2017ai2}
Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro
  Herrasti, Daniel Gordon, Yuke Zhu, Abhinav Gupta, and Ali Farhadi.
\newblock Ai2-thor: An interactive 3d environment for visual ai.
\newblock {\em arXiv preprint arXiv:1712.05474}, 2017.
\newblock License available at:
  \url{https://github.com/allenai/ai2thor/blob/main/LICENSE}.

\bibitem{kumar2020learning}
Ashish Kumar, Saurabh Gupta, and Jitendra Malik.
\newblock Learning navigation subroutines from egocentric videos.
\newblock In {\em CoRL}, 2020.

\bibitem{li2018eye}
Yin Li, Miao Liu, and James~M Rehg.
\newblock In the eye of beholder: Joint learning of gaze and actions in first
  person video.
\newblock In {\em ECCV}, 2018.

\bibitem{liu2018imitation}
YuXuan Liu, Abhishek Gupta, Pieter Abbeel, and Sergey Levine.
\newblock Imitation from observation: Learning to imitate behaviors from raw
  video via context translation.
\newblock In {\em ICRA}, 2018.

\bibitem{lohmann2020learning}
Martin Lohmann, Jordi Salvador, Aniruddha Kembhavi, and Roozbeh Mottaghi.
\newblock Learning about objects by learning to interact with them.
\newblock {\em NeurIPS}, 2020.

\bibitem{lu2013story}
Zheng Lu and Kristen Grauman.
\newblock Story-driven summarization for egocentric video.
\newblock In {\em CVPR}, 2013.

\bibitem{nagarajan2019grounded}
Tushar Nagarajan, Christoph Feichtenhofer, and Kristen Grauman.
\newblock Grounded human-object interaction hotspots from video.
\newblock In {\em ICCV}, 2019.

\bibitem{nagarajan2020learning}
Tushar Nagarajan and Kristen Grauman.
\newblock Learning affordance landscapes for interaction exploration in 3d
  environments.
\newblock {\em NeurIPS}, 2020.

\bibitem{nagarajan2020ego}
Tushar Nagarajan, Yanghao Li, Christoph Feichtenhofer, and Kristen Grauman.
\newblock Ego-topo: Environment affordances from egocentric video.
\newblock In {\em CVPR}, 2020.

\bibitem{pathak2017curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In {\em ICML}, 2017.

\bibitem{pathak2019self}
Deepak Pathak, Dhiraj Gandhi, and Abhinav Gupta.
\newblock Self-supervised exploration via disagreement.
\newblock In {\em ICML}, 2019.

\bibitem{pathak2018zero}
Deepak Pathak, Parsa Mahmoudieh, Guanghao Luo, Pulkit Agrawal, Dian Chen, Yide
  Shentu, Evan Shelhamer, Jitendra Malik, Alexei~A Efros, and Trevor Darrell.
\newblock Zero-shot visual imitation.
\newblock In {\em CVPR-W}, 2018.

\bibitem{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher~D Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em EMNLP}, 2014.

\bibitem{puig2018virtualhome}
Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and
  Antonio Torralba.
\newblock Virtualhome: Simulating household activities via programs.
\newblock In {\em CVPR}, 2018.

\bibitem{qi2020learning}
William Qi, Ravi~Teja Mullapudi, Saurabh Gupta, and Deva Ramanan.
\newblock Learning to move with affordance maps.
\newblock {\em ICLR}, 2020.

\bibitem{qiu2020learning}
Y. {Qiu}, A. {Pal}, and H.~I. {Christensen}.
\newblock Learning hierarchical relationships for object-goal navigation.
\newblock In {\em CoRL}, 2020.

\bibitem{rajeswaran2017learning}
Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, Giulia Vezzani, John
  Schulman, Emanuel Todorov, and Sergey Levine.
\newblock Learning complex dexterous manipulation with deep reinforcement
  learning and demonstrations.
\newblock {\em RSS}, 2018.

\bibitem{ramakrishnan2020exploration}
Santhosh~K. Ramakrishnan, Dinesh Jayaraman, and Kristen Grauman.
\newblock An exploration of embodied visual exploration.
\newblock {\em IJCV}, 2021.

\bibitem{savinov2018episodic}
Nikolay Savinov, Anton Raichuk, Rapha{\"e}l Marinier, Damien Vincent, Marc
  Pollefeys, Timothy Lillicrap, and Sylvain Gelly.
\newblock Episodic curiosity through reachability.
\newblock {\em ICLR}, 2019.

\bibitem{savva2019habitat}
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
  Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et~al.
\newblock Habitat: A platform for embodied ai research.
\newblock In {\em ICCV}, 2019.

\bibitem{schmeckpeper2020reinforcement}
Karl Schmeckpeper, Oleh Rybkin, Kostas Daniilidis, Sergey Levine, and Chelsea
  Finn.
\newblock Reinforcement learning with videos: Combining offline observations
  with interaction.
\newblock {\em CoRL}, 2020.

\bibitem{schmeckpeper2019learning}
Karl Schmeckpeper, Annie Xie, Oleh Rybkin, Stephen Tian, Kostas Daniilidis,
  Sergey Levine, and Chelsea Finn.
\newblock Learning predictive models from observation and interaction.
\newblock {\em ECCV}, 2020.

\bibitem{sermanet2017time}
Pierre Sermanet, Corey Lynch, Jasmine Hsu, and Sergey Levine.
\newblock Time-contrastive networks: Self-supervised learning from multi-view
  observation.
\newblock In {\em CVPR-W}, 2017.

\bibitem{shan2020understanding}
Dandan Shan, Jiaqi Geng, Michelle Shu, and David~F Fouhey.
\newblock Understanding human hands in contact at internet scale.
\newblock In {\em CVPR}, 2020.

\bibitem{sharma2018multiple}
Pratyusha Sharma, Lekha Mohan, Lerrel Pinto, and Abhinav Gupta.
\newblock Multiple interactions made easy (mime): Large scale demonstrations
  data for imitation.
\newblock In {\em CoRL}, 2018.

\bibitem{shen2020igibson}
Bokui Shen, Fei Xia, Chengshu Li, Roberto Mart{\'\i}n-Mart{\'\i}n, Linxi Fan,
  Guanzhi Wang, Shyamal Buch, Claudia D'Arpino, Sanjana Srivastava, Lyne~P
  Tchapmi, et~al.
\newblock igibson, a simulation environment for interactive tasks in large
  realisticscenes.
\newblock {\em arXiv preprint arXiv:2012.02924}, 2020.

\bibitem{shridhar2020alfred}
Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han,
  Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox.
\newblock Alfred: A benchmark for interpreting grounded instructions for
  everyday tasks.
\newblock In {\em CVPR}, 2020.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{tekin2019h}
Bugra Tekin, Federica Bogo, and Marc Pollefeys.
\newblock H+ o: Unified egocentric recognition of 3d hand-object poses and
  interactions.
\newblock In {\em CVPR}, 2019.

\bibitem{wang2016temporal}
Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc
  Van~Gool.
\newblock Temporal segment networks: Towards good practices for deep action
  recognition.
\newblock In {\em ECCV}, 2016.

\bibitem{RoomR}
Luca Weihs, Matt Deitke, Aniruddha Kembhavi, and Roozbeh Mottaghi.
\newblock Visual room rearrangement.
\newblock In {\em CVPR}, 2021.

\bibitem{wijmans2019dd}
Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh,
  Manolis Savva, and Dhruv Batra.
\newblock Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion
  frames.
\newblock {\em arXiv preprint arXiv:1911.00357}, 2019.

\bibitem{wu2018learning}
Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari, and Yuandong
  Tian.
\newblock Learning and planning with a semantic model.
\newblock {\em arXiv preprint arXiv:1809.10842}, 2018.

\bibitem{yang2018visual}
Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, and Roozbeh Mottaghi.
\newblock Visual semantic navigation using scene priors.
\newblock {\em ICLR}, 2019.

\bibitem{yu2018one}
Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Tianhao Zhang, Pieter
  Abbeel, and Sergey Levine.
\newblock One-shot imitation from observing humans via domain-adaptive
  meta-learning.
\newblock {\em RSS}, 2018.

\bibitem{zhang2018deep}
Tianhao Zhang, Zoe McCarthy, Owen Jow, Dennis Lee, Xi Chen, Ken Goldberg, and
  Pieter Abbeel.
\newblock Deep imitation learning for complex manipulation tasks from virtual
  reality teleoperation.
\newblock In {\em ICRA}, 2018.

\bibitem{zhu2017visual}
Yuke Zhu, Daniel Gordon, Eric Kolve, Dieter Fox, Li Fei-Fei, Abhinav Gupta,
  Roozbeh Mottaghi, and Ali Farhadi.
\newblock Visual semantic planning using deep successor representations.
\newblock In {\em ICCV}, 2017.

\bibitem{zhu2020comprehensive}
Yi Zhu, Xinyu Li, Chunhui Liu, Mohammadreza Zolfaghari, Yuanjun Xiong, Chongruo
  Wu, Zhi Zhang, Joseph Tighe, R Manmatha, and Mu Li.
\newblock A comprehensive study of deep video action recognition.
\newblock {\em arXiv preprint arXiv:2012.06567}, 2020.

\end{thebibliography}
