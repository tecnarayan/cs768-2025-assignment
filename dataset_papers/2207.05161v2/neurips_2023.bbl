\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aggarwal et~al.(2021)Aggarwal, Sounderajah, Martin, Ting,
  Karthikesalingam, King, Ashrafian, and Darzi]{aggarwal2021diagnostic}
Ravi Aggarwal, Viknesh Sounderajah, Guy Martin, Daniel~SW Ting, Alan
  Karthikesalingam, Dominic King, Hutan Ashrafian, and Ara Darzi.
\newblock Diagnostic accuracy of deep learning in medical imaging: a systematic
  review and meta-analysis.
\newblock \emph{NPJ digital medicine}, 4\penalty0 (1):\penalty0 1--23, 2021.

\bibitem[Kim et~al.(2020)Kim, Yang, Lessmann, Ma, Sung, and
  Johnson]{kim2020can}
Alisa Kim, Y~Yang, Stefan Lessmann, Tiejun Ma, M-C Sung, and Johnnie~EV
  Johnson.
\newblock Can deep learning predict risky retail investors? a case study in
  financial risk behavior forecasting.
\newblock \emph{European Journal of Operational Research}, 283\penalty0
  (1):\penalty0 217--234, 2020.

\bibitem[Ding et~al.(2020)Ding, Wu, Sun, Guo, and Guo]{ding2020hierarchical}
Qianggang Ding, Sifan Wu, Hao Sun, Jiadong Guo, and Jian Guo.
\newblock Hierarchical multi-scale gaussian transformer for stock movement
  prediction.
\newblock In \emph{IJCAI}, pages 4640--4646, 2020.

\bibitem[Kim and Canny(2017)]{kim2017interpretable}
Jinkyu Kim and John Canny.
\newblock Interpretable learning for self-driving cars by visualizing causal
  attention.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2942--2950, 2017.

\bibitem[Sun et~al.(2021)Sun, Sun, Han, and Zhou]{han2020neuro}
Jiankai Sun, Hao Sun, Tian Han, and Bolei Zhou.
\newblock Neuro-symbolic program search for autonomous driving decision module
  design.
\newblock In Jens Kober, Fabio Ramos, and Claire Tomlin, editors,
  \emph{Proceedings of the 2020 Conference on Robot Learning}, volume 155 of
  \emph{Proceedings of Machine Learning Research}, pages 21--30. PMLR, 16--18
  Nov 2021.
\newblock URL \url{https://proceedings.mlr.press/v155/sun21a.html}.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 6405--6416, 2017.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning}, pages
  1613--1622. PMLR, 2015.

\bibitem[Graves(2011)]{graves2011practical}
Alex Graves.
\newblock Practical variational inference for neural networks.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.

\bibitem[Ghosh et~al.(2018)Ghosh, Yao, and Doshi-Velez]{ghosh2018structured}
Soumya Ghosh, Jiayu Yao, and Finale Doshi-Velez.
\newblock Structured variational learning of bayesian neural networks with
  horseshoe priors.
\newblock In \emph{International Conference on Machine Learning}, pages
  1744--1753. PMLR, 2018.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pages
  1050--1059. PMLR, 2016.

\bibitem[Malinin and Gales(2018)]{malinin2018predictive}
Andrey Malinin and Mark Gales.
\newblock Predictive uncertainty estimation via prior networks.
\newblock \emph{arXiv preprint arXiv:1802.10501}, 2018.

\bibitem[Van~Amersfoort et~al.(2020)Van~Amersfoort, Smith, Teh, and
  Gal]{van2020uncertainty}
Joost Van~Amersfoort, Lewis Smith, Yee~Whye Teh, and Yarin Gal.
\newblock Uncertainty estimation using a single deep deterministic neural
  network.
\newblock In \emph{International Conference on Machine Learning}, pages
  9690--9700. PMLR, 2020.

\bibitem[Abdar et~al.(2021{\natexlab{a}})Abdar, Pourpanah, Hussain,
  Rezazadegan, Liu, Ghavamzadeh, Fieguth, Cao, Khosravi, Acharya,
  et~al.]{abdar2021review}
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li~Liu,
  Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U~Rajendra
  Acharya, et~al.
\newblock A review of uncertainty quantification in deep learning: Techniques,
  applications and challenges.
\newblock \emph{Information Fusion}, 2021{\natexlab{a}}.

\bibitem[Ran et~al.(2022)Ran, Xu, Mei, Xu, and Liu]{ran2022detecting}
Xuming Ran, Mingkun Xu, Lingrui Mei, Qi~Xu, and Quanying Liu.
\newblock Detecting out-of-distribution samples via variational auto-encoder
  with reliable uncertainty estimation.
\newblock \emph{Neural Networks}, 145:\penalty0 199--208, 2022.

\bibitem[Tsipras et~al.(2020)Tsipras, Santurkar, Engstrom, Ilyas, and
  Madry]{tsipras2020imagenet}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Andrew Ilyas, and
  Aleksander Madry.
\newblock From imagenet to image classification: Contextualizing progress on
  benchmarks.
\newblock In \emph{International Conference on Machine Learning}, pages
  9625--9635. PMLR, 2020.

\bibitem[Kishida and Nakayama(2019)]{kishida2019empirical}
Ikki Kishida and Hideki Nakayama.
\newblock Empirical study of easy and hard examples in cnn training.
\newblock In \emph{International Conference on Neural Information Processing},
  pages 179--188. Springer, 2019.

\bibitem[Ekambaram et~al.(2017)Ekambaram, Goldgof, and
  Hall]{ekambaram2017finding}
Rajmadhan Ekambaram, Dmitry~B Goldgof, and Lawrence~O Hall.
\newblock Finding label noise examples in large scale datasets.
\newblock In \emph{2017 IEEE International Conference on Systems, Man, and
  Cybernetics (SMC)}, pages 2420--2424. IEEE, 2017.

\bibitem[Ramalho and Miranda(2020)]{ramalho2020density}
Tiago Ramalho and Miguel Miranda.
\newblock Density estimation in representation space to predict model
  uncertainty.
\newblock In \emph{International Workshop on Engineering Dependable and Secure
  Machine Learning Systems}, pages 84--96. Springer, 2020.

\bibitem[Yao et~al.(2019)Yao, Pan, Ghosh, and Doshi-Velez]{yao2019quality}
Jiayu Yao, Weiwei Pan, Soumya Ghosh, and Finale Doshi-Velez.
\newblock Quality of uncertainty quantification for bayesian neural network
  inference.
\newblock \emph{arXiv preprint arXiv:1906.09686}, 2019.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{ovadia2019can}
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, D~Sculley, Sebastian
  Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 13991--14002, 2019.

\bibitem[Foong et~al.(2019)Foong, Burt, Li, and
  Turner]{foong2019expressiveness}
Andrew~YK Foong, David~R Burt, Yingzhen Li, and Richard~E Turner.
\newblock On the expressiveness of approximate inference in bayesian neural
  networks.
\newblock \emph{arXiv preprint arXiv:1909.00719}, 2019.

\bibitem[Verdoja and Kyrki(2020)]{verdoja2020notes}
Francesco Verdoja and Ville Kyrki.
\newblock Notes on the behavior of mc dropout.
\newblock \emph{arXiv preprint arXiv:2008.02627}, 2020.

\bibitem[Vovk et~al.(2005)Vovk, Gammerman, and Shafer]{vovk2005algorithmic}
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer.
\newblock \emph{Algorithmic learning in a random world}.
\newblock Springer Science \& Business Media, 2005.

\bibitem[Kendall and Gal(2017)]{kendall2017uncertainties}
Alex Kendall and Yarin Gal.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock \emph{Advances in Neural Information Processing Systems},
  30:\penalty0 5574--5584, 2017.

\bibitem[Abdar et~al.(2021{\natexlab{b}})Abdar, Pourpanah, Hussain,
  Rezazadegan, Liu, Ghavamzadeh, Fieguth, Cao, Khosravi, Acharya, Makarenkov,
  and Nahavandi]{Abdar2021}
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li~Liu,
  Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U.~Rajendra
  Acharya, Vladimir Makarenkov, and Saeid Nahavandi.
\newblock {A review of uncertainty quantification in deep learning: Techniques,
  applications and challenges}.
\newblock \emph{Information Fusion}, 76:\penalty0 243--297, 2021{\natexlab{b}}.
\newblock ISSN 1566-2535.
\newblock \doi{10.1016/j.inffus.2021.05.008}.

\bibitem[H{\"u}llermeier and Waegeman(2021)]{Hullermeier2021}
Eyke H{\"u}llermeier and Willem Waegeman.
\newblock {Aleatoric and epistemic uncertainty in machine learning: an
  introduction to concepts and methods}.
\newblock \emph{Machine Learning 2021 110:3}, 110\penalty0 (3):\penalty0
  457--506, 2021.
\newblock ISSN 1573-0565.
\newblock \doi{10.1007/S10994-021-05946-3}.

\bibitem[Schut et~al.(2021)Schut, Key, Mc~Grath, Costabello, Sacaleanu, Gal,
  et~al.]{schut2021generating}
Lisa Schut, Oscar Key, Rory Mc~Grath, Luca Costabello, Bogdan Sacaleanu, Yarin
  Gal, et~al.
\newblock Generating interpretable counterfactual explanations by implicit
  minimisation of epistemic and aleatoric uncertainties.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1756--1764. PMLR, 2021.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018simple}
Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Ren et~al.(2019)Ren, Liu, Fertig, Snoek, Poplin, Depristo, Dillon, and
  Lakshminarayanan]{ren2019likelihood}
Jie Ren, Peter~J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo,
  Joshua Dillon, and Balaji Lakshminarayanan.
\newblock Likelihood ratios for out-of-distribution detection.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 14707--14718, 2019.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Yang et~al.(2022{\natexlab{a}})Yang, Lu, Li, Sun, Fang, Du, Li, Han,
  and Zhang]{yang2022rethinking}
Rui Yang, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han,
  and Chongjie Zhang.
\newblock Rethinking goal-conditioned supervised learning and its connection to
  offline rl.
\newblock \emph{arXiv preprint arXiv:2202.04478}, 2022{\natexlab{a}}.

\bibitem[Wen et~al.(2023)Wen, Yu, Yang, Bai, and Wang]{wen2023towards}
Xiaoyu Wen, Xudong Yu, Rui Yang, Chenjia Bai, and Zhen Wang.
\newblock Towards robust offline-to-online reinforcement learning via
  uncertainty and smoothness.
\newblock \emph{arXiv preprint arXiv:2309.16973}, 2023.

\bibitem[Yang et~al.(2022{\natexlab{b}})Yang, Bai, Ma, Wang, Zhang, and
  Han]{yang2022rorl}
Rui Yang, Chenjia Bai, Xiaoteng Ma, Zhaoran Wang, Chongjie Zhang, and Lei Han.
\newblock Rorl: Robust offline reinforcement learning via conservative
  smoothing.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 23851--23866, 2022{\natexlab{b}}.

\bibitem[Yang et~al.(2023)Yang, Yong, Ma, Hu, Zhang, and
  Zhang]{yang2023essential}
Rui Yang, Lin Yong, Xiaoteng Ma, Hao Hu, Chongjie Zhang, and Tong Zhang.
\newblock What is essential for unseen goal generalization of offline
  goal-conditioned rl?
\newblock In \emph{International Conference on Machine Learning}, pages
  39543--39571. PMLR, 2023.

\bibitem[Liu et~al.(2022)Liu, Zhang, Fu, Yang, and Wang]{liu2022learning}
Zhihan Liu, Yufeng Zhang, Zuyue Fu, Zhuoran Yang, and Zhaoran Wang.
\newblock Learning from demonstration: Provably efficient adversarial policy
  imitation with linear function approximation.
\newblock In \emph{International Conference on Machine Learning}, pages
  14094--14138. PMLR, 2022.

\bibitem[Sun et~al.(2023)Sun, H{\"u}y{\"u}k, Jarrett, and van~der
  Schaar]{sun2023accountability}
Hao Sun, Alihan H{\"u}y{\"u}k, Daniel Jarrett, and Mihaela van~der Schaar.
\newblock Accountability in offline reinforcement learning: Explaining
  decisions with a corpus of examples.
\newblock \emph{arXiv preprint arXiv:2310.07747}, 2023.

\bibitem[Ghanta et~al.(2019)Ghanta, Subramanian, Khermosh, Shah, Goldberg,
  Sundararaman, Roselli, and Talagala]{ghanta2019mpp}
Sindhu Ghanta, Sriram Subramanian, Lior Khermosh, Harshil Shah, Yakov Goldberg,
  Swaminathan Sundararaman, Drew Roselli, and Nisha Talagala.
\newblock $\{$MPP$\}$: Model performance predictor.
\newblock In \emph{2019 $\{$USENIX$\}$ Conference on Operational Machine
  Learning (OpML 19)}, pages 23--25, 2019.

\bibitem[Deng and Zheng(2021)]{deng2021labels}
Weijian Deng and Liang Zheng.
\newblock Are labels always necessary for classifier accuracy evaluation?
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 15069--15078, 2021.

\bibitem[Rasmussen(2003)]{rasmussen2003gaussian}
Carl~Edward Rasmussen.
\newblock Gaussian processes in machine learning.
\newblock In \emph{Summer school on machine learning}, pages 63--71. Springer,
  2003.

\bibitem[Balasubramanian et~al.(2014)Balasubramanian, Ho, and
  Vovk]{balasubramanian2014conformal}
Vineeth Balasubramanian, Shen-Shyang Ho, and Vladimir Vovk.
\newblock \emph{Conformal prediction for reliable machine learning: theory,
  adaptations and applications}.
\newblock Newnes, 2014.

\bibitem[Mukhoti et~al.(2021)Mukhoti, Kirsch, van Amersfoort, Torr, and
  Gal]{mukhoti2021deterministic}
Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip~HS Torr, and Yarin
  Gal.
\newblock Deterministic neural networks with appropriate inductive biases
  capture epistemic and aleatoric uncertainty.
\newblock \emph{arXiv preprint arXiv:2102.11582}, 2021.

\bibitem[Van~der Maaten and Hinton(2008)]{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9\penalty0 (11), 2008.

\bibitem[Dua and Graff(2017)]{dua2019uci}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Jarrett et~al.(2022)Jarrett, Tallec, Altch{\'e}, Mesnard, Munos, and
  Valko]{jarrett2022curiosity}
Daniel Jarrett, Corentin Tallec, Florent Altch{\'e}, Thomas Mesnard, R{\'e}mi
  Munos, and Michal Valko.
\newblock Curiosity in hindsight.
\newblock \emph{arXiv preprint arXiv:2211.10515}, 2022.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[OpenAI(2023)]{openai2023gpt}
R~OpenAI.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv}, pages 2303--08774, 2023.

\bibitem[Sun(2023{\natexlab{a}})]{sun2023offline}
Hao Sun.
\newblock Offline prompt evaluation and optimization with inverse reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2309.06553}, 2023{\natexlab{a}}.

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain,
  Fort, Ganguli, Henighan, et~al.]{bai2022training}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
  Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning
  from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022.

\bibitem[Sun(2023{\natexlab{b}})]{sun2023reinforcement}
Hao Sun.
\newblock Reinforcement learning in the era of llms: What is essential? what is
  needed? an rl perspective on rlhf, prompting, and beyond.
\newblock \emph{arXiv preprint arXiv:2310.06147}, 2023{\natexlab{b}}.

\bibitem[Crabbé et~al.(2021)Crabbé, Qian, Imrie, and van~der
  Schaar]{crabbe2021explaining}
Jonathan Crabbé, Zhaozhi Qian, Fergus Imrie, and Mihaela van~der Schaar.
\newblock Explaining latent representations with a corpus of examples.
\newblock \emph{NeurIPS 2021}, 2021.

\bibitem[Gao and Pavel(2017)]{gao2017softmax}
Bolin Gao and Lacra Pavel.
\newblock On the properties of the softmax function with application in game
  theory and reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1704.00805}, 2017.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Van~Looveren et~al.(2019)Van~Looveren, Klaise, Vacanti, Cobb,
  Scillitoe, and Samoilescu]{alibi-detect}
Arnaud Van~Looveren, Janis Klaise, Giovanni Vacanti, Oliver Cobb, Ashley
  Scillitoe, and Robert Samoilescu.
\newblock Alibi detect: Algorithms for outlier, adversarial and drift
  detection, 2019.
\newblock URL \url{https://github.com/SeldonIO/alibi-detect}.

\bibitem[Liu et~al.(2008)Liu, Ting, and Zhou]{liu2008isolation}
Fei~Tony Liu, Kai~Ming Ting, and Zhi-Hua Zhou.
\newblock Isolation forest.
\newblock In \emph{2008 eighth ieee international conference on data mining},
  pages 413--422. IEEE, 2008.

\bibitem[Sheather and Jones(1991)]{sheather1991reliable}
Simon~J Sheather and Michael~C Jones.
\newblock A reliable data-based bandwidth selection method for kernel density
  estimation.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 53\penalty0 (3):\penalty0 683--690, 1991.

\bibitem[Scott(2012)]{scott2012multivariate}
David~W Scott.
\newblock Multivariate density estimation and visualization.
\newblock In \emph{Handbook of computational statistics}, pages 549--569.
  Springer, 2012.

\bibitem[Silverman(2018)]{silverman2018density}
Bernard~W Silverman.
\newblock \emph{Density estimation for statistics and data analysis}.
\newblock Routledge, 2018.

\bibitem[Ghosh et~al.(2021)Ghosh, Liao, Ramamurthy, Navratil, Sattigeri,
  Varshney, and Zhang]{uq360-june-2021}
Soumya Ghosh, Q.~Vera Liao, Karthikeyan~Natesan Ramamurthy, Jiri Navratil,
  Prasanna Sattigeri, Kush~R. Varshney, and Yunfeng Zhang.
\newblock Uncertainty quantification 360: A holistic toolkit for quantifying
  and communicating the uncertainty of ai, 2021.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{pedregosa2011scikit}
Fabian Pedregosa, Ga{\"e}l Varoquaux, Alexandre Gramfort, Vincent Michel,
  Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
  Weiss, Vincent Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{the Journal of machine Learning research}, 12:\penalty0
  2825--2830, 2011.

\end{thebibliography}
