@article{bayati2011dynamics,
  title={The dynamics of message passing on dense graphs, with applications to compressed sensing},
  author={Bayati, Mohsen and Montanari, Andrea},
  journal={IEEE Transactions on Information Theory},
  volume={57},
  number={2},
  pages={764--785},
  year={2011},
  publisher={IEEE}
}

@book{villani2008optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric},
  volume={338},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article{peligrad2010central,
  title={Central limit theorem for Fourier transforms of stationary processes},
  author={Peligrad, Magda and Wu, Wei Biao and others},
  journal={The Annals of Probability},
  volume={38},
  number={5},
  pages={2009--2022},
  year={2010},
  publisher={Institute of Mathematical Statistics}
}

@article{rangan2019vector,
  title={Vector approximate message passing},
  author={Rangan, Sundeep and Schniter, Philip and Fletcher, Alyson K},
  journal={IEEE Transactions on Information Theory},
  volume={65},
  number={10},
  pages={6664--6684},
  year={2019},
  publisher={IEEE}
}

@article{pandit2020inference,
  title={Inference with deep generative priors in high dimensions},
  author={Pandit, Parthe and Sahraee-Ardakan, Mojtaba and Rangan, Sundeep and Schniter, Philip and Fletcher, Alyson K},
  journal={IEEE Journal on Selected Areas in Information Theory},
  year={2020},
  publisher={IEEE}
}

@article{allen2018convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  journal={arXiv preprint arXiv:1811.03962},
  year={2018}
}

@article{du2018gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  journal={arXiv preprint arXiv:1811.03804},
  year={2018}
}

@article{du2018gradient2,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@inproceedings{li2018learning,
  title={Learning overparameterized neural networks via stochastic gradient descent on structured data},
  author={Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8157--8166},
  year={2018}
}



@article{zou2020gradient,
  title={Gradient descent optimizes over-parameterized deep ReLU networks},
  author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
  journal={Machine Learning},
  volume={109},
  number={3},
  pages={467--492},
  year={2020},
  publisher={Springer}
}

@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@inproceedings{li2020gradient,
  title={Gradient descent with early stopping is provably robust to label noise for overparameterized neural networks},
  author={Li, Mingchen and Soltanolkotabi, Mahdi and Oymak, Samet},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4313--4324},
  year={2020},
  organization={PMLR}
}

@article{soltanolkotabi2018theoretical,
  title={Theoretical insights into the optimization landscape of over-parameterized shallow neural networks},
  author={Soltanolkotabi, Mahdi and Javanmard, Adel and Lee, Jason D},
  journal={IEEE Transactions on Information Theory},
  volume={65},
  number={2},
  pages={742--769},
  year={2018},
  publisher={IEEE}
}

@book{anthony2009neural,
  title={Neural network learning: Theoretical foundations},
  author={Anthony, Martin and Bartlett, Peter L},
  year={2009},
  publisher={cambridge university press}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{kalimeris2019sgd,
  title={Sgd on neural networks learns functions of increasing complexity},
  author={Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3496--3506},
  year={2019}
}

@inproceedings{oymak2019overparameterized,
  title={Overparameterized nonlinear learning: Gradient descent takes the shortest path?},
  author={Oymak, Samet and Soltanolkotabi, Mahdi},
  booktitle={International Conference on Machine Learning},
  pages={4951--4960},
  year={2019}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{DBLP:journals/corr/abs-1811-06965,
  author    = {Yanping Huang and
               Yonglong Cheng and
               Dehao Chen and
               HyoukJoong Lee and
               Jiquan Ngiam and
               Quoc V. Le and
               Zhifeng Chen},
  title     = {GPipe: Efficient Training of Giant Neural Networks using Pipeline
               Parallelism},
  journal   = {CoRR},
  volume    = {abs/1811.06965},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06965},
  archivePrefix = {arXiv},
  eprint    = {1811.06965},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-06965.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{deng2019model,
  title={A model of double descent for high-dimensional binary linear classification},
  author={Deng, Zeyu and Kammoun, Abla and Thrampoulidis, Christos},
  journal={arXiv preprint arXiv:1911.05822},
  year={2019}
}

@article{emami2020generalization,
  title={Generalization error of generalized linear models in high dimensions},
  author={Emami, Melikasadat and Sahraee-Ardakan, Mojtaba and Pandit, Parthe and Rangan, Sundeep and Fletcher, Alyson K},
  journal={arXiv preprint arXiv:2005.00180},
  year={2020}
}

@article{belkin2019two,
  title={Two models of double descent for weak features},
  author={Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
  journal={arXiv preprint arXiv:1903.07571},
  year={2019}
}

@article{nakkiran2019deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1912.02292},
  year={2019}
}

@article{liang2020just,
  title={Just interpolate: Kernel “ridgeless” regression can generalize},
  author={Liang, Tengyuan and Rakhlin, Alexander and others},
  journal={Annals of Statistics},
  volume={48},
  number={3},
  pages={1329--1347},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}

@article{dobriban2018high,
  title={High-dimensional asymptotics of prediction: Ridge regression and classification},
  author={Dobriban, Edgar and Wager, Stefan and others},
  journal={The Annals of Statistics},
  volume={46},
  number={1},
  pages={247--279},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}

@article{li2019enhanced,
  title={Enhanced convolutional neural tangent kernels},
  author={Li, Zhiyuan and Wang, Ruosong and Yu, Dingli and Du, Simon S and Hu, Wei and Salakhutdinov, Ruslan and Arora, Sanjeev},
  journal={arXiv preprint arXiv:1911.00809},
  year={2019}
}

@article{alemohammad2020recurrent,
  title={The Recurrent Neural Tangent Kernel},
  author={Alemohammad, Sina and Wang, Zichao and Balestriero, Randall and Baraniuk, Richard},
  journal={arXiv preprint arXiv:2006.10246},
  year={2020}
}

@article{yang2020tensor,
  title={Tensor Programs II: Neural Tangent Kernel for Any Architecture},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:2006.14548},
  year={2020}
}

@article{montanari2019generalization,
  title={The generalization error of max-margin linear classifiers: High-dimensional asymptotics in the overparametrized regime},
  author={Montanari, Andrea and Ruan, Feng and Sohn, Youngtak and Yan, Jun},
  journal={arXiv preprint arXiv:1911.01544},
  year={2019}
}

@article{mei2019generalization,
  title={The generalization error of random features regression: Precise asymptotics and double descent curve},
  author={Mei, Song and Montanari, Andrea},
  journal={arXiv preprint arXiv:1908.05355},
  year={2019}
}

@article{liao2020random,
  title={A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent},
  author={Liao, Zhenyu and Couillet, Romain and Mahoney, Michael W},
  journal={arXiv preprint arXiv:2006.05013},
  year={2020}
}

@article{dicker2016ridge,
  title={Ridge regression and asymptotic minimax estimation over spheres of growing dimension},
  author={Dicker, Lee H and others},
  journal={Bernoulli},
  volume={22},
  number={1},
  pages={1--37},
  year={2016},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@inproceedings{donoho2010message,
  title={Message passing algorithms for compressed sensing: I. motivation and construction},
  author={Donoho, David L and Maleki, Arian and Montanari, Andrea},
  booktitle={2010 IEEE information theory workshop on information theory (ITW 2010, Cairo)},
  pages={1--5},
  year={2010},
  organization={IEEE}
}

@inproceedings{ulyanov2018deep,
  title={Deep image prior},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9446--9454},
  year={2018}
}

@article{maleki2013asymptotic,
  title={Asymptotic analysis of complex LASSO via complex approximate message passing (CAMP)},
  author={Maleki, Arian and Anitori, Laura and Yang, Zai and Baraniuk, Richard G},
  journal={IEEE Transactions on Information Theory},
  volume={59},
  number={7},
  pages={4290--4308},
  year={2013},
  publisher={IEEE}
}

@article{starck2002deconvolution,
  title={Deconvolution in astronomy: A review},
  author={Starck, Jean-Luc and Pantin, E and Murtagh, F},
  journal={Publications of the Astronomical Society of the Pacific},
  volume={114},
  number={800},
  pages={1051},
  year={2002},
  publisher={IOP Publishing}
}

@article{treitel1982linear,
  title={Linear inverse theory and deconvolution},
  author={Treitel, Sven and Lines, LR},
  journal={Geophysics},
  volume={47},
  number={8},
  pages={1153--1159},
  year={1982},
  publisher={Society of Exploration Geophysicists}
}


@article{mueller1985source,
  title={Source pulse enhancement by deconvolution of an empirical Green's function},
  author={Mueller, Charles S},
  journal={Geophysical Research Letters},
  volume={12},
  number={1},
  pages={33--36},
  year={1985},
  publisher={Wiley Online Library}
}

@article{mcnally1999three,
  title={Three-dimensional imaging by deconvolution microscopy},
  author={McNally, James G and Karpova, Tatiana and Cooper, John and Conchello, Jos{\'e} Angel},
  journal={Methods},
  volume={19},
  number={3},
  pages={373--385},
  year={1999},
  publisher={Elsevier}
}

@article{friedrich2017fast,
  title={Fast online deconvolution of calcium imaging data},
  author={Friedrich, Johannes and Zhou, Pengcheng and Paninski, Liam},
  journal={PLoS computational biology},
  volume={13},
  number={3},
  pages={e1005423},
  year={2017},
  publisher={Public Library of Science}
}