\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2019)Alayrac, Uesato, Huang, Fawzi, Stanforth, and
  Kohli]{semi_sup_AT}
Jean-Baptiste Alayrac, Jonathan Uesato, Po-Sen Huang, Alhussein Fawzi, Robert
  Stanforth, and Pushmeet Kohli.
\newblock Are labels required for improving adversarial robustness?
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and
  Hein]{Square_Attack}
Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, and Matthias Hein.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIII}, pages 484--501.
  Springer, 2020.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and Lopez-Paz]{IRM}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Bommasani et~al.(2021)Bommasani, Hudson, Adeli, Altman, Arora, von
  Arx, Bernstein, Bohg, Bosselut, Brunskill, et~al.]{foundation_model}
Rishi Bommasani, Drew~A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney
  von Arx, Michael~S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma
  Brunskill, et~al.
\newblock On the opportunities and risks of foundation models.
\newblock \emph{arXiv preprint arXiv:2108.07258}, 2021.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{GPT3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Buch et~al.(2018)Buch, Ahmed, and Maruthappu]{medicine_application}
Varun~H Buch, Irfan Ahmed, and Mahiben Maruthappu.
\newblock Artificial intelligence in medicine: current trends and future
  possibilities.
\newblock \emph{British Journal of General Practice}, 68\penalty0
  (668):\penalty0 143--144, 2018.

\bibitem[B{\"u}hlmann(2020)]{causality_OOD_2020}
Peter B{\"u}hlmann.
\newblock Invariance, causality and robustness.
\newblock 2020.

\bibitem[Chalupka et~al.(2014)Chalupka, Perona, and
  Eberhardt]{chalupka2014visual_causasl}
Krzysztof Chalupka, Pietro Perona, and Frederick Eberhardt.
\newblock Visual causal feature learning.
\newblock \emph{arXiv preprint arXiv:1412.2309}, 2014.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{contrastive_SimCLR}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pages
  1597--1607. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{SimCLR_v2}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey~E
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 22243--22255, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2021)Chen, Xie, and He]{MoCo-v3}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9640--9649, 2021.

\bibitem[Coates et~al.(2011)Coates, Ng, and Lee]{stl10}
Adam Coates, Andrew Ng, and Honglak Lee.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 215--223. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Croce and Hein(2020{\natexlab{a}})]{AutoAttack}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{International conference on machine learning}, pages
  2206--2216. PMLR, 2020{\natexlab{a}}.

\bibitem[Croce and Hein(2020{\natexlab{b}})]{FAB}
Francesco Croce and Matthias Hein.
\newblock Minimally distorted adversarial examples with a fast adaptive
  boundary attack.
\newblock In \emph{International Conference on Machine Learning}, pages
  2196--2205. PMLR, 2020{\natexlab{b}}.

\bibitem[Croce et~al.(2020)Croce, Andriushchenko, Sehwag, Debenedetti,
  Flammarion, Chiang, Mittal, and Hein]{croce2020robustbench}
Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti,
  Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock \emph{arXiv preprint arXiv:2010.09670}, 2020.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Elizalde et~al.(2022)Elizalde, Deshmukh, Ismail, and
  Wang]{elizalde2022clap}
Benjamin Elizalde, Soham Deshmukh, Mahmoud~Al Ismail, and Huaming Wang.
\newblock Clap: Learning audio concepts from natural language supervision.
\newblock \emph{arXiv preprint arXiv:2206.04769}, 2022.

\bibitem[Erhan et~al.(2010)Erhan, Courville, Bengio, and
  Vincent]{unsupervised_pretrain}
Dumitru Erhan, Aaron Courville, Yoshua Bengio, and Pascal Vincent.
\newblock Why does unsupervised pre-training help deep learning?
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 201--208. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Fan et~al.(2021)Fan, Liu, Chen, Zhang, and
  Gan]{robpretrain_ACL_fan2021does}
Lijie Fan, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, and Chuang Gan.
\newblock When does contrastive learning preserve adversarial robustness from
  pretraining to finetuning?
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 21480--21492, 2021.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{FGSM}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In Yoshua Bengio and Yann LeCun, editors, \emph{The Third
  International Conference on Learning Representations}, 2015.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar, et~al.]{BYOL}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec, Pierre
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan
  Guo, Mohammad Gheshlaghi~Azar, et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 21271--21284, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Hendrycks and Dietterich(2019)]{corruption}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations}, 2019.

\bibitem[Ho and Nvasconcelos(2020)]{ACL_CALE}
Chih-Hui Ho and Nuno Nvasconcelos.
\newblock Contrastive learning with adversarial examples.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 17081--17093, 2020.

\bibitem[Huang et~al.()Huang, Halbe, Sankar, Amini, Kottur, Geramifard,
  Razaviyayn, and Beirami]{invariant_robustness}
Tianjian Huang, Shaunak~Ashish Halbe, Chinnadhurai Sankar, Pooyan Amini, Satwik
  Kottur, Alborz Geramifard, Meisam Razaviyayn, and Ahmad Beirami.
\newblock Robustness through data augmentation loss consistency.
\newblock \emph{Transactions on Machine Learning Research}.

\bibitem[Jiang et~al.(2020)Jiang, Chen, Chen, and
  Wang]{robpretrain_ACL_jiang2020robust}
Ziyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang Wang.
\newblock Robust pre-training by adversarial contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 16199--16210, 2020.

\bibitem[Kim et~al.(2020)Kim, Tack, and Hwang]{RoCL}
Minseon Kim, Jihoon Tack, and Sung~Ju Hwang.
\newblock Adversarial self-supervised contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2983--2994, 2020.

\bibitem[Krizhevsky(2009)]{cifar}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, 2009.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and
  Liang]{kumar2022fine_LP}
Ananya Kumar, Aditi Raghunathan, Robbie~Matthew Jones, Tengyu Ma, and Percy
  Liang.
\newblock Fine-tuning can distort pretrained features and underperform
  out-of-distribution.
\newblock In \emph{The Tenth International Conference on Learning
  Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=UYneFzXSJWh}.

\bibitem[Kurakin et~al.(2018)Kurakin, Goodfellow, and Bengio]{adv_application}
Alexey Kurakin, Ian~J Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock In \emph{Artificial intelligence safety and security}, pages 99--112.
  Chapman and Hall/CRC, 2018.

\bibitem[Le-Khac et~al.(2020)Le-Khac, Healy, and Smeaton]{contrastive_review}
Phuc~H Le-Khac, Graham Healy, and Alan~F Smeaton.
\newblock Contrastive representation learning: A framework and review.
\newblock \emph{IEEE Access}, 8:\penalty0 193907--193934, 2020.

\bibitem[Loshchilov and Hutter(2016)]{cosine_annealing}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock \emph{arXiv preprint arXiv:1608.03983}, 2016.

\bibitem[Luo et~al.(2023)Luo, Wang, and Wang]{DynACL_iclr2023}
Rundong Luo, Yifei Wang, and Yisen Wang.
\newblock Rethinking the effect of data augmentation in adversarial contrastive
  learning.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=0qmwFNJyxCL}.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{standard_adversarial_training}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Mitrovic et~al.(2021)Mitrovic, McWilliams, Walker, Buesing, and
  Blundell]{contrastive_invariant_iclr2021}
Jovana Mitrovic, Brian McWilliams, Jacob~C Walker, Lars~Holger Buesing, and
  Charles Blundell.
\newblock Representation learning via invariant causal mechanisms.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=9p2ekP904Rs}.

\bibitem[Pearl(2009)]{pearl2009causality_book}
Judea Pearl.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017causality_book}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem[Ridnik et~al.(2021)Ridnik, Ben-Baruch, Noy, and
  Zelnik-Manor]{imagenet-21k}
Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, and Lihi Zelnik-Manor.
\newblock Imagenet-21k pretraining for the masses.
\newblock \emph{arXiv preprint arXiv:2104.10972}, 2021.

\bibitem[Robinson et~al.(2020)Robinson, Chuang, Sra, and Jegelka]{HCL}
Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, and Stefanie Jegelka.
\newblock Contrastive learning with hard negative samples.
\newblock \emph{arXiv preprint arXiv:2010.04592}, 2020.

\bibitem[Sauer and Geiger(2021)]{sauer2021_causal_counterfactual}
Axel Sauer and Andreas Geiger.
\newblock Counterfactual generative networks.
\newblock \emph{arXiv preprint arXiv:2101.06046}, 2021.

\bibitem[Tang et~al.(2020)Tang, Huang, and Zhang]{tang2020causal_longtail}
Kaihua Tang, Jianqiang Huang, and Hanwang Zhang.
\newblock Long-tailed classification by keeping the good and removing the bad
  momentum causal effect.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1513--1524, 2020.

\bibitem[Wang et~al.(2022)Wang, Yi, Chen, and Zhu]{invariant_OOD}
Ruoyu Wang, Mingyang Yi, Zhitang Chen, and Shengyu Zhu.
\newblock Out-of-distribution generalization with causal invariant
  transformations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 375--385, 2022.

\bibitem[Xie et~al.(2020)Xie, Tan, Gong, Wang, Yuille, and Le]{AT_dual_BN}
Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan~L Yuille, and Quoc~V
  Le.
\newblock Adversarial examples improve image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 819--828, 2020.

\bibitem[Xu et~al.(2023{\natexlab{a}})Xu, Zhang, and
  Kankanhalli]{xu2023autolora}
Xilie Xu, Jingfeng Zhang, and Mohan Kankanhalli.
\newblock Autolora: A parameter-free automated robust fine-tuning framework.
\newblock \emph{arXiv preprint arXiv:2310.01818}, 2023{\natexlab{a}}.

\bibitem[Xu et~al.(2023{\natexlab{b}})Xu, Zhang, Liu, Sugiyama, and
  Kankanhalli]{Efficient_ACL_RCS}
Xilie Xu, Jingfeng Zhang, Feng Liu, Masashi Sugiyama, and Mohan Kankanhalli.
\newblock Efficient adversarial contrastive learning via robustness-aware
  coreset selection.
\newblock In \emph{NeurIPS}, 2023{\natexlab{b}}.

\bibitem[Yu et~al.(2022)Yu, Lou, Zhan, Li, Zuo, Liu, and Liu]{ACL_InfoNCE}
Qiying Yu, Jieming Lou, Xianyuan Zhan, Qizhang Li, Wangmeng Zuo, Yang Liu, and
  Jingjing Liu.
\newblock Adversarial contrastive learning via asymmetric infonce.
\newblock In \emph{European Conference on Computer Vision}, pages 53--69.
  Springer, 2022.

\bibitem[Zagoruyko and Komodakis(2016)]{wideresnet}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zhang et~al.(2022{\natexlab{a}})Zhang, Zhang, Zhang, Niu, Feng, Yoo,
  and Kweon]{DeACL}
Chaoning Zhang, Kang Zhang, Chenshuang Zhang, Axi Niu, Jiu Feng, Chang~D Yoo,
  and In~So Kweon.
\newblock Decoupled adversarial contrastive learning for self-supervised
  adversarial robustness.
\newblock In \emph{European Conference on Computer Vision}, pages 725--742.
  Springer, 2022{\natexlab{a}}.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Zhang, and
  Li]{zhang2020causal_robustness}
Cheng Zhang, Kun Zhang, and Yingzhen Li.
\newblock A causal view on robustness of neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 289--301, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and Jordan]{trades}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric~P. Xing, Laurent~El Ghaoui, and
  Michael~I. Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{ICML}, 2019.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Xu, Han, Niu, Cui, Sugiyama,
  and Kankanhalli]{FAT}
Jingfeng Zhang, Xilie Xu, Bo~Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, and
  Mohan~S. Kankanhalli.
\newblock Attacks which do not kill training make adversarial learning
  stronger.
\newblock In \emph{International Conference on Machine Learning}, pages
  11278--11287. {PMLR}, 2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2022{\natexlab{b}})Zhang, Gong, Liu, Niu, Tian, Han,
  Sch{\"o}lkopf, and Zhang]{causal_adv_iclr_2022}
Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo~Han,
  Bernhard Sch{\"o}lkopf, and Kun Zhang.
\newblock Adversarial robustness through the lens of causality.
\newblock In \emph{International Conference on Learning Representations},
  2022{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=cZAi1yWpiXQ}.

\end{thebibliography}
