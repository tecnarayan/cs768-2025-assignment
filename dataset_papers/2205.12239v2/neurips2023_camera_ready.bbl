\begin{thebibliography}{10}

\bibitem{smith2005development}
Linda Smith and Michael Gasser.
\newblock The development of embodied cognition: Six lessons from babies.
\newblock {\em Artificial life}, 11(1-2):13--29, 2005.

\bibitem{gacs1973common}
Peter G{\'a}cs and J{\'a}nos K{\"o}rner.
\newblock Common information is far less than mutual information.
\newblock {\em Problems of Control and Information Theory}, 2(2):149--162,
  1973.

\bibitem{wolf2004zero}
Stefan Wolf and J~Wultschleger.
\newblock Zero-error information and applications in cryptography.
\newblock In {\em Information Theory Workshop}, pages 1--6. IEEE, 2004.

\bibitem{salamatian2020approximate}
S.~{Salamatian}, A.~{Cohen}, and M.~{Médard}.
\newblock Approximate gács-körner common information.
\newblock In {\em 2020 IEEE International Symposium on Information Theory
  (ISIT)}, pages 2234--2239, 2020.

\bibitem{dsprites17}
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.
\newblock dsprites: Disentanglement testing sprites dataset.
\newblock https://github.com/deepmind/dsprites-dataset/, 2017.

\bibitem{3dshapes18}
Chris Burgess and Hyunjik Kim.
\newblock 3d shapes dataset.
\newblock https://github.com/deepmind/3dshapes-dataset/, 2018.

\bibitem{tian2020contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock In {\em European conference on computer vision}, pages 776--794.
  Springer, 2020.

\bibitem{held1963movement}
Richard Held and Alan Hein.
\newblock Movement-produced stimulation in the development of visually guided
  behavior.
\newblock {\em Journal of comparative and physiological psychology}, 56(5):872,
  1963.

\bibitem{kingma2014autoencoding}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{tishby99information}
Naftali Tishby, Fernando~C. Pereira, and William Bialek.
\newblock The information bottleneck method.
\newblock In {\em Proc. of the 37-th Annual Allerton Conference on
  Communication, Control and Computing}, pages 368--377, 1999.

\bibitem{achille2018emergence}
Alessandro Achille and Stefano Soatto.
\newblock Emergence of invariance and disentanglement in deep representations.
\newblock {\em Journal of Machine Learning Research}, 19(50):1--34, 2018.

\bibitem{alemi2018fixing}
Alexander Alemi, Ben Poole, Ian Fischer, Joshua Dillon, Rif~A Saurous, and
  Kevin Murphy.
\newblock Fixing a broken elbo.
\newblock In {\em International Conference on Machine Learning}, pages
  159--168. PMLR, 2018.

\bibitem{achille2018information}
Alessandro Achille and Stefano Soatto.
\newblock Information dropout: Learning optimal representations through noisy
  computation.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  40(12):2897--2905, 2018.

\bibitem{higgins2017beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  35(8):1798--1828, 2013.

\bibitem{burgess2018understanding}
Christopher~P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters,
  Guillaume Desjardins, and Alexander Lerchner.
\newblock Understanding disentangling in $\beta $-vae.
\newblock {\em arXiv preprint arXiv:1804.03599}, 2018.

\bibitem{chen2018isolating}
Ricky T.~Q. Chen, Xuechen Li, Roger Grosse, and David Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{locatello2019challenging}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In {\em international conference on machine learning}, pages
  4114--4124. PMLR, 2019.

\bibitem{locatello2020weakly}
Francesco Locatello, Ben Poole, Gunnar R{\"a}tsch, Bernhard Sch{\"o}lkopf,
  Olivier Bachem, and Michael Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In {\em International Conference on Machine Learning}, pages
  6348--6359. PMLR, 2020.

\bibitem{paninski2003samples}
Liam Paninski.
\newblock Estimation of entropy and mutual information.
\newblock {\em Neural Comput.}, 15(6):1191–1253, June 2003.

\bibitem{shwartz17opening}
Ravid Shwartz{-}Ziv and Naftali Tishby.
\newblock Opening the black box of deep neural networks via information.
\newblock {\em CoRR}, abs/1703.00810, 2017.

\bibitem{saxe2018information}
Andrew~Michael Saxe, Yamini Bansal, Joel Dapello, Madhu Advani, Artemy
  Kolchinsky, Brendan~Daniel Tracey, and David~Daniel Cox.
\newblock On the information bottleneck theory of deep learning.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{goldfeld2019estimating}
Ziv Goldfeld, Ewout Van Den~Berg, Kristjan Greenewald, Igor Melnyk, Nam Nguyen,
  Brian Kingsbury, and Yury Polyanskiy.
\newblock Estimating information flow in deep neural networks.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning}, volume~97 of {\em Proceedings of Machine Learning Research}, pages
  2299--2308. PMLR, 09--15 Jun 2019.

\bibitem{kraskov2004estimating}
Alexander Kraskov, Harald St{\"o}gbauer, and Peter Grassberger.
\newblock Estimating mutual information.
\newblock {\em Physical review E}, 69(6):066138, 2004.

\bibitem{Xu2020theory}
Yilun Xu, Shengjia Zhao, Jiaming Song, Russell Stewart, and Stefano Ermon.
\newblock A theory of usable information under computational constraints.
\newblock In {\em 8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\bibitem{kleinman2020usable}
Michael Kleinman, Alessandro Achille, Daksh Idnani, and Jonathan Kao.
\newblock Usable information and evolution of optimal representations during
  training.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{barber2003variational}
David Barber and Felix Agakov.
\newblock The im algorithm: A variational approach to information maximization.
\newblock In {\em Proceedings of the 16th International Conference on Neural
  Information Processing Systems}, NIPS’03, page 201–208, Cambridge, MA,
  USA, 2003. MIT Press.

\bibitem{poole19variational}
Ben Poole, Sherjil Ozair, Aaron Van Den~Oord, Alex Alemi, and George Tucker.
\newblock On variational bounds of mutual information.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of {\em Proceedings of Machine Learning Research}, pages
  5171--5180, Long Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem{tian2020makes}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and
  Phillip Isola.
\newblock What makes for good views for contrastive learning?
\newblock {\em Advances in Neural Information Processing Systems},
  33:6827--6839, 2020.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{federici2020learning}
Marco Federici, Anjan Dutta, Patrick Forré, Nate Kushman, and Zeynep Akata.
\newblock Learning robust representations via multi-view information
  bottleneck.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{wang2016deep}
Weiran Wang, Xinchen Yan, Honglak Lee, and Karen Livescu.
\newblock Deep variational canonical correlation analysis.
\newblock {\em arXiv preprint arXiv:1610.03454}, 2016.

\bibitem{kingma2016improved}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock {\em Advances in neural information processing systems},
  29:4743--4751, 2016.

\bibitem{li2018disentangled}
Li~Yingzhen and Stephan Mandt.
\newblock Disentangled sequential autoencoder.
\newblock In Jennifer Dy and Andreas Krause, editors, {\em Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of {\em
  Proceedings of Machine Learning Research}, pages 5670--5679. PMLR, 10--15 Jul
  2018.

\bibitem{eastwood2018framework}
Cian Eastwood and Christopher K.~I. Williams.
\newblock A framework for the quantitative evaluation of disentangled
  representations.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{dubois2020learning}
Yann Dubois, Douwe Kiela, David~J Schwab, and Ramakrishna Vedantam.
\newblock Learning optimal representations with the decodable information
  bottleneck.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 18674--18690. Curran Associates, Inc., 2020.

\bibitem{wang2022rethinking}
Haoqing Wang, Xun Guo, Zhi-Hong Deng, and Yan Lu.
\newblock Rethinking minimal sufficient representation in contrastive learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16041--16050, 2022.

\bibitem{salamatian2016maximum}
Salman Salamatian, Asaf Cohen, and Muriel M{\'e}dard.
\newblock Maximum entropy functions: Approximate gacs-korner for distributed
  compression.
\newblock {\em arXiv preprint arXiv:1604.03877}, 2016.

\bibitem{townsend2019practical}
James Townsend, Thomas Bird, and David Barber.
\newblock Practical lossless compression with latent variables using bits back
  coding.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{dubois2019dvae}
Yann Dubois, Alexandros Kastanos, Dave Lines, and Bart Melman.
\newblock Disentangling vae.
\newblock \url{http://github.com/YannDubs/disentangling-vae/}, march 2019.

\bibitem{wang2015multi}
Weiran Wang, Raman Arora, Karen Livescu, and Jeff Bilmes.
\newblock On deep multi-view representation learning.
\newblock In {\em Proceedings of the 32nd International Conference on
  International Conference on Machine Learning - Volume 37}, ICML'15, page
  1083–1092. JMLR.org, 2015.

\bibitem{williams2010nonnegative}
Paul~L Williams and Randall~D Beer.
\newblock Nonnegative decomposition of multivariate information.
\newblock {\em arXiv preprint arXiv:1004.2515}, 2010.

\bibitem{kolchinsky2022novel}
Artemy Kolchinsky.
\newblock A novel approach to the partial information decomposition.
\newblock {\em Entropy}, 24(3):403, 2022.

\bibitem{kleinman2021redundant}
Michael Kleinman, Alessandro Achille, Stefano Soatto, and Jonathan~C. Kao.
\newblock Redundant information neural estimation.
\newblock {\em Entropy}, 23(7), 2021.

\bibitem{bouchacourt2018multi}
Diane Bouchacourt, Ryota Tomioka, and Sebastian Nowozin.
\newblock Multi-level variational autoencoder: Learning disentangled
  representations from grouped observations.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem{jha2018disentangling}
Ananya~Harsh Jha, Saket Anand, Maneesh Singh, and VS~Rao Veeravasarapu.
\newblock Disentangling factors of variation with cycle-consistent variational
  auto-encoders.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 805--820, 2018.

\bibitem{vowels2020nestedvae}
Matthew~J Vowels, Necati~Cihan Camgoz, and Richard Bowden.
\newblock Nestedvae: Isolating common factors via weak supervision.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9202--9212, 2020.

\bibitem{sanchez2020learning}
Eduardo~Hugo Sanchez, Mathieu Serrurier, and Mathias Ortner.
\newblock Learning disentangled representations via mutual information
  estimation.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm,
  editors, {\em Computer Vision -- ECCV 2020}, pages 205--221, Cham, 2020.
  Springer International Publishing.

\end{thebibliography}
