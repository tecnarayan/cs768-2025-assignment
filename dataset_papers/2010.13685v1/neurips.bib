
@inproceedings{off-policy,
 author = {Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
 title = {Eligibility Traces for Off-Policy Policy Evaluation},
 booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
 series = {ICML '00},
 year = {2000},
 isbn = {1-55860-707-2},
 pages = {759--766},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645529.658134},
 acmid = {658134},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Ayoub,
  title = {Model-Based Reinforcement Learning with Value-Targeted Regression},
  author = {Alex Ayoub and Zeyu Jia and Csaba Szepesv\'ari and Mengdi Wang and Lin Yang},
  year = {2020},
  Month = {June},
  booktitle = {ICML},
  url_Paper = {ICML2020_UCRL_VTR.pdf},
}


@article{dayan,
  author    = {Peter Dayan},
  title     = {Improving Generalization for Temporal Difference Learning: The Successor
              Representation},
  journal   = {Neural Computation},
  volume    = {5},
  number    = {4},
  pages     = {613--624},
  year      = {1993},
  url       = {https://doi.org/10.1162/neco.1993.5.4.613},
  doi       = {10.1162/neco.1993.5.4.613},
  timestamp = {Sun, 28 May 2017 13:19:02 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/neco/Dayan93a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{TD,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@inproceedings{option_models,
  author    = {Doina Precup and
              Richard S. Sutton and
              Satinder P. Singh},
  title     = {Theoretical Results on Reinforcement Learning with Temporally Abstract
              Options},
  booktitle = {Machine Learning: ECML-98, 10th European Conference on Machine Learning,
              Chemnitz, Germany, April 21-23, 1998, Proceedings},
  pages     = {382--393},
  year      = {1998},
}

@inproceedings{TD_models,
  author    = {Richard S. Sutton},
  title     = {{TD} Models: Modeling the World at a Mixture of Time Scales},
  booktitle = {Machine Learning, Proceedings of the Twelfth International Conference
              on Machine Learning, Tahoe City, California, USA, July 9-12, 1995},
  pages     = {531--539},
  year      = {1995},
}

@inproceedings{compositional_planning,
  author    = {David Silver and
              Kamil Ciosek},
  title     = {Compositional Planning Using Optimal Option Models},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning,
              {ICML} 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012},
  year      = {2012},
  crossref  = {DBLP:conf/icml/2012},
  url       = {http://icml.cc/2012/papers/564.pdf},
  timestamp = {Wed, 29 Mar 2017 16:45:25 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icml/SilverC12},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{universal_option_models,
  author    = {Hengshuai Yao and
              Csaba Szepesv{\'{a}}ri and
              Richard S. Sutton and
              Joseph Modayil and
              Shalabh Bhatnagar},
  title     = {Universal Option Models},
  booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
              on Neural Information Processing Systems 2014, December 8-13 2014,
              Montreal, Quebec, Canada},
  pages     = {990--998},
  year      = {2014},
}

@article{temporal_abstraction,
 author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
 title = {Between MDPs and semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning},
 journal = {Artif. Intell.},
 issue_date = {Aug. 1999},
 volume = {112},
 number = {1-2},
 month = aug,
 year = {1999},
 issn = {0004-3702},
 pages = {181--211},
 numpages = {31},
 url = {http://dx.doi.org/10.1016/S0004-3702(99)00052-1},
 doi = {10.1016/S0004-3702(99)00052-1},
 acmid = {319108},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
 keywords = {Markov decision processes, hierarchical planning, intra-options learning, macroactions, macros, options, reinforcement learning, semi-Markov decision processes, subgoals, temporal abstraction},
} 
@inproceedings{horde,
  author    = {Richard S. Sutton and
              Joseph Modayil and
              Michael Delp and
              Thomas Degris and
              Patrick M. Pilarski and
              Adam White and
              Doina Precup},
  title     = {Horde: a scalable real-time architecture for learning knowledge from
              unsupervised sensorimotor interaction},
  booktitle = {10th International Conference on Autonomous Agents and Multiagent
              Systems {(AAMAS} 2011), Taipei, Taiwan, May 2-6, 2011, Volume 1-3},
  pages     = {761--768},
  year      = {2011},
}

@incollection{Barreto_linear,
title = {Successor Features for Transfer in Reinforcement Learning},
author = {Barreto, Andre and Dabney, Will and Munos, Remi and Hunt, Jonathan J and Schaul, Tom and {van Hasselt}, Hado P and Silver, David},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4055--4065},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6994-successor-features-for-transfer-in-reinforcement-learning.pdf}
}

@inproceedings{Mann2014,
 author = {Mann, Timothy A. and Mannor, Shie},
 title = {Scaling Up Approximate Value Iteration with Options: Better Policies with Fewer Iterations},
 booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
 series = {ICML'14},
 year = {2014},
 location = {Beijing, China},
 pages = {I-127--I-135},
 url = {http://dl.acm.org/citation.cfm?id=3044805.3044821},
 acmid = {3044821},
 publisher = {JMLR.org},
} 

@inproceedings{linear_options,
 author = {Sorg, Jonathan and Singh, Satinder},
 title = {Linear Options},
 booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: Volume 1 - Volume 1},
 series = {AAMAS '10},
 year = {2010},
 isbn = {978-0-9826571-1-9},
 location = {Toronto, Canada},
 pages = {31--38},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1838206.1838211},
 acmid = {1838211},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 address = {Richland, SC},
 keywords = {reinforcement learning, temporal abstraction},
} 
@article{linear_dyna,
  author    = {Richard S. Sutton and
              Csaba Szepesv{\'{a}}ri and
              Alborz Geramifard and
              Michael Bowling},
  title     = {Dyna-Style Planning with Linear Function Approximation and Prioritized
              Sweeping},
  journal   = {CoRR},
  volume    = {abs/1206.3285},
  year      = {2012},
  url       = {http://arxiv.org/abs/1206.3285},
  archivePrefix = {arXiv},
  eprint    = {1206.3285},
  timestamp = {Mon, 13 Aug 2018 16:46:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1206-3285},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{LSTD,
 author = {Bradtke, Steven J. and Barto, Andrew G.},
 title = {Linear Least-squares Algorithms for Temporal Difference Learning},
 journal = {Mach. Learn.},
 issue_date = {Jan./Feb./March 1996},
 volume = {22},
 number = {1-3},
 month = jan,
 year = {1996},
 issn = {0885-6125},
 pages = {33--57},
 numpages = {25},
 url = {http://dx.doi.org/10.1007/BF00114723},
 doi = {10.1007/BF00114723},
 acmid = {225673},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Markov decision problems, least-squares, reinforcement learning, temporal difference methods},
} 

@article{planning_expectation,
  author    = {Yi Wan and
              Muhammad Zaheer and
              Adam White and
              Martha White and
              Richard S. Sutton},
  title     = {Planning with Expectation Models},
  journal   = {CoRR},
  volume    = {abs/1904.01191},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.01191},
  archivePrefix = {arXiv},
  eprint    = {1904.01191},
  timestamp = {Wed, 24 Apr 2019 12:21:25 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-01191},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Harm,
 author = {Van Seijen, Harm and Sutton, Richard S.},
 title = {A Deeper Look at Planning As Learning from Replay},
 booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
 location = {Lille, France},
 pages = {2314--2322},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=3045118.3045364},
 acmid = {3045364},
 publisher = {JMLR.org},
}

@INPROCEEDINGS{dyna,
    author = {Richard S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {In Proceedings of the Seventh International Conference on Machine Learning},
    year = {1990},
    pages = {216--224},
    publisher = {Morgan Kaufmann}
}
@inproceedings{Parr,
 author = {Parr, Ronald and Li, Lihong and Taylor, Gavin and Painter-Wakefield, Christopher and Littman, Michael L.},
 title = {An Analysis of Linear Models, Linear Value-function Approximation, and Feature Selection for Reinforcement Learning},
 booktitle = {Proceedings of the 25th International Conference on Machine Learning},
 series = {ICML '08},
 year = {2008},
 isbn = {978-1-60558-205-4},
 location = {Helsinki, Finland},
 pages = {752--759},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1390156.1390251},
 doi = {10.1145/1390156.1390251},
 acmid = {1390251},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@inproceedings{Jong,
 author = {Jong, Nicholas K. and Hester, Todd and Stone, Peter},
 title = {The Utility of Temporal Abstraction in Reinforcement Learning},
 booktitle = {Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 1},
 series = {AAMAS '08},
 year = {2008},
 isbn = {978-0-9817381-0-9},
 location = {Estoril, Portugal},
 pages = {299--306},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1402383.1402429},
 acmid = {1402429},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 address = {Richland, SC},
 keywords = {reinforcement learning, temporal abstraction},
}

@article{LSPI,
 author = {Lagoudakis, Michail G. and Parr, Ronald},
 title = {Least-squares Policy Iteration},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2003},
 volume = {4},
 month = dec,
 year = {2003},
 issn = {1532-4435},
 pages = {1107--1149},
 numpages = {43},
 url = {http://dl.acm.org/citation.cfm?id=945365.964290},
 acmid = {964290},
 publisher = {JMLR.org},
} 


@Book{puterman,
  author =       "Puterman, Martin L.",
  title =        "Markov Decision Processes",
  publisher =    "Wiley",
  year =         "1994",
  ISBN =         "978-0471727828",
  url = "http://books.google.com/books/about/Markov_decision_processes.html?id=Y-gmAQAAIAAJ",
  bib2html_rescat = "General RL",
}


@book{rl_book,
title={Reinforcement learning: An introduction},
author={Sutton, Richard S and Barto, Andrew G},
year={2018},
publisher={MIT press}
}

@article{Bellman,
  author    = {Richard Bellman},
  title     = {Dynamic Programming and Stochastic Control Processes},
  journal   = {Information and Control},
  volume    = {1},
  number    = {3},
  pages     = {228--239},
  year      = {1958},
  url       = {https://doi.org/10.1016/S0019-9958(58)80003-0},
  doi       = {10.1016/S0019-9958(58)80003-0},
  timestamp = {Thu, 18 May 2017 09:54:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/iandc/Bellman58},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{GTD,
 author = {Sutton, Richard S. and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv\'{a}ri, Csaba and Wiewiora, Eric},
 title = {Fast Gradient-descent Methods for Temporal-difference Learning with Linear Function Approximation},
 booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
 series = {ICML '09},
 year = {2009},
 isbn = {978-1-60558-516-1},
 location = {Montreal, Quebec, Canada},
 pages = {993--1000},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1553374.1553501},
 doi = {10.1145/1553374.1553501},
 acmid = {1553501},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{morimura,
author = {Morimura, Tetsuro and Uchibe, Eiji and Yoshimoto, Junichiro and Peters, Jan and Doya, Kenji},
title = {Derivatives of Logarithmic Stationary Distributions for Policy Gradient Reinforcement Learning},
year = {2010},
issue_date = {February 2010},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {22},
number = {2},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.2009.12-08-922},
doi = {10.1162/neco.2009.12-08-922},
journal = {Neural Comput.},
month = feb,
pages = {342–376},
numpages = {35}
}

@book{mackay,
author = {MacKay, David J. C.},
title = {Information Theory, Inference \& Learning Algorithms},
year = {2002},
isbn = {0521642981},
publisher = {Cambridge University Press},
address = {USA}
}

@article{hado_models,
  author    = {Hado {van Hasselt} and
               Matteo Hessel and
               John Aslanides},
  title     = {When to use parametric models in reinforcement learning?},
  journal   = {CoRR},
  volume    = {abs/1906.05243},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.05243},
  archivePrefix = {arXiv},
  eprint    = {1906.05243},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-05243.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{prioritized_sweeping_MA,
  author    = {Andrew W. Moore and
               Christopher G. Atkeson},
  title     = {Prioritized Sweeping: Reinforcement Learning With Less Data and Less
               Time},
  journal   = {Mach. Learn.},
  volume    = {13},
  pages     = {103--130},
  year      = {1993},
  url       = {https://doi.org/10.1007/BF00993104},
  doi       = {10.1007/BF00993104},
  timestamp = {Mon, 02 Mar 2020 16:28:44 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/MooreA93.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DynaQ,
author = { Jing Peng and Ronald J. Williams},
title ={Efficient Learning and Planning Within the Dyna Framework},
journal = {Adaptive Behavior},
volume = {1},
number = {4},
pages = {437-454},
year = {1993},
doi = {10.1177/105971239300100403},

URL = { 
        https://doi.org/10.1177/105971239300100403
    
},
eprint = { 
        https://doi.org/10.1177/105971239300100403
    
}
,
    abstract = { Sutton's Dyna framework provides a novel and computationally appealing way to integrate learning, planning, and reacting in autonomous agents. Examined here is a class of strategies designed to enhance the learning and planning power of Dyna systems by increasing their computational efficiency. The benefit of using these strategies is demonstrated on some simple abstract learning tasks. }
}

@inproceedings{prioritized_sweeping_MG,
  author    = {H. Brendan McMahan and
               Geoffrey J. Gordon},
  editor    = {Susanne Biundo and
               Karen L. Myers and
               Kanna Rajan},
  title     = {Fast Exact Planning in Markov Decision Processes},
  booktitle = {Proceedings of the Fifteenth International Conference on Automated
               Planning and Scheduling {(ICAPS} 2005), June 5-10 2005, Monterey,
               California, {USA}},
  pages     = {151--160},
  publisher = {{AAAI}},
  year      = {2005},
  url       = {http://www.aaai.org/Library/ICAPS/2005/icaps05-016.php},
  timestamp = {Thu, 13 Dec 2012 14:15:16 +0100},
  biburl    = {https://dblp.org/rec/conf/aips/McMahanG05.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{organizing_experience,
  author    = {Yangchen Pan and
               Muhammad Zaheer and
               Adam White and
               Andrew Patterson and
               Martha White},
  title     = {Organizing Experience: {A} Deeper Look at Replay Mechanisms for Sample-based
               Planning in Continuous State Domains},
  journal   = {CoRR},
  volume    = {abs/1806.04624},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.04624},
  archivePrefix = {arXiv},
  eprint    = {1806.04624},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-04624.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{source_traces,
  author    = {Silviu Pitis},
  title     = {Source Traces for Temporal Difference Learning},
  journal   = {CoRR},
  volume    = {abs/1902.02907},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.02907},
  archivePrefix = {arXiv},
  eprint    = {1902.02907},
  timestamp = {Tue, 21 May 2019 18:03:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-02907.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{MCTS,
  author    = {R{\'{e}}mi Coulom},
  editor    = {H. Jaap van den Herik and
               Paolo Ciancarini and
               H. H. L. M. Donkers},
  title     = {Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search},
  booktitle = {Computers and Games, 5th International Conference, {CG} 2006, Turin,
               Italy, May 29-31, 2006. Revised Papers},
  series    = {Lecture Notes in Computer Science},
  volume    = {4630},
  pages     = {72--83},
  publisher = {Springer},
  year      = {2006},
  url       = {https://doi.org/10.1007/978-3-540-75538-8\_7},
  doi       = {10.1007/978-3-540-75538-8\_7},
  timestamp = {Fri, 27 Mar 2020 08:58:14 +0100},
  biburl    = {https://dblp.org/rec/conf/cg/Coulom06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{chen_2005, place={Cambridge}, series={Cambridge Monographs on Applied and Computational Mathematics}, title={Matrix Preconditioning Techniques and Applications}, DOI={10.1017/CBO9780511543258}, publisher={Cambridge University Press}, author={Chen, Ke}, year={2005}, collection={Cambridge Monographs on Applied and Computational Mathematics}}

@inproceedings{hindsight_credit_assignment,
  author    = {Anna Harutyunyan and
               Will Dabney and
               Thomas Mesnard and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Nicolas Heess and
               Hado {van Hasselt} and
               Gregory Wayne and
               Satinder Singh and
               Doina Precup and
               R{\'{e}}mi Munos},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Hindsight Credit Assignment},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {12467--12476},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/9413-hindsight-credit-assignment},
  timestamp = {Fri, 06 Mar 2020 16:59:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/HarutyunyanDMAP19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{woulda_coulda_shoulda,
  author    = {Lars Buesing and
               Theophane Weber and
               Yori Zwols and
               Nicolas Heess and
               S{\'{e}}bastien Racani{\`{e}}re and
               Arthur Guez and
               Jean{-}Baptiste Lespiau},
  title     = {Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=BJG0voC9YQ},
  timestamp = {Thu, 25 Jul 2019 14:25:54 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/BuesingWZHRGL19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{muzero,
  author    = {Julian Schrittwieser and
               Ioannis Antonoglou and
               Thomas Hubert and
               Karen Simonyan and
               Laurent Sifre and
               Simon Schmitt and
               Arthur Guez and
               Edward Lockhart and
               Demis Hassabis and
               Thore Graepel and
               Timothy P. Lillicrap and
               David Silver},
  title     = {Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model},
  journal   = {CoRR},
  volume    = {abs/1911.08265},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.08265},
  archivePrefix = {arXiv},
  eprint    = {1911.08265},
  timestamp = {Mon, 02 Dec 2019 17:48:37 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-08265.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{dqn,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Andrei A. Rusu and
               Joel Veness and
               Marc G. Bellemare and
               Alex Graves and
               Martin A. Riedmiller and
               Andreas Fidjeland and
               Georg Ostrovski and
               Stig Petersen and
               Charles Beattie and
               Amir Sadik and
               Ioannis Antonoglou and
               Helen King and
               Dharshan Kumaran and
               Daan Wierstra and
               Shane Legg and
               Demis Hassabis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  url       = {https://doi.org/10.1038/nature14236},
  doi       = {10.1038/nature14236},
  timestamp = {Wed, 14 Nov 2018 10:30:43 +0100},
  biburl    = {https://dblp.org/rec/journals/nature/MnihKSRVBGRFOPB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{prioritized_er,
  author    = {Tom Schaul and
               John Quan and
               Ioannis Antonoglou and
               David Silver},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Prioritized Experience Replay},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  url       = {http://arxiv.org/abs/1511.05952},
  timestamp = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchaulQAS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{experience_replay,
  author    = {Long Ji Lin},
  title     = {Self-Improving Reactive Agents Based On Reinforcement Learning, Planning
               and Teaching},
  journal   = {Mach. Learn.},
  volume    = {8},
  pages     = {293--321},
  year      = {1992},
  url       = {https://doi.org/10.1007/BF00992699},
  doi       = {10.1007/BF00992699},
  timestamp = {Mon, 02 Mar 2020 16:30:02 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/Lin92.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{reverse_replay, title={Forward and reverse hippocampal place-cell sequences during ripples}, volume={10}, DOI={10.1038/nn1961}, number={10}, journal={Nature Neuroscience}, author={Diba, Kamran and Buzsáki, György}, year={2007}, month={Feb}, pages={1241–1242}}

@inproceedings{dice,
  author    = {Ofir Nachum and
               Yinlam Chow and
               Bo Dai and
               Lihong Li},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution
               Corrections},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {2315--2325},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/8503-dualdice-behavior-agnostic-estimation-of-discounted-stationary-distribution-corrections},
  timestamp = {Fri, 06 Mar 2020 16:59:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/NachumCD019.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{meta_gradient,
  author    = {Zhongwen Xu and
               Hado {van Hasselt} and
               David Silver},
  title     = {Meta-Gradient Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1805.09801},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.09801},
  archivePrefix = {arXiv},
  eprint    = {1805.09801},
  timestamp = {Mon, 13 Aug 2018 16:47:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-09801.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{boyan_chain,
author = {Boyan, Justin A.},
title = {Least-Squares Temporal Difference Learning},
year = {1999},
isbn = {1558606122},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
pages = {49–56},
numpages = {8},
series = {ICML ’99}
}

@article{kaelbling,
author = {Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
title = {Reinforcement Learning: A Survey},
year = {1996},
issue_date = {January 1996},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {4},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {237–285},
numpages = {49}
}

@techreport{learning_and_sequential_decision_making,
author = {Barto, A. G. and Sutton, R. S. and Watkins, C. J.C.H.},
title = {Learning and Sequential Decision Making},
year = {1989},
publisher = {University of Massachusetts},
address = {USA}
}

@inproceedings{Sutton1981AnAN,
  title={An adaptive network that constructs and uses an internal model of its world},
  author={Richard Sutton and Andrew G. Barto},
  year={1981}
}

@inproceedings{trueonlineTD,
  title={True online TD($\lambda$)},
  author={Seijen, Harm and Sutton, Rich},
  booktitle={International Conference on Machine Learning},
  pages={692--700},
  year={2014}
}

@article{span,
	Author = {{van Hasselt}, Hado and Sutton, Richard S},
	Journal = {CoRR},
	Title = {Learning to predict independent of span},
	Volume = {abs/1508.04582},
	Year = {2015}}


@article{lin,
	Abstract = {To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.},
	Author = {Lin, Long-Ji},
	Da = {1992/05/01},
	Date-Added = {2020-04-27 14:21:12 +0000},
	Date-Modified = {2020-04-27 14:21:12 +0000},
	Doi = {10.1007/BF00992699},
	Id = {Lin1992},
	Isbn = {1573-0565},
	Journal = {Machine Learning},
	Number = {3},
	Pages = {293--321},
	Title = {Self-improving reactive agents based on reinforcement learning, planning and teaching},
	Ty = {JOUR},
	Url = {https://doi.org/10.1007/BF00992699},
	Volume = {8},
	Year = {1992},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF00992699}}

@article{paml,
  author    = {Romina Abachi and
               Mohammad Ghavamzadeh and
               Amir{-}massoud Farahmand},
  title     = {Policy-Aware Model Learning for Policy Gradient Methods},
  journal   = {CoRR},
  volume    = {abs/2003.00030},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.00030},
  archivePrefix = {arXiv},
  eprint    = {2003.00030},
  timestamp = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-00030.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{iter_vaml,
  author    = {Amir{-}massoud Farahmand},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Iterative Value-Aware Model Learning},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December
               2018, Montr{\'{e}}al, Canada},
  pages     = {9090--9101},
  year      = {2018},
  url       = {http://papers.nips.cc/paper/8121-iterative-value-aware-model-learning},
  timestamp = {Fri, 06 Mar 2020 17:00:31 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/Farahmand18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{vaml,
  author    = {Amir Massoud Farahmand and
               Andr{\'{e}} Barreto and
               Daniel Nikovski},
  editor    = {Aarti Singh and
               Xiaojin (Jerry) Zhu},
  title     = {Value-Aware Loss Function for Model-based Reinforcement Learning},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics, {AISTATS} 2017, 20-22 April 2017, Fort Lauderdale,
               FL, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {54},
  pages     = {1486--1494},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v54/farahmand17a.html},
  timestamp = {Wed, 29 May 2019 08:41:44 +0200},
  biburl    = {https://dblp.org/rec/conf/aistats/FarahmandBN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hester_and_stone,
  author    = {Todd Hester and
               Peter Stone},
  title     = {{TEXPLORE:} real-time sample-efficient reinforcement learning for
               robots},
  journal   = {Mach. Learn.},
  volume    = {90},
  number    = {3},
  pages     = {385--429},
  year      = {2013},
  url       = {https://doi.org/10.1007/s10994-012-5322-7},
  doi       = {10.1007/s10994-012-5322-7},
  timestamp = {Mon, 02 Mar 2020 16:29:53 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/HesterS13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{deisenroth,
  author    = {Marc Peter Deisenroth and
               Dieter Fox and
               Carl Edward Rasmussen},
  title     = {Gaussian Processes for Data-Efficient Learning in Robotics and Control},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {37},
  number    = {2},
  pages     = {408--423},
  year      = {2015},
  url       = {https://doi.org/10.1109/TPAMI.2013.218},
  doi       = {10.1109/TPAMI.2013.218},
  timestamp = {Wed, 14 Nov 2018 10:51:16 +0100},
  biburl    = {https://dblp.org/rec/journals/pami/DeisenrothFR15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{predictron,
  author    = {David Silver and
               Hado {van Hasselt} and
               Matteo Hessel and
               Tom Schaul and
               Arthur Guez and
               Tim Harley and
               Gabriel Dulac{-}Arnold and
               David P. Reichert and
               Neil C. Rabinowitz and
               Andr{\'{e}} Barreto and
               Thomas Degris},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {The Predictron: End-To-End Learning and Planning},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {3191--3199},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v70/silver17a.html},
  timestamp = {Wed, 29 May 2019 08:41:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/SilverHHSGHDRRB17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{talvitie,
  author    = {Erik Talvitie},
  editor    = {Satinder P. Singh and
               Shaul Markovitch},
  title     = {Self-Correcting Models for Model-Based Reinforcement Learning},
  booktitle = {Proceedings of the Thirty-First {AAAI} Conference on Artificial Intelligence,
               February 4-9, 2017, San Francisco, California, {USA}},
  pages     = {2597--2603},
  publisher = {{AAAI} Press},
  year      = {2017},
  url       = {http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14551},
  timestamp = {Mon, 06 Mar 2017 11:36:24 +0100},
  biburl    = {https://dblp.org/rec/conf/aaai/Talvitie17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{has,
  author    = {David Ha and
               J{\"{u}}rgen Schmidhuber},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Recurrent World Models Facilitate Policy Evolution},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December
               2018, Montr{\'{e}}al, Canada},
  pages     = {2455--2467},
  year      = {2018},
  url       = {http://papers.nips.cc/paper/7512-recurrent-world-models-facilitate-policy-evolution},
  timestamp = {Fri, 06 Mar 2020 17:00:31 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/HaS18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{value_pred_net,
  author    = {Junhyuk Oh and
               Satinder Singh and
               Honglak Lee},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {Value Prediction Network},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, 4-9 December 2017,
               Long Beach, CA, {USA}},
  pages     = {6118--6128},
  year      = {2017},
  url       = {http://papers.nips.cc/paper/7192-value-prediction-network},
  timestamp = {Fri, 06 Mar 2020 16:56:22 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/OhSL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{joseph,
  author    = {Joshua Mason Joseph and
               Alborz Geramifard and
               John W. Roberts and
               Jonathan P. How and
               Nicholas Roy},
  title     = {Reinforcement learning with misspecified model classes},
  booktitle = {2013 {IEEE} International Conference on Robotics and Automation, Karlsruhe,
               Germany, May 6-10, 2013},
  pages     = {939--946},
  publisher = {{IEEE}},
  year      = {2013},
  url       = {https://doi.org/10.1109/ICRA.2013.6630686},
  doi       = {10.1109/ICRA.2013.6630686},
  timestamp = {Wed, 16 Oct 2019 14:14:51 +0200},
  biburl    = {https://dblp.org/rec/conf/icra/JosephGRHR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Farquhar,
  author    = {Gregory Farquhar and
               Tim Rockt{\"{a}}schel and
               Maximilian Igl and
               Shimon Whiteson},
  title     = {TreeQN and ATreeC: Differentiable Tree Planning for Deep Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1710.11417},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.11417},
  archivePrefix = {arXiv},
  eprint    = {1710.11417},
  timestamp = {Mon, 13 Aug 2018 16:47:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-11417.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{luo,
  author    = {Yuping Luo and
               Huazhe Xu and
               Yuanzhi Li and
               Yuandong Tian and
               Trevor Darrell and
               Tengyu Ma},
  title     = {Algorithmic Framework for Model-based Deep Reinforcement Learning
               with Theoretical Guarantees},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=BJe1E2R5KX},
  timestamp = {Thu, 25 Jul 2019 14:26:05 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LuoXLTDM19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{doro,
  author    = {Pierluca D'Oro and
               Alberto Maria Metelli and
               Andrea Tirinzoni and
               Matteo Papini and
               Marcello Restelli},
  title     = {Gradient-Aware Model-based Policy Search},
  journal   = {CoRR},
  volume    = {abs/1909.04115},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.04115},
  archivePrefix = {arXiv},
  eprint    = {1909.04115},
  timestamp = {Tue, 17 Sep 2019 11:23:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-04115.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{small_backups,
  author    = {Harm van Seijen and
               Richard S. Sutton},
  title     = {Planning by Prioritized Sweeping with Small Backups},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning,
               {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {28},
  pages     = {361--369},
  publisher = {JMLR.org},
  year      = {2013},
  url       = {http://proceedings.mlr.press/v28/vanseijen13.html},
  timestamp = {Wed, 29 May 2019 08:41:46 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/SeijenS13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DeisenrothR11,
  author    = {Marc Peter Deisenroth and
               Carl Edward Rasmussen},
  editor    = {Lise Getoor and
               Tobias Scheffer},
  title     = {{PILCO:} {A} Model-Based and Data-Efficient Approach to Policy Search},
  booktitle = {Proceedings of the 28th International Conference on Machine Learning,
               {ICML} 2011, Bellevue, Washington, USA, June 28 - July 2, 2011},
  pages     = {465--472},
  publisher = {Omnipress},
  year      = {2011},
  url       = {https://icml.cc/2011/papers/323\_icmlpaper.pdf},
  timestamp = {Wed, 03 Apr 2019 17:43:35 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/DeisenrothR11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Sutton90,
  author    = {Richard S. Sutton},
  editor    = {Richard Lippmann and
               John E. Moody and
               David S. Touretzky},
  title     = {Integrated Modeling and Control Based on Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems 3, {[NIPS} Conference,
               Denver, Colorado, USA, November 26-29, 1990]},
  pages     = {471--478},
  publisher = {Morgan Kaufmann},
  year      = {1990},
  url       = {http://papers.nips.cc/paper/388-integrated-modeling-and-control-based-on-reinforcement-learning},
  timestamp = {Fri, 06 Mar 2020 16:57:00 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/Sutton90.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Asadi2015StrengthsWA,
  title={Strengths, Weaknesses, and Combinations of Model-based and Model-free Reinforcement Learning},
  author={Kavosh Asadi},
  year={2015}
}

@article{Nagabandi,
  author    = {Anusha Nagabandi and
               Gregory Kahn and
               Ronald S. Fearing and
               Sergey Levine},
  title     = {Neural Network Dynamics for Model-Based Deep Reinforcement Learning
               with Model-Free Fine-Tuning},
  journal   = {CoRR},
  volume    = {abs/1708.02596},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.02596},
  archivePrefix = {arXiv},
  eprint    = {1708.02596},
  timestamp = {Mon, 13 Aug 2018 16:47:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-02596.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{multi_step_dyna,
author = {Yao, Hengshuai and Bhatnagar, Shalabh and Diao, Dongcui},
title = {Multi-Step Linear Dyna-Style Planning},
year = {2009},
isbn = {9781615679119},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems},
pages = {2187–2195},
numpages = {9},
location = {Vancouver, British Columbia, Canada},
series = {NIPS’09}
}


@article{mattar,
	Abstract = {To make decisions, animals must evaluate candidate choices by accessing memories of relevant experiences. Yet little is known about which experiences are considered or ignored during deliberation, which ultimately governs choice. We propose a normative theory predicting which memories should be accessed at each moment to optimize future decisions. Using nonlocal `replay'of spatial locations in hippocampus as a window into memory access, we simulate a spatial navigation task in which an agent accesses memories of locations sequentially, ordered by utility: how much extra reward would be earned due to better choices. This prioritization balances two desiderata: the need to evaluate imminent choices versus the gain from propagating newly encountered information to preceding locations. Our theory offers a simple explanation for numerous findings about place cells; unifies seemingly disparate proposed functions of replay including planning, learning, and consolidation; and posits a mechanism whose dysfunction may underlie pathologies like rumination and craving.},
	Author = {Mattar, Marcelo G. and Daw, Nathaniel D.},
	Da = {2018/11/01},
	Date-Added = {2020-05-30 13:52:05 +0000},
	Date-Modified = {2020-05-30 13:52:05 +0000},
	Doi = {10.1038/s41593-018-0232-z},
	Id = {Mattar2018},
	Isbn = {1546-1726},
	Journal = {Nature Neuroscience},
	Number = {11},
	Pages = {1609--1617},
	Title = {Prioritized memory access explains planning and hippocampal replay},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41593-018-0232-z},
	Volume = {21},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41593-018-0232-z}}


@misc{pires2016policy,
    title={Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models},
    author={Bernardo Ávila Pires and Csaba Szepesvári},
    year={2016},
    eprint={1602.06346},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{Asadi2018,
  author    = {Kavosh Asadi and
               Evan Cater and
               Dipendra Misra and
               Michael L. Littman},
  title     = {Equivalence Between Wasserstein and Value-Aware Model-based Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1806.01265},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.01265},
  archivePrefix = {arXiv},
  eprint    = {1806.01265},
  timestamp = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-01265.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kaiser,
  author    = {Lukasz Kaiser and
               Mohammad Babaeizadeh and
               Piotr Milos and
               Blazej Osinski and
               Roy H. Campbell and
               Konrad Czechowski and
               Dumitru Erhan and
               Chelsea Finn and
               Piotr Kozakowski and
               Sergey Levine and
               Ryan Sepassi and
               George Tucker and
               Henryk Michalewski},
  title     = {Model-Based Reinforcement Learning for Atari},
  journal   = {CoRR},
  volume    = {abs/1903.00374},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.00374},
  archivePrefix = {arXiv},
  eprint    = {1903.00374},
  timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00374.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{OhGLLS15,
  author    = {Junhyuk Oh and
               Xiaoxiao Guo and
               Honglak Lee and
               Richard L. Lewis and
               Satinder P. Singh},
  title     = {Action-Conditional Video Prediction using Deep Networks in Atari Games},
  journal   = {CoRR},
  volume    = {abs/1507.08750},
  year      = {2015},
  url       = {http://arxiv.org/abs/1507.08750},
  archivePrefix = {arXiv},
  eprint    = {1507.08750},
  timestamp = {Mon, 13 Aug 2018 16:46:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/OhGLLS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Feinberg,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.00101},
  archivePrefix = {arXiv},
  eprint    = {1803.00101},
  timestamp = {Mon, 13 Aug 2018 16:47:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-00101.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{WeberRRBGRBVHLP17,
  author    = {Theophane Weber and
               S{\'{e}}bastien Racani{\`{e}}re and
               David P. Reichert and
               Lars Buesing and
               Arthur Guez and
               Danilo Jimenez Rezende and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Oriol Vinyals and
               Nicolas Heess and
               Yujia Li and
               Razvan Pascanu and
               Peter W. Battaglia and
               David Silver and
               Daan Wierstra},
  title     = {Imagination-Augmented Agents for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1707.06203},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06203},
  archivePrefix = {arXiv},
  eprint    = {1707.06203},
  timestamp = {Wed, 24 Jul 2019 11:32:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WeberRRBGRBVHLP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{KearnsS02,
  author    = {Michael J. Kearns and
               Satinder P. Singh},
  title     = {Near-Optimal Reinforcement Learning in Polynomial Time},
  journal   = {Mach. Learn.},
  volume    = {49},
  number    = {2-3},
  pages     = {209--232},
  year      = {2002},
  url       = {https://doi.org/10.1023/A:1017984413808},
  doi       = {10.1023/A:1017984413808},
  timestamp = {Mon, 02 Mar 2020 16:29:41 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/KearnsS02.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SilverHMGSDSAPL16,
  author    = {David Silver and
               Aja Huang and
               Chris J. Maddison and
               Arthur Guez and
               Laurent Sifre and
               George van den Driessche and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Vedavyas Panneershelvam and
               Marc Lanctot and
               Sander Dieleman and
               Dominik Grewe and
               John Nham and
               Nal Kalchbrenner and
               Ilya Sutskever and
               Timothy P. Lillicrap and
               Madeleine Leach and
               Koray Kavukcuoglu and
               Thore Graepel and
               Demis Hassabis},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  journal   = {Nature},
  volume    = {529},
  number    = {7587},
  pages     = {484--489},
  year      = {2016},
  url       = {https://doi.org/10.1038/nature16961},
  doi       = {10.1038/nature16961},
  timestamp = {Wed, 14 Nov 2018 10:30:42 +0100},
  biburl    = {https://dblp.org/rec/journals/nature/SilverHMGSDSAPL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{abbeel,
author = {Abbeel, Pieter and Quigley, Morgan and Ng, Andrew Y.},
title = {Using Inaccurate Models in Reinforcement Learning},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143845},
doi = {10.1145/1143844.1143845},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {1–8},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML ’06}
}

@inproceedings{recall_traces,
  author    = {Anirudh Goyal and
               Philemon Brakel and
               William Fedus and
               Soumye Singhal and
               Timothy P. Lillicrap and
               Sergey Levine and
               Hugo Larochelle and
               Yoshua Bengio},
  title     = {Recall Traces: Backtracking Models for Efficient Reinforcement Learning},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=HygsfnR9Ym},
  timestamp = {Thu, 25 Jul 2019 14:25:49 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/GoyalBFSLLLB19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dayan_and_Lengyel,
author = {Lengyel, M\'{a}t\'{e} and Dayan, Peter},
title = {Hippocampal Contributions to Control: The Third Way},
year = {2007},
isbn = {9781605603520},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
pages = {889–896},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {NIPS’07}
}

@misc{
satija2020constrained,
title={Constrained Markov Decision Processes via Backward Value Functions},
author={Harsh Satija and Philip Amortila and Joelle Pineau},
year={2020},
url={https://openreview.net/forum?id=S1lyyANYwr}
}
  
@article{generative_pred_models,
  author    = {Yannick Schroecker and
               Mel Vecer{\'{\i}}k and
               Jonathan Scholz},
  title     = {Generative predecessor models for sample-efficient imitation learning},
  journal   = {CoRR},
  volume    = {abs/1904.01139},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.01139},
  archivePrefix = {arXiv},
  eprint    = {1904.01139},
  timestamp = {Wed, 24 Apr 2019 12:21:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-01139.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{dyna_atari,
  author    = {G. Zacharias Holland and
               Erik Talvitie and
               Michael Bowling},
  title     = {The Effect of Planning Shape on Dyna-style Planning in High-dimensional
               State Spaces},
  journal   = {CoRR},
  volume    = {abs/1806.01825},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.01825},
  archivePrefix = {arXiv},
  eprint    = {1806.01825},
  timestamp = {Mon, 13 Aug 2018 16:46:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-01825.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{multi_step_model_learning,
  author    = {Kavosh Asadi and
               Evan Cater and
               Dipendra Misra and
               Michael L. Littman},
  title     = {Towards a Simple Approach to Multi-step Model-based Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.00128},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.00128},
  archivePrefix = {arXiv},
  eprint    = {1811.00128},
  timestamp = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-00128.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{termination_critic,
  author    = {Anna Harutyunyan and
               Will Dabney and
               Diana Borsa and
               Nicolas Heess and
               R{\'{e}}mi Munos and
               Doina Precup},
  editor    = {Kamalika Chaudhuri and
               Masashi Sugiyama},
  title     = {The Termination Critic},
  booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2019, 16-18 April 2019, Naha, Okinawa, Japan},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  pages     = {2231--2240},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v89/harutyunyan19a.html},
  timestamp = {Fri, 07 Jun 2019 09:03:47 +0200},
  biburl    = {https://dblp.org/rec/conf/aistats/HarutyunyanDBHM19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{Lav06,
  author       = {S. M. LaValle},
  title        = {Planning Algorithms},
  publisher    = {Cambridge University Press},
  address      = {Cambridge, U.K.},
  note         = {Available at http://planning.cs.uiuc.edu/},
  year         = {2006}
}

@article{watkins,
author = {Watkins, Christopher J. C. H. and Dayan, Peter},
title = {Technical Note: \cal Q -Learning},
year = {1992},
issue_date = {May 1992},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3–4},
issn = {0885-6125},
url = {https://doi.org/10.1007/BF00992698},
doi = {10.1007/BF00992698},
journal = {Mach. Learn.},
month = may,
pages = {279–292},
numpages = {14},
keywords = {temporal differences, cal Q -learning, asynchronous dynamic programming, reinforcement learning}
}

@inproceedings{planning_horiz_dependence,
author = {Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
title = {The Dependence of Effective Planning Horizon on Model Accuracy},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1181–1189},
numpages = {9},
keywords = {over-fitting, reinforcement learning, discount factor},
location = {Istanbul, Turkey},
series = {AAMAS ’15}
}

@inproceedings{imperfect_model,
  author    = {Nan Jiang},
  editor    = {Sheila A. McIlraith and
               Kilian Q. Weinberger},
  title     = {{PAC} Reinforcement Learning With an Imperfect Model},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence,
               (AAAI-18), the 30th innovative Applications of Artificial Intelligence
               (IAAI-18), and the 8th {AAAI} Symposium on Educational Advances in
               Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
               2-7, 2018},
  pages     = {3334--3341},
  publisher = {{AAAI} Press},
  year      = {2018},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16052},
  timestamp = {Tue, 23 Oct 2018 06:42:15 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/Jiang18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lipschitz_continuity,
  author    = {Kavosh Asadi and
               Dipendra Misra and
               Michael L. Littman},
  editor    = {Jennifer G. Dy and
               Andreas Krause},
  title     = {Lipschitz Continuity in Model-based Reinforcement Learning},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {264--273},
  publisher = {{PMLR}},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v80/asadi18a.html},
  timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/AsadiML18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mbrl_benchmarks,
  author    = {Tingwu Wang and
               Xuchan Bao and
               Ignasi Clavera and
               Jerrick Hoang and
               Yeming Wen and
               Eric Langlois and
               Shunshi Zhang and
               Guodong Zhang and
               Pieter Abbeel and
               Jimmy Ba},
  title     = {Benchmarking Model-Based Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1907.02057},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.02057},
  archivePrefix = {arXiv},
  eprint    = {1907.02057},
  timestamp = {Mon, 08 Jul 2019 14:12:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-02057.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{pineau,
    title={Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)},
    author={Joelle Pineau and Philippe Vincent-Lamarre and Koustuv Sinha and Vincent Larivière and Alina Beygelzimer and Florence d'Alché-Buc and Emily Fox and Hugo Larochelle},
    year={2020},
    eprint={2003.12206},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{hippo_mbp,
	Author = {Vikbladh, Oliver M and Meager, Michael R and King, John and Blackmon, Karen and Devinsky, Orrin and Shohamy, Daphna and Burgess, Neil and Daw, Nathaniel D},
	Journal = {Neuron},
	Month = {May},
	Number = {3},
	Pages = {683--693},
	Title = {Hippocampal Contributions to Model-Based Planning and Spatial Memory.},
	Volume = {102},
	Year = {2019}}

@inbook{kahneman_tversky_1982, place={Cambridge}, title={The simulation heuristic}, DOI={10.1017/CBO9780511809477.015}, booktitle={Judgment under Uncertainty: Heuristics and Biases}, publisher={Cambridge University Press}, author={Kahneman, Daniel and Tversky, Amos}, editor={Kahneman, Daniel and Slovic, Paul and Tversky, AmosEditors}, year={1982}, pages={201–208}}


@article{counterfactual_conditional,
	Author = {Goodman, Nelson},
	Number = {5},
	Pages = {113-128},
	Title = {The Problem of Counterfactual Conditionals},
	Volume = {44},
	Year = {1947}}


@article{contrary_to_fact,
	Author = {Chisholm, Roderick M. },
	Number = {220},
	Pages = {289-307},
	Title = {The Contrary-to-Fact Conditional},
	Volume = {55},
	Year = {1946}}


@article{causality_pearl,
	Author = {Pearl, Judea. },
	Title = {Causality : models, reasoning, and inference},
	Year = {2000}}


@article{causal_primer_pearl,
	Author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
	Title = {Causal inference in statistics : a primer},
	Year = {2016}}



@misc{rezende2020causally,
    title={Causally Correct Partial Models for Reinforcement Learning},
    author={Danilo J. Rezende and Ivo Danihelka and George Papamakarios and Nan Rosemary Ke and Ray Jiang and Theophane Weber and Karol Gregor and Hamza Merzic and Fabio Viola and Jane Wang and Jovana Mitrovic and Frederic Besse and Ioannis Antonoglou and Lars Buesing},
    year={2020},
    eprint={2002.02836},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{causal_reasoning,
  author    = {Ishita Dasgupta and
               Jane X. Wang and
               Silvia Chiappa and
               Jovana Mitrovic and
               Pedro A. Ortega and
               David Raposo and
               Edward Hughes and
               Peter W. Battaglia and
               Matthew Botvinick and
               Zeb Kurth{-}Nelson},
  title     = {Causal Reasoning from Meta-reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1901.08162},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.08162},
  archivePrefix = {arXiv},
  eprint    = {1901.08162},
  timestamp = {Wed, 24 Jul 2019 11:32:12 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-08162.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Haavelmo,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1906935},
 author = {Trygve Haavelmo},
 journal = {Econometrica},
 pages = {iii--115},
 publisher = {[Wiley, Econometric Society]},
 title = {The Probability Approach in Econometrics},
 volume = {12},
 year = {1944}
}


@article{autonomy,
	Author = {Aldrich, John},
	Journal = {Oxford Economic Papers},
	Month = {01},
	Number = {1},
	Pages = {15-34},
	Title = {{AUTONOMY}},
	Volume = {41},
	Year = {1989}}


@inproceedings{causal_and_anticausal,
  author    = {Bernhard Sch{\"{o}}lkopf and
               Dominik Janzing and
               Jonas Peters and
               Eleni Sgouritsa and
               Kun Zhang and
               Joris M. Mooij},
  title     = {On causal and anticausal learning},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning,
               {ICML} 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012},
  publisher = {icml.cc / Omnipress},
  year      = {2012},
  url       = {http://icml.cc/2012/papers/625.pdf},
  timestamp = {Wed, 03 Apr 2019 17:43:35 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/ScholkopfJPSZM12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mechansim_input_independence,
  author    = {Dominik Janzing and
               Bernhard Sch{\"{o}}lkopf},
  title     = {Causal inference using the algorithmic Markov condition},
  journal   = {{IEEE} Trans. Inf. Theory},
  volume    = {56},
  number    = {10},
  pages     = {5168--5194},
  year      = {2010},
  url       = {https://doi.org/10.1109/TIT.2010.2060095},
  doi       = {10.1109/TIT.2010.2060095},
  timestamp = {Tue, 10 Mar 2020 10:49:21 +0100},
  biburl    = {https://dblp.org/rec/journals/tit/JanzingS10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@book{Sugiyama,
author = {Sugiyama, Masashi and Kawanabe, Motoaki},
title = {Machine Learning in Non-Stationary Environments: Introduction to Covariate Shift Adaptation},
year = {2012},
isbn = {0262017091},
publisher = {The MIT Press}
}

@inproceedings{counterfactual_query,
author = {Balke, Alexander and Pearl, Judea},
title = {Counterfactual Probabilities: Computational Methods, Bounds and Applications},
year = {1994},
isbn = {1558603328},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Tenth International Conference on Uncertainty in Artificial Intelligence},
pages = {46–54},
numpages = {9},
location = {Seattle, WA},
series = {UAI’94}
}




% @article{counterfactual_query},
%   author    = {Alexander Balke and
%               Judea Pearl},
%   title     = {Counterfactual Probabilities: Computational Methods, Bounds and Applications},
%   journal   = {CoRR},
%   volume    = {abs/1302.6784},
%   year      = {2013},
%   url       = {http://arxiv.org/abs/1302.6784},
%   archivePrefix = {arXiv},
%   eprint    = {1302.6784},
%   timestamp = {Mon, 13 Aug 2018 16:46:35 +0200},
%   biburl    = {https://dblp.org/rec/journals/corr/abs-1302-6784.bib},
%   bibsource = {dblp computer science bibliography, https://dblp.org}
% }

@article{Janzing2010CausalIU,
  title={Causal Inference Using the Algorithmic Markov Condition},
  author={Dominik Janzing and Bernhard Sch{\"o}lkopf},
  journal={IEEE Transactions on Information Theory},
  year={2010},
  volume={56},
  pages={5168-5194}
}

@inproceedings{distribution_generalization,
  title={The Difficult Task of Distribution Generalization in Nonlinear Models},
  author={Rune Christiansen and Niklas Pfister and Martin Emil Jakobsen and Nicola Gnecco and Jonas Peters},
  year={2020}
}

@article{hindsight_value_modelling,
  title={Value-driven Hindsight Modelling},
  author={Arthur Guez and Fabio Viola and Th{\'e}ophane Weber and Lars Buesing and Steven Kapturowski and Doina Precup and David Silver and Nicolas Manfred Otto Heess},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.08329}
}

@article{hallucinating_value,
  author    = {Taher Jafferjee and
               Ehsan Imani and
               Erin Talvitie and
               Martha White and
               Michael Bowling},
  title     = {Hallucinating Value: {A} Pitfall of Dyna-style Planning with Imperfect
               Environment Models},
  journal   = {CoRR},
  volume    = {abs/2006.04363},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.04363},
  archivePrefix = {arXiv},
  eprint    = {2006.04363},
  timestamp = {Fri, 12 Jun 2020 14:02:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-04363.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{jaakkola,
author = {Jaakkola, Tommi and Jordan, Michael I. and Singh, Satinder P.},
title = {Convergence of Stochastic Iterative Dynamic Programming Algorithms},
year = {1993},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the 6th International Conference on Neural Information Processing Systems},
pages = {703–710},
numpages = {8},
location = {Denver, Colorado},
series = {NIPS’93}
}


@article{cite-key,
	Abstract = {Remembering the sequence of events is critical for deriving meaning from our experiences and guiding behavior. Prior investigations into the function of the human hippocampus have focused on its more general role in associative binding, but recent work has focused on understanding its specific role in encoding and preserving the temporal order of experiences. In this review we summarize recent work in humans examining hippocampal contributions to sequence learning. We distinguish the learning of sequential relationships through repetition from the rapid, episodic acquisition of sequential associations. Taken together, this research begins to clarify the link between hippocampal representations and the preservation of the order of events.},
	An = {25600586},
	Author = {Davachi, Lila and DuBrow, Sarah},
	Date = {2015/02/},
	Date-Added = {2020-07-12 22:14:38 +0000},
	Date-Modified = {2020-07-12 22:14:38 +0000},
	Db = {PubMed},
	Doi = {10.1016/j.tics.2014.12.004},
	Et = {2015/01/15},
	Isbn = {1879-307X; 1364-6613},
	J2 = {Trends Cogn Sci},
	Journal = {Trends in cognitive sciences},
	Keywords = {context; episodic memory; hippocampus; prediction; sequence memory; Animals; Anticipation, Psychological/*physiology; Hippocampus/*physiology; Humans; Learning/*physiology; Memory/*physiology},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4380862/},
	La = {eng},
	Month = {02},
	Number = {2},
	Pages = {92--99},
	Title = {How the hippocampus preserves order: the role of prediction and context},
	Ty = {JOUR},
	U1 = {25600586{$[$}pmid{$]$}},
	U2 = {PMC4380862{$[$}pmcid{$]$}},
	U4 = {S1364-6613(14)00256-3{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/25600586},
	Volume = {19},
	Year = {2015},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/25600586},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2014.12.004}}




@article{mnih2013playing,
title={Playing atari with deep reinforcement learning},
author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
journal={arXiv preprint arXiv:1312.5602},
year={2013}
}
@misc{tasfi2016PLE,
author = {Tasfi, Norman},
title = {PyGame Learning Environment},
year = {2016},
publisher = {GitHub},
journal = {GitHub repository},
howpublished = {\url{https://github.com/ntasfi/PyGame-Learning-Environment}}
}
@book{rummery1994line,
title={On-line Q-learning using connectionist systems},
author={Rummery, Gavin A and Niranjan, Mahesan},
volume={37},
year={1994},
publisher={University of Cambridge, Department of Engineering Cambridge, England}
}
@article{schaul2015prioritized,
title={Prioritized experience replay},
author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
journal={arXiv preprint arXiv:1511.05952},
year={2015}
}
@article{fu2019diagnosing,
title={Diagnosing Bottlenecks in Deep Q-learning Algorithms},
author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
journal={arXiv preprint arXiv:1902.10250},
year={2019}
}
@inproceedings{thodoroff2018temporal,
title={Temporal Regularization for Markov Decision Process},
author={Thodoroff, Pierre and Durand, Audrey and Pineau, Joelle and Precup, Doina},
booktitle={Advances in Neural Information Processing Systems},
pages={1779--1789},
year={2018}
}
@article{schulman2015high,
title={High-dimensional continuous control using generalized advantage estimation},
author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
journal={arXiv preprint arXiv:1506.02438},
year={2015}
}
@article{jaderberg2016reinforcement,
title={Reinforcement learning with unsupervised auxiliary tasks},
author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
journal={arXiv preprint arXiv:1611.05397},
year={2016}
}
@article{kingma2015adam,
title={Adam: a method for stochastic optimization (2014)},
author={Kingma, Diederik and Ba, Jimmy},
journal={arXiv preprint arXiv:1412.6980},
volume={15},
year={2015}
}
@inproceedings{hardt2016train,
title={Train faster, generalize better: Stability of stochastic gradient descent},
author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
booktitle={International Conference on Machine Learning},
pages={1225--1234},
year={2016}
}
@inproceedings{andrychowicz2017hindsight,
title={Hindsight experience replay},
author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
booktitle={Advances in Neural Information Processing Systems},
pages={5048--5058},
year={2017}
}
@inproceedings{nesterov27method,
title={A method of solving a convex programming problem with convergence rate $ O (1/k^{2} )$ O (1/k2)},
author={Nesterov, Yu},
booktitle={Soviet Mathematics Doklady},
year={1983},
volume={27},
}
@article{hinton2012neural,
title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
year={2012},
journal={CSC321}
}

@inproceedings{oh2017zero,
title={Zero-shot task generalization with multi-task deep reinforcement learning},
author={Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
pages={2661--2670},
year={2017},
organization={JMLR. org}
}
@article{packer2018assessing,
title={Assessing Generalization in Deep Reinforcement Learning},
author={Packer, Charles and Gao, Katelyn and Kos, Jernej and Kr{\"a}henb{\"u}hl, Philipp and Koltun, Vladlen and Song, Dawn},
journal={arXiv preprint arXiv:1810.12282},
year={2018}
}
@article{cobbe2018quantifying,
title={Quantifying generalization in reinforcement learning},
author={Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
journal={arXiv preprint arXiv:1812.02341},
year={2018}
}
@article{zhang2018study,
title={A study on overfitting in deep reinforcement learning},
author={Zhang, Chiyuan and Vinyals, Oriol and Munos, Remi and Bengio, Samy},
journal={arXiv preprint arXiv:1804.06893},
year={2018}
}
@article{farebrother2018generalization,
title={Generalization and Regularization in DQN},
author={Farebrother, Jesse and Machado, Marlos C and Bowling, Michael},
journal={arXiv preprint arXiv:1810.00123},
year={2018}
}
@article{penedones2018leakage,
title={Temporal Difference Learning with Neural Networks-Study of the Leakage Propagation Problem},
author={Penedones, Hugo and Vincent, Damien and Maennel, Hartmut and Gelly, Sylvain and Mann, Timothy and Barreto, Andre},
journal={arXiv preprint arXiv:1807.03064},
year={2018}
}
@inproceedings{hessel2018rainbow,
title={Rainbow: Combining improvements in deep reinforcement learning},
author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
year={2018}
}
@inproceedings{he2015delving,
title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle={Proceedings of the IEEE international conference on computer vision},
pages={1026--1034},
year={2015}
}
@book{sutton2018reinforcement,
title={Reinforcement learning: An introduction},
author={Sutton, Richard S and Barto, Andrew G},
year={2018},
publisher={MIT press}
}
@inproceedings{li2015convergent,
title={Convergent Learning: Do different neural networks learn the same representations?},
author={Li, Yixuan and Yosinski, Jason and Clune, Jeff and Lipson, Hod and Hopcroft, John E},
booktitle={Advances in neural information processing systems},
pages={196--212},
year={2015}
}
@inproceedings{yosinski2014transferable,
title={How transferable are features in deep neural networks?},
author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
booktitle={Advances in neural information processing systems},
pages={3320--3328},
year={2014}
}
@inproceedings{arpit2017closer,
title={A closer look at memorization in deep networks},
author={Arpit, Devansh and Jastrz{\k{e}}bski, Stanis{\l}aw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and others},
booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
pages={233--242},
year={2017},
organization={JMLR. org}
}
@article{ilyas2018deep,
title={Are Deep Policy Gradient Algorithms Truly Policy Gradient Algorithms?},
author={Ilyas, Andrew and Engstrom, Logan and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander},
journal={arXiv preprint arXiv:1811.02553},
year={2018}
}
@article{bellemare2013arcade,
title={The arcade learning environment: An evaluation platform for general agents},
author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
journal={Journal of Artificial Intelligence Research},
volume={47},
pages={253--279},
year={2013}
}
@article{sutton1988learning,
title={Learning to predict by the methods of temporal differences},
author={Sutton, Richard S},
journal={Machine learning},
volume={3},
number={1},
pages={9--44},
year={1988},
publisher={Springer}
}
@article{henderson2018did,
title={Where did my optimum go?: An empirical analysis of gradient descent optimization in policy gradient methods},
author={Henderson, Peter and Romoff, Joshua and Pineau, Joelle},
journal={arXiv preprint arXiv:1810.02525},
year={2018}
}
@article{vinyals2017starcraft,
title={Starcraft ii: A new challenge for reinforcement learning},
author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
journal={arXiv preprint arXiv:1708.04782},
year={2017}
}
@article{mirowski2016learning,
title={Learning to navigate in complex environments},
author={Mirowski, Piotr and Pascanu, Razvan and Viola, Fabio and Soyer, Hubert and Ballard, Andrew J and Banino, Andrea and Denil, Misha and Goroshin, Ross and Sifre, Laurent and Kavukcuoglu, Koray and others},
journal={arXiv preprint arXiv:1611.03673},
year={2016}
}
@inproceedings{riedmiller2005neural,
title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
author={Riedmiller, Martin},
booktitle={European Conference on Machine Learning},
pages={317--328},
year={2005},
organization={Springer}
}
@article{schulman2017proximal,
title={Proximal policy optimization algorithms},
author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
journal={arXiv preprint arXiv:1707.06347},
year={2017}
}
@inproceedings{mnih2016asynchronous,
title={Asynchronous methods for deep reinforcement learning},
author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
booktitle={International conference on machine learning},
pages={1928--1937},
year={2016}
}
@article{haarnoja2018soft,
title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
journal={arXiv preprint arXiv:1801.01290},
year={2018}
}
@inproceedings{sutton1995virtues,
title={On the virtues of linear learning and trajectory distributions},
author={Sutton, Richard S},
booktitle={Proceedings of the Workshop on Value Function Approximation, Machine Learning Conference},
pages={85},
year={1995}
}
@incollection{baird1995residual,
title={Residual algorithms: Reinforcement learning with function approximation},
author={Baird, Leemon},
booktitle={Machine Learning Proceedings 1995},
pages={30--37},
year={1995},
publisher={Elsevier}
}
@inproceedings{tsitsiklis1997analysis,
title={Analysis of temporal-diffference learning with function approximation},
author={Tsitsiklis, John N and Van Roy, Benjamin},
booktitle={Advances in neural information processing systems},
pages={1075--1081},
year={1997}
}
@article{watkins1992q,
title={Q-learning},
author={Watkins, Christopher JCH and Dayan, Peter},
journal={Machine learning},
volume={8},
number={3-4},
pages={279--292},
year={1992},
publisher={Springer}
}
@inproceedings{munos2016safe,
title={Safe and efficient off-policy reinforcement learning},
author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
booktitle={Advances in Neural Information Processing Systems},
pages={1054--1062},
year={2016}
}
@article{silver2016mastering,
title={Mastering the game of Go with deep neural networks and tree search},
author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
journal={nature},
volume={529},
number={7587},
pages={484},
year={2016},
publisher={Nature Publishing Group}
}
@article{tesauro1995temporal,
title={Temporal difference learning and TD-Gammon},
author={Tesauro, Gerald},
year={1995}
}
@article{pineau2019checklist,
title={The Machine Learning Reproducibility Checklist v1.2},
author={Pineau, Joelle},
year={2019}
}
@article{hinton2015distilling,
title={Distilling the knowledge in a neural network},
author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
journal={arXiv preprint arXiv:1503.02531},
year={2015}
}
@inproceedings{montufar2014number,
title={On the number of linear regions of deep neural networks},
author={Montufar, Guido F and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
booktitle={Advances in neural information processing systems},
pages={2924--2932},
year={2014}
}
@article{zhang2016understanding,
title={Understanding deep learning requires rethinking generalization},
author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
journal={arXiv preprint arXiv:1611.03530},
year={2016}
}
@article{agarwal2019striving,
title={Striving for Simplicity in Off-policy Deep Reinforcement Learning},
author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
journal={arXiv preprint arXiv:1907.04543},
year={2019}
}
@article{machado2018revisiting,
title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
journal={Journal of Artificial Intelligence Research},
volume={61},
pages={523--562},
year={2018}
}
@inproceedings{anschel2017averaged,
title={Averaged-dqn: Variance reduction and stabilization for deep reinforcement learning},
author={Anschel, Oron and Baram, Nir and Shimkin, Nahum},
booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
pages={176--185},
year={2017},
organization={JMLR. org}
}
@article{morcos2018importance,
title={On the importance of single directions for generalization},
author={Morcos, Ari and Barrett, David GT and Rabinowitz, Neil C and Botvinick, Matthew},
journal={arXiv preprint arXiv:1803.06959},
year={2018}
}
@inproceedings{raghu2017svcca,
title={Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability},
author={Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
booktitle={Advances in Neural Information Processing Systems},
pages={6076--6085},
year={2017}
}
@inproceedings{maas2013rectifier,
title={Rectifier nonlinearities improve neural network acoustic models},
author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y}
}
@article{anand2019unsupervised,
title={Unsupervised State Representation Learning in Atari},
author={Anand, Ankesh and Racah, Evan and Ozair, Sherjil and Bengio, Yoshua and C{\^o}t{\'e}, Marc-Alexandre and Hjelm, R Devon},
journal={arXiv preprint arXiv:1906.08226},
year={2019}
}
@article{bellman1957markovian,
title={A Markovian decision process},
author={Bellman, Richard},
journal={Journal of mathematics and mechanics},
pages={679--684},
year={1957},
publisher={JSTOR}
}
@article{bengio2013representation,
title={Representation learning: A review and new perspectives},
author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
journal={IEEE transactions on pattern analysis and machine intelligence},
volume={35},
number={8},
pages={1798--1828},
year={2013},
publisher={IEEE}
}
@article{oymak2019generalization,
title={Generalization Guarantees for Neural Networks via Harnessing the Low-rank Structure of the Jacobian},
author={Oymak, Samet and Fabian, Zalan and Li, Mingchen and Soltanolkotabi, Mahdi},
journal={arXiv preprint arXiv:1906.05392},
year={2019}
}
@article{ernst2005tree,
title={Tree-based batch mode reinforcement learning},
author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
journal={Journal of Machine Learning Research},
volume={6},
number={Apr},
pages={503--556},
year={2005}
}
@article{du2019good,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Du, Simon S and Kakade, Sham M and Wang, Ruosong and Yang, Lin F},
journal={arXiv preprint arXiv:1910.03016},
year={2019}
}
@article{zhang2018dissection,
title={A dissection of overfitting and generalization in continuous reinforcement learning},
author={Zhang, Amy and Ballas, Nicolas and Pineau, Joelle},
journal={arXiv preprint arXiv:1806.07937},
year={2018}
}
@article{lee2019simple,
title={A Simple Randomization Technique for Generalization in Deep Reinforcement Learning},
author={Lee, Kimin and Lee, Kibok and Shin, Jinwoo and Lee, Honglak},
journal={arXiv preprint arXiv:1910.05396},
year={2019}
}

@article{Young2019MinAtarAA,
  title={MinAtar: An Atari-inspired Testbed for More Efficient Reinforcement Learning Experiments},
  author={Kenny Young and Tian Tian},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.03176}
}

@article{justesen2018illuminating,
title={Illuminating generalization in deep reinforcement learning through procedural level generation},
author={Justesen, Niels and Torrado, Ruben Rodriguez and Bontrager, Philip and Khalifa, Ahmed and Togelius, Julian and Risi, Sebastian},
journal={arXiv preprint arXiv:1806.10729},
year={2018}
}
@article{witty2018measuring,
title={Measuring and Characterizing Generalization in Deep Reinforcement Learning},
author={Witty, Sam and Lee, Jun Ki and Tosch, Emma and Atrey, Akanksha and Littman, Michael and Jensen, David},
journal={arXiv preprint arXiv:1812.02868},
year={2018}
}
@article{nair2015massively,
title={Massively parallel methods for deep reinforcement learning},
author={Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and others},
journal={arXiv preprint arXiv:1507.04296},
year={2015}
}
@article{wang2019generalization,
title={On the Generalization Gap in Reparameterizable Reinforcement Learning},
author={Wang, Huan and Zheng, Stephan and Xiong, Caiming and Socher, Richard},
journal={arXiv preprint arXiv:1905.12654},
year={2019}
}
@article{zhao2019investigating,
title={Investigating Generalisation in Continuous Deep Reinforcement Learning},
author={Zhao, Chenyang and Siguad, Olivier and Stulp, Freek and Hospedales, Timothy M},
journal={arXiv preprint arXiv:1902.07015},
year={2019}
}
@inproceedings{whiteson2011protecting,
title={Protecting against evaluation overfitting in empirical reinforcement learning},
author={Whiteson, Shimon and Tanner, Brian and Taylor, Matthew E and Stone, Peter},
booktitle={2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
pages={120--127},
year={2011},
organization={IEEE}
}
@inproceedings{sutton1996generalization,
title={Generalization in reinforcement learning: Successful examples using sparse coarse coding},
author={Sutton, Richard S},
booktitle={Advances in neural information processing systems},
pages={1038--1044},
year={1996}
}
@article{liu2019toward,
title={Toward Understanding Catastrophic Interference inValue-based Reinforcement Learning},
author={Liu, Vincent and Yao, Hengshuai and White, Martha},
url={https://optrl2019.github.io/accepted_papers.html},
booktitle={NeurIPS 2019 Optimization Foundations for Reinforcement Learning Workshop},
year={2019}}
@article{fort2019stiffness,
title={Stiffness: A new perspective on generalization in neural networks},
author={Fort, Stanislav and Nowak, Pawe{\l} Krzysztof and Narayanan, Srini},
journal={arXiv preprint arXiv:1901.09491},
year={2019}
}
@article{fort2019emergent,
title={Emergent properties of the local geometry of neural loss landscapes},
author={Fort, Stanislav and Ganguli, Surya},
journal={arXiv preprint arXiv:1910.05929},
year={2019}
}
@article{papyan2019measurements,
title={Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians},
author={Papyan, Vardan},
journal={arXiv preprint arXiv:1901.08244},
year={2019}
}
@inproceedings{igl2019generalization,
title={Generalization in reinforcement learning with selective noise injection and information bottleneck},
author={Igl, Maximilian and Ciosek, Kamil and Li, Yingzhen and Tschiatschek, Sebastian and Zhang, Cheng and Devlin, Sam and Hofmann, Katja},
booktitle={Advances in Neural Information Processing Systems},
pages={13956--13968},
year={2019}
}
@article{riemer2018learning,
title={Learning to learn without forgetting by maximizing transfer and minimizing interference},
author={Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
journal={arXiv preprint arXiv:1810.11910},
year={2018}
}
@inproceedings{kearns2000bias,
title={Bias-Variance Error Bounds for Temporal Difference Updates.},
author={Kearns, Michael J and Singh, Satinder P},
booktitle={COLT},
pages={142--147},
year={2000},
organization={Citeseer}
}
@article{achiam2019towards,
title={Towards Characterizing Divergence in Deep Q-Learning},
author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
journal={arXiv preprint arXiv:1903.08894},
year={2019}
}
@inproceedings{liu2019utility,
title={The utility of sparse representations for control in reinforcement learning},
author={Liu, Vincent and Kumaraswamy, Raksha and Le, Lei and White, Martha},
booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
volume={33},
pages={4384--4391},
year={2019}
}
@misc{feng2020neural,
title={How neural networks find generalizable solutions: Self-tuned annealing in deep learning},
author={Yu Feng and Yuhai Tu},
year={2020},
eprint={2001.01678},
archivePrefix={arXiv},
primaryClass={physics.data-an}
}

@article{frankle2018lottery,
title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
author={Frankle, Jonathan and Carbin, Michael},
journal={arXiv preprint arXiv:1803.03635},
year={2018}
}
@article{gur2018gradient,
title={Gradient descent happens in a tiny subspace},
author={Gur-Ari, Guy and Roberts, Daniel A and Dyer, Ethan},
journal={arXiv preprint arXiv:1812.04754},
year={2018}
}
@inproceedings{morcos2018insights,
title={Insights on representational similarity in neural networks with canonical correlation},
author={Morcos, Ari and Raghu, Maithra and Bengio, Samy},
booktitle={Advances in Neural Information Processing Systems},
pages={5727--5736},
year={2018}
}
@article{frankle2019lottery,
title={The Lottery Ticket Hypothesis at Scale},
author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
journal={arXiv preprint arXiv:1903.01611},
year={2019}
}
@article{frankle2019linear,
title={Linear Mode Connectivity and the Lottery Ticket Hypothesis},
author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
journal={arXiv preprint arXiv:1912.05671},
year={2019}
}
@inproceedings{lopez2017gradient,
title={Gradient episodic memory for continual learning},
author={Lopez-Paz, David and Ranzato, Marc'Aurelio},
booktitle={Advances in Neural Information Processing Systems},
pages={6467--6476},
year={2017}
}
@article{nichol2018first,
title={On first-order meta-learning algorithms},
author={Nichol, Alex and Achiam, Joshua and Schulman, John},
journal={arXiv preprint arXiv:1803.02999},
year={2018}
}
@article{neal2019support,
title={In Support of Over-Parametrization in Deep Reinforcement Learning: an Empirical Study},
author={Neal, Brady and Mitliagkas, Ioannis},
year={2019}
}
@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}
@article{schaul2019ray,
  title={Ray interference: a source of plateaus in deep reinforcement learning},
  author={Schaul, Tom and Borsa, Diana and Modayil, Joseph and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1904.11455},
  year={2019}
}
@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}
@article{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred A},
  journal={arXiv preprint arXiv:1803.00885},
  year={2018}
}
@inproceedings{garipov2018LossSM,
  title={Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs},
  author={Timur Garipov and Pavel Izmailov and Dmitrii Podoprikhin and Dmitry P. Vetrov and Andrew Gordon Wilson},
  booktitle={NeurIPS},
  year={2018}
}
@misc{he2019task,
    title={Task Agnostic Continual Learning via Meta Learning},
    author={Xu He and Jakub Sygnowski and Alexandre Galashov and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu},
    year={2019},
    eprint={1906.05201},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@inproceedings{
chung2018twotimescale,
title={Two-Timescale Networks for Nonlinear Value Function Approximation},
author={Wesley Chung and Somjit Nath and Ajin Joseph and Martha White},
booktitle={International Conference on Learning Representations},
year={2019},
}
@inproceedings{
wu2018the,
title={The Laplacian in {RL}: Learning Representations with Efficient Approximations},
author={Yifan Wu and George Tucker and Ofir Nachum},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HJlNpoA5YQ},
}
@misc{machado2017laplacian,
    title={A Laplacian Framework for Option Discovery in Reinforcement Learning},
    author={Marlos C. Machado and Marc G. Bellemare and Michael Bowling},
    year={2017},
    eprint={1703.00956},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{bellemare2019geometric,
    title={A Geometric Perspective on Optimal Representations for Reinforcement Learning},
    author={Marc G. Bellemare and Will Dabney and Robert Dadashi and Adrien Ali Taiga and Pablo Samuel Castro and Nicolas Le Roux and Dale Schuurmans and Tor Lattimore and Clare Lyle},
    year={2019},
    eprint={1901.11530},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@book{bertsekas2012dynamic,
  title={Dynamic Programming and Optimal Control, Vol. II: Approximate Dynamic Programming},
  author={Bertsekas, Dimitri P},
  volume={2},
  year={2012},
  publisher={Athena scientific}
}
@misc{freeman2019learning,
    title={Learning to Predict Without Looking Ahead: World Models Without Forward Prediction},
    author={C. Daniel Freeman and Luke Metz and David Ha},
    year={2019},
    eprint={1910.13038},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}
@misc{hasselt2018deep,
    title={Deep Reinforcement Learning and the Deadly Triad},
    author={Hado {van Hasselt} and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
    year={2018},
    eprint={1812.02648},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
@misc{zhu2018anisotropic,
    title={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects},
    author={Zhanxing Zhu and Jingfeng Wu and Bing Yu and Lei Wu and Jinwen Ma},
    year={2018},
    eprint={1803.00195},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@misc{sagun2017empirical,
    title={Empirical Analysis of the Hessian of Over-Parametrized Neural Networks},
    author={Levent Sagun and Utku Evci and V. Ugur Guney and Yann Dauphin and Leon Bottou},
    year={2017},
    eprint={1706.04454},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{hanin2019deep,
    title={Deep ReLU Networks Have Surprisingly Few Activation Patterns},
    author={Boris Hanin and David Rolnick},
    year={2019},
    eprint={1906.00904},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@misc{hanin2019complexity,
    title={Complexity of Linear Regions in Deep Networks},
    author={Boris Hanin and David Rolnick},
    year={2019},
    eprint={1901.09021},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@misc{hasselt2019use,
    title={When to use parametric models in reinforcement learning?},
    author={Hado {van Hasselt} and Matteo Hessel and John Aslanides},
    year={2019},
    eprint={1906.05243},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{zhang2019layers,
    title={Are All Layers Created Equal?},
    author={Chiyuan Zhang and Samy Bengio and Yoram Singer},
    year={2019},
    eprint={1902.01996},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@misc{sankararaman2019impact,
    title={The Impact of Neural Network Overparameterization on Gradient Confusion and Stochastic Gradient Descent},
    author={Karthik A. Sankararaman and Soham De and Zheng Xu and W. Ronny Huang and Tom Goldstein},
    year={2019},
    eprint={1904.06963},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{finn2017metalearning,
    title={Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm},
    author={Chelsea Finn and Sergey Levine},
    year={2017},
    eprint={1710.11622},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@inproceedings{
Yin2020Meta-Learning,
title={Meta-Learning without Memorization},
author={Mingzhang Yin and George Tucker and Mingyuan Zhou and Sergey Levine and Chelsea Finn},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BklEFpEYwS}
}
@inproceedings{
Song2020Observational,
title={Observational Overfitting in Reinforcement Learning},
author={Xingyou Song and Yiding Jiang and Stephen Tu and Yilun Du and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJli2hNKDH}
}
@misc{javed2020learning,
    title={Learning Causal Models Online},
    author={Khurram Javed and Martha White and Yoshua Bengio},
    year={2020},
    eprint={2006.07461},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@article{wolpert1997no,
  title={No free lunch theorems for optimization},
  author={Wolpert, David H and Macready, William G},
  journal={IEEE transactions on evolutionary computation},
  volume={1},
  number={1},
  pages={67--82},
  year={1997},
  publisher={IEEE}
}
@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}
@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}


@article{liu2019human,
	Author = {Liu, Yunzhe and Dolan, Raymond J and Kurth-Nelson, Zeb and Behrens, Timothy E J},
	Journal = {Cell},
	Month = {Jul},
	Number = {3},
	Pages = {640--652},
	Title = {Human Replay Spontaneously Reorganizes Experience.},
	Volume = {178},
	Year = {2019}}


@inproceedings{Christiansen2020TheDT,
  title={The Difficult Task of Distribution Generalization in Nonlinear Models},
  author={Rune Christiansen and Niklas Pfister and Martin Emil Jakobsen and Nicola Gnecco and Jonas Peters},
  year={2020}
}

@inproceedings{Scholkopf2019CausalityFM,
  title={Causality for Machine Learning},
  author={Bernhard Scholkopf},
  year={2019}
}

@article{Jaakkola1993OnTC,
  title={On the Convergence of Stochastic Iterative Dynamic Programming Algorithms},
  author={Tommi S. Jaakkola and Michael I. Jordan and Satinder P. Singh},
  journal={Neural Computation},
  year={1993},
  volume={6},
  pages={1185-1201}
}
@article{DoshiVelez2016HiddenPM,
  title={Hidden Parameter Markov Decision Processes: A Semiparametric Regression Approach for Discovering Latent Task Parametrizations},
  author={Finale Doshi-Velez and George Konidaris},
  journal={IJCAI : proceedings of the conference},
  year={2016},
  volume={2016},
  pages={
          1432-1440
        }
}

@inproceedings{Haan2019CausalCI,
  title={Causal Confusion in Imitation Learning},
  author={Pim de Haan and Dinesh Jayaraman and Sergey Levine},
  booktitle={NeurIPS},
  year={2019}
}

@article{ArjonaMedina2019RUDDERRD,
  title={RUDDER: Return Decomposition for Delayed Rewards},
  author={Jose A. Arjona-Medina and Michael Gillhofer and Michael Widrich and Thomas Unterthiner and Sepp Hochreiter},
  journal={ArXiv},
  year={2019},
  volume={abs/1806.07857}
}
@inproceedings{Seijen2020TheLR,
  title={The LoCA Regret: A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning},
  author={Harm van Seijen and Hadi Nekoei and Evan Racah and Sarath Chandar},
  year={2020}
}

@article{Hung2019OptimizingAB,
  title={Optimizing agent behavior over long time scales by transporting value},
  author={Chia-Chun Hung and Timothy P. Lillicrap and Josh Abramson and Yan Wu and Mehdi Mirza and Federico Carnevale and Arun Ahuja and Greg Wayne},
  journal={Nature Communications},
  year={2019},
  volume={10}
}

@article{Harutyunyan2019HindsightCA,
  title={Hindsight Credit Assignment},
  author={Anna Harutyunyan and Will Dabney and Thomas Mesnard and Mohammad Gheshlaghi Azar and Bilal Piot and Nicolas Manfred Otto Heess and Hado {van Hasselt} and Gregory Wayne and Satinder Singh and Doina Precup and R{\'e}mi Munos},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.02503}
}

@article{Buesing2019WouldaCS,
  title={Woulda, Coulda, Shoulda: Counterfactually-Guided Policy Search},
  author={Lars Buesing and Th{\'e}ophane Weber and Yori Zwols and S{\'e}bastien Racani{\`e}re and Arthur Guez and Jean-Baptiste Lespiau and Nicolas Manfred Otto Heess},
  journal={ArXiv},
  year={2019},
  volume={abs/1811.06272}
}

@article{Priol2020AnAO,
  title={An Analysis of the Adaptation Speed of Causal Models},
  author={R{\'e}mi Le Priol and Reza Babanezhad Harikandeh and Yoshua Bengio and Simon Lacoste-Julien},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.09136}
}

@inproceedings{Haan2019CausalCI,
  title={Causal Confusion in Imitation Learning},
  author={Pim de Haan and Dinesh Jayaraman and Sergey Levine},
  booktitle={NeurIPS},
  year={2019}
}

@article{Wang2018TheBO,
  title={The Blessings of Multiple Causes},
  author={Yixin Wang and David M. Blei},
  journal={Journal of the American Statistical Association},
  year={2018},
  volume={114},
  pages={1574 - 1596}
}

@article{Lu2018DeconfoundingRL,
  title={Deconfounding Reinforcement Learning in Observational Settings},
  author={Chaochao Lu and Bernhard Sch{\"o}lkopf and Jos{\'e} Miguel Hern{\'a}ndez-Lobato},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.10576}
}


@inproceedings{Puterman1994MarkovDP,
  title={Markov Decision Processes: Discrete Dynamic Programming},
  author={Martin L. Puterman},
  year={1994}
}

@article{Sutton1998ReinforcementLA,
  title={Reinforcement Learning: An Introduction},
  author={Richard S. Sutton and Andrew G. Barto},
  journal={IEEE Transactions on Neural Networks},
  year={1998},
  volume={16},
  pages={285-286}
}

@article{Sutton2016AnEA,
  title={An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning},
  author={Richard S. Sutton and Ashique Rupam Mahmood and Martha White},
  journal={ArXiv},
  year={2016},
  volume={abs/1503.04269}
}

@article{Zhang2020ProvablyCT,
  title={Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation.},
  author={Shangtong Zhang and Bo Liu and Hengshuai Yao and Shimon Whiteson},
  journal={arXiv: Learning},
  year={2020}
}

@article{Hasselt2015LearningTP,
  title={Learning to Predict Independent of Span},
  author={H. V. Hasselt and R. Sutton},
  journal={ArXiv},
  year={2015},
  volume={abs/1508.04582}
}

@inproceedings{bengio2020interference,
    title={Interference and Generalization in Temporal Difference Learning},
    author={Emmanuel Bengio and Joelle Pineau and Doina Precup},
    year={2020},
    eprint={2003.06350},
    booktitle = {International Conference on Machine Learning},
    year      = {2020},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@inproceedings{liu2019utility,
title={The utility of sparse representations for control in reinforcement learning},
author={Liu, Vincent and Kumaraswamy, Raksha and Le, Lei and White, Martha},
booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
volume={33},
pages={4384--4391},
year={2019}
}

@article{Hasselt2019WhenTU,
  title={When to use parametric models in reinforcement learning?},
  author={H. V. Hasselt and Matteo Hessel and J. Aslanides},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.05243}
}

@article{Xu2018MetaGradientRL,
  title={Meta-Gradient Reinforcement Learning},
  author={Zhongwen Xu and H. V. Hasselt and D. Silver},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.09801}
}

@article{White2016AGA,
  title={A Greedy Approach to Adapting the Trace Parameter for Temporal Difference Learning},
  author={Martha White and A. White},
  journal={ArXiv},
  year={2016},
  volume={abs/1607.00446}
}

@article{Peng1993EfficientLA,
  title={Efficient learning and planning within the Dyna framework},
  author={J. Peng and R. Williams},
  journal={IEEE International Conference on Neural Networks},
  year={1993},
  pages={168-174 vol.1}
}

@inproceedings{McMahan2005FastEP,
  title={Fast Exact Planning in Markov Decision Processes},
  author={H. McMahan and G. Gordon},
  booktitle={ICAPS},
  year={2005}
}

@article{Moore2004PrioritizedSR,
  title={Prioritized Sweeping: Reinforcement Learning with Less Data and Less Time},
  author={A. Moore and C. Atkeson},
  journal={Machine Learning},
  year={2004},
  volume={13},
  pages={103-130}
} 
@article{Sutton2008DynaStylePW,
  title={Dyna-Style Planning with Linear Function Approximation and Prioritized Sweeping},
  author={R. Sutton and Csaba Szepesvari and A. Geramifard and Michael Bowling},
  journal={ArXiv},
  year={2008},
  volume={abs/1206.3285}
}

@inproceedings{Asis2018MultistepRL,
  title={Multi-step Reinforcement Learning: A Unifying Algorithm},
  author={Kristopher De Asis and J. Hernandez-Garcia and G. Holland and R. Sutton},
  booktitle={AAAI},
  year={2018}
}

@inproceedings{Thomas2014BiasIN,
  title={Bias in Natural Actor-Critic Algorithms},
  author={P. Thomas},
  booktitle={ICML},
  year={2014}
}

@article{Nix1994EstimatingTM,
  title={Estimating the mean and variance of the target probability distribution},
  author={D. Nix and A. Weigend},
  journal={Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94)},
  year={1994},
  volume={1},
  pages={55-60 vol.1}
}

@article{Yu2012LeastST,
  title={Least Squares Temporal Difference Methods: An Analysis under General Conditions},
  author={Huizhen Yu},
  journal={SIAM J. Control. Optim.},
  year={2012},
  volume={50},
  pages={3310-3343}
}

@inproceedings{Sutton2014ANQ,
  title={A new Q(lambda) with interim forward view and Monte Carlo equivalence},
  author={R. Sutton and A. R. Mahmood and Doina Precup and H. V. Hasselt},
  booktitle={ICML},
  year={2014}
}
@inproceedings{Maei2010GQAG,
  title={GQ(λ): A general gradient algorithm for temporal-difference prediction learning with eligibility traces},
  author={H. Maei and R. Sutton},
  year={2010}
}
@inproceedings{Sutton1995TDMM,
  title={TD Models: Modeling the World at a Mixture of Time Scales},
  author={R. Sutton},
  booktitle={ICML},
  year={1995}
}

@inproceedings{Bertsekas1989ParallelAD,
  title={Parallel and Distributed Computation: Numerical Methods},
  author={D. Bertsekas and J. Tsitsiklis},
  year={1989}
}

@article{Yu2008NewEB,
  title={New error bounds for approximations from projected linear equations},
  author={Huizhen Yu and D. Bertsekas},
  journal={2008 46th Annual Allerton Conference on Communication, Control, and Computing},
  year={2008},
  pages={1116-1123}
}

@inproceedings{Sutton2009FastGM,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={R. Sutton and H. Maei and Doina Precup and S. Bhatnagar and D. Silver and Csaba Szepesvari and Eric Wiewiora},
  booktitle={ICML '09},
  year={2009}
}

@inproceedings{Precup2001OffPolicyTD,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Doina Precup and R. Sutton and S. Dasgupta},
  booktitle={ICML},
  year={2001}
}

@article{Hallak2016GeneralizedET,
  title={Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis},
  author={Assaf Hallak and A. Tamar and R. Munos and Shie Mannor},
  journal={ArXiv},
  year={2016},
  volume={abs/1509.05172}
}

@article{Bertsekas2016ProximalAA,
  title={Proximal Algorithms and Temporal Differences for Large Linear Systems: Extrapolation, Approximation, and Simulation},
  author={Dimitri P. Bertsekas},
  journal={ArXiv},
  year={2016},
  volume={abs/1610.05427}
}

@article{Liu2017O2TDO,
  title={O2TD: (Near)-Optimal Off-Policy TD Learning},
  author={B. Liu and Daoming Lyu and Wen Dong and S. Biaz},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.05147}
}

@article{Scherrer2010ShouldOC,
  title={Should one compute the Temporal Difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={B. Scherrer},
  journal={ArXiv},
  year={2010},
  volume={abs/1011.4362}
}

@inproceedings{Schoknecht2002OptimalityOR,
  title={Optimality of Reinforcement Learning Algorithms with Linear Function Approximation},
  author={Ralf Schoknecht},
  booktitle={NIPS},
  year={2002}
}

@inproceedings{Harutyunyan2019TheTC,
  title={The Termination Critic},
  author={A. Harutyunyan and W. Dabney and Diana Borsa and N. Heess and R. Munos and Doina Precup},
  booktitle={AISTATS},
  year={2019}
}

@article{Mihatsch2004RiskSensitiveRL,
  title={Risk-Sensitive Reinforcement Learning},
  author={O. Mihatsch and R. Neuneier},
  journal={Machine Learning},
  year={2004},
  volume={49},
  pages={267-290}
}

@inproceedings{Zhang2020LearningRK,
  title={Learning Retrospective Knowledge with Reverse Reinforcement Learning},
  author={Shangtong Zhang and Vivek Veeriah and Shimon Whiteson},
  year={2020}
}

@article{Morimura2010DerivativesOL,
  title={Derivatives of Logarithmic Stationary Distributions for Policy Gradient Reinforcement Learning},
  author={Tetsuro Morimura and Eiji Uchibe and Junichiro Yoshimoto and Jan Peters and Kenji Doya},
  journal={Neural Computation},
  year={2010},
  volume={22},
  pages={342-376}
}

@article{Hallak2017ConsistentOO,
  title={Consistent On-Line Off-Policy Evaluation},
  author={Assaf Hallak and Shie Mannor},
  journal={ArXiv},
  year={2017},
  volume={abs/1702.07121}
}

@inproceedings{Gelada2019OffPolicyDR,
  title={Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift},
  author={Carles Gelada and Marc G. Bellemare},
  booktitle={AAAI},
  year={2019}
}

@article{White2017UnifyingTS,
  title={Unifying Task Specification in Reinforcement Learning},
  author={Martha White},
  journal={ArXiv},
  year={2017},
  volume={abs/1609.01995}
}

@inproceedings{Precup2001OffPolicyTD,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Doina Precup and Richard S. Sutton and Sanjoy Dasgupta},
  booktitle={ICML},
  year={2001}
}

@article{Mahmood2015EmphaticTL,
  title={Emphatic Temporal-Difference Learning},
  author={Ashique Rupam Mahmood and Huizhen Yu and Martha White and Richard S. Sutton},
  journal={ArXiv},
  year={2015},
  volume={abs/1507.01569}
}

@inproceedings{Yu2015OnCO,
  title={On Convergence of Emphatic Temporal-Difference Learning},
  author={Huizhen Yu},
  booktitle={COLT},
  year={2015}
}

@inproceedings{Zhang2019GeneralizedOA,
  title={Generalized Off-Policy Actor-Critic},
  author={Shangtong Zhang and Wendelin B{\"o}hmer and Shimon Whiteson},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{Imani2018AnOP,
  title={An Off-policy Policy Gradient Theorem Using Emphatic Weightings},
  author={Ehsan Imani and Eric Graves and Martha White},
  booktitle={NeurIPS},
  year={2018}
}

@article{White2016InvestigatingPL,
  title={Investigating Practical Linear Temporal Difference Learning},
  author={Adam M. White and Martha White},
  journal={ArXiv},
  year={2016},
  volume={abs/1602.08771}
}

@article{Degris2012OffPolicyA,
  title={Off-Policy Actor-Critic},
  author={Thomas Degris and Martha White and Richard S. Sutton},
  journal={ArXiv},
  year={2012},
  volume={abs/1205.4839}
}
@article{Misra2019KinematicSA,
  title={Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning},
  author={Dipendra Kumar Misra and Mikael Henaff and Akshay Krishnamurthy and John Langford},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.05815}
}

@article{Hasselt2020ExpectedET,
  title={Expected Eligibility Traces},
  author={Hado {van Hasselt} and Sephora Madjiheurem and Matteo Hessel and David Silver and Andr{\'e} Noll Barreto and Diana Borsa},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.01839}
}

@inproceedings{Efroni2019HowTC,
  title={How to Combine Tree-Search Methods in Reinforcement Learning},
  author={Yonathan Efroni and Gal Dalal and Bruno Scherrer and Shie Mannor},
  booktitle={AAAI},
  year={2019}
}


@inproceedings{Kemeny1983FiniteMC,
  title={Finite Markov chains},
  author={J. Kemeny and J. Snell},
  year={1983}
}

@article{Pan2019HillCO,
  title={Hill Climbing on Value Estimates for Search-control in Dyna},
  author={Yangchen Pan and Hengshuai Yao and Amir-massoud Farahmand and Martha White},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.07791}
}

@article{Pan2020FrequencybasedSI,
  title={Frequency-based Search-control in Dyna},
  author={Yangchen Pan and Jincheng Mei and Amir-massoud Farahmand},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.05822}
}

@article{Moran2019RetrospectiveMI,
  title={Retrospective model-based inference guides model-free credit assignment},
  author={Rani Moran and Mehdi Keramati and Peter Dayan and Raymond J. Dolan},
  journal={Nature Communications},
  year={2019},
  volume={10}
}

@inproceedings{Efroni2018BeyondTO,
  title={Beyond the One Step Greedy Approach in Reinforcement Learning},
  author={Yonathan Efroni and Gal Dalal and B. Scherrer and Shie Mannor},
  booktitle={ICML},
  year={2018}
}

@inproceedings{Efroni2019HowTC,
  title={How to Combine Tree-Search Methods in Reinforcement Learning},
  author={Yonathan Efroni and Gal Dalal and B. Scherrer and Shie Mannor},
  booktitle={AAAI},
  year={2019}
}

@article{Efroni2019MultiStepGA,
  title={Multi-Step Greedy and Approximate Real Time Dynamic Programming},
  author={Yonathan Efroni and Mohammad Ghavamzadeh and Shie Mannor},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.04236}
}

@article{Efroni2018MultipleStepGP,
  title={Multiple-Step Greedy Policies in Online and Approximate Reinforcement Learning},
  author={Yonathan Efroni and Gal Dalal and B. Scherrer and Shie Mannor},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.07956}
}

@inproceedings{Tomar2019MultistepGR,
  title={Multi-step Greedy Reinforcement Learning Algorithms},
  author={M. Tomar and Yonathan Efroni and Mohammad Ghavamzadeh},
  year={2019}
}

@article{Efroni2019TightRB,
  title={Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies},
  author={Yonathan Efroni and Nadav Merlis and M. Ghavamzadeh and Shie Mannor},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.11527}
}

@article{Edwards2018ForwardBackwardRL,
  title={Forward-Backward Reinforcement Learning},
  author={A. Edwards and Laura Downs and James C. Davidson},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.10227}
}

@article{Goyal2019RecallTB,
  title={Recall Traces: Backtracking Models for Efficient Reinforcement Learning},
  author={Anirudh Goyal and Philemon Brakel and W. Fedus and Soumye Singhal and T. Lillicrap and S. Levine and H. Larochelle and Yoshua Bengio},
  journal={ArXiv},
  year={2019},
  volume={abs/1804.00379}
}

@inproceedings{Sutton2011HordeAS,
  title={Horde: a scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={R. Sutton and Joseph Modayil and M. Delp and T. Degris and P. Pilarski and Adam White and Doina Precup},
  booktitle={AAMAS},
  year={2011}
}

@article{Xu2018MetaGradientRL,
  title={Meta-Gradient Reinforcement Learning},
  author={Zhongwen Xu and H. V. Hasselt and D. Silver},
  journal={ArXiv},
  year={2018},
  volume={abs/1805.09801}
} 

@article{Oh2020DiscoveringRL,
  title={Discovering Reinforcement Learning Algorithms},
  author={Junhyuk Oh and Matteo Hessel and W. Czarnecki and Zhongwen Xu and H. V. Hasselt and S. Singh and D. Silver},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.08794}
}

@article{Xu2020MetaGradientRL,
  title={Meta-Gradient Reinforcement Learning with an Objective Discovered Online},
  author={Zhongwen Xu and H. V. Hasselt and Matteo Hessel and Junhyuk Oh and S. Singh and D. Silver},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.08433}
}
@article{Sutton1999BetweenMA,
  title={Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning},
  author={R. Sutton and Doina Precup and Satinder Singh},
  journal={Artif. Intell.},
  year={1999},
  volume={112},
  pages={181-211}
}

@inproceedings{Ke2018SparseAB,
  title={Sparse Attentive Backtracking: Temporal CreditAssignment Through Reminding},
  author={Nan Rosemary Ke and Anirudh Goyal and Olexa Bilaniuk and Jonathan Binas and M. Mozer and C. Pal and Yoshua Bengio},
  booktitle={NeurIPS},
  year={2018}
}

@article{Pitis2018SourceTF,
  title={Source Traces for Temporal Difference Learning},
  author={Silviu Pitis},
  journal={ArXiv},
  year={2018},
  volume={abs/1902.02907}
}

@article{Satija2020ConstrainedMD,
  title={Constrained Markov Decision Processes via Backward Value Functions},
  author={Harsh Satija and Philip Amortila and Joelle Pineau},
  journal={ArXiv},
  year={2020},
  volume={abs/2008.11811}
}

@article{Asis2018PerdecisionMT,
  title={Per-decision Multi-step Temporal Difference Learning with Control Variates},
  author={Kristopher De Asis and R. Sutton},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.01830}
}

@article{White2017UnifyingTS,
  title={Unifying Task Specification in Reinforcement Learning},
  author={Martha White},
  journal={ArXiv},
  year={2017},
  volume={abs/1609.01995}
}

@article{Peng1996IncrementalMQ,
  title={Incremental multi-step Q-learning},
  author={Jing Peng and R. J. Williams},
  journal={Machine Learning},
  year={1996},
  volume={22},
  pages={283-290}
}

@article{Rezende2020CausallyCP,
  title={Causally Correct Partial Models for Reinforcement Learning},
  author={Danilo Jimenez Rezende and Ivo Danihelka and George Papamakarios and Nan Rosemary Ke and Ray Jiang and T. Weber and K. Gregor and Hamza Merzic and F. Viola and J. Wang and Jovana Mitrovic and F. Besse and Ioannis Antonoglou and Lars Buesing},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.02836}
}

@inproceedings{Talvitie2008SimpleLM,
  title={Simple Local Models for Complex Dynamical Systems},
  author={Erik Talvitie and S. Singh},
  booktitle={NIPS},
  year={2008}
}