\begin{thebibliography}{10}

\bibitem{ai2003interaction}
Chunrong Ai and Edward~C Norton.
\newblock Interaction terms in logit and probit models.
\newblock {\em Economics letters}, 80(1):123--129, 2003.

\bibitem{cai2018cascade}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Cascade r-cnn: Delving into high quality object detection.
\newblock In {\em CVPR}, pages 6154--6162, 2018.

\bibitem{chen2019hybrid}
Kai Chen, Jiangmiao Pang, Jiaqi Wang, Yu~Xiong, Xiaoxiao Li, Shuyang Sun,
  Wansen Feng, Ziwei Liu, Jianping Shi, Wanli Ouyang, et~al.
\newblock Hybrid task cascade for instance segmentation.
\newblock In {\em CVPR}, pages 4974--4983, 2019.

\bibitem{chen2020dynamic}
Yinpeng Chen, Xiyang Dai, Mengchen Liu, Dongdong Chen, Lu~Yuan, and Zicheng
  Liu.
\newblock Dynamic convolution: Attention over convolution kernels.
\newblock In {\em CVPR}, pages 11030--11039, 2020.

\bibitem{chen2022vision}
Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong Lu, Jifeng Dai, and
  Yu~Qiao.
\newblock Vision transformer adapter for dense predictions.
\newblock {\em arXiv preprint arXiv:2205.08534}, 2022.

\bibitem{cheng2021masked}
Bowen Cheng, Ishan Misra, Alexander~G Schwing, Alexander Kirillov, and Rohit
  Girdhar.
\newblock Masked-attention mask transformer for universal image segmentation.
\newblock {\em arXiv preprint arXiv:2112.01527}, 2021.

\bibitem{cheng2022masked}
Bowen Cheng, Ishan Misra, Alexander~G Schwing, Alexander Kirillov, and Rohit
  Girdhar.
\newblock Masked-attention mask transformer for universal image segmentation.
\newblock In {\em CVPR}, pages 1290--1299, 2022.

\bibitem{cheng2021maskformer}
Bowen Cheng, Alex Schwing, and Alexander Kirillov.
\newblock Per-pixel classification is not all you need for semantic
  segmentation.
\newblock {\em NeurIPS}, 34, 2021.

\bibitem{chu2021twins}
Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo~Zhang, Haibing Ren, Xiaolin Wei,
  Huaxia Xia, and Chunhua Shen.
\newblock Twins: Revisiting the design of spatial attention in vision
  transformers.
\newblock {\em NeurIPS}, 34, 2021.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em CVPRW}, pages 702--703, 2020.

\bibitem{cui2022mixformer}
Yutao Cui, Jiang Cheng, Limin Wang, and Gangshan Wu.
\newblock Mixformer: End-to-end tracking with iterative mixed attention.
\newblock {\em CVPR}, 2022.

\bibitem{dai2021coatnet}
Zihang Dai, Hanxiao Liu, Quoc~V Le, and Mingxing Tan.
\newblock Coatnet: Marrying convolution and attention for all data sizes.
\newblock {\em NeurIPS}, 34:3965--3977, 2021.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, pages 248--255, 2009.

\bibitem{ding2022scaling}
Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, and
  Jian Sun.
\newblock Scaling up your kernels to 31x31: Revisiting large kernel design in
  cnns.
\newblock {\em CVPR}, 2022.

\bibitem{dong2021cswin}
Xiaoyi Dong, Jianmin Bao, Dongdong Chen, Weiming Zhang, Nenghai Yu, Lu~Yuan,
  Dong Chen, and Baining Guo.
\newblock Cswin transformer: A general vision transformer backbone with
  cross-shaped windows.
\newblock {\em CVPR}, 2022.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{d2021convit}
St{\'e}phane dâ€™Ascoli, Hugo Touvron, Matthew~L Leavitt, Ari~S Morcos, Giulio
  Biroli, and Levent Sagun.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock In {\em ICML}, pages 2286--2296, 2021.

\bibitem{fan2021multiscale}
Haoqi Fan, Bo~Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock In {\em ICCV}, pages 6824--6835, 2021.

\bibitem{guo2022van}
Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, and Shi-Min Hu.
\newblock Visual attention network.
\newblock {\em arXiv preprint arXiv:2202.09741}, 2022.

\bibitem{han2021demystifying}
Qi~Han, Zejia Fan, Qi~Dai, Lei Sun, Ming-Ming Cheng, Jiaying Liu, and Jingdong
  Wang.
\newblock Demystifying local vision transformer: Sparse connectivity, weight
  sharing, and dynamic weight.
\newblock {\em arXiv preprint arXiv:2106.04263}, 2021.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em ICCV}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, pages 770--778, 2016.

\bibitem{hochreiter1997lstm}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{howard2017mobilenets}
Andrew~G Howard, Menglong Zhu, Bo~Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, Marco Andreetto, and Hartwig Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock {\em arXiv preprint arXiv:1704.04861}, 2017.

\bibitem{senet}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In {\em CVPR}, pages 7132--7141, 2018.

\bibitem{stochasticdepth}
Gao Huang, Yu~Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In {\em ECCV}, pages 646--661, 2016.

\bibitem{huang2021fapn}
Shihua Huang, Zhichao Lu, Ran Cheng, and Cheng He.
\newblock Fapn: Feature-aligned pyramid network for dense image prediction.
\newblock In {\em ICCV}, pages 864--873, 2021.

\bibitem{jia2016dynamic}
Xu~Jia, Bert De~Brabandere, Tinne Tuytelaars, and Luc~V Gool.
\newblock Dynamic filter networks.
\newblock {\em NeurIPS}, 29, 2016.

\bibitem{jiang2021token}
Zihang Jiang, Qibin Hou, Li~Yuan, Daquan Zhou, Xiaojie Jin, Anran Wang, and
  Jiashi Feng.
\newblock Token labeling: Training a 85.5\% top-1 accuracy vision transformer
  with 56m parameters on imagenet.
\newblock {\em arXiv preprint arXiv:2104.10858}, 2021.

\bibitem{kolesnikov2020big}
Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung,
  Sylvain Gelly, and Neil Houlsby.
\newblock Big transfer (bit): General visual representation learning.
\newblock In {\em ECCV}, pages 491--507. Springer, 2020.

\bibitem{krizhevsky2012alex}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em NeurIPS}, 25:1097--1105, 2012.

\bibitem{lenet}
Yann LeCun, Bernhard Boser, John~S Denker, Donnie Henderson, Richard~E Howard,
  Wayne Hubbard, and Lawrence~D Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock {\em Neural computation}, 1(4):541--551, 1989.

\bibitem{lerman2021explaining}
Samuel Lerman, Charles Venuto, Henry Kautz, and Chenliang Xu.
\newblock Explaining local, global, and higher-order interactions in deep
  learning.
\newblock In {\em ICCV}, pages 1224--1233, 2021.

\bibitem{li2022exploring}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock {\em arXiv preprint arXiv:2203.16527}, 2022.

\bibitem{li2022mvitv2}
Yanghao Li, Chao-Yuan Wu, Haoqi Fan, Karttikeya Mangalam, Bo~Xiong, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Mvitv2: Improved multiscale vision transformers for classification
  and detection.
\newblock In {\em CVPR}, pages 4804--4814, 2022.

\bibitem{lin2017fpn}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em CVPR}, pages 2117--2125, 2017.

\bibitem{lin2017feature}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em CVPR}, pages 2117--2125, 2017.

\bibitem{lin2014coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, pages 740--755. Springer, 2014.

\bibitem{gmlp}
Hanxiao Liu, Zihang Dai, David So, and Quoc~V Le.
\newblock Pay attention to mlps.
\newblock {\em NeurIPS}, 34:9204--9215, 2021.

\bibitem{liu2022dynamic}
Kai Liu, Tianyi Wu, Cong Liu, and Guodong Guo.
\newblock Dynamic group transformer: A general vision transformer backbone with
  dynamic group attention.
\newblock {\em IJCAI}, 2022.

\bibitem{liu2021swinv2}
Ze~Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue
  Cao, Zheng Zhang, Li~Dong, et~al.
\newblock Swin transformer v2: Scaling up capacity and resolution.
\newblock {\em arXiv preprint arXiv:2111.09883}, 2021.

\bibitem{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock {\em arXiv preprint arXiv:2103.14030}, 2021.

\bibitem{liu2022convnet}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
  and Saining Xie.
\newblock A convnet for the 2020s.
\newblock {\em CVPR}, 2022.

\bibitem{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{acmix}
Xuran Pan, Chunjiang Ge, Rui Lu, Shiji Song, Guanfu Chen, Zeyi Huang, and Gao
  Huang.
\newblock On the integration of self-attention and convolution.
\newblock {\em arXiv preprint arXiv:2111.14556}, 2021.

\bibitem{rao2021global}
Yongming Rao, Wenliang Zhao, Zheng Zhu, Jiwen Lu, and Jie Zhou.
\newblock Global filter networks for image classification.
\newblock In {\em NeurIPS}, 2021.

\bibitem{ridnik2021imagenet}
Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, and Lihi Zelnik-Manor.
\newblock Imagenet-21k pretraining for the masses.
\newblock {\em arXiv:2104.10972}, 2021.

\bibitem{riquelme2021scaling}
Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim Neumann, Rodolphe
  Jenatton, Andr{\'e} Susano~Pinto, Daniel Keysers, and Neil Houlsby.
\newblock Scaling vision with sparse mixture of experts.
\newblock {\em NeurIPS}, 34, 2021.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{szegedy2015going}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em CVPR}, pages 1--9, 2015.

\bibitem{tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, pages 6105--6114, 2019.

\bibitem{touvron2020deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv preprint arXiv:2012.12877}, 2020.

\bibitem{touvron2021going}
Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and
  Herv{\'e} J{\'e}gou.
\newblock Going deeper with image transformers.
\newblock {\em arXiv preprint arXiv:2103.17239}, 2021.

\bibitem{tu2022maxim}
Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan
  Bovik, and Yinxiao Li.
\newblock Maxim: Multi-axis mlp for image processing.
\newblock In {\em CVPR}, pages 5769--5780, 2022.

\bibitem{tu2022maxvit}
Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan
  Bovik, and Yinxiao Li.
\newblock Maxvit: Multi-axis vision transformer.
\newblock {\em ECCV}, 2022.

\bibitem{Vaswani2017transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, pages 5998--6008, 2017.

\bibitem{wang2020linformer}
Sinong Wang, Belinda~Z Li, Madian Khabsa, Han Fang, and Hao Ma.
\newblock Linformer: Self-attention with linear complexity.
\newblock {\em arXiv preprint arXiv:2006.04768}, 2020.

\bibitem{wang2021pyramid}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock In {\em ICCV}, 2021.

\bibitem{DBLP:conf/iccv/SORT}
Yan Wang, Lingxi Xie, Chenxi Liu, Siyuan Qiao, Ya~Zhang, Wenjun Zhang, Qi~Tian,
  and Alan~L. Yuille.
\newblock {SORT:} second-order response transform for visual recognition.
\newblock In {\em {IEEE} International Conference on Computer Vision, {ICCV}
  2017, Venice, Italy, October 22-29, 2017}, pages 1368--1377. {IEEE} Computer
  Society, 2017.

\bibitem{wu2021cvt}
Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu~Yuan, and Lei
  Zhang.
\newblock Cvt: Introducing convolutions to vision transformers.
\newblock {\em arXiv preprint arXiv:2103.15808}, 2021.

\bibitem{wu2022pale}
Sitong Wu, Tianyi Wu, Haoru Tan, and Guodong Guo.
\newblock Pale transformer: A general vision transformer backbone with
  pale-shaped attention.
\newblock In {\em AAAI}, volume~36, pages 2731--2739, 2022.

\bibitem{xiao2018unified}
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In {\em ECCV}, pages 418--434, 2018.

\bibitem{xiao2021early}
Tete Xiao, Mannat Singh, Eric Mintun, Trevor Darrell, Piotr Doll{\'a}r, and
  Ross Girshick.
\newblock Early convolutions help transformers see better.
\newblock {\em NeurIPS}, 34:30392--30400, 2021.

\bibitem{yan2022multiview}
Shen Yan, Xuehan Xiong, Anurag Arnab, Zhichao Lu, Mi~Zhang, Chen Sun, and
  Cordelia Schmid.
\newblock Multiview transformers for video recognition.
\newblock {\em arXiv preprint arXiv:2201.04288}, 2022.

\bibitem{yang2022focal}
Jianwei Yang, Chunyuan Li, and Jianfeng Gao.
\newblock Focal modulation networks.
\newblock {\em arXiv preprint arXiv:2203.11926}, 2022.

\bibitem{yang2021focal}
Jianwei Yang, Chunyuan Li, Pengchuan Zhang, Xiyang Dai, Bin Xiao, Lu~Yuan, and
  Jianfeng Gao.
\newblock Focal attention for long-range interactions in vision transformers.
\newblock {\em NeurIPS}, 34, 2021.

\bibitem{yu2021metaformer}
Weihao Yu, Mi~Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi
  Feng, and Shuicheng Yan.
\newblock Metaformer is actually what you need for vision.
\newblock {\em arXiv preprint arXiv:2111.11418}, 2021.

\bibitem{yuan2021t2t}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis~EH
  Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock {\em arXiv:2101.11986}, 2021.

\bibitem{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock {\em arXiv preprint arXiv:1605.07146}, 2016.

\bibitem{zhang2022dino}
Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel~M Ni, and
  Heung-Yeung Shum.
\newblock Dino: Detr with improved denoising anchor boxes for end-to-end object
  detection.
\newblock {\em arXiv preprint arXiv:2203.03605}, 2022.

\bibitem{zhou2017scene}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em CVPR}, pages 633--641, 2017.

\end{thebibliography}
