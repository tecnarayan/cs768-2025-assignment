@inproceedings{10.5555/3495724.3497409,
author = {Zaoui, Ahmed and Denis, Christophe and Hebiri, Mohamed},
title = {Regression with reject option and application to kNN},
year = {2020},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
}

@article{6beb6e26-9d87-3973-947c-6322c6dba60d,
 author = {Jianqing Fan and Qiwei Yao},
 journal = {Biometrika},
 title = {Efficient Estimation of Conditional Variance Functions in Stochastic Regression},
 year = {1998}
}

@book{Vovk2005,
author = {Vovk, Vladimir and Gammerman, Alex and Shafer, Glenn},
title = {Algorithmic Learning in a Random World},
year = {2005},
isbn = {0387001522},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@inproceedings{Chung2021_Cali,
 author = {Chung, Youngseog and Neiswanger, Willie and Char, Ian and Schneider, Jeff},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty Quantification},
 year = {2021}
}

@article{RAO1982,
title = {Diversity and dissimilarity coefficients: A unified approach},
journal = {Theoretical Population Biology},
year = {1982},
author = {C.Radhakrishna Rao},
}

@inproceedings{Tagasovska_2019,
 author = {Tagasovska, Natasa and Lopez-Paz, David},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Single-Model Uncertainties for Deep Learning},
 year = {2019}
}

@article{Fasiolo2021,
  author = {Fasiolo, Matteo and Wood, Simon N. and Zaffran, Margaux and Nedellec, Raphael and Goude, Yannig},
  journal = {Journal of the American Statistical Association},
  title = {Fast Calibrated Additive Quantile Regression},
  year = 2021
}


@InProceedings{hernandez-lobatoc15,
  title = 	 {Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks},
  author = 	 {Hernandez-Lobato, Jose Miguel and Adams, Ryan},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  year = 	 {2015},
}




@inproceedings{DBLP:journals/corr/KingmaB14,
  author       = {Diederik P. Kingma and
                  Jimmy Ba},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {3rd International Conference on Learning Representations},
  year         = {2015},

}

@ARTICLE{9773978,
  author={Picot, Marine and Messina, Francisco and Boudiaf, Malik and Labeau, Fabrice and Ayed, Ismail Ben and Piantanida, Pablo},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Adversarial Robustness Via Fisher-Rao Regularization}, 
  year={2023},
  volume={45},
  number={3},
  pages={2698-2710},
  keywords={Robustness;Manifolds;Training;Perturbation methods;Standards;Neural networks;Adversarial machine learning;Adversarial regularization;adversarial training;computer vision;deep learning;fisher-rao distance;information geometry;neural networks;safety AI},
  doi={10.1109/TPAMI.2022.3174724}}



@InProceedings{KNIFE_2022,
  title = 	 {A Differential Entropy Estimator for Training Neural Networks},
  author =       {Pichler, Georg and Colombo, Pierre Jean A. and Boudiaf, Malik and Koliander, G{\"u}nther and Piantanida, Pablo},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  year = 	 {2022},
}


@InProceedings{pmlr-v108-kivaranovic20a,
  title = 	 {Adaptive, Distribution-Free Prediction Intervals for Deep Networks},
  author =       {Kivaranovic, Danijel and Johnson, Kory D. and Leeb, Hannes},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  year = 	 {2020},
}

@InProceedings{pmlr-v124-saleh-salem20a,
  title = 	 {Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles},
  author =       {S. Salem, T\'arik and Langseth, Helge and Ramampiaro, Heri},
  booktitle = 	 {Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)},
  year = 	 {2020},
}



@article{DBLP:journals/corr/abs-2205-14568,
  author       = {Biprateep Dey and
                  David Zhao and
                  Jeffrey A. Newman and
                  Brett H. Andrews and
                  Rafael Izbicki and
                  Ann B. Lee},
  title        = {Calibrated Predictive Distributions via Diagnostics for Conditional
                  Coverage},
  journal      = {CoRR},
  year         = {2022},
}

@article{AUROC_2004,
  author       = { Bewick, V. and Cheek, L. and Ball, J. },
  title        = {Statistics review 13: receiver operating characteristic curves.},
  journal      = {Crit Care.},
  year         = {2004},
doi = {10.1186/cc3000},
}


@InProceedings{pmlr-v37-ioffe15,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/ioffe15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/ioffe15.html},
  abstract = 	 {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.}
}


@misc{Wang2023,
      title={Generative Quantile Regression with Variability Penalty}, 
      author={Shijie Wang and Minsuk Shin and Ray Bai},
      year={2023},
      eprint={2301.03661},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@misc{,
      title={Conditional Coverage Estimation for High-Quality Prediction Intervals}, 
      author={Ziyi Huang, Henry Lam, Haofeng Zhang},
      year={2023},
      eprint={},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
https://openreview.net/forum?id=GBjukBaBLXK

@article{Huang2023,
    title={Conditional Coverage Estimation for High-Quality Prediction Intervals}, 
	journal = {J. Syst. Sci. Syst. Eng.},
	year = {2023},
	author={Ziyi Huang, Henry Lam, Haofeng Zhang},

}


@inproceedings{Zhao2020,
author = {Zhao, Shengjia and Ma, Tengyu and Ermon, Stefano},
title = {Individual calibration with randomized forecasting},
year = {2020},
publisher = {JMLR.org},
abstract = {Machine learning applications often require calibrated predictions, e.g. a 90\% credible interval should contain the true outcome 90\% of the times. However, typical definitions of calibration only require this to hold on average, and offer no guarantees on predictions made on individual samples. Thus, predictions can be systematically over or under confident on certain subgroups, leading to issues of fairness and potential vulnerabilities. We show that calibration for individual samples is possible in the regression setup if the predictions are randomized, i.e. outputting randomized credible intervals. Randomization removes systematic bias by trading off bias with variance. We design a training objective to enforce individual calibration and use it to train randomized regression functions. The resulting models are more calibrated for arbitrarily chosen subgroups of the data, and can achieve higher utility in decision making against adversaries that exploit miscalibrated predictions.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {1056},
numpages = {11},
series = {ICML'20}
}
@article{pnas.1907377117,
author = {Vegard Antun  and Francesco Renna  and Clarice Poon  and Ben Adcock  and Anders C. Hansen },
title = {On instabilities of deep learning in image reconstruction and the potential costs of AI},
journal = {Proceedings of the National Academy of Sciences},
volume = {117},
number = {48},
pages = {30088-30095},
year = {2020},
doi = {10.1073/pnas.1907377117},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1907377117},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1907377117},
abstract = {Deep learning, due to its unprecedented success in tasks such as image classification, has emerged as a new tool in image reconstruction with potential to change the field. In this paper, we demonstrate a crucial phenomenon: Deep learning typically yields unstable methods for image reconstruction. The instabilities usually occur in several forms: 1) Certain tiny, almost undetectable perturbations, both in the image and sampling domain, may result in severe artefacts in the reconstruction; 2) a small structural change, for example, a tumor, may not be captured in the reconstructed image; and 3) (a counterintuitive type of instability) more samples may yield poorer performance. Our stability test with algorithms and easy-to-use software detects the instability phenomena. The test is aimed at researchers, to test their networks for instabilities, and for government agencies, such as the Food and Drug Administration (FDA), to secure safe use of deep learning methods.}}



@inproceedings{
ritter2018a,
title={A Scalable Laplace Approximation for Neural Networks},
author={Hippolyt Ritter and Aleksandar Botev and David Barber},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=Skdvd2xAZ},
}


@article{DBLP:journals/jmlr/ZhouLWC2021,
  author       = {Tianhui Zhou and
                  Yitong Li and
                  Yuan Wu and
                  David E. Carlson},
  title        = {Estimating Uncertainty Intervals from Collaborating Networks},
  journal      = {J. Mach. Learn. Res.},
  year         = {2021},
}




@InProceedings{Marx_modular_2022,
  title = 	 {Modular Conformal Calibration},
  author =       {Marx, Charles and Zhao, Shengjia and Neiswanger, Willie and Ermon, Stefano},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  year = 	 {2022},
  }

@inproceedings{Lakshminarayanan17,
  author    = {Balaji Lakshminarayanan and
               Alexander Pritzel and
               Charles Blundell},
  title     = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems},
  year      = {2017},
}
@InProceedings{pmlr-v206-alaa23a,
  title = 	 {Conformalized Unconditional Quantile Regression},
  author =       {Alaa, Ahmed M. and Hussain, Zeshan and Sontag, David},
  booktitle = 	 {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  year = 	 {2023},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

Evaluating and Calibrating Uncertainty Prediction in Regression Tasks

@article{Foygel2020_2,
author = {Rina Foygel Barber},
title = {{Is distribution-free inference possible for binary regression?}},
journal = {Electronic Journal of Statistics},
year = {2020},
}

@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  year = 	 {2016},
}

@inproceedings{Romano2019,
 author = {Romano, Yaniv and Patterson, Evan and Candes, Emmanuel},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Conformalized Quantile Regression},
 year = {2019}
}

@book{Koenker_2005, place={Cambridge}, series={Econometric Society Monographs}, title={Quantile Regression}, publisher={Cambridge University Press}, author={Koenker, Roger}, year={2005}, collection={Econometric Society Monographs}}


@Article{pinball78,
  author={Koenker, Roger W and Bassett, Gilbert, Jr},
  title={{Regression Quantiles}},
  journal={Econometrica},
  year=1978,
  }

@misc{UCI,
  author = {Kelly, Markelle and Longjohn, Rachel  and  Nottingham, Kolby},
  year = {},
  title = {UCI Machine Learning Repository},
  url = {https://archive.ics.uci.edu},
  institution = {University of California, Irvine, School of Information and Computer Sciences}
} 





@inproceedings{Kendall2017,
author = {Kendall, Alex and Gal, Yarin},
title = {What uncertainties do we need in Bayesian deep learning for computer vision?},
year = {2017},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
}

  


@inproceedings{Kuleshov2018AccurateUF,
  author       = {Volodymyr Kuleshov and
                  Nathan Fenner and
                  Stefano Ermon},
 
  title        = {Accurate Uncertainties for Deep Learning Using Calibrated Regression},
  booktitle    = {Proceedings of the 35th International Conference on Machine Learning},
  year         = {2018},
}





@inproceedings{SharmaAzizanEtAl2021,
  author = {Sharma, A. and Azizan, N. and Pavone, M.},
  title = {Sketching Curvature for Efficient Out-of-Distribution Detection for Deep Neural Networks},
  booktitle = {{Proc. Conf. on Uncertainty in Artificial Intelligence}},
  year = {2021},
  
}


@InProceedings{Papadopoulos2002,
author="Papadopoulos, Harris
and Proedrou, Kostas
and Vovk, Volodya
and Gammerman, Alex",
editor="Elomaa, Tapio
and Mannila, Heikki
and Toivonen, Hannu",
title="Inductive Confidence Machines for Regression",
booktitle="Machine Learning: ECML 2002",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="345--356",
abstract="The existing methods of predicting with confidence give good accuracy and confidence values, but quite often are computationally inefficient. Some partial solutions have been suggested in the past. Both the original method and these solutions were based on transductive inference. In this paper we make a radical step of replacing transductive inference with inductive inference and define what we call the Inductive Confidence Machine (ICM); our main concern in this paper is the use of ICM in regression problems. The algorithm proposed in this paper is based on the Ridge Regression procedure (which is usually used for outputting bare predictions) and is much faster than the existing transductive techniques. The inductive approach described in this paper may be the only option available when dealing with large data sets.",
isbn="978-3-540-36755-0"
}

@InProceedings{pmlr-v80-pearce18a,
  title = 	 {High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach},
  author =       {Pearce, Tim and Brintrup, Alexandra and Zaki, Mohamed and Neely, Andy},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
}



@inproceedings{
gomes2023a,
title={A Data-Driven Measure of Relative Uncertainty for Misclassification Detection},
author={Eduardo Dadalto C{\^a}mara Gomes and Marco Romanelli and Georg Pichler and Pablo Piantanida},
booktitle={NeurIPS 2023 Workshop on Mathematics of Modern Machine Learning},
year={2023},
}

@inproceedings{ODIN_2018,
title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks},
author={Shiyu Liang and Yixuan Li and R. Srikant},
booktitle={International Conference on Learning Representations},
year={2018},
}
@article{Foygel2020,
    author = {Foygel Barber, Rina and Candès, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
    title = "{The limits of distribution-free conditional predictive inference}",
    journal = {Information and Inference: A Journal of the IMA},
    volume = {10},
    number = {2},
    pages = {455-482},
    year = {2020},
    month = {08},
    abstract = "{We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work, we aim to explore the space in between these two and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.}",
    issn = {2049-8772},
    doi = {10.1093/imaiai/iaaa017},
    url = {https://doi.org/10.1093/imaiai/iaaa017},
    eprint = {https://academic.oup.com/imaiai/article-pdf/10/2/455/38549621/iaaa017.pdf},
}

@Article{s22155540,
AUTHOR = {Levi, Dan and Gispan, Liran and Giladi, Niv and Fetaya, Ethan},
TITLE = {Evaluating and Calibrating Uncertainty Prediction in Regression Tasks},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {15},
ARTICLE-NUMBER = {5540},
URL = {https://www.mdpi.com/1424-8220/22/15/5540},
PubMedID = {35898047},
ISSN = {1424-8220},
ABSTRACT = {Predicting not only the target but also an accurate measure of uncertainty is important for many machine learning applications, and in particular, safety-critical ones. In this work, we study the calibration of uncertainty prediction for regression tasks which often arise in real-world systems. We show that the existing definition for the calibration of regression uncertainty has severe limitations in distinguishing informative from non-informative uncertainty predictions. We propose a new definition that escapes this caveat and an evaluation method using a simple histogram-based approach. Our method clusters examples with similar uncertainty prediction and compares the prediction with the empirical uncertainty on these examples. We also propose a simple, scaling-based calibration method that preforms as well as much more complex ones. We show results on both a synthetic, controlled problem and on the object detection bounding-box regression task using the COCO and KITTI datasets.},
DOI = {10.3390/s22155540}
}





@inproceedings{guo_calibration_2017,
  author       = {Chuan Guo and
                  Geoff Pleiss and
                  Yu Sun and
                  Kilian Q. Weinberger},
  title        = {On Calibration of Modern Neural Networks},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning},
  year         = {2017},
}



@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}



@article{amodei_concrete_2016,
  author       = {Dario Amodei and
                  Chris Olah and
                  Jacob Steinhardt and
                  Paul F. Christiano and
                  John Schulman and
                  Dan Man{\'{e}}},
  title        = {Concrete Problems in {AI} Safety},
  journal      = {CoRR},
  year         = {2016},
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
@article{KIUREGHIAN2009105,
title = {Aleatory or epistemic? Does it matter?},
journal = {Structural Safety},
year = {2009},
author = {Armen Der Kiureghian and Ove Ditlevsen},
}

@Book{Lehmann2005Testing,
  author       = {Lehmann, Erich Leo and Romano, Joseph P and Casella, George},
  publisher    = {Springer},
  title        = {Testing statistical hypotheses},
  year         = {2005},
  volume       = {3},
  creationdate = {2023-06-13T17:18:02},
  groups       = {Statistics},
}
@article{10.1145/3555803,
author = {Li, Bo and Qi, Peng and Liu, Bo and Di, Shuai and Liu, Jingen and Pei, Jiquan and Yi, Jinfeng and Zhou, Bowen},
title = {Trustworthy AI: From Principles to Practices},
year = {2023},
journal = {ACM Comput. Surv.},
}

@inproceedings{gomes2022igeood,
  title        = {Igeood: An Information Geometry Approach to Out-of-Distribution Detection},
  author       = {Eduardo Dadalto and Florence Alberge and Pierre Duhamel and Pablo Piantanida},
  year         = 2022,
  booktitle    = {International Conference on Learning Representations}
}

@inproceedings{ming2023how,
  title        = {How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?},
  author       = {Yifei Ming and Yiyou Sun and Ousmane Dia and Yixuan Li},
  year         = 2023,
  booktitle    = {The Eleventh International Conference on Learning Representations}
}

@inproceedings{CorbiereTBCP2019NeurIPS,
  title        = {Addressing Failure Prediction by Learning Model Confidence},
  author       = {Charles Corbi{\`{e}}re and Nicolas Thome and Avner Bar{-}Hen and Matthieu Cord and Patrick P{\'{e}}rez},
  year         = 2019,
  booktitle    = {Advances in Neural Information Processing Systems},
}

@inproceedings{HuangZZ2020NeurIPS,
  title        = {Self-Adaptive Training: beyond Empirical Risk Minimization},
  author       = {Lang Huang and Chao Zhang and Hongyang Zhang},
  year         = 2020,
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual}
}

@inproceedings{GraneseRGPP2021NeurIPS,
  title        = {{DOCTOR:} {A} Simple Method for Detecting Misclassification Errors},
  author       = {Federica Granese and Marco Romanelli and Daniele Gorla and Catuscia Palamidessi and Pablo Piantanida},
  year         = 2021,
  booktitle    = {Advances in Neural Information Processing Systems},
}

@inproceedings{goodfellow2015explaining,
  title        = {Explaining and Harnessing Adversarial Examples},
  author       = {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
  year         = 2015,
  booktitle    = {International Conference on Learning Representations}
}

@inproceedings{DBLP:conf/nips/KotelevskiiAFNF22,
  author       = {Nikita Kotelevskii and
                  Aleksandr Artemenkov and
                  Kirill Fedyanin and
                  Fedor Noskov and
                  Alexander Fishkov and
                  Artem Shelmanov and
                  Artem Vazhentsev and
                  Aleksandr Petiushko and
                  Maxim Panov},
  title        = {Nonparametric Uncertainty Quantification for Single Deterministic
                  Neural Network},
  booktitle    = {Advances in Neural Information Processing Systems },
  year         = {2022},
}

@inproceedings{DBLP:conf/nips/LiuLPTBL20,
  author       = {Jeremiah Z. Liu and
                  Zi Lin and
                  Shreyas Padhy and
                  Dustin Tran and
                  Tania Bedrax{-}Weiss and
                  Balaji Lakshminarayanan},
  title        = {Simple and Principled Uncertainty Estimation with Deterministic Deep
                  Learning via Distance Awareness},
  booktitle    = {Advances in Neural Information Processing Systems },
  year         = {2020},
}

@inproceedings{Rio,
  author       = {Xin Qiu and
                  Elliot Meyerson and
                  Risto Miikkulainen},
  title        = {Quantifying Point-Prediction Uncertainty in Neural Networks via Residual
                  Estimation with an {I/O} Kernel},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
  url          = {https://openreview.net/forum?id=rkxNh1Stvr},
  timestamp    = {Thu, 07 May 2020 17:11:48 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/QiuMM20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}