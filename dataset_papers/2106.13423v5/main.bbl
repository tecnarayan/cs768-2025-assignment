\begin{thebibliography}{10}

\bibitem{bourgain1985}
Jean Bourgain.
\newblock On lipschitz embedding of finite metric spaces in hilbert space.
\newblock {\em Israel Journal of Mathematics}, 52 (1):46--52, 1985.

\bibitem{briggs2020federated}
Christopher Briggs, Zhong Fan, and Peter Andras.
\newblock Federated learning with hierarchical clustering of local updates to
  improve training on non-iid data.
\newblock In {\em IJCNN}, 2020.

\bibitem{caldarola2021clusterdriven}
Debora Caldarola, Massimiliano Mancini, Fabio Galasso, Marco Ciccone, Emanuele
  Rodolà, and Barbara Caputo.
\newblock Cluster-driven graph federated learning over multiple domains.
\newblock In {\em CVPRW}, 2021.

\bibitem{chen2018federated}
Fei Chen, Mi~Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He.
\newblock Federated meta-learning with fast convergence and efficient
  communication.
\newblock {\em arXiv preprint arXiv:1802.07876}, 2018.

\bibitem{chen2020fede}
Mingyang Chen, Wen Zhang, Zonggang Yuan, Yantao Jia, and Huajun Chen.
\newblock Fede: Embedding knowledge graphs in federated setting.
\newblock {\em arXiv preprint arXiv:2010.12882}, 2020.

\bibitem{dinh2021personalized}
Canh~T. Dinh, Nguyen~H. Tran, and Tuan~Dung Nguyen.
\newblock Personalized federated learning with moreau envelopes.
\newblock In {\em NeurIPS}, 2021.

\bibitem{erdos1959}
Paul Erdős and Alfréd Rényi.
\newblock On random graphs. $\mathbb{I}$.
\newblock {\em Publicationes Mathematicae.}, 6:290--297, 1959.

\bibitem{fallah2020personalized}
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
\newblock Personalized federated learning: A meta-learning approach.
\newblock In {\em NeurIPS}, 2020.

\bibitem{ghosh2020efficient}
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran.
\newblock An efficient framework for clustered federated learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{gilbert1959}
Edgar Gilbert.
\newblock Random graphs.
\newblock {\em Annals of Mathematical Statistics.}, 30 (4):1141–1144, 1959.

\bibitem{he2021fedgraphnn}
Chaoyang He, Keshav Balasubramanian, Emir Ceyani, Carl Yang, Han Xie, Lichao
  Sun, Lifang He, Liangwei Yang, Philip~S Yu, Yu~Rong, Peilin Zhao, Junzhou
  Huang, Murali Annavaram, and Salman Avestimehr.
\newblock Fedgraphnn: A federated learning system and benchmark for graph
  neural networks.
\newblock {\em arXiv preprint arXiv:2104.07145}, 2021.

\bibitem{huang2018loadaboost}
Li~Huang, Yifeng Yin, Zeng Fu, Shifa Zhang, Hao Deng, and Dianbo Liu.
\newblock Loadaboost: Loss-based adaboost federated machine learning on medical
  data.
\newblock {\em PLoS ONE}, 15(4):e0230706, 2020.

\bibitem{huang2021personalized}
Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei,
  and Yong Zhang.
\newblock Personalized cross-silo federated learning on non-iid data.
\newblock In {\em AAAI}, 2021.

\bibitem{pmlr-v80-ivanov18a}
Sergey Ivanov and Evgeny Burnaev.
\newblock Anonymous walk embeddings.
\newblock In {\em ICML}, 2018.

\bibitem{jeong2018communication}
Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and
  Seong-Lyun Kim.
\newblock Communication-efficient on-device machine learning: Federated
  distillation and augmentation under non-iid private data.
\newblock In {\em NIPSW}, 2018.

\bibitem{jiang2020federated}
Meng Jiang, Taeho Jung, Ryan Karl, and Tong Zhao.
\newblock Federated dynamic gnn with secure aggregation.
\newblock {\em arXiv preprint arXiv:2009.07351}, 2020.

\bibitem{kairouz2019advances}
Peter Kairouz, H~Brendan McMahan, Brendan Avent, Aur{\'e}lien Bellet, Mehdi
  Bennis, Arjun~Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
  Rachel Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock {\em Foundations and Trends in Machine Learning}, 14 (1), 2019.

\bibitem{karimireddy2019scaffold}
Sai~Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank~J Reddi,
  Sebastian~U Stich, and Ananda~Theertha Suresh.
\newblock Scaffold: Stochastic controlled averaging for federated learning.
\newblock In {\em ICML}, 2019.

\bibitem{khaled2020tighter}
Ahmed Khaled, Konstantin Mishchenko, and Peter Richt{\'a}rik.
\newblock Tighter theory for local sgd on identical and heterogeneous data.
\newblock In {\em AISTATS}, 2020.

\bibitem{kingma2017adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em ICLR}, 2017.

\bibitem{kipf2016semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In {\em ICLR}, 2017.

\bibitem{lalitha2019peer}
Anusha Lalitha, Osman~Cihan Kilinc, Tara Javidi, and Farinaz Koushanfar.
\newblock Peer-to-peer federated learning on graphs.
\newblock {\em arXiv preprint arXiv:1901.11173}, 2019.

\bibitem{10.5555/3121445.3121464}
Jurij Leskovec, Deepayan Chakrabarti, Jon Kleinberg, and Christos Faloutsos.
\newblock Realistic, mathematically tractable graph generation and evolution,
  using kronecker multiplication.
\newblock In {\em ECML-PKDD}, 2005.

\bibitem{pmlr-v139-li21h}
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith.
\newblock Ditto: Fair and robust federated learning through personalization.
\newblock In {\em ICML}, 2021.

\bibitem{li2020federated}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock In {\em Proceedings of Machine Learning and Systems}, 2020.

\bibitem{liang2019variance}
Xianfeng Liang, Shuheng Shen, Jingchang Liu, Zhen Pan, Enhong Chen, and Yifei
  Cheng.
\newblock Variance reduced local sgd with lower communication complexity.
\newblock {\em arXiv preprint arXiv:1912.12844}, 2019.

\bibitem{mcmahan2017communication}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise~Aguera
  y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em Artificial Intelligence and Statistics}, 2017.

\bibitem{mcmahan2017communicationefficient}
H.~Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
  Blaise~Agüera y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em AISTATS}, 2017.

\bibitem{cnfgnn}
Chuizheng Meng, Sirisha Rambhatla, and Yan Liu.
\newblock Cross-node federated graph neural network for spatio-temporal data
  modeling.
\newblock In {\em KDD}, 2021.

\bibitem{Morris+2020}
Christopher Morris, Nils~M. Kriege, Franka Bause, Kristian Kersting, Petra
  Mutzel, and Marion Neumann.
\newblock Tudataset: A collection of benchmark datasets for learning with
  graphs.
\newblock In {\em ICMLW}, 2020.

\bibitem{olsen2017simultaneous}
Niels~Lundtorp Olsen, Bo~Markussen, and Lars~Lau Rakêt.
\newblock Simultaneous inference for misaligned multivariate functional data.
\newblock {\em Journal of the Royal Statistical Society Series C}, 67
  (5):1147--1176, 2017.

\bibitem{Pearson1905}
Karl Pearson.
\newblock Das fehlergesetz und seine verallgemeinerungen durch fechner und
  pearson. a rejoinder [the error law and its generalizations by fechner and
  pearson. a rejoinder].
\newblock {\em Biometrika}, 4 (1-2):169--212, 1905.

\bibitem{9174890}
Felix Sattler, Klaus-Robert Müller, and Wojciech Samek.
\newblock Clustered federated learning: Model-agnostic distributed multitask
  optimization under privacy constraints.
\newblock {\em TNNLS}, pages 1--13, 2020.

\bibitem{10.5555/2984093.2984279}
Nino Shervashidze and Karsten~M. Borgwardt.
\newblock Fast subtree kernels on graphs.
\newblock In {\em NIPS}, 2009.

\bibitem{StoerWagner}
Mechthild Stoer and Frank Wagner.
\newblock A simple min-cut algorithm.
\newblock {\em J. ACM}, 44(4), 1997.

\bibitem{vishwanathan2010graph}
S~Vichy~N Vishwanathan, Nicol~N Schraudolph, Risi Kondor, and Karsten~M
  Borgwardt.
\newblock Graph kernels.
\newblock {\em JMLR}, 11:1201--1242, 2010.

\bibitem{wang2020graphfl}
Binghui Wang, Ang Li, Hai Li, and Yiran Chen.
\newblock Graphfl: A federated learning framework for semi-supervised node
  classification on graphs.
\newblock {\em arXiv preprint arXiv:2012.04187}, 2020.

\bibitem{wang2021fl}
Chunnan Wang, Bozhou Chen, Geng Li, and Hongzhi Wang.
\newblock Fl-agcns: Federated learning framework for automatic graph
  convolutional network search.
\newblock In {\em ICML}, 2021.

\bibitem{wang2019adaptive}
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin~K Leung, Christian
  Makaya, Ting He, and Kevin Chan.
\newblock Adaptive federated learning in resource constrained edge computing
  systems.
\newblock {\em IEEE Journal on Selected Areas in Communications},
  37(6):1205--1221, 2019.

\bibitem{wu2021fedgnn}
Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, and Xing Xie.
\newblock Fedgnn: Federated graph neural network for privacy-preserving
  recommendation.
\newblock {\em arXiv preprint arXiv:2102.04925}, 2021.

\bibitem{wu2019simplifying}
Felix Wu, Tianyi Zhang, Amauri Holanda~de Souza~Jr, Christopher Fifty, Tao Yu,
  and Kilian~Q Weinberger.
\newblock Simplifying graph convolutional networks.
\newblock In {\em ICML}, 2019.

\bibitem{Wu_2021}
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
  Philip~S. Yu.
\newblock A comprehensive survey on graph neural networks.
\newblock {\em IEEE TNNLS}, 32(1):4--24, 2021.

\bibitem{xu2018how}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock In {\em ICLR}, 2019.

\bibitem{10.1145/2783258.2783417}
Pinar Yanardag and S.V.N. Vishwanathan.
\newblock Deep graph kernels.
\newblock In {\em KDD}, 2015.

\bibitem{yang2018node}
Carl Yang, Mengxiong Liu, Vincent~W Zheng, and Jiawei Han.
\newblock Node, motif and subgraph: Leveraging network functional blocks
  through structural convolution.
\newblock In {\em ASONAM}, 2018.

\bibitem{yang2020heterogeneous}
Carl Yang, Yuxin Xiao, Yu~Zhang, Yizhou Sun, and Jiawei Han.
\newblock Heterogeneous network representation learning: A unified framework
  with survey and benchmark.
\newblock In {\em TKDE}, 2020.

\bibitem{yang2020co}
Carl Yang, Jieyu Zhang, and Jiawei Han.
\newblock Co-embedding network nodes and hierarchical labels with taxonomy
  based generative adversarial nets.
\newblock In {\em ICDM}, 2020.

\bibitem{yang2019conditional}
Carl Yang, Peiye Zhuang, Wenhan Shi, Alan Luu, and Pan Li.
\newblock Conditional structure generation through graph variational generative
  adversarial nets.
\newblock In {\em NIPS}, 2019.

\bibitem{ying2018hierarchical}
Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William~L Hamilton, and
  Jure Leskovec.
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock In {\em NeurIPS}, 2018.

\bibitem{you2019position}
Jiaxuan You, Rex Ying, and Jure Leskovec.
\newblock Position-aware graph neural networks.
\newblock In {\em ICML}, pages 7134--7143, 2019.

\bibitem{yu2019parallel}
Hao Yu, Sen Yang, and Shenghuo Zhu.
\newblock Parallel restarted sgd with faster convergence and less
  communication: Demystifying why model averaging works for deep learning.
\newblock In {\em AAAI}, 2019.

\bibitem{zhang2021subgraph}
Ke~Zhang, Carl Yang, Xiaoxiao Li, Lichao Sun, and Siu~Ming Yiu.
\newblock Subgraph federated learning with missing neighbor generation.
\newblock In {\em NeurIPS}, 2021.

\bibitem{zhao2018federated}
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.
\newblock Federated learning with non-iid data.
\newblock {\em arXiv preprint arXiv:1806.00582}, 2018.

\bibitem{zhou2020vertically}
Jun Zhou, Chaochao Chen, Longfei Zheng, Huiwen Wu, Jia Wu, Xiaolin Zheng,
  Bingzhe Wu, Ziqi Liu, and Li~Wang.
\newblock Vertically federated graph neural network for privacy-preserving node
  classification.
\newblock {\em arXiv preprint arXiv:2005.11903}, 2020.

\end{thebibliography}
