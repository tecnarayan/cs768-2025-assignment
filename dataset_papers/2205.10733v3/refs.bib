@inproceedings{lu2021general,
  title={{A General Analysis of Example-Selection for Stochastic Gradient Descent}},
  author={Lu, Yucheng and Meng, Si Yi and De Sa, Christopher},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@Inbook{barany2008power,
  title={{On the Power of Linear Dependencies}},
  author={B{\'a}r{\'a}ny, Imre},
  booktitle={Building Bridges: Between Mathematics and Computer Science},
  pages={31--45},
  year={2008},
  publisher={Springer Berlin Heidelberg}
}

@inproceedings{chobanyan2012signs,
  title={Signs and permutations: two problems of the function theory},
  author={Chobanyan, S. and Giorgobiani, G. and Tarieladze, V.},
  booktitle={Proceedings of A. Razmadze Mathematical Institute},
  volume={160},
  pages={25--34},
  year={2012}
}

@inproceedings{harvey2014near,
  author    = {Nick Harvey and
               Samira Samadi},
  title     = {{Near-Optimal Herding}},
  booktitle = {Proceedings of The 27th Conference on Learning Theory},
  volume    = {35},
  pages     = {1165--1182},
  year      = {2014},
}

@article{ernst1994appointment,
 author = {Lawrence R. Ernst},
 journal = {Management Science},
 number = {10},
 pages = {1207--1227},
 publisher = {INFORMS},
 title = {{Apportionment Methods for the House of Representatives and the Court Challenges}},
 volume = {40},
 year = {1994}
}

@article{spencer1977balancing,
  title={Balancing games},
  author={Spencer, Joel},
  journal={Journal of Combinatorial Theory, Series B},
  volume={23},
  number={1},
  pages={68--74},
  year={1977},
  publisher={Elsevier}
}

@article{aru2016balancing,
  title={Balancing sums of random vectors},
  author={Aru, Juhan and Narayanan, Bhargav and Scott, Alex and Venkatesan, Ramarathnam},
  journal={arXiv preprint arXiv:1610.05221},
  year={2016}
}

@article{bansal2020line,
  title={On-line balancing of random inputs},
  author={Bansal, Nikhil and Spencer, Joel H},
  journal={Random Structures \& Algorithms},
  volume={57},
  number={4},
  pages={879--891},
  year={2020},
  publisher={Wiley Online Library}
}

@inproceedings{bansal2020online,
  title={Online vector balancing and geometric discrepancy},
  author={Bansal, Nikhil and Jiang, Haotian and Singla, Sahil and Sinha, Makrand},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1139--1152},
  year={2020}
}

@article{bansal2019algorithm,
  title={An algorithm for Koml{\'o}s conjecture matching Banaszczyk's bound},
  author={Bansal, Nikhil and Dadush, Daniel and Garg, Shashwat},
  journal={SIAM Journal on Computing},
  volume={48},
  number={2},
  pages={534--553},
  year={2019},
  publisher={SIAM}
}

@inproceedings{bansal2010constructive,
  title={Constructive algorithms for discrepancy minimization},
  author={Bansal, Nikhil},
  booktitle={2010 IEEE 51st Annual Symposium on Foundations of Computer Science},
  pages={3--10},
  year={2010},
  organization={IEEE}
}

@article{chobanyan2015maximum,
  title={Maximum inequalities for rearrangements of summands and assignments of signs},
  author={Chobanyan, S and Levental, Shlomo and Salehi, Habib},
  journal={Theory of Probability \& Its Applications},
  volume={59},
  number={4},
  pages={677--684},
  year={2015},
  publisher={SIAM}
}

@article{jiang2019online,
  title={Online geometric discrepancy for stochastic arrivals with applications to envy minimization},
  author={Jiang, Haotian and Kulkarni, Janardhan and Singla, Sahil},
  journal={arXiv preprint arXiv:1910.01073},
  year={2019}
}

@inproceedings{chobanyan2016inequalities,
  title={Inequalities on Rearrangements of Summands with Applications in as Convergence of Functional Series},
  author={Chobanyan, Sergei},
  booktitle={VII International Joint Conference of Georgian Mathematical Union \& Georgian Mechanical Union},
  pages={56},
  year={2016}
}

@inproceedings{bansal2021online,
  title={Online discrepancy minimization for stochastic arrivals},
  author={Bansal, Nikhil and Jiang, Haotian and Meka, Raghu and Singla, Sahil and Sinha, Makrand},
  booktitle={Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  pages={2842--2861},
  year={2021},
  organization={SIAM}
}

@inproceedings{alweiss2021discrepancy,
  title={Discrepancy minimization via a self-balancing walk},
  author={Alweiss, Ryan and Liu, Yang P and Sawhney, Mehtaab},
  booktitle={Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={14--20},
  year={2021}
}

@article{gurbuzbalaban2021random,
  title={Why random reshuffling beats stochastic gradient descent},
  author={G{\"u}rb{\"u}zbalaban, Mert and Ozdaglar, Asu and Parrilo, Pablo A},
  journal={Mathematical Programming},
  volume={186},
  number={1},
  pages={49--84},
  year={2021},
  publisher={Springer}
}

@article{de2020random,
  title={Random reshuffling is not always better},
  author={De Sa, Christopher M},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5957--5967},
  year={2020}
}

@article{mohtashami2022characterizing,
  title={Characterizing \& Finding Good Data Orderings for Fast Convergence of Sequential Gradient Methods},
  author={Mohtashami, Amirkeivan and Stich, Sebastian and Jaggi, Martin},
  journal={arXiv preprint arXiv:2202.01838},
  year={2022}
}

@article{bottou2018optimization,
  title     = {Optimization methods for large-scale machine learning},
  author    = {Bottou, L{\'e}on and Curtis, Frank E. and Nocedal, Jorge},
  journal   = {SIAM Review},
  volume    = {60},
  number    = {2},
  pages     = {223--311},
  year      = {2018},
  publisher = {SIAM}
}

@inproceedings{nguyen2018sgd,
  author    = {Lam M. Nguyen and
               Phuong Ha Nguyen and
               Marten van Dijk and
               Peter Richt{\'{a}}rik and
               Katya Scheinberg and
               Martin Tak{\'{a}}c},
  title     = {{SGD} and {H}ogwild! Convergence Without the Bounded Gradients Assumption},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  volume    = {80},
  pages     = {3747--3755},
  year      = {2018}
}

@inproceedings{shamir2016without,
  author    = {Ohad Shamir},
  title     = {Without-Replacement Sampling for Stochastic Gradient Methods},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {46--54},
  year      = {2016}
}

@article{ying2018stochastic,
  author    = {Bicheng Ying and
               Kun Yuan and
               Stefan Vlaski and
               Ali H. Sayed},
  title     = {Stochastic Learning Under Random Reshuffling With Constant Step-Sizes},
  journal   = {{IEEE} Trans. Signal Process.},
  volume    = {67},
  number    = {2},
  pages     = {474--489},
  year      = {2019},
}

@inproceedings{haochen2019random,
  author    = {Jeff Z. HaoChen and
               Suvrit Sra},
  title     = {Random Shuffling Beats {SGD} after Finite Epochs},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  volume    = {97},
  pages     = {2624--2633},
  year      = {2019}
}

@article{nguyen2020unified,
  title   = {A unified convergence analysis for shuffling-type gradient methods},
  author  = {Lam M. Nguyen and
            Quoc Tran{-}Dinh and
            Dzung T. Phan and
            Phuong Ha Nguyen and
            Marten van Dijk},
  journal = {arXiv:2002.08246},
  year    = {2020}
}

@inproceedings{mishchenko2020random,
  author    = {Konstantin Mishchenko and
               Ahmed Khaled and
               Peter Richt{\'{a}}rik},
  title     = {Random Reshuffling: Simple Analysis with Vast Improvements},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@inproceedings{nagaraj2019sgd,
  author    = {Dheeraj Nagaraj and
               Prateek Jain and
               Praneeth Netrapalli},
  title     = {{SGD} without Replacement: Sharper Rates for General Smooth Convex
               Functions},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  volume    = {97},
  pages     = {4703--4711},
  year      = {2019}
}

@article{ahn2020tight,
  title   = {On tight convergence rates of without-replacement {SGD}},
  author  = {Ahn, Kwangjun and Sra, Suvrit},
  journal = {arXiv:2004.08657},
  year    = {2020}
}

@inproceedings{ahn2020sgd,
  author    = {Kwangjun Ahn and
               Chulhee Yun and
               Suvrit Sra},
  title     = {{SGD} with shuffling: optimal rates without component convexity and
               large epoch requirements},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@inproceedings{rajput2020closing,
  author    = {Shashank Rajput and
               Anant Gupta and
               Dimitris S. Papailiopoulos},
  title     = {Closing the convergence gap of {SGD} without replacement},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  volume    = {119},
  pages     = {7964--7973},
  year      = {2020}
}

@article{choi2019faster,
  title={Faster neural network training with data echoing},
  author={Choi, Dami and Passos, Alexandre and Shallue, Christopher J. and Dahl, George E.},
  journal={arXiv:1907.05550},
  year={2019}
}

@article{caflisch1998monte,
    title={{Monte Carlo and quasi-Monte Carlo methods}}, 
    volume={7}, 
    journal={Acta Numerica}, 
    publisher={Cambridge University Press}, 
    author={Caflisch, Russel E.}, 
    year={1998}, 
    pages={1â€“49}
}

@inproceedings{agarwal2020stochastic,
  author    = {Naman Agarwal and
               Rohan Anil and
               Tomer Koren and
               Kunal Talwar and
               Cyril Zhang},
  title     = {Stochastic Optimization with Laggard Data Pipelines},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020},
}

@article{robbins1951stochastic,
  author    = {Herbert Robbins and Sutton Monro},
  title     = {{A Stochastic Approximation Method}},
  volume    = {22},
  journal   = {The Annals of Mathematical Statistics},
  number    = {3},
  publisher = {Institute of Mathematical Statistics},
  pages     = {400 -- 407},
  year      = {1951},
}

@inproceedings{zhang2004solving,
  author    = {Tong Zhang},
  title     = {Solving large scale linear prediction problems using stochastic gradient
               descent algorithms},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  pages     = {116},
  volume    = {69},
  year      = {2004},
}

@inproceedings{recht2012toward,
  author    = {Benjamin Recht and
               Christopher R{\'{e}}},
  title     = {Toward a Noncommutative Arithmetic-geometric Mean Inequality: Conjectures,
               Case-studies, and Consequences},
  booktitle = {Conference on Learning Theory},
  volume    = {23},
  pages     = {11.1--11.24},
  year      = {2012},
}

@inproceedings{safran2020good,
  author    = {Itay Safran and
               Ohad Shamir},
  title     = {How Good is {SGD} with Random Shuffling?},
  booktitle = {Conference on Learning Theory},
  series    = {Proceedings of Machine Learning Research},
  volume    = {125},
  pages     = {3250--3284},
  publisher = {{PMLR}},
  year      = {2020},
}

@inproceedings{drori2020complexity,
  title={The complexity of finding stationary points with stochastic gradient descent},
  author={Drori, Yoel and Shamir, Ohad},
  booktitle={Proceedings of the International Conference on Machine Learning},
  volume={119},
  pages={2658--2667},
  year={2020},
  organization={PMLR}
}

@incollection{bottou2012stochastic,
  title={Stochastic gradient descent tricks},
  author={Bottou, L{\'e}on},
  booktitle={Neural networks: Tricks of the trade},
  pages={421--436},
  year={2012},
  publisher={Springer}
}

@incollection{bertsekas2011incremental,
  author    = {Bertsekas, Dimitri P.},
  title     = {{Incremental Gradient, Subgradient, and Proximal Methods for Convex Optimization: A Survey}},
  booktitle = {{Optimization for Machine Learning}},
  publisher = {The MIT Press},
  year      = {2011},
}

@article{gurbuzbalaban2019convergence,
  author    = {Mert G{\"{u}}rb{\"{u}}zbalaban and
               Asuman E. Ozdaglar and
               Pablo A. Parrilo},
  title     = {Convergence Rate of Incremental Gradient and Incremental {Newton} Methods},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {29},
  number    = {4},
  pages     = {2542--2565},
  year      = {2019},
}

@inproceedings{ying2017performance,
  title={On the performance of random reshuffling in stochastic learning},
  author={Ying, Bicheng and Yuan, Kun and Vlaski, Stefan and Sayed, Ali H.},
  booktitle={2017 Information Theory and Applications Workshop (ITA)},
  pages={1--5},
  year={2017},
  organization={IEEE}
}

@article{alain2015variance,
  author        = {Guillaume Alain and
               Alex Lamb and
               Chinnadhurai Sankar and
               Aaron C. Courville and
               Yoshua Bengio},
  title         = {Variance Reduction in {SGD} by Distributed Importance Sampling},
  journal       = {arXiv:1511.06481},
  year          = {2015},
}

@article{loshchilov2015online,
  title={Online batch selection for faster training of neural networks},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv:1511.06343},
  year={2015}
}

@inproceedings{lee2019meta,
  title={Meta-learning with differentiable convex optimization},
  author={Lee, Kwonjoon and Maji, Subhransu and Ravichandran, Avinash and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10657--10665},
  year={2019}
}

@inproceedings{yun2021can,
  author    = {Chulhee Yun and
               Suvrit Sra and
               Ali Jadbabaie},
  title     = {Open Problem: Can Single-Shuffle {SGD} be Better than Reshuffling
               {SGD} and {GD}?},
  booktitle = {Conference on Learning Theory},
  year      = {2021},
}

@inproceedings{NEURIPS2020_42299f06,
  author    = {De Sa, Christopher},
  title     = {Random Reshuffling is Not Always Better},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020},
}

@article{rajput2021permutation,
  title={Permutation-Based SGD: Is Random Optimal?},
  author={Rajput, Shashank and Lee, Kangwook and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2102.09718},
  year={2021}
}

@article{matousek2014factorization,
  title={Factorization norms and hereditary discrepancy},
  author={Matousek, Jiri and Nikolov, Aleksandar and Talwar, Kunal},
  journal={arXiv preprint arXiv:1408.1376},
  year={2014}
}

@inproceedings{matouvsek2015combinatorial,
  title={Combinatorial Discrepancy for Boxes via the gamma\_2 Norm},
  author={Matou{\v{s}}ek, Jir{\'\i} and Nikolov, Aleksandar},
  booktitle={31st International Symposium on Computational Geometry (SoCG 2015)},
  year={2015},
  organization={Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}

@article{krizhevsky2010convolutional,
  title={Convolutional deep belief networks on cifar-10},
  author={Krizhevsky, Alex and Hinton, Geoff},
  journal={Unpublished manuscript},
  volume={40},
  number={7},
  pages={1--9},
  year={2010}
}

@article{merity2017regularizing,
  title={Regularizing and optimizing LSTM language models},
  author={Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
  journal={arXiv preprint arXiv:1708.02182},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{chelidze2010greedy,
  title={Greedy algorithm fails in compact vector summation},
  author={Chelidze, George and Chobanyan, Sergei and Giorgobiani, George and Kvaratskhelia, Vakhtang},
  journal={Bull. Georg. Natl. Acad. Sci},
  volume={4},
  number={2},
  year={2010}
}

@inproceedings{welling2009herding,
  title={Herding dynamical weights to learn},
  author={Welling, Max},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={1121--1128},
  year={2009}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{turc2019,
  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962v2 },
  year={2019}
}

@article{li2019dimension,
  title={Dimension-free bounds for low-precision training},
  author={Li, Zheng and De Sa, Christopher M},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{lu2021variance,
  title={Variance Reduced Training with Stratified Sampling for Forecasting Models},
  author={Lu, Yucheng and Park, Youngsuk and Chen, Lifan and Wang, Yuyang and De Sa, Christopher and Foster, Dean},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={7145--7155},
  year={2021},
  organization={PMLR}
}

@article{schmidt2017minimizing,
  author    = {Mark Schmidt and
               Nicolas Le Roux and
               Francis R. Bach},
  title     = {Minimizing finite sums with the stochastic average gradient},
  journal   = {Mathematical Programming},
  volume    = {162},
  number    = {1-2},
  pages     = {83--112},
  year      = {2017},
}

@inproceedings{needell2014stochastic,
  author    = {Deanna Needell and
               Rachel Ward and
               Nathan Srebro},
  title     = {{Stochastic Gradient Descent, Weighted Sampling, and the Randomized
               Kaczmarz algorithm}},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {1017--1025},
  year      = {2014},
}

@inproceedings{bansal2017algorithmic,
  title={Algorithmic discrepancy beyond partial coloring},
  author={Bansal, Nikhil and Garg, Shashwat},
  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={914--926},
  year={2017}
}

@article{bansal2013deterministic,
  title={Deterministic discrepancy minimization},
  author={Bansal, Nikhil and Spencer, Joel},
  journal={Algorithmica},
  volume={67},
  number={4},
  pages={451--471},
  year={2013},
  publisher={Springer}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@inproceedings{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  booktitle={international conference on machine learning},
  pages={1311--1320},
  year={2017},
  organization={PMLR}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}

@article{soviany2022curriculum,
  title={Curriculum learning: A survey},
  author={Soviany, Petru and Ionescu, Radu Tudor and Rota, Paolo and Sebe, Nicu},
  journal={International Journal of Computer Vision},
  pages={1--40},
  year={2022},
  publisher={Springer}
}

@inproceedings{lu2020moniqua,
  title={Moniqua: Modulo quantized communication in decentralized SGD},
  author={Lu, Yucheng and De Sa, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={6415--6425},
  year={2020},
  organization={PMLR}
}