% Encoding: UTF-8


@Article{Ye2020b,
  author  = {Ye, Mao and Wu, Lemeng and Liu, Qiang},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Greedy optimization provably wins the lottery: Logarithmic number of winning tickets is enough},
  year    = {2020},
  pages   = {16409--16420},
  volume  = {33},
}


@InProceedings{He2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  title     = {Deep residual learning for image recognition},
  pages     = {770--778},
  year      = {2016},
}


@Misc{Li2022,
  author    = {Li, Wenxin and Feldman, Moran and Kazemi, Ehsan and Karbasi, Amin},
  title     = {Submodular Maximization in Clean Linear Time},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2006.09327},
  keywords  = {Data Structures and Algorithms (cs.DS), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences, F.2.2; G.2.1; I.2.6, 90C27 (Primary) 68Q32, 68R05 (Secondary)},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2006.09327},
}



@Article{Mussay2021,
  author  = {Mussay, Ben and Feldman, Dan and Zhou, Samson and Braverman, Vladimir and Osadchy, Margarita},
  title   = {Data-Independent Structured Pruning of Neural Networks via Coresets},
  doi     = {10.1109/TNNLS.2021.3088587},
  pages   = {1-13},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  year    = {2021},
}

@InProceedings{Mussay2020,
  author    = {Ben Mussay and Margarita Osadchy and Vladimir Braverman and Samson Zhou and Dan Feldman},
  booktitle = {International Conference on Learning Representations},
  title     = {Data-Independent Neural Pruning via Coresets},
  url       = {https://openreview.net/forum?id=H1gmHaEKwB},
  year      = {2020},
}

@InProceedings{Liebenwein2020,
  author    = {Lucas Liebenwein and Cenk Baykal and Harry Lang and Dan Feldman and Daniela Rus},
  booktitle = {International Conference on Learning Representations},
  title     = {Provable Filter Pruning for Efficient Neural Networks},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BJxkOlSYDH},
}


@Article{ElHalabi2018,
  author  = {El Halabi, M. and Bach, F. and Cevher, V},
  title   = {Combinatorial Penalties: Structure preserved by convex relaxations},
  journal = {Proceedings of the 21st International Conference on Artificial Intelligence and Statistics},
  year    = {2018},
}

@Article{Lehmann2006,
  author    = {Lehmann, Benny and Lehmann, Daniel and Nisan, Noam},
  title     = {Combinatorial auctions with decreasing marginal utilities},
  journal   = {Games and Economic Behavior},
  year      = {2006},
  volume    = {55},
  number    = {2},
  pages     = {270--296},
  publisher = {Elsevier},
}

@Misc{Phan2021,
  author    = {Huy Phan},
  title     = {huyvnphan/PyTorch\_CIFAR10},
  doi       = {10.5281/zenodo.4431043},
  url       = {https://doi.org/10.5281/zenodo.4431043},
  version   = {v3.0.1},
  month     = jan,
  publisher = {Zenodo},
  year      = {2021},
}

@Article{Paszke2017,
  author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  title  = {Automatic differentiation in PyTorch},
  year   = {2017},
}

@InProceedings{Simonyan2015,
  author    = {Karen Simonyan and Andrew Zisserman},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  editor    = {Yoshua Bengio and Yann LeCun},
  url       = {http://arxiv.org/abs/1409.1556},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  year      = {2015},
}

@Article{LeCun1989,
  author    = {LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  title     = {Backpropagation applied to handwritten zip code recognition},
  number    = {4},
  pages     = {541--551},
  volume    = {1},
  journal   = {Neural computation},
  publisher = {MIT Press},
  year      = {1989},
}

@Misc{Buschjaeger2020,
  author        = {Sebastian Buschj√§ger and Philipp-Jan Honysz and Katharina Morik},
  title         = {Very Fast Streaming Submodular Function Maximization},
  eprint        = {2010.10059},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  year          = {2020},
}

@InProceedings{Mirzasoleiman2015,
  author    = {Mirzasoleiman, Baharan and Badanidiyuru, Ashwinkumar and Karbasi, Amin and Vondr{\'a}k, Jan and Krause, Andreas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title     = {Lazier than lazy greedy},
  volume    = {29},
  year      = {2015},
}

@InProceedings{Li2017,
  author    = {Hao Li and Asim Kadav and Igor Durdanovic and Hanan Samet and Hans Peter Graf},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  title     = {Pruning Filters for Efficient ConvNets},
  publisher = {OpenReview.net},
  url       = {https://openreview.net/forum?id=rJqFGTslg},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/iclr/0022KDSG17.bib},
  timestamp = {Thu, 25 Jul 2019 14:25:50 +0200},
  year      = {2017},
}

@article{gong2014compressing,
  title={Compressing deep convolutional networks using vector quantization},
  author={Gong, Yunchao and Liu, Liu and Yang, Ming and Bourdev, Lubomir},
  journal={arXiv preprint arXiv:1412.6115},
  year={2014}
}

@inproceedings{Denil2013Predicting,
 author = {Denil, Misha and Shakibi, Babak and Dinh, Laurent and Ranzato, Marc Aurelio and de Freitas, Nando},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Predicting Parameters in Deep Learning},
 url = {https://proceedings.neurips.cc/paper/2013/file/7fec306d1e665bc9c748b5d2b99a6e97-Paper.pdf},
 volume = {26},
 year = {2013}
}

@INPROCEEDINGS{sainath2013lowrank,
  author={Sainath, Tara N. and Kingsbury, Brian and Sindhwani, Vikas and Arisoy, Ebru and Ramabhadran, Bhuvana},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Low-rank matrix factorization for Deep Neural Network training with high-dimensional output targets}, 
  year={2013},
  volume={},
  number={},
  pages={6655-6659},
  doi={10.1109/ICASSP.2013.6638949}
}

@inproceedings{jaderberg2014speeding,
	title = {Speeding up Convolutional Neural Networks with Low Rank Expansions},
	author = {Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
	year = {2014},
	booktitle = {Proceedings of the British Machine Vision Conference},
	publisher = {BMVA Press},
	editors = {Valstar, Michel and French, Andrew and Pridmore, Tony},
	doi = { http://dx.doi.org/10.5244/C.28.88 }
}

@inproceedings{denton2014exploiting,
  title={Exploiting linear structure within convolutional networks for efficient evaluation},
  author={Denton, Emily L and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
  booktitle={Advances in neural information processing systems},
  pages={1269--1277},
  year={2014}
}

@inproceedings{lebedev2015speeding,
  title={Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition},
  author={Lebedev, Vadim and Ganin, Yaroslav and Rakhuba, Maksim and Oseledets, Ivan V and Lempitsky, Victor S},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@article{kim2015compression,
  title={Compression of deep convolutional neural networks for fast and low power mobile applications},
  author={Kim, Yong-Deok and Park, Eunhyeok and Yoo, Sungjoo and Choi, Taelim and Yang, Lu and Shin, Dongjun},
  journal={arXiv preprint arXiv:1511.06530},
  year={2015}
}

@ARTICLE{zhang2016accelerating,

  author={Zhang, Xiangyu and Zou, Jianhua and He, Kaiming and Sun, Jian},

  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 

  title={Accelerating Very Deep Convolutional Networks for Classification and Detection}, 

  year={2016},

  volume={38},

  number={10},

  pages={1943-1955},

  doi={10.1109/TPAMI.2015.2502579}}


@article{su2018tensorial,
  title={Tensorial neural networks: Generalization of neural networks and application to model compression},
  author={Su, Jiahao and Li, Jingling and Bhattacharjee, Bobby and Huang, Furong},
  journal={arXiv preprint arXiv:1805.10352},
  year={2018}
}


@Article{Elenberg2016,
  author  = {Elenberg, Ethan R and Khanna, Rajiv and Dimakis, Alexandros G and Negahban, Sahand},
  title   = {Restricted strong convexity implies weak submodularity},
  journal = {arXiv preprint arXiv:1612.00804},
  year    = {2016},
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binaryconnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Advances in neural information processing systems},
  pages={3123--3131},
  year={2015}
}


@Article{Natarajan1995,
  author    = {Natarajan, Balas Kausik},
  title     = {Sparse approximate solutions to linear systems},
  journal   = {SIAM journal on computing},
  year      = {1995},
  volume    = {24},
  number    = {2},
  pages     = {227--234},
  publisher = {SIAM},
}

@Article{Nemhauser1978,
  author    = {Nemhauser, G.L. and Wolsey, L.A. and Fisher, M.L.},
  title     = {An analysis of approximations for maximizing submodular set functions --- {I}},
  journal   = {Mathematical Programming},
  year      = {1978},
  volume    = {14},
  number    = {1},
  pages     = {265--294},
  publisher = {Springer},
}

@Article{Das2011,
  author  = {Das, A. and Kempe, D.},
  title   = {Submodular meets spectral: Greedy algorithms for subset selection, sparse approximation and dictionary selection},
  journal = {arXiv preprint arXiv:1102.3975},
  year    = {2011},
}

@InProceedings{luo2017,
  author    = {Luo, Jian-Hao and Wu, Jianxin and Lin, Weiyao},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  title     = {Thinet: A filter level pruning method for deep neural network compression},
  pages     = {5058--5066},
  year      = {2017},
}

@InProceedings{He2014,
  author       = {He, Tianxing and Fan, Yuchen and Qian, Yanmin and Tan, Tian and Yu, Kai},
  booktitle    = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title        = {Reshaping deep neural network for fast decoding by node-pruning},
  organization = {IEEE},
  pages        = {245--249},
  year         = {2014},
}

@Article{Hoefler2021,
  author  = {Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
  title   = {Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks},
  journal = {arXiv preprint arXiv:2102.00554},
  year    = {2021},
}

@Article{Blalock2020,
  author  = {Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  title   = {What is the state of neural network pruning?},
  journal = {arXiv preprint arXiv:2003.03033},
  year    = {2020},
}

@Article{Kuzmin2019,
  author  = {Kuzmin, Andrey and Nagel, Markus and Pitre, Saurabh and Pendyam, Sandeep and Blankevoort, Tijmen and Welling, Max},
  title   = {Taxonomy and evaluation of structured compression of convolutional neural networks},
  journal = {arXiv preprint arXiv:1912.09802},
  year    = {2019},
}

@Article{McGuffie2020,
  author  = {McGuffie, Kris and Newhouse, Alex},
  title   = {The radicalization risks of GPT-3 and advanced neural language models},
  journal = {arXiv preprint arXiv:2009.06807},
  year    = {2020},
}

@Misc{Lecun1998,
  author = {Lecun, Y and Cortes, C and Burges, C},
  title  = {The mnist databaseof handwritten digits},
  year   = {1998},
}

@Article{Krizhevsky2009,
  author    = {Krizhevsky, Alex and Hinton, Geoffrey and others},
  title     = {Learning multiple layers of features from tiny images},
  publisher = {Citeseer},
  year      = {2009},
}

@InProceedings{Zhuang2018,
  author    = {Zhuang, Zhuangwei and Tan, Mingkui and Zhuang, Bohan and Liu, Jing and Guo, Yong and Wu, Qingyao and Huang, Junzhou and Zhu, Jinhui},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Discrimination-aware Channel Pruning for Deep Neural Networks},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper/2018/file/55a7cf9c71f1c9c495413f934dd1a158-Paper.pdf},
  volume    = {31},
  year      = {2018},
}

@InProceedings{He2017,
  author    = {He, Yihui and Zhang, Xiangyu and Sun, Jian},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  title     = {Channel pruning for accelerating very deep neural networks},
  pages     = {1389--1397},
  year      = {2017},
}

@Article{Krause2012,
  author  = {Krause, Andreas and Guestrin, Carlos E},
  title   = {Near-optimal nonmyopic value of information in graphical models},
  journal = {arXiv preprint arXiv:1207.1394},
  year    = {2012},
}

@InProceedings{Feldman2018,
  author    = {Feldman, Moran and Karbasi, Amin and Kazemi, Ehsan},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Do less, get more: streaming submodular maximization with subsampling},
  pages     = {732--742},
  year      = {2018},
}

@inproceedings{Srinivas2015,
	title={Data-free Parameter Pruning for Deep Neural Networks},
	author={Suraj Srinivas and R. Venkatesh Babu},
	year={2015},
	month={September},
	pages={31.1-31.12},
	articleno={31},
	numpages={12},
	booktitle={Proceedings of the British Machine Vision Conference (BMVC)},
	publisher={BMVA Press}
}

@article{han2015learning,
  title={Learning both Weights and Connections for Efficient Neural Network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

@InProceedings{Bian2017a,
  author       = {Bian, Andrew An and Buhmann, Joachim M and Krause, Andreas and Tschiatschek, Sebastian},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  title        = {Guarantees for greedy maximization of non-submodular functions with applications},
  organization = {JMLR. org},
  pages        = {498--507},
  year         = {2017},
}

@InProceedings{Iyer2012a,
  author    = {Iyer, Rishabh and Bilmes, Jeff},
  booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence},
  title     = {Algorithms for Approximate Minimization of the Difference Between Submodular Functions, with Applications},
  isbn      = {978-0-9749039-8-9},
  location  = {Catalina Island, CA},
  pages     = {407--417},
  publisher = {AUAI Press},
  series    = {UAI'12},
  url       = {http://dl.acm.org/citation.cfm?id=3020652.3020697},
  acmid     = {3020697},
  address   = {Arlington, Virginia, United States},
  numpages  = {11},
  year      = {2012},
}

@Article{Kulesza2012,
  author    = {Kulesza, Alex and Taskar, Ben and others},
  title     = {Determinantal point processes for machine learning},
  number    = {2--3},
  pages     = {123--286},
  volume    = {5},
  journal   = {Foundations and Trends{\textregistered} in Machine Learning},
  publisher = {Now Publishers, Inc.},
  year      = {2012},
}

@Article{Krause2008a,
  author  = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
  title   = {Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies},
  number  = {Feb},
  pages   = {235--284},
  volume  = {9},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
}

@Article{Axelrod2019,
  author  = {Axelrod, Brian and Liu, Yang P and Sidford, Aaron},
  title   = {Near-optimal Approximate Discrete and Continuous Submodular Function Minimization},
  journal = {arXiv preprint arXiv:1909.00171},
  year    = {2019},
}

@InProceedings{Michel2019,
  author    = {Michel, Paul and Levy, Omer and Neubig, Graham},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Are Sixteen Heads Really Better than One?},
  pages     = {14014--14024},
  year      = {2019},
}

@InProceedings{Chakrabarty2017,
  author    = {Chakrabarty, Deeparnab and Lee, Yin Tat and Sidford, Aaron and Wong, Sam Chiu-wai},
  booktitle = {Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  title     = {Subquadratic Submodular Function Minimization},
  doi       = {10.1145/3055399.3055419},
  isbn      = {978-1-4503-4528-6},
  location  = {Montreal, Canada},
  pages     = {1220--1231},
  publisher = {ACM},
  series    = {STOC 2017},
  url       = {http://doi.acm.org/10.1145/3055399.3055419},
  acmid     = {3055419},
  address   = {New York, NY, USA},
  keywords  = {Lovasz Extension, Subgradient Descent, Submodular Functions},
  numpages  = {12},
  year      = {2017},
}

@Article{Voita2019,
  author  = {Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  title   = {Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned},
  journal = {arXiv preprint arXiv:1905.09418},
  year    = {2019},
}

@Article{Ye2020,
  author  = {Ye, Mao and Gong, Chengyue and Nie, Lizhen and Zhou, Denny and Klivans, Adam and Liu, Qiang},
  title   = {Good Subnetworks Provably Exist: Pruning via Greedy Forward Selection},
  journal = {ICML},
  year    = {2020},
}

@Article{Mariet2015,
  author  = {Mariet, Zelda and Sra, Suvrit},
  title   = {Diversity networks: Neural network compression using determinantal point processes},
  journal = {arXiv preprint arXiv:1511.05077},
  year    = {2015},
}

@InProceedings{Xiong2019,
  author    = {Xiong, Yunyang and Mehta, Ronak and Singh, Vikas},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
  title     = {Resource Constrained Neural Network Architecture Search: Will a Submodularity Assumption Help?},
  pages     = {1901--1910},
  year      = {2019},
}

@InProceedings{Mirzasoleiman2018,
  author    = {Mirzasoleiman, Baharan and Jegelka, Stefanie and Krause, Andreas},
  booktitle = {Thirty-second AAAI conference on artificial intelligence},
  title     = {Streaming non-monotone submodular maximization: Personalized video summarization on the fly},
  year      = {2018},
}

@Article{Sviridenko2017,
  author    = {Sviridenko, Maxim and Vondr{\'a}k, Jan and Ward, Justin},
  title     = {Optimal approximation for submodular and supermodular optimization with bounded curvature},
  number    = {4},
  pages     = {1197--1218},
  volume    = {42},
  journal   = {Mathematics of Operations Research},
  publisher = {INFORMS},
  year      = {2017},
}

@Article{Kitaev2020,
  author  = {Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  title   = {Reformer: The Efficient Transformer},
  journal = {arXiv preprint arXiv:2001.04451},
  year    = {2020},
}

@InProceedings{Ding2017,
  author    = {Ding, Yanzhuo and Liu, Yang and Luan, Huanbo and Sun, Maosong},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {Visualizing and understanding neural machine translation},
  pages     = {1150--1159},
  year      = {2017},
}

@InProceedings{Hu2019,
  author    = {Hu, Hanzhang and Langford, John and Caruana, Rich and Mukherjee, Saurajit and Horvitz, Eric J and Dey, Debadeepta},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Efficient forward architecture search},
  pages     = {10122--10131},
  year      = {2019},
}

@Article{ElHalabi2015,
  author  = {El Halabi, M. and Cevher, V.},
  title   = {A totally unimodular view of structured sparsity},
  journal = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, pp. 223‚Äì231},
  year    = {2015},
}

@InProceedings{Lindgren2016,
  author    = {Lindgren, Erik and Wu, Shanshan and Dimakis, Alexandros G},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Leveraging Sparsity for Efficient Submodular Data Summarization},
  pages     = {3414--3422},
  year      = {2016},
}

@Article{Molchanov2017,
  author  = {Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  title   = {Pruning convolutional neural networks for resource efficient inference},
  journal = {ICLR},
  year    = {2017},
}

@InProceedings{Gong2014,
  author    = {Gong, Boqing and Chao, Wei-Lun and Grauman, Kristen and Sha, Fei},
  booktitle = {Advances in neural information processing systems},
  title     = {Diverse sequential subset selection for supervised video summarization},
  pages     = {2069--2077},
  year      = {2014},
}

@InProceedings{Badanidiyuru2014,
  author    = {Badanidiyuru, Ashwinkumar and Mirzasoleiman, Baharan and Karbasi, Amin and Krause, Andreas},
  booktitle = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  title     = {Streaming submodular maximization: Massive data summarization on the fly},
  pages     = {671--680},
  year      = {2014},
}

@inproceedings{bucila2006model,
author = {Bucila, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
title = {Model Compression},
year = {2006},
isbn = {1595933395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1150402.1150464},
doi = {10.1145/1150402.1150464},
abstract = {Often the best performing supervised learning models are ensembles of hundreds or thousands of base-level classifiers. Unfortunately, the space required to store this many classifiers, and the time required to execute them at run-time, prohibits their use in applications where test sets are large (e.g. Google), where storage space is at a premium (e.g. PDAs), and where computational power is limited (e.g. hea-ring aids). We present a method for "compressing" large, complex ensembles into smaller, faster models, usually without significant loss in performance.},
booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {535‚Äì541},
numpages = {7},
keywords = {model compression, supervised learning},
location = {Philadelphia, PA, USA},
series = {KDD '06}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={Neural Information Processing Systems (NeurIPS) Workshops},
  year={2015}
}

@article{collins2014memory,
  title={Memory bounded deep convolutional networks},
  author={Collins, Maxwell D and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:1412.1442},
  year={2014}
}

@inproceedings{voita2019analyzing,
  title={Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
  author={Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={5797--5808},
  year={2019}
}

@inproceedings{lecun1990optimal,
 author = {LeCun, Yann and Denker, John and Solla, Sara},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Optimal Brain Damage},
 url = {https://proceedings.neurips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf},
 volume = {2},
 year = {1990}
}

@INPROCEEDINGS{hassibi1993optimal,

  author={Hassibi, B. and Stork, D.G. and Wolff, G.J.},

  booktitle={IEEE International Conference on Neural Networks}, 

  title={Optimal Brain Surgeon and general network pruning}, 

  year={1993},

  volume={},

  number={},

  pages={293-299 vol.1},

  doi={10.1109/ICNN.1993.298572}}
