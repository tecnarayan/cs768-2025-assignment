\begin{thebibliography}{10}

\bibitem{abe2010optimizing}
N.~Abe, P.~Melville, C.~Pendus, C.~Reddy, D.~Jensen, V.~Thomas, J.~Bennett,
  G.~Anderson, B.~Cooley, M.~Kowalczyk, et~al.
\newblock Optimizing debt collections using constrained reinforcement learning.
\newblock In {\em Proceedings of the 16th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 75--84, 2010.

\bibitem{achiam2017constrained}
J.~Achiam, D.~Held, A.~Tamar, and P.~Abbeel.
\newblock Constrained policy optimization.
\newblock In {\em International Conference of Machine Learning}, 2017.

\bibitem{altman1999constrained}
E.~Altman.
\newblock {\em Constrained {M}arkov decision processes}, volume~7.
\newblock CRC Press, 1999.

\bibitem{altman1998constrained}
Eitan Altman.
\newblock Constrained {M}arkov decision processes with total cost criteria:
  {L}agrangian approach and dual linear program.
\newblock {\em Mathematical methods of operations research}, 48(3):387--417,
  1998.

\bibitem{amodei2016concrete}
D.~Amodei, C.~Olah, J.~Steinhardt, P.~Christiano, J.~Schulman, and D.~Man{\'e}.
\newblock Concrete problems in {AI} safety.
\newblock {\em arXiv preprint arXiv:1606.06565}, 2016.

\bibitem{berkenkamp2017safe}
F.~Berkenkamp, M.~Turchetta, A.~Schoellig, and A.~Krause.
\newblock Safe model-based reinforcement learning with stability guarantees.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  908--919, 2017.

\bibitem{bertsekas1995dynamic}
D.~Bertsekas.
\newblock {\em Dynamic programming and optimal control}.
\newblock Athena scientific Belmont, MA, 1995.

\bibitem{boyd2004convex}
S.~Boyd and L.~Vandenberghe.
\newblock {\em Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem{el2016convex}
M~El Chamie, Y.~Yu, and B.~A{\c{c}}{\i}kme{\c{s}}e.
\newblock Convex synthesis of randomized policies for controlled {M}arkov
  chains with density safety upper bound constraints.
\newblock In {\em American Control Conference}, pages 6290--6295, 2016.

\bibitem{chow2015trading}
Y.~Chow, M.~Pavone, B.~Sadler, and S.~Carpin.
\newblock Trading safety versus performance: Rapid deployment of robotic swarms
  with robust performance constraints.
\newblock {\em Journal of Dynamic Systems, Measurement, and Control}, 137(3),
  2015.

\bibitem{chow2015risk}
Yinlam Chow, Mohammad Ghavamzadeh, Lucas Janson, and Marco Pavone.
\newblock Risk-constrained reinforcement learning with percentile risk
  criteria.
\newblock {\em arXiv preprint arXiv:1512.01629}, 2015.

\bibitem{dalal2018safe}
G.~Dalal, K.~Dvijotham, M.~Vecerik, T.~Hester, C.~Paduraru, and Y.~Tassa.
\newblock Safe exploration in continuous action spaces.
\newblock {\em arXiv preprint arXiv:1801.08757}, 2018.

\bibitem{gabor1998multi}
Z.~G{\'a}bor and Z.~Kalm{\'a}r.
\newblock Multi-criteria reinforcement learning.
\newblock In {\em International Conference of Machine Learning}, 1998.

\bibitem{geibel2005risk}
P.~Geibel and F.~Wysotzki.
\newblock Risk-sensitive reinforcement learning applied to control under
  constraints.
\newblock {\em Journal of Artificial Intelligence Research}, 24:81--108, 2005.

\bibitem{glynn2008bounding}
P.~Glynn, A.~Zeevi, et~al.
\newblock Bounding stationary expectations of markov processes.
\newblock In {\em Markov processes and related topics: a Festschrift for Thomas
  G. Kurtz}, pages 195--214. Institute of Mathematical Statistics, 2008.

\bibitem{gu2016continuous}
S.~Gu, T.~Lillicrap, I.~Sutskever, and S.~Levine.
\newblock Continuous deep {Q-}learning with model-based acceleration.
\newblock In {\em International Conference on Machine Learning}, pages
  2829--2838, 2016.

\bibitem{junges2016safety}
S.~Junges, N.~Jansen, C.~Dehnert, U.~Topcu, and J.~Katoen.
\newblock Safety-constrained reinforcement learning for {MDPs}.
\newblock In {\em International Conference on Tools and Algorithms for the
  Construction and Analysis of Systems}, pages 130--146, 2016.

\bibitem{kakade2002approximately}
S.~Kakade and J.~Langford.
\newblock Approximately optimal approximate reinforcement learning.
\newblock In {\em International Conference on International Conference on
  Machine Learning}, pages 267--274, 2002.

\bibitem{khalil1996noninear}
Hassan~K Khalil.
\newblock Noninear systems.
\newblock {\em Prentice-Hall, New Jersey}, 2(5):5--1, 1996.

\bibitem{lee2017first}
J.~Lee, I.~Panageas, G.~Piliouras, M.~Simchowitz, M.~Jordan, and B.~Recht.
\newblock First-order methods almost always avoid saddle points.
\newblock {\em arXiv preprint arXiv:1710.07406}, 2017.

\bibitem{leike2017ai}
J.~Leike, M.~Martic, V.~Krakovna, P.~Ortega, T.~Everitt, A.~Lefrancq,
  L.~Orseau, and S.~Legg.
\newblock Ai safety gridworlds.
\newblock {\em arXiv preprint arXiv:1711.09883}, 2017.

\bibitem{luenberger1984linear}
D.~Luenberger, Y.~Ye, et~al.
\newblock {\em Linear and nonlinear programming}, volume~2.
\newblock Springer, 1984.

\bibitem{mastronarde2011fast}
N.~Mastronarde and M.~van~der Schaar.
\newblock Fast reinforcement learning for energy-efficient wireless
  communication.
\newblock {\em IEEE Transactions on Signal Processing}, 59(12):6262--6266,
  2011.

\bibitem{mnih2013playing}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra, and
  M.~Riedmiller.
\newblock Playing {A}tari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{moldovan2012safe}
T.~Moldovan and P.~Abbeel.
\newblock Safe exploration in {M}arkov decision processes.
\newblock {\em arXiv preprint arXiv:1205.4810}, 2012.

\bibitem{mossalam2016multi}
H.~Mossalam, Y.~Assael, D.~Roijers, and S.~Whiteson.
\newblock Multi-objective deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1610.02707}, 2016.

\bibitem{neely2010stochastic}
M.~Neely.
\newblock Stochastic network optimization with application to communication and
  queueing systems.
\newblock {\em Synthesis Lectures on Communication Networks}, 3(1):1--211,
  2010.

\bibitem{neu2017unified}
G.~Neu, A.~Jonsson, and V.~G{\'o}mez.
\newblock A unified view of entropy-regularized markov decision processes.
\newblock {\em arXiv preprint arXiv:1705.07798}, 2017.

\bibitem{ono2015chance}
M.~Ono, M.~Pavone, Y.~Kuwata, and J.~Balaram.
\newblock Chance-constrained dynamic programming with application to risk-aware
  robotic space exploration.
\newblock {\em Autonomous Robots}, 39(4):555--571, 2015.

\bibitem{perkins2002lyapunov}
T.~Perkins and A.~Barto.
\newblock Lyapunov design for safe reinforcement learning.
\newblock {\em Journal of Machine Learning Research}, 3:803--832, 2002.

\bibitem{regan2009regret}
K.~Regan and C.~Boutilier.
\newblock Regret-based reward elicitation for {M}arkov decision processes.
\newblock In {\em Proceedings of the Twenty-Fifth Conference on Uncertainty in
  Artificial Intelligence}, pages 444--451, 2009.

\bibitem{roijers2013survey}
D.~Roijers, P.~Vamplew, S.~Whiteson, and R.~Dazeley.
\newblock A survey of multi-objective sequential decision-making.
\newblock {\em Journal of Artificial Intelligence Research}, 48:67--113, 2013.

\bibitem{rusu2015policy}
A.~Rusu, S.~Colmenarejo, C.~Gulcehre, G.~Desjardins, J.~Kirkpatrick,
  R.~Pascanu, V.~Mnih, K.~Kavukcuoglu, and R.~Hadsell.
\newblock Policy distillation.
\newblock {\em arXiv preprint arXiv:1511.06295}, 2015.

\bibitem{schaul2015prioritized}
T.~Schaul, J.~Quan, I.~Antonoglou, and D.~Silver.
\newblock Prioritized experience replay.
\newblock {\em arXiv preprint arXiv:1511.05952}, 2015.

\bibitem{scherrer2013performance}
Bruno Scherrer.
\newblock Performance bounds for $\lambda$ policy iteration and application to
  the game of {T}etris.
\newblock {\em Journal of Machine Learning Research}, 14(Apr):1181--1227, 2013.

\bibitem{schmitt2006complexity}
M.~Schmitt and L.~Martignon.
\newblock On the complexity of learning lexicographic strategies.
\newblock {\em Journal of Machine Learning Research}, 7:55--83, 2006.

\bibitem{shani2005mdp}
G.~Shani, D.~Heckerman, and R.~Brafman.
\newblock An {MDP}-based recommender system.
\newblock {\em Journal of Machine Learning Research}, 6:1265--1295, 2005.

\bibitem{tamar2012policy}
A.~Tamar, D.~Di Castro, and S.~Mannor.
\newblock Policy gradients with variance related risk criteria.
\newblock In {\em International Conference of Machine Learning}, 2012.

\bibitem{hasselt2010double}
H.~van Hasselt.
\newblock Double {Q-}learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2613--2621, 2010.

\end{thebibliography}
