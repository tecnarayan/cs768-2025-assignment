\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{abadi2016deep}
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.~B., Mironov, I., Talwar, K.,
  and Zhang, L.
\newblock Deep learning with differential privacy.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC conference on computer
  and communications security}, pp.\  308--318, 2016.

\bibitem[Amodei et~al.(2016)Amodei, Ananthanarayanan, Anubhai, Bai, Battenberg,
  Case, Casper, Catanzaro, Cheng, Chen, et~al.]{amodei2016deep}
Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case,
  C., Casper, J., Catanzaro, B., Cheng, Q., Chen, G., et~al.
\newblock Deep speech 2: End-to-end speech recognition in english and mandarin.
\newblock In \emph{International conference on machine learning}, pp.\
  173--182. PMLR, 2016.

\bibitem[Anil et~al.(2021)Anil, Ghazi, Gupta, Kumar, and Manurangsi]{DPBert}
Anil, R., Ghazi, B., Gupta, V., Kumar, R., and Manurangsi, P.
\newblock Large-scale differentially private bert, 2021.
\newblock URL \url{https://arxiv.org/abs/2108.01624}.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{LayerNorm}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization, 2016.
\newblock URL \url{https://arxiv.org/abs/1607.06450}.

\bibitem[Balle et~al.(2020)Balle, Barthe, Gaboardi, Hsu, and
  Sato]{balle2020hypothesis}
Balle, B., Barthe, G., Gaboardi, M., Hsu, J., and Sato, T.
\newblock Hypothesis testing interpretations and {R}{\'e}nyi differential
  privacy.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  2496--2506. PMLR, 2020.

\bibitem[Bassily et~al.(2014)Bassily, Smith, and Thakurta]{bassily2014private}
Bassily, R., Smith, A., and Thakurta, A.
\newblock Private empirical risk minimization: Efficient algorithms and tight
  error bounds.
\newblock In \emph{55th Annual Symposium on Foundations of Computer Science
  (FOCS)}, pp.\  464--473. IEEE, 2014.

\bibitem[Brock et~al.(2021{\natexlab{a}})Brock, De, and Smith]{ConvBN}
Brock, A., De, S., and Smith, S.~L.
\newblock Characterizing signal propagation to close the performance gap in
  unnormalized resnets, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2101.08692}.

\bibitem[Brock et~al.(2021{\natexlab{b}})Brock, De, Smith, and Simonyan]{NFnet}
Brock, A., De, S., Smith, S.~L., and Simonyan, K.
\newblock High-performance large-scale image recognition without normalization,
  2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2102.06171}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{GPT}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D.
\newblock Language models are few-shot learners, 2020.
\newblock URL \url{https://arxiv.org/abs/2005.14165}.

\bibitem[Bu et~al.(2020)Bu, Dong, Long, and Su]{bu2020deep}
Bu, Z., Dong, J., Long, Q., and Su, W.~J.
\newblock Deep learning with gaussian differential privacy.
\newblock \emph{Harvard data science review}, 2020\penalty0 (23), 2020.

\bibitem[Bun \& Steinke(2016)Bun and Steinke]{bun2016concentrated}
Bun, M. and Steinke, T.
\newblock Concentrated differential privacy: Simplifications, extensions, and
  lower bounds.
\newblock In \emph{Theory of Cryptography Conference}, pp.\  635--658.
  Springer, 2016.

\bibitem[Bun et~al.(2018)Bun, Dwork, Rothblum, and Steinke]{bun2018composable}
Bun, M., Dwork, C., Rothblum, G.~N., and Steinke, T.
\newblock Composable and versatile privacy via truncated cdp.
\newblock In \emph{Proceedings of the 50th Annual ACM SIGACT Symposium on
  Theory of Computing}, pp.\  74--86, 2018.

\bibitem[Carlini et~al.(2019)Carlini, Liu, Erlingsson, Kos, and
  Song]{carlini2019secret}
Carlini, N., Liu, C., Erlingsson, {\'U}., Kos, J., and Song, D.
\newblock The secret sharer: Evaluating and testing unintended memorization in
  neural networks.
\newblock In \emph{28th {USENIX} Security Symposium}, pp.\  267--284, 2019.

\bibitem[Carlini et~al.(2021)Carlini, Tramer, Wallace, Jagielski, Herbert-Voss,
  Lee, Roberts, Brown, Song, Erlingsson, et~al.]{carlini2021extracting}
Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K.,
  Roberts, A., Brown, T., Song, D., Erlingsson, U., et~al.
\newblock Extracting training data from large language models.
\newblock In \emph{30th USENIX Security Symposium (USENIX Security 21)}, pp.\
  2633--2650, 2021.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{simclr}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.~E.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{CoRR}, abs/2002.05709, 2020.
\newblock URL \url{https://arxiv.org/abs/2002.05709}.

\bibitem[De et~al.(2022)De, Berrada, Hayes, Smith, and
  Balle]{DeepMindUnlocking}
De, S., Berrada, L., Hayes, J., Smith, S.~L., and Balle, B.
\newblock Unlocking high-accuracy differentially private image classification
  through scale, 2022.
\newblock URL \url{https://arxiv.org/abs/2204.13650}.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{Imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pp.\  248--255, 2009.
\newblock \doi{10.1109/CVPR.2009.5206848}.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{ViT}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale, 2020.
\newblock URL \url{https://arxiv.org/abs/2010.11929}.

\bibitem[Dwork \& Rothblum(2016)Dwork and Rothblum]{dwork2016concentrated}
Dwork, C. and Rothblum, G.~N.
\newblock Concentrated differential privacy.
\newblock \emph{arXiv preprint arXiv:1603.01887}, 2016.

\bibitem[Dwork et~al.(2006)Dwork, McSherry, Nissim, and
  Smith]{dwork2006calibrating}
Dwork, C., McSherry, F., Nissim, K., and Smith, A.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In \emph{Proceedings of the Third Conference on Theory of
  Cryptography}, pp.\  265–284, 2006.

\bibitem[Feldman et~al.(2018)Feldman, Mironov, Talwar, and
  Thakurta]{feldman2018privacy}
Feldman, V., Mironov, I., Talwar, K., and Thakurta, A.
\newblock Privacy amplification by iteration.
\newblock In \emph{2018 IEEE 59th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pp.\  521--532. IEEE, 2018.

\bibitem[Gopi et~al.(2021)Gopi, Lee, and Wutschitz]{gopi2021numerical}
Gopi, S., Lee, Y.~T., and Wutschitz, L.
\newblock Numerical composition of differential privacy.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11631--11642, 2021.

\bibitem[Gower et~al.(2019)Gower, Loizou, Qian, Sailanbayev, Shulgin, and
  Richt{\'a}rik]{gower2019sgd}
Gower, R.~M., Loizou, N., Qian, X., Sailanbayev, A., Shulgin, E., and
  Richt{\'a}rik, P.
\newblock Sgd: General analysis and improved rates.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5200--5209. PMLR, 2019.

\bibitem[Goyal et~al.(2017)Goyal, Doll{\'a}r, Girshick, Noordhuis, Wesolowski,
  Kyrola, Tulloch, Jia, and He]{goyal2017accurate}
Goyal, P., Doll{\'a}r, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola,
  A., Tulloch, A., Jia, Y., and He, K.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock \emph{arXiv preprint arXiv:1706.02677}, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{ResNets}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{BatchNorm}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{CoRR}, abs/1502.03167, 2015.
\newblock URL \url{http://arxiv.org/abs/1502.03167}.

\bibitem[Keskar et~al.(2016)Keskar, Mudigere, Nocedal, Smelyanskiy, and
  Tang]{keskar2016large}
Keskar, N.~S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P. T.~P.
\newblock On large-batch training for deep learning: Generalization gap and
  sharp minima.
\newblock \emph{arXiv preprint arXiv:1609.04836}, 2016.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kurakin et~al.(2022)Kurakin, Song, Chien, Geambasu, Terzis, and
  Thakurta]{google6imagenet}
Kurakin, A., Song, S., Chien, S., Geambasu, R., Terzis, A., and Thakurta, A.
\newblock Toward training at imagenet scale with differential privacy, 2022.
\newblock URL \url{https://arxiv.org/abs/2201.12328}.

\bibitem[Li et~al.(2021)Li, Tramèr, Liang, and Hashimoto]{li2021large}
Li, X., Tramèr, F., Liang, P., and Hashimoto, T.
\newblock Large language models can be strong differentially private learners,
  2021.

\bibitem[Liu \& Talwar(2019)Liu and Talwar]{liu2019private}
Liu, J. and Talwar, K.
\newblock Private selection from private candidates.
\newblock In \emph{Proceedings of the 51st Annual ACM SIGACT Symposium on
  Theory of Computing (STOC)}, pp.\  298--309, 2019.

\bibitem[Masters \& Luschi(2018)Masters and Luschi]{masters2018revisiting}
Masters, D. and Luschi, C.
\newblock Revisiting small batch training for deep neural networks.
\newblock \emph{arXiv preprint arXiv:1804.07612}, 2018.

\bibitem[Mironov(2017)]{mironov2017renyi}
Mironov, I.
\newblock R{\'e}nyi differential privacy.
\newblock In \emph{2017 IEEE 30th Computer Security Foundations Symposium
  (CSF)}, pp.\  263--275. IEEE, 2017.

\bibitem[Mironov et~al.(2019)Mironov, Talwar, and Zhang]{mironov2019r}
Mironov, I., Talwar, K., and Zhang, L.
\newblock R\'{e}nyi differential privacy of the {S}ampled {G}aussian
  {M}echanism.
\newblock \emph{arXiv preprint arXiv:1908.10530}, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Pesme et~al.(2021)Pesme, Pillaud-Vivien, and
  Flammarion]{pesme2021implicit}
Pesme, S., Pillaud-Vivien, L., and Flammarion, N.
\newblock Implicit bias of sgd for diagonal linear networks: a provable benefit
  of stochasticity.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 29218--29230, 2021.

\bibitem[Rae et~al.(2021)Rae, Borgeaud, Cai, Millican, Hoffmann, Song,
  Aslanides, Henderson, Ring, Young, Rutherford, Hennigan, Menick, Cassirer,
  Powell, Driessche, Hendricks, Rauh, Huang, Glaese, Welbl, Dathathri, Huang,
  Uesato, Mellor, Higgins, Creswell, McAleese, Wu, Elsen, Jayakumar,
  Buchatskaya, Budden, Sutherland, Simonyan, Paganini, Sifre, Martens, Li,
  Kuncoro, Nematzadeh, Gribovskaya, Donato, Lazaridou, Mensch, Lespiau,
  Tsimpoukelli, Grigorev, Fritz, Sottiaux, Pajarskas, Pohlen, Gong, Toyama,
  d'Autume, Li, Terzi, Mikulik, Babuschkin, Clark, Casas, Guy, Jones, Bradbury,
  Johnson, Hechtman, Weidinger, Gabriel, Isaac, Lockhart, Osindero, Rimell,
  Dyer, Vinyals, Ayoub, Stanway, Bennett, Hassabis, Kavukcuoglu, and
  Irving]{gopher}
Rae, J.~W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F.,
  Aslanides, J., Henderson, S., Ring, R., Young, S., Rutherford, E., Hennigan,
  T., Menick, J., Cassirer, A., Powell, R., Driessche, G. v.~d., Hendricks,
  L.~A., Rauh, M., Huang, P.-S., Glaese, A., Welbl, J., Dathathri, S., Huang,
  S., Uesato, J., Mellor, J., Higgins, I., Creswell, A., McAleese, N., Wu, A.,
  Elsen, E., Jayakumar, S., Buchatskaya, E., Budden, D., Sutherland, E.,
  Simonyan, K., Paganini, M., Sifre, L., Martens, L., Li, X.~L., Kuncoro, A.,
  Nematzadeh, A., Gribovskaya, E., Donato, D., Lazaridou, A., Mensch, A.,
  Lespiau, J.-B., Tsimpoukelli, M., Grigorev, N., Fritz, D., Sottiaux, T.,
  Pajarskas, M., Pohlen, T., Gong, Z., Toyama, D., d'Autume, C. d.~M., Li, Y.,
  Terzi, T., Mikulik, V., Babuschkin, I., Clark, A., Casas, D. d.~L., Guy, A.,
  Jones, C., Bradbury, J., Johnson, M., Hechtman, B., Weidinger, L., Gabriel,
  I., Isaac, W., Lockhart, E., Osindero, S., Rimell, L., Dyer, C., Vinyals, O.,
  Ayoub, K., Stanway, J., Bennett, L., Hassabis, D., Kavukcuoglu, K., and
  Irving, G.
\newblock Scaling language models: Methods, analysis \& insights from training
  gopher, 2021.
\newblock URL \url{https://arxiv.org/abs/2112.11446}.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{Dalle-2}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents,
  2022.
\newblock URL \url{https://arxiv.org/abs/2204.06125}.

\bibitem[Russakovsky et~al.(2014)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{Imagenet2}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock Imagenet large scale visual recognition challenge, 2014.
\newblock URL \url{https://arxiv.org/abs/1409.0575}.

\bibitem[Smith et~al.(2020)Smith, Elsen, and De]{SmallBS}
Smith, S.~L., Elsen, E., and De, S.
\newblock On the generalization benefit of noise in stochastic gradient
  descent.
\newblock \emph{CoRR}, abs/2006.15081, 2020.
\newblock URL \url{https://arxiv.org/abs/2006.15081}.

\bibitem[Tan \& Le(2019)Tan and Le]{tan2019efficientnet}
Tan, M. and Le, Q.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International conference on machine learning}, pp.\
  6105--6114. PMLR, 2019.

\bibitem[Touvron et~al.(2019)Touvron, Vedaldi, Douze, and
  J{\'e}gou]{touvron2019fixing}
Touvron, H., Vedaldi, A., Douze, M., and J{\'e}gou, H.
\newblock Fixing the train-test resolution discrepancy.
\newblock volume~32, 2019.

\bibitem[Touvron et~al.(2020)Touvron, Cord, Douze, Massa, Sablayrolles, and
  J{\'{e}}gou]{deit}
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., and J{\'{e}}gou,
  H.
\newblock Training data-efficient image transformers {\&} distillation through
  attention.
\newblock \emph{CoRR}, abs/2012.12877, 2020.
\newblock URL \url{https://arxiv.org/abs/2012.12877}.

\bibitem[Tramer \& Boneh(2020)Tramer and Boneh]{tramer2020differentially}
Tramer, F. and Boneh, D.
\newblock Differentially private learning needs better features (or much more
  data).
\newblock 2020.

\bibitem[Wang et~al.(2017)Wang, Ye, and Xu]{wang2017differentially}
Wang, D., Ye, M., and Xu, J.
\newblock Differentially private empirical risk minimization revisited: Faster
  and more general.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Wang et~al.(2019)Wang, Balle, and Kasiviswanathan]{wang2019subsampled}
Wang, Y.-X., Balle, B., and Kasiviswanathan, S.~P.
\newblock Subsampled r{\'e}nyi differential privacy and analytical moments
  accountant.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pp.\  1226--1235. PMLR, 2019.

\bibitem[Wightman(2019)]{rw2019timm}
Wightman, R.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Wu \& He(2018)Wu and He]{GroupNorm}
Wu, Y. and He, K.
\newblock Group normalization, 2018.
\newblock URL \url{https://arxiv.org/abs/1803.08494}.

\bibitem[Ye \& Shokri(2022)Ye and Shokri]{ye2022differentially}
Ye, J. and Shokri, R.
\newblock Differentially private learning needs hidden state (or much faster
  convergence).
\newblock \emph{arXiv preprint arXiv:2203.05363}, 2022.

\bibitem[Yousefpour et~al.(2021)Yousefpour, Shilov, Sablayrolles, Testuggine,
  Prasad, Malek, Nguyen, Ghosh, Bharadwaj, Zhao, Cormode, and
  Mironov]{yousefpour2021opacus}
Yousefpour, A., Shilov, I., Sablayrolles, A., Testuggine, D., Prasad, K.,
  Malek, M., Nguyen, J., Ghosh, S., Bharadwaj, A., Zhao, J., Cormode, G., and
  Mironov, I.
\newblock Opacus: User-friendly differential privacy library in {PyTorch},
  2021.

\bibitem[Yu et~al.(2021{\natexlab{a}})Yu, Naik, Backurs, Gopi, Inan, Kamath,
  Kulkarni, Lee, Manoel, Wutschitz, Yekhanin, and Zhang]{yu2021differentially}
Yu, D., Naik, S., Backurs, A., Gopi, S., Inan, H.~A., Kamath, G., Kulkarni, J.,
  Lee, Y.~T., Manoel, A., Wutschitz, L., Yekhanin, S., and Zhang, H.
\newblock Differentially private fine-tuning of language models,
  2021{\natexlab{a}}.

\bibitem[Yu et~al.(2021{\natexlab{b}})Yu, Zhang, Chen, Yin, and Liu]{LowRank}
Yu, D., Zhang, H., Chen, W., Yin, J., and Liu, T.-Y.
\newblock Large scale private learning via low-rank reparametrization,
  2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2106.09352}.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{WideResnets}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{CoRR}, abs/1605.07146, 2016.
\newblock URL \url{http://arxiv.org/abs/1605.07146}.

\end{thebibliography}
