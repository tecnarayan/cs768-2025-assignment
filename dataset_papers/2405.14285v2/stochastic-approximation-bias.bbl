\begin{thebibliography}{10}

\bibitem{allmeier2023bias}
Sebastian Allmeier and Nicolas Gast.
\newblock Bias and refinement of multiscale mean field models.
\newblock {\em Proceedings of the ACM on Measurement and Analysis of Computing Systems}, 7(1):1--29, 2023.

\bibitem{azizian2024long}
Wa{\"\i}ss Azizian, Franck Iutzeler, J{\'e}r{\^o}me Malick, and Panayotis Mertikopoulos.
\newblock What is the long-run distribution of stochastic gradient descent? a large deviations analysis.
\newblock {\em arXiv preprint arXiv:2406.09241}, 2024.

\bibitem{benaim2006dynamics}
Michel Bena{\"\i}m.
\newblock Dynamics of stochastic approximation algorithms.
\newblock In {\em Seminaire de probabilites XXXIII}, pages 1--68. Springer, 2006.

\bibitem{benveniste2012adaptive}
Albert Benveniste, Michel M{\'e}tivier, and Pierre Priouret.
\newblock {\em Adaptive algorithms and stochastic approximations}, volume~22.
\newblock Springer Science \& Business Media, 2012.

\bibitem{bertsekas2019reinforcement}
Dimitri Bertsekas.
\newblock {\em Reinforcement learning and optimal control}, volume~1.
\newblock Athena Scientific, 2019.

\bibitem{blum1954approximation}
Julius~R Blum.
\newblock Approximation methods which converge with probability one.
\newblock {\em The Annals of Mathematical Statistics}, pages 382--386, 1954.

\bibitem{bof2018lyapunov}
Nicoletta Bof, Ruggero Carli, and Luca Schenato.
\newblock Lyapunov theory for discrete time systems.
\newblock {\em arXiv preprint arXiv:1809.05289}, 2018.

\bibitem{borkar2009stochastic}
Vivek~S Borkar.
\newblock {\em Stochastic approximation: a dynamical systems viewpoint}, volume~48.
\newblock Springer, 2009.

\bibitem{borkar2000ode}
Vivek~S Borkar and Sean~P Meyn.
\newblock The ode method for convergence of stochastic approximation and reinforcement learning.
\newblock {\em SIAM Journal on Control and Optimization}, 38(2):447--469, 2000.

\bibitem{braverman2024high}
Anton Braverman, JG~Dai, and Xiao Fang.
\newblock High-order steady-state diffusion approximations.
\newblock {\em Operations Research}, 72(2):604--616, 2024.

\bibitem{chandak2022concentration}
Siddharth Chandak, Vivek~S Borkar, and Parth Dodhia.
\newblock Concentration of contractive stochastic approximation and reinforcement learning.
\newblock {\em Stochastic Systems}, 12(4):411--430, 2022.

\bibitem{chen2023hoeffding}
Hao Chen, Abhishek Gupta, Yin Sun, and Ness Shroff.
\newblock Hoeffding's inequality for markov chains under generalized concentrability condition.
\newblock {\em arXiv preprint arXiv:2310.02941}, 2023.

\bibitem{chen2023lyapunov}
Zaiwei Chen, Siva~T Maguluri, Sanjay Shakkottai, and Karthikeyan Shanmugam.
\newblock A lyapunov theory for finite-sample guarantees of markovian stochastic approximation.
\newblock {\em Operations Research}, 2023.

\bibitem{chen2023concentration}
Zaiwei Chen, Siva~Theja Maguluri, and Martin Zubeldia.
\newblock Concentration of contractive stochastic approximation: Additive and multiplicative noise.
\newblock {\em arXiv preprint arXiv:2303.15740}, 2023.

\bibitem{chen2022finite}
Zaiwei Chen, Sheng Zhang, Thinh~T Doan, John-Paul Clarke, and Siva~Theja Maguluri.
\newblock Finite-sample analysis of nonlinear stochastic approximation with applications in reinforcement learning.
\newblock {\em Automatica}, 146:110623, 2022.

\bibitem{dieuleveut2020bridging}
Aymeric Dieuleveut, Alain Durmus, and Francis Bach.
\newblock Bridging the gap between constant step size stochastic gradient descent and markov chains.
\newblock {\em The Annals of Statistics}, 48(3):pp. 1348--1382, 2020.

\bibitem{gast2017expected}
Nicolas Gast.
\newblock Expected values estimated via mean-field approximation are 1/n-accurate.
\newblock {\em Proceedings of the ACM on Measurement and Analysis of Computing Systems}, 1(1):1--26, 2017.

\bibitem{gast2017refined}
Nicolas Gast and Benny Van~Houdt.
\newblock A refined mean field approximation.
\newblock {\em Proceedings of the ACM on Measurement and Analysis of Computing Systems}, 1(2):1--28, 2017.

\bibitem{hildebrand1987introduction}
Francis~Begnaud Hildebrand.
\newblock {\em Introduction to numerical analysis}.
\newblock Courier Corporation, 1987.

\bibitem{huo2023bias}
Dongyan Huo, Yudong Chen, and Qiaomin Xie.
\newblock Bias and extrapolation in markovian linear stochastic approximation with constant stepsizes.
\newblock In {\em Abstract Proceedings of the 2023 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems}, pages 81--82, 2023.

\bibitem{khalil_nonlinear_2002}
Hassan~K Khalil.
\newblock {\em Nonlinear systems}.
\newblock Prentice Hall, Upper Saddle River, {N.J.}, 2002.

\bibitem{kolokoltsovMeanFieldGames2012}
Vassili~N. Kolokoltsov, Jiajie Li, and Wei Yang.
\newblock Mean {{Field Games}} and {{Nonlinear Markov Processes}}.
\newblock {\em arXiv:1112.3744}, April 2012.

\bibitem{kushner2003stochastic}
H.~Kushner and G.G. Yin.
\newblock {\em Stochastic Approximation and Recursive Algorithms and Applications}.
\newblock Stochastic Modelling and Applied Probability. Springer New York, 2003.

\bibitem{lan2020first}
Guanghui Lan.
\newblock {\em First-order and stochastic optimization methods for machine learning}, volume~1.
\newblock Springer, 2020.

\bibitem{lauand2023curse}
Caio~Kalil Lauand and Sean Meyn.
\newblock The curse of memory in stochastic approximation.
\newblock In {\em 2023 62nd IEEE Conference on Decision and Control (CDC)}, pages 7803--7809. IEEE, 2023.

\bibitem{mou2021optimal}
Wenlong Mou, Ashwin Pananjady, Martin~J Wainwright, and Peter~L Bartlett.
\newblock Optimal and instance-dependent guarantees for markovian linear stochastic approximation.
\newblock {\em arXiv preprint arXiv:2112.12770}, 2021.

\bibitem{moulines2011non}
Eric Moulines and Francis Bach.
\newblock Non-asymptotic analysis of stochastic approximation algorithms for machine learning.
\newblock {\em Advances in neural information processing systems}, 24, 2011.

\bibitem{polyak1992acceleration}
Boris~T Polyak and Anatoli~B Juditsky.
\newblock Acceleration of stochastic approximation by averaging.
\newblock {\em SIAM journal on control and optimization}, 30(4):838--855, 1992.

\bibitem{qu2020finite}
Guannan Qu and Adam Wierman.
\newblock Finite-time analysis of asynchronous stochastic approximation and $q$-learning.
\newblock In {\em Conference on Learning Theory}, pages 3185--3205. PMLR, 2020.

\bibitem{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock {\em The annals of mathematical statistics}, pages 400--407, 1951.

\bibitem{ruppert1988efficient}
David Ruppert.
\newblock Efficient estimations from a slowly convergent robbins-monro process.
\newblock Technical report, Cornell University Operations Research and Industrial Engineering, 1988.

\bibitem{sheshukova2024nonasymptotic}
Marina Sheshukova, Denis Belomestny, Alain Durmus, Eric Moulines, Alexey Naumov, and Sergey Samsonov.
\newblock Nonasymptotic analysis of stochastic gradient descent with the richardson-romberg extrapolation.
\newblock {\em arXiv preprint arXiv:2410.05106}, 2024.

\bibitem{srikant2019finite}
Rayadurgam Srikant and Lei Ying.
\newblock Finite-time error bounds for linear stochastic approximation andtd learning.
\newblock In {\em Conference on Learning Theory}, pages 2803--2830. PMLR, 2019.

\bibitem{stein1986approximate}
Charles Stein.
\newblock Approximate computation of expectations.
\newblock {\em Lecture Notes-Monograph Series}, 7:i--164, 1986.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{tsitsiklis1994asynchronous}
John~N Tsitsiklis.
\newblock Asynchronous stochastic approximation and q-learning.
\newblock {\em Machine learning}, 16:185--202, 1994.

\bibitem{watkins1992q}
Christopher~JCH Watkins and Peter Dayan.
\newblock Q-learning.
\newblock {\em Machine learning}, 8:279--292, 1992.

\bibitem{yasodharan2022large}
Sarath Yasodharan and Rajesh Sundaresan.
\newblock Large deviations of mean-field interacting particle systems in a fast varying environment.
\newblock {\em The Annals of Applied Probability}, 32(3):1666--1704, 2022.

\bibitem{ying2016rate}
Lei Ying.
\newblock On the approximation error of mean-field models.
\newblock In {\em Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science}, pages 285--297. ACM, 2016.

\bibitem{ying2017stein}
Lei Ying.
\newblock Stein's method for mean field approximations in light and heavy traffic regimes.
\newblock {\em Proceedings of the ACM on Measurement and Analysis of Computing Systems}, 1(1):12, 2017.

\bibitem{yu2021analysis}
Lu~Yu, Krishnakumar Balasubramanian, Stanislav Volgushev, and Murat~A Erdogdu.
\newblock An analysis of constant step size sgd in the non-convex regime: Asymptotic normality and bias.
\newblock {\em Advances in Neural Information Processing Systems}, 34:4234--4248, 2021.

\bibitem{zhang2024constant}
Yixuan Zhang and Qiaomin Xie.
\newblock Constant stepsize q-learning: Distributional convergence, bias and extrapolation.
\newblock {\em arXiv preprint arXiv:2401.13884}, 2024.

\end{thebibliography}
