\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{International conference on machine learning}, pages
  1278--1286. PMLR, 2014.

\bibitem[Kingma et~al.(2014)Kingma, Mohamed, Rezende, and
  Welling]{kingma2014semi}
Diederik~P Kingma, Shakir Mohamed, Danilo~Jimenez Rezende, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In \emph{Advances in neural information processing systems}, pages
  3581--3589, 2014.

\bibitem[An and Cho(2015)]{an2015variational}
Jinwon An and Sungzoon Cho.
\newblock Variational autoencoder based anomaly detection using reconstruction
  probability.
\newblock \emph{Special Lecture on IE}, 2\penalty0 (1), 2015.

\bibitem[Zhang et~al.(2016)Zhang, Xiong, Su, Duan, and
  Zhang]{zhang2016variational}
Biao Zhang, Deyi Xiong, Jinsong Su, Hong Duan, and Min Zhang.
\newblock Variational neural machine translation.
\newblock \emph{arXiv preprint arXiv:1605.07869}, 2016.

\bibitem[Eslami et~al.(2018)Eslami, Rezende, Besse, Viola, Morcos, Garnelo,
  Ruderman, Rusu, Danihelka, Gregor, et~al.]{eslami2018neural}
SM~Ali Eslami, Danilo~Jimenez Rezende, Frederic Besse, Fabio Viola, Ari~S
  Morcos, Marta Garnelo, Avraham Ruderman, Andrei~A Rusu, Ivo Danihelka, Karol
  Gregor, et~al.
\newblock Neural scene representation and rendering.
\newblock \emph{Science}, 360\penalty0 (6394):\penalty0 1204--1210, 2018.

\bibitem[Kumar et~al.(2018)Kumar, Eslami, Rezende, Garnelo, Viola, Lockhart,
  and Shanahan]{kumar2018consistent}
Ananya Kumar, SM~Eslami, Danilo~J Rezende, Marta Garnelo, Fabio Viola, Edward
  Lockhart, and Murray Shanahan.
\newblock Consistent generative query networks.
\newblock \emph{arXiv preprint arXiv:1807.02033}, 2018.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In \emph{Advances in neural information processing systems}, pages
  4743--4751, 2016.

\bibitem[Van Den~Berg et~al.(2018)Van Den~Berg, Hasenclever, Tomczak, and
  Welling]{van2018sylvester}
Rianne Van Den~Berg, Leonard Hasenclever, Jakub~M Tomczak, and Max Welling.
\newblock Sylvester normalizing flows for variational inference.
\newblock In \emph{34th Conference on Uncertainty in Artificial Intelligence
  2018, UAI 2018}, pages 393--402. Association For Uncertainty in Artificial
  Intelligence (AUAI), 2018.

\bibitem[Huang et~al.(2018)Huang, Krueger, Lacoste, and
  Courville]{huang2018neural}
Chin-Wei Huang, David Krueger, Alexandre Lacoste, and Aaron Courville.
\newblock Neural autoregressive flows.
\newblock In \emph{International Conference on Machine Learning}, pages
  2078--2087. PMLR, 2018.

\bibitem[Hoffman(2017)]{hoffman2017learning}
Matthew~D Hoffman.
\newblock Learning deep latent gaussian models with markov chain monte carlo.
\newblock In \emph{International conference on machine learning}, pages
  1510--1519. PMLR, 2017.

\bibitem[Liu and Liu(2001)]{liu2001monte}
Jun~S Liu and Jun~S Liu.
\newblock \emph{Monte Carlo strategies in scientific computing}, volume~10.
\newblock Springer, 2001.

\bibitem[Robert et~al.(2004)Robert, Casella, and Casella]{robert2004monte}
Christian~P Robert, George Casella, and George Casella.
\newblock \emph{Monte Carlo statistical methods}, volume~2.
\newblock Springer, 2004.

\bibitem[Gilks et~al.(1995)Gilks, Richardson, and
  Spiegelhalter]{gilks1995markov}
Walter~R Gilks, Sylvia Richardson, and David Spiegelhalter.
\newblock \emph{Markov chain Monte Carlo in practice}.
\newblock CRC press, 1995.

\bibitem[Geyer(1992)]{geyer1992practical}
Charles~J Geyer.
\newblock Practical markov chain monte carlo.
\newblock \emph{Statistical science}, pages 473--483, 1992.

\bibitem[Hinton and Salakhutdinov(2006)]{hinton2006reducing}
Geoffrey~E Hinton and Ruslan~R Salakhutdinov.
\newblock Reducing the dimensionality of data with neural networks.
\newblock \emph{science}, 313\penalty0 (5786):\penalty0 504--507, 2006.

\bibitem[Neal(2011)]{neal2011mcmc}
Radford~M Neal.
\newblock Mcmc using hamiltonian dynamics.
\newblock \emph{Handbook of Markov Chain Monte Carlo}, page 113, 2011.

\bibitem[Kloeden and Platen(2013)]{kloeden2013numerical}
Peter~E Kloeden and Eckhard Platen.
\newblock \emph{Numerical solution of stochastic differential equations},
  volume~23.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Tieleman(2008)]{tieleman2008training}
Tijmen Tieleman.
\newblock Training restricted boltzmann machines using approximations to the
  likelihood gradient.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 1064--1071, 2008.

\bibitem[Han et~al.(2017)Han, Lu, Zhu, and Wu]{han2017alternating}
Tian Han, Yang Lu, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Alternating back-propagation for generator network.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~31, 2017.

\bibitem[DP and Ba(2015)]{dp2015adam}
Kingma DP and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{Proc. of the 3rd International Conference for Learning
  Representations (ICLR)}, 2015.

\bibitem[Shu et~al.(2018)Shu, Bui, Zhao, Kochenderfer, and
  Ermon]{shu2018amortized}
Rui Shu, Hung~H Bui, Shengjia Zhao, Mykel~J Kochenderfer, and Stefano Ermon.
\newblock Amortized inference regularization.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 4398--4407, 2018.

\bibitem[Xie et~al.(2019)Xie, Gao, Zheng, Zhu, and Wu]{xie2019learning}
Jianwen Xie, Ruiqi Gao, Zilong Zheng, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Learning dynamic generator model by alternating back-propagation
  through time.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 5498--5507, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Xie, and Barnes]{zhang2020learning}
Jing Zhang, Jianwen Xie, and Nick Barnes.
\newblock Learning noise-aware encoder-decoder from noisy labels by alternating
  back-propagation for saliency detection.
\newblock \emph{arXiv preprint arXiv:2007.12211}, 2020.

\bibitem[Xing et~al.(2018)Xing, Gao, Han, Zhu, and Wu]{xing2018deformable}
Xianglei Xing, Ruiqi Gao, Tian Han, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Deformable generator network: Unsupervised disentanglement of
  appearance and geometry.
\newblock \emph{arXiv preprint arXiv:1806.06298}, 2018.

\bibitem[Zhu et~al.(2019)Zhu, Xie, Liu, and Elgammal]{zhu2019learning}
Yizhe Zhu, Jianwen Xie, Bingchen Liu, and Ahmed Elgammal.
\newblock Learning feature-to-feature translator by alternating
  back-propagation for generative zero-shot learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9844--9854, 2019.

\bibitem[Li et~al.(2017)Li, Turner, and Liu]{li2017approximate}
Yingzhen Li, Richard~E Turner, and Qiang Liu.
\newblock Approximate inference with amortised mcmc.
\newblock \emph{arXiv preprint arXiv:1702.08343}, 2017.

\bibitem[Salimans et~al.(2015)Salimans, Kingma, and
  Welling]{salimans2015markov}
Tim Salimans, Diederik Kingma, and Max Welling.
\newblock Markov chain monte carlo and variational inference: Bridging the gap.
\newblock In \emph{International Conference on Machine Learning}, pages
  1218--1226. PMLR, 2015.

\bibitem[Ng et~al.(2011)]{ng2011sparse}
Andrew Ng et~al.
\newblock Sparse autoencoder.
\newblock \emph{CS294A Lecture notes}, 72\penalty0 (2011):\penalty0 1--19,
  2011.

\bibitem[Titsias and Ruiz(2019)]{titsias2019unbiased}
Michalis~K Titsias and Francisco Ruiz.
\newblock Unbiased implicit variational inference.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 167--176. PMLR, 2019.

\bibitem[Jacob et~al.(2020)Jacob, O’Leary, and
  Atchad{\'e}]{jacob2020unbiased}
Pierre~E Jacob, John O’Leary, and Yves~F Atchad{\'e}.
\newblock Unbiased markov chain monte carlo methods with couplings.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 82\penalty0 (3):\penalty0 543--600, 2020.

\bibitem[Vahdat and Kautz(2020)]{vahdat2020nvae}
Arash Vahdat and Jan Kautz.
\newblock Nvae: A deep hierarchical variational autoencoder.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 19667--19679, 2020.

\bibitem[Child(2020)]{child2020very}
Rewon Child.
\newblock Very deep vaes generalize autoregressive models and can outperform
  them on images.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and
  Kingma]{salimans2017pixelcnn++}
Tim Salimans, Andrej Karpathy, Xi~Chen, and Diederik~P Kingma.
\newblock Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
  likelihood and other modifications.
\newblock \emph{arXiv preprint arXiv:1701.05517}, 2017.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Rezende and Viola(2018)]{rezende2018taming}
Danilo~Jimenez Rezende and Fabio Viola.
\newblock Taming vaes.
\newblock \emph{arXiv preprint arXiv:1810.00597}, 2018.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\end{thebibliography}
