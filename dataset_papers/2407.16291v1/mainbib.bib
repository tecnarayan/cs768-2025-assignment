% object box tracking 
@inproceedings{meinhardt2022trackformer,
  title={{TrackFormer: Multi-Object Tracking with Transformers}},
  author={Meinhardt, Tim and Kirillov, Alexander and Leal-Taixe, Laura and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8844--8854},
  year={2022}
}
@article{sun2012transtrack,
  title={{TransTrack: Multiple Object Tracking with Transformer}},
  author={Sun, Peize and Cao, J and Jiang, Y and Zhang, R and Xie, E and Yuan, Z and Wang, C and Luo, P},
  journal={arXiv preprint arXiv:2012.15460},
  year={2012}
}
@article{xu2022transcenter,
  title={{TransCenter: Transformers with Dense Representations for Multiple-Object Tracking}},
  author={Xu, Yihong and Ban, Yutong and Delorme, Guillaume and Gan, Chuang and Rus, Daniela and Alameda-Pineda, Xavier},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={6},
  pages={7820--7835},
  year={2022},
  publisher={IEEE}
}
@inproceedings{zeng2022motr,
  title={{MOTR: End-to-End Multiple-Object Tracking with Transformer}},
  author={Zeng, Fangao and Dong, Bin and Zhang, Yuang and Wang, Tiancai and Zhang, Xiangyu and Wei, Yichen},
  booktitle={European Conference on Computer Vision},
  pages={659--675},
  year={2022},
  organization={Springer}
}



@inproceedings{neoral2024mft,
  title={{MFT: Long-Term Tracking of Every Pixel}},
  author={Neoral, Michal and {\v{S}}er{\`y}ch, Jon{\'a}{\v{s}} and Matas, Ji{\v{r}}{\'\i}},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6837--6847},
  year={2024}
}
@inproceedings{harley2022particle,
  title={{Particle Video Revisited: Tracking Through Occlusions Using Point Trajectories}},
  author={Harley, Adam W and Fang, Zhaoyuan and Fragkiadaki, Katerina},
  booktitle={European Conference on Computer Vision},
  pages={59--75},
  year={2022},
  organization={Springer}
}
@article{karaev2023cotracker,
  title={{CoTracker: It is Better to Track Together}},
  author={Karaev, Nikita and Rocco, Ignacio and Graham, Benjamin and Neverova, Natalia and Vedaldi, Andrea and Rupprecht, Christian},
  journal={arXiv preprint arXiv:2307.07635},
  year={2023}
}
@article{doersch2022tap,
  title={{TAP-Vid: A Benchmark for Tracking Any Point in a Video}},
  author={Doersch, Carl and Gupta, Ankush and Markeeva, Larisa and Recasens, Adri{\`a} and Smaira, Lucas and Aytar, Yusuf and Carreira, Jo{\~a}o and Zisserman, Andrew and Yang, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={13610--13626},
  year={2022}
}
@article{doersch2024bootstap,
  title={{BootsTAP: Bootstrapped Training for Tracking-Any-Point}},
  author={Doersch, Carl and Yang, Yi and Gokay, Dilara and Luc, Pauline and Koppula, Skanda and Gupta, Ankush and Heyward, Joseph and Goroshin, Ross and Carreira, Jo{\~a}o and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2402.00847},
  year={2024}
}
@inproceedings{teed2020raft,
  title={{RAFT: Recurrent All-Pairs Field Transforms for Optical Flow}},
  author={Teed, Zachary and Deng, Jia},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  pages={402--419},
  year={2020},
  organization={Springer}
}
@inproceedings{vendrow2023jrdb,
  title={{JRDB-Pose: A Large-scale Dataset for Multi-Person Pose Estimation and Tracking}},
  author={Vendrow, Edward and Le, Duy Tho and Cai, Jianfei and Rezatofighi, Hamid},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4811--4820},
  year={2023}
}
@article{liu2022dab,
  title={{DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR}},
  author={Liu, Shilong and Li, Feng and Zhang, Hao and Yang, Xiao and Qi, Xianbiao and Su, Hang and Zhu, Jun and Zhang, Lei},
  journal={arXiv preprint arXiv:2201.12329},
  year={2022}
}
@inproceedings{li2022dn,
  title={{DN-DETR: Accelerate DETR Training by Introducing Query DeNoising}},
  author={Li, Feng and Zhang, Hao and Liu, Shilong and Guo, Jian and Ni, Lionel M and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13619--13627},
  year={2022}
}
@article{zhang2022dino,
  title={{DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection}},
  author={Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel M and Shum, Heung-Yeung},
  journal={arXiv preprint arXiv:2203.03605},
  year={2022}
}

@inproceedings{carion2020end,
  title={{End-to-End Object Detection with Transformers}},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@article{zhu2020deformable,
  title={{Deformable DETR: Deformable Transformers for End-to-End Object Detection}},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}

@inproceedings{wang2022anchor,
  title={{Anchor DETR: Query Design for Transformer-Based Object Detection}},
  author={Wang, Yingming and Zhang, Xiangyu and Yang, Tong and Sun, Jian},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={3},
  pages={2567--2575},
  year={2022}
}

@inproceedings{meng2021conditional,
  title={{Conditional DETR for Fast Training Convergence}},
  author={Meng, Depu and Chen, Xiaokang and Fan, Zejia and Zeng, Gang and Li, Houqiang and Yuan, Yuhui and Sun, Lei and Wang, Jingdong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3651--3660},
  year={2021}
}

@inproceedings{li2023dfa3d,
  title={{DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting}},
  author={Li, Hongyang and Zhang, Hao and Zeng, Zhaoyang and Liu, Shilong and Li, Feng and Ren, Tianhe and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6684--6693},
  year={2023}
}

@article{zhuang2022understanding,
  title={{Understanding AdamW through Proximal Methods and Scale-Freeness}},
  author={Zhuang, Zhenxun and Liu, Mingrui and Cutkosky, Ashok and Orabona, Francesco},
  journal={arXiv preprint arXiv:2202.00089},
  year={2022}
}

@article{klinker2011exponential,
  title={{Exponential moving average versus moving exponential average}},
  author={Klinker, Frank},
  journal={Mathematische Semesterberichte},
  volume={58},
  pages={97--107},
  year={2011},
  publisher={Springer}
}

@inproceedings{greff2022kubric,
  title={{Kubric: A scalable dataset generator}},
  author={Greff, Klaus and Belletti, Francois and Beyer, Lucas and Doersch, Carl and Du, Yilun and Duckworth, Daniel and Fleet, David J and Gnanapragasam, Dan and Golemo, Florian and Herrmann, Charles and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3749--3761},
  year={2022}
}

@article{Horn_Schunck_1981,   
    title={{Determining Optical Flow}},  
    journal={Artificial Intelligence},  
    author={Horn, Berthold K.P. and Schunck, Brian G.},  
    year={1981},  month={Aug},  pages={185–203},  language={en-US}  
}
@inproceedings{Black_Anandan_2002,   title={{A Framework for the Robust Estimation of Optical Flow}},  booktitle={1993 (4th) International Conference on Computer Vision},  author={Black, M.J. and Anandan, P.},  year={2002},  month={Dec},  language={en-US}  }
@article{Bruhn_Weickert_Schnörr_2005,   title={Lucas/Kanade meets Horn/Schunck: combining local and global optic flow methods},  journal={International Journal of Computer Vision,International Journal of Computer Vision},  author={Bruhn, Andrés and Weickert, Joachim and Schnörr, Christoph},  year={2005},  month={Feb},  language={en-US}  }
@inproceedings{Dosovitskiy_Fischer_Ilg_Hausser_Hazirbas_Golkov_Smagt_Cremers_Brox_2015,   
    title={{FlowNet: Learning Optical Flow with Convolutional Networks}},  
    booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},  author={Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Smagt, Patrick van der and Cremers, Daniel and Brox, Thomas},  year={2015},  month={Dec},  language={en-US}  
}
@inproceedings{Ilg_Mayer_Saikia_Keuper_Dosovitskiy_Brox_2017,   title={{FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks}},  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},  author={Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},  year={2017},  month={Jul},  language={en-US}  }
@inproceedings{Xu_Ranftl_Koltun_2017,   title={{Accurate Optical Flow via Direct Cost Volume Processing}},  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},  author={Xu, Jia and Ranftl, Rene and Koltun, Vladlen},  year={2017},  month={Jul},  language={en-US}  }
@inproceedings{Sun_Yang_Liu_Kautz_2018,   title={{PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume}},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},  year={2018},  month={Jun},  language={en-US}  }
@article{Wang_Zhong_Dai_Zhang_Ji_Li_2020,   title={{Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation}},  journal={Cornell University - arXiv,Cornell University - arXiv},  author={Wang, Jianyuan and Zhong, Yiran and Dai, Yuchao and Zhang, Kaihao and Ji, Pan and Li, Hongdong},  year={2020},  month={Oct},  language={en-US}  }
@inproceedings{Jiang_Lu_Li_Hartley_2021,   title={{Learning Optical Flow from a Few Matches}},  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},  author={Jiang, Shihao and Lu, Yao and Li, Hongdong and Hartley, Richard},  year={2021},  month={Jun},  language={en-US}  }
@article{Xu_Yang_Cai_Zhang_Tong_2021,   title={{High-Resolution Optical Flow from 1D Attention and Correlation}},  journal={Cornell University - arXiv,Cornell University - arXiv},  author={Xu, Haofei and Yang, Jiaolong and Cai, Jianfei and Zhang, Jie and Tong, Xin},  year={2021},  month={Apr},  language={en-US}  }
@inproceedings{Zhang_Woodford_Prisacariu_Torr_2021,   title={{Separable Flow: Learning Motion Cost Volumes for Optical Flow Estimation}},  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},  author={Zhang, Feihu and Woodford, Oliver J. and Prisacariu, Victor and Torr, Philip H. S.},  year={2021},  month={Oct},  language={en-US}  }
@article{Huang_Shi_Zhang_Wang_Cheung_Qin_Dai_Li,   title={{FlowFormer: A Transformer Architecture for Optical Flow}},  author={Huang, Zhaoyang and Shi, Xiaoyu and Zhang, Chao and Wang, Qiang and Cheung, KaChun and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},  language={en-US}  }
@article{Shi_Huang_Li_Zhang_Cheung_See_Qin_Dai_Li_2023,   title={{FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical Flow Estimation}},  author={Shi, Xiaoyu and Huang, Zhaoyang and Li, Dasong and Zhang, Manyuan and Cheung, KaChun and See, Simon and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},  year={2023},  month={Mar},  language={en-US}  }
@article{Zhao_Zhao_Zhang_Zhou_Metaxas,   title={{Global Matching with Overlapping Attention for Optical Flow Estimation}},  author={Zhao, Shiyu and Zhao, Long and Zhang, Zhixing and Zhou, Enyu and Metaxas, Dimitris},  language={en-US}  }
@article{yang2023unipose,
  title={{UniPose: Detecting Any Keypoints}},
  author={Yang, Jie and Zeng, Ailing and Zhang, Ruimao and Zhang, Lei},
  journal={arXiv preprint arXiv:2310.08530},
  year={2023}
}
@inproceedings{Guler_Neverova_Kokkinos_2018,   title={{DensePose: Dense Human Pose Estimation in the Wild}},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},  author={Guler, Riza Alp and Neverova, Natalia and Kokkinos, Iasonas},  year={2018},  month={Jun},  language={en-US}  }
@article{chen2023humanmac,
  title={{HumanMAC: Masked Motion Completion for Human Motion Prediction}},
  author={Chen, Ling-Hao and Zhang, Jiawei and Li, Yewen and Pang, Yiren and Xia, Xiaobo and Liu, Tongliang},
  journal={arXiv preprint arXiv:2302.03665},
  year={2023}
}
@inproceedings{wang2020combining,
  title={{Combining detection and tracking for human pose estimation in videos}},
  author={Wang, Manchen and Tighe, Joseph and Modolo, Davide},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11088--11096},
  year={2020}
}
@inproceedings{ning2020lighttrack,
  title={{LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking}},
  author={Ning, Guanghan and Pei, Jian and Huang, Heng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={1034--1035},
  year={2020}
}
@inproceedings{sun2022dancetrack,
  title={{Dancetrack: Multi-object tracking in uniform appearance and diverse motion}},
  author={Sun, Peize and Cao, Jinkun and Jiang, Yi and Yuan, Zehuan and Bai, Song and Kitani, Kris and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20993--21002},
  year={2022}
}
@article{sethi1987finding,
  title={{Finding Trajectories of Feature Points in a Monocular Image Sequence}},
  author={Sethi, Ishwar K and Jain, Ramesh},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  number={1},
  pages={56--73},
  year={1987},
  publisher={IEEE}
}
@article{li2023stereoscene,
  title={{StereoScene: BEV-Assisted Stereo Matching Empowers 3D Semantic Scene Completion}},
  author={Li, Bohan and Sun, Yasheng and Jin, Xin and Zeng, Wenjun and Zhu, Zheng and Wang, Xiaoefeng and Zhang, Yunpeng and Okae, James and Xiao, Hang and Du, Dalong},
  journal={arXiv preprint arXiv:2303.13959},
  year={2023}
}
@article{liang2019stereo,
  title={{Stereo Matching Using Multi-Level Cost Volume and Multi-Scale Feature Constancy}},
  author={Liang, Zhengfa and Guo, Yulan and Feng, Yiliu and Chen, Wei and Qiao, Linbo and Zhou, Li and Zhang, Jianfeng and Liu, Hengzhu},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={1},
  pages={300--315},
  year={2019},
  publisher={IEEE}
}
@inproceedings{zhao2023high,
  title={{High-Frequency Stereo Matching Network}},
  author={Zhao, Haoliang and Zhou, Huizhou and Zhang, Yongjun and Chen, Jie and Yang, Yitong and Zhao, Yong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1327--1336},
  year={2023}
}
@inproceedings{shen2021cfnet,
  title={{CFNet: Cascade and Fused Cost Volume for Robust Stereo Matching}},
  author={Shen, Zhelun and Dai, Yuchao and Rao, Zhibo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13906--13915},
  year={2021}
}
@inproceedings{xu2023iterative,
  title={{Iterative Geometry Encoding Volume for Stereo Matching}},
  author={Xu, Gangwei and Wang, Xianqi and Ding, Xiaohuan and Yang, Xin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21919--21928},
  year={2023}
}
@inproceedings{liu2024global,
  title={{Global Occlusion-Aware Transformer for Robust Stereo Matching}},
  author={Liu, Zihua and Li, Yizhou and Okutomi, Masatoshi},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3535--3544},
  year={2024}
}
@article{wang2023omnimotion,
    title   = {{Tracking Everything Everywhere All at Once}},
    author  = {Wang, Qianqian and Chang, Yen-Yu and Cai, Ruojin and Li, Zhengqi and Hariharan, Bharath and Holynski, Aleksander and Snavely, Noah},
    journal = {ICCV},
    year    = {2023}
}
@inproceedings{jiang2021cotr,
  title={{{COTR: Correspondence Transformer for Matching Across Images}}},
  author={Wei Jiang and Eduard Trulls and Jan Hosang and Andrea Tagliasacchi and Kwang Moo Yi},
  booktitle=ICCV,
  year={2021}
}
@article{greff2021kubric,
    title = {Kubric: a scalable dataset generator}, 
    author = {Klaus Greff and Francois Belletti and Lucas Beyer and Carl Doersch and
              Yilun Du and Daniel Duckworth and David J Fleet and Dan Gnanapragasam and
              Florian Golemo and Charles Herrmann and Thomas Kipf and Abhijit Kundu and
              Dmitry Lagun and Issam Laradji and Hsueh-Ti (Derek) Liu and Henning Meyer and
              Yishu Miao and Derek Nowrouzezahrai and Cengiz Oztireli and Etienne Pot and
              Noha Radwan and Daniel Rebain and Sara Sabour and Mehdi S. M. Sajjadi and Matan Sela and
              Vincent Sitzmann and Austin Stone and Deqing Sun and Suhani Vora and Ziyu Wang and
              Tianhao Wu and Kwang Moo Yi and Fangcheng Zhong and Andrea Tagliasacchi},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year = {2022},
}
@article{jabri2020space,
  title={Space-Time Correspondence as a Contrastive Random Walk},
  author={Jabri, Allan and Owens, Andrew and Efros, Alexei},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19545--19560},
  year={2020}
}
@inproceedings{xu2021vfs,
  title={Rethinking Self-supervised Correspondence Learning: A Video Frame-level Similarity Perspective},
  author={Xu, Jiarui and Wang, Xiaolong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10075--10085},
  year={2021}
}
@inproceedings{lai2020mast,
  title={MAST: A Memory-Augmented Self-Supervised Tracker},
  author={Lai, Zihang and Lu, Erika and Xie, Weidi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6479--6488},
  year={2020}
}
@article{vecerik2023robotap,
  title={{RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation}},
  author={Vecerik, Mel and Doersch, Carl and Yang, Yi and Davchev, Todor and Aytar, Yusuf and Zhou, Guangyao and Hadsell, Raia and Agapito, Lourdes and Scholz, Jon},
  journal={arXiv preprint arXiv:2308.15975},
  year={2023}
}
@inproceedings{shi2023videoflow,
  title={{VideoFlow: Exploiting Temporal Cues for Multi-frame Optical Flow Estimation}},
  author={Shi, Xiaoyu and Huang, Zhaoyang and Bian, Weikang and Li, Dasong and Zhang, Manyuan and Cheung, Ka Chun and See, Simon and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12469--12480},
  year={2023}
}
@article{xiao2024spatialtracker,
  title={SpatialTracker: Tracking Any 2D Pixels in 3D Space},
  author={Xiao, Yuxi and Wang, Qianqian and Zhang, Shangzhan and Xue, Nan and Peng, Sida and Shen, Yujun and Zhou, Xiaowei},
  journal={arXiv preprint arXiv:2404.04319},
  year={2024}
}
@article{li2024taptr,
  title={{TAPTR: Tracking Any Point with Transformers as Detection}},
  author={Li, Hongyang and Zhang, Hao and Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Lei},
  journal={arXiv preprint arXiv:2403.13042},
  year={2024}
}
@article{vaswani2017attention,
  title={{Attention Is All You Need}},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{li2023lite,
  title={{Lite DETR: An Interleaved Multi-Scale Encoder for Efficient DETR}},
  author={Li, Feng and Zeng, Ailing and Liu, Shilong and Zhang, Hao and Li, Hongyang and Zhang, Lei and Ni, Lionel M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18558--18567},
  year={2023}
}

% vos
@inproceedings{caelles2017one,
  title={{One-Shot Video Object Segmentation}},
  author={Caelles, Sergi and Maninis, Kevis-Kokitsi and Pont-Tuset, Jordi and Leal-Taix{\'e}, Laura and Cremers, Daniel and Van Gool, Luc},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={221--230},
  year={2017}
}

@article{pont20172017,
  title={{The 2017 DAVIS Challenge on Video Object Segmentation}},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}

@article{xu2018youtube,
  title={{A Large-Scale Video Object Segmentation Benchmark}},
  author={Xu, Ning and Yang, Linjie and Fan, Yuchen and Yue, Dingcheng and Liang, Yuchen and Yang, Jianchao and Huang, Thomas},
  journal={arXiv preprint arXiv:1809.03327},
  year={2018}
}

@article{yang2021associating,
  title={{Associating Objects with Transformers for Video Object Segmentation}},
  author={Yang, Zongxin and Wei, Yunchao and Yang, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2491--2502},
  year={2021}
}

@inproceedings{voigtlaender2019feelvos,
  title={{FEELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation}},
  author={Voigtlaender, Paul and Chai, Yuning and Schroff, Florian and Adam, Hartwig and Leibe, Bastian and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9481--9490},
  year={2019}
}

@inproceedings{oh2019video,
  title={Video Object Segmentation using Space-Time Memory Networks},
  author={Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon Joo},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9226--9235},
  year={2019}
}

% dynamic 3D 
@article{luiten2023dynamic,
  title={{Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis}},
  author={Luiten, Jonathon and Kopanas, Georgios and Leibe, Bastian and Ramanan, Deva},
  journal={arXiv preprint arXiv:2308.09713},
  year={2023}
}

@article{duisterhof2023md,
  title={{MD-Splatting: Learning Metric Deformation from 4D Gaussians in Highly Deformable Scenes}},
  author={Duisterhof, Bardienus P and Mandi, Zhao and Yao, Yunchao and Liu, Jia-Wei and Shou, Mike Zheng and Song, Shuran and Ichnowski, Jeffrey},
  journal={arXiv preprint arXiv:2312.00583},
  year={2023}
}

@article{yin20234dgen,
  title={{4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency}},
  author={Yin, Yuyang and Xu, Dejia and Wang, Zhangyang and Zhao, Yao and Wei, Yunchao},
  journal={arXiv preprint arXiv:2312.17225},
  year={2023}
}

@article{gu2023videoswap,
  title={{VideoSwap: Customized Video Subject Swapping with Interactive Semantic Point Correspondence}},
  author={Gu, Yuchao and Zhou, Yipin and Wu, Bichen and Yu, Licheng and Liu, Jia-Wei and Zhao, Rui and Wu, Jay Zhangjie and Zhang, David Junhao and Shou, Mike Zheng and Tang, Kevin},
  journal={arXiv preprint arXiv:2312.02087},
  year={2023}
}

@article{kratimenos2023dynmf,
  title={{DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis with 3D Gaussian Splatting}},
  author={Kratimenos, Agelos and Lei, Jiahui and Daniilidis, Kostas},
  journal={arXiv preprint arXiv:2312.00112},
  year={2023}
}

@inproceedings{wang2023tracking,
  title={{Tracking Everything Everywhere All at Once}},
  author={Wang, Qianqian and Chang, Yen-Yu and Cai, Ruojin and Li, Zhengqi and Hariharan, Bharath and Holynski, Aleksander and Snavely, Noah},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19795--19806},
  year={2023}
}

@inproceedings{doersch2023tapir,
  title={{TAPIR: Tracking Any Point with per-frame Initialization and temporal Refinement}},
  author={Doersch, Carl and Yang, Yi and Vecerik, Mel and Gokay, Dilara and Gupta, Ankush and Aytar, Yusuf and Carreira, Joao and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10061--10072},
  year={2023}
}

@inproceedings{zheng2023pointodyssey,
  title={{PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point Tracking}},
  author={Zheng, Yang and Harley, Adam W and Shen, Bokui and Wetzstein, Gordon and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19855--19865},
  year={2023}
}

@article{moing2023dense,
  title={{Dense Optical Tracking: Connecting the Dots}},
  author={Moing, Guillaume Le and Ponce, Jean and Schmid, Cordelia},
  journal={arXiv preprint arXiv:2312.00786},
  year={2023}
}

@article{jiang2024t,
  title={{T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy}},
  author={Jiang, Qing and Li, Feng and Zeng, Zhaoyang and Ren, Tianhe and Liu, Shilong and Zhang, Lei},
  journal={arXiv preprint arXiv:2403.14610},
  year={2024}
}

@article{li2023visual,
  title={Visual In-Context Prompting},
  author={Li, Feng and Jiang, Qing and Zhang, Hao and Ren, Tianhe and Liu, Shilong and Zou, Xueyan and Xu, Huaizhe and Li, Hongyang and Li, Chunyuan and Yang, Jianwei and others},
  journal={arXiv preprint arXiv:2311.13601},
  year={2023}
}

@inproceedings{carreira2017quo,
  title={{Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset}},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@article{song2024track,
  title={{Track Everything Everywhere Fast and Robustly}},
  author={Song, Yunzhou and Lei, Jiahui and Wang, Ziyun and Liu, Lingjie and Daniilidis, Kostas},
  journal={arXiv preprint arXiv:2403.17931},
  year={2024}
}