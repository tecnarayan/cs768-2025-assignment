% 1-22
% [1]
@article{du2024impacts,
  title={Impacts of Darwinian Evolution on Pre-trained Deep Neural Networks},
  author={Du, Guodong and Jiang, Runhua and Yang, Senqiao and Li, Haoyang and Chen, Wei and Li, Keren and Goh, Sim Kuan and Tang, Ho-Kin},
  journal={arXiv preprint arXiv:2408.05563},
  year={2024}
}


@article{yang2024evolutionary,
  title={Evolutionary Neural Architecture Search for 3D Point Cloud Analysis},
  author={Yang, Yisheng and Du, Guodong and Toa, Chean Khim and Tang, Ho-Kin and Goh, Sim Kuan},
  journal={arXiv preprint arXiv:2408.05556},
  year={2024}
}

@article{du2024knowledge,
  title={Knowledge Fusion By Evolving Weights of Language Models},
  author={Du, Guodong and Li, Jing and Liu, Hanting and Jiang, Runhua and Yu, Shuyang and Guo, Yifei and Goh, Sim Kuan and Tang, Ho-Kin},
  journal={arXiv preprint arXiv:2406.12208},
  year={2024}
}

@article{jiang2024cade,
  title={CADE: Cosine Annealing Differential Evolution for Spiking Neural Network},
  author={Jiang, Runhua and Du, Guodong and Yu, Shuyang and Guo, Yifei and Goh, Sim Kuan and Tang, Ho-Kin},
  journal={arXiv preprint arXiv:2406.02349},
  year={2024}
}

@article{li2023deep,
  title={Deep model fusion: A survey},
  author={Li, Weishi and Peng, Yong and Zhang, Miao and Ding, Liang and Hu, Han and Shen, Li},
  journal={arXiv preprint arXiv:2309.15698},
  year={2023}
}

@article{sagi2018ensemble,
  title={Ensemble learning: A survey},
  author={Sagi, Omer and Rokach, Lior},
  journal={Wiley interdisciplinary reviews: data mining and knowledge discovery},
  volume={8},
  number={4},
  pages={e1249},
  year={2018},
  publisher={Wiley Online Library}
}

%[3]
@article{jiang2023llm,
  title={Llm-blender: Ensembling large language models with pairwise ranking and generative fusion},
  author={Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2306.02561},
  year={2023}
}

%[4]
@inproceedings{ainsworth2022git,
  title={Git re-basin: Merging models modulo permutation symmetries},
  author={Ainsworth, Samuel K and Hayase, Jonathan and Srinivasa, Siddhartha},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2023}
}

%[5]
@article{xu2024training,
  title={Training-Free Pretrained Model Merging},
  author={Xu, Zhengqi and Yuan, Ke and Wang, Huiqiong and Wang, Yong and Song, Mingli and Song, Jie},
  journal={arXiv preprint arXiv:2403.01753},
  year={2024}
}

[6]
@inproceedings{stoica2023zipit,
  title={Zipit! merging models from different tasks without training},
  author={Stoica, George and Bolya, Daniel and Bjorner, Jakob and Ramesh, Pratik and Hearn, Taylor and Hoffman, Judy},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2024}
}

[7]
@article{wan2024knowledge,
  title={Knowledge fusion of large language models},
  author={Wan, Fanqi and Huang, Xinting and Cai, Deng and Quan, Xiaojun and Bi, Wei and Shi, Shuming},
  journal={arXiv preprint arXiv:2401.10491},
  year={2024}
}

[8]
@article{gupta2020stochastic,
  title={Stochastic weight averaging in parallel: Large-batch training that generalizes well},
  author={Gupta, Vipul and Serrano, Santiago Akle and DeCoste, Dennis},
  journal={arXiv preprint arXiv:2001.02312},
  year={2020}
}

[9]
@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={23965--23998},
  year={2022},
}

[10]
@article{arpit2022ensemble,
  title={Ensemble of averages: Improving model selection and boosting performance in domain generalization},
  author={Arpit, Devansh and Wang, Huan and Zhou, Yingbo and Xiong, Caiming},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={8265--8277},
  year={2022}
}

[11]
@article{rame2022diverse,
  title={Diverse weight averaging for out-of-distribution generalization},
  author={Rame, Alexandre and Kirchmeyer, Matthieu and Rahier, Thibaud and Rakotomamonjy, Alain and Gallinari, Patrick and Cord, Matthieu},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={10821--10836},
  year={2022}
}

[12]
@article{choshen2022fusing,
  title={Fusing finetuned models for better pretraining},
  author={Choshen, Leshem and Venezian, Elad and Slonim, Noam and Katz, Yoav},
  journal={arXiv preprint arXiv:2204.03044},
  year={2022}
}

[13]
@article{matena2022merging,
  title={Merging models with fisher-weighted averaging},
  author={Matena, Michael S and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={17703--17716},
  year={2022}
}

[14]
@article{fisher1922mathematical,
  title={On the mathematical foundations of theoretical statistics},
  author={Fisher, Ronald A},
  journal={Philosophical transactions of the Royal Society of London. Series A, containing papers of a mathematical or physical character},
  volume={222},
  number={594-604},
  pages={309--368},
  year={1922},
  publisher={The Royal Society London}
}


[15]
@article{jin2022dataless,
  title={Dataless knowledge fusion by merging weights of language models},
  author={Jin, Xisen and Ren, Xiang and Preotiuc-Pietro, Daniel and Cheng, Pengxiang},
  journal={arXiv preprint arXiv:2212.09849},
  year={2022}
}


[16]
@inproceedings{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2023}
}

[17]
@article{zhang2023composing,
  title={Composing parameter-efficient modules with arithmetic operation},
  author={Zhang, Jinghan and Liu, Junteng and He, Junxian and others},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={36},
  pages={12589--12610},
  year={2023}
}

[18]
@article{ties,
  title={Ties-merging: Resolving interference when merging models},
  author={Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin A and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={36},
  year={2024}
}

[19]
@inproceedings{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2022}
}

[20]
@article{huang2023lorahub,
  title={Lorahub: Efficient cross-task generalization via dynamic lora composition},
  author={Huang, Chengsong and Liu, Qian and Lin, Bill Yuchen and Pang, Tianyu and Du, Chao and Lin, Min},
  journal={arXiv preprint arXiv:2307.13269},
  year={2023}
}

[21]
@inproceedings{yang2023adamerging,
  title={Adamerging: Adaptive model merging for multi-task learning},
  author={Yang, Enneng and Wang, Zhenyi and Shen, Li and Liu, Shiwei and Guo, Guibing and Wang, Xingwei and Tao, Dacheng},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2024}
}

[22]
@article{yu2023language,
  title={Language models are super mario: Absorbing abilities from homologous models as a free lunch},
  author={Yu, Le and Yu, Bowen and Yu, Haiyang and Huang, Fei and Li, Yongbin},
  journal={arXiv preprint arXiv:2311.03099},
  year={2023}
}

[51]
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={30},
  year={2017}
}

[52]
@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7132--7141},
  year={2018}
}

[53]
@inproceedings{zhu2019empirical,
  title={An empirical study of spatial attention mechanisms in deep networks},
  author={Zhu, Xizhou and Cheng, Dazhi and Zhang, Zheng and Lin, Stephen and Dai, Jifeng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (CVPR)},
  pages={6688--6697},
  year={2019}
}

[54]
@inproceedings{liu2019end,
  title={End-to-end multi-task learning with attention},
  author={Liu, Shikun and Johns, Edward and Davison, Andrew J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1871--1880},
  year={2019}
}

[66]
@article{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={31},
  year={2018}
}

@article{singh2020model,
  title={Model fusion via optimal transport},
  author={Singh, Sidak Pal and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={22045--22055},
  year={2020}
}

@article{tatro2020optimizing,
  title={Optimizing mode connectivity via neuron alignment},
  author={Tatro, Norman and Chen, Pin-Yu and Das, Payel and Melnyk, Igor and Sattigeri, Prasanna and Lai, Rongjie},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={15300--15311},
  year={2020}
}

@article{li2015convergent,
  title={Convergent learning: Do different neural networks learn the same representations?},
  author={Li, Yixuan and Yosinski, Jason and Clune, Jeff and Lipson, Hod and Hopcroft, John},
  journal={arXiv preprint arXiv:1511.07543},
  year={2015}
}

@inproceedings{ferbach2024proving,
  title={Proving linear mode connectivity of neural networks via optimal transport},
  author={Ferbach, Damien and Goujaud, Baptiste and Gidel, Gauthier and Dieuleveut, Aymeric},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={3853--3861},
  year={2024},
}

@article{zhou2024going,
  title={Going beyond linear mode connectivity: The layerwise linear feature connectivity},
  author={Zhou, Zhanpeng and Yang, Yongyi and Yang, Xiaojiang and Yan, Junchi and Hu, Wei},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={36},
  year={2024}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{liu2022few,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={1950--1965},
  year={2022}
}

@article{ilharco2022patching,
  title={Patching open-vocabulary models by interpolating weights},
  author={Ilharco, Gabriel and Wortsman, Mitchell and Gadre, Samir Yitzhak and Song, Shuran and Hajishirzi, Hannaneh and Kornblith, Simon and Farhadi, Ali and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={29262--29277},
  year={2022}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={8748--8763},
  year={2021},
}

@inproceedings{oberlander2018analysis,
  title={An analysis of annotated corpora for emotion classification in text},
  author={Oberl{\"a}nder, Laura Ana Maria and Klinger, Roman},
  booktitle={Proceedings of the International Conference on Computational Linguistics (COLING)},
  pages={2104--2119},
  year={2018}
}

@inproceedings{bach2022promptsource,
  title={Promptsource: An integrated development environment and repository for natural language prompts},
  author={Bach, Stephen H and Sanh, Victor and Yong, Zheng-Xin and Webson, Albert and Raffel, Colin and Nayak, Nihal V and Sharma, Abheesht and Kim, Taewoon and Bari, M Saiful and Fevry, Thibault and others},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2022}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@inproceedings{sun2022black,
  title={Black-box tuning for language-model-as-a-service},
  author={Sun, Tianxiang and Shao, Yunfan and Qian, Hong and Huang, Xuanjing and Qiu, Xipeng},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={20841--20855},
  year={2022},
}

@inproceedings{hansen1996adapting,
  title={Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation},
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  booktitle={Proceedings of IEEE International Conference on Evolutionary Computation (ICEC)},
  pages={312--317},
  year={1996},
}

@article{cobbe2021training,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      journal={arXiv preprint arXiv:2110.14168},
      year={2021}
}

@article{yu2024metamath,
      title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models}, 
      author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng Yu and Zhengying Liu and Yu Zhang and James T. Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
      journal={arXiv preprint arXiv:2309.12284},
      year={2023}
}

@article{touvron2023llama,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
      journal={arXiv preprint arXiv:2307.09288},
      year={2023}
}

@article{li2024cmmlu,
      title={CMMLU: Measuring massive multitask language understanding in Chinese}, 
      author={Haonan Li and Yixuan Zhang and Fajri Koto and Yifei Yang and Hai Zhao and Yeyun Gong and Nan Duan and Timothy Baldwin},
      journal={arXiv preprint arXiv:2306.09212},
      year={2023}
}

@article{chen2021evaluating,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
      journal={arXiv preprint arXiv:2107.03374},
      year={2021}
}

@article{rozière2024code,
      title={Code Llama: Open Foundation Models for Code}, 
      author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
      journal={arXiv preprint arXiv:2308.12950},
      year={2023}
}

@misc{chinese_llama_2_7b,
  title        = {{Chinese Llama 2 7B}},
  author       = {LinkSoul},
  year         = {2023},
  howpublished = {\url{https://huggingface.co/LinkSoul/Chinese-Llama-2-7b}},
  note         = {Accessed: 2023-05-08}
}


@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@inproceedings{Amari1996fisher,
  title={Neural Learning in Structured Parameter Spaces - Natural Riemannian Gradient},
  author={Shun‐ichi Amari},
  booktitle={NIPS},
  year={1996}
}

@inproceedings{
taskarithmetic,
title={Editing models with task arithmetic},
author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=6t0Kwf8-jrj}
}

@article{fifty2021efficiently,
  title={Efficiently identifying task groupings for multi-task learning},
  author={Fifty, Chris and Amid, Ehsan and Zhao, Zhe and Yu, Tianhe and Anil, Rohan and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={27503--27516},
  year={2021}
}

@inproceedings{wang2020federated,
  title={Federated Learning with Matched Averaging},
  author={Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{zhuang2020comprehensive,
  title={A comprehensive survey on transfer learning},
  author={Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  journal={Proceedings of the IEEE},
  year={2020},
}

@article{bommasani2021opportunities,
  title={On the Opportunities and Risks of Foundation Models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{shnarch2022label,
  title={Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours},
  author={Shnarch, Eyal and Halfon, Alon and Gera, Ariel and Danilevsky, Marina and Katsis, Yannis and Choshen, Leshem and Cooper, Martin Santillan and Epelboim, Dina and Zhang, Zheng and Wang, Dakuo and others},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2022}
}

@inproceedings{devlin2018bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  pages={4171--4186},
  year={2019}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@inproceedings{sanh2022multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2022}
}

@article{colin2020exploring,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research (JMLR)},
  year    = {2020},
  note     = {\url{http://jmlr.org/papers/v21/20-074.html}}
}

@inproceedings{poth2021pre,
  title={What to pre-train on? efficient intermediate task selection},
  author={Poth, Clifton and Pfeiffer, Jonas and R{\"u}ckl{\'e}, Andreas and Gurevych, Iryna},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2021}
}

@article{matena2021merging,
  title={Merging models with fisher-weighted averaging},
  author={Matena, Michael and Raffel, Colin},
  journal={arXiv preprint arXiv:2111.09832},
  year={2021}
}

@inproceedings{
jin2023regmean,
title={Dataless Knowledge Fusion by Merging Weights of Language Models},
author={Xisen Jin and Xiang Ren and Daniel Preotiuc-Pietro and Pengxiang Cheng},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2023},
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2021},
}

@article{liu2022tfew,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1950--1965},
  year={2022}
}
@inproceedings{zellers2019hellaswag,
  title={{HellaSwag}: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2019}
}

@inproceedings{khot2020qasc,
  title={Qasc: A dataset for question answering via sentence composition},
  author={Khot, Tushar and Clark, Peter and Guerquin, Michal and Jansen, Peter and Sabharwal, Ashish},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  volume={34},
  pages={8082--8090},
  year={2020}
}

@inproceedings{yang2015wikiqa,
  title={Wikiqa: A challenge dataset for open-domain question answering},
  author={Yang, Yi and Yih, Wen-tau and Meek, Christopher},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={2013--2018},
  year={2015}
}

@inproceedings{tafjord2019quartz,
  title={QuaRTz: An open-domain dataset of qualitative relationship questions},
  author={Tafjord, Oyvind and Gardner, Matt and Lin, Kevin and Clark, Peter},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages= {5940--5945},
  year={2019}
}

@inproceedings{zhang2019paws,
  title={PAWS: Paraphrase adversaries from word scrambling},
  author={Zhang, Yuan and Baldridge, Jason and He, Luheng},
  booktitle={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  year={2019},
  
}

@inproceedings{sharma2018tackling,
  title={Tackling the story ending biases in the story cloze test},
  author={Sharma, Rishi and Allen, James and Bakhshandeh, Omid and Mostafazadeh, Nasrin},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={752--757},
  year={2018}
}

@article{sakaguchi2021winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{wsc,
  title={The Winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Proceedings of the International Conference on the Principles of Knowledge Representation and Reasoning (KR)},
  year={2012}
}

@inproceedings{wic,
   title={{WiC}: The Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations},
   author={Pilehvar, Mohammad Taher and Camacho-Collados, Jose},
   booktitle={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
   year={2019}
 }


@inproceedings{copa,
  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning.},
  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S.},
  booktitle={2011 AAAI Spring Symposium Series},
  year={2011}
}

@article{roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{mrpc,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, Bill and Brockett, Chris},
  booktitle={International Workshop on Paraphrasing (IWP)},
  year={2005}
}

@inproceedings{rte,
  title={The third pascal recognizing textual entailment challenge},
  author={Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, William B},
  booktitle={Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing},
  pages={1--9},
  year={2007}
}
@article{cola,
  title={Neural Network Acceptability Judgments},
  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={625--641},
  year={2019}
}

@inproceedings{sst-2,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1631--1642},
  year={2013}
}

@inproceedings{glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{cars,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVW)},
  pages={554--561},
  year={2013}
}

@inproceedings{dtd,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@article{eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={7},
  pages={2217--2226},
  year={2019},
}

@inproceedings{gtsrb,
  title={The German traffic sign recognition benchmark: a multi-class classification competition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  booktitle={Proceedings of the International Joint Conference on Neural Networks (IJCNN)},
  year={2011},
}

@misc{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  note={\url{http://yann.lecun.com/exdb/mnist/}},
  year={1998}
}

@article{cheng2017remote,
  title={Remote sensing image scene classification: Benchmark and state of the art},
  author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},
  journal={Proceedings of the IEEE},
  volume={105},
  number={10},
  pages={1865--1883},
  year={2017},
  publisher={IEEE}
}

@article{xiao2016sun,
  title={Sun database: Exploring a large collection of scene categories},
  author={Xiao, Jianxiong and Ehinger, Krista A and Hays, James and Torralba, Antonio and Oliva, Aude},
  journal={International Journal of Computer Vision (IJCV)},
  volume={119},
  pages={3--22},
  year={2016},
  publisher={Springer}
}

@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Baolin and Ng, Andrew Y and others},
  booktitle={NIPS workshop on deep learning and unsupervised feature learning},
  volume={2011},
  pages={7},
  year={2011},
}

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2015}
}

@article{matthews1975comparison,
  title={Comparison of the predicted and observed secondary structure of T4 phage lysozyme},
  author={Matthews, Brian W},
  journal={Biochimica et Biophysica Acta (BBA)-Protein Structure},
  year={1975},
  publisher={Elsevier}
}

@inproceedings{nie2019adversarial,
  title={{Adversarial NLI}: A new benchmark for natural language understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2020}
}


@inproceedings{cb,
  title={{The CommitmentBank}: Investigating projection in naturally occurring discourse},
  author={Marneffe, Marie-Catherine de and Simons, Mandy and Tonhauser, Judith},
  booktitle={proceedings of Sinn und Bedeutung},
  volume={23},
  pages={107--124},
  year={2019}
}

@inproceedings{sap2019social,
  title={Social IQa: Commonsense Reasoning about Social Interactions},
  author={Sap, Maarten and Rashkin, Hannah and Chen, Derek and Le Bras, Ronan and Choi, Yejin},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4463--4473},
  year={2019}
}

@inproceedings{huang2019cosmos,
  title={Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning},
  author={Huang, Lifu and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2391--2401},
  year={2019}
}
@inproceedings{quail_dataset,
  author    = {Anna Rogers and
               Olga Kovaleva and
               Matthew Downey and
               Anna Rumshisky},
  title     = {Getting Closer to {AI} Complete Question Answering: {A} Set of Prerequisite
               Real Tasks},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  volume={34},
  pages={8722--8731},
  year={2020}
}

% emotions
@article{li2017dailydialog,
  title={Dailydialog: A manually labelled multi-turn dialogue dataset},
  author={Li, Yanran and Su, Hui and Shen, Xiaoyu and Li, Wenjie and Cao, Ziqiang and Niu, Shuzi},
  journal={arXiv preprint arXiv:1710.03957},
  year={2017}
}


@inproceedings{mohammad2012emotional,
  title={{\#}Emotional Tweets},
  author={Saif M. Mohammad},
  booktitle={Proceedings of the First Joint Conference on Lexical and Computational Semantics (SEM)},
  pages={246--255},
  year={2012}
}

@inproceedings{alm2005emotions,
  title={Emotions from text: machine learning for text-based emotion prediction},
  author={Alm, Cecilia Ovesdotter and Roth, Dan and Sproat, Richard},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={579--586},
  year={2005}
}

@article{scherer1994evidence,
  title={Evidence for universality and cultural variation of differential emotion response patterning.},
  author={Scherer, Klaus R and Wallbott, Harald G},
  journal={Journal of personality and social psychology},
  volume={66},
  number={2},
  pages={310},
  year={1994},
  publisher={American Psychological Association}
}

@inproceedings{mohammad2017wassa,
  title={WASSA-2017 Shared Task on Emotion Intensity},
  author={Mohammad, Saif and Bravo-Marquez, Felipe},
  booktitle={Proceedings of the Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA)},
  pages={34--49},
  year={2017}
}

@inproceedings{schuff2017annotation,
  title={Annotation, modelling and analysis of fine-grained emotions on a stance and sentiment detection corpus},
  author={Schuff, Hendrik and Barnes, Jeremy and Mohme, Julian and Pad{\'o}, Sebastian and Klinger, Roman},
  booktitle={Proceedings of the Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA)},
  pages={13--23},
  year={2017}
}


@article{mohammad2015sentiment,
  title={Sentiment, emotion, purpose, and style in electoral tweets},
  author={Mohammad, Saif M and Zhu, Xiaodan and Kiritchenko, Svetlana and Martin, Joel},
  journal={Information Processing \& Management},
  volume={51},
  number={4},
  pages={480--499},
  year={2015},
  publisher={Elsevier}
}


@inproceedings{liu2017grounded,
  title={Grounded emotions},
  author={Liu, Vicki and Banea, Carmen and Mihalcea, Rada},
  booktitle={Proceedings of the International Conference on Affective Computing and Intelligent Interaction (ACII)},
  pages={477--483},
  year={2017}
}


@inproceedings{strapparava2007semeval,
  title={Semeval-2007 task 14: Affective text},
  author={Strapparava, Carlo and Mihalcea, Rada},
  booktitle={Proceedings of the International Workshop on Semantic Evaluations (SemEval)},
  pages={70--74},
  year={2007}
}

@inproceedings{orgad2023editing,
  title={Editing implicit assumptions in text-to-image diffusion models},
  author={Orgad, Hadas and Kawar, Bahjat and Belinkov, Yonatan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (CVPR)},
  pages={7053--7061},
  year={2023}
}

@article{ortiz2024task,
  title={Task arithmetic in the tangent space: Improved editing of pre-trained models},
  author={Ortiz-Jimenez, Guillermo and Favero, Alessandro and Frossard, Pascal},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={36},
  year={2024}
}

@article{klimaszewski2024no,
  title={No Train but Gain: Language Arithmetic for training-free Language Adapters enhancement},
  author={Klimaszewski, Mateusz and Andruszkiewicz, Piotr and Birch, Alexandra},
  journal={arXiv preprint arXiv:2404.15737},
  year={2024}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}
