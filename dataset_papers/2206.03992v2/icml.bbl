\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Berkeley et~al.(2022)Berkeley, Moss, Artemev, Pascual-Diaz, Granta,
  Stojic, Couckuyt, Qing, Loka, Paleyes, Ober, and
  Picheny]{berkeley2022trieste}
Berkeley, J., Moss, H.~B., Artemev, A., Pascual-Diaz, S., Granta, U., Stojic,
  H., Couckuyt, I., Qing, J., Loka, N., Paleyes, A., Ober, S.~W., and Picheny,
  V.
\newblock {Trieste}, 2022.
\newblock URL \url{https://github.com/secondmind-labs/trieste}.

\bibitem[Bond-Taylor \& Willcocks(2023)Bond-Taylor and
  Willcocks]{bond2023infty}
Bond-Taylor, S. and Willcocks, C.~G.
\newblock infinite-diff: Infinite resolution diffusion with subsampled
  mollified states.
\newblock \emph{arXiv preprint arXiv:2303.18242}, 2023.

\bibitem[Bruinsma et~al.(2023)Bruinsma, Markou, Requeima, Foong, Vaughan,
  Andersson, Buonomo, Hosking, and Turner]{bruinsma2023autoregressive}
Bruinsma, W., Markou, S., Requeima, J., Foong, A. Y.~K., Vaughan, A.,
  Andersson, T., Buonomo, A., Hosking, S., and Turner, R.~E.
\newblock Autoregressive {{Conditional Neural Processes}}.
\newblock In \emph{International {{Conference}} on {{Learning
  Representations}}}, February 2023.
\newblock URL \url{https://openreview.net/forum?id=OAsXFPBfTBh}.

\bibitem[Bruinsma et~al.(2021)Bruinsma, Requeima, Foong, Gordon, and
  Turner]{bruinsma2021gaussian}
Bruinsma, W.~P., Requeima, J., Foong, A.~Y., Gordon, J., and Turner, R.~E.
\newblock The {G}aussian neural process.
\newblock In \emph{Advances in Approximate Bayesian Inference}, 2021.

\bibitem[Dubois et~al.(2020)Dubois, Gordon, and Foong]{dubois2020npf}
Dubois, Y., Gordon, J., and Foong, A.~Y.
\newblock Neural process family.
\newblock \url{http://yanndubs.github.io/Neural-Process-Family/}, September
  2020.

\bibitem[Foong et~al.(2020)Foong, Bruinsma, Gordon, Dubois, Requeima, and
  Turner]{foong2020MetaLearning}
Foong, A. Y.~K., Bruinsma, W.~P., Gordon, J., Dubois, Y., Requeima, J., and
  Turner, R.~E.
\newblock Meta-{{Learning Stationary Stochastic Process Prediction}} with
  {{Convolutional Neural Processes}}.
\newblock \emph{arXiv:2007.01332 [cs, stat]}, November 2020.

\bibitem[Fortuin et~al.(2020)Fortuin, Baranchuk, R{\"a}tsch, and
  Mandt]{fortuin2020gp}
Fortuin, V., Baranchuk, D., R{\"a}tsch, G., and Mandt, S.
\newblock {GP-VAE}: Deep probabilistic time series imputation.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\bibitem[Franzese et~al.(2023)Franzese, Rossi, Rossi, Heinonen, Filippone, and
  Michiardi]{franzese2023continuous}
Franzese, G., Rossi, S., Rossi, D., Heinonen, M., Filippone, M., and Michiardi,
  P.
\newblock Continuous-time functional diffusion processes.
\newblock \emph{arXiv preprint arXiv:2303.00800}, 2023.

\bibitem[Garnelo et~al.(2018{\natexlab{a}})Garnelo, Rosenbaum, Maddison,
  Ramalho, Saxton, Shanahan, Teh, Rezende, and Eslami]{garnelo2018conditional}
Garnelo, M., Rosenbaum, D., Maddison, C., Ramalho, T., Saxton, D., Shanahan,
  M., Teh, Y.~W., Rezende, D.~J., and Eslami, S. M.~A.
\newblock Conditional neural processes.
\newblock In \emph{International Conference on Machine Learning},
  2018{\natexlab{a}}.

\bibitem[Garnelo et~al.(2018{\natexlab{b}})Garnelo, Schwarz, Rosenbaum, Viola,
  Rezende, Eslami, and Teh]{garnelo2018neural}
Garnelo, M., Schwarz, J., Rosenbaum, D., Viola, F., Rezende, D.~J., Eslami, S.
  M.~A., and Teh, Y.~W.
\newblock Neural processes.
\newblock 2018{\natexlab{b}}.

\bibitem[Gordon et~al.(2019)Gordon, Bruinsma, Foong, Requeima, Dubois, and
  Turner]{Gordon2019Convultional}
Gordon, J., Bruinsma, W.~P., Foong, A. Y.~K., Requeima, J., Dubois, Y., and
  Turner, R.~E.
\newblock Convolutional conditional neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{Neural Information Processing Systems}, 2020.

\bibitem[Hoogeboom et~al.(2022)Hoogeboom, Satorras, Vignac, and
  Welling]{hoogeboom22Equivariant}
Hoogeboom, E., Satorras, V.~G., Vignac, C., and Welling, M.
\newblock Equivariant diffusion for molecule generation in 3{D}.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8867--8887, 2022.

\bibitem[Kerrigan et~al.(2022)Kerrigan, Ley, and Smyth]{kerrigan2022Diffusion}
Kerrigan, G., Ley, J., and Smyth, P.
\newblock Diffusion {{Generative Models}} in {{Infinite Dimensions}}, 2022.

\bibitem[Kim et~al.(2019)Kim, Mnih, Schwarz, Garnelo, Eslami, Rosenbaum,
  Vinyals, and Teh]{kim2019attentive}
Kim, H., Mnih, A., Schwarz, J., Garnelo, M., Eslami, S. M.~A., Rosenbaum, D.,
  Vinyals, O., and Teh, Y.~W.
\newblock Attentive neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Kong et~al.(2020)Kong, Ping, Huang, Zhao, and
  Catanzaro]{kong2020diffwave}
Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.
\newblock Diffwave: A versatile diffusion model for audio synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Kossen et~al.(2021)Kossen, Band, Gomez, Lyle, Rainforth, and
  Gal]{kossen2021self}
Kossen, J., Band, N., Gomez, A.~N., Lyle, C., Rainforth, T., and Gal, Y.
\newblock Self-attention between datapoints: Going beyond individual
  input-output pairs in deep learning.
\newblock \emph{arXiv:2106.02584}, 2021.

\bibitem[Lalchand \& Rasmussen(2020)Lalchand and
  Rasmussen]{lalchand2020approximate}
Lalchand, V. and Rasmussen, C.~E.
\newblock Approximate inference for fully {B}ayesian {G}aussian process
  regression.
\newblock In \emph{Advances in Approximate Bayesian Inference}, 2020.

\bibitem[Lim et~al.(2023)Lim, Kovachki, Baptista, Beckham, Azizzadenesheli,
  Kossaifi, Voleti, Song, Kreis, Kautz, Pal, Vahdat, and
  Anandkumar]{lim2023score}
Lim, J.~H., Kovachki, N.~B., Baptista, R., Beckham, C., Azizzadenesheli, K.,
  Kossaifi, J., Voleti, V., Song, J., Kreis, K., Kautz, J., Pal, C., Vahdat,
  A., and Anandkumar, A.
\newblock Score-based diffusion models in function space, 2023.

\bibitem[Liu et~al.(2020)Liu, Sun, Ramadge, and Adams]{liu2020task}
Liu, S., Sun, X., Ramadge, P.~J., and Adams, R.~P.
\newblock Task-agnostic amortized inference of {G}aussian process
  hyperparameters.
\newblock In \emph{Neural Information Processing Systems}, 2020.

\bibitem[Lugmayr et~al.(2022)Lugmayr, Danelljan, Romero, Yu, Timofte, and
  Van~Gool]{lugmayr2022repaint}
Lugmayr, A., Danelljan, M., Romero, A., Yu, F., Timofte, R., and Van~Gool, L.
\newblock Repaint: Inpainting using denoising diffusion probabilistic models.
\newblock 2022.

\bibitem[Luo \& Hu(2021)Luo and Hu]{luo2021diffusion}
Luo, S. and Hu, W.
\newblock Diffusion probabilistic models for 3d point cloud generation.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2021.

\bibitem[Mishra et~al.(2020)Mishra, Flaxman, Berah, Pakkanen, Zhu, and
  Bhatt]{mishra2020pi}
Mishra, S., Flaxman, S., Berah, T., Pakkanen, M., Zhu, H., and Bhatt, S.
\newblock pivae: Encoding stochastic process priors with variational
  autoencoders.
\newblock \emph{arXiv preprint arXiv:2002.06873}, 2020.

\bibitem[Neal(1998)]{Neal1998Regression}
Neal, R.~M.
\newblock Regression and classification using gaussian process priors.
\newblock In Bernardo, J.~M., Berger, J.~O., Dawid, J.~W., and Smith, A. F.~M.
  (eds.), \emph{International Conference on Learning Representations}. Oxford
  University Press, 1998.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew,
  Sutskever, and Chen]{nichol2021glide}
Nichol, A., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., McGrew, B.,
  Sutskever, I., and Chen, M.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Phillips et~al.(2022)Phillips, Seror, Hutchinson, De~Bortoli, Doucet,
  and Mathieu]{phillips2022Spectral}
Phillips, A., Seror, T., Hutchinson, M., De~Bortoli, V., Doucet, A., and
  Mathieu, E.
\newblock Spectral {{Diffusion Processes}}, November 2022.
\newblock URL \url{http://arxiv.org/abs/2209.14125}.

\bibitem[Pidstrigach et~al.(2023)Pidstrigach, Marzouk, Reich, and
  Wang]{pidstrigach2023InfiniteDimensional}
Pidstrigach, J., Marzouk, Y., Reich, S., and Wang, S.
\newblock Infinite-{{Dimensional Diffusion Models}} for {{Function Spaces}},
  February 2023.
\newblock URL \url{http://arxiv.org/abs/2302.10130}.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with {CLIP} latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and Williams]{rasmussen06}
Rasmussen, C.~E. and Williams, C.~K.
\newblock \emph{{G}aussian processes for machine learning}.
\newblock MIT Press, 2006.

\bibitem[Shahriari et~al.(2015)Shahriari, Swersky, Wang, Adams, and
  De~Freitas]{shahriari2015taking}
Shahriari, B., Swersky, K., Wang, Z., Adams, R.~P., and De~Freitas, N.
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock \emph{Proceedings of the IEEE}, 2015.

\bibitem[Simpson et~al.(2021{\natexlab{a}})Simpson, Davies, Lalchand, Vullo,
  Durrande, and Rasmussen]{simpson2021kernel}
Simpson, F., Davies, I., Lalchand, V., Vullo, A., Durrande, N., and Rasmussen,
  C.~E.
\newblock Kernel identification through transformers.
\newblock In \emph{Neural Information Processing Systems}, 2021{\natexlab{a}}.

\bibitem[Simpson et~al.(2021{\natexlab{b}})Simpson, Lalchand, and
  Rasmussen]{simpson2021marginalised}
Simpson, F., Lalchand, V., and Rasmussen, C.~E.
\newblock Marginalised {G}aussian processes with nested sampling.
\newblock In \emph{Neural Information Processing Systems}, 2021{\natexlab{b}}.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Sohl-Dickstein, J., Weiss, E.~A., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock \emph{arXiv preprint arXiv:1503.03585}, 2015.

\bibitem[Song \& Ermon(2020)Song and Ermon]{song2020improved}
Song, Y. and Ermon, S.
\newblock Improved techniques for training score-based generative models.
\newblock In \emph{Neural Information Processing Systems}, volume~33, 2020.

\bibitem[{van der Wilk} et~al.(2020){van der Wilk}, Dutordoir, John, Artemev,
  Adam, and Hensman]{gpflow2020}
{van der Wilk}, M., Dutordoir, V., John, S., Artemev, A., Adam, V., and
  Hensman, J.
\newblock A framework for interdomain and multioutput {G}aussian processes.
\newblock \emph{arxiv preprint arXiv:2003.01115}, 2020.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Neural Information Processing Systems}, 2017.

\bibitem[Wang \& Neal(2012)Wang and Neal]{wang2012gaussian}
Wang, C. and Neal, R.~M.
\newblock Gaussian process regression with heteroscedastic or non-gaussian
  residuals.
\newblock \emph{arXiv preprint arXiv:1212.6246}, 2012.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016deep}
Wilson, A.~G., Hu, Z., Salakhutdinov, R., and Xing, E.~P.
\newblock Deep kernel learning.
\newblock In Gretton, A. and Robert, C.~C. (eds.), \emph{Proceedings of the
  19th International Conference on Artificial Intelligence and Statistics},
  volume~51 of \emph{Proceedings of Machine Learning Research}, pp.\  370--378,
  Cadiz, Spain, 09--11 May 2016. PMLR.

\bibitem[Xu et~al.(2022)Xu, Yu, Song, Shi, Ermon, and Tang]{xu2022geodiff}
Xu, M., Yu, L., Song, Y., Shi, C., Ermon, S., and Tang, J.
\newblock Geodiff: A geometric diffusion model for molecular conformation
  generation.
\newblock \emph{arXiv preprint arXiv:2203.02923}, 2022.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.~R., and
  Smola, A.~J.
\newblock Deep sets.
\newblock In \emph{Neural Information Processing Systems}, 2017.

\end{thebibliography}
