@article{muzero,
  author    = {Julian Schrittwieser and
               Ioannis Antonoglou and
               Thomas Hubert and
               Karen Simonyan and
               Laurent Sifre and
               Simon Schmitt and
               Arthur Guez and
               Edward Lockhart and
               Demis Hassabis and
               Thore Graepel and
               Timothy P. Lillicrap and
               David Silver},
  title     = {Mastering {A}tari, {G}o, {C}hess and {S}hogi by {P}lanning with a {L}earned {M}odel},
  journal   = {Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
}

@article{ALE,
  title={The {A}rcade {L}earning {E}nvironment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}


@article{Marlos2017Atari,
author = {Machado, Marlos and Bellemare, Marc and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
year = {2017},
month = {09},
pages = {},
title = {Revisiting the {A}rcade {L}earning {E}nvironment: Evaluation Protocols and Open Problems for General Agents},
volume = {61},
journal = {Journal of Artificial Intelligence Research},
doi = {10.1613/jair.5699}
}

@article{resv2,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Identity Mappings in Deep Residual Networks},
  journal   = {CoRR},
  volume    = {abs/1603.05027},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.05027},
  archivePrefix = {arXiv},
  eprint    = {1603.05027},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZR016.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ba2016layer,
      title={Layer Normalization},
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2015},
  volume={abs/1412.6980}
}

@article{adam_weight_decay,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Fixing Weight Decay Regularization in Adam},
  journal   = {CoRR},
  volume    = {abs/1711.05101},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.05101},
  archivePrefix = {arXiv},
  eprint    = {1711.05101},
  timestamp = {Mon, 13 Aug 2018 16:48:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-05101.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.2.5},
  year = {2018},
}

@inproceedings{mujoco,
author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
year = {2012},
month = {10},
pages = {5026-5033},
title = {MuJoCo: A physics engine for model-based control},
isbn = {978-1-4673-1737-5},
journal = {Proceedings of the ... IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2012.6386109}
}

@misc{tassa2018deepmind,
      title={DeepMind Control Suite},
      author={Yuval Tassa and Yotam Doron and Alistair Muldal and Tom Erez and Yazhe Li and Diego de Las Casas and David Budden and Abbas Abdolmaleki and Josh Merel and Andrew Lefrancq and Timothy Lillicrap and Martin Riedmiller},
      year={2018},
      eprint={1801.00690},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{dulacarnold2020empirical,
      title={An empirical investigation of the challenges of real-world reinforcement learning},
      author={Gabriel Dulac-Arnold and Nir Levine and Daniel J. Mankowitz and Jerry Li and Cosmin Paduraru and Sven Gowal and Todd Hester},
      year={2020},
      eprint={2003.11881},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{progressive_widening,
author = {Chaslot, Guillaume and Winands, Mark and Herik, H. and Uiterwijk, Jos and Bouzy, Bruno},
year = {2008},
month = {11},
pages = {343-357},
title = {Progressive Strategies for Monte-Carlo Tree Search},
volume = {04},
journal = {New Mathematics and Natural Computation},
doi = {10.1142/S1793005708001094}
}

@inproceedings{impala,
  title={{IMPALA}: Scalable Distributed Deep-{RL} with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2018}
}

@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{unreal,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{laser,
  title={Off-Policy Actor-Critic with Shared Experience Replay},
  author={Schmitt, Simon and Hessel, Matteo and Simonyan, Karen},
  journal={arXiv preprint arXiv:1909.11583},
  year={2019}
}

@article{wang2020critic,
  title={{C}ritic {R}egularized {R}egression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{agarwal2020optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{hafner:planet,
  title={Learning Latent Dynamics for Planning from Pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  journal={arXiv preprint arXiv:1811.04551},
  year={2018}
}

@misc{kidambi2020morel,
      title={{MOReL} : {M}odel-{B}ased {O}ffline {R}einforcement {L}earning},
      author={Rahul Kidambi and Aravind Rajeswaran and Praneeth Netrapalli and Thorsten Joachims},
      year={2020},
      eprint={2005.05951},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{yu2020mopo,
      title={{MOPO}: {M}odel-based {O}ffline {P}olicy {O}ptimization},
      author={Tianhe Yu and Garrett Thomas and Lantao Yu and Stefano Ermon and James Zou and Sergey Levine and Chelsea Finn and Tengyu Ma},
      year={2020},
      eprint={2005.13239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kaplan2020scaling,
      title={Scaling Laws for Neural Language Models},
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kumar2020conservative,
      title={{C}onservative {Q}-Learning for {O}ffline {R}einforcement {L}earning},
      author={Aviral Kumar and Aurick Zhou and George Tucker and Sergey Levine},
      year={2020},
      eprint={2006.04779},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{levine2020offline,
      title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
      author={Sergey Levine and Aviral Kumar and George Tucker and Justin Fu},
      year={2020},
      eprint={2005.01643},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{he2021popo,
      title={{POPO}: {P}essimistic {O}ffline {P}olicy {O}ptimization},
      author={Qiang He and Xinwen Hou},
      year={2021},
      eprint={2012.13682},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{matsushima2020deploymentefficient,
      title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
      author={Tatsuya Matsushima and Hiroki Furuta and Yutaka Matsuo and Ofir Nachum and Shixiang Gu},
      year={2020},
      eprint={2006.03647},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{argenson2020modelbased,
      title={Model-Based Offline Planning},
      author={Arthur Argenson and Gabriel Dulac-Arnold},
      year={2020},
      eprint={2008.05556},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@inproceedings{coulom:mcts,
  title={Efficient selectivity and backup operators in Monte-Carlo tree search},
  author={Coulom, R{\'e}mi},
  booktitle={International conference on computers and games},
  pages={72--83},
  year={2006},
  organization={Springer}
}

@misc{tang2020discretizing,
      title={Discretizing Continuous Action Space for On-Policy Optimization},
      author={Yunhao Tang and Shipra Agrawal},
      year={2020},
      eprint={1901.10500},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{yang2020continuous,
      title={Continuous Control for Searching and Planning with a Learned Model},
      author={Xuxi Yang and Werner Duvaud and Peng Wei},
      year={2020},
      eprint={2006.07430},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{moerland2018a0c,
      title={{A0C}: {A}lpha{Z}ero in Continuous Action Space},
      author={Thomas M. Moerland and Joost Broekens and Aske Plaat and Catholijn M. Jonker},
      year={2018},
      eprint={1805.09613},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{kearns-mansour-ng:sparse-sampling,
author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y.},
title = {A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes},
year = {1999},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the 16th International Joint Conference on Artificial Intelligence - Volume 2},
pages = {1324–1331},
numpages = {8},
location = {Stockholm, Sweden},
series = {IJCAI'99}
}

@article{rust1997,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/2171751},
 abstract = {This paper introduces random versions of successive approximations and multigrid algorithms for computing approximate solutions to a class of finite and infinite horizon Markovian decision problems (MDPs). We prove that these algorithms succeed in breaking the "curse of dimensionality" for a subclass of MDPs known as discrete decision processes (DDPs).},
 author = {John Rust},
 journal = {Econometrica},
 number = {3},
 pages = {487--516},
 publisher = {[Wiley, Econometric Society]},
 title = {Using Randomization to Break the Curse of Dimensionality},
 volume = {65},
 year = {1997}
}

@misc{ghosh2020operator,
      title={An operator view of policy gradient methods}, 
      author={Dibya Ghosh and Marlos C. Machado and Nicolas Le Roux},
      year={2020},
      eprint={2006.11266},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dulacarnold2016deep,
      title={Deep Reinforcement Learning in Large Discrete Action Spaces}, 
      author={Gabriel Dulac-Arnold and Richard Evans and Hado van Hasselt and Peter Sunehag and Timothy Lillicrap and Jonathan Hunt and Timothy Mann and Theophane Weber and Thomas Degris and Ben Coppin},
      year={2016},
      eprint={1512.07679},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{Silver16AG,
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  journal = {Nature},
  month = {January},
  number = 7587,
  pages = {484--489},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  volume = 529,
  year = 2016
}

@article{sir,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2289460},
 author = {Donald B. Rubin},
 journal = {Journal of the American Statistical Association},
 number = {398},
 pages = {543--546},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {The Calculation of Posterior Distributions by Data Augmentation: Comment: A Noniterative Sampling/Importance Resampling Alternative to the Data Augmentation Algorithm for Creating a Few Imputations When Fractions of Missing Information Are Modest: The SIR Algorithm},
 volume = {82},
 year = {1987}
}

@misc{mpo,
      title={Relative Entropy Regularized Policy Iteration}, 
      author={Abbas Abdolmaleki and Jost Tobias Springenberg and Jonas Degrave and Steven Bohez and Yuval Tassa and Dan Belov and Nicolas Heess and Martin Riedmiller},
      year={2018},
      eprint={1812.02256},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{d4pg,
      title={{D}istributed {D}istributional {D}eterministic {P}olicy {G}radients},
      author={Gabriel Barth-Maron and Matthew W. Hoffman and David Budden and Will Dabney and Dan Horgan and Dhruva TB and Alistair Muldal and Nicolas Heess and Timothy Lillicrap},
      year={2018},
      eprint={1804.08617},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{haarnoja2018soft,
      title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
      author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
      year={2018},
      eprint={1801.01290},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{hoffman2020acme,
    title={Acme: A Research Framework for Distributed Reinforcement Learning},
    author={Matt Hoffman and Bobak Shahriari and John Aslanides and Gabriel
        Barth-Maron and Feryal Behbahani and Tamara Norman and Abbas Abdolmaleki
        and Albin Cassirer and Fan Yang and Kate Baumli and Sarah Henderson and
        Alex Novikov and Sergio Gómez Colmenarejo and Serkan Cabi and Caglar
        Gulcehre and Tom Le Paine and Andrew Cowie and Ziyu Wang and Bilal Piot
        and Nando de Freitas},
    year={2020},
    journal={arXiv preprint arXiv:2006.00979},
    url={https://arxiv.org/abs/2006.00979},
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@InProceedings{ddpg2014silver,
  title =  {Deterministic Policy Gradient Algorithms},
  author =  {David Silver and Guy Lever and Nicolas Heess and Thomas Degris and Daan Wierstra and Martin Riedmiller},
  booktitle =  {Proceedings of the 31st International Conference on Machine Learning},
  pages =  {387--395},
  year =  {2014},
  editor = {Eric P. Xing and Tony Jebara},
  volume =  {32},
  number =       {1},
  series =  {Proceedings of Machine Learning Research},
  address =  {Bejing, China},
  month =  {22--24 Jun},
  publisher =    {PMLR},
  pdf =  {http://proceedings.mlr.press/v32/silver14.pdf},
  url =  {http://proceedings.mlr.press/v32/silver14.html},
  abstract =  {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. Deterministic policy gradient algorithms outperformed their stochastic counterparts in several benchmark problems, particularly in high-dimensional action spaces.}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{Silver18AZ,
  title={A general reinforcement learning algorithm that masters chess, shogi, and {Go} through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{brown2018superhuman,
  title={Superhuman {AI} for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{deepstack,
  title={Deepstack: Expert-level artificial intelligence in heads-up no-limit poker},
  author={Morav{\v{c}}{\'\i}k, Matej and Schmid, Martin and Burch, Neil and Lis{\`y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
  journal={Science},
  volume={356},
  number={6337},
  pages={508--513},
  year={2017},
  publisher={American Association for the Advancement of Science}
}

@article{zahavy2020stacx,
  title={A self-tuning actor-critic algorithm},
  author={Zahavy, Tom and Xu, Zhongwen and Veeriah, Vivek and Hessel, Matteo and Oh, Junhyuk and van Hasselt, Hado P and Silver, David and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{
merel2018hierarchical,
title={Hierarchical Visuomotor Control of Humanoids},
author={Josh Merel and Arun Ahuja and Vu Pham and Saran Tunyasuvunakool and Siqi Liu and Dhruva Tirumala and Nicolas Heess and Greg Wayne},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJfYvo09Y7},
}

@article{tassa2020dm_control,
  title={dm\_control: Software and tasks for continuous control},
  author={Tassa, Yuval and Tunyasuvunakool, Saran and Muldal, Alistair and Doron, Yotam and Liu, Siqi and Bohez, Steven and Merel, Josh and Erez, Tom and Lillicrap, Timothy and Heess, Nicolas},
  journal={arXiv preprint arXiv:2006.12983},
  year={2020}
}

@inproceedings{
  Song2020VMPO,
  title={{V-MPO}: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control},
  author={H. Francis Song and Abbas Abdolmaleki and Jost Tobias Springenberg and Aidan Clark and Hubert Soyer and Jack W. Rae and Seb Noury and Arun Ahuja and Siqi Liu and Dhruva Tirumala and Nicolas Heess and Dan Belov and Martin Riedmiller and Matthew M. Botvinick},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=SylOlp4FvH}
}

@inproceedings{byravan2020imagined,
  title={Imagined value gradients: Model-based policy optimization with transferable latent dynamics models},
  author={Byravan, Arunkumar and Springenberg, Jost Tobias and Abdolmaleki, Abbas and Hafner, Roland and Neunert, Michael and Lampe, Thomas and Siegel, Noah and Heess, Nicolas and Riedmiller, Martin},
  booktitle={Conference on Robot Learning},
  pages={566--589},
  year={2020},
  organization={PMLR}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@misc{koul2020dream,
      title={Dream and Search to Control: Latent Space Planning for Continuous Control}, 
      author={Anurag Koul and Varun V. Kumar and Alan Fern and Somdeb Majumdar},
      year={2020},
      eprint={2010.09832},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{bhardwaj2020information,
  title={Information theoretic model predictive q-learning},
  author={Bhardwaj, Mohak and Handa, Ankur and Fox, Dieter and Boots, Byron},
  booktitle={Learning for Dynamics and Control},
  pages={840--850},
  year={2020},
  organization={PMLR}
}

@article{springenberg2020local,
  title={Local Search for Policy Iteration in Continuous Control},
  author={Springenberg, Jost Tobias and Heess, Nicolas and Mankowitz, Daniel and Merel, Josh and Byravan, Arunkumar and Abdolmaleki, Abbas and Kay, Jackie and Degrave, Jonas and Schrittwieser, Julian and Tassa, Yuval and others},
  journal={arXiv preprint arXiv:2010.05545},
  year={2020}
}

@inproceedings{piche2018probabilistic,
  title={Probabilistic planning with sequential monte carlo methods},
  author={Pich{\'e}, Alexandre and Thomas, Valentin and Ibrahim, Cyril and Bengio, Yoshua and Pal, Chris},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@software{haiku2020github,
  author = {Tom Hennigan and Trevor Cai and Tamara Norman and Igor Babuschkin},
  title = {{H}aiku: {S}onnet for {JAX}},
  url = {http://github.com/deepmind/dm-haiku},
  version = {0.0.3},
  year = {2020},
}

@misc{grill2020montecarlo,
      title={Monte-Carlo Tree Search as Regularized Policy Optimization}, 
      author={Jean-Bastien Grill and Florent Altché and Yunhao Tang and Thomas Hubert and Michal Valko and Ioannis Antonoglou and Rémi Munos},
      year={2020},
      eprint={2007.12509},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Schaul2016,
address = {Puerto Rico},
author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
booktitle = {International Conference on Learning Representations},
title = {Prioritized Experience Replay},
year = {2016}
}

@article{sutton88,
  title = {Learning to predict by the methods of temporal differences},
  author = {Sutton, Richard S.},
  year={1988},
  url={http://incompleteideas.net/papers/sutton-88-with-erratum.pdf}
}

