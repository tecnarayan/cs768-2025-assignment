\begin{thebibliography}{10}

\bibitem{Bubeck10BestArm}
J-Y. Audibert, S.~Bubeck, and R.~Munos.
\newblock {Best Arm Identification in Multi-armed Bandits}.
\newblock In {\em {Proceedings of the 23rd Conference on Learning Theory}},
  2010.

\bibitem{Aueral02}
P.~Auer, N.~Cesa-Bianchi, and P.~Fischer.
\newblock {Finite-time analysis of the multiarmed bandit problem}.
\newblock {\em Machine Learning}, 47(2):235--256, 2002.

\bibitem{OMS14}
L.~Borsoniu, R.~Munos, and E.~P{\'a}ll.
\newblock An analysis of optimistic, best-first search for minimax sequential
  decision making.
\newblock In {\em ADPRL14}, 2014.

\bibitem{SurveyMCTS12}
C.~Browne, E.~Powley, D.~Whitehouse, S.~Lucas, P.~Cowling, P.~Rohlfshagen,
  S.~Tavener, D.~Perez, S.~Samothrakis, and S.~Colton.
\newblock A survey of monte carlo tree search methods.
\newblock {\em IEEE Transactions on Computational Intelligence and AI in
  games,}, 4(1):1--49, 2012.

\bibitem{KLUCBJournal}
O.~Capp{\'e}, A.~Garivier, O-A. Maillard, R.~Munos, and G.~Stoltz.
\newblock {{K}ullback-{L}eibler upper confidence bounds for optimal sequential
  allocation}.
\newblock {\em Annals of Statistics}, 41(3):1516--1541, 2013.

\bibitem{Cazenave15SHOT}
T.~Cazenave.
\newblock Sequential halving applied to trees.
\newblock {\em IEEE Transactions on Computational Intelligence and AI in
  Games}, 7(1):102--105, 2015.

\bibitem{EvenDaral06}
E.~Even-Dar, S.~Mannor, and Y.~Mansour.
\newblock {Action Elimination and Stopping Conditions for the Multi-Armed
  Bandit and Reinforcement Learning Problems}.
\newblock {\em Journal of Machine Learning Research}, 7:1079--1105, 2006.

\bibitem{Gabillon:al12}
V.~Gabillon, M.~Ghavamzadeh, and A.~Lazaric.
\newblock {Best Arm Identification: A Unified Approach to Fixed Budget and
  Fixed Confidence}.
\newblock In {\em {Advances in Neural Information Processing Systems}}, 2012.

\bibitem{GK16}
A.~Garivier and E.~Kaufmann.
\newblock Optimal best arm identification with fixed confidence.
\newblock In {\em Proceedings of the 29th Conference On Learning Theory
  (COLT)}, 2016.

\bibitem{GKK16}
A.~Garivier, E.~Kaufmann, and W.M. Koolen.
\newblock Maximin action identification: A new bandit framework for games.
\newblock In {\em Proceedings of the 29th Conference On Learning Theory}, 2016.

\bibitem{HuangASM17}
Ruitong Huang, Mohammad~M. Ajallooeian, Csaba Szepesv{\'{a}}ri, and Martin
  M{\"{u}}ller.
\newblock Structured best arm identification with fixed confidence.
\newblock In {\em 28th International Conference on Algorithmic Learning Theory
  (ALT)}, 2017.

\bibitem{Jamiesonal14LILUCB}
K.~Jamieson, M.~Malloy, R.~Nowak, and S.~Bubeck.
\newblock {lil'{UCB}: an Optimal Exploration Algorithm for Multi-Armed
  Bandits}.
\newblock In {\em {Proceedings of the 27th Conference on Learning Theory}},
  2014.

\bibitem{Shivaramal12}
S.~Kalyanakrishnan, A.~Tewari, P.~Auer, and P.~Stone.
\newblock {{PAC} subset selection in stochastic multi-armed bandits}.
\newblock In {\em {International Conference on Machine Learning (ICML)}}, 2012.

\bibitem{Karnin:al13}
Z.~Karnin, T.~Koren, and O.~Somekh.
\newblock {Almost optimal Exploration in multi-armed bandits}.
\newblock In {\em {International Conference on Machine Learning (ICML)}}, 2013.

\bibitem{JMLR15}
E.~Kaufmann, O.~Capp{\'e}, and A.~Garivier.
\newblock {On the Complexity of Best Arm Identification in Multi-Armed Bandit
  Models}.
\newblock {\em Journal of Machine Learning Research}, 17(1):1--42, 2016.

\bibitem{COLT13}
E.~Kaufmann and S.~Kalyanakrishnan.
\newblock {Information complexity in bandit subset selection}.
\newblock In {\em {Proceeding of the 26th Conference On Learning Theory.}},
  2013.

\bibitem{KocsisBBMCP06}
L.~Kocsis and C.~Szepesv\'{a}ri.
\newblock Bandit based monte-carlo planning.
\newblock In {\em Proceedings of the 17th European Conference on Machine
  Learning}, ECML'06, pages 282--293, Berlin, Heidelberg, 2006.
  Springer-Verlag.

\bibitem{LaiRobbins85bandits}
T.L. Lai and H.~Robbins.
\newblock {Asymptotically efficient adaptive allocation rules}.
\newblock {\em Advances in Applied Mathematics}, 6(1):4--22, 1985.

\bibitem{Pepels14HybridMCTS}
T.~Pepels, T.~Cazenave, M.~Winands, and M.~Lanctot.
\newblock Minimizing simple and cumulative regret in monte-carlo tree search.
\newblock In {\em Computer Games Workshop, ECAI}, 2014.

\bibitem{PLAAT1996255}
Aske Plaat, Jonathan Schaeffer, Wim Pijls, and Arie de~Bruin.
\newblock Best-first fixed-depth minimax algorithms.
\newblock {\em Artificial Intelligence}, 87(1):255 -- 293, 1996.

\bibitem{deep.go}
David Silver, Aja Huang, Chris~J. Maddison, Arthur Guez, Laurent Sifre, George
  van~den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal
  Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray
  Kavukcuoglu, Thore Graepel, and Demis Hassabis.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529:484--489, 2016.

\bibitem{Teraoka14MCTS}
K.~Teraoka, K.~Hatano, and E.~Takimoto.
\newblock Efficient sampling method for monte carlo tree search problem.
\newblock {\em IEICE Transactions on Infomation and Systems}, pages 392--398,
  2014.

\bibitem{Thompson33}
W.R. Thompson.
\newblock {On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples}.
\newblock {\em Biometrika}, 25:285--294, 1933.

\end{thebibliography}
