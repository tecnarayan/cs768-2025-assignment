\begin{thebibliography}{10}

\bibitem{Acharya2020GeneralLB}
J.~Acharya, C.~L. Canonne, and H.~Tyagi.
\newblock General lower bounds for interactive high-dimensional estimation
  under information constraints.
\newblock {\em arXiv: Data Structures and Algorithms}, 2020.

\bibitem{Acharya2020InferenceUI}
J.~Acharya, C.~L. Canonne, and H.~Tyagi.
\newblock Inference under information constraints ii: Communication constraints
  and shared randomness.
\newblock {\em IEEE Transactions on Information Theory}, 66:7856--7877, 2020.

\bibitem{pmlr-v132-acharya21b}
J.~Acharya, P.~Kairouz, Y.~Liu, and Z.~Sun.
\newblock Estimating sparse discrete distributions under privacy and
  communication constraints.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  2021.

\bibitem{Achituve2021PersonalizedFL}
I.~Achituve, A.~Shamsian, A.~Navon, G.~Chechik, and E.~Fetaya.
\newblock Personalized federated learning with gaussian processes.
\newblock {\em ArXiv}, abs/2106.15482, 2021.

\bibitem{agresti2003categorical}
A.~Agresti.
\newblock {\em Categorical data analysis}.
\newblock John Wiley \& Sons, 2003.

\bibitem{Anscombe1960RejectionOO}
F.~J. Anscombe.
\newblock Rejection of outliers.
\newblock {\em Technometrics}, 1960.

\bibitem{pmlr-v23-balcan12a}
M.~F. Balcan, A.~Blum, S.~Fine, and Y.~Mansour.
\newblock Distributed learning, communication complexity and privacy.
\newblock In {\em Proceedings of the 25th Annual Conference on Learning
  Theory}, volume~23, pages 26.1--26.22, 2012.

\bibitem{Barnes2019LowerBF}
L.~P. Barnes, Y.~Han, and A.~Ozgur.
\newblock Lower bounds for learning distributions under communication
  constraints via fisher information.
\newblock {\em arXiv: Information Theory}, 2019.

\bibitem{Bastani2021PredictingWP}
H.~Bastani.
\newblock Predicting with proxies: Transfer learning in high dimension.
\newblock {\em Management Science}, 67:2964--2984, 2021.

\bibitem{Baxter2000AMO}
J.~Baxter.
\newblock A model of inductive bias learning.
\newblock {\em Journal of Artificial Intelligence Research}, 12:149--198, 2000.

\bibitem{Blanchard2017ByzantineTolerantML}
P.~Blanchard, E.~M.~E. Mhamdi, R.~Guerraoui, and J.~Stainer.
\newblock Byzantine-tolerant machine learning.
\newblock {\em ArXiv}, abs/1703.02757, 2017.

\bibitem{caldas2018leaf}
S.~Caldas, S.~M.~K. Duddu, P.~Wu, T.~Li, J.~Kone{\v{c}}n{\`y}, H.~B. McMahan,
  V.~Smith, and A.~Talwalkar.
\newblock Leaf: A benchmark for federated settings.
\newblock {\em arXiv preprint arXiv:1812.01097}, 2018.

\bibitem{RCaruana}
R.~Caruana.
\newblock Multitask learning.
\newblock {\em Machine Learning}, 28:41--75, 1997.

\bibitem{NEURIPS2020_222afbe0}
W.-N. Chen, P.~Kairouz, and A.~Ozgur.
\newblock Breaking the communication-privacy-accuracy trilemma.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 3312--3324. Curran Associates, Inc., 2020.

\bibitem{chen2021breaking}
W.-N. Chen, P.~Kairouz, and A.~{\"O}zg{\"u}r.
\newblock Breaking the dimension dependence in sparse distribution estimation
  under communication constraints.
\newblock {\em arXiv preprint arXiv:2106.08597}, 2021.

\bibitem{Chen2021PointwiseBF}
W.-N. Chen, P.~Kairouz, and A.~{\"O}zg{\"u}r.
\newblock Pointwise bounds for distribution estimation under communication
  constraints.
\newblock {\em ArXiv}, abs/2110.03189, 2021.

\bibitem{Collins2021ExploitingSR}
L.~Collins, H.~Hassani, A.~Mokhtari, and S.~Shakkottai.
\newblock Exploiting shared representations for personalized federated
  learning.
\newblock {\em ArXiv}, abs/2102.07078, 2021.

\bibitem{Daum2012EfficientPF}
H.~Daum{\'e}, J.~M. Phillips, A.~Saha, and S.~Venkatasubramanian.
\newblock Efficient protocols for distributed classification and optimization.
\newblock {\em ArXiv}, abs/1204.3523, 2012.

\bibitem{Dobriban2018DistributedLR}
E.~Dobriban and Y.~Sheng.
\newblock Distributed linear regression by averaging.
\newblock {\em The Annals of Statistics}, 2018.

\bibitem{Du2021FewShotLV}
S.~S. Du, W.~Hu, S.~M. Kakade, J.~Lee, and Q.~Lei.
\newblock Few-shot learning via learning the representation, provably.
\newblock {\em ArXiv}, abs/2002.09434, 2021.

\bibitem{Garg2014OnCC}
A.~Garg, T.~Ma, and H.~L. Nguyen.
\newblock On communication cost of distributed statistical estimation and
  dimensionality.
\newblock In {\em Advances in Neural Information Systems}, 2014.

\bibitem{Goyal2019ScalingAB}
P.~Goyal, D.~K. Mahajan, A.~K. Gupta, and I.~Misra.
\newblock Scaling and benchmarking self-supervised visual representation
  learning.
\newblock {\em 2019 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pages 6390--6399, 2019.

\bibitem{Grimberg2021OptimalMA}
F.~Grimberg, M.-A. Hartley, S.~P. Karimireddy, and M.~Jaggi.
\newblock Optimal model averaging: Towards personalized collaborative learning.
\newblock {\em ArXiv}, abs/2110.12946, 2021.

\bibitem{hampel2011robust}
F.~R. Hampel, E.~M. Ronchetti, P.~J. Rousseeuw, and W.~A. Stahel.
\newblock {\em Robust statistics: the approach based on influence functions},
  volume 196.
\newblock John Wiley \& Sons, 2011.

\bibitem{Han2018DistributedSE}
Y.~Han, P.~Mukherjee, A.~{\"O}zg{\"u}r, and T.~Weissman.
\newblock Distributed statistical estimation of high-dimensional and
  nonparametric distributions.
\newblock {\em 2018 IEEE International Symposium on Information Theory (ISIT)},
  pages 506--510, 2018.

\bibitem{Han2021GeometricLB}
Y.~Han, A.~{\"O}zg{\"u}r, and T.~Weissman.
\newblock Geometric lower bounds for distributed parameter estimation under
  communication constraints.
\newblock {\em IEEE Transactions on Information Theory}, 67:8248--8263, 2021.

\bibitem{Hu2019HERSMI}
L.~Hu, S.~Jian, L.~Cao, Z.~Gu, Q.~Chen, and A.~Amirbekyan.
\newblock Hers: Modeling influential contexts with heterogeneous relations for
  sparse and cold-start recommendation.
\newblock In {\em The Thirty-Third AAAI Conference on Artificial Intelligence},
  2019.

\bibitem{huang2022lb}
X.~Huang, Y.~Chen, W.~Yin, and K.~Yuan.
\newblock Lower bounds and nearly optimal algorithms in distributed learning
  with communication compression.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{Huber1964RobustEO}
P.~J. Huber.
\newblock Robust estimation of a location parameter.
\newblock {\em Annals of Mathematical Statistics}, 1964.

\bibitem{huber1981robust}
P.~J. Huber.
\newblock Robust statistics.
\newblock {\em Wiley Series in Probability and Mathematical Statistics}, 1981.

\bibitem{Kairouz2021AdvancesAO}
P.~Kairouz, H.~B. McMahan, B.~Avent, A.~Bellet, M.~Bennis, A.~N. Bhagoji,
  K.~Bonawitz, Z.~B. Charles, G.~Cormode, R.~Cummings, R.~G.~L. D'Oliveira,
  S.~Y.~E. Rouayheb, D.~Evans, J.~Gardner, Z.~Garrett, A.~Gasc{\'o}n, B.~Ghazi,
  P.~B. Gibbons, M.~Gruteser, Z.~Harchaoui, C.~He, L.~He, Z.~Huo,
  B.~Hutchinson, J.~Hsu, M.~Jaggi, T.~Javidi, G.~Joshi, M.~Khodak,
  J.~Konecn{\'y}, A.~Korolova, F.~Koushanfar, O.~Koyejo, T.~Lepoint, Y.~Liu,
  P.~Mittal, M.~Mohri, R.~Nock, A.~{\"O}zg{\"u}r, R.~Pagh, M.~Raykova, H.~Qi,
  D.~Ramage, R.~Raskar, D.~X. Song, W.~Song, S.~U. Stich, Z.~Sun, A.~T. Suresh,
  F.~Tram{\`e}r, P.~Vepakomma, J.~Wang, L.~Xiong, Z.~Xu, Q.~Yang, F.~X. Yu,
  H.~Yu, and S.~Zhao.
\newblock Advances and open problems in federated learning.
\newblock {\em Foundations and Trends in Machine Learning}, 2021.

\bibitem{lehmann2006theory}
E.~L. Lehmann and G.~Casella.
\newblock {\em Theory of point estimation}.
\newblock Springer Science \& Business Media, 2006.

\bibitem{Lerasle2011ROBUSTEM}
M.~Lerasle and R.~I. Oliveira.
\newblock Robust empirical mean estimators.
\newblock {\em arXiv: Statistics Theory}, 2011.

\bibitem{leskovec2020mining}
J.~Leskovec, A.~Rajaraman, and J.~D. Ullman.
\newblock {\em Mining of massive data sets}.
\newblock Cambridge university press, 2020.

\bibitem{Li2020OnTC}
X.~Li, K.~Huang, W.~Yang, S.~Wang, and Z.~Zhang.
\newblock On the convergence of fedavg on non-iid data.
\newblock {\em ArXiv}, abs/1907.02189, 2020.

\bibitem{Liu2019RecommenderSW}
T.~Liu, Z.~Wang, J.~Tang, S.~Yang, G.~Y. Huang, and Z.~Liu.
\newblock Recommender systems with heterogeneous side information.
\newblock {\em The World Wide Web Conference}, 2019.

\bibitem{Maurer2016TheBO}
A.~Maurer, M.~Pontil, and B.~Romera-Paredes.
\newblock The benefit of multitask representation learning.
\newblock {\em Journal of Machine Learning Research}, 17:81:1--81:32, 2016.

\bibitem{McMahan2017CommunicationEfficientLO}
H.~B. McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em Artificial Intelligence and Statistics}, 2017.

\bibitem{Minsker2015GeometricMA}
S.~Minsker.
\newblock Geometric median and robust estimation in banach spaces.
\newblock {\em Bernoulli}, 2015.

\bibitem{Minsker2019DistributedSE}
S.~Minsker and N.~Strawn.
\newblock Distributed statistical estimation and rates of convergence in normal
  approximation.
\newblock {\em ArXiv}, 2019.

\bibitem{Mullainathan2017DoesML}
S.~Mullainathan and Z.~Obermeyer.
\newblock Does machine learning automate moral hazard and error?
\newblock {\em The American Economic Review}, 107(5):476--480, 2017.

\bibitem{Nowak2003DistributedEA}
R.~D. Nowak.
\newblock Distributed em algorithms for density estimation in sensor networks.
\newblock {\em International Conference on Acoustics, Speech, and Signal
  Processing}, 2003.

\bibitem{Qian2015StructuredSR}
M.~Qian, L.~Hong, Y.~Shi, and S.~Rajan.
\newblock Structured sparse regression for recommender systems.
\newblock {\em Proceedings of the 24th ACM International on Conference on
  Information and Knowledge Management}, 2015.

\bibitem{QuioneroCandela2009DatasetSI}
J.~Quionero-Candela, M.~Sugiyama, A.~Schwaighofer, and N.~D. Lawrence.
\newblock {\em Dataset Shift in Machine Learning}.
\newblock MIT Press, 2009.

\bibitem{Shamsian2021PersonalizedFL}
A.~Shamsian, A.~Navon, E.~Fetaya, and G.~Chechik.
\newblock Personalized federated learning using hypernetworks.
\newblock In {\em International Conference on Machine Learning}, 2021.

\bibitem{Slavov2013AGA}
V.~Slavov and P.~R. Rao.
\newblock A gossip-based approach for internet-scale cardinality estimation of
  xpath queries over distributed semistructured data.
\newblock {\em The International Journal on Very Large Data Bases}, 2013.

\bibitem{smith2017federated}
V.~Smith, C.-K. Chiang, M.~Sanjabi, and A.~S. Talwalkar.
\newblock Federated multi-task learning.
\newblock In {\em Advances in neural information processing systems}, 2017.

\bibitem{Su2016FaultTolerantMO}
L.~Su and N.~H. Vaidya.
\newblock Fault-tolerant multi-agent optimization: Optimal iterative
  distributed algorithms.
\newblock In {\em Proceedings of the 2016 ACM Symposium on Principles of
  Distributed Computing}, 2016.

\bibitem{Su2016NonBayesianLI}
L.~Su and N.~H. Vaidya.
\newblock Non-bayesian learning in the presence of byzantine agents.
\newblock In {\em International Symposium on Distributed Computing}, pages
  414--427, 2016.

\bibitem{Subbaswamy2019FromDT}
A.~Subbaswamy and S.~Saria.
\newblock From development to deployment: dataset shift, causality, and
  shift-stable models in health ai.
\newblock {\em Biostatistics}, 2019.

\bibitem{Sun2017RevisitingUE}
C.~Sun, A.~Shrivastava, S.~Singh, and A.~K. Gupta.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock {\em 2017 IEEE International Conference on Computer Vision (ICCV)},
  pages 843--852, 2017.

\bibitem{Thrun1998LearningTL}
S.~Thrun and L.~Y. Pratt.
\newblock Learning to learn: Introduction and overview.
\newblock In {\em Learning to Learn}. Springer, 1998.

\bibitem{Tripuraneni2021ProvableMO}
N.~Tripuraneni, C.~Jin, and M.~I. Jordan.
\newblock Provable meta-learning of linear representations.
\newblock In {\em International Conference on Machine Learning}, 2021.

\bibitem{Tukey1960ASO}
J.~W. Tukey.
\newblock A survey of sampling from contaminated distributions.
\newblock {\em Contributions to probability and statistics}, 1960.

\bibitem{Uspensky1937IntroductionTM}
J.~V. Uspensky.
\newblock {\em Introduction to mathematical probability}.
\newblock McGraw-Hill Book Company, 1937.

\bibitem{Vershynin2018HighDimensionalP}
R.~Vershynin.
\newblock {\em High-Dimensional Probability}.
\newblock 2018.

\bibitem{Wang2022FederatedAO}
D.~Wang, S.~Shi, Y.~Zhu, and Z.~Han.
\newblock Federated analytics: Opportunities and challenges.
\newblock {\em IEEE Network}, 2022.

\bibitem{Xu2021LearningAB}
K.~Xu and H.~Bastani.
\newblock Learning across bandits in high dimension via robust statistics.
\newblock {\em ArXiv}, abs/2112.14233, 2021.

\bibitem{Yin2018ByzantineRobustDL}
D.~Yin, Y.~Chen, K.~Ramchandran, and P.~L. Bartlett.
\newblock Byzantine-robust distributed learning: Towards optimal statistical
  rates.
\newblock {\em ArXiv}, abs/1803.01498, 2018.

\bibitem{Zhou2012EffectiveDD}
M.~Zhou, H.~T. Shen, X.~Zhou, W.~Qian, and A.~Zhou.
\newblock Effective data density estimation in ring-based p2p networks.
\newblock {\em International Conference on Data Engineering}, 2012.

\end{thebibliography}
