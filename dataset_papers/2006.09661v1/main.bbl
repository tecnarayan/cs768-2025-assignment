\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Park et~al.(2019)Park, Florence, Straub, Newcombe, and
  Lovegrove]{park2019deepsdf}
Jeong~Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven
  Lovegrove.
\newblock Deepsdf: Learning continuous signed distance functions for shape
  representation.
\newblock \emph{Proc. CVPR}, 2019.

\bibitem[Mescheder et~al.(2019)Mescheder, Oechsle, Niemeyer, Nowozin, and
  Geiger]{mescheder2019occupancy}
Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and
  Andreas Geiger.
\newblock Occupancy networks: Learning 3d reconstruction in function space.
\newblock In \emph{Proc. CVPR}, 2019.

\bibitem[Saito et~al.(2019)Saito, Huang, Natsume, Morishima, Kanazawa, and
  Li]{saito2019pifu}
Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa,
  and Hao Li.
\newblock Pifu: Pixel-aligned implicit function for high-resolution clothed
  human digitization.
\newblock In \emph{Proc. ICCV}, pages 2304--2314, 2019.

\bibitem[Atzmon and Lipman(2020)]{atzmon2019sal}
Matan Atzmon and Yaron Lipman.
\newblock Sal: Sign agnostic learning of shapes from raw data.
\newblock In \emph{Proc. CVPR}, 2020.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{mildenhall2020nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock \emph{arXiv preprint arXiv:2003.08934}, 2020.

\bibitem[Genova et~al.(2019{\natexlab{a}})Genova, Cole, Vlasic, Sarna, Freeman,
  and Funkhouser]{genova2019learning}
Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William~T Freeman, and
  Thomas Funkhouser.
\newblock Learning shape templates with structured implicit functions.
\newblock In \emph{Proc. ICCV}, pages 7154--7164, 2019{\natexlab{a}}.

\bibitem[Genova et~al.(2019{\natexlab{b}})Genova, Cole, Sud, Sarna, and
  Funkhouser]{genova2019deep}
Kyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, and Thomas Funkhouser.
\newblock Deep structured implicit functions.
\newblock \emph{arXiv preprint arXiv:1912.06126}, 2019{\natexlab{b}}.

\bibitem[Michalkiewicz et~al.(2019)Michalkiewicz, Pontes, Jack, Baktashmotlagh,
  and Eriksson]{michalkiewicz2019implicit}
Mateusz Michalkiewicz, Jhony~K Pontes, Dominic Jack, Mahsa Baktashmotlagh, and
  Anders Eriksson.
\newblock Implicit surface representations as layers in neural networks.
\newblock In \emph{Proc. ICCV}, pages 4743--4752, 2019.

\bibitem[Gropp et~al.(2020)Gropp, Yariv, Haim, Atzmon, and
  Lipman]{gropp2020implicit}
Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, and Yaron Lipman.
\newblock Implicit geometric regularization for learning shapes.
\newblock \emph{arXiv preprint arXiv:2002.10099}, 2020.

\bibitem[Sitzmann et~al.(2019)Sitzmann, Zollh{\"o}fer, and
  Wetzstein]{sitzmann2019srns}
Vincent Sitzmann, Michael Zollh{\"o}fer, and Gordon Wetzstein.
\newblock Scene representation networks: Continuous 3d-structure-aware neural
  scene representations.
\newblock In \emph{Proc. NeurIPS}, 2019.

\bibitem[Jiang et~al.(2020)Jiang, Sud, Makadia, Huang, Nie{\ss}ner, and
  Funkhouser]{jiang2020local}
Chiyu Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nie{\ss}ner,
  and Thomas Funkhouser.
\newblock Local implicit grid representations for 3d scenes.
\newblock In \emph{Proc. CVPR}, pages 6001--6010, 2020.

\bibitem[Peng et~al.(2020)Peng, Niemeyer, Mescheder, Pollefeys, and
  Geiger]{peng2020convolutional}
Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas
  Geiger.
\newblock Convolutional occupancy networks.
\newblock \emph{arXiv preprint arXiv:2003.04618}, 2020.

\bibitem[Chabra et~al.(2020)Chabra, Lenssen, Ilg, Schmidt, Straub, Lovegrove,
  and Newcombe]{chabra2020deep}
Rohan Chabra, Jan~Eric Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven
  Lovegrove, and Richard Newcombe.
\newblock Deep local shapes: Learning local sdf priors for detailed 3d
  reconstruction.
\newblock \emph{arXiv preprint arXiv:2003.10983}, 2020.

\bibitem[Chen and Zhang(2019)]{chen2019learning}
Zhiqin Chen and Hao Zhang.
\newblock Learning implicit fields for generative shape modeling.
\newblock In \emph{Proc. CVPR}, pages 5939--5948, 2019.

\bibitem[Oechsle et~al.(2019)Oechsle, Mescheder, Niemeyer, Strauss, and
  Geiger]{Oechsle2019ICCV}
Michael Oechsle, Lars Mescheder, Michael Niemeyer, Thilo Strauss, and Andreas
  Geiger.
\newblock Texture fields: Learning texture representations in function space.
\newblock In \emph{Proc. ICCV}, 2019.

\bibitem[Niemeyer et~al.(2020)Niemeyer, Mescheder, Oechsle, and
  Geiger]{Niemeyer2020CVPR}
Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger.
\newblock Differentiable volumetric rendering: Learning implicit 3d
  representations without 3d supervision.
\newblock In \emph{Proc. CVPR}, 2020.

\bibitem[Tewari et~al.(2020)Tewari, Fried, Thies, Sitzmann, Lombardi,
  Sunkavalli, Martin-Brualla, Simon, Saragih, Nie{\ss}ner,
  et~al.]{tewari2020state}
Ayush Tewari, Ohad Fried, Justus Thies, Vincent Sitzmann, Stephen Lombardi,
  Kalyan Sunkavalli, Ricardo Martin-Brualla, Tomas Simon, Jason Saragih,
  Matthias Nie{\ss}ner, et~al.
\newblock State of the art on neural rendering.
\newblock \emph{Proc. Eurographics}, 2020.

\bibitem[Niemeyer et~al.(2019)Niemeyer, Mescheder, Oechsle, and
  Geiger]{Niemeyer2019ICCV}
Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger.
\newblock Occupancy flow: 4d reconstruction by learning particle dynamics.
\newblock In \emph{Proc. ICCV}, 2019.

\bibitem[Kohli et~al.(2020)Kohli, Sitzmann, and Wetzstein]{kohli2020inferring}
Amit Kohli, Vincent Sitzmann, and Gordon Wetzstein.
\newblock Inferring semantic information with 3d neural scene representations.
\newblock \emph{arXiv preprint arXiv:2003.12673}, 2020.

\bibitem[Gallant and White(1988)]{Gallant:1988}
R.~Gallant and H.~White.
\newblock There exists a neural network that does not make avoidable mistakes.
\newblock In \emph{IEEE Int. Conference on Neural Networks}, pages 657--664,
  1988.

\bibitem[Zhumekenov et~al.(2019)Zhumekenov, Uteuliyeva, Kabdolov, Takhanov,
  Assylbekov, and Castro]{zhumekenov2019fourier}
Abylay Zhumekenov, Malika Uteuliyeva, Olzhas Kabdolov, Rustem Takhanov,
  Zhenisbek Assylbekov, and Alejandro~J Castro.
\newblock Fourier neural networks: A comparative study.
\newblock \emph{arXiv preprint arXiv:1902.03011}, 2019.

\bibitem[Sopena et~al.(1999)Sopena, Romero, and Alquezar]{sopena1999neural}
Josep~M Sopena, Enrique Romero, and Rene Alquezar.
\newblock Neural networks with periodic and monotonic activation functions: a
  comparative study in classification problems.
\newblock In \emph{Proc. ICANN}, 1999.

\bibitem[Wong et~al.(2002)Wong, Leung, and Chang]{wong2002handwritten}
Kwok-wo Wong, Chi-sing Leung, and Sheng-jiang Chang.
\newblock Handwritten digit recognition using multilayer feedforward neural
  networks with periodic and monotonic activation functions.
\newblock In \emph{Object recognition supported by user interaction for service
  robots}, volume~3, pages 106--109. IEEE, 2002.

\bibitem[Parascandolo et~al.(2016)Parascandolo, Huttunen, and
  Virtanen]{parascandolo2016taming}
Giambattista Parascandolo, Heikki Huttunen, and Tuomas Virtanen.
\newblock Taming the waves: sine as activation function in deep neural
  networks.
\newblock 2016.

\bibitem[Liu et~al.(2015{\natexlab{a}})Liu, Zeng, and
  Wang]{liu2015multistability}
Peng Liu, Zhigang Zeng, and Jun Wang.
\newblock Multistability of recurrent neural networks with nonmonotonic
  activation functions and mixed time delays.
\newblock \emph{IEEE Trans. on Systems, Man, and Cybernetics: Systems},
  46\penalty0 (4):\penalty0 512--523, 2015{\natexlab{a}}.

\bibitem[Koplon and Sontag(1997)]{koplon1997using}
Ren{\'e}e Koplon and Eduardo~D Sontag.
\newblock Using fourier-neural recurrent networks to fit sequential
  input/output data.
\newblock \emph{Neurocomputing}, 15\penalty0 (3-4):\penalty0 225--248, 1997.

\bibitem[Choueiki et~al.(1997)Choueiki, Mount-Campbell, and
  Ahalt]{choueiki1997implementing}
M~Hisham Choueiki, Clark~A Mount-Campbell, and Stanley~C Ahalt.
\newblock Implementing a weighted least squares procedure in training a neural
  network to solve the short-term load forecasting problem.
\newblock \emph{IEEE Trans. on Power systems}, 12\penalty0 (4):\penalty0
  1689--1694, 1997.

\bibitem[Alqu{\'e}zar~Mancho(1997)]{alquezar1997symbolic}
Ren{\'e} Alqu{\'e}zar~Mancho.
\newblock \emph{Symbolic and connectionist learning techniques for grammatical
  inference}.
\newblock Universitat Polit{\`e}cnica de Catalunya, 1997.

\bibitem[Sopena and Alquezar(1994)]{sopena1994improvement}
JM~Sopena and R~Alquezar.
\newblock Improvement of learning in recurrent networks by substituting the
  sigmoid activation function.
\newblock In \emph{Proc. ICANN}, pages 417--420. Springer, 1994.

\bibitem[Cand{\`e}s(1999)]{candes1999harmonic}
Emmanuel~J Cand{\`e}s.
\newblock Harmonic analysis of neural networks.
\newblock \emph{Applied and Computational Harmonic Analysis}, 6\penalty0
  (2):\penalty0 197--218, 1999.

\bibitem[Lin et~al.(2013)Lin, Guo, Cao, and Xu]{lin2013approximation}
Shaobo Lin, Xiaofei Guo, Feilong Cao, and Zongben Xu.
\newblock Approximation by neural networks with scattered data.
\newblock \emph{Applied Mathematics and Computation}, 224:\penalty0 29--35,
  2013.

\bibitem[Sonoda and Murata(2017)]{sonoda2017neural}
Sho Sonoda and Noboru Murata.
\newblock Neural network with unbounded activation functions is universal
  approximator.
\newblock \emph{Applied and Computational Harmonic Analysis}, 43\penalty0
  (2):\penalty0 233--268, 2017.

\bibitem[Stanley(2007)]{stanley2007compositional}
Kenneth~O Stanley.
\newblock Compositional pattern producing networks: A novel abstraction of
  development.
\newblock \emph{Genetic programming and evolvable machines}, 8\penalty0
  (2):\penalty0 131--162, 2007.

\bibitem[Mordvintsev et~al.(2018)Mordvintsev, Pezzotti, Schubert, and
  Olah]{mordvintsev2018differentiable}
Alexander Mordvintsev, Nicola Pezzotti, Ludwig Schubert, and Chris Olah.
\newblock Differentiable image parameterizations.
\newblock \emph{Distill}, 3\penalty0 (7):\penalty0 e12, 2018.

\bibitem[Klocek et~al.(2019)Klocek, Maziarka, Wo{\l}czyk, Tabor, Nowak, and
  {\'S}mieja]{klocek2019hypernetwork}
Sylwester Klocek, {\L}ukasz Maziarka, Maciej Wo{\l}czyk, Jacek Tabor, Jakub
  Nowak, and Marek {\'S}mieja.
\newblock Hypernetwork functional image representation.
\newblock In \emph{Proc. ICANN}, pages 496--510. Springer, 2019.

\bibitem[Lee and Kang(1990)]{lee1990neural}
Hyuk Lee and In~Seok Kang.
\newblock Neural algorithm for solving differential equations.
\newblock \emph{Journal of Computational Physics}, 91\penalty0 (1):\penalty0
  110--131, 1990.

\bibitem[Lagaris et~al.(1998)Lagaris, Likas, and
  Fotiadis]{lagaris1998artificial}
Isaac~E Lagaris, Aristidis Likas, and Dimitrios~I Fotiadis.
\newblock Artificial neural networks for solving ordinary and partial
  differential equations.
\newblock \emph{IEEE Trans. on neural networks}, 9\penalty0 (5):\penalty0
  987--1000, 1998.

\bibitem[He et~al.(2000)He, Reif, and Unbehauen]{he2000multilayer}
Shouling He, Konrad Reif, and Rolf Unbehauen.
\newblock Multilayer neural networks for solving a class of partial
  differential equations.
\newblock \emph{Neural networks}, 13\penalty0 (3):\penalty0 385--396, 2000.

\bibitem[Mai-Duy and Tran-Cong(2003)]{mai2003approximation}
Nam Mai-Duy and Thanh Tran-Cong.
\newblock Approximation of function and its derivatives using radial basis
  function networks.
\newblock \emph{Applied Mathematical Modelling}, 27\penalty0 (3):\penalty0
  197--220, 2003.

\bibitem[Sirignano and Spiliopoulos(2018)]{sirignano2018dgm}
Justin Sirignano and Konstantinos Spiliopoulos.
\newblock Dgm: A deep learning algorithm for solving partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 375:\penalty0 1339--1364,
  2018.

\bibitem[Raissi et~al.(2019)Raissi, Perdikaris, and
  Karniadakis]{raissi2019physics}
Maziar Raissi, Paris Perdikaris, and George~E Karniadakis.
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 378:\penalty0 686--707,
  2019.

\bibitem[Berg and Nystr{\"o}m(2018)]{berg2018unified}
Jens Berg and Kaj Nystr{\"o}m.
\newblock A unified deep artificial neural network approach to partial
  differential equations in complex geometries.
\newblock \emph{Neurocomputing}, 317:\penalty0 28--41, 2018.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Tian~Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In \emph{Proc. NIPS}, pages 6571--6583, 2018.

\bibitem[P\'{e}rez et~al.(2003)P\'{e}rez, Gangnet, and Blake]{perez:2003}
Patrick P\'{e}rez, Michel Gangnet, and Andrew Blake.
\newblock Poisson image editing.
\newblock \emph{ACM Trans. on Graphics}, 22\penalty0 (3):\penalty0 313â€“318,
  2003.

\bibitem[Chen et~al.(2013)Chen, Cheng, Feng, and Wu]{chen2013optimal}
Zhongying Chen, Dongsheng Cheng, Wei Feng, and Tingting Wu.
\newblock An optimal 9-point finite difference scheme for the helmholtz
  equation with pml.
\newblock \emph{International Journal of Numerical Analysis \& Modeling},
  10\penalty0 (2), 2013.

\bibitem[Aghamiry et~al.(2019)Aghamiry, Gholami, and
  Operto]{aghamiry2019improving}
Hossein~S Aghamiry, Ali Gholami, and St{\'e}phane Operto.
\newblock Improving full-waveform inversion by wavefield reconstruction with
  the alternating direction method of multipliers.
\newblock \emph{Geophysics}, 84\penalty0 (1):\penalty0 R139--R162, 2019.

\bibitem[Van~Leeuwen and Herrmann(2013)]{van2013mitigating}
Tristan Van~Leeuwen and Felix~J Herrmann.
\newblock Mitigating local minima in full-waveform inversion by expanding the
  search space.
\newblock \emph{Geophysical Journal International}, 195\penalty0 (1):\penalty0
  661--667, 2013.

\bibitem[Boyd et~al.(2011)Boyd, Parikh, Chu, Peleato, Eckstein,
  et~al.]{boyd2011distributed}
Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et~al.
\newblock Distributed optimization and statistical learning via the alternating
  direction method of multipliers.
\newblock \emph{Foundations and Trends{\textregistered} in Machine learning},
  3\penalty0 (1):\penalty0 1--122, 2011.

\bibitem[Liu et~al.(2015{\natexlab{b}})Liu, Luo, Wang, and
  Tang]{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proc. ICCV}, December 2015{\natexlab{b}}.

\bibitem[Garnelo et~al.(2018)Garnelo, Rosenbaum, Maddison, Ramalho, Saxton,
  Shanahan, Teh, Rezende, and Eslami]{garnelo2018conditional}
Marta Garnelo, Dan Rosenbaum, Chris~J Maddison, Tiago Ramalho, David Saxton,
  Murray Shanahan, Yee~Whye Teh, Danilo~J Rezende, and SM~Eslami.
\newblock Conditional neural processes.
\newblock \emph{arXiv preprint arXiv:1807.01613}, 2018.

\bibitem[Eslami et~al.(2018)Eslami, Rezende, Besse, Viola, Morcos, Garnelo,
  Ruderman, Rusu, Danihelka, Gregor, et~al.]{eslami2018neural}
SM~Ali Eslami, Danilo~Jimenez Rezende, Frederic Besse, Fabio Viola, Ari~S
  Morcos, Marta Garnelo, Avraham Ruderman, Andrei~A Rusu, Ivo Danihelka, Karol
  Gregor, et~al.
\newblock Neural scene representation and rendering.
\newblock \emph{Science}, 360\penalty0 (6394):\penalty0 1204--1210, 2018.

\bibitem[Kim et~al.(2019)Kim, Mnih, Schwarz, Garnelo, Eslami, Rosenbaum,
  Vinyals, and Teh]{kim2019attentive}
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan
  Rosenbaum, Oriol Vinyals, and Yee~Whye Teh.
\newblock Attentive neural processes.
\newblock \emph{Proc. ICLR}, 2019.

\bibitem[Ha et~al.(2017)Ha, Dai, and Le]{ha2016hypernetworks}
David Ha, Andrew Dai, and Quoc~V Le.
\newblock Hypernetworks.
\newblock In \emph{Proc. ICLR}, 2017.

\end{thebibliography}
