\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Azaria(2022)]{azaria2022chatgpt}
Amos Azaria.
\newblock Chatgpt usage and limitations.
\newblock 2022.

\bibitem[Bird et~al.(2009)Bird, Klein, and Loper]{bird2009natural}
Steven Bird, Ewan Klein, and Edward Loper.
\newblock \emph{Natural language processing with Python: analyzing text with
  the natural language toolkit}.
\newblock " O'Reilly Media, Inc.", 2009.

\bibitem[Borji(2023)]{borji2023categorical}
Ali Borji.
\newblock A categorical archive of chatgpt failures.
\newblock \emph{arXiv preprint arXiv:2302.03494}, 2023.

\bibitem[Brodersen et~al.(2010)Brodersen, Ong, Stephan, and
  Buhmann]{brodersen2010balanced}
Kay~Henning Brodersen, Cheng~Soon Ong, Klaas~Enno Stephan, and Joachim~M
  Buhmann.
\newblock The balanced accuracy and its posterior distribution.
\newblock In \emph{2010 20th international conference on pattern recognition},
  pp.\  3121--3124. IEEE, 2010.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Pinto, Kaplan, Edwards,
  Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira
  Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
  Brockman, et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem[Chen et~al.(2023)Chen, Gao, and He]{DBLP:journals/corr/abs-2305-14069}
Shiqi Chen, Siyang Gao, and Junxian He.
\newblock Evaluating factual consistency of summaries with large language
  models.
\newblock \emph{CoRR}, abs/2305.14069, 2023.
\newblock \doi{10.48550/arXiv.2305.14069}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2305.14069}.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang,
  Zhuang, Gonzalez, Stoica, and Xing]{vicuna2023}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
  Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E. Gonzalez, Ion Stoica, and
  Eric~P. Xing.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt
  quality, March 2023.
\newblock URL \url{https://lmsys.org/blog/2023-03-30-vicuna/}.

\bibitem[Chowdhery et~al.(2022)Chowdhery, Narang, Devlin, Bosma, Mishra,
  Roberts, Barham, Chung, Sutton, Gehrmann, et~al.]{chowdhery2022palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, et~al.
\newblock Palm: Scaling language modeling with pathways.
\newblock \emph{arXiv preprint arXiv:2204.02311}, 2022.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser,
  Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
  Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
  et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[Dziri et~al.(2022)Dziri, Rashkin, Linzen, and
  Reitter]{dziri2022evaluating}
Nouha Dziri, Hannah Rashkin, Tal Linzen, and David Reitter.
\newblock Evaluating attribution in dialogue systems: The begin benchmark.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  10:\penalty0 1066--1083, 2022.

\bibitem[Fabbri et~al.(2021)Fabbri, Kry{\'s}ci{\'n}ski, McCann, Xiong, Socher,
  and Radev]{fabbri-etal-2021-summeval}
Alexander~R. Fabbri, Wojciech Kry{\'s}ci{\'n}ski, Bryan McCann, Caiming Xiong,
  Richard Socher, and Dragomir Radev.
\newblock {S}umm{E}val: Re-evaluating summarization evaluation.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:\penalty0 391--409, 2021.
\newblock \doi{10.1162/tacl_a_00373}.
\newblock URL \url{https://aclanthology.org/2021.tacl-1.24}.

\bibitem[Frieder et~al.(2023)Frieder, Pinchetti, Griffiths, Salvatori,
  Lukasiewicz, Petersen, Chevalier, and Berner]{frieder2023mathematical}
Simon Frieder, Luca Pinchetti, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas
  Lukasiewicz, Philipp~Christian Petersen, Alexis Chevalier, and Julius Berner.
\newblock Mathematical capabilities of chatgpt.
\newblock \emph{arXiv preprint arXiv:2301.13867}, 2023.

\bibitem[Guo et~al.(2023)Guo, Zhang, Wang, Jiang, Nie, Ding, Yue, and
  Wu]{guo2023close}
Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,
  Jianwei Yue, and Yupeng Wu.
\newblock How close is chatgpt to human experts? comparison corpus, evaluation,
  and detection.
\newblock \emph{arXiv preprint arXiv:2301.07597}, 2023.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song,
  and Steinhardt]{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
  Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2009, 2020.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Burns, Kadavath, Arora, Basart, Tang,
  Song, and Steinhardt]{hendrycks2021measuring}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric
  Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2103, 2021.

\bibitem[Honovich et~al.(2022)Honovich, Aharoni, Herzig, Taitelbaum, Kukliansy,
  Cohen, Scialom, Szpektor, Hassidim, and Matias]{honovich-etal-2022-true}
Or~Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy,
  Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi
  Matias.
\newblock {TRUE}: Re-evaluating factual consistency evaluation.
\newblock In \emph{Proceedings of the Second DialDoc Workshop on
  Document-grounded Dialogue and Conversational Question Answering}, pp.\
  161--175, Dublin, Ireland, May 2022. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/2022.dialdoc-1.19}.
\newblock URL \url{https://aclanthology.org/2022.dialdoc-1.19}.

\bibitem[Jung et~al.(2022)Jung, Qin, Welleck, Brahman, Bhagavatula, Le~Bras,
  and Choi]{jung-etal-2022-maieutic}
Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula,
  Ronan Le~Bras, and Yejin Choi.
\newblock Maieutic prompting: Logically consistent reasoning with recursive
  explanations.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1266--1279, Abu Dhabi, United Arab
  Emirates, December 2022. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2022.emnlp-main.82}.

\bibitem[Kamoi et~al.(2023)Kamoi, Goyal, Rodriguez, and Durrett]{kamoi2023wice}
Ryo Kamoi, Tanya Goyal, Juan~Diego Rodriguez, and Greg Durrett.
\newblock Wice: Real-world entailment for claims in wikipedia.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2303, 2023.

\bibitem[Kryscinski et~al.(2020)Kryscinski, McCann, Xiong, and
  Socher]{kryscinski2020evaluating}
Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and Richard Socher.
\newblock Evaluating the factual consistency of abstractive text summarization.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  9332--9346, Online, 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.750}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.750}.

\bibitem[Lewis et~al.(2020)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer]{lewis2020bart}
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
  Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.
\newblock Bart: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  7871--7880, 2020.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Cheng, Zhao, Nie, and
  Wen]{li2023halueval}
Junyi Li, Xiaoxue Cheng, Wayne~Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.
\newblock Halueval: A large-scale hallucination evaluation benchmark for large
  language models.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2305, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Allal, Zi, Muennighoff, Kocetkov,
  Mou, Marone, Akiki, Li, Chim, et~al.]{li2023starcoder}
Raymond Li, Loubna~Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov,
  Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et~al.
\newblock Starcoder: may the source be with you!
\newblock \emph{arXiv preprint arXiv:2305.06161}, 2023{\natexlab{b}}.

\bibitem[Liang et~al.(2022)Liang, Bommasani, Lee, Tsipras, Soylu, Yasunaga,
  Zhang, Narayanan, Wu, Kumar, et~al.]{liang2022holistic}
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
  Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar,
  et~al.
\newblock Holistic evaluation of language models.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2211, 2022.

\bibitem[Lightman et~al.(2023)Lightman, Kosaraju, Burda, Edwards, Baker, Lee,
  Leike, Schulman, Sutskever, and Cobbe]{lightman2023let}
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy
  Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.
\newblock Let's verify step by step.
\newblock \emph{arXiv preprint arXiv:2305.20050}, 2023.

\bibitem[Lin et~al.(2022)Lin, Hilton, and Evans]{lin2022truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  3214--3252,
  2022.

\bibitem[Maynez et~al.(2020)Maynez, Narayan, Bohnet, and
  McDonald]{maynez2020faithfulness}
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald.
\newblock On faithfulness and factuality in abstractive summarization.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  1906--1919, 2020.

\bibitem[Min et~al.(2023)Min, Krishna, Lyu, Lewis, tau Yih, Koh, Iyyer,
  Zettlemoyer, and Hajishirzi]{min2023factscore}
Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen tau Yih, Pang~Wei Koh,
  Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi.
\newblock Factscore: Fine-grained atomic evaluation of factual precision in
  long form text generation, 2023.

\bibitem[OpenAI(2022)]{chatgpt}
OpenAI.
\newblock Chatgpt: Optimizing language models for dialogue.
\newblock \emph{OpenAI Blog}, 2022.
\newblock URL \url{https://openai.com/blog/chatgpt/}.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock {GPT}-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Pagnoni et~al.(2021)Pagnoni, Balachandran, and
  Tsvetkov]{pagnoni2021understanding}
Artidoro Pagnoni, Vidhisha Balachandran, and Yulia Tsvetkov.
\newblock Understanding factuality in abstractive summarization with {FRANK}: A
  benchmark for factuality metrics.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  4812--4829, Online, 2021. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/2021.naacl-main.383}.
\newblock URL \url{https://aclanthology.org/2021.naacl-main.383}.

\bibitem[Rashkin et~al.(2023)Rashkin, Nikolaev, Lamm, Aroyo, Collins, Das,
  Petrov, Singh~Tomar, Turc, and Reitter]{rashkin2023measuring}
Hannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Lora Aroyo, Michael Collins,
  Dipanjan Das, Slav Petrov, Gaurav Singh~Tomar, Iulia Turc, and David Reitter.
\newblock Measuring attribution in natural language generation models.
\newblock \emph{Computational Linguistics}, pp.\  1--66, 2023.

\bibitem[Robertson et~al.(2009)Robertson, Zaragoza,
  et~al.]{robertson2009probabilistic}
Stephen Robertson, Hugo Zaragoza, et~al.
\newblock The probabilistic relevance framework: Bm25 and beyond.
\newblock \emph{Foundations and Trends{\textregistered} in Information
  Retrieval}, 3\penalty0 (4):\penalty0 333--389, 2009.

\bibitem[Schuster et~al.(2021)Schuster, Fisch, and Barzilay]{schuster2021get}
Tal Schuster, Adam Fisch, and Regina Barzilay.
\newblock Get your vitamin c! robust fact verification with contrastive
  evidence.
\newblock \emph{arXiv preprint arXiv:2103.08541}, 2021.

\bibitem[Tang et~al.(2022)Tang, Goyal, Fabbri, Laban, Xu, Yahvuz,
  Kry{\'s}ci{\'n}ski, Rousseau, and Durrett]{tang2022understanding}
Liyan Tang, Tanya Goyal, Alexander~R Fabbri, Philippe Laban, Jiacheng Xu, Semih
  Yahvuz, Wojciech Kry{\'s}ci{\'n}ski, Justin~F Rousseau, and Greg Durrett.
\newblock Understanding factual errors in summarization: Errors, summarizers,
  datasets, error detectors.
\newblock \emph{arXiv preprint arXiv:2205.12854}, 2022.

\bibitem[Taylor et~al.(2022)Taylor, Kardas, Cucurull, Scialom, Hartshorn,
  Saravia, Poulton, Kerkez, and Stojnic]{taylor2022galactica}
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
  Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.
\newblock Galactica: A large language model for science.
\newblock \emph{arXiv preprint arXiv:2211.09085}, 2022.

\bibitem[Thorne et~al.(2018)Thorne, Vlachos, Christodoulopoulos, and
  Mittal]{thorne2018fever}
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
\newblock Fever: a large-scale dataset for fact extraction and verification.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pp.\  809--819, 2018.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Wang et~al.(2020)Wang, Cho, and Lewis]{wang-etal-2020-asking}
Alex Wang, Kyunghyun Cho, and Mike Lewis.
\newblock Asking and answering questions to evaluate the factual consistency of
  summaries.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  5008--5020, Online, July 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.450}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.450}.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Wei, Schuurmans, Le, Chi, Narang,
  Chowdhery, and Zhou]{wang2022self}
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc~V Le, Ed~H Chi, Sharan Narang,
  Aakanksha Chowdhery, and Denny Zhou.
\newblock Self-consistency improves chain of thought reasoning in language
  models.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Kordi, Mishra, Liu, Smith,
  Khashabi, and Hajishirzi]{selfinstruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel
  Khashabi, and Hannaneh Hajishirzi.
\newblock Self-instruct: Aligning language model with self generated
  instructions, 2022{\natexlab{b}}.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le,
  and Zhou]{DBLP:conf/nips/Wei0SBIXCLZ22}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia,
  Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language
  models.
\newblock In \emph{NeurIPS}, 2022.
\newblock URL
  \url{http://papers.nips.cc/paper\_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html}.

\bibitem[Zhuo et~al.(2023)Zhuo, Huang, Chen, and Xing]{zhuo2023exploring}
Terry~Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing.
\newblock Exploring ai ethics of chatgpt: A diagnostic analysis.
\newblock \emph{arXiv preprint arXiv:2301.12867}, 2023.

\end{thebibliography}
