\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2019)Agarwal, Dudik, and Wu]{agarwal2019fair}
Alekh Agarwal, Miroslav Dudik, and Zhiwei~Steven Wu.
\newblock Fair regression: Quantitative definitions and reduction-based
  algorithms.
\newblock In \emph{International Conference on Machine Learning}, pages
  120--129, 2019.

\bibitem[Arjovsky and Bottou(2017)]{arjovsky2017towards}
Martin Arjovsky and L{\'e}on Bottou.
\newblock Towards principled methods for training generative adversarial
  networks. arxiv e-prints, art.
\newblock \emph{arXiv preprint arXiv:1701.04862}, 2017.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  214--223, 2017.

\bibitem[Bagdasaryan et~al.(2019)Bagdasaryan, Poursaeed, and
  Shmatikov]{bagdasaryan2019differential}
Eugene Bagdasaryan, Omid Poursaeed, and Vitaly Shmatikov.
\newblock Differential privacy has disparate impact on model accuracy.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  15453--15462, 2019.

\bibitem[Barocas and Selbst(2016)]{barocas2016big}
Solon Barocas and Andrew~D Selbst.
\newblock Big data's disparate impact.
\newblock \emph{Calif. L. Rev.}, 104:\penalty0 671, 2016.

\bibitem[Berk et~al.(2018)Berk, Heidari, Jabbari, Kearns, and
  Roth]{berk2018fairness}
Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth.
\newblock Fairness in criminal justice risk assessments: The state of the art.
\newblock \emph{Sociological Methods \& Research}, page 0049124118782533, 2018.

\bibitem[Beutel et~al.(2017)Beutel, Chen, Zhao, and Chi]{beutel2017data}
Alex Beutel, Jilin Chen, Zhe Zhao, and Ed~H Chi.
\newblock Data decisions and theoretical implications when adversarially
  learning fair representations.
\newblock \emph{arXiv preprint arXiv:1707.00075}, 2017.

\bibitem[Bigot(2020)]{bigot2020statistical}
J{\'e}r{\'e}mie Bigot.
\newblock Statistical data analysis in the wasserstein space.
\newblock \emph{ESAIM: Proceedings and Surveys}, 68:\penalty0 1--19, 2020.

\bibitem[Bird et~al.(2020)Bird, Dud{\'i}k, Edgar, Horn, Lutz, Milan, Sameki,
  Wallach, and Walker]{bird2020fairlearn}
Sarah Bird, Miro Dud{\'i}k, Richard Edgar, Brandon Horn, Roman Lutz, Vanessa
  Milan, Mehrnoosh Sameki, Hanna Wallach, and Kathleen Walker.
\newblock Fairlearn: A toolkit for assessing and improving fairness in {AI}.
\newblock Technical Report MSR-TR-2020-32, Microsoft, May 2020.

\bibitem[Buolamwini and Gebru(2018)]{buolamwini2018gender}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on fairness, accountability and transparency},
  pages 77--91, 2018.

\bibitem[Calders et~al.(2013)Calders, Karim, Kamiran, Ali, and
  Zhang]{calders2013controlling}
Toon Calders, Asim Karim, Faisal Kamiran, Wasif Ali, and Xiangliang Zhang.
\newblock Controlling attribute effect in linear regression.
\newblock In \emph{2013 IEEE 13th international conference on data mining},
  pages 71--80. IEEE, 2013.

\bibitem[Chen et~al.(2018)Chen, Johansson, and Sontag]{chen2018my}
Irene Chen, Fredrik~D Johansson, and David Sontag.
\newblock Why is my classifier discriminatory?
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3539--3550, 2018.

\bibitem[Chzhen et~al.(2020{\natexlab{a}})Chzhen, Denis, Hebiri, Oneto, and
  Pontil]{chzhen2020fair-a}
Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano
  Pontil.
\newblock Fair regression with wasserstein barycenters.
\newblock \emph{arXiv preprint arXiv:2006.07286}, 2020{\natexlab{a}}.

\bibitem[Chzhen et~al.(2020{\natexlab{b}})Chzhen, Denis, Hebiri, Oneto, and
  Pontil]{chzhen2020fair-b}
Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano
  Pontil.
\newblock Fair regression via plug-in estimator and recalibration with
  statistical guarantees.
\newblock \emph{Advances in Neural Information Processing Systems}, 33,
  2020{\natexlab{b}}.

\bibitem[Daskalakis and Panageas(2018)]{daskalakis2018limit}
Constantinos Daskalakis and Ioannis Panageas.
\newblock The limit points of (optimistic) gradient descent in min-max
  optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9236--9246, 2018.

\bibitem[Dieterich et~al.(2016)Dieterich, Mendoza, and
  Brennan]{dieterich2016compas}
William Dieterich, Christina Mendoza, and Tim Brennan.
\newblock Compas risk scales: Demonstrating accuracy equity and predictive
  parity.
\newblock \emph{Northpointe Inc}, 2016.

\bibitem[Dua and Graff(2017)]{Dua:2019}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012fairness}
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
\newblock Fairness through awareness.
\newblock In \emph{Proceedings of the 3rd innovations in theoretical computer
  science conference}, pages 214--226, 2012.

\bibitem[Edwards and Storkey(2015)]{edwards2015censoring}
Harrison Edwards and Amos Storkey.
\newblock Censoring representations with an adversary.
\newblock \emph{arXiv preprint arXiv:1511.05897}, 2015.

\bibitem[Feldman et~al.(2015)Feldman, Friedler, Moeller, Scheidegger, and
  Venkatasubramanian]{feldman2015certifying}
Michael Feldman, Sorelle~A Friedler, John Moeller, Carlos Scheidegger, and
  Suresh Venkatasubramanian.
\newblock Certifying and removing disparate impact.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 259--268. ACM, 2015.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Hardt et~al.(2016)Hardt, Price, Srebro, et~al.]{hardt2016equality}
Moritz Hardt, Eric Price, Nati Srebro, et~al.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  3315--3323, 2016.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Srivastava, Namkoong, and
  Liang]{hashimoto2018fairness}
Tatsunori~B Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang.
\newblock Fairness without demographics in repeated loss minimization.
\newblock \emph{arXiv preprint arXiv:1806.08010}, 2018.

\bibitem[Hittmeir et~al.(2019)Hittmeir, Ekelhart, and
  Mayer]{hittmeir2019utility}
Markus Hittmeir, Andreas Ekelhart, and Rudolf Mayer.
\newblock Utility and privacy assessments of synthetic data for regression
  tasks.
\newblock In \emph{2019 IEEE International Conference on Big Data (Big Data)},
  pages 5763--5772. IEEE, 2019.

\bibitem[Hui and Belkin(2021)]{hui2021evaluation}
Like Hui and Mikhail Belkin.
\newblock {\{}EVALUATION{\}} {\{}of{\}} {\{}neural{\}} {\{}architectures{\}}
  {\{}trained{\}} {\{}with{\}} {\{}square{\}} {\{}loss{\}} {\{}vs{\}}
  {\{}cross{\}}-{\{}entropy{\}} {\{}in{\}} {\{}classification{\}}
  {\{}tasks{\}}.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=hsFN92eQEla}.

\bibitem[Jiang et~al.(2019)Jiang, Pacchiano, Stepleton, Jiang, and
  Chiappa]{jiang2019wasserstein}
Ray Jiang, Aldo Pacchiano, Tom Stepleton, Heinrich Jiang, and Silvia Chiappa.
\newblock Wasserstein fair classification.
\newblock \emph{arXiv preprint arXiv:1907.12059}, 2019.

\bibitem[Johnson et~al.(2016)Johnson, Foster, and Stine]{johnson2016impartial}
Kory~D Johnson, Dean~P Foster, and Robert~A Stine.
\newblock Impartial predictive modeling: Ensuring fairness in arbitrary models.
\newblock \emph{arXiv preprint arXiv:1608.00528}, 2016.

\bibitem[Khani and Liang(2019)]{khani2019noise}
Fereshte Khani and Percy Liang.
\newblock Noise induces loss discrepancy across groups for linear regression.
\newblock \emph{arXiv preprint arXiv:1911.09876}, 2019.

\bibitem[Khani and Liang(2020)]{khani2020removing}
Fereshte Khani and Percy Liang.
\newblock Removing spurious features can hurt accuracy and affect groups
  disproportionately.
\newblock \emph{arXiv preprint arXiv:2012.04104}, 2020.

\bibitem[Kim(2016)]{kim2016data}
Pauline~T Kim.
\newblock Data-driven discrimination at work.
\newblock \emph{Wm. \& Mary L. Rev.}, 58:\penalty0 857, 2016.

\bibitem[Komiyama et~al.(2018)Komiyama, Takeda, Honda, and
  Shimao]{komiyama2018nonconvex}
Junpei Komiyama, Akiko Takeda, Junya Honda, and Hajime Shimao.
\newblock Nonconvex optimization for regression with fairness constraints.
\newblock In \emph{International conference on machine learning}, pages
  2737--2746, 2018.

\bibitem[Lantz(2013)]{lantz2013machine}
Brett Lantz.
\newblock \emph{Machine learning with R}.
\newblock Packt publishing ltd, 2013.

\bibitem[Louizos et~al.(2015)Louizos, Swersky, Li, Welling, and
  Zemel]{louizos2015variational}
Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard Zemel.
\newblock The variational fair autoencoder.
\newblock \emph{arXiv preprint arXiv:1511.00830}, 2015.

\bibitem[Madras et~al.(2018)Madras, Creager, Pitassi, and
  Zemel]{madras2018learning}
David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel.
\newblock Learning adversarially fair and transferable representations.
\newblock \emph{arXiv preprint arXiv:1802.06309}, 2018.

\bibitem[Madras et~al.(2019)Madras, Creager, Pitassi, and
  Zemel]{madras2019fairness}
David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel.
\newblock Fairness through causal awareness: Learning causal latent-variable
  models for biased data.
\newblock In \emph{Proceedings of the Conference on Fairness, Accountability,
  and Transparency}, pages 349--358, 2019.

\bibitem[Mary et~al.(2019)Mary, Calauz{\`e}nes, and
  El~Karoui]{mary2019fairness}
J{\'e}r{\'e}mie Mary, Cl{\'e}ment Calauz{\`e}nes, and Noureddine El~Karoui.
\newblock Fairness-aware learning for continuous attributes and treatments.
\newblock In \emph{International Conference on Machine Learning}, pages
  4382--4391, 2019.

\bibitem[Muthukumar et~al.(2020)Muthukumar, Narang, Subramanian, Belkin, Hsu,
  and Sahai]{muthukumar2020classification}
Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin, Daniel
  Hsu, and Anant Sahai.
\newblock Classification vs regression in overparameterized regimes: Does the
  loss function matter?
\newblock \emph{arXiv preprint arXiv:2005.08054}, 2020.

\bibitem[Narasimhan et~al.(2020)Narasimhan, Cotter, Gupta, and
  Wang]{narasimhan2020pairwise}
Harikrishna Narasimhan, Andrew Cotter, Maya~R Gupta, and Serena Wang.
\newblock Pairwise fairness for ranking and regression.
\newblock In \emph{AAAI}, pages 5248--5255, 2020.

\bibitem[Narayanan(2018)]{narayanan2018translation}
Arvind Narayanan.
\newblock Translation tutorial: 21 fairness definitions and their politics.
\newblock In \emph{Proc. Conf. Fairness Accountability Transp., New York, USA},
  2018.

\bibitem[Pan et~al.(2020)Pan, Imani, Farahmand, and White]{pan2020implicit}
Yangchen Pan, Ehsan Imani, Amir-massoud Farahmand, and Martha White.
\newblock An implicit function learning approach for parametric modal
  regression.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Panay et~al.(2019)Panay, Baloian, Pino, Pe{\~n}afiel, Sanson, and
  Bersano]{panay2019predicting}
Belisario Panay, Nelson Baloian, Jos{\'e}~A Pino, Sergio Pe{\~n}afiel, Horacio
  Sanson, and Nicolas Bersano.
\newblock Predicting health care costs using evidence regression.
\newblock In \emph{Multidisciplinary Digital Publishing Institute Proceedings},
  volume~31, page~74, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 8026--8037, 2019.

\bibitem[Que and Belkin(2016)]{pmlr-v51-que16}
Qichao Que and Mikhail Belkin.
\newblock Back to the future: Radial basis function networks revisited.
\newblock In Arthur Gretton and Christian~C. Robert, editors, \emph{Proceedings
  of the 19th International Conference on Artificial Intelligence and
  Statistics}, volume~51 of \emph{Proceedings of Machine Learning Research},
  pages 1375--1383, Cadiz, Spain, 09--11 May 2016. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v51/que16.html}.

\bibitem[Villani(2008)]{villani2008optimal}
C{\'e}dric Villani.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Wightman and Ramsey(1998)]{wightman1998lsac}
Linda~F Wightman and Henry Ramsey.
\newblock \emph{LSAC national longitudinal bar passage study}.
\newblock Law School Admission Council, 1998.

\bibitem[Yaghini et~al.(2019)Yaghini, Kulynych, and
  Troncoso]{yaghini2019disparate}
Mohammad Yaghini, Bogdan Kulynych, and Carmela Troncoso.
\newblock Disparate vulnerability: On the unfairness of privacy attacks against
  machine learning.
\newblock \emph{arXiv preprint arXiv:1906.00389}, 2019.

\bibitem[Zafar et~al.(2017{\natexlab{a}})Zafar, Valera, Gomez~Rodriguez, and
  Gummadi]{zafar2017fairness-a}
Muhammad~Bilal Zafar, Isabel Valera, Manuel Gomez~Rodriguez, and Krishna~P
  Gummadi.
\newblock Fairness beyond disparate treatment \& disparate impact: Learning
  classification without disparate mistreatment.
\newblock In \emph{Proceedings of the 26th International Conference on World
  Wide Web}, pages 1171--1180. International World Wide Web Conferences
  Steering Committee, 2017{\natexlab{a}}.

\bibitem[Zafar et~al.(2017{\natexlab{b}})Zafar, Valera, Rogriguez, and
  Gummadi]{zafar2017fairness-b}
Muhammad~Bilal Zafar, Isabel Valera, Manuel~Gomez Rogriguez, and Krishna~P
  Gummadi.
\newblock Fairness constraints: Mechanisms for fair classification.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 962--970,
  2017{\natexlab{b}}.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and
  Dwork]{zemel2013learning}
Rich Zemel, Yu~Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork.
\newblock Learning fair representations.
\newblock In \emph{International Conference on Machine Learning}, pages
  325--333, 2013.

\bibitem[Zhao and Gordon(2019)]{zhao2019inherent}
Han Zhao and Geoffrey~J Gordon.
\newblock Inherent tradeoffs in learning fair representations.
\newblock In \emph{Advances in neural information processing systems}, 2019.

\bibitem[Zhao et~al.(2019)Zhao, Coston, Adel, and Gordon]{zhao2019conditional}
Han Zhao, Amanda Coston, Tameem Adel, and Geoffrey~J Gordon.
\newblock Conditional learning of fair representations.
\newblock \emph{arXiv preprint arXiv:1910.07162}, 2019.

\bibitem[Zhao et~al.(2020)Zhao, Chi, Tian, and Gordon]{zhao2020trade}
Han Zhao, Jianfeng Chi, Yuan Tian, and Geoffrey~J Gordon.
\newblock Trade-offs and guarantees of adversarial representation learning for
  information obfuscation.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Zink and Rose(2020)]{zink2020fair}
Anna Zink and Sherri Rose.
\newblock Fair regression for health care spending.
\newblock \emph{Biometrics}, 76\penalty0 (3):\penalty0 973--982, 2020.

\end{thebibliography}
