\begin{thebibliography}{90}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Pieter~Abbeel, and
  Zaremba]{andrychowicz2017hindsight}
Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong,
  Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter~Abbeel, and Wojciech
  Zaremba.
\newblock Hindsight experience replay.
\newblock \emph{Advances in neural information processing systems}, 2017.

\bibitem[Antognini and Faltings(2021)]{antognini2021rationalization}
Diego Antognini and Boi Faltings.
\newblock Rationalization through concepts.
\newblock \emph{ArXiv}, 2021.

\bibitem[Arnold and Kasenberg(2017)]{arnold2017value}
Thomas Arnold and Daniel Kasenberg.
\newblock Value alignment or misalignment -- what will keep systems
  accountable?
\newblock In \emph{AAAI Workshop on AI, Ethics, and Society}, 2017.

\bibitem[Bacon et~al.(2017)Bacon, Harb, and Precup]{BaconHP17}
Pierre{-}Luc Bacon, Jean Harb, and Doina Precup.
\newblock The option-critic architecture.
\newblock In \emph{Proceedings of the Thirty-First {AAAI} Conference on
  Artificial Intelligence, February 4-9, 2017, San Francisco, California,
  {USA}}, 2017.

\bibitem[Bastani et~al.(2018)Bastani, Pu, and Solar{-}Lezama]{BastaniPS18}
Osbert Bastani, Yewen Pu, and Armando Solar{-}Lezama.
\newblock Verifiable reinforcement learning via policy extraction.
\newblock In Samy Bengio, Hanna~M. Wallach, Hugo Larochelle, Kristen Grauman,
  Nicol{\`{o}} Cesa{-}Bianchi, and Roman Garnett, editors, \emph{Advances in
  Neural Information Processing Systems 31: Annual Conference on Neural
  Information Processing Systems, NeurIPS}, 2018.

\bibitem[Bellemare et~al.(2012)Bellemare, Naddaf, Veness, and
  Bowling]{Bellemare2012TheAL}
Marc~G. Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general
  agents (extended abstract).
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2012.

\bibitem[Bontempelli et~al.(2023)Bontempelli, Teso, Tentori, Giunchiglia, and
  Passerini]{BontempelliTTGP23}
Andrea Bontempelli, Stefano Teso, Katya Tentori, Fausto Giunchiglia, and Andrea
  Passerini.
\newblock Concept-level debugging of part-prototype networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Broelemann and Kasneci(2019)]{BroelemannK19}
Klaus Broelemann and Gjergji Kasneci.
\newblock A gradient-based split criterion for highly accurate and transparent
  model trees.
\newblock In \emph{Proceedings of the Twenty-Eighth International Joint
  Conference on Artificial Intelligence, {IJCAI} 2019, Macao, China, August
  10-16, 2019}, 2019.

\bibitem[Cao et~al.(2022)Cao, Li, Yang, Zhang, Zheng, Li, Hao, and
  Liu]{cao2022galois}
Yushi Cao, Zhiming Li, Tianpei Yang, Hao Zhang, Yan Zheng, Yi~Li, Jianye Hao,
  and Yang Liu.
\newblock Galois: boosting deep reinforcement learning via generalizable logic
  synthesis.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Chan et~al.(2022)Chan, Kong, and Liang]{ChanKL22}
Chun~Sik Chan, Huanqi Kong, and Guanqing Liang.
\newblock A comparative study of faithfulness metrics for model
  interpretability methods.
\newblock In \emph{Conference of the Association for Computational Linguistics
  (ACL)}, 2022.

\bibitem[Cobbe et~al.(2019)Cobbe, Klimov, Hesse, Kim, and Schulman]{coinrun19}
Karl Cobbe, Oleg Klimov, Christopher Hesse, Taehoon Kim, and John Schulman.
\newblock Quantifying generalization in reinforcement learning.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning,
  {ICML} 2019}, 2019.

\bibitem[Cuccu et~al.(2020)Cuccu, Togelius, and
  Cudr{\'{e}}{-}Mauroux]{Cucca2020playing6neurons}
Giuseppe Cuccu, Julian Togelius, and Philippe Cudr{\'{e}}{-}Mauroux.
\newblock Playing atari with six neurons (extended abstract).
\newblock In Christian Bessiere, editor, \emph{Proceedings of the Twenty-Ninth
  International Joint Conference on Artificial Intelligence, {IJCAI} 2020},
  2020.

\bibitem[Dazeley et~al.(2022)Dazeley, Vamplew, and Cruz]{dazeley2023xrl}
Richard Dazeley, Peter Vamplew, and Francisco Cruz.
\newblock Explainable reinforcement learning for broad-xai: a conceptual
  framework and survey.
\newblock \emph{Neural Computing and Applications}, 2022.

\bibitem[Delfosse et~al.(2023{\natexlab{a}})Delfosse, Shindo, Dhami, and
  Kersting]{Delfosse2023InterpretableAE}
Quentin Delfosse, Hikaru Shindo, Devendra~Singh Dhami, and Kristian Kersting.
\newblock Interpretable and explainable logical policies via neurally guided
  symbolic abstraction.
\newblock In \emph{Advances in Neural Information Processing (NeurIPS)},
  2023{\natexlab{a}}.

\bibitem[Delfosse et~al.(2023{\natexlab{b}})Delfosse, Stammer, Rothenbacher,
  Vittal, and Kersting]{delfosse2021moc}
Quentin Delfosse, Wolfgang Stammer, Thomas Rothenbacher, Dwarak Vittal, and
  Kristian Kersting.
\newblock Boosting object representation learning via motion and object
  continuity.
\newblock In Danai Koutra, Claudia Plant, Manuel~Gomez Rodriguez, Elena
  Baralis, and Francesco Bonchi, editors, \emph{European Conference on Machine
  Learning and Principles and Practice of Knowledge Discovery in Databases
  ({ECML})}, 2023{\natexlab{b}}.

\bibitem[Delfosse et~al.(2024{\natexlab{a}})Delfosse, Bl{\"u}ml, Gregori, and
  Kersting]{delfosse2024hackatari}
Quentin Delfosse, Jannis Bl{\"u}ml, Bjarne Gregori, and Kristian Kersting.
\newblock Hackatari: Atari learning environments for robust and continual
  reinforcement learning.
\newblock \emph{arXiv}, 2024{\natexlab{a}}.

\bibitem[Delfosse et~al.(2024{\natexlab{b}})Delfosse, Bl{\"{u}}ml, Gregori,
  Sztwiertnia, and Kersting]{delfosse2024ocatari}
Quentin Delfosse, Jannis Bl{\"{u}}ml, Bjarne Gregori, Sebastian Sztwiertnia,
  and Kristian Kersting.
\newblock {OCAtari}: {O}bject-centric {Atari} 2600 reinforcement learning
  environments.
\newblock \emph{Reinforcement Learning Journal}, 2024{\natexlab{b}}.

\bibitem[Delfosse et~al.(2024{\natexlab{c}})Delfosse, Schramowski, Mundt,
  Molina, and Kersting]{delfosse2021rationalrl}
Quentin Delfosse, Patrick Schramowski, Martin Mundt, Alejandro Molina, and
  Kristian Kersting.
\newblock Adaptive rational activations to boost deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations
  ({ICLR})}, 2024{\natexlab{c}}.

\bibitem[di~Langosco et~al.(2022)di~Langosco, Koch, Sharkey, Pfau, and
  Krueger]{Langosco2022goal}
Lauro~Langosco di~Langosco, Jack Koch, Lee~D. Sharkey, Jacob Pfau, and David
  Krueger.
\newblock Goal misgeneralization in deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning {ICML}}, 2022.

\bibitem[Friedrich et~al.(2023)Friedrich, Steinmann, and
  Kersting]{friedrich2023one}
Felix Friedrich, David Steinmann, and Kristian Kersting.
\newblock One explanation does not fit xil.
\newblock \emph{arXiv}, 2023.

\bibitem[Fuhrer et~al.(2024)Fuhrer, Tessler, and Dalal]{fuhrer2024gradient}
Benjamin Fuhrer, Chen Tessler, and Gal Dalal.
\newblock Gradient boosting reinforcement learning.
\newblock \emph{arXiv}, 2024.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{shortcutlearning}
Robert Geirhos, J{\"{o}}rn{-}Henrik Jacobsen, Claudio Michaelis, Richard~S.
  Zemel, Wieland Brendel, Matthias Bethge, and Felix~A. Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2020.

\bibitem[Grandien et~al.(2024)Grandien, Delfosse, and
  Kersting]{grandien2024interpretableete}
Nils Grandien, Quentin Delfosse, and Kristian Kersting.
\newblock Interpretable end-to-end neurosymbolic reinforcement learning agents.
\newblock \emph{arXiv}, 2024.

\bibitem[Grupen et~al.(2022)Grupen, Jaques, Kim, and
  Omidshafiei]{grupen2022conceptbased}
Niko Grupen, Natasha Jaques, Been Kim, and Shayegan Omidshafiei.
\newblock Concept-based understanding of emergent multi-agent behavior.
\newblock In \emph{Deep Reinforcement Learning Workshop NeurIPS 2022}, 2022.

\bibitem[Guan et~al.(2023)Guan, Valmeekam, and Kambhampati]{Guan2022RelativeBA}
Lin Guan, Karthik Valmeekam, and Subbarao Kambhampati.
\newblock Relative behavioral attributes: Filling the gap between symbolic goal
  specification and reward learning from human preferences.
\newblock In \emph{International Conference on Learning Representations
  ({ICLR})}, 2023.

\bibitem[Henderson et~al.(2017)Henderson, Islam, Bachman, Pineau, Precup, and
  Meger]{Henderson2017DeepRL}
Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup,
  and David Meger.
\newblock Deep reinforcement learning that matters.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2017.

\bibitem[Irving et~al.(2018)Irving, Christiano, and Amodei]{Irving2018AISV}
Geoffrey Irving, Paul~Francis Christiano, and Dario Amodei.
\newblock Ai safety via debate.
\newblock \emph{ArXiv}, 2018.

\bibitem[Itaya et~al.(2021)Itaya, Hirakawa, Yamashita, Fujiyoshi, and
  Sugiura]{Itaya2021VisualEU}
Hidenori Itaya, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi, and
  Komei Sugiura.
\newblock Visual explanation using attention mechanism in actor-critic-based
  deep reinforcement learning.
\newblock \emph{2021 International Joint Conference on Neural Networks
  (IJCNN)}, 2021.

\bibitem[Jabri et~al.(2019)Jabri, Hsu, Eysenbach, Gupta, Efros, Levine, and
  Finn]{Jabri2019UnsupervisedCF}
A.~Jabri, Kyle Hsu, Benjamin Eysenbach, Abhishek Gupta, Alexei~A. Efros, Sergey
  Levine, and Chelsea Finn.
\newblock Unsupervised curricula for visual meta-reinforcement learning.
\newblock \emph{ArXiv}, 2019.

\bibitem[Jiang and Luo(2019)]{jiang2019neural}
Zhengyao Jiang and Shan Luo.
\newblock Neural logic reinforcement learning.
\newblock In \emph{International conference on machine learning}, 2019.

\bibitem[Kaiser et~al.(2019)Kaiser, Babaeizadeh, Milos, Osinski, Campbell,
  Czechowski, Erhan, Finn, Kozakowski, Levine, Mohiuddin, Sepassi, Tucker, and
  Michalewski]{Kaiser2019ModelBasedRL}
Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy~H.
  Campbell, K.~Czechowski, D.~Erhan, Chelsea Finn, Piotr Kozakowski, Sergey
  Levine, Afroz Mohiuddin, Ryan Sepassi, G.~Tucker, and Henryk Michalewski.
\newblock Model-based reinforcement learning for atari.
\newblock \emph{ArXiv}, 2019.

\bibitem[Kambhampati et~al.(2021)Kambhampati, Sreedharan, Verma, Zha, and
  Guan]{Kambhampati2021SymbolsAA}
Subbarao Kambhampati, Sarath Sreedharan, Mudit Verma, Yantian Zha, and L.~Guan.
\newblock Symbols as a lingua franca for bridging human-ai chasm for
  explainable and advisable ai systems.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2021.

\bibitem[Kaufmann et~al.(2024)Kaufmann, Bl{\"u}ml, W{\"u}st, Delfosse,
  Kersting, and H{\"u}llermeier]{kaufmann2024ocalm}
Timo Kaufmann, Jannis Bl{\"u}ml, Antonia W{\"u}st, Quentin Delfosse, Kristian
  Kersting, and Eyke H{\"u}llermeier.
\newblock Ocalm: Object-centric assessment with language models.
\newblock \emph{arXiv}, 2024.

\bibitem[Kimura et~al.(2021)Kimura, Ono, Chaudhury, Kohita, Wachi, Agravante,
  Tatsubori, Munawar, and Gray]{kimura2021neuro}
Daiki Kimura, Masaki Ono, Subhajit Chaudhury, Ryosuke Kohita, Akifumi Wachi,
  Don~Joven Agravante, Michiaki Tatsubori, Asim Munawar, and Alexander Gray.
\newblock Neuro-symbolic reinforcement learning with first-order logic.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, 2021.

\bibitem[Koch et~al.(2021)Koch, Langosco, Pfau, Le, and
  Sharkey]{Koch2021-misalignment}
Jack Koch, Lauro Langosco, Jacob Pfau, James Le, and Lee Sharkey.
\newblock Objective robustness in deep reinforcement learning, 2021.

\bibitem[Koh et~al.(2020)Koh, Nguyen, Tang, Mussmann, Pierson, Kim, and
  Liang]{KohNTMPKL20conceptbottleneck}
Pang~Wei Koh, Thao Nguyen, Yew~Siang Tang, Stephen Mussmann, Emma Pierson, Been
  Kim, and Percy Liang.
\newblock Concept bottleneck models.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, 2020.

\bibitem[Kohler et~al.(2024)Kohler, Delfosse, Akrour, Kersting, and
  Preux]{kohler2024interpretable}
Hector Kohler, Quentin Delfosse, Riad Akrour, Kristian Kersting, and Philippe
  Preux.
\newblock Interpretable and editable programmatic tree policies for
  reinforcement learning.
\newblock In \emph{Workshop on Interpretable Policies in Reinforcement
  Learning@ RLC-2024}, 2024.

\bibitem[Krajna et~al.(2022)Krajna, Brčič, Lipi{\'c}, and
  Doncevic]{krajna2022explainability}
Agneza Krajna, Mario Brčič, Tomislav Lipi{\'c}, and Juraj Doncevic.
\newblock Explainability in reinforcement learning: perspective and position.
\newblock \emph{ArXiv}, 2022.

\bibitem[Kraus et~al.(2024)Kraus, Steinmann, W{\"u}st, Kokozinski, and
  Kersting]{kraus2024right}
Maurice Kraus, David Steinmann, Antonia W{\"u}st, Andre Kokozinski, and
  Kristian Kersting.
\newblock Right on time: Revising time series models by constraining their
  explanations.
\newblock \emph{arXiv}, 2024.

\bibitem[Kumar et~al.(2009)Kumar, Berg, Belhumeur, and
  Nayar]{kumar2009attribute}
Neeraj Kumar, Alexander~C. Berg, Peter~N. Belhumeur, and Shree~K. Nayar.
\newblock Attribute and simile classifiers for face verification.
\newblock \emph{2009 IEEE 12th International Conference on Computer Vision},
  2009.

\bibitem[Kwon et~al.(2023)Kwon, Xie, Bullard, and Sadigh]{kwon2023reward}
Minae Kwon, Sang~Michael Xie, Kalesha Bullard, and Dorsa Sadigh.
\newblock Reward design with language models.
\newblock \emph{arXiv}, 2023.

\bibitem[Lage and Doshi-Velez(2020)]{lage2020concept}
Isaac Lage and Finale Doshi-Velez.
\newblock Learning interpretable concept-based models with human feedback.
\newblock \emph{ArXiv}, 2020.

\bibitem[Lampert et~al.(2009)Lampert, Nickisch, and
  Harmeling]{lampert2009attributes}
Christoph~H. Lampert, Hannes Nickisch, and Stefan Harmeling.
\newblock Learning to detect unseen object classes by between-class attribute
  transfer.
\newblock \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, 2009.

\bibitem[Lapuschkin et~al.(2019)Lapuschkin, W{\"a}ldchen, Binder, Montavon,
  Samek, and M{\"u}ller]{lapuschkin2019unmasking}
Sebastian Lapuschkin, Stephan W{\"a}ldchen, Alexander Binder, Gr{\'e}goire
  Montavon, Wojciech Samek, and Klaus-Robert M{\"u}ller.
\newblock Unmasking clever hans predictors and assessing what machines really
  learn.
\newblock \emph{Nature communications}, 2019.

\bibitem[Lin et~al.(2020)Lin, Wu, Peri, Sun, Singh, Deng, Jiang, and
  Ahn]{lin2020space}
Zhixuan Lin, Yi{-}Fu Wu, Skand~Vishwanath Peri, Weihao Sun, Gautam Singh, Fei
  Deng, Jindong Jiang, and Sungjin Ahn.
\newblock {SPACE:} unsupervised object-oriented scene representation via
  spatial attention and decomposition.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Locatello et~al.(2020)Locatello, Weissenborn, Unterthiner, Mahendran,
  Heigold, Uszkoreit, Dosovitskiy, and Kipf]{locatello2020object}
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran,
  Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf.
\newblock Object-centric learning with slot attention.
\newblock \emph{Advances in neural information processing systems}, 2020.

\bibitem[Luo et~al.(2024)Luo, Zhang, Xu, Yang, Fang, and Li]{luoend}
Lirui Luo, Guoxi Zhang, Hongming Xu, Yaodong Yang, Cong Fang, and Qing Li.
\newblock End-to-end neuro-symbolic reinforcement learning with textual
  explanations.
\newblock In \emph{Forty-first International Conference on Machine Learning},
  2024.

\bibitem[Machado et~al.(2018)Machado, Bellemare, Talvitie, Veness, Hausknecht,
  and Bowling]{MachadoBTVHB18}
Marlos~C. Machado, Marc~G. Bellemare, Erik Talvitie, Joel Veness, Matthew~J.
  Hausknecht, and Michael Bowling.
\newblock Revisiting the arcade learning environment: Evaluation protocols and
  open problems for general agents (extended abstract).
\newblock In \emph{Proceedings of the Twenty-Seventh International Joint
  Conference on Artificial Intelligence, {IJCAI}}, 2018.

\bibitem[Marconato et~al.(2022)Marconato, Passerini, and Teso]{MarconatoPT22}
Emanuele Marconato, Andrea Passerini, and Stefano Teso.
\newblock Glancenets: Interpretable, leak-proof concept-based models.
\newblock In \emph{Advances in Neural Information Processing (NeurIPS)}, 2022.

\bibitem[Marconato et~al.(2023)Marconato, Teso, and Passerini]{MarconatoTP23}
Emanuele Marconato, Stefano Teso, and Andrea Passerini.
\newblock Neuro-symbolic reasoning shortcuts: Mitigation strategies and their
  limitations.
\newblock In \emph{International Workshop on Neural-Symbolic Learning and
  Reasoning}, 2023.

\bibitem[Marton et~al.(2024)Marton, Grams, Vogt, L{\"u}dtke, Bartelt, and
  Stuckenschmidt]{marton2024sympol}
Sascha Marton, Tim Grams, Florian Vogt, Stefan L{\"u}dtke, Christian Bartelt,
  and Heiner Stuckenschmidt.
\newblock Sympol: Symbolic tree-based on-policy reinforcement learning.
\newblock \emph{arXiv}, 2024.

\bibitem[Mesnard et~al.(2021)Mesnard, Weber, Viola, Thakoor, Saade,
  Harutyunyan, Dabney, Stepleton, Heess, Guez, Moulines, Hutter, Buesing, and
  Munos]{Mesnard2021credit}
Thomas Mesnard, Theophane Weber, Fabio Viola, Shantanu Thakoor, Alaa Saade,
  Anna Harutyunyan, Will Dabney, Thomas~S. Stepleton, Nicolas Heess, Arthur
  Guez, Eric Moulines, Marcus Hutter, Lars Buesing, and R{\'{e}}mi Munos.
\newblock Counterfactual credit assignment in model-free reinforcement
  learning.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning {(ICML)}}, 2021.

\bibitem[Milani et~al.(2023)Milani, Topin, Veloso, and
  Fang]{Milani2023ExplainableRL}
Stephanie Milani, Nicholay Topin, Manuela Veloso, and Fei Fang.
\newblock Explainable reinforcement learning: A survey and comparative review.
\newblock \emph{ACM Computing Surveys}, 2023.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{Mnih2013PlayingAW}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin~A. Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{ArXiv}, 2013.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{Mnih2015dqn}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A. Rusu, Joel Veness,
  Marc~G. Bellemare, Alex Graves, Martin~A. Riedmiller, Andreas Fidjeland,
  Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis
  Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and
  Demis Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 2015.

\bibitem[Nahian et~al.(2021)Nahian, Frazier, Harrison, and
  Riedl]{Nahian2021TrainingVR}
Md~Sultan~Al Nahian, Spencer Frazier, Brent Harrison, and Mark~O. Riedl.
\newblock Training value-aligned reinforcement learning agents using a
  normative prior.
\newblock \emph{ArXiv}, 2021.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{Ng1999PolicyIU}
A.~Ng, Daishi Harada, and Stuart~J. Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{International Conference on Machine Learning}, 1999.

\bibitem[Ngo(2022)]{Ngo2022TheAP}
Richard Ngo.
\newblock The alignment problem from a deep learning perspective.
\newblock \emph{ArXiv}, 2022.

\bibitem[Qing et~al.(2022)Qing, Liu, Song, and Song]{qing2022survey}
Yunpeng Qing, Shunyu Liu, Jie Song, and Mingli Song.
\newblock A survey on explainable reinforcement learning: Concepts, algorithms,
  challenges.
\newblock \emph{ArXiv}, 2022.

\bibitem[Raffin et~al.(2021)Raffin, Hill, Gleave, Kanervisto, Ernestus, and
  Dormann]{stable-baselines3}
Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian
  Ernestus, and Noah Dormann.
\newblock Stable-baselines3: Reliable reinforcement learning implementations.
\newblock \emph{Journal of Machine Learning Research}, 2021.

\bibitem[Raposo et~al.(2021)Raposo, Ritter, Santoro, Wayne, Weber, Botvinick,
  Hasselt, and Song]{Raposo2021SyntheticRF}
David Raposo, Samuel Ritter, Adam Santoro, Greg Wayne, Th{\'e}ophane Weber,
  Matthew~M. Botvinick, H.~V. Hasselt, and Francis Song.
\newblock Synthetic returns for long-term credit assignment.
\newblock \emph{ArXiv}, 2021.

\bibitem[Redmon et~al.(2016)Redmon, Divvala, Girshick, and
  Farhadi]{RedmonDGF16YOLO}
Joseph Redmon, Santosh~Kumar Divvala, Ross~B. Girshick, and Ali Farhadi.
\newblock You only look once: Unified, real-time object detection.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition,
  {CVPR} 2016}, 2016.

\bibitem[Roy et~al.(2022)Roy, Kim, and Rabinowitz]{RoyKR22}
Nicholas~A. Roy, Junkyung Kim, and Neil~C. Rabinowitz.
\newblock Explainability via causal self-talk.
\newblock \emph{Advances on Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem[Saeed and Omlin(2023)]{SaeedO23}
Waddah Saeed and Christian~W. Omlin.
\newblock Explainable {AI} {(XAI):} {A} systematic meta-survey of current
  challenges and future opportunities.
\newblock \emph{Knowledge-Based Systems}, 2023.

\bibitem[Sawada and Nakamura(2022)]{unsupervised_sawada}
Yoshihide Sawada and Keigo Nakamura.
\newblock Concept bottleneck model with additional unsupervised concepts.
\newblock \emph{{IEEE} Access}, 2022.

\bibitem[Schaul et~al.(2016)Schaul, Quan, Antonoglou, and
  Silver]{Schaul2015prioritize}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock In Yoshua Bengio and Yann LeCun, editors, \emph{4th International
  Conference on Learning Representations, {ICLR}}, 2016.

\bibitem[Schramowski et~al.(2020)Schramowski, Stammer, Teso, Brugger, Herbert,
  Shao, Luigs, Mahlein, and Kersting]{SchramowskiSTBH20}
Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger, Franziska
  Herbert, Xiaoting Shao, Hans{-}Georg Luigs, Anne{-}Katrin Mahlein, and
  Kristian Kersting.
\newblock Making deep neural networks right for the right scientific reasons by
  interacting with their explanations.
\newblock \emph{Nature Machine Intelligence}, 2020.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{Schulman2017ProximalPO}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{ArXiv}, 2017.

\bibitem[Sha et~al.(2024)Sha, Shindo, Delfosse, Kersting, and
  Dhami]{sha2024expil}
Jingyuan Sha, Hikaru Shindo, Quentin Delfosse, Kristian Kersting, and
  Devendra~Singh Dhami.
\newblock Expil: Explanatory predicate invention for learning in games.
\newblock \emph{arXiv preprint}, 2024.

\bibitem[Shen et~al.(2024)Shen, Zhu, Sun, Gao, and Li]{shen2024beyond}
Zichao Shen, Tianchen Zhu, Qingyun Sun, Shiqi Gao, and Jianxin Li.
\newblock Beyond human preferences: Exploring reinforcement learning trajectory
  evaluation and improvement through llms.
\newblock \emph{arXiv}, 2024.

\bibitem[Shindo et~al.(2024)Shindo, Delfosse, Dhami, and
  Kersting]{shindo2024blendrl}
Hikaru Shindo, Quentin Delfosse, Devendra~Singh Dhami, and Kristian Kersting.
\newblock Blendrl: A framework for merging symbolic and neural policy learning.
\newblock \emph{arXiv}, 2024.

\bibitem[Srinivas et~al.(2020)Srinivas, Laskin, and Abbeel]{Srinivas2020CURLCU}
A.~Srinivas, Michael Laskin, and P.~Abbeel.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock \emph{ArXiv}, 2020.

\bibitem[Stammer et~al.(2021)Stammer, Schramowski, and Kersting]{rightconcepts}
Wolfgang Stammer, Patrick Schramowski, and Kristian Kersting.
\newblock Right for the right concept: Revising neuro-symbolic concepts by
  interacting with their explanations.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR}}, 2021.

\bibitem[Stammer et~al.(2022)Stammer, Memmel, Schramowski, and
  Kersting]{StammerMSK22}
Wolfgang Stammer, Marius Memmel, Patrick Schramowski, and Kristian Kersting.
\newblock Interactive disentanglement: Learning concepts by interacting with
  their prototype representations.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition,
  (CVPR)}, 2022.

\bibitem[Stammer et~al.(2024)Stammer, W{\"u}st, Steinmann, and
  Kersting]{stammer2024neural}
Wolfgang Stammer, Antonia W{\"u}st, David Steinmann, and Kristian Kersting.
\newblock Neural concept binder.
\newblock \emph{Advances in Neural Information Processing (NeurIPS)}, 2024.

\bibitem[Steinmann et~al.(2023)Steinmann, Stammer, Friedrich, and
  Kersting]{Steinmann2023LearningTI}
David Steinmann, Wolfgang Stammer, Felix Friedrich, and Kristian Kersting.
\newblock Learning to intervene on concept bottlenecks.
\newblock \emph{ArXiv}, 2023.

\bibitem[Teso et~al.(2023)Teso, Alkan, Stammer, and Daly]{TesoASD23}
Stefano Teso, {\"{O}}znur Alkan, Wolfgang Stammer, and Elizabeth Daly.
\newblock Leveraging explanations in interactive machine learning: An overview.
\newblock \emph{Frontiers in Artificial Intelligence}, 2023.

\bibitem[Touzet(1997)]{Touzet1997NeuralRL}
Claude~F. Touzet.
\newblock Neural reinforcement learning for behaviour synthesis.
\newblock \emph{Robotics Auton. Syst.}, 1997.

\bibitem[Trivedi et~al.(2021)Trivedi, Zhang, Sun, and Lim]{trivedi2021learning}
Dweep Trivedi, Jesse Zhang, Shao-Hua Sun, and Joseph~J Lim.
\newblock Learning to synthesize programs as interpretable and generalizable
  policies.
\newblock \emph{Advances in neural information processing systems}, 2021.

\bibitem[van Hasselt et~al.(2016)van Hasselt, Guez, and
  Silver]{vanHasseltGS16ddqn}
Hado van Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{Proceedings of the Thirtieth {AAAI} Conference on Artificial
  Intelligence, February 12-17, 2016, Phoenix, Arizona, {USA}}, 2016.

\bibitem[Verma et~al.(2018)Verma, Murali, Singh, Kohli, and
  Chaudhuri]{verma2018programmatically}
Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat
  Chaudhuri.
\newblock Programmatically interpretable reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2018.

\bibitem[Vouros(2022)]{vouros2022xrl}
George~A. Vouros.
\newblock Explainable deep reinforcement learning: State of the art and
  challenges.
\newblock \emph{ACM Computing Surveys}, 2022.

\bibitem[Weitkamp et~al.(2018)Weitkamp, van~der Pol, and
  Akata]{Weitkamp2018VisualRI}
Laurens Weitkamp, Elise van~der Pol, and Zeynep Akata.
\newblock Visual rationalizations in deep reinforcement learning for atari
  games.
\newblock In \emph{BNCAI}, 2018.

\bibitem[Wu(2024)]{wu2024reward}
Xiefeng Wu.
\newblock From reward shaping to q-shaping: Achieving unbiased learning with
  llm-guided knowledge.
\newblock \emph{arXiv}, 2024.

\bibitem[Wu et~al.(2024)Wu, Fan, Liang, Azaria, Li, and Mitchell]{Wu2023ReadAR}
Yue Wu, Yewen Fan, Paul~Pu Liang, Amos Azaria, Yuanzhi Li, and Tom~M Mitchell.
\newblock Read and reap the rewards: Learning to play atari with the help of
  instruction manuals.
\newblock \emph{Advances in Neural Information Processing Systems}, 2024.

\bibitem[W{\"u}st et~al.(2024)W{\"u}st, Stammer, Delfosse, Dhami, and
  Kersting]{wustpix2code}
Antonia W{\"u}st, Wolfgang Stammer, Quentin Delfosse, Devendra~Singh Dhami, and
  Kristian Kersting.
\newblock Pix2code: Learning to compose neural visual concepts as programs.
\newblock In \emph{The 40th Conference on Uncertainty in Artificial
  Intelligence}, 2024.

\bibitem[Zabounidis et~al.(2023)Zabounidis, Campbell, Stepputtis, Hughes, and
  Sycara]{Zabounidis2023Concept}
Renos Zabounidis, Joseph Campbell, Simon Stepputtis, Dana Hughes, and Katia~P.
  Sycara.
\newblock Concept learning for interpretable multi-agent reinforcement
  learning.
\newblock \emph{ArXiv}, 2023.

\bibitem[Zhang et~al.(2021)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{Zhang2021UnderstandingDL}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning (still) requires rethinking
  generalization.
\newblock \emph{Communications of the ACM}, 2021.

\bibitem[Zhou et~al.(2019)Zhou, Bai, Gao, and Han]{Zhou2019VisionBasedRN}
Xiaomao Zhou, Tao Bai, Yanbin Gao, and Yuntao Han.
\newblock Vision-based robot navigation through combining unsupervised learning
  and hierarchical reinforcement learning.
\newblock \emph{Sensors (Basel, Switzerland)}, 2019.

\bibitem[Çağlar Aytekin(2022)]{Aytekin2022NeuralNA}
Çağlar Aytekin.
\newblock Neural networks are decision trees.
\newblock \emph{ArXiv}, 2022.

\end{thebibliography}
