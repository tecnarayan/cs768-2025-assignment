\begin{thebibliography}{82}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bergstra \& Bengio(2012)Bergstra and Bengio]{bergstra2012random}
Bergstra, J. and Bengio, Y.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 281--305, 2012.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra2011algorithms}
Bergstra, J.~S., Bardenet, R., Bengio, Y., and K{\'e}gl, B.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2546--2554, 2011.

\bibitem[Bickel et~al.(2007)Bickel, Br{\"u}ckner, and
  Scheffer]{bickel2007discriminative}
Bickel, S., Br{\"u}ckner, M., and Scheffer, T.
\newblock Discriminative learning for differing training and test
  distributions.
\newblock In \emph{Proceedings of the 24th international conference on Machine
  learning}, pp.\  81--88, 2007.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1613--1622. PMLR, 2015.

\bibitem[Breiman(2001)]{breiman2001random}
Breiman, L.
\newblock Random forests.
\newblock \emph{Machine learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Brochu et~al.(2010)Brochu, Cora, and De~Freitas]{brochu2010tutorial}
Brochu, E., Cora, V.~M., and De~Freitas, N.
\newblock A tutorial on bayesian optimization of expensive cost functions, with
  application to active user modeling and hierarchical reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1012.2599}, 2010.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{chen2016xgboost}
Chen, T. and Guestrin, C.
\newblock Xgboost: A scalable tree boosting system.
\newblock In \emph{Proceedings of the 22nd acm sigkdd international conference
  on knowledge discovery and data mining}, pp.\  785--794, 2016.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{chen2014stochastic}
Chen, T., Fox, E., and Guestrin, C.
\newblock Stochastic gradient hamiltonian monte carlo.
\newblock In \emph{International conference on machine learning}, pp.\
  1683--1691, 2014.

\bibitem[Cheng et~al.(2004)Cheng, Chu, et~al.]{cheng2004semiparametric}
Cheng, K.~F., Chu, C.-K., et~al.
\newblock Semiparametric density estimation under a two-sample density ratio
  model.
\newblock \emph{Bernoulli}, 10\penalty0 (4):\penalty0 583--604, 2004.

\bibitem[Chrabaszcz et~al.(2017)Chrabaszcz, Loshchilov, and
  Hutter]{chrabaszcz2017downsampled}
Chrabaszcz, P., Loshchilov, I., and Hutter, F.
\newblock A downsampled variant of imagenet as an alternative to the cifar
  datasets.
\newblock \emph{arXiv preprint arXiv:1707.08819}, 2017.

\bibitem[Clevert et~al.(2015)Clevert, Unterthiner, and
  Hochreiter]{clevert2015fast}
Clevert, D.-A., Unterthiner, T., and Hochreiter, S.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock \emph{arXiv preprint arXiv:1511.07289}, 2015.

\bibitem[Comaniciu \& Meer(2002)Comaniciu and Meer]{comaniciu2002mean}
Comaniciu, D. and Meer, P.
\newblock Mean shift: A robust approach toward feature space analysis.
\newblock \emph{IEEE Transactions on pattern analysis and machine
  intelligence}, 24\penalty0 (5):\penalty0 603--619, 2002.

\bibitem[Dong \& Yang(2020)Dong and Yang]{dong2020bench}
Dong, X. and Yang, Y.
\newblock Nas-bench-102: Extending the scope of reproducible neural
  architecture search.
\newblock \emph{arXiv preprint arXiv:2001.00326}, 2020.

\bibitem[Falkner et~al.(2018)Falkner, Klein, and Hutter]{falkner2018bohb}
Falkner, S., Klein, A., and Hutter, F.
\newblock Bohb: Robust and efficient hyperparameter optimization at scale.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1437--1446, 2018.

\bibitem[Frazier(2018)]{frazier2018tutorial}
Frazier, P.~I.
\newblock A tutorial on bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1807.02811}, 2018.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pp.\
  1050--1059. PMLR, 2016.

\bibitem[Garrido-Merch{\'a}n \& Hern{\'a}ndez-Lobato(2020)Garrido-Merch{\'a}n
  and Hern{\'a}ndez-Lobato]{garrido2020dealing}
Garrido-Merch{\'a}n, E.~C. and Hern{\'a}ndez-Lobato, D.
\newblock Dealing with categorical and integer-valued variables in bayesian
  optimization with gaussian processes.
\newblock \emph{Neurocomputing}, 380:\penalty0 20--35, 2020.

\bibitem[Gneiting \& Raftery(2007)Gneiting and Raftery]{gneiting2007strictly}
Gneiting, T. and Raftery, A.~E.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock \emph{Journal of the American statistical Association}, 102\penalty0
  (477):\penalty0 359--378, 2007.

\bibitem[G{\'o}mez-Bombarelli et~al.(2018)G{\'o}mez-Bombarelli, Wei, Duvenaud,
  Hern{\'a}ndez-Lobato, S{\'a}nchez-Lengeling, Sheberla, Aguilera-Iparraguirre,
  Hirzel, Adams, and Aspuru-Guzik]{gomez2018automatic}
G{\'o}mez-Bombarelli, R., Wei, J.~N., Duvenaud, D., Hern{\'a}ndez-Lobato,
  J.~M., S{\'a}nchez-Lengeling, B., Sheberla, D., Aguilera-Iparraguirre, J.,
  Hirzel, T.~D., Adams, R.~P., and Aspuru-Guzik, A.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS central science}, 4\penalty0 (2):\penalty0 268--276, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock \emph{Advances in neural information processing systems},
  27:\penalty0 2672--2680, 2014.

\bibitem[Gretton et~al.(2009)Gretton, Smola, Huang, Schmittfull, Borgwardt, and
  Sch{\"o}lkopf]{gretton2009covariate}
Gretton, A., Smola, A., Huang, J., Schmittfull, M., Borgwardt, K., and
  Sch{\"o}lkopf, B.
\newblock Covariate shift by kernel mean matching.
\newblock \emph{Dataset shift in machine learning}, 3\penalty0 (4):\penalty0 5,
  2009.

\bibitem[Gutmann \& Hyv{\"a}rinen(2012)Gutmann and
  Hyv{\"a}rinen]{gutmann2012noise}
Gutmann, M.~U. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation of unnormalized statistical models, with
  applications to natural image statistics.
\newblock \emph{The journal of machine learning research}, 13\penalty0
  (1):\penalty0 307--361, 2012.

\bibitem[Hennig \& Schuler(2012)Hennig and Schuler]{hennig2012entropy}
Hennig, P. and Schuler, C.~J.
\newblock Entropy search for information-efficient global optimization.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 1809--1837, 2012.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2016)Hern{\'a}ndez-Lobato,
  Hernandez-Lobato, Shah, and Adams]{hernandez2016predictive}
Hern{\'a}ndez-Lobato, D., Hernandez-Lobato, J., Shah, A., and Adams, R.
\newblock Predictive entropy search for multi-objective bayesian optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1492--1501, 2016.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2014)Hern{\'a}ndez-Lobato, Hoffman, and
  Ghahramani]{hernandez2014predictive}
Hern{\'a}ndez-Lobato, J.~M., Hoffman, M.~W., and Ghahramani, Z.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock \emph{Advances in neural information processing systems},
  27:\penalty0 918--926, 2014.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, White,
  et~al.]{hornik1989multilayer}
Hornik, K., Stinchcombe, M., White, H., et~al.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural networks}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and
  Leyton-Brown]{hutter2011sequential}
Hutter, F., Hoos, H.~H., and Leyton-Brown, K.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{International conference on learning and intelligent
  optimization}, pp.\  507--523. Springer, 2011.

\bibitem[Jain \& Morari(2020)Jain and Morari]{jain2020computing}
Jain, A. and Morari, M.
\newblock Computing the racing line using bayesian optimization.
\newblock In \emph{2020 59th IEEE Conference on Decision and Control (CDC)},
  pp.\  6192--6197. IEEE, 2020.

\bibitem[Jenatton et~al.(2017)Jenatton, Archambeau, Gonz{\'a}lez, and
  Seeger]{jenatton2017bayesian}
Jenatton, R., Archambeau, C., Gonz{\'a}lez, J., and Seeger, M.
\newblock Bayesian optimization with tree-structured dependencies.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1655--1664, 2017.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{jones1998efficient}
Jones, D.~R., Schonlau, M., and Welch, W.~J.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global optimization}, 13\penalty0 (4):\penalty0
  455--492, 1998.

\bibitem[Kanamori et~al.(2009)Kanamori, Hido, and Sugiyama]{kanamori2009least}
Kanamori, T., Hido, S., and Sugiyama, M.
\newblock A least-squares approach to direct importance estimation.
\newblock \emph{The Journal of Machine Learning Research}, 10:\penalty0
  1391--1445, 2009.

\bibitem[Kanamori et~al.(2010)Kanamori, Suzuki, and
  Sugiyama]{kanamori2010theoretical}
Kanamori, T., Suzuki, T., and Sugiyama, M.
\newblock Theoretical analysis of density ratio estimation.
\newblock \emph{IEICE transactions on fundamentals of electronics,
  communications and computer sciences}, 93\penalty0 (4):\penalty0 787--798,
  2010.

\bibitem[Kandasamy et~al.(2017)Kandasamy, Dasarathy, Schneider, and
  P{\'o}czos]{kandasamy2017multi}
Kandasamy, K., Dasarathy, G., Schneider, J., and P{\'o}czos, B.
\newblock Multi-fidelity bayesian optimisation with continuous approximations.
\newblock \emph{arXiv preprint arXiv:1703.06240}, 2017.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Klein \& Hutter(2019)Klein and Hutter]{klein2019tabular}
Klein, A. and Hutter, F.
\newblock Tabular benchmarks for joint architecture and hyperparameter
  optimization.
\newblock \emph{arXiv preprint arXiv:1905.04970}, 2019.

\bibitem[Kleinegesse \& Gutmann(2019)Kleinegesse and
  Gutmann]{kleinegesse2019efficient}
Kleinegesse, S. and Gutmann, M.~U.
\newblock Efficient bayesian experimental design for implicit models.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pp.\  476--485. PMLR, 2019.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kushner(1964)]{kushner1964new}
Kushner, H.~J.
\newblock A new method of locating the maximum point of an arbitrary multipeak
  curve in the presence of noise.
\newblock 1964.

\bibitem[Lakshminarayanan et~al.(2016)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2016simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock \emph{arXiv preprint arXiv:1612.01474}, 2016.

\bibitem[LeCun et~al.(2012)LeCun, Bottou, Orr, and
  M{\"u}ller]{lecun2012efficient}
LeCun, Y.~A., Bottou, L., Orr, G.~B., and M{\"u}ller, K.-R.
\newblock Efficient backprop.
\newblock In \emph{Neural networks: Tricks of the trade}, pp.\  9--48.
  Springer, 2012.

\bibitem[Liniger et~al.(2015)Liniger, Domahidi, and
  Morari]{liniger2015optimization}
Liniger, A., Domahidi, A., and Morari, M.
\newblock Optimization-based autonomous racing of 1: 43 scale rc cars.
\newblock \emph{Optimal Control Applications and Methods}, 36\penalty0
  (5):\penalty0 628--647, 2015.

\bibitem[Lipp \& Boyd(2014)Lipp and Boyd]{lipp2014minimum}
Lipp, T. and Boyd, S.
\newblock Minimum-time speed optimisation over a fixed path.
\newblock \emph{International Journal of Control}, 87\penalty0 (6):\penalty0
  1297--1311, 2014.

\bibitem[Liu \& Nocedal(1989)Liu and Nocedal]{liu1989limited}
Liu, D.~C. and Nocedal, J.
\newblock On the limited memory bfgs method for large scale optimization.
\newblock \emph{Mathematical programming}, 45\penalty0 (1-3):\penalty0
  503--528, 1989.

\bibitem[Menon \& Ong(2016)Menon and Ong]{menon2016linking}
Menon, A. and Ong, C.~S.
\newblock Linking losses for density ratio and class-probability estimation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  304--313, 2016.

\bibitem[Mockus et~al.(1978)Mockus, Tiesis, and
  Zilinskas]{mockus1978application}
Mockus, J., Tiesis, V., and Zilinskas, A.
\newblock The application of bayesian methods for seeking the extremum.
\newblock \emph{Towards global optimization}, 2\penalty0 (117-129):\penalty0 2,
  1978.

\bibitem[Moss et~al.(2020)Moss, Beck, Gonz{\'a}lez, Leslie, and
  Rayson]{moss2020boss}
Moss, H.~B., Beck, D., Gonz{\'a}lez, J., Leslie, D.~S., and Rayson, P.
\newblock Boss: Bayesian optimization over string spaces.
\newblock \emph{arXiv preprint arXiv:2010.00979}, 2020.

\bibitem[Neal(2003)]{neal2003slice}
Neal, R.~M.
\newblock Slice sampling.
\newblock \emph{Annals of statistics}, pp.\  705--741, 2003.

\bibitem[Niculescu-Mizil \& Caruana(2005)Niculescu-Mizil and
  Caruana]{niculescu2005predicting}
Niculescu-Mizil, A. and Caruana, R.
\newblock Predicting good probabilities with supervised learning.
\newblock In \emph{Proceedings of the 22nd international conference on Machine
  learning}, pp.\  625--632, 2005.

\bibitem[Nowozin et~al.(2016)Nowozin, Cseke, and Tomioka]{nowozin2016f}
Nowozin, S., Cseke, B., and Tomioka, R.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  271--279, 2016.

\bibitem[Park \& Marron(1990)Park and Marron]{park1990comparison}
Park, B.~U. and Marron, J.~S.
\newblock Comparison of data-driven bandwidth selectors.
\newblock \emph{Journal of the American Statistical Association}, 85\penalty0
  (409):\penalty0 66--72, 1990.

\bibitem[Perrone et~al.(2018)Perrone, Jenatton, Seeger, and
  Archambeau]{perrone2018scalable}
Perrone, V., Jenatton, R., Seeger, M.~W., and Archambeau, C.
\newblock Scalable hyperparameter transfer learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6845--6855, 2018.

\bibitem[Platt et~al.(1999)]{platt1999probabilistic}
Platt, J. et~al.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock \emph{Advances in large margin classifiers}, 10\penalty0
  (3):\penalty0 61--74, 1999.

\bibitem[Qin(1998)]{qin1998inferences}
Qin, J.
\newblock Inferences for case-control and semiparametric two-sample density
  ratio models.
\newblock \emph{Biometrika}, 85\penalty0 (3):\penalty0 619--630, 1998.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2019regularized}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock In \emph{Proceedings of the aaai conference on artificial
  intelligence}, volume~33, pp.\  4780--4789, 2019.

\bibitem[Rosolia \& Borrelli(2019)Rosolia and Borrelli]{rosolia2019learning}
Rosolia, U. and Borrelli, F.
\newblock Learning how to autonomously race a car: a predictive control
  approach.
\newblock \emph{IEEE Transactions on Control Systems Technology}, 28\penalty0
  (6):\penalty0 2713--2719, 2019.

\bibitem[Saffari et~al.(2009)Saffari, Leistner, Santner, Godec, and
  Bischof]{saffari2009line}
Saffari, A., Leistner, C., Santner, J., Godec, M., and Bischof, H.
\newblock On-line random forests.
\newblock In \emph{2009 ieee 12th international conference on computer vision
  workshops, iccv workshops}, pp.\  1393--1400. IEEE, 2009.

\bibitem[Scott et~al.(2011)Scott, Frazier, and Powell]{scott2011correlated}
Scott, W., Frazier, P., and Powell, W.
\newblock The correlated knowledge gradient for simulation optimization of
  continuous parameters using gaussian process regression.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (3):\penalty0
  996--1026, 2011.

\bibitem[Shahriari et~al.(2015)Shahriari, Swersky, Wang, Adams, and
  De~Freitas]{shahriari2015taking}
Shahriari, B., Swersky, K., Wang, Z., Adams, R.~P., and De~Freitas, N.
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock \emph{Proceedings of the IEEE}, 104\penalty0 (1):\penalty0 148--175,
  2015.

\bibitem[Sheather \& Jones(1991)Sheather and Jones]{sheather1991reliable}
Sheather, S.~J. and Jones, M.~C.
\newblock A reliable data-based bandwidth selection method for kernel density
  estimation.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 53\penalty0 (3):\penalty0 683--690, 1991.

\bibitem[Silverman(1986)]{silverman1986density}
Silverman, B.~W.
\newblock \emph{Density estimation for statistics and data analysis},
  volume~26.
\newblock CRC press, 1986.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock \emph{Advances in neural information processing systems},
  25:\penalty0 2951--2959, 2012.

\bibitem[Snoek et~al.(2014)Snoek, Swersky, Zemel, and Adams]{snoek2014input}
Snoek, J., Swersky, K., Zemel, R., and Adams, R.
\newblock Input warping for bayesian optimization of non-stationary functions.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1674--1682, 2014.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{snoek2015scalable}
Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N.,
  Patwary, M., Prabhat, M., and Adams, R.
\newblock Scalable bayesian optimization using deep neural networks.
\newblock In \emph{International conference on machine learning}, pp.\
  2171--2180, 2015.

\bibitem[Springenberg et~al.(2016)Springenberg, Klein, Falkner, and
  Hutter]{springenberg2016bayesian}
Springenberg, J.~T., Klein, A., Falkner, S., and Hutter, F.
\newblock Bayesian optimization with robust bayesian neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  4134--4142, 2016.

\bibitem[Srinivas et~al.(2009)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Srinivas, N., Krause, A., Kakade, S.~M., and Seeger, M.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock \emph{arXiv preprint arXiv:0912.3995}, 2009.

\bibitem[Storn \& Price(1997)Storn and Price]{storn-jgo97}
Storn, R. and Price, K.
\newblock Differential evolution -- a simple and efficient heuristic for global
  optimization over continuous spaces.
\newblock \emph{Journal of Global Optimization}, 1997.

\bibitem[Sugiyama et~al.(2008)Sugiyama, Nakajima, Kashima, Buenau, and
  Kawanabe]{sugiyama2008direct}
Sugiyama, M., Nakajima, S., Kashima, H., Buenau, P.~V., and Kawanabe, M.
\newblock Direct importance estimation with model selection and its application
  to covariate shift adaptation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1433--1440, 2008.

\bibitem[Sugiyama et~al.(2012)Sugiyama, Suzuki, and
  Kanamori]{sugiyama2012density}
Sugiyama, M., Suzuki, T., and Kanamori, T.
\newblock \emph{Density Ratio Estimation in Machine Learning}.
\newblock Cambridge University Press, 2012.

\bibitem[Swersky et~al.(2013)Swersky, Snoek, and Adams]{swersky2013multi}
Swersky, K., Snoek, J., and Adams, R.~P.
\newblock Multi-task bayesian optimization.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2004--2012, 2013.

\bibitem[Terrell \& Scott(1992)Terrell and Scott]{terrell1992variable}
Terrell, G.~R. and Scott, D.~W.
\newblock Variable kernel density estimation.
\newblock \emph{The Annals of Statistics}, pp.\  1236--1265, 1992.

\bibitem[Thomas et~al.(2020)Thomas, Dutta, Corander, Kaski, Gutmann,
  et~al.]{thomas2020likelihood}
Thomas, O., Dutta, R., Corander, J., Kaski, S., Gutmann, M.~U., et~al.
\newblock Likelihood-free inference by ratio estimation.
\newblock \emph{Bayesian Analysis}, 2020.

\bibitem[Tran et~al.(2017)Tran, Ranganath, and Blei]{tran2017hierarchical}
Tran, D., Ranganath, R., and Blei, D.
\newblock Hierarchical implicit models and likelihood-free variational
  inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5523--5533, 2017.

\bibitem[Vapnik(2013)]{vapnik2013nature}
Vapnik, V.
\newblock \emph{The nature of statistical learning theory}.
\newblock Springer science \& business media, 2013.

\bibitem[Wang \& Jegelka(2017)Wang and Jegelka]{wang2017max}
Wang, Z. and Jegelka, S.
\newblock Max-value entropy search for efficient bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1703.01968}, 2017.

\bibitem[Wang et~al.(2018)Wang, Gehring, Kohli, and Jegelka]{wang2018batched}
Wang, Z., Gehring, C., Kohli, P., and Jegelka, S.
\newblock Batched large-scale bayesian optimization in high-dimensional spaces.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  745--754. PMLR, 2018.

\bibitem[Wenzel et~al.(2020)Wenzel, Snoek, Tran, and
  Jenatton]{wenzel2020hyperparameter}
Wenzel, F., Snoek, J., Tran, D., and Jenatton, R.
\newblock Hyperparameter ensembles for robustness and uncertainty
  quantification.
\newblock \emph{arXiv preprint arXiv:2006.13570}, 2020.

\bibitem[White et~al.(2019)White, Neiswanger, and Savani]{white2019bananas}
White, C., Neiswanger, W., and Savani, Y.
\newblock Bananas: Bayesian optimization with neural architectures for neural
  architecture search.
\newblock \emph{arXiv preprint arXiv:1910.11858}, 2019.

\bibitem[Williams \& Rasmussen(1996)Williams and
  Rasmussen]{williams1996gaussian}
Williams, C.~K. and Rasmussen, C.~E.
\newblock Gaussian processes for regression.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  514--520, 1996.

\bibitem[Wilson et~al.(2018)Wilson, Hutter, and
  Deisenroth]{wilson2018maximizing}
Wilson, J.~T., Hutter, F., and Deisenroth, M.~P.
\newblock Maximizing acquisition functions for bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1805.10196}, 2018.

\bibitem[Yamada et~al.(2011)Yamada, Suzuki, Kanamori, Hachiya, and
  Sugiyama]{yamada2011relative}
Yamada, M., Suzuki, T., Kanamori, T., Hachiya, H., and Sugiyama, M.
\newblock Relative density-ratio estimation for robust distribution comparison.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  594--602, 2011.

\bibitem[Zadrozny \& Elkan(2001)Zadrozny and Elkan]{zadrozny2001obtaining}
Zadrozny, B. and Elkan, C.
\newblock Obtaining calibrated probability estimates from decision trees and
  naive bayesian classifiers.
\newblock In \emph{Icml}, volume~1, pp.\  609--616. Citeseer, 2001.

\bibitem[Zadrozny \& Elkan(2002)Zadrozny and Elkan]{zadrozny2002transforming}
Zadrozny, B. and Elkan, C.
\newblock Transforming classifier scores into accurate multiclass probability
  estimates.
\newblock In \emph{Proceedings of the eighth ACM SIGKDD international
  conference on Knowledge discovery and data mining}, pp.\  694--699, 2002.

\end{thebibliography}
