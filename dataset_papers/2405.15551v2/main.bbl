\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and Arcas]{macmahan2017aFedLearning}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera~y Arcas.
\newblock {Communication-Efficient Learning of Deep Networks from Decentralized Data}.
\newblock In \emph{Proceedings of the 20th International Conference on Artificial Intelligence and Statistics}, Proceedings of Machine Learning Research. PMLR, 2017.

\bibitem[Kairouz et~al.(2021)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji, Bonawitz, Charles, Cormode, Cummings, D'Oliveira, Eichner, Rouayheb, Evans, Gardner, Garrett, Gascón, Ghazi, Gibbons, Gruteser, Harchaoui, He, He, Huo, Hutchinson, Hsu, Jaggi, Javidi, Joshi, Khodak, Konecný, Korolova, Koushanfar, Koyejo, Lepoint, Liu, Mittal, Mohri, Nock, Özgür, Pagh, Qi, Ramage, Raskar, Raykova, Song, Song, Stich, Sun, Suresh, Tramèr, Vepakomma, Wang, Xiong, Xu, Yang, Yu, Yu, and Zhao]{kairouz2021open}
Peter Kairouz, H.~Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun~Nitin Bhagoji, Kallista~A. Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G.~L. D'Oliveira, Hubert Eichner, Salim~El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adrià Gascón, Badih Ghazi, Phillip~B. Gibbons, Marco Gruteser, Zaïd Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konecný, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancrède Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Özgür, Rasmus Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song, Weikang Song, Sebastian~U. Stich, Ziteng Sun, Ananda~Theertha Suresh, Florian Tramèr, Praneeth Vepakomma, Jianyu Wang, Li~Xiong, Zheng Xu, Qiang Yang, Felix~X. Yu, Han Yu, and Sen Zhao.
\newblock Advances and open problems in federated learning.
\newblock \emph{Foundations and Trends in Machine Learning}, 2021.

\bibitem[Loftus et~al.(2022)Loftus, Ruppert, Shickel, Ozrazgat-Baslanti, Balch, Efron, Gilbert R~Upchurch, Rashidi, Tignanelli, Bian, and Bihorac]{loftus2022FLHealthcare}
Tyler~J Loftus, Matthew~M Ruppert, Benjamin Shickel, Tezcan Ozrazgat-Baslanti, Jeremy~A Balch, Philip~A Efron, Jr. Gilbert R~Upchurch, Parisa Rashidi, Christopher Tignanelli, Jiang Bian, and Azra Bihorac.
\newblock Federated learning for preserving data privacy in collaborative healthcare research.
\newblock \emph{Digital Health}, 2022.

\bibitem[Li et~al.(2022)Li, Yu, Cai, He, and Liu]{li2022healthiot}
Li~Li, Xi~Yu, Xuliang Cai, Xin He, and Yanhong Liu.
\newblock Contract theory based incentive mechanism for federated learning in health crowdsensing.
\newblock \emph{IEEE Internet of Things Journal}, 2022.

\bibitem[Dara et~al.(2022)Dara, Kanapala, Babu, Dhamercherala, Vidyarthi, and Agarwal]{dara2022FLiot}
Suresh Dara, Ambedkar Kanapala, A.~Ramesh Babu, Swetha Dhamercherala, Ankit Vidyarthi, and Ruchi Agarwal.
\newblock Scalable federated-learning and internet-of-things enabled architecture for chest computer tomography image classification.
\newblock \emph{Computers and Electrical Engineering}, 2022.

\bibitem[Pinelli et~al.(2023)Pinelli, Tolomei, and Trappolini]{pinelli2023flirt}
Fabio Pinelli, Gabriele Tolomei, and Giovanni Trappolini.
\newblock Flirt: Federated learning for information retrieval.
\newblock In \emph{Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval}, 2023.

\bibitem[OpenAI et~al.(2024)OpenAI, Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, Avila, Babuschkin, Balaji, Balcom, Baltescu, Bao, Bavarian, Belgum, Bello, Berdine, Bernadett-Shapiro, Berner, Bogdonoff, Boiko, Boyd, Brakman, Brockman, Brooks, Brundage, Button, Cai, Campbell, Cann, Carey, Carlson, Carmichael, Chan, Chang, Chantzis, Chen, Chen, Chen, Chen, Chen, Chess, Cho, Chu, Chung, Cummings, Currier, Dai, Decareaux, Degry, Deutsch, Deville, Dhar, Dohan, Dowling, Dunning, Ecoffet, Eleti, Eloundou, Farhi, Fedus, Felix, Fishman, Forte, Fulford, Gao, Georges, Gibson, Goel, Gogineni, Goh, Gontijo-Lopes, Gordon, Grafstein, Gray, Greene, Gross, Gu, Guo, Hallacy, Han, Harris, He, Heaton, Heidecke, Hesse, Hickey, Hickey, Hoeschele, Houghton, Hsu, Hu, Hu, Huizinga, Jain, Jain, Jang, Jiang, Jiang, Jin, Jin, Jomoto, Jonn, Jun, Kaftan, Łukasz Kaiser, Kamali, Kanitscheider, Keskar, Khan, Kilpatrick, Kim, Kim, Kim, Kirchner, Kiros, Knight, Kokotajlo, Łukasz Kondraciuk, Kondrich,
  Konstantinidis, Kosic, Krueger, Kuo, Lampe, Lan, Lee, Leike, Leung, Levy, Li, Lim, Lin, Lin, Litwin, Lopez, Lowe, Lue, Makanju, Malfacini, Manning, Markov, Markovski, Martin, Mayer, Mayne, McGrew, McKinney, McLeavey, McMillan, McNeil, Medina, Mehta, Menick, Metz, Mishchenko, Mishkin, Monaco, Morikawa, Mossing, Mu, Murati, Murk, Mély, Nair, Nakano, Nayak, Neelakantan, Ngo, Noh, Ouyang, O'Keefe, Pachocki, Paino, Palermo, Pantuliano, Parascandolo, Parish, Parparita, Passos, Pavlov, Peng, Perelman, de~Avila Belbute~Peres, Petrov, de~Oliveira~Pinto, Michael, Pokorny, Pokrass, Pong, Powell, Power, Power, Proehl, Puri, Radford, Rae, Ramesh, Raymond, Real, Rimbach, Ross, Rotsted, Roussez, Ryder, Saltarelli, Sanders, Santurkar, Sastry, Schmidt, Schnurr, Schulman, Selsam, Sheppard, Sherbakov, Shieh, Shoker, Shyam, Sidor, Sigler, Simens, Sitkin, Slama, Sohl, Sokolowsky, Song, Staudacher, Such, Summers, Sutskever, Tang, Tezak, Thompson, Tillet, Tootoonchian, Tseng, Tuggle, Turley, Tworek, Uribe, Vallone, Vijayvergiya,
  Voss, Wainwright, Wang, Wang, Wang, Ward, Wei, Weinmann, Welihinda, Welinder, Weng, Weng, Wiethoff, Willner, Winter, Wolrich, Wong, Workman, Wu, Wu, Wu, Xiao, Xu, Yoo, Yu, Yuan, Zaremba, Zellers, Zhang, Zhang, Zhao, Zheng, Zhuang, Zhuk, and Zoph]{openai2024gpt4}
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung~Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón~Posada Fishman, Juston Forte, Isabella Fulford, Leo
  Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang~Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish~Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong~Wook Kim, Christina Kim, Yongjik Kim, Jan~Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak~Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan
  Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott~Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O'Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de~Avila Belbute~Peres, Michael Petrov, Henrique~Ponde de~Oliveira~Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr~H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez,
  Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe~Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine~B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe~Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin~Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ~Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia
  Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv 2303.08774}, 2024.

\bibitem[Anil et~al.(2023)Anil, Dai, Firat, Johnson, Lepikhin, Passos, Shakeri, Taropa, Bailey, Chen, Chu, Clark, Shafey, Huang, Meier-Hellstern, Mishra, Moreira, Omernick, Robinson, Ruder, Tay, Xiao, Xu, Zhang, Abrego, Ahn, Austin, Barham, Botha, Bradbury, Brahma, Brooks, Catasta, Cheng, Cherry, Choquette-Choo, Chowdhery, Crepy, Dave, Dehghani, Dev, Devlin, Díaz, Du, Dyer, Feinberg, Feng, Fienber, Freitag, Garcia, Gehrmann, Gonzalez, Gur-Ari, Hand, Hashemi, Hou, Howland, Hu, Hui, Hurwitz, Isard, Ittycheriah, Jagielski, Jia, Kenealy, Krikun, Kudugunta, Lan, Lee, Lee, Li, Li, Li, Li, Li, Lim, Lin, Liu, Liu, Maggioni, Mahendru, Maynez, Misra, Moussalem, Nado, Nham, Ni, Nystrom, Parrish, Pellat, Polacek, Polozov, Pope, Qiao, Reif, Richter, Riley, Ros, Roy, Saeta, Samuel, Shelby, Slone, Smilkov, So, Sohn, Tokumine, Valter, Vasudevan, Vodrahalli, Wang, Wang, Wang, Wang, Wieting, Wu, Xu, Xu, Xue, Yin, Yu, Zhang, Zheng, Zheng, Zhou, Zhou, Petrov, and Wu]{anil2023palm}
Rohan Anil, Andrew~M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan~H. Clark, Laurent~El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi~Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo~Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher~A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le~Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang
  Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex~Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David~R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce~Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu.
\newblock Palm 2 technical report.
\newblock \emph{arXiv 2305.10403}, 2023.

\bibitem[Lin et~al.(2022)Lin, He, Ze, Wang, Hua, Dupuy, Gupta, Soltanolkotabi, Ren, and Avestimehr]{lin2022fednlp}
Bill~Yuchen Lin, Chaoyang He, Zihang Ze, Hulin Wang, Yufen Hua, Christophe Dupuy, Rahul Gupta, Mahdi Soltanolkotabi, Xiang Ren, and Salman Avestimehr.
\newblock {F}ed{NLP}: Benchmarking federated learning methods for natural language processing tasks.
\newblock In \emph{Findings of the Association for Computational Linguistics: NAACL 2022}. Association for Computational Linguistics, 2022.

\bibitem[Tian et~al.(2022)Tian, Wan, Lyu, Yao, Jin, and Sun]{tian2022fedbert}
Yuanyishu Tian, Yao Wan, Lingjuan Lyu, Dezhong Yao, Hai Jin, and Lichao Sun.
\newblock Fedbert: When federated learning meets pre-training.
\newblock \emph{ACM Transactions on Intelligent Systems and Technology (TIST)}, 2022.

\bibitem[Borzunov et~al.(2024)Borzunov, Ryabinin, Chumachenko, Baranchuk, Dettmers, Belkada, Samygin, and Raffel]{borzunov2024distributed}
Alexander Borzunov, Max Ryabinin, Artem Chumachenko, Dmitry Baranchuk, Tim Dettmers, Younes Belkada, Pavel Samygin, and Colin~A Raffel.
\newblock Distributed inference and fine-tuning of large language models over the internet.
\newblock \emph{Advances in Neural Information Processing Systems}, 2024.

\bibitem[Hu et~al.(2022)Hu, yelong shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2022lora}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Cai et~al.(2023)Cai, Wu, Wang, and Xu]{cai2023fedadapter}
Dongqi Cai, Yaozong Wu, Shangguang Wang, and Mengwei Xu.
\newblock Fedadapter: Efficient federated learning for mobile nlp.
\newblock In \emph{Proceedings of the ACM Turing Award Celebration Conference - China 2023}. Association for Computing Machinery, 2023.

\bibitem[Qiu et~al.(2023)Qiu, Liu, Feng, Xue, Feng, Liu, Zhang, Weller, and Sch{\"o}lkopf]{qiu2023oft}
Zeju Qiu, Weiyang Liu, Haiwen Feng, Yuxuan Xue, Yao Feng, Zhen Liu, Dan Zhang, Adrian Weller, and Bernhard Sch{\"o}lkopf.
\newblock Controlling text-to-image diffusion by orthogonal finetuning.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Liu et~al.(2022)Liu, Tam, Muqeeth, Mohta, Huang, Bansal, and Raffel]{liu2022ia3}
Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin~A Raffel.
\newblock Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Li and Liang(2021)]{li2021prefixtuning}
Xiang~Lisa Li and Percy Liang.
\newblock Prefix-tuning: Optimizing continuous prompts for generation.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}. Association for Computational Linguistics, 2021.

\bibitem[Jacob et~al.(2018)Jacob, Kligys, Chen, Zhu, Tang, Howard, Adam, and Kalenichenko]{jacob2018quant}
Benoit Jacob, Skirmantas Kligys, Bo~Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko.
\newblock Quantization and training of neural networks for efficient integer-arithmetic-only inference.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2018.

\bibitem[Malladi et~al.(2023)Malladi, Gao, Nichani, Damian, Lee, Chen, and Arora]{malladi2023mezo}
Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason~D. Lee, Danqi Chen, and Sanjeev Arora.
\newblock Fine-tuning language models with just forward passes.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Xu et~al.(2024)Xu, Cai, Wu, Li, and Wang]{xu2024fwdllm}
Mengwei Xu, Dongqi Cai, Yaozong Wu, Xiang Li, and Shangguang Wang.
\newblock Fwdllm: Efficient fedllm using forward gradient.
\newblock \emph{arXiv 2308.13894}, 2024.

\bibitem[Feng et~al.(2023)Feng, Pang, Du, Chen, Yan, and Lin]{feng2023baffle}
Haozhe Feng, Tianyu Pang, Chao Du, Wei Chen, Shuicheng Yan, and Min Lin.
\newblock Does federated learning really need backpropagation?
\newblock \emph{arXiv 2301.12195}, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher, Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao, Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa, Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet, Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi, Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu, Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and Scialom]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian~Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit~Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric~Michael Smith, Ranjan Subramanian, Xiaoqing~Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian~Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
  Scialom.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv 2307.09288}, 2023.

\bibitem[Richardson(1955)]{richardson1955finitedifferences}
C.~H. Richardson.
\newblock An introduction to the calculus of finite differences. by c.h. richardson pp. vi, 142. 28s. 1954. (van nostrand, new york; macmillan, london).
\newblock \emph{The Mathematical Gazette}, 39\penalty0 (330), 1955.
\newblock \doi{10.2307/3608616}.

\bibitem[Baydin et~al.(2022)Baydin, Pearlmutter, Syme, Wood, and Torr]{baydin2022gradients}
Atılım~Güneş Baydin, Barak~A. Pearlmutter, Don Syme, Frank Wood, and Philip Torr.
\newblock Gradients without backpropagation.
\newblock \emph{arXiv 2202.08587}, 2022.

\bibitem[Baydin et~al.(2017)Baydin, Pearlmutter, Radul, and Siskind]{baydin2017autodiff}
At\i{}l\i{}m~G\"{u}nes Baydin, Barak~A. Pearlmutter, Alexey~Andreyevich Radul, and Jeffrey~Mark Siskind.
\newblock Automatic differentiation in machine learning: a survey.
\newblock \emph{The Journal of Machine Learning Research}, 2017.

\bibitem[Reddi et~al.(2021)Reddi, Charles, Zaheer, Garrett, Rush, Kone{\v{c}}n{\'y}, Kumar, and McMahan]{reddi2021adaptive}
Sashank~J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Kone{\v{c}}n{\'y}, Sanjiv Kumar, and Hugh~Brendan McMahan.
\newblock Adaptive federated optimization.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Thapa et~al.(2022)Thapa, Arachchige, Camtepe, and Sun]{thapa2022splitfed}
Chandra Thapa, Pathum Chamikara~Mahawaga Arachchige, Seyit Camtepe, and Lichao Sun.
\newblock Splitfed: When federated learning meets split learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 2022.

\bibitem[Zhang et~al.(2024)Zhang, Han, Liu, Zhou, Lu, Li, Gao, and Qiao]{zhang2024llamaadapter}
Renrui Zhang, Jiaming Han, Chris Liu, Aojun Zhou, Pan Lu, Hongsheng Li, Peng Gao, and Yu~Qiao.
\newblock {LL}a{MA}-adapter: Efficient fine-tuning of large language models with zero-initialized attention.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Ben~Zaken et~al.(2022)Ben~Zaken, Goldberg, and Ravfogel]{zaken2022bitfit}
Elad Ben~Zaken, Yoav Goldberg, and Shauli Ravfogel.
\newblock {B}it{F}it: Simple parameter-efficient fine-tuning for transformer-based masked language-models.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}. Association for Computational Linguistics, 2022.

\bibitem[Panchal et~al.(2023{\natexlab{a}})Panchal, Choudhary, Mitra, Mukherjee, Sarkhel, Mitra, and Guan]{panchal2023flash}
Kunjal Panchal, Sunav Choudhary, Subrata Mitra, Koyel Mukherjee, Somdeb Sarkhel, Saayan Mitra, and Hui Guan.
\newblock Flash: concept drift adaptation in federated learning.
\newblock In \emph{International Conference on Machine Learning}, pages 26931--26962. PMLR, 2023{\natexlab{a}}.

\bibitem[Wu et~al.(2022)Wu, Li, Charles, Xiao, Liu, Xu, and Smith]{wu2022motley}
Shanshan Wu, Tian Li, Zachary Charles, Yu~Xiao, Ziyu Liu, Zheng Xu, and Virginia Smith.
\newblock Motley: Benchmarking heterogeneity and personalization in federated learning.
\newblock \emph{arXiv 2206.09262}, 2022.

\bibitem[Zhang et~al.(2015)Zhang, Zhao, and LeCun]{zhang2015agnewsyelpyahoo}
Xiang Zhang, Junbo~Jake Zhao, and Yann LeCun.
\newblock Character-level convolutional networks for text classification.
\newblock In \emph{Neural Information Processing Systems}, 2015.
\newblock Available at \url{https://huggingface.co/datasets/ag_news}, \url{https://huggingface.co/datasets/yelp_polarity}, \url{https://huggingface.co/datasets/yahoo_answers_topics}, Accessed on 15 May, 2024.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and Potts]{socher2013sst2}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning, Andrew Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment treebank.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing}. Association for Computational Linguistics, 2013.
\newblock Available at \url{https://huggingface.co/datasets/stanfordnlp/sst2}, Accessed on 15 May, 2024.

\bibitem[Bowman et~al.(2015)Bowman, Angeli, Potts, and Manning]{bowman2015snli}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
\newblock A large annotated corpus for learning natural language inference.
\newblock In \emph{Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}. Association for Computational Linguistics, 2015.
\newblock Available at \url{https://huggingface.co/datasets/stanfordnlp/snli}, Accessed on 15 May, 2024.

\bibitem[Williams et~al.(2018)Williams, Nangia, and Bowman]{williams2018mnli}
Adina Williams, Nikita Nangia, and Samuel Bowman.
\newblock A broad-coverage challenge corpus for sentence understanding through inference.
\newblock In \emph{Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)}. Association for Computational Linguistics, 2018.
\newblock Available at \url{https://huggingface.co/datasets/SetFit/mnli}, Accessed on 15 May, 2024.

\bibitem[Rajpurkar et~al.(2018)Rajpurkar, Jia, and Liang]{rajpurkar2018squad}
Pranav Rajpurkar, Robin Jia, and Percy Liang.
\newblock Know what you don{'}t know: Unanswerable questions for {SQ}u{AD}.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}. Association for Computational Linguistics, 2018.
\newblock Available at \url{https://huggingface.co/datasets/rajpurkar/squad_v2}, Accessed on 15 May, 2024.

\bibitem[Khashabi et~al.(2018)Khashabi, Chaturvedi, Roth, Upadhyay, and Roth]{khashabi2018multirc}
Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth.
\newblock Looking beyond the surface: A challenge set for reading comprehension over multiple sentences.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)}. Association for Computational Linguistics, 2018.
\newblock Available at \url{https://huggingface.co/datasets/mtc/multirc}, Accessed on 15 May, 2024.

\bibitem[Panchal et~al.(2023{\natexlab{b}})Panchal, Choudhary, Parikh, Zhang, and Guan]{panchal2023flow}
Kunjal Panchal, Sunav Choudhary, Nisarg Parikh, Lijun Zhang, and Hui Guan.
\newblock Flow: Per-instance personalized federated learning.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2022)Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan, Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang, and Zettlemoyer]{zhang2022opt}
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi~Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit~Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer.
\newblock Opt: Open pre-trained transformer language models.
\newblock \emph{arXiv 2205.01068}, 2022.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov]{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: {A} robustly optimized {BERT} pretraining approach.
\newblock \emph{arxiv 1907.11692}, 2019.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv 1810.04805}, 2018.

\bibitem[Sanh et~al.(2019)Sanh, Debut, Chaumond, and Wolf]{sanh2019distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.
\newblock \emph{arXiv 1910.01108}, 2019.

\bibitem[Lan et~al.(2019)Lan, Chen, Goodman, Gimpel, Sharma, and Soricut]{lan2019albert}
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut.
\newblock {ALBERT:} {A} lite {BERT} for self-supervised learning of language representations.
\newblock \emph{arXiv 1909.11942}, 2019.

\bibitem[Beutel et~al.(2020)Beutel, Topal, Mathur, Qiu, Parcollet, and Lane]{beutel2020flower}
Daniel~J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and Nicholas~D Lane.
\newblock Flower: A friendly federated learning research framework.
\newblock \emph{arXiv preprint 2007.14390}, 2020.

\bibitem[aut(2024)]{autogptq}
{AutoGPTQ}, 2024.
\newblock URL \url{https://github.com/AutoGPTQ/AutoGPTQ}.

\bibitem[Burden and Faires(2005)]{burden2005numerical}
Richard~L. Burden and J.~Douglas. Faires.
\newblock \emph{Numerical analysis / Richard L. Burden, J. Douglas Faires.}
\newblock Thomson Brooks/Cole, 8th ed. edition, 2005.
\newblock ISBN 0534392008.

\bibitem[Jord{\'a}n(1965)]{jordan1965calculus}
K{\'a}roly Jord{\'a}n.
\newblock \emph{Calculus of finite differences}.
\newblock American Mathematical Soc., 1965.

\bibitem[Fang et~al.(2022)Fang, Yu, Jiang, Shi, Jones, and Zhou]{fang2022fedzo}
Wenzhi Fang, Ziyi Yu, Yuning Jiang, Yuanming Shi, Colin~N. Jones, and Yong Zhou.
\newblock Communication-efficient stochastic zeroth-order optimization for federated learning.
\newblock \emph{IEEE Transactions on Signal Processing}, 2022.

\bibitem[Ye et~al.(2024)Ye, Wang, Chai, Li, Li, Xu, Du, Wang, and Chen]{ye2024openfedllm}
Rui Ye, Wenhao Wang, Jingyi Chai, Dihan Li, Zexi Li, Yinda Xu, Yaxin Du, Yanfeng Wang, and Siheng Chen.
\newblock Openfedllm: Training large language models on decentralized private data via federated learning.
\newblock \emph{arXiv 2402.06954}, 2024.

\bibitem[Fan et~al.(2023)Fan, Kang, Ma, Chen, Wei, Fan, and Yang]{fan2023fatellm}
Tao Fan, Yan Kang, Guoqiang Ma, Weijing Chen, Wenbin Wei, Lixin Fan, and Qiang Yang.
\newblock Fate-llm: A industrial grade federated learning framework for large language models.
\newblock \emph{arXiv 2310.10049}, 2023.

\bibitem[Lai et~al.(2022)Lai, Dai, Singapuram, Liu, Zhu, Madhyastha, and Chowdhury]{lai2022fedscale}
Fan Lai, Yinwei Dai, Sanjay~S. Singapuram, Jiachen Liu, Xiangfeng Zhu, Harsha~V. Madhyastha, and Mosharaf Chowdhury.
\newblock Fedscale: Benchmarking model and system performance of federated learning at scale.
\newblock \emph{arXiv 2105.11367}, 2022.

\bibitem[Ro et~al.(2022)Ro, Breiner, McConnaughey, Chen, Suresh, Kumar, and Mathews]{ro2022scaling}
Jae Ro, Theresa Breiner, Lara McConnaughey, Mingqing Chen, Ananda Suresh, Shankar Kumar, and Rajiv Mathews.
\newblock Scaling language model size in cross-device federated learning.
\newblock In \emph{Proceedings of the First Workshop on Federated Learning for Natural Language Processing (FL4NLP 2022)}. Association for Computational Linguistics, 2022.

\bibitem[Malaviya et~al.(2023)Malaviya, Shukla, and Lodha]{malaviya2023reducing}
Shubham Malaviya, Manish Shukla, and Sachin Lodha.
\newblock Reducing communication overhead in federated learning for pre-trained language models using parameter-efficient finetuning.
\newblock In \emph{Conference on Lifelong Learning Agents}. PMLR, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Yang, Dai, Wang, Yu, Qu, and Xu]{zhang2023fedpetuning}
Zhuo Zhang, Yuanhang Yang, Yong Dai, Qifan Wang, Yue Yu, Lizhen Qu, and Zenglin Xu.
\newblock {F}ed{PET}uning: When federated learning meets the parameter-efficient tuning methods of pre-trained language models.
\newblock In \emph{Findings of the Association for Computational Linguistics: ACL 2023}. Association for Computational Linguistics, 2023.

\bibitem[Park et~al.(2023)Park, Shin, Chung, and Lee]{park2023fedfwd}
Seonghwan Park, Dahun Shin, Jinseok Chung, and Namhoon Lee.
\newblock Fedfwd: Federated learning without backpropagation.
\newblock \emph{arXiv 2309.01150}, 2023.

\bibitem[Hinton(2022)]{hinton2022forwardforward}
Geoffrey Hinton.
\newblock The forward-forward algorithm: Some preliminary investigations.
\newblock \emph{arXiv 2212.13345}, 2022.

\bibitem[Ding et~al.(2023)Ding, Qin, Yang, Wei, Yang, Su, Hu, Chen, Chan, Chen, et~al.]{ding2023peftsurvey}
Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et~al.
\newblock Parameter-efficient fine-tuning of large-scale pre-trained language models.
\newblock \emph{Nature Machine Intelligence}, 2023.

\bibitem[Han et~al.(2024)Han, Gao, Liu, Zhang, and Zhang]{han2024peftsurvey}
Zeyu Han, Chao Gao, Jinyang Liu, Jeff Zhang, and Sai~Qian Zhang.
\newblock Parameter-efficient fine-tuning for large models: A comprehensive survey.
\newblock \emph{arXiv 2403.14608}, 2024.

\bibitem[Dettmers et~al.(2023)Dettmers, Pagnoni, Holtzman, and Zettlemoyer]{dettmers2023qlora}
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.
\newblock {QL}o{RA}: Efficient finetuning of quantized {LLM}s.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\end{thebibliography}
