\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Brock et~al.(2019)Brock, Donahue, and Simonyan]{biggan}
A.~Brock, J.~Donahue, and K.~Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In \emph{Int. Conf. Learn. Represent.}, 2019.

\bibitem[Chan et~al.(2021)Chan, Monteiro, Kellnhofer, Wu, and Wetzstein]{pigan}
E.~Chan, M.~Monteiro, P.~Kellnhofer, J.~Wu, and G.~Wetzstein.
\newblock pi-{GAN}: Periodic implicit generative adversarial networks for
  3d-aware image synthesis.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Chan et~al.(2022)Chan, Lin, Chan, Nagano, Pan, De~Mello, Gallo,
  Guibas, Tremblay, Khamis, et~al.]{eg3d}
E.~R. Chan, C.~Z. Lin, M.~A. Chan, K.~Nagano, B.~Pan, S.~De~Mello, O.~Gallo,
  L.~Guibas, J.~Tremblay, S.~Khamis, et~al.
\newblock Efficient geometry-aware 3d generative adversarial networks.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2022.

\bibitem[Choi et~al.(2020)Choi, Uh, Yoo, and Ha]{starganv2}
Y.~Choi, Y.~Uh, J.~Yoo, and J.-W. Ha.
\newblock Stargan v2: Diverse image synthesis for multiple domains.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem[Deng et~al.(2022)Deng, Yang, Xiang, and Tong]{gram}
Y.~Deng, J.~Yang, J.~Xiang, and X.~Tong.
\newblock Gram: Generative radiance manifolds for 3d-aware image generation.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2022.

\bibitem[Eigen et~al.(2014)Eigen, Puhrsch, and Fergus]{SIDE}
D.~Eigen, C.~Puhrsch, and R.~Fergus.
\newblock Depth map prediction from a single image using a multi-scale deep
  network.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2014.

\bibitem[Godard et~al.(2017)Godard, Mac~Aodha, and Brostow]{depth1}
C.~Godard, O.~Mac~Aodha, and G.~J. Brostow.
\newblock Unsupervised monocular depth estimation with left-right consistency.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2017.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{gan}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2014.

\bibitem[Gu et~al.(2022)Gu, Liu, Wang, and Theobalt]{stylenerf}
J.~Gu, L.~Liu, P.~Wang, and C.~Theobalt.
\newblock Stylenerf: A style-based 3d-aware generator for high-resolution image
  synthesis.
\newblock In \emph{Int. Conf. Learn. Represent.}, 2022.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{fid}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock {GANs} trained by a two time-scale update rule converge to a local
  nash equilibrium.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2017.

\bibitem[Ho et~al.(2021)Ho, Tran, Phung, and Hoai]{lemul}
L.-N. Ho, A.~T. Tran, Q.~Phung, and M.~Hoai.
\newblock Toward realistic single-view 3d object reconstruction with
  unsupervised learning from multiple images.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Johnson et~al.(2016)Johnson, Alahi, and Fei-Fei]{perceptual}
J.~Johnson, A.~Alahi, and L.~Fei-Fei.
\newblock Perceptual losses for real-time style transfer and super-resolution.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2016.

\bibitem[Karras et~al.(2018)Karras, Aila, Laine, and Lehtinen]{pggan}
T.~Karras, T.~Aila, S.~Laine, and J.~Lehtinen.
\newblock Progressive growing of {GAN}s for improved quality, stability, and
  variation.
\newblock In \emph{Int. Conf. Learn. Represent.}, 2018.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{stylegan}
T.~Karras, S.~Laine, and T.~Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2019.

\bibitem[Karras et~al.(2020)Karras, Laine, Aittala, Hellsten, Lehtinen, and
  Aila]{stylegan2}
T.~Karras, S.~Laine, M.~Aittala, J.~Hellsten, J.~Lehtinen, and T.~Aila.
\newblock Analyzing and improving the image quality of {StyleGAN}.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem[Karras et~al.(2021)Karras, Aittala, Laine, H\"ark\"onen, Hellsten,
  Lehtinen, and Aila]{stylegan3}
T.~Karras, M.~Aittala, S.~Laine, E.~H\"ark\"onen, J.~Hellsten, J.~Lehtinen, and
  T.~Aila.
\newblock Alias-free generative adversarial networks.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2021.

\bibitem[Li et~al.(2018)Li, Xu, Ramamoorthi, Sunkavalli, and
  Chandraker]{lilearning}
Z.~Li, Z.~Xu, R.~Ramamoorthi, K.~Sunkavalli, and M.~Chandraker.
\newblock Learning to reconstruct shape and spatially-varying reflectance from
  a single image.
\newblock \emph{ACM Trans. Graph.}, 2018.

\bibitem[Li et~al.(2020)Li, Shafiei, Ramamoorthi, Sunkavalli, and
  Chandraker]{liinverse}
Z.~Li, M.~Shafiei, R.~Ramamoorthi, K.~Sunkavalli, and M.~Chandraker.
\newblock Inverse rendering for complex indoor scenes: Shape, spatially-varying
  lighting and svbrdf from a single image.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and
  R.~Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2020.

\bibitem[Nagarajan and Kolter(2017)]{gradient}
V.~Nagarajan and J.~Z. Kolter.
\newblock Gradient descent gan optimization is locally stable.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2017.

\bibitem[Nathan~Silberman and Fergus(2012)]{nyu}
P.~K. Nathan~Silberman, Derek~Hoiem and R.~Fergus.
\newblock Indoor segmentation and support inference from rgbd images.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2012.

\bibitem[Nguyen-Phuoc et~al.(2019)Nguyen-Phuoc, Li, Theis, Richardt, and
  Yang]{hologan}
T.~Nguyen-Phuoc, C.~Li, L.~Theis, C.~Richardt, and Y.-L. Yang.
\newblock {HoloGAN}: Unsupervised learning of 3d representations from natural
  images.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2019.

\bibitem[Niemeyer and Geiger(2021)]{giraffe}
M.~Niemeyer and A.~Geiger.
\newblock {GIRAFFE}: Representing scenes as compositional generative neural
  feature fields.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Or-El et~al.(2022)Or-El, Luo, Shan, Shechtman, Park, and
  Kemelmacher-Shlizerman]{stylesdf}
R.~Or-El, X.~Luo, M.~Shan, E.~Shechtman, J.~J. Park, and
  I.~Kemelmacher-Shlizerman.
\newblock Stylesdf: High-resolution 3d-consistent image and geometry
  generation.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2022.

\bibitem[Pan et~al.(2021)Pan, Xu, Loy, Theobalt, and Dai]{shadegan}
X.~Pan, X.~Xu, C.~C. Loy, C.~Theobalt, and B.~Dai.
\newblock A shading-guided generative implicit model for shape-accurate
  3d-aware image synthesis.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2021.

\bibitem[Ranftl et~al.(2020)Ranftl, Lasinger, Hafner, Schindler, and
  Koltun]{midas}
R.~Ranftl, K.~Lasinger, D.~Hafner, K.~Schindler, and V.~Koltun.
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2020.

\bibitem[Ranftl et~al.(2021)Ranftl, Bochkovskiy, and Koltun]{dpt}
R.~Ranftl, A.~Bochkovskiy, and V.~Koltun.
\newblock Vision transformers for dense prediction.
\newblock \emph{ArXiv preprint}, 2021.

\bibitem[Sauer et~al.(2022)Sauer, Schwarz, and Geiger]{stylegan-xl}
A.~Sauer, K.~Schwarz, and A.~Geiger.
\newblock Stylegan-xl: Scaling stylegan to large diverse datasets.
\newblock In \emph{SIGGRAPH}, 2022.

\bibitem[Schwarz et~al.(2020)Schwarz, Liao, Niemeyer, and Geiger]{graf}
K.~Schwarz, Y.~Liao, M.~Niemeyer, and A.~Geiger.
\newblock {GRAF}: Generative radiance fields for 3d-aware image synthesis.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2020.

\bibitem[Tewari et~al.(2022)Tewari, Pan, Fried, Agrawala, Theobalt,
  et~al.]{d3d}
A.~Tewari, X.~Pan, O.~Fried, M.~Agrawala, C.~Theobalt, et~al.
\newblock Disentangled3d: Learning a 3d generative model with disentangled
  geometry and appearance from monocular images.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2022.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Wang, Genova, Srinivasan, Zhou,
  Barron, Martin-Brualla, Snavely, and Funkhouser]{ibrnet}
Q.~Wang, Z.~Wang, K.~Genova, P.~Srinivasan, H.~Zhou, J.~T. Barron,
  R.~Martin-Brualla, N.~Snavely, and T.~Funkhouser.
\newblock Ibrnet: Learning multi-view image-based rendering.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Philion, Fidler, and
  Kautz]{wanglearning}
Z.~Wang, J.~Philion, S.~Fidler, and J.~Kautz.
\newblock Learning indoor inverse rendering with 3d spatially-varying lighting.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021{\natexlab{b}}.

\bibitem[Wu et~al.(2020)Wu, Rupprecht, and Vedaldi]{unsup3d}
S.~Wu, C.~Rupprecht, and A.~Vedaldi.
\newblock Unsupervised learning of probably symmetric deformable 3d objects
  from images in the wild.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem[Xu et~al.(2022)Xu, Peng, Yang, Shen, and Zhou]{volumegan}
Y.~Xu, S.~Peng, C.~Yang, Y.~Shen, and B.~Zhou.
\newblock 3d-aware image synthesis via learning structural and textural
  representations.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2022.

\bibitem[Yu et~al.(2015)Yu, Seff, Zhang, Song, Funkhouser, and Xiao]{lsun}
F.~Yu, A.~Seff, Y.~Zhang, S.~Song, T.~Funkhouser, and J.~Xiao.
\newblock {LSUN}: Construction of a large-scale image dataset using deep
  learning with humans in the loop.
\newblock \emph{arXiv preprint arXiv:1506.03365}, 2015.

\bibitem[Zhou et~al.(2021)Zhou, Xie, Ni, and Tian]{cips3d}
P.~Zhou, L.~Xie, B.~Ni, and Q.~Tian.
\newblock Cips-3d: A 3d-aware generator of gans based on
  conditionally-independent pixel synthesis.
\newblock \emph{arXiv preprint arXiv:2110.09788}, 2021.

\bibitem[Zhu et~al.(2018)Zhu, Zhang, Zhang, Wu, Torralba, Tenenbaum, and
  Freeman]{VON}
J.-Y. Zhu, Z.~Zhang, C.~Zhang, J.~Wu, A.~Torralba, J.~B. Tenenbaum, and W.~T.
  Freeman.
\newblock Visual object networks: image generation with disentangled 3{D}
  representations.
\newblock In \emph{Adv. Neural Inform. Process. Syst.}, 2018.

\end{thebibliography}
