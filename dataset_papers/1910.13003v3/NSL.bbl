\begin{thebibliography}{10}

\bibitem{andrychowicz2016learning}
Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew~W Hoffman, David Pfau,
  Tom Schaul, Brendan Shillingford, and Nando De~Freitas.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In {\em NIPS}, 2016.

\bibitem{antoniou2017data}
Antreas Antoniou, Amos Storkey, and Harrison Edwards.
\newblock Data augmentation generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1711.04340}, 2017.

\bibitem{arora2018convergence}
Sanjeev Arora, Nadav Cohen, Noah Golowich, and Wei Hu.
\newblock A convergence analysis of gradient descent for deep linear neural
  networks.
\newblock {\em arXiv preprint arXiv:1810.02281}, 2018.

\bibitem{arora2018optimization}
Sanjeev Arora, Nadav Cohen, and Elad Hazan.
\newblock On the optimization of deep networks: Implicit acceleration by
  overparameterization.
\newblock {\em arXiv preprint arXiv:1802.06509}, 2018.

\bibitem{arora2019implicit}
Sanjeev Arora, Nadav Cohen, Wei Hu, and Yuping Luo.
\newblock Implicit regularization in deep matrix factorization.
\newblock {\em arXiv preprint arXiv:1905.13655}, 2019.

\bibitem{bauer2017discriminative}
Matthias Bauer, Mateo Rojas-Carulla, Jakub~Bart{\l}omiej {\'S}wi{\k{a}}tkowski,
  Bernhard Sch{\"o}lkopf, and Richard~E Turner.
\newblock Discriminative k-shot learning using probabilistic models.
\newblock {\em arXiv preprint arXiv:1706.00326}, 2017.

\bibitem{bengio1990learning}
Yoshua Bengio, Samy Bengio, and Jocelyn Cloutier.
\newblock {\em Learning a synaptic learning rule}.
\newblock Universit{\'e} de Montr{\'e}al, D{\'e}partement d'informatique et de
  recherche~â€¦, 1990.

\bibitem{chen2018deeplab}
Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan~L
  Yuille.
\newblock Deeplab: Semantic image segmentation with deep convolutional nets,
  atrous convolution, and fully connected crfs.
\newblock {\em TPAMI}, 2018.

\bibitem{chen2018neural}
Tian~Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In {\em NIPS}, 2018.

\bibitem{chen2018a}
Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang~Frank Wang, and Jia-Bin
  Huang.
\newblock A closer look at few-shot classification.
\newblock In {\em ICLR}, 2019.

\bibitem{chen2018gaternet}
Zhourong Chen, Yang Li, Samy Bengio, and Si~Si.
\newblock Gaternet: Dynamic filter selection in convolutional neural network
  via a dedicated global gating network.
\newblock {\em arXiv preprint arXiv:1811.11205}, 2018.

\bibitem{courbariaux2015binaryconnect}
Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David.
\newblock Binaryconnect: Training deep neural networks with binary weights
  during propagations.
\newblock In {\em NIPS}, 2015.

\bibitem{dai2017deformable}
Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi~Li, Guodong Zhang, Han Hu, and Yichen
  Wei.
\newblock Deformable convolutional networks.
\newblock In {\em ICCV}, 2017.

\bibitem{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em ICML}, 2017.

\bibitem{gunasekar2018implicit}
Suriya Gunasekar, Jason~D Lee, Daniel Soudry, and Nati Srebro.
\newblock Implicit bias of gradient descent on linear convolutional networks.
\newblock In {\em NIPS}, 2018.

\bibitem{gunasekar2017implicit}
Suriya Gunasekar, Blake~E Woodworth, Srinadh Bhojanapalli, Behnam Neyshabur,
  and Nati Srebro.
\newblock Implicit regularization in matrix factorization.
\newblock In {\em NIPS}, 2017.

\bibitem{gupta2004static}
Madan Gupta, Liang Jin, and Noriyasu Homma.
\newblock {\em Static and dynamic neural networks: from fundamentals to
  advanced theory}.
\newblock John Wiley \& Sons, 2004.

\bibitem{ha2016hypernetworks}
David Ha, Andrew Dai, and Quoc~V Le.
\newblock Hypernetworks.
\newblock {\em arXiv preprint arXiv:1609.09106}, 2016.

\bibitem{hariharan2017low}
Bharath Hariharan and Ross Girshick.
\newblock Low-shot visual recognition by shrinking and hallucinating features.
\newblock In {\em ICCV}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{he2016identity}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In {\em ECCV}, 2016.

\bibitem{hubara2016binarized}
Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
  Bengio.
\newblock Binarized neural networks.
\newblock In {\em NIPS}, 2016.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em ICML}, 2015.

\bibitem{jaderberg2015spatial}
Max Jaderberg, Karen Simonyan, Andrew Zisserman, et~al.
\newblock Spatial transformer networks.
\newblock In {\em NIPS}, 2015.

\bibitem{jeon2017active}
Yunho Jeon and Junmo Kim.
\newblock Active convolution: Learning the shape of convolution for image
  classification.
\newblock In {\em CVPR}, 2017.

\bibitem{jeon2018constructing}
Yunho Jeon and Junmo Kim.
\newblock Constructing fast network through deconstruction of convolution.
\newblock In {\em NIPS}, 2018.

\bibitem{ji2018gradient}
Ziwei Ji and Matus Telgarsky.
\newblock Gradient descent aligns the layers of deep linear networks.
\newblock {\em arXiv preprint arXiv:1810.02032}, 2018.

\bibitem{jia2016dynamic}
Xu~Jia, Bert De~Brabandere, Tinne Tuytelaars, and Luc~V Gool.
\newblock Dynamic filter networks.
\newblock In {\em NIPS}, 2016.

\bibitem{kawaguchi2016deep}
Kenji Kawaguchi.
\newblock Deep learning without poor local minima.
\newblock In {\em NIPS}, 2016.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NIPS}, 2012.

\bibitem{leven1996multiattribute}
Samuel~J Leven and Daniel~S Levine.
\newblock Multiattribute decision making in context: A dynamic neural network
  methodology.
\newblock {\em Cognitive Science}, 20(2):271--299, 1996.

\bibitem{li2016learning}
Ke~Li and Jitendra Malik.
\newblock Learning to optimize.
\newblock {\em arXiv preprint arXiv:1606.01885}, 2016.

\bibitem{li2018algorithmic}
Yuanzhi Li, Tengyu Ma, and Hongyang Zhang.
\newblock Algorithmic regularization in over-parameterized matrix sensing and
  neural networks with quadratic activations.
\newblock In {\em COLT}, 2018.

\bibitem{LinCoMHE19}
Rongmei Lin, Weiyang Liu, Zhen Liu, Chen Feng, Zhiding Yu, James~M. Rehg,
  Li~Xiong, and Le~Song.
\newblock Compressive hyperspherical energy minimization.
\newblock {\em arXiv preprint arXiv:1906.04892}, 2019.

\bibitem{liu2018learning}
Weiyang Liu, Rongmei Lin, Zhen Liu, Lixin Liu, Zhiding Yu, Bo~Dai, and Le~Song.
\newblock Learning towards minimum hyperspherical energy.
\newblock In {\em NIPS}, 2018.

\bibitem{liu2018decoupled}
Weiyang Liu, Zhen Liu, Zhiding Yu, Bo~Dai, Rongmei Lin, Yisen Wang, James~M
  Rehg, and Le~Song.
\newblock Decoupled networks.
\newblock {\em CVPR}, 2018.

\bibitem{liu2017sphereface}
Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le~Song.
\newblock Sphereface: Deep hypersphere embedding for face recognition.
\newblock In {\em CVPR}, 2017.

\bibitem{liu2016large}
Weiyang Liu, Yandong Wen, Zhiding Yu, and Meng Yang.
\newblock Large-margin softmax loss for convolutional neural networks.
\newblock In {\em ICML}, 2016.

\bibitem{liu2017hyper}
Weiyang Liu, Yan-Ming Zhang, Xingguo Li, Zhiding Yu, Bo~Dai, Tuo Zhao, and
  Le~Song.
\newblock Deep hyperspherical learning.
\newblock In {\em NIPS}, 2017.

\bibitem{long2015fully}
Jonathan Long, Evan Shelhamer, and Trevor Darrell.
\newblock Fully convolutional networks for semantic segmentation.
\newblock In {\em CVPR}, 2015.

\bibitem{lu2017beyond}
Yiping Lu, Aoxiao Zhong, Quanzheng Li, and Bin Dong.
\newblock Beyond finite layer neural networks: Bridging deep architectures and
  numerical differential equations.
\newblock In {\em ICML}, 2018.

\bibitem{mallya2018piggyback}
Arun Mallya, Dillon Davis, and Svetlana Lazebnik.
\newblock Piggyback: Adapting a single network to multiple tasks by learning to
  mask weights.
\newblock {\em arXiv preprint arXiv:1801.06519}, 2018.

\bibitem{munkhdalai2017meta}
Tsendsuren Munkhdalai and Hong Yu.
\newblock Meta networks.
\newblock {\em arXiv preprint arXiv:1703.00837}, 2017.

\bibitem{neyshabur2018towards}
Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, and Nathan
  Srebro.
\newblock Towards understanding the role of over-parametrization in
  generalization of neural networks.
\newblock {\em arXiv preprint arXiv:1805.12076}, 2018.

\bibitem{oreshkin2018tadam}
Boris Oreshkin, Pau~Rodr{\'\i}guez L{\'o}pez, and Alexandre Lacoste.
\newblock Tadam: Task dependent adaptive metric for improved few-shot learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  721--731, 2018.

\bibitem{ravi2016optimization}
Sachin Ravi and Hugo Larochelle.
\newblock Optimization as a model for few-shot learning.
\newblock In {\em ICLR}, 2017.

\bibitem{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  91--99, 2015.

\bibitem{rusu2018meta}
Andrei~A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,
  Simon Osindero, and Raia Hadsell.
\newblock Meta-learning with latent embedding optimization.
\newblock {\em arXiv preprint arXiv:1807.05960}, 2018.

\bibitem{ruthotto2018deep}
Lars Ruthotto and Eldad Haber.
\newblock Deep neural networks motivated by partial differential equations.
\newblock {\em arXiv preprint arXiv:1804.04272}, 2018.

\bibitem{schmidhuber1992learning}
J{\"u}rgen Schmidhuber.
\newblock Learning to control fast-weight memories: An alternative to dynamic
  recurrent networks.
\newblock {\em Neural Computation}, 4(1):131--139, 1992.

\bibitem{shaw2019meta}
Albert Shaw, Wei Wei, Weiyang Liu, Le~Song, and Bo~Dai.
\newblock Meta architecture search.
\newblock In {\em NeurIPS}, 2019.

\bibitem{snell2017prototypical}
Jake Snell, Kevin Swersky, and Richard Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock In {\em NIPS}, 2017.

\bibitem{su2017learning}
Yu-Chuan Su and Kristen Grauman.
\newblock Learning spherical convolution for fast features from 360 imagery.
\newblock In {\em NIPS}, 2017.

\bibitem{sung2018learning}
Flood Sung, Yongxin Yang, Li~Zhang, Tao Xiang, Philip~HS Torr, and Timothy~M
  Hospedales.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In {\em CVPR}, 2018.

\bibitem{vinyals2016matching}
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et~al.
\newblock Matching networks for one shot learning.
\newblock In {\em NIPS}, 2016.

\bibitem{wang2007cognitive}
Yingxu Wang.
\newblock The cognitive processes of formal inferences.
\newblock {\em International Journal of Cognitive Informatics and Natural
  Intelligence (IJCINI)}, 1(4):75--86, 2007.

\bibitem{wang2018low}
Yu-Xiong Wang, Ross Girshick, Martial Hebert, and Bharath Hariharan.
\newblock Low-shot learning from imaginary data.
\newblock {\em arXiv preprint arXiv:1801.05401}, 2018.

\bibitem{weinan2017proposal}
E~Weinan.
\newblock A proposal on machine learning via dynamical systems.
\newblock {\em Communications in Mathematics and Statistics}, 5(1):1--11, 2017.

\bibitem{wu2018shift}
Bichen Wu, Alvin Wan, Xiangyu Yue, Peter Jin, Sicheng Zhao, Noah Golmant, Amir
  Gholaminejad, Joseph Gonzalez, and Kurt Keutzer.
\newblock Shift: A zero flop, zero parameter alternative to spatial
  convolutions.
\newblock In {\em CVPR}, 2018.

\bibitem{xing2003distance}
Eric~P Xing, Michael~I Jordan, Stuart~J Russell, and Andrew~Y Ng.
\newblock Distance metric learning with application to clustering with
  side-information.
\newblock In {\em NIPS}, 2003.

\bibitem{yu2015multi}
Fisher Yu and Vladlen Koltun.
\newblock Multi-scale context aggregation by dilated convolutions.
\newblock {\em arXiv preprint arXiv:1511.07122}, 2015.

\bibitem{zhang2018self}
Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena.
\newblock Self-attention generative adversarial networks.
\newblock In {\em ICML}, 2019.

\bibitem{zhu2018deformable}
Xizhou Zhu, Han Hu, Stephen Lin, and Jifeng Dai.
\newblock Deformable convnets v2: More deformable, better results.
\newblock {\em arXiv preprint arXiv:1811.11168}, 2018.

\end{thebibliography}
