@article{coronato2020reinforcement,
	title={Reinforcement learning for intelligent healthcare applications: A survey},
	author={Coronato, Antonio and Naeem, Muddasar and De Pietro, Giuseppe and Paragliola, Giovanni},
	journal={Artificial Intelligence in Medicine},
	volume={109},
	pages={101964},
	year={2020},
	publisher={Elsevier}
}

@inproceedings{johannink2019residual,
	title={Residual reinforcement learning for robot control},
	author={Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},
	booktitle={Proceedings of the 2019 International Conference on Robotics and Automation (ICRA)},
	pages={6023--6029},
	year={2019},
	organization={IEEE}
}

@article{wang2021tactical,
	title={Tactical driving decisions of unmanned ground vehicles in complex highway environments: A deep reinforcement learning approach},
	author={Wang, Huanjie and Yuan, Shihua and Guo, Mengyu and Chan, Ching-Yao and Li, Xueyuan and Lan, Wei},
	journal={Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering},
	volume={235},
	number={4},
	pages={1113--1127},
	year={2021},
	publisher={SAGE Publications Sage UK: London, England}
}

@article{oroojlooyjadid2019review,
	title={A review of cooperative multi-agent deep reinforcement learning},
	author={OroojlooyJadid, Afshin and Hajinezhad, Davood},
	journal={arXiv preprint arXiv:1908.03963},
	year={2019}
}

@article{sunehag2017value,
	title={Value-decomposition networks for cooperative multi-agent learning},
	author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
	journal={arXiv preprint arXiv:1706.05296},
	year={2017}
}

@inproceedings{rashid2018qmix,
	title={Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning},
	author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
	booktitle={Proceedings of the International Conference on Machine Learning},
	pages={4295--4304},
	year={2018},
	organization={PMLR}
}

@article{yang2020qatten,
	title={Qatten: A general framework for cooperative multiagent reinforcement learning},
	author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
	journal={arXiv preprint arXiv:2002.03939},
	year={2020}
}

@inproceedings{son2019qtran,
	title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
	author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
	booktitle={Proceedings of the International Conference on Machine Learning},
	pages={5887--5896},
	year={2019},
	organization={PMLR}
}

@inproceedings{
wang2021qplex,
title={{\{}QPLEX{\}}: Duplex Dueling Multi-Agent Q-Learning},
author={Jianhao Wang and Zhizhou Ren and Terry Liu and Yang Yu and Chongjie Zhang},
booktitle={Proceedings of the International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Rcmk0xxIQV}
}

@article{whiteson2020weighted,
	title={Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi- Agent Reinforcement Learning},
	author={Whiteson, Shimon},
	year={2020}
}

@article{su2020value,
	title={Value-Decomposition Multi-Agent Actor-Critics},
	author={Su, Jianyu and Adams, Stephen and Beling, Peter A},
	journal={arXiv preprint arXiv:2007.12306},
	year={2020}
}

@article{wang2020off,
	title={Off-policy multi-agent decomposed policy gradients},
	author={Wang, Yihan and Han, Beining and Wang, Tonghan and Dong, Heng and Zhang, Chongjie},
	journal={arXiv preprint arXiv:2007.12322},
	year={2020}
}

@inproceedings{hausknecht2015deep,
	title={Deep recurrent q-learning for partially observable mdps},
	author={Hausknecht, Matthew and Stone, Peter},
	booktitle={Proceedings of the 2015 AAAI fall symposium series},
	year={2015}
}

@inproceedings{foerster2018counterfactual,
	title={Counterfactual multi-agent policy gradients},
	author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={32},
	number={1},
	year={2018}
}

@article{lowe2017multi,
	title={Multi-agent actor-critic for mixed cooperative-competitive environments},
	author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
	journal={arXiv preprint arXiv:1706.02275},
	year={2017}
}


@article{wang2020r,
	title={R-MADDPG for partially observable environments and limited communication},
	author={Wang, Rose E and Everett, Michael and How, Jonathan P},
	journal={arXiv preprint arXiv:2002.06684},
	year={2020}
}


@article{mao2018modelling,
	title={Modelling the dynamic joint policy of teammates with attention multi-agent DDPG},
	author={Mao, Hangyu and Zhang, Zhengchao and Xiao, Zhen and Gong, Zhibo},
	journal={arXiv preprint arXiv:1811.07029},
	year={2018}
}


@article{chen2019new,
	title={A New Framework for Multi-Agent Reinforcement Learning--Centralized Training and Exploration with Decentralized Execution via Policy Distillation},
	author={Chen, Gang},
	journal={arXiv preprint arXiv:1910.09152},
	year={2019}
}

@book{oliehoek2016concise,
	title={A concise introduction to decentralized POMDPs},
	author={Oliehoek, Frans A and Amato, Christopher},
	year={2016},
	publisher={Springer}
}

@inproceedings{sun2021dfac,
  title={DFAC framework: Factorizing the value function via quantile mixture for multi-agent distributional q-learning},
  author={Sun, Wei-Fang and Lee, Cheng-Kuang and Lee, Chun-Yi},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={9945--9954},
  year={2021},
  organization={PMLR}
}

@article{hu2021rethinking,
  title={Rethinking the implementation tricks and monotonicity constraint in cooperative multi-agent reinforcement learning},
  author={Hu, Jian and Jiang, Siyang and Harding, Seth Austin and Wu, Haibin and Liao, SW},
  journal={arXiv preprint arXiv:2102.03479},
  year={2021}
}

@inproceedings{zhang2021avd,
  title={AVD-Net: Attention Value Decomposition Network For Deep Multi-Agent Reinforcement Learning},
  author={Zhang, Yuanxin and Ma, Huimin and Wang, Yu},
  booktitle={Proceedings of the 25th International Conference on Pattern Recognition},
  pages={7810--7816},
  year={2021},
  organization={IEEE}
}

@inproceedings{mahajan2019maven,
  title={Maven: Multi-agent variational exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  booktitle={Proceedings of the Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{oliehoek2008optimal,
  title={Optimal and approximate Q-value functions for decentralized POMDPs},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={289--353},
  year={2008}
}

@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{sunehag2018value,
  title={Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vin{\'\i}cius Flores and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  booktitle={Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
  year={2018}
}

@inproceedings{samvelyan2019starcraft,
  title={The StarCraft Multi-Agent Challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and Schroeder de Witt, Christian and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2186--2188},
  year={2019}
}

@inproceedings{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  booktitle={Proceedings of the Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}


@inproceedings{wang2020roma,
  title={ROMA: Multi-Agent Reinforcement Learning with Emergent Roles},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  pages={9876--9886},
  year={2020},
  organization={PMLR}
}

@incollection{bain1999framework,
  title={A Framework for Behavioural Cloning},
  author={Bain, Michael and Sammut, Claude},
  booktitle={Machine Intelligence 15, Intelligent Agents [St. Catherine's College, Oxford, July 1995]},
  pages={103--129},
  year={1999}
}

@article{yun2022cooperative,
  title={Cooperative Multi-Agent Deep Reinforcement Learning for Reliable Surveillance via Autonomous Multi-UAV Control},
  author={Yun, Won Joon and Park, Soohyun and Kim, Joongheon and Shin, Myungjae and Jung, Soyi and Mohaisen, Aziz and Kim, Jae-Hyun},
  journal={IEEE Transactions on Industrial Informatics},
  year={2022},
  publisher={IEEE}
}

@article{xu2020multi,
  title={A multi-agent reinforcement learning-based data-driven method for home energy management},
  author={Xu, Xu and Jia, Youwei and Xu, Yan and Xu, Zhao and Chai, Songjian and Lai, Chun Sing},
  journal={IEEE Transactions on Smart Grid},
  volume={11},
  number={4},
  pages={3201--3211},
  year={2020},
  publisher={IEEE}
}

@article{yu2020multi,
  title={Multi-agent deep reinforcement learning for HVAC control in commercial buildings},
  author={Yu, Liang and Sun, Yi and Xu, Zhanbo and Shen, Chao and Yue, Dong and Jiang, Tao and Guan, Xiaohong},
  journal={IEEE Transactions on Smart Grid},
  volume={12},
  number={1},
  pages={407--419},
  year={2020},
  publisher={IEEE}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of Reinforcement Learning and Control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

@inproceedings{eccles2019biases,
  title={Biases for emergent communication in multi-agent reinforcement learning},
  author={Eccles, Tom and Bachrach, Yoram and Lever, Guy and Lazaridou, Angeliki and Graepel, Thore},
  booktitle={Proceedings of the Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zhang2018fully,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{shao1989monte,
  title={Monte Carlo approximations in Bayesian decision theory},
  author={Shao, Jun},
  journal={Journal of the American Statistical Association},
  volume={84},
  number={407},
  pages={727--732},
  year={1989},
  publisher={Taylor \& Francis}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{ma2020feudal,
  title={Feudal multi-agent deep reinforcement learning for traffic signal control},
  author={Ma, Jinming and Wu, Feng},
  booktitle={Proceedings of the 19th International Conference on Autonomous Agents and Multiagent Systems},
  pages={816--824},
  year={2020}
}

@inproceedings{du2021learning,
  title={Learning correlated communication topology in multi-agent reinforcement learning},
  author={Du, Yali and Liu, Bo and Moens, Vincent and Liu, Ziqi and Ren, Zhicheng and Wang, Jun and Chen, Xu and Zhang, Haifeng},
  booktitle={Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={456--464},
  year={2021}
}

@article{wang2021multi,
  title={Multi-agent reinforcement learning for active voltage control on power distribution networks},
  author={Wang, Jianhong and Xu, Wangkun and Gu, Yunjie and Song, Wenbin and Green, Tim C},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3271--3284},
  year={2021}
}

@article{zhu2022multi,
  title={Multi-agent Reinforcement Learning Aided Service Function Chain Deployment for Internet of Things},
  author={Zhu, Yuchao and Yao, Haipeng and Mai, Tianle and He, Wenji and Zhang, Ni and Guizani, Mohsen},
  journal={IEEE Internet of Things Journal},
  year={2022},
  publisher={IEEE}
}


@inproceedings{wang2019learning,
  title={Learning Nearly Decomposable Value Functions Via Communication Minimization},
  author={Wang, Tonghan and Wang, Jianhao and Zheng, Chongyi and Zhang, Chongjie},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{chen2020new,
  title={A New Framework for Multi-Agent Reinforcement Learning--Centralized Training and Exploration with Decentralized Execution via Policy Distillation},
  author={Chen, Gang},
  booktitle={Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1801--1803},
  year={2020}
}

@article{nguyen2020deep,
  title={Deep reinforcement learning for multiagent systems: A review of challenges, solutions, and applications},
  author={Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
  journal={IEEE transactions on cybernetics},
  volume={50},
  number={9},
  pages={3826--3839},
  year={2020},
  publisher={IEEE}
}

@inproceedings{castellini2019representational,
  title={The Representational Capacity of Action-Value Networks for Multi-Agent Reinforcement Learning},
  author={Castellini, Jacopo and Oliehoek, Frans A and Savani, Rahul and Whiteson, Shimon},
  booktitle={AAMAS 2019: The 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1862--1864},
  year={2019},
  organization={International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)}
}

@article{wang2021towards,
  title={Towards understanding cooperative multi-agent q-learning with value factorization},
  author={Wang, Jianhao and Ren, Zhizhou and Han, Beining and Ye, Jianing and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29142--29155},
  year={2021}
}

@inproceedings{huang2022multiagent,
  title={Multiagent Q-learning with Sub-Team Coordination},
  author={Huang, Wenhan and Li, Kai and Shao, Kun and Zhou, Tianze and Luo, Jun and Wang, Dongge and Mao, Hangyu and Hao, Jianye and Wang, Jun and Deng, Xiaotie},
  booktitle={Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
  pages={1630--1632},
  year={2022}
}