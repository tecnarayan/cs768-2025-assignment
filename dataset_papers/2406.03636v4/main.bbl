\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2023)Agrawal, Kanade, Goyal, Lahiri, and Rajamani]{AgrawalNeurIPS2023}
Lakshya Agrawal, Aditya Kanade, Navin Goyal, Shuvendu~K Lahiri, and Sriram Rajamani.
\newblock Monitor-guided decoding of code {LM}s with static analysis of repository context.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=qPUbKxKvXq}.

\bibitem[Akhundov et~al.(2021)Akhundov, Mora, Feng, Hui, and Chechik]{akhundov2021verification}
Murad Akhundov, Federico Mora, Nick Feng, Vincent Hui, and Marsha Chechik.
\newblock Verification by gambling on program slices.
\newblock In \emph{Automated Technology for Verification and Analysis: 19th International Symposium, ATVA 2021, Gold Coast, QLD, Australia, October 18--22, 2021, Proceedings 19}, pages 266--282. Springer, 2021.

\bibitem[Austin et~al.(2021)Austin, Odena, Nye, Bosma, Michalewski, Dohan, Jiang, Cai, Terry, Le, et~al.]{mbpp}
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et~al.
\newblock Program synthesis with large language models.
\newblock \emph{arXiv preprint arXiv:2108.07732}, 2021.

\bibitem[Baier and Katoen(2008)]{baierkatoen}
Christel Baier and Joost{-}Pieter Katoen.
\newblock \emph{Principles of model checking}.
\newblock {MIT} Press, 2008.

\bibitem[Barke et~al.(2023)Barke, James, and Polikarpova]{10.1145/3586030}
Shraddha Barke, Michael~B. James, and Nadia Polikarpova.
\newblock Grounded copilot: How programmers interact with code-generating models.
\newblock \emph{Proc. ACM Program. Lang.}, 7\penalty0 (OOPSLA1), April 2023.
\newblock \doi{10.1145/3586030}.
\newblock URL \url{https://doi.org/10.1145/3586030}.

\bibitem[Barrett et~al.(2010)Barrett, Stump, Tinelli, et~al.]{barrett2010smt}
Clark Barrett, Aaron Stump, Cesare Tinelli, et~al.
\newblock The smt-lib standard: Version 2.0.
\newblock In \emph{Proceedings of the 8th international workshop on satisfiability modulo theories (Edinburgh, UK)}, volume~13, page~14, 2010.

\bibitem[Barrett et~al.(2021)Barrett, Sebastiani, Seshia, and Tinelli]{barrett-smtbookch21}
Clark Barrett, Roberto Sebastiani, Sanjit~A. Seshia, and Cesare Tinelli.
\newblock Satisfiability modulo theories.
\newblock In Armin Biere, Marijn Heule, Hans van Maaren, and Toby Walsh, editors, \emph{Handbook of Satisfiability}, chapter~33, pages 1267--1329. IOS Press, second edition, 2021.

\bibitem[Bhatia et~al.(2024)Bhatia, Qiu, Hasabnis, Seshia, and Cheung]{bhatia2024verifiedcodetranspilationllms}
Sahil Bhatia, Jie Qiu, Niranjan Hasabnis, Sanjit~A. Seshia, and Alvin Cheung.
\newblock Verified code transpilation with llms, 2024.
\newblock URL \url{https://arxiv.org/abs/2406.03003}.

\bibitem[Bj{\o}rner et~al.(2015)Bj{\o}rner, Phan, and Fleckenstein]{z3opt}
Nikolaj Bj{\o}rner, Anh-Dung Phan, and Lars Fleckenstein.
\newblock $\nu$z-an optimizing smt solver.
\newblock In \emph{Tools and Algorithms for the Construction and Analysis of Systems: 21st International Conference, TACAS 2015, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2015, London, UK, April 11-18, 2015, Proceedings 21}, pages 194--199. Springer, 2015.

\bibitem[Cassano et~al.(2023)Cassano, Gouwar, Lucchetti, Schlesinger, Anderson, Greenberg, Jangda, and Guha]{CassanoArxiv2023}
Federico Cassano, John Gouwar, Francesca Lucchetti, Claire Schlesinger, Carolyn~Jane Anderson, Michael Greenberg, Abhinav Jangda, and Arjun Guha.
\newblock Knowledge transfer from high-resource to low-resource programming languages for code llms.
\newblock \emph{arXiv preprint arXiv:2308.09895}, 2023.

\bibitem[Chasins et~al.(2021)Chasins, Glassman, and Sunshine]{ChasinsCACM2021}
Sarah~E. Chasins, Elena~L. Glassman, and Joshua Sunshine.
\newblock {PL} and {HCI}: better together.
\newblock \emph{Commun. ACM}, 64\penalty0 (8):\penalty0 98–106, jul 2021.
\newblock ISSN 0001-0782.
\newblock \doi{10.1145/3469279}.
\newblock URL \url{https://doi.org/10.1145/3469279}.

\bibitem[Chen et~al.(2022)Chen, Fard, Lo, and Bryksin]{chen2022transferability}
Fuxiang Chen, Fatemeh~H Fard, David Lo, and Timofey Bryksin.
\newblock On the transferability of pre-trained language models for low-resource programming languages.
\newblock In \emph{Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension}, pages 401--412, 2022.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem[Chen et~al.(2023)Chen, Lin, Sch{\"a}rli, and Zhou]{selfdebug}
Xinyun Chen, Maxwell Lin, Nathanael Sch{\"a}rli, and Denny Zhou.
\newblock Teaching large language models to self-debug.
\newblock \emph{arXiv preprint arXiv:2304.05128}, 2023.

\bibitem[De~Moura and Bj{\o}rner(2008)]{z3}
Leonardo De~Moura and Nikolaj Bj{\o}rner.
\newblock Z3: An efficient smt solver.
\newblock In \emph{International conference on Tools and Algorithms for the Construction and Analysis of Systems}, pages 337--340. Springer, 2008.

\bibitem[Elmaaroufi et~al.(2024)Elmaaroufi, Shanker, Cismaru, Vazquez{-}Chanlatte, Sangiovanni{-}Vincentelli, Zaharia, and Seshia]{elmaaroufi-colm24}
Karim Elmaaroufi, Devan Shanker, Ana Cismaru, Marcell Vazquez{-}Chanlatte, Alberto~L. Sangiovanni{-}Vincentelli, Matei Zaharia, and Sanjit~A. Seshia.
\newblock {ScenicNL:} generating probabilistic scenario programs from natural language.
\newblock In \emph{Conference on Language Models (COLM)}, 2024.

\bibitem[Fremont et~al.(2023)Fremont, Kim, Dreossi, Ghosh, Yue, Sangiovanni-Vincentelli, and Seshia]{fremont2023scenic}
Daniel~J Fremont, Edward Kim, Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Alberto~L Sangiovanni-Vincentelli, and Sanjit~A Seshia.
\newblock Scenic: A language for scenario specification and data generation.
\newblock \emph{Machine Learning}, 112\penalty0 (10):\penalty0 3805--3849, 2023.

\bibitem[Geng et~al.(2023)Geng, Josifoski, Peyrard, and West]{constraineddecoding}
Saibo Geng, Martin Josifoski, Maxime Peyrard, and Robert West.
\newblock Grammar-constrained decoding for structured {NLP} tasks without finetuning.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 10932--10952, Singapore, December 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.emnlp-main.674}.
\newblock URL \url{https://aclanthology.org/2023.emnlp-main.674}.

\bibitem[Glaser and Strauss(2017)]{Glaser2017Routledge}
Barney Glaser and Anselm Strauss.
\newblock \emph{Discovery of grounded theory: Strategies for qualitative research}.
\newblock Routledge, 2017.

\bibitem[Guo et~al.(2024)Guo, Zhu, Yang, Xie, Dong, Zhang, Chen, Bi, Wu, Li, et~al.]{deepseek-coder}
Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y~Wu, YK~Li, et~al.
\newblock Deepseek-coder: When the large language model meets programming--the rise of code intelligence.
\newblock \emph{arXiv preprint arXiv:2401.14196}, 2024.

\bibitem[Huth and Ryan(2004)]{huthryan}
Michael Huth and Mark~Dermot Ryan.
\newblock \emph{Logic in computer science - modelling and reasoning about systems {(2.} ed.)}.
\newblock Cambridge University Press, 2004.

\bibitem[Jain et~al.(2024)Jain, Han, Gu, Li, Yan, Zhang, Wang, Solar-Lezama, Sen, and Stoica]{livecodebench}
Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica.
\newblock Livecodebench: Holistic and contamination free evaluation of large language models for code.
\newblock \emph{arXiv preprint arXiv:2403.07974}, 2024.

\bibitem[Lee and Seshia(2010)]{leeseshia}
Edward~A. Lee and Sanjit~A. Seshia.
\newblock An introductory textbook on cyber-physical systems.
\newblock In \emph{{WESE}}, page~1. {ACM}, 2010.

\bibitem[Lee and Seshia(2016)]{leeseshia-16}
Edward~A. Lee and Sanjit~A. Seshia.
\newblock \emph{Introduction to Embedded Systems: A Cyber-Physical Systems Approach}.
\newblock MIT Press, second edition edition, 2016.
\newblock URL \url{http://leeseshia.org}.

\bibitem[Leino(2010)]{leino2010dafny}
K~Rustan~M Leino.
\newblock Dafny: An automatic program verifier for functional correctness.
\newblock In \emph{International conference on logic for programming artificial intelligence and reasoning}, pages 348--370. Springer, 2010.

\bibitem[Li et~al.(2023)Li, Allal, Zi, Muennighoff, Kocetkov, Mou, Marone, Akiki, Li, Chim, Liu, Zheltonozhskii, Zhuo, Wang, Dehaene, Davaadorj, Lamy-Poirier, Monteiro, et~al.]{li2023starcodersourceyou}
Raymond Li, Loubna~Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry~Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, et~al.
\newblock Starcoder: may the source be with you!, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.06161}.

\bibitem[Melcer et~al.(2024)Melcer, Fulton, Gouda, and Qian]{melcer2024constrained}
Daniel Melcer, Nathan Fulton, Sanjay~Krishna Gouda, and Haifeng Qian.
\newblock Constrained decoding for code language models via efficient left and right quotienting of context-sensitive grammars.
\newblock \emph{arXiv preprint arXiv:2402.17988}, 2024.

\bibitem[Misu et~al.(2024)Misu, Lopes, Ma, and Noble]{fsedafny}
Md~Rakib~Hossain Misu, Cristina~V. Lopes, Iris Ma, and James Noble.
\newblock Towards ai-assisted synthesis of verified dafny methods.
\newblock \emph{Proc. ACM Softw. Eng.}, 1\penalty0 (FSE), July 2024.
\newblock \doi{10.1145/3643763}.
\newblock URL \url{https://doi.org/10.1145/3643763}.

\bibitem[Myers et~al.(2004)Myers, Pane, and Ko]{MyersCACM2004}
Brad~A. Myers, John~F. Pane, and Amy~J. Ko.
\newblock Natural programming languages and environments.
\newblock \emph{Commun. ACM}, 47\penalty0 (9):\penalty0 47–52, sep 2004.
\newblock ISSN 0001-0782.
\newblock \doi{10.1145/1015864.1015888}.
\newblock URL \url{https://doi.org/10.1145/1015864.1015888}.

\bibitem[Olausson et~al.(2023)Olausson, Inala, Wang, Gao, and Solar-Lezama]{selfrepair}
Theo~X Olausson, Jeevana~Priya Inala, Chenglong Wang, Jianfeng Gao, and Armando Solar-Lezama.
\newblock Is self-repair a silver bullet for code generation?
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[OpenAI et~al.(2024)OpenAI, Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, Avila, Babuschkin, Balaji, Balcom, Baltescu, Bao, Bavarian, , et~al.]{openai2024gpt4}
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, , et~al.
\newblock Gpt-4 technical report, 2024.

\bibitem[Pavlinovic et~al.(2014)Pavlinovic, King, and Wies]{ZvonimirOOPSLA2014}
Zvonimir Pavlinovic, Tim King, and Thomas Wies.
\newblock Finding minimum type error sources.
\newblock \emph{SIGPLAN Not.}, 49\penalty0 (10):\penalty0 525–542, oct 2014.
\newblock ISSN 0362-1340.
\newblock \doi{10.1145/2714064.2660230}.
\newblock URL \url{https://doi.org/10.1145/2714064.2660230}.

\bibitem[Peng et~al.(2024)Peng, Chai, and Li]{peng2024humanevalxlmultilingualcodegeneration}
Qiwei Peng, Yekun Chai, and Xuhong Li.
\newblock Humaneval-xl: A multilingual code generation benchmark for cross-lingual natural language generalization, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.16694}.

\bibitem[Polgreen et~al.(2022)Polgreen, Cheang, Gaddamadugu, Godbole, Laeufer, Lin, Manerkar, Mora, and Seshia]{uclid5}
Elizabeth Polgreen, Kevin Cheang, Pranav Gaddamadugu, Adwait Godbole, Kevin Laeufer, Shaokai Lin, Yatin~A. Manerkar, Federico Mora, and Sanjit~A. Seshia.
\newblock {UCLID5:} multi-modal formal modeling, verification, and synthesis.
\newblock In \emph{{CAV} {(1)}}, volume 13371 of \emph{Lecture Notes in Computer Science}, pages 538--551. Springer, 2022.

\bibitem[Roziere et~al.(2023)Roziere, Gehring, Gloeckle, Sootla, Gat, Tan, Adi, Liu, Remez, Rapin, et~al.]{codellama}
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing~Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, J{\'e}r{\'e}my Rapin, et~al.
\newblock Code llama: Open foundation models for code.
\newblock \emph{arXiv preprint arXiv:2308.12950}, 2023.

\bibitem[Scholak et~al.(2021)Scholak, Schucher, and Bahdanau]{picard}
Torsten Scholak, Nathan Schucher, and Dzmitry Bahdanau.
\newblock Picard: Parsing incrementally for constrained auto-regressive decoding from language models.
\newblock \emph{arXiv preprint arXiv:2109.05093}, 2021.

\bibitem[Seshia and Subramanyan(2018)]{uclid52}
Sanjit~A. Seshia and Pramod Subramanyan.
\newblock {UCLID5:} integrating modeling, verification, synthesis and learning.
\newblock In \emph{{MEMOCODE}}, pages 1--10. {IEEE}, 2018.

\bibitem[Shinn et~al.(2024)Shinn, Cassano, Gopinath, Narasimhan, and Yao]{reflexion}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Stol et~al.(2016)Stol, Ralph, and Fitzgerald]{10.1145/2884781.2884833}
Klaas-Jan Stol, Paul Ralph, and Brian Fitzgerald.
\newblock Grounded theory in software engineering research: a critical review and guidelines.
\newblock In \emph{Proceedings of the 38th International Conference on Software Engineering}, ICSE '16, page 120–131, New York, NY, USA, 2016. Association for Computing Machinery.
\newblock ISBN 9781450339001.
\newblock \doi{10.1145/2884781.2884833}.
\newblock URL \url{https://doi.org/10.1145/2884781.2884833}.

\bibitem[Tarassow(2023)]{TarassowArxiv2023}
Artur Tarassow.
\newblock The potential of llms for coding with low-resource and domain-specific programming languages.
\newblock \emph{arXiv preprint arXiv:2307.13018}, 2023.

\bibitem[Team et~al.(2024)Team, Anil, Borgeaud, Alayrac, Yu, Soricut, Schalkwyk, Dai, Hauth, Millican, Silver, Johnson, Antonoglou, Schrittwieser, Glaese, Chen, Pitler, et~al.]{geminiteam2024geminifamilyhighlycapable}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M. Dai, Anja Hauth, Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, et~al.
\newblock Gemini: A family of highly capable multimodal models, 2024.
\newblock URL \url{https://arxiv.org/abs/2312.11805}.

\bibitem[Wang et~al.(2024)Wang, Wang, Wang, Cao, A~Saurous, and Kim]{WangNeurIPS2024}
Bailin Wang, Zi~Wang, Xuezhi Wang, Yuan Cao, Rif A~Saurous, and Yoon Kim.
\newblock Grammar prompting for domain-specific language generation with large language models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Wang et~al.(2023)Wang, Kordi, Mishra, Liu, Smith, Khashabi, and Hajishirzi]{wang-etal-2023-self-instruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi.
\newblock Self-instruct: Aligning language models with self-generated instructions.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics}, pages 13484--13508, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.754}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.754}.

\bibitem[Wei et~al.(2024)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou]{10.5555/3600270.3602070}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock In \emph{Proceedings of the 36th International Conference on Neural Information Processing Systems}, NIPS '22, Red Hook, NY, USA, 2024. Curran Associates Inc.
\newblock ISBN 9781713871088.

\end{thebibliography}
