\begin{thebibliography}{71}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amari(1998)]{Amari1998}
S.-I. Amari.
\newblock {Natural gradient works efficiently in learning}.
\newblock \emph{Neural Computation}, 10\penalty0 (2):\penalty0 251--276, 1998.

\bibitem[Amari(2016)]{Amari2016}
S.-I. Amari.
\newblock \emph{{Information Geometry and Its Applications}}, volume 194.
\newblock Springer, 2016.

\bibitem[Barbour and Chen(2005)]{Barbour2005}
A.~Barbour and L.~H.~Y. Chen.
\newblock \emph{{An introduction to Stein's method}}.
\newblock Lecture Notes Series, Institute for Mathematical Sciences, National
  University of Singapore, 2005.

\bibitem[Basu et~al.(2011)Basu, Shioya, and Park]{Basu2011}
A.~Basu, H.~Shioya, and C.~Park.
\newblock \emph{{Statistical Inference: The Minimum Distance Approach}}.
\newblock CRC Press, 2011.

\bibitem[Berlinet and Thomas-Agnan(2004)]{Berlinet2004}
A.~Berlinet and C.~Thomas-Agnan.
\newblock \emph{{Reproducing Kernel Hilbert Spaces in Probability and
  Statistics}}.
\newblock Springer Science+Business Media, New York, 2004.

\bibitem[Bernton et~al.(2019)Bernton, Jacob, Gerber, and Robert]{Bernton2017}
E.~Bernton, P.~E. Jacob, M.~Gerber, and C.~P. Robert.
\newblock {Approximate Bayesian computation with the Wasserstein distance}.
\newblock \emph{Journal of the Royal Statistical Society Series B: Statistical
  Methodology}, 81\penalty0 (2):\penalty0 235--269, 2019.

\bibitem[Bonnabel(2013)]{bonnabel2013stochastic}
S.~Bonnabel.
\newblock {Stochastic gradient descent on Riemannian manifolds}.
\newblock \emph{{IEEE Transactions on Automatic Control}}, 58\penalty0
  (9):\penalty0 2217--2229, 2013.

\bibitem[Briol et~al.(2019)Briol, Barp, Duncan, and Girolami]{Briol2019}
F.-X. Briol, A.~Barp, A.~B. Duncan, and M.~Girolami.
\newblock {Statistical inference for generative models with maximum mean
  discrepancy}.
\newblock \emph{arXiv:1906.05944}, 2019.

\bibitem[Casella and Berger(2001)]{Casella2001}
G.~Casella and R.~Berger.
\newblock \emph{{Statistical Inference}}.
\newblock 2001.

\bibitem[Ceylan and Gutmann(2018)]{ceylan2018conditional}
C.~Ceylan and M.~U. Gutmann.
\newblock Conditional noise-contrastive estimation of unnormalised models.
\newblock \emph{arXiv:1806.03664}, 2018.

\bibitem[Chen et~al.(2011)Chen, Goldstein, and Shao]{Chen2011}
L.~H.~Y. Chen, L.~Goldstein, and Q.-M. Shao.
\newblock \emph{{Normal Approximation by Stein's Method}}.
\newblock Springer, 2011.

\bibitem[Chen et~al.(2018)Chen, Mackey, Gorham, Briol, and Oates]{Chen2018}
W.~Y. Chen, L.~Mackey, J.~Gorham, F.-X. Briol, and C.~J. Oates.
\newblock {Stein points}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning, PMLR 80:843-852}, 2018.

\bibitem[Chen et~al.(2019)Chen, Barp, Briol, Gorham, Girolami, Mackey, and
  Oates]{Chen2019}
W.~Y. Chen, A.~Barp, F.-X. Briol, J.~Gorham, M.~Girolami, L.~Mackey, and C.~J.
  Oates.
\newblock {Stein point Markov chain Monte Carlo}.
\newblock In \emph{International Conference on Machine Learning, PMLR 97},
  pages 1011--1021, 2019.

\bibitem[Chwialkowski et~al.(2016)Chwialkowski, Strathmann, and
  Gretton]{Chwialkowski2016}
K.~Chwialkowski, H.~Strathmann, and A.~Gretton.
\newblock {A kernel test of goodness of fit}.
\newblock In \emph{International Conference on Machine Learning}, pages
  2606--2615, 2016.

\bibitem[Dawid and Musio(2014)]{Dawid2014}
A.~P. Dawid and M.~Musio.
\newblock {Theory and applications of proper scoring rules}.
\newblock \emph{Metron}, 72\penalty0 (2):\penalty0 169--183, 2014.
\newblock ISSN 2281695X.
\newblock \doi{10.1007/s40300-014-0039-y}.

\bibitem[Dawid et~al.(2016)Dawid, Musio, and Ventura]{Dawid2016}
A.~P. Dawid, M.~Musio, and L.~Ventura.
\newblock {Minimum scoring rule inference}.
\newblock \emph{Scandinavian Journal of Statistics}, 43\penalty0 (1):\penalty0
  123--138, 2016.

\bibitem[Detommaso et~al.(2018)Detommaso, Cui, Marzouk, Spantini, and
  Scheichl]{Detommaso2018}
G.~Detommaso, T.~Cui, Y.~Marzouk, A.~Spantini, and R.~Scheichl.
\newblock A stein variational newton method.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pages
  9169--9179. 2018.

\bibitem[Dziugaite et~al.(2015)Dziugaite, Roy, and Ghahramani]{Dziugaite2015}
G.~K. Dziugaite, D.~M. Roy, and Z.~Ghahramani.
\newblock {Training generative neural networks via maximum mean discrepancy
  optimization}.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2015.

\bibitem[Frogner et~al.(2015)Frogner, Zhang, Mobahi, Araya-Polo, and
  Poggio]{Frogner2015}
C.~Frogner, C.~Zhang, H.~Mobahi, M.~Araya-Polo, and T.~Poggio.
\newblock {Learning with a Wasserstein loss}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2053--2061, 2015.

\bibitem[Gabay(1982)]{gabay1982minimizing}
D.~Gabay.
\newblock Minimizing a differentiable function over a differential manifold.
\newblock \emph{Journal of Optimization Theory and Applications}, 37\penalty0
  (2):\penalty0 177--219, 1982.

\bibitem[Genevay et~al.(2018)Genevay, Peyr{\'{e}}, and Cuturi]{Genevay2017}
A.~Genevay, G.~Peyr{\'{e}}, and M.~Cuturi.
\newblock {Learning generative models with Sinkhorn divergences}.
\newblock In \emph{Proceedings of the Twenty-First International Conference on
  Artificial Intelligence and Statistics, PMLR 84}, pages 1608--1617, 2018.

\bibitem[Geyer(1994)]{geyer1994convergence}
C.~J. Geyer.
\newblock On the convergence of {M}onte {C}arlo maximum likelihood
  calculations.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 56\penalty0 (1):\penalty0 261--274, 1994.

\bibitem[Gorham and Mackey(2015)]{Gorham2015}
J.~Gorham and L.~Mackey.
\newblock {Measuring sample quality with Stein's method}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  226--234, 2015.

\bibitem[Gorham and Mackey(2017)]{Gorham2017}
J.~Gorham and L.~Mackey.
\newblock {Measuring sample quality with kernels}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 1292--1301, 2017.

\bibitem[Gorham et~al.(2016)Gorham, Duncan, Mackey, and Vollmer]{Gorham2016}
J.~Gorham, A.~Duncan, L.~Mackey, and S.~Vollmer.
\newblock {Measuring sample quality with diffusions}.
\newblock \emph{arXiv:1506.03039. To appear in Annals of Applied Probability.},
  2016.

\bibitem[Gutmann and Hyv{\"a}rinen(2010)]{gutmann2010noise}
M.~U. Gutmann and A.~Hyv{\"a}rinen.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 297--304, 2010.

\bibitem[Gutmann and Hyvarinen(2012)]{Gutmann2012}
M.~U. Gutmann and A.~Hyvarinen.
\newblock {Noise-contrastive estimation of unnormalized statistical models,
  with applications to natural image statistics}.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 307--361,
  2012.

\bibitem[Hinton(2002)]{Hinton2002}
G.~E. Hinton.
\newblock {Training products of experts by minimizing contrastive divergence}.
\newblock \emph{Neural Computation}, 14\penalty0 (8):\penalty0 1771--1800,
  2002.

\bibitem[Hoeffding(1948)]{hoeffding1948class}
W.~Hoeffding.
\newblock A class of statistics with asymptotically normal distribution.
\newblock \emph{The Annals of Mathematical Statistics}, pages 293--325, 1948.

\bibitem[Hoeffding(1961)]{hoeffding1961strong}
W.~Hoeffding.
\newblock The strong law of large numbers for {U}-statistics.
\newblock Technical report, North Carolina State University Department of
  Statistics, 1961.

\bibitem[Huber and Ronchetti(2009)]{Huber2009}
P.~J. Huber and E.~M. Ronchetti.
\newblock \emph{{Robust Statistics}}.
\newblock Wiley, 2009.

\bibitem[Huggins and Mackey(2018)]{huggins2018random}
J.~Huggins and L.~Mackey.
\newblock Random feature stein discrepancies.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1899--1909, 2018.

\bibitem[Hyv{\"a}rinen(1999)]{hyvarinen1999sparse}
A.~Hyv{\"a}rinen.
\newblock Sparse code shrinkage: Denoising of nongaussian data by maximum
  likelihood estimation.
\newblock \emph{Neural computation}, 11\penalty0 (7):\penalty0 1739--1768,
  1999.

\bibitem[Hyv{\"{a}}rinen(2006)]{Hyvarinen2006}
A.~Hyv{\"{a}}rinen.
\newblock {Estimation of non-normalized statistical models by score matching}.
\newblock \emph{Journal of Machine Learning Research}, 6:\penalty0 695--708,
  2006.

\bibitem[Hyv{\"{a}}rinen(2007)]{Hyvarinen2007}
A.~Hyv{\"{a}}rinen.
\newblock {Some extensions of score matching}.
\newblock \emph{Computational Statistics and Data Analysis}, 51\penalty0
  (5):\penalty0 2499--2512, 2007.

\bibitem[Jitkrittum et~al.(2017)Jitkrittum, Xu, Szabo, Fukumizu, and
  Gretton]{Jitkrittum2017}
W.~Jitkrittum, W.~Xu, Z.~Szabo, K.~Fukumizu, and A.~Gretton.
\newblock {A linear-time kernel goodness-of-fit test}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  261--270, 2017.

\bibitem[Karakida et~al.(2016)Karakida, Okada, and Amari]{Karakida2016}
R.~Karakida, M.~Okada, and S.-I. Amari.
\newblock {Adaptive natural gradient learning algorithms for unnormalized
  statistical models}.
\newblock \emph{Artificial Neural Networks and Machine Learning - ICANN}, 2016.

\bibitem[Kingma and LeCun(2010)]{Kingma2010}
D.~P. Kingma and Y.~LeCun.
\newblock {Regularized estimation of image statistics by score matching}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1126--1134, 2010.

\bibitem[K{\"o}ster and Hyv{\"a}rinen(2010)]{koster2010two}
U.~K{\"o}ster and A.~Hyv{\"a}rinen.
\newblock A two-layer model of natural stimuli estimated with score matching.
\newblock \emph{Neural Computation}, 22\penalty0 (9):\penalty0 2308--2333,
  2010.

\bibitem[Kotz et~al.(2001)Kotz, Kozubowski, and Podgorski]{Kotz2001}
S.~Kotz, T.~J. Kozubowski, and K.~Podgorski.
\newblock \emph{{The Laplace Distribution and Generalizations}}.
\newblock Springer, 2001.

\bibitem[Li and Turner(2018)]{Li2018implicit}
Y.~Li and R.~E. Turner.
\newblock {Gradient estimators for implicit models}.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Li et~al.(2015)Li, Swersky, and Zemel]{Li2015GMMN}
Y.~Li, K.~Swersky, and R.~Zemel.
\newblock {Generative moment matching networks}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, volume~37, pages 1718--1727, 2015.

\bibitem[Liu and Zhu(2017)]{Liu2017geomSVGD}
C.~Liu and J.~Zhu.
\newblock {Riemannian Stein Variational Gradient Descent for Bayesian
  Inference}.
\newblock \penalty0 (i), 2017.
\newblock URL \url{http://arxiv.org/abs/1711.11216}.

\bibitem[Liu and Wang(2016)]{Liu2016}
Q.~Liu and D.~Wang.
\newblock {Stein variational gradient descent: A general purpose Bayesian
  inference algorithm}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Liu and Wang(2017)]{liu2017learning}
Q.~Liu and D.~Wang.
\newblock Learning deep energy models: Contrastive divergence vs. amortized
  mle.
\newblock \emph{arXiv preprint arXiv:1707.00797}, 2017.

\bibitem[Liu et~al.(2016)Liu, Lee, and Jordan]{Liu2016testing}
Q.~Liu, J.~Lee, and M.~Jordan.
\newblock {A kernelized Stein discrepancy for goodness-of-fit tests}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 276--284, 2016.

\bibitem[Liu et~al.(2018)Liu, Kanamori, Jitkrittum, and Chen]{Liu2018Fisher}
S.~Liu, T.~Kanamori, W.~Jitkrittum, and Y.~Chen.
\newblock {Fisher efficient inference of intractable models}.
\newblock \emph{arXiv:1805.07454}, 2018.

\bibitem[Lyu(2009)]{Lyu2009}
S.~Lyu.
\newblock {Interpretation and generalization of score matching}.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pages
  359--366, 2009.

\bibitem[Ma and Barber(2017)]{Ma2017}
C.~Ma and D.~Barber.
\newblock {Black-box Stein divergence minimization for learning latent variable
  models}.
\newblock \emph{Advances in Approximate Bayesian Inference, NIPS 2017
  Workshop}, 2017.

\bibitem[Mackey and Gorham(2016)]{mackey2016multivariate}
L.~Mackey and J.~Gorham.
\newblock Multivariate {S}tein factors for a class of strongly log-concave
  distributions.
\newblock \emph{Electronic Communications in Probability}, 21, 2016.

\bibitem[Mardia et~al.(2016)Mardia, Kent, and Laha]{mardia2016score}
K.~V. Mardia, J.~T. Kent, and A.~K. Laha.
\newblock Score matching estimators for directional distributions.
\newblock \emph{arXiv preprint arXiv:1604.08470}, 2016.

\bibitem[Micchelli and Pontil(2005)]{micchelli2005learning}
C.~A. Micchelli and M.~Pontil.
\newblock On learning vector-valued functions.
\newblock \emph{Neural computation}, 17\penalty0 (1):\penalty0 177--204, 2005.

\bibitem[Micheli and Glaunes(2013)]{micheli2013matrix}
M.~Micheli and J.~A. Glaunes.
\newblock Matrix-valued kernels for shape deformation analysis.
\newblock \emph{arXiv preprint arXiv:1308.5739}, 2013.

\bibitem[Mnih and Teh(2012)]{mnih2012fast}
A.~Mnih and Y.~W. Teh.
\newblock {A fast and simple algorithm for training neural probabilistic
  language models}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 419--426, 2012.

\bibitem[Muller(1997)]{Muller1997}
A.~Muller.
\newblock {Integral probability metrics and their generating classes of
  functions}.
\newblock \emph{Advances in Applied Probability}, 29\penalty0 (2):\penalty0
  429--443, 1997.

\bibitem[Newey and McFadden(1994)]{newey1994large}
W.~K. Newey and D.~McFadden.
\newblock Large sample estimation and hypothesis testing.
\newblock \emph{Handbook of Econometrics}, 4:\penalty0 2111--2245, 1994.

\bibitem[Oates et~al.(2017)Oates, Girolami, and Chopin]{Oates2017}
C.~J. Oates, M.~Girolami, and N.~Chopin.
\newblock {Control functionals for Monte Carlo integration}.
\newblock \emph{Journal of the Royal Statistical Society B: Statistical
  Methodology}, 79\penalty0 (3):\penalty0 695--718, 2017.

\bibitem[Pardo(2005)]{Pardo2005}
L.~Pardo.
\newblock \emph{{Statistical Inference Based on Divergence Measures}}, volume
  170.
\newblock Chapman and Hall/CRC, 2005.

\bibitem[Pigola and Setti(2014)]{pigola2014global}
S.~Pigola and A.~G. Setti.
\newblock Global divergence theorems in nonlinear {PDE}s and geometry.
\newblock \emph{Ensaios Matem{\'a}ticos}, 26:\penalty0 1--77, 2014.

\bibitem[Ranganath et~al.(2016)Ranganath, Altosaar, Tran, and
  Blei]{Ranganath2016}
R.~Ranganath, J.~Altosaar, D.~Tran, and D.~M. Blei.
\newblock {Operator variational inference}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  496--504, 2016.

\bibitem[Roth and Black(2009)]{roth2009fields}
S.~Roth and M.~J. Black.
\newblock Fields of experts.
\newblock \emph{International Journal of Computer Vision}, 82\penalty0
  (2):\penalty0 205, 2009.

\bibitem[Sohl-Dickstein et~al.(2009)Sohl-Dickstein, Battaglino, and
  DeWeese]{sohl2009minimum2009}
J.~Sohl-Dickstein, P.~Battaglino, and M.~R. DeWeese.
\newblock Minimum probability flow learning.
\newblock \emph{arXiv preprint arXiv:0906.4779}, 2009.

\bibitem[Sohl-dickstein et~al.(2011)Sohl-dickstein, Battaglino, and
  DeWeese]{sohl2009minimum}
J.~Sohl-dickstein, P.~Battaglino, and M.~R. DeWeese.
\newblock {Minimum probability flow learning}.
\newblock In \emph{Proceedings of the 28th International Conference on
  International Conference on Machine Learning}, pages 905--912, 2011.

\bibitem[Sriperumbudur et~al.(2017)Sriperumbudur, Fukumizu, Gretton,
  Hyv{\"a}rinen, and Kumar]{Sriperumbudur2017density}
B.~Sriperumbudur, K.~Fukumizu, A.~Gretton, A.~Hyv{\"a}rinen, and R.~Kumar.
\newblock Density estimation in infinite dimensional exponential families.
\newblock \emph{Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 1830--1888, 2017.

\bibitem[Sriperumbudur et~al.(2010)Sriperumbudur, Gretton, Fukumizu,
  Sch{\"{o}}lkopf, and Lanckriet]{Sriperumbudur2009}
B.~K. Sriperumbudur, A.~Gretton, K.~Fukumizu, B.~Sch{\"{o}}lkopf, and
  G.~Lanckriet.
\newblock {Hilbert space embeddings and metrics on probability measures}.
\newblock \emph{Journal of Machine Learning Research}, 11:\penalty0 1517--1561,
  2010.

\bibitem[Stein(1972)]{Stein1972}
C.~Stein.
\newblock {A bound for the error in the normal approximation to the
  distribution of a sum of dependent random variables}.
\newblock In \emph{Proceedings of 6th Berkeley Symposium on Mathematical
  Statistics and Probability}, pages 583--602. University of California Press,
  1972.

\bibitem[Swersky et~al.(2011)Swersky, Ranzato, Buchman, Marlin, and
  de~Freitas]{Swersky2011}
K.~Swersky, M.~A. Ranzato, D.~Buchman, B.~M. Marlin, and N.~de~Freitas.
\newblock {On autoencoders and score matching for energy based models}.
\newblock In \emph{International Conference on Machine Learning}, pages
  1201--1208, 2011.

\bibitem[Vishwanathan et~al.(2010)Vishwanathan, Schraudolph, Kondor, and
  Borgwardt]{Vishwanathan2010}
S.~V.~N. Vishwanathan, N.~Schraudolph, R.~Kondor, and K.~Borgwardt.
\newblock {Graph kernels}.
\newblock \emph{Journal of Machine Learning Research}, pages 1201--1242, 2010.

\bibitem[Welling et~al.(2003)Welling, Hinton, and Osindero]{Welling2003}
M.~Welling, G.~Hinton, and S.~Osindero.
\newblock {Learning sparse topographic representations with products of
  student-t distributions}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1383--1390, 2003.

\bibitem[Wenliang et~al.(2018)Wenliang, Sutherland, Strathmann, and
  Gretton]{wenliang2018learning}
L.~Wenliang, D.~Sutherland, H.~Strathmann, and A.~Gretton.
\newblock Learning deep kernels for exponential family densities.
\newblock \emph{arXiv:1811.08357}, 2018.

\bibitem[Yeo and Johnson(2001)]{yeo2001uniform}
I.-K. Yeo and R.~A. Johnson.
\newblock A uniform strong law of large numbers for {U}-statistics with
  application to transforming to near symmetry.
\newblock \emph{Statistics \& Probability Letters}, 51\penalty0 (1):\penalty0
  63--69, 2001.

\end{thebibliography}
