\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Austin et~al.(2021)Austin, Odena, Nye, Bosma, Michalewski, Dohan, Jiang, Cai, Terry, Le, et~al.]{austin2021program}
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et~al.
\newblock Program synthesis with large language models.
\newblock \emph{arXiv preprint arXiv:2108.07732}, 2021.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and Bowling]{bellemare2013arcade}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0 253--279, 2013.

\bibitem[Bender \& Friedman(2018)Bender and Friedman]{bender2018data}
Emily~M Bender and Batya Friedman.
\newblock Data statements for natural language processing: Toward mitigating system bias and enabling better science.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 6:\penalty0 587--604, 2018.

\bibitem[Bisk et~al.(2020)Bisk, Zellers, Gao, Choi, et~al.]{bisk2020piqa}
Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et~al.
\newblock Piqa: Reasoning about physical commonsense in natural language.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~34, pp.\  7432--7439, 2020.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang, Zhuang, Gonzalez, et~al.]{chiang2023vicuna}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E Gonzalez, et~al.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality.
\newblock \emph{See https://vicuna. lmsys. org (accessed 14 April 2023)}, 2\penalty0 (3):\penalty0 6, 2023.

\bibitem[Chiang et~al.(2024)Chiang, Zheng, Sheng, Angelopoulos, Li, Li, Zhang, Zhu, Jordan, Gonzalez, et~al.]{chiang2024chatbot}
Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios~Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph~E Gonzalez, et~al.
\newblock Chatbot arena: An open platform for evaluating llms by human preference.
\newblock \emph{arXiv preprint arXiv:2403.04132}, 2024.

\bibitem[Chicco \& Jurman(2020)Chicco and Jurman]{chicco2020advantages}
Davide Chicco and Giuseppe Jurman.
\newblock The advantages of the matthews correlation coefficient (mcc) over f1 score and accuracy in binary classification evaluation.
\newblock \emph{BMC genomics}, 21:\penalty0 1--13, 2020.

\bibitem[Clark et~al.(2019)Clark, Lee, Chang, Kwiatkowski, Collins, and Toutanova]{clark2019boolq}
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova.
\newblock Boolq: Exploring the surprising difficulty of natural yes/no questions.
\newblock \emph{arXiv preprint arXiv:1905.10044}, 2019.

\bibitem[Clark et~al.(2018)Clark, Cowhey, Etzioni, Khot, Sabharwal, Schoenick, and Tafjord]{clark2018think}
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.
\newblock Think you have solved question answering? try arc, the ai2 reasoning challenge.
\newblock \emph{arXiv preprint arXiv:1803.05457}, 2018.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[Computer(2023)]{together2023redpajama}
Together Computer.
\newblock Redpajama: an open dataset for training large language models, 2023.
\newblock URL \url{https://github.com/togethercomputer/RedPajama-Data}.

\bibitem[Contributors(2023)]{contributors2023opencompass}
OpenCompass Contributors.
\newblock Opencompass: A universal evaluation platform for foundation models.
\newblock \emph{GitHub repository}, 2023.

\bibitem[Dua et~al.(2019)Dua, Wang, Dasigi, Stanovsky, Singh, and Gardner]{dua2019drop}
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner.
\newblock Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs.
\newblock \emph{arXiv preprint arXiv:1903.00161}, 2019.

\bibitem[Dubois et~al.(2024{\natexlab{a}})Dubois, Galambosi, Liang, and Hashimoto]{dubois2024length}
Yann Dubois, Bal{\'a}zs Galambosi, Percy Liang, and Tatsunori~B Hashimoto.
\newblock Length-controlled alpacaeval: A simple way to debias automatic evaluators.
\newblock \emph{arXiv preprint arXiv:2404.04475}, 2024{\natexlab{a}}.

\bibitem[Dubois et~al.(2024{\natexlab{b}})Dubois, Li, Taori, Zhang, Gulrajani, Ba, Guestrin, Liang, and Hashimoto]{dubois2024alpacafarm}
Yann Dubois, Chen~Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy~S Liang, and Tatsunori~B Hashimoto.
\newblock Alpacafarm: A simulation framework for methods that learn from human feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{b}}.

\bibitem[Face(2023)]{openllmleaderboard}
Hugging Face.
\newblock Open llm leaderboard, 2023.
\newblock URL \url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}.

\bibitem[Fan et~al.(2023)Fan, Hua, Li, Ling, Zhang, and Hemphill]{fan2023nphardeval}
Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng Zhang, and Libby Hemphill.
\newblock Nphardeval: Dynamic benchmark on reasoning ability of large language models via complexity classes.
\newblock \emph{arXiv preprint arXiv:2312.14890}, 2023.

\bibitem[Foundation(2022)]{wikidump}
Wikimedia Foundation.
\newblock Wikimedia downloads, 2022.
\newblock URL \url{https://dumps.wikimedia.org}.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock \emph{arXiv preprint arXiv:2009.03300}, 2020.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycksmath2021}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Huang et~al.(2024)Huang, Zhang, Shan, and He]{huang2024compression}
Yuzhen Huang, Jinghan Zhang, Zifei Shan, and Junxian He.
\newblock Compression represents intelligence linearly.
\newblock \emph{arXiv preprint arXiv:2404.09937}, 2024.

\bibitem[Jain et~al.(2024)Jain, Han, Gu, Li, Yan, Zhang, Wang, Solar-Lezama, Sen, and Stoica]{jain2024livecodebench}
Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica.
\newblock Livecodebench: Holistic and contamination free evaluation of large language models for code.
\newblock \emph{arXiv preprint arXiv:2403.07974}, 2024.

\bibitem[Joshi et~al.(2017)Joshi, Choi, Weld, and Zettlemoyer]{joshi2017triviaqa}
Mandar Joshi, Eunsol Choi, Daniel~S Weld, and Luke Zettlemoyer.
\newblock Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension.
\newblock \emph{arXiv preprint arXiv:1705.03551}, 2017.

\bibitem[Lin et~al.(2024)Lin, Chandu, Brahman, Deng, Ravichander, Pyatkin, Bras, and Choi]{wildbench2024}
Bill~Yuchen Lin, Khyathi Chandu, Faeze Brahman, Yuntian Deng, Abhilasha Ravichander, Valentina Pyatkin, Ronan~Le Bras, and Yejin Choi.
\newblock Wildbench: Benchmarking llms with challenging tasks from real users in the wild, 2024.
\newblock URL \url{https://huggingface.co/spaces/allenai/WildBench}.

\bibitem[Menzies \& Zimmermann(2013)Menzies and Zimmermann]{menzies2013software}
Tim Menzies and Thomas Zimmermann.
\newblock Software analytics: so what?
\newblock \emph{IEEE Software}, 30\penalty0 (4):\penalty0 31--37, 2013.

\bibitem[Mihaylov et~al.(2018)Mihaylov, Clark, Khot, and Sabharwal]{mihaylov2018can}
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal.
\newblock Can a suit of armor conduct electricity? a new dataset for open book question answering.
\newblock \emph{arXiv preprint arXiv:1809.02789}, 2018.

\bibitem[Padlewski et~al.(2024)Padlewski, Bain, Henderson, Zhu, Relan, Pham, Ong, Aleksiev, Ormazabal, Phua, et~al.]{padlewski2024vibe}
Piotr Padlewski, Max Bain, Matthew Henderson, Zhongkai Zhu, Nishant Relan, Hai Pham, Donovan Ong, Kaloyan Aleksiev, Aitor Ormazabal, Samuel Phua, et~al.
\newblock Vibe-eval: A hard evaluation suite for measuring progress of multimodal language models.
\newblock \emph{arXiv preprint arXiv:2405.02287}, 2024.

\bibitem[Reimers \& Gurevych(2019)Reimers and Gurevych]{reimers2019sentence}
Nils Reimers and Iryna Gurevych.
\newblock Sentence-bert: Sentence embeddings using siamese bert-networks.
\newblock \emph{arXiv preprint arXiv:1908.10084}, 2019.

\bibitem[Rein et~al.(2023)Rein, Hou, Stickland, Petty, Pang, Dirani, Michael, and Bowman]{rein2023gpqa}
David Rein, Betty~Li Hou, Asa~Cooper Stickland, Jackson Petty, Richard~Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel~R Bowman.
\newblock Gpqa: A graduate-level google-proof q\&a benchmark.
\newblock \emph{arXiv preprint arXiv:2311.12022}, 2023.

\bibitem[Sakaguchi et~al.(2021)Sakaguchi, Bras, Bhagavatula, and Choi]{sakaguchi2021winogrande}
Keisuke Sakaguchi, Ronan~Le Bras, Chandra Bhagavatula, and Yejin Choi.
\newblock Winogrande: An adversarial winograd schema challenge at scale.
\newblock \emph{Communications of the ACM}, 64\penalty0 (9):\penalty0 99--106, 2021.

\bibitem[Sap et~al.(2019)Sap, Rashkin, Chen, LeBras, and Choi]{sap2019socialiqa}
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi.
\newblock Socialiqa: Commonsense reasoning about social interactions.
\newblock \emph{arXiv preprint arXiv:1904.09728}, 2019.

\bibitem[ShareGPT(2023)]{sharegpt2023sharegpt}
Teams ShareGPT.
\newblock Sharegpt: Share your wildest chatgpt conversations with one click, 2023.

\bibitem[Suzgun et~al.(2022)Suzgun, Scales, Sch{\"a}rli, Gehrmann, Tay, Chung, Chowdhery, Le, Chi, Zhou, et~al.]{suzgun2022challenging}
Mirac Suzgun, Nathan Scales, Nathanael Sch{\"a}rli, Sebastian Gehrmann, Yi~Tay, Hyung~Won Chung, Aakanksha Chowdhery, Quoc~V Le, Ed~H Chi, Denny Zhou, et~al.
\newblock Challenging big-bench tasks and whether chain-of-thought can solve them.
\newblock \emph{arXiv preprint arXiv:2210.09261}, 2022.

\bibitem[Talmor et~al.(2018)Talmor, Herzig, Lourie, and Berant]{talmor2018commonsenseqa}
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant.
\newblock Commonsenseqa: A question answering challenge targeting commonsense knowledge.
\newblock \emph{arXiv preprint arXiv:1811.00937}, 2018.

\bibitem[Tianle et~al.(2024)Tianle, Wei-Lin, Evan, Lisa, Banghua, Joseph~E., and Ion]{tianle2024from}
Li~Tianle, Chiang Wei-Lin, Frick Evan, Dunlap Lisa, Zhu Banghua, Gonzalez Joseph~E., and Stoica Ion.
\newblock From live data to high-quality benchmarks: The arena-hard pipeline.
\newblock \emph{See https://lmsys.org/blog/2024-04-19-arena-hard/}, 2024.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz, et~al.
\newblock Huggingface's transformers: State-of-the-art natural language processing.
\newblock \emph{arXiv preprint arXiv:1910.03771}, 2019.

\bibitem[Yang et~al.(2023)Yang, Chiang, Zheng, Gonzalez, and Stoica]{yang2023rethinking}
Shuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph~E Gonzalez, and Ion Stoica.
\newblock Rethinking benchmark and contamination for language models with rephrased samples.
\newblock \emph{arXiv preprint arXiv:2311.04850}, 2023.

\bibitem[Yi et~al.(2012)Yi, Steyvers, Lee, and Dry]{yi2012wisdom}
Sheng Kung~Michael Yi, Mark Steyvers, Michael~D Lee, and Matthew~J Dry.
\newblock The wisdom of the crowd in combinatorial problems.
\newblock \emph{Cognitive science}, 36\penalty0 (3):\penalty0 452--470, 2012.

\bibitem[Yue et~al.(2024)Yue, Zheng, Zhang, and Chen]{yue2024mammoth2}
Xiang Yue, Tuney Zheng, Ge~Zhang, and Wenhu Chen.
\newblock Mammoth2: Scaling instructions from the web.
\newblock \emph{arXiv preprint arXiv:2405.03548}, 2024.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and Choi]{zellers2019hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock \emph{arXiv preprint arXiv:1905.07830}, 2019.

\bibitem[Zhang et~al.(2024{\natexlab{a}})Zhang, Da, Lee, Robinson, Wu, Song, Zhao, Raja, Slack, Lyu, et~al.]{zhang2024careful}
Hugh Zhang, Jeff Da, Dean Lee, Vaughn Robinson, Catherine Wu, Will Song, Tiffany Zhao, Pranav Raja, Dylan Slack, Qin Lyu, et~al.
\newblock A careful examination of large language model performance on grade school arithmetic.
\newblock \emph{arXiv preprint arXiv:2405.00332}, 2024{\natexlab{a}}.

\bibitem[Zhang et~al.(2024{\natexlab{b}})Zhang, Gui, Sun, Feng, Xu, Zhang, Fu, Li, Hauptmann, Bisk, et~al.]{zhang2024direct}
Ruohong Zhang, Liangke Gui, Zhiqing Sun, Yihao Feng, Keyang Xu, Yuanhan Zhang, Di~Fu, Chunyuan Li, Alexander Hauptmann, Yonatan Bisk, et~al.
\newblock Direct preference optimization of video large multimodal models from language model reward.
\newblock \emph{arXiv preprint arXiv:2404.01258}, 2024{\natexlab{b}}.

\bibitem[Zhao et~al.(2024)Zhao, Ren, Hessel, Cardie, Choi, and Deng]{zhao2024wildchat}
Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng.
\newblock Wildchat: 1m chatgpt interaction logs in the wild.
\newblock \emph{arXiv preprint arXiv:2405.01470}, 2024.

\bibitem[Zheng et~al.(2024)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, et~al.]{zheng2024judging}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric Xing, et~al.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Zhong et~al.(2023)Zhong, Cui, Guo, Liang, Lu, Wang, Saied, Chen, and Duan]{zhong2023agieval}
Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan.
\newblock Agieval: A human-centric benchmark for evaluating foundation models.
\newblock \emph{arXiv preprint arXiv:2304.06364}, 2023.

\end{thebibliography}
