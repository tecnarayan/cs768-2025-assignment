\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{abadi2016deep}
Martin Abadi, Andy Chu, Ian Goodfellow, H~Brendan McMahan, Ilya Mironov, Kunal
  Talwar, and Li~Zhang.
\newblock Deep learning with differential privacy.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC Conference on Computer
  and Communications Security}, pages 308--318. ACM, 2016.

\bibitem[Adler and Blue(2002)]{adler2002cooperative}
Jeffrey~L Adler and Victor~J Blue.
\newblock A cooperative multi-agent transportation management and route
  guidance system.
\newblock \emph{Transportation Research Part C: Emerging Technologies},
  10\penalty0 (5-6):\penalty0 433--454, 2002.

\bibitem[Antos et~al.(2008)Antos, Szepesv{\'a}ri, and Munos]{antos2008learning}
Andr{\'a}s Antos, Csaba Szepesv{\'a}ri, and R{\'e}mi Munos.
\newblock Learning near-optimal policies with bellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock \emph{Machine Learning}, 71\penalty0 (1):\penalty0 89--129, 2008.

\bibitem[Boyd et~al.(2006)Boyd, Ghosh, Prabhakar, and Shah]{boyd2006randomized}
Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, and Devavrat Shah.
\newblock Randomized gossip algorithms.
\newblock \emph{IEEE transactions on information theory}, 52\penalty0
  (6):\penalty0 2508--2530, 2006.

\bibitem[Bu et~al.(2008)Bu, Babu, De~Schutter, et~al.]{bu2008comprehensive}
Lucian Bu, Robert Babu, Bart De~Schutter, et~al.
\newblock A comprehensive survey of multiagent reinforcement learning.
\newblock \emph{IEEE Transactions on Systems, Man, and Cybernetics, Part C
  (Applications and Reviews)}, 38\penalty0 (2):\penalty0 156--172, 2008.

\bibitem[Callaway and Hiskens(2011)]{callaway2011achieving}
Duncan~S Callaway and Ian~A Hiskens.
\newblock Achieving controllability of electric loads.
\newblock \emph{Proceedings of the IEEE}, 99\penalty0 (1):\penalty0 184--199,
  2011.

\bibitem[Cattivelli et~al.(2008)Cattivelli, Lopes, and
  Sayed]{cattivelli2008diffusion}
Federico~S Cattivelli, Cassio~G Lopes, and Ali~H Sayed.
\newblock Diffusion recursive least-squares for distributed estimation over
  adaptive networks.
\newblock \emph{IEEE Transactions on Signal Processing}, 56\penalty0
  (5):\penalty0 1865--1877, 2008.

\bibitem[Cortes et~al.(2004)Cortes, Martinez, Karatas, and
  Bullo]{cortes2004coverage}
Jorge Cortes, Sonia Martinez, Timur Karatas, and Francesco Bullo.
\newblock Coverage control for mobile sensing networks.
\newblock \emph{IEEE Transactions on robotics and Automation}, 20\penalty0
  (2):\penalty0 243--255, 2004.

\bibitem[Dai et~al.(2018)Dai, Shaw, Li, Xiao, He, Liu, Chen, and
  Song]{dai2018sbeed}
Bo~Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu Chen, and
  Le~Song.
\newblock Sbeed: Convergent reinforcement learning with nonlinear function
  approximation.
\newblock In \emph{International Conference on Machine Learning}, pages
  1133--1142, 2018.

\bibitem[Dann et~al.(2014)Dann, Neumann, and Peters]{dann2014policy}
Christoph Dann, Gerhard Neumann, and Jan Peters.
\newblock Policy evaluation with temporal differences: A survey and comparison.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 809--883, 2014.

\bibitem[DeGroot(1974)]{degroot1974reaching}
Morris~H DeGroot.
\newblock Reaching a consensus.
\newblock \emph{Journal of the American Statistical Association}, 69\penalty0
  (345):\penalty0 118--121, 1974.

\bibitem[Duchi et~al.(2011)Duchi, Hazan, and Singer]{duchi2011adaptive}
John Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0
  (Jul):\penalty0 2121--2159, 2011.

\bibitem[El-Tantawy et~al.(2013)El-Tantawy, Abdulhai, and
  Abdelgawad]{el2013multiagent}
Samah El-Tantawy, Baher Abdulhai, and Hossam Abdelgawad.
\newblock Multiagent reinforcement learning for integrated network of adaptive
  traffic signal controllers (marlin-atsc): methodology and large-scale
  application on downtown toronto.
\newblock \emph{IEEE Transactions on Intelligent Transportation Systems},
  14\penalty0 (3):\penalty0 1140--1150, 2013.

\bibitem[Fax and Murray(2002)]{fax2002information}
J~Alexander Fax and Richard~M Murray.
\newblock Information flow and cooperative control of vehicle formations.
\newblock In \emph{IFAC World Congress}, volume~22, 2002.

\bibitem[Foerster et~al.(2016)Foerster, Assael, de~Freitas, and
  Whiteson]{foerster2016learning}
Jakob Foerster, Ioannis~Alexandros Assael, Nando de~Freitas, and Shimon
  Whiteson.
\newblock Learning to communicate with deep multi-agent reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2137--2145, 2016.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018counterfactual}
Jakob~N Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Ghadimi and Lan(2016)]{ghadimi2016accelerated}
Saeed Ghadimi and Guanghui Lan.
\newblock Accelerated gradient methods for nonconvex nonlinear and stochastic
  programming.
\newblock \emph{Mathematical Programming}, 156\penalty0 (1-2):\penalty0 59--99,
  2016.

\bibitem[Hong(2016)]{hong2016decomposing}
Mingyi Hong.
\newblock Decomposing linearly constrained nonconvex problems by a proximal
  primal dual approach: Algorithms, convergence, and applications.
\newblock \emph{arXiv preprint arXiv:1604.00543}, 2016.

\bibitem[Hong et~al.(2017)Hong, Hajinezhad, and Zhao]{hong2017prox}
Mingyi Hong, Davood Hajinezhad, and Ming-Min Zhao.
\newblock Prox-pda: The proximal primal-dual algorithm for fast distributed
  nonconvex optimization and learning over networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  1529--1538, 2017.

\bibitem[Hu and Wellman(2003)]{hu2003nash}
Junling Hu and Michael~P Wellman.
\newblock Nash q-learning for general-sum stochastic games.
\newblock \emph{Journal of machine learning research}, 4\penalty0
  (Nov):\penalty0 1039--1069, 2003.

\bibitem[Jiang et~al.(2018)Jiang, Dun, and Lu]{jiang2018graph}
Jiechuan Jiang, Chen Dun, and Zongqing Lu.
\newblock Graph convolutional reinforcement learning for multi-agent
  cooperation.
\newblock \emph{arXiv preprint arXiv:1810.09202}, 2018.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock \emph{arXiv preprint arXiv:1611.01236}, 2016.

\bibitem[Lauer and Riedmiller(2000)]{lauer2000algorithm}
Martin Lauer and Martin Riedmiller.
\newblock An algorithm for distributed reinforcement learning in cooperative
  multi-agent systems.
\newblock In \emph{In Proceedings of the Seventeenth International Conference
  on Machine Learning}. Citeseer, 2000.

\bibitem[Littman(1994)]{littman1994markov}
Michael~L Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{Machine Learning Proceedings 1994}, pages 157--163.
  Elsevier, 1994.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, OpenAI~Pieter Abbeel, and Igor
  Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6379--6390, 2017.

\bibitem[McMahan et~al.(2016)McMahan, Moore, Ramage, Hampson,
  et~al.]{mcmahan2016communication}
H~Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, et~al.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock \emph{arXiv preprint arXiv:1602.05629}, 2016.

\bibitem[Mo and Murray(2017)]{mo2017privacy}
Yilin Mo and Richard~M Murray.
\newblock Privacy preserving average consensus.
\newblock \emph{IEEE Transactions on Automatic Control}, 62\penalty0
  (2):\penalty0 753--765, 2017.

\bibitem[Nachum et~al.(2017)Nachum, Norouzi, Xu, and
  Schuurmans]{nachum2017bridging}
Ofir Nachum, Mohammad Norouzi, Kelvin Xu, and Dale Schuurmans.
\newblock Bridging the gap between value and policy based reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2775--2785, 2017.

\bibitem[Rabbat and Nowak(2004)]{rabbat2004distributed}
Michael Rabbat and Robert Nowak.
\newblock Distributed optimization in sensor networks.
\newblock In \emph{Proceedings of the 3rd international symposium on
  Information processing in sensor networks}, pages 20--27. ACM, 2004.

\bibitem[Raileanu et~al.(2018)Raileanu, Denton, Szlam, and
  Fergus]{raileanu2018modeling}
Roberta Raileanu, Emily Denton, Arthur Szlam, and Rob Fergus.
\newblock Modeling others using oneself in multi-agent reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1802.09640}, 2018.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, de~Witt, Farquhar, Foerster, and
  Whiteson]{rashid2018qmix}
Tabish Rashid, Mikayel Samvelyan, Christian~Schroeder de~Witt, Gregory
  Farquhar, Jakob Foerster, and Shimon Whiteson.
\newblock Qmix: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1803.11485}, 2018.

\bibitem[Shapiro et~al.(2009)Shapiro, Dentcheva, and
  Ruszczy{\'n}ski]{shapiro2009lectures}
Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczy{\'n}ski.
\newblock \emph{Lectures on stochastic programming: modeling and theory}.
\newblock SIAM, 2009.

\bibitem[Shi et~al.(2015)Shi, Ling, Wu, and Yin]{shi2015extra}
Wei Shi, Qing Ling, Gang Wu, and Wotao Yin.
\newblock Extra: An exact first-order algorithm for decentralized consensus
  optimization.
\newblock \emph{SIAM Journal on Optimization}, 25\penalty0 (2):\penalty0
  944--966, 2015.

\bibitem[Tan(1993)]{tan1993multi}
Ming Tan.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In \emph{Proceedings of the tenth international conference on machine
  learning}, pages 330--337, 1993.

\bibitem[Tieleman and Hinton()]{tielemandivide}
T~Tieleman and G~Hinton.
\newblock Divide the gradient by a running average of its recent magnitude.
  coursera: Neural networks for machine learning.
\newblock Technical report, Technical Report. Available online: https://zh.
  coursera. org/learn~â€¦.

\bibitem[Xiao et~al.(2005)Xiao, Boyd, and Lall]{xiao2005scheme}
Lin Xiao, Stephen Boyd, and Sanjay Lall.
\newblock A scheme for robust distributed sensor fusion based on average
  consensus.
\newblock In \emph{Information Processing in Sensor Networks, 2005. IPSN 2005.
  Fourth International Symposium on}, pages 63--70. IEEE, 2005.

\bibitem[Zhang et~al.(2018)Zhang, Yang, Liu, Zhang, and
  Ba{\c{s}}ar]{zhang2018fully}
Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Ba{\c{s}}ar.
\newblock Fully decentralized multi-agent reinforcement learning with networked
  agents.
\newblock \emph{International Conference on Machine Learning}, 2018.

\end{thebibliography}
