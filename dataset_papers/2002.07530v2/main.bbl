\begin{thebibliography}{}

\bibitem[Abbasi-Yadkori et~al., 2011]{abbasi2011improved}
Abbasi-Yadkori, Y., P{\'a}l, D., and Szepesv{\'a}ri, C. (2011).
\newblock {Improved Algorithms for Linear Stochastic Bandits}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2312--2320.

\bibitem[Abeille et~al., 2017]{abeille2017linear}
Abeille, M., Lazaric, A., et~al. (2017).
\newblock Linear thompson sampling revisited.
\newblock {\em Electronic Journal of Statistics}, 11(2):5165--5197.

\bibitem[Bach et~al., 2010]{bach2010self}
Bach, F. et~al. (2010).
\newblock Self-concordant analysis for logistic regression.
\newblock {\em Electronic Journal of Statistics}, 4:384--414.

\bibitem[Dani et~al., 2008]{dani2008stochastic}
Dani, V., Hayes, T.~P., and Kakade, S.~M. (2008).
\newblock Stochastic linear optimization under bandit feedback.
\newblock In {\em COLT}.

\bibitem[de~la Pena et~al., 2004]{de2004self}
de~la Pena, V.~H., Klass, M.~J., and Lai, T.~L. (2004).
\newblock Self-normalized processes: exponential inequalities, moment bounds
  and iterated logarithm laws.
\newblock {\em Annals of probability}, pages 1902--1933.

\bibitem[Dong et~al., 2019]{dongon2019}
Dong, S., Ma, T., and Roy, B.~V. (2019).
\newblock On the performance of thompson sampling on logistic bandits.
\newblock In {\em Conference on Learning Theory, {COLT} 2019}, pages
  1158--1160.

\bibitem[Dong and Van~Roy, 2018]{dong2018information}
Dong, S. and Van~Roy, B. (2018).
\newblock An information-theoretic analysis for thompson sampling with many
  actions.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4157--4165.

\bibitem[Dumitrascu et~al., 2018]{dumitrascu2018pg}
Dumitrascu, B., Feng, K., and Engelhardt, B. (2018).
\newblock Pg-ts: Improved thompson sampling for logistic contextual bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4624--4633.

\bibitem[Filippi et~al., 2010]{filippi2010parametric}
Filippi, S., Cappe, O., Garivier, A., and Szepesv{\'a}ri, C. (2010).
\newblock {Parametric Bandits: The Generalized Linear Case}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  586--594.

\bibitem[Jun et~al., 2017]{jun2017scalable}
Jun, K.-S., Bhargava, A., Nowak, R., and Willett, R. (2017).
\newblock Scalable generalized linear bandits: Online computation and hashing.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  99--109.

\bibitem[Lattimore and Szepesv{\'a}ri, 2018]{lattimore2018bandit}
Lattimore, T. and Szepesv{\'a}ri, C. (2018).
\newblock Bandit algorithms.
\newblock {\em preprint}.

\bibitem[Li et~al., 2017]{li2017provably}
Li, L., Lu, Y., and Zhou, D. (2017).
\newblock Provably optimal algorithms for generalized linear contextual
  bandits.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2071--2080. JMLR. org.

\bibitem[Rusmevichientong and Tsitsiklis, 2010]{rusmevichientong2010linearly}
Rusmevichientong, P. and Tsitsiklis, J.~N. (2010).
\newblock Linearly parameterized bandits.
\newblock {\em Mathematics of Operations Research}, 35(2):395--411.

\bibitem[Russo and Van~Roy, 2013]{russo2013eluder}
Russo, D. and Van~Roy, B. (2013).
\newblock Eluder dimension and the sample complexity of optimistic exploration.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2256--2264.

\bibitem[Russo and Van~Roy, 2014]{russo2014learning}
Russo, D. and Van~Roy, B. (2014).
\newblock Learning to optimize via posterior sampling.
\newblock {\em Mathematics of Operations Research}, 39(4):1221--1243.

\bibitem[Valko et~al., 2013]{valko2013finite}
Valko, M., Korda, N., Munos, R., Flaounas, I., and Cristianini, N. (2013).
\newblock Finite-time analysis of kernelised contextual bandits.
\newblock In {\em Proceedings of the Twenty-Ninth Conference on Uncertainty in
  Artificial Intelligence}, pages 654--663.

\end{thebibliography}
