\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baevski et~al.(2020{\natexlab{a}})Baevski, Schneider, and
  Auli]{Baevski2020vqwav2vecSL}
Baevski, A., Schneider, S., and Auli, M.
\newblock vq-wav2vec: Self-supervised learning of discrete speech
  representations.
\newblock \emph{ArXiv}, abs/1910.05453, 2020{\natexlab{a}}.

\bibitem[Baevski et~al.(2020{\natexlab{b}})Baevski, Zhou, rahman Mohamed, and
  Auli]{Baevski2020wav2vec2A}
Baevski, A., Zhou, H., rahman Mohamed, A., and Auli, M.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock \emph{ArXiv}, abs/2006.11477, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pp.\
  1597--1607. PMLR, 2020.

\bibitem[Chen et~al.(2021)Chen, Wu, Wu, and yi~Lee]{Chen2021AgainVCAO}
Chen, Y.-H., Wu, D.-Y., Wu, T.-H., and yi~Lee, H.
\newblock Again-vc: A one-shot voice conversion using activation guidance and
  adaptive instance normalization.
\newblock \emph{ICASSP 2021 - 2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  5954--5958, 2021.

\bibitem[Choi et~al.(2021)Choi, Lee, Kim, Lee, Heo, and Lee]{choi2021neural}
Choi, H.-S., Lee, J., Kim, W., Lee, J.~H., Heo, H., and Lee, K.
\newblock Neural analysis and synthesis: Reconstructing speech from
  self-supervised representations.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Choi et~al.(2018)Choi, Choi, Kim, Ha, Kim, and
  Choo]{Choi2018StarGANUG}
Choi, Y., Choi, M.-J., Kim, M.~S., Ha, J.-W., Kim, S., and Choo, J.
\newblock Stargan: Unified generative adversarial networks for multi-domain
  image-to-image translation.
\newblock \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  8789--8797, 2018.

\bibitem[Chou et~al.(2018)Chou, chieh Yeh, yi~Lee, and
  Lee]{Chou2018MultitargetVC}
Chou, J.-C., chieh Yeh, C., yi~Lee, H., and Lee, L.-S.
\newblock Multi-target voice conversion without parallel data by adversarially
  learning disentangled audio representations.
\newblock In \emph{INTERSPEECH}, 2018.

\bibitem[Chou et~al.(2019)Chou, chieh Yeh, and yi~Lee]{Chou2019OneshotVC}
Chou, J.-C., chieh Yeh, C., and yi~Lee, H.
\newblock One-shot voice conversion by separating speaker and content
  representations with instance normalization.
\newblock In \emph{INTERSPEECH}, 2019.

\bibitem[Chung \& Glass(2020)Chung and Glass]{Chung2020GenerativePF}
Chung, Y.-A. and Glass, J.~R.
\newblock Generative pre-training for speech with autoregressive predictive
  coding.
\newblock \emph{ICASSP 2020 - 2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  3497--3501, 2020.

\bibitem[Chung et~al.(2019)Chung, Hsu, Tang, and Glass]{Chung2019AnUA}
Chung, Y.-A., Hsu, W.-N., Tang, H., and Glass, J.~R.
\newblock An unsupervised autoregressive model for speech representation
  learning.
\newblock In \emph{INTERSPEECH}, 2019.

\bibitem[Chung et~al.(2021)Chung, Zhang, Han, Chiu, Qin, Pang, and
  Wu]{Chung2021W2vBERTCC}
Chung, Y.-A., Zhang, Y., Han, W., Chiu, C.-C., Qin, J., Pang, R., and Wu, Y.
\newblock W2v-bert: Combining contrastive learning and masked language modeling
  for self-supervised speech pre-training.
\newblock \emph{ArXiv}, abs/2108.06209, 2021.

\bibitem[Dunbar et~al.(2021)Dunbar, Bernard, Hamilakis, Nguyen, de~Seyssel,
  Roz'e, Rivi{\`e}re, Kharitonov, and Dupoux]{Dunbar2021TheZR}
Dunbar, E., Bernard, M., Hamilakis, N., Nguyen, T.~A., de~Seyssel, M., Roz'e,
  P., Rivi{\`e}re, M., Kharitonov, E., and Dupoux, E.
\newblock The zero resource speech challenge 2021: Spoken language modelling.
\newblock \emph{Interspeech 2021}, 2021.

\bibitem[Eide \& Gish(1996)Eide and Gish]{eide1996parametric}
Eide, E. and Gish, H.
\newblock Parametric approach to vocal tract length normalization.
\newblock In \emph{ICASSP}, pp.\  346--9, 1996.

\bibitem[Heigold et~al.(2016)Heigold, Moreno, Bengio, and
  Shazeer]{Heigold2016EndtoendTS}
Heigold, G., Moreno, I., Bengio, S., and Shazeer, N.~M.
\newblock End-to-end text-dependent speaker verification.
\newblock \emph{2016 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5115--5119, 2016.

\bibitem[Hsu et~al.(2016)Hsu, Hwang, Wu, Tsao, and Wang]{hsu2016voice}
Hsu, C.-C., Hwang, H.-T., Wu, Y.-C., Tsao, Y., and Wang, H.-M.
\newblock Voice conversion from non-parallel corpora using variational
  auto-encoder.
\newblock In \emph{Signal and Information Processing Association Annual Summit
  and Conference (APSIPA), 2016 Asia-Pacific}, pp.\  1--6. IEEE, 2016.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and
  Mohamed]{Hsu2021HuBERTSS}
Hsu, W.-N., Bolte, B., Tsai, Y.-H.~H., Lakhotia, K., Salakhutdinov, R., and
  Mohamed, A.
\newblock Hubert: Self-supervised speech representation learning by masked
  prediction of hidden units.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 29:\penalty0 3451--3460, 2021.

\bibitem[Ito \& Johnson(2017)Ito and Johnson]{ljspeech17}
Ito, K. and Johnson, L.
\newblock The lj speech dataset.
\newblock \url{https://keithito.com/LJ-Speech-Dataset/}, 2017.

\bibitem[Kameoka et~al.(2018)Kameoka, Kaneko, Tanaka, and
  Hojo]{Kameoka2018StarGANVCNM}
Kameoka, H., Kaneko, T., Tanaka, K., and Hojo, N.
\newblock Stargan-vc: non-parallel many-to-many voice conversion using star
  generative adversarial networks.
\newblock \emph{2018 IEEE Spoken Language Technology Workshop (SLT)}, pp.\
  266--273, 2018.

\bibitem[Kameoka et~al.(2019)Kameoka, Kaneko, Tanaka, and
  Hojo]{kameoka2018acvae}
Kameoka, H., Kaneko, T., Tanaka, K., and Hojo, N.
\newblock Acvae-vc: Non-parallel voice conversion with auxiliary classifier
  variational autoencoder.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 27\penalty0 (9):\penalty0 1432--1443, 2019.
\newblock \doi{10.1109/TASLP.2019.2917232}.

\bibitem[Kaneko \& Kameoka(2018)Kaneko and Kameoka]{Kaneko2018CycleGANVCNV}
Kaneko, T. and Kameoka, H.
\newblock Cyclegan-vc: Non-parallel voice conversion using cycle-consistent
  adversarial networks.
\newblock \emph{2018 26th European Signal Processing Conference (EUSIPCO)},
  pp.\  2100--2104, 2018.

\bibitem[Kaneko et~al.(2019{\natexlab{a}})Kaneko, Kameoka, Tanaka, and
  Hojo]{Kaneko2019CycleganVC2IC}
Kaneko, T., Kameoka, H., Tanaka, K., and Hojo, N.
\newblock Cyclegan-vc2: Improved cyclegan-based non-parallel voice conversion.
\newblock \emph{ICASSP 2019 - 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  6820--6824, 2019{\natexlab{a}}.

\bibitem[Kaneko et~al.(2019{\natexlab{b}})Kaneko, Kameoka, Tanaka, and
  Hojo]{kaneko2019stargan}
Kaneko, T., Kameoka, H., Tanaka, K., and Hojo, N.
\newblock {StarGAN-VC2}: Rethinking conditional methods for {StarGAN}-based
  voice conversion.
\newblock \emph{Proc. Interspeech 2019}, pp.\  679--683, 2019{\natexlab{b}}.

\bibitem[Kharitonov et~al.(2021)Kharitonov, Rivi{\`e}re, Synnaeve, Wolf,
  Mazar'e, Douze, and Dupoux]{Kharitonov2021DataAC}
Kharitonov, E., Rivi{\`e}re, M., Synnaeve, G., Wolf, L., Mazar'e, P.-E., Douze,
  M., and Dupoux, E.
\newblock Data augmenting contrastive learning of speech representations in the
  time domain.
\newblock \emph{2021 IEEE Spoken Language Technology Workshop (SLT)}, pp.\
  215--222, 2021.

\bibitem[Kong et~al.(2020)Kong, Kim, and Bae]{Kong2020HiFiGANGA}
Kong, J., Kim, J., and Bae, J.
\newblock Hifi-gan: Generative adversarial networks for efficient and high
  fidelity speech synthesis.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  17022--17033. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf}.

\bibitem[Lakhotia et~al.(2021)Lakhotia, Kharitonov, Hsu, Adi, Polyak, Bolte,
  Nguyen, Copet, Baevski, Mohamed, and Dupoux]{Lakhotia2021OnGS}
Lakhotia, K., Kharitonov, E., Hsu, W.-N., Adi, Y., Polyak, A., Bolte, B.,
  Nguyen, T., Copet, J., Baevski, A., Mohamed, A.~B., and Dupoux, E.
\newblock On generative spoken language modeling from raw audio.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:\penalty0 1336--1354, 2021.

\bibitem[Lee \& Kim(2021)Lee and Kim]{Lee2021VoiceMixerAV}
Lee, S.-H. and Kim, J.-H.
\newblock Voicemixer: Adversarial voice style mixup.
\newblock 2021.

\bibitem[Ling \& Liu(2020)Ling and Liu]{Ling2020DeCoAR2D}
Ling, S. and Liu, Y.
\newblock Decoar 2.0: Deep contextualized acoustic representations with vector
  quantization.
\newblock \emph{ArXiv}, abs/2012.06659, 2020.

\bibitem[Liu et~al.(2020)Liu, wen Yang, Chi, Hsu, and
  yi~Lee]{Liu2020MockingjayUS}
Liu, A.~T., wen Yang, S., Chi, P.-H., Hsu, P.-C., and yi~Lee, H.
\newblock Mockingjay: Unsupervised speech representation learning with deep
  bidirectional transformer encoders.
\newblock \emph{ICASSP 2020 - 2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  6419--6423, 2020.

\bibitem[Liu et~al.(2021)Liu, Li, and yi~Lee]{Liu2021TERASL}
Liu, A.~T., Li, S.-W., and yi~Lee, H.
\newblock Tera: Self-supervised learning of transformer encoder representation
  for speech.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 29:\penalty0 2351--2366, 2021.

\bibitem[Ott et~al.(2019)Ott, Edunov, Baevski, Fan, Gross, Ng, Grangier, and
  Auli]{Ott2019fairseqAF}
Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., Grangier, D., and
  Auli, M.
\newblock fairseq: A fast, extensible toolkit for sequence modeling.
\newblock In \emph{NAACL}, 2019.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{Panayotov2015LibrispeechAA}
Panayotov, V., Chen, G., Povey, D., and Khudanpur, S.
\newblock Librispeech: An asr corpus based on public domain audio books.
\newblock \emph{2015 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5206--5210, 2015.

\bibitem[Pascual et~al.(2019)Pascual, Ravanelli, Serr{\`a}, Bonafonte, and
  Bengio]{Pascual2019LearningPS}
Pascual, S., Ravanelli, M., Serr{\`a}, J., Bonafonte, A., and Bengio, Y.
\newblock Learning problem-agnostic speech representations from multiple
  self-supervised tasks.
\newblock In \emph{INTERSPEECH}, 2019.

\bibitem[Polyak et~al.(2021)Polyak, Adi, Copet, Kharitonov, Lakhotia, Hsu,
  Mohamed, and Dupoux]{polyak2021speech}
Polyak, A., Adi, Y., Copet, J., Kharitonov, E., Lakhotia, K., Hsu, W.-N.,
  Mohamed, A., and Dupoux, E.
\newblock {Speech Resynthesis from Discrete Disentangled Self-Supervised
  Representations}.
\newblock In \emph{Proc. Interspeech 2021}, 2021.

\bibitem[Qian et~al.(2019)Qian, Zhang, Chang, Yang, and
  Hasegawa-Johnson]{qian2019autovc}
Qian, K., Zhang, Y., Chang, S., Yang, X., and Hasegawa-Johnson, M.
\newblock Autovc: Zero-shot voice style transfer with only autoencoder loss.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5210--5219. PMLR, 2019.

\bibitem[Qian et~al.(2020{\natexlab{a}})Qian, Jin, Hasegawa-Johnson, and
  Mysore]{qian2020f0}
Qian, K., Jin, Z., Hasegawa-Johnson, M., and Mysore, G.~J.
\newblock {F0}-consistent many-to-many non-parallel voice conversion via
  conditional autoencoder.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  6284--6288. IEEE, 2020{\natexlab{a}}.

\bibitem[Qian et~al.(2020{\natexlab{b}})Qian, Zhang, Chang, Hasegawa-Johnson,
  and Cox]{qian2020unsupervised}
Qian, K., Zhang, Y., Chang, S., Hasegawa-Johnson, M., and Cox, D.
\newblock Unsupervised speech decomposition via triple information bottleneck.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7836--7846. PMLR, 2020{\natexlab{b}}.

\bibitem[Qian et~al.(2021)Qian, Zhang, Chang, Xiong, Gan, Cox, and
  Hasegawa-Johnson]{Qian2021GlobalPS}
Qian, K., Zhang, Y., Chang, S., Xiong, J., Gan, C., Cox, D., and
  Hasegawa-Johnson, M.~A.
\newblock Global prosody style transfer without text transcriptions.
\newblock In \emph{ICML}, 2021.

\bibitem[Ravanelli et~al.(2020)Ravanelli, Zhong, Pascual, Swietojanski,
  Monteiro, Trmal, and Bengio]{Ravanelli2020MultiTaskSL}
Ravanelli, M., Zhong, J., Pascual, S., Swietojanski, P., Monteiro, J., Trmal,
  J., and Bengio, Y.
\newblock Multi-task self-supervised learning for robust speech recognition.
\newblock \emph{ICASSP 2020 - 2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  6989--6993, 2020.

\bibitem[Rivi{\`e}re \& Dupoux(2021)Rivi{\`e}re and
  Dupoux]{Rivire2021TowardsUL}
Rivi{\`e}re, M. and Dupoux, E.
\newblock Towards unsupervised learning of speech features in the wild.
\newblock \emph{2021 IEEE Spoken Language Technology Workshop (SLT)}, pp.\
  156--163, 2021.

\bibitem[Schneider et~al.(2019)Schneider, Baevski, Collobert, and
  Auli]{Schneider2019wav2vecUP}
Schneider, S., Baevski, A., Collobert, R., and Auli, M.
\newblock wav2vec: Unsupervised pre-training for speech recognition.
\newblock In \emph{INTERSPEECH}, 2019.

\bibitem[Stevens(1987)]{stevens1987relational}
Stevens, K.~N.
\newblock Relational properties as perceptual correlates of phonetic features.
\newblock In \emph{Proc. Eleventh Int. Conf. Phonetic Sciences}, volume~4, pp.\
   352--356, Talinn, Estonia, 1987.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Vinyals, and
  Kavukcuoglu]{Oord2017NeuralDR}
van~den Oord, A., Vinyals, O., and Kavukcuoglu, K.
\newblock Neural discrete representation learning.
\newblock In \emph{NIPS}, 2017.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and
  Vinyals]{Oord2018RepresentationLW}
van~den Oord, A., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{ArXiv}, abs/1807.03748, 2018.

\bibitem[Wan et~al.(2018)Wan, Wang, Papir, and Moreno]{wan2018generalized}
Wan, L., Wang, Q., Papir, A., and Moreno, I.~L.
\newblock Generalized end-to-end loss for speaker verification.
\newblock In \emph{2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  4879--4883. IEEE, 2018.

\bibitem[Wang et~al.(2021)Wang, Wu, Chen, Liu, Li, Qian, and
  Yang]{Wang2021SelfSupervisedLF}
Wang, C., Wu, Y., Chen, S., Liu, S., Li, J., Qian, Y., and Yang, Z.
\newblock Self-supervised learning for speech recognition with intermediate
  layer supervision.
\newblock \emph{ArXiv}, abs/2112.08778, 2021.

\bibitem[Wang et~al.(2020)Wang, Tang, and Livescu]{Wang2020UnsupervisedPO}
Wang, W., Tang, Q., and Livescu, K.
\newblock Unsupervised pre-training of bidirectional speech encoders via masked
  reconstruction.
\newblock \emph{ICASSP 2020 - 2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  6889--6893, 2020.

\bibitem[Yang et~al.(2021)Yang, Chi, Chuang, Lai, Lakhotia, Lin, Liu, Shi,
  Chang, Lin, et~al.]{yang2021superb}
Yang, S.-w., Chi, P.-H., Chuang, Y.-S., Lai, C.-I.~J., Lakhotia, K., Lin,
  Y.~Y., Liu, A.~T., Shi, J., Chang, X., Lin, G.-T., et~al.
\newblock Superb: Speech processing universal performance benchmark.
\newblock \emph{arXiv preprint arXiv:2105.01051}, 2021.

\bibitem[Zhang et~al.(2020)Zhang, Qin, Park, Han, Chiu, Pang, Le, and
  Wu]{Zhang2020PushingTL}
Zhang, Y., Qin, J., Park, D.~S., Han, W., Chiu, C.-C., Pang, R., Le, Q.~V., and
  Wu, Y.
\newblock Pushing the limits of semi-supervised learning for automatic speech
  recognition.
\newblock \emph{ArXiv}, abs/2010.10504, 2020.

\bibitem[Zhu et~al.(2017)Zhu, Park, Isola, and Efros]{Zhu2017UnpairedIT}
Zhu, J.-Y., Park, T., Isola, P., and Efros, A.~A.
\newblock Unpaired image-to-image translation using cycle-consistent
  adversarial networks.
\newblock \emph{2017 IEEE International Conference on Computer Vision (ICCV)},
  pp.\  2242--2251, 2017.

\bibitem[Zhu et~al.(2018)Zhu, Lu, Zheng, Guo, Zhang, Wang, and
  Yu]{10.1145/3209978.3210080}
Zhu, Y., Lu, S., Zheng, L., Guo, J., Zhang, W., Wang, J., and Yu, Y.
\newblock Texygen: A benchmarking platform for text generation models.
\newblock In \emph{The 41st International ACM SIGIR Conference on Research \&
  Development in Information Retrieval}, SIGIR '18, pp.\  1097–1100, New
  York, NY, USA, 2018. Association for Computing Machinery.
\newblock ISBN 9781450356572.
\newblock \doi{10.1145/3209978.3210080}.
\newblock URL \url{https://doi.org/10.1145/3209978.3210080}.

\end{thebibliography}
