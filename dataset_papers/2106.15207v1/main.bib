@article{bousquet2002stability,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={The Journal of Machine Learning Research},
  volume={2},
  pages={499--526},
  year={2002},
  publisher={JMLR. org}
}

@article{shalev2010learnability,
  title={Learnability, stability and uniform convergence},
  author={Shalev-Shwartz, Shai and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={2635--2670},
  year={2010},
  publisher={JMLR. org}
}

@inproceedings{hardt2016train,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
  booktitle={International Conference on Machine Learning},
  pages={1225--1234},
  year={2016},
  organization={PMLR}
}


@article{hazan2019introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={arXiv preprint arXiv:1909.05207},
  year={2019}
}

@inproceedings{arora2013stochastic,
  title={Stochastic optimization of PCA with capped MSG},
  author={Arora, Raman and Cotter, Andrew and Srebro, Nathan},
  booktitle={Proceedings of the 26th International Conference on Neural Information Processing Systems-Volume 2},
  pages={1815--1823},
  year={2013}
}

@inproceedings{nagaraj2019sgd,
  title={Sgd without replacement: Sharper rates for general smooth convex functions},
  author={Nagaraj, Dheeraj and Jain, Prateek and Netrapalli, Praneeth},
  booktitle={International Conference on Machine Learning},
  pages={4703--4711},
  year={2019},
  organization={PMLR}
}


@inproceedings{garber2020online,
  title={Online Convex Optimization in the Random Order Model},
  author={Garber, Dan and Korcia, Gal and Levy, Kfir},
  booktitle={International Conference on Machine Learning},
  pages={3387--3396},
  year={2020},
  organization={PMLR}
}

@inproceedings{harvey2019tight,
  title={Tight analyses for non-smooth stochastic gradient descent},
  author={Harvey, Nicholas JA and Liaw, Christopher and Plan, Yaniv and Randhawa, Sikander},
  booktitle={Conference on Learning Theory},
  pages={1579--1613},
  year={2019},
  organization={PMLR}
}

@article{vitter1985random,
  title={Random sampling with a reservoir},
  author={Vitter, Jeffrey S},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={11},
  number={1},
  pages={37--57},
  year={1985},
  publisher={ACM New York, NY, USA}
}



@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={Proceedings of the 20th international conference on machine learning (icml-03)},
  pages={928--936},
  year={2003}
}



@article{ahn2020sgd,
  title={SGD with shuffling: optimal rates without component convexity and large epoch requirements},
  author={Ahn, Kwangjun and Yun, Chulhee and Sra, Suvrit},
  journal={arXiv preprint arXiv:2006.06946},
  year={2020}
}


@article{bubeck2015convex,
  title={Convex Optimization: Algorithms and Complexity},
  author={Bubeck, S{\'e}bastien and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers, Inc.}
}


@inproceedings{shamir2016without,
  title={Without-replacement sampling for stochastic gradient methods},
  author={Shamir, Ohad},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={46--54},
  year={2016}
}

@inproceedings{haochen2019random,
  title={Random shuffling beats sgd after finite epochs},
  author={Haochen, Jeff and Sra, Suvrit},
  booktitle={International Conference on Machine Learning},
  pages={2624--2633},
  year={2019},
  organization={PMLR}
}


@article{gurbuzbalaban2019random,
  title={Why random reshuffling beats stochastic gradient descent},
  author={G{\"u}rb{\"u}zbalaban, Mert and Ozdaglar, Asu and Parrilo, Pablo A},
  journal={Mathematical Programming},
  pages={1--36},
  year={2019},
  publisher={Springer}
}

@inproceedings{safran2020good,
  title={How good is SGD with random shuffling?},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={3250--3284},
  year={2020},
  organization={PMLR}
}

@article{nguyen2020unified,
  title={A unified convergence analysis for shuffling-type gradient methods},
  author={Nguyen, Lam M and Tran-Dinh, Quoc and Phan, Dzung T and Nguyen, Phuong Ha and van Dijk, Marten},
  journal={arXiv preprint arXiv:2002.08246},
  year={2020}
}

@inproceedings{rajput2020closing,
  title={Closing the convergence gap of SGD without replacement},
  author={Rajput, Shashank and Gupta, Anant and Papailiopoulos, Dimitris},
  booktitle={International Conference on Machine Learning},
  pages={7964--7973},
  year={2020},
  organization={PMLR}
}


@article{hazan2007logarithmic,
  title={Logarithmic regret algorithms for online convex optimization},
  author={Hazan, Elad and Agarwal, Amit and Kale, Satyen},
  journal={Machine Learning},
  volume={69},
  number={2-3},
  pages={169--192},
  year={2007},
  publisher={Springer}
}

@inproceedings{takimoto2000minimax,
  title={The minimax strategy for Gaussian density estimation},
  author={Takimoto, Eiji and Warmuth, Manfred},
  booktitle={Proc. 13th Annu. Conference on Comput. Learning Theory},
  pages={100--106},
  year={2000},
  organization={Citeseer}
}

@inproceedings{hazan2011beyond,
  title={Beyond the regret minimization barrier: an optimal algorithm for stochastic strongly-convex optimization},
  author={Hazan, Elad and Kale, Satyen},
  booktitle={Proceedings of the 24th Annual Conference on Learning Theory},
  pages={421--436},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{rogers1978finite,
  title={A finite sample distribution-free performance bound for local discrimination rules},
  author={Rogers, William H and Wagner, Terry J},
  journal={The Annals of Statistics},
  pages={506--514},
  year={1978},
  publisher={JSTOR}
}

@article{devroye1979distributiona,
  title={Distribution-free inequalities for the deleted and holdout error estimates},
  author={Devroye, Luc and Wagner, Terry},
  journal={IEEE Transactions on Information Theory},
  volume={25},
  number={2},
  pages={202--207},
  year={1979},
  publisher={IEEE}
}

@article{devroye1979distributionb,
  title={Distribution-free performance bounds with the resubstitution error estimate (Corresp.)},
  author={Devroye, Luc and Wagner, T},
  journal={IEEE Transactions on Information Theory},
  volume={25},
  number={2},
  pages={208--210},
  year={1979},
  publisher={IEEE}
}

@inproceedings{london2017pac,
  title={A PAC-Bayesian analysis of randomized learning with application to stochastic gradient descent},
  author={London, Ben},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={2935--2944},
  year={2017}
}

@inproceedings{feldman2019high,
  title={High probability generalization bounds for uniformly stable algorithms with nearly optimal rate},
  author={Feldman, Vitaly and Vondrak, Jan},
  booktitle={Conference on Learning Theory},
  pages={1270--1279},
  year={2019},
  organization={PMLR}
}

@article{bassily2020stability,
  title={Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses},
  author={Bassily, Raef and Feldman, Vitaly and Guzm{\'a}n, Crist{\'o}bal and Talwar, Kunal},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{mackey2014matrix,
  title={Matrix concentration inequalities via the method of exchangeable pairs},
  author={Mackey, Lester and Jordan, Michael I and Chen, Richard Y and Farrell, Brendan and Tropp, Joel A and others},
  journal={Annals of Probability},
  volume={42},
  number={3},
  pages={906--945},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}



@incollection{nedic2001convergence,
  title={Convergence rate of incremental subgradient algorithms},
  author={Nedi{\'c}, Angelia and Bertsekas, Dimitri},
  booktitle={Stochastic optimization: algorithms and applications},
  pages={223--264},
  year={2001},
  publisher={Springer}
}


@inproceedings{schneider2016probability,
  title={Probability inequalities for kernel embeddings in sampling without replacement},
  author={Schneider, Markus},
  booktitle={Artificial Intelligence and Statistics},
  pages={66--74},
  year={2016},
  organization={PMLR}
}