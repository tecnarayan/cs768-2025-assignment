\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[icl(2017)]{iclr17}
\emph{Proceedings of the International Conference on Learning Representations
  (ICLR'17)}, 2017.
\newblock Published online: \url{iclr.cc}.

\bibitem[Bach \& Blei(2015)Bach and Blei]{icml15}
Bach, F. and Blei, D. (eds.).
\newblock \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML'15)}, volume~37, 2015. Omnipress.

\bibitem[Baldi et~al.(2014)Baldi, Sadowski, and Whiteson]{baldi2014searching}
Baldi, P., Sadowski, P., and Whiteson, D.
\newblock Searching for exotic particles in high-energy physics with deep
  learning.
\newblock \emph{Nature communications}, 5, 2014.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra-nips11a}
Bergstra, J., Bardenet, R., Bengio, Y., and K{\'e}gl, B.
\newblock Algorithms for hyper-parameter optimization.
\newblock In Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., and
  Weinberger, K. (eds.), \emph{Proceedings of the 25th International Conference
  on Advances in Neural Information Processing Systems (NIPS'11)}, pp.\
  2546--2554, 2011.

\bibitem[Bergstra et~al.(2014)Bergstra, Yamins, and Cox]{bergstra-icml13a}
Bergstra, J., Yamins, D., and Cox, D.
\newblock Making a science of model search: Hyperparameter optimization in
  hundreds of dimensions for vision architectures.
\newblock In Dasgupta, S. and McAllester, D. (eds.), \emph{Proceedings of the
  30th International Conference on Machine Learning (ICML'13)}, pp.\  115--123.
  Omnipress, 2014.

\bibitem[Bertrand et~al.(2017)Bertrand, Ardon, Perrot, and
  Bloch]{bertrandhyperparameter}
Bertrand, H., Ardon, R., Perrot, M., and Bloch, I.
\newblock Hyperparameter optimization of deep neural networks: Combining
  hyperband with {B}ayesian model selection.
\newblock \emph{Proceedings of Conf√©rence sur l'Apprentissage Automatique (CAP
  2017)}, 2017.

\bibitem[Brochu et~al.(2010)Brochu, Cora, and de~Freitas]{brochu-arXiv10a}
Brochu, E., Cora, V., and de~Freitas, N.
\newblock A tutorial on {Bayesian} optimization of expensive cost functions,
  with application to active user modeling and hierarchical reinforcement
  learning.
\newblock arXiv:1012.2599, 2010.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman-corr16}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym, 2016.

\bibitem[Cattral et~al.(2002)Cattral, Oppacher, and
  Deugo]{cattral2002evolutionary}
Cattral, R., Oppacher, F., and Deugo, D.
\newblock Evolutionary data mining with automatic rule generalization.
\newblock \emph{Recent Advances in Computers, Computing and Communications},
  1\penalty0 (1):\penalty0 296--300, 2002.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{chen-icml14}
Chen, T., Fox, E., and Guestrin, C.
\newblock Stochastic gradient {H}amiltonian {M}onte {C}arlo.
\newblock In Xing, E. and Jebara, T. (eds.), \emph{Proceedings of the 31th
  International Conference on Machine Learning, (ICML'14)}. Omnipress, 2014.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017improved}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Eggensperger et~al.(2013)Eggensperger, Feurer, Hutter, Bergstra,
  Snoek, Hoos, and Leyton-Brown]{eggensperger-bayesopt13}
Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H.,
  and Leyton-Brown, K.
\newblock Towards an empirical foundation for assessing {Bayesian} optimization
  of hyperparameters.
\newblock In \emph{NIPS Workshop on {B}ayesian Optimization in Theory and
  Practice (BayesOpt'13)}, 2013.

\bibitem[Eggensperger et~al.(2015)Eggensperger, Hutter, Hoos, and
  Leyton-Brown]{eggensperger-aaai15}
Eggensperger, K., Hutter, F., Hoos, H., and Leyton-Brown, K.
\newblock Efficient benchmarking of hyperparameter optimizers via surrogates.
\newblock In Bonet, B. and Koenig, S. (eds.), \emph{Proceedings of the
  Twenty-nineth National Conference on Artificial Intelligence (AAAI'15)}, pp.\
   1114--1120. AAAI Press, 2015.

\bibitem[Frey \& Slate(1991)Frey and Slate]{Frey1991}
Frey, P.~W. and Slate, D.~J.
\newblock Letter recognition using holland-style adaptive classifiers.
\newblock \emph{Machine Learning}, 6\penalty0 (2):\penalty0 161--182, Mar 1991.

\bibitem[Gastaldi(2017)]{gastaldi2017shake}
Gastaldi, X.
\newblock Shake-shake regularization.
\newblock \emph{arXiv preprint arXiv:1705.07485}, 2017.

\bibitem[Henderson et~al.(2017)Henderson, Islam, Bachman, Pineau, Precup, and
  Meger]{henderson2017deep}
Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., and Meger, D.
\newblock Deep reinforcement learning that matters.
\newblock \emph{arXiv preprint arXiv:1709.06560}, 2017.

\bibitem[Hern{\'{a}}ndez{-}Lobato \& Adams(2015)Hern{\'{a}}ndez{-}Lobato and
  Adams]{lobato-icml15}
Hern{\'{a}}ndez{-}Lobato, J. and Adams, R.
\newblock Probabilistic backpropagation for scalable learning of {Bayesian}
  neural networks.
\newblock In  \citet{icml15}.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and Leyton-Brown]{hutter-lion11a}
Hutter, F., Hoos, H., and Leyton-Brown, K.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In Coello, C. (ed.), \emph{Proceedings of the Fifth International
  Conference on Learning and Intelligent Optimization (LION'11)}, volume 6683
  of \emph{Lecture Notes in Computer Science}, pp.\  507--523. Springer-Verlag,
  2011.

\bibitem[Jamieson \& Talwalkar(2016)Jamieson and Talwalkar]{jamieson-aistats16}
Jamieson, K. and Talwalkar, A.
\newblock Non-stochastic best arm identification and hyperparameter
  optimization.
\newblock In \emph{Proceedings of the Seventeenth International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, 2016.

\bibitem[Kandasamy et~al.(2017)Kandasamy, Dasarathy, Schneider, and
  Poczos]{kandasamy2017multi}
Kandasamy, K., Dasarathy, G., Schneider, J., and Poczos, B.
\newblock Multi-fidelity bayesian optimisation with continuous approximations.
\newblock \emph{arXiv preprint arXiv:1703.06240}, 2017.

\bibitem[Klein et~al.(2017{\natexlab{a}})Klein, Falkner, Bartels, Hennig, and
  Hutter]{klein-ejs17}
Klein, A., Falkner, S., Bartels, S., Hennig, P., and Hutter, F.
\newblock Fast {B}ayesian hyperparameter optimization on large datasets.
\newblock \emph{Electron. J. Statist.}, 11\penalty0 (2):\penalty0 4945--4968,
  2017{\natexlab{a}}.

\bibitem[Klein et~al.(2017{\natexlab{b}})Klein, Falkner, Mansur, and
  Hutter]{klein-bayesopt17}
Klein, A., Falkner, S., Mansur, N., and Hutter, F.
\newblock Robo: A flexible and robust bayesian optimization framework in
  python.
\newblock In \emph{NIPS 2017 Bayesian Optimization Workshop}, December
  2017{\natexlab{b}}.

\bibitem[Klein et~al.(2017{\natexlab{c}})Klein, Falkner, Springenberg, and
  Hutter]{klein-iclr17}
Klein, A., Falkner, S., Springenberg, J.~T., and Hutter, F.
\newblock Learning curve prediction with {Bayesian} neural networks.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR'17)} \citet{iclr17}.
\newblock Published online: \url{iclr.cc}.

\bibitem[Kohavi(1996)]{kohavi1996scaling}
Kohavi, R.
\newblock Scaling up the accuracy of naive-bayes classifiers: A decision-tree
  hybrid.
\newblock In \emph{KDD}, volume~96, pp.\  202--207, 1996.

\bibitem[{LeCun} et~al.(2001){LeCun}, Bottou, Bengio, and
  Haffner]{lecun-isp01a}
{LeCun}, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock In Haykin, S. and Kosko, B. (eds.), \emph{Intelligent Signal
  Processing}, pp.\  306--351. IEEE Press, 2001.
\newblock URL \url{http://www.iro.umontreal.ca/~lisa/pointeurs/lecun-01a.pdf}.

\bibitem[Li et~al.(2017)Li, Jamieson, DeSalvo, Rostamizadeh, and
  Talwalkar]{li-iclr17}
Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A.
\newblock Hyperband: Bandit-based configuration evaluation for hyperparameter
  optimization.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR'17)} \citet{iclr17}.
\newblock Published online: \url{iclr.cc}.

\bibitem[Li et~al.(2018)Li, Jamieson, Rostamizadeh, Gonina, Hardt, Recht, and
  Talwalkar]{li2018massively}
Li, L., Jamieson, K., Rostamizadeh, A., Gonina, K., Hardt, M., Recht, B., and
  Talwalkar, A.
\newblock Massively parallel hyperparameter tuning, 2018.
\newblock URL \url{https://openreview.net/forum?id=S1Y7OOlRZ}.

\bibitem[Lichman(2013)]{lichman-13}
Lichman, M.
\newblock {UCI} machine learning repository, 2013.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Liu et~al.(2017)Liu, Zoph, Shlens, Hua, Li, Fei-Fei, Yuille, Huang,
  and Murphy]{progressive}
Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A.,
  Huang, J., and Murphy, K.
\newblock Progressive neural architecture search.
\newblock \emph{arXiv preprint arXiv:1712.00559}, 2017.

\bibitem[Melis et~al.(2017)Melis, Dyer, and Blunsom]{melis2017state}
Melis, G., Dyer, C., and Blunsom, P.
\newblock On the state of the art of evaluation in neural language models.
\newblock \emph{arXiv preprint arXiv:1707.05589}, 2017.

\bibitem[Mendoza et~al.(2016)Mendoza, Klein, Feurer, Springenberg, and
  Hutter]{mendoza-automl16a}
Mendoza, H., Klein, A., Feurer, M., Springenberg, J., and Hutter, F.
\newblock Towards automatically-tuned neural networks.
\newblock In \emph{ICML 2016 AutoML Workshop}, 2016.

\bibitem[Perrone et~al.(2017)Perrone, Jenatton, Seeger, and
  Archambeau]{Perrone2017}
Perrone, V., Jenatton, R., Seeger, M., and Archambeau, C.
\newblock Multiple adaptive bayesian linear regression for scalable bayesian
  optimization with warm start.
\newblock \emph{arXiv preprint arXiv:1712.02902}, 2017.

\bibitem[Poloczek et~al.(2017)Poloczek, Wang, and Frazier]{Poloczek2017}
Poloczek, M., Wang, J., and Frazier, P.
\newblock Multi-information source optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4291--4301, 2017.

\bibitem[Real et~al.(2018)Real, Aggarwal, Huang, and Le]{real_regularized_2018}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized {Evolution} for {Image} {Classifier} {Architecture}
  {Search}.
\newblock In \emph{{arXiv}:1802.01548 [cs]}, February 2018.

\bibitem[Schaarschmidt et~al.(2017)Schaarschmidt, Kuhnle, and
  Fricke]{schaarschmidt2017tensorforce}
Schaarschmidt, M., Kuhnle, A., and Fricke, K.
\newblock Tensorforce: A tensorflow library for applied reinforcement learning.
\newblock Web page, 2017.
\newblock URL \url{https://github.com/reinforceio/tensorforce}.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Seabold \& Perktold(2010)Seabold and Perktold]{seabold2010statsmodels}
Seabold, S. and Perktold, J.
\newblock Statsmodels: Econometric and statistical modeling with python.
\newblock In \emph{9th Python in Science Conference}, 2010.

\bibitem[Shahriari et~al.(2016)Shahriari, Swersky, Wang, Adams, and
  de~Freitas]{shahriari-ieee16a}
Shahriari, B., Swersky, K., Wang, Z., Adams, R., and de~Freitas, N.
\newblock Taking the human out of the loop: {A} review of {B}ayesian
  optimization.
\newblock \emph{Proceedings of the {IEEE}}, 104\penalty0 (1):\penalty0
  148--175, 2016.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek-nips12a}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In Bartlett, P., Pereira, F., Burges, C., Bottou, L., and Weinberger,
  K. (eds.), \emph{Proceedings of the 26th International Conference on Advances
  in Neural Information Processing Systems (NIPS'12)}, pp.\  2960--2968, 2012.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{snoek-icml15a}
Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N.,
  Patwary, M., Prabhat, and Adams, R.
\newblock Scalable {B}ayesian optimization using deep neural networks.
\newblock In  \citet{icml15}, pp.\  2171--2180.

\bibitem[Springenberg et~al.(2016)Springenberg, Klein, Falkner, and
  Hutter]{springenberg-nips2016}
Springenberg, J., Klein, A., Falkner, S., and Hutter, F.
\newblock Bayesian optimization with robust bayesian neural networks.
\newblock In Lee, D., Sugiyama, M., von Luxburg, U., Guyon, I., and Garnett, R.
  (eds.), \emph{Proceedings of the 30th International Conference on Advances in
  Neural Information Processing Systems (NIPS'16)}, 2016.

\bibitem[Swersky et~al.(2013)Swersky, Snoek, and Adams]{swersky-nips13a}
Swersky, K., Snoek, J., and Adams, R.
\newblock Multi-task {Bayesian} optimization.
\newblock In Burges, C., Bottou, L., Welling, M., Ghahramani, Z., and
  Weinberger, K. (eds.), \emph{Proceedings of the 27th International Conference
  on Advances in Neural Information Processing Systems (NIPS'13)}, pp.\
  2004--2012, 2013.

\bibitem[Swersky et~al.(2014)Swersky, Snoek, and Adams]{swersky-archive14}
Swersky, K., Snoek, J., and Adams, R.
\newblock Freeze-thaw bayesian optimization.
\newblock arXiv:1406.3896, 2014.

\bibitem[Vanschoren et~al.(2014)Vanschoren, van Rijn, Bischl, and
  Torgo]{vanschoren-sigkdd13a}
Vanschoren, J., van Rijn, J., Bischl, B., and Torgo, L.
\newblock {OpenML}: Networked science in machine learning.
\newblock \emph{SIGKDD Explor. Newsl.}, 15\penalty0 (2):\penalty0 49--60, June
  2014.

\bibitem[Wang et~al.(2018)Wang, Xu, and Wang]{wang-arxiv18}
Wang, J., Xu, J., and Wang, X.
\newblock Combination of hyperband and bayesian optimization for hyperparameter
  optimization in deep learning.
\newblock \emph{arXiv preprint arxiv:1801.01596}, 01 2018.

\bibitem[Zoph \& Le(2017)Zoph and Le]{zoph-iclr17a}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR'17)} \citet{iclr17}.
\newblock Published online: \url{iclr.cc}.

\bibitem[Zoph et~al.(2017)Zoph, Vasudevan, Shlens, and Le]{zoph_arxiv2017}
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q.~V.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{arXiv:1707.07012 [cs.CV]}, 2017.

\end{thebibliography}
