\begin{thebibliography}{10}

\bibitem{smola-book}
B.~Sch{\"o}lkopf and A.~J. Smola.
\newblock {\em Learning with Kernels}.
\newblock MIT Press, 2002.

\bibitem{Cristianini2004}
J.~Shawe-Taylor and N.~Cristianini.
\newblock {\em Kernel Methods for Pattern Analysis}.
\newblock Camb. U. P., 2004.

\bibitem{Zhaoyu}
P.~Zhao and B.~Yu.
\newblock On model selection consistency of {L}asso.
\newblock {\em J. Mach. Learn. Res.}, 7:2541--2563, 2006.

\bibitem{grouplasso}
F.~R. Bach.
\newblock Consistency of the group {L}asso and multiple kernel learning.
\newblock Technical Report 00164735, HAL, 2008.

\bibitem{skm}
F.~R. Bach, G.~R.~G. Lanckriet, and M.~I. Jordan.
\newblock Multiple kernel learning, conic duality, and the {SMO} algorithm.
\newblock In {\em Proc. ICML}, 2004.

\bibitem{cap}
P.~Zhao, G.~Rocha, and B.~Yu.
\newblock Grouped and hierarchical model selection through composite absolute
  penalties.
\newblock {\em Annals of Statistics}, To appear, 2008.

\bibitem{marie}
M.~Szafranski, Y.~Grandvalet, and A.~Rakotomamonjy.
\newblock Composite kernel learning.
\newblock In {\em Proc. ICML}, pages 1040--1047, 2008.

\bibitem{williams00effect}
C.~K.~I. Williams and M.~Seeger.
\newblock The effect of the input density distribution on kernel-based
  classifiers.
\newblock In {\em Proc. ICML}, 2000.

\bibitem{rakoto}
A.~Rakotomamonjy, F.~R. Bach, S.~Canu, and Y.~Grandvalet.
\newblock More efficiency in multiple kernel learning.
\newblock In {\em Proc. ICML}, 2007.

\bibitem{pontil-jmlr}
M.~Pontil and C.A. Micchelli.
\newblock Learning the kernel function via regularization.
\newblock {\em J. Mach. Learn. Res.}, 6:1099--1125, 2005.

\bibitem{ng-sparsecoding}
H.~Lee, A.~Battle, R.~Raina, and A.~Ng.
\newblock Efficient sparse coding algorithms.
\newblock In {\em NIPS}, 2007.

\bibitem{boyd}
S.~Boyd and L.~Vandenberghe.
\newblock {\em Convex Optimization}.
\newblock Cambridge Univ. Press, 2003.

\bibitem{bennett}
K.~Bennett, M.~Momma, and J.~Embrechts.
\newblock Mark: A boosting algorithm for heterogeneous kernel models.
\newblock In {\em Proc. SIGKDD}, 2002.

\bibitem{roth}
V.~Roth.
\newblock The generalized {L}asso.
\newblock {\em IEEE Trans. on Neural Networks}, 15(1), 2004.

\bibitem{grauman}
K.~Grauman and T.~Darrell.
\newblock The pyramid match kernel: Efficient learning with sets of features.
\newblock {\em J. Mach. Learn. Res.}, 8:725--760, 2007.

\bibitem{bach_thibaux}
F.~R. Bach, R.~Thibaux, and M.~I. Jordan.
\newblock Computing regularization paths for learning multiple kernels.
\newblock In {\em Adv. NIPS 17}, 2004.

\bibitem{sonnenburg}
S.~Sonnenburg, G.~R{\"a}tsch, C.~Sch{\"a}fer, and B.~Sch{\"o}lkopf.
\newblock Large scale multiple kernel learning.
\newblock {\em J. Mach. Learn. Res.}, 7:1531--1565, 07 2006.

\bibitem{zou}
H.~Zou.
\newblock The adaptive {L}asso and its oracle properties.
\newblock {\em Journal of the American Statistical Association},
  101:1418--1429, December 2006.

\bibitem{fu}
W.~Fu and K.~Knight.
\newblock Asymptotics for {L}asso-type estimators.
\newblock {\em Annals of Statistics}, 28(5):1356--1378, 2000.

\bibitem{yuanlin}
M.~Yuan and Y.~Lin.
\newblock On the non-negative garrotte estimator.
\newblock {\em Journal of The Royal Statistical Society Series B},
  69(2):143--161, 2007.

\end{thebibliography}
