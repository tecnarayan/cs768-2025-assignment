@inproceedings{li2017provably,
  title={Provably optimal algorithms for generalized linear contextual bandits},
  author={Li, Lihong and Lu, Yu and Zhou, Dengyong},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{modi2018markov,
  title={Markov decision processes with continuous side information},
  author={Modi, Aditya and Jiang, Nan and Singh, Satinder and Tewari, Ambuj},
  booktitle={Algorithmic Learning Theory (ALT)},
  year={2018}
}

@article{abbasi2014online,
  title={Online learning in {MDP}s with side information},
  author={Abbasi-Yadkori, Yasin and Neu, Gergely},
  journal={arXiv preprint arXiv:1406.6812},
  year={2014}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={International Conference on World Wide Web (WWW)},
  year={2010}
}

@inproceedings{NIPS2010_4166,
title = {Parametric Bandits: The Generalized Linear Case},
author = {Sarah Filippi and Cappe, Olivier and Garivier, Aur\'{e}lien and Csaba Szepesv\'{a}ri},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2010}
}

@article{pleiss2018constant,
  title={Constant-time predictive distributions for {Gaussian} processes},
  author={Pleiss, Geoff and Gardner, Jacob R and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.06058},
  year={2018}
}

@inproceedings{moldovan2012safe,
  title={Safe Exploration in {Markov} decision processes},
  author={Moldovan, Teodor and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2012}
}

@inproceedings{turchetta2016safe,
  title={Safe exploration in finite {Markov} decision processes with {Gaussian} processes},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2016}
}

@inproceedings{sui2015safe,
  title={Safe exploration for optimization with {Gaussian} processes},
  author={Sui, Yanan and Gotovos, Alkis and Burdick, Joel W and Krause, Andreas},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2015}
}

@inproceedings{srinivas2009gaussian,
  title={Gaussian process optimization in the bandit setting: No regret and experimental design},
  author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2010}
}

@inproceedings{strens2000bayesian,
  title={A {Bayesian} framework for reinforcement learning},
  author={Strens, Malcolm},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2000}
}

@inproceedings{kolter2009near,
  title={Near-{Bayesian} exploration in polynomial time},
  author={Kolter, J Zico and Ng, Andrew Y},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2009}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine Learning},
  volume={49},
  number={2-3},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@article{brafman2002r,
  title={R-max - a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research (JMLR)},
  pages={213--231},
  year={2002}
}

@inproceedings{strehl2006pac,
  title={{PAC} model-free reinforcement learning},
  author={Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2006}
}

@inproceedings{araya2012near,
  title={Near-Optimal {BRL} using Optimistic Local Transitions},
  author={Araya, Mauricio and Buffet, Olivier and Thomas, Vincent},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2012}
}

@article{fisac2018general,
  title={A general safety framework for learning-based control in uncertain robotic systems},
  author={Fisac, Jaime F and Akametalu, Anayo K and Zeilinger, Melanie N and Kaynama, Shahab and Gillula, Jeremy and Tomlin, Claire J},
  journal={IEEE Transactions on Automatic Control},
  year={2018},
  publisher={IEEE}
}

@inproceedings{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela and Krause, Andreas},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@inproceedings{chowdhury2017kernelized,
  title={On kernelized multi-armed bandits},
  author={Chowdhury, Sayak Ray and Gopalan, Aditya},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{chow2018lyapunov,
  title={A {Lyapunov}-based approach to safe reinforcement learning},
  author={Chow, Yinlam and Nachum, Ofir and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@inproceedings{wachi2018safe,
  author = {Akifumi Wachi and Yanan Sui and Yisong Yue and Masahiro Ono},
  title = {Safe Exploration and Optimization of Constrained {MDP}s Using {Gaussian} Processes},
  booktitle = {{AAAI} Conference on Artificial Intelligence ({AAAI})},
  year = {2018},
}

@inproceedings{sui2018stagewise,
  title={Stagewise Safe {Bayesian} Optimization with {Gaussian} Processes},
  author={Yanan Sui and Vincent Zhuang and Joel W. Burdick and Yisong Yue},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for {Markov} decision processes},
  author={Strehl, Alexander L and Littman, Michael L},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{auer2007logarithmic,
  title={Logarithmic online regret bounds for undiscounted reinforcement learning},
  author={Auer, Peter and Ortner, Ronald},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2007}
}

@inproceedings{turchetta19goose,
	Author = {Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
	Booktitle = {Neural Information Processing Systems (NeurIPS)},
	Title = {Safe Exploration for Interactive Machine Learning},
	Year = {2019}
}

@book{Ray2019,
    author = {Ray, Alex and Achiam, Joshua and Amodei, Dario},
    title = {Benchmarking safe exploration in deep reinforcement learning},
    year = {2019},
    publisher = {OpenAI}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@book{scholkopf2001learning,
  title={Learning with kernels: support vector machines, regularization, optimization, and beyond},
  author={Sch{\"o}lkopf, Bernhard and Smola, Alexander J},
  year={2001},
  publisher={MIT press}
}

@incollection{rasmussengaussian,
  title={Gaussian Processes in Machine Learning},
  author={Rasmussen, Carl Edward},
  booktitle={Advanced Lectures on Machine Learning},
  pages={63--71},
  year={2004},
  publisher={Springer}
}

@inproceedings{strehl2005theoretical,
  title={A theoretical analysis of model-based interval estimation},
  author={Strehl, Alexander L and Littman, Michael L},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2005}
}

@article{aswani2013provably,
  title={Provably safe and robust learning-based model predictive control},
  author={Aswani, Anil and Gonzalez, Humberto and Sastry, S Shankar and Tomlin, Claire},
  journal={Automatica},
  volume={49},
  number={5},
  pages={1216--1226},
  year={2013}
}

@article{mayne2000constrained,
  title={Constrained model predictive control: Stability and optimality},
  author={Mayne, David Q and Rawlings, James B and Rao, Christopher V and Scokaert, Pierre OM},
  journal={Automatica},
  volume={36},
  number={6},
  pages={789--814},
  year={2000}
}

@article{chow2019lyapunov,
  title={Lyapunov-based safe policy optimization for continuous control},
  author={Chow, Yinlam and Nachum, Ofir and Faust, Aleksandra and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1901.10031},
  year={2019}
}

@inproceedings{akametalu2014reachability,
  title={Reachability-based safe learning with {Gaussian} processes},
  author={Akametalu, Anayo K and Fisac, Jaime F and Gillula, Jeremy H and Kaynama, Shahab and Zeilinger, Melanie N and Tomlin, Claire J},
  booktitle={IEEE Conference on Decision and Control (CDC)},
  year={2014}
}

@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

% OK
@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and others},
  journal={The Journal of Machine Learning Research (JMLR)},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
}

% OK
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

% OK
@article{silver2016mastering,
  title={Mastering the game of {G}o with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{wachi_sui_snomdp_icml2020,
  Author = {Akifumi Wachi and Yanan Sui},
  Title = {Safe Reinforcement Learning in Constrained {M}arkov Decision Processes},
  Booktitle  = {International Conference on Machine Learning (ICML)},
  Year = {2020}
}

@inproceedings{snelson2006sparse,
  title={Sparse {G}aussian processes using pseudo-inputs},
  author={Snelson, Edward and Ghahramani, Zoubin},
  booktitle={Neural information processing systems (NeurIPS)},
  year={2006}
}

@misc{gym_minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for {OpenAI} Gym},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/maximecb/gym-minigrid}},
}

@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTAT)},
  year={2011}
}

@article{hallak2015contextual,
  title={Contextual {Markov} decision processes},
  author={Hallak, Assaf and Di Castro, Dotan and Mannor, Shie},
  journal={arXiv preprint arXiv:1502.02259},
  year={2015}
}

@InProceedings{amani2019linear,
  title={Linear stochastic bandits under safety constraints},
  author={Amani, Sanae and Alizadeh, Mahnoosh and Thrampoulidis, Christos},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@InProceedings{pmlr-v108-hao20b,
  title = 	 {Adaptive Exploration in Linear Contextual Bandit},
  author =       {Hao, Botao and Lattimore, Tor and Szepesvari, Csaba},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics (AISTAT)},
  year = 	 {2020},
}

@inproceedings{NIPS2008_23ce1851,
 author = {Agarwal, Deepak and Chen, Bee-chung and Elango, Pradheep and Motgi, Nitin and Park, Seung-taek and Ramakrishnan, Raghu and Roy, Scott and Zachariah, Joe},
 booktitle = {Neural Information Processing Systems (NeurIPS)},
 title = {Online Models for Content Optimization},
 year = {2009}
}

@article{richter2019open,
  title={Open-sourced reinforcement learning environments for surgical robotics},
  author={Richter, Florian and Orosco, Ryan K and Yip, Michael C},
  journal={arXiv preprint arXiv:1903.02090},
  year={2019}
}

@inproceedings{scherrer2012approximate,
  title={Approximate modified policy iteration},
  author={Scherrer, Bruno and Ghavamzadeh, Mohammad and Gabillon, Victor and Geist, Matthieu},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2012}
}

@inproceedings{NIPS2011_e1d5be1c,
 author = {Abbasi-yadkori, Yasin and P\'{a}l, D\'{a}vid and Szepesv\'{a}ri, Csaba},
 booktitle = {Neural Information Processing Systems (NeurIPS)},
 title = {Improved Algorithms for Linear Stochastic Bandits},
 year = {2011}
}

@inproceedings{kehoe2014autonomous,
  title={Autonomous multilateral debridement with the raven surgical robot},
  author={Kehoe, Ben and Kahn, Gregory and Mahler, Jeffrey and Kim, Jonathan and Lee, Alex and Lee, Anna and Nakagawa, Keisuke and Patil, Sachin and Boyd, W Douglas and Abbeel, Pieter and others},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2014}
}

@inproceedings{van2010superhuman,
  title={Superhuman performance of surgical tasks by robots using iterative learning from human-guided demonstrations},
  author={Van Den Berg, Jur and Miller, Stephen and Duckworth, Daniel and Hu, Humphrey and Wan, Andrew and Fu, Xiao-Yu and Goldberg, Ken and Abbeel, Pieter},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2010},
}

@article{villar2015multi,
  title={Multi-armed bandit models for the optimal design of clinical trials: benefits and challenges},
  author={Villar, Sof{\'\i}a S and Bowden, Jack and Wason, James},
  journal={Statistical science: a review journal of the Institute of Mathematical Statistics},
  volume={30},
  number={2},
  pages={199},
  year={2015}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
}

@inproceedings{gillula2012guaranteed,
  title={Guaranteed safe online learning via reachability: tracking a ground target using a quadrotor},
  author={Gillula, Jeremy H and Tomlin, Claire J},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2012}
}

@inproceedings{cohen2018diverse,
  title={Diverse exploration for fast and safe policy improvement},
  author={Cohen, Andrew and Yu, Lei and Wright, Robert},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

@article{mahadevan2007proto,
  title={Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes.},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={10},
  year={2007}
}

@book{altman1999constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  volume={7},
  year={1999},
  publisher={CRC Press}
}

@article{bradtke1996linear,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@inproceedings{yang2019sample,
  title={Sample-optimal parametric Q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory (COLT)},
  year={2020},
}

@inproceedings{wang2019optimism,
  title={Optimism in reinforcement learning with generalized linear function approximation},
  author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
  booktitle={International Conference on Learning Representation (ICLR)},
  year={2019}
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@inproceedings{ding2021provably,
  title={Provably efficient safe exploration via primal-dual policy optimization},
  author={Ding, Dongsheng and Wei, Xiaohan and Yang, Zhuoran and Wang, Zhaoran and Jovanovic, Mihailo},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTAT)},
  year={2021}
}

@InProceedings{pmlr-v119-yang20h,
    title = {Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
    author = {Yang, Lin and Wang, Mengdi}, booktitle = {International Conference on Machine Learning (ICML)},
    year = {2020}
}

@inproceedings{osband2016generalization,
  title={Generalization and exploration via randomized value functions},
  author={Osband, Ian and Van Roy, Benjamin and Wen, Zheng},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{tessler2018reward,
  title={Reward constrained policy optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  journal={arXiv preprint arXiv:1805.11074},
  year={2018}
}

@article{paternain2019safe,
  title={Safe policies for reinforcement learning via primal-dual methods},
  author={Paternain, Santiago and Calvo-Fullana, Miguel and Chamon, Luiz FO and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:1911.09101},
  year={2019}
}

@inproceedings{biyik2019efficient,
  title={Efficient and safe exploration in deterministic markov decision processes with unknown transition models},
  author={Biyik, Erdem and Margoliash, Jonathan and Alimo, Shahrouz Ryan and Sadigh, Dorsa},
  booktitle={American Control Conference (ACC)},
  year={2019},
  organization={IEEE}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2015}
}

@article{dulac2021challenges,
  title={Challenges of real-world reinforcement learning: definitions, benchmarks and analysis},
  author={Dulac-Arnold, Gabriel and Levine, Nir and Mankowitz, Daniel J and Li, Jerry and Paduraru, Cosmin and Gowal, Sven and Hester, Todd},
  journal={Machine Learning},
  pages={1--50},
  year={2021},
  publisher={Springer}
}

@article{bhatnagar2012online,
  title={An online actor--critic algorithm with function approximation for constrained markov decision processes},
  author={Bhatnagar, Shalabh and Lakshmanan, K},
  journal={Journal of Optimization Theory and Applications},
  volume={153},
  number={3},
  pages={688--708},
  year={2012},
  publisher={Springer}
}

@article{borkar2005actor,
  title={An actor-critic algorithm for constrained Markov decision processes},
  author={Borkar, Vivek S},
  journal={Systems \& control letters},
  volume={54},
  number={3},
  pages={207--213},
  year={2005},
  publisher={Elsevier}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017}
}

@inproceedings{liu2020ipo,
  title={IPO: Interior-point policy optimization under constraints},
  author={Liu, Yongshuai and Ding, Jiaxin and Liu, Xin},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2020}
}

@inproceedings{satija2020constrained,
  title={Constrained markov decision processes via backward value functions},
  author={Satija, Harsh and Amortila, Philip and Pineau, Joelle},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@inproceedings{alshiekh2018safe,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

@inproceedings{fulton2018safe,
  title={Safe reinforcement learning via formal methods: Toward safe control through proof and learning},
  author={Fulton, Nathan and Platzer, Andr{\'e}},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

@inproceedings{cheng2019end,
  title={End-to-end safe reinforcement learning through barrier functions for safety-critical continuous control tasks},
  author={Cheng, Richard and Orosz, G{\'a}bor and Murray, Richard M and Burdick, Joel W},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2019}
}