\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ainsworth et~al.(2023)Ainsworth, Hayase, and Srinivasa]{ainsworthGitReBasinMerging2023}
Ainsworth, S.~K., Hayase, J., and Srinivasa, S.
\newblock Git {{Re-Basin}}: {{Merging Models}} modulo {{Permutation Symmetries}}, March 2023.
\newblock URL \url{http://arxiv.org/abs/2209.04836}.

\bibitem[Benton et~al.(2021)Benton, Maddox, Lotfi, and Wilson]{bentonLossSurfaceSimplexes2021}
Benton, G.~W., Maddox, W.~J., Lotfi, S., and Wilson, A.~G.
\newblock Loss {{Surface Simplexes}} for {{Mode Connecting Volumes}} and {{Fast Ensembling}}, November 2021.
\newblock URL \url{http://arxiv.org/abs/2102.13042}.

\bibitem[Cao et~al.(2024)Cao, Lin, Han, and Sun]{DBLP:journals/ijautcomp/CaoLHS24}
Cao, B., Lin, H., Han, X., and Sun, L.
\newblock The life cycle of knowledge in big language models: {A} survey.
\newblock \emph{Mach. Intell. Res.}, 21\penalty0 (2):\penalty0 217--238, 2024.
\newblock \doi{10.1007/S11633-023-1416-X}.
\newblock URL \url{https://doi.org/10.1007/s11633-023-1416-x}.

\bibitem[Cheng et~al.(2017)Cheng, Han, and Lu]{cheng_remote_2017}
Cheng, G., Han, J., and Lu, X.
\newblock Remote {Sensing} {Image} {Scene} {Classification}: {Benchmark} and {State} of the {Art}.
\newblock \emph{Proceedings of the IEEE}, 105\penalty0 (10):\penalty0 1865--1883, October 2017.
\newblock ISSN 0018-9219, 1558-2256.
\newblock \doi{10.1109/JPROC.2017.2675998}.
\newblock URL \url{http://arxiv.org/abs/1703.00121}.
\newblock arXiv:1703.00121 [cs].

\bibitem[Chung et~al.(2022)Chung, Hou, Longpre, Zoph, Tay, Fedus, Li, Wang, Dehghani, Brahma, Webson, Gu, Dai, Suzgun, Chen, Chowdhery, {Castro-Ros}, Pellat, Robinson, Valter, Narang, Mishra, Yu, Zhao, Huang, Dai, Yu, Petrov, Chi, Dean, Devlin, Roberts, Zhou, Le, and Wei]{chungScalingInstructionFinetunedLanguage2022}
Chung, H.~W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., Webson, A., Gu, S.~S., Dai, Z., Suzgun, M., Chen, X., Chowdhery, A., {Castro-Ros}, A., Pellat, M., Robinson, K., Valter, D., Narang, S., Mishra, G., Yu, A., Zhao, V., Huang, Y., Dai, A., Yu, H., Petrov, S., Chi, E.~H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q.~V., and Wei, J.
\newblock Scaling {{Instruction-Finetuned Language Models}}, December 2022.
\newblock URL \url{http://arxiv.org/abs/2210.11416}.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{cimpoi_describing_2014}
Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., and Vedaldi, A.
\newblock Describing {Textures} in the {Wild}.
\newblock In \emph{2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}}, pp.\  3606--3613, Columbus, OH, USA, June 2014. IEEE.
\newblock ISBN 978-1-4799-5118-5.
\newblock \doi{10.1109/CVPR.2014.461}.
\newblock URL \url{https://ieeexplore.ieee.org/document/6909856}.

\bibitem[Dai et~al.(2024)Dai, Deng, Zhao, Xu, Gao, Chen, Li, Zeng, Yu, Wu, Xie, Li, Huang, Luo, Ruan, Sui, and Liang]{daiDeepSeekMoEUltimateExpert}
Dai, D., Deng, C., Zhao, C., Xu, R.~X., Gao, H., Chen, D., Li, J., Zeng, W., Yu, X., Wu, Y., Xie, Z., Li, Y.~K., Huang, P., Luo, F., Ruan, C., Sui, Z., and Liang, W.
\newblock {{DeepSeekMoE}}: {{Towards Ultimate Expert Specialization}} in {{Mixture-of-Experts Language Models}}.
\newblock 2024.

\bibitem[Daniel~Freeman \& Bruna(2017)Daniel~Freeman and Bruna]{danielfreemanTopologyGeometryHalfrectified2017}
Daniel~Freeman, C. and Bruna, J.
\newblock Topology and geometry of half-rectified network optimization: 5th {{International Conference}} on {{Learning Representations}}, {{ICLR}} 2017.
\newblock 2017.
\newblock URL \url{http://www.scopus.com/inward/record.url?scp=85064823226&partnerID=8YFLogxK}.

\bibitem[Draxler et~al.(2019)Draxler, Veschgini, Salmhofer, and Hamprecht]{draxlerEssentiallyNoBarriers2019}
Draxler, F., Veschgini, K., Salmhofer, M., and Hamprecht, F.~A.
\newblock Essentially {{No Barriers}} in {{Neural Network Energy Landscape}}, February 2019.
\newblock URL \url{http://arxiv.org/abs/1803.00885}.

\bibitem[Entezari et~al.(2022)Entezari, Sedghi, Saukh, and Neyshabur]{entezariRolePermutationInvariance2022}
Entezari, R., Sedghi, H., Saukh, O., and Neyshabur, B.
\newblock The {{Role}} of {{Permutation Invariance}} in {{Linear Mode Connectivity}} of {{Neural Networks}}, July 2022.
\newblock URL \url{http://arxiv.org/abs/2110.06296}.

\bibitem[Fedus et~al.(2022{\natexlab{a}})Fedus, Dean, and Zoph]{fedusReviewSparseExpert2022}
Fedus, W., Dean, J., and Zoph, B.
\newblock A {{Review}} of {{Sparse Expert Models}} in {{Deep Learning}}, September 2022{\natexlab{a}}.
\newblock URL \url{http://arxiv.org/abs/2209.01667}.

\bibitem[Fedus et~al.(2022{\natexlab{b}})Fedus, Zoph, and Shazeer]{fedusSwitchTransformersScaling2022}
Fedus, W., Zoph, B., and Shazeer, N.
\newblock Switch {{Transformers}}: {{Scaling}} to {{Trillion Parameter Models}} with {{Simple}} and {{Efficient Sparsity}}, June 2022{\natexlab{b}}.
\newblock URL \url{http://arxiv.org/abs/2101.03961}.

\bibitem[Frankle et~al.(2020)Frankle, Dziugaite, Roy, and Carbin]{frankleLinearModeConnectivity2020}
Frankle, J., Dziugaite, G.~K., Roy, D.~M., and Carbin, M.
\newblock Linear {{Mode Connectivity}} and the {{Lottery Ticket Hypothesis}}, July 2020.
\newblock URL \url{http://arxiv.org/abs/1912.05671}.

\bibitem[Frankle et~al.(2021)Frankle, Dziugaite, Roy, and Carbin]{franklePruningNeuralNetworks2021}
Frankle, J., Dziugaite, G.~K., Roy, D.~M., and Carbin, M.
\newblock Pruning {{Neural Networks}} at {{Initialization}}: {{Why}} are {{We Missing}} the {{Mark}}?, March 2021.
\newblock URL \url{http://arxiv.org/abs/2009.08576}.

\bibitem[Garipov et~al.(2018)Garipov, Izmailov, Podoprikhin, Vetrov, and Wilson]{garipovLossSurfacesMode2018}
Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D., and Wilson, A.~G.
\newblock Loss {{Surfaces}}, {{Mode Connectivity}}, and {{Fast Ensembling}} of {{DNNs}}, October 2018.
\newblock URL \url{http://arxiv.org/abs/1802.10026}.

\bibitem[{George Stoica} et~al.(2023){George Stoica}, {Daniel Bolya}, {Jakob Bjorner}, {Taylor Hearn}, and {Judy Hoffman}]{georgestoicaZipItMergingModels2023}
{George Stoica}, {Daniel Bolya}, {Jakob Bjorner}, {Taylor Hearn}, and {Judy Hoffman}.
\newblock {{ZipIt}}! {{Merging Models}} from {{Different Tasks}} without {{Training}}, May 2023.
\newblock URL \url{http://arxiv.org/abs/2305.03053}.

\bibitem[He et~al.(2021)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{heMaskedAutoencodersAre2021}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'a}r, P., and Girshick, R.
\newblock Masked {{Autoencoders Are Scalable Vision Learners}}, December 2021.
\newblock URL \url{http://arxiv.org/abs/2111.06377}.

\bibitem[Helber et~al.(2018)Helber, Bischke, Dengel, and Borth]{helber2018introducing}
Helber, P., Bischke, B., Dengel, A., and Borth, D.
\newblock Introducing eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.
\newblock In \emph{IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium}, pp.\  204--207. IEEE, 2018.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and Dietterich]{hendrycksBenchmarkingNeuralNetwork2019}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking {{Neural Network Robustness}} to {{Common Corruptions}} and {{Perturbations}}, March 2019.
\newblock URL \url{http://arxiv.org/abs/1903.12261}.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hintonDistillingKnowledgeNeural2015}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the {{Knowledge}} in a {{Neural Network}}, March 2015.
\newblock URL \url{http://arxiv.org/abs/1503.02531}.

\bibitem[Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone, {de Laroussilhe}, Gesmundo, Attariyan, and Gelly]{houlsbyParameterEfficientTransferLearning2019}
Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., {de Laroussilhe}, Q., Gesmundo, A., Attariyan, M., and Gelly, S.
\newblock Parameter-{{Efficient Transfer Learning}} for {{NLP}}, June 2019.
\newblock URL \url{http://arxiv.org/abs/1902.00751}.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, {Allen-Zhu}, Li, Wang, Wang, and Chen]{huLoRALowRankAdaptation2021}
Hu, E.~J., Shen, Y., Wallis, P., {Allen-Zhu}, Z., Li, Y., Wang, S., Wang, L., and Chen, W.
\newblock {{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}, October 2021.
\newblock URL \url{http://arxiv.org/abs/2106.09685}.

\bibitem[Ilharco et~al.(2023)Ilharco, Ribeiro, Wortsman, Gururangan, Schmidt, Hajishirzi, and Farhadi]{ilharcoEditingModelsTask2023}
Ilharco, G., Ribeiro, M.~T., Wortsman, M., Gururangan, S., Schmidt, L., Hajishirzi, H., and Farhadi, A.
\newblock Editing {{Models}} with {{Task Arithmetic}}, March 2023.
\newblock URL \url{http://arxiv.org/abs/2212.04089}.

\bibitem[Izmailov et~al.(2019)Izmailov, Podoprikhin, Garipov, Vetrov, and Wilson]{izmailovAveragingWeightsLeads2019}
Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A.~G.
\newblock Averaging {{Weights Leads}} to {{Wider Optima}} and {{Better Generalization}}, February 2019.
\newblock URL \url{http://arxiv.org/abs/1803.05407}.

\bibitem[Jacobs et~al.(1991)Jacobs, Jordan, Nowlan, and Hinton]{jacobsAdaptiveMixturesLocal1991}
Jacobs, R.~A., Jordan, M.~I., Nowlan, S.~J., and Hinton, G.~E.
\newblock Adaptive {{Mixtures}} of {{Local Experts}}.
\newblock \emph{Neural Computation}, 3\penalty0 (1):\penalty0 79--87, March 1991.
\newblock ISSN 0899-7667.
\newblock \doi{10.1162/neco.1991.3.1.79}.
\newblock URL \url{https://ieeexplore.ieee.org/document/6797059}.

\bibitem[Jiang et~al.(2024)Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford, Chaplot, de~las Casas, Hanna, Bressand, Lengyel, Bour, Lample, Lavaud, Saulnier, Lachaux, Stock, Subramanian, Yang, Antoniak, Scao, Gervet, Lavril, Wang, Lacroix, and Sayed]{jiangMixtralExperts2024}
Jiang, A.~Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C., Chaplot, D.~S., de~las Casas, D., Hanna, E.~B., Bressand, F., Lengyel, G., Bour, G., Lample, G., Lavaud, L.~R., Saulnier, L., Lachaux, M.-A., Stock, P., Subramanian, S., Yang, S., Antoniak, S., Scao, T.~L., Gervet, T., Lavril, T., Wang, T., Lacroix, T., and Sayed, W.~E.
\newblock Mixtral of {{Experts}}, January 2024.
\newblock URL \url{http://arxiv.org/abs/2401.04088}.

\bibitem[Jin et~al.(2023)Jin, Ren, {Preotiuc-Pietro}, and Cheng]{jinDatalessKnowledgeFusion2023}
Jin, X., Ren, X., {Preotiuc-Pietro}, D., and Cheng, P.
\newblock Dataless {{Knowledge Fusion}} by {{Merging Weights}} of {{Language Models}}, April 2023.
\newblock URL \url{http://arxiv.org/abs/2212.09849}.

\bibitem[Kaddour(2022)]{kaddourStopWastingMy2022}
Kaddour, J.
\newblock Stop {{Wasting My Time}}! {{Saving Days}} of {{ImageNet}} and {{BERT Training}} with {{Latest Weight Averaging}}, October 2022.
\newblock URL \url{http://arxiv.org/abs/2209.14981}.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{krause_3d_2013}
Krause, J., Stark, M., Deng, J., and Fei-Fei, L.
\newblock {3D} {Object} {Representations} for {Fine}-{Grained} {Categorization}.
\newblock In \emph{2013 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops}}, pp.\  554--561, December 2013.
\newblock \doi{10.1109/ICCVW.2013.77}.
\newblock URL \url{https://ieeexplore.ieee.org/document/6755945}.

\bibitem[Lawson \& Qureshi(2023)Lawson and Qureshi]{lawsonMergingDecisionTransformers2023}
Lawson, D. and Qureshi, A.~H.
\newblock Merging {{Decision Transformers}}: {{Weight Averaging}} for {{Forming Multi-Task Policies}}, September 2023.
\newblock URL \url{http://arxiv.org/abs/2303.07551}.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{lecunGradientbasedLearningApplied1998}
Lecun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0 2278--2324, 1998.
\newblock ISSN 00189219.
\newblock \doi{10.1109/5.726791}.
\newblock URL \url{http://ieeexplore.ieee.org/document/726791/}.

\bibitem[Lewis et~al.(2021)Lewis, Bhosale, Dettmers, Goyal, and Zettlemoyer]{lewisBASELayersSimplifying2021}
Lewis, M., Bhosale, S., Dettmers, T., Goyal, N., and Zettlemoyer, L.
\newblock {{BASE Layers}}: {{Simplifying Training}} of {{Large}}, {{Sparse Models}}.
\newblock In \emph{Proceedings of the 38th {{International Conference}} on {{Machine Learning}}}, pp.\  6265--6274. {PMLR}, July 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/lewis21a.html}.

\bibitem[Li et~al.(2023)Li, Peng, Zhang, Ding, Hu, and Shen]{liDeepModelFusion2023}
Li, W., Peng, Y., Zhang, M., Ding, L., Hu, H., and Shen, L.
\newblock Deep {{Model Fusion}}: {{A Survey}}, September 2023.
\newblock URL \url{http://arxiv.org/abs/2309.15698}.

\bibitem[Li et~al.(2016)Li, Yosinski, Clune, Lipson, and Hopcroft]{liConvergentLearningDifferent2016}
Li, Y., Yosinski, J., Clune, J., Lipson, H., and Hopcroft, J.
\newblock Convergent {{Learning}}: {{Do}} different neural networks learn the same representations?, February 2016.
\newblock URL \url{http://arxiv.org/abs/1511.07543}.

\bibitem[Liang et~al.(2023)Liang, He, and Tan]{liangComprehensiveSurveyTestTime2023}
Liang, J., He, R., and Tan, T.
\newblock A {{Comprehensive Survey}} on {{Test-Time Adaptation}} under {{Distribution Shifts}}, March 2023.
\newblock URL \url{http://arxiv.org/abs/2303.15361}.

\bibitem[Lin et~al.(2023)Lin, Gao, Gong, Zhang, Zhang, and Li]{DBLP:journals/ijautcomp/LinGGZZL23}
Lin, Y., Gao, Y., Gong, M., Zhang, S., Zhang, Y., and Li, Z.
\newblock Federated learning on multimodal data: {A} comprehensive survey.
\newblock \emph{Mach. Intell. Res.}, 20\penalty0 (4):\penalty0 539--553, 2023.
\newblock \doi{10.1007/S11633-022-1398-0}.
\newblock URL \url{https://doi.org/10.1007/s11633-022-1398-0}.

\bibitem[Liu et~al.(2022)Liu, Lou, Wang, Xi, Shen, and Yan]{liuDeepNeuralNetwork2022a}
Liu, C., Lou, C., Wang, R., Xi, A.~Y., Shen, L., and Yan, J.
\newblock Deep {{Neural Network Fusion}} via {{Graph Matching}} with {{Applications}} to {{Model Ensemble}} and {{Federated Learning}}.
\newblock In \emph{Proceedings of the 39th {{International Conference}} on {{Machine Learning}}}, pp.\  13857--13869. {PMLR}, June 2022.
\newblock URL \url{https://proceedings.mlr.press/v162/liu22k.html}.

\bibitem[Matena \& Raffel(2022)Matena and Raffel]{matenaMergingModelsFisherWeighted2022}
Matena, M. and Raffel, C.
\newblock Merging {{Models}} with {{Fisher-Weighted Averaging}}, August 2022.
\newblock URL \url{http://arxiv.org/abs/2111.09832}.

\bibitem[Mounsaveng et~al.(2023)Mounsaveng, Chiaroni, Boudiaf, Pedersoli, and Ayed]{mounsavengBagTricksFully2023}
Mounsaveng, S., Chiaroni, F., Boudiaf, M., Pedersoli, M., and Ayed, I.~B.
\newblock Bag of {{Tricks}} for {{Fully Test-Time Adaptation}}, October 2023.
\newblock URL \url{http://arxiv.org/abs/2310.02416}.

\bibitem[Nagarajan \& Kolter(2019)Nagarajan and Kolter]{nagarajanUniformConvergenceMay2019}
Nagarajan, V. and Kolter, J.~Z.
\newblock Uniform convergence may be unable to explain generalization in deep learning.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}}, volume~32. {Curran Associates, Inc.}, 2019.

\bibitem[Netzer et~al.(2021)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{netzer_reading_2021}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading {Digits} in {Natural} {Images} with {Unsupervised} {Feature} {Learning}.
\newblock 2021.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and Sutskever]{radfordLanguageModelsAre2019}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language {{Models}} are {{Unsupervised Multitask Learners}}.
\newblock 1:\penalty0 9, 2019.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{radfordLearningTransferableVisual2021}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I.
\newblock Learning {{Transferable Visual Models From Natural Language Supervision}}, February 2021.
\newblock URL \url{http://arxiv.org/abs/2103.00020}.

\bibitem[Stallkamp et~al.(2012)Stallkamp, Schlipsing, Salmen, and Igel]{stallkamp_man_2012}
Stallkamp, J., Schlipsing, M., Salmen, J., and Igel, C.
\newblock Man vs. computer: {Benchmarking} machine learning algorithms for traffic sign recognition.
\newblock \emph{Neural Networks}, 32:\penalty0 323--332, August 2012.
\newblock ISSN 0893-6080.
\newblock \doi{10.1016/j.neunet.2012.02.016}.
\newblock URL \url{https://www.sciencedirect.com/science/article/pii/S0893608012000457}.

\bibitem[Tang et~al.(2023{\natexlab{a}})Tang, Luo, Hu, He, Su, Du, Chen, and Tao]{tangImprovingHeterogeneousModel2023a}
Tang, A., Luo, Y., Hu, H., He, F., Su, K., Du, B., Chen, Y., and Tao, D.
\newblock Improving {{Heterogeneous Model Reuse}} by {{Density Estimation}}.
\newblock In \emph{Thirty-{{Second International Joint Conference}} on {{Artificial Intelligence}}}, volume~4, pp.\  4244--4252, August 2023{\natexlab{a}}.
\newblock \doi{10.24963/ijcai.2023/472}.
\newblock URL \url{https://www.ijcai.org/proceedings/2023/472}.

\bibitem[Tang et~al.(2023{\natexlab{b}})Tang, Shen, Luo, Ding, Hu, Du, and Tao]{tangConcreteSubspaceLearning2023}
Tang, A., Shen, L., Luo, Y., Ding, L., Hu, H., Du, B., and Tao, D.
\newblock Concrete {{Subspace Learning}} based {{Interference Elimination}} for {{Multi-task Model Fusion}}, December 2023{\natexlab{b}}.
\newblock URL \url{http://arxiv.org/abs/2312.06173}.

\bibitem[Tatro et~al.(2020)Tatro, Chen, Das, Melnyk, Sattigeri, and Lai]{tatroOptimizingModeConnectivity2020}
Tatro, N., Chen, P.-Y., Das, P., Melnyk, I., Sattigeri, P., and Lai, R.
\newblock Optimizing {{Mode Connectivity}} via {{Neuron Alignment}}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}}, volume~33, pp.\  15300--15311. {Curran Associates, Inc.}, 2020.

\bibitem[Wang et~al.(2023)Wang, Chen, Qian, Gao, Wei, Wang, Tian, and Gao]{DBLP:journals/ijautcomp/WangCQGWWTG23}
Wang, X., Chen, G., Qian, G., Gao, P., Wei, X., Wang, Y., Tian, Y., and Gao, W.
\newblock Large-scale multi-modal pre-trained models: {A} comprehensive survey.
\newblock \emph{Mach. Intell. Res.}, 20\penalty0 (4):\penalty0 447--482, 2023.
\newblock \doi{10.1007/S11633-022-1410-8}.
\newblock URL \url{https://doi.org/10.1007/s11633-022-1410-8}.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Gadre, Roelofs, {Gontijo-Lopes}, Morcos, Namkoong, Farhadi, Carmon, Kornblith, and Schmidt]{wortsmanModelSoupsAveraging2022}
Wortsman, M., Ilharco, G., Gadre, S.~Y., Roelofs, R., {Gontijo-Lopes}, R., Morcos, A.~S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S., and Schmidt, L.
\newblock Model soups: Averaging weights of multiple fine-tuned models improves accuracy without increasing inference time, July 2022.
\newblock URL \url{http://arxiv.org/abs/2203.05482}.

\bibitem[Wu et~al.(2023)Wu, Wang, Ge, Lu, Zhou, Shan, and Luo]{wuPiTuningTransferring2023}
Wu, C., Wang, T., Ge, Y., Lu, Z., Zhou, R., Shan, Y., and Luo, P.
\newblock {$\pi$}-tuning: transferring multimodal foundation models with optimal multi-task interpolation.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning}, ICML'23. JMLR.org, 2023.

\bibitem[Xiao et~al.(2010)Xiao, Hays, Ehinger, Oliva, and Torralba]{xiao_sun_2010}
Xiao, J., Hays, J., Ehinger, K.~A., Oliva, A., and Torralba, A.
\newblock {SUN} database: {Large}-scale scene recognition from abbey to zoo.
\newblock In \emph{2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}}, pp.\  3485--3492, San Francisco, CA, USA, June 2010. IEEE.
\newblock ISBN 978-1-4244-6984-0.
\newblock \doi{10.1109/CVPR.2010.5539970}.
\newblock URL \url{http://ieeexplore.ieee.org/document/5539970/}.

\bibitem[Yadav et~al.(2023)Yadav, Tam, Choshen, Raffel, and Bansal]{yadavResolvingInterferenceWhen2023}
Yadav, P., Tam, D., Choshen, L., Raffel, C., and Bansal, M.
\newblock Resolving {{Interference When Merging Models}}, June 2023.
\newblock URL \url{http://arxiv.org/abs/2306.01708}.

\bibitem[Yang et~al.(2023)Yang, Wang, Shen, Liu, Guo, Wang, and Tao]{yangAdaMergingAdaptiveModel2023}
Yang, E., Wang, Z., Shen, L., Liu, S., Guo, G., Wang, X., and Tao, D.
\newblock {{AdaMerging}}: {{Adaptive Model Merging}} for {{Multi-Task Learning}}, October 2023.
\newblock URL \url{http://arxiv.org/abs/2310.02575}.

\bibitem[Ye \& Xu(2023)Ye and Xu]{yeTaskExpertDynamicallyAssembling2023}
Ye, H. and Xu, D.
\newblock {{TaskExpert}}: {{Dynamically Assembling Multi-Task Representations}} with {{Memorial Mixture-of-Experts}}, July 2023.
\newblock URL \url{http://arxiv.org/abs/2307.15324}.

\bibitem[Yosinski et~al.(2015)Yosinski, Clune, Nguyen, Fuchs, and Lipson]{yosinskiUnderstandingNeuralNetworks2015}
Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., and Lipson, H.
\newblock Understanding {{Neural Networks Through Deep Visualization}}, June 2015.
\newblock URL \url{http://arxiv.org/abs/1506.06579}.

\bibitem[Yu et~al.(2023)Yu, Yu, Yu, Huang, and Li]{yuLanguageModelsAre2023}
Yu, L., Yu, B., Yu, H., Huang, F., and Li, Y.
\newblock Language {{Models}} are {{Super Mario}}: {{Absorbing Abilities}} from {{Homologous Models}} as a {{Free Lunch}}, November 2023.
\newblock URL \url{http://arxiv.org/abs/2311.03099}.

\bibitem[Yunis et~al.(2022)Yunis, Patel, Savarese, Vardi, Livescu, Walter, Frankle, and Maire]{yunisConvexityLinearMode2022}
Yunis, D., Patel, K.~K., Savarese, P., Vardi, G., Livescu, K., Walter, M., Frankle, J., and Maire, M.
\newblock On {{Convexity}} and {{Linear Mode Connectivity}} in {{Neural Networks}}.
\newblock \emph{OPT2022: 14th Annual Workshop on Optimization for Machine Learning}, 2022.

\bibitem[Zheng et~al.(2023)Zheng, Shen, Tang, Luo, Hu, Du, and Tao]{zhengLearnModelFineTuning2023}
Zheng, H., Shen, L., Tang, A., Luo, Y., Hu, H., Du, B., and Tao, D.
\newblock Learn {{From Model Beyond Fine-Tuning}}: {{A Survey}}, October 2023.
\newblock URL \url{http://arxiv.org/abs/2310.08184}.

\bibitem[Zhou et~al.(2022)Zhou, Lei, Liu, Du, Huang, Zhao, Dai, Chen, Le, and Laudon]{zhouMixtureofExpertsExpertChoice2022}
Zhou, Y., Lei, T., Liu, H., Du, N., Huang, Y., Zhao, V., Dai, A., Chen, Z., Le, Q., and Laudon, J.
\newblock Mixture-of-{{Experts}} with {{Expert Choice Routing}}, October 2022.
\newblock URL \url{http://arxiv.org/abs/2202.09368}.

\end{thebibliography}
