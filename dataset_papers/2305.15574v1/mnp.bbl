\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bertsekas and Shreve(2007)]{Bertsekas2007StochasticOC}
Dimitri~P. Bertsekas and Steven~E. Shreve.
\newblock Stochastic optimal control : the discrete time case.
\newblock 2007.

\bibitem[{Bickford Smith} et~al.(2023){Bickford Smith}, Kirsch, Farquhar, Gal,
  Foster, and Rainforth]{bickfordsmith2023prediction}
{Bickford Smith}, Kirsch, Farquhar, Gal, Foster, and Rainforth.
\newblock Prediction-oriented {Bayesian} active learning.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics}, 2023.

\bibitem[Bressloff(2021)]{Bressloff2021StochasticPI}
Paul~C. Bressloff.
\newblock Stochastic processes in cell biology.
\newblock \emph{Interdisciplinary Applied Mathematics}, 2021.

\bibitem[Bruinsma et~al.(2021)Bruinsma, Requeima, Foong, Gordon, and
  Turner]{bruinsmagaussian}
Wessel Bruinsma, James Requeima, Andrew~YK Foong, Jonathan Gordon, and
  Richard~E Turner.
\newblock The gaussian neural process.
\newblock In \emph{Third Symposium on Advances in Approximate Bayesian
  Inference}, 2021.

\bibitem[Bui et~al.(2016)Bui, Tran, and Turner]{bui2016student}
Tu~Dinh Bui, Dinh Tran, and Richard~E Turner.
\newblock Student-t processes as alternatives to gaussian processes.
\newblock In \emph{International Conference on Machine Learning}, pages
  1232--1241, 2016.

\bibitem[Burda et~al.(2016)Burda, Grosse, and
  Salakhutdinov]{burda2016importance}
Yuri Burda, Roger~B Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock In \emph{ICLR (Poster)}, 2016.

\bibitem[Chaloner and Verdinelli(1995)]{chaloner1995bayesian}
Kathryn Chaloner and Isabella Verdinelli.
\newblock Bayesian experimental design: A review.
\newblock \emph{Statistical science}, pages 273--304, 1995.

\bibitem[Chan and Elsheikh(2019)]{chan2019parametric}
Shing Chan and Ahmed~H Elsheikh.
\newblock Parametric generation of conditional geological realizations using
  generative neural networks.
\newblock \emph{Computational Geosciences}, 23\penalty0 (5):\penalty0 925--952,
  2019.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Chung and Turner(2019)]{chung2019non}
Muyang Chung and Richard~E Turner.
\newblock Non-gaussian process regression with student-t processes.
\newblock In \emph{International Conference on Machine Learning}, pages
  4607--4616, 2019.

\bibitem[Cornish et~al.(2020)Cornish, Caterini, Deligiannidis, and
  Doucet]{cornish2020relaxing}
Rob Cornish, Anthony Caterini, George Deligiannidis, and Arnaud Doucet.
\newblock Relaxing bijectivity constraints with continuously indexed
  normalising flows.
\newblock In \emph{International conference on machine learning}, pages
  2133--2143. PMLR, 2020.

\bibitem[Cressie(1990)]{cressie1990origins}
Noel Cressie.
\newblock The origins of kriging.
\newblock \emph{Mathematical geology}, 22\penalty0 (3):\penalty0 239--252,
  1990.

\bibitem[Damianou and Lawrence(2013)]{damianou2013deep}
Andreas Damianou and Neil~D Lawrence.
\newblock Deep gaussian processes.
\newblock In \emph{Artificial intelligence and statistics}, pages 207--215.
  PMLR, 2013.

\bibitem[Dupont et~al.(2018)Dupont, Zhang, Tilke, Liang, and
  Bailey]{dupont2018generating}
Emilien Dupont, Tuanfeng Zhang, Peter Tilke, Lin Liang, and William Bailey.
\newblock Generating realistic geology conditioned on physical measurements
  with generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1802.03065}, 2018.

\bibitem[Dupont et~al.(2022)Dupont, Teh, and Doucet]{Dupont2022GenerativeMA}
Emilien Dupont, Yee~Whye Teh, and A.~Doucet.
\newblock Generative models as distributions of functions.
\newblock In \emph{AISTATS}, 2022.

\bibitem[Durkan et~al.(2019)Durkan, Papamakarios, Murray, and
  Sohl-Dickstein]{durkan2019neural}
Conor Durkan, George Papamakarios, Iain Murray, and Jascha Sohl-Dickstein.
\newblock Neural spline flows.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Dutordoir et~al.(2022)Dutordoir, Saul, Ghahramani, and
  Simpson]{dutordoir2022neural}
Vincent Dutordoir, Alan Saul, Zoubin Ghahramani, and Fergus Simpson.
\newblock Neural diffusion processes.
\newblock \emph{arXiv preprint arXiv:2206.03992}, 2022.

\bibitem[Foong et~al.(2020)Foong, Bruinsma, Gordon, Dubois, Requeima, and
  Turner]{foong2020meta}
Andrew Foong, Wessel Bruinsma, Jonathan Gordon, Yann Dubois, James Requeima,
  and Richard Turner.
\newblock Meta-learning stationary stochastic process prediction with
  convolutional neural processes.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 8284--8295, 2020.

\bibitem[Frazier(2018)]{frazier2018tutorial}
Peter~I Frazier.
\newblock A tutorial on bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1807.02811}, 2018.

\bibitem[Fritsch and Butland(1984)]{Fritsch1984AMF}
Fred~N. Fritsch and Judy Butland.
\newblock A method for constructing local monotone piecewise cubic
  interpolants.
\newblock \emph{Siam Journal on Scientific and Statistical Computing},
  5:\penalty0 300--304, 1984.

\bibitem[Garnelo et~al.(2018{\natexlab{a}})Garnelo, Rosenbaum, Maddison,
  Ramalho, Saxton, Shanahan, Teh, Rezende, and Eslami]{garnelo2018conditional}
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David
  Saxton, Murray Shanahan, Yee~Whye Teh, Danilo Rezende, and SM~Ali Eslami.
\newblock Conditional neural processes.
\newblock In \emph{International Conference on Machine Learning}, pages
  1704--1713. PMLR, 2018{\natexlab{a}}.

\bibitem[Garnelo et~al.(2018{\natexlab{b}})Garnelo, Schwarz, Rosenbaum, Viola,
  Rezende, Eslami, and Teh]{Garnelo2018NeuralP}
Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo~Jimenez
  Rezende, S.~M.~Ali Eslami, and Yee~Whye Teh.
\newblock Neural processes.
\newblock \emph{ArXiv}, abs/1807.01622, 2018{\natexlab{b}}.

\bibitem[Garnett(2023)]{garnett2023bayesian}
Roman Garnett.
\newblock \emph{Bayesian optimization}.
\newblock Cambridge University Press, 2023.

\bibitem[Ghahramani(1999)]{ghahramani1999tutorial}
Zoubin Ghahramani.
\newblock A tutorial on gaussian processes.
\newblock \emph{Summer School on Machine Learning}, 6:\penalty0 67--80, 1999.

\bibitem[Gordon et~al.(2019)Gordon, Bruinsma, Foong, Requeima, Dubois, and
  Turner]{gordon2019convolutional}
Jonathan Gordon, Wessel~P Bruinsma, Andrew~YK Foong, James Requeima, Yann
  Dubois, and Richard~E Turner.
\newblock Convolutional conditional neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[H{\'a}jek(2009)]{Hjek2009DutchBA}
Alan H{\'a}jek.
\newblock Dutch book arguments.
\newblock In \emph{The Handbook of Rational and Social Choice}, 2009.

\bibitem[Houlsby et~al.(2011)Houlsby, Husz{\'a}r, Ghahramani, and
  Lengyel]{houlsby2011bayesian}
Houlsby, Husz{\'a}r, Ghahramani, and Lengyel.
\newblock {Bayesian} active learning for classification and preference
  learning.
\newblock \emph{arXiv}, 2011.

\bibitem[Joe(1997)]{joe1997multivariate}
Harry Joe.
\newblock Multivariate models and dependence concepts.
\newblock \emph{Chapman \& Hall/CRC}, 1997.

\bibitem[Kawano et~al.(2020)Kawano, Kumagai, Sannai, Iwasawa, and
  Matsuo]{kawano2020group}
Makoto Kawano, Wataru Kumagai, Akiyoshi Sannai, Yusuke Iwasawa, and Yutaka
  Matsuo.
\newblock Group equivariant conditional neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Kim et~al.(2018)Kim, Mnih, Schwarz, Garnelo, Eslami, Rosenbaum,
  Vinyals, and Teh]{kim2018attentive}
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan
  Rosenbaum, Oriol Vinyals, and Yee~Whye Teh.
\newblock Attentive neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Kingma and Ba(2014)]{Kingma2014AdamAM}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.

\bibitem[Korshunova et~al.(2018)Korshunova, Degrave, Husz{\'a}r, Gal, Gretton,
  and Dambre]{korshunova2018bruno}
Iryna Korshunova, Jonas Degrave, Ferenc Husz{\'a}r, Yarin Gal, Arthur Gretton,
  and Joni Dambre.
\newblock Bruno: A deep recurrent model for exchangeable data.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Korshunova et~al.(2020)Korshunova, Gal, Gretton, and
  Dambre]{KORSHUNOVA2020305}
Iryna Korshunova, Yarin Gal, Arthur Gretton, and Joni Dambre.
\newblock Conditional bruno: A neural process for exchangeable labelled data.
\newblock \emph{Neurocomputing}, 416:\penalty0 305--309, 2020.
\newblock ISSN 0925-2312.
\newblock \doi{https://doi.org/10.1016/j.neucom.2019.11.108}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0925231220304987}.

\bibitem[Laing and Lord(2009)]{Laing2009StochasticMI}
Carlo~R. Laing and Gabriel~J. Lord.
\newblock Stochastic methods in neuroscience.
\newblock 2009.

\bibitem[Langford and Zhang(2007)]{langford2007epoch}
John Langford and Tong Zhang.
\newblock The epoch-greedy algorithm for contextual multi-armed bandits.
\newblock \emph{Advances in neural information processing systems}, 20\penalty0
  (1):\penalty0 96--1, 2007.

\bibitem[Lee et~al.(2019)Lee, Lee, Kim, Kosiorek, Choi, and Teh]{lee2019set}
Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee~Whye
  Teh.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In \emph{International conference on machine learning}, pages
  3744--3753. PMLR, 2019.

\bibitem[Li et~al.(2020)Li, Chen, Wong, and Duvenaud]{sdes2020}
Xuechen Li, Ricky Tian~Qi Chen, Ting-Kam~Leonard Wong, and David Duvenaud.
\newblock Scalable gradients for stochastic differential equations.
\newblock In \emph{Artificial Intelligence and Statistics}, 2020.

\bibitem[Maro{\~n}as et~al.(2021)Maro{\~n}as, Hamelijnck, Knoblauch, and
  Damoulas]{maronas2021transforming}
Juan Maro{\~n}as, Oliver Hamelijnck, Jeremias Knoblauch, and Theodoros
  Damoulas.
\newblock Transforming gaussian processes with normalizing flows.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1081--1089. PMLR, 2021.

\bibitem[Mathieu et~al.(2021)Mathieu, Foster, and Teh]{Mathieu2021OnCR}
Emile Mathieu, Adam Foster, and Yee~Whye Teh.
\newblock On contrastive representations of stochastic processes.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Mohamed et~al.(2020)Mohamed, Rosca, Figurnov, and
  Mnih]{mohamed2020monte}
Shakir Mohamed, Mihaela Rosca, Michael Figurnov, and Andriy Mnih.
\newblock Monte carlo gradient estimation in machine learning.
\newblock \emph{J. Mach. Learn. Res.}, 21\penalty0 (132):\penalty0 1--62, 2020.

\bibitem[Nelsen(2007)]{nelsen2007introduction}
Roger~B Nelsen.
\newblock \emph{An introduction to copulas}.
\newblock Springer Science \& Business Media, 2007.

\bibitem[Papamakarios et~al.(2019)Papamakarios, Murray, Gorham, and
  Sohl-Dickstein]{papamakarios2019normalizing}
George Papamakarios, Iain Murray, Matthew Gorham, and Jascha Sohl-Dickstein.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock \emph{arXiv preprint arXiv:1912.02762}, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Paul and Baschnagel(2000)]{Paul2000StochasticPF}
Wolfgang Paul and J{\"o}rg Baschnagel.
\newblock Stochastic processes: From physics to finance.
\newblock 2000.

\bibitem[Rainforth et~al.(2023)Rainforth, Foster, Ivanova, and
  Smith]{rainforth2023modern}
Tom Rainforth, Adam Foster, Desi~R Ivanova, and Freddie~Bickford Smith.
\newblock Modern bayesian experimental design.
\newblock \emph{arXiv preprint arXiv:2302.14545}, 2023.

\bibitem[Rasmussen and Williams(2009)]{Rasmussen2009GaussianPF}
Carl~Edward Rasmussen and Christopher K.~I. Williams.
\newblock Gaussian processes for machine learning.
\newblock In \emph{Adaptive computation and machine learning}, 2009.

\bibitem[Rasmussen and Williams(2006)]{rasmussen2006gaussian}
Carl~Edward Rasmussen and Christopher~KI Williams.
\newblock \emph{Gaussian processes for machine learning}.
\newblock MIT press, 2006.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem[Riquelme et~al.(2018)Riquelme, Tucker, and Snoek]{riquelme2018deep}
Carlos Riquelme, George Tucker, and Jasper Snoek.
\newblock Deep bayesian bandits showdown: An empirical comparison of bayesian
  deep networks for thompson sampling.
\newblock \emph{arXiv preprint arXiv:1802.09127}, 2018.

\bibitem[Settles(2009)]{settles2009active}
Settles.
\newblock Active learning literature survey.
\newblock Technical report, University of Wisconsin, Madison, 2009.

\bibitem[Shah et~al.(2014)Shah, Wilson, and Ghahramani]{shah14}
Amar Shah, Andrew Wilson, and Zoubin Ghahramani.
\newblock {Student-t Processes as Alternatives to Gaussian Processes}.
\newblock In Samuel Kaski and Jukka Corander, editors, \emph{Proceedings of the
  Seventeenth International Conference on Artificial Intelligence and
  Statistics}, volume~33 of \emph{Proceedings of Machine Learning Research},
  pages 877--885, Reykjavik, Iceland, 22--25 Apr 2014. PMLR.

\bibitem[Strebelle(2002)]{strebelle2002conditional}
Sebastien Strebelle.
\newblock Conditional simulation of complex geological structures using
  multiple-point statistics.
\newblock \emph{Mathematical geology}, 34\penalty0 (1):\penalty0 1--21, 2002.

\bibitem[Sylvester et~al.(2019)Sylvester, Durkin, and
  Covault]{sylvester2019high}
Zolt{\'a}n Sylvester, Paul Durkin, and Jacob~A Covault.
\newblock High curvatures drive river meandering.
\newblock \emph{Geology}, 47\penalty0 (3):\penalty0 263--266, 2019.

\bibitem[Tancik et~al.(2020)Tancik, Srinivasan, Mildenhall, Fridovich-Keil,
  Raghavan, Singhal, Ramamoorthi, Barron, and Ng]{tancik2020fourier}
Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin
  Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng.
\newblock Fourier features let networks learn high frequency functions in low
  dimensional domains.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 7537--7547, 2020.

\bibitem[Teh et~al.(2004)Teh, Jordan, Beal, and Blei]{teh2004sharing}
Yee Teh, Michael Jordan, Matthew Beal, and David Blei.
\newblock Sharing clusters among related groups: Hierarchical dirichlet
  processes.
\newblock \emph{Advances in neural information processing systems}, 17, 2004.

\bibitem[van Kampen and Reinhardt(1981)]{Kampen1981StochasticPI}
Nico~G. van Kampen and William~P. Reinhardt.
\newblock Stochastic processes in physics and chemistry.
\newblock 1981.

\bibitem[Wilson and Ghahramani(2010)]{wilson2010copula}
Andrew~G Wilson and Zoubin Ghahramani.
\newblock Copula processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 23, 2010.

\bibitem[Wilson et~al.(2016)Wilson, Hoffman, Wang, Fox, and
  Ghahramani]{wilson2016deep}
Andrew~Gordon Wilson, Matthew~D Hoffman, Cheng Wang, Eric Fox, and Zoubin
  Ghahramani.
\newblock Deep gaussian processes with stochastic backpropagation.
\newblock In \emph{International Conference on Machine Learning}, pages
  1436--1445, 2016.

\bibitem[Xu et~al.(2020)Xu, Ton, Kim, Kosiorek, and Teh]{xu2020metafun}
Jin Xu, Jean-Francois Ton, Hyunjik Kim, Adam Kosiorek, and Yee~Whye Teh.
\newblock Metafun: Meta-learning with iterative functional updates.
\newblock In \emph{International Conference on Machine Learning}, pages
  10617--10627. PMLR, 2020.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ~R
  Salakhutdinov, and Alexander~J Smola.
\newblock Deep sets.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Zhang et~al.(2019)Zhang, Tilke, Dupont, Zhu, Liang, and
  Bailey]{zhang2019generating}
Tuan-Feng Zhang, Peter Tilke, Emilien Dupont, Ling-Chen Zhu, Lin Liang, and
  William Bailey.
\newblock Generating geologically realistic 3d reservoir facies models using
  deep learning of sedimentary architecture with generative adversarial
  networks.
\newblock \emph{Petroleum Science}, 16\penalty0 (3):\penalty0 541--549, 2019.

\bibitem[Zhang et~al.(2006)Zhang, Switzer, and Journel]{zhang2006filter}
Tuanfeng Zhang, Paul Switzer, and Andre Journel.
\newblock Filter-based classification of training image patterns for spatial
  simulation.
\newblock \emph{Mathematical Geology}, 38\penalty0 (1):\penalty0 63--80, 2006.

\end{thebibliography}
