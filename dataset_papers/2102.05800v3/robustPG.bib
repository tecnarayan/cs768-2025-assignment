

@article{schulman2015high,
	title={High-dimensional continuous control using generalized advantage estimation},
	author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1506.02438},
	year={2015}
}

@article{zhang2020stability,
	title={On the stability and convergence of robust adversarial reinforcement learning: A case study on linear quadratic systems},
	author={Zhang, Kaiqing and Hu, Bin and Basar, Tamer},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@inproceedings{zinkevich2003online,
	title={Online convex programming and generalized infinitesimal gradient ascent},
	author={Zinkevich, Martin},
	booktitle={Proceedings of the 20th international conference on machine learning (icml-03)},
	pages={928--936},
	year={2003}
}

@inproceedings{zhang2020policy,
	title={Policy Optimization for H-2 Linear Control with H-$\infty$ Robustness Guarantee: Implicit Regularization and Global Convergence},
	author={Zhang, Kaiqing and Hu, Bin and Basar, Tamer},
	booktitle={Learning for Dynamics and Control},
	pages={179--190},
	year={2020},
	organization={PMLR}
}

@article{zhang2021derivative,
	title={Derivative-Free Policy Optimization for Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity},
	author={Zhang, Kaiqing and Zhang, Xiangyuan and Hu, Bin and Ba{\c{s}}ar, Tamer},
	journal={arXiv preprint arXiv:2101.01041},
	year={2021}
}

@inproceedings{pinto2017robust,
	title={Robust adversarial reinforcement learning},
	author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
	booktitle={International Conference on Machine Learning},
	pages={2817--2826},
	year={2017},
	organization={PMLR}
}

@book{zhou1998essentials,
	title={Essentials of robust control},
	author={Zhou, Kemin and Doyle, John Comstock},
	volume={104},
	year={1998},
	publisher={Prentice hall Upper Saddle River, NJ}
}

@inproceedings{derman2020bayesian,
	title={A bayesian approach to robust reinforcement learning},
	author={Derman, Esther and Mankowitz, Daniel and Mann, Timothy and Mannor, Shie},
	booktitle={Uncertainty in Artificial Intelligence},
	pages={648--658},
	year={2020},
	organization={PMLR}
}

@book{petersen2012robust,
	title={Robust Control Design Using H-$\infty$ Methods},
	author={Petersen, Ian R and Ugrinovskii, Valery A and Savkin, Andrey V},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@inproceedings{jin2020learning,
	title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
	author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
	booktitle={International Conference on Machine Learning},
	pages={4860--4869},
	year={2020},
	organization={PMLR}
}

@inproceedings{yang2019sample,
	title={Sample-optimal parametric Q-learning using linearly additive features},
	author={Yang, Lin and Wang, Mengdi},
	booktitle={International Conference on Machine Learning},
	pages={6995--7004},
	year={2019},
	organization={PMLR}
}

@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}

@article{tropp2015introduction,
	title={An introduction to matrix concentration inequalities},
	author={Tropp, Joel A},
	journal={arXiv preprint arXiv:1501.01571},
	year={2015}
}

@article{lee2020bias,
	title={Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs},
	author={Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu and Zhang, Mengxiao},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@article{osband2016lower,
	title={On lower bounds for regret in reinforcement learning},
	author={Osband, Ian and Van Roy, Benjamin},
	journal={arXiv preprint arXiv:1608.02732},
	year={2016}
}

@article{jin2019short,
	title={A short note on concentration inequalities for random vectors with subgaussian norm},
	author={Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M and Jordan, Michael I},
	journal={arXiv preprint arXiv:1902.03736},
	year={2019}
}

@article{jin2020simultaneously,
	title={Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition},
	author={Jin, Tiancheng and Luo, Haipeng},
	journal={arXiv preprint arXiv:2006.05606},
	year={2020}
}

@inproceedings{jin2020provably,
	title={Provably efficient reinforcement learning with linear function approximation},
	author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
	booktitle={Conference on Learning Theory},
	pages={2137--2143},
	year={2020},
	organization={PMLR}
}

@inproceedings{dann2017unifying,
	title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
	author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5713--5723},
	year={2017}
}

@article{neu2020online,
	title={Online learning in MDPs with linear function approximation and bandit feedback},
	author={Neu, Gergely and Olkhovskaya, Julia},
	journal={arXiv preprint arXiv:2007.01612},
	year={2020}
}

@inproceedings{dann2015sample,
	title={Sample complexity of episodic fixed-horizon reinforcement learning},
	author={Dann, Christoph and Brunskill, Emma},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2818--2826},
	year={2015}
}

@inproceedings{yadkori2013online,
	title={Online learning in Markov decision processes with adversarially chosen transition probability distributions},
	author={Yadkori, Yasin Abbasi and Bartlett, Peter L and Kanade, Varun and Seldin, Yevgeny and Szepesv{\'a}ri, Csaba},
	booktitle={Advances in neural information processing systems},
	pages={2508--2516},
	year={2013}
}

@article{neff2016automation,
	title={Automation, algorithms, and politics| talking to Bots: Symbiotic agency and the case of Tay},
	author={Neff, Gina and Nagy, Peter},
	journal={International Journal of Communication},
	volume={10},
	pages={17},
	year={2016}
}

@inproceedings{ma2019policy,
	title={Policy poisoning in batch reinforcement learning and control},
	author={Ma, Yuzhe and Zhang, Xuezhou and Sun, Wen and Zhu, Jerry},
	booktitle={Advances in Neural Information Processing Systems},
	pages={14570--14580},
	year={2019}
}

@InProceedings{jin2018q,
	author    = {Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
	booktitle = {Advances in Neural Information Processing Systems},
	title     = {Is q-learning provably efficient?},
	pages     = {4863--4873},
	year      = {2018},
}

@article{ayoub2020model,
	title={Model-Based Reinforcement Learning with Value-Targeted Regression},
	author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin F},
	journal={arXiv preprint arXiv:2006.01107},
	year={2020}
}

@article{zhang2020adaptive,
	title={Adaptive Reward-Poisoning Attacks against Reinforcement Learning},
	author={Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish and Zhu, Xiaojin},
	journal={arXiv preprint arXiv:2003.12613},
	year={2020}
}

@inproceedings{schulman2015trust,
	title={Trust region policy optimization},
	author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	booktitle={International conference on machine learning},
	pages={1889--1897},
	year={2015}
}

@article{diakonikolas2017being,
	title={Being robust (in high dimensions) can be practical},
	author={Diakonikolas, Ilias and Kamath, Gautam and Kane, Daniel M and Li, Jerry and Moitra, Ankur and Stewart, Alistair},
	journal={arXiv preprint arXiv:1703.00893},
	year={2017}
}

@inproceedings{lai2016agnostic,
	title={Agnostic estimation of mean and covariance},
	author={Lai, Kevin A and Rao, Anup B and Vempala, Santosh},
	booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)},
	pages={665--674},
	year={2016},
	organization={IEEE}
}

@inproceedings{diakonikolas2016robust,
	title={Robust Estimators in High Dimensions without the Computational Intractability},
	author={Diakonikolas, I and Kamath, G and Kane, DM and Li, J and Moitra, A and Stewart, A},
	booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)},
	pages={655--664},
	year={2016}
}

@article{cai2019provably,
	title={Provably efficient exploration in policy optimization},
	author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
	journal={arXiv preprint arXiv:1912.05830},
	year={2019}
}

@article{zhou2020provably,
	title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
	author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
	journal={arXiv preprint arXiv:2006.13165},
	year={2020}
}

@inproceedings{zanette2020frequentist,
	title={Frequentist regret bounds for randomized least-squares value iteration},
	author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={1954--1964},
	year={2020}
}

@inproceedings{jiang2017contextual,
	title={Contextual decision processes with low bellman rank are pac-learnable},
	author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
	booktitle={International Conference on Machine Learning},
	pages={1704--1713},
	year={2017},
	organization={PMLR}
}

@InProceedings{auer2009near,
	author    = {Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
	booktitle = {Advances in neural information processing systems},
	title     = {Near-optimal regret bounds for reinforcement learning},
	pages     = {89--96},
	year      = {2009},
}

@article{yang2019reinforcement,
	title={Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
	author={Yang, Lin F and Wang, Mengdi},
	journal={arXiv preprint arXiv:1905.10389},
	year={2019}
}

@InProceedings{azar2017minimax,
	author    = {Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
	booktitle = {International Conference on Machine Learning},
	title     = {Minimax Regret Bounds for Reinforcement Learning},
	pages     = {263--272},
	year      = {2017},
}

@article{bubeck2012regret,
	title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
	author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo},
	journal={arXiv preprint arXiv:1204.5721},
	year={2012}
}

@article{gupta2019better,
	title={Better algorithms for stochastic bandits with adversarial corruptions},
	author={Gupta, Anupam and Koren, Tomer and Talwar, Kunal},
	journal={arXiv preprint arXiv:1902.08647},
	year={2019}
}

@inproceedings{lykouris2018stochastic,
	title={Stochastic bandits robust to adversarial corruptions},
	author={Lykouris, Thodoris and Mirrokni, Vahab and Paes Leme, Renato},
	booktitle={Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing},
	pages={114--122},
	year={2018}
}

@article{shalev2011online,
	title={Online learning and online convex optimization},
	author={Shalev-Shwartz, Shai and others},
	journal={Foundations and trends in Machine Learning},
	volume={4},
	number={2},
	pages={107--194},
	year={2011}
}

@article{kakade2001natural,
	title={A natural policy gradient},
	author={Kakade, Sham M},
	journal={Advances in neural information processing systems},
	volume={14},
	pages={1531--1538},
	year={2001}
}

@article{huber1964robust,
	title={Robust Estimation of a Location Parameter},
	author={Huber, Peter J},
	journal={The Annals of Mathematical Statistics},
	pages={73--101},
	year={1964},
	publisher={JSTOR}
}

@inproceedings{todorov2012mujoco,
	title={Mujoco: A physics engine for model-based control},
	author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
	booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
	pages={5026--5033},
	year={2012},
	organization={IEEE}
}

@inproceedings{eykholt2018robust,
	title={Robust physical-world attacks on deep learning visual classification},
	author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={1625--1634},
	year={2018}
}

@article{agarwal2019optimality,
	title={On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift},
	author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
	journal={arXiv preprint arXiv:1908.00261},
	year={2019}
}

@inproceedings{diakonikolas2019sever,
	title={Sever: A robust meta-algorithm for stochastic optimization},
	author={Diakonikolas, Ilias and Kamath, Gautam and Kane, Daniel and Li, Jerry and Steinhardt, Jacob and Stewart, Alistair},
	booktitle={International Conference on Machine Learning},
	pages={1596--1606},
	year={2019}
}

@article{agarwal2020pc,
	title={PC-PG: Policy cover directed exploration for provable policy gradient learning},
	author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
	journal={arXiv preprint arXiv:2007.08459},
	year={2020}
}

@article{even2009online,
	title={Online Markov decision processes},
	author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
	journal={Mathematics of Operations Research},
	volume={34},
	number={3},
	pages={726--736},
	year={2009},
	publisher={INFORMS}
}

@article{brafman2002r,
	title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
	author={Brafman, Ronen I and Tennenholtz, Moshe},
	journal={Journal of Machine Learning Research},
	volume={3},
	number={Oct},
	pages={213--231},
	year={2002}
}

@inproceedings{neu2010online,
	title={The Online Loop-free Stochastic Shortest-Path Problem.},
	author={Neu, Gergely and Gy{\"o}rgy, Andr{\'a}s and Szepesv{\'a}ri, Csaba},
	booktitle={COLT},
	volume={2010},
	pages={231--243},
	year={2010},
	organization={Citeseer}
}

@inproceedings{neu2012adversarial,
	title={The adversarial stochastic shortest path problem with unknown transition probabilities},
	author={Neu, Gergely and Gyorgy, Andras and Szepesv{\'a}ri, Csaba},
	booktitle={Artificial Intelligence and Statistics},
	pages={805--813},
	year={2012}
}

@inproceedings{zimin2013online,
	title={Online learning in episodic Markovian decision processes by relative entropy policy search},
	author={Zimin, Alexander and Neu, Gergely},
	booktitle={Advances in neural information processing systems},
	pages={1583--1591},
	year={2013}
}

@article{domingues2020kernel,
	title={A kernel-based approach to non-stationary reinforcement learning in metric spaces},
	author={Domingues, Omar Darwiche and M{\'e}nard, Pierre and Pirotta, Matteo and Kaufmann, Emilie and Valko, Michal},
	journal={arXiv preprint arXiv:2007.05078},
	year={2020}
}

@article{rosenberg2019online,
	title={Online convex optimization in adversarial markov decision processes},
	author={Rosenberg, Aviv and Mansour, Yishay},
	journal={arXiv preprint arXiv:1905.07773},
	year={2019}
}

@article{cheung2019non,
	title={Non-Stationary Reinforcement Learning: The Blessing of (More) Optimism},
	author={Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
	journal={Available at SSRN 3397818},
	year={2019}
}

@article{ornik2019learning,
	title={Learning and Planning for Time-Varying MDPs Using Maximum Likelihood Estimation},
	author={Ornik, Melkior and Topcu, Ufuk},
	journal={arXiv preprint arXiv:1911.12976},
	year={2019}
}

@article{lykouris2019corruption,
	title={Corruption robust exploration in episodic reinforcement learning},
	author={Lykouris, Thodoris and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
	journal={arXiv preprint arXiv:1911.08689},
	year={2019}
}

@inproceedings{ortner2019variational,
	title={Variational Regret Bounds for Reinforcement Learning.},
	author={Ortner, Ronald and Gajane, Pratik and Auer, Peter},
	booktitle={UAI},
	pages={16},
	year={2019}
}

@inproceedings{charikar2017learning,
	title={Learning from untrusted data},
	author={Charikar, Moses and Steinhardt, Jacob and Valiant, Gregory},
	booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
	pages={47--60},
	year={2017}
}

@article{diakonikolas2019recent,
	title={Recent advances in algorithmic high-dimensional robust statistics},
	author={Diakonikolas, Ilias and Kane, Daniel M},
	journal={arXiv preprint arXiv:1911.05911},
	year={2019}
}

@article{arora2012online,
	title={Online bandit learning against an adaptive adversary: from regret to policy regret},
	author={Arora, Raman and Dekel, Ofer and Tewari, Ambuj},
	journal={arXiv preprint arXiv:1206.6400},
	year={2012}
}

@inproceedings{sun2019model,
	title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
	author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
	booktitle={Conference on Learning Theory},
	pages={2898--2933},
	year={2019},
	organization={PMLR}
}

@inproceedings{du2019provably,
	title={Provably efficient Q-learning with function approximation via distribution shift error checking oracle},
	author={Du, Simon S and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
	booktitle={Advances in Neural Information Processing Systems},
	pages={8060--8070},
	year={2019}
}

@article{osband2014model,
	title={Model-based reinforcement learning and the eluder dimension},
	author={Osband, Ian and Van Roy, Benjamin},
	journal={Advances in Neural Information Processing Systems},
	volume={27},
	pages={1466--1474},
	year={2014}
}

@article{kakade2020information,
	title={Information theoretic regret bounds for online nonlinear control},
	author={Kakade, Sham and Krishnamurthy, Akshay and Lowrey, Kendall and Ohnishi, Motoya and Sun, Wen},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@article{agarwal2020flambe,
	title={Flambe: Structural complexity and representation learning of low rank mdps},
	author={Agarwal, Alekh and Kakade, Sham and Krishnamurthy, Akshay and Sun, Wen},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@article{berner2019dota,
	title={Dota 2 with large scale deep reinforcement learning},
	author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
	journal={arXiv preprint arXiv:1912.06680},
	year={2019}
}
@article{akkaya2019solving,
	title={Solving rubik's cube with a robot hand},
	author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
	journal={arXiv preprint arXiv:1910.07113},
	year={2019}
}

@Article{williams1992simple,
	author    = {Williams, Ronald J},
	title     = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	journal   = {Machine learning},
	year      = {1992},
	volume    = {8},
	number    = {3-4},
	pages     = {229--256},
	publisher = {Springer},
}

@InProceedings{sutton1999policy,
	author    = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
	title     = {Policy gradient methods for reinforcement learning with function approximation},
	booktitle = {Advances in Neural Information Processing Systems},
	year      = {1999},
	volume    = {99},
	pages     = {1057--1063},
}

@inproceedings{kakade2002approximately,
	title={Approximately optimal approximate reinforcement learning},
	author={Kakade, Sham and Langford, John},
	booktitle={ICML},
	volume={2},
	pages={267--274},
	year={2002}
}

@article{diakonikolas2020outlier,
	title={Outlier robust mean estimation with subgaussian rates via stability},
	author={Diakonikolas, Ilias and Kane, Daniel M and Pensia, Ankit},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}
