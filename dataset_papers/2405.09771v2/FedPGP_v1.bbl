\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghajanyan et~al.(2020)Aghajanyan, Zettlemoyer, and Gupta]{aghajanyan2020intrinsic}
Aghajanyan, A., Zettlemoyer, L., and Gupta, S.
\newblock Intrinsic dimensionality explains the effectiveness of language model fine-tuning.
\newblock \emph{arXiv preprint arXiv:2012.13255}, 2020.

\bibitem[Arivazhagan et~al.(2019)Arivazhagan, Aggarwal, Singh, and Choudhary]{arivazhagan2019federated}
Arivazhagan, M.~G., Aggarwal, V., Singh, A.~K., and Choudhary, S.
\newblock Federated learning with personalization layers.
\newblock \emph{arXiv preprint arXiv:1912.00818}, 2019.

\bibitem[Bossard et~al.(2014)Bossard, Guillaumin, and Van~Gool]{bossard2014food}
Bossard, L., Guillaumin, M., and Van~Gool, L.
\newblock Food-101--mining discriminative components with random forests.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VI 13}, pp.\  446--461. Springer, 2014.

\bibitem[Cai et~al.(2024)Cai, Shi, Huang, and Wang]{cai2024fed}
Cai, Z., Shi, Y., Huang, W., and Wang, J.
\newblock Fed-{CO}$_2$: Cooperation of online and offline models for severe data heterogeneity in federated learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Cao et~al.(2023)Cao, Shi, Yu, Wang, and Tao]{cao2023knowledge}
Cao, Y.-T., Shi, Y., Yu, B., Wang, J., and Tao, D.
\newblock Knowledge-aware federated active learning with non-iid data.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  22279--22289, 2023.

\bibitem[Chen \& Chao(2021)Chen and Chao]{chen2021bridging}
Chen, H.-Y. and Chao, W.-L.
\newblock On bridging generic and personalized federated learning for image classification.
\newblock \emph{arXiv preprint arXiv:2107.00778}, 2021.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International conference on machine learning}, pp.\  1597--1607. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Fan, Girshick, and He]{chen2020improved}
Chen, X., Fan, H., Girshick, R., and He, K.
\newblock Improved baselines with momentum contrastive learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}, 2020{\natexlab{b}}.

\bibitem[Cheng et~al.(2021)Cheng, Chadha, and Duchi]{cheng2021fine}
Cheng, G., Chadha, K., and Duchi, J.
\newblock Fine-tuning is fine in federated learning.
\newblock \emph{arXiv preprint arXiv:2108.07313}, 3, 2021.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{cimpoi2014describing}
Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., and Vedaldi, A.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  3606--3613, 2014.

\bibitem[Collins et~al.(2021)Collins, Hassani, Mokhtari, and Shakkottai]{collins2021exploiting}
Collins, L., Hassani, H., Mokhtari, A., and Shakkottai, S.
\newblock Exploiting shared representations for personalized federated learning.
\newblock In \emph{International conference on machine learning}, pp.\  2089--2099. PMLR, 2021.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Fei-Fei(2004)]{fei2004learning}
Fei-Fei, L.
\newblock Learning generative visual models from few training examples.
\newblock In \emph{Workshop on Generative-Model Based Vision, IEEE Proc. CVPR, 2004}, 2004.

\bibitem[Feng et~al.(2023)Feng, Li, Xu, Liu, Fu, and Zuo]{feng2023learning}
Feng, C.-M., Li, B., Xu, X., Liu, Y., Fu, H., and Zuo, W.
\newblock {Learning Federated Visual Prompt in Null Space for MRI Reconstruction}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  8064--8073, 2023.

\bibitem[Gong et~al.(2012)Gong, Shi, Sha, and Grauman]{gong2012geodesic}
Gong, B., Shi, Y., Sha, F., and Grauman, K.
\newblock Geodesic flow kernel for unsupervised domain adaptation.
\newblock In \emph{2012 IEEE conference on computer vision and pattern recognition}, pp.\  2066--2073. IEEE, 2012.

\bibitem[Guo et~al.(2023{\natexlab{a}})Guo, Guo, and Wang]{guo2023pfedprompt}
Guo, T., Guo, S., and Wang, J.
\newblock {pFedPrompt: Learning Personalized Prompt for Vision-Language Models in Federated Learning}.
\newblock In \emph{Proceedings of the ACM Web Conference 2023}, pp.\  1364--1374, 2023{\natexlab{a}}.

\bibitem[Guo et~al.(2023{\natexlab{b}})Guo, Guo, Wang, Tang, and Xu]{guo2023promptfl}
Guo, T., Guo, S., Wang, J., Tang, X., and Xu, W.
\newblock {Prompt{FL}: Let federated participants cooperatively learn prompts instead of models-federated learning in age of foundation model}.
\newblock \emph{IEEE Transactions on Mobile Computing}, 2023{\natexlab{b}}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  770--778, 2016.

\bibitem[Huang et~al.(2023)Huang, Shi, Cai, and Suzuki]{huang2023understanding}
Huang, W., Shi, Y., Cai, Z., and Suzuki, T.
\newblock Understanding convergence and generalization in federated learning through feature learning theory.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[Huang et~al.(2021)Huang, Chu, Zhou, Wang, Liu, Pei, and Zhang]{huang2021personalized}
Huang, Y., Chu, L., Zhou, Z., Wang, L., Liu, J., Pei, J., and Zhang, Y.
\newblock Personalized cross-silo federated learning on non-iid data.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~35, pp.\  7865--7873, 2021.

\bibitem[Hyeon-Woo et~al.(2021)Hyeon-Woo, Ye-Bin, and Oh]{hyeon2021fedpara}
Hyeon-Woo, N., Ye-Bin, M., and Oh, T.-H.
\newblock Fedpara: Low-rank hadamard product for communication-efficient federated learning.
\newblock \emph{arXiv preprint arXiv:2108.06098}, 2021.

\bibitem[Jeong \& Hwang(2022)Jeong and Hwang]{jeong2022factorized}
Jeong, W. and Hwang, S.~J.
\newblock {Factorized-FL: Personalized Federated Learning with Parameter Factorization \& Similarity Matching}.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 35684--35695, 2022.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig]{jia2021scaling}
Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh, Z., Pham, H., Le, Q., Sung, Y.-H., Li, Z., and Duerig, T.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In \emph{International conference on machine learning}, pp.\  4904--4916. PMLR, 2021.

\bibitem[Khattak et~al.(2023{\natexlab{a}})Khattak, Rasheed, Maaz, Khan, and Khan]{khattak2023maple}
Khattak, M.~U., Rasheed, H., Maaz, M., Khan, S., and Khan, F.~S.
\newblock {Maple: Multi-modal prompt learning}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  19113--19122, 2023{\natexlab{a}}.

\bibitem[Khattak et~al.(2023{\natexlab{b}})Khattak, Wasim, Naseer, Khan, Yang, and Khan]{khattak2023self}
Khattak, M.~U., Wasim, S.~T., Naseer, M., Khan, S., Yang, M.-H., and Khan, F.~S.
\newblock {Self-regulating Prompts: Foundational model adaptation without forgetting}.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  15190--15200, 2023{\natexlab{b}}.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2010)Krizhevsky, Nair, and Hinton]{krizhevsky2010cifar}
Krizhevsky, A., Nair, V., and Hinton, G.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock \emph{URL http://www. cs. toronto. edu/kriz/cifar. html}, 5\penalty0 (4):\penalty0 1, 2010.

\bibitem[Li et~al.(2023)Li, Cai, Wang, Tang, Ding, Lin, and Shi]{li2023fedtp}
Li, H., Cai, Z., Wang, J., Tang, J., Ding, W., Lin, C.-T., and Shi, Y.
\newblock {FedTP: Federated Learning by Transformer Personalization}.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 2023.

\bibitem[Li et~al.(2024)Li, Huang, Wang, and Shi]{li2024global}
Li, H., Huang, W., Wang, J., and Shi, Y.
\newblock Global and local prompts cooperation via optimal transport for federated learning.
\newblock \emph{In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, He, and Song]{li2021model}
Li, Q., He, B., and Song, D.
\newblock Model-contrastive federated learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10713--10722, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2020)Li, Sahu, Zaheer, Sanjabi, Talwalkar, and Smith]{li2020federated}
Li, T., Sahu, A.~K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V.
\newblock Federated optimization in heterogeneous networks.
\newblock \emph{Proceedings of Machine learning and systems}, 2:\penalty0 429--450, 2020.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Hu, Beirami, and Smith]{li2021ditto}
Li, T., Hu, S., Beirami, A., and Smith, V.
\newblock {Ditto: Fair and robust federated learning through personalization}.
\newblock In \emph{International Conference on Machine Learning}, pp.\  6357--6368. PMLR, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2021{\natexlab{c}})Li, Jiang, Zhang, Kamp, and Dou]{li2021fedbn}
Li, X., Jiang, M., Zhang, X., Kamp, M., and Dou, Q.
\newblock {FedBN: Federated learning on non-iid features via local batch normalization}.
\newblock \emph{arXiv preprint arXiv:2102.07623}, 2021{\natexlab{c}}.

\bibitem[Liu et~al.(2021)Liu, Chen, Qin, Dou, and Heng]{liu2021feddg}
Liu, Q., Chen, C., Qin, J., Dou, Q., and Heng, P.-A.
\newblock Fed{DG}: Federated domain generalization on medical image segmentation via episodic learning in continuous frequency space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1013--1023, 2021.

\bibitem[Ma et~al.(2023)Ma, Liu, Deng, Xie, Dong, and Xu]{ma2023understanding}
Ma, C., Liu, Y., Deng, J., Xie, L., Dong, W., and Xu, C.
\newblock Understanding and mitigating overfitting in prompt tuning for vision-language models.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video Technology}, 2023.

\bibitem[Ma et~al.(2022)Ma, Zhang, Guo, and Xu]{ma2022layer}
Ma, X., Zhang, J., Guo, S., and Xu, W.
\newblock Layer-wised model aggregation for personalized federated learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  10092--10101, 2022.

\bibitem[Mansour et~al.(2020)Mansour, Mohri, Ro, and Suresh]{mansour2020three}
Mansour, Y., Mohri, M., Ro, J., and Suresh, A.~T.
\newblock Three approaches for personalization with applications to federated learning.
\newblock \emph{arXiv preprint arXiv:2002.10619}, 2020.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized data.
\newblock In \emph{Artificial intelligence and statistics}, pp.\  1273--1282. PMLR, 2017.

\bibitem[Mu et~al.(2023)Mu, Shen, Cheng, Geng, Fu, Zhang, and Zhang]{mu2023fedproc}
Mu, X., Shen, Y., Cheng, K., Geng, X., Fu, J., Zhang, T., and Zhang, Z.
\newblock {FedProc: Prototypical contrastive federated learning on non-iid data}.
\newblock \emph{Future Generation Computer Systems}, 143:\penalty0 93--104, 2023.

\bibitem[Nguyen et~al.(2022)Nguyen, Torr, and Lim]{nguyen2022fedsr}
Nguyen, A.~T., Torr, P., and Lim, S.~N.
\newblock Fed{SR}: A simple and effective domain generalization method for federated learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 38831--38843, 2022.

\bibitem[Nilsback \& Zisserman(2008)Nilsback and Zisserman]{nilsback2008automated}
Nilsback, M.-E. and Zisserman, A.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{2008 Sixth Indian conference on computer vision, graphics \& image processing}, pp.\  722--729. IEEE, 2008.

\bibitem[Oh et~al.(2021)Oh, Kim, and Yun]{oh2021fedbabu}
Oh, J., Kim, S., and Yun, S.-Y.
\newblock {FedBABU: Towards enhanced representation for federated image classification}.
\newblock \emph{arXiv preprint arXiv:2106.06042}, 2021.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and Jawahar]{parkhi2012cats}
Parkhi, O.~M., Vedaldi, A., Zisserman, A., and Jawahar, C.
\newblock Cats and dogs.
\newblock In \emph{2012 IEEE conference on computer vision and pattern recognition}, pp.\  3498--3505. IEEE, 2012.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and Wang]{peng2019moment}
Peng, X., Bai, Q., Xia, X., Huang, Z., Saenko, K., and Wang, B.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  1406--1415, 2019.

\bibitem[Qiu et~al.(2023)Qiu, Li, Mummadi, Ganesh, Li, Peng, and Lin]{qiu2023text}
Qiu, C., Li, X., Mummadi, C.~K., Ganesh, M.~R., Li, Z., Peng, L., and Lin, W.-Y.
\newblock {Text-driven Prompt Generation for Vision-Language Models in Federated Learning}.
\newblock \emph{arXiv preprint arXiv:2310.06123}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Sattler et~al.(2020)Sattler, M{\"u}ller, and Samek]{sattler2020clustered}
Sattler, F., M{\"u}ller, K.-R., and Samek, W.
\newblock {Clustered federated learning: Model-agnostic distributed multitask optimization under privacy constraints}.
\newblock \emph{IEEE transactions on neural networks and learning systems}, 32\penalty0 (8):\penalty0 3710--3722, 2020.

\bibitem[Shamsian et~al.(2021)Shamsian, Navon, Fetaya, and Chechik]{shamsian2021personalized}
Shamsian, A., Navon, A., Fetaya, E., and Chechik, G.
\newblock Personalized federated learning using hypernetworks.
\newblock In \emph{International Conference on Machine Learning}, pp.\  9489--9502. PMLR, 2021.

\bibitem[Su et~al.(2022)Su, Yang, Li, and Xue]{su2022cross}
Su, S., Yang, M., Li, B., and Xue, X.
\newblock Cross-domain federated adaptive prompt tuning for clip.
\newblock \emph{arXiv preprint arXiv:2211.07864}, 2022.

\bibitem[T~Dinh et~al.(2020)T~Dinh, Tran, and Nguyen]{t2020personalized}
T~Dinh, C., Tran, N., and Nguyen, J.
\newblock Personalized federated learning with moreau envelopes.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 21394--21405, 2020.

\bibitem[Tan et~al.(2022{\natexlab{a}})Tan, Yu, Cui, and Yang]{tan2022towards}
Tan, A.~Z., Yu, H., Cui, L., and Yang, Q.
\newblock Towards personalized federated learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 2022{\natexlab{a}}.

\bibitem[Tan et~al.(2022{\natexlab{b}})Tan, Long, Ma, Liu, Zhou, and Jiang]{tan2022federated}
Tan, Y., Long, G., Ma, J., Liu, L., Zhou, T., and Jiang, J.
\newblock {Federated learning from pre-trained models: A contrastive learning approach}.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 19332--19344, 2022{\natexlab{b}}.

\bibitem[Wang et~al.(2019)Wang, Mathews, Kiddon, Eichner, Beaufays, and Ramage]{wang2019federated}
Wang, K., Mathews, R., Kiddon, C., Eichner, H., Beaufays, F., and Ramage, D.
\newblock Federated evaluation of on-device personalization.
\newblock \emph{arXiv preprint arXiv:1910.10252}, 2019.

\bibitem[Wei et~al.(2023)Wei, Wang, Shah, and Chellappa]{wei2023dual}
Wei, G., Wang, F., Shah, A., and Chellappa, R.
\newblock Dual prompt tuning for domain-aware federated learning.
\newblock \emph{arXiv preprint arXiv:2310.03103}, 2023.

\bibitem[Xie et~al.(2022)Xie, Zhang, Cao, Lin, Bao, Yao, Dai, and Hu]{xie2022simmim}
Xie, Z., Zhang, Z., Cao, Y., Lin, Y., Bao, J., Yao, Z., Dai, Q., and Hu, H.
\newblock {Simmim: A simple framework for masked image modeling}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  9653--9663, 2022.

\bibitem[Yang et~al.(2023)Yang, Wang, and Wang]{yang2023efficient}
Yang, F.-E., Wang, C.-Y., and Wang, Y.-C.~F.
\newblock Efficient model personalization in federated learning via client-specific prompt generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  19159--19168, 2023.

\bibitem[Zhang et~al.(2021)Zhang, Lei, Shi, Huang, and Chen]{zhang2021federated}
Zhang, L., Lei, X., Shi, Y., Huang, H., and Chen, C.
\newblock Federated learning with domain generalization.
\newblock \emph{arXiv preprint arXiv:2111.10487}, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Shi, Chang, and Lin]{zhang2022federated}
Zhang, L., Shi, Y., Chang, Y.-C., and Lin, C.-T.
\newblock Federated fuzzy neural network with evolutionary rule learning.
\newblock \emph{IEEE Transactions on Fuzzy Systems}, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Sapra, Fidler, Yeung, and Alvarez]{zhang2020personalized}
Zhang, M., Sapra, K., Fidler, S., Yeung, S., and Alvarez, J.~M.
\newblock Personalized federated learning with first order model optimization.
\newblock \emph{arXiv preprint arXiv:2012.08565}, 2020.

\bibitem[Zhao et~al.(2022)Zhao, Du, Li, Li, and Liu]{zhao2022reduce}
Zhao, H., Du, W., Li, F., Li, P., and Liu, G.
\newblock {Reduce communication costs and preserve privacy: Prompt tuning method in federated learning}.
\newblock \emph{arXiv preprint arXiv:2208.12268}, 2022.

\bibitem[Zhou et~al.(2022{\natexlab{a}})Zhou, Yang, Loy, and Liu]{zhou2022conditional}
Zhou, K., Yang, J., Loy, C.~C., and Liu, Z.
\newblock Conditional prompt learning for vision-language models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  16816--16825, 2022{\natexlab{a}}.

\bibitem[Zhou et~al.(2022{\natexlab{b}})Zhou, Yang, Loy, and Liu]{zhou2022learning}
Zhou, K., Yang, J., Loy, C.~C., and Liu, Z.
\newblock Learning to prompt for vision-language models.
\newblock \emph{International Journal of Computer Vision}, 130\penalty0 (9):\penalty0 2337--2348, 2022{\natexlab{b}}.

\bibitem[Zhu et~al.(2023)Zhu, Niu, Han, Wu, and Zhang]{zhu2023prompt}
Zhu, B., Niu, Y., Han, Y., Wu, Y., and Zhang, H.
\newblock Prompt-aligned gradient for prompt tuning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  15659--15669, 2023.

\end{thebibliography}
