\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri]{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2312--2320, 2011.

\bibitem[Abbasi-Yadkori et~al.(2012)Abbasi-Yadkori, Pal, and
  Szepesvari]{abbasi2012online}
Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari.
\newblock Online-to-confidence-set conversions and application to sparse
  stochastic bandits.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 1--9, 2012.

\bibitem[Agrawal and Goyal(2013)]{agrawal2013thompson}
Shipra Agrawal and Navin Goyal.
\newblock Thompson sampling for contextual bandits with linear payoffs.
\newblock In \emph{International Conference on Machine Learning}, pages
  127--135, 2013.

\bibitem[Auer(2002)]{auer2002using}
Peter Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Bart{\'o}k et~al.(2014)Bart{\'o}k, Foster, P{\'a}l, Rakhlin, and
  Szepesv{\'a}ri]{BFPRS14}
G.~Bart{\'o}k, D.~P. Foster, D.~P{\'a}l, A.~Rakhlin, and Cs. Szepesv{\'a}ri.
\newblock Partial monitoring---classification, regret bounds, and algorithms.
\newblock \emph{Mathematics of Operations Research}, 39\penalty0 (4):\penalty0
  967--997, 2014.

\bibitem[Bastani and Bayati(2020)]{bastani2020online}
Hamsa Bastani and Mohsen Bayati.
\newblock Online decision making with high-dimensional covariates.
\newblock \emph{Operations Research}, 68\penalty0 (1):\penalty0 276--294, 2020.

\bibitem[Belloni et~al.(2013)Belloni, Chernozhukov, et~al.]{belloni2013least}
Alexandre Belloni, Victor Chernozhukov, et~al.
\newblock Least squares after model selection in high-dimensional sparse
  models.
\newblock \emph{Bernoulli}, 19\penalty0 (2):\penalty0 521--547, 2013.

\bibitem[Bickel et~al.(2009)Bickel, Ritov, Tsybakov,
  et~al.]{bickel2009simultaneous}
Peter~J Bickel, Yaâ€™acov Ritov, Alexandre~B Tsybakov, et~al.
\newblock Simultaneous analysis of lasso and dantzig selector.
\newblock \emph{The Annals of Statistics}, 37\penalty0 (4):\penalty0
  1705--1732, 2009.

\bibitem[Boyd et~al.(2004)Boyd, Boyd, and Vandenberghe]{boyd2004convex}
Stephen Boyd, Stephen~P Boyd, and Lieven Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[B{\"u}hlmann and Van De~Geer(2011)]{buhlmann2011statistics}
Peter B{\"u}hlmann and Sara Van De~Geer.
\newblock \emph{Statistics for high-dimensional data: methods, theory and
  applications}.
\newblock Springer Science \& Business Media, 2011.

\bibitem[Carpentier and Munos(2012)]{carpentier2012bandit}
Alexandra Carpentier and R{\'e}mi Munos.
\newblock Bandit theory meets compressed sensing for high dimensional
  stochastic linear bandit.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 190--198,
  2012.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 208--214, 2011.

\bibitem[Combes et~al.(2017)Combes, Magureanu, and
  Proutiere]{combes2017minimal}
Richard Combes, Stefan Magureanu, and Alexandre Proutiere.
\newblock Minimal exploration in structured stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1763--1771, 2017.

\bibitem[Dani et~al.(2008)Dani, Hayes, and Kakade]{dani2008stochastic}
Varsha Dani, Thomas~P Hayes, and Sham~M Kakade.
\newblock Stochastic linear optimization under bandit feedback.
\newblock 2008.

\bibitem[Deshmukh et~al.(2018)Deshmukh, Sharma, Cutler, Moldwin, and
  Scott]{deshmukh2018simple}
Aniket~Anand Deshmukh, Srinagesh Sharma, James~W Cutler, Mark Moldwin, and
  Clayton Scott.
\newblock Simple regret minimization for contextual bandits.
\newblock \emph{arXiv preprint arXiv:1810.07371}, 2018.

\bibitem[Deshpande and Montanari(2012)]{deshpande2012linear}
Yash Deshpande and Andrea Montanari.
\newblock Linear bandits in high dimension and recommendation systems.
\newblock In \emph{2012 50th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pages 1750--1754. IEEE, 2012.

\bibitem[Diamond and Boyd(2016)]{diamond2016cvxpy}
Steven Diamond and Stephen Boyd.
\newblock Cvxpy: A python-embedded modeling language for convex optimization.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2909--2913, 2016.

\bibitem[Hao et~al.(2020)Hao, Lattimore, and Szepesvari]{hao2019adaptive}
Botao Hao, Tor Lattimore, and Csaba Szepesvari.
\newblock Adaptive exploration in linear contextual bandit.
\newblock \emph{AISTATS}, 2020.

\bibitem[Javanmard and Montanari(2014)]{javanmard2014confidence}
Adel Javanmard and Andrea Montanari.
\newblock Confidence intervals and hypothesis testing for high-dimensional
  regression.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 2869--2909, 2014.

\bibitem[Javanmard et~al.(2018)Javanmard, Montanari,
  et~al.]{javanmard2018debiasing}
Adel Javanmard, Andrea Montanari, et~al.
\newblock Debiasing the lasso: Optimal sample size for gaussian designs.
\newblock \emph{The Annals of Statistics}, 46\penalty0 (6A):\penalty0
  2593--2622, 2018.

\bibitem[Kim and Paik(2019)]{kim2019doubly}
Gi-Soo Kim and Myunghee~Cho Paik.
\newblock Doubly-robust lasso bandit.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5869--5879, 2019.

\bibitem[Lattimore and Szepesvari(2017)]{lattimore2017end}
Tor Lattimore and Csaba Szepesvari.
\newblock The end of optimism? an asymptotic analysis of finite-armed linear
  bandits.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 728--737,
  2017.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2018bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lattimore et~al.(2015)Lattimore, Crammer, and
  Szepesv{\'a}ri]{lattimore2015linear}
Tor Lattimore, Koby Crammer, and Csaba Szepesv{\'a}ri.
\newblock Linear multi-resource allocation with semi-bandit feedback.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  964--972, 2015.

\bibitem[Lattimore et~al.(2020)Lattimore, Szepesvari, and
  Weisz]{lattimore2019learning}
Tor Lattimore, Csaba Szepesvari, and Gellert Weisz.
\newblock Learning with good feature representations in bandits and in rl with
  a generative model.
\newblock \emph{International Conference on Machine Learning}, 2020.

\bibitem[{Raskutti} et~al.(2011){Raskutti}, {Wainwright}, and {Yu}]{6034739}
G.~{Raskutti}, M.~J. {Wainwright}, and B.~{Yu}.
\newblock Minimax rates of estimation for high-dimensional linear regression
  over $\ell_q$ -balls.
\newblock \emph{IEEE Transactions on Information Theory}, 57\penalty0
  (10):\penalty0 6976--6994, 2011.

\bibitem[Rudelson and Zhou(2013)]{rudelson2013reconstruction}
Mark Rudelson and Shuheng Zhou.
\newblock Reconstruction from anisotropic random measurements.
\newblock \emph{IEEE Transactions on Information Theory}, 59\penalty0
  (6):\penalty0 3434--3447, 2013.

\bibitem[Rusmevichientong and Tsitsiklis(2010)]{rusmevichientong2010linearly}
Paat Rusmevichientong and John~N Tsitsiklis.
\newblock Linearly parameterized bandits.
\newblock \emph{Mathematics of Operations Research}, 35\penalty0 (2):\penalty0
  395--411, 2010.

\bibitem[Russo and Van~Roy(2014)]{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via posterior sampling.
\newblock \emph{Mathematics of Operations Research}, 39\penalty0 (4):\penalty0
  1221--1243, 2014.

\bibitem[Sivakumar et~al.(2020)Sivakumar, Wu, and
  Banerjee]{sivakumar2020structured}
Vidyashankar Sivakumar, Zhiwei~Steven Wu, and Arindam Banerjee.
\newblock Structured linear contextual bandits: A sharp and geometric smoothed
  analysis.
\newblock \emph{International Conference on Machine Learning}, 2020.

\bibitem[Tibshirani(1996)]{tibshirani1996}
R.~Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society, Series B},
  58:\penalty0 267--288, 1996.

\bibitem[Tsybakov(2008)]{Tsybakov:2008:INE:1522486}
Alexandre~B. Tsybakov.
\newblock \emph{Introduction to Nonparametric Estimation}.
\newblock Springer Publishing Company, Incorporated, 1st edition, 2008.
\newblock ISBN 0387790519, 9780387790510.

\bibitem[Vershynin(2010)]{vershynin2010introduction}
Roman Vershynin.
\newblock Introduction to the non-asymptotic analysis of random matrices.
\newblock \emph{arXiv preprint arXiv:1011.3027}, 2010.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\bibitem[Wang et~al.(2018)Wang, Wei, and Yao]{wang2018minimax}
Xue Wang, Mingcheng Wei, and Tao Yao.
\newblock Minimax concave penalized multi-armed bandit model with
  high-dimensional covariates.
\newblock In \emph{International Conference on Machine Learning}, pages
  5200--5208, 2018.

\end{thebibliography}
