% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{xu2022survey,
  title={A Survey on Pretrained Language Models for Neural Code Intelligence},
  author={Xu, Yichen and Zhu, Yanqiao},
  journal={arXiv preprint arXiv:2212.10079},
  year={2022}
}

@article{wang2021codet5,
  title={Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2109.00859},
  year={2021}
}

@misc{deepseekcoder, 
  title={Deepseek-ai/deepseek-coder: Deepseek coder: Let the code write itself}, 
  url={https://github.com/deepseek-ai/DeepSeek-Coder}, 
  author={Deepseek-Ai},
  year={2023}
} 

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@article{hendrycks2021measuring,
  title={Measuring coding challenge competence with apps},
  author={Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others},
  journal={arXiv preprint arXiv:2105.09938},
  year={2021}
}

@inproceedings{vaithilingam2022expectation,
  title={Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models},
  author={Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L},
  booktitle={Chi conference on human factors in computing systems extended abstracts},
  pages={1--7},
  year={2022}
}

@inproceedings{zan2023large,
  title={Large language models meet NL2Code: A survey},
  author={Zan, Daoguang and Chen, Bei and Zhang, Fengji and Lu, Dianjie and Wu, Bingchao and Guan, Bei and Yongji, Wang and Lou, Jian-Guang},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7443--7464},
  year={2023}
}

@article{fan2023large,
  title={Large language models for software engineering: Survey and open problems},
  author={Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M},
  journal={arXiv preprint arXiv:2310.03533},
  year={2023}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@article{shinn2023reflexion,
  title={Reflexion: an autonomous agent with dynamic memory and self-reflection},
  author={Shinn, Noah and Labash, Beck and Gopinath, Ashwin},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023}
}

@article{zelikman2022parsel,
  title={Parsel: A unified natural language framework for algorithmic reasoning},
  author={Zelikman, Eric and Huang, Qian and Poesia, Gabriel and Goodman, Noah D and Haber, Nick},
  journal={arXiv preprint arXiv:2212.10561},
  year={2022}
}

@article{openai2023gpt4,
  title={GPT-4 technical report},
  author={OpenAI, R},
  journal={arXiv},
  pages={2303--08774},
  year={2023}
}

@article{evalplusliu, 
  title={Is Your Code Generated by ChatGPT Really Correct?}, 
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming}, 
  journal={arXiv},
  language={en},
  year={2023}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

 @article{Ristad_Yianilos_1998, title={Learning string-edit distance}, volume={20}, ISSN={1939-3539}, DOI={10.1109/34.682181}, number={5}, journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, author={Ristad, E.S. and Yianilos, P.N.}, year={1998}, month=may, pages={522â€“532} }

@article{min2023recent,
  title={Recent advances in natural language processing via large pre-trained language models: A survey},
  author={Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
  journal={ACM Computing Surveys},
  volume={56},
  number={2},
  pages={1--40},
  year={2023},
  publisher={ACM New York, NY}
}

@article{alom2019state,
  title={A state-of-the-art survey on deep learning theory and architectures},
  author={Alom, Md Zahangir and Taha, Tarek M and Yakopcic, Chris and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Hasan, Mahmudul and Van Essen, Brian C and Awwal, Abdul AS and Asari, Vijayan K},
  journal={electronics},
  volume={8},
  number={3},
  pages={292},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{bakker2022fine,
  title={Fine-tuning language models to find agreement among humans with diverse preferences},
  author={Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38176--38189},
  year={2022}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@Misc{accelerate,
  title =        {Accelerate: Training and inference at scale made simple, efficient and adaptable.},
  author =       {Sylvain Gugger and Lysandre Debut and Thomas Wolf and Philipp Schmid and Zachary Mueller and Sourab Mangrulkar and Marc Sun and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/accelerate}},
  year =         {2022}
}

@inproceedings{aminabadi2022deepspeed,
  title={DeepSpeed-inference: enabling efficient inference of transformer models at unprecedented scale},
  author={Aminabadi, Reza Yazdani and Rajbhandari, Samyam and Awan, Ammar Ahmad and Li, Cheng and Li, Du and Zheng, Elton and Ruwase, Olatunji and Smith, Shaden and Zhang, Minjia and Rasley, Jeff and others},
  booktitle={SC22: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2022},
  organization={IEEE}
}

@article{dettmers2022llmint8,
  title={LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2208.07339},
  year={2022}
}

@inproceedings{joshi2003formalism,
  title={A formalism for dependency grammar based on tree adjoining grammar},
  author={Joshi, Aravind and Rambow, Owen},
  booktitle={Proceedings of the Conference on Meaning-text Theory},
  pages={207--216},
  year={2003},
  organization={MTT Paris, France}
}

@inproceedings{de2008z3,
  title={Z3: An efficient SMT solver},
  author={De Moura, Leonardo and Bj{\o}rner, Nikolaj},
  booktitle={International conference on Tools and Algorithms for the Construction and Analysis of Systems},
  pages={337--340},
  year={2008},
  organization={Springer}
}

@inproceedings{nguyen2013statistical,
  title={A statistical semantic language model for source code},
  author={Nguyen, Tung Thanh and Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tien N},
  booktitle={Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
  pages={532--542},
  year={2013}
}

@article{sutskever2008recurrent,
  title={The recurrent temporal restricted boltzmann machine},
  author={Sutskever, Ilya and Hinton, Geoffrey E and Taylor, Graham W},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{mastropaolo2021studying,
  title={Studying the usage of text-to-text transfer transformer to support code-related tasks},
  author={Mastropaolo, Antonio and Scalabrino, Simone and Cooper, Nathan and Palacio, David Nader and Poshyvanyk, Denys and Oliveto, Rocco and Bavota, Gabriele},
  booktitle={2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  pages={336--347},
  year={2021},
  organization={IEEE}
}

@article{ren2020codebleu,
  title={Codebleu: a method for automatic evaluation of code synthesis},
  author={Ren, Shuo and Guo, Daya and Lu, Shuai and Zhou, Long and Liu, Shujie and Tang, Duyu and Sundaresan, Neel and Zhou, Ming and Blanco, Ambrosio and Ma, Shuai},
  journal={arXiv preprint arXiv:2009.10297},
  year={2020}
}

@article{wang2022execution,
  title={Execution-based evaluation for open-domain code generation},
  author={Wang, Zhiruo and Zhou, Shuyan and Fried, Daniel and Neubig, Graham},
  journal={arXiv preprint arXiv:2212.10481},
  year={2022}
}

@article{athiwaratkun2022multi,
  title={Multi-lingual evaluation of code generation models},
  author={Athiwaratkun, Ben and Gouda, Sanjay Krishna and Wang, Zijian and Li, Xiaopeng and Tian, Yuchen and Tan, Ming and Ahmad, Wasi Uddin and Wang, Shiqi and Sun, Qing and Shang, Mingyue and others},
  journal={arXiv preprint arXiv:2210.14868},
  year={2022}
}

@inproceedings{siddiq2022securityeval,
  title={SecurityEval dataset: mining vulnerability examples to evaluate machine learning-based code generation techniques},
  author={Siddiq, Mohammed Latif and Santos, Joanna CS},
  booktitle={Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security},
  pages={29--33},
  year={2022}
}

@inproceedings{lai2023ds,
  title={DS-1000: A natural and reliable benchmark for data science code generation},
  author={Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Wen-tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  booktitle={International Conference on Machine Learning},
  pages={18319--18345},
  year={2023},
  organization={PMLR}
}

@article{zan2022language,
  title={When language model meets private library},
  author={Zan, Daoguang and Chen, Bei and Lin, Zeqi and Guan, Bei and Wang, Yongji and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2210.17236},
  year={2022}
}

@article{zan2022large,
  title={Large language models meet nl2code: A survey},
  author={Zan, Daoguang and Chen, Bei and Zhang, Fengji and Lu, Dianjie and Wu, Bingchao and Guan, Bei and Wang, Yongji and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2212.09420},
  year={2022}
}

@article{nijkamp2022codegen,
  title={Codegen: An open large language model for code with multi-turn program synthesis},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  journal={arXiv preprint arXiv:2203.13474},
  year={2022}
}

@misc{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways (No. arXiv: 2204.02311). arXiv},
  author={Chowdhery, A and Narang, S and Devlin, J and Bosma, M and Mishra, G and Roberts, A and Barham, P and Chung, HW and Sutton, C and Gehrmann, S and others},
  year={2022}
}

@article{li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{kir2017overcome,
    author={Kirkpatrick,James and Pascanu,Razvan and Rabinowitz,Neil and Veness,Joel and Desjardins,Guillaume and Rusu,Andrei A. and Milan,Kieran and Quan,John and Ramalho,Tiago and Grabska-Barwinska,Agnieszka and Hassabis,Demis and Clopath,Claudia and Kumaran,Dharshan and Hadsell,Raia},
    year={2017},
    title={Overcoming catastrophic forgetting in neural networks},
    journal={Proceedings of the National Academy of Sciences - PNAS},
    volume={114},
    number={13},
    pages={3521-3526},
    isbn={0027-8424},
    language={English},
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{jafari2021survey,
  title={A survey on locality sensitive hashing algorithms and their applications},
  author={Jafari, Omid and Maurya, Preeti and Nagarkar, Parth and Islam, Khandker Mushfiqul and Crushev, Chidambaram},
  journal={arXiv preprint arXiv:2102.08942},
  year={2021}
}

@article{al2013review,
  title={Review on sorting algorithms a comparative study},
  author={Al-Kharabsheh, Khalid Suleiman and AlTurani, Ibrahim Mahmoud and AlTurani, Abdallah Mahmoud Ibrahim and Zanoon, Nabeel Imhammed},
  journal={International Journal of Computer Science and Security (IJCSS)},
  volume={7},
  number={3},
  pages={120--126},
  year={2013}
}

@article{lowry1969object,
  title={Object code optimization},
  author={Lowry, Edward S and Medlock, Cleburne W},
  journal={Communications of the ACM},
  volume={12},
  number={1},
  pages={13--22},
  year={1969},
  publisher={ACM New York, NY, USA}
}

@article{lozhkov2024starcoder,
  title={StarCoder 2 and The Stack v2: The Next Generation},
  author={Lozhkov, Anton and Li, Raymond and Allal, Loubna Ben and Cassano, Federico and Lamy-Poirier, Joel and Tazi, Nouamane and Tang, Ao and Pykhtar, Dmytro and Liu, Jiawei and Wei, Yuxiang and others},
  journal={arXiv preprint arXiv:2402.19173},
  year={2024}
}

@article{wong2023natural,
  title={Natural language generation and understanding of big code for ai-assisted programming: A review},
  author={Wong, Man-Fai and Guo, Shangxin and Hang, Ching-Nam and Ho, Siu-Wai and Tan, Chee-Wei},
  journal={Entropy},
  volume={25},
  number={6},
  pages={888},
  year={2023},
  publisher={MDPI}
}

@article{liu2024your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{chen2022learning,
  title={Learning to improve code efficiency},
  author={Chen, Binghong and Tarlow, Daniel and Swersky, Kevin and Maas, Martin and Heiber, Pablo and Naik, Ashish and Hashemi, Milad and Ranganathan, Parthasarathy},
  journal={arXiv preprint arXiv:2208.05297},
  year={2022}
}

@article{jain2024livecodebench,
  title={LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code},
  author={Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
  journal={arXiv preprint arXiv:2403.07974},
  year={2024}
}

@article{qwen,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{kulal2019spoc,
  title={Spoc: Search-based pseudocode to code},
  author={Kulal, Sumith and Pasupat, Panupong and Chandra, Kartik and Lee, Mina and Padon, Oded and Aiken, Alex and Liang, Percy S},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@misc{fairuse,
  title={U.S. Copyright Office Fair Use Index},
  author={U.S. Copyright Office},
  howpublished = {\url{https://www.copyright.gov/fair-use/}},
  year={2024},
  note = {[Accessed 25-05-2024]},
}

@misc{leetcode,
  author = {LeetCode},
  title = {{L}eet{C}ode},
  howpublished = {\url{https://leetcode.com/problemset/algorithms/}},
  year = {2024},
  note = {[Accessed 25-05-2024]},
}

@misc{cc_by_nc_4,
  author = {Creative Commons},
  title = {CC BY-NC 4.0 DEED},
  howpublished = {\url{https://creativecommons.org/licenses/by-nc/4.0/}},
  year = {2024},
  note = {[Accessed 25-05-2024]},
}




