\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.(2022)Bai, Hu, Zhu, Huang, Chen, Fu, and Tai]{bai2022transfusion}
Xuyang Bai, Zeyu Hu, Xinge Zhu, Qingqiu Huang, Yilun Chen, Hongbo Fu, and Chiew-Lan Tai.
\newblock Transfusion: Robust lidar-camera fusion for 3d object detection with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 1090--1099, 2022.

\bibitem[Chang et~al.(2024)Chang, Roh, Jang, Lee, Ji, Oh, Park, Kim, and Kim]{chang2024cmda}
Gyusam Chang, Wonseok Roh, Sujin Jang, Dongwook Lee, Daehyun Ji, Gyeongrok Oh, Jinsun Park, Jinkyu Kim, and Sangpil Kim.
\newblock Cmda: Cross-modal and domain adversarial adaptation for lidar-based 3d object detection.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 972--980, 2024.

\bibitem[Liang et~al.(2022)Liang, Xie, Yu, Xia, Lin, Wang, Tang, Wang, and Tang]{liang2022bevfusion}
Tingting Liang, Hongwei Xie, Kaicheng Yu, Zhongyu Xia, Zhiwei Lin, Yongtao Wang, Tao Tang, Bing Wang, and Zhi Tang.
\newblock Bevfusion: A simple and robust lidar-camera fusion framework.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 10421--10434, 2022.

\bibitem[Liu et~al.(2023)Liu, Tang, Amini, Yang, Mao, Rus, and Han]{liu2023bevfusion}
Zhijian Liu, Haotian Tang, Alexander Amini, Xinyu Yang, Huizi Mao, Daniela~L Rus, and Song Han.
\newblock Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation.
\newblock In \emph{2023 IEEE international conference on robotics and automation (ICRA)}, pages 2774--2781. IEEE, 2023.

\bibitem[Sun et~al.(2020)Sun, Kretzschmar, Dotiwalla, Chouard, Patnaik, Tsui, Guo, Zhou, Chai, Caine, et~al.]{sun2020scalability}
Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et~al.
\newblock Scalability in perception for autonomous driving: Waymo open dataset.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2446--2454, 2020.

\bibitem[Caesar et~al.(2020)Caesar, Bankiti, Lang, Vora, Liong, Xu, Krishnan, Pan, Baldan, and Beijbom]{caesar2020nuscenes}
Holger Caesar, Varun Bankiti, Alex~H Lang, Sourabh Vora, Venice~Erin Liong, Qiang Xu, Anush Krishnan, Yu~Pan, Giancarlo Baldan, and Oscar Beijbom.
\newblock nuscenes: A multimodal dataset for autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 11621--11631, 2020.

\bibitem[Houston et~al.(2021)Houston, Zuidhof, Bergamini, Ye, Chen, Jain, Omari, Iglovikov, and Ondruska]{houston2021one}
John Houston, Guido Zuidhof, Luca Bergamini, Yawei Ye, Long Chen, Ashesh Jain, Sammy Omari, Vladimir Iglovikov, and Peter Ondruska.
\newblock One thousand and one hours: Self-driving motion prediction dataset.
\newblock In \emph{Conference on Robot Learning}, pages 409--418. PMLR, 2021.

\bibitem[Wang et~al.(2022)Wang, Guizilini, Zhang, Wang, Zhao, and Solomon]{wang2022detr3d}
Yue Wang, Vitor~Campagnolo Guizilini, Tianyuan Zhang, Yilun Wang, Hang Zhao, and Justin Solomon.
\newblock Detr3d: 3d object detection from multi-view images via 3d-to-2d queries.
\newblock In \emph{Conference on Robot Learning}, pages 180--191. PMLR, 2022.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Wang, Li, Xie, Sima, Lu, Qiao, and Dai]{li2022bevformer}
Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Yu~Qiao, and Jifeng Dai.
\newblock Bevformer: Learning birdâ€™s-eye-view representation from multi-camera images via spatiotemporal transformers.
\newblock In \emph{European conference on computer vision}, pages 1--18. Springer, 2022{\natexlab{a}}.

\bibitem[Roh et~al.(2022)Roh, Chang, Moon, Nam, Kim, Kim, Kim, and Kim]{roh2022ora3d}
Wonseok Roh, Gyusam Chang, Seokha Moon, Giljoo Nam, Chanyoung Kim, Younghyun Kim, Jinkyu Kim, and Sangpil Kim.
\newblock Ora3d: Overlap region aware multi-view 3d object detection.
\newblock \emph{arXiv preprint arXiv:2207.00865}, 2022.

\bibitem[Huang et~al.(2021)Huang, Huang, Zhu, Ye, and Du]{huang2021bevdet}
Junjie Huang, Guan Huang, Zheng Zhu, Yun Ye, and Dalong Du.
\newblock Bevdet: High-performance multi-camera 3d object detection in bird-eye-view.
\newblock \emph{arXiv preprint arXiv:2112.11790}, 2021.

\bibitem[Li et~al.(2023)Li, Ge, Yu, Yang, Wang, Shi, Sun, and Li]{li2023bevdepth}
Yinhao Li, Zheng Ge, Guanyi Yu, Jinrong Yang, Zengran Wang, Yukang Shi, Jianjian Sun, and Zeming Li.
\newblock Bevdepth: Acquisition of reliable depth for multi-view 3d object detection.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pages 1477--1485, 2023.

\bibitem[Facil et~al.(2019)Facil, Ummenhofer, Zhou, Montesano, Brox, and Civera]{facil2019cam}
Jose~M Facil, Benjamin Ummenhofer, Huizhong Zhou, Luis Montesano, Thomas Brox, and Javier Civera.
\newblock Cam-convs: Camera-aware multi-scale convolutions for single-view depth.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 11826--11835, 2019.

\bibitem[Wang et~al.(2023)Wang, Zhao, Xu, Chen, Yu, Chang, Yang, and Zhao]{wang2023towards}
Shuo Wang, Xinhai Zhao, Hai-Ming Xu, Zehui Chen, Dameng Yu, Jiahao Chang, Zhen Yang, and Feng Zhao.
\newblock Towards domain generalization for multi-view 3d object detection in bird-eye-view.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 13333--13342, 2023.

\bibitem[Lu et~al.(2023)Lu, Zhang, Lian, Du, and Chen]{lu2023towards}
Hao Lu, Yunpeng Zhang, Qing Lian, Dalong Du, and Yingcong Chen.
\newblock Towards generalizable multi-camera 3d object detection via perspective debiasing.
\newblock \emph{arXiv preprint arXiv:2310.11346}, 2023.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Lester et~al.(2021)Lester, Al-Rfou, and Constant]{lester2021power}
Brian Lester, Rami Al-Rfou, and Noah Constant.
\newblock The power of scale for parameter-efficient prompt tuning.
\newblock \emph{arXiv preprint arXiv:2104.08691}, 2021.

\bibitem[Liu et~al.(2021)Liu, Ji, Fu, Tam, Du, Yang, and Tang]{liu2021p}
Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng~Lam Tam, Zhengxiao Du, Zhilin Yang, and Jie Tang.
\newblock P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks.
\newblock \emph{arXiv preprint arXiv:2110.07602}, 2021.

\bibitem[Yan et~al.(2018)Yan, Mao, and Li]{yan2018second}
Yan Yan, Yuxing Mao, and Bo~Li.
\newblock Second: Sparsely embedded convolutional detection.
\newblock \emph{Sensors}, 18\penalty0 (10):\penalty0 3337, 2018.

\bibitem[Park et~al.(2021)Park, Ambrus, Guizilini, Li, and Gaidon]{park2021dd3d}
Dennis Park, Rares Ambrus, Vitor Guizilini, Jie Li, and Adrien Gaidon.
\newblock Is pseudo-lidar needed for monocular 3d object detection?
\newblock In \emph{IEEE/CVF International Conference on Computer Vision (ICCV)}, 2021.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Zhu, Pang, and Lin]{wang2021pgd}
Tai Wang, Xinge Zhu, Jiangmiao Pang, and Dahua Lin.
\newblock {Probabilistic and Geometric Depth: Detecting} objects in perspective.
\newblock In \emph{Conference on Robot Learning (CoRL) 2021}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Zhu, Pang, and Lin]{wang2021fcos3d}
Tai Wang, Xinge Zhu, Jiangmiao Pang, and Dahua Lin.
\newblock Fcos3d: Fully convolutional one-stage monocular 3d object detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 913--922, 2021{\natexlab{b}}.

\bibitem[Brazil and Liu(2019)]{brazil2019m3d}
Garrick Brazil and Xiaoming Liu.
\newblock M3d-rpn: Monocular 3d region proposal network for object detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 9287--9296, 2019.

\bibitem[Liu et~al.(2020)Liu, Wu, and T{\'o}th]{liu2020smoke}
Zechen Liu, Zizhang Wu, and Roland T{\'o}th.
\newblock Smoke: Single-stage monocular 3d object detection via keypoint estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops}, pages 996--997, 2020.

\bibitem[Zhou and Tuzel(2018)]{zhou2018voxelnet}
Yin Zhou and Oncel Tuzel.
\newblock Voxelnet: End-to-end learning for point cloud based 3d object detection.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4490--4499, 2018.

\bibitem[Lang et~al.(2019)Lang, Vora, Caesar, Zhou, Yang, and Beijbom]{lang2019pointpillars}
Alex~H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom.
\newblock Pointpillars: Fast encoders for object detection from point clouds.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12697--12705, 2019.

\bibitem[Philion and Fidler(2020)]{philion2020lift}
Jonah Philion and Sanja Fidler.
\newblock Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16}, pages 194--210. Springer, 2020.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Wang, Zhang, and Sun]{liu2022petr}
Yingfei Liu, Tiancai Wang, Xiangyu Zhang, and Jian Sun.
\newblock Petr: Position embedding transformation for multi-view 3d object detection.
\newblock In \emph{European Conference on Computer Vision}, pages 531--548. Springer, 2022{\natexlab{a}}.

\bibitem[Vaswani(2017)]{vaswani2017attention}
A~Vaswani.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Park et~al.(2022)Park, Xu, Yang, Keutzer, Kitani, Tomizuka, and Zhan]{park2022time}
Jinhyung Park, Chenfeng Xu, Shijia Yang, Kurt Keutzer, Kris~M Kitani, Masayoshi Tomizuka, and Wei Zhan.
\newblock Time will tell: New outlooks and a baseline for temporal multi-view 3d object detection.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem[Yang et~al.(2023)Yang, Chen, Tian, Tao, Zhu, Zhang, Huang, Li, Qiao, Lu, et~al.]{yang2023bevformer}
Chenyu Yang, Yuntao Chen, Hao Tian, Chenxin Tao, Xizhou Zhu, Zhaoxiang Zhang, Gao Huang, Hongyang Li, Yu~Qiao, Lewei Lu, et~al.
\newblock Bevformer v2: Adapting modern image backbones to bird's-eye-view recognition via perspective supervision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 17830--17839, 2023.

\bibitem[Hong et~al.(2022)Hong, Dai, and Ding]{yuhong-CMKD-ECCV2022}
Yu~Hong, Hang Dai, and Yong Ding.
\newblock Cross-modality knowledge distillation network for monocular 3d object detection.
\newblock In \emph{{ECCV}}, Lecture Notes in Computer Science. Springer, 2022.

\bibitem[Huang et~al.(2022)Huang, Liu, Zhang, Zhang, Xu, Wang, and Liu]{huang2022tig}
Peixiang Huang, Li~Liu, Renrui Zhang, Song Zhang, Xinli Xu, Baichao Wang, and Guoyi Liu.
\newblock Tig-bev: Multi-view bev 3d object detection via target inner-geometry learning.
\newblock \emph{arXiv preprint arXiv:2212.13979}, 2022.

\bibitem[Chen et~al.(2022)Chen, Li, Zhang, Fang, Jiang, and Zhao]{chen2022bevdistill}
Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, Qinhong Jiang, and Feng Zhao.
\newblock Bevdistill: Cross-modal bev distillation for multi-view 3d object detection.
\newblock \emph{arXiv preprint arXiv:2211.09386}, 2022.

\bibitem[Jang et~al.(2024)Jang, Jo, Hwang, Lee, and Ji]{jang2024stxd}
Sujin Jang, Dae~Ung Jo, Sung~Ju Hwang, Dongwook Lee, and Daehyun Ji.
\newblock Stxd: Structural and temporal cross-modal distillation for multi-view 3d object detection.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Wang et~al.(2020)Wang, Chen, You, Li, Hariharan, Campbell, Weinberger, and Chao]{wang2020train}
Yan Wang, Xiangyu Chen, Yurong You, Li~Erran Li, Bharath Hariharan, Mark Campbell, Kilian~Q Weinberger, and Wei-Lun Chao.
\newblock Train in germany, test in the usa: Making 3d object detectors generalize.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 11713--11723, 2020.

\bibitem[Yang et~al.(2021)Yang, Shi, Wang, Li, and Qi]{yang2021st3d}
Jihan Yang, Shaoshuai Shi, Zhe Wang, Hongsheng Li, and Xiaojuan Qi.
\newblock St3d: Self-training for unsupervised domain adaptation on 3d object detection.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10368--10378, 2021.

\bibitem[Xu et~al.(2021)Xu, Zhou, Wang, Qi, and Anguelov]{xu2021spg}
Qiangeng Xu, Yin Zhou, Weiyue Wang, Charles~R Qi, and Dragomir Anguelov.
\newblock Spg: Unsupervised domain adaptation for 3d object detection via semantic point generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 15446--15456, 2021.

\bibitem[Yihan et~al.(2021)Yihan, Wang, Wang, Xu, Ye, Yang, and Ma]{yihan2021learning}
Zeng Yihan, Chunwei Wang, Yunbo Wang, Hang Xu, Chaoqiang Ye, Zhen Yang, and Chao Ma.
\newblock Learning transferable features for point cloud detection via 3d contrastive co-training.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 21493--21504, 2021.

\bibitem[Wei et~al.(2022{\natexlab{a}})Wei, Wei, Rao, Li, Zhou, and Lu]{wei2022lidar}
Yi~Wei, Zibu Wei, Yongming Rao, Jiaxin Li, Jie Zhou, and Jiwen Lu.
\newblock Lidar distillation: Bridging the beam-induced domain gap for 3d object detection.
\newblock In \emph{European Conference on Computer Vision}, pages 179--195. Springer, 2022{\natexlab{a}}.

\bibitem[Zhang et~al.(2024)Zhang, Zhou, and Huang]{zhang2024stal3d}
Yanan Zhang, Chao Zhou, and Di~Huang.
\newblock Stal3d: Unsupervised domain adaptation for 3d object detection via collaborating self-training and adversarial learning.
\newblock \emph{IEEE Transactions on Intelligent Vehicles}, 2024.

\bibitem[Hu et~al.(2023)Hu, Liu, and Hu]{hu2023density}
Qianjiang Hu, Daizong Liu, and Wei Hu.
\newblock Density-insensitive unsupervised domain adaption on 3d object detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 17556--17566, 2023.

\bibitem[Vidit et~al.(2023)Vidit, Engilberge, and Salzmann]{vidit2023clip}
Vidit Vidit, Martin Engilberge, and Mathieu Salzmann.
\newblock Clip the gap: A single domain generalization approach for object detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3219--3229, 2023.

\bibitem[Wu and Deng(2022)]{wu2022single}
Aming Wu and Cheng Deng.
\newblock Single-domain generalized object detection in urban scene via cyclic-disentangled self-distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition}, pages 847--856, 2022.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 16000--16009, 2022.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International conference on machine learning}, pages 1597--1607. PMLR, 2020.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Chen, Li, Fang, Jiang, Liu, and Jiang]{li2022unsupervised}
Zhenyu Li, Zehui Chen, Ang Li, Liangji Fang, Qinhong Jiang, Xianming Liu, and Junjun Jiang.
\newblock Unsupervised domain adaptation for monocular 3d object detection via self-training.
\newblock In \emph{European conference on computer vision}, pages 245--262. Springer, 2022{\natexlab{b}}.

\bibitem[Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone, De~Laroussilhe, Gesmundo, Attariyan, and Gelly]{houlsby2019parameter}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In \emph{International conference on machine learning}, pages 2790--2799. PMLR, 2019.

\bibitem[Lian et~al.(2022)Lian, Zhou, Feng, and Wang]{lian2022scaling}
Dongze Lian, Daquan Zhou, Jiashi Feng, and Xinchao Wang.
\newblock Scaling \& shifting your features: A new baseline for efficient model tuning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 109--123, 2022.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Tam, Muqeeth, Mohta, Huang, Bansal, and Raffel]{liu2022few}
Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin~A Raffel.
\newblock Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 1950--1965, 2022{\natexlab{b}}.

\bibitem[Dong et~al.(2024)Dong, Guo, Liu, Zhang, and Zhang]{dong2024ppea}
Yue-Jiang Dong, Yuan-Chen Guo, Ying-Tian Liu, Fang-Lue Zhang, and Song-Hai Zhang.
\newblock Ppea-depth: Progressive parameter-efficient adaptation for self-supervised monocular depth estimation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 1609--1617, 2024.

\bibitem[Dosovitskiy et~al.(2017)Dosovitskiy, Ros, Codevilla, Lopez, and Koltun]{Dosovitskiy17}
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun.
\newblock {CARLA}: {An} open urban driving simulator.
\newblock In \emph{Proceedings of the 1st Annual Conference on Robot Learning}, pages 1--16, 2017.

\bibitem[Gu et~al.(2021)Gu, Zhou, Xu, Feng, Cheng, Lu, Shi, and Ma]{gu2021pit}
Qiqi Gu, Qianyu Zhou, Minghao Xu, Zhengyang Feng, Guangliang Cheng, Xuequan Lu, Jianping Shi, and Lizhuang Ma.
\newblock Pit: Position-invariant transform for cross-fov domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 8761--8770, 2021.

\bibitem[Klinghoffer et~al.(2023)Klinghoffer, Philion, Chen, Litany, Gojcic, Joo, Raskar, Fidler, and Alvarez]{klinghoffer2023towards}
Tzofi Klinghoffer, Jonah Philion, Wenzheng Chen, Or~Litany, Zan Gojcic, Jungseock Joo, Ramesh Raskar, Sanja Fidler, and Jose~M Alvarez.
\newblock Towards viewpoint robustness in bird's eye view segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 8515--8524, 2023.

\bibitem[Zhao et~al.(2021)Zhao, Kong, and Fowlkes]{zhao2021camera}
Yunhan Zhao, Shu Kong, and Charless Fowlkes.
\newblock Camera pose matters: Improving depth prediction by mitigating pose distribution bias.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15759--15768, 2021.

\bibitem[Wang et~al.(2019)Wang, Fang, Qian, Yang, Zhou, and Zhou]{wang2019perspective}
Ke~Wang, Bin Fang, Jiye Qian, Su~Yang, Xin Zhou, and Jie Zhou.
\newblock Perspective transformation data augmentation for object detection.
\newblock \emph{IEEE Access}, 8:\penalty0 4935--4943, 2019.

\bibitem[Godard et~al.(2019)Godard, Mac~Aodha, Firman, and Brostow]{godard2019digging}
Cl{\'e}ment Godard, Oisin Mac~Aodha, Michael Firman, and Gabriel~J Brostow.
\newblock Digging into self-supervised monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 3828--3838, 2019.

\bibitem[Bian et~al.(2023)Bian, Wang, Li, Bian, and Prisacariu]{bian2023nope}
Wenjing Bian, Zirui Wang, Kejie Li, Jia-Wang Bian, and Victor~Adrian Prisacariu.
\newblock Nope-nerf: Optimising neural radiance field with no pose prior.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4160--4169, 2023.

\bibitem[Lyu et~al.(2021)Lyu, Liu, Wang, Kong, Liu, Liu, Chen, and Yuan]{lyu2021hr}
Xiaoyang Lyu, Liang Liu, Mengmeng Wang, Xin Kong, Lina Liu, Yong Liu, Xinxin Chen, and Yi~Yuan.
\newblock Hr-depth: High resolution self-supervised monocular depth estimation.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~35, pages 2294--2301, 2021.

\bibitem[Zhou et~al.(2021)Zhou, Greenwood, and Taylor]{zhou2021self}
Hang Zhou, David Greenwood, and Sarah Taylor.
\newblock Self-supervised monocular depth estimation with internal feature fusion.
\newblock \emph{arXiv preprint arXiv:2110.09482}, 2021.

\bibitem[Wei et~al.(2022{\natexlab{b}})Wei, Zhao, Zheng, Zhu, Rao, Huang, Lu, and Zhou]{wei2022surround}
Yi~Wei, Linqing Zhao, Wenzhao Zheng, Zheng Zhu, Yongming Rao, Guan Huang, Jiwen Lu, and Jie Zhou.
\newblock Surrounddepth: Entangling surrounding views for self-supervised multi-camera depth estimation.
\newblock \emph{arXiv preprint arXiv:2204.03636}, 2022{\natexlab{b}}.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{wang2004image}
Zhou Wang, Alan~C Bovik, Hamid~R Sheikh, and Eero~P Simoncelli.
\newblock Image quality assessment: from error visibility to structural similarity.
\newblock \emph{IEEE transactions on image processing}, 13\penalty0 (4):\penalty0 600--612, 2004.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem[Zhu et~al.(2019)Zhu, Jiang, Zhou, Li, and Yu]{zhu2019class}
Benjin Zhu, Zhengkai Jiang, Xiangxin Zhou, Zeming Li, and Gang Yu.
\newblock Class-balanced grouping and sampling for point cloud 3d object detection.
\newblock 2019.

\end{thebibliography}
