Towards Robust Interpretability with Self-Explaining Neural Networks