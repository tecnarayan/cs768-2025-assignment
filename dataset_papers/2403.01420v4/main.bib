@inproceedings{ma2023algorithmic,
  title={Algorithmic Regularization in Tensor Optimization: Towards a Lifted Approach in Matrix Sensing},
  author={Ma, Ziye and Lavaei, Javad and Sojoudi, Somayeh},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{gu2024causality,
  title={Causality Pursuit from Heterogeneous Environments via Neural Adversarial Invariance Learning},
  author={Gu, Yihong and Fang, Cong and B{\"u}hlmann, Peter and Fan, Jianqing},
  journal={arXiv preprint arXiv:2405.04715},
  year={2024}
}

@article{nastl2024predictors,
  title={Predictors from causal features do not generalize better to new domains},
  author={Nastl, Vivian Y and Hardt, Moritz},
  journal={arXiv preprint arXiv:2402.09891},
  year={2024}
}

@book{peters2017elements,
  title={Elements of causal inference: foundations and learning algorithms},
  author={Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year={2017},
  publisher={The MIT Press}
}

@inproceedings{idrissi2022simple,
  title={Simple data balancing achieves competitive worst-group-accuracy},
  author={Idrissi, Badr Youbi and Arjovsky, Martin and Pezeshki, Mohammad and Lopez-Paz, David},
  booktitle={Conference on Causal Learning and Reasoning},
  pages={336--351},
  year={2022},
  organization={PMLR}
}



@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}
@article{fan2014endogeneity,
  title={Endogeneity in high dimensions},
  author={Fan, Jianqing and Liao, Yuan},
  journal={Annals of Statistics},
  volume={42},
  number={3},
  pages={872},
  year={2014},
  publisher={NIH Public Access}
}
@article{candes2005decoding,
  title={Decoding by linear programming},
  author={Candes, Emmanuel J and Tao, Terence},
  journal={IEEE transactions on information theory},
  volume={51},
  number={12},
  pages={4203--4215},
  year={2005},
  publisher={IEEE}
}

@article{zou2020gradient,
  title={Gradient descent optimizes over-parameterized deep ReLU networks},
  author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
  journal={Machine learning},
  volume={109},
  pages={467--492},
  year={2020},
  publisher={Springer}
}


@inproceedings{du2018gradient,
  title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}

@inproceedings{kirichenko2022last,
  title={Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations},
  author={Kirichenko, Polina and Izmailov, Pavel and Wilson, Andrew Gordon},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@ARTICLE{5730578,
  author={Candès, Emmanuel J. and Plan, Yaniv},
  journal={IEEE Transactions on Information Theory}, 
  title={Tight Oracle Inequalities for Low-Rank Matrix Recovery From a Minimal Number of Noisy Random Measurements}, 
  year={2011},
  volume={57},
  number={4},
  pages={2342-2359},
  keywords={Linear matrix inequalities;Noise measurement;Minimization;Sparse matrices;Noise;Compressed sensing;Measurement uncertainty;Convex optimization;Dantzig selector;matrix completion;norm of random matrices;oracle inequalities and semidefinite programming},
  doi={10.1109/TIT.2011.2111771}}

@inproceedings{li2018algorithmic,
  title={Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
  booktitle={Conference on Learning Theory},
  pages={2--47},
  year={2018},
  organization={PMLR}
}

@inproceedings{vivien2022label,
  title={Label noise (stochastic) gradient descent implicitly solves the lasso for quadratic parametrisation},
  author={Vivien, Loucas Pillaud and Reygner, Julien and Flammarion, Nicolas},
  booktitle={Conference on Learning Theory},
  pages={2127--2159},
  year={2022},
  organization={PMLR}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@article{fan2023environment,
  title={Environment Invariant Linear Least Squares},
  author={Fan, Jianqing and Fang, Cong and Gu, Yihong and Zhang, Tong},
  journal={arXiv preprint arXiv:2303.03092},
  year={2023}
}

@article{Haavelmo_1944,
   title={The Probability Approach in Econometrics},
   volume={12},
   ISSN={0012-9682},
   url={http://dx.doi.org/10.2307/1906935},
   DOI={10.2307/1906935},
   journal={Econometrica},
   publisher={JSTOR},
   author={Haavelmo, Trygve},
   year={1944},
   month=jul, pages={iii} }
@article{aldrich1989autonomy,
  title={Autonomy},
  author={Aldrich, John},
  journal={Oxford Economic Papers},
  volume={41},
  number={1},
  pages={15--34},
  year={1989},
  publisher={Oxford University Press}
}

@article{Dawid_2010,
   title={Identifying the consequences of dynamic treatment strategies: A decision-theoretic overview},
   volume={4},
   ISSN={1935-7516},
   url={http://dx.doi.org/10.1214/10-SS081},
   DOI={10.1214/10-ss081},
   number={none},
   journal={Statistics Surveys},
   publisher={Institute of Mathematical Statistics},
   author={Dawid, A. Philip and Didelez, Vanessa},
   year={2010},
   month=jan }

@article{_uklina_2021,
   title={Diagnostics and correction of batch effects in large‐scale proteomic studies: a tutorial},
   volume={17},
   ISSN={1744-4292},
   url={http://dx.doi.org/10.15252/msb.202110240},
   DOI={10.15252/msb.202110240},
   number={8},
   journal={Molecular Systems Biology},
   publisher={Springer Science and Business Media LLC},
   author={Čuklina, Jelena and Lee, Chloe H and Williams, Evan G and Sajic, Tatjana and Collins, Ben C and Rodríguez Martínez, María and Sharma, Varun S and Wendt, Fabian and Goetze, Sandra and Keele, Gregory R and Wollscheid, Bernd and Aebersold, Ruedi and Pedrioli, Patrick G A},
   year={2021},
   month=aug }

@article{meinshausen2016methods,
  title={Methods for causal inference from gene perturbation experiments and validation},
  author={Meinshausen, Nicolai and Hauser, Alain and Mooij, Joris M and Peters, Jonas and Versteeg, Philip and B{\"u}hlmann, Peter},
  journal={Proceedings of the National Academy of Sciences},
  volume={113},
  number={27},
  pages={7361--7368},
  year={2016},
  publisher={National Acad Sciences}
}


@inproceedings{lin2022bayesian,
  title={Bayesian invariant risk minimization},
  author={Lin, Yong and Dong, Hanze and Wang, Hao and Zhang, Tong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16021--16030},
  year={2022}
}


@article{ghassami2017learning,
  title={Learning causal structures using regression invariance},
  author={Ghassami, AmirEmad and Salehkaleybar, Saber and Kiyavash, Negar and Zhang, Kun},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{Rothenh_usler_2019,
   title={Causal Dantzig: Fast inference in linear structural equation models with hidden variables under additive interventions},
   volume={47},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/18-AOS1732},
   DOI={10.1214/18-aos1732},
   number={3},
   journal={Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Rothenhäusler, Dominik and Bühlmann, Peter and Meinshausen, Nicolai},
   year={2019},
   month=jun }

@article{Rothenh_usler_2021,
   title={Anchor Regression: Heterogeneous Data Meet Causality},
   volume={83},
   ISSN={1467-9868},
   url={http://dx.doi.org/10.1111/rssb.12398},
   DOI={10.1111/rssb.12398},
   number={2},
   journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
   publisher={Oxford University Press (OUP)},
   author={Rothenhäusler, Dominik and Meinshausen, Nicolai and Bühlmann, Peter and Peters, Jonas},
   year={2021},
   month=jan, pages={215–246} }


@article{Pfister_2021,
   title={Stabilizing variable selection and regression},
   volume={15},
   ISSN={1932-6157},
   url={http://dx.doi.org/10.1214/21-aoas1487},
   DOI={10.1214/21-aoas1487},
   number={3},
   journal={The Annals of Applied Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Pfister, Niklas and Williams, Evan G. and Peters, Jonas and Aebersold, Ruedi and Bühlmann, Peter},
   year={2021},
   month=sep }

@inproceedings{yin2022optimization,
  title={Optimization-based Causal Estimation from Heterogenous Environments},
  author={Yin, Mingzhang and Wang, Yixin and Blei, David},
  booktitle={ICML 2022: Workshop on Spurious Correlations, Invariance and Stability},
  year={2022}
}

@article{Heinze_Deml_2018,
   title={Invariant Causal Prediction for Nonlinear Models},
   volume={6},
   ISSN={2193-3677},
   url={http://dx.doi.org/10.1515/jci-2017-0016},
   DOI={10.1515/jci-2017-0016},
   number={2},
   journal={Journal of Causal Inference},
   publisher={Walter de Gruyter GmbH},
   author={Heinze-Deml, Christina and Peters, Jonas and Meinshausen, Nicolai},
   year={2018},
   month=sep }

@book{pearl2016causal,
  title={Causal inference in statistics: A primer},
  author={Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P},
  year={2016},
  publisher={John Wiley \& Sons}
}


@inproceedings{scholkopf2012causal,
  title={On causal and anticausal learning},
  author={Sch{\"o}lkopf, B and Janzing, D and Peters, J and Sgouritsa, E and Zhang, K and Mooij, J},
  booktitle={International Conference on Machine Learning},
  pages={1255--1262},
  year={2012},
  organization={International Machine Learning Society}
}
@article{peters2016causal,
  title={Causal inference by using invariant prediction: identification and confidence intervals},
  author={Peters, Jonas and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={78},
  number={5},
  pages={947--1012},
  year={2016},
  publisher={Oxford University Press}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}


@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{
wald2023malign,
title={Malign Overfitting: Interpolation and Invariance are Fundamentally at Odds},
author={Yoav Wald and Gal Yona and Uri Shalit and Yair Carmon},
booktitle={International Conference on Learning Representations},
year={2023},
}

@inproceedings{zhang2020invariant,
  title={Invariant causal prediction for block mdps},
  author={Zhang, Amy and Lyle, Clare and Sodhani, Shagun and Filos, Angelos and Kwiatkowska, Marta and Pineau, Joelle and Gal, Yarin and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={11214--11224},
  year={2020},
  organization={PMLR}
}
@inproceedings{zhou2022sparse,
  title={Sparse invariant risk minimization},
  author={Zhou, Xiao and Lin, Yong and Zhang, Weizhong and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={27222--27244},
  year={2022},
  organization={PMLR}
}


@inproceedings{krueger2021out,
  title={Out-of-distribution generalization via risk extrapolation (rex)},
  author={Krueger, David and Caballero, Ethan and Jacobsen, Joern-Henrik and Zhang, Amy and Binas, Jonathan and Zhang, Dinghuai and Le Priol, Remi and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5815--5826},
  year={2021},
  organization={PMLR}
}


@article{ando2005framework,
  title={A framework for learning predictive structures from multiple tasks and unlabeled data.},
  author={Ando, Rie Kubota and Zhang, Tong and Bartlett, Peter},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={11},
  year={2005}
}

@book{nesterov2013introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2013},
  publisher={Springer Science \& Business Media}
}


@article{lu2021nonlinear,
  title={Nonlinear invariant risk minimization: A causal approach},
  author={Lu, Chaochao and Wu, Yuhuai and Hern{\'a}ndez-Lobato, Jo{\'s}e Miguel and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2102.12353},
  year={2021}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{lin2022zin,
  title={Zin: When and how to learn invariance without environment partition?},
  author={Lin, Yong and Zhu, Shengyu and Tan, Lu and Cui, Peng},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}


@article{song2018mean,
  title={A mean field view of the landscape of two-layers neural networks},
  author={Song, Mei and Montanari, Andrea and Nguyen, P},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={33},
  pages={E7665--E7671},
  year={2018}
}

@inproceedings{fang2021modeling,
  title={Modeling from features: a mean-field framework for over-parameterized deep neural networks},
  author={Fang, Cong and Lee, Jason and Yang, Pengkun and Zhang, Tong},
  booktitle={Conference on Learning Theory},
  pages={1887--1936},
  year={2021},
  organization={PMLR}
}

@article{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@article{even2024s,
  title={(S) GD over Diagonal Linear Networks: Implicit bias, Large Stepsizes and Edge of Stability},
  author={Even, Mathieu and Pesme, Scott and Gunasekar, Suriya and Flammarion, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{fan2023understanding,
  title={Understanding implicit regularization in over-parameterized single index model},
  author={Fan, Jianqing and Yang, Zhuoran and Yu, Mengxin},
  journal={Journal of the American Statistical Association},
  volume={118},
  number={544},
  pages={2315--2328},
  year={2023},
  publisher={Taylor \& Francis}
}

@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on Learning Theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhu2019anisotropic,
  title={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  booktitle={International Conference on Machine Learning},
  pages={7654--7663},
  year={2019},
  organization={PMLR}
}

@article{soudry2018implicit,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={2822--2878},
  year={2018},
  publisher={JMLR. org}
}

@inproceedings{ji2019gradient,
  title={Gradient descent aligns the layers of deep linear networks},
  author={Ji, Ziwei and Telgarsky, Matus},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{neyshabur2014search,
  title={In search of the real inductive bias: On the role of implicit regularization in deep learning},
  author={Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
  journal={arXiv preprint arXiv:1412.6614},
  year={2014}
}


@inproceedings{
zhang2017understanding,
title={Understanding deep learning requires rethinking generalization},
author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
booktitle={International Conference on Learning Representations},
year={2017}
}





@inproceedings{ji2019implicit,
  title={The implicit bias of gradient descent on nonseparable data},
  author={Ji, Ziwei and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1772--1798},
  year={2019},
  organization={PMLR}
}


@article{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{nacson2019convergence,
  title={Convergence of gradient descent on separable data},
  author={Nacson, Mor Shpigel and Lee, Jason and Gunasekar, Suriya and Savarese, Pedro Henrique Pamplona and Srebro, Nathan and Soudry, Daniel},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={3420--3428},
  year={2019},
  organization={PMLR}
}

@article{ji2019refined,
  title={A refined primal-dual analysis of the implicit bias},
  author={Ji, Ziwei and Telgarsky, Matus},
  journal={Journal of Environmental Sciences (China) English Ed},
  year={2019},
  publisher={Chinese Academy of Sciences}
}

@inproceedings{chaudhari2018stochastic,
  title={Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks},
  author={Chaudhari, Pratik and Soatto, Stefano},
  booktitle={2018 Information Theory and Applications Workshop (ITA)},
  pages={1--10},
  year={2018},
  organization={IEEE}
}

@article{wei2019noise,
  title={How noise affects the hessian spectrum in overparameterized neural networks},
  author={Wei, Mingwei and Schwab, David J},
  journal={arXiv preprint arXiv:1910.00195},
  year={2019}
}


@inproceedings{yaida2018fluctuation,
  title={Fluctuation-dissipation relations for stochastic gradient descent},
  author={Yaida, Sho},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{haochen2021shape,
  title={Shape matters: Understanding the implicit bias of the noise covariance},
  author={HaoChen, Jeff Z and Wei, Colin and Lee, Jason and Ma, Tengyu},
  booktitle={Conference on Learning Theory},
  pages={2315--2357},
  year={2021},
  organization={PMLR}
}

@inproceedings{gupta2023context,
  title={Context is Environment},
  author={Gupta, Sharut and Lopez-Paz, David and Jegelka, Stefanie and Ahuja, Kartik},
  booktitle={NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models},
  year={2023}
}


@article{hoover1990logic,
  title={The logic of causal inference: Econometrics and the conditional analysis of causation},
  author={Hoover, Kevin D},
  journal={Economics \& Philosophy},
  volume={6},
  number={2},
  pages={207--234},
  year={1990},
  publisher={Cambridge University Press}
}

@inproceedings{jin2023understanding,
  title={Understanding incremental learning of gradient descent: A fine-grained analysis of matrix sensing},
  author={Jin, Jikai and Li, Zhiyuan and Lyu, Kaifeng and Du, Simon Shaolei and Lee, Jason D},
  booktitle={International Conference on Machine Learning},
  pages={15200--15238},
  year={2023},
  organization={PMLR}
}

@article{candes2008restricted,
  title={The restricted isometry property and its implications for compressed sensing},
  author={Candes, Emmanuel J},
  journal={Comptes rendus. Mathematique},
  volume={346},
  number={9-10},
  pages={589--592},
  year={2008}
}

@article{stoger2021small,
  title={Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction},
  author={St{\"o}ger, Dominik and Soltanolkotabi, Mahdi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{zhuo2021computational,
  title={On the computational and statistical complexity of over-parameterized matrix sensing},
  author={Zhuo, Jiacheng and Kwon, Jeongyeol and Ho, Nhat and Caramanis, Constantine},
  journal={arXiv preprint arXiv:2102.02756},
  year={2021}
}




@article{damian2021label,
  title={Label noise {SGD} provably prefers flat global minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason D},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{ji2020directional,
  title={Directional convergence and alignment in deep learning},
  author={Ji, Ziwei and Telgarsky, Matus},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{li2021happens,
  title={What Happens after SGD Reaches Zero Loss?--A Mathematical Framework},
  author={Li, Zhiyuan and Wang, Tianhao and Arora, Sanjeev},
  booktitle={International Conference on Learning Representations},
  year={2021}
}



@inproceedings{wang2021importance,
  title={Is Importance Weighting Incompatible with Interpolating Classifiers?},
  author={Wang, Ke Alexander and Chatterji, Niladri Shekhar and Haque, Saminul and Hashimoto, Tatsunori},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{rosenfeld2021risks,
  title={The Risks of Invariant Risk Minimization},
  author={Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
  booktitle={International Conference on Learning Representations},
  volume={9},
  year={2021}
}


@inproceedings{kamath2021does,
  title={Does invariant risk minimization capture invariance?},
  author={Kamath, Pritish and Tangella, Akilesh and Sutherland, Danica and Srebro, Nathan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4069--4077},
  year={2021},
  organization={PMLR}
}



@inproceedings{arora2022understanding,
  title={Understanding gradient descent on the edge of stability in deep learning},
  author={Arora, Sanjeev and Li, Zhiyuan and Panigrahi, Abhishek},
  booktitle={International Conference on Machine Learning},
  pages={948--1024},
  year={2022},
  organization={PMLR}
}


@article{lyu2022understanding,
  title={Understanding the generalization benefit of normalization layers: Sharpness reduction},
  author={Lyu, Kaifeng and Li, Zhiyuan and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}

@article{kalimeris2019SGD,
  title={SGD on neural networks learns functions of increasing complexity},
  author={Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@inproceedings{gissin2019implicit,
  title={The Implicit Bias of Depth: How Incremental Learning Drives Generalization},
  author={Gissin, Daniel and Shalev-Shwartz, Shai and Daniely, Amit},
  booktitle={International Conference on Learning Representations},
  year={2019}
}



@article{jiang2023algorithmic,
  title={Algorithmic regularization in model-free overparametrized asymmetric matrix factorization},
  author={Jiang, Liwei and Chen, Yudong and Ding, Lijun},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={5},
  number={3},
  pages={723--744},
  year={2023},
  publisher={SIAM}
}

@inproceedings{lu2023benign,
  title={Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate},
  author={Lu, Miao and Wu, Beining and Yang, Xiaodong and Zou, Difan},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@inproceedings{cohen2020gradient,
  title={Gradient descent on neural networks typically occurs at the edge of stability},
  author={Cohen, Jeremy and Kaur, Simran and Li, Yuanzhi and Kolter, J Zico and Talwalkar, Ameet},
  booktitle={International Conference on Learning Representations},
  year={2020}
}



@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}



@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}



@article{katz2024gpt,
  title={Gpt-4 passes the bar exam},
  author={Katz, Daniel Martin and Bommarito, Michael James and Gao, Shang and Arredondo, Pablo},
  journal={Philosophical Transactions of the Royal Society A},
  volume={382},
  number={2270},
  pages={20230254},
  year={2024},
  publisher={The Royal Society}
}


@article{liu2023evaluating,
  title={Evaluating the logical reasoning ability of chatgpt and gpt-4},
  author={Liu, Hanmeng and Ning, Ruoxi and Teng, Zhiyang and Liu, Jian and Zhou, Qiji and Zhang, Yue},
  journal={arXiv preprint arXiv:2304.03439},
  year={2023}
}



@article{zhang2023understanding,
  title={Understanding causality with large language models: Feasibility and opportunities},
  author={Zhang, Cheng and Bauer, Stefan and Bennett, Paul and Gao, Jiangfeng and Gong, Wenbo and Hilmkil, Agrin and Jennings, Joel and Ma, Chao and Minka, Tom and Pawlowski, Nick and others},
  journal={arXiv preprint arXiv:2304.05524},
  year={2023}
}

@article{kiciman2023causal,
  title={Causal reasoning and large language models: Opening a new frontier for causality},
  author={K{\i}c{\i}man, Emre and Ness, Robert and Sharma, Amit and Tan, Chenhao},
  journal={arXiv preprint arXiv:2305.00050},
  year={2023}
}


@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and trends{\textregistered} in machine learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@inproceedings{dwork2006our,
  title={Our data, ourselves: Privacy via distributed noise generation},
  author={Dwork, Cynthia and Kenthapadi, Krishnaram and McSherry, Frank and Mironov, Ilya and Naor, Moni},
  booktitle={Advances in Cryptology-EUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25},
  pages={486--503},
  year={2006},
  organization={Springer}
}


@inproceedings{chang2019upload,
  title={On the upload versus download cost for secure and private matrix multiplication},
  author={Chang, Wei-Ting and Tandon, Ravi},
  booktitle={2019 IEEE Information Theory Workshop (ITW)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}



@inproceedings{li2021ditto,
  title={Ditto: Fair and robust federated learning through personalization},
  author={Li, Tian and Hu, Shengyuan and Beirami, Ahmad and Smith, Virginia},
  booktitle={International Conference on Machine Learning},
  pages={6357--6368},
  year={2021},
  organization={PMLR}
}


@article{lin2022personalized,
  title={Personalized federated learning towards communication efficiency, robustness and fairness},
  author={Lin, Shiyun and Han, Yuze and Li, Xiang and Zhang, Zhihua},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30471--30485},
  year={2022}
}

