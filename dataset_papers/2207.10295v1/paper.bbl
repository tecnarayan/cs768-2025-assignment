\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[age()]{agent_transformer}


\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{straight_through}
Bengio, Y., L{\'e}onard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{nlp}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Chen et~al.(2020)Chen, Zhou, Koltun, and Kr{\"a}henb{\"u}hl]{lbc}
Chen, D., Zhou, B., Koltun, V., and Kr{\"a}henb{\"u}hl, P.
\newblock Learning by cheating.
\newblock In \emph{Conference on Robot Learning}, pp.\  66--75. PMLR, 2020.

\bibitem[Chen et~al.(2021{\natexlab{a}})Chen, Koltun, and
  Kr{\"a}henb{\"u}hl]{world_rails}
Chen, D., Koltun, V., and Kr{\"a}henb{\"u}hl, P.
\newblock Learning to drive from a world on rails.
\newblock \emph{arXiv preprint arXiv:2105.00636}, 2021{\natexlab{a}}.

\bibitem[Chen et~al.(2021{\natexlab{b}})Chen, Lu, Rajeswaran, Lee, Grover,
  Laskin, Abbeel, Srinivas, and Mordatch]{DT}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P.,
  Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{arXiv preprint arXiv:2106.01345}, 2021{\natexlab{b}}.

\bibitem[Choi et~al.(2019)Choi, Kim, and Yeo]{rnn_atten}
Choi, S., Kim, J., and Yeo, H.
\newblock Attention-based recurrent neural network for urban vehicle trajectory
  prediction.
\newblock \emph{Procedia Computer Science}, 151:\penalty0 327--334, 2019.

\bibitem[Codevilla et~al.(2019)Codevilla, Santana, L{\'o}pez, and
  Gaidon]{no_crash}
Codevilla, F., Santana, E., L{\'o}pez, A.~M., and Gaidon, A.
\newblock Exploring the limitations of behavior cloning for autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9329--9338, 2019.

\bibitem[Coulom(2006)]{mcts}
Coulom, R.
\newblock Efficient selectivity and backup operators in monte-carlo tree
  search.
\newblock In \emph{International conference on computers and games}, pp.\
  72--83. Springer, 2006.

\bibitem[Dabney et~al.(2018)Dabney, Ostrovski, Silver, and Munos]{iqn}
Dabney, W., Ostrovski, G., Silver, D., and Munos, R.
\newblock Implicit quantile networks for distributional reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1096--1105. PMLR, 2018.

\bibitem[Dosovitskiy et~al.(2017)Dosovitskiy, Ros, Codevilla, Lopez, and
  Koltun]{carla}
Dosovitskiy, A., Ros, G., Codevilla, F., Lopez, A., and Koltun, V.
\newblock Carla: An open urban driving simulator.
\newblock In \emph{Conference on robot learning}, pp.\  1--16. PMLR, 2017.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{d4rl}
Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Norouzi, and Ba]{dreamerv2}
Hafner, D., Lillicrap, T., Norouzi, M., and Ba, J.
\newblock Mastering atari with discrete world models.
\newblock \emph{arXiv preprint arXiv:2010.02193}, 2020.

\bibitem[Higgins et~al.(2016)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{bvae}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., and Lerchner, A.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock 2016.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{TT}
Janner, M., Li, Q., and Levine, S.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Kidambi et~al.(2020)Kidambi, Rajeswaran, Netrapalli, and
  Joachims]{morel}
Kidambi, R., Rajeswaran, A., Netrapalli, P., and Joachims, T.
\newblock Morel: Model-based offline reinforcement learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 21810--21823, 2020.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{vae}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kostrikov et~al.(2021)Kostrikov, Nair, and Levine]{iql}
Kostrikov, I., Nair, A., and Levine, S.
\newblock Offline reinforcement learning with implicit q-learning.
\newblock \emph{arXiv preprint arXiv:2110.06169}, 2021.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{cnn}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems},
  25:\penalty0 1097--1105, 2012.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{cql}
Kumar, A., Zhou, A., Tucker, G., and Levine, S.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1179--1191, 2020.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{offline}
Levine, S., Kumar, A., Tucker, G., and Fu, J.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Liu et~al.(2021)Liu, Zhang, Fang, Jiang, and
  Zhou]{stacked_transformers}
Liu, Y., Zhang, J., Fang, L., Jiang, Q., and Zhou, B.
\newblock Multimodal motion prediction with stacked transformers.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7577--7586, 2021.

\bibitem[Ma et~al.(2021)Ma, Jayaraman, and Bastani]{conservative}
Ma, Y., Jayaraman, D., and Bastani, O.
\newblock Conservative offline distributional reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 19235--19247, 2021.

\bibitem[Machado et~al.(2018)Machado, Bellemare, Talvitie, Veness, Hausknecht,
  and Bowling]{atari}
Machado, M.~C., Bellemare, M.~G., Talvitie, E., Veness, J., Hausknecht, M., and
  Bowling, M.
\newblock Revisiting the arcade learning environment: Evaluation protocols and
  open problems for general agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 61:\penalty0
  523--562, 2018.

\bibitem[Ngiam et~al.(2021)Ngiam, Caine, Vasudevan, Zhang, Chiang, Ling,
  Roelofs, Bewley, Liu, Venugopal, et~al.]{scene_transformer}
Ngiam, J., Caine, B., Vasudevan, V., Zhang, Z., Chiang, H.-T.~L., Ling, J.,
  Roelofs, R., Bewley, A., Liu, C., Venugopal, A., et~al.
\newblock Scene transformer: A unified architecture for predicting multiple
  agent trajectories.
\newblock \emph{arXiv preprint arXiv:2106.08417}, 2021.

\bibitem[Ozair et~al.(2021)Ozair, Li, Razavi, Antonoglou, Oord, and
  Vinyals]{VQ_planning}
Ozair, S., Li, Y., Razavi, A., Antonoglou, I., Oord, A. v.~d., and Vinyals, O.
\newblock Vector quantized models for planning.
\newblock \emph{arXiv preprint arXiv:2106.04615}, 2021.

\bibitem[Peng et~al.(2019)Peng, Kumar, Zhang, and Levine]{AWR}
Peng, X.~B., Kumar, A., Zhang, G., and Levine, S.
\newblock Advantage-weighted regression: Simple and scalable off-policy
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.00177}, 2019.

\bibitem[Prakash et~al.(2021)Prakash, Chitta, and Geiger]{transfuser}
Prakash, A., Chitta, K., and Geiger, A.
\newblock Multi-modal fusion transformer for end-to-end autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7077--7087, 2021.

\bibitem[Quintanar et~al.(2021)Quintanar, Fern{\'a}ndez-Llorca, Parra,
  Izquierdo, and Sotelo]{urban_transformer}
Quintanar, A., Fern{\'a}ndez-Llorca, D., Parra, I., Izquierdo, R., and Sotelo,
  M.
\newblock Predicting vehicles trajectories in urban scenarios with transformer
  networks and augmented information.
\newblock \emph{arXiv preprint arXiv:2106.00559}, 2021.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and Sutskever]{gpt}
Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{nlp2}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, et~al.]{muzero}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Shen et~al.(2014)Shen, Tobia, Sommer, and Obermayer]{risk}
Shen, Y., Tobia, M.~J., Sommer, T., and Obermayer, K.
\newblock Risk-sensitive reinforcement learning.
\newblock \emph{Neural computation}, 26\penalty0 (7):\penalty0 1298--1328,
  2014.

\bibitem[Tang \& Salakhutdinov(2019)Tang and Salakhutdinov]{multi_futures}
Tang, C. and Salakhutdinov, R.~R.
\newblock Multiple futures prediction.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 15424--15434, 2019.

\bibitem[Treiber et~al.(2000)Treiber, Hennecke, and Helbing]{idm}
Treiber, M., Hennecke, A., and Helbing, D.
\newblock Congested traffic states in empirical observations and microscopic
  simulations.
\newblock \emph{Physical review E}, 62\penalty0 (2):\penalty0 1805, 2000.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Williams \& Zipser(1989)Williams and Zipser]{teacher_forcing}
Williams, R.~J. and Zipser, D.
\newblock A learning algorithm for continually running fully recurrent neural
  networks.
\newblock \emph{Neural computation}, 1\penalty0 (2):\penalty0 270--280, 1989.

\bibitem[Yu et~al.(2020)Yu, Thomas, Yu, Ermon, Zou, Levine, Finn, and Ma]{mopo}
Yu, T., Thomas, G., Yu, L., Ermon, S., Zou, J.~Y., Levine, S., Finn, C., and
  Ma, T.
\newblock Mopo: Model-based offline policy optimization.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 14129--14142, 2020.

\end{thebibliography}
