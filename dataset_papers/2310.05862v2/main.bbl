\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bansal et~al.(2023)Bansal, Singhi, Yang, Yin, Grover, and
  Chang]{bansal2023cleanclip}
Bansal, H., Singhi, N., Yang, Y., Yin, F., Grover, A., and Chang, K.-W.
\newblock Cleanclip: Mitigating data poisoning attacks in multimodal
  contrastive learning.
\newblock \emph{arXiv preprint arXiv:2303.03323}, 2023.

\bibitem[Biggio et~al.(2012)Biggio, Nelson, and Laskov]{biggio2012poisoning}
Biggio, B., Nelson, B., and Laskov, P.
\newblock Poisoning attacks against support vector machines.
\newblock \emph{arXiv preprint arXiv:1206.6389}, 2012.

\bibitem[Carlini(2021)]{carlini2021poisoningb}
Carlini, N.
\newblock Poisoning the unlabeled dataset of $\{$Semi-Supervised$\}$ learning.
\newblock In \emph{30th USENIX Security Symposium (USENIX Security 21)}, pp.\
  1577--1592, 2021.

\bibitem[Carlini \& Terzis(2021)Carlini and Terzis]{carlini2021poisoning}
Carlini, N. and Terzis, A.
\newblock Poisoning and backdooring contrastive learning.
\newblock \emph{arXiv preprint arXiv:2106.09667}, 2021.

\bibitem[Carlini et~al.(2023)Carlini, Jagielski, Choquette-Choo, Paleka,
  Pearce, Anderson, Terzis, Thomas, and Tram{\`e}r]{carlini2023poisoning}
Carlini, N., Jagielski, M., Choquette-Choo, C.~A., Paleka, D., Pearce, W.,
  Anderson, H., Terzis, A., Thomas, K., and Tram{\`e}r, F.
\newblock Poisoning web-scale training datasets is practical.
\newblock \emph{arXiv preprint arXiv:2302.10149}, 2023.

\bibitem[Caron et~al.(2020)Caron, Misra, Mairal, Goyal, Bojanowski, and
  Joulin]{caron2020unsupervised}
Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., and Joulin, A.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 9912--9924, 2020.

\bibitem[Chen et~al.(2018)Chen, Carvalho, Baracaldo, Ludwig, Edwards, Lee,
  Molloy, and Srivastava]{chen2018detecting}
Chen, B., Carvalho, W., Baracaldo, N., Ludwig, H., Edwards, B., Lee, T.,
  Molloy, I., and Srivastava, B.
\newblock Detecting backdoor attacks on deep neural networks by activation
  clustering.
\newblock \emph{arXiv preprint arXiv:1811.03728}, 2018.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pp.\
  1597--1607. PMLR, 2020.

\bibitem[Chen \& He(2021)Chen and He]{chen2021exploring}
Chen, X. and He, K.
\newblock Exploring simple siamese representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  15750--15758, 2021.

\bibitem[Chen et~al.(2017)Chen, Liu, Li, Lu, and Song]{chen2017targeted}
Chen, X., Liu, C., Li, B., Lu, K., and Song, D.
\newblock Targeted backdoor attacks on deep learning systems using data
  poisoning.
\newblock \emph{arXiv preprint arXiv:1712.05526}, 2017.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dwibedi et~al.(2021)Dwibedi, Aytar, Tompson, Sermanet, and
  Zisserman]{dwibedi2021little}
Dwibedi, D., Aytar, Y., Tompson, J., Sermanet, P., and Zisserman, A.
\newblock With a little help from my friends: Nearest-neighbor contrastive
  learning of visual representations.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9588--9597, 2021.

\bibitem[Geiping et~al.(2021)Geiping, Fowl, Somepalli, Goldblum, Moeller, and
  Goldstein]{geiping2021doesn}
Geiping, J., Fowl, L., Somepalli, G., Goldblum, M., Moeller, M., and Goldstein,
  T.
\newblock What doesn't kill you makes you robust (er): How to adversarially
  train against data poisoning.
\newblock \emph{arXiv preprint arXiv:2102.13624}, 2021.

\bibitem[Goel et~al.(2022)Goel, Bansal, Bhatia, Rossi, Vinay, and
  Grover]{goel2022cyclip}
Goel, S., Bansal, H., Bhatia, S., Rossi, R., Vinay, V., and Grover, A.
\newblock Cyclip: Cyclic contrastive language-image pretraining.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 6704--6719, 2022.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar,
  et~al.]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.,
  Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M.,
  et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 21271--21284, 2020.

\bibitem[Gu et~al.(2017)Gu, Dolan-Gavitt, and Garg]{gu2017badnets}
Gu, T., Dolan-Gavitt, B., and Garg, S.
\newblock Badnets: Identifying vulnerabilities in the machine learning model
  supply chain.
\newblock \emph{arXiv preprint arXiv:1708.06733}, 2017.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  9729--9738, 2020.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh, Z., Pham, H., Le, Q., Sung,
  Y.-H., Li, Z., and Duerig, T.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International conference on machine learning}, pp.\
  4904--4916. PMLR, 2021.

\bibitem[Kim et~al.(2020)Kim, Tack, and Hwang]{kim2020adversarial}
Kim, M., Tack, J., and Hwang, S.~J.
\newblock Adversarial self-supervised contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2983--2994, 2020.

\bibitem[Krishna et~al.(2017)Krishna, Zhu, Groth, Johnson, Hata, Kravitz, Chen,
  Kalantidis, Li, Shamma, et~al.]{krishna2017visual}
Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S.,
  Kalantidis, Y., Li, L.-J., Shamma, D.~A., et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock \emph{International journal of computer vision}, 123:\penalty0
  32--73, 2017.

\bibitem[Li et~al.(2021)Li, Liang, Zhao, Cui, Ouyang, Shao, Yu, and
  Yan]{li2021supervision}
Li, Y., Liang, F., Zhao, L., Cui, Y., Ouyang, W., Shao, J., Yu, F., and Yan, J.
\newblock Supervision exists everywhere: A data efficient contrastive
  language-image pre-training paradigm.
\newblock \emph{arXiv preprint arXiv:2110.05208}, 2021.

\bibitem[Li et~al.(2024)Li, Ma, He, Huang, and Jiang]{li2024multi}
Li, Y., Ma, X., He, J., Huang, H., and Jiang, Y.-G.
\newblock Multi-trigger backdoor attacks: More triggers, more threats.
\newblock \emph{arXiv preprint arXiv:2401.15295}, 2024.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pp.\
  740--755. Springer, 2014.

\bibitem[Mu et~al.(2022)Mu, Kirillov, Wagner, and Xie]{mu2022slip}
Mu, N., Kirillov, A., Wagner, D., and Xie, S.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock In \emph{European Conference on Computer Vision}, pp.\  529--544.
  Springer, 2022.

\bibitem[Nguyen \& Tran(2021)Nguyen and Tran]{nguyen2021wanet}
Nguyen, A. and Tran, A.
\newblock Wanet--imperceptible warping-based backdoor attack.
\newblock \emph{arXiv preprint arXiv:2102.10369}, 2021.

\bibitem[Peri et~al.(2020)Peri, Gupta, Huang, Fowl, Zhu, Feizi, Goldstein, and
  Dickerson]{peri2020deep}
Peri, N., Gupta, N., Huang, W.~R., Fowl, L., Zhu, C., Feizi, S., Goldstein, T.,
  and Dickerson, J.~P.
\newblock Deep k-nn defense against clean-label data poisoning attacks.
\newblock In \emph{Computer Vision--ECCV 2020 Workshops: Glasgow, UK, August
  23--28, 2020, Proceedings, Part I 16}, pp.\  55--70. Springer, 2020.

\bibitem[Permuter et~al.(2006)Permuter, Francos, and Jermyn]{permuter2006study}
Permuter, H., Francos, J., and Jermyn, I.
\newblock A study of gaussian mixture models of color and texture features for
  image classification and segmentation.
\newblock \emph{Pattern recognition}, 39\penalty0 (4):\penalty0 695--706, 2006.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pp.\
  8748--8763. PMLR, 2021.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
Sharma, P., Ding, N., Goodman, S., and Soricut, R.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  2556--2565,
  2018.

\bibitem[Tran et~al.(2018)Tran, Li, and Madry]{tran2018spectral}
Tran, B., Li, J., and Madry, A.
\newblock Spectral signatures in backdoor attacks.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Turner et~al.(2019)Turner, Tsipras, and Madry]{turner2019label}
Turner, A., Tsipras, D., and Madry, A.
\newblock Label-consistent backdoor attacks.
\newblock \emph{arXiv preprint arXiv:1912.02771}, 2019.

\bibitem[Wei \& Zou(2019)Wei and Zou]{wei2019eda}
Wei, J. and Zou, K.
\newblock Eda: Easy data augmentation techniques for boosting performance on
  text classification tasks.
\newblock \emph{arXiv preprint arXiv:1901.11196}, 2019.

\bibitem[Yang \& Mirzasoleiman(2023)Yang and Mirzasoleiman]{yang2023robust}
Yang, W. and Mirzasoleiman, B.
\newblock Robust contrastive language-image pretraining against adversarial
  attacks.
\newblock \emph{arXiv preprint arXiv:2303.06854}, 2023.

\bibitem[Yang et~al.(2023)Yang, He, Li, Backes, Humbert, Berrang, and
  Zhang]{yang2023data}
Yang, Z., He, X., Li, Z., Backes, M., Humbert, M., Berrang, P., and Zhang, Y.
\newblock Data poisoning attacks against multimodal encoders.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  39299--39313. PMLR, 2023.

\bibitem[Zbontar et~al.(2021)Zbontar, Jing, Misra, LeCun, and
  Deny]{zbontar2021barlow}
Zbontar, J., Jing, L., Misra, I., LeCun, Y., and Deny, S.
\newblock Barlow twins: Self-supervised learning via redundancy reduction.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  12310--12320. PMLR, 2021.

\end{thebibliography}
