\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amari(1985)]{amari1985book}
Amari, Shun-ichi.
\newblock \emph{Differential-Geometrical Methods in Statistic}.
\newblock Springer, New York, 1985.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Mane]{amodei2016concrete}
Amodei, Dario, Olah, Chris, Steinhardt, Jacob, Christiano, Paul, Schulman,
  John, and Mane, Dan.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Angermueller \& Stegle(2015)Angermueller and
  Stegle]{angermueller2015multi}
Angermueller, C and Stegle, O.
\newblock Multi-task deep neural network to predict {CpG} methylation profiles
  from low-coverage sequencing data.
\newblock In \emph{NIPS MLCB workshop}, 2015.

\bibitem[Barber \& Bishop(1998)Barber and Bishop]{barber1998ensemble}
Barber, David and Bishop, Christopher~M.
\newblock Ensemble learning in {B}ayesian neural networks.
\newblock \emph{NATO ASI SERIES F COMPUTER AND SYSTEMS SCIENCES}, 168:\penalty0
  215--238, 1998.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, Charles, Cornebise, Julien, Kavukcuoglu, Koray, and Wierstra, Daan.
\newblock Weight uncertainty in neural network.
\newblock In \emph{ICML}, 2015.

\bibitem[Bui et~al.(2016)Bui, Hern{\'a}ndez-Lobato, Li, Hern{\'a}ndez-Lobato,
  and Turner]{bui2016dgp}
Bui, Thang~D, Hern{\'a}ndez-Lobato, Daniel, Li, Yingzhen, Hern{\'a}ndez-Lobato,
  Jos{\'e}~Miguel, and Turner, Richard~E.
\newblock Deep gaussian processes for regression using approximate expectation
  propagation.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning (ICML)}, 2016.

\bibitem[Carlini \& Wagner(2016)Carlini and Wagner]{carlini2016towards}
Carlini, Nicholas and Wagner, David.
\newblock Towards evaluating the robustness of neural networks.
\newblock \emph{arXiv preprint arXiv:1608.04644}, 2016.

\bibitem[Chollet(2015)]{keras2015}
Chollet, Francois.
\newblock Keras.
\newblock \url{https://github.com/fchollet/keras}, 2015.

\bibitem[Denker \& LeCun(1991)Denker and LeCun]{denker1991transforming}
Denker, John and LeCun, Yann.
\newblock Transforming neural-net output levels to probability distributions.
\newblock In \emph{Advances in Neural Information Processing Systems 3}.
  Citeseer, 1991.

\bibitem[Depeweg et~al.(2016)Depeweg, Hern{\'a}ndez-Lobato, Doshi-Velez, and
  Udluft]{depeweg2016bnn_rl}
Depeweg, Stefan, Hern{\'a}ndez-Lobato, Jos{\'e}~Miguel, Doshi-Velez, Finale,
  and Udluft, Steffen.
\newblock Learning and policy search in stochastic dynamical systems with
  bayesian neural networks.
\newblock \emph{arXiv preprint arXiv:1605.07127}, 2016.

\bibitem[Gal(2016)]{Gal2016Uncertainty}
Gal, Yarin.
\newblock \emph{Uncertainty in Deep Learning}.
\newblock PhD thesis, University of Cambridge, 2016.

\bibitem[Gal \& Ghahramani(2016{\natexlab{a}})Gal and
  Ghahramani]{Gal2016Bayesian}
Gal, Yarin and Ghahramani, Zoubin.
\newblock Bayesian convolutional neural networks with {B}ernoulli approximate
  variational inference.
\newblock \emph{ICLR workshop track}, 2016{\natexlab{a}}.

\bibitem[Gal \& Ghahramani(2016{\natexlab{b}})Gal and
  Ghahramani]{gal2016dropout}
Gal, Yarin and Ghahramani, Zoubin.
\newblock Dropout as a {B}ayesian approximation: Representing model uncertainty
  in deep learning.
\newblock \emph{ICML}, 2016{\natexlab{b}}.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, Ian~J, Shlens, Jonathon, and Szegedy, Christian.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Graves(2011)]{graves2011practical}
Graves, Alex.
\newblock Practical variational inference for neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2348--2356, 2011.

\bibitem[Hellinger(1909)]{hellinger1909neue}
Hellinger, Ernst.
\newblock Neue begr{\"u}ndung der theorie quadratischer formen von
  unendlichvielen ver{\"a}nderlichen.
\newblock \emph{Journal f{\"u}r die reine und angewandte Mathematik},
  136:\penalty0 210--271, 1909.

\bibitem[Hernandez-Lobato \& Adams(2015)Hernandez-Lobato and
  Adams]{hernandez2015probabilistic}
Hernandez-Lobato, Jose~Miguel and Adams, Ryan.
\newblock Probabilistic backpropagation for scalable learning of {B}ayesian
  neural networks.
\newblock In \emph{ICML}, 2015.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2016)Hern{\'a}ndez-Lobato, Li,
  Hern{\'a}ndez-Lobato, Bui, and Turner]{hernandez2016black}
Hern{\'a}ndez-Lobato, Jos{\'e}~Miguel, Li, Yingzhen, Hern{\'a}ndez-Lobato,
  Daniel, Bui, Thang, and Turner, Richard~E.
\newblock Black-box alpha divergence minimization.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning}, pp.\  1511--1520, 2016.

\bibitem[Hinton \& Van~Camp(1993)Hinton and Van~Camp]{hinton1993keeping}
Hinton, Geoffrey~E and Van~Camp, Drew.
\newblock Keeping the neural networks simple by minimizing the description
  length of the weights.
\newblock In \emph{COLT}, pp.\  5--13. ACM, 1993.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, Krizhevsky, Sutskever, and
  Salakhutdinov]{hinton2012improving}
Hinton, Geoffrey~E, Srivastava, Nitish, Krizhevsky, Alex, Sutskever, Ilya, and
  Salakhutdinov, Ruslan~R.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock \emph{arXiv preprint arXiv:1207.0580}, 2012.

\bibitem[Jordan et~al.(1999)Jordan, Ghahramani, Jaakkola, and
  Saul]{jordan1999introduction}
Jordan, Michael~I, Ghahramani, Zoubin, Jaakkola, Tommi~S, and Saul, Lawrence~K.
\newblock An introduction to variational methods for graphical models.
\newblock \emph{Machine learning}, 37\penalty0 (2):\penalty0 183--233, 1999.

\bibitem[Kalchbrenner \& Blunsom(2013)Kalchbrenner and
  Blunsom]{kalchbrenner2013recurrent}
Kalchbrenner, Nal and Blunsom, Phil.
\newblock Recurrent continuous translation models.
\newblock In \emph{EMNLP}, 2013.

\bibitem[Kendall \& Cipolla(2016)Kendall and Cipolla]{kendall2016modelling}
Kendall, Alex and Cipolla, Roberto.
\newblock Modelling uncertainty in deep learning for camera relocalization.
\newblock In \emph{2016 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  4762--4769. IEEE, 2016.

\bibitem[Kendall et~al.(2015)Kendall, Badrinarayanan, and
  Cipolla]{kendall2015bayesian}
Kendall, Alex, Badrinarayanan, Vijay, and Cipolla, Roberto.
\newblock Bayesian segnet: Model uncertainty in deep convolutional
  encoder-decoder architectures for scene understanding.
\newblock \emph{arXiv preprint arXiv:1511.02680}, 2015.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1097--1105, 2012.

\bibitem[Kullback(1959)]{kullback1959information}
Kullback, Solomon.
\newblock \emph{Information theory and statistics}.
\newblock John Wiley \& Sons, 1959.

\bibitem[Kullback \& Leibler(1951)Kullback and
  Leibler]{kullback1951information}
Kullback, Solomon and Leibler, Richard~A.
\newblock On information and sufficiency.
\newblock \emph{The annals of mathematical statistics}, 22\penalty0
  (1):\penalty0 79--86, 1951.

\bibitem[LeCun \& Cortes(1998)LeCun and Cortes]{lecun1998mnist}
LeCun, Yann and Cortes, Corinna.
\newblock The mnist database of handwritten digits, 1998.

\bibitem[LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard,
  and Jackel]{lecun1989backpropagation}
LeCun, Yann, Boser, Bernhard, Denker, John~S, Henderson, Donnie, Howard,
  Richard~E, Hubbard, Wayne, and Jackel, Lawrence~D.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock \emph{Neural Computation}, 1\penalty0 (4):\penalty0 541--551, 1989.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, and
  Huang]{lecun2006energy}
LeCun, Yann, Chopra, Sumit, Hadsell, Raia, Ranzato, M, and Huang, F.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 1:\penalty0 0, 2006.

\bibitem[Li \& Turner(2016)Li and Turner]{li2016variational}
Li, Yingzhen and Turner, Richard~E.
\newblock R{\'e}nyi divergence variational inference.
\newblock In \emph{NIPS}, 2016.

\bibitem[Li et~al.(2015)Li, Hern{\'a}ndez-Lobato, and Turner]{li2015sep}
Li, Yingzhen, Hern{\'a}ndez-Lobato, Jos{\'e}~Miguel, and Turner, Richard~E.
\newblock Stochastic expectation propagation.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2015.

\bibitem[MacKay(1992)]{mackay1992practical}
MacKay, David~JC.
\newblock A practical {B}ayesian framework for backpropagation networks.
\newblock \emph{Neural Computation}, 4\penalty0 (3):\penalty0 448--472, 1992.

\bibitem[Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget, {\v{C}}ernock{\`y},
  and Khudanpur]{mikolov2010recurrent}
Mikolov, Tom{\'a}{\v{s}}, Karafi{\'a}t, Martin, Burget, Luk{\'a}{\v{s}},
  {\v{C}}ernock{\`y}, Jan, and Khudanpur, Sanjeev.
\newblock Recurrent neural network based language model.
\newblock In \emph{Eleventh Annual Conference of the International Speech
  Communication Association}, 2010.

\bibitem[Minka(2005)]{minka2005divergence}
Minka, Tom.
\newblock Divergence measures and message passing.
\newblock Technical report, Microsoft Research, 2005.

\bibitem[Minka(2001)]{minka2001ep}
Minka, T.P.
\newblock {Expectation propagation for approximate Bayesian inference}.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  2001.

\bibitem[Minka(2004)]{minka2004powerep}
Minka, T.P.
\newblock {Power EP}.
\newblock Technical Report MSR-TR-2004-149, Microsoft Research, 2004.

\bibitem[Neal(1995)]{neal1995bayesian}
Neal, Radford~M.
\newblock \emph{Bayesian learning for neural networks}.
\newblock PhD thesis, University of Toronto, 1995.

\bibitem[Papernot et~al.(2016)Papernot, Goodfellow, Sheatsley, Feinman, and
  McDaniel]{papernot2016cleverhans}
Papernot, Nicolas, Goodfellow, Ian, Sheatsley, Ryan, Feinman, Reuben, and
  McDaniel, Patrick.
\newblock cleverhans v1.0.0: an adversarial machine learning library.
\newblock \emph{arXiv preprint arXiv:1610.00768}, 2016.

\bibitem[R{\'e}nyi(1961)]{renyi1961divergence}
R{\'e}nyi, Alfr{\'e}d.
\newblock On measures of entropy and information.
\newblock \emph{Fourth Berkeley symposium on mathematical statistics and
  probability}, 1, 1961.

\bibitem[Rumelhart et~al.(1985)Rumelhart, Hinton, and
  Williams]{rumelhart1985learning}
Rumelhart, David~E, Hinton, Geoffrey~E, and Williams, Ronald~J.
\newblock Learning internal representations by error propagation.
\newblock Technical report, DTIC Document, 1985.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch]{sennrich2016Edinburgh}
Sennrich, Rico, Haddow, Barry, and Birch, Alexandra.
\newblock Edinburgh neural machine translation systems for wmt 16.
\newblock In \emph{Proceedings of the First Conference on Machine Translation},
  pp.\  371--376, Berlin, Germany, August 2016. Association for Computational
  Linguistics.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex, Sutskever, Ilya, and
  Salakhutdinov, Ruslan.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Sundermeyer et~al.(2012)Sundermeyer, Schl{\"u}ter, and
  Ney]{sundermeyer2012lstm}
Sundermeyer, Martin, Schl{\"u}ter, Ralf, and Ney, Hermann.
\newblock {LSTM} neural networks for language modeling.
\newblock In \emph{INTERSPEECH}, 2012.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Sutskever, Ilya, Vinyals, Oriol, and Le, Quoc~VV.
\newblock Sequence to sequence learning with neural networks.
\newblock In \emph{NIPS}, 2014.

\bibitem[Szegedy et~al.(2014)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2014going}
Szegedy, Christian, Liu, Wei, Jia, Yangqing, Sermanet, Pierre, Reed, Scott,
  Anguelov, Dragomir, Erhan, Dumitru, Vanhoucke, Vincent, and Rabinovich,
  Andrew.
\newblock Going deeper with convolutions.
\newblock \emph{arXiv preprint arXiv:1409.4842}, 2014.

\bibitem[Turner \& Sahani(2011)Turner and Sahani]{turner2011two}
Turner, RE and Sahani, M.
\newblock Two problems with variational expectation maximisation for
  time-series models.
\newblock \emph{Inference and Estimation in Probabilistic Time-Series Models},
  2011.

\bibitem[Van~Erven \& Harremo{\"e}s(2014)Van~Erven and
  Harremo{\"e}s]{van_erven2014renyi}
Van~Erven, Tim and Harremo{\"e}s, Peter.
\newblock R{\'e}nyi divergence and {Kullback-Leibler} divergence.
\newblock \emph{Information Theory, IEEE Transactions on}, 60\penalty0
  (7):\penalty0 3797--3820, 2014.

\bibitem[Wan et~al.(2013)Wan, Zeiler, Zhang, LeCun, and
  Fergus]{wan2013regularization}
Wan, L, Zeiler, M, Zhang, S, LeCun, Y, and Fergus, R.
\newblock Regularization of neural networks using dropconnect.
\newblock In \emph{ICML-13}, 2013.

\bibitem[Yang et~al.(2016)Yang, Kwitt, and Niethammer]{yang2016fast}
Yang, Xiao, Kwitt, Roland, and Niethammer, Marc.
\newblock Fast predictive image registration.
\newblock \emph{arXiv preprint arXiv:1607.02504}, 2016.

\end{thebibliography}
