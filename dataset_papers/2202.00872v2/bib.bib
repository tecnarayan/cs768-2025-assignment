@article{Fazel19,
  author    = {Maryam Fazel and
               Rong Ge and
               Sham M. Kakade and
               Mehran Mesbahi},
  title     = {Global Convergence of Policy Gradient Methods for Linearized Control
               Problems},
  journal   = {CoRR},
  volume    = {abs/1801.05039},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1801.05039},
  timestamp = {Mon, 13 Aug 2018 16:48:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1801-05039.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Sham02,
  author =       "Kakade, Sham",
  title =        "A Natural Policy Gradient",
  booktitle =    "Advances in Neural Information Processing Systems 14 (NIPS 2001)",
  editor =    "Dietterich, Thomas G. and Becker, Suzanna and Ghahramani, Zoubin",
  year =         "2001",
  publisher = "MIT Press",
  pages =     "1531-1538",
  url = "http://books.nips.cc/papers/files/nips14/CN11.pdf",
  bib2html_rescat = "Learning Methods, MDP",
}

@incollection{Rajeswaran17,
title = {Towards Generalization and Simplicity in Continuous Control},
author = {Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel V. and Kakade, Sham M},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {6550--6561},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@article{Amari98,
  added-at = {2008-02-26T12:05:08.000+0100},
  author = {Amari, S.},
  biburl = {https://www.bibsonomy.org/bibtex/204cab5fc779db34f662a2ae0f25e96ad/schaul},
  citeulike-article-id = {2374794},
  description = {idsia},
  interhash = {a5cad2a0bad7028a732ae79e9fa6a4b2},
  intrahash = {04cab5fc779db34f662a2ae0f25e96ad},
  journal = {Neural Computation},
  keywords = {daanbib},
  number = 2,
  pages = {251--276},
  priority = {2},
  timestamp = {2008-02-26T12:06:57.000+0100},
  title = {Natural Gradient Works Efficiently in Learning},
  volume = 10,
  year = 1998
}

@article{Lagoudakis03,
author = {Lagoudakis, Michail G. and Parr, Ronald},
title = {Least-Squares Policy Iteration},
year = {2003},
issue_date = {December 2003},
publisher = {JMLR.org},
volume = {4},
number = {null},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = dec,
pages = {1107–1149},
numpages = {43}
}

@inproceedings{Krauth19,
  title={Finite-time analysis of approximate policy iteration for the linear quadratic regulator},
  author={Krauth, Karl and Tu, Stephen and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8512--8522},
  year={2019}
}



@inproceedings{Silver14,
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
title = {Deterministic Policy Gradient Algorithms},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {I–387–I–395},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}

@inproceedings{Kakade02,
  author    = {Sham M. Kakade and
               John Langford},
  editor    = {Claude Sammut and
               Achim G. Hoffmann},
  title     = {Approximately Optimal Approximate Reinforcement Learning},
  booktitle = {Machine Learning, Proceedings of the Nineteenth International Conference
               {(ICML} 2002), University of New South Wales, Sydney, Australia, July
               8-12, 2002},
  pages     = {267--274},
  publisher = {Morgan Kaufmann},
  year      = {2002},
  timestamp = {Tue, 23 Jul 2019 15:03:10 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/KakadeL02.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Lewis09,
  author={F. L. {Lewis} and D. {Vrabie}},
  journal={IEEE Circuits and Systems Magazine}, 
  title={Reinforcement learning and adaptive dynamic programming for feedback control}, 
  year={2009},
  volume={9},
  number={3},
  pages={32-50},}

@article{Malik18,
  author    = {Dhruv Malik and
               Ashwin Pananjady and
               Kush Bhatia and
               Koulik Khamaru and
               Peter L. Bartlett and
               Martin J. Wainwright},
  title     = {Derivative-Free Methods for Policy Optimization: Guarantees for Linear
               Quadratic Systems},
  journal   = {CoRR},
  volume    = {abs/1812.08305},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1812.08305},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-08305.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{qu2019,
    title={Scalable Reinforcement Learning of Localized Policies for Multi-Agent Networked Systems},
    author={Guannan Qu and Adam Wierman and Na Li},
    year={2019},
    eprint={1912.02906},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@article{abbasi18,
  title={Model-free linear quadratic control via reduction to expert prediction},
  author={Abbasi-Yadkori, Yasin and Lazic, Nevena and Szepesv{\'a}ri, Csaba},
  journal={arXiv preprint arXiv:1804.06021},
  year={2018}
}

@article{schacke04,
  title={On the kronecker product},
  author={Schacke, Kathrin},
  journal={Master's thesis, University of Waterloo},
  year={2004}
}

@article{simchowitz18,
  title={Learning without mixing: Towards a sharp analysis of linear system identification},
  author={Simchowitz, Max and Mania, Horia and Tu, Stephen and Jordan, Michael I and Recht, Benjamin},
  journal={arXiv preprint arXiv:1802.08334},
  year={2018}
}

@book{Sutton18,
author = {Sutton, Richard S. and Barto, Andrew G.},
title = {Reinforcement Learning: An Introduction},
year = {2018},
isbn = {0262039249},
publisher = {A Bradford Book},
address = {Cambridge, MA, USA}
}

@misc{dean17,
    title={On the Sample Complexity of the Linear Quadratic Regulator},
    author={Sarah Dean and Horia Mania and Nikolai Matni and Benjamin Recht and Stephen Tu},
    year={2017},
    eprint={1710.01688},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@article{abbasi11,
  title={Online least squares estimation with self-normalized processes: An application to bandit problems},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={arXiv preprint arXiv:1102.2670},
  year={2011}
}

@misc{li19,
    title={Distributed Reinforcement Learning for Decentralized Linear Quadratic Control: A Derivative-Free Policy Optimization Approach},
    author={Yingying Li and Yujie Tang and Runyu Zhang and Na Li},
    year={2019},
    eprint={1912.09135},
    archivePrefix={arXiv},
    primaryClass={eess.SY}
}

@misc{lale2020,
    title={Logarithmic Regret Bound in Partially Observable Linear Dynamical Systems},
    author={Sahin Lale and Kamyar Azizzadenesheli and Babak Hassibi and Anima Anandkumar},
    year={2020},
    eprint={2003.11227},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{agarwal2020,
      title={On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift}, 
      author={Alekh Agarwal and Sham M. Kakade and Jason D. Lee and Gaurav Mahajan},
      year={2020},
      eprint={1908.00261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@ARTICLE{Shamma05,
  author={J. S. {Shamma} and G. {Arslan}},
  journal={IEEE Transactions on Automatic Control}, 
  title={Dynamic fictitious play, dynamic gradient play, and distributed convergence to Nash equilibria}, 
  year={2005},
  volume={50},
  number={3},
  pages={312-327},
  doi={10.1109/TAC.2005.843878}}
  
@inproceedings{Sutton1999,
  title={Policy gradient methods for reinforcement learning with function approximation.},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay and others},
  booktitle={NIPs},
  volume={99},
  pages={1057--1063},
  year={1999},
  organization={Citeseer}
}

@book{beck2017,
  title={First-order methods in optimization},
  author={Beck, Amir},
  year={2017},
  publisher={SIAM}
}
@inproceedings{qu2020,
  title={Scalable reinforcement learning of localized policies for multi-agent networked systems},
  author={Qu, Guannan and Wierman, Adam and Li, Na},
  booktitle={Learning for Dynamics and Control},
  pages={256--266},
  year={2020},
  organization={PMLR}
}

@article{mazumdar20,
  title={On gradient-based learning in continuous games},
  author={Mazumdar, Eric and Ratliff, Lillian J and Sastry, S Shankar},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={1},
  pages={103--131},
  year={2020},
  publisher={SIAM}
}

@article{Tesauro03,
  title={Extending Q-learning to general adaptive multi-agent systems},
  author={Tesauro, Gerald},
  journal={Advances in neural information processing systems},
  volume={16},
  pages={871--878},
  year={2003}
}

@inproceedings{Bowling01,
  title={Rational and convergent learning in stochastic games},
  author={Bowling, Michael and Veloso, Manuela},
  booktitle={International joint conference on artificial intelligence},
  volume={17},
  number={1},
  pages={1021--1026},
  year={2001},
  organization={Citeseer}
}

@article{Hu03,
  title={Nash Q-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of machine learning research},
  volume={4},
  number={Nov},
  pages={1039--1069},
  year={2003}
}

@incollection{Littman94,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@article{Bucsoniu10,
  title={Multi-agent reinforcement learning: An overview},
  author={Bu{\c{s}}oniu, Lucian and Babu{\v{s}}ka, Robert and De Schutter, Bart},
  journal={Innovations in multi-agent systems and applications-1},
  pages={183--221},
  year={2010},
  publisher={Springer}
}

@techreport{Bowling00,
  title={An analysis of stochastic game theory for multiagent reinforcement learning},
  author={Bowling, Michael and Veloso, Manuela},
  year={2000},
  institution={Carnegie-Mellon Univ Pittsburgh Pa School of Computer Science}
}

@techreport{Shoham03,
  title={Multi-agent reinforcement learning: a critical survey},
  author={Shoham, Yoav and Powers, Rob and Grenager, Trond},
  year={2003},
  institution={Technical report, Stanford University}
}
@article{Zhang19,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={arXiv preprint arXiv:1911.10635},
  year={2019}
}

@article{Lanctot17,
  title={A unified game-theoretic approach to multiagent reinforcement learning},
  author={Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and P{\'e}rolat, Julien and Silver, David and Graepel, Thore},
  journal={arXiv preprint arXiv:1711.00832},
  year={2017}
}

@book{Gonzalez13,
  title={Discrete--time stochastic control and dynamic potential games: the Euler--Equation approach},
  author={Gonz{\'a}lez-S{\'a}nchez, David and Hern{\'a}ndez-Lerma, On{\'e}simo},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{Ghadimi16,
  title={Accelerated gradient methods for nonconvex nonlinear and stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={Mathematical Programming},
  volume={156},
  number={1-2},
  pages={59--99},
  year={2016},
  publisher={Springer}
}

@article{Foerster17,
  title={Learning with opponent-learning awareness},
  author={Foerster, Jakob N and Chen, Richard Y and Al-Shedivat, Maruan and Whiteson, Shimon and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:1709.04326},
  year={2017}
}

@article{Abdallah08,
  title={A multiagent reinforcement learning algorithm with non-linear dynamics},
  author={Abdallah, Sherief and Lesser, Victor},
  journal={Journal of Artificial Intelligence Research},
  volume={33},
  pages={521--549},
  year={2008}
}
@inproceedings{Zhang10,
  title={Multi-agent learning with policy prediction},
  author={Zhang, Chongjie and Lesser, Victor},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={24},
  number={1},
  year={2010}
}

@article{Monderer96,
  title={Potential games},
  author={Monderer, Dov and Shapley, Lloyd S},
  journal={Games and economic behavior},
  volume={14},
  number={1},
  pages={124--143},
  year={1996},
  publisher={Elsevier}
}

@article{Monderer96fictitious,
  title={Fictitious play property for games with identical interests},
  author={Monderer, Dov and Shapley, Lloyd S},
  journal={Journal of economic theory},
  volume={68},
  number={1},
  pages={258--265},
  year={1996},
  publisher={Elsevier}
}

@article{Monderer97,
  title={Fictitious play and no-cycling conditions},
  author={Monderer, Dov and Sela, Aner},
  year={1997}
}
@article{Marden09,
  title={Joint strategy fictitious play with inertia for potential games},
  author={Marden, Jason R and Arslan, G{\"u}rdal and Shamma, Jeff S},
  journal={IEEE Transactions on Automatic Control},
  volume={54},
  number={2},
  pages={208--220},
  year={2009},
  publisher={IEEE}
}

@article{Shapley64,
  title={Some topics in two-person games},
  author={Shapley, Lloyd},
  journal={Advances in game theory},
  volume={52},
  pages={1--29},
  year={1964}
}

@article{Jordan93,
  title={Three problems in learning mixed-strategy Nash equilibria},
  author={Jordan, James S},
  journal={Games and Economic Behavior},
  volume={5},
  number={3},
  pages={368--386},
  year={1993},
  publisher={Elsevier}
}
@article{Krishna98,
  title={On the convergence of fictitious play},
  author={Krishna, Vijay and Sj{\"o}str{\"o}m, Tomas},
  journal={Mathematics of Operations Research},
  volume={23},
  number={2},
  pages={479--511},
  year={1998},
  publisher={INFORMS}
}

@article{Crawford85,
  title={Learning behavior and mixed-strategy Nash equilibria},
  author={Crawford, Vincent P},
  journal={Journal of Economic Behavior \& Organization},
  volume={6},
  number={1},
  pages={69--78},
  year={1985},
  publisher={Elsevier}
}

@article{Heikkinen06,
  title={A potential game approach to distributed power control and scheduling},
  author={Heikkinen, Tiina},
  journal={Computer Networks},
  volume={50},
  number={13},
  pages={2295--2311},
  year={2006},
  publisher={Elsevier}
}

@inproceedings{Ibars10,
  title={Distributed demand management in smart grid with a congestion game},
  author={Ibars, Christian and Navarro, Monica and Giupponi, Lorenza},
  booktitle={2010 First IEEE International Conference on Smart Grid Communications},
  pages={495--500},
  year={2010},
  organization={IEEE}
}

@article{Marden13,
  title={A model-free approach to wind farm control using game theoretic methods},
  author={Marden, Jason R and Ruben, Shalom D and Pao, Lucy Y},
  journal={IEEE Transactions on Control Systems Technology},
  volume={21},
  number={4},
  pages={1207--1214},
  year={2013},
  publisher={IEEE}
}

@inproceedings{Ge2015,
  title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on learning theory},
  pages={797--842},
  year={2015},
  organization={PMLR}
}

@article{Wang13,
  author    = {Weiran Wang and
               Miguel {\'{A}}. Carreira{-}Perpi{\~{n}}{\'{a}}n},
  title     = {Projection onto the probability simplex: An efficient algorithm with
               a simple proof, and an application},
  journal   = {CoRR},
  volume    = {abs/1309.1541},
  year      = {2013},
  archivePrefix = {arXiv},
  eprint    = {1309.1541},
  timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WangC13a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Macua18,
  author    = {Sergio Valcarcel Macua and
               Javier Zazo and
               Santiago Zazo},
  title     = {Learning Parametric Closed-Loop Policies for Markov Potential Games},
  journal   = {CoRR},
  volume    = {abs/1802.00899},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1802.00899},
  timestamp = {Mon, 13 Aug 2018 16:49:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-00899.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Arslan16,
  title={Decentralized Q-learning for stochastic teams and games},
  author={Arslan, G{\"u}rdal and Y{\"u}ksel, Serdar},
  journal={IEEE Transactions on Automatic Control},
  volume={62},
  number={4},
  pages={1545--1558},
  year={2016},
  publisher={IEEE}
}

@article{shapley53,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the national academy of sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}

@article{Kohlberg86,
  title={On the strategic stability of equilibria},
  author={Kohlberg, Elon and Mertens, Jean-Francois},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1003--1037},
  year={1986},
  publisher={JSTOR}
}
@book{Van91,
  title={Stability and perfection of Nash equilibria},
  author={Van Damme, Eric},
  volume={339},
  year={1991},
  publisher={Springer}
}

@inproceedings{Tan93,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}

@article{Claus98,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI/IAAI},
  volume={1998},
  number={746-752},
  pages={2},
  year={1998}
}

@article{Panait05,
  title={Cooperative multi-agent learning: The state of the art},
  author={Panait, Liviu and Luke, Sean},
  journal={Autonomous agents and multi-agent systems},
  volume={11},
  number={3},
  pages={387--434},
  year={2005},
  publisher={Springer}
}

@article{Levhari80,
  title={The Great Fish War: An Example Using a Dynamic Cournot-Nash Solution},
  author={Levhari, David and Mirman, Leonard},
  journal={Bell Journal of Economics},
  volume={11},
  number={1},
  pages={322--334},
  year={1980},
  publisher={The RAND Corporation}
}

@article{Dechert06,
  title={The stochastic lake game: A numerical solution},
  author={Dechert, W Davis and O’Donnell, SI},
  journal={Journal of Economic Dynamics and Control},
  volume={30},
  number={9-10},
  pages={1569--1587},
  year={2006},
  publisher={Elsevier}
}

@inproceedings{Hoi-To18,
author = {Wai, Hoi-To and Yang, Zhuoran and Wang, Zhaoran and Hong, Mingyi},
title = {Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
pages = {9672–9683},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@article{Chen18,
  title={Communication-Efficient Policy Gradient Methods for Distributed Reinforcement Learning},
  author={Chen, Tianyi and Zhang, Kaiqing and Giannakis, Georgios B and Ba{\c{s}}ar, Tamer},
  journal={arXiv preprint arXiv:1812.03239},
  year={2018}
}

@inproceedings{Zhang18,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}

@inproceedings{Zhang19-LQgame,
 author = {Zhang, Kaiqing and Yang, Zhuoran and Basar, Tamer},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Policy Optimization Provably Converges to Nash Equilibria in Zero-Sum Linear Quadratic Games},
 url = {https://proceedings.neurips.cc/paper/2019/file/5446f217e9504bc593ad9dcf2ec88dda-Paper.pdf},
 volume = {32},
 year = {2019}
}


@InProceedings{Mei20, 
title = {On the Global Convergence Rates of Softmax Policy Gradient Methods}, author = {Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {6820--6829}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}, publisher = {PMLR} }

@article{ShalevShwartz2016,
  title={Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving},
  author={S. Shalev-Shwartz and Shaked Shammah and A. Shashua},
  journal={ArXiv},
  year={2016},
  volume={abs/1610.03295}
}

@article{daneshfar2010,
  title={Load--frequency control: a GA-based multi-agent reinforcement learning},
  author={Daneshfar, Fatheme and Bevrani, Hassan},
  journal={IET generation, transmission \& distribution},
  volume={4},
  number={1},
  pages={13--26},
  year={2010},
  publisher={IET}
}

@inproceedings{vidhate2017cooperative,
  title={Cooperative multi-agent reinforcement learning models (CMRLM) for intelligent traffic control},
  author={Vidhate, Deepak A and Kulkarni, Parag},
  booktitle={2017 1st International Conference on Intelligent Systems and Information Management (ICISIM)},
  pages={325--331},
  year={2017},
  organization={IEEE}
}

@article{xu2020multi,
  title={A multi-agent reinforcement learning-based data-driven method for home energy management},
  author={Xu, Xu and Jia, Youwei and Xu, Yan and Xu, Zhao and Chai, Songjian and Lai, Chun Sing},
  journal={IEEE Transactions on Smart Grid},
  volume={11},
  number={4},
  pages={3201--3211},
  year={2020},
  publisher={IEEE}
}

@inproceedings{Sidford18,
 author = {Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model},
 url = {https://proceedings.neurips.cc/paper/2018/file/bb03e43ffe34eeb242a2ee4a4f125e56-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{leonardos21,
  title={Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games},
  author={Leonardos, Stefanos and Overman, Will and Panageas, Ioannis and Piliouras, Georgios},
  journal={arXiv preprint arXiv:2106.01969},
  year={2021}
}

@inproceedings{srikant19,
  title={Finite-time error bounds for linear stochastic approximation andtd learning},
  author={Srikant, Rayadurgam and Ying, Lei},
  booktitle={Conference on Learning Theory},
  pages={2803--2830},
  year={2019},
  organization={PMLR}
}
@incollection{hoeffding94,
  title={Probability inequalities for sums of bounded random variables},
  author={Hoeffding, Wassily},
  booktitle={The collected works of Wassily Hoeffding},
  pages={409--426},
  year={1994},
  publisher={Springer}
}
@article{azuma67,
  title={Weighted sums of certain dependent random variables},
  author={Azuma, Kazuoki},
  journal={Tohoku Mathematical Journal, Second Series},
  volume={19},
  number={3},
  pages={357--367},
  year={1967},
  publisher={Mathematical Institute, Tohoku University}
}

@article{bertrand20,
  title={Dynamic network congestion games},
  author={Bertrand, Nathalie and Markey, Nicolas and Sadhukhan, Suman and Sankur, Ocan},
  journal={arXiv preprint arXiv:2009.13632},
  year={2020}
}

@article{mguni20,
  title={Stochastic potential games},
  author={Mguni, David},
  journal={arXiv preprint arXiv:2005.13527},
  year={2020}
}
@article{zazo16,
  title={Dynamic potential games with constraints: Fundamentals and applications in communications},
  author={Zazo, Santiago and Macua, Sergio Valcarcel and S{\'a}nchez-Fern{\'a}ndez, Matilde and Zazo, Javier},
  journal={IEEE Transactions on Signal Processing},
  volume={64},
  number={14},
  pages={3806--3821},
  year={2016},
  publisher={IEEE}
}

@article{daskalakis2021,
  title={Independent policy gradient methods for competitive reinforcement learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={arXiv preprint arXiv:2101.04233},
  year={2021}
}

@misc{song2021,
      title={When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?}, 
      author={Ziang Song and Song Mei and Yu Bai},
      year={2021},
      eprint={2110.04184},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{mguni2021learning,
  title={Learning in Nonzero-Sum Stochastic Games with Potentials},
  author={Mguni, David and Wu, Yutong and Du, Yali and Yang, Yaodong and Wang, Ziyi and Li, Minne and Wen, Ying and Jennings, Joel and Wang, Jun},
  journal={arXiv preprint arXiv:2103.09284},
  year={2021}
}

@article{zhang21,
  author    = {Runyu Zhang and
               Zhaolin Ren and
               Na Li},
  title     = {Gradient Play in Multi-Agent Markov Stochastic Games: stationary points, convergence, and sample complexity},
  journal   = {CoRR},
  volume    = {abs/2106.00198},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2106.00198},
  timestamp = {Wed, 09 Jun 2021 18:45:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-00198.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bai2020,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={551--560},
  year={2020},
  organization={PMLR}
  }
  
@article{absil2005,
  title={Convergence of the iterates of descent methods for analytic cost functions},
  author={Absil, Pierre-Antoine and Mahony, Robert and Andrews, Benjamin},
  journal={SIAM Journal on Optimization},
  volume={16},
  number={2},
  pages={531--547},
  year={2005},
  publisher={SIAM}
}

@article{Fox21,
  author    = {Roy Fox and
               Stephen McAleer and
               Will Overman and
               Ioannis Panageas},
  title     = {Independent Natural Policy Gradient Always Converges in Markov Potential
               Games},
  journal   = {CoRR},
  volume    = {abs/2110.10614},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2110.10614},
  timestamp = {Thu, 28 Oct 2021 15:25:31 +0200},
}

@article{Khodadadian2021,
  title={On the linear convergence of natural policy gradient algorithm},
  author={Khodadadian, Sajad and Jhunjhunwala, Prakirt Raj and Varma, Sushil Mahavir and Maguluri, Siva Theja},
  journal={arXiv preprint arXiv:2105.01424},
  year={2021}
}

@article{Mei2021,
  title={Understanding the Effect of Stochasticity in Policy Optimization},
  author={Mei, Jincheng and Dai, Bo and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{tao2001,
  title={A multi-agent, policy-gradient approach to network routing},
  author={Tao, Nigel and Baxter, Jonathan and Weaver, Lex},
  booktitle={In: Proc. of the 18th Int. Conf. on Machine Learning},
  year={2001},
  organization={Citeseer}
}

@article{claes2011,
  title={A decentralized approach for anticipatory vehicle routing using delegate multiagent systems},
  author={Claes, Rutger and Holvoet, Tom and Weyns, Danny},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={12},
  number={2},
  pages={364--373},
  year={2011},
  publisher={IEEE}
}

@book{ventre2013,
  title={Multicriteria and Multiagent Decision Making with Applications to Economics and Social Sciences},
  author={Ventre, Aldo GS and Maturo, Antonio and Ho{\v{s}}kov{\'a}-Mayerov{\'a}, {\v{S}}{\'a}rka and Kacprzyk, Janusz},
  volume={305},
  year={2013},
  publisher={Springer}
}

@inproceedings{roscia2013,
  title={Smart City by multi-agent systems},
  author={Roscia, Mariacristina and Longo, Michela and Lazaroiu, George Cristian},
  booktitle={2013 International Conference on Renewable Energy Research and Applications (ICRERA)},
  pages={371--376},
  year={2013},
  organization={IEEE}
}

@book{liu2018,
  title={Multiagent robotic systems},
  author={Liu, Jiming and Wu, Jianbing},
  year={2018},
  publisher={CRC press}
}

@article{inigo2012,
  title={Robotics software frameworks for multi-agent robotic systems development},
  author={I{\~n}igo-Blasco, Pablo and Diaz-del-Rio, Fernando and Romero-Ternero, Ma Carmen and Cagigas-Mu{\~n}iz, Daniel and Vicente-Diaz, Saturnino},
  journal={Robotics and Autonomous Systems},
  volume={60},
  number={6},
  pages={803--821},
  year={2012},
  publisher={Elsevier}
}

@article{Li2021softmax,
  author    = {Gen Li and
               Yuting Wei and
               Yuejie Chi and
               Yuantao Gu and
               Yuxin Chen},
  title     = {Softmax Policy Gradient Methods Can Take Exponential Time to Converge},
  journal   = {CoRR},
  volume    = {abs/2102.11270},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2102.11270},
  timestamp = {Wed, 24 Feb 2021 15:42:45 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-11270.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{cen2021,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  year={2021},
  publisher={INFORMS}
}

@inproceedings{haarnoja2017,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}

@incollection{rao1992information,
  title={Information and the accuracy attainable in the estimation of statistical parameters},
  author={Rao, C Radhakrishna},
  booktitle={Breakthroughs in statistics},
  pages={235--247},
  year={1992},
  publisher={Springer}
}

@book{amari2012differential,
  title={Differential-geometrical methods in statistics},
  author={Amari, Shun-ichi},
  volume={28},
  year={2012},
  publisher={Springer Science \& Business Media}
}