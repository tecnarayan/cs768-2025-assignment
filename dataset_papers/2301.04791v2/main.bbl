\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achlioptas et~al.(2018)Achlioptas, Diamanti, Mitliagkas, and
  Guibas]{achlioptas2018learning}
Achlioptas, P., Diamanti, O., Mitliagkas, I., and Guibas, L.
\newblock Learning representations and generative models for 3d point clouds.
\newblock In \emph{International conference on machine learning}, pp.\  40--49.
  PMLR, 2018.

\bibitem[Alvarez-Melis \& Fusi(2020)Alvarez-Melis and
  Fusi]{alvarez2020geometric}
Alvarez-Melis, D. and Fusi, N.
\newblock Geometric dataset distances via optimal transport.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21428--21439, 2020.

\bibitem[Amos(2022)]{amos2022tutorial}
Amos, B.
\newblock Tutorial on amortized optimization for learning to optimize over
  continuous domains.
\newblock \emph{arXiv preprint arXiv:2202.00665}, 2022.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock {W}asserstein generative adversarial networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  214--223, 2017.

\bibitem[Barrow et~al.(1977)Barrow, Tenenbaum, Bolles, and
  Wolf]{barrow1977parametric}
Barrow, H.~G., Tenenbaum, J.~M., Bolles, R.~C., and Wolf, H.~C.
\newblock Parametric correspondence and chamfer matching: Two new techniques
  for image matching.
\newblock Technical report, SRI INTERNATIONAL MENLO PARK CA ARTIFICIAL
  INTELLIGENCE CENTER, 1977.

\bibitem[Bhushan~Damodaran et~al.(2018)Bhushan~Damodaran, Kellenberger,
  Flamary, Tuia, and Courty]{bhushan2018deepjdot}
Bhushan~Damodaran, B., Kellenberger, B., Flamary, R., Tuia, D., and Courty, N.
\newblock Deepjdot: Deep joint distribution optimal transport for unsupervised
  domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  447--463, 2018.

\bibitem[Bonneel et~al.(2015)Bonneel, Rabin, Peyr{\'e}, and
  Pfister]{bonneel2015sliced}
Bonneel, N., Rabin, J., Peyr{\'e}, G., and Pfister, H.
\newblock Sliced and {R}adon {W}asserstein barycenters of measures.
\newblock \emph{Journal of Mathematical Imaging and Vision}, 1\penalty0
  (51):\penalty0 22--45, 2015.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020end}
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko,
  S.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European conference on computer vision}, pp.\  213--229.
  Springer, 2020.

\bibitem[Chang et~al.(2015)Chang, Funkhouser, Guibas, Hanrahan, Huang, Li,
  Savarese, Savva, Song, Su, Xiao, Yi, and Yu]{shapenet2015}
Chang, A.~X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z.,
  Savarese, S., Savva, M., Song, S., Su, H., Xiao, J., Yi, L., and Yu, F.
\newblock {ShapeNet: {A}n Information-Rich 3D Model Repository}.
\newblock Technical Report arXiv:1512.03012 [cs.GR], Stanford University ---
  Princeton University --- Toyota Technological Institute at Chicago, 2015.

\bibitem[Christensen(2002)]{christensen2002plane}
Christensen, R.
\newblock \emph{Plane answers to complex questions}, volume~35.
\newblock Springer, 2002.

\bibitem[Courty et~al.(2016)Courty, Flamary, Tuia, and
  Rakotomamonjy]{courty2016optimal}
Courty, N., Flamary, R., Tuia, D., and Rakotomamonjy, A.
\newblock Optimal transport for domain adaptation.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 39\penalty0 (9):\penalty0 1853--1865, 2016.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Cuturi, M.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2292--2300, 2013.

\bibitem[Damodaran et~al.(2018)Damodaran, Kellenberger, Flamary, Tuia, and
  Courty]{damodaran2018deepjdot}
Damodaran, B.~B., Kellenberger, B., Flamary, R., Tuia, D., and Courty, N.
\newblock Deepjdot: Deep joint distribution optimal transport for unsupervised
  domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  447--463, 2018.

\bibitem[Davidson et~al.(2018{\natexlab{a}})Davidson, Falorsi, De~Cao, Kipf,
  and Tomczak]{davidson2018hyperspherical}
Davidson, T.~R., Falorsi, L., De~Cao, N., Kipf, T., and Tomczak, J.~M.
\newblock Hyperspherical variational auto-encoders.
\newblock In \emph{34th Conference on Uncertainty in Artificial Intelligence
  2018, UAI 2018}, pp.\  856--865. Association For Uncertainty in Artificial
  Intelligence (AUAI), 2018{\natexlab{a}}.

\bibitem[Davidson et~al.(2018{\natexlab{b}})Davidson, Falorsi, De~Cao, and
  Tomczak]{davidsonhyperspherical}
Davidson, T.~R., Falorsi, L., De~Cao, N., and Tomczak, T. K. J.~M.
\newblock Hyperspherical variational auto-encoders.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  2018{\natexlab{b}}.

\bibitem[Deshpande et~al.(2018)Deshpande, Zhang, and
  Schwing]{deshpande2018generative}
Deshpande, I., Zhang, Z., and Schwing, A.~G.
\newblock Generative modeling using the sliced {W}asserstein distance.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3483--3491, 2018.

\bibitem[Deshpande et~al.(2019)Deshpande, Hu, Sun, Pyrros, Siddiqui, Koyejo,
  Zhao, Forsyth, and Schwing]{deshpande2019max}
Deshpande, I., Hu, Y.-T., Sun, R., Pyrros, A., Siddiqui, N., Koyejo, S., Zhao,
  Z., Forsyth, D., and Schwing, A.~G.
\newblock Max-sliced {W}asserstein distance and its use for {GAN}s.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  10648--10656, 2019.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://aclanthology.org/N19-1423}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Dwivedi \& Bresson(2021)Dwivedi and
  Bresson]{dwivedi2021generalization}
Dwivedi, V.~P. and Bresson, X.
\newblock A generalization of transformer networks to graphs.
\newblock \emph{AAAI Workshop on Deep Learning on Graphs: Methods and
  Applications}, 2021.

\bibitem[Genevay et~al.(2018)Genevay, Peyr{\'e}, and
  Cuturi]{genevay2018learning}
Genevay, A., Peyr{\'e}, G., and Cuturi, M.
\newblock Learning generative models with {S}inkhorn divergences.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  1608--1617. PMLR, 2018.

\bibitem[Guo et~al.(2021)Guo, Cai, Liu, Mu, Martin, and Hu]{guo2021pct}
Guo, M.-H., Cai, J.-X., Liu, Z.-N., Mu, T.-J., Martin, R.~R., and Hu, S.-M.
\newblock Pct: Point cloud transformer.
\newblock \emph{Computational Visual Media}, 7\penalty0 (2):\penalty0
  187â€“199, Apr 2021.
\newblock ISSN 2096-0662.
\newblock \doi{10.1007/s41095-021-0229-5}.
\newblock URL \url{http://dx.doi.org/10.1007/s41095-021-0229-5}.

\bibitem[Ho et~al.(2017)Ho, Nguyen, Yurochkin, Bui, Huynh, and
  Phung]{ho2017multilevel}
Ho, N., Nguyen, X., Yurochkin, M., Bui, H.~H., Huynh, V., and Phung, D.
\newblock Multilevel clustering via {W}asserstein means.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1501--1509, 2017.

\bibitem[Huynh et~al.(2020)Huynh, Zhao, and Phung]{huynh2020otlda}
Huynh, V., Zhao, H., and Phung, D.
\newblock Otlda: A geometry-aware optimal transport approach for topic
  modeling.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 18573--18582, 2020.

\bibitem[Jupp \& Mardia(1979)Jupp and Mardia]{jupp1979maximum}
Jupp, P.~E. and Mardia, K.~V.
\newblock Maximum likelihood estimators for the matrix von {M}ises-{F}isher and
  bingham distributions.
\newblock \emph{The Annals of Statistics}, 7\penalty0 (3):\penalty0 599--606,
  1979.

\bibitem[Katharopoulos et~al.(2020)Katharopoulos, Vyas, Pappas, and
  Fleuret]{katharopoulos2020transformers}
Katharopoulos, A., Vyas, A., Pappas, N., and Fleuret, F.
\newblock Transformers are rnns: Fast autoregressive transformers with linear
  attention.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5156--5165. PMLR, 2020.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kolouri et~al.(2018)Kolouri, Pope, Martin, and
  Rohde]{kolouri2018sliced}
Kolouri, S., Pope, P.~E., Martin, C.~E., and Rohde, G.~K.
\newblock Sliced {W}asserstein auto-encoders.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Lee et~al.(2019{\natexlab{a}})Lee, Batra, Baig, and
  Ulbricht]{lee2019sliced}
Lee, C.-Y., Batra, T., Baig, M.~H., and Ulbricht, D.
\newblock Sliced {W}asserstein discrepancy for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10285--10295, 2019{\natexlab{a}}.

\bibitem[Lee et~al.(2019{\natexlab{b}})Lee, Lee, Kim, Kosiorek, Choi, and
  Teh]{lee2019set}
Lee, J., Lee, Y., Kim, J., Kosiorek, A., Choi, S., and Teh, Y.~W.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In \emph{International conference on machine learning}, pp.\
  3744--3753. PMLR, 2019{\natexlab{b}}.

\bibitem[Lee et~al.(2022)Lee, Kim, Choi, and Park]{lee2022statistical}
Lee, Y., Kim, S., Choi, J., and Park, F.
\newblock A statistical manifold framework for point cloud data.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  12378--12402. PMLR, 2022.

\bibitem[Li et~al.(2020)Li, Su, Duan, and Zheng]{li2020linear}
Li, R., Su, J., Duan, C., and Zheng, S.
\newblock Linear attention mechanism: An efficient attention for semantic
  segmentation.
\newblock \emph{arXiv preprint arXiv:2007.14902}, 2020.

\bibitem[Li et~al.(2019)Li, Raj, Lu, Shen, Kawahara, and
  Kawai]{li2019improving}
Li, S., Raj, D., Lu, X., Shen, P., Kawahara, T., and Kawai, H.
\newblock {Improving Transformer-Based Speech Recognition Systems with
  Compressed Structure and Speech Attributes Augmentation}.
\newblock In \emph{Proc. Interspeech 2019}, pp.\  4400--4404, 2019.
\newblock \doi{10.21437/Interspeech.2019-2112}.
\newblock URL \url{http://dx.doi.org/10.21437/Interspeech.2019-2112}.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Naderializadeh et~al.(2021)Naderializadeh, Comer, Andrews, Hoffmann,
  and Kolouri]{naderializadeh2021pooling}
Naderializadeh, N., Comer, J., Andrews, R., Hoffmann, H., and Kolouri, S.
\newblock Pooling by sliced-{W}asserstein embedding.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Nadjahi et~al.(2020)Nadjahi, De~Bortoli, Durmus, Badeau, and
  {\c{S}}im{\c{s}}ekli]{nadjahi2020approximate}
Nadjahi, K., De~Bortoli, V., Durmus, A., Badeau, R., and {\c{S}}im{\c{s}}ekli,
  U.
\newblock Approximate {B}ayesian computation with the sliced-{W}asserstein
  distance.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  5470--5474. IEEE, 2020.

\bibitem[Nguyen \& Ho(2022{\natexlab{a}})Nguyen and Ho]{nguyen2022amortized}
Nguyen, K. and Ho, N.
\newblock Amortized projection optimization for sliced {W}asserstein generative
  models.
\newblock \emph{Advances in Neural Information Processing Systems},
  2022{\natexlab{a}}.

\bibitem[Nguyen \& Ho(2022{\natexlab{b}})Nguyen and Ho]{nguyen2022revisiting}
Nguyen, K. and Ho, N.
\newblock Revisiting sliced {W}asserstein on images: From vectorization to
  convolution.
\newblock \emph{Advances in Neural Information Processing Systems},
  2022{\natexlab{b}}.

\bibitem[Nguyen et~al.(2021{\natexlab{a}})Nguyen, Ho, Pham, and
  Bui]{nguyen2021distributional}
Nguyen, K., Ho, N., Pham, T., and Bui, H.
\newblock Distributional sliced-{W}asserstein and applications to generative
  modeling.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Nguyen et~al.(2021{\natexlab{b}})Nguyen, Nguyen, Ho, Pham, and
  Bui]{nguyen2021improving}
Nguyen, K., Nguyen, S., Ho, N., Pham, T., and Bui, H.
\newblock Improving relational regularized autoencoders with spherical sliced
  fused {G}romov {W}asserstein.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.

\bibitem[Nguyen et~al.(2023)Nguyen, Ren, Nguyen, Rout, Nguyen, and
  Ho]{nguyen2023hierarchical}
Nguyen, K., Ren, T., Nguyen, H., Rout, L., Nguyen, T.~M., and Ho, N.
\newblock Hierarchical sliced wasserstein distance.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Nguyen et~al.(2021{\natexlab{c}})Nguyen, Pham, Le, Pham, Ho, and
  Hua]{Nguyen2021PointSetDistances}
Nguyen, T., Pham, Q.-H., Le, T., Pham, T., Ho, N., and Hua, B.-S.
\newblock Point-set distances for learning representations of 3d point clouds.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2021{\natexlab{c}}.

\bibitem[Nietert et~al.(2022)Nietert, Sadhu, Goldfeld, and
  Kato]{nietert2022statistical}
Nietert, S., Sadhu, R., Goldfeld, Z., and Kato, K.
\newblock Statistical, robustness, and computational guarantees for sliced
  wasserstein distances.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Peyr{\'e} \& Cuturi(2019)Peyr{\'e} and Cuturi]{peyre2019computational}
Peyr{\'e}, G. and Cuturi, M.
\newblock Computational optimal transport: With applications to data science.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  11\penalty0 (5-6):\penalty0 355--607, 2019.

\bibitem[Pham et~al.(2020)Pham, Uy, Hua, Nguyen, Roig, and Yeung]{pham2020lcd}
Pham, Q.-H., Uy, M.~A., Hua, B.-S., Nguyen, D.~T., Roig, G., and Yeung, S.-K.
\newblock {LCD}: {L}earned cross-domain descriptors for 2{D}-3{D} matching.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2020.

\bibitem[Qi et~al.(2017)Qi, Su, Mo, and Guibas]{qi2017pointnet}
Qi, C.~R., Su, H., Mo, K., and Guibas, L.~J.
\newblock Pointnet: {D}eep learning on point sets for 3d classification and
  segmentation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  652--660, 2017.

\bibitem[Shen et~al.(2021)Shen, Zhang, Zhao, Yi, and Li]{shen2021efficient}
Shen, Z., Zhang, M., Zhao, H., Yi, S., and Li, H.
\newblock Efficient attention: {A}ttention with linear complexities.
\newblock In \emph{Proceedings of the IEEE/CVF winter conference on
  applications of computer vision}, pp.\  3531--3539, 2021.

\bibitem[Shu(2017)]{ruishu2017}
Shu, R.
\newblock Amortized optimization
  \url{http://ruishu.io/2017/11/07/amortized-optimization/}.
\newblock \emph{Personal Blog}, 2017.

\bibitem[Sra(2016)]{Suvrit_directional}
Sra, S.
\newblock Directional statistics in machine learning: a brief review.
\newblock \emph{arXiv preprint arXiv:1605.00316}, 2016.

\bibitem[Sun et~al.(2019)Sun, Myers, Vondrick, Murphy, and
  Schmid]{sun2019videobert}
Sun, C., Myers, A., Vondrick, C., Murphy, K., and Schmid, C.
\newblock Videobert: A joint model for video and language representation
  learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  7464--7473, 2019.

\bibitem[Temme(2011)]{temme2011special}
Temme, N.~M.
\newblock \emph{Special functions: An introduction to the classical functions
  of mathematical physics}.
\newblock John Wiley \& Sons, 2011.

\bibitem[Tolstikhin et~al.(2018)Tolstikhin, Bousquet, Gelly, and
  Schoelkopf]{tolstikhin2018wasserstein}
Tolstikhin, I., Bousquet, O., Gelly, S., and Schoelkopf, B.
\newblock {W}asserstein auto-encoders.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Villani(2008)]{villani2008optimal}
Villani, C.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Vincent-Cuaz et~al.(2022)Vincent-Cuaz, Flamary, Corneli, Vayer, and
  Courty]{vincent2022template}
Vincent-Cuaz, C., Flamary, R., Corneli, M., Vayer, T., and Courty, N.
\newblock Template based graph neural network with optimal transport distances.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Li, Khabsa, Fang, and
  Ma]{wang2020linformer}
Wang, S., Li, B.~Z., Khabsa, M., Fang, H., and Ma, H.
\newblock Linformer: Self-attention with linear complexity.
\newblock \emph{arXiv preprint arXiv:2006.04768}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Mohamed, Le, Liu, Xiao,
  Mahadeokar, Huang, Tjandra, Zhang, Zhang, et~al.]{wang2020transformer}
Wang, Y., Mohamed, A., Le, D., Liu, C., Xiao, A., Mahadeokar, J., Huang, H.,
  Tjandra, A., Zhang, X., Zhang, F., et~al.
\newblock Transformer-based acoustic modeling for hybrid speech recognition.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  6874--6878. IEEE,
  2020{\natexlab{b}}.

\bibitem[Wu et~al.(2015)Wu, Song, Khosla, Yu, Zhang, Tang, and Xiao]{wu20153d}
Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., and Xiao, J.
\newblock 3d shapenets: {A} deep representation for volumetric shapes.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1912--1920, 2015.

\bibitem[Yang et~al.(2019{\natexlab{a}})Yang, Huang, Hao, Liu, Belongie, and
  Hariharan]{yang2019pointflow}
Yang, G., Huang, X., Hao, Z., Liu, M.-Y., Belongie, S., and Hariharan, B.
\newblock Pointflow: 3d point cloud generation with continuous normalizing
  flows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  4541--4550, 2019{\natexlab{a}}.

\bibitem[Yang et~al.(2019{\natexlab{b}})Yang, Zhang, Ni, Li, Liu, Zhou, and
  Tian]{yang2019modeling}
Yang, J., Zhang, Q., Ni, B., Li, L., Liu, J., Zhou, M., and Tian, Q.
\newblock Modeling point clouds with self-attention and gumbel subset sampling.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  3323--3332, 2019{\natexlab{b}}.

\bibitem[Yi \& Liu(2021)Yi and Liu]{yi2021sliced}
Yi, M. and Liu, S.
\newblock Sliced {W}asserstein variational inference.
\newblock In \emph{Fourth Symposium on Advances in Approximate Bayesian
  Inference}, 2021.

\bibitem[Zhao et~al.(2021)Zhao, Jiang, Jia, Torr, and Koltun]{zhao2021point}
Zhao, H., Jiang, L., Jia, J., Torr, P.~H., and Koltun, V.
\newblock Point transformer.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  16259--16268, 2021.

\end{thebibliography}
