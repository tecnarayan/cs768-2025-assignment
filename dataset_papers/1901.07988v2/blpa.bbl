\begin{thebibliography}{10}

\bibitem{banner2018}
Ron Banner, Itay Hubara, Elad Hoffer, and Daniel Soudry.
\newblock Scalable methods for 8-bit training of neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{ChenXZG16}
Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin.
\newblock Training deep nets with sublinear memory cost.
\newblock {\em arXiv preprint arXiv:1604.06174}, 2016.

\bibitem{dist2}
Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao,
  Andrew Senior, Paul Tucker, Ke~Yang, Quoc~V Le, et~al.
\newblock Large scale distributed deep networks.
\newblock In {\em Advances in Neural Information Processing Systems}, 2012.

\bibitem{GomezRUG17}
Aidan~N. Gomez, Mengye Ren, Raquel Urtasun, and Roger~B. Grosse.
\newblock The reversible residual network: Backpropagation without storing
  activations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2211--2221, 2017.

\bibitem{GruslysMDLG16}
Audrunas Gruslys, R{\'{e}}mi Munos, Ivo Danihelka, Marc Lanctot, and Alex
  Graves.
\newblock Memory-efficient backpropagation through time.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4125--4133, 2016.

\bibitem{gupta2015deep}
Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan.
\newblock Deep learning with limited numerical precision.
\newblock In {\em Proc.~International Conference on Machine Learning (ICML)},
  pages 1737--1746, 2015.

\bibitem{han2015deep}
Song Han, Huizi Mao, and William~J Dally.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock {\em arXiv preprint arXiv:1510.00149}, 2015.

\bibitem{HeZRS16}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proc.~ {IEEE} {C}onference on {C}omputer {V}ision and
  {P}attern {R}ecognition ({CVPR}),}, pages 770--778, 2016.

\bibitem{res1}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In {\em Proc.~the European Conference on Computer Vision (ECCV)},
  2016.

\bibitem{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In {\em Proc.~ {IEEE} {C}onference on {C}omputer {V}ision and
  {P}attern {R}ecognition ({CVPR}),}, 2017.

\bibitem{hubarai}
Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
  Bengio.
\newblock Quantized neural networks: Training neural networks with low
  precision weights and activations.
\newblock {\em Journal of Machine Learning Research (JMLR)}, 2017.

\bibitem{IoffeS15}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em Proc.~ International Conference on Machine Learning (ICML),},
  pages 448--456, 2015.

\bibitem{cifar}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, 2009.

\bibitem{MartensS12}
James Martens and Ilya Sutskever.
\newblock Training deep and recurrent networks with hessian-free optimization.
\newblock In {\em Neural Networks: Tricks of the Trade - Second Edition}, pages
  479--535. 2012.

\bibitem{micikevicius2017mixed}
Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen,
  David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaev, Ganesh
  Venkatesh, et~al.
\newblock Mixed precision training.
\newblock {\em arXiv preprint arXiv:1710.03740}, 2017.

\bibitem{dist1}
Benjamin Recht, Christopher Re, Stephen Wright, and Feng Niu.
\newblock Hogwild: A lock-free approach to parallelizing stochastic gradient
  descent.
\newblock In {\em Advances in neural information processing systems}, 2011.

\bibitem{sgd}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock In {\em Herbert Robbins Selected Papers}, pages 102--109. Springer,
  1985.

\bibitem{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International Journal of Computer Vision ({IJCV})}, 115(3),
  2015.

\bibitem{gradq1}
Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu.
\newblock 1-bit {S}tochastic {G}radient {D}escent and its {A}pplication to
  {D}ata-parallel {D}istributed {T}raining of {S}peech {DNN}s.
\newblock In {\em Proc.~Interspeech}, 2014.

\bibitem{gradq2}
Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li.
\newblock Terngrad: Ternary gradients to reduce communication in distributed
  deep learning.
\newblock In {\em Advances in neural information processing systems}, 2017.

\end{thebibliography}
