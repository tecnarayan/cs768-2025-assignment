@article{mitrovic2020representation,
  title={Representation Learning via Invariant Causal Mechanisms},
  author={Mitrovic, Jovana and McWilliams, Brian and Walker, Jacob and Buesing, Lars and Blundell, Charles},
  journal={arXiv preprint arXiv:2010.07922},
  year={2020}
}

@article{purushwalkam2020demystifying,
  title={Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases},
  author={Purushwalkam, Senthil and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2007.13916},
  year={2020}
}

@article{raileanu2020automatic,
  title={Automatic data augmentation for generalization in deep reinforcement learning},
  author={Raileanu, Roberta and Goldstein, Max and Yarats, Denis and Kostrikov, Ilya and Fergus, Rob},
  journal={arXiv preprint arXiv:2006.12862},
  year={2020}
}

@article{saran2020efficiently,
  title={Efficiently Guiding Imitation Learning Algorithms with Human Gaze},
  author={Saran, Akanksha and Zhang, Ruohan and Short, Elaine Schaertl and Niekum, Scott},
  journal={arXiv preprint arXiv:2002.12500},
  year={2020}
}

@inproceedings{laskin2020reinforcement,
	title="Reinforcement Learning with Augmented Data",
	author="Michael {Laskin} and Kimin {Lee} and Adam {Stooke} and Lerrel {Pinto} and Pieter {Abbeel} and Aravind {Srinivas}",
	booktitle="Advances in Neural Information Processing Systems",
	volume="33",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3098053103",
	year="2020"
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{chen2019active,
  title={Active deep Q-learning with demonstration},
  author={Chen, Si-An and Tangkaratt, Voot and Lin, Hsuan-Tien and Sugiyama, Masashi},
  journal={Machine Learning},
  pages={1--27},
  year={2019},
  publisher={Springer}
}


@inproceedings{teso2019explanatory,
  title={Explanatory interactive machine learning},
  author={Teso, Stefano and Kersting, Kristian},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={239--245},
  year={2019}
}


@article{schramowski2020making,
  title={Making deep neural networks right for the right scientific reasons by interacting with their explanations},
  author={Schramowski, Patrick and Stammer, Wolfgang and Teso, Stefano and Brugger, Anna and Herbert, Franziska and Shao, Xiaoting and Luigs, Hans-Georg and Mahlein, Anne-Katrin and Kersting, Kristian},
  journal={Nature Machine Intelligence},
  volume={2},
  number={8},
  pages={476--486},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{gupta2019explain,
  title={Explain Your Move: Understanding Agent Actions Using Focused Feature Saliency},
  author={Gupta, Piyush and Puri, Nikaash and Verma, Sukriti and Singh, Sameer and Kayastha, Dhruv and Deshmukh, Shripad and Krishnamurthy, Balaji},
  journal={arXiv preprint arXiv:1912.12191},
  year={2019}
}

@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}

@article{davidson2020investigating,
  title={Investigating Simple Object Representations in Model-Free Deep Reinforcement Learning},
  author={Davidson, Guy and Lake, Brenden M},
  journal={arXiv preprint arXiv:2002.06703},
  year={2020}
}
@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{arakawa2018dqn,
  title={DQN-TAMER: Human-in-the-loop reinforcement learning with intractable feedback},
  author={Arakawa, Riku and Kobayashi, Sosuke and Unno, Yuya and Tsuboi, Yuta and Maeda, Shin-ichi},
  journal={arXiv preprint arXiv:1810.11748},
  year={2018}
}

@inproceedings{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in Atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  booktitle={Advances in neural information processing systems},
  pages={8011--8023},
  year={2018}
}

@inproceedings{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4299--4307},
  year={2017}
}

@article{krening2016learning,
  title={Learning from explanations using sentiment and advice in RL},
  author={Krening, Samantha and Harrison, Brent and Feigh, Karen M and Isbell, Charles Lee and Riedl, Mark and Thomaz, Andrea},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  volume={9},
  number={1},
  pages={44--55},
  year={2016},
  publisher={IEEE}
}

@inproceedings{schaul2016prioritized,
	title="Prioritized Experience Replay",
	author="Tom {Schaul} and John {Quan} and Ioannis {Antonoglou} and David {Silver}",
	booktitle="ICLR 2016 : International Conference on Learning Representations 2016 ",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2963477884",
	year="2016"
}

@inproceedings{griffith2013policy,
  title={Policy shaping: Integrating human feedback with reinforcement learning},
  author={Griffith, Shane and Subramanian, Kaushik and Scholz, Jonathan and Isbell, Charles L and Thomaz, Andrea L},
  booktitle={Advances in neural information processing systems},
  pages={2625--2633},
  year={2013}
}

@inproceedings{such2019an,
	title="An Atari Model Zoo for Analyzing, Visualizing, and Comparing Deep Reinforcement Learning Agents.",
	author="Felipe Petroski {Such} and Vashisht {Madhavan} and Rosanne {Liu} and Rui {Wang} and Pablo Samuel {Castro} and Yulun {Li} and Jiale {Zhi} and Ludwig {Schubert} and Marc G. {Bellemare} and Jeff {Clune} and Joel {Lehman}",
	booktitle="Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence",
	pages="3260--3267",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2965822359",
	year="2019"
}



@article{littman2017environment,
  title={Environment-independent task specifications via GLTL},
  author={Littman, Michael L and Topcu, Ufuk and Fu, Jie and Isbell, Charles and Wen, Min and MacGlashan, James},
  journal={arXiv preprint arXiv:1704.04341},
  year={2017}
}

@inproceedings{loftin2014learning,
  title={Learning something from nothing: Leveraging implicit human feedback strategies},
  author={Loftin, Robert and Peng, Bei and MacGlashan, James and Littman, Michael L and Taylor, Matthew E and Huang, Jeff and Roberts, David L},
  booktitle={The 23rd IEEE International Symposium on Robot and Human Interactive Communication},
  pages={607--612},
  year={2014},
  organization={IEEE}
}

@article{loftin2016learning,
  title={Learning behaviors via human-delivered discrete feedback: modeling implicit feedback strategies to speed up learning},
  author={Loftin, Robert and Peng, Bei and MacGlashan, James and Littman, Michael L and Taylor, Matthew E and Huang, Jeff and Roberts, David L},
  journal={Autonomous agents and multi-agent systems},
  volume={30},
  number={1},
  pages={30--59},
  year={2016},
  publisher={Springer}
}

@inproceedings{cederborg2015policy,
  title={Policy shaping with human teachers},
  author={Cederborg, Thomas and Grover, Ishaan and Isbell, Charles L and Thomaz, Andrea L},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}

@inproceedings{knox2009interactively,
  title={Interactively shaping agents via human reinforcement: The TAMER framework},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={Proceedings of the fifth international conference on Knowledge capture},
  pages={9--16},
  year={2009}
}

@inproceedings{warnell2018deep,
  title={Deep tamer: Interactive agent shaping in high-dimensional state spaces},
  author={Warnell, Garrett and Waytowich, Nicholas and Lawhern, Vernon and Stone, Peter},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{macglashan2017interactive,
  title={Interactive learning from policy-dependent human feedback},
  author={MacGlashan, James and Ho, Mark K and Loftin, Robert and Peng, Bei and Wang, Guan and Roberts, David L and Taylor, Matthew E and Littman, Michael L},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2285--2294},
  year={2017},
  organization={JMLR. org}
}

@article{arumugam2019deep,
  title={Deep reinforcement learning from policy-dependent human feedback},
  author={Arumugam, Dilip and Lee, Jun Ki and Saskin, Sophie and Littman, Michael L},
  journal={arXiv preprint arXiv:1902.04257},
  year={2019}
}

@inproceedings{knox2010combining,
  title={Combining manual feedback with subsequent MDP reward signals for reinforcement learning},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1-Volume 1},
  pages={5--12},
  year={2010},
  organization={Citeseer}
}

@inproceedings{knox2012reinforcement,
  title={Reinforcement learning from simultaneous human and MDP reward.},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={AAMAS},
  pages={475--482},
  year={2012}
}

@inproceedings{peng2016need,
  title={A need for speed: Adapting agent action speed to improve task learning from non-expert humans},
  author={Peng, Bei and MacGlashan, James and Loftin, Robert and Littman, Michael L and Roberts, David L and Taylor, Matthew E},
  booktitle={Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems},
  year={2016}
}

@inproceedings{thomaz2006reinforcement,
  title={Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance},
  author={Thomaz, Andrea Lockerd and Breazeal, Cynthia and others},
  booktitle={Aaai},
  volume={6},
  pages={1000--1005},
  year={2006},
  organization={Boston, MA}
}

@inproceedings{tenorio2010dynamic,
  title={Dynamic reward shaping: training a robot by voice},
  author={Tenorio-Gonzalez, Ana C and Morales, Eduardo F and Villase{\~n}or-Pineda, Luis},
  booktitle={Ibero-American conference on artificial intelligence},
  pages={483--492},
  year={2010},
  organization={Springer}
}


@article{greydanus2017visualizing,
  title={Visualizing and understanding atari agents},
  author={Greydanus, Sam and Koul, Anurag and Dodge, Jonathan and Fern, Alan},
  journal={arXiv preprint arXiv:1711.00138},
  year={2017}
}

@inproceedings{wilson2012bayesian,
  title={A bayesian approach for policy learning from trajectory preference queries},
  author={Wilson, Aaron and Fern, Alan and Tadepalli, Prasad},
  booktitle={Advances in neural information processing systems},
  pages={1133--1141},
  year={2012}
}

@article{furnkranz2012preference,
  title={Preference-based reinforcement learning: a formal framework and a policy iteration algorithm},
  author={F{\"u}rnkranz, Johannes and H{\"u}llermeier, Eyke and Cheng, Weiwei and Park, Sang-Hyeun},
  journal={Machine learning},
  volume={89},
  number={1-2},
  pages={123--156},
  year={2012},
  publisher={Springer}
}

@inproceedings{ijcai2019-884,
  title     = {Leveraging Human Guidance for Deep Reinforcement Learning Tasks},
  author    = {Zhang, Ruohan and Torabi, Faraz and Guan, Lin and Ballard, Dana H. and Stone, Peter},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {6339--6346},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcaai.2019/884},
}

@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4945--4990},
  year={2017},
  publisher={JMLR. org}
}

@incollection{NIPS2016_6391,
title = {Generative Adversarial Imitation Learning},
author = {Ho, Jonathan and Ermon, Stefano},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {4565--4573},
year = {2016},
publisher = {Curran Associates, Inc.},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{schaal1997learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  booktitle={Advances in neural information processing systems},
  pages={1040--1046},
  year={1997}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{xiao2020fresh,
  title={FRESH: Interactive Reward Shaping in High-Dimensional State Spaces using Human Feedback},
  author={Xiao, Baicen and Lu, Qifan and Ramasubramanian, Bhaskar and Clark, Andrew and Bushnell, Linda and Poovendran, Radha},
  journal={arXiv preprint arXiv:2001.06781},
  year={2020}
}

@article{yeh2018bridging,
  title={Bridging the gap: Converting human advice into imagined examples},
  author={Yeh, Eric and Gervasio, Melinda and Sanchez, Daniel and Crossley, Matthew and Myers, Karen},
  journal={Advances in Cognitive Systems},
  volume={6},
  pages={1168--1176},
  year={2018}
}
@inproceedings{puri2019explain,
  title={Explain Your Move: Understanding Agent Actions Using Specific and Relevant Feature Attribution},
  author={Puri, Nikaash and Verma, Sukriti and Gupta, Piyush and Kayastha, Dhruv and Deshmukh, Shripad and Krishnamurthy, Balaji and Singh, Sameer},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{sorokin2015deep,
  title={Deep attention recurrent Q-network},
  author={Sorokin, Ivan and Seleznev, Alexey and Pavlov, Mikhail and Fedorov, Aleksandr and Ignateva, Anastasiia},
  journal={arXiv preprint arXiv:1512.01693},
  year={2015}
}

@inproceedings{mott2019towards,
  title={Towards interpretable reinforcement learning using attention augmented agents},
  author={Mott, Alexander and Zoran, Daniel and Chrzanowski, Mike and Wierstra, Daan and Rezende, Danilo Jimenez},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12329--12338},
  year={2019}
}

@article{wang2015dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}

@inproceedings{zahavy2016graying,
  title={Graying the black box: Understanding dqns},
  author={Zahavy, Tom and Ben-Zrihem, Nir and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={1899--1908},
  year={2016}
}

@article{stangor2018introduction,
  title={Introduction to Psychology-1st Canadian Edition},
  author={Stangor, Charles and Walinga, Jennifer and others},
  year={2018}
}

@inproceedings{zhang2018agil,
  title={Agil: Learning attention from human for visuomotor tasks},
  author={Zhang, Ruohan and Liu, Zhuode and Zhang, Luxin and Whritner, Jake A and Muller, Karl S and Hayhoe, Mary M and Ballard, Dana H},
  booktitle={Proceedings of the european conference on computer vision (eccv)},
  pages={663--679},
  year={2018}
}

@article{zhang2019atari,
  title={Atari-head: Atari human eye-tracking and demonstration dataset},
  author={Zhang, Ruohan and Walshe, Calen and Liu, Zhuode and Guan, Lin and Muller, Karl S and Whritner, Jake A and Zhang, Luxin and Hayhoe, Mary M and Ballard, Dana H},
  journal={arXiv preprint arXiv:1903.06754},
  year={2019}
}

@article{kim2020using,
  title={Using human gaze to improve robustness against irrelevant objects in robot manipulation tasks},
  author={Kim, Heecheol and Ohmura, Yoshiyuki and Kuniyoshi, Yasuo},
  journal={IEEE Robotics and Automation Letters},
  year={2020},
  publisher={IEEE}
}

@inproceedings{piot2014boosted,
  title={Boosted bellman residual minimization handling expert demonstrations},
  author={Piot, Bilal and Geist, Matthieu and Pietquin, Olivier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={549--564},
  year={2014},
  organization={Springer}
}

@article{yang2018learn,
  title={Learn to interpret atari agents},
  author={Yang, Zhao and Bai, Song and Zhang, Li and Torr, Philip HS},
  journal={arXiv preprint arXiv:1812.11276},
  year={2018}
}

@article{nikulin2019free,
  title={Free-lunch saliency via attention in atari agents},
  author={Nikulin, Dmitry and Ianina, Anastasia and Aliev, Vladimir and Nikolenko, Sergey},
  journal={arXiv preprint arXiv:1908.02511},
  year={2019}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}


@inproceedings{lukezic2017discriminative,
  title={Discriminative correlation filter with channel and spatial reliability},
  author={Lukezic, Alan and Vojir, Tomas and Cehovin Zajc, Luka and Matas, Jiri and Kristan, Matej},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6309--6318},
  year={2017}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@inproceedings{zhang2020human,
  title={Human Gaze Assisted Artificial Intelligence: A Review},
  author={Zhang, R and Saran, A and Liu, B and Zhu, Y and Guo, S and Niekum, S and Ballard, D and Hayhoe, M},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2020}
}

@article{shorten2019survey,
  title={A survey on image data augmentation for deep learning},
  author={Shorten, Connor and Khoshgoftaar, Taghi M},
  journal={Journal of Big Data},
  volume={6},
  number={1},
  pages={60},
  year={2019},
  publisher={Springer}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{ross2017right,
  title={Right for the right reasons: Training differentiable models by constraining their explanations},
  author={Ross, Andrew Slavin and Hughes, Michael C and Doshi-Velez, Finale},
  journal={arXiv preprint arXiv:1703.03717},
  year={2017}
}

@inproceedings{rieger2020interpretations,
  title={Interpretations are useful: penalizing explanations to align neural networks with prior knowledge},
  author={Rieger, Laura and Singh, Chandan and Murdoch, William and Yu, Bin},
  booktitle={International Conference on Machine Learning},
  pages={8116--8126},
  year={2020},
  organization={PMLR}
}

@inproceedings{bobu2021feature,
  title={Feature Expansive Reward Learning: Rethinking Human Input},
  author={Bobu, Andreea and Wiggert, Marius and Tomlin, Claire and Dragan, Anca D},
  booktitle={Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={216--224},
  year={2021}
}

@inproceedings{lee2021pebble,
	title="PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training",
	author="Kimin {Lee} and Laura {Smith} and Pieter {Abbeel}",
	booktitle="ICML 2021: 38th International Conference on Machine Learning",
	pages="6152--6163",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3171136997",
	year="2021"
}

@inproceedings{cui2020empathic,
  title={The EMPATHIC Framework for Task Learning from Implicit Human Feedback},
  author={Cui, Yuchen and Zhang, Qiping and Allievi, Alessandro and Stone, Peter and Niekum, Scott and Knox, W Bradley},
  booktitle={Conference on Robot Learning},
  year={2020},
  organization={PMLR}
}

@inproceedings{kambhampati2022symbols,
  title={Symbols as a Lingua Franca for Bridging Human-AI Chasm for Explainable and Advisable AI Systems},
  author={Kambhampati, Subbarao and Sreedharan, Sarath and Verma, Mudit and Zha, Yantian and Guan, Lin},
  booktitle={AAAI},
  year={2022}
}







