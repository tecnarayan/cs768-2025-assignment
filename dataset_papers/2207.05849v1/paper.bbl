\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri]{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In \emph{NIPS}, volume~11, pages 2312--2320, 2011.

\bibitem[Abe and Long(1999)]{abe1999associative}
Naoki Abe and Philip~M Long.
\newblock Associative reinforcement learning using linear probabilistic
  concepts.
\newblock In \emph{ICML}, pages 3--11. Citeseer, 1999.

\bibitem[Agarwal et~al.(2012)Agarwal, Dud{\'\i}k, Kale, Langford, and
  Schapire]{agarwal2012contextual}
Alekh Agarwal, Miroslav Dud{\'\i}k, Satyen Kale, John Langford, and Robert
  Schapire.
\newblock Contextual bandit learning with predictable rewards.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 19--26. PMLR,
  2012.

\bibitem[Agarwal et~al.(2014)Agarwal, Hsu, Kale, Langford, Li, and
  Schapire]{agarwal2014taming}
Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert
  Schapire.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  1638--1646. PMLR, 2014.

\bibitem[Agarwal et~al.(2017)Agarwal, Luo, Neyshabur, and
  Schapire]{agarwal2017corralling}
Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, and Robert~E Schapire.
\newblock Corralling a band of bandit algorithms.
\newblock In \emph{Conference on Learning Theory}, pages 12--38. PMLR, 2017.

\bibitem[Auer(2002)]{auer2002using}
Peter Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Chaudhuri and Kalyanakrishnan(2018)]{chaudhuri2018quantile}
Arghya~Roy Chaudhuri and Shivaram Kalyanakrishnan.
\newblock Quantile-regret minimisation in infinitely many-armed bandits.
\newblock In \emph{UAI}, pages 425--434, 2018.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 208--214. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Foster and Rakhlin(2020)]{foster2020beyond}
Dylan Foster and Alexander Rakhlin.
\newblock Beyond {UCB}: Optimal and efficient contextual bandits with
  regression oracles.
\newblock In \emph{International Conference on Machine Learning}, pages
  3199--3210. PMLR, 2020.

\bibitem[Foster et~al.(2018)Foster, Agarwal, Dudik, Luo, and
  Schapire]{foster2018practical}
Dylan Foster, Alekh Agarwal, Miroslav Dudik, Haipeng Luo, and Robert Schapire.
\newblock Practical contextual bandits with regression oracles.
\newblock In \emph{International Conference on Machine Learning}, pages
  1539--1548. PMLR, 2018.

\bibitem[Foster et~al.(2021{\natexlab{a}})Foster, Rakhlin, Simchi-Levi, and
  Xu]{foster2021instance}
Dylan Foster, Alexander Rakhlin, David Simchi-Levi, and Yunzong Xu.
\newblock Instance-dependent complexity of contextual bandits and reinforcement
  learning: A disagreement-based perspective.
\newblock In \emph{Conference on Learning Theory}, pages 2059--2059. PMLR,
  2021{\natexlab{a}}.

\bibitem[Foster and Krishnamurthy(2021)]{foster2021efficient}
Dylan~J Foster and Akshay Krishnamurthy.
\newblock Efficient first-order contextual bandits: Prediction, allocation, and
  triangular discrimination.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Foster et~al.(2020)Foster, Gentile, Mohri, and
  Zimmert]{foster2020adapting}
Dylan~J Foster, Claudio Gentile, Mehryar Mohri, and Julian Zimmert.
\newblock Adapting to misspecification in contextual bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Foster et~al.(2021{\natexlab{b}})Foster, Kakade, Qian, and
  Rakhlin]{foster2021statistical}
Dylan~J Foster, Sham~M Kakade, Jian Qian, and Alexander Rakhlin.
\newblock The statistical complexity of interactive decision making.
\newblock \emph{arXiv preprint arXiv:2112.13487}, 2021{\natexlab{b}}.

\bibitem[Gaillard and Gerchinovitz(2015)]{gaillard2015chaining}
Pierre Gaillard and S{\'e}bastien Gerchinovitz.
\newblock A chaining algorithm for online nonparametric regression.
\newblock In \emph{Conference on Learning Theory}, pages 764--796. PMLR, 2015.

\bibitem[Hadiji(2019)]{hadiji2019polynomial}
H{\'e}di Hadiji.
\newblock Polynomial cost of adaptation for {X}-armed bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Hazan et~al.(2007)Hazan, Agarwal, and Kale]{hazan2007logarithmic}
Elad Hazan, Amit Agarwal, and Satyen Kale.
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock \emph{Machine Learning}, 69\penalty0 (2-3):\penalty0 169--192, 2007.

\bibitem[Kakade et~al.(2011)Kakade, Kanade, Shamir, and
  Kalai]{kakade2011efficient}
Sham~M Kakade, Varun Kanade, Ohad Shamir, and Adam Kalai.
\newblock Efficient learning of generalized linear and single index models with
  isotonic regression.
\newblock \emph{Advances in Neural Information Processing Systems}, 24, 2011.

\bibitem[Kleinberg(2004)]{kleinberg2004nearly}
Robert Kleinberg.
\newblock Nearly tight bounds for the continuum-armed bandit problem.
\newblock \emph{Advances in Neural Information Processing Systems},
  17:\penalty0 697--704, 2004.

\bibitem[Krishnamurthy et~al.(2020)Krishnamurthy, Langford, Slivkins, and
  Zhang]{krishnamurthy2020contextual}
Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins, and Chicheng Zhang.
\newblock Contextual bandits with continuous actions: Smoothing, zooming, and
  adapting.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (137):\penalty0 1--45, 2020.

\bibitem[Langford and Zhang(2007)]{langford2007epoch}
John Langford and Tong Zhang.
\newblock The epoch-greedy algorithm for contextual multi-armed bandits.
\newblock \emph{Advances in neural information processing systems}, 20\penalty0
  (1):\penalty0 96--1, 2007.

\bibitem[Lattimore(2020)]{lattimore2020improved}
Tor Lattimore.
\newblock Improved regret for zeroth-order adversarial bandit convex
  optimisation.
\newblock \emph{Mathematical Statistics and Learning}, 2\penalty0 (3):\penalty0
  311--334, 2020.

\bibitem[Majzoubi et~al.(2020)Majzoubi, Zhang, Chari, Krishnamurthy, Langford,
  and Slivkins]{majzoubi2020efficient}
Maryam Majzoubi, Chicheng Zhang, Rajan Chari, Akshay Krishnamurthy, John
  Langford, and Aleksandrs Slivkins.
\newblock Efficient contextual bandits with continuous actions.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 349--360, 2020.

\bibitem[Rahimi et~al.(2007)Rahimi, Recht, et~al.]{rahimi2007random}
Ali Rahimi, Benjamin Recht, et~al.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{NIPS}, volume~3, page~5. Citeseer, 2007.

\bibitem[Simchi-Levi and Xu(2021)]{simchi2021bypassing}
David Simchi-Levi and Yunzong Xu.
\newblock Bypassing the monster: A faster and simpler optimal algorithm for
  contextual bandits under realizability.
\newblock \emph{Mathematics of Operations Research}, 2021.

\bibitem[Vovk(1998)]{vovk1998game}
Vladimir Vovk.
\newblock A game of prediction with expert advice.
\newblock \emph{Journal of Computer and System Sciences}, 56\penalty0
  (2):\penalty0 153--173, 1998.

\bibitem[Xu and Zeevi(2020)]{xu2020upper}
Yunbei Xu and Assaf Zeevi.
\newblock Upper counterfactual confidence bounds: a new optimism principle for
  contextual bandits.
\newblock \emph{arXiv preprint arXiv:2007.07876}, 2020.

\bibitem[Zhu and Nowak(2020)]{zhu2020regret}
Yinglun Zhu and Robert Nowak.
\newblock On regret with multiple best arms.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 9050--9060, 2020.

\end{thebibliography}
