\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2019)Agrawal, Amos, Barratt, Boyd, Diamond, and
  Kolter]{agrawal2019differentiable}
A.~Agrawal, B.~Amos, S.~Barratt, S.~Boyd, S.~Diamond, and Z.~Kolter.
\newblock Differentiable convex optimization layers.
\newblock \emph{arXiv preprint arXiv:1910.12430}, 2019.

\bibitem[Amos and Kolter(2017)]{amos2017optnet}
B.~Amos and J.~Z. Kolter.
\newblock Optnet: Differentiable optimization as a layer in neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  136--145. PMLR, 2017.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Bengio et~al.(2020)Bengio, Lodi, and Prouvost]{bengio2020machine}
Y.~Bengio, A.~Lodi, and A.~Prouvost.
\newblock Machine learning for combinatorial optimization: a methodological
  tour dâ€™horizon.
\newblock \emph{European Journal of Operational Research}, 2020.

\bibitem[Berthet et~al.(2020)Berthet, Blondel, Teboul, Cuturi, Vert, and
  Bach]{berthet2020learning}
Q.~Berthet, M.~Blondel, O.~Teboul, M.~Cuturi, J.~Vert, and F.~R. Bach.
\newblock Learning with differentiable pertubed optimizers.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Chen et~al.(2018)Chen, Song, Wainwright, and Jordan]{chen2018learning}
J.~Chen, L.~Song, M.~Wainwright, and M.~Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock In \emph{International Conference on Machine Learning}, pages
  883--892. PMLR, 2018.

\bibitem[Chen et~al.(2020)Chen, Zhang, Reisinger, and
  Song]{chen2020understanding}
X.~Chen, Y.~Zhang, C.~Reisinger, and L.~Song.
\newblock Understanding deep architecture with reasoning layer.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Correia et~al.(2020)Correia, Niculae, Aziz, and
  Martins]{correia2020efficient}
G.~M. Correia, V.~Niculae, W.~Aziz, and A.~F. Martins.
\newblock Efficient marginalization of discrete and structured latent variables
  via sparsity.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Domke(2010)]{domke:2010}
J.~Domke.
\newblock Implicit differentiation by perturbation.
\newblock In \emph{Advances in Neural Information Processing Systems 23}, pages
  523--531. 2010.

\bibitem[Domke(2012)]{domke2012generic}
J.~Domke.
\newblock Generic methods for optimization-based modeling.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 318--326.
  PMLR, 2012.

\bibitem[Donti et~al.(2017)Donti, Amos, and Kolter]{donti2017task}
P.~L. Donti, B.~Amos, and J.~Z. Kolter.
\newblock Task-based end-to-end model learning in stochastic optimization.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Elmachtoub and Grigas(2020)]{elmachtoub2020smart}
A.~N. Elmachtoub and P.~Grigas.
\newblock Smart ``predict, then optimize", 2020.

\bibitem[Evans and Grefenstette(2018)]{evans2018learning}
R.~Evans and E.~Grefenstette.
\newblock Learning explanatory rules from noisy data.
\newblock \emph{Journal of Artificial Intelligence Research}, 61:\penalty0
  1--64, 2018.

\bibitem[Ferber et~al.(2020)Ferber, Wilder, Dilkina, and
  Tambe]{ferber2020mipaal}
A.~Ferber, B.~Wilder, B.~Dilkina, and M.~Tambe.
\newblock Mipaal: Mixed integer program as a layer.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 1504--1511, 2020.

\bibitem[Franceschi et~al.(2018)Franceschi, Frasconi, Salzo, Grazzi, and
  Pontil]{franceschi2018bilevel}
L.~Franceschi, P.~Frasconi, S.~Salzo, R.~Grazzi, and M.~Pontil.
\newblock Bilevel programming for hyperparameter optimization and
  meta-learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1568--1577. PMLR, 2018.

\bibitem[Franceschi et~al.(2019)Franceschi, Niepert, Pontil, and
  He]{franceschi2019learning}
L.~Franceschi, M.~Niepert, M.~Pontil, and X.~He.
\newblock Learning discrete structures for graph neural networks.
\newblock In \emph{International conference on machine learning}, pages
  1972--1982. PMLR, 2019.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Choi, Wu, Roeder, and
  Duvenaud]{grathwohl2017backpropagation}
W.~Grathwohl, D.~Choi, Y.~Wu, G.~Roeder, and D.~Duvenaud.
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock \emph{ICLR}, 2018.

\bibitem[Grover et~al.(2019)Grover, Wang, Zweig, and
  Ermon]{grover2019stochastic}
A.~Grover, E.~Wang, A.~Zweig, and S.~Ermon.
\newblock Stochastic optimization of sorting networks via continuous
  relaxations.
\newblock \emph{arXiv preprint arXiv:1903.08850}, 2019.

\bibitem[Guyomarch(2017)]{warcraft_map_editor}
J.~Guyomarch.
\newblock {Warcraft II Open-Source Map Editor}.
\newblock \url{http://github.com/war2/war2edit}, 2017.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Norouzi, and
  Ba]{hafner2020mastering}
D.~Hafner, T.~Lillicrap, M.~Norouzi, and J.~Ba.
\newblock Mastering atari with discrete world models.
\newblock \emph{arXiv preprint arXiv:2010.02193}, 2020.

\bibitem[Hazan and Jaakkola(2012)]{hazan2012partition}
T.~Hazan and T.~Jaakkola.
\newblock On the partition function and random maximum a-posteriori
  perturbations.
\newblock In \emph{Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 1667--1674, 2012.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{DBLP:conf/cvpr/HeZRS16}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{{CVPR}}, pages 770--778. {IEEE} Computer Society, 2016.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2016categorical}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{ICLR}, 2017.

\bibitem[Johnson and Balakrishnan(1998)]{johnson1998advances}
N.~L. Johnson and N.~Balakrishnan.
\newblock Advances in the theory and practice of statistics, 1998.

\bibitem[Kim et~al.(2016)Kim, Sabharwal, and Ermon]{kim2016exact}
C.~Kim, A.~Sabharwal, and S.~Ermon.
\newblock Exact sampling with integer linear programs and random perturbations.
\newblock In \emph{Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[Kool et~al.(2020)Kool, van Hoof, and Welling]{kool2020estimating}
W.~Kool, H.~van Hoof, and M.~Welling.
\newblock Estimating gradients for discrete random variables by sampling
  without replacement.
\newblock \emph{ICLR}, 2020.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, and
  Huang]{lecun2006tutorial}
Y.~LeCun, S.~Chopra, R.~Hadsell, M.~Ranzato, and F.~Huang.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 1\penalty0 (0), 2006.

\bibitem[Lei et~al.(2016)Lei, Barzilay, and Jaakkola]{Lei2016RationalizingNP}
T.~Lei, R.~Barzilay, and T.~Jaakkola.
\newblock Rationalizing neural predictions.
\newblock In \emph{EMNLP}, 2016.

\bibitem[Liu et~al.(2019)Liu, Regier, Tripuraneni, Jordan, and
  Mcauliffe]{liu2019rao}
R.~Liu, J.~Regier, N.~Tripuraneni, M.~Jordan, and J.~Mcauliffe.
\newblock Rao-blackwellized stochastic gradients for discrete distributions.
\newblock In \emph{International Conference on Machine Learning}, pages
  4023--4031. PMLR, 2019.

\bibitem[Lorberbom et~al.(2019)Lorberbom, Gane, Jaakkola, and
  Hazan]{lorberbom:2019}
G.~Lorberbom, A.~Gane, T.~Jaakkola, and T.~Hazan.
\newblock Direct optimization through argmax for discrete variational
  auto-encoder.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6203--6214, 2019.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{maddison2016concrete}
C.~J. Maddison, A.~Mnih, and Y.~W. Teh.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock \emph{ICLR}, 2017.

\bibitem[Mandi and Guns(2020)]{DBLP:conf/nips/MandiG20}
J.~Mandi and T.~Guns.
\newblock Interior point solving for lp-based prediction+optimisation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Mandi et~al.(2020)Mandi, Demirovi{\'c}, Stuckey, and
  Guns]{Mandi_Guns:2020}
J.~Mandi, E.~Demirovi{\'c}, P.~J. Stuckey, and T.~Guns.
\newblock Smart predict-and-optimize for hard combinatorial optimization
  problems.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 1603--1610, 2020.

\bibitem[McAllester et~al.(2010)McAllester, Hazan, and
  Keshet]{mcallester2010direct}
D.~A. McAllester, T.~Hazan, and J.~Keshet.
\newblock Direct loss minimization for structured prediction.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~1, page~3, 2010.

\bibitem[McAuley et~al.(2012)McAuley, Leskovec, and
  Jurafsky]{McAuley2012LearningAA}
J.~McAuley, J.~Leskovec, and D.~Jurafsky.
\newblock Learning attitudes and attributes from multi-aspect reviews.
\newblock \emph{2012 IEEE 12th International Conference on Data Mining}, pages
  1020--1025, 2012.

\bibitem[Mi{\v{s}}i{\'c} and Perakis(2020)]{mivsic2020data}
V.~V. Mi{\v{s}}i{\'c} and G.~Perakis.
\newblock Data analytics in operations management: A review.
\newblock \emph{Manufacturing \& Service Operations Management}, 22\penalty0
  (1):\penalty0 158--169, 2020.

\bibitem[Mortici(2010)]{MORTICI2010}
C.~Mortici.
\newblock {Fast convergences towards Euler-Mascheroni constant}.
\newblock \emph{{Computational \& Applied Mathematics}}, 29, 00 2010.

\bibitem[Murphy(2012)]{murphy2012machine}
K.~P. Murphy.
\newblock \emph{Machine learning: a probabilistic perspective}.
\newblock MIT press, 2012.

\bibitem[Niculae and Martins(2020)]{Niculae2020LPSparseMAPDR}
V.~Niculae and A.~F.~T. Martins.
\newblock Lp-sparsemap: Differentiable relaxed optimization for sparse
  structured prediction.
\newblock In \emph{ICML}, 2020.

\bibitem[Niculae et~al.(2018)Niculae, Martins, Blondel, and
  Cardie]{Niculae2018SparseMAPDS}
V.~Niculae, A.~F.~T. Martins, M.~Blondel, and C.~Cardie.
\newblock Sparsemap: Differentiable sparse structured inference.
\newblock In \emph{ICML}, 2018.

\bibitem[{Papandreou} and {Yuille}(2011)]{Papandreou:2011}
G.~{Papandreou} and A.~L. {Yuille}.
\newblock Perturb-and-map random fields: Using discrete optimization to learn
  and sample from energy models.
\newblock In \emph{2011 International Conference on Computer Vision}, pages
  193--200, 2011.

\bibitem[Paulus et~al.(2020)Paulus, Choi, Tarlow, Krause, and
  Maddison]{paulus2020gradient}
M.~B. Paulus, D.~Choi, D.~Tarlow, A.~Krause, and C.~J. Maddison.
\newblock Gradient estimation with stochastic softmax tricks.
\newblock \emph{arXiv preprint arXiv:2006.08063}, 2020.

\bibitem[Pogan{\v{c}}i{\'c} et~al.(2019)Pogan{\v{c}}i{\'c}, Paulus, Musil,
  Martius, and Rolinek]{poganvcic2019differentiation}
M.~V. Pogan{\v{c}}i{\'c}, A.~Paulus, V.~Musil, G.~Martius, and M.~Rolinek.
\newblock Differentiation of blackbox combinatorial solvers.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Raedt et~al.(2016)Raedt, Kersting, Natarajan, and
  Poole]{raedt2016statistical}
L.~D. Raedt, K.~Kersting, S.~Natarajan, and D.~Poole.
\newblock Statistical relational artificial intelligence: Logic, probability,
  and computation.
\newblock \emph{Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 10\penalty0 (2):\penalty0 1--189, 2016.

\bibitem[Rol{\'\i}nek et~al.(2020)Rol{\'\i}nek, Swoboda, Zietlow, Paulus,
  Musil, and Martius]{rolinek2020deep}
M.~Rol{\'\i}nek, P.~Swoboda, D.~Zietlow, A.~Paulus, V.~Musil, and G.~Martius.
\newblock Deep graph matching via blackbox differentiation of combinatorial
  solvers.
\newblock In \emph{ECCV}, 2020.

\bibitem[Schulman et~al.(2015)Schulman, Heess, Weber, and
  Abbeel]{schulman2015gradient}
J.~Schulman, N.~Heess, T.~Weber, and P.~Abbeel.
\newblock Gradient estimation using stochastic computation graphs.
\newblock In \emph{Proceedings of the 28th International Conference on Neural
  Information Processing Systems-Volume 2}, pages 3528--3536, 2015.

\bibitem[Shpakova and Bach(2016)]{shpakova:2016}
T.~Shpakova and F.~Bach.
\newblock Parameter learning for log-supermodular distributions.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~29, pages 3234--3242, 2016.

\bibitem[Song et~al.(2016)Song, Schwing, Urtasun, et~al.]{song2016training}
Y.~Song, A.~Schwing, R.~Urtasun, et~al.
\newblock Training deep neural networks via direct loss minimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  2169--2177, 2016.

\bibitem[Tucker et~al.(2017)Tucker, Mnih, Maddison, Lawson, and
  Sohl-Dickstein]{tucker2017rebar}
G.~Tucker, A.~Mnih, C.~J. Maddison, D.~Lawson, and J.~Sohl-Dickstein.
\newblock Rebar: Low-variance, unbiased gradient estimates for discrete latent
  variable models.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Wainwright and Jordan(2008)]{wainwright2008graphical}
M.~J. Wainwright and M.~I. Jordan.
\newblock \emph{Graphical models, exponential families, and variational
  inference}.
\newblock Now Publishers Inc, 2008.

\bibitem[Wang et~al.(2019)Wang, Donti, Wilder, and Kolter]{wang2019satnet}
P.-W. Wang, P.~Donti, B.~Wilder, and Z.~Kolter.
\newblock Satnet: Bridging deep learning and logical reasoning using a
  differentiable satisfiability solver.
\newblock In \emph{International Conference on Machine Learning}, pages
  6545--6554. PMLR, 2019.

\bibitem[Wilder et~al.(2019)Wilder, Dilkina, and Tambe]{wilder2019melding}
B.~Wilder, B.~Dilkina, and M.~Tambe.
\newblock Melding the data-decisions pipeline: Decision-focused learning for
  combinatorial optimization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 1658--1665, 2019.

\bibitem[Xi'an(2016)]{214875}
Xi'an.
\newblock Which pdf of x leads to a gumbel distribution of the finite-size
  average of x?
\newblock Cross Validated, 2016.
\newblock URL \url{https://stats.stackexchange.com/q/214875}.
\newblock URL:https://stats.stackexchange.com/q/214875 (version: 2016-05-27).

\bibitem[Xie and Ermon(2019)]{Xie2019ReparameterizableSS}
S.~M. Xie and S.~Ermon.
\newblock Reparameterizable subset sampling via continuous relaxations.
\newblock In \emph{IJCAI}, 2019.

\end{thebibliography}
