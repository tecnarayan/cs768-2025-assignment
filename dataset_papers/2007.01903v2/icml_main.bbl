\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anderson et~al.(2020)Anderson, Huchette, Ma, Tjandraatmadja, and
  Vielma]{anderson2020strong}
Anderson, R., Huchette, J., Ma, W., Tjandraatmadja, C., and Vielma, J.~P.
\newblock Strong mixed-integer programming formulations for trained neural
  networks.
\newblock \emph{Mathematical Programming}, pp.\  1--37, 2020.

\bibitem[Athey \& Imbens(2016)Athey and Imbens]{athey2016recursive}
Athey, S. and Imbens, G.
\newblock Recursive partitioning for heterogeneous causal effects.
\newblock \emph{Proceedings of the National Academy of Sciences}, 113\penalty0
  (27):\penalty0 7353--7360, 2016.

\bibitem[Baardman et~al.(2018)Baardman, Borjian~Boroujeni, Cohen-Hillel,
  Panchamgam, and Perakis]{baardman2018detecting}
Baardman, L., Borjian~Boroujeni, S., Cohen-Hillel, T., Panchamgam, K., and
  Perakis, G.
\newblock Detecting customer trends for optimal promotion targeting.
\newblock \emph{Available at SSRN 3242529}, 2018.

\bibitem[Baehrens et~al.(2010)Baehrens, Schroeter, Harmeling, Kawanabe, Hansen,
  and M{\~A}{\v{z}}ller]{baehrens2010explain}
Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M., Hansen, K., and
  M{\~A}{\v{z}}ller, K.-R.
\newblock How to explain individual classification decisions.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (Jun):\penalty0 1803--1831, 2010.

\bibitem[Ban \& Keskin(2020)Ban and Keskin]{ban2020personalized}
Ban, G.-Y. and Keskin, N.~B.
\newblock Personalized dynamic pricing with machine learning: High dimensional
  features and heterogeneous elasticity.
\newblock \emph{Available at SSRN 2972985}, 2020.

\bibitem[Ban \& Rudin(2019)Ban and Rudin]{ban2019big}
Ban, G.-Y. and Rudin, C.
\newblock The big data newsvendor: Practical insights from machine learning.
\newblock \emph{Operations Research}, 67\penalty0 (1):\penalty0 90--108, 2019.

\bibitem[Bastani et~al.(2018)Bastani, Bastani, and
  Kim]{bastani2018interpreting}
Bastani, H., Bastani, O., and Kim, C.
\newblock Interpreting predictive models for human-in-the-loop analytics.
\newblock \emph{arXiv preprint arXiv:1705.08504}, pp.\  1--45, 2018.

\bibitem[Bastani et~al.(2020)Bastani, Bayati, and Khosravi]{bastani2020mostly}
Bastani, H., Bayati, M., and Khosravi, K.
\newblock Mostly exploration-free algorithms for contextual bandits.
\newblock \emph{Management Science}, 2020.

\bibitem[Bastani et~al.(2017)Bastani, Kim, and
  Bastani]{bastani2017interpreting}
Bastani, O., Kim, C., and Bastani, H.
\newblock Interpreting blackbox models via model extraction.
\newblock \emph{arXiv preprint arXiv:1705.08504}, 2017.

\bibitem[Bertsimas \& Kallus(2016)Bertsimas and Kallus]{bertsimas2016power}
Bertsimas, D. and Kallus, N.
\newblock The power and limits of predictive approaches to
  observational-data-driven optimization.
\newblock \emph{arXiv preprint arXiv:1605.02347}, 2016.

\bibitem[Bertsimas \& Kallus(2020)Bertsimas and
  Kallus]{bertsimas2020predictive}
Bertsimas, D. and Kallus, N.
\newblock From predictive to prescriptive analytics.
\newblock \emph{Management Science}, 66\penalty0 (3):\penalty0 1025--1044,
  2020.

\bibitem[Bertsimas \& McCord(2018)Bertsimas and
  McCord]{bertsimas2018optimization}
Bertsimas, D. and McCord, C.
\newblock Optimization over continuous and multi-dimensional decisions with
  observational data.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2962--2970, 2018.

\bibitem[Bertsimas et~al.(2019{\natexlab{a}})Bertsimas, Delarue, Jaillet, and
  Martin]{bertsimas2019price}
Bertsimas, D., Delarue, A., Jaillet, P., and Martin, S.
\newblock The price of interpretability.
\newblock \emph{arXiv preprint arXiv:1907.03419}, 2019{\natexlab{a}}.

\bibitem[Bertsimas et~al.(2019{\natexlab{b}})Bertsimas, Dunn, and
  Mundru]{bertsimas2019optimal}
Bertsimas, D., Dunn, J., and Mundru, N.
\newblock Optimal prescriptive trees.
\newblock \emph{INFORMS Journal on Optimization}, 1\penalty0 (2):\penalty0
  164--183, 2019{\natexlab{b}}.

\bibitem[Biggs et~al.(2017)Biggs, Hariss, and Perakis]{biggs2017optimizing}
Biggs, M., Hariss, R., and Perakis, G.
\newblock Optimizing objective functions determined from random forests.
\newblock \emph{Available at SSRN 2986630}, 2017.

\bibitem[Breiman et~al.(1984)Breiman, Friedman, Stone, and
  Olshen]{breiman1984classification}
Breiman, L., Friedman, J., Stone, C.~J., and Olshen, R.~A.
\newblock \emph{Classification and regression trees}.
\newblock CRC press, 1984.

\bibitem[Buciluǎ et~al.(2006)Buciluǎ, Caruana, and
  Niculescu-Mizil]{bucilua2006model}
Buciluǎ, C., Caruana, R., and Niculescu-Mizil, A.
\newblock Model compression.
\newblock In \emph{Proceedings of the 12th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  535--541, 2006.

\bibitem[Che et~al.(2015)Che, Purushotham, Khemani, and Liu]{che2015distilling}
Che, Z., Purushotham, S., Khemani, R., and Liu, Y.
\newblock Distilling knowledge from deep networks with applications to
  healthcare domain.
\newblock \emph{arXiv preprint arXiv:1512.03542}, 2015.

\bibitem[Chen et~al.(2015)Chen, Owen, Pixton, and
  Simchi-Levi]{chen2015statistical}
Chen, X., Owen, Z., Pixton, C., and Simchi-Levi, D.
\newblock A statistical learning approach to personalization in revenue
  management.
\newblock \emph{Available at SSRN 2579462}, 2015.

\bibitem[Ciocan \& Mi{\v{s}}i{\'c}(2018)Ciocan and
  Mi{\v{s}}i{\'c}]{ciocan2018interpretable}
Ciocan, D. and Mi{\v{s}}i{\'c}, V.
\newblock Interpretable optimal stopping.
\newblock 2018.

\bibitem[Craven \& Shavlik(1996)Craven and Shavlik]{craven1996extracting}
Craven, M. and Shavlik, J.~W.
\newblock Extracting tree-structured representations of trained networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  24--30, 1996.

\bibitem[Ding et~al.(2018)Ding, Hasan, Bickel, and Pan]{ding2018interpreting}
Ding, T., Hasan, F., Bickel, W.~K., and Pan, S.
\newblock Interpreting social media-based substance use prediction models with
  knowledge distillation.
\newblock In \emph{2018 IEEE 30th International Conference on Tools with
  Artificial Intelligence (ICTAI)}, pp.\  623--630. IEEE, 2018.

\bibitem[Elmachtoub \& Grigas(2017)Elmachtoub and Grigas]{elmachtoub2017smart}
Elmachtoub, A.~N. and Grigas, P.
\newblock Smart "predict, then optimize", 2017.

\bibitem[Elmachtoub et~al.(2018)Elmachtoub, Gupta, and
  Hamilton]{elmachtoub2018value}
Elmachtoub, A.~N., Gupta, V., and Hamilton, M.
\newblock The value of personalized pricing.
\newblock \emph{Available at SSRN 3127719}, 2018.

\bibitem[Elmachtoub et~al.(2020)Elmachtoub, Liang, and
  McNellis]{elmachtoub2020decision}
Elmachtoub, A.~N., Liang, J. C.~N., and McNellis, R.
\newblock Decision trees for decision-making under the predict-then-optimize
  framework, 2020.

\bibitem[Ferreira et~al.(2016)Ferreira, Lee, and
  Simchi-Levi]{ferreira2016analytics}
Ferreira, K.~J., Lee, B. H.~A., and Simchi-Levi, D.
\newblock Analytics for an online retailer: Demand forecasting and price
  optimization.
\newblock \emph{Manufacturing \& Service Operations Management}, 18\penalty0
  (1):\penalty0 69--88, 2016.

\bibitem[Friedman et~al.(2008)Friedman, Popescu,
  et~al.]{friedman2008predictive}
Friedman, J.~H., Popescu, B.~E., et~al.
\newblock Predictive learning via rule ensembles.
\newblock \emph{The Annals of Applied Statistics}, 2\penalty0 (3):\penalty0
  916--954, 2008.

\bibitem[Frosst \& Hinton(2017)Frosst and Hinton]{frosst2017distilling}
Frosst, N. and Hinton, G.
\newblock Distilling a neural network into a soft decision tree.
\newblock \emph{arXiv preprint arXiv:1711.09784}, 2017.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2015.

\bibitem[Hirano \& Imbens(2004)Hirano and Imbens]{hirano2004propensity}
Hirano, K. and Imbens, G.~W.
\newblock The propensity score with continuous treatments.
\newblock \emph{Applied Bayesian modeling and causal inference from
  incomplete-data perspectives}, 226164:\penalty0 73--84, 2004.

\bibitem[Javanmard \& Nazerzadeh(2016)Javanmard and
  Nazerzadeh]{javanmard2016dynamic}
Javanmard, A. and Nazerzadeh, H.
\newblock Dynamic pricing in high-dimensions.
\newblock \emph{arXiv preprint arXiv:1609.07574}, 2016.

\bibitem[Kallus(2017)]{kallus2017recursive}
Kallus, N.
\newblock Recursive partitioning for personalization using observational data.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1789--1798. JMLR. org, 2017.

\bibitem[Ke et~al.(2017)Ke, Meng, Finley, Wang, Chen, Ma, Ye, and
  Liu]{ke2017lightgbm}
Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., and Liu,
  T.-Y.
\newblock Lightgbm: A highly efficient gradient boosting decision tree.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3146--3154, 2017.

\bibitem[Lakkaraju et~al.(2016)Lakkaraju, Bach, and
  Leskovec]{lakkaraju2016interpretable}
Lakkaraju, H., Bach, S.~H., and Leskovec, J.
\newblock Interpretable decision sets: A joint framework for description and
  prediction.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pp.\  1675--1684, 2016.

\bibitem[Laurent \& Rivest(1976)Laurent and Rivest]{laurent1976constructing}
Laurent, H. and Rivest, R.~L.
\newblock Constructing optimal binary decision trees is np-complete.
\newblock \emph{Information processing letters}, 5\penalty0 (1):\penalty0
  15--17, 1976.

\bibitem[Letham et~al.(2015)Letham, Rudin, McCormick, Madigan,
  et~al.]{letham2015interpretable}
Letham, B., Rudin, C., McCormick, T.~H., Madigan, D., et~al.
\newblock Interpretable classifiers using rules and bayesian analysis: Building
  a better stroke prediction model.
\newblock \emph{The Annals of Applied Statistics}, 9\penalty0 (3):\penalty0
  1350--1371, 2015.

\bibitem[Liu et~al.(2020)Liu, Cheng, Dong, He, Pan, and Ming]{liu2020general}
Liu, D., Cheng, P., Dong, Z., He, X., Pan, W., and Ming, Z.
\newblock A general knowledge distillation framework for counterfactual
  recommendation via uniform data.
\newblock In \emph{Proceedings of the 43rd International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, pp.\  831--840, 2020.

\bibitem[Lundberg \& Lee(2017)Lundberg and Lee]{lundberg2017unified}
Lundberg, S.~M. and Lee, S.-I.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  4765--4774, 2017.

\bibitem[Miller(2019)]{miller2019explanation}
Miller, T.
\newblock Explanation in artificial intelligence: Insights from the social
  sciences.
\newblock \emph{Artificial intelligence}, 267:\penalty0 1--38, 2019.

\bibitem[Mi{\v{s}}ic(2017)]{mivsic2017optimization}
Mi{\v{s}}ic, V.~V.
\newblock Optimization of tree ensembles.
\newblock \emph{arXiv preprint arXiv:1705.10883}, 2017.

\bibitem[Pan et~al.(2019)Pan, He, and Yu]{pan2019novel}
Pan, Y., He, F., and Yu, H.
\newblock A novel enhanced collaborative autoencoder with knowledge
  distillation for top-n recommender systems.
\newblock \emph{Neurocomputing}, 332:\penalty0 137--148, 2019.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016should}
Ribeiro, M.~T., Singh, S., and Guestrin, C.
\newblock " why should i trust you?" explaining the predictions of any
  classifier.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pp.\  1135--1144, 2016.

\bibitem[Ribeiro et~al.(2018)Ribeiro, Singh, and Guestrin]{ribeiro2018anchors}
Ribeiro, M.~T., Singh, S., and Guestrin, C.
\newblock Anchors: High-precision model-agnostic explanations.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Sanchez et~al.(2015)Sanchez, Rocktaschel, Riedel, and
  Singh]{sanchez2015towards}
Sanchez, I., Rocktaschel, T., Riedel, S., and Singh, S.
\newblock Towards extracting faithful and descriptive representations of latent
  variable models.
\newblock In \emph{AAAI Spring Syposium on Knowledge Representation and
  Reasoning (KRR): Integrating Symbolic and Neural Approaches}, volume~1, pp.\
  4--1, 2015.

\bibitem[Tang \& Wang(2018)Tang and Wang]{tang2018ranking}
Tang, J. and Wang, K.
\newblock Ranking distillation: Learning compact ranking models with high
  performance for recommender system.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  2289--2298, 2018.

\bibitem[Ustun \& Rudin(2016)Ustun and Rudin]{ustun2016supersparse}
Ustun, B. and Rudin, C.
\newblock Supersparse linear integer models for optimized medical scoring
  systems.
\newblock \emph{Machine Learning}, 102\penalty0 (3):\penalty0 349--391, 2016.

\bibitem[Vongkulbhisal et~al.(2019)Vongkulbhisal, Vinayavekhin, and
  Visentini-Scarzanella]{vongkulbhisal2019unifying}
Vongkulbhisal, J., Vinayavekhin, P., and Visentini-Scarzanella, M.
\newblock Unifying heterogeneous classifiers with distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3175--3184, 2019.

\bibitem[Wager \& Athey(2018)Wager and Athey]{wager2018estimation}
Wager, S. and Athey, S.
\newblock Estimation and inference of heterogeneous treatment effects using
  random forests.
\newblock \emph{Journal of the American Statistical Association}, 113\penalty0
  (523):\penalty0 1228--1242, 2018.

\bibitem[Ye et~al.(2018)Ye, Qian, Chen, Wu, Zhou, De~Mars, Yang, and
  Zhang]{ye2018customized}
Ye, P., Qian, J., Chen, J., Wu, C.-h., Zhou, Y., De~Mars, S., Yang, F., and
  Zhang, L.
\newblock Customized regression model for airbnb dynamic pricing.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  932--940, 2018.

\bibitem[Zhou et~al.(2018)Zhou, Athey, and Wager]{zhou2018offline}
Zhou, Z., Athey, S., and Wager, S.
\newblock Offline multi-action policy learning: Generalization and
  optimization.
\newblock \emph{arXiv preprint arXiv:1810.04778}, 2018.

\end{thebibliography}
