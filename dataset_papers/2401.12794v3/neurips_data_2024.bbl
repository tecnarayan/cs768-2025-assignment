\begin{thebibliography}{10}

\bibitem{2023Yi}
01.AI.
\newblock Yi series.
\newblock \url{https://www.lingyiwanwu.com/en}, 2023.

\bibitem{abdar2021review}
Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li~Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U~Rajendra Acharya, et~al.
\newblock A review of uncertainty quantification in deep learning: Techniques, applications and challenges.
\newblock {\em Information fusion}, 76:243--297, 2021.

\bibitem{falcon}
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Maitha Alhammadi, Mazzotta Daniele, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo.
\newblock The falcon series of language models: Towards open frontier models.
\newblock 2023.

\bibitem{angelopoulos2020uncertainty}
Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, and Michael~I Jordan.
\newblock Uncertainty sets for image classifiers using conformal prediction.
\newblock {\em arXiv preprint arXiv:2009.14193}, 2020.

\bibitem{angelopoulos2021gentle}
Anastasios~N Angelopoulos and Stephen Bates.
\newblock A gentle introduction to conformal prediction and distribution-free uncertainty quantification.
\newblock {\em arXiv preprint arXiv:2107.07511}, 2021.

\bibitem{2023flageval}
BAAI.
\newblock Flageval: An open-source evaluation toolkit and an open platform for evaluation of large models.
\newblock \url{https://github.com/FlagOpen/FlagEval}, 2023.

\bibitem{qwen}
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu~Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An~Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu.
\newblock Qwen technical report.
\newblock {\em arXiv preprint arXiv:2309.16609}, 2023.

\bibitem{balasubramanian2014conformal}
Vineeth Balasubramanian, Shen-Shyang Ho, and Vladimir Vovk.
\newblock {\em Conformal prediction for reliable machine learning: theory, adaptations and applications}.
\newblock Newnes, 2014.

\bibitem{chang2023survey}
Yupeng Chang, Xu~Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et~al.
\newblock A survey on evaluation of large language models.
\newblock {\em arXiv preprint arXiv:2307.03109}, 2023.

\bibitem{chen2023quantifying}
Jiuhai Chen and Jonas Mueller.
\newblock Quantifying uncertainty in answers from any language model via intrinsic and extrinsic confidence assessment.
\newblock {\em arXiv preprint arXiv:2308.16175}, 2023.

\bibitem{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.
\newblock Evaluating large language models trained on code.
\newblock {\em arXiv preprint arXiv:2107.03374}, 2021.

\bibitem{chen2023felm}
Shiqi Chen, Yiran Zhao, Jinghan Zhang, I-Chun Chern, Siyang Gao, Pengfei Liu, and Junxian He.
\newblock Felm: Benchmarking factuality evaluation of large language models.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2023.

\bibitem{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et~al.
\newblock Training verifiers to solve math word problems.
\newblock {\em arXiv preprint arXiv:2110.14168}, 2021.

\bibitem{2023opencompass}
OpenCompass Contributors.
\newblock Opencompass: A universal evaluation platform for foundation models.
\newblock \url{https://github.com/open-compass/opencompass}, 2023.

\bibitem{deepseek-llm}
DeepSeek.
\newblock Deepseek llm: Let there be answers.
\newblock \url{https://github.com/deepseek-ai/DeepSeek-LLM}, 2023.

\bibitem{deutschmann2023conformal}
Nicolas Deutschmann, Marvin Alberts, and Mar{\'\i}a~Rodr{\'\i}guez Mart{\'\i}nez.
\newblock Conformal autoregressive generation: Beam search with coverage guarantees.
\newblock {\em arXiv preprint arXiv:2309.03797}, 2023.

\bibitem{dey2022conformal}
Neil Dey, Jing Ding, Jack Ferrell, Carolina Kapper, Maxwell Lovig, Emiliano Planchon, and Jonathan~P Williams.
\newblock Conformal prediction for text infilling and part-of-speech prediction.
\newblock {\em The New England Journal of Statistics in Data Science}, 1(1):69--83, 2022.

\bibitem{dhamala2021bold}
Jwala Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, and Rahul Gupta.
\newblock Bold: Dataset and metrics for measuring biases in open-ended language generation.
\newblock In {\em Proceedings of the 2021 ACM conference on fairness, accountability, and transparency}, pages 862--872, 2021.

\bibitem{dong2022survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce~Zheng, Zhiyong Wu, Baobao Chang, Xu~Sun, Jingjing Xu, and Zhifang Sui.
\newblock A survey for in-context learning.
\newblock {\em arXiv preprint arXiv:2301.00234}, 2022.

\bibitem{fadeeva-etal-2023-lm}
Ekaterina Fadeeva, Roman Vashurin, Akim Tsvigun, Artem Vazhentsev, Sergey Petrakov, Kirill Fedyanin, Daniil Vasilev, Elizaveta Goncharova, Alexander Panchenko, Maxim Panov, Timothy Baldwin, and Artem Shelmanov.
\newblock {LM}-polygraph: Uncertainty estimation for language models.
\newblock In Yansong Feng and Els Lefever, editors, {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pages 446--461, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{fisch2020efficient}
Adam Fisch, Tal Schuster, Tommi Jaakkola, and Regina Barzilay.
\newblock Efficient conformal prediction via cascaded inference with expanded admission.
\newblock {\em arXiv preprint arXiv:2007.03114}, 2020.

\bibitem{fomicheva-etal-2020-unsupervised}
Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Fr{\'e}d{\'e}ric Blain, Francisco Guzm{\'a}n, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, and Lucia Specia.
\newblock Unsupervised quality estimation for neural machine translation.
\newblock {\em Transactions of the Association for Computational Linguistics}, 8:539--555, 2020.

\bibitem{fontana2023conformal}
Matteo Fontana, Gianluca Zeni, and Simone Vantini.
\newblock Conformal prediction: a unified review of theory and new challenges.
\newblock {\em Bernoulli}, 29(1):1--23, 2023.

\bibitem{eval-harness}
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le~Noac'h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou.
\newblock A framework for few-shot language model evaluation, 12 2023.

\bibitem{gawlikowski2023survey}
Jakob Gawlikowski, Cedrique Rovile~Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et~al.
\newblock A survey of uncertainty in deep neural networks.
\newblock {\em Artificial Intelligence Review}, 56(Suppl 1):1513--1589, 2023.

\bibitem{giovannotti2021transformer}
Patrizio Giovannotti and Alex Gammerman.
\newblock Transformer-based conformal predictors for paraphrase detection.
\newblock In {\em Conformal and Probabilistic Prediction and Applications}, pages 243--265. PMLR, 2021.

\bibitem{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In {\em International conference on machine learning}, pages 1321--1330. PMLR, 2017.

\bibitem{guo2023evaluating}
Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong, et~al.
\newblock Evaluating large language models: A comprehensive survey.
\newblock {\em arXiv preprint arXiv:2310.19736}, 2023.

\bibitem{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock {\em arXiv preprint arXiv:2009.03300}, 2020.

\bibitem{hu2023uncertainty}
Mengting Hu, Zhen Zhang, Shiwan Zhao, Minlie Huang, and Bingzhe Wu.
\newblock Uncertainty in natural language processing: Sources, quantification, and applications.
\newblock {\em arXiv preprint arXiv:2306.04459}, 2023.

\bibitem{huang-etal-2019-cosmos}
Lifu Huang, Ronan Le~Bras, Chandra Bhagavatula, and Yejin Choi.
\newblock Cosmos {QA}: Machine reading comprehension with contextual commonsense reasoning.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, pages 2391--2401, Hong Kong, China, November 2019. Association for Computational Linguistics.

\bibitem{huang2023look}
Yuheng Huang, Jiayang Song, Zhijie Wang, Huaming Chen, and Lei Ma.
\newblock Look before you leap: An exploratory study of uncertainty measurement for large language models.
\newblock {\em arXiv preprint arXiv:2307.10236}, 2023.

\bibitem{jelinek1977perplexity}
Fred Jelinek, Robert~L Mercer, Lalit~R Bahl, and James~K Baker.
\newblock Perplexityâ€”a measure of the difficulty of speech recognition tasks.
\newblock {\em The Journal of the Acoustical Society of America}, 62(S1):S63--S63, 1977.

\bibitem{jiang2023mistral}
Albert~Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et~al.
\newblock Mistral 7b.
\newblock {\em arXiv preprint arXiv:2310.06825}, 2023.

\bibitem{joshi2017triviaqa}
Mandar Joshi, Eunsol Choi, Daniel~S Weld, and Luke Zettlemoyer.
\newblock Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension.
\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1601--1611, 2017.

\bibitem{kaddour2023challenges}
Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy.
\newblock Challenges and applications of large language models.
\newblock {\em arXiv preprint arXiv:2307.10169}, 2023.

\bibitem{kuhn2022semantic}
Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar.
\newblock Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{kumar2023conformal}
Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy, Ramesh Raskar, and Andrew Beam.
\newblock Conformal prediction with large language models for multi-choice question answering.
\newblock {\em arXiv preprint arXiv:2305.18404}, 2023.

\bibitem{kwon2020uncertainty}
Yongchan Kwon, Joong-Ho Won, Beom~Joon Kim, and Myunghee~Cho Paik.
\newblock Uncertainty quantification using bayesian neural networks in classification: Application to biomedical image segmentation.
\newblock {\em Computational Statistics \& Data Analysis}, 142:106816, 2020.

\bibitem{li-etal-2023-halueval}
Junyi Li, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.
\newblock {H}alu{E}val: A large-scale hallucination evaluation benchmark for large language models.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 6449--6464, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{li2023comprehensive}
Yunxin Li, Longyue Wang, Baotian Hu, Xinyu Chen, Wanqi Zhong, Chenyang Lyu, and Min Zhang.
\newblock A comprehensive evaluation of gpt-4v on knowledge-intensive visual question answering.
\newblock {\em arXiv preprint arXiv:2311.07536}, 2023.

\bibitem{liang2022holistic}
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et~al.
\newblock Holistic evaluation of language models.
\newblock {\em arXiv preprint arXiv:2211.09110}, 2022.

\bibitem{lin2023generating}
Zhen Lin, Shubhendu Trivedi, and Jimeng Sun.
\newblock Generating with confidence: Uncertainty quantification for black-box large language models.
\newblock {\em arXiv preprint arXiv:2305.19187}, 2023.

\bibitem{liu2023retrieval}
Bingshuai Liu, Chenyang Lyu, Zijun Min, Zhanyu Wang, Jinsong Su, and Longyue Wang.
\newblock Retrieval-augmented multi-modal chain-of-thoughts reasoning for large language models.
\newblock {\em arXiv preprint arXiv:2312.01714}, 2023.

\bibitem{liu2024datasets}
Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, and Lianwen Jin.
\newblock Datasets for large language models: A comprehensive survey.
\newblock {\em arXiv preprint arXiv:2402.18041}, 2024.

\bibitem{lu2023federated}
Charles Lu, Yaodong Yu, Sai~Praneeth Karimireddy, Michael Jordan, and Ramesh Raskar.
\newblock Federated conformal predictors for distributed uncertainty quantification.
\newblock In {\em International Conference on Machine Learning}, pages 22942--22964. PMLR, 2023.

\bibitem{lyu2023macaw}
Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming Shi, and Zhaopeng Tu.
\newblock Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration.
\newblock {\em arXiv preprint arXiv:2306.09093}, 2023.

\bibitem{minderer2021revisiting}
Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, and Mario Lucic.
\newblock Revisiting the calibration of modern neural networks.
\newblock {\em Advances in Neural Information Processing Systems}, 34:15682--15694, 2021.

\bibitem{moon-etal-2019-opendialkg}
Seungwhan Moon, Pararth Shah, Anuj Kumar, and Rajen Subba.
\newblock {O}pen{D}ial{KG}: Explainable conversational reasoning with attention-based walks over knowledge graphs.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages 845--854, Florence, Italy, July 2019. Association for Computational Linguistics.

\bibitem{naveed2023comprehensive}
Humza Naveed, Asad~Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Nick Barnes, and Ajmal Mian.
\newblock A comprehensive overview of large language models.
\newblock {\em arXiv preprint arXiv:2307.06435}, 2023.

\bibitem{norvig1987unified}
Peter Norvig.
\newblock {\em A unified theory of inference for text understanding}.
\newblock PhD thesis, University of California, Berkeley, 1987.

\bibitem{pang2024salute}
Jianhui Pang, Fanghua Ye, Longyue Wang, Dian Yu, Derek~F Wong, Shuming Shi, and Zhaopeng Tu.
\newblock Salute the classic: Revisiting challenges of machine translation in the age of large language models.
\newblock {\em arXiv preprint arXiv:2401.08350}, 2024.

\bibitem{quach2023conformal}
Victor Quach, Adam Fisch, Tal Schuster, Adam Yala, Jae~Ho Sohn, Tommi~S Jaakkola, and Regina Barzilay.
\newblock Conformal language modeling.
\newblock {\em arXiv preprint arXiv:2306.10193}, 2023.

\bibitem{rahaman2021uncertainty}
Rahul Rahaman et~al.
\newblock Uncertainty quantification and deep ensembles.
\newblock {\em Advances in Neural Information Processing Systems}, 34:20063--20075, 2021.

\bibitem{ravfogel-etal-2023-conformal}
Shauli Ravfogel, Yoav Goldberg, and Jacob Goldberger.
\newblock Conformal nucleus sampling.
\newblock In {\em Findings of the Association for Computational Linguistics: ACL 2023}, pages 27--34, Toronto, Canada, July 2023. Association for Computational Linguistics.

\bibitem{renyi1961measures}
Alfr{\'e}d R{\'e}nyi.
\newblock On measures of entropy and information.
\newblock In {\em Proceedings of the fourth Berkeley symposium on mathematical statistics and probability, volume 1: contributions to the theory of statistics}, volume~4, pages 547--562. University of California Press, 1961.

\bibitem{romano2020classification}
Yaniv Romano, Matteo Sesia, and Emmanuel Candes.
\newblock Classification with valid and adaptive coverage.
\newblock {\em Advances in Neural Information Processing Systems}, 33:3581--3591, 2020.

\bibitem{sadinle2019least}
Mauricio Sadinle, Jing Lei, and Larry Wasserman.
\newblock Least ambiguous set-valued classifiers with bounded error levels.
\newblock {\em Journal of the American Statistical Association}, 114(525):223--234, 2019.

\bibitem{see-etal-2017-get}
Abigail See, Peter~J. Liu, and Christopher~D. Manning.
\newblock Get to the point: Summarization with pointer-generator networks.
\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1073--1083, Vancouver, Canada, July 2017. Association for Computational Linguistics.

\bibitem{team2024gemma}
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi{\`e}re, Mihir~Sanjay Kale, Juliette Love, et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock {\em arXiv preprint arXiv:2403.08295}, 2024.

\bibitem{2023internlm}
InternLM Team.
\newblock Internlm: A multilingual language model with progressively enhanced capabilities.
\newblock \url{https://github.com/InternLM/InternLM}, 2023.

\bibitem{MosaicML2023Introducing}
MosaicML~NLP Team.
\newblock Introducing mpt-7b: A new standard for open-source, commercially usable llms.
\newblock \url{www.mosaicml.com/blog/mpt-7b}, 2023.
\newblock Accessed: 2023-05-05.

\bibitem{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{vovk2005algorithmic}
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer.
\newblock {\em Algorithmic learning in a random world}, volume~29.
\newblock Springer, 2005.

\bibitem{wagle2023empirical}
Sridevi Wagle, Sai Munikoti, Anurag Acharya, Sara Smith, and Sameera Horawalavithana.
\newblock Empirical evaluation of uncertainty quantification in retrieval-augmented language models for science.
\newblock {\em arXiv preprint arXiv:2311.09358}, 2023.

\bibitem{xie2021explanation}
Sang~Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma.
\newblock An explanation of in-context learning as implicit bayesian inference.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{xiong2023can}
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi.
\newblock Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.
\newblock {\em arXiv preprint arXiv:2306.13063}, 2023.

\bibitem{yang2023harnessing}
Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu.
\newblock Harnessing the power of llms in practice: A survey on chatgpt and beyond.
\newblock {\em arXiv preprint arXiv:2304.13712}, 2023.

\bibitem{yang2023improving}
Yuchen Yang, Houqiang Li, Yanfeng Wang, and Yu~Wang.
\newblock Improving the reliability of large language models by leveraging uncertainty-aware in-context learning.
\newblock {\em arXiv preprint arXiv:2310.04782}, 2023.

\bibitem{ye-etal-2023-enhancing}
Fanghua Ye, Meng Fang, Shenghui Li, and Emine Yilmaz.
\newblock Enhancing conversational search: Large language model-aided informative query rewriting.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Findings of the Association for Computational Linguistics: EMNLP 2023}, pages 5985--6006, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{ye2023flask}
Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo, James Thorne, Juho Kim, and Minjoon Seo.
\newblock Flask: Fine-grained language model evaluation based on alignment skill sets.
\newblock {\em arXiv preprint arXiv:2307.10928}, 2023.

\bibitem{zellers-etal-2019-hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock {H}ella{S}wag: Can a machine really finish your sentence?
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages 4791--4800, Florence, Italy, July 2019. Association for Computational Linguistics.

\bibitem{zhang2023safetybench}
Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, and Minlie Huang.
\newblock Safetybench: Evaluating the safety of large language models with multiple choice questions.
\newblock {\em arXiv preprint arXiv:2309.07045}, 2023.

\bibitem{zhao2023survey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et~al.
\newblock A survey of large language models.
\newblock {\em arXiv preprint arXiv:2303.18223}, 2023.

\bibitem{zheng2023judging}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric Xing, et~al.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\end{thebibliography}
