Estimating a vector $\mathbf{x}$ from noisy linear measurements
$\mathbf{Ax}+\mathbf{w}$ often requires use of prior knowledge or structural
constraints on $\mathbf{x}$ for accurate reconstruction. Several recent works
have considered combining linear least-squares estimation with a generic or
"plug-in" denoiser function that can be designed in a modular manner based on
the prior knowledge about $\mathbf{x}$. While these methods have shown
excellent performance, it has been difficult to obtain rigorous performance
guarantees. This work considers plug-in denoising combined with the
recently-developed Vector Approximate Message Passing (VAMP) algorithm, which
is itself derived via Expectation Propagation techniques. It shown that the
mean squared error of this "plug-and-play" VAMP can be exactly predicted for
high-dimensional right-rotationally invariant random $\mathbf{A}$ and Lipschitz
denoisers. The method is demonstrated on applications in image recovery and
parametric bilinear estimation.