\begin{thebibliography}{10}

\bibitem{xu2021bayesian}
Kai Xu, Akash Srivastava, Dan Gutfreund, Felix Sosa, Tomer Ullman, Josh
  Tenenbaum, and Charles Sutton.
\newblock A bayesian-symbolic approach to reasoning and learning in intuitive
  physics.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{cranmer2006discovering}
Miles Cranmer, Alvaro Sanchez-Gonzalez, Peter Battaglia, Rui Xu, Kyle Cranmer,
  David Spergel, and Shirley Ho.
\newblock Discovering symbolic models from deep learning with inductive biases
  (2020).
\newblock {\em arXiv preprint arXiv:2006.11287}, 2006.

\bibitem{li2020ngs}
Qing Li, Siyuan Huang, Yining Hong, Yixin Chen, Ying~Nian Wu, and Song-Chun.
  Zhu.
\newblock Closed loop neural-symbolic learning via integrating neural
  perception, grammar parsing, and symbolic reasoning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2020.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{lu2021learning}
Yuchen Lu, Yikang Shen, Siyuan Zhou, Aaron Courville, Joshua~B Tenenbaum, and
  Chuang Gan.
\newblock Learning task decomposition with ordered memory policy network.
\newblock {\em arXiv preprint arXiv:2103.10972}, 2021.

\bibitem{yang2021program}
Yichen Yang, Jeevana~Priya Inala, Osbert Bastani, Yewen Pu, Armando
  Solar-Lezama, and Martin Rinard.
\newblock Program synthesis guided reinforcement learning for partially
  observed environments.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{landajuela2021discovering}
Mikel Landajuela, Brenden~K Petersen, Sookyung Kim, Claudio~P Santiago, Ruben
  Glatt, Nathan Mundhenk, Jacob~F Pettit, and Daniel Faissol.
\newblock Discovering symbolic policies with deep reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  5979--5989. PMLR, 2021.

\bibitem{han2020neuro}
Jiankai Sun1 Hao Sun1~Tian Han and Bolei Zhou.
\newblock Neuro-symbolic program search for autonomous driving decision module
  design.
\newblock In {\em Conference on Robot Learning (CoRL)}, 2020.

\bibitem{zhao2021proto}
Zelin Zhao, Karan Samel, Binghong Chen, et~al.
\newblock Proto: Program-guided transformer for program-guided tasks.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{sun2019program}
Shao-Hua Sun, Te-Lin Wu, and Joseph~J Lim.
\newblock Program guided agent.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{gershman2017reinforcement}
Samuel~J Gershman.
\newblock Reinforcement learning and causal models.
\newblock {\em The Oxford handbook of causal reasoning}, 1:295, 2017.

\bibitem{zhang2020invariant}
Amy Zhang, Clare Lyle, Shagun Sodhani, Angelos Filos, Marta Kwiatkowska, Joelle
  Pineau, Yarin Gal, and Doina Precup.
\newblock Invariant causal prediction for block mdps.
\newblock In {\em International Conference on Machine Learning}, pages
  11214--11224. PMLR, 2020.

\bibitem{tomar2021model}
Manan Tomar, Amy Zhang, Roberto Calandra, Matthew~E Taylor, and Joelle Pineau.
\newblock Model-invariant state abstractions for model-based reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:2102.09850}, 2021.

\bibitem{sontakke2021causal}
Sumedh~A Sontakke, Arash Mehrjou, Laurent Itti, and Bernhard Sch{\"o}lkopf.
\newblock Causal curiosity: Rl agents discovering self-supervised experiments
  for causal representation learning.
\newblock In {\em International Conference on Machine Learning}, pages
  9848--9858. PMLR, 2021.

\bibitem{sodhani2022improving}
Shagun Sodhani, Sergey Levine, and Amy Zhang.
\newblock Improving generalization with approximate factored value functions.
\newblock In {\em ICLR2022 Workshop on the Elements of Reasoning: Objects,
  Structure and Causality}, 2022.

\bibitem{bica2021invariant}
Ioana Bica, Daniel Jarrett, and Mihaela van~der Schaar.
\newblock Invariant causal imitation learning for generalizable policies.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{han2021learning}
Beining Han, Chongyi Zheng, Harris Chan, Keiran Paster, Michael Zhang, and
  Jimmy Ba.
\newblock Learning domain invariant representations in goal-conditioned block
  mdps.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{wangtask}
Zizhao Wang, Xuesu Xiao, Yuke Zhu, and Peter Stone.
\newblock Task-independent causal state abstraction.
\newblock {\em Workshop on Robot Learning: Self-Supervised and Lifelong
  Learning, NeurIPS}, 2021.

\bibitem{volodin2020resolving}
Sergei Volodin, Nevan Wichers, and Jeremy Nixon.
\newblock Resolving spurious correlations in causal models of environments via
  interventions.
\newblock {\em arXiv preprint arXiv:2002.05217}, 2020.

\bibitem{seitzer2021causal}
Maximilian Seitzer, Bernhard Sch{\"o}lkopf, and Georg Martius.
\newblock Causal influence detection for improving efficiency in reinforcement
  learning.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{gasse2021causal}
Maxime Gasse, Damien Grasset, Guillaume Gaudron, and Pierre-Yves Oudeyer.
\newblock Causal reinforcement learning using observational and interventional
  data.
\newblock {\em arXiv preprint arXiv:2106.14421}, 2021.

\bibitem{abel2022theory}
David Abel.
\newblock A theory of abstraction in reinforcement learning.
\newblock {\em arXiv preprint arXiv:2203.00397}, 2022.

\bibitem{shanahan2022abstraction}
Murray Shanahan and Melanie Mitchell.
\newblock Abstraction for deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:2202.05839}, 2022.

\bibitem{abel2018state}
David Abel, Dilip Arumugam, Lucas Lehnert, and Michael Littman.
\newblock State abstractions for lifelong reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages 10--19.
  PMLR, 2018.

\bibitem{nair2019causal}
Suraj Nair, Yuke Zhu, Silvio Savarese, and Li~Fei-Fei.
\newblock Causal induction from visual observations for goal directed tasks.
\newblock {\em arXiv preprint arXiv:1910.01751}, 2019.

\bibitem{liu2022goal}
Minghuan Liu, Menghui Zhu, and Weinan Zhang.
\newblock Goal-conditioned reinforcement learning: Problems and solutions.
\newblock {\em arXiv preprint arXiv:2201.08299}, 2022.

\bibitem{levine2018reinforcement}
Sergey Levine.
\newblock Reinforcement learning and control as probabilistic inference:
  Tutorial and review.
\newblock {\em arXiv preprint arXiv:1805.00909}, 2018.

\bibitem{boutilier2000stochastic}
Craig Boutilier, Richard Dearden, and Mois{\'e}s Goldszmidt.
\newblock Stochastic dynamic programming with factored representations.
\newblock {\em Artificial intelligence}, 121(1-2):49--107, 2000.

\bibitem{peters2017elements}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock {\em Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem{spirtes2000causation}
Peter Spirtes, Clark~N Glymour, Richard Scheines, and David Heckerman.
\newblock {\em Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem{pitis2020counterfactual}
Silviu Pitis, Elliot Creager, and Animesh Garg.
\newblock Counterfactual data augmentation using locally factored dynamics.
\newblock {\em Advances in Neural Information Processing Systems},
  33:3976--3990, 2020.

\bibitem{abdolmaleki2018maximum}
Abbas Abdolmaleki, Jost~Tobias Springenberg, Yuval Tassa, Remi Munos, Nicolas
  Heess, and Martin Riedmiller.
\newblock Maximum a posteriori policy optimisation.
\newblock {\em arXiv preprint arXiv:1806.06920}, 2018.

\bibitem{marino2019inference}
Joseph Marino and Yisong Yue.
\newblock An inference perspective on model-based reinforcement learning.
\newblock In {\em ICML Workshop on Generative Modeling and Model-Based
  Reasoning for Robotics and AI}, 2019.

\bibitem{andrychowicz2017hindsight}
Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong,
  Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter~Abbeel, and Wojciech
  Zaremba.
\newblock Hindsight experience replay.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{chung2014empirical}
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em arXiv preprint arXiv:1412.3555}, 2014.

\bibitem{camacho2013model}
Eduardo~F Camacho and Carlos~Bordons Alba.
\newblock {\em Model predictive control}.
\newblock Springer science \& business media, 2013.

\bibitem{richards2005robust}
Arthur~George Richards.
\newblock {\em Robust constrained model predictive control}.
\newblock PhD thesis, Massachusetts Institute of Technology, 2005.

\bibitem{wang2019benchmarking}
Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric
  Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, and Jimmy Ba.
\newblock Benchmarking model-based reinforcement learning.
\newblock {\em arXiv preprint arXiv:1907.02057}, 2019.

\bibitem{chickering2002optimal}
David~Maxwell Chickering.
\newblock Optimal structure identification with greedy search.
\newblock {\em Journal of machine learning research}, 3(Nov):507--554, 2002.

\bibitem{chalupka2018fast}
Krzysztof Chalupka, Pietro Perona, and Frederick Eberhardt.
\newblock Fast conditional independence test for vector variables with large
  sample sizes.
\newblock {\em arXiv preprint arXiv:1804.02747}, 2018.

\bibitem{canonne2018testing}
Cl{\'e}ment~L Canonne, Ilias Diakonikolas, Daniel~M Kane, and Alistair Stewart.
\newblock Testing conditional independence of discrete distributions.
\newblock In {\em 2018 Information Theory and Applications Workshop (ITA)},
  pages 1--57. IEEE, 2018.

\bibitem{shah2020hardness}
Rajen~D Shah and Jonas Peters.
\newblock The hardness of conditional independence testing and the generalised
  covariance measure.
\newblock {\em The Annals of Statistics}, 48(3):1514--1538, 2020.

\bibitem{ke2021systematic}
Nan~Rosemary Ke, Aniket Didolkar, Sarthak Mittal, Anirudh Goyal, Guillaume
  Lajoie, Stefan Bauer, Danilo Rezende, Yoshua Bengio, Michael Mozer, and
  Christopher Pal.
\newblock Systematic evaluation of causal discovery in visual model based
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:2107.00848}, 2021.

\bibitem{ahmed2020causalworld}
Ossama Ahmed, Frederik Tr{\"a}uble, Anirudh Goyal, Alexander Neitz, Yoshua
  Bengio, Bernhard Sch{\"o}lkopf, Manuel W{\"u}thrich, and Stefan Bauer.
\newblock Causalworld: A robotic manipulation benchmark for causal structure
  and transfer learning.
\newblock {\em arXiv preprint arXiv:2010.04296}, 2020.

\bibitem{gym_minigrid}
Maxime Chevalier-Boisvert, Lucas Willems, and Suman Pal.
\newblock Minimalistic gridworld environment for openai gym.
\newblock \url{https://github.com/maximecb/gym-minigrid}, 2018.

\bibitem{tavares2021language}
Zenna Tavares, James Koppel, Xin Zhang, Ria Das, and Armando Solar-Lezama.
\newblock A language for counterfactual generative models.
\newblock In {\em International Conference on Machine Learning}, pages
  10173--10182. PMLR, 2021.

\bibitem{highway-env}
Edouard Leurent.
\newblock An environment for autonomous driving decision-making.
\newblock \url{https://github.com/eleurent/highway-env}, 2018.

\bibitem{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In {\em International conference on machine learning}, pages
  1861--1870. PMLR, 2018.

\bibitem{ross2011no}
St{\'e}phane Ross, Geoffrey~J Gordon, and J~Andrew Bagnell.
\newblock No-regret reductions for imitation learning and structured
  prediction.
\newblock In {\em In AISTATS}. Citeseer, 2011.

\bibitem{chua2018deep}
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{schlichtkrull2018modeling}
Michael Schlichtkrull, Thomas~N Kipf, Peter Bloem, Rianne van~den Berg, Ivan
  Titov, and Max Welling.
\newblock Modeling relational data with graph convolutional networks.
\newblock In {\em European semantic web conference}, pages 593--607. Springer,
  2018.

\bibitem{zhu2022offline}
Zheng-Mao Zhu, Xiong-Hui Chen, Hong-Long Tian, Kun Zhang, and Yang Yu.
\newblock Offline reinforcement learning with causal structured world models.
\newblock {\em arXiv preprint arXiv:2206.01474}, 2022.

\bibitem{tsamardinos2006max}
Ioannis Tsamardinos, Laura~E Brown, and Constantin~F Aliferis.
\newblock The max-min hill-climbing bayesian network structure learning
  algorithm.
\newblock {\em Machine learning}, 65(1):31--78, 2006.

\bibitem{brouillard2020differentiable}
Philippe Brouillard, S{\'e}bastien Lachapelle, Alexandre Lacoste, Simon
  Lacoste-Julien, and Alexandre Drouin.
\newblock Differentiable causal discovery from interventional data.
\newblock {\em arXiv preprint arXiv:2007.01754}, 2020.

\bibitem{kipf2019compile}
Thomas Kipf, Yujia Li, Hanjun Dai, Vinicius Zambaldi, Alvaro Sanchez-Gonzalez,
  Edward Grefenstette, Pushmeet Kohli, and Peter Battaglia.
\newblock Compile: Compositional imitation learning and execution.
\newblock In {\em International Conference on Machine Learning}, pages
  3418--3428. PMLR, 2019.

\bibitem{xu2019regression}
Danfei Xu, Roberto Mart{\'\i}n-Mart{\'\i}n, De-An Huang, Yuke Zhu, Silvio
  Savarese, and Li~F Fei-Fei.
\newblock Regression planning networks.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{huang2019neural}
De-An Huang, Suraj Nair, Danfei Xu, Yuke Zhu, Animesh Garg, Li~Fei-Fei, Silvio
  Savarese, and Juan~Carlos Niebles.
\newblock Neural task graphs: Generalizing to unseen tasks from a single video
  demonstration.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8565--8574, 2019.

\bibitem{garnelo2016towards}
Marta Garnelo, Kai Arulkumaran, and Murray Shanahan.
\newblock Towards deep symbolic reinforcement learning.
\newblock {\em arXiv preprint arXiv:1609.05518}, 2016.

\bibitem{kostrikov2020image}
Ilya Kostrikov, Denis Yarats, and Rob Fergus.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock {\em arXiv preprint arXiv:2004.13649}, 2020.

\bibitem{hansen2021stabilizing}
Nicklas Hansen, Hao Su, and Xiaolong Wang.
\newblock Stabilizing deep q-learning with convnets and vision transformers
  under data augmentation.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{srinivas2020curl}
Aravind Srinivas, Michael Laskin, and Pieter Abbeel.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:2004.04136}, 2020.

\bibitem{hansen2021generalization}
Nicklas Hansen and Xiaolong Wang.
\newblock Generalization in reinforcement learning by soft data augmentation.
\newblock In {\em 2021 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 13611--13617. IEEE, 2021.

\bibitem{lee2019network}
Kimin Lee, Kibok Lee, Jinwoo Shin, and Honglak Lee.
\newblock Network randomization: A simple technique for generalization in deep
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1910.05396}, 2019.

\bibitem{raileanu2021automatic}
Roberta Raileanu, Maxwell Goldstein, Denis Yarats, Ilya Kostrikov, and Rob
  Fergus.
\newblock Automatic data augmentation for generalization in reinforcement
  learning.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{tobin2017domain}
Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and
  Pieter Abbeel.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world.
\newblock In {\em 2017 IEEE/RSJ international conference on intelligent robots
  and systems (IROS)}, pages 23--30. IEEE, 2017.

\bibitem{mehta2020active}
Bhairav Mehta, Manfred Diaz, Florian Golemo, Christopher~J Pal, and Liam Paull.
\newblock Active domain randomization.
\newblock In {\em Conference on Robot Learning}, pages 1162--1176. PMLR, 2020.

\bibitem{prakash2019structured}
Aayush Prakash, Shaad Boochoon, Mark Brophy, David Acuna, Eric Cameracci,
  Gavriel State, Omer Shapira, and Stan Birchfield.
\newblock Structured domain randomization: Bridging the reality gap by
  context-aware synthetic data.
\newblock In {\em 2019 International Conference on Robotics and Automation
  (ICRA)}, pages 7249--7255. IEEE, 2019.

\bibitem{narvekar2020curriculum}
Sanmit Narvekar, Bei Peng, Matteo Leonetti, Jivko Sinapov, Matthew~E Taylor,
  and Peter Stone.
\newblock Curriculum learning for reinforcement learning domains: A framework
  and survey.
\newblock {\em arXiv preprint arXiv:2003.04960}, 2020.

\bibitem{schaul2015universal}
Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver.
\newblock Universal value function approximators.
\newblock In {\em International conference on machine learning}, pages
  1312--1320. PMLR, 2015.

\bibitem{trott2019keeping}
Alexander Trott, Stephan Zheng, Caiming Xiong, and Richard Socher.
\newblock Keeping your distance: Solving sparse reward tasks using
  self-balancing shaped rewards.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{nair2020goal}
Suraj Nair, Silvio Savarese, and Chelsea Finn.
\newblock Goal-aware prediction: Learning to model what matters.
\newblock In {\em International Conference on Machine Learning}, pages
  7207--7219. PMLR, 2020.

\bibitem{florensa2018automatic}
Carlos Florensa, David Held, Xinyang Geng, and Pieter Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In {\em International conference on machine learning}, pages
  1515--1528. PMLR, 2018.

\bibitem{ren2019exploration}
Zhizhou Ren, Kefan Dong, Yuan Zhou, Qiang Liu, and Jian Peng.
\newblock Exploration via hindsight goal generation.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{pitis2020maximum}
Silviu Pitis, Harris Chan, Stephen Zhao, Bradly Stadie, and Jimmy Ba.
\newblock Maximum entropy gain exploration for long horizon multi-goal
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  7750--7761. PMLR, 2020.

\bibitem{fang2019curriculum}
Meng Fang, Tianyi Zhou, Yali Du, Lei Han, and Zhengyou Zhang.
\newblock Curriculum-guided hindsight experience replay.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{tang2021hindsight}
Yunhao Tang and Alp Kucukelbir.
\newblock Hindsight expectation maximization for goal-conditioned reinforcement
  learning.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2863--2871. PMLR, 2021.

\bibitem{rudner2021outcome}
Tim~GJ Rudner, Vitchyr Pong, Rowan McAllister, Yarin Gal, and Sergey Levine.
\newblock Outcome-driven reinforcement learning via variational inference.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{madumal2020explainable}
Prashan Madumal, Tim Miller, Liz Sonenberg, and Frank Vetere.
\newblock Explainable reinforcement learning through a causal lens.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~34, pages 2493--2500, 2020.

\bibitem{ding2021causalaf}
Wenhao Ding, Haohong Lin, Bo~Li, and Ding Zhao.
\newblock Causalaf: Causal autoregressive flow for goal-directed
  safety-critical scenes generation.
\newblock {\em arXiv preprint arXiv:2110.13939}, 2021.

\bibitem{wang2022causal}
Zizhao Wang, Xuesu Xiao, Zifan Xu, Yuke Zhu, and Peter Stone.
\newblock Causal dynamics learning for task-independent state abstraction.
\newblock {\em arXiv preprint arXiv:2206.13452}, 2022.

\bibitem{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}, 2019.

\bibitem{glymour2019review}
Clark Glymour, Kun Zhang, and Peter Spirtes.
\newblock Review of causal discovery methods based on graphical models.
\newblock {\em Frontiers in genetics}, 10:524, 2019.

\bibitem{pearson1900x}
Karl Pearson.
\newblock X. on the criterion that a given system of deviations from the
  probable in the case of a correlated system of variables is such that it can
  be reasonably supposed to have arisen from random sampling.
\newblock {\em The London, Edinburgh, and Dublin Philosophical Magazine and
  Journal of Science}, 50(302):157--175, 1900.

\bibitem{zhang2012kernel}
Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock Kernel-based conditional independence test and application in causal
  discovery.
\newblock {\em arXiv preprint arXiv:1202.3775}, 2012.

\bibitem{hauser2012characterization}
Alain Hauser and Peter B{\"u}hlmann.
\newblock Characterization and greedy learning of interventional markov
  equivalence classes of directed acyclic graphs.
\newblock {\em The Journal of Machine Learning Research}, 13(1):2409--2464,
  2012.

\bibitem{neath2012bayesian}
Andrew~A Neath and Joseph~E Cavanaugh.
\newblock The bayesian information criterion: background, derivation, and
  applications.
\newblock {\em Wiley Interdisciplinary Reviews: Computational Statistics},
  4(2):199--203, 2012.

\bibitem{zhu2019causal}
Shengyu Zhu, Ignavier Ng, and Zhitang Chen.
\newblock Causal discovery with reinforcement learning.
\newblock {\em arXiv preprint arXiv:1906.04477}, 2019.

\bibitem{ke2019learning}
Nan~Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo Larochelle,
  Bernhard Sch{\"o}lkopf, Michael~C Mozer, Chris Pal, and Yoshua Bengio.
\newblock Learning neural causal models from unknown interventions.
\newblock {\em arXiv preprint arXiv:1910.01075}, 2019.

\bibitem{li2020causal}
Yunzhu Li, Antonio Torralba, Anima Anandkumar, Dieter Fox, and Animesh Garg.
\newblock Causal discovery in physical systems from videos.
\newblock {\em Advances in Neural Information Processing Systems},
  33:9180--9192, 2020.

\bibitem{scherrer2021learning}
Nino Scherrer, Olexa Bilaniuk, Yashas Annadani, Anirudh Goyal, Patrick Schwab,
  Bernhard Sch{\"o}lkopf, Michael~C Mozer, Yoshua Bengio, Stefan Bauer, and
  Nan~Rosemary Ke.
\newblock Learning neural causal models with active interventions.
\newblock {\em arXiv preprint arXiv:2109.02429}, 2021.

\bibitem{lindgren2018experimental}
Erik Lindgren, Murat Kocaoglu, Alexandros~G Dimakis, and Sriram Vishwanath.
\newblock Experimental design for cost-aware learning of causal graphs.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{Gilboa2019DynamicalIA}
Dar Gilboa, B.~Chang, Minmin Chen, Greg Yang, Samuel~S. Schoenholz, Ed~H. Chi,
  and Jeffrey Pennington.
\newblock Dynamical isometry and a mean field theory of lstms and grus.
\newblock {\em ArXiv}, abs/1901.08987, 2019.

\bibitem{Yang2018CharacterizingAL}
Karren~D. Yang, Abigail Katoff, and Caroline Uhler.
\newblock Characterizing and learning equivalence classes of causal dags under
  interventions.
\newblock In {\em ICML}, 2018.

\bibitem{pmlr-v119-addanki20a}
Raghavendra Addanki, Shiva Kasiviswanathan, Andrew Mcgregor, and Cameron Musco.
\newblock Efficient intervention design for causal discovery with latents.
\newblock In Hal~Daumé III and Aarti Singh, editors, {\em Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of {\em
  Proceedings of Machine Learning Research}, pages 63--73. PMLR, 13--18 Jul
  2020.

\bibitem{ding2022survey}
Wenhao Ding, Chejian Xu, Haohong Lin, Bo~Li, and Ding Zhao.
\newblock A survey on safety-critical scenario generation from methodological
  perspective.
\newblock {\em arXiv preprint arXiv:2202.02215}, 2022.

\end{thebibliography}
