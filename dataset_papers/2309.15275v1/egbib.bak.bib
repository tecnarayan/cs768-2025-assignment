@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{yang2023efficient,
  title={Efficient On-device Training via Gradient Filtering},
  author={Yang, Yuedong and Li, Guihong and Marculescu, Radu},
  journal={arXiv preprint arXiv:2301.00330},
  year={2023}
}

@inproceedings{liu2022swin,
  title={Swin transformer v2: Scaling up capacity and resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12009--12019},
  year={2022}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International conference on machine learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{zhao2022monovit,
  title={Monovit: Self-supervised monocular depth estimation with a vision transformer},
  author={Zhao, Chaoqiang and Zhang, Youmin and Poggi, Matteo and Tosi, Fabio and Guo, Xianda and Zhu, Zheng and Huang, Guan and Tang, Yang and Mattoccia, Stefano},
  journal={arXiv preprint arXiv:2208.03543},
  year={2022}
}

@article{agarwal2022depthformer,
  title={Depthformer: Multiscale Vision Transformer For Monocular Depth Estimation With Local Global Information Fusion},
  author={Agarwal, Ashutosh and Arora, Chetan},
  journal={arXiv preprint arXiv:2207.04535},
  year={2022}
}

@inproceedings{lin2023vision,
  title={Vision transformer for nerf-based view synthesis from a single input image},
  author={Lin, Kai-En and Lin, Yen-Chen and Lai, Wei-Sheng and Lin, Tsung-Yi and Shih, Yi-Chang and Ramamoorthi, Ravi},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={806--815},
  year={2023}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{zhang2021survey,
  title={A survey on federated learning},
  author={Zhang, Chen and Xie, Yu and Bai, Hang and Yu, Bin and Li, Weihong and Gao, Yuan},
  journal={Knowledge-Based Systems},
  volume={216},
  pages={106775},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{chen2021fedmax,
  title={Fedmax: mitigating activation divergence for accurate and communication-efficient federated learning},
  author={Chen, Wei and Bhardwaj, Kartikeya and Marculescu, Radu},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14--18, 2020, Proceedings, Part II},
  pages={348--363},
  year={2021},
  organization={Springer}
}


@inproceedings{yang2022anytime,
  title={Anytime Depth Estimation with Limited Sensing and Computation Capabilities on Mobile Devices},
  author={Yang, Yuedong and Xue, Zihui and Marculescu, Radu},
  booktitle={Conference on Robot Learning},
  pages={609--618},
  year={2022},
  organization={PMLR}
}

@article{li2021flash,
  title={FLASH: Fast Neural Architecture Search with Hardware Optimization},
  author={Li, Guihong and Mandal, Sumit K and Ogras, Umit Y and Marculescu, Radu},
  journal={ACM Transactions on Embedded Computing Systems (TECS)},
  volume={20},
  number={5s},
  pages={1--26},
  year={2021},
  publisher={ACM New York, NY}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    year={2016}
}

@book{ryser_1963, series={Carus Mathematical Monographs}, title={Combinatorial Mathematics}, DOI={10.5948/UPO9781614440147}, publisher={Mathematical Association of America}, author={Ryser, Herbert John}, year={1963}, collection={Carus Mathematical Monographs}}

@ARTICLE{1671278,
  author={Shanks, J.L.},
  journal={IEEE Transactions on Computers}, 
  title={Computation of the Fast Walsh-Fourier Transform}, 
  year={1969},
  volume={C-18},
  number={5},
  pages={457-459},
  doi={10.1109/T-C.1969.222685}}

@book{10.5555/22881,
author = {Gonzales, Rafael C. and Wintz, Paul},
title = {Digital Image Processing (2nd Ed.)},
year = {1987},
isbn = {0201110261},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}

@article{parseval1806memoire,
  title={M{\'e}moire sur les s{\'e}ries et sur l’int{\'e}gration compl{\`e}te d’une {\'e}quation aux diff{\'e}rences partielles lin{\'e}aires du second ordre, {\`a} coefficients constants},
  author={Parseval, Marc-Antoine},
  journal={M{\'e}m. pr{\'e}s. par divers savants, Acad. des Sciences, Paris,(1)},
  volume={1},
  pages={638--648},
  year={1806}
}

@article{cai2020tinytl,
  title={Tinytl: Reduce memory, not parameters for efficient on-device learning},
  author={Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11285--11297},
  year={2020}
}

@inproceedings{krause20133d,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={554--561},
  year={2013}
}

@InProceedings{Nilsback06,
  author       = "Maria-Elena Nilsback and Andrew Zisserman",
  title        = "A Visual Vocabulary for Flower Classification",
  booktitle    = "IEEE Conference on Computer Vision and Pattern Recognition",
  volume       = "2",
  pages        = "1447--1454",
  year         = "2006",
}

@inproceedings{bossard14,
  title = {Food-101 -- Mining Discriminative Components with Random Forests},
  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle = {European Conference on Computer Vision},
  year = {2014}
}

@InProceedings{parkhi12a,
  author       = "Omkar M. Parkhi and Andrea Vedaldi and Andrew Zisserman and C. V. Jawahar",
  title        = "Cats and Dogs",
  booktitle    = "IEEE Conference on Computer Vision and Pattern Recognition",
  year         = "2012",
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@techreport{WahCUB_200_2011,
	Title = {The Caltech-UCSD Birds-200-2011 Dataset},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@techreport{maji13fine-grained,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}

@misc{li2022efficientformer,
      title={EfficientFormer: Vision Transformers at MobileNet Speed}, 
      author={Yanyu Li and Geng Yuan and Yang Wen and Ju Hu and Georgios Evangelidis and Sergey Tulyakov and Yanzhi Wang and Jian Ren},
      year={2022},
      eprint={2206.01191},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{8100027,
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Scene Parsing through ADE20K Dataset}, 
  year={2017},
  volume={},
  number={},
  pages={5122-5130},
  doi={10.1109/CVPR.2017.544}}

@inproceedings{xie2021segformer,
  title={SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{Cordts2016Cityscapes,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}

@ARTICLE{2017arXiv170605587C,
       author = {{Chen}, Liang-Chieh and {Papandreou}, George and {Schroff}, Florian and {Adam}, Hartwig},
        title = "{Rethinking Atrous Convolution for Semantic Image Segmentation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2017,
        month = jun,
          eid = {arXiv:1706.05587},
        pages = {arXiv:1706.05587},
          doi = {10.48550/arXiv.1706.05587},
archivePrefix = {arXiv},
       eprint = {1706.05587},
 primaryClass = {cs.CV},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{lin2022device,
  title={On-device training under 256kb memory},
  author={Lin, Ji and Zhu, Ligeng and Chen, Wei-Ming and Wang, Wei-Chen and Gan, Chuang and Han, Song},
  journal={arXiv preprint arXiv:2206.15472},
  year={2022}
}

@inproceedings{guo2019spottune,
  title={Spottune: transfer learning through adaptive fine-tuning},
  author={Guo, Yunhui and Shi, Honghui and Kumar, Abhishek and Grauman, Kristen and Rosing, Tajana and Feris, Rogerio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4805--4814},
  year={2019}
}

@inproceedings{long2015learning,
  title={Learning transferable features with deep adaptation networks},
  author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael},
  booktitle={International conference on machine learning},
  pages={97--105},
  year={2015},
  organization={PMLR}
}

@article{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{li2022rethinking,
  title={Rethinking Vision Transformers for MobileNet Size and Speed},
  author={Li, Yanyu and Hu, Ju and Wen, Yang and Evangelidis, Georgios and Salahi, Kamyar and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
  journal={arXiv preprint arXiv:2212.08059},
  year={2022}
}

@inproceedings{chen2020statistical,
 author = {Chen, Jianfei and Gai, Yu and Yao, Zhewei and Mahoney, Michael W and Gonzalez, Joseph E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {883--894},
 publisher = {Curran Associates, Inc.},
 title = {A Statistical Framework for Low-bitwidth Training of Deep Neural Networks},
 volume = {33},
 year = {2020}
}

@inproceedings{banner2018scalable,
author = {Banner, Ron and Hubara, Itay and Hoffer, Elad and Soudry, Daniel},
title = {Scalable Methods for 8-Bit Training of Neural Networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Quantized Neural Networks (QNNs) are often used to improve network efficiency during the inference phase, i.e. after the network has been trained. Extensive research in the field suggests many different quantization schemes. Still, the number of bits required, as well as the best quantization scheme, are yet unknown. Our theoretical analysis suggests that most of the training process is robust to substantial precision reduction, and points to only a few specific operations that require higher precision. Armed with this knowledge, we quantize the model parameters, activations and layer gradients to 8-bit, leaving at a higher precision only the final step in the computation of the weight gradients. Additionally, as QNNs require batch-normalization to be trained at high precision, we introduce Range Batch-Normalization (BN) which has significantly higher tolerance to quantization noise and improved computational complexity. Our simulations show that Range BN is equivalent to the traditional batch norm if a precise scale adjustment, which can be approximated analytically, is applied. To the best of the authors' knowledge, this work is the first to quantize the weights, activations, as well as a substantial volume of the gradients stream, in all layers (including batch normalization) to 8-bit while showing state-of-the-art results over the ImageNet-1K dataset.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {5151–5159},
numpages = {9},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{sun2020ultra,
 author = {Sun, Xiao and Wang, Naigang and Chen, Chia-Yu and Ni, Jiamin and Agrawal, Ankur and Cui, Xiaodong and Venkataramani, Swagath and El Maghraoui, Kaoutar and Srinivasan, Vijayalakshmi (Viji) and Gopalakrishnan, Kailash},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1796--1807},
 publisher = {Curran Associates, Inc.},
 title = {Ultra-Low Precision 4-bit Training of Deep Neural Networks},
 volume = {33},
 year = {2020}
}

@article{hubara2017quantized,
author = {Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
title = {Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations},
year = {2017},
issue_date = {January 2017},
publisher = {JMLR.org},
volume = {18},
number = {1},
issn = {1532-4435},
abstract = {We introduce a method to train Quantized Neural Networks (QNNs) -- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At traintime the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51\% top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online.},
journal = {J. Mach. Learn. Res.},
month = {jan},
pages = {6869–6898},
numpages = {30},
keywords = {neural networks compression, computer vision, deep learning, energy efficient neural networks, language models}
}

@inproceedings{zhao2021distribution,
  title={Distribution adaptive int8 quantization for training cnns},
  author={Zhao, Kang and Huang, Sida and Pan, Pan and Li, Yinghan and Zhang, Yingya and Gu, Zhenyu and Xu, Yinghui},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={3483--3491},
  year={2021}
}

@article{hong2022efficient,
author = {Hong, Ziyang and Yue, C. Patrick},
title = {Efficient-Grad: Efficient Training Deep Convolutional Neural Networks on Edge Devices with Gradient Optimizations},
year = {2022},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1539-9087},
doi = {10.1145/3504034},
abstract = {With the prospering of mobile devices, the distributed learning approach, enabling model training with decentralized data, has attracted great interest from researchers. However, the lack of training capability for edge devices significantly limits the energy efficiency of distributed learning in real life. This article describes Efficient-Grad, an algorithm-hardware co-design approach for training deep convolutional neural networks, which improves both throughput and energy saving during model training, with negligible validation accuracy loss.The key to Efficient-Grad is its exploitation of two observations. Firstly, the sparsity has potential for not only activation and weight, but gradients and the asymmetry residing in the gradients for the conventional back propagation (BP). Secondly, a dedicated hardware architecture for sparsity utilization and efficient data movement can be optimized to support the Efficient-Grad algorithm in a scalable manner. To the best of our knowledge, Efficient-Grad is the first approach that successfully adopts a feedback-alignment (FA)-based gradient optimization scheme for deep convolutional neural network training, which leads to its superiority in terms of energy efficiency. We present case studies to demonstrate that the Efficient-Grad design outperforms the prior arts by 3.72x in terms of energy efficiency.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {feb},
articleno = {19},
numpages = {24},
keywords = {Deep neural networks, edge computing, model training, gradient pruning, hardware acceleration}
}


@article{sung2022lst,
  title={Lst: Ladder side-tuning for parameter and memory efficient transfer learning},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  journal={arXiv preprint arXiv:2206.06522},
  year={2022}
}

