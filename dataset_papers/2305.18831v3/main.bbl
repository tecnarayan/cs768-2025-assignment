\providecommand{\href}[2]{#2}\begingroup\raggedright\begin{thebibliography}{10}

\bibitem{STEVENS200445}
S.~Stevens and G.~Clark, \href{https://dx.doi.org/https://doi.org/10.1016/B978-1-56053-592-8.50010-5}{``Chapter 6 - polysomnography,''} in {\em Sleep Medicine Secrets}, D.~STEVENS, ed., pp.~45--63.
\newblock Hanley \& Belfus, 2004.

\bibitem{MASS}
C.~O'Reilly, N.~Gosselin, and J.~Carrier, ``Montreal archive of sleep studies: an open-access resource for instrument benchmarking and exploratory research,'' \href{https://dx.doi.org/10.1111/jsr.12169}{{\em Journal of sleep research} {\bfseries 23} (06, 2014) }.

\bibitem{goldberger2000physiobank}
A.~L. Goldberger, L.~A. Amaral, L.~Glass, J.~M. Hausdorff, P.~C. Ivanov, R.~G. Mark, J.~E. Mietus, G.~B. Moody, C.-K. Peng, and H.~E. Stanley, ``{PhysioBank, PhysioToolkit, and PhysioNet}: components of a new research resource for complex physiologic signals,'' {\em circulation} {\bfseries 101} no.~23, (2000) e215--e220.

\bibitem{SHHS}
G.-Q. Zhang, L.~Cui, R.~Mueller, S.~Tao, M.~Kim, M.~Rueschman, S.~Mariani, D.~Mobley, and S.~Redline, ``The national sleep research resource: Towards a sleep data commons,'' \href{https://dx.doi.org/10.1145/3233547.3233725}{{\em Journal of the American Medical Informatics Association} (08, 2018) 572--572}.

\bibitem{apicella2023effects}
A.~Apicella, F.~Isgrò, A.~Pollastro, and R.~Prevete, ``On the effects of data normalisation for domain adaptation on {EEG} data,'' \href{https://arxiv.org/abs/2210.01081}{{\ttfamily arXiv:2210.01081 [cs.LG]}}.

\bibitem{chambon2017deep}
S.~Chambon, M.~Galtier, P.~Arnal, G.~Wainrib, and A.~Gramfort, ``A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series,'' \href{https://arxiv.org/abs/1707.03321}{{\ttfamily arXiv:1707.03321 [stat.ML]}}.

\bibitem{Supratak_2017}
A.~Supratak, H.~Dong, C.~Wu, and Y.~Guo, ``{DeepSleepNet}: A model for automatic sleep stage scoring based on raw single-channel {EEG},'' \href{https://dx.doi.org/10.1109/tnsre.2017.2721116}{{\em {IEEE} Transactions on Neural Systems and Rehabilitation Engineering} {\bfseries 25} no.~11, nov1998--2008}.

\bibitem{Perslev2021Usleep}
M.~Perslev, S.~Darkner, L.~Kempfner, M.~Nikolic, P.~Jennum, and C.~Igel, ``{U-Sleep}: resilient high-frequency sleep staging,'' \href{https://dx.doi.org/10.1038/s41746-021-00440-5}{{\em npj Digital Medicine} {\bfseries 4} (04, 2021) 72}.

\bibitem{li2016revisiting}
Y.~Li, N.~Wang, J.~Shi, J.~Liu, and X.~Hou, ``Revisiting batch normalization for practical domain adaptation,'' {\em arXiv preprint arXiv:1603.04779} (2016) .

\bibitem{chehab2022deep}
O.~Chehab, A.~Defossez, J.-C. Loiseau, A.~Gramfort, and J.-R. King, ``Deep recurrent encoder: A scalable end-to-end network to model brain signals,'' \href{https://arxiv.org/abs/2103.02339}{{\ttfamily arXiv:2103.02339 [q-bio.NC]}}.

\bibitem{liu2022convolutional}
S.~Liu, X.~Li, Y.~Zhai, C.~You, Z.~Zhu, C.~Fernandez-Granda, and Q.~Qu, ``Convolutional normalization: Improving deep convolutional network robustness and training,'' \href{https://arxiv.org/abs/2103.00673}{{\ttfamily arXiv:2103.00673 [cs.CV]}}.

\bibitem{pmlr-v176-wei22a}
X.~Wei, A.~A. Faisal, {\em et~al.}, ``2021 {BEETL} competition: Advancing transfer learning for subject independence and heterogenous eeg data sets,'' in {\em Proceedings of the NeurIPS 2021 Competitions and Demonstrations Track}, D.~Kiela, M.~Ciccone, and B.~Caputo, eds., vol.~176 of {\em Proceedings of Machine Learning Research}, pp.~205--219.
\newblock PMLR, 06--14 dec, 2022.

\bibitem{csaky2023grouplevel}
R.~Csaky, M.~V. Es, O.~P. Jones, and M.~Woolrich, ``Group-level brain decoding with deep learning,'' \href{https://arxiv.org/abs/2205.14102}{{\ttfamily arXiv:2205.14102 [cs.LG]}}.

\bibitem{kobler2022spd}
R.~J. Kobler, J.~ichiro Hirayama, Q.~Zhao, and M.~Kawanabe, ``{SPD} domain-specific batch normalization to crack interpretable unsupervised domain adaptation in {EEG},'' \href{https://arxiv.org/abs/2206.01323}{{\ttfamily arXiv:2206.01323 [cs.LG]}}.

\bibitem{phan2023regu}
H.~Phan, E.~Heremans, O.~Y. Chén, P.~Koch, A.~Mertins, and M.~De~Vos, \href{https://dx.doi.org/10.1109/ICASSP49357.2023.10095805}{``Improving automatic sleep staging via temporal smoothness regularization,''} in {\em ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.~1--5.
\newblock 2023.

\bibitem{quinonero2008dataset}
J.~Quinonero-Candela, M.~Sugiyama, A.~Schwaighofer, and N.~D. Lawrence, {\em Dataset shift in machine learning}.
\newblock Mit Press, 2008.

\bibitem{sun2016deep}
B.~Sun and K.~Saenko, ``Deep {CORAL}: Correlation alignment for deep domain adaptation,'' \href{https://arxiv.org/abs/1607.01719}{{\ttfamily arXiv:1607.01719 [cs.CV]}}.

\bibitem{ganin2016domainadversarial}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette, M.~Marchand, and V.~Lempitsky, ``Domain-adversarial training of neural networks,'' \href{https://arxiv.org/abs/1505.07818}{{\ttfamily arXiv:1505.07818 [stat.ML]}}.

\bibitem{long2015learning}
M.~Long, Y.~Cao, J.~Wang, and M.~I. Jordan, ``Learning transferable features with deep adaptation networks,'' \href{https://arxiv.org/abs/1502.02791}{{\ttfamily arXiv:1502.02791 [cs.LG]}}.

\bibitem{damodaran2018deepjdot}
B.~B. Damodaran, B.~Kellenberger, R.~Flamary, D.~Tuia, and N.~Courty, ``{DeepJDOT}: Deep joint distribution optimal transport for unsupervised domain adaptation,'' \href{https://arxiv.org/abs/1803.10081}{{\ttfamily arXiv:1803.10081 [cs.CV]}}.

\bibitem{montesuma2021wasserstein}
E.~F. Montesuma and F.~M.~N. Mboula, ``Wasserstein barycenter for multi-source domain adaptation,'' in {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.~16785--16793.
\newblock 2021.

\bibitem{chen2022contrastive}
D.~Chen, D.~Wang, T.~Darrell, and S.~Ebrahimi, ``Contrastive test-time adaptation,'' \href{https://arxiv.org/abs/2204.10377}{{\ttfamily arXiv:2204.10377 [cs.CV]}}.

\bibitem{bhatia2019bures}
R.~Bhatia, T.~Jain, and Y.~Lim, ``On the bures--wasserstein distance between positive definite matrices,'' {\em Expositiones Mathematicae} {\bfseries 37} no.~2, (2019) 165--191.

\bibitem{peyre2020computational}
G.~Peyré and M.~Cuturi, ``Computational optimal transport,'' \href{https://arxiv.org/abs/1803.00567}{{\ttfamily arXiv:1803.00567 [stat.ML]}}.

\bibitem{Forrester_2015}
P.~J. Forrester and M.~Kieburg, ``Relating the {Bures} measure to the {Cauchy} two-matrix model,'' \href{https://dx.doi.org/10.1007/s00220-015-2435-4}{{\em Communications in Mathematical Physics} {\bfseries 342} no.~1, (Oct, 2015) 151--187}.

\bibitem{nadjahi2021fast}
K.~Nadjahi, A.~Durmus, P.~E. Jacob, R.~Badeau, and U.~Simsekli, ``Fast approximation of the sliced-{Wasserstein} distance using concentration of random projections,'' {\em Advances in Neural Information Processing Systems} {\bfseries 34} (2021) 12411--12424.

\bibitem{flamary2020concentration}
R.~Flamary, K.~Lounici, and A.~Ferrari, ``Concentration bounds for linear {Monge} mapping estimation and optimal transport domain adaptation,'' \href{https://arxiv.org/abs/1905.10155}{{\ttfamily arXiv:1905.10155 [stat.ML]}}.

\bibitem{fournier2015rate}
N.~Fournier and A.~Guillin, ``On the rate of convergence in wasserstein distance of the empirical measure,'' {\em Probability theory and related fields} {\bfseries 162} no.~3-4, (2015) 707--738.

\bibitem{agueh2011bary}
M.~Agueh and G.~Carlier, ``Barycenters in the wasserstein space,'' \href{https://dx.doi.org/10.1137/100805741}{{\em SIAM Journal on Mathematical Analysis} {\bfseries 43} no.~2, (2011) 904--924}, \href{https://arxiv.org/abs/https://doi.org/10.1137/100805741}{{\ttfamily https://doi.org/10.1137/100805741}}. \url{https://doi.org/10.1137/100805741}.

\bibitem{mroueh2019wasserstein}
Y.~Mroueh, ``Wasserstein style transfer,'' \href{https://arxiv.org/abs/1905.12828}{{\ttfamily arXiv:1905.12828 [cs.LG]}}.

\bibitem{kroshnin2021statistical}
A.~Kroshnin, V.~Spokoiny, and A.~Suvorikova, ``Statistical inference for {Bures--Wasserstein} barycenters,'' {\em The Annals of Applied Probability} {\bfseries 31} no.~3, (2021) 1264--1298.

\bibitem{Welch:67}
P.~Welch, ``The use of fast fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms,'' \href{https://dx.doi.org/10.1109/TAU.1967.1161901}{{\em IEEE Transactions on Audio and Electroacoustics} {\bfseries 15} no.~2, (1967) 70--73}.

\bibitem{oppen1996elec}
A.~V. Oppenheim, A.~S. Willsky, and S.~H. Nawab, {\em Signals \& Systems (2nd Ed.)}.
\newblock Prentice-Hall, Inc., USA, 1996.

\bibitem{bhatia2019matrix}
R.~Bhatia, S.~Gaubert, and T.~Jain, ``Matrix versions of the hellinger distance,'' {\em Letters in Mathematical Physics} {\bfseries 109} (2019) 1777--1804.

\bibitem{courty2014domain}
N.~Courty, R.~Flamary, and D.~Tuia, ``Domain adaptation with regularized optimal transport,'' in {\em Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part I 14}, pp.~274--289, Springer.
\newblock 2014.

\bibitem{xsleepnet}
H.~Phan, O.~Y. Chen, M.~C. Tran, P.~Koch, A.~Mertins, and M.~D. Vos, ``{XSleepNet}: Multi-view sequential model for automatic sleep staging,'' \href{https://dx.doi.org/10.1109/TPAMI.2021.3070057}{{\em IEEE Transactions on Pattern Analysis and Machine Intelligence} {\bfseries 44} no.~09, (Sep, 2022) 5903--5915}.

\bibitem{SHHS2}
S.~Quan, B.~Howard, {\em et~al.}, ``The sleep heart health study: Design, rationale, and methods,'' \href{https://dx.doi.org/10.1093/sleep/20.12.1077}{{\em Sleep} {\bfseries 20} (01, 1998) 1077--85}.

\bibitem{Stephansen_2018}
J.~B. Stephansen, A.~N. Olesen, {\em et~al.}, ``Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy,'' \href{https://dx.doi.org/10.1038/s41467-018-07229-3}{{\em Nature Communications} {\bfseries 9} no.~1, (Dec, 2018) }.

\bibitem{Appelhoff2019}
S.~Appelhoff, M.~Sanderson, {\em et~al.}, ``{MNE-BIDS}: Organizing electrophysiological data into the {BIDS} format and facilitating their analysis,'' \href{https://dx.doi.org/10.21105/joss.01896}{{\em Journal of Open Source Software} {\bfseries 4} no.~44, (2019) 1896}.

\bibitem{GramfortEtAl2013a}
A.~Gramfort, M.~Luessi, {\em et~al.}, ``{{MEG}} and {{EEG}} data analysis with {{MNE}}-{{Python}},'' \href{https://dx.doi.org/10.3389/fnins.2013.00267}{{\em Frontiers in Neuroscience} {\bfseries 7} no.~267, (2013) 1--13}.

\bibitem{Eldele2021atten}
E.~Eldele, Z.~Chen, C.~Liu, M.~Wu, C.-K. Kwoh, X.~Li, and C.~Guan, ``An attention-based deep learning approach for sleep stage classification with single-channel {EEG},'' \href{https://dx.doi.org/10.1109/TNSRE.2021.3076234}{{\em IEEE Transactions on Neural Systems and Rehabilitation Engineering} {\bfseries 29} (2021) 809--818}.

\bibitem{braindecode}
R.~T. Schirrmeister, J.~T. Springenberg, L.~D.~J. Fiederer, M.~Glasstetter, K.~Eggensperger, M.~Tangermann, F.~Hutter, W.~Burgard, and T.~Ball, ``Deep learning with convolutional neural networks for {EEG} decoding and visualization,'' \href{https://dx.doi.org/10.1002/hbm.23730}{{\em Human Brain Mapping} (Aug, 2017) }.

\bibitem{salvador2022reproducible}
T.~Salvador, K.~Fatras, I.~Mitliagkas, and A.~Oberman, ``A reproducible and realistic evaluation of partial domain adaptation methods,'' \href{https://arxiv.org/abs/2210.01210}{{\ttfamily arXiv:2210.01210 [cs.CV]}}.

\bibitem{wei2020federated}
K.~Wei, J.~Li, M.~Ding, C.~Ma, H.~H. Yang, F.~Farokhi, S.~Jin, T.~Q. Quek, and H.~V. Poor, ``Federated learning with differential privacy: Algorithms and performance analysis,'' {\em IEEE Transactions on Information Forensics and Security} {\bfseries 15} (2020) 3454--3469.

\bibitem{kairouz2021advances}
P.~Kairouz, H.~B. McMahan, {\em et~al.}, ``Advances and open problems in federated learning,'' {\em Foundations and Trends{\textregistered} in Machine Learning} {\bfseries 14} no.~1--2, (2021) 1--210.

\bibitem{harris_array_2020}
C.~R. Harris, K.~J. Millman, {\em et~al.}, ``Array programming with {NumPy},''. \url{https://www.nature.com/articles/s41586-020-2649-2}. Number: 7825 Publisher: Nature Publishing Group.

\bibitem{virtanen_scipy_2020}
P.~Virtanen, R.~Gommers, {\em et~al.}, ``{SciPy} 1.0: fundamental algorithms for scientific computing in python,''. \url{https://www.nature.com/articles/s41592-019-0686-2}. Number: 3 Publisher: Nature Publishing Group.

\bibitem{hunter_matplotlib_2007}
J.~D. Hunter, ``Matplotlib: A 2d graphics environment,''. Conference Name: Computing in Science \& Engineering.

\bibitem{waskom_seaborn_2021}
M.~L. Waskom, ``seaborn: statistical data visualization,''. \url{https://joss.theoj.org/papers/10.21105/joss.03021}.

\bibitem{paszke_pytorch_2019}
A.~Paszke, S.~Gross, {\em et~al.}, ``{PyTorch}: An imperative style, high-performance deep learning library,'' in {\em Advances in Neural Information Processing Systems}, vol.~32.
\newblock Curran Associates, Inc.
\newblock \url{https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html}.

\bibitem{Hobson1969AMO}
J.~A. Hobson, ``A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects: {A. Rechtschaffen and A. Kales} (editors). (public health service, u.s. government printing office, washington, d.c., 1968, 58 p., \$4.00),'' {\em Electroencephalography and Clinical Neurophysiology} {\bfseries 26} (1969) 644.

\bibitem{AASM}
C.~Iber, S.~Ancoli-Israel, A.~Chesson, and S.~Quan, ``The {AASM} manual for the scoring of sleep and associated events: Rules, terminology and technical specifications,'' {\em Westchester, IL: American Academy of Sleep Medicine} (01, 2007) .

\end{thebibliography}\endgroup
