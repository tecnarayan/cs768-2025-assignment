\providecommand{\AC}{A.-C}\providecommand{\CA}{C.-A}\providecommand{\CH}{C.-H}\providecommand{\CJ}{C.-J}\providecommand{\JC}{J.-C}\providecommand{\JP}{J.-P}\providecommand{\JB}{J.-B}\providecommand{\JF}{J.-F}\providecommand{\JJ}{J.-J}\providecommand{\JM}{J.-M}\providecommand{\KW}{K.-W}\providecommand{\PL}{P.-L}\providecommand{\RE}{R.-E}\providecommand{\SJ}{S.-J}\providecommand{\XR}{X.-R}\providecommand{\WX}{W.-X}
\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bach(2008)]{Bach08b}
Bach, F.
\newblock Bolasso: model consistent {Lasso} estimation through the bootstrap.
\newblock In \emph{ICML}, 2008.

\bibitem[Beck \& Teboulle(2009)Beck and Teboulle]{Beck_Teboulle09}
Beck, A. and Teboulle, M.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock \emph{SIAM J. Imaging Sci.}, 2\penalty0 (1):\penalty0 183--202, 2009.

\bibitem[Bickel et~al.(2009)Bickel, Ritov, and
  Tsybakov]{Bickel_Ritov_Tsybakov09}
Bickel, P.~J., Ritov, Y., and Tsybakov, A.~B.
\newblock Simultaneous analysis of {Lasso} and {D}antzig selector.
\newblock \emph{Ann. Statist.}, 37\penalty0 (4):\penalty0 1705--1732, 2009.

\bibitem[Bonnefoy et~al.(2014{\natexlab{a}})Bonnefoy, Emiya, Ralaivola, and
  Gribonval]{Bonnefoy_Emiya_Ralaivola_Gribonval14}
Bonnefoy, A., Emiya, V., Ralaivola, L., and Gribonval, R.
\newblock A dynamic screening principle for the lasso.
\newblock In \emph{EUSIPCO}, 2014{\natexlab{a}}.

\bibitem[Bonnefoy et~al.(2014{\natexlab{b}})Bonnefoy, Emiya, Ralaivola, and
  Gribonval]{Bonnefoy_Emiya_Ralaivola_Gribonval15}
Bonnefoy, A., Emiya, V., Ralaivola, L., and Gribonval, R.
\newblock {Dynamic Screening: Accelerating First-Order Algorithms for the Lasso
  and Group-Lasso}.
\newblock \emph{ArXiv e-prints}, 2014{\natexlab{b}}.

\bibitem[B{\"u}hlmann \& {van de Geer}(2011)B{\"u}hlmann and {van de
  Geer}]{Buhlmann_vandeGeer11}
B{\"u}hlmann, P. and {van de Geer}, S.
\newblock \emph{Statistics for high-dimensional data}.
\newblock Springer Series in Statistics. Springer, Heidelberg, 2011.
\newblock Methods, theory and applications.

\bibitem[Cand{\`e}s et~al.(2008)Cand{\`e}s, Wakin, and
  Boyd]{Candes_Wakin_Boyd08}
Cand{\`e}s, E.~J., Wakin, M.~B., and Boyd, S.~P.
\newblock Enhancing sparsity by reweighted {$l_1$} minimization.
\newblock \emph{J. Fourier Anal. Applicat.}, 14\penalty0 (5-6):\penalty0
  877--905, 2008.

\bibitem[Chambolle \& Pock(2011)Chambolle and Pock]{Chambolle_Pock11}
Chambolle, A. and Pock, T.
\newblock A first-order primal-dual algorithm for convex problems with
  applications to imaging.
\newblock \emph{J. Math. Imaging Vis.}, 40\penalty0 (1):\penalty0 120--145,
  2011.

\bibitem[Chen et~al.(1998)Chen, Donoho, and Saunders]{Chen_Donoho_Saunders98}
Chen, S.~S., Donoho, D.~L., and Saunders, M.~A.
\newblock Atomic decomposition by basis pursuit.
\newblock \emph{SIAM J. Sci. Comput.}, 20\penalty0 (1):\penalty0 33--61
  (electronic), 1998.

\bibitem[Efron et~al.(2004)Efron, Hastie, Johnstone, and
  Tibshirani]{Efron_Hastie_Johnstone_Tibshirani04}
Efron, B., Hastie, T., Johnstone, I.~M., and Tibshirani, R.
\newblock Least angle regression.
\newblock \emph{Ann. Statist.}, 32\penalty0 (2):\penalty0 407--499, 2004.
\newblock With discussion, and a rejoinder by the authors.

\bibitem[{El Ghaoui} et~al.(2012){El Ghaoui}, Viallon, and
  Rabbani]{ElGhaoui_Viallon_Rabbani12}
{El Ghaoui}, L., Viallon, V., and Rabbani, T.
\newblock Safe feature elimination in sparse supervised learning.
\newblock \emph{J. Pacific Optim.}, 8\penalty0 (4):\penalty0 667--698, 2012.

\bibitem[Fan \& Li(2001)Fan and Li]{Fan_Li01}
Fan, J. and Li, R.
\newblock Variable selection via nonconcave penalized likelihood and its oracle
  properties.
\newblock \emph{J. Amer. Statist. Assoc.}, 96\penalty0 (456):\penalty0
  1348--1360, 2001.

\bibitem[Fan \& Lv(2008)Fan and Lv]{Fan_Lv2008}
Fan, J. and Lv, J.
\newblock Sure independence screening for ultrahigh dimensional feature space.
\newblock \emph{J. Roy. Statist. Soc. Ser. B}, 70\penalty0 (5):\penalty0
  849--911, 2008.

\bibitem[Friedman et~al.(2007)Friedman, Hastie, H{\"o}fling, and
  Tibshirani]{Friedman_Hastie_Hofling_Tibshirani07}
Friedman, J., Hastie, T., H{\"o}fling, H., and Tibshirani, R.
\newblock Pathwise coordinate optimization.
\newblock \emph{Ann. Appl. Stat.}, 1\penalty0 (2):\penalty0 302--332, 2007.

\bibitem[Gramfort et~al.(2012)Gramfort, Kowalski, and
  H{\"a}m{\"a}l{\"a}inen]{Gramfort_Kowalski_Hamalainen12}
Gramfort, A., Kowalski, M., and H{\"a}m{\"a}l{\"a}inen, M.
\newblock Mixed-norm estimates for the {M/EEG} inverse problem using
  accelerated gradient methods.
\newblock \emph{Phys. Med. Biol.}, 57\penalty0 (7):\penalty0 1937--1961, 2012.

\bibitem[Haury et~al.(2012)Haury, Mordelet, Vera-Licona, and
  Vert]{Haury_Mordelet_Verra-Licona_Vert12}
Haury, {\AC}., Mordelet, F., Vera-Licona, P., and Vert, {\JP}.
\newblock {TIGRESS: Trustful Inference of Gene REgulation using Stability
  Selection.}
\newblock \emph{BMC systems biology}, 6\penalty0 (1):\penalty0 145, 2012.

\bibitem[Hiriart-Urruty \& Lemar{\'e}chal(1993)Hiriart-Urruty and
  Lemar{\'e}chal]{Hiriart-Urruty_Lemarechal93}
Hiriart-Urruty, {\JB}. and Lemar{\'e}chal, C.
\newblock \emph{Convex analysis and minimization algorithms. {I}}, volume 305.
\newblock Springer-Verlag, Berlin, 1993.

\bibitem[Kim et~al.(2007)Kim, Koh, Lustig, Boyd, and
  Gorinevsky]{Kim_Koh_Lustig_Boyd_Gorinevsky07}
Kim, {\SJ}., Koh, K., Lustig, M., Boyd, S., and Gorinevsky, D.
\newblock An interior-point method for large-scale {$l_1$}-regularized least
  squares.
\newblock \emph{IEEE J. Sel. Topics Signal Process.}, 1\penalty0 (4):\penalty0
  606--617, 2007.

\bibitem[Liang et~al.(2014)Liang, Fadili, and Peyr\'{e}]{Liang_Fadili_Peyere14}
Liang, J., Fadili, J., and Peyr\'{e}, G.
\newblock Local linear convergence of forward--backward under partial
  smoothness.
\newblock In \emph{NIPS}, pp.\  1970--1978, 2014.

\bibitem[Lustig et~al.(2007)Lustig, Donoho, and Pauly]{Lustig_Donoho_Pauly07}
Lustig, M., Donoho, D.~L., and Pauly, J.~M.
\newblock Sparse {MRI}: The application of compressed sensing for rapid {MR}
  imaging.
\newblock \emph{Magnetic Resonance in Medicine}, 58\penalty0 (6):\penalty0
  1182--1195, 2007.

\bibitem[Mairal(2010)]{Mairal}
Mairal, J.
\newblock \emph{Sparse coding for machine learning, image processing and
  computer vision}.
\newblock PhD thesis, {\'E}cole normale sup{\'e}rieure de Cachan, 2010.

\bibitem[Mairal \& Yu(2012)Mairal and Yu]{Mairal_Yu12}
Mairal, J. and Yu, B.
\newblock Complexity analysis of the lasso regularization path.
\newblock In \emph{ICML}, 2012.

\bibitem[Meinshausen \& B{\"u}hlmann(2010)Meinshausen and
  B{\"u}hlmann]{Meinshausen_Buhlmann10}
Meinshausen, N. and B{\"u}hlmann, P.
\newblock Stability selection.
\newblock \emph{J. Roy. Statist. Soc. Ser. B}, 72\penalty0 (4):\penalty0
  417--473, 2010.

\bibitem[Osborne et~al.(2000)Osborne, Presnell, and
  Turlach]{Osborne_Presnnell_Turlach00}
Osborne, M.~R., Presnell, B., and Turlach, B.~A.
\newblock A new approach to variable selection in least squares problems.
\newblock \emph{IMA J. Numer. Anal.}, 20\penalty0 (3):\penalty0 389--403, 2000.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{Pedregosa_etal11}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{J. Mach. Learn. Res.}, 12:\penalty0 2825--2830, 2011.

\bibitem[Rockafellar \& Wets(1998)Rockafellar and Wets]{Rockafellar_Wets98}
Rockafellar, R.~T. and Wets, R.~{\JB}.
\newblock \emph{Variational analysis}, volume 317 of \emph{Grundlehren der
  Mathematischen Wissenschaften [Fundamental Principles of Mathematical
  Sciences]}.
\newblock Springer-Verlag, Berlin, 1998.

\bibitem[Schmidt et~al.(2013)Schmidt, {Le Roux}, and
  Bach]{Schmidt_LeRoux_Bach13}
Schmidt, M., {Le Roux}, N., and Bach, F.
\newblock Minimizing finite sums with the stochastic average gradient.
\newblock \emph{arXiv preprint arXiv:1309.2388}, 2013.

\bibitem[Tibshirani(1996)]{Tibshirani96}
Tibshirani, R.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{J. Roy. Statist. Soc. Ser. B}, 58\penalty0 (1):\penalty0
  267--288, 1996.

\bibitem[Tibshirani et~al.(2012)Tibshirani, Bien, Friedman, Hastie, Simon,
  Taylor, and Tibshirani]{Tibshirani_Bien_Friedman_Hastie_Simon_Tibshirani12}
Tibshirani, R., Bien, J., Friedman, J., Hastie, T., Simon, N., Taylor, J., and
  Tibshirani, R.~J.
\newblock Strong rules for discarding predictors in lasso-type problems.
\newblock \emph{J. Roy. Statist. Soc. Ser. B}, 74\penalty0 (2):\penalty0
  245--266, 2012.

\bibitem[Tibshirani(2013)]{Tibshirani13}
Tibshirani, R.~J.
\newblock The lasso problem and uniqueness.
\newblock \emph{Electron. J. Stat.}, 7:\penalty0 1456--1490, 2013.

\bibitem[Tseng(2001)]{Tseng01}
Tseng, P.
\newblock Convergence of a block coordinate descent method for
  nondifferentiable minimization.
\newblock \emph{J. Optim. Theory Appl.}, 109\penalty0 (3):\penalty0 475--494,
  2001.

\bibitem[Varoquaux et~al.(2012)Varoquaux, Gramfort, and
  Thirion]{Varoquaux_Thirion_Gramfort12}
Varoquaux, G., Gramfort, A., and Thirion, B.
\newblock Small-sample brain mapping: sparse recovery on spatially correlated
  designs with randomization and clustering.
\newblock In \emph{ICML}, 2012.

\bibitem[Wang et~al.(2013)Wang, Zhou, Wonka, and Ye]{Wang_Zhou_Wonka_Ye13}
Wang, J., Zhou, J., Wonka, P., and Ye, J.
\newblock Lasso screening rules via dual polytope projection.
\newblock In \emph{NIPS}, pp.\  1070--1078, 2013.

\bibitem[Xiang \& Ramadge(2012)Xiang and Ramadge]{Xiang_Ramadge11}
Xiang, Z.~J. and Ramadge, P.~J.
\newblock Fast lasso screening tests based on correlations.
\newblock In \emph{ICASSP}, pp.\  2137--2140, 2012.

\bibitem[Xiang et~al.(2011)Xiang, Xu, and Ramadge]{Xiang_Xu_Ramadge11}
Xiang, Z.~J., Xu, H., and Ramadge, P.~J.
\newblock Learning sparse representations of high dimensional data on large
  scale dictionaries.
\newblock In \emph{NIPS}, pp.\  900--908, 2011.

\bibitem[Xiang et~al.(2014)Xiang, Wang, and Ramadge]{Xiang_Wang_Ramadge14}
Xiang, Z.~J., Wang, Y., and Ramadge, P.~J.
\newblock Screening tests for lasso problems.
\newblock \emph{arXiv preprint arXiv:1405.4897}, 2014.

\bibitem[Xu \& Ramadge(2013)Xu and Ramadge]{Xu_Ramadge13}
Xu, P. and Ramadge, P.~J.
\newblock Three structural results on the lasso problem.
\newblock In \emph{ICASSP}, pp.\  3392--3396, 2013.

\bibitem[Zhang(2010)]{Zhang10}
Zhang, {\CH}.
\newblock Nearly unbiased variable selection under minimax concave penalty.
\newblock \emph{Ann. Statist.}, 38\penalty0 (2):\penalty0 894--942, 2010.

\bibitem[Zhang \& Zhang(2012)Zhang and Zhang]{Zhang_Zhang12}
Zhang, {\CH}. and Zhang, T.
\newblock A general theory of concave regularization for high-dimensional
  sparse estimation problems.
\newblock \emph{Statistical Science}, 27\penalty0 (4):\penalty0 576--593, 2012.

\bibitem[Zou(2006)]{Zou06}
Zou, H.
\newblock The adaptive lasso and its oracle properties.
\newblock \emph{J. Am. Statist. Assoc.}, 101\penalty0 (476):\penalty0
  1418--1429, 2006.

\bibitem[Zou \& Hastie(2005)Zou and Hastie]{Zou_Hastie05}
Zou, H. and Hastie, T.
\newblock Regularization and variable selection via the elastic net.
\newblock \emph{J. Roy. Statist. Soc. Ser. B}, 67\penalty0 (2):\penalty0
  301--320, 2005.

\end{thebibliography}
