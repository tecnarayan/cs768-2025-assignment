% Related Works
@inproceedings{wolf2020huggin,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "EMNLP System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
}

@misc{hwang2020spade,
      title={Spatial Dependency Parsing for Semi-Structured Document Information Extraction}, 
      author={Wonseok Hwang and Jinyeong Yim and Seunghyun Park and Sohee Yang and Minjoon Seo},
      year={2020},
      eprint={2005.00642},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{hwang2019pot,
  title={Post-OCR parsing: building simple and robust parser via BIO tagging},
  author={Hwang, Wonseok and Kim, Seonghyeon and Yim, Jinyeong and Seo, Minjoon and Park, Seunghyun and Park, Sungrae and Lee, Junyeop and Lee, Bado and Lee, Hwalsuk},
  booktitle="Workshop on Document Intelligence at NeurIPS 2019",
  year={2019},
}

@inproceedings{hwang2021wyvern,
    title = "Cost-effective End-to-end Information Extraction for Semi-structured Document Images",
    author = "Hwang, Wonseok  and
      Lee, Hyunji  and
      Yim, Jinyeong  and
      Kim, Geewook  and
      Seo, Minjoon",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.271",
    doi = "10.18653/v1/2021.emnlp-main.271",
    pages = "3375--3383",
    abstract = "A real-world information extraction (IE) system for semi-structured document images often involves a long pipeline of multiple modules, whose complexity dramatically increases its development and maintenance cost. One can instead consider an end-to-end model that directly maps the input to the target output and simplify the entire process. However, such generation approach is known to lead to unstable performance if not designed carefully. Here we present our recent effort on transitioning from our existing pipeline-based IE system to an end-to-end system focusing on practical challenges that are associated with replacing and deploying the system in real, large-scale production. By carefully formulating document IE as a sequence generation task, we show that a single end-to-end IE system can be built and still achieve competent performance.",
}

@article{kim2021donut,
  title={Donut: Document Understanding Transformer without OCR},
  author={Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  journal={arXiv preprint arXiv:2111.15664},
  year={2021}
}

@inproceedings{park2019cord,
  title={CORD: A Consolidated Receipt Dataset for Post-OCR Parsing},
  author={Park, Seunghyun and Shin, Seung and Lee, Bado and Lee, Junyeop and Surh, Jaeheung and Seo, Minjoon and Lee, Hwalsuk},
  booktitle="Workshop on Document Intelligence at NeurIPS 2019",
  year={2019}
}


@article{hwang2019sqlova,
  author    = {Wonseok Hwang and
               Jinyeung Yim and
               Seunghyun Park and
               Minjoon Seo},
  title     = {A Comprehensive Exploration on WikiSQL with Table-Aware Word Contextualization},
  journal   = {CoRR},
  volume    = {abs/1902.01069},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.01069},
  archivePrefix = {arXiv},
  eprint    = {1902.01069},
  timestamp = {Fri, 01 Mar 2019 17:14:14 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-01069},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{park2021klue,
 author = {Park, Sungjoon and Moon, Jihyung and Kim, Sungdong and Cho, Won Ik and Han, Ji Yoon and Park, Jangwon and Song, Chisung and Kim, Junseong and Song, Youngsook and Oh, Taehwan and Lee, Joohong and Oh, Juhyun and Lyu, Sungwon and Jeong, Younghoon and Lee, Inkwon and Seo, Sangwoo and Lee, Dongjun and Kim, Hyunwoo and Lee, Myeonghwa and Jang, Seongbo and Do, Seungwon and Kim, Sunkyoung and Lim, Kyungtae and Lee, Jongwon and Park, Kyumin and Shin, Jamin and Kim, Seonghyun and Park, Lucy and Park, Lucy and Oh, Alice and Ha (NAVER AI Lab), Jung-Woo and Cho, Kyunghyun and Cho, Kyunghyun},
 booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
 editor = {J. Vanschoren and S. Yeung},
 pages = {},
 title = {KLUE: Korean Language Understanding Evaluation},
 url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/98dce83da57b0395e163467c9dae521b-Paper-round2.pdf},
 volume = {1},
 year = {2021}
}


@article{raffle2019t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@article{loshchilov2017adamw,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Fixing Weight Decay Regularization in Adam},
  journal   = {CoRR},
  volume    = {abs/1711.05101},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.05101},
  eprinttype = {arXiv},
  eprint    = {1711.05101},
  timestamp = {Mon, 13 Aug 2018 16:48:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-05101.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@inproceedings{chalkidis2019aclLJP,
    title = "Neural Legal Judgment Prediction in {E}nglish",
    author = "Chalkidis, Ilias  and
      Androutsopoulos, Ion  and
      Aletras, Nikolaos",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1424",
    doi = "10.18653/v1/P19-1424",
    pages = "4317--4323",
    abstract = "Legal judgment prediction is the task of automatically predicting the outcome of a court case, given a text describing the case{'}s facts. Previous work on using neural models for this task has focused on Chinese; only feature-based models (e.g., using bags of words and topics) have been considered in English. We release a new English legal judgment prediction dataset, containing cases from the European Court of Human Rights. We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks: (1) binary violation classification; (2) multi-label classification; (3) case importance prediction. We also explore if models are biased towards demographic information via data anonymization. As a side-product, we propose a hierarchical version of BERT, which bypasses BERT{'}s length limitation.",
}


@article{chalkidis2021multieurlex,
  title={MultiEURLEX--A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer},
  author={Chalkidis, Ilias and Fergadiotis, Manos and Androutsopoulos, Ion},
  journal={arXiv preprint arXiv:2109.00904},
  year={2021}
}

@inproceedings{tonguz2021NLLUautomatingPatent,
    title = "Automating Claim Construction in Patent Applications: The {CMU}mine Dataset",
    author = "Tonguz, Ozan  and
      Qin, Yiwei  and
      Gu, Yimeng  and
      Moon, Hyun Hannah",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.21",
    doi = "10.18653/v1/2021.nllp-1.21",
    pages = "205--209",
    abstract = "Intellectual Property (IP) in the form of issued patents is a critical and very desirable element of innovation in high-tech. In this position paper, we explore the possibility of automating the legal task of Claim Construction in patent applications via Natural Language Processing (NLP) and Machine Learning (ML). To this end, we first create a large dataset known as CMUmine{\mbox{$^\mbox{TM}$}}and then demonstrate that, using NLP and ML techniques the Claim Construction in patent applications, a crucial legal task currently performed by IP attorneys, can be automated. To the best of our knowledge, this is the first public patent application dataset. Our results look very promising in automating the patent application process.",
}

@article{yao2022FACLlevenEventDetection,
  title={LEVEN: A Large-Scale Chinese Legal Event Detection Dataset},
  author={Yao, Feng and Xiao, Chaojun and Wang, Xiaozhi and Liu, Zhiyuan and Hou, Lei and Tu, Cunchao and Li, Juanzi and Liu, Yun and Shen, Weixing and Sun, Maosong},
  journal={arXiv preprint arXiv:2203.08556},
  year={2022}
}

@book{ashley2017legal_analytics, place={Cambridge}, title={Artificial Intelligence and Legal Analytics: New Tools for Law Practice in the Digital Age}, DOI={10.1017/9781316761380}, publisher={Cambridge University Press}, author={Ashley, Kevin D.}, year={2017}}

@book{waterman1981legaldecision,
author="Waterman, D. A. and Mark A. Peterson",
title="Models of Legal Decisionmaking: Research Design and Methods",
address="Santa Monica, CA",
year="1981",
doi="",
publisher="RAND Corporation"
}

@inproceedings{ma2021sigarLJPRealCourtSetting, author = {Ma, Luyao and Zhang, Yating and Wang, Tianyi and Liu, Xiaozhong and Ye, Wei and Sun, Changlong and Zhang, Shikun}, title = {Legal Judgment Prediction with Multi-Stage Case Representation Learning in the Real Court Setting}, year = {2021}, isbn = {9781450380379}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3404835.3462945}, doi = {10.1145/3404835.3462945}, abstract = {Legal judgment prediction(LJP) is an essential task for legal AI. While prior methods studied on this topic in a pseudo setting by employing the judge-summarized case narrative as the input to predict the judgment, neglecting critical case life-cycle information in real court setting could threaten the case logic representation quality and prediction correctness. In this paper, we introduce a novel challenging dataset from real courtrooms to predict the legal judgment in a reasonably encyclopedic manner by leveraging the genuine input of the case - plaintiff's claims and court debate data, from which the case's facts are automatically recognized by comprehensively understanding the multi-role dialogues of the court debate, and then learnt to discriminate the claims so as to reach the final judgment through multi-task learning. An extensive set of experiments with a large civil trial data set shows that the proposed model can more accurately characterize the interactions among claims, fact and debate for legal judgment prediction, achieving significant improvements over strong state-of-the-art baselines. Moreover, the user study conducted with real judges and law school students shows the neural predictions can also be interpretable and easily observed, and thus enhancing the trial efficiency and judgment quality.}, booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval}, pages = {993–1002}, numpages = {10}, keywords = {multi-task learning, judgment prediction, case life-cycle}, location = {Virtual Event, Canada}, series = {SIGIR '21} }

@article{zhong2020aaai_ljp_qa_interpretable, title={Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/5479}, DOI={10.1609/aaai.v34i01.5479}, abstractNote={&lt;p&gt;&lt;strong&gt;L&lt;/strong&gt;egal &lt;strong&gt;J&lt;/strong&gt;udgment &lt;strong&gt;P&lt;/strong&gt;rediction (LJP) aims to predict judgment results according to the facts of cases. In recent years, LJP has drawn increasing attention rapidly from both academia and the legal industry, as it can provide references for legal practitioners and is expected to promote judicial justice. However, the research to date usually suffers from the lack of interpretability, which may lead to ethical issues like inconsistent judgments or gender bias. In this paper, we present QAjudge, a model based on reinforcement learning to visualize the prediction process and give interpretable judgments. QAjudge follows two essential principles in legal systems across the world: Presumption of Innocence and Elemental Trial. During inference, a Question Net will select questions from the given set and an Answer Net will answer the question according to the fact description. Finally, a Predict Net will produce judgment results based on the answers. Reward functions are designed to minimize the number of questions asked. We conduct extensive experiments on several real-world datasets. Experimental results show that QAjudge can provide interpretable judgments while maintaining comparable performance with other state-of-the-art LJP models. The codes can be found from https://github.com/thunlp/QAjudge.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhong, Haoxi and Wang, Yuzhong and Tu, Cunchao and Zhang, Tianyang and Liu, Zhiyuan and Sun, Maosong}, year={2020}, month={Apr.}, pages={1250-1257} }

@inproceedings{wu2020emnlp_court_view_gen,
    title = "De-Biased Court{'}s View Generation with Causality",
    author = "Wu, Yiquan  and
      Kuang, Kun  and
      Zhang, Yating  and
      Liu, Xiaozhong  and
      Sun, Changlong  and
      Xiao, Jun  and
      Zhuang, Yueting  and
      Si, Luo  and
      Wu, Fei",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.56",
    doi = "10.18653/v1/2020.emnlp-main.56",
    pages = "763--780",
    abstract = "Court{'}s view generation is a novel but essential task for legal AI, aiming at improving the interpretability of judgment prediction results and enabling automatic legal document generation. While prior text-to-text natural language generation (NLG) approaches can be used to address this problem, neglecting the confounding bias from the data generation mechanism can limit the model performance, and the bias may pollute the learning outcomes. In this paper, we propose a novel Attentional and Counterfactual based Natural Language Generation (AC-NLG) method, consisting of an attentional encoder and a pair of innovative counterfactual decoders. The attentional encoder leverages the plaintiff{'}s claim and fact description as input to learn a claim-aware encoder from which the claim-related information in fact description can be emphasized. The counterfactual decoders are employed to eliminate the confounding bias in data and generate judgment-discriminative court{'}s views (both supportive and non-supportive views) by incorporating with a synergistic judgment predictive model. Comprehensive experiments show the effectiveness of our method under both quantitative and qualitative evaluation metrics.",
}

@article{chalkidis2022FACL_doc_class_data_imblance,
  title={Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting},
  author={Chalkidis, Ilias and S{\o}gaard, Anders},
  journal={arXiv preprint arXiv:2203.07856},
  year={2022}
}
@inproceedings{chalkidis2019ACLeurlex,
    title = "Large-Scale Multi-Label Text Classification on {EU} Legislation",
    author = "Chalkidis, Ilias  and
      Fergadiotis, Emmanouil  and
      Malakasiotis, Prodromos  and
      Androutsopoulos, Ion",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1636",
    doi = "10.18653/v1/P19-1636",
    pages = "6314--6322",
    abstract = "We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, annotated with ∼4.3k EUROVOC labels, which is suitable for LMTC, few- and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with label-wise attention perform better than other current state of the art methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings further improve performance. We also find that considering only particular zones of the documents is sufficient. This allows us to bypass BERT{'}s maximum text length limit and fine-tune BERT, obtaining the best results in all but zero-shot learning cases.",
}

@inproceedings{hong2021nllu_ie_dialogue,
    title = "Learning from Limited Labels for Long Legal Dialogue",
    author = "Hong, Jenny  and
      Chong, Derek  and
      Manning, Christopher",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.20",
    doi = "10.18653/v1/2021.nllp-1.20",
    pages = "190--204",
    abstract = "We study attempting to achieve high accuracy information extraction of case factors from a challenging dataset of parole hearings, which, compared to other legal NLP datasets, has longer texts, with fewer labels. On this corpus, existing work directly applying pretrained neural models has failed to extract all but a few relatively basic items with little improvement over rule-based extraction. We address two challenges posed by existing work: training on long documents and reasoning over complex speech patterns. We use a similar approach to the two-step open-domain question answering approach by using a Reducer to extract relevant text segments and a Producer to generate both extractive answers and non-extractive classifications. In a context like ours, with limited labeled data, we show that a superior approach for strong performance within limited development time is to use a combination of a rule-based Reducer and a neural Producer. We study four representative tasks from the parole dataset. On all four, we improve extraction from the previous benchmark of 0.41{--}0.63 to 0.83{--}0.89 F1.",
}

@inproceedings{khazaeli2021nllu_qa,
    title = "A Free Format Legal Question Answering System",
    author = "Khazaeli, Soha  and
      Punuru, Janardhana  and
      Morris, Chad  and
      Sharma, Sanjay  and
      Staub, Bert  and
      Cole, Michael  and
      Chiu-Webster, Sunny  and
      Sakalley, Dhruv",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.11",
    doi = "10.18653/v1/2021.nllp-1.11",
    pages = "107--113",
    abstract = "We present an information retrieval-based question answer system to answer legal questions. The system is not limited to a predefined set of questions or patterns and uses both sparse vector search and embeddings for input to a BERT-based answer re-ranking system. A combination of general domain and legal domain data is used for training. This natural question answering system is in production and is used commercially.",
}

@inproceedings{niklaus2021nllu_swiss_ljp,
    title = "{S}wiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark",
    author = {Niklaus, Joel  and
      Chalkidis, Ilias  and
      St{\"u}rmer, Matthias},
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.3",
    doi = "10.18653/v1/2021.nllp-1.3",
    pages = "19--35",
    abstract = "In many jurisdictions, the excessive workload of courts leads to high delays. Suitable predictive AI models can assist legal professionals in their work, and thus enhance and speed up the process. So far, Legal Judgment Prediction (LJP) datasets have been released in English, French, and Chinese. We publicly release a multilingual (German, French, and Italian), diachronic (2000-2020) corpus of 85K cases from the Federal Supreme Court of Switzer- land (FSCS). We evaluate state-of-the-art BERT-based methods including two variants of BERT that overcome the BERT input (text) length limitation (up to 512 tokens). Hierarchical BERT has the best performance (approx. 68-70{\%} Macro-F1-Score in German and French). Furthermore, we study how several factors (canton of origin, year of publication, text length, legal area) affect performance. We release both the benchmark dataset and our code to accelerate future research and ensure reproducibility.",
}

@inproceedings{kapoor2022facl_hindi_legal_corpus,
    title = "{HLDC}: {H}indi Legal Documents Corpus",
    author = "Kapoor, Arnav  and
      Dhawan, Mudit  and
      Goel, Anmol  and
      T H, Arjun  and
      Bhatnagar, Akshala  and
      Agrawal, Vibhu  and
      Agrawal, Amul  and
      Bhattacharya, Arnab  and
      Kumaraguru, Ponnurangam  and
      Modi, Ashutosh",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.278",
    doi = "10.18653/v1/2022.findings-acl.278",
    pages = "3521--3536",
    abstract = "Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area.",
}


@inproceedings{koreeda2021contractnli-dataset,
    title = "{C}ontract{NLI}: A Dataset for Document-level Natural Language Inference for Contracts",
    author = "Koreeda, Yuta  and
      Manning, Christopher",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.164",
    doi = "10.18653/v1/2021.findings-emnlp.164",
    pages = "1907--1919",
    abstract = "Reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. In this work, we propose {``}document-level natural language inference (NLI) for contracts{''}, a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as {``}Some obligations of Agreement may survive termination.{''}) and a contract, and it is asked to classify whether each hypothesis is {``}entailed by{''}, {``}contradicting to{''} or {``}not mentioned by{''} (neutral to) the contract as well as identifying {``}evidence{''} for the decision as spans in the contract. We annotated and release the largest corpus to date consisting of 607 annotated contracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (a) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (b) employs more sophisticated context segmentation for dealing with long documents. We also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement.",
}

@inproceedings{chalkidis2022acl_lexglue,
    title = "{L}ex{GLUE}: A Benchmark Dataset for Legal Language Understanding in {E}nglish",
    author = "Chalkidis, Ilias  and
      Jana, Abhik  and
      Hartung, Dirk  and
      Bommarito, Michael  and
      Androutsopoulos, Ion  and
      Katz, Daniel  and
      Aletras, Nikolaos",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.297",
    doi = "10.18653/v1/2022.acl-long.297",
    pages = "4310--4330",
    abstract = "Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text. Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size. Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain. To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way. We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently offer performance improvements across multiple tasks.",
}


@inbook{rossi2021verbcl,
author = {Rossi, Julien and Vakulenko, Svitlana and Kanoulas, Evangelos},
title = {VerbCL: A Dataset of Verbatim Quotes for Highlight Extraction in Case Law},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482021},
abstract = {Citing legal opinions is a key part of legal argumentation, an expert task that requires retrieval, extraction and summarization of information from court decisions. The identification of legally salient parts in an opinion for the purpose of citation may be seen as a domain-specific formulation of a highlight extraction or passage retrieval task. As similar tasks in other domains such as web search show significant attention and improvement, progress in the legal domain is hindered by the lack of resources for training and evaluation. This paper presents a new dataset that consists of the citation graph of court opinions, which cite previously published court opinions in support of their arguments. In particular, we focus on the verbatim quotes, i.e., where the text of the original opinion is directly reused. With this approach, we explain the relative importance of different text spans of a court opinion by showcasing their usage in citations, and measuring their contribution to the relations between opinions in the citation graph. We release VerbCL, a large-scale dataset derived from CourtListener and introduce the task of highlight extraction as a single-document summarization task based on the citation graph establishing the first baseline results for this task on the VerbCL dataset.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {4554–4563},
numpages = {10}
}


@inproceedings{kim2021hyperclova,
    title = "What Changes Can Large-scale Language Models Bring? Intensive Study on {H}yper{CLOVA}: Billions-scale {K}orean Generative Pretrained Transformers",
    author = "Kim, Boseop  and
      Kim, HyoungSeok  and
      Lee, Sang-Woo  and
      Lee, Gichang  and
      Kwak, Donghyun  and
      Dong Hyeon, Jeon  and
      Park, Sunghyun  and
      Kim, Sungju  and
      Kim, Seonhoon  and
      Seo, Dongpil  and
      Lee, Heungsub  and
      Jeong, Minyoung  and
      Lee, Sungjae  and
      Kim, Minsub  and
      Ko, Suk Hyun  and
      Kim, Seokhun  and
      Park, Taeyong  and
      Kim, Jinuk  and
      Kang, Soyoung  and
      Ryu, Na-Hyeon  and
      Yoo, Kang Min  and
      Chang, Minsuk  and
      Suh, Soobin  and
      In, Sookyo  and
      Park, Jinseong  and
      Kim, Kyungduk  and
      Kim, Hiun  and
      Jeong, Jisu  and
      Yeo, Yong Goo  and
      Ham, Donghoon  and
      Park, Dongju  and
      Lee, Min Young  and
      Kang, Jaewook  and
      Kang, Inho  and
      Ha, Jung-Woo  and
      Park, Woomyoung  and
      Sung, Nako",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.274",
    doi = "10.18653/v1/2021.emnlp-main.274",
    pages = "3405--3424",
    abstract = "GPT-3 shows remarkable in-context learning ability of large-scale language models (LMs) trained on hundreds of billion scale data. Here we address some remaining issues less reported by the GPT-3 paper, such as a non-English LM, the performances of different sized models, and the effect of recently introduced prompt optimization on in-context learning. To achieve this, we introduce HyperCLOVA, a Korean variant of 82B GPT-3 trained on a Korean-centric corpus of 560B tokens. Enhanced by our Korean-specific tokenization, HyperCLOVA with our training configuration shows state-of-the-art in-context zero-shot and few-shot learning performances on various downstream tasks in Korean. Also, we show the performance benefits of prompt-based learning and demonstrate how it can be integrated into the prompt engineering pipeline. Then we discuss the possibility of materializing the No Code AI paradigm by providing AI prototyping capabilities to non-experts of ML by introducing HyperCLOVA studio, an interactive prompt engineering interface. Lastly, we demonstrate the potential of our methods with three successful in-house applications.",
}

@inproceedings{chalkidis2020legalbert,
    title = "{LEGAL}-{BERT}: The Muppets straight out of Law School",
    author = "Chalkidis, Ilias  and
      Fergadiotis, Manos  and
      Malakasiotis, Prodromos  and
      Aletras, Nikolaos  and
      Androutsopoulos, Ion",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.261",
    doi = "10.18653/v1/2020.findings-emnlp.261",
    pages = "2898--2904",
    abstract = "BERT has achieved impressive performance in several NLP tasks. However, there has been limited investigation on its adaptation guidelines in specialised domains. Here we focus on the legal domain, where we explore several approaches for applying BERT models to downstream legal tasks, evaluating on multiple datasets. Our findings indicate that the previous guidelines for pre-training and fine-tuning, often blindly followed, do not always generalize well in the legal domain. Thus we propose a systematic investigation of the available strategies when applying BERT in specialised domains. These are: (a) use the original BERT out of the box, (b) adapt BERT by additional pre-training on domain-specific corpora, and (c) pre-train BERT from scratch on domain-specific corpora. We also propose a broader hyper-parameter search space when fine-tuning for downstream tasks and we release LEGAL-BERT, a family of BERT models intended to assist legal NLP research, computational law, and legal technology applications.",
}


@inproceedings{
ghorbani2022scalinglaws,
title={Scaling Laws for Neural Machine Translation},
author={Behrooz Ghorbani and Orhan Firat and Markus Freitag and Ankur Bapna and Maxim Krikun and Xavier Garcia and Ciprian Chelba and Colin Cherry},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=hR_SMu8cxCV}
}


@inproceedings{brown2020gpt3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{gururangan2020dapt,
    title = "Don{'}t Stop Pretraining: Adapt Language Models to Domains and Tasks",
    author = "Gururangan, Suchin  and
      Marasovi{\'c}, Ana  and
      Swayamdipta, Swabha  and
      Lo, Kyle  and
      Beltagy, Iz  and
      Downey, Doug  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.740",
    doi = "10.18653/v1/2020.acl-main.740",
    pages = "8342--8360",
    abstract = "Language models pretrained on text from a wide variety of sources form the foundation of today{'}s NLP. In light of the success of these broad-coverage models, we investigate whether it is still helpful to tailor a pretrained model to the domain of a target task. We present a study across four domains (biomedical and computer science publications, news, and reviews) and eight classification tasks, showing that a second phase of pretraining in-domain (domain-adaptive pretraining) leads to performance gains, under both high- and low-resource settings. Moreover, adapting to the task{'}s unlabeled data (task-adaptive pretraining) improves performance even after domain-adaptive pretraining. Finally, we show that adapting to a task corpus augmented using simple data selection strategies is an effective alternative, especially when resources for domain-adaptive pretraining might be unavailable. Overall, we consistently find that multi-phase adaptive pretraining offers large gains in task performance.",
}


@misc{hoffmann2022chinchilla,
  doi = {10.48550/ARXIV.2203.15556},
  url = {https://arxiv.org/abs/2203.15556},
  author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and Driessche, George van den and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Training Compute-Optimal Large Language Models},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@inproceedings{
scao2022what_lm_limited_budget,
title={What Language Model to Train if You Have One Million {GPU} Hours?},
author={Teven Le Scao and Thomas Wang and Daniel Hesslow and Lucile Saulnier and Stas Bekman and M Saiful Bari and Stella Biderman and Hady Elsahar and Jason Phang and Ofir Press and Colin Raffel and Victor Sanh and Sheng Shen and Lintang Sutawika and Jaesung Tae and Zheng Xin Yong and Julien Launay and Iz Beltagy},
booktitle={Challenges {\&} Perspectives in Creating Large Language Models},
year={2022},
url={https://openreview.net/forum?id=rI7BL3fHIZq}
}

@article{wang2022what_language_decoder_only,
  title={What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?},
  author={Wang, Thomas and Roberts, Adam and Hesslow, Daniel and Scao, Teven Le and Chung, Hyung Won and Beltagy, Iz and Launay, Julien and Raffel, Colin},
  journal={arXiv preprint arXiv:2204.05832},
  year={2022}
}
@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{he2017maskrcnn,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@inproceedings{xue2021aclmt5,
    title = "m{T}5: A Massively Multilingual Pre-trained Text-to-Text Transformer",
    author = "Xue, Linting  and
      Constant, Noah  and
      Roberts, Adam  and
      Kale, Mihir  and
      Al-Rfou, Rami  and
      Siddhant, Aditya  and
      Barua, Aditya  and
      Raffel, Colin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.41",
    doi = "10.18653/v1/2021.naacl-main.41",
    pages = "483--498",
    abstract = "The recent {``}Text-to-Text Transfer Transformer{''} (T5) leveraged a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of English-language NLP tasks. In this paper, we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. We detail the design and modified training of mT5 and demonstrate its state-of-the-art performance on many multilingual benchmarks. We also describe a simple technique to prevent {``}accidental translation{''} in the zero-shot setting, where a generative model chooses to (partially) translate its prediction into the wrong language. All of the code and model checkpoints used in this work are publicly available.",
}
@inproceedings{glaser2021nllu_german_court_summarization,
    title = "Summarization of {G}erman Court Rulings",
    author = "Glaser, Ingo  and
      Moser, Sebastian  and
      Matthes, Florian",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nllp-1.19",
    doi = "10.18653/v1/2021.nllp-1.19",
    pages = "180--189",
    abstract = "Historically speaking, the German legal language is widely neglected in NLP research, especially in summarization systems, as most of them are based on English newspaper articles. In this paper, we propose the task of automatic summarization of German court rulings. Due to their complexity and length, it is of critical importance that legal practitioners can quickly identify the content of a verdict and thus be able to decide on the relevance for a given legal case. To tackle this problem, we introduce a new dataset consisting of 100k German judgments with short summaries. Our dataset has the highest compression ratio among the most common summarization datasets. German court rulings contain much structural information, so we create a pre-processing pipeline tailored explicitly to the German legal domain. Additionally, we implement multiple extractive as well as abstractive summarization systems and build a wide variety of baseline models. Our best model achieves a ROUGE-1 score of 30.50. Therefore with this work, we are laying the crucial groundwork for further research on German summarization systems.",
}

@article{hendrycks2021cuad,
      title={CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review}, 
      author={Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball},
      journal={NeurIPS},
      year={2021}
}

@article{xiao2018cail2018,
  title={Cail2018: A large-scale legal dataset for judgment prediction},
  author={Xiao, Chaojun and Zhong, Haoxi and Guo, Zhipeng and Tu, Cunchao and Liu, Zhiyuan and Sun, Maosong and Feng, Yansong and Han, Xianpei and Hu, Zhen and Wang, Heng and others},
  journal={arXiv preprint arXiv:1807.02478},
  year={2018}
}
@inproceedings{paul2022lesicin,
   author = {Paul, Shounak and Goyal, Pawan and Ghosh, Saptarshi},
   title = {{LeSICiN: A Heterogeneous Graph-based Approach for Automatic Legal Statute Identification from Indian Legal Documents}},
   booktitle = {{Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI)}},
   year = {2022}
}
  
  
@inproceedings{chalkidis2022facl_fairlex,
    title = "{F}air{L}ex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing",
    author = "Chalkidis, Ilias  and
      Pasini, Tommaso  and
      Zhang, Sheng  and
      Tomada, Letizia  and
      Schwemer, Sebastian  and
      S{\o}gaard, Anders",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.301",
    doi = "10.18653/v1/2022.acl-long.301",
    pages = "4389--4406",
    abstract = "We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities. Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP.",
}


@article{shin2022corpora_effect_hyperclova,
  title={On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model},
  author={Shin, Seongjin and Lee, Sang-Woo and Ahn, Hwijeen and Kim, Sungdong and Kim, HyoungSeok and Kim, Boseop and Cho, Kyunghyun and Lee, Gichang and Park, Woomyoung and Ha, Jung-Woo and others},
  journal={arXiv preprint arXiv:2204.13509},
  year={2022}
}

@ARTICLE{soltan2022arXiv_alexatm,
       author = {{Soltan}, Saleh and {Ananthakrishnan}, Shankar and {FitzGerald}, Jack and {Gupta}, Rahul and {Hamza}, Wael and {Khan}, Haidar and {Peris}, Charith and {Rawls}, Stephen and {Rosenbaum}, Andy and {Rumshisky}, Anna and {Prakash}, Chandana Satya and {Sridhar}, Mukund and {Triefenbach}, Fabian and {Verma}, Apurv and {Tur}, Gokhan and {Natarajan}, Prem},
        title = "{AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
         year = 2022,
        month = aug,
          eid = {arXiv:2208.01448},
        pages = {arXiv:2208.01448},
archivePrefix = {arXiv},
       eprint = {2208.01448},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220801448S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}




@Book{bishop:2006:PRML,
  author = 	 "Christopher M. Bishop",
  title = 	 "Pattern Recognition and Machine Learning",
  publisher = 	 "Springer",
  year = 	 "2006",
}

@inproceedings{louis2022acl_belgian_statutory_retrieval,
    title = "A Statutory Article Retrieval Dataset in {F}rench",
    author = "Louis, Antoine  and
      Spanakis, Gerasimos",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.468",
    doi = "10.18653/v1/2022.acl-long.468",
    pages = "6789--6803",
    abstract = "Statutory article retrieval is the task of automatically retrieving law articles relevant to a legal question. While recent advances in natural language processing have sparked considerable interest in many legal tasks, statutory article retrieval remains primarily untouched due to the scarcity of large-scale and high-quality annotated datasets. To address this bottleneck, we introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which consists of 1,100+ French native legal questions labeled by experienced jurists with relevant articles from a corpus of 22,600+ Belgian law articles. Using BSARD, we benchmark several state-of-the-art retrieval approaches, including lexical and dense architectures, both in zero-shot and supervised setups. We find that fine-tuned dense retrieval models significantly outperform other systems. Our best performing baseline achieves 74.8{\%} R@100, which is promising for the feasibility of the task and indicates there is still room for improvement. By the specificity of the domain and addressed task, BSARD presents a unique challenge problem for future research on legal information retrieval. Our dataset and source code are publicly available.",
}

@inproceedings{rabelo2020coliee,
author = {Rabelo, Juliano and Kim, Mi-Young and Goebel, Randy and Yoshioka, Masaharu and Kano, Yoshinobu and Satoh, Ken}, title = {COLIEE 2020: Methods for Legal Document Retrieval and Entailment}, year = {2020}, isbn = {978-3-030-79941-0}, publisher = {Springer-Verlag}, address = {Berlin, Heidelberg}, url = {https://doi.org/10.1007/978-3-030-79942-7_13}, doi = {10.1007/978-3-030-79942-7_13}, abstract = {We present a summary of the 7th Competition on Legal Information Extraction and Entailment. The competition consists of four tasks on case law and statute law. The case law component includes an information retrieval task (Task 1), and the confirmation of an entailment relation between an existing case and an unseen case (Task 2). The statute law component includes an information retrieval task (Task 3) and an entailment/question answering task (Task 4). Participation was open to any group based on any approach. Ten different teams participated in the case law competition tasks, most of them in more than one task. We received results from 9 teams for Task 1 (22 runs) and 8 teams for Task 2 (22 runs). On the statute law task, there were 14 different teams participating, most in more than one task. Eleven teams submitted a total of 28 runs for Task 3, and 13 teams submitted a total of 30 runs for Task 4. We summarize the approaches, our official evaluation, and analysis on our data and submission results.}, booktitle = {New Frontiers in Artificial Intelligence: JSAI-IsAI 2020 Workshops, JURISIN, LENLS 2020 Workshops, Virtual Event, November 15–17, 2020, Revised Selected Papers}, pages = {196–210}, numpages = {15}, keywords = {Textual entailment, Information retrieval, Legal documents processing, Classification, Question answering} }

@inproceedings{zhong2019jecqa,
  title={JEC-QA: A Legal-Domain Question Answering Dataset},
  author={Zhong, Haoxi and Xiao, Chaojun and Tu, Cunchao and Zhang, Tianyang and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of AAAI},
  year={2020},
}

@article{Zhong2019publaynet,
  author    = {Xu Zhong and
               Jianbin Tang and
               Antonio Jimeno{-}Yepes},
  title     = {PubLayNet: largest dataset ever for document layout analysis},
  journal   = {CoRR},
  volume    = {abs/1908.07836},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.07836},
  eprinttype = {arXiv},
  eprint    = {1908.07836},
  timestamp = {Mon, 26 Aug 2019 13:20:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-07836.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}

@article{ding2021openprompt,
  title={OpenPrompt: An Open-source Framework for Prompt-learning},
  author={Ding, Ning and Hu, Shengding and Zhao, Weilin and Chen, Yulin and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong},
  journal={arXiv preprint arXiv:2111.01998},
  year={2021}
}

@article{liu2021ptuning,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2103.10385},
  year={2021}
}

@InProceedings{duan2019cjrc,
author="Duan, Xingyi
and Wang, Baoxin
and Wang, Ziyue
and Ma, Wentao
and Cui, Yiming
and Wu, Dayong
and Wang, Shijin
and Liu, Ting
and Huo, Tianxiang
and Hu, Zhen
and Wang, Heng
and Liu, Zhiyuan",
editor="Sun, Maosong
and Huang, Xuanjing
and Ji, Heng
and Liu, Zhiyuan
and Liu, Yang",
title="CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial Reading Comprehension",
booktitle="Chinese Computational Linguistics",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="439--451",
abstract="We present a Chinese judicial reading comprehension (CJRC) dataset which contains approximately 10K documents and almost 50K questions with answers. The documents come from judgment documents and the questions are annotated by law experts. The CJRC dataset can help researchers extract elements by reading comprehension technology. Element extraction is an important task in the legal field. However, it is difficult to predefine the element types completely due to the diversity of document types and causes of action. By contrast, machine reading comprehension technology can quickly extract elements by answering various questions from the long document. We build two strong baseline models based on BERT and BiDAF. The experimental results show that there is enough space for improvement compared to human annotators.",
isbn="978-3-030-32381-3"
}

