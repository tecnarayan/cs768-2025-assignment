@inproceedings{pg_theorem,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{seqool,
  title={A simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption},
  author={Bartlett, Peter L and Gabillon, Victor and Valko, Michal},
  journal={arXiv preprint arXiv:1810.00997},
  year={2018}
}

@inproceedings{beta_gradients,
  title={Improving stochastic policy gradients in continuous control with deep reinforcement learning using the beta distribution},
  author={Chou, Po-Wei and Maturana, Daniel and Scherer, Sebastian},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={834--843},
  year={2017},
  organization={JMLR. org}
}

@article{reinforce,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}

@article{leike2017ai,
  title={AI Safety Gridworlds},
  author={Leike, Jan and Martic, Miljan and Krakovna, Victoria and Ortega, Pedro A and Everitt, Tom and Lefrancq, Andrew and Orseau, Laurent and Legg, Shane},
  journal={arXiv preprint arXiv:1711.09883},
  year={2017}
}

@inproceedings{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1522--1530},
  year={2015}
}

@article{borkar2008stochastic,
  title={Stochastic approximation},
  author={Borkar, Vivek S and others},
  journal={Cambridge Books},
  year={2008},
  publisher={Cambridge University Press}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={ICML},
  volume={2},
  pages={267--274},
  year={2002}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{hessel2017rainbow,
  title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  journal={arXiv preprint arXiv:1710.02298},
  year={2017}
}

@article{dabney2017distributional,
  title={Distributional Reinforcement Learning with Quantile Regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}

@article{dalal2018safe,
  title={Safe Exploration in Continuous Action Spaces},
  author={Dalal, Gal and Dvijotham, Krishnamurthy and Vecerik, Matej and Hester, Todd and Paduraru, Cosmin and Tassa, Yuval},
  journal={arXiv preprint arXiv:1801.08757},
  year={2018}
}

@inproceedings{tamar2012policy,
  title={Policy gradients with variance related risk criteria},
  author={Tamar, Aviv and Di Castro, Dotan and Mannor, Shie},
  booktitle={Proceedings of the twenty-ninth international conference on machine learning},
  pages={387--396},
  year={2012}
}

@inproceedings{lakshmanan2012novel,
  title={A novel Q-learning algorithm with function approximation for constrained Markov decision processes},
  author={Lakshmanan, K and Bhatnagar, Shalabh},
  booktitle={Communication, Control, and Computing (Allerton), 2012 50th Annual Allerton Conference on},
  pages={400--405},
  year={2012},
  organization={IEEE}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@misc{bostondynamics,
  title = {Atlas - The World's Most Dynamic Humanoid},
  \howpublished = {\url{https://www.bostondynamics.com/atlas}},
  author= {BostonDynamics},
  year = {2013}
}

@misc{openaigym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{roboschool,
  author = {OpenAI},
  title = {Roboschool},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/roboschool}},
}

@article{peng2018deepmimic,
  title={DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills},
  author={Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
  journal={arXiv preprint arXiv:1804.02717},
  year={2018}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@inproceedings{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela and Krause, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={908--919},
  year={2017}
}

@article{amos2017optnet,
  title={Optnet: Differentiable optimization as a layer in neural networks},
  author={Amos, Brandon and Kolter, J Zico},
  journal={arXiv preprint arXiv:1703.00443},
  year={2017}
}

@article{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1705.10528},
  year={2017}
}

@article{bellemare2013arcade,
  title={The Arcade Learning Environment: An evaluation platform for general agents.},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={J. Artif. Intell. Res.(JAIR)},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{schmitt2018kickstarting,
  title={Kickstarting Deep Reinforcement Learning},
  author={Schmitt, Simon and Hudson, Jonathan J and Zidek, Augustin and Osindero, Simon and Doersch, Carl and Czarnecki, Wojciech M and Leibo, Joel Z and Kuttler, Heinrich and Zisserman, Andrew and Simonyan, Karen and others},
  journal={arXiv preprint arXiv:1803.03835},
  year={2018}
}

@article{tamar2013variance,
  title={Variance adjusted actor critic algorithms},
  author={Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1310.3697},
  year={2013}
}

@inproceedings{prashanth2014policy,
  title={Policy gradients for CVaR-constrained MDPs},
  author={Prashanth, LA},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={155--169},
  year={2014},
  organization={Springer}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@inproceedings{koutsopoulos2011control,
  title={Control and optimization meet the smart power grid: Scheduling of power demands for optimal energy management},
  author={Koutsopoulos, Iordanis and Tassiulas, Leandros},
  booktitle={Proceedings of the 2nd International Conference on Energy-efficient Computing and Networking},
  pages={41--50},
  year={2011},
  organization={ACM}
}

@article{hou2017optimization,
  title={Optimization of Web Service-Based Control System for Balance Between Network Traffic and Delay},
  author={Hou, Chen and Zhao, Qianchuan},
  journal={IEEE Transactions on Automation Science and Engineering},
  year={2017},
  publisher={IEEE}
}

@incollection{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  booktitle={Reinforcement Learning},
  pages={5--32},
  year={1992},
  publisher={Springer}
}

@article{krokhmal2002portfolio,
  title={Portfolio optimization with conditional value-at-risk objective and constraints},
  author={Krokhmal, Pavlo and Palmquist, Jonas and Uryasev, Stanislav},
  journal={Journal of risk},
  volume={4},
  pages={43--68},
  year={2002},
  publisher={Citeseer}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{prashanth2016variance,
  title={Variance-constrained actor-critic algorithms for discounted and average reward MDPs},
  author={Prashanth, LA and Ghavamzadeh, Mohammad},
  journal={Machine Learning},
  volume={105},
  number={3},
  pages={367--417},
  year={2016},
  publisher={Springer}
}

@book{bertsekas1995dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P},
  volume={1},
  year={1995},
  publisher={Athena scientific Belmont, MA}
}

@misc{pytorchrl,
  author = {Kostrikov, Ilya},
  title = {PyTorch Implementations of Reinforcement Learning Algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr}},
}

@inproceedings{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS-W},
  year={2017}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@inproceedings{chow2014algorithms,
  title={Algorithms for CVaR optimization in MDPs},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad},
  booktitle={Advances in neural information processing systems},
  pages={3509--3517},
  year={2014}
}

@article{bertesekas1999nonlinear,
  title={Nonlinear programming. athena scientific},
  author={Bertesekas, D},
  journal={Belmont, Massachusetts},
  year={1999}
}

@article{marbach2001simulation,
  title={Simulation-based optimization of Markov reward processes},
  author={Marbach, Peter and Tsitsiklis, John N},
  journal={IEEE Transactions on Automatic Control},
  volume={46},
  number={2},
  pages={191--209},
  year={2001},
  publisher={IEEE}
}

@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@book{puterman1994markov,
	title={Markov decision processes: discrete stochastic dynamic programming},
	author={Puterman, Martin L},
	year={1994},
	publisher={John Wiley \& Sons}
}

@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of the 34th IEEE Conference on Decision and Control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE Publ. Piscataway, NJ}
}

@article{tang2019discretizing,
  title={Discretizing Continuous Action Space for On-Policy Optimization},
  author={Tang, Yunhao and Agrawal, Shipra},
  journal={arXiv preprint arXiv:1901.10500},
  year={2019}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}

@article{koenker2001quantile,
  title={Quantile regression: An introduction},
  author={Koenker, Roger and Hallock, Kevin},
  journal={Journal of Economic Perspectives},
  volume={15},
  number={4},
  pages={43--56},
  year={2001}
}

@article{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.06923},
  year={2018}
}

@article{ostrovski2018autoregressive,
  title={Autoregressive quantile networks for generative modeling},
  author={Ostrovski, Georg and Dabney, Will and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.05575},
  year={2018}
}

@book{kallenberg2006foundations,
  title={Foundations of modern probability},
  author={Kallenberg, Olav},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@incollection{huber1992robust,
  title={Robust estimation of a location parameter},
  author={Huber, Peter J},
  booktitle={Breakthroughs in statistics},
  pages={492--518},
  year={1992},
  publisher={Springer}
}

@article{koenker2006quantile,
  title={Quantile autoregression},
  author={Koenker, Roger and Xiao, Zhijie},
  journal={Journal of the American Statistical Association},
  volume={101},
  number={475},
  pages={980--990},
  year={2006},
  publisher={Taylor \& Francis}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{feng2017learning,
  title={Learning to draw samples with amortized stein variational gradient descent},
  author={Feng, Yihao and Wang, Dilin and Liu, Qiang},
  journal={arXiv preprint arXiv:1707.06626},
  year={2017}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International Conference on Machine Learning},
  pages={214--223},
  year={2017}
}

@inproceedings{gulrajani2017improved,
  title={Improved training of wasserstein gans},
  author={Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5767--5777},
  year={2017}
}

@inproceedings{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  booktitle={Advances in neural information processing systems},
  pages={4790--4798},
  year={2016}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{bubeck2011x,
  title={X-armed bandits},
  author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={May},
  pages={1655--1695},
  year={2011}
}

@article{bartlett2018simple,
  title={A simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption},
  author={Bartlett, Peter L and Gabillon, Victor and Valko, Michal},
  journal={arXiv preprint arXiv:1810.00997},
  year={2018}
}

@inproceedings{munos2011optimistic,
  title={Optimistic optimization of a deterministic function without the knowledge of its smoothness},
  author={Munos, R{\'e}mi},
  booktitle={Advances in neural information processing systems},
  pages={783--791},
  year={2011}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}


@article{andrychowicz2018learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={arXiv preprint arXiv:1808.00177},
  year={2018}
}

@inproceedings{riedmiller2018learning,
  title={Learning by Playing Solving Sparse Reward Tasks from Scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},
  booktitle={International Conference on Machine Learning},
  pages={4341--4350},
  year={2018}
}

@misc{OpenAI_dota,
      author={OpenAI},
      title={OpenAI Five},
      howpublished={\url{https://blog.openai.com/openai-five/}},
      year={2018}
}
      
@misc{alphastarblog,
  title="{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}",
  author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M. and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Wu, Yuhuai and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
  howpublished={\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
  year={2019}
}

@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}

@article{lyle2019comparative,
  title={A Comparative Analysis of Expected and Distributional Reinforcement Learning},
  author={Lyle, Clare and Castro, Pablo Samuel and Bellemare, Marc G},
  journal={arXiv preprint arXiv:1901.11084},
  year={2019}
}

@article{dinh2014nice,
  title={Nice: Non-linear independent components estimation},
  author={Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1410.8516},
  year={2014}
}

@article{dinh2016density,
  title={Density estimation using real nvp},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  journal={arXiv preprint arXiv:1605.08803},
  year={2016}
}

@inproceedings{kingma2018glow,
  title={Glow: Generative flow with invertible 1x1 convolutions},
  author={Kingma, Durk P and Dhariwal, Prafulla},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10215--10224},
  year={2018}
}

@inproceedings{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1856--1865},
  year={2018}
}

@article{local_is_global,
  title={Policy search: Any local optimum enjoys a global performance guarantee},
  author={Scherrer, Bruno and Geist, Matthieu},
  journal={arXiv preprint arXiv:1306.1520},
  year={2013}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{salimans2016improved,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in neural information processing systems},
  pages={2234--2242},
  year={2016}
}

@article{puterman1979convergence,
  title={On the convergence of policy iteration in stationary dynamic programming},
  author={Puterman, Martin L and Brumelle, Shelby L},
  journal={Mathematics of Operations Research},
  volume={4},
  number={1},
  pages={60--69},
  year={1979},
  publisher={INFORMS}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{bhatnagar2012online,
  title={An online actor--critic algorithm with function approximation for constrained markov decision processes},
  author={Bhatnagar, Shalabh and Lakshmanan, K},
  journal={Journal of Optimization Theory and Applications},
  volume={153},
  number={3},
  pages={688--708},
  year={2012},
  publisher={Springer}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017},
  publisher={JMLR. org}
}

@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}

@article{qu2018nonlinear,
  title={Nonlinear Distributional Gradient Temporal-Difference Learning},
  author={Qu, Chao and Mannor, Shie and Xu, Huan},
  journal={arXiv preprint arXiv:1805.07732},
  year={2018}
}

@article{rowland2018analysis,
  title={An analysis of categorical distributional reinforcement learning},
  author={Rowland, Mark and Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1802.08163},
  year={2018}
}

@article{ghavamzadeh2016bayesian,
  title={Bayesian policy gradient and actor-critic algorithms},
  author={Ghavamzadeh, Mohammad and Engel, Yaakov and Valko, Michal},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2319--2371},
  year={2016},
  publisher={JMLR. org}
}

@article{polyak1990new,
  title={New stochastic approximation type procedures},
  author={Polyak, Boris T},
  journal={Automat. i Telemekh},
  volume={7},
  number={98-107},
  pages={2},
  year={1990}
}

@article{mania2018simple,
  title={Simple random search provides a competitive approach to reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  journal={arXiv preprint arXiv:1803.07055},
  year={2018}
}

@article{korenkevych2019autoregressive,
  title={Autoregressive Policies for Continuous Control Deep Reinforcement Learning},
  author={Korenkevych, Dmytro and Mahmood, A Rupam and Vasan, Gautham and Bergstra, James},
  journal={arXiv preprint arXiv:1903.11524},
  year={2019}
}

@article{wolpert1997no,
  title={No free lunch theorems for optimization},
  author={Wolpert, David H and Macready, William G and others},
  journal={IEEE transactions on evolutionary computation},
  volume={1},
  number={1},
  pages={67--82},
  year={1997}
}