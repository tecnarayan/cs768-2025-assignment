\begin{thebibliography}{10}

\bibitem{agrawal2012analysis}
Shipra Agrawal and Navin Goyal.
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock In {\em Conference on learning theory}, pages 39--1. JMLR Workshop
  and Conference Proceedings, 2012.

\bibitem{ahneman2018predicting}
Derek~T Ahneman, Jes{\'u}s~G Estrada, Shishi Lin, Spencer~D Dreher, and
  Abigail~G Doyle.
\newblock Predicting reaction performance in c--n cross-coupling using machine
  learning.
\newblock {\em Science}, 360(6385):186--190, 2018.

\bibitem{arnavaz2021bayesian}
Kasra Arnavaz, Aasa Feragen, Oswin Krause, and Marco Loog.
\newblock Bayesian active learning for maximal information gain on model
  parameters.
\newblock In {\em 2020 25th International Conference on Pattern Recognition
  (ICPR)}, pages 10524--10531. IEEE, 2021.

\bibitem{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47(2):235--256, 2002.

\bibitem{bajorath2020artificial}
JÃ¼rgen Bajorath, Steven Kearnes, W~Patrick Walters, Nicholas~A Meanwell,
  Gunda~I Georg, and Shaomeng Wang.
\newblock Artificial intelligence in drug discovery: into the great wide open,
  2020.

\bibitem{bickel2006optimal}
J~Eric Bickel and James~E Smith.
\newblock Optimal sequential exploration: A binary learning model.
\newblock {\em Decision Analysis}, 3(1):16--32, 2006.

\bibitem{brown2013optimal}
David~B Brown and James~E Smith.
\newblock Optimal sequential exploration: Bandits, clairvoyants, and wildcats.
\newblock {\em Operations research}, 61(3):644--665, 2013.

\bibitem{chakraborty2013active}
Shayok Chakraborty, Jiayu Zhou, Vineeth Balasubramanian, Sethuraman
  Panchanathan, Ian Davidson, and Jieping Ye.
\newblock Active matrix completion.
\newblock In {\em 2013 IEEE 13th international conference on data mining},
  pages 81--90. IEEE, 2013.

\bibitem{cortes2019online}
Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, and Scott Yang.
\newblock Online learning with sleeping experts and feedback graphs.
\newblock In {\em International Conference on Machine Learning}, pages
  1370--1378. PMLR, 2019.

\bibitem{dong2018information}
Shi Dong and Benjamin Van~Roy.
\newblock An information-theoretic analysis for thompson sampling with many
  actions.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{dreher2021chemistry}
Spencer~D Dreher and Shane~W Krska.
\newblock Chemistry informer libraries: Conception, early experience, and role
  in the future of cheminformatics.
\newblock {\em Accounts of Chemical Research}, 54(7):1586--1596, 2021.

\bibitem{filippi2010parametric}
Sarah Filippi, Olivier Cappe, Aur{\'e}lien Garivier, and Csaba Szepesv{\'a}ri.
\newblock Parametric bandits: The generalized linear case.
\newblock {\em Advances in Neural Information Processing Systems}, 23, 2010.

\bibitem{gil2014amplify}
Yolanda Gil, Mark Greaves, James Hendler, and Haym Hirsh.
\newblock Amplify scientific discovery with artificial intelligence.
\newblock {\em Science}, 346(6206):171--172, 2014.

\bibitem{hao2021information}
Botao Hao, Tor Lattimore, and Wei Deng.
\newblock Information directed sampling for sparse linear bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{he2020active}
Zichang He, Bo~Zhao, and Zheng Zhang.
\newblock Active sampling for accelerated mri with low-rank tensors.
\newblock {\em arXiv preprint arXiv:2012.12496}, 2020.

\bibitem{jaakkola1997variational}
Tommi~S Jaakkola and Michael~I Jordan.
\newblock A variational approach to bayesian logistic regression models and
  their extensions.
\newblock In {\em Sixth International Workshop on Artificial Intelligence and
  Statistics}, pages 283--294. PMLR, 1997.

\bibitem{jafarizadeh2021two}
Babak Jafarizadeh and Reidar Bratvold.
\newblock The two-factor price process in optimal sequential exploration.
\newblock {\em Journal of the Operational Research Society}, 72(7):1637--1647,
  2021.

\bibitem{jain2013low}
Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi.
\newblock Low-rank matrix completion using alternating minimization.
\newblock In {\em Proceedings of the forty-fifth annual ACM symposium on Theory
  of computing}, pages 665--674, 2013.

\bibitem{jia2021physics}
Xiaowei Jia, Jared Willard, Anuj Karpatne, Jordan~S Read, Jacob~A Zwart,
  Michael Steinbach, and Vipin Kumar.
\newblock Physics-guided machine learning for scientific discovery: An
  application in simulating lake temperature profiles.
\newblock {\em ACM/IMS Transactions on Data Science}, 2(3):1--26, 2021.

\bibitem{jiang2018efficient}
Shali Jiang, Gustavo Malkomes, Matthew Abbott, Benjamin Moseley, and Roman
  Garnett.
\newblock Efficient nonmyopic batch active search.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{jiang2017efficient}
Shali Jiang, Gustavo Malkomes, Geoff Converse, Alyssa Shofner, Benjamin
  Moseley, and Roman Garnett.
\newblock Efficient nonmyopic active search.
\newblock In {\em International Conference on Machine Learning}, pages
  1714--1723. PMLR, 2017.

\bibitem{kanade2009sleeping}
Varun Kanade, H~Brendan McMahan, and Brent Bryan.
\newblock Sleeping experts and bandits with stochastic action availability and
  adversarial rewards.
\newblock In {\em Artificial Intelligence and Statistics}, pages 272--279.
  PMLR, 2009.

\bibitem{karpatne2017theory}
Anuj Karpatne, Gowtham Atluri, James~H Faghmous, Michael Steinbach, Arindam
  Banerjee, Auroop Ganguly, Shashi Shekhar, Nagiza Samatova, and Vipin Kumar.
\newblock Theory-guided data science: A new paradigm for scientific discovery
  from data.
\newblock {\em IEEE Transactions on knowledge and data engineering},
  29(10):2318--2331, 2017.

\bibitem{kleinberg2010regret}
Robert Kleinberg, Alexandru Niculescu-Mizil, and Yogeshwer Sharma.
\newblock Regret bounds for sleeping experts and bandits.
\newblock {\em Machine learning}, 80(2):245--272, 2010.

\bibitem{koltchinskii2011nuclear}
Vladimir Koltchinskii, Karim Lounici, and Alexandre~B Tsybakov.
\newblock Nuclear-norm penalization and optimal rates for noisy low-rank matrix
  completion.
\newblock {\em The Annals of Statistics}, 39(5):2302--2329, 2011.

\bibitem{lattimore2015optimally}
Tor Lattimore.
\newblock Optimally confident ucb: Improved regret for finite-armed bandits.
\newblock {\em arXiv preprint arXiv:1507.07880}, 2015.

\bibitem{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock {\em Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem{lu2021low}
Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari.
\newblock Low-rank generalized linear bandit problems.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 460--468. PMLR, 2021.

\bibitem{mak2017information}
Simon Mak, Henry~Shaowu Yushi, and Yao Xie.
\newblock Information-guided sampling for low-rank matrix completion.
\newblock {\em arXiv preprint arXiv:1706.08037}, 2017.

\bibitem{mcinnes2020transfer}
Gregory McInnes, Rachel Dalton, Katrin Sangkuhl, Michelle Whirl-Carrillo,
  Seung-been Lee, Philip~S Tsao, Andrea Gaedigk, Russ~B Altman, and Erica~L
  Woodahl.
\newblock Transfer learning enables prediction of cyp2d6 haplotype function.
\newblock {\em PLoS Computational Biology}, 16(11):e1008399, 2020.

\bibitem{nguyen2019low}
Luong~Trung Nguyen, Junhan Kim, and Byonghyo Shim.
\newblock Low-rank matrix completion: A contemporary survey.
\newblock {\em IEEE Access}, 7:94215--94237, 2019.

\bibitem{nguyen2022nonmyopic}
Quan Nguyen and Roman Garnett.
\newblock Nonmyopic multiclass active search for diverse discovery.
\newblock {\em arXiv preprint arXiv:2202.03593}, 2022.

\bibitem{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via information-directed sampling.
\newblock {\em Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem{russo2016information}
Daniel Russo and Benjamin Van~Roy.
\newblock An information-theoretic analysis of thompson sampling.
\newblock {\em The Journal of Machine Learning Research}, 17(1):2442--2471,
  2016.

\bibitem{russo2018learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via information-directed sampling.
\newblock {\em Operations Research}, 66(1):230--252, 2018.

\bibitem{russo2018tutorial}
Daniel~J Russo, Benjamin Van~Roy, Abbas Kazerouni, Ian Osband, Zheng Wen,
  et~al.
\newblock A tutorial on thompson sampling.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  11(1):1--96, 2018.

\bibitem{D1SC06932B}
Eunjae Shim, Joshua Kammeraad, Ziping Xu, Ambuj Tewari, Tim Cernak, and Paul
  Zimmerman.
\newblock Predicting reaction conditions from limited data through active
  transfer learning.
\newblock {\em Chem. Sci.}, pages~--, 2022.

\bibitem{struble2020current}
Thomas~J Struble, Juan~C Alvarez, Scott~P Brown, Milan Chytil, Justin Cisar,
  Renee~L DesJarlais, Ola Engkvist, Scott~A Frank, Daniel~R Greve, Daniel~J
  Griffin, et~al.
\newblock Current and future roles of artificial intelligence in medicinal
  chemistry synthesis.
\newblock {\em Journal of medicinal chemistry}, 63(16):8667--8682, 2020.

\bibitem{thekumparampil2021statistically}
Kiran~K Thekumparampil, Prateek Jain, Praneeth Netrapalli, and Sewoong Oh.
\newblock Statistically and computationally efficient linear
  meta-representation learning.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{vamathevan2019applications}
Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran,
  George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer, et~al.
\newblock Applications of machine learning in drug discovery and development.
\newblock {\em Nature reviews Drug discovery}, 18(6):463--477, 2019.

\bibitem{wang2008algorithms}
Yizao Wang, Jean-Yves Audibert, and R{\'e}mi Munos.
\newblock Algorithms for infinitely many-armed bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 21, 2008.

\bibitem{zhou2020neural}
Dongruo Zhou, Lihong Li, and Quanquan Gu.
\newblock Neural contextual bandits with ucb-based exploration.
\newblock In {\em International Conference on Machine Learning}, pages
  11492--11502. PMLR, 2020.

\end{thebibliography}
