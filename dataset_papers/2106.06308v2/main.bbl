\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{AMMN19}

\bibitem[AMMN19]{arous2019landscape}
Gerard~Ben Arous, Song Mei, Andrea Montanari, and Mihai Nica.
\newblock The landscape of the spiked tensor model.
\newblock {\em Communications on Pure and Applied Mathematics},
  72(11):2282--2330, 2019.

\bibitem[AW08]{amini2008high}
Arash~A Amini and Martin~J Wainwright.
\newblock High-dimensional analysis of semidefinite relaxations for sparse
  principal components.
\newblock In {\em 2008 IEEE International Symposium on Information Theory},
  pages 2454--2458. IEEE, 2008.

\bibitem[BB20]{DBLP:conf/colt/BrennanB20}
Matthew Brennan and Guy Bresler.
\newblock Reducibility and statistical-computational gaps from secret leakage.
\newblock In {\em Conference on Learning Theory, {COLT} 2020, 9-12 July 2020,
  Virtual Event [Graz, Austria]}, pages 648--847, 2020.

\bibitem[BCPS20]{buhmannrecovery}
Joachim~M Buhmann, Luca Corinzia, Paolo Penna, and Wojciech Szpankowski.
\newblock {Recovery of a Planted k-Densest Sub-Hypergraph}, 2020.
\newblock Available at:
  \url{https://www.cs.purdue.edu/homes/spa/papers/isit20-clique.pdf}.

\bibitem[BGL16]{bhattiprolu2016sum}
Vijay Bhattiprolu, Venkatesan Guruswami, and Euiwoong Lee.
\newblock Sum-of-squares certificates for maxima of random tensors on the
  sphere.
\newblock {\em arXiv preprint arXiv:1605.00903}, 2016.

\bibitem[BHK{\etalchar{+}}19]{barak2019nearly}
Boaz Barak, Samuel Hopkins, Jonathan Kelner, Pravesh~K Kothari, Ankur Moitra,
  and Aaron Potechin.
\newblock A nearly tight sum-of-squares lower bound for the planted clique
  problem.
\newblock {\em SIAM Journal on Computing}, 48(2):687--735, 2019.

\bibitem[BKW20]{conf/innovations/BandeiraKW20}
Afonso~S. Bandeira, Dmitriy Kunisky, and Alexander~S. Wein.
\newblock Computational hardness of certifying bounds on constrained {PCA}
  problems.
\newblock In {\em 11th Innovations in Theoretical Computer Science Conference,
  {ITCS} 2020, January 12-14, 2020, Seattle, Washington, {USA}}, pages
  78:1--78:29, 2020.

\bibitem[BR13a]{berthet2013complexity}
Quentin Berthet and Philippe Rigollet.
\newblock {Complexity Theoretic Lower Bounds for Sparse Principal Component
  Detection}.
\newblock In {\em Conference on Learning Theory}, pages 1046--1066, 2013.

\bibitem[BR13b]{berthet2013optimal}
Quentin Berthet and Philippe Rigollet.
\newblock {OPTIMAL DETECTION OF SPARSE PRINCIPAL COMPONENTS IN HIGH DIMENSION}.
\newblock {\em The Annals of Statistics}, 41(4):1780--1815, 2013.

\bibitem[Cam60]{leCam}
Lucien~Le Cam.
\newblock Locally asymptotically normal families.
\newblock {\em Univ. California Publ. Statist.}, 1960.

\bibitem[CMW13]{cai2013sparse}
T~Tony Cai, Zongming Ma, and Yihong Wu.
\newblock {SPARSE PCA: OPTIMAL RATES AND ADAPTIVE ESTIMATION}.
\newblock {\em The Annals of Statistics}, 41(6):3074--3110, 2013.

\bibitem[CPMB19]{corinzia2019exact}
Luca Corinzia, Paolo Penna, Luca Mondada, and Joachim~M Buhmann.
\newblock {Exact Recovery for a Family of Community-Detection Generative
  Models}.
\newblock In {\em 2019 IEEE International Symposium on Information Theory
  (ISIT)}, pages 415--419. IEEE, 2019.

\bibitem[CPSB20]{corinzia2020statistical}
Luca Corinzia, Paolo Penna, Wojciech Szpankowski, and Joachim~M. Buhmann.
\newblock Statistical and computational thresholds for the planted $k$-densest
  sub-hypergraph problem, 2020.

\bibitem[dGJL07]{DBLP:journals/siamrev/dAspremontGJL07}
Alexandre d'Aspremont, Laurent~El Ghaoui, Michael~I. Jordan, and Gert R.~G.
  Lanckriet.
\newblock A direct formulation for sparse {PCA} using semidefinite programming.
\newblock {\em {SIAM} Review}, 49(3):434--448, 2007.

\bibitem[dKNS20]{dOrsi2020}
Tommaso d'Orsi, Pravesh~K. Kothari, Gleb Novikov, and David Steurer.
\newblock {Sparse PCA: Algorithms, Adversarial Perturbations and Certificates},
  2020.
\newblock To appear in FOCS 2020.

\bibitem[DKWB19]{ding2019subexponential}
Yunzi Ding, Dmitriy Kunisky, Alexander~S Wein, and Afonso~S Bandeira.
\newblock {Subexponential-Time Algorithms for Sparse PCA}.
\newblock {\em arXiv preprint arXiv:1907.11635}, 2019.

\bibitem[DM16]{deshpande2016sparse}
Yash Deshpande and Andrea Montanari.
\newblock {Sparse PCA via Covariance Thresholding}.
\newblock {\em The Journal of Machine Learning Research}, 17(1):4913--4953,
  2016.

\bibitem[Duc16]{duchi2016lecture}
John Duchi.
\newblock {Lecture Notes for Statistics 311/Electrical engineering 377}, 2016.
\newblock Available at:
  \url{https://stanford.edu/class/stats311/Lectures/full_notes.pdf}.

\bibitem[FP07]{feral2007largest}
Delphine F{\'e}ral and Sandrine P{\'e}ch{\'e}.
\newblock {The Largest Eigenvalue of Rank One Deformation of Large Wigner
  Matrices}.
\newblock {\em Communications in mathematical physics}, 272(1):185--228, 2007.

\bibitem[HKP{\etalchar{+}}17]{hopkins2017power}
Samuel~B Hopkins, Pravesh~K Kothari, Aaron Potechin, Prasad Raghavendra, Tselil
  Schramm, and David Steurer.
\newblock The power of sum-of-squares for detecting hidden structures.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 720--731. IEEE, 2017.

\bibitem[HL13]{hillar2013most}
Christopher~J Hillar and Lek-Heng Lim.
\newblock Most tensor problems are np-hard.
\newblock {\em Journal of the ACM (JACM)}, 60(6):1--39, 2013.

\bibitem[Hop18]{hopkins2018statistical}
Samuel Brink~Klevit Hopkins.
\newblock {\em {STATISTICAL INFERENCE AND THE SUM OF SQUARES METHOD}}.
\newblock PhD thesis, Cornell University, 2018.

\bibitem[HS17]{hopkins2017efficient}
Samuel~B Hopkins and David Steurer.
\newblock {Efficient Bayesian estimation from few samples: community detection
  and related problems}.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 379--390. IEEE, 2017.

\bibitem[HSS15]{hopkins2015tensor}
Samuel~B Hopkins, Jonathan Shi, and David Steurer.
\newblock Tensor principal component analysis via sum-of-squares proofs.
\newblock In {\em Conference on Learning Theory}, pages 956--1006, 2015.

\bibitem[HSS19]{hopkins2019robust}
Samuel~B Hopkins, Tselil Schramm, and Jonathan Shi.
\newblock A robust spectral algorithm for overcomplete tensor decomposition.
\newblock In {\em Conference on Learning Theory}, pages 1683--1722, 2019.

\bibitem[HSV20]{DBLP:conf/colt/HoltzmanSV20}
Guy Holtzman, Adam Soffer, and Dan Vilenchik.
\newblock A greedy anytime algorithm for sparse {PCA}.
\newblock In {\em Conference on Learning Theory, {COLT} 2020, 9-12 July 2020,
  Virtual Event [Graz, Austria]}, pages 1939--1956, 2020.

\bibitem[HW20]{holmgren2020counterexamples}
Justin Holmgren and Alexander~S Wein.
\newblock Counterexamples to the low-degree conjecture.
\newblock {\em arXiv preprint arXiv:2004.08454}, 2020.

\bibitem[JL09]{johnstone2009consistency}
Iain~M Johnstone and Arthur~Yu Lu.
\newblock {On Consistency and Sparsity for Principal Components Analysis in
  High Dimensions}.
\newblock {\em Journal of the American Statistical Association},
  104(486):682--693, 2009.

\bibitem[KWB19]{kunisky2019notes}
Dmitriy Kunisky, Alexander~S Wein, and Afonso~S Bandeira.
\newblock {Notes on Computational Hardness of Hypothesis Testing: Predictions
  using the Low-Degree Likelihood Ratio}.
\newblock {\em arXiv preprint arXiv:1907.11636}, 2019.

\bibitem[LZ20]{DBLP:journals/corr/abs-2005-10743}
Yuetian Luo and Anru Zhang.
\newblock Tensor clustering with planted structures: Statistical optimality and
  computational limits.
\newblock {\em CoRR}, abs/2005.10743, 2020.

\bibitem[MR14]{richard2014statistical}
Andrea Montanari and Emile Richard.
\newblock {A statistical model for tensor PCA}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2897--2905, 2014.

\bibitem[MSS16]{ma2016polynomial}
Tengyu Ma, Jonathan Shi, and David Steurer.
\newblock Polynomial-time tensor decompositions with sum-of-squares.
\newblock In {\em 2016 IEEE 57th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 438--446. IEEE, 2016.

\bibitem[NP33]{neymanpearson}
J.~Neyman and E.~S. Pearson.
\newblock On the problem of the most efficient tests of statistical hypotheses.
\newblock {\em Philosophical Transactions of the Royal Society of London.
  Series A, Containing Papers of a Mathematical or Physical Character},
  231:289--337, 1933.

\bibitem[NWZ20]{NEURIPS2020_cd0b43ea}
Jonathan Niles-Weed and Ilias Zadik.
\newblock The all-or-nothing phenomenon in sparse tensor pca.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 17674--17684. Curran Associates, Inc., 2020.

\bibitem[NZ20]{DBLP:conf/nips/Niles-WeedZ20}
Jonathan Niles{-}Weed and Ilias Zadik.
\newblock The all-or-nothing phenomenon in sparse tensor {PCA}.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.

\bibitem[O'D14]{o2014analysis}
Ryan O'Donnell.
\newblock {\em Analysis of boolean functions}.
\newblock Cambridge University Press, 2014.

\bibitem[PWB16]{DBLP:journals/corr/PerryWB16}
Amelia Perry, Alexander~S. Wein, and Afonso~S. Bandeira.
\newblock Statistical limits of spiked tensor models.
\newblock {\em CoRR}, abs/1612.07728, 2016.

\bibitem[PWB{\etalchar{+}}20]{perry2020statistical}
Amelia Perry, Alexander~S Wein, Afonso~S Bandeira, et~al.
\newblock Statistical limits of spiked tensor models.
\newblock In {\em Annales de l'Institut Henri Poincar{\'e}, Probabilit{\'e}s et
  Statistiques}, volume~56, pages 230--264. Institut Henri Poincar{\'e}, 2020.

\bibitem[SC19]{scarlett2019introductory}
Jonathan Scarlett and Volkan Cevher.
\newblock {An Introductory Guide to Fanoâ€™s Inequality with Applications in
  Statistical Estimation}.
\newblock {\em arXiv preprint arXiv:1901.00555}, 2019.

\bibitem[SS17]{schramm2017fast}
Tselil Schramm and David Steurer.
\newblock Fast and robust tensor decomposition with applications to dictionary
  learning.
\newblock {\em arXiv preprint arXiv:1706.08672}, 2017.

\bibitem[Tao12]{tao2012topics}
Terence Tao.
\newblock {\em Topics in random matrix theory}, volume 132.
\newblock American Mathematical Soc., 2012.

\bibitem[Tao14]{tao2014metric}
Terence Tao.
\newblock {Metric entropy analogues of sum set theory}, 2014.
\newblock Available at:
  \url{https://terrytao.wordpress.com/2014/03/19/metric-entropy-analogues-of-sum-set-theory/}.

\bibitem[Tro15]{tropp2015introduction}
Joel~A Tropp.
\newblock {An Introduction to Matrix Concentration Inequalities}.
\newblock {\em arXiv preprint arXiv:1501.01571}, 2015.

\bibitem[TS14]{tomioka2014spectral}
Ryota Tomioka and Taiji Suzuki.
\newblock Spectral norm of random tensors.
\newblock {\em arXiv preprint arXiv:1407.1870}, 2014.

\bibitem[Ver18]{vershynin2018high}
Roman Vershynin.
\newblock {\em {High-Dimensional Probability: An Introduction with Applications
  in Data Science}}, volume~47.
\newblock Cambridge University Press, 2018.

\end{thebibliography}
