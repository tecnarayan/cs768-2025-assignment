\begin{thebibliography}{10}

\bibitem{amplayo2020unsupervised}
R.~K. Amplayo and M.~Lapata.
\newblock Unsupervised opinion summarization with noising and denoising.
\newblock In {\em ACL}, 2020.

\bibitem{bao2019generating}
Y.~Bao, H.~Zhou, S.~Huang, L.~Li, L.~Mou, O.~Vechtomova, X.~Dai, and J.~Chen.
\newblock Generating sentences from disentangled syntactic and semantic spaces.
\newblock In {\em ACL}, pages 6008--6019, 2019.

\bibitem{bowman2015generating}
S.~R. Bowman, L.~Vilnis, O.~Vinyals, A.~M. Dai, R.~Jozefowicz, and S.~Bengio.
\newblock Generating sentences from a continuous space.
\newblock In {\em CoNLL}, pages 10--21, 2015.

\bibitem{chu2018meansum}
E.~Chu and P.~J. Liu.
\newblock {MeanSum}: A neural model for unsupervised multi-document abstractive
  summarization.
\newblock In {\em ICML}, pages 1223--1232, 2018.

\bibitem{daume2005learning}
H.~Daum{\'e}~III and D.~Marcu.
\newblock Learning as search optimization: Approximate large margin methods for
  structured prediction.
\newblock In {\em ICML}, pages 169--176, 2005.

\bibitem{LaSO}
H.~Daum{\'e}~III and D.~Marcu.
\newblock Learning as search optimization: Approximate large margin methods for
  structured prediction.
\newblock In {\em ICML}, pages 169--176, 2005.

\bibitem{du2019empirical}
W.~Du and Y.~Ji.
\newblock An empirical comparison on imitation learning and reinforcement
  learning for paraphrase generation.
\newblock In {\em EMNLP-IJCNLP}, pages 6014--6020, 2019.

\bibitem{fu2019paraphrase}
Y.~Fu, Y.~Feng, and J.~P. Cunningham.
\newblock Paraphrase generation with latent bag of words.
\newblock In {\em NeurIPS}, pages 13623--13634, 2019.

\bibitem{fu2018style}
Z.~Fu, X.~Tan, N.~Peng, D.~Zhao, and R.~Yan.
\newblock Style transfer in text: Exploration and evaluation.
\newblock In {\em AAAI}, pages 663--670, 2018.

\bibitem{LN2BN}
K.~Goyal, C.~Dyer, and T.~Berg-Kirkpatrick.
\newblock {A}n empirical investigation of global and local normalization for
  recurrent neural sequence models using a continuous relaxation to beam
  search.
\newblock In {\em NAACL-HLT}, pages 1724--1733, 2019.

\bibitem{guo2019zero}
Y.~Guo, Y.~Liao, X.~Jiang, Q.~Zhang, Y.~Zhang, and Q.~Liu.
\newblock Zero-shot paraphrase generation with multilingual language models.
\newblock {\em arXiv preprint arXiv:1911.03597}, 2019.

\bibitem{gupta2018deep}
A.~Gupta, A.~Agarwal, P.~Singh, and P.~Rai.
\newblock A deep generative framework for paraphrase generation.
\newblock In {\em AAAI}, pages 5149--5156, 2018.

\bibitem{PoE}
G.~E. Hinton.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock {\em Neural Computation}, 14(8):1771--1800, 2002.

\bibitem{hu2017toward}
Z.~Hu, Z.~Yang, X.~Liang, R.~Salakhutdinov, and E.~P. Xing.
\newblock Toward controlled generation of text.
\newblock In {\em ICML}, pages 1587--1596, 2017.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{kirkpatrick1983optimization}
S.~Kirkpatrick, C.~D. Gelatt, and M.~P. Vecchi.
\newblock Optimization by simulated annealing.
\newblock {\em Science}, 220(4598):671--680, 1983.

\bibitem{krishnamurthy2015learning}
A.~Krishnamurthy, H.~D. CMU EDU~III, and U.~EDU.
\newblock Learning to search better than your teacher.
\newblock {\em arXiv preprint arXiv:1502.02206}, 2015.

\bibitem{simplification}
D.~Kumar, L.~Mou, L.~Golab, and O.~Vechtomova.
\newblock Iterative edit-based unsupervised sentence simplification.
\newblock In {\em ACL}, 2020.

\bibitem{lample2019cross}
G.~Lample and A.~Conneau.
\newblock Cross-lingual language model pretraining.
\newblock In {\em NeurIPS}, pages 7057--7067, 2019.

\bibitem{lample2017unsupervised}
G.~Lample, A.~Conneau, L.~Denoyer, and M.~Ranzato.
\newblock Unsupervised machine translation using monolingual corpora only.
\newblock In {\em ICLR}, 2018.

\bibitem{lample2018phrase}
G.~Lample, M.~Ott, A.~Conneau, L.~Denoyer, and M.~Ranzato.
\newblock Phrase-based \& neural unsupervised machine translation.
\newblock In {\em EMNLP}, pages 5039--5049, 2018.

\bibitem{li2018delete}
J.~Li, R.~Jia, H.~He, and P.~Liang.
\newblock Delete, retrieve, generate: A simple approach to sentiment and style
  transfer.
\newblock In {\em NAACL-HLT}, pages 1865--1874, 2018.

\bibitem{li2017paraphrase}
Z.~Li, X.~Jiang, L.~Shang, and H.~Li.
\newblock Paraphrase generation with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1711.00279}, 2017.

\bibitem{Liu2019UnsupervisedPB}
X.~Liu, L.~Mou, F.~Meng, H.~Zhou, J.~Zhou, and S.~Song.
\newblock Unsupervised paraphrasing by simulated annealing.
\newblock In {\em ACL}, 2020.

\bibitem{liu2019roberta}
Y.~Liu, M.~Ott, N.~Goyal, J.~Du, M.~Joshi, D.~Chen, O.~Levy, M.~Lewis,
  L.~Zettlemoyer, and V.~Stoyanov.
\newblock {RoBERTa}: A robustly optimized {BERT} pretraining approach.
\newblock {\em arXiv preprint arXiv:1907.11692}, 2019.

\bibitem{Luo19DualRL}
F.~Luo, P.~Li, J.~Zhou, P.~Yang, B.~Chang, Z.~Sui, and X.~Sun.
\newblock A dual reinforcement learning framework for unsupervised text style
  transfer.
\newblock In {\em IJCAI}, pages 5116--5122, 2019.

\bibitem{mallinson2017paraphrasing}
J.~Mallinson, R.~Sennrich, and M.~Lapata.
\newblock Paraphrasing revisited with neural machine translation.
\newblock In {\em ACL}, pages 881--893, 2017.

\bibitem{mcroy2003augmented}
S.~W. McRoy, S.~Channarukul, and S.~S. Ali.
\newblock An augmented template-based approach to text realization.
\newblock {\em Natural Language Engineering}, 9(4):381--420, 2003.

\bibitem{miao2019cgmh}
N.~Miao, H.~Zhou, L.~Mou, R.~Yan, and L.~Li.
\newblock {CGMH}: Constrained sentence generation by metropolis-hastings
  sampling.
\newblock In {\em AAAI}, pages 6834--6842, 2019.

\bibitem{narayan2015unsupervised}
S.~Narayan and C.~Gardent.
\newblock Unsupervised sentence simplification using deep semantics.
\newblock In {\em INLG}, pages 111--120, 2015.

\bibitem{pavlick2015ppdb}
E.~Pavlick, P.~Rastogi, J.~Ganitkevitch, B.~Van~Durme, and C.~Callison-Burch.
\newblock Ppdb 2.0: Better paraphrase ranking, fine-grained entailment
  relations, word embeddings, and style classification.
\newblock In {\em ACL}, pages 425--430, 2015.

\bibitem{prabhumoye2018style}
S.~Prabhumoye, Y.~Tsvetkov, R.~Salakhutdinov, and A.~W. Black.
\newblock Style transfer through back-translation.
\newblock In {\em ACL}, pages 866--876, 2018.

\bibitem{qian2019exploring}
L.~Qian, L.~Qiu, W.~Zhang, X.~Jiang, and Y.~Yu.
\newblock Exploring diverse expressions for paraphrase generation.
\newblock In {\em EMNLP-IJCNLP}, pages 3164--3173, 2019.

\bibitem{radford2019language}
A.~Radford, J.~Wu, R.~Child, D.~Luan, D.~Amodei, and I.~Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI Blog}, 2019.

\bibitem{seq-level}
M.~Ranzato, S.~Chopra, M.~Auli, and W.~Zaremba.
\newblock Sequence level training with recurrent neural networks.
\newblock In {\em ICLR}, 2017.

\bibitem{Rao2018DearSO}
S.~Rao and J.~R. Tetreault.
\newblock Dear sir or madam, may {I} introduce the {GYAFC} dataset: Corpus,
  benchmarks and metrics for formality style transfer.
\newblock In {\em NAACL-HLT}, pages 129--140, 2018.

\bibitem{rose2010automatic}
S.~Rose, D.~Engel, N.~Cramer, and W.~Cowley.
\newblock Automatic keyword extraction from individual documents.
\newblock {\em Text Mining: Applications and Theory}, 1:1--20, 2010.

\bibitem{schumann2020discrete}
R.~Schumann, L.~Mou, Y.~Lu, O.~Vechtomova, and K.~Markert.
\newblock Discrete optimization for unsupervised sentence summarization with
  word-level extraction.
\newblock In {\em ACL}, 2020.

\bibitem{shen2017style}
T.~Shen, T.~Lei, R.~Barzilay, and T.~Jaakkola.
\newblock Style transfer from non-parallel text by cross-alignment.
\newblock In {\em NIPS}, pages 6830--6841, 2017.

\bibitem{alphaGo}
D.~Silver, T.~Hubert, J.~Schrittwieser, I.~Antonoglou, M.~Lai, A.~Guez,
  M.~Lanctot, L.~Sifre, D.~Kumaran, T.~Graepel, et~al.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and {Go} through self-play.
\newblock {\em Science}, 362(6419):1140--1144, 2018.

\bibitem{sun2012joint}
H.~Sun and M.~Zhou.
\newblock Joint learning of a dual {SMT} system for paraphrase generation.
\newblock In {\em ACL}, volume~2, pages 38--42, 2012.

\bibitem{surya2019unsupervised}
S.~Surya, A.~Mishra, A.~Laha, P.~Jain, and K.~Sankaranarayanan.
\newblock Unsupervised neural text simplification.
\newblock In {\em ACL}, pages 2058--2068, 2019.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems}, pages
  5998--6008, 2017.

\bibitem{wang2019topic}
W.~Wang, Z.~Gan, H.~Xu, R.~Zhang, G.~Wang, D.~Shen, C.~Chen, and L.~Carin.
\newblock Topic-guided variational auto-encoder for text generation.
\newblock In {\em NAACL}, pages 166--177, 2019.

\bibitem{weizenbaum1966eliza}
J.~Weizenbaum.
\newblock Elizaâ€”a computer program for the study of natural language
  communication between man and machine.
\newblock {\em Communications of the ACM}, 9(1):36--45, 1966.

\bibitem{BSO}
S.~Wiseman and A.~M. Rush.
\newblock Sequence-to-sequence learning as beam-search optimization.
\newblock In {\em EMNLP}, pages 1296--1306, 2016.

\bibitem{unsupervised}
P.~Xu, J.~C.~K. Cheung, and Y.~Cao.
\newblock On variational learning of controllable representations for text
  without supervision.
\newblock In {\em ICML}, 2020.

\bibitem{Xu2019FormalityST}
R.~Xu, T.~Ge, and F.~Wei.
\newblock Formality style transfer with hybrid textual annotations.
\newblock {\em arXiv preprint arXiv 1903.06353}, 2019.

\bibitem{xu2012paraphrasing}
W.~Xu, A.~Ritter, B.~Dolan, R.~Grishman, and C.~Cherry.
\newblock Paraphrasing for style.
\newblock In {\em COLING}, pages 2899--2914, 2012.

\bibitem{yang2019end}
Q.~Yang, D.~Shen, Y.~Cheng, W.~Wang, G.~Wang, L.~Carin, et~al.
\newblock An end-to-end generative architecture for paraphrase generation.
\newblock In {\em EMNLP-IJCNLP}, pages 3123--3133, 2019.

\bibitem{seqGAN}
L.~Yu, W.~Zhang, J.~Wang, and Y.~Yu.
\newblock {SeqGAN}: Sequence generative adversarial nets with policy gradient.
\newblock In {\em AAAI}, pages 2852--2858, 2017.

\bibitem{zhang2019bridging}
W.~Zhang, Y.~Feng, F.~Meng, D.~You, and Q.~Liu.
\newblock Bridging the gap between training and inference for neural machine
  translation.
\newblock In {\em ACL}, pages 4334--4343, 2019.

\bibitem{zhang2019syntax}
X.~Zhang, Y.~Yang, S.~Yuan, D.~Shen, and L.~Carin.
\newblock Syntax-infused variational autoencoder for text generation.
\newblock In {\em ACL}, pages 2069--2078, 2019.

\bibitem{zhang2018style}
Z.~Zhang, S.~Ren, S.~Liu, J.~Wang, P.~Chen, M.~Li, M.~Zhou, and E.~Chen.
\newblock Style transfer as unsupervised machine translation.
\newblock {\em arXiv preprint arXiv:1808.07894}, 2018.

\bibitem{zhao2010leveraging}
S.~Zhao, H.~Wang, X.~Lan, and T.~Liu.
\newblock Leveraging multiple mt engines for paraphrase generation.
\newblock In {\em COLING}, pages 1326--1334, 2010.

\bibitem{zheng2019sentence}
H.~Zheng and M.~Lapata.
\newblock Sentence centrality revisited for unsupervised summarization.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 6236--6247, 2019.

\end{thebibliography}
