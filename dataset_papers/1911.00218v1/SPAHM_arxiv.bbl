\begin{thebibliography}{}

\bibitem[Bauer {\em et~al.\/}(2016)Bauer, van~der Wilk, and
  Rasmussen]{bauer2016understanding}
Bauer, M., van~der Wilk, M., and Rasmussen, C.~E. (2016).
\newblock Understanding probabilistic sparse gaussian process approximations.
\newblock In {\em Advances in neural information processing systems\/}, pages
  1533--1541.

\bibitem[Baydin {\em et~al.\/}(2018)Baydin, Pearlmutter, Radul, and
  Siskind]{baydin18}
Baydin, A.~G., Pearlmutter, B.~A., Radul, A.~A., and Siskind, J.~M. (2018).
\newblock Automatic differentiation in machine learning: A survey.
\newblock {\em Journal of Machine Learning Research\/}, pages 1--43.

\bibitem[Blei {\em et~al.\/}(2003)Blei, Ng, and Jordan]{blei2003latent}
Blei, D.~M., Ng, A.~Y., and Jordan, M.~I. (2003).
\newblock Latent {D}irichlet {A}llocation.
\newblock {\em Journal of Machine Learning Research\/}, {\bf 3}, 993--1022.

\bibitem[Blomstedt {\em et~al.\/}(2019)Blomstedt, Mesquita, Lintusaari, Sivula,
  Corander, and Kaski]{blomstedt2019meta}
Blomstedt, P., Mesquita, D., Lintusaari, J., Sivula, T., Corander, J., and
  Kaski, S. (2019).
\newblock Meta-analysis of bayesian analyses.
\newblock {\em arXiv preprint arXiv:1904.04484\/}.

\bibitem[Campbell and How(2014)Campbell and How]{CampbellUAI14}
Campbell, T. and How, J.~P. (2014).
\newblock Approximate decentralized bayesian inference.
\newblock In {\em Uncertainty in Artificial Intelligence (UAI)\/}.

\bibitem[Campbell {\em et~al.\/}(2015)Campbell, Straub, Fisher~III, and
  How]{campbell2015streaming}
Campbell, T., Straub, J., Fisher~III, J.~W., and How, J.~P. (2015).
\newblock Streaming, distributed variational inference for bayesian
  nonparametrics.
\newblock In {\em Advances in Neural Information Processing Systems\/}, pages
  280--288.

\bibitem[Das {\em et~al.\/}(2015)Das, Zaheer, and Dyer]{das2015gaussian}
Das, R., Zaheer, M., and Dyer, C. (2015).
\newblock Gaussian lda for topic models with word embeddings.
\newblock In {\em Proceedings of the 53rd Annual Meeting of the Association for
  Computational Linguistics and the 7th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)\/}, volume~1, pages
  795--804.

\bibitem[Dean {\em et~al.\/}(2012)Dean, Corrado, Monga, Chen, Devin, Mao,
  Senior, Tucker, Yang, Le, {\em et~al.\/}]{dean2012large}
Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., Senior, A.,
  Tucker, P., Yang, K., Le, Q.~V., {\em et~al.\/} (2012).
\newblock Large scale distributed deep networks.
\newblock In {\em Advances in neural information processing systems\/}, pages
  1223--1231.

\bibitem[Deisenroth and Ng(2015)Deisenroth and Ng]{Marc15}
Deisenroth, M.~P. and Ng, J.~W. (2015).
\newblock Distributed {Gaussian} processes.
\newblock In {\em Proc. {ICML}\/}, pages 1481--1490.

\bibitem[Dutta {\em et~al.\/}(2016)Dutta, Blomstedt, and
  Kaski]{dutta2016bayesian}
Dutta, R., Blomstedt, P., and Kaski, S. (2016).
\newblock Bayesian inference in hierarchical models by combining independent
  posteriors.
\newblock {\em arXiv preprint arXiv:1603.09272\/}.

\bibitem[{E}{U}(2016){E}{U}]{eu:gdpr}
{E}{U} (2016).
\newblock {Regulation (EU) 2016/679 of the European Parliament and of the
  Council of 27 April 2016 on the protection of natural persons with regard to
  the processing of personal data and on the free movement of such data, and
  repealing Directive 95/46/EC (General Data Protection Regulation)}.
\newblock {\em Official Journal of the European Union\/}, {\bf L119}, 1--88.

\bibitem[Fox {\em et~al.\/}(2009)Fox, Jordan, Sudderth, and
  Willsky]{fox2009sharing}
Fox, E., Jordan, M.~I., Sudderth, E.~B., and Willsky, A.~S. (2009).
\newblock Sharing features among dynamical systems with {B}eta processes.
\newblock In {\em Advances in Neural Information Processing Systems\/}, pages
  549--557.

\bibitem[Fox {\em et~al.\/}(2008)Fox, Sudderth, Jordan, and
  Willsky]{fox2008hdp}
Fox, E.~B., Sudderth, E.~B., Jordan, M.~I., and Willsky, A.~S. (2008).
\newblock An hdp-hmm for systems with state persistence.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning\/}, pages 312--319. ACM.

\bibitem[Fox {\em et~al.\/}(2014)Fox, Hughes, Sudderth, and
  Jordan]{fox2014joint}
Fox, E.~B., Hughes, M.~C., Sudderth, E.~B., and Jordan, M.~I. (2014).
\newblock Joint modeling of multiple time series via the beta process with
  application to motion capture segmentation.
\newblock {\em The Annals of Applied Statistics\/}, pages 1281--1313.

\bibitem[Gal {\em et~al.\/}(2014)Gal, {van der Wilk}, and Rasmussen]{Yarin14}
Gal, Y., {van der Wilk}, M., and Rasmussen, C. (2014).
\newblock Distributed variational inference in sparse {G}aussian process
  regression and latent variable models.
\newblock In {\em Proc. NIPS\/}.

\bibitem[Gelman {\em et~al.\/}(2013)Gelman, Stern, Carlin, Dunson, Vehtari, and
  Rubin]{gelman2013bayesian}
Gelman, A., Stern, H.~S., Carlin, J.~B., Dunson, D.~B., Vehtari, A., and Rubin,
  D.~B. (2013).
\newblock {\em Bayesian data analysis\/}.
\newblock Chapman and Hall/CRC.

\bibitem[Ghahramani and Griffiths(2005)Ghahramani and
  Griffiths]{ghahramani2005infinite}
Ghahramani, Z. and Griffiths, T.~L. (2005).
\newblock Infinite latent feature models and the {I}ndian buffet process.
\newblock In {\em Advances in Neural Information Processing Systems\/}, pages
  475--482.

\bibitem[Hasenclever {\em et~al.\/}(2017)Hasenclever, Webb, Lienart, Vollmer,
  Lakshminarayanan, Blundell, and Teh]{hasenclever2017distributed}
Hasenclever, L., Webb, S., Lienart, T., Vollmer, S., Lakshminarayanan, B.,
  Blundell, C., and Teh, Y.~W. (2017).
\newblock Distributed bayesian learning with stochastic natural gradient
  expectation propagation and the posterior server.
\newblock {\em The Journal of Machine Learning Research\/}, {\bf 18}(1),
  3744--3780.

\bibitem[Heikkil{\"a} {\em et~al.\/}(2017)Heikkil{\"a}, Lagerspetz, Kaski,
  Shimizu, Tarkoma, and Honkela]{heikkila2017differentially}
Heikkil{\"a}, M., Lagerspetz, E., Kaski, S., Shimizu, K., Tarkoma, S., and
  Honkela, A. (2017).
\newblock Differentially private bayesian learning on distributed data.
\newblock In {\em Advances in neural information processing systems\/}, pages
  3226--3235.

\bibitem[Hoang {\em et~al.\/}(2019a)Hoang, Hoang, Low, and
  Kingsford]{hoang2019modelfusion}
Hoang, Q.~M., Hoang, T.~N., Low, K.~H., and Kingsford, C. (2019a).
\newblock Collective model fusion for multiple black-box experts.
\newblock In {\em Proc. ICML\/}, pages 2742--2750.

\bibitem[Hoang {\em et~al.\/}(2016)Hoang, Hoang, and Low]{NghiaICML16}
Hoang, T.~N., Hoang, Q.~M., and Low, K.~H. (2016).
\newblock A distributed variational inference framework for unifying parallel
  sparse {G}aussian process regression models.
\newblock In {\em Proc. {ICML}\/}, pages 382--391.

\bibitem[Hoang {\em et~al.\/}(2018)Hoang, Hoang, Ruofei, and Low]{NghiaAAAI18}
Hoang, T.~N., Hoang, Q.~M., Ruofei, O., and Low, K.~H. (2018).
\newblock Decentralized high-dimensional bayesian optimization with factor
  graphs.
\newblock In {\em Proc. AAAI\/}.

\bibitem[Hoang {\em et~al.\/}(2019b)Hoang, Hoang, Low, and How]{NghiaAAAI19}
Hoang, T.~N., Hoang, Q.~M., Low, K.~H., and How, J.~P. (2019b).
\newblock Collective online learning of gaussian processes in massive
  multi-agent systems.
\newblock In {\em Proc. AAAI\/}.

\bibitem[Hughes {\em et~al.\/}(2015)Hughes, Stephenson, and
  Sudderth]{hughes2015scalable}
Hughes, M.~C., Stephenson, W.~T., and Sudderth, E. (2015).
\newblock Scalable adaptation of state complexity for nonparametric hidden
  markov models.
\newblock In {\em Advances in Neural Information Processing Systems\/}, pages
  1198--1206.

\bibitem[Kuhn(1955)Kuhn]{kuhn1955hungarian}
Kuhn, H.~W. (1955).
\newblock The {H}ungarian method for the assignment problem.
\newblock {\em Naval Research Logistics (NRL)\/}, {\bf 2}(1-2), 83--97.

\bibitem[Lahiri(2014)Lahiri]{lahiri:2014:SRW}
Lahiri, S. (2014).
\newblock {Complexity of Word Collocation Networks: A Preliminary Structural
  Analysis}.
\newblock In {\em Proceedings of the Student Research Workshop at the 14th
  Conference of the European Chapter of the Association for Computational
  Linguistics\/}, pages 96--105, Gothenburg, Sweden. Association for
  Computational Linguistics.

\bibitem[McMahan {\em et~al.\/}(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A. (2017).
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em Artificial Intelligence and Statistics\/}, pages 1273--1282.

\bibitem[Newman {\em et~al.\/}(2010)Newman, Lau, Grieser, and
  Baldwin]{newman2010automatic}
Newman, D., Lau, J.~H., Grieser, K., and Baldwin, T. (2010).
\newblock Automatic evaluation of topic coherence.
\newblock In {\em Human Language Technologies: The 2010 Annual Conference of
  the North American Chapter of the Association for Computational
  Linguistics\/}, pages 100--108. Association for Computational Linguistics.

\bibitem[Rand(1971)Rand]{rand1971objective}
Rand, W.~M. (1971).
\newblock Objective criteria for the evaluation of clustering methods.
\newblock {\em Journal of the American Statistical association\/}, {\bf
  66}(336), 846--850.

\bibitem[Teh {\em et~al.\/}(2005)Teh, Jordan, Beal, and Blei]{teh2005sharing}
Teh, Y.~W., Jordan, M.~I., Beal, M.~J., and Blei, D.~M. (2005).
\newblock Sharing clusters among related groups: Hierarchical dirichlet
  processes.
\newblock In {\em Advances in neural information processing systems\/}, pages
  1385--1392.

\bibitem[Teh {\em et~al.\/}(2007)Teh, Gr{\"u}r, and Ghahramani]{teh2007stick}
Teh, Y.~W., Gr{\"u}r, D., and Ghahramani, Z. (2007).
\newblock Stick-breaking construction for the {I}ndian buffet process.
\newblock In {\em Artificial Intelligence and Statistics\/}, pages 556--563.

\bibitem[Thibaux and Jordan(2007)Thibaux and Jordan]{thibaux2007hierarchical}
Thibaux, R. and Jordan, M.~I. (2007).
\newblock Hierarchical {B}eta processes and the {I}ndian buffet process.
\newblock In {\em Artificial Intelligence and Statistics\/}, pages 564--571.

\bibitem[Vershynin(2010)Vershynin]{vershynin2010introduction}
Vershynin, R. (2010).
\newblock Introduction to the non-asymptotic analysis of random matrices.
\newblock {\em arXiv preprint arXiv:1011.3027\/}.

\bibitem[Yurochkin {\em et~al.\/}(2019a)Yurochkin, Agarwal, Ghosh, Greenewald,
  Hoang, and Khazaeni]{yurochkin2019bayesian}
Yurochkin, M., Agarwal, M., Ghosh, S., Greenewald, K., Hoang, N., and Khazaeni,
  Y. (2019a).
\newblock Bayesian nonparametric federated learning of neural networks.
\newblock In {\em International Conference on Machine Learning\/}, pages
  7252--7261.

\bibitem[Yurochkin {\em et~al.\/}(2019b)Yurochkin, Fan, Guha, Koutris, and
  Nguyen]{yurochkin2019sddm}
Yurochkin, M., Fan, Z., Guha, A., Koutris, P., and Nguyen, X. (2019b).
\newblock Scalable inference of topic evolution via models for latent geometric
  structures.
\newblock In {\em Advances in Neural Information Processing Systems\/}.

\end{thebibliography}
