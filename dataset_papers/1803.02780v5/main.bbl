\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bergstra and Bengio(2012)]{bergstra2012random}
James Bergstra and Yoshua Bengio.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{JMLR}, 2012.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra2011algorithms}
James~S Bergstra, R{\'e}mi Bardenet, Yoshua Bengio, and Bal{\'a}zs K{\'e}gl.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{NIPS}, 2011.

\bibitem[Bergstra et~al.(2013)Bergstra, Yamins, and Cox]{bergstra2013making}
James Bergstra, Daniel Yamins, and David Cox.
\newblock Making a science of model search: Hyperparameter optimization in
  hundreds of dimensions for vision architectures.
\newblock In \emph{ICML}, 2013.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Jasper Snoek, Hugo Larochelle, and Ryan~P Adams.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{NIPS}, 2012.

\bibitem[Real et~al.(2017)Real, Moore, Selle, Saxena, Suematsu, Le, and
  Kurakin]{real2017large}
Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka~Leon Suematsu,
  Quoc Le, and Alex Kurakin.
\newblock Large-scale evolution of image classifiers.
\newblock In \emph{ICML}, 2017.

\bibitem[Miikkulainen et~al.(2017)Miikkulainen, Liang, Meyerson, Rawal, Fink,
  Francon, Raju, Shahrzad, Navruzyan, Duffy, and
  Hodjat]{miikkulainen2017evolving}
Risto Miikkulainen, Jason~Zhi Liang, Elliot Meyerson, Aditya Rawal, Dan Fink,
  Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel Duffy,
  and Babak Hodjat.
\newblock Evolving deep neural networks.
\newblock \emph{CoRR}, abs/1703.00548, 2017.

\bibitem[Baker et~al.(2017)Baker, Gupta, Naik, and Raskar]{baker2017designing}
Bowen Baker, Otkrist Gupta, Nikhil Naik, and Ramesh Raskar.
\newblock Designing neural network architectures using reinforcement learning.
\newblock In \emph{ICLR}, 2017.

\bibitem[Zoph and Le(2017)]{ZophLe2017}
Barret Zoph and Quoc~V. Le.
\newblock Neural architecture search with reinforcement learning.
\newblock In \emph{ICLR}, 2017.

\bibitem[Zhong et~al.(2018)Zhong, Yan, and Liu]{zhong2018practical}
Zhao Zhong, Junjie Yan, and Cheng-Lin Liu.
\newblock Practical network blocks design with q-learning.
\newblock In \emph{AAAI}, 2018.

\bibitem[Zoph et~al.(2017)Zoph, Vasudevan, Shlens, and Le]{ZophVSL17}
Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc~V. Le.
\newblock Learning transferable architectures for scalable image recognition.
\newblock \emph{CoRR}, abs/1707.07012, 2017.

\bibitem[Liu et~al.(2017)Liu, Zoph, Shlens, Hua, Li, Fei-Fei, Yuille, Huang,
  and Murphy]{liu2017progressive}
Chenxi Liu, Barret Zoph, Jonathon Shlens, Wei Hua, Li-Jia Li, Li~Fei-Fei, Alan
  Yuille, Jonathan Huang, and Kevin Murphy.
\newblock Progressive neural architecture search.
\newblock \emph{arXiv preprint arXiv:1712.00559}, 2017.

\bibitem[Pham et~al.(2018)Pham, Guan, Zoph, Le, and Dean]{pham2018efficient}
Hieu Pham, Melody~Y Guan, Barret Zoph, Quoc~V Le, and Jeff Dean.
\newblock Efficient neural architecture search via parameter sharing.
\newblock \emph{arXiv preprint arXiv:1802.03268}, 2018.

\bibitem[Liu et~al.(2018)Liu, Simonyan, and Yang]{liu2018darts}
Hanxiao Liu, Karen Simonyan, and Yiming Yang.
\newblock Darts: Differentiable architecture search.
\newblock \emph{arXiv preprint arXiv:1806.09055}, 2018.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{NIPS}, pages 3111--3119, 2013.

\bibitem[Greensmith et~al.(2004)Greensmith, Bartlett, and
  Baxter]{greensmith2004variance}
Evan Greensmith, Peter~L Bartlett, and Jonathan Baxter.
\newblock Variance reduction techniques for gradient estimates in reinforcement
  learning.
\newblock \emph{JMLR}, 2004.

\bibitem[Feurer et~al.(2015)Feurer, Springenberg, and
  Hutter]{feurer2015initializing}
Matthias Feurer, Jost~Tobias Springenberg, and Frank Hutter.
\newblock Initializing bayesian hyperparameter optimization via meta-learning.
\newblock In \emph{AAAI}, 2015.

\bibitem[Negrinho and Gordon(2017)]{negrinho2017deeparchitect}
Renato Negrinho and Geoff Gordon.
\newblock Deeparchitect: Automatically designing and training deep
  architectures.
\newblock \emph{arXiv preprint arXiv:1704.08792}, 2017.

\bibitem[Wichrowska et~al.(2017)Wichrowska, Maheswaranathan, Hoffman,
  Colmenarejo, Denil, de~Freitas, and Sohl-Dickstein]{wichrowska2017learned}
Olga Wichrowska, Niru Maheswaranathan, Matthew~W Hoffman, Sergio~Gomez
  Colmenarejo, Misha Denil, Nando de~Freitas, and Jascha Sohl-Dickstein.
\newblock Learned optimizers that scale and generalize.
\newblock \emph{arXiv preprint arXiv:1703.04813}, 2017.

\bibitem[Bello et~al.(2017)Bello, Zoph, Vasudevan, and Le]{bello2017neural}
Irwan Bello, Barret Zoph, Vijay Vasudevan, and Quoc~V. Le.
\newblock Neural optimizer search with reinforcement learning.
\newblock In \emph{ICML}, 2017.

\bibitem[Conti et~al.(2017)Conti, Madhavan, Such, Lehman, Stanley, and
  Clune]{conti2017improving}
Edoardo Conti, Vashisht Madhavan, Felipe~Petroski Such, Joel Lehman, Kenneth~O
  Stanley, and Jeff Clune.
\newblock Improving exploration in evolution strategies for deep reinforcement
  learning via a population of novelty-seeking agents.
\newblock \emph{arXiv preprint arXiv:1712.06560}, 2017.

\bibitem[Such et~al.(2017)Such, Madhavan, Conti, Lehman, Stanley, and
  Clune]{such2017deep}
Felipe~Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman, Kenneth~O
  Stanley, and Jeff Clune.
\newblock Deep neuroevolution: Genetic algorithms are a competitive alternative
  for training deep neural networks for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1712.06567}, 2017.

\bibitem[Baker et~al.(2016)Baker, Gupta, Naik, and Raskar]{baker2016designing}
Bowen Baker, Otkrist Gupta, Nikhil Naik, and Ramesh Raskar.
\newblock Designing neural network architectures using reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02167}, 2016.

\bibitem[Cai et~al.(2017)Cai, Chen, Zhang, Yu, and Wang]{cai2017reinforcement}
Han Cai, Tianyao Chen, Weinan Zhang, Yong Yu, and Jun Wang.
\newblock Reinforcement learning for architecture search by network
  transformation.
\newblock \emph{arXiv preprint arXiv:1707.04873}, 2017.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski2014transferable}
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
\newblock How transferable are features in deep neural networks?
\newblock In \emph{NIPS}, 2014.

\bibitem[Sharif~Razavian et~al.(2014)Sharif~Razavian, Azizpour, Sullivan, and
  Carlsson]{sharif2014cnn}
Ali Sharif~Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan Carlsson.
\newblock Cnn features off-the-shelf: an astounding baseline for recognition.
\newblock In \emph{CVPR workshops}, 2014.

\bibitem[Zhan and Taylor(2015)]{zhan2015online}
Yusen Zhan and Matthew~E Taylor.
\newblock Online transfer learning in reinforcement learning domains.
\newblock \emph{arXiv preprint arXiv:1507.00436}, 2015.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock \emph{ICML}, 2017.

\bibitem[Mishra et~al.(2017)Mishra, Rohaninejad, Chen, and
  Abbeel]{mishra2017simple}
Nikhil Mishra, Mostafa Rohaninejad, Xi~Chen, and Pieter Abbeel.
\newblock A simple neural attentive meta-learner.
\newblock In \emph{NIPS 2017 Workshop on Meta-Learning}, 2017.

\bibitem[Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska,
  et~al.]{kirkpatrick2017overcoming}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{PNAS}, 2017.

\bibitem[Teh et~al.(2017)Teh, Bapst, Czarnecki, Quan, Kirkpatrick, Hadsell,
  Heess, and Pascanu]{teh2017distral}
Yee~Whye Teh, Victor Bapst, Wojciech~Marian Czarnecki, John Quan, James
  Kirkpatrick, Raia Hadsell, Nicolas Heess, and Razvan Pascanu.
\newblock Distral: Robust multitask reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1707.04175}, 2017.

\bibitem[Bardenet et~al.(2013)Bardenet, Brendel, K{\'e}gl, and
  Sebag]{bardenet2013collaborative}
R{\'e}mi Bardenet, M{\'a}ty{\'a}s Brendel, Bal{\'a}zs K{\'e}gl, and Michele
  Sebag.
\newblock Collaborative hyperparameter tuning.
\newblock In \emph{ICML}, pages 199--207, 2013.

\bibitem[Yogatama and Mann(2014)]{yogatama2014efficient}
Dani Yogatama and Gideon Mann.
\newblock Efficient transfer learning method for automatic hyperparameter
  tuning.
\newblock In \emph{AISTATS}, pages 1077--1085, 2014.

\bibitem[Cheng et~al.(2016)Cheng, Koc, Harmsen, Shaked, Chandra, Aradhye,
  Anderson, Corrado, Chai, Ispir, Anil, Haque, Hong, Jain, Liu, and
  Shah]{cheng2017}
Heng{-}Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
  Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan
  Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah.
\newblock Wide {\&} deep learning for recommender systems.
\newblock \emph{CoRR}, abs/1606.07792, 2016.

\bibitem[Williams(1992)]{williams1992simple}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock In \emph{Reinforcement Learning}. Springer, 1992.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015trust}
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp
  Moritz.
\newblock Trust region policy optimization.
\newblock In \emph{ICML}, 2015.

\bibitem[Nachum et~al.(2017)Nachum, Norouzi, and Schuurmans]{Nachum2017}
Ofir Nachum, Mohammad Norouzi, and Dale Schuurmans.
\newblock Improving policy gradient by exploring under-appreciated rewards.
\newblock In \emph{ICLR}, 2017.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Almeida et~al.(2013)Almeida, Hidalgo, and Silva]{almeida2013towards}
Tiago Almeida, Jos{\'e} Mar{\'\i}a~G{\'o}mez Hidalgo, and Tiago~Pasqualini
  Silva.
\newblock Towards sms spam filtering: Results under a new dataset.
\newblock \emph{International Journal of Information Security Science}, 2013.

\bibitem[Le and Mikolov(2014)]{LeM14}
Quoc Le and Tomas Mikolov.
\newblock Distributed representations of sentences and documents.
\newblock In \emph{ICML}, ICML'14, 2014.

\bibitem[Li et~al.(2016)Li, Zhao, Liu, Wang, and Du]{li2016weighted}
Bofang Li, Zhe Zhao, Tao Liu, Puwei Wang, and Xiaoyong Du.
\newblock Weighted neural bag-of-n-grams model: New baselines for text
  classification.
\newblock In \emph{COLING}, 2016.

\bibitem[Barnes et~al.(2017)Barnes, Klinger, and Schulte~im Walde]{barnes2017}
Jeremy Barnes, Roman Klinger, and Sabine Schulte~im Walde.
\newblock Assessing state-of-the-art sentiment models on state-of-the-art
  sentiment datasets.
\newblock In \emph{Proceedings of the 8th Workshop on Computational Approaches
  to Subjectivity, Sentiment and Social Media Analysis}. ACL, 2017.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and
  Potts]{maas-EtAl:2011:ACL-HLT2011}
Andrew~L. Maas, Raymond~E. Daly, Peter~T. Pham, Dan Huang, Andrew~Y. Ng, and
  Christopher Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{ACL: Human Language Technologies}. ACL, 2011.

\bibitem[Ramachandran et~al.(2017)Ramachandran, Zoph, and
  Le]{ramachandran2017swish}
Prajit Ramachandran, Barret Zoph, and Quoc~V Le.
\newblock Swish: a self-gated activation function.
\newblock \emph{arXiv preprint arXiv:1710.05941}, 2017.

\end{thebibliography}
