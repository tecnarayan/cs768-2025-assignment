\begin{thebibliography}{10}

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem{openai2023gpt4}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock {GPT-4 Technical Report}.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{nori2023capabilities}
Harsha Nori, Nicholas King, Scott~Mayer McKinney, Dean Carignan, and Eric Horvitz.
\newblock Capabilities of gpt-4 on medical challenge problems.
\newblock {\em arXiv preprint arXiv:2303.13375}, 2023.

\bibitem{liang2022effective}
Xiwen Liang, Yangxin Wu, Jianhua Han, Hang Xu, Chunjing Xu, and Xiaodan Liang.
\newblock Effective adaptation in multi-task co-training for unified autonomous driving.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{liang2023visual}
Xiwen Liang, Minzhe Niu, Jianhua Han, Hang Xu, Chunjing Xu, and Xiaodan Liang.
\newblock Visual exemplar driven task-prompting for unified perception in autonomous driving.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 9611--9621, 2023.

\bibitem{teach1981analysis}
Randy~L Teach and Edward~H Shortliffe.
\newblock An analysis of physician attitudes regarding computer-based clinical consultation systems.
\newblock {\em Computers and Biomedical Research}, 14(6):542--558, 1981.

\bibitem{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock " why should i trust you?" explaining the predictions of any classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining}, pages 1135--1144, 2016.

\bibitem{rudin2019stop}
Cynthia Rudin.
\newblock Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead.
\newblock {\em Nature Machine Intelligence}, 1(5):206--215, 2019.

\bibitem{menon2022visual}
Sachit Menon and Carl Vondrick.
\newblock Visual classification via description from large language models.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{yuksekgonul2022post}
Mert Yuksekgonul, Maggie Wang, and James Zou.
\newblock Post-hoc concept bottleneck models.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{yuksekgonul2022and}
Mert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, and James Zou.
\newblock When and why vision-language models behave like bags-of-words, and what to do about it?
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{ye2023improving}
Shuquan Ye, Yujia Xie, Dongdong Chen, Yichong Xu, Lu~Yuan, Chenguang Zhu, and Jing Liao.
\newblock Improving commonsense in vision-language models via knowledge graph riddles.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2634--2645, 2023.

\bibitem{li2025deal}
Tang Li, Mengmeng Ma, and Xi~Peng.
\newblock Deal: Disentangle and localize concept-level explanations for vlms.
\newblock In {\em European Conference on Computer Vision}, pages 383--401. Springer, 2025.

\bibitem{margeloiu2021concept}
Andrei Margeloiu, Matthew Ashman, Umang Bhatt, Yanzhi Chen, Mateja Jamnik, and Adrian Weller.
\newblock Do concept bottleneck models learn as intended?
\newblock {\em ICLR Workshop}, 2021.

\bibitem{tong2024eyes}
Shengbang Tong, Zhuang Liu, Yuexiang Zhai, Yi~Ma, Yann LeCun, and Saining Xie.
\newblock Eyes wide shut? exploring the visual shortcomings of multimodal llms.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 9568--9578, 2024.

\bibitem{fei2006one}
Li~Fei-Fei, Robert Fergus, and Pietro Perona.
\newblock One-shot learning of object categories.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence}, 28(4):594--611, 2006.

\bibitem{wah2011caltech}
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem{speer2017conceptnet}
Robyn Speer, Joshua Chin, and Catherine Havasi.
\newblock Conceptnet 5.5: An open multilingual graph of general knowledge.
\newblock In {\em Proceedings of the AAAI conference on artificial intelligence}, volume~31, 2017.

\bibitem{miller1995wordnet}
George~A Miller.
\newblock Wordnet: a lexical database for english.
\newblock {\em Communications of the ACM}, 38(11):39--41, 1995.

\bibitem{krishna2017visual}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced dense image annotations.
\newblock {\em International journal of computer vision}, 123:32--73, 2017.

\bibitem{tschandl2018ham10000}
Philipp Tschandl, Cliff Rosendahl, and Harald Kittler.
\newblock The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions.
\newblock {\em Scientific data}, 5(1):1--9, 2018.

\bibitem{roscher2020explainable}
Ribana Roscher, Bastian Bohn, Marco~F Duarte, and Jochen Garcke.
\newblock Explainable machine learning for scientific insights and discoveries.
\newblock {\em Ieee Access}, 8:42200--42216, 2020.

\bibitem{barsalou2008grounded}
Lawrence~W Barsalou.
\newblock Grounded cognition.
\newblock {\em Annu. Rev. Psychol.}, 59:617--645, 2008.

\bibitem{siskind1994grounding}
Jeffrey~Mark Siskind.
\newblock Grounding language in perception.
\newblock {\em Artificial Intelligence Review}, 8:371--391, 1994.

\bibitem{daneshjou2022skincon}
Roxana Daneshjou, Mert Yuksekgonul, Zhuo~Ran Cai, Roberto Novoa, and James~Y Zou.
\newblock Skincon: A skin disease dataset densely annotated by domain experts for fine-grained debugging and analysis.
\newblock {\em Advances in Neural Information Processing Systems}, 35:18157--18167, 2022.

\bibitem{wang2020self}
Yude Wang, Jie Zhang, Meina Kan, Shiguang Shan, and Xilin Chen.
\newblock Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12275--12284, 2020.

\bibitem{wang2017knowledge}
Quan Wang, Zhendong Mao, Bin Wang, and Li~Guo.
\newblock Knowledge graph embedding: A survey of approaches and applications.
\newblock {\em IEEE transactions on knowledge and data engineering}, 29(12):2724--2743, 2017.

\bibitem{ji2021survey}
Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S~Yu Philip.
\newblock A survey on knowledge graphs: Representation, acquisition, and applications.
\newblock {\em IEEE transactions on neural networks and learning systems}, 33(2):494--514, 2021.

\bibitem{bubeck2023sparks}
S{\'e}bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg, et~al.
\newblock Sparks of artificial general intelligence: Early experiments with gpt-4. arxiv.
\newblock {\em arXiv preprint arXiv:2303.12712}, 2023.

\bibitem{liu2023holistic}
Zhengliang Liu, Hanqi Jiang, Tianyang Zhong, Zihao Wu, Chong Ma, Yiwei Li, Xiaowei Yu, Yutong Zhang, Yi~Pan, Peng Shu, et~al.
\newblock Holistic evaluation of gpt-4v for biomedical imaging.
\newblock {\em arXiv preprint arXiv:2312.05256}, 2023.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems}, 33:1877--1901, 2020.

\bibitem{mcintosh2023culturally}
Timothy~R McIntosh, Tong Liu, Teo Susnjak, Paul Watters, Alex Ng, and Malka~N Halgamuge.
\newblock A culturally sensitive test to evaluate nuanced gpt hallucination.
\newblock {\em IEEE Transactions on Artificial Intelligence}, 2023.

\bibitem{chelli2024hallucination}
Mika{\"e}l Chelli, Jules Descamps, Vincent Lavou{\'e}, Christophe Trojani, Michel Azar, Marcel Deckert, Jean-Luc Raynier, Gilles Clowez, Pascal Boileau, and Caroline Ruetsch-Chelli.
\newblock Hallucination rates and reference accuracy of chatgpt and bard for systematic reviews: Comparative analysis.
\newblock {\em Journal of Medical Internet Research}, 26:e53164, 2024.

\bibitem{yang2023language}
Yue Yang, Artemis Panagopoulou, Shenghao Zhou, Daniel Jin, Chris Callison-Burch, and Mark Yatskar.
\newblock Language in a bottle: Language model guided concept bottlenecks for interpretable image classification.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 19187--19197, 2023.

\bibitem{qin2022medical}
Ziyuan Qin, Hua~Hui Yi, Qicheng Lao, and Kang Li.
\newblock Medical image understanding with pretrained vision language models: A comprehensive study.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{zhou2022conditional}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Conditional prompt learning for vision-language models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 16816--16825, 2022.

\bibitem{abnar2020quantifying}
Samira Abnar and Willem Zuidema.
\newblock Quantifying attention flow in transformers.
\newblock {\em arXiv preprint arXiv:2005.00928}, 2020.

\bibitem{chefer2021transformer}
Hila Chefer, Shir Gur, and Lior Wolf.
\newblock Transformer interpretability beyond attention visualization.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 782--791, 2021.

\bibitem{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based localization.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 618--626, 2017.

\bibitem{liu2022rethinking}
Yibing Liu, Haoliang Li, Yangyang Guo, Chenqi Kong, Jing Li, and Shiqi Wang.
\newblock Rethinking attention-model explainability through faithfulness violation test.
\newblock In {\em International Conference on Machine Learning}, pages 13807--13824. PMLR, 2022.

\bibitem{elhage2021mathematical}
Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, et~al.
\newblock A mathematical framework for transformer circuits.
\newblock {\em Transformer Circuits Thread}, 1(1):12, 2021.

\bibitem{gandelsman2023interpreting}
Yossi Gandelsman, Alexei~A Efros, and Jacob Steinhardt.
\newblock Interpreting clip's image representation via text-based decomposition.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2023.

\bibitem{guillaumin2014imagenet}
Matthieu Guillaumin, Daniel K{\"u}ttel, and Vittorio Ferrari.
\newblock Imagenet auto-annotation with segmentation propagation.
\newblock {\em International Journal of Computer Vision}, 110:328--348, 2014.

\bibitem{binder2016layer}
Alexander Binder, Gr{\'e}goire Montavon, Sebastian Lapuschkin, Klaus-Robert M{\"u}ller, and Wojciech Samek.
\newblock Layer-wise relevance propagation for neural networks with local renormalization layers.
\newblock In {\em Artificial Neural Networks and Machine Learning--ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II 25}, pages 63--71. Springer, 2016.

\bibitem{li2023dre}
Tang Li, Fengchun Qiao, Mengmeng Ma, and Xi~Peng.
\newblock Are data-driven explanations robust against out-of-distribution data?
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3821--3831, 2023.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{robey2021model}
Alexander Robey, George~J Pappas, and Hamed Hassani.
\newblock Model-based domain generalization.
\newblock {\em Advances in Neural Information Processing Systems}, 34:20210--20229, 2021.

\bibitem{qiao2023topology}
Fengchun Qiao and Xi~Peng.
\newblock Topology-aware robust optimization for out-of-distribution generalization.
\newblock In {\em Proceedings of the International Conference on Learning Representations (ICLR)}, 2023.

\bibitem{boyd2004convex}
Stephen Boyd, Stephen~P Boyd, and Lieven Vandenberghe.
\newblock {\em Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem{ma2024beyond}
Mengmeng Ma, Tang Li, and Xi~Peng.
\newblock Beyond the federation: Topology-aware federated learning for generalization to unseen clients.
\newblock In {\em Proceedings of the International Conference on Machine Learning (ICML)}, 2024.

\bibitem{gao2022pyramidclip}
Yuting Gao, Jinfeng Liu, Zihan Xu, Jun Zhang, Ke~Li, Rongrong Ji, and Chunhua Shen.
\newblock Pyramidclip: Hierarchical feature alignment for vision-language model pretraining.
\newblock {\em Advances in neural information processing systems}, 35:35959--35970, 2022.

\bibitem{zeng2022multi}
Yan Zeng, Xinsong Zhang, and Hang Li.
\newblock Multi-grained vision language pre-training: Aligning texts with visual concepts.
\newblock In {\em International Conference on Machine Learning}, pages 25994--26009. PMLR, 2022.

\bibitem{torralba2011unbiased}
Antonio Torralba and Alexei~A Efros.
\newblock Unbiased look at dataset bias.
\newblock In {\em CVPR 2011}, pages 1521--1528. IEEE, 2011.

\bibitem{li2022supervision}
Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao, Fengwei Yu, and Junjie Yan.
\newblock Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{yao2021filip}
Y.~L. et~al.
\newblock Filip: Fine-grained interactive language-image pre-training.
\newblock {\em ICLR}, 2022.

\bibitem{fei2004learning}
Li~Fei-Fei, Rob Fergus, and Pietro Perona.
\newblock Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories.
\newblock In {\em 2004 conference on computer vision and pattern recognition workshop}, pages 178--178. IEEE, 2004.

\bibitem{parkhi2012cats}
Omkar~M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV~Jawahar.
\newblock Cats and dogs.
\newblock In {\em 2012 IEEE conference on computer vision and pattern recognition}, pages 3498--3505. IEEE, 2012.

\bibitem{bossard2014food}
Lukas Bossard, Matthieu Guillaumin, and Luc Van~Gool.
\newblock Food-101--mining discriminative components with random forests.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VI 13}, pages 446--461. Springer, 2014.

\bibitem{xiao2010sun}
Jianxiong Xiao, James Hays, Krista~A Ehinger, Aude Oliva, and Antonio Torralba.
\newblock Sun database: Large-scale scene recognition from abbey to zoo.
\newblock In {\em 2010 IEEE computer society conference on computer vision and pattern recognition}, pages 3485--3492. IEEE, 2010.

\bibitem{krause20133d}
Jonathan Krause, Michael Stark, Jia Deng, and Li~Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In {\em Proceedings of the IEEE international conference on computer vision workshops}, pages 554--561, 2013.

\bibitem{cimpoi2014describing}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi.
\newblock Describing textures in the wild.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 3606--3613, 2014.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{young2014image}
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.
\newblock From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions.
\newblock {\em Transactions of the Association for Computational Linguistics}, 2:67--78, 2014.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755. Springer, 2014.

\bibitem{saha2022improving}
Oindrila Saha, Zezhou Cheng, and Subhransu Maji.
\newblock Improving few-shot part segmentation using coarse supervision.
\newblock In {\em European Conference on Computer Vision}, pages 283--299. Springer, 2022.

\bibitem{he2022partimagenet}
Ju~He, Shuo Yang, Shaokang Yang, Adam Kortylewski, Xiaoding Yuan, Jie-Neng Chen, Shuai Liu, Cheng Yang, Qihang Yu, and Alan Yuille.
\newblock Partimagenet: A large, high-quality dataset of parts.
\newblock In {\em European Conference on Computer Vision}, pages 128--145. Springer, 2022.

\bibitem{loshchilov2018decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{selva2017grad}
R.~S. et~al.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based localization.
\newblock {\em ICCV}, 2017.

\bibitem{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In {\em International conference on machine learning}, pages 4904--4916. PMLR, 2021.

\bibitem{roth2023waffling}
Karsten Roth, Jae~Myung Kim, A~Koepke, Oriol Vinyals, Cordelia Schmid, and Zeynep Akata.
\newblock Waffling around for performance: Visual classification with random words and broad concepts.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 15746--15757, 2023.

\bibitem{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{kim2018interpretability}
Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, et~al.
\newblock Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav).
\newblock In {\em International conference on machine learning}, pages 2668--2677. PMLR, 2018.

\bibitem{achtibat2022towards}
Reduan Achtibat, Maximilian Dreyer, Ilona Eisenbraun, Sebastian Bosse, Thomas Wiegand, Wojciech Samek, and Sebastian Lapuschkin.
\newblock From" where" to" what": Towards human-understandable explanations through concept relevance propagation.
\newblock {\em arXiv preprint arXiv:2206.03208}, 2022.

\bibitem{koh2020concept}
Pang~Wei Koh, Thao Nguyen, Yew~Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, and Percy Liang.
\newblock Concept bottleneck models.
\newblock In {\em International conference on machine learning}, pages 5338--5348. PMLR, 2020.

\bibitem{chen2019looks}
Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, and Jonathan~K Su.
\newblock This looks like that: deep learning for interpretable image recognition.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}, 2019.

\bibitem{qiao2020learning}
Fengchun Qiao, Long Zhao, and Xi~Peng.
\newblock Learning to learn single domain generalization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12556--12565, 2020.

\bibitem{li2021deep}
Tang Li, Jing Gao, and Xi~Peng.
\newblock Deep learning for spatiotemporal modeling of urbanization.
\newblock {\em Advances in Neural Information Processing Systems Workshops (Best Paper Award)}, 2021.

\bibitem{shen2022k}
S.~S. et~al.
\newblock K-lite: Learning transferable visual models with external knowledge.
\newblock {\em NeurIPS}, 2022.

\bibitem{meyer2012wiktionary}
Christian~M Meyer and Iryna Gurevych.
\newblock {\em Wiktionary: A new rival for expert-built lexicons? Exploring the possibilities of collaborative lexicography}.
\newblock na, 2012.

\bibitem{huang2024structure}
Yufeng Huang, Jiji Tang, Zhuo Chen, Rongsheng Zhang, Xinfeng Zhang, Weijie Chen, Zeng Zhao, Zhou Zhao, Tangjie Lv, Zhipeng Hu, et~al.
\newblock Structure-clip: Towards scene graph knowledge to enhance multi-modal structured representations.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 2417--2425, 2024.

\bibitem{ma2021smil}
Mengmeng Ma, Jian Ren, Long Zhao, Sergey Tulyakov, Cathy Wu, and Xi~Peng.
\newblock Smil: Multimodal learning with severely missing modality.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pages 2302--2310, 2021.

\bibitem{ma2022multimodal}
Mengmeng Ma, Jian Ren, Long Zhao, Davide Testuggine, and Xi~Peng.
\newblock Are multimodal transformers robust to missing modality?
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18177--18186, 2022.

\end{thebibliography}
