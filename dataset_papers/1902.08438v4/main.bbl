\begin{thebibliography}{73}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Al-Shedivat et~al.(2017)Al-Shedivat, Bansal, Burda, Sutskever,
  Mordatch, and Abbeel]{AlShedivat2017ContinuousAV}
Al-Shedivat, M., Bansal, T., Burda, Y., Sutskever, I., Mordatch, I., and
  Abbeel, P.
\newblock Continuous adaptation via meta-learning in nonstationary and
  competitive environments.
\newblock \emph{CoRR}, abs/1710.03641, 2017.

\bibitem[Aljundi et~al.(2017)Aljundi, Chakravarty, and
  Tuytelaars]{aljundi2017expert}
Aljundi, R., Chakravarty, P., and Tuytelaars, T.
\newblock Expert gate: Lifelong learning with a network of experts.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017.

\bibitem[Alquier et~al.(2016)Alquier, Mai, and Pontil]{Alquier2016RegretBF}
Alquier, P., Mai, T.~T., and Pontil, M.
\newblock Regret bounds for lifelong learning.
\newblock In \emph{AISTATS}, 2016.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, and de~Freitas]{learntolearnbygdbygd}
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.~W., Pfau, D., Schaul, T.,
  and de~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2016.

\bibitem[Antoniou et~al.(2018)Antoniou, Edwards, and
  Storkey]{antoniou2018train}
Antoniou, A., Edwards, H., and Storkey, A.
\newblock How to train your maml.
\newblock \emph{arXiv preprint arXiv:1810.09502}, 2018.

\bibitem[Barto et~al.(1995)Barto, Bradtke, and Singh]{Barto1995}
Barto, A.~G., Bradtke, S.~J., and Singh, S.~P.
\newblock Learning to act using real-time dynamic programming.
\newblock \emph{Artif. Intell.}, 72:\penalty0 81--138, 1995.

\bibitem[Baydin et~al.(2017)Baydin, Cornish, Rubio, Schmidt, and
  Wood]{baydin2017online}
Baydin, A.~G., Cornish, R., Rubio, D.~M., Schmidt, M., and Wood, F.
\newblock Online learning rate adaptation with hypergradient descent.
\newblock \emph{arXiv:1703.04782}, 2017.

\bibitem[Bengio et~al.(1992)Bengio, Bengio, Cloutier, and
  Gecsei]{bengiobengio1}
Bengio, S., Bengio, Y., Cloutier, J., and Gecsei, J.
\newblock On the optimization of a synaptic learning rule.
\newblock In \emph{Optimality in Artificial and Biological Neural Networks},
  1992.

\bibitem[Besbes et~al.(2015)Besbes, Gur, and Zeevi]{Besbes2015NonstationarySO}
Besbes, O., Gur, Y., and Zeevi, A.~J.
\newblock Non-stationary stochastic optimization.
\newblock \emph{Operations Research}, 63:\penalty0 1227--1244, 2015.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{BoydBook}
Boyd, S. and Vandenberghe, L.
\newblock \emph{Convex Optimization}.
\newblock Cambridge University Press, 2004.

\bibitem[Cesa-Bianchi \& Lugosi(2006)Cesa-Bianchi and
  Lugosi]{CesaBianchi2006PLA}
Cesa-Bianchi, N. and Lugosi, G.
\newblock Prediction, learning, and games.
\newblock 2006.

\bibitem[Denevi et~al.(2019)Denevi, Ciliberto, Grazzi, and
  Pontil]{Denevi2019LearningtoLearnSG}
Denevi, G., Ciliberto, C., Grazzi, R., and Pontil, M.
\newblock Learning-to-learn stochastic gradient descent with biased
  regularization.
\newblock \emph{CoRR}, abs/1903.10399, 2019.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{rl2}
Duan, Y., Schulman, J., Chen, X., Bartlett, P.~L., Sutskever, I., and Abbeel,
  P.
\newblock Rl2: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv:1611.02779}, 2016.

\bibitem[Duchi et~al.(2011)Duchi, Hazan, and Singer]{duchi2011adaptive}
Duchi, J., Hazan, E., and Singer, Y.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 2011.

\bibitem[Elfwing et~al.(2017)Elfwing, Uchibe, and Doya]{elfwing2017online}
Elfwing, S., Uchibe, E., and Doya, K.
\newblock Online meta-learning by parallel algorithm competition.
\newblock \emph{arXiv:1702.07490}, 2017.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{maml}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Mirza, Xiao, Courville, and
  Bengio]{goodfellow2013empirical}
Goodfellow, I.~J., Mirza, M., Xiao, D., Courville, A., and Bengio, Y.
\newblock An empirical investigation of catastrophic forgetting in
  gradient-based neural networks.
\newblock \emph{arXiv:1312.6211}, 2013.

\bibitem[Grant et~al.(2018)Grant, Finn, Levine, Darrell, and Griffiths]{erin}
Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T.
\newblock Recasting gradient-based meta-learning as hierarchical bayes.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2018.

\bibitem[Grant et~al.(2019)Grant, Jerfel, Heller, and
  Griffiths]{erin_openreview}
Grant, E., Jerfel, G., Heller, K., and Griffiths, T.~L.
\newblock Modulating transfer between tasks in gradient-based meta-learning,
  2019.

\bibitem[Ha et~al.(2017)Ha, Dai, and Le]{hypernets}
Ha, D., Dai, A., and Le, Q.~V.
\newblock Hypernetworks.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2017.

\bibitem[Hall \& Willett(2015)Hall and Willett]{Hall2015OnlineCO}
Hall, E.~C. and Willett, R.~M.
\newblock Online convex optimization in dynamic environments.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  9:\penalty0 647--662, 2015.

\bibitem[Hannan(1957)]{Hannan}
Hannan, J.
\newblock Approximation to bayes risk in repeated play.
\newblock \emph{Contributions to the Theory of Games}, 1957.

\bibitem[Hazan(2016)]{HazanOCOBook}
Hazan, E.
\newblock Introduction to online convex optimization.
\newblock 2016.

\bibitem[Hazan \& Comandur(2009)Hazan and Comandur]{Hazan2009EfficientLA}
Hazan, E. and Comandur, S.
\newblock Efficient learning algorithms for changing environments.
\newblock In \emph{ICML}, 2009.

\bibitem[Hazan et~al.(2006)Hazan, Kalai, Kale, and
  Agarwal]{Hazan2006LogarithmicRA}
Hazan, E., Kalai, A.~T., Kale, S., and Agarwal, A.
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock \emph{Machine Learning}, 69:\penalty0 169--192, 2006.

\bibitem[Herbster \& Warmuth(1995)Herbster and Warmuth]{Herbster1995TrackingTB}
Herbster, M. and Warmuth, M.~K.
\newblock Tracking the best expert.
\newblock \emph{Machine Learning}, 32:\penalty0 151--178, 1995.

\bibitem[Hochreiter et~al.(2001)Hochreiter, Younger, and Conwell]{hochreiter}
Hochreiter, S., Younger, A.~S., and Conwell, P.~R.
\newblock Learning to learn using gradient descent.
\newblock In \emph{International Conference on Artificial Neural Networks},
  2001.

\bibitem[Isele \& Cosgun(2018)Isele and Cosgun]{isele2018selective}
Isele, D. and Cosgun, A.
\newblock Selective experience replay for lifelong learning.
\newblock \emph{arXiv preprint arXiv:1802.10269}, 2018.

\bibitem[Jin et~al.(2017)Jin, Ge, Netrapalli, Kakade, and Jordan]{Jin2017HowTE}
Jin, C., Ge, R., Netrapalli, P., Kakade, S.~M., and Jordan, M.~I.
\newblock How to escape saddle points efficiently.
\newblock In \emph{ICML}, 2017.

\bibitem[Kalai \& Vempala(2005)Kalai and Vempala]{Kalai2005EfficientAF}
Kalai, A.~T. and Vempala, S.
\newblock Efficient algorithms for online decision problems.
\newblock \emph{J. Comput. Syst. Sci.}, 71:\penalty0 291--307, 2005.

\bibitem[Khodak et~al.(2019)Khodak, Balcan, and
  Talwalkar]{Khodak2019ProvableGF}
Khodak, M., Balcan, M.-F., and Talwalkar, A.~S.
\newblock Provable guarantees for gradient-based meta-learning.
\newblock \emph{CoRR}, abs/1902.10644, 2019.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{adam}
Kingma, D. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2015.

\bibitem[Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska,
  et~al.]{kirkpatrick2017overcoming}
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu,
  A.~A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{Proceedings of the National Academy of Sciences}, 2017.

\bibitem[Lee et~al.(2017)Lee, Yun, Hwang, and Yang]{lee2017lifelong}
Lee, J., Yun, J., Hwang, S., and Yang, E.
\newblock Lifelong learning with dynamically expandable networks.
\newblock \emph{arXiv:1708.01547}, 2017.

\bibitem[Levine et~al.(2016)Levine, Finn, Darrell, and Abbeel]{e2e}
Levine, S., Finn, C., Darrell, T., and Abbeel, P.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{The Journal of Machine Learning Research}, 2016.

\bibitem[Li \& Malik(2017)Li and Malik]{learntooptimize}
Li, K. and Malik, J.
\newblock Learning to optimize.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2017.

\bibitem[Lopez-Paz et~al.(2017)]{gradient_episodic}
Lopez-Paz, D. et~al.
\newblock Gradient episodic memory for continual learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Lowrey et~al.(2019)Lowrey, Rajeswaran, Kakade, Todorov, and
  Mordatch]{Lowrey-ICLR-19}
Lowrey, K., Rajeswaran, A., Kakade, S., Todorov, E., and Mordatch, I.
\newblock {Plan Online, Learn Offline: Efficient Learning and Exploration via
  Model-Based Control}.
\newblock In \emph{{ICLR}}, 2019.

\bibitem[Mallya \& Lazebnik(2017)Mallya and Lazebnik]{mallya2017packnet}
Mallya, A. and Lazebnik, S.
\newblock Packnet: Adding multiple tasks to a single network by iterative
  pruning.
\newblock \emph{arXiv:1711.05769}, 2017.

\bibitem[Meier et~al.(2017)Meier, Kappler, and Schaal]{meier2017online}
Meier, F., Kappler, D., and Schaal, S.
\newblock Online learning of a memory for learning rates.
\newblock \emph{arXiv:1709.06709}, 2017.

\bibitem[Mishra et~al.(2017)Mishra, Rohaninejad, Chen, and
  Abbeel]{mishra2017meta}
Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P.
\newblock Meta-learning with temporal convolutions.
\newblock \emph{arXiv preprint arXiv:1707.03141}, 2017.

\bibitem[Munkhdalai \& Yu(2017)Munkhdalai and Yu]{metanetworks}
Munkhdalai, T. and Yu, H.
\newblock Meta networks.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Nagabandi et~al.(2018)Nagabandi, Finn, and Levine]{nagabandi2018deep}
Nagabandi, A., Finn, C., and Levine, S.
\newblock Deep online learning via meta-learning: Continual adaptation for
  model-based rl.
\newblock \emph{arXiv preprint arXiv:1812.07671}, 2018.

\bibitem[Naik \& Mammone(1992)Naik and Mammone]{naik}
Naik, D.~K. and Mammone, R.
\newblock Meta-neural networks that learn by learning.
\newblock In \emph{International Joint Conference on Neural Netowrks (IJCNN)},
  1992.

\bibitem[Nesterov \& Polyak(2006)Nesterov and Polyak]{Nesterov2006CubicRO}
Nesterov, Y. and Polyak, B.~T.
\newblock Cubic regularization of newton method and its global performance.
\newblock \emph{Math. Program.}, 108:\penalty0 177--205, 2006.

\bibitem[Nguyen et~al.(2017)Nguyen, Li, Bui, and Turner]{nguyen2017variational}
Nguyen, C.~V., Li, Y., Bui, T.~D., and Turner, R.~E.
\newblock Variational continual learning.
\newblock \emph{arXiv:1710.10628}, 2017.

\bibitem[Parisotto et~al.(2016)Parisotto, Ba, and Salakhutdinov]{actormimic}
Parisotto, E., Ba, J.~L., and Salakhutdinov, R.
\newblock Actor-mimic: Deep multitask and transfer reinforcement learning.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2016.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{hugo}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Rebuffi et~al.(2017)Rebuffi, Kolesnikov, and
  Lampert]{rebuffi2017icarl}
Rebuffi, S.-A., Kolesnikov, A., and Lampert, C.~H.
\newblock icarl: Incremental classifier and representation learning.
\newblock In \emph{Proc. CVPR}, 2017.

\bibitem[Rusu et~al.(2016)Rusu, Rabinowitz, Desjardins, Soyer, Kirkpatrick,
  Kavukcuoglu, Pascanu, and Hadsell]{rusu2016progressive}
Rusu, A.~A., Rabinowitz, N.~C., Desjardins, G., Soyer, H., Kirkpatrick, J.,
  Kavukcuoglu, K., Pascanu, R., and Hadsell, R.
\newblock Progressive neural networks.
\newblock \emph{arXiv:1606.04671}, 2016.

\bibitem[Ruvolo \& Eaton(2013)Ruvolo and Eaton]{ruvolo2013ella}
Ruvolo, P. and Eaton, E.
\newblock Ella: An efficient lifelong learning algorithm.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  507--515, 2013.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lillicrap]{mann}
Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., and Lillicrap, T.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Schmidhuber(1987)]{schmidhuber1987}
Schmidhuber, J.
\newblock Evolutionary principles in self-referential learning.
\newblock \emph{Diploma thesis, Institut f. Informatik, Tech. Univ. Munich},
  1987.

\bibitem[Schmidhuber(2002)]{Schmidhuber2002OptimalOP}
Schmidhuber, J.
\newblock Optimal ordered problem solver.
\newblock \emph{Machine Learning}, 54:\penalty0 211--254, 2002.

\bibitem[Schmidhuber(2013)]{Schmidhuber2013PowerPlayTA}
Schmidhuber, J.
\newblock Powerplay: Training an increasingly general problem solver by
  continually searching for the simplest still unsolvable problem.
\newblock In \emph{Front. Psychol.}, 2013.

\bibitem[Shaban et~al.(2018)Shaban, Cheng, Hirschey, and
  Boots]{Shaban2018TruncatedBF}
Shaban, A., Cheng, C.-A., Hirschey, O., and Boots, B.
\newblock Truncated back-propagation for bilevel optimization.
\newblock \emph{CoRR}, abs/1810.10667, 2018.

\bibitem[Shalev-Shwartz(2012)]{ShaiBook}
Shalev-Shwartz, S.
\newblock Online learning and online convex optimization.
\newblock \emph{"Foundations and Trends in Machine Learning"}, 2012.

\bibitem[Shalev-Shwartz \& Kakade(2008)Shalev-Shwartz and
  Kakade]{ShalevShwartz2008MindTD}
Shalev-Shwartz, S. and Kakade, S.~M.
\newblock Mind the duality gap: Logarithmic regret algorithms for online
  optimization.
\newblock In \emph{NIPS}, 2008.

\bibitem[Shin et~al.(2017)Shin, Lee, Kim, and Kim]{shin2017continual}
Shin, H., Lee, J.~K., Kim, J., and Kim, J.
\newblock Continual learning with deep generative replay.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Shmelkov et~al.(2017)Shmelkov, Schmid, and
  Alahari]{shmelkov2017incremental}
Shmelkov, K., Schmid, C., and Alahari, K.
\newblock Incremental learning of object detectors without catastrophic
  forgetting.
\newblock \emph{arXiv:1708.06977}, 2017.

\bibitem[Singh et~al.(2017)Singh, Yang, and Levine]{singh2017gplac}
Singh, A., Yang, L., and Levine, S.
\newblock Gplac: Generalizing vision-based robotic skills using weakly labeled
  images.
\newblock \emph{arXiv:1708.02313}, 2017.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem[Thrun(1998)]{thrun1998lifelong}
Thrun, S.
\newblock Lifelong learning algorithms.
\newblock In \emph{Learning to learn}. Springer, 1998.

\bibitem[Thrun \& Pratt(1998)Thrun and Pratt]{thrun}
Thrun, S. and Pratt, L.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  (IROS)}, 2012.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{matchingnets}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2016.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{learningrl}
Wang, J.~X., Kurth-Nelson, Z., Tirumala, D., Soyer, H., Leibo, J.~Z., Munos,
  R., Blundell, C., Kumaran, D., and Botvinick, M.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv:1611.05763}, 2016.

\bibitem[Wang et~al.(2017)Wang, Ramanan, and Hebert]{wang2017growing}
Wang, Y.-X., Ramanan, D., and Hebert, M.
\newblock Growing a brain: Fine-tuning by increasing model capacity.
\newblock In \emph{IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2017.

\bibitem[Xiang et~al.(2014)Xiang, Mottaghi, and Savarese]{xiang2014beyond}
Xiang, Y., Mottaghi, R., and Savarese, S.
\newblock Beyond pascal: A benchmark for 3d object detection in the wild.
\newblock In \emph{Conference on Applications of Computer Vision (WACV)}, 2014.

\bibitem[Yang et~al.(2016)Yang, Zhang, Jin, and Yi]{Yang2016TrackingSM}
Yang, T., Zhang, L., Jin, R., and Yi, J.
\newblock Tracking slowly moving clairvoyant: Optimal dynamic regret of online
  learning with true and noisy gradient.
\newblock In \emph{ICML}, 2016.

\bibitem[Zenke et~al.(2017)Zenke, Poole, and Ganguli]{zenke2017continual}
Zenke, F., Poole, B., and Ganguli, S.
\newblock Continual learning through synaptic intelligence.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Zhao \& Schmidhuber(1996)Zhao and Schmidhuber]{zhao1996incremental}
Zhao, J. and Schmidhuber, J.
\newblock Incremental self-improvement for life-time multi-agent reinforcement
  learning.
\newblock In \emph{From Animals to Animats 4: International Conference on
  Simulation of Adaptive Behavior}, 1996.

\bibitem[Zinkevich(2003)]{Zinkevich2003OnlineCP}
Zinkevich, M.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{ICML}, 2003.

\end{thebibliography}
