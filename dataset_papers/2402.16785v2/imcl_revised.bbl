\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abutbul et~al.(2020)Abutbul, Elidan, Katzir, and {El-Yaniv}]{abutbulDNFNetNeuralArchitecture2020a}
Abutbul, A., Elidan, G., Katzir, L., and {El-Yaniv}, R.
\newblock {{DNF-Net}}: {{A Neural Architecture}} for {{Tabular Data}}, June 2020.

\bibitem[Arik \& Pfister(2020)Arik and Pfister]{arikTabNetAttentiveInterpretable2020}
Arik, S.~O. and Pfister, T.
\newblock {{TabNet}}: {{Attentive Interpretable Tabular Learning}}, December 2020.

\bibitem[Balazevic et~al.(2019)Balazevic, Allen, and Hospedales]{balazevic2019multi}
Balazevic, I., Allen, C., and Hospedales, T.
\newblock Multi-relational poincar{\'e} graph embeddings.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Bommasani et~al.(2021)Bommasani, Hudson, Adeli, Altman, Arora, von Arx, Bernstein, Bohg, Bosselut, Brunskill, et~al.]{bommasani2021opportunities}
Bommasani, R., Hudson, D.~A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M.~S., Bohg, J., Bosselut, A., Brunskill, E., et~al.
\newblock On the opportunities and risks of foundation models.
\newblock \emph{arXiv preprint arXiv:2108.07258}, 2021.

\bibitem[Breiman(1996)]{breiman1996bagging}
Breiman, L.
\newblock Bagging predictors.
\newblock \emph{Machine learning}, 24:\penalty0 123--140, 1996.

\bibitem[Cerda \& Varoquaux(2022)Cerda and Varoquaux]{cerdaEncodingHighcardinalityString2022}
Cerda, P. and Varoquaux, G.
\newblock Encoding high-cardinality string categorical variables.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 34\penalty0 (3):\penalty0 1164--1176, March 2022.
\newblock ISSN 1041-4347, 1558-2191, 2326-3865.
\newblock \doi{10.1109/TKDE.2020.2992529}.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Lin, Li, Li, Zhou, and Sun]{chen2020measuring}
Chen, D., Lin, Y., Li, W., Li, P., Zhou, J., and Sun, X.
\newblock Measuring and relieving the over-smoothing problem for graph neural networks from the topological view.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~34, pp.\  3438--3445, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2023)Chen, Yan, Chen, and Wu]{chenExcelFormerNeuralNetwork2023}
Chen, J., Yan, J., Chen, D.~Z., and Wu, J.
\newblock {{ExcelFormer}}: {{A Neural Network Surpassing GBDTs}} on {{Tabular Data}}, January 2023.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{chen2016xgboost}
Chen, T. and Guestrin, C.
\newblock Xgboost: A scalable tree boosting system.
\newblock In \emph{Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining}, pp.\  785--794, 2016.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International conference on machine learning}, pp.\  1597--1607. PMLR, 2020{\natexlab{b}}.

\bibitem[Conover(1999)]{conover1999practical}
Conover, W.~J.
\newblock \emph{Practical nonparametric statistics}, volume 350.
\newblock john wiley \& sons, 1999.

\bibitem[Crossley et~al.(2023)Crossley, Heintz, Choi, Batchelor, Karimi, and Malatinszky]{crossleyLarge2023}
Crossley, S., Heintz, A., Choi, J.~S., Batchelor, J., Karimi, M., and Malatinszky, A.
\newblock A large-scaled corpus for assessing text readability.
\newblock \emph{Behavior Research Methods}, 55\penalty0 (2):\penalty0 491--507, 2023.

\bibitem[Cvetkov-Iliev et~al.(2023)Cvetkov-Iliev, Allauzen, and Varoquaux]{cvetkov2023relational}
Cvetkov-Iliev, A., Allauzen, A., and Varoquaux, G.
\newblock Relational data embeddings for feature enrichment with background information.
\newblock \emph{Machine Learning}, 112\penalty0 (2):\penalty0 687--720, 2023.

\bibitem[Deng et~al.(2020)Deng, Sun, Lees, Wu, and Yu]{dengTURLTableUnderstanding2020}
Deng, X., Sun, H., Lees, A., Wu, Y., and Yu, C.
\newblock {{TURL}}: {{Table Understanding}} through {{Representation Learning}}, December 2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlinBERTPretrainingDeep2019}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}, May 2019.

\bibitem[Doan et~al.(2012)Doan, Halevy, and Ives]{doan2012principles}
Doan, A., Halevy, A., and Ives, Z.
\newblock \emph{Principles of data integration}.
\newblock Elsevier, 2012.

\bibitem[Dorogush et~al.(2018)Dorogush, Ershov, and Gulin]{dorogushCatboost2018}
Dorogush, A.~V., Ershov, V., and Gulin, A.
\newblock {{CatBoost}}: Gradient boosting with categorical features support.
\newblock \emph{arXiv preprint arXiv:1810.11363}, 2018.

\bibitem[Eggert et~al.(2023)Eggert, Huo, Biven, and Waugh]{eggertTabLibDataset627M2023}
Eggert, G., Huo, K., Biven, M., and Waugh, J.
\newblock {{TabLib}}: {{A Dataset}} of {{627M Tables}} with {{Context}}, October 2023.

\bibitem[Fey et~al.(2023)Fey, Hu, Huang, Lenssen, Ranjan, Robinson, Ying, You, and Leskovec]{fey2023relational}
Fey, M., Hu, W., Huang, K., Lenssen, J.~E., Ranjan, R., Robinson, J., Ying, R., You, J., and Leskovec, J.
\newblock Relational deep learning: Graph representation learning on relational databases.
\newblock \emph{arXiv preprint arXiv:2312.04615}, 2023.

\bibitem[Gardner et~al.(2022)Gardner, Popovic, and Schmidt]{gardnerSubgroupRobustnessGrows2022}
Gardner, J., Popovic, Z., and Schmidt, L.
\newblock Subgroup {{Robustness Grows On Trees}}: {{An Empirical Baseline Investigation}}.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 9939--9954, December 2022.

\bibitem[Gorishniy et~al.(2022)Gorishniy, Rubachev, and Babenko]{gorishniy2022embeddings}
Gorishniy, Y., Rubachev, I., and Babenko, A.
\newblock On embeddings for numerical features in tabular deep learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 24991--25004, 2022.

\bibitem[Gorishniy et~al.(2023{\natexlab{a}})Gorishniy, Rubachev, Kartashev, Shlenskii, Kotelnikov, and Babenko]{gorishniyTabRTabularDeep2023}
Gorishniy, Y., Rubachev, I., Kartashev, N., Shlenskii, D., Kotelnikov, A., and Babenko, A.
\newblock {{TabR}}: {{Tabular Deep Learning Meets Nearest Neighbors}} in 2023, October 2023{\natexlab{a}}.

\bibitem[Gorishniy et~al.(2023{\natexlab{b}})Gorishniy, Rubachev, Khrulkov, and Babenko]{gorishniyRevisitingDeepLearning2023}
Gorishniy, Y., Rubachev, I., Khrulkov, V., and Babenko, A.
\newblock Revisiting {{Deep Learning Models}} for {{Tabular Data}}, October 2023{\natexlab{b}}.

\bibitem[Grinsztajn et~al.(2022)Grinsztajn, Oyallon, and Varoquaux]{grinsztajnWhyTreebasedModels2022}
Grinsztajn, L., Oyallon, E., and Varoquaux, G.
\newblock Why do tree-based models still outperform deep learning on tabular data?, July 2022.

\bibitem[Hegselmann et~al.(2023)Hegselmann, Buendia, Lang, Agrawal, Jiang, and Sontag]{hegselmannTabLLMFewshotClassification2023}
Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., and Sontag, D.
\newblock {{TabLLM}}: {{Few-shot Classification}} of {{Tabular Data}} with {{Large Language Models}}, March 2023.

\bibitem[Hollmann et~al.(2023)Hollmann, M{\"u}ller, Eggensperger, and Hutter]{hollmannTabPFNTransformerThat2023}
Hollmann, N., M{\"u}ller, S., Eggensperger, K., and Hutter, F.
\newblock {{TabPFN}}: {{A Transformer That Solves Small Tabular Classification Problems}} in a {{Second}}, September 2023.

\bibitem[Hulsebos et~al.(2019)Hulsebos, Hu, Bakker, Zgraggen, Satyanarayan, Kraska, Demiralp, and Hidalgo]{hulsebos2019sherlock}
Hulsebos, M., Hu, K., Bakker, M., Zgraggen, E., Satyanarayan, A., Kraska, T., Demiralp, {\c{C}}., and Hidalgo, C.
\newblock Sherlock: A deep learning approach to semantic data type detection.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining}, pp.\  1500--1508, 2019.

\bibitem[Hulsebos et~al.(2023)Hulsebos, Demiralp, and Groth]{hulsebosGitTablesLargeScaleCorpus2023}
Hulsebos, M., Demiralp, {\c C}., and Groth, P.
\newblock {{GitTables}}: {{A Large-Scale Corpus}} of {{Relational Tables}}.
\newblock \emph{Proceedings of the ACM on Management of Data}, 1\penalty0 (1):\penalty0 1--17, May 2023.
\newblock ISSN 2836-6573.
\newblock \doi{10.1145/3588710}.

\bibitem[Levin et~al.(2023)Levin, Cherepanova, Schwarzschild, Bansal, Bruss, Goldstein, Wilson, and Goldblum]{levinTransferLearningDeep2023}
Levin, R., Cherepanova, V., Schwarzschild, A., Bansal, A., Bruss, C.~B., Goldstein, T., Wilson, A.~G., and Goldblum, M.
\newblock Transfer {{Learning}} with {{Deep Tabular Models}}, August 2023.

\bibitem[Mahdisoltani et~al.(2013)Mahdisoltani, Biega, and Suchanek]{mahdisoltani2013yago3}
Mahdisoltani, F., Biega, J., and Suchanek, F.~M.
\newblock Yago3: A knowledge base from multilingual wikipedias.
\newblock In \emph{CIDR}, 2013.

\bibitem[McElfresh et~al.(2023)McElfresh, Khandagale, Valverde, C, Feuer, Hegde, Ramakrishnan, Goldblum, and White]{mcelfreshWhenNeuralNets2023}
McElfresh, D., Khandagale, S., Valverde, J., C, V.~P., Feuer, B., Hegde, C., Ramakrishnan, G., Goldblum, M., and White, C.
\newblock When {{Do Neural Nets Outperform Boosted Trees}} on {{Tabular Data}}?, October 2023.

\bibitem[Micci-Barreca(2001)]{micci2001preprocessing}
Micci-Barreca, D.
\newblock A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems.
\newblock \emph{ACM SIGKDD Explorations Newsletter}, 3\penalty0 (1):\penalty0 27--32, 2001.

\bibitem[Mikolov et~al.(2017)Mikolov, Grave, Bojanowski, Puhrsch, and Joulin]{mikolov2017advances}
Mikolov, T., Grave, E., Bojanowski, P., Puhrsch, C., and Joulin, A.
\newblock Advances in pre-training distributed word representations.
\newblock \emph{arXiv preprint arXiv:1712.09405}, 2017.

\bibitem[Narayan et~al.(2022)Narayan, Chami, Orr, and R{\'e}]{narayan2022can}
Narayan, A., Chami, I., Orr, L., and R{\'e}, C.
\newblock Can foundation models wrangle your data?
\newblock \emph{Proceedings of the VLDB Endowment}, 16\penalty0 (4):\penalty0 738--746, 2022.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{pedregosa2011scikit}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{the Journal of machine Learning research}, 12:\penalty0 2825--2830, 2011.

\bibitem[Popov et~al.(2019)Popov, Morozov, and Babenko]{popovNeuralObliviousDecision2019}
Popov, S., Morozov, S., and Babenko, A.
\newblock Neural {{Oblivious Decision Ensembles}} for {{Deep Learning}} on {{Tabular Data}}, September 2019.

\bibitem[Rusch et~al.(2023)Rusch, Bronstein, and Mishra]{rusch2023survey}
Rusch, T.~K., Bronstein, M.~M., and Mishra, S.
\newblock A survey on oversmoothing in graph neural networks.
\newblock \emph{arXiv preprint arXiv:2303.10993}, 2023.

\bibitem[Sanjib et~al.(2023)Sanjib, AnHai, Suganthan, Chaitanya, Pradap, Yash, and Derek]{magellandata}
Sanjib, D., AnHai, D., Suganthan, P., Chaitanya, G., Pradap, K., Yash, G., and Derek, P.
\newblock The {{Magellan Data Repository}}, 2023.

\bibitem[{Shwartz-Ziv} \& Armon(2021){Shwartz-Ziv} and Armon]{shwartz-zivTabularDataDeep2021b}
{Shwartz-Ziv}, R. and Armon, A.
\newblock Tabular {{Data}}: {{Deep Learning}} is {{Not All You Need}}, November 2021.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{simonyan2015very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations (ICLR 2015)}, 2015.

\bibitem[Skrub(2024)]{skrub2024}
Skrub.
\newblock Skrub, prepping tables for machine learning.
\newblock \url{https://skrub-data.org}, 2024.

\bibitem[Somepalli et~al.(2021)Somepalli, Goldblum, Schwarzschild, Bruss, and Goldstein]{somepalliSAINTImprovedNeural2021a}
Somepalli, G., Goldblum, M., Schwarzschild, A., Bruss, C.~B., and Goldstein, T.
\newblock {{SAINT}}: {{Improved Neural Networks}} for {{Tabular Data}} via {{Row Attention}} and {{Contrastive Pre-Training}}, June 2021.

\bibitem[Terpilowski(2019)]{Terpilowski2019}
Terpilowski, M.
\newblock scikit-posthocs: Pairwise multiple comparison tests in python.
\newblock \emph{The Journal of Open Source Software}, 4\penalty0 (36):\penalty0 1169, 2019.
\newblock \doi{10.21105/joss.01169}.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[{UCI}()]{uci}
{UCI}.
\newblock {UC Irvine Machine Learning Repository}.
\newblock \url{https://archive.ics.uci.edu}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Velickovic et~al.(2017)Velickovic, Cucurull, Casanova, Romero, Lio, Bengio, et~al.]{velickovic2017graph}
Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., et~al.
\newblock Graph attention networks.
\newblock \emph{stat}, 1050\penalty0 (20):\penalty0 10--48550, 2017.

\bibitem[Wang et~al.(2022)Wang, Yang, Huang, Jiao, Yang, Jiang, Majumder, and Wei]{wang2022text}
Wang, L., Yang, N., Huang, X., Jiao, B., Yang, L., Jiang, D., Majumder, R., and Wei, F.
\newblock Text embeddings by weakly-supervised contrastive pre-training.
\newblock \emph{arXiv preprint arXiv:2212.03533}, 2022.

\bibitem[Wang \& Sun(2022)Wang and Sun]{wang2022transtab}
Wang, Z. and Sun, J.
\newblock Transtab: Learning transferable tabular transformers across tables.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 2902--2915, 2022.

\bibitem[Yeo \& Johnson(2000)Yeo and Johnson]{yeo2000new}
Yeo, I.-K. and Johnson, R.~A.
\newblock A new family of power transformations to improve normality or symmetry.
\newblock \emph{Biometrika}, 87\penalty0 (4):\penalty0 954--959, 2000.

\bibitem[Zhu et~al.(2023)Zhu, Shi, Erickson, Li, Karypis, and Shoaran]{zhu2023xtab}
Zhu, B., Shi, X., Erickson, N., Li, M., Karypis, G., and Shoaran, M.
\newblock Xtab: Cross-table pretraining for tabular transformers.
\newblock \emph{arXiv preprint arXiv:2305.06090}, 2023.

\end{thebibliography}
