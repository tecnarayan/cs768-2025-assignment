\begin{thebibliography}{15}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen-Zhu and Li(2020)]{allen2020feature}
Zeyuan Allen-Zhu and Yuanzhi Li.
\newblock Feature purification: How adversarial training performs robust deep
  learning.
\newblock \emph{arXiv preprint arXiv:2005.10190}, 2020.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Ben~Arous et~al.(2020)Ben~Arous, Subag, and
  Zeitouni]{arous2020geometry}
G{\'e}rard Ben~Arous, Eliran Subag, and Ofer Zeitouni.
\newblock Geometry and temperature chaos in mixed spherical spin glasses at low
  temperature: the perturbative regime.
\newblock \emph{Communications on Pure and Applied Mathematics}, 73\penalty0
  (8):\penalty0 1732--1828, 2020.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and Massart]{BLM}
St{\'e}phane Boucheron, G{\'a}bor Lugosi, and Pascal Massart.
\newblock \emph{Concentration inequalities: A nonasymptotic theory of
  independence}.
\newblock Oxford university press, 2013.

\bibitem[Daniely and Schacham(2020)]{DanielySchacham}
Amit Daniely and Hadas Schacham.
\newblock Most relu networks suffer from $\ell^2$ adversarial perturbations.
\newblock \emph{arXiv preprint arXiv:2010.14927}, 2020.

\bibitem[Eldan et~al.(2021)Eldan, Mikulincer, and Schramm]{EMS21}
Ronen Eldan, Dan Mikulincer, and Tselil Schramm.
\newblock Non-asymptotic approximations of neural networks by gaussian
  processes.
\newblock \emph{arXiv preprint arXiv:2102.08668}, 2021.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{Goodfellow15}
Ian Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{Madry18}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Moosavi-Dezfooli et~al.(2017)Moosavi-Dezfooli, Fawzi, Fawzi, and
  Frossard]{moosavi2017universal}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
  Frossard.
\newblock Universal adversarial perturbations.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1765--1773, 2017.

\bibitem[{Moosavi-Dezfooli} et~al.(2019){Moosavi-Dezfooli}, {Fawzi}, {Uesato},
  and {Frossard}]{8953595}
Seyed-Mohsen {Moosavi-Dezfooli}, Alhussein {Fawzi}, Jonathan {Uesato}, and
  Pascal {Frossard}.
\newblock Robustness via curvature regularization, and vice versa.
\newblock In \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2019.

\bibitem[Papernot et~al.(2017)Papernot, McDaniel, Goodfellow, Jha, Celik, and
  Swami]{papernot2017practical}
Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z~Berkay Celik,
  and Ananthram Swami.
\newblock Practical black-box attacks against machine learning.
\newblock In \emph{Proceedings of the 2017 ACM on Asia conference on computer
  and communications security}, 2017.

\bibitem[Qin et~al.(2019)Qin, Martens, Gowal, Krishnan, Dvijotham, Fawzi, De,
  Stanforth, and Kohli]{NEURIPS2019_0defd533}
Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy
  Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, and Pushmeet Kohli.
\newblock Adversarial robustness through local linearization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Shamir et~al.(2019)Shamir, Safran, Ronen, and Dunkelman]{ShamirFather}
Adi Shamir, Itay Safran, Eyal Ronen, and Orr Dunkelman.
\newblock A simple explanation for the existence of adversarial examples with
  small hamming distance.
\newblock \emph{arXiv preprint arXiv:1901.10861}, 2019.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{G14}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Wainwright(2019)]{Wainwright}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\end{thebibliography}
