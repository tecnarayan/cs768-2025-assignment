\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Awasthi et~al.(2015)Awasthi, Balcan, Haghtalab, and
  Urner]{awasthi2015efficient}
Awasthi, P., Balcan, M.-F., Haghtalab, N., and Urner, R.
\newblock Efficient learning of linear separators under bounded noise.
\newblock In \emph{Proceedings of COLT}, pp.\  167--190, 2015.

\bibitem[Balcan \& Long(2013)Balcan and Long]{balcan2013active}
Balcan, M.-F. and Long, P.
\newblock Active and passive learning of linear separators under log-concave
  distributions.
\newblock In \emph{Proceedings of COLT}, pp.\  288--316, 2013.

\bibitem[Balcan et~al.(2006)Balcan, Beygelzimer, and
  Langford]{Balcan2006AgnosticAL}
Balcan, M.-F., Beygelzimer, A., and Langford, J.
\newblock Agnostic active learning.
\newblock In \emph{Proceedings of ICML}, 2006.

\bibitem[Balcan et~al.(2007)Balcan, Broder, and Zhang]{balcan2007margin}
Balcan, M.-F., Broder, A., and Zhang, T.
\newblock Margin based active learning.
\newblock In \emph{International Conference on Computational Learning Theory},
  pp.\  35--50. Springer, 2007.

\bibitem[Beygelzimer et~al.(2009)Beygelzimer, Dasgupta, and
  Langford]{beygelzimer2009importance}
Beygelzimer, A., Dasgupta, S., and Langford, J.
\newblock Importance weighted active learning.
\newblock In \emph{Proceedings of ICML}, pp.\  49--56. ACM, 2009.

\bibitem[Beygelzimer et~al.(2010)Beygelzimer, Hsu, Langford, and
  Zhang]{beygelzimer2010agnostic}
Beygelzimer, A., Hsu, D.~J., Langford, J., and Zhang, T.
\newblock Agnostic active learning without constraints.
\newblock In \emph{Proceedings of NIPS}, pp.\  199--207, 2010.

\bibitem[Castro \& Nowak(2008)Castro and Nowak]{castro2008minimax}
Castro, R.~M. and Nowak, R.~D.
\newblock Minimax bounds for active learning.
\newblock \emph{IEEE Transactions on Information Theory}, 54\penalty0
  (5):\penalty0 2339--2353, 2008.

\bibitem[Chuang et~al.(2019)Chuang, DeSalvo, Karydas, Kagy, Rostamizadeh, and
  Theeraphol]{cd19}
Chuang, G., DeSalvo, G., Karydas, L., Kagy, J., Rostamizadeh, A., and
  Theeraphol, A.
\newblock Active learning empirical study.
\newblock In \emph{NeurIPS2019 LIRE Workshop}, 2019.

\bibitem[Cohn et~al.(1994)Cohn, Atlas, and Ladner]{cohn1994improving}
Cohn, D., Atlas, L., and Ladner, R.
\newblock Improving generalization with active learning.
\newblock \emph{Machine learning}, 15\penalty0 (2):\penalty0 201--221, 1994.

\bibitem[Cortes et~al.(2019{\natexlab{a}})Cortes, DeSalvo, Gentile, Mohri, and
  Zhang]{cortes2019disgraph}
Cortes, C., DeSalvo, G., Gentile, C., Mohri, M., and Zhang, N.
\newblock Active learning with disagreement graphs.
\newblock In \emph{{Proceedings of ICML}}, 2019{\natexlab{a}}.

\bibitem[Cortes et~al.(2019{\natexlab{b}})Cortes, DeSalvo, Gentile, Mohri, and
  Zhang]{cortes2019rbal}
Cortes, C., DeSalvo, G., Gentile, C., Mohri, M., and Zhang, N.
\newblock Region-based active learning.
\newblock In \emph{Proceedings of AISTATS 2019}, 2019{\natexlab{b}}.

\bibitem[Crammer et~al.(2009)Crammer, Kulesza, and Dredze]{ckd09}
Crammer, K., Kulesza, A., and Dredze, M.
\newblock Adaptive regularization of weight vectors.
\newblock In \emph{Nips}, 2009.

\bibitem[Dasgupta(2004)]{das04}
Dasgupta, S.
\newblock Analysis of a greedy active learning strategy.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  337--344, 2004.

\bibitem[Dasgupta(2006)]{dasgupta2006coarse}
Dasgupta, S.
\newblock Coarse sample complexity bounds for active learning.
\newblock In \emph{Proceedings of NIPS}, pp.\  235--242, 2006.

\bibitem[Dasgupta(2011)]{Dasgupta2011}
Dasgupta, S.
\newblock Two faces of active learning.
\newblock \emph{Theor. Comput. Sci.}, 412\penalty0 (19):\penalty0 1767--1781,
  2011.

\bibitem[Dasgupta \& Hsu(2008)Dasgupta and Hsu]{dasgupta2008hierarchical}
Dasgupta, S. and Hsu, D.
\newblock Hierarchical sampling for active learning.
\newblock In \emph{Proceedings of ICML}, pp.\  208--215. ACM, 2008.

\bibitem[Dasgupta et~al.(2005)Dasgupta, Kalai, and
  Monteleoni]{dasgupta2005analysis}
Dasgupta, S., Kalai, A.~T., and Monteleoni, C.
\newblock Analysis of perceptron-based active learning.
\newblock In \emph{International Conference on Computational Learning Theory},
  pp.\  249--263. Springer, 2005.

\bibitem[Dasgupta et~al.(2008)Dasgupta, Hsu, and
  Monteleoni]{dasgupta2008general}
Dasgupta, S., Hsu, D.~J., and Monteleoni, C.
\newblock A general agnostic active learning algorithm.
\newblock In \emph{Proceedings of NIPS}, pp.\  353--360, 2008.

\bibitem[Freund et~al.(1997)Freund, Seung, Shamir, and
  Tishby]{freund1997selective}
Freund, Y., Seung, H.~S., Shamir, E., and Tishby, N.
\newblock Selective sampling using the query by committee algorithm.
\newblock \emph{Machine learning}, 28\penalty0 (2-3):\penalty0 133--168, 1997.

\bibitem[Golovin \& Krause(2017)Golovin and Krause]{gk17}
Golovin, D. and Krause, A.
\newblock Adaptive submodularity: A new approach to active learning and
  stochastic optimization.
\newblock In \emph{arXiv:1003.3967}, 2017.

\bibitem[Hanneke(2007)]{hanneke2007bound}
Hanneke, S.
\newblock A bound on the label complexity of agnostic active learning.
\newblock In \emph{Proceedings of ICML}, pp.\  353--360. ACM, 2007.

\bibitem[Hanneke(2014)]{Hanneke2014}
Hanneke, S.
\newblock Theory of disagreement-based active learning.
\newblock \emph{Foundations and Trends in Machine Learning}, 7\penalty0
  (2-3):\penalty0 131--309, 2014.

\bibitem[Hanneke \& Yang(2015)Hanneke and Yang]{hanneke2015minimax}
Hanneke, S. and Yang, L.
\newblock Minimax analysis of active learning.
\newblock \emph{The Journal of Machine Learning Research}, 16\penalty0
  (1):\penalty0 3487--3602, 2015.

\bibitem[Huang et~al.(2015)Huang, Agarwal, Hsu, Langford, and
  E.~Schapire]{huang2015efficient}
Huang, T.-K., Agarwal, A., Hsu, D., Langford, J., and E.~Schapire, R.
\newblock Efficient and parsimonious agnostic active learning.
\newblock In \emph{Proceedings of NIPS}, 2015.

\bibitem[Koltchinskii(2010)]{koltchinskii2010rademacher}
Koltchinskii, V.
\newblock Rademacher complexities and bounding the excess risk in active
  learning.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (Sep):\penalty0 2457--2485, 2010.

\bibitem[Kpotufe et~al.(2015)Kpotufe, Urner, and
  Ben-David]{kpotufe2015hierarchical}
Kpotufe, S., Urner, R., and Ben-David, S.
\newblock Hierarchical label queries with data-dependent partitions.
\newblock In \emph{Proceedings of COLT}, pp.\  1176--1189, 2015.

\bibitem[Mussmann \& Liang(2018)Mussmann and Liang]{ml18}
Mussmann, S. and Liang, P.
\newblock On the relationship between data efficiency and error for uncertainty
  sampling.
\newblock In \emph{PMLR 80: Proceedings of the 35th International Conference on
  Machine Learning}, pp.\  3674--3682, 2018.

\bibitem[Nowak(2011)]{no11}
Nowak, R.
\newblock The geometry of generalized binary search.
\newblock \emph{IEEE Transactions on Information Theory}, 57\penalty0
  (12):\penalty0 7893--7906, 2011.

\bibitem[Tosh \& Dasgupta(2017)Tosh and Dasgupta]{td17}
Tosh, C. and Dasgupta, S.
\newblock Diameter-based active learning.
\newblock In \emph{Thirty-fourth International Conference on Machine Learning
  (ICML)}, 2017.

\bibitem[Urner et~al.(2013)Urner, Wulff, and Ben-David]{urner2013plal}
Urner, R., Wulff, S., and Ben-David, S.
\newblock {PLAL}: Cluster-based active learning.
\newblock In \emph{Proceedings of COLT}, pp.\  376--397, 2013.

\bibitem[Zhang(2018)]{Zhang2018EfficientAL}
Zhang, C.
\newblock Efficient active learning of sparse halfspaces.
\newblock In \emph{Proceedings of COLT}, 2018.

\bibitem[Zhang \& Chaudhuri(2014)Zhang and Chaudhuri]{zhang2014beyond}
Zhang, C. and Chaudhuri, K.
\newblock Beyond disagreement-based agnostic active learning.
\newblock In \emph{Proceedings of NIPS}, pp.\  442--450, 2014.

\end{thebibliography}
