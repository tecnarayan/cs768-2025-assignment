\begin{thebibliography}{76}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Thoppilan et~al.(2022)Thoppilan, De~Freitas, Hall, Shazeer, Kulshreshtha, Cheng, Jin, Bos, Baker, Du, et~al.]{lamda}
Romal Thoppilan, Daniel De~Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu~Du, et~al.
\newblock Lamda: Language models for dialog applications.
\newblock \emph{arXiv preprint arXiv:2201.08239}, 2022.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, et~al.]{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Esser et~al.(2021)Esser, Rombach, and Ommer]{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12873--12883, 2021.

\bibitem[Yu et~al.(2022{\natexlab{a}})Yu, Xu, Koh, Luong, Baid, Wang, Vasudevan, Ku, Yang, Ayan, Hutchinson, Han, Parekh, Li, Zhang, Baldridge, and Wu]{yu2022scaling}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui Wu.
\newblock Scaling autoregressive models for content-rich text-to-image generation.
\newblock \emph{Transactions on Machine Learning Research}, 2022{\natexlab{a}}.

\bibitem[Yu et~al.(2022{\natexlab{b}})Yu, Li, Koh, Zhang, Pang, Qin, Ku, Xu, Baldridge, and Wu]{yu2022vectorquantized}
Jiahui Yu, Xin Li, Jing~Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.
\newblock Vector-quantized image modeling with improved {VQGAN}.
\newblock In \emph{International Conference on Learning Representations}, 2022{\natexlab{b}}.

\bibitem[Ren et~al.(2021)Ren, Hu, Tan, Qin, Zhao, Zhao, and Liu]{fastspeech}
Yi~Ren, Chenxu Hu, Xu~Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu.
\newblock Fastspeech 2: Fast and high-quality end-to-end text to speech.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Kim et~al.(2021)Kim, Kong, and Son]{vits}
Jaehyeon Kim, Jungil Kong, and Juhee Son.
\newblock Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech.
\newblock In \emph{International Conference on Machine Learning}, pages 5530--5540. PMLR, 2021.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Chen, Wu, Zhang, Zhou, Liu, Chen, Liu, Wang, Li, et~al.]{valle}
Chengyi Wang, Sanyuan Chen, Yu~Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et~al.
\newblock Neural codec language models are zero-shot text to speech synthesizers.
\newblock \emph{arXiv preprint arXiv:2301.02111}, 2023{\natexlab{a}}.

\bibitem[Shen et~al.(2024)Shen, Ju, Tan, Liu, Leng, He, Qin, sheng zhao, and Bian]{naturalspeech}
Kai Shen, Zeqian Ju, Xu~Tan, Eric Liu, Yichong Leng, Lei He, Tao Qin, sheng zhao, and Jiang Bian.
\newblock Naturalspeech 2: Latent diffusion models are natural and zero-shot speech and singing synthesizers.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Jiang et~al.(2023{\natexlab{a}})Jiang, Liu, Ren, He, Ye, Ji, Yang, Zhang, Wei, Wang, et~al.]{megatts}
Ziyue Jiang, Jinglin Liu, Yi~Ren, Jinzheng He, Zhenhui Ye, Shengpeng Ji, Qian Yang, Chen Zhang, Pengfei Wei, Chunfeng Wang, et~al.
\newblock Boosting prompting mechanisms for zero-shot speech synthesis.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023{\natexlab{a}}.

\bibitem[Dhariwal et~al.(2020)Dhariwal, Jun, Payne, Kim, Radford, and Sutskever]{dhariwal2020jukebox}
Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong~Wook Kim, Alec Radford, and Ilya Sutskever.
\newblock Jukebox: A generative model for music.
\newblock \emph{arXiv preprint arXiv:2005.00341}, 2020.

\bibitem[sun()]{suno}
Suno.
\newblock [Online].
\newblock \url{https://suno.com/}.

\bibitem[udi()]{udio}
Udio.
\newblock [Online].
\newblock \url{https://www.udio.com/}.

\bibitem[Chen et~al.(2020)Chen, Tan, Luan, Qin, and Liu]{chen2020hifisinger}
Jiawei Chen, Xu~Tan, Jian Luan, Tao Qin, and Tie-Yan Liu.
\newblock Hifisinger: Towards high-fidelity neural singing voice synthesis.
\newblock \emph{arXiv preprint arXiv:2009.01776}, 2020.

\bibitem[Huang et~al.(2022)Huang, Cui, Chen, Ren, Liu, Zhao, Huai, and Wang]{huang2022singgan}
Rongjie Huang, Chenye Cui, Feiyang Chen, Yi~Ren, Jinglin Liu, Zhou Zhao, Baoxing Huai, and Zhefeng Wang.
\newblock Singgan: Generative adversarial network for high-fidelity singing voice generation.
\newblock In \emph{Proceedings of the 30th ACM International Conference on Multimedia}, pages 2525--2535, 2022.

\bibitem[Zhang et~al.(2022)Zhang, Cong, Xue, Xie, Zhu, and Bi]{zhang2022visinger}
Yongmao Zhang, Jian Cong, Heyang Xue, Lei Xie, Pengcheng Zhu, and Mengxiao Bi.
\newblock Visinger: Variational inference with adversarial learning for end-to-end singing voice synthesis.
\newblock In \emph{ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 7237--7241, 2022.

\bibitem[Hong et~al.(2023)Hong, Cui, Huang, Zhang, Liu, He, and Zhao]{hong2023unisinger}
Zhiqing Hong, Chenye Cui, Rongjie Huang, Lichao Zhang, Jinglin Liu, Jinzheng He, and Zhou Zhao.
\newblock Unisinger: Unified end-to-end singing voice synthesis with cross-modality information matching.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Multimedia}, pages 7569--7579, 2023.

\bibitem[Liu et~al.(2022)Liu, Li, Ren, Chen, and Zhao]{liu2022diffsinger}
Jinglin Liu, Chengxi Li, Yi~Ren, Feiyang Chen, and Zhou Zhao.
\newblock Diffsinger: Singing voice synthesis via shallow diffusion mechanism.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~36, pages 11020--11028, 2022.

\bibitem[Hwang et~al.(2023)Hwang, Lee, and Lee]{hwang2023hiddensinger}
Ji-Sang Hwang, Sang-Hoon Lee, and Seong-Whan Lee.
\newblock Hiddensinger: High-quality singing voice synthesis via neural audio codec and latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2306.06814}, 2023.

\bibitem[Ding et~al.(2024)Ding, Liu, Dong, Zhang, Qian, He, Lin, and Wang]{ding2024songcomposer}
Shuangrui Ding, Zihan Liu, Xiaoyi Dong, Pan Zhang, Rui Qian, Conghui He, Dahua Lin, and Jiaqi Wang.
\newblock Songcomposer: A large language model for lyric and melody composition in song generation.
\newblock \emph{arXiv preprint arXiv:2402.17645}, 2024.

\bibitem[Copet et~al.(2024)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and D{\'e}fossez]{musicgen}
Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre D{\'e}fossez.
\newblock Simple and controllable music generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Lam et~al.(2024)Lam, Tian, Li, Yin, Feng, Tu, Ji, Xia, Ma, Song, et~al.]{melody}
Max~WY Lam, Qiao Tian, Tang Li, Zongyu Yin, Siyuan Feng, Ming Tu, Yuliang Ji, Rui Xia, Mingbo Ma, Xuchen Song, et~al.
\newblock Efficient neural music generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Schneider et~al.(2023)Schneider, Jin, and Sch{\"o}lkopf]{mousai}
Flavio Schneider, Zhijing Jin, and Bernhard Sch{\"o}lkopf.
\newblock Mo{\^u}sai: Text-to-music generation with long-context latent diffusion.
\newblock \emph{arXiv e-prints}, pages arXiv--2301, 2023.

\bibitem[Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti, Caillon, Huang, Jansen, Roberts, Tagliasacchi, et~al.]{musiclm}
Andrea Agostinelli, Timo~I Denk, Zal{\'a}n Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, et~al.
\newblock Musiclm: Generating music from text.
\newblock \emph{arXiv preprint arXiv:2301.11325}, 2023.

\bibitem[Grachten et~al.(2020)Grachten, Lattner, and Deruty]{grachten2020bassnet}
Maarten Grachten, Stefan Lattner, and Emmanuel Deruty.
\newblock Bassnet: A variational gated autoencoder for conditional generation of bass guitar tracks with learned interactive control.
\newblock \emph{Applied Sciences}, 10\penalty0 (18):\penalty0 6627, 2020.

\bibitem[Wu et~al.(2022)Wu, Chiu, and Yang]{wu2022jukedrummer}
Yueh-Kao Wu, Ching-Yu Chiu, and Yi-Hsuan Yang.
\newblock Jukedrummer: Conditional beat-aware audio-domain drum accompaniment generation via transformer vq-vae.
\newblock In \emph{Ismir 2022 Hybrid Conference}, 2022.

\bibitem[Yeh et~al.(2021)Yeh, Hsiao, Fukayama, Kitahara, Genchel, Liu, Dong, Chen, Leong, and Yang]{yeh2021automatic}
Yin-Cheng Yeh, Wen-Yi Hsiao, Satoru Fukayama, Tetsuro Kitahara, Benjamin Genchel, Hao-Min Liu, Hao-Wen Dong, Yian Chen, Terence Leong, and Yi-Hsuan Yang.
\newblock Automatic melody harmonization with triad chords: A comparative study.
\newblock \emph{Journal of New Music Research}, 50\penalty0 (1):\penalty0 37--51, 2021.

\bibitem[Donahue et~al.(2023)Donahue, Caillon, Roberts, Manilow, Esling, Agostinelli, Verzetti, Simon, Pietquin, Zeghidour, et~al.]{donahue2023singsong}
Chris Donahue, Antoine Caillon, Adam Roberts, Ethan Manilow, Philippe Esling, Andrea Agostinelli, Mauro Verzetti, Ian Simon, Olivier Pietquin, Neil Zeghidour, et~al.
\newblock Singsong: Generating musical accompaniments from singing.
\newblock \emph{arXiv preprint arXiv:2301.12662}, 2023.

\bibitem[Zhiqing et~al.(2024)Zhiqing, Rongjie, Xize, Yongqi, Ruiqi, Fuming, Zhou, and Zhimeng]{zhiqing2024text}
Hong Zhiqing, Huang Rongjie, Cheng Xize, Wang Yongqi, Li~Ruiqi, You Fuming, Zhao Zhou, and Zhang Zhimeng.
\newblock Text-to-song: Towards controllable music generation incorporating vocals and accompaniment.
\newblock \emph{arXiv preprint arXiv:2404.09313}, 2024.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{ldm}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Dong et~al.(2019)Dong, Yang, Wang, Wei, Liu, Wang, Gao, Zhou, and Hon]{dong2019unilm}
Li~Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu~Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon.
\newblock Unified language model pre-training for natural language understanding and generation.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Du et~al.(2022)Du, Qian, Liu, Ding, Qiu, Yang, and Tang]{du2022glm}
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang.
\newblock Glm: General language model pretraining with autoregressive blank infilling.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 320--335, 2022.

\bibitem[Dong et~al.(2018)Dong, Hsiao, Yang, and Yang]{dong2018musegan}
Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, and Yi-Hsuan Yang.
\newblock Musegan: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~32, 2018.

\bibitem[Wei et~al.(2023)Wei, Chen, Zheng, Guo, Li, and Wang]{wei23c_interspeech}
Xipin Wei, Junhui Chen, Zirui Zheng, Li~Guo, Lantian Li, and Dong Wang.
\newblock {A Multi-Scale Attentive Transformer for Multi-Instrument Symbolic Music Generation}.
\newblock In \emph{Proc. INTERSPEECH 2023}, pages 5391--5395, 2023.

\bibitem[Borsos et~al.(2023)Borsos, Marinier, Vincent, Kharitonov, Pietquin, Sharifi, Roblek, Teboul, Grangier, Tagliasacchi, et~al.]{audiolm}
Zal{\'a}n Borsos, Rapha{\"e}l Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, et~al.
\newblock Audiolm: a language modeling approach to audio generation.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 2023.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages 2256--2265, 2015.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Kingma et~al.(2021)Kingma, Salimans, Poole, and Ho]{vdm}
Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock Variational diffusion models.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 21696--21707, 2021.

\bibitem[Chen et~al.(2024)Chen, Wu, Liu, Nezhurina, Berg-Kirkpatrick, and Dubnov]{chen2024musicldm}
Ke~Chen, Yusong Wu, Haohe Liu, Marianna Nezhurina, Taylor Berg-Kirkpatrick, and Shlomo Dubnov.
\newblock Musicldm: Enhancing novelty in text-to-music generation using beat-synchronous mixup strategies.
\newblock In \emph{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1206--1210. IEEE, 2024.

\bibitem[Forsgren and Martiros(2022)]{riffusion}
Seth* Forsgren and Hayk* Martiros.
\newblock {Riffusion - Stable diffusion for real-time music generation}.
\newblock 2022.
\newblock URL \url{https://riffusion.com/about}.

\bibitem[Huang et~al.(2023{\natexlab{a}})Huang, Park, Wang, Denk, Ly, Chen, Zhang, Zhang, Yu, Frank, et~al.]{noise2music}
Qingqing Huang, Daniel~S Park, Tao Wang, Timo~I Denk, Andy Ly, Nanxin Chen, Zhengdong Zhang, Zhishuai Zhang, Jiahui Yu, Christian Frank, et~al.
\newblock Noise2music: Text-conditioned music generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.03917}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023)Liu, Tian, Yuan, Liu, Mei, Kong, Wang, Wang, Wang, and Plumbley]{liu2023audioldm}
Haohe Liu, Qiao Tian, Yi~Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, and Mark~D Plumbley.
\newblock Audioldm 2: Learning holistic audio generation with self-supervised pretraining.
\newblock \emph{arXiv preprint arXiv:2308.05734}, 2023.

\bibitem[Tan et~al.(2021)Tan, Deng, Yeung, Jiang, Chen, and Lee]{tan2021editspeech}
Daxin Tan, Liqun Deng, Yu~Ting Yeung, Xin Jiang, Xiao Chen, and Tan Lee.
\newblock Editspeech: A text based speech editing system using partial inference and bidirectional fusion.
\newblock In \emph{2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, pages 626--633. IEEE, 2021.

\bibitem[Wang et~al.(2022)Wang, Yi, Fu, Tao, and Wen]{wang2022campnet}
Tao Wang, Jiangyan Yi, Ruibo Fu, Jianhua Tao, and Zhengqi Wen.
\newblock Campnet: Context-aware mask prediction for end-to-end text-based speech editing.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 30:\penalty0 2241--2254, 2022.

\bibitem[Bai et~al.(2022)Bai, Zheng, Chen, Ma, Li, and Huang]{bai20223}
He~Bai, Renjie Zheng, Junkun Chen, Mingbo Ma, Xintong Li, and Liang Huang.
\newblock A3t: Alignment-aware acoustic and text pretraining for speech synthesis and editing.
\newblock In \emph{International Conference on Machine Learning}, pages 1399--1411, 2022.

\bibitem[Borsos et~al.(2022)Borsos, Sharifi, and Tagliasacchi]{borsos22_interspeech}
Zalan Borsos, Matthew Sharifi, and Marco Tagliasacchi.
\newblock {SpeechPainter: Text-conditioned Speech Inpainting}.
\newblock In \emph{Proc. Interspeech 2022}, pages 431--435, 2022.

\bibitem[Jiang et~al.(2023{\natexlab{b}})Jiang, Yang, Zuo, Ye, Huang, Ren, and Zhao]{jiang2023fluentspeech}
Ziyue Jiang, Qian Yang, Jialong Zuo, Zhenhui Ye, Rongjie Huang, Yi~Ren, and Zhou Zhao.
\newblock Fluentspeech: Stutter-oriented automatic speech editing with context-aware diffusion models.
\newblock In \emph{Findings of the Association for Computational Linguistics: ACL 2023}, pages 11655--11671, 2023{\natexlab{b}}.

\bibitem[Du et~al.(2024{\natexlab{a}})Du, Guo, Shen, Liu, Liang, Chen, Wang, Zhang, and Yu]{du2024unicats}
Chenpeng Du, Yiwei Guo, Feiyu Shen, Zhijun Liu, Zheng Liang, Xie Chen, Shuai Wang, Hui Zhang, and Kai Yu.
\newblock Unicats: A unified context-aware text-to-speech framework with contextual vq-diffusion and vocoding.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 17924--17932, 2024{\natexlab{a}}.

\bibitem[Yin et~al.(2022)Yin, Tang, Liu, Wang, Zhao, Zhao, Xiong, Zhao, and Luo]{yin22_interspeech}
Dacheng Yin, Chuanxin Tang, Yanqing Liu, Xiaoqiang Wang, Zhiyuan Zhao, Yucheng Zhao, Zhiwei Xiong, Sheng Zhao, and Chong Luo.
\newblock {RetrieverTTS: Modeling Decomposed Factors for Text-Based Speech Insertion}.
\newblock In \emph{Proc. Interspeech 2022}, pages 1571--1575, 2022.

\bibitem[Yang et~al.(2023)Yang, Tian, Tan, Huang, Liu, Chang, Shi, Zhao, Bian, Wu, et~al.]{yang2023uniaudio}
Dongchao Yang, Jinchuan Tian, Xu~Tan, Rongjie Huang, Songxiang Liu, Xuankai Chang, Jiatong Shi, Sheng Zhao, Jiang Bian, Xixin Wu, et~al.
\newblock Uniaudio: An audio foundation model toward universal audio generation.
\newblock \emph{arXiv preprint arXiv:2310.00704}, 2023.

\bibitem[Kharitonov et~al.(2023)Kharitonov, Vincent, Borsos, Marinier, Girgin, Pietquin, Sharifi, Tagliasacchi, and Zeghidour]{speartts}
Eugene Kharitonov, Damien Vincent, Zal{\'a}n Borsos, Rapha{\"e}l Marinier, Sertan Girgin, Olivier Pietquin, Matt Sharifi, Marco Tagliasacchi, and Neil Zeghidour.
\newblock Speak, read and prompt: High-fidelity text-to-speech with minimal supervision.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 11:\penalty0 1703--1718, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Zhou, Wang, Chen, Wu, Liu, Chen, Liu, Wang, Li, et~al.]{zhang2023speak}
Ziqiang Zhang, Long Zhou, Chengyi Wang, Sanyuan Chen, Yu~Wu, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et~al.
\newblock Speak foreign languages with your own voice: Cross-lingual neural codec language modeling.
\newblock \emph{arXiv preprint arXiv:2303.03926}, 2023.

\bibitem[Le et~al.(2024)Le, Vyas, Shi, Karrer, Sari, Moritz, Williamson, Manohar, Adi, Mahadeokar, et~al.]{le2024voicebox}
Matthew Le, Apoorv Vyas, Bowen Shi, Brian Karrer, Leda Sari, Rashel Moritz, Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, et~al.
\newblock Voicebox: Text-guided multilingual universal speech generation at scale.
\newblock \emph{Advances in neural information processing systems}, 36, 2024.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Thakker, Chen, Kanda, Eskimez, Chen, Tang, Liu, Li, and Yoshioka]{wang2023speechx}
Xiaofei Wang, Manthan Thakker, Zhuo Chen, Naoyuki Kanda, Sefik~Emre Eskimez, Sanyuan Chen, Min Tang, Shujie Liu, Jinyu Li, and Takuya Yoshioka.
\newblock Speechx: Neural codec language model as a versatile speech transformer.
\newblock \emph{arXiv preprint arXiv:2308.06873}, 2023{\natexlab{b}}.

\bibitem[Peng et~al.(2024)Peng, Huang, Li, Mohamed, and Harwath]{peng2024voicecraft}
Puyuan Peng, Po-Yao Huang, Daniel Li, Abdelrahman Mohamed, and David Harwath.
\newblock Voicecraft: Zero-shot speech editing and text-to-speech in the wild.
\newblock \emph{arXiv preprint arXiv:2403.16973}, 2024.

\bibitem[Chiu et~al.(2022)Chiu, Qin, Zhang, Yu, and Wu]{bestrq}
Chung-Cheng Chiu, James Qin, Yu~Zhang, Jiahui Yu, and Yonghui Wu.
\newblock Self-supervised learning with random-projection quantizer for speech recognition.
\newblock In \emph{International Conference on Machine Learning}, pages 3915--3924. PMLR, 2022.

\bibitem[Li et~al.(2019)Li, Liu, Liu, Zhao, and Liu]{li2019neural}
Naihan Li, Shujie Liu, Yanqing Liu, Sheng Zhao, and Ming Liu.
\newblock Neural speech synthesis with transformer network.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~33, pages 6706--6713, 2019.

\bibitem[Shen et~al.(2018)Shen, Pang, Weiss, Schuster, Jaitly, Yang, Chen, Zhang, Wang, Skerrv-Ryan, et~al.]{shen2018natural}
Jonathan Shen, Ruoming Pang, Ron~J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu~Zhang, Yuxuan Wang, Rj~Skerrv-Ryan, et~al.
\newblock Natural tts synthesis by conditioning wavenet on mel spectrogram predictions.
\newblock In \emph{2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)}, pages 4779--4783. IEEE, 2018.

\bibitem[Huang et~al.(2023{\natexlab{b}})Huang, Huang, Yang, Ren, Liu, Li, Ye, Liu, Yin, and Zhao]{makeanaudio}
Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi~Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao.
\newblock Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models.
\newblock In \emph{International Conference on Machine Learning}, pages 13916--13932. PMLR, 2023{\natexlab{b}}.

\bibitem[sta()]{stableaudio}
Stable audio: Fast timing-conditioned latent audio diffusion.
\newblock [Online].
\newblock \url{https://stability.ai/research/stable-audio-efficient-timing-latent-diffusion}.

\bibitem[Du et~al.(2024{\natexlab{b}})Du, Chen, Zhang, Hu, Lu, Yang, Hu, Zheng, Gu, Ma, et~al.]{du2024cosyvoice}
Zhihao Du, Qian Chen, Shiliang Zhang, Kai Hu, Heng Lu, Yexin Yang, Hangrui Hu, Siqi Zheng, Yue Gu, Ziyang Ma, et~al.
\newblock Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens.
\newblock \emph{arXiv preprint arXiv:2407.05407}, 2024{\natexlab{b}}.

\bibitem[Aghajanyan et~al.(2022)Aghajanyan, Huang, Ross, Karpukhin, Xu, Goyal, Okhonko, Joshi, Ghosh, Lewis, et~al.]{aghajanyan2022cm3}
Armen Aghajanyan, Bernie Huang, Candace Ross, Vladimir Karpukhin, Hu~Xu, Naman Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, et~al.
\newblock Cm3: A causal masked multimodal model of the internet.
\newblock \emph{arXiv preprint arXiv:2201.07520}, 2022.

\bibitem[Rouard et~al.(2023)Rouard, Massa, and D{\'e}fossez]{rouard2023hybrid}
Simon Rouard, Francisco Massa, and Alexandre D{\'e}fossez.
\newblock Hybrid transformers for music source separation.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1--5. IEEE, 2023.

\bibitem[D{\'e}fossez(2021)]{defossez2021hybrid}
Alexandre D{\'e}fossez.
\newblock Hybrid spectrogram and waveform source separation.
\newblock In \emph{Proceedings of the ISMIR 2021 Workshop on Music Source Separation}, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Kilgour et~al.(2019)Kilgour, Zuluaga, Roblek, and Sharifi]{kilgour19_interspeech}
Kevin Kilgour, Mauricio Zuluaga, Dominik Roblek, and Matthew Sharifi.
\newblock {Fr√©chet Audio Distance: A Reference-Free Metric for Evaluating Music Enhancement Algorithms}.
\newblock In \emph{Proc. Interspeech 2019}, pages 2350--2354, 2019.

\bibitem[Radford et~al.()Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{gpt2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.

\bibitem[Lanzend{\"o}rfer et~al.(2024)Lanzend{\"o}rfer, Gr{\"o}tschla, Funke, and Wattenhofer]{lanzendorfer2024disco}
Luca Lanzend{\"o}rfer, Florian Gr{\"o}tschla, Emil Funke, and Roger Wattenhofer.
\newblock Disco-10m: A large-scale music dataset.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and Mohamed]{hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed.
\newblock Hubert: Self-supervised speech representation learning by masked prediction of hidden units.
\newblock \emph{IEEE/ACM transactions on audio, speech, and language processing}, 29:\penalty0 3451--3460, 2021.

\bibitem[Li et~al.(2023)Li, Yuan, Zhang, Ma, Chen, Yin, Xiao, Lin, Ragni, Benetos, et~al.]{mert}
Yizhi Li, Ruibin Yuan, Ge~Zhang, Yinghao Ma, Xingran Chen, Hanzhi Yin, Chenghao Xiao, Chenghua Lin, Anton Ragni, Emmanouil Benetos, et~al.
\newblock Mert: Acoustic music understanding model with large-scale self-supervised training.
\newblock \emph{arXiv preprint arXiv:2306.00107}, 2023.

\bibitem[Won et~al.(2024)Won, Hung, and Le]{musicfm}
Minz Won, Yun-Ning Hung, and Duc Le.
\newblock A foundation model for music informatics.
\newblock In \emph{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1226--1230. IEEE, 2024.

\bibitem[Hines et~al.(2015)Hines, Skoglund, Kokaram, and Harte]{hines2015visqol}
Andrew Hines, Jan Skoglund, Anil~C Kokaram, and Naomi Harte.
\newblock Visqol: an objective speech quality model.
\newblock \emph{EURASIP Journal on Audio, Speech, and Music Processing}, 2015:\penalty0 1--18, 2015.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and Tagliasacchi]{zeghidour2021soundstream}
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 30:\penalty0 495--507, 2021.

\bibitem[D{\'e}fossez et~al.(2023)D{\'e}fossez, Copet, Synnaeve, and Adi]{dfossez2023high}
Alexandre D{\'e}fossez, Jade Copet, Gabriel Synnaeve, and Yossi Adi.
\newblock High fidelity neural audio compression.
\newblock \emph{Transactions on Machine Learning Research}, 2023.

\bibitem[Hershey et~al.(2017)Hershey, Chaudhuri, Ellis, Gemmeke, Jansen, Moore, Plakal, Platt, Saurous, Seybold, et~al.]{hershey2017cnn}
Shawn Hershey, Sourish Chaudhuri, Daniel~PW Ellis, Jort~F Gemmeke, Aren Jansen, R~Channing Moore, Manoj Plakal, Devin Platt, Rif~A Saurous, Bryan Seybold, et~al.
\newblock Cnn architectures for large-scale audio classification.
\newblock In \emph{2017 ieee international conference on acoustics, speech and signal processing (icassp)}, pages 131--135, 2017.

\end{thebibliography}
