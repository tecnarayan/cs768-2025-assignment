% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})


@article{yang2022diffusion,
  title={Diffusion models: A comprehensive survey of methods and applications},
  author={Yang, Ling and Zhang, Zhilong and Hong, Shenda},
  journal={arXiv:2209.00796},
  year={2022}
}

@inproceedings{deshmukh2022overview,
  title={An Overview of Deep Learning Techniques for Autonomous Driving Vehicles},
  author={Deshmukh, Vaishali M and Rajalakshmi, B and Krishna, Gopi BS and Rudrawar, Gourav},
  booktitle={International Conference on Smart Systems and Inventive Technology (ICSSIT)},
  pages={979--983},
  year={2022},
  organization={IEEE}
}

@inproceedings{li2022learning,
  title={Learning from students: Online contrastive distillation network for general continual learning},
  author={Li, Jin and Ji, Zhong and Wang, Gang and Wang, Qiang and Gao, Feng},
  booktitle={Proc. International Joint Conference on Artificial Intelligence (IJCAI)},
  pages={3215--3221},
  year={2022}
}

@article{gupta2021deep,
  title={Deep learning for object detection and scene perception in self-driving cars: Survey, challenges, and open issues},
  author={Gupta, Abhishek and Anpalagan, Alagan and Guan, Ling and Khwaja, Ahmed Shaharyar},
  journal={Array},
  volume={10},
  pages={100057},
  year={2021},
  publisher={Elsevier}
}

@article{yang2022chroma,
  title={Chroma-vae: Mitigating shortcut learning with generative classifiers},
  author={Yang, Wanqian and Kirichenko, Polina and Goldblum, Micah and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20351--20365},
  year={2022}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{ramezanian2022generative,
  title={Generative models of brain dynamics},
  author={Ramezanian-Panahi, Mahta and Abrevaya, Germ{\'a}n and Gagnon-Audet, Jean-Christophe and Voleti, Vikram and Rish, Irina and Dumas, Guillaume},
  journal={Frontiers in artificial intelligence},
  volume={5},
  pages={807406},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{degrave2022magnetic,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022},
  publisher={Nature}
}

@article{cremer2021deep,
  title={Deep limitations? {E}xamining expert disagreement over deep learning},
  author={Cremer, Carla Zoe},
  journal={Progress in Artificial Intelligence},
  volume={10},
  number={4},
  pages={449--464},
  year={2021},
  publisher={Springer}
}

@article{hadsell2020embracing,
  title={Embracing change: Continual learning in deep neural networks},
  author={Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A and Pascanu, Razvan},
  journal={Trends in cognitive sciences},
  volume={24},
  number={12},
  pages={1028--1040},
  year={2020},
  publisher={Elsevier}
}

@InProceedings{van_de_Ven_2021_CVPR,
    author    = {Ven, Gido M and Li, Zhe and Tolias, Andreas S},
    title     = {Class-Incremental Learning With Generative Classifiers},
    booktitle = {Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    year      = {2021},
    pages     = {3611--3620}
}

@article{li2017learnings,
	title={Learning without forgetting},
	author={Li, Zhizhong and Hoiem, Derek},
	journal={IEEE Trans on Pattern Analysis and Machine Intelligence},
	volume={40},
	number={12},
	pages={2935--2947},
	year={2017},
	publisher={IEEE}
}

@inproceedings{douillard2020podnet,
	title={Podnet: Pooled outputs distillation for small-tasks incremental learning},
	author={Douillard, Arthur and Cord, Matthieu and Ollion, Charles and Robert, Thomas and Valle, Eduardo},
	booktitle={European Conference on Computer Vision (ECCV)},
	pages={86--102},
	year={2020},
	organization={Springer}
}

@InProceedings{ven_three,
    author    = {Ven, Gido M and Tolias, Andreas S},
    title     = {Three scenarios for continual learning},
    booktitle = {Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop},
    year      = {2019},
    pages     = {3611--3620}
}

@article{zeno2021task,
	author = {Zeno, Chen and Golan, Itay and Hoffer, Elad and Soudry, Daniel},
	title = {Task-Agnostic Continual Learning Using Online Variational Bayes With Fixed-Point Updates},
	journal = {Neural Computation},
	volume = {33},
	number = {11},
	pages = {3139-3177},
	year = {2021}
}

@inproceedings{liu2020generative,
  title={Generative feature replay for class-incremental learning},
  author={Liu, Xialei and Wu, Chenshen and Menta, Mikel and Herranz, Luis and Raducanu, Bogdan and Bagdanov, Andrew D and Jui, Shangling and de Weijer, Joost van},
  booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages={226--227},
  year={2020}
}

@inproceedings{yu2020semantic,
  title={Semantic drift compensation for class-incremental learning},
  author={Yu, Lu and Twardowski, Bartlomiej and Liu, Xialei and Herranz, Luis and Wang, Kai and Cheng, Yongmei and Jui, Shangling and Weijer, Joost van de},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages={6982--6991},
  year={2020}
}

@inproceedings{zhang2020class,
  title={Class-incremental learning via deep model consolidation},
  author={Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and Kuo, C-C Jay},
  booktitle={Proc. of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={1131--1140},
  year={2020}
}

@article{ven2020brain,
  title={Brain-inspired replay for continual learning with artificial neural networks},
  author={Ven, Gido M and Siegelmann, Hava T and Tolias, Andreas S},
  journal={Nature Communications},
  volume={11},
  number={1},
  pages={1--14},
  year={2020},
  publisher={Nature}
}

@inproceedings{belouadah2020scail,
	title={Scail: Classifier weights scaling for class incremental learning},
	author={Belouadah, Eden and Popescu, Adrian},
	booktitle={Proc. of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
	pages={1266--1275},
	year={2020}
}

@article{belouadah2021comprehensive,
  title={A comprehensive study of class-incremental learning algorithms for visual tasks},
  author={Belouadah, Eden and Popescu, Adrian and Kanellos, Ioannis},
  journal={Neural Networks},
  volume={135},
  number={1},
  pages={38--54},
  year={2021},
  publisher={Elsevier}
}

@InProceedings{crosstask,
    author    = {Cormerais, Albin Soutif and Masana, Marc and Van de Weijer, Joost and Twardowski, Bartlomiej},
    title     = {On the importance of cross-task features for class-incremental learning},
    booktitle = {Proc. of International Conference on Machine Learning (ICML) Workshops},
    year      = {2021},
    pages     = {3611--3620}
}

@article{masana2020class,
  title={Class-incremental learning: {S}urvey and performance evaluation on image classification},
  author={Masana, Marc and Liu, Xialei and Twardowski, Bartlomiej and Menta, Mikel and Bagdanov, Andrew D and van de Weijer, Joost},
  journal={arXiv:2010.15277},
  year={2020}
}

@article{kirhar,
	title={One-Class Classification: {A} Survey},
	author={Perera, Pramuditha and Oza, Poojan and Patel, Vishal M},
	journal={arXiv:2101.03064},
	year={2021}
}


@article{MatthiasDe,
	title={Continual prototype evolution: {L}earning online from non-stationary data streams},
	author={De Lange, Matthias and Tuytelaars, Tinne},
	journal={arXiv:2009.00919},
	year={2020}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={National Academy of Sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
}

@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={Proc. International Conference on Machine Learning (ICML)},
  pages={3987--3995},
  year={2017}
}

@inproceedings{varcl,
  title={Variational continual learning},
  author={Nguyen, Cuong V and Li, Yingzhen and Bui, Thang D and Turner, Richard E},
  booktitle={Proc. International Conference on Learning Representations (ICLR)},
  pages={3987--3995},
  year={2018}
}

@inproceedings{unif,
  title={A Unifying Bayesian View of Continual Learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  booktitle={Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop},
  pages={3987--3995},
  year={2018}
}

@article{farquhar2018towards,
  title={Towards robust evaluations of continual learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv:1805.09733},
  year={2018}
}

@inproceedings{YenChang,
  title={Re-evaluating Continual Learning Scenarios: {A} Categorization and Case for Strong Baselines},
  author={Hsu, Yen-Chang and Liu, Yen-Cheng and Ramasamy, Anita and Kira, Zsolt},
  booktitle={Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop},
  pages={3987--3995},
  year={2018}
}

@inproceedings{SaihuiHou,
	title={Learning a unified classifier incrementally via rebalancing},
	author={Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
	booktitle={Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop},
	pages={831--839},
	year={2019}
}

@article{gener,
  author    = {Ven, Gido M and Tolias, Andreas S},
  title     = {Generative replay with feedback connections as a general strategy for continual learning},
  journal   = {arXiv:1805.09733},
  year = {2018}
}

@article{ManelBaradad,
	author    = {Baradad, Manel and Wulff, Jonas and Wang, Tongzhou and Isola, Phillip and Torralba, Antonio},
	title     = {Learning to See by Looking at Noise},
	journal   = {arXiv:2106.05963},
	year = {2021}
}

@inproceedings{dhar2019learning,
	title={Learning without memorizing},
	author={Dhar, Prithviraj and Singh, Rajat Vikram and Peng, Kuan-Chuan and Wu, Ziyan and Chellappa, Rama},
	booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={5138--5146},
	year={2019}
}

@inproceedings{JoanSerra,
	title={Overcoming catastrophic forgetting with hard attention to the task},
	author={Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
	booktitle={Proc. of International Conference on Machine Learning (ICML)},
	pages={4548--4557},
	year={2018}
}

@inproceedings{LukasSchott,
	title={Towards the first adversarially robust neural network model on mnist},
	author={Schott, Lukas and Rauber, Jonas and Bethge, Matthias and Brendel, Wieland},
	booktitle={Proc. of International Conference on Learning Representations (ICLR)},
	pages={1--16},
	year={2019}
}

@inproceedings{MatthewRiemer,
	title={Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference},
	author={Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
	booktitle={Proc. of International Conference on Learning Representations (ICLR)},
	pages={1--16},
	year={2019}
}

@book{StephanLewandowsky,
	title = {Interference and Inhibition in Cognition},
	pages = {329--361},
	year = {1995},
	author = {Lewandowsky, Stephan and Li, Shu-Chen}
}

@inproceedings{DecebalConstantinMocanu,
	title={One-Shot Learning using Mixture of Variational Autoencoders: {A} Generalization Learning Approach},
	author={Mocanu, Decebal Constantin and Mocanu, Elena},
	booktitle={Proc. of International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
	pages={1--16},
	year={2018}
}

@inproceedings{KenMcRae,
	title={Catastrophic Interference is Eliminated in Pre-Trained Networks},
	author={McRae, Ken and Hetherington, Phil A.},
	booktitle={Proc. of Conference of the Cognitive Science (CCS)},
	pages={723--728},
	year={1993}
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: {A} review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{LewandowskyStephan,
	title={Gradual unlearning and catastrophic interference: {A} comparison of distributed architectures},
	author={Stephan, Lewandowsky},
	booktitle={Proc. of Relating Theory and Data},
	pages={445--476},
	year={1991}
}

@inproceedings{JaehongYoon,
	title={Scalable and Order-robust Continual Learning with Additive Parameter Decomposition},
	author={Yoon, Jaehong and Kim, Saehoon and Yang, Eunho and Hwang, Sung Ju},
	booktitle={Proc. of International Conference on Learning Representation (ICLR)},
	pages={445--476},
	year={2020}
}



@article{li2020energy,
  title={Energy-Based Models for Continual Learning},
  author={Li, Shuang and Du, Yilun and Ven, Gido M. and Mordatch, Igor},
  journal={arXiv:2011.12216},
  year={2020}
}

@article{MarcosFCriado,
	title={Non-IID data and Continual Learning processes in Federated Learning: A long road ahead},
	author={Criado, Marcos F. and Casado, Fernando E. and Iglesias, Roberto and Iglesias, Carlos V. and Barro, Senen},
	journal={arXiv:2111.13394},
	year={2021}
}

@article{ThangDBui,
	title={Partitioned variational inference: A unified framework encompassing federated and continual learning},
	author={Bui, Thang D and Nguyen, Cuong V and Swaroop, Siddharth and Turner, Richard E},
	journal={arXiv:1811.11206 },
	year={2018}
}

@article{nori2021fast,
	title={Fast Federated Learning by Balancing Communication Trade-Offs},
	author={Khademi Nori, Milad and Yun, Sangseok and Kim, Il-Min},
	journal={IEEE Trans. on Communications (TCOM)},
	volume={69},
	number={8},
	pages={3521--3526},
	year={2021}
}

@article{vanschoren2018meta,
	title={Meta-learning: {A} survey},
	author={Vanschoren, Joaquin},
	journal={arXiv:1810.03548},
	year={2018}
}

@inproceedings{finn2017model,
	title={Model-agnostic meta-learning for fast adaptation of deep networks},
	author={inn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	booktitle={Proc. of International Conference on Machine Learning (ICML)},
	pages={1126--1135},
	year={2017}
}

@article{2ndPar2nd,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Konecny, Jakub and McMahan, H Brendan and Yu, Felix X and Richtarik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv:1610.05492},
  year={2016}
}

@inproceedings{wu2019large,
  title={Large scale incremental learning},
  author={Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Fu, Yun},
  booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={374--382},
  year={2019}
}

@inproceedings{Vincenzo,
	title={Rehearsal-free continual learning over small non-iid batches},
	author={Lomonaco, Vincenzo and Maltoni, Davide and Pellegrini, Lorenzo},
	booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
	pages={989--998},
	year={2020}
}

@inproceedings{lomonaco2017core50,
  title={Core50: {A} new dataset and benchmark for continuous object recognition},
  author={Lomonaco, Vincenzo and Maltoni, Davide},
  booktitle={Proc. of International Conference on Robot Learning (ICRL)},
  pages={17--26},
  year={2017}
}

@inproceedings{YuriBurda,
	title={Importance weighted autoencoders},
	author={Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
	booktitle={Proc. of International Conference on Learning Representations (ICLR)},
	pages={17--26},
	year={2016}
}

@inproceedings{AleksanderMadry,
	title={Towards Deep Learning Models Resistant to Adversarial Attacks},
	author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	booktitle={Proc. of International Conference on Learning Representations (ICLR)},
	pages={17--26},
	year={2018}
}

@inproceedings{IanJGoodfellow,
	title={Explaining and harnessing adversarial examples},
	author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
	booktitle={Proc. of International Conference on Learning Representations (ICLR)},
	pages={17--26},
	year={2015}
}

@article{TakashiKitamura,
	author = {Kitamura, Takashi and Ogawa, Sachie K. and Roy, Dheeraj S. and Okuyama, Teruhiro and Morrissey, Mark D. and Smith, Lillian M. and Redondo, Roger L. and Tonegawa, Susumu},
	title = {Engrams and circuits crucial for systems consolidation of a memory},
	journal = {Science},
	volume = {356},
	number = {6333},
	pages = {73--78},
	year = {2017}
}

@inproceedings{Castro,
	title={End-to-end incremental learning},
	author={Castro, Francisco M. and Marin-Jimenez, Manuel J. and Guil, Nicolas and Schmid, Cordelia and Alahari, Karteek},
	booktitle={Proc. of the European Conference on Computer	Vision (ECCV)},
	pages={233--248},
	year={2018}
}

@article{maltoni2019continuous,
  title={Continuous learning in single-incremental-task scenarios},
  author={Maltoni, Davide and Lomonaco, Vincenzo},
  journal={Neural Networks},
  volume={116},
  number={3},
  pages={56--73},
  year={2019},
  publisher={Elsevier}
}

@article{AlhusseinFawzi,
	title={Analysis of classifiers’ robustness to adversarial perturbations},
	author={Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
	journal={Machine Learning},
	volume={107},
	number={3},
	pages={481--508},
	year={2018}
}

@article{Anthony,
	title={Catastrophic forgetting, rehearsal and pseudorehearsal},
	author={Robins, Anthony},
	journal={Connection Science},
	volume={7},
	number={2},
	pages={123--146},
	year={1995}
}

@article{ShaoningPang,
  title={Incremental linear discriminant analysis for classification of data streams},
  author={Pang, Shaoning and Ozawa, Seiichi and Kasabov, Nikola},
  journal={IEEE Trans. on Systems, Man, and Cybernetics (TSMC)},
  volume={35},
  number={5},
  pages={905--914},
  year={2005}
}


@inproceedings{recentreg,
  title={Natural continual learning: success is a journey, not (just) a destination},
  author={Kao, Ta-Chu and Jensen, Kristopher T and Ven, Gido M. and Bernacchia, Alberto and Hennequin, Guillaume},
  booktitle={Proc. International Conference on Neural Information Processing Systems (NeurIPS)},
  pages={1266--1275},
  year={2020}
}


@inproceedings{LucasCaccia,
	title={Online learned continual compression with adaptive quantization modules},
	author={Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Pineau, Joelle},
	booktitle={Proc. of International Conference on Machine Learning (ICML)},
	pages={1240--1250},
	year={2020}
}

@inproceedings{TylerHayes,
	title={Remind your neural network to prevent catastrophic forgetting},
	author={Hayes, Tyler L and Kafle, Kushal and Shrestha, Robik and Acharya, Manoj and Kanan, Christopher},
	booktitle={Proc. of European Conference	on Computer Vision (ECCV)},
	pages={466--483},
	year={2020}
}

@article{vogelstein2020omnidirectional,
  title={Omnidirectional Transfer for Quasilinear Lifelong Learning},
  author={Vogelstein, Joshua T. and Dey, Jayanta and Helm, Hayden S. and LeVine, Will and Mehta, Ronak D. and Geisa, Ali and Xu, Haoyin and Ven, Gido M. and Chang, Emily and Gao, Chenyu and Yang, Weiwei and Tower, Bryan and Larson, Jonathan and White, Christopher M. and Priebe, Carey E.},
  journal={arXiv:2004.12908},
  year={2020}
}

@article{MartinMundt,
	title={A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning},
	author={Mundt, Martin and Hong, Yong Won and Pliushch, Iuliia and Ramesh, Visvanathan},
	journal={arXiv:2009.01797},
	year={2020}
}

@article{DiederikPKingma,
	title={Auto-encoding variational bayes},
	author={Kingma, Diederik P and Welling, Max},
	journal={arXiv:1312.6114},
	year={2013}
}


@article{aljundi2019online,
  title={Online continual learning with maximally interfered retrieval},
  author={Aljundi, Rahaf and Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Lin, Min and Charlin, Laurent and Tuytelaars, Tinne},
  journal={arXiv:1908.04742},
  year={2019}
}

@article{arslanch,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K. and Torr, Philip HS and Ranzato, Marc Aurelio},
  journal={arXiv:1902.10486},
  year={2019}
}

@inproceedings{aljundi2019task,
  title={Task-free continual learning},
  author={Aljundi, Rahaf and Kelchtermans, Klaas and Tuytelaars, Tinne},
  booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)} ,
  pages={11254--11263},
  year={2019}
}

@inproceedings{TimotheLesort,
	title={Generative models from the perspective of continual learning},
	author={Lesort, Timothe and Caselles-Dupre, Hugo and Garcia-Ortiz, Michael and Stoian, Andrei and Filliat, David},
	booktitle={Proc. of International Joint Conference on Neural Networks (IJCNN)},
	pages={11254--11263},
	year={2019}
}

@inproceedings{TaeKyunKim,
	title={Incremental linear discriminant analysis using sufficient spanning sets and its applications},
	author={Kim, Tae-Kyun and Stenger, Bjorn and Kittler, Josef and Cipolla, Roberto},
	booktitle={Proc. of International Journal of Computer Vision (IJCV)},
	pages={216–232},
	year={2011}
}

@inproceedings{hayes2020lifelong,
  title={Lifelong machine learning with deep streaming linear discriminant analysis},
  author={Hayes, Tyler L. and Kanan, Christopher},
  booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages={220--221},
  year={2020}
}

@InProceedings{shin,
    author    = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
    title     = {Continual Learning with Deep Generative Replay},
    booktitle = {Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop},
    year      = {2017},
    pages     = {2994--3003}
}

@InProceedings{finn, 
	title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}, 
	author = {Chelsea Finn and Pieter Abbeel and Sergey Levine}, 
	booktitle = {Proc. International Conference on Machine Learning}, 
	pages = {1126--1135}, 
	year = {2017}, 
}


@article{1stPar1st,
  title={Petuum: A new platform for distributed machine learning on big data},
  author={Xing, Eric P and Ho, Qirong and Dai, Wei and Kim, Jin Kyu and Wei, Jinliang and Lee, Seunghak and Zheng, Xun and Xie, Pengtao and Kumar, Abhimanu and Yu, Yaoliang},
  journal={IEEE Trans. Big Data},
  volume={1},
  number={2},
  pages={49--67},
  month={Jun.},
  year={2015},
  publisher={IEEE}
}

@article{wang2020convergence,
  title={Convergence of edge computing and deep learning: A comprehensive survey},
  author={Wang, Xiaofei and Han, Yiwen and Leung, Victor CM and Niyato, Dusit and Yan, Xueqiang and Chen, Xu},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={22},
  number={2},
  pages={869--904},
  month={Jan.},
  year={2020},
  publisher={IEEE}
}


@InProceedings{adacom,
  title={Adaptive communication strategies to achieve the best error-runtime trade-off in local-update {SGD}},
  author={Wang, Jianyu and Joshi, Gauri},
  booktitle = {Proc. Conference on Machine Learning and Systems}, 
  pages = {126--145},
  year={2019},
  volume = {1}
}


@article{1stPar2nd,
  title={Revisiting distributed synchronous {SGD}},
  author={Chen, Jianmin and Pan, Xinghao and Monga, Rajat and Bengio, Samy and Jozefowicz, Rafal},
  journal={arXiv:1604.00981},
  year={2016}
}

@article{1stPar3rd,
  title={Accurate, large minibatch {SGD}: Training {I}mage{N}et in 1 hour},
  author={Goyal, Priya and Dollar, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv:1706.02677},
  year={2017}
}

@inproceedings{2ndPar1st,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera},
  booktitle={Proc. Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017}
}


@article{theRecentSurvey,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv:1908.07873},
  year={2019}
}

@inproceedings{ternGrad,
  title={Tern{G}rad: Ternary gradients to reduce communication in distributed deep learning},
  author={Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={1509--1519},
  year={2017}
}


@inproceedings{qsgd,
  title={{QSGD}: Communication-efficient {SGD} via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={1709--1720},
  year={2017}
}

@inproceedings{one,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech {DNN}s},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Proc. International Speech Communication Association},
  year={2014},
  pages={1--8}
}

@article{quan1,
  title={Error compensated quantized {SGD} and its applications to large-scale distributed optimization},
  author={Wu, Jiaxiang and Huang, Weidong and Huang, Junzhou and Zhang, Tong},
  journal={arXiv:1806.08054},
  year={2018}
}

@inproceedings{quan2,
  title={A linear speedup analysis of distributed deep learning with sparse and quantized communication},
  author={Jiang, Peng and Agrawal, Gagan},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={2525--2536},
  year={2018}
}


@inproceedings{atomo,
  title={{ATOMO}: Communication-efficient learning via atomic sparsification},
  author={Wang, Hongyi and Sievert, Scott and Liu, Shengchao and Charles, Zachary and Papailiopoulos, Dimitris and Wright, Stephen},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={9850--9861},
  year={2018}
}


@inproceedings{dgc,
title={Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training},
author={Yujun Lin and Song Han and Huizi Mao and Yu Wang and Bill Dally},
booktitle={Proc. International Conference on Learning Representations},
pages={9850--9861},
year={2018}
}

@INPROCEEDINGS{sbc,
    title={Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication},
    author={Felix Sattler and Simon Wiedemann and Klaus-Robert Muller and Wojciech Samek},
    booktitle={Proc. International Joint Conference on Neural Networks (IJCNN)}, 
    year={2019},
    pages={1-8}
}



@INPROCEEDINGS{amir,
  author={M. M. {Amiri} and D. {Gündüz}},
  booktitle={Proc. IEEE International Symposium on Information Theory (ISIT)}, 
  title={Machine Learning at the Wireless Edge: Distributed Stochastic Gradient Descent Over-the-Air}, 
  year={2019},
  volume={},
  number={},
  pages={1432-1436}
}

@article{rmt,
  title={Implicit self-regularization in deep neural networks: Evidence from random matrix theory and implications for learning},
  author={Martin, Charles H and Mahoney, Michael W},
  journal={arXiv:1810.01075},
  year={2018}
}

@article{local,
  title={Don't Use Large Mini-Batches, Use Local {SGD}},
  author={Lin, Tao and Stich, Sebastian U and Patel, Kumar Kshitij and Jaggi, Martin},
  journal={arXiv:1808.07217},
  year={2018}
}

@ARTICLE{noniid,
  author={F. Sattler and S. Wiedemann and K. -R. Muller and W. Samek},
  journal={IEEE Trans. Neural Networks and Learning Systems}, 
  title={Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data}, 
  year={2020},
  volume={31},
  number={9},
  pages={3400-3413},
  month={Sep.},
  publisher={IEEE}
}

@inproceedings{scafold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={Proc. International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
}


@article{adapjsac,
  title={Adaptive federated learning in resource constrained edge computing systems},
  author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin},
  journal={IEEE J. Sel. Areas Comm.},
  volume={37},
  number={6},
  pages={1205--1221},
  year={2019},
  month={Mar.},
  publisher={IEEE}
}

@article{adaptau,
  title={On the convergence properties of a $K$-step averaging stochastic gradient descent algorithm for nonconvex optimization},
  author={Zhou, Fan and Cong, Guojing},
  journal={arXiv:1708.01012},
  year={2017}
}

@article{cooperativesgd,
  title={Cooperative {SGD}: A unified framework for the design and analysis of communication-efficient {SGD} algorithms},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={arXiv:1808.07576},
  year={2018}
}

@article{matcha,
  title={{MATCHA}: Speeding Up Decentralized {SGD} via Matching Decomposition Sampling},
  author={Wang, Jianyu and Sahu, Anit Kumar and Yang, Zhouyi and Joshi, Gauri and Kar, Soummya},
  journal={arXiv:1905.09435},
  year={2019}
}


@article{bigMatrix,
  title={Why Are Big Data Matrices Approximately Low Rank?},
  author={Udell, Madeleine and Townsend, Alex},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={1},
  number={1},
  pages={144--160},
  year={2019},
  publisher={SIAM},
  month={Feb.}
}


@article{eck,
  title={The approximation of one matrix by another of lower rank},
  author={Eckart, Carl and Young, Gale},
  journal={Psychometrika},
  volume={1},
  number={3},
  pages={211--218},
  year={1936},
  publisher={Springer}
}


@article{lecun2010mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  year={2010}
}


@online{xiao2017,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}


@article{li2019federated,
  title={Federated learning systems: Vision, hype and reality for data privacy and protection},
  author={Li, Qinbin and Wen, Zeyi and He, Bingsheng},
  journal={arXiv:1907.09693},
  year={2019}
}

@article{qualcomm1,
  title={We are making on-device {AI} ubiquitous},
  author={Qualcomm},
  journal={https://www.qualcomm.com/news/onq/2017/08/16/we-are-making-device-ai-ubiquitous},
  year={2017}
}

@article{qualcomm2,
  title={Snapdragon 835 Mobile Platform},
  author={Qualcomm},
  journal={https://www.qualcomm.com/products/snapdragon-835-mobile-platform},
  year={2020}
}

@article{gartner,
  title={Gartner Highlights 10 Uses for {AI}-Powered Smartphones},
  author={Gartner},
  journal={https://www.gartner.com/en/newsroom/press-releases/2018-03-20-gartner-highlights-10-uses-for-ai-powered-smartphones},
  year={2018}
}


@article{yang2018applied,
  title={Applied federated learning: Improving {G}oogle keyboard query suggestions},
  author={Yang, Timothy and Andrew, Galen and Eichner, Hubert and Sun, Haicheng and Li, Wei and Kong, Nicholas and Ramage, Daniel and Beaufays, Francoise},
  journal={arXiv:1812.02903},
  year={2018}
}


@inproceedings{doku2019towards,
  title={Towards Federated Learning Approach to Determine Data Relevance in Big Data},
  author={Doku, Ronald and Rawat, Danda B and Liu, Chunmei},
  booktitle={Proc. International Conference on Information Reuse and Integration for Data Science (IRI)},
  pages={184--192},
  year={2019},
  organization={IEEE}
}

@article{pokhrel2020compound,
  title={Compound-TCP Performance for Industry 4.0 WiFi: A Cognitive Federated Learning Approach},
  author={Pokhrel, Shiva Raj and Singh, Surjit},
  journal={IEEE Trans. Industrial Informatics},
  year={2020},
  publisher={IEEE}
}

@article{imteaj2020federated,
  title={Federated Learning for Resource-Constrained IoT Devices: Panoramas and State-of-the-art},
  author={Imteaj, Ahmed and Thakker, Urmish and Wang, Shiqiang and Li, Jian and Amini, M Hadi},
  journal={arXiv:2002.10610},
  year={2020}
}

@article{zhan2020learning,
  title={A Learning-based Incentive Mechanism for Federated Learning},
  author={Zhan, Yufeng and Li, Peng and Qu, Zhihao and Zeng, Deze and Guo, Song},
  journal={IEEE Internet of Things Journal},
  year={2020},
  publisher={IEEE}
}


@article{savazzi2020federated,
  title={Federated Learning with Cooperating Devices: A Consensus Approach for Massive IoT Networks},
  author={Savazzi, Stefano and Nicoli, Monica and Rampa, Vittorio},
  journal={IEEE Internet of Things Journal},
  year={2020},
  publisher={IEEE}
}


@article{ang2020robust,
  title={Robust Federated Learning With Noisy Communication},
  author={Ang, Fan and Chen, Li and Zhao, Nan and Chen, Yunfei and Wang, Weidong and Yu, F Richard},
  journal={IEEE Trans. Communications},
  year={2020},
  publisher={IEEE}
}


@article{fallah2020personalized,
  title={Personalized federated learning: A meta-learning approach},
  author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
  journal={arXiv:2002.07948},
  year={2020}
}

@article{jin2020survey,
  title={A Survey towards Federated Semi-supervised Learning},
  author={Jin, Yilun and Wei, Xiguang and Liu, Yang and Yang, Qiang},
  journal={arXiv:2002.11545},
  year={2020}
}


@article{xie2019asynchronous,
  title={Asynchronous federated optimization},
  author={Xie, Cong and Koyejo, Sanmi and Gupta, Indranil},
  journal={arXiv:1903.03934},
  year={2019}
}


@article{fantacci2020federated,
  title={Federated learning framework for mobile edge computing networks},
  author={Fantacci, Romano and Picano, Benedetta},
  journal={CAAI Trans. Intelligence Technology},
  volume={5},
  number={1},
  pages={15--21},
  year={2020},
  publisher={IET}
}

@article{kulkarni2020survey,
  title={Survey of Personalization Techniques for Federated Learning},
  author={Kulkarni, Viraj and Kulkarni, Milind and Pant, Aniruddha},
  journal={arXiv:2003.08673},
  year={2020}
}


@inproceedings{imteaj2019distributed,
  title={Distributed sensing using smart end-user devices: pathway to federated learning for autonomous IoT},
  author={Imteaj, Ahmed and Amini, M Hadi},
  booktitle={International Conference on Computational Science and Computational Intelligence (CSCI)},
  pages={1156--1161},
  year={2019},
  organization={IEEE}
}


@inproceedings{luping2019cmfl,
  title={CMFL: Mitigating communication overhead for federated learning},
  author={Luping, WANG and Wei, WANG and Bo, LI},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)},
  pages={954--964},
  year={2019},
  organization={IEEE}
}


@article{karimireddy2019scaffold,
  title={{SCAFFOLD}: Stochastic controlled averaging for on-device federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
  journal={arXiv:1910.06378},
  year={2019}
}


@article{zhu2019multi,
  title={Multi-objective evolutionary federated learning},
  author={Zhu, Hangyu and Jin, Yaochu},
  journal={IEEE Trans. Neural Networks and Learning Systems},
  volume={31},
  number={4},
  pages={1310--1322},
  year={2019},
  month={Jun.},
  publisher={IEEE}
}

@inproceedings{smith2017federated,
  title={Federated multi-task learning},
  author={Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet S},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={4424--4434},
  year={2017}
}


@article{mohri2019agnostic,
  title={Agnostic federated learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  journal={arXiv:1902.00146},
  year={2019}
}


@article{wang2019edge,
  title={In-edge {AI}: Intelligentizing mobile edge computing, caching and communication by federated learning},
  author={Wang, Xiaofei and Han, Yiwen and Wang, Chenyang and Zhao, Qiyang and Chen, Xu and Chen, Min},
  journal={IEEE Network},
  volume={33},
  number={5},
  pages={156--165},
  year={2019},
  month={Sep.},
  publisher={IEEE}
}

@article{lim2019federated,
  title={Federated learning in mobile edge networks: A comprehensive survey},
  author={Lim, Wei Yang Bryan and Luong, Nguyen Cong and Hoang, Dinh Thai and Jiao, Yutao and Liang, Ying-Chang and Yang, Qiang and Niyato, Dusit and Miao, Chunyan},
  journal={arXiv:1909.11875},
  year={2019}
}

@article{yang2019federated,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Trans. Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--19},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aurelien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv:1912.04977},
  year={2019}
}


@inproceedings{tran2019federated,
  title={Federated learning over wireless networks: Optimization model design and analysis},
  author={Tran, Nguyen H and Bao, Wei and Zomaya, Albert and NH, Nguyen Minh and Hong, Choong Seon},
  booktitle={IEEE INFOCOM 2019-IEEE Conference on Computer Communications},
  pages={1387--1395},
  year={2019},
  organization={IEEE}
}

@article{hard2018federated,
  title={Federated learning for mobile keyboard prediction},
  author={Hard, Andrew and Rao, Kanishka and Mathews, Rajiv and Ramaswamy, Swaroop and Beaufays, Francoise and Augenstein, Sean and Eichner, Hubert and Kiddon, Chloe and Ramage, Daniel},
  journal={arXiv:1811.03604},
  year={2018}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Konecny, Jakub and Mazzocchi, Stefano and McMahan, H Brendan and others},
  journal={arXiv:1902.01046},
  year={2019}
}

@article{sattler2019robust,
  title={Robust and communication-efficient federated learning from non-iid data},
  author={Sattler, Felix and Wiedemann, Simon and Muller, Klaus-Robert and Samek, Wojciech},
  journal={IEEE Trans. Neural Networks and Learning Systems},
  year={2019},
  publisher={IEEE}
}

@article{sahu2018convergence,
  title={On the convergence of federated optimization in heterogeneous networks},
  author={Sahu, Anit Kumar and Li, Tian and Sanjabi, Maziar and Zaheer, Manzil and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv:1812.06127},
  year={2018}
}

@inproceedings{kang2019incentive,
  title={Incentive design for efficient federated learning in mobile networks: A contract theory approach},
  author={Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Yu, Han and Liang, Ying-Chang and Kim, Dong In},
  booktitle={2019 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}

@article{yang2020federated,
  title={Federated learning via over-the-air computation},
  author={Yang, Kai and Jiang, Tao and Shi, Yuanming and Ding, Zhi},
  journal={IEEE Trans. Wireless Communications},
  volume={19},
  number={3},
  pages={2022--2035},
  year={2020},
  publisher={IEEE}
}

@article{zeng2019energy,
  title={Energy-efficient radio resource allocation for federated edge learning},
  author={Zeng, Qunsong and Du, Yuqing and Leung, Kin K and Huang, Kaibin},
  journal={arXiv:1907.06040},
  year={2019}
}


@article{chen2019joint,
  title={A joint learning and communications framework for federated learning over wireless networks},
  author={Chen, Mingzhe and Yang, Zhaohui and Saad, Walid and Yin, Changchuan and Poor, H Vincent and Cui, Shuguang},
  journal={arXiv:1909.07972},
  year={2019}
}


@article{letaief2019roadmap,
  title={The roadmap to 6G: AI empowered wireless networks},
  author={Letaief, Khaled B and Chen, Wei and Shi, Yuanming and Zhang, Jun and Zhang, Ying-Jun Angela},
  journal={IEEE Communications Magazine},
  volume={57},
  number={8},
  pages={84--90},
  year={2019},
  publisher={IEEE}
}

@article{shi2020communication,
  title={Communication-Efficient Edge {AI}: Algorithms and Systems},
  author={Shi, Yuanming and Yang, Kai and Jiang, Tao and Zhang, Jun and Letaief, Khaled B},
  journal={arXiv:2002.09668},
  year={2020}
}

@inproceedings{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={873--881},
  year={2011}
}

@inproceedings{lian2015asynchronous,
  title={Asynchronous parallel stochastic gradient for nonconvex optimization},
  author={Lian, Xiangru and Huang, Yijun and Li, Yuncheng and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2737--2745},
  year={2015}
}

@inproceedings{zheng2017asynchronous,
  title={Asynchronous stochastic gradient descent with delay compensation},
  author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4120--4129},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? A case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  booktitle={Proc. Advances in Neural Information Processing Systems},
  pages={5330--5340},
  year={2017}
}

@article{lian2017asynchronous,
  title={Asynchronous decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Wei and Zhang, Ce and Liu, Ji},
  journal={arXiv:1710.06952},
  year={2017}
}

@inproceedings{hsieh2017gaia,
  title={Gaia: Geo-distributed machine learning approaching LAN speeds},
  author={Hsieh, Kevin and Harlap, Aaron and Vijaykumar, Nandita and Konomis, Dimitris and Ganger, Gregory R and Gibbons, Phillip B and Mutlu, Onur},
  booktitle={14th USENIX Symposium on Networked Systems Design and Implementation NSDI 17},
  pages={629--647},
  year={2017}
}

@inproceedings{yu2019parallel,
  title={Parallel restarted {SGD} with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proc. AAAI Conference on Artificial Intelligence},
  pages={5693--5700},
  year={2019}
}

@article{zhang2013communication,
  title={Communication-efficient algorithms for statistical optimization},
  author={Zhang, Yuchen and Duchi, John C and Wainwright, Martin J},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3321--3363},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{arjevani2015communication,
  title={Communication complexity of distributed convex learning and optimization},
  author={Arjevani, Yossi and Shamir, Ohad},
  booktitle={Advances in neural information processing systems},
  pages={1756--1764},
  year={2015}
}

@article{ma2017distributed,
  title={Distributed optimization with arbitrary local solvers},
  author={Ma, Chenxin and Konevcny, Jakub and Jaggi, Martin and Smith, Virginia and Jordan, Michael I and Richtarik, Peter and Takac, Martin},
  journal={Optimization Methods and Software},
  volume={32},
  number={4},
  pages={813--848},
  year={2017},
  month={Jul.},
  publisher={Taylor \& Francis}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{vu2019cell,
  title={Cell-Free Massive MIMO for Wireless Federated Learning},
  author={Vu, Tung T and Ngo, Duy T and Tran, Nguyen H and Ngo, Hien Quoc and Dao, Minh N and Middleton, Richard H},
  journal={arXiv:1909.12567},
  year={2019}
}

@article{zhao2018federated,
  title={Federated learning with non-iid data},
  author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
  journal={arXiv:1806.00582},
  year={2018}
}

@article{samarakoon2019distributed,
  title={Distributed federated learning for ultra-reliable low-latency vehicular communications},
  author={Samarakoon, Sumudu and Bennis, Mehdi and Saad, Walid and Debbah, Merouane},
  journal={IEEE Trans. Communications},
  year={2019},
  publisher={IEEE}
}

@article{caldas2018expanding,
  title={Expanding the reach of federated learning by reducing client resource requirements},
  author={Caldas, Sebastian and Konecny, Jakub and McMahan, H Brendan and Talwalkar, Ameet},
  journal={arXiv:1812.07210},
  year={2018}
}

@article{li2019fair,
  title={Fair resource allocation in federated learning},
  author={Li, Tian and Sanjabi, Maziar and Smith, Virginia},
  journal={arXiv:1905.10497},
  year={2019}
}

@article{Niknam2019FederatedLF,
  title={Federated Learning for Wireless Communications: Motivation, Opportunities and Challenges},
  author={Solmaz Niknam and Harpreet S. Dhillon and Jeffery H. Reed},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.06847}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, Leon and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  month={May},
  publisher={SIAM}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  month={Dec.},
  publisher={SIAM}
}

@article{yao2019federated,
  title={Federated Learning with Additional Mechanisms on Clients to Reduce Communication Costs},
  author={Yao, Xin and Huang, Tianchi and Wu, Chenglei and Zhang, Rui-xiao and Sun, Lifeng},
  journal={arXiv:1908.05891},
  year={2019}
}

@article{chang2020communication,
  title={Communication efficient federated learning over multiple access channels},
  author={Chang, Wei-Ting and Tandon, Ravi},
  journal={arXiv:2001.08737},
  year={2020}
}

@article{brand2006fast,
  title={Fast low-rank modifications of the thin singular value decomposition},
  author={Brand, Matthew},
  journal={Linear Algebra and Its Applications},
  volume={415},
  number={1},
  pages={20--30},
  year={2006},
  month={May},
  publisher={Elsevier}
}


@article{kukavcka2017regularization,
	title={Regularization for deep learning: A taxonomy},
	author={Kukacka, Jan and Golkov, Vladimir and Cremers, Daniel},
	journal={arXiv:1710.10686},
	year={2017}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{ruff2018deep,
	title={Deep one-class classification},
	author={Ruff, Lukas and Vandermeulen, Robert and Goernitz, Nico and Deecke, Lucas and Siddiqui, Shoaib Ahmed and Binder, Alexander and M{\"u}ller, Emmanuel and Kloft, Marius},
	booktitle={International Conference on Machine Learning},
	pages={4393--4402},
	year={2018},
	organization={PMLR}
}

@article{liznerski2020explainable,
	title={Explainable deep one-class classification},
	author={Liznerski, Philipp and Ruff, Lukas and Vandermeulen, Robert A and Franks, Billy Joe and Kloft, Marius and M{\"u}ller, Klaus-Robert},
	journal={arXiv:2007.01760},
	year={2020}
}

@article{perera2019learning,
	title={Learning deep features for one-class classification},
	author={Perera, Pramuditha and Patel, Vishal M},
	journal={IEEE Trans. on Image Processing},
	volume={28},
	number={11},
	pages={5450--5463},
	year={2019},
	publisher={IEEE}
}

@article{sohn2020learning,
	title={Learning and evaluating representations for deep one-class classification},
	author={Sohn, Kihyuk and Li, Chun-Liang and Yoon, Jinsung and Jin, Minho and Pfister, Tomas},
	journal={arXiv:2011.02578},
	year={2020}
}

@inproceedings{nilsback2008automated,
	title={Automated flower classification over a large number of classes},
	author={Nilsback, Maria-Elena and Zisserman, Andrew},
	booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
	pages={722--729},
	year={2008},
	organization={IEEE}
}

@article{an2015variational,
	title={Variational autoencoder based anomaly detection using reconstruction probability},
	author={An, Jinwon and Cho, Sungzoon},
	journal={Special Lecture on IE},
	volume={2},
	number={1},
	pages={1--18},
	year={2015}
}

@inproceedings{zhou2017anomaly,
	title={Anomaly detection with robust deep autoencoders},
	author={Zhou, Chong and Paffenroth, Randy C},
	booktitle={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
	pages={665--674},
	year={2017}
}

@inproceedings{chen2018autoencoder,
	title={Autoencoder-based network anomaly detection},
	author={Chen, Zhaomin and Yeo, Chai Kiat and Lee, Bu Sung and Lau, Chiew Tong},
	booktitle={2018 Wireless Telecommunications Symposium (WTS)},
	pages={1--5},
	year={2018},
	organization={IEEE}
}

@techreport{krizhevsky2009learning,
	title = {Learning Multiple Layers of Features from Tiny Images},
	author = {Alex Krizhevsky},
	year = {2009},
	institution = {University of Toronto},
	type = {Technical Report}
}


@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv:1412.6980},
	year={2014}
}

@inproceedings{keller2021predictive,
	title={Predictive coding with topographic variational autoencoders},
	author={Keller, T Anderson and Welling, Max},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={1086--1091},
	year={2021}
}

@techreport{WahCUB_200_2011,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{fei2004learning,
	title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
	author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
	booktitle={2004 Conference on Computer Vision and Pattern Recognition Workshop},
	pages={178--178},
	year={2004},
	organization={IEEE}
}

@article{zhang2021understanding,
	title={Understanding deep learning (still) requires rethinking generalization},
	author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	journal={Communications of the ACM},
	volume={64},
	number={3},
	pages={107--115},
	year={2021}
}

@article{xu2012l,
	title={$ L\_ $\{$1/2$\}$ $ regularization: A thresholding representation theory and a fast solver},
	author={Xu, Zongben and Chang, Xiangyu and Xu, Fengmin and Zhang, Hai},
	journal={IEEE Transactions on neural networks and learning systems},
	volume={23},
	number={7},
	pages={1013--1027},
	year={2012}
}

@incollection{michalski1983theory,
	title={A theory and methodology of inductive learning},
	author={Michalski, Ryszard S},
	booktitle={Machine learning},
	pages={83--134},
	year={1983}
}

@article{pazzani1992utility,
	title={The utility of knowledge in inductive learning},
	author={Pazzani, Michael and Kibler, Dennis},
	journal={Machine learning},
	volume={9},
	number={1},
	pages={57--94},
	year={1992}
}

@article{de1998machine,
	title={Machine learning from examples: Inductive and Lazy methods},
	author={De Mantaras, Ramon Lopez and Armengol, Eva},
	journal={Data \& Knowledge Engineering},
	volume={25},
	number={1-2},
	pages={99--123},
	year={1998}
}

@article{tian2022comprehensive,
	title={A comprehensive survey on regularization strategies in machine learning},
	author={Tian, Yingjie and Zhang, Yuqi},
	journal={Information Fusion},
	volume={80},
	pages={146--166},
	year={2022}
}

@article{moradi2020survey,
	title={A survey of regularization strategies for deep models},
	author={Moradi, Reza and Berangi, Reza and Minaei, Behrouz},
	journal={Artificial Intelligence Review},
	volume={53},
	number={6},
	pages={3947--3986},
	year={2020}
}

@article{van2017l2,
	title={L2 regularization versus batch and weight normalization},
	author={Van Laarhoven, Twan},
	journal={arXiv:1706.05350},
	year={2017}
}

@article{gitman2017comparison,
	title={Comparison of batch normalization and weight normalization algorithms for the large-scale image classification},
	author={Gitman, Igor and Ginsburg, Boris},
	journal={arXiv:1709.08145},
	year={2017}
}

@inproceedings{ioffe2015batch,
	title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	booktitle={International Conference on Machine Learning},
	pages={448--456},
	year={2015}
}

@article{breiman1996bagging,
	title={Bagging predictors},
	author={Breiman, Leo},
	journal={Machine learning},
	volume={24},
	number={2},
	pages={123--140},
	year={1996}
}

@incollection{zhou2021ensemble,
	title={Ensemble learning},
	author={Zhou, Zhi-Hua},
	booktitle={Machine learning},
	pages={181--210},
	year={2021}
}

@article{salimans2016weight,
	title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
	author={Salimans, Tim and Kingma, Durk P},
	journal={Advances in Neural Information Processing Systems},
	volume={29},
	pages={901--909},
	year={2016}
}


@article{kilinc2018learning,
	title={Learning latent representations in neural networks for clustering through pseudo supervision and graph-based activity regularization},
	author={Kilinc, Ozsel and Uysal, Ismail},
	journal={arXiv:1802.03063},
	year={2018}
}

@article{deng2019comprehensive,
	title={Comprehensive {SNN} compression using {ADMM} optimization and activity regularization},
	author={Deng, Lei and Wu, Yujie and Hu, Yifan and Liang, Ling and Li, Guoqi and Hu, Xing and Ding, Yufei and Li, Peng and Xie, Yuan},
	journal={arXiv:1911.00822},
	year={2019}
}

@article{kilinc2018gar,
	title={{GAR}: an efficient and scalable graph-based activity regularization for semi-supervised learning},
	author={Kilinc, Ozsel and Uysal, Ismail},
	journal={Neurocomputing},
	volume={296},
	pages={46--54},
	year={2018}
}

@inproceedings{lukasik2020does,
	title={Does label smoothing mitigate label noise?},
	author={Lukasik, Michal and Bhojanapalli, Srinadh and Menon, Aditya and Kumar, Sanjiv},
	booktitle={International Conference on Machine Learning},
	pages={6448--6458},
	year={2020}
}

@article{meister2020generalized,
	title={Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing},
	author={Meister, Clara and Salesky, Elizabeth and Cotterell, Ryan},
	journal={arXiv:2005.00820},
	year={2020}
}



@article{Testingthe,
	title={Testing the Tools of Systems Neuroscience on Artificial Neural Networks},
	author={Lindsay, Grace W.},
	journal={arXiv:2202.07035},
	year={2020}
}


@inproceedings{li2020regularization,
	title={Regularization via structural label smoothing},
	author={Li, Weizhi and Dasarathy, Gautam and Berisha, Visar},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={1453--1463},
	year={2020}
}

@article{xu2020towards,
	title={Towards understanding label smoothing},
	author={Xu, Yi and Xu, Yuanhong and Qian, Qi and Li, Hao and Jin, Rong},
	journal={arXiv:2006.11653},
	year={2020}
}

@inproceedings{yuan2020revisiting,
	title={Revisiting knowledge distillation via label smoothing regularization},
	author={Yuan, Li and Tay, Francis EH and Li, Guilin and Wang, Tao and Feng, Jiashi},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={3903--3911},
	year={2020}
}


@article{hernandez2018data,
	title={Data augmentation instead of explicit regularization},
	author={Hernandez-Garcia, Alex and Konig, Peter},
	journal={arXiv:1806.03852},
	year={2018}
}

@inproceedings{srebro2005rank,
	title={Rank, trace-norm and max-norm},
	author={Srebro, Nathan and Shraibman, Adi},
	booktitle={International Conference on Computational Learning Theory},
	pages={545--560},
	year={2005}
}

@article{srivastava2014dropout,
	title={Dropout: a simple way to prevent neural networks from overfitting},
	author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={The journal of machine learning research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014}
}

@article{yao2007early,
	title={On early stopping in gradient descent learning},
	author={Yao, Yuan and Rosasco, Lorenzo and Caponnetto, Andrea},
	journal={Constructive Approximation},
	volume={26},
	number={2},
	pages={289--315},
	year={2007}
}

@article{bishop1995training,
	title={Training with noise is equivalent to {T}ikhonov regularization},
	author={Bishop, Chris M},
	journal={Neural computation},
	volume={7},
	number={1},
	pages={108--116},
	year={1995}
}

@article{vincent2010stacked,
	title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.},
	author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine and Bottou, Leon},
	journal={Journal of machine learning research},
	volume={11},
	number={12},
	year={2010}
}

@article{neelakantan2015adding,
	title={Adding gradient noise improves learning for very deep networks},
	author={Neelakantan, Arvind and Vilnis, Luke and Le, Quoc V and Sutskever, Ilya and Kaiser, Lukasz and Kurach, Karol and Martens, James},
	journal={arXiv:1511.06807},
	year={2015}
}


@article{holmstrom1992using,
	title={Using additive noise in back-propagation training},
	author={Holmstrom, Lasse and Koistinen, Petri},
	journal={IEEE Trans. on Neural Networks},
	volume={3},
	number={1},
	pages={24--38},
	year={1992}
}

@article{poole2014analyzing,
	title={Analyzing noise in autoencoders and deep networks},
	author={Poole, Ben and Sohl-Dickstein, Jascha and Ganguli, Surya},
	journal={arXiv:1406.1831},
	year={2014}
}

@inproceedings{gulcehre2016noisy,
	title={Noisy activation functions},
	author={Gulcehre, Caglar and Moczulski, Marcin and Denil, Misha and Bengio, Yoshua},
	booktitle={International Conference on Machine Learning},
	pages={3059--3068},
	year={2016}
}


@article{ruda2020ignoring,
	title={Ignoring correlated activity causes a failure of retinal population codes},
	author={Ruda, Kiersten and Zylberberg, Joel and Field, Greg D},
	journal={Nature communications},
	volume={11},
	number={1},
	pages={1--15},
	year={2020},
	publisher={Nature Publishing Group}
}

@article{averbeck2006neural,
	title={Neural correlations, population coding and computation},
	author={Averbeck, Bruno B and Latham, Peter E and Pouget, Alexandre},
	journal={Nature reviews neuroscience},
	volume={7},
	number={5},
	pages={358--366},
	year={2006},
	publisher={Nature Publishing Group}
}

@article{zylberberg2016direction,
	title={Direction-selective circuits shape noise to ensure a precise population code},
	author={Zylberberg, Joel and Cafaro, Jon and Turner, Maxwell H and Shea-Brown, Eric and Rieke, Fred},
	journal={Neuron},
	volume={89},
	number={2},
	pages={369--383},
	year={2016},
	publisher={Elsevier}
}

@article{zohary1994correlated,
	title={Correlated neuronal discharge rate and its implications for psychophysical performance},
	author={Zohary, Ehud and Shadlen, Michael N and Newsome, William T},
	journal={Nature},
	volume={370},
	number={6485},
	pages={140--143},
	year={1994},
	publisher={Nature Publishing Group}
}

@article{dan1998coding,
	title={Coding of visual information by precisely correlated spikes in the lateral geniculate nucleus},
	author={Dan, Yang and Alonso, Jose-Manuel and Usrey, W Martin and Reid, R Clay},
	journal={Nature neuroscience},
	volume={1},
	number={6},
	pages={501--507},
	year={1998},
	publisher={Nature Publishing Group}
}

@article{richards2019deep,
	title={A deep learning framework for neuroscience},
	author={Richards, Blake A and Lillicrap, Timothy P and Beaudoin, Philippe and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and Clopath, Claudia and Costa, Rui Ponte and de Berker, Archy and Ganguli, Surya and others},
	journal={Nature neuroscience},
	volume={22},
	number={11},
	pages={1761--1770},
	year={2019},
	publisher={Nature Publishing Group}
}

@article{abbott1999effect,
	title={The effect of correlated variability on the accuracy of a population code},
	author={Abbott, Larry F and Dayan, Peter},
	journal={Neural computation},
	volume={11},
	number={1},
	pages={91--101},
	year={1999},
	publisher={MIT Press}
}

@article{romo2003correlated,
	title={Correlated neuronal discharges that increase coding efficiency during perceptual discrimination},
	author={Romo, Ranulfo and Hern{\'a}ndez, Adri{\'a}n and Zainos, Antonio and Salinas, Emilio},
	journal={Neuron},
	volume={38},
	number={4},
	pages={649--657},
	year={2003},
	publisher={Elsevier}
}

@article{wu2001population,
	title={Population coding with correlation and an unfaithful model},
	author={Wu, Si and Nakahara, Hiroyuki and Amari, Shun-ichi},
	journal={Neural computation},
	volume={13},
	number={4},
	pages={775--797},
	year={2001},
	publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@InProceedings{davidrolnick,
  	author = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy P. and Wayne, Greg},
	title     = {Experience replay for continual learning},
	booktitle = {Proc. International Conference on Neural Information Processing Systems},
	year      = {2019},
	pages     = {3611-3620}
}

@article{kirhar,
	title={One-Class Classification: {A} Survey},
	author={Pramuditha Perera, Poojan Oza, Vishal M. Patel},
	journal={arXiv:2101.03064},
	year={2021}
}

@article{ManelBaradad,
	author    = {Manel Baradad, Jonas Wulff, Tongzhou Wang, Phillip Isola, Antonio Torralba},
	title     = {Learning to See by Looking at Noise},
	journal   = {arXiv:2106.05963},
	year = {2021}
}

@inproceedings{LukasSchott,
	title={Towards the first adversarially robust neural network model on mnist},
	author={Lukas Schott, Jonas Rauber, Matthias Bethge, and Wieland Brendel},
	booktitle={Proc. of International Conference on Learning Representations},
	pages={1---16},
	year={2019}
}

@inproceedings{MatthewRiemer,
	title={Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference},
	author={Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro},
	booktitle={Proc. of International Conference on Learning Representations},
	pages={1---16},
	year={2019}
}

@book{StephanLewandowsky,
	title = {Interference and Inhibition in Cognition},
	pages = {329-361},
	year = {1995},
	author = {Stephan Lewandowsky and Shu-Chen Li}
}

@inproceedings{DecebalConstantinMocanu,
	title={One-Shot Learning using Mixture of Variational Autoencoders: {A} Generalization Learning Approach},
	author={Decebal Constantin Mocanu, Elena Mocanu},
	booktitle={Proc. of International Conference on Autonomous Agents and Multiagent Systems},
	pages={1---16},
	year={2018}
}

@inproceedings{KenMcRae,
	title={Catastrophic Interference is Eliminated in Pre-Trained Networks},
	author={Ken McRae and Phil A. Hetherington},
	booktitle={Proc. of Conference of the Cognitive Science},
	pages={723---728},
	year={1993}
}

@inproceedings{LewandowskyStephan,
	title={Gradual unlearning and catastrophic interference: {A} comparison of distributed architectures},
	author={Lewandowsky Stephan},
	booktitle={Proc. of Relating Theory and Data},
	pages={445---476},
	year={1991}
}

@inproceedings{JaehongYoon,
	title={Scalable and Order-robust Continual Learning with Additive Parameter Decomposition},
	author={Jaehong Yoon, Saehoon Kim, Eunho Yang, Sung Ju Hwang},
	booktitle={Proc. of International Conference on Learning Representation},
	pages={445---476},
	year={2020}
}

@article{MarcosFCriado,
	title={Non-IID data and Continual Learning processes in Federated Learning: A long road ahead},
	author={Marcos F. Criado, Fernando E. Casado, Roberto Iglesias, Carlos V. Regueiro, Senén Barro},
	journal={arXiv:2111.13394},
	year={2021}
}

@article{lecun2006tutorial,
	title={A tutorial on energy-based learning},
	author={LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, M and Huang, F},
	journal={Predicting structured data},
	volume={1},
	number={0},
	year={2006}
}

@article{scellier2017equilibrium,
	title={Equilibrium propagation: Bridging the gap between energy-based models and backpropagation},
	author={Scellier, Benjamin and Bengio, Yoshua},
	journal={Frontiers in computational neuroscience},
	volume={11},
	pages={24},
	year={2017},
	publisher={Frontiers}
}

@inproceedings{xie2016theory,
	title={A theory of generative convnet},
	author={Xie, Jianwen and Lu, Yang and Zhu, Song-Chun and Wu, Yingnian},
	booktitle={International Conference on Machine Learning},
	pages={2635--2644},
	year={2016},
	organization={PMLR}
}

@inproceedings{nijkamp2020anatomy,
	title={On the anatomy of mcmc-based maximum likelihood learning of energy-based models},
	author={Nijkamp, Erik and Hill, Mitch and Han, Tian and Zhu, Song-Chun and Wu, Ying Nian},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={34},
	number={04},
	pages={5272--5280},
	year={2020}
}

@article{deng2020residual,
	title={Residual energy-based models for text generation},
	author={Deng, Yuntian and Bakhtin, Anton and Ott, Myle and Szlam, Arthur and Ranzato, Marc'Aurelio},
	journal={arXiv:2004.11714},
	year={2020}
}

@inproceedings{belanger2016structured,
	title={Structured prediction energy networks},
	author={Belanger, David and McCallum, Andrew},
	booktitle={International Conference on Machine Learning},
	pages={983--992},
	year={2016},
	organization={PMLR}
}

@article{tu2020engine,
	title={ENGINE: Energy-based inference networks for non-autoregressive machine translation},
	author={Tu, Lifu and Pang, Richard Yuanzhe and Wiseman, Sam and Gimpel, Kevin},
	journal={arXiv:2005.00850},
	year={2020}
}

@inproceedings{haarnoja2017reinforcement,
	title={Reinforcement learning with deep energy-based policies},
	author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
	booktitle={International Conference on Machine Learning},
	pages={1352--1361},
	year={2017},
	organization={PMLR}
}

@article{bartunov2019meta,
	title={Meta-learning deep energy-based memory models},
	author={Bartunov, Sergey and Rae, Jack W and Osindero, Simon and Lillicrap, Timothy P},
	journal={arXiv:1910.02720},
	year={2019}
}

@article{grathwohl2019your,
	title={Your classifier is secretly an energy based model and you should treat it like one},
	author={Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Jorn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
	journal={arXiv:1912.03263},
	year={2019}
}

@article{ThangDBui,
	title={Partitioned variational inference: A unified framework encompassing federated and continual learning},
	author={Thang D Bui, Cuong V Nguyen, Siddharth Swaroop, Richard E Turner},
	journal={arXiv:1811.11206 },
	year={2018}
}

@article{muller2019neural,
	title={Neural importance sampling},
	author={M{\"u}ller, Thomas and McWilliams, Brian and Rousselle, Fabrice and Gross, Markus and Nov{\'a}k, Jan},
	journal={ACM Transactions on Graphics (TOG)},
	volume={38},
	number={5},
	pages={1--19},
	year={2019},
	publisher={ACM New York, NY, USA}
}

@article{bengio2008adaptive,
	title={Adaptive importance sampling to accelerate training of a neural probabilistic language model},
	author={Bengio, Yoshua and Senecal, Jean-Sebastien},
	journal={IEEE Transactions on Neural Networks},
	volume={19},
	number={4},
	pages={713--722},
	year={2008},
	publisher={IEEE}
}

@article{katharopoulos2017biased,
	title={Biased importance sampling for deep neural network training},
	author={Katharopoulos, Angelos and Fleuret, Francois},
	journal={arXiv:1706.00043},
	year={2017}
}

@article{nori2021fast,
	title={Fast Federated Learning by Balancing Communication Trade-Offs},
	author={Nori, Milad Khademi and Yun, Sangseok and Kim, Il-Min},
	journal={IEEE Trans. on Communications},
	volume={69},
	number={8},
	pages={3521--3526},
	year={2021}
}

@article{vanschoren2018meta,
	title={Meta-learning: {A} survey},
	author={Vanschoren, Joaquin},
	journal={arXiv:1810.03548},
	year={2018}
}

@inproceedings{finn2017model,
	title={Model-agnostic meta-learning for fast adaptation of deep networks},
	author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	booktitle={Proc. of International Conference on Machine Learning},
	pages={1126--1135},
	year={2017}
}

@article{2ndPar2nd,
	title={Federated learning: Strategies for improving communication efficiency},
	author={Konecny, Jakub and McMahan, H Brendan and Yu, Felix X and Richtarik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
	journal={arXiv:1610.05492},
	year={2016}
}

@inproceedings{Vincenzo,
	title={Rehearsal-free continual learning over small non-iid batches},
	author={Vincenzo Lomonaco, Davide Maltoni, and Lorenzo Pellegrini},
	booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
	pages={989---998},
	year={2020}
}

@inproceedings{AleksanderMadry,
	title={Towards Deep Learning Models Resistant to Adversarial Attacks},
	author={Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu},
	booktitle={Proc. of International Conference on Learning Representations},
	pages={17--26},
	year={2018}
}

@inproceedings{IanJGoodfellow,
	title={Explaining and harnessing adversarial examples},
	author={Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy},
	booktitle={Proc. of International Conference on Learning Representations},
	pages={17--26},
	year={2015}
}

@article{TakashiKitamura,
	author = {Takashi Kitamura  and Sachie K. Ogawa  and Dheeraj S. Roy  and Teruhiro Okuyama  and Mark D. Morrissey  and Lillian M. Smith  and Roger L. Redondo  and Susumu Tonegawa },
	title = {Engrams and circuits crucial for systems consolidation of a memory},
	journal = {Science},
	volume = {356},
	number = {6333},
	pages = {73-78},
	year = {2017}
}

@article{AlhusseinFawzi,
	title={Analysis of classifiers’ robustness to adversarial perturbations},
	author={Alhussein Fawzi, Omar Fawzi, and Pascal Frossard},
	journal={Machine Learning},
	volume={107},
	number={3},
	pages={481---508},
	year={2018}
}

@article{vogelstein2020omnidirectional,
	title={Omnidirectional Transfer for Quasilinear Lifelong Learning},
	author={Vogelstein, Joshua T and Dey, Jayanta and Helm, Hayden S and LeVine, Will and Mehta, Ronak D and Geisa, Ali and Xu, Haoyin and van de Ven, Gido M and Chang, Emily and Gao, Chenyu and others},
	journal={arXiv:2004.12908},
	year={2020}
}

@InProceedings{YulaiCong,
	author = {Cong, Yulai and Zhao, Miaoyun and Li, Jianqiao and Wang, Sijia and Carin, Lawrence},
	title     = {{GAN} memory with no forgetting.},
	booktitle = {Proc. International Conference on Neural Information Processing Systems},
	year      = {2020},
	pages     = {2994–3003}
}

@inproceedings{icarl,
	title={{i}CaRL: Incremental classifier and representation learning},
  	author = {Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H.},
	booktitle={Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={2001–2010},
	year={2017}
}













@InProceedings{finn, 
	title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}, 
	author = {Chelsea Finn and Pieter Abbeel and Sergey Levine}, 
	booktitle = {Proc. International Conference on Machine Learning}, 
	pages = {1126--1135}, 
	year = {2017}, 
}


@article{1stPar1st,
	title={Petuum: A new platform for distributed machine learning on big data},
	author={Xing, Eric P and Ho, Qirong and Dai, Wei and Kim, Jin Kyu and Wei, Jinliang and Lee, Seunghak and Zheng, Xun and Xie, Pengtao and Kumar, Abhimanu and Yu, Yaoliang},
	journal={IEEE Trans. Big Data},
	volume={1},
	number={2},
	pages={49--67},
	month={Jun.},
	year={2015},
	publisher={IEEE}
}

@article{wang2020convergence,
	title={Convergence of edge computing and deep learning: A comprehensive survey},
	author={Wang, Xiaofei and Han, Yiwen and Leung, Victor CM and Niyato, Dusit and Yan, Xueqiang and Chen, Xu},
	journal={IEEE Communications Surveys \& Tutorials},
	volume={22},
	number={2},
	pages={869--904},
	month={Jan.},
	year={2020},
	publisher={IEEE}
}


@InProceedings{adacom,
	title={Adaptive communication strategies to achieve the best error-runtime trade-off in local-update {SGD}},
	author={Wang, Jianyu and Joshi, Gauri},
	booktitle = {Proc. Conference on Machine Learning and Systems}, 
	pages = {126--145},
	year={2019},
	volume = {1}
}


@article{1stPar2nd,
	title={Revisiting distributed synchronous {SGD}},
	author={Chen, Jianmin and Pan, Xinghao and Monga, Rajat and Bengio, Samy and Jozefowicz, Rafal},
	journal={arXiv:1604.00981},
	year={2016}
}

@article{1stPar3rd,
	title={Accurate, large minibatch {SGD}: Training {I}mage{N}et in 1 hour},
	author={Goyal, Priya and Dollar, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
	journal={arXiv:1706.02677},
	year={2017}
}

@inproceedings{2ndPar1st,
	title={Communication-efficient learning of deep networks from decentralized data},
	author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera},
	booktitle={Proc. Artificial Intelligence and Statistics},
	pages={1273--1282},
	year={2017}
}


@article{theRecentSurvey,
	title={Federated learning: Challenges, methods, and future directions},
	author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
	journal={arXiv:1908.07873},
	year={2019}
}

@inproceedings{ternGrad,
	title={Tern{G}rad: Ternary gradients to reduce communication in distributed deep learning},
	author={Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
	booktitle={Proc. Advances in Neural Information Processing Systems},
	pages={1509--1519},
	year={2017}
}


@inproceedings{qsgd,
	title={{QSGD}: Communication-efficient {SGD} via gradient quantization and encoding},
	author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
	booktitle={Proc. Advances in Neural Information Processing Systems},
	pages={1709--1720},
	year={2017}
}

@inproceedings{one,
	title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech {DNN}s},
	author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
	booktitle={Proc. International Speech Communication Association},
	year={2014},
	pages={1--8}
}

@article{quan1,
	title={Error compensated quantized {SGD} and its applications to large-scale distributed optimization},
	author={Wu, Jiaxiang and Huang, Weidong and Huang, Junzhou and Zhang, Tong},
	journal={arXiv:1806.08054},
	year={2018}
}

@inproceedings{quan2,
	title={A linear speedup analysis of distributed deep learning with sparse and quantized communication},
	author={Jiang, Peng and Agrawal, Gagan},
	booktitle={Proc. Advances in Neural Information Processing Systems},
	pages={2525--2536},
	year={2018}
}


@inproceedings{atomo,
	title={{ATOMO}: Communication-efficient learning via atomic sparsification},
	author={Wang, Hongyi and Sievert, Scott and Liu, Shengchao and Charles, Zachary and Papailiopoulos, Dimitris and Wright, Stephen},
	booktitle={Proc. Advances in Neural Information Processing Systems},
	pages={9850--9861},
	year={2018}
}


@inproceedings{dgc,
	title={Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training},
	author={Yujun Lin and Song Han and Huizi Mao and Yu Wang and Bill Dally},
	booktitle={Proc. International Conference on Learning Representations},
	pages={9850--9861},
	year={2018}
}

@INPROCEEDINGS{sbc,
	title={Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication},
	author={Felix Sattler and Simon Wiedemann and Klaus-Robert Muller and Wojciech Samek},
	booktitle={Proc. International Joint Conference on Neural Networks (IJCNN)}, 
	year={2019},
	pages={1-8}
}



@INPROCEEDINGS{amir,
	author={M. M. {Amiri} and D. {Gündüz}},
	booktitle={Proc. IEEE International Symposium on Information Theory (ISIT)}, 
	title={Machine Learning at the Wireless Edge: Distributed Stochastic Gradient Descent Over-the-Air}, 
	year={2019},
	volume={},
	number={},
	pages={1432-1436}
}

@article{rmt,
	title={Implicit self-regularization in deep neural networks: Evidence from random matrix theory and implications for learning},
	author={Martin, Charles H and Mahoney, Michael W},
	journal={arXiv:1810.01075},
	year={2018}
}

@article{local,
	title={Don't Use Large Mini-Batches, Use Local {SGD}},
	author={Lin, Tao and Stich, Sebastian U and Patel, Kumar Kshitij and Jaggi, Martin},
	journal={arXiv:1808.07217},
	year={2018}
}

@ARTICLE{noniid,
	author={F. Sattler and S. Wiedemann and K. -R. Muller and W. Samek},
	journal={IEEE Trans. Neural Networks and Learning Systems}, 
	title={Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data}, 
	year={2020},
	volume={31},
	number={9},
	pages={3400-3413},
	month={Sep.},
	publisher={IEEE}
}

@inproceedings{scafold,
	title={Scaffold: Stochastic controlled averaging for federated learning},
	author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
	booktitle={Proc. International Conference on Machine Learning},
	pages={5132--5143},
	year={2020},
}


@article{adapjsac,
	title={Adaptive federated learning in resource constrained edge computing systems},
	author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin},
	journal={IEEE J. Sel. Areas Comm.},
	volume={37},
	number={6},
	pages={1205--1221},
	year={2019},
	month={Mar.},
	publisher={IEEE}
}

@article{adaptau,
	title={On the convergence properties of a $K$-step averaging stochastic gradient descent algorithm for nonconvex optimization},
	author={Zhou, Fan and Cong, Guojing},
	journal={arXiv:1708.01012},
	year={2017}
}

@article{cooperativesgd,
	title={Cooperative {SGD}: A unified framework for the design and analysis of communication-efficient {SGD} algorithms},
	author={Wang, Jianyu and Joshi, Gauri},
	journal={arXiv:1808.07576},
	year={2018}
}

@article{matcha,
	title={{MATCHA}: Speeding Up Decentralized {SGD} via Matching Decomposition Sampling},
	author={Wang, Jianyu and Sahu, Anit Kumar and Yang, Zhouyi and Joshi, Gauri and Kar, Soummya},
	journal={arXiv:1905.09435},
	year={2019}
}

@article{tokdar2010importance,
	title={Importance sampling: a review},
	author={Tokdar, Surya T and Kass, Robert E},
	journal={Wiley Interdisciplinary Reviews: Computational Statistics},
	volume={2},
	number={1},
	pages={54--60},
	year={2010},
	publisher={Wiley Online Library}
}

@inproceedings{hammersley1956new,
	title={A new Monte Carlo technique: antithetic variates},
	author={Hammersley, JM and Morton, KW},
	booktitle={Mathematical proceedings of the Cambridge philosophical society},
	volume={52},
	number={3},
	pages={449--475},
	year={1956},
	organization={Cambridge University Press}
}


@article{hammersley1954poor,
	title={Poor man's monte carlo},
	author={Hammersley, John M and Morton, K William},
	journal={Journal of the Royal Statistical Society: Series B (Methodological)},
	volume={16},
	number={1},
	pages={23--38},
	year={1954},
	publisher={Wiley Online Library}
}

@article{bigMatrix,
	title={Why Are Big Data Matrices Approximately Low Rank?},
	author={Udell, Madeleine and Townsend, Alex},
	journal={SIAM Journal on Mathematics of Data Science},
	volume={1},
	number={1},
	pages={144--160},
	year={2019},
	publisher={SIAM},
	month={Feb.}
}


@article{eck,
	title={The approximation of one matrix by another of lower rank},
	author={Eckart, Carl and Young, Gale},
	journal={Psychometrika},
	volume={1},
	number={3},
	pages={211--218},
	year={1936},
	publisher={Springer}
}


@article{lecun2010mnist,
	title={MNIST handwritten digit database},
	author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
	year={2010}
}


@online{xiao2017,
	author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
	title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	date         = {2017-08-28},
	year         = {2017},
	eprintclass  = {cs.LG},
	eprinttype   = {arXiv},
	eprint       = {cs.LG/1708.07747},
}


@article{li2019federated,
	title={Federated learning systems: Vision, hype and reality for data privacy and protection},
	author={Li, Qinbin and Wen, Zeyi and He, Bingsheng},
	journal={arXiv:1907.09693},
	year={2019}
}

@article{qualcomm1,
	title={We are making on-device {AI} ubiquitous},
	author={Qualcomm},
	journal={https://www.qualcomm.com/news/onq/2017/08/16/we-are-making-device-ai-ubiquitous},
	year={2017}
}

@article{qualcomm2,
	title={Snapdragon 835 Mobile Platform},
	author={Qualcomm},
	journal={https://www.qualcomm.com/products/snapdragon-835-mobile-platform},
	year={2020}
}

@article{gartner,
	title={Gartner Highlights 10 Uses for {AI}-Powered Smartphones},
	author={Gartner},
	journal={https://www.gartner.com/en/newsroom/press-releases/2018-03-20-gartner-highlights-10-uses-for-ai-powered-smartphones},
	year={2018}
}


@article{yang2018applied,
	title={Applied federated learning: Improving {G}oogle keyboard query suggestions},
	author={Yang, Timothy and Andrew, Galen and Eichner, Hubert and Sun, Haicheng and Li, Wei and Kong, Nicholas and Ramage, Daniel and Beaufays, Francoise},
	journal={arXiv:1812.02903},
	year={2018}
}


@inproceedings{doku2019towards,
	title={Towards Federated Learning Approach to Determine Data Relevance in Big Data},
	author={Doku, Ronald and Rawat, Danda B and Liu, Chunmei},
	booktitle={Proc. International Conference on Information Reuse and Integration for Data Science (IRI)},
	pages={184--192},
	year={2019},
	organization={IEEE}
}

@article{pokhrel2020compound,
	title={Compound-TCP Performance for Industry 4.0 WiFi: A Cognitive Federated Learning Approach},
	author={Pokhrel, Shiva Raj and Singh, Surjit},
	journal={IEEE Trans. Industrial Informatics},
	year={2020},
	publisher={IEEE}
}

@article{imteaj2020federated,
	title={Federated Learning for Resource-Constrained IoT Devices: Panoramas and State-of-the-art},
	author={Imteaj, Ahmed and Thakker, Urmish and Wang, Shiqiang and Li, Jian and Amini, M Hadi},
	journal={arXiv:2002.10610},
	year={2020}
}

@article{zhan2020learning,
	title={A Learning-based Incentive Mechanism for Federated Learning},
	author={Zhan, Yufeng and Li, Peng and Qu, Zhihao and Zeng, Deze and Guo, Song},
	journal={IEEE Internet of Things Journal},
	year={2020},
	publisher={IEEE}
}


@article{savazzi2020federated,
	title={Federated Learning with Cooperating Devices: A Consensus Approach for Massive IoT Networks},
	author={Savazzi, Stefano and Nicoli, Monica and Rampa, Vittorio},
	journal={IEEE Internet of Things Journal},
	year={2020},
	publisher={IEEE}
}


@article{ang2020robust,
	title={Robust Federated Learning With Noisy Communication},
	author={Ang, Fan and Chen, Li and Zhao, Nan and Chen, Yunfei and Wang, Weidong and Yu, F Richard},
	journal={IEEE Trans. Communications},
	year={2020},
	publisher={IEEE}
}


@article{fallah2020personalized,
	title={Personalized federated learning: A meta-learning approach},
	author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
	journal={arXiv:2002.07948},
	year={2020}
}

@article{jin2020survey,
	title={A Survey towards Federated Semi-supervised Learning},
	author={Jin, Yilun and Wei, Xiguang and Liu, Yang and Yang, Qiang},
	journal={arXiv:2002.11545},
	year={2020}
}


@article{xie2019asynchronous,
	title={Asynchronous federated optimization},
	author={Xie, Cong and Koyejo, Sanmi and Gupta, Indranil},
	journal={arXiv:1903.03934},
	year={2019}
}


@article{fantacci2020federated,
	title={Federated learning framework for mobile edge computing networks},
	author={Fantacci, Romano and Picano, Benedetta},
	journal={CAAI Trans. Intelligence Technology},
	volume={5},
	number={1},
	pages={15--21},
	year={2020},
	publisher={IET}
}

@article{kulkarni2020survey,
	title={Survey of Personalization Techniques for Federated Learning},
	author={Kulkarni, Viraj and Kulkarni, Milind and Pant, Aniruddha},
	journal={arXiv:2003.08673},
	year={2020}
}


@inproceedings{imteaj2019distributed,
	title={Distributed sensing using smart end-user devices: pathway to federated learning for autonomous IoT},
	author={Imteaj, Ahmed and Amini, M Hadi},
	booktitle={International Conference on Computational Science and Computational Intelligence (CSCI)},
	pages={1156--1161},
	year={2019},
	organization={IEEE}
}


@inproceedings{luping2019cmfl,
	title={CMFL: Mitigating communication overhead for federated learning},
	author={Luping, WANG and Wei, WANG and Bo, LI},
	booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)},
	pages={954--964},
	year={2019},
	organization={IEEE}
}


@article{karimireddy2019scaffold,
	title={{SCAFFOLD}: Stochastic controlled averaging for on-device federated learning},
	author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
	journal={arXiv:1910.06378},
	year={2019}
}


@article{zhu2019multi,
	title={Multi-objective evolutionary federated learning},
	author={Zhu, Hangyu and Jin, Yaochu},
	journal={IEEE Trans. Neural Networks and Learning Systems},
	volume={31},
	number={4},
	pages={1310--1322},
	year={2019},
	month={Jun.},
	publisher={IEEE}
}

@inproceedings{smith2017federated,
	title={Federated multi-task learning},
	author={Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet S},
	booktitle={Proc. Advances in Neural Information Processing Systems},
	pages={4424--4434},
	year={2017}
}


@article{mohri2019agnostic,
	title={Agnostic federated learning},
	author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
	journal={arXiv:1902.00146},
	year={2019}
}


@article{wang2019edge,
	title={In-edge {AI}: Intelligentizing mobile edge computing, caching and communication by federated learning},
	author={Wang, Xiaofei and Han, Yiwen and Wang, Chenyang and Zhao, Qiyang and Chen, Xu and Chen, Min},
	journal={IEEE Network},
	volume={33},
	number={5},
	pages={156--165},
	year={2019},
	month={Sep.},
	publisher={IEEE}
}

@article{lim2019federated,
	title={Federated learning in mobile edge networks: A comprehensive survey},
	author={Lim, Wei Yang Bryan and Luong, Nguyen Cong and Hoang, Dinh Thai and Jiao, Yutao and Liang, Ying-Chang and Yang, Qiang and Niyato, Dusit and Miao, Chunyan},
	journal={arXiv:1909.11875},
	year={2019}
}

@article{yang2019federated,
	title={Federated machine learning: Concept and applications},
	author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
	journal={ACM Trans. Intelligent Systems and Technology (TIST)},
	volume={10},
	number={2},
	pages={1--19},
	year={2019},
	publisher={ACM New York, NY, USA}
}

@article{kairouz2019advances,
	title={Advances and open problems in federated learning},
	author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aurelien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
	journal={arXiv:1912.04977},
	year={2019}
}


@inproceedings{tran2019federated,
	title={Federated learning over wireless networks: Optimization model design and analysis},
	author={Tran, Nguyen H and Bao, Wei and Zomaya, Albert and NH, Nguyen Minh and Hong, Choong Seon},
	booktitle={IEEE INFOCOM 2019-IEEE Conference on Computer Communications},
	pages={1387--1395},
	year={2019},
	organization={IEEE}
}

@article{hard2018federated,
	title={Federated learning for mobile keyboard prediction},
	author={Hard, Andrew and Rao, Kanishka and Mathews, Rajiv and Ramaswamy, Swaroop and Beaufays, Francoise and Augenstein, Sean and Eichner, Hubert and Kiddon, Chloe and Ramage, Daniel},
	journal={arXiv:1811.03604},
	year={2018}
}

@article{bonawitz2019towards,
	title={Towards federated learning at scale: System design},
	author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Konecny, Jakub and Mazzocchi, Stefano and McMahan, H Brendan and others},
	journal={arXiv:1902.01046},
	year={2019}
}

@article{sattler2019robust,
	title={Robust and communication-efficient federated learning from non-iid data},
	author={Sattler, Felix and Wiedemann, Simon and Muller, Klaus-Robert and Samek, Wojciech},
	journal={IEEE Trans. Neural Networks and Learning Systems},
	year={2019},
	publisher={IEEE}
}

@article{sahu2018convergence,
	title={On the convergence of federated optimization in heterogeneous networks},
	author={Sahu, Anit Kumar and Li, Tian and Sanjabi, Maziar and Zaheer, Manzil and Talwalkar, Ameet and Smith, Virginia},
	journal={arXiv:1812.06127},
	year={2018}
}

@inproceedings{kang2019incentive,
	title={Incentive design for efficient federated learning in mobile networks: A contract theory approach},
	author={Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Yu, Han and Liang, Ying-Chang and Kim, Dong In},
	booktitle={2019 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS)},
	pages={1--5},
	year={2019},
	organization={IEEE}
}

@article{yang2020federated,
	title={Federated learning via over-the-air computation},
	author={Yang, Kai and Jiang, Tao and Shi, Yuanming and Ding, Zhi},
	journal={IEEE Trans. Wireless Communications},
	volume={19},
	number={3},
	pages={2022--2035},
	year={2020},
	publisher={IEEE}
}

@article{zeng2019energy,
	title={Energy-efficient radio resource allocation for federated edge learning},
	author={Zeng, Qunsong and Du, Yuqing and Leung, Kin K and Huang, Kaibin},
	journal={arXiv:1907.06040},
	year={2019}
}


@article{chen2019joint,
	title={A joint learning and communications framework for federated learning over wireless networks},
	author={Chen, Mingzhe and Yang, Zhaohui and Saad, Walid and Yin, Changchuan and Poor, H Vincent and Cui, Shuguang},
	journal={arXiv:1909.07972},
	year={2019}
}


@article{letaief2019roadmap,
	title={The roadmap to 6G: AI empowered wireless networks},
	author={Letaief, Khaled B and Chen, Wei and Shi, Yuanming and Zhang, Jun and Zhang, Ying-Jun Angela},
	journal={IEEE Communications Magazine},
	volume={57},
	number={8},
	pages={84--90},
	year={2019},
	publisher={IEEE}
}

@article{shi2020communication,
	title={Communication-Efficient Edge {AI}: Algorithms and Systems},
	author={Shi, Yuanming and Yang, Kai and Jiang, Tao and Zhang, Jun and Letaief, Khaled B},
	journal={arXiv:2002.09668},
	year={2020}
}

@inproceedings{agarwal2011distributed,
	title={Distributed delayed stochastic optimization},
	author={Agarwal, Alekh and Duchi, John C},
	booktitle={Proc. Advances in Neural Information Processing Systems},
	pages={873--881},
	year={2011}
}

@inproceedings{lian2015asynchronous,
	title={Asynchronous parallel stochastic gradient for nonconvex optimization},
	author={Lian, Xiangru and Huang, Yijun and Li, Yuncheng and Liu, Ji},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2737--2745},
	year={2015}
}

@inproceedings{zheng2017asynchronous,
	title={Asynchronous stochastic gradient descent with delay compensation},
	author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={4120--4129},
	year={2017},
	organization={JMLR. org}
}

@article{de2021continual,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ale{\v{s}} and Slabaugh, Gregory and Tuytelaars, Tinne},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAML)},
  volume={44},
  number={7},
  pages={3366--3385},
  year={2021},
  publisher={IEEE}
}

@article{lee2020neural,
  title={A neural dirichlet process mixture model for task-free continual learning},
  author={Lee, Soochan and Ha, Junsoo and Zhang, Dongsu and Kim, Gunhee},
  journal={Proc. International Conference on Learning Representations (ICLR)},
  pages={3987--3995},
  year={2020}
  }

@article{jin2021gradient,
  title={Gradient-based Editing of Memory Examples for Online Task-free Continual Learning},
  author={Jin, Xisen and Sadhu, Arka and Du, Junyi and Ren, Xiang},
  journal={Proc. International Conference on Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={29193--29205},
  year={2021}
}

@inproceedings{wang2022improving,
  title={Improving task-free continual learning by distributionally robust memory evolution},
  author={Wang, Zhenyi and Shen, Li and Fang, Le and Suo, Qiuling and Duan, Tiehang and Gao, Mingchen},
  booktitle={Proc. International Conference on Machine Learning (ICML)},
  pages={22985--22998},
  year={2022},
  organization={PMLR}
}

@article{shanahan2021encoders,
  title={Encoders and ensembles for task-free continual learning},
  author={Shanahan, Murray and Kaplanis, Christos and Mitrovi{\'c}, Jovana},
  journal={Proc. International Conference on Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={29193--29205},
  year={2021}
}

@article{ye2022learning,
  title={Learning an evolved mixture model for task-free continual learning},
  author={Ye, Fei and Bors, Adrian G},
  journal={arXiv:2207.05080},
  year={2022}
}

@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year={2016},
	publisher={MIT press}
}

@article{lecun2015deep,
	title={Deep learning},
	author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	journal={Nature},
	volume={521},
	number={7553},
	pages={436--444},
	year={2015},
	publisher={Nature Publishing Group}
}


@article{kim2022theoretical,
  title={A theoretical study on solving continual learning},
  author={Kim, Gyuhak and Xiao, Changnan and Konishi, Tatsuya and Ke, Zixuan and Liu, Bing},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5065--5079},
  year={2022}
}


@misc{Anonymous24,
 author = {Anonymous},
 title = {The frobnicatable foo filter},
 note = {{ECCV} submission ID 00324, supplied as supplemental material {\tt 00324.pdf}},
 year = 2024
}

@misc{Anonymous24b,
 author = {Anonymous},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2024
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@book{ECCV2022,
    editor = {Shai Avidan and Gabriel Brostow and Moustapha Cissé and Giovanni Maria Farinella and Tal Hassner},
    title = {Computer Vision -- ECCV 2022},
    year = {2022},
    publisher = {Springer},
    doi = {10.1007/978-3-031-19769-7}
}