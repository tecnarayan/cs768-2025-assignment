\begin{thebibliography}{10}

\bibitem{andriushchenko2020square}
Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, and Matthias Hein.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In {\em European Conference on Computer Vision}, pages 484--501.
  Springer, 2020.

\bibitem{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em International conference on machine learning}, pages
  274--283. PMLR, 2018.

\bibitem{athalye2018synthesizing}
Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok.
\newblock Synthesizing robust adversarial examples.
\newblock In {\em International conference on machine learning}, pages
  284--293. PMLR, 2018.

\bibitem{blau2022threat}
Tsachi Blau, Roy Ganz, Bahjat Kawar, Alex Bronstein, and Michael Elad.
\newblock Threat model-agnostic adversarial defense using diffusion models.
\newblock {\em arXiv preprint arXiv:2207.08089}, 2022.

\bibitem{cao2021invisible}
Yulong Cao, Ningfei Wang, Chaowei Xiao, Dawei Yang, Jin Fang, Ruigang Yang,
  Qi~Alfred Chen, Mingyan Liu, and Bo~Li.
\newblock Invisible for both camera and lidar: Security of multi-sensor fusion
  based perception in autonomous driving under physical-world attacks.
\newblock In {\em 2021 IEEE Symposium on Security and Privacy (SP)}, pages
  176--194. IEEE, 2021.

\bibitem{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In {\em Proceedings of the 10th ACM workshop on artificial
  intelligence and security}, pages 3--14, 2017.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. Ieee, 2017.

\bibitem{chang2018reversible}
Bo~Chang, Lili Meng, Eldad Haber, Lars Ruthotto, David Begert, and Elliot
  Holtham.
\newblock Reversible architectures for arbitrarily deep residual neural
  networks.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~32, 2018.

\bibitem{chen2016training}
Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin.
\newblock Training deep nets with sublinear memory cost.
\newblock {\em arXiv preprint arXiv:1604.06174}, 2016.

\bibitem{chen2023content}
Zhaoyu Chen, Bo~Li, Shuang Wu, Kaixun Jiang, Shouhong Ding, and Wenqiang Zhang.
\newblock Content-based unrestricted adversarial attack.
\newblock {\em arXiv preprint arXiv:2305.10665}, 2023.

\bibitem{croce2020robustbench}
Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti,
  Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock {\em arXiv preprint arXiv:2010.09670}, 2020.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em International conference on machine learning}, pages
  2206--2216. PMLR, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{devroye2018total}
Luc Devroye, Abbas Mehrabian, and Tommy Reddad.
\newblock The total variation distance between high-dimensional gaussians.
\newblock {\em arXiv preprint arXiv:1810.08693}, 2018.

\bibitem{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems},
  34:8780--8794, 2021.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{du2019implicit}
Yilun Du and Igor Mordatch.
\newblock Implicit generation and modeling with energy based models.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{eykholt2018robust}
Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo~Li, Amir Rahmati, Chaowei
  Xiao, Atul Prakash, Tadayoshi Kohno, and Dawn Song.
\newblock Robust physical-world attacks on deep learning visual classification.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1625--1634, 2018.

\bibitem{gomez2017reversible}
Aidan~N Gomez, Mengye Ren, Raquel Urtasun, and Roger~B Grosse.
\newblock The reversible residual network: Backpropagation without storing
  activations.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{gowal2021improving}
Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg,
  Dan~Andrei Calian, and Timothy~A Mann.
\newblock Improving robustness using generated data.
\newblock {\em Advances in Neural Information Processing Systems},
  34:4218--4233, 2021.

\bibitem{grathwohl2019your}
Will Grathwohl, Kuan-Chieh Wang, J{\"o}rn-Henrik Jacobsen, David Duvenaud,
  Mohammad Norouzi, and Kevin Swersky.
\newblock Your classifier is secretly an energy based model and you should
  treat it like one.
\newblock {\em arXiv preprint arXiv:1912.03263}, 2019.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hill2020stochastic}
Mitch Hill, Jonathan Mitchell, and Song-Chun Zhu.
\newblock Stochastic security: Adversarial defense using long-run dynamics of
  energy-based models.
\newblock {\em arXiv preprint arXiv:2005.13525}, 2020.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6840--6851, 2020.

\bibitem{hyvarinen2005estimation}
Aapo Hyv{\"a}rinen and Peter Dayan.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock {\em Journal of Machine Learning Research}, 6(4), 2005.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{li2020scalable}
Xuechen Li, Ting-Kam~Leonard Wong, Ricky~TQ Chen, and David Duvenaud.
\newblock Scalable gradients for stochastic differential equations.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3870--3882. PMLR, 2020.

\bibitem{ling2019deepsec}
Xiang Ling, Shouling Ji, Jiaxu Zou, Jiannan Wang, Chunming Wu, Bo~Li, and Ting
  Wang.
\newblock Deepsec: A uniform platform for security analysis of deep learning
  model.
\newblock In {\em 2019 IEEE Symposium on Security and Privacy (SP)}, pages
  673--690. IEEE, 2019.

\bibitem{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{meng2021sdedit}
Chenlin Meng, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano
  Ermon.
\newblock Sdedit: Image synthesis and editing with stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2108.01073}, 2021.

\bibitem{mosbach2018logit}
Marius Mosbach, Maksym Andriushchenko, Thomas Trost, Matthias Hein, and
  Dietrich Klakow.
\newblock Logit pairing methods can fool gradient-based attacks.
\newblock {\em arXiv preprint arXiv:1810.12042}, 2018.

\bibitem{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In {\em International Conference on Machine Learning}, pages
  8162--8171. PMLR, 2021.

\bibitem{nie2022DiffPure}
Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, and Anima
  Anandkumar.
\newblock Diffusion models for adversarial purification.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2022.

\bibitem{papernot2017practical}
Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z~Berkay Celik,
  and Ananthram Swami.
\newblock Practical black-box attacks against machine learning.
\newblock In {\em Proceedings of the 2017 ACM on Asia conference on computer
  and communications security}, pages 506--519, 2017.

\bibitem{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{pintor2021indicators}
Maura Pintor, Luca Demetrio, Angelo Sotgiu, Ambra Demontis, Nicholas Carlini,
  Battista Biggio, and Fabio Roli.
\newblock Indicators of attack failure: Debugging and improving optimization of
  adversarial examples.
\newblock {\em arXiv preprint arXiv:2106.09947}, 2021.

\bibitem{rebuffi2021fixing}
Sylvestre-Alvise Rebuffi, Sven Gowal, Dan~A Calian, Florian Stimberg, Olivia
  Wiles, and Timothy Mann.
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock {\em arXiv preprint arXiv:2103.01946}, 2021.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{saharia2022palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim
  Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In {\em ACM SIGGRAPH 2022 Conference Proceedings}, pages 1--10, 2022.

\bibitem{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily
  Denton, Seyed Kamyar~Seyed Ghasemipour, Burcu~Karagol Ayan, S~Sara Mahdavi,
  Rapha~Gontijo Lopes, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock {\em arXiv preprint arXiv:2205.11487}, 2022.

\bibitem{saharia2022image}
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David~J Fleet, and
  Mohammad Norouzi.
\newblock Image super-resolution via iterative refinement.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2022.

\bibitem{samangouei2018defense}
Pouya Samangouei, Maya Kabkab, and Rama Chellappa.
\newblock Defense-gan: Protecting classifiers against adversarial attacks using
  generative models.
\newblock {\em arXiv preprint arXiv:1805.06605}, 2018.

\bibitem{sarkka2019applied}
Simo S{\"a}rkk{\"a} and Arno Solin.
\newblock {\em Applied stochastic differential equations}, volume~10.
\newblock Cambridge University Press, 2019.

\bibitem{shi2021online}
Changhao Shi, Chester Holtz, and Gal Mishne.
\newblock Online adversarial purification based on self-supervision.
\newblock {\em arXiv preprint arXiv:2101.09387}, 2021.

\bibitem{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem{song2020sliced}
Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon.
\newblock Sliced score matching: A scalable approach to density and score
  estimation.
\newblock In {\em Uncertainty in Artificial Intelligence}, pages 574--584.
  PMLR, 2020.

\bibitem{song2017pixeldefend}
Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman.
\newblock Pixeldefend: Leveraging generative models to understand and defend
  against adversarial examples.
\newblock {\em arXiv preprint arXiv:1710.10766}, 2017.

\bibitem{song2021scorebased}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{srinivasan2021robustifying}
Vignesh Srinivasan, Csaba Rohrer, Arturo Marban, Klaus-Robert M{\"u}ller,
  Wojciech Samek, and Shinichi Nakajima.
\newblock Robustifying models against adversarial attacks by langevin dynamics.
\newblock {\em Neural Networks}, 137:1--17, 2021.

\bibitem{sun2022pointdp}
Jiachen Sun, Weili Nie, Zhiding Yu, Z~Morley Mao, and Chaowei Xiao.
\newblock Pointdp: Diffusion-driven purification against adversarial attacks on
  3d point cloud recognition.
\newblock {\em arXiv preprint arXiv:2208.09801}, 2022.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{pmlr-v80-uesato18a}
Jonathan Uesato, Brendan O'Donoghue, Pushmeet Kohli, and A{\"{a}}ron van~den
  Oord.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In {\em icml2018}, 2018.

\bibitem{wang2023decodingtrust}
Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang,
  Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et~al.
\newblock Decodingtrust: A comprehensive assessment of trustworthiness in gpt
  models.
\newblock {\em arXiv preprint arXiv:2306.11698}, 2023.

\bibitem{wang2022guided}
Jinyi Wang, Zhaoyang Lyu, Dahua Lin, Bo~Dai, and Hongfei Fu.
\newblock Guided diffusion model for adversarial purification.
\newblock {\em arXiv preprint arXiv:2205.14969}, 2022.

\bibitem{wu2022guided}
Quanlin Wu, Hang Ye, and Yuntian Gu.
\newblock Guided diffusion model for adversarial purification from random
  noise.
\newblock {\em arXiv preprint arXiv:2206.10875}, 2022.

\bibitem{xiao2022densepure}
Chaowei Xiao, Zhongzhu Chen, Kun Jin, Jiongxiao Wang, Weili Nie, Mingyan Liu,
  Anima Anandkumar, Bo~Li, and Dawn Song.
\newblock Densepure: Understanding diffusion models towards adversarial
  robustness.
\newblock {\em arXiv preprint arXiv:2211.00322}, 2022.

\bibitem{xue2023diffusion}
Haotian Xue, Alexandre Araujo, Bin Hu, and Yongxin Chen.
\newblock Diffusion-based adversarial sample generation for improved
  stealthiness and controllability.
\newblock {\em arXiv preprint arXiv:2305.16494}, 2023.

\bibitem{yao2021automated}
Chengyuan Yao, Pavol Bielik, Petar Tsankov, and Martin Vechev.
\newblock Automated discovery of adaptive attacks on adversarial defenses.
\newblock {\em Advances in Neural Information Processing Systems},
  34:26858--26870, 2021.

\bibitem{yoon2021adversarial}
Jongmin Yoon, Sung~Ju Hwang, and Juho Lee.
\newblock Adversarial purification with score-based generative models.
\newblock In {\em International Conference on Machine Learning}, pages
  12062--12072. PMLR, 2021.

\bibitem{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock {\em arXiv preprint arXiv:1605.07146}, 2016.

\bibitem{zhang2022ada3diff}
Kui Zhang, Hang Zhou, Jie Zhang, Qidong Huang, Weiming Zhang, and Nenghai Yu.
\newblock Ada3diff: Defending against 3d adversarial point clouds via adaptive
  diffusion.
\newblock {\em arXiv preprint arXiv:2211.16247}, 2022.

\end{thebibliography}
