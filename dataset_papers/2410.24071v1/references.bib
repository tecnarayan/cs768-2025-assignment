#############
# Introduction
#############

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{hambly2023recent,
  title={Recent advances in reinforcement learning in finance},
  author={Hambly, Ben and Xu, Renyuan and Yang, Huining},
  journal={Mathematical Finance},
  volume={33},
  number={3},
  pages={437--503},
  year={2023},
  publisher={Wiley Online Library}
}

@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={6},
  pages={4909--4926},
  year={2021},
  publisher={IEEE}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

###########
### LQR

@article{bemporad2002explicit,
  title={The explicit linear quadratic regulator for constrained systems},
  author={Bemporad, Alberto and Morari, Manfred and Dua, Vivek and Pistikopoulos, Efstratios N},
  journal={Automatica},
  volume={38},
  number={1},
  pages={3--20},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{abbasi2011regret,
  title={Regret bounds for the adaptive control of linear quadratic systems},
  author={Abbasi-Yadkori, Yasin and Szepesv{\'a}ri, Csaba},
  booktitle={Proceedings of the 24th Annual Conference on Learning Theory},
  pages={1--26},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{kakade2020information,
  title={Information theoretic regret bounds for online nonlinear control},
  author={Kakade, Sham and Krishnamurthy, Akshay and Lowrey, Kendall and Ohnishi, Motoya and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15312--15325},
  year={2020}
}

@article{dean2018regret,
  title={Regret bounds for robust adaptive control of the linear quadratic regulator},
  author={Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{cohen2019learning,
  title={Learning Linear-Quadratic Regulators Efficiently with only $\sqrt T$ Regret},
  author={Cohen, Alon and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={1300--1309},
  year={2019},
  organization={PMLR}
}

#################################
#### Lipschitz MDPs


@article{rachelson2010locality,
  title={On the locality of action domination in sequential decision making},
  author={Rachelson, Emmanuel and Lagoudakis, Michail G},
  journal={International Symposium on Artificial Intelligence and Mathematics},
  year={2010}
}

@inproceedings{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael},
  booktitle={International Conference on Machine Learning},
  pages={264--273},
  year={2018},
  organization={PMLR}
}

@inproceedings{damiani2022balancing,
  title={Balancing Sample Efficiency and Suboptimality in Inverse Reinforcement Learning},
  author={Damiani, Angelo and Manganini, Giorgio and Metelli, Alberto Maria and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={4618--4629},
  year={2022},
  organization={PMLR}
}

@article{pirotta2015policy,
  title={Policy gradient in lipschitz markov decision processes},
  author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
  journal={Machine Learning},
  volume={100},
  pages={255--283},
  year={2015},
  publisher={Springer}
}

@inproceedings{metelli2020control,
  title={Control frequency adaptation via action persistence in batch reinforcement learning},
  author={Metelli, Alberto Maria and Mazzolini, Flavio and Bisi, Lorenzo and Sabbioni, Luca and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={6862--6873},
  year={2020},
  organization={PMLR}
}


@inproceedings{maran2023tight,
  title={Tight performance guarantees of imitator policies with continuous actions},
  author={Maran, Davide and Metelli, Alberto Maria and Restelli, Marcello},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={9073--9080},
  year={2023}
}

@book{metelli2022exploiting,
  title={Exploiting environment configurability in reinforcement learning},
  author={Metelli, Alberto Maria},
  volume={361},
  year={2022},
  publisher={IOS Press}
}

@inproceedings{liotet2022delayed,
  title={Delayed reinforcement learning by imitation},
  author={Liotet, Pierre and Maran, Davide and Bisi, Lorenzo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={13528--13556},
  year={2022},
  organization={PMLR}
}

@article{ortner2012online,
  title={Online regret bounds for undiscounted continuous reinforcement learning},
  author={Ortner, Ronald and Ryabko, Daniil},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@inproceedings{domingues2020regret,
  title={Regret bounds for kernel-based reinforcement learning},
  author={Domingues, Omar D and M{\'e}nard, Pierre and Pirotta, Matteo and Kaufmann, Emilie and Valko, Michal},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@article{sinclair2020adaptive,
  title={Adaptive discretization for model-based reinforcement learning},
  author={Sinclair, Sean and Wang, Tianyu and Jain, Gauri and Banerjee, Siddhartha and Yu, Christina},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3858--3871},
  year={2020}
}

@article{song2019efficient,
  title={Efficient model-free reinforcement learning in metric spaces},
  author={Song, Zhao and Sun, Wen},
  journal={arXiv preprint arXiv:1905.00475},
  year={2019}
}

@article{sinclair2019adaptive,
  title={Adaptive discretization for episodic reinforcement learning in metric spaces},
  author={Sinclair, Sean R and Banerjee, Siddhartha and Yu, Christina Lee},
  journal={Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume={3},
  number={3},
  pages={1--44},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{le2021metrics,
  title={Metrics and continuity in reinforcement learning},
  author={Le Lan, Charline and Bellemare, Marc G and Castro, Pablo Samuel},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={8261--8269},
  year={2021}
}


########################
# Linear MDPs

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}



#######################
### Kernelized RL

@article{vakili2024kernelized,
  title={Kernelized Reinforcement Learning with Order Optimal Regret Bounds},
  author={Vakili, Sattar and Olkhovskaya, Julia},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{domingues2021kernel,
  title={Kernel-based reinforcement learning: A finite-time analysis},
  author={Domingues, Omar Darwiche and M{\'e}nard, Pierre and Pirotta, Matteo and Kaufmann, Emilie and Valko, Michal},
  booktitle={International Conference on Machine Learning},
  pages={2783--2792},
  year={2021},
  organization={PMLR}
}

@inproceedings{chowdhury2019online,
  title={Online learning in kernelized markov decision processes},
  author={Chowdhury, Sayak Ray and Gopalan, Aditya},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={3197--3205},
  year={2019},
  organization={PMLR}
}


@article{yang2020provably,
  title={Provably efficient reinforcement learning with kernel and neural function approximations},
  author={Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13903--13916},
  year={2020}
}

#######################
# MDPs

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}


##############
# Analysis
##############


@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{maran2024no,
  title={No-Regret Reinforcement Learning in Smooth MDPs},
  author={Maran, Davide and Metelli, Alberto Maria and Papini, Matteo and Restelli, Marcello},
  booktitle={Forty-first International Conference on Machine Learning},
  pages={34760-34789},
  year={2024},
  organization={PMLR}
}

@inproceedings{maran2024projection,
  title={Projection by Convolution: Optimal Sample Complexity for Reinforcement Learning in Continuous-Space MDPs},
  author={Maran, Davide and Metelli, Alberto Maria and Papini, Matteo and Restell, Marcello},
  booktitle={Proceedings of the 37th Annual Conference on Learning Theory},
  pages={3743-3774},
  year={2024},
  organization={PMLR}
}

@book{folland1999real,
  title={Real analysis: modern techniques and their applications},
  author={Folland, Gerald B},
  volume={40},
  year={1999},
  publisher={John Wiley \& Sons}
}


%%%%%%%%%%%%%%%%%%%%%%%
% altre Baselines
%%%%%%%%%%%%%%%%%%%%%%%


@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@inproceedings{ren2022free,
  title={A free lunch from the noise: Provable and practical exploration for representation learning},
  author={Ren, Tongzheng and Zhang, Tianjun and Szepesv{\'a}ri, Csaba and Dai, Bo},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1686--1696},
  year={2022},
  organization={PMLR}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{yang2019sample,
  author       = {Lin Yang and
                  Mengdi Wang},
  title        = {Sample-Optimal Parametric Q-Learning Using Linearly Additive Features},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {97},
  pages        = {6995--7004},
  publisher    = {{PMLR}},
  year         = {2019}
}

@inproceedings{zhang2021reinforcement,
  author       = {Zihan Zhang and
                  Xiangyang Ji and
                  Simon S. Du},
  title        = {Is Reinforcement Learning More Difficult Than Bandits? {A} Near-optimal
                  Algorithm Escaping the Curse of Horizon},
  booktitle    = {{COLT}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {134},
  pages        = {4528--4531},
  publisher    = {{PMLR}},
  year         = {2021}
}

@book{bertsekas1996stochastic,
  title={Stochastic optimal control: the discrete-time case},
  author={Bertsekas, Dimitri and Shreve, Steven E},
  volume={5},
  year={1996},
  publisher={Athena Scientific}
}


###################
# Additionals for the appendix

@book{wendland2004scattered,
  title={Scattered data approximation},
  author={Wendland, Holger},
  volume={17},
  year={2004},
  publisher={Cambridge university press}
}

@article{da2023sample,
  title={Sample Path Regularity of Gaussian Processes from the Covariance Kernel},
  author={Da Costa, Natha{\"e}l and Pf{\"o}rtner, Marvin and Da Costa, Lancelot and Hennig, Philipp},
  journal={arXiv preprint arXiv:2312.14886},
  year={2023}
}

@inproceedings{liu2021smooth,
  title={Smooth bandit optimization: generalization to holder space},
  author={Liu, Yusha and Wang, Yining and Singh, Aarti},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2206--2214},
  year={2021},
  organization={PMLR}
}

@inproceedings{janz2020bandit,
  title={Bandit optimisation of functions in the Mat{\'e}rn kernel RKHS},
  author={Janz, David and Burt, David and Gonz{\'a}lez, Javier},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2486--2495},
  year={2020},
  organization={PMLR}
}

@article{vakili2024arxiv,
  title={Kernelized Reinforcement Learning with Order Optimal Regret Bounds},
  author={Vakili, Sattar and Olkhovskaya, Julia},
  journal={arXiv preprint arXiv:2306.07745},
  year={2024}
}

@inproceedings{vakili2021information,
  title={On information gain and regret bounds in gaussian process bandits},
  author={Vakili, Sattar and Khezeli, Kia and Picheny, Victor},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={82--90},
  year={2021},
  organization={PMLR}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

