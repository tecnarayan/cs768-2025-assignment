
@article{lei2022revealing,
  title={Revealing single frame bias for video-and-language learning},
  author={Lei, Jie and Berg, Tamara L and Bansal, Mohit},
  journal={Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics},
  year={2023}
}

@article{kim2023semi,
  title={Semi-Parametric Video-Grounded Text Generation},
  author={Kim, Sungdong and Kim, Jin-Hwa and Lee, Jiyoung and Seo, Minjoon},
  journal={arXiv preprint arXiv:2301.11507},
  year={2023}
}

@inproceedings{buch2022revisiting,
  title={Revisiting the" video" in video-language understanding},
  author={Buch, Shyamal and Eyzaguirre, Crist{\'o}bal and Gaidon, Adrien and Wu, Jiajun and Fei-Fei, Li and Niebles, Juan Carlos},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2917--2927},
  year={2022}
}

@inproceedings{xiao2022video,
  title={Video graph transformer for video question answering},
  author={Xiao, Junbin and Zhou, Pan and Chua, Tat-Seng and Yan, Shuicheng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVI},
  pages={39--58},
  year={2022},
  organization={Springer}
}

@inproceedings{li2023blip,
    author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  booktitle={International conference on machine learning},
  pages={19730-19742},
  year={2023},
  organization={PMLR}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}


% Image-Languge Model
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{li2022scaling,
  title={Scaling language-image pre-training via masking},
  author={Li, Yanghao and Fan, Haoqi and Hu, Ronghang and Feichtenhofer, Christoph and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23390--23400},
  year={2023}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}

@inproceedings{cho2021unifying,
  title={Unifying vision-and-language tasks via text generation},
  author={Cho, Jaemin and Lei, Jie and Tan, Hao and Bansal, Mohit},
  booktitle={International Conference on Machine Learning},
  pages={1931--1942},
  year={2021},
  organization={PMLR}
}

@inproceedings{lu2022unified,
  title={Unified-io: A unified model for vision, language, and multi-modal tasks},
  author={Lu, Jiasen and Clark, Christopher and Zellers, Rowan and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  booktitle={ICLR},
  year={2023}
}


@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{yao2021filip,
  title={FILIP: fine-grained interactive language-image pre-training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  booktitle={ICLR},
  year={2022}
}


@inproceedings{beit3,
title={Image as a foreign language: {BEiT} pretraining for vision and vision-language tasks},
author={Wenhui Wang and Hangbo Bao and Li Dong and Johan Bjorck and Zhiliang Peng and Qiang Liu and Kriti Aggarwal and Owais Khan Mohammed and Saksham Singhal and Subhojit Som and Furu Wei},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
year={2023}
}

@article{sun2023eva,
  title={EVA-CLIP: Improved Training Techniques for CLIP at Scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}

@inproceedings{chen2019uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022},
  booktitle={NeurIPS}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={EMNLP},
  year={2019}
}


@article{
yu2022coca,
title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=Ee277P3AYC},
note={}
}

% Video-Language
@inproceedings{li2020hero,
  title={Hero: Hierarchical encoder for video+ language omni-representation pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  booktitle={ACL},
  year={2020}
}

@inproceedings{wang2022all,
  title={All in one: Exploring unified video-language pre-training},
  author={Wang, Alex Jinpeng and Ge, Yixiao and Yan, Rui and Ge, Yuying and Lin, Xudong and Cai, Guanyu and Wu, Jianping and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2203.07303},
  year={2023},
booktitle={CVPR}
}

@article{ma2023temporal,
  title={Temporal Perceiving Video-Language Pre-training},
  author={Ma, Fan and Jin, Xiaojie and Wang, Heng and Huang, Jingjia and Zhu, Linchao and Feng, Jiashi and Yang, Yi},
  journal={arXiv preprint arXiv:2301.07463},
  year={2023}
}

@inproceedings{xu2021videoclip,
  title={Videoclip: Contrastive pre-training for zero-shot video-text understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2109.14084},
  year={2021},
  booktitle={EMNLP}
}

@inproceedings{zellers2022merlot,
  title={Merlot reserve: Neural script knowledge through vision and language and sound},
  author={Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16375--16387},
  year={2022}
}

@inproceedings{wu2019multi,
  title={Multi-agent reinforcement learning based frame sampling for effective untrimmed video recognition},
  author={Wu, Wenhao and He, Dongliang and Tan, Xiao and Chen, Shifeng and Wen, Shilei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6222--6231},
  year={2019}
}

@inproceedings{fu2021violet,
  author = {Tsu-Jui Fu* and Linjie Li* and Zhe Gan and Kevin Lin and William Yang Wang and Lijuan Wang and Zicheng Liu}, 
title = {{An Empirical Study of End-to-End Video-Language Transformers with Masked Visual Modeling}}, 
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
year = {2023} 
}

@article{li2022lavender,
  title={Lavender: Unifying video-language understanding as masked language modeling},
  author={Li, Linjie and Gan, Zhe and Lin, Kevin and Lin, Chung-Ching and Liu, Zicheng and Liu, Ce and Wang, Lijuan},
  journal={arXiv preprint arXiv:2206.07160},
  year={2022}
}

@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7331--7341},
  year={2021}
}

@article{wang2022internvideo,
  title={InternVideo: General Video Foundation Models via Generative and Discriminative Learning},
  author={Wang, Yi and Li, Kunchang and Li, Yizhuo and He, Yinan and Huang, Bingkun and Zhao, Zhiyu and Zhang, Hongjie and Xu, Jilan and Liu, Yi and Wang, Zun and others},
  journal={arXiv preprint arXiv:2212.03191},
  year={2022}
}

% video-language model

@inproceedings{xu2023mplug,
  title={mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video},
  author={Xu, Haiyang and Ye, Qinghao and Yan, Ming and Shi, Yaya and Ye, Jiabo and Xu, Yuanhong and Li, Chenliang and Bi, Bin and Qian, Qi and Wang, Wei and others},
  journal={arXiv preprint arXiv:2302.00402},
  year={2023},
  booktitle={ICML}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}



@inproceedings{yang2021just,
  title={Just ask: Learning to answer questions from millions of narrated videos},
  author={Yang, Antoine and Miech, Antoine and Sivic, Josef and Laptev, Ivan and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1686--1697},
  year={2021}
}

@article{yan2022video,
  title={Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners},
  author={Yan, Shen and Zhu, Tao and Wang, Zirui and Cao, Yuan and Zhang, Mi and Ghosh, Soham and Wu, Yonghui and Yu, Jiahui},
  journal={arXiv preprint arXiv:2212.04979},
  year={2022}
}

@inproceedings{ye2022hitea,
  title={HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training},
  author={Ye, Qinghao and Xu, Guohai and Yan, Ming and Xu, Haiyang and Qian, Qi and Zhang, Ji and Huang, Fei},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{
wang2022language,
title={Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners},
author={Zhenhailong Wang and Manling Li and Ruochen Xu and Luowei Zhou and Jie Lei and Xudong Lin and Shuohang Wang and Ziyi Yang and Chenguang Zhu and Derek Hoiem and Shih-Fu Chang and Mohit Bansal and Heng Ji},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
}


@inproceedings{yang2022zero,
title = {Zero-Shot Video Question Answering via Frozen Bidirectional Language Models},
author = {Antoine Yang and Antoine Miech and Josef Sivic and Ivan Laptev and Cordelia Schmid},
booktitle={NeurIPS},
year = {2022}}

@inproceedings{wu2022promptchainer,
  title={Promptchainer: Chaining large language model prompts through visual programming},
  author={Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J},
  booktitle={CHI Conference on Human Factors in Computing Systems Extended Abstracts},
  pages={1--10},
  year={2022}
}

@article{regneri2013grounding,
  title={Grounding action descriptions in videos},
  author={Regneri, Michaela and Rohrbach, Marcus and Wetzel, Dominikus and Thater, Stefan and Schiele, Bernt and Pinkal, Manfred},
  journal={Transactions of the Association for Computational Linguistics},
  volume={1},
  pages={25--36},
  year={2013},
  publisher={MIT Press}
}

@article{tan2020vokenization,
  title={Vokenization: Improving language understanding with contextualized, visual-grounded supervision},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:2010.06775},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@InProceedings{qian2022locate,
  title={Locate before Answering: Answer Guided Question Localization for Video Question Answering},
  author={Qian, Tianwen and Cui, Ran and Chen, Jingjing and Peng, Pai and Guo, Xiaowei and Jiang, Yu-Gang},
  booktitle={IEEE transactions on multimedia},
  year={2022}
}

@InProceedings{fang2022eva,
    author    = {Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
    title     = {EVA: Exploring the Limits of Masked Visual Representation Learning at Scale},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {19358-19369}
}

@InProceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@inproceedings{ni2022expanding,
  title={Expanding language-image pretrained models for general video recognition},
  author={Ni, Bolin and Peng, Houwen and Chen, Minghao and Zhang, Songyang and Meng, Gaofeng and Fu, Jianlong and Xiang, Shiming and Ling, Haibin},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part IV},
  pages={1--18},
  year={2022},
  organization={Springer}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXIII},
  pages={709--727},
  year={2022},
  organization={Springer}
}

% seleciton method
@inproceedings{cordonnier2021differentiable,
  title={Differentiable patch selection for image recognition},
  author={Cordonnier, Jean-Baptiste and Mahendran, Aravindh and Dosovitskiy, Alexey and Weissenborn, Dirk and Uszkoreit, Jakob and Unterthiner, Thomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2351--2360},
  year={2021}
}

@inproceedings{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021},
  booktitle={NeurIPS Workshop}
}

@article{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@InProceedings{gao2022mist,
    author    = {Gao, Difei and Zhou, Luowei and Ji, Lei and Zhu, Linchao and Yang, Yi and Shou, Mike Zheng},
    title     = {MIST: Multi-Modal Iterative Spatial-Temporal Transformer for Long-Form Video Question Answering},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {14773-14783}
}

@article{mundur2006keyframe,
  title={Keyframe-based video summarization using delaunay clustering},
  author={Mundur, Padmavathi and Rao, Yong and Yesha, Yelena},
  journal={International Journal on Digital Libraries},
  volume={6},
  pages={219--232},
  year={2006},
  publisher={Springer}
}

@inproceedings{klein2008improving,
  title={Improving the agility of keyframe-based SLAM},
  author={Klein, Georg and Murray, David},
  booktitle={Computer Vision--ECCV 2008: 10th European Conference on Computer Vision, Marseille, France, October 12-18, 2008, Proceedings, Part II 10},
  pages={802--815},
  year={2008},
  organization={Springer}
}

% dataset 
@inproceedings{lei2018tvqa,
  title={TVQA: Localized, Compositional Video Question Answering},
  author={Lei, Jie and Yu, Licheng and Bansal, Mohit and Berg, Tamara L},
  booktitle={EMNLP},
  year={2018}
}


@inproceedings{wu2021star,
  title={Star: A benchmark for situated reasoning in real-world videos},
  author={Wu, Bo and Yu, Shoubin and Chen, Zhenfang and Tenenbaum, Joshua B and Gan, Chuang},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{xiao2021next,
  title={Next-qa: Next phase of question-answering to explaining temporal actions},
  author={Xiao, Junbin and Shang, Xindi and Yao, Angela and Chua, Tat-Seng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9777--9786},
  year={2021}
}

@article{lei2021detecting,
  title={Detecting moments and highlights in videos via natural language queries},
  author={Lei, Jie and Berg, Tamara L and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11846--11858},
  year={2021}
}

@inproceedings{lei2020more,
  title={What is more likely to happen next? video-and-language future event prediction},
  author={Lei, Jie and Yu, Licheng and Berg, Tamara L and Bansal, Mohit},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2020},
pages = {8769--8784},
organization={Association for Computational Linguistics}
}

@inproceedings{lee2013pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee, Dong-Hyun and others},
  booktitle={Workshop on challenges in representation learning, ICML},
  pages={896},
  year={2013}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{openai2022chatgpt,
  title={Chatgpt: Optimizing language models for dialogue},
  author={OpenAI, TB},
  journal={OpenAI},
  year={2022}
}

@article{zhu2023chatgpt,
  title={Chatgpt asks, blip-2 answers: Automatic questioning towards enriched visual descriptions},
  author={Zhu, Deyao and Chen, Jun and Haydarov, Kilichbek and Shen, Xiaoqian and Zhang, Wenxuan and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2303.06594},
  year={2023}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@inproceedings{lei2020tvr,
  title={Tvr: A large-scale dataset for video-subtitle moment retrieval},
  author={Lei, Jie and Yu, Licheng and Berg, Tamara L and Bansal, Mohit},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXI 16},
  pages={447--463},
  year={2020},
  organization={Springer}
}

@inproceedings{moon2023query,
  title={Query-dependent video representation for moment retrieval and highlight detection},
  author={Moon, WonJun and Hyun, Sangeek and Park, SangUk and Park, Dongchan and Heo, Jae-Pil},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23023--23033},
  year={2023}
}

@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5227--5237},
  year={2022}
}

@InProceedings{lin2022towards,
    author    = {Lin, Xudong and Tiwari, Simran and Huang, Shiyuan and Li, Manling and Shou, Mike Zheng and Ji, Heng and Chang, Shih-Fu},
    title     = {Towards Fast Adaptation of Pretrained Contrastive Models for Multi-Channel Video-Language Retrieval},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {14846-14855}
}


@misc{escorcia2019temporal,
  title={Temporal localization of moments in video collections with natural language},
  author={Escorcia, Victor and Soldan, Mattia and Sivic, Josef and Ghanem, Bernard and Russell, Bryan},
  year={2019},
  publisher={arXiv}
}

@InProceedings{momeni2023verbs,
    author    = {Momeni, Liliane and Caron, Mathilde and Nagrani, Arsha and Zisserman, Andrew and Schmid, Cordelia},
    title     = {Verbs in Action: Improving Verb Understanding in Video-Language Models},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {15579-15591}
}


@InProceedings{suris2023vipergpt,
  title={Vipergpt: Visual inference via python execution for reasoning},
  author={Sur{\'\i}s, D{\'\i}dac and Menon, Sachit and Vondrick, Carl},
  booktitle={ICCV},
  year={2023}
}

@ARTICLE {xiao2023contrastive,
author = {Junbin Xiao and Pan Zhou and Angela Yao and Yicong Li and Richang Hong and Shuicheng Yan and Tat Seng Chua},
journal = {IEEE Transactions on Pattern Analysis; Machine Intelligence},
title = {Contrastive Video Question Answering via Video Graph Transformer},
year = {2023},
volume = {45},
number = {11},
issn = {1939-3539},
pages = {13265-13280},
doi = {10.1109/TPAMI.2023.3292266},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov}
}

@inproceedings{cui2022video,
  title={Video Moment Retrieval from Text Queries via Single Frame Annotation},
  author={Cui, Ran and Qian, Tianwen and Peng, Pai and Daskalaki, Elena and Chen, Jingjing and Guo, Xiaowei and Sun, Huyang and Jiang, Yu-Gang},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1033--1043},
  year={2022}
}

@inproceedings{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  booktitle={Advances in neural information processing systems},
  year={2023}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{sun2019videobert,
  title={Videobert: A joint model for video and language representation learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={7464--7473},
  year={2019}
}

@article{luo2022clip4clip,
  title={CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={Neurocomputing},
  volume={508},
  pages={293--304},
  year={2022},
  publisher={Elsevier}
}

@article{fang2021clip2video,
  title={Clip2video: Mastering video-text retrieval via image clip},
  author={Fang, Han and Xiong, Pengfei and Xu, Luhui and Chen, Yu},
  journal={arXiv preprint arXiv:2106.11097},
  year={2021}
}

@inproceedings{ju2022prompting,
  title={Prompting visual-language models for efficient video understanding},
  author={Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={105--124},
  year={2022},
  organization={Springer}
}

@inproceedings{gorti2022x,
  title={X-pool: Cross-modal language-video attention for text-video retrieval},
  author={Gorti, Satya Krishna and Vouitsis, No{\"e}l and Ma, Junwei and Golestan, Keyvan and Volkovs, Maksims and Garg, Animesh and Yu, Guangwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5006--5015},
  year={2022}
}

@inproceedings{ma2022x,
  title={X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval},
  author={Ma, Yiwei and Xu, Guohai and Sun, Xiaoshuai and Yan, Ming and Zhang, Ji and Ji, Rongrong},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={638--647},
  year={2022}
}

@article{fang2022transferring,
  title={Transferring Image-CLIP to Video-Text Retrieval via Temporal Relations},
  author={Fang, Han and Xiong, Pengfei and Xu, Luhui and Luo, Wenhan},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@inproceedings{cao2022locvtp,
  title={Locvtp: Video-text pre-training for temporal localization},
  author={Cao, Meng and Yang, Tianyu and Weng, Junwu and Zhang, Can and Wang, Jue and Zou, Yuexian},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVI},
  pages={38--56},
  year={2022},
  organization={Springer}
}

@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@inproceedings{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  booktitle={ICML},
  year={2023}
}

@inproceedings{wang2022object,
  title={Object-aware video-language pre-training for retrieval},
  author={Wang, Jinpeng and Ge, Yixiao and Cai, Guanyu and Yan, Rui and Lin, Xudong and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3313--3322},
  year={2022}
}

@inproceedings{wang2022contrastive,
    title = "Contrastive Video-Language Learning with Fine-grained Frame Sampling",
    author = "Wang, Zixu  and
      Zhong, Yujie  and
      Miao, Yishu  and
      Ma, Lin  and
      Specia, Lucia",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2022",
    publisher = "Association for Computational Linguistics",
    pages = "694--705",
}

@inproceedings{
xueclip,
title={{CLIP}-ViP: Adapting Pre-trained Image-Text Model to Video-Language Alignment},
author={Hongwei Xue and Yuchong Sun and Bei Liu and Jianlong Fu and Ruihua Song and Houqiang Li and Jiebo Luo},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@inproceedings{liu2022ts2,
  title={Ts2-net: Token shift and selection transformer for text-video retrieval},
  author={Liu, Yuqi and Xiong, Pengfei and Xu, Luhui and Cao, Shengming and Jin, Qin},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIV},
  pages={319--335},
  year={2022},
  organization={Springer}
}

@inproceedings{lu2022lgdn,
    title={{LGDN}: Language-Guided Denoising Network for Video-Language Modeling},
    author={Haoyu Lu and Mingyu Ding and Nanyi Fei and Yuqi Huo and Zhiwu Lu},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
}

@inproceedings{li2023lavis,
  title={LAVIS: A one-stop library for language-vision intelligence},
  author={Li, Dongxu and Li, Junnan and Le, Hung and Wang, Guangsen and Savarese, Silvio and Hoi, Steven CH},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  pages={31--41},
  year={2023}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@inproceedings{ma2023world,
  title={World-to-Words: Grounded Open Vocabulary Acquisition through Fast Mapping in Vision-Language Models},
  author={Ma, Ziqiao and Pan, Jiayi and Chai, Joyce},
  booktitle={ACL},
  year={2023}
}


@inproceedings{wolf2019huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}


@inproceedings{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{marcel2010torchvision,
  title={Torchvision the machine-vision package of torch},
  author={Marcel, S{\'e}bastien and Rodriguez, Yann},
  booktitle={Proceedings of the 18th ACM international conference on Multimedia},
  pages={1485--1488},
  year={2010}
}

@inproceedings{deng2023large,
  title={A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition},
  author={Deng, Andong and Yang, Taojiannan and Chen, Chen},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{wang2023unified,
  title={Unified Coarse-to-Fine Alignment for Video-Text Retrieval},
  author={Wang, Ziyang and Sung, Yi-Lin and Cheng, Feng and Bertasius, Gedas and Bansal, Mohit},
  journal={arXiv preprint arXiv:2309.10091},
  year={2023},
  booktitle={ICCV}
}