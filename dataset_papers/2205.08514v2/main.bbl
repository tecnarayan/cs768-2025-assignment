\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{abadi2016deep}
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.~B., Mironov, I., Talwar, K.,
  and Zhang, L.
\newblock Deep learning with differential privacy.
\newblock In \emph{ACM SIGSAC Conference on Computer and Communications
  Security (CCS)}, 2016.

\bibitem[Alsentzer et~al.(2019)Alsentzer, Murphy, Boag, Weng, Jin, Naumann, and
  McDermott]{alsentzer2019publicly}
Alsentzer, E., Murphy, J.~R., Boag, W., Weng, W.-H., Jin, D., Naumann, T., and
  McDermott, M.
\newblock Publicly available clinical {BERT} embeddings.
\newblock \emph{arXiv preprint arXiv:1904.03323}, 2019.

\bibitem[Arpit et~al.(2017)Arpit, Jastrzebski, Ballas, Krueger, Bengio, Kanwal,
  Maharaj, Fischer, Courville, Bengio, et~al.]{arpit2017closer}
Arpit, D., Jastrzebski, S., Ballas, N., Krueger, D., Bengio, E., Kanwal, M.~S.,
  Maharaj, T., Fischer, A., Courville, A., Bengio, Y., et~al.
\newblock A closer look at memorization in deep networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Bender et~al.(2021)Bender, Gebru, McMillan-Major, and
  Shmitchell]{bender_dangers_2021}
Bender, E.~M., Gebru, T., McMillan-Major, A., and Shmitchell, S.
\newblock On the {Dangers} of {Stochastic} {Parrots}: {Can} {Language} {Models}
  {Be} {Too} {Big}?
\newblock In \emph{Proceedings of the 2021 {ACM} {Conference} on {Fairness},
  {Accountability}, and {Transparency}}, Virtual Event Canada, 2021. ACM.

\bibitem[Boenisch et~al.(2021)Boenisch, Dziedzic, Schuster, Shamsabadi,
  Shumailov, and Papernot]{boenisch2021curious}
Boenisch, F., Dziedzic, A., Schuster, R., Shamsabadi, A.~S., Shumailov, I., and
  Papernot, N.
\newblock When the curious abandon honesty: Federated learning is not private.
\newblock \emph{arXiv preprint arXiv:2112.02918}, 2021.

\bibitem[Bonawitz et~al.(2016)Bonawitz, Ivanov, Kreuter, Marcedone, McMahan,
  Patel, Ramage, Segal, and Seth]{bonawitz2016practical}
Bonawitz, K.~A., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.~B., Patel,
  S., Ramage, D., Segal, A., and Seth, K.
\newblock Practical secure aggregation for federated learning on user-held
  data.
\newblock In \emph{NIPS Workshop on Private Multi-Party Machine Learning},
  2016.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Carlini et~al.(2019)Carlini, Liu, Erlingsson, Kos, and
  Song]{carlini2019secret}
Carlini, N., Liu, C., Erlingsson, {\'U}., Kos, J., and Song, D.
\newblock The secret sharer: Evaluating and testing unintended memorization in
  neural networks.
\newblock In \emph{28th USENIX Security Symposium (USENIX Security 19)}, 2019.

\bibitem[Carlini et~al.(2021)Carlini, Tramer, Wallace, Jagielski, Herbert-Voss,
  Lee, Roberts, Brown, Song, Erlingsson, et~al.]{carlini2021extracting}
Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K.,
  Roberts, A., Brown, T., Song, D., Erlingsson, U., et~al.
\newblock Extracting training data from large language models.
\newblock In \emph{30th USENIX Security Symposium (USENIX Security 21)}, 2021.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Bahdanau, and
  Bengio]{cho2014properties}
Cho, K., van Merri{\"e}nboer, B., Bahdanau, D., and Bengio, Y.
\newblock On the properties of neural machine translation: Encoder--decoder
  approaches.
\newblock In \emph{Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics
  and Structure in Statistical Translation}, pp.\  103--111, 2014.

\bibitem[Deng et~al.(2021)Deng, Wang, Li, Wang, Shang, Liu, Rajasekaran, and
  Ding]{deng2021tag}
Deng, J., Wang, Y., Li, J., Wang, C., Shang, C., Liu, H., Rajasekaran, S., and
  Ding, C.
\newblock Tag: Gradient attack on transformer-based language models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pp.\  3600--3610, 2021.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics (NAACL)}, 2019.

\bibitem[Dimitrov et~al.(2022)Dimitrov, Balunovi{\'c}, Jovanovi{\'c}, and
  Vechev]{dimitrov2022lamp}
Dimitrov, D.~I., Balunovi{\'c}, M., Jovanovi{\'c}, N., and Vechev, M.
\newblock Lamp: Extracting text from gradients with language model priors.
\newblock \emph{arXiv preprint arXiv:2202.08827}, 2022.

\bibitem[Enthoven \& Al-Ars(2021)Enthoven and Al-Ars]{enthoven2021fidel}
Enthoven, D. and Al-Ars, Z.
\newblock Fidel: Reconstructing private training samples from weight updates in
  federated learning.
\newblock \emph{arXiv preprint arXiv:2101.00159}, 2021.

\bibitem[Fowl et~al.(2022)Fowl, Geiping, Reich, Wen, Czaja, Goldblum, and
  Goldstein]{fowl2022decepticons}
Fowl, L., Geiping, J., Reich, S., Wen, Y., Czaja, W., Goldblum, M., and
  Goldstein, T.
\newblock Decepticons: Corrupted transformers breach privacy in federated
  learning for language models.
\newblock \emph{arXiv preprint arXiv:2201.12675}, 2022.

\bibitem[Geiping et~al.(2020)Geiping, Bauermeister, Dr{\"o}ge, and
  Moeller]{geiping2020inverting}
Geiping, J., Bauermeister, H., Dr{\"o}ge, H., and Moeller, M.
\newblock Inverting gradients--how easy is it to break privacy in federated
  learning?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Gupta et~al.(2021)Gupta, Stripelis, Lam, Thompson, Ambite, and
  Ver~Steeg]{gupta2021membership}
Gupta, U., Stripelis, D., Lam, P.~K., Thompson, P., Ambite, J.~L., and
  Ver~Steeg, G.
\newblock Membership inference attacks on deep regression models for
  neuroimaging.
\newblock In \emph{Medical Imaging with Deep Learning}, pp.\  228--251. PMLR,
  2021.

\bibitem[Hard et~al.(2018)Hard, Rao, Mathews, Ramaswamy, Beaufays, Augenstein,
  Eichner, Kiddon, and Ramage]{hard2018federated}
Hard, A., Rao, K., Mathews, R., Ramaswamy, S., Beaufays, F., Augenstein, S.,
  Eichner, H., Kiddon, C., and Ramage, D.
\newblock Federated learning for mobile keyboard prediction.
\newblock \emph{arXiv preprint arXiv:1811.03604}, 2018.

\bibitem[Holtzman et~al.(2020)Holtzman, Buys, Du, Forbes, and
  Choi]{Holtzman2020The}
Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.
\newblock The curious case of neural text degeneration.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Honnibal et~al.(2020)Honnibal, Montani, Van~Landeghem, and
  Boyd]{spacy2}
Honnibal, M., Montani, I., Van~Landeghem, S., and Boyd, A.
\newblock {spaCy: Industrial-strength Natural Language Processing in Python}.
\newblock 2020.
\newblock \doi{10.5281/zenodo.1212303}.

\bibitem[Huang et~al.(2019)Huang, Altosaar, and
  Ranganath]{huang2019clinicalbert}
Huang, K., Altosaar, J., and Ranganath, R.
\newblock {ClinicalBERT}: Modeling clinical notes and predicting hospital
  readmission.
\newblock \emph{arXiv preprint arXiv:1904.05342}, 2019.

\bibitem[Huang et~al.(2020{\natexlab{a}})Huang, Song, Chen, Li, and
  Arora]{huang2020texthide}
Huang, Y., Song, Z., Chen, D., Li, K., and Arora, S.
\newblock {TextHide}: Tackling data privacy in language understanding tasks.
\newblock In \emph{Findings of EMNLP}, 2020{\natexlab{a}}.

\bibitem[Huang et~al.(2020{\natexlab{b}})Huang, Song, Li, and
  Arora]{huang2020instahide}
Huang, Y., Song, Z., Li, K., and Arora, S.
\newblock {InstaHide}: Instance-hiding schemes for private distributed
  learning.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2020{\natexlab{b}}.

\bibitem[Huang et~al.(2021)Huang, Gupta, Song, Li, and
  Arora]{huang2021evaluating}
Huang, Y., Gupta, S., Song, Z., Li, K., and Arora, S.
\newblock Evaluating gradient inversion attacks and defenses in federated
  learning.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  34, 2021.

\bibitem[Jeon et~al.(2021)Jeon, Lee, Oh, Ok, et~al.]{jeon2021gradient}
Jeon, J., Lee, K., Oh, S., Ok, J., et~al.
\newblock Gradient inversion with generative image prior.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~34, 2021.

\bibitem[Jin et~al.(2021)Jin, Chen, Hsu, Yu, and Chen]{jin2021catastrophic}
Jin, X., Chen, P.-Y., Hsu, C.-Y., Yu, C.-M., and Chen, T.
\newblock Catastrophic data leakage in vertical federated learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~34, 2021.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Klimt \& Yang(2004)Klimt and Yang]{klimt2004enron}
Klimt, B. and Yang, Y.
\newblock The enron corpus: A new dataset for email classification research.
\newblock In \emph{European Conference on Machine Learning}. Springer, 2004.

\bibitem[Kraljevic et~al.(2021)Kraljevic, Shek, Bean, Bendayan, Teo, and
  Dobson]{kraljevic2021medgpt}
Kraljevic, Z., Shek, A., Bean, D., Bendayan, R., Teo, J., and Dobson, R.
\newblock {MedGPT}: Medical concept prediction from clinical narratives.
\newblock \emph{arXiv preprint arXiv:2107.03134}, 2021.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Sahu, Talwalkar, and
  Smith]{li2020federated}
Li, T., Sahu, A.~K., Talwalkar, A., and Smith, V.
\newblock Federated learning: Challenges, methods, and future directions.
\newblock \emph{IEEE Signal Processing Magazine}, 37\penalty0 (3):\penalty0
  50--60, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2021)Li, Tramer, Liang, and Hashimoto]{li2021large}
Li, X., Tramer, F., Liang, P., and Hashimoto, T.
\newblock Large language models can be strong differentially private learners.
\newblock \emph{arXiv preprint arXiv:2110.05679}, 2021.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Rao, Solares, Hassaine, Ramakrishnan,
  Canoy, Zhu, Rahimi, and Salimi-Khorshidi]{li2020behrt}
Li, Y., Rao, S., Solares, J. R.~A., Hassaine, A., Ramakrishnan, R., Canoy, D.,
  Zhu, Y., Rahimi, K., and Salimi-Khorshidi, G.
\newblock {BEHRT}: transformer for electronic health records.
\newblock \emph{Scientific reports}, 10\penalty0 (1):\penalty0 1--12,
  2020{\natexlab{b}}.

\bibitem[Lin(2004)]{lin-2004-rouge}
Lin, C.-Y.
\newblock {ROUGE}: A package for automatic evaluation of summaries.
\newblock In \emph{Text Summarization Branches Out}, pp.\  74--81, July 2004.

\bibitem[Liu \& Miller(2020)Liu and Miller]{liu2020federated}
Liu, D. and Miller, T.
\newblock Federated pretraining and fine tuning of {BERT} using clinical notes
  from multiple silos.
\newblock \emph{arXiv preprint arXiv:2002.08562}, 2020.

\bibitem[Lyu et~al.(2020)Lyu, Yu, Ma, Sun, Zhao, Yang, and Yu]{lyu2020privacy}
Lyu, L., Yu, H., Ma, X., Sun, L., Zhao, J., Yang, Q., and Yu, P.~S.
\newblock Privacy and robustness in federated learning: Attacks and defenses.
\newblock \emph{arXiv preprint arXiv:2012.06337}, 2020.

\bibitem[Malkin et~al.(2021)Malkin, Lanka, Goel, and Jojic]{malkin2021studying}
Malkin, N., Lanka, S., Goel, P., and Jojic, N.
\newblock Studying word order through iterative shuffling.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  pp.\  10351--10366, 2021.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson,
  et~al.]{mcmahan2016communication}
McMahan, H.~B., Moore, E., Ramage, D., Hampson, S., et~al.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)}, pp.\
  1273--1282, 2017.

\bibitem[Melis et~al.(2019)Melis, Song, De~Cristofaro, and
  Shmatikov]{melis2019exploiting}
Melis, L., Song, C., De~Cristofaro, E., and Shmatikov, V.
\newblock Exploiting unintended feature leakage in collaborative learning.
\newblock In \emph{2019 IEEE Symposium on Security and Privacy (SP)}, pp.\
  691--706. IEEE, 2019.

\bibitem[Merity et~al.(2017)Merity, Xiong, Bradbury, and
  Socher]{merity2016pointer}
Merity, S., Xiong, C., Bradbury, J., and Socher, R.
\newblock Pointer sentinel mixture models.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget, Cernock{\`y}, and
  Khudanpur]{mikolov2010recurrent}
Mikolov, T., Karafi{\'a}t, M., Burget, L., Cernock{\`y}, J., and Khudanpur, S.
\newblock Recurrent neural network based language model.
\newblock In \emph{Annual Conference of the International Speech Communication
  Association (INTERSPEECH)}, volume~2, pp.\  1045--1048. Makuhari, 2010.

\bibitem[Phong et~al.(2018)Phong, Aono, Hayashi, Wang, and Moriai]{phong18}
Phong, L.~T., Aono, Y., Hayashi, T., Wang, L., and Moriai, S.
\newblock Privacy-preserving deep learning via additively homomorphic
  encryption.
\newblock \emph{IEEE Transactions on Information Forensics and Security}, 2018.

\bibitem[Pustozerova \& Mayer(2020)Pustozerova and
  Mayer]{pustozerova2020information}
Pustozerova, A. and Mayer, R.
\newblock Information leaks in federated learning.
\newblock In \emph{Proceedings of the Network and Distributed System Security
  Symposium}, volume~10, 2020.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.
\newblock Improving language understanding by generative pre-training.
\newblock Technical report, OpenAI, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Reddy et~al.(1977)]{reddy1977speech}
Reddy, D.~R. et~al.
\newblock Speech understanding systems: A summary of results of the five-year
  research effort.
\newblock \emph{Department of Computer Science. Camegie-Mell University,
  Pittsburgh, PA}, 17:\penalty0 138, 1977.

\bibitem[Russell \& Norvig(2010)Russell and Norvig]{russell2002artificial}
Russell, S. and Norvig, P.
\newblock \emph{Artificial Intelligence: A Modern Approach}.
\newblock Prentice Hall, 3 edition, 2010.

\bibitem[Song \& Raghunathan(2020)Song and Raghunathan]{song2020information}
Song, C. and Raghunathan, A.
\newblock Information leakage in embedding models.
\newblock In \emph{ACM SIGSAC Conference on Computer and Communications
  Security (CCS)}, 2020.

\bibitem[Thakkar et~al.(2021)Thakkar, Ramaswamy, Mathews, and
  Beaufays]{thakkar2020understanding}
Thakkar, O., Ramaswamy, S., Mathews, R., and Beaufays, F.
\newblock Understanding unintended memorization in federated learning.
\newblock In \emph{Proceedings of the Third Workshop on Privacy in Natural
  Language Processing}, pp.\  1--10, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Vijayakumar et~al.(2016)Vijayakumar, Cogswell, Selvaraju, Sun, Lee,
  Crandall, and Batra]{vijayakumar2016diverse}
Vijayakumar, A.~K., Cogswell, M., Selvaraju, R.~R., Sun, Q., Lee, S., Crandall,
  D., and Batra, D.
\newblock Diverse beam search: Decoding diverse solutions from neural sequence
  models.
\newblock \emph{arXiv preprint arXiv:1610.02424}, 2016.

\bibitem[Wainakh et~al.(2021)Wainakh, Ventola, M{\"u}{\ss}ig, Keim, Cordero,
  Zimmer, Grube, Kersting, and M{\"u}hlh{\"a}user]{wainakh2021user}
Wainakh, A., Ventola, F., M{\"u}{\ss}ig, T., Keim, J., Cordero, C.~G., Zimmer,
  E., Grube, T., Kersting, K., and M{\"u}hlh{\"a}user, M.
\newblock User label leakage from gradients in federated learning.
\newblock \emph{arXiv preprint arXiv:2105.09369}, 2021.

\bibitem[Yin et~al.(2021)Yin, Mallya, Vahdat, Alvarez, Kautz, and
  Molchanov]{yin2021see}
Yin, H., Mallya, A., Vahdat, A., Alvarez, J.~M., Kautz, J., and Molchanov, P.
\newblock See through gradients: Image batch recovery via gradinversion.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2021.

\bibitem[Yu et~al.(2021)Yu, Naik, Backurs, Gopi, Inan, Kamath, Kulkarni, Lee,
  Manoel, Wutschitz, et~al.]{yu2021differentially}
Yu, D., Naik, S., Backurs, A., Gopi, S., Inan, H.~A., Kamath, G., Kulkarni, J.,
  Lee, Y.~T., Manoel, A., Wutschitz, L., et~al.
\newblock Differentially private fine-tuning of language models.
\newblock \emph{arXiv preprint arXiv:2110.06500}, 2021.

\bibitem[Zanella-B{\'e}guelin et~al.(2020)Zanella-B{\'e}guelin, Wutschitz,
  Tople, R{\"u}hle, Paverd, Ohrimenko, K{\"o}pf, and
  Brockschmidt]{zanella2020analyzing}
Zanella-B{\'e}guelin, S., Wutschitz, L., Tople, S., R{\"u}hle, V., Paverd, A.,
  Ohrimenko, O., K{\"o}pf, B., and Brockschmidt, M.
\newblock Analyzing information leakage of updates to natural language models.
\newblock In \emph{ACM SIGSAC Conference on Computer and Communications
  Security (CCS)}, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock {mixup}: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Zhao et~al.(2020)Zhao, Mopuri, and Bilen]{zhao2020idlg}
Zhao, B., Mopuri, K.~R., and Bilen, H.
\newblock {iDLG}: Improved deep leakage from gradients.
\newblock \emph{arXiv preprint arXiv:2001.02610}, 2020.

\bibitem[Zhu \& Blaschko(2021)Zhu and Blaschko]{zhu2021r}
Zhu, J. and Blaschko, M.~B.
\newblock R-gap: Recursive gradient attack on privacy.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Zhu et~al.(2019)Zhu, Liu, and Han]{zhu2020deep}
Zhu, L., Liu, Z., and Han, S.
\newblock Deep leakage from gradients.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\end{thebibliography}
