@inproceedings{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  booktitle={International Conference on Machine Learning},
  pages={244--253},
  year={2018},
  organization={PMLR}
}

@inproceedings{agarwal2017finding,
  title={Finding approximate local minima faster than gradient descent},
  author={Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1195--1199},
  year={2017}
}

@MISC{Hazan_approximatingquadratic,
    author = {Elad Hazan and Satyen Kale},
    title = {Approximating Quadratic Programs with Positive Semidefinite Constraints},
    year = {2015}
}

@article{JMLR:v15:shamir14a,
  author  = {Ohad Shamir and Shai Shalev-Shwartz},
  title   = {Matrix Completion with the Trace Norm: Learning, Bounding, and Transducing},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {98},
  pages   = {3401-3423},
  url     = {http://jmlr.org/papers/v15/shamir14a.html}
}

@inproceedings{hazan2012near,
  title={Near-optimal algorithms for online matrix prediction},
  author={Hazan, Elad and Kale, Satyen and Shalev-Shwartz, Shai},
  booktitle={Conference on Learning Theory},
  pages={38--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}

@misc{hazan2021boosting,
    title={Boosting for Online Convex Optimization},
    author={Elad Hazan and Karan Singh},
    year={2021},
    eprint={2102.09305},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{hazan2020nonstochastic,
  title={The nonstochastic control problem},
  author={Hazan, Elad and Kakade, Sham and Singh, Karan},
  booktitle={Algorithmic Learning Theory},
  pages={408--421},
  year={2020},
  organization={PMLR}
}

@article{chen2020black,
  title={Black-box control for linear dynamical systems},
  author={Chen, Xinyi and Hazan, Elad},
  journal={arXiv preprint arXiv:2007.06650},
  year={2020}
}

@article{faradonbeh2018finite,
  title={Finite-time adaptive stabilization of linear systems},
  author={Faradonbeh, Mohamad Kazem Shirani and Tewari, Ambuj and Michailidis, George},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={8},
  pages={3498--3505},
  year={2018},
  publisher={IEEE}
}

@inproceedings{simchowitz2019learning,
  title={Learning linear dynamical systems with semi-parametric least squares},
  author={Simchowitz, Max and Boczar, Ross and Recht, Benjamin},
  booktitle={Conference on Learning Theory},
  pages={2714--2802},
  year={2019},
  organization={PMLR}
}

@article{amid2020reparameterizing,
  title={Reparameterizing mirror descent as gradient descent},
  author={Amid, Ehsan and Warmuth, Manfred KK},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8430--8439},
  year={2020}
}

@inproceedings{amid2020winnowing,
  title={Winnowing with gradient descent},
  author={Amid, Ehsan and Warmuth, Manfred K},
  booktitle={Conference on Learning Theory},
  pages={163--182},
  year={2020},
  organization={PMLR}
}

@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={Proceedings of the 20th international conference on machine learning (icml-03)},
  pages={928--936},
  year={2003}
}

@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM}
}

@inproceedings{jin2017escape,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={International Conference on Machine Learning},
  pages={1724--1732},
  year={2017},
  organization={PMLR}
}

@inproceedings{lee2016gradient,
  title={Gradient descent only converges to minimizers},
  author={Lee, Jason D and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  booktitle={Conference on learning theory},
  pages={1246--1257},
  year={2016},
  organization={PMLR}
}

@article{bauschke2017descent,
  title={A descent lemma beyond Lipschitz gradient continuity: first-order methods revisited and applications},
  author={Bauschke, Heinz H and Bolte, J{\'e}r{\^o}me and Teboulle, Marc},
  journal={Mathematics of Operations Research},
  volume={42},
  number={2},
  pages={330--348},
  year={2017},
  publisher={Informs}
}

@inproceedings{hazan2017efficient,
  title={Efficient regret minimization in non-convex games},
  author={Hazan, Elad and Singh, Karan and Zhang, Cyril},
  booktitle={International Conference on Machine Learning},
  pages={1433--1441},
  year={2017},
  organization={PMLR}
}

@article{nemirovskij1983problem,
  title={Problem complexity and method efficiency in optimization},
  author={Nemirovskij, Arkadij Semenovi{\v{c}} and Yudin, David Borisovich},
  year={1983},
  journal = {SIAM Review},
  publisher={Wiley-Interscience}
}



@article{srebro2011universality,
  title={On the universality of online mirror descent},
  author={Srebro, Nati and Sridharan, Karthik and Tewari, Ambuj},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{gunasekar2021mirrorless,
  title={Mirrorless mirror descent: A natural derivation of mirror descent},
  author={Gunasekar, Suriya and Woodworth, Blake and Srebro, Nathan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2305--2313},
  year={2021},
  organization={PMLR}
}
















 
@inproceedings{yehudai2019power,
	author = {Yehudai, Gilad and Shamir, Ohad},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {On the Power and Limitations of Random Features for Understanding Neural Networks},
	url = {https://proceedings.neurips.cc/paper/2019/file/5481b2f34a74e427a2818014b8e103b0-Paper.pdf},
	volume = {32},
	year = {2019},
}



@InProceedings{malach2021connection,
  title = 	 {The Connection Between Approximation, Depth Separation and Learnability in Neural Networks},
  author =       {Malach, Eran and Yehudai, Gilad and Shalev-Schwartz, Shai and Shamir, Ohad},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory},
  pages = 	 {3265--3295},
  year = 	 {2021},
  editor = 	 {Belkin, Mikhail and Kpotufe, Samory},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--19 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v134/malach21a/malach21a.pdf},
  url = 	 {https://proceedings.mlr.press/v134/malach21a.html},
}

@article{minasyan2021online,
  title={Online Control of Unknown Time-Varying Dynamical Systems},
  author={Minasyan, Edgar and Gradu, Paula and Simchowitz, Max and Hazan, Elad},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{massart,
	author = {B. Laurent and P. Massart},
	doi = {10.1214/aos/1015957395},
	journal = {The Annals of Statistics},
	keywords = {$l_p$-bodies, adaptive estimation, Besov bodies, efficient estimation, Gaussian sequence model, Model selection, quadratic functionals},
	number = {5},
	pages = {1302 -- 1338},
	publisher = {Institute of Mathematical Statistics},
	title = {{Adaptive estimation of a quadratic functional by model selection}},
	url = {https://doi.org/10.1214/aos/1015957395},
	volume = {28},
	year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1214/aos/1015957395}}


@article{rajeswaran2017towards,
  title={Towards generalization and simplicity in continuous control},
  author={Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel and Kakade, Sham},
  journal={arXiv preprint arXiv:1703.02660},
  year={2017}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{lillicrap2016continuous,
  title={Continuous control with deep reinforcement learning.},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle={ICLR (Poster)},
  year={2016}
}
@book{vershynin_2018, place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={High-Dimensional Probability: An Introduction with Applications in Data Science}, DOI={10.1017/9781108231596}, publisher={Cambridge University Press}, author={Vershynin, Roman}, year={2018}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}

@incollection{LEWIS1997161,
	address = {San Diego},
	author = {F.L. Lewis and S. Jagannathan and A. Ye{\c s}ildirek},
	booktitle = {Neural Systems for Control},
	doi = {https://doi.org/10.1016/B978-012526430-3/50008-8},
	editor = {Omid Omidvar and David L. Elliott},
	isbn = {978-0-12-526430-3},
	pages = {161-211},
	year = 1997,
	publisher = {Academic Press},
	title = {Chapter 7 - Neural Network Control of Robot Arms and Nonlinear Systems}}


@article{yang2021neural,
  title={Neural Network Controller for Autonomous Pile Loading Revised},
  author={Yang, Wenyan and Strokina, Nataliya and Serbenyuk, Nikolay and Pajarinen, Joni and Ghabcheloo, Reza and Vihonen, Juho and Aref, Mohammad M and K{\"a}m{\"a}r{\"a}inen, Joni-Kristian},
  journal={arXiv preprint arXiv:2103.12379},
  year={2021}
}

@inproceedings{simchowitzmaking,
	author = {Simchowitz, Max},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {18318--18329},
	publisher = {Curran Associates, Inc.},
	title = {Making Non-Stochastic Control (Almost) as Easy as Stochastic},
	volume = {33},
	year = {2020}}


@article{blondel2000survey,
  title={A survey of computational complexity results in systems and control},
  author={Blondel, Vincent D and Tsitsiklis, John N},
  journal={Automatica},
  volume={36},
  number={9},
  pages={1249--1274},
  year={2000},
  publisher={Elsevier}
}

@inproceedings{bansal2017hamilton,
  title={Hamilton-Jacobi reachability: A brief overview and recent advances},
  author={Bansal, Somil and Chen, Mo and Herbert, Sylvia and Tomlin, Claire J},
  booktitle={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  pages={2242--2253},
  year={2017},
  organization={IEEE}
}

@book{moore2012iterative,
  title={Iterative learning control for deterministic systems},
  author={Moore, Kevin L},
  year={2012},
  publisher={Springer Science \& Business Media}
}


@article{clancy,
author = {Rowley, Clarence W. and Dawson, Scott T.M.},
title = {Model Reduction for Flow Analysis and Control},
journal = {Annual Review of Fluid Mechanics},
volume = {49},
number = {1},
pages = {387-417},
year = {2017},
}

@misc{simchowitz2020improper,
    title={Improper Learning for Non-Stochastic Control},
    author={Max Simchowitz and Karan Singh and Elad Hazan},
    year={2020},
    eprint={2001.09254},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{majumdar2020recent,
  title={Recent scalability improvements for semidefinite programming with applications in machine learning, control, and robotics},
  author={Majumdar, Anirudha and Hall, Georgina and Ahmadi, Amir Ali},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={3},
  pages={331--360},
  year={2020},
  publisher={Annual Reviews}
}

@inproceedings{todorov2005generalized,
  title={A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems},
  author={Todorov, Emanuel and Li, Weiwei},
  booktitle={Proceedings of the 2005, American Control Conference, 2005.},
  pages={300--306},
  year={2005},
  organization={IEEE}
}

@article{Koopmanism,
   title={Applied Koopmanism},
   volume={22},
   number={4},
   journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
   publisher={AIP Publishing},
   author={Budisic, Marko and Mohr, Ryan and Mezic, Igor},
   year={2012},
   month={Dec},
}

@article{westenbroek2021stability,
  title={On the stability of nonlinear receding horizon control: a geometric perspective},
  author={Westenbroek, Tyler and Simchowitz, Max and Jordan, Michael I and Sastry, S Shankar},
  journal={arXiv preprint arXiv:2103.15010},
  year={2021}
}

@article{ahn2007ilc,
  author={Ahn, Hyo-Sung and Chen, YangQuan and Moore, Kevin L.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={Iterative Learning Control: Brief Survey and Categorization}, 
  year={2007},
  volume={37},
  number={6},
  pages={1099-1121},
  doi={10.1109/TSMCC.2007.905759}}

@article{wei2019regularization,
	title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
	author={Wei, Colin and Lee, Jason and Liu, Qiang and Ma, Tengyu},
	year={2019}
}

@article{montanari2020interpolation,
	title={The interpolation phase transition in neural networks: Memorization and generalization under lazy training},
	author={Montanari, Andrea and Zhong, Yiqiao},
	journal={arXiv preprint arXiv:2007.12826},
	year={2020}
}

@inproceedings{ghai2020exponentiated,
  title={Exponentiated gradient meets gradient descent},
  author={Ghai, Udaya and Hazan, Elad and Singer, Yoram},
  booktitle={Algorithmic Learning Theory},
  pages={386--407},
  year={2020},
  organization={PMLR}
}


@article{bai2019beyond,
	title={Beyond linearization: On quadratic and higher-order approximation of wide neural networks},
	author={Bai, Yu and Lee, Jason D},
	journal={arXiv preprint arXiv:1910.01619},
	year={2019}
}



@inproceedings{wang2021modular,
	title={A Modular Analysis of Provable Acceleration via Polyak’s Momentum: Training a Wide ReLU Network and a Deep Linear Network},
	author={Wang, Jun-Kun and Lin, Chi-Heng and Abernethy, Jacob D},
	booktitle={International Conference on Machine Learning},
	pages={10816--10827},
	year={2021},
	organization={PMLR}
}

@article{cai2019gram,
	title={Gram-gauss-newton method: Learning overparameterized neural networks for regression problems},
	author={Cai, Tianle and Gao, Ruiqi and Hou, Jikai and Chen, Siyu and Wang, Dong and He, Di and Zhang, Zhihua and Wang, Liwei},
	journal={arXiv preprint arXiv:1905.11675},
	year={2019}
}

@article{wu2019global,
	title={Global convergence of adaptive gradient methods for an over-parameterized neural network},
	author={Wu, Xiaoxia and Du, Simon S and Ward, Rachel},
	journal={arXiv preprint arXiv:1902.07111},
	year={2019}
}

@article{wu2021adaloss,
	title={AdaLoss: A computationally-efficient and provably convergent adaptive gradient method},
	author={Wu, Xiaoxia and Xie, Yuege and Du, Simon and Ward, Rachel},
	journal={arXiv preprint arXiv:2109.08282},
	year={2021}
}

@InProceedings{hazan2019nonstochastic,
  title =    {The Nonstochastic Control Problem},
  author =   {Hazan, Elad and Kakade, Sham and Singh, Karan},
  booktitle =    {Proceedings of the 31st International Conference  on Algorithmic Learning Theory},
  pages =    {408--421},
  year =   {2020},
  publisher =    {PMLR}
  }

@inproceedings{
bubeck2021a,
title={A Universal Law of Robustness via Isoperimetry},
author={Sebastien Bubeck and Mark Sellke},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=z71OSKqTFh7}
}

@misc{hazan2021tutorial,
  author        = {Elad Hazan and Karan Singh},
  title         = {Tutorial: online and non-stochastic control},
  month         = {July},
  year          = {2021},
  publisher={Thirty-eighth International Conference on Machine Learning}
}

@article{gradu2020adaptive,
  title={Adaptive regret for control of time-varying dynamics},
  author={Gradu, Paula and Hazan, Elad and Minasyan, Edgar},
  journal={arXiv preprint arXiv:2007.04393},
  year={2020}
}

@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}

@inbook{inductivebias,
author = {Bietti, Alberto and Mairal, Julien},
title = {On the Inductive Bias of Neural Tangent Kernels},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1155},
numpages = {12}
}

@inproceedings{abbasi2011regret,
  title={Regret bounds for the adaptive control of linear quadratic systems},
  author={Abbasi-Yadkori, Yasin and Szepesv{\'a}ri, Csaba},
  booktitle={Proceedings of the 24th Annual Conference on Learning Theory},
  pages={1--26},
  year={2011}
}

@inproceedings{dean2018regret,
  title={Regret bounds for robust adaptive control of the linear quadratic regulator},
  author={Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4188--4197},
  year={2018}
}

@inproceedings{mania2019certainty,
  title={Certainty equivalence is efficient for linear quadratic control},
  author={Mania, Horia and Tu, Stephen and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10154--10164},
  year={2019}
}

@inproceedings{cohen2019learning,
  title={Learning Linear-Quadratic Regulators Efficiently with only $\sqrt{T}$ Regret},
  author={Cohen, Alon and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={1300--1309},
  year={2019}
}

@inproceedings{simchowitz2020naive,
  title={Naive exploration is optimal for online lqr},
  author={Simchowitz, Max and Foster, Dylan},
  booktitle={International Conference on Machine Learning},
  pages={8937--8948},
  year={2020},
  organization={PMLR}
}

@inproceedings{agarwal2019online,
  title={Online Control with Adversarial Disturbances},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad and Kakade, Sham and Singh, Karan},
  booktitle={International Conference on Machine Learning},
  pages={111--119},
  year={2019}
}

@article{hazan2019introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={arXiv preprint arXiv:1909.05207},
  year={2019}
} 

@inproceedings{kakade2020information,
 author = {Kakade, Sham and Krishnamurthy, Akshay and Lowrey, Kendall and Ohnishi, Motoya and Sun, Wen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {15312--15325},
 publisher = {Curran Associates, Inc.},
 title = {Information Theoretic Regret Bounds for Online Nonlinear Control},
 url = {https://proceedings.neurips.cc/paper/2020/file/aee5620fa0432e528275b8668581d9a8-Paper.pdf},
 volume = {33},
 year = {2020}
}
@misc{jacot2020neural,
      title={Neural Tangent Kernel: Convergence and Generalization in Neural Networks}, 
      author={Arthur Jacot and Franck Gabriel and Clément Hongler},
      year={2020},
      eprint={1806.07572},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{mania2020active,
  title={Active learning for nonlinear system identification with guarantees},
  author={Mania, Horia and Jordan, Michael I and Recht, Benjamin},
  journal={arXiv preprint arXiv:2006.10277},
  year={2020}
}

@misc{gao2019convergence,
      title={Convergence of Adversarial Training in Overparametrized Neural Networks}, 
      author={Ruiqi Gao and Tianle Cai and Haochuan Li and Liwei Wang and Cho-Jui Hsieh and Jason D. Lee},
      year={2019},
      eprint={1906.07916},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{allenzhu2019convergence,
      title={A Convergence Theory for Deep Learning via Over-Parameterization}, 
      author={Zeyuan Allen-Zhu and Yuanzhi Li and Zhao Song},
      year={2019},
      eprint={1811.03962},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{cao2019generalization,
	title={Generalization bounds of stochastic gradient descent for wide and deep neural networks},
	author={Cao, Yuan and Gu, Quanquan},
	journal={Advances in Neural Information Processing Systems},
	volume={32},
	pages={10836--10846},
	year={2019}
}

@article{du2018gradient_deep,
	title={Gradient descent finds global minima of deep neural networks},
	author={Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	journal={arXiv preprint arXiv:1811.03804},
	year={2018}
}

@article{arora2019fine,
	title={Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks},
	author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
	journal={arXiv preprint arXiv:1901.08584},
	year={2019}
}

@article{chizat2018note,
	title={A Note on Lazy Training in Supervised Differentiable Programming},
	author={Chizat, Lenaic and Bach, Francis},
	journal={arXiv preprint arXiv:1812.07956},
	year={2018}
}

@article{jacot2018neural,
	title={Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
	author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	journal={arXiv preprint arXiv:1806.07572},
	year={2018}
}

@article{zou2018stochastic,
	title={Stochastic Gradient Descent Optimizes Over-parameterized Deep {ReLU} Networks},
	author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
	journal={arXiv preprint arXiv:1811.08888},
	year={2018}
}

@article{du2018gradient,
	title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
	author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
	journal={arXiv preprint arXiv:1810.02054},
	year={2018}
}

@article{wei2018margin,
	title={On the Margin Theory of Feedforward Neural Networks},
	author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
	journal={arXiv preprint arXiv:1810.05369},
	year={2018}
}

@article{soltanolkotabi2018theoretical,
	title={Theoretical insights into the optimization landscape of over-parameterized shallow neural networks},
	author={Soltanolkotabi, Mahdi and Javanmard, Adel and Lee, Jason D},
	journal={IEEE Transactions on Information Theory},
	year={2018},
	publisher={IEEE}
}

@misc{ji2020polylogarithmic,
	title={Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks}, 
	author={Ziwei Ji and Matus Telgarsky},
	year={2020},
	eprint={1909.12292},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{zhang2020overparameterized,
	title={Over-parameterized Adversarial Training: An Analysis Overcoming the Curse of Dimensionality}, 
	author={Yi Zhang and Orestis Plevrakis and Simon S. Du and Xingguo Li and Zhao Song and Sanjeev Arora},
	year={2020},
	eprint={2002.06668},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{li2018learning,
	title={Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data},
	author={Li, Yuanzhi and Liang, Yingyu},
	journal={arXiv preprint arXiv:1808.01204},
	year={2018}
}

@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018},
  publisher={MIT press}
}


@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@book{vapnik1999nature,
  title={The nature of statistical learning theory},
  author={Vapnik, Vladimir},
  year={1999},
  publisher={Springer science \& business media}
}


@article{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{JMLR:v6:tsuda05a,
  author  = {Koji Tsuda and Gunnar R{{\"a}}tsch and Manfred K. Warmuth},
  title   = {Matrix Exponentiated Gradient Updates for On-line Learning and Bregman Projection},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {34},
  pages   = {995-1018},
  url     = {http://jmlr.org/papers/v6/tsuda05a.html}
}

@inproceedings{usmanova2021fast,
  title={Fast Projection Onto Convex Smooth Constraints},
  author={Usmanova, Ilnura and Kamgarpour, Maryam and Krause, Andreas and Levy, Kfir},
  booktitle={International Conference on Machine Learning},
  pages={10476--10486},
  year={2021},
  organization={PMLR}
}


@inproceedings{FKM,
author = {Flaxman, Abraham D. and Kalai, Adam Tauman and McMahan, H. Brendan},
title = {Online Convex Optimization in the Bandit Setting: Gradient Descent without a Gradient},
year = {2005},
isbn = {0898715857},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
booktitle = {Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {385–394},
numpages = {10},
location = {Vancouver, British Columbia},
series = {SODA '05}
}

@inproceedings{abernethy2008competing,
  title={Competing in the dark: An efficient algorithm for bandit linear optimization},
  author={Abernethy, Jacob and Hazan, Elad E and Rakhlin, Alexander},
  booktitle={21st Annual Conference on Learning Theory, COLT 2008},
  pages={263--273},
  year={2008}
}

	
@article{amid2019robust,
  title={Robust bi-tempered logistic loss based on bregman divergences},
  author={Amid, Ehsan and Warmuth, Manfred KK and Anil, Rohan and Koren, Tomer},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{laurent2018deep,
  title={Deep linear networks with arbitrary loss: All local minima are global},
  author={Laurent, Thomas and Brecht, James},
  booktitle={International conference on machine learning},
  pages={2902--2907},
  year={2018},
  organization={PMLR}
}

@article{kawaguchi2016deep,
  title={Deep learning without poor local minima},
  author={Kawaguchi, Kenji},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{OGD,
author = {Zinkevich, Martin},
title = {Online Convex Programming and Generalized Infinitesimal Gradient Ascent},
year = {2003},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {928–935},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML'03}
}

@article{arora2012multiplicative,
  title={The multiplicative weights update method: a meta-algorithm and applications},
  author={Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
  journal={Theory of computing},
  volume={8},
  number={1},
  pages={121--164},
  year={2012},
  publisher={Theory of Computing Exchange}
}

@article{li2022implicit,
  title={Implicit Bias of Gradient Descent on Reparametrized Models: On Equivalence to Mirror Descent},
  author={Li, Zhiyuan and Wang, Tianhao and Lee, JasonD and Arora, Sanjeev},
  journal={arXiv preprint arXiv:2207.04036},
  year={2022}
}