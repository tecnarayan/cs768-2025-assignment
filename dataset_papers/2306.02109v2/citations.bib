@article{wagner2020ptb,
  title={PTB-XL, a large publicly available electrocardiography dataset},
  author={Wagner, Patrick and Strodthoff, Nils and Bousseljot, Ralf-Dieter and Kreiseler, Dieter and Lunze, Fatima I and Samek, Wojciech and Schaeffter, Tobias},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={154},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@misc{liao2022humancentered,
      title={Human-Centered Explainable AI (XAI): From Algorithms to User Experiences}, 
      author={Q. Vera Liao and Kush R. Varshney},
      year={2022},
      eprint={2110.10790},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{
azizmalayeri2022your,
title={Your Out-of-Distribution Detection Method is Not Robust!},
author={Mohammad Azizmalayeri and Arshia Soltani Moakar and Arman Zarei and Reihaneh Zohrabi and Mohammad Taghi Manzuri and Mohammad Hossein Rohban},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=YUEP3ZmkL1}
}
@article{Makowski2021neurokit,
    author = {Dominique Makowski and Tam Pham and Zen J. Lau and Jan C. Brammer and Fran{\c{c}}ois Lespinasse and Hung Pham and Christopher Sch√∂lzel and S. H. Annabel Chen},
    title = {{NeuroKit}2: A Python toolbox for neurophysiological signal processing},
    journal = {Behavior Research Methods},
    volume = {53},
    number = {4},
    pages = {1689--1696},
    publisher = {Springer Science and Business Media {LLC}},
    doi = {10.3758/s13428-020-01516-y},
    year = 2021,
    month = {feb}
}

@misc{awav-bn36-19,
doi = {10.21227/awav-bn36},
url = {https://dx.doi.org/10.21227/awav-bn36},
author = {Shohet, R. and Kandil, M. and McArthur, J.J.},
publisher = {IEEE Dataport},
title = {Simulated boiler data for fault detection and classification},
year = {2019} 
}

@article{Oreshkin2019NBEATSNB,
  title={N-BEATS: Neural basis expansion analysis for interpretable time series forecasting},
  author={Boris N. Oreshkin and Dmitri Carpov and Nicolas Chapados and Yoshua Bengio},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.10437}
}
@article{Chuang2023CoRTXCF,
  title={CoRTX: Contrastive Framework for Real-time Explanation},
  author={Yu-Neng Chuang and Guanchu Wang and Fan Yang and Quan Zhou and Pushkar Tripathi and Xuanting Cai and Xia Hu},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.02794}
}
@inproceedings{Vaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle={NIPS},
  year={2017}
}
@article{Liu2009uWaveAP,
  title={uWave: Accelerometer-based personalized gesture recognition and its applications},
  author={Jiayang Liu and Lin Zhong and Jehan Wickramasuriya and Venu Vasudevan},
  journal={2009 IEEE International Conference on Pervasive Computing and Communications},
  year={2009},
  pages={1-9}
}

@article{Moody2001TheIO,
  title={The impact of the MIT-BIH Arrhythmia Database},
  author={George B. Moody and Roger G. Mark},
  journal={IEEE Engineering in Medicine and Biology Magazine},
  year={2001},
  volume={20},
  pages={45-50}
}

@article{Andrzejak2001IndicationsON,
  title={Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: dependence on recording region and brain state.},
  author={Ralph G. Andrzejak and Klaus Lehnertz and Florian Mormann and Christoph Rieke and Peter David and Christian Erich Elger},
  journal={Physical review. E, Statistical, nonlinear, and soft matter physics},
  year={2001},
  volume={64 6 Pt 1},
}

@inproceedings{bastings2019interpretable,
    title = "Interpretable Neural Predictions with Differentiable Binary Variables",
    author = "Bastings, Jasmijn  and
      Aziz, Wilker  and
      Titov, Ivan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1284",
    doi = "10.18653/v1/P19-1284",
    pages = "2963--2977",
}

@inproceedings{
jang2017categorical,
title={Categorical Reparameterization with Gumbel-Softmax},
author={Eric Jang and Shixiang Gu and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=rkE3y85ee}
}

@inproceedings{hase2021ood,
 author = {Hase, Peter and Xie, Harry and Bansal, Mohit},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {3650--3666},
 publisher = {Curran Associates, Inc.},
 title = {The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations},
 url = {https://proceedings.neurips.cc/paper/2021/file/1def1713ebf17722cbe300cfc1c88558-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@inproceedings{ismail2020benchmarking,
 author = {Ismail, Aya Abdelsalam and Gunady, Mohamed and Corrada Bravo, Hector and Feizi, Soheil},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {6441--6452},
 publisher = {Curran Associates, Inc.},
 title = {Benchmarking Deep Learning Interpretability in Time Series Predictions},
 url = {https://proceedings.neurips.cc/paper/2020/file/47a3893cc405396a5c30d91320572d6d-Paper.pdf},
 volume = {33},
 year = {2020}
}

@InProceedings{crabbe2021explaining,
  title = 	 {Explaining Time Series Predictions with Dynamic Masks},
  author =       {Crabb{\'e}, Jonathan and Van Der Schaar, Mihaela},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {2166--2177},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/crabbe21a/crabbe21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/crabbe21a.html},
  abstract = 	 {How can we explain the predictions of a machine learning model? When the data is structured as a multivariate time series, this question induces additional difficulties such as the necessity for the explanation to embody the time dependency and the large number of inputs. To address these challenges, we propose dynamic masks (Dynamask). This method produces instance-wise importance scores for each feature at each time step by fitting a perturbation mask to the input sequence. In order to incorporate the time dependency of the data, Dynamask studies the effects of dynamic perturbation operators. In order to tackle the large number of inputs, we propose a scheme to make the feature selection parsimonious (to select no more feature than necessary) and legible (a notion that we detail by making a parallel with information theory). With synthetic and real-world data, we demonstrate that the dynamic underpinning of Dynamask, together with its parsimony, offer a neat improvement in the identification of feature importance over time. The modularity of Dynamask makes it ideal as a plug-in to increase the transparency of a wide range of machine learning models in areas such as medicine and finance, where time series are abundant.}
}

@article{burns2022discovering,
  title={Discovering latent knowledge in language models without supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv:2212.03827},
  year={2022}
}

@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press}
}

@article{dai2021knowledge,
  title={Knowledge neurons in pretrained transformers},
  author={Dai, Damai and Dong, Li and Hao, Yaru and Sui, Zhifang and Chang, Baobao and Wei, Furu},
  journal={arXiv:2104.08696},
  year={2021}
}

@article{rogers2021primer,
  title={A primer in {BERTology}: What we know about how {BERT} works},
  author={Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={842--866},
  year={2021}
}

@inproceedings{
ismail2021improving,
title={Improving Deep Learning Interpretability by Saliency Guided Training},
author={Aya Abdelsalam Ismail and Hector Corrada Bravo and Soheil Feizi},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=x4zs7eC-BsI}
}

@article{meng2022locating,
  title={Locating and editing factual associations in {GPT}},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@article{zhang2022self,
  title={Self-supervised contrastive pre-training for time series via time-frequency consistency},
  author={Zhang, Xiang and Zhao, Ziyuan and Tsiligkaridis, Theodoros and Zitnik, Marinka},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{robust_xai:spm:2022,
    title={Robust Explainability: A tutorial on gradient-based attribution methods for deep neural networks},
    author={Ian E. Nielsen and Dimah Dera and Ghulam Rasool, Ravi P. Ramachandran and Nidhal Carla Bouay},
    journal={IEEE Signal Processing Magazine},
    volume={39},
    number={4},
    month={July},
    year={2022}
}

@inproceedings{tsiligkaridis:cvpr:2022,
    title={Understanding and Increasing Efficiency of Frank-Wolfe Adversarial Training},
    author={Theodoros Tsiligkaridis and Jay Roberts},
    booktitle={CVPR},
    year={2022}
}

@inproceedings {10.2312:mlvis.20211072,
booktitle = {Machine Learning Methods in Visualisation for Big Data},
editor = {Archambault, Daniel and Nabney, Ian and Peltonen, Jaakko},
title = {{Controllably Sparse Perturbations of Robust Classifiers for Explaining Predictions and Probing Learned Concepts}},
author = {Roberts, Jay and Tsiligkaridis, Theodoros},
year = {2021},
publisher = {The Eurographics Association},
ISBN = {978-3-03868-146-5},
DOI = {10.2312/mlvis.20211072}
}

@inproceedings{roberts:covid:2020,
    title={Ultrasound Diagnosis of COVID-19: Robustness and Explainability},
    author={Jay Roberts and Theodoros Tsiligkaridis},
    booktitle={Medical Imaging meets NeurIPS Workshop},
    year={2020}
}




@article{vig2020investigating,
  title={Investigating gender bias in language models using causal mediation analysis},
  author={Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12388--12401},
  year={2020}
}

@article{olsson2022context,
  title={In-context learning and induction heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and others},
  journal={arXiv:2209.11895},
  year={2022}
}

@article{abnar2020quantifying,
  title={Quantifying attention flow in transformers},
  author={Abnar, Samira and Zuidema, Willem},
  journal={ACL},
  year={2020}
}

@article{vig2019multiscale,
  title={A multiscale visualization of attention in the transformer model},
  author={Vig, Jesse},
  journal={arXiv:1906.05714},
  year={2019}
}

@inproceedings{agarwal2022probing,
  title={Probing GNN explainers: A rigorous theoretical and empirical analysis of GNN explanation methods},
  author={Agarwal, Chirag and Zitnik, Marinka and Lakkaraju, Himabindu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={8969--8996},
  year={2022},
  organization={PMLR}
}

@inproceedings{tonekaboni2020fit,
 author = {Tonekaboni, Sana and Joshi, Shalmali and Campbell, Kieran and Duvenaud, David K and Goldenberg, Anna},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {799--809},
 publisher = {Curran Associates, Inc.},
 title = {What went wrong and when? Instance-wise feature importance for time-series black-box models},
 url = {https://proceedings.neurips.cc/paper/2020/file/08fa43588c2571ade19bc0fa5936e028-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}


@InProceedings{miao2022interpretable,
  title = 	 {Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism},
  author =       {Miao, Siqi and Liu, Mia and Li, Pan},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {15524--15543},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/miao22a/miao22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/miao22a.html},
  abstract = 	 {Interpretable graph learning is in need as many scientific applications depend on learning models to collect insights from graph-structured data. Previous works mostly focused on using post-hoc approaches to interpret pre-trained models (graph neural networks in particular). They argue against inherently interpretable models because the good interpretability of these models is often at the cost of their prediction accuracy. However, those post-hoc methods often fail to provide stable interpretation and may extract features that are spuriously correlated with the task. In this work, we address these issues by proposing Graph Stochastic Attention (GSAT). Derived from the information bottleneck principle, GSAT injects stochasticity to the attention weights to block the information from task-irrelevant graph components while learning stochasticity-reduced attention to select task-relevant subgraphs for interpretation. The selected subgraphs provably do not contain patterns that are spuriously correlated with the task under some assumptions. Extensive experiments on eight datasets show that GSAT outperforms the state-of-the-art methods by up to 20% in interpretation AUC and 5% in prediction accuracy. Our code is available at https://github.com/Graph-COM/GSAT.}
}

@article{sturmfels2020visualizing,
  author = {Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In},
  title = {Visualizing the Impact of Feature Attribution Baselines},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/attribution-baselines},
  doi = {10.23915/distill.00022}
}

@misc{haug2021baselines,
      title={On Baselines for Local Feature Attributions}, 
      author={Johannes Haug and Stefan Z√ºrn and Peter El-Jiz and Gjergji Kasneci},
      year={2021},
      eprint={2101.00905},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{tan2022maximum,
  doi = {10.48550/ARXIV.2204.05948},
  
  url = {https://arxiv.org/abs/2204.05948},
  
  author = {Tan, Hanxiao},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Maximum Entropy Baseline for Integrated Gradients},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@inproceedings{doddaiah2022class,
  title={Class-Specific Explainability for Deep Time Series Classifiers},
  author={Doddaiah, Ramesh and Parvatharaju, Prathyush and Rundensteiner, Elke and Hartvigsen, Thomas},
  booktitle={Proceedings of the International Conference on Data Mining},
  year={2022}
}

@inproceedings{parvatharaju2021learning,
  title={Learning saliency maps to explain deep time series classifiers},
  author={Parvatharaju, Prathyush S and Doddaiah, Ramesh and Hartvigsen, Thomas and Rundensteiner, Elke A},
  booktitle={Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
  pages={1406--1415},
  year={2021}
}

@article{chechik2002extracting,
  title={Extracting relevant structures with side information},
  author={Chechik, Gal and Tishby, Naftali},
  journal={Advances in Neural Information Processing Systems},
  volume={15},
  year={2002}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{rooke2021temporal,
  title={Temporal Dependencies in Feature Importance for Time Series Predictions},
  author={Rooke, Clayton and Smith, Jonathan and Leung, Kin Kwan and Volkovs, Maksims and Zuberi, Saba},
  journal={arXiv preprint arXiv:2107.14317},
  year={2021}
}

@article{malhotra2017timenet,
  title={{TimeNet:} Pre-trained deep recurrent neural network for time series classification},
  author={Malhotra, Pankaj and TV, Vishnu and Vig, Lovekesh and Agarwal, Puneet and Shroff, Gautam},
  journal={arXiv:1706.08838},
  year={2017}
}

@article{lim2021temporal,
  title={Temporal fusion transformers for interpretable multi-horizon time series forecasting},
  author={Lim, Bryan and Ar{\i}k, Sercan {\"O} and Loeff, Nicolas and Pfister, Tomas},
  journal={International Journal of Forecasting},
  volume={37},
  number={4},
  pages={1748--1764},
  year={2021},
  publisher={Elsevier}
}

@article{spinelli2022mate, title={A Meta-Learning Approach for Training Explainable Graph Neural Networks}, ISSN={2162-237X, 2162-2388}, DOI={10.1109/TNNLS.2022.3171398}, journal={IEEE Transactions on Neural Networks and Learning Systems}, author={Spinelli, Indro and Scardapane, Simone and Uncini, Aurelio}, year={2022}, pages={1‚Äì9}, language={en} }
 
@inproceedings{sivill2022limesegment, title={LIMESegment: Meaningful, Realistic Time Series Explanations}, ISSN={2640-3498}, url={https://proceedings.mlr.press/v151/sivill22a.html}, booktitle={Proceedings of The 25th International Conference on Artificial Intelligence and Statistics}, publisher={PMLR}, author={Sivill, Torty and Flach, Peter}, year={2022}, month={May}, pages={3418‚Äì3433}, language={en} }

@article{linardatos2020explainable,
  title={Explainable ai: A review of machine learning interpretability methods},
  author={Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris},
  journal={Entropy},
  volume={23},
  number={1},
  pages={18},
  year={2020},
  publisher={MDPI}
}

@article{gautam2022protovae,
  title={Protovae: A trustworthy self-explainable prototypical variational model},
  author={Gautam, Srishti and Boubekki, Ahcene and Hansen, Stine and Salahuddin, Suaiba and Jenssen, Robert and H{\"o}hne, Marina and Kampffmeyer, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17940--17952},
  year={2022}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{kindermans2019reliability,
  title={The (un) reliability of saliency methods},
  author={Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Sch{\"u}tt, Kristof T and D{\"a}hne, Sven and Erhan, Dumitru and Kim, Been},
  journal={Explainable AI: Interpreting, explaining and visualizing deep learning},
  pages={267--280},
  year={2019},
  publisher={Springer}
}

@article{agarwal2023evaluating,
  title={Evaluating explainability for graph neural networks},
  author={Agarwal, Chirag and Queen, Owen and Lakkaraju, Himabindu and Zitnik, Marinka},
  journal={Scientific Data},
  volume={10},
  number={1},
  pages={144},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{ying2019gnnexplainer,
  title={Gnnexplainer: Generating explanations for graph neural networks},
  author={Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{zhang2021learning,
  title={Learning optimal predictive checklists},
  author={Zhang, Haoran and Morris, Quaid and Ustun, Berk and Ghassemi, Marzyeh},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1215--1229},
  year={2021}
}

@article{lundberg2020local,
  title={From local explanations to global understanding with explainable AI for trees},
  author={Lundberg, Scott M and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
  journal={Nature machine intelligence},
  volume={2},
  number={1},
  pages={56--67},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  journal={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{lakkaraju2019faithful,
  title={Faithful and customizable explanations of black box models},
  author={Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={131--138},
  year={2019}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{ghassemi2021false,
  title={The false hope of current approaches to explainable artificial intelligence in health care},
  author={Ghassemi, Marzyeh and Oakden-Rayner, Luke and Beam, Andrew L},
  journal={The Lancet Digital Health},
  volume={3},
  number={11},
  pages={e745--e750},
  year={2021},
  publisher={Elsevier}
}

@article{samek2021explaining,
  title={Explaining deep neural networks and beyond: A review of methods and applications},
  author={Samek, Wojciech and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Anders, Christopher J and M{\"u}ller, Klaus-Robert},
  journal={Proceedings of the IEEE},
  volume={109},
  number={3},
  pages={247--278},
  year={2021},
  publisher={IEEE}
}

 @inproceedings{ribeiro2016lime, address={San Francisco California USA}, title={‚ÄúWhy Should I Trust You?‚Äù: Explaining the Predictions of Any Classifier}, ISBN={978-1-4503-4232-2}, url={https://dl.acm.org/doi/10.1145/2939672.2939778}, DOI={10.1145/2939672.2939778}, booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, publisher={ACM}, author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos}, year={2016}, month={Aug}, pages={1135‚Äì1144}, language={en} }

@inproceedings{petsiuk2018rise,
  title={Rise: Randomized input sampling for explanation of black-box models},
  author={Petsiuk, Vitali and Das, Abir and Saenko, Kate},
  booktitle={British Machine Vision Conference},
  year={2018}
}

@inproceedings{yuksekgonul2023post,
  title={Post-hoc concept bottleneck models},
  author={Yuksekgonul, Mert and Wang, Maggie and Zou, James},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{rojat2021explainable,
  title={Explainable artificial intelligence (xai) on timeseries data: A survey},
  author={Rojat, Thomas and Puget, Rapha{\"e}l and Filliat, David and Del Ser, Javier and Gelin, Rodolphe and D{\'\i}az-Rodr{\'\i}guez, Natalia},
  journal={arXiv preprint arXiv:2104.00950},
  year={2021}
}

@article{Guidotti2020ExplainingAT,
  title={Explaining Any Time Series Classifier},
  author={Riccardo Guidotti and et al.},
  journal={International Conference on Cognitive Machine Intelligence},
  year={2020},
}

@inproceedings{sarkar:2022,
  title={A Framework for Learning Ante-hoc Explainable Models via Concepts},
  author={Anirban Sarkar and Deepak Vijaykeerthy and Anindya Sarkar and Vineeth N. Balasubramanian},
  booktitle={CVPR},
  pages={10286--10295},
  year={2022}
}

@article{bodria2021benchmarking,
  title={Benchmarking and survey of explanation methods for black box models},
  author={Bodria, Francesco and Giannotti, Fosca and Guidotti, Riccardo and Naretto, Francesca and Pedreschi, Dino and Rinzivillo, Salvatore},
  journal={arXiv preprint arXiv:2102.13076},
  year={2021}
}

@article{madsen2022post,
  title={Post-hoc interpretability for neural nlp: A survey},
  author={Madsen, Andreas and Reddy, Siva and Chandar, Sarath},
  journal={ACM Computing Surveys},
  volume={55},
  number={8},
  pages={1--42},
  year={2022},
  publisher={ACM New York, NY}
}

@article{danilevsky2020survey,
  title={A survey of the state of explainable AI for natural language processing},
  author={Danilevsky, Marina and Qian, Kun and Aharonov, Ranit and Katsis, Yannis and Kawas, Ban and Sen, Prithviraj},
  journal={arXiv preprint arXiv:2010.00711},
  year={2020}
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@inproceedings{schlegel2019towards,
  title={Towards a rigorous evaluation of XAI methods on time series},
  author={Schlegel, Udo and Arnout, Hiba and El-Assady, Mennatallah and Oelke, Daniela and Keim, Daniel A},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  pages={4197--4201},
  year={2019},
  organization={IEEE}
}

@article{mujkanovic2020timexplain,
  title={timeXplain--A Framework for Explaining the Predictions of Time Series Classifiers},
  author={Mujkanovic, F.and et al},
  journal={ArXiv},
  year={2020},
}

 @inproceedings{bento2021timeshap, title={TimeSHAP: Explaining Recurrent Models through Sequence Perturbations}, url={http://arxiv.org/abs/2012.00073}, DOI={10.1145/3447548.3467166}, note={arXiv:2012.00073 [cs]}, booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining}, author={Bento, Jo√£o and Saleiro, Pedro and Cruz, Andr√© F. and Figueiredo, M√°rio A. T. and Bizarro, Pedro}, year={2021}, month={Aug}, pages={2565‚Äì2573} }


@InProceedings{dasgupta2022framework,
  title = 	 {Framework for Evaluating Faithfulness of Local Explanations},
  author =       {Dasgupta, Sanjoy and Frost, Nave and Moshkovitz, Michal},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {4794--4815},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/dasgupta22a/dasgupta22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/dasgupta22a.html},
}



 @article{degrave2021radiographic, title={AI for radiographic COVID-19 detection selects shortcuts over signal}, volume={3}, rights={2021 The Author(s), under exclusive licence to Springer Nature Limited}, ISSN={2522-5839}, DOI={10.1038/s42256-021-00338-7}, number={77}, journal={Nature Machine Intelligence}, publisher={Nature Publishing Group}, author={DeGrave, Alex J. and Janizek, Joseph D. and Lee, Su-In}, year={2021}, month={Jul}, pages={610‚Äì619}, language={en} }



@inproceedings{
colin2022what,
title={What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods},
author={Julien Colin and Thomas FEL and Remi Cadene and Thomas Serre},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=59pMU2xFxG}
}

@inproceedings{liu2022rethinking,
  title={Rethinking attention-model explainability through faithfulness violation test},
  author={Liu, Yibing and Li, Haoliang and Guo, Yangyang and Kong, Chenqi and Li, Jing and Wang, Shiqi},
  booktitle={International Conference on Machine Learning},
  pages={13807--13824},
  year={2022},
  organization={PMLR}
}

@inproceedings{
robinson2021can,
title={Can contrastive learning avoid shortcut solutions?},
author={Joshua David Robinson and Li Sun and Ke Yu and kayhan Batmanghelich and Stefanie Jegelka and Suvrit Sra},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=ud-WYSo9JSL}
}

@inproceedings{
wu2022zeroc,
title={ZeroC: A Neuro-Symbolic Model for Zero-shot Concept Recognition and Acquisition at Inference Time},
author={Tailin Wu and Megan Tjandrasuwita and Zhengxuan Wu and Xuelin Yang and Kevin Liu and Rok Sosic and Jure Leskovec},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=T7114JzrwB}
}

@article{higgins2017scan,
  title={Scan: Learning hierarchical compositional visual concepts},
  author={Higgins, Irina and Sonnerat, Nicolas and Matthey, Loic and Pal, Arka and Burgess, Christopher P and Bosnjak, Matko and Shanahan, Murray and Botvinick, Matthew and Hassabis, Demis and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1707.03389},
  year={2017}
}

@article{mao2019neuro,
  title={The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision},
  author={Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B and Wu, Jiajun},
  journal={International Conference on Learning Representations},
  year={2019}
}


@InProceedings{koh2020concept,
  title = 	 {Concept Bottleneck Models},
  author =       {Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {5338--5348},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/koh20a/koh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/koh20a.html},
}

@inproceedings{
marconato2022glancenets,
title={GlanceNets: Interpretable, Leak-proof Concept-based Models},
author={Emanuele Marconato and Andrea Passerini and Stefano Teso},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=J7zY9j75GoG}
}

@inproceedings{
leung2023temporal,
title={Temporal Dependencies in Feature Importance for Time Series Prediction},
author={Kin Kwan Leung and Clayton Rooke and Jonathan Smith and Saba Zuberi and Maksims Volkovs},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=C0q9oBc3n4}
}

@inproceedings{ye2009time,
  title={Time series shapelets: a new primitive for data mining},
  author={Ye, Lexiang and Keogh, Eamonn},
  booktitle={Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={947--956},
  year={2009}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@inproceedings{
maddison2017concrete,
title={The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
author={Chris J. Maddison and Andriy Mnih and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=S1jE5L5gl}
}

@inproceedings{
miao2023interpretable,
title={Interpretable Geometric Deep Learning via Learnable Randomness Injection},
author={Siqi Miao and Yunan Luo and Mia Liu and Pan Li},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=6u7mf9s2A9}
}

@inproceedings{nguyen2020differentiable,
    title = "Differentiable Window for Dynamic Local Attention",
    author = "Nguyen, Thanh-Tung  and
      Nguyen, Xuan-Phi  and
      Joty, Shafiq  and
      Li, Xiaoli",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.589",
    doi = "10.18653/v1/2020.acl-main.589",
    pages = "6589--6599",
}

@inproceedings{reiss2012introducing,
  title={Introducing a new benchmarked dataset for activity monitoring},
  author={Reiss, Attila and Stricker, Didier},
  booktitle={2012 16th international symposium on wearable computers},
  pages={108--109},
  year={2012},
  organization={IEEE}
}

@article{andrzejak2001indications,
  title={Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state},
  author={Andrzejak, Ralph G and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian E},
  journal={Physical Review E},
  volume={64},
  number={6},
  pages={061907},
  year={2001},
  publisher={APS}
}

@inproceedings{lei2016rationalizing,
    title = "Rationalizing Neural Predictions",
    author = "Lei, Tao  and
      Barzilay, Regina  and
      Jaakkola, Tommi",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1011",
    doi = "10.18653/v1/D16-1011",
    pages = "107--117",
}

@inproceedings{
goel2022cyclip,
title={Cy{CLIP}: Cyclic Contrastive Language-Image Pretraining},
author={Shashank Goel and Hritik Bansal and Sumit Bhatia and Ryan A. Rossi and Vishwa Vinay and Aditya Grover},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=I-6yh2-dkyD}
}

@inproceedings{fong2019understanding,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2950--2958},
  year={2019}
}

@inproceedings{
hsieh2021evaluations,
title={Evaluations and Methods for Explanation through Robustness Analysis},
author={Cheng-Yu Hsieh and Chih-Kuan Yeh and Xuanqing Liu and Pradeep Kumar Ravikumar and Seungyeon Kim and Sanjiv Kumar and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=4dXmpCDGNp7}
}

@article{qiu2021resisting,
  title={Resisting out-of-distribution data problem in perturbation of xai},
  author={Qiu, Luyu and Yang, Yi and Cao, Caleb Chen and Liu, Jing and Zheng, Yueyuan and Ngai, Hilary Hei Ting and Hsiao, Janet and Chen, Lei},
  journal={arXiv preprint arXiv:2107.14000},
  year={2021}
}

@article{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@INPROCEEDINGS{kusters2020conceptual,
  author={K√ºsters, Ferdinand and Schichtel, Peter and Ahmed, Sheraz and Dengel, Andreas},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Conceptual Explanations of Neural Network Prediction for Time Series}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN48605.2020.9207341}}

@article{agarwal2021neural,
  title={Neural additive models: Interpretable machine learning with neural nets},
  author={Agarwal, Rishabh and Melnick, Levi and Frosst, Nicholas and Zhang, Xuezhou and Lengerich, Ben and Caruana, Rich and Hinton, Geoffrey E},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4699--4711},
  year={2021}
}

@inproceedings{henderson2021improving,
  title={Improving molecular graph neural network explainability with orthonormalization and induced sparsity},
  author={Henderson, Ryan and Clevert, Djork-Arn{\'e} and Montanari, Floriane},
  booktitle={International Conference on Machine Learning},
  pages={4203--4213},
  year={2021},
  organization={PMLR}
}

