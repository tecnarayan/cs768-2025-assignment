\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmadinejad et~al.(2019)Ahmadinejad, Dehghani, Hajiaghayi, Lucier,
  Mahini, and Seddighin]{ahmadinejad2019duels}
AmirMahdi Ahmadinejad, Sina Dehghani, MohammadTaghi Hajiaghayi, Brendan Lucier,
  Hamid Mahini, and Saeed Seddighin.
\newblock From duels to battlefields: Computing equilibria of blotto and other
  games.
\newblock \emph{Mathematics of Operations Research}, 44\penalty0 (4):\penalty0
  1304--1325, 2019.

\bibitem[Altman(1999)]{altman1999constrained}
Eitan Altman.
\newblock \emph{Constrained Markov decision processes}, volume~7.
\newblock CRC Press, 1999.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017minimax}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  263--272. PMLR, 2017.

\bibitem[Bai and Jin(2020)]{bai2020provable}
Yu~Bai and Chi Jin.
\newblock Provable self-play algorithms for competitive reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  551--560. PMLR, 2020.

\bibitem[Bai et~al.(2020)Bai, Jin, and Yu]{bai2020near}
Yu~Bai, Chi Jin, and Tiancheng Yu.
\newblock Near-optimal reinforcement learning with self-play.
\newblock \emph{arXiv preprint arXiv:2006.12007}, 2020.

\bibitem[Blum et~al.(2014)Blum, Haghtalab, and Procaccia]{blum2014learning}
Avrim Blum, Nika Haghtalab, and Ariel~D Procaccia.
\newblock Learning optimal commitment to overcome insecurity.
\newblock 2014.

\bibitem[Blum et~al.(2019)Blum, Haghtalab, Hajiaghayi, and
  Seddighin]{blum2019computing}
Avrim Blum, Nika Haghtalab, MohammadTaghi Hajiaghayi, and Saeed Seddighin.
\newblock Computing stackelberg equilibria of large general-sum games.
\newblock In \emph{International Symposium on Algorithmic Game Theory}, pages
  168--182. Springer, 2019.

\bibitem[Boyd and Vandenberghe(2004)]{boyd2004convex}
Stephen~P Boyd and Lieven Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{cesa2006prediction}
Nicolo Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem[Cole and Roughgarden(2014)]{cole2014sample}
Richard Cole and Tim Roughgarden.
\newblock The sample complexity of revenue maximization.
\newblock In \emph{Proceedings of the forty-sixth annual ACM symposium on
  Theory of computing}, pages 243--252, 2014.

\bibitem[Conitzer and Sandholm(2002)]{conitzer2002complexity}
Vincent Conitzer and Tuomas Sandholm.
\newblock Complexity of mechanism design.
\newblock \emph{arXiv preprint cs/0205075}, 2002.

\bibitem[Conitzer and Sandholm(2004)]{conitzer2004self}
Vincent Conitzer and Tuomas Sandholm.
\newblock Self-interested automated mechanism design and implications for
  optimal combinatorial auctions.
\newblock In \emph{Proceedings of the 5th ACM Conference on Electronic
  Commerce}, pages 132--141, 2004.

\bibitem[Conitzer and Sandholm(2006)]{conitzer2006computing}
Vincent Conitzer and Tuomas Sandholm.
\newblock Computing the optimal strategy to commit to.
\newblock In \emph{Proceedings of the 7th ACM conference on Electronic
  commerce}, pages 82--90, 2006.

\bibitem[D{\"u}tting et~al.(2019)D{\"u}tting, Feng, Narasimhan, Parkes, and
  Ravindranath]{dutting2019optimal}
Paul D{\"u}tting, Zhe Feng, Harikrishna Narasimhan, David Parkes, and
  Sai~Srivatsa Ravindranath.
\newblock Optimal auctions through deep learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1706--1715. PMLR, 2019.

\bibitem[Fiez et~al.(2019)Fiez, Chasnov, and Ratliff]{fiez2019convergence}
Tanner Fiez, Benjamin Chasnov, and Lillian~J Ratliff.
\newblock Convergence of learning dynamics in stackelberg games.
\newblock \emph{arXiv preprint arXiv:1906.01217}, 2019.

\bibitem[Foster et~al.(2016)Foster, Li, Lykouris, Sridharan, and
  Tardos]{foster2016learning}
Dylan~J Foster, Zhiyuan Li, Thodoris Lykouris, Karthik Sridharan, and Eva
  Tardos.
\newblock Learning in games: Robustness of fast convergence.
\newblock \emph{arXiv preprint arXiv:1606.06244}, 2016.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{jin2018q}
Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael~I Jordan.
\newblock Is q-learning provably efficient?
\newblock \emph{arXiv preprint arXiv:1807.03765}, 2018.

\bibitem[Jin et~al.(2020{\natexlab{a}})Jin, Krishnamurthy, Simchowitz, and
  Yu]{jin2020reward}
Chi Jin, Akshay Krishnamurthy, Max Simchowitz, and Tiancheng Yu.
\newblock Reward-free exploration for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2002.02794}, 2020{\natexlab{a}}.

\bibitem[Jin et~al.(2020{\natexlab{b}})Jin, Netrapalli, and
  Jordan]{jin2020local}
Chi Jin, Praneeth Netrapalli, and Michael Jordan.
\newblock What is local optimality in nonconvex-nonconcave minimax
  optimization?
\newblock In \emph{International Conference on Machine Learning}, pages
  4880--4889. PMLR, 2020{\natexlab{b}}.

\bibitem[Jordan et~al.(2008)Jordan, Vorobeychik, and
  Wellman]{jordan2008searching}
Patrick~R Jordan, Yevgeniy Vorobeychik, and Michael~P Wellman.
\newblock Searching for approximate equilibria in empirical games.
\newblock In \emph{Proceedings of the 7th international joint conference on
  Autonomous agents and multiagent systems-Volume 2}, pages 1063--1070, 2008.

\bibitem[Korpelevich(1976)]{korpelevich1976extragradient}
GM~Korpelevich.
\newblock The extragradient method for finding saddle points and other
  problems.
\newblock \emph{Matecon}, 12:\penalty0 747--756, 1976.

\bibitem[Korzhyk et~al.(2011)Korzhyk, Yin, Kiekintveld, Conitzer, and
  Tambe]{korzhyk2011stackelberg}
Dmytro Korzhyk, Zhengyu Yin, Christopher Kiekintveld, Vincent Conitzer, and
  Milind Tambe.
\newblock Stackelberg vs. nash in security games: An extended investigation of
  interchangeability, equivalence, and uniqueness.
\newblock \emph{Journal of Artificial Intelligence Research}, 41:\penalty0
  297--327, 2011.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lattimore et~al.(2020)Lattimore, Szepesvari, and
  Weisz]{lattimore2020learning}
Tor Lattimore, Csaba Szepesvari, and Gellert Weisz.
\newblock Learning with good feature representations in bandits and in rl with
  a generative model.
\newblock In \emph{International Conference on Machine Learning}, pages
  5662--5670. PMLR, 2020.

\bibitem[Leibo et~al.(2017)Leibo, Zambaldi, Lanctot, Marecki, and
  Graepel]{leibo2017multi}
Joel~Z Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, and Thore
  Graepel.
\newblock Multi-agent reinforcement learning in sequential social dilemmas.
\newblock \emph{arXiv preprint arXiv:1702.03037}, 2017.

\bibitem[Letchford and Conitzer(2010)]{letchford2010computing}
Joshua Letchford and Vincent Conitzer.
\newblock Computing optimal strategies to commit to in extensive-form games.
\newblock In \emph{Proceedings of the 11th ACM conference on Electronic
  commerce}, pages 83--92, 2010.

\bibitem[Letchford et~al.(2009)Letchford, Conitzer, and
  Munagala]{letchford2009learning}
Joshua Letchford, Vincent Conitzer, and Kamesh Munagala.
\newblock Learning and approximating the optimal strategy to commit to.
\newblock In \emph{International Symposium on Algorithmic Game Theory}, pages
  250--262. Springer, 2009.

\bibitem[Liu et~al.(2020)Liu, Yu, Bai, and Jin]{liu2020sharp}
Qinghua Liu, Tiancheng Yu, Yu~Bai, and Chi Jin.
\newblock A sharp analysis of model-based reinforcement learning with
  self-play.
\newblock \emph{arXiv preprint arXiv:2010.01604}, 2020.

\bibitem[Marchesi et~al.(2020)Marchesi, Trov{\`o}, and
  Gatti]{marchesi2020learning}
Alberto Marchesi, Francesco Trov{\`o}, and Nicola Gatti.
\newblock Learning probably approximately correct maximin strategies in
  simulation-based games with infinite strategy spaces.
\newblock In \emph{Proceedings of the 19th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 834--842, 2020.

\bibitem[Nash(1951)]{nash1951non}
John Nash.
\newblock Non-cooperative games.
\newblock \emph{Annals of mathematics}, pages 286--295, 1951.

\bibitem[Nemirovski(2004)]{nemirovski2004prox}
Arkadi Nemirovski.
\newblock Prox-method with rate of convergence o (1/t) for variational
  inequalities with {L}ipschitz continuous monotone operators and smooth
  convex-concave saddle point problems.
\newblock \emph{SIAM Journal on Optimization}, 15\penalty0 (1):\penalty0
  229--251, 2004.

\bibitem[Nemirovski and Yudin(1978)]{nemirovski1978cesari}
Arkadi~S Nemirovski and David~Berkovich Yudin.
\newblock Cesari convergence of the gradient method of approximating saddle
  points of convex-concave functions.
\newblock In \emph{Doklady Akademii Nauk}, volume 239, pages 1056--1059.
  Russian Academy of Sciences, 1978.

\bibitem[Nouiehed et~al.(2019)Nouiehed, Sanjabi, Lee, and
  Razaviyayn]{nouiehed2019solving}
Maher Nouiehed, Maziar Sanjabi, Jason~D Lee, and Meisam Razaviyayn.
\newblock Solving a class of non-convex min-max games using iterative first
  order methods.
\newblock \emph{arXiv preprint arXiv:1902.08297}, 2019.

\bibitem[Peng et~al.(2019)Peng, Shen, Tang, and Zuo]{peng2019learning}
Binghui Peng, Weiran Shen, Pingzhong Tang, and Song Zuo.
\newblock Learning optimal strategies to commit to.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 2149--2156, 2019.

\bibitem[P{\'e}rolat et~al.(2017)P{\'e}rolat, Strub, Piot, and
  Pietquin]{perolat2017learning}
Julien P{\'e}rolat, Florian Strub, Bilal Piot, and Olivier Pietquin.
\newblock Learning nash equilibrium for general-sum markov games from batch
  data.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 232--241.
  PMLR, 2017.

\bibitem[Rafique et~al.(2018)Rafique, Liu, Lin, and Yang]{rafique2018non}
Hassan Rafique, Mingrui Liu, Qihang Lin, and Tianbao Yang.
\newblock Non-convex min-max optimization: Provable algorithms and applications
  in machine learning.
\newblock \emph{arXiv preprint arXiv:1810.02060}, 2018.

\bibitem[Rakhlin and Sridharan(2013)]{rakhlin2013optimization}
Alexander Rakhlin and Karthik Sridharan.
\newblock Optimization, learning, and games with predictable sequences.
\newblock \emph{arXiv preprint arXiv:1311.1869}, 2013.

\bibitem[Roughgarden(2010)]{roughgarden2010algorithmic}
Tim Roughgarden.
\newblock Algorithmic game theory.
\newblock \emph{Communications of the ACM}, 53\penalty0 (7):\penalty0 78--86,
  2010.

\bibitem[Sessa et~al.(2020)Sessa, Bogunovic, Kamgarpour, and
  Krause]{sessa2020learning}
Pier~Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, and Andreas Krause.
\newblock Learning to play sequential games versus unknown opponents.
\newblock \emph{arXiv preprint arXiv:2007.05271}, 2020.

\bibitem[Shapley(1953)]{shapley1953stochastic}
Lloyd~S Shapley.
\newblock Stochastic games.
\newblock \emph{Proceedings of the national academy of sciences}, 39\penalty0
  (10):\penalty0 1095--1100, 1953.

\bibitem[Shoham and Leyton-Brown(2008)]{shoham2008multiagent}
Yoav Shoham and Kevin Leyton-Brown.
\newblock \emph{Multiagent systems: Algorithmic, game-theoretic, and logical
  foundations}.
\newblock Cambridge University Press, 2008.

\bibitem[Simaan and Cruz(1973)]{simaan1973stackelberg}
Marwaan Simaan and Jose~B Cruz.
\newblock On the stackelberg strategy in nonzero-sum games.
\newblock \emph{Journal of Optimization Theory and Applications}, 11\penalty0
  (5):\penalty0 533--555, 1973.

\bibitem[Tambe(2011)]{tambe2011security}
Milind Tambe.
\newblock \emph{Security and game theory: algorithms, deployed systems, lessons
  learned}.
\newblock Cambridge university press, 2011.

\bibitem[Todd(2016)]{todd2016minimum}
Michael~J Todd.
\newblock \emph{Minimum-volume ellipsoids: Theory and algorithms}.
\newblock SIAM, 2016.

\bibitem[Vasal(2020)]{vasal2020stochastic}
Deepanshu Vasal.
\newblock Stochastic stackelberg games.
\newblock \emph{arXiv preprint arXiv:2005.01997}, 2020.

\bibitem[von Neumann(1928)]{neumann1928theorie}
J~von Neumann.
\newblock Zur theorie der gesellschaftsspiele.
\newblock \emph{Mathematische annalen}, 100\penalty0 (1):\penalty0 295--320,
  1928.

\bibitem[Von~Stengel and Zamir(2010)]{von2010leadership}
Bernhard Von~Stengel and Shmuel Zamir.
\newblock Leadership games with convex strategy sets.
\newblock \emph{Games and Economic Behavior}, 69\penalty0 (2):\penalty0
  446--457, 2010.

\bibitem[Vorobeychik et~al.(2007)Vorobeychik, Wellman, and
  Singh]{vorobeychik2007learning}
Yevgeniy Vorobeychik, Michael~P Wellman, and Satinder Singh.
\newblock Learning payoff functions in infinite games.
\newblock \emph{Machine Learning}, 67\penalty0 (1-2):\penalty0 145--168, 2007.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\bibitem[Wellman(2006)]{wellman2006methods}
Michael~P Wellman.
\newblock Methods for empirical game-theoretic analysis.
\newblock In \emph{proceedings of the 21st national conference on Artificial
  intelligence-Volume 2}, pages 1552--1555, 2006.

\bibitem[Xie et~al.(2020)Xie, Chen, Wang, and Yang]{xie2020learning}
Qiaomin Xie, Yudong Chen, Zhaoran Wang, and Zhuoran Yang.
\newblock Learning zero-sum simultaneous-move markov games using function
  approximation and correlated equilibrium.
\newblock In \emph{Conference on Learning Theory}, pages 3674--3682. PMLR,
  2020.

\bibitem[Zhang et~al.(2020)Zhang, Kakade, Ba{\c{s}}ar, and
  Yang]{zhang2020model}
Kaiqing Zhang, Sham~M Kakade, Tamer Ba{\c{s}}ar, and Lin~F Yang.
\newblock Model-based multi-agent rl in zero-sum markov games with near-optimal
  sample complexity.
\newblock \emph{arXiv preprint arXiv:2007.07461}, 2020.

\bibitem[Zheng et~al.(2020)Zheng, Trott, Srinivasa, Naik, Gruesbeck, Parkes,
  and Socher]{zheng2020ai}
Stephan Zheng, Alexander Trott, Sunil Srinivasa, Nikhil Naik, Melvin Gruesbeck,
  David~C Parkes, and Richard Socher.
\newblock The ai economist: Improving equality and productivity with ai-driven
  tax policies.
\newblock \emph{arXiv preprint arXiv:2004.13332}, 2020.

\end{thebibliography}
