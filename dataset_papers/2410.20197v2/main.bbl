\begin{thebibliography}{10}

\bibitem{achiam2023gpt}
J.~Achiam, S.~Adler, S.~Agarwal, L.~Ahmad, I.~Akkaya, F.~L. Aleman, D.~Almeida, J.~Altenschmidt, S.~Altman, S.~Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{alayrac2022flamingo}
J.-B. Alayrac, J.~Donahue, P.~Luc, A.~Miech, I.~Barr, Y.~Hasson, K.~Lenc, A.~Mensch, K.~Millican, M.~Reynolds, et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2022.

\bibitem{athalye2018synthesizing}
A.~Athalye, L.~Engstrom, A.~Ilyas, and K.~Kwok.
\newblock Synthesizing robust adversarial examples.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2018.

\bibitem{benz2021batch}
P.~Benz, C.~Zhang, and I.~S. Kweon.
\newblock Batch normalization increases adversarial vulnerability and decreases adversarial transferability: A non-robust feature perspective.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2021.

\bibitem{biggio2013evasion}
B.~Biggio, I.~Corona, D.~Maiorca, B.~Nelson, N.~{\v{S}}rndi{\'c}, P.~Laskov, G.~Giacinto, and F.~Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In {\em Joint European conference on machine learning and knowledge discovery in databases}, 2013.

\bibitem{bommasani2021opportunities}
R.~Bommasani, D.~A. Hudson, E.~Adeli, R.~Altman, S.~Arora, S.~von Arx, M.~S. Bernstein, J.~Bohg, A.~Bosselut, E.~Brunskill, et~al.
\newblock On the opportunities and risks of foundation models.
\newblock {\em arXiv preprint arXiv:2108.07258}, 2021.

\bibitem{brendel2018decision}
W.~Brendel, J.~Rauber, and M.~Bethge.
\newblock Decision-based adversarial attacks: Reliable attacks against black-box machine learning models.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2018.

\bibitem{byun2022improving}
J.~Byun, S.~Cho, M.-J. Kwon, H.-S. Kim, and C.~Kim.
\newblock Improving the transferability of targeted adversarial examples through object-based diverse input.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2022.

\bibitem{cen2023segment}
J.~Cen, Z.~Zhou, J.~Fang, W.~Shen, L.~Xie, D.~Jiang, X.~Zhang, Q.~Tian, et~al.
\newblock Segment anything in 3d with nerfs.
\newblock {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2023.

\bibitem{chen2020hopskipjumpattack}
J.~Chen, M.~I. Jordan, and M.~J. Wainwright.
\newblock Hopskipjumpattack: A query-efficient decision-based attack.
\newblock In {\em IEEE symposium on security and privacy}, 2020.

\bibitem{chen2023sam}
T.~Chen, L.~Zhu, C.~Deng, R.~Cao, Y.~Wang, S.~Zhang, Z.~Li, L.~Sun, Y.~Zang, and P.~Mao.
\newblock Sam-adapter: Adapting segment anything in underperformed scenes.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2023.

\bibitem{croce2022sparse}
F.~Croce, M.~Andriushchenko, N.~D. Singh, N.~Flammarion, and M.~Hein.
\newblock Sparse-rs: a versatile framework for query-efficient sparse black-box adversarial attacks.
\newblock In {\em Proc.~AAAI Conf. on Artificial Intelligence}, pages 6437--6445, 2022.

\bibitem{dong2018boosting}
Y.~Dong, F.~Liao, T.~Pang, H.~Su, J.~Zhu, X.~Hu, and J.~Li.
\newblock Boosting adversarial attacks with momentum.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, pages 9185--9193, 2018.

\bibitem{fan2020camouflaged}
D.-P. Fan, G.-P. Ji, G.~Sun, M.-M. Cheng, J.~Shen, and L.~Shao.
\newblock Camouflaged object detection.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, pages 2777--2787, 2020.

\bibitem{fang2024strong}
Z.~Fang, R.~Wang, T.~Huang, and L.~Jing.
\newblock Strong transferable adversarial attacks via ensembled asymptotically normal distribution learning.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2024.

\bibitem{finn2017model}
C.~Finn, P.~Abbeel, and S.~Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2017.

\bibitem{ge2023boosting}
Z.~Ge, H.~Liu, W.~Xiaosen, F.~Shang, and Y.~Liu.
\newblock Boosting adversarial transferability by achieving flat local maxima.
\newblock {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2023.

\bibitem{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{gubri2022lgv}
M.~Gubri, M.~Cordy, M.~Papadakis, Y.~L. Traon, and K.~Sen.
\newblock Lgv: Boosting adversarial example transferability from large geometric vicinity.
\newblock In {\em Proc.~IEEE European Conf.~Computer Vision}, 2022.

\bibitem{houlsby2019parameter}
N.~Houlsby, A.~Giurgiu, S.~Jastrzebski, B.~Morrone, Q.~De~Laroussilhe, A.~Gesmundo, M.~Attariyan, and S.~Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2019.

\bibitem{hu2021lora}
E.~J. Hu, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, W.~Chen, et~al.
\newblock Lora: Low-rank adaptation of large language models.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2021.

\bibitem{huang2019enhancing}
Q.~Huang, I.~Katsman, H.~He, Z.~Gu, S.~Belongie, and S.-N. Lim.
\newblock Enhancing adversarial example transferability with an intermediate level attack.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2019.

\bibitem{ilyas2018black}
A.~Ilyas, L.~Engstrom, A.~Athalye, and J.~Lin.
\newblock Black-box adversarial attacks with limited queries and information.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2018.

\bibitem{ilyas2019prior}
A.~Ilyas, L.~Engstrom, and A.~Madry.
\newblock Prior convictions: Black-box adversarial attacks with bandits and priors.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2019.

\bibitem{ke2024segment}
L.~Ke, M.~Ye, M.~Danelljan, Y.-W. Tai, C.-K. Tang, F.~Yu, et~al.
\newblock Segment anything in high quality.
\newblock {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2024.

\bibitem{kirillov2023segment}
A.~Kirillov, E.~Mintun, N.~Ravi, H.~Mao, C.~Rolland, L.~Gustafson, T.~Xiao, S.~Whitehead, A.~C. Berg, W.-Y. Lo, et~al.
\newblock Segment anything.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2023.

\bibitem{kong2023pixel}
C.~Kong, A.~Luo, S.~Wang, H.~Li, A.~Rocha, and A.~C. Kot.
\newblock Pixel-inconsistency modeling for image manipulation localization.
\newblock {\em arXiv preprint arXiv:2310.00234}, 2023.

\bibitem{kurakin2018adversarial}
A.~Kurakin, I.~J. Goodfellow, and S.~Bengio.
\newblock Adversarial examples in the physical world.
\newblock In {\em Artificial intelligence safety and security}. 2018.

\bibitem{landman2015miccai}
B.~Landman, Z.~Xu, J.~Igelsias, M.~Styner, T.~Langerak, and A.~Klein.
\newblock Miccai multi-atlas labeling beyond the cranial vault--workshop and challenge.
\newblock In {\em Proc. MICCAI Multi-Atlas Labeling Beyond Cranial Vaultâ€”Workshop Challenge}, 2015.

\bibitem{le2019anabranch}
T.-N. Le, T.~V. Nguyen, Z.~Nie, M.-T. Tran, and A.~Sugimoto.
\newblock Anabranch network for camouflaged object segmentation.
\newblock {\em Computer vision and image understanding}, 2019.

\bibitem{li2023blip}
J.~Li, D.~Li, S.~Savarese, and S.~Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2023.

\bibitem{li2020yet}
Q.~Li, Y.~Guo, and H.~Chen.
\newblock Yet another intermediate-level attack.
\newblock In {\em Proc.~IEEE European Conf.~Computer Vision}, 2020.

\bibitem{li2022making}
Q.~Li, Y.~Guo, W.~Zuo, and H.~Chen.
\newblock Making substitute models more bayesian can enhance transferability of adversarial examples.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2022.

\bibitem{li2023improving}
Q.~Li, Y.~Guo, W.~Zuo, and H.~Chen.
\newblock Improving adversarial transferability via intermediate-level perturbation decay.
\newblock {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2023.

\bibitem{lin2019nesterov}
J.~Lin, C.~Song, K.~He, L.~Wang, and J.~E. Hopcroft.
\newblock Nesterov accelerated gradient and scale invariance for adversarial attacks.
\newblock {\em arXiv preprint arXiv:1908.06281}, 2019.

\bibitem{lin2024boosting}
Q.~Lin, C.~Luo, Z.~Niu, X.~He, W.~Xie, Y.~Hou, L.~Shen, and S.~Song.
\newblock Boosting adversarial transferability across model genus by deformation-constrained warping.
\newblock In {\em Proc.~AAAI Conf. on Artificial Intelligence}, 2024.

\bibitem{liu2016delving}
Y.~Liu, X.~Chen, C.~Liu, and D.~Song.
\newblock Delving into transferable adversarial examples and black-box attacks.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2016.

\bibitem{ma2023transferable}
W.~Ma, Y.~Li, X.~Jia, and W.~Xu.
\newblock Transferable adversarial attack for both vision transformers and convolutional networks via momentum integrated gradients.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2023.

\bibitem{mazurowski2023segment}
M.~A. Mazurowski, H.~Dong, H.~Gu, J.~Yang, N.~Konz, and Y.~Zhang.
\newblock Segment anything model for medical image analysis: an experimental study.
\newblock {\em Medical Image Analysis}, 2023.

\bibitem{moosavi2017universal}
S.-M. Moosavi-Dezfooli, A.~Fawzi, O.~Fawzi, and P.~Frossard.
\newblock Universal adversarial perturbations.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2017.

\bibitem{nichol2018first}
A.~Nichol, J.~Achiam, and J.~Schulman.
\newblock On first-order meta-learning algorithms.
\newblock {\em arXiv preprint arXiv:1803.02999}, 2018.

\bibitem{nichol2022glide}
A.~Q. Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~Mcgrew, I.~Sutskever, and M.~Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2022.

\bibitem{qian2023lea2}
Y.~Qian, S.~He, C.~Zhao, J.~Sha, W.~Wang, and B.~Wang.
\newblock Lea2: A lightweight ensemble adversarial attack via non-overlapping vulnerable frequency regions.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2023.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu, and M.~Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{ren2024segment}
S.~Ren, F.~Luzi, S.~Lahrichi, K.~Kassaw, L.~M. Collins, K.~Bradbury, and J.~M. Malof.
\newblock Segment anything, from space?
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2024.

\bibitem{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2022.

\bibitem{vo2024brusleattack}
V.~Q. Vo, E.~Abbasnejad, and D.~C. Ranasinghe.
\newblock Brusleattack: A query-efficient score-based black-box sparse adversarial attack.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2024.

\bibitem{wang2024benchmarking}
C.~Wang, Y.~Yu, L.~Guo, and B.~Wen.
\newblock Benchmarking adversarial robustness of image shadow removal with shadow-adaptive attacks.
\newblock In {\em Proc.~IEEE Int'l Conf.~Acoustics, Speech, and Signal Processing}, pages 13126--13130. IEEE, 2024.

\bibitem{wang2018stacked}
J.~Wang, X.~Li, and J.~Yang.
\newblock Stacked conditional generative adversarial networks for jointly learning shadow detection and shadow removal.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2018.

\bibitem{wang2023boosting}
K.~Wang, X.~He, W.~Wang, and X.~Wang.
\newblock Boosting adversarial transferability by block shuffle and rotation.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2024.

\bibitem{wang2021enhancing}
X.~Wang and K.~He.
\newblock Enhancing the transferability of adversarial attacks through variance tuning.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2021.

\bibitem{wang2021admix}
X.~Wang, X.~He, J.~Wang, and K.~He.
\newblock Admix: Enhancing the transferability of adversarial attacks.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2021.

\bibitem{wu2019skip}
D.~Wu, Y.~Wang, S.-T. Xia, J.~Bailey, and X.~Ma.
\newblock Skip connections matter: On the transferability of adversarial examples generated with resnets.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2019.

\bibitem{wu2023medical}
J.~Wu, R.~Fu, H.~Fang, Y.~Liu, Z.~Wang, Y.~Xu, Y.~Jin, and T.~Arbel.
\newblock Medical sam adapter: Adapting segment anything model for medical image segmentation.
\newblock {\em arXiv preprint arXiv:2304.12620}, 2023.

\bibitem{xiamitigating}
S.~Xia, Y.~Yu, X.~Jiang, and H.~Ding.
\newblock Mitigating the curse of dimensionality for certified robustness via dual randomized smoothing.
\newblock In {\em Proc.~Int'l Conf.~Learning Representations}, 2024.

\bibitem{xie2019improving}
C.~Xie, Z.~Zhang, Y.~Zhou, S.~Bai, J.~Wang, Z.~Ren, and A.~L. Yuille.
\newblock Improving transferability of adversarial examples with input diversity.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2019.

\bibitem{xu2023llm}
X.~Xu, K.~Kong, N.~Liu, L.~Cui, D.~Wang, J.~Zhang, and M.~Kankanhalli.
\newblock An llm can fool itself: A prompt-based adversarial attack.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2023.

\bibitem{yupurify}
Y.~Yu, Y.~Wang, S.~Xia, W.~Yang, S.~Lu, Y.-p. Tan, and A.~Kot.
\newblock Purify unlearnable examples via rate-constrained variational autoencoders.
\newblock In {\em Proc.~Int'l Conf.~Machine Learning}, 2024.

\bibitem{Yu_2023_CVPR}
Y.~Yu, Y.~Wang, W.~Yang, S.~Lu, Y.-P. Tan, and A.~C. Kot.
\newblock Backdoor attacks against deep image compression via adaptive frequency trigger.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, pages 12250--12259, June 2023.

\bibitem{yu2022towards}
Y.~Yu, W.~Yang, Y.-P. Tan, and A.~C. Kot.
\newblock Towards robust rain removal against adversarial attacks: A comprehensive benchmark analysis and beyond.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision and Pattern Recognition}, 2022.

\bibitem{zhang2023customized}
K.~Zhang and D.~Liu.
\newblock Customized segment anything model for medical image segmentation.
\newblock {\em arXiv preprint arXiv:2304.13785}, 2023.

\bibitem{zhao2021success}
Z.~Zhao, Z.~Liu, and M.~Larson.
\newblock On success and simplicity: A second look at transferable targeted attacks.
\newblock {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2021.

\bibitem{zhou2023advclip}
Z.~Zhou, S.~Hu, M.~Li, H.~Zhang, Y.~Zhang, and H.~Jin.
\newblock Advclip: Downstream-agnostic adversarial examples in multimodal contrastive learning.
\newblock In {\em Proceedings of the 31st ACM International Conference on Multimedia}, 2023.

\bibitem{zhou2023downstream}
Z.~Zhou, S.~Hu, R.~Zhao, Q.~Wang, L.~Y. Zhang, J.~Hou, and H.~Jin.
\newblock Downstream-agnostic adversarial examples.
\newblock In {\em Proc.~IEEE Int'l Conf.~Computer Vision}, 2023.

\bibitem{zhou2024securely}
Z.~Zhou, M.~Li, W.~Liu, S.~Hu, Y.~Zhang, W.~Wan, L.~Xue, L.~Y. Zhang, D.~Yao, and H.~Jin.
\newblock Securely fine-tuning pre-trained encoders against adversarial examples.
\newblock In {\em Proceedings of the 2024 IEEE Symposium on Security and Privacy (SP'24)}, 2024.

\bibitem{zhou2024dark}
Z.~Zhou, Y.~Song, M.~Li, S.~Hu, X.~Wang, L.~Y. Zhang, D.~Yao, and H.~Jin.
\newblock Darksam: Fooling segment anything model to segment nothing.
\newblock In {\em Proc.~Annual Conf.~Neural Information Processing Systems}, 2024.

\end{thebibliography}
