\begin{thebibliography}{10}

\bibitem{bommasani2022opportunities}
Rishi Bommasani, Drew~A. Hudson, Ehsan Adeli, et~al.
\newblock On the opportunities and risks of foundation models.
\newblock {\em arXiv:2108.07258}, 2022.

\bibitem{calian2022defending}
Dan~Andrei Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi,
  Andr{\'a}s Gy{\"o}rgy, Timothy~A Mann, and Sven Gowal.
\newblock Defending against image corruptions through adversarial
  augmentations.
\newblock In {\em ICLR}, 2022.

\bibitem{carmon2019unlabeled}
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John~C Duchi, and Percy~S
  Liang.
\newblock Unlabeled data improves adversarial robustness.
\newblock In {\em NeurIPS}, 2019.

\bibitem{cha2022domain}
Junbum Cha, Kyungjae Lee, Sungrae Park, and Sanghyuk Chun.
\newblock Domain generalization by mutual-information regularization with
  pre-trained models.
\newblock In {\em ECCV}, 2022.

\bibitem{CHAE2020108771}
Minwoo Chae and Stephen~G. Walker.
\newblock Wasserstein upper bounds of the total variation for smooth densities.
\newblock {\em Statistics and Probability Letters}, 163:108771, 2020.

\bibitem{chen2017learning}
Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Manmohan Chandraker.
\newblock Learning efficient object detection models with knowledge
  distillation.
\newblock In {\em NeurIPS}, 2017.

\bibitem{Chen2020WassersteinCR}
Liqun Chen, Zhe Gan, Dong Wang, Jingjing Liu, Ricardo Henao, and Lawrence
  Carin.
\newblock Wasserstein contrastive representation distillation.
\newblock {\em CVPR}, 2020.

\bibitem{cho2019efficacy}
Jang~Hyun Cho and Bharath Hariharan.
\newblock On the efficacy of knowledge distillation.
\newblock In {\em ICCV}, 2019.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em ICML}, 2020.

\bibitem{Cubuk_2019_CVPR}
Ekin~D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc~V. Le.
\newblock Autoaugment: Learning augmentation strategies from data.
\newblock In {\em CVPR}, June 2019.

\bibitem{cubuk2019randaugment}
Ekin~Dogus Cubuk, Barret Zoph, Jon Shlens, and Quoc Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em NeurIPS}, 2019.

\bibitem{dehghani2023scaling}
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, et~al.
\newblock Scaling vision transformers to 22 billion parameters.
\newblock In {\em ICML}, 2023.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv:2010.11929}, 2020.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em CVPR}, 2021.

\bibitem{fang2022data}
Alex Fang, Gabriel Ilharco, Mitchell Wortsman, Yuhao Wan, Vaishaal Shankar,
  Achal Dave, and Ludwig Schmidt.
\newblock Data determines distributional robustness in contrastive language
  image pre-training (clip).
\newblock In {\em ICML}, 2022.

\bibitem{geirhos2019imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock In {\em ICLR}, 2019.

\bibitem{ghiasi2021augmax}
Golnaz Ghiasi, Hugo Touvron, Tom DeVries, Tsung-Yi Lin, Yann LeCun, and Roozbeh
  Mottaghi.
\newblock Augmax: Adversarial composition of mixtures for robust data
  augmentation.
\newblock {\em arXiv:2106.00582}, 2021.

\bibitem{gine2021mathematical}
Evarist Gin{\'e} and Richard Nickl.
\newblock {\em Mathematical foundations of infinite-dimensional statistical
  models}.
\newblock Cambridge university press, 2021.

\bibitem{goldblum2020ard}
Micah Goldblum, Liam Fowl, Soheil Feizi, and Tom Goldstein.
\newblock Adversarially robust distillation.
\newblock {\em AAAI}, 2020.

\bibitem{gong2021maxup}
Chengyue Gong, Tongzheng Ren, Mao Ye, and Qiang Liu.
\newblock Maxup: A simple way to improve generalization of neural network
  training.
\newblock In {\em CVPR}, 2021.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv:1412.6572}, 2014.

\bibitem{gowal2020achieving}
Sven Gowal, Chuan Qin, Po-Sen Huang, Taylan Cemgil, Krishnamurthy Dvijotham,
  Tim Mann, and Pushmeet Kohli.
\newblock Achieving robustness in the wild via adversarial mixing with
  disentangled representations.
\newblock In {\em CVPR}, 2020.

\bibitem{gowal2021improving}
Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg,
  Dan~Andrei Calian, and Timothy~A Mann.
\newblock Improving robustness using generated data.
\newblock {\em NeurIPS}, 2021.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{hendrycks2021manyfaces}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob
  Steinhardt, and Justin Gilmer.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In {\em ICCV}, 2021.

\bibitem{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In {\em ICLR}, 2019.

\bibitem{hendrycks2019augmix}
Dan Hendrycks, Norman Mu, Ekin~D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji
  Lakshminarayanan.
\newblock Augmix: A simple data processing method to improve robustness and
  uncertainty.
\newblock {\em ICLR}, 2019.

\bibitem{hendrycks2021natural}
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
\newblock Natural adversarial examples.
\newblock In {\em CVPR}, 2021.

\bibitem{heo2019knowledge}
Byeongho Heo, Minsik Lee, Sangdoo Yun, and Jin~Young Choi.
\newblock Knowledge transfer via distillation of activation boundaries formed
  by hidden neurons.
\newblock In {\em AAAI}, 2019.

\bibitem{herrmann2022pyramid}
Charles Herrmann, Kyle Sargent, Lu~Jiang, Ramin Zabih, Huiwen Chang, Ce~Liu,
  Dilip Krishnan, and Deqing Sun.
\newblock Pyramid adversarial training improves vit performance.
\newblock In {\em CVPR}, 2022.

\bibitem{hinton2015kd}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv:1503.02531}, 2015.

\bibitem{huang2022knowledge}
Tao Huang, Shan You, Fei Wang, Chen Qian, and Chang Xu.
\newblock Knowledge distillation from a stronger teacher.
\newblock In {\em NeurIPS}, 2022.

\bibitem{Huang_2023_ICCV}
Zeyi Huang, Andy Zhou, Zijian Ling, Mu~Cai, Haohan Wang, and Yong~Jae Lee.
\newblock A sentence speaks a thousand images: Domain generalization through
  distilling clip with language guidance.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 11685--11695, October 2023.

\bibitem{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em CVPR}, 2019.

\bibitem{kim2023feature}
Woo~Jae Kim, Yoonki Cho, Junsik Jung, and Sung-Eui Yoon.
\newblock Feature separation and recalibration for adversarial robustness.
\newblock In {\em CVPR}, 2023.

\bibitem{li2020shape}
Yingwei Li, Qihang Yu, Mingxing Tan, Jieru Mei, Peng Tang, Wei Shen, Alan
  Yuille, et~al.
\newblock Shape-texture debiased neural network training.
\newblock In {\em ICLR}, 2020.

\bibitem{liu2023towards}
Haoyang Liu, Maheep Chaudhary, and Haohan Wang.
\newblock Towards trustworthy and aligned machine learning: A data-centric
  survey with causality perspectives.
\newblock {\em arXiv:2307.16851}, 2023.

\bibitem{liu2019knowledge}
Yufan Liu, Jiajiong Cao, Bing Li, Chunfeng Yuan, Weiming Hu, Yangxi Li, and
  Yunqiang Duan.
\newblock Knowledge distillation via instance relationship graph.
\newblock In {\em CVPR}, 2019.

\bibitem{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em ICLR}, 2018.

\bibitem{mao2022discrete}
Chengzhi Mao, Lu~Jiang, Mostafa Dehghani, Carl Vondrick, Rahul Sukthankar, and
  Irfan Essa.
\newblock Discrete representations strengthen vision transformer robustness.
\newblock In {\em ICLR}, 2022.

\bibitem{mao2022dat}
Xiaofeng Mao, Yuefeng Chen, Ranjie Duan, Yao Zhu, Gege Qi, Shaokai Ye, Xiaodan
  Li, Rong Zhang, and Hui Xue.
\newblock Enhance the visual representation via discrete adversarial training.
\newblock In {\em NeurIPS}, 2022.

\bibitem{mei2022fast}
Jieru Mei, Yucheng Han, Yutong Bai, Yixiao Zhang, Yingwei Li, Xianhang Li, Alan
  Yuille, and Cihang Xie.
\newblock Fast advprop.
\newblock In {\em ICLR}, 2022.

\bibitem{menon2021statistical}
Aditya~K Menon, Ankit~Singh Rawat, Sashank Reddi, Seungyeon Kim, and Sanjiv
  Kumar.
\newblock A statistical perspective on distillation.
\newblock In {\em ICML}, 2021.

\bibitem{park2019relational}
Wonpyo Park, Dongju Kim, Yan Lu, and Minsu Cho.
\newblock Relational knowledge distillation.
\newblock In {\em CVPR}, 2019.

\bibitem{passalis2018learning}
Nikolaos Passalis and Anastasios Tefas.
\newblock Learning deep representations with probabilistic knowledge transfer.
\newblock In {\em ECCV}, 2018.

\bibitem{qin2019adversarial}
C.~Qin, J.~Martens, S.~Gowal, D.~Krishnan, K.~Dvijotham, A.~Fawzi, S.~De,
  R.~Stanforth, and P.~Kohli.
\newblock Adversarial robustness through local linearization.
\newblock In {\em NeurIPS}, 2019.

\bibitem{rade2021reducing}
Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli.
\newblock Reducing excessive margin to achieve a better accuracy vs. robustness
  trade-off.
\newblock In {\em ICLR}, 2021.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em ICML}, 2021.

\bibitem{raghunathan2020understanding_icml}
Aditi Raghunathan, Sang~Michael Xie, Fanny Yang, John~C. Duchi, and Percy
  Liang.
\newblock Understanding and mitigating the tradeoff between robustness and
  accuracy.
\newblock In {\em ICML}, 2020.

\bibitem{rebuffi2023revisiting}
Sylvestre-Alvise Rebuffi, Francesco Croce, and Sven Gowal.
\newblock Revisiting adapters with adversarial training.
\newblock In {\em ICLR}, 2023.

\bibitem{recht2019imagenet}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In {\em ICML}, 2019.

\bibitem{Robey2021ModelBasedDG}
Alexander Robey, George~J. Pappas, and Hamed Hassani.
\newblock Model-based domain generalization.
\newblock In {\em NeurIPS}, 2021.

\bibitem{rombach2021highresolution}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj√∂rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em CVPR}, 2022.

\bibitem{romero2015fitnets}
Adriana Romero, Nicolas Ballas, Samira~Ebrahimi Kahou, Antoine Chassang, Carlo
  Gatta, and Yoshua Bengio.
\newblock Fitnets: Hints for thin deep nets.
\newblock In {\em ICLR}, 2015.

\bibitem{sanh2020distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and
  lighter.
\newblock {\em arXiv:1910.01108}, 2020.

\bibitem{schmidt2018adversarially}
L.~Schmidt, S.~Santurkar, D.~Tsipras, K.~Talwar, and A.~Madry.
\newblock Adversarially robust generalization requires more data.
\newblock In {\em NeurIPS}, 2018.

\bibitem{schuhmann2022laion5b}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, Patrick Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig
  Schmidt, Robert Kaczmarczyk, and Jenia Jitsev.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock In {\em NeurIPS}, 2022.

\bibitem{shamsabadi2020colorfool}
Ali~Shahin Shamsabadi, Ricardo Sanchez-Matilla, and Andrea Cavallaro.
\newblock Colorfool: Semantic adversarial colorization.
\newblock In {\em CVPR}, 2020.

\bibitem{steiner2022train}
Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob
  Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in
  vision transformers.
\newblock {\em arXiv:2106.10270}, 2022.

\bibitem{szegedy2019intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, D.~Erhan,
  Ian~J. Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em ICLR}, 2014.

\bibitem{tack2022consistency}
Jihoon Tack, Sihyun Yu, Jongheon Jeong, Minseon Kim, Sung~Ju Hwang, and Jinwoo
  Shin.
\newblock Consistency regularization for adversarial robustness.
\newblock In {\em AAAI}, 2022.

\bibitem{taori2020measuring}
Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht,
  and Ludwig Schmidt.
\newblock Measuring robustness to natural distribution shifts in image
  classification.
\newblock {\em arXiv:2007.00644}, 2020.

\bibitem{tian2019crd}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive representation distillation.
\newblock In {\em ICLR}, 2020.

\bibitem{tsipras2019robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In {\em ICML}, 2019.

\bibitem{tu2019theoretical}
Zhuozhuo Tu, Jingwei Zhang, and Dacheng Tao.
\newblock Theoretical analysis of adversarial learning: A minimax approach.
\newblock In {\em NeurIPS}, 2019.

\bibitem{tung2019similarity}
Frederick Tung and Greg Mori.
\newblock Similarity-preserving knowledge distillation.
\newblock In {\em CVPR}, 2019.

\bibitem{oord2017neural}
Aaron van~den Oord, Oriol Vinyals, and Koray Kavukcuoglu.
\newblock Neural discrete representation learning.
\newblock In {\em NeurIPS}, 2017.

\bibitem{wang2019learning}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock In {\em NeurIPS}, 2019.

\bibitem{wang2022toward2}
Haohan Wang, Zeyi Huang, Xindi Wu, and Eric Xing.
\newblock Toward learning robust and invariant representations with alignment
  regularization and data augmentation.
\newblock In {\em Proceedings of the 28th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining}, 2022.

\bibitem{wang2020high}
Haohan Wang, Xindi Wu, Zeyi Huang, and Eric~P Xing.
\newblock High-frequency component helps explain the generalization of
  convolutional neural networks.
\newblock In {\em CVPR}, 2020.

\bibitem{wang2020collaborative}
Huan Wang, Yijun Li, Yuehai Wang, Haoji Hu, and Ming-Hsuan Yang.
\newblock Collaborative distillation for ultra-resolution universal style
  transfer.
\newblock In {\em CVPR}, 2020.

\bibitem{wang2022dakd}
Huan Wang, Suhas Lohit, Mike Jones, and Yun Fu.
\newblock What makes a "good" data augmentation in knowledge distillation -- a
  statistical perspective.
\newblock {\em NeurIPS}, 2020.

\bibitem{wu2020adversarial}
D.~Wu, S.-T. Xia, and Y.~Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In {\em NeurIPS}, 2020.

\bibitem{xie2020adversarial}
Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan Yuille, and Quoc~V. Le.
\newblock Adversarial examples improve image recognition.
\newblock In {\em CVPR}, 2020.

\bibitem{yang2022image}
Suorong Yang, Weikang Xiao, Mengcheng Zhang, Suhan Guo, Jian Zhao, and Furao
  Shen.
\newblock Image data augmentation for deep learning: A survey.
\newblock {\em arXiv:2204.08610}, 2022.

\bibitem{https://doi.org/10.48550/arxiv.2205.01917}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
  Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock {\em arXiv:2205.01917}, 2022.

\bibitem{zagoruyko2017attention}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Paying more attention to attention: Improving the performance of
  convolutional neural networks via attention transfer.
\newblock In {\em ICLR}, 2017.

\bibitem{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em ICML}, 2019.

\bibitem{zhang2018mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock Mixup: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\bibitem{zhang2023foundation}
Peiyan Zhang, Haoyang Liu, Chaozhuo Li, Xing Xie, Sunghun Kim, and Haohan Wang.
\newblock Foundation model-oriented robustness: Robust image model evaluation
  with pretrained models.
\newblock {\em arXiv:2308.10632}, 2023.

\bibitem{zhang2019adversarial}
Xinyu Zhang, Qiang Wang, Jian Zhang, and Zhao Zhong.
\newblock Adversarial autoaugment.
\newblock In {\em ICLR}, 2019.

\bibitem{Zhao2022EnhancedAA}
Shiji Zhao, Jie Yu, Zhenlong Sun, Bo~Zhang, and Xingxing Wei.
\newblock Enhanced accuracy and robustness via multi-teacher adversarial
  distillation.
\newblock In {\em ECCV}, 2022.

\bibitem{zi2021rslad}
Bojia Zi, Shihao Zhao, Xingjun Ma, and Yu-Gang Jiang.
\newblock Revisiting adversarial robustness distillation: Robust soft labels
  make student better.
\newblock {\em ICCV}, 2021.

\end{thebibliography}
