\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Dyn()]{DynamicalDeepGenerative}
Dynamical {{Deep Generative Latent Modeling}} of {{3D Skeletal Motion}}
  {\textbar} {{International Journal}} of {{Computer Vision}}.
\newblock
  https://link-springer-com.cmu.idm.oclc.org/article/10.1007/s11263-022-01668-8.

\bibitem[Abbeel and Ng(2004)]{abbeel2004apprenticeship}
Pieter Abbeel and Andrew~Y Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{ICML}, 2004.

\bibitem[Bain and Sammut(1995)]{bain1995framework}
Michael Bain and Claude Sammut.
\newblock A framework for behavioural cloning.
\newblock In \emph{Machine Intelligence 15}, 1995.

\bibitem[Baldassano et~al.(2017)Baldassano, Chen, Zadbood, Pillow, Hasson, and
  Norman]{baldassano2017discovering}
Christopher Baldassano, Janice Chen, Asieh Zadbood, Jonathan~W Pillow, Uri
  Hasson, and Kenneth~A Norman.
\newblock Discovering event structure in continuous narrative perception and
  memory.
\newblock \emph{Neuron}, 95\penalty0 (3):\penalty0 709--721, 2017.

\bibitem[Bareinboim et~al.(2014)Bareinboim, Tian, and
  Pearl]{bareinboim2014recovering}
Elias Bareinboim, Jin Tian, and Judea Pearl.
\newblock Recovering from selection bias in causal and statistical inference.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~28, 2014.

\bibitem[Bera et~al.(2020)Bera, Goecks, Gremillion, Valasek, and
  Waytowich]{beraPODNetNeuralNetwork2020}
Ritwik Bera, Vinicius~G. Goecks, Gregory~M. Gremillion, John Valasek, and
  Nicholas~R. Waytowich.
\newblock {{PODNet}}: {{A Neural Network}} for {{Discovery}} of {{Plannable
  Options}}, February 2020.

\bibitem[Chen et~al.(2023)Chen, Tamboli, Lan, and
  Aggarwal]{chenMultitaskHierarchicalAdversarial2023}
Jiayu Chen, Dipesh Tamboli, Tian Lan, and Vaneet Aggarwal.
\newblock Multi-task {{Hierarchical Adversarial Inverse Reinforcement
  Learning}}.
\newblock In \emph{Proceedings of the 40th {{International Conference}} on
  {{Machine Learning}}}, pages 4895--4920. PMLR, July 2023.

\bibitem[Chen et~al.(2024)Chen, Zoeter, and Mooij]{chen2024modeling}
Leihao Chen, Onno Zoeter, and Joris~M Mooij.
\newblock Modeling latent selection with structural causal models.
\newblock \emph{arXiv preprint arXiv:2401.06925}, 2024.

\bibitem[Chen et~al.(2018)Chen, Amiri, and
  Prakash]{chenAutomaticSegmentationData2018}
Liangzhe Chen, Sorour~E. Amiri, and B.~Aditya Prakash.
\newblock Automatic {{Segmentation}} of {{Data Sequences}}.
\newblock \emph{AAAI}, 32\penalty0 (1), April 2018.
\newblock ISSN 2374-3468, 2159-5399.
\newblock \doi{10.1609/aaai.v32i1.11815}.

\bibitem[Correa et~al.(2019)Correa, Tian, and
  Bareinboim]{CorreaTianBareinboim2019}
Juan~D. Correa, Jin Tian, and Elias Bareinboim.
\newblock Identification of causal effects in the presence of selection bias.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 2744--2751, 2019.

\bibitem[De~Haan et~al.(2019)De~Haan, Jayaraman, and Levine]{de2019causal}
Pim De~Haan, Dinesh Jayaraman, and Sergey Levine.
\newblock Causal confusion in imitation learning.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Denil et~al.(2017)Denil, Colmenarejo, Cabi, Saxton, and
  De~Freitas]{denil2017programmable}
Misha Denil, Sergio~G{\'o}mez Colmenarejo, Serkan Cabi, David Saxton, and Nando
  De~Freitas.
\newblock Programmable agents.
\newblock \emph{arXiv preprint arXiv:1706.06383}, 2017.

\bibitem[Eberhardt and Scheines(2007)]{eberhardt2007interventions}
Frederick Eberhardt and Richard Scheines.
\newblock Interventions and causal inference.
\newblock \emph{Philosophy of science}, 74\penalty0 (5):\penalty0 981--995,
  2007.

\bibitem[Finn et~al.(2016)Finn, Levine, and Abbeel]{finn2016guided}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In \emph{ICML}, 2016.

\bibitem[Florensa et~al.(2017)Florensa, Duan, and
  Abbeel]{florensa2017stochastic}
Carlos Florensa, Yan Duan, and Pieter Abbeel.
\newblock Stochastic neural networks for hierarchical reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1704.03012}, 2017.

\bibitem[Forr{\'e} and Mooij(2020)]{forre2020causal}
Patrick Forr{\'e} and Joris~M Mooij.
\newblock Causal calculus in the presence of cycles, latent confounders and
  selection bias.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 71--80. PMLR,
  2020.

\bibitem[Fox et~al.(2017)Fox, Krishnan, Stoica, and
  Goldberg]{foxMultiLevelDiscoveryDeep2017}
Roy Fox, Sanjay Krishnan, Ion Stoica, and Ken Goldberg.
\newblock Multi-{{Level Discovery}} of {{Deep Options}}, October 2017.

\bibitem[Fu et~al.(2018)Fu, Luo, and Levine]{fu2017learning}
Justin Fu, Katie Luo, and Sergey Levine.
\newblock Learning robust rewards with adverserial inverse reinforcement
  learning.
\newblock In \emph{ICLR}, 2018.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{fu2020d4rl}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Gehring et~al.(2021)Gehring, Synnaeve, Krause, and
  Usunier]{gehring2021hierarchical}
Jonas Gehring, Gabriel Synnaeve, Andreas Krause, and Nicolas Usunier.
\newblock Hierarchical skills for efficient exploration.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11553--11564, 2021.

\bibitem[Griffiths et~al.(2019)Griffiths, Callaway, Chang, Grant, Krueger, and
  Lieder]{griffiths2019doing}
Thomas~L Griffiths, Frederick Callaway, Michael~B Chang, Erin Grant, Paul~M
  Krueger, and Falk Lieder.
\newblock Doing more with less: meta-reasoning and meta-learning in humans and
  machines.
\newblock \emph{Current Opinion in Behavioral Sciences}, 29:\penalty0 24--30,
  2019.

\bibitem[Gupta et~al.(2019)Gupta, Kumar, Lynch, Levine, and
  Hausman]{guptaRelayPolicyLearning2019}
Abhishek Gupta, Vikash Kumar, Corey Lynch, Sergey Levine, and Karol Hausman.
\newblock Relay {{Policy Learning}}: {{Solving Long-Horizon Tasks}} via
  {{Imitation}} and {{Reinforcement Learning}}, October 2019.

\bibitem[Hafner et~al.(2022)Hafner, Lee, Fischer, and
  Abbeel]{hafnerDeepHierarchicalPlanning2022}
Danijar Hafner, Kuang-Huei Lee, Ian Fischer, and Pieter Abbeel.
\newblock Deep {{Hierarchical Planning}} from {{Pixels}}, June 2022.

\bibitem[Heckman(1979)]{heckman1979sample}
James~J Heckman.
\newblock Sample selection bias as a specification error.
\newblock \emph{Econometrica: Journal of the econometric society}, pages
  153--161, 1979.

\bibitem[Hern{\'a}n et~al.(2004)Hern{\'a}n, Hern{\'a}ndez-D{\'\i}az, and
  Robins]{hernan2004structural}
Miguel~A Hern{\'a}n, Sonia Hern{\'a}ndez-D{\'\i}az, and James~M Robins.
\newblock A structural approach to selection bias.
\newblock \emph{Epidemiology}, pages 615--625, 2004.

\bibitem[Ho and Ermon(2016)]{ho2016generative}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Hussein et~al.(2017)Hussein, Gaber, Elyan, and
  Jayne]{hussein2017imitation}
Ahmed Hussein, Mohamed~Medhat Gaber, Eyad Elyan, and Chrisina Jayne.
\newblock Imitation learning: A survey of learning methods.
\newblock \emph{ACM Computing Surveys (CSUR)}, 50\penalty0 (2):\penalty0 1--35,
  2017.

\bibitem[Jiang et~al.()Jiang, Liu, Eysenbach, Kolter, and
  Finn]{jiangLearningOptionsCompression}
Yiding Jiang, Evan~Zheran Liu, Benjamin Eysenbach, J~Zico Kolter, and Chelsea
  Finn.
\newblock Learning {{Options}} via {{Compression}}.
\newblock page~26.

\bibitem[Jing et~al.(2021)Jing, Huang, Sun, Ma, Kong, Gan, and
  Li]{jingAdversarialOptionAwareHierarchical2021}
Mingxuan Jing, Wenbing Huang, Fuchun Sun, Xiaojian Ma, Tao Kong, Chuang Gan,
  and Lei Li.
\newblock Adversarial {{Option-Aware Hierarchical Imitation Learning}}, June
  2021.

\bibitem[Kim et~al.(2019)Kim, Ahn, and Bengio]{kim2019variational}
Taesup Kim, Sungjin Ahn, and Yoshua Bengio.
\newblock Variational temporal abstraction.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Kipf et~al.(2019)Kipf, Li, Dai, Zambaldi, {Sanchez-Gonzalez},
  Grefenstette, Kohli, and Battaglia]{kipfCompILECompositionalImitation2019}
Thomas Kipf, Yujia Li, Hanjun Dai, Vinicius Zambaldi, Alvaro
  {Sanchez-Gonzalez}, Edward Grefenstette, Pushmeet Kohli, and Peter Battaglia.
\newblock {{CompILE}}: {{Compositional Imitation Learning}} and {{Execution}},
  May 2019.

\bibitem[Krishnan et~al.(2017)Krishnan, Fox, Stoica, and
  Goldberg]{krishnanDDCODiscoveryDeep2017}
Sanjay Krishnan, Roy Fox, Ion Stoica, and Ken Goldberg.
\newblock {{DDCO}}: {{Discovery}} of {{Deep Continuous Options}} for {{Robot
  Learning}} from {{Demonstrations}}, October 2017.

\bibitem[LeCun(2022)]{lecunPathAutonomousMachine}
Yann LeCun.
\newblock A {{Path Towards Autonomous Machine Intelligence Version}} 0.9.2,
  2022-06-27.
\newblock 2022.

\bibitem[Lee and Seung(1999)]{leeLearningPartsObjects1999}
Daniel~D. Lee and H.~Sebastian Seung.
\newblock Learning the parts of objects by non-negative matrix factorization.
\newblock \emph{Nature}, 401\penalty0 (6755):\penalty0 788--791, October 1999.
\newblock ISSN 1476-4687.
\newblock \doi{10.1038/44565}.

\bibitem[Lee(2020)]{Lee2020}
Sang-Hyun Lee.
\newblock Learning compound tasks without task-specific knowledge via imitation
  and self-supervised learning.
\newblock 2020.

\bibitem[Lee et~al.(2021)Lee, Zhao, Sawhney, Girdhar, and
  Kroemer]{lee2021causal}
Tabitha~E Lee, Jialiang~Alan Zhao, Amrita~S Sawhney, Siddharth Girdhar, and
  Oliver Kroemer.
\newblock Causal reasoning in simulation for structure and transfer learning of
  robot manipulation policies.
\newblock In \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 4776--4782. IEEE, 2021.

\bibitem[Levine(2018)]{levineReinforcementLearningControl2018}
Sergey Levine.
\newblock Reinforcement {{Learning}} and {{Control}} as {{Probabilistic
  Inference}}: {{Tutorial}} and {{Review}}, May 2018.

\bibitem[Mackevicius et~al.(2019)Mackevicius, Bahle, Williams, Gu, Denisenko,
  Goldman, and Fee]{mackeviciusUnsupervisedDiscoveryTemporal2019a}
Emily~L Mackevicius, Andrew~H Bahle, Alex~H Williams, Shijie Gu, Natalia~I
  Denisenko, Mark~S Goldman, and Michale~S Fee.
\newblock Unsupervised discovery of temporal sequences in high-dimensional
  datasets, with applications to neuroscience.
\newblock \emph{eLife}, 8:\penalty0 e38471, February 2019.
\newblock ISSN 2050-084X.
\newblock \doi{10.7554/eLife.38471}.

\bibitem[Matsubara et~al.(2014)Matsubara, Sakurai, and
  Faloutsos]{matsubaraAutoPlaitAutomaticMining2014}
Yasuko Matsubara, Yasushi Sakurai, and Christos Faloutsos.
\newblock {{AutoPlait}}: Automatic mining of co-evolving time sequences.
\newblock In \emph{Proceedings of the 2014 {{ACM SIGMOD International
  Conference}} on {{Management}} of {{Data}}}, {{SIGMOD}} '14, pages 193--204,
  New York, NY, USA, June 2014. Association for Computing Machinery.
\newblock ISBN 978-1-4503-2376-5.
\newblock \doi{10.1145/2588555.2588556}.

\bibitem[McGovern and Barto(2001)]{mcgovernAutomaticDiscoverySubgoals2001}
Amy McGovern and Andrew~G Barto.
\newblock Automatic {{Discovery}} of {{Subgoals}} in {{Reinforcement Learning}}
  using {{Diverse Density}}.
\newblock 2001.

\bibitem[Murphy(2002)]{murphy2002dynamic}
Kevin~Patrick Murphy.
\newblock \emph{Dynamic bayesian networks: representation, inference and
  learning}.
\newblock University of California, Berkeley, 2002.

\bibitem[Ng et~al.(2000)Ng, Russell, et~al.]{ng2000algorithms}
Andrew~Y Ng, Stuart~J Russell, et~al.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{ICML}, 2000.

\bibitem[Paul et~al.(2019)Paul, Vanbaar, and
  {Roy-Chowdhury}]{paulLearningTrajectoriesSubgoal2019}
Sujoy Paul, Jeroen Vanbaar, and Amit {Roy-Chowdhury}.
\newblock Learning from {{Trajectories}} via {{Subgoal Discovery}}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}},
  volume~32. Curran Associates, Inc., 2019.

\bibitem[Pearl(2009)]{pearl2009causality}
Judea Pearl.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Seyed~Ghasemipour et~al.(2019)Seyed~Ghasemipour, Gu, and
  Zemel]{seyed2019smile}
Seyed~Kamyar Seyed~Ghasemipour, Shixiang~Shane Gu, and Richard Zemel.
\newblock Smile: Scalable meta inverse reinforcement learning through
  context-conditional policies.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Sharma et~al.(2019{\natexlab{a}})Sharma, Sharma, Rhinehart, and
  Kitani]{Sharma2019}
Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, and Kris~M Kitani.
\newblock {{DIRECTED-INFO GAIL}}: {{LEARNING HIERARCHICAL POLICIES FROM
  UNSEGMENTED DEMONSTRATIONS USING DIRECTED INFORMATION}}.
\newblock 2019{\natexlab{a}}.

\bibitem[Sharma et~al.(2019{\natexlab{b}})Sharma, Sharma, Rhinehart, and
  Kitani]{sharmaDirectedInfoGAILLearning2019}
Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, and Kris~M. Kitani.
\newblock Directed-{{Info GAIL}}: {{Learning Hierarchical Policies}} from
  {{Unsegmented Demonstrations}} using {{Directed Information}}, March
  2019{\natexlab{b}}.

\bibitem[{\c S}im{\c s}ek and Barto(2004)]{simsekUsingRelativeNovelty2004}
{\"O}zg{\"u}r {\c S}im{\c s}ek and Andrew~G. Barto.
\newblock Using relative novelty to identify useful temporal abstractions in
  reinforcement learning.
\newblock In \emph{Twenty-First International Conference on {{Machine}}
  Learning - {{ICML}} '04}, page~95, Banff, Alberta, Canada, 2004. ACM Press.
\newblock \doi{10.1145/1015330.1015353}.

\bibitem[{\c S}im{\c s}ek et~al.(2005){\c S}im{\c s}ek, Wolfe, and
  Barto]{simsekIdentifyingUsefulSubgoals2005}
{\"O}zg{\"u}r {\c S}im{\c s}ek, Alicia~P. Wolfe, and Andrew~G. Barto.
\newblock Identifying useful subgoals in reinforcement learning by local graph
  partitioning.
\newblock In \emph{Proceedings of the 22nd International Conference on
  {{Machine}} Learning - {{ICML}} '05}, pages 816--823, Bonn, Germany, 2005.
  ACM Press.
\newblock ISBN 978-1-59593-180-1.
\newblock \doi{10.1145/1102351.1102454}.

\bibitem[Smaragdis(2004)]{smaragdis2004non}
Paris Smaragdis.
\newblock Non-negative matrix factor deconvolution; extraction of multiple
  sound sources from monophonic inputs.
\newblock In \emph{Independent Component Analysis and Blind Signal Separation:
  Fifth International Conference, ICA 2004, Granada, Spain, September 22-24,
  2004. Proceedings 5}, pages 494--499. Springer, 2004.

\bibitem[Smaragdis(2006)]{smaragdis2006convolutive}
Paris Smaragdis.
\newblock Convolutive speech bases and their application to supervised speech
  separation.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  15\penalty0 (1):\penalty0 1--12, 2006.

\bibitem[Spirtes et~al.(1995)Spirtes, Meek, and Richardson]{spirtes1995causal}
Peter Spirtes, Christopher Meek, and Thomas Richardson.
\newblock Causal inference in the presence of latent variables and selection
  bias.
\newblock In \emph{Proceedings of the Eleventh conference on Uncertainty in
  artificial intelligence}, pages 499--506, 1995.

\bibitem[Spirtes et~al.(2001)Spirtes, Glymour, and
  Scheines]{spirtes2001causation}
Peter Spirtes, Clark Glymour, and Richard Scheines.
\newblock \emph{Causation, prediction, and search}.
\newblock MIT press, 2001.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Sutton et~al.(1999)Sutton, Precup, and Singh]{sutton1999between}
Richard~S Sutton, Doina Precup, and Satinder Singh.
\newblock Between mdps and semi-mdps: A framework for temporal abstraction in
  reinforcement learning.
\newblock \emph{Artificial intelligence}, 112\penalty0 (1-2):\penalty0
  181--211, 1999.

\bibitem[Tanneberg et~al.(2021)Tanneberg, Ploeger, Rueckert, and
  Peters]{tannebergSKIDRAWSkill2021}
Daniel Tanneberg, Kai Ploeger, Elmar Rueckert, and Jan Peters.
\newblock {{SKID RAW}}: {{Skill Discovery From Raw Trajectories}}.
\newblock \emph{IEEE Robot. Autom. Lett.}, 6\penalty0 (3):\penalty0 4696--4703,
  July 2021.
\newblock ISSN 2377-3766, 2377-3774.
\newblock \doi{10.1109/LRA.2021.3068891}.

\bibitem[Thrun and O'Sullivan(1996)]{thrun1996discovering}
Sebastian Thrun and Joseph O'Sullivan.
\newblock Discovering structure in multiple learning tasks: The tc algorithm.
\newblock In \emph{ICML}, volume~96, pages 489--497. Citeseer, 1996.

\bibitem[Versteeg et~al.(2022)Versteeg, Mooij, and Zhang]{versteeg2022local}
Philip Versteeg, Joris Mooij, and Cheng Zhang.
\newblock Local constraint-based causal discovery under selection bias.
\newblock In \emph{Conference on Causal Learning and Reasoning}, pages
  840--860. PMLR, 2022.

\bibitem[Wang et~al.(2014)Wang, Fan, Song, Gao, and
  Chen]{wangReinforcementLearningTransfer2014}
Hao Wang, Shunguo Fan, Jinhua Song, Yang Gao, and Xingguo Chen.
\newblock Reinforcement learning transfer based on subgoal discovery and
  subtask similarity.
\newblock \emph{IEEE/CAA Journal of Automatica Sinica}, 1\penalty0
  (3):\penalty0 257--266, July 2014.
\newblock ISSN 2329-9274.
\newblock \doi{10.1109/JAS.2014.7004683}.

\bibitem[Yu et~al.(2019)Yu, Yu, Finn, and Ermon]{Yu2019}
Lantao Yu, Tianhe Yu, Chelsea Finn, and Stefano Ermon.
\newblock Meta-inverse reinforcement learning with probabilistic context
  variables.
\newblock September 2019.

\bibitem[Zacks et~al.(2001)Zacks, Tversky, and Iyer]{zacks2001perceiving}
Jeffrey~M Zacks, Barbara Tversky, and Gowri Iyer.
\newblock Perceiving, remembering, and communicating structure in events.
\newblock \emph{Journal of experimental psychology: General}, 130\penalty0
  (1):\penalty0 29, 2001.

\bibitem[Zhang et~al.(2021)Zhang, Pertsch, Yang, and Lim]{zhang2021minimum}
Jesse Zhang, Karl Pertsch, Jiefan Yang, and Joseph~J Lim.
\newblock Minimum description length skills for accelerated reinforcement
  learning.
\newblock In \emph{Self-Supervision for Reinforcement Learning Workshop-ICLR},
  volume 2021, 2021.

\bibitem[Zhang(2008)]{zhang2008completeness}
Jiji Zhang.
\newblock On the completeness of orientation rules for causal discovery in the
  presence of latent confounders and selection bias.
\newblock \emph{Artificial Intelligence}, 172\penalty0 (16-17):\penalty0
  1873--1896, 2008.

\bibitem[Zhang et~al.(2016)Zhang, Zhang, Huang, Sch{\"o}lkopf, and
  Glymour]{zhang2016identifiability}
Kun Zhang, Jiji Zhang, Biwei Huang, Bernhard Sch{\"o}lkopf, and Clark Glymour.
\newblock On the identifiability and estimation of functional causal models in
  the presence of outcome-dependent selection.
\newblock In \emph{UAI}, 2016.

\bibitem[Zheng et~al.(2024)Zheng, Tang, Qiu, Sch{\"o}lkopf, and
  Zhang]{zheng2024detecting}
Yujia Zheng, Zeyu Tang, Yiwen Qiu, Bernhard Sch{\"o}lkopf, and Kun Zhang.
\newblock Detecting and identifying selection structure in sequential data.
\newblock In \emph{ICML}, 2024.

\bibitem[Zhu et~al.(2022)Zhu, Stone, and Zhu]{zhu2022bottom}
Yifeng Zhu, Peter Stone, and Yuke Zhu.
\newblock Bottom-up skill discovery from unsegmented demonstrations for
  long-horizon robot manipulation.
\newblock \emph{IEEE Robotics and Automation Letters}, 7\penalty0 (2):\penalty0
  4126--4133, 2022.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and
  Dey]{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{AAAI}, 2008.

\end{thebibliography}
