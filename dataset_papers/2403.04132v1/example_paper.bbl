\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain, Fort, Ganguli, Henighan, et~al.]{bai2022training}
Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., DasSarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T., et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022.

\bibitem[Boubdir et~al.(2023)Boubdir, Kim, Ermis, Hooker, and Fadaee]{boubdir2023elo}
Boubdir, M., Kim, E., Ermis, B., Hooker, S., and Fadaee, M.
\newblock Elo uncovered: Robustness and best practices in language model evaluation, 2023.

\bibitem[Bradley \& Terry(1952)Bradley and Terry]{bradley1952rank}
Bradley, R.~A. and Terry, M.~E.
\newblock Rank analysis of incomplete block designs: I. the method of paired comparisons.
\newblock \emph{Biometrika}, 39\penalty0 (3/4):\penalty0 324--345, 1952.

\bibitem[Busa-Fekete et~al.(2014{\natexlab{a}})Busa-Fekete, Huellermeier, and Szörényi]{pmlr-v32-busa-fekete14}
Busa-Fekete, R., Huellermeier, E., and Szörényi, B.
\newblock Preference-based rank elicitation using statistical models: The case of mallows.
\newblock In Xing, E.~P. and Jebara, T. (eds.), \emph{Proceedings of the 31st International Conference on Machine Learning}, volume~32 of \emph{Proceedings of Machine Learning Research}, pp.\  1071--1079, Bejing, China, 22--24 Jun 2014{\natexlab{a}}. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v32/busa-fekete14.html}.

\bibitem[Busa-Fekete et~al.(2014{\natexlab{b}})Busa-Fekete, Huellermeier, and Szörényi]{preference_rank_elicitation}
Busa-Fekete, R., Huellermeier, E., and Szörényi, B.
\newblock Preference-based rank elicitation using statistical models: The case of mallows.
\newblock In Xing, E.~P. and Jebara, T. (eds.), \emph{Proceedings of the 31st International Conference on Machine Learning}, volume~32 of \emph{Proceedings of Machine Learning Research}, pp.\  1071--1079, Bejing, China, 22--24 Jun 2014{\natexlab{b}}. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v32/busa-fekete14.html}.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d.~O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem[Chernoff(1992)]{sequential_design}
Chernoff, H.
\newblock \emph{Sequential Design of Experiments}, pp.\  345--360.
\newblock Springer New York, New York, NY, 1992.
\newblock ISBN 978-1-4612-4380-9.
\newblock \doi{10.1007/978-1-4612-4380-9_27}.
\newblock URL \url{https://doi.org/10.1007/978-1-4612-4380-9_27}.

\bibitem[Chiang \& Lee(2023)Chiang and Lee]{chiang-lee-2023-large}
Chiang, C.-H. and Lee, H.-y.
\newblock Can large language models be an alternative to human evaluations?
\newblock In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  15607--15631, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.870}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.870}.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021gsm}
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[Cui et~al.(2023)Cui, Yuan, Ding, Yao, Zhu, Ni, Xie, Liu, and Sun]{cui2023ultrafeedback}
Cui, G., Yuan, L., Ding, N., Yao, G., Zhu, W., Ni, Y., Xie, G., Liu, Z., and Sun, M.
\newblock Ultrafeedback: Boosting language models with high-quality feedback, 2023.

\bibitem[DiCiccio \& Efron(1996)DiCiccio and Efron]{diciccio1996bootstrap}
DiCiccio, T.~J. and Efron, B.
\newblock Bootstrap confidence intervals.
\newblock \emph{Statistical science}, 11\penalty0 (3):\penalty0 189--228, 1996.

\bibitem[Durrett(2019)]{durrett2019probability}
Durrett, R.
\newblock \emph{Probability: theory and examples}, volume~49.
\newblock Cambridge university press, 2019.

\bibitem[Elo(1967)]{elo1967proposed}
Elo, A.~E.
\newblock The proposed uscf rating system, its development, theory, and applications.
\newblock \emph{Chess Life}, 22\penalty0 (8):\penalty0 242--247, 1967.

\bibitem[Fisher(1928)]{fisher1928statistical}
Fisher, R.~A.
\newblock \emph{Statistical methods for research workers}.
\newblock Number~5. Oliver and Boyd, 1928.

\bibitem[Freedman(2006)]{freedman2006so}
Freedman, D.~A.
\newblock On the so-called ``huber sandwich estimator''' and ``robust standard errors'''.
\newblock \emph{The American Statistician}, 60\penalty0 (4):\penalty0 299--302, 2006.

\bibitem[Gemini et~al.(2023)Gemini, Anil, Borgeaud, Wu, Alayrac, Yu, Soricut, Schalkwyk, Dai, Hauth, et~al.]{team2023gemini}
Gemini, T., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A.~M., Hauth, A., et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Geng et~al.(2023)Geng, Gudibande, Liu, Wallace, Abbeel, Levine, and Song]{koala_blogpost_2023}
Geng, X., Gudibande, A., Liu, H., Wallace, E., Abbeel, P., Levine, S., and Song, D.
\newblock Koala: A dialogue model for academic research.
\newblock Blog post, April 2023.
\newblock URL \url{https://bair.berkeley.edu/blog/2023/04/03/koala/}.

\bibitem[Grootendorst(2022)]{grootendorst2022bertopic}
Grootendorst, M.
\newblock Bertopic: Neural topic modeling with a class-based tf-idf procedure.
\newblock \emph{arXiv preprint arXiv:2203.05794}, 2022.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2020measuring}
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J.
\newblock Measuring massive multitask language understanding.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Howard et~al.(2020)Howard, Ramdas, McAuliffe, and Sekhon]{howard2020time}
Howard, S.~R., Ramdas, A., McAuliffe, J., and Sekhon, J.
\newblock Time-uniform chernoff bounds via nonnegative supermartingales.
\newblock 2020.

\bibitem[Huang et~al.(2023)Huang, Lin, Liu, Gong, Lu, Lei, Liang, Shen, Lin, Duan, et~al.]{huang2023competition}
Huang, Y., Lin, Z., Liu, X., Gong, Y., Lu, S., Lei, F., Liang, Y., Shen, Y., Lin, C., Duan, N., et~al.
\newblock Competition-level problems are effective llm evaluators.
\newblock \emph{arXiv preprint arXiv:2312.02143}, 2023.

\bibitem[Huber et~al.(1967)]{huber1967behavior}
Huber, P.~J. et~al.
\newblock The behavior of maximum likelihood estimates under nonstandard conditions.
\newblock In \emph{Proceedings of the fifth Berkeley symposium on mathematical statistics and probability}, volume~1, pp.\  221--233. Berkeley, CA: University of California Press, 1967.

\bibitem[Hunter(2004)]{mm_bradley_terry}
Hunter, D.~R.
\newblock {MM algorithms for generalized Bradley-Terry models}.
\newblock \emph{The Annals of Statistics}, 32\penalty0 (1):\penalty0 384 -- 406, 2004.
\newblock \doi{10.1214/aos/1079120141}.
\newblock URL \url{https://doi.org/10.1214/aos/1079120141}.

\bibitem[Karimi et~al.(2021)Karimi, G{\"u}rel, Karla{\v{s}}, Rausch, Zhang, and Krause]{karimi2021online}
Karimi, M.~R., G{\"u}rel, N.~M., Karla{\v{s}}, B., Rausch, J., Zhang, C., and Krause, A.
\newblock Online active model selection for pre-trained classifiers.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pp.\  307--315. PMLR, 2021.

\bibitem[Karpinska et~al.(2021)Karpinska, Akoury, and Iyyer]{karpinska-etal-2021-perils}
Karpinska, M., Akoury, N., and Iyyer, M.
\newblock The perils of using {M}echanical {T}urk to evaluate open-ended text generation.
\newblock In Moens, M.-F., Huang, X., Specia, L., and Yih, S. W.-t. (eds.), \emph{Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing}, pp.\  1265--1285, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.emnlp-main.97}.
\newblock URL \url{https://aclanthology.org/2021.emnlp-main.97}.

\bibitem[Kiela et~al.(2021)Kiela, Bartolo, Nie, Kaushik, Geiger, Wu, Vidgen, Prasad, Singh, Ringshia, et~al.]{kiela2021dynabench}
Kiela, D., Bartolo, M., Nie, Y., Kaushik, D., Geiger, A., Wu, Z., Vidgen, B., Prasad, G., Singh, A., Ringshia, P., et~al.
\newblock Dynabench: Rethinking benchmarking in nlp.
\newblock In \emph{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pp.\  4110--4124, 2021.

\bibitem[K{\"o}pf et~al.(2023)K{\"o}pf, Kilcher, von R{\"u}tte, Anagnostidis, Tam, Stevens, Barhoum, Duc, Stanley, Nagyfi, et~al.]{kopf2023openassistant}
K{\"o}pf, A., Kilcher, Y., von R{\"u}tte, D., Anagnostidis, S., Tam, Z.-R., Stevens, K., Barhoum, A., Duc, N.~M., Stanley, O., Nagyfi, R., et~al.
\newblock Openassistant conversations--democratizing large language model alignment.
\newblock \emph{arXiv preprint arXiv:2304.07327}, 2023.

\bibitem[Langley(2000)]{langley00}
Langley, P.
\newblock Crafting papers on machine learning.
\newblock In Langley, P. (ed.), \emph{Proceedings of the 17th International Conference on Machine Learning (ICML 2000)}, pp.\  1207--1216, Stanford, CA, 2000. Morgan Kaufmann.

\bibitem[Li et~al.(2023)Li, Zhang, Dubois, Taori, Gulrajani, Guestrin, Liang, and Hashimoto]{alpaca_eval}
Li, X., Zhang, T., Dubois, Y., Taori, R., Gulrajani, I., Guestrin, C., Liang, P., and Hashimoto, T.~B.
\newblock Alpacaeval: An automatic evaluator of instruction-following models.
\newblock \url{https://github.com/tatsu-lab/alpaca_eval}, 2023.

\bibitem[Li et~al.(2022)Li, Choi, Chung, Kushman, Schrittwieser, Leblond, Eccles, Keeling, Gimeno, Dal~Lago, et~al.]{li2022competition}
Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Dal~Lago, A., et~al.
\newblock Competition-level code generation with alphacode.
\newblock \emph{Science}, 378\penalty0 (6624):\penalty0 1092--1097, 2022.

\bibitem[Liang et~al.(2022)Liang, Bommasani, Lee, Tsipras, Soylu, Yasunaga, Zhang, Narayanan, Wu, Kumar, et~al.]{liang2022holistic}
Liang, P., Bommasani, R., Lee, T., Tsipras, D., Soylu, D., Yasunaga, M., Zhang, Y., Narayanan, D., Wu, Y., Kumar, A., et~al.
\newblock Holistic evaluation of language models.
\newblock \emph{arXiv preprint arXiv:2211.09110}, 2022.

\bibitem[Lin et~al.(2023)Lin, Wang, Tong, Wang, Guo, Wang, and Shang]{toxicchat}
Lin, Z., Wang, Z., Tong, Y., Wang, Y., Guo, Y., Wang, Y., and Shang, J.
\newblock {T}oxic{C}hat: Unveiling hidden challenges of toxicity detection in real-world user-{AI} conversation.
\newblock In Bouamor, H., Pino, J., and Bali, K. (eds.), \emph{Findings of the Association for Computational Linguistics: EMNLP 2023}, pp.\  4694--4702, Singapore, December 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.findings-emnlp.311}.
\newblock URL \url{https://aclanthology.org/2023.findings-emnlp.311}.

\bibitem[Liu et~al.(2009)]{liu2009learning}
Liu, T.-Y. et~al.
\newblock Learning to rank for information retrieval.
\newblock \emph{Foundations and Trends{\textregistered} in Information Retrieval}, 3\penalty0 (3):\penalty0 225--331, 2009.

\bibitem[McInnes et~al.(2020)McInnes, Healy, and Melville]{mcinnes2020umap}
McInnes, L., Healy, J., and Melville, J.
\newblock Umap: Uniform manifold approximation and projection for dimension reduction, 2020.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Oren et~al.(2023)Oren, Meister, Chatterji, Ladhak, and Hashimoto]{oren2023proving}
Oren, Y., Meister, N., Chatterji, N., Ladhak, F., and Hashimoto, T.~B.
\newblock Proving test set contamination in black box language models.
\newblock \emph{arXiv preprint arXiv:2310.17623}, 2023.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell, Welinder, Christiano, Leike, and Lowe]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.~L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R.
\newblock Training language models to follow instructions with human feedback, 2022.

\bibitem[Ramdas et~al.(2023)Ramdas, Gr{\"u}nwald, Vovk, and Shafer]{ramdas2023game}
Ramdas, A., Gr{\"u}nwald, P., Vovk, V., and Shafer, G.
\newblock Game-theoretic statistics and safe anytime-valid inference.
\newblock \emph{Statistical Science}, 38\penalty0 (4):\penalty0 576--601, 2023.

\bibitem[Rao \& Kupper(1967)Rao and Kupper]{tie_in_bradley_terry}
Rao, P.~V. and Kupper, L.~L.
\newblock Ties in paired-comparison experiments: A generalization of the bradley-terry model.
\newblock \emph{Journal of the American Statistical Association}, 62\penalty0 (317):\penalty0 194--204, 1967.
\newblock \doi{10.1080/01621459.1967.10482901}.

\bibitem[Srivastava et~al.(2023)Srivastava, Rastogi, Rao, Shoeb, Abid, Fisch, Brown, Santoro, Gupta, Garriga-Alonso, et~al.]{srivastava2023beyond}
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A.~M., Abid, A., Fisch, A., Brown, A.~R., Santoro, A., Gupta, A., Garriga-Alonso, A., et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
\newblock \emph{Transactions on Machine Learning Research}, 2023.

\bibitem[Sz\"{o}r\'{e}nyi et~al.(2015)Sz\"{o}r\'{e}nyi, Busa-Fekete, Paul, and H\"{u}llermeier]{online_rank}
Sz\"{o}r\'{e}nyi, B., Busa-Fekete, R., Paul, A., and H\"{u}llermeier, E.
\newblock Online rank elicitation for plackett-luce: A dueling bandits approach.
\newblock In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~28. Curran Associates, Inc., 2015.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2015/file/7eacb532570ff6858afd2723755ff790-Paper.pdf}.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama2}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Vovk \& Wang(2021)Vovk and Wang]{vovk2021values}
Vovk, V. and Wang, R.
\newblock E-values: Calibration, combination and applications.
\newblock \emph{The Annals of Statistics}, 49\penalty0 (3):\penalty0 1736--1754, 2021.

\bibitem[Wang et~al.(2023)Wang, Kordi, Mishra, Liu, Smith, Khashabi, and Hajishirzi]{wang-etal-2023-self-instruct}
Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N.~A., Khashabi, D., and Hajishirzi, H.
\newblock Self-instruct: Aligning language models with self-generated instructions.
\newblock In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  13484--13508, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.754}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.754}.

\bibitem[Waudby-Smith \& Ramdas(2020)Waudby-Smith and Ramdas]{waudby2020estimating}
Waudby-Smith, I. and Ramdas, A.
\newblock Estimating means of bounded random variables by betting.
\newblock \emph{arXiv preprint arXiv:2010.09686}, 2020.

\bibitem[White(1982)]{white1982maximum}
White, H.
\newblock Maximum likelihood estimation of misspecified models.
\newblock \emph{Econometrica: Journal of the econometric society}, pp.\  1--25, 1982.

\bibitem[Yang et~al.(2023)Yang, Chiang, Zheng, Gonzalez, and Stoica]{yang2023rethinking}
Yang, S., Chiang, W.-L., Zheng, L., Gonzalez, J.~E., and Stoica, I.
\newblock Rethinking benchmark and contamination for language models with rephrased samples.
\newblock \emph{arXiv preprint arXiv:2311.04850}, 2023.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and Choi]{zellers2019hellaswag}
Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pp.\  4791--4800, 2019.

\bibitem[Zheng et~al.(2023{\natexlab{a}})Zheng, Chiang, Sheng, Li, Zhuang, Wu, Zhuang, Li, Lin, Xing, Gonzalez, Stoica, and Zhang]{zheng2023lmsyschat1m}
Zheng, L., Chiang, W.-L., Sheng, Y., Li, T., Zhuang, S., Wu, Z., Zhuang, Y., Li, Z., Lin, Z., Xing, E.~P., Gonzalez, J.~E., Stoica, I., and Zhang, H.
\newblock Lmsys-chat-1m: A large-scale real-world llm conversation dataset, 2023{\natexlab{a}}.

\bibitem[Zheng et~al.(2023{\natexlab{b}})Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, Zhang, Gonzalez, and Stoica]{zheng2023judging}
Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., Zhang, H., Gonzalez, J.~E., and Stoica, I.
\newblock Judging {LLM}-as-a-judge with {MT}-bench and chatbot arena.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2023{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=uccHPGDlao}.

\bibitem[Zhong et~al.(2023)Zhong, Cui, Guo, Liang, Lu, Wang, Saied, Chen, and Duan]{zhong2023agieval}
Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., and Duan, N.
\newblock Agieval: A human-centric benchmark for evaluating foundation models.
\newblock \emph{arXiv preprint arXiv:2304.06364}, 2023.

\bibitem[Zhu et~al.(2023)Zhu, Frick, Wu, Zhu, and Jiao]{starling2023}
Zhu, B., Frick, E., Wu, T., Zhu, H., and Jiao, J.
\newblock Starling-7b: Improving llm helpfulness \& harmlessness with rlaif, November 2023.

\end{thebibliography}
