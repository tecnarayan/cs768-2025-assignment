\begin{thebibliography}{80}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Alex et~al.(2021)Alex, Lifland, Tunstall, Thakur, Maham, Riedel,
  Hine, Ashurst, Sedille, Carlier, Noetel, and
  Stuhlm{\"{u}}ller}]{Alex2021RAFTAR}
Neel Alex, Eli Lifland, Lewis Tunstall, Abhishek Thakur, Pegah Maham, C.~Jess
  Riedel, Emmie Hine, Carolyn Ashurst, Paul Sedille, Alexis Carlier, Michael
  Noetel, and Andreas Stuhlm{\"{u}}ller. 2021.
\newblock \href {http://arxiv.org/abs/2109.14076} {{RAFT:} {A} real-world
  few-shot text classification benchmark}.
\newblock \emph{CoRR}, abs/2109.14076.

\bibitem[{Arnold et~al.(2020)Arnold, Mahajan, Datta, Bunner, and
  Zarkias}]{Arnold2020-ss}
S{\'e}bastien M~R Arnold, Praateek Mahajan, Debajyoti Datta, Ian Bunner, and
  Konstantinos~Saitas Zarkias. 2020.
\newblock \href {http://arxiv.org/abs/2008.12284} {learn2learn: A library for
  {Meta-Learning} research}.

\bibitem[{Bansal et~al.(2020{\natexlab{a}})Bansal, Jha, and
  McCallum}]{bansal-coling20}
Trapit Bansal, Rishikesh Jha, and Andrew McCallum. 2020{\natexlab{a}}.
\newblock Learning to {{Few}}-{{Shot Learn Across Diverse Natural Language
  Classification Tasks}}.
\newblock In \emph{COLING}.

\bibitem[{Bansal et~al.(2020{\natexlab{b}})Bansal, Jha, Munkhdalai, and
  McCallum}]{bansal-emnlp20-self-supervised}
Trapit Bansal, Rishikesh Jha, Tsendsuren Munkhdalai, and Andrew McCallum.
  2020{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.38}
  {Self-{{Supervised Meta}}-{{Learning}} for {{Few}}-{{Shot Natural Language
  Classification Tasks}}}.
\newblock In \emph{EMNLP}.

\bibitem[{Bao et~al.(2020)Bao, Wu, Chang, and Barzilay}]{bao2020}
Yujia Bao, Menghua Wu, Shiyu Chang, and Regina Barzilay. 2020.
\newblock Few-shot {{Text Classification}} with {{Distributional Signatures}}.
\newblock In \emph{{{ICLR}}}.

\bibitem[{{Bar-Haim} et~al.(2006){Bar-Haim}, Dagan, Dolan, Ferro, Giampiccolo,
  and Magnini}]{bar-haim2006}
Roy {Bar-Haim}, Ido Dagan, Bill Dolan, L.~Ferro, Danilo Giampiccolo, and
  B.~Magnini. 2006.
\newblock The second {{PASCAL}} recognising textual entailment challenge.

\bibitem[{Bender et~al.(2021)Bender, Gebru, McMillan-Major, and
  Shmitchell}]{Bender2021OnTD}
Emily~M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
  Shmitchell. 2021.
\newblock On the dangers of stochastic parrots: Can language models be too big?
\newblock \emph{FAccT}.

\bibitem[{Bentivogli et~al.(2009)Bentivogli, Clark, Dagan, and
  Giampiccolo}]{bentivogli2009}
Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. 2009.
\newblock The fifth {{PASCAL}} recognizing textual entailment challenge.
\newblock In \emph{{{TAC}}}.

\bibitem[{Bowman et~al.(2015)Bowman, Angeli, Potts, and Manning}]{bowman2015}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
  2015.
\newblock \href {https://doi.org/10.18653/v1/D15-1075} {A large annotated
  corpus for learning natural language inference}.
\newblock In \emph{EMNLP}.

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger,
  Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin,
  Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei}]{brown2020}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert{-}Voss, Gretchen Krueger, Tom
  Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens
  Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
  Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec
  Radford, Ilya Sutskever, and Dario Amodei. 2020.
\newblock \href
  {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html}
  {Language models are few-shot learners}.
\newblock In \emph{NeurIPS}.

\bibitem[{Buda et~al.(2018)Buda, Maki, and Mazurowski}]{Buda2018ASS}
Mateusz Buda, Atsuto Maki, and Maciej~A. Mazurowski. 2018.
\newblock \href {https://doi.org/10.1016/j.neunet.2018.07.011} {A systematic
  study of the class imbalance problem in convolutional neural networks}.
\newblock \emph{Neural Networks}, 106:249--259.

\bibitem[{Cao et~al.(2020)Cao, Law, and Fidler}]{cao2020}
Tianshi Cao, Marc~T. Law, and Sanja Fidler. 2020.
\newblock A {{Theoretical Analysis}} of the {{Number}} of {{Shots}} in
  {{Few}}-{{Shot Learning}}.
\newblock In \emph{ICLR}.

\bibitem[{Card et~al.(2020)Card, Henderson, Khandelwal, Jia, Mahowald, and
  Jurafsky}]{Card2020WithLP}
Dallas Card, Peter Henderson, Urvashi Khandelwal, Robin Jia, Kyle Mahowald, and
  Dan Jurafsky. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.745} {With little
  power comes great responsibility}.
\newblock In \emph{{EMNLP}}.

\bibitem[{Carlini et~al.(2020)Carlini, Tram{\`{e}}r, Wallace, Jagielski,
  Herbert{-}Voss, Lee, Roberts, Brown, Song, Erlingsson, Oprea, and
  Raffel}]{Carlini2020ExtractingTD}
Nicholas Carlini, Florian Tram{\`{e}}r, Eric Wallace, Matthew Jagielski, Ariel
  Herbert{-}Voss, Katherine Lee, Adam Roberts, Tom~B. Brown, Dawn Song,
  {\'{U}}lfar Erlingsson, Alina Oprea, and Colin Raffel. 2020.
\newblock \href {http://arxiv.org/abs/2012.07805} {Extracting training data
  from large language models}.
\newblock \emph{CoRR}, abs/2012.07805.

\bibitem[{Chen et~al.(2019)Chen, Liu, Kira, Wang, and Huang}]{chen-iclr2019}
Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang~Frank Wang, and Jia-Bin
  Huang. 2019.
\newblock A closer look at few-shot classification.
\newblock In \emph{ICLR}.

\bibitem[{Clark et~al.(2019)Clark, Lee, Chang, Kwiatkowski, Collins, and
  Toutanova}]{clark2019}
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael
  Collins, and Kristina Toutanova. 2019.
\newblock {{BoolQ}}: {{Exploring}} the {{Surprising Difficulty}} of {{Natural
  Yes}}/{{No Questions}}.
\newblock In \emph{NAACL}.

\bibitem[{Dagan et~al.(2005)Dagan, Glickman, and Magnini}]{dagan2005}
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.
\newblock \href {https://doi.org/10.1007/11736790_9} {The {{PASCAL}}
  recognising textual entailment challenge}.
\newblock In \emph{International Conference on Machine Learning Challenges}.

\bibitem[{Deleu et~al.(2019)Deleu, W\"urfl, Samiei, Cohen, and
  Bengio}]{deleu2019torchmeta}
Tristan Deleu, Tobias W\"urfl, Mandana Samiei, Joseph~Paul Cohen, and Yoshua
  Bengio. 2019.
\newblock \href {https://arxiv.org/abs/1909.06576} {{Torchmeta: A Meta-Learning
  library for PyTorch}}.
\newblock Available at: https://github.com/tristandeleu/pytorch-meta.

\bibitem[{Dhillon et~al.(2020)Dhillon, Chaudhari, Ravichandran, and
  Soatto}]{dhillon2020}
Guneet~S. Dhillon, Pratik Chaudhari, Avinash Ravichandran, and Stefano Soatto.
  2020.
\newblock \href {http://arxiv.org/abs/1909.02729} {A {{Baseline}} for
  {{Few}}-{{Shot Image Classification}}}.
\newblock In \emph{{{ICLR}}}.

\bibitem[{Dolan and Brockett(2005)}]{dolan2005}
William~B. Dolan and Chris Brockett. 2005.
\newblock Automatically {{Constructing}} a {{Corpus}} of {{Sentential
  Paraphrases}}.
\newblock In \emph{Proceedings of the {{Third International Workshop}} on
  {{Paraphrasing}} ({{IWP2005}})}.

\bibitem[{Dou et~al.(2019)Dou, Yu, and Anastasopoulos}]{dou2019}
Zi-Yi Dou, Keyi Yu, and Antonios Anastasopoulos. 2019.
\newblock Investigating {{Meta}}-{{Learning Algorithms}} for {{Low}}-{{Resource
  Natural Language Understanding Tasks}}.
\newblock In \emph{EMNLP}.

\bibitem[{Dror et~al.(2018)Dror, Baumer, Shlomov, and Reichart}]{dror2018}
Rotem Dror, Gili Baumer, Segev Shlomov, and Roi Reichart. 2018.
\newblock The {{Hitchhiker}}'s {{Guide}} to {{Testing Statistical
  Significance}} in {{Natural Language Processing}}.
\newblock In \emph{ACL}.

\bibitem[{Finn et~al.(2017)Finn, Abbeel, and Levine}]{finn2017}
Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017.
\newblock \href {http://proceedings.mlr.press/v70/finn17a.html}
  {{Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}}.
\newblock In \emph{ICML}.

\bibitem[{Gao et~al.(2021)Gao, Fisch, and Chen}]{gao2020}
Tianyu Gao, Adam Fisch, and Danqi Chen. 2021.
\newblock Making pre-trained language models better few-shot learners.
\newblock In \emph{ACL}.

\bibitem[{Gao et~al.(2019)Gao, Han, Liu, and Sun}]{gao2019a}
Tianyu Gao, Xu~Han, Zhiyuan Liu, and Maosong Sun. 2019.
\newblock \href {https://doi.org/10.1609/aaai.v33i01.33016407} {Hybrid
  {{Attention}}-{{Based Prototypical Networks}} for {{Noisy Few}}-{{Shot
  Relation Classification}}}.
\newblock In \emph{Proceedings of the {{AAAI Conference}} on {{Artificial
  Intelligence}}}, volume~33, pages 6407--6414.

\bibitem[{Giampiccolo et~al.(2007)Giampiccolo, Magnini, Dagan, and
  Dolan}]{giampiccolo2007}
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007.
\newblock The {{Third PASCAL Recognizing Textual Entailment Challenge}}.
\newblock In \emph{Proceedings of the {{ACL}}-{{PASCAL Workshop}} on {{Textual
  Entailment}} and {{Paraphrasing}}}, pages 1--9, {Prague}. {Association for
  Computational Linguistics}.

\bibitem[{Gu et~al.(2018)Gu, Wang, Chen, Li, and Cho}]{gu2018}
Jiatao Gu, Yong Wang, Yun Chen, Victor O.~K. Li, and Kyunghyun Cho. 2018.
\newblock \href {https://doi.org/10.18653/v1/D18-1398} {Meta-{{Learning}} for
  {{Low}}-{{Resource Neural Machine Translation}}}.
\newblock In \emph{Proceedings of the 2018 {{Conference}} on {{Empirical
  Methods}} in {{Natural Language Processing}}}, pages 3622--3631, {Brussels,
  Belgium}. {Association for Computational Linguistics}.

\bibitem[{Han et~al.(2018)Han, Zhu, Yu, Wang, Yao, Liu, and Sun}]{han2018}
Xu~Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong
  Sun. 2018.
\newblock \href {https://doi.org/10.18653/v1/D18-1514} {{{FewRel}}: {{A
  Large}}-{{Scale Supervised Few}}-{{Shot Relation Classification Dataset}}
  with {{State}}-of-the-{{Art Evaluation}}}.
\newblock In \emph{EMNLP}.

\bibitem[{Hase and Bansal(2021)}]{Hase2021WhenCM}
Peter Hase and Mohit Bansal. 2021.
\newblock \href {http://arxiv.org/abs/2102.02201} {When can models learn from
  explanations? {A} formal framework for understanding the roles of explanation
  data}.
\newblock \emph{CoRR}, abs/2102.02201.

\bibitem[{He and McAuley(2016)}]{he2016}
Ruining He and Julian McAuley. 2016.
\newblock \href {https://doi.org/10.1145/2872427.2883037} {Ups and {{Downs}}:
  {{Modeling}} the {{Visual Evolution}} of {{Fashion Trends}} with
  {{One}}-{{Class Collaborative Filtering}}}.
\newblock In \emph{WWW}, pages 507--517.

\bibitem[{Hou et~al.(2020)Hou, Mao, Lai, Chen, Che, Chen, and Liu}]{hou2020}
Yutai Hou, Jiafeng Mao, Yongkui Lai, Cheng Chen, Wanxiang Che, Zhigang Chen,
  and Ting Liu. 2020.
\newblock \href {http://arxiv.org/abs/2009.08138} {Few{J}oint: {A} few-shot
  learning benchmark for joint language understanding}.
\newblock \emph{CoRR}, abs/2009.08138.

\bibitem[{Hu and Liu(2004)}]{hu2004}
Minqing Hu and Bing Liu. 2004.
\newblock Mining and summarizing customer reviews.
\newblock In \emph{KDD}.

\bibitem[{IV et~al.(2021)IV, Balazevic, Wallace, Petroni, Singh, and
  Riedel}]{logan-cutting-down-2021}
Robert L.~Logan IV, Ivana Balazevic, Eric Wallace, Fabio Petroni, Sameer Singh,
  and Sebastian Riedel. 2021.
\newblock \href {http://arxiv.org/abs/2106.13353} {Cutting down on prompts and
  parameters: Simple few-shot learning with language models}.
\newblock \emph{CoRR}, abs/2106.13353.

\bibitem[{Khashabi et~al.(2020)Khashabi, Min, Khot, Sabharwal, Tafjord, Clark,
  and Hajishirzi}]{Khashabi2020UnifiedQACF}
Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,
  P.~Clark, and Hannaneh Hajishirzi. 2020.
\newblock {UnifiedQA: Crossing Format Boundaries With a Single QA System}.
\newblock In \emph{EMNLP}.

\bibitem[{Khot et~al.(2018)Khot, Sabharwal, and Clark}]{khot2018}
Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018.
\newblock {SciTaiL: A Textual Entailment Dataset from Science Question
  Answering}.
\newblock In \emph{AAAI}.

\bibitem[{Koh et~al.(2021)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, hua
  Hu, Yasunaga, Phillips, Beery, Leskovec, Kundaje, Pierson, Levine, Finn, and
  Liang}]{Koh2021WILDSAB}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang,
  Akshay Balsubramani, Wei hua Hu, Michihiro Yasunaga, Richard~L. Phillips,
  Sara Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine,
  Chelsea Finn, and Percy Liang. 2021.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In \emph{ICML}.

\bibitem[{Krone et~al.(2020)Krone, Zhang, and Diab}]{krone2020}
Jason Krone, Yi~Zhang, and Mona Diab. 2020.
\newblock Learning to classify intents and slot labels given a handful of
  examples.
\newblock In \emph{Workshop on Natural Language Processing for Conversational
  AI}.

\bibitem[{Lang(1995)}]{lang1995}
Ken Lang. 1995.
\newblock {NewsWeeder: Learning to Filter Netnews}.
\newblock In \emph{ICML}.

\bibitem[{Lee et~al.(2019)Lee, Maji, Ravichandran, and Soatto}]{lee2019}
Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto. 2019.
\newblock Meta-learning with differentiable convex optimization.
\newblock In \emph{CVPR}.

\bibitem[{Levesque et~al.(2011)Levesque, Davis, and Morgenstern}]{levesque2011}
Hector Levesque, Ernest Davis, and Leora Morgenstern. 2011.
\newblock The {{Winograd}} schema challenge.
\newblock \emph{AAAI Spring Symposium: Logical Formalizations of Commonsense
  Reasoning}, 46:47.

\bibitem[{Lewis(1997)}]{lewis1997}
David~D. Lewis. 1997.
\newblock Reuters-21578 text categorization test collection, distribution 1.0.

\bibitem[{Lhoest et~al.(2021)Lhoest, von Platen, Wolf, del Moral, Jernite,
  Thakur, Patil, Tunstall, Drame, Chaumond, Plu, Davison, Brandeis, Sanh, Scao,
  Xu, Patry, McMillan-Major, Schmid, Gugger, Delangue, Matussière, Debut,
  Bekman, and Lagunas}]{2020HuggingFace-datasets}
Quentin Lhoest, Patrick von Platen, Thomas Wolf, Albert~Villanova del Moral,
  Yacine Jernite, Abhishek Thakur, Suraj Patil, Lewis Tunstall, Mariama Drame,
  Julien Chaumond, Julien Plu, Joe Davison, Simon Brandeis, Victor Sanh,
  Teven~Le Scao, Kevin~Canwen Xu, Nicolas Patry, Angelina McMillan-Major,
  Philipp Schmid, Sylvain Gugger, Clément Delangue, Théo Matussière,
  Lysandre Debut, Stas Bekman, and François Lagunas. 2021.
\newblock \href {https://doi.org/10.5281/zenodo.5071218} {huggingface/datasets:
  1.9.0}.

\bibitem[{Liu et~al.(2019)Liu, He, Chen, and Gao}]{liu2019}
Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019.
\newblock Multi-{{Task Deep Neural Networks}} for {{Natural Language
  Understanding}}.
\newblock In \emph{ACL}.

\bibitem[{Lu et~al.(2021)Lu, Bartolo, Moore, Riedel, and
  Stenetorp}]{lu2021fantastically}
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp.
  2021.
\newblock \href {http://arxiv.org/abs/2104.08786} {Fantastically ordered
  prompts and where to find them: Overcoming few-shot prompt order
  sensitivity}.
\newblock \emph{CoRR}, abs/2104.08786.

\bibitem[{Luo et~al.(2021)Luo, Liu, Lin, and Zhang}]{luo-etal-2021-dont}
Qiaoyang Luo, Lingqiao Liu, Yuhao Lin, and Wei Zhang. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.findings-acl.245} {Don{'}t
  miss the labels: Label-semantic augmented meta-learner for few-shot text
  classification}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL-IJCNLP 2021}.

\bibitem[{Misra(2018)}]{misra2018}
Rishabh Misra. 2018.
\newblock \href {https://doi.org/10.13140/RG.2.2.20331.18729} {News category
  dataset}.

\bibitem[{Ochal et~al.(2021)Ochal, Patacchiola, Storkey, Vazquez, and
  Wang}]{ochal2021}
Mateusz Ochal, Massimiliano Patacchiola, Amos Storkey, Jose Vazquez, and Sen
  Wang. 2021.
\newblock \href {http://arxiv.org/abs/2101.02523} {Few-{{Shot Learning}} with
  {{Class Imbalance}}}.

\bibitem[{Pang and Lee(2004)}]{pang2004}
Bo~Pang and Lillian Lee. 2004.
\newblock A {{Sentimental Education}}: {{Sentiment Analysis Using Subjectivity
  Summarization Based}} on {{Minimum Cuts}}.
\newblock In \emph{ACL}.

\bibitem[{Pang and Lee(2005)}]{pang2005}
Bo~Pang and Lillian Lee. 2005.
\newblock Seeing {{Stars}}: {{Exploiting Class Relationships}} for {{Sentiment
  Categorization}} with {{Respect}} to {{Rating Scales}}.
\newblock In \emph{ACL}.

\bibitem[{Perez et~al.(2021)Perez, Kiela, and Cho}]{perez2021}
Ethan Perez, Douwe Kiela, and Kyunghyun Cho. 2021.
\newblock \href {http://arxiv.org/abs/2105.11447} {True few-shot learning with
  language models}.
\newblock \emph{CoRR}, abs/2105.11447.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu}]{Raffel2020ExploringTL}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, W.~Li, and Peter~J. Liu. 2020.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{J. Mach. Learn. Res.}, 21:140:1--140:67.

\bibitem[{Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and
  Liang}]{rajpurkar2016}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.
\newblock {{SQuAD}}: 100,000+ {{Questions}} for {{Machine Comprehension}} of
  {{Text}}.
\newblock In \emph{EMNLP}.

\bibitem[{Rubin and
  Schenker(1986)}]{rubin-schenker-confidence-interval-coverage}
D.~B. Rubin and N.~Schenker. 1986.
\newblock \href {https://doi.org/https://doi.org/10.2307/2347266} {Efficiently
  simulating the coverage properties of interval estimates}.
\newblock \emph{Journal of the Royal Statistical Society: Series C (Applied
  Statistics)}, 35(2):159--167.

\bibitem[{Rusu et~al.(2019)Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero,
  and Hadsell}]{rusu2019}
Andrei~A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,
  Simon Osindero, and Raia Hadsell. 2019.
\newblock Meta-learning with latent embedding optimization.
\newblock In \emph{ICLR}.

\bibitem[{Schick and
  Sch{\"{u}}tze(2021{\natexlab{a}})}]{Schick2020ExploitingCQ}
Timo Schick and Hinrich Sch{\"{u}}tze. 2021{\natexlab{a}}.
\newblock \href {https://aclanthology.org/2021.eacl-main.20/} {Exploiting
  cloze-questions for few-shot text classification and natural language
  inference}.
\newblock In \emph{Proceedings of the 16th Conference of the European Chapter
  of the Association for Computational Linguistics: Main Volume, {EACL}}.

\bibitem[{Schick and Sch{\"{u}}tze(2021{\natexlab{b}})}]{Schick2020ItsNJ}
Timo Schick and Hinrich Sch{\"{u}}tze. 2021{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/v1/2021.naacl-main.185} {It's not
  just size that matters: Small language models are also few-shot learners}.
\newblock In \emph{NAACL}.

\bibitem[{Schwartz et~al.(2020)Schwartz, Dodge, Smith, and
  Etzioni}]{Schwartz2020GreenA}
Roy Schwartz, Jesse Dodge, Noah~A. Smith, and Oren Etzioni. 2020.
\newblock Green {AI}.
\newblock \emph{Communications of the ACM}, 63:54 -- 63.

\bibitem[{Sharaf et~al.(2020)Sharaf, Hassan, and Daum{\'e}~III}]{sharaf2020}
Amr Sharaf, Hany Hassan, and Hal Daum{\'e}~III. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.ngt-1.5} {Meta-{{Learning}}
  for {{Few}}-{{Shot NMT Adaptation}}}.
\newblock In \emph{Proceedings of the {{Fourth Workshop}} on {{Neural
  Generation}} and {{Translation}}}, pages 43--53, {Online}. {Association for
  Computational Linguistics}.

\bibitem[{Shin et~al.(2020)Shin, Razeghi, IV, Wallace, and
  Singh}]{Shin2020AutoPromptEK}
Taylor Shin, Yasaman Razeghi, Robert L.~Logan IV, Eric Wallace, and Sameer
  Singh. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.346}
  {Auto{P}rompt: Eliciting knowledge from language models with automatically
  generated prompts}.
\newblock In \emph{EMNLP}.

\bibitem[{Si et~al.(2019)Si, Yang, Dai, Naik, and Song}]{si2018learning}
Xujie Si, Yuan Yang, Hanjun Dai, Mayur Naik, and Le~Song. 2019.
\newblock \href {https://openreview.net/forum?id=Syl8Sn0cK7} {Learning a
  meta-solver for syntax-guided program synthesis}.
\newblock In \emph{ICLR}.

\bibitem[{Snell et~al.(2017)Snell, Swersky, and Zemel}]{snell2017}
Jake Snell, Kevin Swersky, and Richard Zemel. 2017.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{NeurIPS}.

\bibitem[{Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts}]{socher2013}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew Ng, and Christopher Potts. 2013.
\newblock Recursive {{Deep Models}} for {{Semantic Compositionality Over}} a
  {{Sentiment Treebank}}.
\newblock In \emph{EMNLP}.

\bibitem[{Solaiman et~al.(2019)Solaiman, Brundage, Clark, Askell,
  Herbert{-}Voss, Wu, Radford, and Wang}]{Solaiman2019ReleaseSA}
Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel
  Herbert{-}Voss, Jeff Wu, Alec Radford, and Jasmine Wang. 2019.
\newblock \href {http://arxiv.org/abs/1908.09203} {Release strategies and the
  social impacts of language models}.
\newblock \emph{CoRR}, abs/1908.09203.

\bibitem[{Sun et~al.(2019)Sun, Sun, Zhou, and Lv}]{sun2019}
Shengli Sun, Qingfeng Sun, Kevin Zhou, and Tengchao Lv. 2019.
\newblock Hierarchical {{Attention Prototypical Networks}} for {{Few}}-{{Shot
  Text Classification}}.
\newblock In \emph{EMNLP}.

\bibitem[{Tam et~al.(2021)Tam, Menon, Bansal, Srivastava, and Raffel}]{tam2021}
Derek Tam, Rakesh~R. Menon, Mohit Bansal, Shashank Srivastava, and Colin
  Raffel. 2021.
\newblock \href {http://arxiv.org/abs/2103.11955} {Improving and simplifying
  pattern exploiting training}.
\newblock \emph{CoRR}, abs/2103.11955.

\bibitem[{Tjong Kim~Sang and De~Meulder(2003)}]{sang2003}
Erik~F. Tjong Kim~Sang and Fien De~Meulder. 2003.
\newblock Introduction to the {{CoNLL}}-2003 {{Shared Task}}:
  {{Language}}-{{Independent Named Entity Recognition}}.
\newblock In \emph{Proceedings of the {{Seventh Conference}} on {{Natural
  Language Learning}} at {{HLT}}-{{NAACL}} 2003}, pages 142--147.

\bibitem[{Triantafillou et~al.(2020)Triantafillou, Zhu, Dumoulin, Lamblin,
  Evci, Xu, Goroshin, Gelada, Swersky, Manzagol, and
  Larochelle}]{triantafillou2020}
Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci,
  Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine
  Manzagol, and Hugo Larochelle. 2020.
\newblock \href {http://arxiv.org/abs/1903.03096} {Meta-{{Dataset}}: {{A
  Dataset}} of {{Datasets}} for {{Learning}} to {{Learn}} from {{Few
  Examples}}}.
\newblock In \emph{{{ICLR}}}.

\bibitem[{Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Kavukcuoglu, and
  Wierstra}]{Vinyals2016MatchingNF}
Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan
  Wierstra. 2016.
\newblock \href
  {https://proceedings.neurips.cc/paper/2016/hash/90e1357833654983612fb05e3ec9148c-Abstract.html}
  {Matching networks for one shot learning}.
\newblock In \emph{Advances in Neural Information Processing Systems 29: Annual
  Conference on Neural Information Processing Systems 2016}.

\bibitem[{Voorhees and Tice(2000)}]{voorhees2000}
Ellen~M. Voorhees and Dawn~M. Tice. 2000.
\newblock Building a question answering test collection.
\newblock In \emph{SIGIR}.

\bibitem[{Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman}]{wang2018}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and
  Samuel~R. Bowman. 2018.
\newblock {{GLUE}}: {{A Multi}}-{{Task Benchmark}} and {{Analysis Platform}}
  for {{Natural Language Understanding}}.
\newblock In \emph{{{ICLR}}}.

\bibitem[{Wang et~al.(2020)Wang, Yao, Kwok, and Ni}]{wang2020}
Yaqing Wang, Quanming Yao, James~T. Kwok, and Lionel~M. Ni. 2020.
\newblock \href {https://doi.org/10.1145/3386252} {Generalizing from a {{Few
  Examples}}: {{A Survey}} on {{Few}}-shot {{Learning}}}.
\newblock \emph{ACM Computing Surveys}, 53(3):63:1--63:34.

\bibitem[{Warstadt et~al.(2019)Warstadt, Singh, and Bowman}]{warstadt2019}
Alex Warstadt, Amanpreet Singh, and Samuel~R. Bowman. 2019.
\newblock \href {https://doi.org/10.1162/tacl_a_00290} {Neural {{Network
  Acceptability Judgments}}}.
\newblock \emph{TACL}, 7:625--641.

\bibitem[{Weller et~al.(2020)Weller, Lourie, Gardner, and Peters}]{weller2020}
Orion Weller, Nicholas Lourie, Matt Gardner, and Matthew Peters. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.105} {Learning
  from {{Task Descriptions}}}.
\newblock In \emph{EMNLP}.

\bibitem[{Williams et~al.(2018)Williams, Nangia, and Bowman}]{williams2018}
Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.
\newblock A {{Broad}}-{{Coverage Challenge Corpus}} for {{Sentence
  Understanding}} through {{Inference}}.
\newblock In \emph{NAACL}.

\bibitem[{Ye et~al.(2021)Ye, Lin, and Ren}]{ye2021}
Qinyuan Ye, Bill~Yuchen Lin, and Xiang Ren. 2021.
\newblock \href {http://arxiv.org/abs/2104.08835} {Cross{F}it: {A} few-shot
  learning challenge for cross-task generalization in {NLP}}.
\newblock \emph{CoRR}, abs/2104.08835.

\bibitem[{Yin(2020)}]{yin2020}
Wenpeng Yin. 2020.
\newblock \href {http://arxiv.org/abs/2007.09604} {Meta-learning for few-shot
  natural language processing: {A} survey}.
\newblock \emph{CoRR}, abs/2007.09604.

\bibitem[{Yu et~al.(2018)Yu, Guo, Yi, Chang, Potdar, Cheng, Tesauro, Wang, and
  Zhou}]{yu2018}
Mo~Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu~Cheng, Gerald
  Tesauro, Haoyu Wang, and Bowen Zhou. 2018.
\newblock Diverse {{Few}}-{{Shot Text Classification}} with {{Multiple
  Metrics}}.
\newblock In \emph{NAACL}.

\bibitem[{Zhao et~al.(2021)Zhao, Wallace, Feng, Klein, and
  Singh}]{Zhao2021CalibrateBU}
Tony~Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021.
\newblock \href {http://arxiv.org/abs/2102.09690} {Calibrate before use:
  Improving few-shot performance of language models}.
\newblock \emph{CoRR}, abs/2102.09690.

\bibitem[{Zheng et~al.(2021)Zheng, Zhou, Qian, Ding, Li, Salakhutdinov, Tang,
  Ruder, and Yang}]{zheng2021fewnlu}
Yanan Zheng, Jing Zhou, Yujie Qian, Ming Ding, Jian Li, Ruslan Salakhutdinov,
  Jie Tang, Sebastian Ruder, and Zhilin Yang. 2021.
\newblock \href {http://arxiv.org/abs/2109.12742} {Few{NLU}: Benchmarking
  state-of-the-art methods for few-shot natural language understanding}.
\newblock \emph{CoRR}, abs/2109.12742.

\bibitem[{Zhong et~al.(2021)Zhong, Lee, Zhang, and Klein}]{zhong2021adapting}
Ruiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein. 2021.
\newblock \href {http://arxiv.org/abs/2104.04670} {Adapting language models for
  zero-shot learning by meta-tuning on dataset and prompt collections}.
\newblock \emph{CoRR}, abs/2104.04670.

\end{thebibliography}
