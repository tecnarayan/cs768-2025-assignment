\begin{thebibliography}{10}

\bibitem{Sutskever:2014:SSLNN}
Ilya Sutskever, Oriol Vinyals, and Quoc V.~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.D. Lawrence, and K.Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems
  27}, pages 3104--3112. Curran Associates, Inc., 2014.

\bibitem{Cho:2014:TranslationGRU}
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger
  Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock {\em arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{Sun:1998:NeuralPDA}
GZ~Sun, C~Lee Giles, HH~Chen, and YC~Lee.
\newblock The neural network pushdown automaton: Model, stack and learning
  simulations.
\newblock 1998.

\bibitem{Graves:2014:NTM}
Alex Graves, Greg Wayne, and Ivo Danihelka.
\newblock Neural turing machines.
\newblock {\em CoRR}, abs/1410.5401, 2014.

\bibitem{Graves:2012:SSLRNN}
Alex Graves.
\newblock {\em Supervised Sequence Labelling with Recurrent Neural Networks},
  volume 385 of {\em Studies in Computational Intelligence}.
\newblock Springer, 2012.

\bibitem{Dreyer:2008:LFST}
Markus Dreyer, Jason~R. Smith, and Jason Eisner.
\newblock Latent-variable modeling of string transductions with finite-state
  methods.
\newblock In {\em Proceedings of the Conference on Empirical Methods in Natural
  Language Processing}, EMNLP '08, pages 1080--1089, Stroudsburg, PA, USA,
  2008. Association for Computational Linguistics.

\bibitem{Allauzen:2007:OpenFST}
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wojciech Skut, and Mehryar
  Mohri.
\newblock {OpenFST}: A general and efficient weighted finite-state transducer
  library.
\newblock In {\em Implementation and Application of Automata}, volume 4783 of
  {\em Lecture Notes in Computer Science}, pages 11--23. Springer Berlin
  Heidelberg, 2007.

\bibitem{Wu:1997:Stochastic}
Dekai Wu.
\newblock Stochastic inversion transduction grammars and bilingual parsing of
  parallel corpora.
\newblock {\em Computational linguistics}, 23(3):377--403, 1997.

\bibitem{Graves:2012:STRNN}
Alex Graves.
\newblock Sequence transduction with recurrent neural networks.
\newblock In {\em Representation Learning Worksop, ICML}. 2012.

\bibitem{Das:1992:LearningCFGstack}
Sreerupa Das, C~Lee Giles, and Guo-Zheng Sun.
\newblock Learning context-free grammars: Capabilities and limitations of a
  recurrent neural network with an external stack memory.
\newblock In {\em Proceedings of The Fourteenth Annual Conference of Cognitive
  Science Society. Indiana University}, 1992.

\bibitem{Das:1993:PriorKnowledgeNNPDA}
Sreerupa Das, C~Lee Giles, and Guo-Zheng Sun.
\newblock Using prior knowledge in a $\{$NNPDA$\}$ to learn context-free
  languages.
\newblock {\em Advances in neural information processing systems}, 1993.

\bibitem{Dyer:2015:StackLSTM}
Chris Dyer, Miguel Ballesteros, Wang Ling, Austin Matthews, and Noah~A Smith.
\newblock Transition-based dependency parsing with stack long short-term
  memory.
\newblock In {\em Proceedings of the 53rd Annual Meeting of the Association for
  Computational Linguistics and the 7th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, ACL '15, pages
  334--343, Beijing, China, 2015. Association for Computational Linguistics.

\bibitem{Sukhbaatar:2015:WSMN}
Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus.
\newblock Weakly supervised memory networks.
\newblock {\em CoRR}, abs/1503.08895, 2015.

\bibitem{Zaremba:2015:ReinforcementNTM}
Wojciech Zaremba and Ilya Sutskever.
\newblock Reinforcement learning neural turing machines.
\newblock {\em arXiv preprint arXiv:1505.00521}, 2015.

\bibitem{Joulin:2015:Stack}
Armand Joulin and Tomas Mikolov.
\newblock Inferring algorithmic patterns with stack-augmented recurrent nets.
\newblock {\em arXiv preprint arXiv:1503.01007}, 2015.

\bibitem{Nair:2010:Rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 807--814, 2010.

\bibitem{Aho:1972:SCFG}
Alfred~V Aho and Jeffrey~D Ullman.
\newblock {\em The theory of parsing, translation, and compiling}.
\newblock Prentice-Hall, Inc., 1972.

\bibitem{Wu:1998:ITGandMT}
Dekai Wu and Hongsing Wong.
\newblock Machine translation with a stochastic grammatical channel.
\newblock In {\em Proceedings of the 17th international conference on
  Computational linguistics-Volume 2}, pages 1408--1415. Association for
  Computational Linguistics, 1998.

\bibitem{Tieleman:2012:RMSprop}
Tijmen Tieleman and Geoffrey Hinton.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock {\em COURSERA: Neural Networks for Machine Learning}, 4, 2012.

\bibitem{Pascanu:2012:ExplodingGradient}
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.
\newblock Understanding the exploding gradient problem.
\newblock {\em Computing Research Repository (CoRR) abs/1211.5063}, 2012.

\bibitem{Zhou:2002:Ensembling}
Zhi-Hua Zhou, Jianxin Wu, and Wei Tang.
\newblock Ensembling neural networks: many could be better than all.
\newblock {\em Artificial intelligence}, 137(1):239--263, 2002.

\end{thebibliography}
