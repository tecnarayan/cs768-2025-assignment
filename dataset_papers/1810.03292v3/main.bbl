\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Vellido et~al.(2012)Vellido, Mart{\'\i}n-Guerrero, and
  Lisboa]{vellido2012making}
Alfredo Vellido, Jos{\'e}~David Mart{\'\i}n-Guerrero, and Paulo~JG Lisboa.
\newblock Making machine learning models interpretable.
\newblock In \emph{ESANN}, volume~12, pages 163--172. Citeseer, 2012.

\bibitem[Doshi-Velez et~al.(2017)Doshi-Velez, Kortz, Budish, Bavitz, Gershman,
  O'Brien, Schieber, Waldo, Weinberger, and Wood]{doshi2017accountability}
Finale Doshi-Velez, Mason Kortz, Ryan Budish, Chris Bavitz, Sam Gershman, David
  O'Brien, Stuart Schieber, James Waldo, David Weinberger, and Alexandra Wood.
\newblock Accountability of ai under the law: The role of explanation.
\newblock \emph{arXiv preprint arXiv:1711.01134}, 2017.

\bibitem[Goodman and Flaxman(2016)]{goodman2016european}
Bryce Goodman and Seth Flaxman.
\newblock European union regulations on algorithmic decision-making and a"
  right to explanation".
\newblock \emph{arXiv preprint arXiv:1606.08813}, 2016.

\bibitem[Casillas et~al.(2013)Casillas, Cord{\'o}n, Triguero, and
  Magdalena]{casillas2013interpretability}
Jorge Casillas, Oscar Cord{\'o}n, Francisco~Herrera Triguero, and Luis
  Magdalena.
\newblock \emph{Interpretability issues in fuzzy modeling}, volume 128.
\newblock Springer, 2013.

\bibitem[Cadamuro et~al.(2016)Cadamuro, Gilad-Bachrach, and
  Zhu]{cadamuro2016debugging}
Gabriel Cadamuro, Ran Gilad-Bachrach, and Xiaojin Zhu.
\newblock Debugging machine learning models.
\newblock In \emph{ICML Workshop on Reliable Machine Learning in the Wild},
  2016.

\bibitem[Lakkaraju et~al.(2017)Lakkaraju, Kamar, Caruana, and
  Leskovec]{lakkaraju2017interpretable}
Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Jure Leskovec.
\newblock Interpretable \& explorable approximations of black box models.
\newblock \emph{arXiv preprint arXiv:1707.01154}, 2017.

\bibitem[Wang and Rudin(2015)]{wang2015causal}
Fulton Wang and Cynthia Rudin.
\newblock Causal falling rule lists.
\newblock \emph{arXiv preprint arXiv:1510.05189}, 2015.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock \emph{arXiv preprint arXiv:1312.6034}, 2013.

\bibitem[Springenberg et~al.(2014)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{springenberg2014striving}
Jost~Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin
  Riedmiller.
\newblock Striving for simplicity: The all convolutional net.
\newblock \emph{arXiv preprint arXiv:1412.6806}, 2014.

\bibitem[Zeiler and Fergus(2014)]{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pages 818--833.
  Springer, 2014.

\bibitem[Pieter-Jan~Kindermans(2018)]{kindermans2018learning}
Maximilian Alber Klaus-Robert M체ller Dumitru Erhan Been Kim Sven~D채hne
  Pieter-Jan~Kindermans, Kristof T.~Sch체tt.
\newblock Learning how to explain neural networks: Patternnet and
  patternattribution.
\newblock \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=Hkn7CBaTW}.

\bibitem[Zintgraf et~al.(2017)Zintgraf, Cohen, Adel, and
  Welling]{zintgraf2017visualizing}
Luisa~M Zintgraf, Taco~S Cohen, Tameem Adel, and Max Welling.
\newblock Visualizing deep neural network decisions: Prediction difference
  analysis.
\newblock \emph{arXiv preprint arXiv:1702.04595}, 2017.

\bibitem[Shrikumar et~al.(2016)Shrikumar, Greenside, Shcherbina, and
  Kundaje]{shrikumar2016not}
Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, and Anshul Kundaje.
\newblock Not just a black box: Learning important features through propagating
  activation differences.
\newblock \emph{arXiv preprint arXiv:1605.01713}, 2016.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock \emph{arXiv preprint arXiv:1703.01365}, 2017.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Why should i trust you?: Explaining the predictions of any
  classifier.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1135--1144. ACM, 2016.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and
  Wattenberg]{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Dabkowski and Gal(2017)]{dabkowski2017real}
Piotr Dabkowski and Yarin Gal.
\newblock Real time image saliency for black box classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6970--6979, 2017.

\bibitem[Lundberg and Lee(2017)]{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4768--4777, 2017.

\bibitem[Selvaraju et~al.(2016)Selvaraju, Das, Vedantam, Cogswell, Parikh, and
  Batra]{selvaraju2016grad}
Ramprasaath~R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Why did you say that?
\newblock \emph{arXiv preprint arXiv:1611.07450}, 2016.

\bibitem[Fong and Vedaldi(2017)]{fong2017interpretable}
Ruth~C Fong and Andrea Vedaldi.
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock \emph{arXiv preprint arXiv:1704.03296}, 2017.

\bibitem[Chen et~al.(2018)Chen, Song, Wainwright, and Jordan]{pmlr-v80-chen18j}
Jianbo Chen, Le~Song, Martin Wainwright, and Michael Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 883--892,
  Stockholmsm채ssan, Stockholm Sweden, 10--15 Jul 2018. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/chen18j.html}.

\bibitem[Baehrens et~al.(2010)Baehrens, Schroeter, Harmeling, Kawanabe, Hansen,
  and M{\~A}{\v{z}}ller]{baehrens2010explain}
David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja
  Hansen, and Klaus-Robert M{\~A}{\v{z}}ller.
\newblock How to explain individual classification decisions.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (Jun):\penalty0 1803--1831, 2010.

\bibitem[Erhan et~al.(2009)Erhan, Bengio, Courville, and
  Vincent]{erhan2009visualizing}
Dumitru Erhan, Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Visualizing higher-layer features of a deep network.
\newblock \emph{University of Montreal}, 1341\penalty0 (3):\penalty0 1, 2009.

\bibitem[Ancona et~al.(2017)Ancona, Ceolini, {\"O}ztireli, and
  Gross]{ancona2017unified}
Marco Ancona, Enea Ceolini, Cengiz {\"O}ztireli, and Markus Gross.
\newblock A unified view of gradient-based attribution methods for deep neural
  networks.
\newblock \emph{arXiv preprint arXiv:1711.06104}, 2017.

\bibitem[Ghorbani et~al.(2017)Ghorbani, Abid, and
  Zou]{ghorbani2017interpretation}
Amirata Ghorbani, Abubakar Abid, and James Zou.
\newblock Interpretation of neural networks is fragile.
\newblock \emph{arXiv preprint arXiv:1710.10547}, 2017.

\bibitem[Kindermans et~al.(2017)Kindermans, Hooker, Adebayo, Alber, Sch{\"u}tt,
  D{\"a}hne, Erhan, and Kim]{kindermans2017reliability}
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof~T
  Sch{\"u}tt, Sven D{\"a}hne, Dumitru Erhan, and Been Kim.
\newblock The (un) reliability of saliency methods.
\newblock \emph{arXiv preprint arXiv:1711.00867}, 2017.

\bibitem[Nie et~al.(2018)Nie, Zhang, and Patel]{nie2018theoretical}
Weili Nie, Yang Zhang, and Ankit Patel.
\newblock A theoretical explanation for perplexing behaviors of
  backpropagation-based visualizations.
\newblock In \emph{ICML}, 2018.

\bibitem[Mahendran and Vedaldi(2016)]{mahendran2016salient}
Aravindh Mahendran and Andrea Vedaldi.
\newblock Salient deconvolutional networks.
\newblock In \emph{European Conference on Computer Vision}, pages 120--135.
  Springer, 2016.

\bibitem[Samek et~al.(2017)Samek, Binder, Montavon, Lapuschkin, and
  M{\"u}ller]{samek2017evaluating}
Wojciech Samek, Alexander Binder, Gr{\'e}goire Montavon, Sebastian Lapuschkin,
  and Klaus-Robert M{\"u}ller.
\newblock Evaluating the visualization of what a deep neural network has
  learned.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  28\penalty0 (11):\penalty0 2660--2673, 2017.

\bibitem[Montavon et~al.(2017)Montavon, Samek, and
  M{\"u}ller]{montavon2017methods}
Gr{\'e}goire Montavon, Wojciech Samek, and Klaus-Robert M{\"u}ller.
\newblock Methods for interpreting and understanding deep neural networks.
\newblock \emph{Digital Signal Processing}, 2017.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{zhang2017understanding}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock In \emph{In Proc.~$5$th ICLR}, 2017.

\bibitem[Meng et~al.(2018)Meng, Baumgartner, Sinclair, Housden, Rajchl, Gomez,
  Hou, Toussaint, Tan, Matthew, et~al.]{meng2018automatic}
Qingjie Meng, Christian Baumgartner, Matthew Sinclair, James Housden, Martin
  Rajchl, Alberto Gomez, Benjamin Hou, Nicolas Toussaint, Jeremy Tan,
  Jacqueline Matthew, et~al.
\newblock Automatic shadow detection in 2d ultrasound.
\newblock 2018.

\bibitem[Ancona et~al.(2018)Ancona, Ceolini, \"Oztireli, and
  Gross]{ancona2018towards}
Marco Ancona, Enea Ceolini, Cengiz \"Oztireli, and Markus Gross.
\newblock Towards better understanding of gradient-based attribution methods
  for deep neural networks.
\newblock In \emph{In Proc.~$6$th ICLR}, 2018.

\bibitem[Saxe et~al.(2011)Saxe, Koh, Chen, Bhand, Suresh, and
  Ng]{saxe2011random}
Andrew~M Saxe, Pang~Wei Koh, Zhenghao Chen, Maneesh Bhand, Bipin Suresh, and
  Andrew~Y Ng.
\newblock On random weights and unsupervised feature learning.
\newblock In \emph{ICML}, pages 1089--1096, 2011.

\bibitem[Alain and Bengio(2016)]{alain2016understanding}
Guillaume Alain and Yoshua Bengio.
\newblock Understanding intermediate layers using linear classifier probes.
\newblock \emph{arXiv preprint arXiv:1610.01644}, 2016.

\bibitem[Ulyanov et~al.(2017)Ulyanov, Vedaldi, and Lempitsky]{ulyanov2017deep}
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
\newblock Deep image prior.
\newblock \emph{arXiv preprint arXiv:1711.10925}, 2017.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Goodfellow, and
  Kim]{adebayo2018local}
Julius Adebayo, Justin Gilmer, Ian Goodfellow, and Been Kim.
\newblock Local explanation methods for deep neural networks lack sensitivity
  to parameter values.
\newblock 2018.

\bibitem[Seo et~al.(2018)Seo, Choe, Koo, Jeon, Kim, and Jeon]{seo2018noise}
Junghoon Seo, Jeongyeol Choe, Jamyoung Koo, Seunghyeon Jeon, Beomsu Kim, and
  Taegyun Jeon.
\newblock Noise-adding methods of saliency map as series of higher order
  partial derivative.
\newblock \emph{arXiv preprint arXiv:1806.03000}, 2018.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2818--2826, 2016.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International Journal of Computer Vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[LeCun(1998)]{lecun1998mnist}
Yann LeCun.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Szegedy et~al.(2017)Szegedy, Ioffe, Vanhoucke, and
  Alemi]{szegedy2017inception}
Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander~A Alemi.
\newblock Inception-v4, inception-resnet and the impact of residual connections
  on learning.
\newblock In \emph{AAAI}, volume~4, page~12, 2017.

\end{thebibliography}
