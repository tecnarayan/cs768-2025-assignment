@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{kalashnikov2018qt,
  title={QT-Opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@article{lumbrl,
  author    = {Kevin Lu and
               Aditya Grover and
               Pieter Abbeel and
               Igor Mordatch},
  title     = {Reset-Free Lifelong Learning with Skill-Space Planning},
  journal   = {CoRR},
  volume    = {abs/2012.03548},
  year      = {2020},
}

@inproceedings{nagabandi2020deep,
  title={Deep dynamics models for learning dexterous manipulation},
  author={Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1101--1112},
  year={2020},
  organization={PMLR}
}

@article{sharma2020emergent,
  title={Emergent Real-World Robotic Skills via Unsupervised Off-Policy Reinforcement Learning},
  author={Sharma, Archit and Ahn, Michael and Levine, Sergey and Kumar, Vikash and Hausman, Karol and Gu, Shixiang},
  journal={arXiv preprint arXiv:2004.12974},
  year={2020}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}

@inproceedings{yang2020data,
  title={Data efficient reinforcement learning for legged robots},
  author={Yang, Yuxiang and Caluwaerts, Ken and Iscen, Atil and Zhang, Tingnan and Tan, Jie and Sindhwani, Vikas},
  booktitle={Conference on Robot Learning},
  pages={1--10},
  year={2020},
  organization={PMLR}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{zhu2020ingredients,
  title={The Ingredients of Real-World Robotic Reinforcement Learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}
@inproceedings{kohl2004policy,
  title={Policy gradient reinforcement learning for fast quadrupedal locomotion},
  author={Kohl, Nate and Stone, Peter},
  booktitle={IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA'04. 2004},
  volume={3},
  pages={2619--2624},
  year={2004},
  organization={IEEE}
}

@inproceedings{ng2003autonomous,
  title={Autonomous helicopter flight via reinforcement learning.},
  author={Ng, Andrew Y and Kim, H Jin and Jordan, Michael I and Sastry, Shankar and Ballianda, Shiv},
  booktitle={NIPS},
  volume={16},
  year={2003},
  organization={Citeseer}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}

@inproceedings{ghadirzadeh2017deep,
  title={Deep predictive policy training using reinforcement learning},
  author={Ghadirzadeh, Ali and Maki, Atsuto and Kragic, Danica and Bj{\"o}rkman, M{\aa}rten},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2351--2358},
  year={2017},
  organization={IEEE}
}

@inproceedings{chebotar2017combining,
  title={Combining model-based and model-free updates for trajectory-centric reinforcement learning},
  author={Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={703--711},
  year={2017},
  organization={PMLR}
}

@article{haarnoja2018learning,
  title={Learning to walk via deep reinforcement learning},
  author={Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.11103},
  year={2018}
}

@misc{ha2020learning,
      title={Learning to Walk in the Real World with Minimal Human Effort}, 
      author={Sehoon Ha and Peng Xu and Zhenyu Tan and Sergey Levine and Jie Tan},
      year={2020},
      eprint={2002.08550},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{moldovan2012safe,
  title={Safe exploration in markov decision processes},
  author={Moldovan, Teodor Mihai and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1205.4810},
  year={2012}
}

@article{thananjeyan2020recovery,
  title={Recovery rl: Safe reinforcement learning with learned recovery zones},
  author={Thananjeyan, Brijen and Balakrishna, Ashwin and Nair, Suraj and Luo, Michael and Srinivasan, Krishnan and Hwang, Minho and Gonzalez, Joseph E and Ibarz, Julian and Finn, Chelsea and Goldberg, Ken},
  journal={arXiv preprint arXiv:2010.15920},
  year={2020}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@inproceedings{han2015learning,
  title={Learning compound multi-step controllers under unknown dynamics},
  author={Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6435--6442},
  year={2015},
  organization={IEEE}
}

@article{chow2018lyapunov,
  title={A lyapunov-based approach to safe reinforcement learning},
  author={Chow, Yinlam and Nachum, Ofir and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1805.07708},
  year={2018}
}

@inproceedings{bansal2017hamilton,
  title={Hamilton-Jacobi reachability: A brief overview and recent advances},
  author={Bansal, Somil and Chen, Mo and Herbert, Sylvia and Tomlin, Claire J},
  booktitle={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  pages={2242--2253},
  year={2017},
  organization={IEEE}
}

@article{fisac2018general,
  title={A general safety framework for learning-based control in uncertain robotic systems},
  author={Fisac, Jaime F and Akametalu, Anayo K and Zeilinger, Melanie N and Kaynama, Shahab and Gillula, Jeremy and Tomlin, Claire J},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={7},
  pages={2737--2752},
  year={2018},
  publisher={IEEE}
}

@inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{khetarpal2020towards,
  title={Towards Continual Reinforcement Learning: A Review and Perspectives},
  author={Khetarpal, Khimya and Riemer, Matthew and Rish, Irina and Precup, Doina},
  journal={arXiv preprint arXiv:2012.13490},
  year={2020}
}

@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}

@article{zeng2020tossingbot,
  title={Tossingbot: Learning to throw arbitrary objects with residual physics},
  author={Zeng, Andy and Song, Shuran and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  journal={IEEE Transactions on Robotics},
  volume={36},
  number={4},
  pages={1307--1319},
  year={2020},
  publisher={IEEE}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  journal={arXiv preprint arXiv:1705.08551},
  year={2017}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@article{turchetta2016safe,
  title={Safe exploration in finite markov decision processes with gaussian processes},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  journal={arXiv preprint arXiv:1606.04753},
  year={2016}
}

@inproceedings{alshiekh2018safe,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}

@article{narvekar2018learning,
  title={Learning curriculum policies for reinforcement learning},
  author={Narvekar, Sanmit and Stone, Peter},
  journal={arXiv preprint arXiv:1812.00285},
  year={2018}
}

@article{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.2661},
  year={2014}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{yahya2017collective,
  title={Collective robot reinforcement learning with distributed asynchronous guided policy search},
  author={Yahya, Ali and Li, Adrian and Kalakrishnan, Mrinal and Chebotar, Yevgen and Levine, Sergey},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={79--86},
  year={2017},
  organization={IEEE}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{Tesauro1995TemporalDL,
  title={Temporal difference learning and TD-Gammon},
  author={G. Tesauro},
  journal={Commun. ACM},
  year={1995},
  volume={38},
  pages={58-68}
}

@inproceedings{poking,
  editor    = {Daniel D. Lee and
               Masashi Sugiyama and
               Ulrike von Luxburg and
               Isabelle Guyon and
               Roman Garnett},
  title     = {Learning to Poke by Poking: Experiential Learning of Intuitive Physics},
  booktitle = {NeurIPS},
  year      = {2016},
}

@article{Rajeswaran2018LearningCD,
  title={Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations},
  author={A. Rajeswaran and V. Kumar and Abhishek Gupta and John Schulman and E. Todorov and Sergey Levine},
  journal={ArXiv},
  year={2018},
  volume={abs/1709.10087}
}

@article{Gupta2021ResetFreeRL,
  title={Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention},
  author={Abhishek Gupta and Justin Yu and Tony Zhao and Vikash Kumar and Aaron Rovinsky and Kelvin Xu and Thomas Devlin and Sergey Levine},
  journal={ArXiv},
  year={2021},
  volume={abs/2104.11203}
}

@article{Xu2020ContinualLO,
  title={Continual Learning of Control Primitives: Skill Discovery via Reset-Games},
  author={Kelvin Xu and Siddharth Verma and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2011.05286}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

@article{lu2020reset,
  title={Reset-Free Lifelong Learning with Skill-Space Planning},
  author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:2012.03548},
  year={2020}
}

@article{hafner2017tensorflow,
  title={Tensorflow agents: Efficient batched reinforcement learning in tensorflow},
  author={Hafner, Danijar and Davidson, James and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1709.02878},
  year={2017}
}

@article{konidaris2009skill,
  title={Skill discovery in continuous reinforcement learning domains using skill chaining},
  author={Konidaris, George and Barto, Andrew},
  journal={Advances in neural information processing systems},
  volume={22},
  pages={1015--1023},
  year={2009}
}