@article{black2017transitions,
  title={Transitions of care: improving the quality of discharge summaries completed by internal medicine residents},
  author={Black, Meghan and Colford, Cristin M},
  journal={MedEdPORTAL},
  volume={13},
  pages={10613},
  year={2017},
  publisher={Association of American Medical Colleges}
}

@article{chatterton2023primary,
  title={Primary Care Physicians’ Perspectives on High-Quality Discharge Summaries},
  author={Chatterton, Brittany and Chen, Jennifer and Schwarz, Eleanor Bimla and Karlin, Jennifer},
  journal={Journal of General Internal Medicine},
  pages={1--6},
  year={2023},
  publisher={Springer}
}

@article{bae2024ehrxqa,
  title={EHRXQA: A multi-modal question answering dataset for electronic health records with chest x-ray images},
  author={Bae, Seongsu and Kyung, Daeun and Ryu, Jaehee and Cho, Eunbyeol and Lee, Gyubok and Kweon, Sunjun and Oh, Jungwoo and Ji, Lei and Chang, Eric and Kim, Tackeun and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{zhang2023deep,
  title={Deep learning for medical prediction in electronic health records},
  author={Zhang, Xinlu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={13},
  pages={16145--16146},
  year={2023}
}

@article{yang2022large,
  title={A large language model for electronic health records},
  author={Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B and Flores, Mona G and others},
  journal={NPJ digital medicine},
  volume={5},
  number={1},
  pages={194},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{guevara2024large,
  title={Large language models to identify social determinants of health in electronic health records},
  author={Guevara, Marco and Chen, Shan and Thomas, Spencer and Chaunzwa, Tafadzwa L and Franco, Idalid and Kann, Benjamin H and Moningi, Shalini and Qian, Jack M and Goldstein, Madeleine and Harper, Susan and others},
  journal={NPJ digital medicine},
  volume={7},
  number={1},
  pages={6},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{peng2023study,
  title={A study of generative large language model for medical research and healthcare},
  author={Peng, Cheng and Yang, Xi and Chen, Aokun and Smith, Kaleb E and PourNejatian, Nima and Costa, Anthony B and Martin, Cheryl and Flores, Mona G and Zhang, Ying and Magoc, Tanja and others},
  journal={NPJ Digital Medicine},
  volume={6},
  number={1},
  pages={210},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{fleming2024medalign,
  title={MedAlign: A Clinician-Generated Dataset for Instruction Following with Electronic Medical Records},
  author={Fleming, Scott L and Lozano, Alejandro and Haberkorn, William J and Jindal, Jenelle A and Reis, Eduardo and Thapa, Rahul and Blankemeier, Louis and Genkins, Julian Z and Steinberg, Ethan and Nayak, Ashwin and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22021--22030},
  year={2024}
}

@article{d2004evaluation,
  title={An evaluation of information-seeking behaviors of general pediatricians},
  author={D’Alessandro, Donna M and Kreiter, Clarence D and Peterson, Michael W},
  journal={Pediatrics},
  volume={113},
  number={1},
  pages={64--69},
  year={2004},
  publisher={American Academy of Pediatrics}
}

@inproceedings{jin2019pubmedqa,
  title={PubMedQA: A Dataset for Biomedical Research Question Answering},
  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2567--2577},
  year={2019}
}

@inproceedings{pal2022medmcqa,
  title={Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering},
  author={Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle={Conference on Health, Inference, and Learning},
  pages={248--260},
  year={2022},
  organization={PMLR}
}

@article{jin2021disease,
  title={What disease does this patient have? a large-scale open domain question answering dataset from medical exams},
  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
  journal={Applied Sciences},
  volume={11},
  number={14},
  pages={6421},
  year={2021},
  publisher={MDPI}
}


@inproceedings{hendrycks2020measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@article{raghavan2018annotating,
  title={Annotating electronic medical records for question answering},
  author={Raghavan, Preethi and Patwardhan, Siddharth and Liang, Jennifer J and Devarakonda, Murthy V},
  journal={arXiv preprint arXiv:1805.06816},
  year={2018}
}

@inproceedings{fan2019annotating,
  title={Annotating and characterizing clinical sentences with explicit why-QA cues},
  author={Fan, Jungwei},
  booktitle={Proceedings of the 2nd Clinical Natural Language Processing Workshop},
  pages={101--106},
  year={2019}
}

@inproceedings{yue-etal-2020-clinical,
    title = "Clinical Reading Comprehension: A Thorough Analysis of the emr{QA} Dataset",
    author = "Yue, Xiang  and
      Jimenez Gutierrez, Bernal  and
      Sun, Huan",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "4474--4486",
}


@inproceedings{soni2022radqa,
  title={RadQA: A Question Answering Dataset to Improve Comprehension of Radiology Reports},
  author={Soni, Sarvesh and Gudala, Meghana and Pajouhi, Atieh and Roberts, Kirk},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={6250--6259},
  year={2022}
}

@article{moon2023extractive,
  title={Extractive Clinical Question-Answering With Multianswer and Multifocus Questions: Data Set Development and Evaluation Study},
  author={Moon, Sungrim and He, Huan and Jia, Heling and Liu, Hongfang and Fan, Jungwei Wilfred and others},
  journal={JMIR AI},
  volume={2},
  number={1},
  pages={e41818},
  year={2023},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@inproceedings{lehman2022learning,
  title={Learning to Ask Like a Physician},
  author={Lehman, Eric and Lialin, Vladislav and Legaspi, Katelyn Edelwina and Sy, Anne Janelle and Pile, Patricia Therese and Alberto, Nicole Rose and Ragasa, Richard Raymund and Puyat, Corinna Victoria and Tali{\~n}o, Marianne Katharina and Alberto, Isabelle Rose and others},
  booktitle={Proceedings of the 4th Clinical Natural Language Processing Workshop},
  pages={74--86},
  year={2022}
}

@article{johnson2023mimic,
  title={MIMIC-IV, a freely accessible electronic health record dataset},
  author={Johnson, Alistair EW and Bulgarelli, Lucas and Shen, Lu and Gayles, Alvin and Shammout, Ayad and Horng, Steven and Pollard, Tom J and Hao, Sicheng and Moody, Benjamin and Gow, Brian and others},
  journal={Scientific data},
  volume={10},
  number={1},
  pages={1},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{uslu2021value,
  title={Value of the electronic medical record for hospital care: update from the literature},
  author={Uslu, Aykut and Stausberg, J{\"u}rgen and others},
  journal={Journal of medical Internet research},
  volume={23},
  number={12},
  pages={e26323},
  year={2021},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{upadhyay2022qualitative,
  title={A qualitative analysis of the impact of electronic health records (EHR) on healthcare quality and safety: Clinicians’ lived experiences},
  author={Upadhyay, Soumya and Hu, Han-fen},
  journal={Health Services Insights},
  volume={15},
  pages={11786329211070722},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{singhal2023large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={172--180},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{singhal2023towards,
  title={Towards expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and Pfohl, Stephen and Cole-Lewis, Heather and Neal, Darlene and others},
  journal={arXiv preprint arXiv:2305.09617},
  year={2023}
}

@article{nori2023capabilities,
  title={Capabilities of gpt-4 on medical challenge problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023}
}

@article{lievin2024can,
  title={Can large language models reason about medical questions?},
  author={Li{\'e}vin, Valentin and Hother, Christoffer Egeberg and Motzfeldt, Andreas Geert and Winther, Ole},
  journal={Patterns},
  volume={5},
  number={3},
  year={2024},
  publisher={Elsevier}
}


@article{nori2023can,
  title={Can generalist foundation models outcompete special-purpose tuning? case study in medicine},
  author={Nori, Harsha and Lee, Yin Tat and Zhang, Sheng and Carignan, Dean and Edgar, Richard and Fusi, Nicolo and King, Nicholas and Larson, Jonathan and Li, Yuanzhi and Liu, Weishung and others},
  journal={arXiv preprint arXiv:2311.16452},
  year={2023}
}

@article{chen2023meditron,
  title={Meditron-70b: Scaling medical pretraining for large language models},
  author={Chen, Zeming and Cano, Alejandro Hern{\'a}ndez and Romanou, Angelika and Bonnet, Antoine and Matoba, Kyle and Salvi, Francesco and Pagliardini, Matteo and Fan, Simin and K{\"o}pf, Andreas and Mohtashami, Amirkeivan and others},
  journal={arXiv preprint arXiv:2311.16079},
  year={2023}
}

@article{mehandru2024evaluating,
  title={Evaluating large language models as agents in the clinic},
  author={Mehandru, Nikita and Miao, Brenda Y and Almaraz, Eduardo Rodriguez and Sushil, Madhumita and Butte, Atul J and Alaa, Ahmed},
  journal={npj Digital Medicine},
  volume={7},
  number={1},
  pages={84},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{raghavan2018annotating,
  title={Annotating electronic medical records for question answering},
  author={Raghavan, Preethi and Patwardhan, Siddharth and Liang, Jennifer J and Devarakonda, Murthy V},
  journal={arXiv preprint arXiv:1805.06816},
  year={2018}
}

@article{pampari2018emrqa,
  title={emrqa: A large corpus for question answering on electronic medical records},
  author={Pampari, Anusri and Raghavan, Preethi and Liang, Jennifer and Peng, Jian},
  journal={arXiv preprint arXiv:1809.00732},
  year={2018}
}

@article{uzuner2008identifying,
  title={Identifying patient smoking status from medical discharge records},
  author={Uzuner, {\"O}zlem and Goldstein, Ira and Luo, Yuan and Kohane, Isaac},
  journal={Journal of the American Medical Informatics Association},
  volume={15},
  number={1},
  pages={14--24},
  year={2008},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{uzuner2009recognizing,
  title={Recognizing obesity and comorbidities in sparse data},
  author={Uzuner, {\"O}zlem},
  journal={Journal of the American Medical Informatics Association},
  volume={16},
  number={4},
  pages={561--570},
  year={2009},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{uzuner2010extracting,
  title={Extracting medication information from clinical text},
  author={Uzuner, {\"O}zlem and Solti, Imre and Cadag, Eithon},
  journal={Journal of the American Medical Informatics Association},
  volume={17},
  number={5},
  pages={514--518},
  year={2010},
  publisher={Oxford University Press}
}

@article{uzuner20112010,
  title={2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text},
  author={Uzuner, {\"O}zlem and South, Brett R and Shen, Shuying and DuVall, Scott L},
  journal={Journal of the American Medical Informatics Association},
  volume={18},
  number={5},
  pages={552--556},
  year={2011},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Lehman, Li-wei H and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  number={1},
  pages={1--9},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{yue2021cliniqg4qa,
  title={Cliniqg4qa: Generating diverse questions for domain adaptation of clinical question answering},
  author={Yue, Xiang and Zhang, Xinliang Frederick and Yao, Ziyu and Lin, Simon and Sun, Huan},
  booktitle={2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  pages={580--587},
  year={2021},
  organization={IEEE}
}


@inproceedings{devlin2018bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{kamalloo-etal-2023-evaluating,
    title = "Evaluating Open-Domain Question Answering in the Era of Large Language Models",
    author = "Kamalloo, Ehsan  and
      Dziri, Nouha  and
      Clarke, Charles  and
      Rafiei, Davood",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.307",
    doi = "10.18653/v1/2023.acl-long.307",
    pages = "5591--5606",
    abstract = "Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-open, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60{\%}, making it on par with existing top models, and the InstructGPT (few-shot) model actually achieves a new state-of-the-art on NQ-open. We also find that more than 50{\%} of lexical matching failures are attributed to semantically equivalent answers. We further demonstrate that regex matching ranks QA models consistent with human judgments, although still suffering from unnecessary strictness. Finally, we demonstrate that automated evaluation models are a reasonable surrogate for lexical matching in some circumstances, but not for long-form answers generated by LLMs. The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs. At this time, there appears to be no substitute for human evaluation.",
}



@article{demner2009can,
  title={What can natural language processing do for clinical decision support?},
  author={Demner-Fushman, Dina and Chapman, Wendy W and McDonald, Clement J},
  journal={Journal of biomedical informatics},
  volume={42},
  number={5},
  pages={760--772},
  year={2009},
  publisher={Elsevier}
}

@article{lederman2022tasks,
  title={Tasks as needs: reframing the paradigm of clinical natural language processing research for real-world decision support},
  author={Lederman, Asher and Lederman, Reeva and Verspoor, Karin},
  journal={Journal of the American Medical Informatics Association},
  volume={29},
  number={10},
  pages={1810--1817},
  year={2022},
  publisher={Oxford Academic}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{liu2303g,
  title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment (2023)},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={URL http://arxiv. org/abs/2303.16634}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{llama3modelcard,

title={Llama 3 Model Card},

author={AI@Meta},

year={2024},

url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}

}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{toma2023clinical,
  title={Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding},
  author={Toma, Augustin and Lawler, Patrick R and Ba, Jimmy and Krishnan, Rahul G and Rubin, Barry B and Wang, Bo},
  journal={arXiv preprint arXiv:2305.12031},
  year={2023}
}

@software{hunterlee2023orcaplaty1,
  title = {OpenOrcaPlatypus: Llama2-13B Model Instruct-tuned on Filtered OpenOrcaV1 GPT-4 Dataset and Merged with divergent STEM and Logic Dataset Model},
  author = {Ariel N. Lee and Cole J. Hunter and Nataniel Ruiz and Bleys Goodson and Wing Lian and Guan Wang and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B}},
}

@article{lee2023platypus,
  title = {Platypus: Quick, cheap, and powerful refinement of llms},
  author = {Lee, Ariel N and Hunter, Cole J and Ruiz, Nataniel},
  journal = {arXiv preprint arXiv:2308.07317},
  year = {2023},
}

@online{MosaicML2023Introducing,
    author    = {MosaicML},
    title     = {Introducing MPT-7B: A New Standard for Open-Source,
    Commercially Usable LLMs},
    year      = {2023},
    url       = {www.mosaicml.com/blog/mpt-7b},
    note      = {Accessed: 2023-05-05},
    urldate   = {2023-05-05}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

@misc{Synthia-13B-v1.2,
  author = {Migel Tissera},
  title = {Synthia-13B-v1.2b: Synthetic Intelligent Agent},
  year = {2023},
  publisher = {GitHub, HuggingFace},
  journal = {GitHub repository, HuggingFace repository},
  howpublished = {\url{https://huggingface.co/migtissera/Synthia-13B}},
}

@article{kweon2023publicly,
  title={Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes},
  author={Kweon, Sunjun and Kim, Junu and Kim, Jiyoun and Im, Sujeong and Cho, Eunbyeol and Bae, Seongsu and Oh, Jungwoo and Lee, Gyubok and Moon, Jong Hak and You, Seng Chan and others},
  journal={arXiv preprint arXiv:2309.00237},
  year={2023}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@misc{dolphin,
  author = {Cognitive},
  title = {Dolphin-2.0-mistral-7b},
  year = {2023},
  publisher = {GitHub, HuggingFace},
  journal = {GitHub repository, HuggingFace repository},
  howpublished = {\url{https://huggingface.co/cognitivecomputations/dolphin-2.0-mistral-7b}},
}

@software{lian2023mistralorca1,
  title = {MistralOrca: Mistral-7B Model Instruct-tuned on Filtered OpenOrcaV1 GPT-4 Dataset},
  author = {Wing Lian and Bleys Goodson and Guan Wang and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca}},
}

@misc{SynthIA-7B-v1.3,
  author = {Migel Tissera},
  title = {SynthIA-7B-v1.3: Synthetic Intelligent Agent},
  year = {2023},
  publisher = {GitHub, HuggingFace},
  journal = {GitHub repository, HuggingFace repository},
  howpublished = {\url{https://huggingface.co/migtissera/Synthia-13B}},
}

@article{henry20202018,
  title={2018 n2c2 shared task on adverse drug events and medication extraction in electronic health records},
  author={Henry, Sam and Buchan, Kevin and Filannino, Michele and Stubbs, Amber and Uzuner, Ozlem},
  journal={Journal of the American Medical Informatics Association},
  volume={27},
  number={1},
  pages={3--12},
  year={2020},
  publisher={Oxford University Press}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@misc{open-llm-leaderboard,
  author = {Edward Beeching and Clémentine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstall and Thomas Wolf},
  title = {Open LLM Leaderboard},
  year = {2023},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}"
}

@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@article{zellers2019hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@article{sakaguchi2021winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 12,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.4.0},
  doi          = {10.5281/zenodo.10256836},
  url          = {https://zenodo.org/records/10256836}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{lin2021truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}

@article{park2024assessing,
  title={Assessing the research landscape and clinical utility of large language models: a scoping review},
  author={Park, Ye-Jean and Pillai, Abhinav and Deng, Jiawen and Guo, Eddie and Gupta, Mehul and Paget, Mike and Naugler, Christopher},
  journal={BMC Medical Informatics and Decision Making},
  volume={24},
  number={1},
  pages={72},
  year={2024},
  publisher={Springer}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@inproceedings{alsentzer2019publicly,
  title={Publicly Available Clinical BERT Embeddings},
  author={Alsentzer, Emily and Murphy, John and Boag, William and Weng, Wei-Hung and Jindi, Di and Naumann, Tristan and McDermott, Matthew},
  booktitle={Proceedings of the 2nd Clinical Natural Language Processing Workshop},
  pages={72--78},
  year={2019}
}