@inproceedings{mvitv1,
  title={Multiscale vision transformers},
  author={Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{mvitv2,
  title={MViTv2: Improved Multiscale Vision Transformers for Classification and Detection},
  author={Li, Yanghao and Wu, Chao-Yuan and Fan, Haoqi and Mangalam, Karttikeya and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{mae,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {NeurIPS},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 year = {2012}
}



@inproceedings{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={ICML},
  year={2019},
}

@inproceedings{swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009},
}

@inproceedings{droppath,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={ECCV},
  year={2016},
}

@article{mae-st,
  title={Masked Autoencoders As Spatiotemporal Learners},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Li, Yanghao and He, Kaiming},
  journal={NeurIPS},
  year={2022}
}

@article{mae-audio,
  title={Masked Autoencoders that Listen},
  author={Huang, Po-Yao and Xu, Hu and Li, Juncheng and Baevski, Alexei and Auli, Michael and Galuba, Wojciech and Metze, Florian and Feichtenhofer, Christoph},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{maskfeat,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{scalingvits,
  title={Scaling Vision Transformers},
  author={Xiaohua Zhai and Alexander Kolesnikov and Neil Houlsby and Lucas Beyer},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{vitdet,
  title={Exploring plain vision transformer backbones for object detection},
  author={Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
  booktitle={ECCV},
  year={2022}
}

@article{deit3,
  title={Deit iii: Revenge of the vit},
  author={Touvron, Hugo and Cord, Matthieu and J{\'e}gou, Herv{\'e}},
  journal={ECCV},
  year={2022}
}

@inproceedings{levit,
  title={Levit: a vision transformer in convnet's clothing for faster inference},
  author={Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\'e}gou, Herv{\'e} and Douze, Matthijs},
  booktitle={ICCV},
  year={2021}
}



%%%%%%%%%%%%%%%%%%% related work session

@inproceedings{ranftl2021vision,
  title={Vision transformers for dense prediction},
  author={Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{duke2021sstvos,
  title={Sstvos: Sparse spatiotemporal transformers for video object segmentation},
  author={Duke, Brendan and Ahmed, Abdalla and Wolf, Christian and Aarabi, Parham and Taylor, Graham W},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{misra2021end,
  title={An end-to-end transformer model for 3d object detection},
  author={Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
  booktitle={ICCV},
  year={2021}
}

@article{bozic2021transformerfusion,
  title={Transformerfusion: Monocular rgb scene reconstruction using transformers},
  author={Bozic, Aljaz and Palafox, Pablo and Thies, Justus and Dai, Angela and Nie{\ss}ner, Matthias},
  journal={NeurIPS},
  year={2021}
}

%convmae
@inproceedings{gao2022mcmae,
  title={MCMAE: Masked Convolution Meets Masked Autoencoders},
  author={Gao, Peng and Ma, Teli and Li, Hongsheng and Lin, Ziyi and Dai, Jifeng and Qiao, Yu},
  booktitle={NeurIPS},
  year={2022},
}

%videomae
@inproceedings{tong2022videomae,
  title={Video{MAE}: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training},
  author={Zhan Tong and Yibing Song and Jue Wang and Limin Wang},
  booktitle={NeurIPS},
  year={2022}
}

%greenhvit
@inproceedings{huang2022green,
  title={Green Hierarchical Vision Transformer for Masked Image Modeling},
  author={Huang, Lang and You, Shan and Zheng, Mingkai and Wang, Fei and Qian, Chen and Yamasaki, Toshihiko},
  booktitle={NeurIPS},
  year={2022},
}

%%% MIM

@article{vincent2010stacked,
  title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.},
  author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine and Bottou, L{\'e}on},
  journal={JMLR},
  year={2010}
}

@inproceedings{pathak2016context,
  title={Context encoders: Feature learning by inpainting},
  author={Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle={CVPR},
  year={2016}
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={ICLR},
  year={2022},
}

@inproceedings{chen2020generative,
  title={Generative pretraining from pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle={ICML},
  year={2020},
}

@article{li2022uniform,
  title={Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality},
  author={Li, Xiang and Wang, Wenhai and Yang, Lingfeng and Yang, Jian},
  journal={arXiv preprint arXiv:2205.10063},
  year={2022}
}

@article{woo2023convnextv2,
  title={ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders},
  author={Woo, Sanghyun and Debnath, Shoubhik and Hu, Ronghang and Chen, Xinlei and Liu, Zhuang and Kweon, In So and Xie, Saining},
  journal={arXiv preprint arXiv:2301.00808},
  year={2023}
}



%simmim
@inproceedings{xie2021simmim,
  title={SimMIM: A Simple Framework for Masked Image Modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={CVPR},
  year={2022}
}



% EMA teachers (orthogonal to our work)


@inproceedings{data2vec,
  author = {Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  title = {data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language},
  booktitle={ICML},
  year = {2022},
}


@article{splitmask,  
  author = {El-Nouby, Alaaeldin and Izacard, Gautier and Touvron, Hugo and Laptev, Ivan and Jegou, Herv√© and Grave, Edouard},
  title = {Are Large-scale Datasets Necessary for Self-Supervised Pre-training?},
  journal={arXiv preprint arXiv:2112.10740},
  year = {2021},
}


% clip targets
@article{milan,
  author = {Hou, Zejiang and Sun, Fei and Chen, Yen-Kuang and Xie, Yuan and Kung, Sun-Yuan},
  title = {MILAN: Masked Image Pretraining on Language Assisted Representation},
  journal={arXiv preprint arXiv:2208.06049},
  year = {2022},
}


%% CNNs
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  year={1998},
}

%% datasets
@inproceedings {NIPS2014_3fe94a00,
    author = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
    booktitle = {NeurIPS},
    title = {Learning Deep Features for Scene Recognition using Places Database},
    year = {2014},
}

% dataset AVA
@inproceedings{gu2018ava,
  title={{AVA}: A video dataset of spatio-temporally localized atomic visual actions},
  author={Gu, Chunhui and Sun, Chen and Ross, David A and Vondrick, Carl and Pantofaru, Caroline and Li, Yeqing and Vijayanarasimhan, Sudheendra and Toderici, George and Ricco, Susanna and Sukthankar, Rahul and others},
  booktitle={CVPR},
  year={2018}
}

% AdamW
@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{loshchilov2016sgdr,
  title={{SGDR}: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2017}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv:1706.02677},
  year={2017}
}

% dataset ssv2
@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={ICCV},
  year={2017}
}

% dataset iNats
@inproceedings{van2018inaturalist,
  title={The {iNaturalist} species classification and detection dataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle={CVPR},
  year={2018}
}


% dataset kinetics-400
@article{k400,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}


@article{k600,  
  author = {Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  title = {A Short Note about Kinetics-600},
  journal={arXiv preprint arXiv:1808.01340},
  year = {2018},
}


@article{k700,
  author = {Carreira, Joao and Noland, Eric and Hillier, Chloe and Zisserman, Andrew},
  title = {A Short Note on the Kinetics-700 Human Action Dataset},
  journal={arXiv preprint arXiv:1907.06987},
  year = {2019},
}




@InProceedings{maskrcnn,
  author    = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  title     = {{Mask R-CNN}},
  booktitle = {ICCV},
  year      = {2017},
}

@InProceedings{coco,
  author    = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  title     = {{Microsoft COCO: Common objects in context}},
  booktitle = {ECCV},
  year      = {2014},
}

@InProceedings{fpn,
  author    = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  title     = {Feature Pyramid Networks for Object Detection},
  booktitle = {CVPR},
  year      = {2017},
}

% faster rcnn
@article{ren2015faster,
  title={{Faster R-CNN}: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={NeurIPS},
  year={2015}
}


@Misc{Wu2019,
  author          = {Yuxin Wu and Alexander Kirillov and Francisco Massa and Wan-Yen Lo and Ross Girshick},
  title           = {Detectron2},
  year            = {2019},
  nothowpublished = {\url{https://github.com/facebookresearch/detectron2}},
}

@inproceedings{Ghiasi2021,
  title={Simple copy-paste is a strong data augmentation method for instance segmentation},
  author={Ghiasi, Golnaz and Cui, Yin and Srinivas, Aravind and Qian, Rui and Lin, Tsung-Yi and Cubuk, Ekin D and Le, Quoc V and Zoph, Barret},
  booktitle={CVPR},
  year={2021}
}


@article{Goyal2017,  
  author = {Goyal, Priya and Doll√°r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal = {arXiv preprint arXiv:1706.02677},
  title = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
  year = {2017},
}



@inproceedings{adamw,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2019},
}


@inproceedings{sgdr,
  title={{SGDR}: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2017}
}


@inproceedings{Hoffer2020,
  title={Augment your batch: Improving generalization through instance
  repetition},
  author={Hoffer, Elad and Ben-Nun, Tal and Hubara, Itay and Giladi, Niv and Hoefler, Torsten and Soudry, Daniel},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={ICCV},
  year={2019}
}


@inproceedings{inception,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={CVPR},
  year={2016}
}


@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {JMLR},
  year    = {2014},
}


@inproceedings{electra,
  title={{ELECTRA}: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{randaug,
  title={{RandAugment}: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={CVPR},
  year={2020}
}


@article{flashattn,
  title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  author={Dao, Tri and Fu, Daniel Y and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2205.14135},
  year={2022}
}


@inproceedings{bertasius2021space,
  title={Is Space-Time Attention All You Need for Video Understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  year={2021}
}

@inproceedings{vivit,
  title={ViViT: A Video Vision Transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{pvt,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{hog,
  title={Histograms of oriented gradients for human detection},
  author={Dalal, Navneet and Triggs, Bill},
  booktitle={CVPR},
  year={2005},
}