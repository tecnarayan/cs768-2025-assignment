\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmed et~al.(2022{\natexlab{a}})Ahmed, Li, Ton, Guo, Chang,
  Kordjamshidi, Srikumar, Van~den Broeck, and Singh]{Ahmed22pylon}
Kareem Ahmed, Tao Li, Thy Ton, Quan Guo, Kai-Wei Chang, Parisa Kordjamshidi,
  Vivek Srikumar, Guy Van~den Broeck, and Sameer Singh.
\newblock Pylon: A pytorch framework for learning with constraints.
\newblock In \emph{Proceedings of the 36th AAAI Conference on Artificial
  Intelligence (Demo Track)}, feb 2022{\natexlab{a}}.

\bibitem[Ahmed et~al.(2022{\natexlab{b}})Ahmed, Teso, Chang, Broeck, and
  Vergari]{Ahmed2022}
Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van~den Broeck, and Antonio
  Vergari.
\newblock Semantic probabilistic layers for neuro-symbolic learning.
\newblock In \emph{NeurIPS}, 2022{\natexlab{b}}.

\bibitem[Ahmed et~al.(2022{\natexlab{c}})Ahmed, Wang, Chang, and den
  Broeck]{Ahmed22nesyentropy}
Kareem Ahmed, Eric Wang, Kai-Wei Chang, and Guy~Van den Broeck.
\newblock Neuro-symbolic entropy regularization.
\newblock In \emph{The 38th Conference on Uncertainty in Artificial
  Intelligence}, 2022{\natexlab{c}}.

\bibitem[Ahmed et~al.(2023{\natexlab{a}})Ahmed, Chang, and Van~den
  Broeck]{AhmedAISTATS23}
Kareem Ahmed, Kai-Wei Chang, and Guy Van~den Broeck.
\newblock Semantic strengthening of neuro-symbolic learning.
\newblock In \emph{Proceedings of the 26th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, apr 2023{\natexlab{a}}.

\bibitem[Ahmed et~al.(2023{\natexlab{b}})Ahmed, Zeng, Niepert, and Van~den
  Broeck]{AhmedICLR23}
Kareem Ahmed, Zhe Zeng, Mathias Niepert, and Guy Van~den Broeck.
\newblock Simple: A gradient estimator for k-subset sampling.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, may 2023{\natexlab{b}}.

\bibitem[Besag(1975)]{Besag1975}
Julian Besag.
\newblock Statistical analysis of non-lattice data.
\newblock \emph{Journal of the Royal Statistical Society. Series D (The
  Statistician)}, pages pp. 179--195, 1975.

\bibitem[Bo{\v{s}}njak et~al.(2017)Bo{\v{s}}njak, Rockt{\"a}schel, Naradowsky,
  and Riedel]{bosnjak2017programming}
Matko Bo{\v{s}}njak, Tim Rockt{\"a}schel, Jason Naradowsky, and Sebastian
  Riedel.
\newblock Programming with a differentiable forth interpreter.
\newblock In \emph{Proceedings of the 34th ICML}, 2017.

\bibitem[Choi et~al.(2020)Choi, Vergari, and Van~den Broeck]{choi2020pc}
YooJung Choi, Antonio Vergari, and Guy Van~den Broeck.
\newblock Probabilistic circuits: A unifying framework for tractable
  probabilistic modeling.
\newblock 2020.

\bibitem[Dai et~al.(2018)Dai, Xu, Yu, and Zhou]{dai2018}
Wang-Zhou Dai, Qiu-Ling Xu, Yang Yu, and Zhi-Hua Zhou.
\newblock Tunneling neural perception and logic reasoning through abductive
  learning, 2018.

\bibitem[Darwiche and Marquis(2002)]{darwiche02}
Adnan Darwiche and Pierre Marquis.
\newblock A knowledge compilation map.
\newblock \emph{JAIR}, 2002.

\bibitem[Diligenti et~al.(2017)Diligenti, Gori, and Saccà]{diligenti2017}
Michelangelo Diligenti, Marco Gori, and Claudio Saccà.
\newblock Semantic-based regularization for learning and inference.
\newblock \emph{Artificial Intelligence}, 2017.

\bibitem[Donadello et~al.(2017)Donadello, Serafini, and d'Avila
  Garcez]{donadello2017}
Ivan Donadello, Luciano Serafini, and Artur d'Avila Garcez.
\newblock Logic tensor networks for semantic image interpretation.
\newblock In \emph{IJCAI}, 2017.

\bibitem[Fischer et~al.(2019)Fischer, Balunovic, Drachsler-Cohen, Gehr, Zhang,
  and Vechev]{fischer19a}
Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce~Zhang, and
  Martin Vechev.
\newblock {DL}2: Training and querying neural networks with logic.
\newblock In \emph{ICML}, 2019.

\bibitem[Ganchev et~al.(2010)Ganchev, Gra{\c{c}}a, Gillenwater, and Taskar]{PR}
Kuzman Ganchev, Joao Gra{\c{c}}a, Jennifer Gillenwater, and Ben Taskar.
\newblock Posterior regularization for structured latent variable models.
\newblock \emph{Journal of Machine Learning Research}, 2010.

\bibitem[Gehman et~al.(2020)Gehman, Gururangan, Sap, Choi, and
  Smith]{Gehman2020RealToxicityPromptsEN}
Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah~A. Smith.
\newblock Realtoxicityprompts: Evaluating neural toxic degeneration in language
  models.
\newblock \emph{ArXiv}, abs/2009.11462, 2020.

\bibitem[Giunchiglia and Lukasiewicz(2020)]{giunchiglia2020coherent}
Eleonora Giunchiglia and Thomas Lukasiewicz.
\newblock Coherent hierarchical multi-label classification networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 9662--9673, 2020.

\bibitem[Giunchiglia and Lukasiewicz(2021)]{giunchiglia2021multi}
Eleonora Giunchiglia and Thomas Lukasiewicz.
\newblock Multi-label classification neural networks with hard logical
  constraints.
\newblock \emph{Journal of Artificial Intelligence Research}, 72:\penalty0
  759--818, 2021.

\bibitem[Gugger et~al.(2022)Gugger, Debut, Wolf, Schmid, Mueller, and
  Mangrulkar]{accelerate}
Sylvain Gugger, Lysandre Debut, Thomas Wolf, Philipp Schmid, Zachary Mueller,
  and Sourab Mangrulkar.
\newblock Accelerate: Training and inference at scale made simple, efficient
  and adaptable., 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He2016}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, June 2016.

\bibitem[Hoernle et~al.(2022)Hoernle, Karampatsis, Belle, and
  Gal]{Hoernle2021MultiplexNetTF}
Nicholas Hoernle, Rafael-Michael Karampatsis, Vaishak Belle, and Ya'akov Gal.
\newblock Multiplexnet: Towards fully satisfied logical constraints in neural
  networks.
\newblock In \emph{AAAI}, 2022.

\bibitem[Hu et~al.(2018)Hu, Yang, Salakhutdinov, Qin, Liang, Dong, and
  Xing]{PR3}
Zhiting Hu, Zichao Yang, Russ~R Salakhutdinov, LIANHUI Qin, Xiaodan Liang,
  Haoye Dong, and Eric~P Xing.
\newblock Deep generative models with learnable knowledge constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Kimmig et~al.(2012)Kimmig, Bach, Broecheler, Huang, and
  Getoor]{kimmig2012short}
Angelika Kimmig, Stephen Bach, Matthias Broecheler, Bert Huang, and Lise
  Getoor.
\newblock A short introduction to probabilistic soft logic.
\newblock In \emph{Proceedings of the NIPS Workshop on Probabilistic
  Programming: Foundations and Applications}, 2012.

\bibitem[Loshchilov and Hutter(2017)]{AdamW}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Lu et~al.(2022{\natexlab{a}})Lu, Meng, and Peng]{lu2022insnet}
Sidi Lu, Tao Meng, and Nanyun Peng.
\newblock Insnet: An efficient, flexible, and performant insertion-based text
  generation model.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022{\natexlab{a}}.

\bibitem[Lu et~al.(2021)Lu, West, Zellers, Le~Bras, Bhagavatula, and
  Choi]{lu2021neurologic}
Ximing Lu, Peter West, Rowan Zellers, Ronan Le~Bras, Chandra Bhagavatula, and
  Yejin Choi.
\newblock Neurologic decoding:(un) supervised neural text generation with
  predicate logic constraints.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2021.

\bibitem[Lu et~al.(2022{\natexlab{b}})Lu, Welleck, West, Jiang, Kasai,
  Khashabi, Le~Bras, Qin, Yu, Zellers, Smith, and Choi]{lu2022astar}
Ximing Lu, Sean Welleck, Peter West, Liwei Jiang, Jungo Kasai, Daniel Khashabi,
  Ronan Le~Bras, Lianhui Qin, Youngjae Yu, Rowan Zellers, Noah~A. Smith, and
  Yejin Choi.
\newblock {N}euro{L}ogic a*esque decoding: Constrained text generation with
  lookahead heuristics.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2022{\natexlab{b}}.

\bibitem[Manhaeve et~al.(2018)Manhaeve, Dumancic, Kimmig, Demeester, and
  De~Raedt]{manhaeve2018}
Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc
  De~Raedt.
\newblock Deepproblog: Neural probabilistic logic programming.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Medina~Grespan et~al.(2021)Medina~Grespan, Gupta, and
  Srikumar]{Grespan21}
Mattia Medina~Grespan, Ashim Gupta, and Vivek Srikumar.
\newblock Evaluating relaxations of logic for neural networks: A comprehensive
  study.
\newblock In \emph{Proceedings of the Thirtieth International Joint Conference
  on Artificial Intelligence, {IJCAI-21}}, pages 2812--2818, 8 2021.

\bibitem[Meng et~al.(2022)Meng, Lu, Peng, and Chang]{meng2022nado}
Tao Meng, Sidi Lu, Nanyun Peng, and Kai-Wei Chang.
\newblock Controllable text generation with neurally-decomposed oracle.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022.

\bibitem[Mullenbach et~al.(2018)Mullenbach, Wiegreffe, Duke, Sun, and
  Eisenstein]{mullenbach2018explainable}
James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng Sun, and Jacob Eisenstein.
\newblock Explainable prediction of medical codes from clinical text.
\newblock \emph{arXiv preprint arXiv:1802.05695}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pazske2019}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Peharz et~al.(2020)Peharz, Lang, Vergari, Stelzner, Molina, Trapp,
  Broeck, Kersting, and Ghahramani]{peharz2020einsum}
Robert Peharz, Steven Lang, Antonio Vergari, Karl Stelzner, Alejandro Molina,
  Martin Trapp, Guy Van~den Broeck, Kristian Kersting, and Zoubin Ghahramani.
\newblock Einsum networks: Fast and scalable learning of tractable
  probabilistic circuits.
\newblock In \emph{International Conference of Machine Learning}, 2020.

\bibitem[Pogančić et~al.(2020)Pogančić, Paulus, Musil, Martius, and
  Rolinek]{Pogancic2020}
Marin~Vlastelica Pogančić, Anselm Paulus, Vit Musil, Georg Martius, and
  Michal Rolinek.
\newblock Differentiation of blackbox combinatorial solvers.
\newblock In \emph{ICLR}, 2020.

\bibitem[Post and Vilar(2018)]{post2018fast}
Matt Post and David Vilar.
\newblock Fast lexically constrained decoding with dynamic beam allocation for
  neural machine translation.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL) (Long Papers)}, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{Radford2019}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Rockt{\"a}schel et~al.(2015)Rockt{\"a}schel, Singh, and
  Riedel]{rocktaschel2015}
Tim Rockt{\"a}schel, Sameer Singh, and Sebastian Riedel.
\newblock Injecting logical background knowledge into embeddings for relation
  extraction.
\newblock In \emph{Proceedings of the 2015 Conference of the NAACL}, 2015.

\bibitem[Roth(1993)]{Roth93}
Dan Roth.
\newblock On the hardness of approximate reasoning.
\newblock In \emph{{IJCAI}}, pages 613--619. Morgan Kaufmann, 1993.

\bibitem[Susanto et~al.(2020)Susanto, Chollampatt, and
  Tan]{susanto2020lexically}
Raymond~Hendy Susanto, Shamil Chollampatt, and Liling Tan.
\newblock Lexically constrained neural machine translation with levenshtein
  transformer.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics (ACL)}, 2020.

\bibitem[Valiant(1979{\natexlab{a}})]{Valiant1979a}
Leslie~G. Valiant.
\newblock The complexity of enumeration and reliability problems.
\newblock \emph{SIAM Journal on Computing}, 1979{\natexlab{a}}.

\bibitem[Valiant(1979{\natexlab{b}})]{Valiant1979b}
L.G. Valiant.
\newblock The complexity of computing the permanent.
\newblock \emph{Theoretical Computer Science}, 1979{\natexlab{b}}.

\bibitem[Vergari et~al.(2015)Vergari, Di~Mauro, and
  Esposito]{vergari2015simplifying}
Antonio Vergari, Nicola Di~Mauro, and Floriana Esposito.
\newblock Simplifying, regularizing and strengthening sum-product network
  structure learning.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 343--358. Springer, 2015.

\bibitem[Wang et~al.(2022)Wang, Ping, Xiao, Xu, Patwary, Shoeybi, Li,
  Anandkumar, and Catanzaro]{wang2022exploring}
Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi,
  Bo~Li, Anima Anandkumar, and Bryan Catanzaro.
\newblock Exploring the limits of domain-adaptive training for detoxifying
  large-scale language models.
\newblock In \emph{Neurips}, 2022.

\bibitem[Wang et~al.(2019)Wang, Donti, Wilder, and Kolter]{Wang19}
Po{-}Wei Wang, Priya~L. Donti, Bryan Wilder, and J.~Zico Kolter.
\newblock Satnet: Bridging deep learning and logical reasoning using a
  differentiable satisfiability solver.
\newblock In \emph{{ICML}}, volume~97 of \emph{Proceedings of Machine Learning
  Research}, pages 6545--6554. {PMLR}, 2019.

\bibitem[Welbl et~al.(2021)Welbl, Glaese, Uesato, Dathathri, Mellor, Hendricks,
  Anderson, Kohli, Coppin, and Huang]{Welbl2021ChallengesID}
Johannes Welbl, Amelia Glaese, Jonathan Uesato, Sumanth Dathathri, John F.~J.
  Mellor, Lisa~Anne Hendricks, Kirsty Anderson, Pushmeet Kohli, Ben Coppin, and
  Po-Sen Huang.
\newblock Challenges in detoxifying language models.
\newblock \emph{ArXiv}, abs/2109.07445, 2021.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Scao, Gugger, Drame, Lhoest, and Rush]{transformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander~M. Rush.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}. Association for
  Computational Linguistics, 2020.

\bibitem[Xu et~al.(2018)Xu, Zhang, Friedman, Liang, and Van~den
  Broeck]{xu2018semantic}
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van~den Broeck.
\newblock A semantic loss function for deep learning with symbolic knowledge.
\newblock In \emph{International conference on machine learning}, pages
  5502--5511. PMLR, 2018.

\bibitem[Yang and Klein(2021)]{yang2021fudge}
Kevin Yang and Dan Klein.
\newblock Fudge: Controlled text generation with future discriminators.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2021.

\bibitem[Yu et~al.(2022)Yu, Zhu, Li, Hu, Wang, Ji, and
  Jiang]{SurveyConstraints}
Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji, and
  Meng Jiang.
\newblock A survey of knowledge-enhanced text generation.
\newblock \emph{ACM Comput. Surv.}, 2022.

\bibitem[Zhang et~al.(2023)Zhang, Dang, Peng, and Van~den Broeck]{GeLaTo}
Honghua Zhang, Meihua Dang, Nanyun Peng, and Guy Van~den Broeck.
\newblock Tractable control for autoregressive language generation.
\newblock In \emph{Proceedings of the 40th International Conference on Machine
  Learning (ICML)}, jul 2023.

\bibitem[Zhang et~al.(2017)Zhang, Liu, Luan, Xu, and Sun]{PR2}
Jiacheng Zhang, Yang Liu, Huanbo Luan, Jingfang Xu, and Maosong Sun.
\newblock Prior knowledge integration for neural machine translation using
  posterior regularization.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, 2017.

\end{thebibliography}
