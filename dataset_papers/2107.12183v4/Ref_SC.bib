% Encoding: UTF-8
@article{FAN201736,
title = {Sparse subspace clustering for data with missing entries and high-rank matrix completion},
journal = {Neural Networks},
volume = {93},
pages = {36-44},
year = {2017},
issn = {0893-6080},
author = {Jicong Fan and Tommy W.S. Chow},
}

@article{FAN201839,
title = {Accelerated low-rank representation for subspace clustering and semi-supervised classification on large-scale data},
journal = {Neural Networks},
volume = {100},
pages = {39-48},
year = {2018},
issn = {0893-6080},
author = {Jicong Fan and Zhaoyang Tian and Mingbo Zhao and Tommy W.S. Chow},
}

@ARTICLE{fantsp2021,
  author={Fan, Jicong and Yang, Chengrun and Udell, Madeleine},
  journal={IEEE Transactions on Signal Processing}, 
  title={Robust Non-Linear Matrix Factorization for Dictionary Learning, Denoising, and Clustering}, 
  year={2021},
  volume={69},
  number={},
  pages={1755-1770},
  doi={10.1109/TSP.2021.3062988}
}

@InProceedings{caicvpr2022, 
author = {Cai, Jinyu and Fan, Jicong and Guo, Wenzhong and Wang, Shiping and Zhang, Yunhe and Zhang, Zhao}, 
title = {Efficient Deep Embedded Subspace Clustering}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
month = {June}, 
year = {2022}, 
pages = {1-10} 
}

@inproceedings{fankdd2021,
author = {Fan, Jicong},
title = {Large-Scale Subspace Clustering via k-Factorization},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3447548.3467267},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {342–352},
numpages = {11},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{kang2020large,
  title={Large-scale multi-view subspace clustering in linear time},
  author={Kang, Zhao and Zhou, Wangtao and Zhao, Zhitong and Shao, Junming and Han, Meng and Xu, Zenglin},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={4412--4419},
  year={2020}
}


@article{pan2021multi,
  title={Multi-view Contrastive Graph Clustering},
  author={Pan, Erlin and Kang, Zhao},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}  


@ARTICLE{lv2021pseudo, 
author={Lv, Juncheng and Kang, Zhao and Lu, Xiao and Xu, Zenglin}, 
journal={IEEE Transactions on Image Processing}, 
title={Pseudo-supervised Deep Subspace Clustering}, 
pages={5252-5263},
year={2021},
volume={30}
}

@article{kang2021structured,
  title={Structured graph learning for scalable subspace clustering: From single view to multiview},
  author={Kang, Zhao and Lin, Zhiping and Zhu, Xiaofeng and Xu, Wenbo},
  journal={IEEE Transactions on Cybernetics},
  year={2022},
  publisher={IEEE},
  pages={8976 - 8986}, 
  volume={52},
  number={9}
} 
 
@inproceedings{mahon2021selective,
  title={Selective Pseudo-Label Clustering},
  author={Mahon, Louis and Lukasiewicz, Thomas},
  booktitle={German Conference on Artificial Intelligence (K{\"u}nstliche Intelligenz)},
  pages={158--178},
  year={2021},
  organization={Springer}
}

@inproceedings{zhang2019neural,
  title={Neural collaborative subspace clustering},
  author={Zhang, Tong and Ji, Pan and Harandi, Mehrtash and Huang, Wenbing and Li, Hongdong},
  booktitle={International Conference on Machine Learning},
  pages={7384--7393},
  year={2019},
  organization={PMLR}
}

@inproceedings{zhang2019self,
  title={Self-supervised convolutional subspace clustering network},
  author={Zhang, Junjian and Li, Chun-Guang and You, Chong and Qi, Xianbiao and Zhang, Honggang and Guo, Jun and Lin, Zhouchen},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5473--5482},
  year={2019}
}


@inproceedings{huang2012affinity,
  title={Affinity aggregation for spectral clustering},
  author={Huang, Hsin-Chien and Chuang, Yung-Yu and Chen, Chu-Song},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={773--780},
  year={2012},
  organization={IEEE}
}

@article{regsc2006,
  title={Regularized spectral learning},
  author={Meila, Marian and Shortreed, Susan},
  journal = {Journal of machine learning research},
  year    = {2006},
  volume  = {1},
  number  = {1},
  pages   = {1--20},
}



@inproceedings{fan2020polynomial,
  title={Polynomial matrix completion for missing data imputation and transductive learning},
  author={Fan, Jicong and Zhang, Yuqian and Udell, Madeleine},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={3842--3849},
  year={2020}
}

@article{roweis2000nonlinear,
  title={Nonlinear dimensionality reduction by locally linear embedding},
  author={Roweis, Sam T and Saul, Lawrence K},
  journal={Science},
  volume={290},
  number={5500},
  pages={2323--2326},
  year={2000},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{klein2017fast,
  title={Fast bayesian optimization of machine learning hyperparameters on large datasets},
  author={Klein, Aaron and Falkner, Stefan and Bartels, Simon and Hennig, Philipp and Hutter, Frank},
  booktitle={Artificial Intelligence and Statistics},
  pages={528--536},
  year={2017},
  organization={PMLR}
}

@article{snoek2012practical,
  title={Practical bayesian optimization of machine learning algorithms},
  author={Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@book{matern2013spatial,
  title={Spatial variation},
  author={Mat{\'e}rn, Bertil},
  volume={36},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher K and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@article{jones1998efficient,
  title={Efficient global optimization of expensive black-box functions},
  author={Jones, Donald R and Schonlau, Matthias and Welch, William J},
  journal={Journal of Global optimization},
  volume={13},
  number={4},
  pages={455--492},
  year={1998},
  publisher={Springer}
}

@inproceedings{liu2010understanding,
  title={Understanding of internal clustering validation measures},
  author={Liu, Yanchi and Li, Zhongmou and Xiong, Hui and Gao, Xuedong and Wu, Junjie},
  booktitle={2010 IEEE international conference on data mining},
  pages={911--916},
  year={2010},
  organization={IEEE}
}

@INPROCEEDINGS{989517,
  author={Halkidi, M. and Vazirgiannis, M.},
  booktitle={Proceedings 2001 IEEE International Conference on Data Mining}, 
  title={Clustering validity assessment: finding the optimal partitioning of a data set}, 
  year={2001},
  volume={},
  number={},
  pages={187-194},
  doi={10.1109/ICDM.2001.989517}}
  
@inproceedings{ester1996density,
  title={A density-based algorithm for discovering clusters in large spatial databases with noise.},
  author={Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg and Xu, Xiaowei and others},
  booktitle={kdd},
  volume={96},
  number={34},
  pages={226--231},
  year={1996}
}

@mastersthesis{poulakis2020unsupervised,
  title={Unsupervised AutoML: a study on automated machine learning in the context of clustering},
  author={Poulakis, Giannis},
  year={2020},
  school={$\Pi$$\alpha$$\nu$$\varepsilon$$\pi$$\iota$$\sigma$$\tau$$\acute{\eta}$$\mu$$\iota$o $\Pi$$\varepsilon$$\iota$$\rho$$\alpha$$\iota$$\acute{\omega}$$\varsigma$}
}

@book{hutter2019automated,
  title={Automated machine learning: methods, systems, challenges},
  author={Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  year={2019},
  publisher={Springer Nature}
}

@article{soltanolkotabi2014robust,
  title={Robust subspace clustering},
  author={Soltanolkotabi, Mahdi and Elhamifar, Ehsan and Candes, Emmanuel J},
  journal={The Annals of Statistics},
  volume={42},
  number={2},
  pages={669--699},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{wang2013noisy,
  title={Noisy sparse subspace clustering},
  author={Wang, Yu-Xiang and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={89--97},
  year={2013},
  organization={PMLR}
}

@article{tipping1999mixtures,
  title={Mixtures of probabilistic principal component analyzers},
  author={Tipping, Michael E and Bishop, Christopher M},
  journal={Neural computation},
  volume={11},
  number={2},
  pages={443--482},
  year={1999},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{steinhaus1956division,
  title={Sur la division des corps mat{\'e}riels en parties},
  author={Steinhaus, Hugo and others},
  journal={Bull. Acad. Polon. Sci},
  volume={1},
  number={804},
  pages={801},
  year={1956}
}

@Inbook{Bock2007,
author="Bock, Hans-Hermann",
editor="Brito, Paula
and Cucumel, Guy
and Bertrand, Patrice
and de Carvalho, Francisco",
title="Clustering Methods: A History of k-Means Algorithms",
bookTitle="Selected Contributions in Data Analysis and Classification",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="161--172",
abstract="This paper surveys some historical issues related to the well-known k-means algorithm in cluster analysis. It shows to which authors the different versions of this algorithm can be traced back, and which were the underlying applications. We sketch various generalizations (with references also to Diday's work) and thereby underline the usefulness of the k-means approach in data analysis.",
isbn="978-3-540-73560-1",
doi="10.1007/978-3-540-73560-1_15",
url="https://doi.org/10.1007/978-3-540-73560-1_15"
}

@article{johnson1967hierarchical,
  title={Hierarchical clustering schemes},
  author={Johnson, Stephen C},
  journal={Psychometrika},
  volume={32},
  number={3},
  pages={241--254},
  year={1967},
  publisher={Springer}
}

@inproceedings{ng2002spectral,
  title={On spectral clustering: Analysis and an algorithm},
  author={Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
  booktitle={Advances in neural information processing systems},
  pages={849--856},
  year={2002}
}

@article{shi2000normalized,
  title={Normalized cuts and image segmentation},
  author={Shi, Jianbo and Malik, Jitendra},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={22},
  number={8},
  pages={888--905},
  year={2000},
  publisher={Ieee}
}

@INPROCEEDINGS{790354,
  author={Weiss, Y.},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={Segmentation using eigenvectors: a unifying view}, 
  year={1999},
  volume={2},
  number={},
  pages={975-982 vol.2},
  doi={10.1109/ICCV.1999.790354}}
  
@article{{kang2020partition, 
author={Kang, Zhao and Zhao, Xinjia and Shi and Peng, chong and Zhu, Hongyuan and Zhou, Joey Tianyi and Peng, Xi and Chen, Wenyu and Xu, Zenglin}, 
journal={Neural Networks}, 
title={Partition Level Multiview Subspace Clustering}, 
year={2020},
 volume={122},
pages={279--288},
 }
 
 
@article{henderson1981deriving,
  title={On deriving the inverse of a sum of matrices},
  author={Henderson, Harold V and Searle, Shayle R},
  journal={Siam Review},
  volume={23},
  number={1},
  pages={53--60},
  year={1981},
  publisher={SIAM}
}

@article{stallkamp2012man,
  title={Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  journal={Neural networks},
  volume={32},
  pages={323--332},
  year={2012},
  publisher={Elsevier}
}

@InProceedings{Ji_2015_ICCV,
author = {Ji, Pan and Salzmann, Mathieu and Li, Hongdong},
title = {Shape Interaction Matrix Revisited and Robustified: Efficient Subspace Clustering With Corrupted and Incomplete Data},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@INPROCEEDINGS{6836065,
  author={ {Pan Ji} and M. {Salzmann} and  {Hongdong Li}},
  booktitle={IEEE Winter Conference on Applications of Computer Vision}, 
  title={Efficient dense subspace clustering}, 
  year={2014},
  volume={},
  number={},
  pages={461-468},
  doi={10.1109/WACV.2014.6836065}}
  
@Article{adam2014,
  author  = {Kingma, Diederik P and Ba, Jimmy},
  title   = {Adam: A method for stochastic optimization},
  journal = {arXiv preprint arXiv:1412.6980},
  year    = {2014},
}



@article{fiedler1973algebraic,
  title={Algebraic connectivity of graphs},
  author={Fiedler, Miroslav},
  journal={Czechoslovak mathematical journal},
  volume={23},
  number={2},
  pages={298--305},
  year={1973},
  publisher={Institute of Mathematics, Academy of Sciences of the Czech Republic}
}

@InProceedings{Kheirandishfard_2020_CVPR_Workshops,
author = {Kheirandishfard, Mohsen and Zohrizadeh, Fariba and Kamangar, Farhad},
title = {Deep Low-Rank Subspace Clustering},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}
@inproceedings{seo2019deep,
  title={Deep Closed-Form Subspace Clustering},
  author={Seo, Junghoon and Koo, Jamyoung and Jeon, Taegyun},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}
@inproceedings{zhang2019self,
  title={Self-supervised convolutional subspace clustering network},
  author={Zhang, Junjian and Li, Chun-Guang and You, Chong and Qi, Xianbiao and Zhang, Honggang and Guo, Jun and Lin, Zhouchen},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5473--5482},
  year={2019}
}

@article{meila2001multicut,
  title={The multicut lemma},
  author={Meila, Marina},
  journal={UW Statistics Technical Report},
  volume={417},
  year={2001}
}


@InProceedings{ORL_face,
  author    = {F. S. Samaria and A. C. Harter},
  title     = {Parameterisation of a stochastic model for human face identification},
  booktitle = {Proceedings of 1994 IEEE Workshop on Applications of Computer Vision},
  year      = {1994},
  pages     = {138-142},
  month     = {Dec},
}

@article{SONODA2017233,
title = "Neural network with unbounded activation functions is universal approximator",
journal = "Applied and Computational Harmonic Analysis",
volume = "43",
number = "2",
pages = "233 - 268",
year = "2017",
issn = "1063-5203",
doi = "https://doi.org/10.1016/j.acha.2015.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S1063520315001748",
author = "Sho Sonoda and Noboru Murata",
}

@TechReport{Dataset_COIL20,
  author      = {Nene, S. A. and Nayar, S. K. and Murase, H.},
  title       = {Columbia object image library (COIL-20)},
  institution = {Columbia University},
  year        = {1996},
  type        = {Report},
}

@Article{Dataset_ExtendYaleB,
  author  = {Kuang-Chih, Lee and Ho, J. and Kriegman, D. J.},
  title   = {Acquiring linear subspaces for face recognition under variable lighting},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2005},
  volume  = {27},
  number  = {5},
  pages   = {684-698},
  doi     = {10.1109/TPAMI.2005.92},
  issn    = {0162-8828},
  type    = {Journal Article},
}

@inproceedings{regsc2005,
  title={Regularized spectral learning},
  author={Meila, Marian and Shortreed, Susan and Xu, Liang},
  booktitle={AISTATS},
  year={2005},
  organization={PMLR}
}

@article{hu2017finding,
  title={Finding multiple stable clusterings},
  author={Hu, Juhua and Qian, Qi and Pei, Jian and Jin, Rong and Zhu, Shenghuo},
  journal={Knowledge and Information Systems},
  volume={51},
  number={3},
  pages={991--1021},
  year={2017},
  publisher={Springer}
}

@inproceedings{you2016scalable,
  title={Scalable sparse subspace clustering by orthogonal matching pursuit},
  author={You, Chong and Robinson, Daniel and Vidal, Ren{\'e}},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3918--3927},
  year={2016}
}

@misc{Dua:2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }


@article{andrzejak2001indications,
  title={Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state},
  author={Andrzejak, Ralph G and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian E},
  journal={Physical Review E},
  volume={64},
  number={6},
  pages={061907},
  year={2001},
  publisher={APS}
}

@article{bruna2013invariant,
  title={Invariant scattering convolution networks},
  author={Bruna, Joan and Mallat, St{\'e}phane},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1872--1886},
  year={2013},
  publisher={IEEE}
}

@online{xiao2017fmnist,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}

 @article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@inproceedings{zhang2019neural,
  title={Neural Collaborative Subspace Clustering},
  author={Zhang, Tong and Ji, Pan and Harandi, Mehrtash and Huang, Wenbing and Li, Hongdong},
  booktitle={International Conference on Machine Learning},
  pages={7384--7393},
  year={2019}
}

@article{fowlkes2004spectral,
  title={Spectral grouping using the Nystrom method},
  author={Fowlkes, Charless and Belongie, Serge and Chung, Fan and Malik, Jitendra},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={26},
  number={2},
  pages={214--225},
  year={2004},
  publisher={IEEE}
}

@book{beck2017first,
  title={First-order methods in optimization},
  author={Beck, Amir},
  year={2017},
  publisher={SIAM}
}

@article{olshausen1996emergence,
  title={Emergence of simple-cell receptive field properties by learning a sparse code for natural images},
  author={Olshausen, Bruno A and Field, David J},
  journal={Nature},
  volume={381},
  number={6583},
  pages={607--609},
  year={1996},
  publisher={Nature Publishing Group}
}


@article{xu2013block,
  title={A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion},
  author={Xu, Yangyang and Yin, Wotao},
  journal={SIAM Journal on imaging sciences},
  volume={6},
  number={3},
  pages={1758--1789},
  year={2013},
  publisher={SIAM}
}

@inproceedings{fan2019factor,
  title={Factor group-sparse regularization for efficient low-rank matrix recovery},
  author={Fan, Jicong and Ding, Lijun and Chen, Yudong and Udell, Madeleine},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5104--5114},
  year={2019}
}

@inproceedings{nie2010efficient,
  title={Efficient and robust feature selection via joint $\ell_{2,1}$-norms minimization},
  author={Nie, Feiping and Huang, Heng and Cai, Xiao and Ding, Chris H},
  booktitle={Advances in neural information processing systems},
  pages={1813--1821},
  year={2010}
}

@inproceedings{ding2006r,
  title={R1-PCA: rotational invariant L1-norm principal component analysis for robust subspace factorization},
  author={Ding, Chris and Zhou, Ding and He, Xiaofeng and Zha, Hongyuan},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={281--288},
  year={2006}
}

@inproceedings{sprechmann2010dictionary,
  title={Dictionary learning and sparse coding for unsupervised clustering},
  author={Sprechmann, Pablo and Sapiro, Guillermo},
  booktitle={2010 IEEE international conference on acoustics, speech and signal processing},
  pages={2042--2045},
  year={2010},
  organization={IEEE}
}

@article{song2019subspace,
  title={Subspace clustering via structure-enforced dictionary learning},
  author={Song, Jinjoo and Yoon, Gangjoon and Hahn, Kwangsoo and Yoon, Sang Min},
  journal={Neurocomputing},
  volume={362},
  pages={1--10},
  year={2019},
  publisher={Elsevier}
}

@article{aharon2006k,
  title={K-{SVD}: An algorithm for designing overcomplete dictionaries for sparse representation},
  author={Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
  journal={IEEE Transactions on signal processing},
  volume={54},
  number={11},
  pages={4311--4322},
  year={2006},
  publisher={IEEE}
}

@inproceedings{ji2017deep,
  title={Deep subspace clustering networks},
  author={Ji, Pan and Zhang, Tong and Li, Hongdong and Salzmann, Mathieu and Reid, Ian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={24--33},
  year={2017}
}

@inproceedings{dhillon2004kernel,
  title={Kernel k-means: spectral clustering and normalized cuts},
  author={Dhillon, Inderjit S and Guan, Yuqiang and Kulis, Brian},
  booktitle={Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={551--556},
  year={2004}
}

@inproceedings{lee2001algorithms,
  title={Algorithms for non-negative matrix factorization},
  author={Lee, Daniel D and Seung, H Sebastian},
  booktitle={Advances in neural information processing systems},
  pages={556--562},
  year={2001}
}

@article{lin2007projected,
  title={Projected gradient methods for nonnegative matrix factorization},
  author={Lin, Chih-Jen},
  journal={Neural computation},
  volume={19},
  number={10},
  pages={2756--2779},
  year={2007},
  publisher={MIT Press}
}

@article{wang2012nonnegative,
  title={Nonnegative matrix factorization: A comprehensive review},
  author={Wang, Yu-Xiong and Zhang, Yu-Jin},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={25},
  number={6},
  pages={1336--1353},
  year={2012},
  publisher={IEEE}
}

@inproceedings{ding2005equivalence,
  title={On the equivalence of nonnegative matrix factorization and spectral clustering},
  author={Ding, Chris and He, Xiaofeng and Simon, Horst D},
  booktitle={Proceedings of the 2005 SIAM international conference on data mining},
  pages={606--610},
  year={2005},
  organization={SIAM}
}

@article{turkmen2015review,
  title={A review of nonnegative matrix factorization methods for clustering},
  author={T{\"u}rkmen, Ali Caner},
  journal={arXiv preprint arXiv:1507.03194},
  year={2015}
}

@article{von2007tutorial,
  title={A tutorial on spectral clustering},
  author={Von Luxburg, Ulrike},
  journal={Statistics and computing},
  volume={17},
  number={4},
  pages={395--416},
  year={2007},
  publisher={Springer}
}

@inproceedings{he2016robust,
  title={Robust k-subspaces recovery with combinatorial initialization},
  author={He, Jun and Zhang, Yue and Wang, Jiye and Zeng, Nan and Hao, Hanyong},
  booktitle={2016 IEEE International Conference on Big Data (Big Data)},
  pages={3573--3582},
  year={2016},
  organization={IEEE}
}

@article{gitlin2018improving,
  title={Improving $ K $-Subspaces via Coherence Pursuit},
  author={Gitlin, Andrew and Tao, Biaoshuai and Balzano, Laura and Lipor, John},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={12},
  number={6},
  pages={1575--1588},
  year={2018},
  publisher={IEEE}
}

@inproceedings{agarwal2004k,
  title={K-means projective clustering},
  author={Agarwal, Pankaj K and Mustafa, Nabil H},
  booktitle={Proceedings of the twenty-third ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
  pages={155--165},
  year={2004}
}

@article{bradley2000k,
  title={K-plane clustering},
  author={Bradley, Paul S and Mangasarian, Olvi L},
  journal={Journal of Global Optimization},
  volume={16},
  number={1},
  pages={23--32},
  year={2000},
  publisher={Springer}
}

@inproceedings{you2018scalable,
  title={Scalable exemplar-based subspace clustering on class-imbalanced data},
  author={You, Chong and Li, Chi and Robinson, Daniel P and Vidal, Ren{\'e}},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={67--83},
  year={2018}
}

@inproceedings{you2016scalable,
  title={Scalable sparse subspace clustering by orthogonal matching pursuit},
  author={You, Chong and Robinson, Daniel and Vidal, Ren{\'e}},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3918--3927},
  year={2016}
}

@article{dyer2013greedy,
  title={Greedy feature selection for subspace clustering},
  author={Dyer, Eva L and Sankaranarayanan, Aswin C and Baraniuk, Richard G},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={2487--2517},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{chen2020stochastic,
  title={Stochastic Sparse Subspace Clustering},
  author={Chen, Ying and Li, Chun-Guang and You, Chong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4155--4164},
  year={2020}
}

@ARTICLE{li2020learnable,
  author={Li, Jun and Liu, Hongfu and Tao, Zhiqiang and Zhao, Handong and Fu, Yun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Learnable Subspace Clustering}, 
  year={2020},
  volume={},
  number={},
  pages={1-15},
  doi={10.1109/TNNLS.2020.3040379}}

@article{lu2018subspace,
  title={Subspace clustering by block diagonal representation},
  author={Lu, Canyi and Feng, Jiashi and Lin, Zhouchen and Mei, Tao and Yan, Shuicheng},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={487--501},
  year={2018},
  publisher={IEEE}
}

@inproceedings{matsushima2019selective,
  title={Selective sampling-based scalable sparse subspace clustering},
  author={Matsushima, Shin and Brbic, Maria},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12416--12425},
  year={2019}
}

@article{cai2014large,
  title={Large scale spectral clustering via landmark-based sparse representation},
  author={Cai, Deng and Chen, Xinlei},
  journal={IEEE transactions on cybernetics},
  volume={45},
  number={8},
  pages={1669--1680},
  year={2014},
  publisher={IEEE}
}

@inproceedings{li2017large,
  title={Large-scale subspace clustering by fast regression coding},
  author={Li, Jun and Zhao, Handong},
  booktitle={IJCAI},
  year={2017}
}

@inproceedings{you2016oracle,
  title={Oracle based active set algorithm for scalable elastic net subspace clustering},
  author={You, Chong and Li, Chun-Guang and Robinson, Daniel P and Vidal, Ren{\'e}},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3928--3937},
  year={2016}
}

@inproceedings{li2015structured,
  title={Structured sparse subspace clustering: A unified optimization framework},
  author={Li, Chun-Guang and Vidal, Rene},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={277--286},
  year={2015}
}

@article{peng2015unified,
  title={A unified framework for representation-based subspace clustering of out-of-sample and large-scale data},
  author={Peng, Xi and Tang, Huajin and Zhang, Lei and Yi, Zhang and Xiao, Shijie},
  journal={IEEE transactions on neural networks and learning systems},
  volume={27},
  number={12},
  pages={2499--2512},
  year={2015},
  publisher={IEEE}
}

@inproceedings{wang2014exact,
  title={Exact subspace clustering in linear time},
  author={Wang, Shusen and Tu, Bojun and Xu, Congfu and Zhang, Zhihua},
  booktitle={Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence},
  pages={2113--2120},
  year={2014}
}

@inproceedings{peng2013scalable,
  title={Scalable sparse subspace clustering},
  author={Peng, Xi and Zhang, Lei and Yi, Zhang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={430--437},
  year={2013}
}

@article{chen2010parallel, 
  title={Parallel spectral clustering in distributed systems},
  author={Chen, Wen-Yen and Song, Yangqiu and Bai, Hongjie and Lin, Chih-Jen and Chang, Edward Y},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={33},
  number={3},
  pages={568--586},
  year={2010},
  publisher={IEEE}
}

@inproceedings{chen2011large,
  title={Large scale spectral clustering with landmark-based representation},
  author={Chen, Xinlei and Cai, Deng},
  booktitle={Twenty-fifth AAAI conference on artificial intelligence},
  year={2011},
  organization={Citeseer}
}

@inproceedings{LSRSCLu2012,
  title={Robust and efficient subspace segmentation via least squares regression},
  author={Lu, Can-Yi and Min, Hai and Zhao, Zhong-Qiu and Zhu, Lin and Huang, De-Shuang and Yan, Shuicheng},
  booktitle={European conference on computer vision},
  pages={347--360},
  year={2012},
  organization={Springer}
}

@article{parikh2014proximal,
  title={Proximal algorithms},
  author={Parikh, Neal and Boyd, Stephen and others},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={1},
  number={3},
  pages={127--239},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{bolte2014proximal,
  title={Proximal alternating linearized minimization for nonconvex and nonsmooth problems},
  author={Bolte, J{\'e}r{\^o}me and Sabach, Shoham and Teboulle, Marc},
  journal={Mathematical Programming},
  volume={146},
  number={1-2},
  pages={459--494},
  year={2014},
  publisher={Springer}
}

@InProceedings{pmlr-v51-shen16,
  title = 	 {Learning Structured Low-Rank Representation via Matrix Factorization},
  author = 	 {Jie Shen and Ping Li},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {500--509},
  year = 	 {2016},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher = 	 {PMLR},
}

@incollection{NIPS2013_4865,
title = {Provable Subspace Clustering: When LRR meets SSC},
author = {Wang, Yu-Xiang and Xu, Huan and Leng, Chenlei},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {64--72},
year = {2013},
publisher = {Curran Associates, Inc.},
}

@article{lipor2017subspace,
  title={Subspace Clustering using Ensembles of $ K $-Subspaces},
  author={Lipor, John and Hong, David and Tan, Yan Shuo and Balzano, Laura},
  journal={arXiv preprint arXiv:1709.04744},
  year={2017}
}

@ARTICLE{8573150,
author={M. {Brbić} and I. {Kopriva}},
journal={IEEE Transactions on Cybernetics},
title={ $\ell_0$ -Motivated Low-Rank Sparse Subspace Clustering},
year={2020},
volume={50},
number={4},
pages={1711-1725},
ISSN={2168-2275},
month={April},}

@INPROCEEDINGS{KSSC,
author={V. M. {Patel} and R. {Vidal}},
booktitle={2014 IEEE International Conference on Image Processing (ICIP)},
title={Kernel sparse subspace clustering},
year={2014},
volume={},
number={},
pages={2849-2853},
doi={10.1109/ICIP.2014.7025576},
ISSN={2381-8549},
month={Oct},}

@Article{FastISTA,
  author   = {Beck, Amir and Teboulle, Marc},
  title    = {A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems},
  journal  = {SIAM Journal on Imaging Sciences},
  year     = {2009},
  volume   = {2},
  number   = {1},
  pages    = {183-202},
  doi      = {doi:10.1137/080716542},
  keywords = {90C25,90C06,65F22},
  type     = {Journal Article},
}

@Article{RPCA,
  author  = {Cand\`{e}s, Emmanuel J. and Li, Xiaodong and Ma, Yi and Wright, John},
  title   = {Robust principal component analysis?},
  journal = {J. ACM},
  year    = {2011},
  volume  = {58},
  number  = {3},
  pages   = {1-37},
  issn    = {0004-5411},
  doi     = {10.1145/1970392.1970395},
  type    = {Journal Article},
}

@Article{,
  author   = {Fang, X. and Xu, Y. and Li, X. and Lai, Z. and Wong, W. K.},
  title    = {Robust Semi-Supervised Subspace Clustering via Non-Negative Low-Rank Representation},
  journal  = {Cybernetics, IEEE Transactions on},
  year     = {2015},
  volume   = {PP},
  number   = {99},
  pages    = {1-1},
  doi      = {10.1109/TCYB.2015.2454521},
  issn     = {2168-2267},
  keywords = {Clustering algorithms Clustering methods Matrix converters Optimization Principal component analysis Robustness Sparse matrices Affinity matrix low-rank representation (LRR) subspace clustering supervision information},
  type     = {Journal Article},
}

@InProceedings{,
  author    = {Karasuyama, Masayuki and Mamitsuka, Hiroshi},
  title     = {Manifold-based Similarity Adaptation for Label Propagation},
  booktitle = {Advances in Neural Information Processing Systems 26 (NIPS 2013)},
  type      = {Conference Proceedings},
}

@Article{LRR_PAMI_2013,
  author   = {Liu, G. and Lin, Z. and Yan, S. and Sun, J. and Yu, Y. and Ma, Y.},
  title    = {Robust Recovery of Subspace Structures by Low-Rank Representation},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2013},
  volume   = {35},
  number   = {1},
  pages    = {171-184},
  doi      = {10.1109/TPAMI.2012.88},
  issn     = {0162-8828},
  keywords = {convex programming pattern clustering sparse matrices LRR convex program data sample vectors dictionary low-rank representation objective function outlier removal robust subspace structure recovery row space sparse error correction subspace clustering problem subspace membership Data models Dictionaries Noise Optimization Polynomials Robustness Vectors outlier detection segmentation subspace clustering Algorithms Artificial Intelligence Computer Simulation Models, Theoretical Pattern Recognition, Automated Signal Processing, Computer-Assisted},
  type     = {Journal Article},
}

@InProceedings{LatentLRR,
  author    = {Liu, G. and Yan, S.},
  title     = {Latent Low-Rank Representation for subspace segmentation and feature extraction},
  booktitle = {2011 International Conference on Computer Vision},
  pages     = {1615-1622},
  doi       = {10.1109/ICCV.2011.6126422},
  isbn      = {1550-5499},
  keywords  = {convex programming data encapsulation data structures feature extraction image segmentation matrix algebra minimisation vectors LatLRR convex problem corrupted data data vectors dictionary dimension reduction based methods hidden data latent low-rank representation multiple subspace data structures nuclear norm minimization problem observed data matrix salient features state-of-the-art algorithms subspace segmentation algorithm unsupervised feature extraction algorithm Dictionaries Motion segmentation Noise Robustness Strontium},
  type      = {Conference Proceedings},
}

@Article{sc2004,
  author  = {Parsons, Lance and Haque, Ehtesham and Liu, Huan},
  title   = {Subspace clustering for high dimensional data: a review},
  journal = {SIGKDD Explor. Newsl.},
  year    = {2004},
  volume  = {6},
  number  = {1},
  pages   = {90-105},
  doi     = {10.1145/1007730.1007731},
  issn    = {1931-0145},
  type    = {Journal Article},
}

@Article{LSSLRSC,
  author   = {Patel, V. M. and Hien Van, Nguyen and Vidal, R.},
  title    = {Latent Space Sparse and Low-Rank Subspace Clustering},
  journal  = {Selected Topics in Signal Processing, IEEE Journal of},
  year     = {2015},
  volume   = {9},
  number   = {4},
  pages    = {691-701},
  issn     = {1932-4553},
  doi      = {10.1109/JSTSP.2015.2402643},
  keywords = {data reduction matrix algebra optimisation pattern clustering cluster labels data clustering data projection dimensionality reduction kernel methods latent space sparse low-dimensional latent space low-rank coefficients low-rank subspace clustering optimization methods similarity matrix spectral clustering Clustering algorithms Clustering methods Cost function Kernel Signal processing algorithms Sparse matrices Dimension reduction manifold clustering sparse subspace clustering subspace clustering},
  type     = {Journal Article},
}

@Article{,
  author   = {Peng, Yong and Lu, Bao-Liang and Wang, Suhang},
  title    = {Enhanced low-rank representation via sparse manifold adaption for semi-supervised learning},
  journal  = {Neural Networks},
  year     = {2015},
  volume   = {65},
  pages    = {1-17},
  abstract = {Constructing an informative and discriminative graph plays an important role in various pattern recognition tasks such as clustering and classification. Among the existing graph-based learning models, low-rank representation (LRR) is a very competitive one, which has been extensively employed in spectral clustering and semi-supervised learning (SSL). In SSL, the graph is composed of both labeled and unlabeled samples, where the edge weights are calculated based on the LRR coefficients. However, most of existing LRR related approaches fail to consider the geometrical structure of data, which has been shown beneficial for discriminative tasks. In this paper, we propose an enhanced LRR via sparse manifold adaption, termed manifold low-rank representation (MLRR), to learn low-rank data representation. MLRR can explicitly take the data local manifold structure into consideration, which can be identified by the geometric sparsity idea; specifically, the local tangent space of each data point was sought by solving a sparse representation objective. Therefore, the graph to depict the relationship of data points can be built once the manifold information is obtained. We incorporate a regularizer into LRR to make the learned coefficients preserve the geometric constraints revealed in the data space. As a result, MLRR combines both the global information emphasized by low-rank property and the local information emphasized by the identified manifold structure. Extensive experimental results on semi-supervised classification tasks demonstrate that MLRR is an excellent method in comparison with several state-of-the-art graph construction approaches.},
  doi      = {http://dx.doi.org/10.1016/j.neunet.2015.01.001},
  issn     = {0893-6080},
  keywords = {Low-rank representation Sparse manifold adaption Graph construction Semi-supervised learning Face recognition},
  type     = {Journal Article},
  url      = {http://www.sciencedirect.com/science/article/pii/S0893608015000027},
}

@article{Zhang2012,
   author = {Zhang, Teng and Szlam, Arthur and Wang, Yi and Lerman, Gilad},
   title = {Hybrid Linear Modeling via Local Best-Fit Flats},
   journal = {International Journal of Computer Vision},
   volume = {100},
   number = {3},
   pages = {217-240},
   abstract = {We present a simple and fast geometric method for modeling data by a union of affine subspaces. The method begins by forming a collection of local best-fit affine subspaces, i.e., subspaces approximating the data in local neighborhoods. The correct sizes of the local neighborhoods are determined automatically by the Jones’ β 2 numbers (we prove under certain geometric conditions that our method finds the optimal local neighborhoods). The collection of subspaces is further processed by a greedy selection procedure or a spectral method to generate the final model. We discuss applications to tracking-based motion segmentation and clustering of faces under different illuminating conditions. We give extensive experimental evidence demonstrating the state of the art accuracy and speed of the suggested algorithms on these problems and also on synthetic hybrid linear data as well as the MNIST handwritten digits data; and we demonstrate how to use our algorithms for fast determination of the number of affine subspaces.},
   ISSN = {1573-1405},
   DOI = {10.1007/s11263-012-0535-6},
   url = {http://dx.doi.org/10.1007/s11263-012-0535-6},
   year = {2012},
   type = {Journal Article}
}

@Article{,
  author   = {Zhao, Miaoyun and Jiao, Licheng and Ma, Wenping and Liu, Hongying and Yang, Shuyuan},
  title    = {Classification and saliency detection by semi-supervised low-rank representation},
  journal  = {Pattern Recognition},
  year     = {2016},
  volume   = {51},
  pages    = {281-294},
  abstract = {In the area of pattern recognition, Low Rank Representation (LRR) is an efficient method in recovering the subspace structure of the dataset. However, LRR is unsupervised. Without any label information, LRR constructs an informative graph which is then combined with the mature graph-based semi-supervised learning (GSSL) framework to complete the classification task. In this paper, we propose a new low rank learning method which constructs the low rank representation matrix utilizing label information to obtain a more informative graph. This method integrates the low rank graph construction and the label information propagation processes together. Thus the optimization of the low rank representation and the soft label prediction function are calculated iteratively at the same time. We name this method as Semi-Supervised Low Rank Learning (SSLRL). It enhanced the classification performance of traditional LRR-Graph based SSL by 5–30% and the running time is reduced from hundreds to less than ten seconds. Based on this method, a new outlier detection strategy is presented. This strategy succeeds with an AUC of at least 93% even if the detection condition of LRR is not satisfied. The effectiveness of SSLRL is demonstrated in semi-supervised classification, outlier detection, and salient detection tasks. These extensive experimental results highlight the outperforming of our method over state-of-the-art methods.},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2015.09.008},
  issn     = {0031-3203},
  keywords = {Low rank representation Semi-supervised learning Outlier detection Saliency detection},
  type     = {Journal Article},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320315003398},
}

@InProceedings{,
  author    = {Zhuang, L. and Gao, H. and Lin, Z. and Ma, Y. and Zhang, X. and Yu, N.},
  title     = {Non-negative low rank and sparse graph for semi-supervised learning},
  booktitle = {Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
  pages     = {2328-2335},
  doi       = {10.1109/CVPR.2012.6247944},
  isbn      = {1063-6919},
  keywords  = {data structures graph theory learning (artificial intelligence) matrix algebra pattern classification pattern clustering NNLRS-graph clustering task data structure representation discriminative analysis locally linear structure machine learning tasks nonnegative low rank-and-sparse graph nonnegative low-rank-and-sparse matrix semisupervised classification semisupervised learning subspaces structure Databases Educational institutions Noise Optimization Sparse matrices Strontium Vectors},
  type      = {Conference Proceedings},
}

@InProceedings{MC_Universal2014,
  author    = {Bhojanapalli, Srinadh and Jain, Prateek},
  title     = {Universal Matrix Completion},
  booktitle = {Proceedings of The 31st International Conference on Machine Learning},
  year      = {2014},
  pages     = {1881-1889},
  publisher = {JMLR},
  type      = {Conference Proceedings},
}

@Article{CaiCandesShen2010,
  author   = {Cai, Jian-Feng and Cand\`{e}s, Emmanuel J. and Shen, Zuowei},
  title    = {A Singular Value Thresholding Algorithm for Matrix Completion},
  journal  = {SIAM Journal on Optimization},
  year     = {2010},
  volume   = {20},
  number   = {4},
  pages    = {1956-1982},
  doi      = {doi:10.1137/080738970},
  keywords = {90C25,15A83,65K05},
  type     = {Journal Article},
}

@Article{CandesPlan2010,
  author   = {Cand\`{e}s, E. J. and Plan, Y.},
  title    = {Matrix Completion With Noise},
  journal  = {Proceedings of the IEEE},
  year     = {2010},
  volume   = {98},
  number   = {6},
  pages    = {925-936},
  issn     = {0018-9219},
  doi      = {10.1109/JPROC.2009.2035722},
  keywords = {data integrity matrix algebra minimisation noise signal sampling compressed sensing convex optimization problem data constraints low rank matrices matrix completion nuclear norm minimization Collaboration Computer vision Filtering Frequency Linear matrix inequalities Machine learning Motion pictures Noise level Remote sensing duality in optimization low-rank matrices nuclear-norm minimization oracle inequalities semidefinite programming},
  type     = {Journal Article},
}

@Article{CandesRecht2009,
  author   = {Cand\`{e}s, Emmanuel J. and Recht, Benjamin},
  title    = {Exact Matrix Completion via Convex Optimization},
  journal  = {Foundations of Computational Mathematics},
  year     = {2009},
  volume   = {9},
  number   = {6},
  pages    = {717-772},
  issn     = {1615-3383},
  doi      = {10.1007/s10208-009-9045-5},
  type     = {Journal Article},
}

@Misc{Netflix2006,
  author = {Netflix},
  title  = {Netflx Prize},
  year   = {2006},
  type   = {Web Page},
}

@Unpublished{ZhangYangJinEtAl2015,
  author  = {Zhang, Lijun and Yang, Tianbao and Jin, Rong and Zhou, Zhi-Hua},
  title   = {Analysis of Nuclear Norm Regularization for Full-rank Matrix Completion},
  year    = {2015},
  address = {arXiv:1504.06817v1 [cs.LG]},
  type    = {Unpublished Work},
}

@InProceedings{,
  author    = {Patel, V. M. and Vidal, R.},
  title     = {Kernel sparse subspace clustering},
  booktitle = {2014 IEEE International Conference on Image Processing (ICIP)},
  pages     = {2849-2853},
  doi       = {10.1109/ICIP.2014.7025576},
  isbn      = {1522-4880},
  keywords  = {computer vision data handling pattern clustering Kernel sparse subspace clustering data points data representation image processing kernel sparse representations kernel trick nonlinear manifolds nonlinear mappings Clustering algorithms Conferences Kernel Manifolds Pattern recognition Signal processing algorithms Subspace clustering kernel methods non-linear subspace clustering sparse subspace clustering},
  type      = {Conference Proceedings},
}

@InProceedings{,
  author    = {Goh, A. and Vidal, R.},
  title     = {Segmenting Motions of Different Types by Unsupervised Manifold Clustering},
  booktitle = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
  pages     = {1-6},
  doi       = {10.1109/CVPR.2007.383235},
  isbn      = {1063-6919},
  keywords  = {image motion analysis image segmentation image sequences motion sequences multiple affine multiple motions segmentation nonlinear dimensionality reduction perspective views unsupervised manifold clustering Algorithm design and analysis Analysis of variance Clustering algorithms Computer vision Data analysis Functional analysis Motion segmentation Null space Testing Vectors},
  type      = {Conference Proceedings},
}

@Article{RKLRR,
  author   = {Xiao, S. and Tan, M. and Xu, D. and Dong, Z. Y.},
  title    = {Robust Kernel Low-Rank Representation},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  year     = {2015},
  volume   = {PP},
  number   = {99},
  pages    = {1-1},
  doi      = {10.1109/TNNLS.2015.2472284},
  issn     = {2162-237X},
  keywords = {Closed-form solutions Convergence Face Kernel Linear programming Optimization Robustness Low-rank representation (LRR) kernel methods.},
  type     = {Journal Article},
}

@Article{SSC_PAMIN_2013,
  author   = {Elhamifar, E. and Vidal, R.},
  title    = {Sparse Subspace Clustering: Algorithm, Theory, and Applications},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2013},
  volume   = {35},
  number   = {11},
  pages    = {2765-2781},
  doi      = {10.1109/TPAMI.2013.57},
  issn     = {0162-8828},
  keywords = {computational complexity convex programming data structures minimisation pattern clustering convex relaxation data point clustering data point representation face clustering general NP-hard problem high-dimensional data collection minimization program motion segmentation sparse optimization program sparse representation sparse subspace clustering algorithm spectral clustering framework synthetic data Clustering algorithms Computer vision Face Noise Optimization Sparse matrices Vectors $(ell_1)$-minimization High-dimensional data clustering intrinsic low-dimensionality principal angles spectral clustering subspaces Algorithms Artificial Intelligence Biometry Humans Image Interpretation, Computer-Assisted Pattern Recognition, Automated Sample Size},
  type     = {Journal Article},
}

@Article{SC_tutorial2011,
  author   = {Vidal, R.},
  title    = {Subspace Clustering},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2011},
  volume   = {28},
  number   = {2},
  pages    = {52-68},
  doi      = {10.1109/MSP.2010.939739},
  issn     = {1053-5888},
  keywords = {computer vision face recognition image motion analysis image segmentation pattern clustering affine subspace face clustering problem high-dimensional data set clustering linear subspace motion segmentation subspace clustering Clustering algorithms Data models Noise Polynomials Principal component analysis Signal processing algorithms Subspace constraints},
  type     = {Journal Article},
}

@Article{,
  author   = {Yang, Allen Y. and Wright, John and Ma, Yi and Sastry, S. Shankar},
  title    = {Unsupervised segmentation of natural images via lossy data compression},
  journal  = {Computer Vision and Image Understanding},
  year     = {2008},
  volume   = {110},
  number   = {2},
  pages    = {212-225},
  abstract = {In this paper, we cast natural-image segmentation as a problem of clustering texture features as multivariate mixed data. We model the distribution of the texture features using a mixture of Gaussian distributions. Unlike most existing clustering methods, we allow the mixture components to be degenerate or nearly-degenerate. We contend that this assumption is particularly important for mid-level image segmentation, where degeneracy is typically introduced by using a common feature representation for different textures in an image. We show that such a mixture distribution can be effectively segmented by a simple agglomerative clustering algorithm derived from a lossy data compression approach. Using either 2D texture filter banks or simple fixed-size windows to obtain texture features, the algorithm effectively segments an image by minimizing the overall coding length of the feature vectors. We conduct comprehensive experiments to measure the performance of the algorithm in terms of visual evaluation and a variety of quantitative indices for image segmentation. The algorithm compares favorably against other well-known image-segmentation methods on the Berkeley image database.},
  doi      = {http://dx.doi.org/10.1016/j.cviu.2007.07.005},
  issn     = {1077-3142},
  keywords = {Image segmentation Texture segmentation Lossy compression Mixture of Gaussian distributions Clustering},
  type     = {Journal Article},
  url      = {http://www.sciencedirect.com/science/article/pii/S1077314207001300},
}

@Article{Luxburg2007,
  author   = {Luxburg, Ulrike},
  title    = {A tutorial on spectral clustering},
  journal  = {Statistics and Computing},
  year     = {2007},
  volume   = {17},
  number   = {4},
  pages    = {395-416},
  abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
  doi      = {10.1007/s11222-007-9033-z},
  issn     = {1573-1375},
  type     = {Journal Article},
  url      = {http://dx.doi.org/10.1007/s11222-007-9033-z},
}

@Article{Vidal2007,
  author   = {Vidal, René and Tron, Roberto and Hartley, Richard},
  title    = {Multiframe Motion Segmentation with Missing Data Using PowerFactorization and GPCA},
  journal  = {International Journal of Computer Vision},
  year     = {2007},
  volume   = {79},
  number   = {1},
  pages    = {85-105},
  abstract = {We consider the problem of segmenting multiple rigid-body motions from point correspondences in multiple affine views. We cast this problem as a subspace clustering problem in which point trajectories associated with each motion live in a linear subspace of dimension two, three or four. Our algorithm involves projecting all point trajectories onto a 5-dimensional subspace using the SVD, the PowerFactorization method, or RANSAC, and fitting multiple linear subspaces representing different rigid-body motions to the points in ℝ5 using GPCA. Unlike previous work, our approach does not restrict the motion subspaces to be four-dimensional and independent. Instead, it deals gracefully with all the spectrum of possible affine motions: from two-dimensional and partially dependent to four-dimensional and fully independent. Our algorithm can handle the case of missing data, meaning that point tracks do not have to be visible in all images, by using the PowerFactorization method to project the data. In addition, our method can handle outlying trajectories by using RANSAC to perform the projection. We compare our approach to other methods on a database of 167 motion sequences with full motions, independent motions, degenerate motions, partially dependent motions, missing data, outliers, etc. On motion sequences with complete data our method achieves a misclassification error of less that 5% for two motions and 29% for three motions.},
  doi      = {10.1007/s11263-007-0099-z},
  issn     = {1573-1405},
  type     = {Journal Article},
  url      = {http://dx.doi.org/10.1007/s11263-007-0099-z},
}

@InBook{Yan2006,
  pages     = {94-106},
  title     = {A General Framework for Motion Segmentation: Independent, Articulated, Rigid, Non-rigid, Degenerate and Non-degenerate},
  publisher = {Springer Berlin Heidelberg},
  year      = {2006},
  author    = {Yan, Jingyu and Pollefeys, Marc},
  editor    = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
  type      = {Book Section},
  address   = {Berlin, Heidelberg},
  booktitle = {Computer Vision – ECCV 2006: 9th European Conference on Computer Vision, Graz, Austria, May 7-13, 2006, Proceedings, Part IV},
  doi       = {10.1007/11744085_8},
  isbn      = {978-3-540-33839-0},
  url       = {http://dx.doi.org/10.1007/11744085_8},
}

@Article{,
  author   = {Vidal, R. and Yi, Ma and Sastry, S.},
  title    = {Generalized principal component analysis (GPCA)},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2005},
  volume   = {27},
  number   = {12},
  pages    = {1945-1959},
  doi      = {10.1109/TPAMI.2005.244},
  issn     = {0162-8828},
  keywords = {computer vision expectation-maximisation algorithm geometry polynomials principal component analysis algebro-geometric solution expectation maximization generalized principal component analysis homogeneous polynomials iterative techniques polynomial factorization subspace segmentation Application software Clustering algorithms Iterative algorithms Kernel Machine learning Matrix decomposition Motion segmentation Index Terms- Principal component analysis (PCA) Veronese map dimensionality reduction dynamic scenes and motion segmentation. temporal video segmentation Algorithms Artificial Intelligence Cluster Analysis Computer Simulation Image Enhancement Image Interpretation, Computer-Assisted Imaging, Three-Dimensional Information Storage and Retrieval Models, Statistical Pattern Recognition, Automated},
  type     = {Journal Article},
}

@Article{ref1,
  author   = {Gear, C.W.},
  title    = {Multibody Grouping from Motion Images},
  journal  = {International Journal of Computer Vision},
  year     = {1998},
  volume   = {29},
  number   = {2},
  pages    = {133-150},
  abstract = {We want to deduce, from a sequence of noisy two-dimensional images of a scene of several rigid bodies moving independently in three dimensions, the number of bodies and the grouping of given feature points in the images to the bodies. Prior processing is assumed to have identified features or points common to all frames and the images are assumed to be created by orthographic projection (i.e., perspective effects are minimal). We describe a computationally inexpensive algorithm that can determine which points or features belong to which rigid body using the fact that, with exact observations in orthographic projection, points on a single body lie in a three or less dimensional linear manifold of frame space. If there are enough observations and independent motions, these manifolds can be viewed as a set linearly independent, four or less dimensional subspaces. We show that the row echelon canonical form provides direct information on the grouping of points to these subspaces. Treatment of the noise is the most difficult part of the problem. This paper uses a statistical approach to estimate the grouping of points to subspaces in the presence of noise by computing which partition has the maximum likelihood. The input data is assumed to be contaminated with independent Gaussian noise. The algorithm can base its estimates on a user-supplied standard deviation of the noise, or it can estimate the noise from the data. The algorithm can also be used to estimate the probability of a user-specified partition so that the hypothesis can be combined with others using Bayesian statistics.},
  doi      = {10.1023/a:1008026310903},
  issn     = {1573-1405},
  type     = {Journal Article},
  url      = {http://dx.doi.org/10.1023/A:1008026310903},
}

@Article{MC_MultiLlabel2015PAMI,
  author   = {Cabral, R. and Torre, F. D. l. and Costeira, J. P. and Bernardino, A.},
  title    = {Matrix Completion for Weakly-Supervised Multi-Label Image Classification},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2015},
  volume   = {37},
  number   = {1},
  pages    = {121-135},
  doi      = {10.1109/TPAMI.2014.2343234},
  issn     = {0162-8828},
  keywords = {image classification image segmentation learning (artificial intelligence) matrix algebra background noise bounding boxes discriminative methods labeling errors low-rank matrix completion problem manual labeling manual segmentations matrix completion multiple-instance learning methods object classifiers optimal spatial enclosure partial occlusions pixelwise segmentations semantic segmentation state-of-the-art classification algorithms training images visual concepts visual recognition weakly-supervised multilabel image classification Histograms Minimization Pattern analysis Semantics Training Vectors Weakly-supervised learning multi-label image classification nuclear norm rank minimization segmentation},
  type     = {Journal Article},
}

@Article{LuoMCmultilabel,
  author   = {Luo, Y. and Liu, T. and Tao, D. and Xu, C.},
  title    = {Multiview Matrix Completion for Multilabel Image Classification},
  journal  = {IEEE Transactions on Image Processing},
  year     = {2015},
  volume   = {24},
  number   = {8},
  pages    = {2355-2368},
  doi      = {10.1109/TIP.2015.2421309},
  issn     = {1057-7149},
  keywords = {computational complexity feature extraction image classification least squares approximations matrix algebra AP loss MC-based image classification MVMC framework average precision loss features concatenate learning process least squares loss formulation multilabel image classification multiview MC framework multiview matrix completion ranking- based criteria single-view feature time complexity web-based image analytics-based application Minimization Optimization Robustness Support vector machines average precision matrix completion multi-label multi-view transductive},
  type     = {Journal Article},
}

@Article{Lin2014,
  author   = {Lin, Zhouchen and Liu, Risheng and Li, Huan},
  title    = {Linearized alternating direction method with parallel splitting and adaptive penalty for separable convex programs in machine learning},
  journal  = {Machine Learning},
  year     = {2014},
  volume   = {99},
  number   = {2},
  pages    = {287-325},
  abstract = {Many problems in machine learning and other fields can be (re)formulated as linearly constrained separable convex programs. In most of the cases, there are multiple blocks of variables. However, the traditional alternating direction method (ADM) and its linearized version (LADM, obtained by linearizing the quadratic penalty term) are for the two-block case and cannot be naively generalized to solve the multi-block case. So there is great demand on extending the ADM based methods for the multi-block case. In this paper, we propose LADM with parallel splitting and adaptive penalty (LADMPSAP) to solve multi-block separable convex programs efficiently. When all the component objective functions have bounded subgradients, we obtain convergence results that are stronger than those of ADM and LADM, e.g., allowing the penalty parameter to be unbounded and proving the sufficient and necessary conditions for global convergence. We further propose a simple optimality measure and reveal the convergence rate of LADMPSAP in an ergodic sense. For programs with extra convex set constraints, with refined parameter estimation we devise a practical version of LADMPSAP for faster convergence. Finally, we generalize LADMPSAP to handle programs with more difficult objective functions by linearizing part of the objective function as well. LADMPSAP is particularly suitable for sparse representation and low-rank recovery problems because its subproblems have closed form solutions and the sparsity and low-rankness of the iterates can be preserved during the iteration. It is also highly parallelizable and hence fits for parallel or distributed computing. Numerical experiments testify to the advantages of LADMPSAP in speed and numerical accuracy.},
  doi      = {10.1007/s10994-014-5469-5},
  issn     = {1573-0565},
  type     = {Journal Article},
  url      = {http://dx.doi.org/10.1007/s10994-014-5469-5},
}

@Article{,
  author   = {Yang, Junfeng and Zhang, Yin},
  title    = {Alternating Direction Algorithms for $\ell_1$-Problems in Compressive Sensing},
  journal  = {SIAM Journal on Scientific Computing},
  year     = {2011},
  volume   = {33},
  number   = {1},
  pages    = {250-278},
  doi      = {doi:10.1137/090777761},
  keywords = {65F22,65J22,65K10,90C25,90C06},
  type     = {Journal Article},
  url      = {http://epubs.siam.org/doi/abs/10.1137/090777761},
}

@Article{ADMM,
  author  = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  title   = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
  journal = {Found. Trends Mach. Learn.},
  year    = {2011},
  volume  = {3},
  number  = {1},
  pages   = {1-122},
  doi     = {10.1561/2200000016},
  issn    = {1935-8237},
  type    = {Journal Article},
}

@Article{Gorski2007,
  author   = {Gorski, Jochen and Pfeuffer, Frank and Klamroth, Kathrin},
  title    = {Biconvex sets and optimization with biconvex functions: a survey and extensions},
  journal  = {Mathematical Methods of Operations Research},
  year     = {2007},
  volume   = {66},
  number   = {3},
  pages    = {373-407},
  abstract = {The problem of optimizing a biconvex function over a given (bi)convex or compact set frequently occurs in theory as well as in industrial applications, for example, in the field of multifacility location or medical image registration. Thereby, a function $$f:X\times Y\to{\mathbb{R}}$$ is called biconvex, if f(x,y) is convex in y for fixed x∈X, and f(x,y) is convex in x for fixed y∈Y. This paper presents a survey of existing results concerning the theory of biconvex sets and biconvex functions and gives some extensions. In particular, we focus on biconvex minimization problems and survey methods and algorithms for the constrained as well as for the unconstrained case. Furthermore, we state new theoretical results for the maximum of a biconvex function over biconvex sets.},
  doi      = {10.1007/s00186-007-0161-1},
  issn     = {1432-5217},
  type     = {Journal Article},
  url      = {http://dx.doi.org/10.1007/s00186-007-0161-1},
}

@InProceedings{YangRobinsonVidal,
  author    = {Yang, Congyuan and Robinson, Daniel and Vidal, Rene},
  title     = {Sparse Subspace Clustering with Missing Entries},
  booktitle = {The 32 nd International Conference on Machine Learning},
  year      = {2015},
  volume    = {37},
  publisher = {JMLR W\&CP},
  type      = {Conference Proceedings},
}

@Article{Su:2009:SCF:1592474.1722966,
  author     = {Su, Xiaoyuan and Khoshgoftaar, Taghi M.},
  title      = {A Survey of Collaborative Filtering Techniques},
  journal    = {Adv. in Artif. Intell.},
  year       = {2009},
  volume     = {2009},
  pages      = {4:2--4:2},
  month      = jan,
  acmid      = {1722966},
  address    = {New York, NY, United States},
  articleno  = {4},
  doi        = {10.1155/2009/421425},
  issn       = {1687-7470},
  issue_date = {January 2009},
  numpages   = {1},
  publisher  = {Hindawi Publishing Corp.},
  url        = {http://dx.doi.org/10.1155/2009/421425},
}

@Article{MC_TNNR_PAMI2013,
  author    = {Yao Hu and Debing Zhang and Jieping Ye and Xuelong Li and Xiaofei He},
  title     = {Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2013},
  volume    = {35},
  number    = {9},
  pages     = {2117-2130},
  address   = {Los Alamitos, CA, USA},
  doi       = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2012.271},
  issn      = {0162-8828},
  publisher = {IEEE Computer Society},
}

@Article{MCGross2011,
  author   = {D. Gross},
  title    = {Recovering Low-Rank Matrices From Few Coefficients in Any Basis},
  journal  = {IEEE Transactions on Information Theory},
  year     = {2011},
  volume   = {57},
  number   = {3},
  pages    = {1548-1566},
  month    = {March},
  doi      = {10.1109/TIT.2011.2104999},
  issn     = {0018-9448},
  keywords = {computational complexity;matrix algebra;degree of incoherence;low-rank matrix recovery;matrix completion;multiplicative constants;randomly sampled expansion coefficients;Coherence;Compressed sensing;Convex functions;Eigenvalues and eigenfunctions;Linear matrix inequalities;Random variables;Compressed sensing;matrix completion;matrix recovery;operator large-deviation bound;quantum-state tomography},
}

@Article{MC_Candes2010TIT,
  author     = {Cand\`{e}s, Emmanuel J. and Tao, Terence},
  title      = {The Power of Convex Relaxation: Near-optimal Matrix Completion},
  journal    = {IEEE Trans. Inf. Theor.},
  year       = {2010},
  volume     = {56},
  number     = {5},
  pages      = {2053--2080},
  month      = may,
  issn       = {0018-9448},
  acmid      = {1823678},
  address    = {Piscataway, NJ, USA},
  doi        = {10.1109/TIT.2010.2044061},
  issue_date = {May 2010},
  keywords   = {Duality in optimization, duality in optimization, free probability, low-rank matrices, matrix completion, nuclear norm minimization, random matrices and techniques from random matrix theory, semidefinite programming},
  numpages   = {28},
  publisher  = {IEEE Press},
  url        = {http://dx.doi.org/10.1109/TIT.2010.2044061},
}

@InProceedings{MC_icml2014c1_chenc14,
  author    = {Yudong Chen and Srinadh Bhojanapalli and Sujay Sanghavi and Rachel Ward},
  title     = {Coherent Matrix Completion},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
  year      = {2014},
  pages     = {674-682},
  publisher = {JMLR Workshop and Conference Proceedings},
}

@InCollection{MC_NIPS2015_6022,
  author    = {Gunasekar, Suriya and Banerjee, Arindam and Ghosh, Joydeep},
  title     = {Unified View of Matrix Completion under General Structural Constraints},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  year      = {2015},
  editor    = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
  pages     = {1180--1188},
  url       = {http://papers.nips.cc/paper/6022-unified-view-of-matrix-completion-under-general-structural-constraints.pdf},
}

@Article{MC_corrupcolumn2011,
  author        = {{Chen}, Y. and {Xu}, H. and {Caramanis}, C. and {Sanghavi}, S.},
  title         = {{Matrix completion with column manipulation: Near-optimal sample-robustness-rank tradeoffs}},
  journal       = {ArXiv e-prints},
  year          = {2011},
  month         = feb,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2011arXiv1102.2254C},
  archiveprefix = {arXiv},
  eprint        = {1102.2254},
  keywords      = {Statistics - Machine Learning, Computer Science - Information Theory},
  primaryclass  = {stat.ML},
}

@Article{MC_robust_2014arXiv,
  author        = {{Klopp}, O. and {Lounici}, K. and {Tsybakov}, A.~B.},
  title         = {{Robust Matrix Completion}},
  journal       = {ArXiv e-prints},
  year          = {2014},
  month         = dec,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2014arXiv1412.8132K},
  archiveprefix = {arXiv},
  eprint        = {1412.8132},
  keywords      = {Mathematics - Statistics Theory},
  primaryclass  = {math.ST},
}

@PhdThesis{MC_Srebro2004,
  author    = {Srebro, Nathan},
  title     = {Learning with Matrix Factorizations},
  year      = {2004},
  address   = {Cambridge, MA, USA},
  note      = {AAI0807530},
  publisher = {Massachusetts Institute of Technology},
}

@Article{MC_MF_Wen2012,
  author   = {Wen, Zaiwen and Yin, Wotao and Zhang, Yin},
  title    = {Solving a low-rank factorization model for matrix completion by a nonlinear successive over-relaxation algorithm},
  journal  = {Mathematical Programming Computation},
  year     = {2012},
  volume   = {4},
  number   = {4},
  pages    = {333--361},
  abstract = {The matrix completion problem is to recover a low-rank matrix from a subset of its entries. The main solution strategy for this problem has been based on nuclear-norm minimization which requires computing singular value decompositions---a task that is increasingly costly as matrix sizes and ranks increase. To improve the capacity of solving large-scale problems, we propose a low-rank factorization model and construct a nonlinear successive over-relaxation (SOR) algorithm that only requires solving a linear least squares problem per iteration. Extensive numerical experiments show that the algorithm can reliably solve a wide range of problems at a speed at least several times faster than many nuclear-norm minimization algorithms. In addition, convergence of this nonlinear SOR algorithm to a stationary point is analyzed.},
  doi      = {10.1007/s12532-012-0044-1},
  issn     = {1867-2957},
  url      = {http://dx.doi.org/10.1007/s12532-012-0044-1},
}

@Article{MC_ADMM2014,
  author  = {Y. Shen and Z. Wen and Y. Zhang},
  title   = {Augmented Lagrangian alternating direction method for matrix separation based on low-rank factorization},
  journal = {Optimization Methods and Software},
  year    = {2014},
  volume  = {29},
  number  = {2},
  pages   = {239-263},
  doi     = {10.1080/10556788.2012.700713},
  eprint  = { http://dx.doi.org/10.1080/10556788.2012.700713 },
  url     = {
        http://dx.doi.org/10.1080/10556788.2012.700713

},
}

@Article{MC_Riemannian2013,
  author  = {Bart Vandereycken},
  title   = {Low-Rank Matrix Completion by Riemannian Optimization},
  journal = {SIAM Journal on Optimization},
  year    = {2013},
  volume  = {23},
  number  = {2},
  pages   = {1214-1236},
  doi     = {10.1137/110845768},
  eprint  = { http://dx.doi.org/10.1137/110845768 },
  url     = {
        http://dx.doi.org/10.1137/110845768

},
}

@Article{MC_OptSpace_2009,
  author        = {{Keshavan}, R.~H. and {Oh}, S.},
  title         = {{A Gradient Descent Algorithm on the Grassman Manifold for Matrix Completion}},
  journal       = {ArXiv e-prints},
  year          = {2009},
  month         = oct,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2009arXiv0910.5260K},
  archiveprefix = {arXiv},
  eprint        = {0910.5260},
  keywords      = {Computer Science - Numerical Analysis, Computer Science - Learning},
  primaryclass  = {cs.NA},
}

@InProceedings{MC_GROUSE_2010,
  author    = {L. Balzano and R. Nowak and B. Recht},
  title     = {Online identification and tracking of subspaces from highly incomplete information},
  booktitle = {Communication, Control, and Computing (Allerton), 2010 48th Annual Allerton Conference on},
  year      = {2010},
  pages     = {704-711},
  month     = {Sept},
  doi       = {10.1109/ALLERTON.2010.5706976},
  keywords  = {Internet;gradient methods;iterative methods;matrix algebra;symbol manipulation;GROUSE;Grassmanian rank-one update subspace estimation;Grassmannian manifold;gradient descent algorithm;linear algebraic manipulations;low-rank matrix completion problem;online identification;online incremental algorithm;subspace update;subspaces tracking;Algorithm design and analysis;Approximation methods;Cost function;Estimation;Manifolds;Noise;Steady-state},
}

@Article{MC_ADM_Chen09062011,
  author   = {Chen, Caihua and He, Bingsheng and Yuan, Xiaoming},
  title    = {Matrix completion via an alternating direction method},
  journal  = {IMA Journal of Numerical Analysis},
  year     = {2011},
  abstract = {The matrix completion problem is to complete an unknown matrix from a small number of entries, and it captures many applications in diversified areas. Recently, it was shown that completing a low-rank matrix can be successfully accomplished by solving its convex relaxation problem using the nuclear norm. This paper shows that the alternating direction method (ADM) is applicable for completing a low-rank matrix including the noiseless case, the noisy case and the positive semidefinite case. The ADM approach for the matrix completion problem is easily implementable and very efficient. Numerical comparisons of the ADM approach with some state-of-the-art methods are reported.},
  doi      = {10.1093/imanum/drq039},
  eprint   = {http://imajna.oxfordjournals.org/content/early/2011/06/08/imanum.drq039.full.pdf+html},
  url      = {http://imajna.oxfordjournals.org/content/early/2011/06/08/imanum.drq039.abstract},
}

@InProceedings{MC_ShattenP_AAAI125165,
  author    = {Nie, Feiping and Huang, Heng and Ding, Chris},
  title     = {Low-rank Matrix Recovery via Efficient Schatten P-norm Minimization},
  booktitle = {Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence},
  year      = {2012},
  pages     = {655--661},
  publisher = {AAAI Press},
  acmid     = {2900822},
  location  = {Toronto, Ontario, Canada},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=2900728.2900822},
}

@Article{MC_GSVT_2014,
  author        = {{Lu}, C. and {Zhu}, C. and {Xu}, C. and {Yan}, S. and {Lin}, Z.},
  title         = {{Generalized Singular Value Thresholding}},
  journal       = {ArXiv e-prints},
  year          = {2014},
  month         = dec,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2014arXiv1412.2231L},
  archiveprefix = {arXiv},
  eprint        = {1412.2231},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Numerical Analysis, Mathematics - Numerical Analysis},
  primaryclass  = {cs.CV},
}

@InBook{SC_LSR_Lu2012,
  chapter   = {Robust and Efficient Subspace Segmentation via Least Squares Regression},
  pages     = {347--360},
  title     = {Computer Vision -- ECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part VII},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Lu, Can-Yi and Min, Hai and Zhao, Zhong-Qiu and Zhu, Lin and Huang, De-Shuang and Yan, Shuicheng},
  editor    = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  address   = {Berlin, Heidelberg},
  doi       = {10.1007/978-3-642-33786-4_26},
  isbn      = {978-3-642-33786-4},
  url       = {http://dx.doi.org/10.1007/978-3-642-33786-4_26},
}

@InCollection{LADMMAP_NIPS2011,
  author    = {Lin, Zhouchen and Risheng Liu and Zhixun Su},
  title     = {Linearized Alternating Direction Method with Adaptive Penalty for Low-Rank Representation},
  booktitle = {Advances in Neural Information Processing Systems 24},
  publisher = {Curran Associates, Inc.},
  year      = {2011},
  editor    = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
  pages     = {612--620},
  url       = {http://papers.nips.cc/paper/4434-linearized-alternating-direction-method-with-adaptive-penalty-for-low-rank-representation.pdf},
}

@Article{LALM_LADMM,
  author     = {Yang, Junfeng and Yuan, Xiaoming},
  title      = {Linearized augmented {L}agrangian and alternating direction methods for nuclear norm minimization},
  journal    = {Math. Comp.},
  year       = {2013},
  volume     = {82},
  number     = {281},
  pages      = {301--329},
  coden      = {MCMPAF},
  doi        = {10.1090/S0025-5718-2012-02598-1},
  fjournal   = {Mathematics of Computation},
  issn       = {0025-5718},
  mrclass    = {90C25 (90C06)},
  mrnumber   = {2983026},
  mrreviewer = {Lei-Hong Zhang},
  url        = {http://dx.doi.org/10.1090/S0025-5718-2012-02598-1},
}

@Article{ProximalA,
  author     = {Parikh, Neal and Boyd, Stephen},
  title      = {Proximal Algorithms},
  journal    = {Found. Trends Optim.},
  year       = {2014},
  volume     = {1},
  number     = {3},
  pages      = {127--239},
  month      = jan,
  acmid      = {2693613},
  address    = {Hanover, MA, USA},
  doi        = {10.1561/2400000003},
  issn       = {2167-3888},
  issue_date = {January 2014},
  numpages   = {113},
  publisher  = {Now Publishers Inc.},
  url        = {http://dx.doi.org/10.1561/2400000003},
}

@Article{Dataset_ExtendYaleB,
  author  = {Kuang-Chih, Lee and Ho, J. and Kriegman, D. J.},
  title   = {Acquiring linear subspaces for face recognition under variable lighting},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2005},
  volume  = {27},
  number  = {5},
  pages   = {684-698},
  doi     = {10.1109/TPAMI.2005.92},
  issn    = {0162-8828},
  type    = {Journal Article},
}

@InProceedings{Dataset_MITCBCL,
  author    = {B. Weyrauch and B. Heisele and J. Huang and V. Blanz},
  title     = {Component-Based Face Recognition with 3D Morphable Models},
  booktitle = {Computer Vision and Pattern Recognition Workshop, 2004. CVPRW '04. Conference on},
  year      = {2004},
  pages     = {85-85},
  month     = {June},
  doi       = {10.1109/CVPR.2004.41},
  keywords  = {Biology computing;Computer vision;Detectors;Face detection;Face recognition;Image databases;Image recognition;Lighting;Object detection;Support vector machines},
}

@Article{Web_NCDC,
  title   = {National Climatic Data Center},
  journal = {http://www.ncdc.noaa.gov},
}

@Article{Web_JesterJoke,
  title   = {Jester jokes datasets},
  journal = {http://eigentaste.berkeley.edu/dataset/},
}

@Article{Web_MovieLens100K,
  title   = {MovieLens 100K Dataset},
  journal = {http://grouplens.org/datasets/movielens/100k/},
}

@Article{Toh:2010vx,
  author               = {Toh, Kim-Chuan and Yun, Sangwoon},
  title                = {{An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems}},
  journal              = {Pacific Journal of Optimization},
  year                 = {2010},
  abstract             = {{The affine rank minimization problem , which consists of finding a matrix of mini- mum rank subject to linear equality constraints, has been proposed in many areas of engineering and science. A specific rank minimization problem is the matrix comple- tion problem , in which we wish ...}},
  citeulike-article-id = {9501533},
  citeulike-linkout-0  = {http://www.math.nus.edu.sg/\~{}mattohkc/papers/mc11.pdf},
  posted-at            = {2011-07-04 10:28:54},
  url                  = {http://www.math.nus.edu.sg/\~{}mattohkc/papers/mc11.pdf},
}

@Article{LinChenMa2013,
  author  = {Lin, Zhouchen and Chen, Minming and Ma, Yi},
  title   = {The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices},
  journal = {arXiv:1009.5055v3 [math.OC]},
  year    = {2010},
}

@Article{ErikssonBalzanoNowak2011,
  author    = {Eriksson, Brian and Balzano, Laura and Nowak, Robert D.},
  title     = {High-Rank Matrix Completion and Subspace Clustering with Missing Data},
  journal   = {CoRR},
  year      = {2011},
  volume    = {abs/1112.5629},
  added-at  = {2015-05-07T00:00:00.000+0200},
  biburl    = {http://www.bibsonomy.org/bibtex/261172e2bad9b4ec34ae977dba81446c3/dblp},
  ee        = {http://arxiv.org/abs/1112.5629},
  interhash = {0372a9ef4aca67b5ffe504afb4858e14},
  intrahash = {61172e2bad9b4ec34ae977dba81446c3},
  keywords  = {dblp},
  timestamp = {2015-06-18T03:54:10.000+0200},
  url       = {http://dblp.uni-trier.de/db/journals/corr/corr1112.html#abs-1112-5629},
}

@Article{MC_Recht2011:SAM,
  author     = {Recht, Benjamin},
  title      = {A Simpler Approach to Matrix Completion},
  journal    = {J. Mach. Learn. Res.},
  year       = {2011},
  volume     = {12},
  pages      = {3413--3430},
  month      = dec,
  acmid      = {2185803},
  issn       = {1532-4435},
  issue_date = {2/1/2011},
  numpages   = {18},
  publisher  = {JMLR.org},
  url        = {http://dl.acm.org/citation.cfm?id=1953048.2185803},
}

@Proceedings{,
}

@InProceedings{MC_IRRN,
  author    = {C. Lu and J. Tang and S. Yan and Z. Lin},
  title     = {Generalized Nonconvex Nonsmooth Low-Rank Minimization},
  booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2014},
  pages     = {4130-4137},
  month     = {June},
  doi       = {10.1109/CVPR.2014.526},
  issn      = {1063-6919},
  keywords  = {concave programming;minimisation;concave function;generalized nonconvex minimization;iteratively reweighted nuclear norm algorithm;low rank matrix recovery;nonconvex penalty function;nonsmooth low rank minimization;surrogate functions;weight vector;weighted singular value thresholding problem;Algorithm design and analysis;Convergence;Convex functions;Educational institutions;Minimization;Programming;Vectors},
}

@Proceedings{,
}

@Article{KPCA1998,
  author  = {Schölkopf, Bernhard and Smola, Alexander and Müller, Klaus-Robert},
  title   = {Nonlinear Component Analysis as a Kernel Eigenvalue Problem},
  journal = {Neural Computation},
  year    = {1998},
  volume  = {10},
  number  = {5},
  pages   = {1299-1319},
  doi     = {10.1162/089976698300017467},
  issn    = {0899-7667},
  type    = {Journal Article},
  url     = {http://dx.doi.org/10.1162/089976698300017467},
}

@Article{L-BFGS,
  author   = {Liu, Dong C. and Nocedal, Jorge},
  title    = {On the limited memory BFGS method for large scale optimization},
  journal  = {Mathematical Programming},
  year     = {1989},
  volume   = {45},
  number   = {1},
  pages    = {503--528},
  abstract = {We study the numerical performance of a limited memory quasi-Newton method for large scale optimization, which we call the L-BFGS method. We compare its performance with that of the method developed by Buckley and LeNir (1985), which combines cycles of BFGS steps and conjugate direction steps. Our numerical tests indicate that the L-BFGS method is faster than the method of Buckley and LeNir, and is better able to use additional storage to accelerate convergence. We show that the L-BFGS method can be greatly accelerated by means of a simple scaling. We then compare the L-BFGS method with the partitioned quasi-Newton method of Griewank and Toint (1982a). The results show that, for some problems, the partitioned quasi-Newton method is clearly superior to the L-BFGS method. However we find that for other problems the L-BFGS method is very competitive due to its low iteration cost. We also study the convergence properties of the L-BFGS method, and prove global convergence on uniformly convex problems.},
  doi      = {10.1007/BF01589116},
  issn     = {1436-4646},
  url      = {http://dx.doi.org/10.1007/BF01589116},
}

@InCollection{NIPS2010_3932,
  author    = {Andrew Goldberg and Ben Recht and Junming Xu and Robert Nowak and Zhu, Xiaojin},
  title     = {Transduction with Matrix Completion: Three Birds with One Stone},
  booktitle = {Advances in Neural Information Processing Systems 23},
  publisher = {Curran Associates, Inc.},
  year      = {2010},
  pages     = {757--765},
}

@Misc{minFunc,
  author       = {M. Schmidt},
  title        = {minFunc: unconstrained differentiable multivariate optimization in Matlab},
  howpublished = {http://www.cs.ubc.ca/~schmidtm/Software/minFunc. html},
  year         = {2005},
}

@Article{Kallas20133066,
  author   = {Maya Kallas and Paul Honeine and Cédric Richard and Clovis Francis and Hassan Amoud},
  title    = {Non-negativity constraints on the pre-image for pattern recognition with kernel machines},
  journal  = {Pattern Recognition},
  year     = {2013},
  volume   = {46},
  number   = {11},
  pages    = {3066 - 3080},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2013.03.021},
  issn     = {0031-3203},
  keywords = {Kernel machines, Machine learning, SVM, Kernel PCA, Pre-image problem, Non-negativity constraints, Nonlinear denoising, Pattern recognition },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320313001507},
}

@Article{PreImageKPCA2010TNN,
  author   = {W. S. Zheng and J. Lai and P. C. Yuen},
  title    = {Penalized Preimage Learning in Kernel Principal Component Analysis},
  journal  = {IEEE Transactions on Neural Networks},
  year     = {2010},
  volume   = {21},
  number   = {4},
  pages    = {551-570},
  month    = {April},
  doi      = {10.1109/TNN.2009.2039647},
  issn     = {1045-9227},
  keywords = {face recognition;image reconstruction;learning (artificial intelligence);principal component analysis;Laplacian penalty;convexity constraint;face image data sets;face image denoising;facial expression normalization;feature vector;illumination normalization;image preprocessing;image reconstruction;kernel principal component analysis;mean square error;occlusion;optimization function;penalized preimage learning;pointwise conditional mutual information;ridge penalty;visual quality;Constraint optimization;Image denoising;Image reconstruction;Kernel;Laplace equations;Lighting;Mean square error methods;Mutual information;Principal component analysis;Turning;Kernel;kernel principal component analysis (KPCA);locality preservation;penalty function;preimage problem;Algorithms;Artificial Intelligence;Computer Simulation;Humans;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Principal Component Analysis},
}

@Article{PreImageKPCA2004TNN,
  author   = {J. T. Y. Kwok and I. W. H. Tsang},
  title    = {The pre-image problem in kernel methods},
  journal  = {IEEE Transactions on Neural Networks},
  year     = {2004},
  volume   = {15},
  number   = {6},
  pages    = {1517-1525},
  month    = {Nov},
  doi      = {10.1109/TNN.2004.837781},
  issn     = {1045-9227},
  keywords = {image denoising;linear algebra;principal component analysis;distance constraint;feature space;feature vector;kernel clustering;kernel method;kernel principal component analysis;linear algebra;preimage problem;Clustering algorithms;Constraint optimization;Image denoising;Kernel;Linear algebra;Noise reduction;Optimization methods;Performance evaluation;Principal component analysis;Space technology;Kernel principal component analysis (PCA);multidimensional scaling (MDS);pre-image;Algorithms;Artificial Intelligence;Cluster Analysis;Computer Simulation;Decision Support Techniques;Feedback;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Neural Networks (Computer);Pattern Recognition, Automated;Principal Component Analysis},
}

@Article{Data_MNIST1998,
  author   = {Y. Lecun and L. Bottou and Y. Bengio and P. Haffner},
  title    = {Gradient-based learning applied to document recognition},
  journal  = {Proceedings of the IEEE},
  year     = {1998},
  volume   = {86},
  number   = {11},
  pages    = {2278-2324},
  month    = {Nov},
  doi      = {10.1109/5.726791},
  issn     = {0018-9219},
  keywords = {backpropagation;convolution;multilayer perceptrons;optical character recognition;2D shape variability;GTN;back-propagation;cheque reading;complex decision surface synthesis;convolutional neural network character recognizers;document recognition;document recognition systems;field extraction;gradient based learning technique;gradient-based learning;graph transformer networks;handwritten character recognition;handwritten digit recognition task;high-dimensional patterns;language modeling;multilayer neural networks;multimodule systems;performance measure minimization;segmentation recognition;Character recognition;Feature extraction;Hidden Markov models;Machine learning;Multi-layer neural network;Neural networks;Optical character recognition software;Optical computing;Pattern recognition;Principal component analysis},
}

@Misc{SVM-KMToolbox,
  author       = {S. Canu and Y. Grandvalet and V. Guigue and A. Rakotomamonjy},
  title        = {SVM and Kernel Methods Matlab Toolbox},
  howpublished = {Perception Syst�mes et Information, INSA de Rouen, Rouen, France},
  year         = {2005},
}

@Article{ML_KNN,
  author   = {Min-Ling Zhang and Zhi-Hua Zhou},
  title    = {ML-KNN: A lazy learning approach to multi-label learning},
  journal  = {Pattern Recognition},
  year     = {2007},
  volume   = {40},
  number   = {7},
  pages    = {2038 - 2048},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2006.12.019},
  issn     = {0031-3203},
  keywords = {Machine learning, Multi-label learning, Lazy learning, K-nearest neighbor, Functional genomics, Natural scene classification, Text categorization },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320307000027},
}

@Article{ML_RBF,
  author   = {Zhang, Min-Ling},
  title    = {Ml-rbf: RBF Neural Networks for Multi-Label Learning},
  journal  = {Neural Processing Letters},
  year     = {2009},
  volume   = {29},
  number   = {2},
  pages    = {61--74},
  abstract = {Multi-label learning deals with the problem where each instance is associated with multiple labels simultaneously. The task of this learning paradigm is to predict the label set for each unseen instance, through analyzing training instances with known label sets. In this paper, a neural network based multi-label learning algorithm named Ml-rbf is proposed, which is derived from the traditional radial basis function (RBF) methods. Briefly, the first layer of an Ml-rbf neural network is formed by conducting clustering analysis on instances of each possible class, where the centroid of each clustered groups is regarded as the prototype vector of a basis function. After that, second layer weights of the Ml-rbf neural network are learned by minimizing a sum-of-squares error function. Specifically, information encoded in the prototype vectors corresponding to all classes are fully exploited to optimize the weights corresponding to each specific class. Experiments on three real-world multi-label data sets show that Ml-rbf achieves highly competitive performance to other well-established multi-label learning algorithms.},
  doi      = {10.1007/s11063-009-9095-3},
  issn     = {1573-773X},
  url      = {http://dx.doi.org/10.1007/s11063-009-9095-3},
}

@InProceedings{Mika99kernelpca,
  author    = {Sebastian Mika and Bernhard Schölkopf and Alex Smola and Klaus-Robert Müller and Matthias Scholz and Gunnar Rätsch},
  title     = {Kernel PCA and De-Noising in Feature Spaces},
  booktitle = {Advances in Neural Information Processing Systems 11},
  year      = {1999},
  pages     = {536--542},
  publisher = {MIT Press},
}

@InProceedings{NLMC2016,
  author    = {Alameda-Pineda, Xavier and Ricci, Elisa and Yan, Yan and Sebe, Nicu},
  title     = {Recognizing Emotions From Abstract Paintings Using Non-Linear Matrix Completion},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {5240--5248},
}

@Article{KPCA2014,
  author   = {A. Papaioannou and S. Zafeiriou},
  title    = {Principal Component Analysis With Complex Kernel: The Widely Linear Model},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  year     = {2014},
  volume   = {25},
  number   = {9},
  pages    = {1719-1726},
  month    = {Sept},
  doi      = {10.1109/TNNLS.2013.2285783},
  issn     = {2162-237X},
  keywords = {Hilbert spaces;digital filters;principal component analysis;regression analysis;CRKHS;Euler data representation;classification frameworks;complex kernel;complex reproducing kernel Hilbert spaces;digital filters;dimensionality reduction;nonlinear complex representations;principal component analysis;regression frameworks;robust reconstruction;widely linear model;Covariance matrices;Eigenvalues and eigenfunctions;Image reconstruction;Kernel;Principal component analysis;Robustness;Vectors;Complex kernels;machine vision;pattern recognition;principal component analysis (PCA);principal component analysis (PCA).},
}

@Article{Multi-label2013,
  author   = {Y. Luo and D. Tao and C. Xu and C. Xu and H. Liu and Y. Wen},
  title    = {Multiview Vector-Valued Manifold Regularization for Multilabel Image Classification},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  year     = {2013},
  volume   = {24},
  number   = {5},
  pages    = {709-722},
  month    = {May},
  doi      = {10.1109/TNNLS.2013.2238682},
  issn     = {2162-237X},
  keywords = {computer vision;feature extraction;image classification;matrix algebra;vectors;MIR Flickr datasets;MV3MR;PASCAL datasets;VOC' 07 datasets;complementary property;computer vision;image datasets;intrinsic local geometry discovery;label relationship;matrix-valued kernel construction;multilabel image classification;multiview vector-valued manifold regularization;vector-valued function;visual features;Correlation;Image color analysis;Kernel;Laplace equations;Manifolds;Optimization;Support vector machines;Image classification;manifold;multilabel;multiview;semisupervised},
}

@Article{Multi-label2015,
  author   = {Q. Wu and Y. Ye and H. Zhang and T. W. S. Chow and S. S. Ho},
  title    = {ML-TREE: A Tree-Structure-Based Approach to Multilabel Learning},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  year     = {2015},
  volume   = {26},
  number   = {3},
  pages    = {430-443},
  month    = {March},
  doi      = {10.1109/TNNLS.2014.2315296},
  issn     = {2162-237X},
  keywords = {learning (artificial intelligence);pattern classification;support vector machines;trees (mathematics);Friedman tests;ML-Tree algorithm;Nemenyi tests;automatic label relationships discovery;child nodes;hierarchical tree model;multilabel learning;multilabel prediction;one-against-all SVM classifiers;predictive label cooccurrence;predictive label transmission;predictive label vector;training samples;tree-structure-based approach;Clustering algorithms;Correlation;Partitioning algorithms;Prediction algorithms;Support vector machines;Training;Vectors;Hierarchical tree model;multilabel classification;multilabel learning;tree-based classification;tree-based classification.},
}

@Book{PCA_Jolliffe2002,
  title     = {Principal Component Analysis},
  publisher = {Springer},
  year      = {2002},
  author    = {Jolliffe, I.T.},
  series    = {Springer Series in Statistics},
  isbn      = {9780387954424},
  lccn      = {2002019560},
  }

@InProceedings{Si:2016:GIM:2939672.2939809,
  author    = {Si, Si and Chiang, Kai-Yang and Hsieh, Cho-Jui and Rao, Nikhil and Dhillon, Inderjit S.},
  title     = {Goal-Directed Inductive Matrix Completion},
  booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2016},
  series    = {KDD '16},
  pages     = {1165--1174},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2939809},
  doi       = {10.1145/2939672.2939809},
  isbn      = {978-1-4503-4232-2},
  keywords  = {matrix completion},
  location  = {San Francisco, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2939672.2939809},
}

@InProceedings{liu2016kernelized,
  author    = {Liu, Xinyue and Aggarwal, Charu and Li, Yu-Feng and Kong, Xiangnan and Sun, Xinyuan and Sathe, Saket},
  title     = {Kernelized matrix factorization for collaborative filtering},
  booktitle = {SIAM Conference on Data Mining},
  year      = {2016},
  pages     = {399--416},
}

@InProceedings{icml2014c2_wanga14,
  author    = {Zheng Wang and Ming-jun Lai and Zhaosong Lu and Wei Fan and Hasan Davulcu and Jieping Ye},
  title     = {Rank-One Matrix Pursuit for Matrix Completion},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
  year      = {2014},
  pages     = {91-99},
}

@InBook{KMC2012,
  pages     = {403-414},
  title     = {Kernelized Probabilistic Matrix Factorization: Exploiting Graphs and Side Information},
  year      = {2012},
  author    = {Tinghui Zhou and Hanhuai Shan and Arindam Banerjee and Guillermo Sapiro},
  booktitle = {Proceedings of the 2012 SIAM International Conference on Data Mining},
}

@Article{IMC2013,
  author  = {Jain, Prateek and Dhillon, Inderjit S},
  title   = {Provable inductive matrix completion},
  journal = {arXiv preprint arXiv:1306.0626},
  year    = {2013},
}

@Article{TIP_MC_201501,
  author  = {K. H. Jin and J. C. Ye},
  title   = {Annihilating Filter-Based Low-Rank Hankel Matrix Approach for Image Inpainting},
  journal = {IEEE Transactions on Image Processing},
  year    = {2015},
  volume  = {24},
  number  = {11},
  pages   = {3498-3511},
  month   = {Nov},
  doi     = {10.1109/TIP.2015.2446943},
  issn    = {1057-7149},
}

@Article{TIP_MC_2016,
  author  = {Q. Liu and Z. Lai and Z. Zhou and F. Kuang and Z. Jin},
  title   = {A Truncated Nuclear Norm Regularization Method Based on Weighted Residual Error for Matrix Completion},
  journal = {IEEE Transactions on Image Processing},
  year    = {2016},
  volume  = {25},
  number  = {1},
  pages   = {316-330},
  month   = {Jan},
}

@Article{TIP_MC_TNNM,
  author  = {C. Lee and E. Y. Lam},
  title   = {Computationally Efficient Truncated Nuclear Norm Minimization for High Dynamic Range Imaging},
  journal = {IEEE Transactions on Image Processing},
  year    = {2016},
  volume  = {25},
  number  = {9},
  pages   = {4145-4157},
  month   = {Sept},
}

@Article{Liu2014218,
  author   = {Lu Liu and Wei Huang and Di-Rong Chen},
  title    = {Exact minimum rank approximation via Schatten p-norm minimization},
  journal  = {Journal of Computational and Applied Mathematics},
  year     = {2014},
  volume   = {267},
  pages    = {218 - 227},
  doi      = {http://dx.doi.org/10.1016/j.cam.2014.02.015},
  issn     = {0377-0427},
  keywords = {Rank minimization, Schatten p -norm, Singular value decomposition, Restricted isometry constant, Random matrix, Majorization minimization },
  url      = {http://www.sciencedirect.com/science/article/pii/S0377042714001010},
}

@Article{2012arXiv1209.0377Y,
  author        = {{Yue}, M.-C. and {Man-Cho So}, A.},
  title         = {{A Perturbation Inequality for the Schatten-$p$ Quasi-Norm and Its Applications to Low-Rank Matrix Recovery}},
  journal       = {ArXiv e-prints},
  year          = {2012},
  month         = sep,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2012arXiv1209.0377Y},
  archiveprefix = {arXiv},
  eprint        = {1209.0377},
  keywords      = {Mathematics - Optimization and Control, Computer Science - Information Theory},
  primaryclass  = {math.OC},
}

@Article{MC_TSP_2015_Mard,
  author  = {M. Mardani and G. Mateos and G. B. Giannakis},
  title   = {Subspace Learning and Imputation for Streaming Big Data Matrices and Tensors},
  journal = {IEEE Transactions on Signal Processing},
  year    = {2015},
  volume  = {63},
  number  = {10},
  pages   = {2663-2677},
  month   = {May},
  doi     = {10.1109/TSP.2015.2417491},
  issn    = {1053-587X},
}

@Article{MC_TSP_2015_Chou,
  author   = {S. Chouvardas and Y. Kopsinis and S. Theodoridis},
  title    = {Robust Subspace Tracking With Missing Entries: The Set-Theoretic Approach},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2015},
  volume   = {63},
  number   = {19},
  pages    = {5060-5070},
  month    = {Oct},
  doi      = {10.1109/TSP.2015.2449254},
  issn     = {1053-587X},
  keywords = {gradient methods;matrix algebra;object tracking;set theory;APSM based algorithm;adaptive projected subgradient method;corrupted data purification;observation vectors;outlier detection mechanism;outlier vector estimation;prediction procedure;robust matrix completion;robust subspace estimation;robust subspace tracking;set theoretic approach;sparsity-promoting greedy algorithm;time instance;zero level set;Algorithm design and analysis;Cost function;Estimation;Noise;Prediction algorithms;Robustness;Signal processing algorithms;APSM;Robust subspace tracking;greedy algorithms},
}

@Article{MC_TSP_2016_Cao,
  author   = {Y. Cao and Y. Xie},
  title    = {Poisson Matrix Recovery and Completion},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {6},
  pages    = {1609-1620},
  month    = {March},
  doi      = {10.1109/TSP.2015.2500192},
  issn     = {1053-587X},
  keywords = {Gaussian noise;Poisson distribution;matrix algebra;maximum likelihood estimation;signal processing;stochastic processes;vectors;Poisson distribution;Poisson likelihood function;Poisson noise;compressed measurement;iterative algorithm;low-rank Poisson matrix recovery theory;matrix completion;maximum likelihood;signal-to-noise requirement;sparse vector recovery;subGaussian characteristics;word length 1 bit;Approximation algorithms;Compressed sensing;Noise measurement;Random variables;Signal to noise ratio;Sparse matrices;Upper bound;Estimation;Poisson noise;information theoretic bounds;low-rank matrix recovery;matrix completion},
}

@Article{LiuLi2016,
  author   = {G. Liu and P. Li},
  title    = {Low-Rank Matrix Completion in the Presence of High Coherence},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {PP},
  number   = {99},
  pages    = {1-1},
  doi      = {10.1109/TSP.2016.2586753},
  issn     = {1053-587X},
  keywords = {Coherence;Dictionaries;Distributed databases;Electronic mail;Indexes;Manifolds;Matrix decomposition},
}

@Article{MC_TSP_2016_Zhao,
  author   = {L. Zhao and P. Babu and D. P. Palomar},
  title    = {Efficient Algorithms on Robust Low-Rank Matrix Completion Against Outliers},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {18},
  pages    = {4767-4780},
  month    = {Sept},
  doi      = {10.1109/TSP.2016.2572049},
  issn     = {1053-587X},
  keywords = {Big Data;Gaussian noise;data analysis;matrix algebra;parallel processing;Big Data system analytics;additive Gaussian noise;bilinear factorization formulation;dense outlier;parallel computing;robust low-rank matrix completion;sparse spike-like outlier;Approximation algorithms;Convergence;Gaussian noise;Manganese;Principal component analysis;Robustness;Signal processing algorithms;Matrix completion;factorization formulation;parallel algorithm;robust loss functions},
}

@Article{MC_TSP_2016_Yang,
  author   = {L. Yang and J. Fang and H. Li and B. Zeng},
  title    = {An Iterative Reweighted Method for Tucker Decomposition of Incomplete Tensors},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {18},
  pages    = {4817-4829},
  month    = {Sept},
  doi      = {10.1109/TSP.2016.2572047},
  issn     = {1053-587X},
  keywords = {data analysis;iterative methods;tensors;Tucker decomposition;computational complexity;data analysis;group-based log-sum penalty functional;iterative optimization;iterative reweighted method;low-rank incomplete tensor decomposition;model complexity;multilinear low-rank structure;multilinear operations;objective function;over-relaxed monotone fast iterative shrinkage-thresholding technique;surrogate function;Complexity theory;Electronic mail;Iterative methods;Matrix decomposition;Optimization;Signal processing algorithms;Tensile stress;Tucker decomposition;iterative reweighted method;low rank tensor decomposition;tensor completion},
}

@Article{MC_TSP_2016_Xin,
  author  = {B. Xin and Y. Wang and W. Gao and D. Wipf},
  title   = {Exploring Algorithmic Limits of Matrix Rank Minimization Under Affine Constraints},
  journal = {IEEE Transactions on Signal Processing},
  year    = {2016},
  volume  = {64},
  number  = {19},
  pages   = {4960-4974},
  month   = {Oct},
  doi     = {10.1109/TSP.2016.2551697},
  issn    = {1053-587X},
}

@Article{MC_TSP_2016_Huang,
  author   = {K. Huang and N. D. Sidiropoulos and A. P. Liavas},
  title    = {A Flexible and Efficient Algorithmic Framework for Constrained Matrix and Tensor Factorization},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {19},
  pages    = {5052-5065},
  month    = {Oct},
  doi      = {10.1109/TSP.2016.2576427},
  issn     = {1053-587X},
  keywords = {matrix decomposition;signal processing;tensors;AO-ADMM;alternating direction method;alternating optimization;block coordinate descent-type methods;computation caching;dictionary learning;general algorithmic framework;machine learning;matrix factorization;matrix/tensor completion;multipliers;non-negative matrix;signal processing;tensor factorization;Complexity theory;Loss measurement;Matrix decomposition;Optimization;Signal processing;Signal processing algorithms;Tensile stress;Constrained matrix/tensor factorization;PARAFAC;alternating direction method of multipliers;alternating optimization;canonical polyadic decomposition;dictionary learning;matrix/tensor completion;non-negative matrix/tensor factorization},
}

@Article{MC_TSP_2016_Velas,
  author   = {J. Velasco and D. Pizarro and J. Macias-Guarasa and A. Asaei},
  title    = {TDOA Matrices: Algebraic Properties and Their Application to Robust Denoising With Missing Data},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {20},
  pages    = {5242-5254},
  month    = {Oct},
  doi      = {10.1109/TSP.2016.2593690},
  issn     = {1053-587X},
  keywords = {Estimation;Matrix decomposition;Noise measurement;Noise reduction;Pollution measurement;Robustness;Sensors;TDOA denoising;TDOA estimation;matrix completion;missing data;skew-symmetric matrices},
}

@Article{MC_2016_Sun,
  author   = {M. Sundin and C. R. Rojas and M. Jansson and S. Chatterjee},
  title    = {Relevance Singular Vector Machine for Low-Rank Matrix Reconstruction},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {20},
  pages    = {5327-5339},
  month    = {Oct},
  doi      = {10.1109/TSP.2016.2597121},
  issn     = {1053-587X},
  keywords = {Bayes methods;Convex functions;Covariance matrices;Estimation;Signal processing algorithms;Sparse matrices;Standards;Bayes methods;Machine learning;compressed sensing},
}

@Article{MC_TSP_2016_Yokota,
  author   = {T. Yokota and Q. Zhao and A. Cichocki},
  title    = {Smooth PARAFAC Decomposition for Tensor Completion},
  journal  = {IEEE Transactions on Signal Processing},
  year     = {2016},
  volume   = {64},
  number   = {20},
  pages    = {5423-5436},
  month    = {Oct},
  doi      = {10.1109/TSP.2016.2586759},
  issn     = {1053-587X},
  keywords = {Image color analysis;Interpolation;Matrix decomposition;Minimization;TV;Tensile stress;Visualization;CP model;PARAFAC model;Tensor completion for images;low-rank tensor approximation;quadratic variation;smoothness;total variation (TV)},
}

@Article{li2016structured,
  author    = {Li, Chun-Guang and Vidal, Rene},
  title     = {A Structured Sparse Plus Structured Low-Rank Framework for Subspace Clustering and Completion},
  journal   = {IEEE Transactions on Signal Processing},
  year      = {2016},
  volume    = {64},
  number    = {24},
  pages     = {6557--6570},
  publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
}

@Article{liu2016low,
  author    = {Liu, Guangcan and Li, Ping},
  title     = {Low-rank matrix completion in the presence of high coherence},
  journal   = {IEEE Transactions on Signal Processing},
  year      = {2016},
  volume    = {64},
  number    = {21},
  pages     = {5623--5633},
  publisher = {IEEE},
}

@Article{,
  author   = {Zhao, Miaoyun and Jiao, Licheng and Ma, Wenping and Liu, Hongying and Yang, Shuyuan},
  title    = {Classification and saliency detection by semi-supervised low-rank representation},
  journal  = {Pattern Recognition},
  year     = {2016},
  volume   = {51},
  pages    = {281-294},
  abstract = {In the area of pattern recognition, Low Rank Representation (LRR) is an efficient method in recovering the subspace structure of the dataset. However, LRR is unsupervised. Without any label information, LRR constructs an informative graph which is then combined with the mature graph-based semi-supervised learning (GSSL) framework to complete the classification task. In this paper, we propose a new low rank learning method which constructs the low rank representation matrix utilizing label information to obtain a more informative graph. This method integrates the low rank graph construction and the label information propagation processes together. Thus the optimization of the low rank representation and the soft label prediction function are calculated iteratively at the same time. We name this method as Semi-Supervised Low Rank Learning (SSLRL). It enhanced the classification performance of traditional LRR-Graph based SSL by 5–30% and the running time is reduced from hundreds to less than ten seconds. Based on this method, a new outlier detection strategy is presented. This strategy succeeds with an AUC of at least 93% even if the detection condition of LRR is not satisfied. The effectiveness of SSLRL is demonstrated in semi-supervised classification, outlier detection, and salient detection tasks. These extensive experimental results highlight the outperforming of our method over state-of-the-art methods.},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2015.09.008},
  issn     = {0031-3203},
  keywords = {Low rank representation Semi-supervised learning Outlier detection Saliency detection},
  type     = {Journal Article},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320315003398},
}

@Article{Liu2013284,
  author   = {Yuanyuan Liu and L.C. Jiao and Fanhua Shang},
  title    = {An efficient matrix factorization based low-rank representation for subspace clustering},
  journal  = {Pattern Recognition},
  year     = {2013},
  volume   = {46},
  number   = {1},
  pages    = {284 - 292},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2012.06.011},
  issn     = {0031-3203},
  keywords = {Nuclear norm minimization (NNM), Low rank representation, Alternating direction method (ADM), Matrix tri-factorization, Positive semidefinite (PSD) },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320312002816},
}

@Article{He20161041,
  author   = {Zhi He and Lin Liu and Suhong Zhou and Yi Shen},
  title    = {Learning group-based sparse and low-rank representation for hyperspectral image classification},
  journal  = {Pattern Recognition},
  year     = {2016},
  volume   = {60},
  pages    = {1041 - 1056},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2016.04.009},
  issn     = {0031-3203},
  keywords = {Classification, Hyperspectral image (HSI), Dictionary learning, Sparse representation, Low-rank representation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320316300425},
}

@Article{Zhao2016281,
  author   = {Miaoyun Zhao and Licheng Jiao and Wenping Ma and Hongying Liu and Shuyuan Yang},
  title    = {Classification and saliency detection by semi-supervised low-rank representation},
  journal  = {Pattern Recognition},
  year     = {2016},
  volume   = {51},
  pages    = {281 - 294},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2015.09.008},
  issn     = {0031-3203},
  keywords = {Low rank representation, Semi-supervised learning, Outlier detection, Saliency detection },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320315003398},
}

@Article{Liu2013163,
  author   = {Yuanyuan Liu and L.C. Jiao and Fanhua Shang},
  title    = {A fast tri-factorization method for low-rank matrix recovery and completion},
  journal  = {Pattern Recognition},
  year     = {2013},
  volume   = {46},
  number   = {1},
  pages    = {163 - 173},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2012.07.003},
  issn     = {0031-3203},
  keywords = {Rank minimization, Nuclear norm minimization, Matrix completion, Low-rank and sparse decomposition, Low rank representation },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320312002981},
}

@Article{Li2016890,
  author   = {Yongqiang Li and Baoyuan Wu and Bernard Ghanem and Yongping Zhao and Hongxun Yao and Qiang Ji},
  title    = {Facial action unit recognition under incomplete data based on multi-label learning with missing labels},
  journal  = {Pattern Recognition},
  year     = {2016},
  volume   = {60},
  pages    = {890 - 900},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2016.07.009},
  issn     = {0031-3203},
  keywords = {Face action unit recognition, Incomplete data, Multi-label learning },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320316301583},
}

@Article{Wu20152279,
  author   = {Baoyuan Wu and Siwei Lyu and Bao-Gang Hu and Qiang Ji},
  title    = {Multi-label learning with missing labels for image annotation and facial action unit recognition},
  journal  = {Pattern Recognition},
  year     = {2015},
  volume   = {48},
  number   = {7},
  pages    = {2279 - 2289},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2015.01.022},
  issn     = {0031-3203},
  keywords = {Multi-label learning, Missing labels, Image annotation, Facial action unit recognition },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320315000412},
}

@Article{Liu201685,
  author   = {Zhun-ga Liu and Quan Pan and Jean Dezert and Arnaud Martin},
  title    = {Adaptive imputation of missing values for incomplete pattern classification},
  journal  = {Pattern Recognition},
  year     = {2016},
  volume   = {52},
  pages    = {85 - 95},
  doi      = {http://dx.doi.org/10.1016/j.patcog.2015.10.001},
  issn     = {0031-3203},
  keywords = {Belief function, Classification, Missing values, SOM, K-NN },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320315003684},
}

@Article{Nie2015,
  author   = {Nie, Feiping and Wang, Hua and Huang, Heng and Ding, Chris},
  title    = {Joint Schatten p-norm and lp-norm robust matrix completion for missing value recovery},
  journal  = {Knowledge and Information Systems},
  year     = {2015},
  volume   = {42},
  number   = {3},
  pages    = {525--544},
  abstract = {The low-rank matrix completion problem is a fundamental machine learning and data mining problem with many important applications. The standard low-rank matrix completion methods relax the rank minimization problem by the trace norm minimization. However, this relaxation may make the solution seriously deviate from the original solution. Meanwhile, most completion methods minimize the squared prediction errors on the observed entries, which is sensitive to outliers. In this paper, we propose a new robust matrix completion method to address these two problems. The joint Schatten                                                                           {\$}{\$}p{\$}{\$}                                                            p                                                      -norm and                                                                           {\$}{\$}{\backslash}ell {\_}p{\$}{\$}                                                                                    ℓ                        p                                                                            -norm are used to better approximate the rank minimization problem and enhance the robustness to outliers. The extensive experiments are performed on both synthetic data and real-world applications in collaborative filtering prediction and social network link recovery. All empirical results show that our new method outperforms the standard matrix completion methods.},
  doi      = {10.1007/s10115-013-0713-z},
  issn     = {0219-3116},
  url      = {http://dx.doi.org/10.1007/s10115-013-0713-z},
}

@Article{Fan2017290,
  author   = {Jicong Fan and Tommy W.S. Chow},
  title    = {Matrix completion by least-square, low-rank, and sparse self-representations},
  journal  = {Pattern Recognition},
  year     = {2017},
  volume   = {71},
  pages    = {290 - 305},
  doi      = {https://doi.org/10.1016/j.patcog.2017.05.013},
  issn     = {0031-3203},
  keywords = {Matrix completion, Missing value, Low-rank and sparse representations, Image inpainting, Collaborative filtering },
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320317302030},
}

@Article{Fan201736,
  author   = {Jicong Fan and Tommy W.S. Chow},
  title    = {Sparse subspace clustering for data with missing entries and high-rank matrix completion},
  journal  = {Neural Networks},
  year     = {2017},
  volume   = {93},
  pages    = {36 - 44},
  doi      = {https://doi.org/10.1016/j.neunet.2017.04.005},
  issn     = {0893-6080},
  keywords = {Subspace clustering, Sparse representation, Missing entries, High-rank, Matrix completion },
  url      = {http://www.sciencedirect.com/science/article/pii/S0893608017300850},
}

@Article{imageinpainting2014,
  author   = {C. Guillemot and O. Le Meur},
  title    = {Image Inpainting : Overview and Recent Advances},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2014},
  volume   = {31},
  number   = {1},
  pages    = {127-144},
  month    = {Jan},
  doi      = {10.1109/MSP.2013.2273004},
  issn     = {1053-5888},
  keywords = {image restoration;IBR;art restoration;cameras;disocclusion;image inpainting;image restoration;image-based rendering;impaired image transmission;object removal;text overlays;Image color analysis;Image edge detection;Mathematical model;Smoothing methods;Tensile stress},
}

@Article{HOTV2011,
  author  = {Carola-Bibiane Schönlieb and Andrea Bertozzi},
  title   = {Unconditionally stable schemes for higher order inpainting},
  journal = {Communications in Mathematical Sciences},
  year    = {2011},
  volume  = {9},
  number  = {2},
  pages   = {413-457},
}

@Article{Benning2013,
  author   = {Benning, Martin and Brune, Christoph and Burger, Martin and M{\"u}ller, Jahn},
  title    = {Higher-Order TV method---enhancement via Bregman iteration},
  journal  = {Journal of Scientific Computing},
  year     = {2013},
  volume   = {54},
  number   = {2},
  pages    = {269--310},
  abstract = {In this work we analyze and compare two recent variational models for image denoising and improve their reconstructions by applying a Bregman iteration strategy. One of the standard techniques in image denoising, the ROF-model (cf. Rudin et al. in Physica D 60:259--268, 1992), is well known for recovering sharp edges of a signal or image, but also for producing staircase-like artifacts. In order to overcome these model-dependent deficiencies, total variation modifications that incorporate higher-order derivatives have been proposed (cf. Chambolle and Lions in Numer. Math. 76:167--188, 1997; Bredies et al. in SIAM J. Imaging Sci. 3(3):492--526, 2010). These models reduce staircasing for reasonable parameter choices. However, the combination of derivatives of different order leads to other undesired side effects, which we shall also highlight in several examples.},
  doi      = {10.1007/s10915-012-9650-3},
  issn     = {1573-7691},
  url      = {http://dx.doi.org/10.1007/s10915-012-9650-3},
}

@InProceedings{zhang2011sparse,
  author       = {Zhang, Lei and Yang, Meng and Feng, Xiangchu},
  title        = {Sparse representation or collaborative representation: Which helps face recognition?},
  booktitle    = {Computer vision (ICCV), 2011 IEEE international conference on},
  year         = {2011},
  pages        = {471--478},
  organization = {IEEE},
}

@Article{wright2009robust,
  author    = {Wright, John and Yang, Allen Y and Ganesh, Arvind and Sastry, S Shankar and Ma, Yi},
  title     = {Robust face recognition via sparse representation},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2009},
  volume    = {31},
  number    = {2},
  pages     = {210--227},
  publisher = {IEEE},
}

@Article{MA2017,
  author   = {Jianghong Ma and Zhaoyang Tian and Haijun Zhang and Tommy W.S. Chow},
  title    = {Multi-Label Low-dimensional Embedding with Missing Labels},
  journal  = {Knowledge-Based Systems},
  year     = {2017},
  doi      = {https://doi.org/10.1016/j.knosys.2017.09.005},
  issn     = {0950-7051},
  keywords = {Label imputation, Low rank, Instance-wise label correlation, Inductive classifier},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705117304136},
}

@Article{MA2018336,
  author   = {Jianghong Ma and Tommy W.S. Chow},
  title    = {Robust non-negative sparse graph for semi-supervised multi-label learning with missing labels},
  journal  = {Information Sciences},
  year     = {2018},
  volume   = {422},
  number   = {Supplement C},
  pages    = {336 - 351},
  doi      = {https://doi.org/10.1016/j.ins.2017.08.061},
  issn     = {0020-0255},
  keywords = {Label recovery, Semi-supervised setting, Missing labels, Semantic structure, Semantic correlation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025517309088},
}

@Article{FAN2014205,
  author   = {Jicong Fan and S. Joe Qin and Youqing Wang},
  title    = {Online monitoring of nonlinear multivariate industrial processes using filtering KICA–PCA},
  journal  = {Control Engineering Practice},
  year     = {2014},
  volume   = {22},
  pages    = {205 - 216},
  doi      = {https://doi.org/10.1016/j.conengprac.2013.06.017},
  issn     = {0967-0661},
  keywords = {Process monitoring, KICA–PCA, Variance of independent component, EWMA, Variable contribution analysis, TE process},
  url      = {http://www.sciencedirect.com/science/article/pii/S0967066113001275},
}

@Article{FAN2017540,
  author   = {Jicong Fan and Tommy Chow},
  title    = {Deep learning based matrix completion},
  journal  = {Neurocomputing},
  year     = {2017},
  volume   = {266},
  number   = {Supplement C},
  pages    = {540 - 549},
  doi      = {https://doi.org/10.1016/j.neucom.2017.05.074},
  issn     = {0925-2312},
  keywords = {Matrix completion, AutoEncoder, deep learning, out-of-sample extension, image inpainting, collaborative filtering},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231217309621},
}

@Article{Fan2017,
  author   = {Fan, Jicong and Chow, Tommy W. S. and Zhao, Mingbo and Ho, John K. L.},
  title    = {Nonlinear Dimensionality Reduction for Data with Disconnected Neighborhood Graph},
  journal  = {Neural Processing Letters},
  year     = {2017},
  month    = {Aug},
  abstract = {Neighborhood graph based nonlinear dimensionality reduction algorithms, such as Isomap and LLE, perform well under an assumption that the neighborhood graph is connected. However, for datasets consisting of multiple clusters or lying on multiple manifolds, the neighborhood graphs are often disconnected, or in other words, have multiple connected components. Neighborhood graph based dimensionality reduction techniques cannot recognize both the local and global properties of such datasets. In this paper, a new method, called enhanced neighborhood graph, is proposed to solve the problem. The concept is to add edges to the neighborhood graph adaptively and iteratively until it becomes connected. Nonlinear dimensionality reduction can then be performed based on the enhanced neighborhood graph. As a result, both local and global properties of the data can be exactly recognized. In this study, thorough simulations on synthetic datasets and natural datasets are conducted. The experimental results corroborate that the proposed method provides significant improvements on dimensionality reduction for data with disconnected neighborhood graph.},
  day      = {03},
  doi      = {10.1007/s11063-017-9676-5},
  issn     = {1573-773X},
  url      = {https://doi.org/10.1007/s11063-017-9676-5},
}

@Article{6471823,
  author   = {Y. Chen and A. Jalali and S. Sanghavi and C. Caramanis},
  title    = {Low-Rank Matrix Recovery From Errors and Erasures},
  journal  = {IEEE Transactions on Information Theory},
  year     = {2013},
  volume   = {59},
  number   = {7},
  pages    = {4324-4337},
  month    = {July},
  doi      = {10.1109/TIT.2013.2249572},
  issn     = {0018-9448},
  keywords = {matrix decomposition;pattern recognition;erasure patterns;error patterns;low-rank matrix decomposition;low-rank matrix recovery;sparse matrix decomposition;Collaboration;Information theory;Matrix decomposition;Principal component analysis;Sparse matrices;Standards;Technological innovation;Low-rank;matrix decomposition;robustness;sparsity;statistical learning},
}

@Article{7064749,
  author   = {Y. Chen},
  title    = {Incoherence-Optimal Matrix Completion},
  journal  = {IEEE Transactions on Information Theory},
  year     = {2015},
  volume   = {61},
  number   = {5},
  pages    = {2909-2923},
  month    = {May},
  doi      = {10.1109/TIT.2015.2415195},
  issn     = {0018-9448},
  keywords = {computational complexity;singular value decomposition;sparse matrices;ℓ∞,2-norm;incoherence optimal matrix completion problem;incoherence parameter;joint incoherence condition;low rank plus sparse matrix decomposition;matrix decomposition problem;planted clique conjecture;polynomial- time algorithm;sample complexity bound;semidefinite matrix recovery;semisupervised clustering;singular value decomposition projection;structured matrix completion;Complexity theory;Information theory;Joints;Matrix decomposition;Sparse matrices;Standards;Vectors;Matrix completion;computational barrier;incoherence;nuclear norm minimization;robust PCA},
}

@Article{YPlan2012,
  author   = {Y.C. Eldar and D. Needell and Y. Plan},
  title    = {Uniqueness conditions for low-rank matrix recovery},
  journal  = {Applied and Computational Harmonic Analysis},
  year     = {2012},
  volume   = {33},
  number   = {2},
  pages    = {309 - 314},
  doi      = {https://doi.org/10.1016/j.acha.2012.04.002},
  issn     = {1063-5203},
  keywords = {Rank minimization, Nuclear-norm minimization, Low-rank matrix recovery, Random matrices, Compressed sensing},
  url      = {http://www.sciencedirect.com/science/article/pii/S1063520312000528},
}

@Article{5454406,
  author   = {E. J. Cand\`{e}s and Y. Plan},
  title    = {Matrix Completion With Noise},
  journal  = {Proceedings of the IEEE},
  year     = {2010},
  volume   = {98},
  number   = {6},
  pages    = {925-936},
  month    = {June},
  issn     = {0018-9219},
  doi      = {10.1109/JPROC.2009.2035722},
  keywords = {data integrity;matrix algebra;minimisation;noise;signal sampling;compressed sensing;convex optimization problem;data constraints;low rank matrices;matrix completion;nuclear norm minimization;Collaboration;Compressed sensing;Computer vision;Filtering;Frequency;Linear matrix inequalities;Machine learning;Motion pictures;Noise level;Remote sensing;Compressed sensing;duality in optimization;low-rank matrices;matrix completion;nuclear-norm minimization;oracle inequalities;semidefinite programming},
}

@Article{Review_LRMC,
  author   = {M. A. Davenport and J. Romberg},
  title    = {An Overview of Low-Rank Matrix Recovery From Incomplete Observations},
  journal  = {IEEE Journal of Selected Topics in Signal Processing},
  year     = {2016},
  volume   = {10},
  number   = {4},
  pages    = {608-622},
  month    = {June},
  doi      = {10.1109/JSTSP.2016.2539100},
  issn     = {1932-4553},
  keywords = {matrix algebra;signal processing;incomplete observations;indirect observations;low-rank matrix recovery;machine learning;signal processing;Analytical models;Computational modeling;Context;Matrix decomposition;Sensor arrays;Signal processing;Signal processing algorithms;Blind deconvolution;low-rank matrices;matrix completion;matrix recovery algorithms;phase retrieval},
}

@Article{5466511,
  author   = {R. H. Keshavan and A. Montanari and S. Oh},
  title    = {Matrix Completion From a Few Entries},
  journal  = {IEEE Transactions on Information Theory},
  year     = {2010},
  volume   = {56},
  number   = {6},
  pages    = {2980-2998},
  month    = {June},
  doi      = {10.1109/TIT.2010.2046205},
  issn     = {0018-9448},
  keywords = {matrix algebra;signal reconstruction;Feige-Ofek;Friedman-Kahn-Szemeredi;OptSpace;massive data sets;matrix completion;reconstruction algorithm;sparse random matrices;Collaboration;Information filtering;Information filters;Mathematical model;Motion pictures;Optimization methods;Reconstruction algorithms;Root mean square;Sparse matrices;Watches;Gradient descent;low rank;manifold optimization;matrix completion;phase transition;spectral methods},
}

@InProceedings{hardt2014understanding,
  author       = {Hardt, Moritz},
  title        = {Understanding alternating minimization for matrix completion},
  booktitle    = {Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on},
  year         = {2014},
  pages        = {651--660},
  organization = {IEEE},
}

@InProceedings{pmlr-v70-ongie17a,
  author    = {Greg Ongie and Rebecca Willett and Robert D. Nowak and Laura Balzano},
  title     = {Algebraic Variety Models for High-Rank Matrix Completion},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  year      = {2017},
  pages     = {2691--2700},
  publisher = {PMLR},
}

@Article{FANNLMC,
  author   = {Jicong Fan and Tommy W.S. Chow},
  title    = {Non-linear matrix completion},
  journal  = {Pattern Recognition},
  year     = {2018},
  volume   = {77},
  pages    = {378 - 394},
  doi      = {https://doi.org/10.1016/j.patcog.2017.10.014},
  issn     = {0031-3203},
  keywords = {Matrix completion, Low-rank, Kernel, Schatten -norm, Image inpainting, Single-/multi-label classification, Non-linear denoising},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320317304028},
}

@InProceedings{pimentel2016information,
  author    = {Pimentel-Alarcon, Daniel and Nowak, Robert},
  title     = {The information-theoretic requirements of subspace clustering with missing data},
  booktitle = {International Conference on Machine Learning},
  year      = {2016},
  pages     = {802--810},
}

@InProceedings{eriksson2012high,
  author    = {Eriksson, Brian and Balzano, Laura and Nowak, Robert},
  title     = {High-rank matrix completion},
  booktitle = {Artificial Intelligence and Statistics},
  year      = {2012},
  pages     = {373--381},
}

@InProceedings{yang2015sparse,
  author    = {Yang, Congyuan and Robinson, Daniel and Vidal, Rene},
  title     = {Sparse subspace clustering with missing entries},
  booktitle = {International Conference on Machine Learning},
  year      = {2015},
  pages     = {2463--2472},
}

@InProceedings{NIPS2016_6357,
  author    = {Elhamifar, Ehsan},
  title     = {High-Rank Matrix Completion and Clustering under Self-Expressive Models},
  booktitle = {Advances in Neural Information Processing Systems 29},
  year      = {2016},
  pages     = {73--81},
}


@Article{LADMC,
  author        = {{Ongie}, G. and {Balzano}, L. and {Pimentel-Alarc{\'o}n}, D. and {Willett}, R. and {Nowak}, R.~D.},
  title         = {{Tensor Methods for Nonlinear Matrix Completion}},
  journal       = {ArXiv e-prints},
  year          = {2018},
  month         = apr,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2018arXiv180410266O},
  archiveprefix = {arXiv},
  eprint        = {1804.10266},
  keywords      = {Statistics - Machine Learning, Computer Science - Learning},
  primaryclass  = {stat.ML},
}

@Article{pascoe2014inverse,
  author    = {Pascoe, JE},
  title     = {The inverse function theorem and the Jacobian conjecture for free analysis},
  journal   = {Mathematische Zeitschrift},
  year      = {2014},
  volume    = {278},
  number    = {3-4},
  pages     = {987--994},
  publisher = {Springer},
}

@Article{bass1982,
  author    = {Bass, Hyman and Connell, Edwin H. and Wright, David},
  title     = {The Jacobian conjecture: Reduction of degree and formal expansion of the inverse},
  journal   = {Bull. Amer. Math. Soc. (N.S.)},
  year      = {1982},
  volume    = {7},
  number    = {2},
  pages     = {287--330},
  month     = {09},
  fjournal  = {Bulletin (New Series) of the American Mathematical Society},
  publisher = {American Mathematical Society},
  url       = {https://projecteuclid.org:443/euclid.bams/1183549636},
}

@Book{van2012polynomial,
  title     = {Polynomial Automorphisms: and the Jacobian Conjecture},
  publisher = {Birkh{\"a}user},
  year      = {2012},
  author    = {Van den Essen, Arno},
  volume    = {190},
}

@InProceedings{4269999,
  author    = {R. Tron and R. Vidal},
  title     = {A Benchmark for the Comparison of 3-D Motion Segmentation Algorithms},
  booktitle = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2007},
  pages     = {1-8},
  month     = {June},
  doi       = {10.1109/CVPR.2007.382974},
  issn      = {1063-6919},
  keywords  = {computer vision;image segmentation;image sequences;motion estimation;3D motion segmentation algorithm;image sequence;Application software;Benchmark testing;Cameras;Computer vision;Databases;Image segmentation;Layout;Motion segmentation;Statistical analysis;Traffic control},
}

@Article{castella2008inversion,
  author    = {Castella, Marc},
  title     = {Inversion of polynomial systems and separation of nonlinear mixtures of finite-alphabet sources},
  journal   = {IEEE Transactions on Signal Processing},
  year      = {2008},
  volume    = {56},
  number    = {8},
  pages     = {3905--3917},
  publisher = {IEEE},
}

@InBook{Cox2007,
  pages     = {439--508},
  title     = {The Dimension of a Variety},
  publisher = {Springer New York},
  year      = {2007},
  author    = {Cox, David and Little, John and O'Shea, Donal},
  address   = {New York, NY},
  isbn      = {978-0-387-35651-8},
  abstract  = {The most important invariant of a linear subspace of affine space is its dimension. For affine varieties, we have seen numerous examples which have a clearly defined dimension, at least from a naive point of view. In this chapter, we will carefully define the dimension of any affine or projective variety and show how to compute it. We will also show that this notion accords well with what we would expect intuitively. In keeping with our general philosophy, we consider the computational side of dimension theory right from the outset.},
  booktitle = {Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra},
  doi       = {10.1007/978-0-387-35651-8_9},
  url       = {https://doi.org/10.1007/978-0-387-35651-8_9},
}

@Book{eisenbud_harris_2016,
  title     = {3264 and All That: A Second Course in Algebraic Geometry},
  publisher = {Cambridge University Press},
  year      = {2016},
  author    = {Eisenbud, David and Harris, Joe},
  doi       = {10.1017/CBO9781139062046},
  place     = {Cambridge},
}

@Article{5452187,
  author   = {E. J. Cand\`{e}s and T. Tao},
  title    = {The Power of Convex Relaxation: Near-Optimal Matrix Completion},
  journal  = {IEEE Transactions on Information Theory},
  year     = {2010},
  volume   = {56},
  number   = {5},
  pages    = {2053-2080},
  month    = {May},
  issn     = {0018-9448},
  doi      = {10.1109/TIT.2010.2044061},
  keywords = {convex programming;information theory;random processes;convex relaxation;near-optimal matrix completion;matrix completion problem;collaborative filtering;information theoretic limit;free probability;nuclear norm minimization;random matrices;random matrix theory;semidefinite programming;Collaboration;Mathematics;Associate members;Minimization methods;Signal processing;Information filtering;Information filters;Motion pictures;Duality in optimization;free probability;low-rank matrices;matrix completion;nuclear norm minimization;random matrices and techniques from random matrix theory;semidefinite programming},
}

@InProceedings{rendle2008online,
  author       = {Rendle, Steffen and Schmidt-Thieme, Lars},
  title        = {Online-updating regularized kernel matrix factorization models for large-scale recommender systems},
  booktitle    = {Proceedings of the 2008 ACM conference on Recommender systems},
  year         = {2008},
  pages        = {251--258},
  organization = {ACM},
}

@InProceedings{mairal2009online,
  author       = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
  title        = {Online dictionary learning for sparse coding},
  booktitle    = {Proceedings of the 26th annual international conference on machine learning},
  year         = {2009},
  pages        = {689--696},
  organization = {ACM},
}

@InProceedings{balzano2010online,
  author       = {Balzano, Laura and Nowak, Robert and Recht, Benjamin},
  title        = {Online identification and tracking of subspaces from highly incomplete information},
  booktitle    = {Communication, Control, and Computing (Allerton), 2010 48th Annual Allerton Conference on},
  year         = {2010},
  pages        = {704--711},
  organization = {IEEE},
}

@InProceedings{dhanjal2014online,
  author       = {Dhanjal, Charanpal and Gaudel, Romaric and Cl{\'e}men{\c{c}}on, St{\'e}phan},
  title        = {Online matrix completion through nuclear norm regularisation},
  booktitle    = {Proceedings of the 2014 SIAM International Conference on Data Mining},
  year         = {2014},
  pages        = {623--631},
  organization = {SIAM},
}

@InProceedings{kawale2015efficient,
  author    = {Kawale, Jaya and Bui, Hung H and Kveton, Branislav and Tran-Thanh, Long and Chawla, Sanjay},
  title     = {Efficient Thompson Sampling for Online￼ Matrix-Factorization Recommendation},
  booktitle = {Advances in neural information processing systems},
  year      = {2015},
  pages     = {1297--1305},
}

@InProceedings{lois2015online,
  author       = {Lois, Brian and Vaswani, Namrata},
  title        = {Online matrix completion and online robust pca},
  booktitle    = {Information Theory (ISIT), 2015 IEEE International Symposium on},
  year         = {2015},
  pages        = {1826--1830},
  organization = {IEEE},
}

@Article{yun2015streaming,
  author  = {Yun, Se-Young and Lelarge, Marc and Proutiere, Alexandre},
  title   = {Streaming, memory limited matrix completion with noise},
  journal = {arXiv preprint arXiv:1504.03156},
  year    = {2015},
}

@Article{sun2016guaranteed,
  author    = {Sun, Ruoyu and Luo, Zhi-Quan},
  title     = {Guaranteed matrix completion via non-convex factorization},
  journal   = {IEEE Transactions on Information Theory},
  year      = {2016},
  volume    = {62},
  number    = {11},
  pages     = {6535--6579},
  publisher = {IEEE},
}

@InProceedings{jin2016provable,
  author    = {Jin, Chi and Kakade, Sham M and Netrapalli, Praneeth},
  title     = {Provable efficient online matrix completion via non-convex stochastic gradient descent},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2016},
  pages     = {4520--4528},
}

@InProceedings{roggen2010collecting,
  author       = {Roggen, Daniel and Calatroni, Alberto and Rossi, Mirco and Holleczek, Thomas and F{\"o}rster, Kilian and Tr{\"o}ster, Gerhard and Lukowicz, Paul and Bannach, David and Pirkl, Gerald and Ferscha, Alois and others},
  title        = {Collecting complex activity datasets in highly rich networked sensor environments},
  booktitle    = {Networked Sensing Systems (INSS), 2010 Seventh International Conference on},
  year         = {2010},
  pages        = {233--240},
  organization = {IEEE},
}

@Article{randomsvd,
  author  = {N. Halko and P. G. Martinsson and J. A. Tropp},
  title   = {Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions},
  journal = {SIAM Review},
  year    = {2011},
  volume  = {53},
  number  = {2},
  pages   = {217-288},
}

@Article{FAN2018SFMC,
  author   = {J. Fan and M. Zhao and T. W. S. Chow},
  title    = {Matrix completion via sparse factorization solved by accelerated proximal alternating linearized minimization},
  journal  = {IEEE Transactions on Big Data},
  year     = {2018},
  pages    = {1-1},
  issn     = {2332-7790},
  doi      = {10.1109/TBDATA.2018.2871476},
  keywords = {Sparse matrices;Matrix decomposition;Acceleration;Minimization;Optimization;Collaboration;Big Data;matrix completion;sparse factorization;low-rank;accelerated proximal alternating linearized minimization;nonconvex optimization;collaborative filtering},
}

@Article{mazumder2010spectral,
  author  = {Mazumder, Rahul and Hastie, Trevor and Tibshirani, Robert},
  title   = {Spectral regularization algorithms for learning large incomplete matrices},
  journal = {Journal of machine learning research},
  year    = {2010},
  volume  = {11},
  number  = {Aug},
  pages   = {2287--2322},
}

@Article{wold1987principal,
  author    = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
  title     = {Principal component analysis},
  journal   = {Chemometrics and intelligent laboratory systems},
  year      = {1987},
  volume    = {2},
  number    = {1-3},
  pages     = {37--52},
  publisher = {Elsevier},
}

@Article{cs_Donoho,
  author  = {D. L. {Donoho}},
  title   = {Compressed sensing},
  journal = {IEEE Transactions on Information Theory},
  year    = {2006},
  volume  = {52},
  number  = {4},
  pages   = {1289-1306},
  month   = {April},
  doi     = {10.1109/TIT.2006.871582},
}

@Article{4483511,
  author  = {J. {Wright} and A. Y. {Yang} and A. {Ganesh} and S. S. {Sastry} and Y. {Ma}},
  title   = {Robust Face Recognition via Sparse Representation},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2009},
  volume  = {31},
  number  = {2},
  pages   = {210-227},
  month   = {Feb},
  doi     = {10.1109/TPAMI.2008.79},
}

@InProceedings{yang2009linear,
  author       = {Yang, Jianchao and Yu, Kai and Gong, Yihong and Huang, Thomas},
  title        = {Linear spatial pyramid matching using sparse coding for image classification},
  booktitle    = {2009 IEEE Conference on computer vision and pattern recognition},
  year         = {2009},
  pages        = {1794--1801},
  organization = {IEEE},
}

@InProceedings{Zhang2011,
  author       = {Zhang, Lei and Yang, Meng and Feng, Xiangchu},
  title        = {Sparse representation or collaborative representation: Which helps face recognition?},
  booktitle    = {2011 International conference on computer vision},
  year         = {2011},
  pages        = {471--478},
  organization = {IEEE},
}

@Article{hinton2006reducing,
  author    = {Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  title     = {Reducing the dimensionality of data with neural networks},
  journal   = {science},
  year      = {2006},
  volume    = {313},
  number    = {5786},
  pages     = {504--507},
  publisher = {American Association for the Advancement of Science},
}

@Article{tenenbaum2000global,
  author    = {Tenenbaum, Joshua B and De Silva, Vin and Langford, John C},
  title     = {A global geometric framework for nonlinear dimensionality reduction},
  journal   = {science},
  year      = {2000},
  volume    = {290},
  number    = {5500},
  pages     = {2319--2323},
  publisher = {American Association for the Advancement of Science},
}

@InProceedings{lee2001algorithms,
  author    = {Lee, Daniel D and Seung, H Sebastian},
  title     = {Algorithms for non-negative matrix factorization},
  booktitle = {Advances in neural information processing systems},
  year      = {2001},
  pages     = {556--562},
}

@InProceedings{mairal2009supervised,
  author    = {Mairal, Julien and Ponce, Jean and Sapiro, Guillermo and Zisserman, Andrew and Bach, Francis R},
  title     = {Supervised dictionary learning},
  booktitle = {Advances in neural information processing systems},
  year      = {2009},
  pages     = {1033--1040},
}

@Article{Hinton2006,
  author    = {Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  title     = {Reducing the dimensionality of data with neural networks},
  journal   = {science},
  year      = {2006},
  volume    = {313},
  number    = {5786},
  pages     = {504--507},
  publisher = {American Association for the Advancement of Science},
}

@Article{6516503,
  author   = {Z. {Jiang} and Z. {Lin} and L. S. {Davis}},
  title    = {Label Consistent {K-SVD}: Learning a Discriminative Dictionary for Recognition},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2013},
  volume   = {35},
  number   = {11},
  pages    = {2651-2664},
  month    = {Nov},
  doi      = {10.1109/TPAMI.2013.88},
  keywords = {face recognition;image classification;image coding;learning (artificial intelligence);object recognition;singular value decomposition;label consistent K-SVD algorithm;discriminative dictionary learning;sparse coding;label information association;label consistency constraint;discriminative sparse-code error constraint;linear classifier;incremental dictionary learning algorithm;face category recognition;action category recognition;scene category recognition;object category recognition;k-means clustering;singular value decomposition;Dictionaries;Linear programming;Classification algorithms;Training;Algorithm design and analysis;Image reconstruction;Testing;Discriminative dictionary learning;incremental dictionary learning;supervised learning;label consistent K-SVD;discriminative sparse-code error;Algorithms;Biometry;Discriminant Analysis;Face;Humans;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Support Vector Machines},
}

@Article{mairal2011task,
  author    = {Mairal, Julien and Bach, Francis and Ponce, Jean},
  title     = {Task-driven dictionary learning},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2011},
  volume    = {34},
  number    = {4},
  pages     = {791--804},
  publisher = {IEEE},
}

@Article{skretting2010recursive,
  author    = {Skretting, Karl and Engan, Kjersti},
  title     = {Recursive least squares dictionary learning algorithm},
  journal   = {IEEE Transactions on Signal Processing},
  year      = {2010},
  volume    = {58},
  number    = {4},
  pages     = {2121--2130},
  publisher = {IEEE},
}

@InProceedings{lu2013online,
  author    = {Lu, Cewu and Shi, Jiaping and Jia, Jiaya},
  title     = {Online robust dictionary learning},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2013},
  pages     = {415--422},
}

@InProceedings{jiang2015robust,
  author    = {Jiang, Wenhao and Nie, Feiping and Huang, Heng},
  title     = {Robust dictionary learning with capped {$\ell_1$}-norm},
  booktitle = {Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year      = {2015},
}

@InProceedings{chen2013robust,
  author    = {Chen, Zhuoyuan and Wu, Ying},
  title     = {Robust dictionary learning by error source decomposition},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
  year      = {2013},
  pages     = {2216--2223},
}

@InProceedings{wang2013semi,
  author    = {Wang, Hua and Nie, Feiping and Cai, Weidong and Huang, Heng},
  title     = {Semi-supervised robust dictionary learning via efficient l-norms minimization},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
  year      = {2013},
  pages     = {1145--1152},
}

@Article{mukherjee2016ℓ1,
  author    = {Mukherjee, Subhadip and Basu, Rupam and Seelamantula, Chandra Sekhar},
  title     = {ℓ1-K-SVD: A robust dictionary learning algorithm with simultaneous update},
  journal   = {Signal Processing},
  year      = {2016},
  volume    = {123},
  pages     = {42--52},
  publisher = {Elsevier},
}

@Article{8031891,
  author   = {T. {Zhou} and F. {Liu} and H. {Bhaskar} and J. {Yang}},
  title    = {Robust Visual Tracking via Online Discriminative and Low-Rank Dictionary Learning},
  journal  = {IEEE Transactions on Cybernetics},
  year     = {2018},
  volume   = {48},
  number   = {9},
  pages    = {2643-2655},
  month    = {Sep.},
  doi      = {10.1109/TCYB.2017.2747998},
  keywords = {image classification;image representation;learning (artificial intelligence);matrix algebra;maximum likelihood estimation;object tracking;vectors;robust visual tracking;low-rank dictionary learning;low-rank matrices;active learning;discriminative dictionary;robust dictionary;online discriminative dictionary learning;vectors;reconstruction error;multiconstraint objective function;classifier parameters;likelihood function;online update criterion;Target tracking;Dictionaries;Robustness;Machine learning;Visualization;Sparse matrices;Encoding;Dictionary learning;likelihood function;low-rank;visual tracking},
}

@InProceedings{rdlhskf,
  author    = {Awate, Suyash P. and Koushik, Nishanth N.},
  title     = {Robust Dictionary Learning on the Hilbert Sphere in Kernel Feature Space},
  booktitle = {Machine Learning and Knowledge Discovery in Databases},
  year      = {2016},
  editor    = {Frasconi, Paolo and Landwehr, Niels and Manco, Giuseppe and Vreeken, Jilles},
  pages     = {731--748},
  address   = {Cham},
  publisher = {Springer International Publishing},
  isbn      = {978-3-319-46128-1},
}

@InProceedings{quan2016equiangular,
  author    = {Quan, Yuhui and Bao, Chenglong and Ji, Hui},
  title     = {Equiangular kernel dictionary learning with applications to dynamic texture analysis},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {308--316},
}

@InProceedings{7299018,
  author    = {M. {Harandi} and M. {Salzmann}},
  title     = {Riemannian coding and dictionary learning: Kernels to the rescue},
  booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2015},
  pages     = {3926-3935},
  month     = {June},
  doi       = {10.1109/CVPR.2015.7299018},
  keywords  = {image coding;optimisation;unsupervised learning;sparse coding;nonflat Riemannian manifolds;optimization problems;Riemannian coding;kernel-based counterpart;unsupervised dictionary learning;supervised dictionary learning;Euclidean spaces;Encoding;Dictionaries;Kernel;Manifolds;Training;Hilbert space;Optimization},
}

@InProceedings{liu2015robust,
  author    = {Liu, Huaping and Qin, Jie and Cheng, Hong and Sun, Fuchun},
  title     = {Robust kernel dictionary learning using a whole sequence convergent algorithm},
  booktitle = {Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year      = {2015},
}

@Article{van2013design,
  author    = {Van Nguyen, Hien and Patel, Vishal M and Nasrabadi, Nasser M and Chellappa, Rama},
  title     = {Design of non-linear kernel dictionaries for object recognition},
  journal   = {IEEE Transactions on Image Processing},
  year      = {2013},
  volume    = {22},
  number    = {12},
  pages     = {5123--5135},
  publisher = {IEEE},
}

@InProceedings{fan2019online,
  author    = {Fan, Jicong and Udell, Madeleine},
  title     = {Online high rank matrix completion},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2019},
  pages     = {8690--8698},
}

@Article{Kuang-Chih2005,
  author  = {Kuang-Chih, Lee and Ho, J. and Kriegman, D. J.},
  title   = {Acquiring linear subspaces for face recognition under variable lighting},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2005},
  volume  = {27},
  number  = {5},
  pages   = {684-698},
  issn    = {0162-8828},
  type    = {Journal Article},
}

@Article{coil100,
  author    = {Nene, Sameer A and Nayar, Shree K and Murase, Hiroshi},
  title     = {Columbia object image library (COIL-100)},
  year      = {1996},
  publisher = {Technical report CUCS-006-96},
}

@Article{coil20,
  author    = {Nene, Sameer A and Nayar, Shree K and Murase, Hiroshi and others},
  title     = {Columbia object image library (COIL-20)},
  year      = {1996},
  publisher = {Technical report CUCS-005-96},
}

@Article{ARfacedata,
  author    = {Mart{\'\i}nez, Aleix M and Kak, Avinash C},
  title     = {{PCA} versus {LDA}},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2001},
  volume    = {23},
  number    = {2},
  pages     = {228--233},
  publisher = {IEEE},
}

@InProceedings{srebro2005maximum,
  author    = {Srebro, Nathan and Rennie, Jason and Jaakkola, Tommi S},
  title     = {Maximum-margin matrix factorization},
  booktitle = {Advances in neural information processing systems},
  year      = {2005},
  pages     = {1329--1336},
}

@Article{kwok2004pre,
  author    = {Kwok, JT-Y and Tsang, IW-H},
  title     = {The pre-image problem in kernel methods},
  journal   = {IEEE transactions on neural networks},
  year      = {2004},
  volume    = {15},
  number    = {6},
  pages     = {1517--1525},
  publisher = {IEEE},
}

@Article{fan2019exactly,
  author    = {Fan, Jicong and Chow, Tommy WS},
  title     = {Exactly Robust Kernel Principal Component Analysis},
  journal   = {IEEE transactions on neural networks and learning systems},
  year      = {2019},
  publisher = {IEEE},
}

@Article{vincent2010stacked,
  author  = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  title   = {Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion},
  journal = {Journal of machine learning research},
  year    = {2010},
  volume  = {11},
  number  = {Dec},
  pages   = {3371--3408},
}

@InProceedings{gao2017demand,
  author    = {Gao, Ruohan and Grauman, Kristen},
  title     = {On-demand learning for deep image restoration},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
  year      = {2017},
  pages     = {1086--1095},
}

@InProceedings{mao2016image,
  author    = {Mao, Xiaojiao and Shen, Chunhua and Yang, Yu-Bin},
  title     = {Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections},
  booktitle = {Advances in neural information processing systems},
  year      = {2016},
  pages     = {2802--2810},
}

@InProceedings{burger2012image,
  author       = {Burger, Harold C and Schuler, Christian J and Harmeling, Stefan},
  title        = {Image denoising: Can plain neural networks compete with BM3D?},
  booktitle    = {2012 IEEE conference on computer vision and pattern recognition},
  year         = {2012},
  pages        = {2392--2399},
  organization = {IEEE},
}

@article{udell2017why,
  title={Why are Big Data Matrices Approximately Low Rank?},
  author={Udell, Madeleine and Townsend, Alex},
  journal={SIAM Journal on Mathematics of Data Science (SIMODS)},
  volume={1},
  number={1},
  pages={144--160},
  year={2019},
  publisher={SIAM},
  year={2019},
  url={https://epubs.siam.org/doi/pdf/10.1137/18M1183480},
}

@Article{udell2019big,
  author    = {Udell, Madeleine and Townsend, Alex},
  title     = {Why Are Big Data Matrices Approximately Low Rank?},
  journal   = {SIAM Journal on Mathematics of Data Science},
  year      = {2019},
  volume    = {1},
  number    = {1},
  pages     = {144--160},
  publisher = {SIAM},
}

@Article{huang2009robust,
  author    = {Huang, Su-Yun and Yeh, Yi-Ren and Eguchi, Shinto},
  title     = {Robust kernel principal component analysis},
  journal   = {Neural computation},
  year      = {2009},
  volume    = {21},
  number    = {11},
  pages     = {3179--3213},
  publisher = {MIT Press},
}

@InProceedings{nguyen2009robust,
  author    = {Nguyen, Minh H and Torre, Fernando},
  title     = {Robust kernel principal component analysis},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2009},
  pages     = {1185--1192},
}

@Comment{jabref-meta: databaseType:bibtex;}
