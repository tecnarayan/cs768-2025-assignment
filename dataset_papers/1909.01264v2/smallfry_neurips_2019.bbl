\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andor et~al.(2016)Andor, Alberti, Weiss, Severyn, Presta, Ganchev,
  Petrov, and Collins]{collins16}
Daniel Andor, Chris Alberti, David Weiss, Aliaksei Severyn, Alessandro Presta,
  Kuzman Ganchev, Slav Petrov, and Michael Collins.
\newblock Globally normalized transition-based neural networks.
\newblock In \emph{{ACL}}, 2016.

\bibitem[Andrews(2016)]{andrews16}
Martin Andrews.
\newblock Compressing word embeddings.
\newblock In \emph{{ICONIP}}, 2016.

\bibitem[Avron et~al.(2017)Avron, Kapralov, Musco, Musco, Velingker, and
  Zandieh]{avron17}
Haim Avron, Michael Kapralov, Cameron Musco, Christopher Musco, Ameya
  Velingker, and Amir Zandieh.
\newblock Random {F}ourier features for kernel ridge regression: Approximation
  bounds and statistical guarantees.
\newblock In \emph{{ICML}}, 2017.

\bibitem[Bertoldi et~al.(2014)Bertoldi, Mathur, Ruiz, and
  Federico]{bertoldi2014fbk}
Nicola Bertoldi, Prashant Mathur, Nicholas Ruiz, and Marcello Federico.
\newblock {FBK}'s machine translation and speech translation systems for the
  {IWSLT} 2014 evaluation campaign.
\newblock In \emph{IWSLT}, 2014.

\bibitem[Chen et~al.(2017)Chen, Fisch, Weston, and Bordes]{drqa17}
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes.
\newblock Reading {Wikipedia} to answer open-domain questions.
\newblock In \emph{{ACL}}, 2017.

\bibitem[Chen et~al.(2018)Chen, Min, and Sun]{kway18}
Ting Chen, Martin~Renqiang Min, and Yizhou Sun.
\newblock Learning k-way d-dimensional discrete codes for compact embedding
  representations.
\newblock In \emph{{ICML}}, 2018.

\bibitem[{Dan Shiebler, Chris Green, Luca Belli, Abhishek
  Tayal}(2018)]{twitter18}
{Dan Shiebler, Chris Green, Luca Belli, Abhishek Tayal}.
\newblock Embeddings@{T}witter, 2018.
\newblock URL
  \url{https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html}.
\newblock [Online; published 13-Sept-2018; accessed 20-May-2019].

\bibitem[Davis and Kahan(1970)]{sintheta70}
C.~Davis and W.~Kahan.
\newblock The rotation of eigenvectors by a perturbation. iii.
\newblock \emph{SIAM Journal on Numerical Analysis}, 7\penalty0 (1):\penalty0
  1--46, 1970.

\bibitem[De~Sa et~al.(2018)De~Sa, Leszczynski, Zhang, Marzoev, Aberger,
  Olukotun, and R{\'e}]{de2018high}
Christopher De~Sa, Megan Leszczynski, Jian Zhang, Alana Marzoev, Christopher~R
  Aberger, Kunle Olukotun, and Christopher R{\'e}.
\newblock High-accuracy low-precision training.
\newblock \emph{arXiv preprint arXiv:1803.03383}, 2018.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{bert18}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Gersho(1977)]{quant77}
A.~Gersho.
\newblock Quantization.
\newblock \emph{IEEE Communications Society Magazine}, 15\penalty0
  (5):\penalty0 16--16, Sep. 1977.

\bibitem[Grover and Leskovec(2016)]{grover16}
Aditya Grover and Jure Leskovec.
\newblock node2vec: Scalable feature learning for networks.
\newblock In \emph{{KDD}}, 2016.

\bibitem[Gupta et~al.(2015)Gupta, Agrawal, Gopalakrishnan, and
  Narayanan]{gupta15}
Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan.
\newblock Deep learning with limited numerical precision.
\newblock In \emph{ICML}, 2015.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{han2015deep}
Song Han, Huizi Mao, and William~J. Dally.
\newblock Deep compression: Compressing deep neural network with pruning,
  trained quantization and {H}uffman coding.
\newblock In \emph{{ICLR}}, 2016.

\bibitem[Hotelling(1933)]{pca33}
Harold Hotelling.
\newblock Analysis of a complex of statistical variables into principal
  components.
\newblock \emph{Journal of educational psychology}, 24\penalty0 (6):\penalty0
  417, 1933.

\bibitem[Khrulkov et~al.(2019)Khrulkov, Hrinchuk, Mirvakhabova, and
  Oseledets]{tensor19}
Valentin Khrulkov, Oleksii Hrinchuk, Leyla Mirvakhabova, and Ivan~V. Oseledets.
\newblock Tensorized embedding layers for efficient model compression.
\newblock \emph{arXiv preprint arXiv:1901.10787}, 2019.

\bibitem[Kiefer(1953)]{golden53}
J.~Kiefer.
\newblock Sequential minimax search for a maximum.
\newblock \emph{Proceedings of the American Mathematical Society}, 4:\penalty0
  502--506, 1953.

\bibitem[Kim(2014)]{kim14}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock In \emph{{EMNLP}}, 2014.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Levy and Goldberg(2014)]{levy2014neural}
Omer Levy and Yoav Goldberg.
\newblock Neural word embedding as implicit matrix factorization.
\newblock In \emph{{NeurIPS}}, 2014.

\bibitem[Micikevicius et~al.(2018)Micikevicius, Narang, Alben, Diamos, Elsen,
  Garc{\'i}a, Ginsburg, Houston, Kuchaiev, Venkatesh, and
  Wu]{Micikevicius2018MixedPT}
Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory~Frederick Diamos,
  Erich Elsen, David Garc{\'i}a, Boris Ginsburg, Michael Houston, Oleksii
  Kuchaiev, Ganesh Venkatesh, and Hao Wu.
\newblock Mixed precision training.
\newblock In \emph{ICLR}, 2018.

\bibitem[Mikolov et~al.(2013)Mikolov, Chen, Corrado, and Dean]{word2vec13}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space.
\newblock \emph{arXiv preprint arXiv:1301.3781}, 2013.

\bibitem[Mikolov et~al.(2018)Mikolov, Grave, Bojanowski, Puhrsch, and
  Joulin]{fasttext18}
Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and Armand
  Joulin.
\newblock Advances in pre-training distributed word representations.
\newblock In \emph{LREC}, 2018.

\bibitem[Mostafa and Wang(2019)]{mostafa19}
Hesham Mostafa and Xin Wang.
\newblock Parameter efficient training of deep convolutional neural networks by
  dynamic sparse reparameterization.
\newblock In \emph{ICML}, 2019.

\bibitem[Ott et~al.(2019)Ott, Edunov, Baevski, Fan, Gross, Ng, Grangier, and
  Auli]{ott2019fairseq}
Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng,
  David Grangier, and Michael Auli.
\newblock fairseq: A fast, extensible toolkit for sequence modeling.
\newblock In \emph{NAACL-HLT: Demonstrations}, 2019.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in {PyTorch}.
\newblock In \emph{NeurIPS Autodiff Workshop}, 2017.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and Manning]{glove14}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock {GloVe}: Global vectors for word representation.
\newblock In \emph{{EMNLP}}, 2014.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{elmo18}
Matthew~E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock In \emph{{NAACL-HLT}}, 2018.

\bibitem[Popoviciu(1935)]{popoviciu1935equations}
Tiberiu Popoviciu.
\newblock Sur les {\'e}quations alg{\'e}briques ayant toutes leurs racines
  r{\'e}elles.
\newblock \emph{Mathematica}, 9:\penalty0 129--145, 1935.

\bibitem[Rahimi and Recht(2007)]{rahimi07random}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{{NeurIPS}}, 2007.

\bibitem[Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and Liang]{squad16}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.
\newblock {SQuAD}: 100,000+ questions for machine comprehension of text.
\newblock In \emph{{EMNLP}}, 2016.

\bibitem[Shu and Nakayama(2018)]{dccl17}
Raphael Shu and Hideki Nakayama.
\newblock Compressing word embeddings via deep compositional code learning.
\newblock In \emph{ICLR}, 2018.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher13}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew~Y. Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{{EMNLP}}, 2013.

\bibitem[Sohoni et~al.(2019)Sohoni, Aberger, Leszczynski, Zhang, and
  R{\'e}]{Sohoni2019LowMemoryNN}
Nimit~Sharad Sohoni, Christopher~Richard Aberger, Megan Leszczynski, Jian
  Zhang, and Christopher R{\'e}.
\newblock Low-memory neural network training: A technical report.
\newblock \emph{arXiv preprint arXiv:1904.10631}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Wang et~al.(2019)Wang, Singh, Michael, Hill, Levy, and Bowman]{glue19}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman.
\newblock {GLUE}: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock In \emph{ICLR}, 2019.

\bibitem[Williams and Seeger(2000)]{nystrom}
Christopher K.~I. Williams and Matthias~W. Seeger.
\newblock Using the {N}ystr{\"{o}}m method to speed up kernel machines.
\newblock In \emph{{NeurIPS}}, 2000.

\bibitem[Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, Macherey, Krikun, Cao,
  Gao, Macherey, et~al.]{wu2016google}
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc~V Le, Mohammad Norouzi, Wolfgang
  Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et~al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock \emph{arXiv preprint arXiv:1609.08144}, 2016.

\bibitem[Yin and Shen(2018)]{yin18}
Zi~Yin and Yuanyuan Shen.
\newblock On the dimensionality of word embedding.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Zhang et~al.(2019)Zhang, May, Dao, and R{\'{e}}]{lprff18}
Jian Zhang, Avner May, Tri Dao, and Christopher R{\'{e}}.
\newblock Low-precision random {F}ourier features for memory-constrained kernel
  approximation.
\newblock In \emph{{AISTATS}}, 2019.

\end{thebibliography}
