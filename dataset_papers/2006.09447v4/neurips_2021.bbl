\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Albrecht and Stone(2017)]{as2017aamas}
Stefano~V. Albrecht and Peter Stone.
\newblock Reasoning about hypothetical agent behaviours and their parameters.
\newblock In \emph{International Conference on Autonomous Agents and
  Multi-Agent Systems}, 2017.

\bibitem[Albrecht and Stone(2018)]{albrecht2018autonomous}
Stefano~V Albrecht and Peter Stone.
\newblock Autonomous agents modelling other agents: A comprehensive survey and
  open problems.
\newblock \emph{Artificial Intelligence}, pages 66--95, 2018.

\bibitem[Bard et~al.(2013)Bard, Johanson, Burch, and Bowling]{bard2013online}
Nolan Bard, Michael Johanson, Neil Burch, and Michael Bowling.
\newblock Online implicit agent modelling.
\newblock In \emph{International Conference on Autonomous Agents and
  Multi-Agent Systems}, 2013.

\bibitem[B{\"o}hmer et~al.(2020)B{\"o}hmer, Kurin, and
  Whiteson]{bohmer2020deep}
Wendelin B{\"o}hmer, Vitaly Kurin, and Shimon Whiteson.
\newblock Deep coordination graphs.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International Conference on Machine Learning},
  2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2020{\natexlab{b}}.

\bibitem[Chung et~al.(2015)Chung, Kastner, Dinh, Goel, Courville, and
  Bengio]{chung2015recurrent}
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron Courville, and
  Yoshua Bengio.
\newblock A recurrent latent variable model for sequential data.
\newblock \emph{arXiv preprint arXiv:1506.02216}, 2015.

\bibitem[Corneil et~al.(2018)Corneil, Gerstner, and Brea]{corneil2018efficient}
Dane Corneil, Wulfram Gerstner, and Johanni Brea.
\newblock Efficient model-based deep reinforcement learning with variational
  state tabulation.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Doshi-Velez and Konidaris(2016)]{doshi2016hidden}
Finale Doshi-Velez and George Konidaris.
\newblock Hidden parameter markov decision processes: A semiparametric
  regression approach for discovering latent task parametrizations.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2016.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{duan2016rl}
Yan Duan, John Schulman, Xi~Chen, Peter~L Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Rl $^2$: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018counterfactual}
Jakob~N Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Ganzfried and Sandholm(2011)]{ganzfried2011game}
Sam Ganzfried and Tuomas Sandholm.
\newblock Game theory-based opponent modeling in large imperfect-information
  games.
\newblock In \emph{International Conference on Autonomous Agents and Multiagent
  Systems}, 2011.

\bibitem[Ganzfried and Sandholm(2015)]{ganzfried2015safe}
Sam Ganzfried and Tuomas Sandholm.
\newblock Safe opponent exploitation.
\newblock \emph{ACM Transactions on Economics and Computation}, pages 1--28,
  2015.

\bibitem[Gelada et~al.(2019)Gelada, Kumar, Buckman, Nachum, and
  Bellemare]{gelada2019deepmdp}
Carles Gelada, Saurabh Kumar, Jacob Buckman, Ofir Nachum, and Marc~G Bellemare.
\newblock Deepmdp: Learning continuous latent space models for representation
  learning.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Gmytrasiewicz and Doshi(2005)]{gmytrasiewicz2005framework}
Piotr~J Gmytrasiewicz and Prashant Doshi.
\newblock A framework for sequential planning in multi-agent settings.
\newblock \emph{Journal of Artificial Intelligence Research}, pages 49--79,
  2005.

\bibitem[Gregor et~al.(2019)Gregor, Papamakarios, Besse, Buesing, and
  Weber]{gregor2019temporal}
Karol Gregor, George Papamakarios, Frederic Besse, Lars Buesing, and Theophane
  Weber.
\newblock Temporal difference variational auto-encoder.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Gretton et~al.(2007)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{gretton2007kernel}
Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Sch{\"o}lkopf, and
  Alex~J Smola.
\newblock A kernel method for the two-sample-problem.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2007.

\bibitem[Grover et~al.(2018)Grover, Al-Shedivat, Gupta, Burda, and
  Edwards]{grover2018learning}
Aditya Grover, Maruan Al-Shedivat, Jayesh~K Gupta, Yura Burda, and Harrison
  Edwards.
\newblock Learning policy representations in multiagent systems.
\newblock In \emph{International Conference on Machine learning}, 2018.

\bibitem[Ha and Schmidhuber(2018)]{ha2018world}
David Ha and J{\"u}rgen Schmidhuber.
\newblock Recurrent world models facilitate policy evolution.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Norouzi, and
  Ba]{hafner2020mastering}
Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, and Jimmy Ba.
\newblock Mastering atari with discrete world models.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Hansen et~al.(2004)Hansen, Bernstein, and
  Zilberstein]{hansen2004dynamic}
Eric~A Hansen, Daniel~S Bernstein, and Shlomo Zilberstein.
\newblock Dynamic programming for partially observable stochastic games.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2004.

\bibitem[Hausman et~al.(2018)Hausman, Springenberg, Wang, Heess, and
  Riedmiller]{hausman2018learning}
Karol Hausman, Jost~Tobias Springenberg, Ziyu Wang, Nicolas Heess, and Martin
  Riedmiller.
\newblock Learning an embedding space for transferable robot skills.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[He et~al.(2016)He, Boyd-Graber, Kwok, and
  Daum{\'e}~III]{he2016opponent}
He~He, Jordan Boyd-Graber, Kevin Kwok, and Hal Daum{\'e}~III.
\newblock Opponent modeling in deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  2020.

\bibitem[Hernandez-Leal et~al.(2017)Hernandez-Leal, Kaisers, Baarslag, and
  de~Cote]{hernandez2017survey}
Pablo Hernandez-Leal, Michael Kaisers, Tim Baarslag, and Enrique~Munoz de~Cote.
\newblock A survey of learning in multiagent environments: Dealing with
  non-stationarity.
\newblock \emph{arXiv preprint arXiv:1707.09183}, 2017.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2017beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Igl et~al.(2018)Igl, Zintgraf, Le, Wood, and Whiteson]{igl2018deep}
Maximilian Igl, Luisa Zintgraf, Tuan~Anh Le, Frank Wood, and Shimon Whiteson.
\newblock Deep variational reinforcement learning for {POMDPs}.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Jaques et~al.(2019)Jaques, Lazaridou, Hughes, Gulcehre, Ortega,
  Strouse, Leibo, and De~Freitas]{jaques2018social}
Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre, Pedro~A
  Ortega, DJ~Strouse, Joel~Z Leibo, and Nando De~Freitas.
\newblock Social influence as intrinsic motivation for multi-agent deep
  reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Johanson et~al.(2008)Johanson, Zinkevich, and
  Bowling]{johanson2008computing}
Michael Johanson, Martin Zinkevich, and Michael Bowling.
\newblock Computing robust counter-strategies.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2008.

\bibitem[Kingma and Ba(2015)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Kingma and Welling(2014)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kurutach et~al.(2018)Kurutach, Tamar, Yang, Russell, and
  Abbeel]{kurutach2018learning}
Thanard Kurutach, Aviv Tamar, Ge~Yang, Stuart Russell, and Pieter Abbeel.
\newblock Learning plannable representations with causal infogan.
\newblock \emph{arXiv preprint arXiv:1807.09341}, 2018.

\bibitem[Laskin et~al.(2020)Laskin, Srinivas, and Abbeel]{laskin2020curl}
Michael Laskin, Aravind Srinivas, and Pieter Abbeel.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Maas et~al.(2013)Maas, Hannun, and Ng]{maas2013rectifier}
Andrew~L Maas, Awni~Y Hannun, and Andrew~Y Ng.
\newblock Rectifier nonlinearities improve neural network acoustic models.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Mordatch and Abbeel(2017)]{mordatch2017emergence}
Igor Mordatch and Pieter Abbeel.
\newblock Emergence of grounded compositional language in multi-agent
  populations.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2017.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Papoudakis et~al.(2019)Papoudakis, Christianos, Rahman, and
  Albrecht]{papoudakis2019dealing}
Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, and Stefano~V
  Albrecht.
\newblock Dealing with non-stationarity in multi-agent deep reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1906.04737}, 2019.

\bibitem[Papoudakis et~al.(2021)Papoudakis, Christianos, Sch{\"a}fer, and
  Albrecht]{papoudakis2020comparative}
Georgios Papoudakis, Filippos Christianos, Lukas Sch{\"a}fer, and Stefano~V
  Albrecht.
\newblock Benchmarking multi-agent deep reinforcement learning algorithms in
  cooperative tasks.
\newblock In \emph{Advances in Neural Information Processing Systems Track on
  Datasets and Benchmarks}, 2021.

\bibitem[Rabinowitz et~al.(2018)Rabinowitz, Perbet, Song, Zhang, Eslami, and
  Botvinick]{rabinowitz2018machine}
Neil~C Rabinowitz, Frank Perbet, H~Francis Song, Chiyuan Zhang, SM~Eslami, and
  Matthew Botvinick.
\newblock Machine theory of mind.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Raileanu et~al.(2018)Raileanu, Denton, Szlam, and
  Fergus]{raileanu2018modeling}
Roberta Raileanu, Emily Denton, Arthur Szlam, and Rob Fergus.
\newblock Modeling others using oneself in multi-agent reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Quillen, Finn, and
  Levine]{rakelly2019efficient}
Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, and Sergey Levine.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, De~Witt, Farquhar, Foerster, and
  Whiteson]{rashid2018qmix}
Tabish Rashid, Mikayel Samvelyan, Christian~Schroeder De~Witt, Gregory
  Farquhar, Jakob Foerster, and Shimon Whiteson.
\newblock Qmix: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Schmidhuber and Hochreiter(1997)]{schmidhuber1997long}
J{\"u}rgen Schmidhuber and Sepp Hochreiter.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, pages 1735--1780, 1997.

\bibitem[Schulman et~al.(2015)Schulman, Moritz, Levine, Jordan, and
  Abbeel]{schulman2015high}
John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter
  Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock \emph{arXiv preprint arXiv:1506.02438}, 2015.

\bibitem[Shapley(1953)]{shapley1953stochastic}
Lloyd~S Shapley.
\newblock Stochastic games.
\newblock \emph{Proceedings of the National Academy of Sciences}, pages
  1095--1100, 1953.

\bibitem[Shoham et~al.(2007)Shoham, Powers, and Grenager]{shoham2007if}
Yoav Shoham, Rob Powers, and Trond Grenager.
\newblock If multi-agent learning is the answer, what is the question?
\newblock \emph{Artificial intelligence}, pages 365--377, 2007.

\bibitem[Stone et~al.(2010)Stone, Kaminka, Kraus, and Rosenschein]{skkr2010}
P.~Stone, G.A. Kaminka, S.~Kraus, and J.S. Rosenschein.
\newblock Ad hoc autonomous agent teams: collaboration without
  pre-coordination.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2010.

\bibitem[Sunehag et~al.(2018)Sunehag, Lever, Gruslys, Czarnecki, Zambaldi,
  Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, et~al.]{sunehag2017value}
Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech~Marian Czarnecki, Vinicius
  Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel~Z Leibo, Karl
  Tuyls, et~al.
\newblock Value-decomposition networks for cooperative multi-agent learning.
\newblock In \emph{International Conference on Autonomous Agents and
  Multi-Agent Systems}, 2018.

\bibitem[Tacchetti et~al.(2019)Tacchetti, Song, Mediano, Zambaldi, Rabinowitz,
  Graepel, Botvinick, and Battaglia]{tacchetti2018relational}
Andrea Tacchetti, H~Francis Song, Pedro~AM Mediano, Vinicius Zambaldi, Neil~C
  Rabinowitz, Thore Graepel, Matthew Botvinick, and Peter~W Battaglia.
\newblock Relational forward models for multi-agent learning.
\newblock \emph{International Conference on Learning Representations}, 2019.

\bibitem[Van~der Maaten and Hinton(2008)]{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of Machine Learning Research}, pages 2579--2605, 2008.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{wang2016learning}
Jane~X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel~Z Leibo,
  Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Xie et~al.(2020)Xie, Losey, Tolsma, Finn, and Sadigh]{xie2020learning}
Annie Xie, Dylan~P Losey, Ryan Tolsma, Chelsea Finn, and Dorsa Sadigh.
\newblock Learning latent representations to influence multi-agent interaction.
\newblock In \emph{Conference on Robot Learning}, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Satija, and Pineau]{zhang2018decoupling}
Amy Zhang, Harsh Satija, and Joelle Pineau.
\newblock Decoupling dynamics and reward for transfer learning.
\newblock \emph{arXiv preprint arXiv:1804.10689}, 2018.

\bibitem[Zhang et~al.(2020)Zhang, McAllister, Calandra, Gal, and
  Levine]{zhang2020learning}
Amy Zhang, Rowan McAllister, Roberto Calandra, Yarin Gal, and Sergey Levine.
\newblock Learning invariant representations for reinforcement learning without
  reconstruction.
\newblock \emph{arXiv preprint arXiv:2006.10742}, 2020.

\bibitem[Zhao et~al.(2017)Zhao, Song, and Ermon]{zhao2017infovae}
Shengjia Zhao, Jiaming Song, and Stefano Ermon.
\newblock Infovae: Information maximizing variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1706.02262}, 2017.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarlis, Igl, Schulze, Gal, Hofmann,
  and Whiteson]{zintgraf2019varibad}
Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin
  Gal, Katja Hofmann, and Shimon Whiteson.
\newblock Varibad: A very good method for bayes-adaptive deep rl via
  meta-learning.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Zintgraf et~al.(2021)Zintgraf, Devlin, Ciosek, Whiteson, and
  Hofmann]{zintgraf2021deep}
Luisa Zintgraf, Sam Devlin, Kamil Ciosek, Shimon Whiteson, and Katja Hofmann.
\newblock Deep interactive bayesian reinforcement learning via meta-learning.
\newblock In \emph{International Conference on Autonomous Agents and
  Multi-Agent Systems}, 2021.

\end{thebibliography}
