% Video Editing

%% Diffusion-based

@article{li2023video,
  title={A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for Zero-Shot Video Editing},
  author={Li, Maomao and Li, Yu and Yang, Tianyu and Liu, Yunfei and Yue, Dongxu and Lin, Zhihui and Xu, Dong},
  journal={arXiv preprint arXiv:2312.05856},
  year={2023}
}

@article{zhang2024fastvideoedit,
  title={FastVideoEdit: Leveraging Consistency Models for Efficient Text-to-Video Editing},
  author={Zhang, Youyuan and Ju, Xuan and Clark, James J},
  journal={arXiv preprint arXiv:2403.06269},
  year={2024}
}

@article{li2023vidtome,
  title={VidToMe: Video Token Merging for Zero-Shot Video Editing},
  author={Li, Xirui and Ma, Chao and Yang, Xiaokang and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2312.10656},
  year={2023}
}

@article{ma2023maskint,
  title={MaskINT: Video Editing via Interpolative Non-autoregressive Masked Transformers},
  author={Ma, Haoyu and Mahdizadehaghdam, Shahin and Wu, Bichen and Fan, Zhipeng and Gu, Yuchao and Zhao, Wenliang and Shapira, Lior and Xie, Xiaohui},
  journal={arXiv preprint arXiv:2312.12468},
  year={2023}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{zhang2023controlvideo,
  title={Controlvideo: Training-free controllable text-to-video generation},
  author={Zhang, Yabo and Wei, Yuxiang and Jiang, Dongsheng and Zhang, Xiaopeng and Zuo, Wangmeng and Tian, Qi},
  journal={arXiv preprint arXiv:2305.13077},
  year={2023}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

%% Flow & Atlas

@article{wang1994representing,
  title={Representing moving images with layers},
  author={Wang, John YA and Adelson, Edward H},
  journal={IEEE transactions on image processing},
  volume={3},
  number={5},
  pages={625--638},
  year={1994},
  publisher={IEEE}
}

@article{kasten2021layered,
  title={Layered neural atlases for consistent video editing},
  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={6},
  pages={1--12},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{ye2022deformable,
  title={Deformable sprites for unsupervised video decomposition},
  author={Ye, Vickie and Li, Zhengqi and Tucker, Richard and Kanazawa, Angjoo and Snavely, Noah},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2657--2666},
  year={2022}
}

@article{huang2023inve,
  title={Inve: Interactive neural video editing},
  author={Huang, Jiahui and Sigal, Leonid and Yi, Kwang Moo and Wang, Oliver and Lee, Joon-Young},
  journal={arXiv preprint arXiv:2307.07663},
  year={2023}
}

@article{ouyang2023codef,
  title={Codef: Content deformation fields for temporally consistent video processing},
  author={Ouyang, Hao and Wang, Qiuyu and Xiao, Yuxi and Bai, Qingyan and Zhang, Juntao and Zheng, Kecheng and Zhou, Xiaowei and Chen, Qifeng and Shen, Yujun},
  journal={arXiv preprint arXiv:2308.07926},
  year={2023}
}

@article{wang2023gendef,
  title={GenDeF: Learning Generative Deformation Field for Video Generation},
  author={Wang, Wen and Zheng, Kecheng and Wang, Qiuyu and Chen, Hao and Shi, Zifan and Yang, Ceyuan and Shen, Yujun and Shen, Chunhua},
  journal={arXiv preprint arXiv:2312.04561},
  year={2023}
}

@inproceedings{chan2023hashing,
  title={Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time},
  author={Chan, Cheng-Hung and Yuan, Cheng-Yang and Sun, Cheng and Chen, Hwann-Tzong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7743--7753},
  year={2023}
}

@article{lu2020layered,
  title={Layered neural rendering for retiming people in video},
  author={Lu, Erika and Cole, Forrester and Dekel, Tali and Xie, Weidi and Zisserman, Andrew and Salesin, David and Freeman, William T and Rubinstein, Michael},
  journal={arXiv preprint arXiv:2009.07833},
  year={2020}
}

% Tracking

@article{xiao2024spatialtracker,
  title={SpatialTracker: Tracking Any 2D Pixels in 3D Space},
  author={Xiao, Yuxi and Wang, Qianqian and Zhang, Shangzhan and Xue, Nan and Peng, Sida and Shen, Yujun and Zhou, Xiaowei},
  journal={arXiv preprint arXiv:2404.04319},
  year={2024}
}

@inproceedings{wang2023tracking,
  title={Tracking everything everywhere all at once},
  author={Wang, Qianqian and Chang, Yen-Yu and Cai, Ruojin and Li, Zhengqi and Hariharan, Bharath and Holynski, Aleksander and Snavely, Noah},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19795--19806},
  year={2023}
}

@article{karaev2023cotracker,
  title={Cotracker: It is better to track together},
  author={Karaev, Nikita and Rocco, Ignacio and Graham, Benjamin and Neverova, Natalia and Vedaldi, Andrea and Rupprecht, Christian},
  journal={arXiv preprint arXiv:2307.07635},
  year={2023}
}

@article{sand2008particle,
  title={Particle video: Long-range motion estimation using point trajectories},
  author={Sand, Peter and Teller, Seth},
  journal={International journal of computer vision},
  volume={80},
  pages={72--91},
  year={2008},
  publisher={Springer}
}

@inproceedings{harley2022particle,
  title={Particle video revisited: Tracking through occlusions using point trajectories},
  author={Harley, Adam W and Fang, Zhaoyuan and Fragkiadaki, Katerina},
  booktitle={European Conference on Computer Vision},
  pages={59--75},
  year={2022},
  organization={Springer}
}

@inproceedings{neoral2024mft,
  title={Mft: Long-term tracking of every pixel},
  author={Neoral, Michal and {\v{S}}er{\`y}ch, Jon{\'a}{\v{s}} and Matas, Ji{\v{r}}{\'\i}},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6837--6847},
  year={2024}
}

@article{doersch2022tap,
  title={Tap-vid: A benchmark for tracking any point in a video},
  author={Doersch, Carl and Gupta, Ankush and Markeeva, Larisa and Recasens, Adria and Smaira, Lucas and Aytar, Yusuf and Carreira, Joao and Zisserman, Andrew and Yang, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={13610--13626},
  year={2022}
}

@inproceedings{doersch2023tapir,
  title={Tapir: Tracking any point with per-frame initialization and temporal refinement},
  author={Doersch, Carl and Yang, Yi and Vecerik, Mel and Gokay, Dilara and Gupta, Ankush and Aytar, Yusuf and Carreira, Joao and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10061--10072},
  year={2023}
}

@article{jabri2020space,
  title={Space-time correspondence as a contrastive random walk},
  author={Jabri, Allan and Owens, Andrew and Efros, Alexei},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19545--19560},
  year={2020}
}

% Optical Flow

@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  pages={402--419},
  year={2020},
  organization={Springer}
}

@inproceedings{huang2022flowformer,
  title={Flowformer: A transformer architecture for optical flow},
  author={Huang, Zhaoyang and Shi, Xiaoyu and Zhang, Chao and Wang, Qiang and Cheung, Ka Chun and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  booktitle={European conference on computer vision},
  pages={668--685},
  year={2022},
  organization={Springer}
}

% NeRF

@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{horn1981determining,
  title={Determining optical flow},
  author={Horn, Berthold KP and Schunck, Brian G},
  journal={Artificial intelligence},
  volume={17},
  number={1-3},
  pages={185--203},
  year={1981},
  publisher={Elsevier}
}

% Gaussian Splatting

@article{kerbl20233d,
  title={3d gaussian splatting for real-time radiance field rendering},
  author={Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
  journal={ACM Transactions on Graphics},
  volume={42},
  number={4},
  pages={1--14},
  year={2023},
  publisher={ACM}
}

@inproceedings{luiten2023dynamic,
  title={Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis},
  author={Luiten, Jonathon and Kopanas, Georgios and Leibe, Bastian and Ramanan, Deva},
  booktitle={3DV},
  year={2024}
}

@article{yang2023deformable3dgs,
    title={Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction},
    author={Yang, Ziyi and Gao, Xinyu and Zhou, Wen and Jiao, Shaohui and Zhang, Yuqing and Jin, Xiaogang},
    journal={arXiv preprint arXiv:2309.13101},
    year={2023}
}

@article{wu20234dgaussians,
  title={4D Gaussian Splatting for Real-Time Dynamic Scene Rendering},
  author={Wu, Guanjun and Yi, Taoran and Fang, Jiemin and Xie, Lingxi and Zhang, Xiaopeng and Wei Wei and Liu, Wenyu and Tian, Qi and Wang Xinggang},
  journal={arXiv preprint arXiv:2310.08528},
  year={2023}
}

@inproceedings{Cao2023HexPlaneAF,
  title={HexPlane: A Fast Representation for Dynamic Scenes},
  author={Ang Cao and Justin Johnson},
  booktitle=CVPR,
  year={2023},
}

@article{yang2023gs4d,
  title={Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting},
  author={Yang, Zeyu and Yang, Hongye and Pan, Zijie and Zhu, Xiatian and Zhang, Li},
  journal={arXiv preprint arXiv 2310.10642},
  year={2023}
}

@article{sun20243dgstream,
  title={3dgstream: On-the-fly training of 3d gaussians for efficient streaming of photo-realistic free-viewpoint videos},
  author={Sun, Jiakai and Jiao, Han and Li, Guangyuan and Zhang, Zhanjie and Zhao, Lei and Xing, Wei},
  journal={arXiv preprint arXiv:2403.01444},
  year={2024}
}

@article{huang2023sc,
  title={SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes},
  author={Huang, Yi-Hua and Sun, Yang-Tian and Yang, Ziyi and Lyu, Xiaoyang and Cao, Yan-Pei and Qi, Xiaojuan},
  journal={arXiv preprint arXiv:2312.14937},
  year={2023}
}

% Light Field and Volumetric Video

@incollection{levoy2023light,
  title={Light field rendering},
  author={Levoy, Marc and Hanrahan, Pat},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={441--452},
  year={2023}
}

@inproceedings{peng2023representing,
  title={Representing volumetric videos as dynamic mlp maps},
  author={Peng, Sida and Yan, Yunzhi and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4252--4262},
  year={2023}
}

% Camera Pose Estimation

@inproceedings{schoenberger2016sfm,
    author={Sch\"{o}nberger, Johannes Lutz and Frahm, Jan-Michael},
    title={Structure-from-Motion Revisited},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016},
}

@inproceedings{schoenberger2016mvs,
    author={Sch\"{o}nberger, Johannes Lutz and Zheng, Enliang and Pollefeys, Marc and Frahm, Jan-Michael},
    title={Pixelwise View Selection for Unstructured Multi-View Stereo},
    booktitle={European Conference on Computer Vision (ECCV)},
    year={2016},
}

@article{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy V and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and HAZIZA, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@article{lin2023gaussian,
    author    = {Youtian Lin and Zuozhuo Dai and Siyu Zhu and Yao Yao},
    title     = {Gaussian-Flow: 4D Reconstruction with Dynamic 3D Gaussian Particle},
    journal   = {arXiv:2312.03431},
    year      = {2023},
}

% Dynamic NeRF

@article{park2021hypernerf,
  title={HyperNeRF: a higher-dimensional representation for topologically varying neural radiance fields},
  author={Park, Keunhong and Sinha, Utkarsh and Hedman, Peter and Barron, Jonathan T and Bouaziz, Sofien and Goldman, Dan B and Martin-Brualla, Ricardo and Seitz, Steven M},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={6},
  pages={1--12},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{yu2018ds,
  title={DS-SLAM: A semantic visual SLAM towards dynamic environments},
  author={Yu, Chao and Liu, Zuxin and Liu, Xin-Jun and Xie, Fugui and Yang, Yi and Wei, Qi and Fei, Qiao},
  booktitle={2018 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={1168--1174},
  year={2018},
  organization={IEEE}
}

@article{akhter2010trajectory,
  title={Trajectory space: A dual representation for nonrigid structure from motion},
  author={Akhter, Ijaz and Sheikh, Yaser and Khan, Sohaib and Kanade, Takeo},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={33},
  number={7},
  pages={1442--1456},
  year={2010},
  publisher={IEEE}
}

@article{wang2021neural,
  title={Neural trajectory fields for dynamic novel view synthesis},
  author={Wang, Chaoyang and Eckart, Ben and Lucey, Simon and Gallo, Orazio},
  journal={arXiv preprint arXiv:2105.05994},
  year={2021}
}

@inproceedings{li2023dynibar,
  title={Dynibar: Neural dynamic image-based rendering},
  author={Li, Zhengqi and Wang, Qianqian and Cole, Forrester and Tucker, Richard and Snavely, Noah},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4273--4284},
  year={2023}
}

@article{kratimenos2023dynmf,
  title={Dynmf: Neural motion factorization for real-time dynamic view synthesis with 3d gaussian splatting},
  author={Kratimenos, Agelos and Lei, Jiahui and Daniilidis, Kostas},
  journal={arXiv preprint arXiv:2312.00112},
  year={2023}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

% Bazier Curve and B spline

@article{orucc2003q,
  title={q-Bernstein polynomials and B{\'e}zier curves},
  author={Oru{\c{c}}, Halil and Phillips, George M},
  journal={Journal of Computational and Applied Mathematics},
  volume={151},
  number={1},
  pages={1--12},
  year={2003},
  publisher={Elsevier}
}

@incollection{gordon1974b,
  title={B-spline curves and surfaces},
  author={Gordon, William J and Riesenfeld, Richard F},
  booktitle={Computer aided geometric design},
  pages={95--126},
  year={1974},
  publisher={Elsevier}
}

% Depth Estimation

@article{yang2024depth,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  journal={arXiv preprint arXiv:2401.10891},
  year={2024}
}

@InProceedings{ke2023repurposing,
      title={Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation},
      author={Bingxin Ke and Anton Obukhov and Shengyu Huang and Nando Metzger and Rodrigo Caye Daudt and Konrad Schindler},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2024}
}

@article{xu2024diffusion,
  title={Diffusion Models Trained with Large Data Are Transferable Visual Models},
  author={Xu, Guangkai and Ge, Yongtao and Liu, Mingyu and Fan, Chengxiang and Xie, Kangyang and Zhao, Zhiyue and Chen, Hao and Shen, Chunhua},
  journal={arXiv preprint arXiv:2403.06090},
  year={2024}
}

@ARTICLE {Ranftl2022,
    author  = "Ren\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun",
    title   = "Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer",
    journal = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    year    = "2022",
    volume  = "44",
    number  = "3"
}

@article{luo2020consistent,
  title={Consistent video depth estimation},
  author={Luo, Xuan and Huang, Jia-Bin and Szeliski, Richard and Matzen, Kevin and Kopf, Johannes},
  journal={ACM Transactions on Graphics (ToG)},
  volume={39},
  number={4},
  pages={71--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

% ARAP

@inproceedings{sorkine2007rigid,
  title={As-rigid-as-possible surface modeling},
  author={Sorkine, Olga and Alexa, Marc},
  booktitle={Symposium on Geometry processing},
  volume={4},
  pages={109--116},
  year={2007},
  organization={Citeseer}
}

% Video processing

@book{bovik2010handbook,
  title={Handbook of image and video processing},
  author={Bovik, Alan C},
  year={2010},
  publisher={Academic press}
}

@book{wang2002video,
  title={Video processing and communications},
  author={Wang, Yao and Ostermann, J{\"o}rn and Zhang, Ya-Qin},
  volume={1},
  year={2002},
  publisher={Prentice hall Upper Saddle River, NJ}
}

% Dataset

@article{pont20172017,
  title={The 2017 davis challenge on video object segmentation},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}

% scaffold
@article{scaffoldgs,
  title     = {Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering},
  author    = {Lu, Tao and Mulin, Yu and Linning, Xu and Yuanbo, Xiangli and Limin, Wang and Dahua, Lin and Bo, Dai.},
  journal   = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024}
}
