\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Al-Mohy and Higham(2009)]{almohy2009new}
A.~H. Al-Mohy and N.~J. Higham.
\newblock {A New Scaling and Squaring Algorithm for the Matrix Exponential}.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 2009.

\bibitem[Aragam and Zhou(2015)]{aragam2015}
B.~Aragam and Q.~Zhou.
\newblock Concave penalized estimation of sparse {G}aussian {B}ayesian
  networks.
\newblock \emph{Journal of Machine Learning Research}, 16:\penalty0 2273--2328,
  2015.

\bibitem[Aragam et~al.(2016)Aragam, Amini, and Zhou]{aragam2016}
B.~Aragam, A.~A. Amini, and Q.~Zhou.
\newblock Learning directed acyclic graphs with penalized neighbourhood
  regression.
\newblock \emph{Submitted}, arXiv:1511.08963, 2016.

\bibitem[Banerjee et~al.(2008)Banerjee, El~Ghaoui, and
  d'Aspremont]{banerjee2008}
O.~Banerjee, L.~El~Ghaoui, and A.~d'Aspremont.
\newblock Model selection through sparse maximum likelihood estimation for
  multivariate {G}aussian or binary data.
\newblock \emph{Journal of Machine Learning Research}, 9:\penalty0 485--516,
  2008.

\bibitem[Barab{\'a}si and Albert(1999)]{barabasi1999}
A.-L. Barab{\'a}si and R.~Albert.
\newblock Emergence of scaling in random networks.
\newblock \emph{Science}, 286\penalty0 (5439):\penalty0 509--512, 1999.

\bibitem[Botev et~al.(2017)Botev, Ritter, and Barber]{botev2017}
A.~Botev, H.~Ritter, and D.~Barber.
\newblock Practical gauss-newton optimisation for deep learning.
\newblock \emph{arXiv preprint arXiv:1706.03662}, 2017.

\bibitem[Bottou et~al.(2016)Bottou, Curtis, and Nocedal]{bottou2016}
L.~Bottou, F.~E. Curtis, and J.~Nocedal.
\newblock Optimization methods for large-scale machine learning.
\newblock \emph{arXiv preprint arXiv:1606.04838}, 2016.

\bibitem[Bouckaert(1993)]{bouckaert1993}
R.~R. Bouckaert.
\newblock Probabilistic network construction using the minimum description
  length principle.
\newblock In \emph{European conference on symbolic and quantitative approaches
  to reasoning and uncertainty}, pages 41--48. Springer, 1993.

\bibitem[Bousquet and Bottou(2008)]{bousquet2008}
O.~Bousquet and L.~Bottou.
\newblock The tradeoffs of large scale learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  161--168, 2008.

\bibitem[Byrd et~al.(1995)Byrd, Lu, Nocedal, and Zhu]{byrd1995limited}
R.~H. Byrd, P.~Lu, J.~Nocedal, and C.~Zhu.
\newblock {A limited memory algorithm for bound constrained optimization}.
\newblock \emph{SIAM Journal on Scientific Computing}, 1995.

\bibitem[Chen et~al.(2016)Chen, Shen, Choi, and Darwiche]{chen2016bn}
E.~Y.-J. Chen, Y.~Shen, A.~Choi, and A.~Darwiche.
\newblock Learning bayesian networks with ancestral constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2325--2333, 2016.

\bibitem[Chickering(1996)]{chickering1996}
D.~M. Chickering.
\newblock Learning {B}ayesian networks is {NP}-complete.
\newblock In \emph{Learning from data}, pages 121--130. Springer, 1996.

\bibitem[Chickering(2003)]{chickering2003}
D.~M. Chickering.
\newblock Optimal structure identification with greedy search.
\newblock \emph{Journal of Machine Learning Research}, 3:\penalty0 507--554,
  2003.

\bibitem[Chickering and Heckerman(1997)]{chickering1997}
D.~M. Chickering and D.~Heckerman.
\newblock Efficient approximations for the marginal likelihood of {B}ayesian
  networks with hidden variables.
\newblock \emph{Machine Learning}, 29\penalty0 (2-3):\penalty0 181--212, 1997.

\bibitem[Chickering et~al.(2004)Chickering, Heckerman, and
  Meek]{chickering2004}
D.~M. Chickering, D.~Heckerman, and C.~Meek.
\newblock Large-sample learning of {B}ayesian networks is {NP}-hard.
\newblock \emph{Journal of Machine Learning Research}, 5:\penalty0 1287--1330,
  2004.

\bibitem[Cussens(2012)]{cussens2012}
J.~Cussens.
\newblock Bayesian network learning with cutting planes.
\newblock \emph{arXiv preprint arXiv:1202.3713}, 2012.

\bibitem[Cussens et~al.(2017)Cussens, Haws, and Studen{\`y}]{cussens2017}
J.~Cussens, D.~Haws, and M.~Studen{\`y}.
\newblock Polyhedral aspects of score equivalence in bayesian network structure
  learning.
\newblock \emph{Mathematical Programming}, 164\penalty0 (1-2):\penalty0
  285--324, 2017.

\bibitem[Ellis and Wong(2008)]{ellis2008}
B.~Ellis and W.~H. Wong.
\newblock Learning causal {B}ayesian network structures from experimental data.
\newblock \emph{Journal of the American Statistical Association}, 103\penalty0
  (482), 2008.

\bibitem[Friedman et~al.(2008)Friedman, Hastie, and Tibshirani]{friedman2008}
J.~Friedman, T.~Hastie, and R.~Tibshirani.
\newblock Sparse inverse covariance estimation with the {G}raphical {L}asso.
\newblock \emph{Biostatistics}, 9\penalty0 (3):\penalty0 432--441, 2008.

\bibitem[Fu and Zhou(2013)]{fu2013}
F.~Fu and Q.~Zhou.
\newblock Learning sparse causal {G}aussian networks with experimental
  intervention: {R}egularization and coordinate descent.
\newblock \emph{Journal of the American Statistical Association}, 108\penalty0
  (501):\penalty0 288--300, 2013.

\bibitem[G{\'a}mez et~al.(2011)G{\'a}mez, Mateo, and Puerta]{gamez2011}
J.~A. G{\'a}mez, J.~L. Mateo, and J.~M. Puerta.
\newblock Learning {B}ayesian networks by hill climbing: {E}fficient methods
  based on progressive restriction of the neighborhood.
\newblock \emph{Data Mining and Knowledge Discovery}, 22\penalty0
  (1-2):\penalty0 106--148, 2011.

\bibitem[Grant and Boyd(2014)]{cvx}
M.~Grant and S.~Boyd.
\newblock {CVX}: Matlab software for disciplined convex programming, version
  2.1.
\newblock \url{http://cvxr.com/cvx}, Mar. 2014.

\bibitem[Gu et~al.(2018)Gu, Fu, and Zhou]{gu2018}
J.~Gu, F.~Fu, and Q.~Zhou.
\newblock Penalized estimation of directed acyclic graphs from discrete data.
\newblock \emph{Statistics and Computing}, DOI: 10.1007/s11222-018-9801-y,
  2018.

\bibitem[Harary and Manvel(1971)]{harary1971number}
F.~Harary and B.~Manvel.
\newblock {On the number of cycles in a graph}.
\newblock \emph{Matematick{\`y} {\v{c}}asopis}, 1971.

\bibitem[Heckerman et~al.(1995)Heckerman, Geiger, and
  Chickering]{heckerman1995}
D.~Heckerman, D.~Geiger, and D.~M. Chickering.
\newblock Learning {B}ayesian networks: {T}he combination of knowledge and
  statistical data.
\newblock \emph{Machine learning}, 20\penalty0 (3):\penalty0 197--243, 1995.

\bibitem[Hsieh et~al.(2014)Hsieh, Sustik, Dhillon, and
  Ravikumar]{hsieh2014quic}
C.-J. Hsieh, M.~A. Sustik, I.~S. Dhillon, and P.~Ravikumar.
\newblock Quic: quadratic approximation for sparse inverse covariance
  estimation.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 2911--2947, 2014.

\bibitem[Kingma and Ba(2014)]{kingma2014}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Koller and Friedman(2009)]{koller2009}
D.~Koller and N.~Friedman.
\newblock \emph{Probabilistic graphical models: principles and techniques}.
\newblock MIT press, 2009.

\bibitem[Kuipers et~al.(2014)Kuipers, Moffa, and Heckerman]{kuipers2014}
J.~Kuipers, G.~Moffa, and D.~Heckerman.
\newblock Addendum on the scoring of gaussian directed acyclic graphical
  models.
\newblock \emph{The Annals of Statistics}, pages 1689--1691, 2014.

\bibitem[Loh and B{\"u}hlmann(2014)]{loh2014causal}
P.-L. Loh and P.~B{\"u}hlmann.
\newblock High-dimensional learning of linear causal networks via inverse
  covariance estimation.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 3065--3105,
  2014.

\bibitem[Nemirovski(1999)]{nemirovski1999optimization}
A.~Nemirovski.
\newblock {Optimization II: Standard Numerical Methods for Nonlinear Continuous
  Optimization}.
\newblock 1999.

\bibitem[Nesterov(2005)]{nesterov2005smooth}
Y.~Nesterov.
\newblock {Smooth minimization of non-smooth functions}.
\newblock \emph{Mathematical Programming}, 2005.

\bibitem[Niinim{\"a}ki et~al.(2016)Niinim{\"a}ki, Parviainen, and
  Koivisto]{niinimaki2016}
T.~Niinim{\"a}ki, P.~Parviainen, and M.~Koivisto.
\newblock Structure discovery in bayesian networks by sampling partial orders.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2002--2048, 2016.

\bibitem[Nocedal and Wright(2006)]{nocedal2006numerical}
J.~Nocedal and S.~J. Wright.
\newblock \emph{{Numerical Optimization}}.
\newblock 2006.

\bibitem[Ott and Miyano(2003)]{ott2003}
S.~Ott and S.~Miyano.
\newblock Finding optimal gene networks using biological constraints.
\newblock \emph{Genome Informatics}, 14:\penalty0 124--133, 2003.

\bibitem[Ramsey et~al.(2016)Ramsey, Glymour, Sanchez-Romero, and
  Glymour]{ramsey2016}
J.~Ramsey, M.~Glymour, R.~Sanchez-Romero, and C.~Glymour.
\newblock A million variables and more: the fast greedy equivalence search
  algorithm for learning high-dimensional graphical causal models, with an
  application to functional magnetic resonance images.
\newblock \emph{International Journal of Data Science and Analytics}, pages
  1--9, 2016.

\bibitem[Robinson(1977)]{robinson1977}
R.~W. Robinson.
\newblock Counting unlabeled acyclic digraphs.
\newblock In \emph{Combinatorial mathematics V}, pages 28--43. Springer, 1977.

\bibitem[Sachs et~al.(2005)Sachs, Perez, Pe'er, Lauffenburger, and
  Nolan]{sachs2005}
K.~Sachs, O.~Perez, D.~Pe'er, D.~A. Lauffenburger, and G.~P. Nolan.
\newblock Causal protein-signaling networks derived from multiparameter
  single-cell data.
\newblock \emph{Science}, 308\penalty0 (5721):\penalty0 523--529, 2005.

\bibitem[Scanagatta et~al.(2015)Scanagatta, de~Campos, Corani, and
  Zaffalon]{scanagatta2015}
M.~Scanagatta, C.~P. de~Campos, G.~Corani, and M.~Zaffalon.
\newblock Learning bayesian networks with thousands of variables.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1864--1872, 2015.

\bibitem[Scanagatta et~al.(2016)Scanagatta, Corani, de~Campos, and
  Zaffalon]{scanagatta2016}
M.~Scanagatta, G.~Corani, C.~P. de~Campos, and M.~Zaffalon.
\newblock Learning treewidth-bounded bayesian networks with thousands of
  variables.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1462--1470, 2016.

\bibitem[Schmidt et~al.(2007)Schmidt, Niculescu-Mizil, and Murphy]{schmidt2007}
M.~Schmidt, A.~Niculescu-Mizil, and K.~Murphy.
\newblock Learning graphical model structure using {L1}-regularization paths.
\newblock In \emph{AAAI}, volume~7, pages 1278--1283, 2007.

\bibitem[Schmidt et~al.(2009)Schmidt, Berg, Friedlander, and
  Murphy]{schmidt2009}
M.~Schmidt, E.~Berg, M.~Friedlander, and K.~Murphy.
\newblock Optimizing costly functions with simple constraints: A limited-memory
  projected quasi-newton algorithm.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 456--463,
  2009.

\bibitem[Shimizu et~al.(2006)Shimizu, Hoyer, Hyv{\"a}rinen, and
  Kerminen]{shimizu2006}
S.~Shimizu, P.~O. Hoyer, A.~Hyv{\"a}rinen, and A.~Kerminen.
\newblock A linear non-{G}aussian acyclic model for causal discovery.
\newblock \emph{Journal of Machine Learning Research}, 7:\penalty0 2003--2030,
  2006.

\bibitem[Silander and Myllymaki(2006)]{silander2012}
T.~Silander and P.~Myllymaki.
\newblock A simple approach for finding the globally optimal bayesian network
  structure.
\newblock In \emph{Proceedings of the 22nd Conference on Uncertainty in
  Artificial Intelligence}, 2006.

\bibitem[Singh and Moore(2005)]{singh2005}
A.~P. Singh and A.~W. Moore.
\newblock Finding optimal bayesian networks by dynamic programming.
\newblock 2005.

\bibitem[Spirtes and Glymour(1991)]{spirtes1991}
P.~Spirtes and C.~Glymour.
\newblock An algorithm for fast recovery of sparse causal graphs.
\newblock \emph{Social Science Computer Review}, 9\penalty0 (1):\penalty0
  62--72, 1991.

\bibitem[Spirtes et~al.(2000)Spirtes, Glymour, and Scheines]{spirtes2000}
P.~Spirtes, C.~Glymour, and R.~Scheines.
\newblock \emph{Causation, prediction, and search}, volume~81.
\newblock The MIT Press, 2000.

\bibitem[Taylor et~al.(2016)Taylor, Burmeister, Xu, Singh, Patel, and
  Goldstein]{taylor2016}
G.~Taylor, R.~Burmeister, Z.~Xu, B.~Singh, A.~Patel, and T.~Goldstein.
\newblock Training neural networks without gradients: A scalable admm approach.
\newblock In \emph{International Conference on Machine Learning}, pages
  2722--2731, 2016.

\bibitem[Teyssier and Koller(2005)]{teyssier2012}
M.~Teyssier and D.~Koller.
\newblock Ordering-based search: A simple and effective algorithm for learning
  bayesian networks.
\newblock In \emph{Uncertainty in Artifical Intelligence (UAI)}, 2005.

\bibitem[Tsamardinos et~al.(2006)Tsamardinos, Brown, and
  Aliferis]{tsamardinos2006}
I.~Tsamardinos, L.~E. Brown, and C.~F. Aliferis.
\newblock The max-min hill-climbing {B}ayesian network structure learning
  algorithm.
\newblock \emph{Machine Learning}, 65\penalty0 (1):\penalty0 31--78, 2006.

\bibitem[Van~Beek and Hoffmann(2015)]{van-beek2015}
P.~Van~Beek and H.-F. Hoffmann.
\newblock Machine learning of bayesian networks using constraint programming.
\newblock In \emph{International Conference on Principles and Practice of
  Constraint Programming}, pages 429--445. Springer, 2015.

\bibitem[van~de Geer and B{\"u}hlmann(2013)]{geer2013}
S.~van~de Geer and P.~B{\"u}hlmann.
\newblock $\ell_0$-penalized maximum likelihood for sparse directed acyclic
  graphs.
\newblock \emph{Annals of Statistics}, 41\penalty0 (2):\penalty0 536--567,
  2013.

\bibitem[Wang et~al.(2016)Wang, Dunson, and Leng]{wang2016}
X.~Wang, D.~Dunson, and C.~Leng.
\newblock No penalty no tears: Least squares in high-dimensional linear models.
\newblock In \emph{International Conference on Machine Learning}, pages
  1814--1822, 2016.

\bibitem[Watts and Strogatz(1998)]{watts1998}
D.~J. Watts and S.~H. Strogatz.
\newblock Collective dynamics of small-world networks.
\newblock \emph{nature}, 393\penalty0 (6684):\penalty0 440, 1998.

\bibitem[Xiang and Kim(2013)]{xiang2013}
J.~Xiang and S.~Kim.
\newblock A* {L}asso for learning a sparse {B}ayesian network structure for
  continuous variables.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2418--2426, 2013.

\bibitem[Yuan and Lin(2007)]{yuan2007}
M.~Yuan and Y.~Lin.
\newblock Model selection and estimation in the {G}aussian graphical model.
\newblock \emph{Biometrika}, 94\penalty0 (1):\penalty0 19--35, 2007.

\bibitem[Zhang et~al.(2013)Zhang, Gaiteri, Bodea, Wang, McElwee,
  Podtelezhnikov, Zhang, Xie, Tran, Dobrin, et~al.]{zhang2013}
B.~Zhang, C.~Gaiteri, L.-G. Bodea, Z.~Wang, J.~McElwee, A.~A. Podtelezhnikov,
  C.~Zhang, T.~Xie, L.~Tran, R.~Dobrin, et~al.
\newblock Integrated systems approach identifies genetic nodes and networks in
  late-onset alzheimer's disease.
\newblock \emph{Cell}, 153\penalty0 (3):\penalty0 707--720, 2013.

\bibitem[Zhong et~al.(2014)Zhong, Yen, Dhillon, and Ravikumar]{zhong2014}
K.~Zhong, I.~E.-H. Yen, I.~S. Dhillon, and P.~K. Ravikumar.
\newblock Proximal quasi-newton for computationally intensive l1-regularized
  m-estimators.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2375--2383, 2014.

\bibitem[Zhou(2011)]{zhou2011}
Q.~Zhou.
\newblock Multi-domain sampling with applications to structural inference of
  {B}ayesian networks.
\newblock \emph{Journal of the American Statistical Association}, 106\penalty0
  (496):\penalty0 1317--1330, 2011.

\bibitem[Zhou(2009)]{zhou2009}
S.~Zhou.
\newblock Thresholding procedures for high dimensional variable selection and
  statistical estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2304--2312, 2009.

\end{thebibliography}
