\begin{thebibliography}{10}

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.~770--778, 2016.

\bibitem{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang, A.~Karpathy, A.~Khosla, M.~Bernstein, {\em et~al.}, ``Imagenet large scale visual recognition challenge,'' {\em International journal of computer vision}, vol.~115, pp.~211--252, 2015.

\bibitem{cordts2016cityscapes}
M.~Cordts, M.~Omran, S.~Ramos, T.~Rehfeld, M.~Enzweiler, R.~Benenson, U.~Franke, S.~Roth, and B.~Schiele, ``The cityscapes dataset for semantic urban scene understanding,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.~3213--3223, 2016.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan, P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in context,'' in {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pp.~740--755, Springer, 2014.

\bibitem{hoiem2009pascal}
D.~Hoiem, S.~K. Divvala, and J.~H. Hays, ``Pascal voc 2008 challenge,'' {\em World Literature Today}, vol.~24, 2009.

\bibitem{liu2019large}
Z.~Liu, Z.~Miao, X.~Zhan, J.~Wang, B.~Gong, and S.~X. Yu, ``Large-scale long-tailed recognition in an open world,'' in {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.~2537--2546, 2019.

\bibitem{misra2017red}
I.~Misra, A.~Gupta, and M.~Hebert, ``From red wine to red tomato: Composition with context,'' in {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.~1792--1801, 2017.

\bibitem{sakaridis2018semantic}
C.~Sakaridis, D.~Dai, and L.~Van~Gool, ``Semantic foggy scene understanding with synthetic data,'' {\em International Journal of Computer Vision}, vol.~126, pp.~973--992, 2018.

\bibitem{peng2019moment}
X.~Peng, Q.~Bai, X.~Xia, Z.~Huang, K.~Saenko, and B.~Wang, ``Moment matching for multi-source domain adaptation,'' in {\em Proceedings of the IEEE/CVF international conference on computer vision}, pp.~1406--1415, 2019.

\bibitem{hendrycks2019benchmarking}
D.~Hendrycks and T.~Dietterich, ``Benchmarking neural network robustness to common corruptions and perturbations,'' {\em arXiv preprint arXiv:1903.12261}, 2019.

\bibitem{recht2019imagenet}
B.~Recht, R.~Roelofs, L.~Schmidt, and V.~Shankar, ``Do imagenet classifiers generalize to imagenet?,'' in {\em International conference on machine learning}, pp.~5389--5400, PMLR, 2019.

\bibitem{kattakinda2022invariant}
P.~Kattakinda, A.~Levine, and S.~Feizi, ``Invariant learning via diffusion dreamed distribution shifts,'' {\em arXiv preprint arXiv:2211.10370}, 2022.

\bibitem{koh2021wilds}
P.~W. Koh, S.~Sagawa, H.~Marklund, S.~M. Xie, M.~Zhang, A.~Balsubramani, W.~Hu, M.~Yasunaga, R.~L. Phillips, I.~Gao, {\em et~al.}, ``Wilds: A benchmark of in-the-wild distribution shifts,'' in {\em International Conference on Machine Learning}, pp.~5637--5664, PMLR, 2021.

\bibitem{pearl2009causality}
J.~Pearl, {\em Causality}.
\newblock Cambridge university press, 2009.

\bibitem{ramesh2021zero}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen, and I.~Sutskever, ``Zero-shot text-to-image generation,'' in {\em International Conference on Machine Learning}, pp.~8821--8831, PMLR, 2021.

\bibitem{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer, ``High-resolution image synthesis with latent diffusion models,'' in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~10684--10695, 2022.

\bibitem{kawar2022imagic}
B.~Kawar, S.~Zada, O.~Lang, O.~Tov, H.~Chang, T.~Dekel, I.~Mosseri, and M.~Irani, ``Imagic: Text-based real image editing with diffusion models,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, 2023.

\bibitem{brown2020language}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, {\em et~al.}, ``Language models are few-shot learners,'' {\em Advances in neural information processing systems}, vol.~33, pp.~1877--1901, 2020.

\bibitem{hertz2022prompt}
A.~Hertz, R.~Mokady, J.~Tenenbaum, K.~Aberman, Y.~Pritch, and D.~Cohen-Or, ``Prompt-to-prompt image editing with cross attention control,'' in {\em International Conference on Learning Representations}, 2022.

\bibitem{mokady2022null}
R.~Mokady, A.~Hertz, K.~Aberman, Y.~Pritch, and D.~Cohen-Or, ``Null-text inversion for editing real images using guided diffusion models,'' {\em arXiv preprint arXiv:2211.09794}, 2022.

\bibitem{li2023blip}
J.~Li, D.~Li, S.~Savarese, and S.~Hoi, ``Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,'' {\em arXiv preprint arXiv:2301.12597}, 2023.

\bibitem{ouyang2022training}
L.~Ouyang, J.~Wu, X.~Jiang, D.~Almeida, C.~Wainwright, P.~Mishkin, C.~Zhang, S.~Agarwal, K.~Slama, A.~Ray, {\em et~al.}, ``Training language models to follow instructions with human feedback,'' {\em Advances in Neural Information Processing Systems}, vol.~35, pp.~27730--27744, 2022.

\bibitem{wong2021leveraging}
E.~Wong, S.~Santurkar, and A.~Madry, ``Leveraging sparse linear layers for debuggable deep networks,'' in {\em Proceedings of the 38th International Conference on Machine Learning} (M.~Meila and T.~Zhang, eds.), vol.~139 of {\em Proceedings of Machine Learning Research}, pp.~11205--11216, PMLR, 18--24 Jul 2021.

\bibitem{singla2022salient}
S.~Singla and S.~Feizi, ``Salient imagenet: How to discover spurious features in deep learning?,'' in {\em International Conference on Learning Representations}, 2022.

\bibitem{li-2021-discover}
Z.~Li and C.~Xu, ``Discover the unknown biased attribute of an image classifier,'' in {\em The IEEE International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{singla2021understanding}
S.~Singla, B.~Nushi, S.~Shah, E.~Kamar, and E.~Horvitz, ``Understanding failures of deep networks via robust feature extraction,'' in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~12853--12862, 2021.

\bibitem{singla2022data}
S.~Singla, A.~M. Chegini, M.~Moayeri, and S.~Feiz, ``Data-centric debugging: mitigating model failures via targeted data collection,'' {\em arXiv preprint arXiv:2211.09859}, 2022.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark, {\em et~al.}, ``Learning transferable visual models from natural language supervision,'' in {\em International conference on machine learning}, pp.~8748--8763, PMLR, 2021.

\bibitem{eyubogludomino}
S.~Eyuboglu, M.~Varma, K.~K. Saab, J.-B. Delbrouck, C.~Lee-Messer, J.~Dunnmon, J.~Zou, and C.~Re, ``Domino: Discovering systematic errors with cross-modal embeddings,'' in {\em International Conference on Learning Representations}, 2022.

\bibitem{jain2022distilling}
S.~Jain, H.~Lawrence, A.~Moitra, and A.~Madry, ``Distilling model failures as directions in latent space,'' in {\em International Conference on Learning Representations}, 2023.

\bibitem{zhangdiagnosing}
Y.~Zhang, J.~Z. HaoChen, S.-C. Huang, K.-C. Wang, J.~Zou, and S.~Yeung, ``Diagnosing and rectifying vision models using language,'' in {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{geirhos2020shortcut}
R.~Geirhos, J.-H. Jacobsen, C.~Michaelis, R.~Zemel, W.~Brendel, M.~Bethge, and F.~A. Wichmann, ``Shortcut learning in deep neural networks,'' {\em Nature Machine Intelligence}, vol.~2, no.~11, pp.~665--673, 2020.

\bibitem{gatys2015neural}
L.~A. Gatys, A.~S. Ecker, and M.~Bethge, ``A neural algorithm of artistic style,'' {\em arXiv preprint arXiv:1508.06576}, 2015.

\bibitem{gatys2016image}
L.~A. Gatys, A.~S. Ecker, and M.~Bethge, ``Image style transfer using convolutional neural networks,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.~2414--2423, 2016.

\bibitem{karras2019style}
T.~Karras, S.~Laine, and T.~Aila, ``A style-based generator architecture for generative adversarial networks,'' in {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.~4401--4410, 2019.

\bibitem{abdal2019image2stylegan}
R.~Abdal, Y.~Qin, and P.~Wonka, ``Image2stylegan: How to embed images into the stylegan latent space?,'' in {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.~4432--4441, 2019.

\bibitem{abdal2020image2stylegan++}
R.~Abdal, Y.~Qin, and P.~Wonka, ``Image2stylegan++: How to edit the embedded images?,'' in {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.~8296--8305, 2020.

\bibitem{crowson2022vqgan}
K.~Crowson, S.~Biderman, D.~Kornis, D.~Stander, E.~Hallahan, L.~Castricato, and E.~Raff, ``Vqgan-clip: Open domain image generation and editing with natural language guidance,'' in {\em Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVII}, pp.~88--105, Springer, 2022.

\bibitem{nichol2022glide}
A.~Q. Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~Mcgrew, I.~Sutskever, and M.~Chen, ``Glide: Towards photorealistic image generation and editing with text-guided diffusion models,'' in {\em International Conference on Machine Learning}, pp.~16784--16804, PMLR, 2022.

\bibitem{dhariwal2021diffusion}
P.~Dhariwal and A.~Nichol, ``Diffusion models beat gans on image synthesis,'' {\em Advances in Neural Information Processing Systems}, vol.~34, pp.~8780--8794, 2021.

\bibitem{hertz2023delta}
A.~Hertz, K.~Aberman, and D.~Cohen-Or, ``Delta denoising score,'' {\em arXiv preprint arXiv:2304.07090}, 2023.

\bibitem{brooks2022instructpix2pix}
T.~Brooks, A.~Holynski, and A.~A. Efros, ``Instructpix2pix: Learning to follow image editing instructions,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, 2023.

\bibitem{haque2023instruct}
A.~Haque, M.~Tancik, A.~A. Efros, A.~Holynski, and A.~Kanazawa, ``Instruct-nerf2nerf: Editing 3d scenes with instructions,'' {\em arXiv preprint arXiv:2303.12789}, 2023.

\bibitem{sauercounterfactual}
A.~Sauer and A.~Geiger, ``Counterfactual generative networks,'' in {\em International Conference on Learning Representations}.

\bibitem{jeanneret2022diffusion}
G.~Jeanneret, L.~Simon, and F.~Jurie, ``Diffusion models for counterfactual explanations,'' in {\em Proceedings of the Asian Conference on Computer Vision}, pp.~858--876, 2022.

\bibitem{jeanneret2023adversarial}
G.~Jeanneret, L.~Simon, and F.~Jurie, ``Adversarial counterfactual visual explanations,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, 2023.

\bibitem{zemni2022octet}
M.~Zemni, M.~Chen, {\'E}.~Zablocki, H.~Ben-Younes, P.~P{\'e}rez, and M.~Cord, ``Octet: Object-aware counterfactual explanations,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, 2023.

\bibitem{luo2023zero}
J.~Luo, Z.~Wang, C.~H. Wu, D.~Huang, and F.~De~la Torre, ``Zero-shot model diagnosis,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, 2023.

\bibitem{li2023imagenet}
X.~Li, Y.~Chen, Y.~Zhu, S.~Wang, R.~Zhang, and H.~Xue, ``Imagenet-e: Benchmarking neural network robustness via attribute editing,'' in {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, 2023.

\bibitem{wiles2022discovering}
O.~Wiles, I.~Albuquerque, and S.~Gowal, ``Discovering bugs in vision models using off-the-shelf image generation and captioning,'' in {\em NeurIPS ML Safety Workshop}, 2022.

\bibitem{vendrow2023dataset}
J.~Vendrow, S.~Jain, L.~Engstrom, and A.~Madry, ``Dataset interfaces: Diagnosing model failures using controllable counterfactual generation,'' {\em arXiv preprint arXiv:2302.07865}, 2023.

\bibitem{dunlap2023diversify}
L.~Dunlap, A.~Umino, H.~Zhang, J.~Yang, J.~E. Gonzalez, and T.~Darrell, ``Diversify your vision datasets with automatic diffusion-based augmentation,'' {\em arXiv preprint arXiv:2305.16289}, 2023.

\bibitem{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix, B.~Rozi{\`e}re, N.~Goyal, E.~Hambro, F.~Azhar, {\em et~al.}, ``Llama: Open and efficient foundation language models,'' {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{hu2021lora}
E.~J. Hu, Y.~Shen, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, and W.~Chen, ``Lora: Low-rank adaptation of large language models,'' {\em arXiv preprint arXiv:2106.09685}, 2021.

\bibitem{reimers2019sentence}
N.~Reimers and I.~Gurevych, ``Sentence-bert: Sentence embeddings using siamese bert-networks,'' {\em arXiv preprint arXiv:1908.10084}, 2019.

\bibitem{Wallace_2023_ICCV}
B.~Wallace, A.~Gokul, S.~Ermon, and N.~Naik, ``End-to-end diffusion latent optimization improves classifier guidance,'' in {\em Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.~7280--7290, October 2023.

\bibitem{zhang2023adding}
L.~Zhang, A.~Rao, and M.~Agrawala, ``Adding conditional control to text-to-image diffusion models,'' in {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.~3836--3847, 2023.

\bibitem{wu2023latent}
C.~H. Wu and F.~De~la Torre, ``A latent space of stochastic diffusion models for zero-shot image editing and guidance,'' in {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.~7378--7387, 2023.

\bibitem{ho2022classifier}
J.~Ho and T.~Salimans, ``Classifier-free diffusion guidance,'' {\em arXiv preprint arXiv:2207.12598}, 2022.

\bibitem{song2020denoising}
J.~Song, C.~Meng, and S.~Ermon, ``Denoising diffusion implicit models,'' {\em arXiv preprint arXiv:2010.02502}, 2020.

\bibitem{gal2021stylegan}
R.~Gal, O.~Patashnik, H.~Maron, G.~Chechik, and D.~Cohen-Or, ``Stylegan-nada: Clip-guided domain adaptation of image generators,'' {\em arXiv preprint arXiv:2108.00946}, 2021.

\bibitem{moayeri2022hard}
M.~Moayeri, S.~Singla, and S.~Feizi, ``Hard imagenet: Segmentations for objects with strong spurious cues,'' in {\em Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2022.

\bibitem{heusel2017gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter, ``Gans trained by a two time-scale update rule converge to a local nash equilibrium,'' {\em Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{rw2019timm}
R.~Wightman, ``Pytorch image models.'' \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga, {\em et~al.}, ``Pytorch: An imperative style, high-performance deep learning library,'' {\em Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{Sanh2019DistilBERTAD}
V.~Sanh, L.~Debut, J.~Chaumond, and T.~Wolf, ``Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter,'' {\em ArXiv}, vol.~abs/1910.01108, 2019.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, {\em et~al.}, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{liu2022convnet}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie, ``A convnet for the 2020s,'' in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.~11976--11986, 2022.

\bibitem{zhang2023iti}
C.~Zhang, X.~Chen, S.~Chai, C.~H. Wu, D.~Lagun, T.~Beeler, and F.~De~la Torre, ``Iti-gen: Inclusive text-to-image generation,'' in {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.~3969--3980, 2023.

\bibitem{podell2023sdxl}
D.~Podell, Z.~English, K.~Lacey, A.~Blattmann, T.~Dockhorn, J.~M{\"u}ller, J.~Penna, and R.~Rombach, ``Sdxl: improving latent diffusion models for high-resolution image synthesis,'' {\em arXiv preprint arXiv:2307.01952}, 2023.

\end{thebibliography}
