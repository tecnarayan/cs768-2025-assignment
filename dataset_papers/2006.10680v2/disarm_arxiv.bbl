\begin{thebibliography}{}

\bibitem[Bengio et~al., 2013]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A. (2013).
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}.

\bibitem[Buesing et~al., 2016]{buesing2016stochastic}
Buesing, L., Weber, T., and Mohamed, S. (2016).
\newblock Stochastic gradient estimation with finite differences.
\newblock In {\em NIPS2016 Workshop on Advances in Approximate Inference}.

\bibitem[Burda et~al., 2016]{burda2016importance}
Burda, Y., Grosse, R., and Salakhutdinov, R. (2016).
\newblock Importance weighted autoencoders.
\newblock In {\em Proceedings of the 4th International Conference on Learning
  Representations}.

\bibitem[Fu, 2006]{fu2006gradient}
Fu, M.~C. (2006).
\newblock Gradient estimation.
\newblock {\em Handbooks in operations research and management science},
  13:575--616.

\bibitem[Glynn, 1990]{glynn1990likelihood}
Glynn, P.~W. (1990).
\newblock Likelihood ratio gradient estimation for stochastic systems.
\newblock {\em Communications of the ACM}, 33(10):75--84.

\bibitem[Grathwohl et~al., 2018]{grathwohl2018backpropagation}
Grathwohl, W., Choi, D., Wu, Y., Roeder, G., and Duvenaud, D. (2018).
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Gu et~al., 2016]{gu2015muprop}
Gu, S., Levine, S., Sutskever, I., and Mnih, A. (2016).
\newblock {Mu{P}rop}: Unbiased backpropagation for stochastic neural networks.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Jang et~al., 2017]{jang2017categorical}
Jang, E., Gu, S., and Poole, B. (2017).
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Jordan et~al., 1999]{jordan1999introduction}
Jordan, M.~I., Ghahramani, Z., Jaakkola, T.~S., and Saul, L.~K. (1999).
\newblock An introduction to variational methods for graphical models.
\newblock {\em Machine learning}, 37(2):183--233.

\bibitem[Kingma and Ba, 2015]{kingma2015adam}
Kingma, D. and Ba, J. (2015).
\newblock Adam: A method for stochastic optimization.
\newblock In {\em Proceedings of the 3rd International Conference on Learning
  Representations}.

\bibitem[Kingma and Welling, 2014]{kingma2014auto}
Kingma, D.~P. and Welling, M. (2014).
\newblock Auto-encoding variational bayes.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Kool et~al., 2019]{kool2019buy}
Kool, W., van Hoof, H., and Welling, M. (2019).
\newblock Buy 4 reinforce samples, get a baseline for free!
\newblock In {\em Deep RL Meets Structured Prediction ICLR Workshop}.

\bibitem[Maas et~al., 2013]{maas13relu}
Maas, A.~L., Hannun, A.~Y., and Ng, A.~Y. (2013).
\newblock Rectifier nonlinearities improve neural network acoustic models.
\newblock In {\em In ICML Workshop on Deep Learning for Audio, Speech and
  Language Processing}.

\bibitem[Maddison et~al., 2017]{maddison2017concrete}
Maddison, C.~J., Mnih, A., and Teh, Y.~W. (2017).
\newblock {The Concrete Distribution: A Continuous Relaxation of Discrete
  Random Variables}.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Mnih and Gregor, 2014]{mnih2014neural}
Mnih, A. and Gregor, K. (2014).
\newblock Neural variational inference and learning in belief networks.
\newblock In {\em Proceedings of The 31st International Conference on Machine
  Learning}, pages 1791--1799.

\bibitem[Mnih and Rezende, 2016]{mnih2016variational}
Mnih, A. and Rezende, D. (2016).
\newblock Variational inference for monte carlo objectives.
\newblock In {\em Proceedings of The 33rd International Conference on Machine
  Learning}, pages 2188--2196.

\bibitem[Owen, 2013]{mcbook}
Owen, A.~B. (2013).
\newblock {\em Monte Carlo theory, methods and examples}.

\bibitem[Paisley et~al., 2012]{paisley2012variational}
Paisley, J., Blei, D.~M., and Jordan, M.~I. (2012).
\newblock Variational bayesian inference with stochastic search.
\newblock In {\em Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 1363--1370.

\bibitem[Ranganath et~al., 2014]{ranganath2014black}
Ranganath, R., Gerrish, S., and Blei, D.~M. (2014).
\newblock Black box variational inference.
\newblock In {\em AISTATS}, pages 814--822.

\bibitem[Ren et~al., 2019]{ren19adaptive}
Ren, H., Zhao, S., and Ermon, S. (2019).
\newblock Adaptive antithetic sampling for variance reduction.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning}.

\bibitem[Rezende et~al., 2014]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D. (2014).
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In {\em Proceedings of The 31st International Conference on Machine
  Learning}, pages 1278--1286.

\bibitem[Titsias and L{\'a}zaro-Gredilla, 2015]{titsias2015local}
Titsias, M.~K. and L{\'a}zaro-Gredilla, M. (2015).
\newblock Local expectation gradients for black box variational inference.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2638--2646.

\bibitem[Tucker et~al., 2017]{tucker2017rebar}
Tucker, G., Mnih, A., Maddison, C.~J., Lawson, J., and Sohl-Dickstein, J.
  (2017).
\newblock {REBAR}: Low-variance, unbiased gradient estimates for discrete
  latent variable models.
\newblock In {\em Advances in Neural Information Processing Systems 30}.

\bibitem[Williams, 1992]{williams1992simple}
Williams, R.~J. (1992).
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock {\em Machine learning}, 8(3-4):229--256.

\bibitem[Wingate and Weber, 2013]{wingate2013automated}
Wingate, D. and Weber, T. (2013).
\newblock Automated variational inference in probabilistic programming.
\newblock {\em arXiv preprint arXiv:1301.1299}.

\bibitem[Wu et~al., 2019]{wu2019differentiable}
Wu, M., Goodman, N., and Ermon, S. (2019).
\newblock Differentiable antithetic sampling for variance reduction in
  stochastic variational inference.
\newblock In {\em AISTATS}.

\bibitem[{Yin} et~al., 2020]{yin2020probabilistic}
{Yin}, M., {Ho}, N., {Yan}, B., {Qian}, X., and {Zhou}, M. (2020).
\newblock {Probabilistic Best Subset Selection by Gradient-Based Optimization}.
\newblock {\em arXiv e-prints}.

\bibitem[Yin et~al., 2019]{yin2019arsm}
Yin, M., Yue, Y., and Zhou, M. (2019).
\newblock {ARSM}: Augment-{REINFORCE}-swap-merge estimator for gradient
  backpropagation through categorical variables.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning}.

\bibitem[Yin and Zhou, 2019]{yin2018arm}
Yin, M. and Zhou, M. (2019).
\newblock {ARM}: Augment-{REINFORCE}-merge gradient for stochastic binary
  networks.
\newblock In {\em International Conference on Learning Representations}.

\end{thebibliography}
