%%% Federated Learning Methods %%%
%% Background Materials
% async SGD
@inproceedings{async_sgd,
 author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc\textquotesingle aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc and Ng, Andrew},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Large Scale Distributed Deep Networks},

 volume = {25},
 year = {2012}
}
% Local SGD
@article{local_sgd_converges_fast,
  title={Local SGD converges fast and communicates little},
  author={Stich, Sebastian U},
  journal={arXiv preprint arXiv:1805.09767},
  year={2018}
}
% local_sgd
@inproceedings{local_sgd_better,
  title={Is local SGD better than minibatch SGD?},
  author={Woodworth, Blake and Patel, Kumar Kshitij and Stich, Sebastian and Dai, Zhen and Bullins, Brian and Mcmahan, Brendan and Shamir, Ohad and Srebro, Nathan},
  booktitle={International Conference on Machine Learning},
  pages={10334--10343},
  year={2020},
  organization={PMLR}
}
% fl_original1
@article{federated_learning,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}
% fl_original2
@article{federated_optimization,
  title={Federated optimization: Distributed machine learning for on-device intelligence},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Ramage, Daniel and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1610.02527},
  year={2016}
}
% FL survey1
@article{federatedML_concepts_applications,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--19},
  year={2019},
  publisher={ACM New York, NY, USA}
}
% FL survey2
@article{fl_survey_technologies_applications,
  title={Federated learning: A survey on enabling technologies, protocols, and applications},
  author={Aledhari, Mohammed and Razzak, Rehma and Parizi, Reza M and Saeed, Fahad},
  journal={IEEE Access},
  volume={8},
  pages={140699--140725},
  year={2020},
  publisher={IEEE}
}
% FL survey3
@article{advances_open_problems_fl,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}
% FL survey4
@article{fl_challenges_methods,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020},
  publisher={IEEE}
}
% fl_noniid_1
@article{On_the_convergence_fedavg_noniid,
  title={On the convergence of fedavg on non-iid data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  journal={arXiv preprint arXiv:1907.02189},
  year={2019}
}
% fl_noniid_2
@article{fl_with_noniid,
  title={Federated learning with non-iid data},
  author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
  journal={arXiv preprint arXiv:1806.00582},
  year={2018}
}
@inproceedings{tighter_local_sgd,
  title={Tighter theory for local SGD on identical and heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4519--4529},
  year={2020},
  organization={PMLR}
}
% Baseline
@inproceedings{FedAvg,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

%% Local-side
@article{FedProx,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine Learning and Systems},
  volume={2},
  pages={429--450},
  year={2020}
}
@article{FedNova,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={arXiv preprint arXiv:2007.07481},
  year={2020}
}
@inproceedings{SCAFFOLD,
  title={SCAFFOLD: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}
@inproceedings{
FedMix,
title={FedMix: Approximation of Mixup under Mean Augmented Federated Learning},
author={Tehrim Yoon and Sumin Shin and Sung Ju Hwang and Eunho Yang},
booktitle={International Conference on Learning Representations},
year={2021},
}
@article{FedAUX,
  title={FedAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning},
  author={Sattler, Felix and Korjakow, Tim and Rischke, Roman and Samek, Wojciech},
  journal={arXiv preprint arXiv:2102.02514},
  year={2021}
}
@article{FedGEN,
  title={Data-Free Knowledge Distillation for Heterogeneous Federated Learning},
  author={Zhu, Zhuangdi and Hong, Junyuan and Zhou, Jiayu},
  journal={arXiv preprint arXiv:2105.10056},
  year={2021}
}
@inproceedings{MOON,
  title={Model-Contrastive Federated Learning},
  author={Li, Qinbin and He, Bingsheng and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10713--10722},
  year={2021}
}
@article{FedDyn,
  title={Federated learning based on dynamic regularization},
  author={Acar, Durmus Alp Emre and Zhao, Yue and Navarro, Ramon Matas and Mattina, Matthew and Whatmough, Paul N and Saligrama, Venkatesh},
  journal={arXiv preprint arXiv:2111.04263},
  year={2021}
}
%% Server-side
@article{fed_ensemble_distill,
  title={Ensemble distillation for robust model fusion in federated learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:2006.07242},
  year={2020}
}
@article{FedAvgM,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}
@article{FedMA,
  title={Federated learning with matched averaging},
  author={Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  journal={arXiv preprint arXiv:2002.06440},
  year={2020}
}
@inproceedings{PFNM,
  title={Bayesian nonparametric federated learning of neural networks},
  author={Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Nghia and Khazaeni, Yasaman},
  booktitle={International Conference on Machine Learning},
  pages={7252--7261},
  year={2019},
  organization={PMLR}
}
@article{FedBE,
  title={Fedbe: Making bayesian model ensemble applicable to federated learning},
  author={Chen, Hong-You and Chao, Wei-Lun},
  journal={arXiv preprint arXiv:2009.01974},
  year={2020}
}
@article{FedMD,
  title={Fedmd: Heterogenous federated learning via model distillation},
  author={Li, Daliang and Wang, Junpu},
  journal={arXiv preprint arXiv:1910.03581},
  year={2019}
}
@article{distilled_one_shot,
  title={Distilled One-Shot Federated Learning},
  author={Zhou, Yanlin and Pu, George and Ma, Xiyao and Li, Xiaolin and Wu, Dapeng},
  journal={arXiv preprint arXiv:2009.07999},
  year={2020}
}

%% Others
@article{CCVR,
  title={No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data},
  author={Luo, Mi and Chen, Fei and Hu, Dapeng and Zhang, Yifan and Liang, Jian and Feng, Jiashi},
  journal={arXiv preprint arXiv:2106.05001},
  year={2021}
}
@inproceedings{Fed2,
  title={Fed2: Feature-Aligned Federated Learning},
  author={Yu, Fuxun and Zhang, Weishan and Qin, Zhuwei and Xu, Zirui and Wang, Di and Liu, Chenchen and Tian, Zhi and Chen, Xiang},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={2066--2074},
  year={2021}
}
@article{FedCurv,
  title={Overcoming forgetting in federated learning on non-iid data},
  author={Shoham, Neta and Avidor, Tomer and Keren, Aviv and Israel, Nadav and Benditkis, Daniel and Mor-Yosef, Liron and Zeitak, Itai},
  journal={arXiv preprint arXiv:1910.07796},
  year={2019}
}
%% Analysis
@article{FL_on_noniid_silos,
  title={Federated learning on non-iid data silos: An experimental study},
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  journal={arXiv preprint arXiv:2102.02079},
  year={2021}
}
@article{measuring_the_effects_of_noniid,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}
@inproceedings{pr_sgd,
  title={Parallel restarted sgd with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={5693--5700},
  year={2019}
}
%%% Continual Learning - (Task Incremental) %%%
% Background
% stability-plasticity
@article{stability-plasticity,
  title={The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects},
  author={Mermillod, Martial and Bugaiska, Aur{\'e}lia and Bonin, Patrick},
  journal={Frontiers in psychology},
  volume={4},
  pages={504},
  year={2013},
  publisher={Frontiers}
}
% cl_original1
@incollection{cl_original1,
  title={CHILD: A first step towards continual learning},
  author={Ring, Mark B},
  booktitle={Learning to learn},
  pages={261--292},
  year={1998},
  publisher={Springer}
}
% cl_original2
@incollection{cl_original2,
  title={Lifelong learning algorithms},
  author={Thrun, Sebastian},
  booktitle={Learning to learn},
  pages={181--209},
  year={1998},
  publisher={Springer}
}
% cl_forgetting1
@article{cl_forgetting1,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}
% cl_forgetting2
@incollection{cl_forgetting2,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}
% catastrophic forgetting
@article{catastrophic_forgetting,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}
% stability-plasticity
@article{sp_dilemma,
  title={The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects},
  author={Mermillod, Martial and Bugaiska, Aur{\'e}lia and Bonin, Patrick},
  journal={Frontiers in psychology},
  volume={4},
  pages={504},
  year={2013},
  publisher={Frontiers}
}
% cl_survey
@article{continual_learning_survey,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={Delange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Greg and Tuytelaars, Tinne},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}
% Parameter-based
@article{EWC,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}
@inproceedings{MAS,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={139--154},
  year={2018}
}
@article{cl_low_rank_orthogonal,
  title={Continual Learning in Low-rank Orthogonal Subspaces},
  author={Chaudhry, Arslan and Khan, Naeemullah and Dokania, Puneet K and Torr, Philip HS},
  journal={arXiv preprint arXiv:2010.11635},
  year={2020}
}
@inproceedings{RWalk,
  title={Riemannian walk for incremental learning: Understanding forgetting and intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={532--547},
  year={2018}
}
% Regularization-based
@article{LwF,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}
@article{CPR,
  title={CPR: Classifier-Projection Regularization for Continual Learning},
  author={Cha, Sungmin and Hsu, Hsiang and Hwang, Taebaek and Calmon, Flavio P and Moon, Taesup},
  journal={arXiv preprint arXiv:2006.07326},
  year={2020}
}
@inproceedings{OGD,
  title={Orthogonal gradient descent for continual learning},
  author={Farajtabar, Mehrdad and Azizan, Navid and Mott, Alex and Li, Ang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3762--3773},
  year={2020},
  organization={PMLR}
}

% Memory-based
@article{cl_hindsight,
  title={Using hindsight to anchor past knowledge in continual learning},
  author={Chaudhry, Arslan and Gordo, Albert and Dokania, Puneet Kumar and Torr, Philip and Lopez-Paz, David},
  journal={arXiv preprint arXiv:2002.08165},
  volume={2},
  number={7},
  year={2020}
}
@article{a-gem,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:1812.00420},
  year={2018}
}
%%% Continual Learning - (Class Incremental) %%%
@article{class_incremental_survey,
  title={Class-incremental learning: survey and performance evaluation on image classification},
  author={Masana, Marc and Liu, Xialei and Twardowski, Bartlomiej and Menta, Mikel and Bagdanov, Andrew D and van de Weijer, Joost},
  journal={arXiv preprint arXiv:2010.15277},
  year={2020}
}
@article{class_incremental_blurry_config,
  title={Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference},
  author={Koh, Hyunseo and Kim, Dahyun and Ha, Jung-Woo and Choi, Jonghyun},
  journal={arXiv preprint arXiv:2110.10031},
  year={2021}
}
@inproceedings{icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}
@inproceedings{unified_classifier,
  title={Learning a unified classifier incrementally via rebalancing},
  author={Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={831--839},
  year={2019}
}
%%%% Knowledge Distillation %%%%
@article{knowledge_distillation,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}@article{contrastiveKD,
  title={Contrastive representation distillation},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  journal={arXiv preprint arXiv:1910.10699},
  year={2019}
}
@inproceedings{bornagainKD,
  title={Born again neural networks},
  author={Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle={International Conference on Machine Learning},
  pages={1607--1616},
  year={2018},
  organization={PMLR}
}
@inproceedings{ontheflyKD,
  title={Knowledge distillation by on-the-fly native ensemble},
  author={Zhu, Xiatian and Gong, Shaogang and others},
  booktitle={Advances in neural information processing systems},
  pages={7517--7527},
  year={2018}
}
@inproceedings{giftKD,
  title={A gift from knowledge distillation: Fast optimization, network minimization and transfer learning},
  author={Yim, Junho and Joo, Donggyu and Bae, Jihoon and Kim, Junmo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4133--4141},
  year={2017}
}
@article{bias-varianceKD,
  title={Rethinking Soft Labels for Knowledge Distillation: A Bias-Variance Tradeoff Perspective},
  author={Zhou, Helong and Song, Liangchen and Chen, Jiajie and Zhou, Ye and Wang, Guoli and Yuan, Junsong and Zhang, Qian},
  journal={arXiv preprint arXiv:2102.00650},
  year={2021}
}
% Logits Matching
@article{kd_mse,
  title={Comparing Kullback-Leibler Divergence and Mean Squared Error Loss in Knowledge Distillation},
  author={Kim, Taehyeon and Oh, Jaehoon and Kim, NakYil and Cho, Sangwook and Yun, Se-Young},
  journal={arXiv preprint arXiv:2105.08919},
  year={2021}
}
@article{kd_survey,
  title={The state of knowledge distillation for classification},
  author={Ruffy, Fabian and Chahal, Karanbir},
  journal={arXiv preprint arXiv:1912.10850},
  year={2019}
}
@article{understanding_kd,
  title={Understanding and improving knowledge distillation},
  author={Tang, Jiaxi and Shivanna, Rakesh and Zhao, Zhe and Lin, Dong and Singh, Anima and Chi, Ed H and Jain, Sagar},
  journal={arXiv preprint arXiv:2002.03532},
  year={2020}
}
@article{kd_survey2,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}
%%% Misc
@article{cifar,
  title={Cifar-10 and cifar-100 datasets},
  author={Krizhevsky, Alex and Nair, Vinod and Hinton, Geoffrey},
  journal={URl: https://www. cs. toronto. edu/kriz/cifar. html},
  volume={6},
  year={2009}
}
@inproceedings{batch_norm,
  title={The Non-IID Data Quagmire of Decentralized Machine Learning},
  author={Kevin, Hsieh and Amar, Phanishayee and Onur, Mutlu and Phillip B., Gibbons},
  booktitle={Proceedings of the 37th International Conference on Machine Learning, Online, PMLR 119},
  year={2020}
}
@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}
@article{mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}
@article{cinic10,
  title={Cinic-10 is not imagenet or cifar-10},
  author={Darlow, Luke N and Crowley, Elliot J and Antoniou, Antreas and Storkey, Amos J},
  journal={arXiv preprint arXiv:1810.03505},
  year={2018}
}
@article{fedml,
  title={Fedml: A research library and benchmark for federated machine learning},
  author={He, Chaoyang and Li, Songze and So, Jinhyun and Zeng, Xiao and Zhang, Mi and Wang, Hongyi and Wang, Xiaoyang and Vepakomma, Praneeth and Singh, Abhishek and Qiu, Hang and others},
  journal={arXiv preprint arXiv:2007.13518},
  year={2020}
}
@article{cutout,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1708.04552},
  year={2017}
}

% Forgetting
@inproceedings{FedWeIT,
  title={Federated continual learning with weighted inter-client transfer},
  author={Yoon, Jaehong and Jeong, Wonyong and Lee, Giwoong and Yang, Eunho and Hwang, Sung Ju},
  booktitle={International Conference on Machine Learning},
  pages={12073--12086},
  year={2021},
  organization={PMLR}
}

@article{fed_class_incremental,
  title={Federated Class-Incremental Learning},
  author={Dong, Jiahua and Wang, Lixu and Fang, Zhen and Sun, Gan and Xu, Shichao and Wang, Xiao and Zhu, Qi},
  journal={arXiv preprint arXiv:2203.11473},
  year={2022}
}

@article{FedGKD,
  title={Local-Global Knowledge Distillation in Heterogeneous Federated Learning with Non-IID Data},
  author={Yao, Dezhong and Pan, Wanning and Dai, Yutong and Wan, Yao and Ding, Xiaofeng and Jin, Hai and Xu, Zheng and Sun, Lichao},
  journal={arXiv preprint arXiv:2107.00051},
  year={2021}
}
@article{FedReg,
  title={Acceleration of Federated Learning with Alleviated Forgetting in Local Training},
  author={Xu, Chencheng and Hong, Zhiwei and Huang, Minlie and Jiang, Tao},
  journal={arXiv preprint arXiv:2203.02645},
  year={2022}
}
@article{FedFTG,
  title={Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning},
  author={Zhang, Lin and Shen, Li and Ding, Liang and Tao, Dacheng and Duan, Ling-Yu},
  journal={arXiv preprint arXiv:2203.09249},
  year={2022}
}
@article{FedDC,
  title={FedDC: Federated Learning with Non-IID Data via Local Drift Decoupling and Correction},
  author={Gao, Liang and Fu, Huazhu and Li, Li and Chen, Yingwen and Xu, Ming and Xu, Cheng-Zhong},
  journal={arXiv preprint arXiv:2203.11751},
  year={2022}
}
@article{CLEVA,
  title={CLEVA-Compass: A Continual Learning EValuation Assessment Compass to Promote Research Transparency and Comparability},
  author={Mundt, Martin and Lang, Steven and Delfosse, Quentin and Kersting, Kristian},
  journal={arXiv preprint arXiv:2110.03331},
  year={2021}
}

@article{fl_survey_non_iid,
  title={Federated learning on non-IID data: A survey},
  author={Zhu, Hangyu and Xu, Jinjin and Liu, Shiqing and Jin, Yaochu},
  journal={Neurocomputing},
  volume={465},
  pages={371--390},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{FedAlign,
  title={Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning},
  author={Mendieta, Matias and Yang, Taojiannan and Wang, Pu and Lee, Minwoo and Ding, Zhengming and Chen, Chen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8397--8406},
  year={2022}
}