@string{aap = "Adv. Appl. Prob."}
@string{amstat = "Ann. Math. Statist."}
@string{amst="Amer. Math. Soc. Transl."}
@string{allerton="Proc. Annu. Allerton Conf. Communication, Control and Computing"}
@string{arc = "Automat. Remote Contr."}
@string{asilomar = "Proc. Asilomar Conf. Signals, Systems and Computers"}
@string{atttj = "AT\& T Tech. J."}
@string{automatica = "Automatica"}
@string{bstj = "Bell Syst. Tech. J."}
@string{ciss="Proc. Conf. on Information Sciences and Systems (CISS)"}
@string{el = "Electron. Lett."}
@string{ett = "European Trans. on Telecommunications"}
@string{iandc = "Inform. and Comput."}
@string{ibmjrd = "{IBM} J. Res. Dev."}
@string{ieeecommag = "IEEE Commun. Mag."}
@string{ieeejsac = "IEEE J. Sel. Areas Commun."}
@string{ieeepcom = "IEEE Pers. Commun. Mag."}
@string{ieeetac = "IEEE Trans. Automat. Contr. "}
@string{ieeetaes = "IEEE Trans. Aerosp.  Electron. Sys."}
@string{ieeetassp = "IEEE Trans. Acoust., Speech, Signal Proc."}
@string{ieeetcom = "IEEE Trans. Commun."}
@string{ieeetcomt = "IEEE Trans. Commun. Tech."}
@string{ieeetit = "IEEE Trans. Inform. Theory"}
@string{ieeetmag = "IEEE Trans. Magnet."}
@string{ieeetsp = "IEEE Trans. Signal Proc."}
@string{ieeetsmc = "IEEE Trans. Syst., Man, Cybern."}
@string{ieeetvt = "IEEE Trans. Veh. Technol."}
@string{ieeetwireless = "IEEE Trans. Wireless Commun."}
@string{ieeeacmtn = "IEEE/ACM  Trans. Network."}
@string{infocom = "Proc. IEEE Inforcom."}
@string{iretit = "IRE Trans. Inform. Th."}
@string{ijwin = "Internat. J. Wireless Inform. Networks"}
@string{ipsn = "International Workshop on Information Processing in Sensor Networks (IPSN)"}
@string{isit="Proc. IEEE Int. Symp. Information Theory (ISIT)"}
@string{jap = "J. Appl. Phys."}
@string{japrob = "J. Appl. Prob."}
@string{jfa = "J. Functional Anal."}
@string{jfi = "J. Franklin Inst."}
@string{jmaa = "J. Math. Anal. Appl."}
@string{jrss = "J. Roy. Statist. Soc."}
@string{jrsss = "J. Roy. Statist. Soc. Suppl."}
@string{jts = "J. Time Ser. Anal."}
@string{mcss = "Math. Contr. Signals Syst."}
@string{pit = "Probl. Inform. Transm."}
@string{prociee = "Proc. IEE"}
@string{procieee = "Proc. IEEE"}
@string{ptrf = "Probab. Th. Rel. Fields"}
@string{reep = "Radio Eng. Electron. Phys."}
@string{siamjam = "SIAM J. Appl. Math."}
@string{siamjco = "SIAM J. Control Optim."}
@string{sp = "Signal Proc."}
@string{spawc = "IEEE Int. Workshop on Signal Processing Advances for Wireless Communications (SPAWC)"}
@string{tpa = "Theory of Prob. and App."}
@string{wirelesscom= "Proc. WirelessCom, Symp. Inform. Theory"}
@string{wpc = "Wireless Pers. Commun."}
@string{vtc="Vehicular Technology Conference"}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
@string{nips="Proc. Advances in Neural Information Processing Systems (NIPS)"}
@string{nipsnew="Proc. Advances in Neural Information Processing Systems (NeurIPS)"}
@string{uai="Proc. International Conference on Uncertainty in Artificial Intelligence (UAI)"}
@string{icml="Proc. International Conference on Machine Learning (ICML)"}
@string{aaai="Proc. Conference on Artificial Intelligence (AAAI)"}
@string{aistats="Proc. International Conference on Artifical Intelligence and Statistics (AISTATS)"}
@string{colt="Proc. Annual Conference on Learning Theory (CoLT)"}
@string{iclr="Proc. International Conference on Learning Representations (ICLR)"}
@string{ijcai="Proc. International Joint Conferences on Artificial Intelligence (IJCAI)"}
@string{astat = "Ann. Statist."}
@string{jasa = "J. Amer. Stat. Assoc."}
@string{jmlr = "J. Mach. Learn. Res."}

@article{bertsekas2011dynamic,
  title={{Dynamic Programming and Optimal Control 3rd edition, volume II}},
  author={Bertsekas, Dimitri P},
  journal={Belmont, MA: Athena Scientific},
  year={2011}
}


@inproceedings{melo2008analysis,
	title={An analysis of reinforcement learning with function approximation},
	author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
	booktitle=icml,
	pages={664--671},
	year={2008},
	organization={ACM}
}
@book{meyn2012markov,
	title={Markov Chains and Stochastic Stability},
	author={Meyn, Sean P and Tweedie, Richard L},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@inproceedings{bhandari2018finite,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  booktitle=colt,
  pages={1691--1692},
  year={2018},
  organization={PMLR}
}
 
@article{kushner2010stochastic,
	title={Stochastic approximation: a survey},
	author={Kushner, Harold},
	journal={Wiley Interdisciplinary Reviews: Computational Statistics},
	volume={2},
	number={1},
	pages={87--96},
	year={2010},
	publisher={Wiley Online Library}
}
@article{lacoste2012simpler,
	title={A simpler approach to obtaining an $O(1/t)$ convergence rate for the projected stochastic subgradient method},
	author={Lacoste-Julien, Simon and Schmidt, Mark and Bach, Francis},
	journal={arXiv preprint arXiv:1212.2002},
	year={2012}
}
@article{bubeck2015convex,
	title={Convex optimization: Algorithms and complexity},
	author={Bubeck, S{\'e}bastien},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={8},
	number={3-4},
	pages={231--357},
	year={2015},
	publisher={Now Publishers, Inc.}
}
@article{nemirovski2009robust,
	title={Robust stochastic approximation approach to stochastic programming},
	author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
	journal={SIAM Journal on Optimization},
	volume={19},
	number={4},
	pages={1574--1609},
	year={2009},
	publisher={SIAM}
}
@ARTICLE{Tsitsiklis1997, 
	author={J. N. Tsitsiklis and B.  Roy}, 
	journal={IEEE Transactions on Automatic Control}, 
	title={An analysis of temporal-difference learning with function approximation}, 
	year={1997}, 
	volume={42}, 
	number={5}, 
	pages={674-690},
	month={May},}
@inproceedings{perkins2002existence,
	title={On the existence of fixed points for {Q}-learning and {Sarsa} in partially observable domains},
	author={Perkins, Theodore J and Pendrith, Mark D},
	booktitle=icml,
	pages={490--497},
	year={2002}
}
@article{de2000existence,
	title={On the existence of fixed points for approximate value iteration and temporal-difference learning},
	author={De Farias, Daniela Pucci and Van Roy, Benjamin},
	journal={Journal of Optimization theory and Applications},
	volume={105},
	number={3},
	pages={589--608},
	year={2000},
	publisher={Springer}
}
@inproceedings{perkins2003convergent,
	title={A convergent form of approximate policy iteration},
	author={Perkins, Theodore J and Precup, Doina},
	booktitle=nips,
	pages={1627--1634},
	year={2003}
}
@article{mitrophanov2005sensitivity,
	title={Sensitivity and convergence of uniformly ergodic {M}arkov chains},
	author={Mitrophanov, A. Y.},
	journal={Journal of Applied Probability},
	volume={42},
	number={4},
	pages={1003--1014},
	year={2005},
	publisher={Cambridge University Press}
}
@book{benveniste2012adaptive,
	title={Adaptive Algorithms and Stochastic Approximations},
	author={Benveniste, Albert and M{\'e}tivier, Michel and Priouret, Pierre},
	volume={22},
	year={2012},
	publisher={Springer Science \& Business Media}
}
@article{sutton1988learning,
	title={Learning to predict by the methods of temporal differences},
	author={Sutton, Richard S.},
	journal={Machine learning},
	volume={3},
	number={1},
	pages={9--44},
	year={1988},
	publisher={Springer}
}

@article{doan2021finite,
  title={Finite-time analysis and restarting scheme for linear two-time-scale stochastic approximation},
  author={Doan, Thinh T},
  journal={SIAM Journal on Control and Optimization},
  volume={59},
  number={4},
  pages={2798--2819},
  year={2021},
  publisher={SIAM}
}


@inproceedings{perolat2015approximate,
	title={Approximate dynamic programming for two-player zero-sum {M}arkov games},
	author={Perolat, Julien and Scherrer, Bruno and Piot, Bilal and Pietquin, Olivier},
	booktitle=icml,
	year={2015}
}
@article{singh2000convergence,
	title={Convergence results for single-step on-policy reinforcement-learning algorithms},
	author={Singh, Satinder and Jaakkola, Tommi and Littman, Michael L and Szepesv{\'a}ri, Csaba},
	journal={Machine Learning},
	volume={38},
	number={3},
	pages={287--308},
	year={2000},
	publisher={Springer}
}
@article{gordon1996chattering,
  title={Chattering in {SARSA} ($\lambda$)},
  author={Gordon, Geoffrey J},
  journal={CMU Learning Lab Technical Report},
  year={1996}
}

@InProceedings{srikant2019, 
title = {Finite-Time Error Bounds For Linear Stochastic Approximation and {TD} Learning}, 
author = {Srikant, R. and Ying, Lei}, 
booktitle = colt, 
pages = {2803--2830}, 
year = {2019},}



@inproceedings{Asadi2016,
  title={An alternative softmax operator for reinforcement learning},
  author={Asadi, Kavosh and Littman, Michael L},
  booktitle=icml,
  volume={70},
  pages={243--252},
  year={2017},
  organization={JMLR}
}


@inproceedings{gordon2000reinforcement,
	title={Reinforcement Learning with Function Approximation Converges to a Region},
	author={Gordon, Geoffrey J},
	pages={1040--1046},
	year={2001},
booktitle=nips}


@inproceedings{korda2015td,
  title={On {TD}(0) with function approximation: Concentration bounds and a centered variant with exponential convergence},
  author={Korda, Nathaniel and La, Prashanth},
  booktitle=icml,
  pages={626--634},
  year={2015}
}


@inproceedings{gupta2019finite,
  title={Finite-time performance bounds and adaptive learning rate selection for two time-scale reinforcement learning},
  author={Gupta, Harsh and Srikant, R and Ying, Lei},
  booktitle=nipsnew,
  pages={4706--4715},
  year={2019}
}


@article{silver2016mastering,
  title={Mastering the game of {Go} with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{Antos2008,
author = "A. Antos and C. Szepesvari and R. Munos",
title = "Learning near-optimal policies with {B}ellman-residual minimization based fitted policy iteration and a single sample path",
journal = "Machine Learning",
volume = "71",
number = "1",
year = "2008",
pages = "89-129"
}

@inproceedings{Bowling2001,
	author = "Bowling, M.",
	title = "Rational and convergent learning in stochastic games",
	booktitle = "Proc.  International Joint Conference on Artificial intelligence (IJCAI)",
	year = "2001",
} 

@article{Boyan2002,
author = "Boyan, J. A.",
title = "Technical update: {L}east-squares temporal difference learning",
journal = "Machine Learning",
volume = "49",
year = "2002",
pages = "233-246"
}

@article{Brad1996,
author = "Bradtke, S. J. and Barto, A. G.",
title = "Linear least-squares algorithms for temporal difference learning",
journal = "Machine Learning",
volume = "22",
year = "1996",
pages = "33-57"
}

@article{Coni2007,
author = "Conitzer, V. and Sandholm, T.",
title = "{AWESOME: A} general multiagent learning algorithm that converges in self-play and learns a best response against stationary opponents",
journal = "Machine Learning",
volume = "67",
year = "2007",
pages = "23-43"
}

@article{Devraj2018,
	author = {A. M. Devraj and I. Kontoyiannis and S. P. Meyn},
	title = {Differential Temporal Difference Learning},
	journal = {ArXiv: 1812.11137},
	year = 2018,
	month = "Dec.",
}

@inproceedings{Dalal2018a,
	author = {author={Dalal, Gal and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannor, Shie}},
	title = "Finite sample analyses for {TD}(0) with function approximation",
	booktitle = "Proc. AAAI Conference on Artificial Intelligence (AAAI)",
	year = "2018",
	pages= "6144-6160"
} 



@inproceedings{Farah2010,
	author = "Farahmand, A.-M. and Szepesvari, C. and Munos, R.",
	title = "Error propagation for approximate policy and value iteration",
	booktitle = nips,
	year = "2010",
} 

@inproceedings{Ghav2010,
	author = "Mohammad Ghavamzadeh and Alessandro Lazaric and Odalric Maillard and Remi Munos",
	title = "{LSTD} with Random Projections",
	booktitle = nips,
	year = "2010",
} 

@article{Lagou2003,
author = "Lagoudakis, M. G. and Parr, R.",
title = "Least-squares policy iteration",
journal = "Journal of Machine Learning Research",
volume = "4",
year = "2003",
pages = "1107-1149"
}

@inproceedings{Lagou2002,
	author = "Lagoudakis, M. G. and Parr, R.",
	title = "Value function approximation in zero-sum {M}arkov games",
	booktitle = "Proc. Uncertainty in Artificial Intelligence (UAI)",
	year = "2002",
} 

@inproceedings{lakshminarayanan2018linear,
  title={Linear stochastic approximation: {H}ow far does constant step-size and iterate averaging go?},
  author={Lakshminarayanan, Chandrashekar and Szepesvari, Csaba},
  booktitle={Proc. International Conference on Artificial Intelligence and Statistics},
  pages={1347--1355},
  year={2018}
}


@inproceedings{Lazaric2010,
	author = "Alessandro Lazaric and Mohammad Ghavamzadeh and Remi Munos",
	title = "Finite-sample analysis of LSTD",
	booktitle = icml,
	year = "2010",
} 

@article{Lazaric2012,
author = "Lazaric, A. and Ghavamzadeh, M. and Munos, R.",
title = "Finite-sample analysis of least-squares policy iteration",
journal = "Journal of Machine Learning Research",
volume = "13",
year = "2012",
pages = "3041-3074"
}

@article{Lazaric2016,
author = "Lazaric, A. and Ghavamzadeh, M. and Munos, R.",
title = "Analysis of classification-based policy iteration algorithms",
journal = "Journal of Machine Learning Research",
volume = "17",
year = "2016",
pages = "583-612"
}

@inproceedings{Littman1994,
	author = "Littman, M. L.",
	title = "Markov games as a framework for multi-agent reinforcement learning",
	booktitle = icml,
	year = "1994",
} 




@article{Minh2015,
	author = "Mnih, V. and Kavukcuoglu, K. and Silver, D. and Rusu, A. A. and Veness, J. and Bellemare, M. G. and Graves, A. and Riedmiller, M. and Fidjeland, A. K. and Ostrovski, G.",
	title = "Human-level control through deep reinforcement learning",
	journal = "Nature",
	volume = "518",
	year = "2015",
	pages = "529-533"
} 

@inproceedings{Minh2016,
	author = "Mnih, V. and Badia, A. P. and Mirza, M. and Graves, A. and Lillicrap, T. and Harley, T. and Silver, D. and Kavukcuoglu, K.",
	title = "Asynchronous methods for deep reinforcement learning",
	booktitle = icml,
	pages={1928--1937},
	year = "2016",
} 


@article{Munos2008,
author = "R. Munos and C. Szepesvari",
title = "Finite-time bounds for fitted value iteration",
journal = "Journal of Machine Learning Research",
volume = "9",
month = may,
year = "2008",
pages = "815-857"
}

@article{Ormo2002a,
author = "D. Ormoneit and P. Glynn",
title = "Kernel-based reinforcement learning in average-cost problems",
journal = "IEEE Trans. Automatic Control",
volume = "47",
number ="10",
year = "2002",
pages = "1624-1636"
}

@article{Ormo2002b,
author = "Dirk Ormoneit and Saunak Sen",
title = "Kernel-based reinforcement learning",
journal = "Mach. Learning",
volume = "49",
number = "2-3",
year = "2002",
pages = "161-178"
}

@inproceedings{Pires2012,
	author = "Bernardo A. Pires and Csaba Szepesvari",
	title = "Statistical linear estimation with penalized estimators: {A}n application to reinforcement learning",
	booktitle = icml,
	year = "2012",
} 

@inproceedings{Perolat2016a,
	author = "Perolat, J. and Piot, B. and Geist, M. and Scherrer, B. and Pietquin, O. ",
	title = "Softened approximate policy iteration for {M}arkov games",
	booktitle =icml,
	year = "2016",
} 

@inproceedings{Perolat2016b,
	author = "Perolat, J. and Piot and B. and Scherrer B. and Pietquin, O.",
	title = "On the use of non-stationary strategies for solving two-player zero-sum {M}arkov games",
	booktitle = aistats,
	year = "2016",
} 

@inproceedings{Perolat2018,
	author = "Perolat, J. and Piot, B. and Pietquin, O.",
	title = "Actor-critic fictitious play in simultaneous move multistage games",
	booktitle = aistats,
	year = "2018",
} 

@inproceedings{Prasad2015,
	author = "H. L. Prasad and Prashanth L.A. and Shalabh Bhatnagar",
	title = "Two-timescale algorithms for learning {N}ash equilibria in general-sum stochastic games",
	booktitle = "Proc.  International Conference on Autonomous Agents and Multiagent Systems (AAMAS)",
	year = "2015",
} 

@inproceedings{Prash2013,
	author = "La Prashanth and Nathaniel Korda and Remi Munos",
	title = "Fast {LSTD} using stochastic approximation: {F}inite time analysis and application to traffic control",
	booktitle = "Proc. Joint European Conference on Machine Learning and Knowledge Discovery in Databases",
	year = "2013",
} 

@article{Rummery1994,
	author = {G. A. Rummery and M. Niranjan},
	title = {Online {Q}-learning using connectionist systems},
	journal = {Technical Report, {Cambridge University Engineering Department}},
	year = 1994,
	month = sep,
}

@inproceedings{Shah2018,
	author = "Devavrat Shah and Qiaomin Xie",
	title = "{Q}-learning with Nearest Neighbors",
	booktitle = nipsnew,
	year = "2018",
} 

@inproceedings{Srini2018,
	author = "Srinivasan, S. and Lanctot, M. and Zambaldi, V. and Perolat, J. and Tuyls, K. and Munos, R. and Bowling, M.",
	title = "Actor-critic policy optimization in partially observable multiagent environments",
	booktitle = nipsnew,
	year = "2018",
} 

@article{Sutton1988,
author = "Richard S Sutton",
title = "Learning to predict by the methods of temporal differences",
journal = "Machine Learning",
volume = "3",
number = "1",
year = "1988",
pages = "9-44"
}




@inproceedings{sutton2009acov,
  title={A convergent $ {O} (n) $ temporal-difference algorithm for off-policy learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid R and Szepesv{\'a}ri, Csaba},
  booktitle=nips,
  pages={1609--1616},
  year={2009}
}


@inproceedings{Tagorti2015,
	author = "Tagorti, M. and Scherrer, B.",
	title = "On the rate of convergence and error bounds for {LSTD} ($\lambda$)",
	booktitle = icml,
	year = "2015",
} 

@inproceedings{Touati2018,
	author = "Ahmed Touati and Pierre-Luc Bacon and Doina Precup and Pascal Vincent",
	title = "Convergent {TREE BACKUP} and {RETRACE} with function approximation",
	booktitle = icml,
	year = "2018",
} 

@inproceedings{Tu2018,
	author = "Stephen Tu and Benjamin Recht",
	title = "Least-squares temporal difference learning for the linear quadratic regulator",
	booktitle = icml,
	year = "2018",
} 



@inproceedings{Wei2017,
	author = "Wei, C.-Y. and Hong and Y.-T. and Lu, C.-J.",
	title = "Online reinforcement learning in stochastic games",
	booktitle = nips,
	year = "2017",
} 

@article{Yang2019,
	author = {Zhuora Yang and Yuchen Xie and Zhaoran Wang},
	title = {A Theoretical Analysis of Deep {Q}-Learning},
	journal = {ArXiv: 1901.00137},
	year = 2019,
	month = jan,
}

@article{Zhang2018,
	author = {Zhang, K. and Yang, Z. and Liu, H. and Zhang, T. and Basar, T.},
	title = {Finite-sample analyses for fully decentralized multi-agent reinforcement learning},
	journal = {arXiv:1812.02783},
	year = 2018,
}

############################################
# References about  cubic regularization
############################################
@article{Nesterov2006,
	author = "Nesterov, Y. and  Polyak, B.",
	journal = "Mathematical Programming",
	title = "Cubic regularization of {N}ewton's method and its global performance",
	year = "2006"
}

@ARTICLE{Carmon2016,
	author = {{Carmon}, Y. and {Duchi}, J.~C.},
	title = "{Gradient descent efficiently finds the cubic-regularized non-convex Newton step}",
	journal = {ArXiv: 1612.00547},
	year = 2016,
	month = "Dec.",
}
@InProceedings{gu2018,
	author = {{Zhou}, D. and {Xu}, P. and {Gu}, Q.},
	title = {Stochastic Variance-Reduced Cubic Regularized Newton Method},
	booktitle = {Proc. International Conference on Machine Learning (ICML)},
	year = 2018,  
}

@book{Lojasiewicz_book,
	title={Ensembles semi-analytiques},
	author={{\L}ojasiewicz, S.},
	publisher={Bures-sur-Yvette: Institut des Hautes Etudes Scientifiques},
	year={1965}
}


@book{Nesterov_2014,
	author = {Nesterov, Y.},
	title = {Introductory lectures on convex optimization: A Basic Course},
	year = {2014},
	publisher = {Springer},
} 

@article{Nemirovski_2009,
author = "Nemirovski, A. S. and Juditsky, A. and Lan, G. and Shapiro, A.",
title = "Robust stochastic approximation approach to stochastic programming",
journal = "SIAM Journal on Optimization",
volume = 19,
year = 2009,
pages = "1574-1609"
}

@inproceedings{allen2019convergence,
  title={A Convergence Theory for Deep Learning via Over-Parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle=icml,
  pages={242--252},
  year={2019}
}


@article{dalal2018finite,
  title={Finite Sample Analysis of Two-Timescale Stochastic Approximation with Applications to Reinforcement Learning},
  author={Dalal, Gal and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannor, Shie},
  journal={Proceedings of Machine Learning Research},
  volume={75},
  pages={1--35},
  year={2018}
}


@book{sutton2018reinforcement,
	title={Reinforcement Learning: An Introduction, Second Edition},
	author={Richard S. Sutton and Andrew G. Barto},
	publisher={The MIT Press, Cambridge, Massachusetts},
	year={2018}
}







@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}


@article{maei2011gradient,
  title={Gradient temporal-difference learning algorithms},
  author={Maei, Hamid Reza},
  year={2011},
  journal={Thesis, University of Alberta},
}

@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle=icml,
  pages={993--1000},
  year={2009}
}

@inproceedings{antos2008fitted,
  title={Fitted {Q}-iteration in continuous action-space MDPs},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle=nips,
  volume={20},
  pages={9--16},
  year={2007}
}
 

@article{antos2008learning,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@incollection{gordon1995stable,
  title={Stable function approximation in dynamic programming},
  author={Gordon, Geoffrey J},
  booktitle={Machine Learning Proceedings 1995},
  pages={261--268},
  year={1995},
  publisher={Elsevier}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@inproceedings{szepesvari2004interpolation,
  title={Interpolation-based {Q}-learning},
  author={Szepesv{\'a}ri, Csaba and Smart, William D},
  booktitle=icml,
  pages={100},
  year={2004}
}


@inproceedings{xu2019two,
  title={Two time-scale off-policy {TD} learning: Non-asymptotic analysis over {Markovian} samples},
  author={Xu, Tengyu and Zou, Shaofeng and Liang, Yingbin},
  booktitle=nipsnew,
  pages={10633--10643},
  year={2019}
}
@inproceedings{maei2010toward,
  title={Toward off-policy learning control with function approximation},
  author={Maei, Hamid Reza and Szepesv{\'a}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
  booktitle=icml,
  pages={719--726},
  year={2010}
}



@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

@article{ghadimi2013stochastic,
  title={Stochastic first- and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}





@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}


@article{watkins1992q,
  title={{Q}-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}





@inproceedings{borkar2018concentration,
  title={Concentration bounds for two time scale stochastic approximation},
  author={Borkar, Vivek S and Pattathil, Sarath},
  booktitle=allerton,
  pages={504--511},
  year={2018},
  organization={IEEE}
}
@inproceedings{zou2019finite,
  title={Finite-sample analysis for {SARSA} with linear function approximation},
  author={Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
  booktitle=nipsnew,
  pages={8665--8675},
  year={2019}
}
@article{kober2013reinforcement,
  title={Reinforcement Learning in Robotics: A Survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{yu2017convergence,
  title={On convergence of some gradient-based temporal-differences algorithms for off-policy learning},
  author={Yu, Huizhen},
  journal={arXiv preprint arXiv:1712.09652},
  year={2017}
}
@article{karmakar2018two,
  title={Two time-scale stochastic approximation with controlled {Markov} noise and off-policy temporal-difference learning},
  author={Karmakar, Prasenjit and Bhatnagar, Shalabh},
  journal={Mathematics of Operations Research},
  volume={43},
  number={1},
  pages={130--151},
  year={2018},
  publisher={INFORMS}
}
@inproceedings{wang2017finite,
  title={Finite sample analysis of the {GTD} policy evaluation algorithms in {M}arkov setting},
  author={Wang, Yue and Chen, Wei and Liu, Yuting and Ma, Zhi-Ming and Liu, Tie-Yan},
  booktitle=nips,
  pages={5504--5513},
  year={2017}
}
@inproceedings{liu2015finite,
  title={Finite-Sample Analysis of Proximal Gradient TD Algorithms.},
  author={Liu, Bo and Liu, Ji and Ghavamzadeh, Mohammad and Mahadevan, Sridhar and Petrik, Marek},
  booktitle=uai,
  pages={504--513},
  year={2015},
  organization={Citeseer}
}

@inproceedings{cai2019neural,
  title={Neural temporal-difference learning converges to global optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  booktitle=nipsnew,
  pages={11312--11322},
  year={2019}
}
@article{chen2019performance,
  title={Performance of {Q}-learning with linear function approuimation: Stability and finite-time analysis},
  author={Chen, Zaiwei and Zhang, Sheng and Doan, Thinh T and Maguluri, Siva Theja and Clarke, John-Paul},
  journal={arXiv preprint arXiv:1905.11425},
  year={2019}
}
@inproceedings{fang2018spider,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  booktitle=nipsnew,
  pages={689--699},
  year={2018}
}
@article{lan2019lectures,
  title={Lectures on Optimization. Methods for Machine Learning},
  author={Lan, G},
  journal={H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA},
  year={2019}
}
@book{nesterov2013introductory,
  title={Introductory Lectures on Convex Optimization: A Basic Course},
  author={Nesterov, Yurii},
  volume={87},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{jaganathan2015phase,
  title={Phase retrieval: An overview of recent developments},
  author={Jaganathan, Kishore and Eldar, Yonina C and Hassibi, Babak},
  journal={arXiv preprint arXiv:1510.07713},
  year={2015}
}
@inproceedings{zhang2016reshaped,
  title={Reshaped wirtinger flow for solving quadratic system of equations},
  author={Zhang, Huishuai and Liang, Yingbin},
  booktitle=nips,
  pages={2622--2630},
  year={2016}
}
@article{candes2015phase,
  title={Phase retrieval via Wirtinger flow: Theory and algorithms},
  author={Candes, Emmanuel J and Li, Xiaodong and Soltanolkotabi, Mahdi},
  journal={IEEE Transactions on Information Theory},
  volume={61},
  number={4},
  pages={1985--2007},
  year={2015},
  publisher={IEEE}
}
@article{chen2019gradient,
  title={Gradient descent with random initialization: Fast global convergence for nonconvex phase retrieval},
  author={Chen, Yuxin and Chi, Yuejie and Fan, Jianqing and Ma, Cong},
  journal={Mathematical Programming},
  volume={176},
  number={1-2},
  pages={5--37},
  year={2019},
  publisher={Springer}
}

 
@inproceedings{wang2020finite,
  title={Finite-sample analysis of {Greedy-GQ} with linear function approximation under {M}arkovian noise},
  author={Wang, Yue and Zou, Shaofeng},
  booktitle=uai,
  pages={11--20},
  year={2020},
  organization={PMLR}
}



@article{konda2004convergence,
  title={Convergence rate of linear two-time-scale stochastic approximation},
  author={Konda, Vijay R and Tsitsiklis, John N and others},
  journal={The Annals of Applied Probability},
  volume={14},
  number={2},
  pages={796--819},
  year={2004},
  publisher={Institute of Mathematical Statistics}
}



@article{mokkadem2006convergence,
  title={Convergence rate and averaging of nonlinear two-time-scale stochastic approximation algorithms},
  author={Mokkadem, Abdelkader and Pelletier, Mariane and others},
  journal={The Annals of Applied Probability},
  volume={16},
  number={3},
  pages={1671--1702},
  year={2006},
  publisher={Institute of Mathematical Statistics}
}

@article{doan2020nonlinear,
  title={Nonlinear Two-Time-Scale Stochastic Approximation: Convergence and Finite-Time Performance},
  author={Doan, Thinh T},
  journal={arXiv preprint arXiv:2011.01868},
  year={2020}
}

@inproceedings{xu2021sample,
  title={Sample complexity bounds for two timescale value-based reinforcement learning algorithms},
  author={Xu, Tengyu and Liang, Yingbin},
  booktitle=aistats,
  pages={811--819},
  year={2021},
  organization={PMLR}
}

@inproceedings{perkins2003convergent,
  title={A convergent form of approximate policy iteration},
  author={Perkins, Theodore J and Precup, Doina},
  booktitle=nips,
  pages={1627--1634},
  year={2003}
}



@inproceedings{kaledin2020finite,
  title={Finite time analysis of linear two-timescale stochastic approximation with {M}arkovian noise},
  author={Kaledin, Maxim and Moulines, Eric and Naumov, Alexey and Tadic, Vladislav and Wai, Hoi-To},
  booktitle=colt,
  pages={2144--2203},
  year={2020},
  organization={PMLR}
}

 

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@incollection{benaim1999dynamics,
  title={Dynamics of stochastic approximation algorithms},
  author={Bena{\"\i}m, Michel},
  booktitle={Seminaire de probabilites XXXIII},
  pages={1--68},
  year={1999},
  publisher={Springer}
}

@book{kushner2003stochastic,
  title={Stochastic approximation and recursive algorithms and applications},
  author={Kushner, Harold and Yin, G George},
  volume={35},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle=nips,
  pages={1008--1014},
  year={2000}
}
@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}
@inproceedings{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  title=nips,
  volume={14},
  pages={1531--1538},
  year={2001}
}
 
@article{bhatnagar2009natural,
  title={Natural actor--critic algorithms},
  author={Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
  journal={Automatica},
  volume={45},
  number={11},
  pages={2471--2482},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{Wang2020Neural,
title={Neural Policy Gradient Methods: Global Optimality and Rates of Convergence},
author={Lingxiao Wang and Qi Cai and Zhuoran Yang and Zhaoran Wang},
booktitle=iclr,
year={2020}
}

@inproceedings{yang2019provably,
  title={Provably global convergence of actor-critic: A case for linear quadratic regulator with ergodic cost},
  author={Yang, Zhuoran and Chen, Yongxin and Hong, Mingyi and Wang, Zhaoran},
  booktitle=nipsnew,
  pages={8353--8365},
  year={2019}
}

@article{kumar2019sample,
  title={On the sample complexity of actor-critic method for reinforcement learning with function approximation},
  author={Kumar, Harshat and Koppel, Alec and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:1910.08412},
  year={2019}
}
@inproceedings{qiu2019finite,
  title={On the finite-time convergence of actor-critic algorithm},
  author={Qiu, Shuang and Yang, Zhuoran and Ye, Jieping and Wang, Zhaoran},
  booktitle={Proc. Optimization Foundations for Reinforcement Learning Workshop at Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{xu2020non,
  title={Non-asymptotic Convergence Analysis of Two Time-scale (Natural) Actor-Critic Algorithms},
  author={Xu, Tengyu and Wang, Zhe and Liang, Yingbin},
  journal={arXiv preprint arXiv:2005.03557},
  year={2020}
}
@article{wu2020finite,
  title={A Finite Time Analysis of Two Time-Scale Actor Critic Methods},
  author={Wu, Yue and Zhang, Weitong and Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2005.01350},
  year={2020}
}

@article{archibald1995generation,
  title={{On the generation of {M}arkov decision processes}},
  author={Archibald, TW and McKinnon, KIM and Thomas, LC},
  journal={Journal of the Operational Research Society},
  volume={46},
  number={3},
  pages={354--361},
  year={1995},
  publisher={Taylor \& Francis}
}

@article{brockman2016openai,
  title={{OpenAI Gym}},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{borkar1997stochastic,
  title={Stochastic approximation with two time scales},
  author={Borkar, Vivek S},
  journal={Systems \& Control Letters},
  volume={29},
  number={5},
  pages={291--294},
  year={1997},
  publisher={Elsevier}
}

@inproceedings{tadic2004almost,
  title={Almost sure convergence of two time-scale stochastic approximation algorithms},
  author={Tadic, Vladislav B},
  booktitle={Proceedings of the 2004 American Control Conference},
  volume={4},
  pages={3802--3807},
  year={2004},
  organization={IEEE}
}


@inproceedings{xu2020improving,
  title={Improving sample complexity bounds for (natural) actor-critic algorithms},
  author={Xu, Tengyu and Wang, Zhe and Liang, Yingbin},
  booktitle=nipsnew,
  volume={33},
  year={2020}
}

@inproceedings{dalal2020tale,
  title={ A tale of two-timescale reinforcement learning with the tightest finite-time bound},
  author={Dalal, Gal and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan},
  booktitle=aaai,
  pages={3701--3708},
  year={2020}
}
@inproceedings{wang2019spiderboost,
  title={SpiderBoost and momentum: Faster variance reduction algorithms},
  author={Wang, Zhe and Ji, Kaiyi and Zhou, Yi and Liang, Yingbin and Tarokh, Vahid},
  booktitle=nipsnew,
  pages={2406--2416},
  year={2019}
}
@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S and Maei, Hamid and Szepesv{\'a}ri, Csaba},
  booktitle=nips,
  volume={22},
  pages={1204--1212},
  year={2009}
}

@inproceedings{xu2020finite,
  title={A finite-time analysis of {Q}-learning with neural network function approximation},
  author={Xu, Pan and Gu, Quanquan},
  booktitle=icml,
  pages={10555--10565},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2020finite,
  title={Finite-Sample Analysis of Decentralized Temporal-Difference Learning with Linear Function Approximation},
  author={Sun, Jun and Wang, Gang and Giannakis, Georgios B and Yang, Qinmin and Yang, Zaiyue},
  booktitle=aistats,
  year={2020}
}


@article{cen2020fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={arXiv preprint arXiv:2007.06558},
  year={2020}
}
@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}
@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}



@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle=icml,
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}
 
@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@inproceedings{ma2020variance,
  title={Variance-Reduced Off-Policy {TDC} Learning: Non-Asymptotic Convergence Analysis},
  author={Ma, Shaocong and Zhou, Yi and Zou, Shaofeng},
  booktitle=nipsnew,
  volume={33},
   pages = {14796--14806},
  year={2020}
}

@inproceedings{wai2019variance,
  title={Variance reduced policy evaluation with smooth function approximation},
  author={Wai, Hoi-To and Hong, Mingyi and Yang, Zhuoran and Wang, Zhaoran and Tang, Kexin},
  booktitle=nipsnew,
  volume={32},
  pages={5784--5795},
  year={2019}
}
 

@inproceedings{sutton2008convergent,
  title={A convergent {O}(n) algorithm for off-policy temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Szepesv{\'a}ri, Csaba and Maei, Hamid Reza},
  booktitle=nips,
  volume={21},
  pages={1609--1616},
  year={2008},
  publisher={MIT Press}
}

@inproceedings{miyato2018spectral,
  title={Spectral Normalization for Generative Adversarial Networks},
  author={Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  booktitle={Proc. International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{neyshabur2017implicit,
  title={Implicit regularization in deep learning},
  author={Neyshabur, Behnam},
  journal={arXiv preprint arXiv:1709.01953},
  year={2017}
}

@inproceedings{du2019gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle=icml,
  pages={1675--1685},
  year={2019},
  organization={PMLR}
}


@inproceedings{ma2021greedygq,
  title={Greedy-{GQ} with Variance Reduction: Finite-time Analysis and Improved Complexity},
  author={Ma, Shaocong and Zhou, Yi and Zou, Shaofeng},
  booktitle={Proc. International Conference on Learning Representations (ICLR)},
  year={2021}
}

 
@inproceedings{li2020sample,
  title={Sample complexity of asynchronous {Q}-learning: Sharper analysis and variance reduction},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  booktitle=nipsnew,
  year={2020}
}



@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{roy2017reinforcement,
  title={Reinforcement learning under model mismatch},
  author={Roy, Aurko and Xu, Huan and Pokutta, Sebastian},
  booktitle=nips,
  pages={3046--3055},
  year={2017}
}

@article{bagnell2001solving,
author={Bagnell, J Andrew and Ng, Andrew Y and Schneider, Jeff G},
year = {2001},
month = {09},
title = {Solving Uncertain Markov Decision}
}

@article{wiesemann2013robust,
  title={Robust {M}arkov decision processes},
  author={Wiesemann, Wolfram and Kuhn, Daniel and Rustem, Ber{\c{c}}},
  journal={Mathematics of Operations Research},
  volume={38},
  number={1},
  pages={153--183},
  year={2013},
  publisher={INFORMS}
}

@article{satia1973markovian,
  title={{M}arkovian decision processes with uncertain transition probabilities},
  author={Satia, Jay K and Lave Jr, Roy E},
  journal={Operations Research},
  volume={21},
  number={3},
  pages={728--740},
  year={1973},
  publisher={INFORMS}
}


@article{vinitsky2020robust,
  title={Robust Reinforcement Learning using Adversarial Populations},
  author={Vinitsky, Eugene and Du, Yuqing and Parvate, Kanaad and Jang, Kathy and Abbeel, Pieter and Bayen, Alexandre},
  journal={arXiv preprint arXiv:2008.01825},
  year={2020}
}

@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle=icml,
  pages={2817--2826},
  year={2017},
  organization={PMLR}
}

@article{abdullah2019wasserstein,
  title={Wasserstein robust reinforcement learning},
  author={Abdullah, Mohammed Amin and Ren, Hang and Ammar, Haitham Bou and Milenkovic, Vladimir and Luo, Rui and Zhang, Mingtian and Wang, Jun},
  journal={arXiv preprint arXiv:1907.13196},
  year={2019}
}

@article{hou2020robust,
  title={Robust Reinforcement Learning with Wasserstein Constraint},
  author={Hou, Linfang and Pang, Liang and Hong, Xin and Lan, Yanyan and Ma, Zhiming and Yin, Dawei},
  journal={arXiv preprint arXiv:2006.00945},
  year={2020}
}

@inproceedings{rajeswaran2017epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  booktitle=iclr,
  year={2017}
}

@inproceedings{atkeson2002nonparametric,
  title={Nonparametric representation of policies and value functions: a trajectory-based approach},
  author={Atkeson, Christopher G and Morimoto, Jun},
  booktitle={Proceedings of the 15th International Conference on Neural Information Processing Systems},
  pages={1643--1650},
  year={2002}
}

@article{morimoto2005robust,
  title={Robust reinforcement learning},
  author={Morimoto, Jun and Doya, Kenji},
  journal={Neural computation},
  volume={17},
  number={2},
  pages={335--359},
  year={2005},
  publisher={MIT Press}
}

@inproceedings{huang2017adversarial,
  title={Adversarial attacks on neural network policies},
  author={Huang, Sandy and Papernot, Nicolas and Goodfellow, Ian and Duan, Yan and Abbeel, Pieter},
  booktitle=iclr,
  year={2017}
}

@inproceedings{kos2017delving,
  title={Delving into adversarial attacks on deep policies},
  author={Kos, Jernej and Song, Dawn},
  booktitle=iclr,
  year={2017}
}
@inproceedings{lin2017tactics,
  title={Tactics of adversarial attack on deep reinforcement learning agents},
  author={Lin, Yen-Chen and Hong, Zhang-Wei and Liao, Yuan-Hong and Shih, Meng-Li and Liu, Ming-Yu and Sun, Min},
  booktitle=ijcai,
  pages={3756--3762},
  year={2017}
}


@inproceedings{pattanaik2018robust,
  title={Robust Deep Reinforcement Learning with Adversarial Attacks},
  author={Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
  booktitle={Proc. International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2040--2042},
  year={2018}
}



@inproceedings{mandlekar2017adversarially,
  title={Adversarially robust policy learning: Active construction of physically-plausible perturbations},
  author={Mandlekar, Ajay and Zhu, Yuke and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3932--3939},
  year={2017},
  organization={IEEE}
}

@article{even2003learning,
  title={Learning Rates for {Q}-learning.},
  author={Even-Dar, Eyal and Mansour, Yishay and Bartlett, Peter},
  journal={Journal of machine learning Research},
  volume={5},
  number={1},
  year={2003}
}

@article{beck2012error,
  title={Error bounds for constant step-size {Q}-learning},
  author={Beck, Carolyn L and Srikant, Rayadurgam},
  journal={Systems \& control letters},
  volume={61},
  number={12},
  pages={1203--1208},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{qu2020finite,
  title={Finite-Time Analysis of Asynchronous Stochastic Approximation and {Q}-Learning},
  author={Qu, Guannan and Wierman, Adam},
  booktitle=colt,
  pages={3185--3205},
  year={2020},
  organization={PMLR}
}

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@article{wainwright2019variance,
  title={Variance-reduced {Q}-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}

@article{wang2021finite,
  title={Finite-Sample Analysis for Two Time-scale Non-linear {TDC} with General Smooth Function Approximation},
  author={Wang, Yue and Zou, Shaofeng and Zhou, Yi},
  journal={arXiv preprint arXiv:2104.02836},
  year={2021}
}

@article{hub65,
	Author = {P. J. Huber},
	Date-Added = {2020-11-07 09:39:14 -0600},
	Date-Modified = {2020-11-07 10:32:02 -0600},
	Journal = amstat,
	Pages = {1753-1758},
	Title = {A Robust Version of the Probability Ratio Test},
	Volume = 36,
	Year = 1965}


 
@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle=icml,
  pages={181--189},
  year={2014},
  organization={PMLR}
}


@inproceedings{lim2013reinforcement,
  title={Reinforcement learning in robust Markov decision processes},
  author={Lim, Shiau Hong and Xu, Huan and Mannor, Shie},
  booktitle=nips,
  pages={701--709},
  year={2013}
}

@inproceedings{nilim2004robustness,
  title={Robustness in {Markov} decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle=nips,
  pages={839--846},
  year={2004}
}
@inproceedings{atkeson2003nonparametric,
  title={Nonparametric representation of policies and value functions: A trajectory-based approach},
  author={Atkeson, Christopher G and Morimoto, Jun},
  booktitle=nips,
  pages={1643--1650},
  year={2003}
}
@article{li2021q,
  title={Is {Q}-Learning Minimax Optimal? A Tight Sample Complexity Analysis},
  author={Li, Gen and Cai, Changxiao and Chen, Yuxin and Gu, Yuantao and Wei, Yuting and Chi, Yuejie},
  journal={arXiv preprint arXiv:2102.06548},
  year={2021}
}

@inproceedings{zhang2020robust,
  title={Robust Multi-Agent Reinforcement Learning with Model Uncertainty},
  author={Zhang, Kaiqing and Sun, Tao and Tao, Yunzhe and Genc, Sahika and Mallya, Sunil and Basar, Tamer},
  booktitle=nipsnew,
  volume={33},
  year={2020}
}


@inproceedings{zhang2020stability,
  title={On the stability and convergence of robust adversarial reinforcement learning: A case study on linear quadratic systems},
  author={Zhang, Kaiqing and Hu, Bin and Basar, Tamer},
  booktitle=nipsnew,
  volume={33},
  year={2020}
}

 

@inproceedings{badrinath2021robust,
  title={Robust Reinforcement Learning using Least Squares Policy Iteration with Provable Performance Guarantees},
  author={Badrinath, Kishan Panaganti and Kalathil, Dileep},
  booktitle=icml,
  pages={511--520},
  year={2021},
  organization={PMLR}
}