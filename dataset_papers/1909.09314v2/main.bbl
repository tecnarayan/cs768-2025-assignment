\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel and Ng(2004)]{abbeel2004apprenticeship}
Pieter Abbeel and Andrew~Y Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, page~1, 2004.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'{e}}]{amodei2016}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul~F. Christiano, John Schulman,
  and Dan Man{\'{e}}.
\newblock Concrete problems in {AI} safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Colmenarejo, Hoffman,
  Pfau, Schaul, and de~Freitas]{Andrychowicz2016}
Marcin Andrychowicz, Misha Denil, Sergio~Gomez Colmenarejo, Matthew~W. Hoffman,
  David Pfau, Tom Schaul, and Nando de~Freitas.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock \emph{arXiv preprint arXiv:1606.04474}, 2016.

\bibitem[Bengio et~al.(1991)Bengio, Bengio, and Cloutier]{bengio1991}
Yoshua Bengio, Samy Bengio, and Jocelyn Cloutier.
\newblock Learning a synaptic learning rule.
\newblock In \emph{IJCNN-91-Seattle International Joint Conference on Neural
  Networks}, 1991.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{rl2}
Yan Duan, John Schulman, Xi~Chen, Peter~L. Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Rl{\textdollar}{\^{}}2{\textdollar}: Fast reinforcement learning via
  slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Duan et~al.(2017)Duan, Andrychowicz, Stadie, Ho, Schneider, Sutskever,
  Abbeel, and Zaremba]{duan2017}
Yan Duan, Marcin Andrychowicz, Bradly Stadie, Jonathan Ho, Jonas Schneider,
  Ilya Sutskever, Pieter Abbeel, and Wojciech Zaremba.
\newblock One-shot imitation learning.
\newblock \emph{Neural Information Processing Systems (NIPS)}, 2017.

\bibitem[Finn et~al.(2016{\natexlab{a}})Finn, Christiano, Abbeel, and
  Levine]{finn2016connection}
Chelsea Finn, Paul Christiano, Pieter Abbeel, and Sergey Levine.
\newblock A connection between generative adversarial networks, inverse
  reinforcement learning, and energy-based models.
\newblock \emph{arXiv preprint arXiv:1611.03852}, 2016{\natexlab{a}}.

\bibitem[Finn et~al.(2016{\natexlab{b}})Finn, Levine, and
  Abbeel]{finn2016guided}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In \emph{International Conference on Machine Learning}, pages 49--58,
  June 2016{\natexlab{b}}.

\bibitem[Finn et~al.(2017{\natexlab{a}})Finn, Abbeel, and Levine]{finn2017maml}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning},
  2017{\natexlab{a}}.

\bibitem[Finn et~al.(2017{\natexlab{b}})Finn, Yu, Zhang, Abbeel, and
  Levine]{finn2017one}
Chelsea Finn, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, and Sergey Levine.
\newblock One-shot visual imitation learning via meta-learning.
\newblock 2017{\natexlab{b}}.

\bibitem[Fu et~al.(2017)Fu, Luo, and Levine]{fu2017learning}
Justin Fu, Katie Luo, and Sergey Levine.
\newblock Learning robust rewards with adversarial inverse reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1710.11248}, 2017.

\bibitem[Gleave and Habryka(2018)]{multitaskirl}
Adam Gleave and Oliver Habryka.
\newblock Multi-task maximum entropy inverse reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1805.08882}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem[Hausman et~al.(2017)Hausman, Chebotar, Schaal, Sukhatme, and
  Lim]{hausman2017multi}
Karol Hausman, Yevgen Chebotar, Stefan Schaal, Gaurav Sukhatme, and Joseph~J
  Lim.
\newblock Multi-modal imitation learning from unstructured demonstrations using
  generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1235--1245, 2017.

\bibitem[Hausman et~al.(2018)Hausman, Springenberg, Wang, Heess, and
  Riedmiller]{hausman2018learning}
Karol Hausman, Jost~Tobias Springenberg, Ziyu Wang, Nicolas Heess, and Martin
  Riedmiller.
\newblock Learning an embedding space for transferable robot skills.
\newblock 2018.

\bibitem[Ho and Ermon(2016)]{gail}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock In \emph{Advances in Neural Information Processing Systems 29}, pages
  4565--4573. 2016.

\bibitem[Kingma and Welling(2013)]{vae}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kuefler and Kochenderfer(2018)]{Kuefler2018}
Alex Kuefler and Mykel~J. Kochenderfer.
\newblock Burn-in demonstrations for multi-modal imitation learning.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, AAMAS '18, 2018.

\bibitem[Levine(2018)]{levine2018reinforcement}
Sergey Levine.
\newblock Reinforcement learning and control as probabilistic inference:
  Tutorial and review.
\newblock \emph{arXiv preprint arXiv:1805.00909}, 2018.

\bibitem[Li and Malik(2017)]{li17optimize}
Ke~Li and Jitendra Malik.
\newblock Learning to optimize neural nets.
\newblock \emph{arXiv preprint arXiv:1703.00441}, 2017.

\bibitem[Li et~al.(2017)Li, Song, and Ermon]{li2017infogail}
Yunzhu Li, Jiaming Song, and Stefano Ermon.
\newblock Infogail: Interpretable imitation learning from visual
  demonstrations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3812--3822, 2017.

\bibitem[Munkhdalai and Yu(2017)]{metanetworks}
Tsendsuren Munkhdalai and Hong Yu.
\newblock Meta networks.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Ng and Russell(2000)]{ng2000irl}
Andrew~Y. Ng and Stuart~J. Russell.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{Proceedings of the Seventeenth International Conference on
  Machine Learning}, ICML '00, 2000.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{ng1999policy}
Andrew~Y Ng, Daishi Harada, and Stuart Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{ICML}, volume~99, pages 278--287, 1999.

\bibitem[Peng et~al.(2018)Peng, Kanazawa, Toyer, Abbeel, and Levine]{peng2018}
Xue~Bin Peng, Angjoo Kanazawa, Sam Toyer, Pieter Abbeel, and Sergey Levine.
\newblock Variational discriminator bottleneck: Improving imitation learning,
  inverse rl, and gans by constraining information flow.
\newblock \emph{arXiv preprint arXiv:1810.00821}, 2018.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Quillen, Finn, and Levine]{pearl}
Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, and Sergey Levine.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock \emph{arXiv preprint arXiv:1903.08254}, 2019.

\bibitem[Ratliff et~al.(2006)Ratliff, Bagnell, and Zinkevich]{ratliff2006}
Nathan~D. Ratliff, J.~Andrew Bagnell, and Martin~A. Zinkevich.
\newblock Maximum margin planning.
\newblock In \emph{Proceedings of the 23rd International Conference on Machine
  Learning}, ICML '06, 2006.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635, 2011.

\bibitem[S{\ae}mundsson et~al.(2018)S{\ae}mundsson, Hofmann, and
  Deisenroth]{saemundsson2018meta}
Steind{\'o}r S{\ae}mundsson, Katja Hofmann, and Marc~Peter Deisenroth.
\newblock Meta reinforcement learning with latent variable gaussian processes.
\newblock \emph{arXiv preprint arXiv:1803.07551}, 2018.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lillicrap]{mann}
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy
  Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Schaal et~al.(2003)Schaal, Ijspeert, and Billard]{imitation_survey}
Stefan Schaal, Auke Ijspeert, and Aude Billard.
\newblock Computational approaches to motor learning by imitation.
\newblock \emph{Philosophical Transactions of the Royal Society of London B:
  Biological Sciences}, 2003.

\bibitem[Schmidhuber(1987)]{schmidhuber1987evolutionary}
J{\"u}rgen Schmidhuber.
\newblock \emph{Evolutionary principles in self-referential learning, or on
  learning how to learn: the meta-meta-... hook}.
\newblock PhD thesis, Technische Universit{\"a}t M{\"u}nchen, 1987.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Moritz, Jordan, and
  Abbeel]{trpo}
John Schulman, Sergey Levine, Philipp Moritz, Michael~I. Jordan, and Pieter
  Abbeel.
\newblock Trust region policy optimization.
\newblock \emph{International Conference on Machine Learning}, 2015.

\bibitem[Sharma et~al.(2018)Sharma, Sharma, Rhinehart, and
  Kitani]{sharma2018directedinfogail}
Arjun Sharma, Mohit Sharma, Nicholas Rhinehart, and Kris~M. Kitani.
\newblock Directed-info {GAIL:} learning hierarchical policies from unsegmented
  demonstrations using directed information.
\newblock \emph{arXiv preprint arXiv:1810.01266}, 2018.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  (IROS)}, 2012.

\bibitem[Xu et~al.(2018)Xu, Ratner, Dragan, Levine, and Finn]{xu2018learning}
Kelvin Xu, Ellis Ratner, Anca Dragan, Sergey Levine, and Chelsea Finn.
\newblock Learning a prior over intent via meta-inverse reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1805.12573}, 2018.

\bibitem[Yu et~al.(2018{\natexlab{a}})Yu, Abbeel, Levine, and Finn]{yu2018hil}
Tianhe Yu, Pieter Abbeel, Sergey Levine, and Chelsea Finn.
\newblock One-shot hierarchical imitation learning of compound visuomotor
  tasks.
\newblock \emph{arXiv preprint arXiv:1810.11043}, 2018{\natexlab{a}}.

\bibitem[Yu et~al.(2018{\natexlab{b}})Yu, Finn, Xie, Dasari, Zhang, Abbeel, and
  Levine]{yu2018daml}
Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Tianhao Zhang, Pieter
  Abbeel, and Sergey Levine.
\newblock One-shot imitation from observing humans via domain-adaptive
  meta-learning.
\newblock \emph{Robotics: Science and Systems (R:SS)}, 2018{\natexlab{b}}.

\bibitem[Zhang et~al.(2017)Zhang, McCarthy, Jow, Lee, Goldberg, and
  Abbeel]{vr_imitation}
Tianhao Zhang, Zoe McCarthy, Owen Jow, Dennis Lee, Ken Goldberg, and Pieter
  Abbeel.
\newblock Deep imitation learning for complex manipulation tasks from virtual
  reality teleoperation.
\newblock \emph{arXiv preprint arXiv:1710.04615}, 2017.

\bibitem[Zhao et~al.(2018)Zhao, Song, and Ermon]{zhao2018information}
Shengjia Zhao, Jiaming Song, and Stefano Ermon.
\newblock The information autoencoding family: A lagrangian perspective on
  latent variable generative models.
\newblock \emph{arXiv preprint arXiv:1806.06514}, 2018.

\bibitem[Ziebart(2010)]{ziebart2010modeling}
Brian~D Ziebart.
\newblock Modeling purposeful adaptive behavior with the principle of maximum
  causal entropy.
\newblock 2010.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and
  Dey]{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{Aaai}, volume~8, pages 1433--1438. Chicago, IL, USA, 2008.

\end{thebibliography}
