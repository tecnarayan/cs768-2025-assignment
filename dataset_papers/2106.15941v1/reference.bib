@article{gray2006toeplitz,
  title={Toeplitz and circulant matrices: A review},
  author={Gray, Robert M},
  year={2006},
  publisher={now publishers inc}
}


@article{kra2012circulant,
	title={On circulant matrices},
	author={Kra, Irwin and Simanca, Santiago R},
	journal={Notices of the AMS},
	volume={59},
	number={3},
	pages={368--377},
	year={2012}
}

@article{wood1996estimation,
	title={Estimation of the Lipschitz constant of a function},
	author={Wood, GR and Zhang, BP},
	journal={Journal of Global Optimization},
	volume={8},
	number={1},
	pages={91--103},
	year={1996},
	publisher={Springer}
}

@article{aziznejad2020deep,
	title={Deep neural networks with trainable activations and controlled Lipschitz constant},
	author={Aziznejad, Shayan and Gupta, Harshit and Campos, Joaquim and Unser, Michael},
	journal={IEEE Transactions on Signal Processing},
	volume={68},
	pages={4688--4699},
	year={2020},
	publisher={IEEE}
}

@article{aziznejad2020deep,
	title={Deep neural networks with trainable activations and controlled Lipschitz constant},
	author={Aziznejad, Shayan and Gupta, Harshit and Campos, Joaquim and Unser, Michael},
	journal={IEEE Transactions on Signal Processing},
	volume={68},
	pages={4688--4699},
	year={2020},
	publisher={IEEE}
}

@article{dietrich1997fast,
	title={Fast and exact simulation of stationary Gaussian processes through circulant embedding of the covariance matrix},
	author={Dietrich, Claude R and Newsam, Garry N},
	journal={SIAM Journal on Scientific Computing},
	volume={18},
	number={4},
	pages={1088--1107},
	year={1997},
	publisher={SIAM}
}

@article{van2008visualizing,
	title={Visualizing data using t-SNE.},
	author={Van der Maaten, Laurens and Hinton, Geoffrey},
	journal={Journal of machine learning research},
	volume={9},
	number={11},
	year={2008}
}

@inproceedings{he2016identity,
	title={Identity mappings in deep residual networks},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={European conference on computer vision},
	pages={630--645},
	year={2016},
	organization={Springer}
}

@article{hinrichs2011johnson,
	title={Johnson-Lindenstrauss lemma for circulant matrices},
	author={Hinrichs, Aicke and Vyb{\'\i}ral, Jan},
	journal={Random Structures \& Algorithms},
	volume={39},
	number={3},
	pages={391--398},
	year={2011},
	publisher={Wiley Online Library}
}


@article{wang2021pyramid,
	title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
	author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
	journal={arXiv preprint arXiv:2102.12122},
	year={2021}
}

@article{weinstein1971data,
	title={Data transmission by frequency-division multiplexing using the discrete Fourier transform},
	author={Weinstein, Stephen and Ebert, Paul},
	journal={IEEE transactions on Communication Technology},
	volume={19},
	number={5},
	pages={628--634},
	year={1971},
	publisher={IEEE}
}


@incollection{nussbaumer1981fast,
	title={The fast Fourier transform},
	author={Nussbaumer, Henri J},
	booktitle={Fast Fourier Transform and Convolution Algorithms},
	pages={80--111},
	year={1981},
	publisher={Springer}
}

@book{brigham1988fast,
	title={The fast Fourier transform and its applications},
	author={Brigham, E Oran},
	year={1988},
	publisher={Prentice-Hall, Inc.}
}

@article{devlin2018bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{brown2020language,
	title={Language models are few-shot learners},
	author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	journal={arXiv preprint arXiv:2005.14165},
	year={2020}
}


@inproceedings{szegedy2016rethinking,
	title={Rethinking the inception architecture for computer vision},
	author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={2818--2826},
	year={2016}
}

@article{larsson2016fractalnet,
	title={Fractalnet: Ultra-deep neural networks without residuals},
	author={Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
	journal={arXiv preprint arXiv:1605.07648},
	year={2016}
}

@inproceedings{hoffer2020augment,
	title={Augment Your Batch: Improving Generalization Through Instance Repetition},
	author={Hoffer, Elad and Ben-Nun, Tal and Hubara, Itay and Giladi, Niv and Hoefler, Torsten and Soudry, Daniel},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={8129--8138},
	year={2020}
}


@inproceedings{yun2019cutmix,
	title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
	author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={6023--6032},
	year={2019}
}

@article{zhang2017mixup,
	title={mixup: Beyond empirical risk minimization},
	author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
	journal={arXiv preprint arXiv:1710.09412},
	year={2017}
}

@inproceedings{cubuk2020randaugment,
	title={Randaugment: Practical automated data augmentation with a reduced search space},
	author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
	pages={702--703},
	year={2020}
}

@inproceedings{deng2009imagenet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE conference on computer vision and pattern recognition},
	pages={248--255},
	year={2009},
	organization={Ieee}
}

@article{touvron2020training,
	title={Training data-efficient image transformers \& distillation through attention},
	author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
	journal={arXiv preprint arXiv:2012.12877},
	year={2020}
}

@inproceedings{carion2020end,
	title={End-to-end object detection with transformers},
	author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
	booktitle={European Conference on Computer Vision},
	pages={213--229},
	year={2020},
	organization={Springer}
}


@article{loshchilov2017decoupled,
	title={Decoupled weight decay regularization},
	author={Loshchilov, Ilya and Hutter, Frank},
	journal={arXiv preprint arXiv:1711.05101},
	year={2017}
}

@article{dosovitskiy2020image,
	title={An image is worth 16x16 words: Transformers for image recognition at scale},
	author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
	journal={arXiv preprint arXiv:2010.11929},
	year={2020}
}

@article{greff2016lstm,
	title={LSTM: A search space odyssey},
	author={Greff, Klaus and Srivastava, Rupesh K and Koutn{\'\i}k, Jan and Steunebrink, Bas R and Schmidhuber, J{\"u}rgen},
	journal={IEEE transactions on neural networks and learning systems},
	volume={28},
	number={10},
	pages={2222--2232},
	year={2016},
	publisher={IEEE}
}

@article{silver2017mastering,
	title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
	author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
	journal={arXiv preprint arXiv:1712.01815},
	year={2017}
}

@article{yuan2021tokens,
	title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
	author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
	journal={arXiv preprint arXiv:2101.11986},
	year={2021}
}

@article{krizhevsky2009learning,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, Alex and Hinton, Geoffrey and others},
	year={2009},
	publisher={Citeseer}
}


@inproceedings{nilsback2008automated,
	title={Automated flower classification over a large number of classes},
	author={Nilsback, Maria-Elena and Zisserman, Andrew},
	booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
	pages={722--729},
	year={2008},
	organization={IEEE}
}

@inproceedings{parkhi2012cats,
	title={Cats and dogs},
	author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
	booktitle={2012 IEEE conference on computer vision and pattern recognition},
	pages={3498--3505},
	year={2012},
	organization={IEEE}
}

@article{paszke2017automatic,
	title={Automatic differentiation in pytorch},
	author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	year={2017}
}

@article{wang2021pyramid,
	title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
	author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
	journal={arXiv preprint arXiv:2102.12122},
	year={2021}
}
@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{vaswani2017attention,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
	journal={arXiv preprint arXiv:1706.03762},
	year={2017}
}

@inproceedings{carion2020end,
	title={End-to-end object detection with transformers},
	author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
	booktitle={European Conference on Computer Vision},
	pages={213--229},
	year={2020},
	organization={Springer}
}

@article{chen2020pre,
	title={Pre-trained image processing transformer},
	author={Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
	journal={arXiv preprint arXiv:2012.00364},
	year={2020}
}

@inproceedings{tan2019efficientnet,
	title={Efficientnet: Rethinking model scaling for convolutional neural networks},
	author={Tan, Mingxing and Le, Quoc},
	booktitle={International Conference on Machine Learning},
	pages={6105--6114},
	year={2019},
	organization={PMLR}
}

@article{srivastava2015highway,
	title={Highway networks},
	author={Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
	journal={arXiv preprint arXiv:1505.00387},
	year={2015}
}

@inproceedings{he2016identity,
	title={Identity mappings in deep residual networks},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={European conference on computer vision},
	pages={630--645},
	year={2016},
	organization={Springer}
}


@article{veit2016residual,
	title={Residual networks behave like ensembles of relatively shallow networks},
	author={Veit, Andreas and Wilber, Michael and Belongie, Serge},
	journal={arXiv preprint arXiv:1605.06431},
	year={2016}
}

@inproceedings{balduzzi2017shattered,
	title={The shattered gradients problem: If resnets are the answer, then what is the question?},
	author={Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian},
	booktitle={International Conference on Machine Learning},
	pages={342--350},
	year={2017},
	organization={PMLR}
}

@article{dong2021attention,
	title={Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth},
	author={Dong, Yihe and Cordonnier, Jean-Baptiste and Loukas, Andreas},
	journal={arXiv preprint arXiv:2103.03404},
	year={2021}
}

@article{simonyan2014very,
	title={Very deep convolutional networks for large-scale image recognition},
	author={Simonyan, Karen and Zisserman, Andrew},
	journal={arXiv preprint arXiv:1409.1556},
	year={2014}
}
@inproceedings{NEURIPS2019_7716d0fc,
	author = {Liu, Tianyi and Chen, Minshuo and Zhou, Mo and Du, Simon S and Zhou, Enlu and Zhao, Tuo},
	booktitle = {Advances in Neural Information Processing Systems},
	title = {Towards Understanding the Importance of Shortcut Connections in Residual Networks},
	volume = {32},
	year = {2019}
}

