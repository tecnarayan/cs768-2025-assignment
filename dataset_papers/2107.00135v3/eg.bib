@article{abnar2020quantifying,
  title={Quantifying attention flow in transformers},
  author={Abnar, Samira and Zuidema, Willem},
  journal={arXiv preprint arXiv:2005.00928},
  year={2020}
}
@article{fan2019more,
  title={More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation},
  author={Fan, Quanfu and Chen, Chun-Fu and Kuehne, Hilde and Pistoia, Marco and Cox, David},
  journal={arXiv preprint arXiv:1912.00869},
  year={2019}
}
@inproceedings{seo2021look,
  title={Look Before you Speak: Visually Contextualized Utterances},
  author={Seo, Paul Hongsuck and Nagrani, Arsha and Schmid, Cordelia},
  booktitle={CVPR},
  year={2021}
}
@article{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  journal={ICCV},
  year={2021}
}

@article{hendricks2021decoupling,
  title={Decoupling the role of data, attention, and losses in multimodal transformers},
  author={Hendricks, Lisa Anne and Mellor, John and Schneider, Rosalia and Alayrac, Jean-Baptiste and Nematzadeh, Aida},
  journal={arXiv preprint arXiv:2102.00529},
  year={2021}
}
@inproceedings{li2020tea,
  title={Tea: Temporal excitation and aggregation for action recognition},
  author={Li, Yan and Ji, Bin and Shi, Xintian and Zhang, Jianguo and Kang, Bin and Wang, Limin},
  booktitle={CVPR},
  pages={909--918},
  year={2020}
}

@inproceedings{jiang2019stm,
  title={Stm: Spatiotemporal and motion encoding for action recognition},
  author={Jiang, Boyuan and Wang, MengMeng and Gan, Weihao and Wu, Wei and Yan, Junjie},
  booktitle={ICCV},
  pages={2000--2009},
  year={2019}
}
@inproceedings{chen2021localizing,
  title={Localizing Visual Sounds the Hard Way},
  author={Chen, Honglie and Xie, Weidi and Afouras, Triantafyllos and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={CVPR},
  year={2021}
}
@article{jaegle2021perceiver,
  title={Perceiver: General Perception with Iterative Attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andrew and Zisserman, Andrew and Vinyals, Oriol and Carreira, Joao},
  journal={arXiv preprint arXiv:2103.03206},
  year={2021}
}
@article{fayek2020large,
  title={Large Scale Audiovisual Learning of Sounds with Weakly Labeled Data},
  author={Fayek, Haytham M and Kumar, Anurag},
  journal={arXiv preprint arXiv:2006.01595},
  year={2020}
}
@inproceedings{wang2020makes,
  title={What makes training multi-modal classification networks hard?},
  author={Wang, Weiyao and Tran, Du and Feiszli, Matt},
  booktitle={CVPR},
  pages={12695--12705},
  year={2020}
}
@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={ICASSP},
  pages={776--780},
  year={2017},
  organization={IEEE}
}
@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020}
}
@article{smith2005development,
  title={The development of embodied cognition: Six lessons from babies},
  author={Smith, Linda and Gasser, Michael},
  journal={Artificial life},
  volume={11},
  number={1-2},
  pages={13--29},
  year={2005},
  publisher={MIT Press}
}
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@article{gong2021ast,
  title={{AST:} Audio Spectrogram Transformer},
  author={Gong, Yuan and Chung, Yu-An and Glass, James},
  journal={arXiv preprint arXiv:2104.01778},
  year={2021}
}
@inproceedings{chen2020vggsound,
  title={{VGGSound}: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={ICASSP},
  year={2020},
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}
@inproceedings{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL},
  year={2019}
}

@inproceedings{kazakos2021slow,
  title={Slow-Fast Auditory Streams for Audio Recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={ICASSP},
  pages={855--859},
  year={2021},
  organization={IEEE}
}
@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
@article{park2019specaugment,
  title={Specaugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}
@inproceedings{hershey2017cnn,
  title={{CNN} architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={ICASSP},
  pages={131--135},
  year={2017},
  organization={IEEE}
}
@article{valero2012gammatone,
  title={Gammatone cepstral coefficients: Biologically inspired features for non-speech audio classification},
  author={Valero, Xavier and Alias, Francesc},
  journal={IEEE Transactions on Multimedia},
  volume={14},
  number={6},
  pages={1684--1689},
  year={2012},
  publisher={IEEE}
}

@inproceedings{srinivas2021bottleneck,
  title={Bottleneck transformers for visual recognition},
  author={Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages_unused={770--778},
  year={2016}
}


@inproceedings{aytar2016soundnet,
  title={Soundnet: Learning sound representations from unlabeled video},
  author={Aytar, Yusuf and Vondrick, Carl and Torralba, Antonio},
  booktitle={NeurIPS},
  year={2016}
}

@inproceedings{owens2018audio,
  title={Audio-visual scene analysis with self-supervised multisensory features},
  author={Owens, Andrew and Efros, Alexei A},
  booktitle={ECCV},
  pages_unused={631--648},
  year={2018}
}
@article{salamon2017deep,
  title={Deep convolutional neural networks and data augmentation for environmental sound classification},
  author={Salamon, Justin and Bello, Juan Pablo},
  journal={IEEE Signal Processing Letters},
  volume={24},
  number={3},
  pages={279--283},
  year={2017},
  publisher={IEEE}
}
@article{lee2020parameter,
  title={Parameter Efficient Multimodal Transformers for Video Representation Learning},
  author={Lee, Sangho and Yu, Youngjae and Kim, Gunhee and Breuel, Thomas and Kautz, Jan and Song, Yale},
  journal={arXiv preprint arXiv:2012.04124},
  year={2020}
}
@inproceedings{gabeur2020multi,
  title={Multi-modal transformer for video retrieval},
  author={Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
  booktitle={ECCV},
  volume={5},
  year={2020},
  organization={Springer}
}
@inproceedings{arandjelovic2018objects,
  title={Objects that sound},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={ECCV},
  pages_unused={435--451},
  year={2018}
}
@article{ghanem2018activitynet,
  title={The activitynet large-scale activity recognition challenge 2018 summary},
  author={Ghanem, Bernard and Niebles, Juan Carlos and Snoek, Cees and Heilbron, Fabian Caba and Alwassel, Humam and Escorcia, Victor and Krishna, Ranjay and Buch, Shyamal and Dao, Cuong Duc},
  journal={arXiv preprint arXiv:1808.03766},
  year={2018}
}
@inproceedings{kazakos2019epic,
  title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5492--5501},
  year={2019}
}
@article{ryoo2019assemblenet,
  title={Assemblenet: Searching for multi-stream neural connectivity in video architectures},
  author={Ryoo, Michael S and Piergiovanni, AJ and Tan, Mingxing and Angelova, Anelia},
  journal={arXiv preprint arXiv:1905.13209},
  year={2019}
}
@article{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  journal={ICCV},
  year={2021}
}
@inproceedings{qiu2019learning,
  title={Learning spatio-temporal representation with local and global diffusion},
  author={Qiu, Zhaofan and Yao, Ting and Ngo, Chong-Wah and Tian, Xinmei and Mei, Tao},
  booktitle={CVPR},
  year={2019}
}
@article{bian2017revisiting,
  title={Revisiting the effectiveness of off-the-shelf temporal modeling approaches for large-scale video classification},
  author={Bian, Yunlong and Gan, Chuang and Liu, Xiao and Li, Fu and Long, Xiang and Li, Yandong and Qi, Heng and Zhou, Jie and Wen, Shilei and Lin, Yuanqing},
  journal={arXiv preprint arXiv:1708.03805},
  year={2017}
}
@inproceedings{xie2018rethinking,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={ECCV},
  year={2018}
}

@article{xiao2020audiovisual,
  title={Audiovisual slowfast networks for video recognition},
  author={Xiao, Fanyi and Lee, Yong Jae and Grauman, Kristen and Malik, Jitendra and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2001.08740},
  year={2020}
}
@inproceedings{huang2016deep,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={ECCV},
  year={2016}
}
@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@article{ramachandram2017deep,
  title={Deep multimodal learning: A survey on recent advances and trends},
  author={Ramachandram, Dhanesh and Taylor, Graham W},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={96--108},
  year={2017},
  publisher={IEEE}
}
@article{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Linagzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal={NeurIPS},
  year={2021}
}
@inproceedings{ngiam2011multimodal,
  title={Multimodal deep learning},
  author={Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
  booktitle={ICML},
  year={2011}
}
@inproceedings{kim2013deep,
  title={Deep learning for robust feature generation in audiovisual emotion recognition},
  author={Kim, Yelin and Lee, Honglak and Provost, Emily Mower},
  booktitle={ICASSP},
  year={2013},
  organization={IEEE}
}

@article{ephrat2018looking,
  title={Looking to listen at the cocktail party: a speaker-independent audio-visual model for speech separation},
  author={Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T and Rubinstein, Michael},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={4},
  pages={1--11},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{chen1998audio,
  title={Audio-visual integration in multimodal communication},
  author={Chen, Tsuhan and Rao, Ram R},
  journal={Proceedings of the IEEE},
  volume={86},
  number={5},
  pages={837--852},
  year={1998},
  publisher={IEEE}
}

@inproceedings{blum1998combining,
  title={Combining labeled and unlabeled data with co-training},
  author={Blum, Avrim and Mitchell, Tom},
  booktitle={Proceedings of the eleventh annual conference on Computational learning theory},
  pages={92--100},
  year={1998}
}

@article{harwath2017unsupervised,
  title={Unsupervised learning of spoken language with visual context},
  author={Harwath, David and Torralba, Antonio and Glass, James R},
  year={2017},
  journal={NeurIPS}
}

@article{tzinis2020into,
  title={Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds},
  author={Tzinis, Efthymios and Wisdom, Scott and Jansen, Aren and Hershey, Shawn and Remez, Tal and Ellis, Daniel PW and Hershey, John R},
  journal={arXiv preprint arXiv:2011.01143},
  year={2020}
}

@inproceedings{ye2019cross,
  title={Cross-modal self-attention network for referring image segmentation},
  author={Ye, Linwei and Rochan, Mrigank and Liu, Zhi and Wang, Yang},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{jansen2020coincidence,
  title={Coincidence, categorization, and consolidation: Learning to recognize sounds with minimal supervision},
  author={Jansen, Aren and Ellis, Daniel PW and Hershey, Shawn and Moore, R Channing and Plakal, Manoj and Popat, Ashok C and Saurous, Rif A},
  booktitle={ICASSP},
  year={2020},
}

@inproceedings{alayrac2020self,
  title={Self-supervised multimodal versatile networks},
  author={Alayrac, Jean-Baptiste and Recasens, Adri{\`a} and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  booktitle={NeurIPS},
  year={2020}
}

@article{wang2021multimodal,
  title={Multimodal Self-Supervised Learning of General Audio Representations},
  author={Wang, Luyu and Luc, Pauline and Recasens, Adria and Alayrac, Jean-Baptiste and Oord, Aaron van den},
  journal={arXiv preprint arXiv:2104.12807},
  year={2021}
}

@article{recasens2021broaden,
  title={Broaden Your Views for Self-Supervised Video Learning},
  author={Recasens, Adri{\`a} and Luc, Pauline and Alayrac, Jean-Baptiste and Wang, Luyu and Strub, Florian and Tallec, Corentin and Malinowski, Mateusz and Patraucean, Viorica and Altch{\'e}, Florent and Valko, Michal and others},
  journal={arXiv preprint arXiv:2103.16559},
  year={2021}
}

@inproceedings{sun2019videobert,
  title={Videobert: A joint model for video and language representation learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={CVPR},
  year={2020}
}

@article{sun2019learning,
  title={Learning video representations using contrastive bidirectional transformer},
  author={Sun, Chen and Baradel, Fabien and Murphy, Kevin and Schmid, Cordelia},
  journal={arXiv preprint arXiv:1906.05743},
  year={2019}
}

@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={ECCV},
  year={2016},
  organization={Springer}
}

@inproceedings{zhou2018temporal,
  title={Temporal relational reasoning in videos},
  author={Zhou, Bolei and Andonian, Alex and Oliva, Aude and Torralba, Antonio},
  booktitle={ECCV},
  pages={803--818},
  year={2018}
}

@inproceedings{lin2019temporal,
  title={Temporal shift module for efficient video understanding. 2019 IEEE},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={ICCV},
  pages={7082--7092},
  year={2019}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={ICCV},
  pages={6202--6211},
  year={2019}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{li2019entangled,
  title={Entangled transformer for image captioning},
  author={Li, Guang and Zhu, Linchao and Liu, Ping and Yang, Yi},
  booktitle={ICCV},
  pages={8928--8937},
  year={2019}
}

@inproceedings{iashin2020multi,
  title={Multi-modal dense video captioning},
  author={Iashin, Vladimir and Rahtu, Esa},
  booktitle={CVPR Workshops},
  pages={958--959},
  year={2020}
}

@article{gan2020foley,
  title={Foley music: Learning to generate music from videos},
  author={Gan, Chuang and Huang, Deng and Chen, Peihao and Tenenbaum, Joshua B and Torralba, Antonio},
  journal={arXiv preprint arXiv:2007.10984},
  volume={4},
  number={6},
  pages={7},
  year={2020},
  publisher={Springer}
}

@article{li2021learn,
  title={Learn to Dance with AIST++: Music Conditioned 3D Dance Generation},
  author={Li, Ruilong and Yang, Shan and Ross, David A and Kanazawa, Angjoo},
  journal={arXiv preprint arXiv:2101.08779},
  year={2021}
}
@article{li2020learning,
  title={Learning to Generate Diverse Dance Motions with Transformer},
  author={Li, Jiaman and Yin, Yihang and Chu, Hang and Zhou, Yi and Wang, Tingwu and Fidler, Sanja and Li, Hao},
  journal={arXiv preprint arXiv:2008.08171},
  year={2020}
}
@article{monfort2019moments,
  title={Moments in time dataset: one million videos for event understanding},
  author={Monfort, Mathew and Andonian, Alex and Zhou, Bolei and Ramakrishnan, Kandan and Bargal, Sarah Adel and Yan, Tom and Brown, Lisa and Fan, Quanfu and Gutfreund, Dan and Vondrick, Carl and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={2},
  pages={502--508},
  year={2019},
  publisher={IEEE}
}
@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}
@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={ICCV},
  year={2017}
}
@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={CVPR},
  year={2017}
}

@article{dehghani2021scenic,
  author={Mostafa Dehghani and Alexey Gritsenko and Anurag Arnab and Matthias Minderer and Yi Tay},
  title={{Scenic}: A {JAX} Library for Computer Vision Research and Beyond},
  year={2021},
  journal={arXiv preprint arXiv:2110.11403},
}

@inproceedings{et_iccv2021,
  author    = {Alexander Pashevich and
               Cordelia Schmid and
               Chen Sun},
  title     = {Episodic Transformer for Vision-and-Language Navigation},
  booktitle   = {ICCV},
  year      = {2021},
}
