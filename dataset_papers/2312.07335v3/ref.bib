@book{ambrosio2005gradient,
	title        = {Gradient flows: in metric spaces and in the space of probability measures},
	author       = {Ambrosio, Luigi and Gigli, Nicola and Savar{\'e}, Giuseppe},
	year         = 2005,
	publisher    = {Springer Science \& Business Media}
}
@article{andrieu2008tutorial,
  title={A tutorial on adaptive {MCMC}},
  author={Andrieu, Christophe and Thoms, Johannes},
  journal={Statistics and computing},
  volume={18},
  pages={343--373},
  year={2008},
  publisher={Springer}
}
@article{arbel2019maximum,
	title        = {Maximum mean discrepancy gradient flow},
	author       = {Arbel, Michael and Korba, Anna and Salim, Adil and Gretton, Arthur},
	year         = 2019,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 32
}
@incollection{bakry2006diffusions,
	title        = {Diffusions hypercontractives},
	author       = {Bakry, Dominique and {\'E}mery, Michel},
	year         = 2006,
	booktitle    = {S{\'e}minaire de Probabilit{\'e}s XIX 1983/84: Proceedings},
	publisher    = {Springer},
	pages        = {177--206}
}
@inproceedings{bernton2018langevin,
  title={Langevin {M}onte {C}arlo and {JKO} splitting},
  author={Bernton, Espen},
  booktitle={Conference on learning theory},
  pages={1777--1798},
  year={2018},
  organization={PMLR}
}
@book{carmona2016lectures,
	title        = {Lectures on {BSDE}s, stochastic control, and stochastic differential games with financial applications},
	author       = {Carmona, Ren{\'e}},
	year         = 2016,
	publisher    = {SIAM}
}
@article{chen2022uniform,
  title={Uniform-in-time propagation of chaos for kinetic mean field {L}angevin dynamics},
  author={Chen, Fan and Lin, Yiqing and Ren, Zhenjie and Wang, Songbo},
  journal={Electronic Journal of Probability},
  volume={29},
  pages={1--43},
  year={2024},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}
@inproceedings{cheng2018underdamped,
	title        = {Underdamped {L}angevin {MCMC}: A non-asymptotic analysis},
	author       = {Cheng, Xiang and Chatterji, Niladri S and Bartlett, Peter L and Jordan, Michael I},
	year         = 2018,
	booktitle    = {Conference on Learning Theory},
	pages        = {300--323},
	organization = {PMLR}
}
@InProceedings{wibisono2018,
  title = 	 {Sampling as optimization in the space of measures: The {L}angevin dynamics as a composite optimization problem},
  author =       {Wibisono, Andre},
  booktitle = 	 {Conference on Learning Theory},
  pages = 	 {2093--3027},
  year = 	 {2018},
  organization = {PMLR}
}
@article{peyre2019,
year = {2019},
volume = {11},
journal = {Foundations and Trends in Machine Learning},
title = {Computational Optimal Transport: With Applications to Data Science},
doi = {10.1561/2200000073},
issn = {1935-8237},
number = {5-6},
pages = {355-607},
author = {Peyr\'e, Gabriel and Cuturi, Marco}
}
@article{otto2000,
title = {{Generalization of an Inequality by {T}alagrand and Links with the Logarithmic {S}obolev Inequality}},
journal = {Journal of Functional Analysis},
volume = {173},
number = {2},
pages = {361--400},
year = {2000},
author = {Felix Otto and C\'edric Villani},
}
@article{chizat2018global,
  title={On the global convergence of gradient descent for over-parameterized models using optimal transport},
  author={Chizat, Lenaic and Bach, Francis},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{
chizat2022mean,
title={Mean-Field Langevin Dynamics : Exponential Convergence and Annealing},
author={Chizat, L{\'e}na{\"\i}c},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=BDqzLH1gEm},
note={}
}
%
@article{de2021efficient,
  title={Efficient stochastic optimisation by unadjusted {L}angevin {M}onte {C}arlo: {A}pplication to maximum marginal likelihood and empirical {B}ayesian estimation},
  author={De Bortoli, Valentin and Durmus, Alain and Pereyra, Marcelo and Vidal, Ana F},
  journal={Statistics and Computing},
  volume={31},
  pages={1--18},
  year={2021},
  publisher={Springer}
}
@article{delyon1999convergence,
  title={Convergence of a stochastic approximation version of the {EM} algorithm},
  author={Delyon, Bernard and Lavielle, Marc and Moulines, Eric},
  journal={Annals of statistics},
  pages={94--128},
  year={1999},
  publisher={JSTOR}
}
@article{dempster1977maximum,
	title        = {Maximum likelihood from incomplete data via the {EM} algorithm},
	author       = {Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
	year         = 1977,
	journal      = {Journal of the Royal Statistical Society: Series B (Methodological)},
	publisher    = {Wiley Online Library},
	volume       = 39,
	number       = 1,
	pages        = {1--22}
}
@inproceedings{diao2023forward,
  title={Forward-backward {G}aussian variational inference via {JKO} in the {B}ures-{W}asserstein Space},
  author={Diao, Michael Ziyang and Balasubramanian, Krishna and Chewi, Sinho and Salim, Adil},
  booktitle={International Conference on Machine Learning},
  pages={7960--7991},
  year={2023},
  organization={PMLR}
}
@inproceedings{dockhorn2022score,
	title        = {Score-Based Generative Modeling with Critically-Damped {L}angevin Diffusion},
	author       = {Tim Dockhorn and Arash Vahdat and Karsten Kreis},
	year         = 2022,
	booktitle    = {International Conference on Learning Representations (ICLR)}
}
@article{duchi2011adaptive,
	title        = {Adaptive subgradient methods for online learning and stochastic optimization.},
	author       = {Duchi, John and Hazan, Elad and Singer, Yoram},
	year         = 2011,
	journal      = {Journal of machine learning research},
	volume       = 12,
	number       = 7
}
@article{duncan2019geometry,
  author  = {Andrew Duncan and Nikolas N{\"u}sken and Lukasz Szpruch},
  title   = {On the geometry of {S}tein variational gradient descent},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {56},
  pages   = {1--39},
  url     = {http://jmlr.org/papers/v24/20-602.html}
}
@article{garbuno2020affine,
  title={Affine invariant interacting {L}angevin dynamics for {B}ayesian inference},
  author={Garbuno-Inigo, Alfredo and N\"{u}sken, Nikolas and Reich, Sebastian},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={19},
  number={3},
  pages={1633--1658},
  year={2020},
  publisher={SIAM}
}
@book{gelfand2000calculus,
	title        = {Calculus of Variations},
	author       = {Gelfand, Izrail Moiseevitch and Silverman, Richard A},
	year         = 2000,
	publisher    = {Courier Corporation}
}
@article{glaser2021kale,
	title        = {Kale flow: A relaxed {KL} gradient flow for probabilities with disjoint support},
	author       = {Glaser, Pierre and Arbel, Michael and Gretton, Arthur},
	year         = 2021,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 34,
	pages        = {8018--8031}
}
@book{good1983,
	title        = {Good thinking: The foundations of probability and its applications},
	author       = {Good, Irving John},
	year         = 1983,
	publisher    = {University of Minnesota Press}
}
@article{goodfellow2020generative,
	title        = {Generative adversarial networks},
	author       = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year         = 2020,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 63,
	number       = 11,
	pages        = {139--144}
}
@article{gross1975logarithmic,
	title        = {Logarithmic {S}obolev inequalities},
	author       = {Gross, Leonard},
	year         = 1975,
	journal      = {American Journal of Mathematics},
	publisher    = {JSTOR},
	volume       = 97,
	number       = 4,
	pages        = {1061--1083}
}
@inproceedings{han2017alternating,
	title        = {Alternating back-propagation for generator network},
	author       = {Han, Tian and Lu, Yang and Zhu, Song-Chun and Wu, Ying Nian},
	year         = 2017,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 31,
	number       = 1
}
@article{heusel2017gans,
	title        = {{GAN}s trained by a two time-scale update rule converge to a local nash equilibrium},
	author       = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
	year         = 2017,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 30
}
@article{hinton2002training,
  title={Training products of experts by minimizing contrastive divergence},
  author={Hinton, Geoffrey E},
  journal={Neural computation},
  volume={14},
  number={8},
  pages={1771--1800},
  year={2002},
  publisher={MIT Press}
}
@article{hochbruck2010exponential,
	title        = {Exponential integrators},
	author       = {Hochbruck, Marlis and Ostermann, Alexander},
	year         = 2010,
	journal      = {Acta Numerica},
	publisher    = {Cambridge University Press},
	volume       = 19,
	pages        = {209--286}
}
@inproceedings{hu2021mean,
  title={Mean-field {L}angevin dynamics and energy landscape of neural networks},
  author={Hu, Kaitong and Ren, Zhenjie and {\v{S}}i{\v{s}}ka, David and Szpruch, {\L}ukasz},
  booktitle={Annales de l'Institut Henri Poincare (B) Probabilites et statistiques},
  volume={57},
  number={4},
  pages={2043--2065},
  year={2021},
  organization={Institut Henri Poincar{\'e}}
}
@article{jordan1998variational,
	title        = {The variational formulation of the {F}okker--{P}lanck equation},
	author       = {Jordan, Richard and Kinderlehrer, David and Otto, Felix},
	year         = 1998,
	journal      = {SIAM Journal on Mathematical Analysis},
	publisher    = {SIAM},
	volume       = 29,
	number       = 1,
	pages        = {1--17}
}
@inproceedings{kac1956foundations,
	title        = {Foundations of kinetic theory},
	author       = {Kac, Mark},
	year         = 1956,
	booktitle    = {Proceedings of The third Berkeley symposium on mathematical statistics and probability},
	volume       = 3,
	number       = 600,
	pages        = {171--197}
}
@inproceedings{kingma2013auto,
  author       = {Diederik P. Kingma and Max Welling},
  editor       = {Yoshua Bengio and Yann LeCun},
  title        = {Auto-Encoding Variational {B}ayes},
  booktitle    = {2nd International Conference on Learning Representations, {ICLR} 2014,
                  Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year         = {2014},
  url          = {http://arxiv.org/abs/1312.6114},
  timestamp    = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kingma2014adam,
  author       = {Diederik P. Kingma and Jimmy Ba},
  editor       = {Yoshua Bengio and Yann LeCun},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1412.6980},
  timestamp    = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{krizhevsky2009learning,
	title        = {Learning multiple layers of features from tiny images},
	author       = {Krizhevsky, Alex and Hinton, Geoffrey},
	year         = 2009,
	publisher    = {Toronto, ON, Canada}
}
@article{kruger2003frechet,
	title        = {On {F}r{\'e}chet subdifferentials},
	author       = {Kruger, A Ya},
	year         = 2003,
	journal      = {Journal of Mathematical Sciences},
	publisher    = {Springer},
	volume       = 116,
	number       = 3,
	pages        = {3325--3358}
}
@inproceedings{Kuntz2022,
	title        = {Particle algorithms for maximum likelihood training of latent variable models},
	author       = {J. Kuntz and J. N. Lim and A. M. Johansen},
	year         = 2023,
	month        = apr,
	booktitle    = {Proceedings on 26th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	series       = {Proceedings of Machine Learning Research},
	volume       = 206,
	pages        = {5134--5180},
	url          = {https://proceedings.mlr.press/v206/kuntz23a.html},
	optcrossref  = {},
	optkey       = {},
	opteditor    = {},
	optnumber    = {},
	optaddress   = {},
	optorganization = {},
	optpublisher = {},
	optnote      = {Oral presentation.},
	optannote    = {},
	eprint       = {2204.12965}
}
@article{lambert2022variational,
  title={Variational inference via {W}asserstein gradient flows},
  author={Lambert, Marc and Chewi, Sinho and Bach, Francis and Bonnabel, Silv{\`e}re and Rigollet, Philippe},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14434--14447},
  year={2022}
}
@article{lecun1998gradient,
	title        = {Gradient-based learning applied to document recognition},
	author       = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	year         = 1998,
	journal      = {Proceedings of the IEEE},
	publisher    = {Ieee},
	volume       = 86,
	number       = 11,
	pages        = {2278--2324}
}
@inproceedings{li2016preconditioned,
	title        = {Preconditioned stochastic gradient {L}angevin dynamics for deep neural networks},
	author       = {Li, Chunyuan and Chen, Changyou and Carlson, David and Carin, Lawrence},
	year         = 2016,
	booktitle    = {Proceedings of the AAAI conference on artificial intelligence},
	volume       = 30,
	number       = 1
}
@article{liu2017stein,
	title        = {Stein variational gradient descent as gradient flow},
	author       = {Liu, Qiang},
	year         = 2017,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 30
}
@inbook{Loève1977,
	title        = {Probability Concepts},
	author       = {Lo{\`e}ve, M.},
	year         = 1977,
	booktitle    = {Probability Theory I},
	publisher    = {Springer New York},
	address      = {New York, NY},
	pages        = {151--176},
	doi          = {10.1007/978-1-4684-9464-8_4},
	isbn         = {978-1-4684-9464-8},
	url          = {https://doi.org/10.1007/978-1-4684-9464-8_4},
	abstract     = {Probability theory has its own terminology, born from and directly related and adapted to its intuitive background; for the concepts and problems of probability theory are born from and evolve with the analysis of random phenomena. As a branch of mathematics, however, probability theory partakes of and contributes to the whole domain of mathematics and, at present, its general set-up is expressible in terms of measure spaces and measurable functions. We give below a first table of correspondences between the probability and measure theoretic terms. Within parentheses appear the abbreviations to be used throughout this book.}
}
@article{lyapunov1992general,
	title        = {The general problem of the stability of motion},
	author       = {Lyapunov, Aleksandr Mikhailovich},
	year         = 1992,
	journal      = {International Journal of Control},
	publisher    = {Taylor \& Francis},
	volume       = 55,
	number       = 3,
	pages        = {531--534}
}
@article{ma2019there,
	title        = {{Is there an analog of Nesterov acceleration for gradient-based {MCMC}?}},
	author       = {Yi-An Ma and Niladri S. Chatterji and Xiang Cheng and Nicolas Flammarion and Peter L. Bartlett and Michael I. Jordan},
	year         = 2021,
	journal      = {Bernoulli},
	publisher    = {Bernoulli Society for Mathematical Statistics and Probability},
	volume       = 27,
	number       = 3,
	pages        = {1942 -- 1992},
	doi          = {10.3150/20-BEJ1297},
	url          = {https://doi.org/10.3150/20-BEJ1297},
	keywords     = {accelerated gradient descent, Langevin Monte Carlo, Markov chain Monte Carlo, sampling algorithms}
}
@article{maddison2018hamiltonian,
	title        = {Hamiltonian descent methods},
	author       = {Maddison, Chris J and Paulin, Daniel and Teh, Yee Whye and O'Donoghue, Brendan and Doucet, Arnaud},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1809.05042}
}
@article{maoutsa2020interacting,
	title        = {Interacting particle solutions of {F}okker--{P}lanck equations through gradient--log--density estimation},
	author       = {Maoutsa, Dimitra and Reich, Sebastian and Opper, Manfred},
	year         = 2020,
	journal      = {Entropy},
	publisher    = {MDPI},
	volume       = 22,
	number       = 8,
	pages        = 802
}
@inproceedings{martens2010deep,
	title        = {Deep learning via {H}essian-free optimization.},
	author       = {Martens, James},
	year         = 2010,
	booktitle    = {International Conference on Machine Learning},
	volume       = 27,
	pages        = {735--742}
}
@book{mccall2010classical,
	title        = {Classical Mechanics: From {N}ewton to {E}instein: A Modern Introduction},
	author       = {McCall, Martin W},
	year         = 2010,
	publisher    = {John Wiley \& Sons}
}
@article{mckean1966class,
	title        = {A class of {M}arkov processes associated with nonlinear parabolic equations},
	author       = {McKean Jr, Henry P},
	year         = 1966,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 56,
	number       = 6,
	pages        = {1907--1911}
}
@article{mclachlan2001conformal,
	title        = {Conformal {H}amiltonian systems},
	author       = {McLachlan, Robert and Perlmutter, Matthew},
	year         = 2001,
	journal      = {Journal of Geometry and Physics},
	publisher    = {Elsevier},
	volume       = 39,
	number       = 4,
	pages        = {276--300}
}
@article{mei2018mean,
  title={A mean field view of the landscape of two-layer neural networks},
  author={Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={33},
  pages={E7665--E7671},
  year={2018},
  publisher={National Acad Sciences}
}
@inproceedings{mroueh2019sobolev,
	title        = {Sobolev descent},
	author       = {Mroueh, Youssef and Sercu, Tom and Raj, Anant},
	year         = 2019,
	booktitle    = {The 22nd International Conference on Artificial Intelligence and Statistics},
	pages        = {2976--2985},
	organization = {PMLR}
}
@article{neal1998view,
	title        = {A view of the {EM} algorithm that justifies incremental, sparse, and other variants},
	author       = {Neal, Radford M and Hinton, Geoffrey E},
	year         = 1998,
	journal      = {Learning in graphical models},
	publisher    = {Springer},
	pages        = {355--368}
}
@book{nemirovskij1983problem,
	title        = {Problem complexity and method efficiency in optimization},
	author       = {Nemirovskij, Arkadij Semenovi{\v{c}} and Yudin, David Borisovich},
	year         = 1983,
	publisher    = {Wiley-Interscience},
	translator   = {Dawson}
}
Old References
@inproceedings{nesterov1983method,
	title        = {A method of solving a convex programming problem with convergence rate $\mathcal{O}\bigl(\frac{1 }{k^2}\bigr)$},
	author       = {Nesterov, Yurii Evgen'evich},
	year         = 1983,
	booktitle    = {Doklady Akademii Nauk},
	volume       = 269,
	number       = 3,
	pages        = {543--547},
	organization = {Russian Academy of Sciences}
}
@book{nesterov2003introductory,
	title        = {Introductory Lectures on Convex Optimization: A Basic Course},
	author       = {Nesterov, Yurii},
	year         = 2003,
	publisher    = {Springer Science \& Business Media}
}
@inproceedings{nijkamp2020learning,
	title        = {Learning multi-layer latent variable model via variational optimization of short run {MCMC} for approximate inference},
	author       = {Nijkamp, Erik and Pang, Bo and Han, Tian and Zhou, Linqi and Zhu, Song-Chun and Wu, Ying Nian},
	year         = 2020,
	booktitle    = {Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
	pages        = {361--378},
	organization = {Springer}
}
@article{nitanda2017stochastic,
  title={Stochastic particle gradient descent for infinite ensembles},
  author={Nitanda, Atsushi and Suzuki, Taiji},
  journal={arXiv preprint arXiv:1712.05438},
  year={2017}
}
@inproceedings{nitanda2022convex,
  title={Convex analysis of the mean field {L}angevin dynamics},
  author={Nitanda, Atsushi and Wu, Denny and Suzuki, Taiji},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={9741--9757},
  year={2022},
  organization={PMLR}
}
@article{o2015adaptive,
	title        = {Adaptive restart for accelerated gradient schemes},
	author       = {O’Donoghue, Brendan and Candes, Emmanuel},
	year         = 2015,
	journal      = {Foundations of Computational Mathematics},
	publisher    = {Springer},
	volume       = 15,
	pages        = {715--732}
}
@article{pang2020learning,
	title        = {Learning latent space energy-based prior model},
	author       = {Pang, Bo and Han, Tian and Nijkamp, Erik and Zhu, Song-Chun and Wu, Ying Nian},
	year         = 2020,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 33,
	pages        = {21994--22008}
}
@book{platen2010numerical,
	title        = {Numerical Solution of Stochastic Differential Equations with Jumps in Finance},
	author       = {Platen, Eckhard and Bruti-Liberati, Nicola},
	year         = 2010,
	publisher    = {Springer Science \& Business Media}
}
@article{polyak1964gradient,
	title        = {Gradient methods for solving equations and inequalities},
	author       = {Polyak, Boris T},
	year         = 1964,
	journal      = {USSR Computational Mathematics and Mathematical Physics},
	publisher    = {Elsevier},
	volume       = 4,
	number       = 6,
	pages        = {17--32}
}
@article{polyak1964some,
	title        = {Some methods of speeding up the convergence of iteration methods},
	author       = {Polyak, Boris T},
	year         = 1964,
	journal      = {USSR Computational Mathematics and Mathematical Physics},
	publisher    = {Elsevier},
	volume       = 4,
	number       = 5,
	pages        = {1--17}
}
@inproceedings{riou2023adaptive,
  title={Adaptive Tuning for {M}etropolis Adjusted {L}angevin Trajectories},
  author={Riou-Durand, Lionel and Sountsov, Pavel and Vogrinc, Jure and Margossian, Charles and Power, Sam},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={8102--8116},
  year={2023},
  organization={PMLR}
}
@article{roberts2009examples,
  title={Examples of adaptive {MCMC}},
  author={Roberts, Gareth O and Rosenthal, Jeffrey S},
  journal={Journal of computational and graphical statistics},
  volume={18},
  number={2},
  pages={349--367},
  year={2009},
  publisher={Taylor \& Francis}
}
@article{sanz2021wasserstein,
	title        = {Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations},
	author       = {Sanz-Serna, Jesus Maria and Zygalakis, Konstantinos C},
	year         = 2021,
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLRORG},
	volume       = 22,
	number       = 1,
	pages        = {11006--11042}
}
@article{santambrogio2017euclidean,
  title={$\{$Euclidean, metric, and Wasserstein$\}$ gradient flows: an overview},
  author={Santambrogio, Filippo},
  journal={Bulletin of Mathematical Sciences},
  volume={7},
  pages={87--154},
  year={2017},
  publisher={Springer}
}
@InProceedings{sharrock2023coinem,
  title = 	 {Coin Sampling: Gradient-Based {B}ayesian Inference without Learning Rates},
  author =       {Sharrock, Louis and Nemeth, Christopher},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {30850--30882},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/sharrock23a/sharrock23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/sharrock23a.html},
  abstract = 	 {In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortunately, the properties of such methods invariably depend on hyperparameters such as the learning rate, which must be carefully tuned by the practitioner in order to ensure convergence to the target measure at a suitable rate. In this paper, we introduce a suite of new particle-based methods for scalable Bayesian inference based on coin betting, which are entirely learning-rate free. We illustrate the performance of our approach on a range of numerical examples, including several high-dimensional models and datasets, demonstrating comparable performance to other ParVI algorithms with no need to tune a learning rate.}
}
@article{shi2021understanding,
	title        = {Understanding the acceleration phenomenon via high-resolution differential equations},
	author       = {Shi, Bin and Du, Simon S and Jordan, Michael I and Su, Weijie J},
	year         = 2021,
	journal      = {Mathematical Programming},
	publisher    = {Springer},
	volume       = 195,
	pages        = {79--148}
}
@article{silvester2000determinants,
	title        = {Determinants of block matrices},
	author       = {Silvester, John R},
	year         = 2000,
	journal      = {The Mathematical Gazette},
	publisher    = {Cambridge University Press},
	volume       = 84,
	number       = 501,
	pages        = {460--467}
}
@inproceedings{song2021scorebased,
	title        = {Score-Based Generative Modeling through Stochastic Differential Equations},
	author       = {Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=PxTIG12RRHS}
}
@inproceedings{staib2019escaping,
	title        = {Escaping saddle points with adaptive gradient methods},
	author       = {Staib, Matthew and Reddi, Sashank and Kale, Satyen and Kumar, Sanjiv and Sra, Suvrit},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {5956--5965},
	organization = {PMLR}
}
@article{su2014differential,
	title        = {A differential equation for modeling {N}esterov’s accelerated gradient method: theory and insights},
	author       = {Su, Weijie and Boyd, Stephen and Candes, Emmanuel},
	year         = 2014,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 27
}
@inproceedings{sutskever2013importance,
	title        = {On the importance of initialization and momentum in deep learning},
	author       = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
	year         = 2013,
	booktitle    = {International Conference on Machine Learning},
	pages        = {1139--1147},
	organization = {PMLR}
}

@inproceedings{
suzuki2023convergence,
title={Mean-field Langevin dynamics: Time-space discretization, stochastic gradient, and variance reduction},
author={Taiji Suzuki and Denny Wu and Atsushi Nitanda},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=9STYRIVx6u}
}
@article{tieleman2012lecture,
	title        = {Lecture 6.5-rmsprop, coursera: Neural networks for machine learning},
	author       = {Tieleman, Tijmen and Hinton, Geoffrey},
	year         = 2012,
	journal      = {University of Toronto, Technical Report},
	volume       = 6
}

@inproceedings{tomczak2018vae,
	title        = {{VAE} with a {V}amp{P}rior},
	author       = {Tomczak, Jakub and Welling, Max},
	year         = 2018,
	booktitle    = {International Conference on Artificial Intelligence and Statistics},
	pages        = {1214--1223},
	organization = {PMLR}
}
@article{van2014probability,
	title        = {Probability in high dimension},
	author       = {Van Handel, Ramon},
	year         = 2014,
	journal      = {Lecture Notes (Princeton University)}
}
@book{villani2009optimal,
	title        = {Optimal transport: old and new},
	author       = {Villani, C{\'e}dric},
	year         = 2009,
	publisher    = {Springer},
	volume       = 338
}
%
@article{wibisono2016variational,
	title        = {A variational perspective on accelerated methods in optimization},
	author       = {Wibisono, Andre and Wilson, Ashia C and Jordan, Michael I},
	year         = 2016,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 113,
	number       = 47,
	pages        = {E7351--E7358}
}
%
@article{caprio2024error,
  title={Error bounds for particle gradient descent, and extensions of the log-{S}obolev and {T}alagrand inequalities},
  author={Caprio, Rocco and Kuntz, Juan and Power, Samuel and Johansen, Adam M},
  journal={arXiv preprint arXiv:2403.02004},
  year={2024}
}
%
@article{wilson2016lyapunov,
  title={A {L}yapunov analysis of accelerated methods in optimization},
  author={Wilson, Ashia C and Recht, Ben and Jordan, Michael I},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={113},
  pages={1--34},
  year={2021}
}
@article{yao2022mean,
  title={Mean field variational inference via {W}asserstein gradient flow},
  author={Yao, Rentian and Yang, Yun},
  journal={arXiv preprint arXiv:2207.08074},
  year={2022}
}