%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Matthias Geissbühler at 2011-03-21 13:46:46 +0100 


%% Saved with string encoding Unicode (UTF-8) 

@article{doi:10.1162/089976600300015420,
	author = {Amari, Shun-ichi and Park, Hyeyoung and Fukumizu, Kenji},
	title = {Adaptive Method of Realizing Natural Gradient Learning for Multilayer Perceptrons},
	journal = {Neural Computation},
	volume = {12},
	number = {6},
	pages = {1399-1409},
	year = {2000},
	doi = {10.1162/089976600300015420},
	
	URL = { 
	https://doi.org/10.1162/089976600300015420
	
	},
	eprint = { 
	https://doi.org/10.1162/089976600300015420
	
	}	
}

@article{lecun2015deep,
	title={Deep learning},
	author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	journal={nature},
	volume={521},
	number={7553},
	pages={436--444},
	year={2015},
	publisher={Nature Publishing Group}
}


@book{woodbury,
	series = {{SRG} {Memorandum} report ; 42},
	title = {Inverting modified matrices},
	language = {English},
	publisher = {Princeton, NJ: Department of Statistics, Princeton University},
	author = {Woodbury, Max A.},
	editor = {{Princeton University}},
	year = {1950},
	keywords = {Statistics, Matrices}
}


@article{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  journal={arXiv preprint arXiv:2003.03033},
  year={2020}
}

@misc{devlin2018bert,
	title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
	year={2018},
	eprint={1810.04805},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}
@incollection{NIPS1989_250,
	title = {Optimal Brain Damage},
	author = {LeCun, Yann and John S. Denker and Sara A. Solla},
	booktitle = {Advances in Neural Information Processing Systems 2},
	editor = {D. S. Touretzky},
	pages = {598--605},
	year = {1990},
	publisher = {Morgan-Kaufmann},
	url = {http://papers.nips.cc/paper/250-optimal-brain-damage.pdf}
}

@article{He_2016,
	title={Deep Residual Learning for Image Recognition},
	ISBN={9781467388511},
	url={http://dx.doi.org/10.1109/CVPR.2016.90},
	DOI={10.1109/cvpr.2016.90},
	journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	publisher={IEEE},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year={2016},
	month={Jun}
}
@article {Kirkpatrick3521,
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	title = {Overcoming catastrophic forgetting in neural networks},
	volume = {114},
	number = {13},
	pages = {3521--3526},
	year = {2017},
	doi = {10.1073/pnas.1611835114},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/114/13/3521},
	eprint = {https://www.pnas.org/content/114/13/3521.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@misc{wortsman2019discovering,
	title={Discovering Neural Wirings},
	author={Mitchell Wortsman and Ali Farhadi and Mohammad Rastegari},
	year={2019},
	eprint={1906.00586},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}


@misc{ONNX,
	title={The ONNX Runtime},
	author={Microsoft Corporation},
	year={2002},
	eprint={https://github.com/microsoft/onnxruntime},
}



@article{Gale2019TheSO,
	title={The State of Sparsity in Deep Neural Networks},
	author={Trevor Gale and Erich Elsen and Sara Hooker},
	journal={ArXiv},
	year={2019},
	volume={abs/1902.09574}
}

@article{Evci2019RiggingTL,
	title={Rigging the Lottery: Making All Tickets Winners},
	author={Utku Evci and Trevor Gale and Jacob Menick and Pablo Samuel Castro and Erich Elsen},
	journal={ArXiv},
	year={2019},
	volume={abs/1911.11134}
}

@article{Kusupati2020SoftTW,
	title={Soft Threshold Weight Reparameterization for Learnable Sparsity},
	author={Aditya Kusupati and Vivek Ramanujan and Raghav Somani and Mitchell Wortsman and Prateek Jain and Sham M. Kakade and Ali Farhadi},
	journal={ArXiv},
	year={2020},
	volume={abs/2002.03231}
}



@misc{martens2014new,
title={New insights and perspectives on the natural gradient method},
author={James Martens},
year={2014},
eprint={1412.1193},
archivePrefix={arXiv},
primaryClass={cs.LG}
}


@misc{NM,
title={Early Access Signup for the Sparse Inference Engine},
author={Neural Magic Inc.},
year={2020},
url={https://neuralmagic.com/earlyaccess/}
}


@misc{hinton2015distilling,
	title={Distilling the Knowledge in a Neural Network},
	author={Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
	year={2015},
	eprint={1503.02531},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@article{doi:10.1162/089976698300017746,
	author = {Amari, Shun-ichi},
	title = {Natural Gradient Works Efficiently in Learning},
	journal = {Neural Computation},
	volume = {10},
	number = {2},
	pages = {251-276},
	year = {1998},
	doi = {10.1162/089976698300017746},
	
	URL = { 
	https://doi.org/10.1162/089976698300017746
	
	},
	eprint = { 
	https://doi.org/10.1162/089976698300017746
	
	}
}

@misc{thomas2019interplay,
	title={On the interplay between noise and curvature and its effect on optimization and generalization},
	author={Valentin Thomas and Fabian Pedregosa and Bart van Merriënboer and Pierre-Antoine Mangazol and Yoshua Bengio and Nicolas Le Roux},
	year={2019},
	eprint={1906.07774},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{Howard2017MobileNetsEC,
	title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
	author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
	journal={ArXiv},
	year={2017},
	volume={abs/1704.04861}
}
@article{Schraudolph02,
	author    = {Nicol N. Schraudolph},
	title     = {Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent},
	journal   = {Neural Computation},
	volume    = {14},
	number    = {7},
	pages     = {1723--1738},
	year      = {2002},
	url       = {https://doi.org/10.1162/08997660260028683},
	doi       = {10.1162/08997660260028683},
	timestamp = {Wed, 14 Nov 2018 10:31:21 +0100},
	biburl    = {https://dblp.org/rec/journals/neco/Schraudolph02.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Osawa_2019,
	title={Large-Scale Distributed Second-Order Optimization Using Kronecker-Factored Approximate Curvature for Deep Convolutional Neural Networks},
	ISBN={9781728132938},
	url={http://dx.doi.org/10.1109/CVPR.2019.01264},
	DOI={10.1109/cvpr.2019.01264},
	journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	publisher={IEEE},
	author={Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse, Akira and Yokota, Rio and Matsuoka, Satoshi},
	year={2019},
	month={Jun}
}
@inproceedings{WuMGLB17,
	author={Yuhuai Wu and Elman Mansimov and Roger B. Grosse and Shun Liao and Jimmy Ba},
	title={Second-order Optimization for Deep Reinforcement Learning using Kronecker-factored Approximation},
	year={2017},
	cdate={1483228800000},
	pages={5285-5294},
	url={http://papers.nips.cc/paper/7112-second-order-optimization-for-deep-reinforcement-learning-using-kronecker-factored-approximation},
	booktitle={NIPS},
}

@article{ba2016distributed,
	title={Distributed second-order optimization using Kronecker-factored approximations},
	author={Ba, Jimmy and Grosse, Roger and Martens, James},
	year={2016}
}
@misc{
	zeng2019mlprune,
	title={{MLP}rune: Multi-Layer Pruning for Automated Neural Network Compression},
	author={Wenyuan Zeng and Raquel Urtasun},
	year={2019},
	url={https://openreview.net/forum?id=r1g5b2RcKm},
}
@article{Heskes2000OnNL,
	title={On Natural Learning and Pruning in Multilayered Perceptrons},
	author={Tom Heskes},
	journal={Neural Computation},
	year={2000},
	volume={12},
	pages={881-901}
}
@misc{gale2019state,
	title={The State of Sparsity in Deep Neural Networks},
	author={Trevor Gale and Erich Elsen and Sara Hooker},
	year={2019},
	eprint={1902.09574},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@misc{louizos2017learning,
	title={Learning Sparse Neural Networks through $L_0$ Regularization},
	author={Christos Louizos and Max Welling and Diederik P. Kingma},
	year={2017},
	eprint={1712.01312},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{molchanov2017variational,
	title={Variational Dropout Sparsifies Deep Neural Networks},
	author={Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},
	year={2017},
	eprint={1701.05369},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{zhu2017prune,
	title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
	author={Michael Zhu and Suyog Gupta},
	year={2017},
	eprint={1710.01878},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{
	sagun2018empirical,
	title={Empirical Analysis of the Hessian of Over-Parametrized Neural Networks},
	author={Levent Sagun and Utku Evci and V. Ugur Guney and Yann Dauphin and Leon Bottou},
	year={2018},
	url={https://openreview.net/forum?id=rJrTwxbCb},
}

@article{10.1162/neco.1994.6.1.147,
	author = {Pearlmutter, Barak A.},
	title = {Fast Exact Multiplication by the Hessian},
	year = {1994},
	issue_date = {January 1994},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
	volume = {6},
	number = {1},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1994.6.1.147},
	doi = {10.1162/neco.1994.6.1.147},
	journal = {Neural Comput.},
	month = jan,
	pages = {147–160},
	numpages = {14}
}

@misc{theis2018faster,
	title={Faster gaze prediction with dense networks and Fisher pruning},
	author={Lucas Theis and Iryna Korshunova and Alykhan Tejani and Ferenc Huszár},
	year={2018},
	eprint={1801.05787},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@inproceedings{martens_free,
	author = {Martens, James},
	title = {Deep Learning via Hessian-Free Optimization},
	year = {2010},
	isbn = {9781605589077},
	publisher = {Omnipress},
	address = {Madison, WI, USA},
	booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
	pages = {735–742},
	numpages = {8},
	location = {Haifa, Israel},
	series = {ICML’10}
}
@misc{agarwal2016secondorder,
	title={Second-Order Stochastic Optimization for Machine Learning in Linear Time},
	author={Naman Agarwal and Brian Bullins and Elad Hazan},
	year={2016},
	eprint={1602.03943},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{dong2017learning,
	title={Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon},
	author={Xin Dong and Shangyu Chen and Sinno Jialin Pan},
	year={2017},
	eprint={1705.07565},
	archivePrefix={arXiv},
	primaryClass={cs.NE}
}
@incollection{NIPS1992_647,
	title = {Second order derivatives for network pruning: Optimal Brain Surgeon},
	author = {Hassibi, Babak and David G. Stork},
	booktitle = {Advances in Neural Information Processing Systems 5},
	editor = {S. J. Hanson and J. D. Cowan and C. L. Giles},
	pages = {164--171},
	year = {1993},
	publisher = {Morgan-Kaufmann},
	url = {http://papers.nips.cc/paper/647-second-order-derivatives-for-network-pruning-optimal-brain-surgeon.pdf}
}

@inproceedings{
	krishnan2018neumann,
	title={Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks},
	author={Shankar Krishnan and Ying Xiao and Rif. A. Saurous},
	booktitle={International Conference on Learning Representations},
	year={2018},
	url={https://openreview.net/forum?id=rkLyJl-0-},
}

@misc{kingma2014adam,
	title={Adam: A Method for Stochastic Optimization},
	author={Diederik P. Kingma and Jimmy Ba},
	year={2014},
	eprint={1412.6980},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@article{Duchi2010AdaptiveSM,
	title={Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
	author={John C. Duchi and Elad Hazan and Yoram Singer},
	journal={J. Mach. Learn. Res.},
	year={2010},
	volume={12},
	pages={2121-2159}
}
@misc{
	laurent2018an,
	title={An Evaluation of Fisher Approximations Beyond Kronecker Factorization},
	author={César Laurent and Thomas George and Xavier Bouthillier and Nicolas Ballas and Pascal Vincent},
	year={2018},
	url={https://openreview.net/forum?id=ryVC6tkwG}
}
@inproceedings{
	martens2018kroneckerfactored,
	title={Kronecker-factored Curvature Approximations for Recurrent Neural Networks},
	author={James Martens and Jimmy Ba and Matt Johnson},
	booktitle={International Conference on Learning Representations},
	year={2018},
	url={https://openreview.net/forum?id=HyMTkQZAb},
}
@misc{grosse2016kroneckerfactored,
	title={A Kronecker-factored approximate Fisher matrix for convolution layers},
	author={Roger Grosse and James Martens},
	year={2016},
	eprint={1602.01407},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{wang2019eigendamage,
	title={EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis},
	author={Chaoqi Wang and Roger Grosse and Sanja Fidler and Guodong Zhang},
	year={2019},
	eprint={1905.05934},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{martens2015optimizing,
	title={Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
	author={James Martens and Roger Grosse},
	year={2015},
	eprint={1503.05671},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@InProceedings{leroux2008topmoumoute,
	author = {Le Roux, Nicolas and Manzagol, Pierre-Antoine and Bengio, Yoshua},
	title = {Topmoumoute online natural gradient algorithm},
	booktitle = {NIPS2007},
	year = {2008},
	month = {January},
	url = {https://www.microsoft.com/en-us/research/publication/topmoumoute-online-natural-gradient-algorithm/},
	edition = {NIPS2007},
}

@misc{kunstner2019limitations,
	title={Limitations of the Empirical Fisher Approximation for Natural Gradient Descent},
	author={Frederik Kunstner and Lukas Balles and Philipp Hennig},
	year={2019},
	eprint={1905.12558},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{schmidhuber2015deep,
	title={Deep learning in neural networks: An overview},
	author={Schmidhuber, J{\"u}rgen},
	journal={Neural networks},
	volume={61},
	pages={85--117},
	year={2015},
	publisher={Elsevier}
}
@techreport{atc13,
	Address = {California},
	Author = {{Applied Technology Council}},
	Date-Modified = {2011-03-21 13:46:44 +0100},
	Institution = {Seismic Safety Commission, Applied Technology Council (\textsc{atc})},
	Keywords = {ATC},
	Owner = {oropeza},
	Timestamp = {2008.01.11},
	Title = {{E}arthquake damage evaluation data for {C}alifornia},
	Year = {1985}}

@inproceedings{
	Lin2020Dynamic,
	title={Dynamic Model Pruning with Feedback},
	author={Tao Lin and Sebastian U. Stich and Luis Barba and Daniil Dmitriev and Martin Jaggi},
	booktitle={International Conference on Learning Representations},
	year={2020},
	url={https://openreview.net/forum?id=SJem8lSFwB}
}

@misc{dettmers2019sparse,
	title={Sparse Networks from Scratch: Faster Training without Losing Performance},
	author={Tim Dettmers and Luke Zettlemoyer},
	year={2019},
	eprint={1907.04840},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@misc{mostafa2019parameter,
	title={Parameter Efficient Training of Deep Convolutional Neural Networks by Dynamic Sparse Reparameterization},
	author={Hesham Mostafa and Xin Wang},
	year={2019},
	eprint={1902.05967},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{russakovsky2015imagenet,
	title={Imagenet large scale visual recognition challenge},
	author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
	journal={International Journal of Computer Vision},
	volume={115},
	number={3},
	pages={211--252},
	year={2015},
	publisher={Springer}
}


@inproceedings{mozer1989skeletonization,
	title={Skeletonization: A technique for trimming the fat from a network via relevance assessment},
	author={Mozer, Michael C and Smolensky, Paul},
	booktitle={Advances in neural information processing systems},
	pages={107--115},
	year={1989}
}
@article{Luo_2017,
	title={ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression},
	ISBN={9781538610329},
	url={http://dx.doi.org/10.1109/ICCV.2017.541},
	DOI={10.1109/iccv.2017.541},
	journal={2017 IEEE International Conference on Computer Vision (ICCV)},
	publisher={IEEE},
	author={Luo, Jian-Hao and Wu, Jianxin and Lin, Weiyao},
	year={2017},
	month={Oct}
}
@inproceedings{Radford2018ImprovingLU,
	title={Improving Language Understanding by Generative Pre-Training},
	author={Alec Radford},
	year={2018}
}
@incollection{NIPS2015_5638,
	title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	booktitle = {Advances in Neural Information Processing Systems 28},
	editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	pages = {91--99},
	year = {2015},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf}
}

@Miscellaneous{rajbhandari2019zero,
	author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
	title = {ZeRO: Memory Optimization Towards Training A Trillion Parameter Models},
	howpublished = {ArXiv},
	year = {2019},
	month = {October},
	url = {https://www.microsoft.com/en-us/research/publication/zero-memory-optimization-towards-training-a-trillion-parameter-models/},
}
@misc{koh2017understanding,
	title={Understanding Black-box Predictions via Influence Functions},
	author={Pang Wei Koh and Percy Liang},
	year={2017},
	eprint={1703.04730},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}
@misc{frankle2018lottery,
	title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
	author={Jonathan Frankle and Michael Carbin},
	year={2018},
	eprint={1803.03635},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{Singh:277227,
	title = {Efficient second-order methods for model compression},
	author = {Singh, Sidak Pal},
	journal={EPFL Master Thesis},
	year = {2020},
	url = {http://infoscience.epfl.ch/record/277227},
}


@article{nesterov2006cubic,
	title={Cubic regularization of Newton method and its global performance},
	author={Nesterov, Yurii and Polyak, Boris T},
	journal={Mathematical Programming},
	volume={108},
	number={1},
	pages={177--205},
	year={2006},
	publisher={Springer}
}
@inproceedings{Chen2015CompressingNN,
	title={Compressing Neural Networks with the Hashing Trick},
	author={Wenlin Chen and James T. Wilson and Stephen Tyree and Kilian Q. Weinberger and Yixin Chen},
	booktitle={ICML},
	year={2015}
}
@article{Li2016PruningFF,
	title={Pruning Filters for Efficient ConvNets},
	author={Hao Li and Asim Kadav and Igor Durdanovic and Hanan Samet and Hans Peter Graf},
	journal={ArXiv},
	year={2016},
	volume={abs/1608.08710}
}
@misc{vaswani2017attention,
	title={Attention Is All You Need},
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}
@inproceedings{carreira2018learning,
	title={“Learning-Compression” Algorithms for Neural Net Pruning},
	author={Carreira-Perpin{\'a}n, Miguel A and Idelbayev, Yerlan},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={8532--8541},
	year={2018}
}
@misc{guo2016dynamic,
	title={Dynamic Network Surgery for Efficient DNNs},
	author={Yiwen Guo and Anbang Yao and Yurong Chen},
	year={2016},
	eprint={1608.04493},
	archivePrefix={arXiv},
	primaryClass={cs.NE}
}
@misc{han2015deep,
	title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
	author={Song Han and Huizi Mao and William J. Dally},
	year={2015},
	eprint={1510.00149},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
@article{chou2018unifying,
	title={Unifying and merging well-trained deep neural networks for inference stage},
	author={Chou, Yi-Min and Chan, Yi-Ming and Lee, Jia-Hong and Chiu, Chih-Yi and Chen, Chu-Song},
	journal={arXiv preprint arXiv:1805.04980},
	year={2018}
}
@misc{cheng2017survey,
	title={A Survey of Model Compression and Acceleration for Deep Neural Networks},
	author={Yu Cheng and Duo Wang and Pan Zhou and Tao Zhang},
	year={2017},
	eprint={1710.09282},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@misc{singh2019model,
	title={Model Fusion via Optimal Transport},
	author={Sidak Pal Singh and Martin Jaggi},
	year={2019},
	eprint={1910.05653},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}
@misc{zhu2017prune,
	title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
	author={Michael Zhu and Suyog Gupta},
	year={2017},
	eprint={1710.01878},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}