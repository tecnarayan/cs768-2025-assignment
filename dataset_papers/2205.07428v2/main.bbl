\begin{thebibliography}{23}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Banzhaf(1965)]{banzhaf1965}
Banzhaf, J.~F.
\newblock Weighted voting doesn't work: A mathematical analysis.
\newblock \emph{Rutgers Law Review}, 19\penalty0 (2):\penalty0 317--343, 1965.

\bibitem[Blum et~al.(2017)Blum, Haghtalab, Procaccia, and Qiao]{blum2017}
Blum, A., Haghtalab, N., Procaccia, A.~D., and Qiao, M.
\newblock Collaborative {PAC} learning.
\newblock In \emph{Proc. NeurIPS}, 2017.

\bibitem[Cam \& Yang(2000)Cam and Yang]{lecam2000}
Cam, L.~L. and Yang, G.~L.
\newblock \emph{Asymptotics in Statistics: Some Basic Concepts}.
\newblock Springer Series in Statistics. Springer New York, NY, 2nd edition,
  2000.

\bibitem[Chen et~al.(2018)Chen, Zhang, and Zhou]{chen2018}
Chen, J., Zhang, Q., and Zhou, Y.
\newblock Tight bounds for collaborative {PAC} learning via multiplicative
  weights.
\newblock In \emph{Proc. NeurIPS}, 2018.

\bibitem[Cover \& Thomas(2006)Cover and Thomas]{cover2006}
Cover, T.~M. and Thomas, J.~A.
\newblock \emph{Elements of Information Theory}.
\newblock John Wiley \& Sons, Inc., 2nd edition, 2006.

\bibitem[Covert et~al.(2020)Covert, Lundberg, and Lee]{covert2020}
Covert, I.~C., Lundberg, S.~M., and Lee, S.-I.
\newblock Understanding global feature contributions with additive importance
  measures.
\newblock In \emph{Proc. NeurIPS}, 2020.

\bibitem[Drineas et~al.(2012)Drineas, Magdon-Ismail, Mahoney, and
  Woodruff]{Drineas2012-leverageiid}
Drineas, P., Magdon-Ismail, M., Mahoney, M.~W., and Woodruff, D.~P.
\newblock Fast approximation of matrix coherence and statistical leverage.
\newblock \emph{JMLR}, 13\penalty0 (1), 2012.

\bibitem[Ghorbani \& Zou(2019)Ghorbani and Zou]{ghorbani2019}
Ghorbani, A. and Zou, J.
\newblock Data {Shapley}: Equitable valuation of data for machine learning.
\newblock In \emph{Proc. ICML}, 2019.

\bibitem[Ghourchian et~al.(2017)Ghourchian, Gohari, and Amini]{ghourchian2017}
Ghourchian, H., Gohari, A., and Amini, A.
\newblock Existence and continuity of differential entropy for a class of
  distributions.
\newblock \emph{IEEE Communications Letters}, 21\penalty0 (7):\penalty0
  1469--1472, 2017.

\bibitem[Harlfoxem(2016)]{kingH-dataset}
Harlfoxem.
\newblock House sales in {King County, USA}.
\newblock \url{https://www.kaggle.com/harlfoxem/housesalesprediction}, 2016.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{KingmaW13-vae}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational {Bayes}.
\newblock In \emph{Proc. ICLR}, 2014.

\bibitem[Lundberg \& Lee(2017)Lundberg and Lee]{lundberg2017}
Lundberg, S.~M. and Lee, S.-I.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{Proc. NeurIPS}, 2017.

\bibitem[Nguyen \& Zakynthinou(2018)Nguyen and Zakynthinou]{nguyen2018}
Nguyen, H. and Zakynthinou, L.
\newblock Improved algorithms for collaborative {PAC} learning.
\newblock In \emph{Proc. NeurIPS}, 2018.

\bibitem[Pace \& Barry(1997)Pace and Barry]{KELLEYPACE1997291-CaliH}
Pace, R.~K. and Barry, R.
\newblock Sparse spatial autoregressions.
\newblock \emph{Statistics \& Probability Letters}, 33\penalty0 (3):\penalty0
  291--297, 1997.

\bibitem[Shapley(1953)]{shapley1953}
Shapley, L.~S.
\newblock A value for $n$-person games.
\newblock In Kuhn, H.~W. and Tucker, A.~W. (eds.), \emph{Contributions to the
  Theory of Games}, volume~2, pp.\  307--317. Princeton Univ. Press, 1953.

\bibitem[Sim et~al.(2020)Sim, Zhang, Chan, and Low]{sim2020}
Sim, R. H.~L., Zhang, Y., Chan, M.~C., and Low, B. K.~H.
\newblock Collaborative machine learning with incentive-aware model rewards.
\newblock In \emph{Proc. {ICML}}, pp.\  8927--8936, 2020.

\bibitem[Sim et~al.(2022)Sim, Xu, and Low]{rachxinyi}
Sim, R. H.~L., Xu, X., and Low, B. K.~H.
\newblock Data valuation in machine learning: ``ingredients'', strategies, and
  open challenges.
\newblock In \emph{Proc. IJCAI}, 2022.

\bibitem[Tay et~al.(2022)Tay, Xu, Foo, and Low]{tay2021}
Tay, S.~S., Xu, X., Foo, C.~S., and Low, B. K.~H.
\newblock Incentivizing collaboration in machine learning via synthetic data
  rewards.
\newblock In \emph{Proc. AAAI}, 2022.

\bibitem[{van der Vaart}(1998)]{vaart1998}
{van der Vaart}, A.~W.
\newblock \emph{Asymptotic Statistics}.
\newblock Cambridge Univ. Press, 1998.

\bibitem[Wu et~al.(2022)Wu, Shu, and Low]{zhaoxuan22}
Wu, Z., Shu, Y., and Low, B. K.~H.
\newblock \textsc{DaVinz}: Data valuation using deep neural networks at
  initialization.
\newblock In \emph{Proc. {ICML}}, 2022.

\bibitem[Xu et~al.(2021{\natexlab{a}})Xu, Lyu, Ma, Miao, Foo, and
  Low]{xu2021gradient}
Xu, X., Lyu, L., Ma, X., Miao, C., Foo, C.~S., and Low, B. K.~H.
\newblock Gradient driven rewards to guarantee fairness in collaborative
  machine learning.
\newblock In \emph{Proc. NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Xu et~al.(2021{\natexlab{b}})Xu, Wu, Foo, and Low]{xu2021vol}
Xu, X., Wu, Z., Foo, C.~S., and Low, B. K.~H.
\newblock Validation free and replication robust volume-based data valuation.
\newblock In \emph{Proc. NeurIPS}, 2021{\natexlab{b}}.

\bibitem[Zhang et~al.(2017)Zhang, Song, and Qi]{zhifei2017cvpr-FaceA}
Zhang, Z., Song, Y., and Qi, H.
\newblock Age progression/regression by conditional adversarial autoencoder.
\newblock In \emph{Proc. CVPR}, 2017.

\end{thebibliography}
