@inproceedings{efroni2021confidence,
  author    = {Yonathan Efroni and
               Nadav Merlis and
               Aadirupa Saha and
               Shie Mannor},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Confidence-Budget Matching for Sequential Budgeted Learning},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {2937--2947},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/efroni21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/EfroniMSM21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ito2020delay,
  title={Delay and cooperation in nonstochastic linear bandits},
  author={Ito, Shinji and Hatano, Daisuke and Sumita, Hanna and Takemura, Kei and Fukunaga, Takuro and Kakimura, Naonori and Kawarabayashi, Ken-Ichi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4872--4883},
  year={2020}
}

@inproceedings{domingues2021episodic,
  title={Episodic reinforcement learning in finite mdps: Minimax lower bounds revisited},
  author={Domingues, Omar Darwiche and M{\'e}nard, Pierre and Kaufmann, Emilie and Valko, Michal},
  booktitle={Algorithmic Learning Theory},
  pages={578--598},
  year={2021},
  organization={PMLR}
}

@article{cohen2021minimax,
  title={Minimax regret for stochastic shortest path},
  author={Cohen, Alon and Efroni, Yonathan and Mansour, Yishay and Rosenberg, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{dann2017unifying,
  title={Unifying PAC and regret: uniform PAC bounds for episodic reinforcement learning},
  author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={5717--5727},
  year={2017}
}

@inproceedings{rosenberg2020near,
  title={Near-optimal regret bounds for stochastic shortest path},
  author={Rosenberg, Aviv and Cohen, Alon and Mansour, Yishay and Kaplan, Haim},
  booktitle={International Conference on Machine Learning},
  pages={8210--8219},
  year={2020},
  organization={PMLR}
}

@inproceedings{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={5478--5486},
  year={2019},
  organization={PMLR}
}

@article{rosenberg2019onlineb,
  title={Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function},
  author={Rosenberg, Aviv and Mansour, Yishay},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={2212--2221},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@inproceedings{azar2017minimax,
    title={Minimax regret bounds for reinforcement learning},
    author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
    booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
    pages={263--272},
    year={2017},
    organization={JMLR. org}
}

@article{liu2010distributed,
  title={Distributed learning in multi-armed bandit with multiple players},
  author={Liu, Keqin and Zhao, Qing},
  journal={IEEE transactions on signal processing},
  volume={58},
  number={11},
  pages={5667--5681},
  year={2010},
  publisher={IEEE}
}

@inproceedings{lai2008medium,
  title={Medium access in cognitive radio networks: A competitive multi-armed bandit framework},
  author={Lai, Lifeng and Jiang, Hai and Poor, H Vincent},
  booktitle={2008 42nd Asilomar Conference on Signals, Systems and Computers},
  pages={98--102},
  year={2008},
  organization={IEEE}
}

@inproceedings{bubeck2021cooperative,
  title={Cooperative and stochastic multi-player multi-armed bandit: Optimal regret with neither communication nor collisions},
  author={Bubeck, S{\'e}bastien and Budzinski, Thomas and Sellke, Mark},
  booktitle={Conference on Learning Theory},
  pages={821--822},
  year={2021},
  organization={PMLR}
}

@inproceedings{jin2018q,
    title={Is q-learning provably efficient?},
    author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
    booktitle={Advances in Neural Information Processing Systems},
    pages={4863--4873},
    year={2018}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020}
}

@inproceedings{yang2019sample,
  title={Sample-optimal parametric Q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}

@inproceedings{dann2019policy,
  title={Policy certificates: Towards accountable reinforcement learning},
  author={Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={1507--1516},
  year={2019},
  organization={PMLR}
}

@inproceedings{seldin2014prediction,
  title={Prediction with limited advice and multiarmed bandits with paid observations},
  author={Seldin, Yevgeny and Bartlett, Peter and Crammer, Koby and Abbasi-Yadkori, Yasin},
  booktitle={International Conference on Machine Learning},
  pages={280--287},
  year={2014},
  organization={PMLR}
}

@inproceedings{dick2014online,
  title={Online learning in Markov decision processes with changing cost sequences},
  author={Dick, Travis and Gyorgy, Andras and Szepesvari, Csaba},
  booktitle={International Conference on Machine Learning},
  pages={512--520},
  year={2014},
  organization={PMLR}
}

@inproceedings{xu2021fine,
  author    = {Haike Xu and
               Tengyu Ma and
               Simon S. Du},
  editor    = {Mikhail Belkin and
               Samory Kpotufe},
  title     = {Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step
               Bootstrap},
  booktitle = {Conference on Learning Theory, {COLT} 2021, 15-19 August 2021, Boulder,
               Colorado, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {134},
  pages     = {4438--4472},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v134/xu21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:16 +0200},
  biburl    = {https://dblp.org/rec/conf/colt/Xu0D21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{neu2015explore,
  title={Explore no more: Improved high-probability regret bounds for non-stochastic bandits},
  author={Neu, Gergely},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3168--3176},
  year={2015}
}

@article{shalev2011online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and trends in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2011}
}

@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020}
}

@article{lancewicki2020learning,
  title={Learning adversarial markov decision processes with delayed feedback},
  author={Lancewicki, Tal and Rosenberg, Aviv and Mansour, Yishay},
  journal={arXiv preprint arXiv:2012.14843},
  year={2020}
}

@article{howson2021delayed,
  title={Delayed Feedback in Episodic Reinforcement Learning},
  author={Howson, Benjamin and Pike-Burke, Ciara and Filippi, Sarah},
  journal={arXiv preprint arXiv:2111.07615},
  year={2021}
}

@inproceedings{rosenberg2021stochastic,
  author    = {Aviv Rosenberg and
               Yishay Mansour},
  editor    = {Zhi{-}Hua Zhou},
  title     = {Stochastic Shortest Path with Adversarially Changing Costs},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial
               Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada, 19-27
               August 2021},
  pages     = {2936--2942},
  publisher = {ijcai.org},
  year      = {2021},
  url       = {https://doi.org/10.24963/ijcai.2021/404},
  doi       = {10.24963/ijcai.2021/404},
  timestamp = {Wed, 25 Aug 2021 17:11:16 +0200},
  biburl    = {https://dblp.org/rec/conf/ijcai/0002M21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@inproceedings{zanette2019tighter,
    title={Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds},
    author={Zanette, Andrea and Brunskill, Emma},
    booktitle={International Conference on Machine Learning},
    pages={7304--7312},
    year={2019}
}

@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{he2021nearly,
  title={Nearly Optimal Regret for Learning Adversarial MDPs with Linear Function Approximation},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2102.08940},
  year={2021}
}

@article{jin2020simultaneously,
  title={Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition},
  author={Jin, Tiancheng and Luo, Haipeng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@article{streeter2010less,
  title={Less regret via online conditioning},
  author={Streeter, Matthew and McMahan, H Brendan},
  journal={arXiv preprint arXiv:1002.4862},
  year={2010}
}

@inproceedings{zimin2013online,
  title={Online learning in episodic Markovian decision processes by relative entropy policy search},
  author={Zimin, Alexander and Neu, Gergely},
  booktitle={Neural Information Processing Systems 26},
  year={2013}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{jin2020learning,
  title={Learning adversarial Markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4860--4869},
  year={2020},
  organization={PMLR}
}

@inproceedings{lee2002stock,
  title={Stock trading system using reinforcement learning with cooperative agents},
  author={Lee, Jae Won and Zhang, Byoung-Tak and others},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={451--458},
  year={2002}
}

@article{lee2007multiagent,
  title={A multiagent approach to $ q $-learning for daily stock trading},
  author={Lee, Jae Won and Park, Jonghun and Jangmin, O and Lee, Jongwoo and Hong, Euyseok},
  journal={IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans},
  volume={37},
  number={6},
  pages={864--877},
  year={2007},
  publisher={IEEE}
}

@article{adler2002cooperative,
  title={A cooperative multi-agent transportation management and route guidance system},
  author={Adler, Jeffrey L and Blue, Victor J},
  journal={Transportation Research Part C: Emerging Technologies},
  volume={10},
  number={5-6},
  pages={433--454},
  year={2002},
  publisher={Elsevier}
}

@article{wang2016towards,
  title={Towards smart factory for industry 4.0: a self-organized multi-agent system with big data based feedback and coordination},
  author={Wang, Shiyong and Wan, Jiafu and Zhang, Daqiang and Li, Di and Zhang, Chunhua},
  journal={Computer networks},
  volume={101},
  pages={158--168},
  year={2016},
  publisher={Elsevier}
}

@article{cortes2004coverage,
  title={Coverage control for mobile sensing networks},
  author={Cortes, Jorge and Martinez, Sonia and Karatas, Timur and Bullo, Francesco},
  journal={IEEE Transactions on robotics and Automation},
  volume={20},
  number={2},
  pages={243--255},
  year={2004},
  publisher={IEEE}
}

@article{choi2009distributed,
  title={Distributed learning and cooperative control for multi-agent systems},
  author={Choi, Jongeun and Oh, Songhwai and Horowitz, Roberto},
  journal={Automatica},
  volume={45},
  number={12},
  pages={2802--2814},
  year={2009},
  publisher={Elsevier}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of Reinforcement Learning and Control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

@article{jin2021v,
  title={V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2110.14555},
  year={2021}
}

@article{lidard2021provably,
  title={Provably Efficient Multi-Agent Reinforcement Learning with Fully Decentralized Communication},
  author={Lidard, Justin and Madhushani, Udari and Leonard, Naomi Ehrich},
  journal={arXiv preprint arXiv:2110.07392},
  year={2021}
}

@inproceedings{cesa2016delay,
  title={Delay and cooperation in nonstochastic bandits},
  author={Cesa-Bianchi, Nicolâ€˜o and Gentile, Claudio and Mansour, Yishay and Minora, Alberto},
  booktitle={Conference on Learning Theory},
  pages={605--622},
  year={2016},
  organization={PMLR}
}

@article{cesa2019delay,
  title={Delay and Cooperation in Nonstochastic Bandits},
  author={Cesa-Bianchi, Nicol{\`o} and Gentile, Claudio and Mansour, Yishay},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={17},
  pages={1--38},
  year={2019}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{zhang2018fully,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}

@inproceedings{zhang2018networked,
  title={Networked multi-agent reinforcement learning in continuous spaces},
  author={Zhang, Kaiqing and Yang, Zhuoran and Basar, Tamer},
  booktitle={2018 IEEE conference on decision and control (CDC)},
  pages={2771--2776},
  year={2018},
  organization={IEEE}
}

@article{zhang2020model,
  title={Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity},
  author={Zhang, Kaiqing and Kakade, Sham and Basar, Tamer and Yang, Lin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{zhang2021finite,
  title={Finite-sample analysis for decentralized batch multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  journal={IEEE Transactions on Automatic Control},
  year={2021},
  publisher={IEEE}
}

@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on Learning Theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}

@inproceedings{liu2021sharp,
  title={A sharp analysis of model-based reinforcement learning with self-play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={7001--7010},
  year={2021},
  organization={PMLR}
}

@article{bai2020near,
  title={Near-Optimal Reinforcement Learning with Self-Play},
  author={Bai, Yu and Jin, Chi and Yu, Tiancheng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{bai2020provable,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={551--560},
  year={2020},
  organization={PMLR}
}

@article{bar2019individual,
  title={Individual regret in cooperative nonstochastic multi-armed bandits},
  author={Bar-On, Yogev and Mansour, Yishay},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={3116--3126},
  year={2019}
}

@article{madhushani2021one,
  title={One more step towards reality: Cooperative bandits with imperfect communication},
  author={Madhushani, Udari and Dubey, Abhimanyu and Leonard, Naomi and Pentland, Alex},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{landgren2021distributed,
  title={Distributed cooperative decision making in multi-agent multi-armed bandits},
  author={Landgren, Peter and Srivastava, Vaibhav and Leonard, Naomi Ehrich},
  journal={Automatica},
  volume={125},
  pages={109445},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{wang2020optimal,
  title={Optimal algorithms for multiplayer multi-armed bandits},
  author={Wang, Po-An and Proutiere, Alexandre and Ariu, Kaito and Jedra, Yassir and Russo, Alessio},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4120--4129},
  year={2020},
  organization={PMLR}
}

@inproceedings{dubey2020cooperative,
  title={Cooperative multi-agent bandits with heavy tails},
  author={Dubey, Abhimanyu and others},
  booktitle={International Conference on Machine Learning},
  pages={2730--2739},
  year={2020},
  organization={PMLR}
}