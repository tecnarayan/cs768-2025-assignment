\begin{thebibliography}{10}

\bibitem{asmussen2003applied}
S.~Asmussen.
\newblock {\em Applied Probability and Queues}, volume~2.
\newblock Springer, 2003.

\bibitem{bach2022information}
F.~Bach.
\newblock Information theory with kernel methods.
\newblock {\em arXiv preprint arXiv:2202.08545}, 2022.

\bibitem{bach2002kernel}
F.~Bach and M.~I. Jordan.
\newblock Kernel independent component analysis.
\newblock {\em Journal of Machine Learning Research}, 3(Jul):1--48, 2002.

\bibitem{baird1995residual}
L.~Baird.
\newblock Residual algorithms: Reinforcement learning with function
  approximation.
\newblock In {\em Machine Learning Proceedings 1995}, pages 30--37. Elsevier,
  1995.

\bibitem{baker1973joint}
C.~R. Baker.
\newblock Joint measures and cross-covariance operators.
\newblock {\em Transactions of the American Mathematical Society},
  186:273--289, 1973.

\bibitem{barreto2011reinforcement}
A.~Barreto, D.~Precup, and J.~Pineau.
\newblock Reinforcement learning using kernel-based stochastic factorization.
\newblock {\em Advances in Neural Information Processing Systems}, 24, 2011.

\bibitem{barreto2016practical}
A.~M. Barreto, D.~Precup, and J.~Pineau.
\newblock Practical kernel-based reinforcement learning.
\newblock {\em The Journal of Machine Learning Research}, 17(1):2372--2441,
  2016.

\bibitem{benveniste2012adaptive}
A.~Benveniste, M.~M{\'e}tivier, and P.~Priouret.
\newblock {\em Adaptive Algorithms and Stochastic Approximations}, volume~22.
\newblock Springer Science \& Business Media, 1990.

\bibitem{berthier2020tight}
R.~Berthier, F.~Bach, and P.~Gaillard.
\newblock Tight nonparametric convergence rates for stochastic gradient descent
  under the noiseless linear model.
\newblock {\em Advances in Neural Information Processing Systems},
  33:2576--2586, 2020.

\bibitem{bhandari2018finite}
J.~Bhandari, D.~Russo, and R.~Singal.
\newblock A finite time analysis of temporal difference learning with linear
  function approximation.
\newblock In {\em Conference on Learning Theory}, pages 1691--1692, 2018.

\bibitem{bhat2012non}
N.~Bhat, V.~Farias, and C.~C. Moallemi.
\newblock Non-parametric approximate dynamic programming via the kernel method.
\newblock {\em Advances in Neural Information Processing Systems}, 25, 2012.

\bibitem{bhatia2013matrix}
R.~Bhatia.
\newblock {\em Matrix Analysis}, volume 169.
\newblock Springer Science \& Business Media, 2013.

\bibitem{borkar2000ode}
V.~S. Borkar and S.~P. Meyn.
\newblock The {ODE} method for convergence of stochastic approximation and
  reinforcement learning.
\newblock {\em SIAM Journal on Control and Optimization}, 38(2):447--469, 2000.

\bibitem{bottou2018optimization}
L.~Bottou, F.~E. Curtis, and J.~Nocedal.
\newblock Optimization methods for large-scale machine learning.
\newblock {\em SIAM Review}, 60(2):223--311, 2018.

\bibitem{boyan1994generalization}
J.~Boyan and A.~Moore.
\newblock Generalization in reinforcement learning: Safely approximating the
  value function.
\newblock {\em Advances in Neural Information Processing Systems}, 7, 1994.

\bibitem{bradtke1996linear}
S.~J. Bradtke and A.~G. Barto.
\newblock Linear least-squares algorithms for temporal difference learning.
\newblock {\em Machine Learning}, 22(1):33--57, 1996.

\bibitem{caponnetto2007optimal}
A.~Caponnetto and E.~De~Vito.
\newblock Optimal rates for the regularized least-squares algorithm.
\newblock {\em Foundations of Computational Mathematics}, 7(3):331--368, 2007.

\bibitem{cheney2001analysis}
E.~W. Cheney.
\newblock {\em Analysis for Applied Mathematics}, volume~1.
\newblock Springer, 2001.

\bibitem{cristianini2004kernel}
N.~Cristianini and J.~Shawe-Taylor.
\newblock {\em Kernel Methods for Pattern Analysis}, volume 173.
\newblock Cambridge University Press, 2004.

\bibitem{cucker2002mathematical}
F.~Cucker and S.~Smale.
\newblock On the mathematical foundations of learning.
\newblock {\em Bulletin of the American Mathematical Society}, 39(1):1--49,
  2002.

\bibitem{cucker2007learning}
F.~Cucker and D.~X. Zhou.
\newblock {\em Learning Theory: an Approximation Theory Viewpoint}, volume~24.
\newblock Cambridge University Press, 2007.

\bibitem{dai2017learning}
B.~Dai, N.~He, Y.~Pan, B.~Boots, and L.~Song.
\newblock Learning from conditional distributions via dual embeddings.
\newblock In {\em Artificial Intelligence and Statistics}, pages 1458--1467,
  2017.

\bibitem{dalal2017finite}
G.~Dalal, B.~Sz{\"o}r{\'e}nyi, G.~Thoppe, and S.~Mannor.
\newblock Finite sample analyses for {TD}(0) with function approximation.
\newblock {\em AAAI'18/IAAI'18/EAAI'18}, 2018.

\bibitem{dayan1992convergence}
P.~Dayan.
\newblock The convergence of {TD}($\lambda$) for general $\lambda$.
\newblock {\em Machine Learning}, 8(3):341--362, 1992.

\bibitem{defossez2017adabatch}
A.~D{\'e}fossez and F.~Bach.
\newblock Adabatch: Efficient gradient aggregation rules for sequential and
  parallel stochastic gradient methods.
\newblock {\em arXiv preprint arXiv:1711.01761}, 2017.

\bibitem{dietterich2001batch}
T.~Dietterich and X.~Wang.
\newblock Batch value function approximation via support vectors.
\newblock {\em Advances in Neural Information Processing Systems}, 14, 2001.

\bibitem{dieuleveut2017stochastic}
A.~Dieuleveut.
\newblock {\em Stochastic Approximation in {H}ilbert Spaces}.
\newblock PhD thesis, Paris Sciences et Lettres (ComUE), 2017.

\bibitem{dieuleveut2016nonparametric}
A.~Dieuleveut and F.~Bach.
\newblock Nonparametric stochastic approximation with large step-sizes.
\newblock {\em The Annals of Statistics}, 44(4):1363--1399, 2016.

\bibitem{domingues2021kernel}
O.~D. Domingues, P.~M{\'e}nard, M.~Pirotta, E.~Kaufmann, and M.~Valko.
\newblock Kernel-based reinforcement learning: A finite-time analysis.
\newblock In {\em International Conference on Machine Learning}, pages
  2783--2792, 2021.

\bibitem{duan2021optimal}
Y.~Duan, M.~Wang, and M.~J. Wainwright.
\newblock Optimal policy evaluation using kernel-based temporal difference
  methods.
\newblock {\em arXiv preprint arXiv:2109.12002}, 2021.

\bibitem{durrett2019probability}
R.~Durrett.
\newblock {\em Probability: Theory and Examples}, volume~49.
\newblock Cambridge University Press, 2019.

\bibitem{farahmand2016regularized}
A.-M. Farahmand, M.~Ghavamzadeh, C.~Szepesv{\'a}ri, and S.~Mannor.
\newblock Regularized policy iteration with nonparametric function spaces.
\newblock {\em The Journal of Machine Learning Research}, 17(1):4809--4874,
  2016.

\bibitem{fukumizu2004dimensionality}
K.~Fukumizu, F.~R. Bach, and M.~I. Jordan.
\newblock Dimensionality reduction for supervised learning with reproducing
  kernel {H}ilbert spaces.
\newblock {\em Journal of Machine Learning Research}, 5(Jan):73--99, 2004.

\bibitem{grunewalder2012modelling}
S.~Grünewälder, G.~Lever, L.~Baldassarre, M.~Pontil, and A.~Gretton.
\newblock Modelling transition dynamics in {MDP}s with {RKHS} embeddings.
\newblock In {\em International Conference on Machine Learning}, 2012.

\bibitem{halko2011finding}
N.~Halko, P.-G. Martinsson, and J.~A. Tropp.
\newblock Finding structure with randomness: Probabilistic algorithms for
  constructing approximate matrix decompositions.
\newblock {\em SIAM review}, 53(2):217--288, 2011.

\bibitem{jaakkola1993convergence}
T.~Jaakkola, M.~Jordan, and S.~Singh.
\newblock Convergence of stochastic iterative dynamic programming algorithms.
\newblock {\em Advances in Neural Information Processing Systems}, 6, 1993.

\bibitem{klenke2013probability}
A.~Klenke.
\newblock {\em Probability Theory: A Comprehensive Course}.
\newblock Springer Science \& Business Media, 2013.

\bibitem{koppel2020policy}
A.~Koppel, G.~Warnell, E.~Stump, P.~Stone, and A.~Ribeiro.
\newblock Policy evaluation in continuous {MDP}s with efficient kernelized
  gradient temporal difference.
\newblock {\em IEEE Transactions on Automatic Control}, 66(4):1856--1863, 2020.

\bibitem{korda2015td}
N.~Korda and P.~La.
\newblock On {TD}(0) with function approximation: Concentration bounds and a
  centered variant with exponential convergence.
\newblock In {\em International Conference on Machine Learning}, pages
  626--634, 2015.

\bibitem{lakshminarayanan2018linear}
C.~Lakshminarayanan and C.~Szepesvari.
\newblock Linear stochastic approximation: How far does constant step-size and
  iterate averaging go?
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1347--1355, 2018.

\bibitem{levin2017markov}
D.~A. Levin and Y.~Peres.
\newblock {\em Markov Chains and Mixing Times}, volume 107.
\newblock American Mathematical Society, 2017.

\bibitem{long20212}
J.~Long, J.~Han, and W.~E.
\newblock An ${L}^{2}$ analysis of reinforcement learning in high dimensions
  with kernel and neural network approximation.
\newblock {\em arXiv preprint arXiv:2104.07794}, 2021.

\bibitem{micchelli2006universal}
C.~A. Micchelli, Y.~Xu, and H.~Zhang.
\newblock Universal kernels.
\newblock {\em Journal of Machine Learning Research}, 7(12), 2006.

\bibitem{mou2020optimal}
W.~Mou, A.~Pananjady, and M.~J. Wainwright.
\newblock Optimal oracle inequalities for solving projected fixed-point
  equations.
\newblock {\em arXiv preprint arXiv:2012.05299}, 2020.

\bibitem{nagaraj2020least}
D.~Nagaraj, X.~Wu, G.~Bresler, P.~Jain, and P.~Netrapalli.
\newblock Least squares regression with {M}arkovian data: Fundamental limits
  and algorithms.
\newblock {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{novak2018reproducing}
E.~Novak, M.~Ullrich, H.~Wo{\'z}niakowski, and S.~Zhang.
\newblock Reproducing kernels of {S}obolev spaces on $\mathbb{R}^d$ and
  applications to embedding constants and tractability.
\newblock {\em Analysis and Applications}, 16(05):693--715, 2018.

\bibitem{olver2010nist}
F.~W.~J. Olver, D.~W. Lozier, R.~F. Boisvert, and C.~W. Clark.
\newblock {\em NIST Handbook of Mathematical Functions}.
\newblock Cambridge University Press, 2010.

\bibitem{ormoneit2002kernel}
D.~Ormoneit and {\'S}.~Sen.
\newblock Kernel-based reinforcement learning.
\newblock {\em Machine Learning}, 49(2):161--178, 2002.

\bibitem{pillaud2018exponential}
L.~Pillaud-Vivien, A.~Rudi, and F.~Bach.
\newblock Exponential convergence of testing error for stochastic gradient
  methods.
\newblock In {\em Conference on Learning Theory}, pages 250--296, 2018.

\bibitem{polyak1992acceleration}
B.~T. Polyak and A.~B. Juditsky.
\newblock Acceleration of stochastic approximation by averaging.
\newblock {\em SIAM Journal on Control and Optimization}, 30(4):838--855, 1992.

\bibitem{reiss2012course}
R.-D. Reiss.
\newblock {\em A Course on Point Processes}.
\newblock Springer Science \& Business Media, 2012.

\bibitem{rudin}
W.~Rudin.
\newblock {\em Real and Complex Analysis, 3rd Ed.}
\newblock McGraw-Hill, Inc., USA, 1987.

\bibitem{schapire1996worst}
R.~E. Schapire and M.~K. Warmuth.
\newblock On the worst-case analysis of temporal-difference learning
  algorithms.
\newblock {\em Machine Learning}, 22(1):95--121, 1996.

\bibitem{slotine1991applied}
J.-J.~E. Slotine and W.~Li.
\newblock {\em Applied Nonlinear Control}, volume 199.
\newblock Prentice Hall Englewood Cliffs, NJ, 1991.

\bibitem{srikant2019finite}
R.~Srikant and L.~Ying.
\newblock Finite-time error bounds for linear stochastic approximation and {TD}
  learning.
\newblock In {\em Conference on Learning Theory}, pages 2803--2830, 2019.

\bibitem{steinwart2001influence}
I.~Steinwart.
\newblock On the influence of the kernel on the consistency of support vector
  machines.
\newblock {\em Journal of Machine Learning Research}, 2(Nov):67--93, 2001.

\bibitem{sutton1988learning}
R.~S. Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock {\em Machine Learning}, 3(1):9--44, 1988.

\bibitem{sutton2015introduction}
R.~S. Sutton.
\newblock Introduction to reinforcement learning with function approximation.
\newblock In {\em Tutorial at the Conference on Neural Information Processing
  Systems}, page~33, 2015.

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock MIT press, 2018.

\bibitem{tarres2014online}
P.~Tarres and Y.~Yao.
\newblock Online learning as stochastic approximation of regularization paths:
  Optimality and almost-sure convergence.
\newblock {\em IEEE Transactions on Information Theory}, 60(9):5716--5735,
  2014.

\bibitem{tsitsiklis1997analysis}
J.~N. Tsitsiklis and B.~Van~Roy.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock {\em IEEE Transactions on Automatic Control}, 42(5):674--690, 1997.

\bibitem{wahba1990spline}
G.~Wahba.
\newblock {\em Spline Models for Observational Data}.
\newblock CBMS-NSF Regional Conference Series in Applied Mathematics. Society
  for Industrial and Applied Mathematics, 1990.

\bibitem{weidmann2012linear}
J.~Weidmann.
\newblock {\em Linear Operators in {H}ilbert Spaces}, volume~68.
\newblock Springer Science \& Business Media, 2012.

\bibitem{xu2020reanalysis}
T.~Xu, Z.~Wang, Y.~Zhou, and Y.~Liang.
\newblock Reanalysis of variance reduced temporal difference learning.
\newblock {\em arXiv preprint arXiv:2001.01898}, 2020.

\bibitem{yu2010error}
H.~Yu and D.~P. Bertsekas.
\newblock Error bounds for approximations from projected linear equations.
\newblock {\em Mathematics of Operations Research}, 35(2):306--329, 2010.

\end{thebibliography}
