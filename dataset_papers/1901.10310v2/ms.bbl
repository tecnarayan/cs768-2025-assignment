\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alistarh et~al.(2018{\natexlab{a}})Alistarh, Allen-Zhu, and
  Li]{NIPS2018_7712}
Alistarh, D., Allen-Zhu, Z., and Li, J.
\newblock Byzantine stochastic gradient descent.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2018{\natexlab{a}}.

\bibitem[Alistarh et~al.(2018{\natexlab{b}})Alistarh, De~Sa, and
  Konstantinov]{Alistarh:2018:CSG:3212734.3212763}
Alistarh, D., De~Sa, C., and Konstantinov, N.
\newblock The convergence of stochastic gradient descent in asynchronous shared
  memory.
\newblock In \emph{ACM Symposium on Principles of Distributed Computing}, PODC,
  2018{\natexlab{b}}.

\bibitem[Arora et~al.(2017)Arora, Liang, and Ma]{arora2016simple}
Arora, S., Liang, Y., and Ma, T.
\newblock A simple but tough-to-beat baseline for sentence embeddings.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Awasthi et~al.(2017)Awasthi, Blum, Haghtalab, and
  Mansour]{awasthi2017efficient}
Awasthi, P., Blum, A., Haghtalab, N., and Mansour, Y.
\newblock Efficient {PAC} learning from the crowd.
\newblock \emph{Conference on Computational Learning Theory (COLT)}, 2017.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Vaughan,
  J.~W.
\newblock A theory of learning from different domains.
\newblock \emph{Machine Learning}, 79\penalty0 (1-2):\penalty0 151--175, 2010.

\bibitem[Bi et~al.(2014)Bi, Wang, Kwok, and Tu]{bi2014learning}
Bi, W., Wang, L., Kwok, J.~T., and Tu, Z.
\newblock Learning to predict from crowdsourced data.
\newblock In \emph{UAI}, pp.\  82--91, 2014.

\bibitem[Biggio et~al.(2012)Biggio, Nelson, and Laskov]{Biggio}
Biggio, B., Nelson, B., and Laskov, P.
\newblock Poisoning attacks against support vector machines.
\newblock In \emph{International Conference on Machine Learing (ICML)}, 2012.

\bibitem[Blanchard et~al.(2017)Blanchard, Guerraoui, Stainer,
  et~al.]{blanchard2017machine}
Blanchard, P., Guerraoui, R., Stainer, J., et~al.
\newblock Machine learning with adversaries: Byzantine tolerant gradient
  descent.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Bonawitz et~al.(2017)Bonawitz, Ivanov, Kreuter, Marcedone, McMahan,
  Patel, Ramage, Segal, and Seth]{bonawitz2017practical}
Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.~B., Patel,
  S., Ramage, D., Segal, A., and Seth, K.
\newblock Practical secure aggregation for privacy-preserving machine learning.
\newblock In \emph{Proceedings of the 2017 ACM SIGSAC Conference on Computer
  and Communications Security}, 2017.

\bibitem[Bousquet et~al.(2004)Bousquet, Boucheron, and
  Lugosi]{bousquet2004introduction}
Bousquet, O., Boucheron, S., and Lugosi, G.
\newblock Introduction to statistical learning theory.
\newblock In \emph{Advanced lectures on machine learning}, pp.\  169--207.
  Springer, 2004.

\bibitem[Charikar et~al.(2017)Charikar, Steinhardt, and
  Valiant]{charikar2017learning}
Charikar, M., Steinhardt, J., and Valiant, G.
\newblock Learning from untrusted data.
\newblock In \emph{ACM SIGACT Symposium on Theory of Computing}, 2017.

\bibitem[Chen et~al.(2009)Chen, Mitchell, and Martin]{trustedcomp}
Chen, L., Mitchell, C.~J., and Martin, A.~P. (eds.).
\newblock \emph{Trusted Computing, Second International Conference, Trust 2009,
  Oxford, UK, April 6-8, 2009, Proceedings}, volume 5471 of \emph{Lecture Notes
  in Computer Science}, 2009.

\bibitem[Crammer et~al.(2008)Crammer, Kearns, and Wortman]{crammer2008learning}
Crammer, K., Kearns, M., and Wortman, J.
\newblock Learning from multiple sources.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 9\penalty0
  (Aug):\penalty0 1757--1774, 2008.

\bibitem[De~Sa et~al.(2015)De~Sa, Zhang, Olukotun, R\'{e}, and
  R\'{e}]{NIPS2015_5717}
De~Sa, C.~M., Zhang, C., Olukotun, K., R\'{e}, C., and R\'{e}, C.
\newblock Taming the wild: A unified analysis of hogwild-style algorithms.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)}.
  2015.

\bibitem[Dean et~al.(2012)Dean, Corrado, Monga, Chen, Devin, Mao, Senior,
  Tucker, Yang, Le, et~al.]{dean2012large}
Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., Senior, A.,
  Tucker, P., Yang, K., Le, Q.~V., et~al.
\newblock Large scale distributed deep networks.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2012.

\bibitem[Diakonikolas et~al.(2016)Diakonikolas, Kamath, Kane, Li, Moitra, and
  Stewart]{diakonikolas2016robust}
Diakonikolas, I., Kamath, G., Kane, D.~M., Li, J., Moitra, A., and Stewart, A.
\newblock Robust estimators in high dimensions without the computational
  intractability.
\newblock In \emph{Foundations of Computer Science (FOCS)}, pp.\  655--664.
  IEEE, 2016.

\bibitem[Feng(2017)]{feng2017fundamental}
Feng, J.
\newblock On fundamental limits of robust learning.
\newblock \emph{arXiv preprint arXiv:1703.10444}, 2017.

\bibitem[Feng et~al.(2014)Feng, Xu, and Mannor]{feng2014distributed}
Feng, J., Xu, H., and Mannor, S.
\newblock Distributed robust learning.
\newblock \emph{arXiv preprint arXiv:1409.5937}, 2014.

\bibitem[Fung et~al.(2018)Fung, Yoon, and Beschastnikh]{fung2018mitigating}
Fung, C., Yoon, C.~J., and Beschastnikh, I.
\newblock Mitigating sybils in federated learning poisoning.
\newblock \emph{arXiv preprint arXiv:1808.04866}, 2018.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and Gimpel]{hendrycks2017baseline}
Hendrycks, D. and Gimpel, K.
\newblock Improving the generalization of adversarial training with domain
  adaptation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Hendrycks et~al.(2018)Hendrycks, Mazeika, Wilson, and
  Gimpel]{NIPS2018_8246}
Hendrycks, D., Mazeika, M., Wilson, D., and Gimpel, K.
\newblock Using trusted data to train deep networks on labels corrupted by
  severe noise.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Hoffman et~al.(2018)Hoffman, Mohri, and Zhang]{NIPS2018_8046}
Hoffman, J., Mohri, M., and Zhang, N.
\newblock Algorithms and theory for multiple-source adaptation.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Huber(2011)]{huber2011robust}
Huber, P.~J.
\newblock \emph{Robust statistics}.
\newblock Springer, 2011.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learing (ICML)}, 2015.

\bibitem[Kajino et~al.(2012)Kajino, Tsuboi, and Kashima]{kajino2012convex}
Kajino, H., Tsuboi, Y., and Kashima, H.
\newblock A convex formulation for learning from crowds.
\newblock \emph{Transactions of the Japanese Society for Artificial
  Intelligence}, 27\penalty0 (3):\penalty0 133--142, 2012.

\bibitem[Mansour \& Schain(2014)Mansour and Schain]{mansour2014robust}
Mansour, Y. and Schain, M.
\newblock Robust domain adaptation.
\newblock \emph{Annals of Mathematics and Artificial Intelligence}, 71\penalty0
  (4):\penalty0 365--380, 2014.

\bibitem[Mansour et~al.(2009)Mansour, Mohri, and
  Rostamizadeh]{mansour2009domain}
Mansour, Y., Mohri, M., and Rostamizadeh, A.
\newblock Domain adaptation with multiple sources.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  pp.\  1041--1048, 2009.

\bibitem[McAuley et~al.(2015{\natexlab{a}})McAuley, Pandey, and
  Leskovec]{mcauley2015inferring}
McAuley, J., Pandey, R., and Leskovec, J.
\newblock Inferring networks of substitutable and complementary products.
\newblock In \emph{ACM SIGKDD International Conference on Knowledge Discovery
  and Data Mining}, 2015{\natexlab{a}}.

\bibitem[McAuley et~al.(2015{\natexlab{b}})McAuley, Targett, Shi, and Van
  Den~Hengel]{mcauley2015image}
McAuley, J., Targett, C., Shi, Q., and Van Den~Hengel, A.
\newblock Image-based recommendations on styles and substitutes.
\newblock In \emph{ACM SIGIR Conference on Research and Development in
  Information Retrieval}, 2015{\natexlab{b}}.

\bibitem[McKeen et~al.(2016)McKeen, Alexandrovich, Anati, Caspi, Johnson,
  Leslie-Hurd, and Rozas]{mckeen2016intel}
McKeen, F., Alexandrovich, I., Anati, I., Caspi, D., Johnson, S., Leslie-Hurd,
  R., and Rozas, C.
\newblock Intel{\textregistered} software guard extensions
  (intel{\textregistered} sgx) support for dynamic memory management inside an
  enclave.
\newblock In \emph{Proceedings of the Hardware and Architectural Support for
  Security and Privacy 2016}, pp.\ ~10, 2016.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence
  (AISTATS)}, 2017.

\bibitem[Mohri \& Medina(2012)Mohri and Medina]{mohri2012new}
Mohri, M. and Medina, A.~M.
\newblock New analysis and algorithm for learning with drifting distributions.
\newblock In \emph{International Conference on Algorithmic Learning Theory
  (ALT)}, 2012.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Pennington, J., Socher, R., and Manning, C.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing (EMNLP)}, 2014.

\bibitem[Pentina \& Lampert(2017)Pentina and Lampert]{PenLam17}
Pentina, A. and Lampert, C.~H.
\newblock Multi-task learning with labeled and unlabeled tasks.
\newblock In \emph{International Conference on Machine Learing (ICML)}, 2017.

\bibitem[Prasad et~al.(2018)Prasad, Suggala, Balakrishnan, and
  Ravikumar]{prasad2018robust}
Prasad, A., Suggala, A.~S., Balakrishnan, S., and Ravikumar, P.
\newblock Robust estimation via robust gradient estimation.
\newblock \emph{arXiv preprint arXiv:1802.06485}, 2018.

\bibitem[Pregibon(1982)]{pregibon1982resistant}
Pregibon, D.
\newblock Resistant fits for some commonly used logistic models with medical
  applications.
\newblock \emph{Biometrics}, pp.\  485--498, 1982.

\bibitem[Qiao \& Valiant(2018)Qiao and Valiant]{qiao2018learning}
Qiao, M. and Valiant, G.
\newblock Learning discrete distributions from untrusted batches.
\newblock In \emph{LIPIcs-Leibniz International Proceedings in Informatics},
  volume~94. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Shalev-Shwartz \& Ben-David(2014)Shalev-Shwartz and
  Ben-David]{shalev2014understanding}
Shalev-Shwartz, S. and Ben-David, S.
\newblock \emph{Understanding machine learning: From theory to algorithms}.
\newblock Cambridge University Press, 2014.

\bibitem[Shokri \& Shmatikov(2015)Shokri and Shmatikov]{shokri2015privacy}
Shokri, R. and Shmatikov, V.
\newblock Privacy-preserving deep learning.
\newblock In \emph{ACM SIGSAC conference on computer and communications
  security}, 2015.

\bibitem[Smith et~al.(2017)Smith, Chiang, Sanjabi, and
  Talwalkar]{smith2017federated}
Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A.~S.
\newblock Federated multi-task learning.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Song et~al.(2019)Song, He, Wang, and Hopcroft]{song2018improving}
Song, C., He, K., Wang, L., and Hopcroft, J.~E.
\newblock Improving the generalization of adversarial training with domain
  adaptation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Sun \& Lampert(2018)Sun and Lampert]{sun2018ksconf}
Sun, R. and Lampert, C.~H.
\newblock {KS(conf)}: A light-weight test if a convnet operates outside of its
  specifications.
\newblock In \emph{German Conference on Pattern Recognition (GCPR)}, 2018.

\bibitem[Tukey(1960)]{tukey1960survey}
Tukey, J.~W.
\newblock A survey of sampling from contaminated distributions.
\newblock \emph{Contributions to probability and statistics}, pp.\  448--485,
  1960.

\bibitem[Wahlsten et~al.(2003)Wahlsten, Metten, Phillips, Boehm,
  Burkhart-Kasch, Dorow, Doerksen, Downing, Fogarty, Rodd-Henricks,
  et~al.]{wahlsten2003different}
Wahlsten, D., Metten, P., Phillips, T.~J., Boehm, S.~L., Burkhart-Kasch, S.,
  Dorow, J., Doerksen, S., Downing, C., Fogarty, J., Rodd-Henricks, K., et~al.
\newblock Different data from different labs: lessons from studies of
  gene--environment interaction.
\newblock \emph{Journal of neurobiology}, 54\penalty0 (1):\penalty0 283--311,
  2003.

\bibitem[Wais et~al.(2010)Wais, Lingamneni, Cook, Fennell, Goldenberg, Lubarov,
  Marin, and Simons]{Wais10towardsbuilding}
Wais, P., Lingamneni, S., Cook, D., Fennell, J., Goldenberg, B., Lubarov, D.,
  Marin, D., and Simons, H.
\newblock Towards building a high-quality workforce with mechanical turk.
\newblock In \emph{NIPS Workshop on Computational Social Science and the Wisdom
  of Crowds}, 2010.

\bibitem[Xian et~al.(2018)Xian, Lampert, Schiele, and Akata]{xian2018zero}
Xian, Y., Lampert, C.~H., Schiele, B., and Akata, Z.
\newblock Zero-shot learning-a comprehensive evaluation of the good, the bad
  and the ugly.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence
  (T-PAMI)}, 2018.

\bibitem[Xie(2017)]{xie2017robust}
Xie, T.
\newblock \emph{Robust Learning from Multiple Information Sources}.
\newblock PhD thesis, University of Michigan, 2017.

\bibitem[Yin et~al.(2018)Yin, Chen, Kannan, and Bartlett]{pmlr-v80-yin18a}
Yin, D., Chen, Y., Kannan, R., and Bartlett, P.
\newblock {B}yzantine-robust distributed learning: Towards optimal statistical
  rates.
\newblock In \emph{International Conference on Machine Learing (ICML)}, 2018.

\bibitem[Zhang et~al.(2012)Zhang, Zhang, and Ye]{zhang2012generalizationNIPS}
Zhang, C., Zhang, L., and Ye, J.
\newblock Generalization bounds for domain adaptation.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2012.

\bibitem[Zhang et~al.(2013)Zhang, Zhang, and Ye]{zhang2012generalizationArxiv}
Zhang, C., Zhang, L., and Ye, J.
\newblock Generalization bounds for domain adaptation.
\newblock \emph{arXiv preprint arXiv:1304.1574}, 2013.

\bibitem[Zhang et~al.(2017)Zhang, Iwata, and Kashima]{zhang2017robust}
Zhang, G., Iwata, T., and Kashima, H.
\newblock Robust multi-view topic modeling by incorporating detecting
  anomalies.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, 2017.

\bibitem[Zhao et~al.(2017)Zhao, Xie, Xu, and Sun]{zhao2017multi}
Zhao, J., Xie, X., Xu, X., and Sun, S.
\newblock Multi-view learning overview: Recent progress and new challenges.
\newblock \emph{Information Fusion}, 38:\penalty0 43--54, 2017.

\bibitem[Zimin \& Lampert(2017)Zimin and Lampert]{zimin2017learning}
Zimin, A. and Lampert, C.~H.
\newblock Learning theory for conditional risk minimization.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence
  (AISTATS)}, 2017.

\end{thebibliography}
