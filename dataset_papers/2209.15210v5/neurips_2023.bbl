\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ben-David et~al.(2022)Ben-David, Oved, and Reichart]{ben2022pada}
Eyal Ben-David, Nadav Oved, and Roi Reichart.
\newblock Pada: Example-based prompt learning for on-the-fly adaptation to
  unseen domains.
\newblock \emph{TACL}, 2022.

\bibitem[Ben-David et~al.(2006)Ben-David, Blitzer, Crammer, and
  Pereira]{DAanalysis}
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira.
\newblock Analysis of representations for domain adaptation.
\newblock In \emph{NeurIPS}, 2006.

\bibitem[Bousmalis et~al.(2016)Bousmalis, Trigeorgis, Silberman, Krishnan, and
  Erhan]{domainseparationnetwork}
Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan,
  and Dumitru Erhan.
\newblock Domain separation networks.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Csurka(2017)]{csurka2017domain}
Gabriela Csurka.
\newblock Domain adaptation for visual applications: A comprehensive survey.
\newblock \emph{arXiv preprint arXiv:1702.05374}, 2017.

\bibitem[Deng et~al.(2022)Deng, Li, Song, and Xiang]{deng2022robust}
Zhongying Deng, Da~Li, Yi-Zhe Song, and Tao Xiang.
\newblock Robust target training for multi-source domain adaptation.
\newblock \emph{arXiv preprint arXiv:2210.01676}, 2022.

\bibitem[Devillers et~al.(2021)Devillers, Choksi, Bielawski, and
  VanRullen]{devillers2021does}
Benjamin Devillers, Bhavin Choksi, Romain Bielawski, and Rufin VanRullen.
\newblock Does language help generalization in vision models?
\newblock \emph{arXiv preprint arXiv:2104.08313}, 2021.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{ICLR}, 2021.

\bibitem[Fu et~al.(2021)Fu, Zhang, Xu, Cao, Ma, Ji, Zuo, and Lu]{fu2021pfsa}
Yangye Fu, Ming Zhang, Xing Xu, Zuo Cao, Chao Ma, Yanli Ji, Kai Zuo, and Huimin
  Lu.
\newblock Partial feature selection and alignment for multi-source domain
  adaptation.
\newblock In \emph{CVPR}, 2021.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{dannganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{JMLR}, 2016.

\bibitem[Ge et~al.(2022)Ge, Huang, Xie, Lai, Song, Li, and Huang]{dapt}
Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, and Gao
  Huang.
\newblock Domain adaptation via prompt learning.
\newblock \emph{arXiv preprint arXiv:2202.06687}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{Resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Jia et~al.(2022)Jia, Tang, Chen, Cardie, Belongie, Hariharan, and
  Lim]{jia2022vpt}
Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath
  Hariharan, and Ser-Nam Lim.
\newblock Visual prompt tuning.
\newblock \emph{arXiv preprint arXiv:2203.12119}, 2022.

\bibitem[Ju et~al.(2021)Ju, Han, Zheng, Zhang, and Xie]{ju2021videoprompting}
Chen Ju, Tengda Han, Kunhao Zheng, Ya~Zhang, and Weidi Xie.
\newblock Prompting visual-language models for efficient video understanding.
\newblock \emph{arXiv preprint arXiv:2112.04478}, 2021.

\bibitem[Kang et~al.(2019)Kang, Jiang, Yang, and Hauptmann]{contrastivealign}
Guoliang Kang, Lu~Jiang, Yi~Yang, and Alexander~G Hauptmann.
\newblock Contrastive adaptation network for unsupervised domain adaptation.
\newblock In \emph{CVPR}, 2019.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{NIPS2012_c399862d}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{NeurIPS}, 2012.

\bibitem[Lester et~al.(2021)Lester, Al-Rfou, and Constant]{lester2021power}
Brian Lester, Rami Al-Rfou, and Noah Constant.
\newblock The power of scale for parameter-efficient prompt tuning.
\newblock \emph{arXiv preprint arXiv:2104.08691}, 2021.

\bibitem[Li et~al.(2021)Li, Jia, He, Chen, and Hu]{li2021tsvdnet}
Ruihuang Li, Xu~Jia, Jianzhong He, Shuaijun Chen, and Qinghua Hu.
\newblock T-svdnet: Exploring high-order prototypical correlations for
  multi-source domain adaptation.
\newblock In \emph{ICCV}, 2021.

\bibitem[Li and Liang(2021)]{li2021prefix}
Xiang~Lisa Li and Percy Liang.
\newblock Prefix-tuning: Optimizing continuous prompts for generation.
\newblock \emph{arXiv preprint arXiv:2101.00190}, 2021.

\bibitem[Liu et~al.(2021{\natexlab{a}})Liu, Wang, and Long]{liu2021cycle}
Hong Liu, Jianmin Wang, and Mingsheng Long.
\newblock Cycle self-training for domain adaptation.
\newblock In \emph{NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Liu et~al.(2021{\natexlab{b}})Liu, Yuan, Fu, Jiang, Hayashi, and
  Neubig]{liu2021promptsurvey}
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
  Graham Neubig.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock \emph{arXiv preprint arXiv:2107.13586}, 2021{\natexlab{b}}.

\bibitem[Liu et~al.(2018)Liu, Yeh, Fu, Wang, Chiu, and Wang]{liu2018detach}
Yen-Cheng Liu, Yu-Ying Yeh, Tzu-Chien Fu, Sheng-De Wang, Wei-Chen Chiu, and
  Yu-Chiang~Frank Wang.
\newblock Detach and adapt: Learning cross-domain disentangled deep
  representation.
\newblock In \emph{CVPR}, 2018.

\bibitem[Long et~al.(2015)Long, Cao, Wang, and Jordan]{long2015dan}
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{ICML}, 2015.

\bibitem[Meng et~al.(2022)Meng, Li, Chen, Lan, Wu, Jiang, and Lim]{adavit}
Lingchen Meng, Hengduo Li, Bor-Chun Chen, Shiyi Lan, Zuxuan Wu, Yu-Gang Jiang,
  and Ser-Nam Lim.
\newblock Adavit: Adaptive vision transformers for efficient image recognition.
\newblock In \emph{CVPR}, 2022.

\bibitem[Meng et~al.(2023)Meng, Dai, Chen, Zhang, Chen, Liu, Wang, Wu, Yuan,
  and Jiang]{detectionhub}
Lingchen Meng, Xiyang Dai, Yinpeng Chen, Pengchuan Zhang, Dongdong Chen,
  Mengchen Liu, Jianfeng Wang, Zuxuan Wu, Lu~Yuan, and Yu-Gang Jiang.
\newblock Detection hub: Unifying object detection datasets via query
  adaptation on language embedding.
\newblock In \emph{CVPR}, 2023.

\bibitem[Pan and Yang(2010)]{transferlearningsurvey}
Sinno~Jialin Pan and Qiang Yang.
\newblock A survey on transfer learning.
\newblock \emph{TKDE}, 2010.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and
  Wang]{peng2019moment}
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo~Wang.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{ICCV}, 2019.

\bibitem[Quinonero-Candela et~al.(2008)Quinonero-Candela, Sugiyama,
  Schwaighofer, and Lawrence]{quinonero2008dataset}
Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil~D
  Lawrence.
\newblock \emph{Dataset shift in machine learning}.
\newblock 2008.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{ICML}, 2021.

\bibitem[Rakshit et~al.(2019)Rakshit, Banerjee, Roig, and
  Chaudhuri]{rakshit2019unsupervised}
Sayan Rakshit, Biplab Banerjee, Gemma Roig, and Subhasis Chaudhuri.
\newblock Unsupervised multi-source domain adaptation driven by deep
  adversarial ensemble learning.
\newblock In \emph{GCPR}, 2019.

\bibitem[Ren et~al.(2022)Ren, Liu, Zhang, and Huang]{ren2022ptmda}
Chuan-Xian Ren, Yong-Hui Liu, Xi-Wen Zhang, and Ke-Kun Huang.
\newblock Multi-source unsupervised domain adaptation via pseudo target domain.
\newblock \emph{TIP}, 2022.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{fasterrcnn}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Saito et~al.(2018)Saito, Watanabe, Ushiku, and Harada]{saito2018mcd}
Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada.
\newblock Maximum classifier discrepancy for unsupervised domain adaptation.
\newblock In \emph{CVPR}, 2018.

\bibitem[Sun and Saenko(2016)]{dcoralsun2016deep}
Baochen Sun and Kate Saenko.
\newblock Deep coral: Correlation alignment for deep domain adaptation.
\newblock In \emph{ECCV}, 2016.

\bibitem[Torralba and Efros(2011)]{datasetbias}
Antonio Torralba and Alexei~A Efros.
\newblock Unbiased look at dataset bias.
\newblock In \emph{CVPR}, 2011.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{adversarialalign}
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{CVPR}, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Venkat et~al.(2020)Venkat, Kundu, Singh, Revanur,
  et~al.]{venkat2020simpai}
Naveen Venkat, Jogendra~Nath Kundu, Durgesh Singh, Ambareesh Revanur, et~al.
\newblock Your classifier can secretly suffice multi-source domain adaptation.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Wang et~al.(2020)Wang, Xu, Ni, and Zhang]{wang2020ltc}
Hang Wang, Minghao Xu, Bingbing Ni, and Wenjun Zhang.
\newblock Learning to combine: Knowledge aggregation for multi-source domain
  adaptation.
\newblock In \emph{ECCV}, 2020.

\bibitem[Wang and Deng(2018)]{wang2018deep}
Mei Wang and Weihong Deng.
\newblock Deep visual domain adaptation: A survey.
\newblock \emph{Neurocomputing}, 2018.

\bibitem[Wang et~al.(2014)Wang, Huang, Wang, and Wang]{wang2014generalized}
Wei Wang, Yan Huang, Yizhou Wang, and Liang Wang.
\newblock Generalized autoencoder: A neural network framework for
  dimensionality reduction.
\newblock In \emph{CVPR workshops}, 2014.

\bibitem[Wei et~al.(2021)Wei, Xie, and Ma]{wei2021pretrained}
Colin Wei, Sang~Michael Xie, and Tengyu Ma.
\newblock Why do pretrained language models help in downstream tasks? an
  analysis of head and prompt tuning.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Weng et~al.(2023)Weng, Yang, Li, Wu, and Jiang]{openvclip}
Zejia Weng, Xitong Yang, Ang Li, Zuxuan Wu, and Yu-Gang Jiang.
\newblock Open-vclip: Transforming clip to an open-vocabulary video model via
  interpolated weight optimization.
\newblock 2023.

\bibitem[Xu et~al.(2018)Xu, Chen, Zuo, Yan, and Lin]{dctnxu2018deep}
Ruijia Xu, Ziliang Chen, Wangmeng Zuo, Junjie Yan, and Liang Lin.
\newblock Deep cocktail network: Multi-source unsupervised domain adaptation
  with category shift.
\newblock In \emph{CVPR}, 2018.

\bibitem[Xu et~al.(2022)Xu, Kan, Shan, and Chen]{xu2022mutual}
Yuanyuan Xu, Meina Kan, Shiguang Shan, and Xilin Chen.
\newblock Mutual learning of joint and separate domain alignments for
  multi-source domain adaptation.
\newblock In \emph{WACV}, 2022.

\bibitem[Yang et~al.(2022)Yang, Li, Zhang, Xiao, Liu, Yuan, and
  Gao]{yang2022unified}
Jianwei Yang, Chunyuan Li, Pengchuan Zhang, Bin Xiao, Ce~Liu, Lu~Yuan, and
  Jianfeng Gao.
\newblock Unified contrastive learning in image-text-label space.
\newblock In \emph{CVPR}, 2022.

\bibitem[Yang et~al.(2007)Yang, Yan, and Hauptmann]{yang2007cross}
Jun Yang, Rong Yan, and Alexander~G Hauptmann.
\newblock Cross-domain video concept detection using adaptive svms.
\newblock In \emph{ACM MM}, 2007.

\bibitem[Zhang et~al.(2013)Zhang, Sch{\"o}lkopf, Muandet, and
  Wang]{zhang2013domain}
Kun Zhang, Bernhard Sch{\"o}lkopf, Krikamol Muandet, and Zhikun Wang.
\newblock Domain adaptation under target and conditional shift.
\newblock In \emph{ICML}, 2013.

\bibitem[Zhao et~al.(2018)Zhao, Zhang, Wu, Moura, Costeira, and
  Gordon]{zhao2018adversarial}
Han Zhao, Shanghang Zhang, Guanhang Wu, Jos{\'e}~MF Moura, Joao~P Costeira, and
  Geoffrey~J Gordon.
\newblock Adversarial multiple source domain adaptation.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Zhao et~al.(2020)Zhao, Wang, Zhang, Gu, Li, Song, Xu, Hu, Chai, and
  Keutzer]{zhao2020multi}
Sicheng Zhao, Guangzhi Wang, Shanghang Zhang, Yang Gu, Yaxian Li, Zhichao Song,
  Pengfei Xu, Runbo Hu, Hua Chai, and Kurt Keutzer.
\newblock Multi-source distilling domain adaptation.
\newblock In \emph{AAAI}, 2020.

\bibitem[Zhou et~al.(2022)Zhou, Yang, Loy, and Liu]{coop}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Learning to prompt for vision-language models.
\newblock \emph{IJCV}, 2022.

\bibitem[Zhu et~al.(2019)Zhu, Zhuang, and Wang]{zhu2019mfsan}
Yongchun Zhu, Fuzhen Zhuang, and Deqing Wang.
\newblock Aligning domain-specific distribution and classifier for cross-domain
  classification from multiple sources.
\newblock In \emph{AAAI}, 2019.

\bibitem[Zou et~al.(2018)Zou, Yu, Kumar, and Wang]{zou2018unsupervised}
Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang.
\newblock Unsupervised domain adaptation for semantic segmentation via
  class-balanced self-training.
\newblock In \emph{ECCV}, 2018.

\end{thebibliography}
