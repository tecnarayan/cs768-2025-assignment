\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Boyan \& Moore(1995)Boyan and Moore]{boyan1995generalization}
Boyan, J.~A. and Moore, A.~W.
\newblock Generalization in reinforcement learning: Safely approximating the
  value function.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  369--376, 1995.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman2016openai}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Cheng et~al.(2019)Cheng, Verma, Orosz, Chaudhuri, Yue, and
  Burdick]{cheng2019control}
Cheng, R., Verma, A., Orosz, G., Chaudhuri, S., Yue, Y., and Burdick, J.~W.
\newblock Conrol regularization for reduced variance reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1905.05380}, 2019.

\bibitem[Gao \& Kleywegt(2016)Gao and Kleywegt]{gao2016distributionally}
Gao, R. and Kleywegt, A.~J.
\newblock Distributionally robust stochastic optimization with wasserstein
  distance.
\newblock \emph{arXiv preprint arXiv:1604.02199}, 2016.

\bibitem[garage contributors(2019)]{garage}
garage contributors, T.
\newblock Garage: A toolkit for reproducible reinforcement learning research.
\newblock \url{https://github.com/rlworkgroup/garage}, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Hampel(1974)]{hampel1974influence}
Hampel, F.~R.
\newblock The influence curve and its role in robust estimation.
\newblock \emph{Journal of the american statistical association}, 69\penalty0
  (346):\penalty0 383--393, 1974.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, Kadavath, and
  Song]{hendrycks2019using}
Hendrycks, D., Mazeika, M., Kadavath, S., and Song, D.
\newblock Using self-supervised learning can improve model robustness and
  uncertainty.
\newblock \emph{arXiv preprint arXiv:1906.12340}, 2019.

\bibitem[Huang et~al.(2018)Huang, Liu, Lang, Yu, Wang, and
  Li]{huang2018orthogonal}
Huang, L., Liu, X., Lang, B., Yu, A.~W., Wang, Y., and Li, B.
\newblock Orthogonal weight normalization: Solution to optimization over
  multiple dependent stiefel manifolds in deep neural networks.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Jiang et~al.(2019)Jiang, He, Chen, Liu, Gao, and Zhao]{jiang2019smart}
Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Zhao, T.
\newblock Smart: Robust and efficient fine-tuning for pre-trained natural
  language models through principled regularized optimization.
\newblock \emph{arXiv preprint arXiv:1911.03437}, 2019.

\bibitem[Jin et~al.(2018)Jin, Song, Li, Gai, Wang, and Zhang]{jin2018real}
Jin, J., Song, C., Li, H., Gai, K., Wang, J., and Zhang, W.
\newblock Real-time bidding with multi-agent reinforcement learning in display
  advertising.
\newblock In \emph{Proceedings of the 27th ACM International Conference on
  Information and Knowledge Management}, pp.\  2193--2201, 2018.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock \emph{arXiv preprint arXiv:1607.02533}, 2016.

\bibitem[Levine et~al.(2018)Levine, Pastor, Krizhevsky, Ibarz, and
  Quillen]{levine2018learning}
Levine, S., Pastor, P., Krizhevsky, A., Ibarz, J., and Quillen, D.
\newblock Learning hand-eye coordination for robotic grasping with deep
  learning and large-scale data collection.
\newblock \emph{The International Journal of Robotics Research}, 37\penalty0
  (4-5):\penalty0 421--436, 2018.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Miyato et~al.(2018)Miyato, Maeda, Ishii, and
  Koyama]{miyato2018virtual}
Miyato, T., Maeda, S.-i., Ishii, S., and Koyama, M.
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 2018.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Monahan(1982)]{monahan1982state}
Monahan, G.~E.
\newblock State of the art?a survey of partially observable markov decision
  processes: theory, models, and algorithms.
\newblock \emph{Management science}, 28\penalty0 (1):\penalty0 1--16, 1982.

\bibitem[Pinto et~al.(2017)Pinto, Davidson, Sukthankar, and
  Gupta]{pinto2017robust}
Pinto, L., Davidson, J., Sukthankar, R., and Gupta, A.
\newblock Robust adversarial reinforcement learning.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  2817--2826. JMLR. org, 2017.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015trust}
Schulman, J., Levine, S., Abbeel, P., Jordan, M., and Moritz, P.
\newblock Trust region policy optimization.
\newblock In \emph{International conference on machine learning}, pp.\
  1889--1897, 2015.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, et~al.]{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550\penalty0 (7676):\penalty0 354--359, 2017.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The journal of machine learning research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Thrun \& Schwartz(1993)Thrun and Schwartz]{thrun1993issues}
Thrun, S. and Schwartz, A.
\newblock Issues in using function approximation for reinforcement learning.
\newblock In \emph{Proceedings of the 1993 Connectionist Models Summer School
  Hillsdale, NJ. Lawrence Erlbaum}, 1993.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Xie et~al.(2019)Xie, Dai, Hovy, Luong, and Le]{xie2019unsupervised}
Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q.~V.
\newblock Unsupervised data augmentation.
\newblock \emph{arXiv preprint arXiv:1904.12848}, 2019.

\bibitem[Zhang et~al.(2016)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{zhang2016understanding}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O.
\newblock Understanding deep learning requires rethinking generalization.
\newblock \emph{arXiv preprint arXiv:1611.03530}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E.~P., Ghaoui, L.~E., and Jordan, M.~I.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock \emph{arXiv preprint arXiv:1901.08573}, 2019.

\bibitem[Zhao et~al.(2018)Zhao, Qiu, Guan, Zhao, and He]{zhao2018deep}
Zhao, J., Qiu, G., Guan, Z., Zhao, W., and He, X.
\newblock Deep reinforcement learning for sponsored search real-time bidding.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pp.\  1021--1030, 2018.

\bibitem[Zheng et~al.(2018)Zheng, Zhang, Zheng, Xiang, Yuan, Xie, and
  Li]{zheng2018drn}
Zheng, G., Zhang, F., Zheng, Z., Xiang, Y., Yuan, N.~J., Xie, X., and Li, Z.
\newblock Drn: A deep reinforcement learning framework for news recommendation.
\newblock In \emph{Proceedings of the 2018 World Wide Web Conference}, pp.\
  167--176, 2018.

\end{thebibliography}
