\begin{thebibliography}{10}

\bibitem{badias2021morph}
A.~Badias, I.~Alfaro, D.~Gonzalez, F.~Chinesta, and E.~Cueto, ``Morph-dslam:
  Model order reduction for physics-based deformable slam,'' {\em IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, vol.~44, no.~11,
  pp.~7764--7777, 2021.

\bibitem{li2021topologically}
T.~Li, S.~Liu, T.~Bolkart, J.~Liu, H.~Li, and Y.~Zhao, ``Topologically
  consistent multi-view face inference using volumetric sampling,'' in {\em
  Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pp.~3824--3834, 2021.

\bibitem{qian2020html}
N.~Qian, J.~Wang, F.~Mueller, F.~Bernard, V.~Golyanik, and C.~Theobalt, ``Html:
  A parametric hand texture model for 3d hand reconstruction and
  personalization,'' in {\em Computer Vision--ECCV 2020: 16th European
  Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16},
  pp.~54--71, Springer, 2020.

\bibitem{wang2021deep}
J.~Wang, S.~Tan, X.~Zhen, S.~Xu, F.~Zheng, Z.~He, and L.~Shao, ``Deep 3d human
  pose estimation: A review,'' {\em Computer Vision and Image Understanding},
  vol.~210, p.~103225, 2021.

\bibitem{li2021coarse}
C.~Li and G.~H. Lee, ``Coarse-to-fine animal pose and shape estimation,'' {\em
  Advances in Neural Information Processing Systems}, vol.~34,
  pp.~11757--11768, 2021.

\bibitem{su2020mulaycap}
Z.~Su, W.~Wan, T.~Yu, L.~Liu, L.~Fang, W.~Wang, and Y.~Liu, ``Mulaycap:
  Multi-layer human performance capture using a monocular video camera,'' {\em
  IEEE Transactions on Visualization and Computer Graphics}, vol.~28, no.~4,
  pp.~1862--1879, 2020.

\bibitem{lamarca2020defslam}
J.~Lamarca, S.~Parashar, A.~Bartoli, and J.~Montiel, ``Defslam: Tracking and
  mapping of deforming scenes from monocular sequences,'' {\em IEEE
  Transactions on robotics}, vol.~37, no.~1, pp.~291--303, 2020.

\bibitem{sengupta2021colonoscopic}
A.~Sengupta and A.~Bartoli, ``Colonoscopic 3d reconstruction by tubular
  non-rigid structure-from-motion,'' {\em International Journal of Computer
  Assisted Radiology and Surgery}, vol.~16, no.~7, pp.~1237--1241, 2021.

\bibitem{recasens2021endo}
D.~Recasens, J.~Lamarca, J.~M. F{\'a}cil, J.~Montiel, and J.~Civera,
  ``Endo-depth-and-motion: reconstruction and tracking in endoscopic videos
  using depth networks and photometric constraints,'' {\em IEEE Robotics and
  Automation Letters}, vol.~6, no.~4, pp.~7225--7232, 2021.

\bibitem{shao2022self}
S.~Shao, Z.~Pei, W.~Chen, W.~Zhu, X.~Wu, D.~Sun, and B.~Zhang,
  ``Self-supervised monocular depth and ego-motion estimation in endoscopy:
  Appearance flow to the rescue,'' {\em Medical image analysis}, vol.~77,
  p.~102338, 2022.

\bibitem{rabaud2008re}
V.~Rabaud and S.~Belongie, ``Re-thinking non-rigid structure from motion,'' in
  {\em 2008 IEEE Conference on Computer Vision and Pattern Recognition},
  pp.~1--8, IEEE, 2008.

\bibitem{gotardo2011non}
P.~F. Gotardo and A.~M. Martinez, ``Non-rigid structure from motion with
  complementary rank-3 spaces,'' in {\em CVPR 2011}, pp.~3065--3072, IEEE,
  2011.

\bibitem{lee2013procrustean}
M.~Lee, J.~Cho, C.-H. Choi, and S.~Oh, ``Procrustean normal distribution for
  non-rigid structure from motion,'' in {\em Proceedings of the IEEE Conference
  on computer vision and pattern recognition}, pp.~1280--1287, 2013.

\bibitem{garg2013dense}
R.~Garg, A.~Roussos, and L.~Agapito, ``Dense variational reconstruction of
  non-rigid surfaces from monocular video,'' in {\em Proceedings of the IEEE
  Conference on computer vision and pattern recognition}, pp.~1272--1279, 2013.

\bibitem{dai2014simple}
Y.~Dai, H.~Li, and M.~He, ``A simple prior-free method for non-rigid
  structure-from-motion factorization,'' {\em International Journal of Computer
  Vision}, vol.~107, pp.~101--122, 2014.

\bibitem{agudo2014good}
A.~Agudo, L.~Agapito, B.~Calvo, and J.~M. Montiel, ``Good vibrations: A modal
  analysis approach for sequential non-rigid structure from motion,'' in {\em
  Proceedings of the IEEE Conference on computer vision and pattern
  recognition}, pp.~1558--1565, 2014.

\bibitem{kong2019deep}
C.~Kong and S.~Lucey, ``Deep non-rigid structure from motion,'' in {\em
  Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pp.~1558--1567, 2019.

\bibitem{bozic2020deepdeform}
A.~Bozic, M.~Zollhofer, C.~Theobalt, and M.~Nie{\ss}ner, ``Deepdeform: Learning
  non-rigid rgb-d reconstruction with semi-supervised data,'' in {\em
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.~7002--7012, 2020.

\bibitem{yang2021lasr}
G.~Yang, D.~Sun, V.~Jampani, D.~Vlasic, F.~Cole, H.~Chang, D.~Ramanan, W.~T.
  Freeman, and C.~Liu, ``Lasr: Learning articulated shape reconstruction from a
  monocular video,'' in {\em Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, pp.~15980--15989, 2021.

\bibitem{tretschk2021non}
E.~Tretschk, A.~Tewari, V.~Golyanik, M.~Zollh{\"o}fer, C.~Lassner, and
  C.~Theobalt, ``Non-rigid neural radiance fields: Reconstruction and novel
  view synthesis of a dynamic scene from monocular video,'' in {\em Proceedings
  of the IEEE/CVF International Conference on Computer Vision},
  pp.~12959--12970, 2021.

\bibitem{pumarola2021d}
A.~Pumarola, E.~Corona, G.~Pons-Moll, and F.~Moreno-Noguer, ``D-nerf: Neural
  radiance fields for dynamic scenes,'' in {\em Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, pp.~10318--10327,
  2021.

\bibitem{potje2021extracting}
G.~Potje, R.~Martins, F.~Chamone, and E.~Nascimento, ``Extracting
  deformation-aware local features by learning to deform,'' {\em Advances in
  Neural Information Processing Systems}, vol.~34, pp.~10759--10771, 2021.

\bibitem{parashar2021robust}
S.~Parashar, D.~Pizarro, and A.~Bartoli, ``Robust isometric non-rigid
  structure-from-motion,'' {\em IEEE Transactions on Pattern Analysis and
  Machine Intelligence}, vol.~44, no.~10, pp.~6409--6423, 2021.

\bibitem{weng2022humannerf}
C.-Y. Weng, B.~Curless, P.~P. Srinivasan, J.~T. Barron, and
  I.~Kemelmacher-Shlizerman, ``Humannerf: Free-viewpoint rendering of moving
  people from monocular video,'' in {\em Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition}, pp.~16210--16220, 2022.

\bibitem{cadena2016past}
C.~Cadena, L.~Carlone, H.~Carrillo, Y.~Latif, D.~Scaramuzza, J.~Neira, I.~Reid,
  and J.~J. Leonard, ``Past, present, and future of simultaneous localization
  and mapping: Toward the robust-perception age,'' {\em IEEE Transactions on
  robotics}, vol.~32, no.~6, pp.~1309--1332, 2016.

\bibitem{gomez2021sd}
J.~J. G{\'o}mez-Rodr{\'\i}guez, J.~Lamarca, J.~Morlana, J.~D. Tard{\'o}s, and
  J.~M. Montiel, ``Sd-defslam: Semi-direct monocular slam for deformable and
  intracorporeal scenes,'' in {\em 2021 IEEE International Conference on
  Robotics and Automation (ICRA)}, pp.~5170--5177, IEEE, 2021.

\bibitem{ramakrishnan2021habitat}
S.~K. Ramakrishnan, A.~Gokaslan, E.~Wijmans, O.~Maksymets, A.~Clegg, J.~Turner,
  E.~Undersander, W.~Galuba, A.~Westbury, A.~X. Chang, {\em et~al.},
  ``Habitat-matterport 3d dataset (hm3d): 1000 large-scale 3d environments for
  embodied ai,'' {\em arXiv preprint arXiv:2109.08238}, 2021.

\bibitem{butler2012naturalistic}
D.~J. Butler, J.~Wulff, G.~B. Stanley, and M.~J. Black, ``A naturalistic open
  source movie for optical flow evaluation,'' in {\em Computer Vision--ECCV
  2012: 12th European Conference on Computer Vision, Florence, Italy, October
  7-13, 2012, Proceedings, Part VI 12}, pp.~611--625, Springer, 2012.

\bibitem{mayer2016large}
N.~Mayer, E.~Ilg, P.~Hausser, P.~Fischer, D.~Cremers, A.~Dosovitskiy, and
  T.~Brox, ``A large dataset to train convolutional networks for disparity,
  optical flow, and scene flow estimation,'' in {\em Proceedings of the IEEE
  conference on computer vision and pattern recognition}, pp.~4040--4048, 2016.

\bibitem{stoyanov2005soft}
D.~Stoyanov, G.~P. Mylonas, F.~Deligianni, A.~Darzi, and G.-Z. Yang,
  ``Soft-tissue motion tracking and structure estimation for robotic assisted
  mis procedures,'' in {\em MICCAI (2)}, pp.~139--146, 2005.

\bibitem{stoyanov2012stereoscopic}
D.~Stoyanov, ``Stereoscopic scene flow for robotic assisted minimally invasive
  surgery,'' in {\em Medical Image Computing and Computer-Assisted
  Intervention--MICCAI 2012: 15th International Conference, Nice, France,
  October 1-5, 2012, Proceedings, Part I 15}, pp.~479--486, Springer, 2012.

\bibitem{jensen2021benchmark}
S.~H.~N. Jensen, M.~E.~B. Doest, H.~Aan{\ae}s, and A.~Del~Bue, ``A benchmark
  and evaluation of non-rigid structure from motion,'' {\em International
  Journal of Computer Vision}, vol.~129, no.~4, pp.~882--899, 2021.

\bibitem{azagra2022endomapper}
P.~Azagra, C.~Sostres, {\'A}.~Ferrandez, L.~Riazuelo, C.~Tomasini, O.~L.
  Barbed, J.~Morlana, D.~Recasens, V.~M. Batlle, J.~J.
  G{\'o}mez-Rodr{\'\i}guez, {\em et~al.}, ``Endomapper dataset of complete
  calibrated endoscopy procedures,'' {\em arXiv preprint arXiv:2204.14240},
  2022.

\bibitem{teed2021droid}
Z.~Teed and J.~Deng, ``Droid-slam: Deep visual slam for monocular, stereo, and
  rgb-d cameras,'' {\em Advances in Neural Information Processing Systems},
  vol.~34, 2021.

\bibitem{teed2021raft}
Z.~Teed and J.~Deng, ``Raft-3d: Scene flow using rigid-motion embeddings,'' in
  {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.~8375--8384, 2021.

\bibitem{de2008performance}
E.~De~Aguiar, C.~Stoll, C.~Theobalt, N.~Ahmed, H.-P. Seidel, and S.~Thrun,
  ``Performance capture from sparse multi-view video,'' in {\em ACM SIGGRAPH
  2008 papers}, pp.~1--10, 2008.

\bibitem{bogo2014faust}
F.~Bogo, J.~Romero, M.~Loper, and M.~J. Black, ``Faust: Dataset and evaluation
  for 3d mesh registration,'' in {\em Proceedings of the IEEE conference on
  computer vision and pattern recognition}, pp.~3794--3801, 2014.

\bibitem{li20214dcomplete}
Y.~Li, H.~Takehara, T.~Taketomi, B.~Zheng, and M.~Nie{\ss}ner, ``4dcomplete:
  Non-rigid motion estimation beyond the observable surface,'' in {\em
  Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pp.~12706--12716, 2021.

\bibitem{mountney2010three}
P.~Mountney, D.~Stoyanov, and G.-Z. Yang, ``Three-dimensional tissue
  deformation recovery and tracking,'' {\em IEEE Signal Processing Magazine},
  vol.~27, no.~4, pp.~14--24, 2010.

\bibitem{stoyanov2010real}
D.~Stoyanov, M.~V. Scarzanella, P.~Pratt, and G.-Z. Yang, ``Real-time stereo
  reconstruction in robotically assisted minimally invasive surgery,'' in {\em
  International Conference on Medical Image Computing and Computer-Assisted
  Intervention}, 2010.

\bibitem{pratt2010dynamic}
P.~Pratt, D.~Stoyanov, M.~Visentini-Scarzanella, and G.-Z. Yang, ``Dynamic
  guidance for robotic surgery using image-constrained biomechanical models,''
  in {\em International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pp.~77--85, 2010.

\bibitem{sturm2012benchmark}
J.~Sturm, N.~Engelhard, F.~Endres, W.~Burgard, and D.~Cremers, ``A benchmark
  for the evaluation of rgb-d slam systems,'' in {\em 2012 IEEE/RSJ
  international conference on intelligent robots and systems}, pp.~573--580,
  IEEE, 2012.

\bibitem{geiger2013vision}
A.~Geiger, P.~Lenz, C.~Stiller, and R.~Urtasun, ``Vision meets robotics: The
  kitti dataset,'' {\em The International Journal of Robotics Research},
  vol.~32, no.~11, pp.~1231--1237, 2013.

\bibitem{wilson2014robust}
K.~Wilson and N.~Snavely, ``Robust global translations with 1dsfm,'' in {\em
  Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland,
  September 6-12, 2014, Proceedings, Part III 13}, pp.~61--75, Springer, 2014.

\bibitem{burri2016euroc}
M.~Burri, J.~Nikolic, P.~Gohl, T.~Schneider, J.~Rehder, S.~Omari, M.~W.
  Achtelik, and R.~Siegwart, ``The euroc micro aerial vehicle datasets,'' {\em
  The International Journal of Robotics Research}, vol.~35, no.~10,
  pp.~1157--1163, 2016.

\bibitem{dai2017scannet}
A.~Dai, A.~X. Chang, M.~Savva, M.~Halber, T.~Funkhouser, and M.~Nie{\ss}ner,
  ``Scannet: Richly-annotated 3d reconstructions of indoor scenes,'' in {\em
  Proceedings of the IEEE conference on computer vision and pattern
  recognition}, pp.~5828--5839, 2017.

\bibitem{schubert2018tum}
D.~Schubert, T.~Goll, N.~Demmel, V.~Usenko, J.~St{\"u}ckler, and D.~Cremers,
  ``The tum vi benchmark for evaluating visual-inertial odometry,'' in {\em
  2018 IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS)}, pp.~1680--1687, IEEE, 2018.

\bibitem{schops2019bad}
T.~Schops, T.~Sattler, and M.~Pollefeys, ``Bad slam: Bundle adjusted direct
  rgb-d slam,'' in {\em Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, pp.~134--144, 2019.

\bibitem{handa2014benchmark}
A.~Handa, T.~Whelan, J.~McDonald, and A.~J. Davison, ``A benchmark for rgb-d
  visual odometry, 3d reconstruction and slam,'' in {\em 2014 IEEE
  international conference on Robotics and automation (ICRA)}, pp.~1524--1531,
  IEEE, 2014.

\bibitem{straub2019replica}
J.~Straub, T.~Whelan, L.~Ma, Y.~Chen, E.~Wijmans, S.~Green, J.~J. Engel,
  R.~Mur-Artal, C.~Ren, S.~Verma, {\em et~al.}, ``The replica dataset: A
  digital replica of indoor spaces,'' {\em arXiv preprint arXiv:1906.05797},
  2019.

\bibitem{wang2020tartanair}
W.~Wang, D.~Zhu, X.~Wang, Y.~Hu, Y.~Qiu, C.~Wang, Y.~Hu, A.~Kapoor, and
  S.~Scherer, ``Tartanair: A dataset to push the limits of visual slam,'' in
  {\em 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS)}, pp.~4909--4916, IEEE, 2020.

\bibitem{minoda2021viode}
K.~Minoda, F.~Schilling, V.~W{\"u}est, D.~Floreano, and T.~Yairi, ``Viode: A
  simulated dataset to address the challenges of visual-inertial odometry in
  dynamic environments,'' {\em IEEE Robotics and Automation Letters}, vol.~6,
  no.~2, pp.~1343--1350, 2021.

\bibitem{baker2011database}
S.~Baker, D.~Scharstein, J.~Lewis, S.~Roth, M.~J. Black, and R.~Szeliski, ``A
  database and evaluation methodology for optical flow,'' {\em International
  journal of computer vision}, vol.~92, pp.~1--31, 2011.

\bibitem{dosovitskiy2015flownet}
A.~Dosovitskiy, P.~Fischer, E.~Ilg, P.~Hausser, C.~Hazirbas, V.~Golkov, P.~Van
  Der~Smagt, D.~Cremers, and T.~Brox, ``Flownet: Learning optical flow with
  convolutional networks,'' in {\em Proceedings of the IEEE international
  conference on computer vision}, pp.~2758--2766, 2015.

\bibitem{ilg2018occlusions}
E.~Ilg, T.~Saikia, M.~Keuper, and T.~Brox, ``Occlusions, motion and depth
  boundaries with a generic network for disparity, optical flow or scene flow
  estimation,'' in {\em Proceedings of the European conference on computer
  vision (ECCV)}, pp.~614--630, 2018.

\bibitem{mehl2023spring}
L.~Mehl, J.~Schmalfuss, A.~Jahedi, Y.~Nalivayko, and A.~Bruhn, ``Spring: A
  high-resolution high-detail dataset and benchmark for scene flow, optical
  flow and stereo,'' {\em arXiv preprint arXiv:2303.01943}, 2023.

\bibitem{carlucci2017deep}
F.~M. Carlucci, P.~Russo, and B.~Caputo, ``A deep representation for depth
  images from synthetic data,'' in {\em 2017 IEEE international conference on
  robotics and automation (ICRA)}, pp.~1362--1369, IEEE, 2017.

\bibitem{planche2017depthsynth}
B.~Planche, Z.~Wu, K.~Ma, S.~Sun, S.~Kluckner, O.~Lehmann, T.~Chen, A.~Hutter,
  S.~Zakharov, H.~Kosch, {\em et~al.}, ``Depthsynth: Real-time realistic
  synthetic data generation from cad models for 2.5 d recognition,'' in {\em
  2017 International Conference on 3D Vision (3DV)}, pp.~1--10, IEEE, 2017.

\bibitem{chang2015shapenet}
A.~X. Chang, T.~Funkhouser, L.~Guibas, P.~Hanrahan, Q.~Huang, Z.~Li,
  S.~Savarese, M.~Savva, S.~Song, H.~Su, {\em et~al.}, ``Shapenet: An
  information-rich 3d model repository,'' {\em arXiv preprint
  arXiv:1512.03012}, 2015.

\bibitem{gaidon2016virtual}
A.~Gaidon, Q.~Wang, Y.~Cabon, and E.~Vig, ``Virtual worlds as proxy for
  multi-object tracking analysis,'' in {\em Proceedings of the IEEE conference
  on computer vision and pattern recognition}, pp.~4340--4349, 2016.

\bibitem{mccormac2017scenenet}
J.~McCormac, A.~Handa, S.~Leutenegger, and A.~J. Davison, ``Scenenet rgb-d: Can
  5m synthetic images beat generic imagenet pre-training on indoor
  segmentation?,'' in {\em Proceedings of the IEEE International Conference on
  Computer Vision}, pp.~2678--2687, 2017.

\bibitem{johnson2017clevr}
J.~Johnson, B.~Hariharan, L.~Van Der~Maaten, L.~Fei-Fei, C.~Lawrence~Zitnick,
  and R.~Girshick, ``Clevr: A diagnostic dataset for compositional language and
  elementary visual reasoning,'' in {\em Proceedings of the IEEE conference on
  computer vision and pattern recognition}, pp.~2901--2910, 2017.

\bibitem{roberts2021hypersim}
M.~Roberts, J.~Ramapuram, A.~Ranjan, A.~Kumar, M.~A. Bautista, N.~Paczan,
  R.~Webb, and J.~M. Susskind, ``Hypersim: A photorealistic synthetic dataset
  for holistic indoor scene understanding,'' in {\em Proceedings of the
  IEEE/CVF international conference on computer vision}, pp.~10912--10922,
  2021.

\bibitem{nikolenko2019synthetic}
S.~I. Nikolenko, ``Synthetic data for deep learning,'' {\em arXiv preprint
  arXiv:1909.11512}, 2019.

\bibitem{song2018mis}
J.~Song, J.~Wang, L.~Zhao, S.~Huang, and G.~Dissanayake, ``Mis-slam: Real-time
  large-scale dense deformable slam system in minimal invasive surgery based on
  heterogeneous computing,'' {\em IEEE Robotics and Automation Letters},
  vol.~3, no.~4, pp.~4068--4075, 2018.

\bibitem{lamarca2022direct}
J.~Lamarca, J.~J.~G. Rodriguez, J.~D. Tardos, and J.~M. Montiel, ``Direct and
  sparse deformable tracking,'' {\em IEEE Robotics and Automation Letters},
  vol.~7, no.~4, pp.~11450--11457, 2022.

\bibitem{rodriguez2022tracking}
J.~J.~G. Rodr{\'\i}guez, J.~M. Montiel, and J.~D. Tard{\'o}s, ``Tracking
  monocular camera pose and deformation for slam inside the human body,'' in
  {\em 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS)}, pp.~5278--5285, IEEE, 2022.

\bibitem{blender}
B.~O. Community, {\em Blender - a 3D modelling and rendering package}.
\newblock Blender Foundation, Stichting Blender Foundation, Amsterdam, 2018.

\bibitem{cho2014properties}
K.~Cho, B.~Van~Merri{\"e}nboer, D.~Bahdanau, and Y.~Bengio, ``On the properties
  of neural machine translation: Encoder-decoder approaches,'' {\em arXiv
  preprint arXiv:1409.1259}, 2014.

\bibitem{schoenberger2016sfm}
J.~L. Sch\"{o}nberger and J.-M. Frahm, ``Structure-from-motion revisited,'' in
  {\em Conference on Computer Vision and Pattern Recognition (CVPR)}, 2016.

\bibitem{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter, ``Decoupled weight decay regularization,'' {\em
  arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei, ``Imagenet: A
  large-scale hierarchical image database,'' in {\em 2009 IEEE conference on
  computer vision and pattern recognition}, pp.~248--255, Ieee, 2009.

\bibitem{schoenberger2016mvs}
J.~L. Sch\"{o}nberger, E.~Zheng, M.~Pollefeys, and J.-M. Frahm, ``Pixelwise
  view selection for unstructured multi-view stereo,'' in {\em European
  Conference on Computer Vision (ECCV)}, 2016.

\bibitem{prokhorov2019measuring}
D.~Prokhorov, D.~Zhukov, O.~Barinova, K.~Anton, and A.~Vorontsova, ``Measuring
  robustness of visual slam,'' in {\em 2019 16th International Conference on
  Machine Vision Applications (MVA)}, pp.~1--6, IEEE, 2019.

\bibitem{gao2018ldso}
X.~Gao, R.~Wang, N.~Demmel, and D.~Cremers, ``Ldso: Direct sparse odometry with
  loop closure,'' in {\em 2018 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)}, pp.~2198--2204, IEEE, 2018.

\bibitem{engel2017direct}
J.~Engel, V.~Koltun, and D.~Cremers, ``Direct sparse odometry,'' {\em IEEE
  transactions on pattern analysis and machine intelligence}, vol.~40, no.~3,
  pp.~611--625, 2017.

\end{thebibliography}
