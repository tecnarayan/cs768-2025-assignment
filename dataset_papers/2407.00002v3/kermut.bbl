\begin{thebibliography}{10}

\bibitem{riesselman_deep_2018}
Adam~J. Riesselman, John~B. Ingraham, and Debora~S. Marks.
\newblock Deep generative models of genetic variation capture the effects of mutations.
\newblock {\em Nature Methods}, 15(10):816--822, October 2018.

\bibitem{rives_biological_2020}
Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C~Lawrence Zitnick, Jerry Ma, et~al.
\newblock Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.
\newblock {\em Proceedings of the National Academy of Sciences}, 118(15):e2016239118, 2021.

\bibitem{cheng_accurate_2023}
Jun Cheng, Guido Novati, Joshua Pan, Clare Bycroft, Akvil{\.e} {\v Z}emgulyt{\.e}, Taylor Applebaum, Alexander Pritzel, Lai~Hong Wong, Michal Zielinski, Tobias Sargeant, Rosalia~G. Schneider, Andrew~W. Senior, John Jumper, Demis Hassabis, Pushmeet Kohli, and {\v Z}iga Avsec.
\newblock Accurate proteome-wide missense variant effect prediction with {{AlphaMissense}}.
\newblock {\em Science}, 381(6664):eadg7492, September 2023.

\bibitem{tsuboyama_mega-scale_2023}
Kotaro Tsuboyama, Justas Dauparas, Jonathan Chen, Elodie Laine, Yasser Mohseni~Behbahani, Jonathan~J. Weinstein, Niall~M. Mangan, Sergey Ovchinnikov, and Gabriel~J. Rocklin.
\newblock Mega-scale experimental analysis of protein folding stability in biology and design.
\newblock {\em Nature}, pages 1--11, July 2023.

\bibitem{10.1093/nar/gkad1011}
Mihaly Varadi, Damian Bertoni, Paulyna Magana, Urmila Paramval, Ivanna Pidruchna, Malarvizhi Radhakrishnan, Maxim Tsenkov, Sreenath Nair, Milot Mirdita, Jingi Yeo, Oleg Kovalevskiy, Kathryn Tunyasuvunakool, Agata Laydon, Augustin {\v Z}{\'i}dek, Hamish Tomlinson, Dhavanthi Hariharan, Josh Abrahamson, Tim Green, John Jumper, Ewan Birney, Martin Steinegger, Demis Hassabis, and Sameer Velankar.
\newblock {AlphaFold Protein Structure Database in 2024: Providing Structure Coverage for over 214 Million Protein Sequences}.
\newblock {\em Nucleic Acids Research}, 52(D1):D368--D375, November 2023.

\bibitem{dallago_flip_2022}
Christian Dallago, Jody Mou, Kadina~E Johnston, Bruce Wittmann, Nick Bhattacharya, Samuel Goldman, Ali Madani, and Kevin~K. Yang.
\newblock {FLIP}: Benchmark tasks in fitness landscape inference for proteins.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem{notin_proteingym_2023}
Pascal Notin, Aaron~W. Kollasch, Daniel Ritter, Lood~Van Niekerk, Steffan Paul, Han Spinner, Nathan~J. Rollins, Ada Shaw, Rose Orenbuch, Ruben Weitzman, Jonathan Frazer, Mafalda Dias, Dinko Franceschi, Yarin Gal, and Debora~Susan Marks.
\newblock {{ProteinGym}}: {{Large-Scale Benchmarks}} for {{Protein Fitness Prediction}} and {{Design}}.
\newblock In {\em Thirty-Seventh {{Conference}} on {{Neural Information Processing Systems Datasets}} and {{Benchmarks Track}}}, November 2023.

\bibitem{10.5555/3625834.3625890}
Jonathan Foldager, Mikkel Jordahn, Lars~Kai Hansen, and Michael~Riis Andersen.
\newblock {On the Role of Model Uncertainties in Bayesian Optimization}.
\newblock In {\em Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence}, UAI '23. JMLR.org, 2023.

\bibitem{frazer_disease_2021}
Jonathan Frazer, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph~K. Min, Kelly Brock, Yarin Gal, and Debora~S. Marks.
\newblock Disease variant prediction with deep generative models of evolutionary data.
\newblock {\em Nature}, 599(7883):91--95, November 2021.

\bibitem{meier_language_2021}
Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and Alex Rives.
\newblock Language models enable zero-shot prediction of the effects of mutations on protein function.
\newblock {\em Advances in neural information processing systems}, 34:29287--29303, 2021.

\bibitem{notin_tranception_2022}
Pascal Notin, Mafalda Dias, Jonathan Frazer, Javier Marchena-Hurtado, Aidan~N. Gomez, Debora Marks, and Yarin Gal.
\newblock Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval.
\newblock In {\em International Conference on Machine Learning}, pages 16990--17017. PMLR, 2022.

\bibitem{yang_machine-learning-guided_2019}
Kevin~K. Yang, Zachary Wu, and Frances~H. Arnold.
\newblock Machine-learning-guided directed evolution for protein engineering.
\newblock {\em Nature Methods}, 16(8):687--694, August 2019.

\bibitem{asgari2015continuous}
Ehsaneddin Asgari and Mohammad R.~K. Mofrad.
\newblock {Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics}.
\newblock {\em PloS one}, 10(11):e0141287, 2015.

\bibitem{yang_learned_2018}
Kevin~K. Yang, Zachary Wu, Claire~N. Bedbrook, and Frances~H. Arnold.
\newblock Learned protein embeddings for machine learning.
\newblock {\em Bioinformatics (Oxford, England)}, 34(15):2642--2648, August 2018.

\bibitem{elnaggar_prottrans_2021}
Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Yu~Wang, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, et~al.
\newblock {ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning}.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence}, 44(10):7112--7127, 2021.

\bibitem{lin_language_2022}
Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et~al.
\newblock Evolutionary-scale prediction of atomic-level protein structure with a language model.
\newblock {\em Science}, 379(6637):1123--1130, 2023.

\bibitem{su2023saprot}
Jin Su, Chenchen Han, Yuyang Zhou, Junjie Shan, Xibin Zhou, and Fajie Yuan.
\newblock {SaProt}: {Protein Language Modeling with Structure-aware Vocabulary}.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{hsu_learning_2022-1}
Chloe Hsu, Hunter Nisonoff, Clara Fannjiang, and Jennifer Listgarten.
\newblock Learning protein fitness models from evolutionary and assay-labeled data.
\newblock {\em Nature Biotechnology}, pages 1--9, January 2022.

\bibitem{notin_proteinnpt_2023}
Pascal Notin, Ruben Weitzman, Debora Marks, and Yarin Gal.
\newblock {ProteinNPT: Improving Protein Property Prediction and Design with Non-Parametric Transformers}.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~36, pages 33529--33563. Curran Associates, Inc., 2023.

\bibitem{rao_msa_2021}
Roshan~M. Rao, Jason Liu, Robert Verkuil, Joshua Meier, John Canny, Pieter Abbeel, Tom Sercu, and Alexander Rives.
\newblock {{MSA Transformer}}.
\newblock In {\em Proceedings of the 38th {{International Conference}} on {{Machine Learning}}}, pages 8844--8856. {PMLR}, July 2021.

\bibitem{rao_evaluating_2019}
Roshan~M. Rao, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Peter Chen, John Canny, Pieter Abbeel, and Yun Song.
\newblock {Evaluating protein transfer learning with TAPE}.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{xu_peer_2022}
Minghao Xu, Zuobai Zhang, Jiarui Lu, Zhaocheng Zhu, Yangtian Zhang, Ma~Chang, Runcheng Liu, and Jian Tang.
\newblock {{PEER}}: {{A Comprehensive}} and {{Multi-Task Benchmark}} for {{Protein Sequence Understanding}}.
\newblock {\em Advances in Neural Information Processing Systems}, 35:35156--35173, 2022.

\bibitem{townshend_atom3d_2022}
Raphael John~Lamarre Townshend, Martin V{\"o}gele, Patricia~Adriana Suriana, Alexander Derry, Alexander Powers, Yianni Laloudakis, Sidhika Balachandar, Bowen Jing, Brandon~M. Anderson, Stephan Eismann, Risi Kondor, Russ Altman, and Ron~O. Dror.
\newblock {{ATOM3D}}: {{Tasks On Molecules}} in {{Three Dimensions}}.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)}, 2021.

\bibitem{groth_flop_2023}
Peter~M{\o}rch Groth, Richard Michael, Jesper Salomon, Pengfei Tian, and Wouter Boomsma.
\newblock {{FLOP}}: {{Tasks}} for {{Fitness Landscapes Of Protein}} wildtypes, June 2023.

\bibitem{leslie_spectrum_2001}
Christina Leslie, Eleazar Eskin, and William~Stafford Noble.
\newblock {The spectrum kernel: A string kernel for SVM protein classification}.
\newblock In {\em Biocomputing 2002}, pages 564--575. {WORLD SCIENTIFIC}, December 2001.

\bibitem{leslie_mismatch_2004}
Christina~S. Leslie, Eleazar Eskin, Adiel Cohen, Jason Weston, and William~Stafford Noble.
\newblock {Mismatch String Kernels for Discriminative Protein Classification}.
\newblock {\em Bioinformatics}, 20(4):467--476, March 2004.

\bibitem{moss2020boss}
Henry Moss, David Leslie, Daniel Beck, Javier Gonzalez, and Paul Rayson.
\newblock {BOSS: Bayesian Optimization over String Spaces}.
\newblock {\em Advances in neural information processing systems}, 33:15476--15486, 2020.

\bibitem{toussaint2010exploiting}
Nora~C. Toussaint, Christian Widmer, Oliver Kohlbacher, and Gunnar R{\"a}tsch.
\newblock Exploiting physico-chemical properties in string kernels.
\newblock {\em BMC bioinformatics}, 11:1--9, 2010.

\bibitem{romero_navigating_2013}
Philip~A. Romero, Andreas Krause, and Frances~H. Arnold.
\newblock Navigating the protein fitness landscape with {{Gaussian}} processes.
\newblock {\em Proceedings of the National Academy of Sciences}, 110(3):E193--E201, January 2013.

\bibitem{greenhalgh2021machine}
Jonathan~C. Greenhalgh, Sarah~A. Fahlberg, Brian~F. Pfleger, and Philip~A. Romero.
\newblock {Machine learning-guided acyl-ACP reductase engineering for improved in vivo fatty alcohol production}.
\newblock {\em Nature communications}, 12(1):5825, 2021.

\bibitem{amin2023biological}
Alan~Nawzad Amin, Eli~Nathan Weinstein, and Debora~Susan Marks.
\newblock Biological sequence kernels with guaranteed flexibility.
\newblock {\em arXiv preprint arXiv:2304.03775}, 2023.

\bibitem{jokinen_mgpfusion_2018}
Emmi Jokinen, Markus Heinonen, and Harri L{\"a}hdesm{\"a}ki.
\newblock {{mGPfusion}}: Predicting protein stability changes with {{Gaussian}} process kernel learning and data fusion.
\newblock {\em Bioinformatics}, 34(13):i274--i283, July 2018.

\bibitem{leaver2011rosetta3}
Andrew Leaver-Fay, Michael Tyka, Steven~M. Lewis, Oliver~F. Lange, James Thompson, Ron Jacak, Kristian~W. Kaufman, P.~Douglas Renfrew, Colin~A. Smith, Will Sheffler, et~al.
\newblock {ROSETTA3: an object-oriented software suite for the simulation and design of macromolecules}.
\newblock In {\em Methods in enzymology}, volume 487, pages 545--574. Elsevier, 2011.

\bibitem{parkinson2023linear}
Jonathan Parkinson and Wei Wang.
\newblock Linear-scaling kernels for protein sequences and small molecules outperform deep learning while providing uncertainty quantitation and improved interpretability.
\newblock {\em Journal of Chemical Information and Modeling}, 63(15):4589--4601, 2023.

\bibitem{zeng2019quantification}
Haoyang Zeng and David~K Gifford.
\newblock {Quantification of Uncertainty in Peptide-MHC Binding Prediction Improves High-Affinity Peptide Selection for Therapeutic Design}.
\newblock {\em Cell systems}, 9(2):159--166, 2019.

\bibitem{hie_leveraging_2020}
Brian Hie, Bryan~D. Bryson, and Bonnie Berger.
\newblock Leveraging {{Uncertainty}} in {{Machine Learning Accelerates Biological Discovery}} and {{Design}}.
\newblock {\em Cell Systems}, 11(5):461--477.e9, November 2020.

\bibitem{nisonoff2023coherent}
Hunter Nisonoff, Yixin Wang, and Jennifer Listgarten.
\newblock {Coherent Blending of Biophysics-Based Knowledge with Bayesian Neural Networks for Robust Protein Property Prediction}.
\newblock {\em ACS Synthetic Biology}, 12(11):3242--3251, 2023.

\bibitem{ko2024tuna}
Young~Su Ko, Jonathan Parkinson, Cong Liu, and Wei Wang.
\newblock {TUnA}: an uncertainty-aware transformer model for sequence-based protein--protein interaction prediction.
\newblock {\em Briefings in Bioinformatics}, 25(5):bbae359, 2024.

\bibitem{liu2020simple}
Jeremiah Liu, Zi~Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax~Weiss, and Balaji Lakshminarayanan.
\newblock {Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness}.
\newblock {\em Advances in neural information processing systems}, 33:7498--7512, 2020.

\bibitem{gustafsson_evaluating_2020}
Fredrik~K. Gustafsson, Martin Danelljan, and Thomas~B. Schon.
\newblock {Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer Vision}.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops}, pages 318--319, 2020.

\bibitem{scalia_evaluating_2020}
Gabriele Scalia, Colin~A. Grambow, Barbara Pernici, Yi-Pei Li, and William~H. Green.
\newblock Evaluating {{Scalable Uncertainty Estimation Methods}} for {{Deep Learning-Based Molecular Property Prediction}}.
\newblock {\em ACS}, 2020.

\bibitem{levi_evaluating_2020}
Dan Levi, Liran Gispan, Niv Giladi, and Ethan Fetaya.
\newblock Evaluating and {{Calibrating Uncertainty Prediction}} in {{Regression Tasks}}.
\newblock {\em Sensors}, 22(15):5540, 2022.

\bibitem{hirschfeld2020uncertainty}
Lior Hirschfeld, Kyle Swanson, Kevin Yang, Regina Barzilay, and Connor~W Coley.
\newblock {Uncertainty Quantification Using Neural Networks for Molecular Property Prediction}.
\newblock {\em Journal of Chemical Information and Modeling}, 60(8):3770--3780, 2020.

\bibitem{tran2020methods}
Kevin Tran, Willie Neiswanger, Junwoong Yoon, Qingyang Zhang, Eric Xing, and Zachary~W Ulissi.
\newblock Methods for comparing uncertainty quantifications for material property predictions.
\newblock {\em Machine Learning: Science and Technology}, 1(2):025006, 2020.

\bibitem{greenman2023benchmarking}
Kevin~P. Greenman, Ava~P. Amini, and Kevin~K. Yang.
\newblock Benchmarking uncertainty quantification for protein engineering.
\newblock {\em bioRxiv}, pages 2023--04, 2023.

\bibitem{li2023muben}
Yinghao Li, Lingkai Kong, Yuanqi Du, Yue Yu, Yuchen Zhuang, Wenhao Mu, and Chao Zhang.
\newblock {MUB}en: Benchmarking the uncertainty of molecular representation models.
\newblock {\em Transactions on Machine Learning Research}, 2024.

\bibitem{thaler2024active}
Stephan Thaler, Felix Mayr, Siby Thomas, Alessio Gagliardi, and Julija Zavadlav.
\newblock {Active learning graph neural networks for partial charge prediction of metal-organic frameworks via dropout Monte Carlo}.
\newblock {\em npj Computational Materials}, 10(1):86, 2024.

\bibitem{pmlr-v48-gal16}
Yarin Gal and Zoubin Ghahramani.
\newblock {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning}.
\newblock In {\em Proceedings of The 33rd International Conference on Machine Learning}, volume~48 of {\em Proceedings of Machine Learning Research}, pages 1050--1059, New York, New York, USA, 20--22 Jun 2016. PMLR.

\bibitem{michael_systematic_2024}
Richard Michael, Jacob {K{\ae}stel-Hansen}, Peter~M{\o}rch Groth, Simon Bartels, Jesper Salomon, Pengfei Tian, Nikos~S. Hatzakis, and Wouter Boomsma.
\newblock {A Systematic Analysis of Regression Models for Protein Engineering}.
\newblock {\em PLOS Computational Biology}, 20(5):e1012061, May 2024.

\bibitem{10.5555/3454287.3455704}
John Ingraham, Vikas Garg, Regina Barzilay, and Tommi Jaakkola.
\newblock Generative models for graph-based protein design.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{hsu_learning_2022}
Chloe Hsu, Robert Verkuil, Jason Liu, Zeming Lin, Brian Hie, Tom Sercu, Adam Lerer, and Alexander Rives.
\newblock {Learning Inverse Folding from Millions of Predicted Structures}.
\newblock In {\em Proceedings of the 39th {{International Conference}} on {{Machine Learning}}}, pages 8946--8970. {PMLR}, June 2022.

\bibitem{dauparas_robust_2022}
Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert~J. Ragotte, Lukas~F. Milles, Basile I.~M. Wicky, Alexis Courbet, Rob~J. de~Haas, Neville Bethel, et~al.
\newblock {Robust deep learning--based protein sequence design using ProteinMPNN}.
\newblock {\em Science}, 378(6615):49--56, 2022.

\bibitem{gao_pifold_2023}
Zhangyang Gao, Cheng Tan, and Stan~Z. Li.
\newblock {PiFold: Toward effective and efficient protein inverse folding}.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{gao2023knowledge}
Zhangyang Gao, Cheng Tan, Xingran Chen, Yijie Zhang, Jun Xia, Siyuan Li, and Stan~Z. Li.
\newblock {KW-Design: Pushing the Limit of Protein Design via Knowledge Refinement}.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{zhou2023prorefiner}
Xinyi Zhou, Guangyong Chen, Junjie Ye, Ercheng Wang, Jun Zhang, Cong Mao, Zhanwei Li, Jianye Hao, Xingxu Huang, Jin Tang, and Pheng~Ann Heng.
\newblock {ProRefiner: an entropy-based refining strategy for inverse protein folding with global graph attention}.
\newblock {\em Nature Communications}, 14(1):7434, 2023.

\bibitem{ren2024accurate}
Milong Ren, Chungong Yu, Dongbo Bu, and Haicang Zhang.
\newblock {Accurate and robust protein sequence design with CarbonDesign}.
\newblock {\em Nature Machine Intelligence}, 6(5):536--547, 2024.

\bibitem{torng20173d}
Wen Torng and Russ~B. Altman.
\newblock {3D deep convolutional neural networks for amino acid environment similarity analysis}.
\newblock {\em BMC bioinformatics}, 18:1--23, 2017.

\bibitem{gainza_deciphering_2020}
Pablo Gainza, Freyr Sverrisson, Frederico Monti, Emanuele Rodola, Davide Boscaini, Michael~M Bronstein, and Bruno~E Correia.
\newblock Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning.
\newblock {\em Nature Methods}, 17(2):184--192, 2020.

\bibitem{gainza_novo_2023}
Pablo Gainza, Sarah Wehrle, Alexandra {Van Hall-Beauvais}, Anthony Marchand, Andreas Scheck, Zander Harteveld, Stephen Buckley, Dongchun Ni, Shuguang Tan, Freyr Sverrisson, Casper Goverde, Priscilla Turelli, Charl{\`e}ne Raclot, Alexandra Teslenko, Martin Pacesa, St{\'e}phane Rosset, Sandrine Georgeon, Jane Marsden, Aaron Petruzzella, Kefang Liu, Zepeng Xu, Yan Chai, Pu~Han, George~F. Gao, Elisa Oricchio, Beat Fierz, Didier Trono, Henning Stahlberg, Michael Bronstein, and Bruno~E. Correia.
\newblock De novo design of protein interactions with learned surface fingerprints.
\newblock {\em Nature}, 617(7959):176--184, May 2023.

\bibitem{shroff2020discovery}
Raghav Shroff, Austin~W. Cole, Daniel~J. Diaz, Barrett~R. Morrow, Isaac Donnell, Ankur Annapareddy, Jimmy Gollihar, Andrew~D. Ellington, and Ross Thyer.
\newblock {Discovery of Novel Gain-of-Function Mutations Guided by Structure-Based Deep Learning}.
\newblock {\em ACS synthetic biology}, 9(11):2927--2935, 2020.

\bibitem{kulikova2021learning}
Anastasiya~V. Kulikova, Daniel~J. Diaz, James~M. Loy, Andrew~D. Ellington, and Claus~O. Wilke.
\newblock Learning the local landscape of protein structures with convolutional neural networks.
\newblock {\em Journal of Biological Physics}, 47(4):435--454, 2021.

\bibitem{fazekas2024locohd}
Zsolt Fazekas, D{\'o}ra K.~Menyh{\'a}rd, and Andr{\'a}s Perczel.
\newblock {LoCoHD: a metric for comparing local environments of proteins}.
\newblock {\em Nature Communications}, 15(1):4029, 2024.

\bibitem{ding_protein_2023}
David Ding, Ada~Y. Shaw, Sam Sinai, Nathan Rollins, Noam Prywes, David~F. Savage, Michael~T. Laub, and Debora~S. Marks.
\newblock Protein design using structure-based residue preferences.
\newblock {\em Nature Communications}, 15(1):1639, February 2024.

\bibitem{jumper_highly_2021}
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin {\v Z}{\'i}dek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A.~A. Kohl, Andrew~J. Ballard, Andrew Cowie, Bernardino {Romera-Paredes}, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew~W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis.
\newblock Highly accurate protein structure prediction with {{AlphaFold}}.
\newblock {\em Nature}, 596(7873):583--589, August 2021.

\bibitem{rasmussen_gaussian_2006}
Carl~Edward Rasmussen and Christopher K.~I. Williams.
\newblock {\em Gaussian Processes for Machine Learning}.
\newblock Adaptive Computation and Machine Learning. {MIT Press}, {Cambridge, Mass}, 2006.

\bibitem{michael2024continuous}
Richard Michael, Simon Bartels, Miguel González-Duque, Yevgen Zainchkovskyy, Jes Frellsen, Søren Hauberg, and Wouter Boomsma.
\newblock {A Continuous Relaxation for Discrete Bayesian Optimization}, 2024.

\bibitem{hie2020leveraging}
Brian Hie, Bryan~D. Bryson, and Bonnie Berger.
\newblock {Leveraging Uncertainty in Machine Learning Accelerates Biological Discovery and Design}.
\newblock {\em Cell systems}, 11(5):461--477, 2020.

\bibitem{7962ef51-7bc4-3567-8659-0594eb0b8b1f}
Morris~H. DeGroot and Stephen~E. Fienberg.
\newblock {The Comparison and Evaluation of Forecasters}.
\newblock {\em Journal of the Royal Statistical Society. Series D (The Statistician)}, 32(1/2):12--22, 1983.

\bibitem{stiffler_evolvability_2015}
Michael~A. Stiffler, Doeke~R. Hekstra, and Rama Ranganathan.
\newblock Evolvability as a {{Function}} of {{Purifying Selection}} in {{TEM-1}} {$\beta$}-{{Lactamase}}.
\newblock {\em Cell}, 160(5):882--892, February 2015.

\bibitem{wu_functional_2015}
Nicholas~C. Wu, C.~Anders Olson, Yushen Du, Shuai Le, Kevin Tran, Roland Remenyi, Danyang Gong, Laith~Q. {Al-Mawsawi}, Hangfei Qi, Ting-Ting Wu, and Ren Sun.
\newblock Functional {{Constraint Profiling}} of a {{Viral Protein Reveals Discordance}} of {{Evolutionary Conservation}} and {{Functionality}}.
\newblock {\em PLOS Genetics}, 11(7):e1005310, July 2015.

\bibitem{wan_characterizing_2019}
Aliete Wan, Emily Place, Eric~A. Pierce, and Jason Comander.
\newblock {Characterizing Variants of Unknown Significance in Rhodopsin: {{A}} Functional Genomics Approach}.
\newblock {\em Human Mutation}, 40(8):1127--1144, August 2019.

\bibitem{10.5555/2976248.2976406}
Edward Snelson and Zoubin Ghahramani.
\newblock {Sparse Gaussian Processes using Pseudo-inputs}.
\newblock {\em Advances in neural information processing systems}, 18, 2005.

\bibitem{wang_exact_2019}
Ke~Wang, Geoff Pleiss, Jacob Gardner, Stephen Tyree, Kilian~Q Weinberger, and Andrew~Gordon Wilson.
\newblock Exact {Gaussian} {Processes} on a {Million} {Data} {Points}.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{meanti_kernel_2020}
Giacomo Meanti, Luigi Carratino, Lorenzo Rosasco, and Alessandro Rudi.
\newblock {Kernel Methods Through the Roof: Handling Billions of Points Efficiently}.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~33, pages 14410--14422. Curran Associates, Inc., 2020.

\bibitem{hellinger_ref}
Imre Csiszár and Paul~C. Shields.
\newblock Information theory and statistics: A tutorial.
\newblock {\em Foundations and Trends® in Communications and Information Theory}, 1(4):417--528, 2004.

\bibitem{detlefsen_learning_2022}
Nicki~Skafte Detlefsen, S{\o}ren Hauberg, and Wouter Boomsma.
\newblock Learning meaningful representations of protein sequences.
\newblock {\em Nature Communications}, 13(1):1914, April 2022.

\bibitem{10.5555/645531.656014}
Thomas G\"{a}rtner, Peter~A. Flach, Adam Kowalczyk, and Alex~J. Smola.
\newblock Multi-instance kernels.
\newblock In {\em Proceedings of the Nineteenth International Conference on Machine Learning}, ICML '02, page 179–186, San Francisco, CA, USA, 2002. Morgan Kaufmann Publishers Inc.

\bibitem{duvenaud-thesis-2014}
David Duvenaud.
\newblock {\em Automatic Model Construction with {G}aussian Processes}.
\newblock PhD thesis, {Computational and Biological Learning Laboratory, University of Cambridge}, 2014.

\bibitem{gardner_gpytorch_2021}
Jacob Gardner, Geoff Pleiss, Kilian~Q. Weinberger, David Bindel, and Andrew~G. Wilson.
\newblock {{GPyTorch}}: {{Blackbox Matrix-Matrix Gaussian Process Inference}} with {{GPU Acceleration}}.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{polson_half-cauchy_2011}
Nicholas~G. Polson and James~G. Scott.
\newblock {On the Half-Cauchy Prior for a Global Scale Parameter}.
\newblock {\em Bayesian Analysis}, 7(4):887--902, 2012.

\bibitem{loshchilov_decoupled_2019}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled {{Weight Decay Regularization}}, 2019.

\end{thebibliography}
