@article{Efroni_Merlis_Mannor_2021, 
    title={Reinforcement Learning with Trajectory Feedback}, 
    volume={35}, 
    number={8}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Efroni, Yonathan and Merlis, Nadav and Mannor, Shie}, 
    year={2021}, month={May}, 
    pages={7288-7295} 
}


@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020},
  organization={PMLR}
}

@InProceedings{pmlr-v134-cohen21a,
  title = 	 {Online Markov Decision Processes with Aggregate Bandit Feedback},
  author =       {Cohen, Alon and Kaplan, Haim and Koren, Tomer and Mansour, Yishay},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory},
  pages = 	 {1301--1329},
  year = 	 {2021},
  editor = 	 {Belkin, Mikhail and Kpotufe, Samory},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--19 Aug},
  publisher =    {PMLR},
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{wu2023making,
  title={Making RL with Preference-based Feedback Efficient via Randomization},
  author={Wu, Runzhe and Sun, Wen},
  journal={arXiv preprint arXiv:2310.14554},
  year={2023}
}


@article{chatterji2021theory,
  title={On the theory of reinforcement learning with once-per-episode feedback},
  author={Chatterji, Niladri and Pacchiano, Aldo and Bartlett, Peter and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3401--3412},
  year={2021}
}

@article{xu2022provably,
  title={Provably efficient offline reinforcement learning with trajectory-wise reward},
  author={Xu, Tengyu and Wang, Yue and Zou, Shaofeng and Liang, Yingbin},
  journal={arXiv preprint arXiv:2206.06426},
  year={2022}
}

@inproceedings{agrawal2013thompson,
  title={Thompson sampling for contextual bandits with linear payoffs},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={International conference on machine learning},
  pages={127--135},
  year={2013},
  organization={PMLR}
}


@inproceedings{cassel2021online,
  title={Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators with $\sqrt{T}$ Regret},
  author={Cassel, Asaf B and Koren, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={1304--1313},
  year={2021},
  organization={PMLR}
}

@inproceedings{fazel2018global,
  title={Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  volume={80},
  year={2018}
}

@article{sherman2023rate,
  title={Rate-Optimal Policy Optimization for Linear Markov Decision Processes},
  author={Sherman, Uri and Cohen, Alon and Koren, Tomer and Mansour, Yishay},
  journal={arXiv preprint arXiv:2308.14642},
  year={2023}
}

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@inproceedings{hazan2014bandit,
	title={Bandit convex optimization: Towards tight bounds},
	author={Hazan, Elad and Levy, Kfir},
	booktitle={Advances in Neural Information Processing Systems},
	pages={784--792},
	year={2014}
}

@inproceedings{mania2019certainty,
 author = {Mania, Horia and Tu, Stephen and Recht, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {10154--10164},
 title = {Certainty Equivalence is Efficient for Linear Quadratic Control},
 volume = {32},
 year = {2019}
}


@inproceedings{bach2016highly,
	title={Highly-smooth zero-th order online optimization},
	author={Bach, Francis and Perchet, Vianney},
	booktitle={Conference on Learning Theory},
	pages={257--283},
	year={2016}
}



@inproceedings{shamir2013complexity,
	title={On the complexity of bandit and derivative-free stochastic convex optimization},
	author={Shamir, Ohad},
	booktitle={Conference on Learning Theory},
	pages={3--24},
	year={2013}
}

@article{dani2008stochastic,
	title={Stochastic linear optimization under bandit feedback},
	author={Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
	year={2008}
}

@inproceedings{abbasi2011regret,
	title={Regret bounds for the adaptive control of linear quadratic systems},
	author={Abbasi-Yadkori, Yasin and Szepesv{\'a}ri, Csaba},
	booktitle={Proceedings of the 24th Annual Conference on Learning Theory},
	pages={1--26},
	year={2011}
}

@inproceedings{flaxman2005online,
  title={Online convex optimization in the bandit setting: gradient descent without a gradient},
  author={Flaxman, Abraham D and Kalai, Adam Tauman and McMahan, H Brendan},
  booktitle={Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms},
  pages={385--394},
  year={2005}
}


@article{hanson1971bound,
	title={A bound on tail probabilities for quadratic forms in independent random variables},
	author={Hanson, David Lee and Wright, Farroll Tim},
	journal={The Annals of Mathematical Statistics},
	volume={42},
	number={3},
	pages={1079--1083},
	year={1971},
	publisher={JSTOR}
}

@article{wright1973bound,
	title={A bound on tail probabilities for quadratic forms in independent random variables whose distributions are not necessarily symmetric},
	author={Wright, Farrol Tim},
	journal={The Annals of Probability},
	pages={1068--1070},
	year={1973},
	publisher={JSTOR}
}

@article{hsu2012tail,
	title={A tail inequality for quadratic forms of subgaussian random vectors},
	author={Hsu, Daniel and Kakade, Sham and Zhang, Tong and others},
	journal={Electronic Communications in Probability},
	volume={17},
	year={2012},
	publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@inproceedings{agarwal2019online,
  title={Online control with adversarial disturbances},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad and Kakade, Sham and Singh, Karan},
  booktitle={International Conference on Machine Learning},
  pages={111--119},
  year={2019},
  organization={PMLR}
}

@inproceedings{agarwal2019logarithmic,
  title={Logarithmic regret for online control},
  author={Agarwal, Naman and Hazan, Elad and Singh, Karan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10175--10184},
  year={2019}
}

@inproceedings{foster2020logarithmic,
  title={Logarithmic regret for adversarial online control},
  author={Foster, Dylan and Simchowitz, Max},
  booktitle={International Conference on Machine Learning},
  pages={3211--3221},
  year={2020},
  organization={PMLR}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{jain2013learning,
  title={Learning trajectory preferences for manipulators via iterative improvement},
  author={Jain, Ashesh and Wojcik, Brian and Joachims, Thorsten and Saxena, Ashutosh},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@inproceedings{chen2022human,
  title={Human-in-the-loop: Provably efficient preference-based reinforcement learning with general function approximation},
  author={Chen, Xiaoyu and Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and Wang, Liwei},
  booktitle={International Conference on Machine Learning},
  pages={3773--3793},
  year={2022},
  organization={PMLR}
}

@inproceedings{saha2023dueling,
  title={Dueling RL: Reinforcement Learning with Trajectory Preferences},
  author={Saha, Aadirupa and Pacchiano, Aldo and Lee, Jonathan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6263--6289},
  year={2023},
  organization={PMLR}
}

@inproceedings{simchowitz2020improper,
  title={Improper learning for non-stochastic control},
  author={Simchowitz, Max and Singh, Karan and Hazan, Elad},
  booktitle={Conference on Learning Theory},
  pages={3320--3436},
  year={2020},
  organization={PMLR}
}

@inproceedings{anava2015online,
  title={Online learning for adversaries with memory: price of past mistakes},
  author={Anava, Oren and Hazan, Elad and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={784--792},
  year={2015}
}

@article{arora2012online,
  title={Online bandit learning against an adaptive adversary: from regret to policy regret},
  author={Arora, Raman and Dekel, Ofer and Tewari, Ambuj},
  journal={arXiv preprint arXiv:1206.6400},
  year={2012}
}

@inproceedings{cesa2018nonstochastic,
  title={Nonstochastic bandits with composite anonymous feedback},
  author={Cesa-Bianchi, Nicolo and Gentile, Claudio and Mansour, Yishay},
  booktitle={Conference On Learning Theory},
  pages={750--773},
  year={2018}
}

@inproceedings{cohen2019learning,
  title={Learning Linear-Quadratic Regulators Efficiently with only $\sqrt{T}$ Regret},
  author={Cohen, Alon and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={1300--1309},
  year={2019}
}

@inproceedings{cohen2018online,
  title={Online Linear Quadratic Control},
  author={Cohen, Alon and Hasidim, Avinatan and Koren, Tomer and Lazic, Nevena and Mansour, Yishay and Talwar, Kunal},
  booktitle={International Conference on Machine Learning},
  pages={1029--1038},
  year={2018}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}


@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}


@book{bertsekas1995dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P},
  volume={1},
  number={2},
  year={1995},
  publisher={Athena scientific Belmont, MA}
}


@article{chen2020black,
  title={Black-box control for linear dynamical systems},
  author={Chen, Xinyi and Hazan, Elad},
  journal={arXiv preprint arXiv:2007.06650},
  year={2020}
}


@inproceedings{cassel2020logarithmic,
  title={Logarithmic regret for learning linear quadratic regulators efficiently},
  author={Cassel, Asaf and Cohen, Alon and Koren, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={1328--1337},
  year={2020},
  organization={PMLR}
}


@inproceedings{simchowitz2020naive,
  title={Naive exploration is optimal for online lqr},
  author={Simchowitz, Max and Foster, Dylan},
  booktitle={International Conference on Machine Learning},
  pages={8937--8948},
  year={2020},
  organization={PMLR}
}


@inproceedings{abbasi2019model,
  title={Model-free linear quadratic control via reduction to expert prediction},
  author={Abbasi-Yadkori, Yasin and Lazic, Nevena and Szepesv{\'a}ri, Csaba},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={3108--3117},
  year={2019},
  organization={PMLR}
}


@inproceedings{tu2019gap,
  title={The gap between model-based and model-free methods on the linear quadratic regulator: An asymptotic viewpoint},
  author={Tu, Stephen and Recht, Benjamin},
  booktitle={Conference on Learning Theory},
  pages={3036--3083},
  year={2019},
  organization={PMLR}
}


@article{malik2019derivative,
  author  = {Dhruv Malik and Ashwin Pananjady and Kush Bhatia and Koulik Khamaru and Peter L. Bartlett and Martin J. Wainwright},
  title   = {Derivative-Free Methods for Policy Optimization: Guarantees for Linear Quadratic Systems},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {21},
  pages   = {1-51},
}



@inproceedings{yang2019global,
 author = {Yang, Zhuoran and Chen, Yongxin and Hong, Mingyi and Wang, Zhaoran},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Provably Global Convergence of Actor-Critic: A Case for Linear Quadratic Regulator with Ergodic Cost},
 volume = {32},
 year = {2019}
}

@inproceedings{krauth2019finite,
 author = {Krauth, Karl and Tu, Stephen and Recht, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Finite-time Analysis of Approximate Policy Iteration for the Linear Quadratic Regulator},
 volume = {32},
 year = {2019}
}


@inproceedings{mohammadi2020learning,
  title={Learning the model-free linear quadratic regulator via random search},
  author={Mohammadi, Hesameddin and Jovanovic, Mihailo R and Soltanolkotabi, Mahdi},
  booktitle={Learning for Dynamics and Control},
  pages={531--539},
  year={2020},
  organization={PMLR}
}


@article{jin2020analysis,
  title={On the analysis of model-free methods for the linear quadratic regulator},
  author={Jin, Zeyu and Schmitt, Johann Michael and Wen, Zaiwen},
  journal={arXiv preprint arXiv:2007.03861},
  year={2020}
}


@article{hambly2020policy,
  title={Policy Gradient Methods for the Noisy Linear Quadratic Regulator over a Finite Horizon},
  author={Hambly, Ben M and Xu, Renyuan and Yang, Huining},
  journal={Available at SSRN},
  year={2020}
}


@inproceedings{yaghmaie2019using,
  title={Using Reinforcement Learning for Model-free Linear Quadratic Control with Process and Measurement Noises},
  author={Yaghmaie, Farnaz Adib and Gustafsson, Fredrik},
  booktitle={2019 IEEE 58th Conference on Decision and Control (CDC)},
  pages={6510--6517},
  year={2019},
  organization={IEEE}
}

@book{nesterov2003introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2003},
  publisher={Springer Science \& Business Media}
}


@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}


@inproceedings{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation.},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay and others},
  booktitle={NIPs},
  volume={99},
  pages={1057--1063},
  year={1999},
  organization={Citeseer}
}


@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International conference on machine learning},
  pages={387--395},
  year={2014},
  organization={PMLR}
}


@article{cassel2020bandit,
  title={Bandit linear control},
  author={Cassel, Asaf and Koren, Tomer},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{NEURIPS2020_565e8a41,
 author = {Plevrakis, Orestis and Hazan, Elad},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {7637--7647},
 publisher = {Curran Associates, Inc.},
 title = {Geometric Exploration for Online Control},
 volume = {33},
 year = {2020}
}

@article{nesterov2017random,
  title={Random gradient-free minimization of convex functions},
  author={Nesterov, Yurii and Spokoiny, Vladimir},
  journal={Foundations of Computational Mathematics},
  volume={17},
  number={2},
  pages={527--566},
  year={2017},
  publisher={Springer}
}

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@article{mania2018simple,
  title={Simple random search provides a competitive approach to reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  journal={arXiv preprint arXiv:1803.07055},
  year={2018}
}

@article{gao2021provably,
  title={A provably efficient algorithm for linear markov decision process with low switching cost},
  author={Gao, Minbo and Xie, Tianle and Du, Simon S and Yang, Lin F},
  journal={arXiv preprint arXiv:2101.00494},
  year={2021}
}


@inproceedings{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2312--2320},
  year={2011}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{jin2020learning,
  title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4860--4869},
  year={2020},
  organization={PMLR}
}

@inproceedings{zimin2013online,
    title={Online learning in episodic Markovian decision processes by relative entropy policy search},
    author={Alexander Zimin and Gergely Neu},
    booktitle={Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
    pages={1583--1591},
    year={2013},
}

@inproceedings{rosenberg2019bandit,
    title={Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function},
    author={Rosenberg, Aviv and Mansour, Yishay},
    booktitle={Advances in Neural Information Processing Systems},
    pages={2209--2218},
    year={2019}
}

@inproceedings{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={5478--5486},
  year={2019},
  organization={PMLR}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes and others},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={136},
  pages={1--46},
  year={2017},
  publisher={Journal of Machine Learning Research/Massachusetts Institute of Technology~…}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  pages={1563--1600},
  year={2010}
}

@inproceedings{wang2023rlhf,
    title={Is {RLHF} More Difficult than Standard {RL}? A Theoretical Perspective},
    author={Yuanhao Wang and Qinghua Liu and Chi Jin},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
}

@article{zhan2023provable,
  title={Provable Offline Reinforcement Learning with Human Feedback},
  author={Zhan, Wenhao and Uehara, Masatoshi and Kallus, Nathan and Lee, Jason D and Sun, Wen},
  journal={arXiv preprint arXiv:2305.14816},
  year={2023}
}

@article{zhan2023query,
  title={How to Query Human Feedback Efficiently in RL?},
  author={Zhan, Wenhao and Uehara, Masatoshi and Sun, Wen and Lee, Jason D},
  journal={arXiv preprint arXiv:2305.18505},
  year={2023}
}

@inproceedings{howson2023optimism,
  title={Optimism and delays in episodic reinforcement learning},
  author={Howson, Benjamin and Pike-Burke, Ciara and Filippi, Sarah},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6061--6094},
  year={2023},
  organization={PMLR}
}

@inproceedings{lancewicki2020learning,
  title={Learning adversarial markov decision processes with delayed feedback},
  author={Lancewicki, Tal and Rosenberg, Aviv and Mansour, Yishay},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={7281--7289},
  year={2022}
}

@article{jin2022near,
  title={Near-optimal regret for adversarial mdp with delayed bandit feedback},
  author={Jin, Tiancheng and Lancewicki, Tal and Luo, Haipeng and Mansour, Yishay and Rosenberg, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={33469--33481},
  year={2022}
}

@inproceedings{tiapkin2023modelfree,
    title={Model-free Posterior Sampling via Learning Rate Randomization},
    author={Daniil Tiapkin and Denis Belomestny and Daniele Calandriello and Eric Moulines and Remi Munos and Alexey Naumov and pierre perrault and Michal Valko and Pierre MENARD},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
}

@inproceedings{lancewicki2023learning,
  author       = {Tal Lancewicki and
                  Aviv Rosenberg and
                  Dmitry Sotnikov},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Delay-Adapted Policy Optimization and Improved Regret for Adversarial
                  {MDP} with Delayed Bandit Feedback},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {18482--18534},
  publisher    = {{PMLR}},
  year         = {2023},
}

@article{faradonbeh2017finite,
  title={Finite time analysis of optimal adaptive policies for linear-quadratic systems},
  author={Faradonbeh, Mohamad Kazem Shirani and Tewari, Ambuj and Michailidis, George},
  journal={arXiv preprint arXiv:1711.07230},
  year={2017}
}

@article{ibrahimi2012efficient,
  title={Efficient reinforcement learning for high dimensional linear quadratic systems},
  author={Ibrahimi, Morteza and Javanmard, Adel and Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@article{lale2020logarithmic,
  title={Logarithmic regret bound in partially observable linear dynamical systems},
  author={Lale, Sahin and Azizzadenesheli, Kamyar and Hassibi, Babak and Anandkumar, Anima},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20876--20888},
  year={2020}
}

@inproceedings{goel2019online,
  title={An online algorithm for smoothed regression and lqr control},
  author={Goel, Gautam and Wierman, Adam},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2504--2513},
  year={2019},
  organization={PMLR}
}

@article{dean2018regret,
  title={Regret bounds for robust adaptive control of the linear quadratic regulator},
  author={Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{gradu2020non,
  title={Non-stochastic control with bandit feedback},
  author={Gradu, Paula and Hallman, John and Hazan, Elad},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10764--10774},
  year={2020}
}

@techreport{van2014probability,
  title={Probability in high dimension},
  author={Van Handel, Ramon},
  year={2014},
  institution={PRINCETON UNIV NJ}
}

@inproceedings{chen2021black,
  title={Black-box control for linear dynamical systems},
  author={Chen, Xinyi and Hazan, Elad},
  booktitle={Conference on Learning Theory},
  pages={1114--1143},
  year={2021},
  organization={PMLR}
}

@article{agarwal2011stochastic,
  title={Stochastic convex optimization with bandit feedback},
  author={Agarwal, Alekh and Foster, Dean P and Hsu, Daniel J and Kakade, Sham M and Rakhlin, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2},
  pages={235--256},
  year={2002},
  publisher={Springer}
}


@article{simchowitz2020making,
  title={Making non-stochastic control (almost) as easy as stochastic},
  author={Simchowitz, Max},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18318--18329},
  year={2020}
}

@inproceedings{chernov2010prediction,
  title={Prediction with expert advice under discounted loss},
  author={Chernov, Alexey and Zhdanov, Fedor},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={255--269},
  year={2010},
  organization={Springer}
}

@inproceedings{neu2010online,
  title={The Online Loop-free Stochastic Shortest-Path Problem.},
  author={Neu, Gergely and Gy{\"o}rgy, Andr{\'a}s and Szepesv{\'a}ri, Csaba and others},
  booktitle={COLT},
  volume={2010},
  pages={231--243},
  year={2010},
  organization={Citeseer}
}

@article{cassel2022efficient,
  title={Efficient Online Linear Control with Stochastic Convex Costs and Unknown Dynamics},
  author={Cassel, Asaf and Cohen, Alon and Koren, Tomer},
  journal={arXiv preprint arXiv:2203.01170},
  year={2022}
}

@inproceedings{altschuler2018online,
  title={Online learning over a finite action set with limited switching},
  author={Altschuler, Jason and Talwar, Kunal},
  booktitle={Conference On Learning Theory},
  pages={1569--1573},
  year={2018},
  organization={PMLR}
}

@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={Proceedings of the 20th international conference on machine learning (icml-03)},
  pages={928--936},
  year={2003}
}

@article{arora2012multiplicative,
  title={The multiplicative weights update method: a meta-algorithm and applications},
  author={Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
  journal={Theory of computing},
  volume={8},
  number={1},
  pages={121--164},
  year={2012},
  publisher={Theory of Computing Exchange}
}

@article{arora2018towards,
  title={Towards provable control for unknown linear dynamical systems},
  author={Arora, Sanjeev and Hazan, Elad and Lee, Holden and Singh, Karan and Zhang, Cyril and Zhang, Yi},
  year={2018}
}

@inproceedings{abeille2018improved,
  title={Improved regret bounds for thompson sampling in linear quadratic control problems},
  author={Abeille, Marc and Lazaric, Alessandro},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2018},
  organization={PMLR}
}

@inproceedings{ouyang2017control,
  title={Control of unknown linear systems with thompson sampling},
  author={Ouyang, Yi and Gagrani, Mukul and Jain, Rahul},
  booktitle={2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={1198--1205},
  year={2017},
  organization={IEEE}
}


@inproceedings{rosenberg2020near,
  title={Near-optimal regret bounds for stochastic shortest path},
  author={Rosenberg, Aviv and Cohen, Alon and Mansour, Yishay and Kaplan, Haim},
  booktitle={International Conference on Machine Learning},
  pages={8210--8219},
  year={2020},
  organization={PMLR}
}



@article{kalai2005efficient,
  title={Efficient algorithms for online decision problems},
  author={Kalai, Adam and Vempala, Santosh},
  journal={Journal of Computer and System Sciences},
  volume={71},
  number={3},
  pages={291--307},
  year={2005},
  publisher={Elsevier}
}


@article{cassel2022rate,
  title={Rate-Optimal Online Convex Optimization in Adaptive Linear Control},
  author={Cassel, Asaf and Cohen, Alon and Koren, Tomer},
  journal={arXiv preprint arXiv:2206.01426},
  year={2022}
}















@inproceedings{wagenmaker2022reward,
  title={Reward-free rl is no harder than reward-aware rl in linear markov decision processes},
  author={Wagenmaker, Andrew J and Chen, Yifang and Simchowitz, Max and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={22430--22456},
  year={2022},
  organization={PMLR}
}

@inproceedings{wagenmaker2022first,
  title={First-order regret in reinforcement learning with linear function approximation: A robust estimation approach},
  author={Wagenmaker, Andrew J and Chen, Yifang and Simchowitz, Max and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={22384--22429},
  year={2022},
  organization={PMLR}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}