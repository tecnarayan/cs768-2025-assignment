\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel \& Ng(2004)Abbeel and Ng]{abbeel2004apprenticeship}
Abbeel, P. and Ng, A.~Y.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, pp.\ ~1, 2004.

\bibitem[Allen et~al.(2020)Allen, Smith, and Tenenbaum]{allen2020rapid}
Allen, K.~R., Smith, K.~A., and Tenenbaum, J.~B.
\newblock Rapid trial-and-error learning with simulation supports flexible tool
  use and physical reasoning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (47):\penalty0 29302--29310, 2020.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., and
  Man{\'e}, D.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Argall et~al.(2009)Argall, Chernova, Veloso, and
  Browning]{argall2009survey}
Argall, B.~D., Chernova, S., Veloso, M., and Browning, B.
\newblock A survey of robot learning from demonstration.
\newblock \emph{Robotics and autonomous systems}, 57\penalty0 (5):\penalty0
  469--483, 2009.

\bibitem[Arumugam et~al.(2019)Arumugam, Lee, Saskin, and
  Littman]{arumugam2019deep}
Arumugam, D., Lee, J.~K., Saskin, S., and Littman, M.~L.
\newblock Deep reinforcement learning from policy-dependent human feedback.
\newblock \emph{arXiv preprint arXiv:1902.04257}, 2019.

\bibitem[Baker et~al.(2017)Baker, Jara-Ettinger, Saxe, and
  Tenenbaum]{baker2017rational}
Baker, C.~L., Jara-Ettinger, J., Saxe, R., and Tenenbaum, J.~B.
\newblock Rational quantitative attribution of beliefs, desires and percepts in
  human mentalizing.
\newblock \emph{Nature Human Behaviour}, 1\penalty0 (4):\penalty0 1--10, 2017.

\bibitem[Bakhtin et~al.(2019)Bakhtin, van~der Maaten, Johnson, Gustafson, and
  Girshick]{bakhtin2019phyre}
Bakhtin, A., van~der Maaten, L., Johnson, J., Gustafson, L., and Girshick, R.
\newblock Phyre: A new benchmark for physical reasoning.
\newblock \emph{arXiv preprint arXiv:1908.05656}, 2019.

\bibitem[Billard et~al.(2004)Billard, Epars, Calinon, Schaal, and
  Cheng]{billard2004discovering}
Billard, A., Epars, Y., Calinon, S., Schaal, S., and Cheng, G.
\newblock Discovering optimal imitation strategies.
\newblock \emph{Robotics and autonomous systems}, 47\penalty0 (2-3):\penalty0
  69--77, 2004.

\bibitem[B{\i}y{\i}k et~al.(2019)B{\i}y{\i}k, Palan, Landolfi, Losey, and
  Sadigh]{biyik2019asking}
B{\i}y{\i}k, E., Palan, M., Landolfi, N.~C., Losey, D.~P., and Sadigh, D.
\newblock Asking easy questions: A user-friendly approach to active reward
  learning.
\newblock \emph{arXiv preprint arXiv:1910.04365}, 2019.

\bibitem[Bonardi et~al.(2020)Bonardi, James, and Davison]{bonardi2020learning}
Bonardi, A., James, S., and Davison, A.~J.
\newblock Learning one-shot imitation from humans without humans.
\newblock \emph{IEEE Robotics and Automation Letters}, 5\penalty0 (2):\penalty0
  3533--3539, 2020.

\bibitem[Brown et~al.(2019)Brown, Goo, Nagarajan, and
  Niekum]{brown2019extrapolating}
Brown, D., Goo, W., Nagarajan, P., and Niekum, S.
\newblock Extrapolating beyond suboptimal demonstrations via inverse
  reinforcement learning from observations.
\newblock In \emph{International conference on machine learning}, pp.\
  783--792. PMLR, 2019.

\bibitem[Cao et~al.(2020)Cao, Gao, Mangalam, Cai, Vo, and Malik]{cao2020long}
Cao, Z., Gao, H., Mangalam, K., Cai, Q.-Z., Vo, M., and Malik, J.
\newblock Long-term human motion prediction with scene context.
\newblock In \emph{European Conference on Computer Vision}, pp.\  387--404.
  Springer, 2020.

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei]{christiano2017deep}
Christiano, P.~F., Leike, J., Brown, T., Martic, M., Legg, S., and Amodei, D.
\newblock Deep reinforcement learning from human preferences.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30. Curran Associates, Inc., 2017.

\bibitem[Cui \& Niekum(2018)Cui and Niekum]{cui2018active}
Cui, Y. and Niekum, S.
\newblock Active reward learning from critiques.
\newblock In \emph{2018 IEEE international conference on robotics and
  automation (ICRA)}, pp.\  6907--6914. IEEE, 2018.

\bibitem[Daniel et~al.(2014)Daniel, Viering, Metz, Kroemer, and
  Peters]{daniel2014active}
Daniel, C., Viering, M., Metz, J., Kroemer, O., and Peters, J.
\newblock Active reward learning.
\newblock In \emph{Robotics: Science and systems}, volume~98, 2014.

\bibitem[Daniel et~al.(2015)Daniel, Kroemer, Viering, Metz, and
  Peters]{daniel2015active}
Daniel, C., Kroemer, O., Viering, M., Metz, J., and Peters, J.
\newblock Active reward learning with a novel acquisition function.
\newblock \emph{Autonomous Robots}, 39\penalty0 (3):\penalty0 389--405, 2015.

\bibitem[Duan et~al.(2017)Duan, Andrychowicz, Stadie, Jonathan~Ho, Schneider,
  Sutskever, Abbeel, and Zaremba]{duan2017one}
Duan, Y., Andrychowicz, M., Stadie, B., Jonathan~Ho, O., Schneider, J.,
  Sutskever, I., Abbeel, P., and Zaremba, W.
\newblock One-shot imitation learning.
\newblock In \emph{Advances in neural information processing systems}, 2017.

\bibitem[Finn et~al.(2017)Finn, Yu, Zhang, Abbeel, and Levine]{finn2017one}
Finn, C., Yu, T., Zhang, T., Abbeel, P., and Levine, S.
\newblock One-shot visual imitation learning via meta-learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  357--368. PMLR, 2017.

\bibitem[Fu et~al.(2018)Fu, Luo, and Levine]{fu2017learning}
Fu, J., Luo, K., and Levine, S.
\newblock Learning robust rewards with adversarial inverse reinforcement
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Ghasemipour et~al.(2020)Ghasemipour, Zemel, and
  Gu]{ghasemipour2020divergence}
Ghasemipour, S. K.~S., Zemel, R., and Gu, S.
\newblock A divergence minimization perspective on imitation learning methods.
\newblock In \emph{Conference on Robot Learning}, pp.\  1259--1277. PMLR, 2020.

\bibitem[Griffith et~al.(2013)Griffith, Subramanian, Scholz, Isbell, and
  Thomaz]{griffith2013policy}
Griffith, S., Subramanian, K., Scholz, J., Isbell, C.~L., and Thomaz, A.~L.
\newblock Policy shaping: Integrating human feedback with reinforcement
  learning.
\newblock In \emph{Advances in neural information processing systems}, 2013.

\bibitem[Hu et~al.(2020)Hu, Lerer, Peysakhovich, and Foerster]{hu2020other}
Hu, H., Lerer, A., Peysakhovich, A., and Foerster, J.
\newblock “other-play” for zero-shot coordination.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4399--4410. PMLR, 2020.

\bibitem[Huang et~al.(2019)Huang, Xu, Zhu, Garg, Savarese, Fei-Fei, and
  Niebles]{huang2019continuous}
Huang, D.-A., Xu, D., Zhu, Y., Garg, A., Savarese, S., Fei-Fei, L., and
  Niebles, J.~C.
\newblock Continuous relaxation of symbolic planner for one-shot imitation
  learning.
\newblock In \emph{2019 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pp.\  2635--2642. IEEE, 2019.

\bibitem[Johnson et~al.(2017)Johnson, Hariharan, Van Der~Maaten, Fei-Fei,
  Lawrence~Zitnick, and Girshick]{johnson2017clevr}
Johnson, J., Hariharan, B., Van Der~Maaten, L., Fei-Fei, L., Lawrence~Zitnick,
  C., and Girshick, R.
\newblock Clevr: A diagnostic dataset for compositional language and elementary
  visual reasoning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2901--2910, 2017.

\bibitem[Kapelyukh \& Johns(2022)Kapelyukh and Johns]{kapelyukh2022my}
Kapelyukh, I. and Johns, E.
\newblock My house, my rules: Learning tidying preferences with graph neural
  networks.
\newblock In \emph{Conference on Robot Learning}, pp.\  740--749. PMLR, 2022.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Loftin et~al.(2014)Loftin, MacGlashan, Peng, Taylor, Littman, Huang,
  and Roberts]{loftin2014strategy}
Loftin, R., MacGlashan, J., Peng, B., Taylor, M., Littman, M., Huang, J., and
  Roberts, D.
\newblock A strategy-aware technique for learning behaviors from discrete human
  feedback.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~28, 2014.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, P., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock \emph{arXiv preprint arXiv:1706.02275}, 2017.

\bibitem[MacGlashan et~al.(2017)MacGlashan, Ho, Loftin, Peng, Wang, Roberts,
  Taylor, and Littman]{macglashan2017interactive}
MacGlashan, J., Ho, M.~K., Loftin, R., Peng, B., Wang, G., Roberts, D.~L.,
  Taylor, M.~E., and Littman, M.~L.
\newblock Interactive learning from policy-dependent human feedback.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2285--2294. PMLR, 2017.

\bibitem[Nehaniv et~al.(2002)Nehaniv, Dautenhahn,
  et~al.]{nehaniv2002correspondence}
Nehaniv, C.~L., Dautenhahn, K., et~al.
\newblock The correspondence problem.
\newblock \emph{Imitation in animals and artifacts}, 41, 2002.

\bibitem[Netanyahu et~al.(2021)Netanyahu, Shu, Katz, Barbu, and
  Tenenbaum]{NetanyahuPHASE2021}
Netanyahu, A., Shu, T., Katz, B., Barbu, A., and Tenenbaum, J.~B.
\newblock Phase: Physically-grounded abstract social events for machine social
  perception.
\newblock In \emph{35th AAAI Conference on Artificial Intelligence (AAAI)},
  2021.

\bibitem[Ng et~al.(2000)Ng, Russell, et~al.]{ng2000algorithms}
Ng, A.~Y., Russell, S.~J., et~al.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{Icml}, volume~1, pp.\ ~2, 2000.

\bibitem[Puig et~al.(2018)Puig, Ra, Boben, Li, Wang, Fidler, and
  Torralba]{puig2018virtualhome}
Puig, X., Ra, K., Boben, M., Li, J., Wang, T., Fidler, S., and Torralba, A.
\newblock Virtualhome: Simulating household activities via programs.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  8494--8502, 2018.

\bibitem[Puig et~al.(2021)Puig, Shu, Li, Wang, Liao, Tenenbaum, Fidler, and
  Torralba]{puig2021watchandhelp}
Puig, X., Shu, T., Li, S., Wang, Z., Liao, Y.-H., Tenenbaum, J.~B., Fidler, S.,
  and Torralba, A.
\newblock Watch-and-help: A challenge for social perception and
  human-{\{}ai{\}} collaboration.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Reddy et~al.(2020)Reddy, Dragan, Levine, Legg, and
  Leike]{reddy2020learning}
Reddy, S., Dragan, A., Levine, S., Legg, S., and Leike, J.
\newblock Learning human objectives by evaluating hypothetical behavior.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8020--8029. PMLR, 2020.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
Ross, S., Gordon, G., and Bagnell, D.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pp.\  627--635. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Rowe et~al.(2019)Rowe, Singhal, Yi, Bhattacharjee, and
  Srinivasa]{rowe2019desk}
Rowe, R., Singhal, S., Yi, D., Bhattacharjee, T., and Srinivasa, S.~S.
\newblock Desk organization: Effect of multimodal inputs on spatial relational
  learning.
\newblock In \emph{2019 28th IEEE International Conference on Robot and Human
  Interactive Communication (RO-MAN)}, pp.\  1--8. IEEE, 2019.

\bibitem[Schaal(1999)]{schaal1999imitation}
Schaal, S.
\newblock Is imitation learning the route to humanoid robots?
\newblock \emph{Trends in cognitive sciences}, 3\penalty0 (6):\penalty0
  233--242, 1999.

\bibitem[Shah et~al.(2018)Shah, Kamath, Shah, and Li]{shah2018bayesian}
Shah, A., Kamath, P., Shah, J.~A., and Li, S.
\newblock Bayesian inference of temporal task specifications from
  demonstrations.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  3804--3813. Curran Associates,
  Inc., 2018.

\bibitem[Shimodaira(2000)]{shimodaira2000improving}
Shimodaira, H.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock \emph{Journal of statistical planning and inference}, 90\penalty0
  (2):\penalty0 227--244, 2000.

\bibitem[Srivastava et~al.(2022)Srivastava, Li, Lingelbach,
  Mart{\'\i}n-Mart{\'\i}n, Xia, Vainio, Lian, Gokmen, Buch, Liu,
  et~al.]{srivastava2022behavior}
Srivastava, S., Li, C., Lingelbach, M., Mart{\'\i}n-Mart{\'\i}n, R., Xia, F.,
  Vainio, K.~E., Lian, Z., Gokmen, C., Buch, S., Liu, K., et~al.
\newblock Behavior: Benchmark for everyday household activities in virtual,
  interactive, and ecological environments.
\newblock In \emph{Conference on Robot Learning}, pp.\  477--490. PMLR, 2022.

\bibitem[Su et~al.(2016)Su, Gasic, Mrksic, Rojas-Barahona, Ultes, Vandyke, Wen,
  and Young]{su2016line}
Su, P.-H., Gasic, M., Mrksic, N., Rojas-Barahona, L., Ultes, S., Vandyke, D.,
  Wen, T.-H., and Young, S.
\newblock On-line active reward learning for policy optimisation in spoken
  dialogue systems.
\newblock \emph{arXiv preprint arXiv:1605.07669}, 2016.

\bibitem[Sun et~al.(2021)Sun, Yu, Dong, Lu, and Zhou]{sun2021adversarial}
Sun, J., Yu, L., Dong, P., Lu, B., and Zhou, B.
\newblock Adversarial inverse reinforcement learning with self-attention
  dynamics model.
\newblock \emph{IEEE Robotics and Automation Letters}, 6\penalty0 (2):\penalty0
  1880--1886, 2021.

\bibitem[Tobin et~al.(2017)Tobin, Fong, Ray, Schneider, Zaremba, and
  Abbeel]{tobin2017domain}
Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., and Abbeel, P.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world.
\newblock In \emph{2017 IEEE/RSJ international conference on intelligent robots
  and systems (IROS)}, pp.\  23--30. IEEE, 2017.

\bibitem[Wang et~al.(2020)Wang, Toyer, Gleave, and Emmons]{wang2020imitation}
Wang, S., Toyer, S., Gleave, A., and Emmons, S.
\newblock The {\tt imitation} library for imitation learning and inverse
  reinforcement learning.
\newblock \url{https://github.com/HumanCompatibleAI/imitation}, 2020.

\bibitem[Wang et~al.(2022)Wang, Lee, Hakhamaneshi, Abbeel, and
  Laskin]{wang2022skill}
Wang, X., Lee, K., Hakhamaneshi, K., Abbeel, P., and Laskin, M.
\newblock Skill preferences: Learning to extract and execute robotic skills
  from human feedback.
\newblock In \emph{Conference on Robot Learning}, pp.\  1259--1268. PMLR, 2022.

\bibitem[Xu et~al.(2019)Xu, Ratner, Dragan, Levine, and Finn]{xu2019learning}
Xu, K., Ratner, E., Dragan, A., Levine, S., and Finn, C.
\newblock Learning a prior over intent via meta-inverse reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6952--6962. PMLR, 2019.

\bibitem[Yan et~al.(2020)Yan, Wang, and He]{yan2020robotic}
Yan, F., Wang, D., and He, H.
\newblock Robotic understanding of spatial relationships using neural-logic
  learning.
\newblock In \emph{2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pp.\  8358--8365. IEEE, 2020.

\bibitem[Yu et~al.(2018)Yu, Finn, Xie, Dasari, Zhang, Abbeel, and
  Levine]{yu2018one}
Yu, T., Finn, C., Xie, A., Dasari, S., Zhang, T., Abbeel, P., and Levine, S.
\newblock One-shot imitation from observing humans via domain-adaptive
  meta-learning.
\newblock \emph{arXiv preprint arXiv:1802.01557}, 2018.

\end{thebibliography}
