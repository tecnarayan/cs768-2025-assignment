@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI  = {AAAI})
@String(CVPRW = {CVPRW})
@String(CSVT  = {IEEE TCSVT})
@String(arXiv = {arXiv})
@String(BMVC  = {BMVC})
@String(EMNLP = {EMNLP})
@String(ICML = {ICML})


@inproceedings{johnson2015image,
  title={Image retrieval using scene graphs},
  author={Johnson, Justin and Krishna, Ranjay and Stark, Michael and Li, Li-Jia and Shamma, David and Bernstein, Michael and Fei-Fei, Li},
  booktitle=CVPR,
  year={2015}
}

@inproceedings{gu2019unpaired,
  title={Unpaired image captioning via scene graph alignments},
  author={Gu, Jiuxiang and Joty, Shafiq and Cai, Jianfei and Zhao, Handong and Yang, Xu and Wang, Gang},
  booktitle=ICCV,
  pages={10323--10332},
  year={2019}
}

@inproceedings{teney2017graph,
  title={Graph-structured representations for visual question answering},
  author={Teney, Damien and Liu, Lingqiao and van Den Hengel, Anton},
  booktitle=CVPR,
  pages={1--9},
  year={2017}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal=IJCV,
  year={2017}
}

@inproceedings{hetao2022,
author = {He, Tao and Gao, Lianli and Song, Jingkuan and Li, Yuan-Fang},
title = {Towards Open-Vocabulary Scene Graph Generation With Prompt-Based Finetuning},
year = {2022},
booktitle = {ECCV},
}


@inproceedings{tang2020unbiased,
  title={Unbiased scene graph generation from biased training},
  author={Tang, Kaihua and Niu, Yulei and Huang, Jianqiang and Shi, Jiaxin and Zhang, Hanwang},
  booktitle=CVPR,
  pages={3716--3725},
  year={2020}
}


@inproceedings{li2022devil,
  title={The Devil is in the Labels: Noisy Label Correction for Robust Scene Graph Generation},
  author={Li, Lin and Chen, Long and Huang, Yifeng and Zhang, Zhimeng and Zhang, Songyang and Xiao, Jun},
  booktitle=CVPR,
  pages={18869--18878},
  year={2022}
}

@inproceedings{li2022rethinking,
  title={Rethinking the Evaluation of Unbiased Scene Graph Generation},
  author={Li, Xingchen and Chen, Long and Shao, Jian and Xiao, Shaoning and Zhang, Songyang and Xiao, Jun},
  booktitle=BMVC,
  year={2022}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
}

@inproceedings{yoon2022unbiased,
  title={Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network},
  author={Yoon, Kanghoon and Kim, Kibum and Moon, Jinyoung and Park, Chanyoung},
  booktitle={AAAI},
  year={2022}
}

@inproceedings{menon2022visual,
  title={Visual Classification via Description from Large Language Models},
  author={Menon, Sachit and Vondrick, Carl},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NIPS},
  year={2020}
}

@inproceedings{kojima2022large,
  title={Large Language Models are Zero-Shot Reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  booktitle={NIPS},
  year={2022}
}



@inproceedings{xu2017scene,
  title={Scene graph generation by iterative message passing},
  author={Xu, Danfei and Zhu, Yuke and Choy, Christopher B and Fei-Fei, Li},
  booktitle=CVPR,
  pages={5410--5419},
  year={2017}
}


@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle=CVPR,
  pages={6700--6709},
  year={2019}
}

@inproceedings{dong2022stacked,
  title={Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation},
  author={Dong, Xingning and Gan, Tian and Song, Xuemeng and Wu, Jianlong and Cheng, Yuan and Nie, Liqiang},
  booktitle=CVPR,
  pages={19427--19436},
  year={2022}
}

@inproceedings{chao2015hico,
  title={Hico: A benchmark for recognizing human-object interactions in images},
  author={Chao, Yu-Wei and Wang, Zhan and He, Yugeng and Wang, Jiaxuan and Deng, Jia},
  booktitle={ICCV},
  pages={1017--1025},
  year={2015}
}

@article{gupta2015visual,
  title={Visual semantic role labeling},
  author={Gupta, Saurabh and Malik, Jitendra},
  journal={arXiv preprint arXiv:1505.04474},
  year={2015}
}

@inproceedings{chao2018learning,
  title={Learning to detect human-object interactions},
  author={Chao, Yu-Wei and Liu, Yunfan and Liu, Xieyang and Zeng, Huayi and Deng, Jia},
  booktitle={WACV},
  pages={381--389},
  year={2018},
}

@inproceedings{kim2020detecting,
  title={Detecting human-object interactions with action co-occurrence priors},
  author={Kim, Dong-Jin and Sun, Xiao and Choi, Jinsoo and Lin, Stephen and Kweon, In So},
  booktitle={ECCV},
  pages={718--736},
  year={2020},
}


@inproceedings{liao2022gen,
  title={Gen-vlkt: Simplify association and enhance interaction understanding for hoi detection},
  author={Liao, Yue and Zhang, Aixi and Lu, Miao and Wang, Yongliang and Li, Xiaobo and Liu, Si},
  booktitle={CVPR},
  pages={20123--20132},
  year={2022}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{novack2023chils,
  title={Chils: Zero-shot image classification with hierarchical label sets},
  author={Novack, Zachary and Garg, Saurabh and McAuley, Julian and Lipton, Zachary C},
  journal={arXiv preprint arXiv:2302.02551},
  year={2023}
}

@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
  booktitle={CVPR},
  pages={7959--7971},
  year={2022}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  pages={4904--4916},
  year={2021},
}

@inproceedings{Cho2022CLIPReward,
  title     = {Fine-grained Image Captioning with CLIP Reward},
  author    = {Jaemin Cho and Seunghyun Yoon and Ajinkya Kale and Franck Dernoncourt and Trung Bui and Mohit Bansal},
  booktitle = {Findings of NAACL},
  year      = {2022}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={EMNLP},
  pages={1532--1543},
  year={2014}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{gao2023compositional,
  title={Compositional prompt tuning with motion cues for open-vocabulary video relation detection},
  author={Gao, Kaifeng and Chen, Long and Zhang, Hanwang and Xiao, Jun and Sun, Qianru},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{wang2018zero,
  title={Zero-shot recognition via semantic embeddings and knowledge graphs},
  author={Wang, Xiaolong and Ye, Yufei and Gupta, Abhinav},
  booktitle={CVPR},
  pages={6857--6866},
  year={2018}
}

@inproceedings{gao2022open,
  title={Open vocabulary object detection with pseudo bounding-box labels},
  author={Gao, Mingfei and Xing, Chen and Niebles, Juan Carlos and Li, Junnan and Xu, Ran and Liu, Wenhao and Xiong, Caiming},
  booktitle={ECCV},
  pages={266--282},
  year={2022},
}

@inproceedings{gu2022open,
  title={Open-vocabulary object detection via vision and language knowledge distillation},
  author={Gu, Xiuye and Lin, Tsung-Yi and Kuo, Weicheng and Cui, Yin},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{zareian2021open,
  title={Open-vocabulary object detection using captions},
  author={Zareian, Alireza and Rosa, Kevin Dela and Hu, Derek Hao and Chang, Shih-Fu},
  booktitle={CVPR},
  pages={14393--14402},
  year={2021}
}

@inproceedings{wang2023learning,
  title={Learning to Detect and Segment for Open Vocabulary Object Detection},
  author={Wang, Tao and Li, Nan},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{chuang2020debiased,
  title={Debiased contrastive learning},
  author={Chuang, Ching-Yao and Robinson, Joshua and Lin, Yen-Chen and Torralba, Antonio and Jegelka, Stefanie},
  booktitle={NIPS},
  year={2020}
}

@inproceedings{kato2018compositional,
  title={Compositional learning for human object interaction},
  author={Kato, Keizo and Li, Yin and Gupta, Abhinav},
  booktitle={ECCV},
  pages={234--251},
  year={2018}
}

@article{yan2022semantics,
  title={Semantics-guided contrastive network for zero-shot object detection},
  author={Yan, Caixia and Chang, Xiaojun and Luo, Minnan and Liu, Huan and Zhang, Xiaoqin and Zheng, Qinghua},
  journal={TPAMI},
  year={2022},
}

@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}

@inproceedings{gupta2023visual,
  title={Visual programming: Compositional visual reasoning without training},
  booktitle={CVPR},
  year={2023}
}

@article{zhou2023navgpt,
  title={NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models},
  journal={arXiv preprint arXiv:2305.16986},
  year={2023}
}

@article{rajivc2023segment,
  title={Segment Anything Meets Point Tracking},
  journal={arXiv preprint arXiv:2307.01197},
  year={2023}
}



@inproceedings{zhang2022exploring,
  title={Exploring structure-aware transformer over interaction proposals for human-object interaction detection},
  booktitle={CVPR},
  year={2022}
}

@article{yao2022pevl,
  title={PEVL: Position-enhanced pre-training and prompt tuning for vision-language models},
  journal={arXiv preprint arXiv:2205.11169},
  year={2022}
}

@article{liu2023lost,
  title={Lost in the middle: How language models use long contexts},
  journal={arXiv preprint arXiv:2307.03172},
  year={2023}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={ICML},
  year={2022},
  organization={PMLR}
}

@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{li2023decomposed,
  title={Decomposed Prototype Learning for Few-Shot Scene Graph Generation},
  journal={arXiv preprint arXiv:2303.10863},
  year={2023}
}

@inproceedings{zellers2018neural,
  title={Neural motifs: Scene graph parsing with global context},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{yu2023visually,
  title={Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{kan2021zero,
  title={Zero-shot scene graph relation prediction through commonsense knowledge integration},
  booktitle={ECML PKDD},
  year={2021},
}

@inproceedings{you2022learning,
  title={Learning visual representation from modality-shared contrastive language-image pre-training},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{li2022supervision,
  title={Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm},
  booktitle={ICLR},
  year={2022}
}

@article{cui2022democratizing,
  title={Democratizing contrastive language-image pre-training: A clip benchmark of data, model, and supervision},
  journal={arXiv preprint arXiv:2203.05796},
  year={2022}
}

@inproceedings{li2023compositional,
  title={Compositional Feature Augmentation for Unbiased Scene Graph Generation},
  author={Li, Lin and Chen, Guikun and Xiao, Jun and Yang, Yi and Wang, Chunping and Chen, Long},
  booktitle={ICCV},
  pages={21685--21695},
  year={2023}
}

@inproceedings{chen2023addressing,
  title={Addressing Predicate Overlap in Scene Graph Generation with Semantic Granularity Controller},
  author={Chen, Guikun and Li, Lin and Luo, Yawei and Xiao, Jun},
  booktitle={ICME},
  pages={78--83},
  year={2023},
  organization={IEEE}
}

@inproceedings{bui2022sg,
  title={SG-Shuffle: Multi-aspect Shuffle Transformer for Scene Graph Generation},
  author={Bui, Anh Duc and Han, Soyeon Caren and Poon, Josiah},
  booktitle={Australasian Joint Conference on Artificial Intelligence},
  pages={87--101},
  year={2022},
  organization={Springer}
}

@inproceedings{teng2022structured,
  title={Structured sparse r-cnn for direct scene graph generation},
  author={Teng, Yao and Wang, Limin},
  booktitle={CVPR},
  pages={19437--19446},
  year={2022}
}