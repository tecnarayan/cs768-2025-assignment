\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Flash and Hogan(1985)]{flash1985coordination}
Tamar Flash and Neville Hogan.
\newblock The coordination of arm movements: an experimentally confirmed
  mathematical model.
\newblock \emph{Journal of neuroscience}, 5\penalty0 (7):\penalty0 1688--1703,
  1985.

\bibitem[Harris and Wolpert(1998)]{harris1998signal}
Christopher~M Harris and Daniel~M Wolpert.
\newblock Signal-dependent noise determines motor planning.
\newblock \emph{Nature}, 394\penalty0 (6695):\penalty0 780--784, 1998.

\bibitem[Schmidt et~al.(1979)Schmidt, Zelaznik, Hawkins, Frank, and
  Quinn~Jr]{schmidt1979motor}
Richard~A Schmidt, Howard Zelaznik, Brian Hawkins, James~S Frank, and John~T
  Quinn~Jr.
\newblock Motor-output variability: a theory for the accuracy of rapid motor
  acts.
\newblock \emph{Psychological review}, 86\penalty0 (5):\penalty0 415, 1979.

\bibitem[Stengel(1994)]{stengel1994optimal}
Robert~F Stengel.
\newblock \emph{Optimal control and estimation}.
\newblock Courier Corporation, 1994.

\bibitem[Fechner(1860)]{fechner1860elemente}
Gustav~Theodor Fechner.
\newblock \emph{Elemente der psychophysik}, volume~2.
\newblock Breitkopf u. H{\"a}rtel, 1860.

\bibitem[Todorov(2005)]{todorov2005stochastic}
Emanuel Todorov.
\newblock Stochastic optimal control and estimation methods adapted to the
  noise characteristics of the sensorimotor system.
\newblock \emph{Neural computation}, 17\penalty0 (5):\penalty0 1084--1108,
  2005.

\bibitem[Todorov and Jordan(2002)]{todorov2002optimal}
Emanuel Todorov and Michael~I Jordan.
\newblock Optimal feedback control as a theory of motor coordination.
\newblock \emph{Nature neuroscience}, 5\penalty0 (11):\penalty0 1226--1235,
  2002.

\bibitem[Shadmehr and Krakauer(2008)]{shadmehr2008computational}
Reza Shadmehr and John~W Krakauer.
\newblock A computational neuroanatomy for motor control.
\newblock \emph{Experimental brain research}, 185\penalty0 (3):\penalty0
  359--381, 2008.

\bibitem[Franklin and Wolpert(2011)]{franklin_computational_2011}
David~W Franklin and Daniel~M Wolpert.
\newblock Computational mechanisms of sensorimotor control.
\newblock \emph{Neuron}, 72\penalty0 (3):\penalty0 425--442, 2011.

\bibitem[Nashed et~al.(2012)Nashed, Crevecoeur, and Scott]{nashed2012influence}
Joseph~Y Nashed, Fr{\'e}d{\'e}ric Crevecoeur, and Stephen~H Scott.
\newblock Influence of the behavioral goal and environmental obstacles on rapid
  feedback responses.
\newblock \emph{Journal of neurophysiology}, 108\penalty0 (4):\penalty0
  999--1009, 2012.

\bibitem[Crevecoeur et~al.(2016)Crevecoeur, Munoz, and
  Scott]{crevecoeur2016dynamic}
Fr{\'e}d{\'e}ric Crevecoeur, Douglas~P Munoz, and Stephen~H Scott.
\newblock Dynamic multisensory integration: somatosensory speed trumps visual
  accuracy during feedback control.
\newblock \emph{Journal of Neuroscience}, 36\penalty0 (33):\penalty0
  8598--8611, 2016.

\bibitem[Izawa et~al.(2008)Izawa, Rane, Donchin, and Shadmehr]{izawa2008motor}
Jun Izawa, Tushar Rane, Opher Donchin, and Reza Shadmehr.
\newblock Motor adaptation as a process of reoptimization.
\newblock \emph{Journal of Neuroscience}, 28\penalty0 (11):\penalty0
  2883--2891, 2008.

\bibitem[Yeo et~al.(2016)Yeo, Franklin, and Wolpert]{yeo2016optimal}
Sang-Hoon Yeo, David~W Franklin, and Daniel~M Wolpert.
\newblock When optimal feedback control is not enough: Feedforward strategies
  are required for optimal control with active sensing.
\newblock \emph{PLoS computational biology}, 12\penalty0 (12):\penalty0
  e1005190, 2016.

\bibitem[Nagengast et~al.(2010)Nagengast, Braun, and
  Wolpert]{nagengast2010risk}
Arne~J Nagengast, Daniel~A Braun, and Daniel~M Wolpert.
\newblock Risk-sensitive optimal feedback control accounts for sensorimotor
  behavior under uncertainty.
\newblock \emph{PLoS computational biology}, 6\penalty0 (7):\penalty0 e1000857,
  2010.

\bibitem[Ethier et~al.(2008)Ethier, Zee, and Shadmehr]{ethier2008changes}
Vincent Ethier, David~S Zee, and Reza Shadmehr.
\newblock Changes in control of saccades during gain adaptation.
\newblock \emph{Journal of Neuroscience}, 28\penalty0 (51):\penalty0
  13929--13937, 2008.

\bibitem[Diedrichsen(2007)]{diedrichsen2007optimal}
J{\"o}rn Diedrichsen.
\newblock Optimal task-dependent changes of bimanual feedback control and
  adaptation.
\newblock \emph{Current Biology}, 17\penalty0 (19):\penalty0 1675--1679, 2007.

\bibitem[Ng et~al.(2000)Ng, Russell, and {others}]{ng_algorithms_2000}
Andrew~Y Ng, Stuart~J Russell, and {others}.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{Icml}, volume~1, page~2, 2000.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and
  Dey]{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{Aaai}, volume~8, pages 1433--1438. Chicago, IL, USA, 2008.

\bibitem[Finn et~al.(2016)Finn, Levine, and Abbeel]{finn2016guided}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In \emph{International conference on machine learning}, pages 49--58.
  PMLR, 2016.

\bibitem[Priess et~al.(2014)Priess, Choi, and Radcliffe]{priess2014inverse}
M~Cody Priess, Jongeun Choi, and Clark Radcliffe.
\newblock The inverse problem of continuous-time linear quadratic gaussian
  control with application to biological systems analysis.
\newblock In \emph{Dynamic Systems and Control Conference}, volume 46209, page
  V003T42A004. American Society of Mechanical Engineers, 2014.

\bibitem[Golub et~al.(2013)Golub, Chase, and Yu]{golub2013learning}
Matthew Golub, Steven Chase, and Byron Yu.
\newblock Learning an internal dynamics model from control demonstration.
\newblock In \emph{International Conference on Machine Learning}, pages
  606--614. PMLR, 2013.

\bibitem[El-Hussieny and Ryu(2019)]{el2019inverse}
Haitham El-Hussieny and Jee-Hwan Ryu.
\newblock Inverse discounted-based lqr algorithm for learning human movement
  behaviors.
\newblock \emph{Applied Intelligence}, 49\penalty0 (4):\penalty0 1489--1501,
  2019.

\bibitem[Simon(1955)]{simon1955behavioral}
Herbert~A Simon.
\newblock A behavioral model of rational choice.
\newblock \emph{The quarterly journal of economics}, 69\penalty0 (1):\penalty0
  99--118, 1955.

\bibitem[Anderson(1991)]{anderson1991human}
John~R Anderson.
\newblock Is human cognition adaptive?
\newblock \emph{Behavioral and Brain Sciences}, 14\penalty0 (3):\penalty0
  471--485, 1991.

\bibitem[Kahneman and Tversky(1979)]{kahneman1979prospect}
Daniel Kahneman and Amos Tversky.
\newblock Prospect theory: An analysis of decision under risk.
\newblock \emph{Econometrica}, 47\penalty0 (2):\penalty0 263--292, 1979.

\bibitem[Mosteller and Nogee(1951)]{mosteller1951experimental}
Frederick Mosteller and Philip Nogee.
\newblock An experimental measurement of utility.
\newblock \emph{Journal of Political Economy}, 59\penalty0 (5):\penalty0
  371--404, 1951.

\bibitem[Chalk et~al.(2021)Chalk, Tkacik, and Marre]{chalk2021inferring}
Matthew Chalk, Gasper Tkacik, and Olivier Marre.
\newblock Inferring the function performed by a recurrent neural network.
\newblock \emph{Plos one}, 16\penalty0 (4):\penalty0 e0248940, 2021.

\bibitem[Boularias et~al.(2011)Boularias, Kober, and
  Peters]{boularias2011relative}
Abdeslam Boularias, Jens Kober, and Jan Peters.
\newblock Relative entropy inverse reinforcement learning.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 182--189. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem[Rothkopf and Dimitrakakis(2011)]{rothkopf2011preference}
Constantin~A Rothkopf and Christos Dimitrakakis.
\newblock Preference elicitation and inverse reinforcement learning.
\newblock In \emph{Joint European conference on machine learning and knowledge
  discovery in databases}, pages 34--48. Springer, 2011.

\bibitem[Fu et~al.(2018)Fu, Luo, and Levine]{fu2018learning}
Justin Fu, Katie Luo, and Sergey Levine.
\newblock Learning robust rewards with adverserial inverse reinforcement
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Chan and van~der Schaar(2020)]{chan2020scalable}
Alex~James Chan and Mihaela van~der Schaar.
\newblock Scalable bayesian inverse reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Mombaur et~al.(2010)Mombaur, Truong, and Laumond]{mombaur2010human}
Katja Mombaur, Anh Truong, and Jean-Paul Laumond.
\newblock From human to humanoid locomotionâ€”an inverse optimal control
  approach.
\newblock \emph{Autonomous robots}, 28\penalty0 (3):\penalty0 369--383, 2010.

\bibitem[Rothkopf and Ballard(2013)]{rothkopf2013modular}
Constantin~A Rothkopf and Dana~H Ballard.
\newblock Modular inverse reinforcement learning for visuomotor behavior.
\newblock \emph{Biological cybernetics}, 107\penalty0 (4):\penalty0 477--490,
  2013.

\bibitem[Muelling et~al.(2014)Muelling, Boularias, Mohler, Sch{\"o}lkopf, and
  Peters]{muelling2014learning}
Katharina Muelling, Abdeslam Boularias, Betty Mohler, Bernhard Sch{\"o}lkopf,
  and Jan Peters.
\newblock Learning strategies in table tennis using inverse reinforcement
  learning.
\newblock \emph{Biological cybernetics}, 108\penalty0 (5):\penalty0 603--619,
  2014.

\bibitem[Reddy et~al.(2018)Reddy, Dragan, and Levine]{reddy2018you}
Siddharth Reddy, Anca~D Dragan, and Sergey Levine.
\newblock Where do you think you're going? inferring beliefs about dynamics
  from behavior.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 1461--1472, 2018.

\bibitem[Choi and Kim(2011)]{choi2011inverse}
JD~Choi and Kee-Eung Kim.
\newblock Inverse reinforcement learning in partially observable environments.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 691--730,
  2011.

\bibitem[Houlsby et~al.(2013)Houlsby, Husz{\'a}r, Ghassemi, Orb{\'a}n, Wolpert,
  and Lengyel]{houlsby2013cognitive}
Neil~MT Houlsby, Ferenc Husz{\'a}r, Mohammad~M Ghassemi, Gerg{\H{o}} Orb{\'a}n,
  Daniel~M Wolpert, and M{\'a}t{\'e} Lengyel.
\newblock Cognitive tomography reveals complex, task-independent mental
  representations.
\newblock \emph{Current Biology}, 23\penalty0 (21):\penalty0 2169--2175, 2013.

\bibitem[K{\"o}rding and Wolpert(2004)]{kording2004loss}
Konrad~Paul K{\"o}rding and Daniel~M Wolpert.
\newblock The loss function of sensorimotor learning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 101\penalty0
  (26):\penalty0 9839--9842, 2004.

\bibitem[Ahmad and Yu(2013)]{ahmad_active_2013}
Sheeraz Ahmad and Angela~J Yu.
\newblock Active sensing as bayes-optimal sequential decision-making.
\newblock In \emph{Proceedings of the Twenty-Ninth Conference on Uncertainty in
  Artificial Intelligence}, pages 12--21, 2013.

\bibitem[Hoppe and Rothkopf(2019)]{hoppe2019multi}
David Hoppe and Constantin~A Rothkopf.
\newblock Multi-step planning of eye movements in visual search.
\newblock \emph{Scientific reports}, 9\penalty0 (1):\penalty0 1--12, 2019.

\bibitem[Belousov et~al.(2016)Belousov, Neumann, Rothkopf, and
  Peters]{belousov2016catching}
Boris Belousov, Gerhard Neumann, Constantin~A Rothkopf, and Jan~R Peters.
\newblock Catching heuristics are optimal control policies.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 1426--1434, 2016.

\bibitem[Schmitt et~al.(2017)Schmitt, Bieg, Herman, and
  Rothkopf]{schmitt2017see}
Felix Schmitt, Hans-Joachim Bieg, Michael Herman, and Constantin~A Rothkopf.
\newblock I see what you see: Inferring sensor and policy models of human
  real-world motor behavior.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence},
  2017.

\bibitem[Daunizeau et~al.(2010)Daunizeau, Den~Ouden, Pessiglione, Kiebel,
  Stephan, and Friston]{daunizeau2010observing}
Jean Daunizeau, Hanneke~EM Den~Ouden, Matthias Pessiglione, Stefan~J Kiebel,
  Klaas~E Stephan, and Karl~J Friston.
\newblock Observing the observer (i): meta-bayesian models of learning and
  decision-making.
\newblock \emph{PloS one}, 5\penalty0 (12):\penalty0 e15554, 2010.

\bibitem[Wu et~al.(2020)Wu, Kwon, Daptardar, Schrater, and
  Pitkow]{wu2020rational}
Zhengwei Wu, Minhae Kwon, Saurabh Daptardar, Paul Schrater, and Xaq Pitkow.
\newblock Rational thoughts in neural codes.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (47):\penalty0 29311--29320, 2020.

\bibitem[Baker et~al.(2009)Baker, Saxe, and Tenenbaum]{baker_action_2009}
Chris~L. Baker, Rebecca Saxe, and Joshua~B. Tenenbaum.
\newblock Action understanding as inverse planning.
\newblock \emph{Cognition}, 113\penalty0 (3):\penalty0 329--349, 2009.
\newblock Publisher: Elsevier.

\bibitem[Zhi-Xuan et~al.(2020)Zhi-Xuan, Mann, Silver, Tenenbaum, and
  Mansinghka]{zhi-xuan_online_2020}
Tan Zhi-Xuan, Jordyn Mann, Tom Silver, Josh Tenenbaum, and Vikash Mansinghka.
\newblock Online bayesian goal inference for boundedly rational planning
  agents.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Levine and Koltun(2012)]{levine2012continuous}
Sergey Levine and Vladlen Koltun.
\newblock Continuous inverse optimal control with locally optimal examples.
\newblock In \emph{Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 475--482, 2012.

\bibitem[Ramadan et~al.(2016)Ramadan, Choi, and
  Radcliffe]{ramadan2016inferring}
Ahmed Ramadan, Jongeun Choi, and Clark~J Radcliffe.
\newblock Inferring human subject motor control intent using inverse mpc.
\newblock In \emph{2016 American Control Conference (ACC)}, pages 5791--5796.
  IEEE, 2016.

\bibitem[Golub et~al.(2015)Golub, Byron, and Chase]{golub2015internal}
Matthew~D Golub, M~Yu Byron, and Steven~M Chase.
\newblock Internal models for interpreting neural population activity during
  sensorimotor control.
\newblock \emph{Elife}, 4:\penalty0 e10015, 2015.

\bibitem[Chen and Ziebart(2015)]{chen2015predictive}
Xiangli Chen and Brian Ziebart.
\newblock Predictive inverse optimal control for linear-quadratic-gaussian
  systems.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 165--173.
  PMLR, 2015.

\bibitem[Van Den~Berg et~al.(2011)Van Den~Berg, Abbeel, and
  Goldberg]{van2011lqg}
Jur Van Den~Berg, Pieter Abbeel, and Ken Goldberg.
\newblock Lqg-mp: Optimized path planning for robots with motion uncertainty
  and imperfect state information.
\newblock \emph{The International Journal of Robotics Research}, 30\penalty0
  (7):\penalty0 895--913, 2011.

\bibitem[Cartis et~al.(2019)Cartis, Fiala, Marteau, and
  Roberts]{cartis2019improving}
Coralia Cartis, Jan Fiala, Benjamin Marteau, and Lindon Roberts.
\newblock Improving the flexibility and robustness of model-based
  derivative-free optimization solvers.
\newblock \emph{ACM Transactions on Mathematical Software (TOMS)}, 45\penalty0
  (3):\penalty0 1--41, 2019.

\bibitem[Frostig et~al.(2018)Frostig, Johnson, and Leary]{frostig2018compiling}
Roy Frostig, Matthew~James Johnson, and Chris Leary.
\newblock Compiling machine learning programs via high-level tracing.
\newblock \emph{Systems for Machine Learning}, 2018.

\bibitem[Flint et~al.(2012)Flint, Lindberg, Jordan, Miller, and
  Slutzky]{flint2012accurate}
Robert~D Flint, Eric~W Lindberg, Luke~R Jordan, Lee~E Miller, and Marc~W
  Slutzky.
\newblock Accurate decoding of reaching movements from field potentials in the
  absence of spikes.
\newblock \emph{Journal of neural engineering}, 9\penalty0 (4):\penalty0
  046006, 2012.

\bibitem[Crevecoeur and Kording(2017)]{crevecoeur2017saccadic}
Frederic Crevecoeur and Konrad~P Kording.
\newblock Saccadic suppression as a perceptual consequence of efficient
  sensorimotor estimation.
\newblock \emph{Elife}, 6:\penalty0 e25073, 2017.

\bibitem[Todorov and Li(2005)]{todorov2005generalized}
Emanuel Todorov and Weiwei Li.
\newblock A generalized iterative lqg method for locally-optimal feedback
  control of constrained nonlinear stochastic systems.
\newblock In \emph{Proceedings of the 2005, American Control Conference,
  2005.}, pages 300--306. IEEE, 2005.

\bibitem[Levine and Koltun(2013)]{levine2013guided}
Sergey Levine and Vladlen Koltun.
\newblock Guided policy search.
\newblock In \emph{International conference on machine learning}, pages 1--9.
  PMLR, 2013.

\bibitem[Levine et~al.(2016)Levine, Finn, Darrell, and Abbeel]{levine2016end}
Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1334--1373, 2016.

\bibitem[Peters et~al.(2003)Peters, Vijayakumar, and
  Schaal]{peters2003reinforcement}
J~Peters, S~Vijayakumar, and S~Schaal.
\newblock Reinforcement learning for humanoid robotics.
\newblock In \emph{3rd IEEE-RAS International Conference on Humanoid Robots
  (ICHR 2003)}, pages 1--20. VDI/VDE-GMA, 2003.

\bibitem[Abbeel and Ng(2004)]{abbeel2004apprenticeship}
Pieter Abbeel and Andrew~Y Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, page~1, 2004.

\bibitem[Ho and Ermon(2016)]{ho2016generative}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 4565--4573, 2016.

\bibitem[Osa et~al.(2018)Osa, Pajarinen, Neumann, Bagnell, Abbeel, Peters,
  et~al.]{osa2018algorithmic}
Takayuki Osa, Joni Pajarinen, Gerhard Neumann, J~Andrew Bagnell, Pieter Abbeel,
  Jan Peters, et~al.
\newblock An algorithmic perspective on imitation learning.
\newblock \emph{Foundations and Trends in Robotics}, 7\penalty0 (1-2):\penalty0
  1--179, 2018.

\bibitem[Taylor and Stone(2009)]{taylor2009transfer}
Matthew~E Taylor and Peter Stone.
\newblock Transfer learning for reinforcement learning domains: A survey.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0 (7), 2009.

\bibitem[Lazaric(2012)]{lazaric2012transfer}
Alessandro Lazaric.
\newblock Transfer in reinforcement learning: a framework and a survey.
\newblock In \emph{Reinforcement Learning}, pages 143--173. Springer, 2012.

\bibitem[Zhu et~al.(2020)Zhu, Lin, and Zhou]{zhu2020transfer}
Zhuangdi Zhu, Kaixiang Lin, and Jiayu Zhou.
\newblock Transfer learning in deep reinforcement learning: A survey.
\newblock \emph{arXiv preprint arXiv:2009.07888}, 2020.

\end{thebibliography}
