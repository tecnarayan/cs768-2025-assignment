\begin{thebibliography}{10}

\bibitem{reduction}
Alekh Agarwal, Alina Beygelzimer, Miroslav Dud{\'{\i}}k, John Langford, and
  Hanna~M. Wallach.
\newblock A reductions approach to fair classification.
\newblock In Jennifer~G. Dy and Andreas Krause, editors, {\em Proceedings of
  the 35th International Conference on Machine Learning, {ICML} 2018,
  Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018}, volume~80 of
  {\em Proceedings of Machine Learning Research}, pages 60--69. {PMLR}, 2018.

\bibitem{ben2010}
Shai Ben{-}David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira,
  and Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock {\em Mach. Learn.}, 79(1-2):151--175, 2010.

\bibitem{berthelot2021adamatch}
David Berthelot, Rebecca Roelofs, Kihyuk Sohn, Nicholas Carlini, and Alex
  Kurakin.
\newblock Adamatch: A unified approach to semi-supervised learning and domain
  adaptation, 2021.

\bibitem{beutel2017data}
Alex Beutel, Jilin Chen, Zhe Zhao, and Ed~H. Chi.
\newblock Data decisions and theoretical implications when adversarially
  learning fair representations, 2017.

\bibitem{tianle2021}
Tianle Cai, Ruiqi Gao, Jason Lee, and Qi~Lei.
\newblock A theory of label propagation for subpopulation shift.
\newblock In Marina Meila and Tong Zhang, editors, {\em Proceedings of the 38th
  International Conference on Machine Learning}, volume 139 of {\em Proceedings
  of Machine Learning Research}, pages 1170--1182. PMLR, 18--24 Jul 2021.

\bibitem{5360534}
Toon Calders, Faisal Kamiran, and Mykola Pechenizkiy.
\newblock Building classifiers with independency constraints.
\newblock In {\em 2009 IEEE International Conference on Data Mining Workshops},
  pages 13--18, 2009.

\bibitem{caton2020fairness}
Simon Caton and Christian Haas.
\newblock Fairness in machine learning: A survey, 2020.

\bibitem{fairmeta}
L.~Elisa Celis, Lingxiao Huang, Vijay Keswani, and Nisheeth~K. Vishnoi.
\newblock Classification with fairness constraints: A meta-algorithm with
  provable guarantees.
\newblock In {\em Proceedings of the Conference on Fairness, Accountability,
  and Transparency}, FAT* '19, page 319–328, New York, NY, USA, 2019.
  Association for Computing Machinery.

\bibitem{chakraborty2021can}
Joymallya Chakraborty, Huy Tu, Suvodeep Majumder, and Tim Menzies.
\newblock Can we achieve fairness using semi-supervised learning?
\newblock {\em arXiv preprint arXiv:2111.02038}, 2021.

\bibitem{chen2022fairness}
Yatong Chen, Reilly Raab, Jialu Wang, and Yang Liu.
\newblock Fairness transferability subject to bounded distribution shift.
\newblock {\em arXiv preprint arXiv:2206.00129}, 2022.

\bibitem{chen2020self}
Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma.
\newblock Self-training avoids using spurious features under domain shift.
\newblock {\em Advances in Neural Information Processing Systems},
  33:21061--21071, 2020.

\bibitem{chouldechova2016fair}
Alexandra Chouldechova.
\newblock Fair prediction with disparate impact: A study of bias in recidivism
  prediction instruments, 2016.

\bibitem{fairmixup}
Ching{-}Yao Chuang and Youssef Mroueh.
\newblock Fair mixup: Fairness via interpolation.
\newblock In {\em 9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.

\bibitem{chzhen2019leveraging}
Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano
  Pontil.
\newblock Leveraging labeled and unlabeled data for consistent fair binary
  classification.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{corbettdavies2018measure}
Sam Corbett-Davies and Sharad Goel.
\newblock The measure and mismeasure of fairness: A critical review of fair
  machine learning, 2018.

\bibitem{coston_missing}
Amanda Coston, Karthikeyan~Natesan Ramamurthy, Dennis Wei, Kush~R. Varshney,
  Skyler Speakman, Zairah Mustahsan, and Supriyo Chakraborty.
\newblock Fair transfer learning with missing protected attributes.
\newblock In Vincent Conitzer, Gillian~K. Hadfield, and Shannon Vallor,
  editors, {\em Proceedings of the 2019 {AAAI/ACM} Conference on AI, Ethics,
  and Society, {AIES} 2019, Honolulu, HI, USA, January 27-28, 2019}, pages
  91--98. {ACM}, 2019.

\bibitem{disentangle2019}
Elliot Creager, David Madras, J{\"{o}}rn{-}Henrik Jacobsen, Marissa~A. Weis,
  Kevin Swersky, Toniann Pitassi, and Richard~S. Zemel.
\newblock Flexibly fair representation learning by disentanglement.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning, {ICML}
  2019, 9-15 June 2019, Long Beach, California, {USA}}, volume~97 of {\em
  Proceedings of Machine Learning Research}, pages 1436--1445. {PMLR}, 2019.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition Workshops}, pages 702--703, 2020.

\bibitem{ding2021retiring}
Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt.
\newblock Retiring adult: New datasets for fair machine learning.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan,
  editors, {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{Donini_erm_fair}
Michele Donini, Luca Oneto, Shai Ben{-}David, John Shawe{-}Taylor, and
  Massimiliano Pontil.
\newblock Empirical risk minimization under fairness constraints.
\newblock In Samy Bengio, Hanna~M. Wallach, Hugo Larochelle, Kristen Grauman,
  Nicol{\`{o}} Cesa{-}Bianchi, and Roman Garnett, editors, {\em Advances in
  Neural Information Processing Systems 31: Annual Conference on Neural
  Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018,
  Montr{\'{e}}al, Canada}, pages 2796--2806, 2018.

\bibitem{friedler2016impossibility}
Sorelle~A. Friedler, Carlos Scheidegger, and Suresh Venkatasubramanian.
\newblock On the (im)possibility of fairness, 2016.

\bibitem{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock {\em The journal of machine learning research}, 17(1):2096--2030,
  2016.

\bibitem{giguere2022fairness}
Stephen Giguere, Blossom Metevier, Yuriy Brun, Philip~S. Thomas, Scott Niekum,
  and Bruno~Castro da~Silva.
\newblock Fairness guarantees under demographic shift.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{causal2019}
Bruce Glymour and Jonathan Herington.
\newblock Measuring the biases that matter: The ethical and casual foundations
  for measures of fairness in algorithms.
\newblock In danah boyd and Jamie~H. Morgenstern, editors, {\em Proceedings of
  the Conference on Fairness, Accountability, and Transparency, FAT* 2019,
  Atlanta, GA, USA, January 29-31, 2019}, pages 269--278. {ACM}, 2019.

\bibitem{goel2021model}
Karan Goel, Albert Gu, Yixuan Li, and Christopher Re.
\newblock Model patching: Closing the subgroup performance gap with data
  augmentation.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec, Pierre
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan
  Guo, Mohammad Gheshlaghi~Azar, et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:21271--21284, 2020.

\bibitem{hardt2016equality}
Moritz Hardt, Eric Price, and Nati Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{pmlr-v80-hoffman18a}
Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate
  Saenko, Alexei Efros, and Trevor Darrell.
\newblock {C}y{CADA}: Cycle-consistent adversarial domain adaptation.
\newblock In Jennifer Dy and Andreas Krause, editors, {\em Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of {\em
  Proceedings of Machine Learning Research}, pages 1989--1998. PMLR, 10--15 Jul
  2018.

\bibitem{jing2021towards}
Taotao Jing, Bingrong Xu, and Zhengming Ding.
\newblock Towards fair knowledge transfer for imbalanced domain adaptation.
\newblock {\em IEEE Transactions on Image Processing}, 30:8200--8211, 2021.

\bibitem{karkkainen2019fairface}
Kimmo K{\"a}rkk{\"a}inen and Jungseock Joo.
\newblock Fairface: Face attribute dataset for balanced race, gender, and age.
\newblock {\em arXiv preprint arXiv:1908.04913}, 2019.

\bibitem{pmlr-v80-kim18b}
Hyunjik Kim and Andriy Mnih.
\newblock Disentangling by factorising.
\newblock In Jennifer Dy and Andreas Krause, editors, {\em Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of {\em
  Proceedings of Machine Learning Research}, pages 2649--2658. PMLR, 10--15 Jul
  2018.

\bibitem{koh2021wilds}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang,
  Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~Lanas Phillips,
  Irena Gao, et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In {\em International Conference on Machine Learning}, pages
  5637--5664. PMLR, 2021.

\bibitem{kumar2020understanding}
Ananya Kumar, Tengyu Ma, and Percy Liang.
\newblock Understanding self-training for gradual domain adaptation.
\newblock In {\em International Conference on Machine Learning}, pages
  5468--5479. PMLR, 2020.

\bibitem{counter2017}
Matt~J. Kusner, Joshua~R. Loftus, Chris Russell, and Ricardo Silva.
\newblock Counterfactual fairness.
\newblock In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna~M. Wallach,
  Rob Fergus, S.~V.~N. Vishwanathan, and Roman Garnett, editors, {\em Advances
  in Neural Information Processing Systems 30: Annual Conference on Neural
  Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
  {USA}}, pages 4066--4076, 2017.

\bibitem{lan2017discriminatory}
Chao Lan and Jun Huan.
\newblock Discriminatory transfer.
\newblock {\em arXiv preprint arXiv:1707.00780}, 2017.

\bibitem{li2020rethinking}
Bo~Li, Yezhen Wang, Tong Che, Shanghang Zhang, Sicheng Zhao, Pengfei Xu, Wei
  Zhou, Yoshua Bengio, and Kurt Keutzer.
\newblock Rethinking distributional matching based domain adaptation.
\newblock {\em arXiv preprint arXiv:2006.13352}, 2020.

\bibitem{liu2021selfsupervised}
Hong Liu, Jeff~Z. HaoChen, Adrien Gaidon, and Tengyu Ma.
\newblock Self-supervised learning is more robust to dataset imbalance.
\newblock In {\em NeurIPS 2021 Workshop on Distribution Shifts: Connecting
  Methods and Applications}, 2021.

\bibitem{liu2021cycle}
Hong Liu, Jianmin Wang, and Mingsheng Long.
\newblock Cycle self-training for domain adaptation, 2021.

\bibitem{long2015learning}
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In {\em International conference on machine learning}, pages 97--105.
  PMLR, 2015.

\bibitem{long2018conditional}
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael~I Jordan.
\newblock Conditional adversarial domain adaptation.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{fair_vae}
Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard~S. Zemel.
\newblock The variational fair autoencoder.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em 4th International
  Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico,
  May 2-4, 2016, Conference Track Proceedings}, 2016.

\bibitem{david_learning_fair}
David Madras, Elliot Creager, Toniann Pitassi, and Richard~S. Zemel.
\newblock Learning adversarially fair and transferable representations.
\newblock In Jennifer~G. Dy and Andreas Krause, editors, {\em Proceedings of
  the 35th International Conference on Machine Learning, {ICML} 2018,
  Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018}, volume~80 of
  {\em Proceedings of Machine Learning Research}, pages 3381--3390. {PMLR},
  2018.

\bibitem{mandal2020ensuring}
Debmalya Mandal, Samuel Deng, Suman Jana, Jeannette Wing, and Daniel~J Hsu.
\newblock Ensuring fairness beyond the training data.
\newblock {\em Advances in neural information processing systems},
  33:18445--18456, 2020.

\bibitem{survey}
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
  Galstyan.
\newblock A survey on bias and fairness in machine learning.
\newblock {\em CoRR}, abs/1908.09635, 2019.

\bibitem{fairness2020}
Luca Oneto and Silvia Chiappa.
\newblock Fairness in machine learning.
\newblock {\em Studies in Computational Intelligence}, page 155–196, 2020.

\bibitem{rajkomar2018ensuring}
Alvin Rajkomar, Michaela Hardt, Michael~D Howell, Greg Corrado, and Marshall~H
  Chin.
\newblock Ensuring fairness in machine learning to advance health equity.
\newblock {\em Annals of internal medicine}, 169(12):866--872, 2018.

\bibitem{reddy2021benchmarking}
Charan Reddy, Deepak Sharma, Soroush Mehri, Adriana Romero-Soriano, Samira
  Shabanian, and Sina Honari.
\newblock Benchmarking bias mitigation algorithms in representation learning
  through fairness metrics.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 1)}, 2021.

\bibitem{rezaei_robust}
Ashkan Rezaei, Anqi Liu, Omid Memarrast, and Brian~D. Ziebart.
\newblock Robust fairness under covariate shift.
\newblock {\em CoRR}, abs/2010.05166, 2020.

\bibitem{Sagawa2021ExtendingTW}
Shiori Sagawa, Pang~Wei Koh, Tony Lee, Irena Gao, Sang~Michael Xie, Kendrick
  Shen, Ananya Kumar, Weihua Hu, Michihiro Yasunaga, Henrik Marklund, Sara
  Beery, Etienne David, Ian Stavness, Wei Guo, Jure Leskovec, Kate Saenko,
  Tatsunori~B. Hashimoto, Sergey Levine, Chelsea Finn, and Percy Liang.
\newblock Extending the wilds benchmark for unsupervised adaptation.
\newblock {\em ArXiv}, abs/2112.05090, 2021.

\bibitem{schrouff2022maintaining}
Jessica Schrouff, Natalie Harris, Oluwasanmi Koyejo, Ibrahim Alabdulmohsin, Eva
  Schnider, Krista Opsahl-Ong, Alex Brown, Subhrajit Roy, Diana Mincu,
  Christina Chen, Awa Dieng, Yuan Liu, Vivek Natarajan, Alan Karthikesalingam,
  Katherine Heller, Silvia Chiappa, and Alexander D'Amour.
\newblock Maintaining fairness across distribution shift: do we have viable
  solutions for real-world applications?, 2022.

\bibitem{candice_transfer}
Candice Schumann, Xuezhi Wang, Alex Beutel, Jilin Chen, Hai Qian, and Ed~H.
  Chi.
\newblock Transfer of machine learning fairness across domains.
\newblock {\em CoRR}, abs/1906.09688, 2019.

\bibitem{shu2018dirt}
Rui Shu, Hung~H Bui, Hirokazu Narui, and Stefano Ermon.
\newblock A dirt-t approach to unsupervised domain adaptation.
\newblock {\em arXiv preprint arXiv:1802.08735}, 2018.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{singh_violate}
Harvineet Singh, Rina Singh, Vishwali Mhasawade, and Rumi Chunara.
\newblock Fairness violations and mitigation under covariate shift.
\newblock In Madeleine~Clare Elish, William Isaac, and Richard~S. Zemel,
  editors, {\em FAccT '21: 2021 {ACM} Conference on Fairness, Accountability,
  and Transparency, Virtual Event / Toronto, Canada, March 3-10, 2021}, pages
  3--13. {ACM}, 2021.

\bibitem{sohn2020fixmatch}
Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini,
  Ekin~D Cubuk, Alex Kurakin, Han Zhang, and Colin Raffel.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock {\em arXiv preprint arXiv:2001.07685}, 2020.

\bibitem{control2019}
Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, and Stefano
  Ermon.
\newblock Learning controllable fair representations.
\newblock In Kamalika Chaudhuri and Masashi Sugiyama, editors, {\em The 22nd
  International Conference on Artificial Intelligence and Statistics, {AISTATS}
  2019, 16-18 April 2019, Naha, Okinawa, Japan}, volume~89 of {\em Proceedings
  of Machine Learning Research}, pages 2164--2173. {PMLR}, 2019.

\bibitem{tachet2020domain}
Remi Tachet~des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey~J Gordon.
\newblock Domain adaptation with conditional distribution matching and
  generalized label shift.
\newblock {\em Advances in Neural Information Processing Systems},
  33:19276--19289, 2020.

\bibitem{tzeng2017adversarial}
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7167--7176, 2017.

\bibitem{wang2022equalized}
Haotao Wang, Junyuan Hong, Jiayu Zhou, and Zhangyang Wang.
\newblock Equalized robustness: Towards sustainable fairness under
  distributional shifts, 2022.

\bibitem{wang2021towards}
Tongxin Wang, Zhengming Ding, Wei Shao, Haixu Tang, and Kun Huang.
\newblock Towards fair cross-domain adaptation via generative learning.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 454--463, 2021.

\bibitem{colin2021}
Colin Wei, Kendrick Shen, Yining Chen, and Tengyu Ma.
\newblock Theoretical analysis of self-training with deep networks on unlabeled
  data.
\newblock In {\em 9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.

\bibitem{wiles2022a}
Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira
  Ktena, Krishnamurthy~Dj Dvijotham, and Ali~Taylan Cemgil.
\newblock A fine-grained analysis on distribution shift.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{wu2019domain}
Yifan Wu, Ezra Winston, Divyansh Kaushik, and Zachary Lipton.
\newblock Domain adaptation with asymmetrically-relaxed distribution alignment.
\newblock In {\em International Conference on Machine Learning}, pages
  6872--6881. PMLR, 2019.

\bibitem{yoon_wasser}
Tae{-}Ho Yoon, Jaewook Lee, and Woojin Lee.
\newblock Joint transfer of model knowledge and fairness over domains using
  wasserstein distance.
\newblock {\em {IEEE} Access}, 8:123783--123798, 2020.

\bibitem{pmlr-v54-zafar17a}
Muhammad~Bilal Zafar, Isabel Valera, Manuel~Gomez Rogriguez, and Krishna~P.
  Gummadi.
\newblock {Fairness Constraints: Mechanisms for Fair Classification}.
\newblock In Aarti Singh and Jerry Zhu, editors, {\em Proceedings of the 20th
  International Conference on Artificial Intelligence and Statistics},
  volume~54 of {\em Proceedings of Machine Learning Research}, pages 962--970.
  PMLR, 20--22 Apr 2017.

\bibitem{pmlr-v28-zemel13}
Rich Zemel, Yu~Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork.
\newblock Learning fair representations.
\newblock In Sanjoy Dasgupta and David McAllester, editors, {\em Proceedings of
  the 30th International Conference on Machine Learning}, volume~28 of {\em
  Proceedings of Machine Learning Research}, pages 325--333, Atlanta, Georgia,
  USA, 17--19 Jun 2013. PMLR.

\bibitem{zhang2018mitigating}
Brian~Hu Zhang, Blake Lemoine, and Margaret Mitchell.
\newblock Mitigating unwanted biases with adversarial learning.
\newblock In {\em Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 335--340, 2018.

\bibitem{9117188}
Tao Zhang, tianqing zhu, Jing Li, Mengde Han, Wanlei Zhou, and Philip Yu.
\newblock Fairness in semi-supervised learning: Unlabeled data help to reduce
  discrimination.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, pages
  1--1, 2020.

\bibitem{zhang2021farf}
Wenbin Zhang, Albert Bifet, Xiangliang Zhang, Jeremy~C Weiss, and Wolfgang
  Nejdl.
\newblock Farf: A fair and adaptive random forests classifier.
\newblock In {\em Pacific-Asia Conference on Knowledge Discovery and Data
  Mining}, pages 245--256. Springer, 2021.

\bibitem{zhang2021semisupervised}
Yabin Zhang, Haojian Zhang, Bin Deng, Shuai Li, Kui Jia, and Lei Zhang.
\newblock Semi-supervised models are strong unsupervised domain adaptation
  learners, 2021.

\bibitem{zhifei2017cvpr}
Zhifei Zhang, Yang Song, and Hairong Qi.
\newblock Age progression/regression by conditional adversarial autoencoder.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}. IEEE, 2017.

\bibitem{zhao2019conditional}
Han Zhao, Amanda Coston, Tameem Adel, and Geoffrey~J Gordon.
\newblock Conditional learning of fair representations.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{conditionalzhao}
Han Zhao, Amanda Coston, Tameem Adel, and Geoffrey~J. Gordon.
\newblock Conditional learning of fair representations.
\newblock In {\em 8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\bibitem{zhao2019learning}
Han Zhao, Remi~Tachet Des~Combes, Kun Zhang, and Geoffrey Gordon.
\newblock On learning invariant representations for domain adaptation.
\newblock In {\em International Conference on Machine Learning}, pages
  7523--7532. PMLR, 2019.

\bibitem{zhu2021understanding}
Sicheng Zhu, Bang An, and Furong Huang.
\newblock Understanding the generalization benefit of model invariance from a
  data perspective.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{zhu2022the}
Zhaowei Zhu, Tianyi Luo, and Yang Liu.
\newblock The rich get richer: Disparate impact of semi-supervised learning.
\newblock In {\em International Conference on Learning Representations}, 2022.

\end{thebibliography}
