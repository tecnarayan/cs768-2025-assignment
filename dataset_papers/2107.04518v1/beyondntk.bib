%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Zhao, Tuo at 2020-05-30 23:35:13 -0400 


%%

@article{damian2021label,
	title={Label Noise SGD Provably Prefers Flat Global Minimizers},
	author={Damian, Alex and Ma, Tengyu and Lee, Jason},
	journal={arXiv preprint arXiv:2106.06530},
	year={2021}
}

@inproceedings{kalimeris2019sgd,
  title={Sgd on neural networks learns functions of increasing complexity},
  author={Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3496--3506},
  year={2019}
}


@article{hu2020surprising,
  title={The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks},
  author={Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:2006.14599},
  year={2020}
}

@inproceedings{li2020learning,
  title={Learning Over-Parametrized Two-Layer Neural Networks beyond NTK},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang R},
  booktitle={Conference on Learning Theory},
  pages={2613--2682},
  year={2020}
}

@inproceedings{diakonikolas2020algorithms,
  title={Algorithms and SQ Lower Bounds for PAC Learning One-Hidden-Layer ReLU Networks},
  author={Diakonikolas, Ilias and Kane, Daniel M and Kontonis, Vasilis and Zarifis, Nikos},
  booktitle={Conference on Learning Theory},
  pages={1514--1539},
  year={2020}
}

@article{goel2020superpolynomial,
  title={Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent},
  author={Goel, Surbhi and Gollakota, Aravind and Jin, Zhihan and Karmalkar, Sushrut and Klivans, Adam},
  journal={arXiv preprint arXiv:2006.12011},
  year={2020}
}


@inproceedings{mei2018mean,
  title={A mean field view of the landscape of two-layers neural networks},
  author={Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh},
  booktitle={Proceedings of the National Academy of Sciences},
  volume={115},
  pages={E7665--E7671},
  year={2018}
}

@article{sirignano2018mean,
	title={Mean Field Analysis of Neural Networks},
	author={Sirignano, Justin and Spiliopoulos, Konstantinos},
	journal={arXiv preprint arXiv:1805.01053},
	year={2018}
}

@article{rotskoff2018neural,
	title={Neural networks as Interacting Particle Systems: Asymptotic convexity of the Loss Landscape and Universal Scaling of the Approximation Error},
	author={Rotskoff, Grant M and Vanden-Eijnden, Eric},
	journal={arXiv preprint arXiv:1805.00915},
	year={2018}
}



@inproceedings{chizat2018global,
  title={On the global convergence of gradient descent for over-parameterized models using optimal transport},
  author={Chizat, Lenaic and Bach, Francis},
  booktitle={Advances in neural information processing systems},
  pages={3040--3050},
  year={2018}
}

@article{dyer2019asymptotics,
	title={Asymptotics of wide networks from feynman diagrams},
	author={Dyer, Ethan and Gur-Ari, Guy},
	journal={arXiv preprint arXiv:1909.11304},
	year={2019}
}

@article{woodworth2020kernel,
	title={Kernel and rich regimes in overparametrized models},
	author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
	journal={arXiv preprint arXiv:2002.09277},
	year={2020}
}


@article{allen2020backward,
  title={Backward Feature Correction: How Deep Learning Performs Deep Learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2001.04413},
  year={2020}
}

@inproceedings{andoni2014learning,
  title={Learning polynomials with neural networks},
  author={Andoni, Alexandr and Panigrahy, Rina and Valiant, Gregory and Zhang, Li},
  booktitle={International conference on machine learning},
  pages={1908--1916},
  year={2014}
}

@article{montanari2018spectral,
  title={Spectral algorithms for tensor completion},
  author={Montanari, Andrea and Sun, Nike},
  journal={Communications on Pure and Applied Mathematics},
  volume={71},
  number={11},
  pages={2381--2425},
  year={2018},
  publisher={Wiley Online Library}
}

@inproceedings{li2018learning,
  title={Learning overparameterized neural networks via stochastic gradient descent on structured data},
  author={Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8157--8166},
  year={2018}
}

@article{yehudai2019power,
  title={On the power and limitations of random features for understanding neural networks},
  author={Yehudai, Gilad and Shamir, Ohad},
  journal={arXiv preprint arXiv:1904.00687},
  year={2019}
}

@inproceedings{ghorbani2019limitations,
  title={Limitations of Lazy Training of Two-layers Neural Network},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9108--9118},
  year={2019}
}

@article{allen2019can,
  title={What Can ResNet Learn Efficiently, Going Beyond Kernels?},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:1905.10337},
  year={2019}
}

@inproceedings{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9709--9721},
  year={2019}
}

@article{zou2018stochastic,
  title={Stochastic gradient descent optimizes over-parameterized deep relu networks},
  author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:1811.08888},
  year={2018}
}

@inproceedings{lee2016gradient,
	title={Gradient descent only converges to minimizers},
	author={Lee, Jason D and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
	booktitle={Conference on learning theory},
	pages={1246--1257},
	year={2016}
}

@article{chen2020learning,
  title={Learning Polynomials of Few Relevant Dimensions},
  author={Chen, Sitan and Meka, Raghu},
  journal={arXiv preprint arXiv:2004.13748},
  year={2020}
}

@inproceedings{mu2014square,
  title={Square deal: Lower bounds and improved relaxations for tensor recovery},
  author={Mu, Cun and Huang, Bo and Wright, John and Goldfarb, Donald},
  booktitle={International conference on machine learning},
  pages={73--81},
  year={2014}
}

@inproceedings{morcos2018on,
title={On the importance of single directions for generalization},
author={Ari S. Morcos and David G.T. Barrett and Neil C. Rabinowitz and Matthew Botvinick},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=r1iuQjxCZ},
}

@article{huang2019dynamics,
  title={Dynamics of deep neural networks and neural tangent hierarchy},
  author={Huang, Jiaoyang and Yau, Horng-Tzer},
  journal={arXiv preprint arXiv:1909.08156},
  year={2019}
}

@article{bai2020taylorized,
  title={Taylorized Training: Towards Better Approximation of Neural Network Training at Finite Width},
  author={Bai, Yu and Krause, Ben and Wang, Huan and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:2002.04010},
  year={2020}
}

@article{chizat2018note,
	Author = {Chizat, Lenaic and Bach, Francis},
	Date-Added = {2020-06-01 13:19:34 -0400},
	Date-Modified = {2020-06-01 13:19:34 -0400},
	Journal = {arXiv preprint arXiv:1812.07956},
	Title = {A note on lazy training in supervised differentiable programming},
	Volume = {8},
	Year = {2018}}

@inproceedings{arora2019exact,
	Author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {8139--8148},
	Title = {On exact computation with an infinitely wide neural net},
	Year = {2019}}

@inproceedings{chizat2019lazy,
	Author = {Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2933--2943},
	Title = {On lazy training in differentiable programming},
	Year = {2019}}

@inproceedings{du2019gradient,
	Author = {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	Booktitle = {International Conference on Machine Learning},
	Pages = {1675--1685},
	Title = {Gradient Descent Finds Global Minima of Deep Neural Networks},
	Year = {2019}}

@inproceedings{jacot2018neural,
	Author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	Booktitle = {Advances in neural information processing systems},
	Pages = {8571--8580},
	Title = {Neural tangent kernel: Convergence and generalization in neural networks},
	Year = {2018}}

@inproceedings{lee2019wide,
	Author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
	Booktitle = {Advances in neural information processing systems},
	Pages = {8570--8581},
	Title = {Wide neural networks of any depth evolve as linear models under gradient descent},
	Year = {2019}}

@article{telgarsky2016benefits,
	Author = {Telgarsky, Matus},
	Date-Added = {2020-05-30 23:35:11 -0400},
	Date-Modified = {2020-05-30 23:35:11 -0400},
	Journal = {arXiv preprint arXiv:1602.04485},
	Title = {Benefits of depth in neural networks},
	Year = {2016}}

@inproceedings{arora2019exact,
	Author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	Booktitle = {Advances in Neural Information Processing Systems},
	Date-Added = {2020-05-30 23:34:29 -0400},
	Date-Modified = {2020-05-30 23:34:29 -0400},
	Pages = {8139--8148},
	Title = {On exact computation with an infinitely wide neural net},
	Year = {2019}}

@inproceedings{jacot2018neural,
	Author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	Booktitle = {Advances in neural information processing systems},
	Date-Added = {2020-05-30 23:33:51 -0400},
	Date-Modified = {2020-05-30 23:33:51 -0400},
	Pages = {8571--8580},
	Title = {Neural tangent kernel: Convergence and generalization in neural networks},
	Year = {2018}}

@article{chen2020nonparametric,
	Author = {Chen, Minshuo and Jiang, Haoming and Liao, Wenjing and Zhao, Tuo},
	Date-Added = {2020-05-30 23:30:13 -0400},
	Date-Modified = {2020-05-30 23:30:44 -0400},
	Journal = {arXiv preprint arXiv},
	Title = {Nonparametric Regression on Low-Dimensional Manifolds using Deep ReLU Networks},
	Year = {2020}}

@inproceedings{chen2019efficient,
	Author = {Chen, Minshuo and Jiang, Haoming and Liao, Wenjing and Zhao, Tuo},
	Booktitle = {Advances in Neural Information Processing Systems},
	Date-Added = {2020-05-30 23:29:59 -0400},
	Date-Modified = {2020-05-30 23:29:59 -0400},
	Pages = {8172--8182},
	Title = {Efficient approximation of deep relu networks for functions on low dimensional manifolds},
	Year = {2019}}

@article{yarotsky2017error,
	Author = {Yarotsky, Dmitry},
	Date-Added = {2020-05-30 23:29:32 -0400},
	Date-Modified = {2020-05-30 23:29:32 -0400},
	Journal = {Neural Networks},
	Pages = {103--114},
	Publisher = {Elsevier},
	Title = {Error bounds for approximations with deep ReLU networks},
	Volume = {94},
	Year = {2017}}

@article{allen2018convergence,
	Author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	Date-Added = {2020-05-30 23:26:56 -0400},
	Date-Modified = {2020-05-30 23:26:56 -0400},
	Journal = {arXiv preprint arXiv:1811.03962},
	Title = {A convergence theory for deep learning via over-parameterization},
	Year = {2018}}

@article{arora2019fine,
	Author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
	Date-Added = {2020-05-30 23:26:39 -0400},
	Date-Modified = {2020-05-30 23:26:39 -0400},
	Journal = {arXiv preprint arXiv:1901.08584},
	Title = {Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
	Year = {2019}}

@article{du2018gradient,
	Author = {Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	Date-Added = {2020-05-30 23:25:27 -0400},
	Date-Modified = {2020-05-30 23:27:59 -0400},
	Journal = {arXiv preprint arXiv:1811.03804},
	Title = {Gradient descent finds global minima of deep neural networks},
	Year = {2018}}

@article{du2018gradient2,
	Author = {Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
	Date-Added = {2020-05-30 23:25:10 -0400},
	Date-Modified = {2020-05-30 23:28:03 -0400},
	Journal = {arXiv preprint arXiv:1810.02054},
	Title = {Gradient descent provably optimizes over-parameterized neural networks},
	Year = {2018}}

@article{huang2020deep,
	Author = {Huang, Kaixuan and Wang, Yuqing and Tao, Molei and Zhao, Tuo},
	Date-Added = {2020-05-30 23:22:00 -0400},
	Date-Modified = {2020-05-30 23:22:00 -0400},
	Journal = {arXiv preprint arXiv:2002.06262},
	Title = {Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks?--A Neural Tangent Kernel Perspective},
	Year = {2020}}

@article{devlin2018bert,
	Author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	Date-Added = {2020-05-30 22:53:25 -0400},
	Date-Modified = {2020-05-30 22:53:25 -0400},
	Journal = {arXiv preprint arXiv:1810.04805},
	Title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	Year = {2018}}

@inproceedings{girshick2014rich,
	Author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	Booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	Date-Added = {2020-05-30 22:43:31 -0400},
	Date-Modified = {2020-05-30 22:43:31 -0400},
	Pages = {580--587},
	Title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
	Year = {2014}}

@inproceedings{mahajan2018exploring,
	Author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
	Booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
	Date-Added = {2020-05-30 22:41:53 -0400},
	Date-Modified = {2020-05-30 22:41:53 -0400},
	Pages = {181--196},
	Title = {Exploring the limits of weakly supervised pretraining},
	Year = {2018}}

@inproceedings{allen2019learning,
	Author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
	Booktitle = {Advances in neural information processing systems},
	Pages = {6155--6166},
	Title = {Learning and generalization in overparameterized neural networks, going beyond two layers},
	Year = {2019}}

@article{ghorbani2019linearized,
	Author = {Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
	Journal = {arXiv preprint arXiv:1904.12191},
	Title = {Linearized two-layers neural networks in high dimension},
	Year = {2019}}

@inproceedings{he2016deep,
	Author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	Booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	Pages = {770--778},
	Title = {Deep residual learning for image recognition},
	Year = {2016}}

@article{lecun2015deep,
	Author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	Journal = {nature},
	Number = {7553},
	Pages = {436--444},
	Publisher = {Nature Publishing Group},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015}}

@article{vershynin2010introduction,
	Author = {Vershynin, Roman},
	Journal = {arXiv preprint arXiv:1011.3027},
	Title = {Introduction to the non-asymptotic analysis of random matrices},
	Year = {2010}}

@article{jin2019stochastic,
   title={Stochastic gradient descent escapes saddle points efficiently},
   author={Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M and Jordan, Michael I},
   journal={arXiv preprint arXiv:1902.04811},
   year={2019}}

@inproceedings{bai2019beyond,
  title={Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks},
  author={Yu Bai and Jason D. Lee},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=rkllGyBFPH}
}

@article{ghorbani2019linearized,
  title={Linearized two-layers neural networks in high dimension},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={arXiv preprint arXiv:1904.12191},
  year={2019}}

@article{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  journal={arXiv preprint arXiv:1901.08584},
  year={2019}}

@article{cao2019generalization,
  title={Generalization error bounds of gradient descent for learning overparameterized deep relu networks},
  author={Cao, Yuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1902.01384},
  year={2019}}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}}

@article{hornik1991approximation,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Hornik, Kurt},
  journal={Neural networks},
  volume={4},
  number={2},
  pages={251--257},
  year={1991},
  publisher={Elsevier}}