\begin{thebibliography}{}

\bibitem[Abbasi-Yadkori et~al., 2011a]{Abbasi11}
Abbasi-Yadkori, Y., Pal, D., and Szepesvari, C. (2011a).
\newblock Improved algorithms for linear stochastic bandits.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)}.

\bibitem[Abbasi-Yadkori et~al., 2011b]{abbasi2011improved}
Abbasi-Yadkori, Y., P{\'a}l, D., and Szepesv{\'a}ri, C. (2011b).
\newblock Improved algorithms for linear stochastic bandits.
\newblock In {\em NIPS}, volume~11, pages 2312--2320.

\bibitem[Bai et~al., 2019]{bai2019provably}
Bai, Y., Xie, T., Jiang, N., and Wang, Y.~X. (2019).
\newblock Provably efficient q-learning with low switching cost.
\newblock {\em Advances in Neural Information Processing Systems}, 32.

\bibitem[Beygelzimer et~al., 2011]{beygelzimer2011contextual}
Beygelzimer, A., Langford, J., Li, L., Reyzin, L., and Schapire, R. (2011).
\newblock Contextual bandit algorithms with supervised learning guarantees.
\newblock In {\em Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 19--26. JMLR Workshop and
  Conference Proceedings.

\bibitem[Chapelle and Chang, 2011]{chapelle2011yahoo}
Chapelle, O. and Chang, Y. (2011).
\newblock Yahoo! learning to rank challenge overview.
\newblock In {\em Proceedings of the learning to rank challenge}, pages 1--24.
  PMLR.

\bibitem[Chu et~al., 2011]{chu2011contextual}
Chu, W., Li, L., Reyzin, L., and Schapire, R. (2011).
\newblock Contextual bandits with linear payoff functions.
\newblock In {\em Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 208--214. JMLR Workshop and
  Conference Proceedings.

\bibitem[Cortes et~al., 2019]{cortes2019behavioral}
Cortes, K.~E., Fricke, H.~D., Loeb, S., Song, D.~S., and York, B.~N. (2019).
\newblock When behavioral barriers are too high or low--how timing matters for
  parenting interventions.
\newblock Technical report, National Bureau of Economic Research.

\bibitem[Degenne et~al., 2020]{degenne2020gamification}
Degenne, R., M{\'e}nard, P., Shang, X., and Valko, M. (2020).
\newblock Gamification of pure exploration for linear bandits.
\newblock In {\em International Conference on Machine Learning}, pages
  2432--2442. PMLR.

\bibitem[Deshmukh et~al., 2018]{deshmukh2018simple}
Deshmukh, A.~A., Sharma, S., Cutler, J.~W., Moldwin, M., and Scott, C. (2018).
\newblock Simple regret minimization for contextual bandits.
\newblock {\em arXiv preprint arXiv:1810.07371}.

\bibitem[Doss et~al., 2019]{doss2019more}
Doss, C., Fahle, E.~M., Loeb, S., and York, B.~N. (2019).
\newblock More than just a nudge supporting kindergarten parents with
  differentiated and personalized text messages.
\newblock {\em Journal of Human Resources}, 54(3):567--603.

\bibitem[Esfandiari et~al., 2019]{esfandiari2019regret}
Esfandiari, H., Karbasi, A., Mehrabian, A., and Mirrokni, V. (2019).
\newblock Regret bounds for batched bandits.
\newblock {\em arXiv preprint arXiv:1910.04959}.

\bibitem[Fiez et~al., 2019]{fiez2019sequential}
Fiez, T., Jain, L., Jamieson, K., and Ratliff, L. (2019).
\newblock Sequential experimental design for transductive linear bandits.
\newblock {\em arXiv preprint arXiv:1906.08399}.

\bibitem[Foster et~al., 2018]{foster2018practical}
Foster, D., Agarwal, A., Dudik, M., Luo, H., and Schapire, R. (2018).
\newblock Practical contextual bandits with regression oracles.
\newblock In {\em International Conference on Machine Learning}, pages
  1539--1548. PMLR.

\bibitem[Han et~al., 2020]{han2020sequential}
Han, Y., Zhou, Z., Zhou, Z., Blanchet, J., Glynn, P.~W., and Ye, Y. (2020).
\newblock Sequential batch learning in finite-action linear contextual bandits.
\newblock {\em arXiv preprint arXiv:2004.06321}.

\bibitem[Jedra and Proutiere, 2020]{jedra2020optimal}
Jedra, Y. and Proutiere, A. (2020).
\newblock Optimal best-arm identification in linear bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[Kiefer and Wolfowitz, 1960]{kiefer1960equivalence}
Kiefer, J. and Wolfowitz, J. (1960).
\newblock The equivalence of two extremum problems.
\newblock {\em Canadian Journal of Mathematics}, 12:363--366.

\bibitem[Lattimore and Szepesv{\'a}ri, 2020]{lattimore2020bandit}
Lattimore, T. and Szepesv{\'a}ri, C. (2020).
\newblock {\em Bandit Algorithms}.
\newblock Cambridge University Press.

\bibitem[Lattimore and Szepesvari, 2020]{lattimore2020learning}
Lattimore, T. and Szepesvari, C. (2020).
\newblock Learning with good feature representations in bandits and in rl with
  a generative model.
\newblock In {\em International Conference on Machine Learning (ICML)}.

\bibitem[Ren et~al., 2020]{ren2020batched}
Ren, Z., Zhou, Z., and Kalagnanam, J.~R. (2020).
\newblock Batched learning in generalized linear contextual bandits with
  general decision sets.
\newblock {\em IEEE Control Systems Letters}.

\bibitem[Ruan et~al., 2020]{ruan2020linear}
Ruan, Y., Yang, J., and Zhou, Y. (2020).
\newblock Linear bandits with limited adaptivity and learning distributional
  optimal design.
\newblock {\em arXiv preprint arXiv:2007.01980}.

\bibitem[Soare et~al., 2014]{soare2014best}
Soare, M., Lazaric, A., and Munos, R. (2014).
\newblock Best-arm identification in linear bandits.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 828--836.

\bibitem[Tao et~al., 2018]{tao2018best}
Tao, C., Blanco, S., and Zhou, Y. (2018).
\newblock Best arm identification in linear bandits with linear dimension
  dependency.
\newblock In {\em International Conference on Machine Learning}, pages
  4877--4886. PMLR.

\bibitem[Tropp, 2012]{tropp2012user}
Tropp, J.~A. (2012).
\newblock User-friendly tail bounds for sums of random matrices.
\newblock {\em Foundations of computational mathematics}, 12(4):389--434.

\bibitem[Wang et~al., 2021]{wang2021provably}
Wang, T., Zhou, D., and Gu, Q. (2021).
\newblock Provably efficient reinforcement learning with linear function
  approximation under adaptivity constraints.
\newblock {\em arXiv preprint arXiv:2101.02195}.

\bibitem[Xu et~al., 2018]{xu2018fully}
Xu, L., Honda, J., and Sugiyama, M. (2018).
\newblock A fully adaptive algorithm for pure exploration in linear bandits.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 843--851. PMLR.

\bibitem[Zanette et~al., 2021]{zanette2021cautiously}
Zanette, A., Cheng, C.-A., and Agarwal, A. (2021).
\newblock Cautiously optimistic policy optimization and exploration with linear
  function approximation.
\newblock {\em arXiv preprint arXiv:2103.12923}.

\end{thebibliography}
