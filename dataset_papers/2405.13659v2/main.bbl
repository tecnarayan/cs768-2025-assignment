\begin{thebibliography}{100}

\bibitem{adolphs2003cognitive}
Ralph Adolphs.
\newblock Cognitive neuroscience of human social behaviour.
\newblock {\em Nature reviews neuroscience}, 4(3):165--178, 2003.

\bibitem{akiva2023self}
Peri Akiva, Jing Huang, Kevin~J Liang, Rama Kovvuri, Xingyu Chen, Matt Feiszli, Kristin Dana, and Tal Hassner.
\newblock Self-supervised object detection from egocentric videos.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 5225--5237, 2023.

\bibitem{gberta_2021_ICML}
Gedas Bertasius, Heng Wang, and Lorenzo Torresani.
\newblock Is space-time attention all you need for video understanding?
\newblock In {\em Proceedings of the International Conference on Machine Learning (ICML)}, July 2021.

\bibitem{cai2024smpler}
Zhongang Cai, Wanqi Yin, Ailing Zeng, Chen Wei, Qingping Sun, Wang Yanjun, Hui~En Pang, Haiyi Mei, Mingyuan Zhang, Lei Zhang, et~al.
\newblock Smpler-x: Scaling up expressive human pose and shape estimation.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{chao2018learning}
Yu-Wei Chao, Yunfan Liu, Xieyang Liu, Huayi Zeng, and Jia Deng.
\newblock Learning to detect human-object interactions.
\newblock In {\em 2018 ieee winter conference on applications of computer vision (wacv)}, pages 381--389. IEEE, 2018.

\bibitem{chen2024soundingactions}
Changan Chen, Kumar Ashutosh, Rohit Girdhar, David Harwath, and Kristen Grauman.
\newblock Soundingactions: Learning how actions sound from narrated egocentric videos.
\newblock {\em arXiv preprint arXiv:2404.05206}, 2024.

\bibitem{chen2022visual}
Changan Chen, Ruohan Gao, Paul Calamia, and Kristen Grauman.
\newblock Visual acoustic matching.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18858--18868, 2022.

\bibitem{chen2022soundspaces}
Changan Chen, Carl Schissler, Sanchit Garg, Philip Kobernik, Alexander Clegg, Paul Calamia, Dhruv Batra, Philip Robinson, and Kristen Grauman.
\newblock Soundspaces 2.0: A simulation platform for visual-acoustic learning.
\newblock {\em Advances in Neural Information Processing Systems}, 35:8896--8911, 2022.

\bibitem{chen2023detecting}
Yixin Chen, Sai~Kumar Dwivedi, Michael~J Black, and Dimitrios Tzionas.
\newblock Detecting human-object contact in images.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 17100--17110, 2023.

\bibitem{cheng2021mask2former}
Bowen Cheng, Ishan Misra, Alexander~G. Schwing, Alexander Kirillov, and Rohit Girdhar.
\newblock Masked-attention mask transformer for universal image segmentation.
\newblock 2022.

\bibitem{cheng2013affordances}
Kun-Hung Cheng and Chin-Chung Tsai.
\newblock Affordances of augmented reality in science learning: Suggestions for future research.
\newblock {\em Journal of science education and technology}, 22:449--462, 2013.

\bibitem{cuevas2024simpleego}
Hanz Cuevas-Velasquez, Charlie Hewitt, Sadegh Aliakbarian, and Tadas Baltru{\v{s}}aitis.
\newblock Simpleego: Predicting probabilistic body pose from egocentric cameras.
\newblock {\em arXiv preprint arXiv:2401.14785}, 2024.

\bibitem{Damen2021PAMI}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, and Michael Wray.
\newblock The epic-kitchens dataset: Collection, challenges and baselines.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}, 43(11):4125--4141, 2021.

\bibitem{deitke2023objaverse}
Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali Farhadi.
\newblock Objaverse: A universe of annotated 3d objects.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 13142--13153, 2023.

\bibitem{delitzas2024scenefun3d}
Alexandros Delitzas, Ayca Takmaz, Federico Tombari, Robert Sumner, Marc Pollefeys, and Francis Engelmann.
\newblock Scenefun3d: Fine-grained functionality and affordance understanding in 3d scenes.
\newblock In {\em Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)}, 2024.

\bibitem{deng20213d}
Shengheng Deng, Xun Xu, Chaozheng Wu, Ke~Chen, and Kui Jia.
\newblock 3d affordancenet: A benchmark for visual object affordance understanding.
\newblock In {\em proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 1778--1787, 2021.

\bibitem{duan2022survey}
Jiafei Duan, Samson Yu, Hui~Li Tan, Hongyuan Zhu, and Cheston Tan.
\newblock A survey of embodied ai: From simulators to research tasks.
\newblock {\em IEEE Transactions on Emerging Topics in Computational Intelligence}, 6(2):230--244, 2022.

\bibitem{fang2018demo2vec}
Kuan Fang, Te-Lin Wu, Daniel Yang, Silvio Savarese, and Joseph~J Lim.
\newblock Demo2vec: Reasoning object affordances from online videos.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 2139--2147, 2018.

\bibitem{feichtenhofer2019slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 6202--6211, 2019.

\bibitem{fu2023multimodal}
Jie Fu, Junyu Gao, Bing-Kun Bao, and Changsheng Xu.
\newblock Multimodal imbalance-aware gradient modulation for weakly-supervised audio-visual video parsing.
\newblock {\em IEEE Transactions on Circuits and Systems for Video Technology}, 2023.

\bibitem{garg2023visually}
Rishabh Garg, Ruohan Gao, and Kristen Grauman.
\newblock Visually-guided audio spatialization in video with geometry-aware multi-task learning.
\newblock {\em International Journal of Computer Vision}, 131(10):2723--2737, 2023.

\bibitem{geng2022gapartnet}
Haoran Geng, Helin Xu, Chengyang Zhao, Chao Xu, Li~Yi, Siyuan Huang, and He~Wang.
\newblock Gapartnet: Cross-category domain-generalizable object perception and manipulation via generalizable and actionable parts.
\newblock {\em arXiv preprint arXiv:2211.05272}, 2022.

\bibitem{gibbs2005embodiment}
Raymond~W Gibbs~Jr.
\newblock {\em Embodiment and cognitive science}.
\newblock Cambridge University Press, 2005.

\bibitem{gibson2014ecological}
James~J Gibson.
\newblock {\em The ecological approach to visual perception: classic edition}.
\newblock Psychology press, 2014.

\bibitem{gkioxari2018detecting}
Georgia Gkioxari, Ross Girshick, Piotr Doll{\'a}r, and Kaiming He.
\newblock Detecting and recognizing human-object interactions.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 8359--8367, 2018.

\bibitem{grauman2022ego4d}
Kristen Grauman, Andrew Westbury, Eugene Byrne, Zachary Chavis, Antonino Furnari, Rohit Girdhar, Jackson Hamburger, Hao Jiang, Miao Liu, Xingyu Liu, et~al.
\newblock Ego4d: Around the world in 3,000 hours of egocentric video.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18995--19012, 2022.

\bibitem{grauman2023ego}
Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra Malik, Triantafyllos Afouras, Kumar Ashutosh, Vijay Baiyya, Siddhant Bansal, Bikram Boote, et~al.
\newblock Ego-exo4d: Understanding skilled human activity from first-and third-person perspectives.
\newblock {\em arXiv preprint arXiv:2311.18259}, 2023.

\bibitem{hassan2021populating}
Mohamed Hassan, Partha Ghosh, Joachim Tesch, Dimitrios Tzionas, and Michael~J Black.
\newblock Populating 3d scenes by learning human-scene interaction.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14708--14718, 2021.

\bibitem{huang2022capturing}
Chun-Hao~P Huang, Hongwei Yi, Markus H{\"o}schle, Matvey Safroshkin, Tsvetelina Alexiadis, Senya Polikovsky, Daniel Scharstein, and Michael~J Black.
\newblock Capturing and inferring dense full-body human-scene contact.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 13274--13285, 2022.

\bibitem{jia2021intentonomy}
Menglin Jia, Zuxuan Wu, Austin Reiter, Claire Cardie, Serge Belongie, and Ser-Nam Lim.
\newblock Intentonomy: a dataset and study towards human intent understanding.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12986--12996, 2021.

\bibitem{jiang2024scaling}
Nan Jiang, Zhiyuan Zhang, Hongjie Li, Xiaoxuan Ma, Zan Wang, Yixin Chen, Tengyu Liu, Yixin Zhu, and Siyuan Huang.
\newblock Scaling up dynamic human-scene interaction modeling.
\newblock {\em arXiv preprint arXiv:2403.08629}, 2024.

\bibitem{kanazawa2019learning}
Angjoo Kanazawa, Jason~Y Zhang, Panna Felsen, and Jitendra Malik.
\newblock Learning 3d human dynamics from video.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 5614--5623, 2019.

\bibitem{kazakos2019epic}
Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, and Dima Damen.
\newblock Epic-fusion: Audio-visual temporal binding for egocentric action recognition.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 5492--5501, 2019.

\bibitem{kim2024zero}
Hyeonwoo Kim, Sookwan Han, Patrick Kwon, and Hanbyul Joo.
\newblock Zero-shot learning for the primitives of 3d affordance in general objects.
\newblock {\em arXiv preprint arXiv:2401.12978}, 2024.

\bibitem{kocabas2020vibe}
Muhammed Kocabas, Nikos Athanasiou, and Michael~J Black.
\newblock Vibe: Video inference for human body pose and shape estimation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 5253--5263, 2020.

\bibitem{li2024egogen}
Gen Li, Kaifeng Zhao, Siwei Zhang, Xiaozhong Lyu, Mihai Dusmanu, Yan Zhang, Marc Pollefeys, and Siyu Tang.
\newblock {EgoGen: An Egocentric Synthetic Data Generator}.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2024.

\bibitem{li2023ego}
Jiaman Li, Karen Liu, and Jiajun Wu.
\newblock Ego-body pose estimation via ego-head pose estimation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 17142--17151, 2023.

\bibitem{li2023object}
Jiaman Li, Jiajun Wu, and C~Karen Liu.
\newblock Object motion guided human motion synthesis.
\newblock {\em ACM Trans. Graph.}, 42(6), 2023.

\bibitem{li2019putting}
Xueting Li, Sifei Liu, Kihwan Kim, Xiaolong Wang, Ming-Hsuan Yang, and Jan Kautz.
\newblock Putting humans in a scene: Learning affordance in 3d indoor environments.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12368--12376, 2019.

\bibitem{lin2020ego2hands}
Fanqing Lin, Brian Price, and Tony Martinez.
\newblock Ego2hands: A dataset for egocentric two-hand segmentation and detection.
\newblock {\em arXiv preprint arXiv:2011.07252}, 2020.

\bibitem{lin2022egocentric}
Kevin~Qinghong Lin, Jinpeng Wang, Mattia Soldan, Michael Wray, Rui Yan, Eric~Z Xu, Difei Gao, Rong-Cheng Tu, Wenzhe Zhao, Weijie Kong, et~al.
\newblock Egocentric video-language pretraining.
\newblock {\em Advances in Neural Information Processing Systems}, 35:7575--7586, 2022.

\bibitem{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 2980--2988, 2017.

\bibitem{liu2022akb}
Liu Liu, Wenqiang Xu, Haoyuan Fu, Sucheng Qian, Qiaojun Yu, Yang Han, and Cewu Lu.
\newblock Akb-48: A real-world articulated object knowledge base.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14809--14818, 2022.

\bibitem{liu2022egocentric}
Miao Liu, Lingni Ma, Kiran Somasundaram, Yin Li, Kristen Grauman, James~M Rehg, and Chao Li.
\newblock Egocentric activity recognition and localization on a 3d map.
\newblock In {\em European Conference on Computer Vision}, pages 621--638. Springer, 2022.

\bibitem{lobo2008auc}
Jorge~M Lobo, Alberto Jim{\'e}nez-Valverde, and Raimundo Real.
\newblock Auc: a misleading measure of the performance of predictive distribution models.
\newblock {\em Global ecology and Biogeography}, 17(2):145--151, 2008.

\bibitem{SMPL:2015}
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael~J. Black.
\newblock {SMPL}: A skinned multi-person linear model.
\newblock {\em ACM Trans. Graphics (Proc. SIGGRAPH Asia)}, 34(6):248:1--248:16, October 2015.

\bibitem{lu2022phrase}
Liangsheng Lu, Wei Zhai, Hongchen Luo, Yu~Kang, and Yang Cao.
\newblock Phrase-based affordance detection via cyclic bilateral interaction.
\newblock {\em IEEE Transactions on Artificial Intelligence}, 2022.

\bibitem{luo2022learning}
Hongchen Luo, Wei Zhai, Jing Zhang, Yang Cao, and Dacheng Tao.
\newblock Learning affordance grounding from exocentric images.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2252--2261, 2022.

\bibitem{luo2023grounded}
Hongchen Luo, Wei Zhai, Jing Zhang, Yang Cao, and Dacheng Tao.
\newblock Grounded affordance from exocentric view.
\newblock {\em International Journal of Computer Vision}, pages 1--25, 2023.

\bibitem{luo2022embodied}
Zhengyi Luo, Shun Iwase, Ye~Yuan, and Kris Kitani.
\newblock Embodied scene-aware human pose estimation.
\newblock {\em Advances in Neural Information Processing Systems}, 35:6815--6828, 2022.

\bibitem{malle1997folk}
Bertram~F Malle and Joshua Knobe.
\newblock The folk concept of intentionality.
\newblock {\em Journal of experimental social psychology}, 33(2):101--121, 1997.

\bibitem{mandikal2021learning}
Priyanka Mandikal and Kristen Grauman.
\newblock Learning dexterous grasping with object-centric visual affordances.
\newblock In {\em 2021 IEEE international conference on robotics and automation (ICRA)}, pages 6169--6176. IEEE, 2021.

\bibitem{mascaro2023intention}
Esteve~Valls Mascar{\'o}, Hyemin Ahn, and Dongheui Lee.
\newblock Intention-conditioned long-term human egocentric action anticipation.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 6048--6057, 2023.

\bibitem{milletari2016v}
Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi.
\newblock V-net: Fully convolutional neural networks for volumetric medical image segmentation.
\newblock In {\em 2016 fourth international conference on 3D vision (3DV)}, pages 565--571. IEEE, 2016.

\bibitem{mo2021where2act}
Kaichun Mo, Leonidas~J Guibas, Mustafa Mukadam, Abhinav Gupta, and Shubham Tulsiani.
\newblock Where2act: From pixels to actions for articulated 3d objects.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 6813--6823, 2021.

\bibitem{mo2022o2o}
Kaichun Mo, Yuzhe Qin, Fanbo Xiang, Hao Su, and Leonidas Guibas.
\newblock O2o-afford: Annotation-free large-scale object-object affordance learning.
\newblock In {\em Conference on robot learning}, pages 1666--1677. PMLR, 2022.

\bibitem{mur2023multi}
Lorenzo Mur-Labadia, Jose~J Guerrero, and Ruben Martinez-Cantin.
\newblock Multi-label affordance mapping from egocentric vision.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 5238--5249, 2023.

\bibitem{nagarajan2019grounded}
Tushar Nagarajan, Christoph Feichtenhofer, and Kristen Grauman.
\newblock Grounded human-object interaction hotspots from video.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 8688--8697, 2019.

\bibitem{nagarajan2021shaping}
Tushar Nagarajan and Kristen Grauman.
\newblock Shaping embodied agent behavior with activity-context priors from egocentric video.
\newblock {\em Advances in Neural Information Processing Systems}, 34:29794--29805, 2021.

\bibitem{nagarajan2020ego}
Tushar Nagarajan, Yanghao Li, Christoph Feichtenhofer, and Kristen Grauman.
\newblock Ego-topo: Environment affordances from egocentric video.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 163--172, 2020.

\bibitem{nagarajan2024egoenv}
Tushar Nagarajan, Santhosh~Kumar Ramakrishnan, Ruta Desai, James Hillis, and Kristen Grauman.
\newblock Egoenv: Human-centric environment representations from egocentric video.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{nam2024joint}
Hyeongjin Nam, Daniel~Sungho Jung, Gyeongsik Moon, and Kyoung~Mu Lee.
\newblock Joint reconstruction of 3d human and object via contact-based refinement transformer.
\newblock {\em arXiv preprint arXiv:2404.04819}, 2024.

\bibitem{narasimhaswamy2020detecting}
Supreeth Narasimhaswamy, Trung Nguyen, and Minh~Hoai Nguyen.
\newblock Detecting hands and recognizing physical contact in the wild.
\newblock {\em Advances in neural information processing systems}, 33:7841--7851, 2020.

\bibitem{meshlab}
Cignoni Paolo, Muntoni Alessandro, Ranzuglia Guido, and Callieri Marco.
\newblock Meshlab.

\bibitem{peirone2024backpack}
Simone~Alberto Peirone, Francesca Pistilli, Antonio Alliegro, and Giuseppe Averta.
\newblock A backpack full of skills: Egocentric video understanding with diverse task perspectives, 2024.

\bibitem{pelz2001coordination}
Jeff Pelz, Mary Hayhoe, and Russ Loeber.
\newblock The coordination of eye, head, and hand movements in a natural task.
\newblock {\em Experimental brain research}, 139:266--277, 2001.

\bibitem{peng2022balanced}
Xiaokang Peng, Yake Wei, Andong Deng, Dong Wang, and Di~Hu.
\newblock Balanced multimodal learning via on-the-fly gradient modulation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 8238--8247, 2022.

\bibitem{rahman2016optimizing}
Md~Atiqur Rahman and Yang Wang.
\newblock Optimizing intersection-over-union in deep neural networks for image segmentation.
\newblock In {\em International symposium on visual computing}, pages 234--244. Springer, 2016.

\bibitem{ren2024grounded}
Tianhe Ren, Shilong Liu, Ailing Zeng, Jing Lin, Kunchang Li, He~Cao, Jiayu Chen, Xinyu Huang, Yukang Chen, Feng Yan, et~al.
\newblock Grounded sam: Assembling open-world models for diverse visual tasks.
\newblock {\em arXiv preprint arXiv:2401.14159}, 2024.

\bibitem{roy2024interaction}
Debaditya Roy, Ramanathan Rajendiran, and Basura Fernando.
\newblock Interaction region visual transformer for egocentric action anticipation.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 6740--6750, 2024.

\bibitem{savva2019habitat}
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et~al.
\newblock Habitat: A platform for embodied ai research.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 9339--9347, 2019.

\bibitem{schilder2013image}
Paul Schilder.
\newblock {\em The image and appearance of the human body}.
\newblock Routledge, 2013.

\bibitem{shao2023action}
Jiayi Shao, Xiaohan Wang, Ruijie Quan, and Yi~Yang.
\newblock Action sensitivity learning for the ego4d episodic memory challenge 2023.
\newblock {\em arXiv preprint arXiv:2306.09172}, 2023.

\bibitem{shimada2022hulc}
Soshi Shimada, Vladislav Golyanik, Zhi Li, Patrick P{\'e}rez, Weipeng Xu, and Christian Theobalt.
\newblock Hulc: 3d human motion capture with pose manifold sampling and dense contact guidance.
\newblock In {\em European Conference on Computer Vision}, pages 516--533. Springer, 2022.

\bibitem{slade1994body}
Peter~David Slade.
\newblock What is body image?
\newblock {\em Behaviour research and therapy}, 1994.

\bibitem{somayazulu2024self}
Arjun Somayazulu, Changan Chen, and Kristen Grauman.
\newblock Self-supervised visual acoustic matching.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{sudhakaran2019lsta}
Swathikiran Sudhakaran, Sergio Escalera, and Oswald Lanz.
\newblock Lsta: Long short-term attention for egocentric action recognition.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 9954--9963, 2019.

\bibitem{swain1991color}
Michael~J Swain and Dana~H Ballard.
\newblock Color indexing.
\newblock {\em International journal of computer vision}, 7(1):11--32, 1991.

\bibitem{tan2023egodistill}
Shuhan Tan, Tushar Nagarajan, and Kristen Grauman.
\newblock Egodistill: Egocentric head motion distillation for efficient video understanding.
\newblock {\em Advances in Neural Information Processing Systems}, 36:33485--33498, 2023.

\bibitem{tripathi2023deco}
Shashank Tripathi, Agniv Chatterjee, Jean-Claude Passy, Hongwei Yi, Dimitrios Tzionas, and Michael~J Black.
\newblock Deco: Dense estimation of 3d human-scene contact in the wild.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 8001--8013, 2023.

\bibitem{uy2019revisiting}
Mikaela~Angelina Uy, Quang-Hieu Pham, Binh-Son Hua, Thanh Nguyen, and Sai-Kit Yeung.
\newblock Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 1588--1597, 2019.

\bibitem{wan2023unidexgrasp++}
Weikang Wan, Haoran Geng, Yun Liu, Zikang Shan, Yaodong Yang, Li~Yi, and He~Wang.
\newblock Unidexgrasp++: Improving dexterous grasping policy learning via geometry-aware curriculum and iterative generalist-specialist learning.
\newblock {\em arXiv preprint arXiv:2304.00464}, 2023.

\bibitem{wang2023find}
Hongcheng Wang, Andy Guan~Hong Chen, Xiaoqi Li, Mingdong Wu, and Hao Dong.
\newblock Find what you want: Learning demand-conditioned object attribute space for demand-driven navigation.
\newblock {\em Advances in Neural Information Processing Systems}, 2023.

\bibitem{wang2023egocentric}
Jian Wang, Zhe Cao, Diogo Luvizon, Lingjie Liu, Kripasindhu Sarkar, Danhang Tang, Thabo Beeler, and Christian Theobalt.
\newblock Egocentric whole-body motion capture with fisheyevit and diffusion-based motion refinement.
\newblock {\em arXiv preprint arXiv:2311.16495}, 2023.

\bibitem{wang2020deep}
Jingdong Wang, Ke~Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et~al.
\newblock Deep high-resolution representation learning for visual recognition.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence}, 43(10):3349--3364, 2020.

\bibitem{wang2023embodiedscan}
Tai Wang, Xiaohan Mao, Chenming Zhu, Runsen Xu, Ruiyuan Lyu, Peisen Li, Xiao Chen, Wenwei Zhang, Kai Chen, Tianfan Xue, et~al.
\newblock Embodiedscan: A holistic multi-modal 3d perception suite towards embodied ai.
\newblock {\em arXiv preprint arXiv:2312.16170}, 2023.

\bibitem{wang2020makes}
Weiyao Wang, Du~Tran, and Matt Feiszli.
\newblock What makes training multi-modal classification networks hard?
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12695--12705, 2020.

\bibitem{wang2021interactive}
Xiaohan Wang, Linchao Zhu, Heng Wang, and Yi~Yang.
\newblock Interactive prototype learning for egocentric action recognition.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 8168--8177, 2021.

\bibitem{wang2022adaafford}
Yian Wang, Ruihai Wu, Kaichun Mo, Jiaqi Ke, Qingnan Fan, Leonidas~J Guibas, and Hao Dong.
\newblock Adaafford: Learning to adapt manipulation affordance for 3d articulated objects via few-shot interactions.
\newblock In {\em European conference on computer vision}, pages 90--107. Springer, 2022.

\bibitem{wang2019dynamic}
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay~E Sarma, Michael~M Bronstein, and Justin~M Solomon.
\newblock Dynamic graph cnn for learning on point clouds.
\newblock {\em ACM Transactions on Graphics (tog)}, 38(5):1--12, 2019.

\bibitem{wei2013modeling}
Ping Wei, Yibiao Zhao, Nanning Zheng, and Song-Chun Zhu.
\newblock Modeling 4d human-object interactions for event and object recognition.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 3272--3279, 2013.

\bibitem{wu2023omniobject3d}
Tong Wu, Jiarui Zhang, Xiao Fu, Yuxin Wang, Jiawei Ren, Liang Pan, Wayne Wu, Lei Yang, Jiaqi Wang, Chen Qian, et~al.
\newblock Omniobject3d: Large-vocabulary 3d object dataset for realistic perception, reconstruction and generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 803--814, 2023.

\bibitem{wu2020learning}
Yu~Wu, Linchao Zhu, Xiaohan Wang, Yi~Yang, and Fei Wu.
\newblock Learning to anticipate egocentric actions by imagination.
\newblock {\em IEEE Transactions on Image Processing}, 30:1143--1152, 2020.

\bibitem{wu20153d}
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao.
\newblock 3d shapenets: A deep representation for volumetric shapes.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 1912--1920, 2015.

\bibitem{xie2022chore}
Xianghui Xie, Bharat~Lal Bhatnagar, and Gerard Pons-Moll.
\newblock Chore: Contact, human and object reconstruction from a single rgb image.
\newblock In {\em European Conference on Computer Vision}, pages 125--145. Springer, 2022.

\bibitem{xu2022partafford}
Chao Xu, Yixin Chen, He~Wang, Song-Chun Zhu, Yixin Zhu, and Siyuan Huang.
\newblock Partafford: Part-level affordance discovery from 3d objects.
\newblock {\em arXiv preprint arXiv:2202.13519}, 2022.

\bibitem{xu2023interdiff}
Sirui Xu, Zhengyuan Li, Yu-Xiong Wang, and Liang-Yan Gui.
\newblock Interdiff: Generating 3d human-object interactions with physics-informed diffusion.
\newblock In {\em ICCV}, 2023.

\bibitem{xue2023learning}
Zihui Xue, Kumar Ashutosh, and Kristen Grauman.
\newblock Learning object state changes in videos: An open-world perspective.
\newblock {\em arXiv preprint arXiv:2312.11782}, 2023.

\bibitem{xue2023egocentric}
Zihui Xue, Yale Song, Kristen Grauman, and Lorenzo Torresani.
\newblock Egocentric video task translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2310--2320, 2023.

\bibitem{yang2021cpf}
Lixin Yang, Xinyu Zhan, Kailin Li, Wenqiang Xu, Jiefeng Li, and Cewu Lu.
\newblock Cpf: Learning a contact potential field to model the hand-object interaction.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 11097--11106, 2021.

\bibitem{yang2023grounding}
Yuhang Yang, Wei Zhai, Hongchen Luo, Yang Cao, Jiebo Luo, and Zheng-Jun Zha.
\newblock Grounding 3d object affordance from 2d interactions in images.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10905--10915, 2023.

\bibitem{yang2024lemon}
Yuhang Yang, Wei Zhai, Hongchen Luo, Yang Cao, and Zheng-Jun Zha.
\newblock Lemon: Learning 3d human-object interaction relation from 2d images.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 16284--16295, 2024.

\bibitem{yao2010modeling}
Bangpeng Yao and Li~Fei-Fei.
\newblock Modeling mutual context of object and human pose in human-object interaction activities.
\newblock In {\em 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, pages 17--24. IEEE, 2010.

\bibitem{yu2023fine}
Zecheng Yu, Yifei Huang, Ryosuke Furuta, Takuma Yagi, Yusuke Goutsu, and Yoichi Sato.
\newblock Fine-grained affordance annotation for egocentric hand-object interaction videos.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 2155--2163, 2023.

\bibitem{zeng2024unimd}
Yingsen Zeng, Yujie Zhong, Chengjian Feng, and Lin Ma.
\newblock Unimd: Towards unifying moment retrieval and temporal action detection.
\newblock {\em arXiv preprint arXiv:2404.04933}, 2024.

\bibitem{zhai2022one}
Wei Zhai, Hongchen Luo, Jing Zhang, Yang Cao, and Dacheng Tao.
\newblock One-shot object affordance detection in the wild.
\newblock {\em International Journal of Computer Vision}, 130(10):2472--2500, 2022.

\bibitem{zhang2022actionformer}
Chen-Lin Zhang, Jianxin Wu, and Yin Li.
\newblock Actionformer: Localizing moments of actions with transformers.
\newblock In {\em European Conference on Computer Vision}, pages 492--510. Springer, 2022.

\bibitem{zhang2023probabilistic}
Siwei Zhang, Qianli Ma, Yan Zhang, Sadegh Aliakbarian, Darren Cosker, and Siyu Tang.
\newblock Probabilistic human mesh recovery in 3d scenes from egocentric views.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7989--8000, 2023.

\bibitem{zhang2024bidirectional}
Zichen Zhang, Hongchen Luo, Wei Zhai, Yang Cao, and Yu~Kang.
\newblock Bidirectional progressive transformer for interaction intention anticipation.
\newblock {\em arXiv preprint arXiv:2405.05552}, 2024.

\bibitem{zhao2023synthesizing}
Kaifeng Zhao, Yan Zhang, Shaofei Wang, Thabo Beeler, and Siyu Tang.
\newblock Synthesizing diverse human motions in 3d indoor scenes.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 14738--14749, 2023.

\bibitem{zhao2022dualafford}
Yan Zhao, Ruihai Wu, Zhehuan Chen, Yourong Zhang, Qingnan Fan, Kaichun Mo, and Hao Dong.
\newblock Dualafford: Learning collaborative visual affordance for dual-gripper manipulation.
\newblock {\em arXiv preprint arXiv:2207.01971}, 2022.

\bibitem{zhao2023learning}
Yue Zhao, Ishan Misra, Philipp Kr{\"a}henb{\"u}hl, and Rohit Girdhar.
\newblock Learning video representations from large language models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6586--6597, 2023.

\bibitem{zheng2022gimo}
Yang Zheng, Yanchao Yang, Kaichun Mo, Jiaman Li, Tao Yu, Yebin Liu, C~Karen Liu, and Leonidas~J Guibas.
\newblock Gimo: Gaze-informed human motion prediction in context.
\newblock In {\em European Conference on Computer Vision}, pages 676--694. Springer, 2022.

\bibitem{zhu2023egoobjects}
Chenchen Zhu, Fanyi Xiao, Andr{\'e}s Alvarado, Yasmine Babaei, Jiabo Hu, Hichem El-Mohri, Sean Culatana, Roshan Sumbaly, and Zhicheng Yan.
\newblock Egoobjects: A large-scale egocentric dataset for fine-grained object understanding.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 20110--20120, 2023.

\bibitem{zhu2023diff}
Xinghao Zhu, JingHan Ke, Zhixuan Xu, Zhixin Sun, Bizhe Bai, Jun Lv, Qingtao Liu, Yuwei Zeng, Qi~Ye, Cewu Lu, et~al.
\newblock Diff-lfd: Contact-aware model-based learning from visual demonstration for robotic manipulation via differentiable physics-based simulation and rendering.
\newblock In {\em Conference on Robot Learning}, pages 499--512. PMLR, 2023.

\end{thebibliography}
