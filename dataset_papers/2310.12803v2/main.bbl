\begin{thebibliography}{99}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Zech et~al.(2018)Zech, Badgeley, Liu, Costa, Titano, and
  Oermann]{zech2018variable}
John~R Zech, Marcus~A Badgeley, Manway Liu, Anthony~B Costa, Joseph~J Titano,
  and Eric~Karl Oermann.
\newblock Variable generalization performance of a deep learning model to
  detect pneumonia in chest radiographs: a cross-sectional study.
\newblock \emph{PLoS medicine}, 15\penalty0 (11):\penalty0 e1002683, 2018.

\bibitem[DeGrave et~al.(2021)DeGrave, Janizek, and Lee]{degrave2021ai}
Alex~J DeGrave, Joseph~D Janizek, and Su-In Lee.
\newblock Ai for radiographic covid-19 detection selects shortcuts over signal.
\newblock \emph{Nature Machine Intelligence}, 3\penalty0 (7):\penalty0
  610--619, 2021.

\bibitem[McCoy et~al.(2019)McCoy, Pavlick, and Linzen]{mccoy2019right}
R~Thomas McCoy, Ellie Pavlick, and Tal Linzen.
\newblock Right for the wrong reasons: Diagnosing syntactic heuristics in
  natural language inference.
\newblock \emph{arXiv preprint arXiv:1902.01007}, 2019.

\bibitem[Caruana et~al.(2015)Caruana, Lou, Gehrke, Koch, Sturm, and
  Elhadad]{caruana2015intelligible}
Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie
  Elhadad.
\newblock Intelligible models for healthcare: Predicting pneumonia risk and
  hospital 30-day readmission.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1721--1730, 2015.

\bibitem[Quinonero-Candela et~al.(2008)Quinonero-Candela, Sugiyama,
  Schwaighofer, and Lawrence]{quinonero2008dataset}
Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil~D
  Lawrence.
\newblock \emph{Dataset shift in machine learning}.
\newblock Mit Press, 2008.

\bibitem[Subbaswamy et~al.(2019)Subbaswamy, Schulam, and
  Saria]{subbaswamy2019preventing}
Adarsh Subbaswamy, Peter Schulam, and Suchi Saria.
\newblock Preventing failures due to dataset shift: Learning predictive models
  that transport.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3118--3127. PMLR, 2019.

\bibitem[Finlayson et~al.(2021)Finlayson, Subbaswamy, Singh, Bowers, Kupke,
  Zittrain, Kohane, and Saria]{finlayson2021clinician}
Samuel~G Finlayson, Adarsh Subbaswamy, Karandeep Singh, John Bowers, Annabel
  Kupke, Jonathan Zittrain, Isaac~S Kohane, and Suchi Saria.
\newblock The clinician and dataset shift in artificial intelligence.
\newblock \emph{New England Journal of Medicine}, 385\penalty0 (3):\penalty0
  283--286, 2021.

\bibitem[Spyns(1996)]{spyns1996natural}
Peter Spyns.
\newblock Natural language processing in medicine: an overview.
\newblock \emph{Methods of information in medicine}, 35\penalty0
  (04/05):\penalty0 285--301, 1996.

\bibitem[Zhou and Hripcsak(2007)]{zhou2007temporal}
Li~Zhou and George Hripcsak.
\newblock Temporal reasoning with medical data—a review with emphasis on
  medical natural language processing.
\newblock \emph{Journal of biomedical informatics}, 40\penalty0 (2):\penalty0
  183--202, 2007.

\bibitem[Wu et~al.(2020)Wu, Roberts, Datta, Du, Ji, Si, Soni, Wang, Wei, Xiang,
  et~al.]{wu2020deep}
Stephen Wu, Kirk Roberts, Surabhi Datta, Jingcheng Du, Zongcheng Ji, Yuqi Si,
  Sarvesh Soni, Qiong Wang, Qiang Wei, Yang Xiang, et~al.
\newblock Deep learning in clinical natural language processing: a methodical
  review.
\newblock \emph{Journal of the American Medical Informatics Association},
  27\penalty0 (3):\penalty0 457--470, 2020.

\bibitem[Peters et~al.(2016)Peters, B{\"u}hlmann, and
  Meinshausen]{peters2016causal}
Jonas Peters, Peter B{\"u}hlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 2016.

\bibitem[Magliacane et~al.(2018)Magliacane, van Ommen, Claassen, Bongers,
  Versteeg, and Mooij]{magliacane2018domain}
Sara Magliacane, Thijs van Ommen, Tom Claassen, Stephan Bongers, Philip
  Versteeg, and Joris~M Mooij.
\newblock Domain adaptation by using causal inference to predict invariant
  conditional distributions.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, pages
  10869--10879, 2018.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Subbaswamy et~al.(2022)Subbaswamy, Chen, and
  Saria]{subbaswamy2022unifying}
Adarsh Subbaswamy, Bryant Chen, and Suchi Saria.
\newblock A unifying causal framework for analyzing dataset shift-stable
  learning algorithms.
\newblock \emph{Journal of Causal Inference}, 10\penalty0 (1):\penalty0 64--89,
  2022.

\bibitem[Robey et~al.(2021)Robey, Pappas, and Hassani]{robey2021modelbased}
Alexander Robey, George~J. Pappas, and Hamed Hassani.
\newblock Model-based domain generalization.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan,
  editors, \emph{Neural Information Processing Systems (NeurIPS)}, 2021.
\newblock URL \url{https://openreview.net/forum?id=JOxB9h40A-1}.

\bibitem[Yao et~al.(2022)Yao, Wang, Li, Zhang, Liang, Zou, and
  Finn]{yao2022improving}
Huaxiu Yao, Yu~Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, and Chelsea
  Finn.
\newblock Improving out-of-distribution robustness via selective augmentation.
\newblock In \emph{International Conference on Machine Learning}, pages
  25407--25437. PMLR, 2022.

\bibitem[Gao et~al.(2023)Gao, Sagawa, Koh, Hashimoto, and Liang]{gao2023out}
Irena Gao, Shiori Sagawa, Pang~Wei Koh, Tatsunori Hashimoto, and Percy Liang.
\newblock Out-of-domain robustness via targeted augmentations.
\newblock \emph{arXiv preprint arXiv:2302.11861}, 2023.

\bibitem[Kocaoglu et~al.(2018)Kocaoglu, Snyder, Dimakis, and
  Vishwanath]{kocaoglu2018causalgan}
Murat Kocaoglu, Christopher Snyder, Alexandros~G. Dimakis, and Sriram
  Vishwanath.
\newblock Causal{GAN}: Learning causal implicit generative models with
  adversarial training.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=BJE-4xW0W}.

\bibitem[Abadie(2005)]{abadie2005semiparametric}
Alberto Abadie.
\newblock Semiparametric difference-in-differences estimators.
\newblock \emph{The review of economic studies}, 72\penalty0 (1):\penalty0
  1--19, 2005.

\bibitem[Heinze-Deml et~al.(2018)Heinze-Deml, Peters, and
  Meinshausen]{heinze2018invariant}
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen.
\newblock Invariant causal prediction for nonlinear models.
\newblock \emph{Journal of Causal Inference}, 6\penalty0 (2), 2018.

\bibitem[Li et~al.(2018)Li, Tian, Gong, Liu, Liu, Zhang, and Tao]{li2018deep}
Ya~Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and
  Dacheng Tao.
\newblock Deep domain generalization via conditional invariant adversarial
  networks.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pages 624--639, 2018.

\bibitem[Wald et~al.(2021)Wald, Feder, Greenfeld, and
  Shalit]{wald2021calibration}
Yoav Wald, Amir Feder, Daniel Greenfeld, and Uri Shalit.
\newblock On calibration and out-of-domain generalization.
\newblock \emph{Neural Information Processing Systems (NeurIPS)}, 34:\penalty0
  2215--2227, 2021.

\bibitem[Krueger et~al.(2021)Krueger, Caballero, Jacobsen, Zhang, Binas, Zhang,
  Le~Priol, and Courville]{krueger2021out}
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan
  Binas, Dinghuai Zhang, Remi Le~Priol, and Aaron Courville.
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock In \emph{International Conference on Machine Learning}, pages
  5815--5826. PMLR, 2021.

\bibitem[Puli et~al.(2022{\natexlab{a}})Puli, Zhang, Oermann, and
  Ranganath]{puli2022outofdistribution}
Aahlad~Manas Puli, Lily~H Zhang, Eric~Karl Oermann, and Rajesh Ranganath.
\newblock Out-of-distribution generalization in the presence of
  nuisance-induced spurious correlations.
\newblock In \emph{International Conference on Learning Representations},
  2022{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=12RoR2o32T}.

\bibitem[Makar et~al.(2022)Makar, Packer, Moldovan, Blalock, Halpern, and
  D’Amour]{makar2022causally}
Maggie Makar, Ben Packer, Dan Moldovan, Davis Blalock, Yoni Halpern, and
  Alexander D’Amour.
\newblock Causally motivated shortcut removal using auxiliary labels.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 739--766. PMLR, 2022.

\bibitem[Jiang and Veitch(2022)]{jiang2022invariant}
Yibo Jiang and Victor Veitch.
\newblock Invariant and transportable representations for anti-causal domain
  shifts.
\newblock \emph{arXiv preprint arXiv:2207.01603}, 2022.

\bibitem[Shi et~al.(2021)Shi, Veitch, and Blei]{shi2021invariant}
Claudia Shi, Victor Veitch, and David~M Blei.
\newblock Invariant representation learning for treatment effect estimation.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 1546--1555.
  PMLR, 2021.

\bibitem[Yin et~al.(2021)Yin, Wang, and Blei]{yin2021optimization}
Mingzhang Yin, Yixin Wang, and David~M Blei.
\newblock Optimization-based causal estimation from heterogenous environments.
\newblock \emph{arXiv preprint arXiv:2109.11990}, 2021.

\bibitem[Veitch et~al.(2021)Veitch, D'Amour, Yadlowsky, and
  Eisenstein]{veitch2021counterfactual}
Victor Veitch, Alexander D'Amour, Steve Yadlowsky, and Jacob Eisenstein.
\newblock Counterfactual invariance to spurious correlations in text
  classification.
\newblock \emph{Neural Information Processing Systems (NeurIPS)}, 34:\penalty0
  16196--16208, 2021.

\bibitem[Dranker et~al.(2021)Dranker, He, and Belinkov]{dranker2021irm}
Yana Dranker, He~He, and Yonatan Belinkov.
\newblock Irm—when it works and when it doesn't: A test case of natural
  language inference.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 18212--18224, 2021.

\bibitem[Feder et~al.(2022{\natexlab{a}})Feder, Keith, Manzoor, Pryzant,
  Sridhar, Wood-Doughty, Eisenstein, Grimmer, Reichart, Roberts,
  et~al.]{feder2021causal}
Amir Feder, Katherine~A Keith, Emaad Manzoor, Reid Pryzant, Dhanya Sridhar,
  Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart, Margaret~E
  Roberts, et~al.
\newblock Causal inference in natural language processing: Estimation,
  prediction, interpretation and beyond.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  10:\penalty0 1138--1158, 2022{\natexlab{a}}.

\bibitem[Feder et~al.(2022{\natexlab{b}})Feder, Horowitz, Wald, Reichart, and
  Rosenfeld]{feder2022eye}
Amir Feder, Guy Horowitz, Yoav Wald, Roi Reichart, and Nir Rosenfeld.
\newblock In the eye of the beholder: Robust prediction with causal user
  modeling.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)},
  2022{\natexlab{b}}.

\bibitem[Kamath et~al.(2021)Kamath, Tangella, Sutherland, and
  Srebro]{kamath2021does}
Pritish Kamath, Akilesh Tangella, Danica Sutherland, and Nathan Srebro.
\newblock Does invariant risk minimization capture invariance?
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 4069--4077. PMLR, 2021.

\bibitem[Rosenfeld et~al.(2020)Rosenfeld, Ravikumar, and
  Risteski]{rosenfeld2020risks}
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski.
\newblock The risks of invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:2010.05761}, 2020.

\bibitem[Guo et~al.(2021)Guo, Zhang, Liu, and Kiciman]{guo2021out}
Ruocheng Guo, Pengchuan Zhang, Hao Liu, and Emre Kiciman.
\newblock Out-of-distribution prediction with invariant risk minimization: The
  limitation and an effective fix.
\newblock \emph{arXiv preprint arXiv:2101.07732}, 2021.

\bibitem[Wald et~al.(2022)Wald, Yona, Shalit, and Carmon]{wald2022malign}
Yoav Wald, Gal Yona, Uri Shalit, and Yair Carmon.
\newblock Malign overfitting: Interpolation can provably preclude invariance.
\newblock \emph{arXiv preprint arXiv:2211.15724}, 2022.

\bibitem[Kaushik et~al.(2019)Kaushik, Hovy, and Lipton]{kaushik2019learning}
Divyansh Kaushik, Eduard Hovy, and Zachary~C Lipton.
\newblock Learning the difference that makes a difference with
  counterfactually-augmented data.
\newblock \emph{arXiv preprint arXiv:1909.12434}, 2019.

\bibitem[Kaushik et~al.(2020)Kaushik, Setlur, Hovy, and
  Lipton]{kaushik2020explaining}
Divyansh Kaushik, Amrith Setlur, Eduard Hovy, and Zachary~C Lipton.
\newblock Explaining the efficacy of counterfactually-augmented data.
\newblock \emph{arXiv preprint arXiv:2010.02114}, 2020.

\bibitem[Garg et~al.(2019)Garg, Perot, Limtiaco, Taly, Chi, and
  Beutel]{garg2019counterfactual}
Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur Taly, Ed~H Chi, and Alex
  Beutel.
\newblock Counterfactual fairness in text classification through robustness.
\newblock In \emph{Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 219--226, 2019.

\bibitem[Jha et~al.(2020)Jha, Lovering, and Pavlick]{jha2020does}
Rohan Jha, Charles Lovering, and Ellie Pavlick.
\newblock Does data augmentation improve generalization in nlp?
\newblock \emph{arXiv preprint arXiv:2004.15012}, 2020.

\bibitem[Gardner et~al.(2020)Gardner, Artzi, Basmov, Berant, Bogin, Chen,
  Dasigi, Dua, Elazar, Gottumukkala, Gupta, Hajishirzi, Ilharco, Khashabi, Lin,
  Liu, Liu, Mulcaire, Ning, Singh, Smith, Subramanian, Tsarfaty, Wallace,
  Zhang, and Zhou]{gardner-etal-2020-evaluating}
Matt Gardner, Yoav Artzi, Victoria Basmov, Jonathan Berant, Ben Bogin, Sihao
  Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, Nitish
  Gupta, Hannaneh Hajishirzi, Gabriel Ilharco, Daniel Khashabi, Kevin Lin,
  Jiangming Liu, Nelson~F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer Singh,
  Noah~A. Smith, Sanjay Subramanian, Reut Tsarfaty, Eric Wallace, Ally Zhang,
  and Ben Zhou.
\newblock Evaluating models{'} local decision boundaries via contrast sets.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2020}, pages 1307--1323, Online, November 2020. Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/2020.findings-emnlp.117}.
\newblock URL \url{https://aclanthology.org/2020.findings-emnlp.117}.

\bibitem[Shekhar et~al.(2017)Shekhar, Pezzelle, Klimovich, Herbelot, Nabi,
  Sangineto, and Bernardi]{shekhar-etal-2017-foil}
Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aur{\'e}lie Herbelot, Moin
  Nabi, Enver Sangineto, and Raffaella Bernardi.
\newblock {FOIL} it! find one mismatch between image and language caption.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 255--265,
  Vancouver, Canada, July 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P17-1024}.
\newblock URL \url{https://aclanthology.org/P17-1024}.

\bibitem[Feder et~al.(2021)Feder, Oved, Shalit, and Reichart]{feder2021causalm}
Amir Feder, Nadav Oved, Uri Shalit, and Roi Reichart.
\newblock Causalm: Causal model explanation through counterfactual language
  models.
\newblock \emph{Computational Linguistics}, 47\penalty0 (2):\penalty0 333--386,
  2021.

\bibitem[Zmigrod et~al.(2019)Zmigrod, Mielke, Wallach, and
  Cotterell]{zmigrod-etal-2019-counterfactual}
Ran Zmigrod, Sabrina~J. Mielke, Hanna Wallach, and Ryan Cotterell.
\newblock Counterfactual data augmentation for mitigating gender stereotypes in
  languages with rich morphology.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 1651--1661, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1161}.
\newblock URL \url{https://aclanthology.org/P19-1161}.

\bibitem[Riley et~al.(2020)Riley, Constant, Guo, Kumar, Uthus, and
  Parekh]{riley2020textsettr}
Parker Riley, Noah Constant, Mandy Guo, Girish Kumar, David Uthus, and Zarana
  Parekh.
\newblock Textsettr: Label-free text style extraction and tunable targeted
  restyling.
\newblock \emph{arXiv preprint arXiv:2010.03802}, 2020.

\bibitem[Wu et~al.(2021)Wu, Ribeiro, Heer, and Weld]{wu2021polyjuice}
Tongshuang Wu, Marco~Tulio Ribeiro, Jeffrey Heer, and Daniel~S Weld.
\newblock Polyjuice: Automated, general-purpose counterfactual generation.
\newblock \emph{arXiv preprint arXiv:2101.00288}, 2021.

\bibitem[Mao et~al.(2021)Mao, Cha, Gupta, Wang, Yang, and
  Vondrick]{mao2021generative}
Chengzhi Mao, Augustine Cha, Amogh Gupta, Hao Wang, Junfeng Yang, and Carl
  Vondrick.
\newblock Generative interventions for causal learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3947--3956, 2021.

\bibitem[Rosenberg et~al.(2021)Rosenberg, Gat, Feder, and
  Reichart]{rosenberg2021vqa}
Daniel Rosenberg, Itai Gat, Amir Feder, and Roi Reichart.
\newblock Are vqa systems rad? measuring robustness to augmented data with
  focused interventions.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 2: Short Papers)}, pages 61--70, 2021.

\bibitem[Abraham et~al.(2022)Abraham, D'Oosterlinck, Feder, Gat, Geiger, Potts,
  Reichart, and Wu]{abraham2022cebab}
Eldar~D Abraham, Karel D'Oosterlinck, Amir Feder, Yair Gat, Atticus Geiger,
  Christopher Potts, Roi Reichart, and Zhengxuan Wu.
\newblock {CEB}a{B}: Estimating the causal effects of real-world concepts on
  {NLP} model behavior.
\newblock \emph{Neural Information Processing Systems (NeurIPS)}, 35:\penalty0
  17582--17596, 2022.

\bibitem[Wu et~al.(2023)Wu, D’Oosterlinck, Geiger, Zur, and
  Potts]{wu2023causal}
Zhengxuan Wu, Karel D’Oosterlinck, Atticus Geiger, Amir Zur, and Christopher
  Potts.
\newblock Causal proxy models for concept-based model explanations.
\newblock In \emph{International Conference on Machine Learning}, pages
  37313--37334. PMLR, 2023.

\bibitem[Joshi and He(2022)]{joshi2022investigation}
Nitish Joshi and He~He.
\newblock An investigation of the (in) effectiveness of counterfactually
  augmented data.
\newblock In \emph{60th Annual Meeting of the Association for Computational
  Linguistics, ACL 2022}, pages 3668--3681. Association for Computational
  Linguistics (ACL), 2022.

\bibitem[Antoniak and Mimno(2021)]{antoniak-mimno-2021-bad}
Maria Antoniak and David Mimno.
\newblock Bad seeds: Evaluating lexical methods for bias measurement.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pages 1889--1904,
  Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.148}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.148}.

\bibitem[Zhou and Wu(2023)]{zhou2023implicit}
Xiaoling Zhou and Ou~Wu.
\newblock Implicit counterfactual data augmentation for deep neural networks.
\newblock \emph{arXiv preprint arXiv:2304.13431}, 2023.

\bibitem[Calderon et~al.(2022)Calderon, Ben-David, Feder, and
  Reichart]{Calderon:22}
Nitay Calderon, Eyal Ben-David, Amir Feder, and Roi Reichart.
\newblock Do{C}o{G}en: {D}omain {C}ounterfactual {G}eneration for {L}ow
  {R}esource {D}omain {A}daptation.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association of
  Computational Linguistics (ACL)}, 2022.

\bibitem[Kreimeyer et~al.(2017)Kreimeyer, Foster, Pandey, Arya, Halford, Jones,
  Forshee, Walderhaug, and Botsis]{kreimeyer2017natural}
Kory Kreimeyer, Matthew Foster, Abhishek Pandey, Nina Arya, Gwendolyn Halford,
  Sandra~F Jones, Richard Forshee, Mark Walderhaug, and Taxiarchis Botsis.
\newblock Natural language processing systems for capturing and standardizing
  unstructured clinical information: a systematic review.
\newblock \emph{Journal of biomedical informatics}, 73:\penalty0 14--29, 2017.

\bibitem[Uzuner(2009)]{uzuner2009recognizing}
{\"O}zlem Uzuner.
\newblock Recognizing obesity and comorbidities in sparse data.
\newblock \emph{Journal of the American Medical Informatics Association},
  16\penalty0 (4):\penalty0 561--570, 2009.

\bibitem[Savova et~al.(2010)Savova, Masanz, Ogren, Zheng, Sohn, Kipper-Schuler,
  and Chute]{savova2010mayo}
Guergana~K Savova, James~J Masanz, Philip~V Ogren, Jiaping Zheng, Sunghwan
  Sohn, Karin~C Kipper-Schuler, and Christopher~G Chute.
\newblock Mayo clinical text analysis and knowledge extraction system (ctakes):
  architecture, component evaluation and applications.
\newblock \emph{Journal of the American Medical Informatics Association},
  17\penalty0 (5):\penalty0 507--513, 2010.

\bibitem[Jensen et~al.(2012)Jensen, Jensen, and Brunak]{jensen2012mining}
Peter~B Jensen, Lars~J Jensen, and S{\o}ren Brunak.
\newblock Mining electronic health records: towards better research
  applications and clinical care.
\newblock \emph{Nature Reviews Genetics}, 13\penalty0 (6):\penalty0 395--405,
  2012.

\bibitem[Ford et~al.(2016)Ford, Carroll, Smith, Scott, and
  Cassell]{ford2016extracting}
Elizabeth Ford, John~A Carroll, Helen~E Smith, Donia Scott, and Jackie~A
  Cassell.
\newblock Extracting information from the text of electronic medical records to
  improve case detection: a systematic review.
\newblock \emph{Journal of the American Medical Informatics Association},
  23\penalty0 (5):\penalty0 1007--1015, 2016.

\bibitem[Zhu et~al.(2018)Zhu, Paschalidis, and Tahmasebi]{zhu2018clinical}
Henghui Zhu, Ioannis~Ch Paschalidis, and Amir Tahmasebi.
\newblock Clinical concept extraction with contextual word embedding.
\newblock \emph{arXiv preprint arXiv:1810.10566}, 2018.

\bibitem[Peng et~al.(2019)Peng, Yan, and Lu]{peng2019transfer}
Yifan Peng, Shankai Yan, and Zhiyong Lu.
\newblock Transfer learning in biomedical natural language processing: an
  evaluation of bert and elmo on ten benchmarking datasets.
\newblock \emph{arXiv preprint arXiv:1906.05474}, 2019.

\bibitem[Yadav and Bethard(2019)]{yadav2019survey}
Vikas Yadav and Steven Bethard.
\newblock A survey on recent advances in named entity recognition from deep
  learning models.
\newblock \emph{arXiv preprint arXiv:1910.11470}, 2019.

\bibitem[Si et~al.(2019)Si, Wang, Xu, and Roberts]{si2019enhancing}
Yuqi Si, Jingqi Wang, Hua Xu, and Kirk Roberts.
\newblock Enhancing clinical concept extraction with contextual embeddings.
\newblock \emph{Journal of the American Medical Informatics Association},
  26\penalty0 (11):\penalty0 1297--1304, 2019.

\bibitem[Lee et~al.(2020)Lee, Yoon, Kim, Kim, Kim, So, and
  Kang]{lee2020biobert}
Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan~Ho So,
  and Jaewoo Kang.
\newblock Bio{BERT}: a pre-trained biomedical language representation model for
  biomedical text mining.
\newblock \emph{Bioinformatics}, 36\penalty0 (4):\penalty0 1234--1240, 2020.

\bibitem[Roussinov et~al.(2022)Roussinov, Conkie, Patterson, and
  Sainsbury]{roussinov2022predicting}
Dmitri Roussinov, Andrew Conkie, Andrew Patterson, and Christopher Sainsbury.
\newblock Predicting clinical events based on raw text: from bag-of-words to
  attention-based transformers.
\newblock \emph{Frontiers in Digital Health}, 3:\penalty0 214, 2022.

\bibitem[Seinen et~al.(2022)Seinen, Fridgeirsson, Ioannou, Jeannetot, John,
  Kors, Markus, Pera, Rekkas, Williams, et~al.]{seinen2022use}
Tom~M Seinen, Egill~A Fridgeirsson, Solomon Ioannou, Daniel Jeannetot, Luis~H
  John, Jan~A Kors, Aniek~F Markus, Victor Pera, Alexandros Rekkas, Ross~D
  Williams, et~al.
\newblock Use of unstructured text in prognostic clinical prediction models: a
  systematic review.
\newblock \emph{Journal of the American Medical Informatics Association},
  29\penalty0 (7):\penalty0 1292--1302, 2022.

\bibitem[Singhal et~al.(2022)Singhal, Azizi, Tu, Mahdavi, Wei, Chung, Scales,
  Tanwani, Cole-Lewis, Pfohl, et~al.]{singhal2022large}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S~Sara Mahdavi, Jason Wei, Hyung~Won
  Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et~al.
\newblock Large language models encode clinical knowledge.
\newblock \emph{arXiv preprint arXiv:2212.13138}, 2022.

\bibitem[Ayers et~al.(2023)Ayers, Poliak, Dredze, Leas, Zhu, Kelley, Faix,
  Goodman, Longhurst, Hogarth, et~al.]{ayers2023comparing}
John~W Ayers, Adam Poliak, Mark Dredze, Eric~C Leas, Zechariah Zhu, Jessica~B
  Kelley, Dennis~J Faix, Aaron~M Goodman, Christopher~A Longhurst, Michael
  Hogarth, et~al.
\newblock Comparing physician and artificial intelligence chatbot responses to
  patient questions posted to a public social media forum.
\newblock \emph{JAMA Internal Medicine}, 2023.

\bibitem[Feder et~al.(2022{\natexlab{c}})Feder, Laish, Agarwal, Lerner, Atias,
  Cheung, Clardy, Peled-Cohen, Fellinger, Liu, et~al.]{feder2022building}
Amir Feder, Itay Laish, Shashank Agarwal, Uri Lerner, Avel Atias, Cathy Cheung,
  Peter Clardy, Alon Peled-Cohen, Rachana Fellinger, Hengrui Liu, et~al.
\newblock Building a clinically-focused problem list from medical notes.
\newblock In \emph{Proceedings of the 13th International Workshop on Health
  Text Mining and Information Analysis (LOUHI)}, pages 60--68,
  2022{\natexlab{c}}.

\bibitem[Zhang et~al.(2022)Zhang, Laish, Benjamini, and
  Feder]{zhang2022section}
Fan Zhang, Itay Laish, Ayelet Benjamini, and Amir Feder.
\newblock Section classification in clinical notes with multi-task
  transformers.
\newblock In \emph{Proceedings of the 13th International Workshop on Health
  Text Mining and Information Analysis (LOUHI)}, pages 54--59, 2022.

\bibitem[Feder et~al.(2020)Feder, Vainstein, Rosenfeld, Hartman, Hassidim, and
  Matias]{feder2020active}
Amir Feder, Danny Vainstein, Roni Rosenfeld, Tzvika Hartman, Avinatan Hassidim,
  and Yossi Matias.
\newblock Active deep learning to detect demographic traits in free-form
  clinical notes.
\newblock \emph{Journal of Biomedical Informatics}, 107:\penalty0 103436, 2020.

\bibitem[Wang and Veitch(2022)]{wang2022unified}
Zihao Wang and Victor Veitch.
\newblock A unified causal view of domain invariant representation learning.
\newblock \emph{arXiv preprint arXiv:2208.06987}, 2022.

\bibitem[Imbens and Wooldridge(2009)]{imbens2009recent}
Guido~W Imbens and Jeffrey~M Wooldridge.
\newblock Recent developments in the econometrics of program evaluation.
\newblock \emph{Journal of economic literature}, 47\penalty0 (1):\penalty0
  5--86, 2009.

\bibitem[Pearl(2009)]{pearl2009causality}
Judea Pearl.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem[Shalit et~al.(2017)Shalit, Johansson, and
  Sontag]{shalit2017estimating}
Uri Shalit, Fredrik~D Johansson, and David Sontag.
\newblock Estimating individual treatment effect: generalization bounds and
  algorithms.
\newblock In \emph{International conference on machine learning}, pages
  3076--3085. PMLR, 2017.

\bibitem[Rosenbaum and Rubin(1983)]{rosenbaum1983central}
Paul~R Rosenbaum and Donald~B Rubin.
\newblock The central role of the propensity score in observational studies for
  causal effects.
\newblock \emph{Biometrika}, 70\penalty0 (1):\penalty0 41--55, 1983.

\bibitem[Imbens and Rubin(2015)]{imbens2015causal}
Guido~W Imbens and Donald~B Rubin.
\newblock \emph{Causal inference in statistics, social, and biomedical
  sciences}.
\newblock Cambridge University Press, 2015.

\bibitem[Card and Krueger(1993)]{card1993minimum}
David Card and Alan~B Krueger.
\newblock Minimum wages and employment: A case study of the fast food industry
  in new jersey and pennsylvania, 1993.

\bibitem[Angrist and Pischke(2009)]{angrist2009mostly}
Joshua~D Angrist and J{\"o}rn-Steffen Pischke.
\newblock \emph{Mostly harmless econometrics: An empiricist's companion}.
\newblock Princeton university press, 2009.

\bibitem[Shimodaira(2000)]{shimodaira2000improving}
Hidetoshi Shimodaira.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock \emph{Journal of statistical planning and inference}, 90\penalty0
  (2):\penalty0 227--244, 2000.

\bibitem[Cortes et~al.(2010)Cortes, Mansour, and Mohri]{NIPS2010_59c33016}
Corinna Cortes, Yishay Mansour, and Mehryar Mohri.
\newblock Learning bounds for importance weighting.
\newblock In J.~Lafferty, C.~Williams, J.~Shawe-Taylor, R.~Zemel, and
  A.~Culotta, editors, \emph{Neural Information Processing Systems (NeurIPS)},
  volume~23. Curran Associates, Inc., 2010.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79:\penalty0 151--175, 2010.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017elements}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem[Gu et~al.(2021)Gu, Tinn, Cheng, Lucas, Usuyama, Liu, Naumann, Gao, and
  Poon]{gu2021domain}
Yu~Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu,
  Tristan Naumann, Jianfeng Gao, and Hoifung Poon.
\newblock Domain-specific language model pretraining for biomedical natural
  language processing.
\newblock \emph{ACM Transactions on Computing for Healthcare (HEALTH)},
  3\penalty0 (1):\penalty0 1--23, 2021.

\bibitem[Sagawa et~al.(2019)Sagawa, Koh, Hashimoto, and
  Liang]{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Johnson et~al.(2016)Johnson, Pollard, Shen, Lehman, Feng, Ghassemi,
  Moody, Szolovits, Anthony~Celi, and Mark]{johnson2016mimic}
Alistair~EW Johnson, Tom~J Pollard, Lu~Shen, Li-wei~H Lehman, Mengling Feng,
  Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony~Celi, and
  Roger~G Mark.
\newblock Mimic-iii, a freely accessible critical care database.
\newblock \emph{Scientific data}, 3\penalty0 (1):\penalty0 1--9, 2016.

\bibitem[Alsentzer et~al.(2019)Alsentzer, Murphy, Boag, Weng, Jin, Naumann, and
  McDermott]{alsentzer2019publicly}
Emily Alsentzer, John~R Murphy, Willie Boag, Wei-Hung Weng, Di~Jin, Tristan
  Naumann, and Matthew McDermott.
\newblock Publicly available clinical bert embeddings.
\newblock \emph{arXiv preprint arXiv:1904.03323}, 2019.

\bibitem[Uzuner et~al.(2011)Uzuner, South, Shen, and DuVall]{uzuner20112010}
{\"O}zlem Uzuner, Brett~R South, Shuying Shen, and Scott~L DuVall.
\newblock 2010 i2b2/va challenge on concepts, assertions, and relations in
  clinical text.
\newblock \emph{Journal of the American Medical Informatics Association},
  18\penalty0 (5):\penalty0 552--556, 2011.

\bibitem[Pomares-Quimbaya et~al.(2019)Pomares-Quimbaya, Kreuzthaler, and
  Schulz]{pomares2019current}
Alexandra Pomares-Quimbaya, Markus Kreuzthaler, and Stefan Schulz.
\newblock Current approaches to identify sections within clinical narratives
  from electronic health records: a systematic review.
\newblock \emph{BMC medical research methodology}, 19:\penalty0 1--20, 2019.

\bibitem[Tao(2011)]{tao2011introduction}
Terence Tao.
\newblock \emph{An introduction to measure theory}, volume 126.
\newblock American Mathematical Soc., 2011.

\bibitem[Mohri et~al.(2018)Mohri, Rostamizadeh, and
  Talwalkar]{mohri2018foundations}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock \emph{Foundations of machine learning}.
\newblock MIT press, 2018.

\bibitem[Crammer et~al.(2008)Crammer, Kearns, and Wortman]{crammer2008learning}
Koby Crammer, Michael Kearns, and Jennifer Wortman.
\newblock Learning from multiple sources.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (8), 2008.

\bibitem[Puli et~al.(2022{\natexlab{b}})Puli, Joshi, He, and
  Ranganath]{puli2022nuisances}
Aahlad Puli, Nitish Joshi, He~He, and Rajesh Ranganath.
\newblock Nuisances via negativa: Adjusting for spurious correlations via data
  augmentation.
\newblock \emph{arXiv preprint arXiv:2210.01302}, 2022{\natexlab{b}}.

\bibitem[Puli et~al.(2023)Puli, Zhang, Wald, and Ranganath]{puli2023don}
Aahlad Puli, Lily Zhang, Yoav Wald, and Rajesh Ranganath.
\newblock Don't blame dataset shift! shortcut learning due to gradients and
  cross entropy.
\newblock \emph{arXiv preprint arXiv:2308.12553}, 2023.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.
\newblock URL
  \url{http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz,
  et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{arXiv preprint arXiv:1910.03771}, 2019.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{pedregosa2011scikit}
Fabian Pedregosa, Ga{\"e}l Varoquaux, Alexandre Gramfort, Vincent Michel,
  Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
  Weiss, Vincent Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{Journal of machine learning research}, 12\penalty0
  (Oct):\penalty0 2825--2830, 2011.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\end{thebibliography}
