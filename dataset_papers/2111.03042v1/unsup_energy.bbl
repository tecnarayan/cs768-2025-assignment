\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen et~al.(2020)Allen, Smith, and Tenenbaum]{Allen29302}
Kelsey~R. Allen, Kevin~A. Smith, and Joshua~B. Tenenbaum.
\newblock Rapid trial-and-error learning with simulation supports flexible tool
  use and physical reasoning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (47):\penalty0 29302--29310, 2020.
\newblock ISSN 0027-8424.
\newblock \doi{10.1073/pnas.1912341117}.
\newblock URL \url{https://www.pnas.org/content/117/47/29302}.

\bibitem[Bahdanau et~al.(2015)Bahdanau, Cho, and Bengio]{Bahdanau2015Neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock In \emph{ICLR}, 2015.

\bibitem[Bell and Sejnowski(1995)]{bell1995information}
Anthony~J Bell and Terrence~J Sejnowski.
\newblock An information-maximization approach to blind separation and blind
  deconvolution.
\newblock \emph{Neural Computation}, 7\penalty0 (6):\penalty0 1129--1159, 1995.

\bibitem[Branwen(2019)]{anime}
Gwern Branwen.
\newblock Danbooru2019 portraits: A large-scale anime head illustration
  dataset, 2019.

\bibitem[Burgess et~al.(2018)Burgess, Higgins, Pal, Matthey, Watters,
  Desjardins, and Lerchner]{burgess2018understanding}
Christopher~P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters,
  Guillaume Desjardins, and Alexander Lerchner.
\newblock Understanding disentangling in beta-vae.
\newblock \emph{arXiv preprint arXiv:1804.03599}, 2018.

\bibitem[Burgess et~al.(2019)Burgess, Matthey, Watters, Kabra, Higgins,
  Botvinick, and Lerchner]{burgess2019monet}
Christopher~P Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina
  Higgins, Matt Botvinick, and Alexander Lerchner.
\newblock Monet: Unsupervised scene decomposition and representation.
\newblock \emph{arXiv:1901.11390}, 2019.

\bibitem[Cabon et~al.(2020)Cabon, Murray, and Humenberger]{cabon2020vkitti2}
Yohann Cabon, Naila Murray, and Martin Humenberger.
\newblock Virtual kitti 2, 2020.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{Chen2018Isolating}
Tian~Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock \emph{arXiv:1802.04942}, 2018.

\bibitem[Chomsky(1965)]{chomsky1965}
Noam Chomsky.
\newblock \emph{Aspects of the Theory of Syntax}.
\newblock The MIT Press, Cambridge, 1965.
\newblock URL
  \url{http://www.amazon.com/Aspects-Theory-Syntax-Noam-Chomsky/dp/0262530074}.

\bibitem[Comon(1994)]{comon1994independent}
Pierre Comon.
\newblock Independent component analysis, a new concept?
\newblock \emph{Signal processing}, 36\penalty0 (3):\penalty0 287--314, 1994.

\bibitem[Crawford and Pineau(2019)]{crawford2019spatially}
Eric Crawford and Joelle Pineau.
\newblock Spatiial invariant unsupervised object detection with convolutional
  neural networks.
\newblock In \emph{Thirty-Third AAAI Conference on Artificial Intelligence},
  2019.

\bibitem[Du and Mordatch(2019)]{du2019implicit}
Yilun Du and Igor Mordatch.
\newblock Implicit generation and generalization in energy-based models.
\newblock \emph{arXiv preprint arXiv:1903.08689}, 2019.

\bibitem[Du et~al.(2020)Du, Li, and Mordatch]{du2020compositional}
Yilun Du, Shuang Li, and Igor Mordatch.
\newblock Compositional visual generation with energy based models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Du et~al.(2021{\natexlab{a}})Du, Li, Tenenbaum, and
  Mordatch]{du2021improved}
Yilun Du, Shuang Li, Joshua~B Tenenbaum, and igor Mordatch.
\newblock Improved contrastive divergence training of energy based models.
\newblock In \emph{Proceedings of the 38th international conference on Machine
  learning}. ACM, 2021{\natexlab{a}}.

\bibitem[Du et~al.(2021{\natexlab{b}})Du, Smith, Ullman, Tenenbaum, and
  Wu]{du2021unsupervised}
Yilun Du, Kevin~A. Smith, Tomer Ullman, Joshua~B. Tenenbaum, and Jiajun Wu.
\newblock Unsupervised discovery of 3d physical objects.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=lf7st0bJIA5}.

\bibitem[Engelcke et~al.(2020)Engelcke, Kosiorek, Jones, and
  Posner]{Engelcke2020GENESIS}
Martin Engelcke, Adam~R. Kosiorek, Oiwi~Parker Jones, and Ingmar Posner.
\newblock Genesis: Generative scene inference and sampling with object-centric
  latent representations.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=BkxfaTVFwH}.

\bibitem[Eslami et~al.(2016)Eslami, Heess, Weber, Tassa, Kavukcuoglu, and
  Hinton]{Eslami2016Attend}
SM~Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, Koray Kavukcuoglu, and
  Geoffrey~E Hinton.
\newblock Attend, infer, repeat: Fast scene understanding with generative
  models.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Eslami et~al.(2018)Eslami, Rezende, Besse, Viola, Morcos, Garnelo,
  Ruderman, Rusu, Danihelka, Gregor, et~al.]{eslami2018neural}
SM~Ali Eslami, Danilo~Jimenez Rezende, Frederic Besse, Fabio Viola, Ari~S
  Morcos, Marta Garnelo, Avraham Ruderman, Andrei~A Rusu, Ivo Danihelka, Karol
  Gregor, et~al.
\newblock Neural scene representation and rendering.
\newblock \emph{Science}, 360\penalty0 (6394):\penalty0 1204--1210, 2018.

\bibitem[Gao et~al.(2020)Gao, Nijkamp, Kingma, Xu, Dai, and Wu]{gao2020flow}
Ruiqi Gao, Erik Nijkamp, Diederik~P Kingma, Zhen Xu, Andrew~M Dai, and
  Ying~Nian Wu.
\newblock Flow contrastive estimation of energy-based models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7518--7528, 2020.

\bibitem[Geiger et~al.(2012)Geiger, Lenz, and Urtasun]{Geiger2012Are}
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
\newblock Are we ready for autonomous driving? the kitti vision benchmark
  suite.
\newblock In \emph{CVPR}, 2012.

\bibitem[Grathwohl et~al.(2019)Grathwohl, Wang, Jacobsen, Duvenaud, Norouzi,
  and Swersky]{grathwohl2019your}
Will Grathwohl, Kuan-Chieh Wang, J{\"o}rn-Henrik Jacobsen, David Duvenaud,
  Mohammad Norouzi, and Kevin Swersky.
\newblock Your classifier is secretly an energy based model and you should
  treat it like one.
\newblock \emph{arXiv preprint arXiv:1912.03263}, 2019.

\bibitem[Greff et~al.(2017)Greff, van Steenkiste, and
  Schmidhuber]{greff2017neural}
Klaus Greff, Sjoerd van Steenkiste, and J{\"u}rgen Schmidhuber.
\newblock Neural expectation maximization.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Greff et~al.(2019)Greff, Kaufmann, Kabra, Watters, Burgess, Zoran,
  Matthey, Botvinick, and Lerchner]{greff2019multi}
Klaus Greff, Rapha{\"e}l~Lopez Kaufmann, Rishab Kabra, Nick Watters, Chris
  Burgess, Daniel Zoran, Loic Matthey, Matthew Botvinick, and Alexander
  Lerchner.
\newblock Multi-object representation learning with iterative variational
  inference.
\newblock \emph{arXiv preprint arXiv:1903.00450}, 2019.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{Higgins2017Beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher~P Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock Beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{ICLR}, 2017.

\bibitem[Higgins et~al.(2018)Higgins, Sonnerat, Matthey, Pal, Burgess, Bosnjak,
  Shanahan, Botvinick, Hassabis, and Lerchner]{higgins2017scan}
Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher~P Burgess,
  Matko Bosnjak, Murray Shanahan, Matthew Botvinick, Demis Hassabis, and
  Alexander Lerchner.
\newblock Scan: Learning hierarchical compositional visual concepts.
\newblock \emph{ICLR}, 2018.

\bibitem[Hyv{\"a}rinen and Morioka(2016)]{hyvarinen2016unsupervised}
Aapo Hyv{\"a}rinen and Hiroshi Morioka.
\newblock Unsupervised feature extraction by time-contrastive learning and
  nonlinear ica.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3765--3773, 2016.

\bibitem[Hyv{\"a}rinen and Morioka(2017)]{hyvarinen2017nonlinear}
Aapo Hyv{\"a}rinen and Hiroshi Morioka.
\newblock Nonlinear ica of temporally dependent stationary sources.
\newblock In \emph{Proceedings of Machine Learning Research}, 2017.

\bibitem[Hyv{\"a}rinen et~al.(2018)Hyv{\"a}rinen, Sasaki, and
  Turner]{hyvarinen2018nonlinear}
Aapo Hyv{\"a}rinen, Hiroaki Sasaki, and Richard~E Turner.
\newblock Nonlinear ica using auxiliary variables and generalized contrastive
  learning.
\newblock \emph{arXiv preprint arXiv:1805.08651}, 2018.

\bibitem[Impagliazzo and Paturi(1999)]{impagliazzo_paturi_1999}
R.~Impagliazzo and R.~Paturi.
\newblock Complexity of k-sat.
\newblock \emph{Proceedings. Fourteenth Annual IEEE Conference on Computational
  Complexity (Formerly: Structure in Complexity Theory Conference)
  (Cat.No.99CB36317)}, Jun 1999.
\newblock \doi{10.1109/ccc.1999.766282}.

\bibitem[Johnson et~al.(2017)Johnson, Hariharan, van~der Maaten, Fei-Fei,
  Zitnick, and Girshick]{Johnson2017CLEVR}
Justin Johnson, Bharath Hariharan, Laurens van~der Maaten, Li~Fei-Fei,
  C~Lawrence Zitnick, and Ross Girshick.
\newblock Clevr: A diagnostic dataset for compositional language and elementary
  visual reasoning.
\newblock In \emph{CVPR}, 2017.

\bibitem[Karras et~al.(2017)Karras, Aila, Laine, and
  Lehtinen]{Karras2017Progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock In \emph{ICLR}, 2017.

\bibitem[Khemakhem et~al.(2020{\natexlab{a}})Khemakhem, Kingma, and
  Hyv{\"a}rinen]{khemakhem2020variational}
Ilyes Khemakhem, Diederik~P Kingma, and Aapo Hyv{\"a}rinen.
\newblock Variational autoencoders and nonlinear ica: A unifying framework.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2020{\natexlab{a}}.

\bibitem[Khemakhem et~al.(2020{\natexlab{b}})Khemakhem, Monti, Kingma, and
  Hyvarinen]{khemakhem2020ice}
Ilyes Khemakhem, Ricardo Monti, Diederik Kingma, and Aapo Hyvarinen.
\newblock Ice-beem: Identifiable conditional energy-based deep models based on
  nonlinear ica.
\newblock \emph{Advances in Neural Information Processing Systems}, 33,
  2020{\natexlab{b}}.

\bibitem[Kim and Bengio(2016)]{kim2016deep}
Taesup Kim and Yoshua Bengio.
\newblock Deep directed generative models with energy-based probability
  estimation.
\newblock \emph{arXiv preprint arXiv:1606.03439}, 2016.

\bibitem[Kingma and Ba(2015)]{Kingma2015Adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{ICLR}, 2015.

\bibitem[Klindt et~al.(2021)Klindt, Schott, Sharma, Ustyuzhaninov, Brendel,
  Bethge, and Paiton]{klindt2021towards}
David~A. Klindt, Lukas Schott, Yash Sharma, Ivan Ustyuzhaninov, Wieland
  Brendel, Matthias Bethge, and Dylan Paiton.
\newblock Towards nonlinear disentanglement in natural data with temporal
  sparse coding.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=EbIDjBynYJ8}.

\bibitem[Kosiorek et~al.(2018)Kosiorek, Kim, Teh, and
  Posner]{kosiorek2018sequential}
Adam Kosiorek, Hyunjik Kim, Yee~Whye Teh, and Ingmar Posner.
\newblock Sequential attend, infer, repeat: Generative modelling of moving
  objects.
\newblock In \emph{NIPS}, 2018.

\bibitem[Lake et~al.(2017)Lake, Ullman, Tenenbaum, and
  Gershman]{lake2017building}
Brenden~M Lake, Tomer~D Ullman, Joshua~B Tenenbaum, and Samuel~J Gershman.
\newblock Building machines that learn and think like people.
\newblock \emph{Behav. Brain Sci.}, 40, 2017.

\bibitem[Liu et~al.(2018)Liu, Lehman, Molino, Such, Frank, Sergeev, and
  Yosinski]{liu2018intriguing}
Rosanne Liu, Joel Lehman, Piero Molino, Felipe~Petroski Such, Eric Frank, Alex
  Sergeev, and Jason Yosinski.
\newblock An intriguing failing of convolutional neural networks and the
  coordconv solution, 2018.

\bibitem[Locatello et~al.(2020{\natexlab{a}})Locatello, Poole, R{\"a}tsch,
  Sch{\"o}lkopf, Bachem, and Tschannen]{locatello2020weakly}
Francesco Locatello, Ben Poole, Gunnar R{\"a}tsch, Bernhard Sch{\"o}lkopf,
  Olivier Bachem, and Michael Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock \emph{arXiv preprint arXiv:2002.02886}, 2020{\natexlab{a}}.

\bibitem[Locatello et~al.(2020{\natexlab{b}})Locatello, Weissenborn,
  Unterthiner, Mahendran, Heigold, Uszkoreit, Dosovitskiy, and
  Kipf]{locatello2020objectcentric}
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran,
  Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf.
\newblock Object-centric learning with slot attention, 2020{\natexlab{b}}.

\bibitem[Nie et~al.(2020)Nie, Karras, Garg, Debnath, Patney, Patel, and
  Anandkumar]{nie2020nvidia}
Weili Nie, Tero Karras, Animesh Garg, Shoubhik Debnath, Anjul Patney, Ankit
  Patel, and Animashree Anandkumar.
\newblock Semi-supervised {S}tyle{GAN} for disentanglement learning.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pages 7360--7369, 2020.

\bibitem[Nijkamp et~al.(2019)Nijkamp, Hill, Han, Zhu, and
  Wu]{nijkamp2019anatomy}
Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, and Ying~Nian Wu.
\newblock On the anatomy of mcmc-based maximum likelihood learning of
  energy-based models.
\newblock \emph{arXiv preprint arXiv:1903.12370}, 2019.

\bibitem[Perez et~al.(2018)Perez, Strub, De~Vries, Dumoulin, and
  Courville]{Perez2018Film}
Ethan Perez, Florian Strub, Harm De~Vries, Vincent Dumoulin, and Aaron
  Courville.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In \emph{AAAI}, 2018.

\bibitem[Roeder et~al.(2020)Roeder, Metz, and Kingma]{roeder2020linear}
Geoffrey Roeder, Luke Metz, and Diedrik~P. Kingma.
\newblock On linear identifiability of learned representations.
\newblock \emph{arXiv preprint arXiv:2007.00810}, 2020.

\bibitem[Rolinek et~al.(2019)Rolinek, Zietlow, and
  Martius]{rolinek2019variational}
Michal Rolinek, Dominik Zietlow, and Georg Martius.
\newblock Variational autoencoders pursue pca directions (by accident).
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 12406--12415, 2019.

\bibitem[Song and Ou(2018)]{song2018learning}
Yunfu Song and Zhijian Ou.
\newblock Learning neural random fields with inclusive auxiliary generators.
\newblock \emph{arXiv preprint arXiv:1806.00271}, 2018.

\bibitem[Stani{\'c} and Schmidhuber(2019)]{stanic2019r}
Aleksandar Stani{\'c} and J{\"u}rgen Schmidhuber.
\newblock R-sqair: Relational sequential attend, infer, repeat.
\newblock \emph{arXiv:1910.05231}, 2019.

\bibitem[van Steenkiste et~al.(2018{\natexlab{a}})van Steenkiste, Chang, Greff,
  and Schmidhuber]{van2018relational}
Sjoerd van Steenkiste, Michael Chang, Klaus Greff, and J{\"u}rgen Schmidhuber.
\newblock Relational neural expectation maximization: Unsupervised discovery of
  objects and their interactions.
\newblock \emph{arXiv preprint arXiv:1802.10353}, 2018{\natexlab{a}}.

\bibitem[van Steenkiste et~al.(2018{\natexlab{b}})van Steenkiste, Kurach, and
  Gelly]{van2018case}
Sjoerd van Steenkiste, Karol Kurach, and Sylvain Gelly.
\newblock A case for object compositionality in deep generative models of
  images.
\newblock \emph{arXiv preprint arXiv:1810.10340}, 2018{\natexlab{b}}.

\bibitem[Vedantam et~al.(2018)Vedantam, Fischer, Huang, and
  Murphy]{vedantam2017generative}
Ramakrishna Vedantam, Ian Fischer, Jonathan Huang, and Kevin Murphy.
\newblock Generative models of visually grounded imagination.
\newblock In \emph{ICLR}, 2018.

\bibitem[Veerapaneni et~al.(2019)Veerapaneni, Co-Reyes, Chang, Janner, Finn,
  Wu, Tenenbaum, and Levine]{veerapaneni2019entity}
Rishi Veerapaneni, John~D Co-Reyes, Michael Chang, Michael Janner, Chelsea
  Finn, Jiajun Wu, Joshua~B Tenenbaum, and Sergey Levine.
\newblock Entity abstraction in visual model-based reinforcement learning.
\newblock In \emph{CoRL}, 2019.

\bibitem[Xie et~al.(2016)Xie, Lu, Zhu, and Wu]{xie2016theory}
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu.
\newblock A theory of generative convnet.
\newblock In \emph{International Conference on Machine Learning}, pages
  2635--2644, 2016.

\bibitem[Zimmermann et~al.(2021)Zimmermann, Sharma, Schneider, Bethge, and
  Brendel]{zimmermann2021contrastive}
Roland~S Zimmermann, Yash Sharma, Steffen Schneider, Matthias Bethge, and
  Wieland Brendel.
\newblock Contrastive learning inverts the data generating process.
\newblock \emph{arXiv preprint arXiv:2102.08850}, 2021.

\end{thebibliography}
