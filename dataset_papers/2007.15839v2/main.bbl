\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{DKK{\etalchar{+}}19b}

\bibitem[AHK12]{arora2012multiplicative}
Sanjeev Arora, Elad Hazan, and Satyen Kale.
\newblock The multiplicative weights update method: a meta-algorithm and
  applications.
\newblock {\em Theory of Computing}, 8(1):121--164, 2012.

\bibitem[Alb05]{albert2005scale}
Reka Albert.
\newblock Scale-free networks in cell biology.
\newblock {\em Journal of Cell Science}, 118(21):4947--4957, 2005.

\bibitem[AMS99]{alon1999median}
Noga Alon, Yossi Matias, and Mario Szegedy.
\newblock The space complexity of approximating the frequency moments.
\newblock {\em J. Comput. System Sci.}, 58(1):137--147, 1999.

\bibitem[AZLO15]{allen2015spectral}
Zeyuan Allen-Zhu, Zhenyu Liao, and Lorenzo Orecchia.
\newblock Spectral sparsification and regret minimization beyond matrix
  multiplicative updates.
\newblock In {\em ACM Symposium on Theory of Computing (STOC '15)}, 2015.

\bibitem[Bar05]{barabasi2005origin}
Albert-Laszlo Barabasi.
\newblock The origin of bursts and heavy tails in human dynamics.
\newblock {\em Nature}, 435(7039):207--211, 2005.

\bibitem[BDLS17]{balakrishnan2017computationally}
Sivaraman Balakrishnan, Simon~S Du, Jerry Li, and Aarti Singh.
\newblock Computationally efficient robust sparse estimation in high
  dimensions.
\newblock In {\em Conference on Learning Theory (COLT '17)}, 2017.

\bibitem[Cat12]{catoni2012challenging}
Olivier Catoni.
\newblock Challenging the empirical mean and empirical variance: a deviation
  study.
\newblock {\em Annales de l'IHP Probabilit{\'e}s et statistiques},
  48(4):1148--1185, 2012.

\bibitem[CDG19]{cheng2019high}
Yu~Cheng, Ilias Diakonikolas, and Rong Ge.
\newblock High-dimensional robust mean estimation in nearly-linear time.
\newblock In {\em ACM-SIAM Symposium on Discrete Algorithms (SODA '19)}, 2019.

\bibitem[CDGS20]{cheng2020high}
Yu~Cheng, Ilias Diakonikolas, Rong Ge, and Mahdi Soltanolkotabi.
\newblock High-dimensional robust mean estimation via gradient descent.
\newblock In {\em International Conference on Machine Learning (ICML '20)},
  2020.

\bibitem[CDGW19]{cheng2019faster}
Yu~Cheng, Ilias Diakonikolas, Rong Ge, and David~P Woodruff.
\newblock Faster algorithms for high-dimensional robust covariance estimation.
\newblock In {\em Conference on Learning Theory (COLT '19)}, 2019.

\bibitem[CFB19]{cherapanamjeri2019fast}
Yeshwanth Cherapanamjeri, Nicolas Flammarion, and Peter~L Bartlett.
\newblock Fast mean estimation with sub-gaussian rates.
\newblock In {\em Conference on Learning Theory (COLT '19)}, 2019.

\bibitem[DHL19]{dong2019quantum}
Yihe Dong, Samuel~B Hopkins, and Jerry Li.
\newblock Quantum entropy scoring for fast robust mean estimation and improved
  outlier detection.
\newblock In {\em Neural Information Processing Systems (NeurIPS '19)}, 2019.

\bibitem[DK19]{diakonikolas2019recent}
Ilias Diakonikolas and Daniel~M Kane.
\newblock Recent advances in algorithmic high-dimensional robust statistics.
\newblock {\em arXiv preprint arXiv:1911.05911}, 2019.

\bibitem[DKK{\etalchar{+}}17]{diakonikolas2017being}
Ilias Diakonikolas, Gautam Kamath, Daniel~M Kane, Jerry Li, Ankur Moitra, and
  Alistair Stewart.
\newblock Being robust (in high dimensions) can be practical.
\newblock In {\em International Conference on Machine Learning (ICML '17)},
  2017.

\bibitem[DKK{\etalchar{+}}18]{diakonikolas2018robustly}
Ilias Diakonikolas, Gautam Kamath, Daniel~M Kane, Jerry Li, Ankur Moitra, and
  Alistair Stewart.
\newblock Robustly learning a gaussian: Getting optimal error, efficiently.
\newblock In {\em ACM-SIAM Symposium on Discrete Algorithms (SODA '18)}. SIAM,
  2018.

\bibitem[DKK{\etalchar{+}}19a]{diakonikolas2019robust}
Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and
  Alistair Stewart.
\newblock Robust estimators in high-dimensions without the computational
  intractability.
\newblock {\em SIAM Journal on Computing}, 48(2):742--864, 2019.

\bibitem[DKK{\etalchar{+}}19b]{diakonikolas2019sever}
Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and
  Alistair Stewart.
\newblock Sever: A robust meta-algorithm for stochastic optimization.
\newblock In {\em International Conference on Machine Learning (ICML '19)},
  2019.

\bibitem[DKP20]{diakonikolas2020outlier}
Ilias Diakonikolas, Daniel~M Kane, and Ankit Pensia.
\newblock Outlier robust mean estimation with subgaussian rates via stability.
\newblock {\em arXiv preprint arXiv:2007.15618}, 2020.

\bibitem[DKS18]{diakonikolas2018list}
Ilias Diakonikolas, Daniel~M Kane, and Alistair Stewart.
\newblock List-decodable robust mean estimation and learning mixtures of
  spherical gaussians.
\newblock In {\em ACM Symposium on Theory of Computing (STOC '18)}, 2018.

\bibitem[DKS19]{diakonikolas2019efficient}
Ilias Diakonikolas, Weihao Kong, and Alistair Stewart.
\newblock Efficient algorithms and lower bounds for robust linear regression.
\newblock In {\em ACM-SIAM Symposium on Discrete Algorithms (SODA '19)}, 2019.

\bibitem[DL19]{lecue2019robust}
Jules Depersin and Guillaume Lecu{\'e}.
\newblock Robust subgaussian estimation of a mean vector in nearly linear time.
\newblock {\em arXiv:1906.03058}, 2019.

\bibitem[DLLO16]{devroye2016sub}
Luc Devroye, Matthieu Lerasle, Gabor Lugosi, and Roberto~I Oliveira.
\newblock Sub-gaussian mean estimators.
\newblock {\em Annals of Statistics}, 44(6):2695--2725, 2016.

\bibitem[FFF99]{faloutsos1999power}
Michalis Faloutsos, Petros Faloutsos, and Christos Faloutsos.
\newblock On power-law relationships of the internet topology.
\newblock {\em ACM SIGCOMM Computer Communication Review}, 29(4):251--262,
  1999.

\bibitem[Haz16]{hazan2016introduction}
Elad Hazan.
\newblock Introduction to online convex optimization.
\newblock {\em Foundations and Trends in Optimization}, 2(3-4):157--325, 2016.

\bibitem[HL18]{hopkins2018mixture}
Samuel~B Hopkins and Jerry Li.
\newblock Mixture models, robustness, and sum of squares proofs.
\newblock In {\em ACM SIGACT Symposium on Theory of Computing (STOC '18)},
  2018.

\bibitem[Hop20]{hopkins2018mean}
Samuel~B. Hopkins.
\newblock Mean estimation with sub-gaussian rates in polynomial time.
\newblock {\em Annals of Statistics}, 48(2):1193--1213, 04 2020.

\bibitem[Hub64]{huber1964robust}
Peter~J Huber.
\newblock Robust estimation of a location parameter.
\newblock {\em The Annals of Mathematical Statistics}, 35(1):73--101, 1964.

\bibitem[HW01]{herbster2001tracking}
Mark Herbster and Manfred~K Warmuth.
\newblock Tracking the best linear predictor.
\newblock {\em Journal of Machine Learning Research}, 1(Sep):281--309, 2001.

\bibitem[JVV86]{jerrum1986median}
Mark~R. Jerrum, Leslie~G. Valiant, and Vijay~V. Vazirani.
\newblock Random generation of combinatorial structures from a uniform
  distribution.
\newblock {\em Theoret. Comput. Sci.}, 43(2-3):169--188, 1986.

\bibitem[KW92]{kuczynski1992estimating}
Jacek Kuczy{\'n}ski and Henryk Wo{\'z}niakowski.
\newblock Estimating the largest eigenvalue by the power and lanczos algorithms
  with a random start.
\newblock {\em SIAM Journal on Matrix Analysis and Applications},
  13(4):1094--1122, 1992.

\bibitem[Led01]{ledoux2001concentration}
Michel Ledoux.
\newblock {\em The concentration of measure phenomenon}.
\newblock American Mathematical Society, 2001.

\bibitem[Li18]{li2018principled}
Jerry~Zheng Li.
\newblock {\em Principled approaches to robust machine learning and beyond}.
\newblock PhD thesis, Massachusetts Institute of Technology, 2018.

\bibitem[Li19a]{jerrynote}
Jerry Li.
\newblock Lecture 4: Spectral signatures and efficient certifiability.
\newblock \url{https://jerryzli.github.io/robust-ml-fall19/lec4.pdf}, 2019.

\bibitem[Li19b]{jerrynote2}
Jerry Li.
\newblock Lecture 5: Filtering from spectral signatures.
\newblock \url{https://jerryzli.github.io/robust-ml-fall19/lec5.pdf}, 2019.

\bibitem[LKF05]{leskovec2005graphs}
Jure Leskovec, Jon Kleinberg, and Christos Faloutsos.
\newblock Graphs over time: densification laws, shrinking diameters and
  possible explanations.
\newblock In {\em ACM SIGKDD International Conference on Knowledge Discovery in
  Data Mining (KDD '05)}, 2005.

\bibitem[LLVZ20]{lei2019fast}
Zhixian Lei, Kyle Luh, Prayaag Venkat, and Fred Zhang.
\newblock A fast spectral algorithm for mean estimation with sub-gaussian
  rates.
\newblock In {\em Conference on Learning Theory (COLT '20)}, 2020.

\bibitem[LM19]{lugosi2019sub}
G{\'a}bor Lugosi and Shahar Mendelson.
\newblock Sub-gaussian estimators of the mean of a random vector.
\newblock {\em Annals of Statistics}, 47(2):783--794, 2019.

\bibitem[LM20]{lugosi2019robust}
Gabor Lugosi and Shahar Mendelson.
\newblock Robust multivariate mean estimation: the optimality of trimmed mean.
\newblock {\em Annals of Statistics}, 2020.

\bibitem[LRV16]{lai2016agnostic}
Kevin~A Lai, Anup~B Rao, and Santosh Vempala.
\newblock Agnostic estimation of mean and covariance.
\newblock In {\em IEEE Symposium on Foundations of Computer Science (FOCS
  '16)}. IEEE, 2016.

\bibitem[NY83]{nemirovsky1983median}
A.~S. Nemirovsky and D.~B. Yudin.
\newblock {\em Problem complexity and method efficiency in optimization}.
\newblock A Wiley-Interscience Publication. John Wiley \& Sons, Inc., New York,
  1983.
\newblock Translated from the Russian and with a preface by E. R. Dawson,
  Wiley-Interscience Series in Discrete Mathematics.

\bibitem[PBR19]{prasad2019unified}
Adarsh Prasad, Sivaraman Balakrishnan, and Pradeep Ravikumar.
\newblock A unified approach to robust mean estimation.
\newblock {\em arXiv preprint arXiv:1907.00927}, 2019.

\bibitem[SCV18]{steinhardt2018resilience}
Jacob Steinhardt, Moses Charikar, and Gregory Valiant.
\newblock Resilience: A criterion for learning in the presence of arbitrary
  outliers.
\newblock In {\em Innovations in Theoretical Computer Science Conference (ITCS
  '18)}, 2018.

\bibitem[SL14]{pmlr-v32-steinhardtb14}
Jacob Steinhardt and Percy Liang.
\newblock Adaptivity and optimism: An improved exponentiated gradient
  algorithm.
\newblock In {\em International Conference on Machine Learning (ICML '14)},
  2014.

\bibitem[Ste18]{steinhardt2018robust}
Jacob Steinhardt.
\newblock {\em Robust Learning: Information Theory and Algorithms}.
\newblock PhD thesis, Stanford University, 2018.

\bibitem[Tuk60]{tukey60}
John~W. Tukey.
\newblock A survey of sampling from contaminated distributions.
\newblock {\em Contributions to probability and statistics}, 2:448--485, 1960.

\bibitem[WK08]{warmuth2008randomized}
Manfred~K Warmuth and Dima Kuzmin.
\newblock Randomized online pca algorithms with regret bounds that are
  logarithmic in the dimension.
\newblock {\em Journal of Machine Learning Research}, 9(Oct):2287--2320, 2008.

\bibitem[WL15]{wang2015projection}
Weiran Wang and Canyi Lu.
\newblock Projection onto the capped simplex.
\newblock {\em arXiv preprint arXiv:1503.01002}, 2015.

\bibitem[Zin03]{zinkevich2003online}
Martin Zinkevich.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In {\em International Conference on Machine Learning (ICML '03)},
  2003.

\bibitem[ZJS20]{zhu2020robust}
Banghua Zhu, Jiantao Jiao, and Jacob Steinhardt.
\newblock Robust estimation via generalized quasi-gradients.
\newblock {\em arXiv preprint arXiv:2005.14073}, 2020.

\end{thebibliography}
