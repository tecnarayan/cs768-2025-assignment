\begin{thebibliography}{24}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balcan and Long(2013)]{balcan2013active}
Maria-Florina Balcan and Phil Long.
\newblock Active and passive learning of linear separators under log-concave
  distributions.
\newblock In \emph{Conference on Learning Theory}, pages 288--316, 2013.

\bibitem[Balcan et~al.(2006)Balcan, Beygelzimer, and
  Langford]{balcan2006agnostic}
Maria-Florina Balcan, Alina Beygelzimer, and John Langford.
\newblock Agnostic active learning.
\newblock In \emph{Proceedings of the 23rd international conference on Machine
  learning}, pages 65--72. ACM, 2006.

\bibitem[Balcan et~al.(2007)Balcan, Broder, and Zhang]{balcan2007margin}
Maria-Florina Balcan, Andrei Broder, and Tong Zhang.
\newblock Margin based active learning.
\newblock In \emph{Proceedings of the 20th annual conference on Learning
  theory}, pages 35--50. Springer-Verlag, 2007.

\bibitem[Bartlett and Mendelson(2002)]{Bartlett02}
P.~Bartlett and S.~Mendelson.
\newblock {G}aussian and {R}ademacher complexities: {R}isk bounds and
  structural results.
\newblock \emph{Journal of Machine Learning Research}, 3:\penalty0 463--482,
  2002.

\bibitem[Beygelzimer et~al.(2009)Beygelzimer, Dasgupta, and
  Langford]{BeygelDL09}
A.~Beygelzimer, S.~Dasgupta, and J.~Langford.
\newblock Importance weighted active learning.
\newblock In \emph{ICML}, 2009.

\bibitem[Beygelzimer et~al.(2010)Beygelzimer, Hsu, Langford, and
  Zhang]{BeygelHLZ10}
A.~Beygelzimer, D.~Hsu, J.~Langford, and T.~Zhang.
\newblock Agnostic active learning without constraints.
\newblock In \emph{NIPS}, 2010.

\bibitem[Blum et~al.(1999)Blum, Kalai, and Langford]{blum1999beating}
Avrim Blum, Adam Kalai, and John Langford.
\newblock Beating the hold-out: Bounds for k-fold and progressive
  cross-validation.
\newblock In \emph{Proceedings of the twelfth annual conference on
  Computational learning theory}, pages 203--208. ACM, 1999.

\bibitem[Castro and Nowak(2008)]{Castro2008}
R.M. Castro and R.D. Nowak.
\newblock Minimax bounds for active learning.
\newblock \emph{Information Theory, IEEE Transactions on}, 54\penalty0
  (5):\penalty0 2339 --2353, 2008.

\bibitem[Cesa-Bianchi et~al.(2004)Cesa-Bianchi, Conconi, and
  Gentile]{cesa2004generalization}
Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile.
\newblock On the generalization ability of on-line learning algorithms.
\newblock \emph{Information Theory, IEEE Transactions on}, 50\penalty0
  (9):\penalty0 2050--2057, 2004.

\bibitem[Cohn et~al.(1994)Cohn, Atlas, and Ladner]{CohnAL94}
D.~Cohn, L.~Atlas, and R.~Ladner.
\newblock Improving generalization with active learning.
\newblock \emph{Machine Learning}, 15:\penalty0 201--221, 1994.

\bibitem[Dasgupta(2005)]{dasgupta2005coarse}
S.~Dasgupta.
\newblock Coarse sample complexity bounds for active learning.
\newblock In \emph{Advances in Neural Information Processing Systems 18}, 2005.

\bibitem[Dasgupta et~al.(2007)Dasgupta, Hsu, and Monteleoni]{DasguptaHM07}
S.~Dasgupta, D.~Hsu, and C.~Monteleoni.
\newblock A general agnostic active learning algorithm.
\newblock In \emph{NIPS}, 2007.

\bibitem[Freedman(1975)]{Freedman75}
D.~A. Freedman.
\newblock On tail probabilities for martingales.
\newblock \emph{The Annals of Probability}, 3\penalty0 (1):\penalty0 100--118,
  February 1975.

\bibitem[Hanneke(2009)]{Hanneke09}
S.~Hanneke.
\newblock \emph{Theoretical Foundations of Active Learning}.
\newblock PhD thesis, Carnegie Mellon University, 2009.

\bibitem[Hanneke(2014)]{Hanneke2014}
Steve Hanneke.
\newblock Theory of disagreement-based active learning.
\newblock \emph{Foundations and Trends in Machine Learning}, 7\penalty0
  (2-3):\penalty0 131--309, 2014.

\bibitem[Horvitz and Thompson(1952)]{horvitz1952generalization}
D.~G. Horvitz and D.~J. Thompson.
\newblock A generalization of sampling without replacement from a finite
  universe.
\newblock \emph{J. Amer. Statist. Assoc.}, 47:\penalty0 663--685, 1952.
\newblock ISSN 0162-1459.

\bibitem[Hsu(2010)]{hsu2010algorithms}
Daniel~J. Hsu.
\newblock \emph{Algorithms for Active Learning}.
\newblock PhD thesis, University of California at San Diego, 2010.

\bibitem[Kakade and Tewari(2009)]{KakadeTe09}
S.~M. Kakade and A.~Tewari.
\newblock On the generalization ability of online strongly convex programming
  algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems 21}, 2009.

\bibitem[Kakade et~al.(2009)Kakade, Sridharan, and Tewari]{KakadeSrTe2009}
Sham~M Kakade, Karthik Sridharan, and Ambuj Tewari.
\newblock On the complexity of linear prediction: Risk bounds, margin bounds,
  and regularization.
\newblock In \emph{Advances in neural information processing systems}, pages
  793--800, 2009.

\bibitem[Karampatziakis and Langford(2011)]{KLonline}
Nikos Karampatziakis and John Langford.
\newblock Online importance weight aware updates.
\newblock In \emph{{UAI} 2011, Proceedings of the Twenty-Seventh Conference on
  Uncertainty in Artificial Intelligence, Barcelona, Spain, July 14-17, 2011},
  pages 392--399, 2011.

\bibitem[Koltchinskii(2010)]{koltchinskii2010rademacher}
Vladimir Koltchinskii.
\newblock Rademacher complexities and bounding the excess risk in active
  learning.
\newblock \emph{J. Mach. Learn. Res.}, 11:\penalty0 2457--2485, December 2010.

\bibitem[Tsybakov(2004)]{Tsybakov2004}
A.~B. Tsybakov.
\newblock Optimal aggregation of classifiers in statistical learning.
\newblock \emph{Ann. Statist.}, 32:\penalty0 135--166, 2004.

\bibitem[Zhang(2015)]{zhang2015oracular}
Chicheng Zhang.
\newblock A simplified treatment of oracular {CAL}.
\newblock Personal communication, 2015.

\bibitem[Zhang and Chaudhuri(2014)]{zhang2014beyond}
Chicheng Zhang and Kamalika Chaudhuri.
\newblock Beyond disagreement-based agnostic active learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  442--450, 2014.

\end{thebibliography}
