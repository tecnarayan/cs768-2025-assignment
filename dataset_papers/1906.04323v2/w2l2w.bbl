\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amodei et~al.(2016)Amodei, Ananthanarayanan, Anubhai, Bai, Battenberg,
  Case, Casper, Catanzaro, Cheng, Chen, et~al.]{amodei2016}
Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric
  Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang
  Chen, et~al.
\newblock Deep speech 2: End-to-end speech recognition in english and mandarin.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  173--182, 2016.

\bibitem[Audhkhasi et~al.(2017)Audhkhasi, Ramabhadran, Saon, Picheny, and
  Nahamoo]{audhkhasi2017direct}
Kartik Audhkhasi, Bhuvana Ramabhadran, George Saon, Michael Picheny, and David
  Nahamoo.
\newblock Direct acoustics-to-word models for english conversational speech
  recognition.
\newblock \emph{arXiv preprint arXiv:1703.07754}, 2017.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Bahdanau et~al.(2016)Bahdanau, Chorowski, Serdyuk, Brakel, and
  Bengio]{bahdanau2016icassp}
Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and Yoshua
  Bengio.
\newblock End-to-end attention-based large vocabulary speech recognition.
\newblock In \emph{International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, pages 4945--4949. IEEE, 2016.

\bibitem[Bengio and Heigold(2014)]{bengio2014word}
Samy Bengio and Georg Heigold.
\newblock Word embeddings for speech recognition.
\newblock In \emph{Fifteenth Annual Conference of the International Speech
  Communication Association}, 2014.

\bibitem[Bisani and Ney(2008)]{bisani2008joint}
Maximilian Bisani and Hermann Ney.
\newblock Joint-sequence models for grapheme-to-phoneme conversion.
\newblock \emph{Speech communication}, 50\penalty0 (5):\penalty0 434--451,
  2008.

\bibitem[Bojanowski et~al.(2017)Bojanowski, Grave, Joulin, and
  Mikolov]{bojanowski2017enriching}
Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov.
\newblock Enriching word vectors with subword information.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  5:\penalty0 135--146, 2017.

\bibitem[Chan et~al.(2016)Chan, Jaitly, Le, and Vinyals]{chan2016listen}
William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals.
\newblock Listen, attend and spell: A neural network for large vocabulary
  conversational speech recognition.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
  International Conference on}, pages 4960--4964. IEEE, 2016.

\bibitem[Cho et~al.(2014)Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock 2014.

\bibitem[Collobert et~al.(2016)Collobert, Puhrsch, and Synnaeve]{collobert2016}
Ronan Collobert, Christian Puhrsch, and Gabriel Synnaeve.
\newblock Wav2letter: an end-to-end convnet-based speech recognition system.
\newblock \emph{arXiv preprint arXiv:1609.03193}, 2016.

\bibitem[Collobert et~al.(2019)Collobert, Hannun, and Synnaeve]{collobert2019}
Ronan Collobert, Awni Hannun, and Gabriel Synnaeve.
\newblock A fully differentiable beam search decoder.
\newblock In \emph{International Conference on Machine Learning {(ICML)}},
  2019.

\bibitem[Dauphin et~al.(2017)Dauphin, Fan, Auli, and Grangier]{dauphin2017}
Yann~N Dauphin, Angela Fan, Michael Auli, and David Grangier.
\newblock Language modeling with gated convolutional networks.
\newblock In \emph{International Conference on Machine Learning {(ICML)}},
  pages 933--941, 2017.

\bibitem[Fan et~al.(2019)Fan, Grave, and Joulin]{fan2019reducing}
Angela Fan, Edouard Grave, and Armand Joulin.
\newblock Reducing transformer depth on demand with structured dropout.
\newblock \emph{arXiv preprint arXiv:1909.11556}, 2019.

\bibitem[Gibson and Hain(2006)]{gibson2006hypothesis}
Matthew Gibson and Thomas Hain.
\newblock Hypothesis spaces for minimum bayes risk training in large vocabulary
  speech recognition.
\newblock In \emph{Ninth international conference on spoken language
  processing}, 2006.

\bibitem[Graves and Jaitly(2014)]{graves2014towards}
Alex Graves and Navdeep Jaitly.
\newblock Towards end-to-end speech recognition with recurrent neural networks.
\newblock In \emph{International Conference on Machine Learning {(ICML)}},
  pages 1764--1772, 2014.

\bibitem[Graves et~al.(2006)Graves, Fern{\'a}ndez, Gomez, and
  Schmidhuber]{graves2006}
Alex Graves, Santiago Fern{\'a}ndez, Faustino Gomez, and J{\"u}rgen
  Schmidhuber.
\newblock Connectionist temporal classification: labelling unsegmented sequence
  data with recurrent neural networks.
\newblock In \emph{International Conference on Machine Learning {(ICML)}},
  pages 369--376, 2006.

\bibitem[Hannun et~al.(2019)Hannun, Lee, Xu, and Collobert]{hannun2019sequence}
Awni Hannun, Ann Lee, Qiantong Xu, and Ronan Collobert.
\newblock Sequence-to-sequence speech recognition with time-depth separable
  convolutions.
\newblock \emph{arXiv preprint arXiv:1904.02619}, 2019.

\bibitem[Irie et~al.(2019)Irie, Prabhavalkar, Kannan, Bruguier, Rybach, and
  Nguyen]{irie2019model}
Kazuki Irie, Rohit Prabhavalkar, Anjuli Kannan, Antoine Bruguier, David Rybach,
  and Patrick Nguyen.
\newblock On the choice of modeling unit for sequence-to-sequence speech
  recognition.
\newblock In \emph{Interspeech}, 2019.

\bibitem[Kanthak and Ney(2002)]{kanthak2002context}
Stephan Kanthak and Hermann Ney.
\newblock Context-dependent acoustic modeling using graphemes for large
  vocabulary speech recognition.
\newblock In \emph{2002 IEEE International Conference on Acoustics, Speech, and
  Signal Processing}, volume~1, pages I--845. IEEE, 2002.

\bibitem[Killer et~al.(2003)Killer, Stuker, and Schultz]{killer2003grapheme}
Mirjam Killer, Sebastian Stuker, and Tanja Schultz.
\newblock Grapheme based speech recognition.
\newblock In \emph{Eighth European Conference on Speech Communication and
  Technology}, 2003.

\bibitem[Kim et~al.(2016)Kim, Jernite, Sontag, and Rush]{kim2016character}
Yoon Kim, Yacine Jernite, David Sontag, and Alexander~M Rush.
\newblock Character-aware neural language models.
\newblock In \emph{Thirtieth AAAI conference on artificial intelligence}, 2016.

\bibitem[Kudo and Richardson(2018)]{kudo2018sentencepiece}
Taku Kudo and John Richardson.
\newblock {S}entence{P}iece: A simple and language independent subword
  tokenizer and detokenizer for neural text processing.
\newblock \emph{arXiv preprint arXiv:1808.06226}, 2018.

\bibitem[Labeau and Allauzen(2017)]{labeau2017character}
Matthieu Labeau and Alexandre Allauzen.
\newblock Character and subword-based word representation for neural language
  modeling prediction.
\newblock In \emph{Proceedings of the First Workshop on Subword and Character
  Level Models in NLP}, pages 1--13, 2017.

\bibitem[Li et~al.(2018)Li, Ye, Das, Zhao, and Gong]{li2018advancing}
Jinyu Li, Guoli Ye, Amit Das, Rui Zhao, and Yifan Gong.
\newblock Advancing acoustic-to-word ctc model.
\newblock In \emph{2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 5794--5798. IEEE, 2018.

\bibitem[Likhomanenko et~al.(2019)Likhomanenko, Synnaeve, and
  Collobert]{likhomanenko2019}
Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.
\newblock Who needs words? lexicon-free speech recognition.
\newblock \emph{arXiv preprint arXiv:1904.04479}, 2019.

\bibitem[Ling et~al.(2015{\natexlab{a}})Ling, Lu{\'\i}s, Marujo, Astudillo,
  Amir, Dyer, Black, and Trancoso]{ling2015finding}
Wang Ling, Tiago Lu{\'\i}s, Lu{\'\i}s Marujo, Ram{\'o}n~Fernandez Astudillo,
  Silvio Amir, Chris Dyer, Alan~W Black, and Isabel Trancoso.
\newblock Finding function in form: Compositional character models for open
  vocabulary word representation.
\newblock \emph{arXiv preprint arXiv:1508.02096}, 2015{\natexlab{a}}.

\bibitem[Ling et~al.(2015{\natexlab{b}})Ling, Trancoso, Dyer, and
  Black]{ling2015character}
Wang Ling, Isabel Trancoso, Chris Dyer, and Alan~W Black.
\newblock Character-based neural machine translation.
\newblock \emph{arXiv preprint arXiv:1511.04586}, 2015{\natexlab{b}}.

\bibitem[L{\"u}scher et~al.(2019)L{\"u}scher, Beck, Irie, Kitza, Michel, Zeyer,
  Schl{\"u}ter, and Ney]{luscher2019rwth}
Christoph L{\"u}scher, Eugen Beck, Kazuki Irie, Markus Kitza, Wilfried Michel,
  Albert Zeyer, Ralf Schl{\"u}ter, and Hermann Ney.
\newblock Rwth asr systems for librispeech: Hybrid vs attention-w/o data
  augmentation.
\newblock In \emph{Interspeech}, 2019.

\bibitem[Maas et~al.(2015)Maas, Xie, Jurafsky, and Ng]{maas2015lexicon}
Andrew Maas, Ziang Xie, Dan Jurafsky, and Andrew Ng.
\newblock Lexicon-free conversational speech recognition with neural networks.
\newblock In \emph{Proceedings of the 2015 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 345--354, 2015.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{panayotov2015librispeech}
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.
\newblock Librispeech: an asr corpus based on public domain audio books.
\newblock In \emph{2015 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 5206--5210. IEEE, 2015.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specaugment}
Daniel~S Park, William Chan, Yu~Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin~D
  Cubuk, and Quoc~V Le.
\newblock Specaugment: A simple data augmentation method for automatic speech
  recognition.
\newblock In \emph{Interspeech}, 2019.

\bibitem[Prabhavalkar et~al.(2018)Prabhavalkar, Sainath, Wu, Nguyen, Chen,
  Chiu, and Kannan]{prabhavalkar2018minimum}
Rohit Prabhavalkar, Tara~N Sainath, Yonghui Wu, Patrick Nguyen, Zhifeng Chen,
  Chung-Cheng Chiu, and Anjuli Kannan.
\newblock Minimum word error rate training for attention-based
  sequence-to-sequence models.
\newblock In \emph{International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, pages 4839--4843. IEEE, 2018.

\bibitem[Pratap et~al.(2018)Pratap, Hannun, Xu, Cai, Kahn, Synnaeve,
  Liptchinsky, and Collobert]{pratap2018}
Vineel Pratap, Awni Hannun, Qiantong Xu, Jeff Cai, Jacob Kahn, Gabriel
  Synnaeve, Vitaliy Liptchinsky, and Ronan Collobert.
\newblock wav2letter++: The fastest open-source speech recognition system.
\newblock \emph{arXiv preprint arXiv:1812.07625}, 2018.

\bibitem[Rao et~al.(2015)Rao, Peng, Sak, and Beaufays]{rao2015grapheme}
Kanishka Rao, Fuchun Peng, Ha{\c{s}}im Sak, and Fran{\c{c}}oise Beaufays.
\newblock Grapheme-to-phoneme conversion using long short-term memory recurrent
  neural networks.
\newblock In \emph{2015 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 4225--4229. IEEE, 2015.

\bibitem[Santos and Zadrozny(2014)]{santos2014learning}
Cicero~D Santos and Bianca Zadrozny.
\newblock Learning character-level representations for part-of-speech tagging.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 1818--1826, 2014.

\bibitem[Settle et~al.(2019)Settle, Audhkhasi, Livescu, and
  Picheny]{settle2019words}
Shane Settle, Kartik Audhkhasi, Karen Livescu, and Michael Picheny.
\newblock Acoustically grounded word embeddings for improved acoustics-to-word
  speech recognition.
\newblock In \emph{2015 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}. IEEE, 2019.

\bibitem[Soltau et~al.(2016)Soltau, Liao, and Sak]{soltau2016neural}
Hagen Soltau, Hank Liao, and Hasim Sak.
\newblock Neural speech recognizer: Acoustic-to-word lstm model for large
  vocabulary speech recognition.
\newblock \emph{arXiv preprint arXiv:1610.09975}, 2016.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In \emph{Advances in neural information processing systems (NIPS)},
  pages 3104--3112, 2014.

\bibitem[Synnaeve et~al.(2019)Synnaeve, Xu, Kahn, Grave, Likhomanenko, Pratap,
  Sriram, Liptchinsky, and Collobert]{synnaeve2019e2e}
Gabriel Synnaeve, Qiantong Xu, Jacob Kahn, Edouard Grave, Tatiana Likhomanenko,
  Vineel Pratap, Anuroop Sriram, Vitaliy Liptchinsky, and Ronan Collobert.
\newblock End-to-end asr: from supervised to semi-supervised learning with
  modern architectures.
\newblock \emph{arXiv preprint arXiv:1911.08460}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar,
  et~al.]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, et~al.
\newblock Attention is all you need.
\newblock In \emph{Adv. NIPS}, 2017.

\bibitem[Zeyer et~al.(2018)Zeyer, Irie, Schl{\"u}ter, and
  Ney]{zeyer2018improved}
Albert Zeyer, Kazuki Irie, Ralf Schl{\"u}ter, and Hermann Ney.
\newblock Improved training of end-to-end attention models for speech
  recognition.
\newblock \emph{arXiv preprint arXiv:1805.03294}, 2018.

\end{thebibliography}
