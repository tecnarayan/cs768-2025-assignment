\begin{thebibliography}{10}

\bibitem{Schaal1997}
S.~Schaal.
\newblock Learning from demonstration.
\newblock In {\em NeurIPS}, pages 1040--1046, 1997.

\bibitem{argall2009survey}
Brenna~D Argall, Sonia Chernova, Manuela Veloso, and Brett Browning.
\newblock A survey of robot learning from demonstration.
\newblock {\em Robotics and autonomous systems}, 57(5):469--483, 2009.

\bibitem{kober2013reinforcement}
Jens Kober, J~Andrew Bagnell, and Jan Peters.
\newblock Reinforcement learning in robotics: A survey.
\newblock {\em The International Journal of Robotics Research},
  32(11):1238--1274, 2013.

\bibitem{cakmak2014eliciting}
Maya Cakmak and Andrea~L Thomaz.
\newblock Eliciting good teaching from humans for machine learners.
\newblock {\em Artificial Intelligence}, 217:198--215, 2014.

\bibitem{buchsbaum2011children}
Daphna Buchsbaum, Alison Gopnik, Thomas~L Griffiths, and Patrick Shafto.
\newblock Children’s imitation of causal action sequences is influenced by
  statistical and pedagogical evidence.
\newblock {\em Cognition}, 120(3):331--340, 2011.

\bibitem{shafto2014rational}
Patrick Shafto, Noah~D Goodman, and Thomas~L Griffiths.
\newblock A rational account of pedagogical reasoning: Teaching by, and
  learning from, examples.
\newblock {\em Cognitive psychology}, 71:55--89, 2014.

\bibitem{bc1991}
D.~A. {Pomerleau}.
\newblock Efficient training of artificial neural networks for autonomous
  navigation.
\newblock {\em Neural Computation}, 3(1):88--97, 1991.

\bibitem{russell1998learning}
Stuart Russell.
\newblock Learning agents for uncertain environments.
\newblock In {\em COLT}, pages 101--103, 1998.

\bibitem{abbeel2004}
Pieter Abbeel and Andrew~Y Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In {\em ICML}, page~1, 2004.

\bibitem{ziebart2008}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In {\em AAAI}, 2008.

\bibitem{boularias2011relative}
Abdeslam Boularias, Jens Kober, and Jan Peters.
\newblock Relative entropy inverse reinforcement learning.
\newblock In {\em AISTATS}, pages 182--189, 2011.

\bibitem{wulfmeier2015maximum}
Markus Wulfmeier, Peter Ondruska, and Ingmar Posner.
\newblock Maximum entropy deep inverse reinforcement learning.
\newblock {\em arXiv preprint arXiv:1507.04888}, 2015.

\bibitem{finn2016guided}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In {\em ICML}, pages 49--58, 2016.

\bibitem{dorsaactive2017}
Dorsa Sadigh, Anca~D Dragan, Shankar Sastry, and Sanjit~A Seshia.
\newblock Active preference-based learning of reward functions.
\newblock {\em RSS}, 2017.

\bibitem{osa2018algorithmic}
Takayuki Osa, Joni Pajarinen, Gerhard Neumann, J~Andrew Bagnell, Pieter Abbeel,
  and Jan Peters.
\newblock An algorithmic perspective on imitation learning.
\newblock {\em Foundations and Trends{\textregistered} in Robotics}, 2018.

\bibitem{walsh2012dynamic}
Thomas~J Walsh and Sergiu Goschin.
\newblock Dynamic teaching in sequential decision making environments.
\newblock {\em UAI}, 2012.

\bibitem{cakmak2012algorithmic}
Maya Cakmak and Manuel Lopes.
\newblock Algorithmic and human teaching of sequential decision tasks.
\newblock In {\em AAAI}, volume~26, 2012.

\bibitem{brown2019machine}
Daniel~S Brown and Scott Niekum.
\newblock Machine teaching for inverse reinforcement learning: Algorithms and
  applications.
\newblock In {\em AAAI}, 2019.

\bibitem{lopes2009active}
Manuel Lopes, Francisco Melo, and Luis Montesano.
\newblock Active learning for reward estimation in inverse reinforcement
  learning.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 31--46. Springer, 2009.

\bibitem{amin2017repeated}
Kareem Amin, Nan Jiang, and Satinder Singh.
\newblock Repeated inverse reinforcement learning.
\newblock In {\em NeurIPS}, pages 1815--1824, 2017.

\bibitem{svetlik2017automatic}
Maxwell Svetlik, Matteo Leonetti, Jivko Sinapov, Rishi Shah, Nick Walker, and
  Peter Stone.
\newblock Automatic curriculum graph generation for reinforcement learning
  agents.
\newblock In {\em AAAI}, volume~31, 2017.

\bibitem{florensa2017reverse}
Carlos Florensa, David Held, Markus Wulfmeier, Michael Zhang, and Pieter
  Abbeel.
\newblock Reverse curriculum generation for reinforcement learning.
\newblock In {\em CORL}, pages 482--495, 2017.

\bibitem{florensa2018automatic}
Carlos Florensa, David Held, Xinyang Geng, and Pieter Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In {\em ICML}, 2018.

\bibitem{czarnecki2018mix}
Wojciech Czarnecki, Siddhant Jayakumar, Max Jaderberg, Leonard Hasenclever,
  Yee~Whye Teh, Nicolas Heess, Simon Osindero, and Razvan Pascanu.
\newblock Mix \& match agent curricula for reinforcement learning.
\newblock In {\em ICML}, 2018.

\bibitem{narvekar2019learning}
Sanmit Narvekar and Peter Stone.
\newblock Learning curriculum policies for reinforcement learning.
\newblock In {\em AAMAS}, pages 25--33, 2019.

\bibitem{sukhbaatar2018intrinsic}
Sainbayar Sukhbaatar, Zeming Lin, Ilya Kostrikov, Gabriel Synnaeve, Arthur
  Szlam, and Robert Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock In {\em ICLR}, 2018.

\bibitem{riedmiller2018learning}
Martin~A Riedmiller, Roland Hafner, Thomas Lampe, Michael Neunert, Jonas
  Degrave, Tom Van~de Wiele, Vlad Mnih, Nicolas Heess, and Jost~Tobias
  Springenberg.
\newblock Learning by playing solving sparse reward tasks from scratch.
\newblock In {\em ICML}, 2018.

\bibitem{imt_ijcai2019}
Parameswaran Kamalaruban, Rati Devidze, Volkan Cevher, and Adish Singla.
\newblock Interactive teaching algorithms for inverse reinforcement learning.
\newblock In {\em IJCAI}, 2019.

\bibitem{elman1993learning}
Jeffrey~L Elman.
\newblock Learning and development in neural networks: The importance of
  starting small.
\newblock {\em Cognition}, 48(1):71--99, 1993.

\bibitem{bengio2009curriculum}
Yoshua Bengio, J{\'e}r{\^o}me Louradour, Ronan Collobert, and Jason Weston.
\newblock Curriculum learning.
\newblock In {\em ICML}, pages 41--48, 2009.

\bibitem{zaremba2014learning}
Wojciech Zaremba and Ilya Sutskever.
\newblock Learning to execute.
\newblock {\em arXiv preprint arXiv:1410.4615}, 2014.

\bibitem{weinshall2018curriculum}
Daphna Weinshall, Gad Cohen, and Dan Amir.
\newblock Curriculum learning by transfer learning: Theory and experiments with
  deep networks.
\newblock In {\em ICML}, 2018.

\bibitem{weinshall2018theory}
Daphna Weinshall and Dan Amir.
\newblock Theory of curriculum learning, with convex loss functions.
\newblock {\em arXiv preprint arXiv:1812.03472}, 2018.

\bibitem{asada1996purposive}
Minoru Asada, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda.
\newblock Purposive behavior acquisition for a real robot by vision-based
  reinforcement learning.
\newblock {\em Machine learning}, 23(2-3):279--303, 1996.

\bibitem{wu2016training}
Yuxin Wu and Yuandong Tian.
\newblock Training agent for first-person shooter game with actor-critic
  curriculum learning.
\newblock In {\em ICLR}, 2016.

\bibitem{bain1995framework}
Michael Bain.
\newblock A framework for behavioural cloning.
\newblock In {\em Machine Intelligence 15}, pages 103--129, 1995.

\bibitem{liu2017iterative}
Weiyang Liu, Bo~Dai, Ahmad Humayun, Charlene Tay, Chen Yu, Linda~B Smith,
  James~M Rehg, and Le~Song.
\newblock Iterative machine teaching.
\newblock In {\em ICML}, 2017.

\bibitem{graves2017automated}
Alex Graves, Marc~G Bellemare, Jacob Menick, R{\'e}mi Munos, and Koray
  Kavukcuoglu.
\newblock Automated curriculum learning for neural networks.
\newblock In {\em ICML}, pages 1311--1320, 2017.

\bibitem{jiang2018mentornet}
Lu~Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li~Fei-Fei.
\newblock Mentornet: Learning data-driven curriculum for very deep neural
  networks on corrupted labels.
\newblock In {\em ICML}, pages 2304--2313, 2018.

\bibitem{zhou2018minimax}
Tianyi Zhou and Jeff Bilmes.
\newblock Minimax curriculum learning: Machine teaching with desirable
  difficulties and scheduled diversity.
\newblock In {\em ICLR}, 2018.

\bibitem{zhou2021curriculum}
Tianyi Zhou, Shengjie Wang, and Jeff Bilmes.
\newblock Curriculum learning by optimizing learning dynamics.
\newblock In {\em AISTATS}, pages 433--441, 2021.

\bibitem{narvekar2020curriculum}
Sanmit Narvekar, Bei Peng, Matteo Leonetti, Jivko Sinapov, Matthew~E Taylor,
  and Peter Stone.
\newblock Curriculum learning for reinforcement learning domains: A framework
  and survey.
\newblock {\em Journal of Machine Learning Research}, 21:1--50, 2020.

\bibitem{ho2016showing}
Mark~K Ho, Michael Littman, James MacGlashan, Fiery Cushman, and Joseph~L
  Austerweil.
\newblock Showing versus doing: Teaching by demonstration.
\newblock In {\em NeurIPS}, 2016.

\bibitem{ho2017intervention}
Mark~K Ho, Michael Littman, and Joseph~L Austerweil.
\newblock Teaching by intervention: Working backwards, undoing mistakes, or
  correcting mistakes?
\newblock In {\em Conference of the Cognitive Science Society}, 2017.

\bibitem{ho2018effective}
Mark~K Ho, Michael Littman, Fiery Cushman, and Joseph~L Austerweil.
\newblock Effectively learning from pedagogical demonstrations.
\newblock In {\em Conference of the Cognitive Science Society}, 2018.

\bibitem{ho2019}
Mark~K Ho, Fiery Cushman, Michael Littman, and Joseph~L Austerweil.
\newblock People teach with rewards and punishments as communication not
  reinforcements.
\newblock In {\em Journal of Experimental Psychology: General}, page 520–549,
  2019.

\bibitem{ho2021communication}
Mark~K Ho, Fiery Cushman, Michael Littman, and Joseph~L Austerweil.
\newblock Communication in action: Planning and interpreting communicative
  demonstrations.
\newblock In {\em Journal of Experimental Psychology: General}, 2021.

\bibitem{goldman1995complexity}
Sally~A Goldman and Michael~J Kearns.
\newblock On the complexity of teaching.
\newblock {\em Journal of Computer and System Sciences}, 50(1):20--31, 1995.

\bibitem{DBLP:journals/corr/ZhuSingla18}
Xiaojin Zhu, Adish Singla, Sandra Zilles, and Anna~N. Rafferty.
\newblock An overview of machine teaching.
\newblock {\em CoRR}, abs/1801.05927, 2018.

\bibitem{yang2018cooperative}
Scott Cheng-Hsin Yang, Yue Yu, arash Givchi, Pei Wang, Wai~Keen Vong, and
  Patrick Shafto.
\newblock Optimal cooperative inference.
\newblock In {\em AISTATS}, pages 376--385, 2018.

\bibitem{melo2018interactive}
Francisco~S Melo, Carla Guerra, and Manuel Lopes.
\newblock Interactive optimal teaching with unknown learners.
\newblock In {\em IJCAI}, pages 2567--2573, 2018.

\bibitem{pmlr-v80-liu18b}
Weiyang Liu, Bo~Dai, Xingguo Li, Zhen Liu, James Rehg, and Le~Song.
\newblock Towards black-box iterative machine teaching.
\newblock In {\em ICML}, 2018.

\bibitem{chen2018understanding}
Yuxin Chen, Adish Singla, Oisin Mac~Aodha, Pietro Perona, and Yisong Yue.
\newblock Understanding the role of adaptivity in machine teaching: The case of
  version space learners.
\newblock In {\em NeurIPS}, 2018.

\bibitem{yeo2019classroom}
Teresa Yeo, Parameswaran Kamalaruban, Adish Singla, Arpit Merchant, Thibault
  Asselborn, Louis Faucon, Pierre Dillenbourg, and Volkan Cevher.
\newblock Iterative classroom teaching.
\newblock In {\em AAAI}, 2019.

\bibitem{Hunziker2019forgetful}
Anette Hunziker, Yuxin Chen, Oisin Mac~Aodha, Manuel Gomez~Rodriguez, Andreas
  Krause, Pietro Perona, Yisong Yue, and Adish Singla.
\newblock Teaching multiple concepts to a forgetful learner.
\newblock In {\em NeurIPS}, 2019.

\bibitem{Mansouri2019preference}
Farnam Mansouri, Yuxin Chen, Ara Vartanian, Jerry Zhu, and Adish Singla.
\newblock Preference-based batch and sequential teaching: Towards a unified
  view of models.
\newblock In {\em NeurIPS}, 2019.

\bibitem{Huag2018features}
Luis Haug, Sebastian Tschiatschek, and Adish Singla.
\newblock Teaching inverse reinforcement learners via features and
  demonstrations.
\newblock In {\em NeurIPS}, 2018.

\bibitem{Tschiatschek2019learneraware}
Sebastian Tschiatschek, Ahana Ghosh, Luis Haug, Rati Devidze, and Adish Singla.
\newblock Learner-aware teaching: Inverse reinforcement learning with
  preferences and constraints.
\newblock In {\em NeurIPS}, 2019.

\bibitem{ziebart2010modeling}
Brian~D Ziebart.
\newblock {\em Modeling Purposeful Adaptive Behavior with the Principle of
  Maximum Causal Entropy}.
\newblock PhD thesis, University of Washington, 2010.

\bibitem{ziebart2013principle}
Brian~D Ziebart, J~Andrew Bagnell, and Anind~K Dey.
\newblock The principle of maximum causal entropy for estimating interacting
  processes.
\newblock {\em IEEE Transactions on Information Theory}, 59(4):1966--1980,
  2013.

\bibitem{ng2000algorithms}
Andrew~Y Ng and Stuart~J. Russell.
\newblock Algorithms for inverse reinforcement learning.
\newblock In {\em ICML}, 2000.

\bibitem{levine2010feature}
Sergey Levine, Zoran Popovic, and Vladlen Koltun.
\newblock Feature construction for inverse reinforcement learning.
\newblock {\em NeurIPS}, 23:1342--1350, 2010.

\bibitem{sbrl2018}
R.~S. Sutton and A.~G. Barto.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock MIT Press, 2018.

\bibitem{jacq2019learning}
Alexis Jacq, Matthieu Geist, Ana Paiva, and Olivier Pietquin.
\newblock Learning from a learner.
\newblock In {\em ICML}, 2019.

\bibitem{brown2021value}
Daniel~S Brown, Jordan Schneider, Anca Dragan, and Scott Niekum.
\newblock Value alignment verification.
\newblock In {\em ICML}, 2021.

\bibitem{dijkstra1959}
E.~W. Dijkstra.
\newblock A note on two problems in connexion with graphs.
\newblock {\em Numer. Math.}, 1:269–271, December 1959.

\bibitem{kool2018attention}
Wouter Kool, Herke van Hoof, and Max Welling.
\newblock Attention, learn to solve routing problems!
\newblock In {\em ICLR}, 2019.

\bibitem{joshi2019learning}
Chaitanya~K. Joshi, Thomas Laurent, and Xavier Bresson.
\newblock On learning paradigms for the travelling salesman problem.
\newblock In {\em NeurIPS graph representation learning workshop}, 2019.

\bibitem{wu2020curricula}
Xiaoxia Wu, Ethan Dyer, and Behnam Neyshabur.
\newblock When do curricula work?
\newblock In {\em ICLR}, 2020.

\end{thebibliography}
