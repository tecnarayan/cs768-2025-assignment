\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Affandi et~al.(2014)Affandi, Fox, Adams, and
  Taskar]{affandi2014learning}
Affandi, R.~H., Fox, E., Adams, R., and Taskar, B.
\newblock {\href{http://proceedings.mlr.press/v32/affandi14.pdf}{Learning the
  parameters of determinantal point process kernels}}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2014.

\bibitem[Ahle et~al.(2020)Ahle, Kapralov, Knudsen, Pagh, Velingker, Woodruff,
  and Zandieh]{ahle2020oblivious}
Ahle, T.~D., Kapralov, M., Knudsen, J.~B., Pagh, R., Velingker, A., Woodruff,
  D.~P., and Zandieh, A.
\newblock
  {\href{https://epubs.siam.org/doi/pdf/10.1137/1.9781611975994.9}{Oblivious
  sketching of high-degree polynomial kernels}}.
\newblock In \emph{Symposium on Discrete Algorithms (SODA)}, 2020.

\bibitem[Altschuler et~al.(2017)Altschuler, Weed, and
  Rigollet]{altschuler2017near}
Altschuler, J., Weed, J., and Rigollet, P.
\newblock
  {\href{https://papers.nips.cc/paper/6792-near-linear-time-approximation-algorithms-for-optimal-transport-via-sinkhorn-iteration.pdf}{Near-linear
  time approximation algorithms for optimal transport via Sinkhorn iteration}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Altschuler et~al.(2019)Altschuler, Bach, Rudi, and
  Niles-Weed]{altschuler2019massively}
Altschuler, J., Bach, F., Rudi, A., and Niles-Weed, J.
\newblock
  {\href{http://papers.nips.cc/paper/8693-massively-scalable-sinkhorn-distances-via-the-nystrom-method.pdf}{Massively
  scalable Sinkhorn distances via the Nystr{\"o}m method}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2019.

\bibitem[Avron et~al.(2014)Avron, Nguyen, and Woodruff]{avron2014subspace}
Avron, H., Nguyen, H., and Woodruff, D.
\newblock
  {\href{https://papers.nips.cc/paper/5240-subspace-embeddings-for-the-polynomial-kernel.pdf}{Subspace
  embeddings for the polynomial kernel}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2014.

\bibitem[Avron et~al.(2017)Avron, Clarkson, and Woodruff]{avron2017sharper}
Avron, H., Clarkson, K.~L., and Woodruff, D.~P.
\newblock {\href{https://arxiv.org/pdf/1611.03225.pdf}{Sharper Bounds for
  Regularized Data Fitting}}.
\newblock \emph{Approximation, Randomization, and Combinatorial Optimization.
  Algorithms and Techniques}, 2017.

\bibitem[Chang \& Lin(2011)Chang and Lin]{CC01a}
Chang, C.-C. and Lin, C.-J.
\newblock \href{http://www.csie.ntu.edu.tw/~cjlin/libsvm}{{LIBSVM}: A library
  for support vector machines}.
\newblock \emph{Transactions on Intelligent Systems and Technology (TIST)},
  2011.

\bibitem[Charikar et~al.(2002)Charikar, Chen, and
  Farach-Colton]{charikar2002finding}
Charikar, M., Chen, K., and Farach-Colton, M.
\newblock
  {\href{https://link.springer.com/chapter/10.1007/3-540-45465-9_59}{Finding
  frequent items in data streams}}.
\newblock In \emph{International Colloquium on Automata, Languages and
  Programming (ICALP)}, 2002.

\bibitem[Cristianini et~al.(2000)Cristianini, Shawe-Taylor,
  et~al.]{cristianini2000introduction}
Cristianini, N., Shawe-Taylor, J., et~al.
\newblock
  \emph{{\href{https://www.cambridge.org/core/books/an-introduction-to-support-vector-machines-and-other-kernelbased-learning-methods/A6A6F4084056A4B23F88648DDBFDD6FC}{An
  introduction to support vector machines and other kernel-based learning
  methods}}}.
\newblock Cambridge university press, 2000.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Cuturi, M.
\newblock
  {\href{https://papers.nips.cc/paper/4927-sinkhorn-distances-lightspeed-computation-of-optimal-transport.pdf}{Sinkhorn
  distances: Lightspeed computation of optimal transport}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2013.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016deep}
Goodfellow, I., Bengio, Y., and Courville, A.
\newblock \emph{{\href{http://www.deeplearningbook.org}{Deep learning}}}.
\newblock MIT press, 2016.

\bibitem[Han et~al.(2017)Han, Malioutov, Avron, and Shin]{han2016approximating}
Han, I., Malioutov, D., Avron, H., and Shin, J.
\newblock
  {\href{https://epubs.siam.org/doi/pdf/10.1137/16M1078148}{Approximating the
  Spectral Sums of Large-scale Matrices using Chebyshev Approximations}}.
\newblock \emph{SIAM Journal on Scientific Computing}, 2017.

\bibitem[Har-Peledx(2008)]{har2008geometric}
Har-Peledx, S.
\newblock
  {\href{https://graphics.stanford.edu/courses/cs468-06-fall/Papers/01%20har-peled%20notes.pdf}{Geometric
  approximation algorithms}}.
\newblock \emph{Lecture Notes for CS598, UIUC}, 2008.

\bibitem[Hemmerle(1975)]{hemmerle1975explicit}
Hemmerle, W.~J.
\newblock
  {\href{https://www.jstor.org/stable/1268066?seq=1#metadata_info_tab_contents}{An
  explicit solution for generalized ridge regression}}.
\newblock \emph{Technometrics}, 1975.

\bibitem[Higham(2008)]{higham2008functions}
Higham, N.~J.
\newblock
  \emph{{\href{https://www.maths.manchester.ac.uk/~higham/fm/}{Functions of
  matrices: theory and computation}}}.
\newblock SIAM, 2008.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock {\href{https://arxiv.org/pdf/1412.6980.pdf}{Adam: A method for
  stochastic optimization}}.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2015.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock
  {\href{https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}{Imagenet
  classification with deep convolutional neural networks}}.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1097--1105, 2012.

\bibitem[Krizhevsky et~al.(2009)]{krizhevsky2009learning}
Krizhevsky, A. et~al.
\newblock
  {\href{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}{Learning
  multiple layers of features from tiny images}}.
\newblock 2009.

\bibitem[Maaten \& Hinton(2008)Maaten and Hinton]{maaten2008visualizing}
Maaten, L. v.~d. and Hinton, G.
\newblock
  {\href{http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf}{Visualizing
  data using t-SNE}}.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 2008.

\bibitem[Mason \& Handscomb(2002)Mason and Handscomb]{mason2002chebyshev}
Mason, J.~C. and Handscomb, D.~C.
\newblock
  \emph{{\href{http://dl.iranidata.com/book/daneshgahi/Chebyshev\%20polynomials\%28www.iranidata.com\%29.pdf}{Chebyshev
  polynomials}}}.
\newblock Chapman and Hall/CRC, 2002.

\bibitem[Meister et~al.(2019)Meister, Sarlos, and Woodruff]{meister2019tight}
Meister, M., Sarlos, T., and Woodruff, D.
\newblock
  {\href{https://papers.nips.cc/paper/9144-tight-dimensionality-reduction-for-sketching-low-degree-polynomial-kernels.pdf}{Tight
  dimensionality reduction for sketching low degree polynomial kernels}}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2019.

\bibitem[Pennington et~al.(2015)Pennington, Yu, and
  Kumar]{pennington2015spherical}
Pennington, J., Yu, F. X.~X., and Kumar, S.
\newblock
  {\href{https://papers.nips.cc/paper/5943-spherical-random-features-for-polynomial-kernels.pdf}{Spherical
  random features for polynomial kernels}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2015.

\bibitem[Pham \& Pagh(2013)Pham and Pagh]{pham2013fast}
Pham, N. and Pagh, R.
\newblock {\href{http://chbrown.github.io/kdd-2013-usb/kdd/p239.pdf}{Fast and
  scalable polynomial kernels via explicit feature maps}}.
\newblock In \emph{Conference on Knowledge Discovery and Data Mining (KDD)},
  2013.

\bibitem[Rahimi \& Recht(2008)Rahimi and Recht]{rahimi2008random}
Rahimi, A. and Recht, B.
\newblock
  {\href{https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf}{Random
  features for large-scale kernel machines}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2008.

\bibitem[Rasmussen(2003)]{rasmussen2003gaussian}
Rasmussen, C.~E.
\newblock {\href{http://www.gaussianprocess.org/gpml/chapters/RW.pdf}{Gaussian
  processes in machine learning}}.
\newblock In \emph{Summer School on Machine Learning}. Springer, 2003.

\bibitem[Scholkopf \& Smola(2001)Scholkopf and Smola]{scholkopf2001learning}
Scholkopf, B. and Smola, A.~J.
\newblock
  \emph{{\href{https://cds.cern.ch/record/791819/files/0262194759_TOC.pdf}{Learning
  with kernels: support vector machines, regularization, optimization, and
  beyond}}}.
\newblock MIT press, 2001.

\bibitem[Smola \& Sch{\"o}kopf(2000)Smola and Sch{\"o}kopf]{smola2000sparse}
Smola, A.~J. and Sch{\"o}kopf, B.
\newblock
  {\href{https://pdfs.semanticscholar.org/dd09/78a594290f6dc530e65983d79a056874185c.pdf}{Sparse
  Greedy Matrix Approximation for Machine Learning}}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2000.

\bibitem[Szego(1939)]{szeg1939orthogonal}
Szego, G.
\newblock
  \emph{{\href{https://books.google.co.kr/books/about/Orthogonal_Polynomials.html?id=3hcW8HBh7gsC&redir_esc=y}{Orthogonal
  polynomials}}}.
\newblock American Mathematical Soc., 1939.

\bibitem[Ubaru et~al.(2017)Ubaru, Chen, and Saad]{ubaru2017fast}
Ubaru, S., Chen, J., and Saad, Y.
\newblock {\href{https://www-users.cs.umn.edu/~saad/PDF/ys-2016-04.pdf}{Fast
  Estimation of tr(f(A)) via Stochastic Lanczos Quadrature}}.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 2017.

\bibitem[Vazirani(2013)]{vazirani2013approximation}
Vazirani, V.~V.
\newblock
  \emph{{\href{https://doc.lagout.org/science/0_Computer\%20Science/2_Algorithms/Approximation\%20Algorithms\%20\%5BVazirani\%202010-12-01\%5D.pdf}{Approximation
  algorithms}}}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Wang et~al.(2015)Wang, Zhang, Zhou, Tang, and Li]{wang2015beyond}
Wang, L., Zhang, J., Zhou, L., Tang, C., and Li, W.
\newblock
  {\href{https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Wang_Beyond_Covariance_Feature_ICCV_2015_paper.pdf}{Beyond
  covariance: Feature representation with nonlinear kernel matrices}}.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2015.

\bibitem[Weinberger et~al.(2009)Weinberger, Dasgupta, Attenberg, Langford, and
  Smola]{weinberger2009feature}
Weinberger, K., Dasgupta, A., Attenberg, J., Langford, J., and Smola, A.
\newblock
  {\href{https://alex.smola.org/papers/2009/Weinbergeretal09.pdf}{Feature
  hashing for large scale multitask learning}}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2009.

\bibitem[Williams \& Seeger(2001)Williams and Seeger]{williams2001using}
Williams, C.~K. and Seeger, M.
\newblock
  {\href{https://papers.nips.cc/paper/1866-using-the-nystrom-method-to-speed-up-kernel-machines.pdf}{Using
  the Nystrom method to speed up kernel machines}}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2001.

\end{thebibliography}
