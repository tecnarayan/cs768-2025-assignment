\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agmon \& Stone(2012)Agmon and Stone]{agmon2012leading}
Agmon, N. and Stone, P.
\newblock Leading ad hoc agents in joint action settings with multiple
  teammates.
\newblock In \emph{Proc. of 12th Int. Conf. on Autonomous Agents and Multiagent
  Systems (AAMAS 2012)}, June 2012.

\bibitem[Albrecht \& Ramamoorthy(2013)Albrecht and
  Ramamoorthy]{Albrecht2013GameTheoretic}
Albrecht, S.~V. and Ramamoorthy, S.
\newblock A game-theoretic model and best-response learning method for ad hoc
  coordination in multiagent systems.
\newblock In \emph{Proceedings of the 2013 International Conference on
  Autonomous Agents and Multi-Agent Systems}, pp.\  1155--1156, 2013.

\bibitem[Albrecht \& Stone(2017)Albrecht and Stone]{as2017}
Albrecht, S.~V. and Stone, P.
\newblock Reasoning about hypothetical agent behaviours and their parameters.
\newblock In \emph{Proceedings of the 16th International Conference on
  Autonomous Agents and Multiagent Systems}, pp.\  547--555, 2017.

\bibitem[Albrecht \& Stone(2018)Albrecht and Stone]{albrecht2018autonomous}
Albrecht, S.~V. and Stone, P.
\newblock Autonomous agents modelling other agents: A comprehensive survey and
  open problems.
\newblock \emph{Artificial Intelligence}, 258:\penalty0 66--95, 2018.

\bibitem[Albrecht et~al.(2016)Albrecht, Crandall, and
  Ramamoorthy]{albrecht2016belief}
Albrecht, S.~V., Crandall, J.~W., and Ramamoorthy, S.
\newblock Belief and truth in hypothesised behaviours.
\newblock \emph{Artificial Intelligence}, 235:\penalty0 63--94, 2016.

\bibitem[Albrecht et~al.(2021)Albrecht, Brewitt, Wilhelm, Gyevnar, Eiras,
  Dobre, and Ramamoorthy]{albrecht2020igp2}
Albrecht, S.~V., Brewitt, C., Wilhelm, J., Gyevnar, B., Eiras, F., Dobre, M.,
  and Ramamoorthy, S.
\newblock Interpretable goal-based prediction and planning for autonomous
  driving.
\newblock In \emph{IEEE International Conference on Robotics and Automation
  (ICRA)}, 2021.

\bibitem[Barrett \& Stone(2015)Barrett and Stone]{AAAI15-Barrett}
Barrett, S. and Stone, P.
\newblock Cooperating with unknown teammates in complex domains: A robot soccer
  case study of ad hoc teamwork.
\newblock In \emph{Proceedings of the Twenty-Ninth AAAI Conference on
  Artificial Intelligence}, January 2015.

\bibitem[Barrett et~al.(2011)Barrett, Stone, and Kraus]{barrett2011empirical}
Barrett, S., Stone, P., and Kraus, S.
\newblock Empirical evaluation of ad hoc teamwork in the pursuit domain.
\newblock In \emph{Proc. of 11th Int. Conf. on Autonomous Agents and Multiagent
  Systems (AAMAS)}, May 2011.

\bibitem[Barrett et~al.(2017)Barrett, Rosenfeld, Kraus, and
  Stone]{barrett2017making}
Barrett, S., Rosenfeld, A., Kraus, S., and Stone, P.
\newblock Making friends on the fly: Cooperating with new teammates.
\newblock \emph{Artificial Intelligence}, 242:\penalty0 132--171, 2017.

\bibitem[B{\"o}hmer et~al.(2020)B{\"o}hmer, Kurin, and Whiteson]{DCG}
B{\"o}hmer, W., Kurin, V., and Whiteson, S.
\newblock Deep coordination graphs.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  980--991. PMLR, 2020.

\bibitem[Castellini et~al.(2019)Castellini, Oliehoek, Savani, and
  Whiteson]{castellini2019representational}
Castellini, J., Oliehoek, F.~A., Savani, R., and Whiteson, S.
\newblock The representational capacity of action-value networks for
  multi-agent reinforcement learning.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, pp.\  1862--1864, 2019.

\bibitem[Chen et~al.(2020)Chen, Andrejczuk, Cao, and Zhang]{chen2020aateam}
Chen, S., Andrejczuk, E., Cao, Z., and Zhang, J.
\newblock Aateam: Achieving the ad hoc teamwork by employing the attention
  mechanism.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pp.\  7095--7102, 2020.

\bibitem[Christianos et~al.(2020)Christianos, Schäfer, and
  Albrecht]{christianos2020shared}
Christianos, F., Schäfer, L., and Albrecht, S.~V.
\newblock Shared experience actor-critic for multi-agent reinforcement
  learning.
\newblock In \emph{34th Conference on Neural Information Processing Systems},
  2020.

\bibitem[Deka \& Sycara(2020)Deka and Sycara]{deka2020natural}
Deka, A. and Sycara, K.
\newblock Natural emergence of heterogeneous strategies in artificially
  intelligent competitive teams.
\newblock \emph{arXiv preprint arXiv:2007.03102}, 2020.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018a}
Foerster, J., Farquhar, G., Afouras, T., Nardelli, N., and Whiteson, S.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Grover et~al.(2018)Grover, Al-Shedivat, Gupta, Burda, and
  Edwards]{grover2018learning}
Grover, A., Al-Shedivat, M., Gupta, J., Burda, Y., and Edwards, H.
\newblock Learning policy representations in multiagent systems.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1802--1811, 2018.

\bibitem[Guestrin et~al.(2002)Guestrin, Lagoudakis, and
  Parr]{guestrin2002coordinated}
Guestrin, C., Lagoudakis, M.~G., and Parr, R.
\newblock Coordinated reinforcement learning.
\newblock In \emph{Proceedings of the Nineteenth International Conference on
  Machine Learning}, pp.\  227--234, 2002.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1861--1870. PMLR, 2018.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and
  Leskovec]{hamilton2017inductive}
Hamilton, W., Ying, Z., and Leskovec, J.
\newblock Inductive representation learning on large graphs.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1024--1034, 2017.

\bibitem[He et~al.(2016)He, Boyd-Graber, Kwok, and
  Daum{\'e}~III]{he2016opponent}
He, H., Boyd-Graber, J., Kwok, K., and Daum{\'e}~III, H.
\newblock Opponent modeling in deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1804--1813, 2016.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Jiang et~al.(2019)Jiang, Dun, Huang, and Lu]{jiang2019graph}
Jiang, J., Dun, C., Huang, T., and Lu, Z.
\newblock Graph convolutional reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Leibo et~al.(2017)Leibo, Zambaldi, Lanctot, Marecki, and
  Graepel]{Leibo2017SocialDilemmas}
Leibo, J.~Z., Zambaldi, V., Lanctot, M., Marecki, J., and Graepel, T.
\newblock Multi-agent reinforcement learning in sequential social dilemmas.
\newblock In \emph{Proceedings of the 16th Conference on Autonomous Agents and
  MultiAgent Systems}, pp.\  464--473, 2017.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Lowe, R., Wu, Y.~I., Tamar, A., Harb, J., Abbeel, O.~P., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6379--6390, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1928--1937, 2016.

\bibitem[Papoudakis et~al.(2019)Papoudakis, Christianos, Rahman, and
  Albrecht]{papoudakis2019dealing}
Papoudakis, G., Christianos, F., Rahman, A., and Albrecht, S.~V.
\newblock Dealing with non-stationarity in multi-agent deep reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1906.04737}, 2019.

\bibitem[Rabinowitz et~al.(2018)Rabinowitz, Perbet, Song, Zhang, Eslami, and
  Botvinick]{DBLP:conf/icml/RabinowitzPSZEB18}
Rabinowitz, N.~C., Perbet, F., Song, H.~F., Zhang, C., Eslami, S. M.~A., and
  Botvinick, M.
\newblock Machine theory of mind.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, pp.\  4215--4224, 2018.

\bibitem[Raileanu et~al.(2018)Raileanu, Denton, Szlam, and
  Fergus]{DBLP:conf/icml/RaileanuDSF18}
Raileanu, R., Denton, E., Szlam, A., and Fergus, R.
\newblock Modeling others using oneself in multi-agent reinforcement learning.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, pp.\  4254--4263, 2018.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, de~Witt, Farquhar, Foerster, and
  Whiteson]{DBLP:conf/icml/RashidSWFFW18}
Rashid, T., Samvelyan, M., de~Witt, C.~S., Farquhar, G., Foerster, J.~N., and
  Whiteson, S.
\newblock {QMIX:} monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, pp.\  4292--4301, 2018.

\bibitem[Ravula et~al.(2019)Ravula, Alkobi, and Stone]{IJCAI19-ravula}
Ravula, M., Alkobi, S., and Stone, P.
\newblock Ad hoc teamwork with behavior switching agents.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, August 2019.

\bibitem[Rummery \& Niranjan(1994)Rummery and Niranjan]{rummery1994line}
Rummery, G.~A. and Niranjan, M.
\newblock \emph{On-line Q-learning using connectionist systems}, volume~37.
\newblock University of Cambridge, Department of Engineering Cambridge, UK,
  1994.

\bibitem[Stone et~al.(2009)Stone, Kaminka, and Rosenschein]{stone2009leading}
Stone, P., Kaminka, G.~A., and Rosenschein, J.~S.
\newblock Leading a best-response teammate in an ad hoc team.
\newblock In \emph{Agent-mediated electronic commerce. Designing trading
  strategies and mechanisms for electronic markets}, pp.\  132--146. Springer,
  2009.

\bibitem[Stone et~al.(2010)Stone, Kaminka, Kraus, and Rosenschein]{stone2010ad}
Stone, P., Kaminka, G., Kraus, S., and Rosenschein, J.
\newblock Ad hoc autonomous agent teams: Collaboration without
  pre-coordination.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~24, 2010.

\bibitem[Sunehag et~al.(2018)Sunehag, Lever, Gruslys, Czarnecki, Zambaldi,
  Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, and
  Graepel]{DBLP:conf/atal/SunehagLGCZJLSL18}
Sunehag, P., Lever, G., Gruslys, A., Czarnecki, W.~M., Zambaldi, V.~F.,
  Jaderberg, M., Lanctot, M., Sonnerat, N., Leibo, J.~Z., Tuyls, K., and
  Graepel, T.
\newblock Value-decomposition networks for cooperative multi-agent learning
  based on team reward.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, pp.\  2085--2087, 2018.

\bibitem[Tacchetti et~al.(2019)Tacchetti, Song, Mediano, Zambaldi,
  Kram{\'{a}}r, Rabinowitz, Graepel, Botvinick, and
  Battaglia]{DBLP:conf/iclr/TacchettiSMZKRG19}
Tacchetti, A., Song, H.~F., Mediano, P. A.~M., Zambaldi, V.~F., Kram{\'{a}}r,
  J., Rabinowitz, N.~C., Graepel, T., Botvinick, M., and Battaglia, P.~W.
\newblock Relational forward models for multi-agent learning.
\newblock In \emph{7th International Conference on Learning Representations},
  2019.

\bibitem[Tambe(1997)]{tambe1997towards}
Tambe, M.
\newblock Towards flexible teamwork.
\newblock \emph{Journal of Artificial Intelligence Research}, 7:\penalty0
  83--124, 1997.

\bibitem[Tampuu et~al.(2017)Tampuu, Matiisen, Kodelja, Kuzovkin, Korjus, Aru,
  Aru, and Vicente]{tampuu2017multiagent}
Tampuu, A., Matiisen, T., Kodelja, D., Kuzovkin, I., Korjus, K., Aru, J., Aru,
  J., and Vicente, R.
\newblock Multiagent cooperation and competition with deep reinforcement
  learning.
\newblock \emph{PloS one}, 12\penalty0 (4), 2017.

\bibitem[Wang et~al.(2019)Wang, Yu, Zheng, Gan, Gai, Ye, Li, Zhou, Huang, Ma,
  Huang, Guo, Zhang, Lin, Zhao, Li, Smola, and Zhang]{wang2019dgl}
Wang, M., Yu, L., Zheng, D., Gan, Q., Gai, Y., Ye, Z., Li, M., Zhou, J., Huang,
  Q., Ma, C., Huang, Z., Guo, Q., Zhang, H., Lin, H., Zhao, J., Li, J., Smola,
  A.~J., and Zhang, Z.
\newblock Deep graph library: Towards efficient and scalable deep learning on
  graphs.
\newblock \emph{ICLR Workshop on Representation Learning on Graphs and
  Manifolds}, 2019.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{watkins1992q}
Watkins, C.~J. and Dayan, P.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Zhou et~al.(2019)Zhou, Chen, Wen, Yang, Su, Zhang, Zhang, and
  Wang]{zhou2019factorized}
Zhou, M., Chen, Y., Wen, Y., Yang, Y., Su, Y., Zhang, W., Zhang, D., and Wang,
  J.
\newblock Factorized q-learning for large-scale multi-agent systems.
\newblock In \emph{Proceedings of the First International Conference on
  Distributed Artificial Intelligence}, pp.\  1--7, 2019.

\end{thebibliography}
