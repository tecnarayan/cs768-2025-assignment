\begin{thebibliography}{23}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[{Allen-Zhu}(2017)]{Katyusha}
{Allen-Zhu}, Zeyuan.
\newblock {Katyusha: The First Direct Acceleration of Stochastic Gradient
  Methods}.
\newblock \emph{Proceedings of the 49th Annual ACM on Symposium on Theory of
  Computing (to appear)}, 2017.

\bibitem[{Allen-Zhu} \& Yuan(2016){Allen-Zhu} and Yuan]{SVRG++}
{Allen-Zhu}, Zeyuan and Yuan, Yang.
\newblock {Improved SVRG for Non-Strongly-Convex or Sum-of-Non-Convex
  Objectives}.
\newblock In \emph{ICML}, pp.\  1080--1089, 2016.

\bibitem[Beck \& Teboulle(2009)Beck and Teboulle]{fista}
Beck, Amir and Teboulle, Marc.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock \emph{SIAM J. Imaging Sciences}, 2\penalty0 (1):\penalty0 183--202,
  2009.

\bibitem[Bottou(1998)]{Bottou1998}
Bottou, L{\'e}on.
\newblock Online learning and stochastic approximations.
\newblock In Saad, David (ed.), \emph{Online Learning in Neural Networks}, pp.\
   9--42. Cambridge University Press, New York, NY, USA, 1998.
\newblock ISBN 0-521-65263-4.

\bibitem[Bottou et~al.(2016)Bottou, Curtis, and
  Nocedal]{bottou2016optimization}
Bottou, L{\'e}on, Curtis, Frank~E, and Nocedal, Jorge.
\newblock Optimization methods for large-scale machine learning.
\newblock \emph{arXiv:1606.04838}, 2016.

\bibitem[Cotter et~al.(2011)Cotter, Shamir, Srebro, and
  Sridharan]{acceleratedmb}
Cotter, Andrew, Shamir, Ohad, Srebro, Nati, and Sridharan, Karthik.
\newblock Better mini-batch algorithms via accelerated gradient methods.
\newblock In \emph{NIPS}, pp.\  1647--1655, 2011.

\bibitem[Defazio et~al.(2014)Defazio, Bach, and Lacoste-Julien]{SAGA}
Defazio, Aaron, Bach, Francis, and Lacoste-Julien, Simon.
\newblock {SAGA}: A fast incremental gradient method with support for
  non-strongly convex composite objectives.
\newblock In \emph{NIPS}, pp.\  1646--1654, 2014.

\bibitem[Hastie et~al.(2009)Hastie, Tibshirani, and Friedman]{ESL}
Hastie, Trevor, Tibshirani, Robert, and Friedman, Jerome.
\newblock \emph{The Elements of Statistical Learning: Data Mining, Inference,
  and Prediction}.
\newblock Springer Series in Statistics, 2nd edition, 2009.

\bibitem[Johnson \& Zhang(2013)Johnson and Zhang]{SVRG}
Johnson, Rie and Zhang, Tong.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In \emph{NIPS}, pp.\  315--323, 2013.

\bibitem[Kone{\v{c}}n{\'y} et~al.(2016)Kone{\v{c}}n{\'y}, Liu, Richt{\'a}rik,
  and Tak{\'a}{\v{c}}]{konecny2015mini}
Kone{\v{c}}n{\'y}, Jakub, Liu, Jie, Richt{\'a}rik, Peter, and Tak{\'a}{\v{c}},
  Martin.
\newblock Mini-batch semi-stochastic gradient descent in the proximal setting.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  10:\penalty0 242--255, 2016.

\bibitem[Kone\v{c}n{\'y} \& Richt{\'a}rik(2013)Kone\v{c}n{\'y} and
  Richt{\'a}rik]{S2GD}
Kone\v{c}n{\'y}, Jakub and Richt{\'a}rik, Peter.
\newblock Semi-stochastic gradient descent methods.
\newblock \emph{arXiv:1312.1666}, 2013.

\bibitem[Le~Roux et~al.(2012)Le~Roux, Schmidt, and Bach]{SAG}
Le~Roux, Nicolas, Schmidt, Mark, and Bach, Francis.
\newblock A stochastic gradient method with an exponential convergence rate for
  finite training sets.
\newblock In \emph{NIPS}, pp.\  2663--2671, 2012.

\bibitem[Mairal(2013)]{mairal2013optimization}
Mairal, Julien.
\newblock Optimization with first-order surrogate functions.
\newblock In \emph{ICML}, pp.\  783--791, 2013.

\bibitem[Mokhtari et~al.(2017)Mokhtari, G{\"u}rb{\"u}zbalaban, and
  Ribeiro]{mokhtari2017double}
Mokhtari, Aryan, G{\"u}rb{\"u}zbalaban, Mert, and Ribeiro, Alejandro.
\newblock A double incremental aggregated gradient method with linear
  convergence rate for large-scale optimization.
\newblock \emph{Proceedings of IEEE International Conference on Acoustic,
  Speech and Signal Processing (to appear)}, 2017.

\bibitem[Nesterov(2004)]{nesterov2004}
Nesterov, Yurii.
\newblock \emph{Introductory lectures on convex optimization : a basic course}.
\newblock Applied optimization. Kluwer Academic Publ., Boston, Dordrecht,
  London, 2004.
\newblock ISBN 1-4020-7553-7.

\bibitem[Reddi et~al.(2016)Reddi, Hefny, Sra, P{\'{o}}czos, and
  Smola]{nonconvexSVRG}
Reddi, Sashank~J., Hefny, Ahmed, Sra, Suvrit, P{\'{o}}czos, Barnab{\'{a}}s, and
  Smola, Alexander~J.
\newblock Stochastic variance reduction for nonconvex optimization.
\newblock In \emph{ICML}, pp.\  314--323, 2016.

\bibitem[Robbins \& Monro(1951)Robbins and Monro]{RM1951}
Robbins, Herbert and Monro, Sutton.
\newblock A stochastic approximation method.
\newblock \emph{The Annals of Mathematical Statistics}, 22\penalty0
  (3):\penalty0 400--407, 1951.

\bibitem[Schmidt et~al.(2016)Schmidt, Le~Roux, and Bach]{SAGjournal}
Schmidt, Mark, Le~Roux, Nicolas, and Bach, Francis.
\newblock Minimizing finite sums with the stochastic average gradient.
\newblock \emph{Mathematical Programming}, pp.\  1--30, 2016.

\bibitem[Shalev-Shwartz \& Zhang(2013)Shalev-Shwartz and Zhang]{SDCA}
Shalev-Shwartz, Shai and Zhang, Tong.
\newblock Stochastic dual coordinate ascent methods for regularized loss.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (1):\penalty0 567--599, 2013.

\bibitem[Shalev-Shwartz et~al.(2007)Shalev-Shwartz, Singer, and
  Srebro]{pegasosICML}
Shalev-Shwartz, Shai, Singer, Yoram, and Srebro, Nathan.
\newblock Pegasos: Primal estimated sub-gradient solver for {SVM}.
\newblock In \emph{ICML}, pp.\  807--814, 2007.

\bibitem[Shalev-Shwartz et~al.(2011)Shalev-Shwartz, Singer, Srebro, and
  Cotter]{pegasos}
Shalev-Shwartz, Shai, Singer, Yoram, Srebro, Nathan, and Cotter, Andrew.
\newblock Pegasos: Primal estimated sub-gradient solver for {SVM}.
\newblock \emph{Mathematical Programming}, 127\penalty0 (1):\penalty0 3--30,
  2011.

\bibitem[Tak{\'a}\v{c} et~al.(2013)Tak{\'a}\v{c}, Bijral, Richt{\'a}rik, and
  Srebro]{takac2013ICML}
Tak{\'a}\v{c}, Martin, Bijral, Avleen~Singh, Richt{\'a}rik, Peter, and Srebro,
  Nathan.
\newblock Mini-batch primal and dual methods for {SVM}s.
\newblock In \emph{ICML}, pp.\  1022--1030, 2013.

\bibitem[Xiao \& Zhang(2014)Xiao and Zhang]{Xiao2014}
Xiao, Lin and Zhang, Tong.
\newblock A proximal stochastic gradient method with progressive variance
  reduction.
\newblock \emph{{SIAM} Journal on Optimization}, 24\penalty0 (4):\penalty0
  2057--2075, 2014.

\end{thebibliography}
