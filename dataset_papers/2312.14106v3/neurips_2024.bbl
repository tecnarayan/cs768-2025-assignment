\begin{thebibliography}{10}

\bibitem{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock {GPT}-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{safe-exp}
Joshua Achiam and Dario Amodei.
\newblock Benchmarking safe exploration in deep reinforcement learning.
\newblock 2019.

\bibitem{agrawal2012analysis}
Shipra Agrawal and Navin Goyal.
\newblock Analysis of {Thompson} sampling for the multi-armed bandit problem.
\newblock In {\em Conference on Learning Theory}, pages 39--1. JMLR Workshop and Conference Proceedings, 2012.

\bibitem{value_aligned_rl_1}
Md~Sultan Al~Nahian, Spencer Frazier, Brent Harrison, and Mark Riedl.
\newblock Training value-aligned reinforcement learning agents using a normative prior.
\newblock {\em arXiv preprint arXiv:2104.09469}, 2021.

\bibitem{irl-survey}
Saurabh Arora and Prashant Doshi.
\newblock A survey of inverse reinforcement learning: Challenges, methods and progress.
\newblock {\em arXiv preprint arXiv:1806.06877}, 2020.

\bibitem{moral_machine_experiment}
Edmond Awad, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-Fran√ßois Bonnefon, and Iyad Rahwan.
\newblock The moral machine experiment.
\newblock {\em Nature}, pages 59--64, 2018.

\bibitem{svr_explanation}
Mariette Awad and Rahul Khanna.
\newblock {\em Support Vector Regression}, pages 67--80.
\newblock Apress, Berkeley, CA, 2015.

\bibitem{rlhf-assistant}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock {\em arXiv preprint arXiv:2204.05862}, 2022.

\bibitem{human-machine-reps-1}
Mark~H Bickhard.
\newblock Representational content in humans and machines.
\newblock {\em Journal of Experimental \& Theoretical Artificial Intelligence}, 5(4):285--333, 1993.

\bibitem{ra-6}
Andreea Bobu, Andi Peng, Pulkit Agrawal, Julie Shah, and Anca~D Dragan.
\newblock Aligning robot and human representations.
\newblock {\em arXiv preprint arXiv:2302.01928}, 2023.

\bibitem{rlhf-limits}
Stephen Casper, Xander Davies, Claudia Shi, Thomas~Krendl Gilbert, J{\'e}r{\'e}my Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, et~al.
\newblock Open problems and fundamental limitations of reinforcement learning from human feedback.
\newblock {\em arXiv preprint arXiv:2307.15217}, 2023.

\bibitem{llm-bias-1}
Xiangjue Dong, Yibo Wang, Philip~S Yu, and James Caverlee.
\newblock Probing explicit and implicit gender bias through {LLM} conditional text generation.
\newblock {\em arXiv preprint arXiv:2311.00306}, 2023.

\bibitem{gabriel2022challenge}
Iason Gabriel and Vafa Ghazavi.
\newblock The challenge of value alignment.
\newblock In {\em The Oxford Handbook of Digital Ethics}. Oxford University Press Oxford, 2022.

\bibitem{garcia2012safe}
Javier Garcia and Fernando Fern{\'a}ndez.
\newblock Safe exploration of state and action spaces in reinforcement learning.
\newblock {\em Journal of Artificial Intelligence Research}, 45:515--564, 2012.

\bibitem{llm-bias-2}
Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, and Tushar Khot.
\newblock Bias runs deep: Implicit reasoning biases in persona-assigned {LLMs}.
\newblock {\em arXiv preprint arXiv:2311.04892}, 2023.

\bibitem{llm-bias-4}
Janna Hastings.
\newblock Preventing harm from non-conscious bias in medical generative {AI}.
\newblock {\em The Lancet Digital Health}, 6(1):e2--e3, 2024.

\bibitem{hejna2023few}
Donald~Joseph Hejna~III and Dorsa Sadigh.
\newblock Few-shot preference learning for human-in-the-loop {RL}.
\newblock In {\em Conference on Robot Learning}, pages 2014--2025. PMLR, 2023.

\bibitem{ethics_dataset}
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt.
\newblock Aligning {AI} with shared human values.
\newblock {\em arXiv preprint arXiv:2008.02275}, 2020.

\bibitem{jiminy_cricket}
Dan Hendrycks, Mantas Mazeika, Andy Zou, Sahil Patel, Christine Zhu, Jesus Navarro, Dawn Song, Bo~Li, and Jacob Steinhardt.
\newblock What would {Jiminy Cricket} do? towards agents that behave morally.
\newblock {\em arXiv preprint arXiv:2110.13136}, 2021.

\bibitem{hort2022bia}
Max Hort, Zhenpeng Chen, Jie~M Zhang, Federica Sarro, and Mark Harman.
\newblock Bias mitigation for machine learning classifiers: A comprehensive survey.
\newblock {\em arXiv preprint arXiv:2207.07068}, 2022.

\bibitem{ai_alignment_survey}
Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, et~al.
\newblock {AI} alignment: A comprehensive survey.
\newblock {\em arXiv preprint arXiv:2310.19852}, 2023.

\bibitem{krasanakis2018adaptive}
Emmanouil Krasanakis, Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, and Yiannis Kompatsiaris.
\newblock Adaptive sensitive reweighting to mitigate bias in fairness-aware classification.
\newblock In {\em Proceedings of the 2018 World Wide Web Conference}, pages 853--862, 2018.

\bibitem{doc2vec}
Quoc Le and Tomas Mikolov.
\newblock Distributed representations of sentences and documents.
\newblock In {\em International Conference on Machine Learning}, pages 1188--1196. PMLR, 2014.

\bibitem{ra-2}
Raja Marjieh, Ilia Sucholutsky, Ted Sumers, Nori Jacoby, and Tom Griffiths.
\newblock Predicting human similarity judgments using large language models.
\newblock In {\em Proceedings of the Annual Meeting of the Cognitive Science Society}, volume~44, 2022.

\bibitem{ra-5}
Raja Marjieh, Ilia Sucholutsky, Pol van Rijn, Nori Jacoby, and Thomas~L Griffiths.
\newblock What language reveals about perception: Distilling psychophysical knowledge from large language models.
\newblock {\em arXiv preprint arXiv:2302.01308}, 2023.

\bibitem{language_and_perception}
Raja Marjieh, Ilia Sucholutsky, Pol van Rijn, Nori Jacoby, and Tom Griffiths.
\newblock What language reveals about perception: Distilling psychophysical knowledge from large language models.
\newblock {\em Proceedings of the Annual Meeting of the Cognitive Science Society}, 45, 2023.

\bibitem{ra-4}
Raja Marjieh, Pol Van~Rijn, Ilia Sucholutsky, Theodore Sumers, Harin Lee, Thomas~L Griffiths, and Nori Jacoby.
\newblock Words are all you need? language as an approximation for human similarity judgments.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{marjieh2023words}
Raja Marjieh, Pol van Rijn, Ilia Sucholutsky, Theodore~R. Sumers, Harin Lee, Thomas~L. Griffiths, and Nori Jacoby.
\newblock Words are all you need? language as an approximation for human similarity judgments, 2023.

\bibitem{ra-1}
Gabriele Merlin and Mariya Toneva.
\newblock Language models and brain alignment: beyond word-level semantics and prediction.
\newblock {\em arXiv preprint arXiv:2212.00596}, 2022.

\bibitem{ra-3}
Lukas Muttenthaler, Jonas Dippel, Lorenz Linhardt, Robert~A Vandermeulen, and Simon Kornblith.
\newblock Human alignment of neural network representations.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{muttenthaler2023human}
Lukas Muttenthaler, Jonas Dippel, Lorenz Linhardt, Robert~A. Vandermeulen, and Simon Kornblith.
\newblock Human alignment of neural network representations, 2023.

\bibitem{muttenthaler2023improving}
Lukas Muttenthaler, Lorenz Linhardt, Jonas Dippel, Robert~A. Vandermeulen, Katherine Hermann, Andrew~K. Lampinen, and Simon Kornblith.
\newblock Improving neural network representations using human similarity judgments, 2023.

\bibitem{representational_alignment_human_perception}
Vedant Nanda, Ayan Majumdar, Camila Kolling, John~P. Dickerson, Krishna~P. Gummadi, Bradley~C. Love, and Adrian Weller.
\newblock Exploring alignment of representations with human perception.
\newblock {\em arXiv:2111.14726}, 2021.

\bibitem{globalization_color_perception}
Jakob Niedermann, Ilia Sucholutsky, Raja Marjieh, Elif Celen, Thomas~L Griffiths, Nori Jacoby, and Pol van Rijn.
\newblock Studying the effect of globalization on color perception using multilingual online recruitment and large language models, 2024.

\bibitem{oktar2023dimensions}
Kerem Oktar, Ilia Sucholutsky, Tania Lombrozo, and Thomas~L Griffiths.
\newblock Dimensions of disagreement: Unpacking divergence and misalignment in cognitive science and artificial intelligence.
\newblock {\em arXiv preprint arXiv:2310.12994}, 2023.

\bibitem{improving-nn-human-representation-correspondence}
Joshua~C. Peterson, Joshua~T. Abbott, and Thomas~L. Griffiths.
\newblock Evaluating (and improving) the correspondence between deep neural networks and human representations.
\newblock {\em Cognitive Science}, 42(8):2648--2669, 2018.

\bibitem{kr_explanation}
Adityanarayanan Radhakrishnan.
\newblock Lecture 3: Kernel regression, January 2022.

\bibitem{rane2024concept}
Sunayana Rane, Polyphony~J Bruna, Ilia Sucholutsky, Christopher Kello, and Thomas~L Griffiths.
\newblock Concept alignment.
\newblock {\em arXiv preprint arXiv:2401.08672}, 2024.

\bibitem{rane2023concept}
Sunayana Rane, Mark Ho, Ilia Sucholutsky, and Thomas~L Griffiths.
\newblock Concept alignment as a prerequisite for value alignment.
\newblock {\em arXiv preprint arXiv:2310.20059}, 2023.

\bibitem{gp_explanation}
Carl~Edward Rasmussen and Christopher K.~I. Williams, editors.
\newblock {\em {Gaussian Processes for Machine Learning}}.
\newblock The MIT Press, 2005.

\bibitem{reimers-2019-sentence-bert}
Nils Reimers and Iryna Gurevych.
\newblock {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}.
\newblock In {\em {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing}}. Association for Computational Linguistics, 11 2019.

\bibitem{reimers2021curse}
Nils Reimers and Iryna Gurevych.
\newblock The curse of dense low-dimensional information retrieval for large index sizes.
\newblock {\em arXiv preprint arXiv:2012.14210}, 2020.

\bibitem{reimers-2020-multilingual-sentence-bert}
Nils Reimers and Iryna Gurevych.
\newblock Making monolingual sentence embeddings multilingual using knowledge distillation.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing}. Association for Computational Linguistics, 11 2020.

\bibitem{value_aligned_rl_2}
Soto Rodriguez, Marc Serramia, Maite Lopez-Sanchez, and Juan~Antonio Rodriguez-Aguilar.
\newblock Instilling moral value alignment by means of multi‚Äëobjective reinforcement learning.
\newblock 2022.

\bibitem{thompson_sampling_explanation}
Daniel~J. Russo, Benjamin~Van Roy, Abbas Kazerouni, Ian Osband, and Zheng Wen.
\newblock A tutorial on thompson sampling, November 2017.

\bibitem{human-machine-reps-2}
Jake Spicer and Adam~N Sanborn.
\newblock What does the mind learn? a comparison of human and machine learning representations.
\newblock {\em Current Opinion in Neurobiology}, 55:97--102, 2019.

\bibitem{representational_alignment_few_shot_learning}
Ilia Sucholutsky and Thomas~L. Griffiths.
\newblock Alignment with human representations supports robust few-shot learning.
\newblock {\em arXiv:2301.11990}, 2023.

\bibitem{sucholutsky2023getting}
Ilia Sucholutsky, Lukas Muttenthaler, Adrian Weller, Andi Peng, Andreea Bobu, Been Kim, Bradley~C Love, Erin Grant, Jascha Achterberg, Joshua~B Tenenbaum, et~al.
\newblock Getting aligned on representational alignment.
\newblock {\em arXiv preprint arXiv:2310.13018}, 2023.

\bibitem{thakur2021augmented}
Nandan Thakur, Nils Reimers, Johannes Daxenberger, and Iryna Gurevych.
\newblock Augmented {SBERT}: Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks.
\newblock {\em arXiv preprint arXiv:2010.08240}, 2020.

\bibitem{thakur2021beir}
Nandan Thakur, Nils Reimers, Andreas R{\"u}ckl{\'e}, Abhishek Srivastava, and Iryna Gurevych.
\newblock {BEIR}: A heterogenous benchmark for zero-shot evaluation of information retrieval models.
\newblock {\em arXiv preprint arXiv:2104.08663}, 2021.

\bibitem{wang2021tsdae}
Kexin Wang, Nils Reimers, and Iryna Gurevych.
\newblock {TSDAE}: Using transformer-based sequential denoising auto-encoder for unsupervised sentence embedding learning.
\newblock {\em arXiv preprint arXiv:2104.06979}, 2021.

\bibitem{llm-bias-3}
Melissa Warr, Nicole~Jakubczyk Oster, and Roger Isaac.
\newblock Implicit bias in large language models: Experimental proof and implications for education.
\newblock {\em Available at SSRN 4625078}, 2023.

\bibitem{imitation-learning-survey}
Maryam Zare, Parham Kebria, Abbas Khoshravi, and Saeid Nahavandi.
\newblock A survey of imitation learning: Algorithms, recent developments, and challenges.
\newblock {\em arXiv preprint arXiv:2309.02473}, 2023.

\bibitem{rep-e}
Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, Shashwat Goel, Nathaniel Li, Michael~J. Byun, Zifan Wang, Alex Mallen, Steven Basart, Sanmi Koyejo, Dawn Song, Matt Fredrikson, J.~Zico Kolter, and Dan Hendrycks.
\newblock Representation engineering: A top-down approach to {AI} transparency.
\newblock {\em arXiv preprint arXiv:2310.01405}, 2023.

\end{thebibliography}
