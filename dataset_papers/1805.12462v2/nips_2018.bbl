\begin{thebibliography}{10}

\bibitem{abadi2016tensorflow}
Mart{\'\i}n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
  Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et~al.
\newblock {TensorFlow}: A system for large-scale machine learning.
\newblock In {\em OSDI}, volume~16, pages 265--283, 2016.

\bibitem{pmlr-v70-arjovsky17a}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock {W}asserstein {G}enerative {A}dversarial {N}etworks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of {\em Proceedings of Machine Learning Research}, pages
  214--223, 2017.

\bibitem{arora2018gans}
Sanjeev Arora, Andrej Risteski, and Yi~Zhang.
\newblock Do {GAN}s learn the distribution? some theory and empirics.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{bell1997edges}
Anthony~J Bell and Terrence~J Sejnowski.
\newblock Edges are the 'independent components' of natural scenes.
\newblock In {\em Advances in neural information processing systems}, pages
  831--837, 1997.

\bibitem{berthelot2017began}
David Berthelot, Tom Schumm, and Luke Metz.
\newblock {BEGAN}: Boundary equilibrium generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1703.10717}, 2017.

\bibitem{chen2016infogan}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Info{GAN}: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2172--2180, 2016.

\bibitem{daniel1995biostatistics}
Wayne~W Daniel and Chad~Lee Cross.
\newblock Biostatistics: a foundation for analysis in the health sciences.
\newblock 1995.

\bibitem{danihelka2017comparison}
Ivo Danihelka, Balaji Lakshminarayanan, Benigno Uria, Daan Wierstra, and Peter
  Dayan.
\newblock Comparison of maximum likelihood and {GAN}-based training of {Real
  NVPs}.
\newblock {\em arXiv preprint arXiv:1705.05263}, 2017.

\bibitem{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using {Real NVP}.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{fedus2017many}
William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew~M Dai, Shakir
  Mohamed, and Ian Goodfellow.
\newblock Many paths to equilibrium: {GANs} do not need to decrease a
  divergence at every step.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{ghahramani1996algorithm}
Zoubin Ghahramani, Geoffrey~E Hinton, et~al.
\newblock The {EM} algorithm for mixtures of factor analyzers.
\newblock Technical report, Technical Report CRG-TR-96-1, University of
  Toronto, 1996.

\bibitem{goodfellow2016nips}
Ian Goodfellow.
\newblock {NIPS} 2016 tutorial: Generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1701.00160}, 2016.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem{grover2018flow}
Aditya Grover, Manik Dhar, and Stefano Ermon.
\newblock {Flow-GAN}: Combining maximum likelihood and adversarial learning in
  generative models.
\newblock In {\em AAAI Conference on Artificial Intelligence}, 2018.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of wasserstein {GANs}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5769--5779, 2017.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock {GAN}s trained by a two time-scale update rule converge to a local
  {N}ash equilibrium.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6626--6637, 2017.

\bibitem{hou2017deep}
Xianxu Hou, Linlin Shen, Ke~Sun, and Guoping Qiu.
\newblock Deep feature consistent variational autoencoder.
\newblock In {\em Applications of Computer Vision (WACV), 2017 IEEE Winter
  Conference on}, pages 1133--1141. IEEE, 2017.

\bibitem{im2018quantitatively}
Daniel~Jiwoong Im, He~Ma, Graham Taylor, and Kristin Branson.
\newblock Quantitatively evaluating {GANs} with divergences proposed for
  training.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{Isola_2017_CVPR}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A. Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In {\em The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, July 2017.

\bibitem{karras2017progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of {GANs} for improved quality, stability, and
  variation.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational {B}ayes.
\newblock {\em International Conference on Learning Representations}, 2014.

\bibitem{knott1999latent}
Martin Knott and David~J Bartholomew.
\newblock {\em Latent variable models and factor analysis}.
\newblock Number~7. Edward Arnold, 1999.

\bibitem{kolesnikov2017pixelcnn}
Alexander Kolesnikov and Christoph~H Lampert.
\newblock {PixelCNN} models with auxiliary variables for natural image
  modeling.
\newblock In {\em International Conference on Machine Learning}, pages
  1905--1914, 2017.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{li2017mmd}
Chun-Liang Li, Wei-Cheng Chang, Yu~Cheng, Yiming Yang, and Barnabas Poczos.
\newblock {MMD GAN}: Towards deeper understanding of moment matching network.
\newblock In {\em Advances in Neural Information Processing Systems 30}, pages
  2203--2213. 2017.

\bibitem{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In {\em Proceedings of International Conference on Computer Vision
  (ICCV)}, 2015.

\bibitem{lucic2017gans}
Mario Lučić, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier
  Bousquet.
\newblock Are {GAN}s created equal? a large-scale study.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  2018.

\bibitem{metz2016unrolled}
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein.
\newblock Unrolled generative adversarial networks.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{netzer2011reading}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In {\em NIPS workshop on deep learning and unsupervised feature
  learning}, volume 2011, page~5, 2011.

\bibitem{odena2016conditional}
Augustus Odena, Christopher Olah, and Jonathon Shlens.
\newblock Conditional image synthesis with auxiliary classifier {GAN}s.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, pages 2642--2651, 2017.

\bibitem{olshausen1996emergence}
Bruno~A Olshausen and David~J Field.
\newblock Emergence of simple-cell receptive field properties by learning a
  sparse code for natural images.
\newblock {\em Nature}, 381(6583):607, 1996.

\bibitem{radford2015unsupervised}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock {\em International Conference on Learning Representations}, 2016.

\bibitem{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training {GANs}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2234--2242, 2016.

\bibitem{srivastava2017veegan}
Akash Srivastava, Lazar Valkoz, Chris Russell, Michael~U Gutmann, and Charles
  Sutton.
\newblock {VEEGAN}: Reducing mode collapse in {GANs} using implicit variational
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3308--3318, 2017.

\bibitem{tipping1999mixtures}
Michael~E Tipping and Christopher~M Bishop.
\newblock Mixtures of probabilistic principal component analyzers.
\newblock {\em Neural computation}, 11(2):443--482, 1999.

\bibitem{tipping1999probabilistic}
Michael~E Tipping and Christopher~M Bishop.
\newblock Probabilistic principal component analysis.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 61(3):611--622, 1999.

\bibitem{uria2013rnade}
Benigno Uria, Iain Murray, and Hugo Larochelle.
\newblock Rnade: The real-valued neural autoregressive density-estimator.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2175--2183, 2013.

\bibitem{van2016conditional}
Aaron van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4790--4798, 2016.

\bibitem{oord2016pixel}
Aaron Van~Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  1747--1756, 2016.

\bibitem{wu2016quantitative}
Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, and Roger Grosse.
\newblock On the quantitative analysis of decoder-based generative models.
\newblock 2017.

\bibitem{zoran2011learning}
Daniel Zoran and Yair Weiss.
\newblock From learning models of natural image patches to whole image
  restoration.
\newblock In {\em Computer Vision (ICCV), 2011 IEEE International Conference
  on}, pages 479--486. IEEE, 2011.

\end{thebibliography}
