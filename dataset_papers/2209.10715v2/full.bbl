\begin{thebibliography}{74}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Shahriari et~al.(2016)Shahriari, Swersky, Wang, Adams, and {De
  Freitas}]{Shahriari2016}
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan~P. Adams, and Nando {De
  Freitas}.
\newblock {Taking the human out of the loop: A review of Bayesian
  optimization}.
\newblock \emph{Proceedings of the IEEE}, 104\penalty0 (1):\penalty0 148--175,
  2016.

\bibitem[Rasmussen and Williams(2006)]{Rasmussen2006}
Carl~E. Rasmussen and Christopher K.~I. Williams.
\newblock \emph{{Gaussian Processes for Machine Learning}}.
\newblock The MIT Press, Cambridge, MA, 2006.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{Srinivas2010}
Niranjan Srinivas, Andreas Krause, Sham~M. Kakade, and Matthias Seeger.
\newblock {Gaussian Process Optimization in the Bandit Setting: No Regret and
  Experimental Design}.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML 2010)}, pages 1015--1022, 2010.

\bibitem[Bull(2011)]{Bull2011}
Adam~D. Bull.
\newblock {Convergence Rates of Efficient Global Optimization Algorithms}.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 12:\penalty0
  2879--2904, 2011.

\bibitem[Wang et~al.(2018)Wang, Kim, and Kaelbling]{Wang2018meta}
Zi~Wang, Beomjoon Kim, and Leslie Kaelbling.
\newblock Regret bounds for meta {Bayesian} optimization with an unknown
  {Gaussian} process prior.
\newblock In \emph{Conference on Neural Information Processing Systems},
  Montreal, Canada, 2018.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{Snoek2015}
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish,
  Narayanan Sundaram, M~Patwary, Prabhat, and R~Adams.
\newblock Scalable {Bayesian} optimization using deep neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, Lille,
  France, 2015.

\bibitem[Springenberg et~al.(2016)Springenberg, Aaron, Falkner, and
  Hutter]{Springenberg2016}
Jost~Tobias Springenberg, Klein Aaron, Stefan Falkner, and Frank Hutter.
\newblock {Bayesian} optimization with robust {Bayesian} neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  Barcelona, Spain, 2016.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and Leyton-Brown]{Hutter2011smac}
Frank Hutter, Holger~H Hoos, and Kevin Leyton-Brown.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{International conference on learning and intelligent
  optimization}, pages 507--523. Springer, 2011.

\bibitem[Tiao et~al.(2021)Tiao, Klein, Seeger, Bonilla, Archambeau, and
  Ramos]{tiao2021bore}
Louis~C Tiao, Aaron Klein, Matthias Seeger, Edwin~V Bonilla, C\'{e}dric
  Archambeau, and Fabio Ramos.
\newblock {B}ayesian {O}ptimization by {D}ensity-{R}atio {E}stimation.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research. PMLR, Jul 2021.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{Snoek2012}
Jasper Snoek, Hugo Larochelle, and Ryan~P. Adams.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In F.~Pereira, C.~J.~C. Burges, L.~Bottou, and K.~Q. Weinberger,
  editors, \emph{Advances in Neural Information Processing Systems 25}, pages
  2951--2959. Curran Associates, Inc., 2012.

\bibitem[Gonzalez et~al.(2016)Gonzalez, Dai, Hennig, and
  Lawrence]{Gonzalez2016batch}
Javier Gonzalez, Zhenwen Dai, Philipp Hennig, and Neil~D. Lawrence.
\newblock Batch {Bayesian} optimization via local penalization.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, pages 648--657, Cadiz, Spain, 2016.

\bibitem[Wang et~al.(2017)Wang, Li, Jegelka, and Kohli]{Wang2017batch}
Zi~Wang, Chengtao Li, Stefanie Jegelka, and Pushmeet Kohli.
\newblock Batched high-dimensional {Bayesian} optimization via structural
  kernel learning.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of \emph{Proceedings of Machine Learning Research},
  pages 3656--3664, International Convention Centre, Sydney, Australia, 2017.
  PMLR.

\bibitem[Wilson et~al.(2018)Wilson, Hutter, and Deisenroth]{Wilson2018}
James~T. Wilson, Frank Hutter, and Marc~Peter Deisenroth.
\newblock Maximizing acquisition functions for {Bayesian} optimization.
\newblock In \emph{32nd Conference on Neural Information Processing Systems
  (NeurIPS 2018)}, Montr{\'{e}}al, Canada, 2018.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and {W. J. Welch}]{Jones1998}
D.~R. Jones, M.~Schonlau, and {W. J. Welch}.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global Optimization}, 13:\penalty0 455--492, 1998.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra2011algorithms}
James~S Bergstra, R{\'e}mi Bardenet, Yoshua Bengio, and Bal{\'a}zs K{\'e}gl.
\newblock {A}lgorithms for {H}yper-parameter {O}ptimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2546--2554, 2011.

\bibitem[Sugiyama et~al.(2012)Sugiyama, Hachiya, Yamada, Simm, and
  Nam]{Sugiyama2012}
Masashi Sugiyama, Hirotaka Hachiya, Makoto Yamada, Jaak Simm, and Hyunha Nam.
\newblock Least-squares probabilistic classifier: A computationally efficient
  alternative to kernel logistic regression.
\newblock In \emph{Proceedings of International Workshop on Statistical Machine
  Learning for Speech Processing (IWSML2012)}, Kyoto, Japan, 2012.

\bibitem[Gneiting and Raftery(2007)]{gneiting2007strictly}
Tilmann Gneiting and Adrian~E Raftery.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock \emph{Journal of the American Statistical Association}, 102\penalty0
  (477):\penalty0 359--378, 2007.

\bibitem[Barron(1994)]{Barron1994approximation}
Andrew~R Barron.
\newblock {Approximation and estimation bounds for artificial neural networks}.
\newblock \emph{Machine learning}, 14\penalty0 (1):\penalty0 115--133, 1994.

\bibitem[Steinwart and Christmann(2009)]{Steinwart2009}
Ingo Steinwart and Andreas Christmann.
\newblock {Fast learning from Non-i.i.d. observations}.
\newblock In \emph{Advances in Neural Information Processing Systems 22}, pages
  1768--1776, 2009.

\bibitem[Selten(1998)]{Selten1998}
Reinhard Selten.
\newblock Axiomatic characterization of the quadratic scoring rule.
\newblock \emph{Experimental Economics}, 1\penalty0 (1):\penalty0 43--62, 1998.

\bibitem[Suykens and Vandewalle(1999)]{Suykens1999}
J.~A.~K. Suykens and J.~Vandewalle.
\newblock Least squares support vector machine classifier.
\newblock \emph{Neural Processing Letters}, 9:\penalty0 293--300, 1999.

\bibitem[Sch\"{o}lkopf and Smola(2002)]{Scholkopf2002}
Bernhard Sch\"{o}lkopf and Alexander~J. Smola.
\newblock \emph{Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT Press, Cambridge, Mass, 2002.

\bibitem[Abbasi-Yadkori et~al.(2010)Abbasi-Yadkori, Pal, and
  Szepesvari]{Abbasi-Yadkori2010}
Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari.
\newblock {Improved Algorithms for Linear Stochastic Bandits}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 1--19, 2010.

\bibitem[Abbasi-Yadkori(2012)]{Abbasi-Yadkori2012}
Yasin Abbasi-Yadkori.
\newblock \emph{{Online Learning for Linearly Parametrized Control Problems}}.
\newblock Phd, University of Alberta, 2012.

\bibitem[Durand et~al.(2018)Durand, Maillard, and Pineau]{Durand2018}
Audrey Durand, Odalric-Ambrym Maillard, and Joelle Pineau.
\newblock Streaming kernel regression with provably adaptive mean, variance,
  and regularization.
\newblock \emph{Journal of Machine Learning Research}, 19\penalty0
  (1):\penalty0 650--683, 2018.

\bibitem[Chowdhury and Gopalan(2017)]{Chowdhury2017}
Sayak~Ray Chowdhury and Aditya Gopalan.
\newblock {On Kernelized Multi-armed Bandits}.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, Sydney, Australia, 2017.

\bibitem[Vakili et~al.(2021)Vakili, Khezeli, and Picheny]{Vakili2021}
Sattar Vakili, Kia Khezeli, and Victor Picheny.
\newblock On information gain and regret bounds in gaussian process bandits.
\newblock In Arindam Banerjee and Kenji Fukumizu, editors, \emph{Proceedings of
  The 24th International Conference on Artificial Intelligence and Statistics},
  volume 130 of \emph{Proceedings of Machine Learning Research}, pages 82--90.
  PMLR, 13--15 Apr 2021.

\bibitem[Bardsley et~al.(2014)Bardsley, Solonen, Haario, and
  Laine]{Bardsley2014}
Johnathan~M Bardsley, Antti Solonen, Heikki Haario, and Marko Laine.
\newblock Randomize-then-optimize: A method for sampling from posterior
  distributions in nonlinear inverse problems.
\newblock \emph{SIAM Journal on Scientific Computing}, 36\penalty0
  (4):\penalty0 A1895 -- A1910, 2014.

\bibitem[Mandt et~al.(2017)Mandt, Hoffman, and Blei]{Mandt2017}
Stephan Mandt, Matthew~D. Hoffman, and David~M. Blei.
\newblock Stochastic gradient descent as approximate {Bayesian} inference.
\newblock \emph{Journal of Machine Learning Research}, 18, 2017.

\bibitem[Russo and {Van Roy}(2016)]{Russo2016}
Daniel Russo and Benjamin {Van Roy}.
\newblock {An Information-Theoretic Analysis of Thompson Sampling}.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 17:\penalty0
  1--30, 2016.

\bibitem[Rokach(2010)]{Rokach2010ensemble}
Lior Rokach.
\newblock Ensemble-based classifiers.
\newblock \emph{Artificial intelligence review}, 33\penalty0 (1):\penalty0
  1--39, 2010.

\bibitem[Penny and Roberts(1999)]{Penny1999bnn}
William~D Penny and Stephen~J Roberts.
\newblock Bayesian neural networks for classification: how useful is the
  evidence framework?
\newblock \emph{Neural networks}, 12\penalty0 (6):\penalty0 877--892, 1999.

\bibitem[Amit and Geman(1997)]{Amit1997forests}
Yali Amit and Donald Geman.
\newblock Shape quantization and recognition with randomized trees.
\newblock \emph{Neural Computation}, 9\penalty0 (7):\penalty0 1545--1588, 07
  1997.

\bibitem[Polson and Sokolov(2017)]{Polson2017}
Nicholas~G. Polson and Vadim Sokolov.
\newblock Deep learning: A {Bayesian} perspective.
\newblock \emph{Bayesian Analysis}, 12\penalty0 (4):\penalty0 1275--1304, 2017.

\bibitem[Liu and Wang(2016)]{Liu2016}
Qiang Liu and Dilin Wang.
\newblock {Stein variational gradient descent: A general purpose Bayesian
  inference algorithm}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Liu(2017)]{Liu2017}
Qiang Liu.
\newblock {Stein variational gradient descent as gradient flow}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8854--8863, Long Beach, CA, USA, 2017.

\bibitem[Korba et~al.(2020)Korba, Salim, Arbel, Luise, and Gretton]{Korba2020}
Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, and Arthur Gretton.
\newblock {A non-asymptotic analysis for Stein variational gradient descent}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  Vancouver, Canada, 2020.

\bibitem[Detommaso et~al.(2018)Detommaso, Cui, Spantini, Marzouk, and
  Scheichl]{Detommaso2018}
Gianluca Detommaso, Tiangang Cui, Alessio Spantini, Youssef Marzouk, and Robert
  Scheichl.
\newblock {A Stein variational Newton method}.
\newblock In \emph{32nd Conference on Neural Information Processing Systems
  (NeurIPS 2018)}, Montr{\'{e}}al, Canada, 2018.

\bibitem[Liu et~al.(2019)Liu, Zhuo, Cheng, Zhang, Zhu, and Carin]{Liu2019}
Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, Jun Zhu, and Lawrence
  Carin.
\newblock Understanding and accelerating particle-based variational inference.
\newblock In \emph{36th International Conference on Machine Learning (ICML
  2019)}, Long Beach, CA, 2019.

\bibitem[Han and Liu(2018)]{Han2018}
Jun Han and Qiang Liu.
\newblock {Stein variational gradient descent without gradient}.
\newblock In \emph{35th International Conference on Machine Learning (ICML
  2018)}, 2018.

\bibitem[Oliveira et~al.(2021)Oliveira, Ott, and Ramos]{Oliveira2021}
Rafael Oliveira, Lionel Ott, and Fabio Ramos.
\newblock No-regret approximate inference via {B}ayesian optimisation.
\newblock In Cassio de~Campos and Marloes~H. Maathuis, editors,
  \emph{Proceedings of the Thirty-Seventh Conference on Uncertainty in
  Artificial Intelligence}, volume 161 of \emph{Proceedings of Machine Learning
  Research}, pages 2082--2092. PMLR, 27--30 Jul 2021.

\bibitem[Schonlau et~al.(1998)Schonlau, Welch, and Jones]{Schonlau1998}
Matthias Schonlau, William~J. Welch, and Donald~R. Jones.
\newblock {Global versus local search in constrained optimization of computer
  models}.
\newblock \emph{New Developments and Applications in Experimental Design},
  34:\penalty0 11--25, 1998.

\bibitem[Azimi et~al.(2010)Azimi, Fern, and Fern]{Azimi2010}
Javad Azimi, Alan Fern, and Xiaoli~Z. Fern.
\newblock {Batch Bayesian optimization via simulation matching}.
\newblock In \emph{Advances in Neural Information Processing Systems 23: 24th
  Annual Conference on Neural Information Processing Systems 2010 (NIPS 2010)},
  2010.

\bibitem[Kandasamy et~al.(2018)Kandasamy, Krishnamurthy, Schneider, and
  Poczos]{Kandasamy2018}
Kirthevasan Kandasamy, Akshay Krishnamurthy, Jeff Schneider, and Barnabas
  Poczos.
\newblock Parallelised {Bayesian} optimisation via {Thompson} sampling.
\newblock In \emph{Proceedings of the 21st International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, Lanzarote, Spain, 2018.

\bibitem[Eriksson et~al.(2019)Eriksson, Pearce, Gardner, Turner, and
  Poloczek]{Eriksson2019}
David Eriksson, Michael Pearce, Jacob~R Gardner, Ryan Turner, and Matthias
  Poloczek.
\newblock Scalable global optimization via local {Bayesian} optimization.
\newblock In \emph{33rd Conference on Neural Information Processing Systems
  (NeurIPS 2019)}, 2019.

\bibitem[Zhang et~al.(2022)Zhang, Yang, Yan, Zhou, and Zeng]{Zhang2022}
Shuhan Zhang, Fan Yang, Changhao Yan, Dian Zhou, and Xuan Zeng.
\newblock An efficient batch-constrained {Bayesian} optimization approach for
  analog circuit synthesis via multiobjective acquisition ensemble.
\newblock \emph{IEEE Transactions on Computer-Aided Design of Integrated
  Circuits and Systems}, 41\penalty0 (1), 2022.

\bibitem[Todorov(2008)]{Todorov2008}
Emanuel Todorov.
\newblock General duality between optimal control and estimation.
\newblock In \emph{Proceedings of the 47th IEEE Conference on Decision and
  Control}, Cancun, Mexico, 2008.

\bibitem[Fellows et~al.(2019)Fellows, Mahajan, Rudner, and
  Whiteson]{Fellows2019}
Matthew Fellows, Anuj Mahajan, Tim G.~J. Rudner, and Shimon Whiteson.
\newblock {VIREL}: A variational inference framework for reinforcement
  learning.
\newblock In \emph{33rd Conference on Neural Information Processing Systems
  (NeurIPS 2019)}, Vancouver, Canada, 2019.

\bibitem[Gong et~al.(2019)Gong, Peng, and Liu]{Gong2019}
Chengyue Gong, Jian Peng, and Qiang Liu.
\newblock {Quantile Stein Variational Gradient Descent for Batch Bayesian
  Optimization}.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, Long Beach, CA, USA, 2019.

\bibitem[Oliveira et~al.(2019)Oliveira, Ott, and Ramos]{Oliveira2019aabi}
Rafael Oliveira, Lionel Ott, and Fabio Ramos.
\newblock {Distributional Bayesian optimisation for variational inference on
  black-box simulators}.
\newblock In \emph{2nd Symposium on Advances in Approximate Bayesian
  Inference}, Vancouver, Canada, 2019.

\bibitem[De~Ath et~al.(2022)De~Ath, Chugh, and Rahat]{DeAth2022mbore}
George De~Ath, Tinkle Chugh, and Alma A.~M. Rahat.
\newblock {MBORE}: Multi-objective {Bayesian} optimisation by density-ratio
  estimation.
\newblock GECCO '22, page 776–785, New York, NY, USA, 2022. Association for
  Computing Machinery.

\bibitem[Song et~al.(2022)Song, Yu, Neiswanger, and Ermon]{Song2022lfbo}
Jiaming Song, Lantao Yu, Willie Neiswanger, and Stefano Ermon.
\newblock A general recipe for likelihood-free {B}ayesian optimization.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, volume 162 of \emph{Proceedings of Machine Learning Research},
  pages 20384--20404. PMLR, 17--23 Jul 2022.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{Lakshminarayanan2017}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock {Simple and Scalable Predictive Uncertainty Estimation using Deep
  Ensembles}.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2017.

\bibitem[Balog and Teh(2015)]{Balog2015}
Matej Balog and Yee~Whye Teh.
\newblock {The Mondrian Process for Machine Learning}.
\newblock Technical report, University of Oxford, 2015.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and Massart]{Boucheron2013}
St{\'{e}}phane Boucheron, G{\'{a}}bor Lugosi, and Pascal Massart.
\newblock \emph{{Concentration inequalities: A Nonasymptotic Theory of
  Independence}}.
\newblock Oxford University Press, 2013.

\bibitem[Munkres(1975)]{Munkres1975}
James~Raymond Munkres.
\newblock \emph{{Topology: a first course}}.
\newblock Prentice Hall, Edgewood Cliffs, NJ, 1975.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{Jacot2018}
Arthur Jacot, Franck Gabriel, and Cl{\'{e}}ment Hongler.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems},
  Montreal, Canada, 2018.

\bibitem[{de G. Matthews} et~al.(2018){de G. Matthews}, Hron, Rowland, Turner,
  and Ghahramani]{Matthews2018}
Alexander~G. {de G. Matthews}, Jiri Hron, Mark Rowland, Richard~E. Turner, and
  Zoubin Ghahramani.
\newblock {Gaussian Process Behaviour in Wide Deep Neural Networks}.
\newblock In \emph{International Conference on Learning Representations},
  Vancouver, Canada, 2018. OpenReview.net.

\bibitem[Gr{\"{u}}new{\"{a}}lder et~al.(2010)Gr{\"{u}}new{\"{a}}lder, Audibert,
  Opper, and Shawe-Taylor]{Grunewalder2010}
Steffen Gr{\"{u}}new{\"{a}}lder, Jean~Yves Audibert, Manfred Opper, and John
  Shawe-Taylor.
\newblock {Regret bounds for Gaussian process bandit problems}.
\newblock In \emph{Journal of Machine Learning Research}, volume~9, pages
  273--280, 2010.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{PyTorch2019}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d'Alch\'{e} Buc,
  E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural Information
  Processing Systems 32}, pages 8024--8035. Curran Associates, Inc., 2019.

\bibitem[Byrd et~al.(1995)Byrd, Lu, Nocedal, and Zhu]{Byrd1995limited}
Richard~H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on scientific computing}, 16\penalty0
  (5):\penalty0 1190--1208, 1995.

\bibitem[authors(2016)]{GPyOpt2016}
The~GPyOpt authors.
\newblock {GPyOpt}: A {B}ayesian optimization framework in python.
\newblock \url{http://github.com/SheffieldML/GPyOpt}, 2016.

\bibitem[Balandat et~al.(2020)Balandat, Karrer, Jiang, Daulton, Letham, Wilson,
  and Bakshy]{Balandat2020botorch}
Maximilian Balandat, Brian Karrer, Daniel~R. Jiang, Samuel Daulton, Benjamin
  Letham, Andrew~Gordon Wilson, and Eytan Bakshy.
\newblock {BoTorch: A Framework for Efficient {Monte-Carlo Bayesian}
  Optimization}.
\newblock In \emph{Advances in Neural Information Processing Systems 33}, 2020.

\bibitem[Kingma and Ba(2015)]{Kingma2015}
Diederik~P Kingma and Jimmy~Lei Ba.
\newblock {Adam: A Method for Stochastic Optimization}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{SciPy2020}
Pauli Virtanen, Ralf Gommers, Travis~E. Oliphant, Matt Haberland, Tyler Reddy,
  David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan
  Bright, St{\'e}fan~J. {van der Walt}, Matthew Brett, Joshua Wilson, K.~Jarrod
  Millman, Nikolay Mayorov, Andrew R.~J. Nelson, Eric Jones, Robert Kern, Eric
  Larson, C~J Carey, {\.I}lhan Polat, Yu~Feng, Eric~W. Moore, Jake
  {VanderPlas}, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen,
  E.~A. Quintero, Charles~R. Harris, Anne~M. Archibald, Ant{\^o}nio~H. Ribeiro,
  Fabian Pedregosa, Paul {van Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Tsanas et~al.(2009)Tsanas, Little, McSharry, and
  Ramig]{Tsanas2009Parkinsons}
Athanasios Tsanas, Max Little, Patrick McSharry, and Lorraine Ramig.
\newblock Accurate telemonitoring of parkinson’s disease progression by
  non-invasive speech tests.
\newblock \emph{Nature Precedings}, pages 1--1, 2009.

\bibitem[Graf et~al.(2011)Graf, Kriegel, Schubert, P{\"o}lsterl, and
  Cavallaro]{Graf2011CTslice}
Franz Graf, Hans-Peter Kriegel, Matthias Schubert, Sebastian P{\"o}lsterl, and
  Alexander Cavallaro.
\newblock 2d image registration in ct images using radial image descriptors.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 607--614. Springer, 2011.

\bibitem[Dua and Graff(2017)]{Dua2019}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Eggensperger et~al.(2021)Eggensperger, M{\"u}ller, Mallik, Feurer,
  Sass, Klein, Awad, Lindauer, and Hutter]{Eggensperger2021hpobench}
Katharina Eggensperger, Philipp M{\"u}ller, Neeratyoy Mallik, Matthias Feurer,
  Rene Sass, Aaron Klein, Noor Awad, Marius Lindauer, and Frank Hutter.
\newblock Hpobench: A collection of reproducible multi-fidelity benchmark
  problems for hpo.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem[Liniger et~al.(2015)Liniger, Domahidi, and Morari]{Liniger2015}
Alexander Liniger, Alexander Domahidi, and Manfred Morari.
\newblock {Optimization-based autonomous racing of 1:43 scale RC cars}.
\newblock \emph{OPTIMAL CONTROL APPLICATIONS AND METHODS}, 36:\penalty0
  628--647, 2015.

\bibitem[Jain and Morari(2020)]{JainRaceOpt2020}
Achin Jain and Manfred Morari.
\newblock {Computing the racing line using Bayesian optimization}.
\newblock In \emph{Proceedings of the 59th IEEE Conference on Decision and
  Control (CDC)}, 2020.

\bibitem[Deng(2012)]{Deng2012mnist}
Li~Deng.
\newblock The mnist database of handwritten digit images for machine learning
  research.
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0
  141--142, 2012.

\bibitem[Falkner et~al.(2018)Falkner, Klein, and Hutter]{Falkner18a}
Stefan Falkner, Aaron Klein, and Frank Hutter.
\newblock {BOHB}: Robust and efficient hyperparameter optimization at scale.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 1437--1446. PMLR,
  10--15 Jul 2018.

\bibitem[Rahimi and Recht(2007)]{Rahimi2007}
Ali Rahimi and Ben Recht.
\newblock {Random features for large-scale kernel machines}.
\newblock In \emph{Advances in Neural Information Processing (NIPS)}, 2007.

\end{thebibliography}
