\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Pieter~Abbeel, and
  Zaremba]{andrychowicz2017hindsight}
Andrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong, R., Welinder, P.,
  McGrew, B., Tobin, J., Pieter~Abbeel, O., and Zaremba, W.
\newblock Hindsight experience replay.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Athey et~al.(2019)Athey, Chetty, Imbens, and Kang]{athey2019surrogate}
Athey, S., Chetty, R., Imbens, G.~W., and Kang, H.
\newblock The surrogate index: Combining short-term proxies to estimate
  long-term treatment effects more rapidly and precisely.
\newblock Technical report, National Bureau of Economic Research, 2019.

\bibitem[Baird(1995)]{baird1995residual}
Baird, L.
\newblock Residual algorithms: Reinforcement learning with function
  approximation.
\newblock In \emph{Machine Learning Proceedings 1995}, pp.\  30--37. Elsevier,
  1995.

\bibitem[Baird~III(1993)]{baird1993advantage}
Baird~III, L.~C.
\newblock Advantage updating.
\newblock Technical report, WRIGHT LAB WRIGHT-PATTERSON AFB OH, 1993.

\bibitem[Bertsekas \& Tsitsiklis(1991)Bertsekas and
  Tsitsiklis]{bertsekas1991analysis}
Bertsekas, D.~P. and Tsitsiklis, J.~N.
\newblock An analysis of stochastic shortest path problems.
\newblock \emph{Mathematics of Operations Research}, 16\penalty0 (3):\penalty0
  580--595, 1991.

\bibitem[Bhandari et~al.(2018)Bhandari, Russo, and Singal]{bhandari2018finite}
Bhandari, J., Russo, D., and Singal, R.
\newblock A finite time analysis of temporal difference learning with linear
  function approximation.
\newblock In \emph{Conference on learning theory}, pp.\  1691--1692. PMLR,
  2018.

\bibitem[Bradtke \& Barto(1996)Bradtke and Barto]{bradtke1996linear}
Bradtke, S.~J. and Barto, A.~G.
\newblock Linear least-squares algorithms for temporal difference learning.
\newblock \emph{Machine learning}, 22\penalty0 (1):\penalty0 33--57, 1996.

\bibitem[Cai et~al.(2019)Cai, Yang, Lee, and Wang]{cai2019neural}
Cai, Q., Yang, Z., Lee, J.~D., and Wang, Z.
\newblock Neural temporal-difference learning converges to global optima.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Chen et~al.(2020)Chen, Devraj, Busic, and Meyn]{chen2020explicit}
Chen, S., Devraj, A., Busic, A., and Meyn, S.
\newblock Explicit mean-square error bounds for monte-carlo and linear
  stochastic approximation.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  4173--4183. PMLR, 2020.

\bibitem[Dayan \& Sejnowski(1994)Dayan and Sejnowski]{dayan1994td}
Dayan, P. and Sejnowski, T.~J.
\newblock Td ($\lambda$) converges with probability 1.
\newblock \emph{Machine Learning}, 14\penalty0 (3):\penalty0 295--301, 1994.

\bibitem[Farias et~al.(2022)Farias, Li, Peng, and Zheng]{farias2022markovian}
Farias, V.~F., Li, A.~A., Peng, T., and Zheng, A.~T.
\newblock Markovian interference in experiments.
\newblock \emph{arXiv preprint arXiv:2206.02371}, 2022.

\bibitem[Ghugare et~al.(2024)Ghugare, Geist, Berseth, and
  Eysenbach]{ghugare2024closing}
Ghugare, R., Geist, M., Berseth, G., and Eysenbach, B.
\newblock Closing the gap between td learning and supervised learning--a
  generalisation point of view.
\newblock \emph{arXiv preprint arXiv:2401.11237}, 2024.

\bibitem[Gr{\"u}new{\"a}lder \& Obermayer(2011)Gr{\"u}new{\"a}lder and
  Obermayer]{grunewalder2011optimal}
Gr{\"u}new{\"a}lder, S. and Obermayer, K.
\newblock The optimal unbiased value estimator and its relation to lstd, td and
  mc.
\newblock \emph{Machine learning}, 83\penalty0 (3):\penalty0 289--330, 2011.

\bibitem[Grunewalder et~al.(2007)Grunewalder, Hochreiter, and
  Obermayer]{grunewalder2007optimality}
Grunewalder, S., Hochreiter, S., and Obermayer, K.
\newblock Optimality of lstd and its relation to mc.
\newblock In \emph{2007 International Joint Conference on Neural Networks},
  pp.\  338--343. IEEE, 2007.

\bibitem[Jaakkola et~al.(1993)Jaakkola, Jordan, and
  Singh]{jaakkola1993convergence}
Jaakkola, T., Jordan, M., and Singh, S.
\newblock Convergence of stochastic iterative dynamic programming algorithms.
\newblock \emph{Advances in neural information processing systems}, 6, 1993.

\bibitem[Khamaru et~al.(2020)Khamaru, Pananjady, Ruan, Wainwright, and
  Jordan]{khamaru2020temporal}
Khamaru, K., Pananjady, A., Ruan, F., Wainwright, M.~J., and Jordan, M.~I.
\newblock Is temporal difference learning optimal? an instance-dependent
  analysis.
\newblock \emph{arXiv preprint arXiv:2003.07337}, 2020.

\bibitem[Lazaric et~al.(2010)Lazaric, Ghavamzadeh, and
  Munos]{lazaric2010finite}
Lazaric, A., Ghavamzadeh, M., and Munos, R.
\newblock Finite-sample analysis of lstd.
\newblock In \emph{ICML-27th International Conference on Machine Learning},
  pp.\  615--622, 2010.

\bibitem[Lu(2005)]{lu2005error}
Lu, F.
\newblock Error bounds in reinforcement learning policy evaluation.
\newblock In \emph{Conference of the Canadian Society for Computational Studies
  of Intelligence}, pp.\  438--449. Springer, 2005.

\bibitem[Maei et~al.(2009)Maei, Szepesvari, Bhatnagar, Precup, Silver, and
  Sutton]{maei2009convergent}
Maei, H., Szepesvari, C., Bhatnagar, S., Precup, D., Silver, D., and Sutton,
  R.~S.
\newblock Convergent temporal-difference learning with arbitrary smooth
  function approximation.
\newblock \emph{Advances in neural information processing systems}, 22, 2009.

\bibitem[Mannor et~al.(2004)Mannor, Simester, Sun, and
  Tsitsiklis]{mannor2004bias}
Mannor, S., Simester, D., Sun, P., and Tsitsiklis, J.~N.
\newblock Bias and variance in value function estimation.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, pp.\ ~72, 2004.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Pananjady \& Wainwright(2020)Pananjady and
  Wainwright]{pananjady2020instance}
Pananjady, A. and Wainwright, M.~J.
\newblock Instance-dependent $\ell_\infty$-bounds for policy evaluation in
  tabular reinforcement learning.
\newblock \emph{IEEE Transactions on Information Theory}, 67\penalty0
  (1):\penalty0 566--585, 2020.

\bibitem[Pires \& Szepesv{\'a}ri(2012)Pires and
  Szepesv{\'a}ri]{pires2012statistical}
Pires, B.~A. and Szepesv{\'a}ri, C.
\newblock Statistical linear estimation with penalized estimators: an
  application to reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1206.6444}, 2012.

\bibitem[Prentice(1989)]{prentice1989surrogate}
Prentice, R.~L.
\newblock Surrogate endpoints in clinical trials: definition and operational
  criteria.
\newblock \emph{Statistics in Medicine}, 8\penalty0 (4):\penalty0 431--440,
  1989.

\bibitem[Puterman(2014)]{puterman2014markov}
Puterman, M.~L.
\newblock \emph{Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 2014.

\bibitem[Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver]{schaul2015prioritized}
Schaul, T., Quan, J., Antonoglou, I., and Silver, D.
\newblock Prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1511.05952}, 2015.

\bibitem[Schultz et~al.(1997)Schultz, Dayan, and Montague]{schultz1997neural}
Schultz, W., Dayan, P., and Montague, P.~R.
\newblock A neural substrate of prediction and reward.
\newblock \emph{Science}, 275\penalty0 (5306):\penalty0 1593--1599, 1997.

\bibitem[Sutton(1988)]{sutton1988learning}
Sutton, R.~S.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3\penalty0 (1):\penalty0 9--44, 1988.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Sutton et~al.(2009)Sutton, Maei, Precup, Bhatnagar, Silver,
  Szepesv{\'a}ri, and Wiewiora]{sutton2009fast}
Sutton, R.~S., Maei, H.~R., Precup, D., Bhatnagar, S., Silver, D.,
  Szepesv{\'a}ri, C., and Wiewiora, E.
\newblock Fast gradient-descent methods for temporal-difference learning with
  linear function approximation.
\newblock In \emph{Proceedings of the 26th annual international conference on
  machine learning}, pp.\  993--1000, 2009.

\bibitem[Szepesv{\'a}ri(2010)]{szepesvari2010algorithms}
Szepesv{\'a}ri, C.
\newblock Algorithms for reinforcement learning.
\newblock \emph{Synthesis lectures on artificial intelligence and machine
  learning}, 4\penalty0 (1):\penalty0 1--103, 2010.

\bibitem[Tagorti \& Scherrer(2015)Tagorti and Scherrer]{tagorti2015rate}
Tagorti, M. and Scherrer, B.
\newblock On the rate of convergence and error bounds for lstd ($\lambda$).
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1521--1529. PMLR, 2015.

\bibitem[Tsitsiklis \& Van~Roy(1996)Tsitsiklis and
  Van~Roy]{tsitsiklis1996analysis}
Tsitsiklis, J. and Van~Roy, B.
\newblock Analysis of temporal-diffference learning with function
  approximation.
\newblock \emph{Advances in neural information processing systems}, 9, 1996.

\bibitem[Tsitsiklis \& Van~Roy(1997)Tsitsiklis and
  Van~Roy]{tsitsiklis1997analysis}
Tsitsiklis, J.~N. and Van~Roy, B.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock \emph{IEEE TRANSACTIONS ON AUTOMATIC CONTROL}, 42\penalty0 (5), 1997.

\bibitem[Wang et~al.(2016)Wang, Bapst, Heess, Mnih, Munos, Kavukcuoglu, and
  de~Freitas]{wang2016sample}
Wang, Z., Bapst, V., Heess, N., Mnih, V., Munos, R., Kavukcuoglu, K., and
  de~Freitas, N.
\newblock Sample efficient actor-critic with experience replay.
\newblock \emph{arXiv preprint arXiv:1611.01224}, 2016.

\end{thebibliography}
