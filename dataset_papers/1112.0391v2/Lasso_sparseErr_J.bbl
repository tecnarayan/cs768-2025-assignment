% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Tibshirani_Lasso_1996_J}
R.~Tibshirani, ``Regression shrinkage and selection via the lasso,'' \emph{J.
  Roy. Statist. Soc. Ser. B}, vol.~58, no.~1, pp. 267--288, 1996.

\bibitem{CT_Dantzig_2007_J}
E.~J. Cand\`{e}s and T.~Tao, ``The {D}antzig selector: statistical estimation
  when p is much larger than n,'' \emph{Ann. Statist.}, vol.~35, no.~6, pp.
  2313--2351, 2007.

\bibitem{YL_2006_J}
M.~Yuan and Y.~Lin, ``Model selection and estimation in regression with grouped
  variables,'' \emph{J. Roy. Statist. Soc. Ser. B}, vol.~68, no.~1, pp. 49--67,
  2006.

\bibitem{ZRY_2009_J}
P.~Zhao, G.~Rocha, and B.~Yu, ``The composite absolute penalties family for
  grouped and hierarchical variable selection,'' \emph{Ann. Statist.}, vol.~37,
  pp. 3469--3497, 2009.

\bibitem{ZY_Lasso_2006_J}
P.~Zhao and B.~Yu, ``On model selection consistency of {L}asso,'' \emph{J.
  Machine Learn. Res.}, vol.~7, pp. 2541--2563, 2006.

\bibitem{MY_Lasso_2009_J}
N.~Meinshausen and B.~Yu, ``Lasso-type recovery of sparse representations for
  high-dimensional data,'' \emph{Ann. Statist.}, vol.~37, no.~1, pp.
  2246--2270, 2009.

\bibitem{MB_Lasso_2008_J}
N.~Meinshausen and P.~B$\ddot{\text{u}}$hlmann, ``High dimensional graphs and
  variable selection with the lasso,'' \emph{Ann. Statist.}, vol.~34, no.~3,
  pp. 1436--1462, 2008.

\bibitem{Wainwright_Lasso_2009_J}
M.~J. Wainwright, ``Sharp thresholds for high-dimensional and noisy sparsity
  recovery using l1-constrained quadratic programming (lasso ),'' \emph{IEEE
  Trans. Inf. Theory}, vol.~55, no.~5, pp. 2183--2202, May 2009.

\bibitem{CP_Lasso_2009_J}
E.~J. Cand\`es and Y.~Plan, ``Near-ideal model selection by l1 minimization,''
  \emph{Ann. Statist.}, vol.~37, pp. 2145--2177, 2009.

\bibitem{BRT_Lasso_2009_J}
P.~Bickel, Y.~Ritov, and A.~Tsybakov, ``Simultaneous analysis of {L}asso and
  {D}antzig selector,'' \emph{Ann. Statist.}, vol.~37, no.~4, pp. 1705--1732,
  2009.

\bibitem{Zhang_2009_J}
T.~Zhang, ``Some sharp performance bounds for least squares regression with l1
  regularization,'' \emph{Ann. Statist.}, vol.~37, no.~5, pp. 2109--2144, 2009.

\bibitem{BTW_2007_J}
F.~Bunea, A.~Tsybakov, and M.~Wegkamp, ``Sparsity oracle inequalities for the
  lasso,'' \emph{Elec. Journal Statist.}, vol.~1, pp. 169--194, 2007.

\bibitem{Bunea_2008}
F.~Bunea, ``Honest variable selection in linear and logistic regression models
  via $\ell_1$ and $\ell_1 + \ell_2$ penalization,'' \emph{Elec. Journal
  Statist.}, vol.~2, pp. 1153--1194, 2008.

\bibitem{OWJ_2011_J}
G.~Obozinski, M.~J. Wainwright, and M.~I. Jordan, ``Support union recovery in
  high-dimensional multivariate regression,'' \emph{Ann. Statist.}, vol.~39,
  no.~1, pp. 1--47, 2011.

\bibitem{HZ_2010_J}
J.~Huang and T.~Zhang, ``The benefit of group sparsity,'' \emph{Ann. Statist.},
  vol.~38, no.~4, pp. 1978--2004, 2010.

\bibitem{Tropp_Relax_2006_J}
J.~A. Tropp, ``Just relax: Convex programming methods for identifying sparse
  signals,'' \emph{IEEE Trans. Inf. Theory}, vol.~51, no.~3, pp. 1030--1051,
  Mar. 2006.

\bibitem{WYGSM_Face_2009_J}
J.~Wright, A.~Y. Yang, A.~Ganesh, S.~S. Sastry, and Y.~Ma, ``Robust face
  recognition via sparse representation,'' \emph{IEEE Trans. Pattern Anal.
  Mach. Intell.}, vol.~31, no.~2, pp. 210--227, Feb. 2009.

\bibitem{EV_2009_C}
E.~Elhamifar and R.~Vidal, ``Sparse subspace clustering,'' in \emph{IEEE Conf.
  Comput. Vis. Patt. Recog. (CVPR)}, Miami Beach, FL, USA, June 2009, pp.
  2790--2797.

\bibitem{LDB_corruption_2009_C}
J.~N. Laska, M.~A. Davenport, and R.~G. Baraniuk, ``Exact signal recovery from
  sparsely corrupted measurements through the pursuit of justice,'' in
  \emph{Asilomar conf. Sig. Sys. Comput.}, Pacific Grove, CA, USA, Nov. 2009,
  pp. 1556--1560.

\bibitem{WM_denseError_2010_J}
J.~Wright and Y.~Ma, ``Dense error correction via l1 minimization,'' \emph{IEEE
  Trans. Inf. Theory}, vol.~56, no.~7, pp. 3540--3560, July 2010.

\bibitem{LWW_grossError_2010_C}
Z.~Li, F.~Wu, and J.~Wright, ``On the systematic measurement matrix for
  compressed sensing in the presence of gross error,'' in \emph{Data compress.
  conf. (DCC)}, Snowbird, UT, USA, Mar. 2010, pp. 356--365.

\bibitem{NT_GrossError_2010_J}
N.~H. Nguyen and T.~D. Tran, ``Exact recoverability from dense corrupted
  observations via $l_1$ minimization,'' Feb. 2011, preprint at
  \url{http://arxiv.org/abs/1102.1227}.

\bibitem{Li_2011_J}
X.~Li, ``Compressed sensing and matrix completion with constant proportion of
  corruptions,'' April 2011, preprint at \url{http://arxiv.org/abs/1104.1041}.

\bibitem{CLMW_RobustPCA_2009_J}
E.~J. Cand\`es, X.~Li, Y.~Ma, and J.~Wright, ``Robust principal component
  analysis?'' \emph{Journal of the ACM}, vol.~58, no.~3, pp. 1--37, May 2011.

\bibitem{XCS_RPCA_2010_C}
H.~Xu, C.~Caramanis, and S.~Sanghavi, ``Robust {PCA} via outlier pursuit,'' in
  \emph{Ad. Neural Infor. Proc. Sys. (NIPS)}, Vancouver, BC, Canada, Dec. 2010,
  pp. 2496--2504.

\bibitem{ANW_RPCA_2011_C}
A.~Agarwal, S.~Negahban, and M.~Wainwright, ``Noisy matrix decomposition via
  convex relaxation: Optimal rates in high dimensions,'' in \emph{Proc. 28th
  Inter. Conf. Mach. Learn. (ICML)}, Bellevue, Washington, USA, June 2011, pp.
  1129--1136.

\bibitem{HBRN_2008_J}
J.~Haupt, W.~Bajwa, M.~Rabbat, and R.~Nowak, ``Compressed sensing for networked
  data,'' \emph{IEEE Signal Process. Mag.}, vol.~25, no.~2, pp. 92--101, Mar.
  2008.

\bibitem{LMJ_2012_J}
Y.~Lee, S.~N. MacEachern, and Y.~Jung, ``Regularization of case-specific
  parameters for robustness and efficiency,'' \emph{Statis. Science}, 2012, to
  appear.

\bibitem{WLJ_2007_J}
H.~Wang, G.~Li, and G.~Jiang, ``Robust regression shrinkage and consistent
  variable selection through the {LAD}-{L}asso,'' \emph{Journal Busi. Econ.
  Statist.}, vol.~25, no.~3, pp. 347--355, July 2007.

\bibitem{CRT_CS_2004_J}
E.~J. Cand\`{e}s, J.Romberg, and T.~Tao, ``Robust uncertainty principles: exact
  signal reconstruction from highly incomplete frequency information,''
  \emph{IEEE Trans. Inf. Theory}, vol.~52, no.~2, pp. 5406--5425, Feb. 2006.

\bibitem{SKPB_2011_C}
C.~Studer, P.~Kuppinger, G.~Pope, and H.~Bolcskei, ``Sparse signal recovery
  from sparsely corrupted measurements,'' in \emph{Proc. Inter. Symp. Inf.
  Theory (ISIT)}, St. Pertersburg, Russia, Aug. 2011, pp. 1422--1426.

\bibitem{SB_2011_J}
C.~Studer and R.~G. Baraniuk, ``Stable restoration and separation of
  approximately sparse signals,'' July 2011, submitted to Applied Comput. Har.
  Anal., Preprint at \url{http://arxiv.org/abs/1107.0420}.

\bibitem{RWY_RE_2010_J}
G.~Raskutti, M.~J. Wainwright, and B.~Yu, ``Restricted eigenvalue properties
  for correlated gaussian designs,'' \emph{J. Machine Learn. Res.}, vol.~11,
  pp. 2241--2259, 2010.

\bibitem{NRWY_2010_J}
S.~Negahban, P.~Ravikumar, M.~J. Wainwright, and B.~Yu, ``A unified framework
  for high-dimensional analysis of {M}-estimators with decomposable
  regularizers,'' in \emph{Ad. Neural Infor. Proc. Sys. (NIPS)}, Vancouver, BC,
  Canada, Dec. 2009.

\bibitem{GB_Lasso_2009_J}
S.~van~de Geer and P.~B$\ddot{\text{u}}$hlmann, ``On the conditions used to
  prove oracle results for the lasso,'' \emph{Elec. J. Statist.}, vol.~3, no.
  1360-1392, 2009.

\bibitem{CRT_Stability_2006a_J}
E.~J. Cand\`{e}s, J.Romberg, and T.~Tao, ``Stable signal recovery from
  incomplete and inaccurate measurements,'' \emph{Comm. Pure Appl. Math.},
  vol.~59, no.~8, pp. 1207--1223, Aug. 2006.

\bibitem{LT_1991_B}
M.~Ledoux and M.~Talagrand, \emph{Probability in Banach Space: Isoperimetry and
  Processes}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 1991.

\bibitem{LPTG_2009_C}
K.~Lounici, M.~Pontil, A.~Tsybakov, and S.~van~de Geer, ``Taking advantage of
  sparsity in multi-task learning,'' in \emph{Proc. Ann. Conf. Learn. Theory},
  Montreal, Canada, June 2009, pp. 73--82.

\bibitem{NW_2011_J}
S.~Negahban and M.~J. Wainwright, ``Simultaneous support recovery in high
  dimensions: Benefits and perils of block
  $\ell_1/\ell_\infty$-regularization,'' \emph{IEEE Trans. Inf. Theory},
  vol.~57, no.~6, pp. 3841--3863, June 2011.

\bibitem{LW_2011_C}
P.-L. Loh and M.~J. Wainwright, ``High-dimensional regression with noisy and
  missing data: Provable guarantees with non-convexity,'' in \emph{Ad. Neural
  Infor. Proc. Sys. (NIPS)}, Granada, Spain, Dec. 2011.

\bibitem{RLLW_SpAM_2009_J}
R.~Ravikumar, J.~Lafferty, H.~Liu, and L.~Wasserman, ``Sparse additive
  models,'' \emph{J. Royal Statist. Soc.: Series B}, vol.~71, no.~5, pp.
  1009--1030, Nov. 2009.

\bibitem{MGB_2009_J}
L.~Meier, S.~van~de Geer, and P.~B$\ddot{\text{u}}$hlmann, ``High-dimensional
  additive modeling,'' \emph{Ann. Statist.}, vol.~37, no.~6B, pp. 3779--3821,
  2009.

\bibitem{LM_1998_J}
B.~Laurent and P.~Massart, ``Adaptive estimation of a quadratic functional by
  model selection,'' \emph{Ann. Statist.}, vol.~28, no.~5, pp. 1303--1338,
  1998.

\bibitem{Ledoux_2001_B}
M.~Ledoux, \emph{The Concentration of Measure Phenomenon}.\hskip 1em plus 0.5em
  minus 0.4em\relax American Math. Soc., 2001.

\end{thebibliography}
