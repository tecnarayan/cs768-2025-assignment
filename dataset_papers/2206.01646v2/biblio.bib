@inproceedings{dwibedi2021little,
  title={With a little help from my friends: Nearest-neighbor contrastive learning of visual representations},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9588--9597},
  year={2021}
}


@article{saunshi2022understanding,
  title={Understanding Contrastive Learning Requires Incorporating Inductive Biases},
  author={Saunshi, Nikunj and Ash, Jordan and Goel, Surbhi and Misra, Dipendra and Zhang, Cyril and Arora, Sanjeev and Kakade, Sham and Krishnamurthy, Akshay},
  journal={ICML},
  year={2022}
}


@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{you2017large,
  title={Large batch training of convolutional networks},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{yu2014fine,
  title={Fine-grained visual comparisons with local learning},
  author={Yu, Aron and Grauman, Kristen},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={192--199},
  year={2014}
}


@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}


@inproceedings{coates2011analysis,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={215--223},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}


@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@inproceedings{sowrirajan2021moco,
  title={Moco pretraining improves representation and transferability of chest x-ray models},
  author={Sowrirajan, Hari and Yang, Jingbo and Ng, Andrew Y and Rajpurkar, Pranav},
  booktitle={Medical Imaging with Deep Learning},
  pages={728--744},
  year={2021},
  organization={PMLR}
}

@article{zhai2019large,
  title={A large-scale study of representation learning with the visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  journal={arXiv preprint arXiv:1910.04867},
  year={2019}
}

@article{bressem2020comparing,
  title={Comparing different deep learning architectures for classification of chest radiographs},
  author={Bressem, Keno K and Adams, Lisa C and Erxleben, Christoph and Hamm, Bernd and Niehues, Stefan M and Vahldiek, Janis L},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--16},
  year={2020},
  publisher={Nature Publishing Group}
}


@inproceedings{huang2021gloria,
  title={Gloria: A multimodal global-local representation learning framework for label-efficient medical image recognition},
  author={Huang, Shih-Cheng and Shen, Liyue and Lungren, Matthew P and Yeung, Serena},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3942--3951},
  year={2021}
}

@article{robinson2021can,
  title={Can contrastive learning avoid shortcut solutions?},
  author={Robinson, Joshua and Sun, Li and Yu, Ke and Batmanghelich, Kayhan and Jegelka, Stefanie and Sra, Suvrit},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={4974--4986},
  year={2021}
}


@inproceedings{irvin2019chexpert,
  title={Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison},
  author={Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and Ciurea-Ilcus, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  pages={590--597},
  year={2019}
}


@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@article{robinson2020contrastive,
  title={Contrastive learning with hard negative samples},
  author={Robinson, Joshua and Chuang, Ching-Yao and Sra, Suvrit and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:2010.04592},
  year={2020}
}


@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9912--9924},
  year={2020}
}

@inproceedings{chen2021simsiam,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15750--15758},
  year={2021}
}


@inproceedings{tejankar2021isd,
  title={ISD: Self-supervised learning by iterative similarity distillation},
  author={Tejankar, Ajinkya and Koohpayegani, Soroush Abbasi and Pillai, Vipin and Favaro, Paolo and Pirsiavash, Hamed},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9609--9618},
  year={2021}
}


@article{sohn2020fixmatch,
  title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author={Sohn, Kihyuk and Berthelot, David and Carlini, Nicholas and Zhang, Zizhao and Zhang, Han and Raffel, Colin A and Cubuk, Ekin Dogus and Kurakin, Alexey and Li, Chun-Liang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={596--608},
  year={2020}
}


@article{yeh2021decoupled,
  title={Decoupled Contrastive Learning},
  author={Yeh, Chun-Hsiao and Hong, Cheng-Yao and Hsu, Yen-Chi and Liu, Tyng-Luh and Chen, Yubei and LeCun, Yann},
  journal={ECCV},
  year={2022}
}


@article{haochen2021provable,
  title={Provable guarantees for self-supervised deep learning with spectral contrastive loss},
  author={HaoChen, Jeff Z and Wei, Colin and Gaidon, Adrien and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5000--5011},
  year={2021}
}


@article{song2013kernel,
  title={Kernel embeddings of conditional distributions: A unified kernel framework for nonparametric inference in graphical models},
  author={Song, Le and Fukumizu, Kenji and Gretton, Arthur},
  journal={IEEE Signal Processing Magazine},
  volume={30},
  number={4},
  pages={98--111},
  year={2013},
  publisher={IEEE}
}


@inproceedings{cortes2013multi,
  title={Multi-class classification with maximum margin multiple kernel},
  author={Cortes, Corinna and Mohri, Mehryar and Rostamizadeh, Afshin},
  booktitle={International Conference on Machine Learning},
  pages={46--54},
  year={2013},
  organization={PMLR}
}

@article{caron_unsupervised_2019,
	title = {Unsupervised {Pre}-{Training} of {Image} {Features} on {Non}-{Curated} {Data}},
	url = {http://arxiv.org/abs/1905.01278},
	abstract = {Pre-training general-purpose visual features with convolutional neural networks without relying on annotations is a challenging and important task. Most recent efforts in unsupervised feature learning have focused on either small or highly curated datasets like ImageNet, whereas using non-curated raw datasets was found to decrease the feature quality when evaluated on a transfer task. Our goal is to bridge the performance gap between unsupervised methods trained on curated data, which are costly to obtain, and massive raw datasets that are easily available. To that effect, we propose a new unsupervised approach which leverages self-supervision and clustering to capture complementary statistics from large-scale data. We validate our approach on 96 million images from YFCC100M [44], achieving state-of-the-art results among unsupervised methods on standard benchmarks, which conﬁrms the potential of unsupervised learning when only non-curated raw data are available. We also show that pre-training a supervised VGG-16 with our method achieves 74.9\% top-1 classiﬁcation accuracy on the validation set of ImageNet, which is an improvement of +0.8\% over the same network trained from scratch. Our code is available at https://github. com/facebookresearch/DeeperCluster.},
	language = {en},
	urldate = {2021-04-26},
	journal = {arXiv:1905.01278 [cs]},
	author = {Caron, Mathilde and Bojanowski, Piotr and Mairal, Julien and Joulin, Armand},
	month = aug,
	year = {2019},
	note = {arXiv: 1905.01278},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Caron et al. - 2019 - Unsupervised Pre-Training of Image Features on Non.pdf:/home/pgori/Zotero/storage/KIWZNVU8/Caron et al. - 2019 - Unsupervised Pre-Training of Image Features on Non.pdf:application/pdf},
}

@article{xiao_what_2021,
	title = {What {Should} {Not} {Be} {Contrastive} in {Contrastive} {Learning}},
	url = {http://arxiv.org/abs/2008.05659},
	abstract = {Recent self-supervised contrastive methods have been able to produce impressive transferable visual representations by learning to be invariant to different data augmentations. However, these methods implicitly assume a particular set of representational invariances (e.g., invariance to color), and can perform poorly when a downstream task violates this assumption (e.g., distinguishing red vs. yellow cars). We introduce a contrastive learning framework which does not require prior knowledge of speciﬁc, task-dependent invariances. Our model learns to capture varying and invariant factors for visual representations by constructing separate embedding spaces, each of which is invariant to all but one augmentation. We use a multi-head network with a shared backbone which captures information across each augmentation and alone outperforms all baselines on downstream tasks. We further ﬁnd that the concatenation of the invariant and varying spaces performs best across all tasks we investigate, including coarse-grained, ﬁne-grained, and few-shot downstream classiﬁcation tasks, and various data corruptions.},
	language = {en},
	urldate = {2021-04-27},
	journal = {arXiv:2008.05659 [cs]},
	author = {Xiao, Tete and Wang, Xiaolong and Efros, Alexei A. and Darrell, Trevor},
	month = mar,
	year = {2021},
	note = {arXiv: 2008.05659},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Xiao et al. - 2021 - What Should Not Be Contrastive in Contrastive Lear.pdf:/home/pgori/Zotero/storage/3T6K5YI2/Xiao et al. - 2021 - What Should Not Be Contrastive in Contrastive Lear.pdf:application/pdf},
}

@article{goyal_self-supervised_2021,
	title = {Self-supervised {Pretraining} of {Visual} {Features} in the {Wild}},
	url = {http://arxiv.org/abs/2103.01988},
	abstract = {Recently, self-supervised learning methods like MoCo [22], SimCLR [8], BYOL [20] and SwAV [7] have reduced the gap with supervised methods. These results have been achieved in a control environment, that is the highly curated ImageNet dataset. However, the premise of self-supervised learning is that it can learn from any random image and from any unbounded dataset. In this work, we explore if self-supervision lives to its expectation by training large models on random, uncurated images with no supervision. Our ﬁnal SElf-supERvised (SEER) model, a RegNetY with 1.3B parameters trained on 1B random images with 512 GPUs achieves 84.2\% top-1 accuracy, surpassing the best self-supervised pretrained model by 1\% and conﬁrming that self-supervised learning works in a real world setting. Interestingly, we also observe that selfsupervised models are good few-shot learners achieving 77.9\% top-1 with access to only 10\% of ImageNet.},
	language = {en},
	urldate = {2021-04-26},
	journal = {arXiv:2103.01988 [cs]},
	author = {Goyal, Priya and Caron, Mathilde and Lefaudeux, Benjamin and Xu, Min and Wang, Pengchao and Pai, Vivek and Singh, Mannat and Liptchinsky, Vitaliy and Misra, Ishan and Joulin, Armand and Bojanowski, Piotr},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.01988},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {Goyal et al. - 2021 - Self-supervised Pretraining of Visual Features in .pdf:/home/pgori/Zotero/storage/XJBPI98F/Goyal et al. - 2021 - Self-supervised Pretraining of Visual Features in .pdf:application/pdf},
}

@inproceedings{wei_co2_2020,
	title = {{CO2}: {Consistent} {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
	shorttitle = {{CO2}},
	url = {https://openreview.net/forum?id=U4XLJhqwNF1},
	abstract = {Contrastive learning has recently been a core for unsupervised visual representation learning. Without human annotation, the common practice is to perform an instance discrimination task: Given a...},
	language = {en},
	urldate = {2021-04-26},
	author = {Wei, Chen and Wang, Huiyu and Shen, Wei and Yuille, Alan},
	month = sep,
	year = {2020},
	file = {Full Text PDF:/home/pgori/Zotero/storage/PPD6JS62/Wei et al. - 2020 - CO2 Consistent Contrast for Unsupervised Visual R.pdf:application/pdf;Snapshot:/home/pgori/Zotero/storage/FY9AQE7S/forum.html:text/html},
}

@article{bachman2019learning,
  title={Learning representations by maximizing mutual information across views},
  author={Bachman, Philip and Hjelm, R Devon and Buchwalter, William},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{becker1992self,
  title={Self-organizing neural network that discovers surfaces in random-dot stereograms},
  author={Becker, Suzanna and Hinton, Geoffrey E},
  journal={Nature},
  volume={355},
  number={6356},
  pages={161--163},
  year={1992},
  publisher={Nature Publishing Group}
}

@inproceedings{lecun2005loss,
  title={Loss functions for discriminative training of energy-based models},
  author={LeCun, Yann and Huang, Fu Jie},
  booktitle={International Workshop on Artificial Intelligence and Statistics},
  pages={206--213},
  year={2005},
  organization={PMLR}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}


@article{purushwalkam2020demystifying,
  title={Demystifying contrastive self-supervised learning: Invariances, augmentations and dataset biases},
  author={Purushwalkam, Senthil and Gupta, Abhinav},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3407--3418},
  year={2020}
}

@inproceedings{arora_theoretical_2019,
  title={A theoretical analysis of contrastive unsupervised representation learning},
  author={Saunshi, Nikunj and Plevrakis, Orestis and Arora, Sanjeev and Khodak, Mikhail and Khandeparkar, Hrishikesh},
  booktitle={International Conference on Machine Learning},
  pages={5628--5637},
  year={2019},
  organization={PMLR}
}

@article{lee2021predicting,
  title={Predicting what you already know helps: Provable self-supervised learning},
  author={Lee, Jason D and Lei, Qi and Saunshi, Nikunj and Zhuo, Jiacheng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}



@article{li2020prototypical,
  title={Prototypical contrastive learning of unsupervised representations},
  author={Li, Junnan and Zhou, Pan and Xiong, Caiming and Hoi, Steven CH},
  journal={ICLR},
  year={2021}
}

@article{zheng2021ressl,
  title={ReSSL: Relational Self-Supervised Learning with Weak Augmentation},
  author={Zheng, Mingkai and You, Shan and Wang, Fei and Qian, Chen and Zhang, Changshui and Wang, Xiaogang and Xu, Chang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@inproceedings{zheng2021weakly,
  title={Weakly supervised contrastive learning},
  author={Zheng, Mingkai and Wang, Fei and You, Shan and Qian, Chen and Zhang, Changshui and Wang, Xiaogang and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10042--10051},
  year={2021}
}

@inproceedings{graf2021dissecting,
  title={Dissecting supervised constrastive learning},
  author={Graf, Florian and Hofer, Christoph and Niethammer, Marc and Kwitt, Roland},
  booktitle={International Conference on Machine Learning},
  pages={3821--3830},
  year={2021},
  organization={PMLR}
}

@article{shah2020pitfalls,
  title={The pitfalls of simplicity bias in neural networks},
  author={Shah, Harshay and Tamuly, Kaustav and Raghunathan, Aditi and Jain, Prateek and Netrapalli, Praneeth},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9573--9585},
  year={2020}
}


@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@article{bromley1993signature,
  title={Signature verification using a" siamese" time delay neural network},
  author={Bromley, Jane and Guyon, Isabelle and LeCun, Yann and S{\"a}ckinger, Eduard and Shah, Roopak},
  journal={Advances in neural information processing systems},
  volume={6},
  year={1993}
}


@article{zbontar_barlow_2021,
	title = {Barlow {Twins}: {Self}-{Supervised} {Learning} via {Redundancy} {Reduction}},
	shorttitle = {Barlow {Twins}},
	url = {http://arxiv.org/abs/2103.03230},
	abstract = {Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn representations which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant representations. Most current methods avoid such collapsed solutions by careful implementation details. We propose an objective function that naturally avoids such collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the representation vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow's redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. It allows the use of very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.},
	language = {en},
	urldate = {2021-04-27},
	journal = {arXiv:2103.03230 [cs, q-bio]},
	author = {Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, Stéphane},
	month = mar,
	year = {2021},
	note = {tex.ids= zbontar\_barlow\_2021-1
arXiv: 2103.03230},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Zbontar et al. - 2021 - Barlow Twins Self-Supervised Learning via Redunda.pdf:/home/pgori/Zotero/storage/HYNPU2Z7/Zbontar et al. - 2021 - Barlow Twins Self-Supervised Learning via Redunda.pdf:application/pdf;arXiv.org Snapshot:/home/pgori/Zotero/storage/I83VSHFG/2103.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/A9XNTDXG/Zbontar et al. - 2021 - Barlow Twins Self-Supervised Learning via Redunda.pdf:application/pdf},
}

@inproceedings{he_momentum_2020,
	title = {Momentum {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
	urldate = {2021-02-24},
	author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
	booktitle = {CVPR},
	year = {2020},
	pages = {9729--9738},
	file = {Snapshot:/home/pgori/Zotero/storage/6CSWWPHF/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html:text/html;Full Text PDF:/home/pgori/Zotero/storage/JTUFS8TY/He et al. - 2020 - Momentum Contrast for Unsupervised Visual Represen.pdf:application/pdf},
}

@article{chakraborty_g-simclr_2020,
	title = {G-{SimCLR} : {Self}-{Supervised} {Contrastive} {Learning} with {Guided} {Projection} via {Pseudo} {Labelling}},
	shorttitle = {G-{SimCLR}},
	url = {http://arxiv.org/abs/2009.12007},
	abstract = {In the realms of computer vision, it is evident that deep neural networks perform better in a supervised setting with a large amount of labeled data. The representations learned with supervision are not only of high quality but also helps the model in enhancing its accuracy. However, the collection and annotation of a large dataset are costly and time-consuming. To avoid the same, there has been a lot of research going on in the field of unsupervised visual representation learning especially in a self-supervised setting. Amongst the recent advancements in self-supervised methods for visual recognition, in SimCLR Chen et al. shows that good quality representations can indeed be learned without explicit supervision. In SimCLR, the authors maximize the similarity of augmentations of the same image and minimize the similarity of augmentations of different images. A linear classifier trained with the representations learned using this approach yields 76.5\% top-1 accuracy on the ImageNet ILSVRC-2012 dataset. In this work, we propose that, with the normalized temperature-scaled cross-entropy (NT-Xent) loss function (as used in SimCLR), it is beneficial to not have images of the same category in the same batch. In an unsupervised setting, the information of images pertaining to the same category is missing. We use the latent space representation of a denoising autoencoder trained on the unlabeled dataset and cluster them with k-means to obtain pseudo labels. With this apriori information we batch images, where no two images from the same category are to be found. We report comparable performance enhancements on the CIFAR10 dataset and a subset of the ImageNet dataset. We refer to our method as G-SimCLR.},
	urldate = {2021-02-24},
	journal = {arXiv:2009.12007 [cs, stat]},
	author = {Chakraborty, Souradip and Gosthipaty, Aritra Roy and Paul, Sayak},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.12007},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/FZ4CY9SX/2009.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/FQ5CN7M5/Chakraborty et al. - 2020 - G-SimCLR  Self-Supervised Contrastive Learning wi.pdf:application/pdf},
}

@inproceedings{chen_simple_2020,
	title = {A {Simple} {Framework} for {Contrastive} {Learning} of {Visual} {Representations}},
	abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring sp...},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {1597--1607},
	file = {Snapshot:/home/pgori/Zotero/storage/E9UU66XH/chen20j.html:text/html;Full Text PDF:/home/pgori/Zotero/storage/BFD5CASM/Chen et al. - 2020 - A Simple Framework for Contrastive Learning of Vis.pdf:application/pdf},
}


@inproceedings{tian_contrastive_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Contrastive {Multiview} {Coding}},
	isbn = {978-3-030-58621-8},
	doi = {10.1007/978-3-030-58621-8_45},
	abstract = {Humans view the world through many sensory channels, e.g., the long-wavelength light channel, viewed by the left eye, or the high-frequency vibrations channel, heard by the right ear. Each view is noisy and incomplete, but important factors, such as physics, geometry, and semantics, tend to be shared between all views (e.g., a “dog” can be seen, heard, and felt). We investigate the classic hypothesis that a powerful representation is one that models view-invariant factors. We study this hypothesis under the framework of multiview contrastive learning, where we learn a representation that aims to maximize mutual information between different views of the same scene but is otherwise compact. Our approach scales to any number of views, and is view-agnostic. We analyze key properties of the approach that make it work, finding that the contrastive loss outperforms a popular alternative based on cross-view prediction, and that the more views we learn from, the better the resulting representation captures underlying scene semantics. Code is available at: http://github.com/HobbitLong/CMC/.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2020},
	publisher = {Springer International Publishing},
	author = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
	editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
	year = {2020},
	note = {tex.ids= tian\_contrastive\_2020
arXiv: 1906.05849},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {776--794},
	file = {Tian et al. - 2020 - Contrastive Multiview Coding.pdf:/home/pgori/Zotero/storage/NQQQHMQT/Tian et al. - 2020 - Contrastive Multiview Coding.pdf:application/pdf;arXiv.org Snapshot:/home/pgori/Zotero/storage/I8K3GRK7/1906.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/U36UBMTP/Tian et al. - 2020 - Contrastive Multiview Coding.pdf:application/pdf;Submitted Version:/home/pgori/Zotero/storage/96AAVLXG/Tian et al. - 2020 - Contrastive Multiview Coding.pdf:application/pdf},
}

@article{xu_understanding_2021,
	title = {{UNDERSTANDING} {THE} {ROLE} {OF} {IMPORTANCE} {WEIGHT}- {ING} {FOR} {DEEP} {LEARNING}},
	abstract = {The recent paper by Byrd \& Lipton (2019), based on empirical observations, raises a major concern on the impact of importance weighting for the over-parameterized deep learning models. They observe that as long as the model can separate the training data, the impact of importance weighting diminishes as the training proceeds. Nevertheless, there lacks a rigorous characterization of this phenomenon. In this paper, we provide formal characterizations and theoretical justiﬁcations on the role of importance weighting with respect to the implicit bias of gradient descent and margin-based learning theory. We reveal both the optimization dynamics and generalization performance under deep learning models. Our work not only explains the various novel phenomenons observed for importance weighting in deep learning, but also extends to the studies where the weights are being optimized as part of the model, which applies to a number of topics under active research.},
	language = {en},
	author = {Xu, Da},
	year = {2021},
	pages = {20},
	file = {Xu - 2021 - UNDERSTANDING THE ROLE OF IMPORTANCE WEIGHT- ING F.pdf:/home/pgori/Zotero/storage/6RR5QUYU/Xu - 2021 - UNDERSTANDING THE ROLE OF IMPORTANCE WEIGHT- ING F.pdf:application/pdf},
}

@article{tsai2022conditional,
  title={Conditional Contrastive Learning with Kernel},
  author={Tsai, Yao-Hung Hubert and Li, Tianqin and Ma, Martin Q and Zhao, Han and Zhang, Kun and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  journal={ICLR},
  year={2022}
}

@article{chen_intriguing_2021,
  title={Intriguing properties of contrastive losses},
  author={Chen, Ting and Luo, Calvin and Li, Lala},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11834--11845},
  year={2021}
}

@article{wang_understanding_nodate,
	title = {Understanding the {Behaviour} of {Contrastive} {Loss}},
	abstract = {Unsupervised contrastive learning has achieved outstanding success, while the mechanism of contrastive loss has been less studied. In this paper, we concentrate on the understanding of the behaviours of unsupervised contrastive loss. We will show that the contrastive loss is a hardness-aware loss function, and the temperature τ controls the strength of penalties on hard negative samples. The previous study has shown that uniformity is a key property of contrastive learning. We build relations between the uniformity and the temperature τ . We will show that uniformity helps the contrastive learning to learn separable features, however excessive pursuit to the uniformity makes the contrastive loss not tolerant to semantically similar samples, which may break the underlying semantic structure and be harmful to the formation of features useful for downstream tasks. This is caused by the inherent defect of the instance discrimination objective. Speciﬁcally, instance discrimination objective tries to push all different instances apart, ignoring the underlying relations between samples. Pushing semantically consistent samples apart has no positive effect for acquiring a prior informative to general downstream tasks. A well-designed contrastive loss should have some extents of tolerance to the closeness of semantically similar samples. Therefore, we ﬁnd that the contrastive loss meets a uniformity-tolerance dilemma, and a good choice of temperature can compromise these two properties properly to both learn separable features and tolerant to semantically similar samples, improving the feature qualities and the downstream performances.},
	language = {en},
	author = {Wang, Feng and Liu, Huaping},
	pages = {10},
	year={2021},
	file = {Wang et Liu - Understanding the Behaviour of Contrastive Loss.pdf:/home/pgori/Zotero/storage/269VQ6F6/Wang et Liu - Understanding the Behaviour of Contrastive Loss.pdf:application/pdf},
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9640--9649},
  year={2021}
}

@article{sordoni_decomposed_2021,
	title = {Decomposed {Mutual} {Information} {Estimation} for {Contrastive} {Representation} {Learning}},
	url = {http://arxiv.org/abs/2106.13401},
	abstract = {Recent contrastive representation learning methods rely on estimating mutual information (MI) between multiple views of an underlying context. E.g., we can derive multiple views of a given image by applying data augmentation, or we can split a sequence into views comprising the past and future of some step in the sequence. Contrastive lower bounds on MI are easy to optimize, but have a strong underestimation bias when estimating large amounts of MI. We propose decomposing the full MI estimation problem into a sum of smaller estimation problems by splitting one of the views into progressively more informed subviews and by applying the chain rule on MI between the decomposed views. This expression contains a sum of unconditional and conditional MI terms, each measuring modest chunks of the total MI, which facilitates approximation via contrastive bounds. To maximize the sum, we formulate a contrastive lower bound on the conditional MI which can be approximated efficiently. We refer to our general approach as Decomposed Estimation of Mutual Information (DEMI). We show that DEMI can capture a larger amount of MI than standard non-decomposed contrastive bounds in a synthetic setting, and learns better representations in a vision domain and for dialogue generation.},
	urldate = {2021-09-22},
	journal = {arXiv:2106.13401 [cs]},
	author = {Sordoni, Alessandro and Dziri, Nouha and Schulz, Hannes and Gordon, Geoff and Bachman, Phil and Tachet, Remi},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.13401},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/FZUM8AV4/2106.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/CWNWVELQ/Sordoni et al. - 2021 - Decomposed Mutual Information Estimation for Contr.pdf:application/pdf},
}

@article{chen_big_2020,
  title={Big self-supervised models are strong semi-supervised learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22243--22255},
  year={2020}
}

@inproceedings{sohn_improved_2016,
	title = {Improved {Deep} {Metric} {Learning} with {Multi}-class {N}-pair {Loss} {Objective}},
	volume = {29},
	url = {https://papers.nips.cc/paper/2016/hash/6b180037abbebea991d8b1232f8a8ca9-Abstract.html},
	urldate = {2021-09-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Sohn, Kihyuk},
	year = {2016},
	file = {Full Text PDF:/home/pgori/Zotero/storage/6ZWK6SEQ/Sohn - 2016 - Improved Deep Metric Learning with Multi-class N-p.pdf:application/pdf},
}

@inproceedings{verma_towards_2021,
	title = {Towards {Domain}-{Agnostic} {Contrastive} {Learning}},
	url = {https://proceedings.mlr.press/v139/verma21a.html},
	abstract = {Despite recent successes, most contrastive self-supervised learning methods are domain-specific, relying heavily on data augmentation techniques that require knowledge about a particular domain, such as image cropping and rotation. To overcome such limitation, we propose a domain-agnostic approach to contrastive learning, named DACL, that is applicable to problems where domain-specific data augmentations are not readily available. Key to our approach is the use of Mixup noise to create similar and dissimilar examples by mixing data samples differently either at the input or hidden-state levels. We theoretically analyze our method and show advantages over the Gaussian-noise based contrastive learning approach. To demonstrate the effectiveness of DACL, we conduct experiments across various domains such as tabular data, images, and graphs. Our results show that DACL not only outperforms other domain-agnostic noising methods, such as Gaussian-noise, but also combines well with domain-specific methods, such as SimCLR, to improve self-supervised visual representation learning.},
	language = {en},
	urldate = {2021-09-23},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Verma, Vikas and Luong, Thang and Kawaguchi, Kenji and Pham, Hieu and Le, Quoc},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {10530--10541},
	file = {Supplementary PDF:/home/pgori/Zotero/storage/DPLKKV5R/Verma et al. - 2021 - Towards Domain-Agnostic Contrastive Learning.pdf:application/pdf;Full Text PDF:/home/pgori/Zotero/storage/4MHQMH72/Verma et al. - 2021 - Towards Domain-Agnostic Contrastive Learning.pdf:application/pdf},
}

@article{chen_sampling_2017,
	title = {On {Sampling} {Strategies} for {Neural} {Network}-based {Collaborative} {Filtering}},
	url = {http://arxiv.org/abs/1706.07881},
	abstract = {Recent advances in neural networks have inspired people to design hybrid recommendation algorithms that can incorporate both (1) user-item interaction information and (2) content information including image, audio, and text. Despite their promising results, neural network-based recommendation algorithms pose extensive computational costs, making it challenging to scale and improve upon. In this paper, we propose a general neural network-based recommendation framework, which subsumes several existing state-of-the-art recommendation algorithms, and address the efficiency issue by investigating sampling strategies in the stochastic gradient descent training for the framework. We tackle this issue by first establishing a connection between the loss functions and the user-item interaction bipartite graph, where the loss function terms are defined on links while major computation burdens are located at nodes. We call this type of loss functions "graph-based" loss functions, for which varied mini-batch sampling strategies can have different computational costs. Based on the insight, three novel sampling strategies are proposed, which can significantly improve the training efficiency of the proposed framework (up to \${\textbackslash}times 30\$ times speedup in our experiments), as well as improving the recommendation performance. Theoretical analysis is also provided for both the computational cost and the convergence. We believe the study of sampling strategies have further implications on general graph-based loss functions, and would also enable more research under the neural network-based recommendation framework.},
	urldate = {2021-09-23},
	journal = {arXiv:1706.07881 [cs, stat]},
	author = {Chen, Ting and Sun, Yizhou and Shi, Yue and Hong, Liangjie},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.07881},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Information Retrieval, Computer Science - Social and Information Networks},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/NDY6K8V9/1706.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/E868U8ZR/Chen et al. - 2017 - On Sampling Strategies for Neural Network-based Co.pdf:application/pdf},
}

@inproceedings{dufumier_contrastive_2021,
  title={Contrastive learning with continuous proxy meta-data for 3d mri classification},
  author={Dufumier, Benoit and Gori, Pietro and Victor, Julie and Grigis, Antoine and Wessa, Michele and Brambilla, Paolo and Favre, Pauline and Polosan, Mircea and Mcdonald, Colm and Piguet, Camille Marie and others},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={58--68},
  year={2021},
  organization={Springer}
}

@article{chuang_debiased_2020,
  title={Debiased contrastive learning},
  author={Chuang, Ching-Yao and Robinson, Joshua and Lin, Yen-Chen and Torralba, Antonio and Jegelka, Stefanie},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={8765--8775},
  year={2020}
}


@article{nozawa_pac-bayesian_2020,
	title = {{PAC}-{Bayesian} {Contrastive} {Unsupervised} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1910.04464},
	abstract = {Contrastive unsupervised representation learning (CURL) is the state-of-the-art technique to learn representations (as a set of features) from unlabelled data. While CURL has collected several empirical successes recently, theoretical understanding of its performance was still missing. In a recent work, Arora et al. (2019) provide the first generalisation bounds for CURL, relying on a Rademacher complexity. We extend their framework to the flexible PAC-Bayes setting, allowing us to deal with the non-iid setting. We present PAC-Bayesian generalisation bounds for CURL, which are then used to derive a new representation learning algorithm. Numerical experiments on real-life datasets illustrate that our algorithm achieves competitive accuracy, and yields non-vacuous generalisation bounds.},
	urldate = {2021-09-23},
	journal = {arXiv:1910.04464 [cs, math, stat]},
	author = {Nozawa, Kento and Germain, Pascal and Guedj, Benjamin},
	month = jul,
	year = {2020},
	note = {arXiv: 1910.04464},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Statistics Theory},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/GU33LYCU/1910.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/8DWI5RHN/Nozawa et al. - 2020 - PAC-Bayesian Contrastive Unsupervised Representati.pdf:application/pdf},
}

@article{tschannen_mutual_2020,
	title = {On {Mutual} {Information} {Maximization} for {Representation} {Learning}},
	url = {http://arxiv.org/abs/1907.13625},
	abstract = {Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods.},
	urldate = {2021-09-23},
	journal = {arXiv:1907.13625 [cs, stat]},
	author = {Tschannen, Michael and Djolonga, Josip and Rubenstein, Paul K. and Gelly, Sylvain and Lucic, Mario},
	month = jan,
	year = {2020},
	note = {arXiv: 1907.13625},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/UDEM6CI7/1907.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/75LPKHVT/Tschannen et al. - 2020 - On Mutual Information Maximization for Representat.pdf:application/pdf},
}

@article{tian_what_2020,
	title = {What {Makes} for {Good} {Views} for {Contrastive} {Learning}?},
	url = {http://arxiv.org/abs/2005.10243},
	abstract = {Contrastive learning between multiple views of the data has recently achieved state of the art performance in the field of self-supervised representation learning. Despite its success, the influence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classification accuracy. As a by-product, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classification (\$73{\textbackslash}\%\$ top-1 linear readout with a ResNet-50). In addition, transferring our models to PASCAL VOC object detection and COCO instance segmentation consistently outperforms supervised pre-training. Code:http://github.com/HobbitLong/PyContrast},
	urldate = {2021-09-23},
	journal = {arXiv:2005.10243 [cs]},
	author = {Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
	month = dec,
	year = {2020},
	note = {arXiv: 2005.10243},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/6GZ6UBEC/2005.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/U8L4IFGM/Tian et al. - 2020 - What Makes for Good Views for Contrastive Learning.pdf:application/pdf},
}

@article{wu_mutual_2020,
	title = {On {Mutual} {Information} in {Contrastive} {Learning} for {Visual} {Representations}},
	url = {http://arxiv.org/abs/2005.13149},
	abstract = {In recent years, several unsupervised, "contrastive" learning algorithms in vision have been shown to learn representations that perform remarkably well on transfer tasks. We show that this family of algorithms maximizes a lower bound on the mutual information between two or more "views" of an image where typical views come from a composition of image augmentations. Our bound generalizes the InfoNCE objective to support negative sampling from a restricted region of "difficult" contrasts. We find that the choice of negative samples and views are critical to the success of these algorithms. Reformulating previous learning objectives in terms of mutual information also simplifies and stabilizes them. In practice, our new objectives yield representations that outperform those learned with previous approaches for transfer to classification, bounding box detection, instance segmentation, and keypoint detection. \% experiments show that choosing more difficult negative samples results in a stronger representation, outperforming those learned with IR, LA, and CMC in classification, bounding box detection, instance segmentation, and keypoint detection. The mutual information framework provides a unifying comparison of approaches to contrastive learning and uncovers the choices that impact representation learning.},
	urldate = {2021-09-23},
	journal = {arXiv:2005.13149 [cs, stat]},
	author = {Wu, Mike and Zhuang, Chengxu and Mosse, Milan and Yamins, Daniel and Goodman, Noah},
	month = jun,
	year = {2020},
	note = {arXiv: 2005.13149},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/WX7I6UVU/2005.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/R3QEZD8F/Wu et al. - 2020 - On Mutual Information in Contrastive Learning for .pdf:application/pdf},
}

@article{cremer_reinterpreting_2017,
	title = {Reinterpreting {Importance}-{Weighted} {Autoencoders}},
	url = {http://arxiv.org/abs/1704.02916},
	abstract = {The standard interpretation of importance-weighted autoencoders is that they maximize a tighter lower bound on the marginal likelihood than the standard evidence lower bound. We give an alternate interpretation of this procedure: that it optimizes the standard variational lower bound, but using a more complex distribution. We formally derive this result, present a tighter lower bound, and visualize the implicit importance-weighted distribution.},
	urldate = {2021-09-23},
	journal = {arXiv:1704.02916 [stat]},
	author = {Cremer, Chris and Morris, Quaid and Duvenaud, David},
	month = aug,
	year = {2017},
	note = {arXiv: 1704.02916},
	keywords = {Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/H4CNXUNU/1704.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/3JNRAAHR/Cremer et al. - 2017 - Reinterpreting Importance-Weighted Autoencoders.pdf:application/pdf},
}

@article{hadsell_dimensionality_nodate,
	title = {Dimensionality {Reduction} by {Learning} an {Invariant} {Mapping}},
	abstract = {Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that “similar” points in input space are mapped to nearby points on the manifold. Most existing techniques for solving the problem suffer from two drawbacks. First, most of them depend on a meaningful and computable distance metric in input space. Second, they do not compute a “function” that can accurately map new input samples whose relationship to the training data is unknown. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent non-linear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distance measure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.},
	language = {en},
	author = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
	pages = {8},
	file = {Hadsell et al. - Dimensionality Reduction by Learning an Invariant .pdf:/home/pgori/Zotero/storage/CQE8J296/Hadsell et al. - Dimensionality Reduction by Learning an Invariant .pdf:application/pdf},
}

@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={ICLR},
  year={2016}
}

@article{aitchison_infonce_2021,
	title = {{InfoNCE} is a variational autoencoder},
	url = {http://arxiv.org/abs/2107.02495},
	abstract = {We show that a popular self-supervised learning method, InfoNCE, is a special case of a new family of unsupervised learning methods, the self-supervised variational autoencoder (SSVAE). SSVAEs circumvent the usual VAE requirement to reconstruct the data by using a carefully chosen implicit decoder. The InfoNCE objective was motivated as a simplified parametric mutual information estimator. Under one choice of prior, the SSVAE objective (i.e. the ELBO) is exactly equal to the mutual information (up to constants). Under an alternative choice of prior, the SSVAE objective is exactly equal to the simplified parametric mutual information estimator used in InfoNCE (up to constants). Importantly, the use of simplified parametric mutual information estimators is believed to be critical to obtain good high-level representations, and the SSVAE framework naturally provides a principled justification for using prior information to choose these estimators.},
	urldate = {2021-09-23},
	journal = {arXiv:2107.02495 [cs, stat]},
	author = {Aitchison, Laurence},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.02495
version: 1},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/I8RWMJBY/2107.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/G8TH9U4M/Aitchison - 2021 - InfoNCE is a variational autoencoder.pdf:application/pdf},
}

@article{weinberger_distance_nodate,
	title = {Distance {Metric} {Learning} for {Large} {Margin} {Nearest} {Neighbor} {Classiﬁcation}},
	abstract = {The accuracy of k-nearest neighbor (kNN) classiﬁcation depends signiﬁcantly on the metric used to compute distances between different examples. In this paper, we show how to learn a Mahalanobis distance metric for kNN classiﬁcation from labeled examples. The Mahalanobis metric can equivalently be viewed as a global linear transformation of the input space that precedes kNN classiﬁcation using Euclidean distances. In our approach, the metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. As in support vector machines (SVMs), the margin criterion leads to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our approach requires no modiﬁcation or extension for problems in multiway (as opposed to binary) classiﬁcation. In our framework, the Mahalanobis distance metric is obtained as the solution to a semideﬁnite program. On several data sets of varying size and difﬁculty, we ﬁnd that metrics trained in this way lead to signiﬁcant improvements in kNN classiﬁcation. Sometimes these results can be further improved by clustering the training examples and learning an individual metric within each cluster. We show how to learn and combine these local metrics in a globally integrated manner.},
	language = {en},
	author = {Weinberger, Kilian Q and Saul, Lawrence K},
	pages = {38},
	file = {Weinberger and Saul - Distance Metric Learning for Large Margin Nearest .pdf:/home/pgori/Zotero/storage/Z7244VD7/Weinberger and Saul - Distance Metric Learning for Large Margin Nearest .pdf:application/pdf},
}

@article{schroff_facenet_2015,
	title = {{FaceNet}: {A} {Unified} {Embedding} for {Face} {Recognition} and {Clustering}},
	shorttitle = {{FaceNet}},
	url = {http://arxiv.org/abs/1503.03832},
	doi = {10.1109/CVPR.2015.7298682},
	abstract = {Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63\%. On YouTube Faces DB it achieves 95.12\%. Our system cuts the error rate in comparison to the best published result by 30\% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.},
	urldate = {2021-09-23},
	journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
	month = jun,
	year = {2015},
	note = {arXiv: 1503.03832},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {815--823},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/MB4QJVCG/1503.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/QT6XZT9M/Schroff et al. - 2015 - FaceNet A Unified Embedding for Face Recognition .pdf:application/pdf},
}

@article{frosst_analyzing_2019,
	title = {Analyzing and {Improving} {Representations} with the {Soft} {Nearest} {Neighbor} {Loss}},
	url = {http://arxiv.org/abs/1902.01889},
	abstract = {We explore and expand the \${\textbackslash}textit\{Soft Nearest Neighbor Loss\}\$ to measure the \${\textbackslash}textit\{entanglement\}\$ of class manifolds in representation space: i.e., how close pairs of points from the same class are relative to pairs of points from different classes. We demonstrate several use cases of the loss. As an analytical tool, it provides insights into the evolution of class similarity structures during learning. Surprisingly, we find that \${\textbackslash}textit\{maximizing\}\$ the entanglement of representations of different classes in the hidden layers is beneficial for discrimination in the final layer, possibly because it encourages representations to identify class-independent similarity structures. Maximizing the soft nearest neighbor loss in the hidden layers leads not only to improved generalization but also to better-calibrated estimates of uncertainty on outlier data. Data that is not from the training distribution can be recognized by observing that in the hidden layers, it has fewer than the normal number of neighbors from the predicted class.},
	urldate = {2021-09-23},
	journal = {arXiv:1902.01889 [cs, stat]},
	author = {Frosst, Nicholas and Papernot, Nicolas and Hinton, Geoffrey},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.01889},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/NXHS38ZA/1902.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/59M87LCD/Frosst et al. - 2019 - Analyzing and Improving Representations with the S.pdf:application/pdf},
}

@inproceedings{salakhutdinov_learning_2007,
	title = {Learning a {Nonlinear} {Embedding} by {Preserving} {Class} {Neighbourhood} {Structure}},
	url = {https://proceedings.mlr.press/v2/salakhutdinov07a.html},
	abstract = {We show how to pretrain and fine-tune a multilayer neural network to learn a nonlinear transformation from the input space to a lowdimensional feature space in which K-nearest neighbour classification performs well. We also show how the non-linear transformation can be improved using unlabeled data. Our method achieves a much lower error rate than Support Vector Machines or standard backpropagation on a widely used version of the MNIST handwritten digit recognition task. If some of the dimensions of the low-dimensional feature space are not used for nearest neighbor classification, our method uses these dimensions to explicitly represent transformations of the digits that do not affect their identity.},
	language = {en},
	urldate = {2021-09-23},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Salakhutdinov, Ruslan and Hinton, Geoff},
	month = mar,
	year = {2007},
	note = {ISSN: 1938-7228},
	pages = {412--419},
	file = {Full Text PDF:/home/pgori/Zotero/storage/M6R49KP5/Salakhutdinov and Hinton - 2007 - Learning a Nonlinear Embedding by Preserving Class.pdf:application/pdf},
}

@inproceedings{poole_variational_2019,
  title={On variational bounds of mutual information},
  author={Poole, Ben and Ozair, Sherjil and Van Den Oord, Aaron and Alemi, Alex and Tucker, George},
  booktitle={International Conference on Machine Learning},
  pages={5171--5180},
  year={2019},
  organization={PMLR}
}


@article{cortes1995support,
  title={Support vector machine},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995}
}

@article{oord_representation_2019,
	title = {Representation {Learning} with {Contrastive} {Predictive} {Coding}},
	url = {http://arxiv.org/abs/1807.03748},
	abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
	urldate = {2021-09-23},
	journal = {arXiv:1807.03748 [cs, stat]},
	author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	month = jan,
	year = {2019},
	note = {arXiv: 1807.03748},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/2D5LVG2E/1807.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/Z92CBSXA/Oord et al. - 2019 - Representation Learning with Contrastive Predictiv.pdf:application/pdf},
}

@article{foster2020improving,
  title={Improving transformation invariance in contrastive representation learning},
  author={Foster, Adam and Pukdee, Rattana and Rainforth, Tom},
  journal={ICLR},
  year={2021}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{donahue2019large,
  title={Large scale adversarial representation learning},
  author={Donahue, Jeff and Simonyan, Karen},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{hozer2021lithium,
  title={Lithium prevents grey matter atrophy in patients with bipolar disorder: an international multicenter study},
  author={Hozer, Franz and Sarrazin, Samuel and Laidi, Charles and Favre, Pauline and Pauling, Melissa and Cannon, Dara and McDonald, Colm and Emsell, Louise and Mangin, Jean-Fran{\c{c}}ois and Duchesnay, Edouard and others},
  journal={Psychological medicine},
  volume={51},
  number={7},
  pages={1201--1210},
  year={2021},
  publisher={Cambridge University Press}
}


@article{jahanian2021generative,
  title={Generative models as a data source for multiview representation learning},
  author={Jahanian, Ali and Puig, Xavier and Tian, Yonglong and Isola, Phillip},
  journal={ICLR},
  year={2022}
}


@article{dumoulin2016adversarially,
  title={Adversarially learned inference},
  author={Dumoulin, Vincent and Belghazi, Ishmael and Poole, Ben and Mastropietro, Olivier and Lamb, Alex and Arjovsky, Martin and Courville, Aaron},
  journal={ICLR},
  year={2017}
}


@article{donahue2016adversarial,
  title={Adversarial feature learning},
  author={Donahue, Jeff and Kr{\"a}henb{\"u}hl, Philipp and Darrell, Trevor},
  journal={ICLR},
  year={2017}
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{ermolov2021whitening,
  title={Whitening for self-supervised representation learning},
  author={Ermolov, Aleksandr and Siarohin, Aliaksandr and Sangineto, Enver and Sebe, Nicu},
  booktitle={International Conference on Machine Learning},
  pages={3015--3024},
  year={2021},
  organization={PMLR}
}


@article{hibar2018cortical,
  title={Cortical abnormalities in bipolar disorder: an MRI analysis of 6503 individuals from the ENIGMA Bipolar Disorder Working Group},
  author={Hibar, DP and Westlye, Lars Tjelta and Doan, Nhat Trung and Jahanshad, Neda and Cheung, JW and Ching, Christopher RK and Versace, Amelia and Bilderbeck, AC and Uhlmann, Anne and Mwangi, B and others},
  journal={Molecular psychiatry},
  volume={23},
  number={4},
  pages={932--942},
  year={2018},
  publisher={Nature Publishing Group}
}


@article{welinder2010caltech,
  title={Caltech-UCSD birds 200},
  author={Welinder, Peter and Branson, Steve and Mita, Takeshi and Wah, Catherine and Schroff, Florian and Belongie, Serge and Perona, Pietro},
  year={2010},
  publisher={California Institute of Technology}
}


@article{zhou2021models,
  title={Models genesis},
  author={Zhou, Zongwei and Sodha, Vatsal and Pang, Jiaxuan and Gotway, Michael B and Liang, Jianming},
  journal={Medical image analysis},
  volume={67},
  pages={101840},
  year={2021},
  publisher={Elsevier}
}


@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{klebanov2020rigorous,
  title={A rigorous theory of conditional mean embeddings},
  author={Klebanov, Ilja and Schuster, Ingmar and Sullivan, Timothy John},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={3},
  pages={583--606},
  year={2020},
  publisher={SIAM}
}

@inproceedings{ko2022revisiting,
  title={Revisiting contrastive learning through the lens of neighborhood component analysis: an integrated framework},
  author={Ko, Ching-Yun and Mohapatra, Jeet and Liu, Sijia and Chen, Pin-Yu and Daniel, Luca and Weng, Lily},
  booktitle={International Conference on Machine Learning},
  pages={11387--11412},
  year={2022},
  organization={PMLR}
}


@article{grunewalder2012conditional,
  title={Conditional mean embeddings as regressors-supplementary},
  author={Gr{\"u}new{\"a}lder, Steffen and Lever, Guy and Baldassarre, Luca and Patterson, Sam and Gretton, Arthur and Pontil, Massimilano},
  journal={ICML},
  year={2012}
}


@article{molavipour_conditional_2020,
	title = {Conditional {Mutual} {Information} {Neural} {Estimator}},
	url = {http://arxiv.org/abs/1911.02277},
	doi = {10.1109/ICASSP40776.2020.9053422},
	abstract = {Several recent works in communication systems have proposed to leverage the power of neural networks in the design of encoders and decoders. In this approach, these blocks can be tailored to maximize the transmission rate based on aggregated samples from the channel. Motivated by the fact that, in many communication schemes, the achievable transmission rate is determined by a conditional mutual information term, this paper focuses on neural-based estimators for this information-theoretic quantity. Our results are based on variational bounds for the KL-divergence and, in contrast to some previous works, we provide a mathematically rigorous lower bound. However, additional challenges with respect to the unconditional mutual information emerge due to the presence of a conditional density function which we address here.},
	urldate = {2021-09-23},
	journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	author = {Molavipour, Sina and Bassi, Germán and Skoglund, Mikael},
	month = may,
	year = {2020},
	note = {arXiv: 1911.02277},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Theory},
	pages = {5025--5029},
	file = {arXiv.org Snapshot:/home/pgori/Zotero/storage/QRZ4GKAN/1911.html:text/html;arXiv Fulltext PDF:/home/pgori/Zotero/storage/ADR3KTA5/Molavipour et al. - 2020 - Conditional Mutual Information Neural Estimator.pdf:application/pdf},
}

@inproceedings{wang_understanding_2020,
  title={Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  booktitle={International Conference on Machine Learning},
  pages={9929--9939},
  year={2020},
  organization={PMLR}
}



@article{khosla_supervised_2020,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18661--18673},
  year={2020}
}

@inproceedings{chopra_learning_2005,
	title = {Learning a {Similarity} {Metric} {Discriminatively}, with {Application} to {Face} {Verification}},
	volume = {1},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467314/},
	doi = {10.1109/CVPR.2005.202},
	abstract = {We present a method for training a similarity metric from data. The method can be used for recognition or veriﬁcation applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the ¢¤£ norm in the target space approximates the “semantic” distance in the input space. The method is applied to a face veriﬁcation task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artiﬁcial occlusions such as dark glasses and obscuring scarves.},
	language = {en},
	urldate = {2021-09-23},
	booktitle = {{CVPR}},
	publisher = {IEEE},
	author = {Chopra, S. and Hadsell, R. and LeCun, Y.},
	year = {2005},
	pages = {539--546},
	file = {Chopra et al. - 2005 - Learning a Similarity Metric Discriminatively, wit.pdf:/home/pgori/Zotero/storage/LSXMC78M/Chopra et al. - 2005 - Learning a Similarity Metric Discriminatively, wit.pdf:application/pdf},
}


@inproceedings{weinberger_distance_2006,
	title = {Distance {Metric} {Learning} for {Large} {Margin} {Nearest} {Neighbor} {Classification}},
	volume = {18},
	url = {https://proceedings.neurips.cc/paper/2005/hash/a7f592cef8b130a6967a90617db5681b-Abstract.html},
	urldate = {2021-09-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence},
	year = {2006},
	file = {Full Text PDF:/Users/pgori/Zotero/storage/XFD2VHRE/Weinberger et al. - 2006 - Distance Metric Learning for Large Margin Nearest .pdf:application/pdf},
}

@book{borodachov2019discrete,
  title={Discrete energy on rectifiable sets},
  author={Borodachov, Sergiy V and Hardin, Douglas P and Saff, Edward B},
  year={2019},
  publisher={Springer}
}


@article{wang2022chaos,
  title={Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap},
  author={Wang, Yifei and Zhang, Qi and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
  journal={ICLR},
  year={2022}
}


@article{budimir2000further,
  title={Further reverse results for Jensen's discrete inequality and applications in information theory},
  author={Budimir, Ivan and Dragomir, Sever S and Pecaric, Josep},
  journal={RGMIA research report collection},
  volume={3},
  number={1},
  year={2000},
  publisher={School of Communications and Informatics, Faculty of Engineering and Science~…}
}


@inproceedings{wu_unsupervised_2018,
	title = {Unsupervised {Feature} {Learning} via {Non}-{Parametric} {Instance}-level {Discrimination}},
	url = {http://arxiv.org/abs/1805.01978},
	abstract = {Neural net classifiers trained on data with annotated class labels can also capture apparent visual similarity among categories without being directed to do so. We study whether this observation can be extended beyond the conventional domain of supervised learning: Can we learn a good feature representation that captures apparent similarity among instances, instead of classes, by merely asking the feature to be discriminative of individual instances? We formulate this intuition as a non-parametric classification problem at the instance-level, and use noise-contrastive estimation to tackle the computational challenges imposed by the large number of instance classes. Our experimental results demonstrate that, under unsupervised learning settings, our method surpasses the state-of-the-art on ImageNet classification by a large margin. Our method is also remarkable for consistently improving test performance with more training data and better network architectures. By fine-tuning the learned feature, we further obtain competitive results for semi-supervised learning and object detection tasks. Our non-parametric model is highly compact: With 128 features per image, our method requires only 600MB storage for a million images, enabling fast nearest neighbour retrieval at the run time.},
	urldate = {2021-09-24},
	booktitle = {{CVPR}},
	author = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella and Lin, Dahua},
	year = {2018},
	note = {arXiv: 1805.01978},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/pgori/Zotero/storage/QV737CL2/Wu et al. - 2018 - Unsupervised Feature Learning via Non-Parametric I.pdf:application/pdf;arXiv.org Snapshot:/Users/pgori/Zotero/storage/64W3D5C3/1805.html:text/html},
}

@inproceedings{hadsell_dimensionality_2006,
	title = {Dimensionality {Reduction} by {Learning} an {Invariant} {Mapping}},
	volume = {2},
	booktitle = {CVPR},
	publisher = {IEEE},
	author = {Hadsell, R. and Chopra, S. and LeCun, Y.},
	year = {2006},
	pages = {1735--1742}
}


@inproceedings{yu_deep_2019,
	title = {Deep {Metric} {Learning} {With} {Tuplet} {Margin} {Loss}},
	booktitle = {{IEEE} {ICCV}},
	author = {Yu, Baosheng and Tao, Dacheng},
	year = {2019},
	pages = {6489--6498}
}


@inproceedings{wang_ranked_2021,
	title = {Ranked {List} {Loss} for {Deep} {Metric} {Learning}},
	author = {Wang, Xinshao and Hua, Yang and Kodirov, Elyor and Robertson, Neil M.},
	year = {2019},
	booktitle = {{CVPR}}
}


@inproceedings{wang_learning_2014,
	title = {Learning {Fine}-grained {Image} {Similarity} with {Deep} {Ranking}},
	year = {2014},
	booktitle = {{CVPR}}
}


@inproceedings{azizi_big_2021,
	title = {Big {Self}-{Supervised} {Models} {Advance} {Medical} {Image} {Classification}},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Azizi, Shekoofeh and Mustafa, Basil and Ryan, Fiona and Beaver, Zachary and Freyberg, Jan and Deaton, Jonathan and Loh, Aaron and Karthikesalingam, Alan and Kornblith, Simon and Chen, Ting and Natarajan, Vivek and Norouzi, Mohammad},
	year = {2021},
	pages = {3458--3468}
}


@misc{dufumier_benchmarking_2021,
	title = {Benchmarking {CNN} on {3D} {Anatomical} {Brain} {MRI}: {Architectures}, {Data} {Augmentation} and {Deep} {Ensemble} {Learning}},
	shorttitle = {Benchmarking {CNN} on {3D} {Anatomical} {Brain} {MRI}},
	url = {http://arxiv.org/abs/2106.01132},
	abstract = {Deep Learning (DL) and specifically CNN models have become a de facto method for a wide range of vision tasks, outperforming traditional machine learning (ML) methods. Consequently, they drew a lot of attention in the neuroimaging field in particular for phenotype prediction or computer-aided diagnosis. However, most of the current studies often deal with small single-site cohorts, along with a specific pre-processing pipeline and custom CNN architectures, which make them difficult to compare to. We propose an extensive benchmark of recent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data augmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM) pre-processing and quasi-raw images. Experiments were conducted on a large multi-site 3D brain anatomical MRI data-set comprising N=10k scans on 3 challenging tasks: age prediction, sex classification, and schizophrenia diagnosis. We found that all models provide significantly better predictions with VBM images than quasi-raw data. This finding evolved as the training set approaches 10k samples where quasi-raw data almost reach the performance of VBM. Moreover, we showed that linear models perform comparably with SOTA CNN on VBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter version that we proposed, provide a good compromise in terms of performance in all data regime. Therefore, we suggest to employ them as the architectures by default. Critically, we also showed that current CNN are still very biased towards the acquisition site, even when trained with N=10k multi-site images. In this context, VBM pre-processing provides an efficient way to limit this site effect. Surprisingly, we did not find any clear benefit from data augmentation techniques. Finally, we proved that deep ensemble learning is well suited to re-calibrate big CNN models without sacrificing performance.},
	urldate = {2022-09-27},
	publisher = {arXiv},
	author = {Dufumier, Benoit and Gori, Pietro and Battaglia, Ilaria and Victor, Julie and Grigis, Antoine and Duchesnay, Edouard},
	month = jun,
	year = {2021},
	note = {arXiv:2106.01132 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/Users/pgori/Zotero/storage/ETQINGTC/Dufumier et al. - 2021 - Benchmarking CNN on 3D Anatomical Brain MRI Archi.pdf:application/pdf},
}









