\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{abadi2016tensorflow}
Mart{\'\i}n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
  Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et~al.
\newblock Tensorflow: a system for large-scale machine learning.
\newblock In \emph{OSDI}, volume~16, pages 265--283, 2016.

\bibitem[Anthony and Bartlett(1999)]{anthony2009neural}
Martin Anthony and Peter~L Bartlett.
\newblock \emph{Neural network learning: Theoretical foundations}.
\newblock Cambridge University Press, 1999.

\bibitem[Arora et~al.(2018)Arora, Ge, Neyshabur, and Zhang]{arora2018stronger}
Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi~Zhang.
\newblock Stronger generalization bounds for deep nets via a compression
  approach.
\newblock \emph{arXiv preprint arXiv:1802.05296}, 2018.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1802.00420}, 2018.

\bibitem[Attias et~al.(2018)Attias, Kontorovich, and
  Mansour]{attias2018improved}
Idan Attias, Aryeh Kontorovich, and Yishay Mansour.
\newblock Improved generalization bounds for robust learning.
\newblock \emph{arXiv preprint arXiv:1810.02180}, 2018.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Bartlett(1998)]{b-scpcnn-98}
Peter~L Bartlett.
\newblock The sample complexity of pattern classification with neural networks:
  the size of the weights is more important than the size of the network.
\newblock \emph{IEEE Transactions on Information Theory}, 44\penalty0
  (2):\penalty0 525--536, 1998.

\bibitem[Bartlett and Mendelson(2002)]{bartlett2002rademacher}
Peter~L Bartlett and Shahar Mendelson.
\newblock Rademacher and {G}aussian complexities: Risk bounds and structural
  results.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 463--482, 2002.

\bibitem[Bartlett et~al.(2017)Bartlett, Foster, and
  Telgarsky]{bartlett2017spectrally}
Peter~L Bartlett, Dylan~J Foster, and Matus~J Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Ben-Tal et~al.(2009)Ben-Tal, El~Ghaoui, and Nemirovski]{ben2009robust}
Aharon Ben-Tal, Laurent El~Ghaoui, and Arkadi Nemirovski.
\newblock \emph{Robust optimization}.
\newblock Princeton University Press, 2009.

\bibitem[Bubeck et~al.(2018)Bubeck, Price, and
  Razenshteyn]{bubeck2018adversarial}
S{\'e}bastien Bubeck, Eric Price, and Ilya Razenshteyn.
\newblock Adversarial examples from computational constraints.
\newblock \emph{arXiv preprint arXiv:1805.10204}, 2018.

\bibitem[Carlini and Wagner(2016)]{carlini2016defensive}
Nicholas Carlini and David Wagner.
\newblock Defensive distillation is not robust to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1607.04311}, 2016.

\bibitem[Carlini and Wagner(2017)]{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 3--14. ACM, 2017.

\bibitem[Carlini and Wagner(2018)]{carlini2018audio}
Nicholas Carlini and David Wagner.
\newblock Audio adversarial examples: Targeted attacks on speech-to-text.
\newblock \emph{arXiv preprint arXiv:1801.01944}, 2018.

\bibitem[Cullina et~al.(2018)Cullina, Bhagoji, and Mittal]{cullina2018pac}
Daniel Cullina, Arjun~Nitin Bhagoji, and Prateek Mittal.
\newblock {PAC}-learning in the presence of evasion adversaries.
\newblock \emph{arXiv preprint arXiv:1806.01471}, 2018.

\bibitem[Dohmatob(2018)]{dohmatob2018limitations}
Elvis Dohmatob.
\newblock Limitations of adversarial robustness: strong no free lunch theorem.
\newblock \emph{arXiv preprint arXiv:1810.04065}, 2018.

\bibitem[Engstrom et~al.(2017)Engstrom, Tsipras, Schmidt, and
  Madry]{engstrom2017rotation}
Logan Engstrom, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry.
\newblock A rotation and a translation suffice: Fooling {CNN}s with simple
  transformations.
\newblock \emph{arXiv preprint arXiv:1712.02779}, 2017.

\bibitem[Farnia et~al.(2018)Farnia, Zhang, and Tse]{farnia2018generalizable}
Farzan Farnia, Jesse~M Zhang, and David Tse.
\newblock Generalizable adversarial training via spectral normalization.
\newblock \emph{arXiv preprint arXiv:1811.07457}, 2018.

\bibitem[Fawzi et~al.(2016)Fawzi, Moosavi-Dezfooli, and
  Frossard]{fawzi2016robustness}
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Fawzi]{fawzi2018adversarial}
Alhussein Fawzi, Hamza Fawzi, and Omar Fawzi.
\newblock Adversarial vulnerability for any classifier.
\newblock \emph{arXiv preprint arXiv:1802.08686}, 2018.

\bibitem[Gilmer et~al.(2018{\natexlab{a}})Gilmer, Adams, Goodfellow, Andersen,
  and Dahl]{gilmer2018motivating}
Justin Gilmer, Ryan~P Adams, Ian Goodfellow, David Andersen, and George~E Dahl.
\newblock Motivating the rules of the game for adversarial example research.
\newblock \emph{arXiv preprint arXiv:1807.06732}, 2018{\natexlab{a}}.

\bibitem[Gilmer et~al.(2018{\natexlab{b}})Gilmer, Metz, Faghri, Schoenholz,
  Raghu, Wattenberg, and Goodfellow]{gilmer2018adversarial}
Justin Gilmer, Luke Metz, Fartash Faghri, Samuel~S Schoenholz, Maithra Raghu,
  Martin Wattenberg, and Ian Goodfellow.
\newblock Adversarial spheres.
\newblock \emph{arXiv preprint arXiv:1801.02774}, 2018{\natexlab{b}}.

\bibitem[Golowich et~al.(2017)Golowich, Rakhlin, and Shamir]{golowich2017size}
Noah Golowich, Alexander Rakhlin, and Ohad Shamir.
\newblock Size-independent sample complexity of neural networks.
\newblock \emph{arXiv preprint arXiv:1712.06541}, 2017.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow6572explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Graves et~al.(2013)Graves, Mohamed, and Hinton]{graves2013speech}
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton.
\newblock Speech recognition with deep recurrent neural networks.
\newblock In \emph{ICASSP}. IEEE, 2013.

\bibitem[Gu and Rigazio(2014)]{gu2014towards}
Shixiang Gu and Luca Rigazio.
\newblock Towards deep neural network architectures robust to adversarial
  examples.
\newblock \emph{arXiv preprint arXiv:1412.5068}, 2014.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2016.

\bibitem[Huang et~al.(2015)Huang, Xu, Schuurmans, and
  Szepesv{\'a}ri]{huang2015learning}
Ruitong Huang, Bing Xu, Dale Schuurmans, and Csaba Szepesv{\'a}ri.
\newblock Learning with a strong adversary.
\newblock \emph{arXiv preprint arXiv:1511.03034}, 2015.

\bibitem[Khim and Loh(2018)]{khim2018adversarial}
Justin Khim and Po-Ling Loh.
\newblock Adversarial risk bounds for binary classification via function
  transformation.
\newblock \emph{arXiv preprint arXiv:1810.09519}, 2018.

\bibitem[Koltchinskii et~al.(2006)]{koltchinskii2006local}
Vladimir Koltchinskii et~al.
\newblock Local rademacher complexities and oracle inequalities in risk
  minimization.
\newblock \emph{The Annals of Statistics}, 34\penalty0 (6):\penalty0
  2593--2656, 2006.

\bibitem[Kolter and Wong(2017)]{kolter2017provable}
J~Zico Kolter and Eric Wong.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock \emph{arXiv preprint arXiv:1711.00851}, 2017.

\bibitem[Kos et~al.(2018)Kos, Fischer, and Song]{kos2018adversarial}
Jernej Kos, Ian Fischer, and Dawn Song.
\newblock Adversarial examples for generative models.
\newblock In \emph{2018 IEEE Security and Privacy Workshops (SPW)}, pages
  36--42. IEEE, 2018.

\bibitem[Kuznetsov et~al.(2015)Kuznetsov, Mohri, and
  Syed]{kuznetsov2015rademacher}
Vitaly Kuznetsov, Mehryar Mohri, and U~Syed.
\newblock Rademacher complexity margin bounds for learning with a large number
  of classes.
\newblock In \emph{ICML Workshop on Extreme Classification: Learning with a
  Very Large Number of Labels}, 2015.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Ledoux and Talagrand(2013)]{ledoux2013probability}
Michel Ledoux and Michel Talagrand.
\newblock \emph{Probability in {B}anach Spaces: isoperimetry and processes}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Lee et~al.(1996)Lee, Bartlett, and Williamson]{lee1996efficient}
Wee~Sun Lee, Peter~L Bartlett, and Robert~C Williamson.
\newblock Efficient agnostic learning of neural networks with bounded fan-in.
\newblock \emph{IEEE Transactions on Information Theory}, 42\penalty0
  (6):\penalty0 2118--2132, 1996.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Mahloujifar et~al.(2018)Mahloujifar, Diochnos, and
  Mahmoody]{mahloujifar2018curse}
Saeed Mahloujifar, Dimitrios~I Diochnos, and Mohammad Mahmoody.
\newblock The curse of concentration in robust learning: Evasion and poisoning
  attacks from concentration of measure.
\newblock \emph{arXiv preprint arXiv:1809.03063}, 2018.

\bibitem[Maximov and Reshetova(2016)]{maximov2016tight}
Yu~Maximov and Daria Reshetova.
\newblock Tight risk bounds for multi-class margin classifiers.
\newblock \emph{Pattern Recognition and Image Analysis}, 26\penalty0
  (4):\penalty0 673--680, 2016.

\bibitem[Mei et~al.(2018)Mei, Montanari, and Nguyen]{mei2018mean}
Song Mei, Andrea Montanari, and Phan-Minh Nguyen.
\newblock A mean field view of the landscape of two-layers neural networks.
\newblock \emph{arXiv preprint arXiv:1804.06561}, 2018.

\bibitem[Mohri et~al.(2012)Mohri, Rostamizadeh, and
  Talwalkar]{mohri2012foundations}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock \emph{Foundations of machine learning}.
\newblock MIT press, 2012.

\bibitem[Neyshabur et~al.(2017)Neyshabur, Bhojanapalli, McAllester, and
  Srebro]{neyshabur2017pac}
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro.
\newblock A {PAC}-bayesian approach to spectrally-normalized margin bounds for
  neural networks.
\newblock \emph{arXiv preprint arXiv:1707.09564}, 2017.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Sinha, and
  Wellman]{papernot2016towards}
Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael Wellman.
\newblock Towards the science of security and privacy in machine learning.
\newblock \emph{arXiv preprint arXiv:1611.03814}, 2016.

\bibitem[Raghunathan et~al.(2018{\natexlab{a}})Raghunathan, Steinhardt, and
  Liang]{raghunathan2018certified}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock \emph{arXiv preprint arXiv:1801.09344}, 2018{\natexlab{a}}.

\bibitem[Raghunathan et~al.(2018{\natexlab{b}})Raghunathan, Steinhardt, and
  Liang]{raghunathan2018semidefinite}
Aditi Raghunathan, Jacob Steinhardt, and Percy~S Liang.
\newblock Semidefinite relaxations for certifying robustness to adversarial
  examples.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2018{\natexlab{b}}.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander Madry.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{arXiv preprint arXiv:1804.11285}, 2018.

\bibitem[Shaham et~al.(2015)Shaham, Yamada, and
  Negahban]{shaham2015understanding}
Uri Shaham, Yutaro Yamada, and Sahand Negahban.
\newblock Understanding adversarial training: Increasing local stability of
  neural nets through robust optimization.
\newblock \emph{arXiv preprint arXiv:1511.05432}, 2015.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484, 2016.

\bibitem[Sinha et~al.(2018)Sinha, Namkoong, and Duchi]{sinha2018certifying}
Aman Sinha, Hongseok Namkoong, and John Duchi.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Suggala et~al.(2018)Suggala, Prasad, Nagarajan, and
  Ravikumar]{suggala2018adversarial}
Arun~Sai Suggala, Adarsh Prasad, Vaishnavh Nagarajan, and Pradeep Ravikumar.
\newblock On adversarial risk and training.
\newblock \emph{arXiv preprint arXiv:1806.02924}, 2018.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tsipras et~al.(2018)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018there}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock \emph{arXiv preprint arXiv:1805.12152}, 2018.

\bibitem[Wang et~al.(2017)Wang, Jha, and Chaudhuri]{wang2017analyzing}
Yizhen Wang, Somesh Jha, and Kamalika Chaudhuri.
\newblock Analyzing the robustness of nearest neighbors to adversarial
  examples.
\newblock \emph{arXiv preprint arXiv:1706.03922}, 2017.

\bibitem[Wong et~al.(2018)Wong, Schmidt, Metzen, and Kolter]{wong2018scaling}
Eric Wong, Frank Schmidt, Jan~Hendrik Metzen, and J~Zico Kolter.
\newblock Scaling provable adversarial defenses.
\newblock \emph{arXiv preprint arXiv:1805.12514}, 2018.

\bibitem[Xu and Mannor(2012)]{xu2012robustness}
Huan Xu and Shie Mannor.
\newblock Robustness and generalization.
\newblock \emph{Machine learning}, 86\penalty0 (3):\penalty0 391--423, 2012.

\bibitem[Xu et~al.(2009{\natexlab{a}})Xu, Caramanis, and Mannor]{xu2009robust}
Huan Xu, Constantine Caramanis, and Shie Mannor.
\newblock Robust regression and {L}asso.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2009{\natexlab{a}}.

\bibitem[Xu et~al.(2009{\natexlab{b}})Xu, Caramanis, and
  Mannor]{xu2009robustness}
Huan Xu, Constantine Caramanis, and Shie Mannor.
\newblock Robustness and regularization of support vector machines.
\newblock \emph{JMLR}, 10\penalty0 (Jul):\penalty0 1485--1510,
  2009{\natexlab{b}}.

\bibitem[Zhang et~al.(2016{\natexlab{a}})Zhang, Bengio, Hardt, Recht, and
  Vinyals]{zhang2016understanding}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock \emph{arXiv preprint arXiv:1611.03530}, 2016{\natexlab{a}}.

\bibitem[Zhang et~al.(2016{\natexlab{b}})Zhang, Lee, and Jordan]{zhang2016l1}
Yuchen Zhang, Jason~D Lee, and Michael~I Jordan.
\newblock $\ell_1$-regularized neural networks are improperly learnable in
  polynomial time.
\newblock In \emph{International Conference on Machine Learning},
  2016{\natexlab{b}}.

\end{thebibliography}
