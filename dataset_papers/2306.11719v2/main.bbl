\begin{thebibliography}{10}

\bibitem{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em Proc. ICML}, 2015.

\bibitem{mueller2022diffrf}
Norman M{\"{u}}ller, , Yawar Siddiqui, Lorenzo Porzi, Samuel Rota~Bul\`{o},
  Peter Kontschieder, and Matthias Nie{\ss}ner.
\newblock Diffrf: Rendering-guided 3d radiance field diffusion.
\newblock {\em Proc. CVPR}, 2023.

\bibitem{kim2023neuralfield}
Seung~Wook Kim, Bradley Brown, Kangxue Yin, Karsten Kreis, Katja Schwarz,
  Daiqing Li, Robin Rombach, Antonio Torralba, and Sanja Fidler.
\newblock Neuralfield-ldm: Scene generation with hierarchical latent diffusion
  models.
\newblock {\em Proc. CVPR}, 2023.

\bibitem{chan2023generative}
Eric~R Chan, Koki Nagano, Matthew~A Chan, Alexander~W Bergman, Jeong~Joon Park,
  Axel Levy, Miika Aittala, Shalini De~Mello, Tero Karras, and Gordon
  Wetzstein.
\newblock Generative novel view synthesis with 3d-aware diffusion models.
\newblock {\em arXiv preprint arXiv:2304.02602}, 2023.

\bibitem{zhou2022sparsefusion}
Zhizhuo Zhou and Shubham Tulsiani.
\newblock Sparsefusion: Distilling view-conditioned diffusion for 3d
  reconstruction.
\newblock {\em Proc. CVPR}, 2023.

\bibitem{poole2022dreamfusion}
Ben Poole, Ajay Jain, Jonathan~T. Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock {\em Proc. ICLR}, 2023.

\bibitem{anciukevivcius2022renderdiffusion}
Titas Anciukevi{\v{c}}ius, Zexiang Xu, Matthew Fisher, Paul Henderson, Hakan
  Bilen, Niloy~J Mitra, and Paul Guerrero.
\newblock Renderdiffusion: Image diffusion for 3d reconstruction, inpainting
  and generation.
\newblock {\em Proc. CVPR}, 2023.

\bibitem{sg2}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
  Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In {\em Proc. CVPR}, 2020.

\bibitem{yu2021pixelnerf}
Alex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa.
\newblock pixelnerf: Neural radiance fields from one or few images.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em Proc. ICLR}, 2014.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In {\em Proc. ICML}, 2014.

\bibitem{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em Proc. ICML}, 2015.

\bibitem{garnelo2018conditional}
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David
  Saxton, Murray Shanahan, Yee~Whye Teh, Danilo Rezende, and SM~Ali Eslami.
\newblock Conditional neural processes.
\newblock In {\em Proc. ICML}, 2018.

\bibitem{kim2019attentive}
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan
  Rosenbaum, Oriol Vinyals, and Yee~Whye Teh.
\newblock Attentive neural processes.
\newblock {\em Proc. ICLR}, 2019.

\bibitem{kosiorek2021nerf}
Adam~R Kosiorek, Heiko Strathmann, Daniel Zoran, Pol Moreno, Rosalia Schneider,
  Sona Mokr{\'a}, and Danilo~Jimenez Rezende.
\newblock Nerf-vae: A geometry aware 3d scene generative model.
\newblock In {\em Proc. ICML}, 2021.

\bibitem{moreno2023laser}
Pol Moreno, Adam~R Kosiorek, Heiko Strathmann, Daniel Zoran, Rosalia~G
  Schneider, Bj{\"o}rn Winckler, Larisa Markeeva, Th{\'e}ophane Weber, and
  Danilo~J Rezende.
\newblock Laser: Latent set representations for 3d generative modeling.
\newblock {\em arXiv preprint arXiv:2301.05747}, 2023.

\bibitem{chan2021pi}
Eric~R Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, and Gordon Wetzstein.
\newblock pi-gan: Periodic implicit generative adversarial networks for
  3d-aware image synthesis.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{gao2022get3d}
Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li,
  Or~Litany, Zan Gojcic, and Sanja Fidler.
\newblock Get3d: A generative model of high quality 3d textured shapes learned
  from images.
\newblock {\em Proc. NeurIPS}, 2022.

\bibitem{devries2021unconstrained}
Terrance DeVries, Miguel~Angel Bautista, Nitish Srivastava, Graham~W Taylor,
  and Joshua~M Susskind.
\newblock Unconstrained scene generation with locally conditioned radiance
  fields.
\newblock In {\em Proc. ICCV}, 2021.

\bibitem{karnewar2023holodiffusion}
Animesh Karnewar, Andrea Vedaldi, David Novotny, and Niloy Mitra.
\newblock Holodiffusion: Training a 3d diffusion model using 2d images.
\newblock {\em Proc. CVPR}, 2023.

\bibitem{chung2023diffusion}
Hyungjin Chung, Jeongsol Kim, Michael~Thompson Mccann, Marc~Louis Klasky, and
  Jong~Chul Ye.
\newblock Diffusion posterior sampling for general noisy inverse problems.
\newblock In {\em Proc. ICLR}, 2023.

\bibitem{ilvr}
Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.
\newblock Ilvr: Conditioning method for denoising diffusion probabilistic
  models.
\newblock {\em Proc. ICCV}, 2021.

\bibitem{kawar2022denoising}
Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song.
\newblock Denoising diffusion restoration models.
\newblock In {\em Proc. NeurIPS}, 2022.

\bibitem{song2023pseudoinverse}
Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz.
\newblock Pseudoinverse-guided diffusion models for inverse problems.
\newblock In {\em Proc. ICLR}, 2023.

\bibitem{song2021scorebased}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In {\em Proc. ICLR}, 2021.

\bibitem{song2021solving}
Yang Song, Liyue Shen, Lei Xing, and Stefano Ermon.
\newblock Solving inverse problems in medical imaging with score-based
  generative models.
\newblock {\em Proc. ICLR}, 2022.

\bibitem{bardsley2012mcmc}
Johnathan~M Bardsley.
\newblock Mcmc-based image reconstruction with uncertainty quantification.
\newblock {\em SIAM Journal on Scientific Computing}, 34(3):A1316--A1332, 2012.

\bibitem{Venkatakrishnan2013PlugandPlayPF}
Singanallur Venkatakrishnan, Charles~A. Bouman, and Brendt Wohlberg.
\newblock Plug-and-play priors for model based reconstruction.
\newblock {\em 2013 IEEE Global Conference on Signal and Information
  Processing}, pages 945--948, 2013.

\bibitem{romano2017little}
Yaniv Romano, Michael Elad, and Peyman Milanfar.
\newblock The little engine that could: Regularization by denoising (red).
\newblock {\em SIAM Journal on Imaging Sciences}, 10(4):1804--1844, 2017.

\bibitem{sitzmann2019scene}
Vincent Sitzmann, Michael Zollh{\"o}fer, and Gordon Wetzstein.
\newblock Scene representation networks: Continuous 3d-structure-aware neural
  scene representations.
\newblock {\em Proc. NeurIPS}, 2019.

\bibitem{niemeyer2020dvr}
Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger.
\newblock Differentiable volumetric rendering: Learning implicit 3d
  representations without 3d supervision.
\newblock In {\em Proc. CVPR}, 2020.

\bibitem{henzler2021unsupervised}
Philipp Henzler, Jeremy Reizenstein, Patrick Labatut, Roman Shapovalov, Tobias
  Ritschel, Andrea Vedaldi, and David Novotny.
\newblock Unsupervised learning of 3d object categories from videos in the
  wild.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{sharma2022neural}
Prafull Sharma, Ayush Tewari, Yilun Du, Sergey Zakharov, Rares~Andrei Ambrus,
  Adrien Gaidon, William~T Freeman, Fredo Durand, Joshua~B Tenenbaum, and
  Vincent Sitzmann.
\newblock Neural groundplans: Persistent neural scene representations from a
  single image.
\newblock In {\em Proc. ICLR}.

\bibitem{chen2021mvsnerf}
Anpei Chen, Zexiang Xu, Fuqiang Zhao, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu,
  and Hao Su.
\newblock Mvsnerf: Fast generalizable radiance field reconstruction from
  multi-view stereo.
\newblock In {\em Proc. ICCV}, 2021.

\bibitem{du2023cross}
Yilun Du, Cameron Smith, Ayush Tewari, and Vincent Sitzmann.
\newblock Learning to render novel views from wide-baseline stereo pairs.
\newblock In {\em Proc. CVPR}, 2023.

\bibitem{trevithick2021grf}
Alex Trevithick and Bo~Yang.
\newblock Grf: Learning a general radiance field for 3d representation and
  rendering.
\newblock In {\em Proc. ICCV}, 2021.

\bibitem{suhail2022generalizable}
Mohammed Suhail, Carlos Esteves, Leonid Sigal, and Ameesh Makadia.
\newblock Generalizable patch-based neural rendering.
\newblock In {\em Proc. ECCV}, 2022.

\bibitem{chibane2021stereo}
Julian Chibane, Aayush Bansal, Verica Lazova, and Gerard Pons-Moll.
\newblock Stereo radiance fields (srf): Learning view synthesis for sparse
  views of novel scenes.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{wang2021ibrnet}
Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul~P Srinivasan, Howard Zhou,
  Jonathan~T Barron, Ricardo Martin-Brualla, Noah Snavely, and Thomas
  Funkhouser.
\newblock Ibrnet: Learning multi-view image-based rendering.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{lal2021coconets}
Shamit Lal, Mihir Prabhudesai, Ishita Mediratta, Adam~W Harley, and Katerina
  Fragkiadaki.
\newblock Coconets: Continuous contrastive 3d scene representations.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{watson2022novel}
Daniel Watson, William Chan, Ricardo Martin-Brualla, Jonathan Ho, Andrea
  Tagliasacchi, and Mohammad Norouzi.
\newblock Novel view synthesis with diffusion models.
\newblock {\em Proc. ICLR}, 2023.

\bibitem{eslami2018neural}
SM~Ali Eslami, Danilo Jimenez~Rezende, Frederic Besse, Fabio Viola, Ari~S
  Morcos, Marta Garnelo, Avraham Ruderman, Andrei~A Rusu, Ivo Danihelka, Karol
  Gregor, et~al.
\newblock Neural scene representation and rendering.
\newblock {\em Science}, 360(6394):1204--1210, 2018.

\bibitem{tseng2023consistent}
Hung-Yu Tseng, Qinbo Li, Changil Kim, Suhib Alsisan, Jia-Bin Huang, and
  Johannes Kopf.
\newblock Consistent view synthesis with pose-guided diffusion models.
\newblock {\em arXiv preprint arXiv:2303.17598}, 2023.

\bibitem{gu2023learning}
Jiatao Gu, Qingzhe Gao, Shuangfei Zhai, Baoquan Chen, Lingjie Liu, and Josh
  Susskind.
\newblock Learning controllable 3d diffusion models from single-view images.
\newblock {\em arXiv preprint arXiv:2304.06700}, 2023.

\bibitem{melas2023realfusion}
Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi.
\newblock Realfusion: 360 $\{$$\backslash$deg$\}$ reconstruction of any object
  from a single image.
\newblock {\em Proc. CVPR}, 2023.

\bibitem{hollein2023text2room}
Lukas H{\"o}llein, Ang Cao, Andrew Owens, Justin Johnson, and Matthias
  Nie{\ss}ner.
\newblock Text2room: Extracting textured 3d meshes from 2d text-to-image
  models.
\newblock {\em arXiv preprint arXiv:2303.11989}, 2023.

\bibitem{fridman2023scenescape}
Rafail Fridman, Amit Abecasis, Yoni Kasten, and Tali Dekel.
\newblock Scenescape: Text-driven consistent scene generation.
\newblock {\em arXiv preprint arXiv:2302.01133}, 2023.

\bibitem{mildenhall2020nerf}
Ben Mildenhall, Pratul~P. Srinivasan, Matthew Tancik, Jonathan~T. Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In {\em Proc. ECCV}, 2020.

\bibitem{reizenstein21co3d}
Jeremy Reizenstein, Roman Shapovalov, Philipp Henzler, Luca Sbordone, Patrick
  Labatut, and David Novotny.
\newblock Common objects in 3d: Large-scale learning and evaluation of
  real-life 3d category reconstruction.
\newblock In {\em Proc. ICCV}, 2021.

\bibitem{RealEstate10k}
Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe, and Noah Snavely.
\newblock Stereo magnification: Learning view synthesis using multiplane
  images.
\newblock {\em ACM Trans. Graph. (Proc. SIGGRAPH)}, 37, 2018.

\bibitem{ding2021sparse}
Yi~Ding, Alex Rich, Mason Wang, Noah Stier, Matthew Turk, Pradeep Sen, and
  Tobias H{\"o}llerer.
\newblock Sparse fusion for multimodal transformers.
\newblock {\em arXiv preprint arXiv:2111.11992}, 2021.

\bibitem{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em Proc. CVPR}, 2018.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Proc. NeurIPS}, 2017.

\bibitem{kid}
Miko{\l}aj Bi{\'n}kowski, Danica~J Sutherland, Michael Arbel, and Arthur
  Gretton.
\newblock Demystifying mmd gans.
\newblock {\em arXiv preprint arXiv:1801.01401}, 2018.

\bibitem{xue2019video}
Tianfan Xue, Baian Chen, Jiajun Wu, Donglai Wei, and William~T Freeman.
\newblock Video enhancement with task-oriented flow.
\newblock {\em International Journal of Computer Vision}, 127:1106--1125, 2019.

\bibitem{gao2018im2flow}
Ruohan Gao, Bo~Xiong, and Kristen Grauman.
\newblock Im2flow: Motion hallucination from static images for action
  recognition.
\newblock In {\em Proc. CVPR}, 2018.

\bibitem{walker2015dense}
Jacob Walker, Abhinav Gupta, and Martial Hebert.
\newblock Dense optical flow prediction from a static image.
\newblock In {\em Proc. ICCV}, 2015.

\bibitem{pintea2014deja}
Silvia~L Pintea, Jan~C van Gemert, and Arnold~WM Smeulders.
\newblock D{\'e}ja vu: Motion prediction in static images.
\newblock In {\em Proc. ECCV}, 2014.

\bibitem{walker2016uncertain}
Jacob Walker, Carl Doersch, Abhinav Gupta, and Martial Hebert.
\newblock An uncertain future: Forecasting from static images using variational
  autoencoders.
\newblock In {\em Proc. ECCV}. Springer, 2016.

\bibitem{li2018flow}
Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, and Ming-Hsuan Yang.
\newblock Flow-grounded spatial-temporal video prediction from still images.
\newblock In {\em Proc. ICCV}, 2018.

\bibitem{walker2017pose}
Jacob Walker, Kenneth Marino, Abhinav Gupta, and Martial Hebert.
\newblock The pose knows: Video forecasting by generating pose futures.
\newblock In {\em Proc. ICCV}, 2017.

\bibitem{kanazawa2018learning}
Angjoo Kanazawa, Shubham Tulsiani, Alexei~A Efros, and Jitendra Malik.
\newblock Learning category-specific mesh reconstruction from image
  collections.
\newblock In {\em Proc. ECCV}, 2018.

\bibitem{choudhury2022guess}
Subhabrata Choudhury, Laurynas Karazija, Iro Laina, Andrea Vedaldi, and
  Christian Rupprecht.
\newblock Guess what moves: unsupervised video and image segmentation by
  anticipating motion.
\newblock {\em arXiv preprint arXiv:2205.07844}, 2022.

\bibitem{Niklaus_CVPR_2020}
Simon Niklaus and Feng Liu.
\newblock Softmax splatting for video frame interpolation.
\newblock In {\em Proc. CVPR}, 2020.

\bibitem{zhu2016generative}
Jun-Yan Zhu, Philipp Kr{\"a}henb{\"u}hl, Eli Shechtman, and Alexei~A. Efros.
\newblock Generative visual manipulation on the natural image manifold.
\newblock In {\em Proc. ECCV}, 2016.

\bibitem{harkonen2020ganspace}
Erik H{\"a}rk{\"o}nen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.
\newblock Ganspace: Discovering interpretable gan controls.
\newblock {\em Proc. NeurIPS}, 2020.

\bibitem{tewari2020stylerig}
Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian Bernard, Hans-Peter
  Seidel, Patrick P{\'e}rez, Michael Zollhofer, and Christian Theobalt.
\newblock Stylerig: Rigging stylegan for 3d control over portrait images.
\newblock In {\em Proc. CVPR}, 2020.

\bibitem{shen2020interfacegan}
Yujun Shen, Ceyuan Yang, Xiaoou Tang, and Bolei Zhou.
\newblock Interfacegan: Interpreting the disentangled face representation
  learned by gans.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  44(4):2004--2018, 2020.

\bibitem{abdal2019image2stylegan}
Rameen Abdal, Yipeng Qin, and Peter Wonka.
\newblock Image2stylegan: How to embed images into the stylegan latent space?
\newblock In {\em Proc. ICCV}, 2019.

\bibitem{abdal2020image2stylegan++}
Rameen Abdal, Yipeng Qin, and Peter Wonka.
\newblock Image2stylegan++: How to edit the embedded images?
\newblock In {\em Proc. CVPR}, 2020.

\bibitem{bau2020semantic}
David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan
  Zhu, and Antonio Torralba.
\newblock Semantic photo manipulation with a generative image prior.
\newblock {\em arXiv preprint arXiv:2005.07727}, 2020.

\bibitem{alaluf2021restyle}
Yuval Alaluf, Or~Patashnik, and Daniel Cohen-Or.
\newblock Restyle: A residual-based stylegan encoder via iterative refinement.
\newblock In {\em Proc. ICCV}, 2021.

\bibitem{guan2020collaborative}
Shanyan Guan, Ying Tai, Bingbing Ni, Feida Zhu, Feiyue Huang, and Xiaokang
  Yang.
\newblock Collaborative learning for faster stylegan embedding.
\newblock {\em arXiv preprint arXiv:2007.01758}, 2020.

\bibitem{pidhorskyi2020adversarial}
Stanislav Pidhorskyi, Donald~A Adjeroh, and Gianfranco Doretto.
\newblock Adversarial latent autoencoders.
\newblock In {\em Proc. CVPR}, 2020.

\bibitem{richardson2021encoding}
Elad Richardson, Yuval Alaluf, Or~Patashnik, Yotam Nitzan, Yaniv Azar, Stav
  Shapiro, and Daniel Cohen-Or.
\newblock Encoding in style: a stylegan encoder for image-to-image translation.
\newblock In {\em Proc. CVPR}, 2021.

\bibitem{tov2021designing}
Omer Tov, Yuval Alaluf, Yotam Nitzan, Or~Patashnik, and Daniel Cohen-Or.
\newblock Designing an encoder for stylegan image manipulation.
\newblock {\em ACM Transactions on Graphics (TOG)}, 40(4):1--14, 2021.

\bibitem{wang2022high}
Tengfei Wang, Yong Zhang, Yanbo Fan, Jue Wang, and Qifeng Chen.
\newblock High-fidelity gan inversion for image attribute editing.
\newblock In {\em Proc. CVPR}, 2022.

\bibitem{tewari2020pie}
Ayush Tewari, Mohamed Elgharib, Florian Bernard, Hans-Peter Seidel, Patrick
  P{\'e}rez, Michael Zollh{\"o}fer, and Christian Theobalt.
\newblock Pie: Portrait image embedding for semantic control.
\newblock {\em ACM Transactions on Graphics (TOG)}, 39(6):1--14, 2020.

\bibitem{sg1}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em Proc. CVPR}, 2019.

\end{thebibliography}
