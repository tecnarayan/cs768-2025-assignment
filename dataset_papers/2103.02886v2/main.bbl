\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Badia et~al.(2020)Badia, Piot, Kapturowski, Sprechmann, Vitvitskyi,
  Guo, and Blundell]{badia2020agent57}
Badia, Adri{\`a}~Puigdom{\`e}nech, Piot, Bilal, Kapturowski, Steven,
  Sprechmann, Pablo, Vitvitskyi, Alex, Guo, Daniel, and Blundell, Charles.
\newblock Agent57: Outperforming the atari human benchmark.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare2013arcade}
Bellemare, Marc~G, Naddaf, Yavar, Veness, Joel, and Bowling, Michael.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  253--279, 2013.

\bibitem[Bellemare et~al.(2017)Bellemare, Dabney, and
  Munos]{bellemare2017distributional}
Bellemare, Marc~G, Dabney, Will, and Munos, R{\'e}mi.
\newblock A distributional perspective on reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Blalock et~al.(2020)Blalock, Ortiz, Frankle, and
  Guttag]{blalock2020state}
Blalock, Davis, Ortiz, Jose Javier~Gonzalez, Frankle, Jonathan, and Guttag,
  John.
\newblock What is the state of neural network pruning?
\newblock \emph{arXiv preprint arXiv:2003.03033}, 2020.

\bibitem[Brock et~al.(2017)Brock, Lim, Ritchie, and Weston]{brock2017freezeout}
Brock, Andrew, Lim, Theodore, Ritchie, James~M, and Weston, Nick.
\newblock Freezeout: Accelerate training by progressively freezing layers.
\newblock \emph{arXiv preprint arXiv:1706.04983}, 2017.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, Legg, and Kavukcuoglu]{espeholt2018impala}
Espeholt, Lasse, Soyer, Hubert, Munos, Remi, Simonyan, Karen, Mnih, Volodymir,
  Ward, Tom, Doron, Yotam, Firoiu, Vlad, Harley, Tim, Dunning, Iain, Legg,
  Shane, and Kavukcuoglu, Koray.
\newblock Impala: Scalable distributed deep-rl with importance weighted
  actor-learner architectures, 2018.

\bibitem[Fang et~al.(2019)Fang, Toshev, Fei-Fei, and Savarese]{fang2019scene}
Fang, Kuan, Toshev, Alexander, Fei-Fei, Li, and Savarese, Silvio.
\newblock Scene memory transformer for embodied agents in long-horizon tasks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  538--547, 2019.

\bibitem[Frankle \& Carbin(2019)Frankle and Carbin]{frankle2018lottery}
Frankle, Jonathan and Carbin, Michael.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Ha \& Schmidhuber(2018)Ha and Schmidhuber]{ha2018world}
Ha, David and Schmidhuber, J{\"u}rgen.
\newblock World models.
\newblock \emph{arXiv preprint arXiv:1803.10122}, 2018.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, Tuomas, Zhou, Aurick, Abbeel, Pieter, and Levine, Sergey.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner2018learning}
Hafner, Danijar, Lillicrap, Timothy, Fischer, Ian, Villegas, Ruben, Ha, David,
  Lee, Honglak, and Davidson, James.
\newblock Learning latent dynamics for planning from pixels.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Ba, and
  Norouzi]{hafner2019dream}
Hafner, Danijar, Lillicrap, Timothy, Ba, Jimmy, and Norouzi, Mohammad.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Han et~al.(2015)Han, Mao, and Dally]{han2015deep}
Han, Song, Mao, Huizi, and Dally, William~J.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock \emph{arXiv preprint arXiv:1510.00149}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hessel et~al.(2018)Hessel, Modayil, Van~Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{hessel2018rainbow}
Hessel, Matteo, Modayil, Joseph, Van~Hasselt, Hado, Schaul, Tom, Ostrovski,
  Georg, Dabney, Will, Horgan, Dan, Piot, Bilal, Azar, Mohammad, and Silver,
  David.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Higgins et~al.(2017)Higgins, Pal, Rusu, Matthey, Burgess, Pritzel,
  Botvinick, Blundell, and Lerchner]{higgins2017darla}
Higgins, Irina, Pal, Arka, Rusu, Andrei~A, Matthey, Loic, Burgess,
  Christopher~P, Pritzel, Alexander, Botvinick, Matthew, Blundell, Charles, and
  Lerchner, Alexander.
\newblock Darla: Improving zero-shot transfer in reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Huang et~al.(2018)Huang, Liu, Van~der Maaten, and
  Weinberger]{huang2018condensenet}
Huang, Gao, Liu, Shichen, Van~der Maaten, Laurens, and Weinberger, Kilian~Q.
\newblock Condensenet: An efficient densenet using learned group convolutions.
\newblock In \emph{IEEE conference on computer vision and pattern recognition},
  2018.

\bibitem[Iandola et~al.(2016)Iandola, Han, Moskewicz, Ashraf, Dally, and
  Keutzer]{iandola2016squeezenet}
Iandola, Forrest~N, Han, Song, Moskewicz, Matthew~W, Ashraf, Khalid, Dally,
  William~J, and Keutzer, Kurt.
\newblock Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5
  mb model size.
\newblock \emph{arXiv preprint arXiv:1602.07360}, 2016.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Mnih, Czarnecki, Schaul, Leibo,
  Silver, and Kavukcuoglu]{jaderberg2016reinforcement}
Jaderberg, Max, Mnih, Volodymyr, Czarnecki, Wojciech~Marian, Schaul, Tom,
  Leibo, Joel~Z, Silver, David, and Kavukcuoglu, Koray.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Jeong \& Shin(2019)Jeong and Shin]{jeong2019training}
Jeong, Jongheon and Shin, Jinwoo.
\newblock Training cnns with selective allocation of channels.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and
  Cassandra]{kaelbling1998planning}
Kaelbling, Leslie~Pack, Littman, Michael~L, and Cassandra, Anthony~R.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artificial intelligence}, 101\penalty0 (1-2):\penalty0 99--134,
  1998.

\bibitem[Kaiser et~al.(2020)Kaiser, Babaeizadeh, Milos, Osinski, Campbell,
  Czechowski, Erhan, Finn, Kozakowski, Levine, et~al.]{kaiser2019model}
Kaiser, Lukasz, Babaeizadeh, Mohammad, Milos, Piotr, Osinski, Blazej, Campbell,
  Roy~H, Czechowski, Konrad, Erhan, Dumitru, Finn, Chelsea, Kozakowski, Piotr,
  Levine, Sergey, et~al.
\newblock Model-based reinforcement learning for atari.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Kalashnikov et~al.(2018)Kalashnikov, Irpan, Pastor, Ibarz, Herzog,
  Jang, Quillen, Holly, Kalakrishnan, Vanhoucke, et~al.]{kalashnikov2018qt}
Kalashnikov, Dmitry, Irpan, Alex, Pastor, Peter, Ibarz, Julian, Herzog,
  Alexander, Jang, Eric, Quillen, Deirdre, Holly, Ethan, Kalakrishnan, Mrinal,
  Vanhoucke, Vincent, et~al.
\newblock Qt-opt: Scalable deep reinforcement learning for vision-based robotic
  manipulation.
\newblock In \emph{Conference on Robot Learning}, 2018.

\bibitem[Kostrikov et~al.(2020)Kostrikov, Yarats, and
  Fergus]{kostrikov2020image}
Kostrikov, Ilya, Yarats, Denis, and Fergus, Rob.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock \emph{arXiv preprint arXiv:2004.13649}, 2020.

\bibitem[Lake et~al.(2017)Lake, Ullman, Tenenbaum, and
  Gershman]{lake2017building}
Lake, Brenden~M, Ullman, Tomer~D, Tenenbaum, Joshua~B, and Gershman, Samuel~J.
\newblock Building machines that learn and think like people.
\newblock \emph{Behavioral and brain sciences}, 40, 2017.

\bibitem[Laskin et~al.(2020)Laskin, Lee, Stooke, Pinto, Abbeel, and
  Srinivas]{laskin2020reinforcement}
Laskin, Michael, Lee, Kimin, Stooke, Adam, Pinto, Lerrel, Abbeel, Pieter, and
  Srinivas, Aravind.
\newblock Reinforcement learning with augmented data.
\newblock In \emph{Advances in neural information processing systems}, 2020.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
LeCun, Yann, Bottou, L{\'e}on, Bengio, Yoshua, and Haffner, Patrick.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee et~al.(2020)Lee, Laskin, Srinivas, and Abbeel]{lee2020sunrise}
Lee, Kimin, Laskin, Michael, Srinivas, Aravind, and Abbeel, Pieter.
\newblock Sunrise: A simple unified framework for ensemble learning in deep
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2007.04938}, 2020.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, Timothy~P, Hunt, Jonathan~J, Pritzel, Alexander, Heess, Nicolas,
  Erez, Tom, Tassa, Yuval, Silver, David, and Wierstra, Daan.
\newblock Continuous control with deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Lin(1992)]{lin1992self}
Lin, Long-Ji.
\newblock Self-improving reactive agents based on reinforcement learning,
  planning and teaching.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 293--321, 1992.

\bibitem[Mattson et~al.(2020)Mattson, Cheng, Coleman, Diamos, Micikevicius,
  Patterson, Tang, Wei, Bailis, Bittorf, et~al.]{mattson2019mlperf}
Mattson, Peter, Cheng, Christine, Coleman, Cody, Diamos, Greg, Micikevicius,
  Paulius, Patterson, David, Tang, Hanlin, Wei, Gu-Yeon, Bailis, Peter,
  Bittorf, Victor, et~al.
\newblock Mlperf training benchmark.
\newblock In \emph{Conference on Machine Learning and Systems}, 2020.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei~A, Veness,
  Joel, Bellemare, Marc~G, Graves, Alex, Riedmiller, Martin, Fidjeland,
  Andreas~K, Ostrovski, Georg, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Morcos et~al.(2018)Morcos, Raghu, and Bengio]{morcos2018insights}
Morcos, Ari, Raghu, Maithra, and Bengio, Samy.
\newblock Insights on representational similarity in neural networks with
  canonical correlation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Obando-Ceron \& Castro(2020)Obando-Ceron and
  Castro]{obando2020revisiting}
Obando-Ceron, Johan~S and Castro, Pablo~Samuel.
\newblock Revisiting rainbow: Promoting more insightful and inclusive deep
  reinforcement learning research.
\newblock \emph{arXiv preprint arXiv:2011.14826}, 2020.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, Aaron van~den, Li, Yazhe, and Vinyals, Oriol.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and
  Van~Roy]{osband2016deep}
Osband, Ian, Blundell, Charles, Pritzel, Alexander, and Van~Roy, Benjamin.
\newblock Deep exploration via bootstrapped dqn.
\newblock In \emph{Advances in neural information processing systems}, 2016.

\bibitem[Pellegrini et~al.(2019)Pellegrini, Graffieti, Lomonaco, and
  Maltoni]{pellegrini2019latent}
Pellegrini, Lorenzo, Graffieti, Gabrile, Lomonaco, Vincenzo, and Maltoni,
  Davide.
\newblock Latent replay for real-time continual learning.
\newblock \emph{arXiv preprint arXiv:1912.01100}, 2019.

\bibitem[Raghu et~al.(2017)Raghu, Gilmer, Yosinski, and Sohl-Dickstein]{46337}
Raghu, Maithra, Gilmer, Justin, Yosinski, Jason, and Sohl-Dickstein, Jascha.
\newblock Svcca: Singular vector canonical correlation analysis for deep
  understanding and improvement.
\newblock In \emph{Advances in neural information processing systems}, 2017.

\bibitem[Schrittwieser et~al.(2019)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel,
  et~al.]{schrittwieser2019mastering}
Schrittwieser, Julian, Antonoglou, Ioannis, Hubert, Thomas, Simonyan, Karen,
  Sifre, Laurent, Schmitt, Simon, Guez, Arthur, Lockhart, Edward, Hassabis,
  Demis, Graepel, Thore, et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{arXiv preprint arXiv:1911.08265}, 2019.

\bibitem[Schulman et~al.(2017)Schulman, Chen, and
  Abbeel]{schulman2017equivalence}
Schulman, John, Chen, Xi, and Abbeel, Pieter.
\newblock Equivalence between policy gradients and soft q-learning.
\newblock \emph{arXiv preprint arXiv:1704.06440}, 2017.

\bibitem[Srinivas et~al.(2020)Srinivas, Laskin, and Abbeel]{srinivas2020curl}
Srinivas, Aravind, Laskin, Michael, and Abbeel, Pieter.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Stooke et~al.(2020)Stooke, Lee, Abbeel, and
  Laskin]{stooke2020decoupling}
Stooke, Adam, Lee, Kimin, Abbeel, Pieter, and Laskin, Michael.
\newblock Decoupling representation learning from reinforcement learning, 2020.

\bibitem[Stooke et~al.(2021)Stooke, Lee, Abbeel, and
  Laskin]{stooke2021decoupling}
Stooke, Adam, Lee, Kimin, Abbeel, Pieter, and Laskin, Michael.
\newblock Decoupling representation learning from reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9870--9879. PMLR, 2021.

\bibitem[Sun et~al.(2020)Sun, Yu, Song, Liu, Yang, and Zhou]{sun2020mobilebert}
Sun, Zhiqing, Yu, Hongkun, Song, Xiaodan, Liu, Renjie, Yang, Yiming, and Zhou,
  Denny.
\newblock Mobilebert: a compact task-agnostic bert for resource-limited
  devices.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}, 2020.

\bibitem[Sutton(1991)]{sutton1991dyna}
Sutton, Richard~S.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock \emph{ACM Sigart Bulletin}, 2\penalty0 (4):\penalty0 160--163, 1991.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Sutton, Richard~S and Barto, Andrew~G.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT Press, 2018.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden,
  Abdolmaleki, Merel, Lefrancq, et~al.]{tassa2018deepmind}
Tassa, Yuval, Doron, Yotam, Muldal, Alistair, Erez, Tom, Li, Yazhe, Casas,
  Diego de~Las, Budden, David, Abdolmaleki, Abbas, Merel, Josh, Lefrancq,
  Andrew, et~al.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}, 2018.

\bibitem[Tay et~al.(2019)Tay, Zhang, Tuan, Rao, Zhang, Wang, Fu, and
  Hui]{tay2019lightweight}
Tay, Yi, Zhang, Aston, Tuan, Luu~Anh, Rao, Jinfeng, Zhang, Shuai, Wang,
  Shuohang, Fu, Jie, and Hui, Siu~Cheung.
\newblock Lightweight and efficient neural natural language processing with
  quaternion networks.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}, 2019.

\bibitem[Van~Hasselt et~al.(2016)Van~Hasselt, Guez, and Silver]{van2016deep}
Van~Hasselt, Hado, Guez, Arthur, and Silver, David.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[van Hasselt et~al.(2019)van Hasselt, Hessel, and
  Aslanides]{van2019use}
van Hasselt, Hado~P, Hessel, Matteo, and Aslanides, John.
\newblock When to use parametric models in reinforcement learning?
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  14322--14333, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, Ashish, Shazeer, Noam, Parmar, Niki, Uszkoreit, Jakob, Jones, Llion,
  Gomez, Aidan~N, Kaiser, {\L}ukasz, and Polosukhin, Illia.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, 2017.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{vinyals2019grandmaster}
Vinyals, Oriol, Babuschkin, Igor, Czarnecki, Wojciech~M, Mathieu, Micha{\"e}l,
  Dudzik, Andrew, Chung, Junyoung, Choi, David~H, Powell, Richard, Ewalds,
  Timo, Georgiev, Petko, et~al.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{watkins1992q}
Watkins, Christopher~JCH and Dayan, Peter.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Yarats et~al.(2019)Yarats, Zhang, Kostrikov, Amos, Pineau, and
  Fergus]{yarats2019improving}
Yarats, Denis, Zhang, Amy, Kostrikov, Ilya, Amos, Brandon, Pineau, Joelle, and
  Fergus, Rob.
\newblock Improving sample efficiency in model-free reinforcement learning from
  images.
\newblock \emph{arXiv preprint arXiv:1910.01741}, 2019.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski2014transferable}
Yosinski, Jason, Clune, Jeff, Bengio, Yoshua, and Lipson, Hod.
\newblock How transferable are features in deep neural networks?
\newblock In \emph{Advances in neural information processing systems}, 2014.

\bibitem[Zagoruyko \& Komodakis(2017)Zagoruyko and
  Komodakis]{zagoruyko2016paying}
Zagoruyko, Sergey and Komodakis, Nikos.
\newblock Paying more attention to attention: Improving the performance of
  convolutional neural networks via attention transfer.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Ziebart(2010)]{ziebart2010modeling}
Ziebart, Brian~D.
\newblock Modeling purposeful adaptive behavior with the principle of maximum
  causal entropy.
\newblock 2010.

\end{thebibliography}
