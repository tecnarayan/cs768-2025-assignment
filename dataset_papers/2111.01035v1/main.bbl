\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrieu et~al.(2003)Andrieu, De~Freitas, Doucet, and
  Jordan]{andrieu03}
Christophe Andrieu, Nando De~Freitas, Arnaud Doucet, and Michael~I Jordan.
\newblock An introduction to mcmc for machine learning.
\newblock \emph{Machine learning}, 50\penalty0 (1):\penalty0 5--43, 2003.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and Bottou]{arjovsky17}
Mart{\'{\i}}n Arjovsky, Soumith Chintala, and L{\'{e}}on Bottou.
\newblock Wasserstein {GAN}.
\newblock \emph{CoRR}, abs/1701.07875, 2017.

\bibitem[Brock et~al.(2019)Brock, Donahue, and Simonyan]{brock19}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In \emph{ICLR}, 2019.

\bibitem[Chrysos et~al.(2020)Chrysos, Kossaifi, and Zafeiriou]{chrysos20}
Grigorios~G. Chrysos, Jean Kossaifi, and Stefanos Zafeiriou.
\newblock Rocgan: Robust conditional {GAN}.
\newblock \emph{Int. J. Comput. Vis.}, 128\penalty0 (10):\penalty0 2665--2683,
  2020.

\bibitem[Dai et~al.(2019)Dai, Liu, Dai, He, Gretton, Song, and
  Schuurmans]{dai19}
Bo~Dai, Zhen Liu, Hanjun Dai, Niao He, Arthur Gretton, Le~Song, and Dale
  Schuurmans.
\newblock Exponential family estimation via adversarial dynamics embedding.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng09}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, 2009.

\bibitem[Denton et~al.(2015)Denton, Chintala, Szlam, and Fergus]{denton15}
Emily~L. Denton, Soumith Chintala, Arthur Szlam, and Rob Fergus.
\newblock Deep generative image models using a laplacian pyramid of adversarial
  networks.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Fedus et~al.(2018)Fedus, Rosca, Lakshminarayanan, Dai, Mohamed, and
  Goodfellow]{fedus18}
William Fedus, Mihaela Rosca, Balaji Lakshminarayanan, Andrew~M. Dai, Shakir
  Mohamed, and Ian~J. Goodfellow.
\newblock Many paths to equilibrium: Gans do not need to decrease a divergence
  at every step.
\newblock In \emph{ICLR}, 2018.

\bibitem[Gan et~al.(2017)Gan, Chen, Wang, Pu, Zhang, Liu, Li, and Carin]{gan17}
Zhe Gan, Liqun Chen, Weiyao Wang, Yunchen Pu, Yizhe Zhang, Hao Liu, Chunyuan
  Li, and Lawrence Carin.
\newblock Triangle generative adversarial networks.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow14}
Ian~J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock \emph{CoRR}, abs/1406.2661, 2014.

\bibitem[Grathwohl et~al.(2020{\natexlab{a}})Grathwohl, Kelly, Hashemi,
  Norouzi, Swersky, and Duvenaud]{grathwohl20b}
Will Grathwohl, Jacob Kelly, Milad Hashemi, Mohammad Norouzi, Kevin Swersky,
  and David Duvenaud.
\newblock No {MCMC} for me: Amortized sampling for fast and stable training of
  energy-based models.
\newblock \emph{CoRR}, abs/2010.04230, 2020{\natexlab{a}}.

\bibitem[Grathwohl et~al.(2020{\natexlab{b}})Grathwohl, Wang, Jacobsen,
  Duvenaud, Norouzi, and Swersky]{grathwohl20}
Will Grathwohl, Kuan{-}Chieh Wang, J{\"{o}}rn{-}Henrik Jacobsen, David
  Duvenaud, Mohammad Norouzi, and Kevin Swersky.
\newblock Your classifier is secretly an energy based model and you should
  treat it like one.
\newblock In \emph{ICLR}, 2020{\natexlab{b}}.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani17}
Ishaan Gulrajani, Faruk Ahmed, Mart{\'{\i}}n Arjovsky, Vincent Dumoulin, and
  Aaron~C. Courville.
\newblock Improved training of wasserstein gans.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel17}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Hu et~al.(2019)Hu, Zhou, and He]{hu19}
Mingqi Hu, Deyu Zhou, and Yulan He.
\newblock Variational conditional {GAN} for fine-grained controllable image
  generation.
\newblock In \emph{ACML}, 2019.

\bibitem[Kang and Park(2020)]{kang20}
Minguk Kang and Jaesik Park.
\newblock Contragan: Contrastive learning for conditional image generation.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Karras et~al.(2018)Karras, Aila, Laine, and Lehtinen]{karras18}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock In \emph{ICLR}, 2018.

\bibitem[Kim et~al.(2017)Kim, Cha, Kim, Lee, and Kim]{kim17}
Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung~Kwon Lee, and Jiwon Kim.
\newblock Learning to discover cross-domain relations with generative
  adversarial networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Kingma and Ba(2015)]{kingma14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{ICLR}, 2015.

\bibitem[Krizhevsky et~al.(2009)]{krizhevsky09}
Alex Krizhevsky et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kumar et~al.(2019)Kumar, Goyal, Courville, and Bengio]{kumar19}
Rithesh Kumar, Anirudh Goyal, Aaron~C. Courville, and Yoshua Bengio.
\newblock Maximum entropy generators for energy-based models.
\newblock \emph{CoRR}, abs/1901.08508, 2019.

\bibitem[Le and Yang(2015)]{le15}
Ya~Le and Xuan Yang.
\newblock Tiny imagenet visual recognition challenge.
\newblock \emph{CS 231N}, 7:\penalty0 7, 2015.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, and Huang]{lecun06}
Yann LeCun, Sumit Chopra, Raia Hadsell, M~Ranzato, and F~Huang.
\newblock A tutorial on energy-based learning.
\newblock 2006.

\bibitem[Li et~al.(2017{\natexlab{a}})Li, Xu, Zhu, and Zhang]{li17b}
Chongxuan Li, Taufik Xu, Jun Zhu, and Bo~Zhang.
\newblock Triple generative adversarial nets.
\newblock In \emph{NeurIPS}, 2017{\natexlab{a}}.

\bibitem[Li et~al.(2017{\natexlab{b}})Li, Chang, Cheng, Yang, and
  P{\'{o}}czos]{li17}
Chun{-}Liang Li, Wei{-}Cheng Chang, Yu~Cheng, Yiming Yang, and Barnab{\'{a}}s
  P{\'{o}}czos.
\newblock {MMD} {GAN:} towards deeper understanding of moment matching network.
\newblock In \emph{NeurIPS}, 2017{\natexlab{b}}.

\bibitem[Lim and Ye(2017)]{lim17}
Jae~Hyun Lim and Jong~Chul Ye.
\newblock Geometric {GAN}.
\newblock \emph{CoRR}, abs/1705.02894, 2017.

\bibitem[Lim et~al.(2020)Lim, Courville, Pal, and Huang]{lim20}
Jae~Hyun Lim, Aaron~C. Courville, Christopher~J. Pal, and Chin{-}Wei Huang.
\newblock {AR-DAE:} towards unbiased neural entropy gradient estimation.
\newblock In \emph{ICML}, 2020.

\bibitem[Liu and Abbeel(2020)]{liu20}
Hao Liu and Pieter Abbeel.
\newblock Hybrid discriminative-generative training via contrastive learning.
\newblock \emph{CoRR}, abs/2007.09070, 2020.

\bibitem[Mao et~al.(2017)Mao, Li, Xie, Lau, Wang, and Smolley]{mao17}
Xudong Mao, Qing Li, Haoran Xie, Raymond Y.~K. Lau, Zhen Wang, and Stephen~Paul
  Smolley.
\newblock Least squares generative adversarial networks.
\newblock In \emph{ICCV}, 2017.

\bibitem[Maurer et~al.(2016)Maurer, Pontil, and Romera{-}Paredes]{maurer16}
Andreas Maurer, Massimiliano Pontil, and Bernardino Romera{-}Paredes.
\newblock The benefit of multitask representation learning.
\newblock \emph{JMLR}, 17:\penalty0 81:1--81:32, 2016.

\bibitem[Mescheder et~al.(2018)Mescheder, Geiger, and Nowozin]{mescheder18}
Lars~M. Mescheder, Andreas Geiger, and Sebastian Nowozin.
\newblock Which training methods for gans do actually converge?
\newblock In \emph{ICML}, 2018.

\bibitem[Michelsanti and Tan(2017)]{michelsanti17}
Daniel Michelsanti and Zheng{-}Hua Tan.
\newblock Conditional generative adversarial networks for speech enhancement
  and noise-robust speaker verification.
\newblock In \emph{Interspeech}, 2017.

\bibitem[Mirza and Osindero(2014)]{mirza14}
Mehdi Mirza and Simon Osindero.
\newblock Conditional generative adversarial nets.
\newblock \emph{CoRR}, abs/1411.1784, 2014.

\bibitem[Miyato and Koyama(2018)]{miyato18b}
Takeru Miyato and Masanori Koyama.
\newblock cgans with projection discriminator.
\newblock In \emph{ICLR}, 2018.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and Yoshida]{miyato18}
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.
\newblock Spectral normalization for generative adversarial networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Mroueh and Sercu(2017)]{mroueh2017fisher}
Youssef Mroueh and Tom Sercu.
\newblock Fisher gan.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Mroueh et~al.(2017)Mroueh, Sercu, and Goel]{mroueh2017mcgan}
Youssef Mroueh, Tom Sercu, and Vaibhava Goel.
\newblock Mcgan: Mean and covariance feature matching gan.
\newblock In \emph{ICML}, 2017.

\bibitem[Mroueh et~al.(2018)Mroueh, Li, Sercu, Raj, and
  Cheng]{mroueh2017sobolev}
Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, and Yu~Cheng.
\newblock Sobolev gan.
\newblock In \emph{ICLR}, 2018.

\bibitem[Odena et~al.(2017)Odena, Olah, and Shlens]{odena17}
Augustus Odena, Christopher Olah, and Jonathon Shlens.
\newblock Conditional image synthesis with auxiliary classifier gans.
\newblock In Doina Precup and Yee~Whye Teh, editors, \emph{ICML}, 2017.

\bibitem[Poole et~al.(2019)Poole, Ozair, van~den Oord, Alemi, and
  Tucker]{poole19}
Ben Poole, Sherjil Ozair, A{\"{a}}ron van~den Oord, Alex Alemi, and George
  Tucker.
\newblock On variational bounds of mutual information.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, \emph{ICML},
  2019.

\bibitem[Radford et~al.(2016)Radford, Metz, and Chintala]{radford15}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock In \emph{ICLR}, 2016.

\bibitem[Ranganath et~al.(2016)Ranganath, Tran, and Blei]{ranganath16}
Rajesh Ranganath, Dustin Tran, and David~M. Blei.
\newblock Hierarchical variational models.
\newblock In \emph{ICML}, 2016.

\bibitem[Reed et~al.(2016)Reed, Akata, Yan, Logeswaran, Schiele, and
  Lee]{reed16}
Scott~E. Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele,
  and Honglak Lee.
\newblock Generative adversarial text to image synthesis.
\newblock In \emph{ICML}, 2016.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{salimans16}
Tim Salimans, Ian~J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford,
  and Xi~Chen.
\newblock Improved techniques for training gans.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Shu(2017)]{shu17}
Rui Shu.
\newblock Ac-gan learns a biased distribution.
\newblock 2017.

\bibitem[Singh and P{\'{o}}czos(2016)]{singh16}
Shashank Singh and Barnab{\'{a}}s P{\'{o}}czos.
\newblock Analysis of k-nearest neighbor distances with application to entropy
  estimation.
\newblock \emph{CoRR}, abs/1603.08578, 2016.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and Vinyals]{oord18}
A{\"{a}}ron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{CoRR}, abs/1807.03748, 2018.

\bibitem[Wainwright and Jordan(2008)]{wainwright08}
Martin~J. Wainwright and Michael~I. Jordan.
\newblock Graphical models, exponential families, and variational inference.
\newblock \emph{Found. Trends Mach. Learn.}, 1\penalty0 (1-2):\penalty0 1--305,
  2008.

\bibitem[Yazici et~al.(2019)Yazici, Foo, Winkler, Yap, Piliouras, and
  Chandrasekhar]{yazici19}
Yasin Yazici, Chuan{-}Sheng Foo, Stefan Winkler, Kim{-}Hui Yap, Georgios
  Piliouras, and Vijay Chandrasekhar.
\newblock The unusual effectiveness of averaging in {GAN} training.
\newblock In \emph{ICLR}, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Goodfellow, Metaxas, and Odena]{zhang19}
Han Zhang, Ian~J. Goodfellow, Dimitris~N. Metaxas, and Augustus Odena.
\newblock Self-attention generative adversarial networks.
\newblock In \emph{ICML}, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Zhang, Odena, and Lee]{zhang20}
Han Zhang, Zizhao Zhang, Augustus Odena, and Honglak Lee.
\newblock Consistency regularization for generative adversarial networks.
\newblock In \emph{ICLR}, 2020.

\bibitem[Zhao et~al.(2020)Zhao, Liu, Lin, Zhu, and Han]{zhao20}
Shengyu Zhao, Zhijian Liu, Ji~Lin, Jun{-}Yan Zhu, and Song Han.
\newblock Differentiable augmentation for data-efficient {GAN} training.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Zhu et~al.(2017)Zhu, Park, Isola, and Efros]{zhu17}
Jun{-}Yan Zhu, Taesung Park, Phillip Isola, and Alexei~A. Efros.
\newblock Unpaired image-to-image translation using cycle-consistent
  adversarial networks.
\newblock In \emph{ICCV}, 2017.

\end{thebibliography}
