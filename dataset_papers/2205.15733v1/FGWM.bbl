\begin{thebibliography}{10}

\bibitem{afriat1971theory}
S.~Afriat.
\newblock Theory of maxima and the method of lagrange.
\newblock {\em SIAM Journal on Applied Mathematics}, 20(3):343--357, 1971.

\bibitem{balcan2008theory}
M.-F. Balcan, A.~Blum, and N.~Srebro.
\newblock A theory of learning with similarity functions.
\newblock {\em Machine Learning}, 72(1):89--112, 2008.

\bibitem{battaglia2018relational}
P.~W. Battaglia, J.~B. Hamrick, V.~Bapst, A.~Sanchez-Gonzalez, V.~Zambaldi,
  M.~Malinowski, A.~Tacchetti, D.~Raposo, A.~Santoro, R.~Faulkner, C.~Gulcehre,
  F.~Song, A.~Ballard, J.~Gilmer, G.~Dahl, A.~Vaswani, K.~Allen, C.~Nash,
  V.~Langston, C.~Dyer, N.~Heess, D.~Wierstra, P.~Kohli, M.~Botvinick,
  O.~Vinyals, Y.~Li, and R.~Pascanu.
\newblock Relational inductive biases, deep learning, and graph networks, 2018.

\bibitem{bengio2003no}
Y.~Bengio and Y.~Grandvalet.
\newblock No unbiased estimator of the variance of k-fold cross-validation.
\newblock {\em Advances in Neural Information Processing Systems}, 16, 2003.

\bibitem{borgwardt2005shortest}
K.~M. Borgwardt and H.-P. Kriegel.
\newblock Shortest-path kernels on graphs.
\newblock In {\em Fifth IEEE international conference on data mining
  (ICDM'05)}, pages 8--pp. IEEE, 2005.

\bibitem{borgwardt2005protein}
K.~M. Borgwardt, C.~S. Ong, S.~Sch{\"o}nauer, S.~Vishwanathan, A.~J. Smola, and
  H.-P. Kriegel.
\newblock Protein function prediction via graph kernels.
\newblock {\em Bioinformatics}, 21(suppl\_1):i47--i56, 2005.

\bibitem{Bronstein2021GeometricDL}
M.~M. Bronstein, J.~Bruna, T.~Cohen, and P.~Velivckovi\'c.
\newblock Geometric deep learning: Grids, groups, graphs, geodesics, and
  gauges.
\newblock {\em ArXiv}, abs/2104.13478, 2021.

\bibitem{bronstein2017geometric}
M.~M. Bronstein, J.~Bruna, Y.~LeCun, A.~Szlam, and P.~Vandergheynst.
\newblock Geometric deep learning: going beyond euclidean data.
\newblock {\em IEEE Signal Processing Magazine}, 34(4):18--42, 2017.

\bibitem{sklearn_api}
L.~Buitinck, G.~Louppe, M.~Blondel, F.~Pedregosa, A.~Mueller, O.~Grisel,
  V.~Niculae, P.~Prettenhofer, A.~Gramfort, J.~Grobler, R.~Layton,
  J.~VanderPlas, A.~Joly, B.~Holt, and G.~Varoquaux.
\newblock {API} design for machine learning software: experiences from the
  scikit-learn project.
\newblock In {\em ECML PKDD Workshop: Languages for Data Mining and Machine
  Learning}, pages 108--122, 2013.

\bibitem{Chami2022}
I.~Chami, S.~Abu-El-Haija, B.~Perozzi, C.~R\'e, and K.~Murphy.
\newblock Machine learning on graphs: A model and comprehensive taxonomy.
\newblock {\em Journal of Machine Learning Research}, 23(89):1--64, 2022.

\bibitem{chen2020optimal}
B.~Chen, G.~B{\'e}cigneul, O.-E. Ganea, R.~Barzilay, and T.~Jaakkola.
\newblock Optimal transport graph neural networks.
\newblock {\em arXiv preprint arXiv:2006.04804}, 2020.

\bibitem{chen2019equivalence}
Z.~Chen, S.~Villar, L.~Chen, and J.~Bruna.
\newblock On the equivalence between graph isomorphism testing and function
  approximation with gnns.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{chowdhury2021quantized}
S.~Chowdhury, D.~Miller, and T.~Needham.
\newblock Quantized gromov-wasserstein.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 811--827. Springer, 2021.

\bibitem{chowdhury-gromov-wasserstein-2019}
S.~Chowdhury and F.~MÃ©moli.
\newblock The {Gromov}-{Wasserstein} distance between networks and stable
  network invariants.
\newblock {\em arXiv:1808.04337 [cs, math]}, Sept. 2019.
\newblock arXiv: 1808.04337.

\bibitem{chowdhury2021generalized}
S.~Chowdhury and T.~Needham.
\newblock Generalized spectral clustering via gromov-wasserstein learning.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 712--720. PMLR, 2021.

\bibitem{condat2016fast}
L.~Condat.
\newblock Fast projection onto the simplex and the l1 ball.
\newblock {\em Mathematical Programming}, 158(1):575--585, 2016.

\bibitem{feragen2013scalable}
A.~Feragen, N.~Kasenburg, J.~Petersen, M.~de~Bruijne, and K.~Borgwardt.
\newblock Scalable kernels for graphs with continuous attributes.
\newblock {\em Advances in neural information processing systems}, 26, 2013.

\bibitem{flamary2021pot}
R.~Flamary, N.~Courty, A.~Gramfort, M.~Z. Alaya, A.~Boisbunon, S.~Chambon,
  L.~Chapel, A.~Corenflos, K.~Fatras, N.~Fournier, L.~Gautheron, N.~T. Gayraud,
  H.~Janati, A.~Rakotomamonjy, I.~Redko, A.~Rolet, A.~Schutz, V.~Seguy, D.~J.
  Sutherland, R.~Tavenard, A.~Tong, and T.~Vayer.
\newblock Pot: Python optimal transport.
\newblock {\em Journal of Machine Learning Research}, 22(78):1--8, 2021.

\bibitem{gartner2003graph}
T.~G{\"a}rtner, P.~Flach, and S.~Wrobel.
\newblock On graph kernels: Hardness results and efficient alternatives.
\newblock In {\em Learning theory and kernel machines}, pages 129--143.
  Springer, 2003.

\bibitem{hamilton2017inductive}
W.~Hamilton, Z.~Ying, and J.~Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{harchaoui2007image}
Z.~Harchaoui and F.~Bach.
\newblock Image classification with segmentation graph kernels.
\newblock In {\em 2007 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 1--8. IEEE, 2007.

\bibitem{hornik1989multilayer}
K.~Hornik, M.~Stinchcombe, and H.~White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock {\em Neural networks}, 2(5):359--366, 1989.

\bibitem{jumper2021highly}
J.~Jumper, R.~Evans, A.~Pritzel, T.~Green, M.~Figurnov, O.~Ronneberger,
  K.~Tunyasuvunakool, R.~Bates, A.~{\v{Z}}{\'\i}dek, A.~Potapenko, et~al.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock {\em Nature}, 596(7873):583--589, 2021.

\bibitem{KKMMN2016}
K.~Kersting, N.~M. Kriege, C.~Morris, P.~Mutzel, and M.~Neumann.
\newblock Benchmark data sets for graph kernels, 2016.

\bibitem{kipf2016semi}
T.~N. Kipf and M.~Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock {\em arXiv preprint arXiv:1609.02907}, 2016.

\bibitem{knyazev2019understanding}
B.~Knyazev, G.~W. Taylor, and M.~Amer.
\newblock Understanding attention and generalization in graph neural networks.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{kolouri2020wasserstein}
S.~Kolouri, N.~Naderializadeh, G.~K. Rohde, and H.~Hoffmann.
\newblock Wasserstein embedding for graph learning.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{kriege2012subgraph}
N.~Kriege and P.~Mutzel.
\newblock Subgraph matching kernels for attributed graphs.
\newblock {\em arXiv preprint arXiv:1206.6483}, 2012.

\bibitem{kriege2020survey}
N.~M. Kriege, F.~D. Johansson, and C.~Morris.
\newblock A survey on graph kernels.
\newblock {\em Applied Network Science}, 5(1):1--42, 2020.

\bibitem{ktena-distance-2017}
S.~I. Ktena, S.~Parisot, E.~Ferrante, M.~Rajchl, M.~Lee, B.~Glocker, and
  D.~Rueckert.
\newblock Distance metric learning using graph convolutional networks:
  Application to functional brain networks.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 469--477. Springer, 2017.

\bibitem{lacoste-julien-convergence-2016}
S.~Lacoste-Julien.
\newblock Convergence rate of frank-wolfe for non-convex objectives.
\newblock {\em arXiv preprint arXiv:1607.00345}, 2016.

\bibitem{lee2019self}
J.~Lee, I.~Lee, and J.~Kang.
\newblock Self-attention graph pooling.
\newblock In {\em International conference on machine learning}, pages
  3734--3743. PMLR, 2019.

\bibitem{Leman2018THERO}
A.~Leman.
\newblock The reduction of a graph to canonical form and the algebra which
  appears therein.
\newblock 2018.

\bibitem{loukas2019graph}
A.~Loukas.
\newblock What graph neural networks cannot learn: depth vs width.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{maretic2019got}
H.~P. Maretic, M.~El~Gheche, G.~Chierchia, and P.~Frossard.
\newblock Got: an optimal transport framework for graph comparison.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  13876--13887, 2019.

\bibitem{maron2019provably}
H.~Maron, H.~Ben-Hamu, H.~Serviansky, and Y.~Lipman.
\newblock Provably powerful graph networks.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{maron2018invariant}
H.~Maron, H.~Ben-Hamu, N.~Shamir, and Y.~Lipman.
\newblock Invariant and equivariant graph networks.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{mcinnes2018umap}
L.~McInnes, J.~Healy, and J.~Melville.
\newblock Umap: Uniform manifold approximation and projection for dimension
  reduction.
\newblock {\em arXiv preprint arXiv:1802.03426}, 2018.

\bibitem{memoli2011gromov}
F.~M{\'e}moli.
\newblock Gromov--wasserstein distances and the metric approach to object
  matching.
\newblock {\em Foundations of computational mathematics}, 11(4):417--487, 2011.

\bibitem{mesquita2020rethinking}
D.~Mesquita, A.~Souza, and S.~Kaski.
\newblock Rethinking pooling in graph neural networks.
\newblock {\em Advances in Neural Information Processing Systems},
  33:2220--2231, 2020.

\bibitem{NEURIPS2018_1fc21400}
Y.~C. Ng, N.~Colombo, and R.~Silva.
\newblock Bayesian semi-supervised learning with graph gaussian processes.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~31. Curran Associates, Inc., 2018.

\bibitem{niepert2016learning}
M.~Niepert, M.~Ahmed, and K.~Kutzkov.
\newblock Learning convolutional neural networks for graphs.
\newblock In {\em International conference on machine learning}, pages
  2014--2023. PMLR, 2016.

\bibitem{NikolentzosMV17}
G.~Nikolentzos, P.~Meladianos, and M.~Vazirgiannis.
\newblock Matching node embeddings for graph similarity.
\newblock In {\em Proceedings of the Thirty-First {AAAI} Conference on
  Artificial Intelligence, February 4-9, 2017, San Francisco, California,
  {USA.}}, pages 2429--2435, 2017.

\bibitem{papp2021dropgnn}
P.~A. Papp, K.~Martinkus, L.~Faber, and R.~Wattenhofer.
\newblock Drop{GNN}: Random dropouts increase the expressiveness of graph
  neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{paszke2017automatic}
A.~Paszke, S.~Gross, S.~Chintala, G.~Chanan, E.~Yang, Z.~DeVito, Z.~Lin,
  A.~Desmaison, L.~Antiga, and A.~Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{peyre-computational-2020}
G.~Peyr\'{e} and M.~Cuturi.
\newblock Computational optimal transport.
\newblock {\em Foundations and Trends in Machine Learning}, 11:355--607, 2019.

\bibitem{peyre2016gromov}
G.~Peyr{\'e}, M.~Cuturi, and J.~Solomon.
\newblock Gromov-wasserstein averaging of kernel and distance matrices.
\newblock In {\em International Conference on Machine Learning}, pages
  2664--2672, 2016.

\bibitem{rakotomamonjy2018distance}
A.~Rakotomamonjy, A.~Traor{\'e}, M.~Berar, R.~Flamary, and N.~Courty.
\newblock Distance measure machines.
\newblock {\em arXiv preprint arXiv:1803.00250}, 2018.

\bibitem{santambrogio2015optimal}
F.~Santambrogio.
\newblock Optimal transport for applied mathematicians.
\newblock {\em Birk{\"a}user, NY}, 55(58-63):94, 2015.

\bibitem{scetbon2021lineartime}
M.~Scetbon, G.~Peyr{\'e}, and M.~Cuturi.
\newblock Linear-time gromov wasserstein distances using low rank couplings and
  costs, 2021.

\bibitem{shekhovtsov2013distributed}
A.~Shekhovtsov and V.~Hlav{\'a}{\v{c}}.
\newblock A distributed mincut/maxflow algorithm combining path augmentation
  and push-relabel.
\newblock {\em International journal of computer vision}, 104(3):315--342,
  2013.

\bibitem{shervashidze2011weisfeiler}
N.~Shervashidze, P.~Schweitzer, E.~J. Van~Leeuwen, K.~Mehlhorn, and K.~M.
  Borgwardt.
\newblock Weisfeiler-lehman graph kernels.
\newblock {\em Journal of Machine Learning Research}, 12(9), 2011.

\bibitem{shervashidze2009efficient}
N.~Shervashidze, S.~Vishwanathan, T.~Petri, K.~Mehlhorn, and K.~Borgwardt.
\newblock Efficient graphlet kernels for large graph comparison.
\newblock In {\em Artificial intelligence and statistics}, pages 488--495.
  PMLR, 2009.

\bibitem{Shuman2013TheEF}
D.~I. Shuman, S.~K. Narang, P.~Frossard, A.~Ortega, and P.~Vandergheynst.
\newblock The emerging field of signal processing on graphs: Extending
  high-dimensional data analysis to networks and other irregular domains.
\newblock {\em IEEE Signal Processing Magazine}, 30:83--98, 2013.

\bibitem{sturm2012space}
K.-T. Sturm.
\newblock The space of spaces: curvature bounds and gradient flows on the space
  of metric measure spaces.
\newblock {\em arXiv preprint arXiv:1208.0434}, 2012.

\bibitem{Togninalli19}
M.~Togninalli, E.~Ghisu, F.~Llinares-L{\'o}pez, B.~Rieck, and K.~Borgwardt.
\newblock Wasserstein weisfeiler--lehman graph kernels.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6436--6446. Curran Associates, Inc., 2019.

\bibitem{van2008visualizing}
L.~Van~der Maaten and G.~Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(11), 2008.

\bibitem{vayer2020fused}
T.~Vayer, L.~Chapel, R.~Flamary, R.~Tavenard, and N.~Courty.
\newblock Fused gromov-wasserstein distance for structured objects.
\newblock {\em Algorithms}, 13(9):212, 2020.

\bibitem{titouan2019optimal}
T.~Vayer, N.~Courty, R.~Tavenard, and R.~Flamary.
\newblock Optimal transport for structured data with application on graphs.
\newblock In {\em International Conference on Machine Learning}, pages
  6275--6284. PMLR, 2019.

\bibitem{villani2009optimal}
C.~Villani.
\newblock {\em Optimal transport: old and new}, volume 338.
\newblock Springer, 2009.

\bibitem{vincent-cuaz2022semirelaxed}
C.~Vincent-Cuaz, R.~Flamary, M.~Corneli, T.~Vayer, and N.~Courty.
\newblock Semi-relaxed gromov-wasserstein divergence and applications on
  graphs.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{vincent2021online}
C.~Vincent-Cuaz, T.~Vayer, R.~Flamary, M.~Corneli, and N.~Courty.
\newblock Online graph dictionary learning.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning}, volume 139 of {\em Proceedings of Machine Learning Research},
  pages 10564--10574. PMLR, 18--24 Jul 2021.

\bibitem{wu2020comprehensive}
Z.~Wu, S.~Pan, F.~Chen, G.~Long, C.~Zhang, and S.~Y. Philip.
\newblock A comprehensive survey on graph neural networks.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2020.

\bibitem{xu2020gromov}
H.~Xu.
\newblock Gromov-wasserstein factorization models for graph clustering.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 6478--6485, 2020.

\bibitem{xu2019scalable}
H.~Xu, D.~Luo, and L.~Carin.
\newblock Scalable gromov-wasserstein learning for graph partitioning and
  matching.
\newblock {\em Advances in neural information processing systems},
  32:3052--3062, 2019.

\bibitem{xu2018powerful}
K.~Xu, W.~Hu, J.~Leskovec, and S.~Jegelka.
\newblock How powerful are graph neural networks?
\newblock {\em arXiv preprint arXiv:1810.00826}, 2018.

\bibitem{xu2018representation}
K.~Xu, C.~Li, Y.~Tian, T.~Sonobe, K.-i. Kawarabayashi, and S.~Jegelka.
\newblock Representation learning on graphs with jumping knowledge networks.
\newblock In {\em International Conference on Machine Learning}, pages
  5453--5462. PMLR, 2018.

\bibitem{yanardag-deep-2015}
P.~Yanardag and S.~Vishwanathan.
\newblock Deep graph kernels.
\newblock In {\em Proceedings of the 21th ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1365--1374, 2015.

\bibitem{ying2018hierarchical}
Z.~Ying, J.~You, C.~Morris, X.~Ren, W.~Hamilton, and J.~Leskovec.
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{zhang2018end}
M.~Zhang, Z.~Cui, M.~Neumann, and Y.~Chen.
\newblock An end-to-end deep learning architecture for graph classification.
\newblock In {\em Thirty-second AAAI conference on artificial intelligence},
  2018.

\end{thebibliography}
