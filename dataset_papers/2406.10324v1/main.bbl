\begin{thebibliography}{72}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bahmani et~al.(2023)Bahmani, Skorokhodov, Rong, Wetzstein, Guibas, Wonka, Tulyakov, Park, Tagliasacchi, and Lindell]{bahmani20234d}
S.~Bahmani, I.~Skorokhodov, V.~Rong, G.~Wetzstein, L.~Guibas, P.~Wonka, S.~Tulyakov, J.~J. Park, A.~Tagliasacchi, and D.~B. Lindell.
\newblock 4d-fy: Text-to-4d generation using hybrid score distillation sampling.
\newblock \emph{arXiv preprint arXiv:2311.17984}, 2023.

\bibitem[Blattmann et~al.(2023{\natexlab{a}})Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023stable}
A.~Blattmann, T.~Dockhorn, S.~Kulal, D.~Mendelevitch, M.~Kilian, D.~Lorenz, Y.~Levi, Z.~English, V.~Voleti, A.~Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023{\natexlab{a}}.

\bibitem[Blattmann et~al.(2023{\natexlab{b}})Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{blattmann2023videoldm}
A.~Blattmann, R.~Rombach, H.~Ling, T.~Dockhorn, S.~W. Kim, S.~Fidler, and K.~Kreis.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition ({CVPR})}, 2023{\natexlab{b}}.

\bibitem[B{\"u}sching et~al.(2023)B{\"u}sching, Bengtson, Nilsson, and Bj{\"o}rkman]{busching2023flowibr}
M.~B{\"u}sching, J.~Bengtson, D.~Nilsson, and M.~Bj{\"o}rkman.
\newblock Flowibr: Leveraging pre-training for efficient neural image-based rendering of dynamic scenes.
\newblock \emph{arXiv preprint arXiv:2309.05418}, 2023.

\bibitem[Cao and Johnson(2023)]{cao2023hexplane}
A.~Cao and J.~Johnson.
\newblock Hexplane: A fast representation for dynamic scenes.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 130--141, 2023.

\bibitem[Charatan et~al.(2023)Charatan, Li, Tagliasacchi, and Sitzmann]{charatan2023pixelsplat}
D.~Charatan, S.~Li, A.~Tagliasacchi, and V.~Sitzmann.
\newblock pixelsplat: 3d gaussian splats from image pairs for scalable generalizable 3d reconstruction.
\newblock \emph{arXiv preprint arXiv:2312.12337}, 2023.

\bibitem[Chen et~al.(2024)Chen, Xu, Zheng, Zhuang, Pollefeys, Geiger, Cham, and Cai]{chen2024mvsplat}
Y.~Chen, H.~Xu, C.~Zheng, B.~Zhuang, M.~Pollefeys, A.~Geiger, T.-J. Cham, and J.~Cai.
\newblock Mvsplat: Efficient 3d gaussian splatting from sparse multi-view images.
\newblock \emph{arXiv preprint arXiv:2403.14627}, 2024.

\bibitem[Cheng et~al.(2023)Cheng, Li, Xu, Li, Yang, Wang, and Yang]{cheng2023segment}
Y.~Cheng, L.~Li, Y.~Xu, X.~Li, Z.~Yang, W.~Wang, and Y.~Yang.
\newblock Segment and track anything.
\newblock \emph{arXiv preprint arXiv:2305.06558}, 2023.

\bibitem[Community(2018)]{blender}
B.~O. Community.
\newblock \emph{Blender - a 3D modelling and rendering package}.
\newblock Blender Foundation, Stichting Blender Foundation, Amsterdam, 2018.
\newblock URL \url{http://www.blender.org}.

\bibitem[Deepmind(2024)]{veo}
G.~Deepmind.
\newblock Veo: our most capable generative video model.
\newblock 2024.
\newblock URL \url{https://deepmind.google/technologies/veo}.

\bibitem[Deitke et~al.(2023)Deitke, Schwenk, Salvador, Weihs, Michel, VanderBilt, Schmidt, Ehsani, Kembhavi, and Farhadi]{deitke2023objaverse}
M.~Deitke, D.~Schwenk, J.~Salvador, L.~Weihs, O.~Michel, E.~VanderBilt, L.~Schmidt, K.~Ehsani, A.~Kembhavi, and A.~Farhadi.
\newblock Objaverse: A universe of annotated 3d objects.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 13142--13153, 2023.

\bibitem[Fabian Caba~Heilbron and Niebles(2015)]{caba2015activitynet}
B.~G. Fabian Caba~Heilbron, Victor~Escorcia and J.~C. Niebles.
\newblock Activitynet: A large-scale video benchmark for human activity understanding.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 961--970, 2015.

\bibitem[Fridovich-Keil et~al.(2023)Fridovich-Keil, Meanti, Warburg, Recht, and Kanazawa]{fridovich2023k}
S.~Fridovich-Keil, G.~Meanti, F.~R. Warburg, B.~Recht, and A.~Kanazawa.
\newblock K-planes: Explicit radiance fields in space, time, and appearance.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12479--12488, 2023.

\bibitem[Gao et~al.(2021)Gao, Saraf, Kopf, and Huang]{gao2021dynamic}
C.~Gao, A.~Saraf, J.~Kopf, and J.-B. Huang.
\newblock Dynamic view synthesis from dynamic monocular video.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 5712--5721, 2021.

\bibitem[Gao et~al.(2024)Gao, Xu, Cao, Mildenhall, Ma, Chen, Tang, and Neumann]{gao2024gaussianflow}
Q.~Gao, Q.~Xu, Z.~Cao, B.~Mildenhall, W.~Ma, L.~Chen, D.~Tang, and U.~Neumann.
\newblock Gaussianflow: Splatting gaussian dynamics for 4d content creation.
\newblock \emph{arXiv preprint arXiv:2403.12365}, 2024.

\bibitem[Girdhar et~al.(2023)Girdhar, Singh, Brown, Duval, Azadi, Rambhatla, Shah, Yin, Parikh, and Misra]{girdhar2023emu}
R.~Girdhar, M.~Singh, A.~Brown, Q.~Duval, S.~Azadi, S.~S. Rambhatla, A.~Shah, X.~Yin, D.~Parikh, and I.~Misra.
\newblock Emu video: Factorizing text-to-video generation by explicit image conditioning.
\newblock \emph{arXiv preprint arXiv:2311.10709}, 2023.

\bibitem[Grauman et~al.(2022)Grauman, Westbury, Byrne, Chavis, Furnari, Girdhar, Hamburger, Jiang, Liu, Liu, et~al.]{grauman2022ego4d}
K.~Grauman, A.~Westbury, E.~Byrne, Z.~Chavis, A.~Furnari, R.~Girdhar, J.~Hamburger, H.~Jiang, M.~Liu, X.~Liu, et~al.
\newblock Ego4d: Around the world in 3,000 hours of egocentric video.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18995--19012, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem[He and Wang(2023)]{openlrm}
Z.~He and T.~Wang.
\newblock Openlrm: Open-source large reconstruction models.
\newblock \url{https://github.com/3DTopia/OpenLRM}, 2023.

\bibitem[Hong et~al.(2023)Hong, Zhang, Gu, Bi, Zhou, Liu, Liu, Sunkavalli, Bui, and Tan]{hong2023lrm}
Y.~Hong, K.~Zhang, J.~Gu, S.~Bi, Y.~Zhou, D.~Liu, F.~Liu, K.~Sunkavalli, T.~Bui, and H.~Tan.
\newblock Lrm: Large reconstruction model for single image to 3d.
\newblock \emph{arXiv preprint arXiv:2311.04400}, 2023.

\bibitem[Jiang et~al.(2023)Jiang, Zhang, Gao, Hu, and Yao]{jiang2023consistent4d}
Y.~Jiang, L.~Zhang, J.~Gao, W.~Hu, and Y.~Yao.
\newblock Consistent4d: Consistent 360 $\{$$\backslash$deg$\}$ dynamic object generation from monocular video.
\newblock \emph{arXiv preprint arXiv:2311.02848}, 2023.

\bibitem[Kerbl et~al.(2023)Kerbl, Kopanas, Leimk{\"u}hler, and Drettakis]{kerbl20233d}
B.~Kerbl, G.~Kopanas, T.~Leimk{\"u}hler, and G.~Drettakis.
\newblock 3d gaussian splatting for real-time radiance field rendering.
\newblock \emph{ACM Transactions on Graphics}, 42\penalty0 (4):\penalty0 1--14, 2023.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Lin, and Lee]{li2023ghunerf}
C.~Li, J.~Lin, and G.~H. Lee.
\newblock Ghunerf: Generalizable human nerf from a monocular video.
\newblock \emph{arXiv preprint arXiv:2308.16576}, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Li, Zhu, Yu, Zhao, Wan, You, Shi, and Lin]{li2023instant}
S.~Li, C.~Li, W.~Zhu, B.~Yu, Y.~Zhao, C.~Wan, H.~You, H.~Shi, and Y.~Lin.
\newblock Instant-3d: Instant neural radiance field training towards on-device ar/vr 3d reconstruction.
\newblock In \emph{Proceedings of the 50th Annual International Symposium on Computer Architecture}, pages 1--13, 2023{\natexlab{b}}.

\bibitem[Lin et~al.(2023)Lin, Gao, Tang, Takikawa, Zeng, Huang, Kreis, Fidler, Liu, and Lin]{lin2023magic3d}
C.-H. Lin, J.~Gao, L.~Tang, T.~Takikawa, X.~Zeng, X.~Huang, K.~Kreis, S.~Fidler, M.-Y. Liu, and T.-Y. Lin.
\newblock {Magic3D: High-Resolution Text-to-3D Content Creation}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[Ling et~al.(2023)Ling, Kim, Torralba, Fidler, and Kreis]{ling2023align}
H.~Ling, S.~W. Kim, A.~Torralba, S.~Fidler, and K.~Kreis.
\newblock Align your gaussians: Text-to-4d with dynamic 3d gaussians and composed diffusion models.
\newblock \emph{arXiv preprint arXiv:2312.13763}, 2023.

\bibitem[Liu et~al.(2023)Liu, Wu, Van~Hoorick, Tokmakov, Zakharov, and Vondrick]{Liu_2023_ICCV}
R.~Liu, R.~Wu, B.~Van~Hoorick, P.~Tokmakov, S.~Zakharov, and C.~Vondrick.
\newblock Zero-1-to-3: Zero-shot one image to 3d object.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 9298--9309, October 2023.

\bibitem[Lombardi et~al.(2019)Lombardi, Simon, Saragih, Schwartz, Lehrmann, and Sheikh]{lombardi2019neural}
S.~Lombardi, T.~Simon, J.~Saragih, G.~Schwartz, A.~Lehrmann, and Y.~Sheikh.
\newblock Neural volumes: Learning dynamic renderable volumes from images.
\newblock \emph{arXiv preprint arXiv:1906.07751}, 2019.

\bibitem[Luiten et~al.(2023)Luiten, Kopanas, Leibe, and Ramanan]{luiten2023dynamic}
J.~Luiten, G.~Kopanas, B.~Leibe, and D.~Ramanan.
\newblock Dynamic 3d gaussians: Tracking by persistent dynamic view synthesis.
\newblock \emph{arXiv preprint arXiv:2308.09713}, 2023.

\bibitem[Luo et~al.(2023)Luo, Chen, Zhang, Huang, Wang, Shen, Zhao, Zhou, and Tan]{luo2023VideoFusion}
Z.~Luo, D.~Chen, Y.~Zhang, Y.~Huang, L.~Wang, Y.~Shen, D.~Zhao, J.~Zhou, and T.~Tan.
\newblock Videofusion: Decomposed diffusion models for high-quality video generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[Masuda et~al.(2024)Masuda, Park, Iwase, Khirodkar, and Kitani]{masuda2024generalizable}
M.~Masuda, J.~Park, S.~Iwase, R.~Khirodkar, and K.~Kitani.
\newblock Generalizable neural human renderer.
\newblock \emph{arXiv preprint arXiv:2404.14199}, 2024.

\bibitem[Melas-Kyriazi et~al.(2024)Melas-Kyriazi, Laina, Rupprecht, Neverova, Vedaldi, Gafni, and Kokkinos]{melas20243d}
L.~Melas-Kyriazi, I.~Laina, C.~Rupprecht, N.~Neverova, A.~Vedaldi, O.~Gafni, and F.~Kokkinos.
\newblock Im-3d: Iterative multiview diffusion and reconstruction for high-quality 3d generation.
\newblock \emph{arXiv preprint arXiv:2402.08682}, 2024.

\bibitem[Pan et~al.(2024)Pan, Yang, Zhu, and Zhang]{pan2024fast}
Z.~Pan, Z.~Yang, X.~Zhu, and L.~Zhang.
\newblock Fast dynamic 3d object generation from a single-view video, 2024.

\bibitem[Peebles et~al.(2024)Peebles, Brooks, Brooks, Ng, Schnurr, Luhman, Taylor, Jing, Summers, Wang, and et~al.]{sora}
B.~Peebles, T.~Brooks, C.~Brooks, C.~Ng, D.~Schnurr, E.~Luhman, J.~Taylor, L.~Jing, N.~Summers, R.~Wang, and et~al.
\newblock Creating video from text.
\newblock 2024.
\newblock URL \url{https://openai.com/sora}.

\bibitem[Poole et~al.(2023)Poole, Jain, Barron, and Mildenhall]{poole2022dreamfusion}
B.~Poole, A.~Jain, J.~T. Barron, and B.~Mildenhall.
\newblock {DreamFusion: Text-to-3D using 2D Diffusion}.
\newblock In \emph{The Eleventh International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[Pumarola et~al.(2021)Pumarola, Corona, Pons-Moll, and Moreno-Noguer]{pumarola2021d}
A.~Pumarola, E.~Corona, G.~Pons-Moll, and F.~Moreno-Noguer.
\newblock D-nerf: Neural radiance fields for dynamic scenes.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10318--10327, 2021.

\bibitem[Qiu et~al.(2023)Qiu, Chen, Gu, zuo, Xu, Wu, Yuan, Dong, Bo, and Han]{qiu2023richdreamer}
L.~Qiu, G.~Chen, X.~Gu, Q.~zuo, M.~Xu, Y.~Wu, W.~Yuan, Z.~Dong, L.~Bo, and X.~Han.
\newblock Richdreamer: A generalizable normal-depth diffusion model for detail richness in text-to-3d.
\newblock \emph{arXiv preprint arXiv:2311.16918}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Ren et~al.(2023)Ren, Pan, Tang, Zhang, Cao, Zeng, and Liu]{ren2023dreamgaussian4d}
J.~Ren, L.~Pan, J.~Tang, C.~Zhang, A.~Cao, G.~Zeng, and Z.~Liu.
\newblock Dreamgaussian4d: Generative 4d gaussian splatting, 2023.

\bibitem[Rogozhnikov(2021)]{rogozhnikov2021einops}
A.~Rogozhnikov.
\newblock Einops: Clear and reliable tensor manipulations with einstein-like notation.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2021highresolution}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock {High-Resolution Image Synthesis with Latent Diffusion Models}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{ronneberger2015u}
O.~Ronneberger, P.~Fischer, and T.~Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18}, pages 234--241. Springer, 2015.

\bibitem[Seitzer et~al.(2023)Seitzer, van Steenkiste, Kipf, Greff, and Sajjadi]{seitzer2023dyst}
M.~Seitzer, S.~van Steenkiste, T.~Kipf, K.~Greff, and M.~S. Sajjadi.
\newblock Dyst: Towards dynamic neural scene representations on real-world videos.
\newblock \emph{arXiv preprint arXiv:2310.06020}, 2023.

\bibitem[Shen et~al.(2024)Shen, Yi, Wu, Zhou, Zhang, Yan, and Wang]{shen2024gamba}
Q.~Shen, X.~Yi, Z.~Wu, P.~Zhou, H.~Zhang, S.~Yan, and X.~Wang.
\newblock Gamba: Marry gaussian splatting with mamba for single view 3d reconstruction.
\newblock \emph{arXiv preprint arXiv:2403.18795}, 2024.

\bibitem[Shi et~al.(2023)Shi, Wang, Ye, Mai, Li, and Yang]{shi2023MVDream}
Y.~Shi, P.~Wang, J.~Ye, L.~Mai, K.~Li, and X.~Yang.
\newblock Mvdream: Multi-view diffusion for 3d generation.
\newblock \emph{arXiv preprint arXiv:2308.16512}, 2023.

\bibitem[Singer et~al.(2023{\natexlab{a}})Singer, Polyak, Hayes, Yin, An, Zhang, Hu, Yang, Ashual, Gafni, Parikh, Gupta, and Taigman]{singer2023makeavideo}
U.~Singer, A.~Polyak, T.~Hayes, X.~Yin, J.~An, S.~Zhang, Q.~Hu, H.~Yang, O.~Ashual, O.~Gafni, D.~Parikh, S.~Gupta, and Y.~Taigman.
\newblock {Make-A-Video: Text-to-Video Generation without Text-Video Data}.
\newblock In \emph{The Eleventh International Conference on Learning Representations (ICLR)}, 2023{\natexlab{a}}.

\bibitem[Singer et~al.(2023{\natexlab{b}})Singer, Sheynin, Polyak, Ashual, Makarov, Kokkinos, Goyal, Vedaldi, Parikh, Johnson, et~al.]{singer2023text}
U.~Singer, S.~Sheynin, A.~Polyak, O.~Ashual, I.~Makarov, F.~Kokkinos, N.~Goyal, A.~Vedaldi, D.~Parikh, J.~Johnson, et~al.
\newblock Text-to-4d dynamic scene generation.
\newblock \emph{arXiv preprint arXiv:2301.11280}, 2023{\natexlab{b}}.

\bibitem[Sitzmann et~al.(2021)Sitzmann, Rezchikov, Freeman, Tenenbaum, and Durand]{sitzmann2021light}
V.~Sitzmann, S.~Rezchikov, B.~Freeman, J.~Tenenbaum, and F.~Durand.
\newblock Light field networks: Neural scene representations with single-evaluation rendering.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 19313--19325, 2021.

\bibitem[Tang et~al.(2024)Tang, Chen, Chen, Wang, Zeng, and Liu]{tang2024lgm}
J.~Tang, Z.~Chen, X.~Chen, T.~Wang, G.~Zeng, and Z.~Liu.
\newblock Lgm: Large multi-view gaussian model for high-resolution 3d content creation.
\newblock \emph{arXiv preprint arXiv:2402.05054}, 2024.

\bibitem[Tian et~al.(2023)Tian, Du, and Duan]{tian2023mononerf}
F.~Tian, S.~Du, and Y.~Duan.
\newblock Mononerf: Learning a generalizable dynamic radiance field from monocular videos.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 17903--17913, 2023.

\bibitem[Unterthiner et~al.(2018)Unterthiner, Van~Steenkiste, Kurach, Marinier, Michalski, and Gelly]{unterthiner2018towards}
T.~Unterthiner, S.~Van~Steenkiste, K.~Kurach, R.~Marinier, M.~Michalski, and S.~Gelly.
\newblock Towards accurate generative models of video: A new metric \& challenges.
\newblock \emph{arXiv preprint arXiv:1812.01717}, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang and Shi(2023)]{wang2023imagedream}
P.~Wang and Y.~Shi.
\newblock Imagedream: Image-prompt multi-view diffusion for 3d generation.
\newblock \emph{arXiv preprint arXiv:2312.02201}, 2023.

\bibitem[Wang et~al.(2022)Wang, Chen, Chen, Venugopalan, Wang, et~al.]{wang2022attention}
P.~Wang, X.~Chen, T.~Chen, S.~Venugopalan, Z.~Wang, et~al.
\newblock Is attention all that nerf needs?
\newblock \emph{arXiv preprint arXiv:2207.13298}, 2022.

\bibitem[Wang et~al.(2021)Wang, Wang, Genova, Srinivasan, Zhou, Barron, Martin-Brualla, Snavely, and Funkhouser]{wang2021ibrnet}
Q.~Wang, Z.~Wang, K.~Genova, P.~P. Srinivasan, H.~Zhou, J.~T. Barron, R.~Martin-Brualla, N.~Snavely, and T.~Funkhouser.
\newblock Ibrnet: Learning multi-view image-based rendering.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4690--4699, 2021.

\bibitem[Wang et~al.(2023)Wang, Lu, Wang, Bao, Li, Su, and Zhu]{wang2023prolificdreamer}
Z.~Wang, C.~Lu, Y.~Wang, F.~Bao, C.~Li, H.~Su, and J.~Zhu.
\newblock {ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation}.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Wu et~al.(2023{\natexlab{a}})Wu, Johnson, Malik, Feichtenhofer, and Gkioxari]{wu2023multiview}
C.-Y. Wu, J.~Johnson, J.~Malik, C.~Feichtenhofer, and G.~Gkioxari.
\newblock Multiview compressive coding for 3d reconstruction.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 9065--9075, 2023{\natexlab{a}}.

\bibitem[Wu et~al.(2023{\natexlab{b}})Wu, Yi, Fang, Xie, Zhang, Wei, Liu, Tian, and Wang]{wu20234d}
G.~Wu, T.~Yi, J.~Fang, L.~Xie, X.~Zhang, W.~Wei, W.~Liu, Q.~Tian, and X.~Wang.
\newblock 4d gaussian splatting for real-time dynamic scene rendering.
\newblock \emph{arXiv preprint arXiv:2310.08528}, 2023{\natexlab{b}}.

\bibitem[Wu et~al.(2023{\natexlab{c}})Wu, Ge, Wang, Lei, Gu, Shi, Hsu, Shan, Qie, and Shou]{wu2023tune}
J.~Z. Wu, Y.~Ge, X.~Wang, S.~W. Lei, Y.~Gu, Y.~Shi, W.~Hsu, Y.~Shan, X.~Qie, and M.~Z. Shou.
\newblock Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7623--7633, 2023{\natexlab{c}}.

\bibitem[Xian et~al.(2021)Xian, Huang, Kopf, and Kim]{xian2021space}
W.~Xian, J.-B. Huang, J.~Kopf, and C.~Kim.
\newblock Space-time neural irradiance fields for free-viewpoint video.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 9421--9431, 2021.

\bibitem[Xu et~al.(2024)Xu, Shi, Yifan, Chen, Yang, Peng, Shen, and Wetzstein]{xu2024grm}
Y.~Xu, Z.~Shi, W.~Yifan, H.~Chen, C.~Yang, S.~Peng, Y.~Shen, and G.~Wetzstein.
\newblock Grm: Large gaussian reconstruction model for efficient 3d reconstruction and generation.
\newblock \emph{arXiv preprint arXiv:2403.14621}, 2024.

\bibitem[Yang et~al.(2021)Yang, Sun, Jampani, Vlasic, Cole, Chang, Ramanan, Freeman, and Liu]{yang2021lasr}
G.~Yang, D.~Sun, V.~Jampani, D.~Vlasic, F.~Cole, H.~Chang, D.~Ramanan, W.~T. Freeman, and C.~Liu.
\newblock Lasr: Learning articulated shape reconstruction from a monocular video.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15980--15989, 2021.

\bibitem[Yang et~al.(2024)Yang, Pan, Gu, and Zhang]{yang2024diffusion}
Z.~Yang, Z.~Pan, C.~Gu, and L.~Zhang.
\newblock Diffusion$^2$: Dynamic 3d content generation via score composition of orthogonal diffusion models.
\newblock \emph{arXiv preprint arXiv:2404.02148}, 2024.

\bibitem[Yin et~al.(2023)Yin, Xu, Wang, Zhao, and Wei]{yin20234dgen}
Y.~Yin, D.~Xu, Z.~Wang, Y.~Zhao, and Y.~Wei.
\newblock 4dgen: Grounded 4d content generation with spatial-temporal consistency.
\newblock \emph{arXiv preprint arXiv:2312.17225}, 2023.

\bibitem[Yu et~al.(2021)Yu, Ye, Tancik, and Kanazawa]{yu2021pixelnerf}
A.~Yu, V.~Ye, M.~Tancik, and A.~Kanazawa.
\newblock pixelnerf: Neural radiance fields from one or few images.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4578--4587, 2021.

\bibitem[Yu et~al.(2023)Yu, Guo, Li, Liang, Zhang, and Qi]{yu2023csd}
X.~Yu, Y.-C. Guo, Y.~Li, D.~Liang, S.-H. Zhang, and X.~Qi.
\newblock {Text-to-3D with Classifier Score Distillation}.
\newblock \emph{arXiv preprint arXiv:2310.19415}, 2023.

\bibitem[Zeng et~al.(2024)Zeng, Jiang, Zhu, Lu, Lin, Zhu, Hu, Cao, and Yao]{zeng2024stag4d}
Y.~Zeng, Y.~Jiang, S.~Zhu, Y.~Lu, Y.~Lin, H.~Zhu, W.~Hu, X.~Cao, and Y.~Yao.
\newblock Stag4d: Spatial-temporal anchored generative 4d gaussians.
\newblock \emph{arXiv preprint arXiv:2403.14939}, 2024.

\bibitem[Zhang et~al.(2024)Zhang, Bi, Tan, Xiangli, Zhao, Sunkavalli, and Xu]{zhang2024gs}
K.~Zhang, S.~Bi, H.~Tan, Y.~Xiangli, N.~Zhao, K.~Sunkavalli, and Z.~Xu.
\newblock Gs-lrm: Large reconstruction model for 3d gaussian splatting.
\newblock \emph{arXiv preprint arXiv:2404.19702}, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 586--595, 2018.

\bibitem[Zhao et~al.(2024)Zhao, Colburn, Ma, Bautista, Susskind, and Schwing]{zhao2024pseudogeneralized}
X.~Zhao, A.~Colburn, F.~Ma, M.~A. Bautista, J.~M. Susskind, and A.~G. Schwing.
\newblock Pseudo-generalized dynamic view synthesis from a video, 2024.

\bibitem[Zhao et~al.(2023)Zhao, Yan, Xie, Hong, Li, and Lee]{zhao2023animate124}
Y.~Zhao, Z.~Yan, E.~Xie, L.~Hong, Z.~Li, and G.~H. Lee.
\newblock Animate124: Animating one image to 4d dynamic scene.
\newblock \emph{arXiv preprint arXiv:2311.14603}, 2023.

\bibitem[Zheng et~al.(2023)Zheng, Li, Nagano, Liu, Kreis, Hilliges, and Mello]{zheng2023unified}
Y.~Zheng, X.~Li, K.~Nagano, S.~Liu, K.~Kreis, O.~Hilliges, and S.~D. Mello.
\newblock A unified approach for text-and image-guided 4d scene generation.
\newblock \emph{arXiv preprint arXiv:2311.16854}, 2023.

\end{thebibliography}
