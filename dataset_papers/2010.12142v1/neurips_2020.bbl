\begin{thebibliography}{10}

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529, 2015.

\bibitem{lillicrap2015continuous}
Timothy~P Lillicrap, Jonathan~J Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock {\em International Conference on Learning Representations}, 2016.

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em nature}, 529(7587):484--489, 2016.

\bibitem{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{humanlearn}
Pedro Tsividis, Thomas Pouncy, Jaqueline~L. Xu, Joshua~B. Tenenbaum, and
  Samuel~J. Gershman.
\newblock Human learning in atari.
\newblock In {\em 2017 {AAAI} Spring Symposia, Stanford University, Palo Alto,
  California, USA, March 27-29, 2017}. {AAAI} Press, 2017.

\bibitem{VPN}
Junhyuk Oh, Satinder Singh, and Honglak Lee.
\newblock Value prediction network.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6118--6128, 2017.

\bibitem{Deepforesight}
Chelsea Finn and Sergey Levine.
\newblock Deep visual foresight for planning robot motion.
\newblock In {\em 2017 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 2786--2793. IEEE, 2017.

\bibitem{world}
David Ha and Jurgen Schmidhuber.
\newblock World models.
\newblock {\em CoRR}, abs/1803.10122, 2018.

\bibitem{steve}
Jacob Buckman, Danijar Hafner, George Tucker, Eugene Brevdo, and Honglak Lee.
\newblock Sample-efficient reinforcement learning with stochastic ensemble
  value expansion.
\newblock In Samy Bengio, Hanna~M. Wallach, Hugo Larochelle, Kristen Grauman,
  Nicol{\`{o}} Cesa{-}Bianchi, and Roman Garnett, editors, {\em Advances in
  Neural Information Processing Systems 31: Annual Conference on Neural
  Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018,
  Montr{\'{e}}al, Canada}, pages 8234--8244, 2018.

\bibitem{muzero}
Julian {Schrittwieser}, Ioannis {Antonoglou}, Thomas {Hubert}, Karen
  {Simonyan}, Laurent {Sifre}, Simon {Schmitt}, Arthur {Guez}, Edward
  {Lockhart}, Demis {Hassabis}, Thore {Graepel}, Timothy {Lillicrap}, and David
  {Silver}.
\newblock {Mastering Atari, Go, Chess and Shogi by Planning with a Learned
  Model}.
\newblock {\em arXiv e-prints}, page arXiv:1911.08265, November 2019.

\bibitem{simple}
Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy~H
  Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski,
  Sergey Levine, et~al.
\newblock Model-based reinforcement learning for atari.
\newblock {\em arXiv preprint arXiv:1903.00374}, 2019.

\bibitem{planet}
Danijar Hafner, Timothy~P. Lillicrap, Ian Fischer, Ruben Villegas, David Ha,
  Honglak Lee, and James Davidson.
\newblock Learning latent dynamics for planning from pixels.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning, {ICML}
  2019, 9-15 June 2019, Long Beach, California, {USA}}, volume~97 of {\em
  Proceedings of Machine Learning Research}, pages 2555--2565. {PMLR}, 2019.

\bibitem{dreamer}
Danijar Hafner, Timothy~P. Lillicrap, Jimmy Ba, and Mohammad Norouzi.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In {\em 8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\bibitem{dynaQ}
Richard~S Sutton.
\newblock Integrated architectures for learning, planning, and reacting based
  on approximating dynamic programming.
\newblock In {\em Machine learning proceedings 1990}, pages 216--224. Elsevier,
  1990.

\bibitem{metrpo}
Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, and Pieter Abbeel.
\newblock Model-ensemble trust-region policy optimization.
\newblock In {\em 6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net, 2018.

\bibitem{slbo}
Yuping Luo, Huazhe Xu, Yuanzhi Li, Yuandong Tian, Trevor Darrell, and Tengyu
  Ma.
\newblock Algorithmic framework for model-based deep reinforcement learning
  with theoretical guarantees.
\newblock In {\em 7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem{mbmpo}
Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim Asfour,
  and Pieter Abbeel.
\newblock Model-based reinforcement learning via meta-policy optimization.
\newblock In {\em 2nd Annual Conference on Robot Learning, CoRL 2018,
  Z{\"{u}}rich, Switzerland, 29-31 October 2018, Proceedings}, volume~87 of
  {\em Proceedings of Machine Learning Research}, pages 617--629. {PMLR}, 2018.

\bibitem{MPC}
Eduardo~F Camacho and Carlos~Bordons Alba.
\newblock {\em Model predictive control}.
\newblock Springer Science \&amp; Business Media, 2013.

\bibitem{rao2009survey}
Anil~V Rao.
\newblock A survey of numerical methods for optimal control.
\newblock {\em Advances in the Astronautical Sciences}, 135(1):497--528, 2009.

\bibitem{pets}
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4754--4765, 2018.

\bibitem{mve}
Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael~I Jordan, Joseph~E Gonzalez,
  and Sergey Levine.
\newblock Model-based value estimation for efficient model-free reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:1803.00101}, 2018.

\bibitem{vg}
Michael Fairbank.
\newblock Reinforcement learning by value gradients.
\newblock {\em CoRR}, abs/0803.3539, 2008.

\bibitem{svg}
Nicolas Heess, Gregory Wayne, David Silver, Timothy~P. Lillicrap, Tom Erez, and
  Yuval Tassa.
\newblock Learning continuous control policies by stochastic value gradients.
\newblock In Corinna Cortes, Neil~D. Lawrence, Daniel~D. Lee, Masashi Sugiyama,
  and Roman Garnett, editors, {\em Advances in Neural Information Processing
  Systems 28: Annual Conference on Neural Information Processing Systems 2015,
  December 7-12, 2015, Montreal, Quebec, Canada}, pages 2944--2952, 2015.

\bibitem{pilco}
Marc Deisenroth and Carl~E Rasmussen.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In {\em Proceedings of the 28th International Conference on machine
  learning (ICML-11)}, pages 465--472, 2011.

\bibitem{iLQR}
Yuval Tassa, Tom Erez, and Emanuel Todorov.
\newblock Synthesis and stabilization of complex behaviors through online
  trajectory optimization.
\newblock In {\em 2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pages 4906--4913. IEEE, 2012.

\bibitem{gps}
Sergey Levine and Vladlen Koltun.
\newblock Guided policy search.
\newblock In {\em Proceedings of the 30th International Conference on Machine
  Learning, {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013}, volume~28 of {\em
  {JMLR} Workshop and Conference Proceedings}, pages 1--9. JMLR.org, 2013.

\bibitem{IVG}
Arunkumar Byravan, Jost~Tobias Springenberg, Abbas Abdolmaleki, Roland Hafner,
  Michael Neunert, Thomas Lampe, Noah Siegel, Nicolas Heess, and Martin
  Riedmiller.
\newblock Imagined value gradients: Model-based policy optimization with
  transferable latent dynamics models.
\newblock {\em arXiv preprint arXiv:1910.04142}, 2019.

\bibitem{Johnson2002Neural}
Sterling~C. Johnson, Leslie~C. Baxter, Lana~S. Wilder, James~G. Pipe, Joseph~E.
  Heiserman, and George~P. Prigatano.
\newblock Neural correlates of self‐reflection.
\newblock {\em Brain}, (8):8, 2002.

\bibitem{PMID:13056096}
EG~BORING.
\newblock A history of introspection.
\newblock {\em Psychological bulletin}, 50(3):169—189, May 1953.

\bibitem{dmc}
Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego
  de~Las~Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq,
  Timothy~P. Lillicrap, and Martin~A. Riedmiller.
\newblock Deepmind control suite.
\newblock {\em CoRR}, abs/1801.00690, 2018.

\bibitem{mbrl}
Anusha Nagabandi, Gregory Kahn, Ronald~S. Fearing, and Sergey Levine.
\newblock Neural network dynamics for model-based deep reinforcement learning
  with model-free fine-tuning.
\newblock In {\em 2018 {IEEE} International Conference on Robotics and
  Automation, {ICRA} 2018, Brisbane, Australia, May 21-25, 2018}, pages
  7559--7566. {IEEE}, 2018.

\bibitem{dexterous}
Anusha Nagabandi, Kurt Konolige, Sergey Levine, and Vikash Kumar.
\newblock Deep dynamics models for learning dexterous manipulation.
\newblock In Leslie~Pack Kaelbling, Danica Kragic, and Komei Sugiura, editors,
  {\em 3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan,
  October 30 - November 1, 2019, Proceedings}, volume 100 of {\em Proceedings
  of Machine Learning Research}, pages 1101--1112. {PMLR}, 2019.

\bibitem{visualmpc}
Frederik Ebert, Chelsea Finn, Alex~X. Lee, and Sergey Levine.
\newblock Self-supervised visual planning with temporal skip connections.
\newblock In {\em 1st Annual Conference on Robot Learning, CoRL 2017, Mountain
  View, California, USA, November 13-15, 2017, Proceedings}, volume~78 of {\em
  Proceedings of Machine Learning Research}, pages 344--356. {PMLR}, 2017.

\bibitem{benchmark}
Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric
  Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, and Jimmy Ba.
\newblock Benchmarking model-based reinforcement learning.
\newblock {\em CoRR}, abs/1907.02057, 2019.

\bibitem{gps2}
Sergey Levine and Pieter Abbeel.
\newblock Learning neural network policies with guided policy search under
  unknown dynamics.
\newblock In Zoubin Ghahramani, Max Welling, Corinna Cortes, Neil~D. Lawrence,
  and Kilian~Q. Weinberger, editors, {\em Advances in Neural Information
  Processing Systems 27: Annual Conference on Neural Information Processing
  Systems 2014, December 8-13 2014, Montreal, Quebec, Canada}, pages
  1071--1079, 2014.

\bibitem{gps3}
Sergey Levine, Nolan Wagener, and Pieter Abbeel.
\newblock Learning contact-rich manipulation skills with guided policy search.
\newblock In {\em {IEEE} International Conference on Robotics and Automation,
  {ICRA} 2015, Seattle, WA, USA, 26-30 May, 2015}, pages 156--163. {IEEE},
  2015.

\bibitem{gps4}
Tianhao Zhang, Gregory Kahn, Sergey Levine, and Pieter Abbeel.
\newblock Learning deep control policies for autonomous aerial vehicles with
  mpc-guided policy search.
\newblock In Danica Kragic, Antonio Bicchi, and Alessandro~De Luca, editors,
  {\em 2016 {IEEE} International Conference on Robotics and Automation, {ICRA}
  2016, Stockholm, Sweden, May 16-21, 2016}, pages 528--535. {IEEE}, 2016.

\bibitem{gps5}
Yevgen Chebotar, Mrinal Kalakrishnan, Ali Yahya, Adrian Li, Stefan Schaal, and
  Sergey Levine.
\newblock Path integral guided policy search.
\newblock In {\em 2017 {IEEE} International Conference on Robotics and
  Automation, {ICRA} 2017, Singapore, Singapore, May 29 - June 3, 2017}, pages
  3381--3388. {IEEE}, 2017.

\bibitem{henaff2017model}
Mikael Henaff, William~F Whitney, and Yann LeCun.
\newblock Model-based planning with discrete and continuous actions.
\newblock {\em arXiv preprint arXiv:1705.07177}, 2017.

\bibitem{srinivas2018universal}
Aravind Srinivas, Allan Jabri, Pieter Abbeel, Sergey Levine, and Chelsea Finn.
\newblock Universal planning networks.
\newblock {\em arXiv preprint arXiv:1804.00645}, 2018.

\bibitem{vib}
Alexander~A. Alemi, Ian Fischer, Joshua~V. Dillon, and Kevin Murphy.
\newblock Deep variational information bottleneck.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}. OpenReview.net, 2017.

\bibitem{mim}
Michael Tschannen, Josip Djolonga, Paul~K. Rubenstein, Sylvain Gelly, and Mario
  Lucic.
\newblock On mutual information maximization for representation learning.
\newblock In {\em 8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\bibitem{miem}
R.~Devon Hjelm, Alex Fedorov, Samuel Lavoie{-}Marchildon, Karan Grewal, Philip
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In {\em 7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem{ent_and_mi}
Marylou Gabri{\'{e}}, Andre Manoel, Cl{\'{e}}ment Luneau, Jean Barbier, Nicolas
  Macris, Florent Krzakala, and Lenka Zdeborov{\'{a}}.
\newblock Entropy and mutual information in models of deep neural networks.
\newblock In Samy Bengio, Hanna~M. Wallach, Hugo Larochelle, Kristen Grauman,
  Nicol{\`{o}} Cesa{-}Bianchi, and Roman Garnett, editors, {\em Advances in
  Neural Information Processing Systems 31: Annual Conference on Neural
  Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018,
  Montr{\'{e}}al, Canada}, pages 1826--1836, 2018.

\bibitem{infoRL5}
Yingjun Pei and Xinwen Hou.
\newblock Learning representations in reinforcement learning: An information
  bottleneck approach.
\newblock {\em CoRR}, abs/1911.05695, 2019.

\bibitem{cpc}
A{\"{a}}ron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em CoRR}, abs/1807.03748, 2018.

\bibitem{nbsr}
Zhaohan~Daniel Guo, Mohammad~Gheshlaghi Azar, Bilal Piot, Bernardo~A. Pires,
  Toby Pohlen, and R{\'{e}}mi Munos.
\newblock Neural predictive belief representations.
\newblock {\em CoRR}, abs/1811.06407, 2018.

\bibitem{soft-q}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In Doina Precup and Yee~Whye Teh, editors, {\em Proceedings of the
  34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW,
  Australia, 6-11 August 2017}, volume~70 of {\em Proceedings of Machine
  Learning Research}, pages 1352--1361. {PMLR}, 2017.

\bibitem{sac}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In Jennifer~G. Dy and Andreas Krause, editors, {\em Proceedings of
  the 35th International Conference on Machine Learning, {ICML} 2018,
  Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018}, volume~80 of
  {\em Proceedings of Machine Learning Research}, pages 1856--1865. {PMLR},
  2018.

\bibitem{connect}
Brendan O'Donoghue, R{\'{e}}mi Munos, Koray Kavukcuoglu, and Volodymyr Mnih.
\newblock Combining policy gradient and q-learning.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}. OpenReview.net, 2017.

\bibitem{bridge}
Ofir Nachum, Mohammad Norouzi, Kelvin Xu, and Dale Schuurmans.
\newblock Bridging the gap between value and policy based reinforcement
  learning.
\newblock In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna~M. Wallach,
  Rob Fergus, S.~V.~N. Vishwanathan, and Roman Garnett, editors, {\em Advances
  in Neural Information Processing Systems 30: Annual Conference on Neural
  Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA,
  {USA}}, pages 2775--2785, 2017.

\bibitem{infobot}
Anirudh Goyal, Riashat Islam, Daniel Strouse, Zafarali Ahmed, Hugo Larochelle,
  Matthew Botvinick, Yoshua Bengio, and Sergey Levine.
\newblock Infobot: Transfer and exploration via the information bottleneck.
\newblock In {\em 7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem{info-direct}
Nikolay Nikolov, Johannes Kirschner, Felix Berkenkamp, and Andreas Krause.
\newblock Information-directed exploration for deep reinforcement learning.
\newblock In {\em 7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem{rlbook}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge, 1998.

\bibitem{vae}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{a3c}
Volodymyr Mnih, Adri{\`{a}}~Puigdom{\`{e}}nech Badia, Mehdi Mirza, Alex Graves,
  Timothy~P. Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In Maria{-}Florina Balcan and Kilian~Q. Weinberger, editors, {\em
  Proceedings of the 33nd International Conference on Machine Learning, {ICML}
  2016, New York City, NY, USA, June 19-24, 2016}, volume~48 of {\em {JMLR}
  Workshop and Conference Proceedings}, pages 1928--1937. JMLR.org, 2016.

\bibitem{2020Offline}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock 2020.

\bibitem{s2vg}
Xiaoyu Tan, Chao Qu, Junwu Xiong, and James Zhang.
\newblock S2{\{}vg{\}}: Soft stochastic value gradient method, 2020.

\bibitem{d4pg}
Gabriel Barth{-}Maron, Matthew~W. Hoffman, David Budden, Will Dabney, Dan
  Horgan, Dhruva TB, Alistair Muldal, Nicolas Heess, and Timothy~P. Lillicrap.
\newblock Distributed distributional deterministic policy gradients.
\newblock In {\em 6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net, 2018.

\bibitem{chua2018deep}
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4754--4765, 2018.

\bibitem{boney2019regularizing}
Rinu Boney, Norman Di~Palo, Mathias Berglund, Alexander Ilin, Juho Kannala,
  Antti Rasmus, and Harri Valpola.
\newblock Regularizing trajectory optimization with denoising autoencoders.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2859--2869, 2019.

\bibitem{boney2020regularizing}
Rinu Boney, Juho Kannala, and Alexander Ilin.
\newblock Regularizing model-based planning with energy-based models.
\newblock In {\em Conference on Robot Learning}, pages 182--191. PMLR, 2020.

\bibitem{moerland2020model}
Thomas~M Moerland, Joost Broekens, and Catholijn~M Jonker.
\newblock Model-based reinforcement learning: A survey.
\newblock {\em arXiv preprint arXiv:2006.16712}, 2020.

\bibitem{gru}
Junyoung Chung, {\c{C}}aglar G{\"{u}}l{\c{c}}ehre, KyungHyun Cho, and Yoshua
  Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em CoRR}, abs/1412.3555, 2014.

\bibitem{adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em 3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.

\end{thebibliography}
