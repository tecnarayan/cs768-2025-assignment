\begin{thebibliography}{10}

\bibitem{amos23_tutor}
Brandon Amos.
\newblock Tutorial on amortized optimization, April 2023.
\newblock arXiv:2202.00665 [cs, math].

\bibitem{baydin22_gradien_backp}
Atılım~G{\"u}ne{\c{s}} Baydin, Barak~A. Pearlmutter, Don Syme, Frank Wood,
  and Philip Torr.
\newblock Gradients without {Backpropagation}, February 2022.
\newblock arXiv:2202.08587 [cs, stat].

\bibitem{beck21_deep_split_method_parab_pdes}
Christian Beck, Sebastian Becker, Patrick Cheridito, Arnulf Jentzen, and Ariel
  Neufeld.
\newblock Deep splitting method for parabolic {PDEs}.
\newblock {\em SIAM Journal on Scientific Computing}, 43(5):A3135--A3154,
  January 2021.
\newblock arXiv:1907.03452 [cs, math, stat].

\bibitem{becker20_numer_simul_full_histor_recur}
Sebastian Becker, Ramon Braunwarth, Martin Hutzenthaler, Arnulf Jentzen, and
  Philippe von Wurstemberger.
\newblock Numerical simulations for full history recursive multilevel {Picard}
  approximations for systems of high-dimensional partial differential
  equations.
\newblock {\em Communications in Computational Physics}, 28(5):2109--2138, June
  2020.
\newblock arXiv:2005.10206 [cs, math].

\bibitem{bendtsen97_tadif_flexib_c_packag_for}
Claus Bendtsen and Ole Stauning.
\newblock Tadiff , a flexible c + + package for automatic differentiation using
  taylor series expansion.
\newblock 1997.

\bibitem{bettencourt19_taylor_mode_autom_differ_higher}
Jesse Bettencourt, Matthew~J. Johnson, and David Duvenaud.
\newblock Taylor-mode automatic differentiation for higher-order derivatives in
  {JAX}.
\newblock In {\em Program Transformations for ML Workshop at NeurIPS 2019},
  2019.

\bibitem{jax2018github}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary,
  Dougal Maclaurin, George Necula, Adam Paszke, Jake Vander{P}las, Skye
  Wanderman-{M}ilne, and Qiao Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.

\bibitem{ghojogh21_johns_linden_lemma_linear_nonlin}
Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, and Mark Crowley.
\newblock Johnson-{Lindenstrauss} {Lemma}, {Linear} and {Nonlinear} {Random}
  {Projections}, {Random} {Fourier} {Features}, and {Random} {Kitchen} {Sinks}:
  {Tutorial} and {Survey}, August 2021.
\newblock arXiv:2108.04172 [cs, math, stat].

\bibitem{griewank08_evaluat_deriv}
Andreas Griewank and Andrea Walther.
\newblock {\em Evaluating Derivatives}.
\newblock Society for Industrial and Applied Mathematics, second edition, 2008.

\bibitem{han18_solvin_high_dimen_partial_differ}
Jiequn Han, Arnulf Jentzen, and Weinan E.
\newblock Solving high-dimensional partial differential equations using deep
  learning.
\newblock {\em Proceedings of the National Academy of Sciences},
  115(34):8505--8510, Aug 2018.

\bibitem{he23_learn_physic_infor_neural_networ}
Di~He, Shanda Li, Wenlei Shi, Xiaotian Gao, Jia Zhang, Jiang Bian, Liwei Wang,
  and Tie-Yan Liu.
\newblock Learning {Physics}-{Informed} {Neural} {Networks} without {Stacked}
  {Back}-propagation, February 2023.
\newblock arXiv:2202.09340 [cs].

\bibitem{hu24_hutch_trace_estim_high_dimen}
Zheyuan Hu, Zekun Shi, George~Em Karniadakis, and Kenji Kawaguchi.
\newblock Hutchinson {Trace} {Estimation} for {High}-{Dimensional} and
  {High}-{Order} {Physics}-{Informed} {Neural} {Networks}.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  424:116883, May 2024.
\newblock arXiv:2312.14499 [cs, math, stat].

\bibitem{hu24_tackl_curse_dimen_with_physic}
Zheyuan Hu, Khemraj Shukla, George~Em Karniadakis, and Kenji Kawaguchi.
\newblock Tackling the curse of dimensionality with physics-informed neural
  networks.
\newblock {\em Neural Networks}, 176:106369, 2024.

\bibitem{hu23_bias_varian_trade_physic_infor}
Zheyuan Hu, Zhouhao Yang, Yezhen Wang, George~Em Karniadakis, and Kenji
  Kawaguchi.
\newblock Bias-{Variance} {Trade}-off in {Physics}-{Informed} {Neural}
  {Networks} with {Randomized} {Smoothing} for {High}-{Dimensional} {PDEs},
  November 2023.
\newblock arXiv:2311.15283 [cs, math, stat].

\bibitem{hu24_score_based_physic_infor_neural}
Zheyuan Hu, Zhongqiang Zhang, George~Em Karniadakis, and Kenji Kawaguchi.
\newblock Score-{Based} {Physics}-{Informed} {Neural} {Networks} for
  {High}-{Dimensional} {Fokker}-{Planck} {Equations}, February 2024.
\newblock arXiv:2402.07465 [cs, math, stat].

\bibitem{hutchinson89_stoch_estim_trace_influen_matrix}
M.F. Hutchinson.
\newblock A stochastic estimator of the trace of the influence matrix for
  laplacian smoothing splines.
\newblock {\em Communications in Statistics - Simulation and Computation},
  18(3):1059--1076, January 1989.

\bibitem{hutzenthaler18_overc}
Martin Hutzenthaler, Arnulf Jentzen, Thomas Kruse, Tuan~Anh Nguyen, and
  Philippe von Wurstemberger.
\newblock Overcoming the curse of dimensionality in the numerical approximation
  of semilinear parabolic partial differential equations, July 2018.

\bibitem{karczmarczuk98_funct_differ_comput_progr}
Jerzy Karczmarczuk.
\newblock Functional differentiation of computer programs.
\newblock In {\em Proceedings of the Third ACM SIGPLAN International Conference
  on Functional Programming}, ICFP '98, pages 195--203, New York, NY, USA,
  1998. Association for Computing Machinery.

\bibitem{karniadakis21_physic_infor_machin_learn}
George~Em Karniadakis, Ioannis~G. Kevrekidis, Lu~Lu, Paris Perdikaris, Sifan
  Wang, and Liu Yang.
\newblock Physics-informed machine learning.
\newblock {\em Nature Reviews Physics}, 3(6):422--440, Jun 2021.

\bibitem{kingma15_adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em 3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.

\bibitem{lai22_regul}
Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji,
  and Stefano Ermon.
\newblock Regularizing score-based models with score fokker-planck equations.
\newblock In {\em NeurIPS 2022 Workshop on Score-Based Methods}, 2022.

\bibitem{laurel22_gener_const_abstr_inter_higher}
Jacob Laurel, Rem Yang, Shubham Ugare, Robert Nagel, Gagandeep Singh, and Sasa
  Misailovic.
\newblock A general construction for abstract interpretation of higher-order
  automatic differentiation.
\newblock {\em Proc. ACM Program. Lang.}, 6(OOPSLA2), oct 2022.

\bibitem{li24_dof}
Ruichen Li, Chuwei Wang, Haotian Ye, Di~He, and Liwei Wang.
\newblock {DOF}: Accelerating high-order differential operators with forward
  propagation.
\newblock In {\em ICLR 2024 Workshop on AI4DifferentialEquations In Science},
  2024.

\bibitem{li23_forwar_laplac}
Ruichen Li, Haotian Ye, Du~Jiang, Xuelan Wen, Chuwei Wang, Zhe Li, Xiang Li,
  Di~He, Ji~Chen, Weiluo Ren, and Liwei Wang.
\newblock Forward {Laplacian}: {A} {New} {Computational} {Framework} for
  {Neural} {Network}-based {Variational} {Monte} {Carlo}, July 2023.
\newblock arXiv:2307.08214 [physics].

\bibitem{liu20_primer_zerot_order_optim_signal}
Sijia Liu, Pin-Yu Chen, Bhavya Kailkhura, Gaoyuan Zhang, Alfred Hero, and
  Pramod~K. Varshney.
\newblock A {Primer} on {Zeroth}-{Order} {Optimization} in {Signal}
  {Processing} and {Machine} {Learning}, June 2020.
\newblock arXiv:2006.06224 [cs, eess, stat].

\bibitem{lu21_physic_infor_neural_networ_with}
Lu~Lu, Rapha\"{e}l Pestourie, Wenjie Yao, Zhicheng Wang, Francesc Verdugo, and
  Steven~G. Johnson.
\newblock Physics-informed neural networks with hard constraints for inverse
  design.
\newblock {\em SIAM Journal on Scientific Computing}, 43(6):B1105--B1132, 2021.

\bibitem{malladi24_fine_tunin_languag_model_just_forwar_passes}
Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason~D. Lee, Danqi
  Chen, and Sanjeev Arora.
\newblock Fine-{Tuning} {Language} {Models} with {Just} {Forward} {Passes},
  January 2024.
\newblock arXiv:2305.17333 [cs].

\bibitem{martinsson21_random_numer_linear_algeb}
Per-Gunnar Martinsson and Joel Tropp.
\newblock Randomized {Numerical} {Linear} {Algebra}: {Foundations} \&
  {Algorithms}, March 2021.
\newblock arXiv:2002.01387 [cs, math].

\bibitem{murray23_random_numer_linear_algeb}
Riley Murray, James Demmel, Michael~W. Mahoney, N.~Benjamin Erichson, Maksim
  Melnichenko, Osman~Asif Malik, Laura Grigori, Piotr Luszczek, Michał
  Dereziński, Miles~E. Lopes, Tianyu Liang, Hengrui Luo, and Jack Dongarra.
\newblock Randomized {Numerical} {Linear} {Algebra} : {A} {Perspective} on the
  {Field} {With} an {Eye} to {Software}, April 2023.
\newblock arXiv:2302.11474 [cs, math].

\bibitem{oktay21_random_autom_differ}
Deniz Oktay, Nick McGreivy, Joshua Aduol, Alex Beatson, and Ryan~P. Adams.
\newblock Randomized {Automatic} {Differentiation}, March 2021.
\newblock arXiv:2007.10412 [cs, stat].

\bibitem{pang20_effic_learn_gener_model_finit}
Tianyu Pang, Kun Xu, Chongxuan Li, Yang Song, Stefano Ermon, and Jun Zhu.
\newblock Efficient {Learning} of {Generative} {Models} via
  {Finite}-{Difference} {Score} {Matching}, November 2020.
\newblock arXiv:2007.03317 [cs, stat].

\bibitem{pu24_lax}
Juncai Pu and Yong Chen.
\newblock Lax pairs informed neural networks solving integrable systems,
  January 2024.
\newblock arXiv:2401.04982 [nlin].

\bibitem{raissi19_physic_infor_neural_networ}
M.~Raissi, P.~Perdikaris, and G.E. Karniadakis.
\newblock Physics-informed neural networks: a deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock {\em Journal of Computational Physics}, 378:686--707, February 2019.

\bibitem{raissi18_forwar_backw_stoch_neural_networ}
Maziar Raissi.
\newblock Forward-{Backward} {Stochastic} {Neural} {Networks}: {Deep}
  {Learning} of {High}-dimensional {Partial} {Differential} {Equations}, April
  2018.
\newblock arXiv:1804.07010 [cs, math, stat].

\bibitem{sirignano18_dgm}
Justin Sirignano and Konstantinos Spiliopoulos.
\newblock Dgm: a deep learning algorithm for solving partial differential
  equations.
\newblock {\em Journal of computational physics}, 375:1339--1364, 2018.

\bibitem{skorski21_moder_analy_hutch_trace_estim}
Maciej Skorski.
\newblock Modern analysis of hutchinson's trace estimator.
\newblock In {\em 2021 55th Annual Conference on Information Sciences and
  Systems (CISS)}. IEEE, March 2021.

\bibitem{song19_sliced_score_match}
Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon.
\newblock Sliced {Score} {Matching}: {A} {Scalable} {Approach} to {Density} and
  {Score} {Estimation}, June 2019.
\newblock arXiv:1905.07088 [cs, stat].

\bibitem{song21_score_based_gener_model_stoch_differ_equat}
Yang Song, Jascha Sohl-Dickstein, Diederik~P. Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-{Based} {Generative} {Modeling} through {Stochastic}
  {Differential} {Equations}, February 2021.
\newblock arXiv:2011.13456 [cs, stat].

\bibitem{stein81_estim_mean_multiv_normal_distr}
Charles~M. Stein.
\newblock {Estimation of the Mean of a Multivariate Normal Distribution}.
\newblock {\em The Annals of Statistics}, 9(6):1135 -- 1151, 1981.

\bibitem{wang17_high_order_rever_mode_autom_differ}
Mu~Wang.
\newblock {\em High Order Reverse Mode of Automatic Differentiation}.
\newblock PhD thesis, 2017.
\newblock Copyright - Database copyright ProQuest LLC; ProQuest does not claim
  copyright in the individual underlying works; Last updated - 2023-03-04.

\bibitem{weinan17_deep_ritz_method}
E~Weinan and Ting Yu.
\newblock The deep ritz method: a deep learning-based numerical algorithm for
  solving variational problems.
\newblock {\em Communications in Mathematics and Statistics}, 6:1 -- 12, 2017.

\bibitem{yu22_gradien_enhan_physic_infor_neural}
Jeremy Yu, Lu~Lu, Xuhui Meng, and George~Em Karniadakis.
\newblock Gradient-enhanced physics-informed neural networks for forward and
  inverse {PDE} problems.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  393:114823, April 2022.
\newblock arXiv:2111.02801 [physics].

\bibitem{zang20_weak_adver_networ_high_partial_differ_equat}
Yaohua Zang, Gang Bao, Xiaojing Ye, and Haomin Zhou.
\newblock Weak {Adversarial} {Networks} for {High}-dimensional {Partial}
  {Differential} {Equations}.
\newblock {\em Journal of Computational Physics}, 411:109409, June 2020.
\newblock arXiv:1907.08272 [cs, math].

\end{thebibliography}
