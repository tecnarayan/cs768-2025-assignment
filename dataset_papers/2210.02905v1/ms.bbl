\begin{thebibliography}{99}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[{Arellano-Valle} et~al.(2013){Arellano-Valle}, {Contreras-Reyes}, and
  Genton]{arellano-valle2013sjs}
Reinaldo~B. {Arellano-Valle}, Javier~E. {Contreras-Reyes}, and Marc~G. Genton.
\newblock Shannon {{Entropy}} and {{Mutual Information}} for {{Multivariate
  Skew-Elliptical Distributions}}.
\newblock \emph{Scandinavian Journal of Statistics}, 2013.

\bibitem[Azzalini(1985)]{azzalini1985sjs}
Adelchi Azzalini.
\newblock A {{Class}} of {{Distributions Which Includes}} the {{Normal Ones}}.
\newblock \emph{Scandinavian Journal of Statistics}, 1985.

\bibitem[Balandat et~al.(2020)Balandat, Karrer, Jiang, Daulton, Letham, Wilson,
  and Bakshy]{balandat2020anips}
Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham,
  Andrew~G Wilson, and Eytan Bakshy.
\newblock {{BoTorch}}: {{A Framework}} for {{Efficient Monte-Carlo Bayesian
  Optimization}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2020.

\bibitem[Belakaria et~al.(2019)Belakaria, Deshwal, and
  Doppa]{belakaria2019anips}
Syrine Belakaria, Aryan Deshwal, and Janardhan~Rao Doppa.
\newblock Max-value {{Entropy Search}} for {{Multi-Objective Bayesian
  Optimization}}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}},
  2019.

\bibitem[Belakaria et~al.(2020)Belakaria, Deshwal, and
  Doppa]{belakaria2020pacai}
Syrine Belakaria, Aryan Deshwal, and Janardhan~Rao Doppa.
\newblock Multi-{{Fidelity Multi-Objective Bayesian Optimization}}: {{An Output
  Space Entropy Search Approach}}.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  2020.

\bibitem[Belakaria et~al.(2021)Belakaria, Deshwal, and Doppa]{belakaria2021j}
Syrine Belakaria, Aryan Deshwal, and Janardhan~Rao Doppa.
\newblock Output {{Space Entropy Search Framework}} for {{Multi-Objective
  Bayesian Optimization}}.
\newblock \emph{Journal of Artificial Intelligence Research}, 2021.

\bibitem[Berkenkamp et~al.(2021)Berkenkamp, Krause, and
  Schoellig]{berkenkamp2021ml}
Felix Berkenkamp, Andreas Krause, and Angela~P. Schoellig.
\newblock Bayesian optimization with safety {{Constraints}}: Safe and automatic
  parameter tuning in robotics.
\newblock \emph{Machine Learning}, 2021.

\bibitem[Binois et~al.(2020)Binois, Picheny, Taillandier, and
  Habbal]{binois2020jmlr}
Mickael Binois, Victor Picheny, Patrick Taillandier, and Abderrahmane Habbal.
\newblock The {{Kalai-Smorodinsky}} solution for many-objective {{Bayesian}}
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 2020.

\bibitem[Binois et~al.(2021)Binois, Habbal, and Picheny]{binois2021a}
Mickael Binois, Abderrahmane Habbal, and Victor Picheny.
\newblock A game theoretic perspective on {{Bayesian}} multi-objective
  optimization.
\newblock \emph{arXiv:2104.14456}, 2021.

\bibitem[Blank and Deb(2020)]{blank2020ia}
Julian Blank and Kalyanmoy Deb.
\newblock Pymoo: {{Multi-Objective Optimization}} in {{Python}}.
\newblock \emph{IEEE Access}, 2020.

\bibitem[Bochner et~al.(1959)Bochner, Functions, Integrals, Analysis,
  Tenenbaum, and Pollard]{bochner1959}
Salomon Bochner, Monotonic Functions, Stieltjes Integrals, Harmonic Analysis,
  Morris Tenenbaum, and Harry Pollard.
\newblock \emph{Lectures on {{Fourier Integrals}}}.
\newblock {Princeton University Press}, 1959.

\bibitem[Bradford et~al.(2018)Bradford, Schweidtmann, and
  Lapkin]{bradford2018jgo}
Eric Bradford, Artur~M. Schweidtmann, and Alexei Lapkin.
\newblock Efficient multiobjective optimization employing {{Gaussian}}
  processes, spectral sampling and a genetic algorithm.
\newblock \emph{Journal of Global Optimization}, 2018.

\bibitem[Brochu et~al.(2010)Brochu, Cora, and {de Freitas}]{brochu2010a}
Eric Brochu, Vlad~M. Cora, and Nando {de Freitas}.
\newblock A {{Tutorial}} on {{Bayesian Optimization}} of {{Expensive Cost
  Functions}}, with {{Application}} to {{Active User Modeling}} and
  {{Hierarchical Reinforcement Learning}}.
\newblock \emph{arXiv:1012.2599}, 2010.

\bibitem[Calandra et~al.(2016)Calandra, Seyfarth, Peters, and
  Deisenroth]{calandra2016amai}
Roberto Calandra, Andr{\'e} Seyfarth, Jan Peters, and Marc~Peter Deisenroth.
\newblock Bayesian optimization for learning gaits under uncertainty.
\newblock \emph{Annals of Mathematics and Artificial Intelligence}, 2016.

\bibitem[Contal et~al.(2013)Contal, Buffoni, Robicquet, and
  Vayatis]{contal2013mlkdd}
Emile Contal, David Buffoni, Alexandre Robicquet, and Nicolas Vayatis.
\newblock Parallel {{Gaussian Process Optimization}} with {{Upper Confidence
  Bound}} and {{Pure Exploration}}.
\newblock In \emph{Machine {{Learning}} and {{Knowledge Discovery}} in
  {{Databases}}}, Lecture {{Notes}} in {{Computer Science}}, 2013.

\bibitem[Couckuyt et~al.(2014)Couckuyt, Deschrijver, and
  Dhaene]{couckuyt2014jgo}
Ivo Couckuyt, Dirk Deschrijver, and Tom Dhaene.
\newblock Fast calculation of multiobjective probability of improvement and
  expected improvement criteria for {{Pareto}} optimization.
\newblock \emph{Journal of Global Optimization}, 2014.

\bibitem[Cover and Thomas(2006)]{cover2006}
Thomas~M. Cover and Joy~A. Thomas.
\newblock \emph{Elements of {{Information Theory}}}.
\newblock {Wiley-Interscience}, 2nd edition edition, 2006.

\bibitem[Daulton et~al.(2020)Daulton, Balandat, and Bakshy]{daulton2020anips}
Samuel Daulton, Maximilian Balandat, and Eytan Bakshy.
\newblock Differentiable {{Expected Hypervolume Improvement}} for {{Parallel
  Multi-Objective Bayesian Optimization}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2020.

\bibitem[Daulton et~al.(2021)Daulton, Balandat, and Bakshy]{daulton2021anips}
Samuel Daulton, Maximilian Balandat, and Eytan Bakshy.
\newblock Parallel {{Bayesian Optimization}} of {{Multiple Noisy Objectives}}
  with {{Expected Hypervolume Improvement}}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Daulton et~al.(2022{\natexlab{a}})Daulton, Cakmak, Balandat, Osborne,
  Zhou, and Bakshy]{daulton2022icml}
Samuel Daulton, Sait Cakmak, Maximilian Balandat, Michael~A. Osborne, Enlu
  Zhou, and Eytan Bakshy.
\newblock Robust {{Multi-Objective Bayesian Optimization Under Input Noise}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}.
  2022{\natexlab{a}}.

\bibitem[Daulton et~al.(2022{\natexlab{b}})Daulton, Eriksson, Balandat, and
  Bakshy]{daulton2022uai}
Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan Bakshy.
\newblock Multi-{{Objective Bayesian Optimization}} over {{High-Dimensional
  Search Spaces}}.
\newblock In \emph{Uncertainty in {{Artificial Intelligence}}},
  2022{\natexlab{b}}.

\bibitem[Deb et~al.(2002)Deb, Pratap, Agarwal, and Meyarivan]{deb2002itec}
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and T.~Meyarivan.
\newblock A {{Fast}} and {{Elitist Multiobjective Genetic Algorithm}}:
  {{NSGA-II}}.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 2002.

\bibitem[Deng and Zhang(2019)]{deng2019itec}
Jingda Deng and Qingfu Zhang.
\newblock Approximating {{Hypervolume}} and {{Hypervolume Contributions Using
  Polar Coordinate}}.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 2019.

\bibitem[Deutz et~al.(2019)Deutz, Emmerich, and Yang]{deutz2019emo}
Andr{\'e} Deutz, Michael Emmerich, and Kaifeng Yang.
\newblock The {{Expected R2-Indicator Improvement}} for {{Multi-objective
  Bayesian Optimization}}.
\newblock In \emph{Evolutionary {{Multi-Criterion Optimization}}}, Lecture
  {{Notes}} in {{Computer Science}}, 2019.

\bibitem[Dong et~al.(2017)Dong, Eriksson, Nickisch, Bindel, and
  Wilson]{dong2017anips}
Kun Dong, David Eriksson, Hannes Nickisch, David Bindel, and Andrew~G Wilson.
\newblock Scalable {{Log Determinants}} for {{Gaussian Process Kernel
  Learning}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2017.

\bibitem[Emmerich et~al.(2006)Emmerich, Giannakoglou, and
  Naujoks]{emmerich2006itec}
Michael T.~M. Emmerich, Kyriakos~C. Giannakoglou, and Boris Naujoks.
\newblock Single- and {{Multiobjective Evolutionary Optimization Assisted}} by
  {{Gaussian Random Field Metamodels}}.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 2006.

\bibitem[Felton et~al.(2021)Felton, Rittig, and Lapkin]{felton2021c}
Kobi~C. Felton, Jan~G. Rittig, and Alexei~A. Lapkin.
\newblock Summit: {{Benchmarking Machine Learning Methods}} for {{Reaction
  Optimisation}}.
\newblock \emph{Chemistry\textendash Methods}, 2021.

\bibitem[{Fern{\'a}ndez-S{\'a}nchez} et~al.(2021){Fern{\'a}ndez-S{\'a}nchez},
  {Garrido-Merch{\'a}n}, and {Hern{\'a}ndez-Lobato}]{fernandez-sanchez2021a}
Daniel {Fern{\'a}ndez-S{\'a}nchez}, Eduardo~C. {Garrido-Merch{\'a}n}, and
  Daniel {Hern{\'a}ndez-Lobato}.
\newblock Improved {{Max-value Entropy Search}} for {{Multi-objective Bayesian
  Optimization}} with {{Constraints}}.
\newblock \emph{arXiv:2011.01150}, 2021.

\bibitem[Frazier(2018)]{frazier2018a}
Peter~I. Frazier.
\newblock A {{Tutorial}} on {{Bayesian Optimization}}.
\newblock \emph{arXiv:1807.02811}, 2018.

\bibitem[Gardner et~al.(2018)Gardner, Pleiss, Weinberger, Bindel, and
  Wilson]{gardner2018anips}
Jacob Gardner, Geoff Pleiss, Kilian~Q Weinberger, David Bindel, and Andrew~G
  Wilson.
\newblock {{GPyTorch}}: {{Blackbox Matrix-Matrix Gaussian Process Inference}}
  with {{GPU Acceleration}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2018.

\bibitem[{Garrido-Merch{\'a}n} and
  {Hern{\'a}ndez-Lobato}(2019)]{garrido-merchan2019n}
Eduardo~C. {Garrido-Merch{\'a}n} and Daniel {Hern{\'a}ndez-Lobato}.
\newblock Predictive {{Entropy Search}} for {{Multi-objective Bayesian
  Optimization}} with {{Constraints}}.
\newblock \emph{Neurocomputing}, 2019.

\bibitem[{Garrido-Merch{\'a}n} and
  {Hern{\'a}ndez-Lobato}(2020)]{garrido-merchan2020n}
Eduardo~C. {Garrido-Merch{\'a}n} and Daniel {Hern{\'a}ndez-Lobato}.
\newblock Dealing with categorical and integer-valued variables in {{Bayesian
  Optimization}} with {{Gaussian}} processes.
\newblock \emph{Neurocomputing}, 2020.

\bibitem[{Garrido-Merch{\'a}n} and
  {Hern{\'a}ndez-Lobato}(2021)]{garrido-merchan2021a}
Eduardo~C. {Garrido-Merch{\'a}n} and Daniel {Hern{\'a}ndez-Lobato}.
\newblock Parallel {{Predictive Entropy Search}} for {{Multi-objective Bayesian
  Optimization}} with {{Constraints}}.
\newblock \emph{arXiv:2004.00601}, 2021.

\bibitem[Gelbart et~al.(2014)Gelbart, Snoek, and Adams]{gelbart2014uai}
Michael~A. Gelbart, Jasper Snoek, and Ryan~P. Adams.
\newblock Bayesian {{Optimization}} with {{Unknown Constraints}}.
\newblock In \emph{Uncertainty in {{Artificial Intelligence}}}, 2014.

\bibitem[{G{\'o}mez-Bombarelli} et~al.(2018){G{\'o}mez-Bombarelli}, Wei,
  Duvenaud, {Hern{\'a}ndez-Lobato}, {S{\'a}nchez-Lengeling}, Sheberla,
  {Aguilera-Iparraguirre}, Hirzel, Adams, and
  {Aspuru-Guzik}]{gomez-bombarelli2018acs}
Rafael {G{\'o}mez-Bombarelli}, Jennifer~N. Wei, David Duvenaud, Jos{\'e}~Miguel
  {Hern{\'a}ndez-Lobato}, Benjam{\'i}n {S{\'a}nchez-Lengeling}, Dennis
  Sheberla, Jorge {Aguilera-Iparraguirre}, Timothy~D. Hirzel, Ryan~P. Adams,
  and Al{\'a}n {Aspuru-Guzik}.
\newblock Automatic {{Chemical Design Using}} a {{Data-Driven Continuous
  Representation}} of {{Molecules}}.
\newblock \emph{ACS Central Science}, 2018.

\bibitem[Gramacy et~al.(2021)Gramacy, Sauer, and Wycoff]{gramacy2021a}
Robert~B. Gramacy, Annie Sauer, and Nathan Wycoff.
\newblock Triangulation candidates for {{Bayesian}} optimization.
\newblock \emph{arXiv:2112.07457}, 2021.

\bibitem[Harris et~al.(2020)Harris, Millman, {van der Walt}, Gommers, Virtanen,
  Cournapeau, Wieser, Taylor, Berg, Smith, Kern, Picus, Hoyer, {van Kerkwijk},
  Brett, Haldane, {del R{\'i}o}, Wiebe, Peterson, {G{\'e}rard-Marchant},
  Sheppard, Reddy, Weckesser, Abbasi, Gohlke, and Oliphant]{harris2020n}
Charles~R. Harris, K.~Jarrod Millman, St{\'e}fan~J. {van der Walt}, Ralf
  Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor,
  Sebastian Berg, Nathaniel~J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,
  Marten~H. {van Kerkwijk}, Matthew Brett, Allan Haldane, Jaime~Fern{\'a}ndez
  {del R{\'i}o}, Mark Wiebe, Pearu Peterson, Pierre {G{\'e}rard-Marchant},
  Kevin Sheppard, Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph
  Gohlke, and Travis~E. Oliphant.
\newblock Array programming with {{NumPy}}.
\newblock \emph{Nature}, 2020.

\bibitem[Hennig and Schuler(2012)]{hennig2012jmlr}
Philipp Hennig and Christian~J. Schuler.
\newblock Entropy {{Search}} for {{Information-Efficient Global Optimization}}.
\newblock \emph{Journal of Machine Learning Research}, 2012.

\bibitem[{Hernandez-Lobato} et~al.(2016){Hernandez-Lobato}, {Hernandez-Lobato},
  Shah, and Adams]{hernandez-lobato2016icml}
Daniel {Hernandez-Lobato}, Jose {Hernandez-Lobato}, Amar Shah, and Ryan Adams.
\newblock Predictive {{Entropy Search}} for {{Multi-objective Bayesian
  Optimization}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2016.

\bibitem[{Hern{\'a}ndez-Lobato} et~al.(2014){Hern{\'a}ndez-Lobato}, Hoffman,
  and Ghahramani]{hernandez-lobato2014anips}
Jos{\'e}~Miguel {Hern{\'a}ndez-Lobato}, Matthew~W Hoffman, and Zoubin
  Ghahramani.
\newblock Predictive {{Entropy Search}} for {{Efficient Global Optimization}}
  of {{Black-box Functions}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2014.

\bibitem[{Hernandez-Lobato} et~al.(2015){Hernandez-Lobato}, Gelbart, Hoffman,
  Adams, and Ghahramani]{hernandez-lobato2015icml}
Jose~Miguel {Hernandez-Lobato}, Michael Gelbart, Matthew Hoffman, Ryan Adams,
  and Zoubin Ghahramani.
\newblock Predictive {{Entropy Search}} for {{Bayesian Optimization}} with
  {{Unknown Constraints}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2015.

\bibitem[{Hern{\'a}ndez-Lobato} et~al.(2016){Hern{\'a}ndez-Lobato}, Gelbart,
  Adams, Hoffman, and Ghahramani]{hernandez-lobato2016jmlr}
Jos{\'e}~Miguel {Hern{\'a}ndez-Lobato}, Michael~A. Gelbart, Ryan~P. Adams,
  Matthew~W. Hoffman, and Zoubin Ghahramani.
\newblock A {{General Framework}} for {{Constrained Bayesian Optimization}}
  using {{Information-based Search}}.
\newblock \emph{Journal of Machine Learning Research}, 2016.

\bibitem[Hickernell et~al.(2005)Hickernell, Lemieux, and
  Owen]{hickernell2005ss}
Fred~J. Hickernell, Christiane Lemieux, and Art~B. Owen.
\newblock Control {{Variates}} for {{Quasi-Monte Carlo}}.
\newblock \emph{Statistical Science}, 2005.

\bibitem[Hoffman and Ghahramani(2015)]{hoffman2015nwbo}
Matthew~W Hoffman and Zoubin Ghahramani.
\newblock Output-{{Space Predictive Entropy Search}} for {{Flexible Global
  Optimization}}.
\newblock In \emph{{{NIPS}} Workshop on {{Bayesian Optimization}}}, 2015.

\bibitem[Hone et~al.(2017)Hone, Holmes, Akien, Bourne, and Muller]{hone2017rce}
Christopher~A. Hone, Nicholas Holmes, Geoffrey~R. Akien, Richard~A. Bourne, and
  Frans~L. Muller.
\newblock Rapid multistep kinetic model generation from transient flow data.
\newblock \emph{Reaction Chemistry \& Engineering}, 2017.

\bibitem[Hvarfner et~al.(2022)Hvarfner, Hutter, and Nardi]{hvarfner2022aa}
Carl Hvarfner, Frank Hutter, and Luigi Nardi.
\newblock Joint {{Entropy Search For Maximally-Informed Bayesian
  Optimization}}.
\newblock \emph{arXiv:2206.04771}, 2022.

\bibitem[Ishibuchi et~al.(2018)Ishibuchi, Imada, Setoguchi, and
  Nojima]{ishibuchi2018ec}
Hisao Ishibuchi, Ryo Imada, Yu~Setoguchi, and Yusuke Nojima.
\newblock How to {{Specify}} a {{Reference Point}} in {{Hypervolume
  Calculation}} for {{Fair Performance Comparison}}.
\newblock \emph{Evolutionary Computation}, 2018.

\bibitem[Kandasamy et~al.(2017)Kandasamy, Dasarathy, Schneider, and
  P{\'o}czos]{kandasamy2017icml}
Kirthevasan Kandasamy, Gautam Dasarathy, Jeff Schneider, and Barnab{\'a}s
  P{\'o}czos.
\newblock Multi-fidelity {{Bayesian Optimisation}} with {{Continuous
  Approximations}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2017.

\bibitem[Kathuria et~al.(2016)Kathuria, Deshpande, and
  Kohli]{kathuria2016anips}
Tarun Kathuria, Amit Deshpande, and Pushmeet Kohli.
\newblock Batched {{Gaussian Process Bandit Optimization}} via {{Determinantal
  Point Processes}}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}}.
  2016.

\bibitem[Keane(2012)]{keane2012aj}
Andy~J. Keane.
\newblock Statistical {{Improvement Criteria}} for {{Use}} in {{Multiobjective
  Design Optimization}}.
\newblock \emph{AIAA Journal}, 2012.

\bibitem[Knowles(2006)]{knowles2006itec}
Joshua Knowles.
\newblock {{ParEGO}}: {{A Hybrid Algorithm With On-Line Landscape
  Approximation}} for {{Expensive Multiobjective Optimization Problems}}.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 2006.

\bibitem[Konakovic~Lukovic et~al.(2020)Konakovic~Lukovic, Tian, and
  Matusik]{konakoviclukovic2020anips}
Mina Konakovic~Lukovic, Yunsheng Tian, and Wojciech Matusik.
\newblock Diversity-{{Guided Multi-Objective Bayesian Optimization With Batch
  Evaluations}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2020.

\bibitem[Krause and Golovin(2013)]{krause2013t}
Andreas Krause and Daniel Golovin.
\newblock Submodular {{Function Maximization}}.
\newblock In \emph{Tractability}, pages 71--104. {Cambridge University Press},
  {Cambridge}, 2013.

\bibitem[Kulesza and Taskar(2012)]{kulesza2012fiml}
Alex Kulesza and Ben Taskar.
\newblock Determinantal point processes for machine learning.
\newblock \emph{Foundations and Trends\textregistered{} in Machine Learning},
  2012.

\bibitem[Lacour et~al.(2017)Lacour, Klamroth, and Fonseca]{lacour2017c&or}
Renaud Lacour, Kathrin Klamroth, and Carlos~M. Fonseca.
\newblock A box decomposition algorithm to compute the hypervolume indicator.
\newblock \emph{Computers \& Operations Research}, 2017.

\bibitem[Liang and Lai(2021)]{liang2021n2asw}
Qiaohao Liang and Lipeng Lai.
\newblock Scalable {{Bayesian Optimization Accelerates Process Optimization}}
  of {{Penicillin Production}}.
\newblock In \emph{{{NeurIPS}} 2021 {{AI}} for {{Science Workshop}}}, 2021.

\bibitem[Liu et~al.(2021)Liu, Tong, and Liu]{liu2021anips}
Xingchao Liu, Xin Tong, and Qiang Liu.
\newblock Profiling pareto front with multi-objective stein variational
  gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2021.

\bibitem[Minka(2001)]{minka2001uai}
Thomas~P. Minka.
\newblock Expectation {{Propagation}} for {{Approximate Bayesian Inference}}.
\newblock In \emph{Uncertainty in {{Artificial Intelligence}}}, 2001.

\bibitem[Moss et~al.(2021{\natexlab{a}})Moss, Leslie, Gonzalez, and
  Rayson]{moss2021jmlr}
Henry~B. Moss, David~S. Leslie, Javier Gonzalez, and Paul Rayson.
\newblock {{GIBBON}}: {{General-purpose Information-Based Bayesian
  Optimisation}}.
\newblock \emph{Journal of Machine Learning Research}, 2021{\natexlab{a}}.

\bibitem[Moss et~al.(2021{\natexlab{b}})Moss, Leslie, and
  Rayson]{moss2021mlkdd}
Henry~B. Moss, David~S. Leslie, and Paul Rayson.
\newblock {{MUMBO}}: {{MUlti-task Max-Value Bayesian Optimization}}.
\newblock In \emph{Machine {{Learning}} and {{Knowledge Discovery}} in
  {{Databases}}}, Lecture {{Notes}} in {{Computer Science}},
  2021{\natexlab{b}}.

\bibitem[Neiswanger et~al.(2021)Neiswanger, Wang, and
  Ermon]{neiswanger2021icml}
Willie Neiswanger, Ke~Alexander Wang, and Stefano Ermon.
\newblock Bayesian {{Algorithm Execution}}: {{Estimating Computable
  Properties}} of {{Black-box Functions Using Mutual Information}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2021.

\bibitem[Nguyen et~al.(2020)Nguyen, Gupta, Rana, Shilton, and
  Venkatesh]{nguyen2020potacoai}
Dang Nguyen, Sunil Gupta, Santu Rana, Alistair Shilton, and Svetha Venkatesh.
\newblock Bayesian {{Optimization}} for {{Categorical}} and {{Category-Specific
  Continuous Inputs}}.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  2020.

\bibitem[Nour et~al.(2020)Nour, C{\"o}mert, and Polat]{nour2020asc}
Majid Nour, Zafer C{\"o}mert, and Kemal Polat.
\newblock A {{Novel Medical Diagnosis}} model for {{COVID-19}} infection
  detection based on {{Deep Features}} and {{Bayesian Optimization}}.
\newblock \emph{Applied Soft Computing}, 2020.

\bibitem[Paria et~al.(2020)Paria, Kandasamy, and P{\'o}czos]{paria2020uai}
Biswajit Paria, Kirthevasan Kandasamy, and Barnab{\'a}s P{\'o}czos.
\newblock A {{Flexible Framework}} for {{Multi-Objective Bayesian
  Optimization}} using {{Random Scalarizations}}.
\newblock In \emph{Uncertainty in {{Artificial Intelligence}}}. 2020.

\bibitem[Parsons and Scott(2004)]{parsons2004josr}
Michael~G. Parsons and Randall~L. Scott.
\newblock Formulation of {{Multicriterion Design Optimization Problems}} for
  {{Solution With Scalar Numerical Optimization Methods}}.
\newblock \emph{Journal of Ship Research}, 2004.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2019anips}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock {{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep
  Learning Library}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2019.

\bibitem[Perrone et~al.(2019)Perrone, Shcherbatyi, Jenatton, Archambeau, and
  Seeger]{perrone2019nwm}
Valerio Perrone, Iaroslav Shcherbatyi, Rodolphe Jenatton, Cedric Archambeau,
  and Matthias Seeger.
\newblock Constrained {{Bayesian Optimization}} with {{Max-Value Entropy
  Search}}.
\newblock \emph{NeurIPS Workshop on Meta-Learning}, 2019.

\bibitem[Picheny(2015)]{picheny2015sc}
Victor Picheny.
\newblock Multiobjective optimization using {{Gaussian}} process emulators via
  stepwise uncertainty reduction.
\newblock \emph{Statistics and Computing}, 2015.

\bibitem[Picheny et~al.(2019)Picheny, Binois, and Habbal]{picheny2019jgo}
Victor Picheny, Mickael Binois, and Abderrahmane Habbal.
\newblock A {{Bayesian}} optimization approach to find {{Nash}} equilibria.
\newblock \emph{Journal of Global Optimization}, 2019.

\bibitem[Rahimi and Recht(2008)]{rahimi2008anips}
Ali Rahimi and Benjamin Recht.
\newblock Random {{Features}} for {{Large-Scale Kernel Machines}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2008.

\bibitem[Rasmussen and Williams(2006)]{rasmussen2006}
Carl~Edward Rasmussen and Christopher K.~I. Williams.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock Adaptive Computation and Machine Learning. {MIT Press}, 2006.

\bibitem[Ru et~al.(2020)Ru, Alvi, Nguyen, Osborne, and Roberts]{ru2020icml}
Binxin Ru, Ahsan Alvi, Vu~Nguyen, Michael~A. Osborne, and Stephen Roberts.
\newblock Bayesian {{Optimisation}} over {{Multiple Continuous}} and
  {{Categorical Inputs}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2020.

\bibitem[Sen and Yang(1998)]{sen1998}
Pratyush Sen and Jian-Bo Yang.
\newblock \emph{Multiple {{Criteria Decision Support}} in {{Engineering
  Design}}}.
\newblock {Springer London}, 1998.

\bibitem[Shah and Ghahramani(2015)]{shah2015anips}
Amar Shah and Zoubin Ghahramani.
\newblock Parallel predictive entropy search for batch global optimization of
  expensive objective functions.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2015.

\bibitem[Shahriari et~al.(2016)Shahriari, Swersky, Wang, Adams, and
  de~Freitas]{shahriari2016pi}
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan~P. Adams, and Nando de~Freitas.
\newblock Taking the {{Human Out}} of the {{Loop}}: {{A Review}} of {{Bayesian
  Optimization}}.
\newblock \emph{Proceedings of the IEEE}, 2016.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012anips}
Jasper Snoek, Hugo Larochelle, and Ryan~P Adams.
\newblock Practical {{Bayesian Optimization}} of {{Machine Learning
  Algorithms}}.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2012.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{snoek2015icml}
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish,
  Narayanan Sundaram, Mostofa Patwary, Mr~Prabhat, and Ryan Adams.
\newblock Scalable {{Bayesian Optimization Using Deep Neural Networks}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2015.

\bibitem[Song et~al.(2019)Song, Chen, and Yue]{song2019icais}
Jialin Song, Yuxin Chen, and Yisong Yue.
\newblock A {{General Framework}} for {{Multi-fidelity Bayesian Optimization}}
  with {{Gaussian Processes}}.
\newblock In \emph{International {{Conference}} on {{Artificial Intelligence}}
  and {{Statistics}}}. 2019.

\bibitem[Sui et~al.(2018)Sui, Zhuang, Burdick, and Yue]{sui2018icml}
Yanan Sui, Vincent Zhuang, Joel Burdick, and Yisong Yue.
\newblock Stagewise {{Safe Bayesian Optimization}} with {{Gaussian Processes}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2018.

\bibitem[Suzuki et~al.(2020)Suzuki, Takeno, Tamura, Shitara, and
  Karasuyama]{suzuki2020icml}
Shinya Suzuki, Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, and Masayuki
  Karasuyama.
\newblock Multi-objective {{Bayesian Optimization}} using {{Pareto-frontier
  Entropy}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2020.

\bibitem[Takeno et~al.(2020)Takeno, Fukuoka, Tsukada, Koyama, Shiga, Takeuchi,
  and Karasuyama]{takeno2020icml}
Shion Takeno, Hitoshi Fukuoka, Yuhki Tsukada, Toshiyuki Koyama, Motoki Shiga,
  Ichiro Takeuchi, and Masayuki Karasuyama.
\newblock Multi-fidelity {{Bayesian Optimization}} with {{Max-value Entropy
  Search}} and its {{Parallelization}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}, 37.
  2020.

\bibitem[Takeno et~al.(2021)Takeno, Tamura, Shitara, and
  Karasuyama]{takeno2021a}
Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, and Masayuki Karasuyama.
\newblock Sequential- and {{Parallel- Constrained Max-value Entropy Search}}
  via {{Information Lower Bound}}.
\newblock \emph{arXiv:2102.09788}, 2021.

\bibitem[Tanabe and Ishibuchi(2020)]{tanabe2020asc}
Ryoji Tanabe and Hisao Ishibuchi.
\newblock An {{Easy-to-use Real-world Multi-objective Optimization Problem
  Suite}}.
\newblock \emph{Applied Soft Computing}, 2020.

\bibitem[Villemonteix et~al.(2008)Villemonteix, Vazquez, and
  Walter]{villemonteix2008jgo}
Julien Villemonteix, Emmanuel Vazquez, and Eric Walter.
\newblock An informational approach to the global optimization of
  expensive-to-evaluate functions.
\newblock \emph{Journal of Global Optimization}, 2008.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, VanderPlas, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, and {van Mulbregt}]{virtanen2020nm}
Pauli Virtanen, Ralf Gommers, Travis~E. Oliphant, Matt Haberland, Tyler Reddy,
  David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan
  Bright, St{\'e}fan~J. {van der Walt}, Matthew Brett, Joshua Wilson, K.~Jarrod
  Millman, Nikolay Mayorov, Andrew R.~J. Nelson, Eric Jones, Robert Kern, Eric
  Larson, C.~J. Carey, {\.I}lhan Polat, Yu~Feng, Eric~W. Moore, Jake
  VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen,
  E.~A. Quintero, Charles~R. Harris, Anne~M. Archibald, Ant{\^o}nio~H. Ribeiro,
  Fabian Pedregosa, and Paul {van Mulbregt}.
\newblock {{SciPy}} 1.0: Fundamental algorithms for scientific computing in
  {{Python}}.
\newblock \emph{Nature Methods}, 2020.

\bibitem[Wang and Jegelka(2017)]{wang2017icml}
Zi~Wang and Stefanie Jegelka.
\newblock Max-value {{Entropy Search}} for {{Efficient Bayesian Optimization}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2017.

\bibitem[Wang et~al.(2017)Wang, Li, Jegelka, and Kohli]{wang2017icmla}
Zi~Wang, Chengtao Li, Stefanie Jegelka, and Pushmeet Kohli.
\newblock Batched {{High-dimensional Bayesian Optimization}} via {{Structural
  Kernel Learning}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2017.

\bibitem[Wilson et~al.(2018)Wilson, Hutter, and Deisenroth]{wilson2018anips}
James Wilson, Frank Hutter, and Marc Deisenroth.
\newblock Maximizing acquisition functions for {{Bayesian}} optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2018.

\bibitem[Wilson et~al.(2020)Wilson, Borovitskiy, Terenin, Mostowsky, and
  Deisenroth]{wilson2020icml}
James Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, and
  Marc Deisenroth.
\newblock Efficiently {{Sampling Functions}} from {{Gaussian Process
  Posteriors}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2020.

\bibitem[Wilson et~al.(2021)Wilson, Borovitskiy, Terenin, Mostowsky, and
  Deisenroth]{wilson2021jmlr}
James~T. Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky,
  and Marc~Peter Deisenroth.
\newblock Pathwise {{Conditioning}} of {{Gaussian Processes}}.
\newblock \emph{Journal of Machine Learning Research}, 2021.

\bibitem[Wu et~al.(2019)Wu, Chen, Zhang, Xiong, Lei, and Deng]{wu2019joesata}
Jia Wu, Xiu-Yun Chen, Hao Zhang, Li-Dong Xiong, Hang Lei, and Si-Hao Deng.
\newblock Hyperparameter {{Optimization}} for {{Machine Learning Models Based}}
  on {{Bayesian Optimization}}.
\newblock \emph{Journal of Electronic Science and Technology}, 2019.

\bibitem[Wu et~al.(2020)Wu, {Toscano-Palmerin}, Frazier, and Wilson]{wu2020uai}
Jian Wu, Saul {Toscano-Palmerin}, Peter~I. Frazier, and Andrew~Gordon Wilson.
\newblock Practical {{Multi-fidelity Bayesian Optimization}} for
  {{Hyperparameter Tuning}}.
\newblock In \emph{Uncertainty in {{Artificial Intelligence}}}. 2020.

\bibitem[Yang et~al.(2019)Yang, Emmerich, Deutz, and B{\"a}ck]{yang2019jgo}
Kaifeng Yang, Michael Emmerich, Andr{\'e} Deutz, and Thomas B{\"a}ck.
\newblock Efficient computation of expected hypervolume improvement using box
  decomposition algorithms.
\newblock \emph{Journal of Global Optimization}, 2019.

\bibitem[Zhang and Golovin(2020)]{zhang2020icml}
Richard Zhang and Daniel Golovin.
\newblock Random {{Hypervolume Scalarizations}} for {{Provable Multi-Objective
  Black Box Optimization}}.
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}. 2020.

\bibitem[Zhang et~al.(2017)Zhang, Hoang, Low, and Kankanhalli]{zhang2017nwbo}
Yehong Zhang, Trong~Nghia Hoang, Bryan Kian~Hsiang Low, and Mohan Kankanhalli.
\newblock Information-{{Based Multi-Fidelity Bayesian Optimization}}.
\newblock \emph{NIPS Workshop on Bayesian Optimization}, 2017.

\bibitem[Zitzler and Thiele(1998)]{zitzler1998ppsn}
Eckart Zitzler and Lothar Thiele.
\newblock Multiobjective {{Optimization Using Evolutionary Algorithms}} - {{A
  Comparative Case Study}}.
\newblock In \emph{Parallel {{Problem Solving}} from {{Nature}}}, Lecture
  {{Notes}} in {{Computer Science}}, 1998.

\bibitem[Zitzler et~al.(2000)Zitzler, Deb, and Thiele]{zitzler2000ec}
Eckart Zitzler, Kalyanmoy Deb, and Lothar Thiele.
\newblock Comparison of {{Multiobjective Evolutionary Algorithms}}: {{Empirical
  Results}}.
\newblock \emph{Evolutionary Computation}, 2000.

\bibitem[Zitzler et~al.(2003)Zitzler, Thiele, Laumanns, Fonseca, and
  da~Fonseca]{zitzler2003itec}
Eckart Zitzler, Lothar Thiele, Marco Laumanns, Carlos~M. Fonseca, and
  Viviane~Grunert da~Fonseca.
\newblock Performance {{Assessment}} of {{Multiobjective Optimizers}}: {{An
  Analysis}} and {{Review}}.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 2003.

\bibitem[Zitzler et~al.(2007)Zitzler, Brockhoff, and Thiele]{zitzler2007emo}
Eckart Zitzler, Dimo Brockhoff, and Lothar Thiele.
\newblock The {{Hypervolume Indicator Revisited}}: {{On}} the {{Design}} of
  {{Pareto-compliant Indicators Via Weighted Integration}}.
\newblock In \emph{Evolutionary {{Multi-Criterion Optimization}}}, Lecture
  {{Notes}} in {{Computer Science}}, 2007.

\end{thebibliography}
