\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2013)Bengio, Courville, and
  Vincent]{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 35\penalty0 (8):\penalty0 1798--1828, 2013.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Hjelm et~al.(2018)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{hjelm2018learning}
R~Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International Conference on Machine Learning}, pages
  1597--1607. PMLR, 2020.

\bibitem[Golinski et~al.(2020)Golinski, Pourreza, Yang, Sautiere, and
  Cohen]{golinski2020feedback}
Adam Golinski, Reza Pourreza, Yang Yang, Guillaume Sautiere, and Taco~S Cohen.
\newblock Feedback recurrent autoencoder for video compression.
\newblock In \emph{Proceedings of the Asian Conference on Computer Vision},
  2020.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018deep}
Matthew~E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock In \emph{Proceedings of NAACL-HLT}, pages 2227--2237, 2018.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186, 2019.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 1877--1901, 2020.

\bibitem[Baevski and Mohamed(2020)]{baevski2019effectiveness}
Alexei Baevski and Abdelrahman Mohamed.
\newblock Effectiveness of self-supervised pre-training for asr.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 7694--7698. IEEE, 2020.

\bibitem[Chung and Glass(2020)]{chung2020generative}
Yu-An Chung and James Glass.
\newblock Generative pre-training for speech with autoregressive predictive
  coding.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 3497--3501. IEEE, 2020.

\bibitem[Wang et~al.(2020)Wang, Tang, and Livescu]{wang2020unsupervised}
Weiran Wang, Qingming Tang, and Karen Livescu.
\newblock Unsupervised pre-training of bidirectional speech encoders via masked
  reconstruction.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 6889--6893. IEEE, 2020.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, Mohamed, and
  Auli]{baevski2020wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Bai et~al.(2021)Bai, Wang, Zhou, and Xiong]{bai2021representation}
Junwen Bai, Weiran Wang, Yingbo Zhou, and Caiming Xiong.
\newblock Representation learning for sequence data with deep autoencoding
  predictive components.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Villegas et~al.(2017)Villegas, Yang, Hong, Lin, and
  Lee]{villegas2017decomposing}
Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee.
\newblock Decomposing motion and content for natural video sequence prediction.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Denton and Birodkar(2017)]{denton2017unsupervised}
Emily~L Denton and vighnesh Birodkar.
\newblock Unsupervised learning of disentangled representations from video.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30, 2017.

\bibitem[Zhu et~al.(2018)Zhu, Elhoseiny, Liu, Peng, and
  Elgammal]{zhu2018generative}
Yizhe Zhu, Mohamed Elhoseiny, Bingchen Liu, Xi~Peng, and Ahmed Elgammal.
\newblock A generative adversarial approach for zero-shot learning from noisy
  texts.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1004--1013, 2018.

\bibitem[Tian et~al.(2020)Tian, Ren, Chai, Olszewski, Peng, Metaxas, and
  Tulyakov]{tian2021good}
Yu~Tian, Jian Ren, Menglei Chai, Kyle Olszewski, Xi~Peng, Dimitris~N Metaxas,
  and Sergey Tulyakov.
\newblock A good image generator is what you need for high-resolution video
  synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Han et~al.(2021)Han, Min, Han, Li, and Zhang]{han2021disentangled}
Jun Han, Martin~Renqiang Min, Ligong Han, Li~Erran Li, and Xuan Zhang.
\newblock Disentangled recurrent wasserstein autoencoder.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and
  Abbeel]{chen2016infogan}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~29, pages 2172--2180, 2016.

\bibitem[Higgins et~al.(2016)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2016beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock \emph{International Conference on Learning Representations}, 2016.

\bibitem[Fraccaro et~al.(2017)Fraccaro, Kamronn, Paquet, and
  Winther]{fraccaro2017disentangled}
Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther.
\newblock A disentangled recognition and nonlinear dynamics model for
  unsupervised learning.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30, 2017.

\bibitem[Kim and Mnih(2018)]{kim2018disentangling}
Hyunjik Kim and Andriy Mnih.
\newblock Disentangling by factorising.
\newblock In \emph{International Conference on Machine Learning}, pages
  2649--2658. PMLR, 2018.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
Ricky T.~Q. Chen, Xuechen Li, Roger~B Grosse, and David~K Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly,
  Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In \emph{International Conference on Machine Learning}, pages
  4114--4124. PMLR, 2019.

\bibitem[Khemakhem et~al.(2020)Khemakhem, Kingma, Monti, and
  Hyvarinen]{khemakhem2020variational}
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen.
\newblock Variational autoencoders and nonlinear ica: A unifying framework.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2207--2217. PMLR, 2020.

\bibitem[Locatello et~al.(2020)Locatello, Poole, R{\"a}tsch, Sch{\"o}lkopf,
  Bachem, and Tschannen]{locatello20a}
Francesco Locatello, Ben Poole, Gunnar R{\"a}tsch, Bernhard Sch{\"o}lkopf,
  Olivier Bachem, and Michael Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In \emph{International Conference on Machine Learning}, pages
  6348--6359. PMLR, 2020.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Kingma and Welling(2014)]{kingma2014auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Chung et~al.(2015)Chung, Kastner, Dinh, Goel, Courville, and
  Bengio]{chung2015recurrent}
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron~C Courville,
  and Yoshua Bengio.
\newblock A recurrent latent variable model for sequential data.
\newblock In C.~Cortes, N.~Lawrence, D.~Lee, M.~Sugiyama, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~28,
  2015.

\bibitem[Goyal et~al.(2017)Goyal, Sordoni, C{\^o}t{\'e}, Ke, and
  Bengio]{goyal2017z}
Anirudh Goyal, Alessandro Sordoni, Marc-Alexandre C{\^o}t{\'e}, Nan~Rosemary
  Ke, and Yoshua Bengio.
\newblock Z-forcing: Training stochastic recurrent networks.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30, 2017.

\bibitem[Krishnan et~al.(2015)Krishnan, Shalit, and Sontag]{krishnan2015deep}
Rahul~G Krishnan, Uri Shalit, and David Sontag.
\newblock Deep kalman filters.
\newblock \emph{arXiv preprint arXiv:1511.05121}, 2015.

\bibitem[Li and Mandt(2018)]{li2018disentangled}
Yingzhen Li and Stephan Mandt.
\newblock Disentangled sequential autoencoder.
\newblock In \emph{International Conference on Machine Learning}, pages
  5670--5679. PMLR, 2018.

\bibitem[Zhu et~al.(2020)Zhu, Min, Kadav, and Graf]{zhu2020s3vae}
Yizhe Zhu, Martin~Renqiang Min, Asim Kadav, and Hans~Peter Graf.
\newblock S3vae: Self-supervised sequential vae for representation
  disentanglement and data generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 6538--6547, 2020.

\bibitem[Bowman et~al.(2016)Bowman, Vilnis, Vinyals, Dai, Jozefowicz, and
  Bengio]{bowman2015generating}
Samuel Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and
  Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock In \emph{Proceedings of The 20th SIGNLL Conference on Computational
  Natural Language Learning}, pages 10--21, 2016.

\bibitem[Tomczak and Welling(2018)]{tomczak2018vae}
Jakub Tomczak and Max Welling.
\newblock Vae with a vampprior.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2018.

\bibitem[Alemi et~al.(2018)Alemi, Poole, Fischer, Dillon, Saurous, and
  Murphy]{alemi2018fixing}
Alexander Alemi, Ben Poole, Ian Fischer, Joshua Dillon, Rif~A Saurous, and
  Kevin Murphy.
\newblock Fixing a broken elbo.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Takahashi et~al.(2019)Takahashi, Iwata, Yamanaka, Yamada, and
  Yagi]{takahashi2019variational}
Hiroshi Takahashi, Tomoharu Iwata, Yuki Yamanaka, Masanori Yamada, and Satoshi
  Yagi.
\newblock Variational autoencoder with implicit optimal priors.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 5066--5073, 2019.

\bibitem[Tschannen et~al.(2018)Tschannen, Bachem, and
  Lucic]{tschannen2018recent}
Michael Tschannen, Olivier Bachem, and Mario Lucic.
\newblock Recent advances in autoencoder-based representation learning.
\newblock \emph{arXiv preprint arXiv:1812.05069}, 2018.

\bibitem[Akuzawa et~al.(2021)Akuzawa, Iwasawa, and
  Matsuo]{akuzawa2021information}
Kei Akuzawa, Yusuke Iwasawa, and Yutaka Matsuo.
\newblock Information-theoretic regularization for learning global features by
  sequential vae.
\newblock \emph{Machine Learning}, 110\penalty0 (8):\penalty0 2239--2266, 2021.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{bachman2019learning}
Philip Bachman, R~Devon Hjelm, and William Buchwalter.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Verhelst and Roelands(1993)]{verhelst1993overlap}
Werner Verhelst and Marc Roelands.
\newblock An overlap-add technique based on waveform similarity (wsola) for
  high quality time-scale modification of speech.
\newblock In \emph{IEEE International Conference on Acoustics, Speech, and
  Signal Processing}, volume~2, pages 554--557. IEEE, 1993.

\bibitem[Driedger and M{\"u}ller(2016)]{driedger2016review}
Jonathan Driedger and Meinard M{\"u}ller.
\newblock A review of time-scale modification of music signals.
\newblock \emph{Applied Sciences}, 6\penalty0 (2):\penalty0 57, 2016.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip
  Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{NIPS2014_Ian}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~27, 2014.

\bibitem[Tulyakov et~al.(2018)Tulyakov, Liu, Yang, and
  Kautz]{tulyakov2018mocogan}
Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz.
\newblock Mocogan: Decomposing motion and content for video generation.
\newblock In \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 1526--1535. IEEE Computer Society, 2018.

\bibitem[Hsu et~al.(2017)Hsu, Zhang, and Glass]{hsu2017unsupervised}
Wei-Ning Hsu, Yu~Zhang, and James Glass.
\newblock Unsupervised learning of disentangled and interpretable
  representations from sequential data.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30, 2017.

\bibitem[Cheng et~al.(2020)Cheng, Min, Shen, Malon, Zhang, Li, and
  Carin]{cheng2020improving}
Pengyu Cheng, Martin~Renqiang Min, Dinghan Shen, Christopher Malon, Yizhe
  Zhang, Yitong Li, and Lawrence Carin.
\newblock Improving disentangled text representation learning with
  information-theoretic guidance.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 7530--7541, 2020.

\bibitem[Hyvarinen and Morioka(2016)]{NIPS2016_d305281f}
Aapo Hyvarinen and Hiroshi Morioka.
\newblock Unsupervised feature extraction by time-contrastive learning and
  nonlinear ica.
\newblock In D.~Lee, M.~Sugiyama, U.~Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~29,
  2016.

\bibitem[Hyvarinen and Morioka(2017)]{hyvarinen17a}
Aapo Hyvarinen and Hiroshi Morioka.
\newblock Nonlinear ica of temporally dependent stationary sources.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 460--469.
  PMLR, 2017.

\bibitem[Gresele et~al.(2020)Gresele, Rubenstein, Mehrjou, Locatello, and
  Sch{\"o}lkopf]{gresele2019incomplete}
Luigi Gresele, Paul~K Rubenstein, Arash Mehrjou, Francesco Locatello, and
  Bernhard Sch{\"o}lkopf.
\newblock The incomplete rosetta stone problem: Identifiability results for
  multi-view nonlinear ica.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 217--227.
  PMLR, 2020.

\bibitem[Reed et~al.(2015)Reed, Zhang, Zhang, and Lee]{reed2015deep}
Scott~E Reed, Yi~Zhang, Yuting Zhang, and Honglak Lee.
\newblock Deep visual analogy-making.
\newblock In C.~Cortes, N.~Lawrence, D.~Lee, M.~Sugiyama, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~28,
  2015.

\bibitem[Aifanti et~al.(2010)Aifanti, Papachristou, and
  Delopoulos]{aifanti2010mug}
Niki Aifanti, Christos Papachristou, and Anastasios Delopoulos.
\newblock The mug facial expression database.
\newblock In \emph{11th International Workshop on Image Analysis for Multimedia
  Interactive Services WIAMIS 10}, pages 1--4. IEEE, 2010.

\bibitem[Denton and Fergus(2018)]{denton2018stochastic}
Emily Denton and Rob Fergus.
\newblock Stochastic video generation with a learned prior.
\newblock In \emph{International Conference on Machine Learning}, pages
  1174--1183. PMLR, 2018.

\bibitem[Garofolo et~al.(1992)Garofolo, Lamel, Fisher, Fiscus, Pallett,
  Dahlgren, and Zue]{timit1992}
J.~Garofolo, Lori Lamel, W.~Fisher, Jonathan Fiscus, D.~Pallett, N.~Dahlgren,
  and V.~Zue.
\newblock Timit acoustic-phonetic continuous speech corpus.
\newblock \emph{Linguistic Data Consortium}, 1992.

\bibitem[Zhou et~al.(2017)Zhou, Zhang, and Wang]{zhou2017inception}
Zhiming Zhou, Weinan Zhang, and Jun Wang.
\newblock Inception score, label smoothing, gradient vanishing and log(d(x))
  alternative.
\newblock \emph{arXiv preprint arXiv:1708.01729}, 2017.

\bibitem[Dehak et~al.(2010)Dehak, Kenny, Dehak, Dumouchel, and
  Ouellet]{dehak2010front}
Najim Dehak, Patrick~J Kenny, R{\'e}da Dehak, Pierre Dumouchel, and Pierre
  Ouellet.
\newblock Front-end factor analysis for speaker verification.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  19\penalty0 (4):\penalty0 788--798, 2010.

\bibitem[Kingma and Ba(2015)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\end{thebibliography}
