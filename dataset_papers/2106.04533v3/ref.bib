%%% ViT

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{cheng2017survey,
  title={A survey of model compression and acceleration for deep neural networks},
  author={Cheng, Yu and Wang, Duo and Zhou, Pan and Zhang, Tao},
  journal={arXiv preprint arXiv:1710.09282},
  year={2017}
}

@article{han2021transformer,
  title={Transformer in transformer},
  author={Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  journal={arXiv preprint arXiv:2103.00112},
  year={2021}
}

@article{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zihang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2101.11986},
  year={2021}
}

@article{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={arXiv preprint arXiv:2102.12122},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{mocanu2018scalable,
  title={Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science},
  author={Mocanu, Decebal Constantin and Mocanu, Elena and Stone, Peter and Nguyen, Phuong H and Gibescu, Madeleine and Liotta, Antonio},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}

@inproceedings{molchanov2019importance,
  title={Importance estimation for neural network pruning},
  author={Molchanov, Pavlo and Mallya, Arun and Tyree, Stephen and Frosio, Iuri and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11264--11272},
  year={2019}
}

@InProceedings{pmlr-v119-chen20s, title = {Generative Pretraining From Pixels}, author = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {1691--1703}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v119/chen20s/chen20s.pdf}, url = { http://proceedings.mlr.press/v119/chen20s.html }}

@inproceedings{parmar2018image,
  title={Image transformer},
  author={Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle={International Conference on Machine Learning},
  pages={4055--4064},
  year={2018},
  organization={PMLR}
}

@inproceedings{yang2020learning,
  title={Learning texture transformer network for image super-resolution},
  author={Yang, Fuzhi and Yang, Huan and Fu, Jianlong and Lu, Hongtao and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5791--5800},
  year={2020}
}

@article{chen2020pre,
  title={Pre-trained image processing transformer},
  author={Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
  journal={arXiv preprint arXiv:2012.00364},
  year={2020}
}

@article{wang2020end,
  title={End-to-End Video Instance Segmentation with Transformers},
  author={Wang, Yuqing and Xu, Zhaoliang and Wang, Xinlong and Shen, Chunhua and Cheng, Baoshan and Shen, Hao and Xia, Huaxia},
  journal={arXiv preprint arXiv:2011.14503},
  year={2020}
}

@article{wang2020max,
  title={MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers},
  author={Wang, Huiyu and Zhu, Yukun and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2012.00759},
  year={2020}
}

@inproceedings{
zhu2021deformable,
title={Deformable {\{}DETR{\}}: Deformable Transformers for End-to-End Object Detection},
author={Xizhou Zhu and Weijie Su and Lewei Lu and Bin Li and Xiaogang Wang and Jifeng Dai},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=gZ9hCDWe6ke}
}

@article{dai2020up,
  title={UP-DETR: Unsupervised Pre-training for Object Detection with Transformers},
  author={Dai, Zhigang and Cai, Bolun and Lin, Yugeng and Chen, Junying},
  journal={arXiv preprint arXiv:2011.09094},
  year={2020}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@article{gan2021playing,
  title={Playing Lottery Tickets with Vision and Language},
  author={Gan, Zhe and Chen, Yen-Chun and Li, Linjie and Chen, Tianlong and Cheng, Yu and Wang, Shuohang and Liu, Jingjing},
  journal={arXiv preprint arXiv:2104.11832},
  year={2021}
}

@article{chen2021unified,
  title={A Unified Lottery Ticket Hypothesis for Graph Neural Networks},
  author={Chen, Tianlong and Sui, Yongduo and Chen, Xuxi and Zhang, Aston and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2102.06790},
  year={2021}
}

@article{chen2021ultra,
  title={Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly},
  author={Chen, Tianlong and Cheng, Yu and Gan, Zhe and Liu, Jingjing and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2103.00397},
  year={2021}
}

@article{ma2021good,
  title={Good Students Play Big Lottery Better},
  author={Ma, Haoyu and Chen, Tianlong and Hu, Ting-Kuei and You, Chenyu and Xie, Xiaohui and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2101.03255},
  year={2021}
}

@InProceedings{pmlr-v139-zhang21c,
  title = 	 {Efficient Lottery Ticket Finding: Less Data is More},
  author =       {Zhang, Zhenyu and Chen, Xuxi and Chen, Tianlong and Wang, Zhangyang},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {12380--12390},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/zhang21c/zhang21c.pdf},
  url = 	 {https://proceedings.mlr.press/v139/zhang21c.html}
}

@article{touvron2020training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2012.12877},
  year={2020}
}

@article{zheng2020end,
  title={End-to-End Object Detection with Adaptive Clustering Transformer},
  author={Zheng, Minghang and Gao, Peng and Wang, Xiaogang and Li, Hongsheng and Dong, Hao},
  journal={arXiv preprint arXiv:2011.09315},
  year={2020}
}

@article{jiang2021transgan,
  title={Transgan: Two transformers can make one strong gan},
  author={Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2102.07074},
  year={2021}
}

@inproceedings{zeng2020learning,
  title={Learning Joint Spatial-Temporal Transformations for Video Inpainting},
  author={Zeng, Yanhong and Fu, Jianlong and Chao, Hongyang},
  booktitle={European Conference on Computer Vision},
  pages={528--543},
  year={2020},
  organization={Springer}
}

@inproceedings{zhou2018end,
  title={End-to-end dense video captioning with masked transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8739--8748},
  year={2018}
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={arXiv preprint arXiv:1908.02265},
  year={2019}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European Conference on Computer Vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{su2019vl,
  title={Vl-bert: Pre-training of generic visual-linguistic representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  journal={arXiv preprint arXiv:1908.08530},
  year={2019}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{li2020unicoder,
  title={Unicoder-vl: A universal encoder for vision and language by cross-modal pre-training},
  author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={11336--11344},
  year={2020}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{zhou2020unified,
  title={Unified vision-language pre-training for image captioning and vqa},
  author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason and Gao, Jianfeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={13041--13049},
  year={2020}
}

@article{zhao2020point,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2012.09164},
  year={2020}
}

@article{tay2020long,
  title={Long Range Arena: A Benchmark for Efficient Transformers},
  author={Tay, Yi and Dehghani, Mostafa and Abnar, Samira and Shen, Yikang and Bahri, Dara and Pham, Philip and Rao, Jinfeng and Yang, Liu and Ruder, Sebastian and Metzler, Donald},
  journal={arXiv preprint arXiv:2011.04006},
  year={2020}
}

@article{tay2020efficient,
  title={Efficient transformers: A survey},
  author={Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
  journal={arXiv preprint arXiv:2009.06732},
  year={2020}
}

@misc{wang2020linformer,
      title={Linformer: Self-Attention with Linear Complexity}, 
      author={Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
      year={2020},
      eprint={2006.04768},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@article{zhou2021deepvit,
  title={Deepvit: Towards deeper vision transformer},
  author={Zhou, Daquan and Kang, Bingyi and Jin, Xiaojie and Yang, Linjie and Lian, Xiaochen and Jiang, Zihang and Hou, Qibin and Feng, Jiashi},
  journal={arXiv preprint arXiv:2103.11886},
  year={2021}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@article{ho2019axial,
  title={Axial attention in multidimensional transformers},
  author={Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
  journal={arXiv preprint arXiv:1912.12180},
  year={2019}
}

@article{rae2019compressive,
  title={Compressive transformers for long-range sequence modelling},
  author={Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and Lillicrap, Timothy P},
  journal={arXiv preprint arXiv:1911.05507},
  year={2019}
}

@article{zhang2021multi,
  title={Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding},
  author={Zhang, Pengchuan and Dai, Xiyang and Yang, Jianwei and Xiao, Bin and Yuan, Lu and Zhang, Lei and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2103.15358},
  year={2021}
}

@article{roy2021efficient,
  title={Efficient content-based sparse attention with routing transformers},
  author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={53--68},
  year={2021},
  publisher={MIT Press}
}

@inproceedings{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International Conference on Machine Learning},
  pages={3744--3753},
  year={2019},
  organization={PMLR}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{kitaev2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}


%%% Pruning

@inproceedings{ge2015escaping,
  title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on learning theory},
  pages={797--842},
  year={2015},
  organization={PMLR}
}
@article{kawaguchi2016deep,
  title={Deep learning without poor local minima},
  author={Kawaguchi, Kenji},
  journal={arXiv preprint arXiv:1605.07110},
  year={2016}
}
@article{wen2019interplay,
  title={Interplay between optimization and generalization of stochastic gradient descent with covariance noise},
  author={Wen, Yeming and Luk, Kevin and Gazeau, Maxime and Zhang, Guodong and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:1902.08234},
  year={2019}
}
@article{wen2020batchensemble,
  title={Batchensemble: an alternative approach to efficient ensemble and lifelong learning},
  author={Wen, Yeming and Tran, Dustin and Ba, Jimmy},
  journal={arXiv preprint arXiv:2002.06715},
  year={2020}
}
@article{havasi2020training,
  title={Training independent subnetworks for robust prediction},
  author={Havasi, Marton and Jenatton, Rodolphe and Fort, Stanislav and Liu, Jeremiah Zhe and Snoek, Jasper and Lakshminarayanan, Balaji and Dai, Andrew M and Tran, Dustin},
  journal={arXiv preprint arXiv:2010.06610},
  year={2020}
}
@article{lee2015m,
  title={Why M heads are better than one: Training a diverse ensemble of deep networks},
  author={Lee, Stefan and Purushwalkam, Senthil and Cogswell, Michael and Crandall, David and Batra, Dhruv},
  journal={arXiv preprint arXiv:1511.06314},
  year={2015}
}
@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}
@techreport{perrone1992networks,
  title={When networks disagree: Ensemble methods for hybrid neural networks},
  author={Perrone, Michael P and Cooper, Leon N},
  year={1992},
  institution={BROWN UNIV PROVIDENCE RI INST FOR BRAIN AND NEURAL SYSTEMS}
}
@inproceedings{Dietterich2000EnsembleMI,
  title={Ensemble Methods in Machine Learning},
  author={Thomas G. Dietterich},
  booktitle={Multiple Classifier Systems},
  year={2000}
}
@article{wenzel2020hyperparameter,
  title={Hyperparameter ensembles for robustness and uncertainty quantification},
  author={Wenzel, Florian and Snoek, Jasper and Tran, Dustin and Jenatton, Rodolphe},
  journal={arXiv preprint arXiv:2006.13570},
  year={2020}
}
@inproceedings{Lakshminarayanan2017SimpleAS,
  title={Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  author={Balaji Lakshminarayanan and Alexander Pritzel and Charles Blundell},
  booktitle={NIPS},
  year={2017}
}
@article{Xie2013HorizontalAV,
  title={Horizontal and Vertical Ensemble with Deep Representation for Classification},
  author={Jingjing Xie and Bing Xu and Chuang Zhang},
  journal={CoRR},
  year={2013},
  volume={abs/1306.2759}
}
@article{Gustafsson2019EvaluatingSB,
  title={Evaluating Scalable {Bayesian} Deep Learning Methods for Robust Computer Vision},
  author={Fredrik K. Gustafsson and Martin Danelljan and Thomas B. Sch{\"o}n},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.01620}
}
@article{Ovadia2019CanYT,
  title={Can You Trust Your Model's Uncertainty? {Evaluating} Predictive Uncertainty Under Dataset Shift},
  author={Yaniv Ovadia and Emily Fertig and Jie Ren and Zachary Nado and D. Sculley and Sebastian Nowozin and Joshua V. Dillon and Balaji Lakshminarayanan and Jasper Snoek},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.02530}
}
@article{liu2020topological,
  title={Topological insights into sparse neural networks},
  author={Liu, Shiwei and Van der Lee, Tim and Yaman, Anil and Atashgahi, Zahra and Ferraro, Davide and Sokar, Ghada and Pechenizkiy, Mykola and Constantin, Decebal},
  journal={arXiv preprint arXiv:2006.14085},
  year={2020}
}

@article{hansen1990neural,
  title={Neural network ensembles},
  author={Hansen, Lars Kai and Salamon, Peter},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={12},
  number={10},
  pages={993--1001},
  year={1990},
  publisher={IEEE}
}
@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  number={2},
  pages={123--140},
  year={1996},
  publisher={Springer}
}

@article{fort2019deep,
  title={Deep ensembles: A loss landscape perspective},
  author={Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02757},
  year={2019}
}
@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}
@inproceedings{du2019gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle={International Conference on Machine Learning},
  pages={1675--1685},
  year={2019},
  organization={PMLR}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}
@article{strubell2019energy,
  title={Energy and policy considerations for deep learning in NLP},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  journal={arXiv preprint arXiv:1906.02243},
  year={2019}
}
@article{schwartz2019green,
  title={Green ai},
  author={Schwartz, Roy and Dodge, Jesse and Smith, Noah A and Etzioni, Oren},
  journal={arXiv preprint arXiv:1907.10597},
  year={2019}
}
@article{garcia2019estimation,
  title={Estimation of energy consumption in machine learning},
  author={Garc{\'\i}a-Mart{\'\i}n, Eva and Rodrigues, Crefeda Faviola and Riley, Graham and Grahn, H{\aa}kan},
  journal={Journal of Parallel and Distributed Computing},
  volume={134},
  pages={75--88},
  year={2019},
  publisher={Elsevier}
}
@article{touvron2020fixing,
  title={Fixing the train-test resolution discrepancy: Fixefficientnet},
  author={Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2003.08237},
  year={2020}
}
@article{zou2020gradient,
  title={Gradient descent optimizes over-parameterized deep ReLU networks},
  author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
  journal={Machine Learning},
  volume={109},
  number={3},
  pages={467--492},
  year={2020},
  publisher={Springer}
}
@article{evci2019difficulty,
  title={The difficulty of training sparse neural networks},
  author={Evci, Utku and Pedregosa, Fabian and Gomez, Aidan and Elsen, Erich},
  journal={arXiv preprint arXiv:1906.10732},
  year={2019}
}
@inproceedings{zou2019improved,
  title={An improved analysis of training over-parameterized deep neural networks},
  author={Zou, Difan and Gu, Quanquan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2055--2064},
  year={2019}
}
@article{chen2019much,
  title={How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?},
  author={Chen, Zixiang and Cao, Yuan and Zou, Difan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1911.12360},
  year={2019}
}
@article{janowsky1989pruning,
  title={Pruning versus clipping in neural networks},
  author={Janowsky, Steven A},
  journal={Physical Review A},
  volume={39},
  number={12},
  pages={6600},
  year={1989},
  publisher={APS}
}
@article{mozer1989using,
  title={Using relevance to reduce network size automatically},
  author={Mozer, Michael C and Smolensky, Paul},
  journal={Connection Science},
  volume={1},
  number={1},
  pages={3--16},
  year={1989},
  publisher={Taylor \& Francis}
}
@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in neural information processing systems},
  pages={1135--1143},
  year={2015}
}

@misc{zhu2021visual,
      title={Visual Transformer Pruning}, 
      author={Mingjian Zhu and Kai Han and Yehui Tang and Yunhe Wang},
      year={2021},
      eprint={2104.08500},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{mocanu2016topological,
  title={A topological insight into restricted boltzmann machines},
  author={Mocanu, Decebal Constantin and Mocanu, Elena and Nguyen, Phuong H and Gibescu, Madeleine and Liotta, Antonio},
  journal={Machine Learning},
  volume={104},
  number={2-3},
  pages={243--270},
  year={2016},
  publisher={Springer}
}

@article{gomez2019learning,
  title={Learning sparse networks using targeted dropout},
  author={Gomez, Aidan N and Zhang, Ivan and Kamalakara, Siddhartha Rao and Madaan, Divyam and Swersky, Kevin and Gal, Yarin and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1905.13678},
  year={2019}
}
@article{jaderberg2014speeding,
  title={Speeding up convolutional neural networks with low rank expansions},
  author={Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1405.3866},
  year={2014}
}
@inproceedings{
jorge2021progressive,
title={Progressive Skeletonization: Trimming more fat from a network at initialization},
author={Pau de Jorge and Amartya Sanyal and Harkirat Behl and Philip Torr and Gr{\'e}gory Rogez and Puneet K. Dokania},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=9GsFOUyUPi}
}
@inproceedings{
bellec2018deep,
title={Deep Rewiring: Training very sparse deep networks},
author={Guillaume Bellec and David Kappel and Wolfgang Maass and Robert Legenstein},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJ_wN01C-},
}
@inproceedings{
frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJl-b3RcF7},
}
@inproceedings{
LIU2020Dynamic,
title={Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers},
author={Junjie Liu and Zhe Xu and Runbin Shi and Ray C. C. Cheung and Hayden K.H. So},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJlbGJrtDB}
}
@article{savarese2019winning,
  title={Winning the Lottery with Continuous Sparsification},
  author={Savarese, Pedro and Silva, Hugo and Maire, Michael},
  journal={arXiv preprint arXiv:1912.04427},
  year={2019}
}
@inproceedings{wen2016learning,
  title={Learning structured sparsity in deep neural networks},
  author={Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  booktitle={Advances in neural information processing systems},
  pages={2074--2082},
  year={2016}
}
@inproceedings{molchanov2017variational,
  title={Variational dropout sparsifies deep neural networks},
  author={Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
  booktitle={International Conference on Machine Learning},
  year={2017}
}
@article{molchanov2016pruning,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06440},
  year={2016}
}

@inproceedings{lecun1990optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John S and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={598--605},
  year={1990}
}
@inproceedings{lin2017runtime,
  title={Runtime neural pruning},
  author={Lin, Ji and Rao, Yongming and Lu, Jiwen and Zhou, Jie},
  booktitle={Advances in neural information processing systems},
  pages={2181--2191},
  year={2017}
}

@inproceedings{hassibi1993second,
  title={Second order derivatives for network pruning: Optimal brain surgeon},
  author={Hassibi, Babak and Stork, David G},
  booktitle={Advances in neural information processing systems},
  pages={164--171},
  year={1993}
}

@article{yin2019understanding,
  title={Understanding straight-through estimator in training activation quantized neural nets},
  author={Yin, Penghang and Lyu, Jiancheng and Zhang, Shuai and Osher, Stanley and Qi, Yingyong and Xin, Jack},
  journal={arXiv preprint arXiv:1903.05662},
  year={2019}
}

@article{louizos2017learning,
  title={Learning Sparse Neural Networks through $ L\_0 $ Regularization},
  author={Louizos, Christos and Welling, Max and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1712.01312},
  year={2017}
}
@article{gale2019state,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}
@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}

@article{liu2021selfish,
  title={Selfish sparse RNN training},
  author={Liu, Shiwei and Mocanu, Decebal Constantin and Pei, Yulong and Pechenizkiy, Mykola},
  journal={arXiv preprint arXiv:2101.09048},
  year={2021}
}
@inproceedings{mostafa2019parameter,
  title={Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization},
  author={Mostafa, Hesham and Wang, Xin},
  booktitle={International Conference on Machine Learning},
  year={2019}
}
@article{dettmers2019sparse,
  title={Sparse networks from scratch: Faster training without losing performance},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1907.04840},
  year={2019}
}
@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}
@inproceedings{
anonymous2021gradient,
title={Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=V1N4GEWki_E},
note={under review}
}
@inproceedings{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  booktitle={International Conference on Learning Representations},
  year={2016}
}
@inproceedings{guo2016dynamic,
  title={Dynamic network surgery for efficient dnns},
  author={Guo, Yiwen and Yao, Anbang and Chen, Yurong},
  booktitle={Advances in neural information processing systems},
  pages={1379--1387},
  year={2016}
}
@article{zhu2017prune,
  title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
  author={Zhu, Michael and Gupta, Suyog},
  journal={arXiv preprint arXiv:1710.01878},
  year={2017}
}
@article{zhang2019one,
  title={One-shot pruning of recurrent neural networks by jacobian spectrum evaluation},
  author={Zhang, Matthew Shunshi and Stadie, Bradly},
  journal={arXiv preprint arXiv:1912.00120},
  year={2019}
}
@inproceedings{narang2017exploring,
  title={Exploring sparsity in recurrent neural networks},
  author={Narang, Sharan and Elsen, Erich and Diamos, Gregory and Sengupta, Shubho},
  booktitle={International Conference on Learning Representations},
  year={2017},
}
@inproceedings{frankle2020linear,
  title={Linear mode connectivity and the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={3259--3269},
  year={2020},
  organization={PMLR}
}
@inproceedings{kalchbrenner2018efficient,
  title={Efficient neural audio synthesis},
  author={Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={2410--2419},
  year={2018},
  organization={PMLR}
}
@inproceedings{liu2019rethinking,
  title={Rethinking the value of network pruning},
  author={Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{dai2018grow,
  title={Grow and prune compact, fast, and accurate LSTMs},
  author={Dai, Xiaoliang and Yin, Hongxu and Jha, Niraj K},
  journal={arXiv preprint arXiv:1805.11797},
  year={2018}
}
@article{dai2019nest,
  title={NeST: A neural network synthesis tool based on a grow-and-prune paradigm},
  author={Dai, Xiaoliang and Yin, Hongxu and Jha, Niraj K},
  journal={IEEE Transactions on Computers},
  volume={68},
  number={10},
  pages={1487--1497},
  year={2019},
  publisher={IEEE}
} 
@article{jayakumar2020top,
  title={Top-KAST: Top-K Always Sparse Training},
  author={Jayakumar, Siddhant and Pascanu, Razvan and Rae, Jack and Osindero, Simon and Elsen, Erich},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@article{raihan2020sparse,
  title={Sparse weight activation training},
  author={Raihan, Md Aamir and Aamodt, Tor M},
  journal={arXiv preprint arXiv:2001.01969},
  year={2020}
}
@article{liu2021efficient,
  title={Efficient and effective training of sparse recurrent neural networks},
  author={Liu, Shiwei and Ni’mah, Iftitahu and Menkovski, Vlado and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  journal={Neural Computing and Applications},
  pages={1--12},
  year={2021},
  publisher={Springer}
}
@article{atashgahi2020quick,
  title={Quick and Robust Feature Selection: the Strength of Energy-efficient Sparse Training for Autoencoders},
  author={Atashgahi, Zahra and Sokar, Ghada and van der Lee, Tim and Mocanu, Elena and Mocanu, Decebal Constantin and Veldhuis, Raymond and Pechenizkiy, Mykola},
  journal={arXiv preprint arXiv:2012.00560},
  year={2020}
}
@article{tessera2021keep,
  title={Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization},
  author={Tessera, Kale-ab and Hooker, Sara and Rosman, Benjamin},
  journal={arXiv preprint arXiv:2102.01670},
  year={2021}
}
@article{bird2020dendritic,
  title={Dendritic normalisation improves learning in sparsely connected artificial neural networks},
  author={Bird, Alexander D and Cuntz, Hermann},
  journal={bioRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}
@article{zhu2019multi,
  title={Multi-objective evolutionary federated learning},
  author={Zhu, Hangyu and Jin, Yaochu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={4},
  pages={1310--1322},
  year={2019},
  publisher={IEEE}
}
@article{sokar2021spacenet,
  title={SpaceNet: Make Free Space For Continual Learning},
  author={Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  journal={Neurocomputing},
  volume={439},
  pages={1--11},
  year={2021},
  publisher={Elsevier}
}
@article{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred A},
  journal={arXiv preprint arXiv:1803.00885},
  year={2018}
}
@inproceedings{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8789--8798},
  year={2018}
}
@article{stanley2002evolving,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}
@article{evci2020gradient,
  title={Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win},
  author={Evci, Utku and Ioannou, Yani A and Keskin, Cem and Dauphin, Yann},
  journal={arXiv preprint arXiv:2010.03533},
  year={2020}
}
@article{frankle2020pruning,
  title={Pruning Neural Networks at Initialization: Why are We Missing the Mark?},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:2009.08576},
  year={2020}
}
@article{liu2021we,
  title={Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training},
  author={Liu, Shiwei and Yin, Lu and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  journal={arXiv preprint arXiv:2102.02887},
  year={2021}
}
@inproceedings{dai2018compressing,
  title={Compressing neural networks using the variational information bottleneck},
  author={Dai, Bin and Zhu, Chen and Guo, Baining and Wipf, David},
  booktitle={International Conference on Machine Learning},
  pages={1135--1144},
  year={2018},
  organization={PMLR}
}
@inproceedings{xiao2019autoprune,
  title={Autoprune: Automatic network pruning by regularizing auxiliary parameters},
  author={Xiao, Xia and Wang, Zigeng and Rajasekaran, Sanguthevar},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13681--13691},
  year={2019}
}
@inproceedings{kusupati2020soft,
  title={Soft Threshold Weight Reparameterization for Learnable Sparsity},
  author={Kusupati, Aditya and Ramanujan, Vivek and Somani, Raghav and Wortsman, Mitchell and Jain, Prateek and Kakade, Sham and Farhadi, Ali},
  booktitle={International Conference on Machine Learning},
  year={2020}
}
@inproceedings{srinivas2017training,
  title={Training sparse neural networks},
  author={Srinivas, Suraj and Subramanya, Akshayvarun and Venkatesh Babu, R},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={138--145},
  year={2017}
}
@inproceedings{prabhu2018deep,
  title={Deep expander networks: Efficient deep networks from graph theory},
  author={Prabhu, Ameya and Varma, Girish and Namboodiri, Anoop},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={20--35},
  year={2018}
}
@article{levin1990statistical,
  title={A statistical approach to learning and generalization in layered neural networks},
  author={Levin, Esther and Tishby, Naftali and Solla, Sara A},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1568--1574},
  year={1990},
  publisher={IEEE}
}
@inproceedings{kepner2019radix,
  title={Radix-net: Structured sparse matrices for deep neural networks},
  author={Kepner, Jeremy and Robinett, Ryan},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  pages={268--274},
  year={2019},
  organization={IEEE}
}
@article{lakshminarayanan2016simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={arXiv preprint arXiv:1612.01474},
  year={2016}
}
@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}
@inproceedings{goodfellow2014qualitatively,
  title={Qualitatively characterizing neural network optimization problems},
  author={Goodfellow, Ian J and Vinyals, Oriol and Saxe, Andrew M},
  booktitle={International Conference on Learning Representations},
  year={2015}
}
@inproceedings{safran2018spurious,
  title={Spurious local minima are common in two-layer relu neural networks},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={International Conference on Machine Learning},
  pages={4433--4441},
  year={2018},
  organization={PMLR}
}
@article{soudry2016no,
  title={No bad local minima: Data independent training error guarantees for multilayer neural networks},
  author={Soudry, Daniel and Carmon, Yair},
  journal={arXiv preprint arXiv:1605.08361},
  year={2016}
}
@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}
@article{brutzkus2017sgd,
  title={Sgd learns over-parameterized networks that provably generalize on linearly separable data},
  author={Brutzkus, Alon and Globerson, Amir and Malach, Eran and Shalev-Shwartz, Shai},
  journal={arXiv preprint arXiv:1710.10174},
  year={2017}
}
@inproceedings{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  booktitle={International Conference on Learning Representations},
  year={2017}
}
@inproceedings{zhang2019taming,
  title={Taming the noisy gradient: train deep neural networks with small batch sizes},
  author={Zhang, Yikai and Qu, Hui},
  booktitle={IJCAI},
  year={2019}
}
@inproceedings{
lee2018snip,
title={Snip: Single-shot network pruning based on connection sensitivity},
author={Namhoon Lee and Thalaiyasingam Ajanthan and Philip Torr},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1VZqjAcYX},
}
@inproceedings{
Lee2020A,
title={A Signal Propagation Perspective for Pruning Neural Networks at Initialization},
author={Namhoon Lee and Thalaiyasingam Ajanthan and Stephen Gould and Philip H. S. Torr},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJeTo2VFwH}
}

@inproceedings{
Wang2020Picking,
title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
author={Chaoqi Wang and Guodong Zhang and Roger Grosse},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkgsACVKPH}
}
@phdthesis{setphdthesis2017,
title = "Network computations in artificial intelligence",
author = "Decebal Constantin Mocanu",
year = "2017",
month = jun,
day = "29",
language = "English",
isbn = "978-90-386-4305-2",
school = "Technische Universiteit Eindhoven",
}

@article{onemillionneurons,
  author    = {Shiwei Liu and
               Decebal Constantin Mocanu and
               Amarsagar Reddy Ramapuram Matavalam and
               Yulong Pei and
               Mykola Pechenizkiy},
  title     = {Sparse evolutionary Deep Learning with over one million artificial
               neurons on commodity hardware},
  journal   = {Neural Computing and Applications},
  year      = {2020},
}

@inproceedings{ICML-2019-PetersonB0GR,
	author        = "Joshua C. Peterson and David Bourgin and Daniel Reichman 0001 and Thomas L. Griffiths and Stuart J. Russell",
	booktitle     = "{Proceedings of the 36th International Conference on Machine Learning}",
	pages         = "5133--5141",
	publisher     = "{PMLR}",
	title         = "{Cognitive model priors for predicting human decisions}",
	year          = 2019,
}
@inproceedings{
tanaka2020pruning,
title={Pruning neural networks without any data by iteratively conserving synaptic flow},
author={Tanaka, Hidenori and Kunin, Daniel and Yamins, Daniel LK and Ganguli, Surya},
year={2020},
booktitle={Advances in Neural Information Processing Systems 33 pre-proceedings}
}
@article{de2020progressive,
  title={Progressive skeletonization: Trimming more fat from a network at initialization},
  author={de Jorge, Pau and Sanyal, Amartya and Behl, Harkirat S and Torr, Philip HS and Rogez, Gregory and Dokania, Puneet K},
  journal={arXiv preprint arXiv:2006.09081},
  year={2020}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua V and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={arXiv preprint arXiv:1906.02530},
  year={2019}
}

@inproceedings{augustin2020adversarial,
  title={Adversarial robustness on in-and out-distribution improves explainability},
  author={Augustin, Maximilian and Meinke, Alexander and Hein, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={228--245},
  year={2020},
  organization={Springer}
}

@inproceedings{37648,
title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year	= {2011},
URL	= {http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf},
booktitle	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}

@article{mu2020compositional,
  title={Compositional explanations of neurons},
  author={Mu, Jesse and Andreas, Jacob},
  journal={arXiv preprint arXiv:2006.14032},
  year={2020}
}

@inproceedings{hein2019relu,
  title={Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem},
  author={Hein, Matthias and Andriushchenko, Maksym and Bitterwolf, Julian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={41--50},
  year={2019}
}

@article{Krizhevsky09,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, A. and Hinton, G.},
  journal={Master's thesis, Department of Computer Science, University of Toronto},
  year={2009},
  publisher={Citeseer}
}

@article{meinke2019towards,
  title={Towards neural networks that provably know when they don't know},
  author={Meinke, Alexander and Hein, Matthias},
  journal={arXiv preprint arXiv:1909.12180},
  year={2019}
}
@article{gebhart2021unified,
  title={A Unified Paths Perspective for Pruning at Initialization},
  author={Gebhart, Thomas and Saxena, Udit and Schrater, Paul},
  journal={arXiv preprint arXiv:2101.10552},
  year={2021}
}
@inproceedings{
chen2021gans,
title={{\{}GAN{\}}s Can Play Lottery Tickets Too},
author={Xuxi Chen and Zhenyu Zhang and Yongduo Sui and Tianlong Chen},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=1AoMhc_9jER}
}


@article{chen2020lottery2,
  title={The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models},
  author={Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Carbin, Michael and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2012.06908},
  year={2020}
}

@inproceedings{
chen2021long,
title={Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning},
author={Tianlong Chen and Zhenyu Zhang and Sijia Liu and Shiyu Chang and Zhangyang Wang},
booktitle={International Conference on Learning Representations},
year={2021}}
}

@inproceedings{frankle2018lottery,
  title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
  author={Frankle, Jonathan and Carbin, Michael},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@techreport{wu2017tiny,
  title={Tiny ImageNet Challenge},
  author={Wu, Jiayu and Zhang, Qixiang and Xu, Guoxi},
  Year={2017}
}

@article{frankle2019stabilizing,
  title={Stabilizing the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:1903.01611},
  year={2019}
}

@inproceedings{evci2020rigging,
  title={Rigging the lottery: Making all tickets winners},
  author={Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  booktitle={International Conference on Machine Learning},
  pages={2943--2952},
  year={2020},
  organization={PMLR}
}


@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@INPROCEEDINGS{7486599,
  author={S. {Liu} and W. {Deng}},
  booktitle={2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)}, 
  title={Very deep convolutional neural network based image classification using small training sample size}, 
  year={2015},
  volume={},
  number={},
  pages={730-734},
  doi={10.1109/ACPR.2015.7486599}
}

@inproceedings{
liu2018rethinking,
title={Rethinking the Value of Network Pruning},
author={Zhuang Liu and Mingjie Sun and Tinghui Zhou and Gao Huang and Trevor Darrell},
booktitle={7th International Conference on Learning Representations},
year={2019}
}


@inproceedings{
savarese2020winning,
title={Winning the Lottery with Continuous Sparsification},
author={Pedro Savarese and Hugo Silva and Michael Maire},
year={2020},
booktitle={Advances in Neural Information Processing Systems 33 pre-proceedings}
}


@inproceedings{yu2019playing,
    title={Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP},
    author={Haonan Yu and Sergey Edunov and Yuandong Tian and Ari S. Morcos},
    year={2020},
    booktitle = {8th International Conference on Learning Representations}
}

@inproceedings{renda2020comparing,
  title={Comparing rewinding and fine-tuning in neural network pruning},
  author={Renda, Alex and Frankle, Jonathan and Carbin, Michael},
  booktitle = {8th International Conference on Learning Representations},
  year={2020}
}

@article{mehta2019sparse,
  title={Sparse transfer learning via winning lottery tickets},
  author={Mehta, Rahul},
  journal={arXiv},
  volume={abs/1905.07785},
  year={2019}
}

@inproceedings{zhou2018nonvacuous,
title={Non-vacuous Generalization Bounds at the ImageNet Scale: a {PAC}-Bayesian Compression Approach},
author={Wenda Zhou and Victor Veitch and Morgane Austern and Ryan P. Adams and Peter Orbanz},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJgqqsAct7},
}

@inproceedings{morcos2019one,
  title={One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers},
  author={Morcos, Ari and Yu, Haonan and Paganini, Michela and Tian, Yuandong},
  booktitle={Advances in Neural Information Processing Systems 32},
  year={2019}
}

@inproceedings{arora2018stronger,
  title={Stronger generalization bounds for deep nets via a compression approach},
  author={Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle={International Conference on Machine Learning},
  pages={254--263},
  year={2018},
  organization={PMLR}
}

@inproceedings{desai2019evaluating,
  title={Evaluating Lottery Tickets Under Distributional Shifts},
  author={Desai, Shrey and Zhan, Hongyuan and Aly, Ahmed},
  booktitle = "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP",
  year={2019}
}

@inproceedings{kalibhat2020winning,
      title={Winning Lottery Tickets in Deep Generative Models}, 
      author={Neha Mukund Kalibhat and Yogesh Balaji and Soheil Feizi},
      year={2020},
      booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
}
@inproceedings{
toneva2018an,
title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJlxm30cKm},
}

@inproceedings{yao2020searching,
  title={Searching to exploit memorization effect in learning with noisy labels},
  author={Yao, Quanming and Yang, Hansi and Han, Bo and Niu, Gang and Kwok, James Tin-Yau},
  booktitle={International Conference on Machine Learning},
  pages={10789--10798},
  year={2020},
  organization={PMLR}
}

@inproceedings{
xia2021robust,
title={Robust early-learning: Hindering the memorization of noisy labels},
author={Xiaobo Xia and Tongliang Liu and Bo Han and Chen Gong and Nannan Wang and Zongyuan Ge and Yi Chang},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Eql5b1_hTE4}
}

@inproceedings{han2020sigua,
  title={Sigua: Forgetting may make learning with noisy labels more robust},
  author={Han, Bo and Niu, Gang and Yu, Xingrui and Yao, Quanming and Xu, Miao and Tsang, Ivor and Sugiyama, Masashi},
  booktitle={International Conference on Machine Learning},
  pages={4006--4016},
  year={2020},
  organization={PMLR}
}

@inproceedings{mirzasoleiman2020coresets,
  title={Coresets for data-efficient training of machine learning models},
  author={Mirzasoleiman, Baharan and Bilmes, Jeff and Leskovec, Jure},
  booktitle={International Conference on Machine Learning},
  pages={6950--6960},
  year={2020},
  organization={PMLR}
}

@article{wang2018dataset,
  title={Dataset Distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}

@article{hooker2020characterising,
  title={Characterising bias in compressed models},
  author={Hooker, Sara and Moorosi, Nyalleng and Clark, Gregory and Bengio, Samy and Denton, Emily},
  journal={arXiv preprint arXiv:2010.03058},
  year={2020}
}

@article{hooker2020compressed,
  title={What Do Compressed Deep Neural Networks Forget?},
  author={Hooker, Sara and Courville, Aaron and Clark, Gregory and Dauphin, Yann and Frome, Andrea},
  journal={arXiv preprint arXiv:1911.05248},
  year={2020}
}

@article{tsang2005core,
  title={Core vector machines: Fast SVM training on very large data sets},
  author={Tsang, Ivor W and Kwok, James T and Cheung, Pak-Ming},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={363--392},
  year={2005}
}

@article{har2007smaller,
  title={Smaller coresets for k-median and k-means clustering},
  author={Har-Peled, Sariel and Kushal, Akash},
  journal={Discrete \& Computational Geometry},
  volume={37},
  number={1},
  pages={3--19},
  year={2007},
  publisher={Springer}
}

@article{bachem2017practical,
  title={Practical coreset constructions for machine learning},
  author={Bachem, Olivier and Lucic, Mario and Krause, Andreas},
  journal={arXiv preprint arXiv:1703.06476},
  year={2017}
}

@article{sener2017active,
  title={Active learning for convolutional neural networks: A core-set approach},
  author={Sener, Ozan and Savarese, Silvio},
  journal={arXiv preprint arXiv:1708.00489},
  year={2017}
}

@article{arpit2017closer,
  title={A closer look at memorization in deep networks},
  author={Arpit, Devansh and Jastrzebski, Stanislaw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and others},
  journal={arXiv preprint arXiv:1706.05394},
  year={2017}
}

@inproceedings{zhao2015stochastic,
  title={Stochastic optimization with importance sampling for regularized loss minimization},
  author={Zhao, Peilin and Zhang, Tong},
  booktitle={international conference on machine learning},
  pages={1--9},
  year={2015}
}

@article{katharopoulos2018not,
  title={Not all samples are created equal: Deep learning with importance sampling},
  author={Katharopoulos, Angelos and Fleuret, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1803.00942},
  year={2018}
}

@inproceedings{he2017channel,
  title={Channel pruning for accelerating very deep neural networks},
  author={He, Yihui and Zhang, Xiangyu and Sun, Jian},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  year={2017}
}

@article{hendrycks2019natural,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  journal={arXiv preprint arXiv:1907.07174},
  year={2019}
}


@article{voulodimos2018deep,
  title={Deep learning for computer vision: A brief review},
  author={Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
  journal={Computational intelligence and neuroscience},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}

@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}

@inproceedings{malach2020proving,
  title={Proving the lottery ticket hypothesis: Pruning is all you need},
  author={Malach, Eran and Yehudai, Gilad and Shalev-Schwartz, Shai and Shamir, Ohad},
  booktitle={International Conference on Machine Learning},
  pages={6682--6691},
  year={2020},
  organization={PMLR}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@inproceedings{yang2017designing,
  title={Designing energy-efficient convolutional neural networks using energy-aware pruning},
  author={Yang, Tien-Ju and Chen, Yu-Hsin and Sze, Vivienne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5687--5695},
  year={2017}
}

@article{li2016pruning,
  title={Pruning filters for efficient convnets},
  author={Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  journal={arXiv preprint arXiv:1608.08710},
  year={2016}
}

@inproceedings{molchanov2017variational,
  title={Variational dropout sparsifies deep neural networks},
  author={Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
  booktitle={International Conference on Machine Learning},
  pages={2498--2507},
  year={2017},
  organization={PMLR}
}

@inproceedings{ramanujan2020s,
  title={What's Hidden in a Randomly Weighted Neural Network?},
  author={Ramanujan, Vivek and Wortsman, Mitchell and Kembhavi, Aniruddha and Farhadi, Ali and Rastegari, Mohammad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11893--11902},
  year={2020}
}

@article{zhou2019deconstructing,
  title={Deconstructing lottery tickets: Zeros, signs, and the supermask},
  author={Zhou, Hattie and Lan, Janice and Liu, Rosanne and Yosinski, Jason},
  journal={arXiv preprint arXiv:1905.01067},
  year={2019}
}

@article{settles2012active,
  title={Active learning},
  author={Settles, Burr},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={6},
  number={1},
  pages={1--114},
  year={2012},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{lewis1994sequential,
  title={A sequential algorithm for training text classifiers},
  author={Lewis, David D and Gale, William A},
  booktitle={SIGIR’94},
  pages={3--12},
  year={1994},
  organization={Springer}
}

@inproceedings{
Coleman2020Selection,
title={Selection via Proxy: Efficient Data Selection for Deep Learning},
author={Cody Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter Bailis and Percy Liang and Jure Leskovec and Matei Zaharia},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJg2b0VYDr}
}

@article{strauss2017ensemble,
  title={Ensemble methods as a defense to adversarial perturbations against deep neural networks},
  author={Strauss, Thilo and Hanselmann, Markus and Junginger, Andrej and Ulmer, Holger},
  journal={arXiv preprint arXiv:1709.03423},
  year={2017}
}

@article{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  publisher={University of Wisconsin-Madison Department of Computer Sciences}
}

@inproceedings{hauptmann2006extreme,
  title={Extreme video retrieval: joint maximization of human and computer performance},
  author={Hauptmann, Alexander G and Lin, Wei-Hao and Yan, Rong and Yang, Jun and Chen, Ming-Yu},
  booktitle={Proceedings of the 14th ACM international conference on Multimedia},
  pages={385--394},
  year={2006}
}

@article{tur2005combining,
  title={Combining active and semi-supervised learning for spoken language understanding},
  author={Tur, Gokhan and Hakkani-T{\"u}r, Dilek and Schapire, Robert E},
  journal={Speech Communication},
  volume={45},
  number={2},
  pages={171--186},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{yang2003automatically,
  title={Automatically labeling video data using multi-class active learning},
  author={Yang, Jie and others},
  booktitle={Proceedings Ninth IEEE international conference on computer vision},
  pages={516--523},
  year={2003},
  organization={IEEE}
}
@article{chen2020lottery,
  title={The lottery ticket hypothesis for pre-trained bert networks},
  author={Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Wang, Zhangyang and Carbin, Michael},
  journal={arXiv preprint arXiv:2007.12223},
  year={2020}
}
@inproceedings{moskovitch2007improving,
  title={Improving the detection of unknown computer worms activity using active learning},
  author={Moskovitch, Robert and Nissim, Nir and Stopel, Dima and Feher, Clint and Englert, Roman and Elovici, Yuval},
  booktitle={Annual Conference on Artificial Intelligence},
  pages={489--493},
  year={2007},
  organization={Springer}
}

@inproceedings{thompson1999active,
  title={Active learning for natural language parsing and information extraction},
  author={Thompson, Cynthia A and Califf, Mary Elaine and Mooney, Raymond J},
  booktitle={ICML},
  pages={406--414},
  year={1999},
  organization={Citeseer}
}
@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get m for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}

@article{frankle2019stabilizing,
  title={Stabilizing the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:1903.01611},
  year={2019}
}

@incollection{hessian,
title = {Optimal Brain Damage},
author = {LeCun, Yann and John S. Denker and Sara A. Solla},
booktitle = {Advances in Neural Information Processing Systems 2},
editor = {D. S. Touretzky},
pages = {598--605},
year = {1990},
publisher = {Morgan-Kaufmann},
url = {http://papers.nips.cc/paper/250-optimal-brain-damage.pdf}
}

@article{cai2020tiny,
  title={Tiny Transfer Learning: Towards Memory-Efficient On-Device Learning},
  author={Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  journal={arXiv preprint arXiv:2007.11622},
  year={2020}
}


@article{cosentino2019search,
  title={The Search for Sparse, Robust Neural Networks},
  author={Cosentino, Justin and Zaiter, Federico and Pei, Dan and Zhu, Jun},
  journal={arXiv preprint arXiv:1912.02386},
  year={2019}
}

@article{frankle2019linear,
  title={Linear mode connectivity and the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:1912.05671},
  year={2019}
}

@article{girish2020lottery,
  title={The Lottery Ticket Hypothesis for Object Recognition},
  author={Girish, Sharath and Maiya, Shishira R and Gupta, Kamal and Chen, Hao and Davis, Larry and Shrivastava, Abhinav},
  journal={arXiv preprint arXiv:2012.04643},
  year={2020}
}

@article{chen2020earlybert,
  title={EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets},
  author={Chen, Xiaohan and Cheng, Yu and Wang, Shuohang and Gan, Zhe and Wang, Zhangyang and Liu, Jingjing},
  journal={arXiv preprint arXiv:2101.00063},
  year={2020}
}

@article{hooker2019compressed,
  title={What Do Compressed Deep Neural Networks Forget?},
  author={Hooker, Sara and Courville, Aaron and Clark, Gregory and Dauphin, Yann and Frome, Andrea},
  journal={arXiv preprint arXiv:1911.05248},
  year={2019}
}

@inproceedings{
snip,
title={SNIP: Single-shot Network Pruning based on Connection Sensitivity},
author={Namhoon Lee and Thalaiyasingam Ajanthan and Philip Torr},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1VZqjAcYX},
}

@article{dettmers,
  title={Sparse networks from scratch: Faster training without losing performance},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1907.04840},
  year={2019}
}

@inproceedings{grasp,
title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
author={Chaoqi Wang and Guodong Zhang and Roger Grosse},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkgsACVKPH}
}


@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}

@inproceedings{he2018exemplar,
  title={Exemplar-Supported Generative Reproduction for Class Incremental Learning.},
  author={He, Chen and Wang, Ruiping and Shan, Shiguang and Chen, Xilin},
  booktitle={British Machine Vision Conference},
  year={2018}
}

@inproceedings{castro2018end,
  title={End-to-end incremental learning},
  author={Castro, Francisco M and Mar{\'\i}n-Jim{\'e}nez, Manuel J and Guil, Nicol{\'a}s and Schmid, Cordelia and Alahari, Karteek},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={233--248},
  year={2018}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{tishby2015deep,
  title={Deep learning and the information bottleneck principle},
  author={Tishby, Naftali and Zaslavsky, Noga},
  booktitle={2015 IEEE Information Theory Workshop (ITW)},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@inproceedings{javed2018revisiting,
  title={Revisiting distillation and incremental classifier learning},
  author={Javed, Khurram and Shafait, Faisal},
  booktitle={Asian Conference on Computer Vision},
  pages={3--17},
  year={2018},
  organization={Springer}
}


@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

@InProceedings{Belouadah_2019_ICCV,
author = {Belouadah, Eden and Popescu, Adrian},
title = {IL2M: Class Incremental Learning With Dual Memory},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
} 

@inproceedings{
Frankle2020The,
title={The Early Phase of Neural Network Training},
author={Jonathan Frankle and David J. Schwab and Ari S. Morcos},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hkl1iRNFwS}
}


@inproceedings{zhang2020class,
  title={Class-incremental learning via deep model consolidation},
  author={Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and Kuo, C-C Jay},
  booktitle={The IEEE Winter Conference on Applications of Computer Vision},
  pages={1131--1140},
  year={2020}
}

@article{torralba200880,
  title={80 million tiny images: A large data set for nonparametric object and scene recognition},
  author={Torralba, Antonio and Fergus, Rob and Freeman, William T},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={30},
  number={11},
  pages={1958--1970},
  year={2008},
  publisher={IEEE}
}

@article{zhang2019balance,
  title={To Balance or Not to Balance: A Simple-yet-Effective Approach for Learning with Long-Tailed Distributions},
  author={Zhang, Junjie and Liu, Lingqiao and Wang, Peng and Shen, Chunhua},
  journal={arXiv},
  pages={arXiv--1912},
  year={2019}
}



@InProceedings{Castro_2018_ECCV,
author = {Castro, Francisco M. and Marin-Jimenez, Manuel J. and Guil, Nicolas and Schmid, Cordelia and Alahari, Karteek},
title = {End-to-End Incremental Learning},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}


@ARTICLE{nem,
  author={T. {Mensink} and J. {Verbeek} and F. {Perronnin} and G. {Csurka}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Distance-Based Image Classification: Generalizing to New Classes at Near-Zero Cost}, 
  year={2013},
  volume={35},
  number={11},
  pages={2624-2637}
}


  
@article{gumbel, title={Statistical Theory of Extreme Values and Some Practical Applications.}, author={Emit J. Gumbel}, volume={58}, DOI={10.1017/S0368393100099958}, number={527}, journal={The Journal of the Royal Aeronautical Society}, publisher={Cambridge University Press}, year={1954}, pages={792–793}}
  
@article{maddison2014sampling,
  title={A* sampling},
  author={Maddison, Chris J and Tarlow, Daniel and Minka, Tom},
  journal={arXiv preprint arXiv:1411.0030},
  year={2014}
}  

@ARTICLE{8686088,
  author={Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel and Sze, Vivienne},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, 
  title={Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices}, 
  year={2019},
  volume={9},
  number={2},
  pages={292-308},
  doi={10.1109/JETCAS.2019.2910232}}


@INPROCEEDINGS{7551397,
  author={Han, Song and Liu, Xingyu and Mao, Huizi and Pu, Jing and Pedram, Ardavan and Horowitz, Mark A. and Dally, William J.},
  booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)}, 
  title={EIE: Efficient Inference Engine on Compressed Deep Neural Network}, 
  year={2016},
  volume={},
  number={},
  pages={243-254},
  doi={10.1109/ISCA.2016.30}}


@article{ashbyexploiting,
  title={Exploiting Unstructured Sparsity on Next-Generation Datacenter Hardware},
  author={Ashby, Mike and Baaij, Christiaan and Baldwin, Peter and Bastiaan, Martijn and Bunting, Oliver and Cairncross, Aiken and Chalmers, Christopher and Corrigan, Liz and Davis, Sam and van Doorn, Nathan and others},
  journal={None},
  url={https://myrtle.ai/wp-content/uploads/2019/06/IEEEformatMyrtle.ai_.21.06.19_b.pdf},
  year={2019}
}

@article{liu2018memory,
  title={Memory-efficient deep learning on a spinnaker 2 prototype},
  author={Liu, Chen and Bellec, Guillaume and Vogginger, Bernhard and Kappel, David and Partzsch, Johannes and Neum{\"a}rker, Felix and H{\"o}ppner, Sebastian and Maass, Wolfgang and Furber, Steve B and Legenstein, Robert and others},
  journal={Frontiers in neuroscience},
  volume={12},
  pages={840},
  year={2018},
  publisher={Frontiers}
}

@INPROCEEDINGS{8465793,
  author={Wang, Peiqi and Ji, Yu and Hong, Chi and Lyu, Yongqiang and Wang, Dongsheng and Xie, Yuan},
  booktitle={2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)}, 
  title={SNrram: An Efficient Sparse Neural Network Computation Architecture Based on Resistive Random-Access Memory}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/DAC.2018.8465793}}


@article{1905.07785,
  title={Winning the Lottery with Continuous Sparsification},
  author={Savarese, Pedro and Silva, Hugo and Maire, Michael},
  journal={arXiv preprint arXiv:1912.04427},
  year={2019}
}

@article{bartoldson2019generalization,
  title={The generalization-stability tradeoff in neural network pruning},
  author={Bartoldson, Brian R and Morcos, Ari S and Barbu, Adrian and Erlebacher, Gordon},
  journal={arXiv preprint arXiv:1906.03728},
  year={2019}
}

@misc{michel2019sixteen,
      title={Are Sixteen Heads Really Better than One?}, 
      author={Paul Michel and Omer Levy and Graham Neubig},
      year={2019},
      eprint={1905.10650},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@incollection{magnitude,
title = {Learning both Weights and Connections for Efficient Neural Network},
author = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {1135--1143},
year = {2015},
publisher = {Curran Associates, Inc.}
}


@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@inproceedings{schmidt2018adversarially,
  title={Adversarially robust generalization requires more data},
  author={Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{rony2019decoupling,
  title={Decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses},
  author={Rony, J{\'e}r{\^o}me and Hafemann, Luiz G and Oliveira, Luiz S and Ayed, Ismail Ben and Sabourin, Robert and Granger, Eric},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4322--4330},
  year={2019}
}

@article{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric P and Ghaoui, Laurent El and Jordan, Michael I},
  journal={arXiv preprint arXiv:1901.08573},
  year={2019}
}

@inproceedings{
    ding2020mma,
    title={{MMA} Training: Direct Input Space Margin Maximization through Adversarial Training},
    author={Gavin Weiguang Ding and Yash Sharma and Kry Yik Chau Lui and Ruitong Huang},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=HkeryxBtPB}
}

@article{tsipras2018robustness,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  journal={arXiv preprint arXiv:1805.12152},
  year={2018}
}

@InProceedings{pmlr-v97-hendrycks19a,
  title = 	 {Using Pre-Training Can Improve Model Robustness and Uncertainty},
  author = 	 {Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
  month = 	 {09--15 Jun},
}

@article{shafahi2019adversarially,
  title={Adversarially robust transfer learning},
  author={Shafahi, Ali and Saadatpanah, Parsa and Zhu, Chen and Ghiasi, Amin and Studer, Christoph and Jacobs, David and Goldstein, Tom},
  journal={arXiv preprint arXiv:1905.08232},
  year={2019}
}

@article{goldblum2019adversarially,
  title={Adversarially robust distillation},
  author={Goldblum, Micah and Fowl, Liam and Feizi, Soheil and Goldstein, Tom},
  journal={arXiv preprint arXiv:1905.09747},
  year={2019}
}

@misc{chan2019thinks,
    title={What it Thinks is Important is Important: Robustness Transfers through Input Gradients},
    author={Alvin Chan and Yi Tay and Yew-Soon Ong},
    year={2019},
    eprint={1912.05699},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{wang2017growing,
  title={Growing a brain: Fine-tuning by increasing model capacity},
  author={Wang, Yu-Xiong and Ramanan, Deva and Hebert, Martial},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2471--2480},
  year={2017}
}

@article{rosenfeld2018incremental,
  title={Incremental learning through deep adaptation},
  author={Rosenfeld, Amir and Tsotsos, John K},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2018},
  publisher={IEEE}
}

@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

@inproceedings{aljundi2017expert,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3366--3375},
  year={2017}
}

@inproceedings{rebuffi2018efficient,
  title={Efficient parametrization of multi-domain deep neural networks},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8119--8127},
  year={2018}
}

@inproceedings{mallya2018piggyback,
  title={Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author={Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={67--82},
  year={2018}
}

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}

@inproceedings{belouadah2018deesil,
  title={DeeSIL: Deep-Shallow Incremental Learning.},
  author={Belouadah, Eden and Popescu, Adrian},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={0--0},
  year={2018}
}

@article{kemker2017fearnet,
  title={Fearnet: Brain-inspired model for incremental learning},
  author={Kemker, Ronald and Kanan, Christopher},
  journal={arXiv preprint arXiv:1711.10563},
  year={2017}
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2661--2671},
  year={2019}
}

@inproceedings{sharif2014cnn,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={806--813},
  year={2014}
}


@article{buda2018systematic,
  title={A systematic study of the class imbalance problem in convolutional neural networks},
  author={Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A},
  journal={Neural Networks},
  volume={106},
  pages={249--259},
  year={2018},
  publisher={Elsevier}
}

@article{he2009learning,
  title={Learning from imbalanced data},
  author={He, Haibo and Garcia, Edwardo A},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={21},
  number={9},
  pages={1263--1284},
  year={2009},
  publisher={Ieee}
}

@inproceedings{chu2016best,
  title={Best practices for fine-tuning visual classifiers to new domains},
  author={Chu, Brian and Madhavan, Vashisht and Beijbom, Oscar and Hoffman, Judy and Darrell, Trevor},
  booktitle={European conference on computer vision},
  pages={435--442},
  year={2016},
  organization={Springer}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{golkar2019continual,
  title={Continual learning via neural pruning},
  author={Golkar, Siavash and Kagan, Michael and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1903.04476},
  year={2019}
}

@inproceedings{belouadah2020scail,
  title={ScaIL: Classifier Weights Scaling for Class Incremental Learning},
  author={Belouadah, Eden and Popescu, Adrian},
  booktitle={The IEEE Winter Conference on Applications of Computer Vision},
  pages={1266--1275},
  year={2020}
}

@article{zhang2019class,
  title={Class-incremental learning via deep model consolidation},
  author={Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and Kuo, C-C Jay},
  journal={arXiv preprint arXiv:1903.07864},
  year={2019}
}

@article{goodfellow2013empirical,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}



@inproceedings{papernot2016distillation,
  title={Distillation as a defense to adversarial perturbations against deep neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={2016 IEEE Symposium on Security and Privacy (SP)},
  pages={582--597},
  year={2016},
  organization={IEEE}
}

@article{carlini2016defensive,
  title={Defensive distillation is not robust to adversarial examples},
  author={Carlini, Nicholas and Wagner, David},
  journal={arXiv preprint arXiv:1607.04311},
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={IEEE}
}

@article{chawla2002smote,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  pages={321--357},
  year={2002}
}

@article{haixiang2017learning,
  title={Learning from class-imbalanced data: Review of methods and applications},
  author={Haixiang, Guo and Yijing, Li and Shang, Jennifer and Mingyun, Gu and Yuanyue, Huang and Bing, Gong},
  journal={Expert Systems with Applications},
  volume={73},
  pages={220--239},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{tahir2009multiple,
  title={A multiple expert approach to the class imbalance problem using inverse random under sampling},
  author={Tahir, Muhammad Atif and Kittler, Josef and Mikolajczyk, Krystian and Yan, Fei},
  booktitle={International workshop on multiple classifier systems},
  pages={82--91},
  year={2009},
  organization={Springer}
}

@article{huh2016makes,
  title={What makes ImageNet good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}

@article{bengio2006greedy,
  title={Greedy layer-wise training of deep networks},
  author={Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
  journal={Advances in neural information processing systems},
  volume={19},
  pages={153--160},
  year={2006}
}

@inproceedings{wang2019dynamic,
  title={Dynamic curriculum learning for imbalanced data classification},
  author={Wang, Yiru and Gan, Weihao and Yang, Jie and Wu, Wei and Yan, Junjie},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={5017--5026},
  year={2019}
}

@article{kurakin2016adversarial,
  title={Adversarial machine learning at scale},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1611.01236},
  year={2016}
}

@article{zhai2019adversarially,
  title={Adversarially robust generalization just requires more unlabeled data},
  author={Zhai, Runtian and Cai, Tianle and He, Di and Dan, Chen and He, Kun and Hopcroft, John and Wang, Liwei},
  journal={arXiv preprint arXiv:1906.00555},
  year={2019}
}

@article{frankle2019lottery,
  title={The lottery ticket hypothesis at scale},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:1903.01611},
  year={2019}
}

@inproceedings{hassibi1993second,
  title={Second order derivatives for network pruning: Optimal brain surgeon},
  author={Hassibi, Babak and Stork, David G},
  booktitle={Advances in neural information processing systems},
  pages={164--171},
  year={1993}
}

@article{nowlan1992simplifying,
  title={Simplifying neural networks by soft weight-sharing},
  author={Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={4},
  number={4},
  pages={473--493},
  year={1992},
  publisher={MIT Press}
}

@inproceedings{weigend1991generalization,
  title={Generalization by weight-elimination with application to forecasting},
  author={Weigend, Andreas S and Rumelhart, David E and Huberman, Bernardo A},
  booktitle={Advances in neural information processing systems},
  pages={875--882},
  year={1991}
}

@inproceedings{mozer1989skeletonization,
  title={Skeletonization: A technique for trimming the fat from a network via relevance assessment},
  author={Mozer, Michael C and Smolensky, Paul},
  booktitle={Advances in neural information processing systems},
  pages={107--115},
  year={1989}
}

@inproceedings{zhou2016less,
  title={Less is more: Towards compact cnns},
  author={Zhou, Hao and Alvarez, Jose M and Porikli, Fatih},
  booktitle={European Conference on Computer Vision},
  pages={662--677},
  year={2016},
  organization={Springer}
}


@article{han2020survey,
  title={A survey on visual transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={arXiv preprint arXiv:2012.12556},
  year={2020}
}


@article{guo2021cmt,
  title={CMT: Convolutional Neural Networks Meet Vision Transformers},
  author={Guo, Jianyuan and Han, Kai and Wu, Han and Xu, Chang and Tang, Yehui and Xu, Chunjing and Wang, Yunhe},
  journal={arXiv preprint arXiv:2107.06263},
  year={2021}
}

@article{tang2021patch,
  title={Patch Slimming for Efficient Vision Transformers},
  author={Tang, Yehui and Han, Kai and Wang, Yunhe and Xu, Chang and Guo, Jianyuan and Xu, Chao and Tao, Dacheng},
  journal={arXiv preprint arXiv:2106.02852},
  year={2021}
}


@inproceedings{liu2017learning,
  title={Learning efficient convolutional networks through network slimming},
  author={Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2736--2744},
  year={2017}
}

@article{thrun1995lifelong,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  journal={Robotics and autonomous systems},
  volume={15},
  number={1-2},
  pages={25--46},
  year={1995},
  publisher={Elsevier}
}

@ARTICLE{7296710,  author={G. {Ditzler} and M. {Roveri} and C. {Alippi} and R. {Polikar}},  journal={IEEE Computational Intelligence Magazine},   title={Learning in Nonstationary Environments: A Survey},   year={2015},  volume={10},  number={4},  pages={12-25},}

@incollection{grossberg1982does,
  title={How does a brain build a cognitive code?},
  author={Grossberg, Stephen},
  booktitle={Studies of mind and brain},
  pages={1--52},
  year={1982},
  publisher={Springer}
}

@article{grossberg2013adaptive,
  title={Adaptive Resonance Theory: How a brain learns to consciously attend, learn, and recognize a changing world},
  author={Grossberg, Stephen},
  journal={Neural Networks},
  volume={37},
  pages={1--47},
  year={2013},
  publisher={Elsevier}
}

@article{mermillod2013stability,
  title={The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects},
  author={Mermillod, Martial and Bugaiska, Aur{\'e}lia and Bonin, Patrick},
  journal={Frontiers in psychology},
  volume={4},
  pages={504},
  year={2013},
  publisher={Frontiers}
}

@misc{pan2021iared2,
      title={IA-RED$^2$: Interpretability-Aware Redundancy Reduction for Vision Transformers}, 
      author={Bowen Pan and Yifan Jiang and Rameswar Panda and Zhangyang Wang and Rogerio Feris and Aude Oliva},
      year={2021},
      eprint={2106.12620},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{elsen2020fast,
  title={Fast sparse convnets},
  author={Elsen, Erich and Dukhan, Marat and Gale, Trevor and Simonyan, Karen},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14629--14638},
  year={2020}
}

@inproceedings{
Cordonnier2020On,
title={On the Relationship between Self-Attention and Convolutional Layers},
author={Jean-Baptiste Cordonnier and Andreas Loukas and Martin Jaggi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJlnC1rKPB}
}

@inproceedings{lym2019prunetrain,
  title={PruneTrain: fast neural network training by dynamic sparse model reconfiguration},
  author={Lym, Sangkug and Choukse, Esha and Zangeneh, Siavash and Wen, Wei and Sanghavi, Sujay and Erez, Mattan},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--13},
  year={2019}
}

@misc{
yin2020the,
title={The Sooner The Better: Investigating Structure of Early Winning Lottery Tickets},
author={Shihui Yin and Kyu-Hyoun Kim and Jinwook Oh and Naigang Wang and Mauricio Serrano and Jae-Sun Seo and Jungwook Choi},
year={2020},
url={https://openreview.net/forum?id=BJlNs0VYPB}
}

@inproceedings{
You2020Drawing,
title={Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks},
author={Haoran You and Chaojian Li and Pengfei Xu and Yonggan Fu and Yue Wang and Xiaohan Chen and Richard G. Baraniuk and Zhangyang Wang and Yingyan Lin},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJxsrgStvr}
}

@article{prasanna2020bert,
  title={When BERT Plays the Lottery, All Tickets Are Winning},
  author={Prasanna, Sai and Rogers, Anna and Rumshisky, Anna},
  journal={arXiv preprint arXiv:2005.00561},
  year={2020}
}

@inproceedings{girshick2014rich,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}

@inproceedings{he2019rethinking,
  title={Rethinking imagenet pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4918--4927},
  year={2019}
}

@inproceedings{pathak2016context,
  title={Context encoders: Feature learning by inpainting},
  author={Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2536--2544},
  year={2016}
}

@inproceedings{vincent2008extracting,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008}
}

@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={European conference on computer vision},
  pages={649--666},
  year={2016},
  organization={Springer}
}

@inproceedings{zhang2017split,
  title={Split-brain autoencoders: Unsupervised learning by cross-channel prediction},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1058--1067},
  year={2017}
}

@inproceedings{doersch2015unsupervised,
  title={Unsupervised visual representation learning by context prediction},
  author={Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1422--1430},
  year={2015}
}

@inproceedings{dosovitskiy2014discriminative,
  title={Discriminative unsupervised feature learning with convolutional neural networks},
  author={Dosovitskiy, Alexey and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
  booktitle={Advances in neural information processing systems},
  pages={766--774},
  year={2014}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European Conference on Computer Vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@inproceedings{pathak2017learning,
  title={Learning features by watching objects move},
  author={Pathak, Deepak and Girshick, Ross and Doll{\'a}r, Piotr and Darrell, Trevor and Hariharan, Bharath},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2701--2710},
  year={2017}
}

@inproceedings{caron2018deep,
  title={Deep clustering for unsupervised learning of visual features},
  author={Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={132--149},
  year={2018}
}

@inproceedings{caron2019unsupervised,
  title={Unsupervised pre-training of image features on non-curated data},
  author={Caron, Mathilde and Bojanowski, Piotr and Mairal, Julien and Joulin, Armand},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2959--2968},
  year={2019}
}

@inproceedings{chen2020adversarial,
  title={Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning},
  author={Chen, Tianlong and Liu, Sijia and Chang, Shiyu and Cheng, Yu and Amini, Lisa and Wang, Zhangyang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={699--708},
  year={2020}
}

@article{jiang2020robust,
  title={Robust Pre-Training by Adversarial Contrastive Learning},
  author={Jiang, Ziyu and Chen, Tianlong and Chen, Ting and Wang, Zhangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{you2020graph,
  title={Graph Contrastive Learning with Augmentations},
  author={You, Yuning and Chen, Tianlong and Sui, Yongduo and Chen, Ting and Wang, Zhangyang and Shen, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{bachman2019learning,
  title={Learning representations by maximizing mutual information across views},
  author={Bachman, Philip and Hjelm, R Devon and Buchwalter, William},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15535--15545},
  year={2019}
}

@article{henaff2019data,
  title={Data-efficient image recognition with contrastive predictive coding},
  author={H{\'e}naff, Olivier J and Srinivas, Aravind and De Fauw, Jeffrey and Razavi, Ali and Doersch, Carl and Eslami, SM and Oord, Aaron van den},
  journal={arXiv preprint arXiv:1905.09272},
  year={2019}
}

@inproceedings{hjelm2018learning,
  title={Learning deep representations by mutual information estimation and maximization},
  author={Hjelm, R Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{tian2019contrastive,
  title={Contrastive multiview coding},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  journal={arXiv preprint arXiv:1906.05849},
  year={2019}
}

@inproceedings{wu2018unsupervised,
  title={Unsupervised feature learning via non-parametric instance discrimination},
  author={Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X and Lin, Dahua},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3733--3742},
  year={2018}
}

@inproceedings{zhuang2019local,
  title={Local aggregation for unsupervised learning of visual embeddings},
  author={Zhuang, Chengxu and Zhai, Alex Lin and Yamins, Daniel},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={6002--6012},
  year={2019}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@inproceedings{hadsell2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
  volume={2},
  pages={1735--1742},
  year={2006},
  organization={IEEE}
}

@inproceedings{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in neural information processing systems},
  pages={91--99},
  year={2015}
}

@article{tian2020rethinking,
  title={Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need?},
  author={Tian, Yonglong and Wang, Yue and Krishnan, Dilip and Tenenbaum, Joshua B and Isola, Phillip},
  journal={arXiv preprint arXiv:2003.11539},
  year={2020}
}

@inproceedings{chen2018encoder,
  title={Encoder-decoder with atrous separable convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={801--818},
  year={2018}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@article{peng2017visda,
  title={Visda: The visual domain adaptation challenge},
  author={Peng, Xingchao and Usman, Ben and Kaushik, Neela and Hoffman, Judy and Wang, Dequan and Saenko, Kate},
  journal={arXiv preprint arXiv:1710.06924},
  year={2017}
}

@article{everingham2015pascal,
  title={The pascal visual object classes challenge: A retrospective},
  author={Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={111},
  number={1},
  pages={98--136},
  year={2015},
  publisher={Springer}
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@inproceedings{lee2019drop,
  title={Drop to adapt: Learning discriminative features for unsupervised domain adaptation},
  author={Lee, Seungmin and Kim, Dongwan and Kim, Namil and Jeong, Seong-Gyun},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={91--100},
  year={2019}
}

@misc{chen2020intriguing,
      title={Intriguing Properties of Contrastive Losses}, 
      author={Ting Chen and Lala Li},
      year={2020},
      eprint={2011.02803},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{li2020train,
  title={Train large, then compress: Rethinking model size for efficient training and inference of transformers},
  author={Li, Zhuohan and Wallace, Eric and Shen, Sheng and Lin, Kevin and Keutzer, Kurt and Klein, Dan and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2002.11794},
  year={2020}
}

@article{liu2019towards,
  title={Towards Understanding the Transferability of Deep Representations},
  author={Liu, Hong and Long, Mingsheng and Wang, Jianmin and Jordan, Michael I},
  journal={arXiv preprint arXiv:1909.12031},
  year={2019}
}

@article{mohseni2020self,
  title={Self-Supervised Learning for Generalizable Out-of-Distribution Detection},
  author={Mohseni, Sina and Pitale, Mandar and Yadawa, JBS and Wang, Zhangyang},
  journal={AAAI},
  year={2020}
}

@inproceedings{donahue2014decaf,
  title={Decaf: A deep convolutional activation feature for generic visual recognition},
  author={Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={647--655},
  year={2014}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{oquab2014learning,
  title={Learning and transferring mid-level image representations using convolutional neural networks},
  author={Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1717--1724},
  year={2014}
}

@ARTICLE{8364435,
  author={Lane, Nicholas D. and Warden, Pete},
  journal={Computer}, 
  title={The Deep (Learning) Transformation of Mobile and Embedded Computing}, 
  year={2018},
  volume={51},
  number={5},
  pages={12-16},
  doi={10.1109/MC.2018.2381129}}


@INPROCEEDINGS{8100027,
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Scene Parsing through ADE20K Dataset}, 
  year={2017},
  volume={},
  number={},
  pages={5122-5130},
  doi={10.1109/CVPR.2017.544}}


@article{plumb2020regularizing,
  title={Regularizing black-box models for improved interpretability},
  author={Plumb, Gregory and Al-Shedivat, Maruan and Cabrera, {\'A}ngel Alexander and Perer, Adam and Xing, Eric and Talwalkar, Ameet},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{hendrycks2020many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  journal={arXiv preprint arXiv:2006.16241},
  year={2020}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International Conference on Machine Learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{jiang2012,
  title={Calibrating predictive model estimates to support personalized medicine},
  author={Jiang, Xiaoqian and Osl, Melanie and Kim, Jihoon and OhnoMachado, Lucila},
  journal={Journal of the American Medical Informatics Association},
  year={2012}
}

@InProceedings{candela2006evaluating,
author="Qui{\~{n}}onero-Candela, Joaquin
and Rasmussen, Carl Edward
and Sinz, Fabian
and Bousquet, Olivier
and Sch{\"o}lkopf, Bernhard",
editor="Qui{\~{n}}onero-Candela, Joaquin
and Dagan, Ido
and Magnini, Bernardo
and d'Alch{\'e}-Buc, Florence",
title="Evaluating Predictive Uncertainty Challenge",
booktitle="Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--27"
}

@article{10.2307/2987588,
 ISSN = {00390526, 14679884},
 URL = {http://www.jstor.org/stable/2987588},
 author = {Morris H. DeGroot and Stephen E. Fienberg},
 journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
 number = {1/2},
 pages = {12--22},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {The Comparison and Evaluation of Forecasters},
 volume = {32},
 year = {1983}
}

@article{venkatesh2020calibrate,
  title={Calibrate and prune: Improving reliability of lottery tickets through prediction calibration},
  author={Venkatesh, Bindya and Thiagarajan, Jayaraman J and Thopalli, Kowshik and Sattigeri, Prasanna},
  journal={arXiv preprint arXiv:2002.03875},
  year={2020}
}

@article{article,
author = {Pakdaman Naeini, Mahdi and Cooper, Gregory and Hauskrecht, Milos},
year = {2015},
month = {04},
pages = {2901-2907},
title = {Obtaining Well Calibrated Probabilities Using Bayesian Binning},
volume = {2015},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence}
}

@book{statisticallearning,
  added-at = {2008-05-16T16:17:42.000+0200},
  address = {New York, NY, USA},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  interhash = {d585aea274f2b9b228fc1629bc273644},
  intrahash = {f58afc5c9793fcc8ad8389824e57984c},
  keywords = {ml statistics},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  timestamp = {2008-05-16T16:17:43.000+0200},
  title = {The Elements of Statistical Learning},
  year = 2001
}

@article{lecun2015deeplearning,
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://www.bibsonomy.org/bibtex/22d2dbe7ffc1f95b46d0fc31b9b2706d6/muehlburger},
  description = {Deep Learning first paper.},
  doi = {10.1038/nature14539},
  interhash = {6e8511bc64ba3e808ebf330db96a4ea5},
  intrahash = {2d2dbe7ffc1f95b46d0fc31b9b2706d6},
  journal = {Nature},
  keywords = {anomaly-detection deep-learning machine-learning},
  number = 7553,
  pages = {436--444},
  timestamp = {2019-11-21T08:33:04.000+0100},
  title = {Deep Learning},
  url = {https://doi.org/10.1038/nature14539},
  volume = 521,
  year = 2015
}

@inproceedings{
hendrycks2018benchmarking,
title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
author={Dan Hendrycks and Thomas Dietterich},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HJz6tiCqYm},
}

@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={427--436},
  year={2015}
}

@article{hendrycks2016baseline,
  title={A baseline for detecting misclassified and out-of-distribution examples in neural networks},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1610.02136},
  year={2016}
}

@article{jiang2019fantastic,
  title={Fantastic generalization measures and where to find them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press}
}


@article{hendrycks2018deep,
  title={Deep anomaly detection with outlier exposure},
  author={Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1812.04606},
  year={2018}
}

@inproceedings{
chen2021robust,
title={Robust Overfitting may be mitigated by properly learned smoothening},
author={Tianlong Chen and Zhenyu Zhang and Sijia Liu and Shiyu Chang and Zhangyang Wang},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=qZzy5urZw9}
}

@article{wu2020revisiting,
  title={Revisiting Loss Landscape for Adversarial Robustness},
  author={Wu, Dongxian and Wang, Yisen and Xia, Shu-tao},
  journal={arXiv preprint arXiv:2004.05884},
  year={2020}
}

@inproceedings{moosavi2019robustness,
  title={Robustness via curvature regularization, and vice versa},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Uesato, Jonathan and Frossard, Pascal},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9078--9086},
  year={2019}
}

@inproceedings{bau2017network,
  title={Network dissection: Quantifying interpretability of deep visual representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6541--6549},
  year={2017}
}

@inproceedings{ghorbani2019interpretation,
  title={Interpretation of neural networks is fragile},
  author={Ghorbani, Amirata and Abid, Abubakar and Zou, James},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3681--3688},
  year={2019}
}

@article{alvarez2018towards,
  title={Towards robust interpretability with self-explaining neural networks},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1806.07538},
  year={2018}
}

@article{plumb2018model,
  title={Model agnostic supervised local explanations},
  author={Plumb, Gregory and Molitor, Denali and Talwalkar, Ameet},
  journal={arXiv preprint arXiv:1807.02910},
  year={2018}
}

@misc{
kuhn2021robustness,
title={Robustness to Pruning Predicts Generalization in Deep Neural Networks},
author={Lorenz Kuhn and Clare Lyle and Aidan Gomez and Jonas Rothfuss and Yarin Gal},
year={2021},
url={https://openreview.net/forum?id=1P2KAvsE59b}
}


@inproceedings{yao2020pyhessian,
  title={Pyhessian: Neural networks through the lens of the hessian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)},
  pages={581--590},
  year={2020},
  organization={IEEE}
}

@inproceedings{pac, author = {McAllester, David A.}, title = {PAC-Bayesian Model Averaging}, year = {1999}, isbn = {1581131674}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/307400.307435}, doi = {10.1145/307400.307435}, booktitle = {Proceedings of the Twelfth Annual Conference on Computational Learning Theory}, pages = {164–170}, numpages = {7}, location = {Santa Cruz, California, USA}, series = {COLT '99} }


@article{ganesh2020compressing,
  title={Compressing large-scale transformer-based models: A case study on bert},
  author={Ganesh, Prakhar and Chen, Yao and Lou, Xin and Khan, Mohammad Ali and Yang, Yin and Chen, Deming and Winslett, Marianne and Sajjad, Hassan and Nakov, Preslav},
  journal={arXiv preprint arXiv:2002.11985},
  year={2020}
}

@article{guo2020reweighted,
  title={Reweighted proximal pruning for large-scale language representation},
  author={Guo, Fu-Ming and Liu, Sijia and Mungall, Finlay S and Lin, Xue and Wang, Yanzhi},
  journal={arXiv preprint arXiv:1909.12486},
  year={2019}
}

@inproceedings{
Fan2020Reducing,
title={Reducing Transformer Depth on Demand with Structured Dropout},
author={Angela Fan and Edouard Grave and Armand Joulin},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SylO2yStDr}
}


@article{mccarley2019structured,
    title={Structured Pruning of a BERT-based Question Answering Model},
    author={J. S. McCarley and Rishav Chakravarti and Avirup Sil},
    year={2019},
    journal={arXiv preprint arXiv:1910.06360}
}
