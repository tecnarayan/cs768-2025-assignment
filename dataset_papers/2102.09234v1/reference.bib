
@InProceedings{ADIANA,
  author    = {Zhize Li and Dmitry Kovalev and Xun Qian and Peter Richt\'{a}rik},
  booktitle = {International Conference on Machine Learing},
  title     = {Acceleration for Compressed Gradient Descent in Distributed and Federated Optimization},
  year      = {2020},
}


@InProceedings{FEDLEARN,
  author    = {Kone\v{c}n\'{y}, Jakub and McMahan, H. Brendan and Yu, Felix and Richt\'{a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  booktitle = {NIPS Private Multi-Party Machine Learning Workshop},
  title     = {Federated learning: strategies for improving communication efficiency},
  year      = {2016},
  groups    = {richtap:1},
}


@InProceedings{FL2017-AISTATS,
  author    = {McMahan, H Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Ag\"{u}era y Arcas, Blaise},
  title     = {Communication-efficient learning of deep networks from decentralized data},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year      = {2017},
}


@ARTICLE{Zadeh1961,
  author={L. A. {Zadeh}},
  journal={Proceedings of the IRE}, 
  title={Time-Varying Networks, I}, 
  year={1961},
  volume={49},
  number={10},
  pages={1488-1503},
}
  
@Article{Kolar2010,
  author  = {Kolar, Mladen and Song, Le and Ahmed, Amr and Xing, Eric P},
  journal = {The Annals of Applied Statistics},
  title   = {Estimating time-varying networks},
  year    = {2010},
  number  = {1},
  pages   = {94--123},
  volume  = {4},
}

@Article{Gorbunov-Decentralized-Survey2020,
  author  = {Eduard Gorbunov and Alexander Rogozin and Aleksandr Beznosikov and Darina Dvinskikh and Alexander Gasnikov},
  journal = {arXiv preprint arXiv:2011.13259},
  title   = {Recent theoretical advances in decentralized distributed convex optimization},
  year    = {2020},
}


@InProceedings{L-SVRG,
  author    = {Kovalev, Dmitry and Horv\'{a}th, Samuel and Richt\'{a}rik, Peter},
  booktitle = {Proceedings of the 31st International Conference on Algorithmic Learning Theory},
  title     = {Donâ€™t jump through hoops and remove those loops: {SVRG} and {K}atyusha are better without the outer loop},
  year      = {2020},
}

@Article{biased2020,
  author  = {Aleksandr Beznosikov and Samuel Horv\'{a}th and Peter Richt\'{a}rik and Mher Safaryan},
  title   = {On Biased Compression for Distributed Learning},
  journal = {arXiv:2002.12410},
  year    = {2020},
}

@inproceedings{allen2017katyusha,
  title={Katyusha: The first direct acceleration of stochastic gradient methods},
  author={Allen-Zhu, Zeyuan},
  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1200--1205},
  year={2017},
  organization={ACM}
}

@Article{EC-Katyusha,
  author  = {Xun Qian and Peter Richt\'{a}rik and Tong Zhang},
  journal = {arXiv preprint arXiv:2010.00091},
  title   = {Error compensated distributed {SGD} can be accelerated},
  year    = {2020},
}

@Article{FL_survey_2020,
  author  = {Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal = {IEEE Signal Processing Magazine},
  title   = {Federated learning: challenges, methods, and future directions},
  year    = {2020},
  number  = {3},
  pages   = {50--60},
  volume  = {37},
}

@InProceedings{D-DIANA,
  author    = {Kovalev, Dmitry and Koloskova, Anastasia and Jaggi, Martin and Richt\'{a}rik, Peter and Stich, Sebastian},
  booktitle = {The 24th International Conference on Artificial Intelligence and Statistics (AISTATS 2021) },
  title     = {A Linearly Convergent Algorithm for Decentralized Optimization: Sending Less Bits for Free!},
  year      = {2021},
}

@inproceedings{rabbat2004distributed,
	title={Distributed optimization in sensor networks},
	author={Rabbat, Michael and Nowak, Robert},
	booktitle={Proceedings of the 3rd international symposium on Information processing in sensor networks},
	pages={20--27},
	year={2004}
}

@article{beck20141,
	title={An $ O (1/k) $ gradient method for network resource allocation problems},
	author={Beck, Amir and Nedi{\'c}, Angelia and Ozdaglar, Asuman and Teboulle, Marc},
	journal={IEEE Transactions on Control of Network Systems},
	volume={1},
	number={1},
	pages={64--73},
	year={2014},
	publisher={IEEE}
}

@article{giselsson2013accelerated,
	title={Accelerated gradient methods and dual decomposition in distributed model predictive control},
	author={Giselsson, Pontus and Doan, Minh Dang and Keviczky, Tam{\'a}s and De Schutter, Bart and Rantzer, Anders},
	journal={Automatica},
	volume={49},
	number={3},
	pages={829--833},
	year={2013},
	publisher={Elsevier}
}

@article{bazerque2009distributed,
	title={Distributed spectrum sensing for cognitive radio networks by exploiting sparsity},
	author={Bazerque, Juan Andr{\'e}s and Giannakis, Georgios B},
	journal={IEEE Transactions on Signal Processing},
	volume={58},
	number={3},
	pages={1847--1862},
	year={2009},
	publisher={IEEE}
}

@article{gan2012optimal,
	title={Optimal decentralized protocol for electric vehicle charging},
	author={Gan, Lingwen and Topcu, Ufuk and Low, Steven H},
	journal={IEEE Transactions on Power Systems},
	volume={28},
	number={2},
	pages={940--951},
	year={2012},
	publisher={IEEE}
}

@article{scaman2017optimal,
	title={Optimal algorithms for smooth and strongly convex distributed optimization in networks},
	author={Scaman, Kevin and Bach, Francis and Bubeck, S{\'e}bastien and Lee, Yin Tat and Massouli{\'e}, Laurent},
	journal={arXiv preprint arXiv:1702.08704},
	year={2017}
}

@article{kovalev2020optimal,
	title={Optimal and practical algorithms for smooth and strongly convex decentralized optimization},
	author={Kovalev, Dmitry and Salim, Adil and Richt{\'a}rik, Peter},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@article{nedic2017achieving,
	title={Achieving geometric convergence for distributed optimization over time-varying graphs},
	author={Nedic, Angelia and Olshevsky, Alex and Shi, Wei},
	journal={SIAM Journal on Optimization},
	volume={27},
	number={4},
	pages={2597--2633},
	year={2017},
	publisher={SIAM}
}

@article{pu2020push,
	title={Push-pull gradient methods for distributed optimization in networks},
	author={Pu, Shi and Shi, Wei and Xu, Jinming and Nedic, Angelia},
	journal={IEEE Transactions on Automatic Control},
	year={2020},
	publisher={IEEE}
}

@inproceedings{maros2018panda,
	title={Panda: A dual linearly converging method for distributed optimization over time-varying undirected graphs},
	author={Maros, Marie and Jald{\'e}n, Joakim},
	booktitle={2018 IEEE Conference on Decision and Control (CDC)},
	pages={6520--6525},
	year={2018},
	organization={IEEE}
}

@article{qu2019accelerated,
	title={Accelerated distributed Nesterov gradient descent},
	author={Qu, Guannan and Li, Na},
	journal={IEEE Transactions on Automatic Control},
	year={2019},
	publisher={IEEE}
}

@article{ye2020multi,
	title={Multi-consensus Decentralized Accelerated Gradient Descent},
	author={Ye, Haishan and Luo, Luo and Zhou, Ziang and Zhang, Tong},
	journal={arXiv preprint arXiv:2005.00797},
	year={2020}
}

@article{rogozin2020towards,
	title={Towards accelerated rates for distributed optimization over time-varying networks},
	author={Rogozin, Alexander and Lukoshkin, Vladislav and Gasnikov, Alexander and Kovalev, Dmitry and Shulgin, Egor},
	journal={arXiv preprint arXiv:2009.11069},
	year={2020}
}

@article{li2018sharp,
	title={A sharp convergence rate analysis for distributed accelerated gradient methods},
	author={Li, Huan and Fang, Cong and Yin, Wotao and Lin, Zhouchen},
	journal={arXiv preprint arXiv:1810.01053},
	year={2018}
}

@book{nesterov2003introductory,
	title={Introductory lectures on convex optimization: A basic course},
	author={Nesterov, Yurii},
	volume={87},
	year={2003},
	publisher={Springer Science \& Business Media}
}

@article{rogozin2019optimal,
	title={Optimal distributed convex optimization on slowly time-varying graphs},
	author={Rogozin, Alexander and Uribe, Cesar and Gasnikov, Alexander and Malkovskii, Nikolai and Nedich, Angelia},
	journal={IEEE Transactions on Control of Network Systems},
	year={2019},
	publisher={IEEE}
}

@article{gorbunov2020linearly,
	title={Linearly Converging Error Compensated {SGD}},
	author={Gorbunov, Eduard and Kovalev, Dmitry and Makarenko, Dmitry and Richt{\'a}rik, Peter},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@article{stich2019error,
	title={The error-feedback framework: Better rates for {SGD} with delayed gradients and compressed communication},
	author={Stich, Sebastian U and Karimireddy, Sai Praneeth},
	journal={arXiv preprint arXiv:1909.05350},
	year={2019}
}

@article{karimireddy2019error,
	title={Error feedback fixes {S}ign{SGD} and other gradient compression schemes},
	author={Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian U and Jaggi, Martin},
	journal={arXiv preprint arXiv:1901.09847},
	year={2019}
}

@book{rockafellar1970convex,
	title={Convex analysis},
	author={Rockafellar, R Tyrrell},
	volume={36},
	year={1970},
	publisher={Princeton university press}
}

@article{chang2011libsvm,
 author = {Chang, Chih-Chung and Lin, Chih-Jen},
 title = {{LIBSVM}: A library for support vector machines},
 journal = {ACM Transactions on Intelligent Systems and Technology},
 volume = {2},
 issue = {3},
 year = {2011},
 pages = {27:1--27:27},
 note =	 {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}

@inproceedings{morris2020tudataset,
    title={TUDataset: A collection of benchmark datasets for learning with graphs},
    author={Christopher Morris and Nils M. Kriege and Franka Bause and Kristian Kersting and Petra Mutzel and Marion Neumann},
    booktitle={ICML 2020 Workshop on Graph Representation Learning and Beyond (GRL+ 2020)},
    archivePrefix={arXiv},
    eprint={2007.08663},
    url={www.graphlearning.io},
    year={2020}
}
