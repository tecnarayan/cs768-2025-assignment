\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2012)Agarwal, Bartlett, Ravikumar, and
  Wainwright]{IT:SCO}
Alekh Agarwal, Peter~L. Bartlett, Pradeep Ravikumar, and Martin~J. Wainwright.
\newblock Information-theoretic lower bounds on the oracle complexity of
  stochastic convex optimization.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (5):\penalty0 3235--3249, 2012.

\bibitem[Bartlett et~al.(2005)Bartlett, Bousquet, and Mendelson]{Local_RC}
Peter~L. Bartlett, Olivier Bousquet, and Shahar Mendelson.
\newblock Local rademacher complexities.
\newblock \emph{The Annals of Statistics}, 33\penalty0 (4):\penalty0
  1497--1537, 2005.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{bianchi-2006-prediction}
Nicolo Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock \emph{Prediction, Learning, and Games}.
\newblock Cambridge University Press, 2006.

\bibitem[Chen et~al.(2012)Chen, Lin, and Pena]{NIPS2012_DualAve}
Xi~Chen, Qihang Lin, and Javier Pena.
\newblock Optimal regularized dual averaging methods for stochastic
  optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pages
  404--412, 2012.

\bibitem[Clarkson(2010)]{Clarkson:2010:CSG}
Kenneth~L. Clarkson.
\newblock Coresets, sparse greedy approximation, and the frank-wolfe algorithm.
\newblock \emph{ACM Transactions on Algorithms}, 6\penalty0 (4):\penalty0
  63:1--63:30, 2010.

\bibitem[Cotter et~al.(2011)Cotter, Shamir, Srebro, and
  Sridharan]{NIPS2011_0942}
Andrew Cotter, Ohad Shamir, Nati Srebro, and Karthik Sridharan.
\newblock Better mini-batch algorithms via accelerated gradient methods.
\newblock In \emph{Advances in Neural Information Processing Systems 24}, pages
  1647--1655, 2011.

\bibitem[Dekel et~al.(2011)Dekel, Gilad-Bachrach, Shamir, and
  Xiao]{ICML2011Dekel}
Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao.
\newblock Optimal distributed online prediction.
\newblock In Lise Getoor and Tobias Scheffer, editors, \emph{Proceedings of the
  28th International Conference on Machine Learning}, pages 713--720, 2011.

\bibitem[Dekel et~al.(2012)Dekel, Gilad-Bachrach, Shamir, and
  Xiao]{Dekel:2012:ODO}
Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao.
\newblock Optimal distributed online prediction using mini-batches.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 165--202,
  2012.

\bibitem[Frank and Wolfe(1956)]{Frank_Wolfe}
Marguerite Frank and Philip Wolfe.
\newblock An algorithm for quadratic programming.
\newblock \emph{Naval Research Logistics Quarterly}, 3\penalty0 (1-2):\penalty0
  95--110, 1956.

\bibitem[Ghadimi and Lan(2012)]{Lan:SCSC}
Saeed Ghadimi and Guanghui Lan.
\newblock Optimal stochastic approximation algorithms for strongly convex
  stochastic composite optimization i: A generic algorithmic framework.
\newblock \emph{SIAM Journal on Optimization}, 22\penalty0 (4):\penalty0
  1469--1492, 2012.

\bibitem[Hazan(2008)]{Hazan:2008:SAS}
Elad Hazan.
\newblock Sparse approximate solutions to semidefinite programs.
\newblock In \emph{Proceedings of the 8th Latin American conference on
  Theoretical informatics}, pages 306--316, 2008.

\bibitem[Hazan and Kale(2011)]{COLT:Hazan:2011}
Elad Hazan and Satyen Kale.
\newblock Beyond the regret minimization barrier: an optimal algorithm for
  stochastic strongly-convex optimization.
\newblock In \emph{Proceedings of the 24th Annual Conference on Learning
  Theory}, pages 421--436, 2011.

\bibitem[Hazan and Kale(2012)]{ICML2012Hazan}
Elad Hazan and Satyen Kale.
\newblock Projection-free online learning.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning}, pages 521--528, 2012.

\bibitem[Hu et~al.(2009)Hu, Kwok, and Pan]{NIPS2009_AGM}
Chonghai Hu, James Kwok, and Weike Pan.
\newblock Accelerated gradient methods for stochastic optimization and online
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems 22}, pages
  781--789, 2009.

\bibitem[Jaggi(2013)]{ICML2013Jaggi}
Martin Jaggi.
\newblock Revisiting frank-wolfe: Projection-free sparse convex optimization.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning}, 2013.

\bibitem[Jin et~al.(2009)Jin, Wang, and Zhou]{NIPS2009_RDM}
Rong Jin, Shijun Wang, and Yang Zhou.
\newblock Regularized distance metric learning: Theory and algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems 22}, pages
  862--870, 2009.

\bibitem[Juditsky and Nesterov(2010)]{Juditsky:SCS}
Anatoli Juditsky and Yuri Nesterov.
\newblock Primal-dual subgradient methods for minimizing uniformly convex
  functions.
\newblock Technical report, 2010.

\bibitem[Juditsky et~al.(2011)Juditsky, Nemirovski, and Tauvel]{Nemirovski:SMP}
Anatoli Juditsky, Arkadi Nemirovski, and Claire Tauvel.
\newblock Solving variational inequalities with stochastic mirror-prox
  algorithm.
\newblock \emph{Stochastic Systems}, 1\penalty0 (1):\penalty0 17--58, 2011.

\bibitem[Lacoste-Julien et~al.(2013)Lacoste-Julien, Jaggi, Schmidt, and
  Pletscher]{ICML2013Simon}
Simon Lacoste-Julien, Martin Jaggi, Mark Schmidt, and Patrick Pletscher.
\newblock Block-coordinate frank-wolfe optimization for structural svm.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning}, 2013.

\bibitem[Lan(2012)]{Lan:SCO}
Guanghui Lan.
\newblock An optimal method for stochastic composite optimization.
\newblock \emph{Mathematical Programming}, 133:\penalty0 365--397, 2012.

\bibitem[Levitin and Polyak(1966)]{Conditional_Gradient}
Evgenij~S Levitin and Boris~T Polyak.
\newblock Constrained minimization methods.
\newblock \emph{USSR Computational Mathematics and Mathematical Physics},
  6\penalty0 (5):\penalty0 1--50, 1966.

\bibitem[Mahdavi et~al.(2012)Mahdavi, Yang, Jin, Zhu, and Yi]{NIPS2012_OneP}
Mehrdad Mahdavi, Tianbao Yang, Rong Jin, Shenghuo Zhu, and Jinfeng Yi.
\newblock Stochastic gradient descent with only one projection.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pages
  503--511, 2012.

\bibitem[Nemirovski and Yudin(1983)]{Problem_Complexity}
A.~Nemirovski and D.~B. Yudin.
\newblock \emph{Problem complexity and method efficiency in optimization}.
\newblock John Wiley \& Sons Ltd, 1983.

\bibitem[Nemirovski et~al.(2009)Nemirovski, Juditsky, Lan, and
  Shapiro]{nemirovski-2008-robust}
A.~Nemirovski, A.~Juditsky, G.~Lan, and A.~Shapiro.
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock \emph{SIAM Journal on Optimization}, 19\penalty0 (4):\penalty0
  1574--1609, 2009.

\bibitem[Nemirovski(2005)]{nemirovski-2005-prox}
Arkadi Nemirovski.
\newblock Prox-method with rate of convergence o(1/t) for variational
  inequalities with lipschitz continuous monotone operators and smooth
  convex-concave saddle point problems.
\newblock \emph{SIAM Journal on Optimization}, 15\penalty0 (1):\penalty0
  229--251, 2005.

\bibitem[Nesterov(2005)]{Nesterov_Non_Smooth}
Yu. Nesterov.
\newblock Smooth minimization of non-smooth functions.
\newblock \emph{Mathematical Programming}, 103\penalty0 (1):\penalty0 127--152,
  2005.

\bibitem[Nesterov(2004)]{nesterov2004introductory}
Yurii Nesterov.
\newblock \emph{Introductory lectures on convex optimization: a basic course},
  volume~87 of \emph{Applied optimization}.
\newblock Kluwer Academic Publishers, 2004.

\bibitem[Nesterov(2007)]{Nesterov_Composite}
Yurii Nesterov.
\newblock Gradient methods for minimizing composite objective function.
\newblock Core discussion papers, 2007.

\bibitem[Rakhlin et~al.(2012)Rakhlin, Shamir, and Sridharan]{ICML2012Rakhlin}
Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan.
\newblock Making gradient descent optimal for strongly convex stochastic
  optimization.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning}, pages 449--456, 2012.

\bibitem[Roux et~al.(2008)Roux, Manzagol, and Bengio]{NIPS2007_Topmoumoute}
Nicolas~Le Roux, Pierre-Antoine Manzagol, and Yoshua Bengio.
\newblock Topmoumoute online natural gradient algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems 20}, pages
  849--856, 2008.

\bibitem[Shalev-Shwartz et~al.(2009)Shalev-Shwartz, Shamir, Srebro, and
  Sridharan]{COLT:Shalev:2009}
Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan.
\newblock Stochastic convex optimization.
\newblock In \emph{Proceedings of the 22nd Annual Conference on Learning
  Theory}, 2009.

\bibitem[Shalev-Shwartz et~al.(2011)Shalev-Shwartz, Singer, Srebro, and
  Cotter]{Shalev-ShwartzSSC11}
Shai Shalev-Shwartz, Yoram Singer, Nathan Srebro, and Andrew Cotter.
\newblock Pegasos: primal estimated sub-gradient solver for svm.
\newblock \emph{Mathematical Programming}, 127\penalty0 (1):\penalty0 3--30,
  2011.

\bibitem[Smale and Zhou(2009)]{smale-2009-geometry}
Steve Smale and Ding-Xuan Zhou.
\newblock Geometry on probability spaces.
\newblock \emph{Constructive Approximation}, 30:\penalty0 311--323, 2009.

\bibitem[Zhang(2004)]{Zhang_SVM}
Tong Zhang.
\newblock Solving large scale linear prediction problems using stochastic
  gradient descent algorithms.
\newblock In \emph{Proceedings of the 21st International Conference on Machine
  Learning}, pages 919--926, 2004.

\end{thebibliography}
