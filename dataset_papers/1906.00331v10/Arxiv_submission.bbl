\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadeh et~al.(2015)Abadeh, Esfahani, and
  Kuhn]{Abadeh-2015-Distributionally}
S.~S. Abadeh, P.~M.~M. Esfahani, and D.~Kuhn.
\newblock Distributionally robust logistic regression.
\newblock In \emph{NeurIPS}, pages 1576--1584, 2015.

\bibitem[Adolphs et~al.(2018)Adolphs, Daneshmand, Lucchi, and
  Hofmann]{Adolphs-2018-Local}
L.~Adolphs, H.~Daneshmand, A.~Lucchi, and T.~Hofmann.
\newblock Local saddle point optimization: A curvature exploitation approach.
\newblock \emph{ArXiv Preprint: 1805.05751}, 2018.

\bibitem[Azizian et~al.(2019)Azizian, Mitliagkas, Lacoste-Julien, and
  Gidel]{Azizian-2019-Tight}
W.~Azizian, I.~Mitliagkas, S.~Lacoste-Julien, and G.~Gidel.
\newblock A tight and unified analysis of extragradient for a whole spectrum of
  differentiable games.
\newblock \emph{ArXiv Preprint: 1906.05945}, 2019.

\bibitem[Bailey and Piliouras(2018)]{Bailey-2018-Multiplicative}
J.~P. Bailey and G.~Piliouras.
\newblock Multiplicative weights update in zero-sum games.
\newblock In \emph{EC}, pages 321--338, 2018.

\bibitem[Balduzzi et~al.(2018)Balduzzi, Racaniere, Martens, Foerster, Tuyls,
  and Graepel]{Balduzzi-2018-Mechanics}
D.~Balduzzi, S.~Racaniere, J.~Martens, J.~Foerster, K.~Tuyls, and T.~Graepel.
\newblock The mechanics of n-player differentiable games.
\newblock \emph{ArXiv Preprint: 1802.05642}, 2018.

\bibitem[Basar and Olsder(1999)]{Basar-1999-Dynamic}
T.~Basar and G.~J. Olsder.
\newblock \emph{Dynamic Noncooperative Game Theory}, volume~23.
\newblock SIAM, 1999.

\bibitem[Bena{\i}m and Hirsch(1999)]{Benaim-1999-Mixed}
M.~Bena{\i}m and M.~W. Hirsch.
\newblock Mixed equilibria and dynamical systems arising from fictitious play
  in perturbed games.
\newblock \emph{Games and Economic Behavior}, 29\penalty0 (1-2):\penalty0
  36--72, 1999.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{Cesa-2006-Prediction}
N.~Cesa-Bianchi and G.~Lugosi.
\newblock \emph{Prediction, Learning, and Games}.
\newblock Cambridge University Press, 2006.

\bibitem[Chen and Rockafellar(1997)]{Chen-1997-Convergence}
G.~H.~G. Chen and R.~T. Rockafellar.
\newblock Convergence rates in forward--backward splitting.
\newblock \emph{SIAM Journal on Optimization}, 7\penalty0 (2):\penalty0
  421--444, 1997.

\bibitem[Cherukuri et~al.(2017)Cherukuri, Gharesifard, and
  Cortes]{Cherukuri-2017-Saddle}
A.~Cherukuri, B.~Gharesifard, and J.~Cortes.
\newblock Saddle-point dynamics: conditions for asymptotic stability of saddle
  points.
\newblock \emph{SIAM Journal on Control and Optimization}, 55\penalty0
  (1):\penalty0 486--511, 2017.

\bibitem[Daskalakis and Panageas(2018{\natexlab{a}})]{Daskalakis-2018-Last}
C.~Daskalakis and I.~Panageas.
\newblock Last-iterate convergence: Zero-sum games and constrained min-max
  optimization.
\newblock \emph{ArXiv Preprint: 1807.04252}, 2018{\natexlab{a}}.

\bibitem[Daskalakis and Panageas(2018{\natexlab{b}})]{Daskalakis-2018-Limit}
C.~Daskalakis and I.~Panageas.
\newblock The limit points of (optimistic) gradient descent in min-max
  optimization.
\newblock In \emph{NeurIPS}, pages 9236--9246, 2018{\natexlab{b}}.

\bibitem[Daskalakis et~al.(2017)Daskalakis, Ilyas, Syrgkanis, and
  Zeng]{Daskalakis-2017-Training}
C.~Daskalakis, A.~Ilyas, V.~Syrgkanis, and H.~Zeng.
\newblock Training gans with optimism.
\newblock \emph{ArXiv Preprint: 1711.00141}, 2017.

\bibitem[Davis and Drusvyatskiy(2019)]{Davis-2019-Stochastic}
D.~Davis and D.~Drusvyatskiy.
\newblock Stochastic model-based minimization of weakly convex functions.
\newblock \emph{SIAM Journal on Optimization}, 29\penalty0 (1):\penalty0
  207--239, 2019.

\bibitem[Drusvyatskiy and Lewis(2018)]{Drusvyatskiy-2018-Error}
D.~Drusvyatskiy and A.~S. Lewis.
\newblock Error bounds, quadratic growth, and linear convergence of proximal
  methods.
\newblock \emph{Mathematics of Operations Research}, 43\penalty0 (3):\penalty0
  919--948, 2018.

\bibitem[Du and Hu(2018)]{Du-2018-Linear}
S.~S. Du and W.~Hu.
\newblock Linear convergence of the primal-dual gradient method for
  convex-concave saddle point problems without strong convexity.
\newblock \emph{ArXiv Preprint: 1802.01504}, 2018.

\bibitem[Golshtein(1974)]{Golshtein-1974-Generalized}
E.~G. Golshtein.
\newblock Generalized gradient method for finding saddle points.
\newblock \emph{Matekon}, 10\penalty0 (3):\penalty0 36--52, 1974.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{Goodfellow-2014-Generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{NeurIPS}, pages 2672--2680, 2014.

\bibitem[Grnarova et~al.(2018)Grnarova, Levy, Lucchi, Hofmann, and
  Krause]{Grnarova-2018-An}
P.~Grnarova, K.~Y. Levy, A.~Lucchi, T.~Hofmann, and A.~Krause.
\newblock An online learning approach to generative adversarial networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{Heusel-2017-Gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock {GANs} trained by a two time-scale update rule converge to a local
  nash equilibrium.
\newblock In \emph{NeurIPS}, pages 6626--6637, 2017.

\bibitem[Hommes and Ochea(2012)]{Hommes-2012-Multiple}
C.~H. Hommes and M.~I. Ochea.
\newblock Multiple equilibria and limit cycles in evolutionary games with logit
  dynamics.
\newblock \emph{Games and Economic Behavior}, 74\penalty0 (1):\penalty0
  434--441, 2012.

\bibitem[Jin et~al.(2019)Jin, Netrapalli, and Jordan]{Jin-2019-Minmax}
C.~Jin, P.~Netrapalli, and M.~I. Jordan.
\newblock Minmax optimization: Stable limit points of gradient descent ascent
  are locally optimal.
\newblock \emph{ArXiv Preprint: 1902.00618}, 2019.

\bibitem[Jordan(2018)]{Jordan-2018-Artificial}
M.~I. Jordan.
\newblock Artificial intelligence--the revolution hasnâ€™t happened yet.
\newblock \emph{Medium. Vgl. Ders.(2018): Perspectives and Challenges.
  Presentation SysML}, 2018.

\bibitem[Juditsky et~al.(2011)Juditsky, Nemirovski, and
  Tauvel]{Juditsky-2011-Solving}
A.~Juditsky, A.~Nemirovski, and C.~Tauvel.
\newblock Solving variational inequalities with stochastic mirror-prox
  algorithm.
\newblock \emph{Stochastic Systems}, 1\penalty0 (1):\penalty0 17--58, 2011.

\bibitem[Kong and Monteiro(2019)]{Kong-2019-Accelerated}
W.~Kong and R.~D.~C. Monteiro.
\newblock An accelerated inexact proximal point method for solving
  nonconvex-concave min-max problems.
\newblock \emph{ArXiv Preprint:1905.13433}, 2019.

\bibitem[Korpelevich(1976)]{Korpelevich-1976-Extragradient}
G.~M. Korpelevich.
\newblock The extragradient method for finding saddle points and other
  problems.
\newblock \emph{Matecon}, 12:\penalty0 747--756, 1976.

\bibitem[Kose(1956)]{Kose-1956-Solutions}
T.~Kose.
\newblock Solutions of saddle value problems by differential equations.
\newblock \emph{Econometrica, Journal of the Econometric Society}, pages
  59--70, 1956.

\bibitem[Liang and Stokes(2018)]{Liang-2018-Interaction}
T.~Liang and J.~Stokes.
\newblock Interaction matters: A note on non-asymptotic local convergence of
  generative adversarial networks.
\newblock \emph{ArXiv Preprint: 1802.06132}, 2018.

\bibitem[Lin et~al.(2018)Lin, Liu, Rafique, and Yang]{Lin-2018-Solving}
Q.~Lin, M.~Liu, H.~Rafique, and T.~Yang.
\newblock Solving weakly-convex-weakly-concave saddle-point problems as
  weakly-monotone variational inequality.
\newblock \emph{ArXiv Preprint: 1810.10207}, 2018.

\bibitem[Lu et~al.(2019)Lu, Tsaknakis, Hong, and Chen]{Lu-2019-Hybrid}
S.~Lu, I.~Tsaknakis, M.~Hong, and Y.~Chen.
\newblock Hybrid block successive approximation for one-sided non-convex
  min-max problems: Algorithms and applications.
\newblock \emph{ArXiv Preprint: 1902.08294}, 2019.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{Madry-2017-Towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{ArXiv Preprint: 1706.06083}, 2017.

\bibitem[Mateos et~al.(2010)Mateos, Bazerque, and
  Giannakis]{Mateos-2010-Distributed}
G.~Mateos, J.~A. Bazerque, and G.~B. Giannakis.
\newblock Distributed sparse linear regression.
\newblock \emph{IEEE Transactions on Signal Processing}, 58\penalty0
  (10):\penalty0 5262--5276, 2010.

\bibitem[Mazumdar et~al.(2019)Mazumdar, Jordan, and
  Sastry]{Mazumdar-2019-Finding}
E.~V. Mazumdar, M.~I. Jordan, and S.~S. Sastry.
\newblock On finding local nash equilibria (and only local nash equilibria) in
  zero-sum games.
\newblock \emph{ArXiv Preprint: 1901.00838}, 2019.

\bibitem[Mertikopoulos et~al.(2018)Mertikopoulos, Papadimitriou, and
  Piliouras]{Mertikopoulos-2018-Cycles}
P.~Mertikopoulos, C.~Papadimitriou, and G.~Piliouras.
\newblock Cycles in adversarial regularized learning.
\newblock In \emph{SODA}, pages 2703--2717. SIAM, 2018.

\bibitem[Mertikopoulos et~al.(2019)Mertikopoulos, Lecouat, Zenati, Foo,
  Chandrasekhar, and Piliouras]{Mertikopoulos-2019-Optimistic}
P.~Mertikopoulos, B.~Lecouat, H.~Zenati, C-S Foo, V.~Chandrasekhar, and
  G.~Piliouras.
\newblock Optimistic mirror descent in saddle-point problems: Going the
  extra(-gradient) mile.
\newblock In \emph{ICLR}, 2019.

\bibitem[Mokhtari et~al.(2019{\natexlab{a}})Mokhtari, Ozdaglar, and
  Pattathil]{Mokhtari-2019-Proximal}
A.~Mokhtari, A.~Ozdaglar, and S.~Pattathil.
\newblock Proximal point approximations achieving a convergence rate of
  $o(1/k)$ for smooth convex-concave saddle point problems: Optimistic gradient
  and extra-gradient methods.
\newblock \emph{ArXiv Preprint: 1906.01115}, 2019{\natexlab{a}}.

\bibitem[Mokhtari et~al.(2019{\natexlab{b}})Mokhtari, Ozdaglar, and
  Pattathil]{Mokhtari-2019-Unified}
A.~Mokhtari, A.~Ozdaglar, and S.~Pattathil.
\newblock A unified analysis of extra-gradient and optimistic gradient methods
  for saddle point problems: Proximal point approach.
\newblock \emph{ArXiv Preprint: 1901.08511}, 2019{\natexlab{b}}.

\bibitem[Namkoong and Duchi(2016)]{Namkoong-2016-Stochastic}
H.~Namkoong and J.~C. Duchi.
\newblock Stochastic gradient methods for distributionally robust optimization
  with f-divergences.
\newblock In \emph{NIPS}, pages 2208--2216, 2016.

\bibitem[Nedi{\'c} and Ozdaglar(2009)]{Nedic-2009-Subgradient}
A.~Nedi{\'c} and A.~Ozdaglar.
\newblock Subgradient methods for saddle-point problems.
\newblock \emph{Journal of Optimization Theory and Applications}, 142\penalty0
  (1):\penalty0 205--228, 2009.

\bibitem[Nemirovski(2004)]{Nemirovski-2004-Prox}
A.~Nemirovski.
\newblock Prox-method with rate of convergence o (1/t) for variational
  inequalities with lipschitz continuous monotone operators and smooth
  convex-concave saddle point problems.
\newblock \emph{SIAM Journal on Optimization}, 15\penalty0 (1):\penalty0
  229--251, 2004.

\bibitem[Nesterov(2013)]{Nesterov-2013-Introductory}
Y.~Nesterov.
\newblock \emph{Introductory Lectures on Convex Optimization: A Basic Course},
  volume~87.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Neumann(1928)]{Neumann-1928-Theorie}
J.~V. Neumann.
\newblock Zur theorie der gesellschaftsspiele.
\newblock \emph{Mathematische Annalen}, 100\penalty0 (1):\penalty0 295--320,
  1928.

\bibitem[Nisan et~al.(2007)Nisan, Roughgarden, Tardos, and
  Vazirani]{Nisan-2007-Algorithmic}
N.~Nisan, T.~Roughgarden, E.~Tardos, and V.~V. Vazirani.
\newblock \emph{Algorithmic Game Theory}.
\newblock Cambridge University Press, 2007.

\bibitem[Nouiehed et~al.(2019)Nouiehed, Sanjabi, Huang, Lee, and
  Razaviyayn]{Nouiehed-2019-Solving}
M.~Nouiehed, M.~Sanjabi, T.~Huang, J.~D. Lee, and M.~Razaviyayn.
\newblock Solving a class of non-convex min-max games using iterative first
  order methods.
\newblock In \emph{NeurIPS}, pages 14905--14916, 2019.

\bibitem[Rafique et~al.(2018)Rafique, Liu, Lin, and Yang]{Rafique-2018-Non}
H.~Rafique, M.~Liu, Q.~Lin, and T.~Yang.
\newblock Non-convex min-max optimization: Provable algorithms and applications
  in machine learning.
\newblock \emph{ArXiv Preprint: 1810.02060}, 2018.

\bibitem[Robinson(1951)]{Robinson-1951-Iterative}
J.~Robinson.
\newblock An iterative method of solving a game.
\newblock \emph{Annals of Mathematics}, pages 296--301, 1951.

\bibitem[Rockafellar(2015)]{Rockafellar-2015-Convex}
R.~T. Rockafellar.
\newblock \emph{Convex Analysis}.
\newblock Princeton University Press, 2015.

\bibitem[Sanjabi et~al.(2018)Sanjabi, Ba, Razaviyayn, and
  Lee]{Sanjabi-2018-Convergence}
M.~Sanjabi, J.~Ba, M.~Razaviyayn, and J.~D. Lee.
\newblock On the convergence and robustness of training gans with regularized
  optimal transport.
\newblock In \emph{NeurIPS}, pages 7091--7101, 2018.

\bibitem[Shamma(2008)]{Shamma-2008-Cooperative}
J.~Shamma.
\newblock \emph{Cooperative Control of Distributed Multi-agent Systems}.
\newblock John Wiley \& Sons, 2008.

\bibitem[Sinha et~al.(2018)Sinha, Namkoong, and Duchi]{Sinha-2018-Certifiable}
A.~Sinha, H.~Namkoong, and J.~Duchi.
\newblock Certifiable distributional robustness with principled adversarial
  training.
\newblock In \emph{ICLR}, 2018.

\bibitem[Sion(1958)]{Sion-1958-General}
M.~Sion.
\newblock On general minimax theorems.
\newblock \emph{Pacific Journal of Mathematics}, 8\penalty0 (1):\penalty0
  171--176, 1958.

\bibitem[Thekumparampil et~al.(2019)Thekumparampil, Jain, Netrapalli, and
  Oh]{Thekumparampil-2019-Efficient}
K.~K. Thekumparampil, P.~Jain, P.~Netrapalli, and S.~Oh.
\newblock Efficient algorithms for smooth minimax optimization.
\newblock In \emph{NeurIPS}, pages 12659--12670, 2019.

\bibitem[Uzawa(1958)]{Uzawa-1958-Iterative}
H.~Uzawa.
\newblock Iterative methods for concave programming.
\newblock \emph{Studies in Linear and Nonlinear Programming}, 6:\penalty0
  154--165, 1958.

\bibitem[Von~Neumann and Morgenstern(2007)]{Von-2007-Theory}
J.~Von~Neumann and O.~Morgenstern.
\newblock \emph{Theory of Games and Economic Behavior (Commemorative Edition)}.
\newblock Princeton University Press, 2007.

\bibitem[Xu et~al.(2009)Xu, Caramanis, and Mannor]{Xu-2009-Robustness}
H.~Xu, C.~Caramanis, and S.~Mannor.
\newblock Robustness and regularization of support vector machines.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0
  (Jul):\penalty0 1485--1510, 2009.

\end{thebibliography}
