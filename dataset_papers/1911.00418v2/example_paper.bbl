\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alaa and Van Der~Schaar(2019)]{causal}
A.~Alaa and M.~Van Der~Schaar.
\newblock Validating causal inference models via influence functions.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pages 191--201, Long Beach,
  California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/alaa19a.html}.

\bibitem[Arrieta-Ibarra et~al.(2018)Arrieta-Ibarra, Goff, Jiménez-Hernández,
  Lanier, and Weyl]{credit}
I.~Arrieta-Ibarra, L.~Goff, D.~Jiménez-Hernández, J.~Lanier, and E.~G. Weyl.
\newblock Should we treat data as labor? moving beyond "free".
\newblock \emph{AEA Papers and Proceedings}, 108:\penalty0 38--42, May 2018.
\newblock \doi{10.1257/pandp.20181003}.
\newblock URL \url{http://www.aeaweb.org/articles?id=10.1257/pandp.20181003}.

\bibitem[Avrachenkov et~al.(2013)Avrachenkov, Filar, and Howlett]{perturbation}
K.~E. Avrachenkov, J.~A. Filar, and P.~G. Howlett.
\newblock \emph{Analytic Perturbation Theory and Its Applications}.
\newblock Society for Industrial and Applied Mathematics, Philadelphia, PA,
  USA, 2013.
\newblock ISBN 1611973139, 9781611973136.

\bibitem[Brunet et~al.(2018)Brunet, Alkalay{-}Houlihan, Anderson, and
  Zemel]{influence_word_embeddings}
M.~Brunet, C.~Alkalay{-}Houlihan, A.~Anderson, and R.~S. Zemel.
\newblock Understanding the origins of bias in word embeddings.
\newblock \emph{CoRR}, abs/1810.03611, 2018.
\newblock URL \url{http://arxiv.org/abs/1810.03611}.

\bibitem[Candes and Tao(2005)]{Candes:2005:DLP:2263433.2271950}
E.~J. Candes and T.~Tao.
\newblock Decoding by linear programming.
\newblock \emph{IEEE Trans. Inf. Theor.}, 51\penalty0 (12):\penalty0
  4203--4215, Dec. 2005.
\newblock ISSN 0018-9448.
\newblock \doi{10.1109/TIT.2005.858979}.
\newblock URL \url{http://dx.doi.org/10.1109/TIT.2005.858979}.

\bibitem[Chen et~al.(2020)Chen, Si, Li, Chelba, Kumar, Boning, and
  Hsieh]{multistage_influence}
H.~Chen, S.~Si, Y.~Li, C.~Chelba, S.~Kumar, D.~Boning, and C.-J. Hsieh.
\newblock {\{}MULTI{\}}-{\{}stage{\}} {\{}influence{\}} {\{}function{\}}, 2020.
\newblock URL \url{https://openreview.net/forum?id=r1geR1BKPr}.

\bibitem[Chen et~al.(2018)Chen, Johansson, and Sontag]{demograph}
I.~Chen, F.~D. Johansson, and D.~Sontag.
\newblock Why is my classifier discriminatory?
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 3539--3550. Curran Associates, Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/7613-why-is-my-classifier-discriminatory.pdf}.

\bibitem[Cook and Weisberg(1980)]{cook_influence}
R.~Cook and S.~Weisberg.
\newblock Characterizations of an empirical influence function for detecting
  influential cases in regression.
\newblock \emph{Technometrics}, 22\penalty0 (4):\penalty0 495--508, 1980.
\newblock ISSN 0040-1706.
\newblock \doi{10.1080/00401706.1980.10486199}.

\bibitem[Cook and Sanford(1982)]{cook_inf_2}
R.~D. Cook and W.~Sanford.
\newblock Residuals and influence in regression.
\newblock \emph{Chapman and Hall}, 1982.
\newblock URL \url{http://hdl.handle.net/11299/37076}.

\bibitem[Donoho(2006)]{Donoho:2006:CS:2263438.2272089}
D.~L. Donoho.
\newblock Compressed sensing.
\newblock \emph{IEEE Trans. Inf. Theor.}, 52\penalty0 (4):\penalty0 1289--1306,
  Apr. 2006.
\newblock ISSN 0018-9448.
\newblock \doi{10.1109/TIT.2006.871582}.
\newblock URL \url{https://doi.org/10.1109/TIT.2006.871582}.

\bibitem[Duchi et~al.(2008)Duchi, Shalev-Shwartz, Singer, and
  Chandra]{Duchi:2008:EPL:1390156.1390191}
J.~Duchi, S.~Shalev-Shwartz, Y.~Singer, and T.~Chandra.
\newblock Efficient projections onto the l1-ball for learning in high
  dimensions.
\newblock In \emph{Proceedings of the 25th International Conference on Machine
  Learning}, ICML '08, pages 272--279, New York, NY, USA, 2008. ACM.
\newblock ISBN 978-1-60558-205-4.
\newblock \doi{10.1145/1390156.1390191}.
\newblock URL \url{http://doi.acm.org/10.1145/1390156.1390191}.

\bibitem[Efron(1992)]{efron_jackknife}
B.~Efron.
\newblock Jackknife-after-bootstrap standard errors and influence functions.
\newblock \emph{Journal of the Royal Statistical Society. Series B
  (Methodological)}, 54\penalty0 (1):\penalty0 83--127, 1992.
\newblock ISSN 00359246.
\newblock URL \url{http://www.jstor.org/stable/2345949}.

\bibitem[Giordano et~al.(2018)Giordano, Stephenson, Liu, Jordan, and
  Broderick]{Giordano2018ASA}
R.~Giordano, W.~Stephenson, R.~Liu, M.~I. Jordan, and T.~Broderick.
\newblock A swiss army infinitesimal jackknife.
\newblock In \emph{AISTATS}, 2018.

\bibitem[Giordano et~al.(2019)Giordano, Jordan, and Broderick]{Giordano2019AHS}
R.~Giordano, M.~I. Jordan, and T.~Broderick.
\newblock A higher-order swiss army infinitesimal jackknife.
\newblock \emph{ArXiv}, abs/1907.12116, 2019.

\bibitem[Hayes and Ohrimenko(2019)]{multiparty}
J.~Hayes and O.~Ohrimenko.
\newblock Contamination attacks and mitigation in multi-party machine learning.
\newblock \emph{CoRR}, abs/1901.02402, 2019.
\newblock URL \url{http://arxiv.org/abs/1901.02402}.

\bibitem[Jaeckel(1972)]{infinitesimal_jackknife}
L.~A. Jaeckel.
\newblock The infinitesimal jackknife.
\newblock \emph{Technical Report}, 1:\penalty0 1--35, 06 1972.

\bibitem[James et~al.(2017)James, Lingling, Eric, and van~der Vaart]{highorder}
R.~James, L.~Lingling, T.~Eric, and A.~van~der Vaart.
\newblock Higher order influence functions and minimax estimation of nonlinear
  functionals.
\newblock \emph{Probability and Statistics: Essays in Honor of David A.
  Freedman, 335--421}, abs/1706.03825, 2017.
\newblock URL \url{https://projecteuclid.org/euclid.imsc/1207580092}.

\bibitem[Koh and Liang(2017)]{influence1}
P.~W. Koh and P.~Liang.
\newblock Understanding black-box predictions via influence functions.
\newblock In D.~Precup and Y.~W. Teh, editors, \emph{Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of \emph{Proceedings
  of Machine Learning Research}, pages 1885--1894, International Convention
  Centre, Sydney, Australia, 06--11 Aug 2017. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v70/koh17a.html}.

\bibitem[Koh et~al.(2019{\natexlab{a}})Koh, Ang, Teo, and Liang]{influence2}
P.~W. Koh, K.~Ang, H.~H.~K. Teo, and P.~Liang.
\newblock On the accuracy of influence functions for measuring group effects.
\newblock \emph{CoRR}, abs/1905.13289, 2019{\natexlab{a}}.
\newblock URL \url{http://arxiv.org/abs/1905.13289}.

\bibitem[Koh et~al.(2019{\natexlab{b}})Koh, Steinhardt, and
  Liang]{koh2019stronger}
P.~W. Koh, J.~Steinhardt, and P.~Liang.
\newblock Stronger data poisoning attacks break data sanitization defenses.
\newblock \emph{arXiv preprint arXiv:1811.00741}, 2019{\natexlab{b}}.

\bibitem[Langley(2000)]{langley00}
P.~Langley.
\newblock Crafting papers on machine learning.
\newblock In P.~Langley, editor, \emph{Proceedings of the 17th International
  Conference on Machine Learning (ICML 2000)}, pages 1207--1216, Stanford, CA,
  2000. Morgan Kaufmann.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{mnist}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock In \emph{Proceedings of the IEEE}, volume~86, pages 2278--2324, 1998.
\newblock URL
  \url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665}.

\bibitem[Lin et~al.(2012)Lin, Hu, and Tsai]{finance}
W.-Y. Lin, Y.-H. Hu, and C.-F. Tsai.
\newblock Machine learning in financial crisis prediction: A survey.
\newblock \emph{Trans. Sys. Man Cyber Part C}, 42\penalty0 (4):\penalty0
  421--436, July 2012.
\newblock ISSN 1094-6977.
\newblock \doi{10.1109/TSMCC.2011.2170420}.
\newblock URL \url{https://doi.org/10.1109/TSMCC.2011.2170420}.

\bibitem[Liu and Ye(2009)]{projection1}
J.~Liu and J.~Ye.
\newblock Efficient euclidean projections in linear time.
\newblock In \emph{Proceedings of the 26th Annual International Conference on
  Machine Learning}, ICML '09, pages 657--664, New York, NY, USA, 2009. ACM.
\newblock ISBN 978-1-60558-516-1.
\newblock \doi{10.1145/1553374.1553459}.
\newblock URL \url{http://doi.acm.org/10.1145/1553374.1553459}.

\bibitem[Lundervold and Lundervold(2018)]{medical_imaging}
A.~S. Lundervold and A.~Lundervold.
\newblock An overview of deep learning in medical imaging focusing on {MRI}.
\newblock \emph{CoRR}, abs/1811.10052, 2018.
\newblock URL \url{http://arxiv.org/abs/1811.10052}.

\bibitem[Madras et~al.(2019)Madras, Atwood, and D’Amour]{extrapolation}
D.~Madras, J.~Atwood, and A.~D’Amour.
\newblock Detecting extrapolation with influence functions.
\newblock \emph{ICML Workshop}, 2019.

\bibitem[Pearlmutter(1994)]{Pearlmutter}
B.~A. Pearlmutter.
\newblock Fast exact multiplication by the hessian.
\newblock \emph{Neural Comput.}, 6\penalty0 (1):\penalty0 147--160, Jan. 1994.
\newblock ISSN 0899-7667.
\newblock \doi{10.1162/neco.1994.6.1.147}.
\newblock URL \url{http://dx.doi.org/10.1162/neco.1994.6.1.147}.

\bibitem[Ramirez(2013)]{l1approximation}
C.~Ramirez.
\newblock Why l1 is a good approximation to l0: A geometric explanation.
\newblock \emph{Journal of Uncertain Systems}, 7:\penalty0 203--207, 08 2013.

\bibitem[Schulam and Saria(2019)]{Schulam2019CanYT}
P.~G. Schulam and S.~Saria.
\newblock Can you trust this prediction? auditing pointwise reliability after
  learning.
\newblock In \emph{AISTATS}, 2019.

\bibitem[Sebastiani(2002)]{Sebastiani:2002:MLA:505282.505283}
F.~Sebastiani.
\newblock Machine learning in automated text categorization.
\newblock \emph{ACM Comput. Surv.}, 34\penalty0 (1):\penalty0 1--47, Mar. 2002.
\newblock ISSN 0360-0300.
\newblock \doi{10.1145/505282.505283}.
\newblock URL \url{http://doi.acm.org/10.1145/505282.505283}.

\bibitem[Shewchuk(1994)]{conjugate_gradient}
J.~R. Shewchuk.
\newblock An introduction to the conjugate gradient method without the
  agonizing pain.
\newblock \emph{-}, 1994.

\bibitem[Szeliski(2010)]{Szeliski:2010:CVA:1941882}
R.~Szeliski.
\newblock \emph{Computer Vision: Algorithms and Applications}.
\newblock Springer-Verlag, Berlin, Heidelberg, 1st edition, 2010.
\newblock ISBN 1848829345, 9781848829343.

\bibitem[Wang et~al.(2019)Wang, Ustun, and Calmon]{model_fairness}
H.~Wang, B.~Ustun, and F.~P. Calmon.
\newblock Repairing without retraining: Avoiding disparate impact with
  counterfactual distributions.
\newblock \emph{CoRR}, abs/1901.10501, 2019.
\newblock URL \url{http://arxiv.org/abs/1901.10501}.

\bibitem[Yang et~al.(2019)Yang, Li, Qian, Wilhelmsen, Shen, and Li]{sc-Batch}
Y.~Yang, G.~Li, H.~Qian, K.~C. Wilhelmsen, Y.~Shen, and Y.~Li.
\newblock Smnn: Batch effect correction for single-cell rna-seq data via
  supervised mutual nearest neighbor detection.
\newblock \emph{bioRxiv}, 2019.
\newblock \doi{10.1101/672261}.
\newblock URL \url{https://www.biorxiv.org/content/early/2019/06/17/672261}.

\bibitem[Yeh et~al.(2018)Yeh, Kim, Yen, and Ravikumar]{representer}
C.~Yeh, J.~S. Kim, I.~E. Yen, and P.~Ravikumar.
\newblock Representer point selection for explaining deep neural networks.
\newblock \emph{CoRR}, abs/1811.09720, 2018.
\newblock URL \url{http://arxiv.org/abs/1811.09720}.

\end{thebibliography}
