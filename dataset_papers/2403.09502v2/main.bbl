\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2020)Alayrac, Recasens, Schneider, Arandjelovi{\'c}, Ramapuram, De~Fauw, Smaira, Dieleman, and Zisserman]{alayrac2020self}
Alayrac, J.-B., Recasens, A., Schneider, R., Arandjelovi{\'c}, R., Ramapuram, J., De~Fauw, J., Smaira, L., Dieleman, S., and Zisserman, A.
\newblock {S}elf-{S}upervised {M}ulti{M}odal {V}ersatile {N}etworks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Alwassel et~al.(2020{\natexlab{a}})Alwassel, Mahajan, Korbar, Torresani, Ghanem, and Tran]{alwassel2020self}
Alwassel, H., Mahajan, D., Korbar, B., Torresani, L., Ghanem, B., and Tran, D.
\newblock Self-supervised learning by cross-modal audio-video clustering.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 9758--9770, 2020{\natexlab{a}}.

\bibitem[Alwassel et~al.(2020{\natexlab{b}})Alwassel, Mahajan, Korbar, Torresani, Ghanem, and Tran]{alwassel2020xdc}
Alwassel, H., Mahajan, D., Korbar, B., Torresani, L., Ghanem, B., and Tran, D.
\newblock Self-supervised learning by cross-modal audio-video clustering.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020{\natexlab{b}}.

\bibitem[Arandjelovic \& Zisserman(2017)Arandjelovic and Zisserman]{arandjelovic2017look}
Arandjelovic, R. and Zisserman, A.
\newblock Look, listen and learn.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  609--617, 2017.

\bibitem[Boggust et~al.(2019)Boggust, Audhkhasi, Joshi, Harwath, Thomas, Feris, Gutfreund, Zhang, Torralba, Picheny, et~al.]{boggust2019grounding}
Boggust, A.~W., Audhkhasi, K., Joshi, D., Harwath, D., Thomas, S., Feris, R.~S., Gutfreund, D., Zhang, Y., Torralba, A., Picheny, M., et~al.
\newblock Grounding spoken words in unlabeled video.
\newblock In \emph{CVPR Workshops}, volume~2, 2019.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal, Bojanowski, and Joulin]{caron2021emerging}
Caron, M., Touvron, H., Misra, I., J{\'e}gou, H., Mairal, J., Bojanowski, P., and Joulin, A.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  9650--9660, 2021.

\bibitem[Chen et~al.(2021)Chen, Fan, and Panda]{chen2021crossvit}
Chen, C.-F.~R., Fan, Q., and Panda, R.
\newblock {CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification}.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Xie, Vedaldi, and Zisserman]{chen2020vggsound}
Chen, H., Xie, W., Vedaldi, A., and Zisserman, A.
\newblock Vggsound: A large-scale audio-visual dataset.
\newblock In \emph{IEEE international conference on acoustics, speech and signal processing}, pp.\  721--725. IEEE, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1597--1607. PMLR, 2020{\natexlab{b}}.

\bibitem[Chen \& He(2021)Chen and He]{chen2021exploring}
Chen, X. and He, K.
\newblock Exploring simple siamese representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  15750--15758, 2021.

\bibitem[Dangovski et~al.(2022)Dangovski, Jing, Loh, Han, Srivastava, Cheung, Agrawal, and Soljacic]{dangovski2022equivariant}
Dangovski, R., Jing, L., Loh, C., Han, S., Srivastava, A., Cheung, B., Agrawal, P., and Soljacic, M.
\newblock Equivariant self-supervised learning: Encouraging equivariance in representations.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Devillers \& Lefort(2023)Devillers and Lefort]{devillers2023equimod}
Devillers, A. and Lefort, M.
\newblock Equimod: An equivariance module to improve visual instance discrimination.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{dosovitskiy2021an}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Fayek \& Kumar(2021)Fayek and Kumar]{fayek2020large}
Fayek, H.~M. and Kumar, A.
\newblock Large scale audiovisual learning of sounds with weakly labeled data.
\newblock In \emph{Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence}, IJCAI'20, 2021.
\newblock ISBN 9780999241165.

\bibitem[Fonseca et~al.(2021)Fonseca, Favory, Pons, Font, and Serra]{fonseca2022fsd50k}
Fonseca, E., Favory, X., Pons, J., Font, F., and Serra, X.
\newblock Fsd50k: An open dataset of human-labeled sound events.
\newblock \emph{IEEE/ACM Transactions Audio, Speech and Language Processing}, 30:\penalty0 829â€“852, dec 2021.
\newblock ISSN 2329-9290.
\newblock \doi{10.1109/TASLP.2021.3133208}.
\newblock URL \url{https://doi.org/10.1109/TASLP.2021.3133208}.

\bibitem[Garrido et~al.(2023)Garrido, Najman, and LeCun]{sie2023icml}
Garrido, Q., Najman, L., and LeCun, Y.
\newblock Self-supervised learning of split invariant equivariant representations.
\newblock In \emph{International Conference on Machine Learning}, ICML'23. JMLR.org, 2023.

\bibitem[Gemmeke et~al.(2017)Gemmeke, Ellis, Freedman, Jansen, Lawrence, Moore, Plakal, and Ritter]{gemmeke2017audio}
Gemmeke, J.~F., Ellis, D.~P., Freedman, D., Jansen, A., Lawrence, W., Moore, R.~C., Plakal, M., and Ritter, M.
\newblock Audio set: An ontology and human-labeled dataset for audio events.
\newblock In \emph{IEEE international conference on acoustics, speech and signal processing}, pp.\  776--780. IEEE, 2017.

\bibitem[Georgescu et~al.(2023)Georgescu, Fonseca, Ionescu, Lucic, Schmid, and Arnab]{Georgescu2023ICCV}
Georgescu, M.-I., Fonseca, E., Ionescu, R.~T., Lucic, M., Schmid, C., and Arnab, A.
\newblock Audiovisual masked autoencoders.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  16144--16154, October 2023.

\bibitem[Gong et~al.(2021)Gong, Chung, and Glass]{gong21binterspeech}
Gong, Y., Chung, Y.-A., and Glass, J.
\newblock Ast: Audio spectrogram transformer.
\newblock In \emph{Interspeech}, pp.\  571--575, 2021.

\bibitem[Gong et~al.(2023)Gong, Rouditchenko, Liu, Harwath, Karlinsky, Kuehne, and Glass]{gong2023contrastive}
Gong, Y., Rouditchenko, A., Liu, A.~H., Harwath, D., Karlinsky, L., Kuehne, H., and Glass, J.~R.
\newblock Contrastive audio-visual masked autoencoder.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond, Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar, et~al.]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M., et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 21271--21284, 2020.

\bibitem[Haliassos et~al.(2022)Haliassos, Ma, Mira, Petridis, and Pantic]{haliassos2022jointly}
Haliassos, A., Ma, P., Mira, R., Petridis, S., and Pantic, M.
\newblock Jointly learning visual and auditory speech representations from raw data.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  9729--9738, 2020.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll\'ar, and Girshick]{he2022mae}
He, K., Chen, X., Xie, S., Li, Y., Doll\'ar, P., and Girshick, R.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022.

\bibitem[Huang et~al.(2022)Huang, Xu, Li, Baevski, Auli, Galuba, Metze, and Feichtenhofer]{huang2022masked}
Huang, P.-Y., Xu, H., Li, J.~B., Baevski, A., Auli, M., Galuba, W., Metze, F., and Feichtenhofer, C.
\newblock Masked autoencoders that listen.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Huang et~al.(2023)Huang, Sharma, Xu, Ryali, Fan, Li, Li, Ghosh, Malik, and Feichtenhofer]{huang2023mavil}
Huang, P.-Y., Sharma, V., Xu, H., Ryali, C., Fan, H., Li, Y., Li, S.-W., Ghosh, G., Malik, J., and Feichtenhofer, C.
\newblock {MAV}il: Masked audio-video learners.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Jaegle et~al.(2021)Jaegle, Gimeno, Brock, Vinyals, Zisserman, and Carreira]{jaegle2021perceiver}
Jaegle, A., Gimeno, F., Brock, A., Vinyals, O., Zisserman, A., and Carreira, J.
\newblock Perceiver: General perception with iterative attention.
\newblock In \emph{International Conference on Machine Learning}, pp.\  4651--4664. PMLR, 2021.

\bibitem[Jenni et~al.(2023)Jenni, Black, and Collomosse]{jenni2023audio}
Jenni, S., Black, A., and Collomosse, J.
\newblock Audio-visual contrastive learning with temporal self-supervision.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pp.\  7996--8004, 2023.

\bibitem[Kay et~al.(2017)Kay, Carreira, Simonyan, Zhang, Hillier, Vijayanarasimhan, Viola, Green, Back, Natsev, Suleyman, and Zisserman]{kay2017kinetics}
Kay, W., Carreira, J., Simonyan, K., Zhang, B., Hillier, C., Vijayanarasimhan, S., Viola, F., Green, T., Back, T., Natsev, P., Suleyman, M., and Zisserman, A.
\newblock The kinetics human action video dataset.
\newblock \emph{CoRR}, abs/1705.06950, 2017.
\newblock URL \url{http://arxiv.org/abs/1705.06950}.

\bibitem[Korbar et~al.(2016)Korbar, Tran, and Torresani]{korbar2018coop}
Korbar, B., Tran, D., and Torresani, L.
\newblock Cooperative learning of audio and video models from self-supervised synchronization.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~31, 2016.

\bibitem[Kuehne et~al.(2011)Kuehne, Jhuang, Garrote, Poggio, and Serre]{kuehne2011hmdb}
Kuehne, H., Jhuang, H., Garrote, E., Poggio, T., and Serre, T.
\newblock Hmdb: a large video database for human motion recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  2556--2563. IEEE, 2011.

\bibitem[Lee et~al.(2021)Lee, Lee, Lee, Lee, and Shin]{lee2021improving}
Lee, H., Lee, K., Lee, K., Lee, H., and Shin, J.
\newblock Improving transferability of representations via augmentation-aware self-supervision.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 17710--17722, 2021.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{loshchilov2016sgdr}
Loshchilov, I. and Hutter, F.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Ma et~al.(2021{\natexlab{a}})Ma, Zeng, McDuff, and Song]{ma2021active}
Ma, S., Zeng, Z., McDuff, D., and Song, Y.
\newblock Active contrastive learning of audio-visual video representations.
\newblock In \emph{International Conference on Learning Representations}, 2021{\natexlab{a}}.

\bibitem[Ma et~al.(2021{\natexlab{b}})Ma, Zeng, McDuff, and Song]{ma2021contrastive}
Ma, S., Zeng, Z., McDuff, D., and Song, Y.
\newblock Contrastive learning of global and local video representations.
\newblock In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J.~W. (eds.), \emph{Advances in Neural Information Processing Systems}, 2021{\natexlab{b}}.

\bibitem[Morgado et~al.(2021{\natexlab{a}})Morgado, Misra, and Vasconcelos]{morgado2021robust}
Morgado, P., Misra, I., and Vasconcelos, N.
\newblock Robust audio-visual instance discrimination.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12934--12945, 2021{\natexlab{a}}.

\bibitem[Morgado et~al.(2021{\natexlab{b}})Morgado, Vasconcelos, and Misra]{morgado2021audio}
Morgado, P., Vasconcelos, N., and Misra, I.
\newblock Audio-visual instance discrimination with cross-modal agreement.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12475--12486, 2021{\natexlab{b}}.

\bibitem[Morgado et~al.(2021{\natexlab{c}})Morgado, Vasconcelos, and Misra]{morgadoavidcma}
Morgado, P., Vasconcelos, N., and Misra, I.
\newblock Audio-visual instance discrimination with cross-modal agreement.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021{\natexlab{c}}.

\bibitem[Nagrani et~al.(2021)Nagrani, Yang, Arnab, Jansen, Schmid, and Sun]{nagrani2021attention}
Nagrani, A., Yang, S., Arnab, A., Jansen, A., Schmid, C., and Sun, C.
\newblock Attention bottlenecks for multimodal fusion.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 14200--14213, 2021.

\bibitem[Noroozi \& Favaro(2016)Noroozi and Favaro]{noroozi2016unsupervised}
Noroozi, M. and Favaro, P.
\newblock Unsupervised learning of visual representations by solving jigsaw puzzles.
\newblock In \emph{Proceedings of the European Conference on Computer Vision}, pp.\  69--84. Springer, 2016.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Owens \& Efros(2018)Owens and Efros]{owens2018audio}
Owens, A. and Efros, A.~A.
\newblock Audio-visual scene analysis with self-supervised multisensory features.
\newblock In \emph{Proceedings of the European Conference on Computer Vision}, pp.\  631--648, 2018.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and Le]{park2019specaug}
Park, D.~S., Chan, W., Zhang, Y., Chiu, C.-C., Zoph, B., Cubuk, E.~D., and Le, Q.~V.
\newblock Specaugment: A simple data augmentation method for automatic speech recognition.
\newblock In \emph{Interspeech}, pp.\  2613--2617, 2019.

\bibitem[Patrick et~al.(2021)Patrick, Asano, Kuznetsova, Fong, Henriques, Zweig, and Vedaldi]{Patrick2021ICCV}
Patrick, M., Asano, Y.~M., Kuznetsova, P., Fong, R., Henriques, J.~a.~F., Zweig, G., and Vedaldi, A.
\newblock On compositions of transformations in contrastive self-supervised learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  9577--9587, October 2021.

\bibitem[Piczak(2015)]{piczak2015esc}
Piczak, K.~J.
\newblock Esc: Dataset for environmental sound classification.
\newblock In \emph{Proceedings of the 23rd ACM international conference on Multimedia}, pp.\  1015--1018, 2015.

\bibitem[Recasens et~al.(2021)Recasens, Luc, Alayrac, Wang, Strub, Tallec, Malinowski, P{\u{a}}tr{\u{a}}ucean, Altch{\'e}, Valko, et~al.]{recasens2021broaden}
Recasens, A., Luc, P., Alayrac, J.-B., Wang, L., Strub, F., Tallec, C., Malinowski, M., P{\u{a}}tr{\u{a}}ucean, V., Altch{\'e}, F., Valko, M., et~al.
\newblock Broaden your views for self-supervised video learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  1255--1265, 2021.

\bibitem[Sarkar \& Etemad(2023{\natexlab{a}})Sarkar and Etemad]{sarkar2021crisscross}
Sarkar, P. and Etemad, A.
\newblock Self-supervised audio-visual representation learning with relaxed cross-modal synchronicity.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 2023{\natexlab{a}}.

\bibitem[Sarkar \& Etemad(2023{\natexlab{b}})Sarkar and Etemad]{sarkar2023self}
Sarkar, P. and Etemad, A.
\newblock Self-supervised audio-visual representation learning with relaxed cross-modal synchronicity.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pp.\  9723--9732, 2023{\natexlab{b}}.

\bibitem[Sarkar \& Etemad(2024)Sarkar and Etemad]{sarkar2023xkd}
Sarkar, P. and Etemad, A.
\newblock Xkd: Cross-modal knowledge distillation with domain alignment for video representation learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 2024.

\bibitem[Soomro et~al.(2012)Soomro, Zamir, and Shah]{soomro2012ucf101}
Soomro, K., Zamir, A.~R., and Shah, M.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the wild.
\newblock \emph{arXiv preprint arXiv:1212.0402}, 2012.

\bibitem[Tong et~al.(2022)Tong, Song, Wang, and Wang]{tong2022videomae}
Tong, Z., Song, Y., Wang, J., and Wang, L.
\newblock Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 10078--10093, 2022.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Wang et~al.(2021)Wang, Luc, Recasens, Alayrac, and van~den Oord]{wang2021multimodal}
Wang, L., Luc, P., Recasens, A., Alayrac, J., and van~den Oord, A.
\newblock Multimodal self-supervised learning of general audio representations.
\newblock \emph{CoRR}, abs/2104.12807, 2021.

\bibitem[Wang et~al.(2020)Wang, Tran, and Feiszli]{wang2020makes}
Wang, W., Tran, D., and Feiszli, M.
\newblock What makes training multi-modal classification networks hard?
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12695--12705, 2020.

\bibitem[Warden(2018)]{Warden2018SpeechCA}
Warden, P.
\newblock Speech commands: A dataset for limited-vocabulary speech recognition.
\newblock \emph{ArXiv}, abs/1804.03209, 2018.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:4719239}.

\bibitem[Xu et~al.(2016)Xu, Mei, Yao, and Rui]{xu2016msr}
Xu, J., Mei, T., Yao, T., and Rui, Y.
\newblock Msr-vtt: A large video description dataset for bridging video and language.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  5288--5296, 2016.

\end{thebibliography}
