\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Blattmann et~al.(2023{\natexlab{a}})Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023stable}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023{\natexlab{a}}.

\bibitem[Blattmann et~al.(2023{\natexlab{b}})Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{blattmann2023align}
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung~Wook Kim, Sanja Fidler, and Karsten Kreis.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{CVPR}, 2023{\natexlab{b}}.

\bibitem[Cao et~al.(2013)Cao, Barrett, Barbu, Narayanaswamy, Yu, Michaux, Lin, Dickinson, Mark~Siskind, and Wang]{cao2013recognize}
Yu~Cao, Daniel Barrett, Andrei Barbu, Siddharth Narayanaswamy, Haonan Yu, Aaron Michaux, Yuewei Lin, Sven Dickinson, Jeffrey Mark~Siskind, and Song Wang.
\newblock Recognize human activities from partially observed videos.
\newblock In \emph{CVPR}, 2013.

\bibitem[Ceylan et~al.(2023)Ceylan, Huang, and Mitra]{ceylan2023pix2video}
Duygu Ceylan, Chun-Hao~P Huang, and Niloy~J Mitra.
\newblock Pix2video: Video editing using image diffusion.
\newblock In \emph{ICCV}, 2023.

\bibitem[Chai et~al.(2023)Chai, Guo, Wang, and Lu]{chai2023stablevideo}
Wenhao Chai, Xun Guo, Gaoang Wang, and Yan Lu.
\newblock Stablevideo: Text-driven consistency-aware diffusion video editing.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 23040--23050, 2023.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Dong, Wang, Yang, Duan, Su, and Zhu]{chen2023robust}
Huanran Chen, Yinpeng Dong, Zhengyi Wang, Xiao Yang, Chengqi Duan, Hang Su, and Jun Zhu.
\newblock Robust classification via a single diffusion model.
\newblock \emph{arXiv preprint arXiv:2305.15241}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Sun, Song, and Luo]{chen2023diffusiondet}
Shoufa Chen, Peize Sun, Yibing Song, and Ping Luo.
\newblock Diffusiondet: Diffusion model for object detection.
\newblock In \emph{ICCV}, 2023{\natexlab{b}}.

\bibitem[Chen et~al.(2024)Chen, Liu, Xie, and He]{chen2024deconstructing}
Xinlei Chen, Zhuang Liu, Saining Xie, and Kaiming He.
\newblock Deconstructing denoising diffusion models for self-supervised learning.
\newblock \emph{arXiv preprint arXiv:2401.14404}, 2024.

\bibitem[Clark and Jaini(2024)]{clark2024text}
Kevin Clark and Priyank Jaini.
\newblock Text-to-image diffusion models are zero shot classifiers.
\newblock In \emph{NeurIPS}, 2024.

\bibitem[Damen et~al.(2022)Damen, Doughty, Farinella, Furnari, Kazakos, Ma, Moltisanti, Munro, Perrett, Price, et~al.]{damen2022rescaling}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Antonino Furnari, Evangelos Kazakos, Jian Ma, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, et~al.
\newblock Rescaling egocentric vision: Collection, pipeline and challenges for epic-kitchens-100.
\newblock \emph{IJCV}, 2022.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Esser et~al.(2023)Esser, Chiu, Atighehchian, Granskog, and Germanidis]{esser2023structure}
Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, and Anastasis Germanidis.
\newblock Structure and content-guided video synthesis with diffusion models.
\newblock In \emph{ICCV}, 2023.

\bibitem[Gao et~al.(2022)Gao, Tan, Wu, and Li]{gao2022simvp}
Zhangyang Gao, Cheng Tan, Lirong Wu, and Stan~Z Li.
\newblock Simvp: Simpler yet better video prediction.
\newblock In \emph{CVPR}, 2022.

\bibitem[Ge et~al.(2022)Ge, Hayes, Yang, Yin, Pang, Jacobs, Huang, and Parikh]{ge2022long}
Songwei Ge, Thomas Hayes, Harry Yang, Xi~Yin, Guan Pang, David Jacobs, Jia-Bin Huang, and Devi Parikh.
\newblock Long video generation with time-agnostic vqgan and time-sensitive transformer.
\newblock In \emph{ECCV}, 2022.

\bibitem[Ge et~al.(2023)Ge, Nah, Liu, Poon, Tao, Catanzaro, Jacobs, Huang, Liu, and Balaji]{ge2023preserve}
Songwei Ge, Seungjun Nah, Guilin Liu, Tyler Poon, Andrew Tao, Bryan Catanzaro, David Jacobs, Jia-Bin Huang, Ming-Yu Liu, and Yogesh Balaji.
\newblock Preserve your own correlation: A noise prior for video diffusion models.
\newblock In \emph{ICCV}, 2023.

\bibitem[Girdhar et~al.(2023)Girdhar, El-Nouby, Singh, Alwala, Joulin, and Misra]{girdhar2023omnimae}
Rohit Girdhar, Alaaeldin El-Nouby, Mannat Singh, Kalyan~Vasudev Alwala, Armand Joulin, and Ishan Misra.
\newblock Omnimae: Single model masked pretraining on images and videos.
\newblock In \emph{CVPR}, 2023.

\bibitem[Goyal et~al.(2017)Goyal, Ebrahimi~Kahou, Michalski, Materzynska, Westphal, Kim, Haenel, Fruend, Yianilos, Mueller-Freitag, et~al.]{goyal2017something}
Raghav Goyal, Samira Ebrahimi~Kahou, Vincent Michalski, Joanna Materzynska, Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos, Moritz Mueller-Freitag, et~al.
\newblock The" something something" video database for learning and evaluating visual common sense.
\newblock In \emph{ICCV}, 2017.

\bibitem[Gu et~al.(2023)Gu, Wen, Ye, Song, and Gao]{gu2023seer}
Xianfan Gu, Chuan Wen, Weirui Ye, Jiaming Song, and Yang Gao.
\newblock Seer: Language instructed video prediction with latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2303.14897}, 2023.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{CVPR}, 2022.

\bibitem[Ho and Salimans(2022)]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[H{\"o}ppe et~al.(2022)H{\"o}ppe, Mehrjou, Bauer, Nielsen, and Dittadi]{hoppe2022diffusion}
Tobias H{\"o}ppe, Arash Mehrjou, Stefan Bauer, Didrik Nielsen, and Andrea Dittadi.
\newblock Diffusion models for video prediction and infilling.
\newblock \emph{arXiv preprint arXiv:2206.07696}, 2022.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and Laine]{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and Irani]{kawar2023imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In \emph{CVPR}, 2023.

\bibitem[Kay et~al.(2017)Kay, Carreira, Simonyan, Zhang, Hillier, Vijayanarasimhan, Viola, Green, Back, Natsev, et~al.]{kay2017kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
\newblock The kinetics human action video dataset.
\newblock \emph{arXiv preprint arXiv:1705.06950}, 2017.

\bibitem[Lan et~al.(2014)Lan, Chen, and Savarese]{lan2014hierarchical}
Tian Lan, Tsung-Chuan Chen, and Silvio Savarese.
\newblock A hierarchical representation for future action prediction.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part III 13}, 2014.

\bibitem[Liew et~al.(2023)Liew, Yan, Zhang, Xu, and Feng]{liew2023magicedit}
Jun~Hao Liew, Hanshu Yan, Jianfeng Zhang, Zhongcong Xu, and Jiashi Feng.
\newblock Magicedit: High-fidelity and temporally coherent video editing.
\newblock \emph{arXiv preprint arXiv:2308.14749}, 2023.

\bibitem[Lu et~al.(2023)Lu, Yang, Fei, Huo, Lu, Luo, and Ding]{lu2023vdt}
Haoyu Lu, Guoxing Yang, Nanyi Fei, Yuqi Huo, Zhiwu Lu, Ping Luo, and Mingyu Ding.
\newblock Vdt: General-purpose video diffusion transformers via mask modeling.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[Luo et~al.(2023)Luo, Chen, Zhang, Huang, Wang, Shen, Zhao, Zhou, and Tan]{luo2023videofusion}
Zhengxiong Luo, Dayou Chen, Yingya Zhang, Yan Huang, Liang Wang, Yujun Shen, Deli Zhao, Jingren Zhou, and Tieniu Tan.
\newblock Videofusion: Decomposed diffusion models for high-quality video generation.
\newblock In \emph{CVPR}, 2023.

\bibitem[Molad et~al.(2023)Molad, Horwitz, Valevski, Acha, Matias, Pritch, Leviathan, and Hoshen]{molad2023dreamix}
Eyal Molad, Eliahu Horwitz, Dani Valevski, Alex~Rav Acha, Yossi Matias, Yael Pritch, Yaniv Leviathan, and Yedid Hoshen.
\newblock Dreamix: Video diffusion models are general video editors.
\newblock \emph{arXiv preprint arXiv:2302.01329}, 2023.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{ICML}, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}, 2022.

\bibitem[Ryali et~al.(2023)Ryali, Hu, Bolya, Wei, Fan, Huang, Aggarwal, Chowdhury, Poursaeed, Hoffman, et~al.]{ryali2023hiera}
Chaitanya Ryali, Yuan-Ting Hu, Daniel Bolya, Chen Wei, Haoqi Fan, Po-Yao Huang, Vaibhav Aggarwal, Arkabandhu Chowdhury, Omid Poursaeed, Judy Hoffman, et~al.
\newblock Hiera: A hierarchical vision transformer without the bells-and-whistles.
\newblock In \emph{ICML}, 2023.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[Soomro et~al.(2012)Soomro, Zamir, and Shah]{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the wild.
\newblock \emph{arXiv preprint arXiv:1212.0402}, 2012.

\bibitem[Srivastava and Sharma(2024{\natexlab{a}})]{srivastava2024omnivec}
Siddharth Srivastava and Gaurav Sharma.
\newblock Omnivec: Learning robust representations with cross modal sharing.
\newblock In \emph{WACV}, 2024{\natexlab{a}}.

\bibitem[Srivastava and Sharma(2024{\natexlab{b}})]{srivastava2024omnivec2}
Siddharth Srivastava and Gaurav Sharma.
\newblock Omnivec2-a novel transformer based network for large scale multimodal and multitask learning.
\newblock In \emph{CVPR}, 2024{\natexlab{b}}.

\bibitem[Stergiou and Damen(2023)]{stergiou2023wisdom}
Alexandros Stergiou and Dima Damen.
\newblock The wisdom of crowds: Temporal progressive attention for early action prediction.
\newblock In \emph{CVPR}, 2023.

\bibitem[Tang et~al.(2023)Tang, Jia, Wang, Phoo, and Hariharan]{tang2023emergent}
Luming Tang, Menglin Jia, Qianqian Wang, Cheng~Perng Phoo, and Bharath Hariharan.
\newblock Emergent correspondence from image diffusion.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Tong et~al.(2022)Tong, Song, Wang, and Wang]{tong2022videomae}
Zhan Tong, Yibing Song, Jue Wang, and Limin Wang.
\newblock Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Unterthiner et~al.(2018)Unterthiner, Van~Steenkiste, Kurach, Marinier, Michalski, and Gelly]{unterthiner2018towards}
Thomas Unterthiner, Sjoerd Van~Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly.
\newblock Towards accurate generative models of video: A new metric \& challenges.
\newblock \emph{arXiv preprint arXiv:1812.01717}, 2018.

\bibitem[Voleti et~al.(2022)Voleti, Jolicoeur-Martineau, and Pal]{voleti2022mcvd}
Vikram Voleti, Alexia Jolicoeur-Martineau, and Chris Pal.
\newblock Mcvd-masked conditional video diffusion for prediction, generation, and interpolation.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Li, Zhang, Xu, Zhou, Yu, Sheng, and Xu]{wang2023diffusion}
Jinglong Wang, Xiawei Li, Jing Zhang, Qingyuan Xu, Qin Zhou, Qian Yu, Lu~Sheng, and Dong Xu.
\newblock Diffusion model is secretly a training-free open vocabulary semantic segmenter.
\newblock \emph{arXiv preprint arXiv:2309.02773}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Chen, Wu, Chen, Dai, Liu, Yuan, and Jiang]{wang2023masked}
Rui Wang, Dongdong Chen, Zuxuan Wu, Yinpeng Chen, Xiyang Dai, Mengchen Liu, Lu~Yuan, and Yu-Gang Jiang.
\newblock Masked video distillation: Rethinking masked feature modeling for self-supervised video representation learning.
\newblock In \emph{CVPR}, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2022)Wang, Li, Li, He, Huang, Zhao, Zhang, Xu, Liu, Wang, et~al.]{wang2022internvideo}
Yi~Wang, Kunchang Li, Yizhuo Li, Yinan He, Bingkun Huang, Zhiyu Zhao, Hongjie Zhang, Jilan Xu, Yi~Liu, Zun Wang, et~al.
\newblock Internvideo: General video foundation models via generative and discriminative learning.
\newblock \emph{arXiv preprint arXiv:2212.03191}, 2022.

\bibitem[Wang et~al.(2024)Wang, Li, Li, Yu, He, Chen, Pei, Zheng, Xu, Wang, et~al.]{wang2024internvideo2}
Yi~Wang, Kunchang Li, Xinhao Li, Jiashuo Yu, Yinan He, Guo Chen, Baoqi Pei, Rongkun Zheng, Jilan Xu, Zun Wang, et~al.
\newblock Internvideo2: Scaling video foundation models for multimodal video understanding.
\newblock \emph{arXiv preprint arXiv:2403.15377}, 2024.

\bibitem[Wei et~al.(2022)Wei, Fan, Xie, Wu, Yuille, and Feichtenhofer]{wei2022masked}
Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, and Christoph Feichtenhofer.
\newblock Masked feature prediction for self-supervised visual pre-training.
\newblock In \emph{CVPR}, 2022.

\bibitem[Weng et~al.(2023{\natexlab{a}})Weng, Wu, Li, Chen, and Jiang]{weng2023hcms}
Zejia Weng, Zuxuan Wu, Hengduo Li, Jingjing Chen, and Yu-Gang Jiang.
\newblock Hcms: Hierarchical and conditional modality selection for efficient video recognition.
\newblock \emph{ACM TOMM}, 2023{\natexlab{a}}.

\bibitem[Weng et~al.(2023{\natexlab{b}})Weng, Yang, Li, Wu, and Jiang]{weng2023open}
Zejia Weng, Xitong Yang, Ang Li, Zuxuan Wu, and Yu-Gang Jiang.
\newblock Open-vclip: Transforming clip to an open-vocabulary video model via interpolated weight optimization.
\newblock In \emph{ICML}, 2023{\natexlab{b}}.

\bibitem[Wu et~al.(2023)Wu, Ge, Wang, Lei, Gu, Shi, Hsu, Shan, Qie, and Shou]{wu2023tune}
Jay~Zhangjie Wu, Yixiao Ge, Xintao Wang, Stan~Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, and Mike~Zheng Shou.
\newblock Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation.
\newblock In \emph{ICCV}, 2023.

\bibitem[Wu et~al.(2024)Wu, Weng, Peng, Yang, Li, Davis, and Jiang]{wu2024building}
Zuxuan Wu, Zejia Weng, Wujian Peng, Xitong Yang, Ang Li, Larry~S Davis, and Yu-Gang Jiang.
\newblock Building an open-vocabulary video clip model with better architectures, optimization and data.
\newblock \emph{TPAMI}, 2024.

\bibitem[Xing et~al.(2023{\natexlab{a}})Xing, Dai, Hu, Wu, and Jiang]{xing2023simda}
Zhen Xing, Qi~Dai, Han Hu, Zuxuan Wu, and Yu-Gang Jiang.
\newblock Simda: Simple diffusion adapter for efficient video generation.
\newblock \emph{arXiv preprint arXiv:2308.09710}, 2023{\natexlab{a}}.

\bibitem[Xing et~al.(2023{\natexlab{b}})Xing, Dai, Zhang, Zhang, Hu, Wu, and Jiang]{vidiff}
Zhen Xing, Qi~Dai, Zihao Zhang, Hui Zhang, Han Hu, Zuxuan Wu, and Yu-Gang Jiang.
\newblock Vidiff: Translating videos via multi-modal instructions with diffusion models.
\newblock \emph{arXiv preprint arXiv:2311.18837}, 2023{\natexlab{b}}.

\bibitem[Xing et~al.(2023{\natexlab{c}})Xing, Feng, Chen, Dai, Hu, Xu, Wu, and Jiang]{xing2023survey}
Zhen Xing, Qijun Feng, Haoran Chen, Qi~Dai, Han Hu, Hang Xu, Zuxuan Wu, and Yu-Gang Jiang.
\newblock A survey on video diffusion models.
\newblock \emph{ACM Computing Surveys}, 2023{\natexlab{c}}.

\bibitem[Xu et~al.(2023)Xu, Liu, Vahdat, Byeon, Wang, and De~Mello]{xu2023open}
Jiarui Xu, Sifei Liu, Arash Vahdat, Wonmin Byeon, Xiaolong Wang, and Shalini De~Mello.
\newblock Open-vocabulary panoptic segmentation with text-to-image diffusion models.
\newblock In \emph{CVPR}, 2023.

\bibitem[Ye and Bilodeau(2024)]{ye2024stdiff}
Xi~Ye and Guillaume-Alexandre Bilodeau.
\newblock Stdiff: Spatio-temporal diffusion for continuous stochastic video prediction.
\newblock In \emph{AAAI}, 2024.

\bibitem[Zhang et~al.(2023)Zhang, Wang, Wu, and Jiang]{zhang2023diffusionad}
Hui Zhang, Zheng Wang, Zuxuan Wu, and Yu-Gang Jiang.
\newblock Diffusionad: Denoising diffusion for anomaly detection.
\newblock \emph{arXiv preprint arXiv:2303.08730}, 2023.

\end{thebibliography}
