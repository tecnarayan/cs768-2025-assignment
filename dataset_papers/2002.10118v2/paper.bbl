\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., and
  Man{\'e}, D.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Arora et~al.(2018)Arora, Basu, Mianjy, and
  Mukherjee]{arora2018understanding}
Arora, R., Basu, A., Mianjy, P., and Mukherjee, A.
\newblock Understanding deep neural networks with rectified linear units.
\newblock In \emph{ICLR}, 2018.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell_weight_2015}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural networks.
\newblock In \emph{ICML}, 2015.

\bibitem[Brier(1950)]{brier1950verification}
Brier, G.~W.
\newblock Verification of forecasts expressed in terms of probability.
\newblock \emph{Monthly weather review}, 78\penalty0 (1), 1950.

\bibitem[Brosse et~al.(2020)Brosse, Riquelme, Martin, Gelly, and
  Moulines]{brosse2020last}
Brosse, N., Riquelme, C., Martin, A., Gelly, S., and Moulines, {\'E}.
\newblock On last-layer algorithms for classification: Decoupling
  representation from uncertainty estimation.
\newblock \emph{arXiv preprint arXiv:2001.08049}, 2020.

\bibitem[Dangel et~al.(2020)Dangel, Kunstner, and Hennig]{dangel2020backpack}
Dangel, F., Kunstner, F., and Hennig, P.
\newblock {BackPACK: Packing more into Backprop}.
\newblock In \emph{ICLR}, 2020.

\bibitem[Franchi et~al.(2019)Franchi, Bursuc, Aldea, Dubuisson, and
  Bloch]{franchi2019tradi}
Franchi, G., Bursuc, A., Aldea, E., Dubuisson, S., and Bloch, I.
\newblock {TRADI: Tracking deep neural network weight distributions}.
\newblock \emph{arXiv preprint arXiv:1912.11316}, 2019.

\bibitem[Gal(2016)]{gal2016uncertainty}
Gal, Y.
\newblock Uncertainty in deep learning.
\newblock \emph{University of Cambridge}, 2016.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{ICML}, 2016.

\bibitem[Gardner et~al.(2018)Gardner, Pleiss, Bindel, Weinberger, and
  Wilson]{gardner2018gpytorch}
Gardner, J.~R., Pleiss, G., Bindel, D., Weinberger, K.~Q., and Wilson, A.~G.
\newblock {GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU
  Acceleration}.
\newblock In \emph{NIPS}, 2018.

\bibitem[Gast \& Roth(2018)Gast and Roth]{gast2018lightweight}
Gast, J. and Roth, S.
\newblock Lightweight probabilistic deep networks.
\newblock In \emph{CVPR}, 2018.

\bibitem[Gelman et~al.(2008)Gelman, Jakulin, Pittau, Su,
  et~al.]{gelman2008weakly}
Gelman, A., Jakulin, A., Pittau, M.~G., Su, Y.-S., et~al.
\newblock A weakly informative default prior distribution for logistic and
  other regression models.
\newblock \emph{The annals of applied statistics}, 2\penalty0 (4), 2008.

\bibitem[Gibbs(1998)]{gibbs1998bayesian}
Gibbs, M.
\newblock \emph{Bayesian Gaussian processes for regression and classification}.
\newblock PhD thesis, University of Cambridge, 1998.

\bibitem[Graves(2011)]{graves_practical_2011}
Graves, A.
\newblock Practical {Variational} {Inference} for {Neural} {Networks}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}
  24}, pp.\  2348--2356. 2011.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo17calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Gupta \& Nagar(1999)Gupta and Nagar]{gupta1999matrix}
Gupta, A.~K. and Nagar, D.~K.
\newblock \emph{Matrix variate distributions}.
\newblock Chapman and Hall/CRC, 1999.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Hein et~al.(2019)Hein, Andriushchenko, and Bitterwolf]{hein2019relu}
Hein, M., Andriushchenko, M., and Bitterwolf, J.
\newblock Why relu networks yield high-confidence predictions far away from the
  training data and how to mitigate the problem.
\newblock In \emph{CVPR}, 2019.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and Gimpel]{hendrycks17baseline}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{ICLR}, 2017.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, and
  Dietterich]{hendrycks2018deep}
Hendrycks, D., Mazeika, M., and Dietterich, T.
\newblock Deep anomaly detection with outlier exposure.
\newblock In \emph{ICLR}, 2019.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{CVPR}, 2017.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{NIPS}, 2017.

\bibitem[Liang et~al.(2018)Liang, Li, and Srikant]{liang2018enhancing}
Liang, S., Li, Y., and Srikant, R.
\newblock Enhancing the reliability of out-of-distribution image detection in
  neural networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Liu et~al.(2019)Liu, Li, Wu, and Hsieh]{liu2018advbnn}
Liu, X., Li, Y., Wu, C., and Hsieh, C.-J.
\newblock Adv-{BNN}: Improved adversarial defense through robust bayesian
  neural network.
\newblock In \emph{ICLR}, 2019.

\bibitem[Louizos \& Welling(2016)Louizos and Welling]{louizos_structured_2016}
Louizos, C. and Welling, M.
\newblock Structured and efficient variational deep learning with matrix
  gaussian posteriors.
\newblock In \emph{ICML}, 2016.

\bibitem[Louizos \& Welling(2017)Louizos and
  Welling]{louizos2017multiplicative}
Louizos, C. and Welling, M.
\newblock Multiplicative normalizing flows for variational {B}ayesian neural
  networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Lu et~al.(2020)Lu, Ie, and Sha]{lu2020uncertainty}
Lu, Z., Ie, E., and Sha, F.
\newblock {Uncertainty Estimation with Infinitesimal Jackknife, Its
  Distribution and Mean-Field Approximation}.
\newblock \emph{arXiv preprint arXiv:2006.07584}, 2020.

\bibitem[MacKay(1992{\natexlab{a}})]{mackay1992evidence}
MacKay, D.~J.
\newblock The evidence framework applied to classification networks.
\newblock \emph{Neural computation}, 1992{\natexlab{a}}.

\bibitem[MacKay(1992{\natexlab{b}})]{mackay1992practical}
MacKay, D.~J.
\newblock A practical bayesian framework for backpropagation networks.
\newblock \emph{Neural computation}, 4\penalty0 (3):\penalty0 448--472,
  1992{\natexlab{b}}.

\bibitem[MacKay(1995)]{mackay1995probable}
MacKay, D.~J.
\newblock Probable networks and plausible predictions—a review of practical
  bayesian methods for supervised neural networks.
\newblock \emph{Network: computation in neural systems}, 1995.

\bibitem[Maddox et~al.(2019)Maddox, Izmailov, Garipov, Vetrov, and
  Wilson]{maddox2019simple}
Maddox, W.~J., Izmailov, P., Garipov, T., Vetrov, D.~P., and Wilson, A.~G.
\newblock A simple baseline for bayesian uncertainty in deep learning.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Malinin \& Gales(2018)Malinin and Gales]{malinin2018predictive}
Malinin, A. and Gales, M.
\newblock Predictive uncertainty estimation via prior networks.
\newblock In \emph{NIPS}, 2018.

\bibitem[Malinin \& Gales(2019)Malinin and Gales]{malinin2019reverse}
Malinin, A. and Gales, M.
\newblock Reverse kl-divergence training of prior networks: Improved
  uncertainty and adversarial robustness.
\newblock In \emph{NIPS}, 2019.

\bibitem[Martens \& Grosse(2015)Martens and Grosse]{martens2015optimizing}
Martens, J. and Grosse, R.
\newblock Optimizing neural networks with kronecker-factored approximate
  curvature.
\newblock In \emph{International conference on machine learning}, pp.\
  2408--2417, 2015.

\bibitem[Meinke \& Hein(2020)Meinke and Hein]{meinke2020towards}
Meinke, A. and Hein, M.
\newblock Towards neural networks that provably know when they don't know.
\newblock In \emph{ICLR}, 2020.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and
  Hauskrecht]{naeini2015obtaining}
Naeini, M.~P., Cooper, G., and Hauskrecht, M.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{AAAI}, 2015.

\bibitem[Neal(1996)]{neal1996priors}
Neal, R.~M.
\newblock Priors for infinite networks.
\newblock In \emph{Bayesian Learning for Neural Networks}. Springer, 1996.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Nguyen, A., Yosinski, J., and Clune, J.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{CVPR}, 2015.

\bibitem[Ober \& Rasmussen(2019)Ober and Rasmussen]{ober2019benchmarking}
Ober, S.~W. and Rasmussen, C.~E.
\newblock Benchmarking the neural linear model for regression.
\newblock \emph{arXiv preprint arXiv:1912.08416}, 2019.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{ovadia2019can}
Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
  J., Lakshminarayanan, B., and Snoek, J.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Platt et~al.(1999)]{platt1999probabilistic}
Platt, J. et~al.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock \emph{Advances in large margin classifiers}, 10\penalty0
  (3):\penalty0 61--74, 1999.

\bibitem[Riquelme et~al.(2018)Riquelme, Tucker, and Snoek]{riquelme2018deep}
Riquelme, C., Tucker, G., and Snoek, J.
\newblock Deep bayesian bandits showdown: An empirical comparison of bayesian
  deep networks for thompson sampling.
\newblock In \emph{ICLR}, 2018.

\bibitem[Ritter et~al.(2018)Ritter, Botev, and Barber]{ritter_scalable_2018}
Ritter, H., Botev, A., and Barber, D.
\newblock A scalable laplace approximation for neural networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Sensoy et~al.(2018)Sensoy, Kaplan, and Kandemir]{sensoy2018evidential}
Sensoy, M., Kaplan, L., and Kandemir, M.
\newblock Evidential deep learning to quantify classification uncertainty.
\newblock In \emph{NIPS}, 2018.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{snoek2015scalable}
Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N.,
  Patwary, M., Prabhat, M., and Adams, R.
\newblock Scalable bayesian optimization using deep neural networks.
\newblock In \emph{ICML}, 2015.

\bibitem[Spiegelhalter \& Lauritzen(1990)Spiegelhalter and
  Lauritzen]{spiegelhalter1990sequential}
Spiegelhalter, D.~J. and Lauritzen, S.~L.
\newblock Sequential updating of conditional probabilities on directed
  graphical structures.
\newblock \emph{Networks}, 1990.

\bibitem[Wenger et~al.(2019)Wenger, Kjellström, and
  Triebel]{wenger2019nonparametric}
Wenger, J., Kjellström, H., and Triebel, R.
\newblock Non-parametric calibration for classification.
\newblock \emph{arXiv preprint arXiv:1906.04933}, 2019.

\bibitem[Wilson et~al.(2016{\natexlab{a}})Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016deep}
Wilson, A.~G., Hu, Z., Salakhutdinov, R., and Xing, E.~P.
\newblock Deep kernel learning.
\newblock In \emph{AISTATS}, 2016{\natexlab{a}}.

\bibitem[Wilson et~al.(2016{\natexlab{b}})Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016stochastic}
Wilson, A.~G., Hu, Z., Salakhutdinov, R.~R., and Xing, E.~P.
\newblock Stochastic variational deep kernel learning.
\newblock In \emph{NIPS}, 2016{\natexlab{b}}.

\bibitem[Wu et~al.(2019)Wu, Nowozin, Meeds, Turner, Hernandez-Lobato, and
  Gaunt]{wu2018deterministic}
Wu, A., Nowozin, S., Meeds, E., Turner, R.~E., Hernandez-Lobato, J.~M., and
  Gaunt, A.~L.
\newblock Deterministic variational inference for robust bayesian neural
  networks.
\newblock In \emph{ICLR}, 2019.

\bibitem[Zhang et~al.(2018)Zhang, Sun, Duvenaud, and
  Grosse]{DBLP:journals/corr/abs-1712-02390}
Zhang, G., Sun, S., Duvenaud, D., and Grosse, R.
\newblock Noisy natural gradient as variational inference.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, pp.\  5852--5861, 2018.

\end{thebibliography}
