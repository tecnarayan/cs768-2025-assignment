\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anthony \& Bartlett(1999)Anthony and Bartlett]{Anthony1999}
Anthony, M. and Bartlett, P.
\newblock Neural network learning: Theoretical foundations.
\newblock 1999.

\bibitem[Arora et~al.(2018)Arora, Basu, Mianjy, and Mukherjee]{Arora2018}
Arora, R., Basu, A., Mianjy, P., and Mukherjee, A.
\newblock Understanding deep neural networks with rectified linear units.
\newblock In \emph{ICLR}, 2018.

\bibitem[Balas(1979)]{DP}
Balas, E.
\newblock Disjunctive programming.
\newblock \emph{Annals of Discrete Mathematics}, \penalty0 (5):\penalty0 3--51,
  1979.

\bibitem[Balas et~al.(1993)Balas, Ceria, and Cornu\'ejols]{CGLP}
Balas, E., Ceria, S., and Cornu\'ejols, G.
\newblock A lift-and-project cutting plane algorithm for mixed 0--1 programs.
\newblock \emph{Mathematical Programming}, 58:\penalty0 295--324, 1993.

\bibitem[Bianchini \& Scarselli(2014)Bianchini and Scarselli]{Bianchini2014}
Bianchini, M. and Scarselli, F.
\newblock On the complexity of neural network classifiers: A comparison between
  shallow and deep architectures.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  2014.

\bibitem[Camm et~al.(1990)Camm, Raturi, and Tsubakitani]{BigM}
Camm, J.~D., Raturi, A.~S., and Tsubakitani, S.
\newblock Cutting big {M} down to size.
\newblock \emph{Interfaces}, 20\penalty0 (5):\penalty0 61--66, 1990.

\bibitem[Cheng et~al.(2017)Cheng, N{\"u}hrenberg, and Ruess]{Cheng2017}
Cheng, C.-H., N{\"u}hrenberg, G., and Ruess, H.
\newblock Maximum resilience of artificial neural networks.
\newblock In \emph{ATVA}, pp.\  251--268, 2017.

\bibitem[Ciresan et~al.(2012)Ciresan, Meier, Masci, and
  Schmidhuber]{Ciresan2012}
Ciresan, D., Meier, U., Masci, J., and Schmidhuber, J.
\newblock Multi column deep neural network for traffic sign classification.
\newblock \emph{Neural Networks}, 32:\penalty0 333--338, 2012.

\bibitem[Cybenko(1989)]{Cybenko1989}
Cybenko, G.
\newblock Approximation by superpositions of a sigmoidal function.
\newblock \emph{Mathematics of Control, Signals and Systems}, 2\penalty0
  (4):\penalty0 303--314, 1989.

\bibitem[Danna et~al.(2007)Danna, Fenelon, Gu, and Wunderling]{Danna1}
Danna, E., Fenelon, M., Gu, Z., and Wunderling, R.
\newblock Generating multiple solutions for mixed integer programming problems.
\newblock In \emph{IPCO}, pp.\  280--294. 2007.

\bibitem[Delalleau \& Bengio(2011)Delalleau and Bengio]{Delalleau2011}
Delalleau, O. and Bengio, Y.
\newblock Shallow vs. deep sum-product networks.
\newblock In \emph{NIPS}, 2011.

\bibitem[Eldan \& Shamir(2016)Eldan and Shamir]{Eldan2015}
Eldan, R. and Shamir, O.
\newblock The power of depth for feedforward neural networks.
\newblock In \emph{Conference on Learning Theory}, pp.\  907--940, 2016.

\bibitem[Fourier(1826)]{Fourier}
Fourier, J.
\newblock Solution dâ€™une question particuli\'ere du calcul des
  in\'egalit\'es.
\newblock \emph{Nouveau Bulletin des Sciences par la Soci\'et\'e Philomatique
  de Paris}, pp.\  317--319, 1826.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Warde-Farley, Mirza, Courville, and
  Bengio]{Goodfellow2013}
Goodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y.
\newblock Maxout networks.
\newblock In \emph{ICML}, 2013.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He2016DeepRL}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Hinton et~al.(2012)Hinton, Deng, Dahl, Mohamed, Jaitly, Senior,
  Vanhoucke, Nguyen, Sainath, and Kingsbury]{Hinton2012}
Hinton, G., Deng, L., Dahl, G., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke,
  V., Nguyen, P., Sainath, T., and Kingsbury, B.
\newblock Deep neural networks for acoustic modeling in speech recognition.
\newblock \emph{IEEE Signal Processing Magazine}, 2012.

\bibitem[Jeroslow(1987)]{MIR}
Jeroslow, R.
\newblock Representability in mixed integer programming, {I}: Characterization
  results.
\newblock \emph{Discrete Applied Mathematics}, 17\penalty0 (3):\penalty0 223 --
  243, 1987.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{Krizhevsky2012}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{NIPS}, 2012.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{LeCun1998}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Maass et~al.(1994)Maass, Schnitger, and Sontag]{Maass1994}
Maass, W., Schnitger, G., and Sontag, E.
\newblock A comparison of the computational power of sigmoid and boolean
  threshold circuits.
\newblock \emph{Theoretical Advances in Neural Computation and Learning}, pp.\
  127--151, 1994.

\bibitem[Mhaskar et~al.(2016)Mhaskar, Liao, and Poggio]{Mhaskar2016}
Mhaskar, H., Liao, Q., and Poggio, T.~A.
\newblock Learning real and boolean functions: When is deep better than
  shallow.
\newblock \emph{CoRR}, abs/1603.00988, 2016.

\bibitem[Mont\'{u}far(2017)]{Montufar2017}
Mont\'{u}far, G.
\newblock Notes on the number of linear regions of deep neural networks.
\newblock In \emph{SampTA}, 2017.

\bibitem[Mont\'{u}far et~al.(2014)Mont\'{u}far, Pascanu, Cho, and
  Bengio]{Montufar2014}
Mont\'{u}far, G., Pascanu, R., Cho, K., and Bengio, Y.
\newblock On the number of linear regions of deep neural networks.
\newblock In \emph{NIPS}, 2014.

\bibitem[Pan \& Srikumar(2016)Pan and Srikumar]{Pan2016}
Pan, X. and Srikumar, V.
\newblock Expressiveness of rectifier networks.
\newblock In \emph{ICML}, 2016.

\bibitem[Pascanu et~al.(2014)Pascanu, Mont\'{u}far, and Bengio]{Pascanu2013}
Pascanu, R., Mont\'{u}far, G., and Bengio, Y.
\newblock On the number of response regions of deep feedforward networks with
  piecewise linear activations.
\newblock In \emph{ICLR}, 2014.

\bibitem[Raghu et~al.(2017)Raghu, Poole, Kleinberg, Ganguli, and
  Sohl-Dickstein]{Raghu2017}
Raghu, M., Poole, B., Kleinberg, J., Ganguli, S., and Sohl-Dickstein, J.
\newblock On the expressive power of deep neural networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Stirling(1730)]{Stirling}
Stirling, J.
\newblock \emph{Methodus Differentialis sive Tractatus de Summatione et
  Interpolatione Serierum Infinitarum}.
\newblock G. Strahan, London, 1730.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{Szegedy2015}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
  Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock In \emph{CVPR}, 2015.

\bibitem[Telgarsky(2015)]{Telgarsky2015}
Telgarsky, M.
\newblock Representation benefits of deep feedforward networks.
\newblock \emph{CoRR}, abs/1509.08101, 2015.

\bibitem[Zaslavsky(1975)]{Zaslavsky1975}
Zaslavsky, T.
\newblock \emph{Facing up to arrangements: face-count formulas for partitions
  of space by hyperplanes}.
\newblock American Mathematical Society, 1975.

\end{thebibliography}
