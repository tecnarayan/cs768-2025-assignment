\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agustsson and Theis(2020)]{agustsson2020universally}
E.~Agustsson and L.~Theis.
\newblock Universally quantized neural compression.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 12367--12376, 2020.

\bibitem[Agustsson et~al.(2020)Agustsson, Minnen, Johnston, Balle, Hwang, and
  Toderici]{agustsson2020scale}
E.~Agustsson, D.~Minnen, N.~Johnston, J.~Balle, S.~J. Hwang, and G.~Toderici.
\newblock Scale-space flow for end-to-end optimized video compression.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 8503--8512, 2020.

\bibitem[Ball{\'e} et~al.(2017)Ball{\'e}, Laparra, and
  Simoncelli]{balle2017end}
J.~Ball{\'e}, V.~Laparra, and E.~P. Simoncelli.
\newblock End-to-end optimized image compression.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Ball{\'e} et~al.(2018)Ball{\'e}, Minnen, Singh, Hwang, and
  Johnston]{balle2018variational}
J.~Ball{\'e}, D.~Minnen, S.~Singh, S.~J. Hwang, and N.~Johnston.
\newblock Variational image compression with a scale hyperprior.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Bauer and Mnih(2021)]{bauer2021generalized}
M.~Bauer and A.~Mnih.
\newblock Generalized doubly reparameterized gradient estimators.
\newblock In \emph{International Conference on Machine Learning}, pages
  738--747. PMLR, 2021.

\bibitem[Bjontegaard(2001)]{bjontegaard2001calculation}
G.~Bjontegaard.
\newblock Calculation of average psnr differences between rd-curves.
\newblock \emph{VCEG-M33}, 2001.

\bibitem[Bross et~al.(2021)Bross, Chen, Ohm, Sullivan, and
  Wang]{bross2021developments}
B.~Bross, J.~Chen, J.-R. Ohm, G.~J. Sullivan, and Y.-K. Wang.
\newblock Developments in international video coding standardization after avc,
  with an overview of versatile video coding (vvc).
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (9):\penalty0
  1463--1493, 2021.

\bibitem[Burda et~al.(2016)Burda, Grosse, and
  Salakhutdinov]{burda2016importance}
Y.~Burda, R.~B. Grosse, and R.~Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock In \emph{ICLR (Poster)}, 2016.

\bibitem[Chen et~al.(2017)Chen, Kingma, Salimans, Duan, Dhariwal, Schulman,
  Sutskever, and Abbeel]{chen2017variational}
X.~Chen, D.~P. Kingma, T.~Salimans, Y.~Duan, P.~Dhariwal, J.~Schulman,
  I.~Sutskever, and P.~Abbeel.
\newblock Variational lossy autoencoder.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Cheng et~al.(2020)Cheng, Sun, Takeuchi, and Katto]{cheng2020learned}
Z.~Cheng, H.~Sun, M.~Takeuchi, and J.~Katto.
\newblock Learned image compression with discretized gaussian mixture
  likelihoods and attention modules.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7939--7948, 2020.

\bibitem[Choi et~al.(2018)Choi, Tatwawadi, Weissman, and Ermon]{choi2018necst}
K.~Choi, K.~Tatwawadi, T.~Weissman, and S.~Ermon.
\newblock Necst: neural joint source-channel coding.
\newblock 2018.

\bibitem[Cremer et~al.(2017)Cremer, Morris, and
  Duvenaud]{cremer2017reinterpreting}
C.~Cremer, Q.~Morris, and D.~Duvenaud.
\newblock Reinterpreting importance-weighted autoencoders.
\newblock 2017.

\bibitem[Cremer et~al.(2018)Cremer, Li, and Duvenaud]{cremer2018inference}
C.~Cremer, X.~Li, and D.~Duvenaud.
\newblock Inference suboptimality in variational autoencoders.
\newblock In \emph{International Conference on Machine Learning}, pages
  1078--1086. PMLR, 2018.

\bibitem[Dayan et~al.(1995)Dayan, Hinton, Neal, and Zemel]{dayan1995helmholtz}
P.~Dayan, G.~E. Hinton, R.~M. Neal, and R.~S. Zemel.
\newblock The helmholtz machine.
\newblock \emph{Neural computation}, 7\penalty0 (5):\penalty0 889--904, 1995.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Flamich et~al.(2020)Flamich, Havasi, and
  Hern{\'a}ndez-Lobato]{flamich2020compressing}
G.~Flamich, M.~Havasi, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Compressing images by encoding their latent representations with
  relative entropy coding.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 16131--16141, 2020.

\bibitem[Gao et~al.(2021)Gao, You, Pan, Han, Zhang, Dai, and
  Lee]{gao2021neural}
G.~Gao, P.~You, R.~Pan, S.~Han, Y.~Zhang, Y.~Dai, and H.~Lee.
\newblock Neural image compression via attentional multi-scale back projection
  and frequency decomposition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 14677--14686, 2021.

\bibitem[Guo et~al.(2021{\natexlab{a}})Guo, Zhang, Feng, and
  Chen]{guo2021causal}
Z.~Guo, Z.~Zhang, R.~Feng, and Z.~Chen.
\newblock Causal contextual prediction for learned image compression.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video
  Technology}, 2021{\natexlab{a}}.

\bibitem[Guo et~al.(2021{\natexlab{b}})Guo, Zhang, Feng, and Chen]{guo2021soft}
Z.~Guo, Z.~Zhang, R.~Feng, and Z.~Chen.
\newblock Soft then hard: Rethinking the quantization in neural image
  compression.
\newblock In \emph{International Conference on Machine Learning}, pages
  3920--3929. PMLR, 2021{\natexlab{b}}.

\bibitem[He et~al.(2021)He, Zheng, Sun, Wang, and Qin]{he2021checkerboard}
D.~He, Y.~Zheng, B.~Sun, Y.~Wang, and H.~Qin.
\newblock Checkerboard context model for efficient learned image compression.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 14771--14780, 2021.

\bibitem[He et~al.(2022)He, Yang, Peng, Ma, Qin, and Wang]{he2022elic}
D.~He, Z.~Yang, W.~Peng, R.~Ma, H.~Qin, and Y.~Wang.
\newblock Elic: Efficient learned image compression with unevenly grouped
  space-channel contextual adaptive coding.
\newblock \emph{arXiv preprint arXiv:2203.10886}, 2022.

\bibitem[Hinton and Van~Camp(1993)]{hinton1993keeping}
G.~E. Hinton and D.~Van~Camp.
\newblock Keeping the neural networks simple by minimizing the description
  length of the weights.
\newblock In \emph{Proceedings of the sixth annual conference on Computational
  learning theory}, pages 5--13, 1993.

\bibitem[Hinton et~al.(1995)Hinton, Dayan, Frey, and Neal]{hinton1995wake}
G.~E. Hinton, P.~Dayan, B.~J. Frey, and R.~M. Neal.
\newblock The" wake-sleep" algorithm for unsupervised neural networks.
\newblock \emph{Science}, 268\penalty0 (5214):\penalty0 1158--1161, 1995.

\bibitem[Hu et~al.(2021)Hu, Lu, and Xu]{hu2021fvc}
Z.~Hu, G.~Lu, and D.~Xu.
\newblock Fvc: A new framework towards deep video compression in feature space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 1502--1511, 2021.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kodak(1993)]{kodak}
E.~Kodak.
\newblock Kodak lossless true color image suite.
\newblock \url{http://r0k.us/graphics/kodak/}, 1993.

\bibitem[Li et~al.(2021)Li, Li, and Lu]{li2021deep}
J.~Li, B.~Li, and Y.~Lu.
\newblock Deep contextual video compression.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Loshchilov and Hutter(2016)]{loshchilov2016sgdr}
I.~Loshchilov and F.~Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock \emph{arXiv preprint arXiv:1608.03983}, 2016.

\bibitem[Lu et~al.(2019)Lu, Ouyang, Xu, Zhang, Cai, and Gao]{lu2019dvc}
G.~Lu, W.~Ouyang, D.~Xu, X.~Zhang, C.~Cai, and Z.~Gao.
\newblock Dvc: An end-to-end deep video compression framework.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11006--11015, 2019.

\bibitem[Lu et~al.(2020)Lu, Zhang, Ouyang, Chen, Gao, and Xu]{lu2020end}
G.~Lu, X.~Zhang, W.~Ouyang, L.~Chen, Z.~Gao, and D.~Xu.
\newblock An end-to-end learning framework for video compression.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 43\penalty0 (10):\penalty0 3292--3308, 2020.

\bibitem[Minnen and Singh(2020)]{minnen2020channel}
D.~Minnen and S.~Singh.
\newblock Channel-wise autoregressive entropy models for learned image
  compression.
\newblock In \emph{2020 IEEE International Conference on Image Processing
  (ICIP)}, pages 3339--3343. IEEE, 2020.

\bibitem[Minnen et~al.(2018)Minnen, Ball{\'e}, and Toderici]{minnen2018joint}
D.~Minnen, J.~Ball{\'e}, and G.~D. Toderici.
\newblock Joint autoregressive and hierarchical priors for learned image
  compression.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Mnih and Gregor(2014)]{mnih2014neural}
A.~Mnih and K.~Gregor.
\newblock Neural variational inference and learning in belief networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  1791--1799. PMLR, 2014.

\bibitem[Mnih and Rezende(2016)]{mnih2016variational}
A.~Mnih and D.~Rezende.
\newblock Variational inference for monte carlo objectives.
\newblock In \emph{International Conference on Machine Learning}, pages
  2188--2196. PMLR, 2016.

\bibitem[Mohamed et~al.(2020)Mohamed, Rosca, Figurnov, and
  Mnih]{mohamed2020monte}
S.~Mohamed, M.~Rosca, M.~Figurnov, and A.~Mnih.
\newblock Monte carlo gradient estimation in machine learning.
\newblock \emph{J. Mach. Learn. Res.}, 21\penalty0 (132):\penalty0 1--62, 2020.

\bibitem[Nowozin(2018)]{nowozin2018debiasing}
S.~Nowozin.
\newblock Debiasing evidence approximations: On importance-weighted
  autoencoders and jackknife variational inference.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[Paulus et~al.(2020)Paulus, Maddison, and Krause]{paulus2020rao}
M.~B. Paulus, C.~J. Maddison, and A.~Krause.
\newblock Rao-blackwellizing the straight-through gumbel-softmax gradient
  estimator.
\newblock \emph{arXiv preprint arXiv:2010.04838}, 2020.

\bibitem[Rainforth et~al.(2018)Rainforth, Kosiorek, Le, Maddison, Igl, Wood,
  and Teh]{rainforth2018tighter}
T.~Rainforth, A.~Kosiorek, T.~A. Le, C.~Maddison, M.~Igl, F.~Wood, and Y.~W.
  Teh.
\newblock Tighter variational bounds are not necessarily better.
\newblock In \emph{International Conference on Machine Learning}, pages
  4277--4285. PMLR, 2018.

\bibitem[Roeder et~al.(2017)Roeder, Wu, and Duvenaud]{roeder2017sticking}
G.~Roeder, Y.~Wu, and D.~K. Duvenaud.
\newblock Sticking the landing: Simple, lower-variance gradient estimators for
  variational inference.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Ryder et~al.(2022)Ryder, Zhang, Kang, and Zhang]{ryder2022split}
T.~Ryder, C.~Zhang, N.~Kang, and S.~Zhang.
\newblock Split hierarchical variational compression.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 386--395, 2022.

\bibitem[Serban et~al.(2017)Serban, Sordoni, Lowe, Charlin, Pineau, Courville,
  and Bengio]{serban2017hierarchical}
I.~Serban, A.~Sordoni, R.~Lowe, L.~Charlin, J.~Pineau, A.~Courville, and
  Y.~Bengio.
\newblock A hierarchical latent variable encoder-decoder model for generating
  dialogues.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~31, 2017.

\bibitem[Song et~al.(2020)Song, Xu, Yu, Zhou, Shao, and Yu]{song2020infomax}
Y.~Song, M.~Xu, L.~Yu, H.~Zhou, S.~Shao, and Y.~Yu.
\newblock Infomax neural joint source-channel coding via adversarial bit flip.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 5834--5841, 2020.

\bibitem[Theis and Agustsson(2021)]{theis2021advantages}
L.~Theis and E.~Agustsson.
\newblock On the advantages of stochastic encoders.
\newblock \emph{arXiv preprint arXiv:2102.09270}, 2021.

\bibitem[Theis and Ho(2021)]{theis2021importance}
L.~Theis and J.~Ho.
\newblock Importance weighted compression.
\newblock In \emph{Neural Compression: From Information Theory to
  Applications--Workshop@ ICLR 2021}, 2021.

\bibitem[Theis et~al.(2017)Theis, Shi, Cunningham, and
  Husz{\'a}r]{theis2017lossy}
L.~Theis, W.~Shi, A.~Cunningham, and F.~Husz{\'a}r.
\newblock Lossy image compression with compressive autoencoders.
\newblock \emph{arXiv preprint arXiv:1703.00395}, 2017.

\bibitem[Toderici et~al.(2015)Toderici, O'Malley, Hwang, Vincent, Minnen,
  Baluja, Covell, and Sukthankar]{toderici2015variable}
G.~Toderici, S.~M. O'Malley, S.~J. Hwang, D.~Vincent, D.~Minnen, S.~Baluja,
  M.~Covell, and R.~Sukthankar.
\newblock Variable rate image compression with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1511.06085}, 2015.

\bibitem[Toderici et~al.(2017)Toderici, Vincent, Johnston, Jin~Hwang, Minnen,
  Shor, and Covell]{toderici2017full}
G.~Toderici, D.~Vincent, N.~Johnston, S.~Jin~Hwang, D.~Minnen, J.~Shor, and
  M.~Covell.
\newblock Full resolution image compression with recurrent neural networks.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 5306--5314, 2017.

\bibitem[Townsend et~al.(2018)Townsend, Bird, and
  Barber]{townsend2018practical}
J.~Townsend, T.~Bird, and D.~Barber.
\newblock Practical lossless compression with latent variables using bits back
  coding.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Tucker et~al.(2018)Tucker, Lawson, Gu, and Maddison]{tucker2018doubly}
G.~Tucker, D.~Lawson, S.~Gu, and C.~J. Maddison.
\newblock Doubly reparameterized gradient estimators for monte carlo
  objectives.
\newblock 2018.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, et~al.]{van2017neural}
A.~Van Den~Oord, O.~Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Williams(1992)]{williams1992simple}
R.~J. Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3):\penalty0 229--256, 1992.

\bibitem[Xie et~al.(2021)Xie, Cheng, and Chen]{xie2021enhanced}
Y.~Xie, K.~L. Cheng, and Q.~Chen.
\newblock Enhanced invertible encoding for learned image compression.
\newblock In \emph{Proceedings of the 29th ACM International Conference on
  Multimedia}, pages 162--170, 2021.

\bibitem[Yang et~al.(2020)Yang, Bamler, and Mandt]{yang2020improving}
Y.~Yang, R.~Bamler, and S.~Mandt.
\newblock Improving inference for neural image compression.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 573--584, 2020.

\bibitem[Zhu et~al.(2022)Zhu, Song, Gao, Zheng, and Shen]{zhu2022unified}
X.~Zhu, J.~Song, L.~Gao, F.~Zheng, and H.~T. Shen.
\newblock Unified multivariate gaussian mixture for efficient neural image
  compression.
\newblock \emph{arXiv preprint arXiv:2203.10897}, 2022.

\bibitem[Zhu et~al.(2021)Zhu, Yang, and Cohen]{zhu2021transformer}
Y.~Zhu, Y.~Yang, and T.~Cohen.
\newblock Transformer-based transform coding.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\end{thebibliography}
