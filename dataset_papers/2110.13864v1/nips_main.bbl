\begin{thebibliography}{10}

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas,
  ``Communication-efficient learning of deep networks from decentralized
  data,'' in {\em Artificial Intelligence and Statistics}, 2017.

\bibitem{he2020fedml}
C.~He, S.~Li, J.~So, X.~Zeng, M.~Zhang, H.~Wang, X.~Wang, P.~Vepakomma,
  A.~Singh, H.~Qiu, {\em et~al.}, ``Fedml: A research library and benchmark for
  federated machine learning,'' {\em arXiv preprint arXiv:2007.13518}, 2020.

\bibitem{mhamdi2018hidden}
E.~M.~E. Mhamdi, R.~Guerraoui, and S.~Rouault, ``The hidden vulnerability of
  distributed learning in byzantium,'' {\em arXiv preprint arXiv:1802.07927},
  2018.

\bibitem{fang2020local}
M.~Fang, X.~Cao, J.~Jia, and N.~Gong, ``Local model poisoning attacks to
  byzantine-robust federated learning,'' in {\em 29th $\{$USENIX$\}$ Security
  Symposium ($\{$USENIX$\}$ Security 20)}, pp.~1605--1622, 2020.

\bibitem{baruch2019little}
M.~Baruch, G.~Baruch, and Y.~Goldberg, ``A little is enough: Circumventing
  defenses for distributed learning,'' {\em arXiv preprint arXiv:1902.06156},
  2019.

\bibitem{mahloujifar2019universal}
S.~Mahloujifar, M.~Mahmoody, and A.~Mohammed, ``Universal multi-party poisoning
  attacks,'' in {\em International Conference on Machine Learing (ICML)}, 2019.

\bibitem{sun2019can}
Z.~Sun, P.~Kairouz, A.~T. Suresh, and H.~B. McMahan, ``Can you really backdoor
  federated learning?,'' {\em arXiv preprint arXiv:1911.07963}, 2019.

\bibitem{bagdasaryan2020backdoor}
E.~Bagdasaryan, A.~Veit, Y.~Hua, D.~Estrin, and V.~Shmatikov, ``How to backdoor
  federated learning,'' in {\em International Conference on Artificial
  Intelligence and Statistics}, pp.~2938--2948, PMLR, 2020.

\bibitem{wang2020attack}
H.~Wang, K.~Sreenivasan, S.~Rajput, H.~Vishwakarma, S.~Agarwal, J.-y. Sohn,
  K.~Lee, and D.~Papailiopoulos, ``Attack of the tails: Yes, you really can
  backdoor federated learning,'' {\em arXiv preprint arXiv:2007.05084}, 2020.

\bibitem{xie2019dba}
C.~Xie, K.~Huang, P.-Y. Chen, and B.~Li, ``Dba: Distributed backdoor attacks
  against federated learning,'' in {\em International Conference on Learning
  Representations}, 2019.

\bibitem{bhagoji2019analyzing}
A.~N. Bhagoji, S.~Chakraborty, P.~Mittal, and S.~Calo, ``Analyzing federated
  learning through an adversarial lens,'' in {\em International Conference on
  Machine Learning}, pp.~634--643, PMLR, 2019.

\bibitem{tomsett2019model}
R.~Tomsett, K.~Chan, and S.~Chakraborty, ``Model poisoning attacks against
  distributed machine learning systems,'' in {\em Artificial Intelligence and
  Machine Learning for Multi-Domain Operations Applications}, vol.~11006,
  p.~110061D, International Society for Optics and Photonics, 2019.

\bibitem{yin2018byzantine}
D.~Yin, Y.~Chen, R.~Kannan, and P.~Bartlett, ``Byzantine-robust distributed
  learning: Towards optimal statistical rates,'' in {\em International
  Conference on Machine Learning}, pp.~5650--5659, PMLR, 2018.

\bibitem{pillutla2019robust}
K.~Pillutla, S.~M. Kakade, and Z.~Harchaoui, ``Robust aggregation for federated
  learning,'' {\em arXiv preprint arXiv:1912.13445}, 2019.

\bibitem{fu2019attack}
S.~Fu, C.~Xie, B.~Li, and Q.~Chen, ``Attack-resistant federated learning with
  residual-based reweighting,'' {\em arXiv preprint arXiv:1912.11464}, 2019.

\bibitem{siegel1982robust}
A.~F. Siegel, ``Robust regression using repeated medians,'' {\em Biometrika},
  vol.~69, no.~1, pp.~242--244, 1982.

\bibitem{holland1977robust}
P.~W. Holland and R.~E. Welsch, ``Robust regression using iteratively
  reweighted least-squares,'' {\em Communications in Statistics-theory and
  Methods}, vol.~6, no.~9, pp.~813--827, 1977.

\bibitem{xiao2017/online}
H.~Xiao, K.~Rasul, and R.~Vollgraf, ``Fashion-mnist: a novel image dataset for
  benchmarking machine learning algorithms,'' 2017.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, {\em et~al.}, ``Learning multiple layers of features
  from tiny images,'' 2009.

\bibitem{fung2018mitigating}
C.~Fung, C.~J. Yoon, and I.~Beschastnikh, ``Mitigating sybils in federated
  learning poisoning,'' {\em arXiv preprint arXiv:1808.04866}, 2018.

\bibitem{blanchard2017machine}
P.~Blanchard, E.~M. El~Mhamdi, R.~Guerraoui, and J.~Stainer, ``Machine learning
  with adversaries: Byzantine tolerant gradient descent,'' in {\em Proceedings
  of the 31st International Conference on Neural Information Processing
  Systems}, pp.~118--128, 2017.

\bibitem{sattler2020byzantine}
F.~Sattler, K.-R. M{\"u}ller, T.~Wiegand, and W.~Samek, ``On the byzantine
  robustness of clustered federated learning,'' in {\em ICASSP 2020-2020 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp.~8861--8865, IEEE, 2020.

\bibitem{munoz2019byzantine}
L.~Mu{\~n}oz-Gonz{\'a}lez, K.~T. Co, and E.~C. Lupu, ``Byzantine-robust
  federated machine learning through adaptive model averaging,'' {\em arXiv
  preprint arXiv:1909.05125}, 2019.

\bibitem{naseri2020toward}
M.~Naseri, J.~Hayes, and E.~De~Cristofaro, ``Toward robustness and privacy in
  federated learning: Experimenting with local and central differential
  privacy,'' {\em arXiv preprint arXiv:2009.03561}, 2020.

\bibitem{tramer2020adaptive}
F.~Tramer, N.~Carlini, W.~Brendel, and A.~Madry, ``On adaptive attacks to
  adversarial example defenses,'' {\em arXiv preprint arXiv:2002.08347}, 2020.

\bibitem{carlini2019evaluating}
N.~Carlini, A.~Athalye, N.~Papernot, W.~Brendel, J.~Rauber, D.~Tsipras,
  I.~Goodfellow, A.~Madry, and A.~Kurakin, ``On evaluating adversarial
  robustness,'' {\em arXiv preprint arXiv:1902.06705}, 2019.

\bibitem{li2019convergence}
X.~Li, K.~Huang, W.~Yang, S.~Wang, and Z.~Zhang, ``On the convergence of fedavg
  on non-iid data,'' in {\em International Conference on Learning
  Representations}, 2019.

\bibitem{li2020lotteryfl}
A.~Li, J.~Sun, B.~Wang, L.~Duan, S.~Li, Y.~Chen, and H.~Li, ``Lotteryfl:
  Personalized and communication-efficient federated learning with lottery
  ticket hypothesis on non-iid datasets,'' {\em arXiv preprint
  arXiv:2008.03371}, 2020.

\end{thebibliography}
