\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beck and Teboulle(2009)]{beck2009gradient}
Amir Beck and Marc Teboulle.
\newblock Gradient-based algorithms with applications to signal recovery.
\newblock \emph{Convex Optimization in Signal Processing and Communications},
  2009.

\bibitem[Bengio(2000)]{bengio2000gradient}
Yoshua Bengio.
\newblock Gradient-based optimization of hyperparameters.
\newblock \emph{Neural computation}, 12\penalty0 (8):\penalty0 1889--1900,
  2000.

\bibitem[Bergstra and Bengio(2012)]{bergstra2012random}
James Bergstra and Yoshua Bengio.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0 (1),
  2012.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K\'{e}gl]{bergstra2011algorithms}
James~S. Bergstra, R\'{e}mi Bardenet, Yoshua Bengio, and Bal\'{a}zs K\'{e}gl.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 24}. 2011.

\bibitem[Brochu et~al.(2010)Brochu, Cora, and De~Freitas]{brochu2010tutorial}
Eric Brochu, Vlad~M Cora, and Nando De~Freitas.
\newblock A tutorial on bayesian optimization of expensive cost functions, with
  application to active user modeling and hierarchical reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1012.2599}, 2010.

\bibitem[Calatroni et~al.(2015)Calatroni, Chung, Reyes, Sch{\"o}nlieb, and
  Valkonen]{calatroni2015bilevel}
Luca Calatroni, Cao Chung, Juan Carlos De~Los Reyes, Carola-Bibiane
  Sch{\"o}nlieb, and Tuomo Valkonen.
\newblock Bilevel approaches for learning of variational imaging models.
\newblock \emph{arXiv preprint arXiv:1505.02120}, 2015.

\bibitem[Chapelle et~al.(2002)Chapelle, Vapnik, Bousquet, and
  Mukherjee]{chapelle2002choosing}
Olivier Chapelle, Vladimir Vapnik, Olivier Bousquet, and Sayan Mukherjee.
\newblock Choosing multiple parameters for support vector machines.
\newblock \emph{Machine learning}, 2002.

\bibitem[d'Aspremont(2008)]{d2008smooth}
Alexandre d'Aspremont.
\newblock Smooth optimization with approximate gradient.
\newblock \emph{SIAM Journal on Optimization}, 2008.

\bibitem[De~los Reyes et~al.(2015)De~los Reyes, Sch{\"o}nlieb, and
  Valkonen]{reyes2015structure}
J.C. De~los Reyes, Carola-Bibiane Sch{\"o}nlieb, and Tuomo Valkonen.
\newblock The structure of optimal parameters for image restoration problems.
\newblock \emph{arXiv preprint arXiv:1505.01953}, 2015.

\bibitem[Deledalle et~al.(2014)Deledalle, Vaiter, Fadili, and
  Peyr{\'e}]{deledalle2014stein}
Charles-Alban Deledalle, Samuel Vaiter, Jalal Fadili, and Gabriel Peyr{\'e}.
\newblock Stein unbiased gradient estimator of the risk ({SUGAR}) for multiple
  parameter selection.
\newblock \emph{SIAM Journal on Imaging Sciences}, 2014.

\bibitem[Domke(2012)]{domke2012generic}
Justin Domke.
\newblock Generic methods for optimization-based modeling.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2012.

\bibitem[Foo et~al.(2008)Foo, Do, and Ng]{NIPS2007_3286}
{Chuan-Sheng} Foo, Chuong~B. Do, and Andrew~Y. Ng.
\newblock Efficient multiple hyperparameter learning for log-linear models.
\newblock In \emph{Advances in Neural Information Processing Systems 20}. 2008.

\bibitem[Friedlander and Schmidt(2012)]{friedlander2012hybrid}
Michael Friedlander and Mark Schmidt.
\newblock Hybrid deterministic-stochastic methods for data fitting.
\newblock \emph{SIAM Journal on Scientific Computing}, 2012.

\bibitem[Higham(2002)]{higham2002accuracy}
Nicholas~J Higham.
\newblock \emph{Accuracy and stability of numerical algorithms}.
\newblock 2002.

\bibitem[Johnson and Zhang(2013)]{johnson2013accelerating}
Rie Johnson and Tong Zhang.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Kunisch and Pock(2013)]{kunisch2013bilevel}
Karl Kunisch and Thomas Pock.
\newblock A bilevel optimization approach for parameter learning in variational
  models.
\newblock \emph{SIAM Journal on Imaging Sciences}, 2013.

\bibitem[Lacoste et~al.(2014)Lacoste, Larochelle, Laviolette, and
  Marchand]{lacoste2014sequential}
Alexandre Lacoste, Hugo Larochelle, Fran{\c{c}}ois Laviolette, and Mario
  Marchand.
\newblock Sequential model-based ensemble optimization.
\newblock \emph{arXiv preprint arXiv:1402.0796}, 2014.

\bibitem[Larsen et~al.(1996)Larsen, Hansen, Svarer, and
  Ohlsson]{larsen1996design}
Jan Larsen, Lars~Kai Hansen, Claus Svarer, and M~Ohlsson.
\newblock Design and regularization of neural networks: the optimal use of a
  validation set.
\newblock In \emph{Proceedings of the IEEE Signal Processing Society Workshop}.
  IEEE, 1996.

\bibitem[Larsen et~al.(1998)Larsen, Svarer, Andersen, and
  Hansen]{larsen1998adaptive}
Jan Larsen, Claus Svarer, Lars~Nonboe Andersen, and Lars~Kai Hansen.
\newblock Adaptive regularization in neural network modeling.
\newblock In \emph{Neural Networks: Tricks of the Trade}. Springer, 1998.

\bibitem[Lin et~al.(2008)Lin, Weng, and Keerthi]{lin2008trust}
Chih-Jen Lin, Ruby~C Weng, and S~Sathiya Keerthi.
\newblock Trust region newton method for logistic regression.
\newblock \emph{The Journal of Machine Learning Research}, 2008.

\bibitem[Liu and Nocedal(1989)]{liu1989limited}
Dong~C Liu and Jorge Nocedal.
\newblock On the limited memory bfgs method for large scale optimization.
\newblock \emph{Mathematical programming}, 1989.

\bibitem[Liu and Yang(2011)]{liu2011parametric}
Wei Liu and Yuhong Yang.
\newblock Parametric or nonparametric? a parametricness index for model
  selection.
\newblock \emph{The Annals of Statistics}, 2011.

\bibitem[Maclaurin et~al.(2015)Maclaurin, Duvenaud, and
  Adams]{MacDuvAda2015hyper}
Dougal Maclaurin, David Duvenaud, and Ryan~P. Adams.
\newblock Gradient-based hyperparameter optimization through reversible
  learning.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, July 2015.

\bibitem[Mallows(1973)]{mallows1973some}
Colin~L Mallows.
\newblock Some comments on {$C_p$}.
\newblock \emph{Technometrics}, 1973.

\bibitem[Nesterov(2004)]{nesterov2004introductory}
Yurii Nesterov.
\newblock \emph{Introductory lectures on convex optimization}.
\newblock Springer Science \& Business Media, 2004.

\bibitem[Ochs et~al.()Ochs, Ranftl, Brox, and Pock]{ochs2015bilevel}
Peter Ochs, Ren{\'e} Ranftl, Thomas Brox, and Thomas Pock.
\newblock Bilevel optimization with nonsmooth lower level problems.
\newblock In \emph{Scale Space and Variational Methods in Computer Vision}.
  Springer.

\bibitem[Parikh and Boyd(2013)]{parikh2013proximal}
Neal Parikh and Stephen Boyd.
\newblock Proximal algorithms.
\newblock \emph{Foundations and Trends in optimization}, 2013.

\bibitem[Pearlmutter(1994)]{pearlmutter1994fast}
Barak~A Pearlmutter.
\newblock Fast exact multiplication by the hessian.
\newblock \emph{Neural computation}, 1994.

\bibitem[Schmidt et~al.(2011)Schmidt, Le~Roux, and
  Bach]{schmidt2011convergence}
Mark Schmidt, Nicolas Le~Roux, and Francis~R Bach.
\newblock Convergence rates of inexact proximal-gradient methods for convex
  optimization.
\newblock In \emph{Advances in neural information processing systems}, 2011.

\bibitem[Schmidt et~al.(2013)Schmidt, Le~Roux, and Bach]{schmidt2013minimizing}
Mark Schmidt, Nicolas Le~Roux, and Francis Bach.
\newblock Minimizing finite sums with the stochastic average gradient.
\newblock \emph{arXiv preprint arXiv:1309.2388}, 2013.

\bibitem[Seeger(2008)]{seeger2008cross}
Matthias~W Seeger.
\newblock Cross-validation optimization for large scale structured
  classification kernel methods.
\newblock \emph{The Journal of Machine Learning Research}, 2008.

\bibitem[Stein(1981)]{stein1981estimation}
Charles~M Stein.
\newblock Estimation of the mean of a multivariate normal distribution.
\newblock \emph{The annals of Statistics}, 1981.

\bibitem[Swersky et~al.(2014)Swersky, Snoek, and Adams]{swersky2014freeze}
Kevin Swersky, Jasper Snoek, and Ryan~Prescott Adams.
\newblock Freeze-thaw bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1406.3896}, 2014.

\bibitem[Tibshirani(1996)]{tibshirani1996regression}
Robert Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society. Series B
  (Methodological)}, 1996.

\bibitem[Tsanas et~al.(2010)Tsanas, Little, McSharry, and
  Ramig]{tsanas2010accurate}
Athanasios Tsanas, Max~A Little, Patrick~E McSharry, and Lorraine~O Ramig.
\newblock Accurate telemonitoring of parkinson's disease progression by
  noninvasive speech tests.
\newblock \emph{Biomedical Engineering, IEEE Transactions on}, 2010.

\end{thebibliography}
