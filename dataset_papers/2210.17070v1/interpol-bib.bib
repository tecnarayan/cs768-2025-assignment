

@string{nips2011= {Advances in Neural Information Processing Systems 24}}
@string{nips2020= {Advances in Neural Information Processing Systems 33}} % 2020
@string{nips2021= {Advances in Neural Information Processing Systems 34}} % 2021

@string{icml20 = {Proceedings of the 37th International Conference on Machine Learning}}
@string{icml21 = {Proceedings of the 38th International Conference on Machine Learning}}

@string{aistat19 = {Proceedings of the 22nd International Conference
on Artificial Intelligence and Statistics}}


@string{colt20 = {Proceedings of the Thirty Fourth Annual Conference on
	Computational Learning Theory}}	 
@string{colt21 = {Proceedings of the Thirty Fourth Annual Conference on
	Computational Learning Theory}}	  
	
@inproceedings{AsiLeDu21,
author = {Hilal Asi and Daniel Levy and
  John C. Duchi},
title = {Adapting to Function Difficulty and Growth Conditions in Private Optimization},
booktitle = nips2021,
year = 2021,
}

@inproceedings{VaswaniBaSc19,
  title={Fast and faster convergence of {SGD} for over-parameterized models and an accelerated perceptron},
  author={Sharan Vaswani and Francis Bach and Mark Schmidt},
  booktitle= aistat19 ,
  year=2019,
}


@inproceedings{AsiFeKoTa21,
author = {Hilal Asi and Vitaly Feldman and Tomer Koren and Kunal Talwar},
title = {Private Stochastic Convex Optimization: Optimal Rates in {$\ell_1$} Geometry},
year = 2021,
booktitle = icml21,
}

@inproceedings{AsiDuFaJaTa21,
  title={Private Adaptive Gradient Methods for Convex Optimization},
  author={Hilal Asi and  John Duchi and Alireza Fallah and Omid Javidbakht and Kunal Talwar},
  booktitle = icml21,
  pages={383--392},
  year= 2021,
}

@inproceedings{ChadhaChDu22,
  title={Accelerated, Optimal and Parallel: Some results on model-based stochastic optimization},
  author={Chadha, Karan and Cheng, Gary and Duchi, John},
  booktitle={International Conference on Machine Learning},
  pages={2811--2827},
  year={2022},
  organization={PMLR}
}


@InProceedings{BassilyGuNa21,
	title = 	 {Non-Euclidean Differentially Private Stochastic Convex Optimization
},
	author = 	 {Raef Bassily and Cristóbal Guzmán and Anupama Nandi},
	booktitle = colt21,
	pages = 	 {474-499},
	year = 	 {2021},
}

@inproceedings{WoodworthSr21,
author = {Blake E. Woodworth and Nathan Srebro},
title = {An Even More Optimal Stochastic Optimization Algorithm: Minibatching and Interpolation Learning},
booktitle = nips2021,
year = 2021,
}

@inproceedings{BassilyFeGuTa20,
title = {Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses},
author = {Raef Bassily and Vitaly Feldman and Crist\'obal Guzm\'an and Kunal Talwar},
year = 2020,
booktitle = nips2020,
}




@inproceedings{WangXiDeXu20,
author = {Di Wang and Hanshen Xiao and Srini Devadas and Jinhui Xu},
title = {Private StochastiOn Differentially Private Stochastic Convex Optimization with Heavy-tailed Data
},
year = 2020,
booktitle = icml20,
}


@inproceedings{CotterShSrSr11,
title = {Better mini-batch algorithms via accelerated gradient methods},
author = { Andrew Cotter and Ohad Shamir and Nati Srebro and Karthik Sridharan},
year = 2011,
booktitle = nips2011,
}



@inproceedings{
LiuBe20,
title={Accelerating SGD with momentum for over-parameterized learning},
author={Chaoyue Liu and Mikhail Belkin},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{FeldmanVo19,
  title={High probability generalization bounds for uniformly stable algorithms
                  with nearly optimal rate},
  author={Vitaly Feldman  and Jan Vondrak},
  booktitle= colt19,
  pages={1270--1279},
  year={2019},
}

@misc{CevherVu17,
Author = {Volkan Cevher and Bang Cong Vu},
Title = {On the linear convergence of the stochastic gradient method with constant step-size},
Year = {2017},
journal = {arXiv:1712.01906 [math.OC]},
}

@article{NecoaraNeGl18,
  doi = {10.1007/s10107-018-1232-1},
  url = {https://doi.org/10.1007/s10107-018-1232-1},
  year = {2018},
  month = jan,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {175},
  number = {1-2},
  pages = {69--107},
  author = {I. Necoara and Yu. Nesterov and F. Glineur},
  title = {Linear convergence of first order methods for non-strongly convex optimization},
  journal = {Mathematical Programming}
}

@article{GongYe14,
  title={Linear Convergence of Variance-Reduced Stochastic Gradient without Strong Convexity},
  author={Pinghua Gong and Jieping Ye},
  journal={arXiv: cs.NA},
  year={2014}
}