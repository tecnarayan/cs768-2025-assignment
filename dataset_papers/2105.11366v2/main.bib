@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{ale,
    author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
    title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
    journal = {Journal of Artificial Intelligence Research},
    year = "2013",
    volume = "47",
    pages = "253--279",
}

@inproceedings{arjovsky17,
    author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
    title = {Wasserstein GAN},
    year = {2017},
    booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
}

@inproceedings{barth-maron18,
    title={Distributed Distributional Deterministic Policy Gradients},
    author={Gabriel Barth-Maron and Matthew W. Hoffman and David Budden and Will Dabney and Dan Horgan and Dhruva TB and Alistair Muldal and Nicolas Heess and Timothy Lillicrap},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2018},
}

@inproceedings{bellemare17,
    author = {Bellemare, Marc G. and Dabney, Will and Munos, R\'{e}mi},
    title = {A Distributional Perspective on Reinforcement Learning},
    year = {2017},
    booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
}

@article{bellemare17cramer,
  author = {Bellemare, Marc G. and Danihelka, Ivo and Dabney, Will and Mohamed, Shakir and Lakshminarayanan, Balaji and Hoyer, Stephan and Munos, Rémi},
  title = {The Cramer Distance as a Solution to Biased Wasserstein Gradients},
  year = 2017,
  journal={arXiv preprint arXiv:1705.10743},
  ee = {https://arxiv.org/abs/1705.10743},
}

@inproceedings{bellemare19,
  author = {Bellemare, Marc G. and Roux, Nicolas Le and Castro, Pablo Samuel and Moitra, Subhodeep},
  booktitle = {Artificial Intelligence and Statistics},
  pages = {2203-2211},
  series = {Proceedings of Machine Learning Research},
  title = {Distributional reinforcement learning with linear function approximation.},
  volume = 89,
  year = 2019
}

@book{bellman58,
  author = {Bellman, Richard},
  publisher = {Dover Publications},
  title = {{Dynamic Programming}},
  year = 1957
}

@book{bertsekas96,
    author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
    title = {Neuro-Dynamic Programming},
    year = {1996},
    publisher = {Athena Scientific},
    edition = {1st}
}

@inproceedings{burda19,
  author    = {Yuri Burda and
               Harrison Edwards and
               Amos J. Storkey and
               Oleg Klimov},
  title     = {Exploration by random network distillation},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  timestamp = {Thu, 25 Jul 2019 14:25:55 +0200},
}

@article{cichosz95,
  author = {Cichosz, P.},
  journal = {Journal on Artificial Intelligence},
  pages = {287--318},
  title = {Truncating temporal differences: On the efficient implementation of {TD($\lambda$)} for reinforcement learning},
  volume = 2,
  year = 1995
}

@INPROCEEDINGS{choi19, 
    author={Y. {Choi} and K. {Lee} and S. {Oh}},  
    booktitle={2019 International Conference on Robotics and Automation (ICRA)},  
    title={Distributional Deep Reinforcement Learning with a Mixture of Gaussians},   
    year={2019},  
    volume={},  
    number={},  
    pages={9791-9797},
}

@inproceedings{dabney17,
  author = {Dabney, Will and Rowland, Mark and Bellemare, Marc G. and Munos, Rémi},
  booktitle = {AAAI},
  pages = {2892-2901},
  title = {Distributional Reinforcement Learning With Quantile Regression.},
  year = 2018
}

@inproceedings{dabney18,
    author    = {Will Dabney and
               Georg Ostrovski and
               David Silver and
               R{\'{e}}mi Munos},
    title     = {Implicit Quantile Networks for Distributional Reinforcement Learning},
    year      = {2018},
    booktitle   = {Proceedings of the 35th International Conference
               on Machine Learning (ICML)},
}

@article{dearden98,
  author = {Dearden, Richard and Friedman, Nir and Russell, Stuart},
  journal = {Proceedings of the fifteenth national/tenth conference on Artificial
	intelligence/Innovative applications of artificial intelligence},
  pages = {761 - 768},
  title = {Bayesian Q-learning},
  year = 1998
}

@inproceedings{gruslys17,
  author = {Gruslys, Audrunas and Dabney, Will and Azar, Mohammad Gheshlaghi and Piot, Bilal and Bellemare, Marc and Munos, Remi},
  booktitle = {International Conference on Learning Representation (ICLR)},
  title = {The Reactor: A fast and sample-efficient Actor-Critic agent for
  Reinforcement Learning},
  year = 2017
}

@inproceedings{Hessel2018RainbowCI,
  title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
  author={Matteo Hessel and Joseph Modayil and H. V. Hasselt and T. Schaul and Georg Ostrovski and W. Dabney and Dan Horgan and B. Piot and Mohammad Gheshlaghi Azar and D. Silver},
  booktitle={AAAI},
  year={2018}
}

@article{huber1964,
  author = {Huber, Peter J.},
  journal = {The Annals of Mathematical Statistics},
  number = 1,
  pages = {73--101},
  publisher = {Institute of Mathematical Statistics},
  title = {Robust Estimation of a Location Parameter},
  volume = 35,
  year = 1964
}

@inproceedings{kakade02,
    author = {Kakade, Sham and Langford, John},
    title = {Approximately Optimal Approximate Reinforcement Learning},
    year = {2002},
    booktitle = {Proceedings of the 19th International Conference on Machine Learning (ICML)},
}

@book{koenker05,
    author = {Koenker, Roger},
    publisher = {Cambridge University Press},
    series = {Econometric Society Monographs},
    title = {Quantile Regression},
    year = 2005
}

@article{kuznetsov20,
  author = {Kuznetsov, Arsenii and Shvechikov, Pavel and Grishin, Alexander and Vetrov, Dmitry P.},
  journal={arXiv preprint arXiv:2005.04269},
  title = {Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics.},
  year = 2020,
  ee = {https://arxiv.org/abs/2005.04269},
}

@article{levine16,
  author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal = {Journal of Machine Learning Research},
  pages = {39:1-39:40},
  title = {End-to-End Training of Deep Visuomotor Policies.},
  volume = 17,
  year = 2016
}

@inproceedings{lillicrap16,
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle = {Proceedings of the 33rd International Conference on Learning Representations (ICML)},
  title = {Continuous control with deep reinforcement learning.},
  year = 2016
}

@article{journals/tnn/Liu0TC19,
  author = {Liu, Yan-Jun and Li, Shu and Tong, Shaocheng and Chen, C. L. Philip},
  journal = {IEEE Trans. Neural Networks Learn. Syst.},
  number = 1,
  pages = {295-305},
  title = {Adaptive Reinforcement Learning Control Based on Neural Approximation for Nonlinear Discrete-Time Systems With Unknown Nonaffine Dead-Zone Input.},
  volume = 30,
  year = 2019
}

@article{ma20,
  author = {Ma, Xiaoteng and Zhang, Qiyuan and Xia, Li and Zhou, Zhengyuan and Yang, Jun and Zhao, Qianchuan},
  title = {Distributional Soft Actor Critic for Risk Sensitive Learning.},
  year = 2020,
  journal={arXiv preprint arXiv:2004.14547},
  ee = {https://arxiv.org/abs/2004.14547},
}

@InProceedings{mavrin19a,
    title = 	 {Distributional Reinforcement Learning for Efficient Exploration},
    author = 	 {Mavrin, Borislav and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen and Yu, Yaoliang},
    booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML)},
    year = 	 {2019},
}

@article{mnih15,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  journal = {Nature},
  number = 7540,
  pages = {529--533},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}

@article{moerland17,
  title={Efficient exploration with Double Uncertain Value Networks},
  author={Thomas M. Moerland and Joost Broekens and Catholijn M. Jonker},
  journal={Proceedings of the 30th International Conference on Neural Information Processing Systems (NeurIPS)},
  year={2017},
}

@inproceedings{morimura10a,
  author = {Morimura, Tetsuro and Sugiyama, Masashi and Kashima, Hisashi and Hachiya, Hirotaka and Tanaka, Toshiyuki},
  booktitle = {UAI},
  pages = {368-375},
  publisher = {AUAI Press},
  title = {Parametric Return Density Estimation for Reinforcement Learning.},
  year = 2010
}

@inproceedings{morimura10b,
  author = {Morimura, Tetsuro and Sugiyama, Masashi and Kashima, Hisashi and Hachiya, Hirotaka and Tanaka, Toshiyuki},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML)},
  title = {Nonparametric Return Distribution Approximation for Reinforcement Learning.},
  year = 2010
}

@inproceedings{nikolov18,
    title       = {Information-Directed Exploration for Deep Reinforcement Learning},
    author      = {Nikolay Nikolov and 
                   Johannes Kirschner and 
                   Felix Berkenkamp and 
                   Andreas Krause},
    booktitle   = {International Conference on Learning Representations (ICLR)},
    year        = {2019},
}

@book{puterman94,
    author = {Puterman, Martin L.},
    title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
    year = {1994},
    publisher = {John Wiley \& Sons, Inc.},
    edition = {1st}
}

@MISC{pybullet,
    author =   {Erwin Coumans and Yunfei Bai},
    title =    {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
    howpublished = {\url{http://pybullet.org}},
    year = {2016--2020}
}

@InProceedings{qu19,
  title = 	 {Nonlinear Distributional Gradient Temporal-Difference Learning},
  author =       {Qu, Chao and Mannor, Shie and Xu, Huan},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5251--5260},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}

@inproceedings{rowland18,
  author = {Rowland, Mark and Bellemare, Marc G. and Dabney, Will and Munos, Rémi and Teh, Yee Whye},
  booktitle = {Artificial Intelligence and Statistics (AISTATS)},
  editor = {Storkey, Amos J. and Pérez-Cruz, Fernando},
  pages = {29-37},
  publisher = {PMLR},
  series = {Proceedings of Machine Learning Research},
  title = {An Analysis of Categorical Distributional Reinforcement Learning.},
  volume = 84,
  year = 2018
}

@inproceedings{rowland19,
  author = {Rowland, Mark and Dadashi, Robert and Kumar, Saurabh and Munos, Rémi and Bellemare, Marc G. and Dabney, Will},
  title = {Statistics and samples in distributional reinforcement learning},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  year = 2019
}

@inproceedings{schulman15,
    title = 	 {Trust Region Policy Optimization},
    author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
    booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning (ICML)},
    year = 	 {2015},
}

@inproceedings{schulman16,
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I. and Abbeel, Pieter},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation.},
  year = 2016
}

@article{schulman17,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  year      = {2017},
  ee = {http://arxiv.org/abs/1707.06347},
  journal={arXiv preprint arXiv:1707.06347},
}

@article{silver16,
  author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal = {Nature},
  number = 7587,
  pages = {484--489},
  publisher = {Nature Publishing Group},
  title = {Mastering the game of Go with deep neural networks and tree search},
  volume = 529,
  year = 2016
}

@article{singh20,
  author = {Singh, Rahul and Lee, Keuntaek and Chen, Yongxin},
  title = {Sample-based Distributional Policy Gradient.},
  year = 2020,
  ee = {https://arxiv.org/abs/2001.02652},
  journal={arXiv preprint arXiv:2001.02652},
}

@article{sutton88,
    author = {Sutton, Richard S.},
    title = {Learning to Predict by the Methods of Temporal Differences},
    year = {1988},
    issue_date = {August 1988},
    publisher = {Kluwer Academic Publishers},
    address = {USA},
    volume = {3},
    number = {1},
    issn = {0885-6125},
    doi = {10.1023/A:1022633531479},
    journal = {Machine Learning},
    month = {aug},
    pages = {9–44},
    numpages = {36},
    keywords = {evaluation functions, credit assignment, connectionism, Incremental learning, prediction}
}

@book{sutton98,
    author = {Sutton, Richard S. and Barto, Andrew G.},
    title = {Introduction to Reinforcement Learning},
    year = {1998},
    isbn = {0262193981},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    edition = {1st}
}

@inproceedings{sutton99,
  acmid = {3009806},
  address = {Cambridge, MA, USA},
  author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
  booktitle = {Proceedings of the 12th International Conference on Neural Information Processing Systems (NeurIPS)},
  title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  year = {1999}
}

@article{szekely,
    author = {Székely, Gabor},
    year = {2002},
    month = {10},
    pages = {},
    title = {E-statistics: The Energy of Statistical Samples},
    doi = {10.13140/RG.2.1.5063.9761}
}

@article{seijen11,
  author = {van Seijen, Harm and Whiteson, Shimon and van Hasselt, Hado and Wiering, Marco},
  journal = {Journal of  Machine Learning Research},
  pages = {2045-2094},
  title = {Exploiting Best-Match Equations for Efficient Reinforcement Learning.},
  volume = 12,
  year = 2011
}

@phdthesis{watkins89,
  author = {Watkins, C. J. C. H.},
  citeulike-article-id = {2381652},
  priority = {2},
  school = {King's College, Oxford},
  title = {Learning from Delayed Rewards},
  year = 1989
}

@techreport{williams88,
  author = {Williams, R. J.},
  citeulike-article-id = {2381669},
  description = {idsia},
  institution = {College of Comp. Sci., Northeastern University, Boston, MA},
  number = {NU-CCS-88-3},
  title = {Toward a theory of reinforcement-learning connectionist systems},
  year = 1988
}

@article{williams92,
  author = {Williams, R. J.},
  citeulike-article-id = {2374762},
  description = {idsia},
  journal = {Machine Learning},
  keywords = {daanbib},
  pages = {229--256},
  priority = {2},
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  volume = 8,
  year = 1992
}

@inproceedings{yang19,
    author = {Yang, Derek and Zhao, Li and Lin, Zichuan and Qin, Tao and Bian, Jiang and Liu, Tie-Yan},
    booktitle = {33rd Annual Conference on Neural Information Processing Systems (NeurIPS)},
    pages = {6190-6199},
    title = {Fully Parameterized Quantile Function for Distributional Reinforcement Learning.},
    year = 2019
}

@article{duan20,
  title={Distributional soft actor-critic: Off-policy reinforcement learning for addressing value estimation errors},
  author={Duan, Jingliang and Guan, Yang and Li, Shengbo Eben and Ren, Yangang and Cheng, Bo},
  journal={arXiv preprint arXiv:2001.02811},
  ee = {https://arxiv.org/abs/2001.02811},
  year={2020}
}

@book{bogachev07,
  title={Measure theory},
  author={Bogachev, Vladimir I},
  volume={1},
  year={2007},
  publisher={Springer Science \& Business Media}
}