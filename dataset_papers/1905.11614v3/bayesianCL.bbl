\begin{thebibliography}{10}

\bibitem{(BBB)BlundelWierstra15}
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra.
\newblock Weight uncertainty in neural network.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  1613--1622, 2015.

\bibitem{(spdilemma)carpenter87}
Gail~A Carpenter and Stephen Grossberg.
\newblock Art 2: Self-organization of stable category recognition codes for
  analog input patterns.
\newblock {\em Applied Optics}, 26(23):4919--4930, 1987.

\bibitem{(MDL)HintonCamp99}
Geoffrey E.~Hinton and Drew Van~Camp.
\newblock Keeping neural networks simple by minimizing the description length
  of the weights.
\newblock {\em Proceedings of COLT-93}, 07 1999.

\bibitem{(cata)french99}
Robert~M French.
\newblock Catastrophic forgetting in connectionist networks.
\newblock {\em Trends in Cognitive Sciences}, 3(4):128--135, 1999.

\bibitem{(MC-dropout)GalZoubin16}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em International Conference on Machine Learning (ICLR)}, pages
  1050--1059, 2016.

\bibitem{(Practical)Graves11}
Alex Graves.
\newblock Practical variational inference for neural networks.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 2348--2356, 2011.

\bibitem{HeZhaRenSun15}
K.~He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Computer Vision and Pattern Recognition (CVPR)}, 2015.

\bibitem{(PBP)LobatoMiguelAdams15}
Jos{\'e}~Miguel Hern{\'a}ndez-Lobato and Ryan Adams.
\newblock Probabilistic backpropagation for scalable learning of bayesian
  neural networks.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  1861--1869, 2015.

\bibitem{(Distill)HintonOriolDean15}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2015.

\bibitem{(Fearnet)kemker17}
Ronald Kemker and Christopher Kanan.
\newblock Fearnet: Brain-inspired model for incremental learning.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{(VAE)KingWell14}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2014.

\bibitem{(EWC)KirkPascRabi17}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and
  Raia Hadsell.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the National Academy of Sciences},
  114(13):3521--3526, 2017.

\bibitem{(IMM)LeeKimJunHaZhang17}
Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, and Byoung-Tak Zhang.
\newblock Overcoming catastrophic forgetting by incremental moment matching.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 4652--4662. 2017.

\bibitem{(LwF)LiHoiem16}
Zhizhong Li and Derek Hoiem.
\newblock Learning without forgetting.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  40(12):2935--2947, 2017.

\bibitem{(GEM)LopezRanzato17}
David Lopez-Paz and Marc~Aurelio Ranzato.
\newblock Gradient episodic memory for continual learning.
\newblock In {\em Advances in Neural Information Processing System (NIPS)},
  pages 6467--6476. 2017.

\bibitem{(Packnet)MallyaLazebnik18}
Arun Mallya and Svetlana Lazebnik.
\newblock Packnet: Adding multiple tasks to a single network by iterative
  pruning.
\newblock In {\em The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2018.

\bibitem{(cata)mccloskey89}
Michael McCloskey and Neal~J Cohen.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock In {\em Psychology of Learning and Motivation}, volume~24, pages
  109--165. Elsevier, 1989.

\bibitem{(spdilemma)mermillod13}
Martial Mermillod, Aur{\'e}lia Bugaiska, and Patrick Bonin.
\newblock The stability-plasticity dilemma: Investigating the continuum from
  catastrophic forgetting to age-limited learning effects.
\newblock {\em Frontiers in Psychology}, 4:504, 2013.

\bibitem{(VCL)NguLiBuiTurner18}
Cuong~V. Nguyen, Yingzhen Li, Thang~D. Bui, and Richard~E. Turner.
\newblock Variational continual learning.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{(Review)PariKemPartKananWerm18}
German~Ignacio Parisi, Ronald Kemker, Jose~L. Part, Christopher Kanan, and
  Stefan Wermter.
\newblock Continual lifelong learning with neural networks: {A} review.
\newblock {\em CoRR}, abs/1802.07569, 2018.

\bibitem{(RLNoise)PlappertAndry18}
Matthias Plappert, Rein Houthooft, Prafulla Dhariwal, Szymon Sidor, Richard~Y.
  Chen, Xi~Chen, Tamim Asfour, Pieter Abbeel, and Marcin Andrychowicz.
\newblock Parameter space noise for exploration.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{(icarl)rebuffi17}
Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph~H
  Lampert.
\newblock icarl: Incremental classifier and representation learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 2001--2010, 2017.

\bibitem{(PNN)RusuRabiDesjSoyeKirk2016}
Andrei~A Rusu, Neil~C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James
  Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell.
\newblock Progressive neural networks.
\newblock {\em arXiv preprint arXiv:1606.04671}, 2016.

\bibitem{(PPO)SchulmanWlskiKlimov}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{(ProgressCompress)SchwarzLuketinaHadsell18}
Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka
  Grabska-Barwinska, Yee~Whye Teh, Razvan Pascanu, and Raia Hadsell.
\newblock Progress \& compress: A scalable framework for continual learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  4528--4537, 2018.

\bibitem{SerraSurisMironKarat2018(HAT)}
Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou.
\newblock Overcoming catastrophic forgetting with hard attention to the task.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  4548--4557, 2018.

\bibitem{(DGR)ShinLeeKimKim17}
Hanul Shin, Jung~Kwon Lee, Jaehong Kim, and Jiwon Kim.
\newblock Continual learning with deep generative replay.
\newblock In {\em Advances in Neural Information Processing System (NIPS)},
  pages 2990--2999. 2017.

\bibitem{SriHinKriSutSal14}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: {A} simple way to prevent neural networks from overfitting.
\newblock {\em Journal of Machine Learning Research}, 15:1929--1958, 2014.

\bibitem{(DEN)YoonYangLeeHwang18}
Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung~Ju Hwang.
\newblock Lifelong learning with dynamically expandable networks.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{(SI)ZenkePooleGang17}
Friedemann Zenke, Ben Poole, and Surya Ganguli.
\newblock Continual learning through synaptic intelligence.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  3987--3995, 2017.

\end{thebibliography}
