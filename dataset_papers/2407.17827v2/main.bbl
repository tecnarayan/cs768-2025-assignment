\begin{thebibliography}{10}

\bibitem{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{alayrac2022flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock {\em Advances in neural information processing systems}, 35:23716--23736, 2022.

\bibitem{bhalla2024interpreting}
Usha Bhalla, Alex Oesterling, Suraj Srinivas, Flavio~P Calmon, and Himabindu Lakkaraju.
\newblock Interpreting clip with sparse linear concept embeddings (splice).
\newblock {\em arXiv preprint arXiv:2402.10376}, 2024.

\bibitem{changpinyo2021conceptual}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 3558--3568, 2021.

\bibitem{chen2023stair}
Chen Chen, Bowen Zhang, Liangliang Cao, Jiguang Shen, Tom Gunter, Albin~Madappally Jose, Alexander Toshev, Jonathon Shlens, Ruoming Pang, and Yinfei Yang.
\newblock Stair: Learning sparse text and image representation in grounded tokens.
\newblock {\em arXiv preprint arXiv:2301.13081}, 2023.

\bibitem{chen2022prototypical}
Delong Chen, Zhao Wu, Fan Liu, Zaiquan Yang, Yixiang Huang, Yiping Bao, and Erjin Zhou.
\newblock Prototypical contrastive language image pretraining.
\newblock {\em arXiv preprint arXiv:2206.10996}, 2022.

\bibitem{croft2010search}
W~Bruce Croft, Donald Metzler, and Trevor Strohman.
\newblock {\em Search engines: Information retrieval in practice}, volume 520.
\newblock Addison-Wesley Reading, 2010.

\bibitem{dai2024instructblip}
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng~Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale~N Fung, and Steven Hoi.
\newblock Instructblip: Towards general-purpose vision-language models with instruction tuning.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{doveh2024dense}
Sivan Doveh, Assaf Arbelle, Sivan Harary, Roei Herzig, Donghyun Kim, Paola Cascante-Bonilla, Amit Alfassy, Rameswar Panda, Raja Giryes, Rogerio Feris, et~al.
\newblock Dense and aligned captions (dac) promote compositional reasoning in vl models.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{duan2022multi}
Jiali Duan, Liqun Chen, Son Tran, Jinyu Yang, Yi~Xu, Belinda Zeng, and Trishul Chilimbi.
\newblock Multi-modal alignment using representation codebook.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15651--15660, 2022.

\bibitem{formal2021splade}
Thibault Formal, Benjamin Piwowarski, and St{\'e}phane Clinchant.
\newblock Splade: Sparse lexical and expansion model for first stage ranking.
\newblock In {\em Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval}, pages 2288--2292, 2021.

\bibitem{gao2021coil}
Luyu Gao, Zhuyun Dai, and Jamie Callan.
\newblock Coil: Revisit exact lexical match in information retrieval with contextualized inverted list.
\newblock {\em arXiv preprint arXiv:2104.07186}, 2021.

\bibitem{hu2022lora}
Edward~J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, Weizhu Chen, et~al.
\newblock Lora: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{kamath2023s}
Amita Kamath, Jack Hessel, and Kai-Wei Chang.
\newblock What's" up" with vision-language models? investigating their struggle with spatial reasoning.
\newblock {\em arXiv preprint arXiv:2310.19785}, 2023.

\bibitem{karpathy2015deep}
Andrej Karpathy and Li~Fei-Fei.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 3128--3137, 2015.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4015--4026, 2023.

\bibitem{kudo2018sentencepiece}
Taku Kudo and John Richardson.
\newblock Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing.
\newblock In {\em Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pages 66--71, 2018.

\bibitem{li2023blip}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In {\em International conference on machine learning}, pages 19730--19742. PMLR, 2023.

\bibitem{li2021supervision}
Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao, Fengwei Yu, and Junjie Yan.
\newblock Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm.
\newblock {\em arXiv preprint arXiv:2110.05208}, 2021.

\bibitem{li2022supervision}
Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao, Fengwei Yu, and Junjie Yan.
\newblock Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755. Springer, 2014.

\bibitem{liu2024visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em Advances in neural information processing systems}, 36, 2024.

\bibitem{luo2023lexlip}
Ziyang Luo, Pu~Zhao, Can Xu, Xiubo Geng, Tao Shen, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang.
\newblock Lexlip: Lexicon-bottlenecked language-image pre-training for large-scale image-text sparse retrieval.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 11206--11217, 2023.

\bibitem{mu2022slip}
Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock In {\em European conference on computer vision}, pages 529--544. Springer, 2022.

\bibitem{nair2010rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em Proceedings of the 27th international conference on machine learning (ICML-10)}, pages 807--814, 2010.

\bibitem{oesper2011wordcloud}
Layla Oesper, Daniele Merico, Ruth Isserlin, and Gary~D Bader.
\newblock Wordcloud: a cytoscape plugin to create a visual semantic summary of networks.
\newblock {\em Source code for biology and medicine}, 6(1):7, 2011.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timoth{\'e}e Darcet, Th{\'e}o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et~al.
\newblock Dinov2: Learning robust visual features without supervision.
\newblock {\em arXiv preprint arXiv:2304.07193}, 2023.

\bibitem{Paria2020Minimizing}
Biswajit Paria, Chih-Kuan Yeh, Ian~E.H. Yen, Ning Xu, Pradeep Ravikumar, and Barnabás Póczos.
\newblock Minimizing flops to learn efficient sparse representations.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{peters2018deep}
ME~Peters, M~Neumann, M~Iyyer, M~Gardner, C~Clark, K~Lee, and L~Zettlemoyer.
\newblock Deep contextualized word representations. corr.
\newblock {\em arXiv preprint arXiv:1802.05365}, 2018.

\bibitem{plummer2015flickr30k}
Bryan~A Plummer, Liwei Wang, Chris~M Cervantes, Juan~C Caicedo, Julia Hockenmaier, and Svetlana Lazebnik.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 2641--2649, 2015.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem{sennrich2016neural}
Rico Sennrich, Barry Haddow, and Alexandra Birch.
\newblock Neural machine translation of rare words with subword units.
\newblock In {\em Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1715--1725, 2016.

\bibitem{sun2023eva}
Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue Cao.
\newblock Eva-clip: Improved training techniques for clip at scale.
\newblock {\em arXiv preprint arXiv:2303.15389}, 2023.

\bibitem{team2023gemini}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M Dai, Anja Hauth, et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock {\em arXiv preprint arXiv:2312.11805}, 2023.

\bibitem{tong2024eyes}
Shengbang Tong, Zhuang Liu, Yuexiang Zhai, Yi~Ma, Yann LeCun, and Saining Xie.
\newblock Eyes wide shut? exploring the visual shortcomings of multimodal llms.
\newblock {\em arXiv preprint arXiv:2401.06209}, 2024.

\bibitem{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{wang2023can}
Fei Wang, Liang Ding, Jun Rao, Ye~Liu, Li~Shen, and Changxing Ding.
\newblock Can linguistic knowledge improve multimodal alignment in vision-language pretraining?
\newblock {\em arXiv preprint arXiv:2308.12898}, 2023.

\bibitem{wang2023image}
Wenhui Wang, Hangbo Bao, Li~Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais~Khan Mohammed, Saksham Singhal, Subhojit Som, et~al.
\newblock Image as a foreign language: Beit pretraining for vision and vision-language tasks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 19175--19186, 2023.

\bibitem{yao2022filip}
Lewei Yao, Runhui Huang, Lu~Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiaodan Liang, Zhenguo Li, Xin Jiang, and Chunjing Xu.
\newblock {FILIP}: Fine-grained interactive language-image pre-training.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock {\em arXiv preprint arXiv:2205.01917}, 2022.

\bibitem{yuksekgonul2022and}
Mert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, and James Zou.
\newblock When and why vision-language models behave like bags-of-words, and what to do about it?
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{zamani2018neural}
Hamed Zamani, Mostafa Dehghani, W~Bruce Croft, Erik Learned-Miller, and Jaap Kamps.
\newblock From neural re-ranking to neural ranking: Learning a sparse representation for inverted indexing.
\newblock In {\em Proceedings of the 27th ACM international conference on information and knowledge management}, pages 497--506, 2018.

\bibitem{zhai2022lit}
Xiaohua Zhai, Xiao Wang, Basil Mustafa, Andreas Steiner, Daniel Keysers, Alexander Kolesnikov, and Lucas Beyer.
\newblock Lit: Zero-shot transfer with locked-image text tuning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18123--18133, 2022.

\bibitem{zhou2023retrieval}
Jiawei Zhou, Xiaoguang Li, Lifeng Shang, Xin Jiang, Qun Liu, and Lei Chen.
\newblock Retrieval-based disentangled representation learning with natural language supervision.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{zhu2023minigpt}
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.
\newblock Minigpt-4: Enhancing vision-language understanding with advanced large language models.
\newblock {\em arXiv preprint arXiv:2304.10592}, 2023.

\end{thebibliography}
