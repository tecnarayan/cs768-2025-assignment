\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdel-Hamid and Jiang(2013)]{abdel2013fast}
O.~Abdel-Hamid and H.~Jiang.
\newblock Fast speaker adaptation of hybrid nn/hmm model for speech recognition
  based on discriminative learning of speaker code.
\newblock In \emph{IEEE ICASSP}, 2013.

\bibitem[Agiomyrgiannakis and Roupakia(2016)]{VoiceMorphing}
Y.~Agiomyrgiannakis and Z.~Roupakia.
\newblock Voice morphing that improves tts quality using an optimal dynamic
  frequency warping-and-weighting transform.
\newblock \emph{IEEE ICASSP}, 2016.

\bibitem[Amodei et~al.(2016)Amodei, Ananthanarayanan, Anubhai, Bai, Battenberg,
  Case, Casper, Catanzaro, Cheng, Chen, et~al.]{amodei2016deep}
D.~Amodei, S.~Ananthanarayanan, R.~Anubhai, J.~Bai, E.~Battenberg, C.~Case,
  J.~Casper, B.~Catanzaro, Q.~Cheng, G.~Chen, et~al.
\newblock Deep speech 2: End-to-end speech recognition in english and mandarin.
\newblock In \emph{International Conference on Machine Learning}, pages
  173--182, 2016.

\bibitem[Arik et~al.(2017{\natexlab{a}})Arik, Chrzanowski, Coates, Diamos,
  Gibiansky, Kang, Li, Miller, Raiman, Sengupta, and Shoeybi]{DeepVoice1}
S.~{\"{O}}. Arik, M.~Chrzanowski, A.~Coates, G.~Diamos, A.~Gibiansky, Y.~Kang,
  X.~Li, J.~Miller, J.~Raiman, S.~Sengupta, and M.~Shoeybi.
\newblock Deep {V}oice: Real-time neural text-to-speech.
\newblock In \emph{ICML}, 2017{\natexlab{a}}.

\bibitem[Arik et~al.(2017{\natexlab{b}})Arik, Diamos, Gibiansky, Miller, Peng,
  Ping, Raiman, and Zhou]{DeepVoice2}
S.~{\"{O}}. Arik, G.~F. Diamos, A.~Gibiansky, J.~Miller, K.~Peng, W.~Ping,
  J.~Raiman, and Y.~Zhou.
\newblock Deep {V}oice 2: Multi-speaker neural text-to-speech.
\newblock In \emph{NIPS}, pages 2966--2974, 2017{\natexlab{b}}.

\bibitem[Azadi et~al.(2017)Azadi, Fisher, Kim, Wang, Shechtman, and
  Darrell]{fewshotfont}
S.~Azadi, M.~Fisher, V.~Kim, Z.~Wang, E.~Shechtman, and T.~Darrell.
\newblock Multi-content gan for few-shot font style transfer.
\newblock \emph{CoRR}, abs/1708.02182, 2017.

\bibitem[Chen et~al.(2014)Chen, Ling, Liu, and Dai]{voiceConvNN2}
L.~H. Chen, Z.~H. Ling, L.~J. Liu, and L.~R. Dai.
\newblock Voice conversion using deep neural networks with layer-wise
  generative training.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 2014.

\bibitem[Cui et~al.(2017)Cui, Goel, and Saon]{cui2017embedding}
X.~Cui, V.~Goel, and G.~Saon.
\newblock Embedding-based speaker adaptive training of deep neural networks.
\newblock \emph{arXiv preprint arXiv:1710.06937}, 2017.

\bibitem[Desai et~al.(2010)Desai, Black, Yegnanarayana, and
  Prahallad]{voiceConvNN1}
S.~Desai, A.~W. Black, B.~Yegnanarayana, and K.~Prahallad.
\newblock Spectral mapping using artificial neural networks for voice
  conversion.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  2010.

\bibitem[Hwang et~al.(2015)Hwang, Tsao, Wang, Wang, and Chen]{voiceConvNN3}
H.~T. Hwang, Y.~Tsao, H.~M. Wang, Y.~R. Wang, and S.~H. Chen.
\newblock A probabilistic interpretation for artificial neural network-based
  voice conversion.
\newblock In \emph{2015 Asia-Pacific Signal and Information Processing
  Association Annual Summit and Conference (APSIPA)}, 2015.

\bibitem[Jozefowicz et~al.(2016)Jozefowicz, Vinyals, Schuster, Shazeer, and
  Wu]{jozefowicz2016exploring}
R.~Jozefowicz, O.~Vinyals, M.~Schuster, N.~Shazeer, and Y.~Wu.
\newblock Exploring the limits of language modeling.
\newblock \emph{arXiv preprint arXiv:1602.02410}, 2016.

\bibitem[Karras et~al.(2017)Karras, Aila, Laine, and Lehtinen]{progressiveGAN}
T.~Karras, T.~Aila, S.~Laine, and J.~Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock \emph{CoRR}, abs/1710.10196, 2017.

\bibitem[Lake et~al.(2013)Lake, Salakhutdinov, and
  Tenenbaum]{Lake2013OneshotLB}
B.~M. Lake, R.~Salakhutdinov, and J.~B. Tenenbaum.
\newblock One-shot learning by inverting a compositional causal process.
\newblock In \emph{NIPS}, 2013.

\bibitem[Lake et~al.(2014)Lake, ying Lee, Glass, and
  Tenenbaum]{Lake2014OneshotLO}
B.~M. Lake, C.~ying Lee, J.~R. Glass, and J.~B. Tenenbaum.
\newblock One-shot learning of generative speech concepts.
\newblock In \emph{CogSci}, 2014.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{Lake1332}
B.~M. Lake, R.~Salakhutdinov, and J.~B. Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 2015.

\bibitem[Li and Wu(2015)]{Dvector1}
X.~Li and X.~Wu.
\newblock Modeling speaker variability using long short-term memory networks
  for speech recognition.
\newblock In \emph{INTERSPEECH}, 2015.

\bibitem[Mehri et~al.(2016)Mehri, Kumar, Gulrajani, Kumar, Jain, Sotelo,
  Courville, and Bengio]{mehri2016samplernn}
S.~Mehri, K.~Kumar, I.~Gulrajani, R.~Kumar, S.~Jain, J.~Sotelo, A.~Courville,
  and Y.~Bengio.
\newblock Samplernn: An unconditional end-to-end neural audio generation model.
\newblock \emph{arXiv preprint arXiv:1612.07837}, 2016.

\bibitem[Miao and Metze(2015)]{miao2015speaker}
Y.~Miao and F.~Metze.
\newblock On speaker adaptation of long short-term memory recurrent neural
  networks.
\newblock In \emph{Sixteenth Annual Conference of the International Speech
  Communication Association}, 2015.

\bibitem[Miao et~al.(2015)Miao, Zhang, and Metze]{Ivector1}
Y.~Miao, H.~Zhang, and F.~Metze.
\newblock Speaker adaptive training of deep neural network acoustic models
  using i-vectors.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 2015.

\bibitem[Oord et~al.(2016{\natexlab{a}})Oord, Dieleman, Zen, Simonyan, Vinyals,
  Graves, Kalchbrenner, Senior, and Kavukcuoglu]{van2016wavenet}
A.~v.~d. Oord, S.~Dieleman, H.~Zen, K.~Simonyan, O.~Vinyals, A.~Graves,
  N.~Kalchbrenner, A.~Senior, and K.~Kavukcuoglu.
\newblock Wavenet: A generative model for raw audio.
\newblock \emph{arXiv preprint arXiv:1609.03499}, 2016{\natexlab{a}}.

\bibitem[Oord et~al.(2016{\natexlab{b}})Oord, Kalchbrenner, Espeholt, Vinyals,
  Graves, et~al.]{van2016conditional}
A.~v.~d. Oord, N.~Kalchbrenner, L.~Espeholt, O.~Vinyals, A.~Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2016{\natexlab{b}}.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{panayotov2015librispeech}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur.
\newblock Librispeech: an {ASR} corpus based on public domain audio books.
\newblock In \emph{IEEE ICASSP}, 2015.

\bibitem[Ping et~al.(2018)Ping, Peng, Gibiansky, Arik, Kannan, Narang, Raiman,
  and Miller]{DeepVoice3}
W.~Ping, K.~Peng, A.~Gibiansky, S.~Arik, A.~Kannan, S.~Narang, J.~Raiman, and
  J.~Miller.
\newblock Deep {V}oice 3: Scaling text-to-speech with convolutional sequence
  learning.
\newblock In \emph{ICLR}, 2018.

\bibitem[Prince and Elder(2007)]{prince2007probabilistic}
S.~Prince and J.~Elder.
\newblock Probabilistic linear discriminant analysis for inferences about
  identity.
\newblock In \emph{ICCV}, 2007.

\bibitem[Reed et~al.(2017)Reed, Chen, Paine, van~den Oord, Eslami, Rezende,
  Vinyals, and de~Freitas]{FewShotAutoregressive}
S.~E. Reed, Y.~Chen, T.~Paine, A.~van~den Oord, S.~M.~A. Eslami, D.~J. Rezende,
  O.~Vinyals, and N.~de~Freitas.
\newblock Few-shot autoregressive density estimation: Towards learning to learn
  distributions.
\newblock \emph{CoRR}, 2017.

\bibitem[Rezende et~al.(2016)Rezende, Shakir, Danihelka, Gregor, and
  Wierstra]{oneshotgeneralization}
D.~Rezende, Shakir, I.~Danihelka, K.~Gregor, and D.~Wierstra.
\newblock One-shot generalization in deep generative models.
\newblock In \emph{ICML}, 2016.

\bibitem[Shen et~al.(2017)Shen, Pang, Weiss, Schuster, Jaitly, Yang, Chen,
  Zhang, Wang, Skerry-Ryan, et~al.]{shen2017natural}
J.~Shen, R.~Pang, R.~J. Weiss, M.~Schuster, N.~Jaitly, Z.~Yang, Z.~Chen,
  Y.~Zhang, Y.~Wang, R.~Skerry-Ryan, et~al.
\newblock Natural tts synthesis by conditioning wavenet on mel spectrogram
  predictions.
\newblock \emph{arXiv preprint arXiv:1712.05884}, 2017.

\bibitem[Snyder et~al.(2016)Snyder, Ghahremani, Povey, Garcia-Romero, Carmiel,
  and Khudanpur]{snyder2016deep}
D.~Snyder, P.~Ghahremani, D.~Povey, D.~Garcia-Romero, Y.~Carmiel, and
  S.~Khudanpur.
\newblock Deep neural network-based speaker embeddings for end-to-end speaker
  verification.
\newblock In \emph{IEEE Spoken Language Technology Workshop (SLT)}, pages
  165--170, 2016.

\bibitem[Sotelo et~al.(2017)Sotelo, Mehri, Kumar, Santos, Kastner, Courville,
  and Bengio]{sotelo2017char2wav}
J.~Sotelo, S.~Mehri, K.~Kumar, J.~F. Santos, K.~Kastner, A.~Courville, and
  Y.~Bengio.
\newblock Char2wav: End-to-end speech synthesis.
\newblock 2017.

\bibitem[Taigman et~al.(2018)Taigman, Wolf, Polyak, and
  Nachmani]{taigman2018voiceloop}
Y.~Taigman, L.~Wolf, A.~Polyak, and E.~Nachmani.
\newblock Voiceloop: Voice fitting and synthesis via a phonological loop.
\newblock In \emph{ICLR}, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{Attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{NIPS}. 2017.

\bibitem[Veaux et~al.(2017)Veaux, Yamagishi, and MacDonald]{vctk2017}
C.~Veaux, J.~Yamagishi, and K.~e.~a. MacDonald.
\newblock Cstr vctk corpus: English multi-speaker corpus for cstr voice cloning
  toolkit, 2017.

\bibitem[Wang et~al.(2017)Wang, Skerry{-}Ryan, Stanton, Wu, Weiss, Jaitly,
  Yang, Xiao, Chen, Bengio, Le, Agiomyrgiannakis, Clark, and
  Saurous]{Tacotron1}
Y.~Wang, R.~J. Skerry{-}Ryan, D.~Stanton, Y.~Wu, R.~J. Weiss, N.~Jaitly,
  Z.~Yang, Y.~Xiao, Z.~Chen, S.~Bengio, Q.~V. Le, Y.~Agiomyrgiannakis,
  R.~Clark, and R.~A. Saurous.
\newblock Tacotron: {A} fully end-to-end text-to-speech synthesis model.
\newblock \emph{CoRR}, abs/1703.10135, 2017.

\bibitem[Wester et~al.(2016)Wester, Wu, and
  Yamagishi]{VoiceConversionCompetition}
M.~Wester, Z.~Wu, and J.~Yamagishi.
\newblock Analysis of the voice conversion challenge 2016 evaluation results.
\newblock In \emph{INTERSPEECH}, pages 1637--1641, 09 2016.

\bibitem[Wu et~al.(2016)Wu, Hwang, Hsu, Tsao, and Wang]{voiceconvlle}
Y.-C. Wu, H.-T. Hwang, C.-C. Hsu, Y.~Tsao, and H.-m. Wang.
\newblock Locally linear embedding for exemplar-based spectral conversion.
\newblock In \emph{INTERSPEECH}, pages 1652--1656, 09 2016.

\bibitem[Wu et~al.(2015)Wu, Swietojanski, Veaux, Renals, and King]{Ivector2}
Z.~Wu, P.~Swietojanski, C.~Veaux, S.~Renals, and S.~King.
\newblock A study of speaker adaptation for dnn-based speech synthesis.
\newblock In \emph{INTERSPEECH}, 2015.

\bibitem[Xue et~al.(2014)Xue, Abdel-Hamid, Jiang, Dai, and
  Liu]{speakerdependentASR2}
S.~Xue, O.~Abdel-Hamid, H.~Jiang, L.~Dai, and Q.~Liu.
\newblock Fast adaptation of deep neural network based on discriminant codes
  for speech recognition.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 2014.

\bibitem[Yamagishi et~al.(2009)Yamagishi, Kobayashi, Nakano, Ogata, and
  Isogai]{yamagishi2009analysis}
J.~Yamagishi, T.~Kobayashi, Y.~Nakano, K.~Ogata, and J.~Isogai.
\newblock Analysis of speaker adaptation algorithms for hmm-based speech
  synthesis and a constrained smaplr adaptation algorithm.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  2009.

\bibitem[Yu et~al.(2013)Yu, Yao, Su, Li, and Seide]{yu2013kl}
D.~Yu, K.~Yao, H.~Su, G.~Li, and F.~Seide.
\newblock Kl-divergence regularized deep neural network adaptation for improved
  large vocabulary speech recognition.
\newblock In \emph{IEEE ICASSP}, 2013.

\end{thebibliography}
