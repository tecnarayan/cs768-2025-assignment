\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020)Agarwal, Kakade, Lee, and Mahajan]{AgarwalKLM20}
Agarwal, A., Kakade, S.~M., Lee, J.~D., and Mahajan, G.
\newblock Optimality and approximation with policy gradient methods in markov
  decision processes.
\newblock In Abernethy, J.~D. and Agarwal, S. (eds.), \emph{Conference on
  Learning Theory, {COLT} 2020, 9-12 July 2020, Virtual Event [Graz, Austria]},
  volume 125 of \emph{Proceedings of Machine Learning Research}, pp.\  64--66.
  {PMLR}, 2020.
\newblock URL \url{http://proceedings.mlr.press/v125/agarwal20a.html}.

\bibitem[Agarwal et~al.(2021)Agarwal, Kakade, Lee, and
  Mahajan]{agarwal2021theory}
Agarwal, A., Kakade, S.~M., Lee, J.~D., and Mahajan, G.
\newblock On the theory of policy gradient methods: Optimality, approximation,
  and distribution shift.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (98):\penalty0 1--76, 2021.

\bibitem[Azizian et~al.(2021)Azizian, Iutzeler, Malick, and
  Mertikopoulos]{AIMM21}
Azizian, W., Iutzeler, F., Malick, J., and Mertikopoulos, P.
\newblock The last-iterate convergence rate of optimistic mirror descent in
  stochastic variational inequalities.
\newblock In \emph{COLT '21: Proceedings of the 34th Annual Conference on
  Learning Theory}, 2021.

\bibitem[Baxter \& Bartlett(2001)Baxter and Bartlett]{baxter2001infinite}
Baxter, J. and Bartlett, P.~L.
\newblock Infinite-horizon policy-gradient estimation.
\newblock \emph{Journal of Artificial Intelligence Research}, 15:\penalty0
  319--350, 2001.

\bibitem[Bhandari \& Russo(2019)Bhandari and Russo]{bhandari2019global}
Bhandari, J. and Russo, D.
\newblock Global optimality guarantees for policy gradient methods.
\newblock \emph{arXiv preprint arXiv:1906.01786}, 2019.

\bibitem[Bubeck(2015)]{Bub15}
Bubeck, S.
\newblock Convex optimization: {Algorithms} and complexity.
\newblock \emph{Foundations and Trends in Machine Learning}, 8\penalty0
  (3-4):\penalty0 231--358, 2015.

\bibitem[Cen et~al.(2021)Cen, Wei, and Chi]{Cen21:Fast}
Cen, S., Wei, Y., and Chi, Y.
\newblock Fast policy extragradient methods for competitive games with entropy
  regularization.
\newblock In \emph{Advances in Neural Information Processing Systems 34: Annual
  Conference on Neural Information Processing Systems 2021, NeurIPS 2021}, pp.\
   27952--27964, 2021.

\bibitem[Chasnov et~al.(2020)Chasnov, Ratliff, Mazumdar, and Burden]{CRMB20}
Chasnov, B., Ratliff, L., Mazumdar, E., and Burden, S.
\newblock Convergence analysis of gradient-based learning in continuous games.
\newblock In \emph{UAI' 20: Proceedings of the 35th Annual Conference on
  Uncertainty in Artificial Intelligence}, 2020.

\bibitem[Chen \& Jiang(2019)Chen and Jiang]{chen2019information}
Chen, J. and Jiang, N.
\newblock Information-theoretic considerations in batch reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1042--1051. PMLR, 2019.

\bibitem[Chung(1954)]{Chu54}
Chung, K.-L.
\newblock On a stochastic approximation method.
\newblock \emph{The Annals of Mathematical Statistics}, 25\penalty0
  (3):\penalty0 463--483, 1954.

\bibitem[Daskalakis et~al.(2020)Daskalakis, Foster, and
  Golowich]{daskalakis2020independent}
Daskalakis, C., Foster, D.~J., and Golowich, N.
\newblock Independent policy gradient methods for competitive reinforcement
  learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 5527--5540, 2020.

\bibitem[Daskalakis et~al.(2022)Daskalakis, Golowich, and
  Zhang]{daskalakis2022complexity}
Daskalakis, C., Golowich, N., and Zhang, K.
\newblock The complexity of markov equilibrium in stochastic games.
\newblock \emph{arXiv preprint arXiv:2204.03991}, 2022.

\bibitem[Ding et~al.(2022)Ding, Wei, Zhang, and
  Jovanovi{\'c}]{ding2022independent}
Ding, D., Wei, C.-Y., Zhang, K., and Jovanovi{\'c}, M.~R.
\newblock Independent policy gradient for large-scale markov potential games:
  Sharper rates, function approximation, and game-agnostic convergence.
\newblock \emph{arXiv preprint arXiv:2202.04129}, 2022.

\bibitem[Fan et~al.(2020)Fan, Wang, Xie, and Yang]{fan2020theoretical}
Fan, J., Wang, Z., Xie, Y., and Yang, Z.
\newblock A theoretical analysis of deep q-learning.
\newblock In \emph{Learning for Dynamics and Control}, pp.\  486--489. PMLR,
  2020.

\bibitem[Filar \& Vrieze(1997)Filar and Vrieze]{FilVri97}
Filar, J. and Vrieze, K.
\newblock \emph{Competitive Markov Decision Processes}.
\newblock Springer, 1997.

\bibitem[Fink(1964)]{fink1964equilibrium}
Fink, A.~M.
\newblock Equilibrium in a stochastic $ n $-person game.
\newblock \emph{Journal of science of the hiroshima university, series ai
  (mathematics)}, 28\penalty0 (1):\penalty0 89--93, 1964.

\bibitem[Flokas et~al.(2020)Flokas, Vlatakis-Gkaragkounis, Lianeas,
  Mertikopoulos, and Piliouras]{FVGL+20}
Flokas, L., Vlatakis-Gkaragkounis, E.~V., Lianeas, T., Mertikopoulos, P., and
  Piliouras, G.
\newblock No-regret learning and mixed {Nash} equilibria: {They} do not mix.
\newblock In \emph{NeurIPS '20: Proceedings of the 34th International
  Conference on Neural Information Processing Systems}, 2020.

\bibitem[Folland(1999)]{Fol99}
Folland, G.~B.
\newblock \emph{Real Analysis}.
\newblock Wiley-Interscience, 2 edition, 1999.

\bibitem[Giannou et~al.(2021)Giannou, Vlatakis-Gkaragkounis, and
  Mertikopoulos]{GVM21}
Giannou, A., Vlatakis-Gkaragkounis, E.~V., and Mertikopoulos, P.
\newblock Survival of the strictest: {Stable} and unstable equilibria under
  regularized learning with partial information.
\newblock In \emph{COLT '21: Proceedings of the 34th Annual Conference on
  Learning Theory}, 2021.

\bibitem[Hall \& Heyde(1980)Hall and Heyde]{HH80}
Hall, P. and Heyde, C.~C.
\newblock \emph{Martingale Limit Theory and Its Application}.
\newblock Probability and Mathematical Statistics. Academic Press, New York,
  1980.

\bibitem[Hart \& Mas-Colell(2000)Hart and Mas-Colell]{HMC00}
Hart, S. and Mas-Colell, A.
\newblock A simple adaptive procedure leading to correlated equilibrium.
\newblock \emph{Econometrica}, 68\penalty0 (5):\penalty0 1127--1150, September
  2000.

\bibitem[Hart \& Mas-Colell(2003)Hart and Mas-Colell]{HMC03}
Hart, S. and Mas-Colell, A.
\newblock Uncoupled dynamics do not lead to {Nash} equilibrium.
\newblock \emph{American Economic Review}, 93\penalty0 (5):\penalty0
  1830--1836, 2003.

\bibitem[Hsieh et~al.(2019)Hsieh, Iutzeler, Malick, and Mertikopoulos]{HIMM19}
Hsieh, Y.-G., Iutzeler, F., Malick, J., and Mertikopoulos, P.
\newblock On the convergence of single-call stochastic extra-gradient methods.
\newblock In \emph{NeurIPS '19: Proceedings of the 33rd International
  Conference on Neural Information Processing Systems}, pp.\  6936--6946, 2019.

\bibitem[Hsieh et~al.(2020)Hsieh, Iutzeler, Malick, and Mertikopoulos]{HIMM20}
Hsieh, Y.-G., Iutzeler, F., Malick, J., and Mertikopoulos, P.
\newblock Explore aggressively, update conservatively: {Stochastic}
  extragradient methods with variable stepsize scaling.
\newblock In \emph{NeurIPS '20: Proceedings of the 34th International
  Conference on Neural Information Processing Systems}, 2020.

\bibitem[Hsieh et~al.(2021)Hsieh, Mertikopoulos, and Cevher]{HMC21}
Hsieh, Y.-P., Mertikopoulos, P., and Cevher, V.
\newblock The limits of min-max optimization algorithms: {Convergence} to
  spurious non-critical sets.
\newblock In \emph{ICML '21: Proceedings of the 38th International Conference
  on Machine Learning}, 2021.

\bibitem[Jin et~al.(2021)Jin, Liu, Wang, and Yu]{JLWY21}
Jin, C., Liu, Q., Wang, Y., and Yu, T.
\newblock {V-Learning}: {A} simple, efficient, decentralized algorithm for
  multiagent {RL}.
\newblock \url{https://arxiv.org/abs/2110.14555}, 2021.

\bibitem[Jin et~al.(2022)Jin, Muthukumar, and Sidford]{Yujia22:The}
Jin, Y., Muthukumar, V., and Sidford, A.
\newblock The complexity of infinite-horizon general-sum stochastic games,
  2022.

\bibitem[Kakade(2001)]{kakade2001natural}
Kakade, S.~M.
\newblock A natural policy gradient.
\newblock \emph{Advances in neural information processing systems}, 14, 2001.

\bibitem[Konda \& Tsitsiklis(1999)Konda and Tsitsiklis]{konda1999actor}
Konda, V. and Tsitsiklis, J.
\newblock Actor-critic algorithms.
\newblock \emph{Advances in neural information processing systems}, 12, 1999.

\bibitem[Laraki et~al.(2019)Laraki, Renault, and Sorin]{LRS19}
Laraki, R., Renault, J., and Sorin, S.
\newblock \emph{Mathematical Foundations of Game Theory}.
\newblock Universitext. Springer, 2019.

\bibitem[Leonardos et~al.(2022)Leonardos, Overman, Panageas, and
  Piliouras]{LOPP22}
Leonardos, S., Overman, W., Panageas, I., and Piliouras, G.
\newblock Global convergence of multi-agent policy gradient in markov potential
  games.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=gfwON7rAm4}.

\bibitem[Leslie et~al.(2020)Leslie, Perkins, and Xu]{LPX20}
Leslie, D.~S., Perkins, S., and Xu, Z.
\newblock Best-response dynamics in zero-sum stochastic games.
\newblock \emph{Journal of Economic Theory}, 189:\penalty0 105095, 2020.

\bibitem[Mertikopoulos \& Zhou(2019)Mertikopoulos and Zhou]{MZ19}
Mertikopoulos, P. and Zhou, Z.
\newblock Learning in games with continuous action sets and unknown payoff
  functions.
\newblock \emph{Mathematical Programming}, 173\penalty0 (1-2):\penalty0
  465--507, January 2019.

\bibitem[Mertikopoulos et~al.(2018)Mertikopoulos, Papadimitriou, and
  Piliouras]{MPP18}
Mertikopoulos, P., Papadimitriou, C.~H., and Piliouras, G.
\newblock Cycles in adversarial regularized learning.
\newblock In \emph{SODA '18: Proceedings of the 29th annual ACM-SIAM Symposium
  on Discrete Algorithms}, 2018.

\bibitem[Mertikopoulos et~al.(2019)Mertikopoulos, Lecouat, Zenati, Foo,
  Chandrasekhar, and Piliouras]{MLZF+19}
Mertikopoulos, P., Lecouat, B., Zenati, H., Foo, C.-S., Chandrasekhar, V., and
  Piliouras, G.
\newblock Optimistic mirror descent in saddle-point problems: {Going} the extra
  (gradient) mile.
\newblock In \emph{ICLR '19: Proceedings of the 2019 International Conference
  on Learning Representations}, 2019.

\bibitem[Mertikopoulos et~al.(2022)Mertikopoulos, Hsieh, and Cevher]{MHC22}
Mertikopoulos, P., Hsieh, Y.-P., and Cevher, V.
\newblock Learning in games from a stochastic approximation viewpoint.
\newblock \url{https://arxiv.org/abs/2206.03922}, 2022.

\bibitem[Moravčík et~al.(2017)Moravčík, Schmid, Burch, Lisý, Morrill,
  Bard, Davis, Waugh, Johanson, and Bowling]{Mora17:DeepStack}
Moravčík, M., Schmid, M., Burch, N., Lisý, V., Morrill, D., Bard, N., Davis,
  T., Waugh, K., Johanson, M., and Bowling, M.
\newblock Deepstack: Expert-level artificial intelligence in heads-up no-limit
  poker.
\newblock \emph{Science}, 356\penalty0 (6337):\penalty0 508--513, 2017.
\newblock \doi{10.1126/science.aam6960}.

\bibitem[Munos(2003)]{munos2003error}
Munos, R.
\newblock Error bounds for approximate policy iteration.
\newblock In \emph{ICML}, volume~3, pp.\  560--567, 2003.

\bibitem[Munos(2005)]{munos2005error}
Munos, R.
\newblock Error bounds for approximate value iteration.
\newblock In \emph{Proceedings of the National Conference on Artificial
  Intelligence}, volume~20, pp.\  1006. Menlo Park, CA; Cambridge, MA; London;
  AAAI Press; MIT Press; 1999, 2005.

\bibitem[Nesterov(2004)]{Nes04}
Nesterov, Y.
\newblock \emph{Introductory Lectures on Convex Optimization: A Basic Course}.
\newblock Number~87 in Applied Optimization. Kluwer Academic Publishers, 2004.

\bibitem[Neyman \& Sorin(2003)Neyman and Sorin]{NS03}
Neyman, A. and Sorin, S. (eds.).
\newblock \emph{Stochastic Games and Applications}.
\newblock {NATO} {ASI}. Kluwer Academic Publishers, 2003.

\bibitem[Perkins(2013)]{Per13}
Perkins, S.
\newblock \emph{Advanced stochastic approximation frameworks and their
  applications}.
\newblock PhD thesis, University of Bristol, 2013.

\bibitem[Polyak(1963)]{polyak1963}
Polyak, B.
\newblock Gradient methods for the minimisation of functionals.
\newblock \emph{USSR Computational Mathematics and Mathematical Physics},
  3\penalty0 (4):\penalty0 864--878, 1963.
\newblock ISSN 0041-5553.

\bibitem[Polyak(1987)]{Pol87}
Polyak, B.~T.
\newblock \emph{Introduction to Optimization}.
\newblock Optimization Software, New York, NY, USA, 1987.

\bibitem[Ratliff et~al.(2016)Ratliff, Burden, and Sastry]{RBS16}
Ratliff, L.~J., Burden, S.~A., and Sastry, S.~S.
\newblock On the characterization of local {Nash} equilibria in continuous
  games.
\newblock \emph{{IEEE} Trans. Autom. Control}, 61\penalty0 (8):\penalty0
  2301--2307, August 2016.

\bibitem[Rockafellar \& Wets(1998)Rockafellar and Wets]{RW98}
Rockafellar, R.~T. and Wets, R. J.~B.
\newblock \emph{Variational Analysis}, volume 317 of \emph{A Series of
  Comprehensive Studies in Mathematics}.
\newblock Springer-Verlag, Berlin, 1998.

\bibitem[Sayin et~al.(2021)Sayin, Zhang, Leslie, Basar, and
  Ozdaglar]{Sayin21:Decentralized}
Sayin, M., Zhang, K., Leslie, D., Basar, T., and Ozdaglar, A.
\newblock Decentralized q-learning in zero-sum markov games.
\newblock In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
  J.~W. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  18320--18334. Curran Associates, Inc., 2021.

\bibitem[Sayin et~al.(2020)Sayin, Parise, and Ozdaglar]{Sayin20:Fictitious}
Sayin, M.~O., Parise, F., and Ozdaglar, A.
\newblock Fictitious play in zero-sum stochastic games.
\newblock \emph{arXiv preprint arXiv:2010.04223}, 2020.

\bibitem[Shalev-Shwartz et~al.(2016)Shalev-Shwartz, Shammah, and
  Shashua]{shalev2016safe}
Shalev-Shwartz, S., Shammah, S., and Shashua, A.
\newblock Safe, multi-agent, reinforcement learning for autonomous driving.
\newblock \emph{arXiv preprint arXiv:1610.03295}, 2016.

\bibitem[Shapley(1953)]{Sha53}
Shapley, L.~S.
\newblock Stochastic games.
\newblock \emph{Proceedings of the National Academy of Sciences of the USA},
  39:\penalty0 1095--1100, 1953.

\bibitem[Shoham \& Leyton-Brown(2008)Shoham and Leyton-Brown]{SLB08}
Shoham, Y. and Leyton-Brown, K.
\newblock \emph{Multiagent systems: Algorithmic, game-theoretic, and logical
  foundations}.
\newblock Cambridge University Press, 2008.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den
  Driessche, Graepel, and Hassabis]{Silver17:Mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T.~P.,
  Hui, F., Sifre, L., van~den Driessche, G., Graepel, T., and Hassabis, D.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nat.}, 550\penalty0 (7676):\penalty0 354--359, 2017.
\newblock \doi{10.1038/nature24270}.

\bibitem[Solan \& Vieille(2015)Solan and Vieille]{solan2015stochastic}
Solan, E. and Vieille, N.
\newblock Stochastic games.
\newblock \emph{Proceedings of the National Academy of Sciences}, 112\penalty0
  (45):\penalty0 13743--13746, 2015.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{SB98}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock MIT Press, Cambridge, MA, 1998.

\bibitem[Sutton et~al.(1999)Sutton, McAllester, Singh, and
  Mansour]{sutton1999policy}
Sutton, R.~S., McAllester, D., Singh, S., and Mansour, Y.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock \emph{Advances in neural information processing systems}, 12, 1999.

\bibitem[Takahashi(1962)]{takahashi1962stochastic}
Takahashi, M.
\newblock Stochastic games with infinitely many strategies.
\newblock \emph{Journal of Science of the Hiroshima University, Series AI
  (Mathematics)}, 26\penalty0 (2):\penalty0 123--134, 1962.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, Oh, Horgan, Kroiss, Danihelka, Huang,
  Sifre, Cai, Agapiou, Jaderberg, Vezhnevets, Leblond, Pohlen, Dalibard,
  Budden, Sulsky, Molloy, Paine, G{\"{u}}l{\c{c}}ehre, Wang, Pfaff, Wu, Ring,
  Yogatama, W{\"{u}}nsch, McKinney, Smith, Schaul, Lillicrap, Kavukcuoglu,
  Hassabis, Apps, and Silver]{Vinyals19:Grandmaster}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung,
  J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., Oh, J., Horgan, D.,
  Kroiss, M., Danihelka, I., Huang, A., Sifre, L., Cai, T., Agapiou, J.~P.,
  Jaderberg, M., Vezhnevets, A.~S., Leblond, R., Pohlen, T., Dalibard, V.,
  Budden, D., Sulsky, Y., Molloy, J., Paine, T.~L., G{\"{u}}l{\c{c}}ehre,
  {\c{C}}., Wang, Z., Pfaff, T., Wu, Y., Ring, R., Yogatama, D., W{\"{u}}nsch,
  D., McKinney, K., Smith, O., Schaul, T., Lillicrap, T.~P., Kavukcuoglu, K.,
  Hassabis, D., Apps, C., and Silver, D.
\newblock Grandmaster level in starcraft {II} using multi-agent reinforcement
  learning.
\newblock \emph{Nat.}, 575\penalty0 (7782):\penalty0 350--354, 2019.
\newblock \doi{10.1038/s41586-019-1724-z}.

\bibitem[Wei et~al.(2021)Wei, Lee, Zhang, and Luo]{Wei21:Last}
Wei, C.-Y., Lee, C.-W., Zhang, M., and Luo, H.
\newblock Last-iterate convergence of decentralized optimistic gradient
  descent/ascent in infinite-horizon competitive markov games.
\newblock In Belkin, M. and Kpotufe, S. (eds.), \emph{Proceedings of Thirty
  Fourth Conference on Learning Theory}, volume 134 of \emph{Proceedings of
  Machine Learning Research}, pp.\  4259--4299. PMLR, 15--19 Aug 2021.

\bibitem[Williams(1992)]{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3):\penalty0 229--256, 1992.

\bibitem[Zhang et~al.(2020)Zhang, Koppel, Zhu, and Basar]{zhang2020global}
Zhang, K., Koppel, A., Zhu, H., and Basar, T.
\newblock Global convergence of policy gradient methods to (almost) locally
  optimal policies.
\newblock \emph{SIAM Journal on Control and Optimization}, 58\penalty0
  (6):\penalty0 3586--3612, 2020.

\bibitem[Zhang et~al.(2021)Zhang, Ren, and Li]{zhang2021gradient}
Zhang, R., Ren, Z., and Li, N.
\newblock Gradient play in multi-agent markov stochastic games: Stationary
  points and convergence.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2106, 2021.

\bibitem[Zinkevich(2003)]{Zin03}
Zinkevich, M.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{ICML '03: Proceedings of the 20th International Conference
  on Machine Learning}, pp.\  928--936, 2003.

\end{thebibliography}
