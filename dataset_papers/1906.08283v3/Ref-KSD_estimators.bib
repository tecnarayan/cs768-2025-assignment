
@article{micchelli2005learning,
  title={On learning vector-valued functions},
  author={Micchelli, Charles A and Pontil, Massimiliano},
  journal={Neural computation},
  volume={17},
  number={1},
  pages={177--204},
  year={2005},
  publisher={MIT Press}
}

@article{micheli2013matrix,
  title={Matrix-valued kernels for shape deformation analysis},
  author={Micheli, Mario and Glaunes, Joan Alexis},
  journal={arXiv preprint arXiv:1308.5739},
  year={2013}
}


@article{liu2017learning,
  title={Learning deep energy models: Contrastive divergence vs. amortized mle},
  author={Liu, Q. and Wang, D.},
  journal={arXiv preprint arXiv:1707.00797},
  year={2017}
}

@book{Casella2001,
abstract = {We compare official population projections with Bayesian time series forecasts for England and Wales. The Bayesian approach allows the integration of uncertainty in the data, models and model parameters in a coherent and consistent manner. Bayesian methodology for time-series forecasting is introduced, including autoregressive (AR) and stochastic volatility (SV) models. These models are then fitted to a historical time series of data from 1841 to 2007 and used to predict future population totals to 2033. These results are compared to the most recent projections produced by the Office for National Statistics. Sensitivity analyses are then performed to test the effect of changes in the prior uncertainty for a single parameter. Finally, in-sample forecasts are compared with actual population and previous official projections. The article ends with some conclusions and recommendations for future work.},
author = {Casella, G. and Berger, R.},
title = {{Statistical Inference}},
year = {2001}
}


@article{Briol2019,
author = {Briol, F-X. and Barp, A. and Duncan, A. B. and Girolami, M.},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/Distances between distributions/minimum distance estimation/MMD{\_}paper.pdf:pdf},
title = {{Statistical inference for generative models with maximum mean discrepancy}},
journal = {arXiv:1906.05944},
year = {2019}
}


@incollection{Detommaso2018,
title = {A Stein variational Newton method},
author = {Detommaso, G. and Cui, T. and Marzouk, Y. and Spantini, A. and Scheichl, R.},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {9169--9179},
year = {2018},
}

@inproceedings{Li2018implicit,
abstract = {Implicit models, which allow for the generation of samples but not for point-wise evaluation of probabilities, are omnipresent in real-world problems tackled by machine learning and a hot topic of current research. Some examples include data simulators that are widely used in engineering and scientific research, generative adversarial networks (GANs) for image synthesis, and hot-off-the-press approximate inference techniques relying on implicit distributions. The majority of existing approaches to learning implicit models rely on approximating the intractable distribution or optimisation objective for gradient-based optimisation, which is liable to produce inaccurate updates and thus poor models. This paper alleviates the need for such approximations by proposing the Stein gradient estimator, which directly estimates the score function of the implicitly defined distribution. The efficacy of the proposed estimator is empirically demonstrated by examples that include meta-learning for approximate inference, and entropy regularised GANs that provide improved sample diversities.},
author = {Li, Y. and Turner, R. E.},
booktitle = {International Conference on Learning Representations},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Turner - 2017 - Gradient Estimators for Implicit Models.pdf:pdf},
title = {{Gradient estimators for implicit models}},
year = {2018}
}

@article{Liu2018Fisher,
author = {Liu, S. and Kanamori, T. and Jitkrittum, W. and Chen, Y.},
file = {:home/francois/Dropbox/Work/Papers/Stein method/Stein {\&} Kernels/(2019, Liu) Fisher Efficient Inference of Intractable Models.pdf:pdf},
journal = {arXiv:1805.07454},
title = {{Fisher efficient inference of intractable models}},
year = {2018}
}



@inproceedings{Ranganath2016,
author = {Ranganath, R. and Altosaar, J. and Tran, D. and Blei, D. M.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranganath et al. - 2016 - Operator Variational Inference.pdf:pdf},
pages = {496--504},
title = {{Operator variational inference}},
year = {2016}
}

@article{Ma2017,
author = {Ma, C. and Barber, D.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma, Barber - 2017 - Black-box Stein Divergence Minimization For Learning Latent Variable Models.pdf:pdf},
journal = {Advances in Approximate Bayesian Inference, NIPS 2017 Workshop},
title = {{Black-box Stein divergence minimization for learning latent variable models}},
year = {2017}
}



@inproceedings{Li2015GMMN,
abstract = {We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer preceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.},
author = {Li, Y. and Swersky, K. and Zemel, R.},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Swersky, Zemel - 2015 - Generative moment matching networks.pdf:pdf},
pages = {1718--1727},
title = {{Generative moment matching networks}},
volume = {37},
year = {2015}
}



@book{Huber2009,
author = {Huber, P. J. and Ronchetti, E. M.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huber, Ronchetti - 2009 - Robust Statistics.pdf:pdf},
publisher = {Wiley},
title = {{Robust Statistics}},
year = {2009}
}


@article{mackey2016multivariate,
  title={Multivariate {S}tein factors for a class of strongly log-concave distributions},
  author={Mackey, L. and Gorham, J.},
  journal={Electronic Communications in Probability},
  volume={21},
  year={2016},
}

@article{hyvarinen1999sparse,
  title={Sparse code shrinkage: Denoising of nongaussian data by maximum likelihood estimation},
  author={Hyv{\"a}rinen, Aapo},
  journal={Neural computation},
  volume={11},
  number={7},
  pages={1739--1768},
  year={1999},
  publisher={MIT Press}
}

@article{mardia2016score,
  title={Score matching estimators for directional distributions},
  author={Mardia, Kanti V and Kent, John T and Laha, Arnab K},
  journal={arXiv preprint arXiv:1604.08470},
  year={2016}
}


@article{ceylan2018conditional,
  title={Conditional noise-contrastive estimation of unnormalised models},
  author={Ceylan, C. and Gutmann, M. U.},
  journal={arXiv:1806.03664},
  year={2018}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, M. U. and Hyv{\"a}rinen, A.},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={297--304},
  year={2010}
}

@article{geyer1994convergence,
  title={On the convergence of {M}onte {C}arlo maximum likelihood calculations},
  author={Geyer, C. J.},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={56},
  number={1},
  pages={261--274},
  year={1994},
  publisher={Wiley Online Library}
}

@article{wenliang2018learning,
  title={Learning deep kernels for exponential family densities},
  author={Wenliang, L. and Sutherland, D. and Strathmann, H. and Gretton, A.},
  journal={arXiv:1811.08357},
  year={2018}
}


@article{roth2009fields,
  title={Fields of experts},
  author={Roth, S. and Black, M. J.},
  journal={International Journal of Computer Vision},
  volume={82},
  number={2},
  pages={205},
  year={2009},
  publisher={Springer}
}


@article{koster2010two,
  title={A two-layer model of natural stimuli estimated with score matching},
  author={K{\"o}ster, Urs and Hyv{\"a}rinen, Aapo},
  journal={Neural Computation},
  volume={22},
  number={9},
  pages={2308--2333},
  year={2010},
  publisher={MIT Press}
}



@inproceedings{mnih2012fast,
abstract = {In spite of their superior performance, neural probabilistic language models (NPLMs) remain far less widely used than n-gram models due to their notoriously long training times, which are measured in weeks even for moderately-sized datasets. Training NPLMs is computationally expensive because they are explicitly normalized, which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients. We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation, a newly introduced procedure for estimating unnormalized continuous distributions. We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models. The algorithm is also more efficient and much more stable than importance sampling because it requires far fewer noise samples to perform well. We demonstrate the scalability of the proposed approach by training several neural language models on a 47M-word corpus with a 80K-word vocabulary, obtaining state-of-the-art results on the Microsoft Research Sentence Completion Challenge dataset.},
author = {Mnih, A. and Teh, Y. W.},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/francois/Dropbox/Work/Papers/Other Machine Learning/Neural networks/(2012, Mnih) A fast and simple algorithm for training neural probabilistic language models.pdf:pdf},
pages = {419--426},
title = {{A fast and simple algorithm for training neural probabilistic language models}},
year = {2012}
}


@article{Sriperumbudur2017density,
  title={Density estimation in infinite dimensional exponential families},
  author={Sriperumbudur, B. and Fukumizu, K. and Gretton, A. and Hyv{\"a}rinen, A. and Kumar, R.},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={1830--1888},
  year={2017},
}

@article{wenliang2018learning,
  title={Learning deep kernels for exponential family densities},
  author={Wenliang, Li and Sutherland, Dougal and Strathmann, Heiko and Gretton, Arthur},
  journal={arXiv preprint arXiv:1811.08357},
  year={2018}
}

@inproceedings{Frogner2015,
abstract = {Learning to predict multi-label outputs is challenging, but in many problems there is a natural metric on the outputs that can be used to improve predictions. In this paper we develop a loss function for multi-label learning, based on the Wasserstein distance. The Wasserstein distance provides a natural notion of dissimilarity for probability measures. Although optimizing with respect to the exact Wasserstein distance is costly, recent work has described a regularized approximation that is efficiently computed. We describe efficient learning algorithms based on this regularization, extending the Wasserstein loss from probability measures to unnormalized measures. We also describe a statistical learning bound for the loss and show connections with the total variation norm and the Jaccard index. The Wasserstein loss can encourage smoothness of the predictions with respect to a chosen metric on the output space. We demonstrate this property on a real-data tag prediction problem, using the Yahoo Flickr Creative Commons dataset, achieving superior performance over a baseline that doesn't use the metric.},
author = {Frogner, C. and Zhang, C. and Mobahi, H. and Araya-Polo, M. and Poggio, T.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frogner et al. - 2015 - Learning with a Wasserstein Loss.pdf:pdf},
pages = {2053--2061},
title = {{Learning with a Wasserstein loss}},
year = {2015}
}


@article{gutmann2013three,
  title={A three-layer model of natural image statistics},
  author={Gutmann, M. U and Hyv{\"a}rinen, A.},
  journal={Journal of Physiology-Paris},
  volume={107},
  number={5},
  pages={369--398},
  year={2013},
  publisher={Elsevier}
}

@article{gabay1982minimizing,
  title={Minimizing a differentiable function over a differential manifold},
  author={Gabay, Daniel},
  journal={Journal of Optimization Theory and Applications},
  volume={37},
  number={2},
  pages={177--219},
  year={1982},
  publisher={Springer}
}

@article{bonnabel2013stochastic,
  title={{Stochastic gradient descent on Riemannian manifolds}},
  author={Bonnabel, S.},
  journal={{IEEE Transactions on Automatic Control}},
  volume={58},
  number={9},
  pages={2217--2229},
  year={2013},
  publisher={IEEE}
}

@article{newey1994large,
  title={Large sample estimation and hypothesis testing},
  author={Newey, W. K. and McFadden, D.},
  journal={Handbook of Econometrics},
  volume={4},
  pages={2111--2245},
  year={1994},
  publisher={Elsevier}
}

@article{yeo2001uniform,
  title={A uniform strong law of large numbers for {U}-statistics with application to transforming to near symmetry},
  author={Yeo, I.-K. and Johnson, R. A.},
  journal={Statistics \& Probability Letters},
  volume={51},
  number={1},
  pages={63--69},
  year={2001},
}

@inproceedings{huggins2018random,
  title={Random feature Stein discrepancies},
  author={Huggins, Jonathan and Mackey, Lester},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1899--1909},
  year={2018}
}

@article{pigola2014global,
  title={Global divergence theorems in nonlinear {PDE}s and geometry},
  author={Pigola, S. and Setti, A. G.},
  journal={Ensaios Matem{\'a}ticos},
  volume={26},
  pages={1--77},
  year={2014}
}


@article{Hampel1971,
abstract = {Two very closely related definitions of robustness of a sequence of estimators are given which take into account the types of deviations from parametric models that occur in practice. These definitions utilize the properties of the Prokhorov distance between probability distributions. It is proved that weak âˆ—-continuous functionals on the space of probability distributions define robust sequences of estimators (in either sense). The concept of the "breakdown point" of a sequence of estimators is defined, and some examples are given.},
author = {Hampel, F. R.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/Robust statistics/(1971, Hampel) A general qualitative definition of robustness.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {6},
pages = {1887--1896},
title = {{A general qualitative definition of robustness}},
volume = {42},
year = {1971}
}

@book{Kotz2001,
author = {Kotz, S. and Kozubowski, T. J. and Podgorski, K.},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/distributions/(2001, Kotz) The Laplace distribution and generalizations.pdf:pdf},
publisher = {Springer},
title = {{The Laplace Distribution and Generalizations}},
year = {2001}
}



@article{Yang2018,
author = {Yang, J. and Liu, Q. and Rao, V. and Neville, J.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2018 - Goodness-of-fit Testing for Discrete Distributions via Stein Discrepancy.pdf:pdf},
title = {{Goodness-of-fit Testing for Discrete Distributions via Stein Discrepancy}},
year = {2018}
}


@article{Ley2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1105.4925v3},
author = {Ley, Christophe and Swan, Yvik},
eprint = {arXiv:1105.4925v3},
file = {:home/francois/Dropbox/Work/Papers/Stein method/(2011, Ley {\&} Swan) A unified approach to Stein characterizations.pdf:pdf},
journal = {arXiv:1105.4925},
keywords = {1,and phrases,background and motivation,characterization theorems,generalized,introduction,location and scale parameters,parameter of interest,score function,standardized,stein characteri-,zations},
pages = {1--28},
title = {{A unified approach to Stein characterizations}},
year = {2011}
}


@article{Ley2016Parametric,
author = {Ley, C. and Swan, Y.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ley, Swan - 2016 - Parametric Stein operators and variance bounds.pdf:pdf},
journal = {Brazilian Journal of Probability and Statistics},
number = {2},
pages = {171--195},
title = {{Parametric Stein operators and variance bounds}},
volume = {30},
year = {2016}
}



@inproceedings{Yu2018,
abstract = {A common challenge in estimating parameters of probability density functions is the intractability of the normalizing constant. While in such cases maximum likelihood estimation may be implemented using numerical integration, the approach becomes computationally intensive. In contrast, the score matching method of Hyv$\backslash$"arinen (2005) avoids direct calculation of the normalizing constant and yields closed-form estimates for exponential families of continuous distributions over {\$}\backslashmathbb{\{}R{\}}{\^{}}m{\$}. Hyv$\backslash$"arinen (2007) extended the approach to distributions supported on the non-negative orthant {\$}\backslashmathbb{\{}R{\}}{\_}+{\^{}}m{\$}. In this paper, we give a generalized form of score matching for non-negative data that improves estimation efficiency. We also generalize the regularized score matching method of Lin et al. (2016) for non-negative Gaussian graphical models, with improved theoretical guarantees.},
archivePrefix = {arXiv},
arxivId = {1802.06340},
author = {Yu, Shiqing and Drton, Mathias and Shojaie, Ali},
booktitle = {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, PMLR 84},
eprint = {1802.06340},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Drton, Shojaie - 2018 - Graphical Models for Non-Negative Data Using Generalized Score Matching.pdf:pdf},
pages = {1781--1790},
title = {{Graphical Models for Non-Negative Data Using Generalized Score Matching}},
url = {http://arxiv.org/abs/1802.06340},
year = {2018}
}

@inproceedings{Yuille2005,
abstract = {This paper analyses the Contrastive Divergence algorithm for learning statistical parameters. We relate the algorithm to the stochastic approxi- mation literature. This enables us to specify conditions under which the algorithm is guaranteed to converge to the optimal solution (with proba- bility 1). This includes necessary and sufficient conditions for the solu- tion to be unbiased.},
author = {Yuille, A.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/Distances between distributions/minimum distance estimation/(2004, Yuille) The convergence of Contrastive Divergences.pdf:pdf},
pages = {1593--1600},
title = {{The Convergence of Contrastive Divergences}},
year = {2005}
}


@article{Mardia2016,
author = {Mardia, K. V. and Kent, J. T. and Laha, A. K.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mardia, Kent, Laha - Unknown - Score matching estimators for directional distributions Background on Riemannian manifolds.pdf:pdf},
journal = {arXiv:1604.08470},
pages = {2016},
title = {{Score matching estimators for directional distributions}}
}


@inproceedings{sohl2009minimum,
author = {Sohl-dickstein, J. and Battaglino, P. and DeWeese, M. R.},
booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/Distances between distributions/minimum distance estimation/(2011, Sohl-Dickstein) Minimum Probability Flow Learning.pdf:pdf},
pages = {905--912},
title = {{Minimum probability flow learning}},
year = {2011}
}


@article{sohl2009minimum2009,
  title={Minimum probability flow learning},
  author={Sohl-Dickstein, Jascha and Battaglino, Peter and DeWeese, Michael R},
  journal={arXiv preprint arXiv:0906.4779},
  year={2009}
}

@article{Hinton2002,
abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual "expert" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called "contrastive divergence" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
author = {Hinton, G. E.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton - 2002 - Training Products of Experts by Minimizing Contrastive Divergence.pdf:pdf},
journal = {Neural Computation},
number = {8},
pages = {1771--1800},
title = {{Training products of experts by minimizing contrastive divergence}},
volume = {14},
year = {2002}
}


@inproceedings{Carreira-Perpinan2005,
author = {Carreira-Perpinan, M. A. and Hinton, G. E.},
booktitle = {Artificial Intelligence and Statistics},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/Distances between distributions/minimum distance estimation/(2005, Carreira-Perpinan) On Contrastive Divergence Learning.pdf:pdf},
title = {{On Contrastive Divergence Learning}},
year = {2005}
}



@book{Pardo2005,
author = {Pardo, L.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pardo - 2006 - Statistical Inference Based on Divergence Measures.pdf:pdf},
pages = {497},
publisher = {Chapman and Hall/CRC},
title = {{Statistical Inference Based on Divergence Measures}},
volume = {170},
year = {2005}
}



@book{Basu2011,
abstract = {"In many ways, estimation by an appropriate minimum distance method is one of the most natural ideas in statistics. However, there are many different ways of constructing an appropriate distance between the data and the model: the scope of study referred to by "Minimum Distance Estimation" is literally huge. Filling a statistical resource gap, Statistical Inference: The Minimum Distance Approach comprehensively overviews developments in density-based minimum distance inference for independently and identically distributed data. Extensions to other more complex models are also discussed. Comprehensively covering the basics and applications of minimum distance inference, this book introduces and discusses: The estimation and hypothesis testing problems for both discrete and continuous modelsThe robustness properties and the structural geometry of the minimum distance methodsThe inlier problem and its possible solutions, and the weighted likelihood estimation problem The extension of the minimum distance methodology in interdisciplinary areas, such as neural networks and fuzzy sets, as well as specialized models and problems, including semi-parametric problems, mixture models, grouped data problems and survival analysis. Statistical Inference: The Minimum Distance Approach gives a thorough account of density-based minimum distance methods and their use in statistical inference. It covers statistical distances, density-based minimum distance methods, discrete and continuous models, asymptotic distributions, robustness, computational issues, residual adjustment functions, graphical descriptions of robustness, penalized and combined distances, weighted likelihood, and multinomial goodness-of-fit tests. This carefully crafted resource is useful to researchers and scientists within and outside the statistics arena"-- "Preface In many ways, estimation by an appropriate minimum distance method is one of the most natural ideas in statistics. A parametric model imposes a certain structure on the class of probability distributions that may be used to describe real life data generated from a process under study. There hardly appears to be a better way to deal with such a problem than to choose the parametric model that minimizes an appropriately defined distance between the data and the model. The issue is an important and complex one. There are many different ways of constructing an appropriate "distance" between the "data" and the "model". One could, for example, construct a distance between the empirical distribution function and the model distribution function by a suitable measure of distance. Alternatively, one could minimize the distance between the estimated data density (obtained, if necessary, by using a nonparametric smoothing technique such as kernel density estimation) and the parametric model density. And when the particular nature of the distances have been settled (based on distribution functions, based on densities, etc.), there may be innumerable options for the distance to be used within the particular type of distances. So the scope of study referred to by "Minimum Distance Estimation" is literally huge"--},
author = {Basu, A. and Shioya, H. and Park, C.},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/Distances between distributions/minimum distance estimation/(Monographs on statistics and applied probability (Series), 120) Ayanendranath Basu{\_} Hiroyuki Shioya{\_} Chanseok Park-Statistic.pdf:pdf},
publisher = {CRC Press},
title = {{Statistical Inference: The Minimum Distance Approach}},
year = {2011}
}


@inproceedings{Lyu2009,
abstract = {Score matching is a recently developed pa- rameter learning method that is particu- larly effective to complicated high dimen- sional density models with intractable par- tition functions. In this paper, we study two issues that have not been completely re- solved for score matching. First, we provide a formal link between maximum likelihood and score matching. Our analysis shows that score matching finds model parameters that are more robust with noisy training data. Second, we develop a generalization of score matching. Based on this generalization, we further demonstrate an extension of score matching to models of discrete data.},
author = {Lyu, S.},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lyu - 2009 - Interpretation and generalization of score matching.pdf:pdf},
pages = {359--366},
title = {{Interpretation and generalization of score matching}},
year = {2009}
}


@book{Kushner2003,
author = {Kushner, H. J. and Yin, G. G.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/Generative models/(2003, Kushner) Stochastic approximation and recursive algorithms and applications.pdf:pdf},
publisher = {Springer},
title = {{Stochastic approximation and recursive algorithms and applications}},
year = {2003}
}


@book{Gilchrist2000,
author = {Gilchrist, W. G.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/Generative models/Warren Gilchrist-Statistical modelling with quantile functions-Chapman {\&} Hall{\_}CRC (2000).pdf:pdf},
publisher = {Chapman {\&} Hall},
title = {{Statistical Modelling with Quantile Functions Statistical Modelling with Quantile Functions}},
year = {2000}
}



@article{Hinton2015,
abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
author = {Hinton, G. and Vinyals, O. and Dean, J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Machine Learning/Neural networks/(2015, Hinton {\&} Vinyals {\&} Dean) Distilling the Knowledge in a Neural Network.pdf:pdf},
journal = {arXiv:1503.02531},
title = {{Distilling the Knowledge in a Neural Network}},
year = {2015}
}



@article{Steinwart2017,
abstract = {Strictly proper kernel scores are well-known tool in probabilistic forecasting, while characteristic kernels have been extensively investigated in the machine learning literature. We first show that both notions coincide, so that insights from one part of the literature can be used in the other. We then show that the metric induced by a characteristic kernel cannot reliably distinguish between distributions that are far apart in the total variation norm as soon as the underlying space of measures is infinite dimensional. In addition, we provide a characterization of characteristic kernels in terms of eigenvalues and -functions and apply this characterization to the case of continuous kernels on (locally) compact spaces. In the compact case we further show that characteristic kernels exist if and only if the space is metrizable. As special cases of our general theory we investigate translation-invariant kernels on compact Abelian groups and isotropic kernels on spheres. The latter are of particular interest for forecast evaluation of probabilistic predictions on spherical domains as frequently encountered in meteorology and climatology.},
archivePrefix = {arXiv},
arxivId = {1712.05279},
author = {Steinwart, I. and Ziegel, J. F.},
eprint = {1712.05279},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2017, Steinwart {\&} Ziegel) Strictly proper kernel scores and characteristic kernels on compact spaces.pdf:pdf},
pages = {1--32},
title = {{Strictly proper kernel scores and characteristic kernels on compact spaces}},
url = {http://arxiv.org/abs/1712.05279},
volume = {1},
year = {2017}
}

@article{Vishwanathan2010,
abstract = {It is widely believed that comparing discrepancies in the protein-protein interaction (PPI) networks of individuals will become an important tool in understanding and preventing diseases. Currently PPI networks for individuals are not available, but gene expression data is becoming easier to obtain and allows us to represent individuals by a co-integrated gene expression/protein interaction network. Two major problems hamper the application of graph kernels - state-of-the-art methods for whole-graph comparison - to compare PPI networks. First, these methods do not scale to graphs of the size of a PPI network. Second, missing edges in these interaction networks are biologically relevant for detecting discrepancies, yet, these methods do not take this into account. In this article we present graph kernels for biological network comparison that are fast to compute and take into account missing interactions. We evaluate their practical performance on two datasets of co-integrated gene expression/PPI networks.},
author = {Vishwanathan, S. V. N. and Schraudolph, N. and Kondor, R. and Borgwardt, K.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vishwanathan et al. - 2010 - Graph Kernels.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Sylvester equations,bioinformatics,linear algebra in RKHS,random walks,rational kernels,semirings,spectral decomposition,transducers},
pages = {1201--1242},
title = {{Graph kernels}},
year = {2010}
}


@inproceedings{Welling2003,
author = {Welling, M. and Hinton, G. and Osindero, S.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/distributions/(2003, Welling) Learning sparse topographic representations with products of student-t distributions.pdf:pdf},
pages = {1383--1390},
title = {{Learning sparse topographic representations with products of student-t distributions}},
year = {2003}
}



@inproceedings{Kingma2010,
author = {Kingma, D. P. and LeCun, Y.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, LeCun - Unknown - Regularized estimation of image statistics by score matching.pdf:pdf},
pages = {1126--1134},
title = {{Regularized estimation of image statistics by score matching}},
year = {2010}
}

@inproceedings{Swersky2011,
author = {Swersky, K. and Ranzato, M. A. and Buchman, D. and Marlin, B. M. and de Freitas, N.},
booktitle = {International Conference on Machine Learning},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Swersky et al. - 2011 - On Autoencoders and Score Matching for Energy Based Models.pdf:pdf},
pages = {1201--1208},
title = {{On autoencoders and score matching for energy based models}},
year = {2011}
}





@article{Lin2016,
abstract = {Undirected graphical models, also known as Markov random fields, are widely used to model stochastic dependences among large collections of variables. We introduce a new method of estimating sparse undirected conditional independence graphs based on the score matching loss, introduced by Hyvarinen (2005), and subsequently extended in Hyvarinen (2007). The regularized score matching method we propose applies to settings with continuous observations and allows for computationally efficient treatment of possibly non-Gaussian exponential family models. In the well-explored Gaussian setting, regularized score matching avoids issues of asymmetry that arise when applying the technique of neighborhood selection, and compared to existing methods that directly yield symmetric estimates, the score matching approach has the advantage that the considered loss is quadratic and gives piecewise linear solution paths under {\$}\backslashell{\_}1{\$}-regularization. Under suitable irrepresentability conditions, we show that {\$}\backslashell{\_}1{\$}-regularized score matching is consistent for graph estimation in high-dimensional settings. Through numerical experiments and an application to RNSseq data, we confirm that regularized score matching achieves state-of-the-art performance in the Gaussian case and provides a valuable tool for computationally efficient inference in non-Gaussian graphical models.},
archivePrefix = {arXiv},
arxivId = {1507.00433},
author = {Lin, L. and Drton, M. and Shojaie, A.},
eprint = {1507.00433},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2016, Lin {\&} Drton {\&} Shojaie) Estimation of high-dimensional graphical models using regularized score matching.pdf:pdf},
journal = {Electronic Journal of Statistics},
keywords = {and phrases,conditional independence graph,exponential family,graphical,high-dimensional statistics,model,score matching,sparsity},
title = {{Estimation of High-dimensional graphical models using regularized score matching}},
url = {http://arxiv.org/abs/1507.00433},
year = {2016}
}



@inproceedings{Jitkrittum2017,
abstract = {We propose a novel adaptive test of goodness-of-fit, with computational cost linear in the number of samples. We learn the test features that best indicate the differences between observed samples and a reference model, by minimizing the false negative rate. These features are constructed via Stein's method, meaning that it is not necessary to compute the normalising constant of the model. We analyse the asymptotic Bahadur efficiency of the new test, and prove that under a mean-shift alternative, our test always has greater relative efficiency than a previous linear-time kernel test, regardless of the choice of parameters for that test. In experiments, the performance of our method exceeds that of the earlier linear-time test, and matches or exceeds the power of a quadratic-time kernel test. In high dimensions and where model structure may be exploited, our goodness of fit test performs far better than a quadratic-time two-sample test based on the Maximum Mean Discrepancy, with samples drawn from the model.},
author = {Jitkrittum, W. and Xu, W. and Szabo, Z. and Fukumizu, K. and Gretton, A.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jitkrittum et al. - 2017 - A linear-time kernel goodness-of-fit test.pdf:pdf},
pages = {261--270},
title = {{A linear-time kernel goodness-of-fit test}},
year = {2017}
}



@article{Arbel2017,
archivePrefix = {arXiv},
arxivId = {1711.05363},
author = {Arbel, M. and Gretton, A.},
eprint = {1711.05363},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2017, Arbel {\&} Gretton) Kernel Conditional Exponential Family.pdf:pdf},
title = {{Kernel Conditional Exponential Family}},
year = {2017}
}


@article{Shao2007,
archivePrefix = {arXiv},
arxivId = {arXiv:1711.00136v1},
author = {Shao, S. and Jacob, P. E. and Ding, J. and Tarokh, V.},
eprint = {arXiv:1711.00136v1},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2017, Shao {\&} Jacob {\&} Ding {\&} Tarokh) Bayesian model comparison with the Hyvarinen score - computation and consistency.pdf:pdf},
keywords = {bayes factor,model comparison,non-informative prior,sequential monte carlo,state-space model},
pages = {1--27},
title = {{Bayesian model comparison with the Hyvarinen score : computation and consistency}},
volume = {368},
year = {2007}
}

@article{Dawid2016,
abstract = {Proper scoring rules are methods for encouraging honest assessment of probability distributions. Just like likelihood, a proper scoring rule can be applied to supply an unbiased estimating equation for any statistical model, and the theory of such equations can be applied to understand the properties of the associated estimator. In this paper we develop some basic scoring rule estimation theory, and explore robustness and interval estimation properties by means of theory and simulations.},
author = {Dawid, A. P. and Musio, M. and Ventura, L.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2016, Dawid {\&} Musio {\&} Ventura) Minimum scoring rule inference.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {B-robustness,Bregman estimate,Composite score,Godambe information,M-estimator,Pseudo-likelihood,Tsallis score,Unbiased estimating equation},
number = {1},
pages = {123--138},
title = {{Minimum scoring rule inference}},
volume = {43},
year = {2016}
}



@article{Dawid2014,
abstract = {We give an overview of some uses of proper scoring rules in statistical inference, including frequentist estimation theory and Bayesian model selection with improper priors.},
archivePrefix = {arXiv},
arxivId = {1401.0398},
author = {Dawid, A. P. and Musio, Monica},
doi = {10.1007/s40300-014-0039-y},
eprint = {1401.0398},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2014, Dawid {\&} Musio) Theory and Applications of Proper scoring rules.pdf:pdf},
issn = {2281695X},
journal = {Metron},
keywords = {Bayesian model selection,Bregman score,Composite score,Homogeneous score,Hyv??rinen score,Log score,Robust estimation,Survival score},
number = {2},
pages = {169--183},
title = {{Theory and applications of proper scoring rules}},
volume = {72},
year = {2014}
}



@article{Dawid2015,
author = {Dawid, A. P. and Musio, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2015, Dawid {\&} Musio) Bayesian Model Selection Based on Proper Scoring Rules.pdf:pdf},
journal = {Bayesian Analysis},
keywords = {Consistent model selection,Homogeneous score,Hyv??rinen score,Prequential},
number = {2},
pages = {479--499},
title = {{Bayesian model selection based on proper scoring rules}},
volume = {10},
year = {2015}
}

@article{Parry2012,
abstract = {We investigate proper scoring rules for continuous distributions on the real line. It is known that the log score is the only such rule that depends on the quoted density only through its value at the outcome that materializes. Here we allow further dependence on a finite number {\$}m{\$} of derivatives of the density at the outcome, and describe a large class of such {\$}m{\$}-local proper scoring rules: these exist for all even {\$}m{\$} but no odd {\$}m{\$}. We further show that for {\$}m\backslashgeq2{\$} all such {\$}m{\$}-local rules can be computed without knowledge of the normalizing constant of the distribution.},
archivePrefix = {arXiv},
arxivId = {1101.5011},
author = {Parry, M. and Dawid, A. P. and Lauritzen, S.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2012, Parry {\&} Dawid {\&} Lauritzen) Proper local scoring rules.pdf:pdf},
journal = {Annals of Statistics},
keywords = {Bregman score,Concavity,Divergence,Entropy,Euler-Lagrange equation,Homogeneity,Integration by parts,Local function,Score matching,Variational methods},
number = {1},
pages = {561--592},
title = {{Proper local scoring rules}},
volume = {40},
year = {2012}
}

@article{Dawid2007,
abstract = {A decision problem is defined in terms of an outcome space, an action space and a loss function. Starting from these simple ingredients, we can construct: Proper Scoring Rule; Entropy Function; Divergence Function; Riemannian Metric; and Unbiased Estimating Equation. From an abstract viewpoint, the loss function defines a duality between the outcome and action spaces, while the correspondence between a distribution and its Bayes act induces a self-duality. Together these determine a "decision geometry" for the family of distributions on outcome space. This allows generalisation of many standard statistical concepts and properties. In particular we define and study generalised exponential families. Several examples are analysed, including a general Bregman geometry.},
author = {Dawid, A. P.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2006, Dawid) The geometry of proper scoring rules.pdf:pdf},
journal = {Annals of the Institute of Statistical Mathematics},
keywords = {Bregman geometry,Decision geometry,Generalised exponential family,Information geometry,Proper scoring rule,Unbiased estimating equation},
number = {1},
pages = {77--93},
title = {{The geometry of proper scoring rules}},
volume = {59},
year = {2007}
}



@article{Gneiting2007,
abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G?=F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster tomake careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed.We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
author = {Gneiting, T. and Raftery, A. E.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2007, Gneiting {\&} Raftery) Strictly proper scoring rules prediction and estimation.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {bayes factor,bregman divergence,brier score,coherent,continuous ranked probability score,cross-validation,distribution,entropy,kernel score,loss function,minimum contrast estimation,negative definite function,prediction interval,predictive,quantile forecast,scoring rule,skill score,strictly proper,utility function},
number = {477},
pages = {359--378},
title = {{Strictly Proper Scoring Rules, Prediction, and Estimation}},
volume = {102},
year = {2007}
}

@inproceedings{Genevay2017,
abstract = {The ability to compare two degenerate probability distributions (i.e. two probability distributions supported on two distinct low-dimensional manifolds living in a much higher-dimensional space) is a crucial problem arising in the estimation of generative models for high-dimensional observations such as those arising in computer vision or natural language. It is known that optimal transport metrics can represent a cure for this problem, since they were specifically designed as an alternative to information divergences to handle such problematic scenarios. Unfortunately, training generative machines using OT raises formidable computational and statistical challenges, because of (i) the computational burden of evaluating OT losses, (ii) the instability and lack of smoothness of these losses, (iii) the difficulty to estimate robustly these losses and their gradients in high dimension. This paper presents the first tractable computational method to train large scale generative models using an optimal transport loss, and tackles both these issues by relying on two key ideas: (a) entropic smoothing, which turns the original OT loss into one that can be computed using Sinkhorn fixed point iterations; (b) algorithmic (automatic) differentiation of these iterations. These two approximations result in a robust and differentiable approximation of the OT loss with streamlined GPU execution. Entropic smoothing generates a family of losses interpolating between Wasserstein (OT) and Maximum Mean Discrepancy (MMD), thus allowing to find a sweet spot leveraging the geometry of OT and the favorable high-dimensional sample complexity of MMD which comes with unbiased gradient estimates. The resulting computational architecture complements nicely standard deep network generative models by a stack of extra layers implementing the loss function.},
author = {Genevay, A. and Peyr{\'{e}}, G. and Cuturi, M.},
booktitle = {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, PMLR 84},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Genevay, Peyr{\'{e}}, Cuturi - 2017 - Learning generative models with Sinkhorn divergences.pdf:pdf},
pages = {1608--1617},
title = {{Learning generative models with Sinkhorn divergences}},
year = {2018}
}




@article{Liu2017geomSVGD,
abstract = {We develop Riemannian Stein Variational Gradient Descent (RSVGD), a Bayesian inference method that generalizes Stein Variational Gradient Descent (SVGD) to Riemann manifold. The benefits are two-folds: (i) for inference tasks in Euclidean spaces, RSVGD has the advantage over SVGD of utilizing information geometry, and (ii) for inference tasks on Riemann manifolds, RSVGD brings the unique advantages of SVGD to the Riemannian world. To appropriately transfer to Riemann manifolds, we conceive novel and non-trivial techniques for RSVGD, which are required by the intrinsically different characteristics of general Riemann manifolds from Euclidean spaces. We also discover Riemannian Stein's Identity and Riemannian Kernelized Stein Discrepancy. Experimental results show the advantages over SVGD of exploring distribution geometry and the advantages of particle-efficiency, iteration-effectiveness and approximation flexibility over other inference methods on Riemann manifolds.},
archivePrefix = {arXiv},
arxivId = {1711.11216},
author = {Liu, Chang and Zhu, Jun},
eprint = {1711.11216},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Stein method/(2017, liu {\&} Zhu) Riemannian Stein Variational Gradient Descent for Bayesian Inference.pdf:pdf},
number = {i},
title = {{Riemannian Stein Variational Gradient Descent for Bayesian Inference}},
url = {http://arxiv.org/abs/1711.11216},
year = {2017}
}



@article{Balasubramanian2017,
abstract = {The reproducing kernel Hilbert space (RKHS) embedding of distributions offers a general and flexible framework for testing problems in arbitrary domains and has attracted considerable amount of attention in recent years. To gain insights into their operating characteristics, we study here the statistical performance of such approaches within a minimax framework. Focusing on the case of goodness-of-fit tests, our analyses show that a vanilla version of the kernel-embedding based test could be suboptimal, and suggest a simple remedy by moderating the embedding. We prove that the moderated approach provides optimal tests for a wide range of deviations from the null and can also be made adaptive over a large collection of interpolation spaces. Numerical experiments are presented to further demonstrate the merits of our approach.},
author = {Balasubramanian, K. and Li, T. and Yuan, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Hypothesis Testing/(2017, Balasubramanian) On the optimality of kernel-embedding based goodness-of-fit tests.pdf:pdf},
keywords = {adaptation,gence,goodness of fit,maximum mean discrepancy,optimal rates of conver-,reproducing kernel hilbert space},
pages = {1--44},
title = {{On the Optimality of Kernel-Embedding Based Goodness-of-Fit Tests}},
volume = {0},
year = {2017}
}




@article{Kiraly2014,
abstract = {When solving data analysis problems it is important to integrate prior knowledge and/or structural invariances. This paper contributes by a novel framework for incorporating algebraic invariance structure into kernels. In particular, we show that algebraic properties such as sign symmetries in data, phase independence, scaling etc. can be included easily by essentially performing the kernel trick twice. We demonstrate the usefulness of our theory in simulations on selected applications such as sign-invariant spectral clustering and underdetermined ICA.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {1411.7817},
author = {Kir{\'{a}}ly, F. J. and Ziehe, A. and M{\"{u}}ller, K.-R.},
eprint = {1411.7817},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/(2014, Kiraly {\&} Ziehe {\&} Muller) Learning with Algebraic Invariances and the invariant kernel trick.pdf:pdf},
pages = {1--17},
title = {{Learning with Algebraic Invariances, and the Invariant Kernel Trick}},
url = {http://arxiv.org/abs/1411.7817},
year = {2014}
}



@book{Bogachev2007,
author = {Bogachev, V. I.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Theory/(2007, Bogachev) Measure Theory.pdf:pdf},
isbn = {9783540345138},
publisher = {Springer},
title = {{Measure Theory: Volume I}},
volume = {I},
year = {2007}
}


@article{Wibisono2016,
abstract = {Accelerated gradient methods play a central role in optimization, achieving optimal rates in many settings. While many generalizations and extensions of Nesterov's original acceleration method have been proposed, it is not yet clear what is the natural scope of the acceleration concept. In this paper, we study accelerated methods from a continuous-time perspective. We show that there is a Lagrangian functional that we call the $\backslash$emph{\{}Bregman Lagrangian{\}} which generates a large class of accelerated methods in continuous time, including (but not limited to) accelerated gradient descent, its non-Euclidean extension, and accelerated higher-order gradient methods. We show that the continuous-time limit of all of these methods correspond to traveling the same curve in spacetime at different speeds. From this perspective, Nesterov's technique and many of its generalizations can be viewed as a systematic way to go from the continuous-time curves generated by the Bregman Lagrangian to a family of discrete-time accelerated algorithms.},
archivePrefix = {arXiv},
arxivId = {1603.04245},
author = {Wibisono, A. and Wilson, A. C. and Jordan, M. I.},
doi = {10.1073/pnas.1614734113},
eprint = {1603.04245},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Optimization/(2016, Wibisino) A variational perspective on accelerated methods in optimization.pdf:pdf},
isbn = {9781615679119},
issn = {0027-8424},
pages = {1--38},
pmid = {25246403},
title = {{A Variational Perspective on Accelerated Methods in Optimization}},
url = {http://arxiv.org/abs/1603.04245},
year = {2016}
}


@article{Bouranis2017SocialNetworks,
abstract = {Exponential Random Graph models are an important tool in network analysis for describing complicated dependency structures. However, Bayesian parameter estimation for these models is extremely challenging, since evaluation of the posterior distribution typically involves the calculation of an intractable normalizing constant. This barrier motivates the consideration of tractable approximations to the likelihood function, such as pseudolikelihoods, which offer a principled approach to constructing such an approximation. Naive implementation of a posterior from a misspecified model is likely to give misleading inferences. We provide practical guidelines to calibrate in a quick and efficient manner samples coming from an approximated posterior and discuss the efficiency of this approach. The exposition of the methodology is accompanied by the analysis of real-world graphs. Comparisons against the Approximate Exchange algorithm of Caimo and Friel (2011) are provided, followed by concluding remarks.},
archivePrefix = {arXiv},
arxivId = {1510.00934},
author = {Bouranis, L. and Friel, N. and Maire, F.},
doi = {10.1016/j.socnet.2017.03.013},
eprint = {1510.00934},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Likelihood-based inference/pseudo likelihood/(2017, Bouranis) Efficient Bayesian inference for exponential random graph models by correcting the pseudo-posterior distribution.pdf:pdf},
issn = {03788733},
journal = {Social Networks},
keywords = {exponential random graph models,intractable normalizing constants},
pages = {98--108},
publisher = {Elsevier B.V.},
title = {{Efficient Bayesian inference for exponential random graph models by correcting the pseudo-posterior distribution}},
url = {http://arxiv.org/abs/1510.00934},
volume = {50},
year = {2017}
}



@article{Prangle2017,
abstract = {The g-and-k and (generalised) g-and-h distributions are flexible univariate distributions which can model highly skewed or heavy tailed data through only four parameters: location and scale, and two shape parameters influencing the skewness and kurtosis. These distributions have the unusual property that they are defined through their quantile function (inverse cumulative distribution function) and their density is unavailable in closed form, which makes parameter inference complicated. This paper presents the gk R package to work with these distributions. It provides the usual distribution functions and several algorithms for inference of independent identically distributed data, including the finite difference stochastic approximation method, which has not been used before for this problem.},
author = {Prangle, D.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Bayesian Statistics/ABC/(2017, Prangle) gk - an R package for the g-and-k and generalised g-and-h distributions.pdf:pdf},
journal = {arXiv:1706.06889},
title = {{gk: An R Package for the g-and-k and generalised g-and-h Distributions}},
year = {2017}
}


@article{Bouranis2017,
abstract = {Exponential random graph models are a class of widely used exponential family models for social networks. The topological structure of an observed network is modelled by the relative prevalence of a set of local sub-graph configurations termed network statistics. One of the key tasks in the application of these models is which network statistics to include in the model. This can be thought of as statistical model selection problem. This is a very challenging problem-the posterior distribution for each model is often termed " doubly intractable" since computation of the likelihood is rarely available, but also, the evidence of the posterior is, as usual, intractable. The contribution of this paper is the development of a fully Bayesian model selection method based on a reversible jump Markov chain Monte Carlo algorithm extension of Caimo and Friel (2011) which estimates the posterior probability for each competing model. ?? 2012 Elsevier B.V.},
author = {Bouranis, L. and Friel, N. and Maire, F.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Likelihood-based inference/pseudo likelihood/(2017, Bouranis) Bayesian model selection for exponential random graph models via adjusted pseudolikelihoods.pdf:pdf},
journal = {arXiv:1706.06344},
keywords = {bayes factors,constants,evidence,exponential random graph models,intractable normalising,pseudolikelihood,tractable approximation},
title = {{Bayesian model selection for exponential random graph models via adjusted pseudolikelihoods}},
year = {2017}
}


@article{Geyer1991,
abstract = {Markov chain Monte Carlo (e. g., the Metropolis algorithm and Gibbs sampler) is a general tool for simulation of complex stochastic processes useful in many types of statistical inference. The basics of Markov chain Monte Carlo are reviewed, including choice of algorithms and variance estimation, and some new methods are introduced. The use of Markov chain Monte Carlo for maximum likelihood estimation is explained, and its performance is compared with maximum pseudo likelihood estimation},
author = {Geyer, C. J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Likelihood-based inference/Monte Carlo likelihood/(1991, Geyer) Markov Chain Monte Carlo Maximum likelihood.pdf:pdf},
journal = {Computing Science and Statistics: Proceedings of the 23rd Symposium on the Interface},
keywords = {Gibbs sampler,Markov chain,Monte Carlo,likelihood,maximum,metropolis algorithm,vari-},
number = {1},
pages = {156--163},
title = {{Markov Chain Monte Carlo Maximum Likelihood}},
year = {1991}
}



@book{Hall2005,
author = {Hall, A. R.},
publisher = {Oxford University Press},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2005, Hall) Generalized{\_}method{\_}of{\_}moments.pdf:pdf},
title = {{Generalized Method of Moments}},
year = {2005}
}


@article{Varin2011,
abstract = {A survey of recent developments in the theory and application of composite likelihood is provided, building on the review paper of Varin (2008). A range of application areas, including geostatistics, spatial extremes, and space-time models, as well as clustered and longitudinal data and time series are considered. The important area of applications to statistical genetics is omitted, in light of Larribe and Fearnhead (2011). Emphasis is given to the development of the theory, and the current state of knowledge on efficiency and robustness of composite likelihood inference.},
author = {Varin, C. and Reid, N. and Firth, D.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Likelihood-based inference/composite likelihood/(2011, Varin) An overview of composite likelihood methods.pdf:pdf},
journal = {Statistica Sinica},
keywords = {and phrases,copulas,generalized estimating equations,geostatistics,godambe information,hood,longitudinal data,multivariate binary data,pseudo-likeli-,quasi-likelihood,robustness,spatial extremes,time series},
pages = {5--42},
title = {{An overview of composite likelihood methods}},
volume = {21},
year = {2011}
}


@article{Besag1974,
abstract = {The formulation of conditional probability models for finite systems of spatially interacting random variables is examined. A simple alternative proof of the Hammersley-Clifford theorem is presented and the theorem is then used to construct specific spatial schemes on and off the lattice. Particular emphasis is placed upon practical applications of the models in plant ecology when the variates are binary or Gaussian. Some aspects of infinite lattice Gaussian processes are discussed. Methods of statistical analysis for lattice schemes are proposed, including a very flexible coding technique. The methods are illustrated by two numerical examples. It is maintained throughout that the conditional probability approach to the specification and analysis of spatial interaction is more attractive than the alternative joint probability approach. Keywords},
author = {Besag, J},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Likelihood-based inference/Pseudolikelihood/(1974, Besag) Spatial interaction and the statistical analysis of lattice systems.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B},
number = {2},
title = {{Spatial interaction and the statistical analysis of lattice systems}},
volume = {36},
year = {1974}
}



@article{Moller2006,
author = {Moller, J. and Pettitt, A. N. and Reeves, R.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/doubly intractable/(2006, Moller) An efficient Markov Chain Monte Carlo method for distributions with intractable normalising constants.pdf:pdf},
journal = {Biometrika},
number = {2},
pages = {451--458},
title = {{An efficient Markov Chain Monte Carlo method for distributions with intractable normalising constants}},
volume = {93},
year = {2006}
}


@inproceedings{Murray2006,
abstract = {Markov Chain Monte Carlo (MCMC) algorithms are routinely used to draw samples from distributions with intractable normalization constants. However, standard MCMC algorithms do not apply to doubly-intractable distributions in which there are additional parameter-dependent normalization terms; for example, the posterior over parameters of an undirected graphical model. An ingenious auxiliary-variable scheme (Moeller, 2004) offers a solution: exact sampling (Propp and Wilson, 1996) is used to sample from a Metropolis-Hastings proposal for which the acceptance probability is tractable. Unfortunately the acceptance probability of these expensive updates can be low. This paper provides a generalization of Moeller (2004) and a new MCMC algorithm, which obtains better acceptance probabilities for the same amount of exact sampling, and removes the need to estimate model parameters before sampling begins.},
author = {Murray, I. and Ghahramani, Z. and MacKay, D. J. C.},
booktitle = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Murray, Ghahramani, MacKay - 2006 - MCMC for doubly-intractable distributions.pdf:pdf},
keywords = {Theory {\&} Algorithms},
mendeley-groups = {OxWaSP modules/module 4 - Stochastic Simulation},
pages = {359--366},
title = {{MCMC for doubly-intractable distributions}},
year = {2006}
}



@article{Bassetti2006asymptotic,
author = {Bassetti, F. and Regazzini, E.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2006, Basseti) Asymptotic and robustness of minimum dissimilarity estimators of location-scale parameters.pdf:pdf},
journal = {Theory of Probability and Its Applications},
keywords = {10,1137,argmax argument,asymptotic laws,brownian bridge,bustness,doi,estimator,gini,influence function,kantorovich,minimum dissimilarity,minimum dissimilarity estimators,monge,occupation time of a,ro-,s0040585x97981664,wasserstein metric},
number = {2},
pages = {171--186},
title = {{Asymptotic properties and robustness of minimum dissimilarity estimators of location-scale parameters}},
volume = {50},
year = {2006}
}



@article{Sutherland2017score,
abstract = {We propose a fast method with statistical guarantees for learning an exponential family density model where the natural parameter is in a reproducing kernel Hilbert space, and may be infinite dimensional. The model is learned by fitting the derivative of the log density, the score, thus avoiding the need to compute a normalization constant. We improved the computational efficiency of an earlier solution with a low-rank, Nystr$\backslash$"om-like solution. The new solution remains consistent, and is shown to converge in Fisher distance at the same rate as a full-rank solution, with guarantees on the degree of cost and storage reduction. We compare to a popular score learning approach using a denoising autoencoder, in experiments on density estimation and in the construction of an adaptive Hamiltonian Monte Carlo sampler. Apart from the lack of statistical guarantees for the autoencoder, our estimator is more data-efficient when estimating the score, runs faster, and has fewer parameters (which can be tuned in a principled and interpretable way).},
author = {Sutherland, D. J. and Strathmann, H. and Arbel, M. and Gretton, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2017, Sutherland) Efficient and principled score estimation.pdf:pdf},
journal = {arXiv:1705.08360},
title = {{Efficient and principled score estimation}},
year = {2017}
}



@article{Moores2015,
abstract = {The inverse temperature parameter of the Potts model governs the strength of spatial cohesion and therefore has a substantial influence over the resulting model fit. A difficulty arises from the dependence of an intractable normalising constant on the value of this parameter and thus there is no closed form solution for sampling from the posterior distribution directly. There are a variety of computational approaches for sampling from the posterior without evaluating the normalising constant. These algorithms differ in their levels of accuracy and their scalability for datasets of realistic size. This study compares pseudolikelihood, the exchange algorithm, path sampling, and approximate Bayesian computation. We assess their accuracy and scalability using synthetic data as well as 2D remote sensing and 3D medical images. Our findings provide guidance on selecting a suitable algorithm for Bayesian image analysis. For nontrivial images, this necessarily involves some degree of approximation to produce an acceptable compromise between accuracy and computational cost.},
author = {Moores, M. T. and Pettitt, A. N. and Mengersen, K.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Bayesian Statistics/(2015, Moores) Scalable Bayesian Inference for the Inverse Temperature of a Hidden Potts Model.pdf:pdf},
journal = {arXiv:1503.08066},
keywords = {approximate bayesian computation,composite likelihood,hidden,image analysis,markov random field,pseudo-marginal method,thermody-},
pages = {1--30},
title = {{Scalable Bayesian Inference for the Inverse Temperature of a Hidden Potts Model}},
year = {2015}
}

@book{Mockus1989,
author = {Mockus, J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probabilistic Numerics/(1989, Mockus) Bayesian Approach to Global Optimization{\_} Theory and Applications.pdf:pdf},
publisher = {Kluwer Academic Publishers},
title = {{Bayesian Approach to Global Optimization: Theory and Applications}},
year = {1989}
}


@article{Gretton2009,
abstract = {A kernel embedding of probability distributions into reproducing kernel Hilbert spaces (RKHS) has recently been proposed, which allows the comparison of two probability measures P and Q based on the distance between their respective embeddings: for a sufficiently rich RKHS, this distance is zero if and only if P and Q coincide. In using this distance as a statistic for a test of whether two samples are from different distributions, a major difficulty arises in computing the significance threshold, since the empirical statistic has as its null distribution (where P = Q) an infinite weighted sum of 2 random variables. Prior finite sample approximations to the null distribution include using bootstrap resampling, which yields a consistent estimate but is computationally costly; and fitting a parametric model with the low order moments of the test statistic, which can work well in practice but has no consistency or accuracy guarantees. The main result of the present work is a novel estimate of the null distribution, computed from the eigen- spectrum of the Gram matrix on the aggregate sample from P and Q, and having lower computational cost than the bootstrap. A proof of consistency of this estimate is provided. The performance of the null distribution estimate is compared with the bootstrap and parametric approaches on an artificial example, high dimensional multivariate data, and text.},
author = {Gretton, A. and Fukumizu, K. and Harchaoui, Z. and Sriperumbudur, B. K.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Hypothesis Testing/(2009, Gretton et al) A fast consistent kernel two-sample test.pdf:pdf},
isbn = {978-1-615-67911-9},
journal = {Advances in Neural Information Processing Systems},
pages = {673--681},
title = {{A Fast, Consistent Kernel Two-Sample Test}},
year = {2009}
}


@inproceedings{Chwialkowski2015,
abstract = {We propose a class of nonparametric two-sample tests with a cost linear in the sample size. Two tests are given, both based on an ensemble of distances between analytic functions representing each of the distributions. The first test uses smoothed empirical characteristic functions to represent the distributions, the second uses distribution embeddings in a reproducing kernel Hilbert space. Analyticity implies that differences in the distributions may be detected almost surely at a finite number of randomly chosen locations/frequencies. The new tests are consistent against a larger class of alternatives than the previous linear-time tests based on the (non-smoothed) empirical characteristic functions, while being much faster than the current state-of-the-art quadratic-time kernel-based or energy distance-based tests. Experiments on artificial benchmarks and on challenging real-world testing problems demonstrate that our tests give a better power/time tradeoff than competing approaches, and in some cases, better outright power than even the most expensive quadratic-time tests. This performance advantage is retained even in high dimensions, and in cases where the difference in distributions is not observable with low order statistics.},
author = {Chwialkowski, K. and Ramdas, A. and Sejdinovic, D. and Gretton, A.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Hypothesis Testing/(2015, Chwialkowski {\&} Ramdas {\&} Sejdinovic {\&} Gretton) Fast two-sample testing with analytic representations of probability measures.pdf:pdf},
pages = {1981--1989},
title = {{Fast Two-Sample Testing with Analytic Representations of Probability Measures}},
year = {2015}
}


@article{Jitkrittum2017,
abstract = {We propose a novel adaptive test of goodness-of-fit, with computational cost linear in the number of samples. We learn the test features that best indicate the differences between observed samples and a reference model, by minimizing the false negative rate. These features are constructed via Stein's method, meaning that it is not necessary to compute the normalising constant of the model. We analyse the asymptotic Bahadur efficiency of the new test, and prove that under a mean-shift alternative, our test always has greater relative efficiency than a previous linear-time kernel test, regardless of the choice of parameters for that test. In experiments, the performance of our method exceeds that of the earlier linear-time test, and matches or exceeds the power of a quadratic-time kernel test. In high dimensions and where model structure may be exploited, our goodness of fit test performs far better than a quadratic-time two-sample test based on the Maximum Mean Discrepancy, with samples drawn from the model.},
author = {Jitkrittum, W. and Xu, W. and Szabo, Z. and Fukumizu, K. and Gretton, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Stein method/Stein {\&} Kernels/(2017, Jitkrittum) A linear-time kernel goodness-of-fit test.pdf:pdf},
journal = {arXiv:1705.07673},
title = {{A Linear-Time Kernel Goodness-of-Fit Test}},
year = {2017}
}

@article{Gretton2012kernelchoice,
abstract = {Given samples from distributions p and q, a two-sample test determines whether to reject the null hypothesis that p=q, based on the value of a test statistic measuring the distance between the samples. One choice of test statistic is the maximum mean discrepancy (MMD), which is a distance between embeddings of the probability distributions in a reproducing kernel Hilbert space. The kernel used in obtaining these embeddings is thus critical in ensuring the test has high power, and correctly distinguishes unlike distributions with high probability. A means of parameter selection for the two-sample test based on the MMD is proposed. For a given test level (an upper bound on the probability of making a Type I error), the kernel is chosen so as to maximize the test power, and minimize the probability of making a Type II error. The test statistic, test threshold, and optimization over the kernel parameters are obtained with cost linear in the sample size. These properties make the kernel selection and test procedures suited to data streams, where the observations cannot all be stored in memory. In experiments, the new kernel selection approach yields a more powerful test than earlier kernel selection heuristics.},
author = {Gretton, A. and Sriperumbudur, B. K. and Sejdinovic, D. and Strathmann, H. and Balakrishnan, S. and Pontil, M. and Fukumizu, K.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Hypothesis Testing/(2012, Gretton et al) Optimal kernel choice for large-scale two-sample tests.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 25},
pages = {1214--1222},
title = {{Optimal kernel choice for large-scale two-sample tests}},
year = {2012}
}


@article{Mameli2015,
abstract = {In this paper we discuss higher-order asymptotic expansions for proper scoring rules generalizing results for likelihood quantities, but meanwhile bring in the difficulty caused by the failure of the information identity. In particular, we derive higher-order approximations to the distribution of the scoring rule estimator, of the scoring rule ratio test statistic and, for a scalar parameter of interest, of the signed scoring rule root statistic. From these expansions, a modified signed scoring rule root statistic is proposed. Examples are given illustrating the accuracy of the modified signed scoring rule root statistic with respect to first-order methods.},
author = {Mameli, V. and Ventura, L.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Other Statistics/proper scoring rules/(2015, Mameli) Higher-order asymptotics for scoring rules.pdf:pdf},
journal = {Journal of Statistical Planning and Inference},
keywords = {Asymptotic expansions,Hyv{\"{a}}rinen scoring rule,Information identity,Likelihood asymptotics,Robustness,Third-order inference,Tsallis scoring rule},
pages = {13--26},
title = {{Higher-order asymptotics for scoring rules}},
volume = {165},
year = {2015}
}





@inproceedings{Cuturi2013,
abstract = {Optimal transportation distances are a fundamental family of parameterized distances for histograms. Despite their appealing theoretical properties, excellent performance in retrieval tasks and intuitive formulation, their computation involves the resolution of a linear program whose cost is prohibitive whenever the histograms' dimension exceeds a few hundreds. We propose in this work a new family of optimal transportation distances that look at transportation problems from a maximum-entropy perspective. We smooth the classical optimal transportation problem with an entropic regularization term, and show that the resulting optimum is also a distance which can be computed through Sinkhorn-Knopp's matrix scaling algorithm at a speed that is several orders of magnitude faster than that of transportation solvers. We also report improved performance over classical optimal transportation distances on the MNIST benchmark problem.},
author = {Cuturi, M.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Transport of Measure/(2013, Cuturi) Sinkhorn distances - lightspeed computation of optimal transport distances.pdf:pdf},
pages = {2292--2300},
title = {{Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances}},
year = {2013}
}



@article{Gutmann2012,
abstract = {We consider the task of estimating, from observed data, a probabilistic model that is parameterized by a finite number of parameters. In particular, we are considering the situation where the model probability density function is unnormalized. That is, themodel is only specified up to the partition function. The partition function normalizes a model so that it integrates to one for any choice of the parameters. However, it is often impossible to obtain it in closed form. Gibbs distributions, Markov and multi-layer networks are examples of models where analytical normalization is often impossible. Maximum likelihood estimation can then not be used without resorting to numerical approximations which are often computationally expensive. We propose here a new objective func- tion for the estimation of both normalized and unnormalized models. The basic idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially gener- ated noise. With this approach, the normalizing partition function can be estimated like any other parameter. We prove that the new estimation method leads to a consistent (convergent) estimator of the parameters. For large noise sample sizes, the new estimator is furthermore shown to be- have like the maximum likelihood estimator. In the estimation of unnormalized models, there is a trade-off between statistical and computational performance. We show that the new method strikes a competitive trade-off in comparison to other estimationmethods for unnormalizedmodels. As an application to real data, we estimate novel two-layer models of natural image statistics with spline nonlinearities.},
author = {Gutmann, M. U. and Hyvarinen, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2012, Gutmann {\&} Hyvarinen) Noise-contrastive estimation of unnormalized statistical models with applications to natural image statistics.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {computation,estimation,natural image statistics,partition function,unnormalized models},
pages = {307--361},
title = {{Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics}},
volume = {13},
year = {2012}
}




@book{Patel1996,
author = {Patel, J. K. and Read, C. B.},
title = {Handbook of the Normal Distribution},
year = {1996},
series = {Statistics: A Series of Textbooks and Monographs},
publisher = {CRC Press}
}


@article{Marin2012,
author = {Marin, J. M. and Pudlo, P. and Robert, C. P. and Ryder, R. J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Mini-projects/Research on mini-projects/ABC and Nested Sampling - C Robert/(2011, Marin et al) Approximate bayesian Computational methods.pdf:pdf},
journal = {Statistics and Computing},
keywords = {abc methodology,agence nationale de la,anr-09-,as well as by,bayesian model choice,bayesian statistics,blan-0145-01,diyabc,emile,likelihood-free methods,math,recherche grant,supported by the french,the fondation des sciences,this research was financially},
number = {6},
pages = {1167--1180},
title = {{Approximate Bayesian computational methods}},
volume = {22},
year = {2012}
}





@article{Lyne2015,
abstract = {A large number of statistical models are "doubly-intractable": the likelihood normalising term, which is a function of the model parameters, is intractable, as well as the marginal likelihood (model evidence). This means that standard inference techniques to sample from the posterior, such as Markov chain Monte Carlo (MCMC), cannot be used. Examples include, but are not confined to, massive Gaussian Markov random fields, autologistic models and Exponential random graph models. A number of approximate schemes based on MCMC techniques, Approximate Bayesian computation (ABC) or analytic approximations to the posterior have been suggested, and these are reviewed here. Exact MCMC schemes, which can be applied to a subset of doubly-intractable distributions, have also been developed and are described in this paper. As yet, no general method exists which can be applied to all classes of models with doubly-intractable posteriors. In addition, taking inspiration from the Physics literature, we study an alternative method based on representing the intractable likelihood as an infinite series. Unbiased estimates of the likelihood can then be obtained by finite time stochastic truncation of the series via Russian Roulette sampling, although the estimates are not necessarily positive. Results from the Quantum Chromodynamics literature are exploited to allow the use of possibly negative estimates in a pseudo-marginal MCMC scheme such that expectations with respect to the posterior distribution are preserved. The methodology is reviewed on well-known examples such as the parameters in Ising models, the posterior for Fisher-Bingham distributions on the {\$}d{\$}-Sphere and a large-scale Gaussian Markov Random Field model describing the Ozone Column data. This leads to a critical assessment of the strengths and weaknesses of the methodology with pointers to ongoing research.},
author = {Lyne, A.-M. and Girolami, M. and Atchad{\'{e}}, Y. and Strathmann, H. and Simpson, D.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/Russian roulette/(2015, Lyne) Playing russian roulette with doubly intractable  likelihoods.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,anne-marie lyne is a,d,department of,intractable likelihood,london,monte carlo methods,ph,pseudo-marginal mcmc,russian roulette sampling,statistical science,student,university college london},
number = {4},
pages = {443--467},
title = {{On Russian Roulette Estimates for Bayesian Inference with Doubly-Intractable Likelihoods}},
volume = {30},
year = {2015}
}


@article{Li2017,
abstract = {Generative moment matching network (GMMN) is a deep generative model that differs from Generative Adversarial Network (GAN) by replacing the discriminator in GAN with a two-sample test based on kernel maximum mean discrepancy (MMD). Although some theoretical guarantees of MMD have been studied, the empirical performance of GMMN is still not as competitive as that of GAN on challenging and large benchmark datasets. The computational efficiency of GMMN is also less desirable in comparison with GAN, partially due to its requirement for a rather large batch size during the training. In this paper, we propose to improve both the model expressiveness of GMMN and its computational efficiency by introducing adversarial kernel learning techniques, as the replacement of a fixed Gaussian kernel in the original GMMN. The new approach combines the key ideas in both GMMN and GAN, hence we name it MMD-GAN. The new distance measure in MMD-GAN is a meaningful loss that enjoys the advantage of weak topology and can be optimized via gradient descent with relatively small batch sizes. In our evaluation on multiple benchmark datasets, including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GAN significantly outperforms GMMN, and is competitive with other representative GAN works.},
author = {Li, C.-L. and Chang, W.-C. and Cheng, Y. and Yang, Y. and P{\'{o}}czos, B.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Neural Networks/(2017, Li) MMD GAN - Towards deeper understanding of moment matching network.pdf:pdf},
journal = {arXiv:1705.08584},
pages = {1--13},
title = {{MMD GAN: Towards Deeper Understanding of Moment Matching Network}},
url = {http://arxiv.org/abs/1705.08584},
year = {2017}
}



@article{Bernton2017,
author = {Bernton, E. and Jacob, P. E. and Gerber, M. and Robert, C. P.},
file = {:home/francois/Dropbox/Work/Papers/Probability Distributions/Distances between distributions/minimum distance estimation/(2019, Bernton) Approximate Bayesian computation with the Wasserstein distance.pdf:pdf},
journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
keywords = {Approximate Bayesian computation,Generative models,Likelihood-free inference,Optimal transport,Wasserstein distance},
number = {2},
pages = {235--269},
title = {{Approximate Bayesian computation with the Wasserstein distance}},
volume = {81},
year = {2019}
}



@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, M. and Chintala, S. and Bottou, L.},
eprint = {1701.07875},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Variatonal Inference/(2017, Arjovsky {\&} Chintala {\&} Bottou) Wasserstein GAN.pdf:pdf},
title = {{Wasserstein GAN}},
url = {http://arxiv.org/abs/1701.07875},
year = {2017}
}

@inproceedings{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow, Pouget-Abadie, Mirza - 2014 - Generative Adversarial Networks.pdf:pdf},
pages = {2672--2680},
title = {{Generative Adversarial Networks}},
year = {2014}
}

@article{Cameron2012,
author = {Cameron, E. and Pettitt, A. N.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Bayesian Statistics/ABC/(2012, Cameron {\&} Pettitt) Approximate Bayesian computation for astronomical model analysis.pdf:pdf},
journal = {Monthly Notices of the Royal Astronomical Society},
keywords = {evolution,formation,galaxies,methods,statistical},
number = {1},
pages = {44--65},
title = {{Approximate Bayesian Computation for Astronomical Model Analysis: A Case Study in Galaxy Demographics and Morphological Transformation at High Redshift}},
volume = {425},
year = {2012}
}



@article{Beaumont2002,
author = {Beaumont, M. A. and Zhang, W. and Balding, D. J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Bayesian Statistics/ABC/(2002, Beaumont) Approximate Bayesian Computation in Population Genetics.pdf:pdf},
journal = {Genetics},
pages = {2025--2035},
title = {{Approximate Bayesian Computation in Population Genetics}},
volume = {162},
year = {2002}
}

@inproceedings{Li2015GMMN,
abstract = {We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer preceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.},
author = {Li, Y. and Swersky, K. and Zemel, R.},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Kernel Embeddings/(2015, Li) Generative Moment Matching Networks.pdf:pdf},
pages = {1718--1727},
title = {{Generative Moment Matching Networks}},
volume = {37},
year = {2015}
}

@inproceedings{Sutherland2017,
abstract = {We propose a method to optimize the representation and distinguishability of samples from two probability distributions, by maximizing the estimated power of a statistical test based on the maximum mean discrepancy (MMD). This optimized MMD is applied to the setting of unsupervised learning by generative adversarial networks (GAN), in which a model attempts to generate realistic samples, and a discriminator attempts to tell these apart from data samples. In this context, the MMD may be used in two roles: first, as a discriminator, either directly on the samples, or on features of the samples. Second, the MMD can be used to evaluate the performance of a generative model, by testing the model's samples against a reference data set. In the latter role, the optimized MMD is particularly helpful, as it gives an interpretable indication of how the model and data distributions differ, even in cases where individual model samples are not easily distinguished either by eye or by classifier.},
author = {Sutherland, D. J. and Tung, H.-Y. and Strathmann, H. and De, S. and Ramdas, A. and Smola, Al. and Gretton, A.},
booktitle = {Proceedings of the International Conference on Learning Representation},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Kernel Embeddings/(2017, Sutherland et al) Generative models and model criticism via optimized maximum mean discrepancy.pdf:pdf},
title = {{Generate Models and Model Criticism via Optimized Maximum Mean Discrepancy}},
year = {2017}
}


@book{Owen2001,
author = {Owen, Art B.},
booktitle = {Monographs on Statistics and Applied Probability},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/(2001, Owen) Empirical Likelihood.pdf:pdf},
pages = {304},
publisher = {CRC Press},
title = {{Empirical Likelihood}},
year = {2001}
}



@article{Mohamed2016,
abstract = {Generative adversarial networks (GANs) provide an algorithmic framework for constructing generative models with several appealing properties: they do not require a likelihood function to be specified, only a generating procedure; they provide samples that are sharp and compelling; and they allow us to harness our knowledge of building highly accurate neural network classifiers. Here, we develop our understanding of GANs with the aim of forming a rich view of this growing area of machine learning---to build connections to the diverse set of statistical thinking on this topic, of which much can be gained by a mutual exchange of ideas. We frame GANs within the wider landscape of algorithms for learning in implicit generative models--models that only specify a stochastic procedure with which to generate data--and relate these ideas to modelling problems in related fields, such as econometrics and approximate Bayesian computation. We develop likelihood-free inference methods and highlight hypothesis testing as a principle for learning in implicit generative models, using which we are able to derive the objective function used by GANs, and many other related objectives. The testing viewpoint directs our focus to the general problem of density ratio estimation. There are four approaches for density ratio estimation, one of which is a solution using classifiers to distinguish real from generated data. Other approaches such as divergence minimisation and moment matching have also been explored in the GAN literature, and we synthesise these views to form an understanding in terms of the relationships between them and the wider literature, highlighting avenues for future exploration and cross-pollination.},
author = {Mohamed, S. and Lakshminarayanan, B.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Neural Networks/(2017, Mohamed {\&} Lakshimarayanan) Learning in implicit generative models.pdf:pdf},
journal = {arXiv:1610.03483v4},
title = {{Learning in Implicit Generative Models}},
year = {2016}
}


@article{Pascanu2014,
abstract = {We evaluate natural gradient, an algorithm originally proposed in Amari (1997), for learning deep models. The contributions of this paper are as follows. We show the connection between natural gradient and three other recently proposed methods for training deep models: Hessian-Free (Martens, 2010), Krylov Subspace Descent (Vinyals and Povey, 2012) and TONGA (Le Roux et al., 2008). We describe how one can use unlabeled data to improve the generalization error obtained by natural gradient and empirically evaluate the robustness of the algorithm to the ordering of the training set compared to stochastic gradient descent. Finally we extend natural gradient to incorporate second order information alongside the manifold information and provide a benchmark of the new algorithm using a truncated Newton approach for inverting the metric matrix instead of using a diagonal approximation of it.},
author = {Pascanu, Razvan and Bengio, Yoshua},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/natural gradient descent/(2014, Pascanu {\&} Bengio) Revisiting natural gradient for deep networks.pdf:pdf},
journal = {International Conference on Learning Representation},
title = {{Revisiting Natural Gradient for Deep Networks}},
year = {2014}
}





@book{Chen2011,
author = {Chen, L. H. Y. and Goldstein, L. and Shao, Q-M.},
file = {:home/francois/Dropbox/Work/Papers/Stein method/(Probability and Its Applications) Louis H.Y. Chen, Larry Goldstein, Qi-Man Shao (auth.) - Normal Approximation by Stein's Method-Springer-Verlag Berlin Heidelberg (2011).pdf:pdf},
publisher = {Springer},
title = {{Normal Approximation by Stein's Method}},
year = {2011}
}


@inproceedings{Stein1972,
author = {Stein, C.},
booktitle = {Proceedings of 6th Berkeley Symposium on Mathematical Statistics and Probability},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Stein method/(1972, Stein) A bound for the error in the normal approximation to the distribution of a sum of dependent random variables.pdf:pdf},
pages = {583--602},
publisher = {University of California Press},
title = {{A bound for the error in the normal approximation to the distribution of a sum of dependent random variables}},
year = {1972}
}

@book{Barbour2005,
address = {National University of Singapore},
author = {Barbour, A and Chen, L H Y},
publisher = {Lecture Notes Series, Institute for Mathematical Sciences},
title = {{An introduction to Stein's method}},
year = {2005}
}


@inproceedings{Chen2018,
abstract = {An important task in computational statistics and machine learning is to approximate a posterior distribution {\$}p(x){\$} with an empirical measure supported on a set of representative points {\$}\backslash{\{}x{\_}i\backslash{\}}{\_}{\{}i=1{\}}{\^{}}n{\$}. This paper focuses on methods where the selection of points is essentially deterministic, with an emphasis on achieving accurate approximation when {\$}n{\$} is small. To this end, we present `Stein Points'. The idea is to exploit either a greedy or a conditional gradient method to iteratively minimise a kernel Stein discrepancy between the empirical measure and {\$}p(x){\$}. Our empirical results demonstrate that Stein Points enable accurate approximation of the posterior at modest computational cost. In addition, theoretical results are provided to establish convergence of the method.},
author = {Chen, W. Y. and Mackey, L. and Gorham, J. and Briol, F-X. and Oates, C. J.},
booktitle = {Proceedings of the International Conference on Machine Learning, PMLR 80:843-852},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2018 - Stein Points.pdf:pdf},
title = {{Stein points}},
year = {2018}
}


@inproceedings{Chen2019,
author = {Chen, W. Y. and Barp, A. and Briol, F-X. and Gorham, J. and Girolami, M. and Mackey, L. and Oates, C. J.},
booktitle = {International Conference on Machine Learning, PMLR 97},
file = {:home/francois/Dropbox/Work/Papers/Stein method/Stein {\&} Kernels/(2019, Chen) Stein Point Markov Chain Monte Carlo.pdf:pdf},
pages = {1011--1021},
title = {{Stein point Markov chain Monte Carlo}},
year = {2019}
}


@inproceedings{Chen2010,
abstract = {We extend the herding algorithm to continuous spaces by using the kernel$\backslash$ntrick. The resulting "kernel herding" algorithm is an infinite memory$\backslash$ndeterministic process that learns to approximate a PDF with a collection of$\backslash$nsamples. We show that kernel herding decreases the error of expectations of$\backslash$nfunctions in the Hilbert space at a rate O(1/T) which is much faster than the$\backslash$nusual O(1/pT) for iid random samples. We illustrate kernel herding by$\backslash$napproximating Bayesian predictive distributions.},
author = {Chen, Y. and Welling, M. and Smola, A.},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Welling, Smola - 2010 - Super-samples from kernel herding.pdf:pdf},
mendeley-groups = {OxWaSP mini-project 1 - convergence for SBQ},
title = {{Super-samples from kernel herding}},
year = {2010}
}


@inproceedings{Li2015,
abstract = {We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer preceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.},
author = {Li, Yujia and Swersky, Kevin and Zemel, Rich},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Kernel Embeddings/(2015, Li) Generative Moment Matching Networks.pdf:pdf},
pages = {1718--1727},
title = {{Generative Moment Matching Networks}},
volume = {37},
year = {2015}
}



@article{Diggle1984,
author = {Diggle, P. J. and Gratton, R. J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Density estimation/(1984, Diggle {\&} Gratton) Monte Carlo Methods of Inference for Implicit Statistical Models.pdf:pdf},
journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
number = {2},
pages = {193--227},
title = {{Monte Carlo Methods of Inference for Implicit Statistical Models}},
volume = {46},
year = {1984}
}


@article{Wood2010,
abstract = {Chaotic ecological dynamic systems defy conventional statistical analysis. Systems with near-chaotic dynamics are little better. Such systems are almost invariably driven by endogenous dynamic processes plus demographic and environmental process noise, and are only observable with error. Their sensitivity to history means that minute changes in the driving noise realization, or the system parameters, will cause drastic changes in the system trajectory. This sensitivity is inherited and amplified by the joint probability density of the observable data and the process noise, rendering it useless as the basis for obtaining measures of statistical fit. Because the joint density is the basis for the fit measures used by all conventional statistical methods, this is a major theoretical shortcoming. The inability to make well-founded statistical inferences about biological dynamic models in the chaotic and near-chaotic regimes, other than on an ad hoc basis, leaves dynamic theory without the methods of quantitative validation that are essential tools in the rest of biological science. Here I show that this impasse can be resolved in a simple and general manner, using a method that requires only the ability to simulate the observed data on a system from the dynamic model about which inferences are required. The raw data series are reduced to phase-insensitive summary statistics, quantifying local dynamic structure and the distribution of observations. Simulation is used to obtain the mean and the covariance matrix of the statistics, given model parameters, allowing the construction of a 'synthetic likelihood' that assesses model fit. This likelihood can be explored using a straightforward Markov chain Monte Carlo sampler, but one further post-processing step returns pure likelihood-based inference. I apply the method to establish the dynamic nature of the fluctuations in Nicholson's classic blowfly experiments.},
author = {Wood, S. N.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Likelihood-based inference/synthetic likelihood/(2010, Wood) Statistical inference for noisy nonlinear ecological dynamic systems.pdf:pdf},
journal = {Nature},
number = {7310},
pages = {1102--1104},
title = {{Statistical inference for noisy nonlinear ecological dynamic systems}},
volume = {466},
year = {2010}
}

@book{Devroye1986,
abstract = {This chapter provides a survey of the main methods in non-uniform random variate generation, and highlights recent research on the subject. Classical paradigms such as inversion, rejection, guide tables, and transformations are reviewed. We provide information on the ex- pected time complexity of various algorithms, before addressing modern topics such as indirectly specified distributions, random processes, and Markov chain methods.},
address = {New York},
author = {Devroye, L.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Devroye - 2010 - Complexity questions in non-uniform random variate generation.pdf:pdf},
keywords = {Monte Carlo methods,Random variate generation,Simulation},
mendeley-groups = {Master's Thesis/Master Dissertation - Inference for Hawkes Processes},
publisher = {Springer-Verlag},
title = {{Non-Uniform Random Variate Generation}},
year = {1986}
}


@article{Caimo2015,
author = {Caimo, A. and Mira, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/doubly intractable/(2014, Caimo {\&} Mira) Efficient computational strategies for doubly intractable problems with applications to Bayesian social networks.pdf:pdf},
journal = {Statistics and Computing},
keywords = {adaptive metropolis,delayed rejection,doubly-intractable target,exponential,hastings proposal,intractable,likelihoods,markov chain monte carlo},
pages = {113--125},
title = {{Efficient computational strategies for doubly intractable problems with applications to Bayesian social networks}},
volume = {25},
year = {2015}
}


@inproceedings{Dziugaite2015,
abstract = {We consider training a deep neural network to generate samples from an unknown distribution given i.i.d. data. We frame learning as an optimization minimizing a two-sample test statistic---informally speaking, a good generator network produces samples that cause a two-sample test to fail to reject the null hypothesis. As our two-sample test statistic, we use an unbiased estimate of the maximum mean discrepancy, which is the centerpiece of the nonparametric kernel two-sample test proposed by Gretton et al. (2012). We compare to the adversarial nets framework introduced by Goodfellow et al. (2014), in which learning is a two-player game between a generator network and an adversarial discriminator network, both trained to outwit the other. From this perspective, the MMD statistic plays the role of the discriminator. In addition to empirical comparisons, we prove bounds on the generalization error incurred by optimizing the empirical MMD.},
author = {Dziugaite, G. K. and Roy, D. M. and Ghahramani, Z.},
booktitle = {Uncertainty in Artificial Intelligence},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Kernel Embeddings/(2015, Dziugaite) Training generative neural networks via Maximum mean discrepancy optimization.pdf:pdf},
title = {{Training generative neural networks via maximum mean discrepancy optimization}},
year = {2015}
}




@inproceedings{Ranganath2016,
author = {Ranganath, R. and Altosaar, J. and Tran, D. and Blei, D. M.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Variatonal Inference/(2016, Ranganath {\&} Altosaar {\&} Tran {\&} Blei) Operator Variational Inference.pdf:pdf},
title = {{Operator Variational Inference}},
year = {2016}
}


@book{Meyn1993,
abstract = {These lecture notes are a self contained treatment of the solution of equilibria equations and ergodicity for "psi-irreducible Markov chains". For a bit more depth, and in particular the treatment of general state spaces, see 12 (available at black.csl.uiuc.edu/{\~{}}meyn), or see 11.},
author = {Meyn, S. P. and Tweedie, R. L.},
booktitle = {Springer-Verlag},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/MCMC/(2005, Meyn {\&} Tweedie) Markov Chains and Stochastic Volatility.pdf:pdf},
title = {{Markov Chains and Stochastic Stability}},
year = {1993}
}


@book{Villani2009,
author = {Villani, C.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Transport of Measure/(2008, Villani) Optimal transport - old and new.pdf:pdf},
publisher = {Springer},
title = {{Optimal transport. Old and new}},
year = {2009}
}



@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
author = {Arjovsky, M. and Chintala, S. and Bottou, L.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Variatonal Inference/(2017, Arjovsky {\&} Chintala {\&} Bottou) Wasserstein GAN.pdf:pdf},
title = {{Wasserstein GAN}},
year = {2017}
}




@inproceedings{Gorham2015,
author = {Gorham, J. and Mackey, L.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorham, Mackey - 2015 - Measuring Sample Quality with Stein's Method.pdf:pdf},
pages = {226--234},
title = {{Measuring sample quality with Stein's method}},
year = {2015}
}


@article{Kullback1951,
author = {Kullback, S. and Leibler, R. A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(1951, Kullback {\&} Leibler) On information and sufficiency.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {1},
pages = {79--86},
title = {{On Information and Sufficiency}},
volume = {22},
year = {1951}
}



@book{Frankel2012,
abstract = {applicability for this approach.},
author = {Frankel, T.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(2012, Frankel) The Geometry of Physics - 3rd edition.pdf:pdf},
keywords = {icle},
publisher = {Cambridge University Press},
title = {{The Geometry of Physics}},
year = {2012}
}

@book{Arnold1989,
author = {Arnold, V.},
publisher = {Springer-Verlag},
title = {{Mathematical methods of classical mechanics}},
year = {1989}
}



@book{Barndorff-Nielsen1978,
abstract = {Wiley, New York},
author = {Barndorff-Nielsen, O.},
booktitle = {Information and Exponential Families in Statistical Theory},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(1978, Barndorff-Nielsen) Information and Exponential Families in Statistical Theory.pdf:pdf},
publisher = {Wiley},
title = {{Information and Exponential Families in Statistical Theory}},
year = {1978}
}



@book{Kass1997,
abstract = {Differential geometry provides an aesthetically appealing and often revealing view of statistical inference. Beginning with an elementary treatment of one-parameter statistical models and ending with an overview of recent developments, this is the first book to provide an introduction to the subject that is largely accessible to readers not already familiar with differential geometry. It also gives a streamlined entry into the field to readers with richer mathematical backgrounds. Much space is devoted to curved exponential families, which are of interest not only because they may be studied geometrically but also because they are analytically convenient, so that results may be derived rigorously. In addition, several appendices provide useful mathematical material on basic concepts in differential geometry. Topics covered include the following: * Basic properties of curved exponential families * Elements of second-order, asymptotic theory * The Fisher-Efron-Amari theory of information loss and recovery * Jeffreys-Rao information-metric Riemannian geometry * Curvature measures of nonlinearity * Geometrically motivated diagnostics for exponential family regression * Geometrical theory of divergence functions * A classification of and introduction to additional work in the field},
author = {Kass, R. E. and Vos, P. W.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(1997, Kass {\&} Vos) Geometrical Foundations of Asymptotic Inference.pdf:pdf},
pages = {355},
title = {{Geometric Foundations of Asymptotic Inference}},
year = {1997}
}



@article{Amari1995,
author = {Amari, S.-I.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/(1992, Amari) Information geometry of the EM and em algorithms for neural networks.pdf:pdf},
journal = {Neural Networks},
number = {9},
pages = {1379--1408},
title = {{Information Geometry of Em and em Algorithms for Neural Networks}},
volume = {8},
year = {1995}
}



@article{Hyvarinen2007,
abstract = {Many probabilistic models are only defined up to a normalization constant. This makes maximum likelihood estimation of the model parameters very difficult. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Previously, a method called score matching was proposed for computationally efficient yet (locally) consistent estimation of such models. The basic form of score matching is valid, however, only for models which define a differentiable probability density function over Rn. Therefore, some extensions of the framework are proposed. First, a related method for binary variables is proposed. Second, it is shown how to estimate non-normalized models defined in the non-negative real domain, i.e. R+n. As a further result, it is shown that the score matching estimator can be obtained in closed form for some exponential families. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Hyv{\"{a}}rinen, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2007, Hyvarinen) Some extensions of score matching.pdf:pdf},
journal = {Computational Statistics and Data Analysis},
keywords = {Markov Chain Monte Carlo,Non-normalized models,Partition function,Score matching,Statistical estimation},
number = {5},
pages = {2499--2512},
title = {{Some extensions of score matching}},
volume = {51},
year = {2007}
}



@article{Hyvarinen2006,
abstract = {One often wants to estimate statisticalmodels where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlomethods, or approximations of the normalization constant. Here,we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very difficult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simplifies to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete filter set for natural image data.},
author = {Hyv{\"{a}}rinen, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2005, Hyvarinen) Estimation of non-normalized statistical models by score matching.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {contrastive divergence,markov chain,monte carlo,non-normalized densities,pseudo-likelihood,statistical estimation},
pages = {695--708},
title = {{Estimation of non-normalized statistical models by score matching}},
volume = {6},
year = {2006}
}


@inproceedings{Csiszar1984,
author = {Csisz{\'{a}}r, I. and Tusn{\'{a}}dy, G.},
booktitle = {Statistics {\&} Decisions},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/(1984, Csizar {\&} Tusnady) Information geometry and alternating minimization procedures.pdf:pdf},
number = {1},
pages = {205--237},
title = {{Information geometry and alternating minimization procedures}},
year = {1984}
}


@article{Rao45statmanifold,
    abstract = {{The author is concerned with results for finite samples, some of which are familiar as asymptotic formulas. (A) The variance of an unbiased estimate of Î¸ is at least 1/I, where I is R. A. Fisher's amount of information. (B) If a sufficient statistic for Î¸ and an unbiased estimate for Î¸ exist, then among all unbiased estimates there is one with minimum variance, which is a function of the sufficient statistic. (C) If the distribution having the sufficient statistic has the usual analytic form, there is a function of Î¸ which has an estimate satisfying (B). These results depend on differentiation under the integral sign, and are extended to several variables. In particular, if an unbiased estimate of one parameter has minimum variance, then it is uncorrelated with any statistic whose expectation depends solely on other parameters.
   The Riemannian metric ds2=gijdÎ¸idÎ¸j, where
gij=E[(1Ï†âˆ‚Ï†âˆ‚Î¸i)(1Ï†âˆ‚Ï†âˆ‚Î¸j)],
and Ï† is the probability density function of the sample, is introduced into the parameter space, generating the distance proposed by Bhattacharyya [same Bull. 35, 99--109 (1943); MR0010358 (6,7b)]. The distance between two normal populations is calculated and a large-sample test for the equality of all parameters of two populations is proposed.
Reviewed by J. W. Tukey}},
    author = {Rao, C. R.},
    journal = {Bull. Calcutta Math. Soc.},
    keywords = {gt\_mafics, gt\_statmanifold, gts\_statmanifold},
    pages = {81--91},
    title = {{Information and the accuracy attainable in the estimation of statistical parameters}},
    volume = {37},
    year = {1945}
}


@article{Barndorff-Nielsen1986,
abstract = {There has been increasing emphasis recently on the use of differential geometry in statistical theory, especially in asymptotic theory. In this paper a brief relatively nontechnical account is given of some relevant ideas in differential geometry. Some of the early work applying differential geometry in statistics is then sketched. Recent developments are outlined and finally directions of current and possible future work are indicated. /// R{\'{e}}cemment on a appuy{\'{e}} sur l'usage de g{\'{e}}ometrie diff{\'{e}}rentielle en th{\'{e}}orie statistique, particuli{\`{e}}rement en th{\'{e}}orie asymptotique. Dans cet article on d{\'{e}}crit, relativement court et non-technique, quelques id{\'{e}}es de la g{\'{e}}om{\'{e}}trie diff{\'{e}}rentielle qui ont rapport {\`{a}} la statistique. Une partie du travail ant{\'{e}}rieur est ensuite esquiss{\'{e}}e. Le contour des d{\'{e}}veloppements r{\'{e}}cents est dessin{\'{e}} et enfin les directions du travail courant et {\'{e}}ventuel {\`{a}} l'avenir sont indiqu{\'{e}}es.},
author = {Barndorff-Nielsen, O. E. and Cox, D. R. and Reid, N.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(1986, Barndorff-Nielsen) The role of differential geometry in statistical theory.pdf:pdf},
isbn = {03067734},
issn = {03067734},
journal = {I. Stat. Rev.},
keywords = {gt{\_}mafics,gt{\_}statmanifold,gts{\_}statmanifold},
number = {1},
pages = {83--96},
title = {{The Role of Differential Geometry in Statistical Theory}},
volume = {54},
year = {1986}
}



@article{Carter2007,
author = {Carter, K. M. and Raich, R. and Hero, A. O.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/(2007, Carter) Learning on statistical manifolds for clustering and visualization.pdf:pdf},
journal = {Proceedings of 45th Annual Allerton Conference on Communication, Control, and Computing},
title = {{Learning on statistical manifolds for clustering and visualization}},
year = {2007}
}



@article{Marti2016,
abstract = {We present a methodology for clustering N objects which are described by multivariate time series, i.e. several sequences of real-valued random variables. This clustering methodology leverages copulas which are distributions encoding the dependence structure between several random variables. To take fully into account the dependence information while clustering, we need a distance between copulas. In this work, we compare renowned distances between distributions: the Fisher-Rao geodesic distance, related divergences and optimal transport, and discuss their advantages and disadvantages. Applications of such methodology can be found in the clustering of financial assets. A tutorial, experiments and implementation for reproducible research can be found at www.datagrapple.com/Tech.},
author = {Marti, G. and Andler, S. and Nielsen, F. and Donnat, P.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/(2016, Marti) Optimal transport vs Fisher-rao distance between copulas for clustering multivariate time series.pdf:pdf},
journal = {IEEE Workshop on Statistical Signal Processing Proceedings},
keywords = {Fisher-Rao geodesic distance,Wasserstein distances,clustering,copulas,divergences,multivariate time series,optimal transport},
number = {2},
pages = {2--6},
title = {{Optimal transport vs. Fisher-Rao distance between copulas for clustering multivariate time series}},
volume = {2016-Augus},
year = {2016}
}



@article{Marti2015,
abstract = {This paper presents a new methodology for clustering multivariate time series leveraging optimal transport between copulas. Copulas are used to encode both (i) intra-dependence of a multivariate time series, and (ii) inter-dependence between two time series. Then, optimal copula transport allows us to define two distances between multivariate time series: (i) one for measuring intra-dependence dissimilarity, (ii) another one for measuring inter-dependence dissimilarity based on a new multivariate dependence coefficient which is robust to noise, deterministic, and which can target specified dependencies.},
author = {Marti, G. and Nielsen, F. and Donnat, P.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Transport of Measure/(2016, Marti) Optimal copula transport for clustering multivariate time series.pdf:pdf},
journal = {arXiv:1509.08144},
title = {{Optimal Copula Transport for Clustering Multivariate Time Series}},
year = {2015}
}


@article{Sriperumbudur2016,
abstract = {Given random samples drawn i.i.d. from a probability measure {\$}\backslashmathbb{\{}P{\}}{\$} (defined on say, {\$}\backslashmathbb{\{}R{\}}{\^{}}d{\$}), it is well-known that the empirical estimator is an optimal estimator of {\$}\backslashmathbb{\{}P{\}}{\$} in weak topology but not even a consistent estimator of its density (if it exists) in the strong topology (induced by the total variation distance). On the other hand, various popular density estimators such as kernel and wavelet density estimators are optimal in the strong topology in the sense of achieving the minimax rate over all estimators for a Sobolev ball of densities. Recently, it has been shown in a series of papers by Gin$\backslash$'{\{}e{\}} and Nickl that these density estimators on {\$}\backslashmathbb{\{}R{\}}{\$} that are optimal in strong topology are also optimal in {\$}\backslashVert \backslashcdot\backslashVert{\_}\backslashmathcal{\{}F{\}}{\$} for certain choices of {\$}\backslashmathcal{\{}F{\}}{\$} such that {\$}\backslashVert\backslashcdot\backslashVert{\_}\backslashmathcal{\{}F{\}}{\$} metrizes the weak topology, where {\$}\backslashVert\backslashmathbb{\{}P{\}}\backslashVert{\_}\backslashmathcal{\{}F{\}}:=\backslashsup\backslash{\{}\backslashint f\backslash,d\backslashmathbb{\{}P{\}}:f\backslashin\backslashmathcal{\{}F{\}}\backslash{\}}{\$}. In this paper, we investigate this problem of optimal estimation in weak and strong topologies by choosing {\$}\backslashmathcal{\{}F{\}}{\$} to be a unit ball in a reproducing kernel Hilbert space (say {\$}\backslashmathcal{\{}F{\}}{\_}H{\$} defined over {\$}\backslashmathbb{\{}R{\}}{\^{}}d{\$}), where this choice is both of theoretical and computational interest. Under some mild conditions on the reproducing kernel, we show that {\$}\backslashVert\backslashcdot\backslashVert{\_}{\{}\backslashmathcal{\{}F{\}}{\_}H{\}}{\$} metrizes the weak topology and the kernel density estimator (with {\$}L{\^{}}1{\$} optimal bandwidth) estimates {\$}\backslashmathbb{\{}P{\}}{\$} at dimension independent optimal rate of {\$}n{\^{}}{\{}-1/2{\}}{\$} in {\$}\backslashVert\backslashcdot\backslashVert{\_}{\{}\backslashmathcal{\{}F{\}}{\_}H{\}}{\$} along with providing a uniform central limit theorem for the kernel density estimator.},
author = {Sriperumbudur, B. K.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/Integral probability metrics/(2016, Sriperumbudur) On the optimal estimation of probability measures in weak and strong topologies.pdf:pdf},
journal = {Bernoulli},
keywords = {adaptive estimation,bounded lipschitz metric,estimator,exponential inequality,kernel density,rademacher chaos,reproducing kernel hilbert space,smoothed empirical processes,total,two-sample test,u-processes,uniform central limit theorem,variation distance},
number = {3},
pages = {1839--1893},
title = {{On the optimal estimation of probability measures in weak and strong topologies}},
volume = {22},
year = {2016}
}

@article{Mijatovic2015,
abstract = {This paper defines an approximation scheme for a solution of the Poisson equation of a geometrically ergodic Metropolis-Hastings chain {\$}\backslashPhi{\$}. The approximations give rise to a natural sequence of control variates for the ergodic average {\$}S{\_}k(F)=(1/k)\backslashsum{\_}{\{}i=1{\}}{\^{}}{\{}k{\}} F(\backslashPhi{\_}i){\$}, where {\$}F{\$} is the force function in the Poisson equation. The main result of the paper shows that the sequence of the asymptotic variances (in the CLTs for the control-variate estimators) converges to zero. We apply the algorithm to geometrically and non-geometrically ergodic chains and present numerical evidence for a significant variance reduction in both cases.},
archivePrefix = {arXiv},
arxivId = {1511.07464},
author = {Mijatovic, A. and Vogrinc, J.},
eprint = {1511.07464},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/Control variates/(2015, Mijatovic {\&} Vogrinc) On the poisson equation for metropolis-hastings chains.pdf:pdf},
keywords = {and phrases,and useful conversations,asymptotic variance,central limit theorem,chains,for suggesting the problem,imperial college,markov chain monte carlo,metropolis-hastings algo-,out,poisson equation for markov,rithm,the work was carried,variance reduction,we thank petros dellaportas,weak approximation,while am was at},
pages = {34},
title = {{On the Poisson equation for Metropolis-Hastings chains}},
url = {http://arxiv.org/abs/1511.07464},
year = {2015}
}

@article{Sriperumbudur2009,
author = {Sriperumbudur, B. K. and Gretton, A. and Fukumizu, K. and Sch{\"{o}}lkopf, B. and Lanckriet, G.},
journal = {Journal of Machine Learning Research},
pages = {1517--1561},
title = {{Hilbert space embeddings and metrics on probability measures}},
volume = {11},
year = {2010}
}

@inproceedings{Gorham2017,
author = {Gorham, J. and Mackey, L.},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorham, Mackey - 2017 - Measuring Sample Quality with Kernels.pdf:pdf},
pages = {1292--1301},
title = {{Measuring sample quality with kernels}},
year = {2017}
}



@article{Takatsu2011,
abstract = {The space of Gaussian measures on a Euclidean space is geodesically convex in the {\$}L{\^{}}2{\$}-Wasserstein space. This space is a finite dimensional manifold since Gaussian measures are parameterized by means and covariance matrices. By restricting to the space of Gaussian measures inside the {\$}L{\^{}}2{\$}-Wasserstein space, we manage to provide detailed descriptions of the {\$}L{\^{}}2{\$}-Wasserstein geometry from a Riemannian geometric viewpoint. We first construct a Riemannian metric which induces the {\$}L{\^{}}2{\$}-Wasserstein distance. Then we obtain a formula for the sectional curvatures of the space of Gaussian measures, which is written out in terms of the eigenvalues of the covariance matrix.},
author = {Takatsu, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/(2011, Takatsu) Wasserstein geometry of Gaussian Measures.pdf:pdf},
journal = {Osaka Journal of Mathematics},
keywords = {alexandrov space,and phrases,for the,gaussian measures,of the japan society,promotion of science for,supported by research fellowships,this work was partially,wasserstein space,young scientists},
number = {4},
pages = {1005--1026},
title = {{Wasserstein geometry of Gaussian measures}},
volume = {48},
year = {2011}
}




@incollection{Stathopoulos2011,
author = {Stathopoulos, Vassilios and Girolami, Mark},
booktitle = {Mixtures: Estimation and Applications},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2011, Strathopoulos {\&} Girolami) Manifold MCMC for mixtures.pdf:pdf},
keywords = {Application of Riemann manifold Metropolis adjuste,Finite Gaussian mixture models,Gibbs sampler,Gibbs sampler for mixtures of univariate Gaussians,MCMC methods,Manifold MCMC for mixtures,Manifold MCMC for mixtures of univariate Gaussians,Markov chain Monte Carlo Methods,Mixture models,One problem associated with inefficiency of Gibbs,as the Metropolis adjusted Langevin algorithm (MAL,describing a wide variety of random phenomena - be,reparameterisation of mixture model,simulating individual or subsets of variables - fr},
pages = {255--276},
title = {{Manifold MCMC for mixtures}},
year = {2011}
}




@article{Roberts1998,
abstract = {We consider the optimal scaling problem for proposal distributions in Hastingsâ€“Metropolis algorithms derived from Langevin diffusions. We prove an asymptotic diffusion limit theorem and show that the relative efficiency of the algorithm can be characterized by its overall acceptance rate, independently of the target distribution. The asymptotically optimal acceptance rate is 0.574. We show that, as a function of dimension n, the complexity of the algorithm is O(n1/3), which compares favourably with the O(n) complexity of random walk Metropolis algorithms. We illustrate this comparison with some example simulations.},
author = {Roberts, G. O. and Rosenthal, J. S.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/MCMC/(1998, Roberts {\&} Rosenthal) Optimal Scaling of Discrete Approximations to Langevin Diffusions.pdf:pdf},
isbn = {1467-9868},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {1},
pages = {255--268},
title = {{Optimal scaling of discrete approximations to Langevin diffusions.}},
volume = {60},
year = {1998}
}



@book{Leimkuhler2004,
author = {Leimkuhler, B. and Reich, S.},
edition = {Cambirdge },
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/Hamiltonian Dynamics/(2004, Leimkuhler {\&} Reich) Simulating Hamiltonian dynamics.pdf:pdf},
publisher = {Cambridge University Press},
title = {{Simulating Hamiltonian Dynamics}},
year = {2004}
}


@article{Lan2016,
abstract = {The Bayesian approach to Inverse Problems relies predominantly on Markov Chain Monte Carlo methods for posterior inference. The typical nonlinear concentration of posterior measure observed in many such Inverse Problems presents severe challenges to existing simulation based inference methods. Motivated by these challenges the exploitation of local geometric information in the form of covariant gradients, metric tensors, Levi-Civita connections, and local geodesic flows, have been introduced to more effectively locally explore the configuration space of the posterior measure. However, obtaining such geometric quantities usually requires extensive computational effort and despite their effectiveness affect the applicability of these geometrically-based Monte Carlo methods. In this paper we explore one way to address this issue by the construction of an emulator of the model from which all geometric objects can be obtained in a much more computationally feasible manner. The main concept is to approximate the geometric quantities using a Gaussian Process emulator which is conditioned on a carefully chosen design set of configuration points, which also determines the quality of the emulator. To this end we propose the use of statistical experiment design methods to refine a potentially arbitrarily initialized design online without destroying the convergence of the resulting Markov chain to the desired invariant measure. The practical examples considered in this paper provide a demonstration of the significant improvement possible in terms of computational loading suggesting this is a promising avenue of further development.},
author = {Lan, S. and Bui-Thanh, T. and Christie, M. and Girolami, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lan et al. - 2016 - Emulation of Higher-Order Tensors in Manifold Monte Carlo Methods for Bayesian Inverse Problems.pdf:pdf},
journal = {Journal of Computational Physics},
keywords = {bayesian inverse problems,gaussian,hamiltonian monte carlo,markov chain monte carlo,process emulation,uncertainty quantification},
mendeley-groups = {OxWaSP mini-project 2 - scalable kernel method for BQ},
pages = {81--101},
title = {{Emulation of Higher-Order Tensors in Manifold Monte Carlo Methods for Bayesian Inverse Problems}},
volume = {308},
year = {2016}
}



@article{Das2010,
abstract = {The Fisher information matrix (FIM) is a critical quantity in several aspects of mathematical modeling, including input selection and confidence region calculation. Analytical determination of the FIM in a general setting, especially in nonlinear models, may be difficult or almost impossible due to intractable modeling requirements or/and intractable high-dimensional integration. To circumvent these difficulties, a Monte Carlo simulation based technique, known as resampling algorithm, is usually recommended, in which values of the log-likelihood function or its exact stochastic gradient computed based on a set of pseudo-data vectors are used. The current work proposes an extension of this resampling algorithm in order to enhance the statistical qualities of the estimator of the FIM. This modified resampling algorithm is useful in those cases when some elements of the FIM are analytically known from prior information and the rest of the elements are unknown. The estimator of the FIM resulting from the proposed algorithm simultaneously preserves the analytically known elements and reduces variances of the estimators of the unknown elements. This is achieved by capitalizing on the information contained in the known elements. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Das, Sonjoy and Spall, James C. and Ghanem, Roger},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Spall, Ghanem - 2010 - Efficient Monte Carlo computation of Fisher information matrix using prior information.pdf:pdf},
journal = {Computational Statistics and Data Analysis},
mendeley-groups = {OxWaSP modules/module 5 - Bayesian Statistics},
number = {2},
pages = {272--289},
title = {{Efficient Monte Carlo computation of Fisher information matrix using prior information}},
volume = {54},
year = {2010}
}




@article{Spall2005,
author = {Spall, J. C.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/Approximate metric tensors/(2005, Spall) Monte Carlo Computation of the Fisher Information Matrix in Nonstandard Settings.pdf:pdf},
journal = {Journal of Computational and Graphical Statistics},
keywords = {cramtr-,monte carlo,rao bound,simultaneous perturbation,system identification},
number = {4},
pages = {889--909},
title = {{Monte Carlo Computation of the Fisher Information Matrix in Nonstandard Settings}},
volume = {14},
year = {2005}
}



@article{Grosse2016,
abstract = {Second-order optimization methods such as natural gradient descent have the potential to speed up training of neural networks by correcting for the curvature of the loss function. Unfortunately, the exact natural gradient is impractical to compute for large models, and most approximations either require an expensive iterative procedure or make crude approximations to the curvature. We present Kronecker Factors for Convolution (KFC), a tractable approximation to the Fisher matrix for convolutional networks based on a structured probabilistic model for the distribution over backpropagated derivatives. Similarly to the recently proposed Kronecker-Factored Approximate Curvature (K-FAC), each block of the approximate Fisher matrix decomposes as the Kronecker product of small matrices, allowing for efficient inversion. KFC captures important curvature information while still yielding comparably efficient updates to stochastic gradient descent (SGD). We show that the updates are invariant to commonly used reparameterizations, such as centering of the activations. In our experiments, approximate natural gradient descent with KFC was able to train convolutional networks several times faster than carefully tuned SGD. Furthermore, it was able to train the networks in 10-20 times fewer iterations than SGD, suggesting its potential applicability in a distributed setting.},
archivePrefix = {arXiv},
arxivId = {1602.01407},
author = {Grosse, R. and Martens, J.},
eprint = {1602.01407},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(2016, Grosse) A kronecker-factored approximate Fisher matrix for convolution layers.pdf:pdf},
isbn = {9781510829008},
journal = {International Conference on Machine Learning},
pages = {1--34},
title = {{A Kronecker-factored approximate Fisher matrix for convolution layers}},
url = {http://arxiv.org/abs/1602.01407},
year = {2016}
}


@article{Martens2014,
abstract = {Natural gradient descent is an optimization method traditionally motivated from the perspective of information geometry, and works well for many applications as an alternative to stochastic gradient descent. In this paper we critically analyze this method and its properties, and show how it can be viewed as a type of approximate 2nd-order optimization method, where the Fisher information matrix used to compute the natural gradient direction can be viewed as an approximation of the Hessian. This perspective turns out to have significant implications for how to design a practical and robust version of the method. Among our various other contributions is a thorough analysis of the convergence speed of natural gradient descent and more general stochastic methods, a critical examination of the oft-used "empirical" approximation of the Fisher matrix, and an analysis of the (approximate) parameterization invariance property possessed by the method, which we show still holds for certain other choices of the curvature matrix, but notably not the Hessian.},
author = {Martens, J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(2016, Martens) New insights and perspectives on the natural gradient method.pdf:pdf},
journal = {arXiv:1412.1193},
title = {{New insights and perspectives on the natural gradient method}},
year = {2014}
}



@article{Calderhead2012,
author = {Calderhead, B. and Sustik, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2011, Calderhead) Sparse-approximate-manifolds-for-differential-geometric-mcmc.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances in Neural Information Processing},
title = {{Sparse approximate manifolds for differential geometric MCMC}},
year = {2012}
}



@article{OHagan1991,
author = {O'Hagan, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Mini-projects/Research on mini-projects/probabilistic numerics - Girolami {\&} Osborne/Bayesian Quadrature/(1991, O'Hagan) Bayes-Hermite quadrature.pdf:pdf},
journal = {Journal of Statistical Planning and Inference},
keywords = {bayesian},
mendeley-groups = {OxWaSP mini-project 1 - convergence for SBQ},
pages = {245--260},
title = {{Bayesâ€“Hermite quadrature}},
volume = {29},
year = {1991}
}

@article{Cockayne2017,
abstract = {This paper develops meshless methods for probabilistically describing discretisation error in the numerical solution of partial differential equations. This construction enables the solution of Bayesian inverse problems while accounting for the impact of the discretisation of the forward problem. In particular, this drives statistical inferences to be more conservative in the presence of significant solver error. Theoretical results are presented describing rates of convergence for the posteriors in both the forward and inverse problems. This method is tested on a challenging inverse problem with a nonlinear forward model.},
author = {Cockayne, J. and Oates, C. and Sullivan, T. and Girolami, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probabilistic Numerics/(2017, Cockayne) Bayesian Probabilistic Numerical methods.pdf:pdf},
journal = {arXiv:1701.04006},
title = {{Bayesian Probabilistic Numerical Methods}},
year = {2017}
}




@article{Diaconis1988,
author = {Diaconis, P.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Mini-projects/Research on mini-projects/probabilistic numerics - Girolami {\&} Osborne/early probabilistic numerics/(1988, Diaconis) Bayesian numerical analysis.pdf:pdf},
journal = {Statistical Decision Theory and Related Topics IV},
mendeley-groups = {OxWaSP mini-project 1 - convergence for SBQ},
pages = {163--175},
title = {{Bayesian Numerical Analysis}},
year = {1988}
}



@book{Traub1983,
author = {Traub, J. F. and Wasilkowski, G. W. and Wozniakowski, H.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Information Complexity/(1981, Traub) Information uncertainty complexity.pdf:pdf},
publisher = {Addison-Wesley},
title = {{Information, Uncertainty, Complexity}},
year = {1983}
}


@book{Ritter2000,
author = {Ritter, K.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Information Complexity/(2000, Ritter) Average-Case Analysis of Numerical Problems.pdf:pdf},
issn = {0075-8434},
pmid = {13771357},
publisher = {Springer},
title = {{Average-case analysis of numerical problems}},
year = {2000}
}




@article{Oates2016CF2,
author = {Oates, C. J. and Cockayne, J. and Briol, F.-X. and Girolami, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oates et al. - 2016 - Convergence Rates for a Class of Estimators Based on Stein's Identity.pdf:pdf},
journal = {arXiv preprint arXiv:1603.03220},
keywords = {asymptotics,control functionals,reproducing kernel,scattered data,variance},
title = {{Convergence Rates for a Class of Estimators Based on Stein's Identity}},
year = {2016}
}



@misc{Amari1987,
author = {Amari, S.-I.},
edition = {Lecture No},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(1985, Amari) Differential-Geometrical Methods in Statistics.pdf:pdf},
publisher = {Springer-Verlag},
title = {{Differential Geometrical Methods in Statistics}},
year = {1987}
}


@book{Murray1993,
author = {Murray, M. K. and Rice, J. W.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(1993, Murray) Differential Geometry and Statistics.pdf:pdf},
publisher = {Springer Science+Business Media},
title = {{Differential Geometry and Statistics}},
year = {1993}
}


@article{Roberts1998,
abstract = {We consider the optimal scaling problem for proposal distributions in Hastingsâ€“Metropolis algorithms derived from Langevin diffusions. We prove an asymptotic diffusion limit theorem and show that the relative efficiency of the algorithm can be characterized by its overall acceptance rate, independently of the target distribution. The asymptotically optimal acceptance rate is 0.574. We show that, as a function of dimension n, the complexity of the algorithm is O(n1/3), which compares favourably with the O(n) complexity of random walk Metropolis algorithms. We illustrate this comparison with some example simulations.},
author = {Roberts, G. O. and Rosenthal, J. S.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/MCMC/(1998, Roberts {\&} Rosenthal) Optimal Scaling of Discrete Approximations to Langevin Diffusions.pdf:pdf},
isbn = {1467-9868},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {1},
pages = {255--268},
title = {{Optimal scaling of discrete approximations to Langevin diffusions.}},
volume = {60},
year = {1998}
}



@article{Beskos2011,
abstract = {The Hybrid Monte Carlo (HMC) algorithm provides a framework for sampling from complex, high-dimensional target distributions. In contrast with standard Markov chain Monte Carlo (MCMC) algorithms, it generates nonlocal, nonsymmetric moves in the state space, alleviating random walk type behaviour for the simulated trajectories. However, similarly to algorithms based on random walk or Langevin proposals, the number of steps required to explore the target distribution typically grows with the dimension of the state space. We define a generalized HMC algorithm which overcomes this problem for target measures arising as finite-dimensional approximations of measures ?? which have density with respect to a Gaussian measure on an infinite-dimensional Hilbert space. The key idea is to construct an MCMC method which is well defined on the Hilbert space itself. We successively address the following issues in the infinite-dimensional setting of a Hilbert space: (i) construction of a probability measure ?? in an enlarged phase space having the target ?? as a marginal, together with a Hamiltonian flow that preserves ??; (ii) development of a suitable geometric numerical integrator for the Hamiltonian flow; and (iii) derivation of an accept/reject rule to ensure preservation of ?? when using the above numerical integrator instead of the actual Hamiltonian flow. Experiments are reported that compare the new algorithm with standard HMC and with a version of the Langevin MCMC method defined on a Hilbert space. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Beskos, A. and Pinski, F. J. and Sanz-Serna, J. M. and Stuart, A. M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2011, Beskos et al) Hybrid Monte Carlo on Hilbert spaces.pdf:pdf},
journal = {Stochastic Processes and their Applications},
number = {10},
pages = {2201--2230},
title = {{Hybrid Monte Carlo on Hilbert spaces}},
volume = {121},
year = {2011}
}



@article{Haario2001,
abstract = {A proper choice of a proposal distribution for Markov chain Monte Carlo methods, for example for the Metropolis-Hastings algorithm, is well known to be a crucial factor for the convergence of the algorithm. In this paper we introduce an adaptive Metropolis (AM) algorithm, where the Gaussian proposal distribution is updated along the process using the full information cumulated so far. Due to the adaptive nature of the process, the AM algorithm is non-Markovian, but we establish here that it has the correct ergodic properties. We also include the results of our numerical tests, which indicate that the AM algorithm competes well with traditional Metropolis-Hastings algorithms, and demonstrate that the AM algorithm is easy to use in practical computation.},
author = {Haario, Heikki and Saksman, Eero and Tamminen, Johanna},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Haario, Saksman, Tamminen - 2001 - An Adaptive Metropolis Algorithm.pdf:pdf},
journal = {Bernoulli},
keywords = {Convergence},
mendeley-groups = {OxWaSP modules/module 1 - Computational Statistics and Statistical Computing},
number = {2},
pages = {223--242},
title = {{An Adaptive Metropolis Algorithm}},
volume = {7},
year = {2001}
}



@article{Andrieu2008,
abstract = {Abstract We review adaptive Markov chain Monte Carlo algorithms ( MCMC ) as a mean to optimise their performance. Using simple toy examples we review their theoretical underpinnings, and in particular show why adaptive MCMC algorithms might fail when ... $\backslash$n},
author = {Andrieu, Christophe and Thoms, Johannes},
doi = {10.1007/s11222-008-9110-y},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrieu, Thoms - 2008 - A tutorial on adaptive MCMC.pdf:pdf},
isbn = {0960-3174},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Adaptive MCMC,Controlled Markov chain,MCMC,Stochastic approximation},
mendeley-groups = {OxWaSP modules/module 4 - Stochastic Simulation},
number = {November},
pages = {343--373},
title = {{A tutorial on adaptive MCMC}},
volume = {18},
year = {2008}
}



@book{Robert2004,
author = {Robert, C. and Casella, G.},
publisher = {Springer},
title = {{Monte Carlo Statistical Methods}},
year = {2004}
}

@incollection{Neal2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard to compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories form taking much computation time.},
author = {Neal, R. M.},
booktitle = {Handbook of Markov Chain Monte Carlo},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Neal - 2011 - MCMC using Hamiltonian dynamics.pdf:pdf},
keywords = {hamiltonian dynamics,mcmc},
mendeley-groups = {OxWaSP mini-project 2 - scalable kernel method for BQ},
pages = {113--162},
title = {{MCMC using Hamiltonian dynamics}},
year = {2011}
}


@book{Meyn1993,
abstract = {These lecture notes are a self contained treatment of the solution of equilibria equations and ergodicity for "psi-irreducible Markov chains". For a bit more depth, and in particular the treatment of general state spaces, see 12 (available at black.csl.uiuc.edu/{\~{}}meyn), or see 11.},
author = {Meyn, S. P. and Tweedie, R. L.},
booktitle = {Springer-Verlag},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/MCMC/(2005, Meyn {\&} Tweedie) Markov Chains and Stochastic Volatility.pdf:pdf},
title = {{Markov Chains and Stochastic Stability}},
year = {1993}
}

@article{Banerjee2005,
abstract = {A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we pro-pose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based paramet-ric clustering approaches, such as classical kmeans, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical kmeans algorithm, while gener-alizing the method to a large class of clustering loss functions. This is achieved by first posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically de-creases this loss. In addition, we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternative interpretation of an efficient EM scheme for learning mix-tures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Breg-man clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.},
author = {Banerjee, A. and Merugu, S. and Dhillon, I. S. and Ghosh, J.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/Information Geometry/(2005, Banerjee) Clustering with Bregman Divergences.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Bregman divergences,Bregman information,clustering,expectation maxi-mization,exponential families,information theory},
pages = {1705--1749},
title = {{Clustering with Bregman Divergences}},
volume = {6},
year = {2005}
}


@article{Amari1998,
abstract = {When a parameter space has a certain underlying structure, the ordinary gradient of a function does not represent its steepest direction, but the natural gradient does. Information geometry is used for calculating the natural gradients in the parameter space of perceptrons, the space of matrices (for blind source separation), and the space of linear dynamical systems (for blind source deconvolution). The dynamical behavior of natural gradient online learning is analyzed and is proved to be Fisher efficient, implying that it has asymptotically the same performance as the optimal batch estimation of parameters. This suggests that the plateau phenomenon, which appears in the backpropagation learning algorithm of multilayer perceptrons, might disappear or might not be so serious when the natural gradient is used. An adaptive method of updating the learning rate is proposed and analyzed.},
author = {Amari, S.-I.},
journal = {Neural Computation},
number = {2},
pages = {251--276},
title = {{Natural gradient works efficiently in learning}},
volume = {10},
year = {1998}
}




@article{Karakida2016,
abstract = {Shape-selective neurons in inferotemporal cortex show adap- tation if the same shape stimulus is shown repeatedly. Recent electro- physiological experiments have provided critical data that constrain pos- sible underlying neural mechanisms. We propose a neural model that accounts in a unifying manner for a number of these critical observations. The reproduction of the experimental phenomenology seems to require a combination of input fatigue and firing rate fatigue mechanisms, and the adaptive processes need to be largely independent of the duration of the adapting stimulus. The proposed model realizes these constraints by combining a set of physiologically-inspired mechanisms.},
author = {Karakida, R. and Okada, M. and Amari, S.-I.},
journal = {Artificial Neural Networks and Machine Learning - ICANN},
title = {{Adaptive natural gradient learning algorithms for unnormalized statistical models}},
year = {2016}
}



@inproceedings{Chwialkowski2016,
abstract = {We propose a nonparametric statistical test for goodness-of-fit: given a set of samples, the test determines how likely it is that these were generated from a target density function. The measure of goodness-of-fit is a divergence constructed via Stein's method using functions from a Reproducing Kernel Hilbert Space. Our test statistic is based on an empirical estimate of this divergence, taking the form of a V-statistic in terms of the log gradients of the target density and the kernel. We derive a statistical test, both for i.i.d. and non-i.i.d. samples, where we estimate the null distribution quantiles using a wild bootstrap procedure. We apply our test to quantifying convergence of approximate Markov Chain Monte Carlo methods, statistical model criticism, and evaluating quality of fit vs model complexity in nonparametric density estimation.},
author = {Chwialkowski, K. and Strathmann, H. and Gretton, Arthur},
booktitle = {International Conference on Machine Learning},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Hypothesis Testing/(2016, Chwialkowski {\&} Strathmann {\&} Gretton) A kernel test of goodness of fit.pdf:pdf},
pages = {2606--2615},
title = {{A kernel test of goodness of fit}},
year = {2016}
}

@inproceedings{Liu2016testing,
author = {Liu, Q. and Lee, J. and Jordan, M.},
booktitle = {Proceedings of the International Conference on Machine Learning},
pages = {276--284},
title = {{A kernelized Stein discrepancy for goodness-of-fit tests}},
year = {2016}
}




@book{Amari2016,
author = {Amari, S.-I.},
booktitle = {Applied Mathematical Sciences},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Geometry/(2016, Amari) Information Geometry and its applications.pdf:pdf},

publisher = {Springer},
title = {{Information Geometry and Its Applications}},
volume = {194},
year = {2016}
}

@book{Berlinet2004,
address = {New York},
author = {Berlinet, A. and Thomas-Agnan, C.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Mini-projects/Research on mini-projects/probabilistic numerics - Girolami {\&} Osborne/Kernel methods {\&} Functional Analysis/(2004, Berlinet {\&} Thomas-Agnan) RKHS in Probability and Statistics.pdf:pdf},
mendeley-groups = {OxWaSP mini-project 1 - convergence for SBQ},
publisher = {Springer Science+Business Media},
title = {{Reproducing Kernel Hilbert Spaces in Probability and Statistics}},
year = {2004}
}



@book{Dick2010,
author = {Dick, J. and Pillichshammer, F.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Mini-projects/Research on mini-projects/probabilistic numerics - Girolami {\&} Osborne/QMC/(2013, Dick {\&} Pillichshammer) Digital Nets and Sequences.pdf:pdf},
mendeley-groups = {OxWaSP mini-project 1 - convergence for SBQ},
publisher = {Cambridge University Press},
title = {{Digital Nets and Sequences - Discrepancy Theory and Quasi-Monte Carlo Integration}},
year = {2010}
}


@article{Barp2018,
author = {Barp, A. and Briol, F-X. and Kennedy, A. and Girolami, M.},
title = {A review of geometic tools for Markov chain Monte Carlo},
journal = {Annual Reviews of Statistics and It's Applications},
year = {2018},
note = {(to appear)}
}

@article{Livingstone2014,
abstract = {Recent work incorporating geometric ideas in Markov chain Monte Carlo is reviewed in order to highlight these advances and their possible application in a range of domains beyond statistics. A full exposition of Markov chains and their use in Monte Carlo simulation for statistical inference and molecular dynamics is provided, with particular emphasis on methods based on Langevin diffusions. After this, geometric concepts in Markov chain Monte Carlo are introduced. A full derivation of the Langevin diffusion on a Riemannian manifold is given, together with a discussion of the appropriate Riemannian metric choice for different problems. A survey of applications is provided, and some open questions are discussed.},
author = {Livingstone, S. and Girolami, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2014, Livingstone {\&} Girolami) Information-Geometric Markov Chain Monte Carlo methods using diffusions.pdf:pdf},
journal = {Entropy},
keywords = {"information geometry,Bayesian inference,Markov chain Monte Carlo,bayesian inference,computational statistics,diffusions,diffusions",information geometry,machine learning,markov chain monte carlo,statistical mechanics},
number = {6},
pages = {3074--3102},
title = {{Information-Geometric Markov Chain Monte Carlo Methods Using Diffusions}},
volume = {16},
year = {2014}
}

@article{Duane1987,
abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
author = {Duane, S. and Kennedy, A. D. and Pendleton, B. J. and Roweth, D.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Duane et al. - 1987 - Hybrid Monte Carlo.pdf:pdf},
journal = {Physics Letters B},
mendeley-groups = {OxWaSP modules/module 1 - Computational Statistics and Statistical Computing},
number = {2},
pages = {216--222},
title = {{Hybrid Monte Carlo}},
volume = {195},
year = {1987}
}


@article{Byrne2013,
author = {Byrne, S. and Girolami, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2013, Byrne {\&} Girolami) Geodesic Monte Carlo on Embedded Manifolds.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {directional statistics,geodesic,hamiltonian monte carlo,riemannian manifold},
pages = {825--845},
title = {{Geodesic Monte Carlo on Embedded Manifolds}},
volume = {40},
year = {2013}
}


@article{Bui-Thanh2014,
abstract = {We consider the Riemann manifold Hamiltonian Monte Carlo (RMHMC) method for solving statistical inverse problems governed by partial differential equations (PDEs). The power of the RMHMC method is that it exploits the geometric structure induced by the PDE constraints of the underlying inverse problem. Consequently, each RMHMC posterior sample is almost independent from the others providing statistically efficient Markov chain simulation. We reduce the cost of forming the Fisher information matrix by using a low rank approximation via a randomized singular value decomposition technique. This is efficient since a small number of Hessian-vector products are required. The Hessian-vector product in turn requires only two extra PDE solves using the adjoint technique. The results suggest RMHMC as a highly efficient simulation scheme for sampling from PDE induced posterior measures.},
author = {Bui-Thanh, T and Girolami, M},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2011, Bui-Tanh {\&} Girolami) Solving Large-Scale PDE-constrained Bayesian Inverse Problems with Riemannian Manifold Hamiltonian Monte Carlo.pdf:pdf},
issn = {0266-5611},
journal = {Inverse Problems},
number = {11},
pages = {114014},
publisher = {IOP Publishing},
title = {{Solving large-scale PDE-constrained Bayesian inverse problems with Riemann manifold Hamiltonian Monte Carlo}},
volume = {30},
year = {2014}
}


@incollection{Betancourt2013,
abstract = {Markov Chain Monte Carlo (MCMC) is an invaluable means of inference with complicated models, and Hamiltonian Monte Carlo, in particular Riemannian Manifold Hamiltonian Monte Carlo (RMHMC), has demonstrated impressive success in many challenging problems. Current RMHMC implementations, however, rely on a Riemannian metric that limits their application to analytically-convenient models. In this paper I propose a new metric for RMHMC without these limitations and verify its success on a distribution that emulates many hierarchical and latent models.},
author = {Betancourt, M.},
booktitle = {Geometric Science of Information},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2013, Betancourt) A general metric for riemannian manifold Hamiltonian monte carlo.pdf:pdf},
pages = {327--334},
title = {{A general metric for Riemannian manifold Hamiltonian Monte Carlo}},
year = {2013}
}


@article{Cotter2013,
abstract = {Many problems arising in applications result in the need to probe a probability distribution for functions. Examples include Bayesian nonpara-metric statistics and conditioned diffusion processes. Standard MCMC algo-rithms typically become arbitrarily slow under the mesh refinement dictated by nonparametric description of the unknown function. We describe an ap-proach to modifying a whole range of MCMC methods, applicable when-ever the target measure has density with respect to a Gaussian process or Gaussian random field reference measure, which ensures that their speed of convergence is robust under mesh refinement. Gaussian processes or random fields are fields whose marginal distribu-tions, when evaluated at any finite set of N points, are R N -valued Gaussians. The algorithmic approach that we describe is applicable not only when the desired probability measure has density with respect to a Gaussian process or Gaussian random field reference measure, but also to some useful non-Gaussian reference measures constructed through random truncation. In the applications of interest the data is often sparse and the prior specification is an essential part of the overall modelling strategy. These Gaussian-based reference measures are a very flexible modelling tool, finding wide-ranging application. Examples are shown in density estimation, data assimilation in fluid mechanics, subsurface geophysics and image registration. The key design principle is to formulate the MCMC method so that it is, in principle, applicable for functions; this may be achieved by use of propos-als based on carefully chosen time-discretizations of stochastic dynamical systems which exactly preserve the Gaussian reference measure. Taking this approach leads to many new algorithms which can be implemented via minor modification of existing algorithms, yet which show enormous speed-up on a wide range of applied problems.},
author = {Cotter, S. L. and Roberts, G. O. and Stuart, A. and White, D.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/MCMC/(2013, Cotter) MCMC methods for functions - modifying old algorithms to make them faster.pdf:pdf},
isbn = {0128080310},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {Bayesian inverse problems,Bayesian nonparametrics,Gaussian random field,MCMC,algorithms},
number = {3},
pages = {424--446},
title = {{MCMC Methods for Functions: Modifying Old Algorithms to Make Them Faster}},
volume = {28},
year = {2013}
}



@article{Parno2014,
abstract = {We introduce a new framework for efficient sampling from complex probability distributions, using a combination of optimal transport maps and the Metropolis-Hastings rule. The core idea is to use continuous transportation to transform typical Metropolis proposal mechanisms (e.g., random walks, Langevin methods) into non-Gaussian proposal distributions that can more effectively explore the target density. Our approach adaptively constructs a lower triangular transport map-an approximation of the Knothe-Rosenblatt rearrangement-using information from previous MCMC states, via the solution of an optimization problem. This optimization problem is convex regardless of the form of the target distribution. It is solved efficiently using a Newton method that requires no gradient information from the target probability distribution; the target distribution is instead represented via samples. Sequential updates enable efficient and parallelizable adaptation of the map even for large numbers of samples. We show that this approach uses inexact or truncated maps to produce an adaptive MCMC algorithm that is ergodic for the exact target distribution. Numerical demonstrations on a range of parameter inference problems show order-of-magnitude speedups over standard MCMC techniques, measured by the number of effectively independent samples produced per target density evaluation and per unit of wallclock time.},
author = {Parno, M. and Marzouk, Y.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Transport of Measure/(2015, Parno {\&} Marzouk) Transport map accelerated Markov chain Monte Carlo.pdf:pdf},
journal = {arXiv:1412.5492},
keywords = {adaptive mcmc,ams subject classifications,bayesian inference,measure transformation,optimal transport},
title = {{Transport map accelerated Markov chain Monte Carlo}},
year = {2014}
}



@article{Lan2016,
abstract = {The Bayesian approach to Inverse Problems relies predominantly on Markov Chain Monte Carlo methods for posterior inference. The typical nonlinear concentration of posterior measure observed in many such Inverse Problems presents severe challenges to existing simulation based inference methods. Motivated by these challenges the exploitation of local geometric information in the form of covariant gradients, metric tensors, Levi-Civita connections, and local geodesic flows, have been introduced to more effectively locally explore the configuration space of the posterior measure. However, obtaining such geometric quantities usually requires extensive computational effort and despite their effectiveness affect the applicability of these geometrically-based Monte Carlo methods. In this paper we explore one way to address this issue by the construction of an emulator of the model from which all geometric objects can be obtained in a much more computationally feasible manner. The main concept is to approximate the geometric quantities using a Gaussian Process emulator which is conditioned on a carefully chosen design set of configuration points, which also determines the quality of the emulator. To this end we propose the use of statistical experiment design methods to refine a potentially arbitrarily initialized design online without destroying the convergence of the resulting Markov chain to the desired invariant measure. The practical examples considered in this paper provide a demonstration of the significant improvement possible in terms of computational loading suggesting this is a promising avenue of further development.},
author = {Lan, S. and Bui-Thanh, T. and Christie, M. and Girolami, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lan et al. - 2016 - Emulation of Higher-Order Tensors in Manifold Monte Carlo Methods for Bayesian Inverse Problems.pdf:pdf},
journal = {Journal of Computational Physics},
keywords = {bayesian inverse problems,gaussian,hamiltonian monte carlo,markov chain monte carlo,process emulation,uncertainty quantification},
mendeley-groups = {OxWaSP mini-project 2 - scalable kernel method for BQ},
pages = {81--101},
title = {{Emulation of Higher-Order Tensors in Manifold Monte Carlo Methods for Bayesian Inverse Problems}},
volume = {308},
year = {2016}
}


@article{Betancourt2017,
abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous under- standing of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is con- fined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any ex- haustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
author = {Betancourt, M.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/(2017, Betancourt) A conceptual Introduction to Hamiltonian Monte Carlo.pdf:pdf},
journal = {arXiv:1701.02434},
title = {{A Conceptual Introduction to Hamiltonian Monte Carlo}},
year = {2017}
}


@article{Girolami2011,
author = {Girolami, M. and Calderhead, B.},
journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
number = {2},
pages = {123--214},
title = {{Riemann manifold Langevin and Hamiltonian Monte Carlo methods}},
volume = {73},
year = {2011}
}

@article{Oates2017,
abstract = {This paper introduces a novel class of estimators for Monte Carlo integration, that leverage gradient information in order to provide the improved estimator performance demanded by contemporary statistical applications. The proposed estimators, called "control functionals", achieve sub-root-{\$}n{\$} convergence and often require orders of magnitude fewer simulations, compared with existing approaches, in order to achieve a fixed level of precision. We focus on a particular sub-class of estimators that permit an elegant analytic form and study their properties, both theoretically and empirically. Results are presented on Bayes-Hermite quadrature, hierarchical Gaussian process models and non-linear ordinary differential equation models, where in each case our estimators are shown to offer state of the art performance.},
author = {Oates, C. J. and Girolami, M. and Chopin, N.},
file = {:home/francois/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oates, Girolami, Chopin - 2017 - Control functionals for Monte Carlo integration.pdf:pdf},
journal = {Journal of the Royal Statistical Society B: Statistical Methodology},
number = {3},
pages = {695--718},
title = {{Control functionals for Monte Carlo integration}},
volume = {79},
year = {2017}
}


@article{Muller1997,
author = {Muller, A.},
journal = {Advances in Applied Probability},
number = {2},
pages = {429--443},
title = {{Integral probability metrics and their generating classes of functions}},
volume = {29},
year = {1997}
}

@article{Gibbs2002,
author = {Gibbs, A. L. and Su, F. E.},
journal = {International Statistical Review},
number = {3},
pages = {419--435},
pmid = {19618487},
primaryClass = {math},
title = {{On Choosing and Bounding Probability Metrics}},
volume = {70},
year = {2002}
}

@article{Sriperumbudur2012,
author = {Sriperumbudur, B. K. and Fukumizu, K. and Gretton, A. and Sch{\"{o}}lkopf, B. and Lanckriet, . R G},
journal = {Electronic Journal of Statistics},
keywords = {Dual-bounded Lipschitz distance (Dudley metric),Empirical estimation,Integral probability metrics,Kantorovich metric,Kernel distance,Lipschitz classifier,Rademacher average,Reproducing kernel Hilbert space,Support vector machine},
pages = {1550--1599},
title = {{On the empirical estimation of integral probability metrics}},
volume = {6},
year = {2012}
}

@article{Sriperumbudur2009IPM_phidivergence_class,
abstract = {A class of distance measures on probabilities -- the integral probability metrics (IPMs) -- is addressed: these include the Wasserstein distance, Dudley metric, and Maximum Mean Discrepancy. IPMs have thus far mostly been used in more abstract settings, for instance as theoretical tools in mass transportation problems, and in metrizing the weak topology on the set of all Borel probability measures defined on a metric space. Practical applications of IPMs are less common, with some exceptions in the kernel machines literature. The present work contributes a number of novel properties of IPMs, which should contribute to making IPMs more widely used in practice, for instance in areas where {\$}\backslashphi{\$}-divergences are currently popular. First, to understand the relation between IPMs and {\$}\backslashphi{\$}-divergences, the necessary and sufficient conditions under which these classes intersect are derived: the total variation distance is shown to be the only non-trivial {\$}\backslashphi{\$}-divergence that is also an IPM. This shows that IPMs are essentially different from {\$}\backslashphi{\$}-divergences. Second, empirical estimates of several IPMs from finite i.i.d. samples are obtained, and their consistency and convergence rates are analyzed. These estimators are shown to be easily computable, with better rates of convergence than estimators of {\$}\backslashphi{\$}-divergences. Third, a novel interpretation is provided for IPMs by relating them to binary classification, where it is shown that the IPM between class-conditional distributions is the negative of the optimal risk associated with a binary classifier. In addition, the smoothness of an appropriate binary classifier is proved to be inversely related to the distance between the class-conditional distributions, measured in terms of an IPM.},
author = {Sriperumbudur, B. K. and Fukumizu, K. and Gretton, A. and Lanckriet, G. R. G.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Monte Carlo Methods/HMC/Integral probability metrics/(2009, Sriperumbudur et al ) On integral probability metrics - phi-divergences and binary classification.pdf:pdf},
number = {1},
pages = {1--18},
title = {{On Integral Probability Metrics, phi-divergences and binary classification}},
year = {2009}
}


@book{Novak2010,
author = {Novak, E. and Wo{\'{z}}niakowski, H.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Novak, Wo{\'{z}}niakowski - 2010 - Tractability of Multivariate Problems, Volume II Standard Information for Functionals.pdf:pdf},
publisher = {European Mathematical Society Publishing House, EMS Tracts in Mathematics 12},
title = {{Tractability of Multivariate Problems, Volume II : Standard Information for Functionals}},
year = {2010}
}


@article{Dick2013,
abstract = {This paper is a contemporary review of QMC (â€˜quasi-Monte Carlo') methods, that is, equal-weight rules for the approximate evaluation of high-dimensional integrals over the unit cube [0, 1]s,where s may be large, or even infinite. Af- ter a general introduction, the paper surveys recent developments in lattice methods, digital nets, and related themes. Among those recent developments are methods of construction of both lattices and digital nets, to yield QMC rules that have a prescribed rate of convergence for sufficiently smooth func- tions, and ideally also guaranteed slow growth (or no growth) of the worst-case error as s increases. A crucial role is played by parameters called â€˜weights', since a careful use of the weight parameters is needed to ensure that the worst-case errors in an appropriately weighted function space are bounded, or grow only slowly, as the dimension s increases. Important tools for the analysis are weighted function spaces, reproducing kernel Hilbert spaces, and discrepancy, all of which are discussed with an appropriate level of detail.},
author = {Dick, J. and Kuo, F. Y. and Sloan, I. H.},
file = {:C$\backslash$:/Users/Francois-Xavier/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dick, Kuo, Sloan - 2013 - High-dimensional integration The quasi-Monte Carlo way.pdf:pdf},
journal = {Acta Numerica},
mendeley-groups = {OxWaSP mini-project 2 - scalable kernel method for BQ},
number = {April 2013},
pages = {133--288},
title = {{High-dimensional integration: The quasi-Monte Carlo way}},
volume = {22},
year = {2013}
}


@article{Gorham2016,
abstract = {To improve the efficiency of Monte Carlo estimation, practitioners are turning to biased Markov chain Monte Carlo procedures that trade off asymptotic exactness for computational speed. The reasoning is sound: a reduction in variance due to more rapid sampling can outweigh the bias introduced. However, the inexactness creates new challenges for sampler and parameter selection, since standard mea-sures of sample quality like effective sample size do not account for asymptotic bias. To address these challenges, we introduce a new computable quality measure based on Stein's method that bounds the discrepancy between sample and target expectations over a large class of test functions. We use our tool to compare exact, biased, and deterministic sample sequences and illustrate applications to hyper-parameter selection, convergence rate assessment, and quantifying bias-variance tradeoffs in posterior inference.},
author = {Gorham, J. and Duncan, A. and Mackey, L. and Vollmer, S.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Stein method/(2016, Gorham et al) Measuring sample quality with diffusions.pdf:pdf},
journal = {arXiv:1506.03039. To appear in Annals of Applied Probability.},
title = {{Measuring sample quality with diffusions}},
year = {2016}
}

@book{Barbour2005,
author = {Barbour, A. and Chen, L. H. Y.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Stein method/(2005, Barbour {\&} Chen) An introduction to Steins Method.pdf:pdf},
isbn = {981256280X},
title = {{An introduction to Stein's method}},
year = {2005}
}

@article{Gretton2008,
author = {Gretton, A. and Borgwardt, K. and Rasch, M. and Scholkopf, B. and Smola, A.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Kernel Methods/Hypothesis Testing/(2008, Gretton et al) A kernel method for the two-sample problem - JMLR.pdf:pdf},
journal = {Journal of Machine Learning Research},
number = {157},
pages = {0--43},
title = {{A Kernel Method for the Two-Sample Problem}},
volume = {1},
year = {2008}
}


@inproceedings{Liu2016,
author = {Liu, Q. and Wang, D.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Stein method/(2016, Liu {\&} Wang) Stein Variational Gradient Descent - A general purpose Bayesian inference algorithm.pdf:pdf},
title = {{Stein variational gradient descent: A general purpose Bayesian inference algorithm}},
year = {2016}
}


@article{Bassetti2006,
author = {Bassetti, F. and Bodini, A. and Regazzini, E.},
file = {:C$\backslash$:/Users/Francois-Xavier/Dropbox/OxWaSP/Papers/Probability Distributions/Distances between distributions/Integral probability metrics/(2006, Bassetti) On minimum Kantorovich distance estimators.pdf:pdf},
journal = {Statistics {\&} Probability Letters},
keywords = {consistency of point estimators,minimum dissimilarity estimators,minimum kantorovich distance estimators},
pages = {1298--1302},
title = {{On minimum Kantorovich distance estimators}},
volume = {76},
year = {2006}
}


@article{BASSETTI20061298,
title = "On minimum Kantorovich distance estimators",
journal = "Statistics \& Probability Letters",
volume = "76",
number = "12",
pages = "1298 - 1302",
year = "2006",
author = "F. Bassetti and A, Bodini and E. Regazzini"
}


@ARTICLE{Bellemare2017,
   author = {{Bellemare}, M.~G. and {Danihelka}, I. and {Dabney}, W. and 
	{Mohamed}, S. and {Lakshminarayanan}, B. and {Hoyer}, S. and 
	{Munos}, R.},
    title = "{The Cramer Distance as a Solution to Biased Wasserstein Gradients}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1705.10743},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Statistics - Machine Learning},
     year = 2017,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170510743B},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{hampel1971general,
  title={A general qualitative definition of robustness},
  author={Hampel, Frank R},
  journal={The Annals of Mathematical Statistics},
  pages={1887--1896},
  year={1971},
  publisher={JSTOR}
}

@article{cioranescu2000introduction,
  title={Introduction to homogenization},
  author={Cioranescu, Doina and Donato, Patrizia},
  year={2000}
}


@techreport{hoeffding1961strong,
  title={The strong law of large numbers for {U}-statistics.},
  author={Hoeffding, Wassily},
  year={1961},
  institution={North Carolina State University Department of Statistics}
}

@article{hoeffding1948class,
  title={A class of statistics with asymptotically normal distribution},
  author={Hoeffding, Wassily},
  journal={The Annals of Mathematical Statistics},
  pages={293--325},
  year={1948},
  publisher={JSTOR}
}
