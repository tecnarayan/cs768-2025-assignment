\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baevski \& Auli(2019)Baevski and Auli]{baevski2019adaptive}
Baevski, A. and Auli, M.
\newblock Adaptive input representations for neural language modeling.
\newblock In \emph{7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.
\newblock URL \url{https://openreview.net/forum?id=ByxZX20qFQ}.

\bibitem[Bai et~al.(2019)Bai, Kolter, and Koltun]{bai2018deq}
Bai, S., Kolter, J.~Z., and Koltun, V.
\newblock Deep equilibrium models.
\newblock In Wallach, H.~M., Larochelle, H., Beygelzimer, A.,
  d'Alch{\'{e}}{-}Buc, F., Fox, E.~B., and Garnett, R. (eds.), \emph{Advances
  in Neural Information Processing Systems 32: Annual Conference on Neural
  Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019,
  Vancouver, BC, Canada}, pp.\  688--699, 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/hash/01386bd6d8e091c2ab4c7c7de644d37b-Abstract.html}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger,
  Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin,
  Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{brown2020gpt3}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert{-}Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A.,
  Ziegler, D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin,
  M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A.,
  Sutskever, I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020DETR}
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko,
  S.
\newblock End-to-end object detection with transformers.
\newblock In Vedaldi, A., Bischof, H., Brox, T., and Frahm, J. (eds.),
  \emph{Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow, UK,
  August 23-28, 2020, Proceedings, Part {I}}, volume 12346 of \emph{Lecture
  Notes in Computer Science}, pp.\  213--229. Springer, 2020.

\bibitem[Chen et~al.(2021)Chen, Panda, and Fan]{Chen-2021-RegionVit}
Chen, C., Panda, R., and Fan, Q.
\newblock Regionvit: Regional-to-local attention for vision transformers.
\newblock \emph{CoRR}, abs/2106.02689, 2021.
\newblock URL \url{https://arxiv.org/abs/2106.02689}.

\bibitem[Chu et~al.(2021)Chu, Tian, Wang, Zhang, Ren, Wei, Xia, and
  Shen]{Chu-2021-twins}
Chu, X., Tian, Z., Wang, Y., Zhang, B., Ren, H., Wei, X., Xia, H., and Shen, C.
\newblock Twins: Revisiting spatial attention design in vision transformers.
\newblock \emph{CoRR}, abs/2104.13840, 2021.
\newblock URL \url{https://arxiv.org/abs/2104.13840}.

\bibitem[Dai et~al.(2019)Dai, Yang, Yang, Carbonell, Le, and
  Salakhutdinov]{dai-etal-2019-transformer}
Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q., and Salakhutdinov, R.
\newblock Transformer-{XL}: Attentive language models beyond a fixed-length
  context.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  2978--2988, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1285}.
\newblock URL \url{https://aclanthology.org/P19-1285}.

\bibitem[Dehghani et~al.(2019)Dehghani, Gouws, Vinyals, Uszkoreit, and
  Kaiser]{Dehghani2019universal}
Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Kaiser, L.
\newblock Universal transformers.
\newblock In \emph{7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.
\newblock URL \url{https://openreview.net/forum?id=HyzdRiR9Y7}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://aclanthology.org/N19-1423}.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2020ViT}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.
\newblock URL \url{https://openreview.net/forum?id=YicbFdNTTy}.

\bibitem[Fan et~al.(2021{\natexlab{a}})Fan, Xiong, Mangalam, Li, Yan, Malik,
  and Feichtenhofer]{fan2021MViT}
Fan, H., Xiong, B., Mangalam, K., Li, Y., Yan, Z., Malik, J., and
  Feichtenhofer, C.
\newblock Multiscale vision transformers.
\newblock \emph{CoRR}, abs/2104.11227, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2104.11227}.

\bibitem[Fan et~al.(2021{\natexlab{b}})Fan, Xiong, Mangalam, Li, Yan, Malik,
  and Feichtenhofer]{fan2021multiscale}
Fan, H., Xiong, B., Mangalam, K., Li, Y., Yan, Z., Malik, J., and
  Feichtenhofer, C.
\newblock Multiscale vision transformers.
\newblock \emph{arXiv preprint arXiv:2104.11227}, 2021{\natexlab{b}}.

\bibitem[Fan et~al.(2021{\natexlab{c}})Fan, Gong, Liu, Wei, Wang, Jiao, Duan,
  Zhang, and Huang]{fan-etal-2021-mask}
Fan, Z., Gong, Y., Liu, D., Wei, Z., Wang, S., Jiao, J., Duan, N., Zhang, R.,
  and Huang, X.
\newblock Mask attention networks: Rethinking and strengthen transformer.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  1692--1701, Online, June 2021{\natexlab{c}}. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.naacl-main.135}.
\newblock URL \url{https://aclanthology.org/2021.naacl-main.135}.

\bibitem[Gehrmann et~al.(2018)Gehrmann, Deng, and
  Rush]{gehrmann-etal-2018-bottom}
Gehrmann, S., Deng, Y., and Rush, A.
\newblock Bottom-up abstractive summarization.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  4098--4109, Brussels, Belgium,
  October-November 2018.

\bibitem[Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang,
  Zhang, Wu, and Pang]{gulati2020conformer}
Gulati, A., Qin, J., Chiu, C., Parmar, N., Zhang, Y., Yu, J., Han, W., Wang,
  S., Zhang, Z., Wu, Y., and Pang, R.
\newblock Conformer: Convolution-augmented transformer for speech recognition.
\newblock In Meng, H., Xu, B., and Zheng, T.~F. (eds.), \emph{Interspeech 2020,
  21st Annual Conference of the International Speech Communication Association,
  Virtual Event, Shanghai, China, 25-29 October 2020}, pp.\  5036--5040.
  {ISCA}, 2020.
\newblock URL \url{https://doi.org/10.21437/Interspeech.2020-3015}.

\bibitem[Guo et~al.(2020)Guo, Qiu, Liu, Xue, and Zhang]{guo-2020-msan}
Guo, Q., Qiu, X., Liu, P., Xue, X., and Zhang, Z.
\newblock Multi-scale self-attention for text classification.
\newblock In \emph{The Thirty-Fourth {AAAI} Conference on Artificial
  Intelligence, {AAAI} 2020, The Thirty-Second Innovative Applications of
  Artificial Intelligence Conference, {IAAI} 2020, The Tenth {AAAI} Symposium
  on Educational Advances in Artificial Intelligence, {EAAI} 2020, New York,
  NY, USA, February 7-12, 2020}, pp.\  7847--7854. {AAAI} Press, 2020.
\newblock URL \url{https://aaai.org/ojs/index.php/AAAI/article/view/6290}.

\bibitem[Han et~al.(2021)Han, Xiao, Wu, Guo, Xu, and Wang]{han2021transformer}
Han, K., Xiao, A., Wu, E., Guo, J., Xu, C., and Wang, Y.
\newblock Transformer in transformer.
\newblock \emph{arXiv preprint arXiv:2103.00112}, 2021.

\bibitem[Hao et~al.(2019)Hao, Wang, Shi, Zhang, and Tu]{hao-etal-2019-multi}
Hao, J., Wang, X., Shi, S., Zhang, J., and Tu, Z.
\newblock Multi-granularity self-attention for neural machine translation.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pp.\  887--897, Hong Kong,
  China, November 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D19-1082}.
\newblock URL \url{https://aclanthology.org/D19-1082}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{2016 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016}, pp.\
  770--778. {IEEE} Computer Society, 2016.
\newblock \doi{10.1109/CVPR.2016.90}.
\newblock URL \url{https://doi.org/10.1109/CVPR.2016.90}.

\bibitem[Hermann et~al.(2015)Hermann, Kocisk{\'{y}}, Grefenstette, Espeholt,
  Kay, Suleyman, and Blunsom]{hermann2015teaching}
Hermann, K.~M., Kocisk{\'{y}}, T., Grefenstette, E., Espeholt, L., Kay, W.,
  Suleyman, M., and Blunsom, P.
\newblock Teaching machines to read and comprehend.
\newblock In Cortes, C., Lawrence, N.~D., Lee, D.~D., Sugiyama, M., and
  Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems
  28: Annual Conference on Neural Information Processing Systems 2015, December
  7-12, 2015, Montreal, Quebec, Canada}, pp.\  1693--1701, 2015.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2015/hash/afdec7005cc9f14302cd0474fd0f3c96-Abstract.html}.

\bibitem[Kasai et~al.(2020)Kasai, Cross, Ghazvininejad, and Gu]{kasai2020disco}
Kasai, J., Cross, J., Ghazvininejad, M., and Gu, J.
\newblock Non-autoregressive machine translation with disentangled context
  transformer.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pp.\  5144--5155. {PMLR},
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/kasai20a.html}.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Kipf \& Welling(2017)Kipf and Welling]{Kipf2017gcn}
Kipf, T.~N. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}. OpenReview.net, 2017.
\newblock URL \url{https://openreview.net/forum?id=SJU4ayYgl}.

\bibitem[Kitaev \& Klein(2018)Kitaev and Klein]{kitaev-klein-2018-constituency}
Kitaev, N. and Klein, D.
\newblock Constituency parsing with a self-attentive encoder.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  2676--2686,
  Melbourne, Australia, July 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P18-1249}.
\newblock URL \url{https://www.aclweb.org/anthology/P18-1249}.

\bibitem[Kudo \& Richardson(2018)Kudo and
  Richardson]{kudo-richardson-2018-sentencepiece}
Kudo, T. and Richardson, J.
\newblock {S}entence{P}iece: A simple and language independent subword
  tokenizer and detokenizer for neural text processing.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pp.\  66--71, Brussels,
  Belgium, November 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D18-2012}.
\newblock URL \url{https://aclanthology.org/D18-2012}.

\bibitem[Lee et~al.(2018)Lee, Mansimov, and Cho]{lee-etal-2018-deterministic}
Lee, J., Mansimov, E., and Cho, K.
\newblock Deterministic non-autoregressive neural sequence modeling by
  iterative refinement.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1173--1182, Brussels, Belgium,
  October-November 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D18-1149}.
\newblock URL \url{https://aclanthology.org/D18-1149}.

\bibitem[Lei~Ba et~al.(2016)Lei~Ba, Kiros, and Hinton]{lei2016layer}
Lei~Ba, J., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{ArXiv preprint}, abs/1607.06450, 2016.
\newblock URL \url{https://arxiv.org/abs/1607.06450}.

\bibitem[Li et~al.(2020)Li, Wang, Liu, Jiang, Du, Xiao, Wang, and
  Zhu]{li-etal-2020-shallow}
Li, B., Wang, Z., Liu, H., Jiang, Y., Du, Q., Xiao, T., Wang, H., and Zhu, J.
\newblock Shallow-to-deep training for neural machine translation.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  995--1005, Online, November 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.72}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.72}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Wang, Liu, Du, Xiao, Zhang, and
  Zhu]{li2021lightweight}
Li, B., Wang, Z., Liu, H., Du, Q., Xiao, T., Zhang, C., and Zhu, J.
\newblock Learning light-weight translation models from deep transformer.
\newblock In \emph{Thirty-Fifth {AAAI} Conference on Artificial Intelligence,
  {AAAI} 2021, Thirty-Third Conference on Innovative Applications of Artificial
  Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances in
  Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9, 2021},
  pp.\  13217--13225. {AAAI} Press, 2021{\natexlab{a}}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/17561}.

\bibitem[Li et~al.(2022)Li, Du, Zhou, Jing, Zhou, Zeng, Xiao, Zhu, Liu, and
  Zhang]{li-etal-2022-ode}
Li, B., Du, Q., Zhou, T., Jing, Y., Zhou, S., Zeng, X., Xiao, T., Zhu, J., Liu,
  X., and Zhang, M.
\newblock {ODE} transformer: An ordinary differential equation-inspired model
  for sequence generation.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  8335--8351,
  Dublin, Ireland, May 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.acl-long.571}.
\newblock URL \url{https://aclanthology.org/2022.acl-long.571}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Wu, Fan, Mangalam, Xiong, Malik, and
  Feichtenhofer]{li2021improvedMViT}
Li, Y., Wu, C., Fan, H., Mangalam, K., Xiong, B., Malik, J., and Feichtenhofer,
  C.
\newblock Improved multiscale vision transformers for classification and
  detection.
\newblock \emph{CoRR}, abs/2112.01526, 2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2112.01526}.

\bibitem[Lin(2004)]{lin-2004-rouge}
Lin, C.-Y.
\newblock {ROUGE}: A package for automatic evaluation of summaries.
\newblock In \emph{Text Summarization Branches Out}, pp.\  74--81, Barcelona,
  Spain, 2004. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/W04-1013}.

\bibitem[Lin et~al.(2017)Lin, Doll{\'a}r, Girshick, He, Hariharan, and
  Belongie]{lin2017feature}
Lin, T.-Y., Doll{\'a}r, P., Girshick, R., He, K., Hariharan, B., and Belongie,
  S.
\newblock Feature pyramid networks for object detection.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2117--2125, 2017.

\bibitem[Liu et~al.(2020{\natexlab{a}})Liu, Wang, Wong, Ding, Chao, and
  Tu]{liu2020understanding}
Liu, X., Wang, L., Wong, D.~F., Ding, L., Chao, L.~S., and Tu, Z.
\newblock Understanding and improving encoder layer fusion in
  sequence-to-sequence learning.
\newblock \emph{ArXiv preprint}, abs/2012.14768, 2020{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2012.14768}.

\bibitem[Liu et~al.(2020{\natexlab{b}})Liu, Gu, Goyal, Li, Edunov,
  Ghazvininejad, Lewis, and Zettlemoyer]{liu-etal-2020-multilingual-denoising}
Liu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M., Lewis, M.,
  and Zettlemoyer, L.
\newblock Multilingual denoising pre-training for neural machine translation.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:\penalty0 726--742, 2020{\natexlab{b}}.
\newblock \doi{10.1162/tacl_a_00343}.
\newblock URL \url{https://aclanthology.org/2020.tacl-1.47}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021swin}
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., and Guo, B.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock \emph{CoRR}, abs/2103.14030, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.14030}.

\bibitem[Mehta et~al.(2020)Mehta, Ghazvininejad, Iyer, Zettlemoyer, and
  Hajishirzi]{mehta2020delight}
Mehta, S., Ghazvininejad, M., Iyer, S., Zettlemoyer, L., and Hajishirzi, H.
\newblock Delight: Very deep and light-weight transformer.
\newblock \emph{ArXiv preprint}, abs/2008.00623, 2020.
\newblock URL \url{https://arxiv.org/abs/2008.00623}.

\bibitem[Morishita et~al.(2018)Morishita, Suzuki, and
  Nagata]{morishita-etal-2018-improving}
Morishita, M., Suzuki, J., and Nagata, M.
\newblock Improving neural machine translation by incorporating hierarchical
  subword features.
\newblock In \emph{Proceedings of the 27th International Conference on
  Computational Linguistics}, pp.\  618--629, Santa Fe, New Mexico, USA, August
  2018. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/C18-1052}.

\bibitem[Nallapati et~al.(2016)Nallapati, Zhou, dos Santos,
  G{\"{u}}l{\c{c}}ehre, and Xiang]{nallapati-etal-2016-abstractive}
Nallapati, R., Zhou, B., dos Santos, C.~N., G{\"{u}}l{\c{c}}ehre, {\c{C}}., and
  Xiang, B.
\newblock Abstractive text summarization using sequence-to-sequence rnns and
  beyond.
\newblock In Goldberg, Y. and Riezler, S. (eds.), \emph{Proceedings of the 20th
  {SIGNLL} Conference on Computational Natural Language Learning, CoNLL 2016,
  Berlin, Germany, August 11-12, 2016}, pp.\  280--290. {ACL}, 2016.

\bibitem[Ott et~al.(2018)Ott, Edunov, Grangier, and Auli]{ott2018scaling}
Ott, M., Edunov, S., Grangier, D., and Auli, M.
\newblock Scaling neural machine translation.
\newblock In \emph{Proceedings of the Third Conference on Machine Translation:
  Research Papers}, pp.\  1--9, Brussels, Belgium, 2018. Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/W18-6301}.
\newblock URL \url{https://aclanthology.org/W18-6301}.

\bibitem[Ott et~al.(2019)Ott, Edunov, Baevski, Fan, Gross, Ng, Grangier, and
  Auli]{ott2019fairseq}
Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., Grangier, D., and
  Auli, M.
\newblock fairseq: A fast, extensible toolkit for sequence modeling.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics (Demonstrations)},
  pp.\  48--53, Minneapolis, Minnesota, 2019. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/N19-4009}.
\newblock URL \url{https://aclanthology.org/N19-4009}.

\bibitem[Qi et~al.(2018)Qi, Dozat, Zhang, and Manning]{qi2018universal}
Qi, P., Dozat, T., Zhang, Y., and Manning, C.~D.
\newblock Universal dependency parsing from scratch.
\newblock In \emph{Proceedings of the {CoNLL} 2018 Shared Task: Multilingual
  Parsing from Raw Text to Universal Dependencies}, pp.\  160--170, Brussels,
  Belgium, October 2018. Association for Computational Linguistics.
\newblock URL \url{https://nlp.stanford.edu/pubs/qi2018universal.pdf}.

\bibitem[Rei et~al.(2020)Rei, Stewart, Farinha, and Lavie]{rei-etal-2020-comet}
Rei, R., Stewart, C., Farinha, A.~C., and Lavie, A.
\newblock {COMET}: A neural framework for {MT} evaluation.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  2685--2702, Online, November
  2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.213}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.213}.

\bibitem[Sellam et~al.(2020)Sellam, Das, and Parikh]{sellam-etal-2020-bleurt}
Sellam, T., Das, D., and Parikh, A.
\newblock {BLEURT}: Learning robust metrics for text generation.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  7881--7892, Online, July 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.704}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.704}.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch]{sennrich-subword-neural}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  1715--1725,
  Berlin, Germany, 2016. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P16-1162}.
\newblock URL \url{https://aclanthology.org/P16-1162}.

\bibitem[Shaw et~al.(2018)Shaw, Uszkoreit, and Vaswani]{shaw-etal-2018-self}
Shaw, P., Uszkoreit, J., and Vaswani, A.
\newblock Self-attention with relative position representations.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 2 (Short Papers)}, pp.\  464--468, New Orleans,
  Louisiana, 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N18-2074}.
\newblock URL \url{https://aclanthology.org/N18-2074}.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Sutskever, I., Vinyals, O., and Le, Q.~V.
\newblock Sequence to sequence learning with neural networks.
\newblock In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N.~D., and
  Weinberger, K.~Q. (eds.), \emph{Advances in Neural Information Processing
  Systems 27: Annual Conference on Neural Information Processing Systems 2014,
  December 8-13 2014, Montreal, Quebec, Canada}, pp.\  3104--3112, 2014.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.~M., Fergus,
  R., Vishwanathan, S. V.~N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 30: Annual Conference on Neural Information
  Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}}, pp.\
  5998--6008, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}.

\bibitem[Vaswani et~al.(2021)Vaswani, Ramachandran, Srinivas, Parmar, Hechtman,
  and Shlens]{Vaswani-2021-SLSA}
Vaswani, A., Ramachandran, P., Srinivas, A., Parmar, N., Hechtman, B.~A., and
  Shlens, J.
\newblock Scaling local self-attention for parameter efficient visual
  backbones.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2021, virtual, June 19-25, 2021}, pp.\  12894--12904.
  Computer Vision Foundation / {IEEE}, 2021.
\newblock URL
  \url{https://openaccess.thecvf.com/content/CVPR2021/html/Vaswani\_Scaling\_Local\_Self-Attention\_}.

\bibitem[Velickovic et~al.(2018)Velickovic, Cucurull, Casanova, Romero,
  Li{\`{o}}, and Bengio]{Petar2018GAT}
Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Li{\`{o}}, P., and
  Bengio, Y.
\newblock Graph attention networks.
\newblock In \emph{6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJXMpikCZ}.

\bibitem[Wang et~al.(2019)Wang, Li, Xiao, Zhu, Li, Wong, and
  Chao]{wang-etal-2019-learning}
Wang, Q., Li, B., Xiao, T., Zhu, J., Li, C., Wong, D.~F., and Chao, L.~S.
\newblock Learning deep transformer models for machine translation.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  1810--1822, Florence, Italy, 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1176}.
\newblock URL \url{https://aclanthology.org/P19-1176}.

\bibitem[Wang et~al.(2021)Wang, Xie, Li, Fan, Song, Liang, Lu, Luo, and
  Shao]{wang2021pvt}
Wang, W., Xie, E., Li, X., Fan, D., Song, K., Liang, D., Lu, T., Luo, P., and
  Shao, L.
\newblock Pyramid vision transformer: {A} versatile backbone for dense
  prediction without convolutions.
\newblock \emph{CoRR}, abs/2102.12122, 2021.
\newblock URL \url{https://arxiv.org/abs/2102.12122}.

\bibitem[Wei et~al.(2020)Wei, Yu, Hu, Zhang, Weng, and
  Luo]{wei-etal-2020-multiscale}
Wei, X., Yu, H., Hu, Y., Zhang, Y., Weng, R., and Luo, W.
\newblock Multiscale collaborative deep models for neural machine translation.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  414--426, Online, 2020. Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.40}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.40}.

\bibitem[Wu et~al.(2019)Wu, Fan, Baevski, Dauphin, and Auli]{wu2019DynamicConv}
Wu, F., Fan, A., Baevski, A., Dauphin, Y.~N., and Auli, M.
\newblock Pay less attention with lightweight and dynamic convolutions.
\newblock In \emph{7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.
\newblock URL \url{https://openreview.net/forum?id=SkVhlh09tX}.

\bibitem[Wu et~al.(2021)Wu, Xiao, Codella, Liu, Dai, Yuan, and
  Zhang]{Wu-2021-cvt}
Wu, H., Xiao, B., Codella, N., Liu, M., Dai, X., Yuan, L., and Zhang, L.
\newblock Cvt: Introducing convolutions to vision transformers.
\newblock \emph{CoRR}, abs/2103.15808, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.15808}.

\bibitem[Wu et~al.(2020)Wu, Xie, Xia, Fan, Lai, Qin, and Liu]{wu2020mixed}
Wu, L., Xie, S., Xia, Y., Fan, Y., Lai, J., Qin, T., and Liu, T.
\newblock Sequence generation with mixed representations.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pp.\  10388--10398. {PMLR},
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/wu20e.html}.

\bibitem[Wu et~al.(2018)Wu, Wang, Liu, and Ma]{wu-etal-2018-phrase}
Wu, W., Wang, H., Liu, T., and Ma, S.
\newblock Phrase-level self-attention networks for universal sentence encoding.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  3729--3738, Brussels, Belgium,
  October-November 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D18-1408}.
\newblock URL \url{https://aclanthology.org/D18-1408}.

\bibitem[Xu et~al.(2021)Xu, Zhou, Gan, Zheng, and Li]{xu-etal-2021-vocabulary}
Xu, J., Zhou, H., Gan, C., Zheng, Z., and Li, L.
\newblock Vocabulary learning via optimal transport for neural machine
  translation.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pp.\  7361--7373,
  Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.571}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.571}.

\bibitem[Yang et~al.(2019)Yang, Wang, Wong, Chao, and
  Tu]{yang-etal-2019-convolutional}
Yang, B., Wang, L., Wong, D.~F., Chao, L.~S., and Tu, Z.
\newblock Convolutional self-attention networks.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4040--4045,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1407}.
\newblock URL \url{https://aclanthology.org/N19-1407}.

\bibitem[Yang et~al.(2021)Yang, Li, Zhang, Dai, Xiao, Yuan, and
  Gao]{Yang-2021-Focalsan}
Yang, J., Li, C., Zhang, P., Dai, X., Xiao, B., Yuan, L., and Gao, J.
\newblock Focal self-attention for local-global interactions in vision
  transformers.
\newblock \emph{CoRR}, abs/2107.00641, 2021.
\newblock URL \url{https://arxiv.org/abs/2107.00641}.

\bibitem[Zhao et~al.(2019)Zhao, Sun, Xu, Zhang, and Luo]{Zhao-2019-MUSE}
Zhao, G., Sun, X., Xu, J., Zhang, Z., and Luo, L.
\newblock {MUSE:} parallel multi-scale attention for sequence to sequence
  learning.
\newblock \emph{CoRR}, abs/1911.09483, 2019.
\newblock URL \url{http://arxiv.org/abs/1911.09483}.

\end{thebibliography}
