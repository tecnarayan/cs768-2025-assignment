\begin{thebibliography}{10}

\bibitem{barducci2008well}
Alessandro Barducci, Giovanni Bussi, and Michele Parrinello.
\newblock Well-tempered metadynamics: a smoothly converging and tunable
  free-energy method.
\newblock {\em Physical review letters}, 100(2):020603, 2008.

\bibitem{brooks2011handbook}
Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng.
\newblock {\em Handbook of markov chain monte carlo}.
\newblock CRC press, 2011.

\bibitem{chen2014stochastic}
Tianqi Chen, Emily~B Fox, and Carlos Guestrin.
\newblock Stochastic gradient hamiltonian monte carlo.
\newblock In {\em ICML}, pages 1683--1691, 2014.

\bibitem{comer2014adaptive}
Jeffrey Comer, James~C Gumbart, J\'{e}r\^{o}me H\'{e}nin, Tony Leli\`{e}vre,
  Andrew Pohorille, and Christophe Chipot.
\newblock The adaptive biasing force method: Everything you always wanted to
  know but were afraid to ask.
\newblock {\em The Journal of Physical Chemistry B}, 119(3):1129--1151, 2014.

\bibitem{darve2001calculating}
Eric Darve and Andrew Pohorille.
\newblock Calculating free energies using average force.
\newblock {\em The Journal of Chemical Physics}, 115(20):9169--9183, 2001.

\bibitem{ding2014bayesian}
Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert~D Skeel, and Hartmut
  Neven.
\newblock Bayesian sampling using stochastic gradient thermostats.
\newblock In {\em Advances in neural information processing systems}, pages
  3203--3211, 2014.

\bibitem{duane1987hybrid}
Simon Duane, Anthony~D Kennedy, Brian~J Pendleton, and Duncan Roweth.
\newblock Hybrid monte carlo.
\newblock {\em Physics letters B}, 195(2):216--222, 1987.

\bibitem{feroz2008multimodal}
Farhan Feroz and MP~Hobson.
\newblock Multimodal nested sampling: an efficient and robust alternative to
  markov chain monte carlo methods for astronomical data analyses.
\newblock {\em Monthly Notices of the Royal Astronomical Society},
  384(2):449--463, 2008.

\bibitem{gobbo2015extended}
Gianpaolo Gobbo and Benedict~J Leimkuhler.
\newblock Extended hamiltonian approach to continuous tempering.
\newblock {\em Physical Review E}, 91(6):061301, 2015.

\bibitem{DBLP:conf/uai/GrahamS17}
Matthew~M. Graham and Amos~J. Storkey.
\newblock Continuously tempered hamiltonian monte carlo.
\newblock In Gal Elidan, Kristian Kersting, and Alexander~T. Ihler, editors,
  {\em Proceedings of the Thirty-Third Conference on Uncertainty in Artificial
  Intelligence, {UAI} 2017, Sydney, Australia, August 11-15, 2017}. {AUAI}
  Press, 2017.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{hoover1985canonical}
William~G Hoover.
\newblock Canonical dynamics: equilibrium phase-space distributions.
\newblock {\em Physical review A}, 31(3):1695, 1985.

\bibitem{jones2011adaptive}
Andrew Jones and Ben Leimkuhler.
\newblock Adaptive stochastic methods for sampling driven molecular systems.
\newblock {\em The Journal of chemical physics}, 135(8):084125, 2011.

\bibitem{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock {\em CoRR}, abs/1412.6980, 2014.

\bibitem{laio2002escaping}
Alessandro Laio and Michele Parrinello.
\newblock Escaping free-energy minima.
\newblock {\em Proceedings of the National Academy of Sciences},
  99(20):12562--12566, 2002.

\bibitem{lelievre2008long}
Tony Leli{\`e}vre, Mathias Rousset, and Gabriel Stoltz.
\newblock Long-time convergence of an adaptive biasing force method.
\newblock {\em Nonlinearity}, 21(6):1155, 2008.

\bibitem{lenner2016continuous}
Nicolas Lenner and Gerald Mathias.
\newblock Continuous tempering molecular dynamics: A deterministic approach to
  simulated tempering.
\newblock {\em Journal of chemical theory and computation}, 12(2):486--498,
  2016.

\bibitem{neal2011mcmc}
Radford~M Neal et~al.
\newblock Mcmc using hamiltonian dynamics.
\newblock {\em Handbook of Markov Chain Monte Carlo}, 2:113--162, 2011.

\bibitem{nesterov1983nag}
Yurii Nesterov.
\newblock A method of solving a convex programming problem with convergence
  rate o(1/k2).
\newblock {\em Soviet Mathematics Doklady}, 27(2):372--376, 1983.

\bibitem{nose1984unified}
Shuichi Nos{\'e}.
\newblock A unified formulation of the constant temperature molecular dynamics
  methods.
\newblock {\em The Journal of chemical physics}, 81(1):511--519, 1984.

\bibitem{polyak1964some}
Boris~T Polyak.
\newblock Some methods of speeding up the convergence of iteration methods.
\newblock {\em USSR Computational Mathematics and Mathematical Physics},
  4(5):1--17, 1964.

\bibitem{risken1989fpe}
H.~Risken and H.~Haken.
\newblock {\em {The Fokker-Planck Equation: Methods of Solution and
  Applications Second Edition}}.
\newblock Springer, 1989.

\bibitem{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock {\em The annals of mathematical statistics}, pages 400--407, 1951.

\bibitem{roberts1996exponential}
Gareth~O Roberts, Richard~L Tweedie, et~al.
\newblock Exponential convergence of langevin distributions and their discrete
  approximations.
\newblock {\em Bernoulli}, 2(4):341--363, 1996.

\bibitem{sutskever2013importance}
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton.
\newblock On the importance of initialization and momentum in deep learning.
\newblock In {\em International conference on machine learning}, pages
  1139--1147, 2013.

\bibitem{valsson2016enhancing}
Omar Valsson, Pratyush Tiwary, and Michele Parrinello.
\newblock Enhancing important fluctuations: Rare events and metadynamics from a
  conceptual viewpoint.
\newblock {\em Annual review of physical chemistry}, 67:159--184, 2016.

\bibitem{welling2011bayesian}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pages 681--688, 2011.

\bibitem{ye2017langevin}
Nanyang Ye, Zhanxing Zhu, and Rafal Mantiuk.
\newblock Langevin dynamics with continuous tempering for training deep neural
  networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  618--626, 2017.

\end{thebibliography}
