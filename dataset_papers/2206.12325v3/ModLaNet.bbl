\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen-Blanchette et~al.(2020)Allen-Blanchette, Veer, Majumdar, and
  Leonard]{allen2020lagnetvip}
Allen-Blanchette, C., Veer, S., Majumdar, A., and Leonard, N.~E.
\newblock Lagnetvip: A lagrangian neural network for video prediction.
\newblock \emph{arXiv preprint arXiv:2010.12932}, 2020.

\bibitem[Battaglia et~al.(2016)Battaglia, Pascanu, Lai, Rezende, and
  Kavukcuoglu]{battaglia2016interaction}
Battaglia, P., Pascanu, R., Lai, M., Rezende, D.~J., and Kavukcuoglu, K.
\newblock Interaction networks for learning about objects, relations and
  physics.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS
  2016)}, pp.\  4509--4517, 2016.

\bibitem[Chen \& Tao(2021)Chen and Tao]{chen2021data}
Chen, R. and Tao, M.
\newblock Data-driven prediction of general hamiltonian dynamics via learning
  exactly-symplectic maps.
\newblock 2021.

\bibitem[Chen et~al.(2020)Chen, Amos, and Nickel]{chen2020learning}
Chen, R.~T., Amos, B., and Nickel, M.
\newblock Learning neural event functions for ordinary differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Chen, T.~Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K.
\newblock Neural ordinary differential equations.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS
  2018)}, pp.\  6572--6583, 2018.

\bibitem[Cranmer et~al.(2020)Cranmer, Greydanus, Hoyer, Battaglia, Spergel, and
  Ho]{cranmer2020lagrangian}
Cranmer, M., Greydanus, S., Hoyer, S., Battaglia, P., Spergel, D., and Ho, S.
\newblock Lagrangian neural networks.
\newblock In \emph{International Conference on Learning Representations
  Workshop on Integration of Deep Neural Models and Differential Equations},
  2020.

\bibitem[de~Avila Belbute-Peres et~al.(2018)de~Avila Belbute-Peres, Smith,
  Allen, Tenenbaum, and Kolter]{de2018end}
de~Avila Belbute-Peres, F., Smith, K., Allen, K., Tenenbaum, J., and Kolter,
  J.~Z.
\newblock End-to-end differentiable physics for learning and control.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS
  2018)}, 31:\penalty0 7178--7189, 2018.

\bibitem[Finzi et~al.(2020)Finzi, Wang, and Wilson]{finzi2020simplifying}
Finzi, M., Wang, K.~A., and Wilson, A.~G.
\newblock Simplifying hamiltonian and lagrangian neural networks via explicit
  constraints.
\newblock 2020.

\bibitem[Galioto \& Gorodetsky(2020)Galioto and
  Gorodetsky]{galioto2020bayesian}
Galioto, N. and Gorodetsky, A.~A.
\newblock Bayesian identification of hamiltonian dynamics from symplectic data.
\newblock In \emph{2020 59th IEEE Conference on Decision and Control (CDC)},
  pp.\  1190--1195. IEEE, 2020.

\bibitem[Greydanus et~al.(2019)Greydanus, Dzamba, and
  Yosinski]{Greydanus2019deep}
Greydanus, S., Dzamba, M., and Yosinski, J.
\newblock Hamiltonian neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS
  2019)}, 2019.

\bibitem[Hermann et~al.(2020)Hermann, Sch{\"a}tzle, and
  No{\'e}]{hermann2020deep}
Hermann, J., Sch{\"a}tzle, Z., and No{\'e}, F.
\newblock Deep-neural-network solution of the electronic schr{\"o}dinger
  equation.
\newblock \emph{Nature Chemistry}, 12\penalty0 (10):\penalty0 891--897, 2020.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{hornik1989multilayer}
Hornik, K., Stinchcombe, M., and White, H.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural networks}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Jin et~al.(2020{\natexlab{a}})Jin, Zhang, Kevrekidis, and
  Karniadakis]{jin2020learning}
Jin, P., Zhang, Z., Kevrekidis, I.~G., and Karniadakis, G.~E.
\newblock Learning poisson systems and trajectories of autonomous systems via
  poisson neural networks.
\newblock \emph{arXiv preprint arXiv:2012.03133}, 2020{\natexlab{a}}.

\bibitem[Jin et~al.(2020{\natexlab{b}})Jin, Zhang, Zhu, Tang, and
  Karniadakis]{jin2020sympnets}
Jin, P., Zhang, Z., Zhu, A., Tang, Y., and Karniadakis, G.~E.
\newblock Sympnets: Intrinsic structure-preserving symplectic networks for
  identifying hamiltonian systems.
\newblock \emph{Neural Networks}, 132:\penalty0 166--179, 2020{\natexlab{b}}.

\bibitem[Kipf et~al.(2018)Kipf, Fetaya, Wang, Welling, and
  Zemel]{kipf2018neural}
Kipf, T., Fetaya, E., Wang, K.-C., Welling, M., and Zemel, R.
\newblock Neural relational inference for interacting systems.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2688--2697. PMLR, 2018.

\bibitem[Li et~al.(2017)Li, Chen, Tai, and Weinan]{li2017maximum}
Li, Q., Chen, L., Tai, C., and Weinan, E.
\newblock Maximum principle based algorithms for deep learning.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 5998--6026, 2017.

\bibitem[Liberzon(2011)]{liberzon2011calculus}
Liberzon, D.
\newblock \emph{Calculus of variations and optimal control theory}.
\newblock Princeton university press, 2011.

\bibitem[Lutter et~al.(2018)Lutter, Ritter, and Peters]{lutter2018deep}
Lutter, M., Ritter, C., and Peters, J.
\newblock Deep lagrangian networks: Using physics as model prior for deep
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Lutter et~al.(2019)Lutter, Listmann, and Peters]{lutter2019deep}
Lutter, M., Listmann, K., and Peters, J.
\newblock Deep lagrangian networks for end-to-end learning of energy-based
  control for under-actuated systems.
\newblock In \emph{IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS 2019)}, pp.\  7718--7725. IEEE, 2019.

\bibitem[Maclaurin et~al.(2015)Maclaurin, Duvenaud, Johnson, Townsend,
  et~al.]{Autograd}
Maclaurin, D., Duvenaud, D., Johnson, M., Townsend, J., et~al.
\newblock Autograd.
\newblock \url{https://github.com/HIPS/autograd}, 2015.
\newblock Accessed: 2022-06-16.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  et~al.]{NEURIPS2019_9015}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems (NeurIPS 2019)}, pp.\  8024--8035. Curran
  Associates, Inc., 2019.

\bibitem[Pfau et~al.(2020)Pfau, Spencer, Matthews, and Foulkes]{pfau2020ab}
Pfau, D., Spencer, J.~S., Matthews, A.~G., and Foulkes, W. M.~C.
\newblock Ab initio solution of the many-electron schr{\"o}dinger equation with
  deep neural networks.
\newblock \emph{Physical Review Research}, 2\penalty0 (3):\penalty0 033429,
  2020.

\bibitem[Roehrl et~al.(2020)Roehrl, Runkler, Brandtstetter, Tokic, and
  Obermayer]{roehrl2020modeling}
Roehrl, M.~A., Runkler, T.~A., Brandtstetter, V., Tokic, M., and Obermayer, S.
\newblock Modeling system dynamics with physics-informed neural networks based
  on lagrangian mechanics.
\newblock \emph{IFAC-PapersOnLine}, 53\penalty0 (2):\penalty0 9195--9200, 2020.

\bibitem[Shinbrot et~al.(1992)Shinbrot, Grebogi, Wisdom, and
  Yorke]{shinbrot1992chaos}
Shinbrot, T., Grebogi, C., Wisdom, J., and Yorke, J.~A.
\newblock Chaos in a double pendulum.
\newblock \emph{American Journal of Physics}, 60\penalty0 (6):\penalty0
  491--499, 1992.

\bibitem[Toth et~al.(2019)Toth, Rezende, Jaegle, Racani{\`e}re, Botev, and
  Higgins]{toth2019hamiltonian}
Toth, P., Rezende, D.~J., Jaegle, A., Racani{\`e}re, S., Botev, A., and
  Higgins, I.
\newblock Hamiltonian generative networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Vaidyanathan \& Volos(2016)Vaidyanathan and
  Volos]{vaidyanathan2016advances}
Vaidyanathan, S. and Volos, C.
\newblock \emph{Advances and applications in chaotic systems}, volume 636.
\newblock Springer, 2016.

\bibitem[Verma et~al.(2018)Verma, Novati, and Koumoutsakos]{verma2018efficient}
Verma, S., Novati, G., and Koumoutsakos, P.
\newblock Efficient collective swimming by harnessing vortices through deep
  reinforcement learning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 115\penalty0
  (23):\penalty0 5849--5854, 2018.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  et~al.]{2020SciPy-NMeth}
Virtanen, P., Gommers, R., Oliphant, T.~E., Haberland, M., Reddy, T.,
  Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., {van
  der Walt}, S.~J., Brett, M., et~al.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.

\bibitem[Weinan(2017)]{weinan2017proposal}
Weinan, E.
\newblock A proposal on machine learning via dynamical systems.
\newblock \emph{Communications in Mathematics and Statistics}, 5\penalty0
  (1):\penalty0 1--11, 2017.

\bibitem[Willard et~al.(2020)Willard, Jia, Xu, Steinbach, and
  Kumar]{willard2020integrating}
Willard, J., Jia, X., Xu, S., Steinbach, M., and Kumar, V.
\newblock Integrating physics-based modeling with machine learning: A survey.
\newblock \emph{arXiv preprint arXiv:2003.04919}, 1\penalty0 (1):\penalty0
  1--34, 2020.

\bibitem[Yu et~al.(2021)Yu, Tian, Weinan, and Li]{yu2021onsagernet}
Yu, H., Tian, X., Weinan, E., and Li, Q.
\newblock Onsagernet: Learning stable and interpretable dynamics using a
  generalized onsager principle.
\newblock \emph{Physical Review Fluids}, 6\penalty0 (11):\penalty0 114402,
  2021.

\bibitem[Zhang et~al.(2016)Zhang, Chen, and Liu]{zhang2016material}
Zhang, X., Chen, Z., and Liu, Y.
\newblock \emph{The material point method: a continuum-based particle method
  for extreme loading cases}.
\newblock Academic Press, 2016.

\bibitem[Zhao et~al.(2020)Zhao, Ruan, Yue, Hung, Som, and Xu]{zhao2020time}
Zhao, F., Ruan, Z., Yue, Z., Hung, D.~L., Som, S., and Xu, M.
\newblock Time-sequenced flow field prediction in an optical spark-ignition
  direct-injection engine using bidirectional recurrent neural network (bi-rnn)
  with long short-term memory.
\newblock \emph{Applied Thermal Engineering}, 173:\penalty0 115253, 2020.

\bibitem[Zhong \& Leonard(2020)Zhong and Leonard]{zhong2020unsupervised}
Zhong, Y.~D. and Leonard, N.
\newblock Unsupervised learning of lagrangian dynamics from images for
  prediction and control.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS
  2020)}, 33, 2020.

\bibitem[Zhong et~al.(2019)Zhong, Dey, and Chakraborty]{zhong2019symplectic}
Zhong, Y.~D., Dey, B., and Chakraborty, A.
\newblock Symplectic ode-net: Learning hamiltonian dynamics with control.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Zhong et~al.(2021{\natexlab{a}})Zhong, Dey, and
  Chakraborty]{zhong2021benchmarking}
Zhong, Y.~D., Dey, B., and Chakraborty, A.
\newblock Benchmarking energy-conserving neural networks for learning dynamics
  from data.
\newblock In \emph{Learning for Dynamics and Control}, pp.\  1218--1229. PMLR,
  2021{\natexlab{a}}.

\bibitem[Zhong et~al.(2021{\natexlab{b}})Zhong, Dey, and
  Chakraborty]{zhong2021extending}
Zhong, Y.~D., Dey, B., and Chakraborty, A.
\newblock Extending lagrangian and hamiltonian neural networks with
  differentiable contact models.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS
  2021)}, 34, 2021{\natexlab{b}}.

\end{thebibliography}
