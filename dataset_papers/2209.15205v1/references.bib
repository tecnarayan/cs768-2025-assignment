%key paper:
@inproceedings{pertsch2020spirl,
    title={Accelerating Reinforcement Learning with Learned Skill Priors},
    author={Karl Pertsch and Youngwoon Lee and Joseph J. Lim},
    booktitle={Conference on Robot Learning (CoRL)},
    year={2020},
}

@article{DBLP:journals/corr/abs-1803-06773,
  author    = {Tuomas Haarnoja and
               Vitchyr Pong and
               Aurick Zhou and
               Murtaza Dalal and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Composable Deep Reinforcement Learning for Robotic Manipulation},
  journal   = {CoRR},
  volume    = {abs/1803.06773},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.06773},
  eprinttype = {arXiv},
  eprint    = {1803.06773},
  timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-06773.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1805-08296,
  author    = {Ofir Nachum and
               Shixiang Gu and
               Honglak Lee and
               Sergey Levine},
  title     = {Data-Efficient Hierarchical Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1805.08296},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.08296},
  eprinttype = {arXiv},
  eprint    = {1805.08296},
  timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-08296.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%Offline RL
@article{DBLP:journals/corr/abs-2005-01643,
  author    = {Sergey Levine and
               Aviral Kumar and
               George Tucker and
               Justin Fu},
  title     = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives
               on Open Problems},
  journal   = {CoRR},
  volume    = {abs/2005.01643},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.01643},
  eprinttype = {arXiv},
  eprint    = {2005.01643},
  timestamp = {Fri, 08 May 2020 15:04:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-01643.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
%%% model free
@article{DBLP:journals/corr/abs-2006-09359,
  author    = {Ashvin Nair and
               Murtaza Dalal and
               Abhishek Gupta and
               Sergey Levine},
  title     = {Accelerating Online Reinforcement Learning with Offline Datasets},
  journal   = {CoRR},
  volume    = {abs/2006.09359},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09359},
  eprinttype = {arXiv},
  eprint    = {2006.09359},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09359.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Kumar2019StabilizingOQ,
  title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  author={Aviral Kumar and Justin Fu and G. Tucker and Sergey Levine},
  booktitle={NeurIPS},
  year={2019}
}

@article{DBLP:journals/corr/abs-1904-08473,
  author    = {Yao Liu and
               Adith Swaminathan and
               Alekh Agarwal and
               Emma Brunskill},
  title     = {Off-Policy Policy Gradient with State Distribution Correction},
  journal   = {CoRR},
  volume    = {abs/1904.08473},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.08473},
  eprinttype = {arXiv},
  eprint    = {1904.08473},
  timestamp = {Sat, 14 Dec 2019 17:11:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-08473.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Fujimoto2019OffPolicyDR,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Scott Fujimoto and David Meger and Doina Precup},
  booktitle={ICML},
  year={2019}
}



@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{DBLP:journals/corr/abs-1907-04543,
  author    = {Rishabh Agarwal and
               Dale Schuurmans and
               Mohammad Norouzi},
  title     = {Striving for Simplicity in Off-policy Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1907.04543},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.04543},
  eprinttype = {arXiv},
  eprint    = {1907.04543},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-04543.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1911-11361,
  author    = {Yifan Wu and
               George Tucker and
               Ofir Nachum},
  title     = {Behavior Regularized Offline Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1911.11361},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.11361},
  eprinttype = {arXiv},
  eprint    = {1911.11361},
  timestamp = {Tue, 03 Dec 2019 14:15:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-11361.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1907-00456,
  author    = {Natasha Jaques and
               Asma Ghandeharioun and
               Judy Hanwen Shen and
               Craig Ferguson and
               {\`{A}}gata Lapedriza and
               Noah Jones and
               Shixiang Gu and
               Rosalind W. Picard},
  title     = {Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human
               Preferences in Dialog},
  journal   = {CoRR},
  volume    = {abs/1907.00456},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.00456},
  eprinttype = {arXiv},
  eprint    = {1907.00456},
  timestamp = {Thu, 14 Oct 2021 09:17:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-00456.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


% }

@inproceedings{siegel2019keep,
  title={Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  booktitle={Proceedings of the 34th International Conference on Neural Information Processing Systems},
  pages={7768--7778},
  year={2020}
}


@article{kidambi2020morel,
title={Morel: Model-based offline reinforcement learning},
author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
journal={Advances in neural information processing systems},
volume={33},
pages={21810--21823},
year={2020}
}


@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}



@inproceedings{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  booktitle={International Conference on Learning Representations},
  year={2020}
}



@inproceedings{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  booktitle={International Conference on Learning Representations},
  year={2020}
}



@inproceedings{cang2021behavioral,
  title={Behavioral Priors and Dynamics Models: Improving Performance and Domain Transfer in Offline RL},
  author={Cang, Catherine and Rajeswaran, Aravind and Abbeel, Pieter and Laskin, Michael},
  booktitle={Deep RL Workshop NeurIPS 2021},
  year={2021}
}

@inproceedings{Qureshi2020ComposingTP,
  title={Composing Task-Agnostic Policies with Deep Reinforcement Learning},
  author={A. H. Qureshi and Jacob J. Johnson and Yuzhe Qin and Taylor Henderson and Byron Boots and Michael C. Yip},
  booktitle={ICLR},
  year={2020}
}

@misc{ren2021probabilistic,
      title={Probabilistic Mixture-of-Experts for Efficient Deep Reinforcement Learning}, 
      author={Jie Ren and Yewen Li and Zihan Ding and Wei Pan and Hao Dong},
      year={2021},
      eprint={2104.09122},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Peng2019MCPLC,
  title={MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies},
  author={Xue Bin Peng and Michael Chang and Grace H. Zhang and P. Abbeel and Sergey Levine},
  booktitle={NeurIPS},
  year={2019}
}

@misc{urain2021composable,
      title={Composable Energy Policies for Reactive Motion Generation and Reinforcement Learning}, 
      author={Julen Urain and Anqi Li and Puze Liu and Carlo D'Eramo and Jan Peters},
      year={2021},
      eprint={2105.04962},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
@inproceedings{tseng2021toward,
  title={Toward Robust Long Range Policy Transfer},
  author={Tseng, Wei-Cheng and Lin, Jin-Siang and Feng, Yao-Min and Sun, Min},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={11},
  pages={9958--9966},
  year={2021}
}


@inproceedings{rao2021learning,
  title={Learning transferable motor skills with hierarchical latent mixture policies},
  author={Rao, Dushyant and Sadeghi, Fereshteh and Hasenclever, Leonard and Wulfmeier, Markus and Zambelli, Martina and Vezzani, Giulia and Tirumala, Dhruva and Aytar, Yusuf and Merel, Josh and Heess, Nicolas and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
%latent space
@misc{heess2016learning,
      title={Learning and Transfer of Modulated Locomotor Controllers}, 
      author={Nicolas Heess and Greg Wayne and Yuval Tassa and Timothy Lillicrap and Martin Riedmiller and David Silver},
      year={2016},
      eprint={1610.05182},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
@article{DBLP:journals/corr/FlorensaDA17,
  author    = {Carlos Florensa and
               Yan Duan and
               Pieter Abbeel},
  title     = {Stochastic Neural Networks for Hierarchical Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1704.03012},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.03012},
  eprinttype = {arXiv},
  eprint    = {1704.03012},
  timestamp = {Mon, 13 Aug 2018 16:47:12 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FlorensaDA17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{merel2018neural,
  title={Neural Probabilistic Motor Primitives for Humanoid Control},
  author={Merel, Josh and Hasenclever, Leonard and Galashov, Alexandre and Ahuja, Arun and Pham, Vu and Wayne, Greg and Teh, Yee Whye and Heess, Nicolas},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@inproceedings{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{eysenbach2018diversity,
  title={Diversity is All You Need: Learning Skills without a Reward Function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@inproceedings{Haarnoja2018LatentSP,
  title={Latent Space Policies for Hierarchical Reinforcement Learning},
  author={Tuomas Haarnoja and Kristian Hartikainen and P. Abbeel and Sergey Levine},
  booktitle={ICML},
  year={2018}
}

%HRL 

@inproceedings{bagaria2021robustly,
  title={Robustly Learning Composable Options in Deep Reinforcement Learning},
  author={Bagaria, Akhil and Senthil, Jason and Slivinski, Matthew and Konidaris, George},
  booktitle={Proceedings of the 30th International Joint Conference on Artificial Intelligence},
  year={2021}
}
@misc{bacon2016optioncritic,
      title={The Option-Critic Architecture}, 
      author={Pierre-Luc Bacon and Jean Harb and Doina Precup},
      year={2016},
      eprint={1609.05140},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{hausknecht2016deep,
      title={Deep Reinforcement Learning in Parameterized Action Space}, 
      author={Matthew Hausknecht and Peter Stone},
      year={2016},
      eprint={1511.04143},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@inproceedings{frans2018meta,
  title={META LEARNING SHARED HIERARCHIES},
  author={Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  booktitle={International Conference on Learning Representations},
  year={2018}
}



@inproceedings{merel2018hierarchical,
  title={Hierarchical Visuomotor Control of Humanoids},
  author={Merel, Josh and Ahuja, Arun and Pham, Vu and Tunyasuvunakool, Saran and Liu, Siqi and Tirumala, Dhruva and Heess, Nicolas and Wayne, Greg},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{DBLP:journals/corr/abs-1906-11228,
  author    = {Markus Wulfmeier and
               Abbas Abdolmaleki and
               Roland Hafner and
               Jost Tobias Springenberg and
               Michael Neunert and
               Tim Hertweck and
               Thomas Lampe and
               Noah Y. Siegel and
               Nicolas Heess and
               Martin A. Riedmiller},
  title     = {Regularized Hierarchical Policies for Compositional Transfer in Robotics},
  journal   = {CoRR},
  volume    = {abs/1906.11228},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.11228},
  eprinttype = {arXiv},
  eprint    = {1906.11228},
  timestamp = {Mon, 02 Mar 2020 14:31:29 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-11228.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{barreto2018transfer,
  title={Transfer in deep reinforcement learning using successor features and generalised policy improvement},
  author={Barreto, Andre and Borsa, Diana and Quan, John and Schaul, Tom and Silver, David and Hessel, Matteo and Mankowitz, Daniel and Zidek, Augustin and Munos, Remi},
  booktitle={International Conference on Machine Learning},
  pages={501--510},
  year={2018},
  organization={PMLR}
}

@inproceedings{borsa2018universal,
  title={Universal Successor Features Approximators},
  author={Borsa, Diana and Barreto, Andre and Quan, John and Mankowitz, Daniel J and van Hasselt, Hado and Munos, Remi and Silver, David and Schaul, Tom},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@inproceedings{Barreto2019TheOK,
  title={The Option Keyboard: Combining Skills in Reinforcement Learning},
  author={Andr{\'e} Barreto and Diana Borsa and Shaobo Hou and Gheorghe Comanici and Eser Ayg{\"u}n and Philippe Hamel and Daniel Toyama and Jonathan J. Hunt and Shibl Mourad and David Silver and Doina Precup},
  booktitle={NeurIPS},
  year={2019}
}
%value function


@inproceedings{Hunt2019ComposingEP,
  title={Composing Entropic Policies using Divergence Correction},
  author={Jonathan J. Hunt and Andr{\'e} Barreto and Timothy P. Lillicrap and Nicolas Manfred Otto Heess},
  booktitle={ICML},
  year={2019}
}

@InProceedings{pmlr-v97-van-niekerk19a,
  title = 	 {Composing Value Functions in Reinforcement Learning},
  author =       {Van Niekerk, Benjamin and James, Steven and Earle, Adam and Rosman, Benjamin},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6401--6409},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/van-niekerk19a/van-niekerk19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/van-niekerk19a.html},
}


@inproceedings{wang2022skill,
  title={Skill preferences: Learning to extract and execute robotic skills from human feedback},
  author={Wang, Xiaofei and Lee, Kimin and Hakhamaneshi, Kourosh and Abbeel, Pieter and Laskin, Michael},
  booktitle={Conference on Robot Learning},
  pages={1259--1268},
  year={2022},
  organization={PMLR}
}


@inproceedings{singh2020parrot,
  title={Parrot: Data-Driven Behavioral Priors for Reinforcement Learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{ajay2020opal,
  title={OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@inproceedings{gehring2021hierarchical,
  title={Hierarchical Skills for Efficient Exploration},
  author={Gehring, Jonas and Synnaeve, Gabriel and Krause, Andreas and Usunier, Nicolas},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

%d4rl
@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

%TD3
@misc{fujimoto2018addressing,
      title={Addressing Function Approximation Error in Actor-Critic Methods}, 
      author={Scott Fujimoto and Herke van Hoof and David Meger},
      year={2018},
      eprint={1802.09477},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

% weight actor update
@misc{peng2019advantageweighted,
      title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning}, 
      author={Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
      year={2019},
      eprint={1910.00177},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{nair2021awac,
      title={AWAC: Accelerating Online Reinforcement Learning with Offline Datasets}, 
      author={Ashvin Nair and Abhishek Gupta and Murtaza Dalal and Sergey Levine},
      year={2021},
      eprint={2006.09359},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


%policy reuse
@inproceedings{10.1145/1160633.1160762,
author = {Fern\'{a}ndez, Fernando and Veloso, Manuela},
title = {Probabilistic Policy Reuse in a Reinforcement Learning Agent},
year = {2006},
isbn = {1595933034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1160633.1160762},
doi = {10.1145/1160633.1160762},
abstract = {We contribute Policy Reuse as a technique to improve a reinforcement learning agent with guidance from past learned similar policies. Our method relies on using the past policies as a probabilistic bias where the learning agent faces three choices: the exploitation of the ongoing learned policy, the exploration of random unexplored actions, and the exploitation of past policies. We introduce the algorithm and its major components: an exploration strategy to include the new reuse bias, and a similarity function to estimate the similarity of past policies with respect to a new one. We provide empirical results demonstrating that Policy Reuse improves the learning performance over different strategies that learn without reuse. Interestingly and almost as a side effect, Policy Reuse also identifies classes of similar policies revealing a basis of core policies of the domain. We demonstrate that such a basis can be built incrementally, contributing the learning of the structure of a domain.},
booktitle = {Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems},
pages = {720–727},
numpages = {8},
location = {Hakodate, Japan},
series = {AAMAS '06}
}
%sac


@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
% autonmatic temp
@article{DBLP:journals/corr/abs-1812-05905,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Kristian Hartikainen and
               George Tucker and
               Sehoon Ha and
               Jie Tan and
               Vikash Kumar and
               Henry Zhu and
               Abhishek Gupta and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic Algorithms and Applications},
  journal   = {CoRR},
  volume    = {abs/1812.05905},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.05905},
  eprinttype = {arXiv},
  eprint    = {1812.05905},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-05905.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% mix of experts
@ARTICLE{6797059,  author={Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},  journal={Neural Computation},   title={Adaptive Mixtures of Local Experts},   year={1991},  volume={3},  number={1},  pages={79-87},  doi={10.1162/neco.1991.3.1.79}}
%mv paper
@article{article,
author = {Browning, Brett and Bruce, James and Bowling, Michael and Veloso, Manuela},
year = {2004},
month = {12},
pages = {},
title = {STP: Skills, tactics, and plays for multi-robot control in adversarial environments},
volume = {219},
journal = {Proceedings of The Institution of Mechanical Engineers Part I-journal of Systems and Control Engineering - PROC INST MECH ENG I-J SYST C},
doi = {10.1243/095965105X9470}
}

%robotsuit
@inproceedings{robosuite2020,
  title={robosuite: A Modular Simulation Framework and Benchmark for Robot Learning},
  author={Yuke Zhu and Josiah Wong and Ajay Mandlekar and Roberto Mart\'{i}n-Mart\'{i}n},
  booktitle={arXiv preprint arXiv:2009.12293},
  year={2020}
}


@inproceedings{liu2017stein,
  title={Stein variational policy gradient},
  author={Liu, Yang and Ramachandran, Prajit and Liu, Qiang and Peng, Jian},
  booktitle={33rd Conference on Uncertainty in Artificial Intelligence, UAI 2017},
  year={2017}
}


@article{liu2016stein,
  title={Stein variational gradient descent: A general purpose bayesian inference algorithm},
  author={Liu, Qiang and Wang, Dilin},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}