\begin{thebibliography}{77}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahuja et~al.(2020)Ahuja, Shanmugam, Varshney, and
  Dhurandhar]{ahuja2020invariant}
Ahuja, K., Shanmugam, K., Varshney, K., and Dhurandhar, A.
\newblock Invariant risk minimization games.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research, pp.\  145--155. PMLR,
  13--18 Jul 2020.

\bibitem[Aleksandrov \& Peller(2011)Aleksandrov and
  Peller]{aleksandrov2011estimates}
Aleksandrov, A.~B. and Peller, V.~V.
\newblock Estimates of operator moduli of continuity.
\newblock \emph{Journal of Functional Analysis}, 261\penalty0 (10):\penalty0
  2741--2796, 2011.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., and
  Man{\'e}, D.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Arjovsky, M., Bottou, L., Gulrajani, I., and Lopez-Paz, D.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Arora et~al.(2019)Arora, Du, Hu, Li, and
  Wang]{DBLP:conf/icml/AroraDHLW19}
Arora, S., Du, S.~S., Hu, W., Li, Z., and Wang, R.
\newblock Fine-grained analysis of optimization and generalization for
  overparameterized two-layer neural networks.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning, {ICML} 2019, 9-15 June
  2019, Long Beach, California, {USA}}, volume~97 of \emph{Proceedings of
  Machine Learning Research}, pp.\  322--332. {PMLR}, 2019.

\bibitem[Bahng et~al.(2020)Bahng, Chun, Yun, Choo, and Oh]{bahng2020learning}
Bahng, H., Chun, S., Yun, S., Choo, J., and Oh, S.~J.
\newblock Learning de-biased representations with biased representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  528--539. PMLR, 2020.

\bibitem[Bai \& Lee(2020)Bai and Lee]{DBLP:conf/iclr/BaiL20}
Bai, Y. and Lee, J.~D.
\newblock Beyond linearization: On quadratic and higher-order approximation of
  wide neural networks.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\bibitem[{Bansal} et~al.(2019){Bansal}, {Krizhevsky}, and
  {Ogale}]{bansal2018chauffeurnet}
{Bansal}, M., {Krizhevsky}, A., and {Ogale}, A.
\newblock {ChauffeurNet: Learning to Drive by Imitating the Best and
  Synthesizing the Worst}.
\newblock \emph{Robotics: Science \& Systems (RSS)}, art. arXiv:1812.03079,
  2019.

\bibitem[Bargh \& Chartrand(2014)Bargh and Chartrand]{bargh2014mind}
Bargh, J.~A. and Chartrand, T.~L.
\newblock The mind in the middle: A practical guide to priming and automaticity
  research.
\newblock 2014.

\bibitem[Bargh et~al.(1996)Bargh, Chen, and Burrows]{bargh1996automaticity}
Bargh, J.~A., Chen, M., and Burrows, L.
\newblock Automaticity of social behavior: Direct effects of trait construct
  and stereotype activation on action.
\newblock \emph{Journal of personality and social psychology}, 71\penalty0
  (2):\penalty0 230, 1996.

\bibitem[Beery et~al.(2018)Beery, Van~Horn, and Perona]{beery2018recognition}
Beery, S., Van~Horn, G., and Perona, P.
\newblock Recognition in terra incognita.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  456--473, 2018.

\bibitem[Bickel et~al.(2009)Bickel, Br{\"u}ckner, and
  Scheffer]{Bickel2009DiscriminativeLU}
Bickel, S., Br{\"u}ckner, M., and Scheffer, T.
\newblock Discriminative learning under covariate shift.
\newblock \emph{J. Mach. Learn. Res.}, 10:\penalty0 2137--2155, 2009.

\bibitem[Bojarski et~al.(2016)Bojarski, Testa, Dworakowski, Firner, Flepp,
  Goyal, Jackel, Monfort, Muller, Zhang, Zhang, Zhao, and
  Zieba]{bojarski2016end}
Bojarski, M., Testa, D.~D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P.,
  Jackel, L.~D., Monfort, M., Muller, U., Zhang, J., Zhang, X., Zhao, J., and
  Zieba, K.
\newblock End to end learning for self-driving cars.
\newblock \emph{CoRR}, abs/1604.07316, 2016.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and Gebru]{buolamwini2018gender}
Buolamwini, J. and Gebru, T.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on fairness, accountability and transparency},
  pp.\  77--91. PMLR, 2018.

\bibitem[Cadene et~al.(2019)Cadene, Dancette, Cord, Parikh,
  et~al.]{cadene2019rubi}
Cadene, R., Dancette, C., Cord, M., Parikh, D., et~al.
\newblock Rubi: Reducing unimodal biases for visual question answering.
\newblock \emph{Advances in neural information processing systems},
  32:\penalty0 841--852, 2019.

\bibitem[Cao et~al.(2011)Cao, Ni, Sun, Wang, and Yang]{Cao2011DistanceML}
Cao, B., Ni, X., Sun, J.-T., Wang, G., and Yang, Q.
\newblock Distance metric learning under covariate shift.
\newblock In \emph{IJCAI}, 2011.

\bibitem[Chen et~al.(2020)Chen, Zhou, Koltun, and
  Kr{\"a}henb{\"u}hl]{chen2020learning}
Chen, D., Zhou, B., Koltun, V., and Kr{\"a}henb{\"u}hl, P.
\newblock Learning by cheating.
\newblock In \emph{Conference on Robot Learning}, pp.\  66--75. PMLR, 2020.

\bibitem[Chizat et~al.(2019)Chizat, Oyallon, and
  Bach]{DBLP:conf/nips/ChizatOB19}
Chizat, L., Oyallon, E., and Bach, F.~R.
\newblock On lazy training in differentiable programming.
\newblock In Wallach, H.~M., Larochelle, H., Beygelzimer, A.,
  d'Alch{\'{e}}{-}Buc, F., Fox, E.~B., and Garnett, R. (eds.), \emph{Advances
  in Neural Information Processing Systems 32: Annual Conference on Neural
  Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019,
  Vancouver, BC, Canada}, pp.\  2933--2943, 2019.

\bibitem[Clark et~al.(2019)Clark, Yatskar, and Zettlemoyer]{clark2019dont}
Clark, C., Yatskar, M., and Zettlemoyer, L.
\newblock Don{'}t take the easy way out: Ensemble based methods for avoiding
  known dataset biases.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pp.\  4069--4082. Association
  for Computational Linguistics, November 2019.

\bibitem[Codevilla et~al.(2018)Codevilla, Miiller, L{\'o}pez, Koltun, and
  Dosovitskiy]{codevilla2018end}
Codevilla, F., Miiller, M., L{\'o}pez, A., Koltun, V., and Dosovitskiy, A.
\newblock End-to-end driving via conditional imitation learning.
\newblock In \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  1--9. IEEE, 2018.

\bibitem[Codevilla et~al.(2019)Codevilla, Santana, L{\'o}pez, and
  Gaidon]{codevilla2019exploring}
Codevilla, F., Santana, E., L{\'o}pez, A.~M., and Gaidon, A.
\newblock Exploring the limitations of behavior cloning for autonomous driving.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  9329--9338, 2019.

\bibitem[de~Haan et~al.(2019)de~Haan, Jayaraman, and Levine]{de2019causal}
de~Haan, P., Jayaraman, D., and Levine, S.
\newblock Causal confusion in imitation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 11698--11709, 2019.

\bibitem[Delage \& Ye(2010)Delage and Ye]{Delage2010DistributionallyRO}
Delage, E. and Ye, Y.
\newblock Distributionally robust optimization under moment uncertainty with
  application to data-driven problems.
\newblock \emph{Oper. Res.}, 58:\penalty0 595--612, 2010.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017improved}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Dosovitskiy et~al.(2017)Dosovitskiy, Ros, Codevilla, Lopez, and
  Koltun]{Dosovitskiy17}
Dosovitskiy, A., Ros, G., Codevilla, F., Lopez, A., and Koltun, V.
\newblock {CARLA}: {An} open urban driving simulator.
\newblock In \emph{Proceedings of the 1st Annual Conference on Robot Learning},
  pp.\  1--16, 2017.

\bibitem[Duchi \& Namkoong(2021)Duchi and Namkoong]{duchi2021learning}
Duchi, J.~C. and Namkoong, H.
\newblock Learning models with uniform performance via distributionally robust
  optimization.
\newblock \emph{The Annals of Statistics}, 49\penalty0 (3):\penalty0
  1378--1406, 2021.

\bibitem[Geirhos et~al.(2018)Geirhos, Temme, Rauber, Sch\"{u}tt, Bethge, and
  Wichmann]{geirhos2018generalisation}
Geirhos, R., Temme, C. R.~M., Rauber, J., Sch\"{u}tt, H.~H., Bethge, M., and
  Wichmann, F.~A.
\newblock Generalisation in humans and deep neural networks.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{GeirhosRMBWB19}
Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.~A., and
  Brendel, W.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock In \emph{ICLR}. OpenReview.net, 2019.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge,
  M., and Wichmann, F.~A.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (11):\penalty0
  665--673, 2020.

\bibitem[Giusti et~al.(2015)Giusti, Guzzi, Cire{\c{s}}an, He, Rodr{\'\i}guez,
  Fontana, Faessler, Forster, Schmidhuber, Di~Caro, et~al.]{giusti2015machine}
Giusti, A., Guzzi, J., Cire{\c{s}}an, D.~C., He, F.-L., Rodr{\'\i}guez, J.~P.,
  Fontana, F., Faessler, M., Forster, C., Schmidhuber, J., Di~Caro, G., et~al.
\newblock A machine learning approach to visual perception of forest trails for
  mobile robots.
\newblock \emph{IEEE Robotics and Automation Letters}, 1\penalty0 (2):\penalty0
  661--667, 2015.

\bibitem[He et~al.(2019)He, Zha, and Wang]{he2019unlearn}
He, H., Zha, S., and Wang, H.
\newblock Unlearn dataset bias in natural language inference by fitting the
  residual.
\newblock \emph{CoRR}, abs/1908.10763, 2019.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2021)He, Shen, and Cui]{he2021towards}
He, Y., Shen, Z., and Cui, P.
\newblock Towards non-iid image classification: A dataset and baselines.
\newblock \emph{Pattern Recognition}, 110:\penalty0 107383, 2021.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo,
  Desai, Zhu, Parajuli, Guo, Song, Steinhardt, and Gilmer]{Hendrycks2020TheMF}
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai,
  R., Zhu, T.~L., Parajuli, S., Guo, M., Song, D.~X., Steinhardt, J., and
  Gilmer, J.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock \emph{ArXiv}, abs/2006.16241, 2020.

\bibitem[Hu et~al.(2020{\natexlab{a}})Hu, Li, and Yu]{DBLP:conf/iclr/HuLY20}
Hu, W., Li, Z., and Yu, D.
\newblock Simple and effective regularization methods for training on noisily
  labeled data with generalization guarantee.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net,
  2020{\natexlab{a}}.

\bibitem[Hu et~al.(2020{\natexlab{b}})Hu, Xiao, Adlam, and
  Pennington]{DBLP:conf/nips/HuXAP20}
Hu, W., Xiao, L., Adlam, B., and Pennington, J.
\newblock The surprising simplicity of the early-time learning dynamics of
  neural networks.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020{\natexlab{b}}.

\bibitem[Hu et~al.(2020{\natexlab{c}})Hu, Xiao, Adlam, and
  Pennington]{hu2020surprising}
Hu, W., Xiao, L., Adlam, B., and Pennington, J.
\newblock The surprising simplicity of the early-time learning dynamics of
  neural networks.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  17116--17128. Curran Associates, Inc., 2020{\natexlab{c}}.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{jacot2018neural}
Jacot, A., Gabriel, F., and Hongler, C.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[Krueger et~al.(2021{\natexlab{a}})Krueger, Caballero, Jacobsen, Zhang,
  Binas, Priol, and Courville]{Krueger2021OutofDistributionGV}
Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Priol,
  R.~L., and Courville, A.~C.
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock In \emph{ICML}, 2021{\natexlab{a}}.

\bibitem[Krueger et~al.(2021{\natexlab{b}})Krueger, Caballero, Jacobsen, Zhang,
  Binas, Zhang, Le~Priol, and Courville]{krueger2021out}
Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Zhang, D.,
  Le~Priol, R., and Courville, A.
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5815--5826. PMLR, 2021{\natexlab{b}}.

\bibitem[Laskey et~al.(2017)Laskey, Dragan, Lee, Goldberg, and
  Fox]{laskey2017dart}
Laskey, M., Dragan, A., Lee, J., Goldberg, K., and Fox, R.
\newblock Dart: Optimizing noise injection in imitation learning.
\newblock In \emph{Conference on Robot Learning (CoRL)}, volume~2, pp.\ ~12,
  2017.

\bibitem[McCoy et~al.(2019)McCoy, Pavlick, and Linzen]{mccoy2019right}
McCoy, T., Pavlick, E., and Linzen, T.
\newblock Right for the wrong reasons: Diagnosing syntactic heuristics in
  natural language inference.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  3428--3448. Association for
  Computational Linguistics, July 2019.

\bibitem[Muhammad \& Yeasin(2020)Muhammad and Yeasin]{muhammad2020eigen}
Muhammad, M.~B. and Yeasin, M.
\newblock Eigen-cam: Class activation map using principal components.
\newblock In \emph{2020 International Joint Conference on Neural Networks
  (IJCNN)}, pp.\  1--7. IEEE, 2020.

\bibitem[Muller et~al.(2006)Muller, Ben, Cosatto, Flepp, and
  Cun]{muller2006off}
Muller, U., Ben, J., Cosatto, E., Flepp, B., and Cun, Y.~L.
\newblock Off-road obstacle avoidance through end-to-end learning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  739--746. Citeseer, 2006.

\bibitem[Niven \& Kao(2019)Niven and Kao]{niven2019probing}
Niven, T. and Kao, H.-Y.
\newblock Probing neural network comprehension of natural language arguments.
\newblock In \emph{Proceedings of the 57th Conference of the Association for
  Computational Linguistics}, pp.\  4658--4664. Association for Computational
  Linguistics, July 2019.

\bibitem[Oliva \& Torralba(2007)Oliva and Torralba]{oliva2007role}
Oliva, A. and Torralba, A.
\newblock The role of context in object recognition.
\newblock \emph{Trends in cognitive sciences}, 11\penalty0 (12):\penalty0
  520--527, 2007.

\bibitem[Ortega et~al.(2021)Ortega, Kunesch, Del{\'e}tang, Genewein, Grau-Moya,
  Veness, Buchli, Degrave, Piot, Perolat, et~al.]{ortega2021shaking}
Ortega, P.~A., Kunesch, M., Del{\'e}tang, G., Genewein, T., Grau-Moya, J.,
  Veness, J., Buchli, J., Degrave, J., Piot, B., Perolat, J., et~al.
\newblock Shaking the foundations: delusions in sequence models for interaction
  and control.
\newblock \emph{arXiv preprint arXiv:2110.10819}, 2021.

\bibitem[Pearl(1995)]{pearl1995causal}
Pearl, J.
\newblock Causal diagrams for empirical research.
\newblock \emph{Biometrika}, 82\penalty0 (4):\penalty0 669--688, 1995.

\bibitem[Prakash et~al.(2021)Prakash, Chitta, and Geiger]{prakash2021multi}
Prakash, A., Chitta, K., and Geiger, A.
\newblock Multi-modal fusion transformer for end-to-end autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  7077--7087, June 2021.

\bibitem[Qin et~al.(2019)Qin, Zhang, Huang, Gao, Dehghan, and
  Jagersand]{qin2019basnet}
Qin, X., Zhang, Z., Huang, C., Gao, C., Dehghan, M., and Jagersand, M.
\newblock Basnet: Boundary-aware salient object detection.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2019.

\bibitem[Rosenfeld et~al.(2018)Rosenfeld, Zemel, and
  Tsotsos]{rosenfeld2018elephant}
Rosenfeld, A., Zemel, R., and Tsotsos, J.~K.
\newblock The elephant in the room.
\newblock \emph{arXiv preprint arXiv:1808.03305}, 2018.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{Ross2011}
Ross, S., Gordon, G.~J., and Bagnell, J.~A.
\newblock {A reduction of imitation learning and structured prediction to
  no-regret online learning}.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 627--635,
  2011.
\newblock ISSN 15324435.

\bibitem[Rubin(1974)]{rubin1974estimating}
Rubin, D.~B.
\newblock Estimating causal effects of treatments in randomized and
  nonrandomized studies.
\newblock \emph{Journal of educational Psychology}, 66\penalty0 (5):\penalty0
  688, 1974.

\bibitem[Rubin(1978)]{rubin1978bayesian}
Rubin, D.~B.
\newblock Bayesian inference for causal effects: The role of randomization.
\newblock \emph{The Annals of statistics}, pp.\  34--58, 1978.

\bibitem[Sagawa et~al.(2019)Sagawa, Koh, Hashimoto, and
  Liang]{Sagawa2019DistributionallyRN}
Sagawa, S., Koh, P.~W., Hashimoto, T.~B., and Liang, P.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock \emph{ArXiv}, abs/1911.08731, 2019.

\bibitem[Sch{\"o}lkopf et~al.(2012)Sch{\"o}lkopf, Janzing, Peters, Sgouritsa,
  Zhang, and Mooij]{scholkopf2012causal}
Sch{\"o}lkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., and
  Mooij, J.
\newblock On causal and anticausal learning.
\newblock \emph{arXiv preprint arXiv:1206.6471}, 2012.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel,
  et~al.]{schrittwieser2020mastering}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Shah et~al.(2020)Shah, Tamuly, Raghunathan, Jain, and
  Netrapalli]{Shan2020pitfalls}
Shah, H., Tamuly, K., Raghunathan, A., Jain, P., and Netrapalli, P.
\newblock The pitfalls of simplicity bias in neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  9573--9585. Curran Associates, Inc., 2020.

\bibitem[Shen et~al.(2021)Shen, Liu, He, Zhang, Xu, Yu, and
  Cui]{Shen2021TowardsOG}
Shen, Z., Liu, J., He, Y., Zhang, X., Xu, R., Yu, H., and Cui, P.
\newblock Towards out-of-distribution generalization: A survey.
\newblock \emph{ArXiv}, abs/2108.13624, 2021.

\bibitem[Spencer et~al.(2021)Spencer, Choudhury, Venkatraman, Ziebart, and
  Bagnell]{spencer2021feedback}
Spencer, J., Choudhury, S., Venkatraman, A., Ziebart, B., and Bagnell, J.~A.
\newblock Feedback in imitation learning: The three regimes of covariate shift.
\newblock \emph{arXiv preprint arXiv:2102.02872}, 2021.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The journal of machine learning research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Vershynin(2018)]{vershynin_2018}
Vershynin, R.
\newblock \emph{High-Dimensional Probability: An Introduction with Applications
  in Data Science}.
\newblock Cambridge Series in Statistical and Probabilistic Mathematics.
  Cambridge University Press, 2018.
\newblock \doi{10.1017/9781108231596}.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Lan, Liu, Ouyang, and
  Qin]{Wang2021GeneralizingTU}
Wang, J., Lan, C., Liu, C., Ouyang, Y., and Qin, T.
\newblock Generalizing to unseen domains: A survey on domain generalization.
\newblock In \emph{IJCAI}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Zhou, Sun, and
  Zhang]{wang2021causal}
Wang, T., Zhou, C., Sun, Q., and Zhang, H.
\newblock Causal attention for unbiased visual recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2021{\natexlab{b}}.

\bibitem[Weingarten et~al.(2016)Weingarten, Chen, McAdams, Yi, Hepler, and
  Albarrac{\'\i}n]{weingarten2016primed}
Weingarten, E., Chen, Q., McAdams, M., Yi, J., Hepler, J., and Albarrac{\'\i}n,
  D.
\newblock From primed concepts to action: A meta-analysis of the behavioral
  effects of incidentally presented words.
\newblock \emph{Psychological bulletin}, 142\penalty0 (5):\penalty0 472, 2016.

\bibitem[Wen et~al.(2020)Wen, Lin, Darrell, Jayaraman, and
  Gao]{chuan2020fighting}
Wen, C., Lin, J., Darrell, T., Jayaraman, D., and Gao, Y.
\newblock Fighting copycat agents in behavioral cloning from observation
  histories.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem[Wen et~al.(2021)Wen, Lin, Qian, Gao, and Jayaraman]{chuan2021keframe}
Wen, C., Lin, J., Qian, J., Gao, Y., and Jayaraman, D.
\newblock Keyframe-focused visual imitation learning.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research. PMLR, 18--24 Jul 2021.

\bibitem[Xu et~al.(2021)Xu, Zhang, Zhang, Wang, and Tian]{xu2021fourier}
Xu, Q., Zhang, R., Zhang, Y., Wang, Y., and Tian, Q.
\newblock A fourier-based framework for domain generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  14383--14392, 2021.

\bibitem[Xu et~al.(2019)Xu, Zhang, Luo, Xiao, and Ma]{xu2019frequency}
Xu, Z.-Q.~J., Zhang, Y., Luo, T., Xiao, Y., and Ma, Z.
\newblock Frequency principle: Fourier analysis sheds light on deep neural
  networks.
\newblock \emph{arXiv preprint arXiv:1901.06523}, 2019.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, McAllister, Calandra, Gal, and
  Levine]{zhang2021learning}
Zhang, A., McAllister, R.~T., Calandra, R., Gal, Y., and Levine, S.
\newblock Learning invariant representations for reinforcement learning without
  reconstruction.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Cui, Xu, Zhou, He, and
  Shen]{zhang2021deep}
Zhang, X., Cui, P., Xu, R., Zhou, L., He, Y., and Shen, Z.
\newblock Deep stable learning for out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  5372--5382, 2021{\natexlab{b}}.

\bibitem[Zhang et~al.(2020)Zhang, Xu, Luo, and Ma]{DBLP:conf/msml/ZhangXLM20}
Zhang, Y., Xu, Z.~J., Luo, T., and Ma, Z.
\newblock A type of generalization error induced by initialization in deep
  neural networks.
\newblock In Lu, J. and Ward, R. (eds.), \emph{Proceedings of Mathematical and
  Scientific Machine Learning, {MSML} 2020, 20-24 July 2020, Princeton, NJ,
  {USA}}, volume 107 of \emph{Proceedings of Machine Learning Research}, pp.\
  144--164. {PMLR}, 2020.

\end{thebibliography}
