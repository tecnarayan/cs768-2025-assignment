\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Banner et~al.(2018)Banner, Nahshan, Hoffer, and
  Soudry]{banner2018aciq}
Banner, R., Nahshan, Y., Hoffer, E., and Soudry, D.
\newblock {ACIQ: Analytical Clipping for Integer Quantization of Neural
  Networks}.
\newblock \emph{arXiv e-print}, arXiv:1810.05723, Oct 2018.

\bibitem[Chen et~al.(2015)Chen, Li, Li, Lin, Wang, Wang, Xiao, Xu, Zhang, and
  Zhang]{chen2015mxnet}
Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang,
  C., and Zhang, Z.
\newblock {MXNet: A Flexible and Efficient Machine Learning Library for
  Heterogeneous Distributed Systems}.
\newblock \emph{arXiv preprint}, arXiv:1512.01274, Dec 2015.

\bibitem[Chen et~al.(2016)Chen, Goodfellow, and Shlens]{chen2015net2net}
Chen, T., Goodfellow, I., and Shlens, J.
\newblock {Net2net: Accelerating Learning via Knowledge Transfer}.
\newblock \emph{Int'l Conf. on Learning Representations (ICLR)}, May 2016.

\bibitem[Choi et~al.(2018{\natexlab{a}})Choi, Chuang, Wang, Venkataramani,
  Srinivasan, and Gopalakrishnan]{choi2018qnn}
Choi, J., Chuang, P. I.-J., Wang, Z., Venkataramani, S., Srinivasan, V., and
  Gopalakrishnan, K.
\newblock {Bridging the Accuracy Gap for 2-bit Quantized Neural Networks
  (QNN)}.
\newblock \emph{arXiv e-print}, arXiv:1807.06964, Jul 2018{\natexlab{a}}.

\bibitem[Choi et~al.(2018{\natexlab{b}})Choi, Wang, Venkataramani, Chuang,
  Srinivasan, and Gopalakrishnan]{choi2018pact}
Choi, J., Wang, Z., Venkataramani, S., Chuang, P. I.-J., Srinivasan, V., and
  Gopalakrishnan, K.
\newblock {PACT: Parameterized Clipping Activation for Quantized Neural
  Networks}.
\newblock \emph{arXiv e-print}, arXiv:1805.0608, May 2018{\natexlab{b}}.

\bibitem[Chung et~al.(2018)Chung, Fowers, Ovtcharov, Papamichael, Caulfield,
  Massengill, Liu, Lo, Alkalay, Haselman, Abeydeera, Adams, Angepat, Boehn,
  Chiou, Firestein, Forin, Gatlin, Ghandi, Heil, Holohan, Husseini, Juhasz,
  Kagi, Kovvuri, Lanka, van Megen, Mukhortov, Patel, Perez, Rapsang, Reinhardt,
  Rouhani, Sapek, Seera, Shekar, Sridharan, Weisz, Woods, Xiao, Zhang, Zhao, ,
  and Burger]{microsoft2018brainwave}
Chung, E., Fowers, J., Ovtcharov, K., Papamichael, M., Caulfield, A.,
  Massengill, T., Liu, M., Lo, D., Alkalay, S., Haselman, M., Abeydeera, M.,
  Adams, L., Angepat, H., Boehn, C., Chiou, D., Firestein, O., Forin, A.,
  Gatlin, K.~S., Ghandi, M., Heil, S., Holohan, K., Husseini, A.~E., Juhasz,
  T., Kagi, K., Kovvuri, R.~K., Lanka, S., van Megen, F., Mukhortov, D., Patel,
  P., Perez, B., Rapsang, A.~G., Reinhardt, S.~K., Rouhani, B.~D., Sapek, A.,
  Seera, R., Shekar, S., Sridharan, B., Weisz, G., Woods, L., Xiao, P.~Y.,
  Zhang, D., Zhao, R., , and Burger, D.
\newblock {Serving DNNs in Real Time at Datacenter Scale with Project Brainwave
  }.
\newblock \emph{IEEE Micro}, 38\penalty0 (2):\penalty0 8--20, 2018.

\bibitem[Courbariaux et~al.(2015)Courbariaux, Bengio, and
  David]{courbariaux2015binaryconnect}
Courbariaux, M., Bengio, Y., and David, J.-P.
\newblock {BinaryConnect: Training Deep Neural Networks with binary weights
  during propagations}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)}, pp.\
   3123--3131, 2015.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock \emph{Conf. on Computer Vision and Pattern Recognition (CVPR)}, pp.\
  248--255, 2009.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{han2016deep}
Han, S., Mao, H., and Dally, W.~J.
\newblock {Deep Compression: Compressing Deep Neural Networks with Pruning,
  Trained Quantization and Huffman Coding}.
\newblock \emph{Int'l Conf. on Learning Representations (ICLR)}, Feb 2016.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock {Deep Residual Learning for Image Recognition}.
\newblock \emph{arXiv e-print}, arXiv:1512.0338, Dec 2015.

\bibitem[Huang et~al.(2017)Huang, Liu, Weinberger, and van~der
  Maaten]{huang2017densenet}
Huang, G., Liu, Z., Weinberger, K.~Q., and van~der Maaten, L.
\newblock Densely connected convolutional networks.
\newblock \emph{Conf. on Computer Vision and Pattern Recognition (CVPR)},
  1\penalty0 (2):\penalty0 3, 2017.

\bibitem[Hubara et~al.(2017)Hubara, Courbariaux, Soudry, El-Yaniv, and
  Bengio]{hubara2017quantized}
Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., and Bengio, Y.
\newblock {Quantized Neural Networks: Training Neural Networks with Low
  Precision Weights and Activations}.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 18\penalty0
  (187):\penalty0 1--30, 2017.

\bibitem[Jacob et~al.(2018)Jacob, Kligys, Chen, Zhu, Tang, Howard, Adam, and
  Kalenichenko]{jacob2018quantization}
Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., and
  Kalenichenko, D.
\newblock {Quantization and Training of Neural Networks for Efficient
  Integer-Arithmetic-Only Inference}.
\newblock \emph{Conf. on Computer Vision and Pattern Recognition (CVPR)}, pp.\
  2704--2713, Jun 2018.

\bibitem[Jouppi et~al.(2017)Jouppi, Young, Patil, Patterson, Agrawal, Bajwa,
  Bates, Bhatia, Boden, Borchers, et~al.]{google2017tpu}
Jouppi, N.~P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R.,
  Bates, S., Bhatia, S., Boden, N., Borchers, A., et~al.
\newblock {In-Datacenter Performance Analysis of a Tensor Processing Unit}.
\newblock \emph{Int'l Symp. on Computer Architecture (ISCA)}, pp.\  1--12,
  2017.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{krizhevsky2009cifar}
Krizhevsky, A. and Hinton, G.
\newblock {Learning Multiple Layers of Features from Tiny Images}.
\newblock \emph{{Tech report}}, 2009.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014coco}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock {Microsoft COCO: Common Objects in Context}.
\newblock \emph{European Conference on Computer Vision (ECCV)}, pp.\  740--755,
  2014.

\bibitem[McKinstry et~al.(2018)McKinstry, Esser, Appuswamy, Bablani, Arthur,
  Yildiz, and Modha]{mckinstry2018clip}
McKinstry, J.~L., Esser, S.~K., Appuswamy, R., Bablani, D., Arthur, J.~V.,
  Yildiz, I.~B., and Modha, D.~S.
\newblock Discovering low-precision networks close to full-precision networks
  for efficient embedded inference.
\newblock \emph{arXiv preprint}, arXiv:1809.04191, Sep 2018.

\bibitem[Merity et~al.(2016)Merity, Xiong, Bradbury, and
  Socher]{merity2016pointer}
Merity, S., Xiong, C., Bradbury, J., and Socher, R.
\newblock {Pointer Sentinel Mixture Models}.
\newblock \emph{arXiv preprint}, arXiv:1609.07843, Sep 2016.

\bibitem[Migacz(2017)]{tensorrt2017slides}
Migacz, S.
\newblock {8-bit Inference with TensorRT}.
\newblock \emph{NVIDIA GPU Technology Conference}, May 2017.

\bibitem[Park et~al.(2018{\natexlab{a}})Park, Kim, and Yoo]{park2018outlier}
Park, E., Kim, D., and Yoo, S.
\newblock {Energy-Efficient Neural Network Accelerator Based on Outlier-Aware
  Low-Precision Computation}.
\newblock \emph{Int'l Symp. on Computer Architecture (ISCA)}, Jun
  2018{\natexlab{a}}.

\bibitem[Park et~al.(2018{\natexlab{b}})Park, Yoo, and Vajda]{park2018value}
Park, E., Yoo, S., and Vajda, P.
\newblock {Value-aware Quantization for Training and Inference of Neural
  Networks}.
\newblock \emph{arXiv e-print}, arXiv:1804.07802, Apr 2018{\natexlab{b}}.

\bibitem[Park \& Choi(2019)Park and Choi]{park2019celldiv}
Park, H. and Choi, K.
\newblock {Cell Division: Weight Bit-Width Reduction Technique for
  Convolutional Neural Network Hardware Accelerators}.
\newblock \emph{Asia and South Pacific Design Automation Conf. (ASP-DAC)}, pp.\
   286--291, Jan 2019.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017pytorch}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock {Automatic Differentiation in PyTorch}.
\newblock \emph{Advances in Neural Information Processing Systems Workshops
  (NIPS-W)}, 2017.

\bibitem[Savchev \& Andreescu(2003)Savchev and Andreescu]{hermites}
Savchev, S. and Andreescu, T.
\newblock \emph{{Mathematical Miniatures}}, chapter 12. Hermite's Identity,
  pp.\  41--44.
\newblock Mathematical Association of America, 2003.

\bibitem[Settle et~al.(2018)Settle, Bollavaram, D'Alberto, Delaye, Fernandez,
  Fraser, Ng, Sirasao, and Wu]{settle2018quantizing}
Settle, S.~O., Bollavaram, M., D'Alberto, P., Delaye, E., Fernandez, O.,
  Fraser, N., Ng, A., Sirasao, A., and Wu, M.
\newblock {Quantizing Convolutional Neural Networks for Low-Power
  High-Throughput Inference Engines}.
\newblock \emph{arXiv preprint}, arXiv:1805.07941, May 2018.

\bibitem[Shin et~al.(2016)Shin, Hwang, and Sung]{shin2016fixed}
Shin, S., Hwang, K., and Sung, W.
\newblock {Fixed-Point Performance Analysis of Recurrent Neural Networks}.
\newblock \emph{Int'l Conf. on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp.\  976--980, 2016.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{simonyan2015vgg}
Simonyan, K. and Zisserman, A.
\newblock {Very Deep Convolutional Networks for Large-Scale Image Recognition}.
\newblock \emph{arXiv e-print}, arXiv:1409.15568, Apr 2015.

\bibitem[Sung et~al.(2015)Sung, Shin, and Hwang]{sung2015resiliency}
Sung, W., Shin, S., and Hwang, K.
\newblock {Resiliency of Deep Neural Networks Under Quantization}.
\newblock \emph{arXiv preprint arXiv:1511.06488}, 2015.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015inception}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
  Vanhoucke, V., and Rabinovich, A.
\newblock {Going Deeper with Convolutions}.
\newblock \emph{Conf. on Computer Vision and Pattern Recognition (CVPR)}, 2015.

\bibitem[Wu et~al.(2018)Wu, Li, Chen, and Shi]{wu2018training}
Wu, S., Li, G., Chen, F., and Shi, L.
\newblock {Training and Inference with Integers in Deep Neural Networks}.
\newblock \emph{Int'l Conf. on Learning Representations (ICLR)}, May 2018.

\bibitem[Xu et~al.(2018)Xu, Ding, Hu, Niemier, Cong, Hu, and
  Shi]{xu2018scaling}
Xu, X., Ding, Y., Hu, S.~X., Niemier, M., Cong, J., Hu, Y., and Shi, Y.
\newblock {Scaling for Edge Inference of Deep Neural Networks}.
\newblock \emph{Nature Electronics}, 1\penalty0 (4):\penalty0 216, 2018.

\bibitem[Zaremba et~al.(2014)Zaremba, Sutskever, and
  Vinyals]{zaremba2014recurrent}
Zaremba, W., Sutskever, I., and Vinyals, O.
\newblock Recurrent neural network regularization.
\newblock \emph{arXiv preprint arXiv:1409.2329}, 2014.

\bibitem[Zhou et~al.(2017)Zhou, Yao, Guo, Xu, and Chen]{zhou2017incremental}
Zhou, A., Yao, A., Guo, Y., Xu, L., and Chen, Y.
\newblock {Incremental Network Quantization: Towards Lossless CNNs with
  Low-Precision Weights}.
\newblock \emph{arXiv preprint}, arXiv:1702.03044, 2017.

\bibitem[Zhuang et~al.(2018)Zhuang, Shen, Tan, Liu, and
  Reid]{zhuang2018towards}
Zhuang, B., Shen, C., Tan, M., Liu, L., and Reid, I.
\newblock {Towards Effective Low-Bitwidth Convolutional Neural Networks}.
\newblock \emph{Conf. on Computer Vision and Pattern Recognition (CVPR)}, pp.\
  7920--7928, Jun 2018.

\end{thebibliography}
