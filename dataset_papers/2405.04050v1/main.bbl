\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aoudia \& Hoydis(2018)Aoudia and Hoydis]{aoudia2018end}
Aoudia, F.~A. and Hoydis, J.
\newblock End-to-end learning of communications systems without a channel model.
\newblock In \emph{2018 52nd Asilomar Conference on Signals, Systems, and Computers}, pp.\  298--303. IEEE, 2018.

\bibitem[Arikan(2008)]{arikan2008channel}
Arikan, E.
\newblock Channel polarization: A method for constructing capacity-achieving codes.
\newblock In \emph{2008 IEEE International Symposium on Information Theory}, pp.\  1173--1177. IEEE, 2008.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and Courville]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Bennatan et~al.(2018)Bennatan, Choukroun, and Kisilev]{bennatan2018deep}
Bennatan, A., Choukroun, Y., and Kisilev, P.
\newblock Deep learning for decoding of linear codes-a syndrome-based approach.
\newblock In \emph{2018 IEEE International Symposium on Information Theory (ISIT)}, pp.\  1595--1599. IEEE, 2018.

\bibitem[Bose \& Ray-Chaudhuri(1960)Bose and Ray-Chaudhuri]{bose1960class}
Bose, R.~C. and Ray-Chaudhuri, D.~K.
\newblock On a class of error correcting binary group codes.
\newblock \emph{Information and control}, 3\penalty0 (1):\penalty0 68--79, 1960.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020gpt3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Cammerer et~al.(2017)Cammerer, Gruber, Hoydis, and ten Brink]{cammerer2017scaling}
Cammerer, S., Gruber, T., Hoydis, J., and ten Brink, S.
\newblock Scaling deep learning-based decoding of polar codes via partitioning.
\newblock In \emph{GLOBECOM 2017-2017 IEEE Global Communications Conference}, pp.\  1--6. IEEE, 2017.

\bibitem[Cammerer et~al.(2022)Cammerer, Hoydis, Aoudia, and Keller]{cammerer2022graph}
Cammerer, S., Hoydis, J., Aoudia, F.~A., and Keller, A.
\newblock Graph neural networks for channel decoding.
\newblock In \emph{2022 IEEE Globecom Workshops (GC Wkshps)}, pp.\  486--491. IEEE, 2022.

\bibitem[Cassagne et~al.(2019)Cassagne, Hartmann, L\'eonardon, He, Leroux, Tajan, Aumage, Barthou, Tonnellier, Pignoly, {Le Gal}, and J\'ego]{Cassagne2019a}
Cassagne, A., Hartmann, O., L\'eonardon, M., He, K., Leroux, C., Tajan, R., Aumage, O., Barthou, D., Tonnellier, T., Pignoly, V., {Le Gal}, B., and J\'ego, C.
\newblock Aff3ct: A fast forward error correction toolbox!
\newblock \emph{Elsevier SoftwareX}, 10:\penalty0 100345, October 2019.
\newblock ISSN 2352-7110.
\newblock \doi{https://doi.org/10.1016/j.softx.2019.100345}.
\newblock URL \url{http://www.sciencedirect.com/science/article/pii/S2352711019300457}.

\bibitem[Choukroun \& Wolf(2022)Choukroun and Wolf]{choukroun2022error}
Choukroun, Y. and Wolf, L.
\newblock Error correction code transformer.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Choukroun \& Wolf(2023)Choukroun and Wolf]{choukroun2022zdenoising}
Choukroun, Y. and Wolf, L.
\newblock Denoising diffusion error correction codes.
\newblock In \emph{The Eleventh International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[Choukroun \& Wolf(2024{\natexlab{a}})Choukroun and Wolf]{choukroun2023deep}
Choukroun, Y. and Wolf, L.
\newblock Deep quantum error correction.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pp.\  64--72, 2024{\natexlab{a}}.

\bibitem[Choukroun \& Wolf(2024{\natexlab{b}})Choukroun and Wolf]{choukroun2024found}
Choukroun, Y. and Wolf, L.
\newblock A foundation model for error correction codes.
\newblock In \emph{The Twelfth International Conference on Learning Representations (ICLR)}, 2024{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=7KDuQPrAF3}.

\bibitem[Courbariaux et~al.(2015)Courbariaux, Bengio, and David]{courbariaux2015binaryconnect}
Courbariaux, M., Bengio, Y., and David, J.-P.
\newblock Binaryconnect: Training deep neural networks with binary weights during propagations.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[ESTI(2021)]{ETSI}
ESTI.
\newblock 5g nr multiplexing and channel coding. etsi 3gpp ts 38.212.
\newblock \url{https://www.etsi.org/deliver/etsi_ts/138200_138299/138212/16.02.00_60/ts_138212v160200p.pdf}, 2021.

\bibitem[Gallager(1962)]{gallager1962low}
Gallager, R.
\newblock Low-density parity-check codes.
\newblock \emph{IRE Transactions on information theory}, 8\penalty0 (1):\penalty0 21--28, 1962.

\bibitem[Glorot \& Bengio(2010)Glorot and Bengio]{glorot2010understanding}
Glorot, X. and Bengio, Y.
\newblock Understanding the difficulty of training deep feedforward neural networks.
\newblock In \emph{Proceedings of the thirteenth international conference on artificial intelligence and statistics}, pp.\  249--256. JMLR Workshop and Conference Proceedings, 2010.

\bibitem[Gruber et~al.(2017)Gruber, Cammerer, Hoydis, and ten Brink]{gruber2017deep}
Gruber, T., Cammerer, S., Hoydis, J., and ten Brink, S.
\newblock On deep learning-based channel decoding.
\newblock In \emph{2017 51st Annual Conference on Information Sciences and Systems (CISS)}, pp.\  1--6. IEEE, 2017.

\bibitem[Helmling et~al.(2019)Helmling, Scholl, Gensheimer, Dietz, Kraft, Ruzika, and Wehn]{channelcodes}
Helmling, M., Scholl, S., Gensheimer, F., Dietz, T., Kraft, K., Ruzika, S., and Wehn, N.
\newblock {D}atabase of {C}hannel {C}odes and {ML} {S}imulation {R}esults.
\newblock \url{www.uni-kl.de/channel-codes}, 2019.

\bibitem[Hoydis et~al.(2022)Hoydis, Cammerer, {Ait Aoudia}, Vem, Binder, Marcus, and Keller]{sionna}
Hoydis, J., Cammerer, S., {Ait Aoudia}, F., Vem, A., Binder, N., Marcus, G., and Keller, A.
\newblock Sionna: An open-source library for next-generation physical layer research.
\newblock \emph{arXiv preprint}, Mar. 2022.

\bibitem[Jiang et~al.(2019{\natexlab{a}})Jiang, Kannan, Kim, Oh, Asnani, and Viswanath]{jiang2019deepturbo}
Jiang, Y., Kannan, S., Kim, H., Oh, S., Asnani, H., and Viswanath, P.
\newblock Deepturbo: Deep turbo decoder.
\newblock In \emph{2019 IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)}, pp.\  1--5. IEEE, 2019{\natexlab{a}}.

\bibitem[Jiang et~al.(2019{\natexlab{b}})Jiang, Kim, Asnani, Kannan, Oh, and Viswanath]{jiang2019turbo}
Jiang, Y., Kim, H., Asnani, H., Kannan, S., Oh, S., and Viswanath, P.
\newblock Turbo autoencoder: Deep learning based channel codes for point-to-point communication channels.
\newblock \emph{Advances in neural information processing systems}, 32, 2019{\natexlab{b}}.

\bibitem[Kim et~al.(2018{\natexlab{a}})Kim, Jiang, Kannan, Oh, and Viswanath]{kim2018deepcode}
Kim, H., Jiang, Y., Kannan, S., Oh, S., and Viswanath, P.
\newblock Deepcode: Feedback codes via deep learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}, pp.\  9436--9446, 2018{\natexlab{a}}.

\bibitem[Kim et~al.(2018{\natexlab{b}})Kim, Jiang, Rana, Kannan, Oh, and Viswanath]{kim2018communication}
Kim, H., Jiang, Y., Rana, R., Kannan, S., Oh, S., and Viswanath, P.
\newblock Communication algorithms via deep learning.
\newblock In \emph{Sixth International Conference on Learning Representations (ICLR)}, 2018{\natexlab{b}}.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Klein et~al.(2017)Klein, Kim, Deng, Senellart, and Rush]{opennmt}
Klein, G., Kim, Y., Deng, Y., Senellart, J., and Rush, A.~M.
\newblock Opennmt: Open-source toolkit for neural machine translation.
\newblock In \emph{Proc. ACL}, 2017.
\newblock \doi{10.18653/v1/P17-4012}.
\newblock URL \url{https://doi.org/10.18653/v1/P17-4012}.

\bibitem[Kwak et~al.(2023)Kwak, Yun, Kim, Kim, and No]{kwak2023boosting}
Kwak, H.-Y., Yun, D.-Y., Kim, Y., Kim, S.-H., and No, J.-S.
\newblock Boosting learning for ldpc codes to improve the error-floor performance.
\newblock \emph{arXiv preprint arXiv:2310.07194}, 2023.

\bibitem[Lin et~al.(2021)Lin, Wang, Liu, and Qiu]{lin2021survey}
Lin, T., Wang, Y., Liu, X., and Qiu, X.
\newblock A survey of transformers.
\newblock \emph{arXiv preprint arXiv:2106.04554}, 2021.

\bibitem[Nachmani \& Wolf(2019)Nachmani and Wolf]{nachmani2019hyper}
Nachmani, E. and Wolf, L.
\newblock Hyper-graph-network decoders for block codes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  2326--2336, 2019.

\bibitem[Nachmani \& Wolf(2021)Nachmani and Wolf]{nachmani2021autoregressive}
Nachmani, E. and Wolf, L.
\newblock Autoregressive belief propagation for decoding block codes.
\newblock \emph{arXiv preprint arXiv:2103.11780}, 2021.

\bibitem[Nachmani et~al.(2016)Nachmani, Be'ery, and Burshtein]{nachmani2016learning}
Nachmani, E., Be'ery, Y., and Burshtein, D.
\newblock Learning to decode linear codes using deep learning.
\newblock In \emph{2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, pp.\  341--346. IEEE, 2016.

\bibitem[O'Shea \& Hoydis(2017)O'Shea and Hoydis]{AutoencoderComm}
O'Shea, T.~J. and Hoydis, J.
\newblock An introduction to machine learning communications systems.
\newblock \emph{arXiv preprint arXiv:1702.00832}, 2017.

\bibitem[Park et~al.(2023)Park, Kwak, Kim, Kim, Kim, and No]{park2023mask}
Park, S.-J., Kwak, H.-Y., Kim, S.-H., Kim, S., Kim, Y., and No, J.-S.
\newblock How to mask in error correction code transformer: Systematic and double masking.
\newblock \emph{arXiv preprint arXiv:2308.08128}, 2023.

\bibitem[Pearl(1988)]{pearl1988probabilistic}
Pearl, J.
\newblock \emph{Probabilistic reasoning in intelligent systems: networks of plausible inference}.
\newblock Morgan kaufmann, 1988.

\bibitem[Raviv et~al.(2020)Raviv, Caciularu, Raviv, Goldberger, and Be'ery]{raviv2020graph}
Raviv, N., Caciularu, A., Raviv, T., Goldberger, J., and Be'ery, Y.
\newblock perm2vec: Graph permutation selection for decoding of error correction codes using self-attention.
\newblock \emph{arXiv preprint arXiv:2002.02315}, 2020.

\bibitem[Raviv et~al.(2023)Raviv, Goldmann, Vayner, Be'ery, and Shlezinger]{raviv2023crc}
Raviv, T., Goldmann, A., Vayner, O., Be'ery, Y., and Shlezinger, N.
\newblock Crc-aided learned ensembles of belief-propagation polar decoders.
\newblock \emph{arXiv preprint arXiv:2301.06060}, 2023.

\bibitem[Reed \& Solomon(1960)Reed and Solomon]{reed1960polynomial}
Reed, I.~S. and Solomon, G.
\newblock Polynomial codes over certain finite fields.
\newblock \emph{Journal of the society for industrial and applied mathematics}, 8\penalty0 (2):\penalty0 300--304, 1960.

\bibitem[Richardson et~al.(2001)Richardson, Shokrollahi, and Urbanke]{richardson2001design}
Richardson, T.~J., Shokrollahi, M.~A., and Urbanke, R.~L.
\newblock Design of capacity-approaching irregular low-density parity-check codes.
\newblock \emph{IEEE transactions on information theory}, 47\penalty0 (2):\penalty0 619--637, 2001.

\bibitem[Shannon(1948)]{shannon1948mathematical}
Shannon, C.~E.
\newblock A mathematical theory of communication.
\newblock \emph{The Bell system technical journal}, 27\penalty0 (3):\penalty0 379--423, 1948.

\bibitem[Shazeer(2020)]{shazeer2020glu}
Shazeer, N.
\newblock Glu variants improve transformer.
\newblock \emph{arXiv preprint arXiv:2002.05202}, 2020.

\bibitem[Tal \& Vardy(2015)Tal and Vardy]{tal2015list}
Tal, I. and Vardy, A.
\newblock List decoding of polar codes.
\newblock \emph{IEEE Transactions on Information Theory}, 61\penalty0 (5):\penalty0 2213--2226, 2015.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\  5998--6008, 2017.

\bibitem[Wang et~al.(2020)Wang, Li, Khabsa, Fang, and Ma]{wang2020linformer}
Wang, S., Li, B.~Z., Khabsa, M., Fang, H., and Ma, H.
\newblock Linformer: Self-attention with linear complexity.
\newblock \emph{arXiv preprint arXiv:2006.04768}, 2020.

\bibitem[Xiong et~al.(2020)Xiong, Yang, He, Zheng, Zheng, Xing, Zhang, Lan, Wang, and Liu]{xiong2020layer}
Xiong, R., Yang, Y., He, D., Zheng, K., Zheng, S., Xing, C., Zhang, H., Lan, Y., Wang, L., and Liu, T.
\newblock On layer normalization in the transformer architecture.
\newblock In \emph{International Conference on Machine Learning}, pp.\  10524--10533. PMLR, 2020.

\bibitem[Ye et~al.(2018)Ye, Li, Juang, and Sivanesan]{ye2018channel}
Ye, H., Li, G.~Y., Juang, B.-H.~F., and Sivanesan, K.
\newblock Channel agnostic end-to-end learning based communication systems with conditional gan.
\newblock In \emph{2018 IEEE Globecom Workshops (GC Wkshps)}, pp.\  1--5. IEEE, 2018.

\end{thebibliography}
