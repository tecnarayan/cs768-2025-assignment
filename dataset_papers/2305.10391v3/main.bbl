\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adcock et~al.(2013)Adcock, Sullivan, and Mahoney]{adcock2013tree}
A.~B. Adcock, B.~D. Sullivan, and M.~W. Mahoney.
\newblock Tree-like structure in large social and information networks.
\newblock In \emph{2013 IEEE 13th International Conference on Data Mining},
  pages 1--10, 2013.
\newblock \doi{10.1109/ICDM.2013.77}.

\bibitem[Backstrom and Leskovec(2011)]{backstrom2011supervised}
L.~Backstrom and J.~Leskovec.
\newblock {Supervised random walks: predicting and recommending links in social
  networks}.
\newblock In \emph{Proceedings of the fourth ACM international conference on
  Web search and data mining}, pages 635--644, 2011.

\bibitem[Balcilar et~al.(2021)Balcilar, Renton, H{\'e}roux, Ga{\"u}z{\`e}re,
  Adam, and Honeine]{balcilar2021analyzing}
M.~Balcilar, G.~Renton, P.~H{\'e}roux, B.~Ga{\"u}z{\`e}re, S.~Adam, and
  P.~Honeine.
\newblock {Analyzing the Expressive Power of Graph Neural Networks in a
  Spectral Perspective}.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Bapst et~al.(2020)Bapst, Keck, Grabska-Barwi{\'n}ska, Donner, Cubuk,
  Schoenholz, Obika, Nelson, Back, Hassabis, et~al.]{bapst2020unveiling}
V.~Bapst, T.~Keck, A.~Grabska-Barwi{\'n}ska, C.~Donner, E.~D. Cubuk, S.~S.
  Schoenholz, A.~Obika, A.~W. Nelson, T.~Back, D.~Hassabis, et~al.
\newblock {Unveiling the predictive power of static structure in glassy
  systems}.
\newblock \emph{Nature Physics}, 16\penalty0 (4):\penalty0 448--454, 2020.

\bibitem[Baranwal et~al.(2021)Baranwal, Fountoulakis, and
  Jagannath]{pmlr-v139-baranwal21a}
A.~Baranwal, K.~Fountoulakis, and A.~Jagannath.
\newblock {Graph Convolution for Semi-Supervised Classification: Improved
  Linear Separability and Out-of-Distribution Generalization}.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, volume 139 of \emph{Proc. of Mach. Learn. Res.}, pages 684--693.
  PMLR, 18--24 Jul 2021.

\bibitem[Baranwal et~al.(2023)Baranwal, Fountoulakis, and
  Jagannath]{baranwal2023effects}
A.~Baranwal, K.~Fountoulakis, and A.~Jagannath.
\newblock {Effects of Graph Convolutions in Multi-layer Networks}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Barbour and Chen(2005)]{barbour2005introduction}
A.~D. Barbour and L.~H.~Y. Chen.
\newblock \emph{An introduction to {S}tein's method}, volume~4.
\newblock World Scientific, 2005.

\bibitem[Battaglia et~al.(2016)Battaglia, Pascanu, Lai, Rezende, and
  Kavukcuoglu]{battaglia:graphnets}
P.~Battaglia, R.~Pascanu, M.~Lai, D.~J. Rezende, and K.~Kavukcuoglu.
\newblock {Interaction Networks for Learning about Objects, Relations and
  Physics}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2016.

\bibitem[Bordenave(2016)]{bordenave2016lecture}
C.~Bordenave.
\newblock Lecture notes on random graphs and probabilistic combinatorial
  optimization, 2016.

\bibitem[Chen(1975)]{stein-chen1975}
L.~H.~Y. Chen.
\newblock {Poisson Approximation for Dependent Trials}.
\newblock \emph{The Annals of Probability}, 3\penalty0 (3):\penalty0 534 --
  545, 1975.

\bibitem[Chen et~al.(2020)Chen, Wei, Huang, Ding, and Li]{chen2020simple}
M.~Chen, Z.~Wei, Z.~Huang, B.~Ding, and Y.~Li.
\newblock {Simple and Deep Graph Convolutional Networks}.
\newblock In H.~D. III and A.~Singh, editors, \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 1725--1735. PMLR,
  13--18 Jul 2020.

\bibitem[Chen et~al.(2019)Chen, Villar, Chen, and Bruna]{Chen2019Equivalence}
Z.~Chen, S.~Villar, L.~Chen, and J.~Bruna.
\newblock On the equivalence between graph isomorphism testing and function
  approximation with {GNN}s.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Chien et~al.(2022)Chien, Chang, Hsieh, Yu, Zhang, Milenkovic, and
  Dhillon]{chien2022node}
E.~Chien, W.-C. Chang, C.-J. Hsieh, H.-F. Yu, J.~Zhang, O.~Milenkovic, and
  I.~S. Dhillon.
\newblock {Node Feature Extraction by Self-Supervised Multi-scale Neighborhood
  Prediction}.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Chung and Lu(2001)]{chung2001diameter}
F.~Chung and L.~Lu.
\newblock The diameter of sparse random graphs.
\newblock \emph{Advances in Applied Mathematics}, 26\penalty0 (4):\penalty0
  257--279, 2001.

\bibitem[Deshpande et~al.(2018)Deshpande, Sen, Montanari, and Mossel]{DSM18}
Y.~Deshpande, S.~Sen, A.~Montanari, and E.~Mossel.
\newblock {Contextual Stochastic Block Models}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Dreier et~al.(2018)Dreier, Kuinke, Le~Xuan, et~al.]{dreier2018local}
J.~Dreier, P.~Kuinke, B.~Le~Xuan, et~al.
\newblock {Local Structure Theorems for Erdos--R\'enyi Graphs and Their
  Algorithmic Applications}.
\newblock \emph{SOFSEM 2018: Theory and Practice of Computer Science LNCS
  10706}, page 125, 2018.

\bibitem[Feng et~al.(2022)Feng, Chen, Li, Sarkar, and Zhang]{feng2022how}
J.~Feng, Y.~Chen, F.~Li, A.~Sarkar, and M.~Zhang.
\newblock How powerful are k-hop message passing graph neural networks.
\newblock In A.~H. Oh, A.~Agarwal, D.~Belgrave, and K.~Cho, editors,
  \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Fey and Lenssen(2019)]{FL2019}
M.~Fey and J.~E. Lenssen.
\newblock {Fast Graph Representation Learning with {PyTorch Geometric}}.
\newblock In \emph{ICLR Workshop on Representation Learning on Graphs and
  Manifolds}, 2019.

\bibitem[Fountoulakis et~al.(2022)Fountoulakis, He, Lattanzi, Perozzi,
  Tsitsulin, and Yang]{fountoulakis2022classification}
K.~Fountoulakis, D.~He, S.~Lattanzi, B.~Perozzi, A.~Tsitsulin, and S.~Yang.
\newblock On classification thresholds for graph attention with edge features.
\newblock \emph{arXiv preprint arXiv:2210.10014}, 2022.

\bibitem[Fountoulakis et~al.(2023)Fountoulakis, Levi, Yang, Baranwal, and
  Jagannath]{Fountoulakis2022GraphAR}
K.~Fountoulakis, A.~Levi, S.~Yang, A.~Baranwal, and A.~Jagannath.
\newblock Graph attention retrospective.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0
  (246):\penalty0 1--52, 2023.
\newblock URL \url{http://jmlr.org/papers/v24/22-125.html}.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer:quantum}
J.~Gilmer, S.~S. Schoenholz, P.~F. Riley, O.~Vinyals, and G.~E. Dahl.
\newblock {Neural Message Passing for Quantum Chemistry}.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 2017.

\bibitem[Gosch et~al.(2023)Gosch, Sturm, Geisler, and
  G{\"u}nnemann]{gosch2023revisiting}
L.~Gosch, D.~Sturm, S.~Geisler, and S.~G{\"u}nnemann.
\newblock Revisiting robustness in graph machine learning.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=h1o7Ry9Zctm}.

\bibitem[Hao et~al.(2020)Hao, Zhao, Li, Dong, Faloutsos, Sun, and
  Wang]{hao2020p}
J.~Hao, T.~Zhao, J.~Li, X.~L. Dong, C.~Faloutsos, Y.~Sun, and W.~Wang.
\newblock P-companion: A principled framework for diversified complementary
  product recommendation.
\newblock In \emph{Proceedings of the 29th ACM International Conference on
  Information \& Knowledge Management}, pages 2517--2524, 2020.

\bibitem[Holland et~al.(1983)Holland, Laskey, and
  Leinhardt]{holland83stochastic}
P.~W. Holland, K.~B. Laskey, and S.~Leinhardt.
\newblock {Stochastic blockmodels: First steps}.
\newblock \emph{Social networks}, 5\penalty0 (2):\penalty0 109--137, 1983.

\bibitem[Hu et~al.(2020)Hu, Fey, Zitnik, Dong, Ren, Liu, Catasta, and
  Leskovec]{ogb}
W.~Hu, M.~Fey, M.~Zitnik, Y.~Dong, H.~Ren, B.~Liu, M.~Catasta, and J.~Leskovec.
\newblock {Open Graph Benchmark: Datasets for Machine Learning on Graphs}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Javaloy et~al.(2022)Javaloy, Martin, Levi, and
  Valera]{javaloy2022learnable}
A.~Javaloy, P.~S. Martin, A.~Levi, and I.~Valera.
\newblock Learnable graph convolutional attention networks.
\newblock In \emph{Has it Trained Yet? NeurIPS 2022 Workshop}, 2022.

\bibitem[Keriven(2022)]{keriven2022not}
N.~Keriven.
\newblock Not too little, not too much: a theoretical analysis of graph
  (over)smoothing.
\newblock In A.~H. Oh, A.~Agarwal, D.~Belgrave, and K.~Cho, editors,
  \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Keriven et~al.(2021)Keriven, Bietti, and
  Vaiter]{keriven2021universality}
N.~Keriven, A.~Bietti, and S.~Vaiter.
\newblock On the universality of graph neural networks on large random graphs.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~W.
  Vaughan, editors, \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 6960--6971. Curran Associates, Inc., 2021.

\bibitem[Kipf and Welling(2017)]{kipf:gcn}
T.~N. Kipf and M.~Welling.
\newblock {Semi-supervised classification with graph convolutional networks}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Li et~al.(2018)Li, Han, and Wu]{li2018deeper}
Q.~Li, Z.~Han, and X.-M. Wu.
\newblock {Deeper insights into graph convolutional networks for
  semi-supervised learning}.
\newblock In \emph{Thirty-Second AAAI conference on artificial intelligence},
  2018.

\bibitem[Liu et~al.(2022)Liu, Jing, Zhao, Huang, and Wu]{liu2022enhancing}
S.~Liu, S.~Jing, T.~Zhao, Z.~Huang, and D.~Wu.
\newblock {Enhancing Multi-hop Connectivity for Graph Convolutional Networks}.
\newblock In \emph{First Workshop on Pre-training: Perspectives, Pitfalls, and
  Paths Forward at ICML 2022}, 2022.

\bibitem[Lu and Sen(2020)]{Lu:2020:contextual}
C.~Lu and S.~Sen.
\newblock {Contextual Stochastic Block Model: Sharp Thresholds and Contiguity}.
\newblock \emph{ArXiv}, 2020.
\newblock arXiv:2011.09841.

\bibitem[Lu et~al.(2017)Lu, Pu, Wang, Hu, and Wang]{zhou2017expressive}
Z.~Lu, H.~Pu, F.~Wang, Z.~Hu, and L.~Wang.
\newblock The expressive power of neural networks: A view from the width.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem[Maron et~al.(2019)Maron, Ben-Hamu, Shamir, and
  Lipman]{maron2018invariant}
H.~Maron, H.~Ben-Hamu, N.~Shamir, and Y.~Lipman.
\newblock Invariant and equivariant graph networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Maskey et~al.(2022)Maskey, Levie, Lee, and
  Kutyniok]{maskey2022generalization}
S.~Maskey, R.~Levie, Y.~Lee, and G.~Kutyniok.
\newblock Generalization analysis of message passing neural networks on large
  random graphs.
\newblock In A.~H. Oh, A.~Agarwal, D.~Belgrave, and K.~Cho, editors,
  \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Massouli\'{e}(2014)]{massoulie2014community}
L.~Massouli\'{e}.
\newblock {Community Detection Thresholds and the Weak Ramanujan Property}.
\newblock In \emph{Proceedings of the Forty-Sixth Annual ACM Symposium on
  Theory of Computing}, page 694–703, 2014.

\bibitem[Mirhoseini et~al.(2021)Mirhoseini, Goldie, Yazgan, Jiang, Songhori,
  Wang, Lee, Johnson, Pathak, Nazi, et~al.]{mirhoseini2021graph}
A.~Mirhoseini, A.~Goldie, M.~Yazgan, J.~W. Jiang, E.~Songhori, S.~Wang, Y.-J.
  Lee, E.~Johnson, O.~Pathak, A.~Nazi, et~al.
\newblock A graph placement methodology for fast chip design.
\newblock \emph{Nature}, 594\penalty0 (7862):\penalty0 207--212, 2021.

\bibitem[Monti et~al.(2017)Monti, Boscaini, Masci, Rodola, Svoboda, and
  Bronstein]{Monti_2017_CVPR}
F.~Monti, D.~Boscaini, J.~Masci, E.~Rodola, J.~Svoboda, and M.~M. Bronstein.
\newblock {Geometric Deep Learning on Graphs and Manifolds Using Mixture Model
  CNNs}.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, July 2017.

\bibitem[Mossel et~al.(2015)Mossel, Neeman, and Sly]{mossel2015reconstruction}
E.~Mossel, J.~Neeman, and A.~Sly.
\newblock Reconstruction and estimation in the planted partition model.
\newblock \emph{Probability Theory and Related Fields}, 162:\penalty0 431--461,
  2015.

\bibitem[Mossel et~al.(2018)Mossel, Neeman, and Sly]{mossel2018proof}
E.~Mossel, J.~Neeman, and A.~Sly.
\newblock {A proof of the block model threshold conjecture}.
\newblock \emph{Combinatorica}, 38\penalty0 (3):\penalty0 665--708, 2018.

\bibitem[Murphy et~al.(2019)Murphy, Srinivasan, Rao, and
  Ribeiro]{pmlr-v97-murphy19a}
R.~Murphy, B.~Srinivasan, V.~Rao, and B.~Ribeiro.
\newblock Relational pooling for graph representations.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pages 4663--4673. PMLR,
  09--15 Jun 2019.

\bibitem[Nikolentzos et~al.(2020)Nikolentzos, Dasoulas, and
  Vazirgiannis]{nikolentzos2020khop}
G.~Nikolentzos, G.~Dasoulas, and M.~Vazirgiannis.
\newblock {k-hop graph neural networks}.
\newblock \emph{Neural Networks}, 130:\penalty0 195--205, 2020.

\bibitem[Oono and Suzuki(2020)]{oono2020graph}
K.~Oono and T.~Suzuki.
\newblock {Graph Neural Networks Exponentially Lose Expressive Power for Node
  Classification}.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Ramanan(2021)]{ramanancrm2021}
K.~Ramanan.
\newblock {CRM-PIMS Summer School 2021: Background Material For Mini Course on
  Asymptotics of Interacting Stochastic Processes on Sparse Graphs}, 2021.

\bibitem[Rong et~al.(2020)Rong, Huang, Xu, and Huang]{Rong2020DropEdge}
Y.~Rong, W.~Huang, T.~Xu, and J.~Huang.
\newblock {DropEdge: Towards Deep Graph Convolutional Networks on Node
  Classification}.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Scarselli et~al.(2009)Scarselli, Gori, Tsoi, Hagenbuchner, and
  Monfardini]{scarselli:gnn}
F.~Scarselli, M.~Gori, A.~C. Tsoi, M.~Hagenbuchner, and G.~Monfardini.
\newblock {The Graph Neural Network Model}.
\newblock \emph{IEEE Transactions on Neural Networks}, 20\penalty0 (1), 2009.

\bibitem[Stein(1972)]{stein1972bound}
C.~Stein.
\newblock A bound for the error in the normal approximation to the distribution
  of a sum of dependent random variables.
\newblock In \emph{Proc. Sixth Berkeley Symp. Math. Stat. Prob.}, pages
  583--602, 1972.

\bibitem[Stelzl et~al.(2005)Stelzl, Worm, Lalowski, Haenig, Brembeck, Goehler,
  Stroedicke, Zenkner, Schoenherr, Koeppen, et~al.]{stelzl2005human}
U.~Stelzl, U.~Worm, M.~Lalowski, C.~Haenig, F.~H. Brembeck, H.~Goehler,
  M.~Stroedicke, M.~Zenkner, A.~Schoenherr, S.~Koeppen, et~al.
\newblock A human protein-protein interaction network: a resource for
  annotating the proteome.
\newblock \emph{Cell}, 122\penalty0 (6):\penalty0 957--968, 2005.

\bibitem[Veli{\v{c}}kovi{\'c}(2022)]{velivckovic2022message}
P.~Veli{\v{c}}kovi{\'c}.
\newblock Message passing all the way up.
\newblock In \emph{ICLR 2022 Workshop on Geometrical and Topological
  Representation Learning}, 2022.

\bibitem[Veli{\v{c}}kovi{\'c} et~al.(2018)Veli{\v{c}}kovi{\'c}, Cucurull,
  Casanova, Romero, Li{\`o}, and Bengio]{velivckovic2018graph}
P.~Veli{\v{c}}kovi{\'c}, G.~Cucurull, A.~Casanova, A.~Romero, P.~Li{\`o}, and
  Y.~Bengio.
\newblock {Graph Attention Networks}.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Veličković(2022)]{velikovi2022message}
P.~Veličković.
\newblock {Message passing all the way up}, 2022.

\bibitem[Vershynin(2018)]{Vershynin:2018}
R.~Vershynin.
\newblock \emph{{High-Dimensional Probability: An Introduction with
  Applications in Data Science}}, volume~47.
\newblock Cambridge University Press, 2018.

\bibitem[Weber et~al.(2019)Weber, Domeniconi, Chen, Weidele, Bellei, Robinson,
  and Leiserson]{weber2019anti}
M.~Weber, G.~Domeniconi, J.~Chen, D.~K.~I. Weidele, C.~Bellei, T.~Robinson, and
  C.~E. Leiserson.
\newblock {Anti-money laundering in bitcoin: Experimenting with graph
  convolutional networks for financial forensics}.
\newblock \emph{arXiv preprint arXiv:1908.02591}, 2019.

\bibitem[Wei et~al.(2022)Wei, Yin, Jia, Benson, and Li]{wei2022understanding}
R.~Wei, H.~Yin, J.~Jia, A.~R. Benson, and P.~Li.
\newblock {Understanding Non-linearity in Graph Neural Networks from the
  Bayesian-Inference Perspective}.
\newblock In A.~H. Oh, A.~Agarwal, D.~Belgrave, and K.~Cho, editors,
  \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Xu et~al.(2018)Xu, Li, Tian, Sonobe, Kawarabayashi, and
  Jegelka]{Xu2018Jumping}
K.~Xu, C.~Li, Y.~Tian, T.~Sonobe, K.-i. Kawarabayashi, and S.~Jegelka.
\newblock {Representation Learning on Graphs with Jumping Knowledge Networks}.
\newblock In J.~Dy and A.~Krause, editors, \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pages 5453--5462. PMLR, 10--15 Jul 2018.

\bibitem[Xu et~al.(2021)Xu, Zhang, Li, Du, Kawarabayashi, and
  Jegelka]{xu2021how}
K.~Xu, M.~Zhang, J.~Li, S.~S. Du, K.-I. Kawarabayashi, and S.~Jegelka.
\newblock {How Neural Networks Extrapolate: From Feedforward to Graph Neural
  Networks}.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ying et~al.(2018)Ying, He, Chen, Eksombatchai, Hamilton, and
  Leskovec]{YHCEHL18}
R.~Ying, R.~He, K.~Chen, P.~Eksombatchai, W.~L. Hamilton, and J.~Leskovec.
\newblock {Graph Convolutional Neural Networks for Web-Scale Recommender
  Systems}.
\newblock \emph{KDD '18: Proceedings of the 24th ACM SIGKDD International
  Conference on Knowledge Discovery \& Data Mining}, pages 974--983, 2018.

\bibitem[Zhang et~al.(2017)Zhang, Zhou, Yildirim, Alcorn, He, Davulcu, and
  Tong]{zhang2017hidden}
S.~Zhang, D.~Zhou, M.~Y. Yildirim, S.~Alcorn, J.~He, H.~Davulcu, and H.~Tong.
\newblock {Hidden: hierarchical dense subgraph detection with application to
  financial fraud detection}.
\newblock In \emph{Proceedings of the 2017 SIAM International Conference on
  Data Mining}, pages 570--578. SIAM, 2017.

\bibitem[Zhang et~al.(2021)Zhang, Liang, Liu, and Tang]{zhang2021graph}
X.-M. Zhang, L.~Liang, L.~Liu, and M.-J. Tang.
\newblock Graph neural networks and their current applications in
  bioinformatics.
\newblock \emph{Frontiers in genetics}, 12:\penalty0 690049, 2021.

\end{thebibliography}
