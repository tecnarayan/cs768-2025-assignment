\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amari et~al.(2001)Amari, Fujita, and Shinomoto]{amari}
Amari, S.-i., Fujita, N., and Shinomoto, S.
\newblock Four types of learning curves.
\newblock \emph{Neural Computation}, 4, 01 2001.
\newblock \doi{10.1162/neco.1992.4.4.605}.

\bibitem[Anonymous(2021)]{param_scaling_transformers}
Anonymous.
\newblock Scaling laws vs model architectures: How does inductive bias
  influence scaling? an extensive empirical study on language tasks, 2021.

\bibitem[Arivazhagan et~al.(2019)Arivazhagan, Bapna, Firat, Lepikhin, Johnson,
  Krikun, Chen, Cao, Foster, Cherry, Macherey, Chen, and
  Wu]{arivazhagan2019massively}
Arivazhagan, N., Bapna, A., Firat, O., Lepikhin, D., Johnson, M., Krikun, M.,
  Chen, M.~X., Cao, Y., Foster, G., Cherry, C., Macherey, W., Chen, Z., and Wu,
  Y.
\newblock Massively multilingual neural machine translation in the wild:
  Findings and challenges, 2019.

\bibitem[Bahri et~al.(2021)Bahri, Dyer, Kaplan, Lee, and
  Sharma]{bahri2021explaining}
Bahri, Y., Dyer, E., Kaplan, J., Lee, J., and Sharma, U.
\newblock Explaining neural scaling laws.
\newblock \emph{arXiv preprint arXiv:2102.06701}, 2021.

\bibitem[Ba{\~n}{\'o}n et~al.(2020)Ba{\~n}{\'o}n, Chen, Haddow, Heafield,
  Hoang, Espl{\`a}-Gomis, Forcada, Kamran, Kirefu, Koehn, Ortiz~Rojas,
  Pla~Sempere, Ram{\'\i}rez-S{\'a}nchez, Sarr{\'\i}as, Strelec, Thompson,
  Waites, Wiggins, and Zaragoza]{banon-etal-2020-paracrawl}
Ba{\~n}{\'o}n, M., Chen, P., Haddow, B., Heafield, K., Hoang, H.,
  Espl{\`a}-Gomis, M., Forcada, M.~L., Kamran, A., Kirefu, F., Koehn, P.,
  Ortiz~Rojas, S., Pla~Sempere, L., Ram{\'\i}rez-S{\'a}nchez, G., Sarr{\'\i}as,
  E., Strelec, M., Thompson, B., Waites, W., Wiggins, D., and Zaragoza, J.
\newblock {P}ara{C}rawl: Web-scale acquisition of parallel corpora.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  4555--4567, Online, July 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.417}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.417}.

\bibitem[Barrault et~al.(2019)Barrault, Bojar, Costa-Jussa, Federmann, Fishel,
  Graham, Haddow, Huck, Koehn, Malmasi, et~al.]{barrault-EtAl:2019:WMT}
Barrault, L., Bojar, O., Costa-Jussa, M.~R., Federmann, C., Fishel, M., Graham,
  Y., Haddow, B., Huck, M., Koehn, P., Malmasi, S., et~al.
\newblock Findings of the 2019 conference on machine translation (wmt19).
\newblock In \emph{Proceedings of the Fourth Conference on Machine Translation
  (Volume 2: Shared Task Papers, Day 1)}, pp.\  1--61, 2019.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Chen et~al.(2018)Chen, Firat, Bapna, Johnson, Macherey, Foster, Jones,
  Parmar, Schuster, Chen, Wu, and Hughes]{chen2018best}
Chen, M.~X., Firat, O., Bapna, A., Johnson, M., Macherey, W., Foster, G.,
  Jones, L., Parmar, N., Schuster, M., Chen, Z., Wu, Y., and Hughes, M.
\newblock The best of both worlds: Combining recent advances in neural machine
  translation, 2018.

\bibitem[El-Kishky et~al.(2020)El-Kishky, Chaudhary, Guzman, and
  Koehn]{elkishky2020ccaligned}
El-Kishky, A., Chaudhary, V., Guzman, F., and Koehn, P.
\newblock Ccaligned: A massive collection of cross-lingual web-document pairs,
  2020.

\bibitem[Fan et~al.(2020)Fan, Bhosale, Schwenk, Ma, El-Kishky, Goyal, Baines,
  Celebi, Wenzek, Chaudhary, Goyal, Birch, Liptchinsky, Edunov, Grave, Auli,
  and Joulin]{fan2020englishcentric}
Fan, A., Bhosale, S., Schwenk, H., Ma, Z., El-Kishky, A., Goyal, S., Baines,
  M., Celebi, O., Wenzek, G., Chaudhary, V., Goyal, N., Birch, T., Liptchinsky,
  V., Edunov, S., Grave, E., Auli, M., and Joulin, A.
\newblock Beyond english-centric multilingual machine translation, 2020.

\bibitem[Freitag et~al.(2019)Freitag, Caswell, and Roy]{Freitag19}
Freitag, M., Caswell, I., and Roy, S.
\newblock {APE at Scale and Its Implications on MT Evaluation Biases}.
\newblock In \emph{Proceedings of the Fourth Conference on Machine
  Translation}, pp.\  34--44, Florence, Italy, August 2019. Association for
  Computational Linguistics.
\newblock URL \url{http://www.aclweb.org/anthology/W19-5204}.

\bibitem[Freitag et~al.(2020)Freitag, Grangier, and
  Caswell]{freitag-etal-2020-bleu}
Freitag, M., Grangier, D., and Caswell, I.
\newblock {BLEU} might be guilty but references are not innocent.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, Online, November 2020. Association for
  Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.5}.

\bibitem[Freitag et~al.(2021)Freitag, Foster, Grangier, Ratnakar, Tan, and
  Macherey]{freitag2021experts}
Freitag, M., Foster, G., Grangier, D., Ratnakar, V., Tan, Q., and Macherey, W.
\newblock Experts, errors, and context: A large-scale study of human evaluation
  for machine translation, 2021.

\bibitem[Gao(2021)]{gao2021empirical}
Gao, L.
\newblock An empirical exploration in quality filtering of text data, 2021.

\bibitem[Ghorbani et~al.(2021)Ghorbani, Firat, Freitag, Bapna, Krikun, Garcia,
  Chelba, and Cherry]{ghorbani2021scaling}
Ghorbani, B., Firat, O., Freitag, M., Bapna, A., Krikun, M., Garcia, X.,
  Chelba, C., and Cherry, C.
\newblock Scaling laws for neural machine translation, 2021.

\bibitem[Google()]{GoogleHybrid}
Google.
\newblock Recent advances in google translate.
\newblock
  \url{https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html}.

\bibitem[Gordon et~al.(2021)Gordon, Duh, and Kaplan]{gordon2021data}
Gordon, M., Duh, K., and Kaplan, J.
\newblock Data and parameter scaling laws for neural machine translation.
\newblock \emph{ACL Rolling Review-May}, 2021, 2021.

\bibitem[Graham et~al.(2020)Graham, Haddow, and Koehn]{graham2020statistical}
Graham, Y., Haddow, B., and Koehn, P.
\newblock Statistical power and translationese in machine translation
  evaluation.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  72--81, 2020.

\bibitem[Hestness et~al.(2017)Hestness, Narang, Ardalani, Diamos, Jun,
  Kianinejad, Patwary, Yang, and Zhou]{Hestness2017DeepLS}
Hestness, J., Narang, S., Ardalani, N., Diamos, G.~F., Jun, H., Kianinejad, H.,
  Patwary, M. M.~A., Yang, Y., and Zhou, Y.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{ArXiv}, abs/1712.00409, 2017.

\bibitem[Hoiem et~al.(2021)Hoiem, Gupta, Li, and
  Shlapentokh-Rothman]{pmlr-v139-hoiem21a}
Hoiem, D., Gupta, T., Li, Z., and Shlapentokh-Rothman, M.
\newblock Learning curves for analysis of deep networks.
\newblock In Meila, M. and Zhang, T. (eds.), \emph{Proceedings of the 38th
  International Conference on Machine Learning}, volume 139 of
  \emph{Proceedings of Machine Learning Research}, pp.\  4287--4296. PMLR,
  18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/hoiem21a.html}.

\bibitem[Junczys-Dowmunt(2018)]{junczys2018dual}
Junczys-Dowmunt, M.
\newblock Dual conditional cross-entropy filtering of noisy parallel corpora.
\newblock \emph{arXiv preprint arXiv:1809.00197}, 2018.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R.,
  Gray, S., Radford, A., Wu, J., and Amodei, D.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Kasai et~al.(2020)Kasai, Pappas, Peng, Cross, and
  Smith]{kasai2020deep}
Kasai, J., Pappas, N., Peng, H., Cross, J., and Smith, N.~A.
\newblock Deep encoder, shallow decoder: Reevaluating non-autoregressive
  machine translation.
\newblock \emph{arXiv preprint arXiv:2006.10369}, 2020.

\bibitem[Khayrallah \& Koehn(2018)Khayrallah and Koehn]{Khayrallah_2018}
Khayrallah, H. and Koehn, P.
\newblock On the impact of various types of noise on neural machine
  translation.
\newblock \emph{Proceedings of the 2nd Workshop on Neural Machine Translation
  and Generation}, 2018.
\newblock \doi{10.18653/v1/w18-2709}.
\newblock URL \url{http://dx.doi.org/10.18653/v1/W18-2709}.

\bibitem[Kocmi et~al.(2021)Kocmi, Federmann, Grundkiewicz, Junczys-Dowmunt,
  Matsushita, and Menezes]{kocmi2021ship}
Kocmi, T., Federmann, C., Grundkiewicz, R., Junczys-Dowmunt, M., Matsushita,
  H., and Menezes, A.
\newblock To ship or not to ship: An extensive evaluation of automatic metrics
  for machine translation, 2021.

\bibitem[Kolesnikov et~al.(2020)Kolesnikov, Beyer, Zhai, Puigcerver, Yung,
  Gelly, and Houlsby]{kolesnikov2020big}
Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., and
  Houlsby, N.
\newblock Big transfer (bit): General visual representation learning, 2020.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems},
  25:\penalty0 1097--1105, 2012.

\bibitem[Lepikhin et~al.(2020)Lepikhin, Lee, Xu, Chen, Firat, Huang, Krikun,
  Shazeer, and Chen]{lepikhin2020gshard}
Lepikhin, D., Lee, H., Xu, Y., Chen, D., Firat, O., Huang, Y., Krikun, M.,
  Shazeer, N., and Chen, Z.
\newblock Gshard: Scaling giant models with conditional computation and
  automatic sharding, 2020.

\bibitem[Liu et~al.(2020)Liu, Gu, Goyal, Li, Edunov, Ghazvininejad, Lewis, and
  Zettlemoyer]{liu2020multilingual}
Liu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M., Lewis, M.,
  and Zettlemoyer, L.
\newblock Multilingual denoising pre-training for neural machine translation,
  2020.

\bibitem[Mathur et~al.(2020)Mathur, Wei, Freitag, Ma, and
  Bojar]{mathur-etal-2020-results}
Mathur, N., Wei, J., Freitag, M., Ma, Q., and Bojar, O.
\newblock Results of the {WMT}20 metrics shared task.
\newblock In \emph{Proceedings of the Fifth Conference on Machine Translation},
  pp.\  688--725, Online, November 2020. Association for Computational
  Linguistics.
\newblock URL \url{https://aclanthology.org/2020.wmt-1.77}.

\bibitem[Microsoft()]{MSFTHybrid}
Microsoft.
\newblock Neural machine translation enabling human parity innovations in the
  cloud.
\newblock
  \url{https://www.microsoft.com/en-us/translator/blog/2019/06/17/neural-machine-translation-enabling\\-human-parity-innovations-in-the-cloud}.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{miller2021accuracy}
Miller, J.~P., Taori, R., Raghunathan, A., Sagawa, S., Koh, P.~W., Shankar, V.,
  Liang, P., Carmon, Y., and Schmidt, L.
\newblock Accuracy on the line: on the strong correlation between
  out-of-distribution and in-distribution generalization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7721--7735. PMLR, 2021.

\bibitem[Moore \& Lewis(2010)Moore and Lewis]{moore-lewis-2010-intelligent}
Moore, R.~C. and Lewis, W.
\newblock Intelligent selection of language model training data.
\newblock In \emph{Proceedings of the {ACL} 2010 Conference Short Papers}, pp.\
   220--224, Uppsala, Sweden, July 2010. Association for Computational
  Linguistics.
\newblock URL \url{https://aclanthology.org/P10-2041}.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{raffel2020exploring}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer, 2020.

\bibitem[Ram{\'\i}rez-S{\'a}nchez et~al.(2020)Ram{\'\i}rez-S{\'a}nchez,
  Zaragoza-Bernabeu, Ba{\~n}{\'o}n, and
  Rojas]{ramirez-sanchez-etal-2020-bifixer}
Ram{\'\i}rez-S{\'a}nchez, G., Zaragoza-Bernabeu, J., Ba{\~n}{\'o}n, M., and
  Rojas, S.~O.
\newblock Bifixer and bicleaner: two open-source tools to clean your parallel
  data.
\newblock In \emph{Proceedings of the 22nd Annual Conference of the European
  Association for Machine Translation}, pp.\  291--298, Lisboa, Portugal,
  November 2020. European Association for Machine Translation.
\newblock URL \url{https://aclanthology.org/2020.eamt-1.31}.

\bibitem[Rei et~al.(2020)Rei, Stewart, Farinha, and Lavie]{rei-etal-2020-comet}
Rei, R., Stewart, C., Farinha, A.~C., and Lavie, A.
\newblock {COMET}: A neural framework for {MT} evaluation.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, Online, November 2020. Association for
  Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.213}.

\bibitem[Rosenfeld et~al.(2019)Rosenfeld, Rosenfeld, Belinkov, and
  Shavit]{rosenfeld2019constructive}
Rosenfeld, J.~S., Rosenfeld, A., Belinkov, Y., and Shavit, N.
\newblock A constructive prediction of the generalization error across scales.
\newblock \emph{arXiv preprint arXiv:1909.12673}, 2019.

\bibitem[Sellam et~al.(2020)Sellam, Das, and Parikh]{sellam-etal-2020-bleurt}
Sellam, T., Das, D., and Parikh, A.
\newblock {BLEURT}: Learning robust metrics for text generation.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, Online, July 2020. Association for
  Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2020.acl-main.704}.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch]{sennrich2016improving}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Improving neural machine translation models with monolingual data,
  2016.

\bibitem[Sharma \& Kaplan(2020)Sharma and Kaplan]{sharma2020neural}
Sharma, U. and Kaplan, J.
\newblock A neural scaling law from the dimension of the data manifold, 2020.

\bibitem[Shazeer \& Stern(2018)Shazeer and Stern]{shazeer2018adafactor}
Shazeer, N. and Stern, M.
\newblock Adafactor: Adaptive learning rates with sublinear memory cost, 2018.

\bibitem[Siddhant et~al.(2020)Siddhant, Bapna, Cao, Firat, Chen, Kudugunta,
  Arivazhagan, and Wu]{siddhant2020leveraging}
Siddhant, A., Bapna, A., Cao, Y., Firat, O., Chen, M., Kudugunta, S.,
  Arivazhagan, N., and Wu, Y.
\newblock Leveraging monolingual data with self-supervision for multilingual
  neural machine translation, 2020.

\bibitem[Thoppilan et~al.(2022)Thoppilan, Freitas, Hall, Shazeer, Kulshreshtha,
  Cheng, Jin, Bos, Baker, Du, Li, Lee, Zheng, Ghafouri, Menegali, Huang,
  Krikun, Lepikhin, Qin, Chen, Xu, Chen, Roberts, Bosma, Zhou, Chang, Krivokon,
  Rusch, Pickett, Meier-Hellstern, Morris, Doshi, Santos, Duke, Soraker,
  Zevenbergen, Prabhakaran, Diaz, Hutchinson, Olson, Molina, Hoffman-John, Lee,
  Aroyo, Rajakumar, Butryna, Lamm, Kuzmina, Fenton, Cohen, Bernstein, Kurzweil,
  Aguera-Arcas, Cui, Croak, Chi, and Le]{thoppilan2022lamda}
Thoppilan, R., Freitas, D.~D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng,
  H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H.~S.,
  Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J.,
  Chen, D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhou, Y., Chang, C.-C.,
  Krivokon, I., Rusch, W., Pickett, M., Meier-Hellstern, K., Morris, M.~R.,
  Doshi, T., Santos, R.~D., Duke, T., Soraker, J., Zevenbergen, B.,
  Prabhakaran, V., Diaz, M., Hutchinson, B., Olson, K., Molina, A.,
  Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R., Butryna, A., Lamm, M.,
  Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil, R.,
  Aguera-Arcas, B., Cui, C., Croak, M., Chi, E., and Le, Q.
\newblock Lamda: Language models for dialog applications, 2022.

\bibitem[Wang et~al.(2021)Wang, Tu, Tan, Wang, Sun, and Liu]{wang2021language}
Wang, S., Tu, Z., Tan, Z., Wang, W., Sun, M., and Liu, Y.
\newblock Language models are good translators, 2021.

\bibitem[Wang et~al.(2018)Wang, Watanabe, Hughes, Nakagawa, and
  Chelba]{wang2018denoising}
Wang, W., Watanabe, T., Hughes, M., Nakagawa, T., and Chelba, C.
\newblock Denoising neural machine translation training with trusted data and
  online data selection, 2018.

\bibitem[Xiong et~al.(2020)Xiong, Yang, He, Zheng, Zheng, Xing, Zhang, Lan,
  Wang, and Liu]{xiong2020layer}
Xiong, R., Yang, Y., He, D., Zheng, K., Zheng, S., Xing, C., Zhang, H., Lan,
  Y., Wang, L., and Liu, T.-Y.
\newblock On layer normalization in the transformer architecture, 2020.

\bibitem[Xu et~al.(2020)Xu, Ju, Li, Boureau, Weston, and Dinan]{xu2020recipes}
Xu, J., Ju, D., Li, M., Boureau, Y.-L., Weston, J., and Dinan, E.
\newblock Recipes for safety in open-domain chatbots.
\newblock \emph{arXiv preprint arXiv:2010.07079}, 2020.

\bibitem[Zhang \& Toral(2019)Zhang and Toral]{zhang2019effect}
Zhang, M. and Toral, A.
\newblock The effect of translationese in machine translation test sets, 2019.

\end{thebibliography}
