\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{DKK{\etalchar{+}}21b}

\bibitem[ABHM17]{awasthi2017efficient}
Pranjal Awasthi, Avrim Blum, Nika Haghtalab, and Yishay Mansour.
\newblock Efficient {PAC} learning from the crowd.
\newblock In {\em Proceedings of the 30th Annual Conference on Learning
  Theory}, pages 127--150, 2017.

\bibitem[ABHZ16]{awasthi2016learning}
Pranjal Awasthi, Maria{-}Florina Balcan, Nika Haghtalab, and Hongyang Zhang.
\newblock Learning and 1-bit compressed sensing under asymmetric noise.
\newblock In {\em Proceedings of the 29th Annual Conference on Learning
  Theory}, pages 152--192, 2016.

\bibitem[ABL17]{awasthi2017power}
Pranjal Awasthi, Maria{-}Florina Balcan, and Philip~M. Long.
\newblock The power of localization for efficiently learning linear separators
  with noise.
\newblock {\em Journal of the {ACM}}, 63(6):50:1--50:27, 2017.

\bibitem[AL87]{angluin1987learning}
Dana Angluin and Philip~D. Laird.
\newblock Learning from noisy examples.
\newblock {\em Machine Learning}, 2(4):343--370, 1987.

\bibitem[BDLS17]{balakrishnan2017computation}
Sivaraman Balakrishnan, Simon~S. Du, Jerry Li, and Aarti Singh.
\newblock Computationally efficient robust sparse estimation in high
  dimensions.
\newblock In {\em Proceedings of the 30th Annual Conference on Learning
  Theory}, pages 169--212, 2017.

\bibitem[BHL95]{blum1995learning}
Avrim Blum, Lisa Hellerstein, and Nick Littlestone.
\newblock Learning in the presence of finitely or infinitely many irrelevant
  attributes.
\newblock {\em Journal of Computer and System Sciences}, 50(1):32--40, 1995.

\bibitem[BJK15]{bhatia2015robust}
Kush Bhatia, Prateek Jain, and Purushottam Kar.
\newblock Robust regression via hard thresholding.
\newblock In {\em {NIPS}}, pages 721--729, 2015.

\bibitem[BK21]{bakshi2021list}
Ainesh Bakshi and Pravesh~K. Kothari.
\newblock List-decodable subspace recovery: Dimension independent error in
  polynomial time.
\newblock In {\em Proceedings of the 2021 {ACM-SIAM} Symposium on Discrete
  Algorithms}, pages 1279--1297, 2021.

\bibitem[CDK{\etalchar{+}}21]{cheng2021outlier}
Yu~Cheng, Ilias Diakonikolas, Daniel~M. Kane, Rong Ge, Shivam Gupta, and Mahdi
  Soltanolkotabi.
\newblock Outlier-robust sparse estimation via non-convex optimization.
\newblock {\em CoRR}, abs/2109.11515, 2021.

\bibitem[CDS98]{chen1998atomic}
Scott~Shaobing Chen, David~L. Donoho, and Michael~A. Saunders.
\newblock Atomic decomposition by basis pursuit.
\newblock {\em {SIAM} Journal on Scientific Computing}, 20(1):33--61, 1998.

\bibitem[CMY20]{cmy2020list}
Yeshwanth Cherapanamjeri, Sidhanth Mohanty, and Morris Yau.
\newblock List decodable mean estimation in nearly linear time.
\newblock In {\em 61st {IEEE} Annual Symposium on Foundations of Computer
  Science}, pages 141--148. {IEEE}, 2020.

\bibitem[CSV17]{charika2017learning}
Moses Charikar, Jacob Steinhardt, and Gregory Valiant.
\newblock Learning from untrusted data.
\newblock In {\em Proceedings of the 49th Annual {ACM} {SIGACT} Symposium on
  Theory of Computing}, pages 47--60, 2017.

\bibitem[CT05]{candes2005decoding}
Emmanuel~J. Cand{\`{e}}s and Terence Tao.
\newblock Decoding by linear programming.
\newblock {\em {IEEE} Transactions on Information Theory}, 51(12):4203--4215,
  2005.

\bibitem[DKK{\etalchar{+}}16]{diakonikolas2016robust}
Ilias Diakonikolas, Gautam Kamath, Daniel~M. Kane, Jerry Li, Ankur Moitra, and
  Alistair Stewart.
\newblock Robust estimators in high dimensions without the computational
  intractability.
\newblock In {\em Proceedings of the 57th Annual {IEEE} Symposium on
  Foundations of Computer Science}, pages 655--664, 2016.

\bibitem[DKK{\etalchar{+}}17]{dia2017being}
Ilias Diakonikolas, Gautam Kamath, Daniel~M. Kane, Jerry Li, Ankur Moitra, and
  Alistair Stewart.
\newblock Being robust (in high dimensions) can be practical.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of {\em Proceedings of Machine Learning Research}, pages
  999--1008. {PMLR}, 2017.

\bibitem[DKK{\etalchar{+}}19]{dia2019outlier}
Ilias Diakonikolas, Daniel Kane, Sushrut Karmalkar, Eric Price, and Alistair
  Stewart.
\newblock Outlier-robust high-dimensional sparse estimation via iterative
  filtering.
\newblock In {\em NeurIPS}, pages 10688--10699, 2019.

\bibitem[DKK20a]{dia2020list}
Ilias Diakonikolas, Daniel Kane, and Daniel Kongsgaard.
\newblock List-decodable mean estimation via iterative multi-filtering.
\newblock In {\em Proceedings of the 34th Annual Conference on Neural
  Information Processing Systems}, 2020.

\bibitem[DKK{\etalchar{+}}20b]{diakonikolas2020polynomial}
Ilias Diakonikolas, Daniel~M. Kane, Vasilis Kontonis, Christos Tzamos, and
  Nikos Zarifis.
\newblock A polynomial time algorithm for learning halfspaces with {Tsybakov}
  noise.
\newblock {\em CoRR}, abs/2010.01705, 2020.

\bibitem[DKK{\etalchar{+}}21a]{dia2021list}
Ilias Diakonikolas, Daniel Kane, Daniel Kongsgaard, Jerry Li, and Kevin Tian.
\newblock List-decodable mean estimation in nearly-pca time.
\newblock In {\em Proceedings of the 35th Annual Conference on Neural
  Information Processing Systems}, pages 10195--10208, 2021.

\bibitem[DKK{\etalchar{+}}21b]{dia2021cluster}
Ilias Diakonikolas, Daniel~M. Kane, Daniel Kongsgaard, Jerry Li, and Kevin
  Tian.
\newblock Clustering mixture models in almost-linear time via list-decodable
  mean estimation.
\newblock {\em CoRR}, abs/2106.08537, 2021.

\bibitem[DKK{\etalchar{+}}22]{diaLDsparse2022}
Ilias Diakonikolas, Daniel~M. Kane, Sushrut Karmalkar, Ankit Pensia, and
  Thanasis Pittas.
\newblock List-decodable sparse mean estimation via difference-of-pairs
  filtering.
\newblock {\em CoRR}, abs/2206.05245, 2022.

\bibitem[DKS17]{diakonikolas2017statistical}
Ilias Diakonikolas, Daniel~M. Kane, and Alistair Stewart.
\newblock Statistical query lower bounds for robust estimation of
  high-dimensional gaussians and gaussian mixtures.
\newblock In {\em Proceedings of the 58th {IEEE} Annual Symposium on
  Foundations of Computer Science}, pages 73--84, 2017.

\bibitem[DKS18a]{diakonikolas2018learning}
Ilias Diakonikolas, Daniel~M. Kane, and Alistair Stewart.
\newblock Learning geometric concepts with nasty noise.
\newblock In {\em Proceedings of the 50th Annual {ACM} Symposium on Theory of
  Computing}, pages 1061--1073, 2018.

\bibitem[DKS18b]{dia2018list}
Ilias Diakonikolas, Daniel~M. Kane, and Alistair Stewart.
\newblock List-decodable robust mean estimation and learning mixtures of
  spherical gaussians.
\newblock In {\em Proceedings of the 50th Annual {ACM} {SIGACT} Symposium on
  Theory of Computing}, pages 1047--1060. {ACM}, 2018.

\bibitem[DKTZ20]{diakonikolas2020learning}
Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, and Nikos Zarifis.
\newblock Learning halfspaces with {Massart} noise under structured
  distributions.
\newblock In {\em Proceedings of the 33rd Annual Conference on Learning
  Theory}, pages 1486--1513, 2020.

\bibitem[Don06]{donoho2006compressed}
David~L. Donoho.
\newblock Compressed sensing.
\newblock {\em {IEEE} Transactions on Information Theory}, 52(4):1289--1306,
  2006.

\bibitem[Hau92]{haussler1992decision}
David Haussler.
\newblock Decision theoretic generalizations of the {PAC} model for neural net
  and other learning applications.
\newblock {\em Information and Computation}, 100(1):78--150, 1992.

\bibitem[HLZ20]{hopkins2020robust}
Samuel~B. Hopkins, Jerry Li, and Fred Zhang.
\newblock Robust and heavy-tailed mean estimation made simple, via regret
  minimization.
\newblock {\em CoRR}, abs/2007.15839, 2020.

\bibitem[Hub64]{huber1964robust}
Peter~J. Huber.
\newblock {Robust Estimation of a Location Parameter}.
\newblock {\em The Annals of Mathematical Statistics}, 35(1):73 -- 101, 1964.

\bibitem[KKK19]{karmalkar2019list}
Sushrut Karmalkar, Adam~R. Klivans, and Pravesh Kothari.
\newblock List-decodable linear regression.
\newblock In {\em Proceedings of the 33rd Annual Conference on Neural
  Information Processing Systems}, pages 7423--7432, 2019.

\bibitem[KKM18]{klivans2018efficient}
Adam~R. Klivans, Pravesh~K. Kothari, and Raghu Meka.
\newblock Efficient algorithms for outlier-robust regression.
\newblock In {\em Proceedings of the 31st Annual Conference on Learning
  Theory}, volume~75 of {\em Proceedings of Machine Learning Research}, pages
  1420--1430. {PMLR}, 2018.

\bibitem[KKMS05]{kalai2005agnostic}
Adam~Tauman Kalai, Adam~R. Klivans, Yishay Mansour, and Rocco~A. Servedio.
\newblock Agnostically learning halfspaces.
\newblock In {\em Proceedings of the 46th Annual {IEEE} Symposium on
  Foundations of Computer Science}, pages 11--20, 2005.

\bibitem[KL88]{kearns1988learning}
Michael~J. Kearns and Ming Li.
\newblock Learning in the presence of malicious errors.
\newblock In {\em Proceedings of the 20th Annual {ACM} Symposium on Theory of
  Computing}, pages 267--280, 1988.

\bibitem[KSS92]{kearns1992efficient}
Michael~J. Kearns, Robert~E. Schapire, and Linda Sellie.
\newblock Toward efficient agnostic learning.
\newblock In {\em Proceedings of the Fifth Annual {ACM} Conference on
  Computational Learning Theory}, pages 341--352, 1992.

\bibitem[KSS18]{kothari2018robust}
Pravesh~K. Kothari, Jacob Steinhardt, and David Steurer.
\newblock Robust moment estimation and improved clustering via sum of squares.
\newblock In {\em Proceedings of the 50th Annual {ACM} {SIGACT} Symposium on
  Theory of Computing}, pages 1035--1046, 2018.

\bibitem[Lit87]{littlestone1987learning}
Nick Littlestone.
\newblock Learning quickly when irrelevant attributes abound: {A} new
  linear-threshold algorithm.
\newblock In {\em Proceedings of the 28th Annual {IEEE} Symposium on
  Foundations of Computer Science}, pages 68--77, 1987.

\bibitem[LRV16]{lai2016agnostic}
Kevin~A. Lai, Anup~B. Rao, and Santosh~S. Vempala.
\newblock Agnostic estimation of mean and covariance.
\newblock In {\em Proceedings of the 57th Annual {IEEE} Symposium on
  Foundations of Computer Science}, pages 665--674, 2016.

\bibitem[LSLC20]{liu2020high}
Liu Liu, Yanyao Shen, Tianyang Li, and Constantine Caramanis.
\newblock High dimensional robust sparse regression.
\newblock In {\em The 23rd International Conference on Artificial Intelligence
  and Statistics,}, volume 108 of {\em Proceedings of Machine Learning
  Research}, pages 411--421. {PMLR}, 2020.

\bibitem[LT91]{ledoux1991probability}
Michel Ledoux and Michel Talagrand.
\newblock {\em Probability in Banach Spaces: Isoperimetry and Processes}.
\newblock Springer-Verlag Berlin Heidelberg, 1991.

\bibitem[Ma13]{ma2013sparse}
Zongming Ma.
\newblock Sparse principal component analysis and iterative thresholding.
\newblock {\em The Annals of Statistics}, 41(2):772--801, 2013.

\bibitem[MN06]{massart2006risk}
Pascal Massart and {\'E}lodie N{\'e}d{\'e}lec.
\newblock Risk bounds for statistical learning.
\newblock {\em The Annals of Statistics}, pages 2326--2366, 2006.

\bibitem[MV18]{meister2018data}
Michela Meister and Gregory Valiant.
\newblock A data prism: {S}emi-verified learning in the small-alpha regime.
\newblock In {\em Proceedings of the 31st Conference On Learning Theory}, pages
  1530--1546, 2018.

\bibitem[PV13]{plan2013robust}
Yaniv Plan and Roman Vershynin.
\newblock Robust 1-bit compressed sensing and sparse logistic regression: {A}
  convex programming approach.
\newblock {\em {IEEE} Transactions on Information Theory}, 59(1):482--494,
  2013.

\bibitem[RY20a]{raghavendra2020list}
Prasad Raghavendra and Morris Yau.
\newblock List decodable learning via sum of squares.
\newblock In {\em Proceedings of the 2020 {ACM-SIAM} Symposium on Discrete
  Algorithms}, pages 161--180, 2020.

\bibitem[RY20b]{raghavendra2020subspace}
Prasad Raghavendra and Morris Yau.
\newblock List decodable subspace recovery.
\newblock In {\em Proceedings of the 33rd Annual Conference on Learning
  Theory}, pages 3206--3226, 2020.

\bibitem[SCV18]{steinhardt2018resilience}
Jacob Steinhardt, Moses Charikar, and Gregory Valiant.
\newblock Resilience: {A} criterion for learning in the presence of arbitrary
  outliers.
\newblock In {\em Proceedings of the 9th Innovations in Theoretical Computer
  Science Conference}, pages 45:1--45:21, 2018.

\bibitem[She20]{shen2020one}
Jie Shen.
\newblock One-bit compressed sensing via one-shot hard thresholding.
\newblock In {\em Proceedings of the 36th Conference on Uncertainty in
  Artificial Intelligence}, pages 510--519, 2020.

\bibitem[She21]{shen2021sample}
Jie Shen.
\newblock Sample-optimal {PAC} learning of halfspaces with malicious noise.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning}, pages 9515--9524, 2021.

\bibitem[SL17a]{shen2017iteration}
Jie Shen and Ping Li.
\newblock On the iteration complexity of support recovery via hard thresholding
  pursuit.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, pages 3115--3124, 2017.

\bibitem[SL17b]{shen2017partial}
Jie Shen and Ping Li.
\newblock Partial hard thresholding: Towards a principled analysis of support
  recovery.
\newblock In {\em Proceedings of the 31st Annual Conference on Neural
  Information Processing Systems}, pages 3127--3137, 2017.

\bibitem[SL18]{shen2018tight}
Jie Shen and Ping Li.
\newblock A tight bound of hard thresholding.
\newblock {\em Journal of Machine Learning Research}, 18(208):1--42, 2018.

\bibitem[Slo88]{sloan1988types}
Robert~H. Sloan.
\newblock Types of noise in data for concept learning.
\newblock In {\em Proceedings of the First Annual Workshop on Computational
  Learning Theory}, pages 91--96, 1988.

\bibitem[STT12]{servedio2012attribute}
Rocco~A. Servedio, Li{-}Yang Tan, and Justin Thaler.
\newblock Attribute-efficient learning and weight-degree tradeoffs for
  polynomial threshold functions.
\newblock In {\em Proceedings of the 25th Annual Conference on Learning
  Theory}, pages 1--19, 2012.

\bibitem[SVC16]{steinhardt2016avoid}
Jacob Steinhardt, Gregory Valiant, and Moses Charikar.
\newblock Avoiding imposters and delinquents: Adversarial crowdsourcing and
  peer prediction.
\newblock In {\em Proceedings of the 30th Annual Conference on Neural
  Information Processing Systems}, pages 4439--4447, 2016.

\bibitem[SZ21]{shen2021attribute}
Jie Shen and Chicheng Zhang.
\newblock Attribute-efficient learning of halfspaces with malicious noise:
  Near-optimal label complexity and noise tolerance.
\newblock In {\em Proceedings of the 32nd International Conference on
  Algorithmic Learning Theory}, pages 1072--1113, 2021.

\bibitem[Tib96]{tibshirani1996regression}
Robert Tibshirani.
\newblock Regression shrinkage and selection via the {L}asso.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 58(1):267--288, 1996.

\bibitem[Tuk60]{tukey1960survey}
John~W. Tukey.
\newblock A survey of sampling from contaminated distributions.
\newblock {\em Contributions to probability and statistics}, pages 448--485,
  1960.

\bibitem[Val85]{valiant1985learning}
Leslie~G. Valiant.
\newblock Learning disjunction of conjunctions.
\newblock In {\em Proceedings of the 9th International Joint Conference on
  Artificial Intelligence}, pages 560--566, 1985.

\bibitem[Wai19]{wainwright2019high}
Martin~J. Wainwright.
\newblock {\em High-dimensional statistics: {A} non-asymptotic viewpoint}.
\newblock Cambridge University Press, 2019.

\bibitem[WSL18]{wang2018provable}
Jing Wang, Jie Shen, and Ping Li.
\newblock Provable variable selection for streaming features.
\newblock In {\em Proceedings of the 35th International Conference on Machine
  Learning}, pages 5158--5166, 2018.

\bibitem[ZS21]{zeng2021semi}
Shiwei Zeng and Jie Shen.
\newblock Semi-verified learning from the crowd with pairwise comparisons.
\newblock {\em CoRR}, abs/2106.07080, 2021.

\bibitem[ZS22]{zeng2022crowd}
Shiwei Zeng and Jie Shen.
\newblock Efficient {PAC} learning from the crowd with pairwise comparisons.
\newblock In {\em Proceedings of the 39th International Conference on Machine
  Learning}, pages 25973--25993, 2022.

\bibitem[ZSA20]{zhang2020efficient}
Chicheng Zhang, Jie Shen, and Pranjal Awasthi.
\newblock Efficient active learning of sparse halfspaces with arbitrary bounded
  noise.
\newblock In {\em Proceedings of the 34th Annual Conference on Neural
  Information Processing Systems}, pages 7184--7197, 2020.

\end{thebibliography}
