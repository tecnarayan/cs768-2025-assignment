\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abay et~al.(2020)Abay, Zhou, Baracaldo, Rajamoni, Chuba, and
  Ludwig]{abay2020mitigating}
Abay, A., Zhou, Y., Baracaldo, N., Rajamoni, S., Chuba, E., and Ludwig, H.
\newblock Mitigating bias in federated learning.
\newblock \emph{arXiv preprint arXiv:2012.02447}, 2020.

\bibitem[Alistarh et~al.(2018)Alistarh, Allen-Zhu, and
  Li]{alistarh2018byzantine}
Alistarh, D., Allen-Zhu, Z., and Li, J.
\newblock Byzantine stochastic gradient descent.
\newblock \emph{Conference on Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem[Balashov \& Golubev(2012)Balashov and Golubev]{balashov2012lipschitz}
Balashov, M.~V. and Golubev, M.~O.
\newblock About the lipschitz property of the metric projection in the hilbert
  space.
\newblock \emph{Journal of Mathematical Analysis and Applications},
  394\penalty0 (2):\penalty0 545--551, 2012.

\bibitem[Blanchard et~al.(2017)Blanchard, El~Mhamdi, Guerraoui, and
  Stainer]{blanchard2017machine}
Blanchard, P., El~Mhamdi, E.~M., Guerraoui, R., and Stainer, J.
\newblock Machine learning with adversaries: Byzantine tolerant gradient
  descent.
\newblock \emph{Conference on Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Bottou et~al.(2018)Bottou, Curtis, and
  Nocedal]{bottou2018optimization}
Bottou, L., Curtis, F.~E., and Nocedal, J.
\newblock Optimization methods for large-scale machine learning.
\newblock \emph{SIAM review}, 2018.

\bibitem[Cai et~al.(2015)Cai, Daskalakis, and Papadimitriou]{cai2015optimum}
Cai, Y., Daskalakis, C., and Papadimitriou, C.
\newblock Optimum statistical estimation with strategic data sources.
\newblock In \emph{Conference on Learning Theory}, pp.\  280--296. PMLR, 2015.

\bibitem[Caldas et~al.(2018)Caldas, Duddu, Wu, Li, Kone{\v{c}}n{\`y}, McMahan,
  Smith, and Talwalkar]{caldas2018leaf}
Caldas, S., Duddu, S. M.~K., Wu, P., Li, T., Kone{\v{c}}n{\`y}, J., McMahan,
  H.~B., Smith, V., and Talwalkar, A.
\newblock Leaf: A benchmark for federated settings.
\newblock \emph{arXiv preprint arXiv:1812.01097}, 2018.

\bibitem[Chayti et~al.(2021)Chayti, Karimireddy, Stich, Flammarion, and
  Jaggi]{chayti2021linear}
Chayti, E.~M., Karimireddy, S.~P., Stich, S.~U., Flammarion, N., and Jaggi, M.
\newblock Linear speedup in personalized collaborative learning.
\newblock \emph{arXiv preprint arXiv:2111.05968}, 2021.

\bibitem[Chung(1954)]{chung1954stochastic}
Chung, K.~L.
\newblock On a stochastic approximation method.
\newblock \emph{The Annals of Mathematical Statistics}, 1954.

\bibitem[Diakonikolas et~al.(2019)Diakonikolas, Kamath, Kane, Li, Moitra, and
  Stewart]{diakonikolas2019robust}
Diakonikolas, I., Kamath, G., Kane, D., Li, J., Moitra, A., and Stewart, A.
\newblock Robust estimators in high-dimensions without the computational
  intractability.
\newblock \emph{SIAM Journal on Computing}, 48\penalty0 (2):\penalty0 742--864,
  2019.

\bibitem[Donahue \& Kleinberg(2021{\natexlab{a}})Donahue and
  Kleinberg]{donahue2020model}
Donahue, K. and Kleinberg, J.
\newblock Model-sharing games: Analyzing federated learning under voluntary
  participation.
\newblock \emph{AAAI Conference on Artificial Intelligence},
  2021{\natexlab{a}}.

\bibitem[Donahue \& Kleinberg(2021{\natexlab{b}})Donahue and
  Kleinberg]{donahue2021optimality}
Donahue, K. and Kleinberg, J.
\newblock Optimality and stability in federated learning: A game-theoretic
  approach.
\newblock \emph{Conference on Neural Information Processing Systems (NeurIPS)},
  2021{\natexlab{b}}.

\bibitem[Fang \& Ye(2022)Fang and Ye]{fang2022robust}
Fang, X. and Ye, M.
\newblock Robust federated learning with noisy and heterogeneous clients.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2022.

\bibitem[Gao et~al.(2014)Gao, Mao, Chen, and Adams]{gao2014trick}
Gao, X.~A., Mao, A., Chen, Y., and Adams, R.~P.
\newblock Trick or treat: putting peer prediction to the test.
\newblock In \emph{Proceedings of the fifteenth ACM conference on Economics and
  computation}, pp.\  507--524, 2014.

\bibitem[Gradwohl \& Tennenholtz(2022)Gradwohl and
  Tennenholtz]{gradwohl2022coopetition}
Gradwohl, R. and Tennenholtz, M.
\newblock Coopetition against an amazon.
\newblock In \emph{International Symposium on Algorithmic Game Theory}, pp.\
  347--365. Springer, 2022.

\bibitem[Grimberg et~al.(2021)Grimberg, Hartley, Karimireddy, and
  Jaggi]{grimberg2021optimal}
Grimberg, F., Hartley, M.-A., Karimireddy, S.~P., and Jaggi, M.
\newblock Optimal model averaging: Towards personalized collaborative learning.
\newblock \emph{International Workshop on Federated Learning for User Privacy
  and Data Confidentiality in Conjunction with ICML 2021}, 2021.

\bibitem[Gupta et~al.(2022)Gupta, Ahuja, Havaei, Chatterjee, and
  Bengio]{gupta2022fl}
Gupta, S., Ahuja, K., Havaei, M., Chatterjee, N., and Bengio, Y.
\newblock Fl games: A federated learning framework for distribution shifts.
\newblock \emph{arXiv preprint arXiv:2205.11101}, 2022.

\bibitem[Jackson(2014)]{jackson2014mechanism}
Jackson, M.~O.
\newblock Mechanism theory.
\newblock \emph{Available at SSRN 2542983}, 2014.

\bibitem[Kairouz et~al.(2021)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji,
  Bonawitz, Charles, Cormode, Cummings, et~al.]{kairouz2021advances}
Kairouz, P., McMahan, H.~B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.~N.,
  Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et~al.
\newblock Advances and open problems in federated learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  2021.

\bibitem[Karger et~al.(2021)Karger, Monrad, Mellers, and
  Tetlock]{karger2021reciprocal}
Karger, E., Monrad, J., Mellers, B., and Tetlock, P.
\newblock Reciprocal scoring: A method for forecasting unanswerable questions.
\newblock \emph{Available at SSRN}, 2021.

\bibitem[Karimireddy et~al.(2022)Karimireddy, Guo, and
  Jordan]{karimireddy2022mechanisms}
Karimireddy, S.~P., Guo, W., and Jordan, M.
\newblock Mechanisms that incentivize data sharing in federated learning.
\newblock In \emph{Workshop on Federated Learning: Recent Advances and New
  Challenges (in Conjunction with NeurIPS 2022)}, 2022.

\bibitem[Konstantinov et~al.(2020)Konstantinov, Frantar, Alistarh, and
  Lampert]{konstantinov2020sample}
Konstantinov, N., Frantar, E., Alistarh, D., and Lampert, C.
\newblock On the sample complexity of adversarial multi-source pac learning.
\newblock In \emph{International Conference on Machine Learing (ICML)}, 2020.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence
  (AISTATS)}, 2017.

\bibitem[Miller et~al.(2005)Miller, Resnick, and
  Zeckhauser]{miller2005eliciting}
Miller, N., Resnick, P., and Zeckhauser, R.
\newblock Eliciting informative feedback: The peer-prediction method.
\newblock \emph{Management Science}, 51\penalty0 (9):\penalty0 1359--1373,
  2005.

\bibitem[Nash(1951)]{nash1951non}
Nash, J.
\newblock Non-cooperative games.
\newblock \emph{The Annals of Mathematics}, 54\penalty0 (2):\penalty0 286--295,
  1951.

\bibitem[Osborne \& Rubinstein(1994)Osborne and Rubinstein]{osborne1994course}
Osborne, M.~J. and Rubinstein, A.
\newblock \emph{A course in game theory}.
\newblock MIT press, 1994.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Qiao \& Valiant(2018)Qiao and Valiant]{qiao2017learning}
Qiao, M. and Valiant, G.
\newblock Learning discrete distributions from untrusted batches.
\newblock \emph{Innovations of Theoretical Computer Science (ITCS)}, 2018.

\bibitem[Rakhlin et~al.(2012)Rakhlin, Shamir, and Sridharan]{rakhlin2012making}
Rakhlin, A., Shamir, O., and Sridharan, K.
\newblock Making gradient descent optimal for strongly convex stochastic
  optimization.
\newblock In \emph{Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pp.\  1571--1578, 2012.

\bibitem[Shejwalkar et~al.(2022)Shejwalkar, Houmansadr, Kairouz, and
  Ramage]{shejwalkar2022back}
Shejwalkar, V., Houmansadr, A., Kairouz, P., and Ramage, D.
\newblock Back to the drawing board: A critical evaluation of poisoning attacks
  on production federated learning.
\newblock In \emph{IEEE Symposium on Security and Privacy}, 2022.

\bibitem[Stein(1956)]{stein1956inadmissibility}
Stein, C.
\newblock Inadmissibility of the usual estimator for the mean of a multivariate
  normal distribution.
\newblock In \emph{Proceedings of the Third Berkeley Symposium on Mathematical
  Statistics and Probability, Volume 1: Contributions to the Theory of
  Statistics}, volume~3, pp.\  197--207. University of California Press, 1956.

\bibitem[Tolpegin et~al.(2020)Tolpegin, Truex, Gursoy, and
  Liu]{tolpegin2020data}
Tolpegin, V., Truex, S., Gursoy, M.~E., and Liu, L.
\newblock Data poisoning attacks against federated learning systems.
\newblock In \emph{European Symposium on Research in Computer Security}, 2020.

\bibitem[Tu et~al.(2021)Tu, Zhu, Luong, Niyato, Zhang, and Li]{tu2021incentive}
Tu, X., Zhu, K., Luong, N.~C., Niyato, D., Zhang, Y., and Li, J.
\newblock Incentive mechanisms for federated learning: From economic and game
  theoretic perspective.
\newblock \emph{arXiv preprint arXiv:2111.11850}, 2021.

\bibitem[Waggoner \& Chen(2014)Waggoner and Chen]{waggoner2014output}
Waggoner, B. and Chen, Y.
\newblock Output agreement mechanisms and common knowledge.
\newblock In \emph{Second AAAI Conference on Human Computation and
  Crowdsourcing}, 2014.

\bibitem[Witkowski \& Parkes(2012)Witkowski and Parkes]{witkowski2012peer}
Witkowski, J. and Parkes, D.~C.
\newblock Peer prediction without a common prior.
\newblock In \emph{Proceedings of the 13th ACM Conference on Electronic
  Commerce}, pp.\  964--981, 2012.

\bibitem[Yin et~al.(2018)Yin, Chen, Kannan, and Bartlett]{yin2018byzantine}
Yin, D., Chen, Y., Kannan, R., and Bartlett, P.
\newblock Byzantine-robust distributed learning: Towards optimal statistical
  rates.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\end{thebibliography}
