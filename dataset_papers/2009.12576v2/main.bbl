\begin{thebibliography}{10}

\bibitem{fahlman1983massively}
Scott~E Fahlman, Geoffrey~E Hinton, and Terrence~J Sejnowski.
\newblock Massively parallel architectures for al: Netl, thistle, and boltzmann
  machines.
\newblock In {\em National Conference on Artificial Intelligence, AAAI}, 1983.

\bibitem{russell1998learning}
Stuart Russell.
\newblock Learning agents for uncertain environments.
\newblock In {\em Proceedings of the eleventh annual conference on
  Computational learning theory}, pages 101--103. ACM, 1998.

\bibitem{choi2011inverse}
Jaedeug Choi and Kee-Eung Kim.
\newblock Inverse reinforcement learning in partially observable environments.
\newblock {\em Journal of Machine Learning Research}, 12(Mar):691--730, 2011.

\bibitem{babes2011apprenticeship}
Monica Babes, Vukosi Marivate, Kaushik Subramanian, and Michael~L Littman.
\newblock Apprenticeship learning about multiple intentions.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pages 897--904, 2011.

\bibitem{dvijotham2010inverse}
Krishnamurthy Dvijotham and Emanuel Todorov.
\newblock Inverse optimal control with linearly-solvable mdps.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 335--342, 2010.

\bibitem{schmitt2017see}
Felix Schmitt, Hans-Joachim Bieg, Michael Herman, and Constantin~A Rothkopf.
\newblock I see what you see: Inferring sensor and policy models of human
  real-world motor behavior.
\newblock In {\em AAAI}, pages 3797--3803, 2017.

\bibitem{IRC_PNAS}
Z.~Wu, M.~Kwon, S.~Daptardar, P.~Schrater, and X.~Pitkow.
\newblock Rational thoughts in neural codes.
\newblock {\em Proceedings of the National Academy of Sciences of the United
  States of America}, 2020.

\bibitem{sutton1998reinforcement}
Richard~S Sutton, Andrew~G Barto, et~al.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 1998.

\bibitem{aastrom1965optimal}
Karl~Johan {\AA}str{\"o}m.
\newblock Optimal control of markov processes with incomplete state
  information.
\newblock {\em Journal of Mathematical Analysis and Applications},
  10(1):174--205, 1965.

\bibitem{kaelbling1998planning}
Leslie~Pack Kaelbling, Michael~L Littman, and Anthony~R Cassandra.
\newblock Planning and acting in partially observable stochastic domains.
\newblock {\em Artificial intelligence}, 101(1-2):99--134, 1998.

\bibitem{rao2010decision}
Rajesh~PN Rao.
\newblock Decision making under uncertainty: a neural model based on partially
  observable markov decision processes.
\newblock {\em Frontiers in computational neuroscience}, 4:146, 2010.

\bibitem{simon1972theories}
Herbert~A Simon.
\newblock Theories of bounded rationality.
\newblock {\em Decision and organization}, 1(1):161--176, 1972.

\bibitem{ng2000algorithms}
Andrew~Y Ng, Stuart~J Russell, et~al.
\newblock Algorithms for inverse reinforcement learning.
\newblock In {\em Icml}, pages 663--670, 2000.

\bibitem{abbeel2004apprenticeship}
Pieter Abbeel and Andrew~Y Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In {\em Proceedings of the twenty-first international conference on
  Machine learning}, page~1. ACM, 2004.

\bibitem{ratliff2006maximum}
Nathan~D Ratliff, J~Andrew Bagnell, and Martin~A Zinkevich.
\newblock Maximum margin planning.
\newblock In {\em Proceedings of the 23rd international conference on Machine
  learning}, pages 729--736, 2006.

\bibitem{chalk2019inferring}
Matthew Chalk, Ga{\v{s}}per Tka{\v{c}}ik, and Olivier Marre.
\newblock Inferring the function performed by a recurrent neural network.
\newblock {\em bioRxiv}, page 598086, 2019.

\bibitem{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In {\em AAAI}, volume~8, pages 1433--1438. Chicago, IL, USA, 2008.

\bibitem{jaynes1957information}
Edwin~T Jaynes.
\newblock Information theory and statistical mechanics.
\newblock {\em Physical review}, 106(4):620, 1957.

\bibitem{vazquez2018learning}
Marcell Vazquez-Chanlatte, Susmit Jha, Ashish Tiwari, Mark~K Ho, and Sanjit
  Seshia.
\newblock Learning task specifications from demonstrations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5367--5377, 2018.

\bibitem{scobee2020maximum}
Dexter~RR Scobee and S~Shankar Sastry.
\newblock Maximum likelihood constraint inference for inverse reinforcement
  learning.
\newblock In {\em Proceedings of 8th International Conference on Learning
  Representations}, 2020.

\bibitem{ho2016generative}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4565--4573, 2016.

\bibitem{Jeon2018ABA}
Wonseok Jeon, Seokin Seo, and Kee-Eung Kim.
\newblock A bayesian approach to generative adversarial imitation learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{Ravindran2019ADAILAA}
Balaraman Ravindran and Sergey Levine.
\newblock Adail: Adaptive adversarial imitation learning.
\newblock In {\em NeurIPS Workshop on Learning Transferable Skills}, 2019.

\bibitem{gangwani2020state}
Tanmay Gangwani and Jian Peng.
\newblock State-only imitation with transition dynamics mismatch.
\newblock In {\em Proceedings of 8th International Conference on Learning
  Representations}, 2020.

\bibitem{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, pages 1126--1135. JMLR. org, 2017.

\bibitem{zintgraf2019fast}
Luisa~M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, and Shimon
  Whiteson.
\newblock Fast context adaptation via meta-learning.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning}, 2019.

\bibitem{alet2020meta}
Ferran Alet, Martin~F Schneider, Tomas Lozano-Perez, and Leslie~Pack Kaelbling.
\newblock Meta-learning curiosity algorithms.
\newblock In {\em Proceedings of 8th International Conference on Learning
  Representations}, 2020.

\bibitem{fakoor2020meta}
Rasool Fakoor, Pratik Chaudhari, Stefano Soatto, and Alexander~J Smola.
\newblock Meta-q-learning.
\newblock In {\em Proceedings of 8th International Conference on Learning
  Representations}, 2020.

\bibitem{humplik2019meta}
Jan Humplik, Alexandre Galashov, Leonard Hasenclever, Pedro~A Ortega, Yee~Whye
  Teh, and Nicolas Heess.
\newblock Meta reinforcement learning as task inference.
\newblock In {\em Proceedings of 7th International Conference on Learning
  Representations}, 2019.

\bibitem{yoon2018bayesian}
Jaesik Yoon, Taesup Kim, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and Sungjin
  Ahn.
\newblock Bayesian model-agnostic meta-learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  7332--7342, 2018.

\bibitem{doya2007bayesian}
Kenji Doya, Shin Ishii, Alexandre Pouget, and Rajesh~PN Rao.
\newblock {\em Bayesian brain: Probabilistic approaches to neural coding}.
\newblock MIT press, 2007.

\bibitem{dayan2008decision}
Peter Dayan and Nathaniel~D Daw.
\newblock Decision theory, reinforcement learning, and the brain.
\newblock {\em Cognitive, Affective, \& Behavioral Neuroscience},
  8(4):429--453, 2008.

\bibitem{huang2013reward}
Yanping Huang and Rajesh~PN Rao.
\newblock Reward optimization in the primate brain: A probabilistic model of
  decision making under uncertainty.
\newblock {\em PloS one}, 8(1), 2013.

\bibitem{houlsby2013cognitive}
Neil~MT Houlsby, Ferenc Husz{\'a}r, Mohammad~M Ghassemi, Gerg{\H{o}} Orb{\'a}n,
  Daniel~M Wolpert, and M{\'a}t{\'e} Lengyel.
\newblock Cognitive tomography reveals complex, task-independent mental
  representations.
\newblock {\em Current Biology}, 23(21):2169--2175, 2013.

\bibitem{daunizeau2010observing1}
Jean Daunizeau, Hanneke~EM Den~Ouden, Matthias Pessiglione, Stefan~J Kiebel,
  Klaas~E Stephan, and Karl~J Friston.
\newblock Observing the observer (i): meta-bayesian models of learning and
  decision-making.
\newblock {\em PloS one}, 5(12), 2010.

\bibitem{daunizeau2010observing2}
Jean Daunizeau, Hanneke~EM Den~Ouden, Matthias Pessiglione, Stefan~J Kiebel,
  Karl~J Friston, and Klaas~E Stephan.
\newblock Observing the observer (ii): deciding when to decide.
\newblock {\em PLoS one}, 5(12), 2010.

\bibitem{bourgin2019cognitive}
David~D Bourgin, Joshua~C Peterson, Daniel Reichman, Stuart~J Russell, and
  Thomas~L Griffiths.
\newblock Cognitive model priors for predicting human decisions.
\newblock In {\em International conference on machine learning}, pages
  5133--5141, 2019.

\bibitem{howes2009rational}
Andrew Howes, Richard~L Lewis, and Alonso Vera.
\newblock Rational adaptation under task and processing constraints:
  Implications for testing theories of cognition and action.
\newblock {\em Psychological review}, 116(4):717, 2009.

\bibitem{lewis2014computational}
Richard~L Lewis, Andrew Howes, and Satinder Singh.
\newblock Computational rationality: Linking mechanism and behavior through
  bounded utility maximization.
\newblock {\em Topics in cognitive science}, 6(2):279--311, 2014.

\bibitem{lieder2020resource}
Falk Lieder and Thomas~L Griffiths.
\newblock Resource-rational analysis: understanding human cognition as the
  optimal use of limited computational resources.
\newblock {\em Behavioral and Brain Sciences}, 43, 2020.

\bibitem{beck2012not}
Jeffrey~M Beck, Wei~Ji Ma, Xaq Pitkow, Peter~E Latham, and Alexandre Pouget.
\newblock Not noisy, just wrong: the role of suboptimal inference in behavioral
  variability.
\newblock {\em Neuron}, 74(1):30--39, 2012.

\bibitem{LAKSHMINARASIMHAN2018194}
Kaushik~J. Lakshminarasimhan, Marina Petsalis, Hyeshin Park, Gregory~C.
  DeAngelis, Xaq Pitkow, and Dora~E. Angelaki.
\newblock A dynamic bayesian observer model reveals origins of bias in visual
  path integration.
\newblock {\em Neuron}, 99(1):194 -- 206.e5, 2018.

\bibitem{lakshminarasimhan2020tracking}
Kaushik~J Lakshminarasimhan, Eric Avila, Erin Neyhart, Gregory~C DeAngelis, Xaq
  Pitkow, and Dora~E Angelaki.
\newblock Tracking the mind's eye: Primate gaze behavior during virtual
  visuomotor navigation reflects belief dynamics.
\newblock {\em Neuron}, pages 662--674, May 2020.

\bibitem{crosby2019animal}
Matthew Crosby, Benjamin Beyret, and Marta Halina.
\newblock The animal-ai olympics.
\newblock {\em Nature Machine Intelligence}, 1(5):257--257, 2019.

\bibitem{crosby-web}
The animal-{AI} testbed.
\newblock \url{http://animalaiolympics.com/AAI/}.

\bibitem{bellman1957markovian}
Richard Bellman.
\newblock A markovian decision process.
\newblock {\em Journal of mathematics and mechanics}, pages 679--684, 1957.

\bibitem{howard1960dynamic}
Ronald~A Howard.
\newblock Dynamic programming and markov processes.
\newblock 1960.

\bibitem{van1976set}
JAEE Van~Nunen.
\newblock A set of successive approximation methods for discounted markovian
  decision problems.
\newblock {\em Zeitschrift fuer operations research}, 20(5):203--208, 1976.

\bibitem{puterman1978modified}
Martin~L Puterman and Moon~Chirl Shin.
\newblock Modified policy iteration algorithms for discounted markov decision
  problems.
\newblock {\em Management Science}, 24(11):1127--1137, 1978.

\bibitem{julier2004unscented}
Simon~J Julier and Jeffrey~K Uhlmann.
\newblock Unscented filtering and nonlinear estimation.
\newblock {\em Proceedings of the IEEE}, 92(3):401--422, 2004.

\bibitem{vertes2018flexible}
Eszter V{\'e}rtes and Maneesh Sahani.
\newblock Flexible and accurate inference and learning for deep generative
  models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4166--4175, 2018.

\bibitem{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  35(8):1798--1828, 2013.

\bibitem{DDPG}
T.~P. Lillicrap, J.~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa,
  D.~Silver, and D.~Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock In {\em {ICLR}}, 2016.

\bibitem{lazaric2008reinforcement}
Alessandro Lazaric, Marcello Restelli, and Andrea Bonarini.
\newblock Reinforcement learning in continuous action spaces through sequential
  monte carlo methods.
\newblock In {\em Advances in neural information processing systems}, pages
  833--840, 2008.

\bibitem{konda2000actor}
Vijay~R Konda and John~N Tsitsiklis.
\newblock Actor-critic algorithms.
\newblock In {\em Advances in neural information processing systems}, pages
  1008--1014, 2000.

\bibitem{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock {\em arXiv preprint arXiv:1801.01290}, 2018.

\bibitem{simmons2019q}
Riley Simmons-Edler, Ben Eisner, Eric Mitchell, Sebastian Seung, and Daniel
  Lee.
\newblock Q-learning for continuous actions with cross-entropy guided policies.
\newblock {\em arXiv preprint arXiv:1903.10605}, 2019.

\bibitem{bishop2006pattern}
Christopher~M Bishop.
\newblock {\em Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem{lakshminarasimhan2018dynamic}
Kaushik~J Lakshminarasimhan, Marina Petsalis, Hyeshin Park, Gregory~C
  DeAngelis, Xaq Pitkow, and Dora~E Angelaki.
\newblock A dynamic bayesian observer model reveals origins of bias in visual
  path integration.
\newblock {\em Neuron}, 2018.

\bibitem{baker2017rational}
Chris~L Baker, Julian Jara-Ettinger, Rebecca Saxe, and Joshua~B Tenenbaum.
\newblock Rational quantitative attribution of beliefs, desires and percepts in
  human mentalizing.
\newblock {\em Nature Human Behaviour}, 1(4):1--10, 2017.

\bibitem{rafferty2015inferring}
Anna~N Rafferty, Michelle~M LaMar, and Thomas~L Griffiths.
\newblock Inferring learners' knowledge from their actions.
\newblock {\em Cognitive Science}, 39(3):584--618, 2015.

\bibitem{baker2011bayesian}
Chris Baker, Rebecca Saxe, and Joshua Tenenbaum.
\newblock Bayesian theory of mind: Modeling joint belief-desire attribution.
\newblock In {\em Proceedings of the annual meeting of the cognitive science
  society}, volume~33, 2011.

\bibitem{dempster1977maximum}
Arthur~P Dempster, Nan~M Laird, and Donald~B Rubin.
\newblock Maximum likelihood from incomplete data via the em algorithm.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 39(1):1--22, 1977.

\end{thebibliography}
