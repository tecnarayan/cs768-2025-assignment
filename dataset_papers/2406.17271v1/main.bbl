\begin{thebibliography}{100}

\bibitem{abdin2024phi}
Marah Abdin, Sam~Ade Jacobs, Ammar~Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat Behl, et~al.
\newblock Phi-3 technical report: A highly capable language model locally on your phone.
\newblock {\em arXiv preprint arXiv:2404.14219}, 2024.

\bibitem{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{litgpt-2023}
Lightning AI.
\newblock Litgpt.
\newblock \url{https://github.com/Lightning-AI/litgpt}, 2023.

\bibitem{claude3model}
Anthropic.
\newblock The claude 3 model family: Opus, sonnet, haiku.
\newblock Technical report, Anthropic, 2024.

\bibitem{askell2021general}
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et~al.
\newblock A general language assistant as a laboratory for alignment.
\newblock {\em arXiv preprint arXiv:2112.00861}, 2021.

\bibitem{azerbayev2023llemma}
Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco~Dos Santos, Stephen McAleer, Albert~Q Jiang, Jia Deng, Stella Biderman, and Sean Welleck.
\newblock Llemma: An open language model for mathematics.
\newblock {\em arXiv preprint arXiv:2310.10631}, 2023.

\bibitem{balloccu2024leak}
Simone Balloccu, Patr{\'\i}cia Schmidtov{\'a}, Mateusz Lango, and Ond{\v{r}}ej Du{\v{s}}ek.
\newblock Leak, cheat, repeat: Data contamination and evaluation malpractices in closed-source llms.
\newblock {\em arXiv preprint arXiv:2402.03927}, 2024.

\bibitem{bender2021dangers}
Emily~M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.
\newblock On the dangers of stochastic parrots: Can language models be too big?
\newblock In {\em Proceedings of the 2021 ACM conference on fairness, accountability, and transparency}, pages 610--623, 2021.

\bibitem{biderman2024emergent}
Stella Biderman, USVSN PRASHANTH, Lintang Sutawika, Hailey Schoelkopf, Quentin Anthony, Shivanshu Purohit, and Edward Raff.
\newblock Emergent and predictable memorization in large language models.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems}, 33:1877--1901, 2020.

\bibitem{bubeck2023sparks}
S{\'e}bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg, et~al.
\newblock Sparks of artificial general intelligence: Early experiments with gpt-4.
\newblock {\em arXiv preprint arXiv:2303.12712}, 2023.

\bibitem{burns2023weaktostrong}
Collin Burns, Pavel Izmailov, Jan~Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan Leike, Ilya Sutskever, and Jeff Wu.
\newblock Weak-to-strong generalization: Eliciting strong capabilities with weak supervision, 2023.

\bibitem{carlini2022quantifying}
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang.
\newblock Quantifying memorization across neural language models.
\newblock {\em arXiv preprint arXiv:2202.07646}, 2022.

\bibitem{chang2024survey}
Yupeng Chang, Xu~Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et~al.
\newblock A survey on evaluation of large language models.
\newblock {\em ACM Transactions on Intelligent Systems and Technology}, 15(3):1--45, 2024.

\bibitem{chen2023skills}
Jiaao Chen, Xiaoman Pan, Dian Yu, Kaiqiang Song, Xiaoyang Wang, Dong Yu, and Jianshu Chen.
\newblock Skills-in-context prompting: Unlocking compositionality in large language models.
\newblock {\em arXiv preprint arXiv:2308.00304}, 2023.

\bibitem{chen2021codex}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique~Ponde de~Oliveira~Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe~Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William~Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew~N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba.
\newblock Evaluating large language models trained on code.
\newblock 2021.

\bibitem{chuang2024simulating}
Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy~T. Rogers.
\newblock Simulating opinion dynamics with networks of llm-based agents, 2024.

\bibitem{Clark2018ThinkYH}
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.
\newblock Think you have solved question answering? try arc, the ai2 reasoning challenge.
\newblock {\em ArXiv}, abs/1803.05457, 2018.

\bibitem{cobbe2021gsm8k}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
\newblock Training verifiers to solve math word problems.
\newblock {\em arXiv preprint arXiv:2110.14168}, 2021.

\bibitem{cohere2023command}
Cohere.
\newblock Command.
\newblock \url{https://cohere.com/command}, 2023.
\newblock Accessed: 2024-04-28.

\bibitem{deng2023investigating}
Chunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Gerstein, and Arman Cohan.
\newblock Investigating data contamination in modern benchmarks for large language models.
\newblock {\em arXiv preprint arXiv:2311.09783}, 2023.

\bibitem{ding2023enhancing}
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou.
\newblock Enhancing chat language models by scaling high-quality instructional conversations.
\newblock {\em arXiv preprint arXiv:2305.14233}, 2023.

\bibitem{dong2022survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce~Zheng, Zhiyong Wu, Baobao Chang, Xu~Sun, Jingjing Xu, and Zhifang Sui.
\newblock A survey on in-context learning.
\newblock {\em arXiv preprint arXiv:2301.00234}, 2022.

\bibitem{dong2024generalization}
Yihong Dong, Xue Jiang, Huanyu Liu, Zhi Jin, and Ge~Li.
\newblock Generalization or memorization: Data contamination and trustworthy evaluation for large language models.
\newblock {\em arXiv preprint arXiv:2402.15938}, 2024.

\bibitem{dziri2024faith}
Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang~Lorraine Li, Liwei Jiang, Bill~Yuchen Lin, Sean Welleck, Peter West, Chandra Bhagavatula, Ronan Le~Bras, et~al.
\newblock Faith and fate: Limits of transformers on compositionality.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{feng-etal-2023-factkb}
Shangbin Feng, Vidhisha Balachandran, Yuyang Bai, and Yulia Tsvetkov.
\newblock {F}act{KB}: Generalizable factuality evaluation using language models enhanced with factual knowledge.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 933--952, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{gao2023adaptive}
Irena Gao, Gabriel Ilharco, Scott Lundberg, and Marco~Tulio Ribeiro.
\newblock Adaptive testing of computer vision models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4003--4014, 2023.

\bibitem{gao2023pal}
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig.
\newblock Pal: Program-aided language models.
\newblock In {\em International Conference on Machine Learning}, pages 10764--10799. PMLR, 2023.

\bibitem{golchin2023data}
Shahriar Golchin and Mihai Surdeanu.
\newblock Data contamination quiz: A tool to detect and estimate contamination in large language models.
\newblock {\em arXiv preprint arXiv:2311.06233}, 2023.

\bibitem{golchin2023time}
Shahriar Golchin and Mihai Surdeanu.
\newblock Time travel in llms: Tracing data contamination in large language models.
\newblock {\em arXiv preprint arXiv:2308.08493}, 2023.

\bibitem{goodrich2019assessing}
Ben Goodrich, Vinay Rao, Peter~J Liu, and Mohammad Saleh.
\newblock Assessing the factual accuracy of generated text.
\newblock In {\em proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining}, pages 166--175, 2019.

\bibitem{haluptzok2022language}
Patrick Haluptzok, Matthew Bowers, and Adam~Tauman Kalai.
\newblock Language models can teach themselves to program better.
\newblock {\em arXiv preprint arXiv:2207.14502}, 2022.

\bibitem{hendrycks2021ethics}
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt.
\newblock Aligning ai with shared human values.
\newblock {\em Proceedings of the International Conference on Learning Representations (ICLR)}, 2021.

\bibitem{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock {\em arXiv preprint arXiv:2009.03300}, 2020.

\bibitem{hendryckstest2021}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock {\em Proceedings of the International Conference on Learning Representations (ICLR)}, 2021.

\bibitem{hendrycksmath2021}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock {\em NeurIPS}, 2021.

\bibitem{hu2021lora}
Edward~J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, Weizhu Chen, et~al.
\newblock Lora: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{huang2023survey}
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et~al.
\newblock A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.
\newblock {\em arXiv preprint arXiv:2311.05232}, 2023.

\bibitem{huang2022inner}
Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et~al.
\newblock Inner monologue: Embodied reasoning through planning with language models.
\newblock {\em arXiv preprint arXiv:2207.05608}, 2022.

\bibitem{huang2024key}
Yiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, and Weizhu Chen.
\newblock Key-point-driven data synthesis with its enhancement on mathematical reasoning.
\newblock {\em arXiv preprint arXiv:2403.02333}, 2024.

\bibitem{huang2024c}
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Yao Fu, et~al.
\newblock C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{hubinger2024sleeper}
Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel~M Ziegler, Tim Maxwell, Newton Cheng, et~al.
\newblock Sleeper agents: Training deceptive llms that persist through safety training.
\newblock {\em arXiv preprint arXiv:2401.05566}, 2024.

\bibitem{jacovi-etal-2023-stop}
Alon Jacovi, Avi Caciularu, Omer Goldman, and Yoav Goldberg.
\newblock Stop uploading test data in plain text: Practical strategies for mitigating data contamination by evaluation benchmarks.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 5075--5084, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{ji2023survey}
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye~Jin Bang, Andrea Madotto, and Pascale Fung.
\newblock Survey of hallucination in natural language generation.
\newblock {\em ACM Computing Surveys}, 55(12):1--38, 2023.

\bibitem{jiang2023mistral}
Albert~Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et~al.
\newblock Mistral 7b.
\newblock {\em arXiv preprint arXiv:2310.06825}, 2023.

\bibitem{jiang2024mixtral}
Albert~Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Emma~Bou Hanna, Florian Bressand, et~al.
\newblock Mixtral of experts.
\newblock {\em arXiv preprint arXiv:2401.04088}, 2024.

\bibitem{jiang2024investigating}
Minhao Jiang, Ken~Ziyu Liu, Ming Zhong, Rylan Schaeffer, Siru Ouyang, Jiawei Han, and Sanmi Koyejo.
\newblock Investigating data contamination for pre-training language models.
\newblock {\em arXiv preprint arXiv:2401.06059}, 2024.

\bibitem{kiela-etal-2021-dynabench}
Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, and Adina Williams.
\newblock Dynabench: Rethinking benchmarking in {NLP}.
\newblock In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz~Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors, {\em Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 4110--4124, Online, June 2021. Association for Computational Linguistics.

\bibitem{kojima2022large}
Takeshi Kojima, Shixiang~Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.
\newblock Large language models are zero-shot reasoners.
\newblock {\em Advances in neural information processing systems}, 35:22199--22213, 2022.

\bibitem{lambert2024rewardbench}
Nathan Lambert, Valentina Pyatkin, Jacob Morrison, LJ~Miranda, Bill~Yuchen Lin, Khyathi Chandu, Nouha Dziri, Sachin Kumar, Tom Zick, Yejin Choi, et~al.
\newblock Rewardbench: Evaluating reward models for language modeling.
\newblock {\em arXiv preprint arXiv:2403.13787}, 2024.

\bibitem{lei2023s3eval}
Fangyu Lei, Qian Liu, Yiming Huang, Shizhu He, Jun Zhao, and Kang Liu.
\newblock S3eval: A synthetic, scalable, systematic evaluation suite for large language models.
\newblock {\em arXiv preprint arXiv:2310.15147}, 2023.

\bibitem{li2024task}
Changmao Li and Jeffrey Flanigan.
\newblock Task contamination: Language models may not be few-shot anymore.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 18471--18480, 2024.

\bibitem{li2024common}
Chen Li, Weiqi Wang, Jingcheng Hu, Yixuan Wei, Nanning Zheng, Han Hu, Zheng Zhang, and Houwen Peng.
\newblock Common 7b language models already possess strong math capabilities.
\newblock {\em arXiv preprint arXiv:2403.04706}, 2024.

\bibitem{li2024treeeval}
Xiang Li, Yunshi Lan, and Chao Yang.
\newblock Treeeval: Benchmark-free evaluation of large language models through tree planning.
\newblock {\em arXiv preprint arXiv:2402.13125}, 2024.

\bibitem{li2023alpacaeval}
Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori~B Hashimoto.
\newblock Alpacaeval: An automatic evaluator of instruction-following models, 2023.

\bibitem{li2023estimating}
Yucheng Li.
\newblock Estimating contamination via perplexity: Quantifying memorisation in language model evaluation.
\newblock {\em arXiv preprint arXiv:2309.10677}, 2023.

\bibitem{li2024latesteval}
Yucheng Li, Frank Guerin, and Chenghua Lin.
\newblock Latesteval: Addressing data contamination in language model evaluation through dynamic and time-sensitive test construction.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 18600--18607, 2024.

\bibitem{liang2022holistic}
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et~al.
\newblock Holistic evaluation of language models.
\newblock {\em arXiv preprint arXiv:2211.09110}, 2022.

\bibitem{liu2024best}
Ruibo Liu, Jerry Wei, Fangyu Liu, Chenglei Si, Yanzhe Zhang, Jinmeng Rao, Steven Zheng, Daiyi Peng, Diyi Yang, Denny Zhou, et~al.
\newblock Best practices and lessons learned on synthetic data for language models.
\newblock {\em arXiv preprint arXiv:2404.07503}, 2024.

\bibitem{liu2023makes}
Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He.
\newblock What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning.
\newblock {\em arXiv preprint arXiv:2312.15685}, 2023.

\bibitem{lu2024chameleon}
Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying~Nian Wu, Song-Chun Zhu, and Jianfeng Gao.
\newblock Chameleon: Plug-and-play compositional reasoning with large language models.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{luo2023wizardmath}
Haipeng Luo, Qingfeng Sun, Can Xu, Pu~Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang.
\newblock Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct.
\newblock {\em arXiv preprint arXiv:2308.09583}, 2023.

\bibitem{ma2023large}
Tianhui Ma, Yuan Cheng, Hengshu Zhu, and Hui Xiong.
\newblock Large language models are not stable recommender systems.
\newblock {\em arXiv preprint arXiv:2312.15746}, 2023.

\bibitem{Ma2021DynaboardAE}
Zhiyi Ma, Kawin Ethayarajh, Tristan Thrush, Somya Jain, Ledell~Yu Wu, Robin Jia, Christopher Potts, Adina Williams, and Douwe Kiela.
\newblock Dynaboard: An evaluation-as-a-service platform for holistic next-generation benchmarking.
\newblock In {\em Neural Information Processing Systems}, 2021.

\bibitem{madaan2024self}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et~al.
\newblock Self-refine: Iterative refinement with self-feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{magar-schwartz-2022-data}
Inbal Magar and Roy Schwartz.
\newblock Data contamination: From memorization to exploitation.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, {\em Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}, pages 157--165, Dublin, Ireland, May 2022. Association for Computational Linguistics.

\bibitem{magar2022data}
Inbal Magar and Roy Schwartz.
\newblock Data contamination: From memorization to exploitation.
\newblock {\em arXiv preprint arXiv:2203.08242}, 2022.

\bibitem{meta2023metallama3}
Meta.
\newblock Introducing meta llama 3: The most capable openly available llm to date.
\newblock \url{https://ai.meta.com/blog/meta-llama-3/}, 2024.
\newblock Accessed: 2024-04-28.

\bibitem{mialon2023augmented}
Gr{\'e}goire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et~al.
\newblock Augmented language models: a survey.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{min2021metaicl}
Sewon Min, Mike Lewis, Luke Zettlemoyer, and Hannaneh Hajishirzi.
\newblock Metaicl: Learning to learn in context.
\newblock {\em arXiv preprint arXiv:2110.15943}, 2021.

\bibitem{mistralai_2024}
{Mistral AI Team}.
\newblock {Mixtral 8x22B}.
\newblock \url{https://mistral.ai/news/mixtral-8x22b/}, April 2024.
\newblock Accessed: 2024-05-01.

\bibitem{nikolenko2021synthetic}
Sergey~I Nikolenko.
\newblock {\em Synthetic data for deep learning}, volume 174.
\newblock Springer, 2021.

\bibitem{openai2024hello}
OpenAI.
\newblock Hello gpt-4o.
\newblock \url{https://openai.com/index/hello-gpt-4o/}, 2024.
\newblock Accessed: 2024-05-21.

\bibitem{oren2023proving}
Yonatan Oren, Nicole Meister, Niladri Chatterji, Faisal Ladhak, and Tatsunori~B Hashimoto.
\newblock Proving test set contamination in black box language models.
\newblock {\em arXiv preprint arXiv:2310.17623}, 2023.

\bibitem{parrish-etal-2022-bbq}
Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu~Mon Htut, and Samuel Bowman.
\newblock {BBQ}: A hand-built bias benchmark for question answering.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, {\em Findings of the Association for Computational Linguistics: ACL 2022}, pages 2086--2105, Dublin, Ireland, May 2022. Association for Computational Linguistics.

\bibitem{perez-etal-2022-red}
Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving.
\newblock Red teaming language models with language models.
\newblock In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, {\em Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pages 3419--3448, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.

\bibitem{perez2022discovering}
Ethan Perez, Sam Ringer, Kamil{\.e} Luko{\v{s}}i{\=u}t{\.e}, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, et~al.
\newblock Discovering language model behaviors with model-written evaluations.
\newblock {\em arXiv preprint arXiv:2212.09251}, 2022.

\bibitem{pit2024on}
Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Putrasmey Keo, Watey Diep, and Yu-Gang Jiang.
\newblock Whose side are you on? investigating the political stance of large language models, 2024.

\bibitem{reid2024gemini}
Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, et~al.
\newblock Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.
\newblock {\em arXiv preprint arXiv:2403.05530}, 2024.

\bibitem{ribeiro-lundberg-2022-adaptive}
Marco~Tulio Ribeiro and Scott Lundberg.
\newblock Adaptive testing and debugging of {NLP} models.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, {\em Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 3253--3267, Dublin, Ireland, May 2022. Association for Computational Linguistics.

\bibitem{roberts2023cutoff}
Manley Roberts, Himanshu Thakur, Christine Herlihy, Colin White, and Samuel Dooley.
\newblock To the cutoff... and beyond? a longitudinal perspective on llm data contamination.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2023.

\bibitem{sainz-etal-2023-nlp}
Oscar Sainz, Jon Campos, Iker Garc{\'\i}a-Ferrero, Julen Etxaniz, Oier~Lopez de~Lacalle, and Eneko Agirre.
\newblock {NLP} evaluation in trouble: On the need to measure {LLM} data contamination for each benchmark.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Findings of the Association for Computational Linguistics: EMNLP 2023}, pages 10776--10787, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{schick2024toolformer}
Timo Schick, Jane Dwivedi-Yu, Roberto Dess{\`\i}, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
\newblock Toolformer: Language models can teach themselves to use tools.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{shaikh-etal-2023-second}
Omar Shaikh, Hongxin Zhang, William Held, Michael Bernstein, and Diyi Yang.
\newblock On second thought, let{'}s not think step by step! bias and toxicity in zero-shot reasoning.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, {\em Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 4454--4470, Toronto, Canada, July 2023. Association for Computational Linguistics.

\bibitem{shao2024deepseekmath}
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, YK~Li, Y~Wu, and Daya Guo.
\newblock Deepseekmath: Pushing the limits of mathematical reasoning in open language models.
\newblock {\em arXiv preprint arXiv:2402.03300}, 2024.

\bibitem{shen2024hugginggpt}
Yongliang Shen, Kaitao Song, Xu~Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang.
\newblock Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{shi2023detecting}
Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen, and Luke Zettlemoyer.
\newblock Detecting pretraining data from large language models.
\newblock {\em arXiv preprint arXiv:2310.16789}, 2023.

\bibitem{shinn2024reflexion}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{shypula2023learning}
Alexander Shypula, Aman Madaan, Yimeng Zeng, Uri Alon, Jacob Gardner, Milad Hashemi, Graham Neubig, Parthasarathy Ranganathan, Osbert Bastani, and Amir Yazdanbakhsh.
\newblock Learning performance-improving code edits.
\newblock {\em arXiv preprint arXiv:2302.07867}, 2023.

\bibitem{si2022prompting}
Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan~Lee Boyd-Graber, and Lijuan Wang.
\newblock Prompting gpt-3 to be reliable.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{suzgun2022challenging}
Mirac Suzgun, Nathan Scales, Nathanael Sch{\"a}rli, Sebastian Gehrmann, Yi~Tay, Hyung~Won Chung, Aakanksha Chowdhery, Quoc~V Le, Ed~H Chi, Denny Zhou, et~al.
\newblock Challenging big-bench tasks and whether chain-of-thought can solve them.
\newblock {\em arXiv preprint arXiv:2210.09261}, 2022.

\bibitem{tang2023toolalpaca}
Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le~Sun.
\newblock Toolalpaca: Generalized tool learning for language models with 3000 simulated cases.
\newblock {\em arXiv preprint arXiv:2306.05301}, 2023.

\bibitem{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem{trinh2024solving}
Trieu~H Trinh, Yuhuai Wu, Quoc~V Le, He~He, and Thang Luong.
\newblock Solving olympiad geometry without human demonstrations.
\newblock {\em Nature}, 625(7995):476--482, 2024.

\bibitem{wang2023voyager}
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.
\newblock Voyager: An open-ended embodied agent with large language models.
\newblock {\em arXiv preprint arXiv:2305.16291}, 2023.

\bibitem{wang2024benchmark}
Siyuan Wang, Zhuohan Long, Zhihao Fan, Zhongyu Wei, and Xuanjing Huang.
\newblock Benchmark self-evolving: A multi-agent framework for dynamic llm evaluation.
\newblock {\em arXiv preprint arXiv:2402.11443}, 2024.

\bibitem{wang2022self}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.
\newblock Self-instruct: Aligning language models with self-generated instructions.
\newblock {\em arXiv preprint arXiv:2212.10560}, 2022.

\bibitem{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed~Chi, Quoc~V Le, Denny Zhou, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock {\em Advances in neural information processing systems}, 35:24824--24837, 2022.

\bibitem{wei2023symbol}
Jerry Wei, Le~Hou, Andrew Lampinen, Xiangning Chen, Da~Huang, Yi~Tay, Xinyun Chen, Yifeng Lu, Denny Zhou, Tengyu Ma, et~al.
\newblock Symbol tuning improves in-context learning in language models.
\newblock {\em arXiv preprint arXiv:2305.08298}, 2023.

\bibitem{wei2023simple}
Jerry Wei, Da~Huang, Yifeng Lu, Denny Zhou, and Quoc~V Le.
\newblock Simple synthetic data reduces sycophancy in large language models.
\newblock {\em arXiv preprint arXiv:2308.03958}, 2023.

\bibitem{wei2024long}
Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, Ruibo Liu, Da~Huang, Cosmo Du, et~al.
\newblock Long-form factuality in large language models.
\newblock {\em arXiv preprint arXiv:2403.18802}, 2024.

\bibitem{wei2023magicoder}
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang.
\newblock Magicoder: Source code is all you need.
\newblock {\em arXiv preprint arXiv:2312.02120}, 2023.

\bibitem{xu2023wizardlm}
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu~Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang.
\newblock Wizardlm: Empowering large language models to follow complex instructions.
\newblock {\em arXiv preprint arXiv:2304.12244}, 2023.

\bibitem{yang2023rethinking}
Shuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph~E Gonzalez, and Ion Stoica.
\newblock Rethinking benchmark and contamination for language models with rephrased samples.
\newblock {\em arXiv preprint arXiv:2311.04850}, 2023.

\bibitem{yao2024tree}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{yao2022react}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik~R Narasimhan, and Yuan Cao.
\newblock React: Synergizing reasoning and acting in language models.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{yasunaga2022deep}
Michihiro Yasunaga, Antoine Bosselut, Hongyu Ren, Xikun Zhang, Christopher~D Manning, Percy~S Liang, and Jure Leskovec.
\newblock Deep bidirectional language-knowledge graph pretraining.
\newblock {\em Advances in Neural Information Processing Systems}, 35:37309--37323, 2022.

\bibitem{yu2023skill}
Dingli Yu, Simran Kaur, Arushi Gupta, Jonah Brown-Cohen, Anirudh Goyal, and Sanjeev Arora.
\newblock Skill-mix: a flexible and expandable family of evaluations for ai models.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2023.

\bibitem{yu2024kieval}
Zhuohao Yu, Chang Gao, Wenjin Yao, Yidong Wang, Wei Ye, Jindong Wang, Xing Xie, Yue Zhang, and Shikun Zhang.
\newblock Kieval: A knowledge-grounded interactive evaluation framework for large language models.
\newblock {\em arXiv preprint arXiv:2402.15043}, 2024.

\bibitem{yuan2024self}
Weizhe Yuan, Richard~Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing Xu, and Jason Weston.
\newblock Self-rewarding language models.
\newblock {\em arXiv preprint arXiv:2401.10020}, 2024.

\bibitem{zelikman2022star}
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman.
\newblock Star: Bootstrapping reasoning with reasoning.
\newblock {\em Advances in Neural Information Processing Systems}, 35:15476--15488, 2022.

\bibitem{zhang2024careful}
Hugh Zhang, Jeff Da, Dean Lee, Vaughn Robinson, Catherine Wu, Will Song, Tiffany Zhao, Pranav Raja, Dylan Slack, Qin Lyu, Sean Hendryx, Russell Kaplan, Michele Lunati, and Summer Yue.
\newblock A careful examination of large language model performance on grade school arithmetic, 2024.

\bibitem{zhang2022greaselm}
X~Zhang, A~Bosselut, M~Yasunaga, H~Ren, P~Liang, C~Manning, and J~Leskovec.
\newblock Greaselm: Graph reasoning enhanced language models for question answering.
\newblock In {\em International Conference on Representation Learning (ICLR)}, 2022.

\bibitem{zhang-etal-2023-crt}
Zhehao Zhang, Xitao Li, Yan Gao, and Jian-Guang Lou.
\newblock {CRT}-{QA}: A dataset of complex reasoning question answering over tabular data.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 2131--2153, Singapore, December 2023. Association for Computational Linguistics.

\bibitem{zhong2023agieval}
Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan.
\newblock Agieval: A human-centric benchmark for evaluating foundation models.
\newblock {\em arXiv preprint arXiv:2304.06364}, 2023.

\bibitem{zhou2023solving}
Aojun Zhou, Ke~Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, et~al.
\newblock Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2023.

\bibitem{zhou2022least}
Denny Zhou, Nathanael Sch{\"a}rli, Le~Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et~al.
\newblock Least-to-most prompting enables complex reasoning in large language models.
\newblock {\em arXiv preprint arXiv:2205.10625}, 2022.

\bibitem{zhou2023don}
Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne~Xin Zhao, Xu~Chen, Yankai Lin, Ji-Rong Wen, and Jiawei Han.
\newblock Don't make your llm an evaluation benchmark cheater.
\newblock {\em arXiv preprint arXiv:2311.01964}, 2023.

\bibitem{zhu2023dyval}
Kaijie Zhu, Jiaao Chen, Jindong Wang, Neil~Zhenqiang Gong, Diyi Yang, and Xing Xie.
\newblock Dyval: Graph-informed dynamic evaluation of large language models.
\newblock {\em arXiv preprint arXiv:2309.17167}, 2023.

\bibitem{zhu2024dyval}
Kaijie Zhu, Jindong Wang, Qinlin Zhao, Ruochen Xu, and Xing Xie.
\newblock Dyval 2: Dynamic evaluation of large language models by meta probing agents.
\newblock {\em arXiv preprint arXiv:2402.14865}, 2024.

\end{thebibliography}
