\begin{thebibliography}{}

\bibitem[Bottou et~al., 2013]{bottou2013counterfactual}
Bottou, L., Peters, J., Qui{\~n}onero-Candela, J., Charles, D.~X., Chickering,
  D.~M., Portugaly, E., Ray, D., Simard, P., and Snelson, E. (2013).
\newblock Counterfactual reasoning and learning systems: The example of
  computational advertising.
\newblock {\em The Journal of Machine Learning Research}, 14(1):3207--3260.

\bibitem[Chapelle et~al., 2015]{chapelle2015simple}
Chapelle, O., Manavoglu, E., and Rosales, R. (2015).
\newblock Simple and scalable response prediction for display advertising.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  5(4):61.

\bibitem[Chernoff et~al., 1952]{chernoff1952measure}
Chernoff, H. et~al. (1952).
\newblock A measure of asymptotic efficiency for tests of a hypothesis based on
  the sum of observations.
\newblock {\em The Annals of Mathematical Statistics}, 23(4):493--507.

\bibitem[Dud{\'\i}k et~al., 2011]{dudik2011doubly}
Dud{\'\i}k, M., Langford, J., and Li, L. (2011).
\newblock Doubly robust policy evaluation and learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1097--1104. Omnipress.

\bibitem[Ernst et~al., 2006]{ernst2006clinical}
Ernst, D., Stan, G.-B., Goncalves, J., and Wehenkel, L. (2006).
\newblock Clinical data based optimal sti strategies for hiv: a reinforcement
  learning approach.
\newblock In {\em Decision and Control, 2006 45th IEEE Conference on}, pages
  667--672. IEEE.

\bibitem[Farajtabar et~al., 2018]{farajtabar2018more}
Farajtabar, M., Chow, Y., and Ghavamzadeh, M. (2018).
\newblock More robust doubly robust off-policy evaluation.
\newblock In {\em International Conference on Machine Learning (ICML-18)},
  volume~80, pages 1447--1456, Stockholmsm√§ssan, Stockholm Sweden. PMLR.

\bibitem[Gelada and Bellemare, 2019]{gelada2019off}
Gelada, C. and Bellemare, M.~G. (2019).
\newblock Off-policy deep reinforcement learning by bootstrapping the covariate
  shift.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI-19)},
  volume~33, pages 3647--3655.

\bibitem[Gottesman et~al., 2019]{gottesman2019combining}
Gottesman, O., Liu, Y., Sussex, S., Brunskill, E., and Doshi-Velez, F. (2019).
\newblock Combining parametric and nonparametric models for off-policy
  evaluation.
\newblock In {\em International Conference on Machine Learning (ICML-19)}.

\bibitem[Guo et~al., 2017]{guo2017using}
Guo, Z., Thomas, P.~S., and Brunskill, E. (2017).
\newblock Using options and covariance testing for long horizon off-policy
  policy evaluation.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS-17)},
  pages 2492--2501.

\bibitem[Hallak and Mannor, 2017]{hallak2017consistent}
Hallak, A. and Mannor, S. (2017).
\newblock Consistent on-line off-policy evaluation.
\newblock In {\em International Conference on Machine Learning (ICML-17)},
  pages 1372--1383. JMLR. org.

\bibitem[Hirano et~al., 2003]{hirano2003efficient}
Hirano, K., Imbens, G.~W., and Ridder, G. (2003).
\newblock Efficient estimation of average treatment effects using the estimated
  propensity score.
\newblock {\em Econometrica}, 71(4):1161--1189.

\bibitem[Jiang and Li, 2016]{jiang2016doubly}
Jiang, N. and Li, L. (2016).
\newblock Doubly robust off-policy value evaluation for reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML-16)},
  pages 652--661. JMLR. org.

\bibitem[Li et~al., 2015]{li2015toward}
Li, L., Munos, R., and Szepesvari, C. (2015).
\newblock Toward minimax off-policy value estimation.
\newblock In {\em Artificial Intelligence and Statistics (AISTATS-15)}, pages
  608--616.

\bibitem[Liu et~al., 2018a]{liu2018breaking}
Liu, Q., Li, L., Tang, Z., and Zhou, D. (2018a).
\newblock Breaking the curse of horizon: Infinite-horizon off-policy
  estimation.
\newblock In {\em Advances in Neural Information Processing Systems
  (NeurIPS-18)}, pages 5361--5371.

\bibitem[Liu et~al., 2018b]{liu2018representation}
Liu, Y., Gottesman, O., Raghu, A., Komorowski, M., Faisal, A.~A., Doshi-Velez,
  F., and Brunskill, E. (2018b).
\newblock Representation balancing mdps for off-policy policy evaluation.
\newblock In {\em Advances in Neural Information Processing Systems
  (NeurIPS-18)}, pages 2649--2658.

\bibitem[Mandel et~al., 2014]{mandel2014offline}
Mandel, T., Liu, Y.-E., Levine, S., Brunskill, E., and Popovic, Z. (2014).
\newblock Offline policy evaluation across representations with applications to
  educational games.
\newblock In {\em International conference on Autonomous agents and multi-agent
  systems}, pages 1077--1084. International Foundation for Autonomous Agents
  and Multiagent Systems.

\bibitem[Murphy et~al., 2001]{murphy2001marginal}
Murphy, S.~A., van~der Laan, M.~J., Robins, J.~M., and Group, C. P. P.~R.
  (2001).
\newblock Marginal mean models for dynamic regimes.
\newblock {\em Journal of the American Statistical Association},
  96(456):1410--1423.

\bibitem[Precup et~al., 2000]{precup2000eligibility}
Precup, D., Sutton, R.~S., and Singh, S.~P. (2000).
\newblock Eligibility traces for off-policy policy evaluation.
\newblock In {\em International Conference on Machine Learning (ICML-00)},
  pages 759--766. Morgan Kaufmann Publishers Inc.

\bibitem[Raghu et~al., 2017]{raghu2017continuous}
Raghu, A., Komorowski, M., Celi, L.~A., Szolovits, P., and Ghassemi, M. (2017).
\newblock Continuous state-space models for optimal sepsis treatment: a deep
  reinforcement learning approach.
\newblock In {\em Machine Learning for Healthcare Conference}, pages 147--163.

\bibitem[Singh and Sutton, 1996]{singh1996reinforcement}
Singh, S.~P. and Sutton, R.~S. (1996).
\newblock Reinforcement learning with replacing eligibility traces.
\newblock {\em Machine learning}, 22(1-3):123--158.

\bibitem[Sobel, 1982]{sobel1982variance}
Sobel, M.~J. (1982).
\newblock The variance of discounted markov decision processes.
\newblock {\em Journal of Applied Probability}, 19(4):794--802.

\bibitem[Sutton and Barto, 1998]{sutton1998reinforcement}
Sutton, R.~S. and Barto, A.~G. (1998).
\newblock {\em Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge.

\bibitem[Tang et~al., 2013]{tang2013automatic}
Tang, L., Rosales, R., Singh, A., and Agarwal, D. (2013).
\newblock Automatic ad format selection via contextual bandits.
\newblock In {\em ACM International Conference on Information \& Knowledge
  Management (CIKM-13)}, pages 1587--1594. ACM.

\bibitem[Theocharous et~al., 2015]{theocharous2015personalized}
Theocharous, G., Thomas, P.~S., and Ghavamzadeh, M. (2015).
\newblock Personalized ad recommendation systems for life-time value
  optimization with guarantees.
\newblock In {\em International Joint Conferences on Artificial Intelligence
  (IJCAI-15)}, pages 1806--1812.

\bibitem[Thomas and Brunskill, 2016]{thomas2016data}
Thomas, P. and Brunskill, E. (2016).
\newblock Data-efficient off-policy policy evaluation for reinforcement
  learning.
\newblock In {\em International Conference on Machine Learning (ICML-16)},
  pages 2139--2148.

\bibitem[Thomas, 2015]{thomas2015safe}
Thomas, P.~S. (2015).
\newblock {\em Safe reinforcement learning}.
\newblock PhD thesis, University of Massachusetts Amherst.

\bibitem[Thomas et~al., 2015]{thomas2015high}
Thomas, P.~S., Theocharous, G., and Ghavamzadeh, M. (2015).
\newblock High-confidence off-policy evaluation.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI-15)}, pages
  3000--3006.

\bibitem[Thomas et~al., 2017]{thomas2017predictive}
Thomas, P.~S., Theocharous, G., Ghavamzadeh, M., Durugkar, I., and Brunskill,
  E. (2017).
\newblock Predictive off-policy policy evaluation for nonstationary decision
  problems, with applications to digital marketing.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI-17)}, pages
  4740--4745.

\bibitem[Wang et~al., 2017]{wang2017optimal}
Wang, Y.-X., Agarwal, A., and Dud{\i}k, M. (2017).
\newblock Optimal and adaptive off-policy evaluation in contextual bandits.
\newblock In {\em International Conference on Machine Learning (ICML-17)},
  pages 3589--3597.

\end{thebibliography}
