\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Badgeley et~al.(2019)Badgeley, Zech, Oakden-Rayner, Glicksberg, Liu,
  Gale, McConnell, Percha, Snyder, and Dudley]{badgeley2019deep}
Marcus~A Badgeley, John~R Zech, Luke Oakden-Rayner, Benjamin~S Glicksberg,
  Manway Liu, William Gale, Michael~V McConnell, Bethany Percha, Thomas~M
  Snyder, and Joel~T Dudley.
\newblock Deep learning predicts hip fracture using confounding patient and
  healthcare variables.
\newblock \emph{NPJ digital medicine}, 2\penalty0 (1):\penalty0 1--10, 2019.

\bibitem[Baker et~al.(2018)Baker, Lu, Erlikhman, and Kellman]{baker2018deep}
Nicholas Baker, Hongjing Lu, Gennady Erlikhman, and Philip~J Kellman.
\newblock Deep convolutional networks do not classify based on global object
  shape.
\newblock \emph{PLoS computational biology}, 14\penalty0 (12):\penalty0
  e1006613, 2018.

\bibitem[Beery et~al.(2018)Beery, Van~Horn, and Perona]{beery2018recognition}
Sara Beery, Grant Van~Horn, and Pietro Perona.
\newblock Recognition in terra incognita.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pages 456--473, 2018.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson, {\v{S}}rndi{\'c},
  Laskov, Giacinto, and Roli]{biggio2013evasion}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim
  {\v{S}}rndi{\'c}, Pavel Laskov, Giorgio Giacinto, and Fabio Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In \emph{Joint European conference on machine learning and knowledge
  discovery in databases}, pages 387--402. Springer, 2013.

\bibitem[Buolamwini and Gebru(2018)]{buolamwini2018gender}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on fairness, accountability and transparency},
  pages 77--91. PMLR, 2018.

\bibitem[Creager et~al.(2021)Creager, Jacobsen, and
  Zemel]{creager2021environment}
Elliot Creager, J{\"o}rn-Henrik Jacobsen, and Richard Zemel.
\newblock Environment inference for invariant learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2189--2200. PMLR, 2021.

\bibitem[Ganin and Lempitsky(2015)]{ganin2015unsupervised}
Yaroslav Ganin and Victor Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International conference on machine learning}, pages
  1180--1189. PMLR, 2015.

\bibitem[Geirhos et~al.(2018)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2018imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock \emph{arXiv preprint arXiv:1811.12231}, 2018.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
  Wieland Brendel, Matthias Bethge, and Felix~A Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (11):\penalty0
  665--673, 2020.

\bibitem[Grother et~al.(2011)Grother, Grother, Phillips, and
  Quinn]{grother2011report}
Patrick~J Grother, Patrick~J Grother, P~Jonathon Phillips, and George~W Quinn.
\newblock \emph{Report on the evaluation of 2D still-image face recognition
  algorithms}.
\newblock Citeseer, 2011.

\bibitem[Gururangan et~al.(2018)Gururangan, Swayamdipta, Levy, Schwartz,
  Bowman, and Smith]{gururangan2018annotation}
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel~R
  Bowman, and Noah~A Smith.
\newblock Annotation artifacts in natural language inference data.
\newblock \emph{arXiv preprint arXiv:1803.02324}, 2018.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Srivastava, Namkoong, and
  Liang]{hashimoto2018fairness}
Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang.
\newblock Fairness without demographics in repeated loss minimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  1929--1938. PMLR, 2018.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{arXiv preprint arXiv:1903.12261}, 2019.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2016beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Hovy and S{\o}gaard(2015)]{hovy2015tagging}
Dirk Hovy and Anders S{\o}gaard.
\newblock Tagging performance correlates with author age.
\newblock In \emph{Proceedings of the 53rd annual meeting of the Association
  for Computational Linguistics and the 7th international joint conference on
  natural language processing (volume 2: Short papers)}, pages 483--488, 2015.

\bibitem[Iandola et~al.(2014)Iandola, Moskewicz, Karayev, Girshick, Darrell,
  and Keutzer]{iandola2014densenet}
Forrest Iandola, Matt Moskewicz, Sergey Karayev, Ross Girshick, Trevor Darrell,
  and Kurt Keutzer.
\newblock Densenet: Implementing efficient convnet descriptor pyramids.
\newblock \emph{arXiv preprint arXiv:1404.1869}, 2014.

\bibitem[Irvin et~al.(2019)Irvin, Rajpurkar, Ko, Yu, Ciurea-Ilcus, Chute,
  Marklund, Haghgoo, Ball, Shpanskaya, et~al.]{irvin2019chexpert}
Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus,
  Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya,
  et~al.
\newblock Chexpert: A large chest radiograph dataset with uncertainty labels
  and expert comparison.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~33, pages 590--597, 2019.

\bibitem[Izmailov et~al.(2020)Izmailov, Kirichenko, Finzi, and
  Wilson]{izmailov2020semi}
Pavel Izmailov, Polina Kirichenko, Marc Finzi, and Andrew~Gordon Wilson.
\newblock Semi-supervised learning with normalizing flows.
\newblock In \emph{International Conference on Machine Learning}, pages
  4615--4630. PMLR, 2020.

\bibitem[Izmailov et~al.(2022)Izmailov, Kirichenko, Gruver, and
  Wilson]{izmailov2022feature}
Pavel Izmailov, Polina Kirichenko, Nate Gruver, and Andrew~Gordon Wilson.
\newblock On feature learning in the presence of spurious correlations.
\newblock \emph{arXiv preprint arXiv:2210.11369}, 2022.

\bibitem[Jabbour et~al.(2020)Jabbour, Fouhey, Kazerooni, Sjoding, and
  Wiens]{jabbour2020deep}
Sarah Jabbour, David Fouhey, Ella Kazerooni, Michael~W Sjoding, and Jenna
  Wiens.
\newblock Deep learning applied to chest x-rays: Exploiting and preventing
  shortcuts.
\newblock In \emph{Machine Learning for Healthcare Conference}, pages 750--782.
  PMLR, 2020.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kingma et~al.(2014)Kingma, Mohamed, Rezende, and
  Welling]{kingma2014semi}
Diederik~P Kingma, Shakir Mohamed, Danilo~Jimenez Rezende, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In \emph{Advances in neural information processing systems}, pages
  3581--3589, 2014.

\bibitem[Kirichenko et~al.(2022)Kirichenko, Izmailov, and
  Wilson]{kirichenko2022last}
Polina Kirichenko, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Last layer re-training is sufficient for robustness to spurious
  correlations.
\newblock \emph{arXiv preprint arXiv:2204.02937}, 2022.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee et~al.(2022)Lee, Yao, and Finn]{lee2022diversify}
Yoonho Lee, Huaxiu Yao, and Chelsea Finn.
\newblock Diversify and disambiguate: Learning from underspecified data.
\newblock \emph{arXiv preprint arXiv:2202.03418}, 2022.

\bibitem[Liu et~al.(2021)Liu, Haghgoo, Chen, Raghunathan, Koh, Sagawa, Liang,
  and Finn]{liu2021just}
Evan~Z Liu, Behzad Haghgoo, Annie~S Chen, Aditi Raghunathan, Pang~Wei Koh,
  Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group
  information.
\newblock In \emph{International Conference on Machine Learning}, pages
  6781--6792. PMLR, 2021.

\bibitem[Liu et~al.(2018)Liu, Luo, Wang, and Tang]{liu2018large}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Large-scale celebfaces attributes (celeba) dataset.
\newblock \emph{Retrieved August}, 15\penalty0 (2018):\penalty0 11, 2018.

\bibitem[McCoy et~al.(2019)McCoy, Pavlick, and Linzen]{mccoy-etal-2019-right}
Tom McCoy, Ellie Pavlick, and Tal Linzen.
\newblock Right for the wrong reasons: Diagnosing syntactic heuristics in
  natural language inference.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 3428--3448, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1334}.
\newblock URL \url{https://aclanthology.org/P19-1334}.

\bibitem[Moayeri et~al.(2022)Moayeri, Pope, Balaji, and
  Feizi]{moayeri2022comprehensive}
Mazda Moayeri, Phillip Pope, Yogesh Balaji, and Soheil Feizi.
\newblock A comprehensive study of image classification model sensitivity to
  foregrounds, backgrounds, and visual attributes.
\newblock \emph{arXiv preprint arXiv:2201.10766}, 2022.

\bibitem[Nalisnick et~al.(2019)Nalisnick, Matsukawa, Teh, Gorur, and
  Lakshminarayanan]{nalisnick2019hybrid}
Eric Nalisnick, Akihiro Matsukawa, Yee~Whye Teh, Dilan Gorur, and Balaji
  Lakshminarayanan.
\newblock Hybrid models with deep and invertible features.
\newblock In \emph{International Conference on Machine Learning}, pages
  4723--4732. PMLR, 2019.

\bibitem[Nam et~al.(2020)Nam, Cha, Ahn, Lee, and Shin]{nam2020learning}
Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin.
\newblock Learning from failure: Training debiased classifier from biased
  classifier.
\newblock \emph{arXiv preprint arXiv:2007.02561}, 2020.

\bibitem[Oakden-Rayner et~al.(2020)Oakden-Rayner, Dunnmon, Carneiro, and
  R{\'e}]{oakden2020hidden}
Luke Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, and Christopher R{\'e}.
\newblock Hidden stratification causes clinically meaningful failures in
  machine learning for medical imaging.
\newblock In \emph{Proceedings of the ACM conference on health, inference, and
  learning}, pages 151--159, 2020.

\bibitem[Pagliardini et~al.(2022)Pagliardini, Jaggi, Fleuret, and
  Karimireddy]{pagliardini2022agree}
Matteo Pagliardini, Martin Jaggi, Fran{\c{c}}ois Fleuret, and Sai~Praneeth
  Karimireddy.
\newblock Agree to disagree: Diversity through disagreement for better
  transferability.
\newblock \emph{arXiv preprint arXiv:2202.04414}, 2022.

\bibitem[Puli et~al.(2021)Puli, Zhang, Oermann, and
  Ranganath]{puli2021predictive}
Aahlad Puli, Lily~H Zhang, Eric~K Oermann, and Rajesh Ranganath.
\newblock Predictive modeling in the presence of nuisance-induced spurious
  correlations.
\newblock \emph{arXiv preprint arXiv:2107.00520}, 2021.

\bibitem[Recht et~al.(2018)Recht, Roelofs, Schmidt, and
  Shankar]{recht2018cifar}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do cifar-10 classifiers generalize to cifar-10?
\newblock \emph{arXiv preprint arXiv:1806.00451}, 2018.

\bibitem[Sagawa et~al.(2019)Sagawa, Koh, Hashimoto, and
  Liang]{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock \emph{arXiv preprint arXiv:1911.08731}, 2019.

\bibitem[Sagawa et~al.(2020)Sagawa, Raghunathan, Koh, and
  Liang]{sagawa2020investigation}
Shiori Sagawa, Aditi Raghunathan, Pang~Wei Koh, and Percy Liang.
\newblock An investigation of why overparameterization exacerbates spurious
  correlations.
\newblock In \emph{International Conference on Machine Learning}, pages
  8346--8356. PMLR, 2020.

\bibitem[Schott et~al.(2018)Schott, Rauber, Bethge, and
  Brendel]{schott2018towards}
Lukas Schott, Jonas Rauber, Matthias Bethge, and Wieland Brendel.
\newblock Towards the first adversarially robust neural network model on mnist.
\newblock \emph{arXiv preprint arXiv:1805.09190}, 2018.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\bibitem[Shwartz-Ziv and Tishby(2017)]{shwartz2017opening}
Ravid Shwartz-Ziv and Naftali Tishby.
\newblock Opening the black box of deep neural networks via information.
\newblock \emph{arXiv preprint arXiv:1703.00810}, 2017.

\bibitem[Sinz et~al.(2019)Sinz, Pitkow, Reimer, Bethge, and
  Tolias]{sinz2019engineering}
Fabian~H Sinz, Xaq Pitkow, Jacob Reimer, Matthias Bethge, and Andreas~S Tolias.
\newblock Engineering a less artificial intelligence.
\newblock \emph{Neuron}, 103\penalty0 (6):\penalty0 967--979, 2019.

\bibitem[Sohoni et~al.(2020)Sohoni, Dunnmon, Angus, Gu, and
  R{\'e}]{sohoni2020no}
Nimit~S Sohoni, Jared~A Dunnmon, Geoffrey Angus, Albert Gu, and Christopher
  R{\'e}.
\newblock No subclass left behind: Fine-grained robustness in coarse-grained
  classification problems.
\newblock \emph{arXiv preprint arXiv:2011.12945}, 2020.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Teney et~al.(2020)Teney, Abbasnedjad, and Hengel]{teney2020learning}
Damien Teney, Ehsan Abbasnedjad, and Anton van~den Hengel.
\newblock Learning what makes a difference from counterfactual examples and
  gradient supervision.
\newblock In \emph{European Conference on Computer Vision}, pages 580--599.
  Springer, 2020.

\bibitem[Tishby and Zaslavsky(2015)]{tishby2015deep}
Naftali Tishby and Noga Zaslavsky.
\newblock Deep learning and the information bottleneck principle.
\newblock In \emph{2015 IEEE Information Theory Workshop (ITW)}, pages 1--5.
  IEEE, 2015.

\bibitem[Wang et~al.(2017)Wang, Peng, Lu, Lu, Bagheri, and
  Summers]{wang2017chestx}
Xiaosong Wang, Yifan Peng, Le~Lu, Zhiyong Lu, Mohammadhadi Bagheri, and
  Ronald~M Summers.
\newblock Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on
  weakly-supervised classification and localization of common thorax diseases.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2097--2106, 2017.

\bibitem[Westerlund(2019)]{westerlund2019emergence}
Mika Westerlund.
\newblock The emergence of deepfake technology: A review.
\newblock \emph{Technology Innovation Management Review}, 9\penalty0 (11),
  2019.

\bibitem[Xiao et~al.(2020)Xiao, Engstrom, Ilyas, and Madry]{xiao2020noise}
Kai Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry.
\newblock Noise or signal: The role of image backgrounds in object recognition.
\newblock \emph{arXiv preprint arXiv:2006.09994}, 2020.

\bibitem[Yaghoobzadeh et~al.(2019)Yaghoobzadeh, Mehri, Tachet, Hazen, and
  Sordoni]{yaghoobzadeh2019increasing}
Yadollah Yaghoobzadeh, Soroush Mehri, Remi Tachet, Timothy~J Hazen, and
  Alessandro Sordoni.
\newblock Increasing robustness to spurious correlations using forgettable
  examples.
\newblock \emph{arXiv preprint arXiv:1911.03861}, 2019.

\bibitem[Zech et~al.(2018)Zech, Badgeley, Liu, Costa, Titano, and
  Oermann]{zech2018variable}
John~R Zech, Marcus~A Badgeley, Manway Liu, Anthony~B Costa, Joseph~J Titano,
  and Eric~Karl Oermann.
\newblock Variable generalization performance of a deep learning model to
  detect pneumonia in chest radiographs: a cross-sectional study.
\newblock \emph{PLoS medicine}, 15\penalty0 (11):\penalty0 e1002683, 2018.

\bibitem[Zhang and Sabuncu(2018)]{zhang2018generalized}
Zhilu Zhang and Mert~R Sabuncu.
\newblock Generalized cross entropy loss for training deep neural networks with
  noisy labels.
\newblock In \emph{32nd Conference on Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Zimmermann et~al.(2021)Zimmermann, Schott, Song, Dunn, and
  Klindt]{zimmermann2021score}
Roland~S Zimmermann, Lukas Schott, Yang Song, Benjamin~A Dunn, and David~A
  Klindt.
\newblock Score-based generative classifiers.
\newblock \emph{arXiv preprint arXiv:2110.00473}, 2021.

\end{thebibliography}
