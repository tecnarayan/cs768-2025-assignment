\begin{thebibliography}{72}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abe and Long(1999)]{abe1999associative}
Naoki Abe and Philip~M Long.
\newblock Associative reinforcement learning using linear probabilistic
  concepts.
\newblock In \emph{International Conference on Machine Learning}, 1999.

\bibitem[Agarwal et~al.(2012)Agarwal, Dud{\'\i}k, Kale, Langford, and
  Schapire]{agarwal2012contextual}
Alekh Agarwal, Miroslav Dud{\'\i}k, Satyen Kale, John Langford, and Robert~E
  Schapire.
\newblock Contextual bandit learning with predictable rewards.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2012.

\bibitem[Agarwal et~al.(2014)Agarwal, Hsu, Kale, Langford, Li, and
  Schapire]{agarwal2014taming}
Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert
  Schapire.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Agarwal et~al.(2016)Agarwal, Bird, Cozowicz, Hoang, Langford, Lee, Li,
  Melamed, Oshri, Ribas, Sen, and Slivkins]{agarwal2016making}
Alekh Agarwal, Sarah Bird, Markus Cozowicz, Luong Hoang, John Langford, Stephen
  Lee, Jiaji Li, Dan Melamed, Gal Oshri, Oswaldo Ribas, Siddhartha Sen, and
  Aleksandrs Slivkins.
\newblock Making contextual decisions with low technical debt.
\newblock \emph{arXiv:1606.03966}, 2016.

\bibitem[Agarwal et~al.(2017)Agarwal, Krishnamurthy, Langford, Luo, and
  Schapire]{agarwal2017open}
Alekh Agarwal, Akshay Krishnamurthy, John Langford, Haipeng Luo, and Robert~E
  Schapire.
\newblock Open problem: First-order regret bounds for contextual bandits.
\newblock In \emph{Conference on Learning Theory}, 2017.

\bibitem[Allen-Zhu et~al.(2018)Allen-Zhu, Bubeck, and Li]{allen2018make}
Zeyuan Allen-Zhu, S{\'e}bastien Bubeck, and Yuanzhi Li.
\newblock Make the minority great again: First-order regret bound for
  contextual bandits.
\newblock \emph{International Conference on Machine Learning}, 2018.

\bibitem[Allenberg et~al.(2006)Allenberg, Auer, Gy{\"o}rfi, and
  Ottucs{\'a}k]{allenberg2006hannan}
Chamy Allenberg, Peter Auer, L{\'a}szl{\'o} Gy{\"o}rfi, and Gy{\"o}rgy
  Ottucs{\'a}k.
\newblock Hannan consistency in on-line learning in case of unbounded losses
  under partial monitoring.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2006.

\bibitem[Audibert and Tsybakov(2007)]{audibert2007fast}
Jean-Yves Audibert and Alexandre~B Tsybakov.
\newblock Fast learning rates for plug-in classifiers.
\newblock \emph{The Annals of statistics}, 2007.

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002non}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM Journal on Computing}, 2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, and
  Gentile]{auer2002adaptive}
Peter Auer, Nicolo Cesa-Bianchi, and Claudio Gentile.
\newblock Adaptive and self-confident on-line learning algorithms.
\newblock \emph{Journal of Computer and System Sciences}, 2002{\natexlab{b}}.

\bibitem[Benjamini et~al.(2015)Benjamini, Duminil-Copin, Kozma, and
  Yadin]{benjamini2015disorder}
Itai Benjamini, Hugo Duminil-Copin, Gady Kozma, and Ariel Yadin.
\newblock Disorder, entropy and harmonic functions.
\newblock \emph{Annals of Probability}, 2015.

\bibitem[Beygelzimer et~al.(2011)Beygelzimer, Langford, Li, Reyzin, and
  Schapire]{beygelzimer2011contextual}
Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandit algorithms with supervised learning guarantees.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2011.

\bibitem[Bietti et~al.(2018)Bietti, Agarwal, and
  Langford]{bietti2018contextual}
Alberto Bietti, Alekh Agarwal, and John Langford.
\newblock A contextual bandit bake-off.
\newblock \emph{arXiv:1802.04064}, 2018.

\bibitem[Bilodeau et~al.(2020)Bilodeau, Foster, and Roy]{bilodeau2020tight}
Blair Bilodeau, Dylan~J Foster, and Daniel Roy.
\newblock Tight bounds on minimax regret under logarithmic loss via
  self-concordance.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Blum et~al.(1999)Blum, Kalai, and Langford]{blum1999beating}
Avrim Blum, Adam Kalai, and John Langford.
\newblock Beating the hold-out: Bounds for {K}-fold and progressive
  cross-validation.
\newblock In \emph{Conference on Computational Learning Theory}, 1999.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and
  Massart]{boucheron2013concentration}
St{\'e}phane Boucheron, G{\'a}bor Lugosi, and Pascal Massart.
\newblock \emph{Concentration inequalities: A nonasymptotic theory of
  independence}.
\newblock Oxford University Press, 2013.

\bibitem[Bousquet et~al.(2003)Bousquet, Boucheron, and
  Lugosi]{bousquet2003introduction}
Olivier Bousquet, St{\'e}phane Boucheron, and G{\'a}bor Lugosi.
\newblock Introduction to statistical learning theory.
\newblock In \emph{Summer School on Machine Learning}, 2003.

\bibitem[Bubeck and Sellke(2020)]{bubeck2020first}
S{\'e}bastien Bubeck and Mark Sellke.
\newblock First-order bayesian regret analysis of thompson sampling.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2020.

\bibitem[Carroll(1982)]{carroll1982adapting}
Raymond~J Carroll.
\newblock Adapting for heteroscedasticity in linear models.
\newblock \emph{The Annals of Statistics}, 1982.

\bibitem[{Cesa-Bianchi} and {Lugosi}(1999)]{cesabianchi99logloss}
Nicol{\`o} {Cesa-Bianchi} and G{\'a}bor {Lugosi}.
\newblock Minimax regret under log loss for general classes of experts.
\newblock In \emph{Conference on Computational Learning Theory}, 1999.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{PLG}
Nicol{\`o} Cesa-Bianchi and Gabor Lugosi.
\newblock \emph{Prediction, Learning, and Games}.
\newblock Cambridge University Press, 2006.

\bibitem[Cesa-Bianchi et~al.(2007)Cesa-Bianchi, Mansour, and
  Stoltz]{cesa2007improved}
Nicol{\`o} Cesa-Bianchi, Yishay Mansour, and Gilles Stoltz.
\newblock Improved second-order bounds for prediction with expert advice.
\newblock \emph{Machine Learning}, 2007.

\bibitem[Chen et~al.(2020)Chen, Koehler, Moitra, and Yau]{chen2020online}
Sitan Chen, Frederic Koehler, Ankur Moitra, and Morris Yau.
\newblock Online and distribution-free robustness: Regression and contextual
  bandits with {Huber} contamination.
\newblock \emph{arXiv:2010.04157}, 2020.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
Wei Chu, Lihong Li, Lev Reyzin, and Robert~E Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2011.

\bibitem[Cover(1991)]{cover1991universal}
Thomas~M Cover.
\newblock Universal portfolios.
\newblock \emph{Mathematical Finance}, 1991.

\bibitem[Devroye et~al.(2013)Devroye, Gy{\"o}rfi, and
  Lugosi]{devroye2013probabilistic}
Luc Devroye, L{\'a}szl{\'o} Gy{\"o}rfi, and G{\'a}bor Lugosi.
\newblock \emph{A probabilistic theory of pattern recognition}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Duchi et~al.(2011)Duchi, Hazan, and Singer]{duchi2011adaptive}
John Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 2011.

\bibitem[Erschler and Karlsson(2010)]{erschler2010homomorphisms}
Anna Erschler and Anders Karlsson.
\newblock Homomorphisms to $\mathbb{R}$ constructed from random walks.
\newblock \emph{Annales de l'Institut Fourier}, 2010.

\bibitem[Foster and Rakhlin(2020)]{foster2020beyond}
Dylan~J Foster and Alexander Rakhlin.
\newblock Beyond {UCB}: Optimal and efficient contextual bandits with
  regression oracles.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Foster et~al.(2015)Foster, Rakhlin, and Sridharan]{foster2015adaptive}
Dylan~J. Foster, Alexander Rakhlin, and Karthik Sridharan.
\newblock Adaptive online learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Foster et~al.(2016)Foster, Li, Lykouris, Sridharan, and
  Tardos]{foster2016learning}
Dylan~J Foster, Zhiyuan Li, Thodoris Lykouris, Karthik Sridharan, and {\'E}va
  Tardos.
\newblock Learning in games: Robustness of fast convergence.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Foster et~al.(2018{\natexlab{a}})Foster, Agarwal, Dud{\'\i}k, Luo, and
  Schapire]{foster2018practical}
Dylan~J Foster, Alekh Agarwal, Miroslav Dud{\'\i}k, Haipeng Luo, and Robert~E
  Schapire.
\newblock Practical contextual bandits with regression oracles.
\newblock \emph{International Conference on Machine Learning},
  2018{\natexlab{a}}.

\bibitem[Foster et~al.(2018{\natexlab{b}})Foster, Kale, Luo, Mohri, and
  Sridharan]{foster2018logistic}
Dylan~J Foster, Satyen Kale, Haipeng Luo, Mehryar Mohri, and Karthik Sridharan.
\newblock Logistic regression: The importance of being improper.
\newblock \emph{Conference on Learning Theory}, 2018{\natexlab{b}}.

\bibitem[Foster et~al.(2020)Foster, Gentile, Mohri, and
  Zimmert]{foster2020adapting}
Dylan~J Foster, Claudio Gentile, Mehryar Mohri, and Julian Zimmert.
\newblock Adapting to misspecification in contextual bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Foster et~al.(2021)Foster, Rakhlin, Simchi-Levi, and
  Xu]{foster2020instance}
Dylan~J Foster, Alexander Rakhlin, David Simchi-Levi, and Yunzong Xu.
\newblock Instance-dependent complexity of contextual bandits and reinforcement
  learning: A disagreement-based perspective.
\newblock In \emph{Conference on Learning Theory}, 2021.

\bibitem[Freund and Schapire(1997)]{freund1997decision}
Yoav Freund and Robert~E Schapire.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock \emph{Journal of Computer and System Sciences}, 1997.

\bibitem[Hazan and Kale(2015)]{hazan2015online}
Elad Hazan and Satyen Kale.
\newblock An online portfolio selection algorithm with regret logarithmic in
  price variation.
\newblock \emph{Mathematical Finance}, 2015.

\bibitem[Hazan et~al.(2007)Hazan, Agarwal, and Kale]{hazan2007logarithmic}
Elad Hazan, Amit Agarwal, and Satyen Kale.
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock \emph{Machine Learning}, 2007.

\bibitem[Ito et~al.(2020)Ito, Hirahara, Soma, and Yoshida]{ito2020tight}
Shinji Ito, Shuichi Hirahara, Tasuku Soma, and Yuichi Yoshida.
\newblock Tight first-and second-order regret bounds for adversarial linear
  bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Kalai and Vempala(2002)]{kalai2002efficient}
Adam Kalai and Santosh Vempala.
\newblock Efficient algorithms for universal portfolios.
\newblock \emph{Journal of Machine Learning Research}, 2002.

\bibitem[Karampatziakis and Langford(2011)]{karampatziakis2011online}
Nikos Karampatziakis and John Langford.
\newblock Online importance weight aware updates.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2011.

\bibitem[Koolen and van Erven(2015)]{koolen2015second}
Wouter~M. Koolen and Tim van Erven.
\newblock Second-order quantile methods for experts and combinatorial games.
\newblock In \emph{Conference on Learning Theory}, 2015.

\bibitem[Krishnamurthy et~al.(2017)Krishnamurthy, Agarwal, Huang,
  Daum{\'e}~III, and Langford]{krishnamurthy2017active}
Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal Daum{\'e}~III, and John
  Langford.
\newblock Active learning for cost-sensitive classification.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Le~Cam(1986)]{lecam1986asymptotic}
Lucien Le~Cam.
\newblock \emph{Asymptotic methods in statistical decision theory}.
\newblock Springer, 1986.

\bibitem[Li et~al.(2019)Li, Wang, and Zhou]{li2019nearly}
Yingkai Li, Yining Wang, and Yuan Zhou.
\newblock Nearly minimax-optimal regret for linearly parameterized bandits.
\newblock In \emph{Conference on Learning Theory}, 2019.

\bibitem[Luo and Schapire(2015)]{luo2015achieving}
Haipeng Luo and Robert~E Schapire.
\newblock Achieving all with no parameters: {AdaNormalHedge}.
\newblock In \emph{Conference on Learning Theory}, 2015.

\bibitem[Luo et~al.(2018)Luo, Wei, and Zheng]{luo2018efficient}
Haipeng Luo, Chen-Yu Wei, and Kai Zheng.
\newblock Efficient online portfolio with logarithmic regret.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Lykouris et~al.(2018)Lykouris, Sridharan, and
  Tardos]{lykouris2017small}
Thodoris Lykouris, Karthik Sridharan, and {\'{E}}va Tardos.
\newblock Small-loss bounds for online learning with partial information.
\newblock \emph{Conference on Learning Theory}, 2018.

\bibitem[Neu(2015)]{neu2015first}
Gergely Neu.
\newblock First-order regret bounds for combinatorial semi-bandits.
\newblock In \emph{Conference on Learning Theory}, 2015.

\bibitem[{Opper} and {Haussler}(1999)]{opper99logloss}
Manfred {Opper} and David {Haussler}.
\newblock Worst case prediction over sequences under log loss.
\newblock In \emph{The Mathematics of Information Coding, Extraction and
  Distribution}, 1999.

\bibitem[Orseau et~al.(2017)Orseau, Lattimore, and Legg]{orseau2017soft}
Laurent Orseau, Tor Lattimore, and Shane Legg.
\newblock Soft-bayes: Prod for mixtures of experts with log-loss.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2017.

\bibitem[Ozawa(2018)]{ozawa2015functional}
Narutaka Ozawa.
\newblock A functional analysis proof of {Gromov’s} polynomial growth
  theorem.
\newblock \emph{Annales Scientifiques de l'{\'E}cole Normale Sup{\'e}rieure},
  2018.

\bibitem[Panchenko(2002)]{panchenko2002some}
Dmitriy Panchenko.
\newblock Some extensions of an inequality of {Vapnik} and {Chervonenkis}.
\newblock \emph{Electronic Communications in Probability}, 2002.

\bibitem[Rakhlin and Sridharan(2015)]{rakhlin2015sequential}
Alexander Rakhlin and Karthik Sridharan.
\newblock Sequential probability assignment with binary alphabets and large
  classes of experts.
\newblock \emph{arXiv:1501.07340}, 2015.

\bibitem[Ross et~al.(2013)Ross, Mineiro, and Langford]{ross2013normalized}
St{\'e}phane Ross, Paul Mineiro, and John Langford.
\newblock Normalized online learning.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2013.

\bibitem[Shtar'kov(1987)]{shtarkov1987universal}
Yurii~Mikhailovich Shtar'kov.
\newblock Universal sequential coding of single messages.
\newblock \emph{Problemy Peredachi Informatsii}, 1987.

\bibitem[Simchi-Levi and Xu(2020)]{simchi2020bypassing}
David Simchi-Levi and Yunzong Xu.
\newblock Bypassing the monster: A faster and simpler optimal algorithm for
  contextual bandits under realizability.
\newblock \emph{arXiv:2003.12699}, 2020.

\bibitem[Srebro et~al.(2010)Srebro, Sridharan, and
  Tewari]{srebro2010smoothness}
Nathan Srebro, Karthik Sridharan, and Ambuj Tewari.
\newblock Smoothness, low noise and fast rates.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2010.

\bibitem[Takeshi(1985)]{takeshi1985advanced}
Amemiya Takeshi.
\newblock \emph{Advanced econometrics}.
\newblock Harvard university press, 1985.

\bibitem[Tewari and Murphy(2017)]{tewari2017ads}
Ambuj Tewari and Susan~A Murphy.
\newblock From ads to interventions: Contextual bandits in mobile health.
\newblock In \emph{Mobile Health}, 2017.

\bibitem[Topsøe(2000)]{topsoe2000some}
Flemming Topsøe.
\newblock Some inequalities for information divergence and related measures of
  discrimination.
\newblock \emph{IEEE Transactions on Information Theory}, 2000.

\bibitem[van~de Geer(2000)]{Sara00}
Sara~A. van~de Geer.
\newblock \emph{Empirical Processes in {M}-{E}stimation.}
\newblock Cambridge University Press, 2000.

\bibitem[Vanschoren et~al.(2014)Vanschoren, Van~Rijn, Bischl, and
  Torgo]{vanschoren2014openml}
Joaquin Vanschoren, Jan~N Van~Rijn, Bernd Bischl, and Luis Torgo.
\newblock {OpenML}: networked science in machine learning.
\newblock \emph{ACM SIGKDD Explorations Newsletter}, 2014.

\bibitem[Vapnik and Chervonenkis(1971)]{vapnik1971uniform}
Vladimir~N. Vapnik and Alexey~A. Chervonenkis.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock \emph{Measures of Complexity}, 1971.

\bibitem[Vincze(1981)]{vincze1981concept}
Istv{\'a}n Vincze.
\newblock On the concept and measure of information contained in an
  observation.
\newblock In \emph{Contributions to Probability}. Elsevier, 1981.

\bibitem[Vovk(1995)]{vovk1995game}
Vladimir Vovk.
\newblock A game of prediction with expert advice.
\newblock In \emph{Conference on Computational Learning Theory}, 1995.

\bibitem[Xu and Zeevi(2020)]{xu2020upper}
Yunbei Xu and Assaf Zeevi.
\newblock Upper counterfactual confidence bounds: {A} new optimism principle
  for contextual bandits.
\newblock \emph{arXiv:2007.07876}, 2020.

\bibitem[Yang(1999)]{yang1999minimax}
Yuhong Yang.
\newblock Minimax nonparametric classification. {I.} {Rates} of convergence.
\newblock \emph{IEEE Transactions on Information Theory}, 1999.

\bibitem[Yehudayoff(2020)]{yehudayoff2020pointer}
Amir Yehudayoff.
\newblock Pointer chasing via triangular discrimination.
\newblock \emph{Combinatorics, Probability and Computing}, 2020.

\bibitem[Zhang(2006)]{zhang2006from}
Tong Zhang.
\newblock From $\epsilon$-entropy to {KL}-entropy: Analysis of minimum
  information complexity density estimation.
\newblock \emph{The Annals of Statistics}, 2006.

\bibitem[Zhang et~al.(2021)Zhang, Yang, Ji, and Du]{zhang2021variance}
Zihan Zhang, Jiaqi Yang, Xiangyang Ji, and Simon~S Du.
\newblock Variance-aware confidence set: Variance-dependent bound for linear
  bandits and horizon-free bound for linear mixture {MDP}.
\newblock \emph{arXiv:2101.12745}, 2021.

\bibitem[Zhou et~al.(2020)Zhou, Gu, and Szepesvari]{zhou2020nearly}
Dongruo Zhou, Quanquan Gu, and Csaba Szepesvari.
\newblock Nearly minimax optimal reinforcement learning for linear mixture
  {Markov} decision processes.
\newblock \emph{arXiv:2012.08507}, 2020.

\end{thebibliography}
