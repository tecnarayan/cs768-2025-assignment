@book{oliehoek2016concise,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher},
  year={2016},
  publisher={Springer}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine Learning},
  volume={8},
  number={3},
  pages={293--321},
  year={1992},
  publisher={Springer}
}
@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={30},
  year={2016}
}
@article{ye2020towards,
  title={Towards playing full moba games with deep reinforcement learning},
  author={Ye, Deheng and Chen, Guibin and Zhang, Wen and Chen, Sheng and Yuan, Bo and Liu, Bo and Chen, Jia and Liu, Zhao and Qiu, Fuhao and Yu, Hongsheng and others},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={621--632},
  year={2020}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, Przemyslaw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{zhou2020drle,
  title={DRLE: Decentralized reinforcement learning at the edge for traffic light control in the IoV},
  author={Zhou, Pengyuan and Chen, Xianfu and Liu, Zhi and Braud, Tristan and Hui, Pan and Kangasharju, Jussi},
  journal={IEEE Transactions on Intelligent Transportation Systems (T-ITS)},
  volume={22},
  number={4},
  pages={2262--2273},
  year={2020},
  publisher={IEEE}
}

@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems (T-ITS)},
  year={2021},
  publisher={IEEE}
}


@article{wu2020multi,
  title={Multi-agent deep reinforcement learning for urban traffic light control in vehicular networks},
  author={Wu, Tong and Zhou, Pan and Liu, Kai and Yuan, Yali and Wang, Xiumin and Huang, Huawei and Wu, Dapeng Oliver},
  journal={IEEE Transactions on Vehicular Technology},
  volume={69},
  number={8},
  pages={8243--8256},
  year={2020},
  publisher={IEEE}
}

@article{cao2012overview,
  title={An overview of recent progress in the study of distributed multi-agent coordination},
  author={Cao, Yongcan and Yu, Wenwu and Ren, Wei and Chen, Guanrong},
  journal={IEEE Transactions on Industrial Informatics},
  volume={9},
  number={1},
  pages={427--438},
  year={2012},
  publisher={IEEE}
}

@inproceedings{zhang2011coordinated,
  title={Coordinated multi-agent reinforcement learning in networked distributed POMDPs},
  author={Zhang, Chongjie and Lesser, Victor},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={25},
  year={2011}
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@inproceedings{rashid2018qmix,
  title={QMIX: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4295--4304},
  year={2018}
}

@article{yang2020qatten,
  title={Qatten: A general framework for cooperative multiagent reinforcement learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}

@inproceedings{wang2020qplex,
  title={Qplex: Duplex dueling multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{samvelyan19smac,
  title = {{The} {StarCraft} {Multi}-{Agent} {Challenge}},
  author = {Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philiph H. S. Torr and Jakob Foerster and Shimon Whiteson},
  journal = {CoRR},
  volume = {abs/1902.04043},
  year = {2019},
}

@article{rashid2020weighted,
  title={Weighted {QMIX}: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={10199--10210},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={30},
  year={2017}
}


@inproceedings{kurach2020google,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Stanczyk, Piotr and Zajac, Michal and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={34},
  pages={4501--4510},
  year={2020}
}

@article{guo2022attention,
  title={Attention mechanisms in computer vision: A survey},
  author={Guo, Meng-Hao and Xu, Tian-Xing and Liu, Jiang-Jiang and Liu, Zheng-Ning and Jiang, Peng-Tao and Mu, Tai-Jiang and Zhang, Song-Hai and Martin, Ralph R and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={Computational Visual Media},
  pages={1--38},
  year={2022},
  publisher={Springer}
}

@inproceedings{son2019qtran,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@inproceedings{chen2017attentive,
  title={Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention},
  author={Chen, Jingyuan and Zhang, Hanwang and He, Xiangnan and Nie, Liqiang and Liu, Wei and Chua, Tat-Seng},
  booktitle={International Conference on Research and Development in Information Retrieval (SIGIR)},
  pages={335--344},
  year={2017}
}

@inproceedings{khan2022transformer,
  title={Transformer-Based Value Function Decomposition for Cooperative Multi-Agent Reinforcement Learning in StarCraft},
  author={Khan, Muhammad Junaid and Ahmed, Syed Hammad and Sukthankar, Gita},
  booktitle={AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE)},
  volume={18},
  number={1},
  pages={113--119},
  year={2022}
}

@article{bulling2022combining,
  title={Combining quantitative and qualitative reasoning in concurrent multi-player games},
  author={Bulling, Nils and Goranko, Valentin},
  journal={Autonomous Agents and Multi-Agent Systems (AAMAS)},
  volume={36},
  number={1},
  pages={1--33},
  year={2022},
  publisher={Springer}
}

@article{tesauro2002pricing,
  title={Pricing in agent economies using multi-agent Q-learning},
  author={Tesauro, Gerald and Kephart, Jeffrey O},
  journal={Autonomous Agents and Multi-Agent Systems (AAMAS)},
  volume={5},
  number={3},
  pages={289--304},
  year={2002},
  publisher={Springer}
}

@article{gronauer2022multi,
  title={Multi-agent deep reinforcement learning: a survey},
  author={Gronauer, Sven and Diepold, Klaus},
  journal={Artificial Intelligence Review},
  volume={55},
  number={2},
  pages={895--943},
  year={2022},
  publisher={Springer}
}

@article{oroojlooy2022review,
  title={A review of cooperative multi-agent deep reinforcement learning},
  author={Oroojlooy, Afshin and Hajinezhad, Davood},
  journal={Applied Intelligence},
  pages={1--46},
  year={2022},
  publisher={Springer}
}

@inproceedings{seraj2022embodied,
  title={Embodied Team Intelligence in Multi-Robot Systems.},
  author={Seraj, Esmaeil},
  booktitle={Autonomous Agents and Multi-Agent Systems (AAMAS)},
  pages={1869--1871},
  year={2022}
}

@article{oliehoek2008optimal,
  title={Optimal and approximate Q-value functions for decentralized POMDPs},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={289--353},
  year={2008}
}

@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016},
  publisher={Elsevier}
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={30},
  year={2017}
}

@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={AAAI conference on artificial intelligence (AAAI)},
  volume={32},
  year={2018}
}

@article{tampuu2017multiagent,
  title={Multiagent cooperation and competition with deep reinforcement learning},
  author={Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan and Vicente, Raul},
  journal={PloS one},
  volume={12},
  number={4},
  pages={e0172395},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}
@inproceedings{christianos2020shared,
  title={Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning},
  author={Christianos, Filippos and Schäfer, Lukas and Albrecht, Stefano V},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{koller1999computing,
  title={Computing factored value functions for policies in structured MDPs},
  author={Koller, Daphne and Parr, Ronald},
  booktitle={International Joint Conferences on Artificial Intelligence (IJCAI)},
  volume={99},
  pages={1332--1339},
  year={1999}
}

@article{hausknecht2015deep,
  title={Deep Recurrent Q-Learning for Partially Observable MDPs},
  author={Hausknecht, Matthew and Stone, Peter},
  journal={arXiv preprint arXiv:1507.06527},
  year={2015}
}

@inproceedings{iqbal2019actor,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2961--2970},
  year={2019},
  organization={PMLR}
}

@article{liu2022self,
  title={Self-attention-based multi-agent continuous control method in cooperative environments},
  author={Liu, Kai and Zhao, Yuyang and Wang, Gang and Peng, Bei},
  journal={Information Sciences},
  volume={585},
  pages={454--470},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{niu2021multi,
  title={Multi-Agent Graph-Attention Communication and Teaming.},
  author={Niu, Yaru and Paleja, Rohan R and Gombolay, Matthew C},
  booktitle={Autonomous Agents and Multi-Agent Systems (AAMAS)},
  pages={964--973},
  year={2021}
}

@inproceedings{ryu2020multi,
  title={Multi-agent actor-critic with hierarchical graph attention network},
  author={Ryu, Heechang and Shin, Hayong and Park, Jinkyoo},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={34},
  number={05},
  pages={7236--7243},
  year={2020}
}

@article{peng2021facmac,
  title={Facmac: Factored multi-agent centralised policy gradients},
  author={Peng, Bei and Rashid, Tabish and Schroeder de Witt, Christian and Kamienny, Pierre-Alexandre and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={12208--12221},
  year={2021}
}

@inproceedings{schaul2016prioritized,
  title={Prioritized Experience Replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016}
}
@inproceedings{isele2018selective,
  title={Selective experience replay for lifelong learning},
  author={Isele, David and Cosgun, Akansel},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={32},
  number={1},
  year={2018}
}
@inproceedings{sun2020attentive,
  title={Attentive experience replay},
  author={Sun, Peiquan and Zhou, Wengang and Li, Houqiang},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={34},
  number={04},
  pages={5900--5907},
  year={2020}
}


@inproceedings{omidshafiei2017deep,
  title={Deep decentralized multi-task multi-agent reinforcement learning under partial observability},
  author={Omidshafiei, Shayegan and Pazis, Jason and Amato, Christopher and How, Jonathan P and Vian, John},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2681--2690},
  year={2017},
  organization={PMLR}
}
@inproceedings{foerster2017stabilising,
  title={Stabilising experience replay for deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip HS and Kohli, Pushmeet and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1146--1155},
  year={2017},
  organization={PMLR}
}
@article{weber2022remember,
  title={Remember and Forget Experience Replay for Multi-Agent Reinforcement Learning},
  author={Weber, Pascal and W{\"a}lchli, Daniel and Zeqiri, Mustafa and Koumoutsakos, Petros},
  journal={arXiv preprint arXiv:2203.13319},
  year={2022}
}
@inproceedings{fan2020prioritized,
  title={Prioritized Experience Replay in Multi-Actor-Attention-Critic for Reinforcement Learning},
  author={Fan, Sheng and Song, Guanghua and Yang, Bowei and Jiang, Xiaohong},
  booktitle={Journal of Physics: Conference Series},
  volume={1631},
  year={2020}
}

@inproceedings{smith2018don,
  title={Don't Decay the Learning Rate, Increase the Batch Size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Ying, Chris and Le, Quoc V},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@inproceedings{jeon2022maser,
  title={Maser: Multi-agent reinforcement learning with subgoals generated from experience replay buffer},
  author={Jeon, Jeewon and Kim, Woojun and Jung, Whiyoung and Sung, Youngchul},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={10041--10052},
  year={2022},
  organization={PMLR}
}

