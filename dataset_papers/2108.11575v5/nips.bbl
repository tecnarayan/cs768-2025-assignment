\begin{thebibliography}{10}

\bibitem{abnar2020quantifying}
Samira Abnar and Willem Zuidema.
\newblock Quantifying attention flow in transformers.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 4190--4197, 2020.

\bibitem{akbari2021vatt}
Hassan Akbari, Linagzhe Yuan, Rui Qian, Wei-Hong Chuang, Shih-Fu Chang, Yin
  Cui, and Boqing Gong.
\newblock Vatt: Transformers for multimodal self-supervised learning from raw
  video, audio and text.
\newblock {\em arXiv preprint arXiv:2104.11178}, 2021.

\bibitem{andoni2015practical}
Alexandr Andoni, Piotr Indyk, TMM Laarhoven, Ilya Razenshteyn, and Ludwig
  Schmidt.
\newblock Practical and optimal lsh for angular distance.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS
  2015)}, pages 1225--1233. Curran Associates, 2015.

\bibitem{arnab2021vivit}
Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lu{\v{c}}i{\'c},
  and Cordelia Schmid.
\newblock Vivit: A video vision transformer.
\newblock {\em arXiv preprint arXiv:2103.15691}, 2021.

\bibitem{bertasius2021space}
Gedas Bertasius, Heng Wang, and Lorenzo Torresani.
\newblock Is space-time attention all you need for video understanding?
\newblock {\em arXiv preprint arXiv:2102.05095}, 2021.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European Conference on Computer Vision}, pages 213--229.
  Springer, 2020.

\bibitem{carreira2018short}
Joao Carreira, Eric Noland, Andras Banki-Horvath, Chloe Hillier, and Andrew
  Zisserman.
\newblock A short note about kinetics-600.
\newblock {\em arXiv preprint arXiv:1808.01340}, 2018.

\bibitem{carreira2017quo}
Joao Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6299--6308, 2017.

\bibitem{christoph2016spatiotemporal}
R~Christoph and Feichtenhofer~Axel Pinz.
\newblock Spatiotemporal residual networks for video action recognition.
\newblock {\em Advances in Neural Information Processing Systems}, pages
  3468--3476, 2016.

\bibitem{chu2021we}
Xiangxiang Chu, Bo~Zhang, Zhi Tian, Xiaolin Wei, and Huaxia Xia.
\newblock Do we really need explicit position encodings for vision
  transformers?
\newblock {\em arXiv preprint arXiv:2102.10882}, 2021.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 248--255. Ieee, 2009.

\bibitem{devlin2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186, 2019.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{fan2021multiscale}
Haoqi Fan, Bo~Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock {\em arXiv preprint arXiv:2104.11227}, 2021.

\bibitem{feichtenhofer2020x3d}
Christoph Feichtenhofer.
\newblock X3d: Expanding architectures for efficient video recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 203--213, 2020.

\bibitem{feichtenhofer2019slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6202--6211, 2019.

\bibitem{goyal2017something}
Raghav Goyal, Samira Ebrahimi~Kahou, Vincent Michalski, Joanna Materzynska,
  Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos,
  Moritz Mueller-Freitag, et~al.
\newblock The" something something" video database for learning and evaluating
  visual common sense.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 5842--5850, 2017.

\bibitem{hara2018can}
Kensho Hara, Hirokatsu Kataoka, and Yutaka Satoh.
\newblock Can spatiotemporal 3d cnns retrace the history of 2d cnns and
  imagenet?
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6546--6555, 2018.

\bibitem{hendrycks2016gaussian}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock {\em arXiv preprint arXiv:1606.08415}, 2016.

\bibitem{huang2020cycle}
Yufang Huang, Wentao Zhu, Deyi Xiong, Yiye Zhang, Changjian Hu, and Feiyu Xu.
\newblock Cycle-consistent adversarial autoencoders for unsupervised text style
  transfer.
\newblock In {\em Proceedings of the 28th International Conference on
  Computational Linguistics}, pages 2213--2223, 2020.

\bibitem{kay2017kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
  Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
\newblock The kinetics human action video dataset.
\newblock {\em arXiv preprint arXiv:1705.06950}, 2017.

\bibitem{ke2019time}
Qiuhong Ke, Mario Fritz, and Bernt Schiele.
\newblock Time-conditioned action anticipation in one shot.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9925--9934, 2019.

\bibitem{kitaev2020reformer}
Nikita Kitaev, {\L}ukasz Kaiser, and Anselm Levskaya.
\newblock Reformer: The efficient transformer.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{kristan2019seventh}
Matej Kristan, Jiri Matas, Ales Leonardis, Michael Felsberg, Roman Pflugfelder,
  Joni-Kristian Kamarainen, Luka Cehovin~Zajc, Ondrej Drbohlav, Alan Lukezic,
  Amanda Berg, et~al.
\newblock The seventh visual object tracking vot2019 challenge results.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops}, pages 0--0, 2019.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in Neural Information Processing Systems},
  25:1097--1105, 2012.

\bibitem{kuehne2011hmdb}
Hildegard Kuehne, Hueihan Jhuang, Est{\'\i}baliz Garrote, Tomaso Poggio, and
  Thomas Serre.
\newblock Hmdb: a large video database for human motion recognition.
\newblock In {\em International Conference on Computer Vision}, pages
  2556--2563. IEEE, 2011.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{li2020tea}
Yan Li, Bin Ji, Xintian Shi, Jianguo Zhang, Bin Kang, and Limin Wang.
\newblock Tea: Temporal excitation and aggregation for action recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 909--918, 2020.

\bibitem{li2018resound}
Yingwei Li, Yi~Li, and Nuno Vasconcelos.
\newblock Resound: Towards action recognition without representation bias.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 513--528, 2018.

\bibitem{liu2016spatio}
Jun Liu, Amir Shahroudy, Dong Xu, and Gang Wang.
\newblock Spatio-temporal lstm with trust gates for 3d human action
  recognition.
\newblock In {\em European Conference on Computer Vision}, pages 816--833.
  Springer, 2016.

\bibitem{liu2017global}
Jun Liu, Gang Wang, Ping Hu, Ling-Yu Duan, and Alex~C Kot.
\newblock Global context-aware attention lstm networks for 3d action
  recognition.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1647--1656, 2017.

\bibitem{loshchilov2016sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{monfort2019moments}
Mathew Monfort, Alex Andonian, Bolei Zhou, Kandan Ramakrishnan, Sarah~Adel
  Bargal, Tom Yan, Lisa Brown, Quanfu Fan, Dan Gutfreund, Carl Vondrick, et~al.
\newblock Moments in time dataset: one million videos for event understanding.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  42(2):502--508, 2019.

\bibitem{muller2019does}
Rafael M{\"u}ller, Simon Kornblith, and Geoffrey Hinton.
\newblock When does label smoothing help?
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer,
  Alexander Ku, and Dustin Tran.
\newblock Image transformer.
\newblock In {\em International Conference on Machine Learning}, pages
  4055--4064. PMLR, 2018.

\bibitem{qiu2017learning}
Zhaofan Qiu, Ting Yao, and Tao Mei.
\newblock Learning spatio-temporal representation with pseudo-3d residual
  networks.
\newblock In {\em proceedings of the IEEE International Conference on Computer
  Vision}, pages 5533--5541, 2017.

\bibitem{qiu2019learning}
Zhaofan Qiu, Ting Yao, Chong-Wah Ngo, Xinmei Tian, and Tao Mei.
\newblock Learning spatio-temporal representation with local and global
  diffusion.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12056--12065, 2019.

\bibitem{ramachandran2019stand}
Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya,
  and Jonathon Shlens.
\newblock Stand-alone self-attention in vision models.
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{ridnik2021imagenet}
Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, and Lihi Zelnik-Manor.
\newblock Imagenet-21k pretraining for the masses.
\newblock {\em arXiv preprint arXiv:2104.10972}, 2021.

\bibitem{simonyan2014two}
Karen Simonyan and Andrew Zisserman.
\newblock Two-stream convolutional networks for action recognition in videos.
\newblock In {\em Proceedings of the 27th International Conference on Neural
  Information Processing Systems-Volume 1}, pages 568--576, 2014.

\bibitem{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock {\em arXiv preprint arXiv:1212.0402}, 2012.

\bibitem{touvron2020training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv preprint arXiv:2012.12877}, 2020.

\bibitem{tran2015learning}
Du~Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri.
\newblock Learning spatiotemporal features with 3d convolutional networks.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 4489--4497, 2015.

\bibitem{tran2019video}
Du~Tran, Heng Wang, Lorenzo Torresani, and Matt Feiszli.
\newblock Video classification with channel-separated convolutional networks.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5552--5561, 2019.

\bibitem{tran2018closer}
Du~Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, and Manohar
  Paluri.
\newblock A closer look at spatiotemporal convolutions for action recognition.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6450--6459, 2018.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~30, pages 5998--6008, 2017.

\bibitem{vedaldi2010vlfeat}
Andrea Vedaldi and Brian Fulkerson.
\newblock Vlfeat: An open and portable library of computer vision algorithms.
\newblock In {\em Proceedings of the 18th ACM International Conference on
  Multimedia}, pages 1469--1472, 2010.

\bibitem{wang2020video}
Heng Wang, Du~Tran, Lorenzo Torresani, and Matt Feiszli.
\newblock Video modeling with correlation networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 352--361, 2020.

\bibitem{wang2021pyramid}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock {\em arXiv preprint arXiv:2102.12122}, 2021.

\bibitem{wang2020attentionnas}
Xiaofang Wang, Xuehan Xiong, Maxim Neumann, AJ~Piergiovanni, Michael~S Ryoo,
  Anelia Angelova, Kris~M Kitani, and Wei Hua.
\newblock Attentionnas: Spatiotemporal attention cell search for video
  classification.
\newblock In {\em European Conference on Computer Vision}, pages 449--465.
  Springer, 2020.

\bibitem{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 7794--7803, 2018.

\bibitem{wu2021cvt}
Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu~Yuan, and Lei
  Zhang.
\newblock Cvt: Introducing convolutions to vision transformers.
\newblock {\em arXiv preprint arXiv:2103.15808}, 2021.

\bibitem{xie2018rethinking}
Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy.
\newblock Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs
  in video classification.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 305--321, 2018.

\bibitem{yeung2016end}
Serena Yeung, Olga Russakovsky, Greg Mori, and Li~Fei-Fei.
\newblock End-to-end learning of action detection from frame glimpses in
  videos.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2678--2687, 2016.

\bibitem{zheng2020rethinking}
Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang,
  Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip~HS Torr, et~al.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2021.

\bibitem{zhu2021speechnas}
Wentao Zhu, Tianlong Kong, Shun Lu, Jixiang Li, Dawei Zhang, Feng Deng, Xiaorui
  Wang, Sen Yang, and Ji~Liu.
\newblock Speechnas: Towards better trade-off between latency and accuracy for
  large-scale speaker verification.
\newblock In {\em ASRU}, 2021.

\bibitem{zhu2016co}
Wentao Zhu, Cuiling Lan, Junliang Xing, Wenjun Zeng, Yanghao Li, Li~Shen, and
  Xiaohui Xie.
\newblock Co-occurrence feature learning for skeleton based action recognition
  using regularized deep lstm networks.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~30, 2016.

\end{thebibliography}
