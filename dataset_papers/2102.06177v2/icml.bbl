\begin{thebibliography}{82}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen et~al.(2020)Allen, Smith, and
  Tenenbaum]{rapid_trial_and_error_learning_with_simulation_supports_flexible_tool_use_and_physical_reasoning}
Allen, K.~R., Smith, K.~A., and Tenenbaum, J.~B.
\newblock Rapid trial-and-error learning with simulation supports flexible tool
  use and physical reasoning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (47):\penalty0 29302--29310, 2020.
\newblock ISSN 0027-8424.
\newblock \doi{10.1073/pnas.1912341117}.
\newblock URL \url{https://www.pnas.org/content/117/47/29302}.

\bibitem[Andreas et~al.(2017)Andreas, Klein, and
  Levine]{modular_multitask_reinforcement_learning_with_policy_sketches}
Andreas, J., Klein, D., and Levine, S.
\newblock Modular multitask reinforcement learning with policy sketches.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  166--175, 2017.

\bibitem[Bellman(1957)]{Bellman1957}
Bellman, R.
\newblock \emph{Dynamic Programming}.
\newblock Princeton University Press, Princeton, NJ, USA, 1 edition, 1957.

\bibitem[Borsa et~al.(2016)Borsa, Graepel, and Shawe{-}Taylor]{borsa2016mtrl}
Borsa, D., Graepel, T., and Shawe{-}Taylor, J.
\newblock Learning shared representations in multi-task reinforcement learning.
\newblock \emph{CoRR}, abs/1603.02041, 2016.
\newblock URL \url{http://arxiv.org/abs/1603.02041}.

\bibitem[Br{\"a}m et~al.(2019)Br{\"a}m, Brunner, Richter, and
  Wattenhofer]{bram2019attentive}
Br{\"a}m, T., Brunner, G., Richter, O., and Wattenhofer, R.
\newblock Attentive multi-task deep reinforcement learning.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pp.\  134--149. Springer, 2019.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{openai_gym}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Calandriello et~al.(2014)Calandriello, Lazaric, and
  Restelli]{calandriello2014multitask}
Calandriello, D., Lazaric, A., and Restelli, M.
\newblock Sparse multi-task reinforcement learning.
\newblock In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N.~D., and
  Weinberger, K.~Q. (eds.), \emph{Advances in neural information processing
  systems 27}, pp.\  819--827. Curran Associates, Inc., 2014.

\bibitem[Caruana(1997)]{caruana1997multitask_learning}
Caruana, R.
\newblock Multitask learning.
\newblock \emph{Machine learning}, 28\penalty0 (1):\penalty0 41--75, 1997.

\bibitem[Chang et~al.(2018)Chang, Gupta, Levine, and
  Griffiths]{automatically_composing_representation_transformations_as_a_means_for_generalization}
Chang, M.~B., Gupta, A., Levine, S., and Griffiths, T.~L.
\newblock Automatically composing representation transformations as a means for
  generalization.
\newblock \emph{arXiv preprint arXiv:1807.04640}, 2018.

\bibitem[Chao et~al.(2011)Chao, Cakmak, and Thomaz]{chao2011towards}
Chao, C., Cakmak, M., and Thomaz, A.~L.
\newblock Towards grounding concepts for transfer in goal learning from
  demonstration.
\newblock In \emph{2011 IEEE International Conference on Development and
  Learning (ICDL)}, volume~2, pp.\  1--6. IEEE, 2011.

\bibitem[Chaplot et~al.(2017)Chaplot, Sathyendra, Pasumarthi, Rajagopal, and
  Salakhutdinov]{gated_attention_architectures_for_task_oriented_language_grounding}
Chaplot, D.~S., Sathyendra, K.~M., Pasumarthi, R.~K., Rajagopal, D., and
  Salakhutdinov, R.
\newblock Gated-attention architectures for task-oriented language grounding.
\newblock \emph{arXiv preprint arXiv:1706.07230}, 2017.

\bibitem[Chen \& Mooney(2011)Chen and
  Mooney]{learning_to_interpret_natural_language_navigation_instructions_from_observations}
Chen, D.~L. and Mooney, R.~J.
\newblock Learning to interpret natural language navigation instructions from
  observations.
\newblock In \emph{Twenty-Fifth AAAI Conference on Artificial Intelligence},
  2011.

\bibitem[Chen et~al.(2018)Chen, Badrinarayanan, Lee, and
  Rabinovich]{chen2018gradnorm}
Chen, Z., Badrinarayanan, V., Lee, C.-Y., and Rabinovich, A.
\newblock Gradnorm: Gradient normalization for adaptive loss balancing in deep
  multitask networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  794--803. PMLR, 2018.

\bibitem[Chevalier-Boisvert et~al.(2019)Chevalier-Boisvert, Bahdanau, Lahlou,
  Willems, Saharia, Nguyen, and Bengio]{babyai}
Chevalier-Boisvert, M., Bahdanau, D., Lahlou, S., Willems, L., Saharia, C.,
  Nguyen, T.~H., and Bengio, Y.
\newblock Baby{AI}: First steps towards grounded language learning with a human
  in the loop.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=rJeXCo0cYX}.

\bibitem[D'Eramo et~al.(2020)D'Eramo, Tateo, Bonarini, Restelli, and
  Peters]{sharing_knowledge_in_multitask_deep_reinforcement_learning}
D'Eramo, C., Tateo, D., Bonarini, A., Restelli, M., and Peters, J.
\newblock Sharing knowledge in multi-task deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Devin et~al.(2017)Devin, Gupta, Darrell, Abbeel, and
  Levine]{learning_modular_neural_network_policies_for_multi_task_and_multi_robot_transfer}
Devin, C., Gupta, A., Darrell, T., Abbeel, P., and Levine, S.
\newblock Learning modular neural network policies for multi-task and
  multi-robot transfer.
\newblock In \emph{2017 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  2169--2176. IEEE, 2017.

\bibitem[Du et~al.(2019)Du, Krishnamurthy, Jiang, Agarwal, Dud{\'{\i}}k, and
  Langford]{du2019pcid}
Du, S.~S., Krishnamurthy, A., Jiang, N., Agarwal, A., Dud{\'{\i}}k, M., and
  Langford, J.
\newblock Provably efficient {RL} with rich observations via latent state
  decoding.
\newblock \emph{CoRR}, abs/1901.09018, 2019.

\bibitem[Du et~al.(2018)Du, Czarnecki, Jayakumar, Pascanu, and
  Lakshminarayanan]{adapting_auxiliary_losses_using_gradient_similarity}
Du, Y., Czarnecki, W.~M., Jayakumar, S.~M., Pascanu, R., and Lakshminarayanan,
  B.
\newblock Adapting auxiliary losses using gradient similarity.
\newblock \emph{arXiv preprint arXiv:1812.02224}, 2018.

\bibitem[El~Bsat et~al.(2017)El~Bsat, Bou-Ammar, and
  Taylor]{scalable_multitask_policy_gradient_reinforcement_learning}
El~Bsat, S., Bou-Ammar, H., and Taylor, M.~E.
\newblock Scalable multitask policy gradient reinforcement learning.
\newblock In \emph{AAAI}, pp.\  1847--1853, 2017.

\bibitem[Goyal et~al.(2019)Goyal, Lamb, Hoffmann, Sodhani, Levine, Bengio, and
  Sch{\"o}lkopf]{goyal2019recurrent}
Goyal, A., Lamb, A., Hoffmann, J., Sodhani, S., Levine, S., Bengio, Y., and
  Sch{\"o}lkopf, B.
\newblock Recurrent independent mechanisms.
\newblock \emph{arXiv preprint arXiv:1909.10893}, 2019.

\bibitem[Greff et~al.(2019)Greff, Kaufman, Kabra, Watters, Burgess, Zoran,
  Matthey, Botvinick, and
  Lerchner]{multi_object_representation_learning_with_iterative_variational_inference}
Greff, K., Kaufman, R.~L., Kabra, R., Watters, N., Burgess, C., Zoran, D.,
  Matthey, L., Botvinick, M., and Lerchner, A.
\newblock Multi-object representation learning with iterative variational
  inference.
\newblock \emph{arXiv preprint arXiv:1903.00450}, 2019.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{soft-actor-critic}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1861--1870. PMLR, 2018.

\bibitem[Hallak et~al.(2015)Hallak, Castro, and Mannor]{hallak2015contextual}
Hallak, A., Castro, D.~D., and Mannor, S.
\newblock Contextual markov decision processes, 2015.

\bibitem[Harris et~al.(2020)Harris, Millman, van~der Walt, Gommers, Virtanen,
  Cournapeau, Wieser, Taylor, Berg, Smith, Kern, Picus, Hoyer, van Kerkwijk,
  Brett, Haldane, del R{'{\i}}o, Wiebe, Peterson, G{'{e}}rard-Marchant,
  Sheppard, Reddy, Weckesser, Abbasi, Gohlke, and Oliphant]{harris2020array}
Harris, C.~R., Millman, K.~J., van~der Walt, S.~J., Gommers, R., Virtanen, P.,
  Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.~J., Kern, R.,
  Picus, M., Hoyer, S., van Kerkwijk, M.~H., Brett, M., Haldane, A., del
  R{'{\i}}o, J.~F., Wiebe, M., Peterson, P., G{'{e}}rard-Marchant, P.,
  Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant,
  T.~E.
\newblock Array programming with {NumPy}.
\newblock \emph{Nature}, 585\penalty0 (7825):\penalty0 357--362, September
  2020.
\newblock \doi{10.1038/s41586-020-2649-2}.
\newblock URL \url{https://doi.org/10.1038/s41586-020-2649-2}.

\bibitem[Henderson et~al.(2017)Henderson, Islam, Bachman, Pineau, Precup, and
  Meger]{deep_reinforcement_learning_that_matters}
Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., and Meger, D.
\newblock Deep reinforcement learning that matters.
\newblock \emph{arXiv preprint arXiv:1709.06560}, 2017.

\bibitem[Hermann et~al.(2017)Hermann, Hill, Green, Wang, Faulkner, Soyer,
  Szepesvari, Czarnecki, Jaderberg, Teplyashin,
  et~al.]{grounded_language_learning_in_a_simulated_3d_world}
Hermann, K.~M., Hill, F., Green, S., Wang, F., Faulkner, R., Soyer, H.,
  Szepesvari, D., Czarnecki, W.~M., Jaderberg, M., Teplyashin, D., et~al.
\newblock Grounded language learning in a simulated 3d world.
\newblock \emph{arXiv preprint arXiv:1706.06551}, 2017.

\bibitem[Igl et~al.(2020)Igl, Gambardella, He, Nardelli, Siddharth, B{\"o}hmer,
  and Whiteson]{multitask_soft_option_learning}
Igl, M., Gambardella, A., He, J., Nardelli, N., Siddharth, N., B{\"o}hmer, W.,
  and Whiteson, S.
\newblock Multitask soft option learning, 2020.
\newblock URL \url{https://openreview.net/forum?id=BkeDGJBKvB}.

\bibitem[Jiang et~al.(2019)Jiang, Gu, Murphy, and Finn]{jiang2019language}
Jiang, Y., Gu, S.~S., Murphy, K.~P., and Finn, C.
\newblock Language as an abstraction for hierarchical deep reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9419--9431, 2019.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and
  Cassandra]{kaelbling1998pomdp}
Kaelbling, L.~P., Littman, M.~L., and Cassandra, A.~R.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artif. Intell.}, 101\penalty0 (1–2):\penalty0 99–134, May
  1998.
\newblock ISSN 0004-3702.

\bibitem[Kaiser et~al.(2019)Kaiser, Babaeizadeh, Milos, Osinski, Campbell,
  Czechowski, Erhan, Finn, Kozakowski, Levine, et~al.]{kaiser2019model}
Kaiser, L., Babaeizadeh, M., Milos, P., Osinski, B., Campbell, R.~H.,
  Czechowski, K., Erhan, D., Finn, C., Kozakowski, P., Levine, S., et~al.
\newblock Model-based reinforcement learning for atari.
\newblock \emph{arXiv preprint arXiv:1903.00374}, 2019.

\bibitem[Kipf et~al.(2018)Kipf, Fetaya, Wang, Welling, and
  Zemel]{kipf2018interacting}
Kipf, T.~N., Fetaya, E., Wang, K., Welling, M., and Zemel, R.~S.
\newblock Neural relational inference for interacting systems.
\newblock In Dy, J.~G. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning, {ICML} 2018,
  Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pp.\  2693--2702. {PMLR},
  2018.
\newblock URL \url{http://proceedings.mlr.press/v80/kipf18a.html}.

\bibitem[Klink et~al.(2019)Klink, Abdulsamad, Belousov, and
  Peters]{klink2019contextualrl}
Klink, P., Abdulsamad, H., Belousov, B., and Peters, J.
\newblock Self-paced contextual reinforcement learning.
\newblock In Kaelbling, L.~P., Kragic, D., and Sugiura, K. (eds.), \emph{3rd
  Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 -
  November 1, 2019, Proceedings}, volume 100 of \emph{Proceedings of Machine
  Learning Research}, pp.\  513--529. {PMLR}, 2019.
\newblock URL \url{http://proceedings.mlr.press/v100/klink20a.html}.

\bibitem[Kokkinos(2017)]{kokkinos2017ubernet}
Kokkinos, I.
\newblock Ubernet: Training a universal convolutional neural network for low-,
  mid-, and high-level vision using diverse datasets and limited memory.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  6129--6138, 2017.

\bibitem[Lai \& Robbins(1985)Lai and Robbins]{lai1985mab}
Lai, T. and Robbins, H.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock \emph{Adv. Appl. Math.}, 6\penalty0 (1):\penalty0 4–22, March 1985.
\newblock ISSN 0196-8858.
\newblock \doi{10.1016/0196-8858(85)90002-8}.
\newblock URL \url{https://doi.org/10.1016/0196-8858(85)90002-8}.

\bibitem[Langford \& Zhang(2008)Langford and Zhang]{langford2007mab}
Langford, J. and Zhang, T.
\newblock The epoch-greedy algorithm for multi-armed bandits with side
  information.
\newblock In Platt, J., Koller, D., Singer, Y., and Roweis, S. (eds.),
  \emph{Advances in Neural Information Processing Systems}, volume~20, pp.\
  817--824. Curran Associates, Inc., 2008.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2007/file/4b04a686b0ad13dce35fa99fa4161c65-Paper.pdf}.

\bibitem[Li et~al.(2020)Li, Torralba, Anandkumar, Fox, and Garg]{li2020causal}
Li, Y., Torralba, A., Anandkumar, A., Fox, D., and Garg, A.
\newblock Causal discovery in physical systems from videos, 2020.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Johns, and
  Davison]{end_to_end_multi_task_learning_with_attention}
Liu, S., Johns, E., and Davison, A.~J.
\newblock End-to-end multi-task learning with attention.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  1871--1880, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Ott, Goyal, Du, Joshi, Chen, Levy,
  Lewis, Zettlemoyer, and
  Stoyanov]{roberta_a_robustly_optimized_bert_pretraining_approach}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019{\natexlab{b}}.

\bibitem[Locatello et~al.(2020)Locatello, Weissenborn, Unterthiner, Mahendran,
  Heigold, Uszkoreit, Dosovitskiy, and
  Kipf]{object_centric_learning_with_slot_attention}
Locatello, F., Weissenborn, D., Unterthiner, T., Mahendran, A., Heigold, G.,
  Uszkoreit, J., Dosovitskiy, A., and Kipf, T.
\newblock Object-centric learning with slot attention.
\newblock \emph{arXiv preprint arXiv:2006.15055}, 2020.

\bibitem[Luketina et~al.(2019)Luketina, Nardelli, Farquhar, Foerster, Andreas,
  Grefenstette, Whiteson, and
  Rockt{\"a}schel]{a_survey_of_reinforcement_learning_informed_by_natural_language}
Luketina, J., Nardelli, N., Farquhar, G., Foerster, J., Andreas, J.,
  Grefenstette, E., Whiteson, S., and Rockt{\"a}schel, T.
\newblock A survey of reinforcement learning informed by natural language.
\newblock \emph{arXiv preprint arXiv:1906.03926}, 2019.

\bibitem[Maurer et~al.(2016)Maurer, Pontil, and
  Romera-Paredes]{maurerBenefitMultitaskRepresentation}
Maurer, A., Pontil, M., and Romera-Paredes, B.
\newblock The benefit of multitask representation learning.
\newblock \emph{J. Mach. Learn. Res.}, 17\penalty0 (1):\penalty0 2853–2884,
  January 2016.
\newblock ISSN 1532-4435.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013atari}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.
\newblock Playing atari with deep reinforcement learning, 2013.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, February 2015.
\newblock ISSN 00280836.
\newblock URL \url{http://dx.doi.org/10.1038/nature14236}.

\bibitem[Modi et~al.(2017)Modi, Jiang, Singh, and Tewari]{modi_markov_2017}
Modi, A., Jiang, N., Singh, S., and Tewari, A.
\newblock Markov {Decision} {Processes} with {Continuous} {Side} {Information}.
\newblock \emph{arXiv:1711.05726 [cs, stat]}, November 2017.
\newblock URL \url{http://arxiv.org/abs/1711.05726}.
\newblock arXiv: 1711.05726.

\bibitem[Mott et~al.(2019)Mott, Zoran, Chrzanowski, Wierstra, and
  Rezende]{mott2019towards}
Mott, A., Zoran, D., Chrzanowski, M., Wierstra, D., and Rezende, D.~J.
\newblock Towards interpretable reinforcement learning using attention
  augmented agents.
\newblock \emph{arXiv preprint arXiv:1906.02500}, 2019.

\bibitem[Mozifian et~al.(2020)Mozifian, Zhang, Pineau, and
  Meger]{mozifian2020intervention}
Mozifian, M., Zhang, A., Pineau, J., and Meger, D.
\newblock Intervention design for effective sim2real transfer.
\newblock \emph{arXiv preprint arXiv:2012.02055}, 2020.

\bibitem[pandas~development team(2020)]{reback2020pandas}
pandas~development team, T.
\newblock pandas-dev/pandas: Pandas, February 2020.
\newblock URL \url{https://doi.org/10.5281/zenodo.3509134}.

\bibitem[Parascandolo et~al.(2018)Parascandolo, Kilbertus, Rojas-Carulla, and
  Sch{\"o}lkopf]{learning_independent_causal_mechanisms}
Parascandolo, G., Kilbertus, N., Rojas-Carulla, M., and Sch{\"o}lkopf, B.
\newblock Learning independent causal mechanisms.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4036--4044. PMLR, 2018.

\bibitem[Parisotto et~al.(2015)Parisotto, Ba, and
  Salakhutdinov]{actor_mimic_deep_multitask_and_transfer_reinforcement_learning}
Parisotto, E., Ba, J.~L., and Salakhutdinov, R.
\newblock Actor-mimic: Deep multitask and transfer reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1511.06342}, 2015.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{arXiv preprint arXiv:1912.01703}, 2019.

\bibitem[Pathak et~al.(2019)Pathak, Lu, Darrell, Isola, and
  Efros]{pathak2019LearningControlSelfAssembling}
Pathak, D., Lu, C., Darrell, T., Isola, P., and Efros, A.~A.
\newblock Learning to {Control} {Self}-{Assembling} {Morphologies}: {A} {Study}
  of {Generalization} via {Modularity}.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., Alch-Buc, F.~d.,
  Fox, E., and Garnett, R. (eds.), \emph{Advances in {Neural} {Information}
  {Processing} {Systems} 32}, pp.\  2295--2305. Curran Associates, Inc., 2019.

\bibitem[Perez et~al.(2018)Perez, Strub, De~Vries, Dumoulin, and
  Courville]{film}
Perez, E., Strub, F., De~Vries, H., Dumoulin, V., and Courville, A.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Puterman(1995)]{puterman1995markov}
Puterman, M.~L.
\newblock Markov decision processes: Discrete stochastic dynamic programming.
\newblock \emph{Journal of the Operational Research Society}, 1995.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019language_models_are_unsupervised_multitask_learners}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI Blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Rajeswaran et~al.(2016)Rajeswaran, Ghotra, Ravindran, and
  Levine]{epopt_learning_robust_neural_network_policies_using_model_ensembles}
Rajeswaran, A., Ghotra, S., Ravindran, B., and Levine, S.
\newblock Epopt: Learning robust neural network policies using model ensembles.
\newblock \emph{arXiv preprint arXiv:1610.01283}, 2016.

\bibitem[Ruder(2017)]{ruder2017overview}
Ruder, S.
\newblock An overview of multi-task learning in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1706.05098}, 2017.

\bibitem[Rusu et~al.(2016)Rusu, Colmenarejo, Çaglar Gülçehre, Desjardins,
  Kirkpatrick, Pascanu, Mnih, Kavukcuoglu, and Hadsell]{policy_distillation}
Rusu, A.~A., Colmenarejo, S.~G., Çaglar Gülçehre, Desjardins, G.,
  Kirkpatrick, J., Pascanu, R., Mnih, V., Kavukcuoglu, K., and Hadsell, R.
\newblock Policy distillation.
\newblock In \emph{ICLR (Poster)}, 2016.
\newblock URL \url{http://arxiv.org/abs/1511.06295}.

\bibitem[Shu et~al.(2017)Shu, Xiong, and Socher]{shu2017hierarchical}
Shu, T., Xiong, C., and Socher, R.
\newblock Hierarchical and interpretable skill acquisition in multi-task
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1712.07294}, 2017.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den
  Driessche, Graepel, and Hassabis]{silver2017alphaGo}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T., Hui,
  F., Sifre, L., van~den Driessche, G., Graepel, T., and Hassabis, D.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550\penalty0 (7676):\penalty0 354--359, October 2017.
\newblock ISSN 0028-0836, 1476-4687.
\newblock \doi{10.1038/nature24270}.

\bibitem[Sodhani \& Zhang(2021)Sodhani and Zhang]{Sodhani2021MTRL}
Sodhani, S. and Zhang, A.
\newblock Mtrl - multi task rl algorithms.
\newblock Github, 2021.
\newblock URL \url{https://github.com/facebookresearch/mtrl}.

\bibitem[Sodhani et~al.(2021)Sodhani, Denoyer, Kamienny, and
  Delalleau]{Sodhani2021MTEnv}
Sodhani, S., Denoyer, L., Kamienny, P.-A., and Delalleau, O.
\newblock Mtenv - environment interface for mulit-task reinforcement learning.
\newblock Github, 2021.
\newblock URL \url{https://github.com/facebookresearch/mtenv}.

\bibitem[Srinivas et~al.(2020)Srinivas, Laskin, and Abbeel]{srinivas2020curl}
Srinivas, A., Laskin, M., and Abbeel, P.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2004.04136}, 2020.

\bibitem[Standley et~al.(2019)Standley, Zamir, Chen, Guibas, Malik, and
  Savarese]{which_tasks_should_be_learned_together_in_multitask_learning?}
Standley, T., Zamir, A.~R., Chen, D., Guibas, L., Malik, J., and Savarese, S.
\newblock Which tasks should be learned together in multi-task learning?
\newblock \emph{arXiv preprint arXiv:1905.07553}, 2019.

\bibitem[Student(1908)]{student1908probable}
Student.
\newblock The probable error of a mean.
\newblock \emph{Biometrika}, pp.\  1--25, 1908.

\bibitem[Suteu \& Guo(2019)Suteu and
  Guo]{regularizing_deep_multi_task_networks_using_orthogonal_gradients}
Suteu, M. and Guo, Y.
\newblock Regularizing deep multi-task networks using orthogonal gradients.
\newblock \emph{arXiv preprint arXiv:1912.06844}, 2019.

\bibitem[Tanaka \& Yamamura(2003)Tanaka and
  Yamamura]{multitask_reinforcement_learning_on_the_distribution_of_mdps}
Tanaka, F. and Yamamura, M.
\newblock Multitask reinforcement learning on the distribution of {MDPs}.
\newblock In \emph{Proceedings 2003 IEEE International Symposium on
  Computational Intelligence in Robotics and Automation. Computational
  Intelligence in Robotics and Automation for the New Millennium (Cat. No.
  03EX694)}, volume~3, pp.\  1108--1113. IEEE, 2003.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, de~Las~Casas,
  Budden, Abdolmaleki, Merel, Lefrancq, Lillicrap, and Riedmiller]{dmc}
Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., de~Las~Casas, D., Budden,
  D., Abdolmaleki, A., Merel, J., Lefrancq, A., Lillicrap, T.~P., and
  Riedmiller, M.~A.
\newblock Deepmind control suite.
\newblock \emph{CoRR}, abs/1801.00690, 2018.
\newblock URL \url{http://arxiv.org/abs/1801.00690}.

\bibitem[Teh et~al.(2017)Teh, Bapst, Czarnecki, Quan, Kirkpatrick, Hadsell,
  Heess, and Pascanu]{distral}
Teh, Y., Bapst, V., Czarnecki, W.~M., Quan, J., Kirkpatrick, J., Hadsell, R.,
  Heess, N., and Pascanu, R.
\newblock Distral: Robust multitask reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4496--4506, 2017.

\bibitem[Tellex et~al.(2011)Tellex, Kollar, Dickerson, Walter, Banerjee,
  Teller, and
  Roy]{understanding_natural_language_commands_for_robotic_navigation_and_mobile_manipulation}
Tellex, S., Kollar, T., Dickerson, S., Walter, M., Banerjee, A., Teller, S.,
  and Roy, N.
\newblock Understanding natural language commands for robotic navigation and
  mobile manipulation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~25, 2011.

\bibitem[Vithayathil~Varghese \& Mahmoud(2020)Vithayathil~Varghese and
  Mahmoud]{electronics9091363}
Vithayathil~Varghese, N. and Mahmoud, Q.~H.
\newblock A survey of multi-task deep reinforcement learning.
\newblock \emph{Electronics}, 9\penalty0 (9), 2020.
\newblock ISSN 2079-9292.
\newblock \doi{10.3390/electronics9091363}.
\newblock URL \url{https://www.mdpi.com/2079-9292/9/9/1363}.

\bibitem[Williams et~al.(2018)Williams, Gopalan, Rhee, and
  Tellex]{learning_to_parse_natural_language_to_grounded_reward_functions_with_weak_supervision}
Williams, E.~C., Gopalan, N., Rhee, M., and Tellex, S.
\newblock Learning to parse natural language to grounded reward functions with
  weak supervision.
\newblock In \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  1--7. IEEE, 2018.

\bibitem[Yadan(2019)]{Yadan2019Hydra}
Yadan, O.
\newblock Hydra - a framework for elegantly configuring complex applications.
\newblock Github, 2019.
\newblock URL \url{https://github.com/facebookresearch/hydra}.

\bibitem[Yang et~al.(2020)Yang, Xu, Wu, and
  Wang]{multi_task_reinforcement_learning_with_soft_modularization}
Yang, R., Xu, H., Wu, Y., and Wang, X.
\newblock Multi-task reinforcement learning with soft modularization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[You et~al.(2016)You, Wu, Luo, and
  Hu]{Mmtadata_based_clustered_multitask_learning_for_thread_mining_in_web_communities}
You, Q., Wu, O., Luo, G., and Hu, W.
\newblock Metadata-based clustered multi-task learning for thread mining in web
  communities.
\newblock In \emph{International Conference on Machine Learning and Data Mining
  in Pattern Recognition}, pp.\  421--434. Springer, 2016.

\bibitem[Yu et~al.(2020{\natexlab{a}})Yu, Kumar, Gupta, Levine, Hausman, and
  Finn]{gradient_surgery_for_multitask_learning}
Yu, T., Kumar, S., Gupta, A., Levine, S., Hausman, K., and Finn, C.
\newblock Gradient surgery for multi-task learning.
\newblock \emph{arXiv preprint arXiv:2001.06782}, 2020{\natexlab{a}}.

\bibitem[Yu et~al.(2020{\natexlab{b}})Yu, Quillen, He, Julian, Hausman, Finn,
  and Levine]{meta-world}
Yu, T., Quillen, D., He, Z., Julian, R., Hausman, K., Finn, C., and Levine, S.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  1094--1100,
  2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2019)Zhang, Lipton, Pineda, Azizzadenesheli, Anandkumar,
  Itti, Pineau, and Furlanello]{zhang2019causal_states}
Zhang, A., Lipton, Z.~C., Pineda, L., Azizzadenesheli, K., Anandkumar, A.,
  Itti, L., Pineau, J., and Furlanello, T.
\newblock Learning causal state representations of partially observable
  environments, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Lyle, Sodhani, Filos, Kwiatkowska, Pineau,
  Gal, and Precup]{zhang2020invariant}
Zhang, A., Lyle, C., Sodhani, S., Filos, A., Kwiatkowska, M., Pineau, J., Gal,
  Y., and Precup, D.
\newblock Invariant causal prediction for block {MDP}s.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Zhang et~al.(2021)Zhang, Sodhani, Khetarpal, and
  Pineau]{zhang2020hipbmdp}
Zhang, A., Sodhani, S., Khetarpal, K., and Pineau, J.
\newblock Learning robust state abstractions for hidden-parameter block {MDP}s.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Zhang et~al.(2014)Zhang, Luo, Loy, and
  Tang]{zhang2014facial_landmark_detection_by_deep_multitask_learning}
Zhang, Z., Luo, P., Loy, C.~C., and Tang, X.
\newblock Facial landmark detection by deep multi-task learning.
\newblock In \emph{European conference on computer vision}, pp.\  94--108.
  Springer, 2014.

\bibitem[Zheng et~al.(2019)Zheng, Wang, Dai, Zheng, and
  Wang]{zheng2019metadata}
Zheng, Z., Wang, Y., Dai, Q., Zheng, H., and Wang, D.
\newblock Metadata-driven task relation discovery for multi-task learning.
\newblock In \emph{Proceedings of the Twenty-Eighth International Joint
  Conference on Artificial Intelligence, {IJCAI-19}}, pp.\  4426--4432.
  International Joint Conferences on Artificial Intelligence Organization, 7
  2019.
\newblock \doi{10.24963/ijcai.2019/615}.
\newblock URL \url{https://doi.org/10.24963/ijcai.2019/615}.

\bibitem[Zhong et~al.(2020)Zhong, Rocktäschel, and Grefenstette]{rtfm}
Zhong, V., Rocktäschel, T., and Grefenstette, E.
\newblock Rtfm: Generalising to new environment dynamics via reading.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SJgob6NKvH}.

\end{thebibliography}
