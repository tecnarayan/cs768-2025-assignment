\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barni et~al.(2019)Barni, Kallas, and Tondi]{barni2019new}
Mauro Barni, Kassem Kallas, and Benedetta Tondi.
\newblock A new backdoor attack in cnns by training set corruption without
  label poisoning.
\newblock In \emph{2019 IEEE International Conference on Image Processing
  (ICIP)}, pages 101--105. IEEE, 2019.

\bibitem[Carlini and Terzis(2021)]{carlini2021poisoning}
Nicholas Carlini and Andreas Terzis.
\newblock Poisoning and backdooring contrastive learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Carlini and Terzis(2022)]{carlini2022poisoning}
Nicholas Carlini and Andreas Terzis.
\newblock Poisoning and backdooring contrastive learning.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=iC4UHbQ01Mp}.

\bibitem[Carlini et~al.(2023)Carlini, Jagielski, Choquette-Choo, Paleka,
  Pearce, Anderson, Terzis, Thomas, and Tram{\`e}r]{carlini2023poisoning}
Nicholas Carlini, Matthew Jagielski, Christopher~A Choquette-Choo, Daniel
  Paleka, Will Pearce, Hyrum Anderson, Andreas Terzis, Kurt Thomas, and Florian
  Tram{\`e}r.
\newblock Poisoning web-scale training datasets is practical.
\newblock \emph{arXiv preprint arXiv:2302.10149}, 2023.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem[Chen et~al.(2017)Chen, Liu, Li, Lu, and Song]{chen2017targeted}
Xinyun Chen, Chang Liu, Bo~Li, Kimberly Lu, and Dawn Song.
\newblock Targeted backdoor attacks on deep learning systems using data
  poisoning.
\newblock \emph{arXiv preprint arXiv:1712.05526}, 2017.

\bibitem[Chen et~al.(2023)Chen, Huang, Zhou, Bian, Han, and
  Cheng]{chen2023towards}
Yongqiang Chen, Wei Huang, Kaiwen Zhou, Yatao Bian, Bo~Han, and James Cheng.
\newblock Towards understanding feature learning in out-of-distribution
  generalization.
\newblock \emph{arXiv preprint arXiv:2304.11327}, 2023.

\bibitem[Chrabaszcz et~al.(2017)Chrabaszcz, Loshchilov, and
  Hutter]{chrabaszcz2017downsampled}
Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter.
\newblock A downsampled variant of imagenet as an alternative to the cifar
  datasets.
\newblock \emph{arXiv preprint arXiv:1707.08819}, 2017.

\bibitem[Goldblum et~al.(2022)Goldblum, Tsipras, Xie, Chen, Schwarzschild,
  Song, Madry, Li, and Goldstein]{goldblum2022dataset}
Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild,
  Dawn Song, Aleksander Madry, Bo~Li, and Tom Goldstein.
\newblock Dataset security for machine learning: Data poisoning, backdoor
  attacks, and defenses.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2022.

\bibitem[Gu et~al.(2019)Gu, Liu, Dolan-Gavitt, and Garg]{gu2019badnets}
Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Badnets: Evaluating backdooring attacks on deep neural networks.
\newblock \emph{IEEE Access}, 7:\penalty0 47230--47244, 2019.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He_2016_CVPR}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708, 2017.

\bibitem[Huang et~al.(2022)Huang, Li, Wu, Qin, and Ren]{huang2022backdoor}
Kunzhe Huang, Yiming Li, Baoyuan Wu, Zhan Qin, and Kui Ren.
\newblock Backdoor defense via decoupling the training process.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=TySnJ-0RdKI}.

\bibitem[Karim et~al.()Karim, Al~Arafat, Khalid, Guo, and
  Rahnavard]{karimsearch}
Nazmul Karim, Abdullah Al~Arafat, Umar Khalid, Zhishan Guo, and Nazanin
  Rahnavard.
\newblock In search of smooth minima for purifying backdoor in deep neural
  networks.

\bibitem[Krizhevsky et~al.(2009)]{krizhevsky2009learning}
Alex Krizhevsky et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and
  Liang]{kumar2022finetuning}
Ananya Kumar, Aditi Raghunathan, Robbie~Matthew Jones, Tengyu Ma, and Percy
  Liang.
\newblock Fine-tuning can distort pretrained features and underperform
  out-of-distribution.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=UYneFzXSJWh}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Lyu, Koren, Lyu, Li, and
  Ma]{li2021anti}
Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo~Li, and Xingjun Ma.
\newblock Anti-backdoor learning: Training clean models on poisoned data.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 14900--14912, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Li, Wu, Li, He, and
  Lyu]{li2021invisible}
Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, and Siwei Lyu.
\newblock Invisible backdoor attack with sample-specific triggers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 16463--16472, 2021{\natexlab{b}}.

\bibitem[Lin et~al.(2023)Lin, Tan, Hao, Wong, Dong, Zhang, Yang, and
  Zhang]{lin2023spurious}
Yong Lin, Lu~Tan, Yifan Hao, Honam Wong, Hanze Dong, Weizhong Zhang, Yujiu
  Yang, and Tong Zhang.
\newblock Spurious feature diversification improves out-of-distribution
  generalization.
\newblock \emph{arXiv preprint arXiv:2309.17230}, 2023.

\bibitem[Liu et~al.(2018)Liu, Dolan-Gavitt, and Garg]{liu2018fine}
Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Fine-pruning: Defending against backdooring attacks on deep neural
  networks.
\newblock In \emph{International Symposium on Research in Attacks, Intrusions,
  and Defenses}, pages 273--294. Springer, 2018.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 10012--10022, 2021.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{miller2021accuracy}
John~P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang~Wei Koh,
  Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt.
\newblock Accuracy on the line: on the strong correlation between
  out-of-distribution and in-distribution generalization.
\newblock In \emph{International Conference on Machine Learning}, pages
  7721--7735. PMLR, 2021.

\bibitem[Nguyen and Tran(2020)]{nguyen2020input}
Tuan~Anh Nguyen and Anh Tran.
\newblock Input-aware dynamic backdoor attack.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 3454--3464, 2020.

\bibitem[Nguyen and Tran(2021)]{nguyen2021wanet}
Tuan~Anh Nguyen and Anh~Tuan Tran.
\newblock Wanet - imperceptible warping-based backdoor attack.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=eEn8KTtJOx}.

\bibitem[Pham et~al.(2021)Pham, Dai, Ghiasi, Liu, Yu, Luong, Tan, and
  Le]{pham2021combined}
Hieu Pham, Zihang Dai, Golnaz Ghiasi, Hanxiao Liu, Adams~Wei Yu, Minh-Thang
  Luong, Mingxing Tan, and Quoc~V Le.
\newblock Combined scaling for zero-shot transfer learning.
\newblock \emph{arXiv preprint arXiv:2111.10050}, 2021.

\bibitem[Qi et~al.(2023)Qi, Xie, Li, Mahloujifar, and Mittal]{qi2023revisiting}
Xiangyu Qi, Tinghao Xie, Yiming Li, Saeed Mahloujifar, and Prateek Mittal.
\newblock Revisiting the assumption of latent separability for backdoor
  defenses.
\newblock In \emph{The eleventh international conference on learning
  representations}, 2023.

\bibitem[Qin et~al.(2023)Qin, Yao, Chen, Li, Ding, and
  Cheng]{qin2023revisiting}
Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, and Minhao Cheng.
\newblock Revisiting personalized federated learning: Robustness against
  backdoor attacks.
\newblock In \emph{Proceedings of the 29th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining}, KDD '23, page 4743â€“4755, New York, NY, USA,
  2023. Association for Computing Machinery.
\newblock ISBN 9798400701030.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Shejwalkar et~al.(2022)Shejwalkar, Houmansadr, Kairouz, and
  Ramage]{shejwalkar2022back}
Virat Shejwalkar, Amir Houmansadr, Peter Kairouz, and Daniel Ramage.
\newblock Back to the drawing board: A critical evaluation of poisoning attacks
  on production federated learning.
\newblock In \emph{2022 IEEE Symposium on Security and Privacy (SP)}, pages
  1354--1371. IEEE, 2022.

\bibitem[Shokri et~al.(2020)]{shokri2020bypassing}
Reza Shokri et~al.
\newblock Bypassing backdoor detection algorithms in deep learning.
\newblock In \emph{2020 IEEE European Symposium on Security and Privacy
  (EuroS\&P)}, pages 175--183. IEEE, 2020.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Stallkamp et~al.(2012)Stallkamp, Schlipsing, Salmen, and
  Igel]{stallkamp2012man}
Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel.
\newblock Man vs. computer: Benchmarking machine learning algorithms for
  traffic sign recognition.
\newblock \emph{Neural networks}, 32:\penalty0 323--332, 2012.

\bibitem[Turner et~al.(2019)Turner, Tsipras, and Madry]{turner2019label}
Alexander Turner, Dimitris Tsipras, and Aleksander Madry.
\newblock Label-consistent backdoor attacks.
\newblock \emph{arXiv preprint arXiv:1912.02771}, 2019.

\bibitem[Wang et~al.(2019)Wang, Yao, Shan, Li, Viswanath, Zheng, and
  Zhao]{wang2019neural}
Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao
  Zheng, and Ben~Y Zhao.
\newblock Neural cleanse: Identifying and mitigating backdoor attacks in neural
  networks.
\newblock In \emph{2019 IEEE Symposium on Security and Privacy (SP)}, pages
  707--723. IEEE, 2019.

\bibitem[Wei et~al.(2022)Wei, Bosma, Zhao, Guu, Yu, Lester, Du, Dai, and
  Le]{wei2022finetuned}
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams~Wei Yu, Brian Lester,
  Nan Du, Andrew~M. Dai, and Quoc~V Le.
\newblock Finetuned language models are zero-shot learners.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=gEZrGCozdqR}.

\bibitem[Wu et~al.(2022)Wu, Chen, Zhang, Zhu, Wei, Yuan, and
  Shen]{wu2022backdoorbench}
Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, and
  Chao Shen.
\newblock Backdoorbench: A comprehensive benchmark of backdoor learning.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}, 2022.

\bibitem[Wu and Wang(2021)]{wu2021adversarial}
Dongxian Wu and Yisen Wang.
\newblock Adversarial neuron pruning purifies backdoored deep models.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 16913--16925, 2021.

\bibitem[Zeng et~al.(2022)Zeng, Chen, Park, Mao, Jin, and
  Jia]{zeng2022adversarial}
Yi~Zeng, Si~Chen, Won Park, Zhuoqing Mao, Ming Jin, and Ruoxi Jia.
\newblock Adversarial unlearning of backdoors via implicit hypergradient.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=MeeQkFYVbzW}.

\bibitem[Zhang and Bottou(2023)]{zhang2023learning}
Jianyu Zhang and L{\'e}on Bottou.
\newblock Learning useful representations for shifting tasks and distributions.
\newblock In \emph{International Conference on Machine Learning}, pages
  40830--40850. PMLR, 2023.

\bibitem[Zhang et~al.(2022)Zhang, Shen, Ding, Tao, and Duan]{zhang2022fine}
Lin Zhang, Li~Shen, Liang Ding, Dacheng Tao, and Ling-Yu Duan.
\newblock Fine-tuning global model via data-free knowledge distillation for
  non-iid federated learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10174--10183, 2022.

\bibitem[Zheng et~al.(2022)Zheng, Tang, Li, and Liu]{zheng2022data}
Runkai Zheng, Rongjun Tang, Jianze Li, and Li~Liu.
\newblock Data-free backdoor removal based on channel lipschitzness.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part V}, pages 175--191.
  Springer, 2022.

\bibitem[Zhu et~al.(2023)Zhu, Wei, Shen, Fan, and Wu]{zhu2023enhancing}
Mingli Zhu, Shaokui Wei, Li~Shen, Yanbo Fan, and Baoyuan Wu.
\newblock Enhancing fine-tuning based backdoor defense with sharpness-aware
  minimization.
\newblock \emph{arXiv preprint arXiv:2304.11823}, 2023.

\end{thebibliography}
