@inproceedings{yang2024lemon,
  title={LEMON: Learning 3D Human-Object Interaction Relation from 2D Images},
  author={Yang, Yuhang and Zhai, Wei and Luo, Hongchen and Cao, Yang and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16284--16295},
  year={2024}
}

@inproceedings{sudhakaran2019lsta,
  title={Lsta: Long short-term attention for egocentric action recognition},
  author={Sudhakaran, Swathikiran and Escalera, Sergio and Lanz, Oswald},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9954--9963},
  year={2019}
}

@inproceedings{wang2021interactive,
  title={Interactive prototype learning for egocentric action recognition},
  author={Wang, Xiaohan and Zhu, Linchao and Wang, Heng and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8168--8177},
  year={2021}
}

@inproceedings{kazakos2019epic,
  title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5492--5501},
  year={2019}
}

@misc{peirone2024backpack,
    title={A Backpack Full of Skills: Egocentric Video Understanding with Diverse Task Perspectives}, 
    author={Simone Alberto Peirone and Francesca Pistilli and Antonio Alliegro and Giuseppe Averta},
    year={2024},
    eprint={2403.03037},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{wu2020learning,
  title={Learning to anticipate egocentric actions by imagination},
  author={Wu, Yu and Zhu, Linchao and Wang, Xiaohan and Yang, Yi and Wu, Fei},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={1143--1152},
  year={2020},
  publisher={IEEE}
}

@inproceedings{mascaro2023intention,
  title={Intention-conditioned long-term human egocentric action anticipation},
  author={Mascar{\'o}, Esteve Valls and Ahn, Hyemin and Lee, Dongheui},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6048--6057},
  year={2023}
}

@inproceedings{roy2024interaction,
  title={Interaction Region Visual Transformer for Egocentric Action Anticipation},
  author={Roy, Debaditya and Rajendiran, Ramanathan and Fernando, Basura},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6740--6750},
  year={2024}
}

@inproceedings{ego-topo,
    author = {Nagarajan, Tushar and Li, Yanghao and Feichtenhofer, Christoph and Grauman, Kristen},
    title = {EGO-TOPO: Environment Affordances from Egocentric Video},
    booktitle = {CVPR},
    year = {2020}
}

@inproceedings{lee2019hands,
  title={Hands holding clues for object recognition in teachable machines},
  author={Lee, Kyungjun and Kacorri, Hernisa},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--12},
  year={2019}
}

@inproceedings{yu2023fine,
  title={Fine-grained affordance annotation for egocentric hand-object interaction videos},
  author={Yu, Zecheng and Huang, Yifei and Furuta, Ryosuke and Yagi, Takuma and Goutsu, Yusuke and Sato, Yoichi},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2155--2163},
  year={2023}
}

@article{lu2022phrase,
  title={Phrase-based affordance detection via cyclic bilateral interaction},
  author={Lu, Liangsheng and Zhai, Wei and Luo, Hongchen and Kang, Yu and Cao, Yang},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2022},
  publisher={IEEE}
}

@inproceedings{luo2022learning,
  title={Learning affordance grounding from exocentric images},
  author={Luo, Hongchen and Zhai, Wei and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2252--2261},
  year={2022}
}

@article{luo2023grounded,
  title={Grounded affordance from exocentric view},
  author={Luo, Hongchen and Zhai, Wei and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  pages={1--25},
  year={2023},
  publisher={Springer}
}

@inproceedings{akiva2023self,
  title={Self-Supervised Object Detection from Egocentric Videos},
  author={Akiva, Peri and Huang, Jing and Liang, Kevin J and Kovvuri, Rama and Chen, Xingyu and Feiszli, Matt and Dana, Kristin and Hassner, Tal},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5225--5237},
  year={2023}
}

@inproceedings{zhu2023egoobjects,
  title={Egoobjects: A large-scale egocentric dataset for fine-grained object understanding},
  author={Zhu, Chenchen and Xiao, Fanyi and Alvarado, Andr{\'e}s and Babaei, Yasmine and Hu, Jiabo and El-Mohri, Hichem and Culatana, Sean and Sumbaly, Roshan and Yan, Zhicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20110--20120},
  year={2023}
}

@inproceedings{bambach2015lending,
  title={Lending a hand: Detecting hands and recognizing activities in complex egocentric interactions},
  author={Bambach, Sven and Lee, Stefan and Crandall, David J and Yu, Chen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1949--1957},
  year={2015}
}

@article{lin2020ego2hands,
  title={Ego2hands: A dataset for egocentric two-hand segmentation and detection},
  author={Lin, Fanqing and Price, Brian and Martinez, Tony},
  journal={arXiv preprint arXiv:2011.07252},
  year={2020}
}

@inproceedings{mur2023multi,
  title={Multi-label affordance mapping from egocentric vision},
  author={Mur-Labadia, Lorenzo and Guerrero, Jose J and Martinez-Cantin, Ruben},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5238--5249},
  year={2023}
}

@inproceedings{deng20213d,
  title={3d affordancenet: A benchmark for visual object affordance understanding},
  author={Deng, Shengheng and Xu, Xun and Wu, Chaozheng and Chen, Ke and Jia, Kui},
  booktitle={proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1778--1787},
  year={2021}
}

@book{gibson2014ecological,
  title={The ecological approach to visual perception: classic edition},
  author={Gibson, James J},
  year={2014},
  publisher={Psychology press}
}

@inproceedings{tripathi2023deco,
  title={DECO: Dense estimation of 3D human-scene contact in the wild},
  author={Tripathi, Shashank and Chatterjee, Agniv and Passy, Jean-Claude and Yi, Hongwei and Tzionas, Dimitrios and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8001--8013},
  year={2023}
}

@inproceedings{yang2023grounding,
  title={Grounding 3d object affordance from 2d interactions in images},
  author={Yang, Yuhang and Zhai, Wei and Luo, Hongchen and Cao, Yang and Luo, Jiebo and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10905--10915},
  year={2023}
}

@inproceedings{huang2022capturing,
  title={Capturing and inferring dense full-body human-scene contact},
  author={Huang, Chun-Hao P and Yi, Hongwei and H{\"o}schle, Markus and Safroshkin, Matvey and Alexiadis, Tsvetelina and Polikovsky, Senya and Scharstein, Daniel and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13274--13285},
  year={2022}
}

@article{xu2022partafford,
  title={Partafford: Part-level affordance discovery from 3d objects},
  author={Xu, Chao and Chen, Yixin and Wang, He and Zhu, Song-Chun and Zhu, Yixin and Huang, Siyuan},
  journal={arXiv preprint arXiv:2202.13519},
  year={2022}
}

@inproceedings{mo2022o2o,
  title={O2O-Afford: Annotation-free large-scale object-object affordance learning},
  author={Mo, Kaichun and Qin, Yuzhe and Xiang, Fanbo and Su, Hao and Guibas, Leonidas},
  booktitle={Conference on robot learning},
  pages={1666--1677},
  year={2022},
  organization={PMLR}
}

@inproceedings{mo2021where2act,
  title={Where2act: From pixels to actions for articulated 3d objects},
  author={Mo, Kaichun and Guibas, Leonidas J and Mukadam, Mustafa and Gupta, Abhinav and Tulsiani, Shubham},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6813--6823},
  year={2021}
}

@article{zhao2022dualafford,
  title={Dualafford: Learning collaborative visual affordance for dual-gripper manipulation},
  author={Zhao, Yan and Wu, Ruihai and Chen, Zhehuan and Zhang, Yourong and Fan, Qingnan and Mo, Kaichun and Dong, Hao},
  journal={arXiv preprint arXiv:2207.01971},
  year={2022}
}

@inproceedings{shimada2022hulc,
  title={Hulc: 3d human motion capture with pose manifold sampling and dense contact guidance},
  author={Shimada, Soshi and Golyanik, Vladislav and Li, Zhi and P{\'e}rez, Patrick and Xu, Weipeng and Theobalt, Christian},
  booktitle={European Conference on Computer Vision},
  pages={516--533},
  year={2022},
  organization={Springer}
}

@inproceedings{hassan2021populating,
  title={Populating 3D scenes by learning human-scene interaction},
  author={Hassan, Mohamed and Ghosh, Partha and Tesch, Joachim and Tzionas, Dimitrios and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14708--14718},
  year={2021}
}

@article{grauman2023ego,
  title={Ego-exo4d: Understanding skilled human activity from first-and third-person perspectives},
  author={Grauman, Kristen and Westbury, Andrew and Torresani, Lorenzo and Kitani, Kris and Malik, Jitendra and Afouras, Triantafyllos and Ashutosh, Kumar and Baiyya, Vijay and Bansal, Siddhant and Boote, Bikram and others},
  journal={arXiv preprint arXiv:2311.18259},
  year={2023}
}

@inproceedings{zheng2022gimo,
  title={Gimo: Gaze-informed human motion prediction in context},
  author={Zheng, Yang and Yang, Yanchao and Mo, Kaichun and Li, Jiaman and Yu, Tao and Liu, Yebin and Liu, C Karen and Guibas, Leonidas J},
  booktitle={European Conference on Computer Vision},
  pages={676--694},
  year={2022},
  organization={Springer}
}

@inproceedings{SMPL-X:2019,
  title = {Expressive Body Capture: {3D} Hands, Face, and Body from a Single Image},
  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {10975--10985},
  year = {2019}
}

@inproceedings{deitke2023objaverse,
  title={Objaverse: A universe of annotated 3d objects},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13142--13153},
  year={2023}
}

@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}

@inproceedings{uy2019revisiting,
  title={Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data},
  author={Uy, Mikaela Angelina and Pham, Quang-Hieu and Hua, Binh-Son and Nguyen, Thanh and Yeung, Sai-Kit},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1588--1597},
  year={2019}
}

@inproceedings{liu2022akb,
  title={Akb-48: A real-world articulated object knowledge base},
  author={Liu, Liu and Xu, Wenqiang and Fu, Haoyuan and Qian, Sucheng and Yu, Qiaojun and Han, Yang and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14809--14818},
  year={2022}
}

@inproceedings{wu2023omniobject3d,
  title={Omniobject3d: Large-vocabulary 3d object dataset for realistic perception, reconstruction and generation},
  author={Wu, Tong and Zhang, Jiarui and Fu, Xiao and Wang, Yuxin and Ren, Jiawei and Pan, Liang and Wu, Wayne and Yang, Lei and Wang, Jiaqi and Qian, Chen and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={803--814},
  year={2023}
}

@inproceedings{fang2018demo2vec,
  title={Demo2vec: Reasoning object affordances from online videos},
  author={Fang, Kuan and Wu, Te-Lin and Yang, Daniel and Savarese, Silvio and Lim, Joseph J},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2139--2147},
  year={2018}
}

@article{geng2022gapartnet,
  title={GAPartNet: Cross-Category Domain-Generalizable Object Perception and Manipulation via Generalizable and Actionable Parts},
  author={Geng, Haoran and Xu, Helin and Zhao, Chengyang and Xu, Chao and Yi, Li and Huang, Siyuan and Wang, He},
  journal={arXiv preprint arXiv:2211.05272},
  year={2022}
}

@inproceedings{wang2022adaafford,
  title={Adaafford: Learning to adapt manipulation affordance for 3d articulated objects via few-shot interactions},
  author={Wang, Yian and Wu, Ruihai and Mo, Kaichun and Ke, Jiaqi and Fan, Qingnan and Guibas, Leonidas J and Dong, Hao},
  booktitle={European conference on computer vision},
  pages={90--107},
  year={2022},
  organization={Springer}
}

@inproceedings{nagarajan2019grounded,
  title={Grounded human-object interaction hotspots from video},
  author={Nagarajan, Tushar and Feichtenhofer, Christoph and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8688--8697},
  year={2019}
}

@inproceedings{liu2022egocentric,
  title={Egocentric activity recognition and localization on a 3d map},
  author={Liu, Miao and Ma, Lingni and Somasundaram, Kiran and Li, Yin and Grauman, Kristen and Rehg, James M and Li, Chao},
  booktitle={European Conference on Computer Vision},
  pages={621--638},
  year={2022},
  organization={Springer}
}

@article{xue2023learning,
  title={Learning Object State Changes in Videos: An Open-World Perspective},
  author={Xue, Zihui and Ashutosh, Kumar and Grauman, Kristen},
  journal={arXiv preprint arXiv:2312.11782},
  year={2023}
}

@article{nagarajan2024egoenv,
  title={EgoEnv: Human-centric environment representations from egocentric video},
  author={Nagarajan, Tushar and Ramakrishnan, Santhosh Kumar and Desai, Ruta and Hillis, James and Grauman, Kristen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2023embodiedscan,
  title={EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI},
  author={Wang, Tai and Mao, Xiaohan and Zhu, Chenming and Xu, Runsen and Lyu, Ruiyuan and Li, Peisen and Chen, Xiao and Zhang, Wenwei and Chen, Kai and Xue, Tianfan and others},
  journal={arXiv preprint arXiv:2312.16170},
  year={2023}
}

@inproceedings{li2024egogen, 
 title={{EgoGen: An Egocentric Synthetic Data Generator}}, 
 author={Li, Gen and Zhao, Kaifeng and Zhang, Siwei and Lyu, Xiaozhong and Dusmanu, Mihai and Zhang, Yan and Pollefeys, Marc and Tang, Siyu}, 
 booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
 year={2024} 
}

@inproceedings{delitzas2024scenefun3d,
  title={Scenefun3d: Fine-grained functionality and affordance understanding in 3d scenes},
  author={Delitzas, Alexandros and Takmaz, Ayca and Tombari, Federico and Sumner, Robert and Pollefeys, Marc and Engelmann, Francis},
  booktitle={Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{nagarajan2020ego,
  title={Ego-topo: Environment affordances from egocentric video},
  author={Nagarajan, Tushar and Li, Yanghao and Feichtenhofer, Christoph and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={163--172},
  year={2020}
}

@article{garg2023visually,
  title={Visually-Guided Audio Spatialization in Video with Geometry-Aware Multi-task Learning},
  author={Garg, Rishabh and Gao, Ruohan and Grauman, Kristen},
  journal={International Journal of Computer Vision},
  volume={131},
  number={10},
  pages={2723--2737},
  year={2023},
  publisher={Springer}
}

@inproceedings{chen2022visual,
  title={Visual acoustic matching},
  author={Chen, Changan and Gao, Ruohan and Calamia, Paul and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18858--18868},
  year={2022}
}

@article{somayazulu2024self,
  title={Self-Supervised Visual Acoustic Matching},
  author={Somayazulu, Arjun and Chen, Changan and Grauman, Kristen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2022soundspaces,
  title={Soundspaces 2.0: A simulation platform for visual-acoustic learning},
  author={Chen, Changan and Schissler, Carl and Garg, Sanchit and Kobernik, Philip and Clegg, Alexander and Calamia, Paul and Batra, Dhruv and Robinson, Philip and Grauman, Kristen},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8896--8911},
  year={2022}
}

@inproceedings{xue2023egocentric,
  title={Egocentric video task translation},
  author={Xue, Zihui and Song, Yale and Grauman, Kristen and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2310--2320},
  year={2023}
}

@inproceedings{li2019putting,
  title={Putting humans in a scene: Learning affordance in 3d indoor environments},
  author={Li, Xueting and Liu, Sifei and Kim, Kihwan and Wang, Xiaolong and Yang, Ming-Hsuan and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12368--12376},
  year={2019}
}

@article{wan2023unidexgrasp++,
  title={UniDexGrasp++: Improving Dexterous Grasping Policy Learning via Geometry-aware Curriculum and Iterative Generalist-Specialist Learning},
  author={Wan, Weikang and Geng, Haoran and Liu, Yun and Shan, Zikang and Yang, Yaodong and Yi, Li and Wang, He},
  journal={arXiv preprint arXiv:2304.00464},
  year={2023} 
}

@article{luo2022embodied,
  title={Embodied scene-aware human pose estimation},
  author={Luo, Zhengyi and Iwase, Shun and Yuan, Ye and Kitani, Kris},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={6815--6828},
  year={2022}
}

@inproceedings{zhao2023synthesizing,
  title={Synthesizing diverse human motions in 3d indoor scenes},
  author={Zhao, Kaifeng and Zhang, Yan and Wang, Shaofei and Beeler, Thabo and Tang, Siyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14738--14749},
  year={2023}
}

@article{li2023object,
  title={Object Motion Guided Human Motion Synthesis},
  author={Li, Jiaman and Wu, Jiajun and Liu, C Karen},
  journal={ACM Trans. Graph.},
  volume={42},
  number={6},
  year={2023}
}

@inproceedings{zhu2023diff,
  title={Diff-lfd: Contact-aware model-based learning from visual demonstration for robotic manipulation via differentiable physics-based simulation and rendering},
  author={Zhu, Xinghao and Ke, JingHan and Xu, Zhixuan and Sun, Zhixin and Bai, Bizhe and Lv, Jun and Liu, Qingtao and Zeng, Yuwei and Ye, Qi and Lu, Cewu and others},
  booktitle={Conference on Robot Learning},
  pages={499--512},
  year={2023},
  organization={PMLR}
}

@article{wang2023find,
  title={Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation},
  author={Wang, Hongcheng and Chen, Andy Guan Hong and Li, Xiaoqi and Wu, Mingdong and Dong, Hao},
  journal={Advances in Neural Information Processing Systems },
  year={2023}
}

@inproceedings{
   xu2023interdiff,
   title={InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion},
   author={Xu, Sirui and Li, Zhengyuan and Wang, Yu-Xiong and Gui, Liang-Yan},
   booktitle={ICCV},
   year={2023},
}

@inproceedings{jia2021intentonomy,
  title={Intentonomy: a dataset and study towards human intent understanding},
  author={Jia, Menglin and Wu, Zuxuan and Reiter, Austin and Cardie, Claire and Belongie, Serge and Lim, Ser-Nam},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12986--12996},
  year={2021}
}

@article{lin2022egocentric,
  title={Egocentric video-language pretraining},
  author={Lin, Kevin Qinghong and Wang, Jinpeng and Soldan, Mattia and Wray, Michael and Yan, Rui and Xu, Eric Z and Gao, Difei and Tu, Rong-Cheng and Zhao, Wenzhe and Kong, Weijie and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7575--7586},
  year={2022}
}

@article{shao2023action,
  title={Action sensitivity learning for the ego4d episodic memory challenge 2023},
  author={Shao, Jiayi and Wang, Xiaohan and Quan, Ruijie and Yang, Yi},
  journal={arXiv preprint arXiv:2306.09172},
  year={2023}
}

@article{zeng2024unimd,
  title={UniMD: Towards Unifying Moment Retrieval and Temporal Action Detection},
  author={Zeng, Yingsen and Zhong, Yujie and Feng, Chengjian and Ma, Lin},
  journal={arXiv preprint arXiv:2404.04933},
  year={2024}
}

@inproceedings{zhang2022actionformer,
  title={Actionformer: Localizing moments of actions with transformers},
  author={Zhang, Chen-Lin and Wu, Jianxin and Li, Yin},
  booktitle={European Conference on Computer Vision},
  pages={492--510},
  year={2022},
  organization={Springer}
}

@article{chen2024soundingactions,
  title={SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos},
  author={Chen, Changan and Ashutosh, Kumar and Girdhar, Rohit and Harwath, David and Grauman, Kristen},
  journal={arXiv preprint arXiv:2404.05206},
  year={2024}
}

@article{pustejovsky2021embodied,
  title={Embodied human computer interaction},
  author={Pustejovsky, James and Krishnaswamy, Nikhil},
  journal={KI-K{\"u}nstliche Intelligenz},
  volume={35},
  number={3},
  pages={307--327},
  year={2021},
  publisher={Springer}
}

@inproceedings{wei2013modeling,
  title={Modeling 4d human-object interactions for event and object recognition},
  author={Wei, Ping and Zhao, Yibiao and Zheng, Nanning and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3272--3279},
  year={2013}
}

@inproceedings{yao2010modeling,
  title={Modeling mutual context of object and human pose in human-object interaction activities},
  author={Yao, Bangpeng and Fei-Fei, Li},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={17--24},
  year={2010},
  organization={IEEE}
}

@inproceedings{gkioxari2018detecting,
  title={Detecting and recognizing human-object interactions},
  author={Gkioxari, Georgia and Girshick, Ross and Doll{\'a}r, Piotr and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8359--8367},
  year={2018}
}

@inproceedings{chao2018learning,
  title={Learning to detect human-object interactions},
  author={Chao, Yu-Wei and Liu, Yunfan and Liu, Xieyang and Zeng, Huayi and Deng, Jia},
  booktitle={2018 ieee winter conference on applications of computer vision (wacv)},
  pages={381--389},
  year={2018},
  organization={IEEE}
}

@inproceedings{chen2023detecting,
  title={Detecting human-object contact in images},
  author={Chen, Yixin and Dwivedi, Sai Kumar and Black, Michael J and Tzionas, Dimitrios},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17100--17110},
  year={2023}
}

@article{duan2022survey,
  title={A survey of embodied ai: From simulators to research tasks},
  author={Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume={6},
  number={2},
  pages={230--244},
  year={2022},
  publisher={IEEE}
}

@inproceedings{savva2019habitat,
  title={Habitat: A platform for embodied ai research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9339--9347},
  year={2019}
}

@inproceedings{xie2022chore,
  title={Chore: Contact, human and object reconstruction from a single rgb image},
  author={Xie, Xianghui and Bhatnagar, Bharat Lal and Pons-Moll, Gerard},
  booktitle={European Conference on Computer Vision},
  pages={125--145},
  year={2022},
  organization={Springer}
}

@inproceedings{mandikal2021learning,
  title={Learning dexterous grasping with object-centric visual affordances},
  author={Mandikal, Priyanka and Grauman, Kristen},
  booktitle={2021 IEEE international conference on robotics and automation (ICRA)},
  pages={6169--6176},
  year={2021},
  organization={IEEE}
}

@article{narasimhaswamy2020detecting,
  title={Detecting hands and recognizing physical contact in the wild},
  author={Narasimhaswamy, Supreeth and Nguyen, Trung and Nguyen, Minh Hoai},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7841--7851},
  year={2020}
}

@article{nagarajan2021shaping,
  title={Shaping embodied agent behavior with activity-context priors from egocentric video},
  author={Nagarajan, Tushar and Grauman, Kristen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29794--29805},
  year={2021}
}

@article{kim2024zero,
  title={Zero-Shot Learning for the Primitives of 3D Affordance in General Objects},
  author={Kim, Hyeonwoo and Han, Sookwan and Kwon, Patrick and Joo, Hanbyul},
  journal={arXiv preprint arXiv:2401.12978},
  year={2024}
}

@inproceedings{yang2021cpf,
  title={Cpf: Learning a contact potential field to model the hand-object interaction},
  author={Yang, Lixin and Zhan, Xinyu and Li, Kailin and Xu, Wenqiang and Li, Jiefeng and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11097--11106},
  year={2021}
}

@inproceedings{zhao2023learning,
  title={Learning video representations from large language models},
  author={Zhao, Yue and Misra, Ishan and Kr{\"a}henb{\"u}hl, Philipp and Girdhar, Rohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6586--6597},
  year={2023}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@ARTICLE{Damen2021PAMI,
   title={The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines},
   author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and Fidler, Sanja and 
           Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
   year={2021},
   volume={43},
   number={11},
   pages={4125-4141},
   doi={10.1109/TPAMI.2020.2991965}
} 

@inproceedings{gberta_2021_ICML,
    author  = {Gedas Bertasius and Heng Wang and Lorenzo Torresani},
    title = {Is Space-Time Attention All You Need for Video Understanding?},
    booktitle   = {Proceedings of the International Conference on Machine Learning (ICML)}, 
    month = {July},
    year = {2021}
}

@inproceedings{li2023ego,
  title={Ego-body pose estimation via ego-head pose estimation},
  author={Li, Jiaman and Liu, Karen and Wu, Jiajun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17142--17151},
  year={2023}
}

@article{cuevas2024simpleego,
  title={SimpleEgo: Predicting Probabilistic Body Pose from Egocentric Cameras},
  author={Cuevas-Velasquez, Hanz and Hewitt, Charlie and Aliakbarian, Sadegh and Baltru{\v{s}}aitis, Tadas},
  journal={arXiv preprint arXiv:2401.14785},
  year={2024}
}

@article{wang2023egocentric,
  title={Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement},
  author={Wang, Jian and Cao, Zhe and Luvizon, Diogo and Liu, Lingjie and Sarkar, Kripasindhu and Tang, Danhang and Beeler, Thabo and Theobalt, Christian},
  journal={arXiv preprint arXiv:2311.16495},
  year={2023}
}

@article{SMPL:2015,
      author = {Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
      title = {{SMPL}: A Skinned Multi-Person Linear Model},
      journal = {ACM Trans. Graphics (Proc. SIGGRAPH Asia)},
      month = oct,
      number = {6},
      pages = {248:1--248:16},
      publisher = {ACM},
      volume = {34},
      year = {2015}
}

@article{shilling2004body,
  title={The body in culture, technology and society},
  author={Shilling, Chris},
  journal={The Body in Culture, Technology and Society},
  pages={1--256},
  year={2004},
  publisher={Sage}
}

@article{adolphs2003cognitive,
  title={Cognitive neuroscience of human social behaviour},
  author={Adolphs, Ralph},
  journal={Nature reviews neuroscience},
  volume={4},
  number={3},
  pages={165--178},
  year={2003},
  publisher={Nature Publishing Group UK London}
}

@book{gibbs2005embodiment,
  title={Embodiment and cognitive science},
  author={Gibbs Jr, Raymond W},
  year={2005},
  publisher={Cambridge University Press}
}

@book{varela2017embodied,
  title={The embodied mind, revised edition: Cognitive science and human experience},
  author={Varela, Francisco J and Thompson, Evan and Rosch, Eleanor},
  year={2017},
  publisher={MIT press}
}

@inproceedings{kanazawa2019learning,
  title={Learning 3d human dynamics from video},
  author={Kanazawa, Angjoo and Zhang, Jason Y and Felsen, Panna and Malik, Jitendra},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5614--5623},
  year={2019}
}

@inproceedings{kocabas2020vibe,
  title={Vibe: Video inference for human body pose and shape estimation},
  author={Kocabas, Muhammed and Athanasiou, Nikos and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5253--5263},
  year={2020}
}

@inproceedings{wan2021encoder,
  title={Encoder-decoder with multi-level attention for 3d human shape and pose estimation},
  author={Wan, Ziniu and Li, Zhengjia and Tian, Maoqing and Liu, Jianbo and Yi, Shuai and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13033--13042},
  year={2021}
}

@article{wang2020deep,
  title={Deep high-resolution representation learning for visual recognition},
  author={Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={10},
  pages={3349--3364},
  year={2020},
  publisher={IEEE}
}

@article{tan2023egodistill,
  title={Egodistill: Egocentric head motion distillation for efficient video understanding},
  author={Tan, Shuhan and Nagarajan, Tushar and Grauman, Kristen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={33485--33498},
  year={2023}
}

@article{wang2019dynamic,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={ACM Transactions on Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{peng2022balanced,
  title={Balanced multimodal learning via on-the-fly gradient modulation},
  author={Peng, Xiaokang and Wei, Yake and Deng, Andong and Wang, Dong and Hu, Di},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8238--8247},
  year={2022}
}

@article{fu2023multimodal,
  title={Multimodal Imbalance-Aware Gradient Modulation for Weakly-supervised Audio-Visual Video Parsing},
  author={Fu, Jie and Gao, Junyu and Bao, Bing-Kun and Xu, Changsheng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2023},
  publisher={IEEE}
}

@inproceedings{wang2020makes,
  title={What makes training multi-modal classification networks hard?},
  author={Wang, Weiyao and Tran, Du and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12695--12705},
  year={2020}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}

@inproceedings{milletari2016v,
  title={V-net: Fully convolutional neural networks for volumetric medical image segmentation},
  author={Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  booktitle={2016 fourth international conference on 3D vision (3DV)},
  pages={565--571},
  year={2016},
  organization={IEEE}
}

@article{guitchounts2020encoding,
  title={Encoding of 3D head orienting movements in the primary visual cortex},
  author={Guitchounts, Grigori and Mas{\'\i}s, Javier and Wolff, Steffen BE and Cox, David},
  journal={Neuron},
  volume={108},
  number={3},
  pages={512--525},
  year={2020},
  publisher={Elsevier}
}

@article{parker2020movement,
  title={Movement-related signals in sensory areas: roles in natural behavior},
  author={Parker, Philip RL and Brown, Morgan A and Smear, Matthew C and Niell, Cristopher M},
  journal={Trends in neurosciences},
  volume={43},
  number={8},
  pages={581--595},
  year={2020},
  publisher={Elsevier}
}

@article{nam2024joint,
  title={Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer},
  author={Nam, Hyeongjin and Jung, Daniel Sungho and Moon, Gyeongsik and Lee, Kyoung Mu},
  journal={arXiv preprint arXiv:2404.04819},
  year={2024}
}

@article{malle1997folk,
  title={The folk concept of intentionality},
  author={Malle, Bertram F and Knobe, Joshua},
  journal={Journal of experimental social psychology},
  volume={33},
  number={2},
  pages={101--121},
  year={1997},
  publisher={Elsevier}
}

@article{pelz2001coordination,
  title={The coordination of eye, head, and hand movements in a natural task},
  author={Pelz, Jeff and Hayhoe, Mary and Loeber, Russ},
  journal={Experimental brain research},
  volume={139},
  pages={266--277},
  year={2001},
  publisher={Springer}
}

@book{schilder2013image,
  title={The image and appearance of the human body},
  author={Schilder, Paul},
  year={2013},
  publisher={Routledge}
}

@article{slade1994body,
  title={What is body image?},
  author={Slade, Peter David},
  journal={Behaviour research and therapy},
  year={1994},
  publisher={Elsevier Science}
}

@software{meshlab,
  title        = {MeshLab},
  author       = {Paolo, Cignoni and Alessandro, Muntoni and Guido, Ranzuglia and Marco, Callieri},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.5114037}
}

@article{jiang2024scaling,
  title={Scaling up dynamic human-scene interaction modeling},
  author={Jiang, Nan and Zhang, Zhiyuan and Li, Hongjie and Ma, Xiaoxuan and Wang, Zan and Chen, Yixin and Liu, Tengyu and Zhu, Yixin and Huang, Siyuan},
  journal={arXiv preprint arXiv:2403.08629},
  year={2024}
}

@article{cai2024smpler,
  title={Smpler-x: Scaling up expressive human pose and shape estimation},
  author={Cai, Zhongang and Yin, Wanqi and Zeng, Ailing and Wei, Chen and Sun, Qingping and Yanjun, Wang and Pang, Hui En and Mei, Haiyi and Zhang, Mingyuan and Zhang, Lei and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lobo2008auc,
  title={AUC: a misleading measure of the performance of predictive distribution models},
  author={Lobo, Jorge M and Jim{\'e}nez-Valverde, Alberto and Real, Raimundo},
  journal={Global ecology and Biogeography},
  volume={17},
  number={2},
  pages={145--151},
  year={2008},
  publisher={Wiley Online Library}
}

@inproceedings{rahman2016optimizing,
  title={Optimizing intersection-over-union in deep neural networks for image segmentation},
  author={Rahman, Md Atiqur and Wang, Yang},
  booktitle={International symposium on visual computing},
  pages={234--244},
  year={2016},
  organization={Springer}
}

@article{swain1991color,
  title={Color indexing},
  author={Swain, Michael J and Ballard, Dana H},
  journal={International journal of computer vision},
  volume={7},
  number={1},
  pages={11--32},
  year={1991},
  publisher={Springer}
}

@inproceedings{cheng2021mask2former,
  title={Masked-attention Mask Transformer for Universal Image Segmentation},
  author={Bowen Cheng and Ishan Misra and Alexander G. Schwing and Alexander Kirillov and Rohit Girdhar},
  journal={CVPR},
  year={2022}
}

@article{ren2024grounded,
  title={Grounded sam: Assembling open-world models for diverse visual tasks},
  author={Ren, Tianhe and Liu, Shilong and Zeng, Ailing and Lin, Jing and Li, Kunchang and Cao, He and Chen, Jiayu and Huang, Xinyu and Chen, Yukang and Yan, Feng and others},
  journal={arXiv preprint arXiv:2401.14159},
  year={2024}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{cheng2013affordances,
  title={Affordances of augmented reality in science learning: Suggestions for future research},
  author={Cheng, Kun-Hung and Tsai, Chin-Chung},
  journal={Journal of science education and technology},
  volume={22},
  pages={449--462},
  year={2013},
  publisher={Springer}
}

@inproceedings{zhang2023probabilistic,
  title={Probabilistic human mesh recovery in 3d scenes from egocentric views},
  author={Zhang, Siwei and Ma, Qianli and Zhang, Yan and Aliakbarian, Sadegh and Cosker, Darren and Tang, Siyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7989--8000},
  year={2023}
}

@article{varol2017long,
  title={Long-term temporal convolutions for action recognition},
  author={Varol, G{\"u}l and Laptev, Ivan and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={6},
  pages={1510--1517},
  year={2017},
  publisher={IEEE}
}

@article{zhai2022one,
  title={One-shot object affordance detection in the wild},
  author={Zhai, Wei and Luo, Hongchen and Zhang, Jing and Cao, Yang and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={130},
  number={10},
  pages={2472--2500},
  year={2022},
  publisher={Springer}
}

@article{zhang2024bidirectional,
  title={Bidirectional Progressive Transformer for Interaction Intention Anticipation},
  author={Zhang, Zichen and Luo, Hongchen and Zhai, Wei and Cao, Yang and Kang, Yu},
  journal={arXiv preprint arXiv:2405.05552},
  year={2024}
}