\begin{thebibliography}{10}

\bibitem{finn17a}
C.~Finn, P.~Abbeel, and S.~Levine, ``Model-agnostic meta-learning for fast
  adaptation of deep networks,'' in {\em Proceedings of the 34th International
  Conference on Machine Learning}, (Sydney, Australia), 06--11 Aug 2017.

\bibitem{duan2016rl}
Y.~Duan, J.~Schulman, X.~Chen, P.~L. Bartlett, I.~Sutskever, and P.~Abbeel,
  ``Rl2: Fast reinforcement learning via slow reinforcement learning,'' {\em
  arXiv preprint arXiv:1611.02779}, 2016.

\bibitem{wang2016learning}
J.~X. Wang, Z.~Kurth-Nelson, D.~Tirumala, H.~Soyer, J.~Z. Leibo, R.~Munos,
  C.~Blundell, D.~Kumaran, and M.~Botvinick, ``Learning to reinforcement
  learn,'' {\em arXiv preprint arXiv:1611.05763}, 2016.

\bibitem{mishra2017simple}
N.~Mishra, M.~Rohaninejad, X.~Chen, and P.~Abbeel, ``A simple neural attentive
  meta-learner,'' {\em arXiv preprint arXiv:1707.03141}, 2017.

\bibitem{rothfuss2018promp}
J.~Rothfuss, D.~Lee, I.~Clavera, T.~Asfour, and P.~Abbeel, ``Promp: Proximal
  meta-policy search,'' {\em arXiv preprint arXiv:1810.06784}, 2018.

\bibitem{wang2018prefrontal}
J.~X. Wang, Z.~Kurth-Nelson, D.~Kumaran, D.~Tirumala, H.~Soyer, J.~Z. Leibo,
  D.~Hassabis, and M.~Botvinick, ``Prefrontal cortex as a meta-reinforcement
  learning system,'' {\em Nature neuroscience}, vol.~21, no.~6, pp.~860--868,
  2018.

\bibitem{nagabandi2018learning}
A.~Nagabandi, I.~Clavera, S.~Liu, R.~S. Fearing, P.~Abbeel, S.~Levine, and
  C.~Finn, ``Learning to adapt in dynamic, real-world environments through
  meta-reinforcement learning,'' {\em arXiv preprint arXiv:1803.11347}, 2018.

\bibitem{rakelly2019efficient}
K.~Rakelly, A.~Zhou, D.~Quillen, C.~Finn, and S.~Levine, ``Efficient off-policy
  meta-reinforcement learning via probabilistic context variables,'' {\em arXiv
  preprint arXiv:1903.08254}, 2019.

\bibitem{yu2019meta}
T.~Yu, D.~Quillen, Z.~He, R.~Julian, K.~Hausman, C.~Finn, and S.~Levine,
  ``Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning,'' {\em arXiv preprint arXiv:1910.10897}, 2019.

\bibitem{liu2019taming}
H.~Liu, R.~Socher, and C.~Xiong, ``Taming maml: Efficient unbiased
  meta-reinforcement learning,'' in {\em International Conference on Machine
  Learning}, pp.~4061--4071, 2019.

\bibitem{mendonca2019guided}
R.~Mendonca, A.~Gupta, R.~Kralev, P.~Abbeel, S.~Levine, and C.~Finn, ``Guided
  meta-policy search,'' in {\em Advances in Neural Information Processing
  Systems}, pp.~9653--9664, 2019.

\bibitem{gupta2018meta}
A.~Gupta, R.~Mendonca, Y.~Liu, P.~Abbeel, and S.~Levine, ``Meta-reinforcement
  learning of structured exploration strategies,'' in {\em Advances in Neural
  Information Processing Systems}, pp.~5302--5311, 2018.

\bibitem{rajeswaran2019meta}
A.~Rajeswaran, C.~Finn, S.~M. Kakade, and S.~Levine, ``Meta-learning with
  implicit gradients,'' in {\em Advances in Neural Information Processing
  Systems}, pp.~113--124, 2019.

\bibitem{fallah2019convergence}
A.~Fallah, A.~Mokhtari, and A.~Ozdaglar, ``On the convergence theory of
  gradient-based model-agnostic meta-learning algorithms,'' in {\em
  International Conference on Artificial Intelligence and Statistics},
  pp.~1082--1092, PMLR, 2020.

\bibitem{ji2020multi}
K.~Ji, J.~Yang, and Y.~Liang, ``Multi-step model-agnostic meta-learning:
  Convergence and improved algorithms,'' {\em arXiv preprint arXiv:2002.07836},
  2020.

\bibitem{finn19a}
C.~Finn, A.~Rajeswaran, S.~Kakade, and S.~Levine, ``Online meta-learning,'' in
  {\em Proceedings of the 36th International Conference on Machine Learning},
  vol.~97 of {\em Proceedings of Machine Learning Research}, (Long Beach,
  California, USA), pp.~1920--1930, PMLR, 09--15 Jun 2019.

\bibitem{balcan_ICML}
M.~Khodak, M.-F. Balcan, and A.~Talwalkar, ``Provable guarantees for
  gradient-based meta-learning,'' in {\em Proceedings of the 36th International
  Conference on Machine Learning}, vol.~97 of {\em Proceedings of Machine
  Learning Research}, (Long Beach, California, USA), PMLR, 09--15 Jun 2019.

\bibitem{khodak2019adaptive}
M.~Khodak, M.-F.~F. Balcan, and A.~S. Talwalkar, ``Adaptive gradient-based
  meta-learning methods,'' in {\em Advances in Neural Information Processing
  Systems}, pp.~5915--5926, 2019.

\bibitem{foerster2018dice}
J.~Foerster, G.~Farquhar, M.~Al-Shedivat, T.~Rockt{\"a}schel, E.~P. Xing, and
  S.~Whiteson, ``Dice: The infinitely differentiable monte-carlo estimator,''
  {\em arXiv preprint arXiv:1802.05098}, 2018.

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto, {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{peters2008reinforcement}
J.~Peters and S.~Schaal, ``Reinforcement learning of motor skills with policy
  gradients,'' {\em Neural networks}, vol.~21, no.~4, pp.~682--697, 2008.

\bibitem{shen2019hessian}
Z.~Shen, A.~Ribeiro, H.~Hassani, H.~Qian, and C.~Mi, ``Hessian aided policy
  gradient,'' in {\em International Conference on Machine Learning},
  pp.~5729--5738, 2019.

\bibitem{hu2020biased}
Y.~Hu, S.~Zhang, X.~Chen, and N.~He, ``Biased stochastic first-order methods
  for conditional stochastic optimization and applications in meta learning,''
  {\em Advances in Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{pmlr-v80-papini18a}
M.~Papini, D.~Binaghi, G.~Canonaco, M.~Pirotta, and M.~Restelli, ``Stochastic
  variance-reduced policy gradient,'' in {\em Proceedings of the 35th
  International Conference on Machine Learning}, vol.~80 of {\em Proceedings of
  Machine Learning Research}, (StockholmsmÃ¤ssan, Stockholm Sweden),
  pp.~4026--4035, PMLR, 10--15 Jul 2018.

\bibitem{agarwal2019optimality}
A.~Agarwal, S.~M. Kakade, J.~D. Lee, and G.~Mahajan, ``Optimality and
  approximation with policy gradient methods in markov decision processes,''
  {\em arXiv preprint arXiv:1908.00261}, 2019.

\bibitem{mujoco}
E.~{Todorov}, T.~{Erez}, and Y.~{Tassa}, ``Mujoco: A physics engine for
  model-based control,'' in {\em 2012 IEEE/RSJ International Conference on
  Intelligent Robots and Systems}, pp.~5026--5033, 2012.

\bibitem{williams1992simple}
R.~J. Williams, ``Simple statistical gradient-following algorithms for
  connectionist reinforcement learning,'' {\em Machine learning}, vol.~8,
  no.~3-4, pp.~229--256, 1992.

\bibitem{reuther2018interactive}
A.~Reuther, J.~Kepner, C.~Byun, S.~Samsi, W.~Arcand, D.~Bestor, B.~Bergeron,
  V.~Gadepally, M.~Houle, M.~Hubbell, {\em et~al.}, ``Interactive
  supercomputing on 40,000 cores for machine learning and data analysis,'' in
  {\em 2018 IEEE High Performance extreme Computing Conference (HPEC)},
  pp.~1--6, IEEE, 2018.

\bibitem{emaml_stadie2018some}
B.~Stadie, G.~Yang, R.~Houthooft, P.~Chen, Y.~Duan, Y.~Wu, P.~Abbeel, and
  I.~Sutskever, ``The importance of sampling inmeta-reinforcement learning,''
  in {\em Advances in Neural Information Processing Systems} (S.~Bengio,
  H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi, and R.~Garnett,
  eds.), vol.~31, pp.~9280--9290, Curran Associates, Inc., 2018.

\bibitem{nesterov_convex}
Y.~Nesterov, {\em Introductory Lectures on Convex Optimization: A Basic
  Course}, vol.~87.
\newblock Springer, 2004.

\end{thebibliography}
