\begin{thebibliography}{10}

\bibitem{anthony2017thinking}
Thomas Anthony, Zheng Tian, and David Barber.
\newblock Thinking fast and slow with deep learning and tree search.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5360--5370, 2017.

\bibitem{aumann1976agreeing}
Robert~J Aumann.
\newblock Agreeing to disagree.
\newblock {\em The annals of statistics}, pages 1236--1239, 1976.

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{bowling2015heads}
Michael Bowling, Neil Burch, Michael Johanson, and Oskari Tammelin.
\newblock Heads-up limit holdâ€™em poker is solved.
\newblock {\em Science}, 347(6218):145--149, 2015.

\bibitem{brown1951iterative}
George~W Brown.
\newblock Iterative solution of games by fictitious play.
\newblock {\em Activity analysis of production and allocation}, 13(1):374--376,
  1951.

\bibitem{brown2015hierarchical}
Noam Brown, Sam Ganzfried, and Tuomas Sandholm.
\newblock Hierarchical abstraction, distributed equilibrium computation, and
  post-processing, with application to a champion no-limit texas hold'em agent.
\newblock In {\em Proceedings of the 2015 International Conference on
  Autonomous Agents and Multiagent Systems}, pages 7--15. International
  Foundation for Autonomous Agents and Multiagent Systems, 2015.

\bibitem{brown2019deep}
Noam Brown, Adam Lerer, Sam Gross, and Tuomas Sandholm.
\newblock Deep counterfactual regret minimization.
\newblock In {\em International Conference on Machine Learning}, pages
  793--802, 2019.

\bibitem{brown2015simultaneous}
Noam Brown and Tuomas Sandholm.
\newblock Simultaneous abstraction and equilibrium finding in games.
\newblock In {\em Twenty-Fourth International Joint Conference on Artificial
  Intelligence}, 2015.

\bibitem{brown2016baby}
Noam Brown and Tuomas Sandholm.
\newblock Baby tartanian8: Winning agent from the 2016 annual computer poker
  competition.
\newblock In {\em IJCAI}, pages 4238--4239, 2016.

\bibitem{brown2016strategy}
Noam Brown and Tuomas Sandholm.
\newblock Strategy-based warm starting for regret minimization in games.
\newblock In {\em Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem{brown2017safe}
Noam Brown and Tuomas Sandholm.
\newblock Safe and nested subgame solving for imperfect-information games.
\newblock In {\em Advances in neural information processing systems}, pages
  689--699, 2017.

\bibitem{brown2017superhuman}
Noam Brown and Tuomas Sandholm.
\newblock Superhuman {A}{I} for heads-up no-limit poker: Libratus beats top
  professionals.
\newblock {\em Science}, page eaao1733, 2017.

\bibitem{brown2019solving}
Noam Brown and Tuomas Sandholm.
\newblock Solving imperfect-information games via discounted regret
  minimization.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 1829--1836, 2019.

\bibitem{brown2019superhuman}
Noam Brown and Tuomas Sandholm.
\newblock Superhuman {A}{I} for multiplayer poker.
\newblock {\em Science}, page eaay2400, 2019.

\bibitem{brown2018depth}
Noam Brown, Tuomas Sandholm, and Brandon Amos.
\newblock Depth-limited solving for imperfect-information games.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  7663--7674, 2018.

\bibitem{burch2014solving}
Neil Burch, Michael Johanson, and Michael Bowling.
\newblock Solving imperfect information games using decomposition.
\newblock In {\em Twenty-Eighth AAAI Conference on Artificial Intelligence},
  2014.

\bibitem{burch2018aivat}
Neil Burch, Martin Schmid, Matej Moravcik, Dustin Morill, and Michael Bowling.
\newblock Aivat: A new variance reduction technique for agent evaluation in
  imperfect information games.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{chiang2012online}
Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong
  Jin, and Shenghuo Zhu.
\newblock Online optimization with gradual variations.
\newblock In {\em Conference on Learning Theory}, pages 6--1, 2012.

\bibitem{dibangoye2016optimally}
Jilles~Steeve Dibangoye, Christopher Amato, Olivier Buffet, and Fran{\c{c}}ois
  Charpillet.
\newblock Optimally solving dec-pomdps as continuous-state mdps.
\newblock {\em Journal of Artificial Intelligence Research}, 55:443--497, 2016.

\bibitem{foerster2019bayesian}
Jakob Foerster, Francis Song, Edward Hughes, Neil Burch, Iain Dunning, Shimon
  Whiteson, Matthew Botvinick, and Michael Bowling.
\newblock Bayesian action decoder for deep multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1942--1951, 2019.

\bibitem{ganzfried2014potential}
Sam Ganzfried and Tuomas Sandholm.
\newblock Potential-aware imperfect-recall abstraction with earth mover's
  distance in imperfect-information games.
\newblock In {\em Proceedings of the Twenty-Eighth AAAI Conference on
  Artificial Intelligence}, pages 682--690, 2014.

\bibitem{ganzfried2015endgame}
Sam Ganzfried and Tuomas Sandholm.
\newblock Endgame solving in large imperfect-information games.
\newblock In {\em Proceedings of the 2015 International Conference on
  Autonomous Agents and Multiagent Systems}, pages 37--45. International
  Foundation for Autonomous Agents and Multiagent Systems, 2015.

\bibitem{gelly2007combining}
Sylvain Gelly and David Silver.
\newblock Combining online and offline knowledge in uct.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 273--280, 2007.

\bibitem{gilpin2005optimal}
Andrew Gilpin and Tuomas Sandholm.
\newblock Optimal rhode island hold'em poker.
\newblock In {\em Proceedings of the 20th national conference on Artificial
  intelligence-Volume 4}, pages 1684--1685, 2005.

\bibitem{gilpin2006competitive}
Andrew Gilpin and Tuomas Sandholm.
\newblock A competitive texas hold'em poker player via automated abstraction
  and real-time equilibrium computation.
\newblock In {\em Proceedings of the National Conference on Artificial
  Intelligence}, volume~21, page 1007. Menlo Park, CA; Cambridge, MA; London;
  AAAI Press; MIT Press; 1999, 2006.

\bibitem{hansen2004dynamic}
Eric~A Hansen, Daniel~S Bernstein, and Shlomo Zilberstein.
\newblock Dynamic programming for partially observable stochastic games.
\newblock In {\em AAAI}, volume~4, pages 709--715, 2004.

\bibitem{hendrycks2016gaussian}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock {\em arXiv preprint arXiv:1606.08415}, 2016.

\bibitem{hoda2010smoothing}
Samid Hoda, Andrew Gilpin, Javier Pena, and Tuomas Sandholm.
\newblock Smoothing techniques for computing nash equilibria of sequential
  games.
\newblock {\em Mathematics of Operations Research}, 35(2):494--512, 2010.

\bibitem{horak2019solving}
Karel Hor{\'a}k and Branislav Bo{\v{s}}ansk{\`y}.
\newblock Solving partially observable stochastic games with public
  observations.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 2029--2036, 2019.

\bibitem{johanson2012finding}
Michael Johanson, Nolan Bard, Neil Burch, and Michael Bowling.
\newblock Finding optimal abstract strategies in extensive-form games.
\newblock In {\em Proceedings of the Twenty-Sixth AAAI Conference on Artificial
  Intelligence}, pages 1371--1379, 2012.

\bibitem{kaelbling1998planning}
Leslie~Pack Kaelbling, Michael~L Littman, and Anthony~R Cassandra.
\newblock Planning and acting in partially observable stochastic domains.
\newblock {\em Artificial intelligence}, 101(1-2):99--134, 1998.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kovavrik2019problems}
Vojt{\v{e}}ch Kova{\v{r}}{\'\i}k and Viliam Lis{\`y}.
\newblock Problems with the efg formalism: a solution attempt using
  observations.
\newblock {\em arXiv preprint arXiv:1906.06291}, 2019.

\bibitem{kovavrik2019rethinking}
Vojt{\v{e}}ch Kova{\v{r}}{\'\i}k, Martin Schmid, Neil Burch, Michael Bowling,
  and Viliam Lis{\`y}.
\newblock Rethinking formal models of partially observable multiagent decision
  making.
\newblock {\em arXiv preprint arXiv:1906.11110}, 2019.

\bibitem{kroer2018solving}
Christian Kroer, Gabriele Farina, and Tuomas Sandholm.
\newblock Solving large sequential games with the excessive gap technique.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  864--874, 2018.

\bibitem{kroer2018faster}
Christian Kroer, Kevin Waugh, Fatma K{\i}l{\i}n{\c{c}}-Karzan, and Tuomas
  Sandholm.
\newblock Faster algorithms for extensive-form game solving via improved
  smoothing functions.
\newblock {\em Mathematical Programming}, pages 1--33, 2018.

\bibitem{lerer2020improving}
Adam Lerer, Hengyuan Hu, Jakob Foerster, and Noam Brown.
\newblock Improving policies via search in cooperative partially observable
  games.
\newblock In {\em AAAI Conference on Artificial Intelligence}, 2020.

\bibitem{leslie2006generalised}
David~S Leslie and Edmund~J Collins.
\newblock Generalised weakened fictitious play.
\newblock {\em Games and Economic Behavior}, 56(2):285--298, 2006.

\bibitem{lisy2017eqilibrium}
Viliam Lisy and Michael Bowling.
\newblock Eqilibrium approximation quality of current no-limit poker bots.
\newblock In {\em Workshops at the Thirty-First AAAI Conference on Artificial
  Intelligence}, 2017.

\bibitem{moravvcik2017deepstack}
Matej Morav{\v{c}}{\'\i}k, Martin Schmid, Neil Burch, Viliam Lis{\`y}, Dustin
  Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, and Michael
  Bowling.
\newblock Deepstack: Expert-level artificial intelligence in heads-up no-limit
  poker.
\newblock {\em Science}, 356(6337):508--513, 2017.

\bibitem{moravcik2016refining}
Matej Moravcik, Martin Schmid, Karel Ha, Milan Hladik, and Stephen~J
  Gaukrodger.
\newblock Refining subgames in large imperfect information games.
\newblock In {\em Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem{nash1951non}
John Nash.
\newblock Non-cooperative games.
\newblock {\em Annals of mathematics}, pages 286--295, 1951.

\bibitem{nayyar2013decentralized}
Ashutosh Nayyar, Aditya Mahajan, and Demosthenis Teneketzis.
\newblock Decentralized stochastic control with partial history sharing: A
  common information approach.
\newblock {\em IEEE Transactions on Automatic Control}, 58(7):1644--1658, 2013.

\bibitem{newman2016reconnaissance}
Andrew~J Newman, Casey~L Richardson, Sean~M Kain, Paul~G Stankiewicz, Paul~R
  Guseman, Blake~A Schreurs, and Jeffrey~A Dunne.
\newblock Reconnaissance blind multi-chess: an experimentation platform for isr
  sensor fusion and resource management.
\newblock In {\em Signal Processing, Sensor/Information Fusion, and Target
  Recognition XXV}, volume 9842, page 984209. International Society for Optics
  and Photonics, 2016.

\bibitem{oliehoek2013sufficient}
Frans~Adriaan Oliehoek.
\newblock Sufficient plan-time statistics for decentralized pomdps.
\newblock In {\em Twenty-Third International Joint Conference on Artificial
  Intelligence}, 2013.

\bibitem{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em Advances in neural information processing systems}, pages
  8026--8037, 2019.

\bibitem{rakhlin2013online}
Alexander Rakhlin and Karthik Sridharan.
\newblock Online learning with predictable sequences.
\newblock 2013.

\bibitem{rockafellar1970convex}
R~Tyrrell Rockafellar.
\newblock {\em Convex analysis}.
\newblock Number~28. Princeton university press, 1970.

\bibitem{samuel1959some}
Arthur~L Samuel.
\newblock Some studies in machine learning using the game of checkers.
\newblock {\em IBM Journal of research and development}, 3(3):210--229, 1959.

\bibitem{schrittwieser2019mastering}
Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan,
  Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis,
  Thore Graepel, et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock {\em arXiv preprint arXiv:1911.08265}, 2019.

\bibitem{schulman2015high}
John Schulman, Philipp Moritz, Sergey Levine, Michael~I. Jordan, and Pieter
  Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2016.

\bibitem{seitz2019value}
Dominik Seitz, Vojtech Kovar{\'\i}k, Viliam Lis{\`y}, Jan Rudolf, Shuo Sun, and
  Karel Ha.
\newblock Value functions for depth-limited solving in imperfect-information
  games beyond poker.
\newblock {\em arXiv preprint arXiv:1906.06412}, 2019.

\bibitem{serrino2019finding}
Jack Serrino, Max Kleiman-Weiner, David~C Parkes, and Josh Tenenbaum.
\newblock Finding friend and foe in multi-agent games.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1249--1259, 2019.

\bibitem{shannon1950programming}
Claude~E Shannon.
\newblock Programming a computer for playing chess.
\newblock {\em The London, Edinburgh, and Dublin Philosophical Magazine and
  Journal of Science}, 41(314):256--275, 1950.

\bibitem{silver2018general}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and go through self-play.
\newblock {\em Science}, 362(6419):1140--1144, 2018.

\bibitem{silver2017mastering}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  et~al.
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature}, 550(7676):354, 2017.

\bibitem{sustr2019monte}
Michal {\v{S}}ustr, Vojt{\v{e}}ch Kova{\v{r}}{\'\i}k, and Viliam Lis{\`y}.
\newblock Monte carlo continual resolving for online strategy computation in
  imperfect information games.
\newblock In {\em Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 224--232. International
  Foundation for Autonomous Agents and Multiagent Systems, 2019.

\bibitem{syrgkanis2015fast}
Vasilis Syrgkanis, Alekh Agarwal, Haipeng Luo, and Robert~E Schapire.
\newblock Fast convergence of regularized learning in games.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2989--2997, 2015.

\bibitem{tesauro1994td}
Gerald Tesauro.
\newblock T{D}-{G}ammon, a self-teaching backgammon program, achieves
  master-level play.
\newblock {\em Neural computation}, 6(2):215--219, 1994.

\bibitem{van2000weakened}
Ben Van~der Genugten.
\newblock A weakened form of fictitious play in two-person zero-sum games.
\newblock {\em International Game Theory Review}, 2(04):307--328, 2000.

\bibitem{zinkevich2008regret}
Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione.
\newblock Regret minimization in games with incomplete information.
\newblock In {\em Advances in neural information processing systems}, pages
  1729--1736, 2008.

\end{thebibliography}
