\begin{thebibliography}{10}

\bibitem{bellemare:13:arcade}
M.~G. {Bellemare}, Y.~{Naddaf}, J.~{Veness}, and M.~{Bowling}.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock {\em Journal of Artificial Intelligence Research}, 47:253--279, 2013.

\bibitem{mnih:15:nature}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518:529, 2015.

\bibitem{liang2016:stateofartshallow}
Yitao Liang, Marlos~C. Machado, Erik Talvitie, and Michael~H. Bowling.
\newblock State of the art control of atari games using shallow reinforcement
  learning.
\newblock In {\em Proc. of Int'l Conf. on Autonomous Agents and Multiagent
  Systems (AAMAS)}, pages 485--493. {ACM}, 2016.

\bibitem{hessel2018rainbow}
Matteo Hessel, Joseph Modayil, Hado Van~Hasselt, Tom Schaul, Georg Ostrovski,
  Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, and David Silver.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock In {\em Proc. of the National Conference on Artificial Intelligence
  (AAAI)}, pages 3215--3222, 2018.

\bibitem{lipovetzky:15:atari}
Nir Lipovetzky, Miquel Ramirez, and Hector Geffner.
\newblock Classical planning with simulators: results on the atari video games.
\newblock In {\em Proc. of Int'l Joint Conf. in Artificial Intelligence
  (IJCAI)}, pages 1610--1616, 2015.

\bibitem{bandres:18:RIW}
Wilmer Bandres, Blai Bonet, and Hector Geffner.
\newblock Planning with pixels in (almost) real time.
\newblock In {\em Proc. of the National Conference on Artificial Intelligence
  (AAAI)}, volume~32, pages 6102--6109. AAAI Press, 2018.

\bibitem{haslum2019introduction}
Patrik Haslum, Nir Lipovetzky, Daniele Magazzeni, and Christian Muise.
\newblock An introduction to the planning domain definition language.
\newblock {\em Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 13(2):1--187, 2019.

\bibitem{junyent:19:icaps}
Miquel Junyent, Anders Jonsson, and Vicenc Gomez.
\newblock Deep policies for width--based planning.
\newblock In {\em Proc. of the Int'l Conf. in Automated Planning and Scheduling
  (ICAPS)}, volume~29, pages 646--654, 2019.

\bibitem{dittadi2021planning}
Andrea Dittadi, Frederik~K Drachmann, and Thomas Bolander.
\newblock Planning from pixels in atari with learned symbolic representations.
\newblock In {\em Proc. of the National Conference on Artificial Intelligence
  (AAAI)}, volume~35, pages 4941--4949, 2021.

\bibitem{junyent2021hierarchical}
Miquel Junyent, Vicen{\c{c}} G{\'o}mez, and Anders Jonsson.
\newblock Hierarchical width-based planning and learning.
\newblock In {\em Proc. of the Int'l Conf. in Automated Planning and Scheduling
  (ICAPS)}, volume~31, pages 519--527, 2021.

\bibitem{schrittwieser2020mastering}
Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan,
  Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis,
  Thore Graepel, et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock {\em Nature}, 588(7839):604--609, 2020.

\bibitem{geffner2013concise}
Hector Geffner and Blai Bonet.
\newblock A concise introduction to models and methods for automated planning.
\newblock {\em Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 8(1):1--141, 2013.

\bibitem{silver:16:nature}
David Silver, Aja Huang, Chris~J. Maddison, Arthur Guez, Laurent Sifre, George
  Van~Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, and {others}.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529:484--489, 2016.

\bibitem{silver:17:nature}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  and {others}.
\newblock Mastering the game of {Go} without human knowledge.
\newblock {\em Nature}, 550(7676):354, 2017.

\bibitem{silver2018general}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and go through self-play.
\newblock {\em Science}, 362(6419):1140--1144, 2018.

\bibitem{lipovetzky:12:width}
Nir Lipovetzky and H{\'e}ctor Geffner.
\newblock Width and serialization of classical planning problems.
\newblock In {\em Proc. of European Conference in Artificial Intelligence
  (ECAI)}, pages 540--545, 2012.

\bibitem{shleyfman2016blind}
Alexander Shleyfman, Alexander Tuisov, and Carmel Domshlak.
\newblock Blind search for atari-like online planning revisited.
\newblock In {\em Proc. of Int'l Joint Conf. in Artificial Intelligence
  (IJCAI)}, pages 3251--3257, 2016.

\bibitem{jinnai2017learning}
Yuu Jinnai and Alex Fukunaga.
\newblock Learning to prune dominated action sequences in online black-box
  planning.
\newblock In {\em Proc. of the National Conference on Artificial Intelligence
  (AAAI)}, volume~31, pages 839--845, 2017.

\bibitem{kocsis:06:ecml}
Levente Kocsis and Csaba Szepevari.
\newblock Bandit based monte carlo planning.
\newblock In {\em Proc. of European Conference in Machine Learning (ECML)},
  pages 282--293, 2006.

\bibitem{otoole2019width}
Stefan Oâ€™Toole, Miquel Ramirez, Nir Lipovetzky, and Adrian Pearce.
\newblock Width-based lookaheads augmented with base policies for stochastic
  shortest paths.
\newblock In {\em ICAPS Workshop on Heuristics and Domain Independent Planning
  (HSDIP)}, pages 37--45, 2019.

\bibitem{sutton1988TDlearning}
Richard~S Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock {\em Machine learning}, 3(1):9--44, 1988.

\bibitem{welchttest}
B.~L. Welch.
\newblock The generalization of `student's' problem when several different
  population variances are involved.
\newblock {\em Biometrika}, 34(1/2):28--35, 1947.

\bibitem{nelson2021estimates}
Mark~J Nelson.
\newblock Estimates for the branching factors of atari games.
\newblock In {\em Proc. of the IEEE Conference on Games.}, 2021.

\bibitem{barto:95:rtdp}
Andy~G. Barto, S.~J. Bradtke, and S.~P. Singh.
\newblock Real--time learning and control using asynchronous dynamic
  programming.
\newblock {\em Artificial Intelligence Journal}, 72:81--138, 1995.

\bibitem{machado:17:revistale}
Marlos~C Machado, Marc~G Bellemare, Erik Talvitie, Joel Veness, Matthew
  Hausknecht, and Michael Bowling.
\newblock Revisiting the arcade learning environment: {Evaluation} protocols
  and open problems for general agents.
\newblock {\em Journal of Artificial Intelligence Research}, 61:523--562, 2018.

\end{thebibliography}
