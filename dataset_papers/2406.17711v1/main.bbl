\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbas et~al.(2023)Abbas, Tirumala, Simig, Ganguli, and
  Morcos]{abbas2023semdedup}
Amro Abbas, Kushal Tirumala, D{\'a}niel Simig, Surya Ganguli, and Ari~S Morcos.
\newblock Semdedup: Data-efficient learning at web-scale through semantic
  deduplication.
\newblock \emph{arXiv preprint arXiv:2303.09540}, 2023.

\bibitem[Abbas et~al.(2024)Abbas, Rusak, Tirumala, Brendel, Chaudhuri, and
  Morcos]{abbas2024effective}
Amro Abbas, Evgenia Rusak, Kushal Tirumala, Wieland Brendel, Kamalika
  Chaudhuri, and Ari~S Morcos.
\newblock Effective pruning of web-scale datasets based on complexity of
  concept clusters.
\newblock \emph{arXiv preprint arXiv:2401.04578}, 2024.

\bibitem[Beyer et~al.(2022)Beyer, Zhai, and Kolesnikov]{big_vision}
Lucas Beyer, Xiaohua Zhai, and Alexander Kolesnikov.
\newblock Big vision.
\newblock \url{https://github.com/google-research/big_vision}, 2022.

\bibitem[Beyer et~al.(2023)Beyer, Izmailov, Kolesnikov, Caron, Kornblith, Zhai,
  Minderer, Tschannen, Alabdulmohsin, and Pavetic]{beyer2023flexivit}
Lucas Beyer, Pavel Izmailov, Alexander Kolesnikov, Mathilde Caron, Simon
  Kornblith, Xiaohua Zhai, Matthias Minderer, Michael Tschannen, Ibrahim
  Alabdulmohsin, and Filip Pavetic.
\newblock Flexivit: One model for all patch sizes.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 14496--14506, 2023.

\bibitem[Bucher et~al.(2016)Bucher, Herbin, and Jurie]{bucher2016hard}
Maxime Bucher, St{\'e}phane Herbin, and Fr{\'e}d{\'e}ric Jurie.
\newblock Hard negative mining for metric learning based zero-shot
  classification.
\newblock In \emph{Computer Vision--ECCV 2016 Workshops: Amsterdam, The
  Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part III 14}, pages
  524--531. Springer, 2016.

\bibitem[Byeon et~al.(2022)Byeon, Park, Kim, Lee, Baek, and Kim]{byeon2022coyo}
Minwoo Byeon, Beomhee Park, Haecheon Kim, Sungjun Lee, Woonhyuk Baek, and
  Saehoon Kim.
\newblock Coyo-700m: Image-text pair dataset.
\newblock \emph{Coyo-700m: Image-text pair dataset}, 2022.

\bibitem[Campbell and Broderick(2018)]{campbell2018bayesian}
Trevor Campbell and Tamara Broderick.
\newblock Bayesian coreset construction via greedy iterative geodesic ascent.
\newblock In \emph{International Conference on Machine Learning}, pages
  698--706. PMLR, 2018.

\bibitem[Cao et~al.(2023)Cao, Zhang, Chen, Yang, Du, Zhang, Lu, and
  Zheng]{cao2023less}
Liangliang Cao, Bowen Zhang, Chen Chen, Yinfei Yang, Xianzhi Du, Wencong Zhang,
  Zhiyun Lu, and Yantao Zheng.
\newblock Less is more: Removing text-regions improves clip training efficiency
  and robustness.
\newblock \emph{arXiv preprint arXiv:2305.05095}, 2023.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and
  Soricut]{changpinyo2021conceptual}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 3558--3568, 2021.

\bibitem[Chen et~al.(2022)Chen, Wang, Changpinyo, Piergiovanni, Padlewski,
  Salz, Goodman, Grycner, Mustafa, Beyer, et~al.]{chen2022pali}
Xi~Chen, Xiao Wang, Soravit Changpinyo, AJ~Piergiovanni, Piotr Padlewski,
  Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer,
  et~al.
\newblock Pali: A jointly-scaled multilingual language-image model.
\newblock \emph{arXiv preprint arXiv:2209.06794}, 2022.

\bibitem[Chen et~al.(2023)Chen, Wang, Beyer, Kolesnikov, Wu, Voigtlaender,
  Mustafa, Goodman, Alabdulmohsin, Padlewski, et~al.]{chen2023pali}
Xi~Chen, Xiao Wang, Lucas Beyer, Alexander Kolesnikov, Jialin Wu, Paul
  Voigtlaender, Basil Mustafa, Sebastian Goodman, Ibrahim Alabdulmohsin, Piotr
  Padlewski, et~al.
\newblock Pali-3 vision language models: Smaller, faster, stronger.
\newblock \emph{arXiv preprint arXiv:2310.09199}, 2023.

\bibitem[Coleman et~al.(2019)Coleman, Yeh, Mussmann, Mirzasoleiman, Bailis,
  Liang, Leskovec, and Zaharia]{coleman2019selection}
Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan Mirzasoleiman, Peter
  Bailis, Percy Liang, Jure Leskovec, and Matei Zaharia.
\newblock Selection via proxy: Efficient data selection for deep learning.
\newblock \emph{arXiv preprint arXiv:1906.11829}, 2019.

\bibitem[Dehghani et~al.(2024)Dehghani, Mustafa, Djolonga, Heek, Minderer,
  Caron, Steiner, Puigcerver, Geirhos, Alabdulmohsin,
  et~al.]{dehghani2024patch}
Mostafa Dehghani, Basil Mustafa, Josip Djolonga, Jonathan Heek, Matthias
  Minderer, Mathilde Caron, Andreas Steiner, Joan Puigcerver, Robert Geirhos,
  Ibrahim~M Alabdulmohsin, et~al.
\newblock Patch nâ€™pack: Navit, a vision transformer for any aspect ratio and
  resolution.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Evans et~al.(2023)Evans, Pathak, Merzic, Schwarz, Tanno, and
  Henaff]{evans2023bad}
Talfan Evans, Shreya Pathak, Hamza Merzic, Jonathan Schwarz, Ryutaro Tanno, and
  Olivier~J Henaff.
\newblock Bad students make great teachers: Active learning accelerates
  large-scale visual understanding.
\newblock \emph{arXiv preprint arXiv:2312.05328}, 2023.

\bibitem[Fang et~al.(2023)Fang, Jose, Jain, Schmidt, Toshev, and
  Shankar]{fang2023data}
Alex Fang, Albin~Madappally Jose, Amit Jain, Ludwig Schmidt, Alexander Toshev,
  and Vaishaal Shankar.
\newblock Data filtering networks.
\newblock \emph{arXiv preprint arXiv:2309.17425}, 2023.

\bibitem[Gadre et~al.(2023)Gadre, Ilharco, Fang, Hayase, Smyrnis, Nguyen,
  Marten, Wortsman, Ghosh, Zhang, et~al.]{gadre2023datacomp}
Samir~Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan Hayase, Georgios
  Smyrnis, Thao Nguyen, Ryan Marten, Mitchell Wortsman, Dhruba Ghosh, Jieyu
  Zhang, et~al.
\newblock Datacomp: In search of the next generation of multimodal datasets.
\newblock \emph{arXiv preprint arXiv:2304.14108}, 2023.

\bibitem[Goyal et~al.(2024)Goyal, Maini, Lipton, Raghunathan, and
  Kolter]{goyal2024scaling}
Sachin Goyal, Pratyush Maini, Zachary~C Lipton, Aditi Raghunathan, and J~Zico
  Kolter.
\newblock Scaling laws for data filtering--data curation cannot be compute
  agnostic.
\newblock \emph{arXiv preprint arXiv:2404.07177}, 2024.

\bibitem[Gunasekar et~al.(2023)Gunasekar, Zhang, Aneja, Mendes, Del~Giorno,
  Gopi, Javaheripi, Kauffmann, de~Rosa, Saarikivi,
  et~al.]{gunasekar2023textbooks}
Suriya Gunasekar, Yi~Zhang, Jyoti Aneja, Caio C{\'e}sar~Teodoro Mendes, Allie
  Del~Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo
  de~Rosa, Olli Saarikivi, et~al.
\newblock Textbooks are all you need.
\newblock \emph{arXiv preprint arXiv:2306.11644}, 2023.

\bibitem[Har-Peled and Mazumdar(2004)]{har2004coresets}
Sariel Har-Peled and Soham Mazumdar.
\newblock On coresets for k-means and k-median clustering.
\newblock In \emph{Proceedings of the thirty-sixth annual ACM symposium on
  Theory of computing}, pages 291--300, 2004.

\bibitem[Harwood et~al.(2017)Harwood, Kumar~BG, Carneiro, Reid, and
  Drummond]{harwood2017smart}
Ben Harwood, Vijay Kumar~BG, Gustavo Carneiro, Ian Reid, and Tom Drummond.
\newblock Smart mining for deep metric learning.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2821--2829, 2017.

\bibitem[Hessel et~al.(2021)Hessel, Holtzman, Forbes, Bras, and
  Choi]{hessel2021clipscore}
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan~Le Bras, and Yejin Choi.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock \emph{arXiv preprint arXiv:2104.08718}, 2021.

\bibitem[Ilharco et~al.(2021)Ilharco, Wortsman, Wightman, Gordon, Carlini,
  Taori, Dave, Shankar, Namkoong, Miller, Hajishirzi, Farhadi, and
  Schmidt]{ilharco_gabriel_2021_5143773}
Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas
  Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar, Hongseok Namkoong, John
  Miller, Hannaneh Hajishirzi, Ali Farhadi, and Ludwig Schmidt.
\newblock Openclip, July 2021.
\newblock URL \url{https://doi.org/10.5281/zenodo.5143773}.
\newblock If you use this software, please cite it as below.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International conference on machine learning}, pages
  4904--4916. PMLR, 2021.

\bibitem[Jouppi et~al.(2017)Jouppi, Young, Patil, Patterson, Agrawal, Bajwa,
  Bates, Bhatia, Boden, Borchers, et~al.]{jouppi2017datacenter}
Norman~P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal,
  Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al~Borchers, et~al.
\newblock In-datacenter performance analysis of a tensor processing unit.
\newblock In \emph{Proceedings of the 44th annual international symposium on
  computer architecture}, pages 1--12, 2017.

\bibitem[Kudo and Richardson(2018)]{kudo2018sentencepiece}
Taku Kudo and John Richardson.
\newblock Sentencepiece: A simple and language independent subword tokenizer
  and detokenizer for neural text processing.
\newblock \emph{arXiv preprint arXiv:1808.06226}, 2018.

\bibitem[Li et~al.(2022)Li, Li, Xiong, and Hoi]{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified
  vision-language understanding and generation.
\newblock In \emph{International conference on machine learning}, pages
  12888--12900. PMLR, 2022.

\bibitem[Li et~al.(2024)Li, Wang, and Xie]{li2024inverse}
Xianhang Li, Zeyu Wang, and Cihang Xie.
\newblock An inverse scaling law for clip training.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Li et~al.(2023)Li, Fan, Hu, Feichtenhofer, and He]{li2023scaling}
Yanghao Li, Haoqi Fan, Ronghang Hu, Christoph Feichtenhofer, and Kaiming He.
\newblock Scaling language-image pre-training via masking, 2023.

\bibitem[Lin et~al.(2024)Lin, Gou, Gong, Liu, Shen, Xu, Lin, Yang, Jiao, Duan,
  et~al.]{lin2024rho}
Zhenghao Lin, Zhibin Gou, Yeyun Gong, Xiao Liu, Yelong Shen, Ruochen Xu, Chen
  Lin, Yujiu Yang, Jian Jiao, Nan Duan, et~al.
\newblock Rho-1: Not all tokens are what you need.
\newblock \emph{arXiv preprint arXiv:2404.07965}, 2024.

\bibitem[Loshchilov and Hutter(2015)]{loshchilov2015online}
Ilya Loshchilov and Frank Hutter.
\newblock Online batch selection for faster training of neural networks.
\newblock \emph{arXiv preprint arXiv:1511.06343}, 2015.

\bibitem[Mahmoud et~al.(2023)Mahmoud, Elhoushi, Abbas, Yang, Ardalani, Leather,
  and Morcos]{mahmoud2023sieve}
Anas Mahmoud, Mostafa Elhoushi, Amro Abbas, Yu~Yang, Newsha Ardalani, Hugh
  Leather, and Ari Morcos.
\newblock Sieve: Multimodal dataset pruning using image captioning models.
\newblock \emph{arXiv preprint arXiv:2310.02110}, 2023.

\bibitem[Mindermann et~al.(2022)Mindermann, Brauner, Razzak, Sharma, Kirsch,
  Xu, H{\"o}ltgen, Gomez, Morisot, Farquhar, et~al.]{mindermann2022prioritized}
S{\"o}ren Mindermann, Jan~M Brauner, Muhammed~T Razzak, Mrinank Sharma, Andreas
  Kirsch, Winnie Xu, Benedikt H{\"o}ltgen, Aidan~N Gomez, Adrien Morisot,
  Sebastian Farquhar, et~al.
\newblock Prioritized training on points that are learnable, worth learning,
  and not yet learnt.
\newblock In \emph{International Conference on Machine Learning}, pages
  15630--15649. PMLR, 2022.

\bibitem[Mishchuk et~al.(2017)Mishchuk, Mishkin, Radenovic, and
  Matas]{mishchuk2017working}
Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic, and Jiri Matas.
\newblock Working hard to know your neighbor's margins: Local descriptor
  learning loss.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Naeem et~al.(2023)Naeem, Xian, Zhai, Hoyer, Gool, and
  Tombari]{naeem2023silc}
Muhammad~Ferjad Naeem, Yongqin Xian, Xiaohua Zhai, Lukas Hoyer, Luc~Van Gool,
  and Federico Tombari.
\newblock Silc: Improving vision language pretraining with self-distillation,
  2023.

\bibitem[Paul et~al.(2021)Paul, Ganguli, and Dziugaite]{paul2021deep}
Mansheej Paul, Surya Ganguli, and Gintare~Karolina Dziugaite.
\newblock Deep learning on a data diet: Finding important examples early in
  training.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 20596--20607, 2021.

\bibitem[Radenovic et~al.(2023)Radenovic, Dubey, Kadian, Mihaylov, Vandenhende,
  Patel, Wen, Ramanathan, and Mahajan]{radenovic2023filtering}
Filip Radenovic, Abhimanyu Dubey, Abhishek Kadian, Todor Mihaylov, Simon
  Vandenhende, Yash Patel, Yi~Wen, Vignesh Ramanathan, and Dhruv Mahajan.
\newblock Filtering, distillation, and hard negatives for vision-language
  pre-training.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 6967--6977, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{Journal of machine learning research}, 21\penalty0
  (140):\penalty0 1--67, 2020.

\bibitem[Raposo et~al.(2024)Raposo, Ritter, Richards, Lillicrap, Humphreys, and
  Santoro]{raposo2024mixture}
David Raposo, Sam Ritter, Blake Richards, Timothy Lillicrap, Peter~Conway
  Humphreys, and Adam Santoro.
\newblock Mixture-of-depths: Dynamically allocating compute in
  transformer-based language models.
\newblock \emph{arXiv preprint arXiv:2404.02258}, 2024.

\bibitem[Robinson et~al.(2020)Robinson, Chuang, Sra, and
  Jegelka]{robinson2020contrastive}
Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, and Stefanie Jegelka.
\newblock Contrastive learning with hard negative samples.
\newblock \emph{arXiv preprint arXiv:2010.04592}, 2020.

\bibitem[Sachdeva et~al.(2024)Sachdeva, Coleman, Kang, Ni, Hong, Chi, Caverlee,
  McAuley, and Cheng]{sachdeva2024train}
Noveen Sachdeva, Benjamin Coleman, Wang-Cheng Kang, Jianmo Ni, Lichan Hong,
  Ed~H Chi, James Caverlee, Julian McAuley, and Derek~Zhiyuan Cheng.
\newblock How to train data-efficient llms.
\newblock \emph{arXiv preprint arXiv:2402.09668}, 2024.

\bibitem[Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver]{schaul2015prioritized}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1511.05952}, 2015.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman,
  Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{schuhmann2022laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 25278--25294, 2022.

\bibitem[Simo-Serra et~al.(2015)Simo-Serra, Trulls, Ferraz, Kokkinos, Fua, and
  Moreno-Noguer]{simo2015discriminative}
Edgar Simo-Serra, Eduard Trulls, Luis Ferraz, Iasonas Kokkinos, Pascal Fua, and
  Francesc Moreno-Noguer.
\newblock Discriminative learning of deep convolutional feature point
  descriptors.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 118--126, 2015.

\bibitem[Singer et~al.(2022)Singer, Polyak, Hayes, Yin, An, Zhang, Hu, Yang,
  Ashual, Gafni, et~al.]{singer2022make}
Uriel Singer, Adam Polyak, Thomas Hayes, Xi~Yin, Jie An, Songyang Zhang, Qiyuan
  Hu, Harry Yang, Oron Ashual, Oran Gafni, et~al.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock \emph{arXiv preprint arXiv:2209.14792}, 2022.

\bibitem[Sorscher et~al.(2022)Sorscher, Geirhos, Shekhar, Ganguli, and
  Morcos]{sorscher2022beyond}
Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, and Ari Morcos.
\newblock Beyond neural scaling laws: beating power law scaling via data
  pruning.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 19523--19536, 2022.

\bibitem[Sun et~al.(2023)Sun, Fang, Wu, Wang, and Cao]{sun2023eva}
Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue Cao.
\newblock Eva-clip: Improved training techniques for clip at scale.
\newblock \emph{arXiv preprint arXiv:2303.15389}, 2023.

\bibitem[Tian et~al.(2021)Tian, Henaff, and van~den Oord]{tian2021divide}
Yonglong Tian, Olivier~J Henaff, and A{\"a}ron van~den Oord.
\newblock Divide and contrast: Self-supervised learning from uncurated data.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem[Wu et~al.(2017)Wu, Manmatha, Smola, and Krahenbuhl]{wu2017sampling}
Chao-Yuan Wu, R~Manmatha, Alexander~J Smola, and Philipp Krahenbuhl.
\newblock Sampling matters in deep embedding learning.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2840--2848, 2017.

\bibitem[Xie et~al.(2023)Xie, Pham, Dong, Du, Liu, Lu, Liang, Le, Ma, and
  Yu]{xie2023doremi}
Sang~Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy
  Liang, Quoc~V. Le, Tengyu Ma, and Adams~Wei Yu.
\newblock Doremi: Optimizing data mixtures speeds up language model
  pretraining, 2023.

\bibitem[Xu et~al.(2023)Xu, Xie, Tan, Huang, Howes, Sharma, Li, Ghosh,
  Zettlemoyer, and Feichtenhofer]{xu2023demystifying}
Hu~Xu, Saining Xie, Xiaoqing~Ellen Tan, Po-Yao Huang, Russell Howes, Vasu
  Sharma, Shang-Wen Li, Gargi Ghosh, Luke Zettlemoyer, and Christoph
  Feichtenhofer.
\newblock Demystifying clip data.
\newblock \emph{arXiv preprint arXiv:2309.16671}, 2023.

\bibitem[Xuan et~al.(2020)Xuan, Stylianou, Liu, and Pless]{xuan2020hard}
Hong Xuan, Abby Stylianou, Xiaotong Liu, and Robert Pless.
\newblock Hard negative examples are hard, but useful.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16}, pages 126--142.
  Springer, 2020.

\bibitem[Zhai et~al.(2023)Zhai, Mustafa, Kolesnikov, and
  Beyer]{zhai2023sigmoid}
Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer.
\newblock Sigmoid loss for language image pre-training.
\newblock \emph{arXiv preprint arXiv:2303.15343}, 2023.

\bibitem[Zhang and He(2020)]{zhang2020accelerating}
Minjia Zhang and Yuxiong He.
\newblock Accelerating training of transformer-based language models with
  progressive layer dropping.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 14011--14023, 2020.

\end{thebibliography}
