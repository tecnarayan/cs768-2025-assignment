\begin{thebibliography}{10}

\bibitem{candes2018panning}
Emmanuel Candes, Yingying Fan, Lucas Janson, and Jinchi Lv.
\newblock Panning for gold:‘model-x’knockoffs for high dimensional
  controlled variable selection.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 80(3):551--577, 2018.

\bibitem{Chen_2020_CVPR}
Hanting Chen, Yunhe Wang, Han Shu, Yehui Tang, Chunjing Xu, Boxin Shi, Chao Xu,
  Qi~Tian, and Chang Xu.
\newblock Frequency domain compact 3d convolutional neural networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{ding2019centripetal}
Xiaohan Ding, Guiguang Ding, Yuchen Guo, and Jungong Han.
\newblock Centripetal sgd for pruning very deep convolutional networks with
  complicated structure.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4943--4953, 2019.

\bibitem{dong2017more}
Xuanyi Dong, Junshi Huang, Yi~Yang, and Shuicheng Yan.
\newblock More is less: A more complicated network with less inference
  complexity.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5840--5848, 2017.

\bibitem{fu2020autogan}
Yonggan Fu, Wuyang Chen, Haotao Wang, Haoran Li, Yingyan Lin, and Zhangyang
  Wang.
\newblock Autogan-distiller: Searching to compress generative adversarial
  networks.
\newblock {\em arXiv preprint arXiv:2006.08198}, 2020.

\bibitem{han2020training}
Kai Han, Yunhe Wang, Yixing Xu, Chunjing Xu, Enhua Wu, and Chang Xu.
\newblock Training binary neural networks through learning with noisy
  supervision.
\newblock In {\em ICML}, 2020.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{he2018soft}
Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi~Yang.
\newblock Soft filter pruning for accelerating deep convolutional neural
  networks.
\newblock In {\em Proceedings of the 27th International Joint Conference on
  Artificial Intelligence}, pages 2234--2240, 2018.

\bibitem{he2019filter}
Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, and Yi~Yang.
\newblock Filter pruning via geometric median for deep convolutional neural
  networks acceleration.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4340--4349, 2019.

\bibitem{he2017channel}
Yihui He, Xiangyu Zhang, and Jian Sun.
\newblock Channel pruning for accelerating very deep neural networks.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 1389--1397, 2017.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock {\em arXiv preprint arXiv:1502.03167}, 2015.

\bibitem{jordon2018knockoffgan}
James Jordon, Jinsung Yoon, and Mihaela van~der Schaar.
\newblock Knockoff{GAN}: Generating knockoffs for feature selection using
  generative adversarial networks.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{kessler2014distribution}
David~A Kessler, Shlomi Medalion, and Eli Barkai.
\newblock The distribution of the area under a bessel excursion and its
  moments.
\newblock {\em Journal of Statistical Physics}, 156(4):686--706, 2014.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{DBLP:conf/aaai/KongGY020}
Shumin Kong, Tianyu Guo, Shan You, and Chang Xu.
\newblock Learning student networks with few data.
\newblock In {\em {AAAI}}, pages 4469--4476. {AAAI} Press, 2020.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in neural information processing systems}, pages
  1097--1105, 2012.

\bibitem{li2018constrained}
Chong Li and CJ~Richard~Shi.
\newblock Constrained optimization based low-rank approximation of deep neural
  networks.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 732--747, 2018.

\bibitem{DBLP:conf/iclr/0022KDSG17}
Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans~Peter Graf.
\newblock Pruning filters for efficient convnets.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}. OpenReview.net, 2017.

\bibitem{Liebenwein2020Provable}
Lucas Liebenwein, Cenk Baykal, Harry Lang, Dan Feldman, and Daniela Rus.
\newblock Provable filter pruning for efficient neural networks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{lin2020hrank}
Mingbao Lin, Rongrong Ji, Yan Wang, Yichen Zhang, Baochang Zhang, Yonghong
  Tian, and Shao Ling.
\newblock Hrank: Filter pruning using high-rank feature map.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2020.

\bibitem{lin2019towards}
Shaohui Lin, Rongrong Ji, Chenqian Yan, Baochang Zhang, Liujuan Cao, Qixiang
  Ye, Feiyue Huang, and David Doermann.
\newblock Towards optimal structured cnn pruning via generative adversarial
  learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2790--2799, 2019.

\bibitem{liu2020adadeep}
Sicong Liu, Junzhao Du, Kaiming Nan, Atlas Wang, Yingyan Lin, et~al.
\newblock Adadeep: A usage-driven, automated deep model compression framework
  for enabling ubiquitous intelligent mobiles.
\newblock {\em arXiv preprint arXiv:2006.04432}, 2020.

\bibitem{luo2018autopruner}
Jian-Hao Luo and Jianxin Wu.
\newblock Autopruner: An end-to-end trainable filter pruning method for
  efficient deep model inference.
\newblock {\em arXiv preprint arXiv:1805.08941}, 2018.

\bibitem{luo2017thinet}
Jian-Hao Luo, Jianxin Wu, and Weiyao Lin.
\newblock Thinet: A filter level pruning method for deep neural network
  compression.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 5058--5066, 2017.

\bibitem{molchanov2019importance}
Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz.
\newblock Importance estimation for neural network pruning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 11264--11272, 2019.

\bibitem{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  91--99, 2015.

\bibitem{sandler2018mobilenetv2}
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
  Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4510--4520, 2018.

\bibitem{shen2019searching}
Mingzhu Shen, Kai Han, Chunjing Xu, and Yunhe Wang.
\newblock Searching for accurate binary neural architectures.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision Workshops}, pages 0--0, 2019.

\bibitem{tang2020beyond}
Yehui Tang, Yunhe Wang, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, and Chang
  Xu.
\newblock Beyond dropout: Feature map distortion to regularize deep neural
  networks.
\newblock In {\em AAAI}, pages 5964--5971, 2020.

\bibitem{tang2020reborn}
Yehui Tang, Shan You, Chang Xu, Jin Han, Chen Qian, Boxin Shi, Chao Xu, and
  Changshui Zhang.
\newblock Reborn filters: Pruning convolutional neural networks with limited
  data.
\newblock In {\em AAAI}, pages 5972--5980, 2020.

\bibitem{tang2019bringing}
Yehui Tang, Shan You, Chang Xu, Boxin Shi, and Chao Xu.
\newblock Bringing giant neural networks down to earth with unlabeled data.
\newblock {\em arXiv preprint arXiv:1907.06065}, 2019.

\bibitem{tian2019fcos}
Zhi Tian, Chunhua Shen, Hao Chen, and Tong He.
\newblock Fcos: Fully convolutional one-stage object detection.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 9627--9636, 2019.

\bibitem{villegas2019high}
Ruben Villegas, Arkanath Pathak, Harini Kannan, Dumitru Erhan, Quoc~V Le, and
  Honglak Lee.
\newblock High fidelity video prediction with large stochastic recurrent neural
  networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  81--91, 2019.

\bibitem{NIPS2019_8525}
Yixing Xu, Yunhe Wang, Hanting Chen, Kai Han, Chunjing XU, Dacheng Tao, and
  Chang Xu.
\newblock Positive-unlabeled compression on the cloud.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems 32}, pages 2565--2574. Curran Associates,
  Inc., 2019.

\bibitem{Yang_2020_CVPR}
Zhaohui Yang, Yunhe Wang, Xinghao Chen, Boxin Shi, Chao Xu, Chunjing Xu,
  Qi~Tian, and Chang Xu.
\newblock Cars: Continuous evolution for efficient neural architecture search.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem{yang2020searching}
Zhaohui Yang, Yunhe Wang, Kai Han, Chunjing Xu, Chao Xu, Dacheng Tao, and Chang
  Xu.
\newblock Searching for low-bit weights in quantized neural networks.
\newblock {\em arXiv preprint arXiv:2009.08695}, 2020.

\bibitem{yang2019legonet}
Zhaohui Yang, Yunhe Wang, Chuanjian Liu, Hanting Chen, Chunjing Xu, Boxin Shi,
  Chao Xu, and Chang Xu.
\newblock Legonet: Efficient convolutional neural networks with lego filters.
\newblock In {\em International Conference on Machine Learning}, pages
  7005--7014, 2019.

\bibitem{you2018learning}
Shan You, Chang Xu, Chao Xu, and Dacheng Tao.
\newblock Learning with single-teacher multi-student.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{yu2017compressing}
Xiyu Yu, Tongliang Liu, Xinchao Wang, and Dacheng Tao.
\newblock On compressing deep models by low rank and sparse decomposition.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 7370--7379, 2017.

\bibitem{zhao2019object}
Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, and Xindong Wu.
\newblock Object detection with deep learning: A review.
\newblock {\em IEEE transactions on neural networks and learning systems},
  30(11):3212--3232, 2019.

\bibitem{zhou2019accelerate}
Yuefu Zhou, Ya~Zhang, Yanfeng Wang, and Qi~Tian.
\newblock Accelerate cnn via recursive bayesian pruning.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 3306--3315, 2019.

\bibitem{NIPS2018_7367}
Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu,
  Junzhou Huang, and Jinhui Zhu.
\newblock Discrimination-aware channel pruning for deep neural networks.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems 31}, pages 875--886. Curran Associates, Inc., 2018.

\bibitem{zhuo2020cogradient}
Li'an Zhuo, Baochang Zhang, Linlin Yang, Hanlin Chen, Qixiang Ye, David
  Doermann, Rongrong Ji, and Guodong Guo.
\newblock Cogradient descent for bilinear optimization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7959--7967, 2020.

\end{thebibliography}
