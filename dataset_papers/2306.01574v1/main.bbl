\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abid et~al.(2022)Abid, Yuksekgonul, and Zou]{abid2022meaningfully}
Abid, A., Yuksekgonul, M., and Zou, J.
\newblock Meaningfully debugging model mistakes using conceptual counterfactual
  explanations.
\newblock In \emph{International Conference on Machine Learning}, pp.\  66--88.
  PMLR, 2022.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1613--1622. PMLR, 2015.

\bibitem[Bohle et~al.(2021)Bohle, Fritz, and Schiele]{bohle2021convolutional}
Bohle, M., Fritz, M., and Schiele, B.
\newblock Convolutional dynamic alignment networks for interpretable
  classifications.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10029--10038, 2021.

\bibitem[Chauhan et~al.(2022)Chauhan, Tiwari, Freyberg, Shenoy, and
  Dvijotham]{chauhan2022interactive}
Chauhan, K., Tiwari, R., Freyberg, J., Shenoy, P., and Dvijotham, K.
\newblock Interactive concept bottleneck models.
\newblock \emph{arXiv preprint arXiv:2212.07430}, 2022.

\bibitem[Chen et~al.(2019)Chen, Li, Tao, Barnett, Rudin, and Su]{chen2019looks}
Chen, C., Li, O., Tao, D., Barnett, A., Rudin, C., and Su, J.~K.
\newblock This looks like that: deep learning for interpretable image
  recognition.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8930--8941, 2019.

\bibitem[Chen et~al.(2020)Chen, Bei, and Rudin]{chen2020concept}
Chen, Z., Bei, Y., and Rudin, C.
\newblock Concept whitening for interpretable image recognition.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (12):\penalty0
  772--782, 2020.

\bibitem[Chun et~al.(2021)Chun, Oh, De~Rezende, Kalantidis, and
  Larlus]{chun2021probabilistic}
Chun, S., Oh, S.~J., De~Rezende, R.~S., Kalantidis, Y., and Larlus, D.
\newblock Probabilistic embeddings for cross-modal retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8415--8424, 2021.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017improved}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Esteva et~al.(2019)Esteva, Robicquet, Ramsundar, Kuleshov, DePristo,
  Chou, Cui, Corrado, Thrun, and Dean]{esteva2019guide}
Esteva, A., Robicquet, A., Ramsundar, B., Kuleshov, V., DePristo, M., Chou, K.,
  Cui, C., Corrado, G., Thrun, S., and Dean, J.
\newblock A guide to deep learning in healthcare.
\newblock \emph{Nature medicine}, 25\penalty0 (1):\penalty0 24--29, 2019.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{pmlr-v48-gal16}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1050--1059. PMLR, 2016.

\bibitem[Goyal et~al.(2019)Goyal, Wu, Ernst, Batra, Parikh, and
  Lee]{goyal2019counterfactual}
Goyal, Y., Wu, Z., Ernst, J., Batra, D., Parikh, D., and Lee, S.
\newblock Counterfactual visual explanations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2376--2384. PMLR, 2019.

\bibitem[Havasi et~al.(2022)Havasi, Parbhoo, and
  Doshi-Velez]{havasi2022addressing}
Havasi, M., Parbhoo, S., and Doshi-Velez, F.
\newblock Addressing leakage in concept bottleneck models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  770--778, 2016.

\bibitem[Heo et~al.(2021)Heo, Chun, Oh, Han, Yun, Kim, Uh, and
  Ha]{heo2021adamp}
Heo, B., Chun, S., Oh, S.~J., Han, D., Yun, S., Kim, G., Uh, Y., and Ha, J.-W.
\newblock Adamp: Slowing down the slowdown for momentum optimizers on
  scale-invariant weights.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  448--456. PMLR, 2015.

\bibitem[Jung et~al.(2020)Jung, Lee, Yi, and Yoon]{jung2020icaps}
Jung, D., Lee, J., Yi, J., and Yoon, S.
\newblock icaps: An interpretable classifier via disentangled capsule networks.
\newblock In \emph{European Conference on Computer Vision}, pp.\  314--330.
  Springer, 2020.

\bibitem[Kendall \& Gal(2017)Kendall and Gal]{kendall2017uncertainties}
Kendall, A. and Gal, Y.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Kim et~al.(2018{\natexlab{a}})Kim, Wattenberg, Gilmer, Cai, Wexler,
  Viegas, et~al.]{kim2018interpretability}
Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., et~al.
\newblock Interpretability beyond feature attribution: Quantitative testing
  with concept activation vectors (tcav).
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2668--2677. PMLR, 2018{\natexlab{a}}.

\bibitem[Kim et~al.(2018{\natexlab{b}})Kim, Kim, Seo, Kim, Park, Park, Jo, Kim,
  Yang, Kim, et~al.]{kim2018nsml}
Kim, H., Kim, M., Seo, D., Kim, J., Park, H., Park, S., Jo, H., Kim, K., Yang,
  Y., Kim, Y., et~al.
\newblock Nsml: Meet the mlaas platform with a real-world case study.
\newblock \emph{arXiv preprint arXiv:1810.09957}, 2018{\natexlab{b}}.

\bibitem[Koh et~al.(2020)Koh, Nguyen, Tang, Mussmann, Pierson, Kim, and
  Liang]{koh2020concept}
Koh, P.~W., Nguyen, T., Tang, Y.~S., Mussmann, S., Pierson, E., Kim, B., and
  Liang, P.
\newblock Concept bottleneck models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5338--5348. PMLR, 2020.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{lecun2010mnist}
LeCun, Y., Cortes, C., and Burges, C.
\newblock Mnist handwritten digit database.
\newblock \emph{ATT Labs [Online]. Available:
  http://yann.lecun.com/exdb/mnist}, 2, 2010.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{loshchilov2017sgdr}
Loshchilov, I. and Hutter, F.
\newblock {SGDR}: Stochastic gradient descent with warm restarts.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Mahinpei et~al.(2021)Mahinpei, Clark, Lage, Doshi-Velez, and
  WeiWei]{mahinpei2021promises}
Mahinpei, A., Clark, J., Lage, I., Doshi-Velez, F., and WeiWei, P.
\newblock Promises and pitfalls of black-box concept learning models.
\newblock In \emph{Workshop on Theoretic Foundation, Criticism, and Application
  Trend of Explainable AI, ICML}, 2021.

\bibitem[Marconato et~al.(2022)Marconato, Passerini, and
  Teso]{marconato2022glancenets}
Marconato, E., Passerini, A., and Teso, S.
\newblock Glancenets: Interpretable, leak-proof concept-based models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Melis \& Jaakkola(2018)Melis and Jaakkola]{melis2018towards}
Melis, D.~A. and Jaakkola, T.
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7775--7784, 2018.

\bibitem[Miller(2019)]{miller2019explanation}
Miller, T.
\newblock Explanation in artificial intelligence: Insights from the social
  sciences.
\newblock \emph{Artificial Intelligence}, 267:\penalty0 1--38, 2019.

\bibitem[Nair \& Hinton(2010)Nair and Hinton]{nair2010rectified}
Nair, V. and Hinton, G.~E.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning}, pp.\  807--814, 2010.

\bibitem[Oh et~al.(2019)Oh, Gallagher, Murphy, Schroff, Pan, and
  Roth]{oh2018modeling}
Oh, S.~J., Gallagher, A.~C., Murphy, K.~P., Schroff, F., Pan, J., and Roth, J.
\newblock Modeling uncertainty with hedged instance embeddings.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Pearson(1901)]{pearson1901liii}
Pearson, K.
\newblock Liii. on lines and planes of closest fit to systems of points in
  space.
\newblock \emph{The London, Edinburgh, and Dublin philosophical magazine and
  journal of science}, 2\penalty0 (11):\penalty0 559--572, 1901.

\bibitem[Rudin(2019)]{rudin2019stop}
Rudin, C.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock \emph{Nature Machine Intelligence}, 1\penalty0 (5):\penalty0
  206--215, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Sarkar et~al.(2022)Sarkar, Vijaykeerthy, Sarkar, and
  Balasubramanian]{sarkar2022framework}
Sarkar, A., Vijaykeerthy, D., Sarkar, A., and Balasubramanian, V.~N.
\newblock A framework for learning ante-hoc explainable models via concepts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10286--10295, 2022.

\bibitem[Sheth et~al.(2022)Sheth, Rahman, Sevyeri, Havaei, and
  Kahou]{sheth2022learning}
Sheth, I., Rahman, A.~A., Sevyeri, L.~R., Havaei, M., and Kahou, S.~E.
\newblock Learning from uncertain concepts via test time interventions.
\newblock In \emph{Workshop on Trustworthy and Socially Responsible Machine
  Learning, NeurIPS}, 2022.

\bibitem[Shi \& Jain(2019)Shi and Jain]{shi2019probabilistic}
Shi, Y. and Jain, A.~K.
\newblock Probabilistic face embeddings.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  6902--6911, 2019.

\bibitem[Shin et~al.(2022)Shin, Jo, Ahn, and Lee]{shin2022a}
Shin, S., Jo, Y., Ahn, S., and Lee, N.
\newblock A closer look at the intervention procedure of concept bottleneck
  models.
\newblock In \emph{Workshop on Trustworthy and Socially Responsible Machine
  Learning, NeurIPS}, 2022.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Simonyan, K., Vedaldi, A., and Zisserman, A.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{wah2011caltech}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem[Xian et~al.(2018)Xian, Lampert, Schiele, and Akata]{xian2018zero}
Xian, Y., Lampert, C.~H., Schiele, B., and Akata, Z.
\newblock Zero-shot learning—a comprehensive evaluation of the good, the bad
  and the ugly.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 41\penalty0 (9):\penalty0 2251--2265, 2018.

\bibitem[Yuksekgonul et~al.(2023)Yuksekgonul, Wang, and
  Zou]{yuksekgonul2022post}
Yuksekgonul, M., Wang, M., and Zou, J.
\newblock Post-hoc concept bottleneck models.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Zarlenga et~al.(2022)Zarlenga, Barbiero, Ciravegna, Marra, Giannini,
  Diligenti, Shams, Precioso, Melacci, Weller, Lio, and
  Jamnik]{zarlenga2022concept}
Zarlenga, M.~E., Barbiero, P., Ciravegna, G., Marra, G., Giannini, F.,
  Diligenti, M., Shams, Z., Precioso, F., Melacci, S., Weller, A., Lio, P., and
  Jamnik, M.
\newblock Concept embedding models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Zhou et~al.(2018)Zhou, Sun, Bau, and Torralba]{zhou2018interpretable}
Zhou, B., Sun, Y., Bau, D., and Torralba, A.
\newblock Interpretable basis decomposition for visual explanation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  119--134, 2018.

\end{thebibliography}
