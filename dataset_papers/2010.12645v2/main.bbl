\begin{thebibliography}{69}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abel et~al.(2018)Abel, Jinnai, Guo, Konidaris, and
  Littman]{abel2018policy}
D.~Abel, Y.~Jinnai, S.~Y. Guo, G.~Konidaris, and M.~Littman.
\newblock Policy and value transfer in lifelong reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages 20--29,
  2018.

\bibitem[Achiam et~al.(2017)Achiam, Held, Tamar, and
  Abbeel]{achiam2017constrained}
J.~Achiam, D.~Held, A.~Tamar, and P.~Abbeel.
\newblock Constrained policy optimization.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 22--31. JMLR. org, 2017.

\bibitem[Al-Shedivat et~al.(2017)Al-Shedivat, Bansal, Burda, Sutskever,
  Mordatch, and Abbeel]{al2017continuous}
M.~Al-Shedivat, T.~Bansal, Y.~Burda, I.~Sutskever, I.~Mordatch, and P.~Abbeel.
\newblock Continuous adaptation via meta-learning in nonstationary and
  competitive environments.
\newblock \emph{arXiv preprint arXiv:1710.03641}, 2017.

\bibitem[Ammar et~al.(2015)Ammar, Tutunov, and Eaton]{ammar2015safe}
H.~B. Ammar, R.~Tutunov, and E.~Eaton.
\newblock Safe policy search for lifelong reinforcement learning with sublinear
  regret.
\newblock In \emph{International Conference on Machine Learning}, pages
  2361--2369, 2015.

\bibitem[Bastani(2014)]{bastani2014model}
M.~Bastani.
\newblock Model-free intelligent diabetes management using machine learning.
\newblock \emph{M.S. Thesis, University of Alberta}, 2014.

\bibitem[Benjamini and Hochberg(1995)]{benjamini1995controlling}
Y.~Benjamini and Y.~Hochberg.
\newblock Controlling the false discovery rate: A practical and powerful
  approach to multiple testing.
\newblock \emph{Journal of the {R}oyal {S}tatistical {S}ociety: {S}eries B
  (Methodological)}, 57\penalty0 (1):\penalty0 289--300, 1995.

\bibitem[Bertsekas and Tsitsiklis(1996)]{neuro}
D.~P. Bertsekas and J.~N. Tsitsiklis.
\newblock \emph{Neuro-Dynamic Programming}.
\newblock Athena Scientific, 1st edition, 1996.
\newblock ISBN 1886529108.

\bibitem[Blondel et~al.(2020)Blondel, Teboul, Berthet, and
  Djolonga]{blondel2020fast}
M.~Blondel, O.~Teboul, Q.~Berthet, and J.~Djolonga.
\newblock Fast differentiable sorting and ranking.
\newblock \emph{arXiv preprint arXiv:2002.08871}, 2020.

\bibitem[Bloomfield(2004)]{bloomfield2004fourier}
P.~Bloomfield.
\newblock \emph{Fourier analysis of time series: An introduction}.
\newblock John Wiley \& Sons, 2004.

\bibitem[Brunskill and Li(2014)]{brunskill2014pac}
E.~Brunskill and L.~Li.
\newblock {PAC}-inspired option discovery in lifelong reinforcement learning.
\newblock In \emph{International conference on machine learning}, pages
  316--324, 2014.

\bibitem[Carpenter and Bithell(2000)]{carpenter2000bootstrap}
J.~Carpenter and J.~Bithell.
\newblock Bootstrap confidence intervals: When, which, what? {A} practical
  guide for medical statisticians.
\newblock \emph{Statistics in Medicine}, 19\penalty0 (9):\penalty0 1141--1164,
  2000.

\bibitem[Chandak et~al.(2020{\natexlab{a}})Chandak, Theocharous, Nota, and
  Thomas]{chandak2020lifelong}
Y.~Chandak, G.~Theocharous, C.~Nota, and P.~S. Thomas.
\newblock Lifelong learning with a changing action set.
\newblock In \emph{Proceedings of the 34th AAAI Conference on Artificial
  Intelligence}, pages 3373--3380, 2020{\natexlab{a}}.

\bibitem[Chandak et~al.(2020{\natexlab{b}})Chandak, Theocharous, Shankar,
  White, Mahadevan, and Thomas]{chandak2020future}
Y.~Chandak, G.~Theocharous, S.~Shankar, M.~White, S.~Mahadevan, and P.~S.
  Thomas.
\newblock Optimizing for the future in non-stationary {MDP}s.
\newblock \emph{In Proceedings of the 37th International Conference on Machine
  Learning}, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2009)Chen, Pedersen, Bak-Jensen, and Chen]{chen2009arima}
P.~Chen, T.~Pedersen, B.~Bak-Jensen, and Z.~Chen.
\newblock {ARIMA}-based time series model of stochastic wind power generation.
\newblock \emph{IEEE {T}ransactions on {P}ower {S}ystems}, 25\penalty0
  (2):\penalty0 667--676, 2009.

\bibitem[Chen et~al.(2003)Chen, H{\"a}rdle, and Li]{chen2003empirical}
S.~X. Chen, W.~H{\"a}rdle, and M.~Li.
\newblock An empirical likelihood goodness-of-fit test for time series.
\newblock \emph{Journal of the Royal Statistical Society: {S}eries B
  (Statistical Methodology)}, 65\penalty0 (3):\penalty0 663--678, 2003.

\bibitem[Cheung et~al.(2020)Cheung, Simchi-Levi, and Zhu]{Cheung2020drifting}
W.~C. Cheung, D.~Simchi-Levi, and R.~Zhu.
\newblock Drifting reinforcement learning: The blessing of (more) optimism in
  face of endogenous \& exogenous dynamics.
\newblock \emph{Arxiv. 1906.02922v3}, 2020.

\bibitem[Chow et~al.(2018)Chow, Nachum, Duenez-Guzman, and
  Ghavamzadeh]{chow2018lyapunov}
Y.~Chow, O.~Nachum, E.~Duenez-Guzman, and M.~Ghavamzadeh.
\newblock A {L}yapunov-based approach to safe reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8092--8101, 2018.

\bibitem[Cuturi et~al.(2019)Cuturi, Teboul, and Vert]{cuturi2019differentiable}
M.~Cuturi, O.~Teboul, and J.-P. Vert.
\newblock Differentiable ranking and sorting using optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6858--6868, 2019.

\bibitem[Davidson and Flachaire(1999)]{davidson1999wild}
R.~Davidson and E.~Flachaire.
\newblock The wild bootstrap, tamed at last.
\newblock \emph{Citeseer}, 1999.

\bibitem[Davidson and Flachaire(2008)]{davidson2008wild}
R.~Davidson and E.~Flachaire.
\newblock The wild bootstrap, tamed at last.
\newblock \emph{Journal of Econometrics}, 146\penalty0 (1):\penalty0 162--169,
  2008.

\bibitem[DiCiccio and Efron(1996)]{diciccio1996bootstrap}
T.~J. DiCiccio and B.~Efron.
\newblock Bootstrap confidence intervals.
\newblock \emph{Statistical {S}cience}, pages 189--212, 1996.

\bibitem[Djogbenou et~al.(2015)Djogbenou, Gon{\c{c}}alves, and
  Perron]{djogbenou2015bootstrap}
A.~Djogbenou, S.~Gon{\c{c}}alves, and B.~Perron.
\newblock Bootstrap inference in regressions with estimated factors and serial
  correlation.
\newblock \emph{Journal of Time Series Analysis}, 36\penalty0 (3):\penalty0
  481--502, 2015.

\bibitem[Djogbenou et~al.(2019)Djogbenou, MacKinnon, and
  Nielsen]{djogbenou2019asymptotic}
A.~A. Djogbenou, J.~G. MacKinnon, and M.~{\O}. Nielsen.
\newblock Asymptotic theory and wild bootstrap inference with clustered errors.
\newblock \emph{Journal of Econometrics}, 212\penalty0 (2):\penalty0 393--412,
  2019.

\bibitem[Efron and Tibshirani(1994)]{efron1994introduction}
B.~Efron and R.~J. Tibshirani.
\newblock \emph{An introduction to the bootstrap}.
\newblock CRC press, 1994.

\bibitem[Friedrich et~al.(2020)Friedrich, Smeekes, and
  Urbain]{friedrich2020autoregressive}
M.~Friedrich, S.~Smeekes, and J.-P. Urbain.
\newblock Autoregressive wild bootstrap inference for nonparametric trends.
\newblock \emph{Journal of Econometrics}, 214\penalty0 (1):\penalty0 81--109,
  2020.

\bibitem[Garc{\i}a and Fern{\'a}ndez(2015)]{garcia2015comprehensive}
J.~Garc{\i}a and F.~Fern{\'a}ndez.
\newblock A comprehensive survey on safe reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 16\penalty0
  (1):\penalty0 1437--1480, 2015.

\bibitem[Godfrey and Tremayne(2005)]{godfrey2005wild}
L.~Godfrey and A.~Tremayne.
\newblock The wild bootstrap and heteroskedasticity-robust tests for serial
  correlation in dynamic regression models.
\newblock \emph{Computational {S}tatistics \& {D}ata {A}nalysis}, 49\penalty0
  (2):\penalty0 377--395, 2005.

\bibitem[Hall(1989)]{hall1989unusual}
P.~Hall.
\newblock Unusual properties of bootstrap confidence intervals in regression
  problems.
\newblock \emph{Probability Theory and Related Fields}, 81\penalty0
  (2):\penalty0 247--273, 1989.

\bibitem[Hall(2013)]{hall2013bootstrap}
P.~Hall.
\newblock \emph{The bootstrap and Edgeworth expansion}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Jagerman et~al.(2019)Jagerman, {M}arkov, and
  de~Rijke]{jagerman2019people}
R.~Jagerman, I.~{M}arkov, and M.~de~Rijke.
\newblock When people change their mind: Off-policy evaluation in
  non-stationary recommendation environments.
\newblock In \emph{Proceedings of the Twelfth ACM International Conference on
  Web Search and Data Mining}, pages 447--455, 2019.

\bibitem[Jiang and Li(2015)]{jiang2015doubly}
N.~Jiang and L.~Li.
\newblock Doubly robust off-policy value evaluation for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1511.03722}, 2015.

\bibitem[Jordan et~al.(2018)Jordan, Cohen, and Thomas]{jordan2018using}
S.~M. Jordan, D.~Cohen, and P.~S. Thomas.
\newblock Using cumulative distribution based performance analysis to benchmark
  models.
\newblock In \emph{NeurIPS 2018 Workshop on Critiquing and Correcting Trends in
  Machine Learning}, 2018.

\bibitem[Kakade and Langford(2002)]{kakade2002approximately}
S.~Kakade and J.~Langford.
\newblock Approximately optimal approximate reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2002.

\bibitem[Kazerouni et~al.(2017)Kazerouni, Ghavamzadeh, Yadkori, and
  Van~Roy]{kazerouni2017conservative}
A.~Kazerouni, M.~Ghavamzadeh, Y.~A. Yadkori, and B.~Van~Roy.
\newblock Conservative contextual linear bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3910--3919, 2017.

\bibitem[Kearns and Singh(2002)]{kearns2002near}
M.~Kearns and S.~Singh.
\newblock Near-optimal reinforcement learning in polynomial time.
\newblock \emph{Machine learning}, 2002.

\bibitem[Kline and Santos(2012)]{kline2012higher}
P.~Kline and A.~Santos.
\newblock Higher order properties of the wild bootstrap under misspecification.
\newblock \emph{Journal of Econometrics}, 171\penalty0 (1):\penalty0 54--70,
  2012.

\bibitem[Kovatchev et~al.(2009)Kovatchev, Breton, Dalla~Man, and
  Cobelli]{kovatchev2009silico}
B.~P. Kovatchev, M.~Breton, C.~Dalla~Man, and C.~Cobelli.
\newblock In-silico preclinical trials: {A} proof of concept in closed-loop
  control of type 1 diabetes, 2009.

\bibitem[Laroche et~al.(2017)Laroche, Trichelair, and Combes]{laroche2017safe}
R.~Laroche, P.~Trichelair, and R.~T.~d. Combes.
\newblock Safe policy improvement with baseline bootstrapping.
\newblock \emph{arXiv preprint arXiv:1712.06924}, 2017.

\bibitem[Lecarpentier and Rachelson(2019)]{lecarpentier2019non}
E.~Lecarpentier and E.~Rachelson.
\newblock Non-stationary {M}arkov decision processes, a worst-case approach
  using model-based reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  7214--7223, 2019.

\bibitem[Lecarpentier et~al.(2020)Lecarpentier, Abel, Asadi, Jinnai, Rachelson,
  and Littman]{lecarpentier2020lipschitz}
E.~Lecarpentier, D.~Abel, K.~Asadi, Y.~Jinnai, E.~Rachelson, and M.~L. Littman.
\newblock Lipschitz lifelong reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2001.05411}, 2020.

\bibitem[Liu et~al.(1988)]{liu1988bootstrap}
R.~Y. Liu et~al.
\newblock Bootstrap procedures under some non-iid models.
\newblock \emph{The {A}nnals of {S}tatistics}, 16\penalty0 (4):\penalty0
  1696--1708, 1988.

\bibitem[MacKinnon(2012)]{mackinnon2012inference}
J.~G. MacKinnon.
\newblock Inference based on the wild bootstrap.
\newblock In \emph{Seminar presentation given to Carleton University in
  September}, 2012.

\bibitem[Mammen(1993)]{mammen1993bootstrap}
E.~Mammen.
\newblock Bootstrap and wild bootstrap for high dimensional linear models.
\newblock \emph{The {A}nnals of {S}tatistics}, pages 255--285, 1993.

\bibitem[Man et~al.(2014)Man, Micheletto, Lv, Breton, Kovatchev, and
  Cobelli]{man2014uva}
C.~D. Man, F.~Micheletto, D.~Lv, M.~Breton, B.~Kovatchev, and C.~Cobelli.
\newblock The {UVA/PADOVA} type 1 diabetes simulator: {N}ew features.
\newblock \emph{Journal of Diabetes Science and Technology}, 8\penalty0
  (1):\penalty0 26--34, 2014.

\bibitem[Metevier et~al.(2019)Metevier, Giguere, Brockman, Kobren, Brun,
  Brunskill, and Thomas]{metevier2019offline}
B.~Metevier, S.~Giguere, S.~Brockman, A.~Kobren, Y.~Brun, E.~Brunskill, and
  P.~S. Thomas.
\newblock Offline contextual bandits with high probability fairness guarantees.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  14893--14904, 2019.

\bibitem[Pineau et~al.(2009)Pineau, Guez, Vincent, Panuccio, and
  Avoli]{pineau2009treating}
J.~Pineau, A.~Guez, R.~Vincent, G.~Panuccio, and M.~Avoli.
\newblock Treating epilepsy via adaptive neurostimulation: A reinforcement
  learning approach.
\newblock \emph{International Journal of Neural Systems}, 2009.

\bibitem[Pirotta et~al.(2013)Pirotta, Restelli, Pecorino, and
  Calandriello]{pirotta2013safe}
M.~Pirotta, M.~Restelli, A.~Pecorino, and D.~Calandriello.
\newblock Safe policy iteration.
\newblock In \emph{International Conference on Machine Learning}, pages
  307--315, 2013.

\bibitem[Precup(2000)]{precup2000eligibility}
D.~Precup.
\newblock Eligibility traces for off-policy policy evaluation.
\newblock \emph{Computer Science Department Faculty Publication Series},
  page~80, 2000.

\bibitem[Ravindran and Barto(2004)]{ravindran2004approximate}
B.~Ravindran and A.~G. Barto.
\newblock Approximate homomorphisms: A framework for non-exact minimization in
  {M}arkov decision processes.
\newblock In \emph{Proceedings of the Fifth International Conference on
  Knowledge Based Computer Systems}, 2004.

\bibitem[Saria(2018)]{saria2018individualized}
S.~Saria.
\newblock Individualized sepsis treatment using reinforcement learning.
\newblock \emph{Nature Medicine}, 24\penalty0 (11):\penalty0 1641--1642, 2018.

\bibitem[Shalev-Shwartz et~al.(2012)]{shalev2012online}
S.~Shalev-Shwartz et~al.
\newblock Online learning and online convex optimization.
\newblock \emph{Foundations and Trends in Machine Learning}, 4\penalty0
  (2):\penalty0 107--194, 2012.

\bibitem[Student(1908)]{student1908probable}
Student.
\newblock The probable error of a mean.
\newblock \emph{Biometrika}, pages 1--25, 1908.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Theocharous et~al.(2015)Theocharous, Thomas, and
  Ghavamzadeh]{theocharous2015personalized}
G.~Theocharous, P.~S. Thomas, and M.~Ghavamzadeh.
\newblock Personalized ad recommendation systems for life-time value
  optimization with guarantees.
\newblock In \emph{Twenty-Fourth International Joint Conference on Artificial
  Intelligence}, 2015.

\bibitem[Theocharous et~al.(2020)Theocharous, Chandak, Thomas, and
  de~Nijs]{theocharous2020reinforcement}
G.~Theocharous, Y.~Chandak, P.~S. Thomas, and F.~de~Nijs.
\newblock Reinforcement learning for strategic recommendations.
\newblock \emph{arXiv preprint arXiv:2009.07346}, 2020.

\bibitem[Thomas and Brunskill(2016)]{thomas2016data}
P.~Thomas and E.~Brunskill.
\newblock Data-efficient off-policy policy evaluation for reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2139--2148, 2016.

\bibitem[Thomas et~al.(2015{\natexlab{a}})Thomas, Theocharous, and
  Ghavamzadeh]{thomas2015high}
P.~Thomas, G.~Theocharous, and M.~Ghavamzadeh.
\newblock High confidence policy improvement.
\newblock In \emph{International Conference on Machine Learning}, pages
  2380--2388, 2015{\natexlab{a}}.

\bibitem[Thomas(2015)]{thomas2015safe}
P.~S. Thomas.
\newblock \emph{Safe reinforcement learning}.
\newblock PhD thesis, University of Massachusetts Libraries, 2015.

\bibitem[Thomas et~al.(2015{\natexlab{b}})Thomas, Theocharous, and
  Ghavamzadeh]{thomas2015higheval}
P.~S. Thomas, G.~Theocharous, and M.~Ghavamzadeh.
\newblock High-confidence off-policy evaluation.
\newblock In \emph{Twenty-Ninth AAAI Conference on Artificial Intelligence},
  2015{\natexlab{b}}.

\bibitem[Thomas et~al.(2017)Thomas, Theocharous, Ghavamzadeh, Durugkar, and
  Brunskill]{thomas2017predictive}
P.~S. Thomas, G.~Theocharous, M.~Ghavamzadeh, I.~Durugkar, and E.~Brunskill.
\newblock Predictive off-policy policy evaluation for nonstationary decision
  problems, with applications to digital marketing.
\newblock In \emph{Conference on Innovative Applications of Artificial
  Intelligence}, 2017.

\bibitem[Thomas et~al.(2019)Thomas, Castro~da Silva, Barto, Giguere, Brun, and
  Brunskill]{thomas2019preventing}
P.~S. Thomas, B.~Castro~da Silva, A.~G. Barto, S.~Giguere, Y.~Brun, and
  E.~Brunskill.
\newblock Preventing undesirable behavior of intelligent machines.
\newblock \emph{Science}, 366\penalty0 (6468):\penalty0 999--1004, 2019.

\bibitem[Wasserman(2013)]{wasserman2013all}
L.~Wasserman.
\newblock \emph{All of statistics: A concise course in statistical inference}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Whitt(1978)]{whitt1978approximations}
W.~Whitt.
\newblock Approximations of dynamic programs, i.
\newblock \emph{Mathematics of Operations Research}, 3\penalty0 (3):\penalty0
  231--243, 1978.

\bibitem[Wieland and Wolters(2013)]{wieland2013forecasting}
V.~Wieland and M.~Wolters.
\newblock Forecasting and policy making.
\newblock In \emph{Handbook of {E}conomic {F}orecasting}, volume~2, pages
  239--325. Elsevier, 2013.

\bibitem[Wu et~al.(1986)]{wu1986jackknife}
C.-F.~J. Wu et~al.
\newblock Jackknife, bootstrap and other resampling methods in regression
  analysis.
\newblock \emph{{T}he {A}nnals of {S}tatistics}, 14\penalty0 (4):\penalty0
  1261--1295, 1986.

\bibitem[Wu et~al.(2018)Wu, Chen, Yang, Wang, Tan, Zhang, Xu, and
  Gai]{wu2018budget}
D.~Wu, X.~Chen, X.~Yang, H.~Wang, Q.~Tan, X.~Zhang, J.~Xu, and K.~Gai.
\newblock Budget constrained bidding by model-free reinforcement learning in
  display advertising.
\newblock In \emph{Proceedings of the 27th ACM International Conference on
  Information and Knowledge Management}, pages 1443--1451, 2018.

\bibitem[Xie et~al.(2020)Xie, Harrison, and Finn]{xie2020deep}
A.~Xie, J.~Harrison, and C.~Finn.
\newblock Deep reinforcement learning amidst lifelong non-stationarity.
\newblock \emph{arXiv preprint arXiv:2006.10701}, 2020.

\bibitem[Xie(2019)]{simglucose}
J.~Xie.
\newblock \emph{Simglucose v0.2.1 (2018)}, 2019.
\newblock URL \url{https://github.com/jxx123/simglucose}.

\bibitem[Zhang and Cho(2016)]{zhang2016query}
J.~Zhang and K.~Cho.
\newblock Query-efficient imitation learning for end-to-end autonomous driving.
\newblock \emph{arXiv preprint arXiv:1605.06450}, 2016.

\end{thebibliography}
