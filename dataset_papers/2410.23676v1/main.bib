@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})
@String(ICML  =	{ICML})

@article{xiao2024grounding,
  title={Grounding Language Models for Visual Entity Recognition},
  author={Xiao, Zilin and Gong, Ming and Cascante-Bonilla, Paola and Zhang, Xingyao and Wu, Jie and Ordonez, Vicente},
  journal={arXiv preprint arXiv:2402.18695},
  year={2024}
}

@article{shi2023generative,
  title={Generative multimodal entity linking},
  author={Shi, Senbao and Xu, Zhenran and Hu, Baotian and Zhang, Min},
  journal={arXiv preprint arXiv:2306.12725},
  year={2023}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@misc{openai-gpt4vision,
  author = {{OpenAI}},
  title = {GPT-4V(ision) System Card},
  year = {2023},
  howpublished = {System Card},
  url = {URL_of_the_System_Card},
  note = {Version 1.0},
}

@article{awadalla2023openflamingo,
  title={OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models},
  author={Anas Awadalla and Irena Gao and Josh Gardner and Jack Hessel and Yusuf Hanafy and Wanrong Zhu and Kalyani Marathe and Yonatan Bitton and Samir Gadre and Shiori Sagawa and Jenia Jitsev and Simon Kornblith and Pang Wei Koh and Gabriel Ilharco and Mitchell Wortsman and Ludwig Schmidt},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal=NIPS,
  year={2024}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{athousandwords,
  author = {Santurkar, Shibani and Dubois, Yann and Taori, Rohan and Liang, Percy and Hashimoto, Tatsunori},
  title = {Is a Caption Worth a Thousand Images? A Controlled Study for Representation Learning},
  journal = {arXiv preprint arXiv:2207.07635},  
  year = {2022},
}

@inproceedings{lin2022learning,
  title={Learning To Recognize Procedural Activities with Distant Supervision},
  author={Lin, Xudong and Petroni, Fabio and Bertasius, Gedas and Rohrbach, Marcus and Chang, Shih-Fu and Torresani, Lorenzo},
  booktitle={CVPR},
  year={2022}
}

@article{zhao2022lavila,
  title={Learning Video Representations from Large Language Models},
  author={Zhao, Yue and Misra, Ishan and Kr{\"a}henb{\"u}hl, Philipp and Girdhar, Rohit},
  journal={arXiv preprint arXiv:2212.04501},
  year={2022}
}

@inproceedings{zellers2022merlotreserve,
  title={MERLOT Reserve: Multimodal Neural Script Knowledge through Vision and Language and Sound},
  author={Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{yang2021justask,
title={Just ask: Learning to answer questions from millions of narrated videos},
author={Yang, Antoine and Miech, Antoine and Sivic, Josef and Laptev, Ivan and Schmid, Cordelia},
booktitle=ICCV,
year={2021}}

@article{changpinyo2022all,
  title={All you may need for vqa are image captions},
  author={Changpinyo, Soravit and Kukliansky, Doron and Szpektor, Idan and Chen, Xi and Ding, Nan and Soricut, Radu},
  journal={arXiv preprint arXiv:2205.01883},
  year={2022}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{kuznetsova2020open,
  title={The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal=IJCV,
  year={2020},
}

@article{lu2018entity,
  title={Entity-aware image caption generation},
  author={Lu, Di and Whitehead, Spencer and Huang, Lifu and Ji, Heng and Chang, Shih-Fu},
  journal={arXiv preprint arXiv:1804.07889},
  year={2018}
}

@inproceedings{nguyen2023show,
  title={Show, interpret and tell: entity-aware contextualised image captioning in wikipedia},
  author={Nguyen, Khanh and Biten, Ali Furkan and Mafla, Andres and Gomez, Lluis and Karatzas, Dimosthenis},
  booktitle=AAAI,
  year={2023}
}

@article{zhao2023boosting,
  title={Boosting entity-aware image captioning with multi-modal knowledge graph},
  author={Zhao, Wentian and Wu, Xinxiao},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  publisher={IEEE}
}

@article{ayyubi2023video,
  title={Video summarization: towards entity-aware captions},
  author={A Ayyubi, Hammad and Liu, Tianqi and Nagrani, Arsha and Lin, Xudong and Zhang, Mingda and Arnab, Anurag and Han, Feng and Zhu, Yukun and Liu, Jialu and Chang, Shih-Fu},
  journal={arXiv preprint arXiv:2312.02188},
  year={2023}
}

@article{ridnik2021imagenet,
  title={Imagenet-21k pretraining for the masses},
  author={Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
  journal={arXiv preprint arXiv:2104.10972},
  year={2021}
}

@inproceedings{yang2021just,
  title={Just ask: Learning to answer questions from millions of narrated videos},
  author={Yang, Antoine and Miech, Antoine and Sivic, Josef and Laptev, Ivan and Schmid, Cordelia},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{momeni2023verbs,
  title={Verbs in action: Improving verb understanding in video-language models},
  author={Momeni, Liliane and Caron, Mathilde and Nagrani, Arsha and Zisserman, Andrew and Schmid, Cordelia},
  booktitle=ICCV,
  year={2023}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle=ICCV,
  year={2021}
}

@article{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@inproceedings{lerner2022viquae,
  title={ViQuAE, a dataset for knowledge-based visual question answering about named entities},
  author={Lerner, Paul and Ferret, Olivier and Guinaudeau, Camille and Le Borgne, Herv{\'e} and Besan{\c{c}}on, Romaric and Moreno, Jos{\'e} G and Lov{\'o}n Melgarejo, Jes{\'u}s},
  booktitle={ACM SIGIR},
  year={2022}
}

@inproceedings{fu2021mm,
  title={Mm-avs: A full-scale dataset for multi-modal summarization},
  author={Fu, Xiyan and Wang, Jun and Yang, Zhenglu},
  booktitle={NAACL},
  year={2021}
}

@inproceedings{tran2020transform,
  title={Transform and tell: Entity-aware news image captioning},
  author={Tran, Alasdair and Mathews, Alexander and Xie, Lexing},
  booktitle=CVPR,
  year={2020}
}

@article{liu2020visual,
  title={Visual news: Benchmark and challenges in news image captioning},
  author={Liu, Fuxiao and Wang, Yinghan and Wang, Tianlu and Ordonez, Vicente},
  journal={arXiv preprint arXiv:2010.03743},
  year={2020}
}

@inproceedings{biten2019good,
  title={Good news, everyone! context driven entity-aware captioning for news images},
  author={Biten, Ali Furkan and Gomez, Lluis and Rusinol, Mar{\c{c}}al and Karatzas, Dimosthenis},
  booktitle=CVPR,
  year={2019}
}

@techreport{maji13fine-grained,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}


@inproceedings{krause20133d,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={ICCV workshops},
  year={2013}
}

@inproceedings{nilsback2008automated,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={2008 Sixth Indian conference on computer vision, graphics \& image processing},
  year={2008},
}

@article{chen2023can,
  title={Can pre-trained vision and language models answer visual information-seeking questions?},
  author={Chen, Yang and Hu, Hexiang and Luan, Yi and Sun, Haitian and Changpinyo, Soravit and Ritter, Alan and Chang, Ming-Wei},
  journal={arXiv preprint arXiv:2302.11713},
  year={2023}
}

@inproceedings{mensink2023encyclopedic,
  title={Encyclopedic VQA: Visual questions about detailed properties of fine-grained categories},
  author={Mensink, Thomas and Uijlings, Jasper and Castrejon, Lluis and Goel, Arushi and Cadar, Felipe and Zhou, Howard and Sha, Fei and Araujo, Andr{\'e} and Ferrari, Vittorio},
  booktitle=iccv,
  year={2023}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

@article{hsieh2023distilling,
  title={Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes},
  author={Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-Kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alexander and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas},
  journal={arXiv preprint arXiv:2305.02301},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: A family of highly capable multimodal models},
  author={{Gemini Team Google}},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}}

@article{dehghani2021scenic,
  author={Mostafa Dehghani and Alexey Gritsenko and Anurag Arnab and Matthias Minderer and Yi Tay},
  title={{Scenic}: A {JAX} Library for Computer Vision Research and Beyond},
  year={2021},
  journal={arXiv preprint arXiv:2110.11403},
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle=ICML,
  year={2021},
}

@article{sun2023learning,
  title={Learning to tokenize for generative retrieval},
  author={Sun, Weiwei and Yan, Lingyong and Chen, Zheng and Wang, Shuaiqiang and Zhu, Haichao and Ren, Pengjie and Chen, Zhumin and Yin, Dawei and Rijke, Maarten and Ren, Zhaochun},
  journal=NIPS,
  year={2023}
}

@article{mehta2022dsi++,
  title={DSI++: Updating Transformer Memory with New Documents},
  author={Mehta, Sanket Vaibhav and Gupta, Jai and Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Rao, Jinfeng and Najork, Marc and Strubell, Emma and Metzler, Donald},
  journal={arXiv preprint arXiv:2212.09744},
  year={2022}
}

@article{de2020autoregressive,
  title={Autoregressive entity retrieval},
  author={De Cao, Nicola and Izacard, Gautier and Riedel, Sebastian and Petroni, Fabio},
  journal={arXiv preprint arXiv:2010.00904},
  year={2020}
}

@Article{bengio_et_al:DagRep.8.7.62,
  author =	{Bengio, Samy and Dembczynski, Krzysztof and Joachims, Thorsten and Kloft, Marius and Varma, Manik},
  title =	{{Extreme Classification (Dagstuhl Seminar 18291)}},
  journal =	{Dagstuhl Reports},
  year =	{2019},
}

@article{zhu2022webface260m,
  title={Webface260M: A benchmark for million-scale deep face recognition},
  author={Zhu, Zheng and Huang, Guan and Deng, Jiankang and Ye, Yun and Huang, Junjie and Chen, Xinze and Zhu, Jiagang and Yang, Tian and Du, Dalong and Lu, Jiwen and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
}

@inproceedings{weyand2020google,
  title={Google landmarks dataset v2-a large-scale benchmark for instance-level recognition and retrieval},
  author={Weyand, Tobias and Araujo, Andre and Cao, Bingyi and Sim, Jack},
  booktitle=cvpr,
  year={2020}
}

@inproceedings{caron2024generative,
  title={A generative approach for Wikipedia-scale visual entity recognition},
  author={Caron, Mathilde and Iscen, Ahmet and Fathi, Alireza and Schmid, Cordelia},
  booktitle=cvpr,
  year={2024}
}

@inproceedings{agrawal2013multi,
  title={Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages},
  author={Agrawal, Rahul and Gupta, Archit and Prabhu, Yashoteja and Varma, Manik},
  booktitle={Proceedings of the 22nd international conference on World Wide Web},
  pages={13--24},
  year={2013}
}

@inproceedings{mittal2022multi,
  title={Multi-modal extreme classification},
  author={Mittal, Anshul and Dahiya, Kunal and Malani, Shreya and Ramaswamy, Janani and Kuruvilla, Seba and Ajmera, Jitendra and Chang, Keng-hao and Agarwal, Sumeet and Kar, Purushottam and Varma, Manik},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle=ICML,
  year={2019},
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  year={2009},
  publisher={Now Publishers, Inc.}
}


@inproceedings{liu2023learning,
  title={Learning customized visual models with retrieval-augmented knowledge},
  author={Liu, Haotian and Son, Kilho and Yang, Jianwei and Liu, Ce and Gao, Jianfeng and Lee, Yong Jae and Li, Chunyuan},
  booktitle=cvpr,
  year={2023}
}

@article{iscen2023retrieval,
  title={Retrieval-Enhanced Contrastive Vision-Text Models},
  author={Iscen, Ahmet and Caron, Mathilde and Fathi, Alireza and Schmid, Cordelia},
  journal=iclr,
  year={2024}
}

@article{muller2019does,
  title={When does label smoothing help?},
  author={M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
  journal=NIPS,
  year={2019}
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{kudo2018subword,
  title={Subword regularization: Improving neural network translation models with multiple subword candidates},
  author={Kudo, Taku},
  journal={arXiv preprint arXiv:1804.10959},
  year={2018}
}

@article{kudo2018sentencepiece,
  title={Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing},
  author={Kudo, Taku and Richardson, John},
  journal={arXiv preprint arXiv:1808.06226},
  year={2018}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle=CVPR,
  year={2015}
}


@article{wang2022git,
  title={Git: A generative image-to-text transformer for vision and language},
  author={Wang, Jianfeng and Yang, Zhengyuan and Hu, Xiaowei and Li, Linjie and Lin, Kevin and Gan, Zhe and Liu, Zicheng and Liu, Ce and Wang, Lijuan},
  journal={arXiv preprint arXiv:2205.14100},
  year={2022}
}

@inproceedings{ypsilantis2013uned,
  title={Towards Universal Image Embeddings: A Large-Scale Dataset and Challenge for Generic Image Representations},
  author={Ypsilantis, Nikolaos-Antonios and Chen, Kaifeng and Cao, Bingyi and Lipovský, Mário and Dogan-Schönberger, Pelin and Makosa, Grzegorz and Bluntschli, Boris and Seyedhosseini, Mojtaba and Chum, Ondřej and Araujo, André},
  booktitle=ICCV,
  year={2013}
}

@article{zhang2023irgen,
  title={IRGen: Generative Modeling for Image Retrieval},
  author={Zhang, Yidan and Zhang, Ting and Chen, Dong and Wang, Yujing and Chen, Qi and Xie, Xing and Sun, Hao and Deng, Weiwei and Zhang, Qi and Yang, Fan and others},
  journal={arXiv preprint arXiv:2303.10126},
  year={2023}
}

@article{tay2022transformer,
  title={Transformer memory as a differentiable search index},
  author={Tay, Yi and Tran, Vinh and Dehghani, Mostafa and Ni, Jianmo and Bahri, Dara and Mehta, Harsh and Qin, Zhen and Hui, Kai and Zhao, Zhe and Gupta, Jai and others},
  journal=NIPS,
  year={2022}
}

@article{rajput2023recommender,
  title={Recommender Systems with Generative Retrieval},
  author={Rajput, Shashank and Mehta, Nikhil and Singh, Anima and Keshavan, Raghunandan H and Vu, Trung and Heldt, Lukasz and Hong, Lichan and Tay, Yi and Tran, Vinh Q and Samost, Jonah and others},
  journal={arXiv preprint arXiv:2305.05065},
  year={2023}
}

@article{pradeep2023does,
  title={How Does Generative Retrieval Scale to Millions of Passages?},
  author={Pradeep, Ronak and Hui, Kai and Gupta, Jai and Lelkes, Adam D and Zhuang, Honglei and Lin, Jimmy and Metzler, Donald and Tran, Vinh Q},
  journal={arXiv preprint arXiv:2305.11841},
  year={2023}
}

@article{hu2023open,
  title={Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities},
  author={Hu, Hexiang and Luan, Yi and Chen, Yang and Khandelwal, Urvashi and Joshi, Mandar and Lee, Kenton and Toutanova, Kristina and Chang, Ming-Wei},
  journal=iccv,
  year={2023}
}

@article{liang2022open,
  title={Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP},
  author={Liang, Feng and Wu, Bichen and Dai, Xiaoliang and Li, Kunpeng and Zhao, Yinan and Zhang, Hang and Zhang, Peizhao and Vajda, Peter and Marculescu, Diana},
  journal={arXiv preprint arXiv:2210.04150},
  year={2022}
}

@article{minderer2022simple,
  title={Simple open-vocabulary object detection with vision transformers},
  author={Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and others},
  journal={arXiv preprint arXiv:2205.06230},
  year={2022}
}

@article{dong2022maskclip,
  title={Maskclip: Masked self-distillation advances contrastive language-image pretraining},
  author={Dong, Xiaoyi and Zheng, Yinglin and Bao, Jianmin and Zhang, Ting and Chen, Dongdong and Yang, Hao and Zeng, Ming and Zhang, Weiming and Yuan, Lu and Chen, Dong and others},
  journal={arXiv preprint arXiv:2208.12262},
  year={2022}
}

@article{gao2022pyramidclip,
  title={Pyramidclip: Hierarchical feature alignment for vision-language model pretraining},
  author={Gao, Yuting and Liu, Jinfeng and Xu, Zihan and Zhang, Jun and Li, Ke and Ji, Rongrong and Shen, Chunhua},
  journal=NIPS,
  year={2022}
}

@article{pham2021combined,
  title={Combined scaling for open-vocabulary image classification},
  author={Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Kawaguchi, Kenji and Liu, Hanxiao and Yu, Adams Wei and Yu, Jiahui and Chen, Yi-Ting and Luong, Minh-Thang and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2111.10050},
  year={2021}
}

@article{cherti2022reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  journal={arXiv preprint arXiv:2212.07143},
  year={2022}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle=CVPR,
  year={2020}
}

@inproceedings{desai2021virtex,
  title={Virtex: Learning visual representations from textual annotations},
  author={Desai, Karan and Johnson, Justin},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{joulin2016learning,
  title={Learning visual features from large weakly supervised data},
  author={Joulin, Armand and Van Der Maaten, Laurens and Jabri, Allan and Vasilache, Nicolas},
  booktitle=ECCV,
  year={2016},
}

@inproceedings{gomez2017self,
  title={Self-supervised learning of visual features through embedding images into text topic spaces},
  author={Gomez, Lluis and Patel, Yash and Rusinol, Mar{\c{c}}al and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{zhang2022contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  booktitle={Machine Learning for Healthcare Conference},
  year={2022},
}

@inproceedings{guu2020retrieval,
  title={Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle=ICML,
  year={2020},
}

@article{izacard2022few,
  title={Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={arXiv preprint arXiv:2208.03299},
  year={2022}
}

@article{gui2021kat,
  title={Kat: A knowledge augmented transformer for vision-and-language},
  author={Gui, Liangke and Wang, Borui and Huang, Qiuyuan and Hauptmann, Alex and Bisk, Yonatan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2112.08614},
  year={2021}
}

@inproceedings{long2022retrieval,
  title={Retrieval augmented classification for long-tail visual recognition},
  author={Long, Alexander and Yin, Wei and Ajanthan, Thalaiyasingam and Nguyen, Vu and Purkait, Pulak and Garg, Ravi and Blair, Alan and Shen, Chunhua and van den Hengel, Anton},
  booktitle=CVPR,
  year={2022}
}

@article{hu2022reveal,
  title={REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory},
  author={Hu, Ziniu and Iscen, Ahmet and Sun, Chen and Wang, Zirui and Chang, Kai-Wei and Sun, Yizhou and Schmid, Cordelia and Ross, David A and Fathi, Alireza},
  journal={arXiv preprint arXiv:2212.05221},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

@inproceedings{singh2022flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle=CVPR,
  year={2022}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal=NIPS,
  year={2017}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle=CVPR,
  year={2021}
}

@InProceedings{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle=ICLR,
  year={2021}
}


@article{infonce,
  title={Representation Learning with Contrastive Predictive Coding},
  author={A{\"a}ron van den Oord and Yazhe Li and Oriol Vinyals},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018},
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle=ECCV,
  year={2014},
}

@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle=ICCV,
  year={2015}
}

@inproceedings{KhoslaYaoJayadevaprakashFeiFei_FGVC2011,
author = "Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei",
title = "Novel Dataset for Fine-Grained Image Categorization",
booktitle = "First Workshop on Fine-Grained Visual Categorization, CVPR",
year = "2011",
}


@article{zhou2017places,
title={Places: A 10 million Image Database for Scene Recognition},
author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
journal=PAMI,
year={2017},
}


@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal=IJCV,
  year={2015},
}

@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle=ICML,
  year={2021},
}

@inproceedings{hu2023reveal,
  title={REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory},
  author={Hu, Ziniu and Iscen, Ahmet and Sun, Chen and Wang, Zirui and Chang, Kai-Wei and Sun, Yizhou and Schmid, Cordelia and Ross, David A and Fathi, Alireza},
  booktitle=CVPR,
  year={2023}
}

@article{shen2022k,
  title={K-lite: Learning transferable visual models with external knowledge},
  author={Shen, Sheng and Li, Chunyuan and Hu, Xiaowei and Xie, Yujia and Yang, Jianwei and Zhang, Pengchuan and Gan, Zhe and Wang, Lijuan and Yuan, Lu and Liu, Ce and others},
  journal=NIPS,
  year={2022}
}

@book{meyer2012wiktionary,
  title={Wiktionary: A new rival for expert-built lexicons? Exploring the possibilities of collaborative lexicography},
  author={Meyer, Christian M and Gurevych, Iryna},
  year={2012},
  publisher={na}
}

@book{miller1998wordnet,
  title={WordNet: An electronic lexical database},
  author={Miller, George A},
  year={1998},
  publisher={MIT press}
}

@article{banani2023learning,
  title={Learning Visual Representations via Language-Guided Sampling},
  author={Banani, Mohamed El and Desai, Karan and Johnson, Justin},
  journal={arXiv preprint arXiv:2302.12248},
  year={2023}
}

@inproceedings{dwibedi2021little,
  title={With a little help from my friends: Nearest-neighbor contrastive learning of visual representations},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle=CVPR,
  year={2021}
}

@article{iscen2023improving,
  title={Improving Image Recognition by Retrieving from Web-Scale Image-Text Data},
  author={Iscen, Ahmet and Fathi, Alireza and Schmid, Cordelia},
  journal=cvpr,
  year={2023}
}

@article{blattmann2022semi,
  title={Semi-Parametric Neural Image Synthesis},
  author={Blattmann, Andreas and Rombach, Robin and Oktay, Kaan and Müller, Jonas and Ommer, Björn},
  journal={arXiv preprint arXiv:2204.11824},
  year={2022}
}

@article{chen2022re,
  title={Re-Imagen: Retrieval-Augmented Text-to-Image Generator},
  author={Chen, Wenhu and Hu, Hexiang and Saharia, Chitwan and Cohen, William W},
  journal={arXiv preprint arXiv:2209.14491},
  year={2022}
}

@article{pali2022,
  title={Pali: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  journal=ICLR,
  year={2023}
}

@article{khandelwal2019generalization,
  title={Generalization through memorization: Nearest neighbor language models},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  journal=iclr,
  year=2020
}

@article{wang2022training,
  title={Training data is more valuable than you think: A simple and effective method by retrieving from training data},
  author={Wang, Shuohang and Xu, Yichong and Fang, Yuwei and Liu, Yang and Sun, Siqi and Xu, Ruochen and Zhu, Chenguang and Zeng, Michael},
  journal={arXiv preprint arXiv:2203.08773},
  year={2022}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal=nips,
  year={2020}
}


@inproceedings{wu2022memorizing,
title={Memorizing Transformers},
author={Yuhuai Wu and Markus Norman Rabe and DeLesley Hutchins and Christian Szegedy},
booktitle={ICLR},
year={2022},
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle=icml,
  year={2022},
}

@inproceedings{guu2020realm,
  title={{REALM}: Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle=icml,
  year={2020},
}

@inproceedings{guo2020accelerating,
  title={Accelerating large-scale inference with anisotropic vector quantization},
  author={Guo, Ruiqi and Sun, Philip and Lindgren, Erik and Geng, Quan and Simcha, David and Chern, Felix and Kumar, Sanjiv},
  booktitle=icml,
  year={2020},
}


@article{prabhu2020large,
  title={Large image datasets: A pyrrhic win for computer vision?},
  author={Prabhu, Vinay Uday and Birhane, Abeba},
  journal={arXiv preprint arXiv:2006.16923},
  year={2020}
}

@inproceedings{de2019does,
  title={Does object recognition work for everyone?},
  author={De Vries, Terrance and Misra, Ishan and Wang, Changhan and Van der Maaten, Laurens},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle=CVPR,
  year={2015}
}

@inproceedings{van2018inaturalist,
  title={The inaturalist species classification and detection dataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{xiao2010sun,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle=CVPR,
  year={2010},
}

@inproceedings{bossard2014food,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle=ECCV,
  year={2014},
}

@article{maji2013fine,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:1306.5151},
  year={2013}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle=CVPR,
  year={2017}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle=CVPR,
  year={2016}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision},
  volume={123},
  year={2017},
}

@inproceedings{marino2019ok,
  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},
  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle=CVPR,
  year={2019}
}
@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle=CVPR,
  year={2019}
}

@misc{sports100,
	title={Sports100: 100 Sports Image Classification},
	author={Gerry},
	howpublished={\url{https://www.kaggle.com/datasets/gpiosenka/sports-classification/metadata}},
	note={Accessed: 2023-05-23},
	year={2021},
}

@article{udandarao2022sus,
  title={Sus-x: Training-free name-only transfer of vision-language models},
  author={Udandarao, Vishaal and Gupta, Ankush and Albanie, Samuel},
  journal={ICCV},
  year={2023}
}

@inproceedings{xie2023ra,
  title={RA-CLIP: Retrieval Augmented Contrastive Language-Image Pre-Training},
  author={Xie, Chen-Wei and Sun, Siyang and Xiong, Xiong and Zheng, Yun and Zhao, Deli and Zhou, Jingren},
  booktitle={CVPR},
  year={2023}
}

@article{furst2022cloob,
  title={Cloob: Modern hopfield networks with infoloob outperform clip},
  author={F{\"u}rst, Andreas and Rumetshofer, Elisabeth and Lehner, Johannes and Tran, Viet T and Tang, Fei and Ramsauer, Hubert and Kreil, David and Kopp, Michael and Klambauer, G{\"u}nter and Bitto, Angela and others},
  journal=nips,
  year={2022}
}

@article{fan2023improving,
  title={Improving CLIP Training with Language Rewrites},
  author={Fan, Lijie and Krishnan, Dilip and Isola, Phillip and Katabi, Dina and Tian, Yonglong},
  journal={arXiv preprint arXiv:2305.20088},
  year={2023}
}

@inproceedings{bendale2016towards,
  title={Towards open set deep networks},
  author={Bendale, Abhijit and Boult, Terrance E},
  booktitle={CVPR},
  year={2016}
}

@article{scheirer2012toward,
  title={Toward open set recognition},
  author={Scheirer, Walter J and de Rezende Rocha, Anderson and Sapkota, Archana and Boult, Terrance E},
  journal=PAMI,
  volume={35},
  year={2012}
}

@article{lampert2013attribute,
  title={Attribute-based classification for zero-shot visual object categorization},
  author={Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},
  journal=PAMI,
  volume={36},
  year={2013},
}

@article{xian2018zero,
  title={Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly},
  author={Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep},
  journal=PAMI,
  volume={41},
  year={2018},
}

@inproceedings{changpinyo2016synthesized,
  title={Synthesized classifiers for zero-shot learning},
  author={Changpinyo, Soravit and Chao, Wei-Lun and Gong, Boqing and Sha, Fei},
  booktitle={CVPR},
  year={2016}
}

@article{wang2022neural,
  title={A neural corpus indexer for document retrieval},
  author={Wang, Yujing and Hou, Yingyan and Wang, Haonan and Miao, Ziming and Wu, Shibin and Chen, Qi and Xia, Yuqing and Chi, Chengmin and Zhao, Guoshuai and Liu, Zheng and others},
  journal=NIPS,
  year={2022}
}

@article{shi2023parameter,
  title={Parameter-Efficient Long-Tailed Recognition},
  author={Shi, Jiang-Xin and Wei, Tong and Zhou, Zhi and Han, Xin-Yan and Shao, Jie-Jing and Li, Yu-Feng},
  journal={arXiv preprint arXiv:2309.10019},
  year={2023}
}

@inproceedings{iscen2022learning,
  title={Learning with Neighbor Consistency for Noisy Labels},
  author={Iscen, Ahmet and Valmadre, Jack and Arnab, Anurag and Schmid, Cordelia},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{guo2018curriculumnet,
  title={{CurriculumNet}: Weakly supervised learning from large-scale web images},
  author={Guo, Sheng and Huang, Weilin and Zhang, Haozhi and Zhuang, Chenfan and Dong, Dengke and Scott, Matthew R and Huang, Dinglong},
  booktitle=eccv,
  pages={135--150},
  year={2018}
}

@inproceedings{OLTR,
  Author = {Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X.},
  Booktitle = cvpr,
  Title = {Large-Scale Long-Tailed Recognition in an Open World},
  Year = {2019}
  }

@article{li2017webvision,
  title={Webvision database: Visual learning and understanding from web data},
  author={Li, Wen and Wang, Limin and Li, Wei and Agustsson, Eirikur and Van Gool, Luc},
  journal={arXiv preprint arXiv:1708.02862},
  year={2017}
}

@inproceedings{ImageNet,
  Author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  Booktitle = cvpr,
  Title = {Imagenet: A large-scale hierarchical image database},
  Year = {2009}}

@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{touvron2021going,
  title={Going deeper with image transformers},
  author={Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  booktitle=cvpr,
  year={2021}
}

@article{gpt4,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {arXiv preprint arXiv:2303.08774},
  year         = {2023},
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal=IJCV,
  volume={88},
  year={2010},
}

@inproceedings{fei2004learning,
  title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle=cvpr,
  year={2004},
}

@article{ni2021sentence,
  title={Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models},
  author={Ni, Jianmo and {\'A}brego, Gustavo Hern{\'a}ndez and Constant, Noah and Ma, Ji and Hall, Keith B and Cer, Daniel and Yang, Yinfei},
  journal={arXiv preprint arXiv:2108.08877},
  year={2021}
}
