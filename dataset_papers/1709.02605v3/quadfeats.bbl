\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bach(2015)]{bach2015equivalence}
Francis Bach.
\newblock On the equivalence between quadrature rules and random features.
\newblock \emph{arXiv preprint arXiv:1502.06800}, 2015.

\bibitem[Bungartz and Griebel(2004)]{bungartz2004sparse}
Hans-Joachim Bungartz and Michael Griebel.
\newblock Sparse grids.
\newblock \emph{Acta numerica}, 13:\penalty0 147--269, 2004.

\bibitem[Clenshaw and Curtis(1960)]{clenshaw1960method}
Charles~W Clenshaw and Alan~R Curtis.
\newblock A method for numerical integration on an automatic computer.
\newblock \emph{Numerische Mathematik}, 2\penalty0 (1):\penalty0 197--205,
  1960.

\bibitem[Gales(1998)]{gales1998maximum}
Mark~JF Gales.
\newblock Maximum likelihood linear transformations for {HMM}-based speech
  recognition.
\newblock \emph{Computer speech \& language}, 12\penalty0 (2):\penalty0 75--98,
  1998.

\bibitem[Garofolo et~al.(1993)Garofolo, Lamel, Fisher, Fiscus, Pallett, and
  Dahlgren]{timit}
J.~S. Garofolo, L.~F. Lamel, W.~M. Fisher, J.~G. Fiscus, D.~S. Pallett, and
  N.~L. Dahlgren.
\newblock {DARPA} {TIMIT} acoustic phonetic continuous speech corpus {CDROM},
  1993.
\newblock URL \url{http://www.ldc.upenn.edu/Catalog/LDC93S1.html}.

\bibitem[Gauss(1815)]{gauss1815methodus}
Carl~Friedrich Gauss.
\newblock \emph{Methodus nova integralium valores per approximationem
  inveniendi}.
\newblock apvd Henricvm Dieterich, 1815.

\bibitem[Gehring et~al.(2017)Gehring, Auli, Grangier, Yarats, and
  Dauphin]{gehring2017convolutional}
Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann~N Dauphin.
\newblock Convolutional sequence to sequence learning.
\newblock \emph{arXiv preprint arXiv:1705.03122}, 2017.

\bibitem[Gunn and Kandola(2002{\natexlab{a}})]{gunn_structural_2002}
S.~R. Gunn and J.~S. Kandola.
\newblock Structural {Modelling} with {Sparse} {Kernels}.
\newblock \emph{Machine Learning}, 48\penalty0 (1-3):\penalty0 137--163, July
  2002{\natexlab{a}}.
\newblock ISSN 0885-6125, 1573-0565.
\newblock \doi{10.1023/A:1013903804720}.
\newblock URL \url{https://link.springer.com/article/10.1023/A:1013903804720}.

\bibitem[Gunn and Kandola(2002{\natexlab{b}})]{gunn2002structural}
Steve~R. Gunn and Jaz~S. Kandola.
\newblock Structural modelling with sparse kernels.
\newblock \emph{Machine learning}, 48\penalty0 (1-3):\penalty0 137--163,
  2002{\natexlab{b}}.

\bibitem[Hale and Townsend(2013)]{hale2013fast}
Nicholas Hale and Alex Townsend.
\newblock Fast and accurate computation of {Gauss}--{Legendre} and
  {Gauss}--{Jacobi} quadrature nodes and weights.
\newblock \emph{SIAM Journal on Scientific Computing}, 35\penalty0
  (2):\penalty0 A652--A674, 2013.

\bibitem[Hofmann et~al.(2008)Hofmann, Sch{\"o}lkopf, and
  Smola]{hofmann2008kernel}
Thomas Hofmann, Bernhard Sch{\"o}lkopf, and Alexander~J Smola.
\newblock Kernel methods in machine learning.
\newblock \emph{The annals of statistics}, pages 1171--1220, 2008.

\bibitem[Holtz(2010)]{holtz2010sparse}
Markus Holtz.
\newblock \emph{Sparse grid quadrature in high dimensions with applications in
  finance and insurance}, volume~77.
\newblock Springer Science \& Business Media, 2010.

\bibitem[Huang et~al.(2014)Huang, Avron, Sainath, Sindhwani, and
  Ramabhadran]{huang2014kernel}
Po-Sen Huang, Haim Avron, Tara~N Sainath, Vikas Sindhwani, and Bhuvana
  Ramabhadran.
\newblock Kernel methods match deep neural networks on {TIMIT}.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE
  International Conference on}, pages 205--209. IEEE, 2014.

\bibitem[Isaacson and Keller(1994)]{isaacson1994analysis}
Eugene Isaacson and Herbert~Bishop Keller.
\newblock \emph{Analysis of numerical methods}.
\newblock Courier Corporation, 1994.

\bibitem[Kim()]{kim2014convolutional}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1746--1751.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lin et~al.(2014)Lin, Weng, and Zhang]{lin2014sample}
Ming Lin, Shifeng Weng, and Changshui Zhang.
\newblock On the sample complexity of random {Fourier} features for online
  learning: How many random {Fourier} features do we need?
\newblock \emph{ACM Trans. Knowl. Discov. Data}, 2014.

\bibitem[Lu et~al.(2014)Lu, May, Liu, Garakani, Guo, Bellet, Fan, Collins,
  Kingsbury, Picheny, and Sha]{lu_how_2014}
Zhiyun Lu, Avner May, Kuan Liu, Alireza~Bagheri Garakani, Dong Guo, Aurélien
  Bellet, Linxi Fan, Michael Collins, Brian Kingsbury, Michael Picheny, and Fei
  Sha.
\newblock How to scale up kernel methods to be as good as deep neural nets.
\newblock \emph{arXiv:1411.4000 [cs, stat]}, November 2014.
\newblock URL \url{http://arxiv.org/abs/1411.4000}.
\newblock arXiv: 1411.4000.

\bibitem[Lu et~al.(2016)Lu, Quo, Garakani, Liu, May, Bellet, Fan, Collins,
  Kingsbury, Picheny, et~al.]{lu2016comparison}
Zhiyun Lu, Dong Quo, Alireza~Bagheri Garakani, Kuan Liu, Avner May,
  Aur{\'e}lien Bellet, Linxi Fan, Michael Collins, Brian Kingsbury, Michael
  Picheny, et~al.
\newblock A comparison between deep neural nets and kernel acoustic models for
  speech recognition.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
  International Conference on}, pages 5070--5074. IEEE, 2016.

\bibitem[Maji and Malik(2009)]{maji2009fast}
Subhransu Maji and Jitendra Malik.
\newblock Fast and accurate digit classification.
\newblock \emph{EECS Department, University of California, Berkeley, Tech. Rep.
  UCB/EECS-2009-159}, 2009.

\bibitem[May et~al.(2016)May, Collins, Hsu, and Kingsbury]{may2016compact}
Avner May, Michael Collins, Daniel Hsu, and Brian Kingsbury.
\newblock Compact kernel models for acoustic modeling via random feature
  selection.
\newblock In \emph{Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
  International Conference on}, pages 2424--2428. IEEE, 2016.

\bibitem[May et~al.(2017)May, Garakani, Lu, Guo, Liu, Bellet, Fan, Collins,
  Hsu, Kingsbury, et~al.]{may2017kernel}
Avner May, Alireza~Bagheri Garakani, Zhiyun Lu, Dong Guo, Kuan Liu,
  Aur{\'e}lien Bellet, Linxi Fan, Michael Collins, Daniel Hsu, Brian Kingsbury,
  et~al.
\newblock Kernel approximation methods for speech recognition.
\newblock \emph{arXiv preprint arXiv:1701.03577}, 2017.

\bibitem[Rahimi and Recht(2007)]{rahimi2007random}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in neural information processing systems}, pages
  1177--1184, 2007.

\bibitem[Rahimi and Recht(2009)]{rahimi2009weighted}
Ali Rahimi and Benjamin Recht.
\newblock Weighted sums of random kitchen sinks: Replacing minimization with
  randomization in learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  1313--1320, 2009.

\bibitem[Rudin(1990)]{rudin1990fourier}
Walter Rudin.
\newblock \emph{{Fourier} analysis on groups}.
\newblock Number~12. John Wiley \& Sons, 1990.

\bibitem[Sch{\"o}lkopf and Smola(2002)]{scholkopf2002learning}
Bernhard Sch{\"o}lkopf and Alexander~J Smola.
\newblock \emph{Learning with kernels: Support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press, 2002.

\bibitem[Simard et~al.(2003)Simard, Steinkraus, and Platt]{simard2003best}
Patrice~Y Simard, Dave Steinkraus, and John~C Platt.
\newblock Best practices for convolutional neural networks applied to visual
  document analysis.
\newblock In \emph{ICDAR}, page 958. IEEE, 2003.

\bibitem[Smolyak(1963)]{smolyak1963}
S.~A. Smolyak.
\newblock Quadrature and interpolation formulas for tensor products of certain
  class of functions.
\newblock \emph{Dokl. Akad. Nauk SSSR}, 148\penalty0 (5):\penalty0 1042--1053,
  1963.
\newblock Transl.: Soviet Math. Dokl. 4:240-243, 1963.

\bibitem[Sriperumbudur and Szabo(2015)]{sriperumbudur2015rates}
Bharath Sriperumbudur and Zoltan Szabo.
\newblock Optimal rates for random {Fourier} features.
\newblock In C.~Cortes, N.D. Lawrence, D.D. Lee, M.~Sugiyama, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 28}, pages
  1144--1152. Curran Associates, Inc., 2015.

\bibitem[Stitson et~al.(1999)Stitson, Gammerman, Vapnik, Vovk, Watkins, and
  Weston]{stitson1999support}
M~Stitson, Alex Gammerman, Vladimir Vapnik, Volodya Vovk, Chris Watkins, and
  Jason Weston.
\newblock Support vector regression with anova decomposition kernels.
\newblock \emph{Advances in kernel methods—Support vector learning}, pages
  285--292, 1999.

\bibitem[Sutherland and Schneider(2015)]{sutherland2015error}
Dougal~J. Sutherland and Jeff Schneider.
\newblock On the error of random {Fourier} features.
\newblock In \emph{Proceedings of the 31th Annual Conference on {U}ncertainty
  in {A}rtificial {I}ntelligence ({UAI}-15)}. AUAI Press, 2015.

\bibitem[Townsend et~al.(2015)Townsend, Trogdon, and Olver]{townsend2015fast}
Alex Townsend, Thomas Trogdon, and Sheehan Olver.
\newblock Fast computation of {Gauss} quadrature nodes and weights on the whole
  real line.
\newblock \emph{IMA Journal of Numerical Analysis}, page drv002, 2015.

\bibitem[Trefethen(2008)]{trefethen2008gauss}
Lloyd~N Trefethen.
\newblock Is {Gauss} quadrature better than {Clenshaw}--{Curtis}?
\newblock \emph{SIAM review}, 50\penalty0 (1):\penalty0 67--87, 2008.

\bibitem[Yang et~al.(2014)Yang, Sindhwani, Avron, and Mahoney]{yang2014quasi}
Jiyan Yang, Vikas Sindhwani, Haim Avron, and Michael Mahoney.
\newblock Quasi-{Monte} {Carlo} feature maps for shift-invariant kernels.
\newblock In \emph{Proceedings of The 31st International Conference on Machine
  Learning (ICML-14)}, pages 485--493, 2014.

\bibitem[Yang et~al.(2012)Yang, Li, Mahdavi, Jin, and Zhou]{yang2012nystrom}
Tianbao Yang, Yu-Feng Li, Mehrdad Mahdavi, Rong Jin, and Zhi-Hua Zhou.
\newblock {Nystr{\"o}m} method vs random {Fourier} features: A theoretical and
  empirical comparison.
\newblock In \emph{Advances in neural information processing systems}, pages
  476--484, 2012.

\end{thebibliography}
