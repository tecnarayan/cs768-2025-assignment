\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amin et~al.(2015)Amin, Kale, Tesauro, and Turaga]{AKTT}
Kareem Amin, Satyen Kale, Gerald Tesauro, and Deepak~S. Turaga.
\newblock Budgeted prediction with expert advice.
\newblock In \emph{AAAI}, pages 2490--2496, 2015.

\bibitem[Belloni et~al.(2016)Belloni, Rosenbaum, and
  Tsybakov]{belloni2016linear}
Alexandre Belloni, Mathieu Rosenbaum, and Alexandre~B. Tsybakov.
\newblock Linear and conic programming estimators in high dimensional
  errors-in-variables models.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 2016.
\newblock ISSN 1467-9868.

\bibitem[Bickel et~al.(2009)Bickel, Ritov, and
  Tsybakov]{bickel2009simultaneous}
Peter~J Bickel, Ya'acov Ritov, and Alexandre~B Tsybakov.
\newblock {Simultaneous analysis of Lasso and Dantzig selector}.
\newblock \emph{The Annals of Statistics}, pages 1705--1732, 2009.

\bibitem[Boutsidis et~al.(2015)Boutsidis, Liberty, and
  Sviridenko]{boutsidis2015greedy}
Christos Boutsidis, Edo Liberty, and Maxim Sviridenko.
\newblock Greedy minimization of weakly supermodular set functions.
\newblock \emph{arXiv preprint arXiv:1502.06528}, 2015.

\bibitem[Candes and Tao(2007)]{candes2007dantzig}
Emmanuel Candes and Terence Tao.
\newblock {The Dantzig selector: statistical estimation when $p$ is much larger
  than $n$}.
\newblock \emph{The Annals of Statistics}, pages 2313--2351, 2007.

\bibitem[Candes and Tao(2005)]{candes2005decoding}
Emmanuel~J Candes and Terence Tao.
\newblock Decoding by linear programming.
\newblock \emph{IEEE transactions on information theory}, 51\penalty0
  (12):\penalty0 4203--4215, 2005.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{cesa2006prediction}
Nicol\`o Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge University Press, 2006.

\bibitem[Cesa-Bianchi et~al.(2011)Cesa-Bianchi, Shalev-Shwartz, and
  Shamir]{cesa2011efficient}
Nicol\`o Cesa-Bianchi, Shai Shalev-Shwartz, and Ohad Shamir.
\newblock Efficient learning with partially observed attributes.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0
  (Oct):\penalty0 2857--2878, 2011.

\bibitem[Foster et~al.(2015)Foster, Karloff, and Thaler]{foster2015variable}
Dean Foster, Howard Karloff, and Justin Thaler.
\newblock Variable selection is hard.
\newblock In \emph{COLT}, pages 696--709, 2015.

\bibitem[Foster et~al.(2016)Foster, Kale, and Karloff]{foster2016online}
Dean Foster, Satyen Kale, and Howard Karloff.
\newblock Online sparse linear regression.
\newblock In \emph{COLT}, 2016.

\bibitem[Hazan and Kale(2014)]{hazan-kale-2014}
Elad Hazan and Satyen Kale.
\newblock Beyond the regret minimization barrier: optimal algorithms for
  stochastic strongly-convex optimization.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 2489--2512, 2014.

\bibitem[Hazan and Koren(2012)]{HK}
Elad Hazan and Tomer Koren.
\newblock Linear regression with limited observation.
\newblock In \emph{ICML}, 2012.

\bibitem[Javanmard and Montanari(2013)]{javanmard2013model}
Adel Javanmard and Andrea Montanari.
\newblock Model selection for high-dimensional regression under the generalized
  irrepresentability condition.
\newblock In \emph{NIPS}, pages 3012--3020, 2013.

\bibitem[Kale(2014)]{satyen-open-problem}
Satyen Kale.
\newblock Open problem: Efficient online sparse regression.
\newblock In \emph{COLT}, pages 1299--1301, 2014.

\bibitem[Kukliansky and Shamir(2015)]{KS}
Doron Kukliansky and Ohad Shamir.
\newblock Attribute efficient linear regression with distribution-dependent
  sampling.
\newblock In \emph{ICML}, pages 153--161, 2015.

\bibitem[Mendelson(2014)]{mendelson2014learning}
Shahar Mendelson.
\newblock Learning without concentration.
\newblock In \emph{COLT}, pages 25--39, 2014.

\bibitem[Natarajan(1995)]{natarajan1995sparse}
Balas~Kausik Natarajan.
\newblock Sparse approximate solutions to linear systems.
\newblock \emph{SIAM journal on computing}, 24\penalty0 (2):\penalty0 227--234,
  1995.

\bibitem[Rosenbaum and Tsybakov(2010)]{rosenbaum2010sparse}
Mathieu Rosenbaum and Alexandre~B. Tsybakov.
\newblock Sparse recovery under matrix uncertainty.
\newblock \emph{The Annals of Statistics}, 38\penalty0 (5):\penalty0
  2620--2651, 2010.

\bibitem[Streeter and Golovin(2008)]{golovin-streeter}
Matthew~J. Streeter and Daniel Golovin.
\newblock An online algorithm for maximizing submodular functions.
\newblock In \emph{NIPS}, pages 1577--1584, 2008.

\bibitem[Zhao and Yu(2006)]{zhao2006model}
Peng Zhao and Bin Yu.
\newblock On model selection consistency of lasso.
\newblock \emph{Journal of Machine learning research}, 7\penalty0
  (Nov):\penalty0 2541--2563, 2006.

\bibitem[Zolghadr et~al.(2013)Zolghadr, Bart{\'o}k, Greiner, Gy{\"o}rgy, and
  Szepesv{\'a}ri]{andras}
Navid Zolghadr, G{\'a}bor Bart{\'o}k, Russell Greiner, Andr{\'a}s Gy{\"o}rgy,
  and Csaba Szepesv{\'a}ri.
\newblock Online learning with costly features and labels.
\newblock In \emph{NIPS}, pages 1241--1249, 2013.

\end{thebibliography}
