\begin{thebibliography}{10}

\bibitem{arora2012stochastic}
Raman Arora, Andrew Cotter, Karen Livescu, and Nathan Srebro.
\newblock Stochastic optimization for pca and pls.
\newblock In {\em Communication, Control, and Computing (Allerton), 2012 50th
  Annual Allerton Conference on}, pages 861--868. IEEE, 2012.

\bibitem{woodruff_sketching_2014}
David~P. Woodruff.
\newblock Sketching as a tool for numerical linear algebra.
\newblock {\em arXiv preprint arXiv:1411.4357}, 2014.

\bibitem{tropp2012user}
Joel~A Tropp.
\newblock User-friendly tools for random matrices: An introduction.
\newblock Technical report, CALIFORNIA INST OF TECH PASADENA DIV OF ENGINEERING
  AND APPLIED SCIENCE, 2012.

\bibitem{williams2001using}
Christopher Williams and Matthias Seeger.
\newblock {Using the Nystrom method to speed up kernel machines}.
\newblock In {\em Neural Information Processing Systems}, 2001.

\bibitem{bach2013sharp}
Francis Bach.
\newblock {Sharp analysis of low-rank kernel matrix approximations}.
\newblock In {\em Conference on Learning Theory}, 2013.

\bibitem{alaoui2015fast}
Ahmed~El Alaoui and Michael~W. Mahoney.
\newblock {Fast randomized kernel methods with statistical guarantees}.
\newblock In {\em Neural Information Processing Systems}, 2015.

\bibitem{drineas_fast_2012}
Petros Drineas, Malik Magdon-Ismail, Michael~W. Mahoney, and David~P. Woodruff.
\newblock Fast approximation of matrix coherence and statistical leverage.
\newblock {\em The Journal of Machine Learning Research}, 13(1):3475--3506,
  2012.

\bibitem{calandriello_disqueak_2017}
Daniele Calandriello, Alessandro Lazaric, and Michal Valko.
\newblock Distributed adaptive sampling for kernel matrix approximation.
\newblock In {\em {AISTATS}}, 2017.

\bibitem{musco2016provably}
Cameron Musco and Christopher Musco.
\newblock {Recursive Sampling for the Nystr\"{o}m Method}.
\newblock In {\em NIPS}, 2017.

\bibitem{pmlr-v70-calandriello17a}
Daniele Calandriello, Alessandro Lazaric, and Michal Valko.
\newblock Second-order kernel online convex optimization with adaptive
  sketching.
\newblock In Doina Precup and Yee~Whye Teh, editors, {\em Proceedings of the
  34th International Conference on Machine Learning}, volume~70 of {\em
  Proceedings of Machine Learning Research}, pages 645--653, International
  Convention Centre, Sydney, Australia, 06--11 Aug 2017. PMLR.

\bibitem{rasmussen_gaussian_2006}
Carl~Edward Rasmussen and Christopher K.~I. Williams.
\newblock {\em Gaussian processes for machine learning}.
\newblock Adaptive computation and machine learning. MIT Press, Cambridge,
  Mass, 2006.
\newblock OCLC: ocm61285753.

\bibitem{scholkopf2002learning}
Bernhard Sch{\"o}lkopf, Alexander~J Smola, et~al.
\newblock {\em Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press, 2002.

\bibitem{smola2000sparse}
Alex~J Smola and Bernhard Sch{\"o}lkopf.
\newblock Sparse greedy matrix approximation for machine learning.
\newblock 2000.

\bibitem{rudi2017falkon}
Alessandro Rudi, Luigi Carratino, and Lorenzo Rosasco.
\newblock Falkon: An optimal large scale kernel method.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3891--3901, 2017.

\bibitem{rudi2015less}
Alessandro Rudi, Raffaello Camoriano, and Lorenzo Rosasco.
\newblock Less is more: Nystr{\"o}m computational regularization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1657--1665, 2015.

\bibitem{caponnetto}
Andrea Caponnetto and Ernesto De~Vito.
\newblock Optimal rates for the regularized least-squares algorithm.
\newblock {\em Foundations of Computational Mathematics}, 7(3):331--368, 2007.

\bibitem{steinwart2009optimal}
Ingo Steinwart, Don~R Hush, Clint Scovel, et~al.
\newblock Optimal rates for regularized least squares regression.
\newblock In {\em COLT}, 2009.

\bibitem{lin2018optimal}
Junhong Lin, Alessandro Rudi, Lorenzo Rosasco, and Volkan Cevher.
\newblock Optimal rates for spectral algorithms with least-squares regression
  over hilbert spaces.
\newblock {\em Applied and Computational Harmonic Analysis}, 2018.

\bibitem{baldi2014searching}
Pierre Baldi, Peter Sadowski, and Daniel Whiteson.
\newblock Searching for exotic particles in high-energy physics with deep
  learning.
\newblock {\em Nature communications}, 5:4308, 2014.

\bibitem{roux2012stochastic}
Nicolas~L Roux, Mark Schmidt, and Francis~R Bach.
\newblock A stochastic gradient method with an exponential convergence \_rate
  for finite training sets.
\newblock In {\em Advances in neural information processing systems}, pages
  2663--2671, 2012.

\bibitem{NIPS2017_7194}
Daniele Calandriello, Alessandro Lazaric, and Michal Valko.
\newblock Efficient second-order online kernel learning with adaptive
  embedding.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in Neural Information
  Processing Systems 30}, pages 6140--6150. Curran Associates, Inc., 2017.

\bibitem{rahimi2008random}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In {\em Advances in neural information processing systems}, pages
  1177--1184, 2008.

\bibitem{rudi2017generalization}
Alessandro Rudi and Lorenzo Rosasco.
\newblock Generalization properties of learning with random features.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3215--3225, 2017.

\bibitem{NIPS2018_8222}
Luigi Carratino, Alessandro Rudi, and Lorenzo Rosasco.
\newblock Learning with sgd and random features.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems 31}, pages 10213--10224. Curran Associates, Inc., 2018.

\bibitem{argyriou2008convex}
Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil.
\newblock Convex multi-task feature learning.
\newblock {\em Machine Learning}, 73(3):243--272, 2008.

\bibitem{ciliberto2017consistent}
Carlo Ciliberto, Alessandro Rudi, Lorenzo Rosasco, and Massimiliano Pontil.
\newblock Consistent multitask learning with nonlinear output relations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1986--1996, 2017.

\bibitem{ciliberto2016}
Carlo Ciliberto, Lorenzo Rosasco, and Alessandro Rudi.
\newblock A consistent regularization approach for structured prediction.
\newblock {\em Advances in Neural Information Processing Systems 29}, pages
  4412--4420, 2016.

\bibitem{korba2018structured}
Anna Korba, Alexandre Garcia, and Florence d'Alch{\'e} Buc.
\newblock A structured prediction approach for label ranking.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9008--9018, 2018.

\bibitem{aronszajn1950theory}
Nachman Aronszajn.
\newblock Theory of reproducing kernels.
\newblock {\em Transactions of the American mathematical society},
  68(3):337--404, 1950.

\bibitem{steinwart2008support}
Ingo Steinwart and Andreas Christmann.
\newblock {\em Support vector machines}.
\newblock Springer Science \& Business Media, 2008.

\end{thebibliography}
