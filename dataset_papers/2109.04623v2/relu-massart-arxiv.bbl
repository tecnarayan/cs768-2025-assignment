\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{CKMY20b}

\bibitem[AAKS20]{artstein2020radial}
S.~Artstein-Avida, H.~Kaplan, and M.~Sharir.
\newblock On radial isotropic position: Theory and algorithms.
\newblock {\em arXiv preprint arXiv:2005.04918}, 2020.

\bibitem[ABHU15]{AwasthiBHU15}
P.~Awasthi, M.~F. Balcan, N.~Haghtalab, and R.~Urner.
\newblock Efficient learning of linear separators under bounded noise.
\newblock In {\em Proceedings of The 28th Conference on Learning Theory, {COLT}
  2015}, pages 167--190, 2015.

\bibitem[ABHZ16]{AwasthiBHZ16}
P.~Awasthi, M.~F. Balcan, N.~Haghtalab, and H.~Zhang.
\newblock Learning and 1-bit compressed sensing under asymmetric noise.
\newblock In {\em Proceedings of the 29th Conference on Learning Theory, {COLT}
  2016}, pages 152--192, 2016.

\bibitem[BJK15]{BhatiaJK15}
K.~Bhatia, P.~Jain, and P.~Kar.
\newblock Robust regression via hard thresholding.
\newblock In {\em Advances in Neural Information Processing Systems 28: Annual
  Conference on Neural Information Processing Systems 2015}, pages 721--729,
  2015.

\bibitem[BJKK17]{BhatiaJKK17}
K.~Bhatia, P.~Jain, P.~Kamalaruban, and P.~Kar.
\newblock Consistent robust regression.
\newblock In {\em Advances in Neural Information Processing Systems 30: Annual
  Conference on Neural Information Processing Systems 2017}, pages 2107--2116,
  2017.

\bibitem[BNJT10]{Barreno2010}
M.~Barreno, B.~Nelson, A.~D. Joseph, and J.~D. Tygar.
\newblock The security of machine learning.
\newblock {\em Machine Learning}, 81(2):121--148, 2010.

\bibitem[BNL12]{BiggioNL12}
B.~Biggio, B.~Nelson, and P.~Laskov.
\newblock Poisoning attacks against support vector machines.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning, {ICML} 2012}, 2012.

\bibitem[CKMY20a]{ChenKMY20}
S.~Chen, F.~Koehler, A.~Moitra, and M.~Yau.
\newblock Classification under misspecification: Halfspaces, generalized linear
  models, and evolvability.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020},
  2020.

\bibitem[CKMY20b]{chen2020online}
S.~Chen, F.~Koehler, A.~Moitra, and M.~Yau.
\newblock Online and distribution-free robustness: Regression and contextual
  bandits with huber contamination.
\newblock {\em arXiv preprint arXiv:2010.04157}, 2020.

\bibitem[CW08]{candes2008introduction}
E.~J. Cand{\`e}s and M.~B. Wakin.
\newblock An introduction to compressive sampling.
\newblock {\em IEEE signal processing magazine}, 25(2):21--30, 2008.

\bibitem[DGK{\etalchar{+}}20]{DGKKS20}
I.~Diakonikolas, S.~Goel, S.~Karmalkar, A.~R. Klivans, and M.~Soltanolkotabi.
\newblock Approximation schemes for relu regression.
\newblock In {\em Conference on Learning Theory, {COLT} 2020}, volume 125 of
  {\em Proceedings of Machine Learning Research}, pages 1452--1485. {PMLR},
  2020.

\bibitem[DGT19]{DGT19}
I.~Diakonikolas, T.~Gouleakis, and C.~Tzamos.
\newblock Distribution-independent pac learning of halfspaces with massart
  noise.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d'Alch\'{e} Buc,
  E.~Fox, and R.~Garnett, editors, {\em Advances in Neural Information
  Processing Systems 32}, pages 4751--4762. Curran Associates, Inc., 2019.

\bibitem[Die01]{Dielman01}
T.~E. Dielman.
\newblock {\em Applied Regression Analysis for Business and Economics}.
\newblock Duxbury/Thomson Learning Pacific Grove, CA, 2001.

\bibitem[DIK{\etalchar{+}}21]{DiakonikolasIKL21}
I.~Diakonikolas, R.~Impagliazzo, D.~M. Kane, R.~Lei, J.~Sorrell, and C.~Tzamos.
\newblock Boosting in the presence of massart noise.
\newblock In {\em Conference on Learning Theory, {COLT} 2021}, volume 134 of
  {\em Proceedings of Machine Learning Research}, pages 1585--1644. {PMLR},
  2021.

\bibitem[DK19]{DK19-survey}
I.~Diakonikolas and D.~M. Kane.
\newblock Recent advances in algorithmic high-dimensional robust statistics.
\newblock {\em CoRR}, abs/1911.05911, 2019.

\bibitem[DK20]{DK20-hard}
I.~Diakonikolas and D.~M. Kane.
\newblock Hardness of learning halfspaces with massart noise.
\newblock {\em CoRR}, abs/2012.09720, 2020.

\bibitem[DKK{\etalchar{+}}16]{DKKLMS16}
I.~Diakonikolas, G.~Kamath, D.~M. Kane, J.~Li, A.~Moitra, and A.~Stewart.
\newblock Robust estimators in high dimensions without the computational
  intractability.
\newblock In {\em Proc.\ 57th IEEE Symposium on Foundations of Computer Science
  (FOCS)}, pages 655--664, 2016.

\bibitem[DKK{\etalchar{+}}19]{DiakonikolasKKLSS2018sever}
I.~Diakonikolas, G.~Kamath, D.~M. Kane, J.~Li, J.~Steinhardt, and A.~Stewart.
\newblock {SEVER}: {A} robust meta-algorithm for stochastic optimization.
\newblock In {\em Proc.\ 36th International Conference on Machine Learning
  (ICML)}, pages 1596--1606, 2019.

\bibitem[DKK{\etalchar{+}}21]{DKKTZ21-benign}
I.~Diakonikolas, D.~M. Kane, V.~Kontonis, C.~Tzamos, and N.~Zarifis.
\newblock Learning general halfspaces with general massart noise under the gaussian distribution.
\newblock {\em CoRR}, abs/2108.08767, 2021.

\bibitem[DKN20]{DKZ20-sq-reg}
I.~Diakonikolas, D.~Kane, and N.Zarifis.
\newblock Near-optimal {SQ} lower bounds for agnostically learning halfspaces
  and relus under gaussian marginals.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020},
  2020.

\bibitem[DKPZ21]{DKP21-SQ}
I.~Diakonikolas, D.~M. Kane, T.~Pittas, and N.~Zarifis.
\newblock The optimality of polynomial regression for agnostic learning under
  gaussian marginals.
\newblock {\em CoRR}, abs/2102.04401, 2021.
\newblock To appear in COLT 2021.

\bibitem[DKS19]{DKS19-lr}
I.~Diakonikolas, W.~Kong, and A.~Stewart.
\newblock Efficient algorithms and lower bounds for robust linear regression.
\newblock In {\em Proc.\ 30th Annual Symposium on Discrete Algorithms (SODA)},
  pages 2745--2754, 2019.

\bibitem[DKT21]{DKT21-forster}
I.~Diakonikolas, D.~M. Kane, and C.~Tzamos.
\newblock Forster decomposition and learning halfspaces with noise.
\newblock In {\em Advances in Neural Information Processing Systems 34: Annual
  Conference on Neural Information Processing Systems 2021, NeurIPS 2021},
  2021.

\bibitem[DKTZ20]{DKTZ20}
I.~Diakonikolas, V.~Kontonis, C.~Tzamos, and N.~Zarifis.
\newblock Learning halfspaces with massart noise under structured
  distributions.
\newblock In Jacob~D. Abernethy and Shivani Agarwal, editors, {\em Conference
  on Learning Theory, {COLT} 2020}, volume 125 of {\em Proceedings of Machine
  Learning Research}, pages 1486--1513. {PMLR}, 2020.

\bibitem[DLT18]{du18convolutional}
S.~S. Du, J.~D. Lee, and Y.~Tian.
\newblock When is a convolutional filter easy to learn?
\newblock In {\em 6th International Conference on Learning Representations,
  ICLR 2018}, 2018.

\bibitem[DNS21]{d2020regress}
T.~D'Orsi, G.~Novikov, and D.~Steurer.
\newblock Consistent regression when oblivious outliers overwhelm.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning}, volume 139 of {\em Proceedings of Machine Learning Research},
  pages 2297--2306. PMLR, 18--24 Jul 2021.

\bibitem[DV04]{DV:04}
J.~Dunagan and S.~Vempala.
\newblock Optimal outlier removal in high-dimensional spaces.
\newblock {\em J. Computer \& System Sciences}, 68(2):335--373, 2004.

\bibitem[FCG20]{FCG20}
S.~Frei, Y.~Cao, and Q.~Gu.
\newblock Agnostic learning of a single neuron with gradient descent.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020},
  2020.

\bibitem[GGK20]{GGK20}
S.~Goel, A.~Gollakota, and A.~R. Klivans.
\newblock Statistical-query lower bounds via functional gradients.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020},
  2020.

\bibitem[GKK19]{GoelKK19}
S.~Goel, S.~Karmalkar, and A.~R. Klivans.
\newblock Time/accuracy tradeoffs for learning a relu with respect to gaussian
  marginals.
\newblock In {\em Advances in Neural Information Processing Systems 32: Annual
  Conference on Neural Information Processing Systems 2019, NeurIPS 2019},
  pages 8582--8591, 2019.

\bibitem[GKKT17]{GKKT17}
S.~Goel, V.~Kanade, A.~Klivans, and J.~Thaler.
\newblock Reliably learning the relu in polynomial time.
\newblock In {\em Conference on Learning Theory}, pages 1004--1042, 2017.

\bibitem[HKLM20]{hopkins2020point}
M.~Hopkins, D.~M. Kane, S.~Lovett, and G.~Mahajan.
\newblock Point location and active learning: Learning halfspaces almost
  optimally.
\newblock In {\em 61st IEEE Annual Symposium on Foundations of Computer
  Science, {FOCS} 2020}, pages 1034--1044, 2020.

\bibitem[HM13]{HardtM13}
M.~Hardt and A.~Moitra.
\newblock Algorithms and hardness for robust subspace recovery.
\newblock In {\em Proc.\ 26th Annual Conference on Learning Theory (COLT)},
  pages 354--375, 2013.

\bibitem[HR09]{Huber09}
P.~J. Huber and E.~M. Ronchetti.
\newblock {\em Robust statistics}.
\newblock Wiley New York, 2009.

\bibitem[HRRS86]{HampelEtalBook86}
F.~R. Hampel, E.~M. Ronchetti, P.~J. Rousseeuw, and W.~A. Stahel.
\newblock {\em Robust statistics. The approach based on influence functions}.
\newblock Wiley New York, 1986.

\bibitem[Kha95]{khachiyan1995complexity}
L.~Khachiyan.
\newblock On the complexity of approximating extremal determinants in matrices.
\newblock {\em Journal of Complexity}, 11(1):138--153, 1995.

\bibitem[KKM18]{KlivansKM18}
A.~Klivans, P.~Kothari, and R.~Meka.
\newblock Efficient algorithms for outlier-robust regression.
\newblock In {\em Proc.\ 31st Annual Conference on Learning Theory (COLT)},
  pages 1420--1430, 2018.

\bibitem[KMM20]{karmakar2020study}
S.~Karmakar, A.~Mukherjee, and R.~Muthukumar.
\newblock A study of neural training with iterative non-gradient methods.
\newblock {\em arXiv e-prints}, pages arXiv--2005, 2020.

\bibitem[KSA19]{kalan2019fitting}
S.~M.~M. Kalan, M.~Soltanolkotabi, and S.~Avestimehr.
\newblock Fitting relus via sgd and quantized sgd.
\newblock In {\em 2019 IEEE International Symposium on Information Theory
  (ISIT)}, pages 2469--2473. IEEE, 2019.

\bibitem[LAT{\etalchar{+}}08]{Li-Science08}
J.~Z. Li, D.~M. Absher, H.~Tang, A.~M. Southwick, A.~M. Casto, S.~Ramachandran,
  H.~M. Cann, G.~S. Barsh, M.~Feldman, L.~L. Cavalli-Sforza, and R.~M. Myers.
\newblock Worldwide human relationships inferred from genome-wide patterns of
  variation.
\newblock {\em Science}, 319:1100--1104, 2008.

\bibitem[LRV16]{LaiRV16}
K.~A. Lai, A.~B. Rao, and S.~Vempala.
\newblock Agnostic estimation of mean and covariance.
\newblock In {\em Proc.\ 57th IEEE Symposium on Foundations of Computer Science
  (FOCS)}, pages 665--674, 2016.

\bibitem[McD09]{McD09}
J.~H. McDonald.
\newblock {\em Handbook of Biological Statistics, volume 2}.
\newblock Sparky House Publishing, Baltimore, MD, 2009.

\bibitem[MN06]{Massart2006}
P.~Massart and E.~Nedelec.
\newblock Risk bounds for statistical learning.
\newblock {\em Ann. Statist.}, 34(5):2326--2366, 10 2006.

\bibitem[MR18]{MR18}
P.~Manurangsi and D.~Reichman.
\newblock The computational complexity of training relu (s).
\newblock {\em arXiv preprint arXiv:1810.04207}, 2018.

\bibitem[OSB{\etalchar{+}}18]{olier2018meta}
I.~Olier, N.~Sadawi, G.~R. Bickerton, J.~Vanschoren, C.~Grosan, L.~Soldatova,
  and R.~D. King.
\newblock Meta-qsar: a large-scale application of meta-learning to drug design
  and discovery.
\newblock {\em Machine Learning}, 107(1):285--311, 2018.

\bibitem[PF20]{pesme2020online}
S.~Pesme and N.~Flammarion.
\newblock Online robust regression via {SGD} on the l1 loss.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020},
  2020.

\bibitem[PLJD10]{Pas-MG10}
P.~Paschou, J.~Lewis, A.~Javed, and P.~Drineas.
\newblock Ancestry informative markers for fine-scale individual assignment to
  worldwide populations.
\newblock {\em Journal of Medical Genetics}, 47:835--847, 2010.

\bibitem[RL87]{Rousseeuw:1987}
P.~J. Rousseeuw and A.~M. Leroy.
\newblock {\em Robust Regression and Outlier Detection}.
\newblock John Wiley \& Sons, Inc., New York, NY, USA, 1987.

\bibitem[RPW{\etalchar{+}}02]{RP-Gen02}
N.~Rosenberg, J.~Pritchard, J.~Weber, H.~Cann, K.~Kidd, L.A. Zhivotovsky, and
  M.W. Feldman.
\newblock Genetic structure of human populations.
\newblock {\em Science}, 298:2381--2385, 2002.

\bibitem[SBRJ19]{SuggalaBR019}
A.~S. Suggala, K.~Bhatia, P.~Ravikumar, and P.~Jain.
\newblock Adaptive hard thresholding for near-optimal consistent robust
  regression.
\newblock In {\em Conference on Learning Theory, {COLT} 2019}, pages
  2892--2897, 2019.

\bibitem[SKL17]{SteinhardtKL17}
J.~Steinhardt, P.~W. Koh, and P.~S. Liang.
\newblock Certified defenses for data poisoning attacks.
\newblock In {\em Advances in Neural Information Processing Systems 30}, pages
  3520--3532, 2017.

\bibitem[Sol17]{Mahdi17}
M.~Soltanolkotabi.
\newblock Learning relus via gradient descent.
\newblock In {\em Advances in neural information processing systems}, pages
  2007--2017, 2017.

\bibitem[YS19]{YS19}
G.~Yehudai and O.~Shamir.
\newblock On the power and limitations of random features for understanding
  neural networks.
\newblock {\em CoRR}, abs/1904.00687, 2019.

\bibitem[YS20]{yehudai2020learning}
G.~Yehudai and O.~Shamir.
\newblock Learning a single neuron with gradient methods.
\newblock In {\em Conference on Learning Theory}, pages 3756--3786. PMLR, 2020.

\bibitem[ZLC17]{ZhangLC17}
Y.~Zhang, P.~Liang, and M.~Charikar.
\newblock A hitting time analysis of stochastic gradient langevin dynamics.
\newblock In {\em Proceedings of the 30th Conference on Learning Theory, {COLT}
  2017}, pages 1980--2022, 2017.

\bibitem[ZSA20]{Zhang20}
C.~Zhang, J.~Shen, and P.~Awasthi.
\newblock Efficient active learning of sparse halfspaces with arbitrary bounded
  noise.
\newblock In {\em Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020},
  2020.

\end{thebibliography}
