@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{derPol2020homomorphic,
  title={Mdp homomorphic networks: Group symmetries in reinforcement learning},
  author={van der Pol, Elise and Worrall, Daniel and van Hoof, Herke and Oliehoek, Frans and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{tarbouriech2019active,
  title={Active exploration in {M}arkov decision processes},
  author={Tarbouriech, Jean and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2019}
}

@InProceedings{pmlr-v28-jaggi13,
  title = 	 {Revisiting {Frank-Wolfe}: Projection-Free Sparse Convex Optimization},
  author = 	 {Jaggi, Martin},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2013}
}

@inproceedings{tarbouriech2020active,
  title={Active model estimation in markov decision processes},
  author={Tarbouriech, Jean and Shekhar, Shubhanshu and Pirotta, Matteo and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2020}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{mutti2023convex,
  title={Convex Reinforcement Learning in Finite Trials},
  author={Mutti, Mirco and De Santi, Riccardo and De Bartolomeis, Piersilvio and Restelli, Marcello},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={250},
  pages={1--42},
  year={2023}
}

@inproceedings{mutti2022importance,
  title={The Importance of Non-{M}arkovianity in Maximum State Entropy Exploration},
  author={Mutti, Mirco and De Santi, Riccardo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{bianchi2023safe,
  title={Safe and Efficient Reinforcement Learning for Environmental Monitoring},
  author={Bianchi, Federico and Corsi, Davide and Marzari, Luca and Meli, Daniele and Trotti, Francesco and Zuccotto, Maddalena and Castellini, Alberto and Farinelli, Alessandro and others},
  booktitle={Proceedings of the Italia Intelligenza Artificiale-Thematic Workshops co-located with the 3rd CINI National Lab AIIS Conference on Artificial Intelligence (Ital IA 2023)},
  pages={1--6},
  year={2023}
}

@article{Thiede_2022,
  title={Curiosity in exploring chemical spaces: intrinsic rewards for molecular reinforcement learning},
  author={Thiede, Luca A and Krenn, Mario and Nigam, AkshatKumar and Aspuru-Guzik, Alan},
  journal={Machine Learning: Science and Technology},
  volume={3},
  number={3},
  year={2022}
}

@inproceedings{hazan2019maxent,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
  booktitle={International Conference on Machine Learning},
  year={2019},
}

@inproceedings{mutny2023active,
  title={Active exploration via experiment design in {M}arkov chains},
  author={Mutny, Mojmir and Janik, Tadeusz and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2023}
}

@article{vcerny2012two,
  title={Two complexity results on c-optimality in experimental design},
  author={{\v{C}}ern{\`y}, Michal and Hlad{\'\i}k, Milan},
  journal={Computational Optimization and Applications},
  volume={51},
  number={3},
  pages={1397--1408},
  year={2012},
  publisher={Springer}
}


@InProceedings{bakarat2023reinforcement,
  title = 	 {Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space},
  author =       {Barakat, Anas and Fatkhullin, Ilyas and He, Niao},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {1753--1800},
  year = 	 {2023}
}

@inproceedings{zhang2020variational,
  title={Variational Policy Gradient Method for Reinforcement Learning with General Utilities},
  author={Zhang, Junyu and Koppel, Alec and Bedi, Amrit Singh and Szepesvari, Csaba and Wang, Mengdi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{geist2021concave,
  title={Concave Utility Reinforcement Learning: The Mean-field Game Viewpoint},
  author={Geist, Matthieu and P{\'e}rolat, Julien and Lauri{\`e}re, Mathieu and Elie, Romuald and Perrin, Sarah and Bachem, Oliver and Munos, R{\'e}mi and Pietquin, Olivier},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2022}
}

@inproceedings{zahavy2021reward,
  title={Reward is enough for convex MDPs},
  author={Zahavy, Tom and O'Donoghue, Brendan and Desjardins, Guillaume and Singh, Satinder},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{mutti2022challenging,
  title={Challenging common assumptions in convex reinforcement learning},
  author={Mutti, Mirco and De Santi, Riccardo and De Bartolomeis, Piersilvio and Restelli, Marcello},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{prajapat2023submodular,
  title={Submodular reinforcement learning},
  author={Prajapat, Manish and Mutn{\`y}, Mojm{\'\i}r and Zeilinger, Melanie N and Krause, Andreas},
  journal={arXiv preprint arXiv:2307.13372},
  year={2023}
}

@article{kumar2022policy,
  title={Policy gradient for reinforcement learning with general utilities},
  author={Kumar, Navdeep and Wang, Kaixin and Levy, Kfir and Mannor, Shie},
  journal={arXiv preprint arXiv:2210.00991},
  year={2022}
}

@article{ying2023scalable,
  title={Scalable Multi-Agent Reinforcement Learning with General Utilities},
  author={Ying, Donghao and Ding, Yuhao and Koppel, Alec and Lavaei, Javad},
  journal={arXiv preprint arXiv:2302.07938},
  year={2023}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={International Conference on Machine Learning},
  year={2004}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@inproceedings{cheung2019regret,
  title={Regret minimization for reinforcement learning with vectorial feedback and complex objectives},
  author={Cheung, Wang Chi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{cheung2019exploration,
  title={Exploration-exploitation trade-off in reinforcement learning on online {M}arkov decision processes with global concave rewards},
  author={Cheung, Wang Chi},
  journal={arXiv preprint arXiv:1905.06466},
  year={2019}
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  year={2020}
}

@inproceedings{eysenbach2018diversity,
  title={Diversity is All You Need: Learning Skills without a Reward Function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{campos2020explore,
  title={Explore, discover and learn: Unsupervised discovery of state-covering skills},
  author={Campos, V{\'\i}ctor and Trott, Alexander and Xiong, Caiming and Socher, Richard and Gir{\'o}-i-Nieto, Xavier and Torres, Jordi},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@inproceedings{brantley2020constrained,
  title={Constrained episodic reinforcement learning in concave-convex and knapsack settings},
  author={Brantley, Kiant{\'e} and Dudik, Miro and Lykouris, Thodoris and Miryoosefi, Sobhan and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{qin2021density,
  title={Density constrained reinforcement learning},
  author={Qin, Zengyi and Chen, Yuxiao and Fan, Chuchu},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@article{state_marginal,
  title={Efficient exploration via state marginal matching},
  author={Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1906.05274},
  year={2019}
}

@book{pukelsheim2006optimal,
  title={Optimal design of experiments},
  author={Pukelsheim, Friedrich},
  year={2006},
  publisher={SIAM}
}

@article{chaloner1995bayesian,
  title={Bayesian experimental design: A review},
  author={Chaloner, Kathryn and Verdinelli, Isabella},
  journal={Statistical Science},
  pages={273--304},
  year={1995},
  publisher={JSTOR}
}

@article{ravindran2001symmetries,
  title={Symmetries and model minimization in {M}arkov decision processes},
  author={Ravindran, Balaraman and Barto, Andrew G},
  year={2001},
  journal={Technical report},
  publisher={University of Massachusetts}
}

@inproceedings{van2020plannable,
  title={Plannable Approximations to MDP Homomorphisms: Equivariance under Actions},
  author={van der Pol, Elise and Kipf, Thomas and Oliehoek, Frans A and Welling, Max},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2020}
}

@inproceedings{van2021multi,
  title={Multi-agent mdp homomorphic networks},
  author={van der Pol, Elise and van Hoof, Herke and Oliehoek, Frans A and Welling, Max},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{Kearns1998NearOptimalRL,
  title={Near-Optimal Reinforcement Learning in Polynomial Time},
  author={Michael Kearns and Satinder Singh},
  journal={Machine Learning},
  year={1998},
  volume={49},
  pages={209-232},
  url={https://api.semanticscholar.org/CorpusID:2695116}
}

@book{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath},
  year={2003},
  publisher={University of London, University College London (United Kingdom)}
}

@inproceedings{strehl2006pac,
  title={PAC model-free reinforcement learning},
  author={Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={881--888},
  year={2006}
}

@inproceedings{lattimore2012pac,
  title={PAC bounds for discounted MDPs},
  author={Lattimore, Tor and Hutter, Marcus},
  booktitle={Algorithmic Learning Theory: 23rd International Conference, ALT 2012, Lyon, France, October 29-31, 2012. Proceedings 23},
  pages={320--334},
  year={2012},
  organization={Springer}
}

@inproceedings{dean1997model,
  title={Model minimization in {M}arkov decision processes},
  author={Dean, Thomas and Givan, Robert},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={1997}
}

@inproceedings{rezaei2022continuous,
  title={Continuous MDP Homomorphisms and Homomorphic Policy Gradient},
  author={Rezaei-Shoshtari, Sahand and Zhao, Rosie and Panangaden, Prakash and Meger, David and Precup, Doina},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{ravindran2004approximate,
  title={Approximate homomorphisms: A framework for non-exact minimization in {M}arkov decision processes},
  author={Ravindran, Balaraman and Barto, Andrew G},
   journal={Technical report},
  year={2004}
}

@phdthesis{zhao2022continuous,
  title={Continuous Homomorphisms and Leveraging Symmetries in Policy Gradient Algorithms for Markov Decision Processes},
  author={Zhao, Rosie Y},
  year={2022},
  publisher={McGill University}
}

@inproceedings{jiang2014improving,
  title={Improving {UCT} planning via approximate homomorphisms},
  author={Jiang, Nan and Singh, Satinder and Lewis, Richard},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2014}
}

@inproceedings{soni2006using,
  title={Using homomorphisms to transfer options across continuous reinforcement learning domains},
  author={Soni, Vishal and Singh, Satinder},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={6},
  pages={494--499},
  year={2006}
}

--- learn hom:
@inproceedings{biza2018online,
  title={Online abstraction with MDP homomorphisms for deep learning},
  author={Biza, Ondrej and Platt, Robert},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2018}
}

@inproceedings{wolfe2006decision,
  title={Decision tree methods for finding reusable MDP homomorphisms},
  author={Wolfe, Alicia P and Barto, Andrew G},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2006}
}

@article{mavor2022simple,
  title={A simple approach for state-action abstraction using a learned mdp homomorphism},
  author={Mavor-Parker, Augustine N and Sargent, Matthew J and Banino, Andrea and Griffin, Lewis D and Barry, Caswell},
  journal={arXiv preprint arXiv:2209.06356},
  year={2022}
}

@inproceedings{narayanamurthy2008hardness,
  title={On the hardness of finding symmetries in {M}arkov decision processes},
  author={Narayanamurthy, Shravan Matthur and Ravindran, Balaraman},
  booktitle={International Conference on Machine Learning},
  year={2008}
}


@InProceedings{pmlr-v162-mondal22a,
  title = 	 {{E}q{R}: Equivariant Representations for Data-Efficient Reinforcement Learning},
  author =       {Mondal, Arnab Kumar and Jain, Vineet and Siddiqi, Kaleem and Ravanbakhsh, Siamak},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2022}
}

@article{angelotti2021expert,
  title={Expert-Guided Symmetry Detection in {M}arkov Decision Processes},
  author={Angelotti, Giorgio and Drougard, Nicolas and Chanel, Caroline PC},
  journal={arXiv preprint arXiv:2111.10297},
  year={2021}
}

---

@article{cheng2021molecular,
  title={Molecular design in drug discovery: a comprehensive review of deep generative models},
  author={Cheng, Yu and Gong, Yongshun and Liu, Yuansheng and Song, Bosheng and Zou, Quan},
  journal={Briefings in Bioinformatics},
  volume={22},
  number={6},
  year={2021},
  publisher={Oxford University Press}
}

@article{elton2019deep,
  title={Deep learning for molecular design—a review of the state of the art},
  author={Elton, Daniel C and Boukouvalas, Zois and Fuge, Mark D and Chung, Peter W},
  journal={Molecular Systems Design \& Engineering},
  volume={4},
  number={4},
  pages={828--849},
  year={2019},
  publisher={Royal Society of Chemistry}
}

@phdthesis{krause2008optimizing,
  title={Optimizing sensing: Theory and applications},
  author={Krause, Andreas},
  year={2008},
  school={Carnegie Mellon University}
}

@inproceedings{ravindran2003smdp,
  title={SMDP homomorphisms: An algebraic approach to abstraction in semi {M}arkov decision processes},
  author={Ravindran, Balaraman},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2003}
}

@inproceedings{ravindran2002model,
  title={Model minimization in hierarchical reinforcement learning},
  author={Ravindran, Balaraman and Barto, Andrew G},
  booktitle={Abstraction, Reformulation, and Approximation: 5th International Symposium},
  year={2002}
}

@article{mahajan2017symmetry,
  title={Symmetry learning for function approximation in reinforcement learning},
  author={Mahajan, Anuj and Tulabandhula, Theja},
  journal={arXiv preprint arXiv:1706.02999},
  year={2017}
}

@inproceedings{zhu2022invariant,
  title={Invariant action effect model for reinforcement learning},
  author={Zhu, Zheng-Mao and Jiang, Shengyi and Liu, Yu-Ren and Yu, Yang and Zhang, Kun},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{corey1969computer,
  title={Computer-Assisted Design of Complex Organic Syntheses: Pathways for molecular synthesis can be devised with a computer and equipment for graphical communication.},
  author={Corey, Elias James and Wipke, W Todd},
  journal={Science},
  volume={166},
  number={3902},
  pages={178--192},
  year={1969},
  publisher={American Association for the Advancement of Science}
}

@article{schreck2019learning,
  title={Learning retrosynthetic planning through simulated experience},
  author={Schreck, John S and Coley, Connor W and Bishop, Kyle JM},
  journal={ACS Central Science},
  volume={5},
  number={6},
  pages={970--981},
  year={2019},
  publisher={ACS Publications}
}

@article{dong2022deep,
  title={Deep learning in retrosynthesis planning: datasets, models and tools},
  author={Dong, Jingxin and Zhao, Mingyi and Liu, Yuansheng and Su, Yansen and Zeng, Xiangxiang},
  journal={Briefings in Bioinformatics},
  volume={23},
  number={1},
  year={2022},
  publisher={Oxford University Press}
}

@article{krenn2020self,
  title={Self-referencing embedded strings (SELFIES): A 100\% robust molecular string representation},
  author={Krenn, Mario and H{\"a}se, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan},
  journal={Machine Learning: Science and Technology},
  volume={1},
  number={4},
  pages={045024},
  year={2020},
  publisher={IOP Publishing}
}

@article{weininger1988smiles,
  title={SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules},
  author={Weininger, David},
  journal={Journal of chemical information and computer sciences},
  volume={28},
  number={1},
  pages={31--36},
  year={1988},
  publisher={ACS Publications}
}

@book{rotman2010advanced,
  title={Advanced Modern Algebra},
  author={Rotman, Joseph J},
  volume={114},
  year={2010},
  publisher={American Mathematical Society}
}

@article{lafferty2008concentration,
  title={Concentration of measure},
  author={Lafferty, John and Liu, Han and Wasserman, Larry},
  journal={Online  at \url{https://www.stat.cmu.edu/~larry/=sml/Concentration.pdf}},
  year={2008}
}

@article{wang2023scientific,
  title={Scientific discovery in the age of artificial intelligence},
  author={Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={47--60},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{de2003linear,
  title={The linear programming approach to approximate dynamic programming},
  author={De Farias, Daniela Pucci and Van Roy, Benjamin},
  journal={Operations research},
  volume={51},
  number={6},
  pages={850--865},
  year={2003},
  publisher={INFORMS}
}

@article{welch1982algorithmic,
  title={Algorithmic complexity: three NP-hard problems in computational statistics},
  author={Welch, William J},
  journal={Journal of Statistical Computation and Simulation},
  volume={15},
  number={1},
  pages={17--25},
  year={1982},
  publisher={Taylor \& Francis}
}

@article{antos2010active,
  title={Active learning in heteroscedastic noise},
  author={Antos, Andr{\'a}s and Grover, Varun and Szepesv{\'a}ri, Csaba},
  journal={Theoretical Computer Science},
  volume={411},
  number={29-30},
  pages={2712--2728},
  year={2010},
  publisher={Elsevier}
}

@article{szepesvari2009reinforcement,
  title={Reinforcement learning algorithms for MDPs},
  author={Szepesv{\'a}ri, Csaba},
  year={2009}
}

@book{10.5555/2670022,
author = {Nesterov, Yurii},
title = {Introductory Lectures on Convex Optimization: A Basic Course},
year = {2014},
publisher = {Springer Publishing Company}
}

@inproceedings{panaganti2022sample,
  title={Sample complexity of robust reinforcement learning with a generative model},
  author={Panaganti, Kishan and Kalathil, Dileep},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2022}
}

@inproceedings{lindner2022active,
  title={Active exploration for inverse reinforcement learning},
  author={Lindner, David and Krause, Andreas and Ramponi, Giorgia},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}