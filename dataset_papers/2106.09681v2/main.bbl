\begin{thebibliography}{84}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ainslie et~al.(2020)Ainslie, Ontanon, Alberti, Cvicek, Fisher, Pham,
  Ravula, Sanghai, Wang, and Yang]{ainslie2020etc}
Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek, Zachary Fisher,
  Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, and Li~Yang.
\newblock Etc: Encoding long and structured inputs in transformers.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing}, 2020.

\bibitem[Arnab et~al.(2021)Arnab, Dehghani, Heigold, Sun, Lu{\v{c}}i{\'c}, and
  Schmid]{arnab2021vivit}
Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lu{\v{c}}i{\'c},
  and Cordelia Schmid.
\newblock Vivit: A video vision transformer.
\newblock \emph{arXiv preprint arXiv:2103.15691}, 2021.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bello(2021)]{bello2021lambdanetworks}
Irwan Bello.
\newblock {LambdaNetworks}: Modeling long-range interactions without attention.
\newblock \emph{arXiv preprint arXiv:2102.08602}, 2021.

\bibitem[Beltagy et~al.(2020)Beltagy, Peters, and Cohan]{beltagy2020longformer}
Iz~Beltagy, Matthew~E Peters, and Arman Cohan.
\newblock Longformer: The long-document transformer.
\newblock \emph{arXiv preprint arXiv:2004.05150}, 2020.

\bibitem[Berman et~al.(2019)Berman, J{\'e}gou, Vedaldi, Kokkinos, and
  Douze]{berman2019multigrain}
Maxim Berman, Herv{\'e} J{\'e}gou, Andrea Vedaldi, Iasonas Kokkinos, and
  Matthijs Douze.
\newblock {MultiGrain}: a unified image embedding for classes and instances.
\newblock \emph{arXiv preprint arXiv:1902.05509}, 2019.

\bibitem[Bertasius et~al.(2021)Bertasius, Wang, and
  Torresani]{bertasius2021space}
Gedas Bertasius, Heng Wang, and Lorenzo Torresani.
\newblock Is space-time attention all you need for video understanding?
\newblock \emph{arXiv preprint arXiv:2102.05095}, 2021.

\bibitem[Boureau et~al.(2010)Boureau, Ponce, and LeCun]{Boureau2010ATA}
Y-Lan Boureau, Jean Ponce, and Yann LeCun.
\newblock A theoretical analysis of feature pooling in visual recognition.
\newblock In \emph{International Conference on Machine Learning}, 2010.

\bibitem[Brabandere et~al.(2016)Brabandere, Jia, Tuytelaars, and
  Gool]{brabandere16nips}
B.~De Brabandere, X.~Jia, T.~Tuytelaars, and L.~Van Gool.
\newblock Dynamic filter networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Brock et~al.(2021)Brock, De, Smith, and Simonyan]{brock2021high}
Andrew Brock, Soham De, Samuel~L Smith, and Karen Simonyan.
\newblock High-performance large-scale image recognition without normalization.
\newblock \emph{arXiv preprint arXiv:2102.06171}, 2021.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}, 2020.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin]{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock \emph{arXiv preprint arXiv:2104.14294}, 2021.

\bibitem[Chen et~al.(2019)Chen, Wang, Pang, Cao, Xiong, Li, Sun, Feng, Liu, Xu,
  Zhang, Cheng, Zhu, Cheng, Zhao, Li, Lu, Zhu, Wu, Dai, Wang, Shi, Ouyang, Loy,
  and Lin]{mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu~Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng,
  Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu,
  Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen~Change Loy, and
  Dahua Lin.
\newblock {MMDetection}: Open mmlab detection toolbox and benchmark.
\newblock \emph{arXiv preprint arXiv:1906.07155}, 2019.

\bibitem[Child et~al.(2019)Child, Gray, Radford, and
  Sutskever]{child2019generating}
Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever.
\newblock Generating long sequences with sparse transformers.
\newblock \emph{arXiv preprint arXiv:1904.10509}, 2019.

\bibitem[Choromanski et~al.(2020)Choromanski, Likhosherstov, Dohan, Song, Gane,
  Sarlos, Hawkins, Davis, Mohiuddin, Kaiser, et~al.]{choromanski2020rethinking}
Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song,
  Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin,
  Lukasz Kaiser, et~al.
\newblock Rethinking attention with performers.
\newblock \emph{arXiv preprint arXiv:2009.14794}, 2020.

\bibitem[Chum et~al.(2007)Chum, Philbin, Sivic, Isard, and
  Zisserman]{chum2007total}
Ondrej Chum, James Philbin, Josef Sivic, Michael Isard, and Andrew Zisserman.
\newblock Total recall: Automatic query expansion with a generative feature
  model for object retrieval.
\newblock In \emph{International Conference on Computer Vision}, 2007.

\bibitem[Contributors(2020)]{mmseg2020}
MMSegmentation Contributors.
\newblock {MMSegmentation}: Openmmlab semantic segmentation toolbox and
  benchmark.
\newblock \url{https://github.com/open-mmlab/mmsegmentation}, 2020.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, 2020.

\bibitem[d'Ascoli et~al.(2021)d'Ascoli, Touvron, Leavitt, Morcos, Biroli, and
  Sagun]{d2021convit}
St{\'e}phane d'Ascoli, Hugo Touvron, Matthew Leavitt, Ari Morcos, Giulio
  Biroli, and Levent Sagun.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock \emph{arXiv preprint arXiv:2103.10697}, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2009.

\bibitem[Ding et~al.(2021)Ding, Zhang, Han, and Ding]{ding2021repmlp}
Xiaohan Ding, Xiangyu Zhang, Jungong Han, and Guiguang Ding.
\newblock {RepMLP}: Re-parameterizing convolutions into fully-connected layers
  for image recognition.
\newblock \emph{arXiv preprint arXiv:2105.01883}, 2021.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[El-Nouby et~al.(2021)El-Nouby, Neverova, Laptev, and
  J{\'e}gou]{el2021training}
Alaaeldin El-Nouby, Natalia Neverova, Ivan Laptev, and Herv{\'e} J{\'e}gou.
\newblock Training vision transformers for image retrieval.
\newblock \emph{arXiv preprint arXiv:2102.05644}, 2021.

\bibitem[Fan et~al.(2021)Fan, Xiong, Mangalam, Li, Yan, Malik, and
  Feichtenhofer]{fan2021multiscale}
Haoqi Fan, Bo~Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock \emph{arXiv preprint arXiv:2104.11227}, 2021.

\bibitem[Gordo et~al.(2017)Gordo, Almaz{\'a}n, Revaud, and
  Larlus]{Gordo2017EndtoEndLO}
Albert Gordo, Jon Almaz{\'a}n, J{\'e}r{\^o}me Revaud, and Diane Larlus.
\newblock End-to-end learning of deep visual representations for image
  retrieval.
\newblock \emph{International journal of Computer Vision}, 124, 2017.

\bibitem[Graham et~al.(2021)Graham, El-Nouby, Touvron, Stock, Joulin,
  J{\'e}gou, and Douze]{graham2021levit}
Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin,
  Herv{\'e} J{\'e}gou, and Matthijs Douze.
\newblock Levit: a vision transformer in convnet's clothing for faster
  inference.
\newblock \emph{arXiv preprint arXiv:2104.01136}, 2021.

\bibitem[Han et~al.(2021)Han, Xiao, Wu, Guo, Xu, and Wang]{han2021transformer}
Kai Han, An~Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang.
\newblock Transformer in transformer.
\newblock \emph{arXiv preprint arXiv:2103.00112}, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2016.

\bibitem[He et~al.(2017)He, Gkioxari, Doll{\'a}r, and Girshick]{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In \emph{International Conference on Computer Vision}, 2017.

\bibitem[Ho et~al.(2019)Ho, Kalchbrenner, Weissenborn, and
  Salimans]{ho2019axial}
Jonathan Ho, Nal Kalchbrenner, Dirk Weissenborn, and Tim Salimans.
\newblock Axial attention in multidimensional transformers.
\newblock \emph{arXiv preprint arXiv:1912.12180}, 2019.

\bibitem[Horn et~al.(2017)Horn, {Mac Aodha}, Song, Shepard, Adam, Perona, and
  Belongie]{Horn2019INaturalist}
Grant~Van Horn, Oisin {Mac Aodha}, Yang Song, Alexander Shepard, Hartwig Adam,
  Pietro Perona, and Serge~J. Belongie.
\newblock The {iNaturalist} species classification and detection dataset.
\newblock \emph{arXiv preprint arXiv:1707.06642}, 2017.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{hu2018squeeze}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2018.

\bibitem[Huang et~al.(2016)Huang, Sun, Liu, Sedra, and
  Weinberger]{huang2016deep}
Gao Huang, Yu~Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In \emph{European Conference on Computer Vision}, 2016.

\bibitem[Jaegle et~al.(2021)Jaegle, Gimeno, Brock, Zisserman, Vinyals, and
  Carreira]{jaegle2021perceiver}
Andrew Jaegle, Felix Gimeno, Andrew Brock, Andrew Zisserman, Oriol Vinyals, and
  Joao Carreira.
\newblock Perceiver: General perception with iterative attention.
\newblock \emph{arXiv preprint arXiv:2103.03206}, 2021.

\bibitem[J{\'e}gou et~al.(2008)J{\'e}gou, Douze, and
  Schmid]{Jegou2008HammingEA}
Herv{\'e} J{\'e}gou, Matthijs Douze, and Cordelia Schmid.
\newblock Hamming embedding and weak geometric consistency for large scale
  image search.
\newblock In \emph{European Conference on Computer Vision}, 2008.

\bibitem[J{\'e}gou et~al.(2012)J{\'e}gou, Perronnin, Douze, S{\'a}nchez, Perez,
  and Schmid]{jegou2012aggregating}
Herv{\'e} J{\'e}gou, Florent Perronnin, Matthijs Douze, Jorge S{\'a}nchez,
  Patrick Perez, and Cordelia Schmid.
\newblock Aggregating local image descriptors into compact codes.
\newblock \emph{{\sc IEEE} Transactions on Pattern Analysis and Machine
  Intelligence}, 34\penalty0 (9), 2012.

\bibitem[Katharopoulos et~al.(2020)Katharopoulos, Vyas, Pappas, and
  Fleuret]{katharopoulos2020transformers}
Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran{\c{c}}ois
  Fleuret.
\newblock Transformers are {RNNs}: Fast autoregressive transformers with linear
  attention.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Kirillov et~al.(2019)Kirillov, Girshick, He, and
  Doll{\'a}r]{kirillov2019panoptic}
Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Panoptic feature pyramid networks.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2019.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{Cars2013}
Jonathan Krause, Michael Stark, Jia Deng, and Li~Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In \emph{4th International IEEE Workshop on 3D Representation and
  Recognition (3dRR-13)}, 2013.

\bibitem[Krizhevsky(2009)]{Krizhevsky2009LearningML}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, CIFAR, 2009.

\bibitem[Lee-Thorp et~al.(2021)Lee-Thorp, Ainslie, Eckstein, and
  Ontanon]{lee2021fnet}
James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, and Santiago Ontanon.
\newblock Fnet: Mixing tokens with fourier transforms.
\newblock \emph{arXiv preprint arXiv:2105.03824}, 2021.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European Conference on Computer Vision}, 2014.

\bibitem[Lin et~al.(2017)Lin, Doll{\'a}r, Girshick, He, Hariharan, and
  Belongie]{lin2017feature}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2017.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock \emph{arXiv preprint arXiv:2103.14030}, 2021.

\bibitem[Loshchilov and Hutter(2017)]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Melas-Kyriazi(2021)]{melaskyriazi2021doyoueven}
Luke Melas-Kyriazi.
\newblock Do you even need attention? a stack of feed-forward layers does
  surprisingly well on imagenet.
\newblock \emph{arXiv preprint arXiv:2105.02723}, 2021.

\bibitem[Nilsback and Zisserman(2008)]{Nilsback08}
M-E. Nilsback and A.~Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{Proceedings of the Indian Conference on Computer Vision,
  Graphics and Image Processing}, 2008.

\bibitem[Parmar et~al.(2018)Parmar, Vaswani, Uszkoreit, Kaiser, Shazeer, Ku,
  and Tran]{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer,
  Alexander Ku, and Dustin Tran.
\newblock Image transformer.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Philbin et~al.(2007)Philbin, Chum, Isard, Sivic, and
  Zisserman]{Philbin07}
J.~Philbin, O.~Chum, M.~Isard, J.~Sivic, and A.~Zisserman.
\newblock Object retrieval with large vocabularies and fast spatial matching.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2007.

\bibitem[Qiu et~al.(2019)Qiu, Ma, Levy, Yih, Wang, and Tang]{qiu2019blockwise}
Jiezhong Qiu, Hao Ma, Omer Levy, Scott Wen-tau Yih, Sinong Wang, and Jie Tang.
\newblock Blockwise self-attention for long document understanding.
\newblock \emph{arXiv preprint arXiv:1911.02972}, 2019.

\bibitem[Radenovi{\'c} et~al.(2018{\natexlab{a}})Radenovi{\'c}, Iscen, Tolias,
  Avrithis, and Chum]{radenovic2018revisiting}
Filip Radenovi{\'c}, Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, and
  Ond{\v{r}}ej Chum.
\newblock Revisiting oxford and paris: Large-scale image retrieval
  benchmarking.
\newblock In \emph{Computer Vision and Pattern Recognition},
  2018{\natexlab{a}}.

\bibitem[Radenovi{\'c} et~al.(2018{\natexlab{b}})Radenovi{\'c}, Tolias, and
  Chum]{radenovic2018fine}
Filip Radenovi{\'c}, Giorgos Tolias, and Ondrej Chum.
\newblock Fine-tuning {CNN} image retrieval with no human annotation.
\newblock \emph{{\sc IEEE} Transactions on Pattern Analysis and Machine
  Intelligence}, 2018{\natexlab{b}}.

\bibitem[Radosavovic et~al.(2020)Radosavovic, Kosaraju, Girshick, He, and
  Doll{\'a}r]{radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2020.

\bibitem[Ranftl et~al.(2021)Ranftl, Bochkovskiy, and Koltun]{ranftl2021vision}
Ren{\'e} Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.
\newblock Vision transformers for dense prediction.
\newblock \emph{arXiv preprint arXiv:2103.13413}, 2021.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht2019imagenet}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Shen et~al.(2021)Shen, Zhang, Zhao, Yi, and Li]{shen2021efficient}
Zhuoran Shen, Mingyuan Zhang, Haiyu Zhao, Shuai Yi, and Hongsheng Li.
\newblock Efficient attention: Attention with linear complexities.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, 2021.

\bibitem[Sukhbaatar et~al.(2019)Sukhbaatar, Grave, Bojanowski, and
  Joulin]{sukhbaatar2019adaptive}
Sainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, and Armand Joulin.
\newblock Adaptive attention span in transformers.
\newblock \emph{arXiv preprint arXiv:1905.07799}, 2019.

\bibitem[Tan and Le(2019)]{tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2019.

\bibitem[Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland,
  Borth, and Li]{thomee2016yfcc100m}
Bart Thomee, David~A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni,
  Douglas Poland, Damian Borth, and Li-Jia Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock \emph{Communications of the ACM}, 59\penalty0 (2):\penalty0 64--73,
  2016.

\bibitem[Tolias et~al.(2016{\natexlab{a}})Tolias, Avrithis, and
  J{\'e}gou]{tolias2016image}
Giorgos Tolias, Yannis Avrithis, and Herv{\'e} J{\'e}gou.
\newblock Image search with selective match kernels: aggregation across single
  and multiple images.
\newblock \emph{International journal of Computer Vision}, 116\penalty0 (3),
  2016{\natexlab{a}}.

\bibitem[Tolias et~al.(2016{\natexlab{b}})Tolias, Sicre, and
  J{\'e}gou]{tolias2016particular}
Giorgos Tolias, Ronan Sicre, and Herv{\'e} J{\'e}gou.
\newblock Particular object retrieval with integral max-pooling of cnn
  activations.
\newblock In \emph{International Conference on Learning Representations},
  2016{\natexlab{b}}.

\bibitem[Tolias et~al.(2020)Tolias, Jenicek, and Chum]{tolias2020learning}
Giorgos Tolias, Tomas Jenicek, and Ond{\v{r}}ej Chum.
\newblock Learning and aggregating deep local descriptors for instance-level
  recognition.
\newblock In \emph{European Conference on Computer Vision}, 2020.

\bibitem[Tolstikhin et~al.(2021)Tolstikhin, Houlsby, Kolesnikov, Beyer, Zhai,
  Unterthiner, Yung, Steiner, Keysers, Uszkoreit, Lucic, and
  Dosovitskiy]{Tolstikhin21mixer}
Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai,
  Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers, Jakob
  Uszkoreit, Mario Lucic, and Alexey Dosovitskiy.
\newblock {MLP-Mixer}: An all-{MLP} architecture for vision.
\newblock \emph{arXiv preprint arXiv:2105.01601}, 2021.

\bibitem[Touvron et~al.(2019)Touvron, Vedaldi, Douze, and
  J{\'e}gou]{touvron2019fixing}
H~Touvron, A~Vedaldi, M~Douze, and H~J{\'e}gou.
\newblock Fixing the train-test resolution discrepancy.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Touvron et~al.(2020{\natexlab{a}})Touvron, Cord, Douze, Massa,
  Sablayrolles, and J\'egou]{touvron2020deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv\'e J\'egou.
\newblock Training data-efficient image transformers and distillation through
  attention.
\newblock \emph{arXiv preprint arXiv:2012.12877}, 2020{\natexlab{a}}.

\bibitem[Touvron et~al.(2020{\natexlab{b}})Touvron, Vedaldi, Douze, and
  J{\'e}gou]{touvron2020fixing}
Hugo Touvron, Andrea Vedaldi, Matthijs Douze, and Herv{\'e} J{\'e}gou.
\newblock Fixing the train-test resolution discrepancy: Fixefficientnet.
\newblock \emph{arXiv preprint arXiv:2003.08237}, 2020{\natexlab{b}}.

\bibitem[Touvron et~al.(2021{\natexlab{a}})Touvron, Bojanowski, Caron, Cord,
  El-Nouby, Grave, Joulin, Synnaeve, Verbeek, and J\'egou]{Touvron21ResMLP}
Hugo Touvron, Piotr Bojanowski, Mathilde Caron, Matthieu Cord, Alaaeldin
  El-Nouby, Edouard Grave, Armand Joulin, Gabriel Synnaeve, Jakob Verbeek, and
  Herv\'e J\'egou.
\newblock {ResMLP}: Feedforward networks for image classification with
  data-efficient training.
\newblock \emph{arXiv preprint arXiv:2105.03404}, 2021{\natexlab{a}}.

\bibitem[Touvron et~al.(2021{\natexlab{b}})Touvron, Cord, Sablayrolles,
  Synnaeve, and J{\'e}gou]{touvron2021going}
Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and
  Herv{\'e} J{\'e}gou.
\newblock Going deeper with image transformers.
\newblock \emph{arXiv preprint arXiv:2103.17239}, 2021{\natexlab{b}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Wang et~al.(2020)Wang, Li, Khabsa, Fang, and Ma]{wang2020linformer}
Sinong Wang, Belinda Li, Madian Khabsa, Han Fang, and Hao Ma.
\newblock Linformer: Self-attention with linear complexity.
\newblock \emph{arXiv preprint arXiv:2006.04768}, 2020.

\bibitem[Wang et~al.(2021)Wang, Xie, Li, Fan, Song, Liang, Lu, Luo, and
  Shao]{wang2021pyramid}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock \emph{arXiv preprint arXiv:2102.12122}, 2021.

\bibitem[Wightman(2019)]{rw2019timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Wu and He(2018)]{wu2018group}
Yuxin Wu and Kaiming He.
\newblock Group normalization.
\newblock In \emph{European Conference on Computer Vision}, 2018.

\bibitem[Xiao et~al.(2018)Xiao, Liu, Zhou, Jiang, and Sun]{xiao2018unified}
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In \emph{European Conference on Computer Vision}, 2018.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'a}r, Tu, and
  He]{xie2017aggregated}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2017.

\bibitem[Xie et~al.(2021)Xie, Lin, Yao, Zhang, Dai, Cao, and Hu]{xie2021self}
Zhenda Xie, Yutong Lin, Zhuliang Yao, Zheng Zhang, Qi~Dai, Yue Cao, and Han Hu.
\newblock Self-supervised learning with swin transformers.
\newblock \emph{arXiv preprint arXiv:2105.04553}, 2021.

\bibitem[Xiong et~al.(2021)Xiong, Zeng, Chakraborty, Tan, Fung, Li, and
  Singh]{xiong2021nystr}
Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung,
  Yin Li, and Vikas Singh.
\newblock Nystr\" omformer: A nystr\" om-based algorithm for approximating
  self-attention.
\newblock \emph{arXiv preprint arXiv:2102.03902}, 2021.

\bibitem[Yuan et~al.(2021{\natexlab{a}})Yuan, Guo, Liu, Zhou, Yu, and
  Wu]{yuan2021incorporating}
Kun Yuan, Shaopeng Guo, Ziwei Liu, Aojun Zhou, Fengwei Yu, and Wei Wu.
\newblock Incorporating convolution designs into visual transformers.
\newblock \emph{arXiv preprint arXiv:2103.11816}, 2021{\natexlab{a}}.

\bibitem[Yuan et~al.(2021{\natexlab{b}})Yuan, Chen, Wang, Yu, Shi, Jiang, Tay,
  Feng, and Yan]{yuan2021tokens}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis~EH
  Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token {ViT}: Training vision transformers from scratch on
  {ImageNet}.
\newblock \emph{arXiv preprint arXiv:2101.11986}, 2021{\natexlab{b}}.

\bibitem[Zaheer et~al.(2020)Zaheer, Guruganesh, Dubey, Ainslie, Alberti,
  Ontanon, Pham, Ravula, Wang, Yang, et~al.]{zaheer2020big}
Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti,
  Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li~Yang, et~al.
\newblock Big bird: Transformers for longer sequences.
\newblock \emph{arXiv preprint arXiv:2007.14062}, 2020.

\bibitem[Zhang et~al.(2021)Zhang, Dai, Yang, Xiao, Yuan, Zhang, and
  Gao]{zhang2021multi}
Pengchuan Zhang, Xiyang Dai, Jianwei Yang, Bin Xiao, Lu~Yuan, Lei Zhang, and
  Jianfeng Gao.
\newblock Multi-scale vision longformer: A new vision transformer for
  high-resolution image encoding.
\newblock \emph{arXiv preprint arXiv:2103.15358}, 2021.

\bibitem[Zhao et~al.(2020)Zhao, Jia, and Koltun]{zhao20cvpr}
Hengshuang Zhao, Jiaya Jia, and Vladlen Koltun.
\newblock Exploring self-attention for image recognition.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2020.

\bibitem[Zheng et~al.(2020)Zheng, Lu, Zhao, Zhu, Luo, Wang, Fu, Feng, Xiang,
  Torr, et~al.]{zheng2020rethinking}
Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang,
  Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip~HS Torr, et~al.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock \emph{arXiv preprint arXiv:2012.15840}, 2020.

\bibitem[Zhou et~al.(2017)Zhou, Zhao, Puig, Fidler, Barriuso, and
  Torralba]{zhou2017scene}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2017.

\end{thebibliography}
