\begin{thebibliography}{78}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adhikari(2019)]{10.1093/bioinformatics/btz593}
Adhikari, B.
\newblock {DEEPCON: protein contact prediction using dilated convolutional
  neural networks with dropout}.
\newblock \emph{Bioinformatics}, 36\penalty0 (2):\penalty0 470--477, 07 2019.

\bibitem[Aghajanyan et~al.(2021)Aghajanyan, Shrivastava, Gupta, Goyal,
  Zettlemoyer, and Gupta]{Aghajanyan2021BetterFB}
Aghajanyan, A., Shrivastava, A., Gupta, A., Goyal, N., Zettlemoyer, L., and
  Gupta, S.
\newblock Better fine-tuning by reducing representational collapse.
\newblock \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ahn et~al.(2022)Ahn, Brohan, Brown, Chebotar, Cortes, David, Finn,
  Gopalakrishnan, Hausman, Herzog, Ho, Hsu, Ibarz, Ichter, Irpan, Jang, Ruano,
  Jeffrey, Jesmonth, Joshi, Julian, Kalashnikov, Kuang, Lee, Levine, Lu, Luu,
  Parada, Pastor, Quiambao, Rao, Rettinghouse, Reyes, Sermanet, Sievers, Tan,
  Toshev, Vanhoucke, Xia, Xiao, Xu, Xu, and Yan]{Ahn2022DoAI}
Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., Finn, C.,
  Gopalakrishnan, K., Hausman, K., Herzog, A., Ho, D., Hsu, J., Ibarz, J.,
  Ichter, B., Irpan, A., Jang, E., Ruano, R.~J., Jeffrey, K., Jesmonth, S.,
  Joshi, N.~J., Julian, R.~C., Kalashnikov, D., Kuang, Y., Lee, K.-H., Levine,
  S., Lu, Y., Luu, L., Parada, C., Pastor, P., Quiambao, J., Rao, K.,
  Rettinghouse, J., Reyes, D.~M., Sermanet, P., Sievers, N., Tan, C., Toshev,
  A., Vanhoucke, V., Xia, F., Xiao, T., Xu, P., Xu, S., and Yan, M.
\newblock Do as i can, not as i say: Grounding language in robotic affordances.
\newblock \emph{ArXiv}, abs/2204.01691, 2022.

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc,
  Mensch, Millican, Reynolds, Ring, Rutherford, Cabi, Han, Gong, Samangooei,
  Monteiro, Menick, Borgeaud, Brock, Nematzadeh, Sharifzadeh, Binkowski,
  Barreira, Vinyals, Zisserman, and Simonyan]{Alayrac2022FlamingoAV}
Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc,
  K., Mensch, A., Millican, K., Reynolds, M., Ring, R., Rutherford, E., Cabi,
  S., Han, T., Gong, Z., Samangooei, S., Monteiro, M., Menick, J., Borgeaud,
  S., Brock, A., Nematzadeh, A., Sharifzadeh, S., Binkowski, M., Barreira, R.,
  Vinyals, O., Zisserman, A., and Simonyan, K.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem[Alvarez-Melis \& Fusi(2020)Alvarez-Melis and
  Fusi]{AlvarezMelis2020GeometricDD}
Alvarez-Melis, D. and Fusi, N.
\newblock Geometric dataset distances via optimal transport.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, rahman Mohamed, and
  Auli]{Baevski2020wav2vec2A}
Baevski, A., Zhou, H., rahman Mohamed, A., and Auli, M.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem[Bahng et~al.(2022)Bahng, Jahanian, Sankaranarayanan, and
  Isola]{Bahng2022ExploringVP}
Bahng, H., Jahanian, A., Sankaranarayanan, S., and Isola, P.
\newblock Exploring visual prompts for adapting large-scale models.
\newblock 2022.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{Carion2020EndtoEndOD}
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko,
  S.
\newblock End-to-end object detection with transformers.
\newblock \emph{European Conference on Computer Vision}, 2020.

\bibitem[Chen et~al.(2022)Chen, Wang, Chen, Wu, Liu, Chen, Li, Kanda, Yoshioka,
  Xiao, et~al.]{chen2022wavlm}
Chen, S., Wang, C., Chen, Z., Wu, Y., Liu, S., Chen, Z., Li, J., Kanda, N.,
  Yoshioka, T., Xiao, X., et~al.
\newblock Wavlm: Large-scale self-supervised pre-training for full stack speech
  processing.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing}, 2022.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{Chen2016XGBoostAS}
Chen, T. and Guestrin, C.
\newblock Xgboost: A scalable tree boosting system.
\newblock \emph{Proceedings of the 22nd ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining}, 2016.

\bibitem[Cohen et~al.(2018)Cohen, Geiger, K{\"o}hler, and
  Welling]{Cohen2018SphericalC}
Cohen, T., Geiger, M., K{\"o}hler, J., and Welling, M.
\newblock Spherical cnns.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Cuturi(2013)]{Cuturi2013SinkhornDL}
Cuturi, M.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2013.

\bibitem[Dempster et~al.(2020)Dempster, Petitjean, and
  Webb]{Dempster2020ROCKETEF}
Dempster, A., Petitjean, F., and Webb, G.~I.
\newblock Rocket: exceptionally fast and accurate time series classification
  using random convolutional kernels.
\newblock \emph{Data Mining and Knowledge Discovery}, 34:\penalty0 1454--1495,
  2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{Devlin2019BERTPO}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{Proceedings of NAACL-HLT 2019}, 2019.

\bibitem[Dinh et~al.(2022)Dinh, Zeng, Zhang, Lin, Rajput, Gira, yong Sohn,
  Papailiopoulos, and Lee]{Dinh2022LIFTLF}
Dinh, T., Zeng, Y., Zhang, R., Lin, Z., Rajput, S., Gira, M., yong Sohn, J.,
  Papailiopoulos, D., and Lee, K.
\newblock Lift: Language-interfaced fine-tuning for non-language machine
  learning tasks.
\newblock \emph{ArXiv}, abs/2206.06565, 2022.

\bibitem[Dolan \& Mor\'e(2002)Dolan and Mor\'e]{dolan2002profiles}
Dolan, E.~D. and Mor\'e, J.~J.
\newblock Benchmarking optimization software with performance profiles.
\newblock \emph{Mathematical Programming}, 91:\penalty0 201--213, 2002.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{Dosovitskiy2021AnII}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{International Conference on Learning Representations}, 2021.

\bibitem[Erickson et~al.(2020)Erickson, Mueller, Shirkov, Zhang, Larroy, Li,
  and Smola]{Erickson2020AutoGluonTabularRA}
Erickson, N., Mueller, J., Shirkov, A., Zhang, H., Larroy, P., Li, M., and
  Smola, A.
\newblock Autogluon-tabular: Robust and accurate automl for structured data.
\newblock \emph{ArXiv}, abs/2003.06505, 2020.

\bibitem[Fang et~al.(2020)Fang, Sun, Zhang, Li, Liu, and
  Wang]{Fang2020DenselyCS}
Fang, J., Sun, Y., Zhang, Q., Li, Y., Liu, W., and Wang, X.
\newblock Densely connected search space for more flexible neural architecture
  search.
\newblock \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  10625--10634, 2020.

\bibitem[Fonseca et~al.(2021)Fonseca, Favory, Pons, Font, and
  Serra]{Fonseca2021FSD50KAO}
Fonseca, E., Favory, X., Pons, J., Font, F., and Serra, X.
\newblock Fsd50k: an open dataset of human-labeled sound events.
\newblock \emph{ArXiv}, abs/2010.00475, 2021.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{Gretton2012AKT}
Gretton, A., Borgwardt, K.~M., Rasch, M.~J., Sch{\"o}lkopf, B., and Smola, A.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 723--773,
  2012.

\bibitem[He et~al.(2022)He, Zhou, Ma, Berg-Kirkpatrick, and
  Neubig]{He2022TowardsAU}
He, J., Zhou, C., Ma, X., Berg-Kirkpatrick, T., and Neubig, G.
\newblock Towards a unified view of parameter-efficient transfer learning.
\newblock \emph{International Conference on Learning Representations}, 2022.

\bibitem[Hollmann et~al.(2022)Hollmann, Muller, Eggensperger, and
  Hutter]{Hollmann2022TabPFNAT}
Hollmann, N., Muller, S., Eggensperger, K., and Hutter, F.
\newblock Tabpfn: A transformer that solves small tabular classification
  problems in a second.
\newblock 2022.

\bibitem[Hong et~al.(2020)Hong, Xu, Khare, Priambada, Maher, Aljiffry, Sun, and
  Tumanov]{Hong2020HOLMESHO}
Hong, S., Xu, Y., Khare, A., Priambada, S., Maher, K.~O., Aljiffry, A., Sun,
  J., and Tumanov, A.
\newblock Holmes: Health online model ensemble serving for deep learning models
  in intensive care units.
\newblock \emph{Proceedings of the 26th ACM SIGKDD International Conference on
  Knowledge Discovery \& Data Mining}, 2020.

\bibitem[Hu \& Singh(2021)Hu and Singh]{Hu2021UniTMM}
Hu, R. and Singh, A.
\newblock Unit: Multimodal multitask learning with a unified transformer.
\newblock \emph{2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pp.\  1419--1429, 2021.

\bibitem[Huang et~al.(2017)Huang, Liu, and Weinberger]{Huang2017DenselyCC}
Huang, G., Liu, Z., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock \emph{2017 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  2261--2269, 2017.

\bibitem[Jaegle et~al.(2021)Jaegle, Gimeno, Brock, Zisserman, Vinyals, and
  Carreira]{Jaegle2021PerceiverGP}
Jaegle, A., Gimeno, F., Brock, A., Zisserman, A., Vinyals, O., and Carreira, J.
\newblock Perceiver: General perception with iterative attention.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Jaegle et~al.(2022)Jaegle, Borgeaud, Alayrac, Doersch, Ionescu, Ding,
  Koppula, Zoran, Brock, Shelhamer, Henaff, Botvinick, Zisserman, Vinyals, and
  Carreira]{jaegle2022perceiver}
Jaegle, A., Borgeaud, S., Alayrac, J.-B., Doersch, C., Ionescu, C., Ding, D.,
  Koppula, S., Zoran, D., Brock, A., Shelhamer, E., Henaff, O.~J., Botvinick,
  M., Zisserman, A., Vinyals, O., and Carreira, J.
\newblock Perceiver {IO}: A general architecture for structured inputs \&
  outputs.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Jia et~al.(2022)Jia, Tang, Chen, Cardie, Belongie, Hariharan, and
  Lim]{Jia2022VisualPT}
Jia, M., Tang, L., Chen, B.-C., Cardie, C., Belongie, S.~J., Hariharan, B., and
  Lim, S.~N.
\newblock Visual prompt tuning.
\newblock In \emph{ECCV}, 2022.

\bibitem[Jiang et~al.(2021)Jiang, Li, Zhang, Cao, Luo, Han, Zou, Han, and
  Li]{jiang2021further}
Jiang, D., Li, W., Zhang, R., Cao, M., Luo, N., Han, Y., Zou, W., Han, K., and
  Li, X.
\newblock A further study of unsupervised pretraining for transformer based
  speech recognition.
\newblock In \emph{ICASSP 2021-2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  6538--6542. IEEE, 2021.

\bibitem[Jiang et~al.(2020)Jiang, He, Chen, Liu, Gao, and
  Zhao]{Jiang2020SMARTRA}
Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Zhao, T.
\newblock Smart: Robust and efficient fine-tuning for pre-trained natural
  language models through principled regularized optimization.
\newblock \emph{Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, 2020.

\bibitem[Josephs et~al.(2020)Josephs, Drake, Heroy, and
  Santerre]{Josephs2020sEMGGR}
Josephs, D., Drake, C., Heroy, A.~M., and Santerre, J.
\newblock semg gesture recognition with a simple model of attention.
\newblock \emph{Machine Learning for Health}, pp.\  126--138, 2020.

\bibitem[Jumper et~al.(2021)Jumper, Evans, Pritzel, Green, Figurnov,
  Ronneberger, Tunyasuvunakool, Bates, Z{\'i}dek, Potapenko, Bridgland, Meyer,
  Kohl, Ballard, Cowie, Romera-Paredes, Nikolov, Jain, Adler, Back, Petersen,
  Reiman, Clancy, Zielinski, Steinegger, Pacholska, Berghammer, Bodenstein,
  Silver, Vinyals, Senior, Kavukcuoglu, Kohli, and
  Hassabis]{Jumper2021HighlyAP}
Jumper, J.~M., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger,
  O., Tunyasuvunakool, K., Bates, R., Z{\'i}dek, A., Potapenko, A., Bridgland,
  A., Meyer, C., Kohl, S. A.~A., Ballard, A., Cowie, A., Romera-Paredes, B.,
  Nikolov, S., Jain, R., Adler, J., Back, T., Petersen, S., Reiman, D.~A.,
  Clancy, E., Zielinski, M., Steinegger, M., Pacholska, M., Berghammer, T.,
  Bodenstein, S., Silver, D., Vinyals, O., Senior, A.~W., Kavukcuoglu, K.,
  Kohli, P., and Hassabis, D.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock \emph{Nature}, 596:\penalty0 583 -- 589, 2021.

\bibitem[Ke et~al.(2017)Ke, Meng, Finley, Wang, Chen, Ma, Ye, and
  Liu]{Ke2017LightGBMAH}
Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., and Liu,
  T.-Y.
\newblock Lightgbm: A highly efficient gradient boosting decision tree.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Kiela et~al.(2019)Kiela, Bhooshan, Firooz, and
  Testuggine]{Kiela2019SupervisedMB}
Kiela, D., Bhooshan, S., Firooz, H., and Testuggine, D.
\newblock Supervised multimodal bitransformers for classifying images and text.
\newblock \emph{ArXiv}, abs/1909.02950, 2019.

\bibitem[Kim et~al.(2021)Kim, Son, and Kim]{Kim2021ViLTVT}
Kim, W., Son, B., and Kim, I.
\newblock Vilt: Vision-and-language transformer without convolution or region
  supervision.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and
  Liang]{Kumar2022FineTuningCD}
Kumar, A., Raghunathan, A., Jones, R., Ma, T., and Liang, P.
\newblock Fine-tuning can distort pretrained features and underperform
  out-of-distribution.
\newblock \emph{International Conference on Learning Representations}, 2022.

\bibitem[Lee et~al.(2022)Lee, Chen, Tajwar, Kumar, Yao, Liang, and
  Finn]{Lee2022SurgicalFI}
Lee, Y., Chen, A.~S., Tajwar, F., Kumar, A., Yao, H., Liang, P., and Finn, C.
\newblock Surgical fine-tuning improves adaptation to distribution shifts.
\newblock \emph{ArXiv}, abs/2210.11466, 2022.

\bibitem[Li et~al.(2022)Li, Zhang, Xu, Liu, Zhang, Ni, and yeung
  Shum]{Li2022MaskDT}
Li, F., Zhang, H., Xu, H.-S., Liu, S., Zhang, L., Ni, L.~M., and yeung Shum, H.
\newblock Mask dino: Towards a unified transformer-based framework for object
  detection and segmentation.
\newblock \emph{ArXiv}, abs/2206.02777, 2022.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Jamieson, Rostamizadeh, Gonina,
  Ben-Tzur, Hardt, Recht, and Talwalkar]{li2020system}
Li, L., Jamieson, K., Rostamizadeh, A., Gonina, E., Ben-Tzur, J., Hardt, M.,
  Recht, B., and Talwalkar, A.
\newblock A system for massively parallel hyperparameter tuning.
\newblock \emph{Proceedings of Machine Learning and Systems}, 2:\penalty0
  230--246, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Xie, Wu, Zhao, Liu, and
  Ding]{li2020simultaneous}
Li, S., Xie, B., Wu, J., Zhao, Y., Liu, C.~H., and Ding, Z.
\newblock Simultaneous semantic alignment network for heterogeneous domain
  adaptation.
\newblock In \emph{Proceedings of the 28th ACM international conference on
  multimedia}, pp.\  3866--3874, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2020{\natexlab{c}})Li, Ponti, Vulic, and
  Korhonen]{Li2020EmergentCP}
Li, Y., Ponti, E., Vulic, I., and Korhonen, A.
\newblock Emergent communication pretraining for few-shot machine translation.
\newblock In \emph{COLING}, 2020{\natexlab{c}}.

\bibitem[Li et~al.(2021)Li, Kovachki, Azizzadenesheli, Liu, Bhattacharya,
  Stuart, and Anandkumar]{li2021fno}
Li, Z., Kovachki, N.~B., Azizzadenesheli, K., Liu, B., Bhattacharya, K.,
  Stuart, A., and Anandkumar, A.
\newblock Fourier neural operator for parametric partial differential
  equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Chen, Schroff, Adam, Hua, Yuille,
  and Fei-Fei]{Liu2019AutoDeepLabHN}
Liu, C., Chen, L.-C., Schroff, F., Adam, H., Hua, W., Yuille, A.~L., and
  Fei-Fei, L.
\newblock Auto-deeplab: Hierarchical neural architecture search for semantic
  image segmentation.
\newblock \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  82--92, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Simonyan, and Yang]{liu2018darts}
Liu, H., Simonyan, K., and Yang, Y.
\newblock {DARTS}: Differentiable architecture search.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[Liu et~al.(2021{\natexlab{a}})Liu, Yuan, Fu, Jiang, Hayashi, and
  Neubig]{liu2021pre}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock \emph{arXiv preprint arXiv:2107.13586}, 2021{\natexlab{a}}.

\bibitem[Liu et~al.(2022)Liu, Yuan, Fu, Jiang, Hayashi, and
  Neubig]{Liu2022PretrainPA}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock \emph{ACM Computing Surveys (CSUR)}, 2022.

\bibitem[Liu et~al.(2019{\natexlab{c}})Liu, Ott, Goyal, Du, Joshi, Chen, Levy,
  Lewis, Zettlemoyer, and Stoyanov]{Liu2019RoBERTaAR}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{ArXiv}, abs/1907.11692, 2019{\natexlab{c}}.

\bibitem[Liu et~al.(2021{\natexlab{b}})Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{Liu2021SwinTH}
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., and Guo, B.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock \emph{2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pp.\  9992--10002, 2021{\natexlab{b}}.

\bibitem[Lu et~al.(2022)Lu, Grover, Abbeel, and
  Mordatch]{Lu_Grover_Abbeel_Mordatch_2022}
Lu, K., Grover, A., Abbeel, P., and Mordatch, I.
\newblock Frozen pretrained transformers as universal computation engines.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  36\penalty0 (7):\penalty0 7628--7636, Jun. 2022.

\bibitem[Ostroumova et~al.(2017)Ostroumova, Gusev, Vorobev, Dorogush, and
  Gulin]{Ostroumova2017CatBoostUB}
Ostroumova, L., Gusev, G., Vorobev, A., Dorogush, A.~V., and Gulin, A.
\newblock Catboost: unbiased boosting with categorical features.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Pan \& Yang(2009)Pan and Yang]{pan2009survey}
Pan, S.~J. and Yang, Q.
\newblock A survey on transfer learning.
\newblock \emph{IEEE Transactions on knowledge and data engineering},
  22\penalty0 (10):\penalty0 1345--1359, 2009.

\bibitem[Pele \& Werman(2009)Pele and Werman]{Pele2009FastAR}
Pele, O. and Werman, M.
\newblock Fast and robust earth mover's distances.
\newblock \emph{2009 IEEE 12th International Conference on Computer Vision},
  pp.\  460--467, 2009.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and
  Wang]{peng2019moment}
Peng, X., Bai, Q., Xia, X., Huang, Z., Saenko, K., and Wang, B.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1406--1415, 2019.

\bibitem[Radford \& Narasimhan(2018)Radford and
  Narasimhan]{Radford2018ImprovingLU}
Radford, A. and Narasimhan, K.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, Krueger, and
  Sutskever]{Radford2021LearningTV}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Raissi et~al.(2019)Raissi, Perdikaris, and
  Karniadakis]{Raissi2019PhysicsinformedNN}
Raissi, M., Perdikaris, P., and Karniadakis, G.~E.
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock \emph{J. Comput. Phys.}, 378:\penalty0 686--707, 2019.

\bibitem[Real et~al.(2020)Real, Liang, So, and Le]{Real2020AutoMLZeroEM}
Real, E., Liang, C., So, D.~R., and Le, Q.~V.
\newblock Automl-zero: Evolving machine learning algorithms from scratch.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Reed et~al.(2023)Reed, Zolna, Parisotto, Colmenarejo, Novikov,
  Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, Eccles, Bruce, Razavi,
  Edwards, Heess, Chen, Hadsell, Vinyals, Bordbar, and de~Freitas]{Reed2022AGA}
Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.~G., Novikov, A.,
  Barth-Maron, G., Gimenez, M., Sulsky, Y., Kay, J., Springenberg, J.~T.,
  Eccles, T., Bruce, J., Razavi, A., Edwards, A.~D., Heess, N. M.~O., Chen, Y.,
  Hadsell, R., Vinyals, O., Bordbar, M., and de~Freitas, N.
\newblock A generalist agent.
\newblock \emph{Transactions on Machine Learning Research}, 2023.

\bibitem[Reid et~al.(2022)Reid, Yamada, and Gu]{Reid2022CanWH}
Reid, M., Yamada, Y., and Gu, S.~S.
\newblock Can wikipedia help offline reinforcement learning?
\newblock \emph{ArXiv}, abs/2201.12122, 2022.

\bibitem[Roberts et~al.(2021)Roberts, Khodak, Dao, Li, Re, and
  Talwalkar]{roberts2021rethinking}
Roberts, N.~C., Khodak, M., Dao, T., Li, L., Re, C., and Talwalkar, A.
\newblock Rethinking neural operations for diverse tasks.
\newblock In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J.~W.
  (eds.), \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{Ronneberger2015UNetCN}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock \emph{ArXiv}, abs/1505.04597, 2015.

\bibitem[Rothermel et~al.(2021)Rothermel, Li, Rocktaschel, and
  Foerster]{Rothermel2021DontSY}
Rothermel, D., Li, M., Rocktaschel, T., and Foerster, J.~N.
\newblock Don't sweep your learning rate under the rug: A closer look at
  cross-modal transfer of pretrained transformers.
\newblock \emph{ICML 2021 Workshop: Self-Supervised Learning for Reasoning and
  Perception}, 2021.

\bibitem[Shen et~al.(2022)Shen, Khodak, and Talwalkar]{shen2022efficient}
Shen, J., Khodak, M., and Talwalkar, A.
\newblock Efficient architecture search for diverse tasks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Shi et~al.(2016)Shi, Caballero, Husz{\'a}r, Totz, Aitken, Bishop,
  Rueckert, and Wang]{shi2016real}
Shi, W., Caballero, J., Husz{\'a}r, F., Totz, J., Aitken, A.~P., Bishop, R.,
  Rueckert, D., and Wang, Z.
\newblock Real-time single image and video super-resolution using an efficient
  sub-pixel convolutional neural network.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1874--1883, 2016.

\bibitem[Takamoto et~al.(2022)Takamoto, Praditia, Leiteritz, MacKinlay,
  Alesiani, Pfl{\"u}ger, and Niepert]{Takamoto2022PDEBENCHAE}
Takamoto, M., Praditia, T., Leiteritz, R., MacKinlay, D., Alesiani, F.,
  Pfl{\"u}ger, D., and Niepert, M.
\newblock Pdebench: An extensive benchmark for scientific machine learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)
  Datasets and Benchmarks Track}, 2022.

\bibitem[Tan et~al.(2020)Tan, Peng, and Saenko]{Tan2020ClassImbalancedDA}
Tan, S., Peng, X., and Saenko, K.
\newblock Class-imbalanced domain adaptation: An empirical odyssey.
\newblock In \emph{ECCV Workshops}, 2020.

\bibitem[Tu et~al.(2022)Tu, Roberts, Khodak, Shen, Sala, and
  Talwalkar]{nasbench360}
Tu, R., Roberts, N., Khodak, M., Shen, J., Sala, F., and Talwalkar, A.
\newblock {NAS}-bench-360: Benchmarking neural architecture search on diverse
  tasks.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)
  Datasets and Benchmarks Track}, 2022.

\bibitem[Vanschoren et~al.(2014)Vanschoren, van Rijn, Bischl, and
  Torgo]{Vanschoren2014OpenMLNS}
Vanschoren, J., van Rijn, J.~N., Bischl, B., and Torgo, L.
\newblock Openml: networked science in machine learning.
\newblock \emph{SIGKDD Explor.}, 15:\penalty0 49--60, 2014.

\bibitem[Vinod et~al.(2023)Vinod, Chen, and Das]{Vinod2023ReprogrammingPL}
Vinod, R., Chen, P.-Y., and Das, P.
\newblock Reprogramming pretrained language models for protein sequence
  representation learning.
\newblock \emph{ArXiv}, abs/2301.02120, 2023.

\bibitem[Wang \& Deng(2018)Wang and Deng]{wang2018deep}
Wang, M. and Deng, W.
\newblock Deep visual domain adaptation: A survey.
\newblock \emph{Neurocomputing}, 312:\penalty0 135--153, 2018.

\bibitem[Wei et~al.(2022)Wei, Hu, Xie, Zhang, Cao, Bao, Chen, and
  Guo]{Wei2022ContrastiveLR}
Wei, Y., Hu, H., Xie, Z., Zhang, Z., Cao, Y., Bao, J., Chen, D., and Guo, B.
\newblock Contrastive learning rivals masked image modeling in fine-tuning via
  feature distillation.
\newblock \emph{ArXiv}, abs/2205.14141, 2022.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, and Brew]{Wolf2019HuggingFacesTS}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P.,
  Rault, T., Louf, R., Funtowicz, M., and Brew, J.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{ArXiv}, abs/1910.03771, 2019.

\bibitem[Yao et~al.(2019)Yao, Zhang, Li, and Ye]{yao2019heterogeneous}
Yao, Y., Zhang, Y., Li, X., and Ye, Y.
\newblock Heterogeneous domain adaptation via soft transfer network.
\newblock In \emph{Proceedings of the 27th ACM international conference on
  multimedia}, pp.\  1578--1586, 2019.

\bibitem[Zhang \& Bloom(2020)Zhang and Bloom]{Zhang2019deepCRCR}
Zhang, K. and Bloom, J.~S.
\newblock deepcr: Cosmic ray rejection with deep learning.
\newblock \emph{The Astrophysical Journal}, 889\penalty0 (1):\penalty0 24,
  2020.

\bibitem[Zhang et~al.(2020)Zhang, Park, Theesfeld, and
  Troyanskaya]{Zhang2020AnAF}
Zhang, Z., Park, C.~Y., Theesfeld, C.~L., and Troyanskaya, O.~G.
\newblock An automated framework for efficiently designing deep convolutional
  neural networks in genomics.
\newblock \emph{bioRxiv}, 2020.

\bibitem[Zhou \& Troyanskaya(2015)Zhou and Troyanskaya]{Zhou2015PredictingEO}
Zhou, J. and Troyanskaya, O.~G.
\newblock Predicting effects of noncoding variants with deep learning–based
  sequence model.
\newblock \emph{Nature Methods}, 12:\penalty0 931--934, 2015.

\bibitem[Zhu et~al.(2021)Zhu, Brettin, Xia, Partin, Shukla, Yoo, Evrard,
  Doroshow, and Stevens]{Zhu2021ConvertingTD}
Zhu, Y., Brettin, T.~S., Xia, F., Partin, A., Shukla, M., Yoo, H.~S., Evrard,
  Y.~A., Doroshow, J.~H., and Stevens, R.~L.
\newblock Converting tabular data into images for deep learning with
  convolutional neural networks.
\newblock \emph{Scientific Reports}, 11, 2021.

\end{thebibliography}
