@article{lepikhin2020gshard,
  title={Gshard: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={arXiv preprint arXiv:2006.16668},
  year={2020}
}

@article{routingsneha,
  title={Exploring Routing Strategies for Multilingual Mixture-of-Experts Models},
  author={Kudugunta, Sneha and Huang, Yanping and Bapna, Ankur and Krikun, Maxim and Lepikhin, Dmitry and Luong, Thang and Firat, Orhan},
  year={2021}
}

@inproceedings{wang2020balancing,
  title={Balancing Training for Multilingual Neural Machine Translation},
  author={Wang, Xinyi and Tsvetkov, Yulia and Neubig, Graham},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={8526--8537},
  year={2020}
}

@article{arivazhagan2019massively,
  title={Massively multilingual neural machine translation in the wild: Findings and challenges},
  author={Arivazhagan, Naveen and Bapna, Ankur and Firat, Orhan and Lepikhin, Dmitry and Johnson, Melvin and Krikun, Maxim and Chen, Mia Xu and Cao, Yuan and Foster, George and Cherry, Colin and others},
  journal={arXiv preprint arXiv:1907.05019},
  year={2019}
}

@article{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1810.04650},
  year={2018}
}

@article{desideri2012multiple,
  title={Multiple-gradient descent algorithm (MGDA) for multiobjective optimization},
  author={D{\'e}sid{\'e}ri, Jean-Antoine},
  journal={Comptes Rendus Mathematique},
  volume={350},
  number={5-6},
  pages={313--318},
  year={2012},
  publisher={Elsevier}
}

@article{qi2018and,
  title={When and why are pre-trained word embeddings useful for neural machine translation?},
  author={Qi, Ye and Sachan, Devendra Singh and Felix, Matthieu and Padmanabhan, Sarguna Janani and Neubig, Graham},
  journal={arXiv preprint arXiv:1804.06323},
  year={2018}
}
@article{post2018call,
  title={A call for clarity in reporting BLEU scores},
  author={Post, Matt},
  journal={arXiv preprint arXiv:1804.08771},
  year={2018}
}

@inproceedings{chen2018gradnorm,
  title={Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks},
  author={Chen, Zhao and Badrinarayanan, Vijay and Lee, Chen-Yu and Rabinovich, Andrew},
  booktitle={International Conference on Machine Learning},
  pages={794--803},
  year={2018},
  organization={PMLR}
}

@article{lample2019cross,
  title={Cross-lingual language model pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291},
  year={2019}
}

@article{zhang2020improving,
  title={Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation},
  author={Zhang, Biao and Williams, Philip and Titov, Ivan and Sennrich, Rico},
  journal={arXiv preprint arXiv:2004.11867},
  year={2020}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{sen2019multilingual,
  title={Multilingual unsupervised NMT using shared encoder and language-specific decoders},
  author={Sen, Sukanta and Gupta, Kamal Kumar and Ekbal, Asif and Bhattacharyya, Pushpak},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3083--3089},
  year={2019}
}

@book{bertsekas2014constrained,
  title={Constrained optimization and Lagrange multiplier methods},
  author={Bertsekas, Dimitri P},
  year={2014},
  publisher={Academic press}
}

@article{nakkiran2019deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1912.02292},
  year={2019}
}

@article{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  journal={arXiv preprint arXiv:1705.08741},
  year={2017}
}
@article{smith2017don,
  title={Don't decay the learning rate, increase the batch size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Ying, Chris and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.00489},
  year={2017}
}

@article{joshi2020state,
  title={The state and fate of linguistic diversity and inclusion in the NLP world},
  author={Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
  journal={arXiv preprint arXiv:2004.09095},
  year={2020}
}
@article{jean2019adaptive,
  title={Adaptive scheduling for multi-task learning},
  author={Jean, S{\'e}bastien and Firat, Orhan and Johnson, Melvin},
  journal={arXiv preprint arXiv:1909.06434},
  year={2019}
}
@article{mccandlish2018empirical,
  title={An empirical model of large-batch training},
  author={McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Team, OpenAI Dota},
  journal={arXiv preprint arXiv:1812.06162},
  year={2018}
}

@inproceedings{li2020train,
  title={Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers},
  author={Li, Zhuohan and Wallace, Eric and Shen, Sheng and Lin, Kevin and Keutzer, Kurt and Klein, Dan and Gonzalez, Joey},
  booktitle={International Conference on Machine Learning},
  pages={5958--5968},
  year={2020},
  organization={PMLR}
}



@article{gaur2020training,
  title={Training Deep Neural Networks Without Batch Normalization},
  author={Gaur, Divya and Folz, Joachim and Dengel, Andreas},
  journal={arXiv preprint arXiv:2008.07970},
  year={2020}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{ruder2019latent,
  title={Latent multi-task architecture learning},
  author={Ruder, Sebastian and Bingel, Joachim and Augenstein, Isabelle and S{\o}gaard, Anders},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4822--4829},
  year={2019}
}

@article{pires2019multilingual,
  title={How multilingual is Multilingual BERT?},
  author={Pires, Telmo and Schlinger, Eva and Garrette, Dan},
  journal={arXiv preprint arXiv:1906.01502},
  year={2019}
}
@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@inproceedings{standley2020tasks,
  title={Which tasks should be learned together in multi-task learning?},
  author={Standley, Trevor and Zamir, Amir and Chen, Dawn and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
  booktitle={International Conference on Machine Learning},
  pages={9120--9132},
  year={2020},
  organization={PMLR}
}

@article{wang2020gradient,
  title={Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models},
  author={Wang, Zirui and Tsvetkov, Yulia and Firat, Orhan and Cao, Yuan},
  journal={arXiv preprint arXiv:2010.05874},
  year={2020}
}

@article{wang2020negative,
  title={On Negative Interference in Multilingual Models: Findings and A Meta-Learning Treatment},
  author={Wang, Zirui and Lipton, Zachary C and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2010.03017},
  year={2020}
}

@article{suteu2019regularizing,
  title={Regularizing deep multi-task networks using orthogonal gradients},
  author={Suteu, Mihai and Guo, Yike},
  journal={arXiv preprint arXiv:1912.06844},
  year={2019}
}

@article{tang2020multilingual,
  title={Multilingual translation with extensible multilingual pretraining and finetuning},
  author={Tang, Yuqing and Tran, Chau and Li, Xian and Chen, Peng-Jen and Goyal, Naman and Chaudhary, Vishrav and Gu, Jiatao and Fan, Angela},
  journal={arXiv preprint arXiv:2008.00401},
  year={2020}
}
@article{kudugunta2019investigating,
  title={Investigating multilingual nmt representations at scale},
  author={Kudugunta, Sneha Reddy and Bapna, Ankur and Caswell, Isaac and Arivazhagan, Naveen and Firat, Orhan},
  journal={arXiv preprint arXiv:1909.02197},
  year={2019}
}

@article{sachan2018parameter,
  title={Parameter sharing methods for multilingual self-attentional translation models},
  author={Sachan, Devendra Singh and Neubig, Graham},
  journal={arXiv preprint arXiv:1809.00252},
  year={2018}
}
@article{tan2019multilingual,
  title={Multilingual neural machine translation with language clustering},
  author={Tan, Xu and Chen, Jiale and He, Di and Xia, Yingce and Qin, Tao and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1908.09324},
  year={2019}
}

@article{fedus2021switch,
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={arXiv preprint arXiv:2101.03961},
  year={2021}
}

@article{fan2020beyond,
  title={Beyond english-centric multilingual machine translation},
  author={Fan, Angela and Bhosale, Shruti and Schwenk, Holger and Ma, Zhiyi and El-Kishky, Ahmed and Goyal, Siddharth and Baines, Mandeep and Celebi, Onur and Wenzek, Guillaume and Chaudhary, Vishrav and others},
  journal={arXiv preprint arXiv:2010.11125},
  year={2020}
}

@inproceedings{choromanska2015loss,
  title={The loss surfaces of multilayer networks},
  author={Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'e}rard Ben and LeCun, Yann},
  booktitle={Artificial intelligence and statistics},
  pages={192--204},
  year={2015},
  organization={PMLR}
}

@article{goodfellow2014qualitatively,
  title={Qualitatively characterizing neural network optimization problems},
  author={Goodfellow, Ian J and Vinyals, Oriol and Saxe, Andrew M},
  journal={arXiv preprint arXiv:1412.6544},
  year={2014}
}

@article{calamai1987projected,
  title={Projected gradient methods for linearly constrained problems},
  author={Calamai, Paul H and Mor{\'e}, Jorge J},
  journal={Mathematical programming},
  volume={39},
  number={1},
  pages={93--116},
  year={1987},
  publisher={Springer}
}

@article{liu2020multilingual,
  title={Multilingual denoising pre-training for neural machine translation},
  author={Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={726--742},
  year={2020},
  publisher={MIT Press}
}

@article{wu2020all,
  title={Are All Languages Created Equal in Multilingual BERT?},
  author={Wu, Shijie and Dredze, Mark},
  journal={arXiv preprint arXiv:2005.09093},
  year={2020}
}

@article{lin2019pareto,
  title={Pareto multi-task learning},
  author={Lin, Xi and Zhen, Hui-Ling and Li, Zhenhua and Zhang, Qingfu and Kwong, Sam},
  journal={arXiv preprint arXiv:1912.12854},
  year={2019}
}


@article{baldi2013understanding,
  title={Understanding dropout},
  author={Baldi, Pierre and Sadowski, Peter J},
  journal={Advances in neural information processing systems},
  volume={26},
  pages={2814--2822},
  year={2013}
}

@article{mirzadeh2020understanding,
  title={Understanding the role of training regimes in continual learning},
  author={Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Pascanu, Razvan and Ghasemzadeh, Hassan},
  journal={arXiv preprint arXiv:2006.06958},
  year={2020}
}

@inproceedings{dinh2017sharp,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={1019--1028},
  year={2017},
  organization={PMLR}
}

@article{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={arXiv preprint arXiv:1805.11604},
  year={2018}
}

@book{ehrgott2005multicriteria,
  title={Multicriteria optimization},
  author={Ehrgott, Matthias},
  volume={491},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@article{ott2019fairseq,
  title={fairseq: A fast, extensible toolkit for sequence modeling},
  author={Ott, Myle and Edunov, Sergey and Baevski, Alexei and Fan, Angela and Gross, Sam and Ng, Nathan and Grangier, David and Auli, Michael},
  journal={arXiv preprint arXiv:1904.01038},
  year={2019}
}
@inproceedings{zhang2021share,
  title={SHARE OR NOT? LEARNING TO SCHEDULE LANGUAGE-SPECIFIC CA-PACITY FOR MULTILINGUAL TRANSLATION},
  author={Zhang, Biao and Bapna, Ankur and Sennrich, Rico and Firat, Orhan},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{stickland2019bert,
  title={BERT and PALs: Projected attention layers for efficient adaptation in multi-task learning},
  author={Stickland, Asa Cooper and Murray, Iain},
  booktitle={International Conference on Machine Learning},
  pages={5986--5995},
  year={2019},
  organization={PMLR}
}

@inproceedings{liu2019end,
  title={End-to-end multi-task learning with attention},
  author={Liu, Shikun and Johns, Edward and Davison, Andrew J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1871--1880},
  year={2019}
}

@inproceedings{guo2020learning,
  title={Learning to branch for multi-task learning},
  author={Guo, Pengsheng and Lee, Chen-Yu and Ulbricht, Daniel},
  booktitle={International Conference on Machine Learning},
  pages={3854--3863},
  year={2020},
  organization={PMLR}
}

@inproceedings{gao2020mtl,
  title={Mtl-nas: Task-agnostic neural architecture search towards general-purpose multi-task learning},
  author={Gao, Yuan and Bai, Haoping and Jie, Zequn and Ma, Jiayi and Jia, Kui and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11543--11552},
  year={2020}
}

@article{wager2013dropout,
  title={Dropout training as adaptive regularization},
  author={Wager, Stefan and Wang, Sida and Liang, Percy},
  journal={arXiv preprint arXiv:1307.1493},
  year={2013}
}

@article{lu2021pretrained,
  title={Pretrained Transformers as Universal Computation Engines},
  author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:2103.05247},
  year={2021}
}

@article{hu2021transformer,
  title={Transformer is all you need: Multimodal multitask learning with a unified transformer},
  author={Hu, Ronghang and Singh, Amanpreet},
  journal={arXiv preprint arXiv:2102.10772},
  year={2021}
}

@inproceedings{parmar2018image,
  title={Image transformer},
  author={Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle={International Conference on Machine Learning},
  pages={4055--4064},
  year={2018},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@inproceedings{thomas2020interplay,
  title={On the interplay between noise and curvature and its effect on optimization and generalization},
  author={Thomas, Valentin and Pedregosa, Fabian and Merri{\"e}nboer, Bart and Manzagol, Pierre-Antoine and Bengio, Yoshua and Le Roux, Nicolas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3503--3513},
  year={2020},
  organization={PMLR}
}

@article{jastrzebski2020catastrophic,
  title={Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization},
  author={Jastrzebski, Stanislaw and Arpit, Devansh and Astrand, Oliver and Kerg, Giancarlo and Wang, Huan and Xiong, Caiming and Socher, Richard and Cho, Kyunghyun and Geras, Krzysztof},
  journal={arXiv preprint arXiv:2012.14193},
  year={2020}
}

@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
} 
@article{johnson2017google,
  title={Google’s multilingual neural machine translation system: Enabling zero-shot translation},
  author={Johnson, Melvin and Schuster, Mike and Le, Quoc V and Krikun, Maxim and Wu, Yonghui and Chen, Zhifeng and Thorat, Nikhil and Vi{\'e}gas, Fernanda and Wattenberg, Martin and Corrado, Greg and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={339--351},
  year={2017},
  publisher={MIT Press}
}

@inproceedings{hu2020xtreme,
  title={XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalisation},
  author={Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin},
  booktitle={International Conference on Machine Learning},
  pages={4411--4421},
  year={2020},
  organization={PMLR}
}

@inproceedings{aharoni2019massively,
  title={Massively Multilingual Neural Machine Translation},
  author={Aharoni, Roee and Johnson, Melvin and Firat, Orhan},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={3874--3884},
  year={2019}
}

@article{li2020deep,
  title={Deep Transformers with Latent Depth},
  author={Li, Xian and Cooper Stickland, Asa and Tang, Yuqing and Kong, Xiang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{xu2019understanding,
  title={Understanding and improving layer normalization},
  author={Xu, Jingjing and Sun, Xu and Zhang, Zhiyuan and Zhao, Guangxiang and Lin, Junyang},
  journal={arXiv preprint arXiv:1911.07013},
  year={2019}
}

@book{hebb2005organization,
  title={The organization of behavior: A neuropsychological theory},
  author={Hebb, Donald Olding},
  year={2005},
  publisher={Psychology Press}
}

@article{grave2018learning,
  title={Learning word vectors for 157 languages},
  author={Grave, Edouard and Bojanowski, Piotr and Gupta, Prakhar and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1802.06893},
  year={2018}
}

@article{wang2019multilingual,
  title={Multilingual neural machine translation with soft decoupled encoding},
  author={Wang, Xinyi and Pham, Hieu and Arthur, Philip and Neubig, Graham},
  journal={arXiv preprint arXiv:1902.03499},
  year={2019}
}

@article{neubig2018rapid,
  title={Rapid adaptation of neural machine translation to new languages},
  author={Neubig, Graham and Hu, Junjie},
  journal={arXiv preprint arXiv:1808.04189},
  year={2018}
}

@inproceedings{bengio2020interference,
  title={Interference and generalization in temporal difference learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={767--777},
  year={2020},
  organization={PMLR}
}

@article{fort2019stiffness,
  title={Stiffness: A new perspective on generalization in neural networks},
  author={Fort, Stanislav and Nowak, Pawe{\l} Krzysztof and Jastrzebski, Stanislaw and Narayanan, Srini},
  journal={arXiv preprint arXiv:1901.09491},
  year={2019}
}


@article{luong2015multi,
  title={Multi-task sequence to sequence learning},
  author={Luong, Minh-Thang and Le, Quoc V and Sutskever, Ilya and Vinyals, Oriol and Kaiser, Lukasz},
  journal={arXiv preprint arXiv:1511.06114},
  year={2015}
}

@inproceedings{collobert2008unified,
  title={A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author={Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={160--167},
  year={2008}
}

@inproceedings{doersch2017multi,
  title={Multi-task self-supervised visual learning},
  author={Doersch, Carl and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2051--2060},
  year={2017}
}

@article{sun2019ernie,
  title={Ernie: Enhanced representation through knowledge integration},
  author={Sun, Yu and Wang, Shuohuan and Li, Yukun and Feng, Shikun and Chen, Xuyi and Zhang, Han and Tian, Xin and Zhu, Danxiang and Tian, Hao and Wu, Hua},
  journal={arXiv preprint arXiv:1904.09223},
  year={2019}
}
@inproceedings{ravanelli2020multi,
  title={Multi-task self-supervised learning for robust speech recognition},
  author={Ravanelli, Mirco and Zhong, Jianyuan and Pascual, Santiago and Swietojanski, Pawel and Monteiro, Joao and Trmal, Jan and Bengio, Yoshua},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6989--6993},
  year={2020},
  organization={IEEE}
}
@inproceedings{lu202012,
  title={12-in-1: Multi-task vision and language representation learning},
  author={Lu, Jiasen and Goswami, Vedanuj and Rohrbach, Marcus and Parikh, Devi and Lee, Stefan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10437--10446},
  year={2020}
}

@article{cohen2021gradient,
  title={Gradient descent on neural networks typically occurs at the edge of stability},
  author={Cohen, Jeremy M and Kaur, Simran and Li, Yuanzhi and Kolter, J Zico and Talwalkar, Ameet},
  journal={arXiv preprint arXiv:2103.00065},
  year={2021}
}

@inproceedings{liu2019understanding,
  title={Understanding Why Neural Networks Generalize Well Through GSNR of Parameters},
  author={Liu, Jinlong and Bai, Yunzhi and Jiang, Guoqing and Chen, Ting and Wang, Huayan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{jastrzebski2019break,
  title={The Break-Even Point on Optimization Trajectories of Deep Neural Networks},
  author={Jastrzebski, Stanislaw and Szymczak, Maciej and Fort, Stanislav and Arpit, Devansh and Tabor, Jacek and Cho, Kyunghyun and Geras, Krzysztof},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{yao2018hessian,
  title={Hessian-based analysis of large batch training and robustness to adversaries},
  author={Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1802.08241},
  year={2018}
}

@article{lin2021learning,
  title={Learning Language Specific Sub-network for Multilingual Machine Translation},
  author={Lin, Zehui and Wu, Liwei and Wang, Mingxuan and Li, Lei},
  journal={arXiv preprint arXiv:2105.09259},
  year={2021}
}

@article{foret2020sharpness,
  title={Sharpness-aware minimization for efficiently improving generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.01412},
  year={2020}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}
@article{liu2020understanding,
  title={Understanding the difficulty of training transformers},
  author={Liu, Liyuan and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu and Han, Jiawei},
  journal={arXiv preprint arXiv:2004.08249},
  year={2020}
}

@inproceedings{xiong2020layer,
  title={On layer normalization in the transformer architecture},
  author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle={International Conference on Machine Learning},
  pages={10524--10533},
  year={2020},
  organization={PMLR}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}


@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
