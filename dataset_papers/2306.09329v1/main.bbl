\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[cmu()]{cmu_mocap}
\url{http://mocap.cs.cmu.edu/}.

\bibitem[Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti,
  Caillon, Huang, Jansen, Roberts, Tagliasacchi,
  et~al.]{agostinelli2023musiclm}
Andrea Agostinelli, Timo~I Denk, Zal{\'a}n Borsos, Jesse Engel, Mauro Verzetti,
  Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco
  Tagliasacchi, et~al.
\newblock Musiclm: Generating music from text.
\newblock \emph{arXiv preprint arXiv:2301.11325}, 2023.

\bibitem[Alldieck et~al.(2021)Alldieck, Xu, and
  Sminchisescu]{alldieck2021imghum}
Thiemo Alldieck, Hongyi Xu, and Cristian Sminchisescu.
\newblock imghum: Implicit generative models of 3d human shape and articulated
  pose.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5461--5470, 2021.

\bibitem[Athanasiou et~al.(2022)Athanasiou, Petrovich, Black, and
  Varol]{athanasiou2022teach}
Nikos Athanasiou, Mathis Petrovich, Michael~J. Black, and G\"{u}l Varol.
\newblock Teach: Temporal action compositions for 3d humans.
\newblock In \emph{International Conference on 3D Vision (3DV)}, September
  2022.

\bibitem[Barron et~al.(2022)Barron, Mildenhall, Verbin, Srinivasan, and
  Hedman]{barron2022mipnerf360}
Jonathan~T. Barron, Ben Mildenhall, Dor Verbin, Pratul~P. Srinivasan, and Peter
  Hedman.
\newblock Mip-nerf 360: Unbounded anti-aliased neural radiance fields.
\newblock \emph{CVPR}, 2022.

\bibitem[Bazavan et~al.(2021)Bazavan, Zanfir, Zanfir, Freeman, Sukthankar, and
  Sminchisescu]{bazavan2021hspace}
Eduard~Gabriel Bazavan, Andrei Zanfir, Mihai Zanfir, William~T. Freeman, Rahul
  Sukthankar, and Cristian Sminchisescu.
\newblock Hspace: Synthetic parametric humans animated in complex environments,
  2021.

\bibitem[Birhane et~al.(2021)Birhane, Prabhu, and
  Kahembwe]{birhane2021multimodal}
Abeba Birhane, Vinay~Uday Prabhu, and Emmanuel Kahembwe.
\newblock Multimodal datasets: misogyny, pornography, and malignant
  stereotypes.
\newblock \emph{arXiv preprint arXiv:2110.01963}, 2021.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Chang et~al.(2023)Chang, Zhang, Barber, Maschinot, Lezama, Jiang,
  Yang, Murphy, Freeman, Rubinstein, et~al.]{chang2023muse}
Huiwen Chang, Han Zhang, Jarred Barber, AJ~Maschinot, Jose Lezama, Lu~Jiang,
  Ming-Hsuan Yang, Kevin Murphy, William~T Freeman, Michael Rubinstein, et~al.
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock \emph{arXiv preprint arXiv:2301.00704}, 2023.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 8780--8794, 2021.

\bibitem[Guo et~al.(2022)Guo, Zou, Zuo, Wang, Ji, Li, and Cheng]{Guo_2022_CVPR}
Chuan Guo, Shihao Zou, Xinxin Zuo, Sen Wang, Wei Ji, Xingyu Li, and Li~Cheng.
\newblock Generating diverse and natural 3d human motions from text.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 5152--5161, June 2022.

\bibitem[Hertz et~al.(2022)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and
  Cohen-Or]{hertz2022prompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel
  Cohen-Or.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Hong et~al.(2022)Hong, Zhang, Pan, Cai, Yang, and
  Liu]{hong2022avatarclip}
Fangzhou Hong, Mingyuan Zhang, Liang Pan, Zhongang Cai, Lei Yang, and Ziwei
  Liu.
\newblock Avatarclip: Zero-shot text-driven generation and animation of 3d
  avatars.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 41\penalty0 (4):\penalty0
  1--19, 2022.

\bibitem[Huang et~al.(2023)Huang, Park, Wang, Denk, Ly, Chen, Zhang, Zhang, Yu,
  Frank, et~al.]{huang2023noise2music}
Qingqing Huang, Daniel~S Park, Tao Wang, Timo~I Denk, Andy Ly, Nanxin Chen,
  Zhengdong Zhang, Zhishuai Zhang, Jiahui Yu, Christian Frank, et~al.
\newblock Noise2music: Text-conditioned music generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.03917}, 2023.

\bibitem[I\c{s}{\i}k et~al.(2023)I\c{s}{\i}k, Rünz, Georgopoulos, Khakhulin,
  Starck, Agapito, and Nießner]{isik2023humanrf}
Mustafa I\c{s}{\i}k, Martin Rünz, Markos Georgopoulos, Taras Khakhulin,
  Jonathan Starck, Lourdes Agapito, and Matthias Nießner.
\newblock Humanrf: High-fidelity neural radiance fields for humans in motion.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 42\penalty0 (4):\penalty0
  1--12, 2023.
\newblock \doi{10.1145/3592415}.
\newblock URL \url{https://doi.org/10.1145/3592415}.

\bibitem[Jain et~al.(2022)Jain, Mildenhall, Barron, Abbeel, and
  Poole]{jain2021dreamfields}
Ajay Jain, Ben Mildenhall, Jonathan~T. Barron, Pieter Abbeel, and Ben Poole.
\newblock Zero-shot text-guided object generation with dream fields.
\newblock 2022.

\bibitem[Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and
  Irani]{kawar2023imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar
  Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models, 2023.

\bibitem[Khalid et~al.(2022)Khalid, Xie, Belilovsky, and
  Tiberiu]{khalid2022clipmesh}
Nasir~Mohammad Khalid, Tianhao Xie, Eugene Belilovsky, and Popa Tiberiu.
\newblock Clip-mesh: Generating textured meshes from text using pretrained
  image-text models.
\newblock \emph{SIGGRAPH Asia 2022 Conference Papers}, December 2022.

\bibitem[Kim et~al.(2023)Kim, Kim, and Choi]{kim2022flame}
Jihoon Kim, Jiseob Kim, and Sungjoon Choi.
\newblock Flame: Free-form language-based motion synthesis \& editing.
\newblock \emph{AAAI}, 2023.

\bibitem[Li et~al.(2023)Li, Zheng, Liu, Zhou, and Liu]{li2023posevocab}
Zhe Li, Zerong Zheng, Yuxiao Liu, Boyao Zhou, and Yebin Liu.
\newblock Posevocab: Learning joint-structured pose embeddings for human avatar
  modeling.
\newblock In \emph{ACM SIGGRAPH Conference Proceedings}, 2023.

\bibitem[Lin et~al.(2022)Lin, Gao, Tang, Takikawa, Zeng, Huang, Kreis, Fidler,
  Liu, and Lin]{lin2022magic3d}
Chen-Hsuan Lin, Jun Gao, Luming Tang, Towaki Takikawa, Xiaohui Zeng, Xun Huang,
  Karsten Kreis, Sanja Fidler, Ming-Yu Liu, and Tsung-Yi Lin.
\newblock Magic3d: High-resolution text-to-3d content creation.
\newblock \emph{arXiv preprint arXiv:2211.10440}, 2022.

\bibitem[Loper et~al.(2015)Loper, Mahmood, Romero, Pons-Moll, and
  Black]{loper2015smpl}
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael~J
  Black.
\newblock Smpl: A skinned multi-person linear model.
\newblock \emph{ACM transactions on graphics (TOG)}, 34\penalty0 (6):\penalty0
  1--16, 2015.

\bibitem[Metzer et~al.(2022)Metzer, Richardson, Patashnik, Giryes, and
  Cohen-Or]{metzer2022latent}
Gal Metzer, Elad Richardson, Or~Patashnik, Raja Giryes, and Daniel Cohen-Or.
\newblock Latent-nerf for shape-guided generation of 3d shapes and textures.
\newblock \emph{arXiv preprint arXiv:2211.07600}, 2022.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{mildenhall2020nerf}
Ben Mildenhall, Pratul~P. Srinivasan, Matthew Tancik, Jonathan~T. Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In \emph{ECCV}, 2020.

\bibitem[Mokady et~al.(2022)Mokady, Hertz, Aberman, Pritch, and
  Cohen-Or]{mokady2022nulltext}
Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Null-text inversion for editing real images using guided diffusion
  models, 2022.

\bibitem[Mordvintsev et~al.(2018)Mordvintsev, Pezzotti, Schubert, and
  Olah]{mordvintsev2018differentiable}
Alexander Mordvintsev, Nicola Pezzotti, Ludwig Schubert, and Chris Olah.
\newblock Differentiable image parameterizations.
\newblock \emph{Distill}, 3\penalty0 (7):\penalty0 e12, 2018.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew,
  Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Nichol and Dhariwal(2021)]{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In \emph{International Conference on Machine Learning}, pages
  8162--8171. PMLR, 2021.

\bibitem[Noguchi et~al.(2021)Noguchi, Sun, Lin, and Harada]{noguchi2021neural}
Atsuhiro Noguchi, Xiao Sun, Stephen Lin, and Tatsuya Harada.
\newblock Neural articulated radiance field.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5762--5772, 2021.

\bibitem[Oord et~al.(2018)Oord, Li, Babuschkin, Simonyan, Vinyals, Kavukcuoglu,
  Driessche, Lockhart, Cobo, Stimberg, et~al.]{oord2018parallel}
Aaron Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Koray
  Kavukcuoglu, George Driessche, Edward Lockhart, Luis Cobo, Florian Stimberg,
  et~al.
\newblock Parallel wavenet: Fast high-fidelity speech synthesis.
\newblock In \emph{International conference on machine learning}, pages
  3918--3926. PMLR, 2018.

\bibitem[Park et~al.(2021{\natexlab{a}})Park, Sinha, Barron, Bouaziz, Goldman,
  Seitz, and Martin-Brualla]{park2021nerfies}
Keunhong Park, Utkarsh Sinha, Jonathan~T Barron, Sofien Bouaziz, Dan~B Goldman,
  Steven~M Seitz, and Ricardo Martin-Brualla.
\newblock Nerfies: Deformable neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5865--5874, 2021{\natexlab{a}}.

\bibitem[Park et~al.(2021{\natexlab{b}})Park, Sinha, Hedman, Barron, Bouaziz,
  Goldman, Martin-Brualla, and Seitz]{park2021hypernerf}
Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan~T. Barron, Sofien Bouaziz,
  Dan~B Goldman, Ricardo Martin-Brualla, and Steven~M. Seitz.
\newblock Hypernerf: A higher-dimensional representation for topologically
  varying neural radiance fields.
\newblock \emph{ACM Trans. Graph.}, 40\penalty0 (6), dec 2021{\natexlab{b}}.

\bibitem[Petrovich et~al.(2022)Petrovich, Black, and Varol]{petrovich22temos}
Mathis Petrovich, Michael~J. Black, and G{\"u}l Varol.
\newblock {TEMOS}: Generating diverse human motions from textual descriptions.
\newblock In \emph{European Conference on Computer Vision ({ECCV})}, 2022.

\bibitem[Ping et~al.(2018)Ping, Peng, and Chen]{ping2018clarinet}
Wei Ping, Kainan Peng, and Jitong Chen.
\newblock Clarinet: Parallel wave generation in end-to-end text-to-speech.
\newblock \emph{arXiv preprint arXiv:1807.07281}, 2018.

\bibitem[Pons-Moll et~al.(2017)Pons-Moll, Pujades, Hu, and
  Black]{Pons-Moll:Siggraph2017}
Gerard Pons-Moll, Sergi Pujades, Sonny Hu, and Michael Black.
\newblock Clothcap: Seamless 4d clothing capture and retargeting.
\newblock \emph{ACM Transactions on Graphics, (Proc. SIGGRAPH)}, 36\penalty0
  (4), 2017.
\newblock URL \url{http://dx.doi.org/10.1145/3072959.3073711}.
\newblock Two first authors contributed equally.

\bibitem[Poole et~al.(2023)Poole, Jain, Barron, and
  Mildenhall]{poole2022dreamfusion}
Ben Poole, Ajay Jain, Jonathan~T. Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock \emph{ICLR}, 2023.

\bibitem[Pumarola et~al.(2021)Pumarola, Corona, Pons-Moll, and
  Moreno-Noguer]{pumarola2021d}
Albert Pumarola, Enric Corona, Gerard Pons-Moll, and Francesc Moreno-Noguer.
\newblock D-nerf: Neural radiance fields for dynamic scenes.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10318--10327, 2021.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{2020t5}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (140):\penalty0 1--67, 2020.
\newblock URL \url{http://jmlr.org/papers/v21/20-074.html}.

\bibitem[Raj et~al.(2023)Raj, Kaza, Poole, Niemeyer, Ruiz, Mildenhall, Zada,
  Aberman, Rubinstein, Barron, Li, and Jampani]{raj2023dreambooth3d}
Amit Raj, Srinivas Kaza, Ben Poole, Michael Niemeyer, Nataniel Ruiz, Ben
  Mildenhall, Shiran Zada, Kfir Aberman, Michael Rubinstein, Jonathan Barron,
  Yuanzhen Li, and Varun Jampani.
\newblock Dreambooth3d: Subject-driven text-to-3d generation, 2023.

\bibitem[Ramamoorthi and Hanrahan(2001)]{ramamoorthi2001efficient}
Ravi Ramamoorthi and Pat Hanrahan.
\newblock An efficient representation for irradiance environment maps.
\newblock In \emph{Proceedings of the 28th annual conference on Computer
  graphics and interactive techniques}, pages 497--500, 2001.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International Conference on Machine Learning}, pages
  8821--8831, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Richardson et~al.(2023)Richardson, Metzer, Alaluf, Giryes, and
  Cohen-Or]{richardson2023texture}
Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, and Daniel Cohen-Or.
\newblock Texture: Text-guided texturing of 3d shapes.
\newblock \emph{SIGGRAPH}, 2023.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10684--10695, 2022.

\bibitem[Ruiz et~al.(2022)Ruiz, Li, Jampani, Pritch, Rubinstein, and
  Aberman]{ruiz2022dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and
  Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for
  subject-driven generation.
\newblock 2022.

\bibitem[Saharia et~al.(2022{\natexlab{a}})Saharia, Chan, Saxena, Li, Whang,
  Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans,
  et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L
  Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim
  Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 36479--36494, 2022{\natexlab{a}}.

\bibitem[Saharia et~al.(2022{\natexlab{b}})Saharia, Ho, Chan, Salimans, Fleet,
  and Norouzi]{saharia2022image}
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David~J Fleet, and
  Mohammad Norouzi.
\newblock Image super-resolution via iterative refinement.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2022{\natexlab{b}}.

\bibitem[Sanghi et~al.(2022)Sanghi, Chu, Lambourne, Wang, Cheng, Fumero, and
  Malekshan]{sanghi2022clip}
Aditya Sanghi, Hang Chu, Joseph~G Lambourne, Ye~Wang, Chin-Yi Cheng, Marco
  Fumero, and Kamal~Rahimi Malekshan.
\newblock Clip-forge: Towards zero-shot text-to-shape generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 18603--18613, 2022.

\bibitem[Singer et~al.(2023)Singer, Sheynin, Polyak, Ashual, Makarov, Kokkinos,
  Goyal, Vedaldi, Parikh, Johnson, et~al.]{singer2023text}
Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos
  Kokkinos, Naman Goyal, Andrea Vedaldi, Devi Parikh, Justin Johnson, et~al.
\newblock Text-to-4d dynamic scene generation.
\newblock \emph{arXiv preprint arXiv:2301.11280}, 2023.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem[Tevet et~al.(2022)Tevet, Gordon, Hertz, Bermano, and
  Cohen-Or]{tevet2022motionclip}
Guy Tevet, Brian Gordon, Amir Hertz, Amit~H Bermano, and Daniel Cohen-Or.
\newblock Motionclip: Exposing human motion generation to clip space.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXII}, pages 358--374.
  Springer, 2022.

\bibitem[Tevet et~al.(2023)Tevet, Raab, Gordon, Shafir, Bermano, and
  Cohen-Or]{tevet2022human}
Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Amit~H Bermano, and Daniel
  Cohen-Or.
\newblock Human motion diffusion model.
\newblock \emph{ICLR}, 2023.

\bibitem[Tretschk et~al.(2021)Tretschk, Tewari, Golyanik, Zollh{\"o}fer,
  Lassner, and Theobalt]{tretschk2021non}
Edgar Tretschk, Ayush Tewari, Vladislav Golyanik, Michael Zollh{\"o}fer,
  Christoph Lassner, and Christian Theobalt.
\newblock Non-rigid neural radiance fields: Reconstruction and novel view
  synthesis of a dynamic scene from monocular video.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 12959--12970, 2021.

\bibitem[Verbin et~al.(2022)Verbin, Hedman, Mildenhall, Zickler, Barron, and
  Srinivasan]{verbin2022refnerf}
Dor Verbin, Peter Hedman, Ben Mildenhall, Todd Zickler, Jonathan~T. Barron, and
  Pratul~P. Srinivasan.
\newblock {Ref-NeRF}: Structured view-dependent appearance for neural radiance
  fields.
\newblock \emph{CVPR}, 2022.

\bibitem[Weng et~al.(2022)Weng, Curless, Srinivasan, Barron, and
  Kemelmacher-Shlizerman]{weng_humannerf_2022_cvpr}
Chung-Yi Weng, Brian Curless, Pratul~P. Srinivasan, Jonathan~T. Barron, and Ira
  Kemelmacher-Shlizerman.
\newblock Human{N}e{RF}: Free-viewpoint rendering of moving people from
  monocular video.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 16210--16220, June 2022.

\bibitem[Xu et~al.(2020)Xu, Bazavan, Zanfir, Freeman, Sukthankar, and
  Sminchisescu]{xu2020ghum}
Hongyi Xu, Eduard~Gabriel Bazavan, Andrei Zanfir, William~T Freeman, Rahul
  Sukthankar, and Cristian Sminchisescu.
\newblock Ghum \& ghuml: Generative 3d human shape and articulated pose models.
\newblock In \emph{CVPR}, 2020.

\bibitem[Xu et~al.(2021)Xu, Alldieck, and Sminchisescu]{xu2021h}
Hongyi Xu, Thiemo Alldieck, and Cristian Sminchisescu.
\newblock H-nerf: Neural radiance fields for rendering and temporal
  reconstruction of humans in motion.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 14955--14966, 2021.

\bibitem[Xu et~al.(2023)Xu, Zhang, Wang, Zhao, Han, Guojun, and
  Liu]{xu2023latentavatar}
Yuelang Xu, Hongwen Zhang, Lizhen Wang, Xiaochen Zhao, Huang Han, Qi~Guojun,
  and Yebin Liu.
\newblock Latentavatar: Learning latent expression code for expressive neural
  head avatar.
\newblock In \emph{ACM SIGGRAPH 2023 Conference Proceedings}, 2023.

\bibitem[Yu et~al.(2022)Yu, Xu, Koh, Luong, Baid, Wang, Vasudevan, Ku, Yang,
  Ayan, et~al.]{yu2022scaling}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang,
  Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, et~al.
\newblock Scaling autoregressive models for content-rich text-to-image
  generation.
\newblock \emph{arXiv preprint arXiv:2206.10789}, 2022.

\bibitem[Zanfir et~al.(2020)Zanfir, Bazavan, Xu, Freeman, Sukthankar, and
  Sminchisescu]{zanfir2020weakly}
Andrei Zanfir, Eduard~Gabriel Bazavan, Hongyi Xu, William~T Freeman, Rahul
  Sukthankar, and Cristian Sminchisescu.
\newblock Weakly supervised 3d human pose and shape reconstruction with
  normalizing flows.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16}, pages 465--481.
  Springer, 2020.

\bibitem[Zhao et~al.(2022)Zhao, Yang, Zhang, Lin, Zhang, Yu, and
  Xu]{Zhao_2022_CVPR}
Fuqiang Zhao, Wei Yang, Jiakai Zhang, Pei Lin, Yingliang Zhang, Jingyi Yu, and
  Lan Xu.
\newblock Humannerf: Efficiently generated human radiance field from sparse
  inputs.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 7743--7753, June 2022.

\end{thebibliography}
