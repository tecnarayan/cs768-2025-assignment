@article{bergen2012genome,
  title={Genome-wide association studies ({GWAS}) of schizophrenia: does bigger lead to better results?},
  author={Bergen, Sarah E and Petryshen, Tracey L},
  journal={Current opinion in psychiatry},
  volume={25},
  number={2},
  pages={76},
  year={2012},
  publisher={NIH Public Access}
}



@article{schizophrenia2014biological,
  title={Biological insights from 108 schizophrenia-associated genetic loci.},
  author={Schizophrenia Working Group of the Psychiatric Genomics Consortium and others},
  journal={Nature},
  volume={511},
  number={7510},
  pages={421--427},
  year={2014}
}


@article{VARIAN197463,
title = {Equity, envy, and efficiency},
journal = {Journal of Economic Theory},
volume = {9},
number = {1},
pages = {63-91},
year = {1974},
issn = {0022-0531},
author = {Hal R Varian}
}

@article{foley1967resource,
  title={Resource allocation and the public sector.},
  author={Foley, Duncan Karl},
  journal = {Yale economic essays},
  volume = {7},
  number = {1},
  pages = {45-98},
  year={1967}
}

@inproceedings{jia2019towards,
  title={Towards efficient data valuation based on the shapley value},
  author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G{\"u}rel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1167--1176},
  year={2019},
  organization={PMLR}
}

@inproceedings{balkanski2017statistical,
  title={Statistical cost sharing},
  author={Balkanski, Eric and Syed, Umar and Vassilvitskii, Sergei},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={6222--6231},
  year={2017}
}

@inproceedings{agarwal2019marketplace,
  title={A marketplace for data: An algorithmic solution},
  author={Agarwal, Anish and Dahleh, Munther and Sarkar, Tuhin},
  booktitle={Proceedings of the 2019 ACM Conference on Economics and Computation},
  pages={701--726},
  year={2019}
}



@misc{NVIDIA2,
	Author = {Kimberly Powell},
	Howpublished = {\url{https://blogs.nvidia.com/blog/2019/12/01/clara-federated-learning/}},
	Title = {{NVIDIA} Clara Federated Learning to Deliver AI to Hospitals While Protecting Patient Data},
	Year = 2019
}


@article{10.2307/3690406,
 ISSN = {0364765X, 15265471},
 URL = {http://www.jstor.org/stable/3690406},
 abstract = {This paper presents fast algorithms that find approximate solutions for a general class of problems, which we call fractional packing and covering problems. The only previously known algorithms for solving these problems are based on general linear programming techniques. The techniques developed in this paper greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems. Our algorithm is a Lagrangian relaxation technique; an important aspect of our results is that we obtain a theoretical analysis of the running time of a Lagrangian relaxation-based algorithm We give several applications of our algorithms. The new approach yields several orders of magnitude of improvement over the best previously known running times for algorithms for the scheduling of unrelated parallel machines in both the preemptive and the nonpreemptive models, for the job shop problem, for the Held and Karp bound for the traveling salesman problem, for the cutting-stock problem, for the network embedding problem, and for the minimum-cost multicommodity flow problem.},
 author = {Serge A. Plotkin and David B. Shmoys and Éva Tardos},
 journal = {Mathematics of Operations Research},
 number = {2},
 pages = {257--301},
 publisher = {INFORMS},
 title = {Fast Approximation Algorithms for Fractional Packing and Covering Problems},
 volume = {20},
 year = {1995}
}

@article{mcmahan2017federated,
  title={Federated learning: Collaborative machine learning without centralized training data},
  author={McMahan, Brendan and Ramage, Daniel},
  journal={Google Research Blog},
  volume={3},
  year={2017}
}

@techreport{wen2019federated,
  title={Federated Learning powered by {NVIDIA} {Clara}},
  author={Wen, Yuhong and Li, Wenqi and Roth, Holger and Dogra, Prerna},
  journal={{NVIDIA} Developer Blog},
  year = {2019},
  month = {December},
  url = {https://developer.nvidia.com/blog/federated-learning-clara/} 
}



@article{arora_multiplicative_nodate,
	title = {The {Multiplicative} {Weights} {Update} {Method}: a {Meta} {Algorithm} and {Applications}},
	abstract = {Algorithms in varied ﬁelds use the idea of maintaining a distribution over a certain set and use the multiplicative update rule to iteratively change these weights. Their analysis are usually very similar and rely on an exponential potential function.},
	language = {en},
	author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
	  journal={Theory of Computing},
  year={2012},
	pages = {31},
	file = {Arora et al. - The Multiplicative Weights Update Method a Meta A.pdf:/Users/richard/Zotero/storage/IGPV2VUA/Arora et al. - The Multiplicative Weights Update Method a Meta A.pdf:application/pdf}
}

@article{freund1997decision,
  title={A decision-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Journal of computer and system sciences},
  volume={55},
  number={1},
  pages={119--139},
  year={1997},
  publisher={Elsevier}
}

@inproceedings{luo2015achieving,
  title={Achieving all with no parameters: Adanormalhedge},
  author={Luo, Haipeng and Schapire, Robert E},
  booktitle={Conference on Learning Theory},
  pages={1286--1304},
  year={2015},
  organization={PMLR}
}


%============collaborative federated learning==============
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@inproceedings{blum2017collaborative,
  title={Collaborative {PAC} learning},
  author={Blum, Avrim and Haghtalab, Nika and Procaccia, Ariel D and Qiao, Mingda},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2392--2401},
  year={2017}
}

@article{nguyen2018improved,
  title={Improved Algorithms for Collaborative PAC Learning},
  author={Nguyen, Huy and Zakynthinou, Lydia},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={7631--7639},
  year={2018}
}


@incollection{chen:tight2018,
	title = {Tight {Bounds} for {Collaborative} {PAC} {Learning} via {Multiplicative} {Weights}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Chen, Jiecao and Zhang, Qin and Zhou, Yuan},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {3598--3607}
	}


%==============fair federated learning================

@inproceedings{redko2019fair,
  title={On Fair Cost Sharing Games in Machine Learning},
  author={Redko, Ievgen and Laclau, Charlotte},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4790--4797},
  year={2019}
}

@article{donahue2020model,
  title={Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation},
  author={Donahue, Kate and Kleinberg, Jon},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021},
  volume={33},
}

@inproceedings{li2019fair,
  title={Fair Resource Allocation in Federated Learning},
  author={Li, Tian and Sanjabi, Maziar and Beirami, Ahmad and Smith, Virginia},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@incollection{lyu2020collaborative,
  title={Collaborative fairness in federated learning},
  author={Lyu, Lingjuan and Xu, Xinyi and Wang, Qian and Yu, Han},
  booktitle={Federated Learning},
  pages={189--204},
  year={2020},
  publisher={Springer}
}

@inproceedings{yu2020fairness,
  title={A fairness-aware incentive scheme for federated learning},
  author={Yu, Han and Liu, Zelei and Liu, Yang and Chen, Tianjian and Cong, Mingshu and Weng, Xi and Niyato, Dusit and Yang, Qiang},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={393--399},
  year={2020}
}

@article{lin2019free,
  title={Free-riders in federated learning: Attacks and defenses},
  author={Lin, Jierui and Du, Min and Liu, Jian},
  journal={arXiv preprint arXiv:1911.12560},
  year={2019}
}

@article{zhang2020hierarchically,
  title={Hierarchically fair federated learning},
  author={Zhang, Jingfeng and Li, Cheng and Robles-Kelly, Antonio and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2004.10386},
  year={2020}
}

@article{kang2019incentive,
  title={Incentive mechanism for reliable federated learning: A joint optimization approach to combining reputation and contract theory},
  author={Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},
  journal={IEEE Internet of Things Journal},
  volume={6},
  number={6},
  pages={10700--10714},
  year={2019},
  publisher={IEEE}
}
%================game theory===========
@article{nash1950equilibrium,
  title={Equilibrium points in n-person games},
  author={Nash, John F and others},
  journal={Proceedings of the national academy of sciences},
  volume={36},
  number={1},
  pages={48--49},
  year={1950},
  publisher={USA}
}

@article{nash1951non,
  title={Non-cooperative games},
  author={Nash, John},
  journal={Annals of mathematics},
  pages={286--295},
  year={1951},
  publisher={JSTOR}
}

@article{stromquist1980cut,
  title={How to cut a cake fairly},
  author={Stromquist, Walter},
  journal={The American Mathematical Monthly},
  volume={87},
  number={8},
  pages={640--644},
  year={1980},
  publisher={Taylor \& Francis}
}

@article{shapley1953value,
  title={A value for n-person games},
  author={Shapley, Lloyd S},
  journal={Contributions to the Theory of Games},
  volume={2},
  number={28},
  pages={307--317},
  year={1953}
}

@article{caragiannis2012efficiency,
  title={The efficiency of fair division},
  author={Caragiannis, Ioannis and Kaklamanis, Christos and Kanellopoulos, Panagiotis and Kyropoulou, Maria},
  journal={Theory of Computing Systems},
  volume={50},
  number={4},
  pages={589--610},
  year={2012},
  publisher={Springer}
}

@article{anshelevich2008price,
  title={The price of stability for network design with fair cost allocation},
  author={Anshelevich, Elliot and Dasgupta, Anirban and Kleinberg, Jon and Tardos, {\'E}va and Wexler, Tom and Roughgarden, Tim},
  journal={SIAM Journal on Computing},
  volume={38},
  number={4},
  pages={1602--1623},
  year={2008},
  publisher={SIAM}
}

%===============shapley and core==================
@inproceedings{ghorbani2019data,
  title={Data shapley: Equitable valuation of data for machine learning},
  author={Ghorbani, Amirata and Zou, James},
  booktitle={International Conference on Machine Learning},
  pages={2242--2251},
  year={2019},
  organization={PMLR}
}

@misc{yan2020if,
  title={If you like shapley then you’ll love the core},
  author={Yan, Tom and Procaccia, Ariel D},
  year={2020},
  publisher={Manuscript}
}


%===============experimental and datasets==================
@article{DBLP:journals/corr/CohenATS17,
  author    = {Gregory Cohen and
               Saeed Afshar and
               Jonathan Tapson and
               Andr{\'{e}} van Schaik},
  title     = {{EMNIST:} an extension of {MNIST} to handwritten letters},
  journal   = {CoRR},
  volume    = {abs/1702.05373},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.05373},
  archivePrefix = {arXiv},
  eprint    = {1702.05373},
  timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CohenATS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kingma15,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle={International Conference on Learning Representations},
  year      = {2015}
}


@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for ﬁrst-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efﬁcient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the inﬁnity norm.},
	language = {en},
	urldate = {2021-02-04},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:/Users/richard/Zotero/storage/65VGKMCP/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}