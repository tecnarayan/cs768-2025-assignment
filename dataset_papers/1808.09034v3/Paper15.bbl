\begin{thebibliography}{10}

\bibitem{agakov_auxiliary_2004}
Felix~V. Agakov and David Barber.
\newblock An auxiliary variational method.
\newblock In {\em Neural Information Processing}, Lecture Notes in Computer
  Science, pages 561--566. Springer, Berlin, Heidelberg, 2004.

\bibitem{bachman_training_2015}
Philip Bachman and Doina Precup.
\newblock Training deep generative models: Variations on a theme.
\newblock In {\em {NIPS} Workshop: Advances in Approximate Bayesian Inference},
  2015.

\bibitem{bamler_perturbative_2017}
Robert Bamler, Cheng Zhang, Manfred Opper, and Stephan Mandt.
\newblock Perturbative black box variational inference.
\newblock In {\em {NIPS}}, 2017.

\bibitem{bickel2015mathematical}
Peter~J Bickel and Kjell~A Doksum.
\newblock {\em Mathematical statistics: basic ideas and selected topics, volume
  I}, volume 117.
\newblock CRC Press, 2015.

\bibitem{burda_importance_2015}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock 2015.

\bibitem{cremer_reinterpreting_2017}
Chris Cremer, Quaid Morris, and David Duvenaud.
\newblock Reinterpreting importance-weighted autoencoders.
\newblock 2017.

\bibitem{dieng_variational_2017}
Adji~Bousso Dieng, Dustin Tran, Rajesh Ranganath, John Paisley, and David Blei.
\newblock Variational inference via $\chi$ upper bound minimization.
\newblock In {\em NIPS}, pages 2729--2738. 2017.

\bibitem{fang_symmetric_1990}
Kaitai Fang, Samuel Kotz, and Kai~Wang Ng.
\newblock {\em Symmetric multivariate and related distributions}.
\newblock Number~36 in Monographs on statistics and applied probability.
  Chapman and Hall, 1990.

\bibitem{gilks_language_1994}
W.~R. Gilks, A.~Thomas, and D.~J. Spiegelhalter.
\newblock A language and program for complex bayesian modelling.
\newblock 43(1):169--177, 1994.

\bibitem{kingma_auto-encoding_2014}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In {\em {ICLR}}.

\bibitem{kucukelbir_automatic_2017}
Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David~M.
  Blei.
\newblock Automatic differentiation variational inference.
\newblock 18(14):1--45, 2017.

\bibitem{Le2017May}
Tuan~Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood.
\newblock {Auto-Encoding Sequential Monte Carlo}.
\newblock In {\em {ICLR}}, 2018.

\bibitem{maddison_filtering_2017}
Chris~J Maddison, John Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi,
  Andriy Mnih, Arnaud Doucet, and Yee Teh.
\newblock Filtering variational objectives.
\newblock In {\em {NIPS}}, pages 6576--6586. 2017.

\bibitem{marcinkiewicz1937quelques}
J{\'o}zef Marcinkiewicz and Antoni Zygmund.
\newblock Quelques th{\'e}oremes sur les fonctions ind{\'e}pendantes.
\newblock {\em Fund. Math}, 29:60--90, 1937.

\bibitem{minka_thomas_expectation_2001}
{Minka, Thomas}.
\newblock Expectation propagation for approximate bayesian inference.
\newblock In {\em {UAI}}, 2001.

\bibitem{naesseth_variational_2018}
Christian~A. Naesseth, Scott~W. Linderman, Rajesh Ranganath, and David~M. Blei.
\newblock Variational sequential monte carlo.
\newblock In {\em {AISTATS}}, 2018.

\bibitem{owen_monte_2013}
Art Owen.
\newblock {\em Monte Carlo theory, methods and examples}.
\newblock 2013.

\bibitem{rainforth_tighter_2018}
Tom Rainforth, Adam~R. Kosiorek, Tuan~Anh Le, Chris~J. Maddison, Maximilian
  Igl, Frank Wood, and Yee~Whye Teh.
\newblock Tighter variational bounds are not necessarily better.

\bibitem{ranganath_black_2014}
Rajesh Ranganath, Sean Gerrish, and David~M. Blei.
\newblock Black box variational inference.
\newblock In {\em {AISTATS}}, 2014.

\bibitem{ruiz_overdispersed_2016}
Francisco J.~R. Ruiz, Michalis~K. Titsias, and David~M. Blei.
\newblock Overdispersed black-box variational inference.
\newblock In {\em UAI}, 2016.

\bibitem{saul_mean_1996}
L.~K. Saul, T.~Jaakkola, and M.~I. Jordan.
\newblock Mean field theory for sigmoid belief networks.
\newblock {\em Journal of Artificial Intelligence Research}, 4:61--76, 1996.

\bibitem{stan_development_team_modeling_2017}
{Stan Development Team}.
\newblock Modeling language user's guide and reference manual, version 2.17.0,
  2017.

\bibitem{tom_minka_divergence_2005}
{Tom Minka}.
\newblock Divergence measures and message passing.
\newblock 2005.

\end{thebibliography}
