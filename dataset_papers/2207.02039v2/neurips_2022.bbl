\begin{thebibliography}{10}

\bibitem{ahn2019variational}
Sungsoo Ahn, Shell~Xu Hu, Andreas Damianou, Neil~D Lawrence, and Zhenwen Dai.
\newblock Variational information distillation for knowledge transfer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9163--9171, 2019.

\bibitem{benesty2009pearson}
Jacob Benesty, Jingdong Chen, Yiteng Huang, and Israel Cohen.
\newblock Pearson correlation coefficient.
\newblock In {\em Noise reduction in speech processing}, pages 1--4. Springer,
  2009.

\bibitem{cai2018cascade}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Cascade r-cnn: Delving into high quality object detection.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6154--6162, 2018.

\bibitem{cai2019cascade}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Cascade r-cnn: high quality object detection and instance
  segmentation.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  43(5):1483--1498, 2019.

\bibitem{cao2019gcnet}
Yue Cao, Jiarui Xu, Stephen Lin, Fangyun Wei, and Han Hu.
\newblock Gcnet: Non-local networks meet squeeze-excitation networks and
  beyond.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision workshops}, pages 0--0, 2019.

\bibitem{chen2017learning}
Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Manmohan Chandraker.
\newblock Learning efficient object detection models with knowledge
  distillation.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{chen2019mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu~Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, et~al.
\newblock Mmdetection: Open mmlab detection toolbox and benchmark.
\newblock {\em arXiv preprint arXiv:1906.07155}, 2019.

\bibitem{2021mmrazor}
MMRazor Contributors.
\newblock Openmmlab model compression toolbox and benchmark.
\newblock \url{https://github.com/open-mmlab/mmrazor}, 2021.

\bibitem{dai2021general}
Xing Dai, Zeren Jiang, Zhao Wu, Yiping Bao, Zhicheng Wang, Si~Liu, and Erjin
  Zhou.
\newblock General instance distillation for object detection.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7842--7851, 2021.

\bibitem{duan2019centernet}
Kaiwen Duan, Song Bai, Lingxi Xie, Honggang Qi, Qingming Huang, and Qi~Tian.
\newblock Centernet: Keypoint triplets for object detection.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6569--6578, 2019.

\bibitem{feng2021tood}
Chengjian Feng, Yujie Zhong, Yu~Gao, Matthew~R Scott, and Weilin Huang.
\newblock Tood: Task-aligned one-stage object detection.
\newblock In {\em 2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pages 3490--3499. IEEE Computer Society, 2021.

\bibitem{guo2021distilling}
Jianyuan Guo, Kai Han, Yunhe Wang, Han Wu, Xinghao Chen, Chunjing Xu, and Chang
  Xu.
\newblock Distilling object detectors via decoupled features.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2154--2164, 2021.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2961--2969, 2017.

\bibitem{heo2019knowledge}
Byeongho Heo, Minsik Lee, Sangdoo Yun, and Jin~Young Choi.
\newblock Knowledge transfer via distillation of activation boundaries formed
  by hidden neurons.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3779--3787, 2019.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et~al.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2(7), 2015.

\bibitem{huang2017like}
Zehao Huang and Naiyan Wang.
\newblock Like what you like: Knowledge distill via neuron selectivity
  transfer.
\newblock {\em arXiv preprint arXiv:1707.01219}, 2017.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International conference on machine learning}, pages
  448--456. PMLR, 2015.

\bibitem{kang2021instance}
Zijian Kang, Peizhen Zhang, Xiangyu Zhang, Jian Sun, and Nanning Zheng.
\newblock Instance-conditional knowledge distillation for object detection.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{li2021knowledge}
Gang Li, Xiang Li, Yujie Wang, Shanshan Zhang, Yichao Wu, and Ding Liang.
\newblock Knowledge distillation for object detection via rank mimicking and
  prediction-guided feature imitation.
\newblock {\em arXiv preprint arXiv:2112.04840}, 2021.

\bibitem{li2017mimicking}
Quanquan Li, Shengying Jin, and Junjie Yan.
\newblock Mimicking very efficient network for object detection.
\newblock In {\em Proceedings of the ieee conference on computer vision and
  pattern recognition}, pages 6356--6364, 2017.

\bibitem{li2020generalized}
Xiang Li, Wenhai Wang, Lijun Wu, Shuo Chen, Xiaolin Hu, Jun Li, Jinhui Tang,
  and Jian Yang.
\newblock Generalized focal loss: Learning qualified and distributed bounding
  boxes for dense object detection.
\newblock {\em Advances in Neural Information Processing Systems},
  33:21002--21012, 2020.

\bibitem{lin2017feature}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2117--2125, 2017.

\bibitem{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2980--2988, 2017.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem{liu2016ssd}
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
  Cheng-Yang Fu, and Alexander~C Berg.
\newblock Ssd: Single shot multibox detector.
\newblock In {\em European conference on computer vision}, pages 21--37.
  Springer, 2016.

\bibitem{liu2019knowledge}
Yufan Liu, Jiajiong Cao, Bing Li, Chunfeng Yuan, Weiming Hu, Yangxi Li, and
  Yunqiang Duan.
\newblock Knowledge distillation via instance relationship graph.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7096--7104, 2019.

\bibitem{liu2021Swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock {\em arXiv preprint arXiv:2103.14030}, 2021.

\bibitem{park2019relational}
Wonpyo Park, Dongju Kim, Yan Lu, and Minsu Cho.
\newblock Relational knowledge distillation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3967--3976, 2019.

\bibitem{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{redmon2018yolov3}
Joseph Redmon and Ali Farhadi.
\newblock Yolov3: An incremental improvement.
\newblock {\em arXiv preprint arXiv:1804.02767}, 2018.

\bibitem{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{romero2014fitnets}
Adriana Romero, Nicolas Ballas, Samira~Ebrahimi Kahou, Antoine Chassang, Carlo
  Gatta, and Yoshua Bengio.
\newblock Fitnets: Hints for thin deep nets.
\newblock {\em arXiv preprint arXiv:1412.6550}, 2014.

\bibitem{shu2021channel}
Changyong Shu, Yifan Liu, Jianfei Gao, Zheng Yan, and Chunhua Shen.
\newblock Channel-wise knowledge distillation for dense prediction.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5311--5320, 2021.

\bibitem{sun2020distilling}
Ruoyu Sun, Fuhui Tang, Xiaopeng Zhang, Hongkai Xiong, and Qi~Tian.
\newblock Distilling object detectors with task adaptive regularization.
\newblock {\em arXiv preprint arXiv:2006.13108}, 2020.

\bibitem{tian2019contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive representation distillation.
\newblock {\em arXiv preprint arXiv:1910.10699}, 2019.

\bibitem{tian2019fcos}
Zhi Tian, Chunhua Shen, Hao Chen, and Tong He.
\newblock Fcos: Fully convolutional one-stage object detection.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 9627--9636, 2019.

\bibitem{tung2019similarity}
Frederick Tung and Greg Mori.
\newblock Similarity-preserving knowledge distillation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1365--1374, 2019.

\bibitem{ulyanov2016instance}
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
\newblock Instance normalization: The missing ingredient for fast stylization.
\newblock {\em arXiv preprint arXiv:1607.08022}, 2016.

\bibitem{wang2019distilling}
Tao Wang, Li~Yuan, Xiaopeng Zhang, and Jiashi Feng.
\newblock Distilling object detectors with fine-grained feature imitation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4933--4942, 2019.

\bibitem{wang2020intra}
Yukang Wang, Wei Zhou, Tao Jiang, Xiang Bai, and Yongchao Xu.
\newblock Intra-class feature variation distillation for semantic segmentation.
\newblock In {\em European Conference on Computer Vision}, pages 346--362.
  Springer, 2020.

\bibitem{wu2018group}
Yuxin Wu and Kaiming He.
\newblock Group normalization.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 3--19, 2018.

\bibitem{yang2019reppoints}
Ze~Yang, Shaohui Liu, Han Hu, Liwei Wang, and Stephen Lin.
\newblock Reppoints: Point set representation for object detection.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9657--9666, 2019.

\bibitem{yang2021focal}
Zhendong Yang, Zhe Li, Xiaohu Jiang, Yuan Gong, Zehuan Yuan, Danpei Zhao, and
  Chun Yuan.
\newblock Focal and global knowledge distillation for detectors.
\newblock {\em arXiv preprint arXiv:2111.11837}, 2021.

\bibitem{yao2021g}
Lewei Yao, Renjie Pi, Hang Xu, Wei Zhang, Zhenguo Li, and Tong Zhang.
\newblock G-detkd: Towards general distillation framework for object detectors
  via contrastive and semantic-guided feature imitation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 3591--3600, 2021.

\bibitem{yim2017gift}
Junho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim.
\newblock A gift from knowledge distillation: Fast optimization, network
  minimization and transfer learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4133--4141, 2017.

\bibitem{zhang2020improve}
Linfeng Zhang and Kaisheng Ma.
\newblock Improve object detection with feature-based knowledge distillation:
  Towards accurate and efficient detectors.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{zhao2022decoupled}
Borui Zhao, Quan Cui, Renjie Song, Yiyu Qiu, and Jiajun Liang.
\newblock Decoupled knowledge distillation.
\newblock {\em arXiv preprint arXiv:2203.08679}, 2022.

\bibitem{zhixing2021distilling}
Du~Zhixing, Rui Zhang, Ming Chang, Shaoli Liu, Tianshi Chen, Yunji Chen, et~al.
\newblock Distilling object detectors with feature richness.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\end{thebibliography}
