\begin{thebibliography}{10}

\bibitem{altschuler2019massively}
J.~Altschuler, F.~Bach, A.~Rudi, and J.~Niles-Weed.
\newblock Massively scalable sinkhorn distances via the {N}ystr{\"o}m method.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4429--4439, 2019.

\bibitem{altschuler2017near}
J.~Altschuler, J.~Niles-Weed, and P.~Rigollet.
\newblock Near-linear time approximation algorithms for optimal transport via
  sinkhorn iteration.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1964--1974, 2017.

\bibitem{alvarez2018structured}
D.~Alvarez-Melis, T.~Jaakkola, and S.~Jegelka.
\newblock Structured optimal transport.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1771--1780, 2018.

\bibitem{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala, and L.~Bottou.
\newblock {W}asserstein generative adversarial networks.
\newblock In {\em International conference on machine learning}, pages
  214--223, 2017.

\bibitem{artemiou2014cost}
A.~Artemiou and M.~Shu.
\newblock A cost based reweighted scheme of principal support vector machine.
\newblock In {\em Topics in Nonparametric Statistics}, pages 1--12. Springer,
  2014.

\bibitem{asmussen2007stochastic}
S.~Asmussen and P.~W. Glynn.
\newblock {\em Stochastic simulation: algorithms and analysis}.
\newblock Springer Science \& Business Media, 2007.

\bibitem{brenier1991polar}
Y.~Brenier.
\newblock Polar factorization and monotone rearrangement of vector-valued
  functions.
\newblock {\em Communications on pure and applied mathematics}, 44(4):375--417,
  1991.

\bibitem{cai2007locality}
D.~Cai, X.~He, K.~Zhou, J.~Han, and H.~Bao.
\newblock Locality sensitive discriminant analysis.
\newblock In {\em IJCAI}, volume 2007, pages 1713--1726, 2007.

\bibitem{cai2020online}
Z.~Cai, R.~Li, and L.~Zhu.
\newblock Online sufficient dimension reduction through sliced inverse
  regression.
\newblock {\em Journal of Machine Learning Research}, 21(10):1--25, 2020.

\bibitem{canas2012learning}
G.~Canas and L.~Rosasco.
\newblock Learning probability measures with respect to optimal transport
  metrics.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2492--2500, 2012.

\bibitem{cazelles2018geodesic}
E.~Cazelles, V.~Seguy, J.~Bigot, M.~Cuturi, and N.~Papadakis.
\newblock Geodesic {PCA} versus log-{PCA} of histograms in the {W}asserstein
  space.
\newblock {\em SIAM Journal on Scientific Computing}, 40(2):B429--B456, 2018.

\bibitem{chen2001generalization}
C.-H. Chen and K.-C. Li.
\newblock Generalization of fisher's linear discriminant analysis via the
  approach of sliced inverse regression.
\newblock {\em Journal of the Korean Statistical Society}, 30(2):193--217,
  2001.

\bibitem{chen2005local}
H.-T. Chen, H.-W. Chang, and T.-L. Liu.
\newblock Local discriminant embedding and its variants.
\newblock In {\em 2005 IEEE computer society conference on computer vision and
  pattern recognition (CVPR'05)}, volume~2, pages 846--853. IEEE, 2005.

\bibitem{cook1996graphics}
R.~D. Cook.
\newblock Graphics for regressions with a binary response.
\newblock {\em Journal of the American Statistical Association},
  91(435):983--992, 1996.

\bibitem{cook1999dimension}
R.~D. Cook and H.~Lee.
\newblock Dimension reduction in binary response regression.
\newblock {\em Journal of the American Statistical Association},
  94(448):1187--1200, 1999.

\bibitem{cook1991sliced}
R.~D. Cook and S.~Weisberg.
\newblock Sliced inverse regression for dimension reduction: Comment.
\newblock {\em Journal of the American Statistical Association},
  86(414):328--332, 1991.

\bibitem{courty2017joint}
N.~Courty, R.~Flamary, A.~Habrard, and A.~Rakotomamonjy.
\newblock Joint distribution optimal transportation for domain adaptation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3730--3739, 2017.

\bibitem{courty2016optimal}
N.~Courty, R.~Flamary, D.~Tuia, and A.~Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  39(9):1853--1865, 2016.

\bibitem{cuturi2013sinkhorn}
M.~Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In {\em Advances in neural information processing systems}, pages
  2292--2300, 2013.

\bibitem{cuturi2019differentiable}
M.~Cuturi, O.~Teboul, and J.-P. Vert.
\newblock Differentiable ranking and sorting using optimal transport.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6861--6871, 2019.

\bibitem{del2019central}
E.~Del~Barrio, P.~Gordaliza, H.~Lescornel, and J.-M. Loubes.
\newblock Central limit theorem and bootstrap procedure for {W}asserstein’s
  variations with an application to structural relationships between
  distributions.
\newblock {\em Journal of Multivariate Analysis}, 169:341--362, 2019.

\bibitem{deshpande2019max}
I.~Deshpande, Y.-T. Hu, R.~Sun, A.~Pyrros, N.~Siddiqui, S.~Koyejo, Z.~Zhao,
  D.~Forsyth, and A.~G. Schwing.
\newblock Max-sliced wasserstein distance and its use for {GAN}s.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 10648--10656, 2019.

\bibitem{ding2015double}
C.~Ding and L.~Zhang.
\newblock Double adjacency graphs-based discriminant neighborhood embedding.
\newblock {\em Pattern Recognition}, 48(5):1734--1742, 2015.

\bibitem{dornaika2013exponential}
F.~Dornaika and A.~Bosaghzadeh.
\newblock Exponential local discriminant embedding and its application to face
  recognition.
\newblock {\em IEEE transactions on cybernetics}, 43(3):921--934, 2013.

\bibitem{ferradans2014regularized}
S.~Ferradans, N.~Papadakis, G.~Peyr{\'e}, and J.-F. Aujol.
\newblock Regularized discrete optimal transport.
\newblock {\em SIAM Journal on Imaging Sciences}, 7(3):1853--1882, 2014.

\bibitem{flamary2016optimal}
R.~Flamary, N.~Courty, D.~Tuia, and A.~Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock {\em IEEE Trans. Pattern Anal. Mach. Intell}, 2016.

\bibitem{flamary2018wasserstein}
R.~Flamary, M.~Cuturi, N.~Courty, and A.~Rakotomamonjy.
\newblock {W}asserstein discriminant analysis.
\newblock {\em Machine Learning}, 107(12):1923--1945, 2018.

\bibitem{flamary2019concentration}
R.~Flamary, K.~Lounici, and A.~Ferrari.
\newblock Concentration bounds for linear monge mapping estimation and optimal
  transport domain adaptation.
\newblock {\em arXiv preprint arXiv:1905.10155}, 2019.

\bibitem{geyer2009likelihood}
C.~J. Geyer et~al.
\newblock Likelihood inference in exponential families and directions of
  recession.
\newblock {\em Electronic Journal of Statistics}, 3:259--289, 2009.

\bibitem{jolliffe2016principal}
I.~T. Jolliffe and J.~Cadima.
\newblock Principal component analysis: a review and recent developments.
\newblock {\em Philosophical Transactions of the Royal Society A: Mathematical,
  Physical and Engineering Sciences}, 374(2065):20150202, 2016.

\bibitem{kantorovich2006problem}
L.~V. Kantorovich.
\newblock {On a problem of Monge}.
\newblock {\em Journal of Mathematical Sciences}, 133(4):1383--1383, 2006.

\bibitem{kantorovitch1958translocation}
L.~Kantorovitch.
\newblock On the translocation of masses.
\newblock {\em Management Science}, 5(1):1--4, 1958.

\bibitem{kim2019principal}
B.~Kim and S.~J. Shin.
\newblock Principal weighted logistic regression for sufficient dimension
  reduction in binary classification.
\newblock {\em Journal of the Korean Statistical Society}, 48(2):194--206,
  2019.

\bibitem{lesaffre1989partial}
E.~Lesaffre and A.~Albert.
\newblock Partial separation in logistic discrimination.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 51(1):109--116, 1989.

\bibitem{li2018sufficient}
B.~Li.
\newblock {\em Sufficient dimension reduction: Methods and applications with
  R}.
\newblock Chapman and Hall/CRC, 2018.

\bibitem{li2011principal}
B.~Li, A.~Artemiou, L.~Li, et~al.
\newblock Principal support vector machines for linear and nonlinear sufficient
  dimension reduction.
\newblock {\em The Annals of Statistics}, 39(6):3182--3210, 2011.

\bibitem{li2009supervised}
B.~Li, C.~Wang, and D.-S. Huang.
\newblock Supervised feature extraction based on orthogonal discriminant
  projection.
\newblock {\em Neurocomputing}, 73(1-3):191--196, 2009.

\bibitem{li2007directional}
B.~Li and S.~Wang.
\newblock On directional regression for dimension reduction.
\newblock {\em Journal of the American Statistical Association},
  102(479):997--1008, 2007.

\bibitem{li2004efficient}
H.~Li, T.~Jiang, and K.~Zhang.
\newblock Efficient and robust feature extraction by maximum margin criterion.
\newblock In {\em Advances in neural information processing systems}, pages
  97--104, 2004.

\bibitem{li1991sliced}
K.-C. Li.
\newblock Sliced inverse regression for dimension reduction.
\newblock {\em Journal of the American Statistical Association},
  86(414):316--327, 1991.

\bibitem{li1992principal}
K.-C. Li.
\newblock On principal hessian directions for data visualization and dimension
  reduction: {A}nother application of {S}tein's lemma.
\newblock {\em Journal of the American Statistical Association},
  87(420):1025--1039, 1992.

\bibitem{li2000high}
K.-C. Li.
\newblock High dimensional data analysis via the {SIR/PHD} approach.
\newblock 2000.

\bibitem{liu2020ratio}
H.~Liu, Y.~Cai, Y.-L. Chen, and P.~Li.
\newblock Ratio trace formulation of wasserstein discriminant analysis.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{lu2011adaptive}
J.~Lu and Y.-P. Tan.
\newblock Adaptive maximum margin criterion for image classification.
\newblock In {\em 2011 IEEE International Conference on Multimedia and Expo},
  pages 1--6. IEEE, 2011.

\bibitem{luo2019matching}
W.~Luo and Y.~Zhu.
\newblock Matching using sufficient dimension reduction for causal inference.
\newblock {\em Journal of Business \& Economic Statistics}, pages 1--13, 2019.

\bibitem{ma2012semiparametric}
Y.~Ma and L.~Zhu.
\newblock A semiparametric approach to dimension reduction.
\newblock {\em Journal of the American Statistical Association},
  107(497):168--179, 2012.

\bibitem{ma2013review}
Y.~Ma and L.~Zhu.
\newblock A review on dimension reduction.
\newblock {\em International Statistical Review}, 81(1):134--150, 2013.

\bibitem{meng2019large}
C.~Meng, Y.~Ke, J.~Zhang, M.~Zhang, W.~Zhong, and P.~Ma.
\newblock Large-scale optimal transport map estimation using projection
  pursuit.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8116--8127, 2019.

\bibitem{meng2020more}
C.~Meng, X.~Zhang, J.~Zhang, W.~Zhong, and P.~Ma.
\newblock More efficient approximation of smoothing splines via space-filling
  basis selection.
\newblock {\em Biometrika}, 107:723--735, 2020.

\bibitem{nabi2017semi}
R.~Nabi and I.~Shpitser.
\newblock Semi-parametric causal sufficient dimension reduction of high
  dimensional treatments.
\newblock {\em arXiv preprint arXiv:1710.06727}, 2017.

\bibitem{panaretos2019statistical}
V.~M. Panaretos and Y.~Zemel.
\newblock Statistical aspects of {W}asserstein distances.
\newblock {\em Annual review of statistics and its application}, 6:405--431,
  2019.

\bibitem{pass2015multi}
B.~Pass.
\newblock Multi-marginal optimal transport: theory and applications.
\newblock {\em ESAIM: Mathematical Modelling and Numerical Analysis},
  49(6):1771--1790, 2015.

\bibitem{paty2019subspace}
F.-P. Paty and M.~Cuturi.
\newblock Subspace robust {W}asserstein distances.
\newblock In {\em International Conference on Machine Learning}, pages
  5072--5081, 2019.

\bibitem{paty2020regularity}
F.-P. Paty, A.~d’Aspremont, and M.~Cuturi.
\newblock Regularity as regularization: Smooth and strongly convex brenier
  potentials in optimal transport.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1222--1232. PMLR, 2020.

\bibitem{peyre2019computational}
G.~Peyr{\'e}, M.~Cuturi, et~al.
\newblock Computational optimal transport.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  11(5-6):355--607, 2019.

\bibitem{rabin2014adaptive}
J.~Rabin, S.~Ferradans, and N.~Papadakis.
\newblock Adaptive color transfer with relaxed optimal transport.
\newblock In {\em 2014 IEEE International Conference on Image Processing
  (ICIP)}, pages 4852--4856. IEEE, 2014.

\bibitem{rainey2016dealing}
C.~Rainey.
\newblock Dealing with separation in logistic regression models.
\newblock {\em Political Analysis}, 24(3):339--355, 2016.

\bibitem{redko2019optimal}
I.~Redko, N.~Courty, R.~Flamary, and D.~Tuia.
\newblock Optimal transport for multi-source domain adaptation under target
  shift.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 849--858, 2019.

\bibitem{reich2013nonparametric}
S.~Reich.
\newblock A nonparametric ensemble transform method for bayesian inference.
\newblock {\em SIAM Journal on Scientific Computing}, 35(4):A2013--A2024, 2013.

\bibitem{shin2014probability}
S.~J. Shin, Y.~Wu, H.~H. Zhang, and Y.~Liu.
\newblock Probability-enhanced sufficient dimension reduction for binary
  classification.
\newblock {\em Biometrics}, 70(3):546--555, 2014.

\bibitem{shin2017principal}
S.~J. Shin, Y.~Wu, H.~H. Zhang, and Y.~Liu.
\newblock Principal weighted support vector machines for sufficient dimension
  reduction in binary classification.
\newblock {\em Biometrika}, 104(1):67--81, 2017.

\bibitem{song2007face}
F.~Song, D.~Zhang, Q.~Chen, and J.~Wang.
\newblock Face recognition based on a novel linear discriminant criterion.
\newblock {\em Pattern analysis and applications}, 10(3):165--174, 2007.

\bibitem{su2015optimal}
Z.~Su, Y.~Wang, R.~Shi, W.~Zeng, J.~Sun, F.~Luo, and X.~Gu.
\newblock Optimal mass transport for shape matching and comparison.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  37(11):2246--2259, 2015.

\bibitem{villani2008optimal}
C.~Villani.
\newblock {\em Optimal transport: old and new}.
\newblock Springer Science \& Business Media, 2008.

\bibitem{wang2007feature}
F.~Wang and C.~Zhang.
\newblock Feature extraction by maximizing the average neighborhood margin.
\newblock In {\em 2007 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 1--8. IEEE, 2007.

\bibitem{wang2010unsupervised}
M.~Wang, F.~Sha, and M.~I. Jordan.
\newblock Unsupervised kernel dimension reduction.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2379--2387, 2010.

\bibitem{wang2020structural}
Z.~Wang, Y.~Zhang, and H.~Wu.
\newblock Structural-aware sentence similarity with recursive optimal
  transport.
\newblock {\em arXiv preprint arXiv:2002.00745}, 2020.

\bibitem{wang2020robust}
Z.~Wang, D.~Zhou, M.~Yang, Y.~Zhang, C.~Rao, and H.~Wu.
\newblock Robust document distance with wasserstein-fisher-rao metric.
\newblock In {\em Asian Conference on Machine Learning}, 2020.

\bibitem{wu2019sliced}
J.~Wu, Z.~Huang, D.~Acharya, W.~Li, J.~Thoma, D.~P. Paudel, and L.~V. Gool.
\newblock Sliced wasserstein generative models.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3713--3722, 2019.

\bibitem{xia2009adaptive}
Y.~Xia, H.~Tong, W.~K. Li, and L.-X. Zhu.
\newblock An adaptive estimation of dimension reduction space.
\newblock In {\em Exploration Of A Nonlinear World: An Appreciation of Howell
  Tong's Contributions to Statistics}, pages 299--346. World Scientific, 2009.

\bibitem{yu2015useful}
Y.~Yu, T.~Wang, and R.~J. Samworth.
\newblock A useful variant of the davis--kahan theorem for statisticians.
\newblock {\em Biometrika}, 102(2):315--323, 2015.

\bibitem{zhang2020review}
J.~Zhang, W.~Zhong, and P.~Ma.
\newblock A review on modern computational optimal transport methods with
  applications in biomedical research.
\newblock {\em arXiv preprint arXiv:2008.02995}, 2020.

\bibitem{zhang2011modified}
S.~Zhang, Y.-K. Lei, Y.-H. Wu, and J.-A. Yang.
\newblock Modified orthogonal discriminant projection for classification.
\newblock {\em Neurocomputing}, 74(17):3690--3694, 2011.

\bibitem{zhang2006discriminant}
W.~Zhang, X.~Xue, H.~Lu, and Y.-F. Guo.
\newblock Discriminant neighborhood embedding for classification.
\newblock {\em Pattern Recognition}, 39(11):2240--2243, 2006.

\bibitem{zhao2006local}
H.~Zhao, S.~Sun, Z.~Jing, and J.~Yang.
\newblock Local structure based supervised feature extraction.
\newblock {\em Pattern Recognition}, 39(8):1546--1550, 2006.

\bibitem{zhao2009locality}
X.~Zhao and X.~Tian.
\newblock Locality preserving fisher discriminant analysis for face
  recognition.
\newblock In {\em International Conference on Intelligent Computing}, pages
  261--269. Springer, 2009.

\bibitem{DBLP:conf/emnlp/ZhaoWWZ20}
X.~Zhao, Z.~Wang, H.~Wu, and Y.~Zhang.
\newblock Semi-supervised bilingual lexicon induction by two-way interaction.
\newblock In {\em Empirical Method in Natural Language Processing}. Association
  for Computational Linguistics, 2020.

\bibitem{DBLP:conf/acl/ZhaoWZW20}
X.~Zhao, Z.~Wang, Y.~Zhang, and H.~Wu.
\newblock A relaxed matching procedure for unsupervised {BLI}.
\newblock In D.~Jurafsky, J.~Chai, N.~Schluter, and J.~R. Tetreault, editors,
  {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics, {ACL} 2020, Online, July 5-10, 2020}, pages
  3036--3041. Association for Computational Linguistics, 2020.

\bibitem{zhong2005rsir}
W.~Zhong, P.~Zeng, P.~Ma, J.~S. Liu, and Y.~Zhu.
\newblock Rsir: regularized sliced inverse regression for motif discovery.
\newblock {\em Bioinformatics}, 21(22):4169--4175, 2005.

\bibitem{zhou2016principal}
J.~Zhou and L.~Zhu.
\newblock Principal minimax support vector machine for sufficient dimension
  reduction with contaminated data.
\newblock {\em Computational Statistics \& Data Analysis}, 94:33--48, 2016.

\bibitem{zhu2006sliced}
L.~Zhu, B.~Miao, and H.~Peng.
\newblock On sliced inverse regression with high-dimensional covariates.
\newblock {\em Journal of the American Statistical Association},
  101(474):630--643, 2006.

\bibitem{zhu2010dimension}
L.-P. Zhu, L.-X. Zhu, and Z.-H. Feng.
\newblock Dimension reduction in regressions through cumulative slicing
  estimation.
\newblock {\em Journal of the American Statistical Association},
  105(492):1455--1466, 2010.

\end{thebibliography}
