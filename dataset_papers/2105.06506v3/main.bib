@article{JMLR:v20:18-540,
author  = {Maximilian Alber and Sebastian Lapuschkin and Philipp Seegerer and Miriam H{{\"a}}gele and Kristof T. Sch{{\"u}}tt and Gr{{\'e}}goire Montavon and Wojciech Samek and Klaus-Robert M{{\"u}}ller and Sven D{{\"a}}hne and Pieter-Jan Kindermans},
title   = {iNNvestigate Neural Networks!},
journal = {Journal of Machine Learning Research},
year    = {2019},
volume  = {20},
number  = {93},
pages   = {1-8},
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@article{jeyakumar2020can,
  title={How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods},
  author={Jeyakumar, Jeya Vikranth and Noor, Joseph and Cheng, Yu-Hsi and Garcia, Luis and Srivastava, Mani},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{zhou2022feature,
    title = {Do Feature Attribution Methods Correctly Attribute Features?},
    author = {Zhou, Yilun and Booth, Serena and Ribeiro, Marco Tulio and Shah, Julie},
    booktitle = {Proceedings of the 36th AAAI Conference on Artificial Intelligence},
    year = {2022},
    month = {Feb},
    publisher = {AAAI}
}


@inproceedings{liu2021synthetic,
  title={Synthetic Benchmarks for Scientific Research in Explainable Machine Learning},
  author={Liu, Yang and Khandagale, Sujay and White, Colin and Neiswanger, Willie},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}


@inproceedings{wu2019cascaded,
  title={Cascaded partial decoder for fast and accurate salient object detection},
  author={Wu, Zhe and Su, Li and Huang, Qingming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3907--3916},
  year={2019}
}

@inproceedings{liu2019simple,
  title={A simple pooling-based design for real-time salient object detection},
  author={Liu, Jiang-Jiang and Hou, Qibin and Cheng, Ming-Ming and Feng, Jiashi and Jiang, Jianmin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3917--3926},
  year={2019}
}


@article{zhang2021uncertainty,
  title={Uncertainty inspired RGB-D saliency detection},
  author={Zhang, Jing and Fan, Deng-Ping and Dai, Yuchao and Anwar, Saeed and Saleh, Fatemeh and Aliakbarian, Sadegh and Barnes, Nick},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

@misc{pruthi2020evaluating,
    title={Evaluating Explanations: How much do explanations from the teacher aid students?},
    author={Danish Pruthi and Bhuwan Dhingra and Livio Baldini Soares and Michael Collins and Zachary C. Lipton and Graham Neubig and William W. Cohen},
    year={2020},
    eprint={2012.00893},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{hooker2019benchmark,
  title={A benchmark for interpretability methods in deep neural networks},
  author={Hooker, Sara and Erhan, Dumitru and Kindermans, Pieter-Jan and Kim, Been},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9737--9748},
  year={2019}
}

@article{zhou2017places,
  title={Places: A 10 million Image Database for Scene Recognition},
  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  publisher={IEEE}
}

@misc{leavitt2020falsifiable,
    title={Towards falsifiable interpretability research},
    author={Matthew L. Leavitt and Ari Morcos},
    year={2020},
    eprint={2010.12016},
    archivePrefix={arXiv},
    primaryClass={cs.CY}
}

@misc{dinu2020challenging,
    title={Challenging common interpretability assumptions in feature attribution explanations},
    author={Jonathan Dinu and Jeffrey Bigham and J. Zico Kolter},
    year={2020},
    eprint={2012.02748},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{sixt2021users,
  title={Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset},
  author={Sixt, Leon and Schuessler, Martin and Popescu, Oana-Iuliana and Wei{\ss}, Philipp and Landgraf, Tim},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@incollection{kindermans2019reliability,
  title={The (un) reliability of saliency methods},
  author={Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Sch{\"u}tt, Kristof T and D{\"a}hne, Sven and Erhan, Dumitru and Kim, Been},
  booktitle={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={267--280},
  year={2019},
  publisher={Springer}
}

 @InProceedings{pmlr-v97-etmann19a, title = {On the Connection Between Adversarial Robustness and Saliency Map Interpretability}, author = {Etmann, Christian and Lunz, Sebastian and Maass, Peter and Schoenlieb, Carola}, booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {1823--1832}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/etmann19a/etmann19a.pdf}, url = { http://proceedings.mlr.press/v97/etmann19a.html }} 

@inproceedings{alvarez2018,
 author = {Alvarez Melis, David and Jaakkola, Tommi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Towards Robust Interpretability with Self-Explaining Neural Networks},
 volume = {31},
 year = {2018}
}

@article{shah2021input,
  title={Do Input Gradients Highlight Discriminative Features?},
  author={Shah, Harshay and Jain, Prateek and Netrapalli, Praneeth},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{Ghorbani_Abid_Zou_2019, title={Interpretation of Neural Networks Is Fragile}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4252}, DOI={10.1609/aaai.v33i01.33013681}, abstractNote={&lt;p&gt;In order for machine learning to be trusted in many applications, it is critical to be able to reliably explain why the machine learning algorithm makes certain predictions. For this reason, a variety of methods have been developed recently to interpret neural network predictions by providing, for example, feature importance maps. For both scientific robustness and security reasons, it is important to know to what extent can the interpretations be altered by small systematic perturbations to the input data, which might be generated by adversaries or by measurement biases. In this paper, we demonstrate how to generate adversarial perturbations that produce perceptively indistinguishable inputs that are assigned the &lt;em&gt;same&lt;/em&gt; predicted label, yet have very &lt;em&gt;different&lt;/em&gt; interpretations. We systematically characterize the robustness of interpretations generated by several widely-used feature importance interpretation methods (feature importance maps, integrated gradients, and DeepLIFT) on ImageNet and CIFAR-10. In all cases, our experiments show that systematic perturbations can lead to dramatically different interpretations without changing the label. We extend these results to show that interpretations based on exemplars (e.g. influence functions) are similarly susceptible to adversarial attack. Our analysis of the geometry of the Hessian matrix gives insight on why robustness is a general challenge to current interpretation approaches.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Ghorbani, Amirata and Abid, Abubakar and Zou, James}, year={2019}, month={Jul.}, pages={3681-3688} }

@inproceedings{heo2019,
 author = {Heo, Juyeon and Joo, Sunghwan and Moon, Taesup},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Fooling Neural Network Interpretations via Adversarial Model Manipulation},
 url = {https://proceedings.neurips.cc/paper/2019/file/7fea637fd6d02b8f0adf6f7dc36aed93-Paper.pdf},
 volume = {32},
 year = {2019}
}



@inproceedings{subramanya2019fooling,
  title={Fooling network interpretation in image classification},
  author={Subramanya, Akshayvarun and Pillai, Vipin and Pirsiavash, Hamed},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2020--2029},
  year={2019}
}


@misc{simonyan2013deep,
    title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
    author={Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
    year={2013},
    eprint={1312.6034},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science}
}

@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3319--3328},
  year={2017}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3145--3153},
  year={2017}
}

@article{montavon2017explaining,
  title={Explaining nonlinear classification decisions with deep taylor decomposition},
  author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Pattern Recognition},
  volume={65},
  pages={211--222},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{springenberg2015striving,
  title={Striving for Simplicity: The All Convolutional Net},
  author={Springenberg, J and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, M},
  booktitle={ICLR (workshop track)},
  year={2015}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhang2017mdnet,
  title={Mdnet: A semantically and visually interpretable medical image diagnosis network},
  author={Zhang, Zizhao and Xie, Yuanpu and Xing, Fuyong and McGough, Mason and Yang, Lin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6428--6436},
  year={2017}
}

@article{yamashita2018convolutional,
  title={Convolutional neural networks: an overview and application in radiology},
  author={Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
  journal={Insights into imaging},
  volume={9},
  number={4},
  pages={611--629},
  year={2018},
  publisher={Springer}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  pages={9505--9515},
  year={2018}
}

@inproceedings{kapishnikov2019xrai,
  title={Xrai: Better attributions through regions},
  author={Kapishnikov, Andrei and Bolukbasi, Tolga and Vi{\'e}gas, Fernanda and Terry, Michael},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4948--4957},
  year={2019}
}
@article{gao2019res2net,
  title={Res2net: A new multi-scale backbone architecture},
  author={Gao, Shanghua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip HS},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2019},
  publisher={IEEE}
}

 @InProceedings{Zhou_2016_CVPR,
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
title = {Learning Deep Features for Discriminative Localization},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}



@article{arun2020assessing,
  title={Assessing the (un) trustworthiness of saliency maps for localizing abnormalities in medical imaging},
  author={Arun, Nishanth and Gaw, Nathan and Singh, Praveer and Chang, Ken and Aggarwal, Mehak and Chen, Bryan and Hoebel, Katharina and Gupta, Sharut and Patel, Jay and Gidwani, Mishka and others},
  journal={arXiv preprint arXiv:2008.02766},
  year={2020}
}

@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}


@inproceedings{chattopadhay2018grad,
  title={Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks},
  author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
  booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={839--847},
  year={2018},
  organization={IEEE}
}


@inproceedings{
ancona2018towards,
title={Towards better understanding of gradient-based attribution methods for Deep Neural Networks},
author={Marco Ancona and Enea Ceolini and Cengiz Öztireli and Markus Gross},
booktitle={International Conference on Learning Representations},
year={2018},
}

@inproceedings{alexnet2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 year = {2012}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}


@article{Tomsett_2020,
   title={Sanity Checks for Saliency Metrics},
   volume={34},
   number={04},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Tomsett, Richard and Harborne, Dan and Chakraborty, Supriyo and Gurram, Prudhvi and Preece, Alun},
   year={2020},
   month={Apr},
   pages={6021–6029}
}

@inproceedings{adebayo2020debugging,
 author = {Adebayo, Julius and Muelly, Michael and Liccardi, Ilaria and Kim, Been},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {700--712},
 publisher = {Curran Associates, Inc.},
 title = {Debugging Tests for Model Explanations},
 volume = {33},
 year = {2020}
}



@misc{lin2020evaluation,
    title={What Do You See? Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors},
    author={Yi-Shan Lin and Wen-Chuan Lee and Z. Berkay Celik},
    year={2020},
    eprint={2009.10639},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{everingham2015pascal,
  title={The pascal visual object classes challenge: A retrospective},
  author={Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={111},
  number={1},
  pages={98--136},
  year={2015},
  publisher={Springer}
}

@article{zhou2021feature,
  title={Do Feature Attribution Methods Correctly Attribute Features?},
  author={Zhou, Yilun and Booth, Serena and Ribeiro, Marco Tulio and Shah, Julie},
  journal={arXiv preprint arXiv:2104.14403},
  year={2021}
}



@inproceedings{wang2020score,
  title={Score-CAM: Score-weighted visual explanations for convolutional neural networks},
  author={Wang, Haofan and Wang, Zifan and Du, Mengnan and Yang, Fan and Zhang, Zijian and Ding, Sirui and Mardziel, Piotr and Hu, Xia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={24--25},
  year={2020}
}



@inproceedings{wang2019pseudo,
  title={Pseudo-lidar from visual depth estimation: Bridging the gap in 3d object detection for autonomous driving},
  author={Wang, Yan and Chao, Wei-Lun and Garg, Divyansh and Hariharan, Bharath and Campbell, Mark and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8445--8453},
  year={2019}
}


@article{hsieh2020evaluations,
  title={Evaluations and Methods for Explanation through Robustness Analysis},
  author={Hsieh, Cheng-Yu and Yeh, Chih-Kuan and Liu, Xuanqing and Ravikumar, Pradeep and Kim, Seungyeon and Kumar, Sanjiv and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2006.00442},
  year={2020}
}

@article{deyoung2020eraser,
  title={ERASER: A Benchmark to Evaluate Rationalized NLP Models},
  author={DeYoung, Jay and Jain, Sarthak and Rajani, Nazneen Fatema and Lehman, Eric and Xiong, Caiming and Socher, Richard and Wallace, Byron C},
  journal={Transactions of the Association for Computational Linguistics},
  year={2020}
}

@article{wachter2017counterfactual,
  title={Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harv. JL \& Tech.},
  volume={31},
  pages={841},
  year={2017},
  publisher={HeinOnline}
}

@inproceedings{alqaraawi2020evaluating,
  title={Evaluating saliency map explanations for convolutional neural networks: a user study},
  author={Alqaraawi, Ahmed and Schuessler, Martin and Wei{\ss}, Philipp and Costanza, Enrico and Berthouze, Nadia},
  booktitle={Proceedings of the 25th International Conference on Intelligent User Interfaces},
  pages={275--285},
  year={2020}
}

@inproceedings{ross2017right,
  title={Right for the right reasons: training differentiable models by constraining their explanations},
  author={Ross, Andrew Slavin and Hughes, Michael C and Doshi-Velez, Finale},
  booktitle={Proceedings of the 26th International Joint Conference on Artificial Intelligence},
  pages={2662--2670},
  year={2017}
}

@inproceedings{rieger2020interpretations,
  title={Interpretations are useful: penalizing explanations to align neural networks with prior knowledge},
  author={Rieger, Laura and Singh, Chandan and Murdoch, William and Yu, Bin},
  booktitle={International Conference on Machine Learning},
  pages={8116--8126},
  year={2020},
  organization={PMLR}
}

@misc{weinberger2019learning,
    title={Learning Deep Attribution Priors Based On Prior Knowledge},
    author={Ethan Weinberger and Joseph Janizek and Su-In Lee},
    year={2019},
    eprint={1912.10065},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{lage2019evaluation,
    title={An Evaluation of the Human-Interpretability of Explanation},
    author={Isaac Lage and Emily Chen and Jeffrey He and Menaka Narayanan and Been Kim and Sam Gershman and Finale Doshi-Velez},
    year={2019},
    eprint={1902.00006},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{amarasinghe2020explainable,
    title={Explainable Machine Learning for Public Policy: Use Cases, Gaps, and Research Directions},
    author={Kasun Amarasinghe and Kit Rodolfa and Hemank Lamba and Rayid Ghani},
    year={2020},
    eprint={2010.14374},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Murdoch_2019,
   title={Definitions, methods, and applications in interpretable machine learning},
   volume={116},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1900654116},
   DOI={10.1073/pnas.1900654116},
   number={44},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Murdoch, W. James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
   year={2019},
   month={Oct},
   pages={22071–22080}
}

@article{dhurandhar2018explanations,
  title={Explanations based on the missing: Towards contrastive explanations with pertinent negatives},
  author={Dhurandhar, Amit and Chen, Pin-Yu and Luss, Ronny and Tu, Chun-Chen and Ting, Paishun and Shanmugam, Karthikeyan and Das, Payel},
  journal={arXiv preprint arXiv:1802.07623},
  year={2018}
}

@inproceedings{dombrowski,
 author = {Dombrowski, Ann-Kathrin and Alber, Maximillian and Anders, Christopher and Ackermann, Marcel and M\"{u}ller, Klaus-Robert and Kessel, Pan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Explanations can be manipulated and geometry is to blame},
 url = {https://proceedings.neurips.cc/paper/2019/file/bb836c01cdc9120a9c984c525e4b1a4a-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@inproceedings{
srinivas2021rethinking,
title={Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability},
author={Suraj Srinivas and Francois Fleuret},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=dYeAHXnpWJ4}
}

@article{zhang2018top,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}



@article{lundberg2017unified,
  title={A Unified Approach to Interpreting Model Predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={4765--4774},
  year={2017}
}


@misc{yoon2019rllim,
    title={RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling},
    author={Jinsung Yoon and Sercan O. Arik and Tomas Pfister},
    year={2019},
    eprint={1909.12367},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{yang2019benchmarking,
    title={Benchmarking Attribution Methods with Relative Feature Importance},
    author={Mengjiao Yang and Been Kim},
    year={2019},
    eprint={1907.09701},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}