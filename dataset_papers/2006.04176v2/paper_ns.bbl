\begin{thebibliography}{70}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Friston(2010)]{friston2010free}
Karl~J Friston.
\newblock The free-energy principle: A unified brain theory?
\newblock \emph{Nature Reviews Neuroscience}, 11\penalty0 (2):\penalty0
  127--138, 2010.

\bibitem[Friston(2019)]{friston2019free}
Karl~J Friston.
\newblock A free energy principle for a particular physics.
\newblock \emph{arXiv preprint arXiv:1906.10184}, 2019.

\bibitem[Friston et~al.(2016)Friston, FitzGerald, Rigoli, Schwartenbeck,
  O'Doherty, and Pezzulo]{learningpaper}
Karl~J Friston, Thomas. FitzGerald, Francesco Rigoli, Philipp Schwartenbeck,
  John O'Doherty, and Giovanni Pezzulo.
\newblock Active inference and learning.
\newblock \emph{Neuroscience $\&$ Biobehavioral Reviews}, 68:\penalty0 862--79,
  2016.

\bibitem[Friston et~al.(2017{\natexlab{a}})Friston, FitzGerald, Rigoli,
  Schwartenbeck, and Pezzulo]{friston2017active}
Karl~J Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and
  Giovanni Pezzulo.
\newblock Active inference: {A} process theory.
\newblock \emph{Neural Computation}, 29\penalty0 (1):\penalty0 1--49,
  2017{\natexlab{a}}.

\bibitem[Friston et~al.(2017{\natexlab{b}})Friston, Parr, and
  de~Vries]{friston2017graphical}
Karl~J Friston, Thomas Parr, and Bert de~Vries.
\newblock The graphical brain: {Belief} propagation and active inference.
\newblock \emph{Network Neuroscience}, 1\penalty0 (4):\penalty0 381--414,
  2017{\natexlab{b}}.

\bibitem[Pezzulo et~al.(2018)Pezzulo, Rigoli, and
  Friston]{pezzulo2018hierarchical}
Giovanni Pezzulo, Francesco Rigoli, and Karl~J Friston.
\newblock Hierarchical active inference: A theory of motivated control.
\newblock \emph{Trends in Cognitive Sciences}, 22\penalty0 (4):\penalty0
  294--306, 2018.

\bibitem[Da~Costa et~al.(2020)Da~Costa, Parr, Sajid, Veselic, Neacsu, and
  Friston]{da2020active}
Lancelot Da~Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita
  Neacsu, and Karl Friston.
\newblock Active inference on discrete state-spaces: {A} synthesis.
\newblock \emph{arXiv preprint arXiv:2001.07203}, 2020.

\bibitem[Parr and Friston(2017)]{Parr:2017:Uncertainty}
Thomas Parr and Karl~J Friston.
\newblock Uncertainty, epistemics and active inference.
\newblock \emph{Journal of The Royal Society Interface}, 14\penalty0
  (136):\penalty0 20170376, 2017.

\bibitem[Friston et~al.(2018)Friston, Rosch, Parr, Price, and
  Bowman]{deeptemporal}
Karl~J Friston, Richard Rosch, Thomas Parr, Cathy Price, and Howard Bowman.
\newblock Deep temporal models and active inference.
\newblock \emph{Neuroscience and Biobehavioral Reviews}, 90:\penalty0
  486â€”501, 2018.

\bibitem[Sajid et~al.(2019)Sajid, Ball, and Friston]{sajid2019demystifying}
Noor Sajid, Philip~J Ball, and Karl~J Friston.
\newblock Active inference: {Demystified} and compared.
\newblock \emph{arXiv preprint arXiv:1909.10863}, 2019.

\bibitem[Hesp et~al.(2019)Hesp, Smith, Allen, Friston, and
  Ramstead]{hesp2019deeply}
Casper Hesp, Ryan Smith, Micah Allen, Karl~J Friston, and Maxwell Ramstead.
\newblock Deeply felt affect: {The} emergence of valence in deep active
  inference.
\newblock \emph{PsyArXiv}, 2019.

\bibitem[Cullen et~al.(2018)Cullen, Davey, Friston, and Moran]{Cullen}
Maell Cullen, Ben Davey, Karl~J Friston, and Rosalyn~J. Moran.
\newblock Active inference in {OpenAI Gym: A} paradigm for computational
  investigations into psychiatric illness.
\newblock \emph{Biological Psychiatry: Cognitive Neuroscience and
  Neuroimaging}, 3\penalty0 (9):\penalty0 809--818, 2018.

\bibitem[Friston et~al.(2009)Friston, Daunizeau, and Kiebel]{active_rl}
Karl~J Friston, Jean Daunizeau, and Stefan~J Kiebel.
\newblock Reinforcement learning or active inference?
\newblock \emph{PLoS ONE}, 4\penalty0 (7):\penalty0 e6421, 2009.

\bibitem[Ueltzh{\"o}ffer(2018)]{ueltzhoffer2018deep}
Kai Ueltzh{\"o}ffer.
\newblock Deep active inference.
\newblock \emph{Biological Cybernetics}, 112\penalty0 (6):\penalty0 547--573,
  2018.

\bibitem[{\c{C}}atal et~al.(2019){\c{C}}atal, Nauta, Verbelen, Simoens, and
  Dhoedt]{ccatal2019bayesian}
Ozan {\c{C}}atal, Johannes Nauta, Tim Verbelen, Pieter Simoens, and Bart
  Dhoedt.
\newblock Bayesian policy selection using active inference.
\newblock \emph{arXiv preprint arXiv:1904.08149}, 2019.

\bibitem[Tschantz et~al.(2019)Tschantz, Baltieri, Seth, Buckley,
  et~al.]{tschantz2019scaling}
Alexander Tschantz, Manuel Baltieri, Anil Seth, Christopher~L Buckley, et~al.
\newblock Scaling active inference.
\newblock \emph{arXiv preprint arXiv:1911.10601}, 2019.

\bibitem[Millidge(2020)]{millidge2020deep}
Beren Millidge.
\newblock Deep active inference as variational policy gradients.
\newblock \emph{Journal of Mathematical Psychology}, 96:\penalty0 102348, 2020.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017variational}
David~M Blei, Alp Kucukelbir, and Jon~D McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (518):\penalty0 859--877, 2017.

\bibitem[Parr and Friston(2019)]{parr2019generalised}
Thomas Parr and Karl~J Friston.
\newblock Generalised free energy and active inference.
\newblock \emph{Biological Cybernetics}, 113\penalty0 (5-6):\penalty0 495--513,
  2019.

\bibitem[Schwartenbeck et~al.(2019)Schwartenbeck, Passecker, Hauser,
  FitzGerald, Kronbichler, and Friston]{schwartenbeck2019computational}
Philipp Schwartenbeck, Johannes Passecker, Tobias~U Hauser, Thomas~HB
  FitzGerald, Martin Kronbichler, and Karl~J Friston.
\newblock Computational mechanisms of curiosity and goal-directed exploration.
\newblock \emph{eLife}, 8:\penalty0 e41703, 2019.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock MIT press, 2018.

\bibitem[Gal and Ghahramani(2016)]{Gal:2016:Dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a {Bayesian} approximation: {Representing} model
  uncertainty in deep learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1050--1059, 2016.

\bibitem[Coulom(2006)]{coulom2006efficient}
R{\'e}mi Coulom.
\newblock Efficient selectivity and backup operators in monte-carlo tree
  search.
\newblock In \emph{International Conference on Computers and Games}, pages
  72--83. Springer, 2006.

\bibitem[Browne et~al.(2012)Browne, Powley, Whitehouse, Lucas, Cowling,
  Rohlfshagen, Tavener, Perez, Samothrakis, and Colton]{browne2012survey}
Cameron~B Browne, Edward Powley, Daniel Whitehouse, Simon~M Lucas, Peter~I
  Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon
  Samothrakis, and Simon Colton.
\newblock A survey of {Monte Carlo} tree search methods.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in
  Games}, 4\penalty0 (1):\penalty0 1--43, 2012.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, et~al.]{silver2017mastering}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550\penalty0 (7676):\penalty0 354--359, 2017.

\bibitem[Pich{\'e} et~al.(2018)Pich{\'e}, Thomas, Ibrahim, Bengio, and
  Pal]{piche2018probabilistic}
Alexandre Pich{\'e}, Valentin Thomas, Cyril Ibrahim, Yoshua Bengio, and Chris
  Pal.
\newblock Probabilistic planning with sequential monte carlo methods.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Tschantz et~al.(2020)Tschantz, Millidge, Seth, and
  Buckley]{tschantz2020control}
Alexander Tschantz, Beren Millidge, Anil~K Seth, and Christopher~L Buckley.
\newblock Control as hybrid inference.
\newblock \emph{arXiv preprint arXiv:2007.05838}, 2020.

\bibitem[Marino and Yue(2019)]{marinoinference}
Joseph Marino and Yisong Yue.
\newblock An inference perspective on model-based reinforcement learning.
\newblock \emph{ICML Workshop on Generative Modeling and Model-Based Reasoning
  for Robotics and AI}, 2019.

\bibitem[Van Der~Meer et~al.(2012)Van Der~Meer, Kurth-Nelson, and
  Redish]{van2012information}
Matthijs Van Der~Meer, Zeb Kurth-Nelson, and A~David Redish.
\newblock Information processing in decision-making systems.
\newblock \emph{The Neuroscientist}, 18\penalty0 (4):\penalty0 342--359, 2012.

\bibitem[Byers and Serences(2012)]{byers2012topdown}
Anna Byers and John~T. Serences.
\newblock Exploring the relationship between perceptual learning and top-down
  attentional control.
\newblock \emph{Vision Research}, 74:\penalty0 30 -- 39, 2012.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{Higgins:2017:betaVAE}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock \emph{International Conference on Learning Representations},
  2\penalty0 (5):\penalty0 6, 2017.

\bibitem[Matthey et~al.(2017)Matthey, Higgins, Hassabis, and
  Lerchner]{dsprites17}
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.
\newblock dsprites: Disentanglement testing sprites dataset.
\newblock https://github.com/deepmind/dsprites-dataset/, 2017.

\bibitem[Crosby et~al.(2019)Crosby, Beyret, and Halina]{Crosby:2019:animalai}
Matthew Crosby, Benjamin Beyret, and Marta Halina.
\newblock The {Animal-AI} olympics.
\newblock \emph{Nature Machine Intelligence}, 1\penalty0 (5):\penalty0
  257--257, 2019.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Hsieh et~al.(2018)Hsieh, Liu, Huang, Fei-Fei, and
  Niebles]{Hsieh:2018:nips}
Jun-Ting Hsieh, Bingbin Liu, De-An Huang, Li~F Fei-Fei, and Juan~Carlos
  Niebles.
\newblock Learning to decompose and disentangle representations for video
  prediction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  517--526, 2018.

\bibitem[Kim and Mnih(2018)]{Kim:2018:factorvae}
Hyunjik Kim and Andriy Mnih.
\newblock Disentangling by factorising.
\newblock \emph{arXiv preprint arXiv:1802.05983}, 2018.

\bibitem[Dhariwal et~al.(2017)Dhariwal, Hesse, Klimov, Nichol, Plappert,
  Radford, Schulman, Sidor, Wu, and Zhokhov]{baselines}
Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias
  Plappert, Alec Radford, John Schulman, Szymon Sidor, Yuhuai Wu, and Peter
  Zhokhov.
\newblock Openai baselines.
\newblock \url{https://github.com/openai/baselines}, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{Mnih:2015:dqn}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{Mnih:2016:A2C}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pages
  1928--1937, 2016.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{Schulman:2017:PPO}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Isomura and Friston(2018)]{isomura2018vitro}
Takuya Isomura and Karl~J Friston.
\newblock In vitro neural networks minimise variational free energy.
\newblock \emph{Nature Scientific Reports}, 8\penalty0 (1):\penalty0 1--14,
  2018.

\bibitem[Adams et~al.(2013)Adams, Shipp, and Friston]{adams2013predictions}
Rick~A Adams, Stewart Shipp, and Karl~J Friston.
\newblock Predictions not commands: Active inference in the motor system.
\newblock \emph{Brain Structure and Function}, 218\penalty0 (3):\penalty0
  611--643, 2013.

\bibitem[Kocsis and Szepesv{\'a}ri(2006)]{kocsis2006bandit}
Levente Kocsis and Csaba Szepesv{\'a}ri.
\newblock Bandit based {Monte-Carlo} planning.
\newblock In \emph{European Conference on Machine Learning}, pages 282--293.
  Springer, 2006.

\bibitem[Guo et~al.(2014)Guo, Singh, Lee, Lewis, and Wang]{guo2014deep}
Xiaoxiao Guo, Satinder Singh, Honglak Lee, Richard~L Lewis, and Xiaoshi Wang.
\newblock Deep learning for real-time {Atari} game play using offline
  {Monte-Carlo} tree search planning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3338--3346, 2014.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484, 2016.

\bibitem[{\c{C}}atal et~al.(2020){\c{C}}atal, Verbelen, Nauta, De~Boom, and
  Dhoedt]{ccatal2020learning}
Ozan {\c{C}}atal, Tim Verbelen, Johannes Nauta, Cedric De~Boom, and Bart
  Dhoedt.
\newblock Learning perception and planning with deep active inference.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing}, pages 3952--3956, 2020.

\bibitem[Snider et~al.(2015)Snider, Lee, Poizner, and
  Gepshtein]{snider2015prospective}
Joseph Snider, Dongpyo Lee, Howard Poizner, and Sergei Gepshtein.
\newblock Prospective optimization with limited resources.
\newblock \emph{PLoS Computational Biology}, 11\penalty0 (9), 2015.

\bibitem[Solway and Botvinick(2015)]{solway2015evidence}
Alec Solway and Matthew~M Botvinick.
\newblock Evidence integration in model-based tree search.
\newblock \emph{Proceedings of the National Academy of Sciences}, 112\penalty0
  (37):\penalty0 11708--11713, 2015.

\bibitem[van Opheusden et~al.(2017)van Opheusden, Galbiati, Bnaya, Li, and
  Ma]{van2017computational}
Bas van Opheusden, Gianni Galbiati, Zahy Bnaya, Yunqi Li, and Wei~Ji Ma.
\newblock A computational model for decision tree search.
\newblock In \emph{CogSci.}, 2017.

\bibitem[Holding(1989)]{holding1989counting}
Dennis~H Holding.
\newblock Counting backward during chess move choice.
\newblock \emph{Bulletin of the Psychonomic Society}, 27\penalty0 (5):\penalty0
  421--424, 1989.

\bibitem[Huys et~al.(2012)Huys, Eshel, O'Nions, Sheridan, Dayan, and
  Roiser]{huys2012bonsai}
Quentin~JM Huys, Neir Eshel, Elizabeth O'Nions, Luke Sheridan, Peter Dayan, and
  Jonathan~P Roiser.
\newblock Bonsai trees in your head: {How} the {Pavlovian} system sculpts
  goal-directed choices by pruning decision trees.
\newblock \emph{PLoS Computational Biology}, 8\penalty0 (3), 2012.

\bibitem[Burns(2004)]{burns2004effects}
Bruce~D Burns.
\newblock The effects of speed on skilled chess performance.
\newblock \emph{Psychological Science}, 15\penalty0 (7):\penalty0 442--447,
  2004.

\bibitem[Van~Harreveld et~al.(2007)Van~Harreveld, Wagenmakers, and Van
  Der~Maas]{van2007effects}
Frenk Van~Harreveld, Eric-Jan Wagenmakers, and Han~LJ Van Der~Maas.
\newblock The effects of time pressure on chess skill: {An} investigation into
  fast and slow processes underlying expert performance.
\newblock \emph{Psychological Research}, 71\penalty0 (5):\penalty0 591--597,
  2007.

\bibitem[Mathieu et~al.(2018)Mathieu, Rainforth, Siddharth, and
  Teh]{Mathieu:2018}
Emile Mathieu, Tom Rainforth, N~Siddharth, and Yee~Whye Teh.
\newblock Disentangling disentanglement in variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1812.02833}, 2018.

\bibitem[Kim et~al.(2019)Kim, Wang, Sahu, and Pavlovic]{Kim:2019}
Minyoung Kim, Yuting Wang, Pritish Sahu, and Vladimir Pavlovic.
\newblock {Bayes-Factor-VAE: Hierarchical Bayesian} deep auto-encoder models
  for factor disentanglement.
\newblock In \emph{IEEE International Conference on Computer Vision}, pages
  2979--2987, 2019.

\bibitem[Fatemi~Shariatpanahi and Nili~Ahmadabadi(2007)]{hadi2007attention}
Hadi Fatemi~Shariatpanahi and Majid Nili~Ahmadabadi.
\newblock Biologically inspired framework for learning and abstract
  representation of attention control.
\newblock In \emph{Attention in Cognitive Systems. Theories and Systems from an
  Interdisciplinary Viewpoint}, pages 307--324, 2007.

\bibitem[Mott et~al.(2019)Mott, Zoran, Chrzanowski, Wierstra, and
  Rezende]{mott2019towards}
Alexander Mott, Daniel Zoran, Mike Chrzanowski, Daan Wierstra, and Danilo~J
  Rezende.
\newblock Towards interpretable reinforcement learning using attention
  augmented agents.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  12329--12338, 2019.

\bibitem[Parr et~al.(2018)Parr, Benrimoh, Vincent, and
  Friston]{parr2018perceptual}
Thomas Parr, David~A. Benrimoh, Peter Vincent, and Karl~J Friston.
\newblock Precision and false perceptual inference.
\newblock \emph{Frontiers in Integrative Neuroscience}, 12:\penalty0 39, 2018.

\bibitem[Dayan et~al.(2000)Dayan, Kakade, and Montague]{dayan2000learning}
Peter Dayan, Sham Kakade, and Read~P Montague.
\newblock Learning and selective attention.
\newblock \emph{Nature Neuroscience}, 3\penalty0 (11):\penalty0 1218--1223,
  2000.

\bibitem[Baluch and Itti(2011)]{baluch2011mechanisms}
Farhan Baluch and Laurent Itti.
\newblock Mechanisms of top-down attention.
\newblock \emph{Trends in Neurosciences}, 34\penalty0 (4):\penalty0 210--224,
  2011.

\bibitem[Sasaki et~al.(2010)Sasaki, Nanez, and Watanabe]{sasaki2010advances}
Yuka Sasaki, Jose~E Nanez, and Takeo Watanabe.
\newblock Advances in visual perceptual learning and plasticity.
\newblock \emph{Nature Reviews Neuroscience}, 11\penalty0 (1):\penalty0 53--60,
  2010.

\bibitem[Posner and Petersen(1990)]{posner1990attention}
Michael~I Posner and Steven~E Petersen.
\newblock The attention system of the human brain.
\newblock \emph{Annual Review of Neuroscience}, 13\penalty0 (1):\penalty0
  25--42, 1990.

\bibitem[Dayan and Yu(2002)]{dayan2001nips}
Peter Dayan and Angela~J Yu.
\newblock {ACh}, uncertainty, and cortical inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  189--196, 2002.

\bibitem[Gu(2002)]{gu2002neuromodulatory}
Q~Gu.
\newblock Neuromodulatory transmitter systems in the cortex and their role in
  cortical plasticity.
\newblock \emph{Neuroscience}, 111\penalty0 (4):\penalty0 815--835, 2002.

\bibitem[Yu and Dayan(2005)]{Yu:2005:Uncertainty}
Angela~J Yu and Peter Dayan.
\newblock Uncertainty, neuromodulation, and attention.
\newblock \emph{Neuron}, 46\penalty0 (4):\penalty0 681--692, 2005.

\bibitem[Moran et~al.(2013)Moran, Campo, Symmonds, Stephan, Dolan, and
  Friston]{moran2013free}
Rosalyn~J Moran, Pablo Campo, Mkael Symmonds, Klaas~E Stephan, Raymond~J Dolan,
  and Karl~J Friston.
\newblock Free energy, precision and learning: {The} role of cholinergic
  neuromodulation.
\newblock \emph{Journal of Neuroscience}, 33\penalty0 (19):\penalty0
  8227--8236, 2013.

\bibitem[Parr(2019)]{parr2019computational}
Thomas Parr.
\newblock \emph{The Computational Neurology of Active Vision}.
\newblock PhD thesis, University College London, 2019.

\bibitem[Fellows et~al.(2019)Fellows, Mahajan, Rudner, and
  Whiteson]{fellows2019virel}
Matthew Fellows, Anuj Mahajan, Tim~GJ Rudner, and Shimon Whiteson.
\newblock Virel: A variational inference framework for reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  7122--7136, 2019.

\bibitem[Levine(2018)]{levine2018reinforcement}
Sergey Levine.
\newblock Reinforcement learning and control as probabilistic inference:
  Tutorial and review.
\newblock \emph{arXiv preprint arXiv:1805.00909}, 2018.

\bibitem[Parr and Friston(2018)]{parr2018computational}
Thomas Parr and Karl~J Friston.
\newblock The computational anatomy of visual neglect.
\newblock \emph{Cerebral Cortex}, 28\penalty0 (2):\penalty0 777--790, 2018.

\end{thebibliography}
