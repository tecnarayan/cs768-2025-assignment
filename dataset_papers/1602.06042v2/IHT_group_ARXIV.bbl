\begin{thebibliography}{10}

\bibitem{sub_bach}
Francis Bach.
\newblock Convex analysis and optimization with submodular functions: A
  tutorial.
\newblock {\em arXiv preprint arXiv:1010.4207}, 2010.

\bibitem{mbcs}
Richard~G Baraniuk, Volkan Cevher, Marco~F Duarte, and Chinmay Hegde.
\newblock Model-based compressive sensing.
\newblock {\em Information Theory, IEEE Transactions on}, 56(4):1982--2001,
  2010.

\bibitem{volkan_tractability}
Nirav Bhan, Luca Baldassarre, and Volkan Cevher.
\newblock Tractability of interpretability via selection of group-sparse
  models.
\newblock In {\em Information Theory Proceedings (ISIT), 2013 IEEE
  International Symposium on}, pages 1037--1041. IEEE, 2013.

\bibitem{blumensathapprox}
Thomas Blumensath.
\newblock Sampling and reconstructing signals from a union of linear subspaces.
\newblock {\em Information Theory, IEEE Transactions on}, 57(7):4660--4671,
  2011.

\bibitem{blumensathuos}
Thomas Blumensath and Mike~E Davies.
\newblock Sampling theorems for signals from the union of finite-dimensional
  linear subspaces.
\newblock {\em Information Theory, IEEE Transactions on}, 55(4):1872--1882,
  2009.

\bibitem{iht2}
Thomas Blumensath and Mike~E Davies.
\newblock Normalized iterative hard thresholding: Guaranteed stability and
  performance.
\newblock {\em Selected Topics in Signal Processing, IEEE Journal of},
  4(2):298--309, 2010.

\bibitem{hegdeapprox}
Chinmay Hegde, Piotr Indyk, and Ludwig Schmidt.
\newblock Approximation algorithms for model-based compressive sensing.
\newblock {\em Information Theory, IEEE Transactions on}, 61(9):5129--5147,
  2015.

\bibitem{zhang}
Junzhou Huang, Tong Zhang, and Dimitris Metaxas.
\newblock Learning with structured sparsity.
\newblock {\em The Journal of Machine Learning Research}, 12:3371--3412, 2011.

\bibitem{jacob}
Laurent Jacob, Guillaume Obozinski, and Jean-Philippe Vert.
\newblock Group lasso with overlap and graph lasso.
\newblock In {\em Proceedings of the 26th annual International Conference on
  Machine Learning}, pages 433--440. ACM, 2009.

\bibitem{ompr}
Prateek Jain, Ambuj Tewari, and Inderjit~S Dhillon.
\newblock Orthogonal matching pursuit with replacement.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1215--1223, 2011.

\bibitem{jainiht}
Prateek Jain, Ambuj Tewari, and Purushottam Kar.
\newblock On iterative hard thresholding methods for high-dimensional
  m-estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  685--693, 2014.

\bibitem{jenatton2010proximal}
Rodolphe Jenatton, Julien Mairal, Francis~R Bach, and Guillaume~R Obozinski.
\newblock Proximal methods for sparse hierarchical dictionary learning.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 487--494, 2010.

\bibitem{tasosapprox}
Anastasios Kyrillidis and Volkan Cevher.
\newblock Combinatorial selection and least absolute shrinkage via the clash
  algorithm.
\newblock In {\em Information Theory Proceedings (ISIT), 2012 IEEE
  International Symposium on}, pages 2216--2220. IEEE, 2012.

\bibitem{mtl_lounici}
Karim Lounici, Massimiliano Pontil, Alexandre~B Tsybakov, and Sara Van De~Geer.
\newblock Taking advantage of sparsity in multi-task learning.
\newblock {\em arXiv preprint arXiv:0903.1468}, 2009.

\bibitem{nemhauser}
George~L Nemhauser, Laurence~A Wolsey, and Marshall~L Fisher.
\newblock An analysis of approximations for maximizing submodular set
  functions.
\newblock {\em Mathematical Programming}, 14(1):265--294, 1978.

\bibitem{nrsos}
Nikhil Rao, Christopher Cox, Rob Nowak, and Timothy~T Rogers.
\newblock Sparse overlapping sets lasso for multitask learning and its
  application to fmri analysis.
\newblock In {\em Advances in neural information processing systems}, pages
  2202--2210, 2013.

\bibitem{rao2015forward}
Nikhil Rao, Parikshit Shah, and Stephen Wright.
\newblock Forward--backward greedy algorithms for atomic norm regularization.
\newblock {\em Signal Processing, IEEE Transactions on}, 63(21):5798--5811,
  2015.

\bibitem{nraistats}
Nikhil~S Rao, Ben Recht, and Robert~D Nowak.
\newblock Universal measurement bounds for structured sparse signal recovery.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 942--950, 2012.

\bibitem{pariapprox}
Parikshit Shah and Venkat Chandrasekaran.
\newblock Iterative projections for signal identification on manifolds: Global
  recovery guarantees.
\newblock In {\em Communication, Control, and Computing (Allerton), 2011 49th
  Annual Allerton Conference on}, pages 760--767. IEEE, 2011.

\bibitem{groupOMP}
Grzegorz Swirszcz, Naoki Abe, and Aurelie~C Lozano.
\newblock Grouped orthogonal matching pursuit for variable selection and
  prediction.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1150--1158, 2009.

\bibitem{tewari}
Ambuj Tewari, Pradeep~K Ravikumar, and Inderjit~S Dhillon.
\newblock Greedy algorithms for structurally constrained high dimensional
  problems.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  882--890, 2011.

\bibitem{omp}
Joel Tropp, Anna~C Gilbert, et~al.
\newblock Signal recovery from random measurements via orthogonal matching
  pursuit.
\newblock {\em Information Theory, IEEE Transactions on}, 53(12):4655--4666,
  2007.

\bibitem{oracle_vdg}
Sara~A Van De~Geer, Peter B{\"u}hlmann, et~al.
\newblock On the conditions used to prove oracle results for the lasso.
\newblock {\em Electronic Journal of Statistics}, 3:1360--1392, 2009.

\bibitem{grahtp}
Xiaotong Yuan, Ping Li, and Tong Zhang.
\newblock Gradient hard thresholding pursuit for sparsity-constrained
  optimization.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 127--135, 2014.

\end{thebibliography}
