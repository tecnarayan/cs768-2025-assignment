\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, et~al.]{tensorflow}
Abadi, Mart{\'\i}n, Agarwal, Ashish, Barham, Paul, Brevdo, Eugene, Chen,
  Zhifeng, Citro, Craig, Corrado, Greg~S, Davis, Andy, Dean, Jeffrey, Devin,
  Matthieu, et~al.
\newblock Tensorflow: Large-scale machine learning on heterogeneous distributed
  systems.
\newblock \emph{arXiv preprint arXiv:1603.04467}, 2016.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, and de~Freitas]{learntolearnbygdbygd}
Andrychowicz, Marcin, Denil, Misha, Gomez, Sergio, Hoffman, Matthew~W, Pfau,
  David, Schaul, Tom, and de~Freitas, Nando.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2016.

\bibitem[Bengio et~al.(1992)Bengio, Bengio, Cloutier, and
  Gecsei]{bengiobengio1}
Bengio, Samy, Bengio, Yoshua, Cloutier, Jocelyn, and Gecsei, Jan.
\newblock On the optimization of a synaptic learning rule.
\newblock In \emph{Optimality in Artificial and Biological Neural Networks},
  pp.\  6--8, 1992.

\bibitem[Bengio et~al.(1990)Bengio, Bengio, and Cloutier]{bengiobengio2}
Bengio, Yoshua, Bengio, Samy, and Cloutier, Jocelyn.
\newblock \emph{Learning a synaptic learning rule}.
\newblock Universit{\'e} de Montr{\'e}al, D{\'e}partement d'informatique et de
  recherche op{\'e}rationnelle, 1990.

\bibitem[Donahue et~al.(2014)Donahue, Jia, Vinyals, Hoffman, Zhang, Tzeng, and
  Darrell]{decaf}
Donahue, Jeff, Jia, Yangqing, Vinyals, Oriol, Hoffman, Judy, Zhang, Ning,
  Tzeng, Eric, and Darrell, Trevor.
\newblock Decaf: A deep convolutional activation feature for generic visual
  recognition.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2014.

\bibitem[Duan et~al.(2016{\natexlab{a}})Duan, Chen, Houthooft, Schulman, and
  Abbeel]{benchmarking}
Duan, Yan, Chen, Xi, Houthooft, Rein, Schulman, John, and Abbeel, Pieter.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2016{\natexlab{a}}.

\bibitem[Duan et~al.(2016{\natexlab{b}})Duan, Schulman, Chen, Bartlett,
  Sutskever, and Abbeel]{rl2}
Duan, Yan, Schulman, John, Chen, Xi, Bartlett, Peter~L, Sutskever, Ilya, and
  Abbeel, Pieter.
\newblock Rl2: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016{\natexlab{b}}.

\bibitem[Edwards \& Storkey(2017)Edwards and Storkey]{neuralstatistician}
Edwards, Harrison and Storkey, Amos.
\newblock Towards a neural statistician.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{linear}
Goodfellow, Ian~J, Shlens, Jonathon, and Szegedy, Christian.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2015.

\bibitem[Ha et~al.(2017)Ha, Dai, and Le]{hypernets}
Ha, David, Dai, Andrew, and Le, Quoc~V.
\newblock Hypernetworks.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2017.

\bibitem[Hochreiter et~al.(2001)Hochreiter, Younger, and Conwell]{hochreiter}
Hochreiter, Sepp, Younger, A~Steven, and Conwell, Peter~R.
\newblock Learning to learn using gradient descent.
\newblock In \emph{International Conference on Artificial Neural Networks}.
  Springer, 2001.

\bibitem[Husken \& Goerick(2000)Husken and Goerick]{husken}
Husken, Michael and Goerick, Christian.
\newblock Fast learning for problem classes using knowledge based network
  initialization.
\newblock In \emph{Neural Networks, 2000. IJCNN 2000, Proceedings of the
  IEEE-INNS-ENNS International Joint Conference on}, volume~6, pp.\  619--624.
  IEEE, 2000.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{batchnorm}
Ioffe, Sergey and Szegedy, Christian.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Kaiser et~al.(2017)Kaiser, Nachum, Roy, and Bengio]{rareevents}
Kaiser, Lukasz, Nachum, Ofir, Roy, Aurko, and Bengio, Samy.
\newblock Learning to remember rare events.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2017.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{adam}
Kingma, Diederik and Ba, Jimmy.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2015.

\bibitem[Kirkpatrick et~al.(2016)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska,
  et~al.]{forgetting}
Kirkpatrick, James, Pascanu, Razvan, Rabinowitz, Neil, Veness, Joel,
  Desjardins, Guillaume, Rusu, Andrei~A, Milan, Kieran, Quan, John, Ramalho,
  Tiago, Grabska-Barwinska, Agnieszka, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{arXiv preprint arXiv:1612.00796}, 2016.

\bibitem[Koch(2015)]{siameseoneshot}
Koch, Gregory.
\newblock Siamese neural networks for one-shot image recognition.
\newblock \emph{ICML Deep Learning Workshop}, 2015.

\bibitem[Kr{\"a}henb{\"u}hl et~al.(2016)Kr{\"a}henb{\"u}hl, Doersch, Donahue,
  and Darrell]{datadependentinit}
Kr{\"a}henb{\"u}hl, Philipp, Doersch, Carl, Donahue, Jeff, and Darrell, Trevor.
\newblock Data-dependent initializations of convolutional neural networks.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2016.

\bibitem[Lake et~al.(2011)Lake, Salakhutdinov, Gross, and Tenenbaum]{omniglot}
Lake, Brenden~M, Salakhutdinov, Ruslan, Gross, Jason, and Tenenbaum, Joshua~B.
\newblock One shot learning of simple visual concepts.
\newblock In \emph{Conference of the Cognitive Science Society (CogSci)}, 2011.

\bibitem[Li \& Malik(2017)Li and Malik]{learntooptimize}
Li, Ke and Malik, Jitendra.
\newblock Learning to optimize.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2017.

\bibitem[Maclaurin et~al.(2015)Maclaurin, Duvenaud, and Adams]{maclaurin}
Maclaurin, Dougal, Duvenaud, David, and Adams, Ryan.
\newblock Gradient-based hyperparameter optimization through reversible
  learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Munkhdalai \& Yu(2017)Munkhdalai and Yu]{metanets}
Munkhdalai, Tsendsuren and Yu, Hong.
\newblock Meta networks.
\newblock \emph{International Conferecence on Machine Learning (ICML)}, 2017.

\bibitem[Naik \& Mammone(1992)Naik and Mammone]{naik}
Naik, Devang~K and Mammone, RJ.
\newblock Meta-neural networks that learn by learning.
\newblock In \emph{International Joint Conference on Neural Netowrks (IJCNN)},
  1992.

\bibitem[Parisotto et~al.(2016)Parisotto, Ba, and Salakhutdinov]{actormimic}
Parisotto, Emilio, Ba, Jimmy~Lei, and Salakhutdinov, Ruslan.
\newblock Actor-mimic: Deep multitask and transfer reinforcement learning.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2016.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{hugo}
Ravi, Sachin and Larochelle, Hugo.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Rei(2015)]{rei}
Rei, Marek.
\newblock Online representation learning in recurrent neural language models.
\newblock \emph{arXiv preprint arXiv:1508.03854}, 2015.

\bibitem[Rezende et~al.(2016)Rezende, Mohamed, Danihelka, Gregor, and
  Wierstra]{oneshotgenicml}
Rezende, Danilo~Jimenez, Mohamed, Shakir, Danihelka, Ivo, Gregor, Karol, and
  Wierstra, Daan.
\newblock One-shot generalization in deep generative models.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Salimans \& Kingma(2016)Salimans and Kingma]{weightnorm}
Salimans, Tim and Kingma, Diederik~P.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2016.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lillicrap]{mann}
Santoro, Adam, Bartunov, Sergey, Botvinick, Matthew, Wierstra, Daan, and
  Lillicrap, Timothy.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Saxe et~al.(2014)Saxe, McClelland, and Ganguli]{orthogonal}
Saxe, Andrew, McClelland, James, and Ganguli, Surya.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear
  neural networks.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2014.

\bibitem[Schmidhuber(1987)]{schmidhuber1987}
Schmidhuber, Jurgen.
\newblock Evolutionary principles in self-referential learning.
\newblock \emph{On learning how to learn: The meta-meta-... hook.) Diploma
  thesis, Institut f. Informatik, Tech. Univ. Munich}, 1987.

\bibitem[Schmidhuber(1992)]{schmidfastweights}
Schmidhuber, J{\"u}rgen.
\newblock Learning to control fast-weight memories: An alternative to dynamic
  recurrent networks.
\newblock \emph{Neural Computation}, 1992.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{trpo}
Schulman, John, Levine, Sergey, Abbeel, Pieter, Jordan, Michael~I, and Moritz,
  Philipp.
\newblock Trust region policy optimization.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Shyam et~al.(2017)Shyam, Gupta, and Dukkipati]{comparators}
Shyam, Pranav, Gupta, Shubham, and Dukkipati, Ambedkar.
\newblock Attentive recurrent comparators.
\newblock \emph{International Conferecence on Machine Learning (ICML)}, 2017.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{prototypical}
Snell, Jake, Swersky, Kevin, and Zemel, Richard~S.
\newblock Prototypical networks for few-shot learning.
\newblock \emph{arXiv preprint arXiv:1703.05175}, 2017.

\bibitem[Thrun \& Pratt(1998)Thrun and Pratt]{thrun}
Thrun, Sebastian and Pratt, Lorien.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Todorov, Emanuel, Erez, Tom, and Tassa, Yuval.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  (IROS)}, 2012.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{matchingnets}
Vinyals, Oriol, Blundell, Charles, Lillicrap, Tim, Wierstra, Daan, et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2016.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{learningrl}
Wang, Jane~X, Kurth-Nelson, Zeb, Tirumala, Dhruva, Soyer, Hubert, Leibo,
  Joel~Z, Munos, Remi, Blundell, Charles, Kumaran, Dharshan, and Botvinick,
  Matt.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Williams(1992)]{reinforce}
Williams, Ronald~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\end{thebibliography}
