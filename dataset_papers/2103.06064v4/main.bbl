\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrews \& Mallows(1974)Andrews and Mallows]{andrews1974scale}
Andrews, D. and Mallows, C.
\newblock Scale mixtures of normal distributions.
\newblock \emph{J. Royal Statistical Society: Series B}, 36\penalty0 (1), 1974.

\bibitem[Axelsson(1996)]{axelsson1996iterative}
Axelsson, O.
\newblock \emph{Iterative Solution Methods}.
\newblock Cambridge University Press, 1996.

\bibitem[Batson et~al.(2012)Batson, Spielman, and Srivastava]{batson2012twice}
Batson, J., Spielman, D.~A., and Srivastava, N.
\newblock Twice-{R}amanujan sparsifiers.
\newblock \emph{SIAM Journal on Computing}, 41\penalty0 (6):\penalty0
  1704--1721, 2012.

\bibitem[Bubeck(2014)]{bubeck2014convex}
Bubeck, S.
\newblock Convex optimization: {A}lgorithms and complexity.
\newblock \emph{Foundations and Trends in Machine Learning}, 2014.

\bibitem[Chartrand \& Yin(2008)Chartrand and Yin]{Chartrand08}
Chartrand, R. and Yin, W.
\newblock Iteratively reweighted algorithms for compressive sensing.
\newblock \emph{International Conference on Accoustics, Speech, and Signal
  Processing}, 2008.

\bibitem[Chen et~al.(2018{\natexlab{a}})Chen, Ma, and Xiao]{chen2018fastgcn}
Chen, J., Ma, T., and Xiao, C.
\newblock Fast{GCN}: {F}ast learning with graph convolutional networks via
  importance sampling.
\newblock \emph{International Conference on Learning Representations},
  2018{\natexlab{a}}.

\bibitem[Chen et~al.(2018{\natexlab{b}})Chen, Zhu, and
  Song]{chen2018stochastic}
Chen, J., Zhu, J., and Song, L.
\newblock Stochastic training of graph convolutional networks with variance
  reduction.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  942--950, 2018{\natexlab{b}}.

\bibitem[Chen et~al.(2020)Chen, Wei, Huang, Ding, and
  Li]{DBLP:conf/icml/ChenWHDL20}
Chen, M., Wei, Z., Huang, Z., Ding, B., and Li, Y.
\newblock Simple and deep graph convolutional networks.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML}}, volume 119, pp.\  1725--1735, 2020.

\bibitem[Chen et~al.(2017)Chen, Ge, Wang, Wang, Ye, and Yin]{chen2017strong}
Chen, Y., Ge, D., Wang, M., Wang, Z., Ye, Y., and Yin, H.
\newblock Strong {NP}-hardness for sparse optimization with concave penalty
  functions.
\newblock In \emph{International Confernece on Machine Learning}, 2017.

\bibitem[Combettes \& Pesquet(2011)Combettes and
  Pesquet]{combettes2011proximal}
Combettes, P.~L. and Pesquet, J.-C.
\newblock Proximal splitting methods in signal processing.
\newblock In \emph{Fixed-point algorithms for inverse problems in science and
  engineering}, pp.\  185--212. Springer, 2011.

\bibitem[Dai et~al.(2018)Dai, Kozareva, Dai, Smola, and Song]{DaiKDSS18}
Dai, H., Kozareva, Z., Dai, B., Smola, A., and Song, L.
\newblock Learning steady-states of iterative algorithms over graphs.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1106--1114, 2018.

\bibitem[Daubechies et~al.(2010)Daubechies, DeVore, Fornasier, and
  G{\"u}nt{\"u}rk]{daubechies2010iteratively}
Daubechies, I., DeVore, R., Fornasier, M., and G{\"u}nt{\"u}rk, C.~S.
\newblock Iteratively reweighted least squares minimization for sparse
  recovery.
\newblock \emph{Communications on Pure and Applied Mathematics}, 63\penalty0
  (1), 2010.

\bibitem[Emerson(2005)]{DBLP:conf/acl-sighan/Emerson05}
Emerson, T.
\newblock The second international chinese word segmentation bakeoff.
\newblock In \emph{Proceedings of the Fourth {SIGHAN} Workshop on Chinese
  Language Processing, SIGHAN@IJCNLP}, 2005.

\bibitem[Entezari et~al.(2020)Entezari, Al-Sayouri, Darvishzadeh, and
  Papalexakis]{EntezariADP20}
Entezari, N., Al-Sayouri, S.~A., Darvishzadeh, A., and Papalexakis, E.~E.
\newblock All you need is low (rank) defending against adversarial attacks on
  graphs.
\newblock In \emph{Proceedings of the 13th International Conference on Web
  Search and Data Mining}, pp.\  169--177, 2020.

\bibitem[Geng et~al.(2021)Geng, Guo, Chen, Li, Wei, and
  Lin]{DBLP:conf/iclr/GengGCLWL21}
Geng, Z., Guo, M., Chen, H., Li, X., Wei, K., and Lin, Z.
\newblock Is attention better than matrix decomposition?
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}, 2021.

\bibitem[Gregor \& LeCun(2010)Gregor and LeCun]{gregor2010learning}
Gregor, K. and LeCun, Y.
\newblock Learning fast approximations of sparse coding.
\newblock In \emph{International Conference on Machine Learning}, 2010.

\bibitem[Gu et~al.(2020)Gu, Chang, Zhu, Sojoudi, and Ghaoui]{GuC0SG20}
Gu, F., Chang, H., Zhu, W., Sojoudi, S., and Ghaoui, L.~E.
\newblock Implicit graph neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems, NeurIPS},
  2020.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and Leskovec]{HamiltonYL17}
Hamilton, W.~L., Ying, R., and Leskovec, J.
\newblock Inductive representation learning on large graphs.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pp.\  1025--1035, 2017.

\bibitem[Hershey et~al.(2014)Hershey, Roux, and Weninger]{hershey2014deep}
Hershey, J., Roux, J.~L., and Weninger, F.
\newblock Deep unfolding: {M}odel-based inspiration of novel deep
  architectures.
\newblock \emph{ar{X}iv preprint ar{X}iv:1409.2574}, 2014.

\bibitem[Hu et~al.(2020)Hu, Fey, Zitnik, Dong, Ren, Liu, Catasta, and
  Leskovec]{HuFZDRLCL20}
Hu, W., Fey, M., Zitnik, M., Dong, Y., Ren, H., Liu, B., Catasta, M., and
  Leskovec, J.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock 2020.

\bibitem[Hunter \& Lange(2004)Hunter and Lange]{hunter2004tutorial}
Hunter, D.~R. and Lange, K.
\newblock A tutorial on {MM} algorithms.
\newblock \emph{The American Statistician}, 58\penalty0 (1), 2004.

\bibitem[Jia \& Benson(2020)Jia and Benson]{jia2020residual}
Jia, J. and Benson, A.~R.
\newblock Residual correlation in graph neural network regression.
\newblock In \emph{International Conference on Knowledge Discovery \& Data
  Mining}, 2020.

\bibitem[Kearnes et~al.(2016)Kearnes, McCloskey, Berndl, Pande, and
  Riley]{DBLP:journals/jcamd/KearnesMBPR16}
Kearnes, S.~M., McCloskey, K., Berndl, M., Pande, V.~S., and Riley, P.
\newblock Molecular graph convolutions: moving beyond fingerprints.
\newblock \emph{J. Comput. Aided Mol. Des.}, 30\penalty0 (8):\penalty0
  595--608, 2016.

\bibitem[Kipf \& Welling(2017{\natexlab{a}})Kipf and Welling]{kipf2017semi}
Kipf, T. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations},
  2017{\natexlab{a}}.

\bibitem[Kipf \& Welling(2017{\natexlab{b}})Kipf and
  Welling]{DBLP:conf/iclr/KipfW17}
Kipf, T.~N. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR}}, 2017{\natexlab{b}}.

\bibitem[Klicpera et~al.(2019)Klicpera, Bojchevski, and
  G{\"u}nnemann]{klicpera2019predict}
Klicpera, J., Bojchevski, A., and G{\"u}nnemann, S.
\newblock Predict then propagate: {G}raph neural networks meet personalized
  pagerank.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Lee et~al.(2019)Lee, Rossi, Kim, Ahmed, and Koh]{lee2019attention}
Lee, J.~B., Rossi, R., Kim, S., Ahmed, N., and Koh, E.
\newblock Attention models in graphs: A survey.
\newblock \emph{ACM Trans. Knowledge Discovery from Data}, 13\penalty0 (6),
  2019.

\bibitem[Lee \& Sun(2017)Lee and Sun]{lee2017sdp}
Lee, Y.~T. and Sun, H.
\newblock An sdp-based algorithm for linear-sized spectral sparsification.
\newblock In \emph{Proc. ACM Symposium on Theory of Computing}, pp.\  678--687,
  2017.

\bibitem[Li et~al.(2019)Li, Muller, Thabet, and Ghanem]{DBLP:conf/iccv/Li0TG19}
Li, G., Muller, M., Thabet, A., and Ghanem, B.
\newblock Deepgcns: Can gcns go as deep as cnns?
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9267--9276, 2019.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Xiong, Thabet, and
  Ghanem]{li2020deepergcn}
Li, G., Xiong, C., Thabet, A., and Ghanem, B.
\newblock Deepergcn: All you need to train deeper gcns.
\newblock \emph{arXiv preprint arXiv:2006.07739}, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2018)Li, Han, and Wu]{DBLP:conf/aaai/LiHW18}
Li, Q., Han, Z., and Wu, X.-M.
\newblock Deeper insights into graph convolutional networks for semi-supervised
  learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Jin, Xu, and Tang]{abs-2005-06149}
Li, Y., Jin, W., Xu, H., and Tang, J.
\newblock Deeprobust: A pytorch library for adversarial attacks and defenses.
\newblock \emph{arXiv preprint arXiv:2005.06149}, 2020{\natexlab{b}}.

\bibitem[Liu et~al.(2020)Liu, Gao, and Ji]{LiuGJ20}
Liu, M., Gao, H., and Ji, S.
\newblock Towards deeper graph neural networks.
\newblock In \emph{Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  338--348, 2020.

\bibitem[Ma et~al.(2020)Ma, Liu, Zhao, Liu, Tang, and Shah]{ma2020unified}
Ma, Y., Liu, X., Zhao, T., Liu, Y., Tang, J., and Shah, N.
\newblock A unified view on graph neural networks as graph signal denoising.
\newblock \emph{arXiv preprint arXiv:2010.01777}, 2020.

\bibitem[Nocedal \& Wright(2006)Nocedal and Wright]{nocedal2006numerical}
Nocedal, J. and Wright, S.
\newblock \emph{Numerical optimization}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[Oono \& Suzuki(2020)Oono and Suzuki]{DBLP:conf/iclr/OonoS20}
Oono, K. and Suzuki, T.
\newblock Graph neural networks exponentially lose expressive power for node
  classification.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR}}, 2020.

\bibitem[Palmer et~al.(2006)Palmer, Wipf, Kreutz-Delgado, and
  Rao]{palmer2006variational}
Palmer, J., Wipf, D., Kreutz-Delgado, K., and Rao, B.
\newblock Variational {EM} algorithms for non-{G}aussian latent variable
  models.
\newblock \emph{Advances in Neural Information Processing Systems}, 2006.

\bibitem[Pan et~al.(2021)Pan, Song, and Huang]{pan2021a}
Pan, X., Song, S., and Huang, G.
\newblock A unified framework for convolution-based graph neural networks,
  2021.
\newblock URL \url{https://openreview.net/forum?id=zUMD--Fb9Bt}.

\bibitem[Pei et~al.(2019)Pei, Wei, Chang, Lei, and Yang]{PeiWCLY20}
Pei, H., Wei, B., Chang, K. C.-C., Lei, Y., and Yang, B.
\newblock Geom-gcn: Geometric graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Rockafellar(1970)]{Rockafellar70}
Rockafellar, R.~T.
\newblock \emph{Convex Analysis}.
\newblock Princeton University Press, 1970.

\bibitem[Rong et~al.(2019)Rong, Huang, Xu, and Huang]{rong2019dropedge}
Rong, Y., Huang, W., Xu, T., and Huang, J.
\newblock Dropedge: Towards deep graph convolutional networks on node
  classification.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Rong et~al.(2020)Rong, Huang, Xu, and Huang]{DBLP:conf/iclr/RongHXH20}
Rong, Y., Huang, W., Xu, T., and Huang, J.
\newblock Dropedge: Towards deep graph convolutional networks on node
  classification.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR}}, 2020.

\bibitem[Sen et~al.(2008)Sen, Namata, Bilgic, Getoor, Galligher, and
  Eliassi-Rad]{DBLP:journals/aim/SenNBGGE08}
Sen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., and Eliassi-Rad, T.
\newblock Collective classification in network data.
\newblock \emph{AI magazine}, 29\penalty0 (3):\penalty0 93--93, 2008.

\bibitem[Sprechmann et~al.(2015)Sprechmann, Bronstein, and
  Sapiro]{Sprechmann15}
Sprechmann, P., Bronstein, A., and Sapiro, G.
\newblock Learning efficient sparse and low rank models.
\newblock \emph{IEEE Trans. Pattern Analysis and Machine Intelligence},
  37\penalty0 (9), 2015.

\bibitem[Tang et~al.(2009)Tang, Sun, Wang, and Yang]{tang2009social}
Tang, J., Sun, J., Wang, C., and Yang, Z.
\newblock Social influence analysis in large-scale networks.
\newblock In \emph{Proceedings of the 15th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  807--816, 2009.

\bibitem[Thekumparampil et~al.(2018)Thekumparampil, Wang, Oh, and
  Li]{thekumparampil2018attention}
Thekumparampil, K., Wang, C., Oh, S., and Li, L.-J.
\newblock Attention-based graph neural network for semi-supervised learning.
\newblock \emph{ar{X}iv preprint ar{X}iv:1803.03735}, 2018.

\bibitem[Velickovic et~al.(2018)Velickovic, Cucurull, Casanova, Romero,
  Li{\`{o}}, and Bengio]{VelickovicCCRLB18}
Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Li{\`{o}}, P., and
  Bengio, Y.
\newblock Graph attention networks.
\newblock In \emph{6th International Conference on Learning Representations,
  {ICLR}}, 2018.

\bibitem[Veli{\v{c}}kovi{\'c} et~al.(2020)Veli{\v{c}}kovi{\'c}, Ying, Padovano,
  Hadsell, and Blundell]{velivckovic2019neural}
Veli{\v{c}}kovi{\'c}, P., Ying, R., Padovano, M., Hadsell, R., and Blundell, C.
\newblock Neural execution of graph algorithms.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Wang et~al.(2019)Wang, Zheng, Ye, Gan, Li, Song, Zhou, Ma, Yu, Gai,
  Xiao, He, Karypis, Li, and Zhang]{wang2019dgl}
Wang, M., Zheng, D., Ye, Z., Gan, Q., Li, M., Song, X., Zhou, J., Ma, C., Yu,
  L., Gai, Y., Xiao, T., He, T., Karypis, G., Li, J., and Zhang, Z.
\newblock Deep graph library: A graph-centric, highly-performant package for
  graph neural networks.
\newblock \emph{arXiv preprint arXiv:1909.01315}, 2019.

\bibitem[Wang et~al.(2016)Wang, Ling, and Huang]{wang2016learning}
Wang, Z., Ling, Q., and Huang, T.
\newblock Learning deep $\ell_0$ encoders.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, volume~30,
  2016.

\bibitem[West(1984)]{west1984outlier}
West, M.
\newblock Outlier models and prior distributions in {B}ayesian linear
  regression.
\newblock \emph{J. Royal Statistical Society: Series B}, 46\penalty0 (3), 1984.

\bibitem[Widder(2015)]{widder2015laplace}
Widder, D.~V.
\newblock \emph{The Laplace Transform}.
\newblock Princeton university press, 2015.

\bibitem[Wilansky(2013)]{wilansky2013modern}
Wilansky, A.
\newblock \emph{Modern methods in topological vector spaces}.
\newblock Dover Publications, Inc., 2013.

\bibitem[Wu et~al.(2019{\natexlab{a}})Wu, Souza, Zhang, Fifty, Yu, and
  Weinberger]{wu2019simplifying}
Wu, F., Souza, A., Zhang, T., Fifty, C., Yu, T., and Weinberger, K.
\newblock Simplifying graph convolutional networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6861--6871, 2019{\natexlab{a}}.

\bibitem[Wu et~al.(2019{\natexlab{b}})Wu, Wang, Tyshetskiy, Docherty, Lu, and
  Zhu]{Wu0TDLZ19}
Wu, H., Wang, C., Tyshetskiy, Y., Docherty, A., Lu, K., and Zhu, L.
\newblock Adversarial examples for graph data: Deep insights into attack and
  defense.
\newblock In \emph{Proceedings of the Twenty-Eighth International Joint
  Conference on Artificial Intelligence, {IJCAI}}, pp.\  4816--4823,
  2019{\natexlab{b}}.

\bibitem[Xu et~al.(2018)Xu, Li, Tian, Sonobe, Kawarabayashi, and
  Jegelka]{DBLP:conf/icml/XuLTSKJ18}
Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K., and Jegelka, S.
\newblock Representation learning on graphs with jumping knowledge networks.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML}}, volume~80, pp.\  5449--5458, 2018.

\bibitem[Yang et~al.(2021)Yang, Wang, Huang, and
  Wipf]{DBLP:journals/corr/abs-2111-06592}
Yang, Y., Wang, Y., Huang, Z., and Wipf, D.
\newblock Implicit vs unfolded graph neural networks.
\newblock \emph{arXiv preprint arXiv:2111.06592}, 2021.

\bibitem[Yang et~al.(2016)Yang, Cohen, and
  Salakhudinov]{DBLP:conf/icml/YangCS16}
Yang, Z., Cohen, W., and Salakhudinov, R.
\newblock Revisiting semi-supervised learning with graph embeddings.
\newblock In \emph{International Conference on Machine Learning}, pp.\  40--48,
  2016.

\bibitem[Zhang et~al.(2020)Zhang, Yan, Xie, Xia, and Zhang]{thatpaper}
Zhang, H., Yan, T., Xie, Z., Xia, Y., and Zhang, Y.
\newblock Revisiting graph convolutional network on semi-supervised node
  classification from an optimization perspective.
\newblock \emph{arXiv preprint arXiv:2009.11469}, 2020.

\bibitem[Zhang \& Zitnik(2020)Zhang and Zitnik]{ZhangZ20}
Zhang, X. and Zitnik, M.
\newblock Gnnguard: Defending graph neural networks against adversarial
  attacks.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Zhou et~al.(2004)Zhou, Bousquet, Lal, Weston, and
  Sch{\"o}lkopf]{zhou2004learning}
Zhou, D., Bousquet, O., Lal, T.~N., Weston, J., and Sch{\"o}lkopf, B.
\newblock Learning with local and global consistency.
\newblock \emph{Advances in Neural Information Processing Systems}, 2004.

\bibitem[Zhou et~al.(2018)Zhou, Cui, Zhang, Yang, Liu, Wang, Li, and
  Sun]{DBLP:journals/corr/abs-1812-08434}
Zhou, J., Cui, G., Zhang, Z., Yang, C., Liu, Z., Wang, L., Li, C., and Sun, M.
\newblock Graph neural networks: A review of methods and applications.
\newblock \emph{arXiv preprint arXiv:1812.08434}, 2018.

\bibitem[Zhu et~al.(2019)Zhu, Zhang, Cui, and Zhu]{zhu2019robust}
Zhu, D., Zhang, Z., Cui, P., and Zhu, W.
\newblock Robust graph convolutional networks against adversarial attacks.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  1399--1407, 2019.

\bibitem[Zhu et~al.(2020{\natexlab{a}})Zhu, Rossi, Rao, Mai, Lipka, Ahmed, and
  Koutra]{DBLP:journals/corr/abs-2009-13566}
Zhu, J., Rossi, R.~A., Rao, A., Mai, T., Lipka, N., Ahmed, N.~K., and Koutra,
  D.
\newblock Graph neural networks with heterophily.
\newblock \emph{arXiv preprint arXiv:2009.13566}, 2020{\natexlab{a}}.

\bibitem[Zhu et~al.(2020{\natexlab{b}})Zhu, Yan, Zhao, Heimann, Akoglu, and
  Koutra]{DBLP:conf/nips/ZhuYZHAK20}
Zhu, J., Yan, Y., Zhao, L., Heimann, M., Akoglu, L., and Koutra, D.
\newblock Beyond homophily in graph neural networks: Current limitations and
  effective designs.
\newblock In \emph{Advances in Neural Information Processing Systems, NeurIPS},
  2020{\natexlab{b}}.

\bibitem[Zhu et~al.(2021)Zhu, Wang, Shi, Ji, and Cui]{zhu2021interpreting}
Zhu, M., Wang, X., Shi, C., Ji, H., and Cui, P.
\newblock Interpreting and unifying graph neural networks with an optimization
  framework.
\newblock \emph{arXiv preprint arXiv:2101.11859}, 2021.

\bibitem[Z{\"{u}}gner \& G{\"{u}}nnemann(2019)Z{\"{u}}gner and
  G{\"{u}}nnemann]{DBLP:conf/iclr/ZugnerG19}
Z{\"{u}}gner, D. and G{\"{u}}nnemann, S.
\newblock Adversarial attacks on graph neural networks via meta learning.
\newblock In \emph{7th International Conference on Learning Representations,
  {ICLR}}, 2019.

\bibitem[Z{\"{u}}gner et~al.(2019)Z{\"{u}}gner, Akbarnejad, and
  G{\"{u}}nnemann]{DBLP:conf/ijcai/ZugnerAG19}
Z{\"{u}}gner, D., Akbarnejad, A., and G{\"{u}}nnemann, S.
\newblock Adversarial attacks on neural networks for graph data.
\newblock In \emph{Proceedings of the Twenty-Eighth International Joint
  Conference on Artificial Intelligence, {IJCAI}}, 2019.

\end{thebibliography}
