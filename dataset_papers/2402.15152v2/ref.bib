@article{foret2020sharpness,
  title={Sharpness-aware minimization for efficiently improving generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.01412},
  year={2020}
}

@article{Laurent2000AdaptiveEO,
  title={Adaptive estimation of a quadratic functional by model selection},
  author={B{\'e}atrice Laurent and Pascal Massart},
  journal={Annals of Statistics},
  year={2000},
  volume={28},
  pages={1302-1338}
}

@article{wong2020fast,
  title={Fast is better than free: Revisiting adversarial training},
  author={Wong, Eric and Rice, Leslie and Kolter, J Zico},
  journal={arXiv preprint arXiv:2001.03994},
  year={2020}
}

@inproceedings{chen2022bootstrap,
  title={Bootstrap Generalization Ability from Loss Landscape Perspective},
  author={Chen, Huanran and Shao, Shitong and Wang, Ziyi and Shang, Zirui and Chen, Jin and Ji, Xiaofeng and Wu, Xinxiao},
  booktitle={European Conference on Computer Vision},
  pages={500--517},
  year={2022},
  organization={Springer}
}

@inproceedings{Ilyas2019AdversarialEA,
  title={Adversarial Examples Are Not Bugs, They Are Features},
  author={Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran and Aleksander Madry},
  booktitle={NeurIPS},
  year={2019}
}

@article{hochreiter1994simplifying,
  title={Simplifying neural nets by discovering flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={NeurIPS},
  year={1994}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997},
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{neyshabur2017exploring,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@article{dziugaite2017computing,
  title={Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data},
  author={Dziugaite, Gintare Karolina and Roy, Daniel M},
  journal={arXiv preprint arXiv:1703.11008},
  year={2017}
}

@inproceedings{dinh2017sharp,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={1019--1028},
  year={2017},
  organization={PMLR}
}
@inproceedings{McAllester1999PACBayesianMA,
  title={PAC-Bayesian model averaging},
  author={David A. McAllester},
  booktitle={Annual Conference Computational Learning Theory},
  year={1999}
}
@article{jiang2019fantastic,
  title={Fantastic generalization measures and where to find them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}

@article{chaudhari2019entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  year={2019},
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@inproceedings{andriushchenko2022towards,
  title={Towards understanding sharpness-aware minimization},
  author={Andriushchenko, Maksym and Flammarion, Nicolas},
  booktitle={ICML},
  year={2022},
}

@article{zhuang2022surrogate,
  title={Surrogate gap minimization improves sharpness-aware training},
  author={Zhuang, Juntang and Gong, Boqing and Yuan, Liangzhe and Cui, Yin and Adam, Hartwig and Dvornek, Nicha and Tatikonda, Sekhar and Duncan, James and Liu, Ting},
  journal={arXiv preprint arXiv:2203.08065},
  year={2022}
}

@article{wen2022does,
  title={How Does Sharpness-Aware Minimization Minimize Sharpness?},
  author={Wen, Kaiyue and Ma, Tengyu and Li, Zhiyuan},
  journal={arXiv preprint arXiv:2211.05729},
  year={2022}
}

@article{bahri2021sharpness,
  title={Sharpness-aware minimization improves language model generalization},
  author={Bahri, Dara and Mobahi, Hossein and Tay, Yi},
  journal={arXiv preprint arXiv:2110.08529},
  year={2021}
}

@article{jetly2022splash,
  title={Splash in a Flash: Sharpness-aware minimization for efficient liquid splash simulation},
  author={Jetly, Vishrut and Ibayashi, Hikaru and Nakano, Aiichiro},
  year={2022},
  publisher={The Eurographics Association}
}

@inproceedings{kwon2021asam,
  title={Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks},
  author={Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon},
  booktitle={ICML},
  year={2021},
}

@article{du2021efficient,
  title={Efficient sharpness-aware minimization for improved training of neural networks},
  author={Du, Jiawei and Yan, Hanshu and Feng, Jiashi and Zhou, Joey Tianyi and Zhen, Liangli and Goh, Rick Siow Mong and Tan, Vincent YF},
  journal={arXiv preprint arXiv:2110.03141},
  year={2021}
}

@inproceedings{liu2022towards,
  title={Towards efficient and scalable sharpness-aware minimization},
  author={Liu, Yong and Mai, Siqi and Chen, Xiangning and Hsieh, Cho-Jui and You, Yang},
  booktitle={CVPR},
  year={2022}
}

@article{mi2022make,
  title={Make sharpness-aware minimization stronger: A sparsified perturbation approach},
  author={Mi, Peng and Shen, Li and Ren, Tianhe and Zhou, Yiyi and Sun, Xiaoshuai and Ji, Rongrong and Tao, Dacheng},
  journal={arXiv preprint arXiv:2210.05177},
  year={2022}
}

@inproceedings{kim2022fisher,
  title={Fisher sam: Information geometry and sharpness aware minimisation},
  author={Kim, Minyoung and Li, Da and Hu, Shell X and Hospedales, Timothy},
  booktitle={ICML},
  year={2022},
}

@article{zhong2022improving,
  title={Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models},
  author={Zhong, Qihuang and Ding, Liang and Shen, Li and Mi, Peng and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2210.05497},
  year={2022}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={ECCV},
  year={2016},
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{pang2020bag,
  title={Bag of tricks for adversarial training},
  author={Pang, Tianyu and Yang, Xiao and Dong, Yinpeng and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2010.00467},
  year={2020}
}
@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@article{ma2019understanding,
                          title={Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems},
                          author={Ma, Xingjun and Niu, Yuhao and Gu, Lin and Wang, Yisen and Zhao, Yitian and Bailey, James and Lu, Feng},
                          journal={Pattern Recognition},
                          year={2020}}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={ICML},
  year={2018},
}                          
@inproceedings{wu2020adversarial,
                        title={Adversarial Weight Perturbation Helps Robust Generalization},
                        author={Wu, Dongxian and Xia, Shu-Tao and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2020}}

@inproceedings{wang2019dynamic,
                        title={On the Convergence and Robustness of Adversarial Training},
                        author={Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou, Bowen and Gu, Quanquan},
                        booktitle={ICML},
                        year={2019}}                    
                        @inproceedings{wang2020improving,
                      title={Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
                      author={Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
                      booktitle={ICLR},
                      year={2020}}
@inproceedings{bai2021improving,
                        title={Improving adversarial robustness via channel-wise activation suppressing},
                        author={Bai, Yang and Zeng, Yuyuan and Jiang, Yong and Xia, Shu-Tao and Ma, Xingjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2021}}                      

 @inproceedings{tian2021analysis,
                        title={Analysis and Applications of Class-wise Robustness in Adversarial Training},
                        author={Tian, Qi and Kuang, Kun and Jiang, Kelu and Wu, Fei and Wang, Yisen},
                        booktitle={KDD},
                        year={2021}}                        
                        @inproceedings{huang2021exploring,
                      title={Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks},
                      author={Huang, Hanxun and Wang, Yisen and Erfani, Sarah Monazam and Gu, Quanquan and Bailey, James and Ma, Xingjun},
                      booktitle={NeurIPS},
                      year={2021}}

@inproceedings{bai2021clustering,
                        title={Clustering Effect of (Linearized) Adversarial Robust Models},
                        author={Bai, Yang and Yan, Xin and Jiang, Yong and Xia, Shu-Tao and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2021}}

                        @inproceedings{mo2022adversarial,
                      title={When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture},
                      author={Mo, Yichuan and Wu, Dongxian and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2022}}

                @inproceedings{wang2022self,
                        title={Self-Ensemble Adversarial Training for Improved Robustness},
                        author={Wang, Hongjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2022}}
@inproceedings{wang2022unified,
                        title={A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training},
                        author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={ICLR},
                        year={2022}}                      @inproceedings{ren2021unified,
                        title={A unified game-theoretic interpretation of adversarial robustness},
                        author={Ren, Jie and Zhang, Die and Wang, Yisen and Chen, Lu and Zhou, Zhanpeng and Chen, Yiting and Cheng, Xu and Wang, Xin and Zhou, Meng and Shi, Jie and others},
                        booktitle={NeurIPS},
                        year={2021}}  
@inproceedings{wang2021demystifying,
                        title={Demystifying adversarial training via a unified probabilistic framework},
                        author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
                        booktitle={ICML 2021 Workshop on Adversarial Machine Learning},
                        year={2021}}                      @inproceedings{wang2021unified,
                          title={A unified approach to interpreting and boosting adversarial transferability},
                          author={Wang, Xin and Ren, Jie and Lin, Shuyun and Zhu, Xiangming and Wang, Yisen and Zhang, Quanshi},
                          booktitle={ICLR},
                          year={2021}}  

                          @inproceedings{ma2018characterizing,
                        title={Characterizing adversarial subspaces using local intrinsic dimensionality},
                        author={Ma, Xingjun and Li, Bo and Wang, Yisen and Erfani, Sarah M and Wijewickrema, Sudanthi and Schoenebeck, Grant and Song, Dawn and Houle, Michael E and Bailey, James},
                        booktitle={ICLR},
                        year={2018}}
@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={ICML},
  year={2019},
}                    

@InProceedings{pmlr-v129-wu20a,
  title = 	 {Towards Understanding and Improving the Transferability of Adversarial Examples in Deep Neural Networks},
  author =       {Wu, Lei and Zhu, Zhanxing},
  booktitle = 	 {Proceedings of The 12th Asian Conference on Machine Learning},
  pages = 	 {837--850},
  year = 	 {2020},
  editor = 	 {Pan, Sinno Jialin and Sugiyama, Masashi},
  volume = 	 {129},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--20 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v129/wu20a/wu20a.pdf},
  url = 	 {https://proceedings.mlr.press/v129/wu20a.html},
  abstract = 	 {Currently it is well known that deep neural networks are vulnerable to adversarial examples, constructed by applying small but malicious perturbations to the original inputs. Moreover, the perturbed inputs can transfer between different models: adversarial examples generated based on a specific model will often fool other unseen models with a significant success rate. This allows the adversary to leverage it to attack the deployed systems without any query, which could raise severe security issue particularly in safety-critical scenarios. In this work, we empirically investigate two classes of factors that might influence the transferability of adversarial examples. One is about model-specific factors, including network architecture, model capacity and test accuracy. The other is the local smoothness of loss surface for generating adversarial examples. More importantly, relying on these findings on the transferability of adversarial examples, we propose a simple but effective strategy to improve the transferability, whose effectiveness is confirmed through extensive experiments on both CIFAR-10 and ImageNet datasets.}
}

@article{https://doi.org/10.48550/arxiv.1706.10239,
  doi = {10.48550/ARXIV.1706.10239},
  
  url = {https://arxiv.org/abs/1706.10239},
  
  author = {Wu, Lei and Zhu, Zhanxing and E, Weinan},

  title = {Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {Creative Commons Zero v1.0 Universal}
}

@inproceedings{wei2023cfa,
title={CFA: Class-wise Calibrated Fair Adversarial Training},
author={Wei, Zeming and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
booktitle={CVPR},
year={2023}}

@article{tsipras2018robustness,
title={Robustness may be at odds with accuracy},
author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
journal={arXiv preprint arXiv:1805.12152},
year={2018}
}
@inproceedings{wang2023simple,
title={Generalist: Decoupling Natural and Robust Generalization},
author={Hongjun Wang and Yisen Wang},
booktitle={CVPR},
year={2023}}

@article{shafahi2019adversarial,
  title={Adversarial training for free!},
  author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{xu2021robust,
title={To be robust or to be fair: Towards fairness in adversarial training},
author={Xu, Han and Liu, Xiaorui and Li, Yaxin and Jain, Anil and Tang, Jiliang},
booktitle={ICML},
year={2021}
}

@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@inproceedings{wei2023sharpness,
  title={Sharpness-Aware Minimization Alone can Improve Adversarial Robustness},
  author={Wei, Zeming and Zhu, Jingyu and Zhang, Yihao},
  booktitle={The Second Workshop on New Frontiers in Adversarial Machine Learning},
  year={2023}
}


@inproceedings{dong2023robust,
  title={How Robust is Google's Bard to Adversarial Image Attacks?},
  author={Dong, Yinpeng and Chen, Huanran and Chen, Jiawei and Fang, Zhengwei and Yang, Xiao and Zhang, Yichi and Tian, Yu and Su, Hang and Zhu, Jun},
  booktitle={R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Large Foundation Models},
  year={2023}
}

@article{wang2021betacrown,
      title={Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Complete and Incomplete Neural Network Robustness Verification}, 
      author={Shiqi Wang and Huan Zhang and Kaidi Xu and Xue Lin and Suman Jana and Cho-Jui Hsieh and J. Zico Kolter},
      year={2021},
      journal={arXiv preprint arXiv:2103.06624},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{zhang2023using,
      title={Using Z3 for Formal Modeling and Verification of FNN Global Robustness}, 
      author={Yihao Zhang and Zeming Wei and Xiyue Zhang and Meng Sun},
      year={2023},
      journal={arXiv preprint arXiv:2304.10558},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{Huang_2023_CVPR,
    author    = {Huang, Hao and Chen, Ziyan and Chen, Huanran and Wang, Yongtao and Zhang, Kevin},
    title     = {T-SEA: Transfer-Based Self-Ensemble Attack on Object Detection},
    booktitle = {CVPR},
    year      = {2023}
}

@article{chen2023robust,
  title={Robust Classification via a Single Diffusion Model},
  author={Chen, Huanran and Dong, Yinpeng and Wang, Zhengyi and Yang, Xiao and Duan, Chengqi and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2305.15241},
  year={2023}
}

@inproceedings{chen2023rethinking,
  title={Rethinking Model Ensemble in Transfer-based Adversarial Attacks},
  author={Chen, Huanran and Zhang, Yichi and Dong, Yinpeng and Yang, Xiao and Su, Hang and Zhu, Jun},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{chen2024your,
  title={Your Diffusion Model is Secretly a Certifiably Robust Classifier},
  author={Chen, Huanran and Dong, Yinpeng and Shao, Shitong and Hao, Zhongkai and Yang, Xiao and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2402.02316},
  year={2024}
}

@article{wei2024weighted,
  title={Weighted automata extraction and explanation of recurrent neural networks for natural language tasks},
  author={Wei, Zeming and Zhang, Xiyue and Zhang, Yihao and Sun, Meng},
  journal={Journal of Logical and Algebraic Methods in Programming},
  year={2024},
}

@inproceedings{wang2021convergence,
    title={On the convergence and robustness of adversarial training},
    author={Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou, Bowen and Gu, Quanquan},
    booktitle={ICML},
    year={2019}
    }
@inproceedings{papernot2016distillation,
title={Distillation as a defense to adversarial perturbations against deep neural networks},
author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
booktitle={SP},
year={2016}
}
@inproceedings{xie2019feature,
title={Feature denoising for improving adversarial robustness},
author={Xie, Cihang and Wu, Yuxin and Maaten, Laurens van der and Yuille, Alan L and He, Kaiming},
booktitle={CVPR},
year={2019}
}

@inproceedings{bai2019hilbert,
title={Hilbert-based generative defense for adversarial examples},
author={Bai, Yang and Feng, Yan and Wang, Yisen and Dai, Tao and Xia, Shu-Tao and Jiang, Yong},
booktitle={ICCV},
year={2019}
}
@article{yu2022robust,
  title={Robust weight perturbation for adversarial training},
  author={Yu, Chaojian and Han, Bo and Gong, Mingming and Shen, Li and Ge, Shiming and Du, Bo and Liu, Tongliang},
  journal={arXiv preprint arXiv:2205.14826},
  year={2022}
}
@article{yu2022robust2,
  title={Robust weight perturbation for adversarial training},
  author={Yu, Chaojian and Han, Bo and Gong, Mingming and Shen, Li and Ge, Shiming and Du, Bo and Liu, Tongliang},
  journal={arXiv preprint arXiv:2205.14826},
  year={2022}
}


@inproceedings{Cordts2016Cityscapes,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={CVPR},
year={2016}
}

@article{voc-2012,
 author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
 title = "The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults",
 howpublished = "http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html"}

@article{chen2017rethinking,
  title={Rethinking atrous convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  journal={arXiv preprint arXiv:1706.05587},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{croce2020minimally,
  author    = {F. Croce and M. Hein},
  title     = {Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack},
  booktitle = {ICML},
  year      = {2020}
}

@article{goodfellow2015explaining,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      journal={arXiv preprint arXiv:1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{hendrycks2019benchmarking,
      title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations}, 
      author={Dan Hendrycks and Thomas Dietterich},
      year={2019},
      eprint={1903.12261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{croce2021robustbench,
  title     = {RobustBench: a standardized adversarial robustness benchmark},
  author    = {Croce, Francesco and Andriushchenko, Maksym and Sehwag, Vikash and Debenedetti, Edoardo and Flammarion, Nicolas and Chiang, Mung and Mittal, Prateek and Matthias Hein},
  booktitle = {NeurIPS},
  year      = {2021},
}


@article{DBLP:journals/corr/ZagoruykoK16,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}



@article{touvron2021training,
      title={Training data-efficient image transformers distillation through attention}, 
      author={Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and Hervé Jégou},
      year={2021},
      journal={arXiv preprint arXiv:2012.12877},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{du2022efficient,
      title={Efficient Sharpness-aware Minimization for Improved Training of Neural Networks}, 
      author={Jiawei Du and Hanshu Yan and Jiashi Feng and Joey Tianyi Zhou and Liangli Zhen and Rick Siow Mong Goh and Vincent Y. F. Tan},
      year={2022},
      journal={arXiv preprint arXiv:2110.03141},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{jin2020bert,
      title={Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment}, 
      author={Di Jin and Zhijing Jin and Joey Tianyi Zhou and Peter Szolovits},
      year={2020},
      eprint={1907.11932},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chrabaszcz2017downsampled,
      title={A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets}, 
      author={Patryk Chrabaszcz and Ilya Loshchilov and Frank Hutter},
      year={2017},
      journal={arXiv preprint arXiv:1707.08819},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{xiao2018spatially,
      title={Spatially Transformed Adversarial Examples}, 
      author={Chaowei Xiao and Jun-Yan Zhu and Bo Li and Warren He and Mingyan Liu and Dawn Song},
      year={2018},
      journal={arXiv preprint arXiv:1801.02612},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{kim2020torchattacks,
  title={Torchattacks: A pytorch repository for adversarial attacks},
  author={Kim, Hoki},
  journal={arXiv preprint arXiv:2010.01950},
  year={2020}
}

@inproceedings{Pomponi_2022,
   title={Pixle: a fast and effective black-box attack based on rearranging pixels},
   booktitle={IJCNN},
   author={Pomponi, Jary and Scardapane, Simone and Uncini, Aurelio},
   year={2022},
}


@inproceedings{morris2020textattack,
  title={TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP},
  author={Morris, John and Lifland, Eli and Yoo, Jin Yong and Grigsby, Jake and Jin, Di and Qi, Yanjun},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{croce2021mind,
    title={Mind the box: $l_1$-APGD for sparse adversarial attacks on image classifiers}, 
    author={Francesco Croce and Matthias Hein},
    booktitle={ICML},
    year={2021}
}

@article{DistilBERT,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}

@InProceedings{rotten,
  author =       {Bo Pang and Lillian Lee},
  title =        {Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales},
  booktitle =    {ACL},
  year =         2005
}

@article{iga,
      title={Natural Language Adversarial Defense through Synonym Encoding}, 
      author={Xiaosen Wang and Hao Jin and Yichen Yang and Kun He},
      year={2021},
      journal={arXiv preprint arXiv:1909.06723}
}

@inproceedings{pso,
    title = "Word-level Textual Adversarial Attacking as Combinatorial Optimization",
    author = "Zang, Yuan  and
      Qi, Fanchao  and
      Yang, Chenghao  and
      Liu, Zhiyuan  and
      Zhang, Meng  and
      Liu, Qun  and
      Sun, Maosong",
    year = "2020",
    booktitle = "ACL"
}


@INPROCEEDINGS{background_dataset,
  author={Gould, Stephen and Fulton, Richard and Koller, Daphne},
  booktitle={ICCV 2009}, 
  title={Decomposing a scene into geometric and semantically consistent regions}
}

@inproceedings{zhu2021learning,
  title={Learning statistical texture for semantic segmentation},
  author={Zhu, Lanyun and Ji, Deyi and Zhu, Shiping and Gan, Weihao and Wu, Wei and Yan, Junjie},
  booktitle={CVPR},
  year={2021}
}
@inproceedings{ren2003learning,
  title={Learning a classification model for segmentation},
  author={Ren and Malik},
  booktitle={ICCV},
  year={2003}
}

@inproceedings{croce2020reliable,
title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
author={Croce, Francesco and Hein, Matthias},
booktitle={ICML},
year={2020}
}

@article{mueller2023normalization,
      title={Normalization Layers Are All That Sharpness-Aware Minimization Needs}, 
      author={Maximilian Mueller and Tiffany Vlaar and David Rolnick and Matthias Hein},
      year={2023},
      journal={arXiv preprint arXiv:2306.04226},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{andriushchenko2023modern,
      title={A Modern Look at the Relationship between Sharpness and Generalization}, 
      author={Maksym Andriushchenko and Francesco Croce and Maximilian Müller and Matthias Hein and Nicolas Flammarion},
      year={2023},
      journal={arXiv preprint arXiv:2302.07011}
}

@article{ma2023understanding,
      title={Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods}, 
      author={Avery Ma and Yangchen Pan and Amir-massoud Farahmand},
      year={2023},
      journal={arXiv preprint arXiv:2308.06703}
}
@inproceedings{mobilenetv2,
  author       = {Mark Sandler and
                  Andrew G. Howard and
                  Menglong Zhu and
                  Andrey Zhmoginov and
                  Liang{-}Chieh Chen},
  title        = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  booktitle    = {{CVPR}},
  year         = {2018}
}
@article{mIoU,
  author       = {Mark Everingham and
                  S. M. Ali Eslami and
                  Luc Van Gool and
                  Christopher K. I. Williams and
                  John M. Winn and
                  Andrew Zisserman},
  title        = {The Pascal Visual Object Classes Challenge: {A} Retrospective},
  journal      = {Int. J. Comput. Vis.},
  year         = {2015}
}

@misc{zou2023universal,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{mo2024studious,
  title={Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning},
  author={Mo, Yichuan and Wang, Yuji and Wei, Zeming and Wang, Yisen},
  journal={arXiv preprint arXiv:2402.06255},
  year={2024}
}


@misc{cohen2019certified,
      title={Certified Adversarial Robustness via Randomized Smoothing}, 
      author={Jeremy M Cohen and Elan Rosenfeld and J. Zico Kolter},
      year={2019},
      eprint={1902.02918},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{piet2023jatmo,
  title={Jatmo: Prompt injection defense by task-specific finetuning},
  author={Piet, Julien and Alrashed, Maha and Sitawarin, Chawin and Chen, Sizhe and Wei, Zeming and Sun, Elizabeth and Alomair, Basel and Wagner, David},
  journal={arXiv preprint arXiv:2312.17673},
  year={2023}
}

@article{wei2023characterizing,
  title={Characterizing Robust Overfitting in Adversarial Training via Cross-Class Features},
  author={Wei, Zeming and Guo, Yiwen and Wang, Yisen},
    journal={OpenReview preprint},
  year={2023}
}

@misc{rice2020overfitting,
      title={Overfitting in adversarially robust deep learning}, 
      author={Leslie Rice and Eric Wong and J. Zico Kolter},
      year={2020},
      eprint={2002.11569},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{wang2024balance,
  title={Balance, imbalance, and rebalance: Understanding robust overfitting from a minimax game perspective},
  author={Wang, Yifei and Li, Liangchen and Yang, Jiansheng and Lin, Zhouchen and Wang, Yisen},
  journal={NeurIPS},
  year={2023}
}

@misc{jain2023baseline,
      title={Baseline Defenses for Adversarial Attacks Against Aligned Language Models}, 
      author={Neel Jain and Avi Schwarzschild and Yuxin Wen and Gowthami Somepalli and John Kirchenbauer and Ping-yeh Chiang and Micah Goldblum and Aniruddha Saha and Jonas Geiping and Tom Goldstein},
      year={2023},
      eprint={2309.00614},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{zhu2022topology,
  title={Topology-aware generalization of decentralized sgd},
  author={Zhu, Tongtian and He, Fengxiang and Zhang, Lan and Niu, Zhengyang and Song, Mingli and Tao, Dacheng},
  booktitle={International Conference on Machine Learning},
  pages={27479--27503},
  year={2022},
  organization={PMLR}
}

@article{zhu2023decentralized,
  title={Decentralized SGD and Average-direction SAM are Asymptotically Equivalent},
  author={Zhu, Tongtian and He, Fengxiang and Chen, Kaixuan and Song, Mingli and Tao, Dacheng},
  journal={arXiv preprint arXiv:2306.02913},
  year={2023}
}

@article{xie2023defending,
  title={Defending chatgpt against jailbreak attack via self-reminders},
  author={Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing and Wu, Fangzhao},
  journal={Nature Machine Intelligence},
  year={2023},
}

@article{wang2024theoretical,
  title={A Theoretical Understanding of Self-Correction through In-context Alignment},
  author={Wang, Yifei and Wu, Yuyang and Wei, Zeming and Jegelka, Stefanie and Wang, Yisen},
  journal={arXiv preprint arXiv:2405.18634},
  year={2024}
}

@inproceedings{zhang2024boosting,
title={Boosting Jailbreak Attack with Momentum},
author={Yihao Zhang and Zeming Wei},
booktitle={ICLR 2024 Workshop on Reliable and Responsible Foundation Models},
year={2024}
}
