@article{zhang2021multi,
  title={Multi-agent reinforcement learning: {A} selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of Reinforcement Learning and Control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}
@article{busoniu2008comprehensive,
  title={A comprehensive survey of multiagent reinforcement learning},
  author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={2},
  pages={156--172},
  year={2008},
  publisher={IEEE}
}
@article{sayin2021decentralized,
  title={Decentralized {Q}-Learning in Zero-sum {M}arkov Games},
  author={Sayin, Muhammed O and Zhang, Kaiqing and Leslie, David S and Ba\c{s}ar, Tamer and Ozdaglar, Asuman},
  journal={arXiv preprint arXiv:2106.02748},
  year={2021}
}
@inproceedings{guo2021decentralized,
  title={Decentralized Single-Timescale Actor-Critic on Zero-Sum Two-Player Stochastic Games},
  author={Guo, Hongyi and Fu, Zuyue and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={3899--3909},
  year={2021},
  organization={PMLR}
}
@inproceedings{perolat2018actor,
  title={Actor-critic fictitious play in simultaneous move multistage games},
  author={Perolat, Julien and Piot, Bilal and Pietquin, Olivier},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={919--928},
  year={2018},
  organization={PMLR}
} 
@article{oliehoek2008optimal,
  title={Optimal and approximate {Q}-value functions for decentralized {POMDP}s},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={289--353},
  year={2008}
}
@inproceedings{mao2020information,
  title={Information state embedding in partially observable cooperative multi-agent reinforcement learning},
  author={Mao, Weichao and Zhang, Kaiqing and Miehling, Erik and Ba{\c{s}}ar, Tamer},
  booktitle={IEEE Conference on Decision and Control},
  pages={6124--6131},
  year={2020},
  organization={IEEE}
}
@article{lowe2017multi,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Pieter Abbeel, and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={6379--6390},
  year={2017}
}
@inproceedings{son2019qtran,
  title={Qtran: {L}earning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International Conference on Machine Learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}
@inproceedings{jafari2001no,
  title={On no-regret learning, fictitious play, and {N}ash equilibrium},
  author={Jafari, Amir and Greenwald, Amy and Gondek, David and Ercal, Gunes},
  booktitle={International Conference on Machine Learning},
  volume={1},
  pages={226--233},
  year={2001}
}
@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI Conference on Artificial Intelligence},
  volume={1998},
  number={746-752},
  pages={2},
  year={1998}
}
@inproceedings{lauer2000algorithm,
  title={An algorithm for distributed reinforcement learning in cooperative multi-agent systems},
  author={Lauer, Martin and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning},
  year={2000}
}
@article{zhang2020almost,
  title={Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage Decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{bai2020near,
  title={Near-Optimal Reinforcement Learning with Self-Play},
  author={Bai, Yu and Jin, Chi and Yu, Tiancheng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM Journal on Computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002}
}

@book{lattimore2020bandit,
  title={Bandit Algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@inproceedings{jin2018q,
  title={Is {Q}-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={4868--4878},
  year={2018}
}

@book{mitzenmacher2017probability,
  title={Probability and Computing: {R}andomization and Probabilistic Techniques in Algorithms and Data Analysis},
  author={Mitzenmacher, Michael and Upfal, Eli},
  year={2017},
  publisher={Cambridge University Press}
}

@article{leslie2005individual,
  title={Individual {Q}-learning in normal form games},
  author={Leslie, David S and Collins, Edmund J},
  journal={SIAM Journal on Control and Optimization},
  volume={44},
  number={2},
  pages={495--514},
  year={2005}
}


@article{arslan2016decentralized,
  title={Decentralized {Q}-learning for stochastic teams and games},
  author={Arslan, G{\"u}rdal and Y{\"u}ksel, Serdar},
  journal={IEEE Transactions on Automatic Control},
  volume={62},
  number={4},
  pages={1545--1558},
  year={2016}
}



@article{tian2020provably,
  title={Online Learning in Unknown {M}arkov Games},
  author={Yi Tian and Yuanhao Wang and Tiancheng Yu and Suvrit Sra},
  journal={International Conference on Machine Learning},
  year={2021}
}

@article{daskalakis2020independent,
  title={Independent Policy Gradient Methods for Competitive Reinforcement Learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{ho1980team,
  title={Team decision theory and information structures},
  author={Ho, Yu-Chi},
  journal={Proceedings of the IEEE},
  volume={68},
  number={6},
  pages={644--654},
  year={1980}
}

@article{nayyar2013decentralized,
  title={Decentralized stochastic control with partial history sharing: {A} common information approach},
  author={Nayyar, Ashutosh and Mahajan, Aditya and Teneketzis, Demosthenis},
  journal={IEEE Transactions on Automatic Control},
  volume={58},
  number={7},
  pages={1644--1658},
  year={2013}
}


@article{nayyar2013common,
  title={Common information based {M}arkov perfect equilibria for stochastic games with asymmetric information: {F}inite games},
  author={Nayyar, Ashutosh and Gupta, Abhishek and Langbort, Cedric and Ba{\c{s}}ar, Tamer},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={3},
  pages={555--570},
  year={2013}
}

@article{wei2021last,
  title={Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-horizon Competitive {M}arkov Games},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={Annual Conference on Learning Theory},
  year={2021}
}

@article{arslan2016decentralized,
  title={Decentralized {Q}-learning for stochastic teams and games},
  author={Arslan, G{\"u}rdal and Y{\"u}ksel, Serdar},
  journal={IEEE Transactions on Automatic Control},
  volume={62},
  number={4},
  pages={1545--1558},
  year={2016}
}

@article{neu2015explore,
  title={Explore no more: {I}mproved high-probability regret bounds for non-stochastic bandits},
  author={Neu, Gergely},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3168--3176},
  year={2015}
}


@inproceedings{fang2020online,
  title={Online mirror descent and dual averaging: {K}eeping pace in the dynamic case},
  author={Fang, Huang and Harvey, Nick and Portella, Victor and Friedlander, Michael},
  booktitle={International Conference on Machine Learning},
  pages={3008--3017},
  year={2020}
}

@article{bubeck2015convex,
  title={Convex Optimization: {A}lgorithms and Complexity},
  author={Bubeck, S{\'e}bastien and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers, Inc.}
}

@article{nemirovskij1983problem,
  title={Problem complexity and method efficiency in optimization},
  author={Nemirovskij, Arkadij Semenovi{\v{c}} and Yudin, David Borisovich},
  year={1983},
  publisher={Wiley-Interscience}
}

@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={International Conference on Machine Learning},
  pages={928--936},
  year={2003}
}

@article{hazan2016introduction,
  title={Introduction to Online Convex Optimization},
  author={Hazan, Elad},
  journal={Foundations and Trends in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016}
}

@article{orabona2018scale,
  title={Scale-free online learning},
  author={Orabona, Francesco and P{\'a}l, D{\'a}vid},
  journal={Theoretical Computer Science},
  volume={716},
  pages={50--69},
  year={2018}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@inproceedings{roughgarden2009intrinsic,
  title={Intrinsic robustness of the price of anarchy},
  author={Roughgarden, Tim},
  booktitle={ACM Symposium on Theory of Computing},
  pages={513--522},
  year={2009}
}


@inproceedings{syrgkanis2015fast,
  title={Fast convergence of regularized learning in games},
  author={Syrgkanis, Vasilis and Agarwal, Alekh and Luo, Haipeng and Schapire, Robert E},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={2989--2997},
  year={2015}
}

@inproceedings{mao2020near,
  title={Near-Optimal Regret Bounds for Model-Free {RL} in Non-Stationary Episodic {MDP}s},
  author={Mao, Weichao and Zhang, Kaiqing and Zhu, Ruihao and Simchi-Levi, David and Ba{\c{s}}ar, Tamer},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@inproceedings{radanovic2019learning,
  title={Learning to collaborate in {M}arkov decision processes},
  author={Radanovic, Goran and Devidze, Rati and Parkes, David and Singla, Adish},
  booktitle={International Conference on Machine Learning},
  pages={5261--5270},
  year={2019}
}

@inproceedings{syrgkanis2013composable,
  title={Composable and efficient mechanisms},
  author={Syrgkanis, Vasilis and Tardos, Eva},
  booktitle={ACM Symposium on Theory of Computing},
  pages={211--220},
  year={2013}
}




@inproceedings{foster2016learning,
  title={Learning in games: {R}obustness of fast convergence},
  author={Foster, Dylan J and Li, Zhiyuan and Lykouris, Thodoris and Sridharan, Karthik and Tardos, {\'E}va},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={4734--4742},
  year={2016}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017}
}

@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}

@article{menard2021ucb,
  title={{UCB} Momentum {Q}-learning: {C}orrecting the bias without forgetting},
  author={Menard, Pierre and Domingues, Omar Darwiche and Shang, Xuedong and Valko, Michal},
  journal={arXiv preprint arXiv:2103.01312},
  year={2021}
}

@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine Learning},
  pages={157--163},
  year={1994}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the National Academy of Sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953}
}
@inproceedings{littman2001friend,
  title={Friend-or-{F}oe {Q}-learning in General-Sum Games},
  author={Littman, Michael L},
  booktitle={International Conference on Machine Learning},
  pages={322--328},
  year={2001}
}
@article{hu2003nash,
  title={Nash {Q}-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of Machine Learning Research},
  volume={4},
  number={Nov},
  pages={1039--1069},
  year={2003}
}
@article{wang2002reinforcement,
  title={Reinforcement learning to play an optimal {N}ash equilibrium in team {M}arkov games},
  author={Wang, Xiaofeng and Sandholm, Tuomas},
  journal={Advances in Neural Information Processing Systems},
  volume={15},
  pages={1603--1610},
  year={2002}
}
@article{hansen2013strategy,
  title={Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant discount factor},
  author={Hansen, Thomas Dueholm and Miltersen, Peter Bro and Zwick, Uri},
  journal={Journal of the ACM},
  volume={60},
  number={1},
  pages={1--16},
  year={2013}
}
@inproceedings{wei2017online,
  title={Online reinforcement learning in stochastic games},
  author={Wei, Chen-Yu and Hong, Yi-Te and Lu, Chi-Jen},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={4994--5004},
  year={2017}
}
@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move {M}arkov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on Learning Theory},
  pages={3674--3682},
  year={2020}
}
@inproceedings{bai2020provable,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={551--560},
  year={2020}
}
@inproceedings{liu2020sharp,
  title={A Sharp Analysis of Model-based Reinforcement Learning with Self-Play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  year={2021}
}
@article{zhao2021provably,
  title={Provably efficient policy gradient methods for two-player zero-sum {M}arkov games},
  author={Zhao, Yulai and Tian, Yuandong and Lee, Jason D and Du, Simon S},
  journal={arXiv preprint arXiv:2102.08903},
  year={2021}
}

@inproceedings{sidford2020solving,
  title={Solving discounted stochastic two-player games with near-optimal time and sample complexity},
  author={Sidford, Aaron and Wang, Mengdi and Yang, Lin and Ye, Yinyu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2992--3002},
  year={2020},
  organization={PMLR}
}

@article{daskalakis2020independent,
  title={Independent Policy Gradient Methods for Competitive Reinforcement Learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{zhang2020model,
  title={Model-Based Multi-Agent {RL} in Zero-Sum {M}arkov Games with Near-Optimal Sample Complexity},
  author={Zhang, Kaiqing and Kakade, Sham and Ba\c{s}ar, Tamer and Yang, Lin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{boutilier1996planning,
  title={Planning, learning and coordination in multiagent decision processes},
  author={Boutilier, Craig},
  booktitle={Conference on Theoretical Aspects of Rationality and Knowledge},
  pages={195--210},
  year={1996}
}

@article{yongacoglu2019learning,
  title={Learning team-optimality for decentralized stochastic control and dynamic games},
  author={Yongacoglu, Bora and Arslan, G{\"u}rdal and Y{\"u}ksel, Serdar},
  journal={arXiv preprint arXiv:1903.05812},
  year={2019}
}

@article{chasparis2013aspiration,
  title={Aspiration learning in coordination games},
  author={Chasparis, Georgios C and Arapostathis, Ari and Shamma, Jeff S},
  journal={SIAM Journal on Control and Optimization},
  volume={51},
  number={1},
  pages={465--490},
  year={2013}
}

@article{dubey2021provably,
  title={Provably Efficient Cooperative Multi-Agent Reinforcement Learning with Function Approximation},
  author={Dubey, Abhimanyu and Pentland, Alex},
  journal={arXiv preprint arXiv:2103.04972},
  year={2021}
}

@inproceedings{avner2014concurrent,
  title={Concurrent bandits and cognitive radio networks},
  author={Avner, Orly and Mannor, Shie},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={66--81},
  year={2014}
}

@inproceedings{lai2008medium,
  title={Medium access in cognitive radio networks: {A} competitive multi-armed bandit framework},
  author={Lai, Lifeng and Jiang, Hai and Poor, H Vincent},
  booktitle={Asilomar Conference on Signals, Systems and Computers},
  pages={98--102},
  year={2008},
  organization={IEEE}
}

@article{kalathil2014decentralized,
  title={Decentralized learning for multiplayer multiarmed bandits},
  author={Kalathil, Dileep and Nayyar, Naumaan and Jain, Rahul},
  journal={IEEE Transactions on Information Theory},
  volume={60},
  number={4},
  pages={2331--2345},
  year={2014},
  publisher={IEEE}
}

@inproceedings{bubeck2020coordination,
  title={Coordination without communication: {O}ptimal regret in two players multi-armed bandits},
  author={Bubeck, S{\'e}bastien and Budzinski, Thomas},
  booktitle={Conference on Learning Theory},
  pages={916--939},
  year={2020}
}


@article{silver2016mastering,
  title={Mastering the game of {G}o with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016}
}

@article{brown2018superhuman,
  title={Superhuman {AI} for heads-up no-limit poker: {L}ibratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in {S}tar{C}raft {II} using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019}
}


@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: {A} survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013}
}
@inproceedings{corke2005networked,
  title={Networked robots: {F}lying robot navigation using a sensor net},
  author={Corke, Peter and Peterson, Ron and Rus, Daniela},
  booktitle={International Symposium on Robotics Research},
  pages={234--243},
  year={2005}
}
@article{dall2013distributed,
  title={Distributed optimal power flow for smart microgrids},
  author={Dall'Anese, Emiliano and Zhu, Hao and Giannakis, Georgios B},
  journal={Transactions on Smart Grid},
  volume={4},
  number={3},
  pages={1464--1475},
  year={2013},
  publisher={IEEE}
}

@article{pham2018cooperative,
  title={Cooperative and distributed reinforcement learning of drones for field coverage},
  author={Pham, Huy Xuan and La, Hung Manh and Feil-Seifer, David and Nefian, Aria},
  journal={arXiv preprint arXiv:1803.07250},
  year={2018}
}
@article{duan2012multi,
  title={A multi-agent reinforcement learning approach to robot soccer},
  author={Duan, Yong and Cui, Bao Xia and Xu, Xin He},
  journal={Artificial Intelligence Review},
  volume={38},
  number={3},
  pages={193--211},
  year={2012}
}

@article{zhuo2019federated,
  title={Federated reinforcement learning},
  author={Zhuo, Hankz Hankui and Feng, Wenfeng and Xu, Qian and Yang, Qiang and Lin, Yufeng},
  journal={arXiv preprint arXiv:1901.08277},
  volume={1},
  year={2019}
}
@article{peteiro2013survey,
  title={A survey of methods for distributed machine learning},
  author={Peteiro-Barral, Diego and Guijarro-Berdi{\~n}as, Bertha},
  journal={Progress in Artificial Intelligence},
  volume={2},
  number={1},
  pages={1--11},
  year={2013}
}

@article{boyd2006randomized,
  title={Randomized gossip algorithms},
  author={Boyd, Stephen and Ghosh, Arpita and Prabhakar, Balaji and Shah, Devavrat},
  journal={Transactions on Information Theory},
  volume={52},
  number={6},
  pages={2508--2530},
  year={2006},
  publisher={IEEE}
}

@inproceedings{zhang2018fully,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Ba\c{s}ar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5872--5881},
  year={2018}
}

@inproceedings{ding2020distributed,
  title={Distributed Reinforcement Learning for Cooperative Multi-Robot Object Manipulation},
  author={Ding, Guohui and Koh, Joewie J and Merckaert, Kelly and Vanderborght, Bram and Nicotra, Marco M and Heckman, Christoffer and Roncone, Alessandro and Chen, Lijun},
  booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1831--1833},
  year={2020}
}

@article{bernstein2009policy,
  title={Policy iteration for decentralized control of {M}arkov decision processes},
  author={Bernstein, Daniel S and Amato, Christopher and Hansen, Eric A and Zilberstein, Shlomo},
  journal={Journal of Artificial Intelligence Research},
  volume={34},
  pages={89--132},
  year={2009}
}

@inproceedings{zhang2019online,
  title={Online planning for decentralized stochastic control with partial history sharing},
  author={Zhang, Kaiqing and Miehling, Erik and Ba{\c{s}}ar, Tamer},
  booktitle={American Control Conference},
  pages={3544--3550},
  year={2019},
  organization={IEEE}
}

@inproceedings{arabneydi2015reinforcement,
  title={Reinforcement learning in decentralized stochastic control systems with partial history sharing},
  author={Arabneydi, Jalal and Mahajan, Aditya},
  booktitle={American Control Conference},
  pages={5449--5456},
  year={2015},
  organization={IEEE}
}

@article{kar13,  
  author={Kar, Soummya and Moura, José M. F. and Poor, H. Vincent},  
  journal={IEEE Transactions on Signal Processing},   
  title={Q{D}-Learning: A Collaborative Distributed Strategy for Multi-Agent Reinforcement Learning Through  Consensus + Innovations},   
  year={2013},  
  volume={61},  
  number={7},  
  pages={1848-1862}
}

@book{filar2012competitive,
  title={Competitive {M}arkov decision processes},
  author={Filar, Jerzy and Vrieze, Koos},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{verbeeck2002learning,
  title={Learning to reach the {P}areto optimal {N}ash equilibrium as a team},
  author={Verbeeck, Katja and Now{\'e}, Ann and Lenaerts, Tom and Parent, Johan},
  booktitle={Australian Joint Conference on Artificial Intelligence},
  pages={407--418},
  year={2002},
  organization={Springer}
}

@article{marden2009payoff,
  title={Payoff-based dynamics for multiplayer weakly acyclic games},
  author={Marden, Jason R and Young, H Peyton and Arslan, G{\"u}rdal and Shamma, Jeff S},
  journal={SIAM Journal on Control and Optimization},
  volume={48},
  number={1},
  pages={373--396},
  year={2009}
}

@article{marden2009cooperative,
  title={Cooperative control and potential games},
  author={Marden, Jason R and Arslan, G{\"u}rdal and Shamma, Jeff S},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={39},
  number={6},
  pages={1393--1407},
  year={2009}
}

@inproceedings{cohen2017learning,
  title={Learning with bandit feedback in potential games},
  author={Cohen, Johanne and H{\'e}liou, Am{\'e}lie and Mertikopoulos, Panayotis},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={6372--6381},
  year={2017}
}

@article{hart2000simple,
  title={A simple adaptive procedure leading to correlated equilibrium},
  author={Hart, Sergiu and Mas-Colell, Andreu},
  journal={Econometrica},
  volume={68},
  number={5},
  pages={1127--1150},
  year={2000},
  publisher={Wiley Online Library}
}

@article{viossat2013no,
  title={No-regret dynamics and fictitious play},
  author={Viossat, Yannick and Zapechelnyuk, Andriy},
  journal={Journal of Economic Theory},
  volume={148},
  number={2},
  pages={825--842},
  year={2013},
  publisher={Elsevier}
}

@article{hart2003uncoupled,
  title={Uncoupled dynamics do not lead to {N}ash equilibrium},
  author={Hart, Sergiu and Mas-Colell, Andreu},
  journal={American Economic Review},
  volume={93},
  number={5},
  pages={1830--1836},
  year={2003}
}

@article{freund1999adaptive,
  title={Adaptive game playing using multiplicative weights},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Games and Economic Behavior},
  volume={29},
  number={1-2},
  pages={79--103},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{kleinberg2009multiplicative,
  title={Multiplicative updates outperform generic no-regret learning in congestion games},
  author={Kleinberg, Robert and Piliouras, Georgios and Tardos, {\'E}va},
  booktitle={Proceedings of the Forty-First Annual ACM Symposium on Theory of Computing},
  pages={533--542},
  year={2009}
}

@article{zhang2018convergence,
  title={On the convergence rate of stochastic mirror descent for nonsmooth nonconvex optimization},
  author={Zhang, Siqi and He, Niao},
  journal={arXiv preprint arXiv:1806.04781},
  year={2018}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}

@article{davis2018stochastic,
  title={Stochastic subgradient method converges at the rate $ {O} (k^{-1/4}) $ on weakly convex functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy},
  journal={arXiv preprint arXiv:1802.02988},
  year={2018}
}

@article{lu2019relative,
  title={“{R}elative Continuity” for Non-{L}ipschitz Nonsmooth Convex Optimization Using Stochastic (or Deterministic) Mirror Descent},
  author={Lu, Haihao},
  journal={INFORMS Journal on Optimization},
  volume={1},
  number={4},
  pages={288--303},
  year={2019},
  publisher={INFORMS}
}

@book{beck2017first,
  title={First-order Methods in Optimization},
  author={Beck, Amir},
  year={2017},
  publisher={SIAM}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@book{rockafellar2015convex,
  title={Convex analysis},
  author={Rockafellar, Ralph Tyrell},
  year={2015},
  publisher={Princeton University Press}
}

@article{zhang2021gradient,
  title={Gradient Play in Multi-Agent {M}arkov Stochastic Games: {S}tationary Points and Convergence},
  author={Zhang, Runyu and Ren, Zhaolin and Li, Na},
  journal={arXiv preprint arXiv:2106.00198},
  year={2021}
}

@article{leonardos2021global,
  title={Global Convergence of Multi-Agent Policy Gradient in {M}arkov Potential Games},
  author={Leonardos, Stefanos and Overman, Will and Panageas, Ioannis and Piliouras, Georgios},
  journal={arXiv preprint arXiv:2106.01969},
  year={2021}
}

@article{drusvyatskiy2019efficiency,
  title={Efficiency of minimizing compositions of convex functions and smooth maps},
  author={Drusvyatskiy, Dmitriy and Paquette, Courtney},
  journal={Mathematical Programming},
  volume={178},
  number={1},
  pages={503--558},
  year={2019},
  publisher={Springer}
}

@article{monderer1996potential,
  title={Potential games},
  author={Monderer, Dov and Shapley, Lloyd S},
  journal={Games and Economic Behavior},
  volume={14},
  number={1},
  pages={124--143},
  year={1996},
  publisher={Elsevier}
}

@inproceedings{bai2019provably,
  title={Provably efficient {Q}-learning with low switching cost},
  author={Bai, Yu and Xie, Tengyang and Jiang, Nan and Wang, Yu-Xiang},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={8004--8013},
  year={2019}
}

@article{sayin2021decentralized,
  title={Decentralized {Q}-Learning in Zero-sum {M}arkov Games},
  author={Sayin, Muhammed O and Zhang, Kaiqing and Leslie, David S and Ba\c{s}ar, Tamer and Ozdaglar, Asuman},
  journal={arXiv preprint arXiv:2106.02748},
  year={2021}
}

@article{cutkosky2019momentum,
  title={Momentum-Based Variance Reduction in Non-Convex {SGD}},
  author={Cutkosky, Ashok and Orabona, Francesco},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={15236--15245},
  year={2019}
}

@article{kingma2014adam,
  title={Adam: {A} method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  pages={315--323},
  year={2013}
}

@inproceedings{allen2016variance,
  title={Variance reduction for faster non-convex optimization},
  author={Allen-Zhu, Zeyuan and Hazan, Elad},
  booktitle={International Conference on Machine Learning},
  pages={699--707},
  year={2016},
  organization={PMLR}
}

@inproceedings{reddi2016stochastic,
  title={Stochastic variance reduction for nonconvex optimization},
  author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
  booktitle={International Conference on Machine Learning},
  pages={314--323},
  year={2016},
  organization={PMLR}
}

@article{arjevani2019lower,
  title={Lower bounds for non-convex stochastic optimization},
  author={Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Srebro, Nathan and Woodworth, Blake},
  journal={arXiv preprint arXiv:1912.02365},
  year={2019}
}

@book{cesa2006prediction,
  title={Prediction, Learning, and Games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge University Press}
}


@article{moreau1965proximite,
  title={Proximit{\'e} et dualit{\'e} dans un espace Hilbertien},
  author={Moreau, Jean-Jacques},
  journal={Bulletin de la Soci{\'e}t{\'e} math{\'e}matique de France},
  volume={93},
  pages={273--299},
  year={1965}
}

@article{chang2021online,
  title={Online Learning for Cooperative Multi-Player Multi-Armed Bandits},
  author={Chang, William and Jafarnia-Jahromi, Mehdi and Jain, Rahul},
  journal={arXiv preprint arXiv:2109.03818},
  year={2021}
}

@article{li2020high,
  title={A high probability analysis of adaptive {SGD} with momentum},
  author={Li, Xiaoyu and Orabona, Francesco},
  journal={arXiv preprint arXiv:2007.14294},
  year={2020}
}
@inproceedings{foerster2016learning,
  title={Learning to communicate with Deep multi-agent reinforcement learning},
  author={Foerster, Jakob N and Assael, Yannis M and de Freitas, Nando and Whiteson, Shimon},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={2145--2153},
  year={2016}
}
@inproceedings{rashid2018qmix,
  title={{QMIX}: {M}onotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}
@article{wang2008machine,
  title={A machine-learning approach to multi-robot coordination},
  author={Wang, Ying and de Silva, Clarence W},
  journal={Engineering Applications of Artificial Intelligence},
  volume={21},
  number={3},
  pages={470--484},
  year={2008},
  publisher={Elsevier}
}
@inproceedings{kuyer2008multiagent,
  title={Multiagent reinforcement learning for urban traffic control using coordination graphs},
  author={Kuyer, Lior and Whiteson, Shimon and Bakker, Bram and Vlassis, Nikos},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={656--671},
  year={2008},
  organization={Springer}
}
@book{fudenberg1998theory,
  title={The Theory of Learning in Games},
  author={Fudenberg, Drew and Drew, Fudenberg and Levine, David K and Levine, David K},
  volume={2},
  year={1998},
  publisher={MIT press}
}
@article{daskalakis2009complexity,
  title={The complexity of computing a {N}ash equilibrium},
  author={Daskalakis, Constantinos and Goldberg, Paul W and Papadimitriou, Christos H},
  journal={SIAM Journal on Computing},
  volume={39},
  number={1},
  pages={195--259},
  year={2009},
  publisher={SIAM}
}


@article{jin2021v,
  title={V-Learning--{A} Simple, Efficient, Decentralized Algorithm for Multiagent {RL}},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2110.14555},
  year={2021}
}

@article{blum2007external,
  title={From external to internal regret},
  author={Blum, Avrim and Mansour, Yishay},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={6},
  year={2007}
}

@article{song2021can,
  title={When Can We Learn General-Sum {M}arkov Games with a Large Number of Players Sample-Efficiently?},
  author={Song, Ziang and Mei, Song and Bai, Yu},
  journal={arXiv preprint arXiv:2110.04184},
  year={2021}
}

@article{macua2018learning,
  title={Learning parametric closed-loop policies for {M}arkov potential games},
  author={Macua, Sergio Valcarcel and Zazo, Javier and Zazo, Santiago},
  journal={arXiv preprint arXiv:1802.00899},
  year={2018}
}

@article{leonardos2021global,
  title={Global Convergence of Multi-Agent Policy Gradient in {M}arkov Potential Games},
  author={Leonardos, Stefanos and Overman, Will and Panageas, Ioannis and Piliouras, Georgios},
  journal={arXiv preprint arXiv:2106.01969},
  year={2021}
}

@article{zhang2021gradient,
  title={Gradient Play in Multi-Agent {M}arkov Stochastic Games: Stationary Points and Convergence},
  author={Zhang, Runyu and Ren, Zhaolin and Li, Na},
  journal={arXiv preprint arXiv:2106.00198},
  year={2021}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1057--1063},
  year={2000}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{fang2018spider,
  title={{SPIDER}: near-optimal non-convex optimization via stochastic path integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={687--697},
  year={2018}
}

@article{mao2022provably,
  title={Provably efficient reinforcement learning in decentralized general-sum {M}arkov games},
  author={Mao, Weichao and Ba{\c{s}}ar, Tamer},
  journal={Dynamic Games and Applications},
  pages={1--22},
  year={2022},
  publisher={Springer}
}

@book{nisan2007algorithmic,
  title={Algorithmic Game Theory},
  author={Nisan, Noam and Roughgarden, Tim and Tardos, Eva and Vazirani, Vijay V},
  year={2007},
  publisher={Cambridge University Press}
}

@inproceedings{rubinstein2016settling,
  title={Settling the complexity of computing approximate two-player {N}ash equilibria},
  author={Rubinstein, Aviad},
  booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={258--265},
  year={2016},
  organization={IEEE}
}

@article{fox2021independent,
  title={Independent Natural Policy Gradient Always Converges in {M}arkov Potential Games},
  author={Fox, Roy and McAleer, Stephen and Overman, Will and Panageas, Ioannis},
  journal={arXiv preprint arXiv:2110.10614},
  year={2021}
}

@inproceedings{macua2018learning,
  title={Learning Parametric Closed-Loop Policies for {M}arkov Potential Games},
  author={Macua, Sergio Valcarcel and Zazo, Javier and Zazo, Santiago},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{mguni2021learning,
  title={Learning in Nonzero-Sum Stochastic Games with Potentials},
  author={Mguni, David and Wu, Yutong and Du, Yali and Yang, Yaodong and Wang, Ziyi and Li, Minne and Wen, Ying and Jennings, Joel and Wang, Jun},
  journal={arXiv preprint arXiv:2103.09284},
  year={2021}
}

@inproceedings{seuken2007improved,
  title={Improved memory-bounded dynamic programming for decentralized {POMDP}s},
  author={Seuken, Sven and Zilberstein, Shlomo},
  booktitle={Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence},
  pages={344--351},
  year={2007}
}