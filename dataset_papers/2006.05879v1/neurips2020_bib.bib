@inproceedings{hren2008optimistic,
	title = {{Optimistic planning of deterministic systems}},
	year = {2008},
	booktitle = {European Workshop on Reinforcement Learning},
	author = {Hren, Jean-Francois and Munos, Rémi}
}

@inproceedings{coquelin2007bandit,
	title = {{Bandit algorithms for tree search}},
	year = {2007},
	booktitle = {Uncertainty in Artificial Intelligence},
	author = {Coquelin, Pierre-Arnaud and Munos, Rémi},
	url = {https://arxiv.org/pdf/1408.2028.pdf}
}


@inproceedings{
hamrick2019combining,
title="{Combining Q-Learning and Search with Amortized Value Estimates}",
author={Jessica B. Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Tobias Pfaff and Theophane Weber and Lars Buesing and Peter W. Battaglia},
booktitle={International Conference on Learning Representations},
year={2020}
}



@book{cover2012elements,
  title={Elements of information theory},
  author={Cover, Thomas M and Thomas, Joy A},
  year={2012},
  publisher={John Wiley \& Sons}
}


@article{de2004self,
  title={Self-normalized processes: exponential inequalities, moment bounds and iterated logarithm laws},
  author={de la Pena, Victor H and Klass, Michael J and Lai, Tze Leung},
  journal={Annals of probability},
  pages={1902--1933},
  year={2004},
  publisher={JSTOR}
}

@inproceedings{garivier2011kl,
  title="{The KL-UCB algorithm for bounded stochastic bandits and beyond}",
  author={Garivier, Aur{\'e}lien and Capp{\'e}, Olivier},
  booktitle={Proceedings of the 24th annual conference on learning theory},
  pages={359--376},
  year={2011}
}

@Article{KLUCBJournal,
  Title                    = {{{K}ullback-{L}eibler upper confidence bounds for optimal sequential allocation}},
  Author                   = {Capp{\'e}, O. and Garivier, A. and Maillard, O-A. and Munos, R. and Stoltz, G.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {1516--1541},
  Volume                   = {41(3)}
}

@inproceedings{dann2017unifying,
  title="{Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning}",
  author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5713--5723},
  year={2017}
}


@article{garivier2018kl,
  title="{KL-UCB-switch: optimal regret bounds for stochastic bandits from both a distribution-dependent and a distribution-free viewpoints}",
  author={Garivier, Aur{\'e}lien and Hadiji, H{\'e}di and Menard, Pierre and Stoltz, Gilles},
  journal={arXiv preprint arXiv:1805.05071},
  year={2018}
}

@Book{Puterman94MDP,
  Title                    = {{Markov Decision Processes. Discrete Stochastic. Dynamic Programming.}},
  Author                   = {Puterman, M.L.},
  Publisher                = {Wiley},
  Year                     = {1994}
}

@Book{SurveyRemiMCTS,
  Title                    = "{From bandits to Monte-Carlo Tree Search: The optimistic principle applied to optimization and planning}",
  Author                   = {Munos, R.},
  Publisher                = {Foundations and Trends in Machine Learning},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {7}
}

@inproceedings{SmoothCruiser19,
  author    = {Jean{-}Bastien Grill and
               Omar Darwiche Domingues and
               Pierre M{\'{e}}nard and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = "{Planning in entropy-regularized Markov decision processes and games}",
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2019}
}

@inproceedings{Huang17StructuredBAI,
  author    = {Ruitong Huang and
               Mohammad M. Ajallooeian and
               Csaba Szepesv{\'{a}}ri and
               Martin M{\"{u}}ller},
  title     = "{Structured Best Arm Identification with Fixed Confidence}",
  booktitle = {International Conference on Algorithmic Learning Theory (ALT)},
  year      = {2017}
}

@inproceedings{BAIMCTS17,
  author    = {Emilie Kaufmann and
               Wouter M. Koolen},
  title     = {{M}Onte-{C}Arlo Tree Search by Best Arm Identification},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2017},
}

@InProceedings{Kocsis06UCT,
  Title                    = "{Bandit Based Monte-Carlo Planning}",
  Author                   = {Kocsis, Levente and Szepesv\'{a}ri, Csaba},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning (ECML)},
  Year                     = {2006}
}

@book{BanditBook,
author = {Lattimore, Tor and Szepesvari, Csaba},
publisher = {Cambridge University Press},
title = {{Bandit Algorithms}},
year = {2019}
}

@Article{Aueral02,
  Title                    = {{Finite-time analysis of the multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Fischer, P.},
  Journal                  = {Machine Learning},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {235--256},
  Volume                   = {47},
  Publisher                = {Springer}
}

@article{UCRL10,
  author    = {Thomas Jaksch and
               Ronald Ortner and
               Peter Auer},
  title     = {Near-optimal Regret Bounds for Reinforcement Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {11},
  pages     = {1563--1600},
  year      = {2010}
}


@inproceedings{Tolpin12SRMCTS,
  author    = {David Tolpin and
               Solomon Eyal Shimony},
  title     = {{MCTS} Based on Simple Regret},
  booktitle = {Proceedings of the Twenty-Sixth {AAAI} Conference on Artificial Intelligence,
               July 22-26, 2012, Toronto, Ontario, Canada.},
  year      = {2012}
}

@inproceedings{Pepels14SimpleMCTS,
  author    = {Tom Pepels and
               Tristan Cazenave and
               Mark H. M. Winands and
               Marc Lanctot},
  title     = "{Minimizing Simple and Cumulative Regret in Monte-Carlo Tree Search}",
  booktitle = {Third Workshop on Computer Games (CGW)},
  pages     = {1--15},
  year      = {2014}
}

@article{Feldman14BRUE,
  author    = {Zohar Feldman and
               Carmel Domshlak},
  title     = "{Simple Regret Optimization in Online Planning for Markov Decision
               Processes}",
  journal   = {Journal of Artifial Intelligence Research},
  volume    = {51},
  pages     = {165--205},
  year      = {2014}
}



@article{Kearns02SS,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = "{A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov
               Decision Processes}",
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {193--208},
  year      = {2002}
}

@InProceedings{STOP14,
  Title                    = "{Optimistic Planning in Markov Decision Processes using a generative model}",
  Author                   = {Szorenyi, B. and Kedenburg, G. and Munos, R.},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2014}
}

@Book{SuttonBarto98,
  Title                    = "{Reinforcement Learning: an Introduction}",
  Author                   = {Sutton, R. and Barto, A.},
  Publisher                = {MIT press},
  Year                     = {1998},

  Owner                    = {emilie},
  Timestamp                = {2016.11.07}
}


@article{AlphaZero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = "{A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play}",
  journal   = {Science},
  volume    = {362},
  issue = {6419},
  page = {1140-1144},
  year      = {2018},
}

@article{MuZero,
  author    = {Julian Schrittwieser and
               Ioannis Antonoglou and
               Thomas Hubert and
               Karen Simonyan and
               Laurent Sifre and
               Simon Schmitt and
               Arthur Guez and
               Edward Lockhart and
               Demis Hassabis and
               Thore Graepel and
               Timothy P. Lillicrap and
               David Silver},
  title     = "{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}",
  journal   = {arXiv:1911.08265},
  year      = {2019}
}


@Article{SurveyMCTS12,
  Title                    = "{A Survey of Monte Carlo Tree Search Methods}",
  Author                   = {Browne, C. and Powley, E. and Whitehouse, D. and Lucas, S. and Cowling, P. and Rohlfshagen, P. and Tavener, S. and Perez, D. and Samothrakis, S. and Colton, S.},
  Journal                  = {IEEE Transactions on Computational Intelligence and AI in games,},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {1-49},
  Volume                   = {4}
}


@InProceedings{TrailBlazer16,
  Title                    = "{Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning}",
  Author                   = {Grill, J.-B. and Valko, M. and Munos, R.},
  Booktitle                = {Neural Information Processing Systems (NIPS)},
  Year                     = {2016}
}



@inproceedings{gabillon2012best,
  title="{Best arm identification: A unified approach to fixed budget and fixed confidence}",
  author={Gabillon, Victor and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3212--3220},
  year={2012}
}


@InProceedings{filippi2010optimism,
  Title                    = {{Optimism in Reinforcement Learning and {K}ullback-{L}eibler Divergence}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Allerton Conference on Communication, Control, and Computing}},
  Year                     = {2010},
}


@inproceedings{bubeck2010open,
  title={Open Loop Optimistic Planning},
  author={Bubeck, S and Munos, R},
  booktitle={Conference on Learning Theory},
  year={2010}
}


@inproceedings{leurent2019practical,
	title={Practical Open-Loop Optimistic Planning},
	author={Edouard Leurent and Odalric-Ambrym Maillard},
	year={2019},
	booktitle={Proceedings of the 19th European Conference on Machine Learning and Principles and Practice (ECML-PKDD)}
}

@inproceedings{busoniu2012optimistic,
  title="{Optimistic planning for Markov decision processes}",
  author={Busoniu, Lucian and Munos, R{\'e}mi},
  booktitle={Artificial Intelligence and Statistics},
  pages={182--189},
  year={2012}
}

@inproceedings{simchowitz2019gaps,
title = "{Non-Asymptotic Gap-Dependent Regret Bounds for Tabular MDPs}",
author = {Simchowitz, Max and Jamieson, Kevin G},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {1153--1162},
year = {2019},
url = {http://papers.nips.cc/paper/8399-non-asymptotic-gap-dependent-regret-bounds-for-tabular-mdps.pdf}
}

@InProceedings{zanette2019gaps,
  title = 	 {Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds},
  author = 	 {Zanette, Andrea and Brunskill, Emma},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7304--7312},
  year = 	 {2019},
}
