\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrieu and Roberts(2009)]{Andrieu09}
Christophe Andrieu and Gareth~O. Roberts.
\newblock The {P}seudo-{M}arginal {A}pproach for {E}fficient {M}onte {C}arlo
  {C}omputations.
\newblock \emph{The Annals of Statistics}, 37\penalty0 (2):\penalty0 697--725,
  2009.

\bibitem[Applebaum(2004)]{David04}
David Applebaum.
\newblock \emph{L\'{e}vy {P}rocesses and {S}tochastic {C}alculus}.
\newblock Cambridge University Press, 2004.

\bibitem[Bakry and \'{e}mery(1985)]{Bakry85}
Dominique Bakry and Michel \'{e}mery.
\newblock Diffusions {H}ypercontractives.
\newblock \emph{S\'{e}minaire de Probabilit\'{e}s XIX 1983/84}, pages 177--206,
  1985.

\bibitem[Bakry et~al.(2008)Bakry, F.~Barthe, and Guillin]{Bakry08}
Dominique Bakry, Patrick~Cattiaux F.~Barthe, and Arnaud Guillin.
\newblock A {S}imple {P}roof of the {P}oincaré {I}nequality for {A} {L}arge
  {C}lass of {P}robability {M}easures.
\newblock \emph{Electron. Comm. Probab.}, 13:\penalty0 60--66, 2008.

\bibitem[Bakry et~al.(2014)Bakry, Gentil, and Ledoux]{Bakry2014}
Dominique Bakry, Ivan Gentil, and Michel Ledoux.
\newblock {A}nalysis and {G}eometry of {M}arkov {D}iffusion {O}perators.
\newblock \emph{Springer}, 2014.

\bibitem[Bardenet et~al.(2017)Bardenet, Doucet, and Holmes]{talldata17}
R\'{e}mi Bardenet, Arnaud Doucet, and Chris Holmes.
\newblock On {M}arkov {C}hain {M}onte {C}arlo {M}ethods for {T}all {D}ata.
\newblock \emph{Journal of Machine Learning Research}, 18:\penalty0 1--43,
  2017.

\bibitem[Bentata and Cont(2012)]{Amel}
Amel Bentata and Rama Cont.
\newblock Mimicking the {M}arginal {D}istributions of a {S}emimartingale.
\newblock \emph{arXiv:0910.3992v5}, 2012.

\bibitem[Beskos et~al.(2006)Beskos, Papaspiliopoulos, Roberts, and
  Fearnhead]{Alexandros06}
Alexandros Beskos, Omiros Papaspiliopoulos, Gareth~O. Roberts, and Paul
  Fearnhead.
\newblock Exact and {C}omputationally {E}fficient {L}ikelihood-{B}ased
  {E}stimation for {D}iscretely {O}bserved {D}iffusion {P}rocesses.
\newblock \emph{Journal of the Royal Statistical Society, Series B},
  68:\penalty0 333--382, 2006.

\bibitem[Bhanot and Kennedy(1985)]{PhysRevLett85}
Gyan~V. Bhanot and Anthony~D. Kennedy.
\newblock Bosonic {L}attice {G}auge {T}heory with {N}oise.
\newblock \emph{Physics Letters B}, 157B:\penalty0 70--76, 1985.

\bibitem[Bossons(1966)]{john66}
John Bossons.
\newblock The {E}ffects of {P}arameter {M}isspecification and {N}on-stationary
  on {T}he {A}pplicability of {A}daptive {F}orecasts.
\newblock \emph{Management Science}, 58:\penalty0 659– 669, 1966.

\bibitem[Cattiaux et~al.(2010)Cattiaux, Guillin, and Wu]{Cattiaux2010}
Patrick Cattiaux, Arnaud Guillin, and Li-Ming Wu.
\newblock A {N}ote on {T}alagrand’s {T}ransportation {I}nequality and
  {L}ogarithmic {S}obolev {I}nequality.
\newblock \emph{Prob. Theory and Rel. Fields}, 148:\penalty0 285--334, 2010.

\bibitem[Ceperley and Dewing(1999)]{penalty_swap99}
David Ceperley and Mark Dewing.
\newblock The {P}enalty {M}ethod for {R}andom {W}alks with {U}ncertain
  {E}nergies.
\newblock \emph{The Journal of Chemical Physics}, 110:\penalty0 9812--9820,
  1999.

\bibitem[Chen et~al.(2015)Chen, Ding, and Carin]{Chen15}
Changyou Chen, Nan Ding, and Lawrence Carin.
\newblock On the {C}onvergence of {S}tochastic {G}radient {MCMC} {A}lgorithms
  with {H}igh-order {I}ntegrators.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 2278--2286, 2015.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{Chen14}
Tianqi Chen, Emily~B. Fox, and Carlos Guestrin.
\newblock Stochastic {G}radient {H}amiltonian {M}onte {C}arlo.
\newblock In \emph{Proc. of the International Conference on Machine Learning
  (ICML)}, 2014.

\bibitem[Chen et~al.(2019)Chen, Chen, Dong, Peng, and
  Wang]{chen2018accelerating}
Yi~Chen, Jinglin Chen, Jing Dong, Jian Peng, and Zhaoran Wang.
\newblock {A}ccelerating {N}onconvex {L}earning via {R}eplica {E}xchange
  {L}angevin {D}iffusion.
\newblock In \emph{Proc. of the International Conference on Learning
  Representation (ICLR)}, 2019.

\bibitem[\c{S}im\c{s}ekli et~al.(2016)\c{S}im\c{s}ekli, Badeau, Cemgil, and
  Richard]{Simsekli2016}
Umut \c{S}im\c{s}ekli, Roland Badeau, A.~Taylan Cemgil, and Ga\"{e} Richard.
\newblock Stochastic {Q}uasi-{N}ewton {L}angevin {M}onte {C}arlo.
\newblock In \emph{Proc. of the International Conference on Machine Learning
  (ICML)}, pages 642--651, 2016.

\bibitem[\c{S}im\c{s}ekli et~al.(2019)\c{S}im\c{s}ekli, Sagun, and
  G\"{u}rb\"{u}zbalaban]{Simsekli2019b}
Umut \c{S}im\c{s}ekli, Levent Sagun, and Mert G\"{u}rb\"{u}zbalaban.
\newblock A {T}ail-{I}ndex {A}nalysis of {S}tochastic {G}radient {N}oise in
  {D}eep {N}eural {N}etworks.
\newblock In \emph{Proc. of the International Conference on Machine Learning
  (ICML)}, 2019.

\bibitem[Deng et~al.(2019)Deng, Zhang, Liang, and Lin]{deng2019}
Wei Deng, Xiao Zhang, Faming Liang, and Guang Lin.
\newblock An {A}daptive {E}mpirical {B}ayesian {M}ethod for {S}parse {D}eep
  {L}earning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Ding et~al.(2014)Ding, Fang, Babbush, Chen, Skeel, and Neven]{Ding14}
Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert~D. Skeel, and
  Hartmut Neven.
\newblock Bayesian {S}ampling {U}sing {S}tochastic {G}radient {T}hermostats.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 3203--3211, 2014.

\bibitem[Dupuis et~al.(2012)Dupuis, Liu, Plattner, and Doll]{Paul12}
Paul Dupuis, Yufei Liu, Nuria Plattner, and J.~D. Doll.
\newblock On the {I}nfinite {S}wapping {L}imit for {P}arallel {T}empering.
\newblock \emph{SIAM J. Multiscale Modeling \& Simulation}, 10, 2012.

\bibitem[Earl and Deem(2005)]{parallel_tempering05}
David~J. Earl and Michael~W. Deem.
\newblock Parallel {T}empering: {T}heory, {A}pplications, and {N}ew
  {P}erspectives.
\newblock \emph{Phys. Chem. Chem. Phys.}, 7:\penalty0 3910--3916, 2005.

\bibitem[Gijbels et~al.(1999)Gijbels, Pope, and Wand]{Gijbels99}
Ir\`{e}ne Gijbels, Alun Pope, and Matt~P. Wand.
\newblock Understanding {E}xponential {S}moothing via {K}ernel {R}egression.
\newblock \emph{Journal of the Royal Statistical Society, Series B},
  61:\penalty0 39– 50, 1999.

\bibitem[Gy\"{o}ngy(1986)]{Gyongy86}
I.~Gy\"{o}ngy.
\newblock Mimicking the {O}ne-dimensional {M}arginal {D}istributions of
  {P}rocesses {H}aving an {I}to {D}ifferential.
\newblock \emph{Probability Theory and Related Fields}, 71:\penalty0 501--516,
  1986.

\bibitem[Kirkpatrick et~al.(1983)Kirkpatrick, Jr, and
  Vecchi]{Kirkpatrick83optimizationby}
Scott Kirkpatrick, D.~Gelatt Jr, and Mario~P. Vecchi.
\newblock Optimization by {S}imulated {A}nnealing.
\newblock \emph{Science}, 220\penalty0 (4598):\penalty0 671--680, 1983.

\bibitem[Korattikara et~al.(2014)Korattikara, Chen, and Welling]{Anoop14}
Anoop Korattikara, Yutian Chen, and Max Welling.
\newblock Austerity in {MCMC} {L}and: {C}utting the {M}etropolis-{H}astings
  {B}udget.
\newblock In \emph{Proc. of the International Conference on Machine Learning
  (ICML)}, 2014.

\bibitem[Lee et~al.(2018)Lee, Risteski, and Ge]{Holden18}
Holden Lee, Andrej Risteski, and Rong Ge.
\newblock Beyond {L}og-concavity: {P}rovable {G}uarantees for {S}ampling
  {M}ulti-modal {D}istributions using {S}imulated {T}empering {L}angevin
  {M}onte {C}arlo.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Li et~al.(2016)Li, Chen, Carlson, and Carin]{Li16}
Chunyuan Li, Changyou Chen, David Carlson, and Lawrence Carin.
\newblock Preconditioned {S}tochastic {G}radient {L}angevin {D}ynamics for
  {D}eep {N}eural {N}etworks.
\newblock In \emph{Proc. of the National Conference on Artificial Intelligence
  (AAAI)}, pages 1788--1794, 2016.

\bibitem[Li et~al.(2019)Li, Wu, Mackey, and Erdogdu]{Li19}
Xuechen Li, Denny Wu, Lester Mackey, and Murat~A. Erdogdu.
\newblock Stochastic {R}unge-{K}utta {A}ccelerates {L}angevin {M}onte {C}arlo
  and {B}eyond.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 7746--7758, 2019.

\bibitem[Li et~al.(2009)Li, Protopopescu, Arnold, Zhang, and Gorin]{PT_SA}
Yaohang Li, Vladimir~A. Protopopescu, Nikita Arnold, Xinyu Zhang, and Andrey
  Gorin.
\newblock Hybrid {P}arallel {T}empering and {S}imulated {A}nnealing {M}ethod.
\newblock \emph{Applied Mathematics and Computation}, 212\penalty0
  (1):\penalty0 216--228, 2009.

\bibitem[Liang et~al.(2007)Liang, Liu, and Carroll]{Liang07}
Faming Liang, Chuanhai Liu, and Raymond~J. Carroll.
\newblock {S}tochastic {A}pproximation in {M}onte {C}arlo {C}omputation.
\newblock \emph{Journal of the American Statistical Association}, 102:\penalty0
  305--320, 2007.

\bibitem[Ma et~al.(2015)Ma, Chen, and Fox]{yian2015}
Yi-An Ma, Tianqi Chen, and Emily~B. Fox.
\newblock A {C}omplete {R}ecipe for {S}tochastic {G}radient {MCMC}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2015.

\bibitem[Mangoubi and Vishnoi(2018)]{Mangoubi18}
Oren Mangoubi and Nisheeth~K. Vishnoi.
\newblock Convex {O}ptimization with {U}nbounded {N}onconvex {O}racles using
  {S}imulated {A}nnealing.
\newblock In \emph{Proc. of Conference on Learning Theory (COLT)}, 2018.

\bibitem[Marinari and Parisi(1992)]{ST}
E~Marinari and G~Parisi.
\newblock Simulated {T}empering: {A} {N}ew {M}onte {C}arlo {S}cheme.
\newblock \emph{Europhysics Letters ({EPL})}, 19\penalty0 (6):\penalty0
  451--458, 1992.

\bibitem[Martino et~al.(2016)Martino, Elvira, Luengo, Corander, and
  Louzada]{OPT_SA}
L.~Martino, V.~Elvira, D.~Luengo, J.~Corander, and F.~Louzada.
\newblock Orthogonal {P}arallel {MCMC} {M}ethods for {S}ampling and
  {O}ptimization.
\newblock \emph{Digital Signal Processing}, 58:\penalty0 64--84, 2016.

\bibitem[Nicholls et~al.(2012)Nicholls, Fox, and Watt]{Geoff12}
Geoff~K. Nicholls, Colin Fox, and Alexis~Muir Watt.
\newblock Coupled {MCMC} with a {R}andomized {A}cceptance {P}robability.
\newblock \emph{ArXiv e-prints}, 2012.

\bibitem[Quiroz et~al.(2019)Quiroz, Kohn, Villani, and Tran]{Matias19}
Matias Quiroz, Robert Kohn, Mattias Villani, and Minh-Ngoc Tran.
\newblock {S}peeding {U}p {MCMC} by {E}fficient {D}ata {S}ubsampling.
\newblock \emph{Journal of the American Statistical Association}, 114:\penalty0
  831--843, 2019.

\bibitem[Raginsky et~al.(2017)Raginsky, Rakhlin, and Telgarsky]{Maxim17}
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky.
\newblock Non-convex {L}earning via {S}tochastic {G}radient {L}angevin
  {D}ynamics: a {N}onasymptotic {A}nalysis.
\newblock In \emph{Proc. of Conference on Learning Theory (COLT)}, June 2017.

\bibitem[Robbins and Monro(1951)]{Robbins51}
Herbert Robbins and Sutton Monro.
\newblock A {S}tochastic {A}pproximation {M}ethod.
\newblock \emph{The Annals of Mathematical Statistics}, 22\penalty0
  (3):\penalty0 400--407, 1951.

\bibitem[Saatci and Wilson(2017)]{Saatci17}
Yunus Saatci and Andrew~G Wilson.
\newblock {B}ayesian {GAN}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 3622--3631, 2017.

\bibitem[Sato and Nakagawa(2014)]{Issei14}
Issei Sato and Hiroshi Nakagawa.
\newblock Approximation {A}nalysis of {S}tochastic {G}radient {L}angevin
  {D}ynamics by using {F}okker-{P}lanck {E}quation and {I}t\^{o} {P}rocess.
\newblock In \emph{Proc. of the International Conference on Machine Learning
  (ICML)}, pages 982--990, 2014.

\bibitem[Seita et~al.(2017)Seita, Pan, Chen, and Canny]{Daniel17}
Daniel Seita, Xinlei Pan, Haoyu Chen, and John Canny.
\newblock An {E}fficient {M}inibatch {A}cceptance {T}est for
  {M}etropolis-{H}astings.
\newblock In \emph{Proc. of the Conference on Uncertainty in Artificial
  Intelligence (UAI)}, 2017.

\bibitem[Swendsen and Wang(1986)]{PhysRevLett86}
Robert~H. Swendsen and Jian-Sheng Wang.
\newblock Replica {M}onte {C}arlo {S}imulation of {S}pin-{G}lasses.
\newblock \emph{Phys. Rev. Lett.}, 57:\penalty0 2607--2609, 1986.

\bibitem[Teh et~al.(2016)Teh, Thi{\' e}ry, and Vollmer]{Teh16}
Yee~Whye Teh, Alexandre Thi{\' e}ry, and Sebastian Vollmer.
\newblock Consistency and {F}luctuations for {S}tochastic {G}radient {L}angevin
  {D}ynamics.
\newblock \emph{Journal of Machine Learning Research}, 17:\penalty0 1--33,
  2016.

\bibitem[Welling and Teh(2011)]{Welling11}
Max Welling and Yee~Whye Teh.
\newblock {B}ayesian {L}earning via {S}tochastic {G}radient {L}angevin
  {D}ynamics.
\newblock In \emph{Proc. of the International Conference on Machine Learning
  (ICML)}, pages 681--688, 2011.

\bibitem[Wong and Liang(1997)]{wong97}
Wing~Hung Wong and Faming Liang.
\newblock Dynamic {W}eighting in {M}onte {C}arlo and {O}ptimization.
\newblock \emph{Proc. Natl. Acad. Sci.}, 94:\penalty0 14220--14224, 1997.

\bibitem[Xu et~al.(2018)Xu, Chen, Zou, and Gu]{Xu18}
Pan Xu, Jinghui Chen, Difan Zou, and Quanquan Gu.
\newblock Global {C}onvergence of {L}angevin {D}ynamics {B}ased {A}lgorithms
  for {N}onconvex {O}ptimization.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Yin and Zhu(2010)]{yin_zhu_10}
George Yin and Chao Zhu.
\newblock \emph{Hybrid {S}witching {D}iffusions: {P}roperties and
  {A}pplications}.
\newblock Springer, 2010.

\bibitem[Zhang et~al.(2017)Zhang, Liang, and Charikar]{Yuchen17}
Yuchen Zhang, Percy Liang, and Moses Charikar.
\newblock A {H}itting {T}ime {A}nalysis of {S}tochastic {G}radient {L}angevin
  {D}ynamics.
\newblock In \emph{Proc. of Conference on Learning Theory (COLT)}, pages
  1980--2022, 2017.

\end{thebibliography}
