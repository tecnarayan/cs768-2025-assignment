\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc,
  Mensch, Millican, Reynolds, Ring, Rutherford, Cabi, Han, Gong, Samangooei,
  Monteiro, Menick, Borgeaud, Brock, Nematzadeh, Sharifzadeh, Binkowski,
  Barreira, Vinyals, Zisserman, and Simonyan]{Flamingo2022arxiv}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds,
  Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina
  Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew
  Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo
  Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{arXiv preprint arXiv:2204.14198}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom~B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Cao et~al.(2017)Cao, Simon, Wei, and Sheikh]{cao2017realtime}
Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh.
\newblock Realtime multi-person 2d pose estimation using part affinity fields.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7291--7299, 2017.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}, pages 213--229.
  Springer, 2020.

\bibitem[Castrejon et~al.(2017)Castrejon, Kundu, Urtasun, and
  Fidler]{castrejon2017annotating}
Lluis Castrejon, Kaustav Kundu, Raquel Urtasun, and Sanja Fidler.
\newblock Annotating object instances with a polygon-rnn.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5230--5238, 2017.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International Conference on Machine Learning}, pages
  1597--1607. PMLR, 2020.

\bibitem[Chen et~al.(2021{\natexlab{a}})Chen, Saxena, Li, Fleet, and
  Hinton]{chen2021pix2seq}
Ting Chen, Saurabh Saxena, Lala Li, David~J Fleet, and Geoffrey Hinton.
\newblock Pix2seq: A language modeling framework for object detection.
\newblock \emph{arXiv preprint arXiv:2109.10852}, 2021{\natexlab{a}}.

\bibitem[Chen et~al.(2021{\natexlab{b}})Chen, Du, Yang, Beyer, Zhai, Lin, Chen,
  Li, Song, Wang, et~al.]{chen2021simple}
Wuyang Chen, Xianzhi Du, Fan Yang, Lucas Beyer, Xiaohua Zhai, Tsung-Yi Lin,
  Huizhong Chen, Jing Li, Xiaodan Song, Zhangyang Wang, et~al.
\newblock A simple single-scale vision transformer for object localization and
  instance segmentation.
\newblock \emph{arXiv preprint arXiv:2112.09747}, 2021{\natexlab{b}}.

\bibitem[Chen et~al.(2015)Chen, Fang, Lin, Vedantam, Gupta, Doll{\'a}r, and
  Zitnick]{chen2015microsoft}
Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
  Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock \emph{arXiv preprint arXiv:1504.00325}, 2015.

\bibitem[Cheng et~al.(2021)Cheng, Schwing, and Kirillov]{cheng2021per}
Bowen Cheng, Alex Schwing, and Alexander Kirillov.
\newblock Per-pixel classification is not all you need for semantic
  segmentation.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Ghiasi et~al.(2021)Ghiasi, Zoph, Cubuk, Le, and Lin]{ghiasi2021multi}
Golnaz Ghiasi, Barret Zoph, Ekin~D Cubuk, Quoc~V Le, and Tsung-Yi Lin.
\newblock Multi-task self-training for learning general representations.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8856--8865, 2021.

\bibitem[Girshick(2015)]{girshick2015fast}
Ross Girshick.
\newblock Fast r-cnn.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 1440--1448, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 770--778, 2016.

\bibitem[He et~al.(2017)He, Gkioxari, Doll{\'a}r, and Girshick]{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 2961--2969, 2017.

\bibitem[Holtzman et~al.(2019)Holtzman, Buys, Du, Forbes, and
  Choi]{holtzman2019curious}
Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and Yejin Choi.
\newblock The curious case of neural text degeneration.
\newblock \emph{arXiv preprint arXiv:1904.09751}, 2019.

\bibitem[Jaegle et~al.(2021{\natexlab{a}})Jaegle, Borgeaud, Alayrac, Doersch,
  Ionescu, Ding, Koppula, Zoran, Brock, Shelhamer,
  et~al.]{jaegle2021perceiverb}
Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin
  Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan
  Shelhamer, et~al.
\newblock Perceiver io: A general architecture for structured inputs \&
  outputs.
\newblock \emph{arXiv preprint arXiv:2107.14795}, 2021{\natexlab{a}}.

\bibitem[Jaegle et~al.(2021{\natexlab{b}})Jaegle, Gimeno, Brock, Vinyals,
  Zisserman, and Carreira]{jaegle2021perceivera}
Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and
  Joao Carreira.
\newblock Perceiver: General perception with iterative attention.
\newblock In \emph{International Conference on Machine Learning}, pages
  4651--4664. PMLR, 2021{\natexlab{b}}.

\bibitem[Kokkinos(2017)]{kokkinos2017ubernet}
Iasonas Kokkinos.
\newblock Ubernet: Training a universal convolutional neural network for low-,
  mid-, and high-level vision using diverse datasets and limited memory.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6129--6138, 2017.

\bibitem[Kolesnikov et~al.(2020)Kolesnikov, Beyer, Zhai, Puigcerver, Yung,
  Gelly, and Houlsby]{kolesnikov2020big}
Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung,
  Sylvain Gelly, and Neil Houlsby.
\newblock Big transfer (bit): General visual representation learning.
\newblock In \emph{European conference on computer vision}, pages 491--507.
  Springer, 2020.

\bibitem[Kolesnikov et~al.(2022)Kolesnikov, Pinto, Beyer, Zhai, Harmsen, and
  Houlsby]{kolesnikov2022uvim}
Alexander Kolesnikov, Andr{\'e}~Susano Pinto, Lucas Beyer, Xiaohua Zhai,
  Jeremiah Harmsen, and Neil Houlsby.
\newblock Uvim: A unified modeling approach for vision with learned guiding
  codes.
\newblock \emph{arXiv preprint arXiv:2205.10337}, 2022.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  25:\penalty0 1097--1105, 2012.

\bibitem[LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard,
  and Jackel]{lecun1989backpropagation}
Yann LeCun, Bernhard Boser, John~S Denker, Donnie Henderson, Richard~E Howard,
  Wayne Hubbard, and Lawrence~D Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock \emph{Neural computation}, 1\penalty0 (4):\penalty0 541--551, 1989.

\bibitem[Li et~al.(2021)Li, Xie, Chen, Dollar, He, and
  Girshick]{li2021benchmarking}
Yanghao Li, Saining Xie, Xinlei Chen, Piotr Dollar, Kaiming He, and Ross
  Girshick.
\newblock Benchmarking detection transfer learning with vision transformers.
\newblock \emph{arXiv preprint arXiv:2111.11429}, 2021.

\bibitem[Li et~al.(2022)Li, Mao, Girshick, and He]{li2022exploring}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock \emph{arXiv preprint arXiv:2203.16527}, 2022.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European Conference on Computer Vision}, pages 740--755.
  Springer, 2014.

\bibitem[Lin et~al.(2017{\natexlab{a}})Lin, Doll{\'a}r, Girshick, He,
  Hariharan, and Belongie]{lin2017feature}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  pattern recognition}, pages 2117--2125, 2017{\natexlab{a}}.

\bibitem[Lin et~al.(2017{\natexlab{b}})Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 2980--2988, 2017{\natexlab{b}}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022, 2021.

\bibitem[Lu et~al.(2020)Lu, Goswami, Rohrbach, Parikh, and Lee]{lu202012}
Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, and Stefan Lee.
\newblock 12-in-1: Multi-task vision and language representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10437--10446, 2020.

\bibitem[Lu et~al.(2022)Lu, Clark, Zellers, Mottaghi, and
  Kembhavi]{lu2022unified}
Jiasen Lu, Christopher Clark, Rowan Zellers, Roozbeh Mottaghi, and Aniruddha
  Kembhavi.
\newblock Unified-io: A unified model for vision, language, and multi-modal
  tasks.
\newblock \emph{arXiv preprint arXiv:2206.08916}, 2022.

\bibitem[Pan et~al.(2020)Pan, Yao, Li, and Mei]{pan2020x}
Yingwei Pan, Ting Yao, Yehao Li, and Tao Mei.
\newblock X-linear attention networks for image captioning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10971--10980, 2020.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Raffel et~al.(2019)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{raffel2019exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{arXiv preprint arXiv:1910.10683}, 2019.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov,
  Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, Eccles, Bruce, Razavi,
  Edwards, Heess, Chen, Hadsell, Vinyals, Bordbar, and de~Freitas]{Gato2022}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~Gomez Colmenarejo, Alexander
  Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
  Jost~Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards,
  Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and
  Nando de~Freitas.
\newblock A generalist agent.
\newblock \emph{arXiv arXiv:2205.06175}, 2022.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  28:\penalty0 91--99, 2015.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{International Conference on Medical image computing and
  computer-assisted intervention}, pages 234--241. Springer, 2015.

\bibitem[Shao et~al.(2019)Shao, Li, Zhang, Peng, Yu, Zhang, Li, and
  Sun]{shao2019objects365}
Shuai Shao, Zeming Li, Tianyuan Zhang, Chao Peng, Gang Yu, Xiangyu Zhang, Jing
  Li, and Jian Sun.
\newblock Objects365: A large-scale, high-quality dataset for object detection.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 8430--8439, 2019.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 2556--2565,
  2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5998--6008, 2017.

\bibitem[Wang et~al.(2022)Wang, Yang, Men, Lin, Bai, Li, Ma, Zhou, Zhou, and
  Yang]{wang2022unifying}
Peng Wang, An~Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma,
  Chang Zhou, Jingren Zhou, and Hongxia Yang.
\newblock Unifying architectures, tasks, and modalities through a simple
  sequence-to-sequence learning framework.
\newblock \emph{arXiv preprint arXiv:2202.03052}, 2022.

\bibitem[Wang et~al.(2018)Wang, Girshick, Gupta, and He]{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7794--7803, 2018.

\end{thebibliography}
