\begin{thebibliography}{10}

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em NIPS}, 2014.

\bibitem{arjovsky2017towards}
Martin Arjovsky and L{\'e}on Bottou.
\newblock Towards principled methods for training generative adversarial
  networks.
\newblock In {\em ICLR}, 2017.

\bibitem{nowozin2016f}
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock In {\em NIPS}, 2016.

\bibitem{kaae2016amortised}
Casper Kaae~S{\o}nderby, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc
  Husz{\'a}r.
\newblock Amortised map inference for image super-resolution.
\newblock {\em ICLR}, 2017.

\bibitem{mao2016least}
Xudong Mao, Qing Li, Haoran Xie, Raymond~YK Lau, and Zhen Wang.
\newblock Least squares generative adversarial networks.
\newblock {\em arXiv:1611.04076}, 2016.

\bibitem{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein gan.
\newblock {\em ICML}, 2017.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron
  Courville.
\newblock Improved training of wasserstein gans.
\newblock {\em arXiv:1704.00028}, 2017.

\bibitem{mroueh2017mcgan}
Youssef Mroueh, Tom Sercu, and Vaibhava Goel.
\newblock Mcgan: Mean and covariance feature matching gan.
\newblock {\em arXiv:1702.08398 ICML}, 2017.

\bibitem{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training gans.
\newblock {\em NIPS}, 2016.

\bibitem{muller1997integral}
Alfred M{\"u}ller.
\newblock Integral probability metrics and their generating classes of
  functions.
\newblock {\em Advances in Applied Probability}, 1997.

\bibitem{IPMemp}
Bharath~K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard
  Sch\"{o}lkopf, and Gert R.~G. Lanckriet.
\newblock On the empirical estimation of integral probability metrics.
\newblock {\em Electronic Journal of Statistics}, 2012.

\bibitem{mohamed2016learning}
Shakir Mohamed and Balaji Lakshminarayanan.
\newblock Learning in implicit generative models.
\newblock {\em arXiv:1610.03483}, 2016.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em JMLR}, 2012.

\bibitem{li2015generative}
Yujia Li, Kevin Swersky, and Richard Zemel.
\newblock Generative moment matching networks.
\newblock In {\em ICML}, 2015.

\bibitem{dziugaite2015training}
Gintare~Karolina Dziugaite, Daniel~M Roy, and Zoubin Ghahramani.
\newblock Training generative neural networks via maximum mean discrepancy
  optimization.
\newblock {\em UAI}, 2015.

\bibitem{harchaoui2008testing_nips}
Za{\"\i}d Harchaoui, Francis~R Bach, and Eric Moulines.
\newblock Testing for homogeneity with kernel fisher discriminant analysis.
\newblock In {\em NIPS}, 2008.

\bibitem{bartlett2005}
Peter~L. Bartlett, Olivier Bousquet, and Shahar Mendelson.
\newblock Local rademacher complexities.
\newblock {\em Ann. Statist.}, 2005.

\bibitem{Nocedal2006NO}
J.~Nocedal and S.~J. Wright.
\newblock {\em Numerical Optimization}.
\newblock Springer, 2nd edition, 2006.

\bibitem{kingma2014adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em ICLR}, 2015.

\bibitem{cifar10}
A.~Krizhevsky and G.~Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Master's thesis}, 2009.

\bibitem{yu2015lsun}
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong
  Xiao.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock {\em arXiv:1506.03365}, 2015.

\bibitem{liu2015deep}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In {\em ICCV}, 2015.

\bibitem{radford2015unsupervised}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock {\em arXiv:1511.06434}, 2015.

\bibitem{dumoulin2016adversarially}
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky,
  Olivier Mastropietro, and Aaron Courville.
\newblock Adversarially learned inference.
\newblock {\em ICLR}, 2017.

\bibitem{theis2015note}
Lucas Theis, A{\"a}ron van~den Oord, and Matthias Bethge.
\newblock A note on the evaluation of generative models.
\newblock {\em ICLR}, 2016.

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{berthelot2017began}
David Berthelot, Tom Schumm, and Luke Metz.
\newblock Began: Boundary equilibrium generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1703.10717}, 2017.

\bibitem{huang2016stacked}
Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, and Serge Belongie.
\newblock Stacked generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1612.04357}, 2016.

\bibitem{dai2017calibrating}
Zihang Dai, Amjad Almahairi, Philip Bachman, Eduard Hovy, and Aaron Courville.
\newblock Calibrating energy-based generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1702.01691}, 2017.

\bibitem{warde2017improving}
D~Warde-Farley and Y~Bengio.
\newblock Improving generative adversarial networks with denoising feature
  matching.
\newblock {\em ICLR submissions}, 8, 2017.

\bibitem{wang2016learning}
Dilin Wang and Qiang Liu.
\newblock Learning to draw samples: With application to amortized mle for
  generative adversarial learning.
\newblock {\em arXiv preprint arXiv:1611.01722}, 2016.

\bibitem{odena2016conditional}
Augustus Odena, Christopher Olah, and Jonathon Shlens.
\newblock Conditional image synthesis with auxiliary classifier gans.
\newblock {\em arXiv preprint arXiv:1610.09585}, 2016.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock {\em Proc. ICML}, 2015.

\bibitem{springenberg2015unsupervised}
Jost~Tobias Springenberg.
\newblock Unsupervised and semi-supervised learning with categorical generative
  adversarial networks.
\newblock {\em arXiv:1511.06390}, 2015.

\bibitem{metrictensor}
Alessandra Tosi, S{\o}ren Hauberg, Alfredo Vellido, and Neil~D. Lawrence.
\newblock Metrics for probabilistic geometries.
\newblock 2014.

\bibitem{Sriperumbudur2009OnIP}
Bharath~K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Scholkopf,
  and Gert R.~G. Lanckriet.
\newblock On integral probability metrics, $\phi$-divergences and binary
  classification.
\newblock 2009.

\bibitem{convexbook}
I.~Ekeland and T.~Turnbull.
\newblock {\em Infinite-dimensional Optimization and Convexity}.
\newblock The University of Chicago Press, 1983.

\bibitem{glorot2010understanding}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em International conference on artificial intelligence and
  statistics}, pages 249--256, 2010.

\bibitem{he2015delving}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock {\em arXiv preprint arXiv:1502.01852}, 2015.

\end{thebibliography}
