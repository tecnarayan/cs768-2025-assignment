\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alaiz-Rodr{\'\i}guez \& Japkowicz(2008)Alaiz-Rodr{\'\i}guez and
  Japkowicz]{alaiz2008assessing}
Alaiz-Rodr{\'\i}guez, R. and Japkowicz, N.
\newblock Assessing the impact of changing environments on classifier
  performance.
\newblock In \emph{Conference of the Canadian Society for Computational Studies
  of Intelligence}, pp.\  13--24. Springer, 2008.

\bibitem[Bai et~al.(2021)Bai, Yang, Zhang, and Mei]{bai2021directional}
Bai, Y., Yang, Y., Zhang, W., and Mei, T.
\newblock Directional self-supervised learning for risky image augmentations.
\newblock \emph{arXiv preprint arXiv:2110.13555}, 2021.

\bibitem[Brendel \& Bethge(2019)Brendel and Bethge]{brendel2018approximating}
Brendel, W. and Bethge, M.
\newblock Approximating {CNN}s with bag-of-local-features models works
  surprisingly well on imagenet.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=SkfMWhAqYQ}.

\bibitem[Carlucci et~al.(2019)Carlucci, D'Innocente, Bucci, Caputo, and
  Tommasi]{carlucci2019domain}
Carlucci, F.~M., D'Innocente, A., Bucci, S., Caputo, B., and Tommasi, T.
\newblock Domain generalization by solving jigsaw puzzles.
\newblock In \emph{CVPR}, 2019.

\bibitem[Carratino et~al.(2020)Carratino, Ciss{\'e}, Jenatton, and
  Vert]{carratino2020mixup}
Carratino, L., Ciss{\'e}, M., Jenatton, R., and Vert, J.-P.
\newblock On mixup regularization.
\newblock \emph{arXiv preprint arXiv:2006.06049}, 2020.

\bibitem[Chapelle et~al.(2001)Chapelle, Weston, Bottou, and
  Vapnik]{chapelle2001vicinal}
Chapelle, O., Weston, J., Bottou, L., and Vapnik, V.
\newblock Vicinal risk minimization.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  416--422, 2001.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pp.\
  1597--1607. PMLR, 2020.

\bibitem[Chun et~al.(2020)Chun, Oh, Yun, Han, Choe, and Yoo]{chun2020empirical}
Chun, S., Oh, S.~J., Yun, S., Han, D., Choe, J., and Yoo, Y.
\newblock An empirical evaluation on robustness and uncertainty of
  regularization methods.
\newblock \emph{arXiv preprint arXiv:2003.03879}, 2020.

\bibitem[Cieslak \& Chawla(2009)Cieslak and Chawla]{cieslak2009framework}
Cieslak, D.~A. and Chawla, N.~V.
\newblock A framework for monitoring classifiersâ€™ performance: when and why
  failure occurs?
\newblock \emph{Knowledge and Information Systems}, 18\penalty0 (1):\penalty0
  83--108, 2009.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017improved}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Engstrom et~al.(2019)Engstrom, Tran, Tsipras, Schmidt, and
  Madry]{engstrom2019exploring}
Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry, A.
\newblock Exploring the landscape of spatial robustness.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1802--1811. PMLR, 2019.

\bibitem[Fawzi \& Frossard(2016)Fawzi and Frossard]{BMVC2016_137}
Fawzi, A. and Frossard, P.
\newblock Measuring the effect of nuisance variables on classifiers.
\newblock In Richard C.~Wilson, E. R.~H. and Smith, W. A.~P. (eds.),
  \emph{Proceedings of the British Machine Vision Conference (BMVC)}, pp.\
  137.1--137.12. BMVA Press, September 2016.
\newblock ISBN 1-901725-59-6.
\newblock \doi{10.5244/C.30.137}.
\newblock URL \url{https://dx.doi.org/10.5244/C.30.137}.

\bibitem[Feldman \& Zhang(2020)Feldman and Zhang]{feldman2020neural}
Feldman, V. and Zhang, C.
\newblock What neural networks memorize and why: Discovering the long tail via
  influence estimation.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2018imagenet}
Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.~A., and
  Brendel, W.
\newblock Imagenet-trained {CNN}s are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=Bygh9j09KX}.

\bibitem[Gontijo-Lopes et~al.(2020)Gontijo-Lopes, Smullin, Cubuk, and
  Dyer]{gontijo2020affinity}
Gontijo-Lopes, R., Smullin, S.~J., Cubuk, E.~D., and Dyer, E.
\newblock Affinity and diversity: Quantifying mechanisms of data augmentation.
\newblock \emph{arXiv preprint arXiv:2002.08973}, 2020.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Harris et~al.(2020)Harris, Marcu, Painter, Niranjan,
  Pr{\"u}gel-Bennett, and Hare]{harris2020understanding}
Harris, E., Marcu, A., Painter, M., Niranjan, M., Pr{\"u}gel-Bennett, A., and
  Hare, J.
\newblock Understanding and enhancing mixed sample data augmentation.
\newblock \emph{arXiv preprint arXiv:2002.12047}, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016identity}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European conference on computer vision}, pp.\  630--645.
  Springer, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  9729--9738, 2020.

\bibitem[Hooker et~al.(2019)Hooker, Erhan, Kindermans, and
  Kim]{hooker2019benchmark}
Hooker, S., Erhan, D., Kindermans, P.-J., and Kim, B.
\newblock A benchmark for interpretability methods in deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9737--9748, 2019.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4700--4708, 2017.

\bibitem[Husz\'ar(2017)]{huszar2017}
Husz\'ar, F.
\newblock mixup: Data-dependent data augmentation, 2017.
\newblock URL
  \url{http://www.inference.vc/mixup-data-dependent-data-augmentation/}.

\bibitem[Kokhlikyan et~al.(2020)Kokhlikyan, Miglani, Martin, Wang, Alsallakh,
  Reynolds, Melnikov, Kliushkina, Araya, Yan, et~al.]{kokhlikyan2020captum}
Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds, J.,
  Melnikov, A., Kliushkina, N., Araya, C., Yan, S., et~al.
\newblock Captum: A unified and generic model interpretability library for
  pytorch.
\newblock \emph{arXiv preprint arXiv:2009.07896}, 2020.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Master's thesis, University of Toronto, 2009.

\bibitem[Lassance et~al.(2020)Lassance, B{\'e}thune, Bontonou, Hamidouche, and
  Gripon]{lassance2020ranking}
Lassance, C., B{\'e}thune, L., Bontonou, M., Hamidouche, M., and Gripon, V.
\newblock Ranking deep learning generalization using label variation in latent
  geometry graphs.
\newblock \emph{arXiv preprint arXiv:2011.12737}, 2020.

\bibitem[Luo et~al.(2019)Luo, Cai, Zhang, Chen, He, and Wang]{luo2019defective}
Luo, T., Cai, T., Zhang, M., Chen, S., He, D., and Wang, L.
\newblock Defective convolutional layers learn robust {CNN}s.
\newblock \emph{arXiv preprint arXiv:1911.08432}, 2019.

\bibitem[Miller(1995)]{miller1995wordnet}
Miller, G.~A.
\newblock Wordnet: a lexical database for english.
\newblock \emph{Communications of the ACM}, 38:\penalty0 39--41, 1995.

\bibitem[Mummadi et~al.(2021)Mummadi, Subramaniam, Hutmacher, Vitay, Fischer,
  and Metzen]{mummadi2021does}
Mummadi, C.~K., Subramaniam, R., Hutmacher, R., Vitay, J., Fischer, V., and
  Metzen, J.~H.
\newblock Does enhanced shape bias improve neural network robustness to common
  corruptions?
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=yUxUNaj2Sl}.

\bibitem[Natekar \& Sharma(2020)Natekar and Sharma]{natekar2020representation}
Natekar, P. and Sharma, M.
\newblock Representation based complexity measures for predicting
  generalization in deep learning.
\newblock \emph{arXiv preprint arXiv:2012.02775}, 2020.

\bibitem[Rajaei et~al.(2019)Rajaei, Mohsenzadeh, Ebrahimpour, and
  Khaligh-Razavi]{rajaei2019beyond}
Rajaei, K., Mohsenzadeh, Y., Ebrahimpour, R., and Khaligh-Razavi, S.-M.
\newblock Beyond core object recognition: Recurrent processes account for
  object recognition under occlusion.
\newblock \emph{PLoS computational biology}, 15\penalty0 (5):\penalty0
  e1007001, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{ILSVRC15}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Schiff et~al.(2021)Schiff, Quanz, Das, and Chen]{schiff2021gi}
Schiff, Y., Quanz, B., Das, P., and Chen, P.-Y.
\newblock Gi and pal scores: Deep neural network generalization statistics.
\newblock \emph{arXiv preprint arXiv:2104.03469}, 2021.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvaraju2017grad}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra,
  D.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  618--626, 2017.

\bibitem[Shi et~al.(2020)Shi, Zhang, Dai, Zhu, Mu, and
  Wang]{shi2020informative}
Shi, B., Zhang, D., Dai, Q., Zhu, Z., Mu, Y., and Wang, J.
\newblock Informative dropout for robust representation learning: A shape-bias
  perspective.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8828--8839. PMLR, 2020.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{Simonyan15}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Stanford(2015)]{tinyimagenet}
Stanford.
\newblock Tiny imagenet visual recognition challenge, 2015.
\newblock URL \url{https://tiny-imagenet.herokuapp.com/}.

\bibitem[Summers \& Dinneen(2019)Summers and Dinneen]{summers2019improved}
Summers, C. and Dinneen, M.~J.
\newblock Improved mixed-example data augmentation.
\newblock In \emph{2019 IEEE Winter Conference on Applications of Computer
  Vision (WACV)}, pp.\  1262--1270. IEEE, 2019.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tang et~al.(2018)Tang, Schrimpf, Lotter, Moerman, Paredes, Caro,
  Hardesty, Cox, and Kreiman]{tang2018recurrent}
Tang, H., Schrimpf, M., Lotter, W., Moerman, C., Paredes, A., Caro, J.~O.,
  Hardesty, W., Cox, D., and Kreiman, G.
\newblock Recurrent computations for visual pattern completion.
\newblock \emph{Proceedings of the National Academy of Sciences}, 115:\penalty0
  8835--8840, 2018.

\bibitem[Vapnik(1999)]{vapnik2013nature}
Vapnik, V.
\newblock \emph{The nature of statistical learning theory}.
\newblock Springer science \& business media, 1999.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-{MNIST}: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Xie(2019)]{DVN/7CBGOS_2019}
Xie, L.
\newblock {Hardhat}, 2019.
\newblock URL \url{https://doi.org/10.7910/DVN/7CBGOS}.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
Yun, S., Han, D., Oh, S.~J., Chun, S., Choe, J., and Yoo, Y.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  6023--6032, 2019.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2018mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=r1Ddp1-Rb}.

\bibitem[Zhang \& Zhu(2019)Zhang and Zhu]{zhang2019interpreting}
Zhang, T. and Zhu, Z.
\newblock Interpreting adversarially trained convolutional neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7502--7511. PMLR, 2019.

\bibitem[Zhong et~al.(2020)Zhong, Zheng, Kang, Li, and Yang]{zhong2020random}
Zhong, Z., Zheng, L., Kang, G., Li, S., and Yang, Y.
\newblock Random erasing data augmentation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pp.\  13001--13008, 2020.

\end{thebibliography}
