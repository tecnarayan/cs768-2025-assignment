\begin{thebibliography}{10}

\bibitem{bertsekas1996neuro}
D.P. Bertsekas and J.N. Tsitsiklis.
\newblock Neuro-dynamic programming (optimization and neural computation
  series, 3).
\newblock {\em Athena Scientific}, 7:15--23, 1996.

\bibitem{barto2004handbook}
A.G. Barto, W.~Powell, J.~Si, and D.C. Wunsch.
\newblock Handbook of learning and approximate dynamic programming.
\newblock 2004.

\bibitem{Fleming1971}
W.H. Fleming.
\newblock Exit probabilities and optimal stochastic control.
\newblock {\em Applied Math. Optim}, 9:329--346, 1971.

\bibitem{Fleming1993}
W.~H. Fleming and H.~M. Soner.
\newblock {\em Controlled Markov processes and viscosity solutions}.
\newblock Applications of mathematics. Springer, New York, 1st edition, 1993.

\bibitem{Kappen1995}
H.~J. Kappen.
\newblock Linear theory for control of nonlinear stochastic systems.
\newblock {\em Phys Rev Lett}, 95:200--201, 2005.

\bibitem{Kappen2005b}
H.~J. Kappen.
\newblock Path integrals and symmetry breaking for optimal control theory.
\newblock {\em Journal of Statistical Mechanics: Theory and Experiment},
  11:P11011, 2005.

\bibitem{Kappen2007}
H.~J. Kappen.
\newblock An introduction to stochastic control theory, path integrals and
  reinforcement learning.
\newblock {\em AIP Conference Proceedings}, 887(1), 2007.

\bibitem{PhysRevE.91.032104}
S.~Thijssen and H.~J. Kappen.
\newblock Path integral control and state-dependent feedback.
\newblock {\em Phys. Rev. E}, 91:032104, Mar 2015.

\bibitem{todorov2009efficient}
E.~Todorov.
\newblock Efficient computation of optimal actions.
\newblock {\em Proceedings of the national academy of sciences},
  106(28):11478--11483, 2009.

\bibitem{theodorou2010generalized}
E.~Theodorou, J.~Buchli, and S.~Schaal.
\newblock A generalized path integral control approach to reinforcement
  learning.
\newblock {\em The Journal of Machine Learning Research}, 11:3137--3181, 2010.

\bibitem{ICML2012Stulp_171}
F.~Stulp and O.~Sigaud.
\newblock Path integral policy improvement with covariance matrix adaptation.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning (ICML)}, pages 281--288. ACM, 2012.

\bibitem{Rawlik2013}
K.~Rawlik, M.~Toussaint, and S.~Vijayakumar.
\newblock Path integral control by reproducing kernel hilbert space embedding.
\newblock In {\em Proceedings of the Twenty-Third International Joint
  Conference on Artificial Intelligence}, IJCAI'13, pages 1628--1634, 2013.

\bibitem{pan2014nonparametric}
Y.~Pan and E.~Theodorou.
\newblock Nonparametric infinite horizon kullback-leibler stochastic control.
\newblock In {\em 2014 IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning (ADPRL)}, pages 1--8. IEEE, 2014.

\bibitem{gomez2014policy}
V.~G{\'o}mez, H.J. Kappen, J.~Peters, and G.~Neumann.
\newblock Policy search for path integral control.
\newblock In {\em Machine Learning and Knowledge Discovery in Databases}, pages
  482--497. Springer, 2014.

\bibitem{dvijotham2012linearly}
K.~Dvijotham and E~Todorov.
\newblock Linearly solvable optimal control.
\newblock {\em Reinforcement learning and approximate dynamic programming for
  feedback control}, pages 119--141, 2012.

\bibitem{deisenroth2013survey}
M.P. Deisenroth, G.~Neumann, and J.~Peters.
\newblock A survey on policy search for robotics.
\newblock {\em Foundations and Trends in Robotics}, 2(1-2):1--142, 2013.

\bibitem{deisenroth2014gaussian}
M.~Deisenroth, D.~Fox, and C.~Rasmussen.
\newblock Gaussian processes for data-efficient learning in robotics and
  control.
\newblock {\em IEEE Transsactions on Pattern Analysis and Machine
  Intelligence}, 27:75--90, 2015.

\bibitem{theodorou2012relative}
E.~Theodorou and E.~Todorov.
\newblock Relative entropy and free energy dualities: Connections to path
  integral and kl control.
\newblock In {\em 51st IEEE Conference on Decision and Control}, pages
  1466--1473, 2012.

\bibitem{pan2014probabilistic}
Y.~Pan and E.~Theodorou.
\newblock Probabilistic differential dynamic programming.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 1907--1915, 2014.

\bibitem{levine2014learning}
S.~Levine and P.~Abbeel.
\newblock Learning neural network policies with guided policy search under
  unknown dynamics.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 1071--1079, 2014.

\bibitem{levine2014learning2}
S.~Levine and V.~Koltun.
\newblock Learning complex neural network policies with trajectory
  optimization.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 829--837, 2014.

\bibitem{schulman2015trust}
J.~Schulman, S.~Levine, P.~Moritz, M.~I. Jordan, and P.~Abbeel.
\newblock Trust region policy optimization.
\newblock {\em arXiv preprint arXiv:1502.05477}, 2015.

\bibitem{hennig2011optimal}
P.~Hennig.
\newblock Optimal reinforcement learning for gaussian systems.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 325--333, 2011.

\bibitem{candela2003propagation}
J.~Quinonero Candela, A.~Girard, J.~Larsen, and C.~E. Rasmussen.
\newblock Propagation of uncertainty in bayesian kernel models-application to
  multiple-step ahead forecasting.
\newblock In {\em IEEE International Conference on Acoustics, Speech, and
  Signal Processing}, 2003.

\bibitem{williams2006gaussian}
C.K.I Williams and C.E. Rasmussen.
\newblock {\em Gaussian processes for machine learning}.
\newblock MIT Press, 2006.

\bibitem{todorov2009compositionality}
E.~Todorov.
\newblock Compositionality of optimal control laws.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 1856--1864, 2009.

\bibitem{Deisenroth_ICRA_2014}
M.P. Deisenroth, P.~Englert, J.~Peters, and D.~Fox.
\newblock Multi-task policy search for robotics.
\newblock In {\em Proceedings of 2014 IEEE International Conference on Robotics
  and Automation (ICRA)}, 2014.

\end{thebibliography}
