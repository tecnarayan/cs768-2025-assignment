\begin{thebibliography}{10}

\bibitem{ste}
Yoshua Bengio, Nicholas L{\'{e}}onard, and Aaron Courville.
\newblock {Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{gpt_3}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock {Language Models are Few-Shot Learners}.
\newblock In {\em NeurIPS}, 2020.

\bibitem{dino}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'{e}} Jegou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
\newblock {Emerging Properties in Self-Supervised Vision Transformers}.
\newblock In {\em ICCV}, 2021.

\bibitem{muse}
Huiwen Chang, Han Zhang, Jarred Barber, AJ~Maschinot, Jose Lezama, Lu~Jiang, Ming-Hsuan Yang, Kevin Murphy, William~T. Freeman, Michael Rubinstein, Yuanzhen Li, and Dilip Krishnan.
\newblock {Muse: Text-To-Image Generation via Masked Generative Transformers}.
\newblock In {\em ICML}, 2023.

\bibitem{maskgit}
Huiwen Chang, Han Zhang, Lu~Jiang, Ce~Liu, and William~T Freeman.
\newblock {MaskGIT: Masked Generative Image Transformer}.
\newblock In {\em CVPR}, 2022.

\bibitem{coco_captions}
Xinlei Chen, Hao Fang, Tsung-yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollar, and C~Lawrence Zitnick.
\newblock {Microsoft COCO Captions: Data Collection and Evaluation Server}.
\newblock {\em arXiv preprint arXiv:1504.00325}, 2015.

\bibitem{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, {Kai Li}, and {Li Fei-Fei}.
\newblock {ImageNet: A large-scale hierarchical image database}.
\newblock In {\em CVPR}, 2009.

\bibitem{adm}
Prafulla Dhariwal and Alex Nichol.
\newblock {Diffusion Models Beat GANs on Image Synthesis}.
\newblock In {\em NeurIPS}, volume~11, pages 8780--8794, 2021.

\bibitem{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}.
\newblock In {\em ICLR}, 2021.

\bibitem{vqgan}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock {Taming Transformers for High-Resolution Image Synthesis}.
\newblock In {\em CVPR}, 2021.

\bibitem{vq}
R.~Gray.
\newblock {Vector quantization}.
\newblock {\em IEEE ASSP Mag.}, 1(2), 1984.

\bibitem{seq_gan}
Yuchao Gu, Xintao Wang, Yixiao Ge, Ying Shan, Xiaohu Qie, and Mike~Zheng Shou.
\newblock {Rethinking the Objectives of Vector-Quantized Tokenizers for Image Synthesis}.
\newblock {\em arXiv preprint arXiv:2212.03185}, 2022.

\bibitem{mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'{a}}r, and Ross Girshick.
\newblock {Masked Autoencoders Are Scalable Vision Learners}.
\newblock In {\em CVPR}, 2022.

\bibitem{fid}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium}.
\newblock In {\em NeurIPS}, 2017.

\bibitem{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock {Denoising Diffusion Probabilistic Models}.
\newblock In {\em NeurIPS}, 2020.

\bibitem{soda}
Drew~A. Hudson, Daniel Zoran, Mateusz Malinowski, Andrew~K. Lampinen, Andrew Jaegle, James~L. McClelland, Loic Matthey, Felix Hill, and Alexander Lerchner.
\newblock {SODA: Bottleneck Diffusion Models for Representation Learning}.
\newblock {\em arXiv preprint arXiv:2311.17901}, 2023.

\bibitem{openclip}
Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar, Hongseok Namkoong, John Miller, Hannaneh Hajishirzi, Ali Farhadi, and Ludwig Schmidt.
\newblock Openclip.
\newblock \url{https://doi.org/10.5281/zenodo.5143773}, 2021.

\bibitem{adam}
Diederik~P. Kingma and Jimmy~Lei Ba.
\newblock {Adam: A method for stochastic optimization}.
\newblock In {\em ICLR}, 2015.

\bibitem{vae}
Diederik~P. Kingma and Max Welling.
\newblock {Auto-encoding variational bayes}.
\newblock {\em ICLR}, 2014.

\bibitem{videopoet}
Dan Kondratyuk, Lijun Yu, Xiuye Gu, Jos{\'{e}} Lezama, Jonathan Huang, Rachel Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, Yong Cheng, Ming-Chang Chiu, Josh Dillon, Irfan Essa, Agrim Gupta, Meera Hahn, Anja Hauth, David Hendon, Alonso Martinez, David Minnen, David Ross, Grant Schindler, Mikhail Sirotenko, Kihyuk Sohn, Krishna Somandepalli, Huisheng Wang, Jimmy Yan, Ming-Hsuan Yang, Xuan Yang, Bryan Seybold, and Lu~Jiang.
\newblock {VideoPoet: A Large Language Model for Zero-Shot Video Generation}.
\newblock {\em arXiv preprint arXiv:2312.14125}, 2023.

\bibitem{rq_vae}
Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook~Shin Han.
\newblock {Autoregressive Image Generation using Residual Quantization}.
\newblock In {\em CVPR}, 2022.

\bibitem{mage}
Tianhong Li, Huiwen Chang, Shlok~Kumar Mishra, Han Zhang, Dina Katabi, and Dilip Krishnan.
\newblock {MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis}.
\newblock In {\em CVPR}, 2023.

\bibitem{coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C.~Lawrence Zitnick, and Piotr Doll{\'{a}}r.
\newblock {Microsoft COCO: Common Objects in Context}.
\newblock In {\em ECCV}, 2014.

\bibitem{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock {Decoupled weight decay regularization}.
\newblock In {\em ICLR}, 2019.

\bibitem{fsq}
Fabian Mentzer, David Minnen, Eirikur Agustsson, and Michael Tschannen.
\newblock {Finite Scalar Quantization: VQ-VAE Made Simple}.
\newblock In {\em ICLR}, 2024.

\bibitem{gd}
Soumik Mukhopadhyay, Matthew Gwilliam, Vatsal Agarwal, Namitha Padmanabhan, Archana Swaminathan, Srinidhi Hegde, Tianyi Zhou, and Abhinav Shrivastava.
\newblock {Diffusion Models Beat GANs on Image Classification}.
\newblock {\em arXiv preprint arXiv:2307.08702}, 2023.

\bibitem{beitv2}
Zhiliang Peng, Li~Dong, Hangbo Bao, Qixiang Ye, and Furu Wei.
\newblock {BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers}.
\newblock {\em arXiv preprint arXiv:2208.06366}, 2022.

\bibitem{diff_ae}
Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, and Supasorn Suwajanakorn.
\newblock {Diffusion Autoencoders: Toward a Meaningful and Decodable Representation}.
\newblock In {\em CVPR}, 2022.

\bibitem{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
\newblock {Learning Transferable Visual Models From Natural Language Supervision}.
\newblock In {\em ICML}, volume 139, 2021.

\bibitem{gpt}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock {Improving Language Understanding by Generative Pre-Training}.
\newblock 2018.

\bibitem{gpt_2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever.
\newblock {Language Models are Unsupervised Multitask Learners}.
\newblock {\em arXiv preprint arXiv:2007.07582}, 2019.

\bibitem{vq_vae_2}
Ali Razavi, A{\"{a}}ron van~den Oord, and Oriol Vinyals.
\newblock {Generating diverse high-fidelity images with VQ-VAE-2}.
\newblock In {\em NeurIPS}, 2019.

\bibitem{ldm}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer.
\newblock {High-Resolution Image Synthesis with Latent Diffusion Models}.
\newblock In {\em CVPR}, 2022.

\bibitem{is}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi~Chen.
\newblock {Improved Techniques for Training GANs}.
\newblock In {\em NeurIPS}, 2016.

\bibitem{dpm}
Jascha Sohl-Dickstein, Eric~A. Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock {Deep Unsupervised Learning using Nonequilibrium Thermodynamics}.
\newblock In {\em ICML}, 2015.

\bibitem{ddim}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock {Denoising Diffusion Implicit Models}.
\newblock In {\em ICLR}, 2020.

\bibitem{ncsn}
Yang Song and Stefano Ermon.
\newblock {Generative Modeling by Estimating Gradients of the Data Distribution}.
\newblock In {\em NeurIPS}, 2019.

\bibitem{inception_v3}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.
\newblock {Rethinking the Inception Architecture for Computer Vision}.
\newblock In {\em CVPR}, 2016.

\bibitem{hq_vae}
Yuhta Takida, Yukara Ikemiya, Takashi Shibuya, Kazuki Shimada, Woosung Choi, Chieh-Hsin Lai, Naoki Murata, Toshimitsu Uesaka, Kengo Uchida, Wei-Hsiang Liao, and Yuki Mitsufuji.
\newblock {HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes}.
\newblock {\em arXiv preprint arXiv:2401.00365}, 2023.

\bibitem{sq_vae}
Yuhta Takida, Takashi Shibuya, Wei~Hsiang Liao, Chieh~Hsin Lai, Junki Ohmura, Toshimitsu Uesaka, Naoki Murata, Shusuke Takahashi, Toshiyuki Kumakura, and Yuki Mitsufuji.
\newblock {SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization}.
\newblock {\em Proc. Mach. Learn. Res.}, 162, 2022.

\bibitem{vq_vae}
Aaron {Van Den Oord}, Oriol Vinyals, and Koray Kavukcuoglu.
\newblock {Neural discrete representation learning}.
\newblock In {\em NeurIPS}, 2017.

\bibitem{tsne}
Laurens {Van Der Maaten} and Geoffrey Hinton.
\newblock {Visualizing Data using t-SNE}.
\newblock {\em JMLR}, 9, 2008.

\bibitem{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock {Attention Is All You Need}.
\newblock In {\em NeurIPS}, 2017.

\bibitem{vq_wae}
Tung-Long Vuong, Trung Le, He~Zhao, Chuanxia Zheng, Mehrtash Harandi, Jianfei Cai, and Dinh Phung.
\newblock {Vector Quantized Wasserstein Auto-Encoder}.
\newblock {\em ICML}, 2023.

\bibitem{datasetdm}
Weijia Wu, Yuzhong Zhao, Hao Chen, Yuchao Gu, Rui Zhao, Yefei He, Hong Zhou, Mike~Zheng Shou, and Chunhua Shen.
\newblock {DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models}.
\newblock In {\em NeurIPS}, 2023.

\bibitem{freemask}
Lihe Yang, Xiaogang Xu, Bingyi Kang, Yinghuan Shi, and Hengshuang Zhao.
\newblock {FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models}.
\newblock In {\em NeurIPS}, 2023.

\bibitem{vit_vqgan}
Jiahui Yu, Xin Li, Jing~Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.
\newblock {Vector-Quantized Image Modeling With Improved Vqgan}.
\newblock In {\em ICLR}, 2022.

\bibitem{parti}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui Wu.
\newblock {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation}.
\newblock {\em TMLR}, 2022.

\bibitem{magvitv2}
Lijun Yu, Jos{\'{e}} Lezama, Nitesh~B. Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander~G. Hauptmann, Boqing Gong, Ming-Hsuan Yang, Irfan Essa, David~A. Ross, and Lu~Jiang.
\newblock {Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation}.
\newblock {\em arXiv preprint arXiv:2310.05737}, 2023.

\bibitem{cm3leon}
Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, Candace Ross, Adam Polyak, Russell Howes, Vasu Sharma, Puxin Xu, Hovhannes Tamoyan, Oron Ashual, Uriel Singer, Shang-Wen Li, Susan Zhang, Gargi Ghosh, Yaniv Taigman, Maryam Fazel-Zarandi, Asli Celikyilmaz, Luke Zettlemoyer, and Armen Aghajanyan.
\newblock {Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning}.
\newblock {\em arXiv preprint arXiv:2309.02591}, 2023.

\bibitem{diffusionengine}
Manlin Zhang, Jie Wu, Yuxi Ren, Ming Li, Jie Qin, Xuefeng Xiao, Wei Liu, Rui Wang, Min Zheng, and Andy~J. Ma.
\newblock {DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection}.
\newblock {\em arXiv preprint arXiv:2309.03893}, 2023.

\bibitem{pdae}
Zijian Zhang, Zhou Zhao, and Zhijie Lin.
\newblock {Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models}.
\newblock In {\em NeurIPS}, volume~35, 2022.

\bibitem{vpd}
Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou, and Jiwen Lu.
\newblock {Unleashing Text-to-Image Diffusion Models for Visual Perception}.
\newblock In {\em ICCV}, 2023.

\bibitem{movq}
Chuanxia Zheng, Jianfei Cai, Long~Tung Vuong, and Dinh Phung.
\newblock {MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation}.
\newblock In {\em NeurIPS}, 2022.

\bibitem{cvq_vae}
Chuanxia Zheng and Andrea Vedaldi.
\newblock {Online Clustered Codebook}.
\newblock In {\em CVPR}, 2023.

\end{thebibliography}
