\begin{thebibliography}{10}

\bibitem{anand2019unsupervised}
Ankesh Anand, Evan Racah, Sherjil Ozair, Yoshua Bengio, Marc-Alexandre
  C{\^o}t{\'e}, and R~Devon Hjelm.
\newblock Unsupervised state representation learning in atari.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8766--8779, 2019.

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{bassily2017learners}
Raef Bassily, Shay Moran, Ido Nachum, Jonathan Shafer, and Amir Yehudayoff.
\newblock Learners that use little information.
\newblock In {\em Algorithmic Learning Theory}, pages 25--55, 2018.

\bibitem{bialek1999predictive}
William Bialek and Naftali Tishby.
\newblock Predictive information.
\newblock {\em arXiv preprint cond-mat/9902341}, 1999.

\bibitem{pathak18largescale}
Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, and
  Alexei~A. Efros.
\newblock Large-scale study of curiosity-driven learning.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{chua2018deep}
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4754--4765, 2018.

\bibitem{fischer2020ceb}
Ian Fischer.
\newblock The conditional entropy bottleneck.
\newblock {\em arXiv preprint arXiv:2002.05379}, 2020.

\bibitem{fischer2020cebrob}
Ian Fischer and Alexander~A Alemi.
\newblock {CEB} improves model robustness.
\newblock {\em arXiv preprint arXiv:2002.05380}, 2020.

\bibitem{fujimoto2018addressing}
Scott Fujimoto, Herke Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In {\em International Conference on Machine Learning}, pages
  1587--1596, 2018.

\bibitem{gelada2019deepmdp}
Carles Gelada, Saurabh Kumar, Jacob Buckman, Ofir Nachum, and Marc~G Bellemare.
\newblock Deep{MDP}: Learning continuous latent space models for representation
  learning.
\newblock In {\em International Conference on Machine Learning}, pages
  2170--2179, 2019.

\bibitem{goyal2020variational}
Anirudh Goyal, Yoshua Bengio, Matthew Botvinick, and Sergey Levine.
\newblock The variational bandwidth bottleneck: Stochastic evaluation on an
  information budget.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{goyal2019infobot}
Anirudh Goyal, Riashat Islam, Daniel Strouse, Zafarali Ahmed, Matthew
  Botvinick, Hugo Larochelle, Yoshua Bengio, and Sergey Levine.
\newblock Infobot: Transfer and exploration via the information bottleneck.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{TFAgents}
Sergio Guadarrama, Anoop Korattikara, Oscar Ramirez, Pablo Castro, Ethan Holly,
  Sam Fishman, Ke~Wang, Ekaterina Gonina, Neal Wu, Efi Kokiopoulou, Luciano
  Sbaiz, Jamie Smith, G{\'a}bor Bart{\'o}k, Jesse Berent, Chris Harris, Vincent
  Vanhoucke, and Eugene Brevdo.
\newblock {TF-Agents}: A library for reinforcement learning in tensorflow.
\newblock \url{https://github.com/tensorflow/agents}, 2018.
\newblock [Online; accessed 25-June-2019].

\bibitem{ha2018world}
David Ha and J{\"u}rgen Schmidhuber.
\newblock World models.
\newblock {\em arXiv preprint arXiv:1803.10122}, 2018.

\bibitem{haarnoja2017reinforcement}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In {\em International Conference on Machine Learning}, pages
  1352--1361, 2017.

\bibitem{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha,
  Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock {\em arXiv preprint arXiv:1812.05905}, 2018.

\bibitem{hafner2019dream}
Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{hafner2018learning}
Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha,
  Honglak Lee, and James Davidson.
\newblock Learning latent dynamics for planning from pixels.
\newblock In {\em International Conference on Machine Learning}, pages
  2555--2565, 2019.

\bibitem{hjelm2018learning}
R~Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{igl2019generalization}
Maximilian Igl, Kamil Ciosek, Yingzhen Li, Sebastian Tschiatschek, Cheng Zhang,
  Sam Devlin, and Katja Hofmann.
\newblock Generalization in reinforcement learning with selective noise
  injection and information bottleneck.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  13978--13990, 2019.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International Conference on Machine Learning}, pages
  448--456, 2015.

\bibitem{jaderberg2016reinforcement}
Max Jaderberg, Volodymyr Mnih, Wojciech~Marian Czarnecki, Tom Schaul, Joel~Z
  Leibo, David Silver, and Koray Kavukcuoglu.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{janner2019trust}
Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  12498--12509, 2019.

\bibitem{jaynes}
Edwin~T Jaynes.
\newblock Information theory and statistical mechanics.
\newblock {\em Physical review}, 106(4):620, 1957.

\bibitem{kaiser2019model}
Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy~H
  Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski,
  Sergey Levine, et~al.
\newblock Model-based reinforcement learning for atari.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em International Conference on Learning Representations}, 2015.

\bibitem{kostrikov2020image}
Ilya Kostrikov, Denis Yarats, and Rob Fergus.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock {\em arXiv preprint arXiv:2004.13649}, 2020.

\bibitem{laskin2020reinforcement}
Michael Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, and
  Aravind Srinivas.
\newblock Reinforcement learning with augmented data.
\newblock {\em arXiv preprint arXiv:2004.14990}, 2020.

\bibitem{lee2019stochastic}
Alex~X Lee, Anusha Nagabandi, Pieter Abbeel, and Sergey Levine.
\newblock Stochastic latent actor-critic: Deep reinforcement learning with a
  latent variable model.
\newblock {\em arXiv preprint arXiv:1907.00953}, 2019.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{pathak2017curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition Workshops}, pages 16--17, 2017.

\bibitem{poole2019variational}
Ben Poole, Sherjil Ozair, Aaron Van Den~Oord, Alex Alemi, and George Tucker.
\newblock On variational bounds of mutual information.
\newblock In {\em International Conference on Machine Learning}, pages
  5171--5180, 2019.

\bibitem{schmidhuber1990making}
J{\"u}rgen Schmidhuber.
\newblock Making the world differentiable: On using self-supervised fully
  recurrent neural networks for dynamic reinforcement learning and planning in
  non-stationary environments.
\newblock Technical report, Institut f{\"u}r Informatik, Technische
  Universit{\"a}t M{\"u}nchen, 1990.

\bibitem{schmidhuber1991reinforcement}
J{\"u}rgen Schmidhuber.
\newblock Reinforcement learning in markovian and non-markovian environments.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  500--506, 1991.

\bibitem{schmidhuber2015learning}
J{\"u}rgen Schmidhuber.
\newblock On learning to think: Algorithmic information theory for novel
  combinations of reinforcement learning controllers and recurrent neural world
  models.
\newblock {\em arXiv preprint arXiv:1511.09249}, 2015.

\bibitem{shamir2010learning}
Ohad Shamir, Sivan Sabato, and Naftali Tishby.
\newblock Learning and generalization with the information bottleneck.
\newblock {\em Theoretical Computer Science}, 411(29-30):2696--2711, 2010.

\bibitem{shelhamer2016loss}
Evan Shelhamer, Parsa Mahmoudieh, Max Argus, and Trevor Darrell.
\newblock Loss is its own reward: Self-supervision for reinforcement learning.
\newblock {\em arXiv preprint arXiv:1612.07307}, 2016.

\bibitem{singh2019filter}
Saurabh Singh and Shankar Krishnan.
\newblock Filter response normalization layer: Eliminating batch dependence in
  the training of deep neural networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11237--11246, 2020.

\bibitem{srinivas2020curl}
Aravind Srinivas, Michael Laskin, and Pieter Abbeel.
\newblock {CURL}: Contrastive unsupervised representations for reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:2004.04136}, 2020.

\bibitem{still2012information}
Susanne Still and Doina Precup.
\newblock An information-theoretic approach to curiosity-driven reinforcement
  learning.
\newblock {\em Theory in Biosciences}, 131(3):139--148, 2012.

\bibitem{sutton1991dyna}
Richard~S Sutton.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock {\em ACM Sigart Bulletin}, 2(4):160--163, 1991.

\bibitem{tassa2018deepmind}
Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de~Las
  Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, et~al.
\newblock {DeepMind} control suite.
\newblock {\em arXiv preprint arXiv:1801.00690}, 2018.

\bibitem{yarats2019improving}
Denis Yarats, Amy Zhang, Ilya Kostrikov, Brandon Amos, Joelle Pineau, and Rob
  Fergus.
\newblock Improving sample efficiency in model-free reinforcement learning from
  images.
\newblock {\em arXiv preprint arXiv:1910.01741}, 2019.

\bibitem{ziebart2010modeling}
Brian~D Ziebart.
\newblock {\em Modeling Purposeful Adaptive Behavior with the Principle of
  Maximum Causal Entropy}.
\newblock PhD thesis, Carnegie Mellon University, 2010.

\bibitem{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In {\em AAAI}, volume~8, pages 1433--1438. Chicago, IL, USA, 2008.

\end{thebibliography}
