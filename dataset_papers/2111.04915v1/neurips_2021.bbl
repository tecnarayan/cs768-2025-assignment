\begin{thebibliography}{10}

\bibitem{jamieson2018bandit}
Kevin Jamieson and Lalit Jain.
\newblock A bandit approach to multiple testing with false discovery control.
\newblock In {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{settles2009active}
Burr Settles.
\newblock Active learning literature survey.
\newblock 2009.

\bibitem{shahriari2015taking}
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan~P Adams, and Nando De~Freitas.
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock {\em Proceedings of the IEEE}, 104(1):148--175, 2015.

\bibitem{dasgupta2007general}
Sanjoy Dasgupta, Daniel~J Hsu, and Claire Monteleoni.
\newblock {\em A general agnostic active learning algorithm}.
\newblock Citeseer, 2007.

\bibitem{balcan2009agnostic}
Maria-Florina Balcan, Alina Beygelzimer, and John Langford.
\newblock Agnostic active learning.
\newblock {\em Journal of Computer and System Sciences}, 75(1):78--89, 2009.

\bibitem{hanneke2014theory}
Steve Hanneke et~al.
\newblock Theory of disagreement-based active learning.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  7(2-3):131--309, 2014.

\bibitem{soare2014best}
Marta Soare, Alessandro Lazaric, and R{\'e}mi Munos.
\newblock Best-arm identification in linear bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  828--836, 2014.

\bibitem{fiez2019sequential}
Tanner Fiez, Lalit Jain, Kevin~G Jamieson, and Lillian Ratliff.
\newblock Sequential experimental design for transductive linear bandits.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10666--10676, 2019.

\bibitem{katz2020empirical}
Julian Katz-Samuels, Lalit Jain, Kevin~G Jamieson, et~al.
\newblock An empirical process approach to the union bound: Practical
  algorithms for combinatorial and linear bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{lattimore_szepesvari_2020}
Tor Lattimore and Csaba Szepesvári.
\newblock {\em Bandit Algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem{amin2011bandits}
Kareem Amin, Michael Kearns, and Umar Syed.
\newblock Bandits, query learning, and the haystack dimension.
\newblock In {\em Proceedings of the 24th Annual Conference on Learning
  Theory}, pages 87--106. JMLR Workshop and Conference Proceedings, 2011.

\bibitem{jamieson2014lil}
Kevin Jamieson, Matthew Malloy, Robert Nowak, and S{\'e}bastien Bubeck.
\newblock lil’ucb: An optimal exploration algorithm for multi-armed bandits.
\newblock In {\em Conference on Learning Theory}, pages 423--439, 2014.

\bibitem{kaufmann2016complexity}
Emilie Kaufmann, Olivier Capp{\'e}, and Aur{\'e}lien Garivier.
\newblock On the complexity of best-arm identification in multi-armed bandit
  models.
\newblock {\em The Journal of Machine Learning Research}, 17(1):1--42, 2016.

\bibitem{lovasz2006fast}
L{\'a}szl{\'o} Lov{\'a}sz and Santosh Vempala.
\newblock Fast algorithms for logconcave functions: Sampling, rounding,
  integration and optimization.
\newblock In {\em 2006 47th Annual IEEE Symposium on Foundations of Computer
  Science (FOCS'06)}, pages 57--68. IEEE, 2006.

\bibitem{tosh2020diameter}
Christopher Tosh and Daniel Hsu.
\newblock Diameter-based interactive structure discovery.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 580--590. PMLR, 2020.

\bibitem{cohn1994improving}
David Cohn, Les Atlas, and Richard Ladner.
\newblock Improving generalization with active learning.
\newblock {\em Machine learning}, 15(2):201--221, 1994.

\bibitem{dasgupta2005coarse}
Sanjoy Dasgupta.
\newblock Coarse sample complexity bounds for active learning.
\newblock In {\em NIPS}, volume~18, pages 235--242, 2005.

\bibitem{tosh2017diameter}
Christopher Tosh and Sanjoy Dasgupta.
\newblock Diameter-based active learning.
\newblock In {\em International Conference on Machine Learning}, pages
  3444--3452. PMLR, 2017.

\bibitem{beygelzimer2010agnostic}
Alina Beygelzimer, Daniel Hsu, John Langford, and Tong Zhang.
\newblock Agnostic active learning without constraints.
\newblock {\em arXiv preprint arXiv:1006.2588}, 2010.

\bibitem{katz2021improved}
Julian Katz-Samuels, Jifan Zhang, Lalit Jain, and Kevin Jamieson.
\newblock Improved algorithms for agnostic pool-based active classification.
\newblock {\em International Conference on Machine Learning}, 2021.

\bibitem{hegedHus1995generalized}
Tibor Hegedus.
\newblock Generalized teaching dimensions and the query complexity of learning.
\newblock In {\em Proceedings of the eighth annual conference on Computational
  learning theory}, pages 108--117, 1995.

\bibitem{balcazar2002new}
Jos{\'e}~L Balc{\'a}zar, Jorge Castro, and David Guijarro.
\newblock A new abstract combinatorial dimension for exact learning via
  queries.
\newblock {\em Journal of Computer and System Sciences}, 64(1):2--21, 2002.

\bibitem{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham~M Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock {\em arXiv preprint arXiv:0912.3995}, 2009.

\bibitem{bull2011convergence}
Adam~D Bull.
\newblock Convergence rates of efficient global optimization algorithms.
\newblock {\em Journal of Machine Learning Research}, 12(10), 2011.

\bibitem{camilleri2021high}
Romain Camilleri, Julian Katz-Samuels, and Kevin Jamieson.
\newblock High-dimensional experimental design and kernel bandits.
\newblock {\em International Conference on Machine Learning}, 2021.

\bibitem{jain2019new}
Lalit Jain and Kevin~G Jamieson.
\newblock A new perspective on pool-based active classification and
  false-discovery control.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  13992--14003, 2019.

\bibitem{garivier2016optimal}
Aur{\'e}lien Garivier and Emilie Kaufmann.
\newblock Optimal best arm identification with fixed confidence.
\newblock In {\em Conference on Learning Theory}, pages 998--1027, 2016.

\bibitem{williamson2011design}
David~P Williamson and David~B Shmoys.
\newblock {\em The design of approximation algorithms}.
\newblock Cambridge university press, 2011.

\bibitem{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In {\em NIPS}, volume~11, pages 2312--2320, 2011.

\bibitem{swiler2020survey}
Laura~P Swiler, Mamikon Gulian, Ari~L Frankel, Cosmin Safta, and John~D
  Jakeman.
\newblock A survey of constrained gaussian process regression: Approaches and
  implementation challenges.
\newblock {\em Journal of Machine Learning for Modeling and Computing}, 1(2),
  2020.

\bibitem{lattimore2017end}
Tor Lattimore and Csaba Szepesvari.
\newblock The end of optimism? an asymptotic analysis of finite-armed linear
  bandits.
\newblock In {\em Artificial Intelligence and Statistics}, pages 728--737.
  PMLR, 2017.

\bibitem{scholkopf2001generalized}
Bernhard Sch{\"o}lkopf, Ralf Herbrich, and Alex~J Smola.
\newblock A generalized representer theorem.
\newblock In {\em International conference on computational learning theory},
  pages 416--426. Springer, 2001.

\bibitem{boyd2004convex}
Stephen Boyd, Stephen~P Boyd, and Lieven Vandenberghe.
\newblock {\em Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem{katz2020true}
Julian Katz-Samuels and Kevin Jamieson.
\newblock The true sample complexity of identifying good arms.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1781--1791. PMLR, 2020.

\bibitem{katz2018feasible}
Julian Katz-Samuels and Clay Scott.
\newblock Feasible arm identification.
\newblock In {\em International Conference on Machine Learning}, pages
  2535--2543. PMLR, 2018.

\bibitem{katz2019top}
Julian Katz-Samuels and Clayton Scott.
\newblock Top feasible arm identification.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 1593--1601. PMLR, 2019.

\end{thebibliography}
