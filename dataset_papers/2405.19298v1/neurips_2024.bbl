\begin{thebibliography}{10}

\bibitem{wang2006modern}
Zhou Wang and Alan~C. Bovik.
\newblock {\em Modern Image Quality Assessment}.
\newblock Morgan \& Claypool, 2006.

\bibitem{mittal2013making}
Anish Mittal, Rajiv Soundararajan, and Alan~C. Bovik.
\newblock Making a ``completely blind'' image quality analyzer.
\newblock {\em IEEE Signal Processing Letters}, 20(3):209--212, Mar. 2013.

\bibitem{zhang2015feature}
Lin Zhang, Lei Zhang, and Alan~C. Bovik.
\newblock A feature-enriched completely blind image quality evaluator.
\newblock {\em IEEE Transactions on Image Processing}, 24(8):2579--2591, Aug. 2015.

\bibitem{zhang2020blind}
Weixia Zhang, Kede Ma, Jia Yan, Dexiang Deng, and Zhou Wang.
\newblock Blind image quality assessment using a deep bilinear convolutional neural network.
\newblock {\em IEEE Transactions on Circuits and Systems for Video Technology}, 30(1):36--47, Jan. 2020.

\bibitem{chen2022no}
Baoliang Chen, Lingyu Zhu, Chenqi Kong, Hanwei Zhu, Shiqi Wang, and Zhu Li.
\newblock No-reference image quality assessment by hallucinating pristine features.
\newblock {\em IEEE Transactions on Image Processing}, 31:6139--6151, 2022.

\bibitem{ying2020from}
Zhenqiang Ying, Haoran Niu, Praful Gupta, Dhruv Mahajan, Deepti Ghadiyaram, and Alan~C. Bovik.
\newblock From patches to pictures ({P}a{Q}-2-{P}i{Q}): Mapping the perceptual space of picture quality.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 3572--3582, 2020.

\bibitem{hosu2020koniq}
Vlad Hosu, Hanhe Lin, Tamas Sziranyi, and Dietmar Saupe.
\newblock Kon{IQ}-10k: An ecologically valid database for deep learning of blind image quality assessment.
\newblock {\em IEEE Transactions on Image Processing}, 29:4041--4056, Jan. 2020.

\bibitem{su2020blindly}
Shaolin Su, Qingsen Yan, Yu~Zhu, Cheng Zhang, Xin Ge, Jinqiu Sun, and Yanning Zhang.
\newblock Blindly assess image quality in the wild guided by a self-adaptive hyper network.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 3667--3676, 2020.

\bibitem{wang2022exploring}
Jianyi Wang, Kelvin~CK Chan, and Chen~Change Loy.
\newblock Exploring {CLIP} for assessing the look and feel of images.
\newblock {\em CoRR}, abs/2207.12396, 2022.

\bibitem{zhang2023liqe}
Weixia Zhang, Guangtao Zhai, Ying Wei, Xiaokang Yang, and Kede Ma.
\newblock Blind image quality assessment via vision-language correspondence: A multitask learning perspective.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 14071--14081, 2023.

\bibitem{golestaneh2022no}
S.~Alireza Golestaneh, Saba Dadsetan, and Kris~M. Kitani.
\newblock No-reference image quality assessment via transformers, relative ranking, and self-consistency.
\newblock In {\em IEEE Winter Conference on Applications of Computer Vision}, pages 1220--1230, 2022.

\bibitem{wu2023qalign}
Haoning Wu, Zicheng Zhang, Weixia Zhang, Chaofeng Chen, Liang Liao, Chunyi Li, Yixuan Gao, Annan Wang, Erli Zhang, Wenxiu Sun, et~al.
\newblock {Q-Align}: {T}eaching {LMMs} for visual scoring via discrete text-defined levels.
\newblock {\em CoRR}, abs/2312.17090, 2023.

\bibitem{zhu2020metaiqa}
Hancheng Zhu, Leida Li, Jinjian Wu, Weisheng Dong, and Guangming Shi.
\newblock Meta{IQA}: Deep meta-learning for no-reference image quality assessment.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 14131--14140, 2020.

\bibitem{chen2021no}
Baoliang Chen, Haoliang Li, Hongfei Fan, and Shiqi Wang.
\newblock No-reference screen content image quality assessment with unsupervised domain adaptation.
\newblock {\em IEEE Transactions on Image Processing}, 30:5463--5476, 2021.

\bibitem{roy2023test}
Subhadeep Roy, Shankhanil Mitra, Soma Biswas, and Rajiv Soundararajan.
\newblock Test time adaptation for blind image quality assessment.
\newblock In {\em IEEE International Conference on Computer Vision}, pages 16742--16751, 2023.

\bibitem{wang2023deep}
Zhihua Wang, Qiuping Jiang, Shanshan Zhao, Wensen Feng, and Weisi Lin.
\newblock Deep blind image quality assessment powered by online hard example mining.
\newblock {\em IEEE Transactions on Multimedia}, to appear 2023.

\bibitem{zhang2021uncertainty}
Weixia Zhang, Kede Ma, Guangtao Zhai, and Xiaokang Yang.
\newblock Uncertainty-aware blind image quality assessment in the laboratory and wild.
\newblock {\em IEEE Transactions on Image Processing}, 30:3474--3486, Mar. 2021.

\bibitem{gpt4v}
OpenAI.
\newblock {GPT-4V}(ision) system card.
\newblock \url{https://cdn.openai.com/papers/GPTV_System_Card.pdf/}, 2023.

\bibitem{IDEFICS}
Hugging Face.
\newblock Introducing {IDEFICS}: {A}n open reproduction of state-of-the-art visual language model.
\newblock \url{https:// huggingface.co/blog/idefics/}, 2023.

\bibitem{ye2023mplug2}
Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Haowei Liu, Qi~Qian, Ji~Zhang, Fei Huang, and Jingren Zhou.
\newblock {mPLUG-Owl2: R}evolutionizing multi-modal large language model with modality collaboration.
\newblock {\em CoRR}, abs/2311.04257, 2023.

\bibitem{liu2023improved1.5}
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong~Jae Lee.
\newblock Improved baselines with visual instruction tuning.
\newblock {\em CoRR}, abs/2310.03744, 2023.

\bibitem{dong2024internlm}
Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Xilin Wei, Songyang Zhang, Haodong Duan, Maosong Cao, et~al.
\newblock {InternLM-XComposer2: M}astering free-form text-image composition and comprehension in vision-language large model.
\newblock {\em CoRR}, abs/2401.16420, 2024.

\bibitem{liu2024visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em Advances in Neural Information Processing Systems}, pages 34892--34916, 2024.

\bibitem{larson2010most}
Eric~C. Larson and Damon~M. Chandler.
\newblock Most apparent distortion: Full-reference image quality assessment and the role of strategy.
\newblock {\em Journal of Electronic Imaging}, 19(1):1--21, Jan. 2010.

\bibitem{ciancio2011no}
Alexandre Ciancio, A.~L. N.~T. {Targino da Costa}, E.~A.~B. {da Silva}, Amir Said, Ramin Samadani, and Pere Obrador.
\newblock No-reference blur assessment of digital pictures based on multifeature classifiers.
\newblock {\em IEEE Transactions on Image Processing}, 20(1):64--75, Jan. 2011.

\bibitem{lin2019kadid}
Hanhe Lin, Vlad Hosu, and Dietmar Saupe.
\newblock K{ADID}-10k: A large-scale artificially distorted {IQA} database.
\newblock In {\em International Conference on Quality of Multimedia Experience}, pages 1--3, 2019.

\bibitem{mantiuk2012comparison}
Rafa{\l}~K Mantiuk, Anna Tomaszewska, and Rados{\l}aw Mantiuk.
\newblock Comparison of four subjective methods for image quality assessment.
\newblock {\em Computer Graphics Forum}, 31(8):2478--2491, 2012.

\bibitem{mittal2012no}
Anish Mittal, Anush~K. Moorthy, and Alan~C. Bovik.
\newblock No-reference image quality assessment in the spatial domain.
\newblock {\em IEEE Transactions on Image Processing}, 21(12):4695--4708, Dec. 2012.

\bibitem{xu2016blind}
Jingtao Xu, Peng Ye, Qiaohong Li, Haiqing Du, Yong Liu, and David Doermann.
\newblock Blind image quality assessment based on high order statistics aggregation.
\newblock {\em IEEE Transactions on Image Processing}, 25(9):4444--4457, Sep. 2016.

\bibitem{wu2017blind}
Qingbo Wu, Hongliang Li, King~N Ngan, and Kede Ma.
\newblock Blind image quality assessment using local consistency aware retriever and uncertainty aware evaluator.
\newblock {\em IEEE Transactions on Circuits and Systems for Video Technology}, 28(9):2078--2089, 2017.

\bibitem{gu2015using}
Ke~Gu, Guangtao Zhai, Xiaokang Yang, and Wenjun Zhang.
\newblock Using free energy principle for blind image quality assessment.
\newblock {\em IEEE Transactions on Multimedia}, 17(1):50--63, Jan. 2015.

\bibitem{madhusudana2022image}
Pavan~C. Madhusudana, Neil Birkbeck, Yilin Wang, Balu Adsumilli, and Alan~C. Bovik.
\newblock Image quality assessment using contrastive learning.
\newblock {\em IEEE Transactions on Image Processing}, 31:4149--4161, Jun. 2022.

\bibitem{chen2024topiq}
Chaofeng Chen, Jiadi Mo, Jingwen Hou, Haoning Wu, Liang Liao, Wenxiu Sun, Qiong Yan, and Weisi Lin.
\newblock {TOPIQ: A} top-down approach from semantics to distortions for image quality assessment.
\newblock {\em IEEE Transactions on Image Processing}, to appear 2024.

\bibitem{ma2017end}
Kede Ma, Wentao Liu, Kai Zhang, Zhengfang Duanmu, Zhou Wang, and Wangmeng Zuo.
\newblock End-to-end blind image quality assessment using deep neural networks.
\newblock {\em IEEE Transactions on Image Processing}, 27(3):1202--1213, 2017.

\bibitem{bt2002methodology}
B.~T. {ITU-R}.
\newblock Methodology for the subjective assessment of the quality of television pictures.
\newblock \url{https://www.itu.int/rec/R-REC-BT.500}, 2002.

\bibitem{gao2015learning}
Fei Gao, Dacheng Tao, Xinbo Gao, and Xuelong Li.
\newblock Learning to rank for blind image quality assessment.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, 26(10):2275--2290, Oct. 2015.

\bibitem{liu2017rankiqa}
Xialei Liu, Joost van~de Weijer, and Andrew~D. Bagdanov.
\newblock {RankIQA}: Learning from rankings for no-reference image quality assessment.
\newblock In {\em IEEE International Conference on Computer Vision}, pages 1040--1049, 2017.

\bibitem{ma2017dipiq}
Kede Ma, Wentao Liu, Tongliang Liu, Zhou Wang, and Dacheng Tao.
\newblock dip{IQ}: Blind image quality assessment by learning-to-rank discriminable image pairs.
\newblock {\em IEEE Transactions on Image Processing}, 26(8):3951--3964, Aug. 2017.

\bibitem{wu2023q}
Haoning Wu, Zicheng Zhang, Erli Zhang, Chaofeng Chen, Liang Liao, Annan Wang, Kaixin Xu, Chunyi Li, Jingwen Hou, Guangtao Zhai, et~al.
\newblock {Q-I}nstruct: Improving low-level visual abilities for multi-modality foundation models.
\newblock {\em CoRR}, abs/2311.06783, 2023.

\bibitem{zhu20242afc}
Hanwei Zhu, Xiangjie Sui, Baoliang Chen, Xuelin Liu, Peilin Chen, Yuming Fang, and Shiqi Wang.
\newblock {2AFC} prompting of large multimodal models for image quality assessment.
\newblock {\em CoRR}, abs/2402.01162, 2024.

\bibitem{zhang2024benchmark}
Zicheng Zhang, Haoning Wu, Erli Zhang, Guangtao Zhai, and Weisi Lin.
\newblock A benchmark for multi-modal foundation models on low-level vision: from single images to pairs.
\newblock {\em CoRR}, abs/2402.07116, 2024.

\bibitem{wu2024comprehensive}
Tianhe Wu, Kede Ma, Jie Liang, Yujiu Yang, and Lei Zhang.
\newblock A comprehensive study of multimodal large language models for image quality assessment.
\newblock {\em CoRR}, abs/2403.10854, 2024.

\bibitem{zhang2023q}
Zicheng Zhang, Haoning Wu, Zhongpeng Ji, Chunyi Li, Erli Zhang, Wei Sun, Xiaohong Liu, Xiongkuo Min, Fengyu Sun, Shangling Jui, et~al.
\newblock {Q-Boost: O}n visual quality assessment ability of low-level multi-modality foundation models.
\newblock {\em CoRR}, abs/2312.15300, 2023.

\bibitem{huang2024visualcritic}
Zhipeng Huang, Zhizheng Zhang, Yiting Lu, Zheng-Jun Zha, Zhibo Chen, and Baining Guo.
\newblock {VisualCritic: Making LMMs} perceive visual quality like humans.
\newblock {\em CoRR}, abs/2403.12806, 2024.

\bibitem{you2023depicting}
Zhiyuan You, Zheyuan Li, Jinjin Gu, Zhenfei Yin, Tianfan Xue, and Chao Dong.
\newblock Depicting beyond scores: {A}dvancing image quality assessment through multi-modal language models.
\newblock {\em CoRR}, abs/2312.08962, 2023.

\bibitem{wu2024towards}
Haoning Wu, Hanwei Zhu, Zicheng Zhang, Erli Zhang, Chaofeng Chen, Liang Liao, Chunyi Li, Annan Wang, Wenxiu Sun, Qiong Yan, et~al.
\newblock Towards open-ended visual quality comparison.
\newblock {\em CoRR}, abs/2402.16641, 2024.

\bibitem{wu2023qbench}
Haoning Wu, Zicheng Zhang, Erli Zhang, Chaofeng Chen, Liang Liao, Annan Wang, Chunyi Li, Wenxiu Sun, Qiong Yan, Guangtao Zhai, et~al.
\newblock {Q-Bench: A} benchmark for general-purpose foundation models on low-level vision.
\newblock {\em CoRR}, abs/2309.14181, 2023.

\bibitem{duanmu2021quantifying}
Zhengfang Duanmu, Wentao Liu, Zhongling Wang, and Zhou Wang.
\newblock Quantifying visual image quality: {A} bayesian view.
\newblock {\em Annual Review of Vision Science}, 7(1):437--464, 2021.

\bibitem{Tsukida2011}
Kristi Tsukida and Maya~R Gupta.
\newblock How to analyze paired comparison data, {T}echnical Report UWEETR-2011-0004, University of Washington, 2011.

\bibitem{Sheskin2004Handbook}
Sheskin David~J.
\newblock {\em Handbook of Parametric and Nonparametric Statistical Procedures}.
\newblock CRC Press, 2004.

\bibitem{touvron2023llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock {LLaMA 2: O}pen foundation and fine-tuned chat models.
\newblock {\em CoRR}, abs/2307.09288, 2023.

\bibitem{thurstone1927law}
Louis~L. Thurstone.
\newblock A law of comparative judgment.
\newblock {\em Psychological Review}, 34:273--286, Jul. 1927.

\bibitem{sheikh2006statistical}
Hamid~R. Sheikh, Muhammad~F. Sabir, and Alan~C. Bovik.
\newblock A statistical evaluation of recent full reference image quality assessment algorithms.
\newblock {\em IEEE Transactions on Image Processing}, 15(11):3440--3451, Nov. 2006.

\bibitem{ghadiyaram2016massive}
Deepti Ghadiyaram and Alan~C. Bovik.
\newblock Massive online crowdsourced study of subjective and objective picture quality.
\newblock {\em IEEE Transactions on Image Processing}, 25(1):372--387, Jan. 2016.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em International Conference on Machine Learning}, pages 8748--8763, 2021.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI Blog}, 1(8):9, 2019.

\bibitem{video2003final}
VQEG.
\newblock {Final} report from the video quality experts group on the validation of objective models of video quality assessment, 2000.

\bibitem{ma2019blind}
Kede Ma, Xuelin Liu, Yuming Fang, and Eero~P. Simoncelli.
\newblock Blind image quality assessment by learning from multiple annotators.
\newblock In {\em IEEE International Conference on Image Processing}, pages 2344--2348, 2019.

\bibitem{ke2021musiq}
Junjie Ke, Qifei Wang, Yilin Wang, Peyman Milanfar, and Feng Yang.
\newblock {MUSIQ}: Multi-scale image quality transformer.
\newblock In {\em IEEE International Conference on Computer Vision}, pages 5148--5157, 2021.

\bibitem{fang2020perceptual}
Yuming Fang, Hanwei Zhu, Yan Zeng, Kede Ma, and Zhou Wang.
\newblock Perceptual quality assessment of smartphone photography.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 3677--3686, 2020.

\bibitem{li2023agiqa}
Chunyi Li, Zicheng Zhang, Haoning Wu, Wei Sun, Xiongkuo Min, Xiaohong Liu, Guangtao Zhai, and Weisi Lin.
\newblock {AGIQA-3K: A}n open database for ai-generated image quality assessment.
\newblock {\em IEEE Transactions on Circuits and Systems for Video Technology}, to appear 2023.

\bibitem{golan2020controversial}
Tal Golan, Prashant~C Raju, and Nikolaus Kriegeskorte.
\newblock Controversial stimuli: Pitting neural networks against each other as models of human cognition.
\newblock {\em Proceedings of the National Academy of Sciences}, 117(47):29330--29337, 2020.

\bibitem{ponomarenko2013color}
Ponomarenko Nikolay, Jin Lina, Ieremeiev Oleg, Lukin Vladimir, Egiazarian Karen, Astola Jaakko, Vozel Benoit, Chehdi Kacem, Carli Marco, Battisti Federica, and C.-C.~Jay Kuo.
\newblock Image database {TID2013}: Peculiarities, results and perspectives.
\newblock {\em Signal Processing: Image Communication}, 30:57--77, Jan. 2015.

\bibitem{thomee2016yfcc100m}
Bart Thomee, David~A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li.
\newblock {YFCC100M: T}he new data in multimedia research.
\newblock {\em Communications of the ACM}, 59(2):64--73, 2016.

\bibitem{xu2018attngan}
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He.
\newblock {AttnGan: F}ine-grained text to image generation with attentional generative adversarial networks.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 1316--1324, 2018.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with {CLIP} latents.
\newblock {\em CoRR}, abs/2204.06125, 2022.

\bibitem{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock {GLIDE: T}owards photorealistic image generation and editing with text-guided diffusion models.
\newblock {\em CoRR}, abs/2112.10741, 2021.

\bibitem{Midjourney}
David Holz.
\newblock Midjourney.
\newblock url = {https://www.midjourney.com/}, 2023.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{rombach2022text}
Robin Rombach, Andreas Blattmann, and Bj{\"o}rn Ommer.
\newblock Text-guided synthesis of artistic images with retrieval-augmented diffusion models.
\newblock {\em CoRR}, abs/2207.13038, 2022.

\bibitem{awadalla2023openflamingo}
Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, et~al.
\newblock {Openflamingo: A}n open-source framework for training large autoregressive vision-language models.
\newblock {\em CoRR}, abs/2308.01390, 2023.

\bibitem{laurençon2023idefics}
Hugo Laurençon, Lucile Saulnier, Léo Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov, Thomas Wang, Siddharth Karamcheti, Alexander~M. Rush, Douwe Kiela, Matthieu Cord, and Victor Sanh.
\newblock {OBELICS}: An open web-scale filtered dataset of interleaved image-text documents.
\newblock {\em CoRR}, abs/2306.16527, 2023.

\bibitem{chiang2023vicuna}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E Gonzalez, et~al.
\newblock {Vicuna: A}n open-source chatbot impressing {GPT-4} with 90\%* chatgpt quality.
\newblock {\em See https://vicuna. lmsys. org (accessed 14 April 2023)}, 2(3):6, 2023.

\bibitem{cai2024internlm2}
Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, et~al.
\newblock Internlm2 technical report.
\newblock {\em CoRR}, abs/2403.17297, 2024.

\end{thebibliography}
