\begin{thebibliography}{10}

\bibitem{amiranashvili2018analyzing}
Artemij Amiranashvili, Alexey Dosovitskiy, Vladlen Koltun, and Thomas Brox.
\newblock Analyzing the role of temporal differencing in deep reinforcement
  learning.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{azizzadenesheli2018efficient}
Kamyar Azizzadenesheli, Emma Brunskill, and Animashree Anandkumar.
\newblock Efficient exploration through bayesian deep q-networks.
\newblock In {\em 2018 Information Theory and Applications Workshop (ITA)},
  pages 1--9. IEEE, 2018.

\bibitem{bellemare2013arcade}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock {\em Journal of Artificial Intelligence Research}, 47:253--279, 2013.

\bibitem{bellman1957dynamic}
Richard~E. Bellman.
\newblock {\em Dynamic Programming}.
\newblock Princeton University Press, 1957.

\bibitem{blundell2015weight}
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra.
\newblock Weight uncertainty in neural networks.
\newblock {\em arXiv preprint arXiv:1505.05424}, 2015.

\bibitem{bradtke1996linear}
Steven~J Bradtke and Andrew~G Barto.
\newblock Linear least-squares algorithms for temporal difference learning.
\newblock {\em Machine learning}, 22(1-3):33--57, 1996.

\bibitem{downey2010temporal}
Carlton Downey, Scott Sanner, et~al.
\newblock Temporal difference bayesian model averaging: A bayesian perspective
  on adapting lambda.
\newblock In {\em ICML}, pages 311--318. Citeseer, 2010.

\bibitem{efron1982jackknife}
Bradley Efron.
\newblock {\em The jackknife, the bootstrap, and other resampling plans},
  volume~38.
\newblock Siam, 1982.

\bibitem{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em international conference on machine learning}, pages
  1050--1059, 2016.

\bibitem{Geist2014}
Matthieu Geist and Bruno Scherrer.
\newblock Off-policy learning with eligibility traces: A survey.
\newblock {\em J. Mach. Learn. Res.}, 15(1):289--333, 2014.

\bibitem{lakshminarayanan2017simple}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6402--6413, 2017.

\bibitem{mandt2016variational}
Stephan Mandt, Matthew Hoffman, and David Blei.
\newblock A variational analysis of stochastic gradient algorithms.
\newblock In {\em International Conference on Machine Learning}, pages
  354--363, 2016.

\bibitem{mann2016adaptive}
Timothy~A Mann, Hugo Penedones, Shie Mannor, and Todd Hester.
\newblock Adaptive lambda least-squares temporal difference learning.
\newblock {\em arXiv preprint arXiv:1612.09465}, 2016.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529, 2015.

\bibitem{osband2016deep}
Ian Osband, Charles Blundell, Alexander Pritzel, and Benjamin Van~Roy.
\newblock Deep exploration via bootstrapped dqn.
\newblock In {\em Advances in neural information processing systems}, pages
  4026--4034, 2016.

\bibitem{penedones2018leakage}
Hugo Penedones, Damien Vincent, Hartmut Maennel, Sylvain Gelly, Timothy Mann,
  and Andre Barreto.
\newblock Temporal difference learning with neural networks-study of the
  leakage propagation problem.
\newblock {\em arXiv preprint arXiv:1807.03064}, 2018.

\bibitem{rasmussen2003gaussian}
Carl~Edward Rasmussen.
\newblock Gaussian processes in machine learning.
\newblock In {\em Summer School on Machine Learning}, pages 63--71. Springer,
  2003.

\bibitem{riquelme2018deep}
Carlos Riquelme, George Tucker, and Jasper Snoek.
\newblock Deep bayesian bandits showdown: An empirical comparison of bayesian
  deep networks for thompson sampling.
\newblock {\em arXiv preprint arXiv:1802.09127}, 2018.

\bibitem{scherrer2010should}
Bruno Scherrer.
\newblock Should one compute the temporal difference fix point or minimize the
  {B}ellman residual? {T}he unified oblique projection view.
\newblock In {\em 27th International Conference on Machine Learning-ICML 2010},
  2010.

\bibitem{snoek2015scalable}
Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish,
  Narayanan Sundaram, Mostofa Patwary, Mr~Prabhat, and Ryan Adams.
\newblock Scalable bayesian optimization using deep neural networks.
\newblock In {\em International conference on machine learning}, pages
  2171--2180, 2015.

\bibitem{Sutton2014Q}
Rich Sutton, Ashique~Rupam Mahmood, Doina Precup, and Hado Hasselt.
\newblock A new {$Q(\lambda)$} with interim forward view and {Monte Carlo}
  equivalence.
\newblock In Eric~P. Xing and Tony Jebara, editors, {\em Proceedings of the
  31st International Conference on Machine Learning}, volume~32 of {\em
  Proceedings of Machine Learning Research}, pages 568--576, Bejing, China,
  22--24 Jun 2014. PMLR.

\bibitem{Sutton2015}
Richard Sutton, Ashique~Rupam Mahmood, and Martha White.
\newblock An emphatic approach to the problem of off-policy temporal-difference
  learning.
\newblock {\em Journal of Machine Learning Research}, 17, 03 2015.

\bibitem{sutton1988learning}
Richard~S Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock {\em Machine learning}, 3(1):9--44, 1988.

\bibitem{sutton1998introduction}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock MIT press Cambridge, 1998.

\bibitem{sutton2018introduction}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement Learning: An Introduction - second edition}.
\newblock MIT press Cambridge, 2018.

\bibitem{Thomas2015}
Philip~S. Thomas, Scott Niekum, Georgios Theocharous, and George Konidaris.
\newblock Policy evaluation using the {$\Omega$-Return}.
\newblock In C.~Cortes, N.~D. Lawrence, D.~D. Lee, M.~Sugiyama, and R.~Garnett,
  editors, {\em Advances in Neural Information Processing Systems 28}, pages
  334--342. Curran Associates, Inc., 2015.

\bibitem{tsitsiklis1997analysis}
John~N Tsitsiklis and Benjamin Van~Roy.
\newblock Analysis of temporal-diffference learning with function
  approximation.
\newblock In {\em Advances in neural information processing systems}, pages
  1075--1081, 1997.

\bibitem{welling2011bayesian}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 681--688, 2011.

\bibitem{White2016AGA}
Martha White and Adam~M. White.
\newblock A greedy approach to adapting the trace parameter for temporal
  difference learning.
\newblock In {\em AAMAS}, 2016.

\end{thebibliography}
