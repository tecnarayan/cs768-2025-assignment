\begin{thebibliography}{72}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2023)Agarwal, Kumar, Malik, and Pathak]{egocentric}
Agarwal, A., Kumar, A., Malik, J., and Pathak, D.
\newblock Legged locomotion in challenging terrains using egocentric vision.
\newblock In \emph{Conference on Robot Learning}, pp.\  403--415. PMLR, 2023.

\bibitem[Ahn et~al.(2024)Ahn, Dwibedi, Finn, Arenas, Gopalakrishnan, Hausman, Ichter, Irpan, Joshi, Julian, et~al.]{gdm2024autort}
Ahn, M., Dwibedi, D., Finn, C., Arenas, M.~G., Gopalakrishnan, K., Hausman, K., Ichter, B., Irpan, A., Joshi, N., Julian, R., et~al.
\newblock Autort: Embodied foundation models for large scale orchestration of robotic agents.
\newblock \emph{arXiv preprint arXiv:2401.12963}, 2024.

\bibitem[Andrychowicz et~al.(2020)Andrychowicz, Baker, Chociej, Jozefowicz, McGrew, Pachocki, Petron, Plappert, Powell, Ray, et~al.]{andrychowicz2020learning}
Andrychowicz, O.~M., Baker, B., Chociej, M., Jozefowicz, R., McGrew, B., Pachocki, J., Petron, A., Plappert, M., Powell, G., Ray, A., et~al.
\newblock Learning dexterous in-hand manipulation.
\newblock \emph{The International Journal of Robotics Research}, 39\penalty0 (1):\penalty0 3--20, 2020.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layernorm}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bousmalis et~al.(2023)Bousmalis, Vezzani, Rao, Devin, Lee, Bauza, Davchev, Zhou, Gupta, Raju, et~al.]{robocat}
Bousmalis, K., Vezzani, G., Rao, D., Devin, C., Lee, A.~X., Bauza, M., Davchev, T., Zhou, Y., Gupta, A., Raju, A., et~al.
\newblock Robocat: A self-improving foundation agent for robotic manipulation.
\newblock \emph{arXiv preprint arXiv:2306.11706}, 2023.

\bibitem[Brohan et~al.(2022)Brohan, Brown, Carbajal, Chebotar, Dabis, Finn, Gopalakrishnan, Hausman, Herzog, Hsu, et~al.]{rt1}
Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabis, J., Finn, C., Gopalakrishnan, K., Hausman, K., Herzog, A., Hsu, J., et~al.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock \emph{arXiv preprint arXiv:2212.06817}, 2022.

\bibitem[Brohan et~al.(2023)Brohan, Brown, Carbajal, Chebotar, Chen, Choromanski, Ding, Driess, Dubey, Finn, et~al.]{rt2}
Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K., Ding, T., Driess, D., Dubey, A., Finn, C., et~al.
\newblock Rt-2: Vision-language-action models transfer web knowledge to robotic control.
\newblock \emph{arXiv preprint arXiv:2307.15818}, 2023.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chebotar et~al.(2023)Chebotar, Vuong, Hausman, Xia, Lu, Irpan, Kumar, Yu, Herzog, Pertsch, et~al.]{q_transformer}
Chebotar, Y., Vuong, Q., Hausman, K., Xia, F., Lu, Y., Irpan, A., Kumar, A., Yu, T., Herzog, A., Pertsch, K., et~al.
\newblock Q-transformer: Scalable offline reinforcement learning via autoregressive q-functions.
\newblock In \emph{Conference on Robot Learning}, pp.\  3909--3928. PMLR, 2023.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel, Srinivas, and Mordatch]{DT}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 15084--15097, 2021.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and Duvenaud]{chen2018neural}
Chen, R.~T., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K.
\newblock Neural ordinary differential equations.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Child et~al.(2019)Child, Gray, Radford, and Sutskever]{sparse_transformer}
Child, R., Gray, S., Radford, A., and Sutskever, I.
\newblock Generating long sequences with sparse transformers.
\newblock \emph{arXiv preprint arXiv:1904.10509}, 2019.

\bibitem[Dai et~al.(2019)Dai, Yang, Yang, Carbonell, Le, and Salakhutdinov]{transformerxl}
Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q.~V., and Salakhutdinov, R.
\newblock Transformer-xl: Attentive language models beyond a fixed-length context.
\newblock \emph{arXiv preprint arXiv:1901.02860}, 2019.

\bibitem[Dao(2023)]{flashattention2}
Dao, T.
\newblock Flashattention-2: Faster attention with better parallelism and work partitioning.
\newblock \emph{arXiv preprint arXiv:2307.08691}, 2023.

\bibitem[Dao et~al.(2022)Dao, Fu, Ermon, Rudra, and R{\'e}]{flashattention}
Dao, T., Fu, D., Ermon, S., Rudra, A., and R{\'e}, C.
\newblock Flashattention: Fast and memory-efficient exact attention with io-awareness.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 16344--16359, 2022.

\bibitem[Fellows et~al.(2018)Fellows, Ciosek, and Whiteson]{fellows2018fourier}
Fellows, M., Ciosek, K., and Whiteson, S.
\newblock Fourier policy gradients.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1486--1495. PMLR, 2018.

\bibitem[Feng et~al.(2023)Feng, Zhang, Li, Peng, Basireddy, Yue, Song, Yang, Liu, Sreenath, et~al.]{genloco}
Feng, G., Zhang, H., Li, Z., Peng, X.~B., Basireddy, B., Yue, L., Song, Z., Yang, L., Liu, Y., Sreenath, K., et~al.
\newblock Genloco: Generalized locomotion controllers for quadrupedal robots.
\newblock In \emph{Conference on Robot Learning}, pp.\  1893--1903. PMLR, 2023.

\bibitem[Fu et~al.(2022)Fu, Dao, Saab, Thomas, Rudra, and R{\'e}]{h3}
Fu, D.~Y., Dao, T., Saab, K.~K., Thomas, A.~W., Rudra, A., and R{\'e}, C.
\newblock Hungry hungry hippos: Towards language modeling with state space models.
\newblock \emph{arXiv preprint arXiv:2212.14052}, 2022.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{d4rl}
Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Fu et~al.(2024)Fu, Zhao, and Finn]{mobile_aloha}
Fu, Z., Zhao, T.~Z., and Finn, C.
\newblock Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation.
\newblock \emph{arXiv preprint arXiv:2401.02117}, 2024.

\bibitem[Ghosh et~al.(2021)Ghosh, Rahme, Kumar, Zhang, Adams, and Levine]{ghosh2021generalization}
Ghosh, D., Rahme, J., Kumar, A., Zhang, A., Adams, R.~P., and Levine, S.
\newblock Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 25502--25515, 2021.

\bibitem[Gu \& Dao(2023)Gu and Dao]{mamba}
Gu, A. and Dao, T.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock \emph{arXiv preprint arXiv:2312.00752}, 2023.

\bibitem[Gu et~al.(2023)Gu, Kirmani, Wohlhart, Lu, Arenas, Rao, Yu, Fu, Gopalakrishnan, Xu, et~al.]{gu2023rttrajectory}
Gu, J., Kirmani, S., Wohlhart, P., Lu, Y., Arenas, M.~G., Rao, K., Yu, W., Fu, C., Gopalakrishnan, K., Xu, Z., et~al.
\newblock Rt-trajectory: Robotic task generalization via hindsight trajectory sketches.
\newblock \emph{arXiv preprint arXiv:2311.01977}, 2023.

\bibitem[Gu et~al.(2017)Gu, Holly, Lillicrap, and Levine]{gu2017deep}
Gu, S., Holly, E., Lillicrap, T., and Levine, S.
\newblock Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates.
\newblock In \emph{2017 IEEE international conference on robotics and automation (ICRA)}, pp.\  3389--3396. IEEE, 2017.

\bibitem[Gupta et~al.(2016)Gupta, Eppner, Levine, and Abbeel]{gupta2016learning}
Gupta, A., Eppner, C., Levine, S., and Abbeel, P.
\newblock Learning dexterous manipulation for a soft robotic hand from human demonstrations.
\newblock In \emph{2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, pp.\  3786--3793. IEEE, 2016.

\bibitem[Hao et~al.(2022)Hao, Liu, Zhang, Ying, Feng, Su, and Zhu]{hao2022physics}
Hao, Z., Liu, S., Zhang, Y., Ying, C., Feng, Y., Su, H., and Zhu, J.
\newblock Physics-informed machine learning: A survey on problems, methods and applications.
\newblock \emph{arXiv preprint arXiv:2211.08064}, 2022.

\bibitem[He et~al.(2023)He, Yang, Feng, Yin, Wang, Leng, and Lin]{fourier_transformer}
He, Z., Yang, M., Feng, M., Yin, J., Wang, X., Leng, J., and Lin, Z.
\newblock Fourier transformer: Fast long range modeling by removing sequence redundancy with fft operator.
\newblock \emph{arXiv preprint arXiv:2305.15099}, 2023.

\bibitem[Hendrycks \& Gimpel(2016)Hendrycks and Gimpel]{gelu}
Hendrycks, D. and Gimpel, K.
\newblock Gaussian error linear units (gelus).
\newblock \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{TT}
Janner, M., Li, Q., and Levine, S.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 1273--1286, 2021.

\bibitem[Jiang et~al.(2022)Jiang, Gupta, Zhang, Wang, Dou, Chen, Fei-Fei, Anandkumar, Zhu, and Fan]{vima}
Jiang, Y., Gupta, A., Zhang, Z., Wang, G., Dou, Y., Chen, Y., Fei-Fei, L., Anandkumar, A., Zhu, Y., and Fan, L.
\newblock Vima: General robot manipulation with multimodal prompts.
\newblock In \emph{NeurIPS 2022 Foundation Models for Decision Making Workshop}, 2022.

\bibitem[Kalashnikov et~al.(2018)Kalashnikov, Irpan, Pastor, Ibarz, Herzog, Jang, Quillen, Holly, Kalakrishnan, Vanhoucke, et~al.]{kalashnikov2018scalable}
Kalashnikov, D., Irpan, A., Pastor, P., Ibarz, J., Herzog, A., Jang, E., Quillen, D., Holly, E., Kalakrishnan, M., Vanhoucke, V., et~al.
\newblock Scalable deep reinforcement learning for vision-based robotic manipulation.
\newblock In \emph{Conference on Robot Learning}, pp.\  651--673. PMLR, 2018.

\bibitem[Kalashnikov et~al.(2021)Kalashnikov, Varley, Chebotar, Swanson, Jonschkowski, Finn, Levine, and Hausman]{kalashnikov2021mt}
Kalashnikov, D., Varley, J., Chebotar, Y., Swanson, B., Jonschkowski, R., Finn, C., Levine, S., and Hausman, K.
\newblock Mt-opt: Continuous multi-task robotic reinforcement learning at scale.
\newblock \emph{arXiv preprint arXiv:2104.08212}, 2021.

\bibitem[Karniadakis et~al.(2021)Karniadakis, Kevrekidis, Lu, Perdikaris, Wang, and Yang]{karniadakis2021physics}
Karniadakis, G.~E., Kevrekidis, I.~G., Lu, L., Perdikaris, P., Wang, S., and Yang, L.
\newblock Physics-informed machine learning.
\newblock \emph{Nature Reviews Physics}, 3\penalty0 (6):\penalty0 422--440, 2021.

\bibitem[Kashiri et~al.(2018)Kashiri, Abate, Abram, Albu-Schaffer, Clary, Daley, Faraji, Furnemont, Garabini, Geyer, et~al.]{kashiri2018overview}
Kashiri, N., Abate, A., Abram, S.~J., Albu-Schaffer, A., Clary, P.~J., Daley, M., Faraji, S., Furnemont, R., Garabini, M., Geyer, H., et~al.
\newblock An overview on principles for energy efficient robot locomotion.
\newblock \emph{Frontiers in Robotics and AI}, 5:\penalty0 129, 2018.

\bibitem[Katharopoulos et~al.(2020)Katharopoulos, Vyas, Pappas, and Fleuret]{linear_transformers}
Katharopoulos, A., Vyas, A., Pappas, N., and Fleuret, F.
\newblock Transformers are rnns: Fast autoregressive transformers with linear attention.
\newblock In \emph{International conference on machine learning}, pp.\  5156--5165. PMLR, 2020.

\bibitem[Kitaev et~al.(2020)Kitaev, Kaiser, and Levskaya]{Reformer}
Kitaev, N., Kaiser, {\L}., and Levskaya, A.
\newblock Reformer: The efficient transformer.
\newblock \emph{arXiv preprint arXiv:2001.04451}, 2020.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Soh, Tucker, and Levine]{kumar2019stabilizing}
Kumar, A., Fu, J., Soh, M., Tucker, G., and Levine, S.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{kumar2020conservative}
Kumar, A., Zhou, A., Tucker, G., and Levine, S.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 1179--1191, 2020.

\bibitem[Kumar et~al.(2022)Kumar, Singh, Ebert, Nakamoto, Yang, Finn, and Levine]{kumar2022pre}
Kumar, A., Singh, A., Ebert, F., Nakamoto, M., Yang, Y., Finn, C., and Levine, S.
\newblock Pre-training for robots: Offline rl enables learning new tasks from a handful of trials.
\newblock \emph{arXiv preprint arXiv:2210.05178}, 2022.

\bibitem[Lai et~al.(2023)Lai, Zhang, He, Yu, Tian, Yu, and Wang]{tert}
Lai, H., Zhang, W., He, X., Yu, C., Tian, Z., Yu, Y., and Wang, J.
\newblock Sim-to-real transfer for quadrupedal locomotion via terrain transformer.
\newblock In \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}, pp.\  5141--5147. IEEE, 2023.

\bibitem[Lee et~al.(2021)Lee, Devin, Zhou, Lampe, Bousmalis, Springenberg, Byravan, Abdolmaleki, Gileadi, Khosid, et~al.]{lee2022beyond}
Lee, A.~X., Devin, C.~M., Zhou, Y., Lampe, T., Bousmalis, K., Springenberg, J.~T., Byravan, A., Abdolmaleki, A., Gileadi, N., Khosid, D., et~al.
\newblock Beyond pick-and-place: Tackling robotic stacking of diverse shapes.
\newblock In \emph{5th Annual Conference on Robot Learning}, 2021.

\bibitem[Lee et~al.(2020{\natexlab{a}})Lee, Hwangbo, Wellhausen, Koltun, and Hutter]{eth2020}
Lee, J., Hwangbo, J., Wellhausen, L., Koltun, V., and Hutter, M.
\newblock Learning quadrupedal locomotion over challenging terrain.
\newblock \emph{Science robotics}, 5\penalty0 (47):\penalty0 eabc5986, 2020{\natexlab{a}}.

\bibitem[Lee et~al.(2020{\natexlab{b}})Lee, Seo, Lee, Lee, and Shin]{lee2020context}
Lee, K., Seo, Y., Lee, S., Lee, H., and Shin, J.
\newblock Context-aware dynamics model for generalization in model-based reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  5757--5766. PMLR, 2020{\natexlab{b}}.

\bibitem[Lee-Thorp et~al.(2021)Lee-Thorp, Ainslie, Eckstein, and Ontanon]{fnet}
Lee-Thorp, J., Ainslie, J., Eckstein, I., and Ontanon, S.
\newblock Fnet: Mixing tokens with fourier transforms.
\newblock \emph{arXiv preprint arXiv:2105.03824}, 2021.

\bibitem[Li et~al.(2020)Li, Kovachki, Azizzadenesheli, Liu, Bhattacharya, Stuart, and Anandkumar]{li2020fourier}
Li, Z., Kovachki, N., Azizzadenesheli, K., Liu, B., Bhattacharya, K., Stuart, A., and Anandkumar, A.
\newblock Fourier neural operator for parametric partial differential equations.
\newblock \emph{arXiv preprint arXiv:2010.08895}, 2020.

\bibitem[Makoviychuk et~al.(2021)Makoviychuk, Wawrzyniak, Guo, Lu, Storey, Macklin, Hoeller, Rudin, Allshire, Handa, et~al.]{isaacgym}
Makoviychuk, V., Wawrzyniak, L., Guo, Y., Lu, M., Storey, K., Macklin, M., Hoeller, D., Rudin, N., Allshire, A., Handa, A., et~al.
\newblock Isaac gym: High performance gpu-based physics simulation for robot learning.
\newblock \emph{arXiv preprint arXiv:2108.10470}, 2021.

\bibitem[Margolis \& Agrawal(2023)Margolis and Agrawal]{mit2022}
Margolis, G.~B. and Agrawal, P.
\newblock Walk these ways: Tuning robot control for generalization with multiplicity of behavior.
\newblock In \emph{Conference on Robot Learning}, pp.\  22--31. PMLR, 2023.

\bibitem[Nguyen et~al.(2022)Nguyen, Pham, Nguyen, Nguyen, Osher, and Ho]{fourierformer}
Nguyen, T., Pham, M., Nguyen, T., Nguyen, K., Osher, S., and Ho, N.
\newblock Fourierformer: Transformer meets generalized fourier integral theorem.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 29319--29335, 2022.

\bibitem[Padalkar et~al.(2023)Padalkar, Pooley, Jain, Bewley, Herzog, Irpan, Khazatsky, Rai, Singh, Brohan, et~al.]{rtx}
Padalkar, A., Pooley, A., Jain, A., Bewley, A., Herzog, A., Irpan, A., Khazatsky, A., Rai, A., Singh, A., Brohan, A., et~al.
\newblock Open x-embodiment: Robotic learning datasets and rt-x models.
\newblock \emph{arXiv preprint arXiv:2310.08864}, 2023.

\bibitem[Peng et~al.(2023)Peng, Alcaide, Anthony, Albalak, Arcadinho, Cao, Cheng, Chung, Grella, GV, et~al.]{peng2023rwkv}
Peng, B., Alcaide, E., Anthony, Q., Albalak, A., Arcadinho, S., Cao, H., Cheng, X., Chung, M., Grella, M., GV, K.~K., et~al.
\newblock Rwkv: Reinventing rnns for the transformer era.
\newblock \emph{arXiv preprint arXiv:2305.13048}, 2023.

\bibitem[Peng et~al.(2019)Peng, Kumar, Zhang, and Levine]{peng2019advantage}
Peng, X.~B., Kumar, A., Zhang, G., and Levine, S.
\newblock Advantage-weighted regression: Simple and scalable off-policy reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.00177}, 2019.

\bibitem[Poli et~al.(2023)Poli, Massaroli, Nguyen, Fu, Dao, Baccus, Bengio, Ermon, and R{\'e}]{poli2023hyena}
Poli, M., Massaroli, S., Nguyen, E., Fu, D.~Y., Dao, T., Baccus, S., Bengio, Y., Ermon, S., and R{\'e}, C.
\newblock Hyena hierarchy: Towards larger convolutional language models.
\newblock \emph{arXiv preprint arXiv:2302.10866}, 2023.

\bibitem[Qi et~al.(2017)Qi, Su, Mo, and Guibas]{qi2017pointnet}
Qi, C.~R., Su, H., Mo, K., and Guibas, L.~J.
\newblock Pointnet: Deep learning on point sets for 3d classification and segmentation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  652--660, 2017.

\bibitem[Radosavovic et~al.(2023)Radosavovic, Xiao, Zhang, Darrell, Malik, and Sreenath]{HumanoidTransformer}
Radosavovic, I., Xiao, T., Zhang, B., Darrell, T., Malik, J., and Sreenath, K.
\newblock Learning humanoid locomotion with transformers.
\newblock \emph{arXiv preprint arXiv:2303.03381}, 2023.

\bibitem[Rajeswaran et~al.(2017)Rajeswaran, Kumar, Gupta, Vezzani, Schulman, Todorov, and Levine]{rajeswaran2017learning}
Rajeswaran, A., Kumar, V., Gupta, A., Vezzani, G., Schulman, J., Todorov, E., and Levine, S.
\newblock Learning complex dexterous manipulation with deep reinforcement learning and demonstrations.
\newblock \emph{arXiv preprint arXiv:1709.10087}, 2017.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov, Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, et~al.]{gato}
Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.~G., Novikov, A., Barth-Maron, G., Gimenez, M., Sulsky, Y., Kay, J., Springenberg, J.~T., et~al.
\newblock A generalist agent.
\newblock \emph{arXiv preprint arXiv:2205.06175}, 2022.

\bibitem[Rudin et~al.(2022)Rudin, Hoeller, Reist, and Hutter]{eth2022}
Rudin, N., Hoeller, D., Reist, P., and Hutter, M.
\newblock Learning to walk in minutes using massively parallel deep reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  91--100. PMLR, 2022.

\bibitem[Sandha et~al.(2021)Sandha, Garcia, Balaji, Anwar, and Srivastava]{sandha2021sim2real}
Sandha, S.~S., Garcia, L., Balaji, B., Anwar, F., and Srivastava, M.
\newblock Sim2real transfer for deep reinforcement learning with stochastic state transition delays.
\newblock In \emph{Conference on Robot Learning}, pp.\  1066--1083. PMLR, 2021.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{ppo}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Sun et~al.(2023)Sun, Dong, Huang, Ma, Xia, Xue, Wang, and Wei]{retnet}
Sun, Y., Dong, L., Huang, S., Ma, S., Xia, Y., Xue, J., Wang, J., and Wei, F.
\newblock Retentive network: A successor to transformer for large language models.
\newblock \emph{arXiv preprint arXiv:2307.08621}, 2023.

\bibitem[Trefethen(1996)]{trefethen1996finite}
Trefethen, L.~N.
\newblock Finite difference and spectral methods for ordinary and partial differential equations.
\newblock 1996.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{transformer}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Wen et~al.(2022)Wen, Wan, Zhou, Hou, Cao, Le, Chen, Tian, Zhang, and Wang]{db1}
Wen, Y., Wan, Z., Zhou, M., Hou, S., Cao, Z., Le, C., Chen, J., Tian, Z., Zhang, W., and Wang, J.
\newblock On realization of intelligent decision-making in the real world: A foundation decision model perspective.
\newblock \emph{arXiv preprint arXiv:2212.12669}, 2022.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{wu2019behavior}
Wu, Y., Tucker, G., and Nachum, O.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.11361}, 2019.

\bibitem[Xiao et~al.(2023)Xiao, Tian, Chen, Han, and Lewis]{streamingllm}
Xiao, G., Tian, Y., Chen, B., Han, S., and Lewis, M.
\newblock Efficient streaming language models with attention sinks.
\newblock Sep 2023.

\bibitem[Xiong et~al.(2024)Xiong, Mendonca, Shaw, and Pathak]{cmu_xiong2024adaptive}
Xiong, H., Mendonca, R., Shaw, K., and Pathak, D.
\newblock Adaptive mobile manipulation for articulated objects in the open world.
\newblock \emph{arXiv preprint arXiv:2401.14403}, 2024.

\bibitem[Xu et~al.(2024)Xu, Zeng, and Xu]{xu2024fits}
Xu, Z., Zeng, A., and Xu, Q.
\newblock Fits: Modeling time series with $10k$ parameters, 2024.

\bibitem[Ye et~al.(2024)Ye, Kuang, Wang, Rui, Zhou, Li, and Wu]{spf}
Ye, M., Kuang, Y., Wang, J., Rui, Y., Zhou, W., Li, H., and Wu, F.
\newblock State sequences prediction via fourier transform for representation learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Ying et~al.(2023)Ying, Hao, Zhou, Su, Liu, Li, Yan, and Zhu]{ying2023reward}
Ying, C., Hao, Z., Zhou, X., Su, H., Liu, S., Li, J., Yan, D., and Zhu, J.
\newblock Reward informed dreamer for task generalization in reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2303.05092}, 2023.

\bibitem[Yu et~al.(2023)Yu, Zhang, Lai, Tian, Kneip, and Wang]{eat}
Yu, C., Zhang, W., Lai, H., Tian, Z., Kneip, L., and Wang, J.
\newblock Multi-embodiment legged robot control as a sequence modeling problem.
\newblock In \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}, pp.\  7250--7257. IEEE, 2023.

\bibitem[Yu et~al.(2020)Yu, Kumar, Gupta, Levine, Hausman, and Finn]{yu2020gradient}
Yu, T., Kumar, S., Gupta, A., Levine, S., Hausman, K., and Finn, C.
\newblock Gradient surgery for multi-task learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 5824--5836, 2020.

\bibitem[Zhang et~al.(2019)Zhang, Tong, Xu, and Maciejewski]{zhang2019graph}
Zhang, S., Tong, H., Xu, J., and Maciejewski, R.
\newblock Graph convolutional networks: a comprehensive review.
\newblock \emph{Computational Social Networks}, 6\penalty0 (1):\penalty0 1--23, 2019.

\end{thebibliography}
