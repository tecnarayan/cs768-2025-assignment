@inproceedings{rabbat2004distributed,
	title={Distributed optimization in sensor networks},
	author={Rabbat, Michael and Nowak, Robert},
	booktitle={Proceedings of the 3rd international symposium on Information processing in sensor networks},
	pages={20--27},
	year={2004}
}

@inproceedings{ye2020mastering,
	title={Mastering complex control in {MOBA} games with deep reinforcement learning},
	author={Ye, Deheng and Liu, Zhao and Sun, Mingfei and Shi, Bei and Zhao, Peilin and Wu, Hao and Yu, Hongsheng and Yang, Shaojie and Wu, Xipeng and Guo, Qingwei and others},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={34},
	pages={6672--6679},
	year={2020}
}

@inproceedings{cao2020adversarial,
	title={Adversarial Attacks and Detection on Reinforcement Learning-Based Interactive Recommender Systems},
	author={Cao, Yuanjiang and Chen, Xiaocong and Yao, Lina and Wang, Xianzhi and Zhang, Wei Emma},
	booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages={1669--1672},
	year={2020}
}

@article{adler2002cooperative,
	title={A cooperative multi-agent transportation management and route guidance system},
	author={Adler, Jeffrey L and Blue, Victor J},
	journal={Transportation Research Part C: Emerging Technologies},
	volume={10},
	number={5-6},
	pages={433--454},
	year={2002},
	publisher={Elsevier}
}

@article{callaway2010achieving,
	title={Achieving controllability of electric loads},
	author={Callaway, Duncan S and Hiskens, Ian A},
	journal={Proceedings of the IEEE},
	volume={99},
	number={1},
	pages={184--199},
	year={2010},
	publisher={IEEE}
}

@article{fujimoto2019benchmarking,
	title={Benchmarking batch deep reinforcement learning algorithms},
	author={Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle},
	journal={arXiv preprint arXiv:1910.01708},
	year={2019}
}

@article{nachum2019dualdice,
  title={{DualDICE}: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={2318--2328},
  year={2019}
}

@inproceedings{ajay2020opal,
  title={{OPAL}: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{laroche2019safe,
	title={Safe policy improvement with baseline bootstrapping},
	author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
	booktitle={International Conference on Machine Learning},
	pages={3652--3661},
	year={2019},
	organization={PMLR}
}

@inproceedings{vuong2018supervised,
  title={Supervised Policy Update for Deep Reinforcement Learning},
  author={Vuong, Quan and Zhang, Yiming and Ross, Keith W},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{fakoor2020p3o,
	title={{P3O}: Policy-on policy-off policy optimization},
	author={Fakoor, Rasool and Chaudhari, Pratik and Smola, Alexander J},
	booktitle={Uncertainty in Artificial Intelligence},
	pages={1017--1027},
	year={2020},
	organization={PMLR}
}

@article{kingma2013auto,
	title={Auto-encoding variational bayes},
	author={Kingma, Diederik P and Welling, Max},
	journal={arXiv preprint arXiv:1312.6114},
	year={2013}
}

@article{sohn2015learning,
	title={Learning structured output representation using deep conditional generative models},
	author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
	journal={Advances in neural information processing systems},
	volume={28},
	pages={3483--3491},
	year={2015}
}

@article{de2005tutorial,
	title={A tutorial on the cross-entropy method},
	author={De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
	journal={Annals of operations research},
	volume={134},
	number={1},
	pages={19--67},
	year={2005},
	publisher={Springer}
}

@article{santamaria1997experiments,
	title={Experiments with reinforcement learning in problems with continuous state and action spaces},
	author={Santamaria, Juan C and Sutton, Richard S and Ram, Ashwin},
	journal={Adaptive behavior},
	volume={6},
	number={2},
	pages={163--217},
	year={1997},
	publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{neal2001annealed,
	title={Annealed importance sampling},
	author={Neal, Radford M},
	journal={Statistics and computing},
	volume={11},
	number={2},
	pages={125--139},
	year={2001},
	publisher={Springer}
}

@article{sason2016f,
	title={$ f $-divergence Inequalities},
	author={Sason, Igal and Verd{\'u}, Sergio},
	journal={IEEE Transactions on Information Theory},
	volume={62},
	number={11},
	pages={5973--6006},
	year={2016},
	publisher={IEEE}
}

@article{dreves2011solution,
	title={On the solution of the {KKT} conditions of generalized Nash equilibrium problems},
	author={Dreves, Axel and Facchinei, Francisco and Kanzow, Christian and Sagratella, Simone},
	journal={SIAM Journal on Optimization},
	volume={21},
	number={3},
	pages={1082--1108},
	year={2011},
	publisher={SIAM}
}

@inproceedings{codevilla2019exploring,
	title={Exploring the limitations of behavior cloning for autonomous driving},
	author={Codevilla, Felipe and Santana, Eder and L{\'o}pez, Antonio M and Gaidon, Adrien},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={9329--9338},
	year={2019}
}

@inproceedings{kalashnikov2018scalable,
	title={Scalable deep reinforcement learning for vision-based robotic manipulation},
	author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
	booktitle={Conference on Robot Learning},
	pages={651--673},
	year={2018},
	organization={PMLR}
}

@article{wu2019behavior,
	title={Behavior regularized offline reinforcement learning},
	author={Wu, Yifan and Tucker, George and Nachum, Ofir},
	journal={arXiv preprint arXiv:1911.11361},
	year={2019}
}

@inproceedings{todorov2007linearly,
	title={Linearly-solvable Markov decision problems},
	author={Todorov, Emanuel},
	booktitle={Advances in neural information processing systems},
	pages={1369--1376},
	year={2007}
}

@article{jaques2019way,
	title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
	author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
	journal={arXiv preprint arXiv:1907.00456},
	year={2019}
}

@article{sriperumbudur2012empirical,
	title={On the empirical estimation of integral probability metrics},
	author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG and others},
	journal={Electronic Journal of Statistics},
	volume={6},
	pages={1550--1599},
	year={2012},
	publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{vallender1974calculation,
	title={Calculation of the Wasserstein distance between probability distributions on the line},
	author={Vallender, SS},
	journal={Theory of Probability \& Its Applications},
	volume={18},
	number={4},
	pages={784--786},
	year={1974},
	publisher={SIAM}
}

@inproceedings{jiang2016doubly,
	title={Doubly robust off-policy value evaluation for reinforcement learning},
	author={Jiang, Nan and Li, Lihong},
	booktitle={International Conference on Machine Learning},
	pages={652--661},
	year={2016},
	organization={PMLR}
}

@inproceedings{thomas2016data,
	title={Data-efficient off-policy policy evaluation for reinforcement learning},
	author={Thomas, Philip and Brunskill, Emma},
	booktitle={International Conference on Machine Learning},
	pages={2139--2148},
	year={2016},
	organization={PMLR}
}

@inproceedings{farajtabar2018more,
	title={More robust doubly robust off-policy evaluation},
	author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
	booktitle={International Conference on Machine Learning},
	pages={1447--1456},
	year={2018},
	organization={PMLR}
}

@inproceedings{wang2017optimal,
	title={Optimal and adaptive off-policy evaluation in contextual bandits},
	author={Wang, Yu-Xiang and Agarwal, Alekh and Dud{\i}k, Miroslav},
	booktitle={International Conference on Machine Learning},
	pages={3589--3597},
	year={2017},
	organization={PMLR}
}

@inproceedings{kahn2018composable,
	title={Composable action-conditioned predictors: Flexible off-policy learning for robot navigation},
	author={Kahn, Gregory and Villaflor, Adam and Abbeel, Pieter and Levine, Sergey},
	booktitle={Conference on Robot Learning},
	pages={806--816},
	year={2018},
	organization={PMLR}
}

@article{berkenkamp2017safe,
	title={Safe model-based reinforcement learning with stability guarantees},
	author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
	journal={arXiv preprint arXiv:1705.08551},
	year={2017}
}

@article{eysenbach2017leave,
	title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
	author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
	journal={arXiv preprint arXiv:1711.06782},
	year={2017}
}

@article{sonabend2020expert,
	title={Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation},
	author={Sonabend-W, Aaron and Lu, Junwei and Celi, Leo A and Cai, Tianxi and Szolovits, Peter},
	journal={arXiv preprint arXiv:2006.13189},
	year={2020}
}

@article{rajeswaran2017learning,
	title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
	author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
	journal={arXiv preprint arXiv:1709.10087},
	year={2017}
}

@article{gupta2019relay,
	title={Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning},
	author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
	journal={arXiv preprint arXiv:1910.11956},
	year={2019}
}

@article{watkins1992q,
	title={Q-learning},
	author={Watkins, Christopher JCH and Dayan, Peter},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={279--292},
	year={1992},
	publisher={Springer}
}

@inproceedings{touati2020randomized,
	title={Randomized value functions via multiplicative normalizing flows},
	author={Touati, Ahmed and Satija, Harsh and Romoff, Joshua and Pineau, Joelle and Vincent, Pascal},
	booktitle={Uncertainty in Artificial Intelligence},
	pages={422--432},
	year={2020},
	organization={PMLR}
}

@inproceedings{osband2018randomized,
	title={Randomized prior functions for deep reinforcement learning},
	author={Osband, Ian and Aslanides, John and Cassirer, Albin},
	booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
	pages={8626--8638},
	year={2018}
}

@inproceedings{o2018uncertainty,
	title={The uncertainty bellman equation and exploration},
	author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
	booktitle={International Conference on Machine Learning},
	pages={3836--3845},
	year={2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{CooperativeMARL1,
	title={Cooperative multi-agent control using deep reinforcement learning},
	author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
	booktitle={International Conference on Autonomous Agents and Multiagent Systems},
	pages={66--83},
	year={2017},
	organization={Springer}
}

@article{CooperativeMARL2,
	title={A survey and critique of multiagent deep reinforcement learning},
	author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
	journal={Autonomous Agents and Multi-Agent Systems},
	volume={33},
	number={6},
	pages={750--797},
	year={2019},
	publisher={Springer}
}

@inproceedings{traffic_signal_network,
	title={Integrating Independent and Centralized Multi-agent Reinforcement Learning for Traffic Signal Network Optimization},
	author={Zhang, Zhi and Yang, Jiachen and Zha, Hongyuan},
	booktitle={International Conference on Autonomous Agents and Multiagent Systems},
	pages={2083--2085},
	year={2020}
}

@inproceedings{network_packet_routing,
	title={Modelling the Dynamic Joint Policy of Teammates with Attention Multi-agent DDPG},
	author={Mao, Hangyu and Zhang, Zhengchao and Xiao, Zhen and Gong, Zhibo},
	booktitle={International Conference on Autonomous Agents and Multiagent Systems},
	pages={1108--1116},
	year={2019}
}

@inproceedings{EDTI,
	title={Influence-Based Multi-Agent Exploration},
	author={Wang, Tonghan and Wang, Jianhao and Wu, Yi and Zhang, Chongjie},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{levine2020offline,
	title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
	author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	journal={arXiv preprint arXiv:2005.01643},
	year={2020}
}

@article{ebert2018visual,
	title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
	author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
	journal={arXiv preprint arXiv:1812.00568},
	year={2018}
}

@inproceedings{guez2008adaptive,
	title={Adaptive treatment of epilepsy via batch-mode reinforcement learning},
	author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
	booktitle={AAAI Conference on Artificial Intelligence},
	pages={1671--1678},
	year={2008}
}

@inproceedings{kendall2019learning,
	title={Learning to drive in a day},
	author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
	booktitle={International Conference on Robotics and Automation},
	pages={8248--8254},
	year={2019},
	organization={IEEE}
}

@inproceedings{theocharous2015personalized,
	title={Personalized ad recommendation systems for life-time value optimization with guarantees},
	author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
	booktitle={International Joint Conference on Artificial Intelligence},
	year={2015}
}

@inproceedings{fujimoto2019off,
	title={Off-policy deep reinforcement learning without exploration},
	author={Fujimoto, Scott and Meger, David and Precup, Doina},
	booktitle={International Conference on Machine Learning},
	pages={2052--2062},
	year={2019},
	organization={PMLR}
}

@article{fu2020d4rl,
	title={{D4RL}: Datasets for deep data-driven reinforcement learning},
	author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	journal={arXiv preprint arXiv:2004.07219},
	year={2020}
}

@inproceedings{kumar2019stabilizing,
	title={Stabilizing off-policy q-learning via bootstrapping error reduction},
	author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
	booktitle={Advances in Neural Information Processing Systems},
	pages={11784--11794},
	year={2019}
}


@inproceedings{siegel2019keep,
  title={Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{agarwal2020optimistic,
	title={An optimistic perspective on offline reinforcement learning},
	author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
	booktitle={International Conference on Machine Learning},
	pages={104--114},
	year={2020},
	organization={PMLR}
}


@article{nair2020accelerating,
	title={Accelerating online reinforcement learning with offline datasets},
	author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
	journal={arXiv preprint arXiv:2006.09359},
	year={2020}
}

@article{sriperumbudur2009integral,
	title={On integral probability metrics, $\varphi$-divergences and binary classification},
	author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
	journal={arXiv preprint arXiv:0901.2698},
	year={2009}
}

@inproceedings{rashid2018qmix,
	title={{QMIX}: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
	author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
	booktitle={International Conference on Machine Learning},
	pages={4295--4304},
	year={2018}
}

@inproceedings{son2019qtran,
	title={{QTRAN}: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning},
	author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
	booktitle={International Conference on Machine Learning},
	pages={5887--5896},
	year={2019}
}

@inproceedings{sunehag2017value,
	title={Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
	author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
	booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
	pages={2085--2087},
	year={2018}
}

@inproceedings{lowe2017multi,
	title={Multi-agent actor-critic for mixed cooperative-competitive environments},
	author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
	booktitle={Advances in neural information processing systems},
	pages={6379--6390},
	year={2017}
}

@book{oliehoek2016concise,
	title={A concise introduction to decentralized POMDPs},
	author={Oliehoek, Frans A and Amato, Christopher and others},
	volume={1},
	publisher={Springer},
	year={2016}
}

@inproceedings{peters2010relative,
	title={Relative entropy policy search},
	author={Peters, Jan and Mulling, Katharina and Altun, Yasemin},
	booktitle={AAAI Conference on Artificial Intelligence},
	volume={24},
	year={2010}
}

@article{peng2019advantage,
	title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
	author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
	journal={arXiv preprint arXiv:1910.00177},
	year={2019}
}

@article{munos2016safe,
	title={Safe and efficient off-policy reinforcement learning},
	author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
	journal={Advances in neural information processing systems},
	volume={29},
	pages={1054--1062},
	year={2016}
}

@article{kumar2020conservative,
	title={Conservative Q-Learning for Offline Reinforcement Learning},
	author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
	journal={arXiv preprint arXiv:2006.04779},
	year={2020}
}

@inproceedings{foerster2018counterfactual,
	title={Counterfactual multi-agent policy gradients},
	author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
	booktitle={AAAI Conference on Artificial Intelligence},
	volume={32},
	number={1},
	year={2018}
}

@article{wang2020towards,
	title={Towards Understanding Linear Value Decomposition in Cooperative Multi-Agent Q-Learning},
	author={Wang, Jianhao and Ren, Zhizhou and Han, Beining and Zhang, Chongjie},
	journal={arXiv preprint arXiv:2006.00587},
	year={2020}
}

@inproceedings{samvelyan2019starcraft,
	title={The {StarCraft} Multi-Agent Challenge},
	author={Samvelyan, Mikayel and Rashid, Tabish and Schroeder de Witt, Christian and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
	booktitle={International Conference on Autonomous Agents and Multiagent Systems},
	pages={2186--2188},
	year={2019}
}

@article{wang2020off,
	title={Off-Policy Multi-Agent Decomposed Policy Gradients},
	author={Wang, Yihan and Han, Beining and Wang, Tonghan and Dong, Heng and Zhang, Chongjie},
	journal={arXiv preprint arXiv:2007.12322},
	year={2020}
}

@inproceedings{wang2020roma,
	title={Roma: Multi-agent reinforcement learning with emergent roles},
	author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
	booktitle={International Conference on Machine Learning},
	year={2020}
}

@inproceedings{oh2015action,
	title={Action-conditional video prediction using deep networks in Atari games},
	author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
	booktitle={International Conference on Neural Information Processing Systems-Volume 2},
	pages={2863--2871},
	year={2015}
}

@inproceedings{finn2017deep,
	title={Deep visual foresight for planning robot motion},
	author={Finn, Chelsea and Levine, Sergey},
	booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
	pages={2786--2793},
	year={2017},
	organization={IEEE}
}

@article{ernst2005tree,
	title={Tree-based batch mode reinforcement learning},
	author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
	journal={Journal of Machine Learning Research},
	volume={6},
	pages={503--556},
	year={2005},
	publisher={Microtome Publishing}
}

@inproceedings{precup2000eligibility,
	title={Eligibility Traces for Off-Policy Policy Evaluation},
	author={Precup, Doina and Sutton, Richard S and Singh, Satinder P},
	booktitle={International Conference on Machine Learning},
	pages={759--766},
	year={2000}
}

@inproceedings{munos2016q,
	title={Q($\lambda$) with Off-Policy Corrections},
	author={Munos, R{\'e}mi},
	booktitle={Algorithmic Learning Theory: International Conference, ALT 2016, Bari, Italy, October 19-21, 2016, Proceedings},
	volume={9925},
	pages={305},
	year={2016},
	organization={Springer}
}

@inproceedings{peters2007reinforcement,
	title={Reinforcement learning by reward-weighted regression for operational space control},
	author={Peters, Jan and Schaal, Stefan},
	booktitle={International Conference on Machine Learning},
	pages={745--750},
	year={2007}
}

@inproceedings{seijen2014true,
	title={True online TD (lambda)},
	author={Seijen, Harm and Sutton, Rich},
	booktitle={International Conference on Machine Learning},
	pages={692--700},
	year={2014},
	organization={PMLR}
}

@article{sutton1998reinforcement,
	title={Reinforcement Learning: An Introduction},
	author={Sutton, RS and Barto, AG},
	journal={IEEE Transactions on Neural Networks},
	volume={9},
	number={5},
	pages={1054--1054},
	year={1998},
	publisher={IEEE}
}

@article{busoniu2008comprehensive,
	title={A comprehensive survey of multiagent reinforcement learning},
	author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume={38},
	number={2},
	pages={156--172},
	year={2008},
	publisher={IEEE}
}

@inproceedings{palmer2018lenient,
	title={Lenient Multi-Agent Deep Reinforcement Learning},
	author={Palmer, Gregory and Tuyls, Karl and Bloembergen, Daan and Savani, Rahul},
	booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
	pages={443--451},
	year={2018}
}

@inproceedings{ma2021modeling,
  title={Modeling the Interaction between Agents in Cooperative Multi-Agent Reinforcement Learning},
  author={Ma, Xiaoteng and Yang, Yiqin and Li, Chenghao and Lu, Yiwen and Zhao, Qianchuan and Yang, Jun},
  booktitle={Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={853--861},
  year={2021}
}

@book{sutton2018reinforcement,
  title     = {Reinforcement Learning: An Introduction},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  year      = {2018},
  publisher = {MIT press}
}


@inproceedings{abdolmaleki2018maximum,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{pan2020softmax,
 author = {Pan, Ling and Cai, Qingpeng and Huang, Longbo},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {11767--11777},
 title = {Softmax Deep Double Deterministic Policy Gradients},
 volume = {33},
 year = {2020}
}

@inproceedings{song2019revisiting,
  title={Revisiting the softmax bellman operator: New benefits and new perspective},
  author={Song, Zhao and Parr, Ron and Carin, Lawrence},
  booktitle={International Conference on Machine Learning},
  pages={5916--5925},
  year={2019},
  organization={PMLR}
}

@inproceedings{asadi2017alternative,
  title={An alternative softmax operator for reinforcement learning},
  author={Asadi, Kavosh and Littman, Michael L},
  booktitle={International Conference on Machine Learning},
  pages={243--252},
  year={2017},
  organization={PMLR}
}

@article{li2021celebrating,
  title={Celebrating Diversity in Shared Multi-Agent Reinforcement Learning},
  author={Li, Chenghao and Wu, Chengjie and Wang, Tonghan and Yang, Jun and Zhao, Qianchuan and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2106.02195},
  year={2021}
}

@inproceedings{song2019v,
  title={V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control},
  author={Song, H Francis and Abdolmaleki, Abbas and Springenberg, Jost Tobias and Clark, Aidan and Soyer, Hubert and Rae, Jack W and Noury, Seb and Ahuja, Arun and Liu, Siqi and Tirumala, Dhruva and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{siegel2020keep,
  title={Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2019}
}