\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez,
  Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner,
  et~al.]{battaglia2018relational}
Battaglia, P.~W., Hamrick, J.~B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi,
  V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R.,
  et~al.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock \emph{arXiv preprint arXiv:1806.01261}, 2018.

\bibitem[Chen et~al.(2019)Chen, Villar, Chen, and Bruna]{chen2019equivalence}
Chen, Z., Villar, S., Chen, L., and Bruna, J.
\newblock On the equivalence between graph isomorphism testing and function
  approximation with {GNN}s.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  15868--15876, 2019.

\bibitem[Dao et~al.(2017)Dao, {De Sa}, and R{\'e}]{dao2017gaussian}
Dao, T., {De Sa}, C.~M., and R{\'e}, C.
\newblock Gaussian quadrature for kernel features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6107--6117, 2017.

\bibitem[Elton et~al.(2019)Elton, Boukouvalas, Fuge, and Chung]{elton2019deep}
Elton, D.~C., Boukouvalas, Z., Fuge, M.~D., and Chung, P.~W.
\newblock Deep learning for molecular design--a review of the state of the art.
\newblock \emph{Molecular Systems Design \& Engineering}, 2019.
\newblock \doi{10.1039/C9ME00039A}.

\bibitem[Errica et~al.(2020)Errica, Podda, Bacciu, and Micheli]{errica2020fair}
Errica, F., Podda, M., Bacciu, D., and Micheli, A.
\newblock A fair comparison of graph neural networks for graph classification.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=HygDF6NFPB}.

\bibitem[G{\"a}rtner et~al.(2003)G{\"a}rtner, Flach, and
  Wrobel]{gartner2003graph}
G{\"a}rtner, T., Flach, P., and Wrobel, S.
\newblock On graph kernels: Hardness results and efficient alternatives.
\newblock In \emph{Learning Theory and Kernel Machines}, pp.\  129--143.
  Springer, 2003.

\bibitem[{Grattarola} et~al.(2019){Grattarola}, {Zambon}, {Livi}, and
  {Alippi}]{grattarola2019change}
{Grattarola}, D., {Zambon}, D., {Livi}, L., and {Alippi}, C.
\newblock Change detection in graph streams by learning graph embeddings on
  constant-curvature manifolds.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  pp.\  1--14, 2019.
\newblock ISSN 2162-237X.
\newblock \doi{10.1109/TNNLS.2019.2927301}.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and
  Leskovec]{hamilton2017inductive}
Hamilton, W., Ying, Z., and Leskovec, J.
\newblock Inductive representation learning on large graphs.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1024--1034, 2017.

\bibitem[Holland et~al.(1983)Holland, Laskey, and
  Leinhardt]{holland1983stochastic}
Holland, P.~W., Laskey, K.~B., and Leinhardt, S.
\newblock Stochastic blockmodels: First steps.
\newblock \emph{Social Networks}, 5\penalty0 (2):\penalty0 109--137, 1983.
\newblock \doi{10.1016/0378-8733(83)90021-7}.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{hornik1989multilayer}
Hornik, K., Stinchcombe, M., and White, H.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural Networks}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Kar \& Karnick(2012)Kar and Karnick]{kar2012random}
Kar, P. and Karnick, H.
\newblock Random feature maps for dot product kernels.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  583--591,
  2012.

\bibitem[Keriven \& Peyr\'{e}(2019)Keriven and Peyr\'{e}]{keriven2019universal}
Keriven, N. and Peyr\'{e}, G.
\newblock Universal invariant and equivariant graph neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  7090--7099. Curran Associates, Inc., 2019.

\bibitem[Kersting et~al.(2016)Kersting, Kriege, Morris, Mutzel, and
  Neumann]{KKMMN2016}
Kersting, K., Kriege, N.~M., Morris, C., Mutzel, P., and Neumann, M.
\newblock Benchmark data sets for graph kernels, 2016.
\newblock URL \url{http://graphkernels.cs.tu-dortmund.de}.

\bibitem[Li et~al.(2017)Li, Cornelius, Liu, Wang, and
  Barab{\'a}si]{li2017fundamental}
Li, A., Cornelius, S.~P., Liu, Y.-Y., Wang, L., and Barab{\'a}si, A.-L.
\newblock The fundamental advantages of temporal networks.
\newblock \emph{Science}, 358\penalty0 (6366):\penalty0 1042--1046, 2017.
\newblock \doi{10.1126/science.aai7488}.

\bibitem[Li et~al.(2019)Li, Ton, Oglic, and Sejdinovic]{li2019towards}
Li, Z., Ton, J.-F., Oglic, D., and Sejdinovic, D.
\newblock Towards a unified analysis of random {F}ourier features.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3905--3914, 2019.

\bibitem[Maaten \& Hinton(2008)Maaten and Hinton]{maaten2008visualizing}
Maaten, L. and Hinton, G.
\newblock Visualizing data using {t-SNE}.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0
  (Nov.):\penalty0 2579--2605, 2008.

\bibitem[Maron et~al.(2019{\natexlab{a}})Maron, Ben-Hamu, Serviansky, and
  Lipman]{maron2019provably}
Maron, H., Ben-Hamu, H., Serviansky, H., and Lipman, Y.
\newblock Provably powerful graph networks.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  2153--2164. Curran Associates, Inc., 2019{\natexlab{a}}.

\bibitem[Maron et~al.(2019{\natexlab{b}})Maron, Ben-Hamu, Shamir, and
  Lipman]{maron2018invariant}
Maron, H., Ben-Hamu, H., Shamir, N., and Lipman, Y.
\newblock Invariant and equivariant graph networks.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=Syx72jC9tm}.

\bibitem[Maron et~al.(2019{\natexlab{c}})Maron, Fetaya, Segol, and
  Lipman]{maron2019universality}
Maron, H., Fetaya, E., Segol, N., and Lipman, Y.
\newblock On the universality of invariant networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4363--4371, 2019{\natexlab{c}}.

\bibitem[Oneto et~al.(2017)Oneto, Navarin, Donini, Sperduti, Aiolli, and
  Anguita]{oneto2017measuring}
Oneto, L., Navarin, N., Donini, M., Sperduti, A., Aiolli, F., and Anguita, D.
\newblock Measuring the expressivity of graph kernels through statistical
  learning theory.
\newblock \emph{Neurocomputing}, 268:\penalty0 4--16, 2017.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch\'{e} Buc, F.,
  Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural Information
  Processing Systems 32}, pp.\  8024--8035. Curran Associates, Inc., 2019.

\bibitem[Principe \& Chen(2015)Principe and Chen]{principe2015universal}
Principe, J.~C. and Chen, B.
\newblock Universal approximation with convex optimization: Gimmick or reality?
  [discussion forum].
\newblock \emph{IEEE Computational Intelligence Magazine}, 10\penalty0
  (2):\penalty0 68--77, 2015.

\bibitem[Rahimi \& Recht(2008{\natexlab{a}})Rahimi and Recht]{rahimi2008random}
Rahimi, A. and Recht, B.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1177--1184, 2008{\natexlab{a}}.

\bibitem[Rahimi \& Recht(2008{\natexlab{b}})Rahimi and
  Recht]{rahimi2008uniform}
Rahimi, A. and Recht, B.
\newblock Uniform approximation of functions with random bases.
\newblock In \emph{46th Annual Allerton Conference on Communication, Control,
  and Computing}, pp.\  555--561. IEEE, 2008{\natexlab{b}}.

\bibitem[Rahimi \& Recht(2009)Rahimi and Recht]{rahimi2009weighted}
Rahimi, A. and Recht, B.
\newblock Weighted sums of random kitchen sinks: Replacing minimization with
  randomization in learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1313--1320, 2009.

\bibitem[Rudi \& Rosasco(2017)Rudi and Rosasco]{rudi2017generalization}
Rudi, A. and Rosasco, L.
\newblock Generalization properties of learning with random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3215--3225, 2017.

\bibitem[Rudin(1991)]{rudin1991functional}
Rudin, W.
\newblock \emph{Functional Analysis}.
\newblock McGraw-Hill, 1991.

\bibitem[Sejdinovic et~al.(2013)Sejdinovic, Sriperumbudur, Gretton, and
  Fukumizu]{sejdinovic2013equivalence}
Sejdinovic, D., Sriperumbudur, B., Gretton, A., and Fukumizu, K.
\newblock Equivalence of distance-based and {RKHS}-based statistics in
  hypothesis testing.
\newblock \emph{The Annals of Statistics}, pp.\  2263--2291, 2013.

\bibitem[Simonovsky \& Komodakis(2017)Simonovsky and
  Komodakis]{simonovsky2017dynamic}
Simonovsky, M. and Komodakis, N.
\newblock Dynamic edge-conditioned filters in convolutional neural networks on
  graphs.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3693--3702, 2017.

\bibitem[Sinha \& Duchi(2016)Sinha and Duchi]{sinha2016learning}
Sinha, A. and Duchi, J.~C.
\newblock Learning kernels with random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1298--1306, 2016.

\bibitem[Vedaldi \& Zisserman(2012)Vedaldi and Zisserman]{vedaldi2012efficient}
Vedaldi, A. and Zisserman, A.
\newblock Efficient additive kernels via explicit feature maps.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 34\penalty0 (3):\penalty0 480--492, 2012.

\bibitem[Wu et~al.(2018)Wu, Yen, Xu, Ravikumar, and Witbrock]{wu2018d2ke}
Wu, L., Yen, I. E.-H., Xu, F., Ravikumar, P., and Witbrock, M.
\newblock D2ke: From distance to kernel and embedding.
\newblock \emph{arXiv preprint arXiv:1802.04956}, 2018.

\bibitem[Wu et~al.(2019)Wu, Yen, Zhang, Xu, Zhao, Peng, Xia, and
  Aggarwal]{wu2019scalable}
Wu, L., Yen, I. E.-H., Zhang, Z., Xu, K., Zhao, L., Peng, X., Xia, Y., and
  Aggarwal, C.
\newblock Scalable global alignment graph kernel using random features: From
  node embedding to graph embedding.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  1418--1428. ACM, 2019.

\bibitem[Xu et~al.(2019)Xu, Hu, Leskovec, and Jegelka]{xu2018powerful}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S.
\newblock How powerful are graph neural networks?
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=ryGs6iA5Km}.

\bibitem[Ying et~al.(2018)Ying, You, Morris, Ren, Hamilton, and
  Leskovec]{ying2018hierarchical}
Ying, Z., You, J., Morris, C., Ren, X., Hamilton, W., and Leskovec, J.
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  4800--4810, 2018.

\bibitem[Yu et~al.(2016)Yu, Suresh, Choromanski, Holtmann-Rice, and
  Kumar]{yu2016orthogonal}
Yu, F.~X., Suresh, A.~T., Choromanski, K., Holtmann-Rice, D., and Kumar, S.
\newblock Orthogonal random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1975--1983, 2016.

\bibitem[Zambon et~al.(2017)Zambon, Livi, and Alippi]{zambon2017detecting}
Zambon, D., Livi, L., and Alippi, C.
\newblock Detecting changes in sequences of attributed graphs.
\newblock In \emph{IEEE Symposium Series on Computational Intelligence}, pp.\
  1--7, Nov. 2017.
\newblock \doi{10.1109/SSCI.2017.8285273}.

\bibitem[Zhang et~al.(2018)Zhang, Cui, Neumann, and Chen]{zhang2018end}
Zhang, M., Cui, Z., Neumann, M., and Chen, Y.
\newblock An end-to-end deep learning architecture for graph classification.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\end{thebibliography}
