\begin{thebibliography}{74}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[AI@Meta(2024)]{llama3modelcard}
AI@Meta.
\newblock Llama 3 model card.
\newblock 2024.
\newblock URL \url{https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}.

\bibitem[Anil et~al.(2024)Anil, Durmus, Sharma, Benton, Kundu, Batson, Rimsky, Tong, Mu, Ford, et~al.]{anil2024manyshot}
Cem Anil, Esin Durmus, Mrinank Sharma, Joe Benton, Sandipan Kundu, Joshua Batson, Nina Rimsky, Meg Tong, Jesse Mu, Daniel Ford, et~al.
\newblock Many-shot jailbreaking, 2024.

\bibitem[Anwar et~al.(2024)Anwar, Saparov, Rando, Paleka, Turpin, Hase, Lubana, Jenner, Casper, Sourbut, Edelman, Zhang, Günther, Korinek, Hernandez-Orallo, Hammond, Bigelow, Pan, Langosco, Korbak, Zhang, Zhong, hÉigeartaigh, Recchia, Corsi, Chan, Anderljung, Edwards, Bengio, Chen, Albanie, Maharaj, Foerster, Tramer, He, Kasirzadeh, Choi, and Krueger]{anwar2024foundational}
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep~Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin~L. Edelman, Zhaowei Zhang, Mario Günther, Anton Korinek, Jose Hernandez-Orallo, Lewis Hammond, Eric Bigelow, Alexander Pan, Lauro Langosco, Tomasz Korbak, Heidi Zhang, Ruiqi Zhong, Seán~Ó hÉigeartaigh, Gabriel Recchia, Giulio Corsi, Alan Chan, Markus Anderljung, Lilian Edwards, Yoshua Bengio, Danqi Chen, Samuel Albanie, Tegan Maharaj, Jakob Foerster, Florian Tramer, He~He, Atoosa Kasirzadeh, Yejin Choi, and David Krueger.
\newblock Foundational challenges in assuring alignment and safety of large language models, 2024.

\bibitem[Bhatt et~al.(2023)Bhatt, Chennabasappa, Nikolaidis, Wan, Evtimov, Gabi, Song, Ahmad, Aschermann, Fontana, Frolov, Giri, Kapil, Kozyrakis, LeBlanc, Milazzo, Straumann, Synnaeve, Vontimitta, Whitman, and Saxe]{bhatt2023purple}
Manish Bhatt, Sahana Chennabasappa, Cyrus Nikolaidis, Shengye Wan, Ivan Evtimov, Dominik Gabi, Daniel Song, Faizan Ahmad, Cornelius Aschermann, Lorenzo Fontana, Sasha Frolov, Ravi~Prakash Giri, Dhaval Kapil, Yiannis Kozyrakis, David LeBlanc, James Milazzo, Aleksandar Straumann, Gabriel Synnaeve, Varun Vontimitta, Spencer Whitman, and Joshua Saxe.
\newblock Purple llama cyberseceval: A secure coding benchmark for language models, 2023.

\bibitem[Bhatt et~al.(2022)Bhatt, Tjanaka, Fontaine, and Nikolaidis]{bhatt2022deep}
Varun Bhatt, Bryon Tjanaka, Matthew Fontaine, and Stefanos Nikolaidis.
\newblock Deep surrogate assisted generation of environments.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 37762--37777, 2022.

\bibitem[Bradley et~al.(2023)Bradley, Dai, Teufel, Zhang, Oostermeijer, Bellagente, Clune, Stanley, Schott, and Lehman]{bradley2023qualitydiversity}
Herbie Bradley, Andrew Dai, Hannah Teufel, Jenny Zhang, Koen Oostermeijer, Marco Bellagente, Jeff Clune, Kenneth Stanley, Grégory Schott, and Joel Lehman.
\newblock Quality-diversity through ai feedback, 2023.

\bibitem[Bubeck et~al.(2023)Bubeck, Chandrasekaran, Eldan, Gehrke, Horvitz, Kamar, Lee, Lee, Li, Lundberg, Nori, Palangi, Ribeiro, and Zhang]{bubeck2023sparks}
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco~Tulio Ribeiro, and Yi~Zhang.
\newblock Sparks of artificial general intelligence: Early experiments with gpt-4, 2023.

\bibitem[Chao et~al.(2023)Chao, Robey, Dobriban, Hassani, Pappas, and Wong]{chao2023PAIR}
Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George~J Pappas, and Eric Wong.
\newblock Jailbreaking black box large language models in twenty queries.
\newblock \emph{arXiv preprint arXiv:2310.08419}, 2023.

\bibitem[Chao et~al.(2024)Chao, Debenedetti, Robey, Andriushchenko, Croce, Sehwag, Dobriban, Flammarion, Pappas, Tramer, et~al.]{chao2024jailbreakbench}
Patrick Chao, Edoardo Debenedetti, Alexander Robey, Maksym Andriushchenko, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nicolas Flammarion, George~J Pappas, Florian Tramer, et~al.
\newblock Jailbreakbench: An open robustness benchmark for jailbreaking large language models.
\newblock \emph{arXiv preprint arXiv:2404.01318}, 2024.

\bibitem[Chen et~al.(2023)Chen, Dohan, and So]{chen2023evoprompting}
Angelica Chen, David~M. Dohan, and David~R. So.
\newblock Evoprompting: Language models for code-level neural architecture search, 2023.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang, Zhuang, Gonzalez, Stoica, and Xing]{vicuna2023}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E. Gonzalez, Ion Stoica, and Eric~P. Xing.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality, March 2023.
\newblock URL \url{https://lmsys.org/blog/2023-03-30-vicuna/}.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{gsm8k}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
\newblock Training verifiers to solve math word problems, 2021.

\bibitem[Cully and Demiris(2018)]{Cully2018Quality}
Antoine Cully and Yiannis Demiris.
\newblock Quality and diversity optimization: A unifying modular framework.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 22\penalty0 (2):\penalty0 245--259, 2018.
\newblock \doi{10.1109/TEVC.2017.2704781}.

\bibitem[Dennis et~al.(2020)Dennis, Jaques, Vinitsky, Bayen, Russell, Critch, and Levine]{paired}
Michael Dennis, Natasha Jaques, Eugene Vinitsky, Alexandre Bayen, Stuart Russell, Andrew Critch, and Sergey Levine.
\newblock Emergent complexity and zero-shot transfer via unsupervised environment design.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~33, 2020.

\bibitem[Evans et~al.(2023)Evans, Pathak, Merzic, Schwarz, Tanno, and Henaff]{evans2023bad}
Talfan Evans, Shreya Pathak, Hamza Merzic, Jonathan Schwarz, Ryutaro Tanno, and Olivier~J Henaff.
\newblock Bad students make great teachers: Active learning accelerates large-scale visual understanding.
\newblock \emph{arXiv preprint arXiv:2312.05328}, 2023.

\bibitem[Fernando et~al.(2023)Fernando, Banarse, Michalewski, Osindero, and Rocktäschel]{fernando2023promptbreeder}
Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rocktäschel.
\newblock Promptbreeder: Self-referential self-improvement via prompt evolution, 2023.

\bibitem[Fontaine and Nikolaidis(2022)]{fontaine2022evaluating}
Matthew~C Fontaine and Stefanos Nikolaidis.
\newblock Evaluating human--robot interaction algorithms in shared autonomy via quality diversity scenario generation.
\newblock \emph{ACM Transactions on Human-Robot Interaction (THRI)}, 11\penalty0 (3):\penalty0 1--30, 2022.

\bibitem[Fontaine et~al.(2021)Fontaine, Hsu, Zhang, Tjanaka, and Nikolaidis]{fontaine2021importance}
Matthew~C Fontaine, Ya-Chuan Hsu, Yulun Zhang, Bryon Tjanaka, and Stefanos Nikolaidis.
\newblock On the importance of environments in human-robot coordination.
\newblock \emph{Robotics: Science and Systems (RSS)}, 2021.

\bibitem[Ganguli et~al.(2022)Ganguli, Lovitt, Kernion, Askell, Bai, Kadavath, Mann, Perez, Schiefer, Ndousse, Jones, Bowman, Chen, Conerly, DasSarma, Drain, Elhage, El-Showk, Fort, Hatfield-Dodds, Henighan, Hernandez, Hume, Jacobson, Johnston, Kravec, Olsson, Ringer, Tran-Johnson, Amodei, Brown, Joseph, McCandlish, Olah, Kaplan, and Clark]{ganguli2022red}
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, Andy Jones, Sam Bowman, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Nelson Elhage, Sheer El-Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Danny Hernandez, Tristan Hume, Josh Jacobson, Scott Johnston, Shauna Kravec, Catherine Olsson, Sam Ringer, Eli Tran-Johnson, Dario Amodei, Tom Brown, Nicholas Joseph, Sam McCandlish, Chris Olah, Jared Kaplan, and Jack Clark.
\newblock Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned, 2022.

\bibitem[Ge et~al.(2023)Ge, Zhou, Hou, Khabsa, Wang, Wang, Han, and Mao]{ge2023mart}
Suyu Ge, Chunting Zhou, Rui Hou, Madian Khabsa, Yi-Chia Wang, Qifan Wang, Jiawei Han, and Yuning Mao.
\newblock Mart: Improving llm safety with multi-round automatic red-teaming.
\newblock \emph{arXiv preprint arXiv:2311.07689}, 2023.

\bibitem[{Gemini Team} et~al.(2023){Gemini Team}, Anil, Borgeaud, Wu, Alayrac, Yu, Soricut, Schalkwyk, Dai, Hauth, Millican, Silver, Petrov, Johnson, Antonoglou, Schrittwieser, and {others}]{geminiteam2023gemini}
{Gemini Team}, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, and {others}.
\newblock Gemini: A family of highly capable multimodal models, 2023.

\bibitem[Graves et~al.(2017)Graves, Bellemare, Menick, Munos, and Kavukcuoglu]{graves2017automated}
Alex Graves, Marc~G Bellemare, Jacob Menick, Remi Munos, and Koray Kavukcuoglu.
\newblock Automated curriculum learning for neural networks.
\newblock In \emph{international conference on machine learning}, pages 1311--1320. Pmlr, 2017.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{mmlu}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding, 2021.

\bibitem[Hendrycks et~al.(2022)Hendrycks, Carlini, Schulman, and Steinhardt]{hendrycks2022unsolved}
Dan Hendrycks, Nicholas Carlini, John Schulman, and Jacob Steinhardt.
\newblock Unsolved problems in ml safety, 2022.

\bibitem[Hughes et~al.(2024)Hughes, Dennis, Parker-Holder, Behbahani, Mavalankar, Shi, Schaul, and Rockt\"{a}schel]{hughes2024position}
Edward Hughes, Michael~D Dennis, Jack Parker-Holder, Feryal Behbahani, Aditi Mavalankar, Yuge Shi, Tom Schaul, and Tim Rockt\"{a}schel.
\newblock Position: Open-endedness is essential for artificial superhuman intelligence.
\newblock In \emph{Proceedings of the 41st International Conference on Machine Learning}, volume 235 of \emph{Proceedings of Machine Learning Research}, pages 20597--20616. PMLR, 21--27 Jul 2024.

\bibitem[Inan et~al.(2023)Inan, Upasani, Chi, Rungta, Iyer, Mao, Tontchev, Hu, Fuller, Testuggine, et~al.]{inan2023llamaguard}
Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, et~al.
\newblock Llama guard: Llm-based input-output safeguard for human-ai conversations.
\newblock \emph{arXiv preprint arXiv:2312.06674}, 2023.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~las Casas, Bressand, Lengyel, Lample, Saulnier, Lavaud, Lachaux, Stock, Scao, Lavril, Wang, Lacroix, and Sayed]{jiang2023mistral}
Albert~Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio~Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven~Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William~El Sayed.
\newblock Mistral 7b, 2023.

\bibitem[Jiang et~al.(2024)Jiang, Xu, Niu, Xiang, Ramasubramanian, Li, and Poovendran]{jiang2024artprompt_ascii}
Fengqing Jiang, Zhangchen Xu, Luyao Niu, Zhen Xiang, Bhaskar Ramasubramanian, Bo~Li, and Radha Poovendran.
\newblock Artprompt: Ascii art-based jailbreak attacks against aligned llms.
\newblock \emph{arXiv preprint arXiv:2402.11753}, 2024.

\bibitem[Jiang et~al.(2021)Jiang, Dennis, Parker{-}Holder, Foerster, Grefenstette, and Rockt{\"{a}}schel]{jiang2021robustplr}
Minqi Jiang, Michael Dennis, Jack Parker{-}Holder, Jakob Foerster, Edward Grefenstette, and Tim Rockt{\"{a}}schel.
\newblock Replay-guided adversarial environment design.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2021.

\bibitem[Joshi et~al.(2017)Joshi, Choi, Weld, and Zettlemoyer]{JoshiTriviaQA2017}
Mandar Joshi, Eunsol Choi, Daniel~S. Weld, and Luke Zettlemoyer.
\newblock Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics}, Vancouver, Canada, July 2017. Association for Computational Linguistics.

\bibitem[Kiela et~al.(2021)Kiela, Bartolo, Nie, Kaushik, Geiger, Wu, Vidgen, Prasad, Singh, Ringshia, et~al.]{kiela2021dynabench}
Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, et~al.
\newblock Dynabench: Rethinking benchmarking in nlp.
\newblock \emph{arXiv preprint arXiv:2104.14337}, 2021.

\bibitem[Lapid et~al.(2023{\natexlab{a}})Lapid, Langberg, and Sipper]{gen1}
Raz Lapid, Ron Langberg, and Moshe Sipper.
\newblock Open sesame! universal black box jailbreaking of large language models, 2023{\natexlab{a}}.

\bibitem[Lapid et~al.(2023{\natexlab{b}})Lapid, Langberg, and Sipper]{lapid2023opensesame}
Raz Lapid, Ron Langberg, and Moshe Sipper.
\newblock Open sesame! universal black box jailbreaking of large language models.
\newblock \emph{arXiv preprint arXiv:2309.01446}, 2023{\natexlab{b}}.

\bibitem[Lehman and Stanley(2011)]{lehman2011abandoning}
Joel Lehman and Kenneth~O Stanley.
\newblock Abandoning objectives: Evolution through the search for novelty alone.
\newblock \emph{Evolutionary computation}, 19\penalty0 (2):\penalty0 189--223, 2011.

\bibitem[Lehman et~al.(2022)Lehman, Gordon, Jain, Ndousse, Yeh, and Stanley]{lehman2022evolution}
Joel Lehman, Jonathan Gordon, Shawn Jain, Kamal Ndousse, Cathy Yeh, and Kenneth~O. Stanley.
\newblock Evolution through large models, 2022.

\bibitem[Li et~al.(2023)Li, Li, Zhang, Dan, Jiang, and Zhang]{li2023chatdoctor}
Yunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steve Jiang, and You Zhang.
\newblock Chatdoctor: A medical chat model fine-tuned on a large language model meta-ai (llama) using medical domain knowledge, 2023.

\bibitem[Lin and Och(2004)]{lin-och-2004-automatic}
Chin-Yew Lin and Franz~Josef Och.
\newblock Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics.
\newblock In \emph{Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04)}, pages 605--612, Barcelona, Spain, July 2004.
\newblock \doi{10.3115/1218955.1219032}.
\newblock URL \url{https://aclanthology.org/P04-1077}.

\bibitem[Liu et~al.(2023)Liu, Xu, Chen, and Xiao]{liu2023autodan}
Xiaogeng Liu, Nan Xu, Muhao Chen, and Chaowei Xiao.
\newblock Autodan: Generating stealthy jailbreak prompts on aligned large language models.
\newblock \emph{arXiv preprint arXiv:2310.04451}, 2023.

\bibitem[Maddela et~al.(2023)Maddela, Ung, Xu, Madotto, Foran, and Boureau]{maddela2023training}
Mounica Maddela, Megan Ung, Jing Xu, Andrea Madotto, Heather Foran, and Y-Lan Boureau.
\newblock Training models to generate, recognize, and reframe unhelpful thoughts, 2023.

\bibitem[Maus et~al.(2023)Maus, Chao, Wong, and Gardner]{maus2023blackbox}
Natalie Maus, Patrick Chao, Eric Wong, and Jacob~R Gardner.
\newblock Black box adversarial prompting for foundation models.
\newblock In \emph{The Second Workshop on New Frontiers in Adversarial Machine Learning}, 2023.

\bibitem[Mehrotra et~al.(2023)Mehrotra, Zampetakis, Kassianik, Nelson, Anderson, Singer, and Karbasi]{mehrotra2023TAP}
Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum Anderson, Yaron Singer, and Amin Karbasi.
\newblock Tree of attacks: Jailbreaking black-box llms automatically.
\newblock \emph{arXiv preprint arXiv:2312.02119}, 2023.

\bibitem[Mehta et~al.(2020)Mehta, Diaz, Golemo, Pal, and Paull]{adr2020}
Bhairav Mehta, Manfred Diaz, Florian Golemo, Christopher~J. Pal, and Liam Paull.
\newblock Active domain randomization.
\newblock In \emph{Proceedings of the Conference on Robot Learning}, 2020.

\bibitem[Meyerson et~al.(2023)Meyerson, Nelson, Bradley, Gaier, Moradi, Hoover, and Lehman]{meyerson2023language}
Elliot Meyerson, Mark~J. Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy~K. Hoover, and Joel Lehman.
\newblock Language model crossover: Variation through few-shot prompting, 2023.

\bibitem[Mindermann et~al.(2022)Mindermann, Brauner, Razzak, Sharma, Kirsch, Xu, H{\"o}ltgen, Gomez, Morisot, Farquhar, et~al.]{mindermann2022prioritized}
S{\"o}ren Mindermann, Jan~M Brauner, Muhammed~T Razzak, Mrinank Sharma, Andreas Kirsch, Winnie Xu, Benedikt H{\"o}ltgen, Aidan~N Gomez, Adrien Morisot, Sebastian Farquhar, et~al.
\newblock Prioritized training on points that are learnable, worth learning, and not yet learnt.
\newblock In \emph{International Conference on Machine Learning}, pages 15630--15649. PMLR, 2022.

\bibitem[MITRE(2024)]{mitre_attack_enterprise}
MITRE.
\newblock {MITRE ATT\&CK - Enterprise Matrix}.
\newblock \url{https://attack.mitre.org/matrices/enterprise/}, 2024.
\newblock Accessed: 02/02/2024.

\bibitem[Mouret and Clune(2015)]{mouret2015illuminating}
Jean-Baptiste Mouret and Jeff Clune.
\newblock Illuminating search spaces by mapping elites, 2015.

\bibitem[{NLLB Team} et~al.(2022){NLLB Team}, Costa-jussà, Cross, Çelebi, Elbayad, Heafield, Heffernan, Kalbassi, Lam, Licht, Maillard, Sun, Wang, Wenzek, Youngblood, Akula, Barrault, Gonzalez, Hansanti, Hoffman, Jarrett, Sadagopan, Rowe, Spruit, Tran, Andrews, Ayan, Bhosale, Edunov, Fan, Gao, Goswami, Guzmán, Koehn, Mourachko, Ropers, Saleem, Schwenk, and Wang]{nllbteam2022language}
{NLLB Team}, Marta~R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al~Youngblood, Bapi Akula, Loic Barrault, Gabriel~Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik~Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip~Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang.
\newblock No language left behind: Scaling human-centered machine translation, 2022.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and Zhu]{papineni-etal-2002-bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock {B}leu: a method for automatic evaluation of machine translation.
\newblock In Pierre Isabelle, Eugene Charniak, and Dekang Lin, editors, \emph{Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics}, pages 311--318, July 2002.

\bibitem[Parker-Holder et~al.(2022)Parker-Holder, Jiang, Dennis, Samvelyan, Foerster, Grefenstette, and Rocktäschel]{parker-holder2022evolving}
Jack Parker-Holder, Minqi Jiang, Michael Dennis, Mikayel Samvelyan, Jakob Foerster, Edward Grefenstette, and Tim Rocktäschel.
\newblock Evolving curricula with regret-based environment design, 2022.
\newblock URL \url{https://arxiv.org/abs/2203.01302}.

\bibitem[Perez et~al.(2022)Perez, Huang, Song, Cai, Ring, Aslanides, Glaese, McAleese, and Irving]{perez2022red}
Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving.
\newblock Red teaming language models with language models.
\newblock \emph{arXiv preprint arXiv:2202.03286}, 2022.

\bibitem[Pugh et~al.(2016)Pugh, Soros, and Stanley]{pugh2016quality}
Justin~K Pugh, Lisa~B Soros, and Kenneth~O Stanley.
\newblock Quality diversity: A new frontier for evolutionary computation.
\newblock \emph{Frontiers in Robotics and AI}, 3:\penalty0 40, 2016.

\bibitem[Raparthy et~al.(2020)Raparthy, Mehta, Golemo, and Paull]{adr2_2020}
Sharath~Chandra Raparthy, Bhairav Mehta, Florian Golemo, and Liam Paull.
\newblock Generating automatic curricula via self-supervised active domain randomization.
\newblock \emph{CoRR}, abs/2002.07911, 2020.
\newblock URL \url{https://arxiv.org/abs/2002.07911}.

\bibitem[Robey et~al.(2023)Robey, Wong, Hassani, and Pappas]{robey2023smoothllm}
Alexander Robey, Eric Wong, Hamed Hassani, and George~J Pappas.
\newblock Smoothllm: Defending large language models against jailbreaking attacks.
\newblock \emph{arXiv preprint arXiv:2310.03684}, 2023.

\bibitem[Rozière et~al.(2023)Rozière, Gehring, Gloeckle, Sootla, Gat, Tan, Adi, Liu, Remez, Rapin, Kozhevnikov, Evtimov, Bitton, Bhatt, Ferrer, Grattafiori, Xiong, Défossez, Copet, Azhar, Touvron, Martin, Usunier, Scialom, and Synnaeve]{rozière2023code}
Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing~Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian~Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel Synnaeve.
\newblock Code llama: Open foundation models for code, 2023.

\bibitem[Samvelyan et~al.(2023)Samvelyan, Khan, Dennis, Jiang, Parker-Holder, Foerster, Raileanu, and Rockt{\"a}schel]{samvelyan2023maestro}
Mikayel Samvelyan, Akbir Khan, Michael~D Dennis, Minqi Jiang, Jack Parker-Holder, Jakob~Nicolaus Foerster, Roberta Raileanu, and Tim Rockt{\"a}schel.
\newblock {MAESTRO}: Open-ended environment design for multi-agent reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=sKWlRDzPfd7}.

\bibitem[Samvelyan et~al.(2024)Samvelyan, Paglieri, Jiang, Parker-Holder, and Rockt{\"a}schel]{samvelyan2024multi}
Mikayel Samvelyan, Davide Paglieri, Minqi Jiang, Jack Parker-Holder, and Tim Rockt{\"a}schel.
\newblock Multi-agent diagnostics for robustness via illuminated diversity.
\newblock \emph{arXiv preprint arXiv:2401.13460}, 2024.

\bibitem[Savage(1951)]{minimax_regret}
L.~J. Savage.
\newblock The theory of statistical decision.
\newblock \emph{Journal of the American Statistical association}, 1951.

\bibitem[Schick et~al.(2023)Schick, Dwivedi-Yu, Dessì, Raileanu, Lomeli, Zettlemoyer, Cancedda, and Scialom]{schick2023toolformer}
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
\newblock Toolformer: Language models can teach themselves to use tools, 2023.

\bibitem[Shah et~al.(2023)Shah, Pour, Tagade, Casper, Rando, et~al.]{shah2023persona}
Rusheb Shah, Soroush Pour, Arush Tagade, Stephen Casper, Javier Rando, et~al.
\newblock Scalable and transferable black-box jailbreaks for language models via persona modulation.
\newblock \emph{arXiv preprint arXiv:2311.03348}, 2023.

\bibitem[Shaib et~al.(2024)Shaib, Barrow, Sun, Siu, Wallace, and Nenkova]{shaib2024standardizingmeasurementtextdiversity}
Chantal Shaib, Joe Barrow, Jiuding Sun, Alexa~F. Siu, Byron~C. Wallace, and Ani Nenkova.
\newblock Standardizing the measurement of text diversity: A tool and a comparative analysis of scores, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.00553}.

\bibitem[Singhal et~al.(2022)Singhal, Azizi, Tu, Mahdavi, Wei, Chung, Scales, Tanwani, Cole-Lewis, Pfohl, Payne, Seneviratne, Gamble, Kelly, Scharli, Chowdhery, Mansfield, y~Arcas, Webster, Corrado, Matias, Chou, Gottweis, Tomasev, Liu, Rajkomar, Barral, Semturs, Karthikesalingam, and Natarajan]{singhal2022large}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S.~Sara Mahdavi, Jason Wei, Hyung~Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli, Aakanksha Chowdhery, Philip Mansfield, Blaise~Aguera y~Arcas, Dale Webster, Greg~S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, and Vivek Natarajan.
\newblock Large language models encode clinical knowledge, 2022.

\bibitem[Skalse et~al.(2022)Skalse, Howe, Krasheninnikov, and Krueger]{skalse2022defining}
Joar Skalse, Nikolaus H.~R. Howe, Dmitrii Krasheninnikov, and David Krueger.
\newblock Defining and characterizing reward hacking, 2022.

\bibitem[Thirunavukarasu et~al.(2023)Thirunavukarasu, Ting, Elangovan, Gutierrez, Tan, and Ting]{llmmedicine}
Arun~James Thirunavukarasu, Darren Shu~Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting~Fang Tan, and Daniel Shu~Wei Ting.
\newblock Large language models in medicine.
\newblock \emph{Nature Medicine}, 29\penalty0 (8):\penalty0 1930--1940, 2023.
\newblock \doi{10.1038/s41591-023-02448-8}.
\newblock URL \url{https://doi.org/10.1038/s41591-023-02448-8}.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher, Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao, Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa, Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet, Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi, Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu, Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and Scialom]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian~Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit~Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric~Michael Smith, Ranjan Subramanian, Xiaoqing~Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian~Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
  Scialom.
\newblock Llama 2: Open foundation and fine-tuned chat models, 2023.

\bibitem[Wei et~al.(2023)Wei, Haghtalab, and Steinhardt]{wei2023jailbroken}
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.
\newblock Jailbroken: How does llm safety training fail?, 2023.

\bibitem[Wei et~al.(2022)Wei, Bosma, Zhao, Guu, Yu, Lester, Du, Dai, and Le]{wei2022finetuned}
Jason Wei, Maarten Bosma, Vincent~Y. Zhao, Kelvin Guu, Adams~Wei Yu, Brian Lester, Nan Du, Andrew~M. Dai, and Quoc~V. Le.
\newblock Finetuned language models are zero-shot learners, 2022.

\bibitem[Yong et~al.(2023)Yong, Menghini, and Bach]{yong2023low}
Zheng-Xin Yong, Cristina Menghini, and Stephen~H Bach.
\newblock Low-resource languages jailbreak gpt-4.
\newblock \emph{arXiv preprint arXiv:2310.02446}, 2023.

\bibitem[Yu et~al.(2023)Yu, Lin, and Xing]{yu2023gptfuzzer}
Jiahao Yu, Xingwei Lin, and Xinyu Xing.
\newblock Gptfuzzer: Red teaming large language models with auto-generated jailbreak prompts.
\newblock \emph{arXiv preprint arXiv:2309.10253}, 2023.

\bibitem[Zhang et~al.(2020)Zhang, Kishore, Wu, Weinberger, and Artzi]{zhang2020bertscore}
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian~Q. Weinberger, and Yoav Artzi.
\newblock Bertscore: Evaluating text generation with bert, 2020.

\bibitem[Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, Zhang, Gonzalez, and Stoica]{zheng2023judging}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph~E. Gonzalez, and Ion Stoica.
\newblock Judging {LLM}-as-a-judge with {MT}-bench and chatbot arena.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2023.
\newblock URL \url{https://openreview.net/forum?id=uccHPGDlao}.

\bibitem[Zhou et~al.(2022)Zhou, Muresanu, Han, Paster, Pitis, Chan, and Ba]{zhou2022large}
Yongchao Zhou, Andrei~Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.
\newblock Large language models are human-level prompt engineers.
\newblock \emph{arXiv preprint arXiv:2211.01910}, 2022.

\bibitem[Zhu et~al.(2018)Zhu, Lu, Zheng, Guo, Zhang, Wang, and Yu]{zhu2018selfbleu}
Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu.
\newblock Texygen: A benchmarking platform for text generation models.
\newblock In \emph{The 41st international ACM SIGIR conference on research \& development in information retrieval}, pages 1097--1100, 2018.

\bibitem[Zou et~al.(2023)Zou, Wang, Kolter, and Fredrikson]{zou2023universal}
Andy Zou, Zifan Wang, J.~Zico Kolter, and Matt Fredrikson.
\newblock Universal and transferable adversarial attacks on aligned language models, 2023.

\end{thebibliography}
