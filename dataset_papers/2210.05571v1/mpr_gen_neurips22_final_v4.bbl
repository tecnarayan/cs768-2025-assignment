% Generated by IEEEtranS.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranS.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{arias2012fundamental}
E.~Arias-Castro, E.~J. Candes, and M.~A. Davenport, ``On the fundamental limits
  of adaptive sensing,'' \emph{IEEE Trans. Inf. Theory}, vol.~59, no.~1, pp.
  472--481, 2012.

\bibitem{asim2020invertible}
M.~Asim, M.~Daniels, O.~Leong, A.~Ahmed, and P.~Hand, ``Invertible generative
  models for inverse problems: {M}itigating representation error and dataset
  bias,'' in \emph{Int. Conf. Mach. Learn. (ICML)}.\hskip 1em plus 0.5em minus
  0.4em\relax PMLR, 2020, pp. 399--409.

\bibitem{aubin2020exact}
B.~Aubin, B.~Loureiro, A.~Baker, F.~Krzakala, and L.~Zdeborov{\'a}, ``Exact
  asymptotics for phase retrieval and compressed sensing with random generative
  priors,'' in \emph{Math. Sci. Mach. Learn. (MSML)}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2020, pp. 55--73.

\bibitem{bahmani2017phase}
S.~Bahmani and J.~Romberg, ``Phase retrieval meets statistical learning theory:
  A flexible convex relaxation,'' in \emph{Int. Conf. Artif. Intell. Stat.
  (AISTATS)}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 252--260.

\bibitem{barbier2019optimal}
J.~Barbier, F.~Krzakala, N.~Macris, L.~Miolane, and L.~Zdeborov{\'a}, ``Optimal
  errors and phase transitions in high-dimensional generalized linear models,''
  \emph{PNAS}, vol. 116, no.~12, pp. 5451--5460, 2019.

\bibitem{bora2017compressed}
A.~Bora, A.~Jalal, E.~Price, and A.~G. Dimakis, ``Compressed sensing using
  generative models,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2017, pp.
  537--546.

\bibitem{cai2021sample}
J.-F. Cai, Y.~Jiao, X.~Lu, and J.~You, ``Sample-efficient sparse phase
  retrieval via stochastic alternating minimization,''
  \emph{https://arxiv.org/2112.07919}, 2021.

\bibitem{cai2020sparse}
J.-F. Cai, J.~Li, X.~Lu, and J.~You, ``Sparse signal recovery from phaseless
  measurements via hard thresholding pursuit,''
  \emph{https://arxiv.org/abs/2005.08777}, 2020.

\bibitem{cai2021solving}
J.~Cai, M.~Huang, D.~Li, and Y.~Wang, ``Solving phase retrieval with random
  initial guess is nearly as good as by spectral initialization,''
  \emph{https://arxiv.org/abs/2101.03540}, 2021.

\bibitem{cai2016optimal}
T.~T. Cai, X.~Li, and Z.~Ma, ``Optimal rates of convergence for noisy sparse
  phase retrieval via thresholded {W}irtinger flow,'' \emph{Ann. Stat.},
  vol.~44, no.~5, pp. 2221--2251, 2016.

\bibitem{candes2013well}
E.~J. Candes and M.~A. Davenport, ``How well can we estimate a sparse vector?''
  \emph{Appl. Comp. Harm. Analysis}, vol.~34, no.~2, pp. 317--323, 2013.

\bibitem{candes2015phaseMC}
E.~J. Candes, Y.~C. Eldar, T.~Strohmer, and V.~Voroninski, ``Phase retrieval
  via matrix completion,'' \emph{SIAM Rev.}, vol.~57, no.~2, pp. 225--251,
  2015.

\bibitem{candes2015phase}
E.~J. Cand{\`e}s, X.~Li, and M.~Soltanolkotabi, ``Phase retrieval via
  {W}irtinger flow: Theory and algorithms,'' \emph{IEEE Trans. Inf. Theory},
  vol.~61, no.~4, pp. 1985--2007, 2015.

\bibitem{candes2013phaselift}
E.~J. Cand{\`e}s, T.~Strohmer, and V.~Voroninski, ``Phase{L}ift: Exact and
  stable signal recovery from magnitude measurements via convex programming,''
  \emph{Comm. Pure Appl. Math.}, vol.~66, no.~8, pp. 1241--1274, 2013.

\bibitem{chen2017solving}
Y.~Chen and E.~J. Cand{\`e}s, ``Solving random quadratic systems of equations
  is nearly as easy as solving linear systems,'' \emph{Comm. Pure Appl. Math.},
  vol.~70, no.~5, pp. 822--883, 2017.

\bibitem{chen2019gradient}
Y.~Chen, Y.~Chi, J.~Fan, and C.~Ma, ``Gradient descent with random
  initialization: Fast global convergence for nonconvex phase retrieval,''
  \emph{Math. Program.}, vol. 176, no.~1, pp. 5--37, 2019.

\bibitem{cheng2017bs}
L.~Cheng, P.~Zeng, and Y.~Zhu, ``{BS-SIM}: {A}n effective variable selection
  method for high-dimensional single index model,'' \emph{Electron. J. Stat.},
  vol.~11, no.~2, pp. 3522--3548, 2017.

\bibitem{deshpande2014cone}
Y.~Deshpande, A.~Montanari, and E.~Richard, ``Cone-constrained principal
  component analysis,'' in \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)}, 2014,
  pp. 2717--2725.

\bibitem{dhar2018modeling}
M.~Dhar, A.~Grover, and S.~Ermon, ``Modeling sparse deviations for compressed
  sensing using generative models,'' in \emph{Int. Conf. Mach. Learn.
  (ICML)}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 1214--1223.

\bibitem{eftekhari2021inference}
H.~Eftekhari, M.~Banerjee, and Y.~Ritov, ``Inference in high-dimensional
  single-index models under symmetric designs,'' \emph{J. Mach. Learn. Res.},
  vol.~22, pp. 27--1, 2021.

\bibitem{fienup1982phase}
J.~R. Fienup, ``Phase retrieval algorithms: A comparison,'' \emph{Appl. Opt.},
  vol.~21, no.~15, pp. 2758--2769, 1982.

\bibitem{foster2013variable}
J.~C. Foster, J.~M. Taylor, and B.~Nan, ``Variable selection in monotone
  single-index models via the adaptive {L}asso,'' \emph{Stat. Med.}, vol.~32,
  no.~22, pp. 3944--3954, 2013.

\bibitem{Fou13}
S.~Foucart and H.~Rauhut, \emph{A Mathematical Introduction to Compressive
  Sensing}.\hskip 1em plus 0.5em minus 0.4em\relax Springer New York, 2013.

\bibitem{ganti2015learning}
R.~Ganti, N.~Rao, R.~M. Willett, and R.~Nowak, ``Learning single index models
  in high dimensions,'' \emph{https://arxiv.org/1506.08910}, 2015.

\bibitem{gao2020perturbed}
B.~Gao, X.~Sun, Y.~Wang, and Z.~Xu, ``Perturbed amplitude flow for phase
  retrieval,'' \emph{IEEE Trans. Sig. Proc.}, vol.~68, pp. 5427--5440, 2020.

\bibitem{genzel2016high}
M.~Genzel, ``High-dimensional estimation of structured signals from non-linear
  observations with general convex loss functions,'' \emph{IEEE Trans. Inf.
  Theory}, vol.~63, no.~3, pp. 1601--1619, 2016.

\bibitem{gerchberg1972practical}
R.~W. Gerchberg, ``A practical algorithm for the determination of phase from
  image and diffraction plane pictures,'' \emph{Optik}, vol.~35, pp. 237--246,
  1972.

\bibitem{goldstein2018structured}
L.~Goldstein, S.~Minsker, and X.~Wei, ``Structured signal recovery from
  non-linear and heavy-tailed measurements,'' \emph{IEEE Trans. Inf. Theory},
  vol.~64, no.~8, pp. 5513--5530, 2018.

\bibitem{goldstein2018phasemax}
T.~Goldstein and C.~Studer, ``Phase{m}ax: Convex phase retrieval via basis
  pursuit,'' \emph{IEEE Trans. Inf. Theory}, vol.~64, no.~4, pp. 2675--2689,
  2018.

\bibitem{han1987non}
A.~K. Han, ``Non-parametric analysis of a generalized regression model: the
  maximum rank correlation estimator,'' \emph{J. Econom.}, vol.~35, no. 2-3,
  pp. 303--316, 1987.

\bibitem{hand2018phase}
P.~Hand, O.~Leong, and V.~Voroninski, ``Phase retrieval under a generative
  prior,'' in \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)}, 2018, pp.
  9154--9164.

\bibitem{hand2018global}
P.~Hand and V.~Voroninski, ``Global guarantees for enforcing deep generative
  priors by empirical risk,'' in \emph{Conf. Learn. Theory (COLT)}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 970--978.

\bibitem{hao2019bootstrapping}
B.~Hao, Y.~Yadkori, Z.~Wen, and G.~Cheng, ``Bootstrapping upper confidence
  bound,'' \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)}, 2019.

\bibitem{heckel2019deep}
R.~Heckel and P.~Hand, ``Deep decoder: Concise image representations from
  untrained non-convolutional networks,'' in \emph{Int. Conf. Learn. Repr.
  (ICLR)}, 2019.

\bibitem{horowitz2009semiparametric}
J.~L. Horowitz, \emph{Semiparametric and nonparametric methods in
  econometrics}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2009,
  vol.~12.

\bibitem{huang2020estimation}
M.~Huang and Z.~Xu, ``The estimation performance of nonlinear least squares for
  phase retrieval,'' \emph{IEEE Trans. Inf. Theory}, vol.~66, no.~12, pp.
  7967--7977, 2020.

\bibitem{hyder2019alternating}
R.~Hyder, V.~Shah, C.~Hegde, and M.~S. Asif, ``Alternating phase projected
  gradient descent with generative priors for solving compressive phase
  retrieval,'' in \emph{Int. Conf. Acoust. Sp. Sig. Proc. (ICASSP)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 7705--7709.

\bibitem{jagatap2019algorithmic}
G.~Jagatap and C.~Hegde, ``Algorithmic guarantees for inverse imaging with
  untrained network priors,'' in \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)},
  vol.~32, 2019.

\bibitem{jagatap2019sample}
G.~Jagatap and C.~Hegde, ``Sample-efficient algorithms for recovering
  structured signals from magnitude-only measurements,'' \emph{IEEE Trans. Inf.
  Theory}, vol.~65, no.~7, pp. 4434--4456, 2019.

\bibitem{jalal2021instance}
A.~Jalal, S.~Karmalkar, A.~Dimakis, and E.~Price, ``Instance-optimal compressed
  sensing via posterior sampling,'' in \emph{Int. Conf. Mach. Learn. (ICML)},
  2021.

\bibitem{jalal2020robust}
A.~Jalal, L.~Liu, A.~G. Dimakis, and C.~Caramanis, ``Robust compressed sensing
  using generative models,'' \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)},
  2020.

\bibitem{kamath2020power}
A.~Kamath, S.~Karmalkar, and E.~Price, ``On the power of compressed sensing
  with generative models,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2020, pp.
  5101--5109.

\bibitem{kuleshov2013fast}
V.~Kuleshov, ``Fast algorithms for sparse principal component analysis based on
  {R}ayleigh quotient iteration,'' in \emph{Int. Conf. Mach. Learn.
  (ICML)}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2013, pp. 1418--1425.

\bibitem{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning
  applied to document recognition,'' \emph{Proc. IEEE}, vol.~86, no.~11, pp.
  2278--2324, 1998.

\bibitem{li1989regression}
K.-C. Li and N.~Duan, ``Regression analysis under link violation,'' \emph{Ann.
  Stat.}, pp. 1009--1052, 1989.

\bibitem{liu2022non}
J.~Liu and Z.~Liu, ``Non-iterative recovery from nonlinear observations using
  generative models,'' in \emph{IEEE Comput. Soc. Conf. Comput. Vis. Pattern.
  Recognit. (CVPR)}, 2022, pp. 233--243.

\bibitem{liu2021towards}
Z.~Liu, S.~Ghosh, and J.~Scarlett, ``Towards sample-optimal compressive phase
  retrieval with sparse and generative priors,'' in \emph{Conf. Neur. Inf.
  Proc. Sys. (NeurIPS)}, 2021.

\bibitem{liu2020sample}
Z.~Liu, S.~Gomes, A.~Tiwari, and J.~Scarlett, ``Sample complexity bounds for
  $1$-bit compressive sensing and binary stable embeddings with generative
  priors,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2020.

\bibitem{liu2022projected}
Z.~Liu and J.~Han, ``Projected gradient descent algorithms for solving
  nonlinear inverse problems with generative priors,'' in \emph{Int. Jt. Conf.
  Artif. Intell. (IJCAI)}, 2022.

\bibitem{liu2022generative}
Z.~Liu, J.~Liu, S.~Ghosh, J.~Han, and J.~Scarlett, ``Generative principal
  component analysis,'' in \emph{Int. Conf. Learn. Repr. (ICLR)}, 2022.

\bibitem{liu2020generalized}
Z.~Liu and J.~Scarlett, ``The generalized {L}asso with nonlinear observations
  and generative priors,'' in \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)},
  vol.~33, 2020.

\bibitem{liu2020information}
Z.~Liu and J.~Scarlett, ``Information-theoretic lower bounds for compressive
  sensing with generative models,'' \emph{IEEE J. Sel. Areas Inf. Theory},
  vol.~1, no.~1, pp. 292--303, 2020.

\bibitem{liu2015deep}
Z.~Liu, P.~Luo, X.~Wang, and X.~Tang, ``Deep learning face attributes in the
  wild,'' in \emph{Proc. IEEE Int. Conf. Comput. Vis. (ICCV)}, 2015, pp.
  3730--3738.

\bibitem{lu2020phase}
Y.~M. Lu and G.~Li, ``Phase transitions of spectral initialization for
  high-dimensional non-convex estimation,'' \emph{Inf. Inference}, vol.~9,
  no.~3, pp. 507--541, 2020.

\bibitem{luo2016forward}
S.~Luo and S.~Ghosal, ``Forward selection and estimation in high dimensional
  single index models,'' \emph{Stat. Methodol.}, vol.~33, pp. 172--179, 2016.

\bibitem{luo2019optimal}
W.~Luo, W.~Alghamdi, and Y.~M. Lu, ``Optimal spectral initialization for signal
  recovery with applications to phase retrieval,'' \emph{IEEE Trans. Sig.
  Proc.}, vol.~67, no.~9, pp. 2347--2356, 2019.

\bibitem{maillard2022construction}
A.~Maillard, F.~Krzakala, Y.~M. Lu, and L.~Zdeborov{\'a}, ``Construction of
  optimal spectral methods in phase retrieval,'' in \emph{Math. Sci. Mach.
  Learn. (MSML)}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2022, pp.
  693--720.

\bibitem{maillard2020phase}
A.~Maillard, B.~Loureiro, F.~Krzakala, and L.~Zdeborov{\'a}, ``Phase retrieval
  in high dimensions: Statistical and computational phase transitions,''
  \emph{Conf. Neur. Inf. Proc. Sys. (NeurIPS)}, vol.~33, pp. 11\,071--11\,082,
  2020.

\bibitem{mccullagh2019generalized}
P.~McCullagh and J.~A. Nelder, \emph{Generalized linear models}.\hskip 1em plus
  0.5em minus 0.4em\relax Routledge, 2019.

\bibitem{menon2020pulse}
S.~Menon, A.~Damian, S.~Hu, N.~Ravi, and C.~Rudin, ``Pulse: {S}elf-supervised
  photo upsampling via latent space exploration of generative models,'' in
  \emph{IEEE Comput. Soc. Conf. Comput. Vis. Pattern. Recognit. (CVPR)}, 2020,
  pp. 2437--2445.

\bibitem{mondelli2018fundamental}
M.~Mondelli and A.~Montanari, ``Fundamental limits of weak recovery with
  applications to phase retrieval,'' in \emph{Conf. Learn. Theory
  (COLT)}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 1445--1450.

\bibitem{netrapalli2015phase}
P.~Netrapalli, P.~Jain, and S.~Sanghavi, ``Phase retrieval using alternating
  minimization,'' \emph{IEEE Trans. Sig. Proc.}, vol.~63, no.~18, pp.
  4814--4826, 2015.

\bibitem{neykov2016l1}
M.~Neykov, J.~S. Liu, and T.~Cai, ``${L}_1$-regularized least squares for
  support recovery of high dimensional single index models with {G}aussian
  designs,'' \emph{J. Mach. Learn. Res.}, vol.~17, no.~1, pp. 2976--3012, 2016.

\bibitem{neykov2020agnostic}
M.~Neykov, Z.~Wang, and H.~Liu, ``Agnostic estimation for misspecified phase
  retrieval models,'' \emph{J. Mach. Learn. Res.}, vol.~21, pp. 1--39, 2020.

\bibitem{nguyen2021provable}
T.~V. Nguyen, G.~Jagatap, and C.~Hegde, ``Provable compressed sensing with
  generative priors via {L}angevin dynamics,''
  \emph{https://arxiv.org/2102.12643}, 2021.

\bibitem{ohlsson2012cprl}
H.~Ohlsson, A.~Yang, R.~Dong, and S.~Sastry, ``{CPRL}--{A}n extension of
  compressive sensing to the phase retrieval problem,'' \emph{Conf. Neur. Inf.
  Proc. Sys. (NeurIPS)}, vol.~25, pp. 1367--1375, 2012.

\bibitem{ongie2020deep}
G.~Ongie, A.~Jalal, C.~A. Metzler, R.~G. Baraniuk, A.~G. Dimakis, and
  R.~Willett, ``Deep learning techniques for inverse problems in imaging,''
  \emph{IEEE J. Sel. Areas Inf. Theory}, vol.~1, no.~1, pp. 39--56, 2020.

\bibitem{oymak2017fast}
S.~Oymak and M.~Soltanolkotabi, ``Fast and reliable parameter estimation from
  nonlinear observations,'' \emph{SIAM J. Optim.}, vol.~27, no.~4, pp.
  2276--2300, 2017.

\bibitem{pananjady2021single}
A.~Pananjady and D.~P. Foster, ``Single-index models in the high signal
  regime,'' \emph{IEEE Trans. Inf. Theory}, vol.~67, no.~6, pp. 4092--4124,
  2021.

\bibitem{pauwels2017fienup}
E.~J.~R. Pauwels, A.~Beck, Y.~C. Eldar, and S.~Sabach, ``On fienup methods for
  sparse phase retrieval,'' \emph{IEEE Trans. Sig. Proc.}, vol.~66, no.~4, pp.
  982--991, 2017.

\bibitem{peng2020solving}
P.~Peng, S.~Jalali, and X.~Yuan, ``Solving inverse problems via
  auto-encoders,'' \emph{IEEE J. Sel. Areas Inf. Theory}, vol.~1, no.~1, pp.
  312--323, 2020.

\bibitem{plan2016generalized}
Y.~Plan and R.~Vershynin, ``The generalized {L}asso with non-linear
  observations,'' \emph{IEEE Trans. Inf. Theory}, vol.~62, no.~3, pp.
  1528--1537, 2016.

\bibitem{plan2017high}
Y.~Plan, R.~Vershynin, and E.~Yudovina, ``High-dimensional estimation with
  geometric constraints,'' \emph{Inf. Inference}, vol.~6, no.~1, pp. 1--40,
  2017.

\bibitem{radchenko2015high}
P.~Radchenko, ``High dimensional single index models,'' \emph{J. Multivar.
  Anal.}, vol. 139, pp. 266--282, 2015.

\bibitem{raj2019gan}
A.~Raj, Y.~Li, and Y.~Bresler, ``{GAN}-based projector for faster recovery with
  convergence guarantees in linear inverse problems,'' in \emph{Proc. IEEE Int.
  Conf. Comput. Vis. (ICCV)}, 2019.

\bibitem{rick2017one}
J.~Rick~Chang, C.-L. Li, B.~Poczos, B.~Vijaya~Kumar, and A.~C.
  Sankaranarayanan, ``One network to solve them all--solving linear inverse
  problems using deep projection models,'' in \emph{Proc. IEEE Int. Conf.
  Comput. Vis. (ICCV)}, 2017, pp. 5888--5897.

\bibitem{scarlett2016limits}
J.~Scarlett and V.~Cevher, ``Limits on support recovery with probabilistic
  models: {A}n information-theoretic framework,'' \emph{IEEE Trans. Inf.
  Theory}, vol.~63, no.~1, pp. 593--620, 2016.

\bibitem{scarlett2022theoretical}
J.~Scarlett, R.~Heckel, M.~R. Rodrigues, P.~Hand, and Y.~C. Eldar,
  ``Theoretical perspectives on deep learning methods in inverse problems,''
  \emph{https://arxiv.org/2206.14373}, 2022.

\bibitem{shah2018solving}
V.~Shah and C.~Hegde, ``Solving linear inverse problems using {GAN} priors: An
  algorithm with provable guarantees,'' in \emph{Int. Conf. Acoust. Sp. Sig.
  Proc. (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp.
  4609--4613.

\bibitem{shamshad2020compressed}
F.~Shamshad and A.~Ahmed, ``Compressed sensing-based robust phase retrieval via
  deep generative priors,'' \emph{IEEE Sens. J.}, vol.~21, no.~2, pp.
  2286--2298, 2020.

\bibitem{sherman1993limiting}
R.~P. Sherman, ``The limiting distribution of the maximum rank correlation
  estimator,'' \emph{Econometrica}, pp. 123--137, 1993.

\bibitem{soltanolkotabi2019structured}
M.~Soltanolkotabi, ``Structured signal recovery from quadratic measurements:
  Breaking sample complexity barriers via nonconvex optimization,'' \emph{IEEE
  Trans. Inf. Theory}, vol.~65, no.~4, pp. 2374--2400, 2019.

\bibitem{sun2018geometric}
J.~Sun, Q.~Qu, and J.~Wright, ``A geometric analysis of phase retrieval,''
  \emph{Found. Comput. Math.}, vol.~18, no.~5, pp. 1131--1198, 2018.

\bibitem{thrampoulidis2015lasso}
C.~Thrampoulidis, E.~Abbasi, and B.~Hassibi, ``Lasso with non-linear
  measurements is equivalent to one with linear measurements,'' in \emph{Conf.
  Neur. Inf. Proc. Sys. (NeurIPS)}, 2015, pp. 3420--3428.

\bibitem{van2018compressed}
D.~Van~Veen, A.~Jalal, M.~Soltanolkotabi, E.~Price, S.~Vishwanath, and A.~G.
  Dimakis, ``Compressed sensing with deep image prior and learned
  regularization,'' \emph{https://arxiv.org/1806.06438}, 2018.

\bibitem{vershynin2010introduction}
R.~Vershynin, ``Introduction to the non-asymptotic analysis of random
  matrices,'' \emph{https://arxiv.org/abs/1011.3027}, 2010.

\bibitem{vershynin2018high}
R.~Vershynin, \emph{High-dimensional probability: An introduction with
  applications in data science}.\hskip 1em plus 0.5em minus 0.4em\relax
  Cambridge university press, 2018, vol.~47.

\bibitem{wainwright2009information}
M.~J. Wainwright, ``Information-theoretic limits on sparsity recovery in the
  high-dimensional and noisy setting,'' \emph{IEEE Trans. Inf. Theory},
  vol.~55, no.~12, pp. 5728--5741, 2009.

\bibitem{wainwright2019high}
M.~J. Wainwright, \emph{High-dimensional statistics: A non-asymptotic
  viewpoint}.\hskip 1em plus 0.5em minus 0.4em\relax Cambridge University
  Press, 2019, vol.~48.

\bibitem{waldspurger2015phase}
I.~Waldspurger, A.~d'Aspremont, and S.~Mallat, ``Phase recovery, maxcut and
  complex semidefinite programming,'' \emph{Math. Program.}, vol. 149, no.~1,
  pp. 47--81, 2015.

\bibitem{wang2017solving}
G.~Wang, G.~B. Giannakis, and Y.~C. Eldar, ``Solving systems of random
  quadratic equations via truncated amplitude flow,'' \emph{IEEE Trans. Inf.
  Theory}, vol.~64, no.~2, pp. 773--794, 2017.

\bibitem{wang2017sparse}
G.~Wang, L.~Zhang, G.~B. Giannakis, M.~Ak{\c{c}}akaya, and J.~Chen, ``Sparse
  phase retrieval via truncated amplitude flow,'' \emph{IEEE Trans. Sig.
  Proc.}, vol.~66, no.~2, pp. 479--491, 2017.

\bibitem{wei2018structured}
X.~Wei, ``Structured recovery with heavy-tailed measurements: A thresholding
  procedure and optimal rates,'' \emph{https://arxiv.org/abs/1804.05959}, 2018.

\bibitem{wei2019statistical}
X.~Wei, Z.~Yang, and Z.~Wang, ``On the statistical rate of nonlinear recovery
  in generative models with heavy-tailed data,'' in \emph{Int. Conf. Mach.
  Learn. (ICML)}, 2019, pp. 6697--6706.

\bibitem{whang2020compressed}
J.~Whang, Q.~Lei, and A.~G. Dimakis, ``Compressed sensing with invertible
  generative models and dependent noise,'' \emph{https://arxiv.org/2003.08089},
  2020.

\bibitem{wu2019deep}
Y.~Wu, M.~Rosca, and T.~Lillicrap, ``Deep compressed sensing,'' in \emph{Int.
  Conf. Mach. Learn. (ICML)}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2019, pp. 6850--6860.

\bibitem{yang2017high}
Z.~Yang, K.~Balasubramanian, and H.~Liu, ``High-dimensional non-{G}aussian
  single index models via thresholded score function estimation,'' in
  \emph{Int. Conf. Mach. Learn. (ICML)}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2017, pp. 3851--3860.

\bibitem{yang2019misspecified}
Z.~Yang, L.~F. Yang, E.~X. Fang, T.~Zhao, Z.~Wang, and M.~Neykov,
  ``Misspecified nonconvex statistical optimization for sparse phase
  retrieval,'' \emph{Math. Program.}, vol. 176, no.~1, pp. 545--571, 2019.

\bibitem{zhang2017nonconvex}
H.~Zhang, Y.~Zhou, Y.~Liang, and Y.~Chi, ``A nonconvex approach for phase
  retrieval: Reshaped {W}irtinger flow and incremental algorithms,'' \emph{J.
  Mach. Learn. Res.}, vol.~18, 2017.

\end{thebibliography}
