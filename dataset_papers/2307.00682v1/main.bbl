\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{GPAM{\etalchar{+}}20}

\bibitem[AHS22]{ainsworth2022git}
Samuel~K Ainsworth, Jonathan Hayase, and Siddhartha Srinivasa.
\newblock Git re-basin: Merging models modulo permutation symmetries.
\newblock {\em arXiv preprint arXiv:2209.04836}, 2022.

\bibitem[AL07]{aumann2007security}
Yonatan Aumann and Yehuda Lindell.
\newblock Security against covert adversaries: Efficient protocols for
  realistic adversaries.
\newblock In {\em Theory of Cryptography: 4th Theory of Cryptography
  Conference, TCC 2007, Amsterdam, The Netherlands, February 21-24, 2007.
  Proceedings 4}, pages 137--156. Springer, 2007.

\bibitem[BISZ{\etalchar{+}}22]{bober2022architectural}
Mikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert Mullins, and Nicolas
  Papernot.
\newblock Architectural backdoors in neural networks.
\newblock {\em arXiv preprint arXiv:2206.07840}, 2022.

\bibitem[BPS{\etalchar{+}}23]{biderman2023emergent}
Stella Biderman, USVSN~Sai Prashanth, Lintang Sutawika, Hailey Schoelkopf,
  Quentin Anthony, Shivanshu Purohit, and Edward Raf.
\newblock Emergent and predictable memorization in large language models.
\newblock {\em arXiv preprint arXiv:2304.11158}, 2023.

\bibitem[BSA{\etalchar{+}}23]{biderman2023pythia}
Stella Biderman, Hailey Schoelkopf, Quentin Anthony, Herbie Bradley, Kyle
  O'Brien, Eric Hallahan, Mohammad~Aflah Khan, Shivanshu Purohit, USVSN~Sai
  Prashanth, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van~der
  Wal.
\newblock Pythia: A suite for analyzing large language models across training
  and scaling, 2023.

\bibitem[Cen23]{evals_alignment_2023}
Alignment~Research Center.
\newblock Update on {ARC}'s recent eval efforts, March 2023.

\bibitem[CKV10]{chung2010improved}
Kai-Min Chung, Yael Kalai, and Salil Vadhan.
\newblock Improved delegation of computation using fully homomorphic
  encryption.
\newblock In {\em Advances in Cryptology--CRYPTO 2010: 30th Annual Cryptology
  Conference, Santa Barbara, CA, USA, August 15-19, 2010. Proceedings 30},
  pages 483--501. Springer, 2010.

\bibitem[FDRC20]{frankle2020linear}
Jonathan Frankle, Gintare~Karolina Dziugaite, Daniel Roy, and Michael Carbin.
\newblock Linear mode connectivity and the lottery ticket hypothesis.
\newblock In {\em International Conference on Machine Learning}, pages
  3259--3269. PMLR, 2020.

\bibitem[FJT{\etalchar{+}}22]{fang2022fundamental}
Congyu Fang, Hengrui Jia, Anvith Thudi, Mohammad Yaghini, Christopher~A
  Choquette-Choo, Natalie Dullerud, Varun Chandrasekaran, and Nicolas Papernot.
\newblock On the fundamental limits of formally (dis) proving robustness in
  proof-of-learning.
\newblock {\em arXiv preprint arXiv:2208.03567}, 2022.

\bibitem[FZ20]{NEURIPS2020_1e14bfe2}
Vitaly Feldman and Chiyuan Zhang.
\newblock What neural networks memorize and why: Discovering the long tail via
  influence estimation.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 2881--2891. Curran Associates, Inc., 2020.

\bibitem[GBB{\etalchar{+}}20]{pile}
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles
  Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser,
  and Connor Leahy.
\newblock The {P}ile: An 800gb dataset of diverse text for language modeling.
\newblock {\em arXiv preprint arXiv:2101.00027}, 2020.

\bibitem[GCPT19]{Gokaslan2019OpenWeb}
Aaron Gokaslan, Vanya Cohen, Ellie Pavlick, and Stefanie Tellex.
\newblock Openwebtext corpus, 2019.

\bibitem[GKVZ22]{goldwasser2022planting}
Shafi Goldwasser, Michael~P Kim, Vinod Vaikuntanathan, and Or~Zamir.
\newblock Planting undetectable backdoors in machine learning models.
\newblock In {\em 2022 IEEE 63rd Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 931--942. IEEE, 2022.

\bibitem[GPAM{\etalchar{+}}20]{goodfellow2020generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock {\em Communications of the ACM}, 63(11):139--144, 2020.

\bibitem[GTB22]{guo2022overview}
Wei Guo, Benedetta Tondi, and Mauro Barni.
\newblock An overview of backdoor attacks against deep neural networks and
  possible defences.
\newblock {\em IEEE Open Journal of Signal Processing}, 2022.

\bibitem[JYCC{\etalchar{+}}21]{jia2021proof}
Hengrui Jia, Mohammad Yaghini, Christopher~A Choquette-Choo, Natalie Dullerud,
  Anvith Thudi, Varun Chandrasekaran, and Nicolas Papernot.
\newblock Proof-of-learning: Definitions and practice.
\newblock In {\em 2021 IEEE Symposium on Security and Privacy (SP)}, pages
  1039--1056. IEEE, 2021.

\bibitem[KGG{\etalchar{+}}22]{kaplun2022deconstructing}
Gal Kaplun, Nikhil Ghosh, Saurabh Garg, Boaz Barak, and Preetum Nakkiran.
\newblock Deconstructing distributions: A pointwise framework of learning.
\newblock {\em arXiv preprint arXiv:2202.09931}, 2022.

\bibitem[KRCC22]{kong2022forgeability}
Zhifeng Kong, Amrita Roy~Chowdhury, and Kamalika Chaudhuri.
\newblock Forgeability and membership inference attacks.
\newblock In {\em Proceedings of the 15th ACM Workshop on Artificial
  Intelligence and Security}, pages 25--31, 2022.

\bibitem[OWJ{\etalchar{+}}22]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock {\em Advances in Neural Information Processing Systems},
  35:27730--27744, 2022.

\bibitem[RWC{\etalchar{+}}19]{radford2019language}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock arXiv preprint arXiv:1901.11196, 2019.

\bibitem[Sha23]{shavit2023does}
Yonadav Shavit.
\newblock What does it take to catch a {C}hinchilla? {V}erifying rules on
  large-scale neural network training via compute monitoring.
\newblock {\em arXiv preprint arXiv:2303.11341}, 2023.

\bibitem[SSK{\etalchar{+}}21]{shumailov2021manipulating}
Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot,
  Murat~A Erdogdu, and Ross~J Anderson.
\newblock Manipulating sgd with data ordering attacks.
\newblock {\em Advances in Neural Information Processing Systems},
  34:18021--18032, 2021.

\bibitem[TJSP22]{thudi2022necessity}
Anvith Thudi, Hengrui Jia, Ilia Shumailov, and Nicolas Papernot.
\newblock On the necessity of auditable algorithmic definitions for machine
  unlearning.
\newblock In {\em 31st USENIX Security Symposium (USENIX Security 22)}, pages
  4007--4022, 2022.

\bibitem[TSC{\etalchar{+}}18]{toneva2018empirical}
Mariya Toneva, Alessandro Sordoni, Remi Tachet~des Combes, Adam Trischler,
  Yoshua Bengio, and Geoffrey~J Gordon.
\newblock An empirical study of example forgetting during deep neural network
  learning.
\newblock {\em arXiv preprint arXiv:1812.05159}, 2018.

\bibitem[XWL{\etalchar{+}}21]{xu2021detecting}
Xiaojun Xu, Qi~Wang, Huichen Li, Nikita Borisov, Carl~A Gunter, and Bo~Li.
\newblock Detecting ai trojans using meta neural analysis.
\newblock In {\em 2021 IEEE Symposium on Security and Privacy (SP)}, pages
  103--120. IEEE, 2021.

\bibitem[YZS{\etalchar{+}}22]{yang2022diffusion}
Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao,
  Yingxia Shao, Wentao Zhang, Bin Cui, and Ming-Hsuan Yang.
\newblock Diffusion models: A comprehensive survey of methods and applications.
\newblock {\em arXiv preprint arXiv:2209.00796}, 2022.

\bibitem[ZIL{\etalchar{+}}21]{zhang2021counterfactual}
Chiyuan Zhang, Daphne Ippolito, Katherine Lee, Matthew Jagielski, Florian
  Tram{\`e}r, and Nicholas Carlini.
\newblock Counterfactual memorization in neural language models.
\newblock {\em arXiv preprint arXiv:2112.12938}, 2021.

\bibitem[ZLD{\etalchar{+}}22]{zhang2022adversarial}
Rui Zhang, Jian Liu, Yuan Ding, Zhibo Wang, Qingbiao Wu, and Kui Ren.
\newblock “adversarial examples” for proof-of-learning.
\newblock In {\em 2022 IEEE Symposium on Security and Privacy (SP)}, pages
  1408--1422, 2022.

\end{thebibliography}
