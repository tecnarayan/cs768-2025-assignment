\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amershi et~al.(2019)Amershi, Begel, Bird, DeLine, Gall, Kamar,
  Nagappan, Nushi, and Zimmermann]{amershi2019}
S.~Amershi, A.~Begel, C.~Bird, R.~DeLine, H.~Gall, E.~Kamar, N.~Nagappan,
  B.~Nushi, and T.~Zimmermann.
\newblock Software engineering for machine learning: A case study.
\newblock In \emph{Proceedings of the International Conference on Software
  Engineering}, 2019.

\bibitem[Azizpour et~al.(2016)Azizpour, Razavian, Sullivan, Maki, and
  Carlsson]{azizpour2016}
H.~Azizpour, A.~S. Razavian, J.~Sullivan, A.~Maki, and S.~Carlsson.
\newblock Factors of transferability for a generic convnet representation.
\newblock \emph{{IEEE} Transactions on Pattern Analysis and Machince
  Intelligence}, 38\penalty0 (9):\penalty0 1790--1802, 2016.

\bibitem[Bansal et~al.(2020)Bansal, Nushi, Kamar, Weld, Lasecki, and
  Horvitz]{bansal2020}
G.~Bansal, B.~Nushi, E.~Kamar, D.~S. Weld, W.~S. Lasecki, and E.~Horvitz.
\newblock Updates in human-{AI} teams: Understanding and addressing the
  performance/compatibility tradeoff.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 2429--2437, 2020.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{bendavid2010}
S.~Ben-David, J.~Blitzer, K.~Crammer, A.~Kulesza, F.~Pereira, and J.~W.
  Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine Learning}, 79:\penalty0 151--175, 2010.

\bibitem[Bottou and Bousquet(2008)]{bottou2008}
L.~Bottou and O.~Bousquet.
\newblock The tradeoffs of large-scale learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 161--168, 2008.

\bibitem[Boucheron et~al.(2005)Boucheron, Bousquet, and Lugosi]{boucheron2005}
S.~Boucheron, O.~Bousquet, and G.~Lugosi.
\newblock Theory of classification: a survey of recent advances.
\newblock \emph{ESAIM: Probability and Statistics}, 9:\penalty0 323--375, 2005.

\bibitem[Brookshear(2009)]{glenn2009}
J.~Brookshear.
\newblock \emph{Computer Science. An Overview ($9^{th}$ edition)}.
\newblock Addison-Wesley, 2009.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{gpt3}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss,
  G.~M. Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~Ziegler, J.~Wu,
  C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess,
  J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing}, 2020.

\bibitem[Burkov(2020)]{burkov2020mlops}
A.~Burkov.
\newblock \emph{Machine Learning Engineering}.
\newblock True Positive Inc., 2020.

\bibitem[Caruana(1997)]{caruana97}
R.~Caruana.
\newblock Multi-task learning.
\newblock \emph{Machine Learning}, 28:\penalty0 41--75, 1997.

\bibitem[Chang and Chen(2018)]{chang2018pyramid}
J.-R. Chang and Y.-S. Chen.
\newblock Pyramid stereo matching network.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5410--5418, 2018.

\bibitem[Chen et~al.(2015)Chen, Kundu, Zhu, Berneshawi, Ma, Fidler, and
  Urtasun]{chen20153d}
X.~Chen, K.~Kundu, Y.~Zhu, A.~G. Berneshawi, H.~Ma, S.~Fidler, and R.~Urtasun.
\newblock 3{D} object proposals for accurate object class detection.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[D’Amour et~al.(2020)D’Amour, Heller, Moldovan, Adlam, Alipanahi,
  Beutel, Chen, Deaton, Eisenstein, Hoffman, Hormozdiari, Houlsby, Hou, Jerfel,
  Karthikesalingam, Lucic, Ma, McLean, Mincu, Mitani, Montanari, Nado,
  Natarajan, Nielson, Osborne, Raman, Ramasamy, Sayres, Schrouff, Seneviratne,
  Sequeira, Suresh, Veitch, Vladymyrov, Wang, Webster, Yadlowsky, Yun, Zhai,
  and Sculley]{damour2020underspecification}
A.~D’Amour, K.~Heller, D.~Moldovan, B.~Adlam, B.~Alipanahi, A.~Beutel,
  C.~Chen, J.~Deaton, J.~Eisenstein, M.~D. Hoffman, F.~Hormozdiari, N.~Houlsby,
  S.~Hou, G.~Jerfel, A.~Karthikesalingam, M.~Lucic, Y.~Ma, C.~McLean, D.~Mincu,
  A.~Mitani, A.~Montanari, Z.~Nado, V.~Natarajan, C.~Nielson, T.~F. Osborne,
  R.~Raman, K.~Ramasamy, R.~Sayres, J.~Schrouff, M.~Seneviratne, S.~Sequeira,
  H.~Suresh, V.~Veitch, M.~Vladymyrov, X.~Wang, K.~Webster, S.~Yadlowsky,
  T.~Yun, X.~Zhai, and D.~Sculley.
\newblock Underspecification presents challenges for credibility in modern
  machine learning.
\newblock In \emph{arXiv:2011.03395}, 2020.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017}
C.~Finn, P.~Abbeel, and S.~Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 1126--1135, 2017.

\bibitem[Geiger et~al.(2012)Geiger, Lenz, and Urtasun]{Geiger2012CVPR}
A.~Geiger, P.~Lenz, and R.~Urtasun.
\newblock Are we ready for autonomous driving? {T}he {KITTI} vision benchmark
  suite.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2012.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 1321--1330, 2017.

\bibitem[Innes et~al.(2019)Innes, Edelman, Fischer, Rackauckas, Saba, Shah, and
  Tebbutt]{innes2019}
M.~Innes, A.~Edelman, K.~Fischer, C.~Rackauckas, E.~Saba, V.~Shah, and
  W.~Tebbutt.
\newblock A differentiable programming system to bridge machine learning and
  scientific computing.
\newblock In \emph{arXiv:1907.07587}, 2019.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and Le]{kornblith2019better}
S.~Kornblith, J.~Shlens, and Q.~V. Le.
\newblock Do better {I}mage{N}et models transfer better?
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2661--2671, 2019.

\bibitem[Krizhevsky and Hinton(2009)]{krizhevksy2009}
A.~Krizhevsky and G.~Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Lwakatarea et~al.(2020)Lwakatarea, Raj, Crnkovica, Bosch, and
  Olsson]{lwakatarea2020}
L.~Lwakatarea, A.~Raj, I.~Crnkovica, J.~Bosch, and H.~H. Olsson.
\newblock Large-scale machine learning systems in real-world industrial
  settings: A review of challenges and solutions.
\newblock \emph{Information and Software Technology}, 127, 2020.

\bibitem[Nushi et~al.(2017)Nushi, Kamar, Horvitz, and Kossmann]{nushi2017}
B.~Nushi, E.~Kamar, E.~Horvitz, and D.~Kossmann.
\newblock On human intellect and machine failures: Troubleshooting integrative
  machine learning systems.
\newblock In \emph{Proceedings of AAAI Conference on Artificial Intelligence},
  2017.

\bibitem[Ozkaya(2020)]{ozkaya2020}
I.~Ozkaya.
\newblock What is really different in engineering {AI}-enabled systems?
\newblock \emph{IEEE Software}, 37\penalty0 (4), 2020.

\bibitem[Pan and Yang(2010)]{pan2010}
S.~J. Pan and Q.~Yang.
\newblock A survey on transfer learning.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering},
  22:\penalty0 1345--1359, 2010.

\bibitem[Patel et~al.(2015)Patel, Gopalan, Li, and Chellappa]{patel2015}
V.~M. Patel, R.~Gopalan, R.~Li, and R.~Chellappa.
\newblock Visual domain adaptation: A survey of recent advances.
\newblock \emph{IEEE Signal Processing Magazine}, 32:\penalty0 53--69, 2015.

\bibitem[Qi et~al.(2018)Qi, Liu, Wu, Su, and Guibas]{qi2018frustum}
C.~R. Qi, W.~Liu, C.~Wu, H.~Su, and L.~J. Guibas.
\newblock Frustum pointnets for {3D} object detection from {RGB-D} data.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 918--927, 2018.

\bibitem[Scovel and Steinwart(2005)]{scovel2005}
C.~Scovel and I.~Steinwart.
\newblock Fast rates for support vector machines.
\newblock In \emph{Proceedings of the Conference on Learning Theory (COLT
  2005)}, pages 279--294, 2005.

\bibitem[Sculley et~al.(2015)Sculley, Holt, Golovin, Davydov, Phillips, Ebner,
  Chaudhary, Young, Crespo, and Dennison]{sculley2015hidden}
D.~Sculley, G.~Holt, D.~Golovin, E.~Davydov, T.~Phillips, D.~Ebner,
  V.~Chaudhary, M.~Young, J.-F. Crespo, and D.~Dennison.
\newblock Hidden technical debt in machine learning systems.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Shen et~al.(2020)Shen, Xiong, Xia, and Soatto]{shen2020backwards}
Y.~Shen, Y.~Xiong, W.~Xia, and S.~Soatto.
\newblock Towards backward-compatible representation learning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6368--6377, 2020.

\bibitem[Shi et~al.(2019)Shi, Wang, and Li]{shi2019pointrcnn}
S.~Shi, X.~Wang, and H.~Li.
\newblock {PointRCNN}: {3D} object proposal generation and detection from point
  cloud.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 770--779, 2019.

\bibitem[Shimodaira(2000)]{shimodaira2000}
H.~Shimodaira.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock \emph{Journal of Statistical Planning and Inference}, 90:\penalty0
  227--244, 2000.

\bibitem[Srivastava et~al.(2020)Srivastava, Nushi, Kamar, Shah, and
  Horvitz]{srivastava2020}
M.~Srivastava, B.~Nushi, E.~Kamar, S.~Shah, and E.~Horvitz.
\newblock An empirical analysis of backward compatibility in machine learning
  systems.
\newblock In \emph{Proceedings of the ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining}, 2020.

\bibitem[Vapnik(1982)]{vapnik1982}
V.~N. Vapnik.
\newblock \emph{Estimation of Dependences Based on Empirical Data}.
\newblock Springer-Verlag, Berlin, 1982.

\bibitem[Wang et~al.(2020)Wang, Chang, Yang, Chen, and Lai]{wang2020unified}
C.-Y. Wang, Y.-L. Chang, S.-T. Yang, D.~Chen, and S.-H. Lai.
\newblock Unified representation learning for cross model compatibility.
\newblock In \emph{Proceedings of the British Machine Vision Conference}, 2020.

\bibitem[Wang et~al.(2018)Wang, Decker, Wu, Essertel, and
  Rompf]{wang2018backprop}
F.~Wang, J.~Decker, X.~Wu, G.~Essertel, and T.~Rompf.
\newblock Backpropagation with callbacks: Foundations for efficient and
  expressive differentiable programming.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Wang et~al.(2019)Wang, Chao, Garg, Hariharan, Campbell, and
  Weinberger]{wang2019pseudo}
Y.~Wang, W.-L. Chao, D.~Garg, B.~Hariharan, M.~Campbell, and K.~Q. Weinberger.
\newblock Pseudo-{LiDAR} from visual depth estimation: {B}ridging the gap in
  {3D} object detection for autonomous driving.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 8445--8453, 2019.

\bibitem[Yan et~al.(2021)Yan, Xiong, Kundu, Yang, Deng, Wang, Xia, and
  Soatto]{yan2021pc}
S.~Yan, Y.~Xiong, K.~Kundu, S.~Yang, S.~Deng, M.~Wang, W.~Xia, and S.~Soatto.
\newblock Positive-congruent training: Towards regression-free model updates.
\newblock In \emph{arXiv:2011.09161}, 2021.

\bibitem[Zhang(2004)]{zhang2004}
T.~Zhang.
\newblock Statistical behavior and consistency of classification methods based
  on convex risk minimization.
\newblock \emph{The Annals of Statistics}, 32:\penalty0 56--85, 2004.

\end{thebibliography}
