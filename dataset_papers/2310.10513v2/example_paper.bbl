\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agustsson \& Timofte(2017)Agustsson and Timofte]{DIV2K}
Agustsson, E. and Timofte, R.
\newblock Ntire 2017 challenge on single image super-resolution: Dataset and
  study.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition workshops}, pp.\  126--135, 2017.

\bibitem[Aubry et~al.(2014)Aubry, Paris, Hasinoff, Kautz, and Durand]{LLF}
Aubry, M., Paris, S., Hasinoff, S.~W., Kautz, J., and Durand, F.
\newblock Fast local laplacian filters: Theory and applications.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 33\penalty0 (5):\penalty0
  1--14, 2014.

\bibitem[Bar et~al.(2022)Bar, Gandelsman, Darrell, Globerson, and
  Efros]{MAEVQGAN}
Bar, A., Gandelsman, Y., Darrell, T., Globerson, A., and Efros, A.
\newblock Visual prompting via image inpainting.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 25005--25017, 2022.

\bibitem[Bevilacqua et~al.(2012)Bevilacqua, Roumy, Guillemot, and
  Alberi-Morel]{Set5}
Bevilacqua, M., Roumy, A., Guillemot, C., and Alberi-Morel, M.~L.
\newblock Low-complexity single-image super-resolution based on nonnegative
  neighbor embedding.
\newblock 2012.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{GPT3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Bychkovsky et~al.(2011)Bychkovsky, Paris, Chan, and Durand]{FiveK}
Bychkovsky, V., Paris, S., Chan, E., and Durand, F.
\newblock Learning photographic global tonal adjustment with a database of
  input/output image pairs.
\newblock In \emph{CVPR 2011}, pp.\  97--104. IEEE, 2011.

\bibitem[Chen et~al.(2023)Chen, Yao, Chen, Zhang, and
  Liu]{chen2023understanding}
Chen, A., Yao, Y., Chen, P.-Y., Zhang, Y., and Liu, S.
\newblock Understanding and improving visual prompting: A label-mapping
  perspective.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  19133--19143, 2023.

\bibitem[Chen et~al.(2021)Chen, Wang, Guo, Xu, Deng, Liu, Ma, Xu, Xu, and
  Gao]{IPT}
Chen, H., Wang, Y., Guo, T., Xu, C., Deng, Y., Liu, Z., Ma, S., Xu, C., Xu, C.,
  and Gao, W.
\newblock Pre-trained image processing transformer.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  12299--12310, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{ImageNet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dong et~al.(2015)Dong, Loy, He, and Tang]{SRCNN}
Dong, C., Loy, C.~C., He, K., and Tang, X.
\newblock Image super-resolution using deep convolutional networks.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 38\penalty0 (2):\penalty0 295--307, 2015.

\bibitem[Dong et~al.(2016)Dong, Loy, and Tang]{FSRCNN}
Dong, C., Loy, C.~C., and Tang, X.
\newblock Accelerating the super-resolution convolutional neural network.
\newblock In \emph{Computer Vision--ECCV 2016: 14th European Conference,
  Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pp.\  391--407. Springer, 2016.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{ViT}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{MAE}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'a}r, P., and Girshick, R.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  16000--16009, 2022.

\bibitem[Huang et~al.(2015)Huang, Singh, and Ahuja]{Urban100}
Huang, J.-B., Singh, A., and Ahuja, N.
\newblock Single image super-resolution from transformed self-exemplars.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  5197--5206, 2015.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson,
  Xiao, Whitehead, Berg, Lo, et~al.]{SAM}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
  T., Whitehead, S., Berg, A.~C., Lo, W.-Y., et~al.
\newblock Segment anything.
\newblock \emph{arXiv preprint arXiv:2304.02643}, 2023.

\bibitem[Kupyn et~al.(2018)Kupyn, Budzan, Mykhailych, Mishkin, and
  Matas]{DeblurGAN}
Kupyn, O., Budzan, V., Mykhailych, M., Mishkin, D., and Matas, J.
\newblock Deblurgan: Blind motion deblurring using conditional adversarial
  networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  8183--8192, 2018.

\bibitem[Li et~al.(2018)Li, Ren, Fu, Tao, Feng, Zeng, and Wang]{RESIDE}
Li, B., Ren, W., Fu, D., Tao, D., Feng, D., Zeng, W., and Wang, Z.
\newblock Benchmarking single-image dehazing and beyond.
\newblock \emph{IEEE Transactions on Image Processing}, 28\penalty0
  (1):\penalty0 492--505, 2018.

\bibitem[Li et~al.(2022)Li, Liu, Hu, Wu, Lv, and Peng]{AirNet}
Li, B., Liu, X., Hu, P., Wu, Z., Lv, J., and Peng, X.
\newblock All-in-one image restoration for unknown corruption.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  17452--17462, 2022.

\bibitem[Liang et~al.(2021)Liang, Cao, Sun, Zhang, Van~Gool, and
  Timofte]{SwinIR}
Liang, J., Cao, J., Sun, G., Zhang, K., Van~Gool, L., and Timofte, R.
\newblock Swinir: Image restoration using swin transformer.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  1833--1844, 2021.

\bibitem[Liu et~al.(2021)Liu, Shen, Zhang, Dolan, Carin, and
  Chen]{liu2021makes}
Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., and Chen, W.
\newblock What makes good in-context examples for gpt-$3 $?
\newblock \emph{arXiv preprint arXiv:2101.06804}, 2021.

\bibitem[Liu et~al.(2023)Liu, Yuan, Fu, Jiang, Hayashi, and Neubig]{liu2023pre}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock \emph{ACM Computing Surveys}, 55\penalty0 (9):\penalty0 1--35, 2023.

\bibitem[Liu et~al.(2022)Liu, He, Chen, Zhang, Zhao, Dong, and Qiao]{CSRNet}
Liu, Y., He, J., Chen, X., Zhang, Z., Zhao, H., Dong, C., and Qiao, Y.
\newblock Very lightweight photo retouching network with conditional sequential
  modulation.
\newblock \emph{IEEE Transactions on Multimedia}, 2022.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{AdamW}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Ma et~al.(2023)Ma, Cheng, Wang, Zhang, Wang, and Zhang]{ProRes}
Ma, J., Cheng, T., Wang, G., Zhang, Q., Wang, X., and Zhang, L.
\newblock Prores: Exploring degradation-aware visual prompt for universal image
  restoration.
\newblock \emph{arXiv preprint arXiv:2306.13653}, 2023.

\bibitem[Martin et~al.(2001)Martin, Fowlkes, Tal, and Malik]{BSDS100}
Martin, D., Fowlkes, C., Tal, D., and Malik, J.
\newblock A database of human segmented natural images and its application to
  evaluating segmentation algorithms and measuring ecological statistics.
\newblock In \emph{Proceedings Eighth IEEE International Conference on Computer
  Vision. ICCV 2001}, volume~2, pp.\  416--423. IEEE, 2001.

\bibitem[Matsui et~al.(2017)Matsui, Ito, Aramaki, Fujimoto, Ogawa, Yamasaki,
  and Aizawa]{Manga109}
Matsui, Y., Ito, K., Aramaki, Y., Fujimoto, A., Ogawa, T., Yamasaki, T., and
  Aizawa, K.
\newblock Sketch-based manga retrieval using manga109 dataset.
\newblock \emph{Multimedia Tools and Applications}, 76\penalty0 (20):\penalty0
  21811--21838, 2017.

\bibitem[Min et~al.(2022)Min, Lyu, Holtzman, Artetxe, Lewis, Hajishirzi, and
  Zettlemoyer]{min2022rethinking}
Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., and
  Zettlemoyer, L.
\newblock Rethinking the role of demonstrations: What makes in-context learning
  work?
\newblock \emph{arXiv preprint arXiv:2202.12837}, 2022.

\bibitem[Potlapalli et~al.(2023)Potlapalli, Zamir, Khan, and Khan]{PromptIR}
Potlapalli, V., Zamir, S.~W., Khan, S., and Khan, F.~S.
\newblock Promptir: Prompting for all-in-one blind image restoration.
\newblock \emph{arXiv preprint arXiv:2306.13090}, 2023.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{GPT2}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Richardson(1972)]{richardson1972bayesian}
Richardson, W.~H.
\newblock Bayesian-based iterative method of image restoration.
\newblock \emph{JoSA}, 62\penalty0 (1):\penalty0 55--59, 1972.

\bibitem[Sun et~al.(2023)Sun, Chen, Wang, Wang, and Li]{sun2023exploring}
Sun, Y., Chen, Q., Wang, J., Wang, J., and Li, Z.
\newblock Exploring effective factors for improving visual in-context learning.
\newblock \emph{arXiv preprint arXiv:2304.04748}, 2023.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Wang, Dong, Xu, Yang, An, and
  Guo]{DASR}
Wang, L., Wang, Y., Dong, X., Xu, Q., Yang, J., An, W., and Guo, Y.
\newblock Unsupervised degradation representation learning for blind
  super-resolution.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10581--10590, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Dai, Chen, Huang, Li, Zhu, Hu,
  Lu, Lu, Li, et~al.]{InternImage}
Wang, W., Dai, J., Chen, Z., Huang, Z., Li, Z., Zhu, X., Hu, X., Lu, T., Lu,
  L., Li, H., et~al.
\newblock Internimage: Exploring large-scale vision foundation models with
  deformable convolutions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  14408--14419, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Xie, Dong, and Shan]{RealESRGAN}
Wang, X., Xie, L., Dong, C., and Shan, Y.
\newblock Real-esrgan: Training real-world blind super-resolution with pure
  synthetic data.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  1905--1914, 2021{\natexlab{b}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Wang, Cao, Shen, and
  Huang]{Painter}
Wang, X., Wang, W., Cao, Y., Shen, C., and Huang, T.
\newblock Images speak in images: A generalist painter for in-context visual
  learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  6830--6839, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Li, Li, He, Huang, Zhao, Zhang,
  Xu, Liu, Wang, et~al.]{InternVideo}
Wang, Y., Li, K., Li, Y., He, Y., Huang, B., Zhao, Z., Zhang, H., Xu, J., Liu,
  Y., Wang, Z., et~al.
\newblock Internvideo: General video foundation models via generative and
  discriminative learning.
\newblock \emph{arXiv preprint arXiv:2212.03191}, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Cun, Bao, Zhou, Liu, and
  Li]{Uformer}
Wang, Z., Cun, X., Bao, J., Zhou, W., Liu, J., and Li, H.
\newblock Uformer: A general u-shaped transformer for image restoration.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  17683--17693, 2022{\natexlab{b}}.

\bibitem[Wei et~al.(2018)Wei, Wang, Yang, and Liu]{LOL}
Wei, C., Wang, W., Yang, W., and Liu, J.
\newblock Deep retinex decomposition for low-light enhancement.
\newblock \emph{arXiv preprint arXiv:1808.04560}, 2018.

\bibitem[Wei et~al.(2023)Wei, Wei, Tay, Tran, Webson, Lu, Chen, Liu, Huang,
  Zhou, et~al.]{wei2023larger}
Wei, J., Wei, J., Tay, Y., Tran, D., Webson, A., Lu, Y., Chen, X., Liu, H.,
  Huang, D., Zhou, D., et~al.
\newblock Larger language models do in-context learning differently.
\newblock \emph{arXiv preprint arXiv:2303.03846}, 2023.

\bibitem[Xu et~al.(2011)Xu, Lu, Xu, and Jia]{xu2011image}
Xu, L., Lu, C., Xu, Y., and Jia, J.
\newblock Image smoothing via l 0 gradient minimization.
\newblock In \emph{Proceedings of the 2011 SIGGRAPH Asia conference}, pp.\
  1--12, 2011.

\bibitem[Yang et~al.(2023)Yang, Gao, Li, Gao, Wang, and Zheng]{TAM}
Yang, J., Gao, M., Li, Z., Gao, S., Wang, F., and Zheng, F.
\newblock Track anything: Segment anything meets videos.
\newblock \emph{arXiv preprint arXiv:2304.11968}, 2023.

\bibitem[Yu et~al.(2023)Yu, Feng, Feng, Liu, Jin, Zeng, and Chen]{IAM}
Yu, T., Feng, R., Feng, R., Liu, J., Jin, X., Zeng, W., and Chen, Z.
\newblock Inpaint anything: Segment anything meets image inpainting.
\newblock \emph{arXiv preprint arXiv:2304.06790}, 2023.

\bibitem[Zamir et~al.(2021)Zamir, Arora, Khan, Hayat, Khan, Yang, and
  Shao]{MPRNet}
Zamir, S.~W., Arora, A., Khan, S., Hayat, M., Khan, F.~S., Yang, M.-H., and
  Shao, L.
\newblock Multi-stage progressive image restoration.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  14821--14831, 2021.

\bibitem[Zamir et~al.(2022)Zamir, Arora, Khan, Hayat, Khan, and
  Yang]{Restormer}
Zamir, S.~W., Arora, A., Khan, S., Hayat, M., Khan, F.~S., and Yang, M.-H.
\newblock Restormer: Efficient transformer for high-resolution image
  restoration.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  5728--5739, 2022.

\bibitem[Zeyde et~al.(2010)Zeyde, Elad, and Protter]{Set14}
Zeyde, R., Elad, M., and Protter, M.
\newblock On single image scale-up using sparse-representations.
\newblock In \emph{International conference on curves and surfaces}, pp.\
  711--730. Springer, 2010.

\bibitem[Zhang et~al.(2017)Zhang, Zuo, Chen, Meng, and Zhang]{DNCNN}
Zhang, K., Zuo, W., Chen, Y., Meng, D., and Zhang, L.
\newblock Beyond a gaussian denoiser: Residual learning of deep cnn for image
  denoising.
\newblock \emph{IEEE transactions on image processing}, 26\penalty0
  (7):\penalty0 3142--3155, 2017.

\bibitem[Zhang et~al.(2021)Zhang, Liang, Van~Gool, and Timofte]{BSRGAN}
Zhang, K., Liang, J., Van~Gool, L., and Timofte, R.
\newblock Designing a practical degradation model for deep blind image
  super-resolution.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  4791--4800, 2021.

\bibitem[Zhang et~al.(2023)Zhang, Zhou, and Liu]{zhang2023makes}
Zhang, Y., Zhou, K., and Liu, Z.
\newblock What makes good examples for visual in-context learning?
\newblock \emph{arXiv preprint arXiv:2301.13670}, 2023.

\end{thebibliography}
