@article{russo2013eluder,
  title={Eluder dimension and the sample complexity of optimistic exploration},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@article{he2022nearly,
  title={Nearly Optimal Algorithms for Linear Contextual Bandits with Adversarial Corruptions},
  author={He, Jiafan and Zhou, Dongruo and Zhang, Tong and Gu, Quanquan},
  journal={arXiv preprint arXiv:2205.06811},
  year={2022}
}

@article{yang2020provably,
  title={Provably efficient reinforcement learning with kernel and neural function approximations},
  author={Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13903--13916},
  year={2020}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@article{wang2020reinforcement,
  title={Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension},
  author={Wang, Ruosong and Salakhutdinov, Russ R and Yang, Lin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6123--6135},
  year={2020}
}

@inproceedings{bogunovic2021stochastic,
  title={Stochastic linear bandits robust to adversarial attacks},
  author={Bogunovic, Ilija and Losalka, Arpan and Krause, Andreas and Scarlett, Jonathan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={991--999},
  year={2021},
  organization={PMLR}
}

@article{gentile2022achieving,
  title={Achieving Minimax Rates in Pool-Based Batch Active Learning},
  author={Gentile, Claudio and Wang, Zhilei and Zhang, Tong},
  journal={arXiv preprint arXiv:2202.05448},
  year={2022}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}
@InProceedings{jiang@2017,
  title = 	 {Contextual Decision Processes with low {B}ellman rank are {PAC}-Learnable},
  author =       {Nan Jiang and Akshay Krishnamurthy and Alekh Agarwal and John Langford and Robert E. Schapire},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1704--1713},
  year = 	 {2017},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR}
}


@article{dann2021provably,
  title={A provably efficient model-free posterior sampling method for episodic reinforcement learning},
  author={Dann, Christoph and Mohri, Mehryar and Zhang, Tong and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12040--12051},
  year={2021}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@inproceedings{zhou2021nearly,
  title={Nearly minimax optimal reinforcement learning for linear mixture markov decision processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  booktitle={Conference on Learning Theory},
  pages={4532--4576},
  year={2021},
  organization={PMLR}
}

@inproceedings{huang2022near,
  url = {https://arxiv.org/abs/2206.11489},
  author = {Hu, Pihe and Chen, Yu and Huang, Longbo},
  title = {Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation},
  publisher = {arXiv},
  year = {2022},
}

@article{azuma1967weighted,
  title={Weighted sums of certain dependent random variables},
  author={Azuma, Kazuoki},
  journal={Tohoku Mathematical Journal, Second Series},
  volume={19},
  number={3},
  pages={357--367},
  year={1967},
  publisher={Mathematical Institute, Tohoku University}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{eykholt2018robust,
  title={Robust physical-world attacks on deep learning visual classification},
  author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1625--1634},
  year={2018}
}

@inproceedings{deshpande2012linear,
  title={Linear bandits in high dimension and recommendation systems},
  author={Deshpande, Yash and Montanari, Andrea},
  booktitle={2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={1750--1754},
  year={2012},
  organization={IEEE}
}

@article{krishnamurthy2016pac,
  title={PAC reinforcement learning with rich observations},
  author={Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@inproceedings{weisz2021exponential,
  title={Exponential lower bounds for planning in mdps with linearly-realizable optimal action-value functions},
  author={Weisz, Gell{\'e}rt and Amortila, Philip and Szepesv{\'a}ri, Csaba},
  booktitle={Algorithmic Learning Theory},
  pages={1237--1264},
  year={2021},
  organization={PMLR}
}

@article{kong2021online,
  title={Online sub-sampling for reinforcement learning with general function approximation},
  author={Kong, Dingwen and Salakhutdinov, Ruslan and Wang, Ruosong and Yang, Lin F},
  journal={arXiv preprint arXiv:2106.07203},
  year={2021}
}

@article{langford2007epoch,
  title={The epoch-greedy algorithm for multi-armed bandits with side information},
  author={Langford, John and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@inproceedings{foster2020beyond,
  title={Beyond ucb: Optimal and efficient contextual bandits with regression oracles},
  author={Foster, Dylan and Rakhlin, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={3199--3210},
  year={2020},
  organization={PMLR}
}
@inproceedings{agarwal2012contextual,
  title={Contextual bandit learning with predictable rewards},
  author={Agarwal, Alekh and Dud{\'\i}k, Miroslav and Kale, Satyen and Langford, John and Schapire, Robert},
  booktitle={Artificial Intelligence and Statistics},
  pages={19--26},
  year={2012},
  organization={PMLR}
}

@inproceedings{lykouris2018stochastic,
  title={Stochastic bandits robust to adversarial corruptions},
  author={Lykouris, Thodoris and Mirrokni, Vahab and Paes Leme, Renato},
  booktitle={Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={114--122},
  year={2018}
}

@article{zhao2021linear,
  title={Linear contextual bandits with adversarial corruptions},
  author={Zhao, Heyang and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2110.12615},
  year={2021}
}

@inproceedings{wei2022model,
  title={A model selection approach for corruption robust reinforcement learning},
  author={Wei, Chen-Yu and Dann, Christoph and Zimmert, Julian},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={1043--1096},
  year={2022},
  organization={PMLR}
}

@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv preprint arXiv:1011.3027},
  year={2010}
}


@inproceedings{gupta2019better,
  title={Better algorithms for stochastic bandits with adversarial corruptions},
  author={Gupta, Anupam and Koren, Tomer and Talwar, Kunal},
  booktitle={Conference on Learning Theory},
  pages={1562--1578},
  year={2019},
  organization={PMLR}
}

@article{li2019stochastic,
  title={Stochastic linear optimization with adversarial corruption},
  author={Li, Yingkai and Lou, Edmund Y and Shan, Liren},
  journal={arXiv preprint arXiv:1909.02109},
  year={2019}
}

@inproceedings{lee2021achieving,
  title={Achieving near instance-optimality and minimax-optimality in stochastic and adversarial linear bandits simultaneously},
  author={Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu and Zhang, Mengxiao and Zhang, Xiaojin},
  booktitle={International Conference on Machine Learning},
  pages={6142--6151},
  year={2021},
  organization={PMLR}
}


@inproceedings{ding2022robust,
  title={Robust stochastic linear contextual bandits under adversarial attacks},
  author={Ding, Qin and Hsieh, Cho-Jui and Sharpnack, James},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={7111--7123},
  year={2022},
  organization={PMLR}
}

@inproceedings{neu2010online,
  title={The Online Loop-free Stochastic Shortest-Path Problem.},
  author={Neu, Gergely and Gy{\"o}rgy, Andr{\'a}s and Szepesv{\'a}ri, Csaba and others},
  booktitle={COLT},
  volume={2010},
  pages={231--243},
  year={2010},
  organization={Citeseer}
}

@inproceedings{jin2020learning,
  title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4860--4869},
  year={2020},
  organization={PMLR}
}


@article{jin2020simultaneously,
  title={Simultaneously learning stochastic and adversarial episodic mdps with known transition},
  author={Jin, Tiancheng and Luo, Haipeng},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16557--16566},
  year={2020}
}

@inproceedings{chen2021finding,
  title={Finding the stochastic shortest path with low regret: The adversarial cost and unknown transition case},
  author={Chen, Liyu and Luo, Haipeng},
  booktitle={International Conference on Machine Learning},
  pages={1651--1660},
  year={2021},
  organization={PMLR}
}


@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22931--22942},
  year={2021}
}

@article{zhang2022feel,
  title={Feel-good thompson sampling for contextual bandits and reinforcement learning},
  author={Zhang, Tong},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={4},
  number={2},
  pages={834--857},
  year={2022},
  publisher={SIAM}
}

@inproceedings{wu2021reinforcement,
  title={On reinforcement learning with adversarial corruption and its application to block mdp},
  author={Wu, Tianhao and Yang, Yunchang and Du, Simon and Wang, Liwei},
  booktitle={International Conference on Machine Learning},
  pages={11296--11306},
  year={2021},
  organization={PMLR}
}

@article{osband2014model,
  title={Model-based reinforcement learning and the eluder dimension},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@inproceedings{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={5478--5486},
  year={2019},
  organization={PMLR}
}

@article{rosenberg2020stochastic,
  title={Stochastic shortest path with adversarially changing costs},
  author={Rosenberg, Aviv and Mansour, Yishay},
  journal={arXiv preprint arXiv:2006.11561},
  year={2020}
}

@article{foster2020adapting,
  title={Adapting to misspecification in contextual bandits},
  author={Foster, Dylan J and Gentile, Claudio and Mohri, Mehryar and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11478--11489},
  year={2020}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@Book{TZ23-lt,
  author =       {Tong Zhang},
  title =        {Mathematical Analysis of Machine Learning Algorithms},
  publisher =    {Cambridge University Press},
  year =         2023,
  url = {http://tongzhang-ml.org/lt-book.html},
  note =         {in press, also available as \url{http://tongzhang-ml.org/lt-book.html}}
  }

  @book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}

@misc{ye2022corruptionrobust,
      title={Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes}, 
      author={Chenlu Ye and Wei Xiong and Quanquan Gu and Tong Zhang},
      year={2022},
      eprint={2212.05949},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{gine2006concentration,
  title={Concentration inequalities and asymptotic results for ratio type empirical processes},
  author={Gin{\'e}, Evarist and Koltchinskii, Vladimir},
  year={2006}
}


@article{ghasemipour2022so,
  title={Why so pessimistic? estimating uncertainties for offline rl through ensembles, and why their independence matters},
  author={Ghasemipour, Kamyar and Gu, Shixiang Shane and Nachum, Ofir},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18267--18281},
  year={2022}
}


@inproceedings{yangrorl,
  title={RORL: Robust Offline Reinforcement Learning via Conservative Smoothing},
  author={Yang, Rui and Bai, Chenjia and Ma, Xiaoteng and Wang, Zhaoran and Zhang, Chongjie and Han, Lei},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}


@article{zhang2020robust,
  title={Robust deep reinforcement learning against adversarial perturbations on state observations},
  author={Zhang, Huan and Chen, Hongge and Xiao, Chaowei and Li, Bo and Liu, Mingyan and Boning, Duane and Hsieh, Cho-Jui},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21024--21037},
  year={2020}
}


@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified q-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}

@inproceedings{zhang2022corruption,
  title={Corruption-robust offline reinforcement learning},
  author={Zhang, Xuezhou and Chen, Yiding and Zhu, Xiaojin and Sun, Wen},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5757--5773},
  year={2022},
  organization={PMLR}
}

@inproceedings{wucopa,
  title={COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks},
  author={Wu, Fan and Li, Linyi and Zhang, Huan and Kailkhura, Bhavya and Kenthapadi, Krishnaram and Zhao, Ding and Li, Bo},
  booktitle={International Conference on Learning Representations},
  year={2022},
}


@inproceedings{behzadan2018mitigation,
  title={Mitigation of policy manipulation attacks on deep q-networks with parameter-space noise},
  author={Behzadan, Vahid and Munir, Arslan},
  booktitle={Computer Safety, Reliability, and Security: SAFECOMP 2018 Workshops, ASSURE, DECSoS, SASSUR, STRIVE, and WAISE, V{\"a}ster{\aa}s, Sweden, September 18, 2018, Proceedings 37},
  pages={406--417},
  year={2018},
  organization={Springer}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@inproceedings{zhong2022pessimistic,
  title={Pessimistic minimax value iteration: Provably efficient equilibrium learning from offline datasets},
  author={Zhong, Han and Xiong, Wei and Tan, Jiyuan and Wang, Liwei and Zhang, Tong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={International Conference on Machine Learning},
  pages={27117--27142},
  year={2022},
  organization={PMLR}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11702--11716},
  year={2021}
}

@article{bai2022pessimistic,
  title={Pessimistic bootstrapping for uncertainty-driven offline reinforcement learning},
  author={Bai, Chenjia and Wang, Lingxiao and Yang, Zhuoran and Deng, Zhihong and Garg, Animesh and Liu, Peng and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2202.11566},
  year={2022}
}

@article{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{lykouris2021corruption,
  title={Corruption-robust exploration in episodic reinforcement learning},
  author={Lykouris, Thodoris and Simchowitz, Max and Slivkins, Alex and Sun, Wen},
  booktitle={Conference on Learning Theory},
  pages={3242--3245},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2021improved,
  title={Improved corruption robust algorithms for episodic reinforcement learning},
  author={Chen, Yifang and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={1561--1570},
  year={2021},
  organization={PMLR}
}

@inproceedings{wang2018supervised,
  title={Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation},
  author={Wang, Lu and Zhang, Wei and He, Xiaofeng and Zha, Hongyuan},
  booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={2447--2456},
  year={2018}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13626--13640},
  year={2021}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={6683--6694},
  year={2021}
}

@article{yin2021towards,
  title={Towards instance-optimal offline reinforcement learning with pessimism},
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={4065--4078},
  year={2021}
}

@article{uehara2021pessimistic,
  title={Pessimistic model-based offline reinforcement learning under partial coverage},
  author={Uehara, Masatoshi and Sun, Wen},
  journal={arXiv preprint arXiv:2107.06226},
  year={2021}
}

@article{neff2016talking,
  title={Talking to bots: Symbiotic agency and the case of Tay},
  author={Neff, Gina},
  journal={International Journal of Communication},
  year={2016},
  publisher={University of Southern California, Annenberg School for Communication~â€¦}
}

@article{du2023guiding,
  title={Guiding Pretraining in Reinforcement Learning with Large Language Models},
  author={Du, Yuqing and Watkins, Olivia and Wang, Zihan and Colas, C{\'e}dric and Darrell, Trevor and Abbeel, Pieter and Gupta, Abhishek and Andreas, Jacob},
  journal={arXiv preprint arXiv:2302.06692},
  year={2023}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{liu2017deep,
  title={Deep reinforcement learning for dynamic treatment regimes on medical registry data},
  author={Liu, Ying and Logan, Brent and Liu, Ning and Xu, Zhiyuan and Tang, Jian and Wang, Yangzhi},
  booktitle={2017 IEEE international conference on healthcare informatics (ICHI)},
  pages={380--385},
  year={2017},
  organization={IEEE}
}

@article{foster2021statistical,
  title={The statistical complexity of interactive decision making},
  author={Foster, Dylan J and Kakade, Sham M and Qian, Jian and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2112.13487},
  year={2021}
}

@article{zhong2022posterior,
  title={A posterior sampling framework for interactive decision making},
  author={Zhong, Han and Xiong, Wei and Zheng, Sirui and Wang, Liwei and Wang, Zhaoran and Yang, Zhuoran and Zhang, Tong},
  journal={arXiv preprint arXiv:2211.01962},
  year={2022}
}

@article{wang2020statistical,
  title={What are the statistical limits of offline RL with linear function approximation?},
  author={Wang, Ruosong and Foster, Dean P and Kakade, Sham M},
  journal={arXiv preprint arXiv:2010.11895},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  pages={389--434},
  year={2012},
  publisher={Springer}
}

@article{zhou2022computationally,
  title={Computationally efficient horizon-free reinforcement learning for linear mixture mdps},
  author={Zhou, Dongruo and Gu, Quanquan},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36337--36349},
  year={2022}
}

@article{xiong2022nearly,
  title={Nearly minimax optimal offline reinforcement learning with linear function approximation: Single-agent mdp and markov game},
  author={Xiong, Wei and Zhong, Han and Shi, Chengshuai and Shen, Cong and Wang, Liwei and Zhang, Tong},
  journal={arXiv preprint arXiv:2205.15512},
  year={2022}
}

@article{kang2023robust,
  title={Robust Lipschitz Bandits to Adversarial Corruptions},
  author={Kang, Yue and Hsieh, Cho-Jui and Lee, Thomas},
  journal={arXiv preprint arXiv:2305.18543},
  year={2023}
}

@article{ma2019policy,
  title={Policy poisoning in batch reinforcement learning and control},
  author={Ma, Yuzhe and Zhang, Xuezhou and Sun, Wen and Zhu, Jerry},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{zhang2020adaptive,
  title={Adaptive reward-poisoning attacks against reinforcement learning},
  author={Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish and Zhu, Xiaojin},
  booktitle={International Conference on Machine Learning},
  pages={11225--11234},
  year={2020},
  organization={PMLR}
}

@inproceedings{yang2023essential,
  title={What is essential for unseen goal generalization of offline goal-conditioned RL?},
  author={Yang, Rui and Yong, Lin and Ma, Xiaoteng and Hu, Hao and Zhang, Chongjie and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={39543--39571},
  year={2023},
  organization={PMLR}
}

@article{sun2022exploit,
  title={Exploit Reward Shifting in Value-Based Deep-RL: Optimistic Curiosity-Based Exploration and Conservative Exploitation via Linear Reward Shaping},
  author={Sun, Hao and Han, Lei and Yang, Rui and Ma, Xiaoteng and Guo, Jian and Zhou, Bolei},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={37719--37734},
  year={2022}
}

@article{sun2022daux,
  title={Daux: a density-based approach for uncertainty explanations},
  author={Sun, Hao and van Breugel, Boris and Crabbe, Jonathan and Seedat, Nabeel and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2207.05161},
  year={2022}
}

@inproceedings{
tarasov2022corl,
  title={{CORL}: Research-oriented Deep Offline Reinforcement Learning Library},
  author={Denis Tarasov and Alexander Nikulin and Dmitry Akimov and Vladislav Kurenkov and Sergey Kolesnikov},
  booktitle={3rd Offline RL Workshop: Offline RL as a ''Launchpad''},
  year={2022},
  url={https://openreview.net/forum?id=SyAS49bBcv}
}


@inproceedings{chen2022general,
  title={A general framework for sample-efficient function approximation in reinforcement learning},
  author={Chen, Zixiang and Li, Chris Junchi and Yuan, Angela and Gu, Quanquan and Jordan, Michael I},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{deng2023uncertainty,
  title={Uncertainty estimation by fisher information-based evidential deep learning},
  author={Deng, Danruo and Chen, Guangyong and Yu, Yang and Liu, Furui and Heng, Pheng-Ann},
  journal={arXiv preprint arXiv:2303.02045},
  year={2023}
}

@article{wu2021uncertainty,
  title={Uncertainty weighted actor-critic for offline reinforcement learning},
  author={Wu, Yue and Zhai, Shuangfei and Srivastava, Nitish and Susskind, Joshua and Zhang, Jian and Salakhutdinov, Ruslan and Goh, Hanlin},
  journal={arXiv preprint arXiv:2105.08140},
  year={2021}
}

@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}