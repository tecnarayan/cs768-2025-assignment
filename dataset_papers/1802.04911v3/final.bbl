\begin{thebibliography}{10}

\bibitem{agrawal1993cutting}
Ajit Agrawal, Philip Klein, and R~Ravi.
\newblock Cutting down on fill using nested dissection: Provably good
  elimination orderings.
\newblock In {\em Graph Theory and Sparse Matrix Computation}, pages 31--55.
  Springer, 1993.

\bibitem{Andersen2010}
Martin~S Andersen, Joachim Dahl, and Lieven Vandenberghe.
\newblock Implementation of nonsymmetric interior-point methods for linear
  optimization over sparse matrix cones.
\newblock {\em Mathematical Programming Computation}, 2(3):167--201, 2010.

\bibitem{andersen2013cvxopt}
Martin~S Andersen, Joachim Dahl, and Lieven Vandenberghe.
\newblock {CVXOPT: A Python package for convex optimization}.
\newblock {\em Available at cvxopt. org}, 54, 2013.

\bibitem{andersen2013logarithmic}
Martin~S Andersen, Joachim Dahl, and Lieven Vandenberghe.
\newblock Logarithmic barriers for sparse matrix cones.
\newblock {\em Optimization Methods and Software}, 28(3):396--423, 2013.

\bibitem{Banerjee08}
Onureena Banerjee, Laurent~El Ghaoui, and Alexandre d'Aspremont.
\newblock Model selection through sparse maximum likelihood estimation for
  multivariate {Gaussian} or binary data.
\newblock {\em Journal of Machine learning research}, 9:485--516, 2008.

\bibitem{barrett1994templates}
Richard Barrett, Michael~W Berry, Tony~F Chan, James Demmel, June Donato, Jack
  Dongarra, Victor Eijkhout, Roldan Pozo, Charles Romine, and Henk Van~der
  Vorst.
\newblock {\em Templates for the solution of linear systems: building blocks
  for iterative methods}, volume~43.
\newblock Siam, 1994.

\bibitem{Croft10}
D.~Croft, G.~O'Kelly, G.~Wu, R.~Haw, M.~Gillespie, L.~Matthews, M.~Caudy,
  P.~Garapati, G.~Gopinath, B.~Jassal, and S.~Jupe.
\newblock Reactome: a database of reactions, pathways and biological processes.
\newblock {\em Nucleic acids research}, 39:691--697, 2010.

\bibitem{dahl2008covariance}
Joachim Dahl, Lieven Vandenberghe, and Vwani Roychowdhury.
\newblock Covariance selection for nonchordal graphs via chordal embedding.
\newblock {\em Optimization Methods \& Software}, 23(4):501--520, 2008.

\bibitem{Sparse11}
Timothy~A. Davis and Yifan Hu.
\newblock The university of florida sparse matrix collection.
\newblock {\em ACM Transactions on Mathematical Software (TOMS)}, 38(1):1,
  2011.

\bibitem{Steve93}
Steven~N. Durlauf.
\newblock Nonergodic economic growth.
\newblock {\em The Review of Economic Studies}, 60(2):349--366, 1993.

\bibitem{Ortega17}
Hilmi~E. Egilmez, Eduardo Pavez, and Antonio Ortega.
\newblock Graph learning from data under laplacian and structural constraints.
\newblock {\em IEEE Journal of Selected Topics in Signal Processing},
  11(6):825--841, 2017.

\bibitem{Salar17}
Salar Fattahi and Somayeh Sojoudi.
\newblock Graphical lasso and thresholding: Equivalence and closed-form
  solutions.
\newblock {\em \url{https://arxiv.org/abs/1708.09479}}, 2017.

\bibitem{Salar18}
Salar Fattahi, Richard~Y Zhang, and Somayeh Sojoudi.
\newblock Sparse inverse covariance estimation for chordal structures.
\newblock {\em \url{https://arxiv.org/abs/1711.09131}}, 2018.

\bibitem{Friedman08}
Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
\newblock Sparse inverse covariance estimation with the graphical lasso.
\newblock {\em Biostatistics}, 9(3):432--441, 2008.

\bibitem{george1989evolution}
Alan George and Joseph~WH Liu.
\newblock The evolution of the minimum degree ordering algorithm.
\newblock {\em Siam review}, 31(1):1--19, 1989.

\bibitem{gilbert1988some}
John~Russell Gilbert.
\newblock Some nested dissection order is nearly optimal.
\newblock {\em Information Processing Letters}, 26(6):325--328, 1988.

\bibitem{Maxim15}
Maxim Grechkin, Maryam Fazel, Daniela~M. Witten, and Su-In Lee.
\newblock Pathway graphical lasso.
\newblock {\em AAAI}, pages 2617--2623, 2015.

\bibitem{greenbaum1997iterative}
Anne Greenbaum.
\newblock {\em Iterative methods for solving linear systems}, volume~17.
\newblock Siam, 1997.

\bibitem{Honorio09}
Jean Honorio, Dimitris Samaras, Nikos Paragios, Rita Goldstein, and Luis~E.
  Ortiz.
\newblock Sparse and locally constant gaussian graphical models.
\newblock {\em Advances in Neural Information Processing Systems}, pages
  745--753, 2009.

\bibitem{Hsieh14}
C.~J. Hsieh, M.~A. Sustik, I.~S. Dhillon, and P.~Ravikumar.
\newblock Quic: quadratic approximation for sparse inverse covariance
  estimation.
\newblock {\em Journal of Machine Learning Research}, 15(1):2911--2947, 2014.

\bibitem{hsieh2013big}
Cho-Jui Hsieh, M{\'a}ty{\'a}s~A Sustik, Inderjit~S Dhillon, Pradeep~K
  Ravikumar, and Russell Poldrack.
\newblock Big \& quic: Sparse inverse covariance estimation for a million
  variables.
\newblock In {\em Advances in neural information processing systems}, pages
  3165--3173, 2013.

\bibitem{Huang10}
Junzhou Huang and Tong Zhang.
\newblock The benefit of group sparsity.
\newblock {\em The Annals of Statistics}, 38(4):1978--2004, 2010.

\bibitem{li2017inexact}
Jinchao Li, Martin~S Andersen, and Lieven Vandenberghe.
\newblock Inexact proximal newton methods for self-concordant functions.
\newblock {\em Mathematical Methods of Operations Research}, 85(1):19--41,
  2017.

\bibitem{Li94}
Stan~Z. Li.
\newblock Markov random field models in computer vision.
\newblock {\em European conference on computer vision}, pages 351--370, 1994.

\bibitem{Manning99}
Christopher~D. Manning and Hinrich Sch{\"u}tze.
\newblock {\em Foundations of statistical natural language processing}.
\newblock MIT press, 1999.

\bibitem{Mazumdar12}
Rahul Mazumder and Trevor Hastie.
\newblock Exact covariance thresholding into connected components for
  large-scale graphical lasso.
\newblock {\em Journal of Machine Learning Research}, 13:781--794, 2012.

\bibitem{Mein06}
Nicolai Meinshausen and Peter B{\"u}hlmann.
\newblock High-dimensional graphs and variable selection with the lasso.
\newblock {\em The annals of statistics}, 1436--1462, 2006.

\bibitem{Milanfar13}
Peyman Milanfar.
\newblock A tour of modern image filtering: New insights and methods, both
  practical and theoretical.
\newblock {\em IEEE Signal Processing Magazine}, 30(1):106--128, 2013.

\bibitem{Martin082}
Sahand Negahban and Martin~J. Wainwright.
\newblock Joint support recovery under high-dimensional scaling: Benefits and
  perils of $l_{1,\infty}$-regularization.
\newblock {\em Proceedings of the 21st International Conference on Neural
  Information Processing Systems}, pages 1161--1168, 2008.

\bibitem{nesterov2013introductory}
Yurii Nesterov.
\newblock {\em Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2013.

\bibitem{Martin08}
Guillaume Obozinski, Martin~J. Wainwright, and Michael~I. Jordan.
\newblock Union support recovery in high-dimensional multivariate regression.
\newblock {\em Communication, Control, and Computing, 2008 46th Annual Allerton
  Conference on}, pages 21--26, 2008.

\bibitem{oztoprak2012newton}
Figen Oztoprak, Jorge Nocedal, Steven Rennie, and Peder~A Olsen.
\newblock Newton-like methods for sparse inverse covariance estimation.
\newblock In {\em Advances in neural information processing systems}, pages
  755--763, 2012.

\bibitem{Park99}
Dongjoo Park and Laurence~R. Rilett.
\newblock Forecasting freeway link travel times with a multilayer feedforward
  neural network.
\newblock {\em Computer Aided Civil and Infrastructure Engineering},
  14(5):357--367, 1999.

\bibitem{Martin11}
P.~Ravikumar, M.~J. Wainwright, G.~Raskutti, and B.~Yu.
\newblock High-dimensional covariance estimation by minimizing $l_1$-penalized
  log-determinant divergence.
\newblock {\em Electronic Journal of Statistics}, 5:935--980, 2011.

\bibitem{rolfs2012iterative}
Benjamin Rolfs, Bala Rajaratnam, Dominique Guillot, Ian Wong, and Arian Maleki.
\newblock Iterative thresholding algorithm for sparse inverse covariance
  estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1574--1582, 2012.

\bibitem{rose1970triangulated}
Donald~J Rose.
\newblock Triangulated graphs and the elimination process.
\newblock {\em Journal of Mathematical Analysis and Applications},
  32(3):597--609, 1970.

\bibitem{Rothman08}
Adam~J. Rothman, Peter~J. Bickel, Elizaveta Levina, and Ji~Zhu.
\newblock Sparse permutation invariant covariance estimation.
\newblock {\em Electronic Journal of Statistics}, 2:494--515, 2008.

\bibitem{saad2003iterative}
Yousef Saad.
\newblock {\em Iterative methods for sparse linear systems}, volume~82.
\newblock Siam, 2003.

\bibitem{Sojoudi16}
Somayeh Sojoudi.
\newblock Equivalence of graphical lasso and thresholding for sparse graphs.
\newblock {\em Journal of Machine Learning Research}, 17(115):1--21, 2016.

\bibitem{treister2014block}
Eran Treister and Javier~S Turek.
\newblock A block-coordinate descent approach for large-scale sparse inverse
  covariance estimation.
\newblock In {\em Advances in neural information processing systems}, pages
  927--935, 2014.

\bibitem{vandenberghe2015chordal}
Lieven Vandenberghe, Martin~S Andersen, et~al.
\newblock Chordal graphs and semidefinite optimization.
\newblock {\em Foundations and Trends{\textregistered} in Optimization},
  1(4):241--433, 2015.

\bibitem{Martin09}
Martin~J Wainwright.
\newblock Sharp thresholds for high-dimensional and noisy sparsity recovery
  using $\ell _ {1} $-constrained quadratic programming (lasso).
\newblock {\em IEEE transactions on information theory}, 55(5):2183--2202,
  2009.

\bibitem{Yang14}
Eunho Yang, Aur{\'e}lie~C. Lozano, and Pradeep~K. Ravikumar.
\newblock Elementary estimators for graphical models.
\newblock {\em Advances in neural information processing systems}, pages
  2159--2167, 2014.

\bibitem{yannakakis1981computing}
Mihalis Yannakakis.
\newblock Computing the minimum fill-in is {NP}-complete.
\newblock {\em SIAM Journal on Algebraic Discrete Methods}, 2(1):77--79, 1981.

\bibitem{Ming07}
Ming Yuan and Yi~Lin.
\newblock Model selection and estimation in the {Gaussian} graphical model.
\newblock {\em Biometrika}, pages 19--35, 2007.

\end{thebibliography}
