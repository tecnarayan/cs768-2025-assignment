%%%% Introduction %%%%

% LLMs
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

% Image Models
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

% Intro imitation citations
@article{lynch2019play,
  title   = {Learning Latent Plans from Play},
  author  = {Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash
             and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  journal = {Conference on Robot Learning (CoRL)},
  year    = {2019},
  url     = {https://arxiv.org/abs/1903.01973},
  pdf     = {https://arxiv.org/pdf/1903.01973.pdf},
  biburl  = {https://github.com/sermanet/sermanet.github.io/blob/master/assets/bib/Lynch2019Play.bib},
}

@article{cui2022play,
  title={From play to policy: Conditional behavior generation from uncurated robot data},
  author={Cui, Zichen Jeff and Wang, Yibin and Muhammad, Nur and Pinto, Lerrel and others},
  journal={arXiv preprint arXiv:2210.10047},
  year={2022}
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{robomimic2021,
  title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
  author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Li Fei-Fei and Silvio Savarese and Yuke Zhu and Roberto Mart\'{i}n-Mart\'{i}n},
  booktitle={arXiv preprint arXiv:2108.03298},
  year={2021}
}

@article{yarats2022exorl,
  title={Don't Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning},
  author={Denis Yarats and David Brandfonbrener and Hao Liu and Michael Laskin and Pieter Abbeel and Alessandro Lazaric and Lerrel Pinto},
  journal={arXiv preprint arXiv:2201.13425},
  year={2022}
}

@inproceedings{emmons2022rvs,
    title={RvS: What is Essential for Offline {RL} via Supervised Learning?},
    author={Scott Emmons and Benjamin Eysenbach and Ilya Kostrikov and Sergey Levine},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=S874XAIpkR-}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{srivastava2019training,
  title={Training agents using upside-down reinforcement learning},
  author={Srivastava, Rupesh Kumar and Shyam, Pranav and Mutz, Filipe and Ja{\'s}kowski, Wojciech and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1912.02877},
  year={2019}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

% Intro reward difficulty
@inproceedings{
Zhu2020The,
title={The Ingredients of Real World Robotic Reinforcement Learning},
author={Henry Zhu and Justin Yu and Abhishek Gupta and Dhruv Shah and Kristian Hartikainen and Avi Singh and Vikash Kumar and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJe2syrtvS}
}

@article{hadfield2017inverse,
  title={Inverse reward design},
  author={Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart J and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{
pan2022the,
title={The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models},
author={Alexander Pan and Kush Bhatia and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=JYtwGwIL7ye}
}

@inproceedings{
nair2022rm,
title={R3M: A Universal Visual Representation for Robot Manipulation},
author={Suraj Nair and Aravind Rajeswaran and Vikash Kumar and Chelsea Finn and Abhinav Gupta},
booktitle={6th Annual Conference on Robot Learning},
year={2022},
url={https://openreview.net/forum?id=tGbpgz6yOrI}
}

@inproceedings{
radosavovic2022realworld,
title={Real-World Robot Learning with Masked Visual Pre-training},
author={Ilija Radosavovic and Tete Xiao and Stephen James and Pieter Abbeel and Jitendra Malik and Trevor Darrell},
booktitle={6th Annual Conference on Robot Learning},
year={2022},
url={https://openreview.net/forum?id=KWCZfuqshd}
}

@article{kumar2022offline,
  title={Offline Q-Learning on Diverse Multi-Task Data Both Scales And Generalizes},
  author={Kumar, Aviral and Agarwal, Rishabh and Geng, Xinyang and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2211.15144},
  year={2022}
}

@inproceedings{
lee2022multigame,
title={Multi-Game Decision Transformers},
author={Kuang-Huei Lee and Ofir Nachum and Sherry Yang and Lisa Lee and C. Daniel Freeman and Sergio Guadarrama and Ian Fischer and Winnie Xu and Eric Jang and Henryk Michalewski and Igor Mordatch},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=0gouO5saq6K}
}

@article{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{tian2020model,
  title={Model-Based Visual Planning with Self-Supervised Functional Distances},
  author={Tian, Stephen and Nair, Suraj and Ebert, Frederik and Dasari, Sudeep and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{jang2022bc,
  title={Bc-z: Zero-shot task generalization with robotic imitation learning},
  author={Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={991--1002},
  year={2022},
  organization={PMLR}
}

@inproceedings{rt12022arxiv,
    title={RT-1: Robotics Transformer for Real-World Control at Scale},
    author={Anthony	Brohan and  Noah Brown and  Justice Carbajal and  Yevgen Chebotar and  Joseph Dabis and  Chelsea Finn and  Keerthana Gopalakrishnan and  Karol Hausman and  Alex Herzog and  Jasmine Hsu and  Julian Ibarz and  Brian Ichter and  Alex Irpan and  Tomas Jackson and  Sally Jesmonth and  Nikhil Joshi and  Ryan Julian and  Dmitry Kalashnikov and  Yuheng Kuang and  Isabel Leal and  Kuang-Huei Lee and  Sergey Levine and  Yao Lu and  Utsav Malla and  Deeksha Manjunath and  Igor Mordatch and  Ofir Nachum and  Carolina Parada and  Jodilyn Peralta and  Emily Perez and  Karl Pertsch and  Jornell Quiambao and  Kanishka Rao and  Michael Ryoo and  Grecia Salazar and  Pannag Sanketi and  Kevin Sayed and  Jaspiar Singh and  Sumedh Sontakke and  Austin Stone and  Clayton Tan and  Huong Tran and  Vincent Vanhoucke and Steve Vega and  Quan Vuong and  Fei Xia and  Ted Xiao and  Peng Xu and  Sichun Xu and  Tianhe Yu and  Brianna Zitkovich},
    booktitle={arXiv preprint arXiv:2212.06817},
    year={2022}
}

@article{akgun2012keyframe,
  title={Keyframe-based learning from demonstration},
  author={Akgun, Baris and Cakmak, Maya and Jiang, Karl and Thomaz, Andrea L},
  journal={International Journal of Social Robotics},
  volume={4},
  number={4},
  pages={343--355},
  year={2012},
  publisher={Springer}
}

@inproceedings{
kostrikov2022offline,
title={Offline Reinforcement Learning with Implicit Q-Learning},
author={Ilya Kostrikov and Ashvin Nair and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=68n2s9ZJWF8}
}

@inproceedings{
ghosh2021learning,
title={Learning to Reach Goals via Iterated Supervised Learning},
author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rALA0Xo6yNJ}
}

@inproceedings{
yang2022rethinking,
title={Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline {RL}},
author={Rui Yang and Yiming Lu and Wenzhe Li and Hao Sun and Meng Fang and Yali Du and Xiu Li and Lei Han and Chongjie Zhang},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=KJztlfGPdwW}
}


@InProceedings{pmlr-v162-beliaev22a,
  title = 	 {Imitation Learning by Estimating Expertise of Demonstrators},
  author =       {Beliaev, Mark and Shih, Andy and Ermon, Stefano and Sadigh, Dorsa and Pedarsani, Ramtin},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {1732--1748},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/beliaev22a/beliaev22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/beliaev22a.html},
}


@inproceedings{
	garg2023extreme,
	title={Extreme Q-Learning: MaxEnt Reinforcement Learning Without Entropy},
	url = {https://arxiv.org/abs/2301.02328},
  	author = {Garg, Divyansh and Hejna, Joey and Geist, Matthieu and Ermon, Stefano},
booktitle={The Eleventh International Conference on Learning Representations },
  	year = {2023},
	}

@inproceedings{pertsch2021accelerating,
  title={Accelerating reinforcement learning with learned skill priors},
  author={Pertsch, Karl and Lee, Youngwoon and Lim, Joseph},
  booktitle={Conference on robot learning},
  pages={188--204},
  year={2021},
  organization={PMLR}
}

@book{ziebart2010modeling,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010},
  publisher={Carnegie Mellon University}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}


@article{
	AWRPeng19,
	author = {Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
	title = {Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
	journal = {CoRR},
	volume = {abs/1910.00177},
	year = {2019},
	url = {https://arxiv.org/abs/1910.00177},
	archivePrefix = {arXiv},
	eprint = {1910.00177},
	timestamp = {Tue, 01 October 2019 11:27:50 +0200},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-1802-09464,
  publtype={informal},
  author={Matthias Plappert and Marcin Andrychowicz and Alex Ray and Bob McGrew and Bowen Baker and Glenn Powell and Jonas Schneider and Josh Tobin and Maciek Chociej and Peter Welinder and Vikash Kumar and Wojciech Zaremba},
  title={Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},
  year={2018},
  cdate={1514764800000},
  journal={CoRR},
  volume={abs/1802.09464},
  url={http://arxiv.org/abs/1802.09464}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{wang2018exponentially,
  title={Exponentially weighted imitation learning for batched historical data},
  author={Wang, Qing and Xiong, Jiechao and Han, Lei and Liu, Han and Zhang, Tong and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={449--458},
  year={2017},
  organization={PMLR}
}

@article{ma2021offline,
  title={Offline Reinforcement Learning with Value-based Episodic Memory},
  author={Ma, Xiaoteng and Yang, Yiqin and Hu, Hao and Liu, Qihan and Yang, Jun and Zhang, Chongjie and Zhao, Qianchuan and Liang, Bin},
  journal={arXiv preprint arXiv:2110.09796},
  year={2021}
}

@article{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{bertsekas1991analysis,
  title={An analysis of stochastic shortest path problems},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  journal={Mathematics of Operations Research},
  volume={16},
  number={3},
  pages={580--595},
  year={1991},
  publisher={INFORMS}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@inproceedings{
ma2022offline,
title={Offline Goal-Conditioned Reinforcement Learning via \$f\$-Advantage Regression},
author={Yecheng Jason Ma and Jason Yan and Dinesh Jayaraman and Osbert Bastani},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=_h29VprPHD}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Ben and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={14783--14795},
  year={2020}
}

@article{li2020generalized,
  title={Generalized hindsight for reinforcement learning},
  author={Li, Alexander and Pinto, Lerrel and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7754--7767},
  year={2020}
}

@inproceedings{,
  title={C-Learning: Learning to Achieve Goals via Recursive Classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  volume={2},
  pages={1094--8},
  year={1993},
  organization={Citeseer}
}


@InProceedings{pmlr-v37-schaul15,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schaul15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schaul15.html},
  abstract = 	 {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, using parameters Î¸. In this paper we introduce universal value function approximators (UVFAs) V(s,g;theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.}
}

@inproceedings{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jacob and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan C and Finn, Chelsea and others},
  booktitle={International Conference on Machine Learning},
  pages={1518--1528},
  year={2021},
  organization={PMLR}
}

@inproceedings{eysenbach2020c,
  title={C-Learning: Learning to Achieve Goals via Recursive Classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{
belkhale2022plato,
title={{PLATO}: Predicting Latent Affordances Through Object-Centric Play},
author={Suneel Belkhale and Dorsa Sadigh},
booktitle={6th Annual Conference on Robot Learning},
year={2022},
url={https://openreview.net/forum?id=UAA5bNospA0}
}

@article{argall2009survey,
  title={A survey of robot learning from demonstration},
  author={Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal={Robotics and autonomous systems},
  volume={57},
  number={5},
  pages={469--483},
  year={2009},
  publisher={Elsevier}
}

@article{duan2017one,
  title={One-shot imitation learning},
  author={Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Jonathan Ho, OpenAI and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{gupta2020relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  booktitle={Conference on Robot Learning},
  pages={1025--1037},
  year={2020},
  organization={PMLR}
}

@article{ding2019goal,
  title={Goal-conditioned imitation learning},
  author={Ding, Yiming and Florensa, Carlos and Abbeel, Pieter and Phielipp, Mariano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{rosetelatent,
  title={Latent Plans for Task-Agnostic Offline Reinforcement Learning},
  author={Rosete-Beas, Erick and Mees, Oier and Kalweit, Gabriel and Boedecker, Joschka and Burgard, Wolfram},
  booktitle={6th Annual Conference on Robot Learning}
}

@inproceedings{fanggeneralization,
  title={Generalization with Lossy Affordances: Leveraging Broad Offline Data for Learning Visuomotor Tasks},
  author={Fang, Kuan and Yin, Patrick and Nair, Ashvin and Walke, Homer Rich and Yan, Gengchen and Levine, Sergey},
  booktitle={6th Annual Conference on Robot Learning}
}

@inproceedings{yarats2021improving,
  title={Improving sample efficiency in model-free reinforcement learning from images},
  author={Yarats, Denis and Zhang, Amy and Kostrikov, Ilya and Amos, Brandon and Pineau, Joelle and Fergus, Rob},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={10674--10681},
  year={2021}
}

@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@inproceedings{NEURIPS2021_670e8a43,
 author = {Zhang, Songyuan and Cao, Zhangjie and Sadigh, Dorsa and Sui, Yanan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {12340--12350},
 publisher = {Curran Associates, Inc.},
 title = {Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality},
 url = {https://proceedings.neurips.cc/paper/2021/file/670e8a43b246801ca1eaca97b3e19189-Paper.pdf},
 volume = {34},
 year = {2021}
}


@article{cao2021learning,
  title={Learning from imperfect demonstrations from agents with varying dynamics},
  author={Cao, Zhangjie and Sadigh, Dorsa},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={5231--5238},
  year={2021},
  publisher={IEEE}
}

@inproceedings{
fujimoto2021a,
title={A Minimalist Approach to Offline Reinforcement Learning},
author={Scott Fujimoto and Shixiang Gu},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=Q32U7dzWXpc}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{
fu2021benchmarks,
title={Benchmarks for Deep Off-Policy Evaluation},
author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and ziyu wang and Alexander Novikov and Mengjiao Yang and Michael R Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=kWSeGEeHvF8}
}

@inproceedings{
Hartikainen2020Dynamical,
title={Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery},
author={Kristian Hartikainen and Xinyang Geng and Tuomas Haarnoja and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1lmhaVtvr}
}