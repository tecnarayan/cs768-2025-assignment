\begin{thebibliography}{10}

\bibitem{lwl}
C~Atkeson, A~Moore, and S~Schaal.
\newblock Locally weighted learning.
\newblock {\em Artificial Intelligence Review}, 1997.

\bibitem{montreal}
D~Bahdanau, K~Cho, and Y~Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em ICLR}, 2014.

\bibitem{donahue2014decaf}
J~Donahue, Y~Jia, O~Vinyals, J~Hoffman, N~Zhang, E~Tzeng, and T~Darrell.
\newblock Decaf: A deep convolutional activation feature for generic visual
  recognition.
\newblock In {\em ICML}, 2014.

\bibitem{ntm}
A~Graves, G~Wayne, and I~Danihelka.
\newblock Neural turing machines.
\newblock {\em arXiv preprint arXiv:1410.5401}, 2014.

\bibitem{hermann2015teaching}
K~Hermann, T~Kocisky, E~Grefenstette, L~Espeholt, W~Kay, M~Suleyman, and
  P~Blunsom.
\newblock Teaching machines to read and comprehend.
\newblock In {\em NIPS}, 2015.

\bibitem{hill2015goldilocks}
F~Hill, A~Bordes, S~Chopra, and J~Weston.
\newblock The goldilocks principle: Reading children's books with explicit
  memory representations.
\newblock {\em arXiv preprint arXiv:1511.02301}, 2015.

\bibitem{hinton2012deep}
G~Hinton et~al.
\newblock Deep neural networks for acoustic modeling in speech recognition: The
  shared views of four research groups.
\newblock {\em Signal Processing Magazine, IEEE}, 2012.

\bibitem{hochreiter}
S~Hochreiter and J~Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 1997.

\bibitem{hoffer2015deep}
E~Hoffer and N~Ailon.
\newblock Deep metric learning using triplet network.
\newblock {\em Similarity-Based Pattern Recognition}, 2015.

\bibitem{ioffe2015batch}
S~Ioffe and C~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock {\em arXiv preprint arXiv:1502.03167}, 2015.

\bibitem{siamese}
G~Koch, R~Zemel, and R~Salakhutdinov.
\newblock Siamese neural networks for one-shot image recognition.
\newblock In {\em ICML Deep Learning workshop}, 2015.

\bibitem{krizhevsky2010convolutional}
A~Krizhevsky and G~Hinton.
\newblock Convolutional deep belief networks on cifar-10.
\newblock {\em Unpublished}, 2010.

\bibitem{krizhevsky2012imagenet}
A~Krizhevsky, I~Sutskever, and G~Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NIPS}, 2012.

\bibitem{omniglot}
BM~Lake, R~Salakhutdinov, J~Gross, and J~Tenenbaum.
\newblock One shot learning of simple visual concepts.
\newblock In {\em CogSci}, 2011.

\bibitem{marcus1993building}
MP~Marcus, MA~Marcinkiewicz, and B~Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock {\em Computational linguistics}, 1993.

\bibitem{mikolov2010recurrent}
T~Mikolov, M~Karafi{\'a}t, L~Burget, J~Cernock{\`y}, and S~Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In {\em INTERSPEECH}, 2010.

\bibitem{norouzi2013zero}
M~Norouzi, T~Mikolov, S~Bengio, Y~Singer, J~Shlens, A~Frome, G~Corrado, and
  J~Dean.
\newblock Zero-shot learning by convex combination of semantic embeddings.
\newblock {\em arXiv preprint arXiv:1312.5650}, 2013.

\bibitem{nca}
S~Roweis, G~Hinton, and R~Salakhutdinov.
\newblock Neighbourhood component analysis.
\newblock {\em NIPS}, 2004.

\bibitem{ImageNet}
O~Russakovsky, J~Deng, H~Su, J~Krause, S~Satheesh, S~Ma, Z~Huang, A~Karpathy,
  A~Khosla, M~Bernstein, A~Berg, and L~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em IJCV}, 2015.

\bibitem{salakhutdinov2007learning}
R~Salakhutdinov and G~Hinton.
\newblock Learning a nonlinear embedding by preserving class neighbourhood
  structure.
\newblock In {\em AISTATS}, 2007.

\bibitem{mann}
A~Santoro, S~Bartunov, M~Botvinick, D~Wierstra, and T~Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In {\em ICML}, 2016.

\bibitem{simonyan2014very}
K~Simonyan and A~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{seq2seqilya}
I~Sutskever, O~Vinyals, and QV~Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em NIPS}, 2014.

\bibitem{szegedy2015going}
C~Szegedy, W~Liu, Y~Jia, P~Sermanet, S~Reed, D~Anguelov, D~Erhan, V~Vanhoucke,
  and A~Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em CVPR}, 2015.

\bibitem{szegedy2015rethinking}
C~Szegedy, V~Vanhoucke, S~Ioffe, J~Shlens, and Z~Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock {\em arXiv preprint arXiv:1512.00567}, 2015.

\bibitem{vinyals2015order}
O~Vinyals, S~Bengio, and M~Kudlur.
\newblock Order matters: Sequence to sequence for sets.
\newblock {\em arXiv preprint arXiv:1511.06391}, 2015.

\bibitem{ptrnets}
O~Vinyals, M~Fortunato, and N~Jaitly.
\newblock Pointer networks.
\newblock In {\em NIPS}, 2015.

\bibitem{weinberger2009distance}
K~Weinberger and L~Saul.
\newblock Distance metric learning for large margin nearest neighbor
  classification.
\newblock {\em JMLR}, 2009.

\bibitem{memnets}
J~Weston, S~Chopra, and A~Bordes.
\newblock Memory networks.
\newblock {\em ICLR}, 2014.

\bibitem{zaremba2014recurrent}
W~Zaremba, I~Sutskever, and O~Vinyals.
\newblock Recurrent neural network regularization.
\newblock {\em arXiv preprint arXiv:1409.2329}, 2014.

\end{thebibliography}
