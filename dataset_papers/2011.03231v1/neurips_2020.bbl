\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baumgartner et~al.(2020)Baumgartner, Zannettou, Keegan, Squire, and
  Blackburn]{baumgartner2020pushshift}
Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy
  Blackburn.
\newblock The pushshift reddit dataset.
\newblock \emph{arXiv preprint arXiv:2001.08435}, 2020.

\bibitem[Bayer and Osendorfer(2014)]{bayer2014learning}
Justin Bayer and Christian Osendorfer.
\newblock Learning stochastic recurrent networks.
\newblock \emph{arXiv preprint arXiv:1411.7610}, 2014.

\bibitem[Bhattacharjya et~al.(2018)Bhattacharjya, Subramanian, and
  Gao]{bhattacharjya2018proximal}
Debarun Bhattacharjya, Dharmashankar Subramanian, and Tian Gao.
\newblock Proximal graphical event models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8136--8145, 2018.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017variational}
David~M Blei, Alp Kucukelbir, and Jon~D McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, pages
  859--877, 2017.

\bibitem[Bowman et~al.(2016)Bowman, Vilnis, Vinyals, Dai, Jozefowicz, and
  Bengio]{bowman2016generating}
Samuel Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and
  Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock In \emph{Proceedings of The 20th SIGNLL Conference on Computational
  Natural Language Learning}, pages 10--21, 2016.

\bibitem[Celma(2010)]{Celma:Springer2010}
O.~Celma.
\newblock \emph{{Music Recommendation and Discovery in the Long Tail}}.
\newblock Springer, 2010.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Bahdanau, and
  Bengio]{cho2014properties}
Kyunghyun Cho, Bart van Merri{\"e}nboer, Dzmitry Bahdanau, and Yoshua Bengio.
\newblock On the properties of neural machine translation: Encoder--decoder
  approaches.
\newblock In \emph{Proceedings of {SSST}-8, Eighth Workshop on Syntax,
  Semantics and Structure in Statistical Translation}, pages 103--111.
  Association for Computational Linguistics, 2014.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{chua2018deep}
Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4754--4765, 2018.

\bibitem[Chung et~al.(2015)Chung, Kastner, Dinh, Goel, Courville, and
  Bengio]{chung2015recurrent}
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron~C Courville,
  and Yoshua Bengio.
\newblock A recurrent latent variable model for sequential data.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2980--2988, 2015.

\bibitem[Daley and Vere-Jones(2007)]{daley2007introduction}
Daryl~J Daley and David Vere-Jones.
\newblock \emph{An Introduction to the Theory of Point Processes: Volume II:
  Elementary Theory and Methods}.
\newblock Springer Science \& Business Media, 2007.

\bibitem[Denton and Fergus(2018)]{denton2018stochastic}
Emily Denton and Rob Fergus.
\newblock Stochastic video generation with a learned prior.
\newblock In \emph{International Conference on Machine Learning}, pages
  1174--1183, 2018.

\bibitem[Du et~al.(2015)Du, Farajtabar, Ahmed, Smola, and
  Song]{du2015dirichlet}
Nan Du, Mehrdad Farajtabar, Amr Ahmed, Alexander~J Smola, and Le~Song.
\newblock Dirichlet-hawkes processes with applications to clustering
  continuous-time document streams.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 219--228, 2015.

\bibitem[Du et~al.(2016)Du, Dai, Trivedi, Upadhyay, Gomez-Rodriguez, and
  Song]{du2016recurrent}
Nan Du, Hanjun Dai, Rakshit Trivedi, Utkarsh Upadhyay, Manuel Gomez-Rodriguez,
  and Le~Song.
\newblock Recurrent marked temporal point processes: Embedding event history to
  vector.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1555--1564, 2016.

\bibitem[Fu et~al.(2019)Fu, Li, Liu, Gao, Celikyilmaz, and
  Carin]{liu2019cyclical}
Hao Fu, Chunyuan Li, Xiaodong Liu, Jianfeng Gao, Asli Celikyilmaz, and Lawrence
  Carin.
\newblock Cyclical annealing schedule: A simple approach to mitigating {KL}
  vanishing.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 240--250. Association
  for Computational Linguistics, 2019.

\bibitem[Gan et~al.(2015)Gan, Li, Henao, Carlson, and Carin]{gan2015deep}
Zhe Gan, Chunyuan Li, Ricardo Henao, David~E Carlson, and Lawrence Carin.
\newblock Deep temporal sigmoid belief networks for sequence modeling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2467--2475, 2015.

\bibitem[Gunawardana et~al.(2011)Gunawardana, Meek, and
  Xu]{gunawardana2011model}
Asela Gunawardana, Christopher Meek, and Puyang Xu.
\newblock A model for temporal dependencies in event streams.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1962--1970, 2011.

\bibitem[Ha and Schmidhuber(2018)]{ha2018recurrent}
David Ha and J{\"u}rgen Schmidhuber.
\newblock Recurrent world models facilitate policy evolution.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2450--2462, 2018.

\bibitem[Hawkes(1971)]{hawkes1971spectra}
Alan~G Hawkes.
\newblock Spectra of some self-exciting and mutually exciting point processes.
\newblock \emph{Biometrika}, 58\penalty0 (1):\penalty0 83--90, 1971.

\bibitem[Higgins et~al.(2016)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2017beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2014)]{KW2014}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Leskovec and Krevl(2014)]{snapnets}
Jure Leskovec and Andrej Krevl.
\newblock {SNAP Datasets}: {Stanford} large network dataset collection.
\newblock \url{http://snap.stanford.edu/data}, 2014.

\bibitem[Li et~al.(2018)Li, Xiao, Zhu, Du, Xie, and Song]{li2018learning}
Shuang Li, Shuai Xiao, Shixiang Zhu, Nan Du, Yao Xie, and Le~Song.
\newblock Learning temporal point processes via reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10781--10791, 2018.

\bibitem[Li and Mandt(2018)]{yingzhen2018disentangled}
Yingzhen Li and Stephan Mandt.
\newblock Disentangled sequential autoencoder.
\newblock In \emph{International Conference on Machine Learning}, pages
  5670--5679, 2018.

\bibitem[Liang et~al.(2018)Liang, Krishnan, Hoffman, and
  Jebara]{liang2018variational}
Dawen Liang, Rahul~G Krishnan, Matthew~D Hoffman, and Tony Jebara.
\newblock Variational autoencoders for collaborative filtering.
\newblock In \emph{Proceedings of the 2018 World Wide Web Conference}, pages
  689--698, 2018.

\bibitem[Liniger(2009)]{liniger2009multivariate}
Thomas~Josef Liniger.
\newblock \emph{Multivariate Hawkes Processes}.
\newblock PhD thesis, ETH Zurich, 2009.

\bibitem[Lombardo et~al.(2019)Lombardo, Han, Schroers, and
  Mandt]{lombardo2019deep}
Salvator Lombardo, Jun Han, Christopher Schroers, and Stephan Mandt.
\newblock Deep generative video compression.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9283--9294, 2019.

\bibitem[Mei and Eisner(2017)]{mei2017neural}
Hongyuan Mei and Jason~M Eisner.
\newblock The neural hawkes process: A neurally self-modulating multivariate
  point process.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6754--6764, 2017.

\bibitem[Ni et~al.(2019)Ni, Li, and McAuley]{ni2019justifying}
Jianmo Ni, Jiacheng Li, and Julian McAuley.
\newblock Justifying recommendations using distantly-labeled reviews and
  fine-grained aspects.
\newblock In \emph{Proceedings of the EMNLP-IJCNLP Conference}, pages 188--197,
  2019.

\bibitem[Ogata(1981)]{ogata1981lewis}
Yosihiko Ogata.
\newblock On lewis' simulation method for point processes.
\newblock \emph{IEEE Transactions on Information Theory}, 27\penalty0
  (1):\penalty0 23--31, 1981.

\bibitem[Omi et~al.(2019)Omi, Aihara, et~al.]{omi2019fully}
Takahiro Omi, Kazuyuki Aihara, et~al.
\newblock Fully neural network based model for general temporal point
  processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2120--2129, 2019.

\bibitem[Rajaram et~al.(2005)Rajaram, Graepel, and
  Herbrich]{rajaram2005poisson}
Shyamsundar Rajaram, Thore Graepel, and Ralf Herbrich.
\newblock Poisson-networks: A model for structured point processes.
\newblock In \emph{Artificial Intelligence and Statistics}. Citeseer, 2005.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{ICML}, 2014.

\bibitem[Schein et~al.(2015)Schein, Paisley, Blei, and
  Wallach]{schein2015bayesian}
Aaron Schein, John Paisley, David~M Blei, and Hanna Wallach.
\newblock Bayesian poisson tensor factorization for inferring multilateral
  relations from sparse dyadic event counts.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1045--1054, 2015.

\bibitem[Schmidt et~al.(2019)Schmidt, Mandt, and
  Hofmann]{schmidt2019autoregressive}
Florian Schmidt, Stephan Mandt, and Thomas Hofmann.
\newblock Autoregressive text generation beyond feedback loops.
\newblock In \emph{Proceedings of the EMNLP-IJCNLP Conference}, pages
  3391--3397, 2019.

\bibitem[Shchur et~al.(2020)Shchur, Biloš, and
  Günnemann]{shchur2019intensity}
Oleksandr Shchur, Marin Biloš, and Stephan Günnemann.
\newblock Intensity-free learning of temporal point processes.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Shi et~al.(2019)Shi, Siddharth, Paige, and Torr]{shi2019variational}
Yuge Shi, N~Siddharth, Brooks Paige, and Philip Torr.
\newblock Variational mixture-of-experts autoencoders for multi-modal deep
  generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  15692--15703, 2019.

\bibitem[Theis et~al.(2015)Theis, Oord, and Bethge]{theis2015note}
Lucas Theis, A{\"a}ron van~den Oord, and Matthias Bethge.
\newblock A note on the evaluation of generative models.
\newblock \emph{arXiv preprint arXiv:1511.01844}, 2015.

\bibitem[T{\"u}rkmen et~al.(2019)T{\"u}rkmen, Wang, and
  Smola]{turkmen2019fastpoint}
Ali~Caner T{\"u}rkmen, Yuyang Wang, and Alexander~J Smola.
\newblock Fastpoint: Scalable deep point processes.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 465--480, 2019.

\bibitem[Upadhyay et~al.(2018)Upadhyay, De, and Rodriguez]{upadhyay2018deep}
Utkarsh Upadhyay, Abir De, and Manuel~Gomez Rodriguez.
\newblock Deep reinforcement learning of marked temporal point processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3168--3178, 2018.

\bibitem[Vass{\o}y et~al.(2019)Vass{\o}y, Ruocco, de~Souza~da Silva, and
  Aune]{vassoy2019time}
Bj{\o}rnar Vass{\o}y, Massimiliano Ruocco, Eliezer de~Souza~da Silva, and
  Erlend Aune.
\newblock Time is of the essence: A joint hierarchical rnn and point process
  model for time and item predictions.
\newblock In \emph{Proceedings of the Twelfth ACM International Conference on
  Web Search and Data Mining}, pages 591--599, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5998--6008, 2017.

\bibitem[Wang et~al.(2017)Wang, Liu, Shen, Gao, and Cheng]{wang2017marked}
Yongqing Wang, Shenghua Liu, Huawei Shen, Jinhua Gao, and Xueqi Cheng.
\newblock Marked temporal dynamics modeling based on recurrent neural network.
\newblock In \emph{Pacific-Asia Conference on Knowledge Discovery and Data
  Mining}, pages 786--798. Springer, 2017.

\bibitem[Xiao et~al.(2017{\natexlab{a}})Xiao, Farajtabar, Ye, Yan, Song, and
  Zha]{xiao2017wasserstein}
Shuai Xiao, Mehrdad Farajtabar, Xiaojing Ye, Junchi Yan, Le~Song, and Hongyuan
  Zha.
\newblock Wasserstein learning of deep generative point process models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3247--3257, 2017{\natexlab{a}}.

\bibitem[Xiao et~al.(2017{\natexlab{b}})Xiao, Yan, Yang, Zha, and
  Chu]{xiao2017modeling}
Shuai Xiao, Junchi Yan, Xiaokang Yang, Hongyuan Zha, and Stephen~M Chu.
\newblock Modeling the tntensity function of point process via recurrent neural
  networks.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence},
  pages 1597--1603, 2017{\natexlab{b}}.

\bibitem[Xiao et~al.(2018)Xiao, Xu, Yan, Farajtabar, Yang, Song, and
  Zha]{xiao2018learning}
Shuai Xiao, Hongteng Xu, Junchi Yan, Mehrdad Farajtabar, Xiaokang Yang,
  Le~Song, and Hongyuan Zha.
\newblock Learning conditional generative models for temporal point processes.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  pages 6302--6309, 2018.

\bibitem[Xu et~al.(2019)Xu, Ruan, Korpeoglu, Kumar, and Achan]{xu2019self}
Da~Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan.
\newblock Self-attention with functional time representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  15889--15899, 2019.

\bibitem[Xu and Zha(2017)]{xu2017dirichlet}
Hongteng Xu and Hongyuan Zha.
\newblock A dirichlet mixture model of hawkes processes for event sequence
  clustering.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1354--1363, 2017.

\bibitem[Yang et~al.(2017)Yang, Hu, Salakhutdinov, and
  Berg-Kirkpatrick]{yang2017improved}
Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor Berg-Kirkpatrick.
\newblock Improved variational autoencoders for text modeling using dilated
  convolutions.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3881--3890, 2017.

\bibitem[Zhang et~al.(2019{\natexlab{a}})Zhang, Butepage, Kjellstrom, and
  Mandt]{zhang2019advances}
Cheng Zhang, Judith Butepage, Hedvig Kjellstrom, and Stephan Mandt.
\newblock Advances in variational inference.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2019{\natexlab{a}}.

\bibitem[Zhang et~al.(2019{\natexlab{b}})Zhang, Lipani, Kirnap, and
  Yilmaz]{zhang2019self}
Qiang Zhang, Aldo Lipani, Omer Kirnap, and Emine Yilmaz.
\newblock Self-attentive hawkes processes.
\newblock \emph{arXiv preprint arXiv:1907.07561}, 2019{\natexlab{b}}.

\bibitem[Zhu et~al.(2020)Zhu, Li, and Xie]{zhu2019reinforcement}
Shixiang Zhu, Shuang Li, and Yao Xie.
\newblock Reinforcement learning of spatio-temporal point processes.
\newblock \emph{arXiv preprint arXiv:1906.05467}, 2020.

\end{thebibliography}
