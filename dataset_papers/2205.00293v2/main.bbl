\begin{thebibliography}{10}

\bibitem{ahmadi2021cross}
Salman Ahmadi-Asl, Cesar~F Caiafa, Andrzej Cichocki, Anh~Huy Phan, Toshihisa
  Tanaka, Ivan Oseledets, and Jun Wang.
\newblock Cross tensor approximation methods for compression and dimensionality
  reduction.
\newblock {\em IEEE Access}, 9:150809--150838, 2021.

\bibitem{ALARIE2021100011}
Stéphane Alarie, Charles Audet, Aïmen~E. Gheribi, Michael Kokkolaras, and
  Sébastien {Le Digabel}.
\newblock Two decades of blackbox optimization applications.
\newblock {\em EURO Journal on Computational Optimization}, 9:100011, 2021.

\bibitem{alpha_star_es}
Kai Arulkumaran, Antoine Cully, and Julian Togelius.
\newblock Alphastar: An evolutionary computation perspective.
\newblock In {\em Proceedings of the Genetic and Evolutionary Computation
  Conference Companion}, GECCO '19, page 314–315, New York, NY, USA, 2019.
  Association for Computing Machinery.

\bibitem{1562233}
A.F. Atiya, A.G. Parlos, and L.~Ingber.
\newblock A reinforcement learning method based on adaptive simulated
  annealing.
\newblock In {\em 2003 46th Midwest Symposium on Circuits and Systems},
  volume~1, pages 121--124 Vol. 1, 2003.

\bibitem{Nevergrad}
Pauline Bennet, Carola Doerr, Antoine Moreau, Jeremy Rapin, Fabien Teytaud, and
  Olivier Teytaud.
\newblock Nevergrad: Black-box optimization platform.
\newblock {\em SIGEVOlution}, 14(1):8–15, apr 2021.

\bibitem{constraint-es2}
Rafał Biedrzycki.
\newblock Handling bound constraints in cma-es: An experimental study.
\newblock {\em Swarm and Evolutionary Computation}, 52:100627, 2020.

\bibitem{boyko2021tt}
AI~Boyko, IV~Oseledets, and G~Ferrer.
\newblock Tt-qi: Faster value iteration in tensor train format for stochastic
  optimal control.
\newblock {\em Computational Mathematics and Mathematical Physics},
  61(5):836--846, 2021.

\bibitem{Brockman2016OpenAIG}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Wojciech Zaremba.
\newblock Openai gym.
\newblock {\em ArXiv}, abs/1606.01540, 2016.

\bibitem{CAIAFA2010557}
Cesar~F. Caiafa and Andrzej Cichocki.
\newblock Generalizing the column–row matrix decomposition to multi-way
  arrays.
\newblock {\em Linear Algebra and its Applications}, 433(3):557--573, 2010.

\bibitem{pmlr-v80-choromanski18a}
Krzysztof Choromanski, Mark Rowland, Vikas Sindhwani, Richard Turner, and
  Adrian Weller.
\newblock Structured evolution with compact architectures for scalable policy
  optimization.
\newblock In Jennifer Dy and Andreas Krause, editors, {\em Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of {\em
  Proceedings of Machine Learning Research}, pages 970--978. PMLR, 10--15 Jul
  2018.

\bibitem{NEURIPS2019_asebo}
Krzysztof~M Choromanski, Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang, and
  Vikas Sindhwani.
\newblock From complexity to simplicity: Adaptive es-active subspaces for
  blackbox optimization.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem{blind}
Andrzej Cichocki and Shun-ichi Amari.
\newblock {\em Adaptive Blind Signal and Image Processing: Learning Algorithms
  and Applications}.
\newblock John Wiley \& Sons, Inc., USA, 2002.

\bibitem{CichockiBookPart1MAL059}
Andrzej Cichocki, Namgil Lee, Ivan Oseledets, Anh-Huy Phan, Qibin Zhao, and
  Danilo~P. Mandic.
\newblock Tensor networks for dimensionality reduction and large-scale
  optimization: Part 1 low-rank tensor decompositions.
\newblock {\em Foundations and Trends® in Machine Learning}, 9(4-5):249--429,
  2016.

\bibitem{ActiveSubspace}
Paul~G. Constantine.
\newblock Active subspaces - emerging ideas for dimension reduction in
  parameter studies.
\newblock In {\em SIAM spotlights}, 2015.

\bibitem{conti2018}
Edoardo Conti, Vashisht Madhavan, Felipe~Petroski Such, Joel Lehman, Kenneth~O.
  Stanley, and Jeff Clune.
\newblock Improving exploration in evolution strategies for deep reinforcement
  learning via a population of novelty-seeking agents.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, page 5032–5043, Red Hook, NY,
  USA, 2018. Curran Associates Inc.

\bibitem{Coulom-2002a}
R\'emi Coulom.
\newblock {\em Reinforcement Learning Using Neural Networks, with Applications
  to Motor Control}.
\newblock PhD thesis, Institut National Polytechnique de Grenoble, 2002.

\bibitem{ErezTT11}
Tom Erez, Yuval Tassa, and Emanuel Todorov.
\newblock Infinite-horizon model predictive control for periodic tasks with
  contacts.
\newblock In Hugh~F. Durrant{-}Whyte, Nicholas Roy, and Pieter Abbeel, editors,
  {\em Robotics: Science and Systems VII, University of Southern California,
  Los Angeles, CA, USA, June 27-30, 2011}, 2011.

\bibitem{Faust2019EvolvingRT}
Aleksandra Faust, Anthony~G. Francis, and Dar Mehta.
\newblock Evolving rewards to automate reinforcement learning.
\newblock In {\em 6th ICML Workshop on Automated Machine Learning}, 2019.

\bibitem{goreinov2010find}
Sergei~A Goreinov, Ivan~V Oseledets, Dimitry~V Savostyanov, Eugene~E
  Tyrtyshnikov, and Nikolay~L Zamarashkin.
\newblock How to find a good submatrix.
\newblock In {\em Matrix Methods: Theory, Algorithms And Applications:
  Dedicated to the Memory of Gene Golub}, pages 247--256. World Scientific,
  2010.

\bibitem{Gorodetsky2018}
Alex Gorodetsky, Sertac Karaman, and Youssef Marzouk.
\newblock High-dimensional stochastic optimal control using continuous tensor
  decompositions.
\newblock {\em The International Journal of Robotics Research},
  37(2-3):340--377, 2018.

\bibitem{NEURIPS2018_worldmodels}
David Ha and J\"{u}rgen Schmidhuber.
\newblock Recurrent world models facilitate policy evolution.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem{hackbusch2009new}
Wolfgang Hackbusch and Stefan K{\"u}hn.
\newblock A new scheme for the tensor representation.
\newblock {\em Journal of Fourier analysis and applications}, 15(5):706--722,
  2009.

\bibitem{Hansen2006}
Nikolaus Hansen.
\newblock {\em The CMA Evolution Strategy: A Comparing Review}, pages 75--102.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2006.

\bibitem{HEIDRICHMEISNER2009152}
Verena Heidrich-Meisner and Christian Igel.
\newblock Neuroevolution strategies for episodic reinforcement learning.
\newblock {\em Journal of Algorithms}, 64(4):152--168, 2009.
\newblock Special Issue: Reinforcement Learning.

\bibitem{HEIN201787}
Daniel Hein, Alexander Hentschel, Thomas Runkler, and Steffen Udluft.
\newblock Particle swarm optimization for generating interpretable fuzzy
  reinforcement learning policies.
\newblock {\em Engineering Applications of Artificial Intelligence}, 65:87--98,
  2017.

\bibitem{HerrmannPriceJoyce+2020+45+62}
J.~Michael Herrmann, Adam Price, and Thomas Joyce.
\newblock {\em 3. Ant colony optimization and reinforcement learning}, pages
  45--62.
\newblock De Gruyter, 2020.

\bibitem{holland92}
John~H. Holland.
\newblock Genetic algorithms.
\newblock {\em Scientific American}, 267(1):66--73, 1992.

\bibitem{holtz2012alternating}
Sebastian Holtz, Thorsten Rohwedder, and Reinhold Schneider.
\newblock The alternating linear scheme for tensor optimization in the tensor
  train format.
\newblock {\em SIAM Journal on Scientific Computing}, 34(2):A683--A713, 2012.

\bibitem{jamil2013literature}
Momin Jamil and Xin-She Yang.
\newblock A literature survey of benchmark functions for global optimisation
  problems.
\newblock {\em International Journal of Mathematical Modelling and Numerical
  Optimisation}, 4(2):150--194, 2013.

\bibitem{10.5555/3326943.3327053}
Shauharda Khadka and Kagan Tumer.
\newblock Evolution-guided policy gradient in reinforcement learning.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, page 1196–1208, Red Hook, NY,
  USA, 2018. Curran Associates Inc.

\bibitem{Khoromskij2011}
Boris~N. Khoromskij.
\newblock O(dlog{\thinspace}n)-quantics approximation of n-d tensors in
  high-dimensional numerical modeling.
\newblock {\em Constructive Approximation}, 34(2):257--280, Oct 2011.

\bibitem{kolda2003ds}
Tamara~G. Kolda, Robert~Michael Lewis, and Virginia Torczon.
\newblock Optimization by direct search: New perspectives on some classical and
  modern methods.
\newblock {\em SIAM Review}, 45(3):385--482, 2003.

\bibitem{constraint-es1}
Oliver Kramer.
\newblock A review of constraint-handling techniques for evolution strategies.
\newblock {\em Appl. Comp. Intell. Soft Comput.}, 2010, January 2010.

\bibitem{es-not-fd-approx}
Joel Lehman, Jay Chen, Jeff Clune, and Kenneth~O. Stanley.
\newblock Es is more than just a traditional finite-difference approximator.
\newblock In {\em Proceedings of the Genetic and Evolutionary Computation
  Conference}, GECCO '18, page 450–457, New York, NY, USA, 2018. Association
  for Computing Machinery.

\bibitem{self-guided-es}
Fei-Yu Liu, Zi-Niu Li, and Chao Qian.
\newblock Self-guided evolution strategies with historical estimated gradients.
\newblock In {\em Proceedings of the Twenty-Ninth International Joint
  Conference on Artificial Intelligence}, IJCAI'20, 2021.

\bibitem{10.1016/j.engappai.2020.103525}
Tundong Liu, Liduan Li, Guifang Shao, Xiaomin Wu, and Meng Huang.
\newblock A novel policy gradient algorithm with pso-based parameter
  exploration for continuous control.
\newblock {\em Eng. Appl. Artif. Intell.}, 90(C), apr 2020.

\bibitem{mahajan2021tesseract}
Anuj Mahajan, Mikayel Samvelyan, Lei Mao, Viktor Makoviychuk, Animesh Garg,
  Jean Kossaifi, Shimon Whiteson, Yuke Zhu, and Animashree Anandkumar.
\newblock Tesseract: Tensorised actors for multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, volume
  139, pages 7301--7312, 2021.

\bibitem{pmlr-v97-maheswaranathan19a}
Niru Maheswaranathan, Luke Metz, George Tucker, Dami Choi, and Jascha
  Sohl-Dickstein.
\newblock Guided evolutionary strategies: augmenting random search with
  surrogate gradients.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of {\em Proceedings of Machine Learning Research}, pages
  4264--4273. PMLR, 09--15 Jun 2019.

\bibitem{NEURIPS2018_ARS}
Horia Mania, Aurelia Guy, and Benjamin Recht.
\newblock Simple random search of static linear policies is competitive for
  reinforcement learning.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem{JMLR:v22:18-220}
Erich Merrill, Alan Fern, Xiaoli Fern, and Nima Dolatnia.
\newblock An empirical study of bayesian optimization: Acquisition versus
  partition.
\newblock {\em Journal of Machine Learning Research}, 22(4):1--25, 2021.

\bibitem{9524335}
Laurent Meunier, Herilalaina Rakotoarison, Pak~Kan Wong, Baptiste Roziere,
  Jérémy Rapin, Olivier Teytaud, Antoine Moreau, and Carola Doerr.
\newblock Black-box optimization revisited: Improving algorithm selection
  wizards through massive benchmarking.
\newblock {\em IEEE Transactions on Evolutionary Computation}, pages 1--1,
  2021.

\bibitem{mikhalev2018rectangular}
Aleksandr Mikhalev and Ivan~V Oseledets.
\newblock Rectangular maximum-volume submatrices and their applications.
\newblock {\em Linear Algebra and its Applications}, 538:187--211, 2018.

\bibitem{Mnih2015}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A. Rusu, Joel Veness,
  Marc~G. Bellemare, Alex Graves, Martin Riedmiller, Andreas~K. Fidjeland,
  Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis
  Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and
  Demis Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533, Feb 2015.

\bibitem{NeldMead65}
John~A. Nelder and Roger Mead.
\newblock A simplex method for function minimization.
\newblock {\em Computer Journal}, 7:308--313, 1965.

\bibitem{Nesterov2017}
Yurii Nesterov and Vladimir Spokoiny.
\newblock Random gradient-free minimization of convex functions.
\newblock {\em Foundations of Computational Mathematics}, 17(2):527--566, Apr
  2017.

\bibitem{7379496}
Barry~D. Nichols.
\newblock Continuous action-space reinforcement learning methods applied to the
  minimum-time swing-up of the acrobot.
\newblock In {\em 2015 IEEE International Conference on Systems, Man, and
  Cybernetics}, pages 2084--2089, 2015.

\bibitem{oseledets2010approximation}
I.~V. Oseledets.
\newblock Approximation of $2^d \times 2^d$ matrices using tensor
  decomposition.
\newblock {\em SIAM J. Matrix Anal. Appl.}, 31(4):2130--2145, 2010.

\bibitem{oseledets2011tensor}
I.~V. Oseledets.
\newblock Tensor-train decomposition.
\newblock {\em SIAM Journal on Scientific Computing}, 33(5):2295--2317, 2011.

\bibitem{oseledets2009breaking}
Ivan~V Oseledets and Eugene~E Tyrtyshnikov.
\newblock Breaking the curse of dimensionality, or how to use svd in many
  dimensions.
\newblock {\em SIAM Journal on Scientific Computing}, 31(5):3744--3759, 2009.

\bibitem{oseledets2010ttcross}
Ivan~V Oseledets and Eugene~E Tyrtyshnikov.
\newblock {TT-cross} approximation for multidimensional arrays.
\newblock {\em Linear Algebra and its Applications}, 432(1):70--88, 2010.

\bibitem{PhysRevResearch.2.033429}
David Pfau, James~S. Spencer, Alexander G. D.~G. Matthews, and W.~M.~C.
  Foulkes.
\newblock Ab initio solution of the many-electron schr\"odinger equation with
  deep neural networks.
\newblock {\em Phys. Rev. Research}, 2:033429, Sep 2020.

\bibitem{phan2020a}
Anh-Huy Phan, Andrzej Cichocki, André Uschmajew, Petr Tichavský, George Luta,
  and Danilo~P. Mandic.
\newblock Tensor networks for latent variable analysis: Novel algorithms for
  tensor train approximation.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  31(11):4622--4636, 2020.

\bibitem{pmlr-v32-qin14}
Zhiwei Qin, Weichang Li, and Firdaus Janoos.
\newblock Sparse reinforcement learning via convex optimization.
\newblock In Eric~P. Xing and Tony Jebara, editors, {\em Proceedings of the
  31st International Conference on Machine Learning}, volume~32 of {\em
  Proceedings of Machine Learning Research}, pages 424--432, Bejing, China,
  22--24 Jun 2014. PMLR.

\bibitem{doi:10.1177/027836498400300207}
Marc~H. Raibert, Jr~H.~Benjamin~Brown, and Michael Chepponis.
\newblock Experiments in balance with a 3d one-legged hopping machine.
\newblock {\em The International Journal of Robotics Research}, 3(2):75--92,
  1984.

\bibitem{Ramesh2021ZeroShotTG}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock {\em ArXiv}, abs/2102.12092, 2021.

\bibitem{Salimans2017EvolutionSA}
Tim Salimans, Jonathan Ho, Xi~Chen, and Ilya Sutskever.
\newblock Evolution strategies as a scalable alternative to reinforcement
  learning.
\newblock {\em ArXiv}, abs/1703.03864, 2017.

\bibitem{trpo-pmlr-v37-schulman15}
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp
  Moritz.
\newblock Trust region policy optimization.
\newblock In Francis Bach and David Blei, editors, {\em Proceedings of the 32nd
  International Conference on Machine Learning}, volume~37 of {\em Proceedings
  of Machine Learning Research}, pages 1889--1897, Lille, France, 07--09 Jul
  2015. PMLR.

\bibitem{ppo-Schulman2017ProximalPO}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em ArXiv}, abs/1707.06347, 2017.

\bibitem{Schwefel1977}
Hans-Paul Schwefel.
\newblock {\em Evolutionsstrategien f{\"u}r die numerische Optimierung}, pages
  123--176.
\newblock Birkh{\"a}user Basel, Basel, 1977.

\bibitem{Schweidtmann_2018}
Artur~M. Schweidtmann and Alexander Mitsos.
\newblock Deterministic global optimization with artificial neural networks
  embedded.
\newblock {\em Journal of Optimization Theory and Applications},
  180(3):925–948, Oct 2018.

\bibitem{Storn1997-DE}
Rainer Storn and Kenneth Price.
\newblock Differential evolution -- a simple and efficient heuristic for global
  optimization over continuous spaces.
\newblock {\em Journal of Global Optimization}, 11(4):341--359, Dec 1997.

\bibitem{SimpleGASuch2017-DeepNG}
Felipe~Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman, Kenneth~O.
  Stanley, and Jeff Clune.
\newblock Deep neuroevolution: Genetic algorithms are a competitive alternative
  for training deep neural networks for reinforcement learning.
\newblock {\em ArXiv}, abs/1712.06567, 2017.

\bibitem{mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In {\em 2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pages 5026--5033, 2012.

\bibitem{Vinyals2019}
Oriol Vinyals, Igor Babuschkin, Wojciech~M. Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H. Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja
  Huang, Laurent Sifre, Trevor Cai, John~P. Agapiou, Max Jaderberg,
  Alexander~S. Vezhnevets, R{\'e}mi Leblond, Tobias Pohlen, Valentin Dalibard,
  David Budden, Yury Sulsky, James Molloy, Tom~L. Paine, Caglar Gulcehre, Ziyu
  Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama, Dario W{\"u}nsch,
  Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Koray
  Kavukcuoglu, Demis Hassabis, Chris Apps, and David Silver.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575(7782):350--354, Nov 2019.

\bibitem{4400335}
Pawel Wawrzynski.
\newblock Learning to control a 6-degree-of-freedom walking robot.
\newblock In {\em EUROCON 2007 - The International Conference on "Computer as a
  Tool"}, pages 698--705, 2007.

\bibitem{JMLR:v15:wierstra14a}
Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi~Sun, Jan Peters, and
  J\"{u}rgen Schmidhuber.
\newblock Natural evolution strategies.
\newblock {\em Journal of Machine Learning Research}, 15(27):949--980, 2014.

\bibitem{8682231}
Qibin Zhao, Masashi Sugiyama, Longhao Yuan, and Andrzej Cichocki.
\newblock Learning efficient tensor representations with ring-structured
  networks.
\newblock In {\em ICASSP 2019 - 2019 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pages 8608--8612, 2019.

\end{thebibliography}
