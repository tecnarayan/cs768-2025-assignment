\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Azzimonti et~al.(2020)Azzimonti, Ginsbourger, Chevalier, Bect, and
  Richet]{azzimonti2020adaptive}
Dario Azzimonti, David Ginsbourger, Cl{\'e}ment Chevalier, Julien Bect, and
  Yann Richet.
\newblock Adaptive design of experiments for conservative estimation of
  excursion sets.
\newblock \emph{Technometrics}, pages 1--14, 2020.

\bibitem[Baker et~al.(2020)Baker, Barbillon, Fadikar, Gramacy, Herbei, Higdon,
  Huang, Johnson, Ma, Mondal, et~al.]{baker2020analyzing}
Evan Baker, Pierre Barbillon, Arindam Fadikar, Robert~B Gramacy, Radu Herbei,
  David Higdon, Jiangeng Huang, Leah~R Johnson, Pulong Ma, Anirban Mondal,
  et~al.
\newblock Analyzing stochastic computer models: A review with opportunities.
\newblock \emph{arXiv preprint arXiv:2002.01321}, 2020.

\bibitem[Barber et~al.(1996)Barber, Dobkin, and Huhdanpaa]{quickhull}
C.~Bradford Barber, David~P. Dobkin, and Hannu Huhdanpaa.
\newblock The quickhull algorithm for convex hulls.
\newblock \emph{ACM Trans. Math. Softw.}, 22\penalty0 (4):\penalty0 469–483,
  December 1996.
\newblock ISSN 0098-3500.
\newblock \doi{10.1145/235815.235821}.
\newblock URL \url{https://doi.org/10.1145/235815.235821}.

\bibitem[Bates and Pronzato(2001)]{bates2001tri}
R.~Bates and L.~Pronzato.
\newblock Emulator-based global optimisation using lattices and delaunay
  tesselation.
\newblock In \emph{Sensitivity Analysis of Model Output}, pages 189--192,
  Madrid (Espagne), 2001.

\bibitem[Bect et~al.(2012)Bect, Ginsbourger, Li, Picheny, and
  Vazquez]{bect2012sequential}
Julien Bect, David Ginsbourger, Ling Li, Victor Picheny, and Emmanuel Vazquez.
\newblock Sequential design of computer experiments for the estimation of a
  probability of failure.
\newblock \emph{Statistics and Computing}, 22\penalty0 (3):\penalty0 773--793,
  2012.

\bibitem[Bengtsson(2018)]{R.matlab}
Henrik Bengtsson.
\newblock \emph{R.matlab: Read and Write {MAT} Files and Call {MATLAB} from
  Within {R}}, 2018.
\newblock URL \url{https://CRAN.R-project.org/package=R.matlab}.
\newblock R package version 3.6.2.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra2011algorithms}
James Bergstra, R{\'e}mi Bardenet, Yoshua Bengio, and Bal{\'a}zs K{\'e}gl.
\newblock Algorithms for hyper-parameter optimization.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.

\bibitem[Binois et~al.(2018)Binois, Gramacy, and
  Ludkovski]{binois2018practical}
M~Binois, RB~Gramacy, and M~Ludkovski.
\newblock Practical heteroscedastic {G}aussian process modeling for large
  simulation experiments.
\newblock \emph{Journal of Computational and Graphical Statistics}, 27\penalty0
  (4):\penalty0 808--821, 2018.
\newblock \doi{10.1080/10618600.2018.1458625}.
\newblock URL \url{https://doi.org/10.1080/10618600.2018.1458625}.

\bibitem[Binois et~al.(2019)Binois, Huang, Gramacy, and
  Ludkovski]{binois2018replication}
M~Binois, J~Huang, RB~Gramacy, and M~Ludkovski.
\newblock Replication or exploration? {S}equential design for stochastic
  simulation experiments.
\newblock \emph{Technometrics}, 27\penalty0 (4):\penalty0 808--821, 2019.
\newblock \doi{10.1080/00401706.2018.1469433}.
\newblock URL \url{https://doi.org/10.1080/00401706.2018.1469433}.

\bibitem[Binois and Wycoff(2021)]{binois2021survey}
Mickael Binois and Nathan Wycoff.
\newblock A survey on high-dimensional {G}aussian process modeling with
  application to bayesian optimization, 2021.

\bibitem[Binois and Gramacy(2021)]{JSSv098i13}
Mickaël Binois and Robert~B. Gramacy.
\newblock hetgp: Heteroskedastic {G}aussian process modeling and sequential
  design in {\sf r}.
\newblock \emph{Journal of Statistical Software}, 98\penalty0 (13):\penalty0
  1–44, 2021.
\newblock \doi{10.18637/jss.v098.i13}.
\newblock URL
  \url{https://www.jstatsoft.org/index.php/jss/article/view/v098i13}.

\bibitem[Breiman(2001)]{breiman2001random}
Leo Breiman.
\newblock Random forests.
\newblock \emph{Machine learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Bull(2011)]{bull2011convergence}
AD~Bull.
\newblock Convergence rates of efficient global optimization algorithms.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0
  (Oct):\penalty0 2879--2904, 2011.

\bibitem[Burden and Faires(1985)]{burden1985numerical}
R.L. Burden and J.D. Faires.
\newblock \emph{Numerical Analysis}.
\newblock PWS Publishers, 1985.

\bibitem[Byrd et~al.(2003)Byrd, Lu, Nocedal, and Zhu]{BFGS}
Richardh Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on Scientific Computing}, 16, 02 2003.
\newblock \doi{10.1137/0916069}.

\bibitem[Carnell(2018)]{R-lhs}
Rob Carnell.
\newblock \emph{{\tt lhs}: {L}atin Hypercube Samples}, 2018.
\newblock URL \url{https://CRAN.R-project.org/package=lhs}.
\newblock R package version 0.16.

\bibitem[Chevalier and Ginsbourger(2013)]{chevalier2013fast}
Cl{\'e}ment Chevalier and David Ginsbourger.
\newblock Fast computation of the multi-points expected improvement with
  applications in batch selection.
\newblock In \emph{International Conference on Learning and Intelligent
  Optimization}, pages 59--69. Springer, 2013.

\bibitem[Chevalier et~al.(2014)Chevalier, Bect, Ginsbourger, Vazquez, Picheny,
  and Richet]{chevalier2014fast}
Cl{\'e}ment Chevalier, Julien Bect, David Ginsbourger, Emmanuel Vazquez, Victor
  Picheny, and Yann Richet.
\newblock Fast parallel kriging-based stepwise uncertainty reduction with
  application to the identification of an excursion set.
\newblock \emph{Technometrics}, 56\penalty0 (4):\penalty0 455--465, 2014.

\bibitem[Cole et~al.(2021)Cole, Gramacy, Warner, Bomarito, Leser, and
  Leser]{cole2021entropy}
D~Austin Cole, Robert~B Gramacy, James~E Warner, Geoffrey~F Bomarito, Patrick~E
  Leser, and William~P Leser.
\newblock Entropy-based adaptive design for contour finding and estimating
  reliability.
\newblock \emph{arXiv preprint arXiv:2105.11357}, 2021.

\bibitem[Damianou and Lawrence(2013)]{damianou2013deep}
Andreas Damianou and Neil~D Lawrence.
\newblock Deep {G}aussian processes.
\newblock In \emph{Artificial intelligence and statistics}, pages 207--215.
  PMLR, 2013.

\bibitem[Daulton et~al.(2021)Daulton, Eriksson, Balandat, and
  Bakshy]{daulton2021multiobjective}
Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan Bakshy.
\newblock Multi-objective {B}ayesian optimization over high-dimensional search
  spaces, 2021.

\bibitem[Eriksson et~al.(2019)Eriksson, Pearce, Gardner, Turner, and
  Poloczek]{eriksson2019scalable}
David Eriksson, Michael Pearce, Jacob Gardner, Ryan~D Turner, and Matthias
  Poloczek.
\newblock Scalable global optimization via local {B}ayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5497--5508, 2019.

\bibitem[Feurer et~al.(2018)Feurer, Letham, Hutter, and
  Bakshy]{feurer2018practical}
Matthias Feurer, Benjamin Letham, Frank Hutter, and Eytan Bakshy.
\newblock Practical transfer learning for bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1802.02219}, 2018.

\bibitem[Frazier et~al.(2008)Frazier, Powell, and
  Dayanik]{frazier2008knowledge}
Peter~I Frazier, Warren~B Powell, and Savas Dayanik.
\newblock A knowledge-gradient policy for sequential information collection.
\newblock \emph{SIAM Journal on Control and Optimization}, 47\penalty0
  (5):\penalty0 2410--2439, 2008.

\bibitem[Garnett(2022)]{garnett_bayesoptbook_2022}
Roman Garnett.
\newblock \emph{{Bayesian Optimization}}.
\newblock Cambridge University Press, 2022.
\newblock in preparation.

\bibitem[Ginsbourger et~al.(2007)Ginsbourger, Le~Riche, and
  Carraro]{ginsbourger2007multi}
David Ginsbourger, Rodolphe Le~Riche, and Laurent Carraro.
\newblock A multi-points criterion for deterministic parallel global
  optimization based on kriging.
\newblock In \emph{NCP07}, 2007.

\bibitem[Gonzalez et~al.(2016)Gonzalez, Osborne, and
  Lawrence]{gonzalez2016glasses}
J~Gonzalez, M~Osborne, and N~Lawrence.
\newblock {\tt GLASSES}: {R}elieving the myopia of {B}ayesian optimisation.
\newblock In \emph{Proceedings of the 19th International Conference on
  Artificial Intelligence and Statistics}, pages 790--799, 2016.

\bibitem[Gonz{\'a}lez et~al.(2016)Gonz{\'a}lez, Dai, Hennig, and
  Lawrence]{gonzalez2016batch}
Javier Gonz{\'a}lez, Zhenwen Dai, Philipp Hennig, and Neil Lawrence.
\newblock Batch bayesian optimization via local penalization.
\newblock In \emph{Artificial intelligence and statistics}, pages 648--657.
  PMLR, 2016.

\bibitem[Gramacy(2007)]{gramacy2007tgp}
RB~Gramacy.
\newblock {\tt tgp}: an {R} package for {B}ayesian nonstationary,
  semiparametric nonlinear regression and design by treed {G}aussian process
  models.
\newblock \emph{Journal of Statistical Software}, 19\penalty0 (9):\penalty0 6,
  2007.

\bibitem[Gramacy(2016)]{gramacy2016lagp}
RB~Gramacy.
\newblock {\tt laGP}: large-scale spatial modeling via local approximate
  {G}aussian processes in {R}.
\newblock \emph{Journal of Statistical Software}, 72\penalty0 (1):\penalty0
  1--46, 2016.

\bibitem[Gramacy and Lee(2011)]{gramacy2011optimization}
RB~Gramacy and Herbert~KH Lee.
\newblock Optimization under unknown constraints.
\newblock In \emph{Bayesian Statistics}, volume~9. Oxford University Press,
  2011.

\bibitem[Gramacy and Lee(2008)]{gramacy2008bayesian}
RB~Gramacy and HKH Lee.
\newblock Bayesian treed {G}aussian process models with an application to
  computer modeling.
\newblock \emph{Journal of the American Statistical Association}, 103\penalty0
  (483):\penalty0 1119--1130, 2008.

\bibitem[Gramacy and Sun(2018)]{R-laGP}
RB~Gramacy and F~Sun.
\newblock \emph{{\tt laGP}: {L}ocal Approximate {G}aussian Process Regression},
  2018.
\newblock URL \url{http://bobby.gramacy.com/r_packages/laGP}.
\newblock R package version 1.5-3.

\bibitem[Gramacy and Taddy(2010)]{gramacy2010categorical}
RB~Gramacy and MA~Taddy.
\newblock Categorical inputs, sensitivity analysis, optimization and importance
  tempering with {\tt tgp} version 2, an {R} package for treed {G}aussian
  process models.
\newblock \emph{Journal of Statistical Software}, 33\penalty0 (6):\penalty0
  1--48, 2010.

\bibitem[Gramacy(2020)]{gramacy2020surrogates}
Robert~B. Gramacy.
\newblock \emph{Surrogates: {G}aussian Process Modeling, Design and
  Optimization for the Applied Sciences}.
\newblock Chapman Hall/CRC, Boca Raton, Florida, 2020.
\newblock \url{http://bobby.gramacy.com/surrogates/}.

\bibitem[Habel et~al.(2019)Habel, Grasman, Gramacy, Mozharovskyi, and
  Sterratt]{geometry}
Kai Habel, Raoul Grasman, Robert~B. Gramacy, Pavlo Mozharovskyi, and David~C.
  Sterratt.
\newblock \emph{{\tt geometry}: Mesh Generation and Surface Tessellation},
  2019.
\newblock URL \url{https://CRAN.R-project.org/package=geometry}.
\newblock R package version 0.4.5.

\bibitem[Hong and Nelson(2006)]{Hong:2006}
L.J. Hong and B.L. Nelson.
\newblock Discrete optimization via simulation using compass.
\newblock \emph{Operations Research}, 54\penalty0 (1):\penalty0 115--129, 2006.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{jones1998efficient}
Donald~R Jones, Matthias Schonlau, and William~J Welch.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global optimization}, 13\penalty0 (4):\penalty0
  455--492, 1998.

\bibitem[Lam et~al.(2016)Lam, Willcox, and Wolpert]{lam2016bayesian}
Remi Lam, Karen Willcox, and David~H Wolpert.
\newblock Bayesian optimization with a finite budget: An approximate dynamic
  programming approach.
\newblock \emph{Advances in Neural Information Processing Systems},
  29:\penalty0 883--891, 2016.

\bibitem[Leatherman et~al.(2017)Leatherman, Santner, and
  Dean]{leatherman2017computer}
ER~Leatherman, TJ~Santner, and AM~Dean.
\newblock Computer experiment designs for accurate prediction.
\newblock \emph{Statistics and Computing}, pages 1--13, 2017.

\bibitem[Lee and Schachter(1980)]{lee1980two}
Der-Tsai Lee and Bruce~J Schachter.
\newblock Two algorithms for constructing a delaunay triangulation.
\newblock \emph{International Journal of Computer \& Information Sciences},
  9\penalty0 (3):\penalty0 219--242, 1980.

\bibitem[Letham and Bakshy(2019)]{letham2019bayesian}
Benjamin Letham and Eytan Bakshy.
\newblock Bayesian optimization for policy search via online-offline
  experimentation.
\newblock \emph{J. Mach. Learn. Res.}, 20:\penalty0 145--1, 2019.

\bibitem[Marques et~al.(2018)Marques, Lam, and Willcox]{marques2018contour}
Alexandre Marques, Remi Lam, and Karen Willcox.
\newblock Contour location via entropy reduction leveraging multiple
  information sources.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5217--5227, 2018.

\bibitem[Mckay et~al.(1979)Mckay, Beckman, and Conover]{Mckay:1979}
D~Mckay, Richard Beckman, and William Conover.
\newblock A comparison of three methods for selecting vales of input variables
  in the analysis of output from a computer code.
\newblock \emph{Technometrics}, 21:\penalty0 239--245, 05 1979.

\bibitem[Mo{\v{c}}kus(1975)]{movckus1975bayesian}
Jonas Mo{\v{c}}kus.
\newblock On bayesian methods for seeking the extremum.
\newblock In \emph{Optimization techniques IFIP technical conference}, pages
  400--404. Springer, 1975.

\bibitem[Nelder and Mead(1965)]{nelder1965simplex}
JA~Nelder and R~Mead.
\newblock A simplex method for function minimization.
\newblock \emph{The Computer Journal}, 7\penalty0 (4):\penalty0 308--313, 1965.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Picheny et~al.(2012)Picheny, Wagner, and
  Ginsbourger]{picheny2012benchmark}
V~Picheny, T~Wagner, and D~Ginsbourger.
\newblock A benchmark of kriging-based infill criteria for noisy optimization.
\newblock \emph{Structural and Multidisciplinary Optimization}, pages 1--20,
  2012.

\bibitem[Pourmohamad and Lee(2021)]{pourmohamadbayesian}
Tony Pourmohamad and Herbert~KH Lee.
\newblock \emph{Bayesian Optimization with Application to Computer
  Experiments}.
\newblock Springer, New York, NY, 2021.

\bibitem[Ranjan et~al.(2008)Ranjan, Bingham, and
  Michailidis]{ranjan2008sequential}
Pritam Ranjan, Derek Bingham, and George Michailidis.
\newblock Sequential experiment design for contour estimation from complex
  computer codes.
\newblock \emph{Technometrics}, 50\penalty0 (4):\penalty0 527--541, 2008.

\bibitem[Salimbeni and Deisenroth(2017)]{salimbeni2017doubly}
Hugh Salimbeni and Marc Deisenroth.
\newblock Doubly stochastic variational inference for deep {G}aussian
  processes.
\newblock \emph{arXiv preprint arXiv:1705.08933}, 2017.

\bibitem[Sauer(2021)]{deepgp}
Annie Sauer.
\newblock \emph{{\tt deepgp}: Sequential Design for Deep {G}aussian Processes
  using MCMC}, 2021.
\newblock URL \url{https://CRAN.R-project.org/package=deepgp}.
\newblock R package version 0.3.0.

\bibitem[Sauer et~al.(2020)Sauer, Gramacy, and Higdon]{sauer2020active}
Annie Sauer, Robert~B Gramacy, and David Higdon.
\newblock Active learning for deep {G}aussian process surrogates.
\newblock \emph{arXiv preprint arXiv:2012.08015}, 2020.

\bibitem[Scott et~al.(2011)Scott, Frazier, and Powell]{scott2011correlated}
Warren Scott, Peter Frazier, and Warren Powell.
\newblock The correlated knowledge gradient for simulation optimization of
  continuous parameters using {G}aussian process regression.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (3):\penalty0
  996--1026, 2011.

\bibitem[Srinivas et~al.(2009)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham~M Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock \emph{arXiv preprint arXiv:0912.3995}, 2009.

\bibitem[Su and Drysdale(1997)]{su1997comparison}
Peter Su and Robert L~Scot Drysdale.
\newblock A comparison of sequential delaunay triangulation algorithms.
\newblock \emph{Computational Geometry}, 7\penalty0 (5-6):\penalty0 361--385,
  1997.

\bibitem[Surjanovic and Bingham(2013)]{surjanovic2013virtual}
S~Surjanovic and D~Bingham.
\newblock Virtual library of simulation experiments: test functions and
  datasets.
\newblock \url{http://www.sfu.ca/~ssurjano}, 2013.

\bibitem[Taddy et~al.(2009)Taddy, Lee, Gray, and Griffin]{taddy2009bayesian}
MA~Taddy, HKH Lee, GA~Gray, and JD~Griffin.
\newblock Bayesian guided pattern search for robust local optimization.
\newblock \emph{Technometrics}, 51\penalty0 (4):\penalty0 389--401, 2009.

\bibitem[Thompson(1933)]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 25\penalty0 (3/4):\penalty0 285--294, 1933.

\bibitem[Turner et~al.(2021)Turner, Eriksson, McCourt, Kiili, Laaksonen, Xu,
  and Guyon]{turner2021bayesian}
Ryan Turner, David Eriksson, Michael McCourt, Juha Kiili, Eero Laaksonen, Zhen
  Xu, and Isabelle Guyon.
\newblock Bayesian optimization is superior to random search for machine
  learning hyperparameter tuning: Analysis of the black-box optimization
  challenge 2020.
\newblock \emph{arXiv preprint arXiv:2104.10201}, 2021.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{2020SciPy-NMeth}
Pauli Virtanen, Ralf Gommers, Travis~E. Oliphant, Matt Haberland, Tyler Reddy,
  David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan
  Bright, St{\'e}fan~J. {van der Walt}, Matthew Brett, Joshua Wilson, K.~Jarrod
  Millman, Nikolay Mayorov, Andrew R.~J. Nelson, Eric Jones, Robert Kern, Eric
  Larson, C~J Carey, {\.I}lhan Polat, Yu~Feng, Eric~W. Moore, Jake
  {VanderPlas}, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen,
  E.~A. Quintero, Charles~R. Harris, Anne~M. Archibald, Ant{\^o}nio~H. Ribeiro,
  Fabian Pedregosa, Paul {van Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Wang et~al.(2020)Wang, Fonseca, and Tian]{wang2020learning}
Linnan Wang, Rodrigo Fonseca, and Yuandong Tian.
\newblock Learning search space partition for black-box optimization using
  monte carlo tree search.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 19511--19522, 2020.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Gramacy, Johnson, Rose, and
  Smith]{zhang2020batch}
Boya Zhang, Robert~B Gramacy, Leah Johnson, Kenneth~A Rose, and Eric Smith.
\newblock Batch-sequential design and heteroskedastic surrogate modeling for
  delta smelt conservation.
\newblock \emph{arXiv preprint arXiv:2010.06515}, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2021)Zhang, Cole, and Gramacy]{zhang2021distance}
Boya Zhang, D~Austin Cole, and Robert~B Gramacy.
\newblock Distance-distributed design for {G}aussian process surrogates.
\newblock \emph{Technometrics}, 63\penalty0 (1):\penalty0 40--52, 2021.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Apley, and
  Chen]{zhang2020bayesian}
Yichi Zhang, Daniel~W Apley, and Wei Chen.
\newblock Bayesian optimization for materials design with mixed quantitative
  and qualitative variables.
\newblock \emph{Scientific reports}, 10\penalty0 (1):\penalty0 1--13,
  2020{\natexlab{b}}.

\end{thebibliography}
