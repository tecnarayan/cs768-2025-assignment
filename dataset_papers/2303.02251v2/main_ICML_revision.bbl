\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2019)Alayrac, Uesato, Huang, Fawzi, Stanforth, and
  Kohli]{alayrac2019labels}
Alayrac, J.-B., Uesato, J., Huang, P.-S., Fawzi, A., Stanforth, R., and Kohli,
  P.
\newblock Are labels required for improving adversarial robustness?
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Bai et~al.(2021)Bai, Luo, Zhao, Wen, and Wang]{bai2021recent}
Bai, T., Luo, J., Zhao, J., Wen, B., and Wang, Q.
\newblock Recent advances in adversarial training for adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2102.01356}, 2021.

\bibitem[Bennouna \& Van~Parys(2022)Bennouna and
  Van~Parys]{bennouna2022holistic}
Bennouna, A. and Van~Parys, B.
\newblock Holistic robust data-driven decisions.
\newblock \emph{arXiv preprint arXiv:2207.09560}, 2022.

\bibitem[Bennouna \& Van~Parys(2021)Bennouna and
  Van~Parys]{bennouna2021learning}
Bennouna, M. and Van~Parys, B.~P.
\newblock Learning and decision-making with data: Optimal formulations and
  phase transitions.
\newblock \emph{arXiv preprint arXiv:2109.06911}, 2021.

\bibitem[Biggio et~al.(2012)Biggio, Nelson, and Laskov]{biggio2012poisoning}
Biggio, B., Nelson, B., and Laskov, P.
\newblock Poisoning attacks against support vector machines.
\newblock \emph{arXiv preprint arXiv:1206.6389}, 2012.

\bibitem[Bose et~al.(2020)Bose, Gidel, Berard, Cianflone, Vincent,
  Lacoste-Julien, and Hamilton]{bose2020adversarial}
Bose, J., Gidel, G., Berard, H., Cianflone, A., Vincent, P., Lacoste-Julien,
  S., and Hamilton, W.
\newblock Adversarial example games.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 8921--8934, 2020.

\bibitem[Bui et~al.(2022)Bui, Le, Tran, Zhao, and Phung]{bui2022unified}
Bui, T.~A., Le, T., Tran, Q., Zhao, H., and Phung, D.
\newblock A unified wasserstein distributional robustness framework for
  adversarial training.
\newblock \emph{arXiv preprint arXiv:2202.13437}, 2022.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and
  Liang]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.~C., and Liang, P.~S.
\newblock Unlabeled data improves adversarial robustness.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Chen et~al.(2021)Chen, Zhang, Xu, Hu, Niu, Chen, and
  Sugiyama]{chen2021guided}
Chen, C., Zhang, J., Xu, X., Hu, T., Niu, G., Chen, G., and Sugiyama, M.
\newblock Guided interpolation for adversarial training.
\newblock \emph{arXiv preprint arXiv:2102.07327}, 2021.

\bibitem[Cover \& Thomas(1991)Cover and Thomas]{cover1991information}
Cover, T.~M. and Thomas, J.~A.
\newblock Information theory and the stock market.
\newblock \emph{Elements of Information Theory. Wiley Inc., New York}, pp.\
  543--556, 1991.

\bibitem[Dembo \& Zeitouni(2009)Dembo and Zeitouni]{dembo2009large}
Dembo, A. and Zeitouni, O.
\newblock \emph{Large deviations techniques and applications}, volume~38.
\newblock Springer Science \& Business Media, 2009.

\bibitem[Dong et~al.(2021)Dong, Xu, Yang, Pang, Deng, Su, and
  Zhu]{dong2021exploring}
Dong, Y., Xu, K., Yang, X., Pang, T., Deng, Z., Su, H., and Zhu, J.
\newblock Exploring memorization in adversarial training.
\newblock \emph{arXiv preprint arXiv:2106.01606}, 2021.

\bibitem[Gidel et~al.(2021)Gidel, Balduzzi, Czarnecki, Garnelo, and
  Bachrach]{gidel2021limited}
Gidel, G., Balduzzi, D., Czarnecki, W., Garnelo, M., and Bachrach, Y.
\newblock A limited-capacity minimax theorem for non-convex games or: How i
  learned to stop worrying about mixed-nash and love neural nets.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  2548--2556. PMLR, 2021.

\bibitem[Goldblum et~al.(2022)Goldblum, Tsipras, Xie, Chen, Schwarzschild,
  Song, Madry, Li, and Goldstein]{goldblum2022dataset}
Goldblum, M., Tsipras, D., Xie, C., Chen, X., Schwarzschild, A., Song, D.,
  Madry, A., Li, B., and Goldstein, T.
\newblock Dataset security for machine learning: Data poisoning, backdoor
  attacks, and defenses.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2022.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Gotoh et~al.(2018)Gotoh, Kim, and Lim]{gotoh2018robust}
Gotoh, J.-y., Kim, M.~J., and Lim, A.~E.
\newblock Robust empirical optimization is almost the same as mean--variance
  optimization.
\newblock \emph{Operations research letters}, 46\penalty0 (4):\penalty0
  448--452, 2018.

\bibitem[Hampel(1971)]{hampel1971general}
Hampel, F.~R.
\newblock A general qualitative definition of robustness.
\newblock \emph{The annals of mathematical statistics}, 42\penalty0
  (6):\penalty0 1887--1896, 1971.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2019benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{arXiv preprint arXiv:1903.12261}, 2019.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Lee, and Mazeika]{hendrycks2019using}
Hendrycks, D., Lee, K., and Mazeika, M.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2712--2721. PMLR, 2019.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo,
  Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai,
  R., Zhu, T., Parajuli, S., Guo, M., et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8340--8349, 2021.

\bibitem[Huber(1981)]{huber1981robust}
Huber, P.~J.
\newblock \emph{Robust Statistics}.
\newblock Wiley series in probability and mathematical statistics. John Wiley
  \& Sons, 1981.

\bibitem[Kulynych et~al.(2022)Kulynych, Yang, Yu, B{\l}asiok, and
  Nakkiran]{kulynych2022you}
Kulynych, B., Yang, Y.-Y., Yu, Y., B{\l}asiok, J., and Nakkiran, P.
\newblock What you see is what you get: Principled deep learning via
  distributional generalization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Lam(2019)]{lam2019recovering}
Lam, H.
\newblock Recovering best statistical guarantees via the empirical
  divergence-based distributionally robust optimization.
\newblock \emph{Operations Research}, 67\penalty0 (4):\penalty0 1090--1105,
  2019.

\bibitem[Lee et~al.(2020)Lee, Lee, and Yoon]{lee2020adversarial}
Lee, S., Lee, H., and Yoon, S.
\newblock Adversarial vertex mixup: Toward better adversarially robust
  generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  272--281, 2020.

\bibitem[Levine \& Feizi(2020)Levine and Feizi]{levine2020deep}
Levine, A. and Feizi, S.
\newblock Deep partition aggregation: Provable defense against general
  poisoning attacks.
\newblock \emph{arXiv preprint arXiv:2006.14768}, 2020.

\bibitem[Li et~al.(2014)Li, Deng, Gong, and Haeb-Umbach]{li2014overview}
Li, J., Deng, L., Gong, Y., and Haeb-Umbach, R.
\newblock An overview of noise-robust automatic speech recognition.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 22\penalty0 (4):\penalty0 745--777, 2014.

\bibitem[Li \& Spratling(2022)Li and Spratling]{li2022understanding}
Li, L. and Spratling, M.
\newblock Understanding and combating robust overfitting via input loss
  landscape analysis and regularization.
\newblock \emph{Pattern Recognition}, pp.\  109229, 2022.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Mitra et~al.(2017)Mitra, Franco, Stern, Hout, Ferrer, Graciarena,
  Wang, Vergyri, Alwan, and Hansen]{mitra2017robust}
Mitra, V., Franco, H., Stern, R.~M., Hout, J.~v., Ferrer, L., Graciarena, M.,
  Wang, W., Vergyri, D., Alwan, A., and Hansen, J.~H.
\newblock Robust features in deep-learning-based speech recognition.
\newblock In \emph{New era for robust speech recognition}, pp.\  187--217.
  Springer, 2017.

\bibitem[Namkoong \& Duchi(2017)Namkoong and Duchi]{namkoong2017variance}
Namkoong, H. and Duchi, J.~C.
\newblock Variance-based regularization with convex objectives.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Nelson et~al.(2008)Nelson, Barreno, Chi, Joseph, Rubinstein, Saini,
  Sutton, Tygar, and Xia]{nelson2008exploiting}
Nelson, B., Barreno, M., Chi, F.~J., Joseph, A.~D., Rubinstein, B.~I., Saini,
  U., Sutton, C., Tygar, J.~D., and Xia, K.
\newblock Exploiting machine learning to subvert your spam filter.
\newblock \emph{LEET}, 8\penalty0 (1):\penalty0 9, 2008.

\bibitem[Prokhorov(1956)]{prokhorov1956convergence}
Prokhorov, Y.~V.
\newblock Convergence of random processes and limit theorems in probability
  theory.
\newblock \emph{Theory of Probability \& Its Applications}, 1\penalty0
  (2):\penalty0 157--214, 1956.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice2020overfitting}
Rice, L., Wong, E., and Kolter, Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8093--8104. PMLR, 2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Sinha et~al.(2017)Sinha, Namkoong, Volpi, and
  Duchi]{sinha2017certifying}
Sinha, A., Namkoong, H., Volpi, R., and Duchi, J.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock \emph{arXiv preprint arXiv:1710.10571}, 2017.

\bibitem[Sion(1958)]{sion1958general}
Sion, M.
\newblock On general minimax theorems.
\newblock \emph{Pacific Journal of mathematics}, 8\penalty0 (1):\penalty0
  171--176, 1958.

\bibitem[Staib \& Jegelka(2017)Staib and Jegelka]{staib2017distributionally}
Staib, M. and Jegelka, S.
\newblock Distributionally robust deep learning as a generalization of
  adversarial training.
\newblock In \emph{NIPS workshop on Machine Learning and Computer Security},
  volume~3, pp.\ ~4, 2017.

\bibitem[Strassen(1965)]{strassen1965existence}
Strassen, V.
\newblock The existence of probability measures with given marginals.
\newblock \emph{The Annals of Mathematical Statistics}, 36\penalty0
  (2):\penalty0 423--439, 1965.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Tramer, F., Carlini, N., Brendel, W., and Madry, A.
\newblock On adaptive attacks to adversarial example defenses.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1633--1645, 2020.

\bibitem[Van~Erven \& Harremos(2014)Van~Erven and Harremos]{vanerven2014renyi}
Van~Erven, T. and Harremos, P.
\newblock R{\'e}nyi divergence and kullback-leibler divergence.
\newblock \emph{IEEE Transactions on Information Theory}, 60\penalty0
  (7):\penalty0 3797--3820, 2014.

\bibitem[Van~Parys et~al.(2021)Van~Parys, Esfahani, and Kuhn]{vanparys2021data}
Van~Parys, B.~P., Esfahani, P.~M., and Kuhn, D.
\newblock From data to decisions: Distributionally robust optimization is
  optimal.
\newblock \emph{Management Science}, 67\penalty0 (6):\penalty0 3387--3402,
  2021.

\bibitem[Villani(2009)]{villani2009optimal}
Villani, C.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer, 2009.

\bibitem[Wang et~al.(2022)Wang, Levine, and Feizi]{wang2022improved}
Wang, W., Levine, A.~J., and Feizi, S.
\newblock Improved certified defenses against data poisoning with
  (deterministic) finite aggregation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  22769--22783. PMLR, 2022.

\bibitem[Wang et~al.(2019)Wang, Zou, Yi, Bailey, Ma, and Gu]{wang2019improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Wong et~al.(2019)Wong, Schmidt, and Kolter]{wong2019wasserstein}
Wong, E., Schmidt, F., and Kolter, Z.
\newblock Wasserstein adversarial examples via projected sinkhorn iterations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6808--6817. PMLR, 2019.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu2020adversarial}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2958--2969, 2020.

\bibitem[Yu et~al.(2022)Yu, Han, Shen, Yu, Gong, Gong, and
  Liu]{yu2022understanding}
Yu, C., Han, B., Shen, L., Yu, J., Gong, C., Gong, M., and Liu, T.
\newblock Understanding robust overfitting of adversarial training and beyond.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  25595--25610. PMLR, 2022.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, El~Ghaoui, and
  Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E., El~Ghaoui, L., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International conference on machine learning}, pp.\
  7472--7482. PMLR, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Zhu, Niu, Han, Sugiyama, and
  Kankanhalli]{zhang2021geometry}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.~S.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In \emph{ICLR}, 2021.

\bibitem[Zhang \& Sabuncu(2018)Zhang and Sabuncu]{zhang2018generalized}
Zhang, Z. and Sabuncu, M.
\newblock Generalized cross entropy loss for training deep neural networks with
  noisy labels.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\end{thebibliography}
