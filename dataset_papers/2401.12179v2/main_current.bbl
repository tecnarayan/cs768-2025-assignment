\begin{thebibliography}{80}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti, Caillon, Huang, Jansen, Roberts, Tagliasacchi, et~al.]{agostinelli2023musiclm}
Agostinelli, A., Denk, T.~I., Borsos, Z., Engel, J., Verzetti, M., Caillon, A., Huang, Q., Jansen, A., Roberts, A., Tagliasacchi, M., et~al.
\newblock Music{LM}: Generating music from text.
\newblock \emph{arXiv:2301.11325}, 2023.

\bibitem[Bar-Tal et~al.(2023)Bar-Tal, Yariv, Lipman, and Dekel]{bar2023multidiffusion}
Bar-Tal, O., Yariv, L., Lipman, Y., and Dekel, T.
\newblock Multi{D}iffusion: Fusing diffusion paths for controlled image generation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Black et~al.(2023)Black, Janner, Du, Kostrikov, and Levine]{black2023training}
Black, K., Janner, M., Du, Y., Kostrikov, I., and Levine, S.
\newblock Training diffusion models with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2305.13301}, 2023.

\bibitem[Borsos et~al.(2023{\natexlab{a}})Borsos, Marinier, Vincent, Kharitonov, Pietquin, Sharifi, Roblek, Teboul, et~al.]{borsos2023audiolm}
Borsos, Z., Marinier, R., Vincent, D., Kharitonov, E., Pietquin, O., Sharifi, M., Roblek, D., Teboul, O., et~al.
\newblock {AudioLM}: a language modeling approach to audio generation.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)}, 2023{\natexlab{a}}.

\bibitem[Borsos et~al.(2023{\natexlab{b}})Borsos, Sharifi, Vincent, Kharitonov, Zeghidour, and Tagliasacchi]{Borsos2023SoundStormEP}
Borsos, Z., Sharifi, M., Vincent, D., Kharitonov, E., Zeghidour, N., and Tagliasacchi, M.
\newblock Soundstorm: Efficient parallel audio generation.
\newblock \emph{ArXiv}, abs/2305.09636, 2023{\natexlab{b}}.

\bibitem[Chen et~al.(2020)Chen, Wang, Berg-Kirkpatrick, and Dubnov]{chen2020music}
Chen, K., Wang, C.-i., Berg-Kirkpatrick, T., and Dubnov, S.
\newblock {Music SketchNet}: Controllable music generation via factorized representations of pitch and rhythm.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}, 2020.

\bibitem[Chen et~al.(2023)Chen, Wu, Liu, Nezhurina, Berg-Kirkpatrick, and Dubnov]{chen2023musicldm}
Chen, K., Wu, Y., Liu, H., Nezhurina, M., Berg-Kirkpatrick, T., and Dubnov, S.
\newblock {MusicLDM}: Enhancing novelty in text-to-music generation using beat-synchronous mixup strategies.
\newblock \emph{arXiv:2308.01546}, 2023.

\bibitem[Chen(2023)]{chen2023importance}
Chen, T.
\newblock On the importance of noise scheduling for diffusion models.
\newblock Technical report, Google Research, 2023.

\bibitem[Chen et~al.(2016)Chen, Xu, Zhang, and Guestrin]{chen2016training}
Chen, T., Xu, B., Zhang, C., and Guestrin, C.
\newblock Training deep nets with sublinear memory cost.
\newblock \emph{arXiv preprint arXiv:1604.06174}, 2016.

\bibitem[Choi et~al.(2023)Choi, Choi, Kim, Kim, and Yoon]{choi2023custom}
Choi, J., Choi, Y., Kim, Y., Kim, J., and Yoon, S.
\newblock Custom-{E}dit: Text-guided image editing with customized diffusion models.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition - AI4CC Workshop}, 2023.

\bibitem[Chung et~al.(2023)Chung, Kim, McCann, Klasky, and Ye]{Chung2022DiffusionPS}
Chung, H., Kim, J., McCann, M.~T., Klasky, M.~L., and Ye, J.~C.
\newblock Diffusion posterior sampling for general noisy inverse problems.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[Clark et~al.(2023)Clark, Vicol, Swersky, and Fleet]{Clark2023DirectlyFD}
Clark, K., Vicol, P., Swersky, K., and Fleet, D.~J.
\newblock Directly fine-tuning diffusion models on differentiable rewards.
\newblock \emph{ArXiv}, abs/2309.17400, 2023.

\bibitem[Copet et~al.(2023)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and D{\'e}fossez]{copet2023simple}
Copet, J., Kreuk, F., Gat, I., Remez, T., Kant, D., Synnaeve, G., Adi, Y., and D{\'e}fossez, A.
\newblock Simple and controllable music generation.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Dai et~al.(2021)Dai, Jin, Gomes, and Dannenberg]{dai2021controllable}
Dai, S., Jin, Z., Gomes, C., and Dannenberg, R.
\newblock Controllable deep melody generation via hierarchical music structure representation.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}, 2021.

\bibitem[Defferrard et~al.(2017)Defferrard, Benzi, Vandergheynst, and Bresson]{fma_dataset}
Defferrard, M., Benzi, K., Vandergheynst, P., and Bresson, X.
\newblock {FMA}: A dataset for music analysis.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}, 2017.
\newblock URL \url{https://arxiv.org/abs/1612.01840}.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal2021diffusion}
Dhariwal, P. and Nichol, A.
\newblock Diffusion models beat {GANs} on image synthesis.
\newblock \emph{Neural Information Processing Systems (NeurIPS)}, 34, 2021.

\bibitem[Dhariwal et~al.(2020)Dhariwal, Jun, Payne, Kim, Radford, and Sutskever]{dhariwal2020jukebox}
Dhariwal, P., Jun, H., Payne, C., Kim, J.~W., Radford, A., and Sutskever, I.
\newblock Jukebox: A generative model for music.
\newblock \emph{arXiv:2005.00341}, 2020.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
Dinh, L., Krueger, D., and Bengio, Y.
\newblock {NICE}: Non-linear independent components estimation.
\newblock \emph{International Conference on Learning Representations (ICLR) Workshop}, 2014.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Dinh, L., Sohl-Dickstein, J., and Bengio, S.
\newblock Density estimation using real {NVP}.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2016.

\bibitem[Dong et~al.(2018)Dong, Hsiao, Yang, and Yang]{dong2018musegan}
Dong, H.-W., Hsiao, W.-Y., Yang, L.-C., and Yang, Y.-H.
\newblock Muse{GAN}: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, number~1, 2018.

\bibitem[Erickson(1975)]{erickson1975sound}
Erickson, R.
\newblock \emph{Sound structure in music}.
\newblock Univ of California Press, 1975.

\bibitem[Forsgren \& Martiros(2022)Forsgren and Martiros]{forsgren2022riffusion}
Forsgren, S. and Martiros, H.
\newblock {Riffusion: Stable diffusion for real-time music generation}, 2022.
\newblock URL \url{https://riffusion.com/about}.

\bibitem[Gal et~al.(2022)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or]{gal2022textual}
Gal, R., Alaluf, Y., Atzmon, Y., Patashnik, O., Bermano, A.~H., Chechik, G., and Cohen-Or, D.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion, 2022.

\bibitem[Garcia et~al.(2023)Garcia, Seetharaman, Kumar, and Pardo]{garcia2023vampnet}
Garcia, H.~F., Seetharaman, P., Kumar, R., and Pardo, B.
\newblock {VampNet}: Music generation via masked acoustic token modeling.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}, 2023.

\bibitem[Gui et~al.(2023)Gui, Gamper, Braun, and Emmanouilidou]{Gui2023AdaptingFA}
Gui, A., Gamper, H., Braun, S., and Emmanouilidou, D.
\newblock Adapting frechet audio distance for generative music evaluation.
\newblock \emph{ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:265018955}.

\bibitem[Gupta et~al.(2023)Gupta, Yu, Sohn, Gu, Hahn, Li, Essa, Jiang, and Lezama]{Gupta2023PhotorealisticVG}
Gupta, A., Yu, L., Sohn, K., Gu, X., Hahn, M., Li, F.-F., Essa, I., Jiang, L., and Lezama, J.
\newblock Photorealistic video generation with diffusion models.
\newblock 2023.

\bibitem[Hawthorne et~al.(2022)Hawthorne, Simon, Roberts, Zeghidour, Gardner, Manilow, and Engel]{hawthorne2022multi}
Hawthorne, C., Simon, I., Roberts, A., Zeghidour, N., Gardner, J., Manilow, E., and Engel, J.
\newblock Multi-instrument music synthesis with spectrogram diffusion.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2016.

\bibitem[Hertz et~al.(2022)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and Cohen-Or]{hertz2022prompt}
Hertz, A., Mokady, R., Tenenbaum, J., Aberman, K., Pritch, Y., and Cohen-Or, D.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock \emph{arXiv preprint arXiv:2208.01626}, 2022.

\bibitem[Ho \& Salimans(2021)Ho and Salimans]{ho2022classifier}
Ho, J. and Salimans, T.
\newblock Classifier-free diffusion guidance.
\newblock In \emph{NeurIPS Workshop on Deep Gen. Models and Downstream Applications}, 2021.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Neural Information Processing Systems (NeurIPS)}, 33, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and Fleet]{ho2022video}
Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D.~J.
\newblock Video diffusion models.
\newblock \emph{arXiv:2204.03458}, 2022.

\bibitem[Huang et~al.(2023{\natexlab{a}})Huang, Park, Wang, Denk, Ly, Chen, Zhang, Zhang, Yu, Frank, et~al.]{huang2023noise2music}
Huang, Q., Park, D.~S., Wang, T., Denk, T.~I., Ly, A., Chen, N., Zhang, Z., Zhang, Z., Yu, J., Frank, C., et~al.
\newblock Noise2{M}usic: Text-conditioned music generation with diffusion models.
\newblock \emph{arXiv:2302.03917}, 2023{\natexlab{a}}.

\bibitem[Huang et~al.(2023{\natexlab{b}})Huang, Huang, Yang, Ren, Liu, Li, Ye, Liu, Yin, and Zhao]{huang2023make}
Huang, R., Huang, J., Yang, D., Ren, Y., Liu, L., Li, M., Ye, Z., Liu, J., Yin, X., and Zhao, Z.
\newblock Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models.
\newblock \emph{arXiv preprint arXiv:2301.12661}, 2023{\natexlab{b}}.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and Laine]{karras2022elucidating}
Karras, T., Aittala, M., Aila, T., and Laine, S.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Karunratanakul et~al.(2023)Karunratanakul, Preechakul, Aksan, Beeler, Suwajanakorn, and Tang]{karunratanakul2023optimizing}
Karunratanakul, K., Preechakul, K., Aksan, E., Beeler, T., Suwajanakorn, S., and Tang, S.
\newblock Optimizing diffusion noise can serve as universal motion priors.
\newblock \emph{arXiv preprint arXiv:2312.11994}, 2023.

\bibitem[Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and Irani]{kawar2023imagic}
Kawar, B., Zada, S., Lang, O., Tov, O., Chang, H., Dekel, T., Mosseri, I., and Irani, M.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[Kilgour et~al.(2018)Kilgour, Zuluaga, Roblek, and Sharifi]{kilgour2018fr}
Kilgour, K., Zuluaga, M., Roblek, D., and Sharifi, M.
\newblock Frechet audio distance: A metric for evaluating music enhancement algorithms.
\newblock \emph{arXiv:1812.08466}, 2018.

\bibitem[Kim et~al.(2023)Kim, Lai, Liao, Murata, Takida, Uesaka, He, Mitsufuji, and Ermon]{Kim2023ConsistencyTM}
Kim, D., Lai, C.-H., Liao, W.-H., Murata, N., Takida, Y., Uesaka, T., He, Y., Mitsufuji, Y., and Ermon, S.
\newblock Consistency trajectory models: Learning probability flow ode trajectory of diffusion.
\newblock \emph{ArXiv}, abs/2310.02279, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:263622294}.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2013.

\bibitem[Kumar et~al.(2023)Kumar, Seetharaman, Luebs, Kumar, and Kumar]{kumar2023high}
Kumar, R., Seetharaman, P., Luebs, A., Kumar, I., and Kumar, K.
\newblock High-fidelity audio compression with improved {RVQGAN}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Lee et~al.(2022)Lee, Ping, Ginsburg, Catanzaro, and Yoon]{lee2022bigvgan}
Lee, S.-g., Ping, W., Ginsburg, B., Catanzaro, B., and Yoon, S.
\newblock Bigvgan: A universal neural vocoder with large-scale training.
\newblock \emph{arXiv preprint arXiv:2206.04658}, 2022.

\bibitem[Leemput et~al.(2019)Leemput, Teuwen, Ginneken, and Manniesing]{vandeLeemput2019MemCNN}
Leemput, S. C.~v., Teuwen, J., Ginneken, B.~v., and Manniesing, R.
\newblock Memcnn: A python/pytorch package for creating memory-efficient invertible neural networks.
\newblock \emph{Journal of Open Source Software}, 2019.
\newblock ISSN 2475-9066.
\newblock \doi{10.21105/joss.01576}.

\bibitem[Levy et~al.(2023)Levy, Giorgi, Weers, Katharopoulos, and Nickson]{Levy2023ControllableMP}
Levy, M., Giorgi, B.~D., Weers, F., Katharopoulos, A., and Nickson, T.
\newblock Controllable music production with diffusion models and guidance gradients.
\newblock \emph{ArXiv}, abs/2311.00613, 2023.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Chen, Yuan, Mei, Liu, Mandic, Wang, and Plumbley]{liu2023audioldm}
Liu, H., Chen, Z., Yuan, Y., Mei, X., Liu, X., Mandic, D., Wang, W., and Plumbley, M.~D.
\newblock Audio{LDM}: Text-to-audio generation with latent diffusion models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Tian, Yuan, Liu, Mei, Kong, Wang, Wang, Wang, and Plumbley]{liu2023audioldm2}
Liu, H., Tian, Q., Yuan, Y., Liu, X., Mei, X., Kong, Q., Wang, Y., Wang, W., Wang, Y., and Plumbley, M.~D.
\newblock {AudioLDM} 2: Learning holistic audio generation with self-supervised pretraining.
\newblock \emph{arXiv preprint arXiv:2308.05734}, 2023{\natexlab{b}}.

\bibitem[Lu et~al.(2022)Lu, Zhou, Bao, Chen, Li, and Zhu]{Lu2022DPMSolverFS}
Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J.
\newblock Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models.
\newblock \emph{ArXiv}, abs/2211.01095, 2022.

\bibitem[Luo et~al.(2023)Luo, Tan, Huang, Li, and Zhao]{Luo2023LatentCM}
Luo, S., Tan, Y., Huang, L., Li, J., and Zhao, H.
\newblock Latent consistency models: Synthesizing high-resolution images with few-step inference.
\newblock \emph{ArXiv}, abs/2310.04378, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:263831037}.

\bibitem[McFee \& Ellis(2014)McFee and Ellis]{mcfee2014analyzing}
McFee, B. and Ellis, D.
\newblock Analyzing song structure with spectral clustering.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}. Citeseer, 2014.

\bibitem[McFee et~al.(2010)McFee, Barrington, and Lanckriet]{mcfee2010learning}
McFee, B., Barrington, L., and Lanckriet, G.~R.
\newblock Learning similarity from collaborative filters.
\newblock In \emph{International Society for Music Information Retrieval (ISMIR)}, 2010.

\bibitem[Mokady et~al.(2023)Mokady, Hertz, Aberman, Pritch, and Cohen-Or]{mokady2023null}
Mokady, R., Hertz, A., Aberman, K., Pritch, Y., and Cohen-Or, D.
\newblock Null-text inversion for editing real images using guided diffusion models.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[M{\"u}ller(2015)]{muller2015fundamentals}
M{\"u}ller, M.
\newblock \emph{Fundamentals of music processing: Audio, analysis, algorithms, applications}.
\newblock Springer, 2015.

\bibitem[Pan et~al.(2023)Pan, Gherardi, Xie, and Huang]{pan2023effective}
Pan, Z., Gherardi, R., Xie, X., and Huang, S.
\newblock Effective real image editing with accelerated iterative diffusion inversion.
\newblock In \emph{IEEE/CVF International Conference on Computer Vision (CVPR)}, 2023.

\bibitem[Poole et~al.(2022)Poole, Jain, Barron, and Mildenhall]{poole2022dreamfusion}
Poole, B., Jain, A., Barron, J.~T., and Mildenhall, B.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock \emph{arXiv}, 2022.

\bibitem[Prabhudesai et~al.(2023)Prabhudesai, Goyal, Pathak, and Fragkiadaki]{Prabhudesai2023AligningTD}
Prabhudesai, M., Goyal, A., Pathak, D., and Fragkiadaki, K.
\newblock Aligning text-to-image diffusion models with reward backpropagation.
\newblock \emph{ArXiv}, abs/2310.03739, 2023.

\bibitem[Preechakul et~al.(2022)Preechakul, Chatthee, Wizadwongsa, and Suwajanakorn]{preechakul2022diffusion}
Preechakul, K., Chatthee, N., Wizadwongsa, S., and Suwajanakorn, S.
\newblock Diffusion autoencoders: Toward a meaningful and decodable representation.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{ronneberger2022convolutional}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-{N}et: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical Image Computing and Computer Assisted Interventions (MICCAI)}, 2015.

\bibitem[Ruiz et~al.(2023)Ruiz, Li, Jampani, Pritch, Rubinstein, and Aberman]{ruiz2023dreambooth}
Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., and Aberman, K.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[Saharia et~al.(2022{\natexlab{a}})Saharia, Chan, Chang, Lee, Ho, Salimans, Fleet, and Norouzi]{saharia2022palette}
Saharia, C., Chan, W., Chang, H., Lee, C., Ho, J., Salimans, T., Fleet, D., and Norouzi, M.
\newblock Palette: Image-to-image diffusion models.
\newblock In \emph{ACM SIGGRAPH Conference Proceedings}, 2022{\natexlab{a}}.

\bibitem[Saharia et~al.(2022{\natexlab{b}})Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.~L., Ghasemipour, K., Gontijo~Lopes, R., Karagol~Ayan, B., Salimans, T., et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Neural Information Processing Systems (NeurIPS)}, 35, 2022{\natexlab{b}}.

\bibitem[Schneider et~al.(2023)Schneider, Jin, and Sch{\"o}lkopf]{schneider2023mo}
Schneider, F., Jin, Z., and Sch{\"o}lkopf, B.
\newblock Mo$\backslash$\^{} usai: Text-to-music generation with long-context latent diffusion.
\newblock \emph{arXiv preprint arXiv:2301.11757}, 2023.

\bibitem[Si et~al.(2023)Si, Huang, Jiang, and Liu]{Si2023FreeUFL}
Si, C., Huang, Z., Jiang, Y., and Liu, Z.
\newblock Freeu: Free lunch in diffusion u-net.
\newblock \emph{ArXiv}, abs/2309.11497, 2023.

\bibitem[Simonetta et~al.(2018)Simonetta, Carnovalini, Orio, and Rod{\`a}]{simonetta2018symbolic}
Simonetta, F., Carnovalini, F., Orio, N., and Rod{\`a}, A.
\newblock Symbolic music similarity through a graph-based representation.
\newblock In \emph{Audio Mostly 2018 on Sound in Immersion and Emotion}. 2018.

\bibitem[Skalse et~al.(2022)Skalse, Howe, Krasheninnikov, and Krueger]{skalse2022defining}
Skalse, J., Howe, N., Krasheninnikov, D., and Krueger, D.
\newblock Defining and characterizing reward gaming.
\newblock \emph{Neural Information Processing Systems (NeuraIPS)}, 35, 2022.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2020.

\bibitem[Stevens et~al.(1937)Stevens, Volkmann, and Newman]{stevens1937scale}
Stevens, S.~S., Volkmann, J., and Newman, E.~B.
\newblock A scale for the measurement of the psychological magnitude pitch.
\newblock \emph{Journal of the Acoustical Society of America (JASA)}, 1937.

\bibitem[Wallace et~al.(2023{\natexlab{a}})Wallace, Gokul, Ermon, and Naik]{Wallace2023EndtoEndDL}
Wallace, B., Gokul, A., Ermon, S., and Naik, N.~V.
\newblock End-to-end diffusion latent optimization improves classifier guidance.
\newblock \emph{IEEE/CVF International Conference on Computer Vision (ICCV)}, abs/2303.13703, 2023{\natexlab{a}}.

\bibitem[Wallace et~al.(2023{\natexlab{b}})Wallace, Gokul, and Naik]{wallace2023edict}
Wallace, B., Gokul, A., and Naik, N.
\newblock {EDICT}: Exact diffusion inversion via coupled transformations.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023{\natexlab{b}}.

\bibitem[Watson et~al.(2022)Watson, Chan, Martin-Brualla, Ho, Tagliasacchi, and Norouzi]{Watson2022NovelVS}
Watson, D., Chan, W., Martin-Brualla, R., Ho, J., Tagliasacchi, A., and Norouzi, M.
\newblock Novel view synthesis with diffusion models.
\newblock \emph{ArXiv}, abs/2210.04628, 2022.

\bibitem[Wu et~al.(2023{\natexlab{a}})Wu, Donahue, Watanabe, and Bryan]{Wu2023MusicCM}
Wu, S.-L., Donahue, C., Watanabe, S., and Bryan, N.~J.
\newblock Music controlnet: Multiple time-varying controls for music generation.
\newblock \emph{ArXiv}, abs/2311.07069, 2023{\natexlab{a}}.

\bibitem[Wu et~al.(2023{\natexlab{b}})Wu, Chen, Zhang, Hui, Berg-Kirkpatrick, and Dubnov]{wu2023large}
Wu, Y., Chen, K., Zhang, T., Hui, Y., Berg-Kirkpatrick, T., and Dubnov, S.
\newblock Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation.
\newblock In \emph{IEEE International Conference on Audio, Speech and Signal Processing (ICASSP)}, 2023{\natexlab{b}}.

\bibitem[Xia et~al.(2021)Xia, Zhang, Yang, Xue, Zhou, and Yang]{Xia2021GANIA}
Xia, W., Zhang, Y., Yang, Y., Xue, J.-H., Zhou, B., and Yang, M.-H.
\newblock Gan inversion: A survey.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45, 2021.

\bibitem[Yu et~al.(2023)Yu, Wang, Zhao, Ghanem, and Zhang]{yu2023freedom}
Yu, J., Wang, Y., Zhao, C., Ghanem, B., and Zhang, J.
\newblock Freedom: Training-free energy-guided conditional diffusion model.
\newblock \emph{IEEE/CVF International Conference on Computer Vision (ICCV)}, 2023.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and Tagliasacchi]{zeghidour2021soundstream}
Zeghidour, N., Luebs, A., Omran, A., Skoglund, J., and Tagliasacchi, M.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)}, 30, 2021.

\bibitem[Zhang et~al.(2023)Zhang, Rao, and Agrawala]{zhang2023adding}
Zhang, L., Rao, A., and Agrawala, M.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{IEEE/CVF International Conference on Computer Vision (ICCV)}, 2023.

\bibitem[Zhao et~al.(2023)Zhao, Chen, Chen, Bao, Hao, Yuan, and Wong]{zhao2023uni}
Zhao, S., Chen, D., Chen, Y.-C., Bao, J., Hao, S., Yuan, L., and Wong, K.-Y.~K.
\newblock Uni-{C}ontrol{N}et: All-in-one control to text-to-image diffusion models.
\newblock \emph{arXiv:2305.16322}, 2023.

\bibitem[Zhu et~al.(2024)Zhu, Caceres, Duan, and Bryan]{Zhu2024MusicHiFiFH}
Zhu, G., Caceres, J.-P., Duan, Z., and Bryan, N.~J.
\newblock Musichifi: Fast high-fidelity stereo vocoding.
\newblock \emph{ArXiv}, abs/2403.10493, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:268510221}.

\end{thebibliography}
