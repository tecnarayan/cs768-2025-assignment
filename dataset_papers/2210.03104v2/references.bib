@incollection{barto2013intrinsic,
  title={Intrinsic motivation and reinforcement learning},
  author={Barto, Andrew G},
  booktitle={Intrinsically motivated learning in natural and artificial systems},
  pages={17--47},
  year={2013},
  publisher={Springer}
}

@article{lee2019smm,
  author    = {Lisa Lee and
               Benjamin Eysenbach and
               Emilio Parisotto and
               Eric P. Xing and
               Sergey Levine and
               Ruslan Salakhutdinov},
  title     = {Efficient Exploration via State Marginal Matching},
  journal   = {CoRR},
  volume    = {abs/1906.05274},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.05274},
  eprinttype = {arXiv},
  eprint    = {1906.05274},
  timestamp = {Sat, 23 Jan 2021 01:14:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-05274.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{thrun98metalearning,
  editor    = {Sebastian Thrun and
               Lorien Y. Pratt},
  title     = {Learning to Learn},
  publisher = {Springer},
  year      = {1998},
  url       = {https://doi.org/10.1007/978-1-4615-5529-2},
  doi       = {10.1007/978-1-4615-5529-2},
  isbn      = {978-1-4613-7527-2},
  timestamp = {Thu, 16 May 2019 19:18:36 +0200},
  biburl    = {https://dblp.org/rec/books/sp/1998TP.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{chentanez2005intrinsically,
  title={Intrinsically motivated reinforcement learning},
  author={Chentanez, Nuttapong and Barto, Andrew G and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={1281--1288},
  year={2005}
}

@inproceedings{LGPL,
  author    = {John D. Co{-}Reyes and
               Abhishek Gupta and
               Suvansh Sanjeev and
               Nick Altieri and
               Jacob Andreas and
               John DeNero and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Guiding Policies with Language via Meta-Learning},
  booktitle = {ICLR},
  year      = {2019},
}

@article{narasimhan,
  author    = {Karthik Narasimhan and
               Regina Barzilay and
               Tommi S. Jaakkola},
  title     = {Deep Transfer in Reinforcement Learning by Language Grounding},
  journal   = {CoRR},
  volume    = {abs/1708.00133},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.00133},
  archivePrefix = {arXiv},
  eprint    = {1708.00133},
  timestamp = {Mon, 13 Aug 2018 16:48:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-00133.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{eisenstein,
  author    = {Jacob Eisenstein and
               James Clarke and
               Dan Goldwasser and
               Dan Roth},
  title     = {Reading to Learn: Constructing Features from Semantic Abstracts},
  booktitle = {EMNL},
  year      = {2009},
}

@inproceedings{minirts,
  author    = {Hengyuan Hu and
               Denis Yarats and
               Qucheng Gong and
               Yuandong Tian and
               Mike Lewis},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Hierarchical Decision Making by Generating and Following Natural Language
               Instructions},
  booktitle = {NeurIPS},
  year      = {2019},
}

@inproceedings{HAL,
  author    = {Yiding Jiang and
               Shixiang Gu and
               Kevin Murphy and
               Chelsea Finn},
  title     = {Language as an Abstraction for Hierarchical Deep Reinforcement Learning},
  booktitle = {NeurIPS},
  year      = {2019},
}

@inproceedings{L3,
  author    = {Jacob Andreas and
               Dan Klein and
               Sergey Levine},
  editor    = {Marilyn A. Walker and
               Heng Ji and
               Amanda Stent},
  title     = {Learning with Latent Language},
  booktitle = {NAACL},
  year      = {2018},
}

@inproceedings{draggn,
  author    = {Siddharth Karamcheti and
               Edward C. Williams and
               Dilip Arumugam and
               Mina Rhee and
               Nakul Gopalan and
               Lawson L. S. Wong and
               Stefanie Tellex},
  editor    = {Mohit Bansal and
               Cynthia Matuszek and
               Jacob Andreas and
               Yoav Artzi and
               Yonatan Bisk},
  title     = {A Tale of Two DRAGGNs: {A} Hybrid Approach for Interpreting Action-Oriented
               and Goal-Oriented Instructions},
  booktitle = {RoboNLP@ACL},
  year      = {2017},
}
@inproceedings{meibansal,
  author    = {Hongyuan Mei and
               Mohit Bansal and
               Matthew R. Walter},
  editor    = {Dale Schuurmans and
               Michael P. Wellman},
  title     = {Listen, Attend, and Walk: Neural Mapping of Navigational Instructions
               to Action Sequences},
  booktitle = {AAAI},
  year      = {2016},
}


@article{artzizetnav,
  author    = {Yoav Artzi and
               Luke Zettlemoyer},
  title     = {Weakly Supervised Learning of Semantic Parsers for Mapping Instructions
               to Actions},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {1},
  pages     = {49--62},
  year      = {2013},
  url       = {https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/view/27},
  timestamp = {Wed, 17 Feb 2021 21:55:32 +0100},
  biburl    = {https://dblp.org/rec/journals/tacl/ArtziZ13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{chenmooneynav,
  author    = {David L. Chen and
               Raymond J. Mooney},
  editor    = {Wolfram Burgard and
               Dan Roth},
  title     = {Learning to Interpret Natural Language Navigation Instructions from
               Observations},
  booktitle = {AAAI},
  year      = {2011}
}

@inproceedings{languagesurvey,
  author    = {Jelena Luketina and
               Nantas Nardelli and
               Gregory Farquhar and
               Jakob N. Foerster and
               Jacob Andreas and
               Edward Grefenstette and
               Shimon Whiteson and
               Tim Rockt{\"{a}}schel},
  title     = {A Survey of Reinforcement Learning Informed by Natural Language},
  booktitle = {IJCAI},
  year      = {2019},
}

@inproceedings{surveyhuman,
  author    = {Ruohan Zhang and
               Faraz Torabi and
               Lin Guan and
               Dana H. Ballard and
               Peter Stone},
  editor    = {Sarit Kraus},
  title     = {Leveraging Human Guidance for Deep Reinforcement Learning Tasks},
  booktitle = {IJCAI},
  year      = {2019},
}

@inproceedings{deeptamer,
  author    = {Garrett Warnell and
               Nicholas R. Waytowich and
               Vernon Lawhern and
               Peter Stone},
  title     = {Deep {TAMER:} Interactive Agent Shaping in High-Dimensional State
               Spaces},
  booktitle = {AAAI},
  year      = {2018},
}

@inproceedings{coach,
  author    = {James MacGlashan and
               Mark K. Ho and
               Robert Tyler Loftin and
               Bei Peng and
               Guan Wang and
               David L. Roberts and
               Matthew E. Taylor and
               Michael L. Littman},
  title     = {Interactive Learning from Policy-Dependent Human Feedback},
  booktitle = {ICML},
  year      = {2017},
}



@article{attentionreward,
	Abstract = {Infants{\textquoteright} remarkable learning abilities allow them to rapidly acquire many complex skills. It has been suggested that infants achieve this learning by optimally allocating their attention to relevant stimuli in the environment, but the underlying mechanisms remain poorly understood. Here, we modeled infants{\textquoteright} looking behavior during a learning task through an ideal learner that quantified the informational structure of environmental stimuli. We show that saccadic latencies, looking time, and time spent engaged with a stimulus sequence are explained by the properties of the learning environments, including the level of surprise of the stimulus, overall predictability of the environment, and progress in learning the environmental structure. These findings reveal the factors that shape infants{\textquoteright} advanced learning, emphasizing their predisposition to seek out stimuli that maximize learning.},
	Author = {Poli, F. and Serino, G. and Mars, R. B. and Hunnius, S.},
	Doi = {10.1126/sciadv.abb5053},
	Elocation-Id = {eabb5053},
	Eprint = {https://advances.sciencemag.org/content/6/39/eabb5053.full.pdf},
	Journal = {Science Advances},
	Number = {39},
	Publisher = {American Association for the Advancement of Science},
	Title = {Infants tailor their attention to maximize learning},
	Url = {https://advances.sciencemag.org/content/6/39/eabb5053},
	Volume = {6},
	Year = {2020},
	Bdsk-Url-1 = {https://advances.sciencemag.org/content/6/39/eabb5053},
	Bdsk-Url-2 = {https://doi.org/10.1126/sciadv.abb5053}}


@article{gesturelanguage,
	Abstract = {Two experiments investigated gesture as a form of external support for spoken language comprehension. In both experiments, children selected blocks according to a set of videotaped instructions. Across trials, the instructions were given using no gesture, gestures that reinforced speech, and gestures that conflicted with speech. Experiment 1 used spoken messages that were complex for preschool children but not for kindergarten children. Reinforcing gestures facilitated speech comprehension for preschool children but not for kindergarten children, and conflicting gestures hindered comprehension for kindergarten children but not for preschool children. Experiment 2 tested preschool children with simpler spoken messages. Unlike Experiment 1, preschool children's comprehension was not facilitated by reinforcing gestures. However, children's comprehension also was not hindered by conflicting gestures. Thus, the effects of gesture on speech comprehension depend both on the relation of gesture to speech, and on the complexity of the spoken message.},
	Author = {McNeil, Nicole M. and Alibali, Martha W. and Evans, Julia L.},
	Da = {2000/06/01},
	Date-Added = {2021-05-28 14:25:38 +0000},
	Date-Modified = {2021-05-28 14:25:38 +0000},
	Doi = {10.1023/A:1006657929803},
	Id = {McNeil2000},
	Isbn = {1573-3653},
	Journal = {Journal of Nonverbal Behavior},
	Number = {2},
	Pages = {131--150},
	Title = {The Role of Gesture in Children's Comprehension of Spoken Language:Now They Need It, Now They Don't},
	Ty = {JOUR},
	Url = {https://doi.org/10.1023/A:1006657929803},
	Volume = {24},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1023/A:1006657929803}}


@article{deepcoach,
  author    = {Dilip Arumugam and
               Jun Ki Lee and
               Sophie Saskin and
               Michael L. Littman},
  title     = {Deep Reinforcement Learning from Policy-Dependent Human Feedback},
  journal   = {CoRR},
  volume    = {abs/1902.04257},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.04257},
  archivePrefix = {arXiv},
  eprint    = {1902.04257},
  timestamp = {Tue, 21 May 2019 18:03:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-04257.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{tamer,
 author="W.~Bradley Knox and Peter Stone",
 title="{TAMER}: {T}raining an {A}gent {M}anually via {E}valuative {R}einforcement",
 booktitle="IEEE 7th International Conference on Development and Learning",
 month="August",
 year="2008",
 abstract={Though computers have surpassed humans at many tasks, especially
  computationally intensive ones, there are many tasks for which human
  expertise remains necessary and/or useful.  For such tasks, it is
  desirable for a human to be able to transmit knowledge to a learning
  agent as quickly and effortlessly as possible, and, ideally, without
  any knowledge of the details of the agent's learning process.  This
  paper proposes a general framework called Training an Agent
  Manually via Evaluative Reinforcement (TAMER) that allows a human to
  train a learning agent to perform a common class of complex tasks
  simply by giving scalar reward signals in response to the agent's
  observed actions.  Specifically, in sequential decision making tasks,
  an agent models the human's reward function and chooses actions that
  it predicts will receive the most reward.  Our novel algorithm is
  fully implemented and tested on the game Tetris.  Leveraging the human
  trainers' feedback, the agent learns to clear an average of more than
  50 lines by its third game, an order of magnitude faster than the best
  autonomous learning agents.},
 wwwnote={<a href="http://www.icdl08.org/">ICDL-2008</a><br>Also available in <a href="http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=4640795&isYear=2008&count=52&page=1&ResultStart=25">IEEE Xplore</a>, 9-12 Aug. 2008 Pages:292 - 297},
}


@inproceedings{christianopreferences,
  author    = {Paul F. Christiano and
               Jan Leike and
               Tom B. Brown and
               Miljan Martic and
               Shane Legg and
               Dario Amodei},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {Deep Reinforcement Learning from Human Preferences},
  booktitle = {NeurIPS},
  year      = {2017},
}

@inproceedings{rewardpref,
  author    = {Borja Ibarz and
               Jan Leike and
               Tobias Pohlen and
               Geoffrey Irving and
               Shane Legg and
               Dario Amodei},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Reward learning from human preferences and demonstrations in Atari},
  booktitle = {NeurIPS},
  year      = {2018},
}

@inproceedings{phri,
  author    = {Andrea Bajcsy and
               Dylan P. Losey and
               Marcia K. O'Malley and
               Anca D. Dragan},
  title     = {Learning Robot Objectives from Physical Human Interaction},
  booktitle = {Conference on Robot Learning (CoRL)},
  year      = {2017},
}


@article{mundyjoint,
  author    = {Peter Mundy and
               William Jarrold},
  title     = {Infant joint attention, neural networks and social cognition},
  journal   = {Neural Networks},
  volume    = {23},
  number    = {8-9},
  pages     = {985--997},
  year      = {2010},
  url       = {https://doi.org/10.1016/j.neunet.2010.08.009},
  doi       = {10.1016/j.neunet.2010.08.009},
  timestamp = {Wed, 14 Nov 2018 10:30:04 +0100},
  biburl    = {https://dblp.org/rec/journals/nn/MundyJ10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{klyubin2005empowerment,
  title={Empowerment: A universal agent-centric measure of control},
  author={Klyubin, Alexander S and Polani, Daniel and Nehaniv, Chrystopher L},
  booktitle={2005 IEEE Congress on Evolutionary Computation},
  volume={1},
  pages={128--135},
  year={2005},
  organization={IEEE}
}

@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

@inproceedings{schmidhuber1991curious,
  title={Curious model-building control systems},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. international joint conference on neural networks},
  pages={1458--1463},
  year={1991}
}

@article{baranes2013active,
  title={Active learning of inverse models with intrinsically motivated goal exploration in robots},
  author={Baranes, Adrien and Oudeyer, Pierre-Yves},
  journal={Robotics and Autonomous Systems},
  volume={61},
  number={1},
  pages={49--73},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@article{racaniere2019automated,
  title={Automated curricula through setter-solver interactions},
  author={Racaniere, Sebastien and Lampinen, Andrew K and Santoro, Adam and Reichert, David P and Firoiu, Vlad and Lillicrap, Timothy P},
  journal={arXiv preprint arXiv:1909.12892},
  year={2019}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009},
  organization={ACM}
}

@article{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1707.05300},
  year={2017}
}

@article{florensa2017automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1705.06366},
  year={2017}
}

@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2817--2826},
  year={2017},
  organization={JMLR. org}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald},
  year={1995}
}

@article{openaifive2018,
  title={OpenAI Five.},
  author={OpenAI},
  journal={arxiv},
  year={2018}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{jaderberg2019human,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{baker2019emergent,
  title={Emergent tool use from multi-agent autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  journal={arXiv preprint arXiv:1909.07528},
  year={2019}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  organization={Citeseer}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International Conference on Machine Learning},
  pages={1312--1320},
  year={2015}
}

@article{xu2020continual,
  title={Continual Learning of Control Primitives: Skill Discovery via Reset-Games},
  author={Xu, Kelvin and Verma, Siddharth and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.05286},
  year={2020}
}

@article{fu2017learning,
  title={Learning robust rewards with adversarial inverse reinforcement learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  journal={arXiv preprint arXiv:1710.11248},
  year={2017}
}


@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={arXiv preprint arXiv:1606.03476},
  year={2016}
}


@article{mohamed2016learning,
  title={Learning in implicit generative models},
  author={Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1610.03483},
  year={2016}
}

@book{sugiyama2012density,
  title={Density ratio estimation in machine learning},
  author={Sugiyama, Masashi and Suzuki, Taiji and Kanamori, Takafumi},
  year={2012},
  publisher={Cambridge University Press}
}


@article{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  journal={arXiv preprint arXiv:1606.00709},
  year={2016}
}


@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}


@article{hadsell2020embracing,
  title={Embracing Change: Continual Learning in Deep Neural Networks},
  author={Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A and Pascanu, Razvan},
  journal={Trends in Cognitive Sciences},
  year={2020},
  publisher={Elsevier}
}


@article{gupta2021reset,
  title={Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention},
  author={Gupta, Abhishek and Yu, Justin and Zhao, Tony Z and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.11203},
  year={2021}
}


@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}
@article{veeriah2018many,
  title={Many-goals reinforcement learning},
  author={Veeriah, Vivek and Oh, Junhyuk and Singh, Satinder},
  journal={arXiv preprint arXiv:1806.09605},
  year={2018}
}

@inproceedings{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9191--9200},
  year={2018}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{lee2019efficient,
  title={Efficient exploration via state marginal matching},
  author={Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1906.05274},
  year={2019}
}


@article{d4rl,
  author    = {Justin Fu and
               Aviral Kumar and
               Ofir Nachum and
               George Tucker and
               Sergey Levine},
  title     = {{D4RL:} Datasets for Deep Data-Driven Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2004.07219},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.07219},
  archivePrefix = {arXiv},
  eprint    = {2004.07219},
  timestamp = {Tue, 21 Apr 2020 16:51:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-07219.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{waxmanmarkow,
   Author="Waxman, S. R.  and Markow, D. B. ",
   Title="{{W}ords as invitations to form categories: evidence from 12- to 13-month-old infants}",
   Journal="Cogn Psychol",
   Year="1995",
   Volume="29",
   Number="3",
   Pages="257--302",
   Month="Dec"
}


@inproceedings{babyai,
  author    = {Maxime Chevalier{-}Boisvert and
               Dzmitry Bahdanau and
               Salem Lahlou and
               Lucas Willems and
               Chitwan Saharia and
               Thien Huu Nguyen and
               Yoshua Bengio},
  title     = {BabyAI: {A} Platform to Study the Sample Efficiency of Grounded Language
               Learning},
  booktitle = {ICLR},
  year      = {2019},
}

@article{toolmaking,
	Abstract = {Hominin reliance on Oldowan stone tools---which appear from 2.5 mya and are believed to have been socially transmitted---has been hypothesized to have led to the evolution of teaching and language. Here we present an experiment investigating the efficacy of transmission of Oldowan tool-making skills along chains of adult human participants (N=184) using five different transmission mechanisms. Across six measures, transmission improves with teaching, and particularly with language, but not with imitation or emulation. Our results support the hypothesis that hominin reliance on stone tool-making generated selection for teaching and language, and imply that (i) low-fidelity social transmission, such as imitation/emulation, may have contributed to the \~{}700,000 year stasis of the Oldowan technocomplex, and (ii) teaching or proto-language may have been pre-requisites for the appearance of Acheulean technology. This work supports a gradual evolution of language, with simple symbolic communication preceding behavioural modernity by hundreds of thousands of years.},
	Author = {Morgan, T. J. H. and Uomini, N. T. and Rendell, L. E. and Chouinard-Thuly, L. and Street, S. E. and Lewis, H. M. and Cross, C. P. and Evans, C. and Kearney, R. and de la Torre, I. and Whiten, A. and Laland, K. N.},
	Da = {2015/01/13},
	Date-Added = {2021-05-28 07:13:41 +0000},
	Date-Modified = {2021-05-28 07:13:41 +0000},
	Doi = {10.1038/ncomms7029},
	Id = {Morgan2015},
	Isbn = {2041-1723},
	Journal = {Nature Communications},
	Number = {1},
	Pages = {6029},
	Title = {Experimental evidence for the co-evolution of hominin tool-making teaching and language},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/ncomms7029},
	Volume = {6},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1038/ncomms7029}}


@inproceedings{cultural,
  author    = {Sahil Chopra and
               Michael Henry Tessler and
               Noah D. Goodman},
  editor    = {Ashok K. Goel and
               Colleen M. Seifert and
               Christian Freksa},
  title     = {The first crank of the cultural ratchet: Learning and transmitting
               concepts through language},
  booktitle = {CogSci},
  year      = {2019},
}

@article{qtopt,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic
               Manipulation},
  journal   = {CoRR},
  volume    = {abs/1806.10293},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.10293},
  archivePrefix = {arXiv},
  eprint    = {1806.10293},
  timestamp = {Mon, 13 Aug 2018 16:48:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-10293.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dagger,
  author    = {St{\'{e}}phane Ross and
               Geoffrey J. Gordon and
               Drew Bagnell},
  editor    = {Geoffrey J. Gordon and
               David B. Dunson and
               Miroslav Dud{\'{\i}}k},
  title     = {A Reduction of Imitation Learning and Structured Prediction to No-Regret
               Online Learning},
  booktitle = {AISTATS},
  year      = {2011},
}

@inproceedings{drivinginstructions,
  author    = {Junha Roh and
               Chris Paxton and
               Andrzej Pronobis and
               Ali Farhadi and
               Dieter Fox},
  editor    = {Leslie Pack Kaelbling and
               Danica Kragic and
               Komei Sugiura},
  title     = {Conditional Driving from Natural Language Instructions},
  booktitle = {CoRL},
  year      = {2019},
}

@inproceedings{hitlsurvey2,
  author    = {Christian Arzate Cruz and
               Takeo Igarashi},
  editor    = {Ron Wakkary and
               Kristina Andersen and
               Will Odom and
               Audrey Desjardins and
               Marianne Graves Petersen},
  title     = {A Survey on Interactive Reinforcement Learning: Design Principles
               and Open Challenges},
  booktitle = {{DIS} '20: Designing Interactive Systems Conference 2020, Eindhoven,
               The Netherlands, July 6-10, 2020},
  pages     = {1195--1209},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3357236.3395525},
  doi       = {10.1145/3357236.3395525},
  timestamp = {Thu, 09 Jul 2020 16:08:49 +0200},
  biburl    = {https://dblp.org/rec/conf/ACMdis/CruzI20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hitlabel,
  author    = {David Abel and
               John Salvatier and
               Andreas Stuhlm{\"{u}}ller and
               Owain Evans},
  title     = {Agent-Agnostic Human-in-the-Loop Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1701.04079},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.04079},
  archivePrefix = {arXiv},
  eprint    = {1701.04079},
  timestamp = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/AbelSSE17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ziebartirl,
  author    = {Brian D. Ziebart and
               Andrew L. Maas and
               J. Andrew Bagnell and
               Anind K. Dey},
  editor    = {Dieter Fox and
               Carla P. Gomes},
  title     = {Maximum Entropy Inverse Reinforcement Learning},
  booktitle = {AAAI},
  year      = {2008},
}

@article{imitationsurvey,
  author    = {Ahmed Hussein and
               Mohamed Medhat Gaber and
               Eyad Elyan and
               Chrisina Jayne},
  title     = {Imitation Learning: {A} Survey of Learning Methods},
  journal   = {{ACM} Comput. Surv.},
  volume    = {50},
  number    = {2},
  pages     = {21:1--21:35},
  year      = {2017},
  url       = {https://doi.org/10.1145/3054912},
  doi       = {10.1145/3054912},
  timestamp = {Tue, 06 Nov 2018 12:50:49 +0100},
  biburl    = {https://dblp.org/rec/journals/csur/HusseinGEJ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{alvinn,
  author    = {Dean Pomerleau},
  editor    = {David S. Touretzky},
  title     = {{ALVINN:} An Autonomous Land Vehicle in a Neural Network},
  booktitle = {NeurIPS},
  year      = {1988},
}

@article{racaniere2019automated,
  title={Automated curricula through setter-solver interactions},
  author={Racaniere, Sebastien and Lampinen, Andrew K and Santoro, Adam and Reichert, David P and Firoiu, Vlad and Lillicrap, Timothy P},
  journal={arXiv preprint arXiv:1909.12892},
  year={2019}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{bacon2017option,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{schulman2015trpo,
  author    = {John Schulman and
               Sergey Levine and
               Pieter Abbeel and
               Michael I. Jordan and
               Philipp Moritz},
  title     = {Trust Region Policy Optimization},
  booktitle = {ICML},
  year      = {2015},
}

@article{openairubiks,
  author    = {OpenAI and
               Ilge Akkaya and
               Marcin Andrychowicz and
               Maciek Chociej and
               Mateusz Litwin and
               Bob McGrew and
               Arthur Petron and
               Alex Paino and
               Matthias Plappert and
               Glenn Powell and
               Raphael Ribas and
               Jonas Schneider and
               Nikolas Tezak and
               Jerry Tworek and
               Peter Welinder and
               Lilian Weng and
               Qiming Yuan and
               Wojciech Zaremba and
               Lei Zhang},
  title     = {Solving Rubik's Cube with a Robot Hand},
  journal   = {CoRR},
  volume    = {abs/1910.07113},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.07113},
  archivePrefix = {arXiv},
  eprint    = {1910.07113},
  timestamp = {Fri, 08 Nov 2019 12:50:47 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-07113.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3540--3549},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3303--3313},
  year={2018}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@inproceedings{niekumtrex,
  author    = {Daniel S. Brown and
               Wonjoon Goo and
               Scott Niekum},
  title     = {Better-than-Demonstrator Imitation Learning via Automatically-Ranked
               Demonstrations},
  booktitle = {Conference on Robot Learning (CoRL)},
  year      = {2019},
}

@inproceedings{zhu20ingredients,
  title={The Ingredients of Real World Robotic Reinforcement Learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{han2015learning,
  title={Learning compound multi-step controllers under unknown dynamics},
  author={Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6435--6442},
  organization={IEEE}
}

@article{precup2001temporal,
  title={Temporal abstraction in reinforcement learning.},
  author={Precup, Doina},
  year={2001}
}

@article{florensa2017stochastic,
  title={Stochastic neural networks for hierarchical reinforcement learning},
  author={Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.03012},
  year={2017}
}

@inproceedings{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart J},
  booktitle={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}


@article{sharma2019dynamics,
  title={Dynamics-aware unsupervised discovery of skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  journal={arXiv preprint arXiv:1907.01657},
  year={2019}
}

@article{eysenbach2018diversity,
  title={Diversity is all you need: Learning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.06070},
  year={2018}
}


@article{wiering1997hq,
  title={HQ-learning},
  author={Wiering, Marco and Schmidhuber, J{\"u}rgen},
  journal={Adaptive Behavior},
  volume={6},
  number={2},
  pages={219--246},
  year={1997},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@inproceedings{dayan1993feudal,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={271--278},
  year={1993}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2-3},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@article{osband2014generalization,
  title={Generalization and exploration via randomized value functions},
  author={Osband, Ian and Van Roy, Benjamin and Wen, Zheng},
  journal={arXiv preprint arXiv:1402.0635},
  year={2014}
}

@phdthesis{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath and others},
  year={2003}
}

@inproceedings{thodoroff2018temporal,
  title={Temporal regularization for Markov decision process},
  author={Thodoroff, Pierre and Durand, Audrey and Pineau, Joelle and Precup, Doina},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1779--1789},
  year={2018}
}

@article{chatzilygeroudis2018reset,
  title={Reset-free trial-and-error learning for robot damage recovery},
  author={Chatzilygeroudis, Konstantinos and Vassiliades, Vassilis and Mouret, Jean-Baptiste},
  journal={Robotics and Autonomous Systems},
  volume={100},
  pages={236--250},
  year={2018},
  publisher={Elsevier}
}

@article{laux2020deep,
  title={Deep Adversarial Reinforcement Learning for Object Disentangling},
  author={Laux, Melvin and Arenz, Oleg and Peters, Jan and Pajarinen, Joni},
  journal={arXiv preprint arXiv:2003.03779},
  year={2020}
}

@incollection{salge2014empowerment,
  title={Empowerment--an introduction},
  author={Salge, Christoph and Glackin, Cornelius and Polani, Daniel},
  booktitle={Guided Self-Organization: Inception},
  pages={67--114},
  year={2014},
  publisher={Springer}
}

@inproceedings{mohamed2015variational,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle={Advances in neural information processing systems},
  pages={2125--2133},
  year={2015}
}

@article{gregor2016variational,
  title={Variational intrinsic control},
  author={Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint arXiv:1611.07507},
  year={2016}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@inproceedings{yahya2017collective,
  title={Collective robot reinforcement learning with distributed asynchronous guided policy search},
  author={Yahya, Ali and Li, Adrian and Kalakrishnan, Mrinal and Chebotar, Yevgen and Levine, Sergey},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={79--86},
  year={2017},
  organization={IEEE}
}


@inproceedings{haarnoja2018composable,
  title={Composable deep reinforcement learning for robotic manipulation},
  author={Haarnoja, Tuomas and Pong, Vitchyr and Zhou, Aurick and Dalal, Murtaza and Abbeel, Pieter and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6244--6251},
  year={2018},
  organization={IEEE}
}


@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  year={2018}
}

@article{achiam2018variational,
  title={Variational option discovery algorithms},
  author={Achiam, Joshua and Edwards, Harrison and Amodei, Dario and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1807.10299},
  year={2018}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{schmidhuber2010formal,
  title={Formal theory of creativity, fun, and intrinsic motivation (1990--2010)},
  author={Schmidhuber, J{\"u}rgen},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={3},
  pages={230--247},
  year={2010},
  publisher={IEEE}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}
@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{fiez2019convergence,
  title={Convergence of learning dynamics in stackelberg games},
  author={Fiez, Tanner and Chasnov, Benjamin and Ratliff, Lillian J},
  journal={arXiv preprint arXiv:1906.01217},
  year={2019}
}

@article{fu2020d4rl,
  title={{D4RL}: Datasets for Deep Data-Driven Reinforcement
Learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={https://arxiv.org/abs/2004.07219},
  year={2020}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1825--1835},
  year={2017}
}

@article{jin2019local,
  title={What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?},
  author={Jin, Chi and Netrapalli, Praneeth and Jordan, Michael I},
  journal={arXiv preprint arXiv:1902.00618},
  year={2019}
}

@article{wang2019solving,
  title={On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach},
  author={Wang, Yuanhao and Zhang, Guodong and Ba, Jimmy},
  journal={arXiv preprint arXiv:1910.07512},
  year={2019}
}

@article{ha2020learning,
  title={Learning to walk in the real world with minimal human effort},
  author={Ha, Sehoon and Xu, Peng and Tan, Zhenyu and Levine, Sergey and Tan, Jie},
  journal={arXiv preprint arXiv:2002.08550},
  year={2020}
}

@article{balduzzi2018mechanics,
  title={The mechanics of n-player differentiable games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  journal={arXiv preprint arXiv:1802.05642},
  year={2018}
}

@book{von1934market,
  title={Marktform und Gleichgewicht},
  author={Von Stackelberg, Heinrich},
  year={1934},
}

@article{colson2007overview,
  title={An overview of bilevel optimization},
  author={Colson, Beno{\^\i}t and Marcotte, Patrice and Savard, Gilles},
  journal={Annals of operations research},
  volume={153},
  number={1},
  pages={235--256},
  year={2007},
  publisher={Springer}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}


@inproceedings{maclaurin2015gradient,
  title={Gradient-based hyperparameter optimization through reversible learning},
  author={Maclaurin, Dougal and Duvenaud, David and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={2113--2122},
  year={2015}
}

@article{florensa2019self,
  title={Self-supervised learning of image embedding for continuous control},
  author={Florensa, Carlos and Degrave, Jonas and Heess, Nicolas and Springenberg, Jost Tobias and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1901.00943},
  year={2019}
}

@article{wang2019paired,
  title={Paired open-ended trailblazer (poet): Endlessly generating increasingly complex and diverse learning environments and their solutions},
  author={Wang, Rui and Lehman, Joel and Clune, Jeff and Stanley, Kenneth O},
  journal={arXiv preprint arXiv:1901.01753},
  year={2019}
}

@inproceedings{brant2017minimal,
  title={Minimal criterion coevolution: a new approach to open-ended search},
  author={Brant, Jonathan C and Stanley, Kenneth O},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={67--74},
  year={2017}
}

@inproceedings{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8538--8547},
  year={2018}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{zhu2020vision,
  title={Vision-language navigation with self-supervised auxiliary reasoning tasks},
  author={Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10012--10022},
  year={2020}
}

@article{hadfield2016cooperative,
  title={Cooperative inverse reinforcement learning},
  author={Hadfield-Menell, Dylan and Dragan, Anca and Abbeel, Pieter and Russell, Stuart},
  journal={arXiv preprint arXiv:1606.03137},
  year={2016}
}

@inproceedings{hejna2020hierarchically,
  title={Hierarchically decoupled imitation for morphological transfer},
  author={Hejna, Donald and Pinto, Lerrel and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={4159--4171},
  year={2020},
  organization={PMLR}
}

@article{hui2020babyai,
  title={BabyAI 1.1},
  author={Hui, David Yu-Tung and Chevalier-Boisvert, Maxime and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2007.12770},
  year={2020}
}

@article{nguyen2021interactive,
  title={Interactive Learning from Activity Description},
  author={Nguyen, Khanh and Misra, Dipendra and Schapire, Robert and Dud{\'\i}k, Miro and Shafto, Patrick},
  journal={arXiv preprint arXiv:2102.07024},
  year={2021}
}

@inproceedings{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e}, Hal},
  booktitle={International conference on machine learning},
  pages={2917--2926},
  year={2018},
  organization={PMLR}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}


@inproceedings{pebble,
  title={PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training},
  author={Lee, Kimin and Smith, Laura and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@inproceedings{schoettler2020meta,
  title={Meta-reinforcement learning for robotic industrial insertion tasks},
  author={Schoettler, Gerrit and Nair, Ashvin and Ojea, Juan Aparicio and Levine, Sergey and Solowjow, Eugen},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9728--9735},
  year={2020},
  organization={IEEE}
}

@article{nagabandi2018learning,
  title={Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
  author={Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1803.11347},
  year={2018}
}

@article{kumar2021rma,
  title={Rma: Rapid motor adaptation for legged robots},
  author={Kumar, Ashish and Fu, Zipeng and Pathak, Deepak and Malik, Jitendra},
  journal={arXiv preprint arXiv:2107.04034},
  year={2021}
}

@inproceedings{filos2020can,
  title={Can autonomous vehicles identify, recover from, and adapt to distribution shifts?},
  author={Filos, Angelos and Tigkas, Panagiotis and McAllister, Rowan and Rhinehart, Nicholas and Levine, Sergey and Gal, Yarin},
  booktitle={International Conference on Machine Learning},
  pages={3145--3153},
  year={2020},
  organization={PMLR}
}

@inproceedings{ke2021grasping,
  title={Grasping with chopsticks: Combating covariate shift in model-free imitation learning for fine manipulation},
  author={Ke, Liyiming and Wang, Jingqiang and Bhattacharjee, Tapomayukh and Boots, Byron and Srinivasa, Siddhartha},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6185--6191},
  year={2021},
  organization={IEEE}
}

@article{miki2022learning,
  title={Learning robust perceptive locomotion for quadrupedal robots in the wild},
  author={Miki, Takahiro and Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  journal={Science Robotics},
  volume={7},
  number={62},
  pages={eabk2822},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{fallah2021generalization,
  title={Generalization of model-agnostic meta-learning algorithms: Recurring and unseen tasks},
  author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{wu2021prototransformer,
  title={ProtoTransformer: A Meta-Learning Approach to Providing Student Feedback},
  author={Wu, Mike and Goodman, Noah and Piech, Chris and Finn, Chelsea},
  journal={arXiv preprint arXiv:2107.14035},
  year={2021}
}

@article{duan2016rl,
  title={Rl2: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@article{mishra2017simple,
  title={A simple neural attentive meta-learner},
  author={Mishra, Nikhil and Rohaninejad, Mostafa and Chen, Xi and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1707.03141},
  year={2017}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{rothfuss2018promp,
  title={Promp: Proximal meta-policy search},
  author={Rothfuss, Jonas and Lee, Dennis and Clavera, Ignasi and Asfour, Tamim and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1810.06784},
  year={2018}
}

@article{gupta2018meta,
  title={Meta-reinforcement learning of structured exploration strategies},
  author={Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{rakelly2019efficient,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International conference on machine learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@article{zintgraf2019varibad,
  title={Varibad: A very good method for bayes-adaptive deep rl via meta-learning},
  author={Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.08348},
  year={2019}
}

@article{zhao2020meld,
  title={Meld: Meta-reinforcement learning from images via latent state models},
  author={Zhao, Tony Z and Nagabandi, Anusha and Rakelly, Kate and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.13957},
  year={2020}
}

@article{jabri2019unsupervised,
  title={Unsupervised curricula for visual meta-reinforcement learning},
  author={Jabri, Allan and Hsu, Kyle and Gupta, Abhishek and Eysenbach, Ben and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{gupta2018unsupervised,
  title={Unsupervised meta-learning for reinforcement learning},
  author={Gupta, Abhishek and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1806.04640},
  year={2018}
}

@article{dorfman2020offline,
  title={Offline meta learning of exploration},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={arXiv preprint arXiv:2008.02598},
  year={2020}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{mitchell2021offline,
  title={Offline meta-reinforcement learning with advantage weighting},
  author={Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={7780--7791},
  year={2021},
  organization={PMLR}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Volpi, Riccardo and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}

@article{hong2021federated,
  title={Federated robustness propagation: Sharing adversarial robustness in federated learning},
  author={Hong, Junyuan and Wang, Haotao and Wang, Zhangyang and Zhou, Jiayu},
  journal={arXiv preprint arXiv:2106.10196},
  year={2021}
}

@InProceedings{Xie_2019_CVPR,
author = {Xie, Cihang and Wu, Yuxin and Maaten, Laurens van der and Yuille, Alan L. and He, Kaiming},
title = {Feature Denoising for Improving Adversarial Robustness},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@inproceedings{lynch2020learning,
  title={Learning latent plans from play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle={Conference on robot learning},
  pages={1113--1132},
  year={2020},
  organization={PMLR}
}

@inproceedings{choi2021variational,
  title={Variational Empowerment as Representation Learning for Goal-Conditioned Reinforcement Learning},
  author={Choi, Jongwook and Sharma, Archit and Lee, Honglak and Levine, Sergey and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={1953--1963},
  year={2021},
  organization={PMLR}
}

@article{gupta2019relay,
  title={Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@ARTICLE{585893,
  author={Wolpert, D.H. and Macready, W.G.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={No free lunch theorems for optimization}, 
  year={1997},
  volume={1},
  number={1},
  pages={67-82},
  doi={10.1109/4235.585893}}
  
@inproceedings{Mandlekar2017AdversariallyRP,
  title={Adversarially Robust Policy Learning through Active Construction of Physically-Plausible Perturbations},
  author={Ajay Mandlekar and Yuke Zhu and Animesh Garg and Li Fei-Fei and Silvio Savarese},
  year={2017}
}

@article{DBLP:journals/corr/RajeswaranGLR16,
  author    = {Aravind Rajeswaran and
               Sarvjeet Ghotra and
               Sergey Levine and
               Balaraman Ravindran},
  title     = {EPOpt: Learning Robust Neural Network Policies Using Model Ensembles},
  journal   = {CoRR},
  volume    = {abs/1610.01283},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.01283},
  eprinttype = {arXiv},
  eprint    = {1610.01283},
  timestamp = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RajeswaranGLR16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{schulman2017ppo,
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  biburl = {https://www.bibsonomy.org/bibtex/24bbcce6aa1c42ae7f61ef8cf5475aa85/lanteunis},
  ee = {http://arxiv.org/abs/1707.06347},
  interhash = {f57ff463a90dbafb77d55a25aea8355c},
  intrahash = {4bbcce6aa1c42ae7f61ef8cf5475aa85},
  journal = {CoRR},
  keywords = {DRLAlgoComparison ppo reinforcement_learning},
  timestamp = {2019-12-18T21:15:59.000+0100},
  title = {Proximal Policy Optimization Algorithms.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1707.html#SchulmanWDRK17},
  volume = {abs/1707.06347},
  year = 2017
}

@article{Katehakis1987TheMB,
  title={The Multi-Armed Bandit Problem: Decomposition and Computation},
  author={Michael N. Katehakis and Arthur F. Veinott},
  journal={Math. Oper. Res.},
  year={1987},
  volume={12},
  pages={262-268}
}

@article{Thompson1935OnTT,
  title={On the Theory of Apportionment},
  author={William Robin Thompson},
  journal={American Journal of Mathematics},
  year={1935},
  volume={57},
  pages={450}
}


@InProceedings{pmlr-v164-chen22a,
  title = 	 {A System for General In-Hand Object Re-Orientation},
  author =       {Chen, Tao and Xu, Jie and Agrawal, Pulkit},
  booktitle = 	 {Proceedings of the 5th Conference on Robot Learning},
  pages = 	 {297--307},
  year = 	 {2022},
  editor = 	 {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  volume = 	 {164},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--11 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v164/chen22a/chen22a.pdf},
  url = 	 {https://proceedings.mlr.press/v164/chen22a.html},
  abstract = 	 {In-hand object reorientation has been a challenging problem in robotics due to high dimensional actuation space and the frequent change in contact state between the fingers and the objects. We present a simple model-free framework that can learn to reorient objects with both the hand facing upwards and downwards. We demonstrate the capability of reorienting over $2000$ geometrically different objects in both cases. The learned policies show strong zero-shot transfer performance on new objects. We provide evidence that these policies are amenable to real-world operation by distilling them to use observations easily available in the real world. The videos of the learned policies are available at: https://taochenshh.github.io/projects/in-hand-reorientation.}
}

@article{collins2020trmaml,
  author    = {Liam Collins and
               Aryan Mokhtari and
               Sanjay Shakkottai},
  title     = {Distribution-Agnostic Model-Agnostic Meta-Learning},
  journal   = {CoRR},
  volume    = {abs/2002.04766},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.04766},
  eprinttype = {arXiv},
  eprint    = {2002.04766},
  timestamp = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-04766.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{oikarinen2021robbust,
  author    = {Tuomas P. Oikarinen and
               Wang Zhang and
               Alexandre Megretski and
               Luca Daniel and
               Tsui{-}Wei Weng},
  editor    = {Marc'Aurelio Ranzato and
               Alina Beygelzimer and
               Yann N. Dauphin and
               Percy Liang and
               Jennifer Wortman Vaughan},
  title     = {Robust Deep Reinforcement Learning through Adversarial Loss},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
               on Neural Information Processing Systems 2021, NeurIPS 2021, December
               6-14, 2021, virtual},
  pages     = {26156--26167},
  year      = {2021},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/dbb422937d7ff56e049d61da730b3e11-Abstract.html},
  timestamp = {Tue, 03 May 2022 16:20:49 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/OikarinenZMDW21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{pinto2017rarl,
  author    = {Lerrel Pinto and
               James Davidson and
               Rahul Sukthankar and
               Abhinav Gupta},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {Robust Adversarial Reinforcement Learning},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {2817--2826},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v70/pinto17a.html},
  timestamp = {Wed, 29 May 2019 08:41:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/PintoDSG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{margolis2022rapid,
  title={Rapid Locomotion via Reinforcement Learning},
  author={Margolis, Gabriel B and Yang, Ge and Paigwar, Kartik and Chen, Tao and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:2205.02824},
  year={2022}
}

@article{nesterov2009primal,
  title={Primal-dual subgradient methods for convex problems},
  author={Nesterov, Yurii},
  journal={Mathematical programming},
  volume={120},
  number={1},
  pages={221--259},
  year={2009},
  publisher={Springer}
}

@inproceedings{zhang2021robust,
  author    = {Huan Zhang and
               Hongge Chen and
               Duane S. Boning and
               Cho{-}Jui Hsieh},
  title     = {Robust Reinforcement Learning on State Observations with Learned Optimal
               Adversary},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=sCZbhBvqQaU},
  timestamp = {Tue, 10 Aug 2021 16:44:53 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhangCBH21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vinitsky2020robust,
  author    = {Eugene Vinitsky and
               Yuqing Du and
               Kanaad Parvate and
               Kathy Jang and
               Pieter Abbeel and
               Alexandre M. Bayen},
  title     = {Robust Reinforcement Learning using Adversarial Populations},
  journal   = {CoRR},
  volume    = {abs/2008.01825},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.01825},
  eprinttype = {arXiv},
  eprint    = {2008.01825},
  timestamp = {Fri, 07 Aug 2020 15:07:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-01825.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bemporad98robustness,
  author    = {Alberto Bemporad and
               Manfred Morari},
  editor    = {Andrea Garulli and
               Alberto Tesi},
  title     = {Robust model predictive control: {A} survey},
  booktitle = {Robustness in Identification and Control, Workshop Robustness in Identification
               and Control, Siena, Italy, July 30 - August 2, 1998},
  series    = {Lecture Notes in Control and Information Sciences},
  volume    = {245},
  pages     = {207--226},
  publisher = {Springer},
  year      = {1998},
  url       = {https://doi.org/10.1007/bfb0109870},
  doi       = {10.1007/bfb0109870},
  timestamp = {Sun, 28 Jul 2019 13:45:33 +0200},
  biburl    = {https://dblp.org/rec/conf/ric/BemporadM98.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lin2021robustmeta,
  author    = {Zichuan Lin and
               Garrett Thomas and
               Guangwen Yang and
               Tengyu Ma},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Model-based Adversarial Meta-Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/73634c1dcbe056c1f7dcf5969da406c8-Abstract.html},
  timestamp = {Sun, 08 Aug 2021 16:40:51 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/LinTYM20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mendonca2020mier,
  author    = {Russell Mendonca and
               Xinyang Geng and
               Chelsea Finn and
               Sergey Levine},
  title     = {Meta-Reinforcement Learning Robust to Distributional Shift via Model
               Identification and Experience Relabeling},
  journal   = {CoRR},
  volume    = {abs/2006.07178},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.07178},
  eprinttype = {arXiv},
  eprint    = {2006.07178},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-07178.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{
ni2022recurrent,
title={Recurrent Model-Free {RL} is a Strong Baseline for Many {POMDP}s},
author={Tianwei Ni and Benjamin Eysenbach and Sergey Levine and Ruslan Salakhutdinov},
year={2022},
url={https://openreview.net/forum?id=E0zOKxQsZhN}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@inproceedings{zintgraf2021exploration,
  title={Exploration in approximate hyper-state space for meta reinforcement learning},
  author={Zintgraf, Luisa M and Feng, Leo and Lu, Cong and Igl, Maximilian and Hartikainen, Kristian and Hofmann, Katja and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={12991--13001},
  year={2021},
  organization={PMLR}
}

@article{deleu2018effects,
  title={The effects of negative adaptation in model-agnostic meta-learning},
  author={Deleu, Tristan and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1812.02159},
  year={2018}
}

@article{vaserstein1969markov,
  title={Markov processes over denumerable products of spaces, describing large systems of automata},
  author={Vaserstein, Leonid Nisonovich},
  journal={Problemy Peredachi Informatsii},
  volume={5},
  number={3},
  pages={64--72},
  year={1969},
  publisher={Russian Academy of Sciences, Branch of Informatics, Computer Equipment and~…}
}

@inproceedings{renyi1961measures,
  title={On measures of entropy and information},
  author={R{\'e}nyi, Alfr{\'e}d},
  booktitle={Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics},
  volume={4},
  pages={547--562},
  year={1961},
  organization={University of California Press}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{xie2022robust,
  title={Robust Policy Learning over Multiple Uncertainty Sets},
  author={Xie, Annie and Sodhani, Shagun and Finn, Chelsea and Pineau, Joelle and Zhang, Amy},
  journal={arXiv preprint arXiv:2202.07013},
  year={2022}
}

@article{de2005tutorial,
  title={A tutorial on the cross-entropy method},
  author={De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
  journal={Annals of operations research},
  volume={134},
  number={1},
  pages={19--67},
  year={2005},
  publisher={Springer}
}

@inproceedings{fu2021towards,
  title={Towards effective context for meta-reinforcement learning: an approach based on contrastive learning},
  author={Fu, Haotian and Tang, Hongyao and Hao, Jianye and Chen, Chen and Feng, Xidong and Li, Dong and Liu, Wulong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={7457--7465},
  year={2021}
}

@inproceedings{zhang2021metacure,
  title={Metacure: Meta reinforcement learning with empowerment-driven exploration},
  author={Zhang, Jin and Wang, Jianhao and Hu, Hao and Chen, Tong and Chen, Yingfeng and Fan, Changjie and Zhang, Chongjie},
  booktitle={International Conference on Machine Learning},
  pages={12600--12610},
  year={2021},
  organization={PMLR}
}