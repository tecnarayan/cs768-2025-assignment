@inproceedings{teerapittayanon2016branchynet,
  author    = {Surat Teerapittayanon and
               Bradley McDanel and
               H. T. Kung},
  title     = {BranchyNet: Fast inference via early exiting from deep neural networks},
  booktitle = {{ICPR}},
  year      = {2016},
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{zhang2018shufflenet,
  author    = {Xiangyu Zhang and
               Xinyu Zhou and
               Mengxiao Lin and
               Jian Sun},
  title     = {ShuffleNet: An Extremely Efficient Convolutional Neural Network for
               Mobile Devices},
  booktitle = {{CVPR}},
  year      = {2018}
}

@inproceedings{tan2019efficientnet,
  author    = {Mingxing Tan and
               Quoc V. Le},
  title     = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  year      = {2019}
}

@inproceedings{lan2019albert,
  author    = {Zhenzhong Lan and
               Mingda Chen and
               Sebastian Goodman and
               Kevin Gimpel and
               Piyush Sharma and
               Radu Soricut},
  title     = {{ALBERT:} {A} Lite {BERT} for Self-supervised Learning of Language
               Representations},
  booktitle = {{ICLR}},
  year      = {2020}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@inproceedings{wu2016quantized,
  author    = {Jiaxiang Wu and
               Cong Leng and
               Yuhang Wang and
               Qinghao Hu and
               Jian Cheng},
  title     = {Quantized Convolutional Neural Networks for Mobile Devices},
  booktitle = {{CVPR}},
  year      = {2016}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{huang2017multi,
  author    = {Gao Huang and
               Danlu Chen and
               Tianhong Li and
               Felix Wu and
               Laurens van der Maaten and
               Kilian Q. Weinberger},
  title     = {Multi-Scale Dense Networks for Resource Efficient Image Classification},
  booktitle = {{ICLR}},
  year      = {2018}
}

@inproceedings{kaya2018shallow,
  author    = {Yigitcan Kaya and
               Sanghyun Hong and
               Tudor Dumitras},
  title     = {Shallow-Deep Networks: Understanding and Mitigating Network Overthinking},
  booktitle = {{ICML}},
  year      = {2019}
}

@inproceedings{hu2020triple,
  author    = {Ting{-}Kuei Hu and
               Tianlong Chen and
               Haotao Wang and
               Zhangyang Wang},
  title     = {Triple Wins: Boosting Accuracy, Robustness and Efficiency Together
               by Enabling Input-Adaptive Inference},
  booktitle = {{ICLR}},
  year      = {2020}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{xu2020bert,
  title={BERT-of-Theseus: Compressing BERT by Progressive Module Replacing},
  author={Xu, Canwen and Zhou, Wangchunshu and Ge, Tao and Wei, Furu and Zhou, Ming},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{sun2019patient,
  author    = {Siqi Sun and
               Yu Cheng and
               Zhe Gan and
               Jingjing Liu},
  title     = {Patient Knowledge Distillation for {BERT} Model Compression},
  booktitle = {{EMNLP-IJCNLP}},
  year      = {2019}
}

@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}

@inproceedings{michel2019sixteen,
  author    = {Paul Michel and
               Omer Levy and
               Graham Neubig},
  title     = {Are Sixteen Heads Really Better than One?},
  booktitle = {NeurIPS},
  year      = {2019}
}

@inproceedings{voita2019analyzing,
  author    = {Elena Voita and
               David Talbot and
               Fedor Moiseev and
               Rico Sennrich and
               Ivan Titov},
  title     = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy
               Lifting, the Rest Can Be Pruned},
  booktitle = {{ACL}},
  year      = {2019}
}

@inproceedings{fan2019reducing,
  author    = {Angela Fan and
               Edouard Grave and
               Armand Joulin},
  title     = {Reducing Transformer Depth on Demand with Structured Dropout},
  booktitle = {{ICLR}},
  year      = {2020}
}

@article{liu2020fastbert,
  title={FastBERT: a Self-distilling BERT with Adaptive Inference Time},
  author={Liu, Weijie and Zhou, Peng and Zhao, Zhe and Wang, Zhiruo and Deng, Haotang and Ju, Qi},
  journal={arXiv preprint arXiv:2004.02178},
  year={2020}
}

@inproceedings{Schwartz:2020,
        author = {Roy Schwartz and Gabi Stanovsky and Swabha Swayamdipta and Jesse Dodge and Noah A. Smith},
        title = {The Right Tool for the Job: Matching Model and Instance Complexities},
        booktitle = {{ACL}},
        year = {2020}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={NeurIPS},
  year={2012}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{devlin2018bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {{NAACL-HLT}},
  year      = {2019}
}

@inproceedings{yang2019xlnet,
  author    = {Zhilin Yang and
               Zihang Dai and
               Yiming Yang and
               Jaime G. Carbonell and
               Ruslan Salakhutdinov and
               Quoc V. Le},
  title     = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  booktitle = {NeurIPS},
  year      = {2019}
}

@article{liu2019roberta,
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{jin2019bert,
  author    = {Di Jin and
               Zhijing Jin and
               Joey Tianyi Zhou and
               Peter Szolovits},
  title     = {Is {BERT} Really Robust? Natural Language Attack on Text Classification
               and Entailment},
  booktitle = {{AAAI}},
  year      = {2020}
}

@article{graves2016adaptive,
  title={Adaptive computation time for recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1603.08983},
  year={2016}
}

@inproceedings{wang2018skipnet,
  author    = {Xin Wang and
               Fisher Yu and
               Zi{-}Yi Dou and
               Trevor Darrell and
               Joseph E. Gonzalez},
  title     = {SkipNet: Learning Dynamic Routing in Convolutional Networks},
  booktitle = {{ECCV}},
  year      = {2018}
}

@inproceedings{szegedy2013intriguing,
  author    = {Christian Szegedy and
               Wojciech Zaremba and
               Ilya Sutskever and
               Joan Bruna and
               Dumitru Erhan and
               Ian J. Goodfellow and
               Rob Fergus},
  title     = {Intriguing properties of neural networks},
  booktitle = {{ICLR}},
  year      = {2014}
}

@incollection{prechelt1998early,
  title={Early stopping-but when?},
  author={Prechelt, Lutz},
  booktitle={Neural Networks: Tricks of the trade},
  pages={55--69},
  year={1998},
  publisher={Springer}
}

@inproceedings{morgan1990generalization,
  author    = {Nelson Morgan and
               Herv{\'{e}} Bourlard},
  title     = {Generalization and Parameter Estimation in Feedforward Netws: Some
               Experiments},
  booktitle = {{NeurIPS}},
  year      = {1989}
}


@inproceedings{glue,
  author    = {Alex Wang and
               Amanpreet Singh and
               Julian Michael and
               Felix Hill and
               Omer Levy and
               Samuel R. Bowman},
  title     = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
               Language Understanding},
  booktitle = {{ICLR}},
  year      = {2019}
  }
  
  @inproceedings{sst,
  author    = {Richard Socher and
               Alex Perelygin and
               Jean Wu and
               Jason Chuang and
               Christopher D. Manning and
               Andrew Y. Ng and
               Christopher Potts},
  title     = {Recursive Deep Models for Semantic Compositionality Over a Sentiment
               Treebank},
  booktitle = {{EMNLP}},
  year      = {2013}
}

@inproceedings{mrpc,
  author    = {William B. Dolan and
               Chris Brockett},
  title     = {Automatically Constructing a Corpus of Sentential Paraphrases},
  booktitle = {IWP@IJCNLP},
  year      = {2005}
}

@inproceedings{mnli,
  author    = {Adina Williams and
               Nikita Nangia and
               Samuel R. Bowman},
  title     = {A Broad-Coverage Challenge Corpus for Sentence Understanding through
               Inference},
  booktitle = {{NAACL-HLT}},
  year      = {2018}
}

@inproceedings{qnli,
  author    = {Pranav Rajpurkar and
               Jian Zhang and
               Konstantin Lopyrev and
               Percy Liang},
  title     = {SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
  booktitle = {{EMNLP}},
  year      = {2016}
}

@article{cola,
  author    = {Alex Warstadt and
               Amanpreet Singh and
               Samuel R. Bowman},
  title     = {Neural Network Acceptability Judgments},
  journal   = {{TACL}},
  year      = {2019}
}

@inproceedings{senteval,
  author    = {Alexis Conneau and
               Douwe Kiela},
  title     = {SentEval: An Evaluation Toolkit for Universal Sentence Representations},
  booktitle = {{LREC}},
  year      = {2018}
}

@inproceedings{wnli,
  author    = {Hector J. Levesque},
  title     = {The Winograd Schema Challenge},
  booktitle = {{AAAI} Spring Symposium: Logical Formalizations of Commonsense Reasoning},
  year      = {2011}
}

@article{sun2020mobilebert,
  title={MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices},
  author={Sun, Zhiqing and Yu, Hongkun and Song, Xiaodan and Liu, Renjie and Yang, Yiming and Zhou, Denny},
  journal={arXiv preprint arXiv:2004.02984},
  year={2020}
}

@inproceedings{krogh1994ensemble,
  author    = {Anders Krogh and
               Jesper Vedelsby},
  title     = {Neural Network Ensembles, Cross Validation, and Active Learning},
  booktitle = {{NeurIPS}},
  year      = {1994}
}

@inproceedings{snli,
  author    = {Samuel R. Bowman and
               Gabor Angeli and
               Christopher Potts and
               Christopher D. Manning},
  title     = {A large annotated corpus for learning natural language inference},
  booktitle = {{EMNLP}},
  year      = {2015}
}

@inproceedings{yelp,
  author    = {Xiang Zhang and
               Junbo Jake Zhao and
               Yann LeCun},
  title     = {Character-level Convolutional Networks for Text Classification},
  booktitle = {{NeurIPS}},
  year      = {2015}
}

@article{bapna2020controlling,
  title={Controlling Computation versus Quality for Neural Sequence Models},
  author={Bapna, Ankur and Arivazhagan, Naveen and Firat, Orhan},
  journal={arXiv preprint arXiv:2002.07106},
  year={2020}
}

@article{elbayad2019depth,
  author    = {Maha Elbayad and
               Jiatao Gu and
               Edouard Grave and
               Michael Auli},
  title     = {Depth-Adaptive Transformer},
  booktitle = {{ICLR}},
  year      = {2020}
}

@inproceedings{kurakin2017adversarial,
  author    = {Alexey Kurakin and
               Ian J. Goodfellow and
               Samy Bengio},
  title     = {Adversarial examples in the physical world},
  booktitle = {{ICLR} (Workshop)},
  year      = {2017}
}

@inproceedings{he2016deep,
author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  booktitle = {{CVPR}},
  year      = {2016}
}

@inproceedings{Cai2020Once-for-All,
author    = {Han Cai and
               Chuang Gan and
               Tianzhe Wang and
               Zhekai Zhang and
               Song Han},
  title     = {Once-for-All: Train One Network and Specialize it for Efficient Deployment},
  booktitle = {{ICLR}},
  year      = {2020}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009},
  publisher={Citeseer}
}

@article{xin2020deebert,
  title={DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference},
  author={Xin, Ji and Tang, Raphael and Lee, Jaejun and Yu, Yaoliang and Lin, Jimmy},
  journal={arXiv preprint arXiv:2004.12993},
  year={2020}
}

@inproceedings{pang2019improving,
  author    = {Tianyu Pang and
               Kun Xu and
               Chao Du and
               Ning Chen and
               Jun Zhu},
  title     = {Improving Adversarial Robustness via Promoting Ensemble Diversity},
  booktitle = {{ICML}},
  year      = {2019}
}

@inproceedings{tramer2018ensemble,
  author    = {Florian Tram{\`{e}}r and
               Alexey Kurakin and
               Nicolas Papernot and
               Ian J. Goodfellow and
               Dan Boneh and
               Patrick D. McDaniel},
  title     = {Ensemble Adversarial Training: Attacks and Defenses},
  booktitle = {{ICLR}},
  year      = {2018}
}

@article{strauss2017ensemble,
  title={Ensemble methods as a defense to adversarial perturbations against deep neural networks},
  author={Strauss, Thilo and Hanselmann, Markus and Junginger, Andrej and Ulmer, Holger},
  journal={arXiv preprint arXiv:1709.03423},
  year={2017}
}

@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using gpu model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@inproceedings{jiang2018trust,
  title={To trust or not to trust a classifier},
  author={Jiang, Heinrich and Kim, Been and Guan, Melody and Gupta, Maya},
  booktitle={NeurIPS},
  year={2018}
}

@article{schwartz2019green,
  title={Green {AI}},
  author={Roy Schwartz and
               Jesse Dodge and
               Noah A. Smith and
               Oren Etzioni},
  journal={arXiv preprint arXiv:1907.10597},
  year={2019}
}

@inproceedings{zoph2018learning,
  author    = {Barret Zoph and
               Vijay Vasudevan and
               Jonathon Shlens and
               Quoc V. Le},
  title     = {Learning Transferable Architectures for Scalable Image Recognition},
  booktitle = {{CVPR}},
  year      = {2018}
}

@inproceedings{shufflenet,
  author    = {Xiangyu Zhang and
               Xinyu Zhou and
               Mengxiao Lin and
               Jian Sun},
  title     = {ShuffleNet: An Extremely Efficient Convolutional Neural Network for
               Mobile Devices},
  booktitle = {{CVPR}},
  year      = {2018}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{wolf2020huggingfaces,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      journal={arXiv preprint arXiv:1910.03771}
}

@inproceedings{ut,
  author    = {Mostafa Dehghani and
               Stephan Gouws and
               Oriol Vinyals and
               Jakob Uszkoreit and
               Lukasz Kaiser},
  title     = {Universal Transformers},
  booktitle = {{ICLR}},
  year      = {2019}
}
