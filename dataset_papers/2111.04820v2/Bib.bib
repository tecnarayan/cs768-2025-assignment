% related work

@article{HutXuHooLey14,
  author = "F. Hutter and L. Xu and H.~H. Hoos and K. Leyton-Brown",
  title = "Algorithm runtime prediction: Methods \& evaluation",
  journal = "Artificial Intelligence",
  volume = "206",
  pages = "79--111",
  year = "2014",
}

@inproceedings{SrinivasKKS10,
  author    = {Niranjan Srinivas and
               Andreas Krause and
               Sham M. Kakade and
               Matthias W. Seeger},
  title     = {Gaussian Process Optimization in the Bandit Setting: No Regret and
               Experimental Design},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning},
  pages     = {1015--1022},
  year      = {2010},
}

@inproceedings{Hernandez14,
  author    = {Jos{\'{e}} Miguel Hern{\'{a}}ndez{-}Lobato and
               Matthew W. Hoffman and
               Zoubin Ghahramani},
  title     = {Predictive Entropy Search for Efficient Global Optimization of Black-box
               Functions},
  booktitle = {Advances in Neural Information Processing Systems 27},
  pages     = {918--926},
  year      = {2014},
}


@article{HennigS12,
  author    = {Philipp Hennig and
               Christian J. Schuler},
  title     = {Entropy Search for Information-Efficient Global Optimization},
  journal   = {Journal of Machine Learning Research},
  volume    = {13},
  pages     = {1809--1837},
  year      = {2012},
}

@inproceedings{wu-kg17a,
  author    = {Jian Wu and
               Matthias Poloczek and
               Andrew Gordon Wilson and
               Peter I. Frazier},
  title     = {Bayesian Optimization with Gradients},
  booktitle = {Advances in Neural Information Processing Systems 30},
  pages     = {5267--5278},
  year      = {2017},
}

@book{automl-book,
  editor    = {Frank Hutter and
               Lars Kotthoff and
               Joaquin Vanschoren},
  title     = {Automated Machine Learning - Methods, Systems, Challenges},
  series    = {The Springer Series on Challenges in Machine Learning},
  publisher = {Springer},
  year      = {2019},
}

@incollection{mendoza-autonet19,
  author    = {Hector Mendoza and
               Aaron Klein and
               Matthias Feurer and
               Jost Tobias Springenberg and
               Matthias Urban and
               Michael Burkart and
               Maximilian Dippel and
               Marius Lindauer and
               Frank Hutter},
  title     = {Towards Automatically-Tuned Deep Neural Networks},
  booktitle = {Automated Machine Learning - Methods, Systems, Challenges},
  series    = {The Springer Series on Challenges in Machine Learning},
  pages     = {135--149},
  publisher = {Springer},
  year      = {2019},
}

@article{casalicchio2019openml,
  title={OpenML: An R package to connect to the machine learning platform OpenML},
  author={Casalicchio, Giuseppe and Bossek, Jakob and Lang, Michel and Kirchhoff, Dominik and Kerschke, Pascal and Hofner, Benjamin and Seibold, Heidi and Vanschoren, Joaquin and Bischl, Bernd},
  journal={Computational Statistics},
  volume={34},
  number={3},
  pages={977--991},
  year={2019},
  publisher={Springer}
}

@article{vanschoren2014openmlOLD,
  author    = {Joaquin Vanschoren and
               Jan N. van Rijn and
               Bernd Bischl and
               Lu{\'{\i}}s Torgo},
  title     = {{OpenML}: Networked science in machine learning},
  journal   = {CoRR},
  volume    = {abs/1407.7722},
  year      = {2014},
}

@article{vanschoren2014openml,
  author    = {Joaquin Vanschoren and
               Jan N. van Rijn and
               Bernd Bischl and
               Lu{\'{\i}}s Torgo},
  title     = {OpenML: networked science in machine learning},
  journal   = {{SIGKDD} Explor.},
  volume    = {15},
  number    = {2},
  pages     = {49--60},
  year      = {2013},
}

@book{neil1996bayesian,
author = {Radford M. Neil},
title = {Bayesian Learning for Neural Networks},
year = {1996},
isbn = {0387947248},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@article{wright2019splitting,
  title={Splitting on categorical predictors in random forests},
  author={Wright, Marvin N and K{\"o}nig, Inke R},
  journal={PeerJ},
  volume={7},
  pages={e6339},
  year={2019},
  publisher={PeerJ Inc.}
}

@article{fisher1958grouping,
  title={On grouping for maximum homogeneity},
  author={Fisher, Walter D},
  journal={Journal of the American statistical Association},
  volume={53},
  number={284},
  pages={789--798},
  year={1958},
  publisher={Taylor \& Francis}
}

@book{breiman1984trees,
  author    = {Leo Breiman and
               J. H. Friedman and
               R. A. Olshen and
               C. J. Stone},
  title     = {Classification and Regression Trees},
  publisher = {Wadsworth},
  year      = {1984},
  isbn      = {0-534-98053-8},
  timestamp = {Thu, 03 Jan 2002 11:51:52 +0100},
  biburl    = {https://dblp.org/rec/books/wa/BreimanFOS84.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{snoek2012practical,
    author    = {Jasper Snoek and
               Hugo Larochelle and
               Ryan P. Adams},
  title     = {Practical {Bayesian} Optimization of Machine Learning Algorithms},
  booktitle = {Advances in Neural Information Processing Systems 25},
  pages     = {2960--2968},
  year      = {2012},
}

@article{greenwell2018simple,
  title={A simple and effective model-based variable importance measure},
  author={Greenwell, Brandon M and Boehmke, Bradley C and McCarthy, Andrew J},
  journal={arXiv preprint arXiv:1805.04755},
  year={2018}
}


@incollection{feurer2019hyperparameter,
  title={Hyperparameter optimization},
  author={Feurer, Matthias and Hutter, Frank},
  booktitle={Automated Machine Learning},
  pages={3--33},
  year={2019},
  publisher={Springer, Cham}
}



@article{pfisterer:2019,
  author    = {Florian Pfisterer and
               Janek Thomas and
               Bernd Bischl},
  title     = {Towards Human Centered {AutoML}},
  journal   = {CoRR},
  volume    = {abs/1911.02391},
  year      = {2019},
}

@inproceedings{xanthopoulos:2020,
  author    = {Iordanis Xanthopoulos and
               Ioannis Tsamardinos and
               Vassilis Christophides and
               Eric Simon and
               Alejandro Salinger},
  title     = {Putting the Human Back in the {AutoML} Loop},
  booktitle = {Proceedings of the Workshops of the {EDBT/ICDT} 2020 Joint Conference},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {2578},
  publisher = {CEUR-WS.org},
  year      = {2020},
}
@article{Drozdal:2020,
   title={Trust in {AutoML}},
   ISBN={9781450371186},
   url={http://dx.doi.org/10.1145/3377325.3377501},
   DOI={10.1145/3377325.3377501},
   journal={Proceedings of the 25th International Conference on Intelligent User Interfaces},
   publisher={ACM},
   author={Drozdal, Jaimie and Weisz, Justin and Wang, Dakuo and Dass, Gaurav and Yao, Bingsheng and Zhao, Changruo and Muller, Michael and Ju, Lin and Su, Hui},
   year={2020},
   month={Mar}
}

@inproceedings{Freitas:2019,
          volume = {11713},
           month = {August},
          author = {Alex A. Freitas},
       booktitle = {Third IFIP International Cross-Domain Conference for Machine Learning and Knowledge Extraction (CD-MAKE 2019)},
           title = {Automated machine learning for studying the trade-off between predictive accuracy and interpretability},
       publisher = {Springer},
            year = {2019},
         journal = {Lecture Notes in Computer Science},
           pages = {48--66},
        keywords = {classification, machine learning, Auto-ML, interpretable predictive models},
}






%% State-of-the-art: Explain the effects of hyperparameters

@inproceedings{hutter14,
  author    = {Frank Hutter and
               Holger H. Hoos and
               Kevin Leyton{-}Brown},
  title     = {An Efficient Approach for Assessing Hyperparameter Importance},
  booktitle = {Proceedings of the 31th International Conference on Machine Learning,
               {ICML} },
  volume    = {32},
  pages     = {754--762},
  publisher = {JMLR.org},
  year      = {2014},
}


@article{vanRijn:2018,
   title={Hyperparameter Importance Across Datasets},
   ISBN={9781450355520},
   url={http://dx.doi.org/10.1145/3219819.3220058},
   DOI={10.1145/3219819.3220058},
   journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
   publisher={ACM},
   author={van Rijn, Jan N. and Hutter, Frank},
   year={2018},
   month={Jul}
}

@InProceedings{sharma:2019,
  author    = {Abhinav Sharma and
               Jan N. van Rijn and
               Frank Hutter and
               Andreas M{\"{u}}ller},
  title     = {Hyperparameter Importance for Image Classification by Residual Neural
               Networks},
  booktitle = {Discovery Science - 22nd International Conference, {DS}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11828},
  pages     = {112--126},
  publisher = {Springer},
  year      = {2019},
}

@misc{weerts2020importance,
      title={Importance of Tuning Hyperparameters of Machine Learning Algorithms}, 
      author={Hilde J. P. Weerts and Andreas C. Mueller and Joaquin Vanschoren},
      year={2020},
      eprint={2007.07588},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{drozdal2020trust,
  title={Trust in {AutoML}: Exploring information needs for establishing trust in automated machine learning systems},
  author={Drozdal, Jaimie and Weisz, Justin and Wang, Dakuo and Dass, Gaurav and Yao, Bingsheng and Zhao, Changruo and Muller, Michael and Ju, Lin and Su, Hui},
  booktitle={Proceedings of the 25th International Conference on Intelligent User Interfaces},
  pages={297--307},
  year={2020}
}


@misc{breuel2015effects,
      title={The Effects of Hyperparameters on SGD Training of Neural Networks}, 
      author={Thomas M. Breuel},
      year={2015},
      eprint={1508.02788},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@inproceedings{bjorck2018bn,
 author = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {7694--7705},
 publisher = {Curran Associates, Inc.},
 title = {Understanding Batch Normalization},
 url = {https://proceedings.neurips.cc/paper/2018/file/36072923bfc3cf47745d704feb489480-Paper.pdf},
 volume = {31},
 year = {2018}
}


@inproceedings{biedenkapp:2018cave,
  title={Cave: Configuration assessment, visualization and evaluation},
  author={Biedenkapp, Andr{\'e} and Marben, Joshua and Lindauer, Marius and Hutter, Frank},
  booktitle={International Conference on Learning and Intelligent Optimization},
  pages={115--130},
  year={2018},
  organization={Springer}
}

@misc{lindauer2019boah,
      title={BOAH: A Tool Suite for Multi-Fidelity Bayesian Optimization \& Analysis of Hyperparameters}, 
      author={Marius Lindauer and Katharina Eggensperger and Matthias Feurer and André Biedenkapp and Joshua Marben and Philipp Müller and Frank Hutter},
      year={2019},
      eprint={1908.06756},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{jia2016qim,
author="Jia, Dan
and Wang, Rui
and Xu, Chengzhong
and Yu, Zhibin",
editor="Gao, Guang R.
and Qian, Depei
and Gao, Xinbo
and Chapman, Barbara
and Chen, Wenguang",
title="QIM: Quantifying Hyperparameter Importance for Deep Learning",
booktitle="Network and Parallel Computing",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="180--188",
isbn="978-3-319-47099-3"
}

@inproceedings{biedenkapp2018ablation,
author = {Biedenkapp, Andr\'{e} and Lindauer, Marius and Eggensperger, Katharina and Hutter, Frank and Fawcett, Chris and Hoos, Holger H.},
title = {Efficient Parameter Importance Analysis via Ablation with Surrogates},
year = {2017},
publisher = {AAAI Press},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {773–779},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}

@misc{smith2018disciplined,
      title={A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay}, 
      author={Leslie N. Smith},
      year={2018},
      eprint={1803.09820},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@article{probst2018tunability,
  author    = {Philipp Probst and
               Anne{-}Laure Boulesteix and
               Bernd Bischl},
  title     = {Tunability: Importance of Hyperparameters of Machine Learning Algorithms},
  journal   = {Journal of Machine Learning Research},
  volume    = {20},
  pages     = {53:1--53:32},
  year      = {2019},
}

@INPROCEEDINGS{young:2018,
  author={M. T. {Young} and J. {Hinkle} and A. {Ramanathan} and R. {Kannan}},
  booktitle={2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={HyperSpace: Distributed Bayesian Hyperparameter Optimization}, 
  year={2018},
  volume={},
  number={},
  pages={339-347},
  doi={10.1109/CAHPC.2018.8645954}}


@article{gretton:2012,
  author  = {Arthur Gretton and Karsten M. Borgwardt and Malte J. Rasch and Bernhard Sch{{\"o}}lkopf and Alexander Smola},
  title   = {A Kernel Two-Sample Test},
  journal = {Journal of Machine Learning Research},
  year    = {2012},
  volume  = {13},
  number  = {25},
  pages   = {723-773}
}


% uncertainty of PDP
@article{cafri:2016,
  title={Understanding variable effects from black box prediction: Quantifying effects in tree ensembles using partial dependence},
  author={Cafri, Guy and Bailey, Barbara A},
  journal={Journal of Data Science},
  volume={14},
  number={1},
  pages={67--95},
  year={2016},
  publisher={中華資料採礦協會}
}

@article{greenwell:2017,
  author = {Brandon M. Greenwell},
  title = {{pdp: An R Package for Constructing Partial Dependence Plots}},
  year = {2017},
  journal = {{The R Journal}},
  pages = {421--436},
  volume = {9},
  number = {1}
}

% Uncertainty of PFI
@article{ishwaran:2018,
author = {Ishwaran, Hemant and Lu, Min},
year = {2018},
month = {06},
pages = {},
title = {Standard errors and confidence intervals for variable importance in random forest regression, classification, and survival},
volume = {38},
journal = {Statistics in Medicine},
doi = {10.1002/sim.7803}
}

% Subset PDP

@article{molnar2020modelagnostic,
  author    = {Christoph Molnar and
               Gunnar K{\"{o}}nig and
               Bernd Bischl and
               Giuseppe Casalicchio},
  title     = {Model-agnostic Feature Importance and Effects with Dependent Features
               - {A} Conditional Subgroup Approach},
  journal   = {CoRR},
  volume    = {abs/2006.04628},
  year      = {2020},
}


@article{britton:2019,
  author    = {Matthew Britton},
  title     = {{VINE:} {V}isualizing Statistical Interactions in Black Box Models},
  journal   = {CoRR},
  volume    = {abs/1904.00561},
  year      = {2019},
}

@INPROCEEDINGS{groemping:2020,
      title={Model-agnostic Effects Plots for Interpreting Machine Learning Models}, 
      author={Ulrike Grömping},
      year={2020},
      publisher = {Department II, Beuth University of Applied Sciences Berlin},
      series = {Report 1/2020, Reports in Mathematics, Physics and Chemistry}
}



@book{breiman:1984,
  author    = {Leo Breiman and
               J. H. Friedman and
               R. A. Olshen and
               C. J. Stone},
  title     = {Classification and Regression Trees},
  publisher = {Wadsworth},
  year      = {1984},
}

% general IML
@article{friedman2001greedy,
  title =	 {Greedy function approximation: A gradient boosting
                  machine},
  author =	 {Friedman, Jerome H},
  journal =	 {Annals of Statistics},
  pages =	 {1189--1232},
  year =	 2001,
  publisher =	 {JSTOR}
}

@article{goldstein2014peeking,
    author = {Alex Goldstein and Adam Kapelner and Justin Bleich and Emil Pitkin},
    title = {Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation},
    journal = {Journal of Computational and Graphical Statistics},
    volume = {24},
    number = {1},
    pages = {44-65},
    year  = {2015},
    publisher = {Taylor & Francis},
}


@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, * * *, 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Breiman, Leo},
doi = {10.1023/A:1010933404324},
file = {::},
issn = {08856125},
journal = {Machine Learning},
keywords = {Classification,Ensemble,Regression},
mendeley-groups = {gimp},
month = {oct},
number = {1},
pages = {5--32},
title = {{Random forests}},
volume = {45},
year = {2001}
}



@article{Molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}



@article{casa2019,
author="Casalicchio, Giuseppe
and Molnar, Christoph
and Bischl, Bernd",
editor="Berlingerio, Michele
and Bonchi, Francesco
and G{\"a}rtner, Thomas
and Hurley, Neil
and Ifrim, Georgiana",
title="Visualizing the Feature Importance for Black Box Models",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="655--670",
isbn="978-3-030-10925-7"
}



% Benchmarking 

@inproceedings{eggensperger2015efficient,
  title={Efficient benchmarking of hyperparameter optimizers via surrogates},
  author={Eggensperger, Katharina and Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015},
  pages     = {1114--1120},
}

@inproceedings{Falkner2018bohb,
  author    = {Stefan Falkner and
               Aaron Klein and
               Frank Hutter},
  editor    = {Jennifer G. Dy and
               Andreas Krause},
  title     = {{BOHB:} Robust and Efficient Hyperparameter Optimization at Scale},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {1436--1445},
  publisher = {{PMLR}},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v80/falkner18a.html},
  timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/FalknerKH18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Zimmer2020AutoPyTorchTM,
  author    = {Lucas Zimmer and
               Marius Lindauer and
               Frank Hutter},
  title     = {{Auto-PyTorch Tabular}: Multi-Fidelity MetaLearning for Efficient and
               Robust {AutoDL}},
  journal   = {IEEE TPAMI},
  year      = {2021},
  note      = {Preprint via Early Access}
}

@article{jones1998ego,
  author    = {Donald R. Jones and
               Matthias Schonlau and
               William J. Welch},
  title     = {Efficient Global Optimization of Expensive Black-Box Functions},
  journal   = {Journal of Global Optimization},
  volume    = {13},
  number    = {4},
  pages     = {455--492},
  year      = {1998},
}

@article{apley2020visualizing,
  title={Visualizing the effects of predictor variables in black box supervised learning models},
  author={Apley, Daniel W and Zhu, Jingyu},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={82},
  number={4},
  pages={1059--1086},
  year={2020},
  publisher={Wiley Online Library}
}



% Conditional hyperparameter spaces

@inproceedings{LevesqueDGS17,
  author    = {Julien{-}Charles Levesque and
               Audrey Durand and
               Christian Gagn{\'{e}} and
               Robert Sabourin},
  title     = {Bayesian optimization for conditional hyperparameter spaces},
  booktitle = {2017 International Joint Conference on Neural Networks, {IJCNN} 2017,
               Anchorage, AK, USA, May 14-19, 2017},
  pages     = {286--293},
  publisher = {{IEEE}},
  year      = {2017},
  url       = {https://doi.org/10.1109/IJCNN.2017.7965867},
  doi       = {10.1109/IJCNN.2017.7965867},
  timestamp = {Fri, 09 Apr 2021 18:45:11 +0200},
  biburl    = {https://dblp.org/rec/conf/ijcnn/LevesqueDGS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Swersky2014RaidersOT,
  title={Raiders of the Lost Architecture: Kernels for Bayesian Optimization in Conditional Parameter Spaces},
  author={Kevin Swersky and D. Duvenaud and Jasper Snoek and F. Hutter and Michael A. Osborne},
  journal={arXiv: Machine Learning},
  year={2014}
}


@article{friedman2003multiple,
  title={Multiple additive regression trees with application in epidemiology},
  author={Friedman, Jerome H and Meulman, Jacqueline J},
  journal={Statistics in medicine},
  volume={22},
  number={9},
  pages={1365--1381},
  year={2003},
  publisher={Wiley Online Library}
}

@article{cutler2007random,
  title={Random forests for classification in ecology},
  author={Cutler, D Richard and Edwards Jr, Thomas C and Beard, Karen H and Cutler, Adele and Hess, Kyle T and Gibson, Jacob and Lawler, Joshua J},
  journal={Ecology},
  volume={88},
  number={11},
  pages={2783--2792},
  year={2007},
  publisher={Wiley Online Library}
}
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{feurer2020autosklearn2,
  author    = {Matthias Feurer and
               Katharina Eggensperger and
               Stefan Falkner and
               Marius Lindauer and
               Frank Hutter},
  title     = {Auto-Sklearn 2.0: The Next Generation},
  journal   = {CoRR},
  volume    = {abs/2007.04074},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.04074},
  archivePrefix = {arXiv},
  eprint    = {2007.04074},
  timestamp = {Mon, 20 Jul 2020 14:20:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-04074.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{bischl2018mlrmbo,
      title={mlrMBO: A Modular Framework for Model-Based Optimization of Expensive Black-Box Functions}, 
      author={Bernd Bischl and Jakob Richter and Jakob Bossek and Daniel Horn and Janek Thomas and Michel Lang},
      year={2018},
      eprint={1703.03373},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}