\begin{thebibliography}{100}

\bibitem{Wang_2022_CVPR}
Qin Wang, Olga Fink, Luc Van~Gool, and Dengxin Dai.
\newblock Continual test-time domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7201--7211, June 2022.

\bibitem{varsavsky2020test}
Thomas Varsavsky, Mauricio Orbes-Arteaga, Carole~H Sudre, Mark~S Graham, Parashkev Nachev, and M~Jorge Cardoso.
\newblock Test-time unsupervised domain adaptation.
\newblock In {\em International Conference in Medical Image Computing and Computer Assisted Intervention}, pages 428--436. Springer, 2020.

\bibitem{farahani2021brief}
Abolfazl Farahani, Sahar Voghoei, Khaled Rasheed, and Hamid~R Arabnia.
\newblock A brief review of domain adaptation.
\newblock {\em Advances in data science and information engineering}, pages 877--894, 2021.

\bibitem{wilson2020survey}
Garrett Wilson and Diane~J Cook.
\newblock A survey of unsupervised deep domain adaptation.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)}, 11(5):pp. 1--46, 2020.

\bibitem{ganin2015unsupervised}
Yaroslav Ganin and Victor Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 1180--1189. PMLR, 2015.

\bibitem{patel2015visual}
Vishal~M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa.
\newblock Visual domain adaptation: A survey of recent advances.
\newblock {\em IEEE signal processing magazine}, 32(3):pp. 53--69, 2015.

\bibitem{kouw2018introduction}
Wouter~M Kouw and Marco Loog.
\newblock An introduction to domain adaptation and transfer learning.
\newblock {\em arXiv preprint arXiv:1812.11806}, 2018.

\bibitem{peng2018visda}
Xingchao Peng, Ben Usman, Neela Kaushik, Dequan Wang, Judy Hoffman, and Kate Saenko.
\newblock Visda: A synthetic-to-real benchmark for visual domain adaptation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops}, pages 2021--2026, 2018.

\bibitem{zhang2013domain}
Kun Zhang, Bernhard Sch{\"o}lkopf, Krikamol Muandet, and Zhikun Wang.
\newblock Domain adaptation under target and conditional shift.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 819--827. PMLR, 2013.

\bibitem{jain2011online}
Vidit Jain and Erik Learned-Miller.
\newblock Online domain adaptation of a pre-trained cascade of classifiers.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 577--584. IEEE, 2011.

\bibitem{liu2022deep}
Xiaofeng Liu, Chaehwa Yoo, Fangxu Xing, Hyejin Oh, Georges~El Fakhri, Je-Won Kang, and Jonghye Woo.
\newblock Deep unsupervised domain adaptation: A review of recent advances and perspectives.
\newblock {\em APSIPA Transactions on Signal and Information Processing}, 11, 2022.

\bibitem{blitzer2006domain}
John Blitzer, Ryan McDonald, and Fernando Pereira.
\newblock Domain adaptation with structural correspondence learning.
\newblock In {\em Proceedings Conference on Empirical Methods in Natural Language Processing}, pages 120--128, 2006.

\bibitem{shi2022deep}
Yongjie Shi, Xianghua Ying, and Jinfa Yang.
\newblock Deep unsupervised domain adaptation with time series sensor data: A survey.
\newblock {\em Sensors}, 22(15), 2022.

\bibitem{QuioneroCandela2009DatasetSI}
Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil~D. Lawrence.
\newblock {\em Dataset Shift in Machine Learning}.
\newblock The MIT Press, 2009.

\bibitem{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{valanarasu2022onthefly}
Jeya Maria~Jose Valanarasu, Pengfei Guo, Vibashan VS, and Vishal~M. Patel.
\newblock On-the-fly test-time adaptation for medical image segmentation.
\newblock {\em arXiv preprint arXiv:2203.05574}, 2022.

\bibitem{ye2023multi}
Yanyu Ye, Zhenxi Zhang, Wei Wei, and Chunna Tian.
\newblock Multi task consistency guided source-free test-time domain adaptation medical image segmentation.
\newblock {\em arXiv preprint arXiv:2310.11766}, 2023.

\bibitem{KARANI2021101907}
Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu.
\newblock Test-time adaptable neural networks for robust medical image segmentation.
\newblock {\em Medical Image Analysis}, 68:101907, 2021.

\bibitem{he2021autoencoder}
Yufan He, Aaron Carass, Lianrui Zuo, Blake~E Dewey, and Jerry~L Prince.
\newblock Autoencoder based self-supervised test-time adaptation for medical image analysis.
\newblock {\em Medical Image Analysis}, 72:102136, 2021.

\bibitem{li2020community}
Zhang Li, Zheng Zhong, Yang Li, Tianyu Zhang, Liangxin Gao, Dakai Jin, Yue Sun, Xianghua Ye, Li~Yu, Zheyu Hu, Jing Xiao, Lingyun Huang, and Yuling Tang.
\newblock From community-acquired pneumonia to {COVID-19}: a deep learning--based method for quantitative analysis of {COVID-19} on thick-section {CT} scans.
\newblock {\em European Radiology}, 30(12):6828--6837, 2020.

\bibitem{liang2023comprehensive}
Jian Liang, Ran He, and Tieniu Tan.
\newblock A comprehensive survey on test-time adaptation under distribution shifts.
\newblock {\em arXiv preprint arXiv:2303.15361}, 2023.

\bibitem{Pandey_2021_CVPR}
Prashant Pandey, Mrigank Raman, Sumanth Varambally, and Prathosh AP.
\newblock Generalization on unseen domains via inference-time label-preserving target projections.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12924--12933, June 2021.

\bibitem{hendrycks2021faces}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer.
\newblock The many faces of robustness: A critical analysis of out-of-distribution generalization.
\newblock {\em ICCV}, 2021.

\bibitem{Zhang2021MEMOTT}
Marvin Zhang, Sergey Levine, and Chelsea Finn.
\newblock {MEMO}: Test time robustness via adaptation and augmentation.
\newblock {\em Advances in neural information processing systems}, 35:38629--38642, 2022.

\bibitem{hu2021mixnorm}
Xuefeng Hu, Gokhan Uzunbas, Sirius Chen, Rui Wang, Ashish Shah, Ram Nevatia, and Ser-Nam Lim.
\newblock Mixnorm: Test-time adaptation through online normalization estimation.
\newblock {\em arXiv preprint arXiv:2110.11478}, 2021.

\bibitem{mounsaveng2024bag}
Saypraseuth Mounsaveng, Florent Chiaroni, Malik Boudiaf, Marco Pedersoli, and Ismail Ben~Ayed.
\newblock Bag of tricks for fully test-time adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 1936--1945, 2024.

\bibitem{NEURIPS2021_1d497805}
Eric Mintun, Alexander Kirillov, and Saining Xie.
\newblock On interaction between augmentations and corruptions in natural corruption robustness.
\newblock {\em Advances in Neural Information Processing Systems}, 34:3571--3583, 2021.

\bibitem{chen2023improved}
Liang Chen, Yong Zhang, Yibing Song, Ying Shan, and Lingqiao Liu.
\newblock Improved test-time adaptation for domain generalization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 24172--24182, 2023.

\bibitem{chen2011co}
Minmin Chen, Kilian~Q Weinberger, and John Blitzer.
\newblock Co-training for domain adaptation.
\newblock {\em Advances in neural information processing systems}, 24:2456--2464, 2011.

\bibitem{xu2022mutual}
Yuanyuan Xu, Meina Kan, Shiguang Shan, and Xilin Chen.
\newblock Mutual learning of joint and separate domain alignments for multi-source domain adaptation.
\newblock In {\em WACV}, pages 1890--1899, 2022.

\bibitem{zou2018unsupervised}
Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang.
\newblock Unsupervised domain adaptation for semantic segmentation via class-balanced self-training.
\newblock In {\em Proceedings of the European conference on computer vision (ECCV)}, pages 289--305, 2018.

\bibitem{sun2020testtime}
Yu~Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under distribution shifts.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 9229--9248. PMLR, 2020.

\bibitem{shen2018wasserstein}
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu.
\newblock Wasserstein distance guided representation learning for domain adaptation.
\newblock In {\em Proceedings of the AAAI conference on artificial intelligence}, volume~32, 2018.

\bibitem{NEURIPS2021_b618c321}
Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi.
\newblock {TTT++}: When does self-supervised test-time training fail or thrive?
\newblock {\em Advances in neural information processing systems}, 2021.

\bibitem{grandvalet2004semi}
Yves Grandvalet and Yoshua Bengio.
\newblock Semi-supervised learning by entropy minimization.
\newblock {\em Advances in neural information processing systems}, 17, 2004.

\bibitem{haeusser2017associative}
Philip Haeusser, Thomas Frerix, Alexander Mordvintsev, and Daniel Cremers.
\newblock Associative domain adaptation.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 2765--2773, 2017.

\bibitem{tzeng2015simultaneous}
Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko.
\newblock Simultaneous deep transfer across domains and tasks.
\newblock In {\em Proceedings of the IEEE International Conference on Computer Vision (ICCV)}, pages 4068--4076, 2015.

\bibitem{carlucci2017autodial}
Fabio~Maria Carlucci, Lorenzo Porzi, Barbara Caputo, Elisa Ricci, and Samuel~Rota Bulo.
\newblock {AutoDIAL}: Automatic domain alignment layers.
\newblock In {\em Proceedings of the IEEE International Conference on Computer Vision (ICCV)}, pages 5077--5085, 2017.

\bibitem{saito2017asymmetric}
Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada.
\newblock Asymmetric tri-training for unsupervised domain adaptation.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 2988--2997, 2017.

\bibitem{shu2018dirtt}
Rui Shu, Hung~H Bui, Hirokazu Narui, and Stefano Ermon.
\newblock A {DIRT-T} approach to unsupervised domain adaptation.
\newblock In {\em Proceedings of the International Conference on Learning Representations}, 2018.

\bibitem{wang2020tent}
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{niu2022efficient}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan.
\newblock Efficient test-time model adaptation without forgetting.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 16888--16905, 2022.

\bibitem{niu2022towards}
Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan.
\newblock Towards stable test-time adaptation in dynamic wild world.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{10208420}
Masud An-Nur Islam~Fahim and Jani Boutellier.
\newblock {SS-TTA}: Test-time adaption for self-supervised denoising methods.
\newblock In {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, pages 1178--1187, 2023.

\bibitem{chen2022contrastive}
Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi.
\newblock Contrastive test-time adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 295--305, 2022.

\bibitem{cohen2020selfsupervised}
Tomer Cohen, Noy Shulman, Hai Morgenstern, Roey Mechrez, and Erez Farhan.
\newblock Self-supervised dynamic networks for covariate shift robustness.
\newblock {\em arXiv preprint arXiv:2006.03952}, 2020.

\bibitem{bartler2022mt3}
Alexander Bartler, Andre B{\"u}hler, Felix Wiewel, Mario D{\"o}bler, and Bin Yang.
\newblock Mt3: Meta test-time training for self-supervised test-time adaption.
\newblock {\em International Conference on Artificial Intelligence and Statistics}, pages 3080--3090, 2022.

\bibitem{bartler2022ttaps}
Alexander Bartler, Florian Bender, Felix Wiewel, and Bin Yang.
\newblock {TTAPS}: Test-time adaption by aligning prototypes using self-supervision.
\newblock In {\em IEEE International Joint Conference on Neural Networks (IJCNN)}, pages 1--8, 2022.

\bibitem{zhao2023pitfalls}
Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin.
\newblock On pitfalls of test-time adaptation.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2023.

\bibitem{su2023beware}
Yi~Su, Yixin Ji, Juntao Li, Hai Ye, and Min Zhang.
\newblock Beware of model collapse! fast and stable test-time adaptation for robust question answering.
\newblock In {\em Conference on Empirical Methods in Natural Language Processing}, 2023.

\bibitem{Gong2023SoTTART}
Taesik Gong, Yewon Kim, Taeckyung Lee, Sorn Chottananurak, and Sung-Ju Lee.
\newblock {SoTTA}: Robust test-time adaptation on noisy data streams.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{press2024enigma}
Ori Press, Ravid Shwartz-Ziv, Yann LeCun, and Matthias Bethge.
\newblock The entropy enigma: Success and failure of entropy minimization.
\newblock {\em arXiv preprint arXiv:2405.05012}, 2024.

\bibitem{wu2020entropy}
Xiaofu Wu, Suofei Zhang, Quan Zhou, Zhen Yang, Chunming Zhao, and Longin~Jan Latecki.
\newblock Entropy minimization versus diversity maximization for domain adaptation.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, 34(6):2896--2907, 2021.

\bibitem{morerio2017minimalentropy}
Pietro Morerio, Jacopo Cavazza, and Vittorio Murino.
\newblock Minimal-entropy correlation alignment for unsupervised deep domain adaptation.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{Shafer_2011}
Glenn Shafer, Alexander Shen, Nikolai Vereshchagin, and Vladimir Vovk.
\newblock Test martingales, bayes factors and p-values.
\newblock {\em Statistical Science}, 26(1), February 2011.

\bibitem{vovk2003testing}
Vladimir Vovk, Ilia Nouretdinov, and Alexander Gammerman.
\newblock Testing exchangeability on-line.
\newblock In {\em Proceedings of the 20th International Conference on Machine Learning (ICML)}, pages 768--775, 2003.

\bibitem{vovk2021protected}
Vladimir Vovk, Ivan Petej, and Alex Gammerman.
\newblock Protected probabilistic classification.
\newblock In {\em Conformal and Probabilistic Prediction and Applications}, pages 297--299, 2021.

\bibitem{orabona2015scalefree}
Francesco Orabona and D{\'a}vid P{\'a}l.
\newblock Scale-free algorithms for online linear optimization.
\newblock In {\em International Conference on Algorithmic Learning Theory}, pages 287--301, 2015.

\bibitem{orabona2018scale}
Francesco Orabona and D{\'a}vid P{\'a}l.
\newblock Scale-free online learning.
\newblock {\em Theoretical Computer Science}, 716:50--69, 2018.

\bibitem{orabona2016coin}
Francesco Orabona and D{\'a}vid P{\'a}l.
\newblock Coin betting and parameter-free online learning.
\newblock {\em Advances in Neural Information Processing Systems}, 29:577--585, 2016.

\bibitem{vovk2021protectedreg}
Vladimir Vovk.
\newblock Protected probabilistic regression.
\newblock Technical report, Tech. Rep, 2021.

\bibitem{villani2009optimal}
C{\'e}dric Villani.
\newblock {\em Optimal transport: old and new}, volume 338.
\newblock Springer, 2009.

\bibitem{dosovitskiy2021image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 770--778, 2016.

\bibitem{hendrycks_2018_2235448}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{venkateswara2017deep}
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 5018--5027, 2017.

\bibitem{courty2016optimal}
Nicolas Courty, R{\'e}mi Flamary, Devis Tuia, and Alain Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence}, 39(9):1853--1865, 2016.

\bibitem{kim2023reliable}
Eungyeup Kim, Mingjie Sun, Aditi Raghunathan, and J~Zico Kolter.
\newblock Reliable test-time adaptation via agreement-on-the-line.
\newblock In {\em NeurIPS Workshop on Distribution Shifts: New Frontiers with Foundation Models}, 2023.

\bibitem{shafer2019game}
Glenn Shafer and Vladimir Vovk.
\newblock Game-theoretic foundations for probability and finance.
\newblock {\em Wiley Series in Probability and Statistics}, 2019.

\bibitem{shekhar2023nonparametric}
Shubhanshu Shekhar and Aaditya Ramdas.
\newblock Nonparametric two-sample testing by betting.
\newblock {\em IEEE Transactions on Information Theory}, 2023.

\bibitem{podkopaev2024sequential}
Aleksandr Podkopaev and Aaditya Ramdas.
\newblock Sequential predictive two-sample and independence testing.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{shaer2023model}
Shalev Shaer, Gal Maman, and Yaniv Romano.
\newblock Model-{X} sequential testing for conditional independence via testing by betting.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 2054--2086, 2023.

\bibitem{grunwald2023anytime}
Peter Gr{\"u}nwald, Alexander Henzi, and Tyron Lardy.
\newblock Anytime-valid tests of conditional independence under model-{X}.
\newblock {\em Journal of the American Statistical Association}, pages 1--12, 2023.

\bibitem{fedorova2012plug}
Valentina Fedorova, Alex Gammerman, Ilia Nouretdinov, and Vladimir Vovk.
\newblock Plug-in martingales for testing exchangeability on-line.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 923--930, 2012.

\bibitem{vovk2022testing}
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer.
\newblock Testing exchangeability.
\newblock In {\em Algorithmic Learning in a Random World}, pages 227--263. Springer, 2022.

\bibitem{duan2022interactive}
Boyan Duan, Aaditya Ramdas, and Larry Wasserman.
\newblock Interactive rank testing by betting.
\newblock In {\em Conference on Causal Learning and Reasoning}, pages 201--235, 2022.

\bibitem{ramdas2022testing}
Aaditya Ramdas, Johannes Ruf, Martin Larsson, and Wouter~M Koolen.
\newblock Testing exchangeability: Fork-convexity, supermartingales and e-processes.
\newblock {\em International Journal of Approximate Reasoning}, 141:83--109, 2022.

\bibitem{saha2024testing}
Aytijhya Saha and Aaditya Ramdas.
\newblock Testing exchangeability by pairwise betting.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 4915--4923, 2024.

\bibitem{grunwald2020safe}
Peter Gr{\"u}nwald, Rianne de~Heide, and Wouter~M Koolen.
\newblock Safe testing.
\newblock In {\em IEEE Information Theory and Applications Workshop (ITA)}, pages 1--54, 2020.

\bibitem{shafer2011test}
Glenn Shafer, Alexander Shen, Nikolai Vereshchagin, and Vladimir Vovk.
\newblock Test martingales, bayes factors and p-values.
\newblock {\em Statistical Science}, 26(1):84, 2011.

\bibitem{vovk2021values}
Vladimir Vovk and Ruodu Wang.
\newblock E-values: Calibration, combination and applications.
\newblock {\em The Annals of Statistics}, 49(3):1736--1754, 2021.

\bibitem{ramdas2022game}
Aaditya Ramdas, Peter Gr{\"u}nwald, Vladimir Vovk, and Glenn Shafer.
\newblock Game-theoretic statistics and safe anytime-valid inference.
\newblock {\em Statistical Science}, 38(4):576--601, 2023.

\bibitem{howard2021time}
Steven~R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon.
\newblock Time-uniform, nonparametric, nonasymptotic confidence sequences.
\newblock {\em The Annals of Statistics}, 49(2), 2021.

\bibitem{waudby2023estimating}
Ian Waudby-Smith and Aaditya Ramdas.
\newblock Estimating means of bounded random variables by betting.
\newblock {\em Journal of the Royal Statistical Society Series B: Statistical Methodology}, 2023.

\bibitem{grunwald2023posterior}
Peter~D Gr{\"u}nwald.
\newblock The e-posterior.
\newblock {\em Philosophical Transactions of the Royal Society A}, 381(2247), 2023.

\bibitem{perez2022statistics}
Muriel~Felipe P{\'e}rez-Ortiz, Tyron Lardy, Rianne de~Heide, and Peter Gr{\"u}nwald.
\newblock E-statistics, group invariance and anytime valid testing.
\newblock {\em arXiv preprint arXiv:2208.07610}, 2022.

\bibitem{koolen2022log}
Wouter~M Koolen and Peter Gr{\"u}nwald.
\newblock Log-optimal anytime-valid e-values.
\newblock {\em International Journal of Approximate Reasoning}, 141:69--82, 2022.

\bibitem{vovk2023confidence}
Vladimir Vovk and Ruodu Wang.
\newblock Confidence and discoveries with e-values.
\newblock {\em Statistical Science}, 38(2):329--354, 2023.

\bibitem{shekhar2023reducing}
Shubhanshu Shekhar and Aaditya Ramdas.
\newblock Reducing sequential change detection to sequential estimation.
\newblock {\em arXiv preprint arXiv:2309.09111}, 2023.

\bibitem{shin2022detectors}
Jaehyeok Shin, Aaditya Ramdas, and Alessandro Rinaldo.
\newblock E-detectors: A nonparametric framework for sequential change detection.
\newblock {\em The New England Journal of Statistics in Data Science}, pages 1--32, 2023.

\bibitem{vovk2021testing}
Vladimir Vovk.
\newblock Testing randomness online.
\newblock {\em Statistical Science}, 36(4):595--611, 2021.

\bibitem{pmlr-v204-eliades23a}
Charalambos Eliades and Harris Papadopoulos.
\newblock A conformal martingales ensemble approach for addressing concept drift.
\newblock In {\em Conformal and Probabilistic Prediction with Applications}, volume 204, pages 328--346. PMLR, 2023.

\bibitem{vovk2020testing}
Vladimir Vovk.
\newblock Testing for concept shift online.
\newblock {\em arXiv preprint arXiv:2012.14246}, 2020.

\bibitem{dai2021testing}
Liang Dai and Mohamed-Rafik Bouguelia.
\newblock Testing exchangeability with martingale for change-point detection.
\newblock {\em International Journal of Ambient Computing and Intelligence (IJACI)}, 12(2):1--20, 2021.

\bibitem{vovk2021retrain}
Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Ernst Ahlberg, Lars Carlsson, and Alex Gammerman.
\newblock Retrain or not retrain: Conformal test martingales for change-point detection.
\newblock In {\em Conformal and Probabilistic Prediction and Applications}, pages 191--210. PMLR, 2021.

\bibitem{levy_pit}
Paul Lévy.
\newblock Théorie de l’addition de variables aléatoires. second edition 1954. (gauthier-villars, paris).
\newblock {\em The Mathematical Gazette}, 39, 1955.

\bibitem{wang2022continual}
Qin Wang, Olga Fink, Luc Van~Gool, and Dengxin Dai.
\newblock Continual test-time domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7201--7211, 2022.

\bibitem{yuan2023robust}
Longhui Yuan, Binhui Xie, and Shuang Li.
\newblock Robust test-time adaptation in dynamic scenarios.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15922--15932, 2023.

\bibitem{wang2023survey}
Zixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen, Sen Wang, and Zi~Huang.
\newblock In search of lost online test-time adaptation: {A} survey.
\newblock {\em arXiv preprint arXiv:2310.20199}, 2023.

\bibitem{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In {\em International Conference on Machine Learning}, pages 1321--1330. PMLR, 2017.

\bibitem{gong2022note}
Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee.
\newblock Note: Robust continual test-time adaptation against temporal correlation.
\newblock {\em Advances in Neural Information Processing Systems}, 35:27253--27266, 2022.

\bibitem{podkopaev2021distribution}
Aleksandr Podkopaev and Aaditya Ramdas.
\newblock Distribution-free uncertainty quantification for classification under label shift.
\newblock In {\em Uncertainty in artificial intelligence}, pages 844--853. PMLR, 2021.

\bibitem{zhou2023ods}
Zhi Zhou, Lan-Zhe Guo, Lin-Han Jia, Dingchu Zhang, and Yu-Feng Li.
\newblock Ods: Test-time adaptation in the presence of open-world data shift.
\newblock In {\em International Conference on Machine Learning}, pages 42574--42588. PMLR, 2023.

\bibitem{marsden2024universal}
Robert~A Marsden, Mario D{\"o}bler, and Bin Yang.
\newblock Universal test-time adaptation through weight ensembling, diversity weighting, and prior correction.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 2555--2565, 2024.

\bibitem{lu2023metatsallisentropy}
Menglong Lu, Zhen Huang, Zhiliang Tian, Yunxiang Zhao, Xuanyu Fei, and Dongsheng Li.
\newblock Meta-tsallis-entropy minimization: a new self-training approach for domain adaptation on text classification.
\newblock In {\em Proceedings of the International Joint Conference on Artificial Intelligence}, pages 5159--5169, 2023.

\bibitem{liu2021cycle}
Hong Liu, Jianmin Wang, and Mingsheng Long.
\newblock Cycle self-training for domain adaptation.
\newblock {\em Advances in Neural Information Processing Systems}, 34:22968--22981, 2021.

\bibitem{goyal2022testtime}
Sachin Goyal, Mingjie Sun, Aditi Raghunathan, and J~Zico Kolter.
\newblock Test time adaptation via conjugate pseudo-labels.
\newblock {\em Advances in Neural Information Processing Systems}, 35:6204--6218, 2022.

\bibitem{lee2013pseudo}
Dong-Hyun Lee et~al.
\newblock Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks.
\newblock In {\em Workshop on challenges in representation learning, ICML}, volume~3, page 896, 2013.

\bibitem{wang2023understanding}
Jun-Kun Wang and Andre Wibisono.
\newblock Towards understanding {GD} with hard and conjugate pseudo-labels for test-time adaptation.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{schneider2020improving}
Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge.
\newblock Improving robustness against common corruptions by covariate shift adaptation.
\newblock {\em Advances in neural information processing systems}, 33:11539--11551, 2020.

\bibitem{sun2020test}
Yu~Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under distribution shifts.
\newblock In {\em International conference on machine learning}, pages 9229--9248. PMLR, 2020.

\bibitem{chen2021representation}
Xinyang Chen, Sinan Wang, Jianmin Wang, and Mingsheng Long.
\newblock Representation subspace distance for domain adaptation regression.
\newblock In {\em ICML}, pages 1749--1759, 2021.

\bibitem{borgwardt2006integrating}
Karsten~M Borgwardt, Arthur Gretton, Malte~J Rasch, Hans-Peter Kriegel, Bernhard Sch{\"o}lkopf, and Alex~J Smola.
\newblock Integrating structured biological data by kernel maximum mean discrepancy.
\newblock {\em Bioinformatics}, 22(14):e49--e57, 2006.

\bibitem{bhatnagar2023improved}
Aadyot Bhatnagar, Huan Wang, Caiming Xiong, and Yu~Bai.
\newblock Improved online conformal prediction via strongly adaptive online learning.
\newblock In {\em Proceedings of the International Conference on Machine Learning}, pages 2337--2363. PMLR, 2023.

\bibitem{panaretos2019statistical}
Victor~M Panaretos and Yoav Zemel.
\newblock Statistical aspects of {Wasserstein} distances.
\newblock {\em Annual review of statistics and its application}, 6:405--431, 2019.

\bibitem{ville19391ere}
Jean Ville.
\newblock {\em 1ere these: Etude critique de la notion de collectif; 2eme these: La transformation de Laplace}.
\newblock PhD thesis, Gauthier-Villars \& Cie, 1939.

\end{thebibliography}
