\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa{-}Bianchi, and
  Fischer]{AuerCF02}
Auer, P., Cesa{-}Bianchi, N., and Fischer, P.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine Learning}, 47\penalty0 (2-3), 2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Auer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R.~E.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM Journal on Computing}, 32\penalty0 (1),
  2002{\natexlab{b}}.

\bibitem[Bistritz et~al.(2019)Bistritz, Zhou, Chen, Bambos, and
  Blanchet]{bistritz2019exp3}
Bistritz, I., Zhou, Z., Chen, X., Bambos, N., and Blanchet, J.~H.
\newblock Online {EXP3} learning in adversarial bandits with delayed feedback.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Bistritz et~al.(2022)Bistritz, Zhou, Chen, Bambos, and
  Blanchet]{bistritz2021nodiscounted}
Bistritz, I., Zhou, Z., Chen, X., Bambos, N., and Blanchet, J.
\newblock No weighted-regret learning in adversarial bandits with delays.
\newblock \emph{Journal of Machine Learning Research}, 23, 2022.

\bibitem[Cesa-Bianchi et~al.(2019)Cesa-Bianchi, Gentile, and
  Mansour]{cesa2019delay}
Cesa-Bianchi, N., Gentile, C., and Mansour, Y.
\newblock Delay and cooperation in nonstochastic bandits.
\newblock \emph{Journal of Machine Learning Research}, 20, 2019.

\bibitem[Eick(1988)]{Eic88}
Eick, S.~G.
\newblock The two-armed bandit with delayed responses.
\newblock \emph{The Annals of Statistics}, 1988.

\bibitem[Gyorgy \& Joulani(2021)Gyorgy and Joulani]{gyorgy21}
Gyorgy, A. and Joulani, P.
\newblock Adapting to delays and data in adversarial multi-armed bandits.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, volume 139, 2021.

\bibitem[{\VAN{Hoeven}{Van der}{van der}}~Hoeven \&
  Cesa-Bianchi(2022){\VAN{Hoeven}{Van der}{van der}}~Hoeven and
  Cesa-Bianchi]{van2022nonstochastic}
{\VAN{Hoeven}{Van der}{van der}}~Hoeven, D. and Cesa-Bianchi, N.
\newblock Nonstochastic bandits and experts with arm-dependent delays.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2022.

\bibitem[Joulani et~al.(2013)Joulani, Gyorgy, and
  Szepesv{\'a}ri]{joulani2013online}
Joulani, P., Gyorgy, A., and Szepesv{\'a}ri, C.
\newblock Online learning under delayed feedback.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Mann et~al.(2019)Mann, Gowal, Gy{\"{o}}rgy, Hu, Jiang,
  Lakshminarayanan, and Srinivasan]{mann2019learning}
Mann, T.~A., Gowal, S., Gy{\"{o}}rgy, A., Hu, H., Jiang, R., Lakshminarayanan,
  B., and Srinivasan, P.
\newblock Learning from delayed outcomes via proxies with applications to
  recommender systems.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Masoudian et~al.(2022)Masoudian, Zimmert, and Seldin]{Masoudian2022}
Masoudian, S., Zimmert, J., and Seldin, Y.
\newblock A best-of-both-worlds algorithm for bandits with delayed feedback.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Neu(2015)]{Neu15Implicit}
Neu, G.
\newblock Explore no more: Improved high-probability regret bounds for
  non-stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Neu et~al.(2010)Neu, Gy{\"o}rgy, Szepesv{\'a}ri, and
  Antos]{neu2010online}
Neu, G., Gy{\"o}rgy, A., Szepesv{\'a}ri, C., and Antos, A.
\newblock Online markov decision processes under bandit feedback.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2010.

\bibitem[Neu et~al.(2014)Neu, Gy{\"o}rgy, Szepesv{\'a}ri, and
  Antos]{neu2014online}
Neu, G., Gy{\"o}rgy, A., Szepesv{\'a}ri, C., and Antos, A.
\newblock Online markov decision processes under bandit feedback.
\newblock \emph{IEEE Transactions on Automatic Control}, 59, 2014.

\bibitem[Simon(1977)]{Sim77}
Simon, R.
\newblock Adaptive treatment assignment methods and clinical trials.
\newblock \emph{Biometrics}, 33, 1977.

\bibitem[Slivkins et~al.(2019)]{slivkins2019introduction}
Slivkins, A. et~al.
\newblock Introduction to multi-armed bandits.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  12\penalty0 (1-2), 2019.

\bibitem[Thompson(1933)]{Tho33}
Thompson, W.~R.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 25, 1933.

\bibitem[Thune et~al.(2019)Thune, Cesa-Bianchi, and
  Seldin]{thune2019nonstochastic}
Thune, T.~S., Cesa-Bianchi, N., and Seldin, Y.
\newblock Nonstochastic multiarmed bandits with unrestricted delays.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Vernade et~al.(2020)Vernade, Gy{\"{o}}rgy, and Mann]{Vernade0M20}
Vernade, C., Gy{\"{o}}rgy, A., and Mann, T.~A.
\newblock Non-stationary delayed bandits with intermediate observations.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, 2020.

\bibitem[Zimmert \& Seldin(2020)Zimmert and Seldin]{zimmert20}
Zimmert, J. and Seldin, Y.
\newblock An optimal algorithm for adversarial bandits with arbitrary delays.
\newblock In \emph{Proceedings on the International Conference on Artificial
  Intelligence and Statistics}, 2020.

\bibitem[Zimmert \& Seldin(2021)Zimmert and Seldin]{ZimmertS21}
Zimmert, J. and Seldin, Y.
\newblock Tsallis-{INF}: An optimal algorithm for stochastic and adversarial
  bandits.
\newblock \emph{Journal of Machine Learning Research}, 22, 2021.

\end{thebibliography}
