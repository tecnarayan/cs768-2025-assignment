\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Akiba et~al.(2019)Akiba, Sano, Yanase, Ohta, and
  Koyama]{akiba2019optuna}
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M.
\newblock Optuna: A next-generation hyperparameter optimization framework.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pp.\  2623--2631, 2019.

\bibitem[Austin et~al.(2021)Austin, Johnson, Ho, Tarlow, and van~den
  Berg]{austin2021structured}
Austin, J., Johnson, D.~D., Ho, J., Tarlow, D., and van~den Berg, R.
\newblock Structured denoising diffusion models in discrete state-spaces.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 17981--17993, 2021.

\bibitem[Baldi et~al.(2014)Baldi, Sadowski, and Whiteson]{higgs}
Baldi, P., Sadowski, P., and Whiteson, D.
\newblock Searching for exotic particles in high-energy physics with deep
  learning.
\newblock \emph{Nature Communications}, 5, 2014.

\bibitem[Baranchuk et~al.(2021)Baranchuk, Rubachev, Voynov, Khrulkov, and
  Babenko]{baranchuk2021label}
Baranchuk, D., Rubachev, I., Voynov, A., Khrulkov, V., and Babenko, A.
\newblock Label-efficient semantic segmentation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.03126}, 2021.

\bibitem[Camino et~al.(2020)Camino, Hammerschmidt,
  et~al.]{camino2020oversampling}
Camino, R.~D., Hammerschmidt, C.~A., et~al.
\newblock Oversampling tabular data with deep generative models: Is it worth
  the effort?
\newblock 2020.

\bibitem[Campbell et~al.(2022)Campbell, Benton, De~Bortoli, Rainforth,
  Deligiannidis, and Doucet]{campbell2022continuous}
Campbell, A., Benton, J., De~Bortoli, V., Rainforth, T., Deligiannidis, G., and
  Doucet, A.
\newblock A continuous time framework for discrete denoising models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 28266--28279, 2022.

\bibitem[Chawla et~al.(2002)Chawla, Bowyer, Hall, and
  Kegelmeyer]{chawla2002smote}
Chawla, N.~V., Bowyer, K.~W., Hall, L.~O., and Kegelmeyer, W.~P.
\newblock Smote: synthetic minority over-sampling technique.
\newblock \emph{Journal of artificial intelligence research}, 16:\penalty0
  321--357, 2002.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Yu, Zhang, and
  Fritz]{chen2020gan}
Chen, D., Yu, N., Zhang, Y., and Fritz, M.
\newblock Gan-leaks: A taxonomy of membership inference attacks against
  generative models.
\newblock In \emph{Proceedings of the 2020 ACM SIGSAC conference on computer
  and communications security}, pp.\  343--362, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Zhang, Zen, Weiss, Norouzi, and
  Chan]{chen2020wavegrad}
Chen, N., Zhang, Y., Zen, H., Weiss, R.~J., Norouzi, M., and Chan, W.
\newblock Wavegrad: Estimating gradients for waveform generation.
\newblock \emph{arXiv preprint arXiv:2009.00713}, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2022)Chen, Zhang, and Hinton]{chen2022analog}
Chen, T., Zhang, R., and Hinton, G.
\newblock Analog bits: Generating discrete data using diffusion models with
  self-conditioning.
\newblock \emph{arXiv preprint arXiv:2208.04202}, 2022.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal2021diffusion}
Dhariwal, P. and Nichol, A.
\newblock Diffusion models beat gans on image synthesis.
\newblock 2021.

\bibitem[Engelmann \& Lessmann(2021)Engelmann and
  Lessmann]{engelmann2021conditional}
Engelmann, J. and Lessmann, S.
\newblock Conditional wasserstein gan-based oversampling of tabular data for
  imbalanced learning.
\newblock \emph{Expert Systems with Applications}, 174:\penalty0 114582, 2021.

\bibitem[Fan et~al.(2020)Fan, Liu, Li, Chen, Shen, and Du]{fan2020relational}
Fan, J., Liu, T., Li, G., Chen, J., Shen, Y., and Du, X.
\newblock Relational data synthesis using generative adversarial networks: A
  design space exploration.
\newblock \emph{arXiv preprint arXiv:2008.12763}, 2020.

\bibitem[Gorishniy et~al.(2021)Gorishniy, Rubachev, Khrulkov, and
  Babenko]{gorishniy2021revisiting}
Gorishniy, Y., Rubachev, I., Khrulkov, V., and Babenko, A.
\newblock Revisiting deep learning models for tabular data.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 18932--18943, 2021.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock 2020.

\bibitem[Hoogeboom et~al.(2021)Hoogeboom, Nielsen, Jaini, Forr{\'e}, and
  Welling]{hoogeboom2021argmax}
Hoogeboom, E., Nielsen, D., Jaini, P., Forr{\'e}, P., and Welling, M.
\newblock Argmax flows and multinomial diffusion: Learning categorical
  distributions.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 12454--12465, 2021.

\bibitem[Hoogeboom et~al.(2022)Hoogeboom, Satorras, Vignac, and
  Welling]{hoogeboom2022equivariant}
Hoogeboom, E., Satorras, V.~G., Vignac, C., and Welling, M.
\newblock Equivariant diffusion for molecule generation in 3d.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8867--8887. PMLR, 2022.

\bibitem[Jing et~al.(2022)Jing, Corso, Chang, Barzilay, and
  Jaakkola]{jing2022torsional}
Jing, B., Corso, G., Chang, J., Barzilay, R., and Jaakkola, T.
\newblock Torsional diffusion for molecular conformer generation.
\newblock \emph{arXiv preprint arXiv:2206.01729}, 2022.

\bibitem[Jordon et~al.(2018)Jordon, Yoon, and Van Der~Schaar]{jordon2018pate}
Jordon, J., Yoon, J., and Van Der~Schaar, M.
\newblock Pate-gan: Generating synthetic data with differential privacy
  guarantees.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[{Kelley Pace} \& Barry(1997){Kelley Pace} and Barry]{california}
{Kelley Pace}, R. and Barry, R.
\newblock Sparse spatial autoregressions.
\newblock \emph{Statistics \& Probability Letters}, 33\penalty0 (3):\penalty0
  291--297, 1997.

\bibitem[Kim et~al.(2021)Kim, Jeon, Lee, Hyeong, and Park]{kim2021oct}
Kim, J., Jeon, J., Lee, J., Hyeong, J., and Park, N.
\newblock Oct-gan: Neural ode-based conditional tabular gans.
\newblock In \emph{Proceedings of the Web Conference 2021}, pp.\  1506--1515,
  2021.

\bibitem[Kim et~al.(2022)Kim, Lee, Shin, Park, Kim, Park, and Cho]{kim2022sos}
Kim, J., Lee, C., Shin, Y., Park, S., Kim, M., Park, N., and Cho, J.
\newblock Sos: Score-based oversampling for tabular data.
\newblock In \emph{Proceedings of the 28th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining}, pp.\  762--772, 2022.

\bibitem[Kohavi(1996)]{adult}
Kohavi, R.
\newblock Scaling up the accuracy of naive-bayes classifiers: a decision-tree
  hybrid.
\newblock In \emph{KDD}, 1996.

\bibitem[Kong et~al.(2020)Kong, Ping, Huang, Zhao, and
  Catanzaro]{kong2020diffwave}
Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.
\newblock Diffwave: A versatile diffusion model for audio synthesis.
\newblock \emph{arXiv preprint arXiv:2009.09761}, 2020.

\bibitem[Lee et~al.(2021)Lee, Hyeong, Jeon, Park, and Cho]{lee2021invertible}
Lee, J., Hyeong, J., Jeon, J., Park, N., and Cho, J.
\newblock Invertible tabular gans: Killing two birds with one stone for tabular
  data synthesis.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 4263--4273, 2021.

\bibitem[Li et~al.(2021)Li, Yang, Chang, Feng, Xu, Li, and Chen]{li2021srdiff}
Li, H., Yang, Y., Chang, M., Feng, H., Xu, Z., Li, Q., and Chen, Y.
\newblock Srdiff: Single image super-resolution with diffusion probabilistic
  models.
\newblock 2021.

\bibitem[Li et~al.(2022)Li, Thickstun, Gulrajani, Liang, and
  Hashimoto]{li2022diffusion}
Li, X.~L., Thickstun, J., Gulrajani, I., Liang, P., and Hashimoto, T.~B.
\newblock Diffusion-lm improves controllable text generation.
\newblock \emph{arXiv preprint arXiv:2205.14217}, 2022.

\bibitem[Madeo et~al.(2013)Madeo, Lima, and Peres]{gesture}
Madeo, R. C.~B., Lima, C. A.~M., and Peres, S.~M.
\newblock Gesture unit segmentation using support vector machines: segmenting
  gestures from rest positions.
\newblock In \emph{Proceedings of the 28th Annual {ACM} Symposium on Applied
  Computing, {SAC}}, 2013.

\bibitem[Meng et~al.(2021)Meng, Song, Song, Wu, Zhu, and Ermon]{meng2021sdedit}
Meng, C., Song, Y., Song, J., Wu, J., Zhu, J.-Y., and Ermon, S.
\newblock Sdedit: Image synthesis and editing with stochastic differential
  equations.
\newblock 2021.

\bibitem[Naeem et~al.(2020)Naeem, Oh, Uh, Choi, and Yoo]{naeem2020reliable}
Naeem, M.~F., Oh, S.~J., Uh, Y., Choi, Y., and Yoo, J.
\newblock Reliable fidelity and diversity metrics for generative models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7176--7185. PMLR, 2020.

\bibitem[Nazabal et~al.(2020)Nazabal, Olmos, Ghahramani, and
  Valera]{nazabal2020handling}
Nazabal, A., Olmos, P.~M., Ghahramani, Z., and Valera, I.
\newblock Handling incomplete heterogeneous data using vaes.
\newblock \emph{Pattern Recognition}, 107:\penalty0 107501, 2020.

\bibitem[Nichol(2021)]{nichol2021improved}
Nichol, Alex \&~Dhariwal, P.
\newblock Improved denoising diffusion probabilistic models.
\newblock \emph{ICML}, 2021.

\bibitem[Nock \& Guillame-Bert(2022)Nock and Guillame-Bert]{nock2022generative}
Nock, R. and Guillame-Bert, M.
\newblock Generative trees: Adversarial and copycat.
\newblock \emph{ICML}, 2022.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Prokhorenkova et~al.(2018)Prokhorenkova, Gusev, Vorobev, Dorogush, and
  Gulin]{prokhorenkova2018catboost}
Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A.~V., and Gulin, A.
\newblock Catboost: unbiased boosting with categorical features.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10684--10695, 2022.

\bibitem[Saharia et~al.(2021)Saharia, Ho, Chan, Salimans, Fleet, and
  Norouzi]{saharia2021image}
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D.~J., and Norouzi, M.
\newblock Image super-resolution via iterative refinement.
\newblock 2021.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Ayan, Mahdavi, Lopes, et~al.]{saharia2022photorealistic}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour,
  S. K.~S., Ayan, B.~K., Mahdavi, S.~S., Lopes, R.~G., et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock \emph{arXiv preprint arXiv:2205.11487}, 2022.

\bibitem[Singh et~al.(2015)Singh, Sandhu, and Kumar]{fb-comments}
Singh, K., Sandhu, R.~K., and Kumar, D.
\newblock Comment volume prediction using neural networks and decision trees.
\newblock In \emph{IEEE UKSim-AMSS 17th International Conference on Computer
  Modelling and Simulation, UKSim}, 2015.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{ICML}, 2015.

\bibitem[Song \& Ermon(2019)Song and Ermon]{song2019generative}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Song \& Ermon(2020)Song and Ermon]{song2020improved}
Song, Y. and Ermon, S.
\newblock Improved techniques for training score-based generative models.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock 2021.

\bibitem[Tashiro et~al.(2021)Tashiro, Song, Song, and Ermon]{tashiro2021csdi}
Tashiro, Y., Song, J., Song, Y., and Ermon, S.
\newblock Csdi: Conditional score-based diffusion models for probabilistic time
  series imputation.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 24804--24816, 2021.

\bibitem[Torfi et~al.(2022)Torfi, Fox, and Reddy]{torfi2022differentially}
Torfi, A., Fox, E.~A., and Reddy, C.~K.
\newblock Differentially private synthetic medical data generation using
  convolutional gans.
\newblock \emph{Information Sciences}, 586:\penalty0 485--500, 2022.

\bibitem[Vanschoren et~al.(2014)Vanschoren, van Rijn, Bischl, and
  Torgo]{openml}
Vanschoren, J., van Rijn, J.~N., Bischl, B., and Torgo, L.
\newblock Openml: networked science in machine learning.
\newblock \emph{arXiv}, 1407.7722v1, 2014.

\bibitem[Wen et~al.(2022)Wen, Cao, Yang, Subbalakshmi, and
  Chandramouli]{wen2022causal}
Wen, B., Cao, Y., Yang, F., Subbalakshmi, K., and Chandramouli, R.
\newblock Causal-tgan: Modeling tabular data using causally-aware gan.
\newblock In \emph{ICLR Workshop on Deep Generative Models for Highly
  Structured Data}, 2022.

\bibitem[Xu et~al.(2019)Xu, Skoularidou, Cuesta-Infante, and
  Veeramachaneni]{xu2019modeling}
Xu, L., Skoularidou, M., Cuesta-Infante, A., and Veeramachaneni, K.
\newblock Modeling tabular data using conditional gan.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Zaidi, Zhou, and Li]{zhang2021ganblr}
Zhang, Y., Zaidi, N.~A., Zhou, J., and Li, G.
\newblock Ganblr: a tabular data generation model.
\newblock In \emph{2021 IEEE International Conference on Data Mining (ICDM)},
  pp.\  181--190. IEEE, 2021.

\bibitem[Zhao et~al.(2021)Zhao, Kunar, Birke, and Chen]{zhao2021ctab}
Zhao, Z., Kunar, A., Birke, R., and Chen, L.~Y.
\newblock Ctab-gan: Effective table data synthesizing.
\newblock In \emph{Asian Conference on Machine Learning}, pp.\  97--112. PMLR,
  2021.

\bibitem[Zhao et~al.(2022)Zhao, Kunar, Birke, and Chen]{zhao2022ctab}
Zhao, Z., Kunar, A., Birke, R., and Chen, L.~Y.
\newblock Ctab-gan+: Enhancing tabular data synthesis.
\newblock \emph{arXiv preprint arXiv:2204.00401}, 2022.

\bibitem[Zheng \& Charoenphakdee(2022)Zheng and
  Charoenphakdee]{zheng2022diffusion}
Zheng, S. and Charoenphakdee, N.
\newblock Diffusion models for missing value imputation in tabular data.
\newblock \emph{arXiv preprint arXiv:2210.17128}, 2022.

\end{thebibliography}
