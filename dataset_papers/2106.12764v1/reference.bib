@article{Ray2019,
    author = {Ray, Alex and Achiam, Joshua and Amodei, Dario},
    title = {{Benchmarking Safe Exploration in Deep Reinforcement Learning}},
    year = {2019}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{luo1993convergence,
  title={On the convergence rate of dual ascent methods for linearly constrained convex minimization},
  author={Luo, Zhi-Quan and Tseng, Paul},
  journal={Mathematics of Operations Research},
  volume={18},
  number={4},
  pages={846--867},
  year={1993},
  publisher={INFORMS}
}

@article{boyd2003subgradient,
  title={Subgradient methods},
  author={Boyd, Stephen and Xiao, Lin and Mutapcic, Almir},
  journal={lecture notes of EE392o, Stanford University, Autumn Quarter},
  volume={2004},
  pages={2004--2005},
  year={2003}
}


@article{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  journal={arXiv preprint arXiv:1901.11275},
  year={2019}
}

@article{ding2020natural,
  title={Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes},
  author={Ding, Dongsheng and Zhang, Kaiqing and Basar, Tamer and Jovanovic, Mihailo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}
@misc{kerneldensitycmu,
  author        = {Larry Wasserman},
  title         = {Lecture notes in Statistical Methods for Machine Learning},
  url   = {http://www.stat.cmu.edu/~larry/=sml/densityestimation.pdf},
  note = "Online material, last visited on 2019/08/25",
  year={2019}
}

@article{us2019flue,
	title={Alternative fuels data center},
	author={United States Department of Energy},
	year={2019}
}

@article{borkar2002q,
	title={Q-learning for risk-sensitive control},
	author={Borkar, Vivek S},
	journal={Mathematics of operations research},
	volume={27},
	number={2},
	pages={294--311},
	year={2002},
	publisher={INFORMS}
}
@incollection{brockett2012notes,
  title={Notes on the control of the Liouville equation},
  author={Brockett, Roger},
  booktitle={Control of partial differential equations},
  pages={101--129},
  year={2012},
  publisher={Springer}
}
@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}



@book{van1995python,
  title={Python tutorial},
  author={Van Rossum, Guido and Drake Jr, Fred L},
  volume={620},
  year={1995},
  publisher={Centrum voor Wiskunde en Informatica Amsterdam}
}

@misc{traue2019reinforcement,
    title={Towards a Reinforcement Learning Environment Toolbox for Intelligent Electric Motor Control},
    author={Arne Traue and Gerrit Book and Wilhelm Kirchg√§ssner and Oliver Wallscheid},
    year={2019},
    eprint={1910.09434},
    archivePrefix={arXiv},
    primaryClass={eess.SY}
}

@inproceedings{lotjens2019safe,
	title={Safe reinforcement learning with model uncertainty estimates},
	author={L{\"o}tjens, Bj{\"o}rn and Everett, Michael and How, Jonathan P},
	booktitle={2019 International Conference on Robotics and Automation (ICRA)},
	pages={8662--8668},
	year={2019},
	organization={IEEE}
}

@article{geibel2005risk,
	title={Risk-sensitive reinforcement learning applied to control under constraints},
	author={Geibel, Peter and Wysotzki, Fritz},
	journal={Journal of Artificial Intelligence Research},
	volume={24},
	pages={81--108},
	year={2005}
}

@inproceedings{chow2018lyapunov,
	title={A lyapunov-based approach to safe reinforcement learning},
	author={Chow, Yinlam and Nachum, Ofir and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
	booktitle={Advances in neural information processing systems},
	pages={8092--8101},
	year={2018}
}

@inproceedings{thomaz2006reinforcement,
	title={Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance},
	author={Thomaz, Andrea Lockerd and Breazeal, Cynthia and others},
	booktitle={Aaai},
	volume={6},
	pages={1000--1005},
	year={2006},
	organization={Boston, MA}
}

@incollection{clouse1992teaching,
	title={A teaching method for reinforcement learning},
	author={Clouse, Jeffery A and Utgoff, Paul E},
	booktitle={Machine Learning Proceedings 1992},
	pages={92--101},
	year={1992},
	publisher={Elsevier}
}

@article{geramifard2013intelligent,
	title={Intelligent cooperative control architecture: a framework for performance improvement using safe learning},
	author={Geramifard, Alborz and Redding, Joshua and How, Jonathan P},
	journal={Journal of Intelligent \& Robotic Systems},
	volume={72},
	number={1},
	pages={83--103},
	year={2013},
	publisher={Springer}
}

@inproceedings{tang2010parameterized,
	title={Parameterized maneuver learning for autonomous helicopter flight},
	author={Tang, Jie and Singh, Arjun and Goehausen, Nimbus and Abbeel, Pieter},
	booktitle={2010 IEEE International Conference on Robotics and Automation},
	pages={1142--1148},
	year={2010},
	organization={IEEE}
}

@article{abbeel2010autonomous,
	title={Autonomous helicopter aerobatics through apprenticeship learning},
	author={Abbeel, Pieter and Coates, Adam and Ng, Andrew Y},
	journal={The International Journal of Robotics Research},
	volume={29},
	number={13},
	pages={1608--1639},
	year={2010},
	publisher={SAGE Publications Sage UK: London, England}
}

@article{moldovan2012safe,
	title={Safe exploration in Markov decision processes},
	author={Moldovan, Teodor Mihai and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1205.4810},
	year={2012}
}

@article{kadota2006discounted,
	title={Discounted Markov decision processes with utility constraints},
	author={Kadota, Yoshinobu and Kurano, Masami and Yasuda, Masami},
	journal={Computers \& Mathematics with Applications},
	volume={51},
	number={2},
	pages={279--284},
	year={2006},
	publisher={Elsevier}
}

@inproceedings{dotan2012policy,
	title={Policy gradients with variance related risk criteria},
	author={Dotan Di Castro, Aviv Tamar and Mannor, Shie},
	booktitle={Proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, UK},
	year={2012}
}

@article{sato2001td,
	title={TD algorithm for the variance of return and mean-variance reinforcement learning},
	author={Sato, Makoto and Kimura, Hajime and Kobayashi, Shibenobu},
	journal={Transactions of the Japanese Society for Artificial Intelligence},
	volume={16},
	number={3},
	pages={353--362},
	year={2001},
	publisher={Japanese Society for Artificial Intelligence}
}

@article{basu2008learning,
	title={A learning algorithm for risk-sensitive cost},
	author={Basu, Arnab and Bhattacharyya, Tirthankar and Borkar, Vivek S},
	journal={Mathematics of operations research},
	volume={33},
	number={4},
	pages={880--898},
	year={2008},
	publisher={Informs}
}

@article{garcia2015comprehensive,
	title={A comprehensive survey on safe reinforcement learning},
	author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
	journal={Journal of Machine Learning Research},
	volume={16},
	number={1},
	pages={1437--1480},
	year={2015}
}

@incollection{heger1994consideration,
	title={Consideration of risk in reinforcement learning},
	author={Heger, Matthias},
	booktitle={Machine Learning Proceedings 1994},
	pages={105--111},
	year={1994},
	publisher={Elsevier}
}

@article{nilim2005robust,
	title={Robust control of Markov decision processes with uncertain transition matrices},
	author={Nilim, Arnab and El Ghaoui, Laurent},
	journal={Operations Research},
	volume={53},
	number={5},
	pages={780--798},
	year={2005},
	publisher={INFORMS}
}

@article{howard1972risk,
	title={Risk-sensitive Markov decision processes},
	author={Howard, Ronald A and Matheson, James E},
	journal={Management science},
	volume={18},
	number={7},
	pages={356--369},
	year={1972},
	publisher={INFORMS}
}

@article{gerwinski1999analytic,
  title={Analytic approach to the critical density in cellular automata for traffic flow},
  author={Gerwinski, M and Krug, J},
  journal={Physical Review E},
  volume={60},
  number={1},
  pages={188},
  year={1999},
  publisher={APS}
}

@inproceedings{paternain2019constrained,
  title={Constrained Reinforcement Learning Has Zero Duality Gap},
  author={Paternain, Santiago and Chamon, Luiz and Calvo-Fullana, Miguel and Ribeiro, Alejandro},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={7553--7563},
  year={2019}
}

@article{yang1991direct,
  title={Direct calculation of electron density in density-functional theory},
  author={Yang, Weitao},
  journal={Physical review letters},
  volume={66},
  number={11},
  pages={1438},
  year={1991},
  publisher={APS}
}

@article{bovopoulos1992effect,
  title={The effect of delayed feedback information on network performance},
  author={Bovopoulos, Andreas D and Lazar, Aurel A},
  journal={Annals of Operations Research},
  volume={36},
  number={1},
  pages={101--124},
  year={1992},
  publisher={Springer}
}

@inproceedings{pham2018optlayer,
  title={Optlayer-practical constrained optimization for deep reinforcement learning in the real world},
  author={Pham, Tu-Hoa and De Magistris, Giovanni and Tachibana, Ryuki},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6236--6243},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{hou2017optimization,
  title={Optimization of web service-based control system for balance between network traffic and delay},
  author={Hou, Chen and Zhao, Qianchuan},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={15},
  number={3},
  pages={1152--1162},
  year={2017},
  publisher={IEEE}
}

@book{altman1999constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  volume={7},
  year={1999},
  publisher={CRC Press}
}

@incollection{altman2000constrained,
  title={Constrained markov games: Nash equilibria},
  author={Altman, Eitan and Shwartz, Adam},
  booktitle={Advances in Dynamic Games and Applications},
  pages={213--221},
  year={2000},
  publisher={Springer}
}

@article{zhang2020first,
  title={First Order Constrained Optimization in Policy Space},
  author={Zhang, Yiming and Vuong, Quan and Ross, Keith},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{stooke2020responsive,
  title={Responsive safety in reinforcement learning by pid lagrangian methods},
  author={Stooke, Adam and Achiam, Joshua and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={9133--9143},
  year={2020},
  organization={PMLR}
}

@article{dalal2018safe,
  title={Safe exploration in continuous action spaces},
  author={Dalal, Gal and Dvijotham, Krishnamurthy and Vecerik, Matej and Hester, Todd and Paduraru, Cosmin and Tassa, Yuval},
  journal={arXiv preprint arXiv:1801.08757},
  year={2018}
}

@inproceedings{Yang2020Projection,
title={Projection-Based Constrained Policy Optimization},
author={Tsung-Yen Yang and Justinian Rosca and Karthik Narasimhan and Peter J. Ramadge},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{eltom1991motor,
  author={A. H. {Eltom} and N. S. {Moharari}},
  journal={IEEE Transactions on Energy Conversion}, 
  title={Motor temperature estimation incorporating dynamic rotor impedance}, 
  year={1991},
  volume={6},
  number={1},
  pages={107-113}
  }

@inproceedings{tessler2019reward,
	title="Reward Constrained Policy Optimization",
	author="Chen {Tessler} and Daniel J {Mankowitz} and Shie {Mannor}",
	booktitle="International Conference on Learning Representations (ICLR)",
	year="2019"
}

@inproceedings{achiam2017cpo,
	title="Constrained policy optimization",
	author="Joshua {Achiam} and David {Held} and Aviv {Tamar} and Pieter {Abbeel}",
	booktitle="International Conference on Machine Learning (ICML)",
	pages="22--31",
	year="2017"
}

@misc{lillicrap2016ddpg,
	title="Continuous control with deep reinforcement learning",
	author="Timothy P. {Lillicrap} and Jonathan J. {Hunt} and Alexander {Pritzel} and Nicolas {Heess} and Tom {Erez} and Yuval {Tassa} and David {Silver} and Daan {Wierstra}",
	year="2016"
}

@article{chen2019density,
author = {Chen, Yuxiao and Singletary, Andrew and Ames, Aaron},
year = {2019},
month = {10},
title = {Density Functions for Guaranteed Safety on Robotic Systems},
journal = {American Control Conference}
}

@article{rantzer2001a,
	title="A dual to Lyapunov's stability theorem",
	author="Anders {Rantzer}",
	journal="Systems and Control Letters",
	volume="42",
	number="3",
	pages="161--168",
	year="2001"
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{chen2019duality,
	title="Duality between density function and value function with applications in constrained optimal control and Markov Decision Process",
	author="Yuxiao {Chen} and Aaron D. {Ames}",
	journal="arXiv preprint arXiv:1902.09583",
	year="2019"
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{blahoudek2020qualitative,
  title={Qualitative Controller Synthesis for Consumption Markov Decision Processes},
  author={Blahoudek, Franti{\v{s}}ek and Br{\'a}zdil, Tom{\'a}{\v{s}} and Novotn{\`y}, Petr and Ornik, Melkior and Thangeda, Pranay and Topcu, Ufuk},
  journal={International Conference on Computer-aided Verification},
  year={2020}
}

@article{chen2017tutorial,
  title={A tutorial on kernel density estimation and recent advances},
  author={Chen, Yen-Chi},
  journal={Biostatistics \& Epidemiology},
  volume={1},
  number={1},
  pages={161--187},
  year={2017},
  publisher={Taylor \& Francis}
}
@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2318--2328},
  year={2019}
}
@article{nachum2020reinforcement,
  title={Reinforcement learning via fenchel-rockafellar duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}
@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}