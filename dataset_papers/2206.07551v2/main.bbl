\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arazo et~al.(2019)Arazo, Ortego, Albert, O’Connor, and
  Mcguinness]{arazo2019unsupervised}
E.~Arazo, D.~Ortego, P.~Albert, N.~O’Connor, and K.~Mcguinness.
\newblock Unsupervised label noise modeling and loss correction.
\newblock In \emph{International Conference on Machine Learning}, pages
  312--321, 2019.

\bibitem[Baktashmotlagh et~al.(2014)Baktashmotlagh, Harandi, Lovell, and
  Salzmann]{baktashmotlagh2014domain}
M.~Baktashmotlagh, M.~T. Harandi, B.~C. Lovell, and M.~Salzmann.
\newblock Domain adaptation on the statistical manifold.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2481--2488, 2014.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
S.~Ben-David, J.~Blitzer, K.~Crammer, A.~Kulesza, F.~Pereira, and J.~W.
  Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1):\penalty0 151--175, 2010.

\bibitem[Bendale and Boult(2016)]{Bendale_2016_CVPR}
A.~Bendale and T.~E. Boult.
\newblock Towards open set deep networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem[Borgwardt et~al.(2006)Borgwardt, Gretton, Rasch, Kriegel,
  Sch{\"o}lkopf, and Smola]{borgwardt2006integrating}
K.~M. Borgwardt, A.~Gretton, M.~J. Rasch, H.-P. Kriegel, B.~Sch{\"o}lkopf, and
  A.~J. Smola.
\newblock Integrating structured biological data by kernel maximum mean
  discrepancy.
\newblock \emph{Bioinformatics}, 22\penalty0 (14):\penalty0 e49--e57, 2006.

\bibitem[Bucci et~al.(2020)Bucci, Loghmani, and Tommasi]{ROS2020ECCV}
S.~Bucci, M.~R. Loghmani, and T.~Tommasi.
\newblock On the effectiveness of image rotation for open set domain
  adaptation.
\newblock In \emph{European Conference on Computer Vision}, pages 422--438.
  Springer, 2020.

\bibitem[Chen et~al.(2020)Chen, Qiao, Shi, Peng, Li, Huang, Pu, and
  Tian]{chen2020learning}
G.~Chen, L.~Qiao, Y.~Shi, P.~Peng, J.~Li, T.~Huang, S.~Pu, and Y.~Tian.
\newblock Learning open set network with discriminative reciprocal points.
\newblock In \emph{European Conference on Computer Vision}, pages 507--522.
  Springer, 2020.

\bibitem[Chen et~al.(2021)Chen, Peng, Wang, and Tian]{chen2021adversarial}
G.~Chen, P.~Peng, X.~Wang, and Y.~Tian.
\newblock Adversarial reciprocal points learning for open set recognition.
\newblock \emph{arXiv preprint arXiv:2103.00953}, 2021.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
E.~D. Cubuk, B.~Zoph, J.~Shlens, and Q.~V. Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, pages 702--703, 2020.

\bibitem[{Fang} et~al.(2020){Fang}, {Lu}, {Liu}, {Xuan}, and
  {Zhang}]{fang2020open}
Z.~{Fang}, J.~{Lu}, F.~{Liu}, J.~{Xuan}, and G.~{Zhang}.
\newblock Open set domain adaptation: Theoretical bound and algorithm.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  pages 1--14, 2020.
\newblock \doi{10.1109/TNNLS.2020.3017213}.

\bibitem[Ganin and Lempitsky(2015)]{ganin2015unsupervised}
Y.~Ganin and V.~Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International conference on machine learning}, pages
  1180--1189. PMLR, 2015.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette,
  M.~Marchand, and V.~Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem[Grandvalet and Bengio(2004)]{grandvalet2004semi}
Y.~Grandvalet and Y.~Bengio.
\newblock Semi-supervised learning by entropy minimization.
\newblock \emph{Advances in neural information processing systems}, 17, 2004.

\bibitem[Grandvalet and Bengio(2005)]{grandvalet2005semi}
Y.~Grandvalet and Y.~Bengio.
\newblock Semi-supervised learning by entropy minimization.
\newblock In \emph{Advances in neural information processing systems}, pages
  529--536, 2005.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He_2016_CVPR}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
G.~Huang, Z.~Liu, L.~Van Der~Maaten, and K.~Q. Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708, 2017.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kumar et~al.(2020)Kumar, Ma, and Liang]{kumar2020understanding}
A.~Kumar, T.~Ma, and P.~Liang.
\newblock Understanding self-training for gradual domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  5468--5479. PMLR, 2020.

\bibitem[Li et~al.(2021)Li, Kang, Zhu, Wei, and Yang]{li2021domain}
G.~Li, G.~Kang, Y.~Zhu, Y.~Wei, and Y.~Yang.
\newblock Domain consensus clustering for universal domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9757--9766, 2021.

\bibitem[Liu et~al.(2019)Liu, Cao, Long, Wang, and Yang]{liu2019separate}
H.~Liu, Z.~Cao, M.~Long, J.~Wang, and Q.~Yang.
\newblock Separate to adapt: Open set domain adaptation via progressive
  separation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2927--2936, 2019.

\bibitem[Liu et~al.(2021)Liu, Wang, and Long]{liu2021cycle}
H.~Liu, J.~Wang, and M.~Long.
\newblock Cycle self-training for domain adaptation.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Long et~al.(2015{\natexlab{a}})Long, Cao, Wang, and
  Jordan]{long2015learning}
M.~Long, Y.~Cao, J.~Wang, and M.~I. Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{Proceedings of the 32nd International Conference on
  International Conference on Machine Learning-Volume 37}, pages 97--105,
  2015{\natexlab{a}}.

\bibitem[Long et~al.(2015{\natexlab{b}})Long, Cao, Wang, and
  Jordan]{long2015trans}
M.~Long, Y.~Cao, J.~Wang, and M.~I. Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{Proceedings of the 32nd International Conference on
  International Conference on Machine Learning - Volume 37}, ICML'15, page
  97–105. JMLR.org, 2015{\natexlab{b}}.

\bibitem[Long et~al.(2016)Long, Zhu, Wang, and Jordan]{long2016unsupervised}
M.~Long, H.~Zhu, J.~Wang, and M.~I. Jordan.
\newblock Unsupervised domain adaptation with residual transfer networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  136--144, 2016.

\bibitem[Long et~al.(2017{\natexlab{a}})Long, Cao, Wang, and
  Jordan]{long2017conditional}
M.~Long, Z.~Cao, J.~Wang, and M.~I. Jordan.
\newblock Conditional adversarial domain adaptation.
\newblock \emph{arXiv preprint arXiv:1705.10667}, 2017{\natexlab{a}}.

\bibitem[Long et~al.(2017{\natexlab{b}})Long, Zhu, Wang, and
  Jordan]{long2017deep}
M.~Long, H.~Zhu, J.~Wang, and M.~I. Jordan.
\newblock Deep transfer learning with joint adaptation networks.
\newblock In \emph{International conference on machine learning}, pages
  2208--2217. PMLR, 2017{\natexlab{b}}.

\bibitem[Loshchilov and Hutter(2016)]{loshchilov2016sgdr}
I.~Loshchilov and F.~Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock \emph{arXiv preprint arXiv:1608.03983}, 2016.

\bibitem[Luo et~al.(2020)Luo, Wang, Huang, and
  Baktashmotlagh]{luo2020progressive}
Y.~Luo, Z.~Wang, Z.~Huang, and M.~Baktashmotlagh.
\newblock Progressive graph learning for open-set domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  6468--6478. PMLR, 2020.

\bibitem[Mey and Loog(2016)]{mey2016soft}
A.~Mey and M.~Loog.
\newblock A soft-labeled self-training approach.
\newblock In \emph{2016 23rd International Conference on Pattern Recognition
  (ICPR)}, pages 2604--2609. IEEE, 2016.

\bibitem[Neal et~al.(2018)Neal, Olson, Fern, Wong, and Li]{neal2018open}
L.~Neal, M.~Olson, X.~Fern, W.-K. Wong, and F.~Li.
\newblock Open set learning with counterfactual images.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 613--628, 2018.

\bibitem[Oza and Patel(2019)]{oza2019c2ae}
P.~Oza and V.~M. Patel.
\newblock C2ae: Class conditioned auto-encoder for open-set recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 2307--2316, 2019.

\bibitem[Pan et~al.(2010)Pan, Tsang, Kwok, and Yang]{pan2010domain}
S.~J. Pan, I.~W. Tsang, J.~T. Kwok, and Q.~Yang.
\newblock Domain adaptation via transfer component analysis.
\newblock \emph{IEEE transactions on neural networks}, 22\penalty0
  (2):\penalty0 199--210, 2010.

\bibitem[Peng et~al.(2017)Peng, Usman, Kaushik, Hoffman, Wang, and
  Saenko]{peng2017visda}
X.~Peng, B.~Usman, N.~Kaushik, J.~Hoffman, D.~Wang, and K.~Saenko.
\newblock Visda: The visual domain adaptation challenge, 2017.

\bibitem[Prabhu et~al.(2021)Prabhu, Khare, Kartik, and
  Hoffman]{prabhu2021sentry}
V.~Prabhu, S.~Khare, D.~Kartik, and J.~Hoffman.
\newblock Sentry: Selective entropy optimization via committee consistency for
  unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8558--8567, 2021.

\bibitem[Saenko et~al.(2010)Saenko, Kulis, Fritz, and Darrell]{office31}
K.~Saenko, B.~Kulis, M.~Fritz, and T.~Darrell.
\newblock Adapting visual category models to new domains.
\newblock In \emph{Proceedings of the 11th European Conference on Computer
  Vision: Part IV}, ECCV'10, page 213–226, Berlin, Heidelberg, 2010.
  Springer-Verlag.
\newblock ISBN 364215560X.

\bibitem[Saito et~al.(2018)Saito, Yamamoto, Ushiku, and Harada]{saito2018open}
K.~Saito, S.~Yamamoto, Y.~Ushiku, and T.~Harada.
\newblock Open set domain adaptation by backpropagation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 153--168, 2018.

\bibitem[Saito et~al.(2020)Saito, Kim, Sclaroff, and Saenko]{DANCE2020NIPS}
K.~Saito, D.~Kim, S.~Sclaroff, and K.~Saenko.
\newblock Universal domain adaptation through self supervision.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Scheirer et~al.(2012)Scheirer, de~Rezende~Rocha, Sapkota, and
  Boult]{scheirer2012toward}
W.~J. Scheirer, A.~de~Rezende~Rocha, A.~Sapkota, and T.~E. Boult.
\newblock Toward open set recognition.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 35\penalty0 (7):\penalty0 1757--1772, 2012.

\bibitem[Shu et~al.(2020)Shu, Shi, Wang, Huang, and Tian]{shu2020p}
Y.~Shu, Y.~Shi, Y.~Wang, T.~Huang, and Y.~Tian.
\newblock p-odn: prototype-based open deep network for open set recognition.
\newblock \emph{Scientific reports}, 10\penalty0 (1):\penalty0 1--13, 2020.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Simonyan and Zisserman(2015)]{Simonyan15}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Sohn et~al.(2020)Sohn, Berthelot, Carlini, Zhang, Zhang, Raffel,
  Cubuk, Kurakin, and Li]{sohn2020fixmatch}
K.~Sohn, D.~Berthelot, N.~Carlini, Z.~Zhang, H.~Zhang, C.~A. Raffel, E.~D.
  Cubuk, A.~Kurakin, and C.-L. Li.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 596--608, 2020.

\bibitem[Sun et~al.(2020)Sun, Yang, Zhang, Ling, and Peng]{sun2020conditional}
X.~Sun, Z.~Yang, C.~Zhang, K.-V. Ling, and G.~Peng.
\newblock Conditional gaussian distribution learning for open set recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 13480--13489, 2020.

\bibitem[Tan and Le(2019)]{tan2019efficientnet}
M.~Tan and Q.~Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  6105--6114. PMLR, 2019.

\bibitem[Tzeng et~al.(2014)Tzeng, Hoffman, Zhang, Saenko, and
  Darrell]{tzeng2014deep}
E.~Tzeng, J.~Hoffman, N.~Zhang, K.~Saenko, and T.~Darrell.
\newblock Deep domain confusion: Maximizing for domain invariance.
\newblock \emph{arXiv preprint arXiv:1412.3474}, 2014.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{tzeng2017adversarial}
E.~Tzeng, J.~Hoffman, K.~Saenko, and T.~Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7167--7176, 2017.

\bibitem[Van~der Maaten and Hinton(2008)]{van2008visualizing}
L.~Van~der Maaten and G.~Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9\penalty0 (11), 2008.

\bibitem[Vaze et~al.(2021)Vaze, Han, Vedaldi, and Zisserman]{vaze2021open}
S.~Vaze, K.~Han, A.~Vedaldi, and A.~Zisserman.
\newblock Open-set recognition: A good closed-set classifier is all you need.
\newblock \emph{arXiv preprint arXiv:2110.06207}, 2021.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and
  Panchanathan]{officehome}
H.~Venkateswara, J.~Eusebio, S.~Chakraborty, and S.~Panchanathan.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, July 2017.

\bibitem[Wang et~al.(2021)Wang, Meng, and Breckon]{wang2021progressively}
Q.~Wang, F.~Meng, and T.~P. Breckon.
\newblock Progressively select and reject pseudo-labelled samples for open-set
  domain adaptation.
\newblock \emph{arXiv preprint arXiv:2110.12635}, 2021.

\bibitem[Xu et~al.(2015)Xu, Wang, Chen, and Li]{xu2015empirical}
B.~Xu, N.~Wang, T.~Chen, and M.~Li.
\newblock Empirical evaluation of rectified activations in convolutional
  network.
\newblock \emph{arXiv preprint arXiv:1505.00853}, 2015.

\bibitem[Xu et~al.(2019)Xu, Li, Yang, and Lin]{xu2019larger}
R.~Xu, G.~Li, J.~Yang, and L.~Lin.
\newblock Larger norm more transferable: An adaptive feature norm approach for
  unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1426--1435, 2019.

\bibitem[Yamano(2019)]{yamano2019some}
T.~Yamano.
\newblock Some bounds for skewed $\alpha$-jensen-shannon divergence.
\newblock \emph{Results in Applied Mathematics}, 3:\penalty0 100064, 2019.

\end{thebibliography}
