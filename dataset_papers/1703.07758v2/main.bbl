\begin{thebibliography}{10}

\bibitem{anthony2009neural}
M.~Anthony and P.~L. Bartlett.
\newblock {\em Neural network learning: Theoretical foundations}.
\newblock Cambridge University Press, 2009.

\bibitem{applegate1991sampling}
D.~Applegate and R.~Kannan.
\newblock Sampling and integration of near log-concave functions.
\newblock In {\em ACM Symposium on Theory of Computing}, pages 156--163, 1991.

\bibitem{awasthi2015efficient}
P.~Awasthi, M.-F. Balcan, N.~Haghtalab, and R.~Urner.
\newblock Efficient learning of linear separators under bounded noise.
\newblock In {\em Annual Conference on Learning Theory}, pages 167--190, 2015.

\bibitem{awasthi2016learning}
P.~Awasthi, M.-F. Balcan, N.~Haghtalab, and H.~Zhang.
\newblock Learning and 1-bit compressed sensing under asymmetric noise.
\newblock In {\em Annual Conference on Learning Theory}, pages 152--192, 2016.

\bibitem{awasthi2014power}
P.~Awasthi, M.-F. Balcan, and P.~M. Long.
\newblock The power of localization for efficiently learning linear separators
  with noise.
\newblock In {\em ACM Symposium on Theory of Computing}, pages 449--458, 2014.

\bibitem{awasthi2017power}
P.~Awasthi, M.-F. Balcan, and P.~M. Long.
\newblock The power of localization for efficiently learning linear separators
  with noise.
\newblock {\em Journal of the ACM}, 63(6):50, 2017.

\bibitem{balcan2009agnostic}
M.-F. Balcan, A.~Beygelzimer, and J.~Langford.
\newblock Agnostic active learning.
\newblock {\em Journal of Computer and System Sciences}, 75(1):78--89, 2009.

\bibitem{balcan2007margin}
M.-F. Balcan, A.~Broder, and T.~Zhang.
\newblock Margin based active learning.
\newblock In {\em Annual Conference on Learning Theory}, pages 35--50, 2007.

\bibitem{balcan2013active}
M.-F. Balcan and P.~M. Long.
\newblock Active and passive learning of linear separators under log-concave
  distributions.
\newblock In {\em Annual Conference on Learning Theory}, pages 288--316, 2013.

\bibitem{balcan2016noise}
M.-F. Balcan and H.~Zhang.
\newblock Noise-tolerant life-long matrix completion via adaptive sampling.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2955--2963, 2016.

\bibitem{baum1990polynomial}
E.~B. Baum.
\newblock A polynomial time algorithm that learns two hidden unit nets.
\newblock {\em Neural Computation}, 2(4):510--522, 1990.

\bibitem{bertsimas2004solving}
D.~Bertsimas and S.~Vempala.
\newblock Solving convex programs by random walks.
\newblock {\em Journal of the ACM}, 51(4):540--556, 2004.

\bibitem{beygelzimer2009importance}
A.~Beygelzimer, S.~Dasgupta, and J.~Langford.
\newblock Importance weighted active learning.
\newblock In {\em International Conference on Machine Learning}, pages 49--56,
  2009.

\bibitem{beygelzimer2016search}
A.~Beygelzimer, D.~J. Hsu, J.~Langford, and C.~Zhang.
\newblock Search improves label for active learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3342--3350, 2016.

\bibitem{beygelzimer2010agnostic}
A.~Beygelzimer, D.~J. Hsu, J.~Langford, and T.~Zhang.
\newblock Agnostic active learning without constraints.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  199--207, 2010.

\bibitem{blum1996polynomial}
A.~Blum, A.~Frieze, R.~Kannan, and S.~Vempala.
\newblock A polynomial-time algorithm for learning noisy linear threshold
  functions.
\newblock In {\em IEEE Symposium on Foundations of Computer Science}, pages
  330--338, 1996.

\bibitem{blumer1989learnability}
A.~Blumer, A.~Ehrenfeucht, D.~Haussler, and M.~K. Warmuth.
\newblock Learnability and the {V}apnik-{C}hervonenkis dimension.
\newblock {\em Journal of the ACM}, 36(4):929--965, 1989.

\bibitem{bobkov2007large}
S.~G. Bobkov.
\newblock Large deviations and isoperimetry over convex probability measures
  with heavy tails.
\newblock {\em Electronic Journal of Probability}, 12:1072--1100, 2007.

\bibitem{bousquet2005theory}
O.~Bousquet, S.~Boucheron, and G.~Lugosi.
\newblock Theory of classification: A survey of recent advances.
\newblock {\em ESAIM: Probability and Statistics}, 9(9):323--375, 2005.

\bibitem{brascamp2002extensions}
H.~J. Brascamp and E.~H. Lieb.
\newblock On extensions of the {B}runn-{M}inkowski and {P}r{\'e}kopa-{L}eindler
  theorems, including inequalities for log concave functions, and with an
  application to the diffusion equation.
\newblock {\em Journal of Functional Analysis}, 22(4):366--389, 1976.

\bibitem{caramanis2004inequality}
C.~Caramanis and S.~Mannor.
\newblock An inequality for nearly log-concave distributions with applications
  to learning.
\newblock In {\em Annual Conference on Learning Theory}, pages 534--548, 2004.

\bibitem{caramanis2007inequality}
C.~Caramanis and S.~Mannor.
\newblock An inequality for nearly log-concave distributions with applications
  to learning.
\newblock {\em IEEE Transactions on Information Theory}, 53(3):1043--1057,
  2007.

\bibitem{chandrasekaran2009sampling}
K.~Chandrasekaran, A.~Deshpande, and S.~Vempala.
\newblock Sampling s-concave functions: The limit of convexity based
  isoperimetry.
\newblock In {\em Approximation, Randomization, and Combinatorial Optimization.
  Algorithms and Techniques}, pages 420--433. 2009.

\bibitem{cohn1994improving}
D.~Cohn, L.~Atlas, and R.~Ladner.
\newblock Improving generalization with active learning.
\newblock {\em Machine Learning}, 15(2):201--221, 1994.

\bibitem{daniely2016complexity}
A.~Daniely.
\newblock Complexity theoretic limitations on learning halfspaces.
\newblock In {\em ACM Symposium on Theory of computing}, pages 105--117, 2016.

\bibitem{dasgupta2004analysis}
S.~Dasgupta.
\newblock Analysis of a greedy active learning strategy.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~17, pages 337--344, 2004.

\bibitem{dasgupta2007general}
S.~Dasgupta, D.~J. Hsu, and C.~Monteleoni.
\newblock A general agnostic active learning algorithm.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  353--360, 2007.

\bibitem{dasgupta2005analysis}
S.~Dasgupta, A.~T. Kalai, and C.~Monteleoni.
\newblock Analysis of perceptron-based active learning.
\newblock In {\em Annual Conference on Learning Theory}, pages 249--263, 2005.

\bibitem{dunagan2004simple}
J.~Dunagan and S.~Vempala.
\newblock A simple polynomial-time rescaling algorithm for solving linear
  programs.
\newblock In {\em ACM Symposium on Theory of computing}, pages 315--320, 2004.

\bibitem{freund1993information}
Y.~Freund, H.~S. Seung, E.~Shamir, and N.~Tishby.
\newblock Information, prediction, and query by committee.
\newblock {\em Advances in Neural Information Processing Systems}, pages
  483--483, 1993.

\bibitem{friedman2009active}
E.~Friedman.
\newblock Active learning for smooth problems.
\newblock In {\em Annual Conference on Learning Theory}, 2009.

\bibitem{guruswami2009hardness}
V.~Guruswami and P.~Raghavendra.
\newblock Hardness of learning halfspaces with noise.
\newblock {\em SIAM Journal on Computing}, 39(2):742--765, 2009.

\bibitem{han2016approximation}
Q.~Han and J.~A. Wellner.
\newblock Approximation and estimation of s-concave densities via {R}{\'e}nyi
  divergences.
\newblock {\em The Annals of Statistics}, 44(3):1332--1359, 2016.

\bibitem{hanneke2007bound}
S.~Hanneke.
\newblock A bound on the label complexity of agnostic active learning.
\newblock In {\em International Conference on Machine Learning}, pages
  353--360, 2007.

\bibitem{hanneke2014theory}
S.~Hanneke et~al.
\newblock Theory of disagreement-based active learning.
\newblock {\em Foundations and Trends in Machine Learning}, 7(2-3):131--309,
  2014.

\bibitem{kalai2008agnostically}
A.~T. Kalai, A.~R. Klivans, Y.~Mansour, and R.~A. Servedio.
\newblock Agnostically learning halfspaces.
\newblock {\em SIAM Journal on Computing}, 37(6):1777--1805, 2008.

\bibitem{kalai2006simulated}
A.~T. Kalai and S.~Vempala.
\newblock Simulated annealing for convex optimization.
\newblock {\em Mathematics of Operations Research}, 31(2):253--266, 2006.

\bibitem{kane2017active}
D.~M. Kane, S.~Lovett, S.~Moran, and J.~Zhang.
\newblock Active classification with comparison queries.
\newblock In {\em IEEE Symposium on Foundations of Computer Science}, pages
  355--366, 2017.

\bibitem{kearns1993learning}
M.~Kearns and M.~Li.
\newblock Learning in the presence of malicious errors.
\newblock {\em SIAM Journal on Computing}, 22(4):807--837, 1993.

\bibitem{kearns1994toward}
M.~J. Kearns, R.~E. Schapire, and L.~M. Sellie.
\newblock Toward efficient agnostic learning.
\newblock {\em Machine Learning}, 17(2-3):115--141, 1994.

\bibitem{kearns1994introduction}
M.~J. Kearns and U.~V. Vazirani.
\newblock {\em An introduction to computational learning theory}.
\newblock MIT press, 1994.

\bibitem{klivans2014embedding}
A.~Klivans and P.~Kothari.
\newblock Embedding hard learning problems into gaussian space.
\newblock {\em International Workshop on Approximation Algorithms for
  Combinatorial Optimization Problems}, 28:793--809, 2014.

\bibitem{klivans2009learning}
A.~R. Klivans, P.~M. Long, and R.~A. Servedio.
\newblock Learning halfspaces with malicious noise.
\newblock {\em Journal of Machine Learning Research}, 10:2715--2740, 2009.

\bibitem{klivans2009baum}
A.~R. Klivans, P.~M. Long, and A.~K. Tang.
\newblock Baum{'}s algorithm learns intersections of halfspaces with respect to
  log-concave distributions.
\newblock In {\em Approximation, Randomization, and Combinatorial Optimization.
  Algorithms and Techniques}, pages 588--600. 2009.

\bibitem{klivans2002learning}
A.~R. Klivans, R.~O'Donnell, and R.~A. Servedio.
\newblock Learning intersections and thresholds of halfspaces.
\newblock In {\em IEEE Symposium on Foundations of Computer Science}, pages
  177--186, 2002.

\bibitem{kulkarni1993active}
S.~R. Kulkarni, S.~K. Mitter, and J.~N. Tsitsiklis.
\newblock Active learning using arbitrary binary valued queries.
\newblock {\em Machine Learning}, 11(1):23--35, 1993.

\bibitem{littlestone1988learning}
N.~Littlestone.
\newblock Learning quickly when irrelevant attributes abound: A new
  linear-threshold algorithm.
\newblock {\em Machine Learning}, 2(4):285--318, 1988.

\bibitem{long1995sample}
P.~M. Long.
\newblock On the sample complexity of pac learning half-spaces against the
  uniform distribution.
\newblock {\em IEEE Transactions on Neural Networks}, 6(6):1556--1559, 1995.

\bibitem{lovasz2007geometry}
L.~Lov{\'a}sz and S.~Vempala.
\newblock The geometry of logconcave functions and sampling algorithms.
\newblock {\em Random Structures $\&$ Algorithms}, 30(3):307--358, 2007.

\bibitem{minsky1987perceptrons}
M.~Minsky and S.~Papert.
\newblock Perceptrons--extended edition: An introduction to computational
  geometry, 1987.

\bibitem{servedio2001efficient}
R.~A. Servedio.
\newblock {\em Efficient algorithms in computational learning theory}.
\newblock PhD thesis, Harvard University, 2001.

\bibitem{shalev2010learning}
S.~Shalev-Shwartz, O.~Shamir, and K.~Sridharan.
\newblock Learning kernel-based halfspaces with the zero-one loss.
\newblock {\em arXiv preprint arXiv:1005.3681}, 2010.

\bibitem{tsybakov2004optimal}
A.~B. Tsybakov.
\newblock Optimal aggregation of classifiers in statistical learning.
\newblock {\em The Annals of Statistics}, pages 135--166, 2004.

\bibitem{vapnik1982estimations}
V.~Vapnik.
\newblock {\em Estimations of dependences based on statistical data}.
\newblock Springer, 1982.

\bibitem{vapnik1998statistical}
V.~Vapnik.
\newblock {\em The nature of statistical learning theory}.
\newblock Springer Science \& Business Media, 2013.

\bibitem{wang2011smoothness}
L.~Wang.
\newblock Smoothness, disagreement coefficient, and the label complexity of
  agnostic active learning.
\newblock {\em Journal of Machine Learning Research}, 12(Jul):2269--2292, 2011.

\bibitem{xu2017noise}
Y.~Xu, H.~Zhang, A.~Singh, A.~Dubrawski, and K.~Miller.
\newblock Noise-tolerant interactive learning using pairwise comparisons.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2428--2437, 2017.

\bibitem{yan2017revisiting}
S.~Yan and C.~Zhang.
\newblock Revisiting perceptron: Efficient and label-optimal active learning of
  halfspaces.
\newblock {\em arXiv preprint arXiv:1702.05581}, 2017.

\bibitem{zhang2014beyond}
C.~Zhang and K.~Chaudhuri.
\newblock Beyond disagreement-based agnostic active learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  442--450, 2014.

\end{thebibliography}
