\begin{thebibliography}{10}

\bibitem{anselmi2013magic}
F.~Anselmi, J.~Z. Leibo, L.~Rosasco, J.~Mutch, A.~Tacchetti, and T.~Poggio.
\newblock Magic materials: a theory of deep hierarchical architectures for
  learning sensory representations.
\newblock {\em MIT CBCL Technical Report}, 2013.

\bibitem{arora2013provable}
S.~Arora, A.~Bhaskara, R.~Ge, and T.~Ma.
\newblock Provable bounds for learning some deep representations.
\newblock {\em arXiv preprint arXiv:1310.6343}, 2013.

\bibitem{bishop2006pattern}
C.~M. Bishop.
\newblock {\em Pattern Recognition and Machine Learning}, volume~4.
\newblock Springer New York, 2006.

\bibitem{bishop2007generative}
C.~M. Bishop, J.~Lasserre, et~al.
\newblock Generative or discriminative? getting the best of both worlds.
\newblock {\em Bayesian Statistics}, 8:3--24, 2007.

\bibitem{breiman2001random}
L.~Breiman.
\newblock Random forests.
\newblock {\em Machine learning}, 45(1):5--32, 2001.

\bibitem{bruna2013invariant}
J.~Bruna and S.~Mallat.
\newblock Invariant scattering convolution networks.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  35(8):1872--1886, 2013.

\bibitem{goodfellow2013maxout}
I.~J. Goodfellow, D.~Warde-Farley, M.~Mirza, A.~Courville, and Y.~Bengio.
\newblock Maxout networks.
\newblock {\em arXiv preprint arXiv:1302.4389}, 2013.

\bibitem{kingma2014semi}
D.~P. Kingma, S.~Mohamed, D.~J. Rezende, and M.~Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3581--3589, 2014.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{kschischang2001factor}
F.~R. Kschischang, B.~J. Frey, and H.-A. Loeliger.
\newblock Factor graphs and the sum-product algorithm.
\newblock {\em IEEE Transactions on Information Theory}, 47(2):498--519, 2001.

\bibitem{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lee2013pseudo}
D.-H. Lee.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In {\em Workshop on Challenges in Representation Learning, ICML},
  volume~3, 2013.

\bibitem{maaloe2016auxiliary}
L.~Maal{\o}e, C.~K. S{\o}nderby, S.~K. S{\o}nderby, and O.~Winther.
\newblock Auxiliary deep generative models.
\newblock {\em arXiv preprint arXiv:1602.05473}, 2016.

\bibitem{makhzani2015winner}
A.~Makhzani and B.~J. Frey.
\newblock Winner-take-all autoencoders.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2773--2781, 2015.

\bibitem{montufar2014number}
G.~F. Montufar, R.~Pascanu, K.~Cho, and Y.~Bengio.
\newblock On the number of linear regions of deep neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2924--2932, 2014.

\bibitem{jordan2002discriminative}
A.~Ng and M.~Jordan.
\newblock On discriminative vs. generative classifiers: A comparison of
  logistic regression and naive bayes.
\newblock {\em Advances in neural information processing systems}, 14:841,
  2002.

\bibitem{nguyen2016semi}
T.~Nguyen, A.~B. Patel, and R.~G. Baraniuk.
\newblock Semi-supervised learning with deep rendering mixture model.
\newblock {\em CVPR(Submitted)}, 2017.

\bibitem{patel2015-arxiv}
A.~B. Patel, T.~Nguyen, and R.~G. Baraniuk.
\newblock A probabilistic theory of deep learning.
\newblock {\em arXiv preprint arXiv:1504.00641}, 2015.

\bibitem{patel2016probabilistic}
A.~B. Patel, T.~Nguyen, and R.~G. Baraniuk.
\newblock A probabilistic framework for deep learning.
\newblock {\em NIPS}, 2016.

\bibitem{rasmus2015semi}
A.~Rasmus, M.~Berglund, M.~Honkala, H.~Valpola, and T.~Raiko.
\newblock Semi-supervised learning with ladder networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3532--3540, 2015.

\bibitem{rifai2011manifold}
S.~Rifai, Y.~N. Dauphin, P.~Vincent, Y.~Bengio, and X.~Muller.
\newblock The manifold tangent classifier.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2294--2302, 2011.

\bibitem{rifai2011contractive}
S.~Rifai, P.~Vincent, X.~Muller, X.~Glorot, and Y.~Bengio.
\newblock Contractive auto-encoders: Explicit invariance during feature
  extraction.
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 833--840, 2011.

\bibitem{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{salimans2016improved}
T.~Salimans, I.~Goodfellow, W.~Zaremba, V.~Cheung, A.~Radford, and X.~Chen.
\newblock Improved techniques for training gans.
\newblock {\em arXiv preprint arXiv:1606.03498}, 2016.

\bibitem{sheikh2014truncated}
A.-S. Sheikh, J.~A. Shelton, and J.~L{\"u}cke.
\newblock A truncated em approach for spike-and-slab sparse coding.
\newblock {\em Journal of Machine Learning Research}, 15(1):2653--2687, 2014.

\bibitem{simonyan2013deep}
K.~Simonyan, A.~Vedaldi, and A.~Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock {\em arXiv preprint arXiv:1312.6034}, 2013.

\bibitem{soatto2016visual}
S.~Soatto and A.~Chiuso.
\newblock Visual representations: Defining properties and deep approximations.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{springenberg2015unsupervised}
J.~T. Springenberg.
\newblock Unsupervised and semi-supervised learning with categorical generative
  adversarial networks.
\newblock {\em arXiv preprint arXiv:1511.06390}, 2015.

\bibitem{springenberg2014striving}
J.~T. Springenberg, A.~Dosovitskiy, T.~Brox, and M.~Riedmiller.
\newblock Striving for simplicity: The all convolutional net.
\newblock {\em arXiv preprint arXiv:1412.6806}, 2014.

\bibitem{tang2012deep}
Y.~Tang, R.~Salakhutdinov, and G.~Hinton.
\newblock Deep mixtures of factor analysers.
\newblock {\em arXiv preprint arXiv:1206.4635}, 2012.

\bibitem{tomg-admm}
G.~Taylor, R.~Burmeister, Z.~Xu, B.~Singh, A.~Patel, and T.~Goldstein.
\newblock Training neural networks without gradients: A scalable admm approach.
\newblock {\em arXiv preprint arXiv:1605.02026}, 2016.

\bibitem{van2014factoring}
A.~van~den Oord and B.~Schrauwen.
\newblock Factoring variations in natural images with deep gaussian mixture
  models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3518--3526, 2014.

\bibitem{vapnik1998statistical}
V.~N. Vapnik and V.~Vapnik.
\newblock {\em Statistical learning theory}, volume~1.
\newblock Wiley New York, 1998.

\bibitem{zhao2015swwae}
J.~Zhao, M.~Mathieu, R.~Goroshin, and Y.~LeCun.
\newblock Stacked what-where autoencoders.
\newblock {\em arXiv preprint arXiv:1506.02351}, 2016.

\end{thebibliography}
