\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andriushchenko and Flammarion(2020)]{grad_align}
Maksym Andriushchenko and Nicolas Flammarion.
\newblock Understanding and improving fast adversarial training.
\newblock In \emph{{Neural Information Processing Systems (NeurIPS)}}, 2020.

\bibitem[Biggio and Roli(2018)]{biggio2018wild}
Battista Biggio and Fabio Roli.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock \emph{{Pattern Recognition}}, 2018.

\bibitem[Bishop(1995)]{bishop1995training}
Chris~M Bishop.
\newblock Training with noise is equivalent to tikhonov regularization.
\newblock \emph{Neural computation}, 7\penalty0 (1):\penalty0 108--116, 1995.

\bibitem[Boloor et~al.(2019)Boloor, He, Gill, Vorobeychik, and
  Zhang]{DBLP:journals/corr/abs-1903-05157}
Adith Boloor, Xin He, Christopher~D. Gill, Yevgeniy Vorobeychik, and Xuan
  Zhang.
\newblock Simple physical adversarial examples against end-to-end autonomous
  driving models.
\newblock \emph{arxiv:1903.05157}, 2019.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{parseval}
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
  Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{{International Conference on Machine Learning (ICML)}},
  2017.

\bibitem[Croce and Hein(2020)]{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{{International Conference on Machine Learning (ICML)}},
  2020.

\bibitem[Devlin et~al.(2019)Devlin, Changm, Lee, and Toutanova]{bert}
Jacob Devlin, Ming{-}Wei Changm, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{{Annual Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies (NAACL
  HLT)}}, 2019.

\bibitem[Fawzi et~al.(2018)Fawzi, Moosavi-Dezfooli, Frossard, and
  Soatto]{fawzi2018empirical}
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and Stefano
  Soatto.
\newblock Empirical study of the topology and geometry of deep networks.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition
  ({CVPR})}, 2018.

\bibitem[Gilmer et~al.(2019)Gilmer, Ford, Carlini, and
  Cubuk]{gilmer2019adversarial}
Justin Gilmer, Nicolas Ford, Nicholas Carlini, and Ekin Cubuk.
\newblock Adversarial examples are a natural consequence of test error in
  noise.
\newblock In \emph{{International Conference on Machine Learning (ICML)}},
  2019.

\bibitem[Golgooni et~al.(2021)Golgooni, Saberi, Eskandar, and
  Rohban]{zero_grad}
Zeinab Golgooni, Mehrdad Saberi, Masih Eskandar, and Mohammad~Hossein Rohban.
\newblock Zerograd: Mitigating and explaining catastrophic overfitting in fgsm
  adversarial training.
\newblock \emph{arXiv:2103.15476}, 2021.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{fgsm}
Ian Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{{International Conference on Learning Representations (ICLR)}},
  2015.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015delving}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{{IEEE} International Conference on Computer Vision
  ({ICCV})}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{preact}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European Conference on Computer Vision ({ECCV})}, 2016.

\bibitem[Kang and Moosavi-Dezfooli(2021)]{kang2021understanding}
Peilin Kang and Seyed-Mohsen Moosavi-Dezfooli.
\newblock Understanding catastrophic overfitting in adversarial training.
\newblock \emph{arXiv:2105.02942}, 2021.

\bibitem[Kim et~al.(2021)Kim, Lee, and Lee]{AAAI}
Hoki Kim, Woojin Lee, and Jaewook Lee.
\newblock Understanding catastrophic overfitting in single-step adversarial
  training.
\newblock In \emph{{AAAI Conference on Artificial Intelligence (AAAI)}}, 2021.

\bibitem[Krizhevsky and Hinton(2009)]{cifar}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Master's thesis, Department of Computer Science, University of
  Toronto}, 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{{Neural Information Processing Systems (NeurIPS)}}, 2012.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and Bengio]{adv_ml_scale}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR)}}, 2017.

\bibitem[Li et~al.(2020)Li, Wang, Jana, and Carin]{towards}
Bai Li, Shiqi Wang, Suman Jana, and Lawrence Carin.
\newblock Towards understanding fast adversarial training.
\newblock \emph{arXiv:2006.03089}, 2020.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{PGD}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR)}}, 2018.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{svhn}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{{Neural Information Processing Systems (NeurIPS),
  Workshops}}, 2011.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot2016distillation}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{IEEE symposium on security and privacy (SP)}, 2016.

\bibitem[Park and Lee(2021)]{SLAT}
Geon~Yeong Park and Sang~Wan Lee.
\newblock Reliably fast adversarial training via latent adversarial
  perturbation.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR), Workshops}}, 2021.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{overfitting}
Leslie Rice, Eric Wong, and Zico Kolter.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{{International Conference on Machine Learning (ICML)}},
  2020.

\bibitem[Sanyal et~al.(2018)Sanyal, Kanade, and
  Torr]{DBLP:journals/corr/abs-1804-07090}
Amartya Sanyal, Varun Kanade, and Philip H.~S. Torr.
\newblock Robustness via deep low-rank representations.
\newblock \emph{arxiv:1804.07090}, 2018.

\bibitem[Shafahi et~al.(2019)Shafahi, Najibi, Ghiasi, Xu, Dickerson, Studer,
  Davis, Taylor, and Goldstein]{free}
Ali Shafahi, Mahyar Najibi, Mohammad~Amin Ghiasi, Zheng Xu, John Dickerson,
  Christoph Studer, Larry~S Davis, Gavin Taylor, and Tom Goldstein.
\newblock Adversarial training for free!
\newblock \emph{{Neural Information Processing Systems (NeurIPS)}}, 2019.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{go}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 2016.

\bibitem[Simonyan and Zisserman(2015)]{vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Sriramanan et~al.(2020)Sriramanan, Addepalli, Baburaj, et~al.]{GAT}
Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, et~al.
\newblock Guided adversarial attack for evaluating and enhancing adversarial
  defenses.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 20297--20308, 2020.

\bibitem[Sriramanan et~al.(2021)Sriramanan, Addepalli, Baburaj, et~al.]{NuAT}
Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, et~al.
\newblock Towards efficient and effective adversarial training.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11821--11833, 2021.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR)}}, 2014.

\bibitem[Tramèr et~al.(2018)Tramèr, Kurakin, Papernot, Goodfellow, Boneh, and
  McDaniel]{tramer2018ensemble}
Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh,
  and Patrick McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR)}}, 2018.

\bibitem[Vivek and Babu(2020)]{dropout_fgsm}
BS~Vivek and R~Venkatesh Babu.
\newblock Single-step adversarial training with dropout scheduling.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition
  ({CVPR})}, 2020.

\bibitem[Weng et~al.(2018)Weng, Zhang, Chen, Song, Hsieh, Daniel, Boning, and
  Dhillon]{weng2018towards}
Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel,
  Duane Boning, and Inderjit Dhillon.
\newblock Towards fast computation of certified robustness for relu networks.
\newblock In \emph{{International Conference on Machine Learning (ICML)}},
  2018.

\bibitem[Wong et~al.(2020)Wong, Rice, and Kolter]{RS-FGSM}
Eric Wong, Leslie Rice, and J.~Zico Kolter.
\newblock Fast is better than free: Revisiting adversarial training.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR)}}, 2020.

\bibitem[Zagoruyko and Komodakis(2016)]{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{{BMVC British Machine Vision Conference (BMVC)}}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and Jordan]{TRADES}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent~El Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{{International Conference on Machine Learning (ICML)}},
  2019.

\end{thebibliography}
