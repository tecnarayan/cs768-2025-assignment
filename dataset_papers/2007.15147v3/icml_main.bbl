\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmed \& Courville(2020)Ahmed and Courville]{ahmed2020semantic}
Ahmed, F. and Courville, A.~C.
\newblock Detecting semantic anomalies.
\newblock In \emph{The Thirty-Fourth {AAAI} Conference on Artificial
  Intelligence, New York, NY, USA, February 7-12, 2020}, pp.\  3154--3162.
  {AAAI} Press, 2020.

\bibitem[Akhtar \& Mian(2018)Akhtar and Mian]{akhtar2018survey}
Akhtar, N. and Mian, A.~S.
\newblock Threat of adversarial attacks on deep learning in computer vision:
  {A} survey.
\newblock \emph{{IEEE} Access}, 6:\penalty0 14410--14430, 2018.

\bibitem[Amsaleg et~al.(2015)Amsaleg, Chelly, Furon, Girard, Houle,
  Kawarabayashi, and Nett]{amsaleg2015estimating}
Amsaleg, L., Chelly, O., Furon, T., Girard, S., Houle, M.~E., Kawarabayashi,
  K.-i., and Nett, M.
\newblock Estimating local intrinsic dimensionality.
\newblock In \emph{Proceedings of the 21th {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining}, pp.\  29--38. ACM, 2015.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.~A.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML}}, volume~80 of \emph{Proceedings of Machine Learning
  Research}, pp.\  274--283. {PMLR}, 2018.

\bibitem[Barber(2012)]{barber2012}
Barber, D.
\newblock \emph{Bayesian reasoning and machine learning}.
\newblock Cambridge University Press, 2012.
\newblock ISBN 0521518148.

\bibitem[Barreno et~al.(2006)Barreno, Nelson, Sears, Joseph, and
  Tygar]{barreno2006can}
Barreno, M., Nelson, B., Sears, R., Joseph, A.~D., and Tygar, J.~D.
\newblock Can machine learning be secure?
\newblock In \emph{Proceedings of the 2006 {ACM} Symposium on Information,
  Computer and Communications Security ({ASIACCS})}, pp.\  16--25. {ACM}, 2006.
\newblock \doi{10.1145/1128817.1128824}.

\bibitem[Biggio \& Roli(2018)Biggio and Roli]{biggio2018wild}
Biggio, B. and Roli, F.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock \emph{Pattern Recognition}, 84:\penalty0 317--331, 2018.
\newblock \doi{10.1016/j.patcog.2018.07.023}.

\bibitem[Biggio et~al.(2012)Biggio, Nelson, and Laskov]{biggio2012poisoning}
Biggio, B., Nelson, B., and Laskov, P.
\newblock Poisoning attacks against support vector machines.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning, {ICML}}. icml.cc / Omnipress, 2012.

\bibitem[Bulatov(2011)]{bulatov2011notmnist}
Bulatov, Y.
\newblock Not{MNIST} dataset.
\newblock \url{http://yaroslavvb.com/upload/notMNIST/}, 2011.

\bibitem[Bulusu et~al.(2020)Bulusu, Kailkhura, Li, Varshney, and
  Song]{bulusu2020survey}
Bulusu, S., Kailkhura, B., Li, B., Varshney, P.~K., and Song, D.
\newblock Anomalous instance detection in deep learning: {A} survey.
\newblock \emph{CoRR}, abs/2003.06979, 2020.
\newblock URL \url{https://arxiv.org/abs/2003.06979}.

\bibitem[Carlini \& Wagner(2017{\natexlab{a}})Carlini and
  Wagner]{carlini2017bypassing}
Carlini, N. and Wagner, D.~A.
\newblock Adversarial examples are not easily detected: {B}ypassing ten
  detection methods.
\newblock In \emph{Proceedings of the 10th {ACM} Workshop on Artificial
  Intelligence and Security, {AIS}ec@{CCS}}, pp.\  3--14. {ACM},
  2017{\natexlab{a}}.
\newblock \doi{10.1145/3128572.3140444}.

\bibitem[Carlini \& Wagner(2017{\natexlab{b}})Carlini and
  Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.~A.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{{IEEE} Symposium on Security and Privacy ({S\&P})}, pp.\
  39--57. {IEEE} Computer Society, 2017{\natexlab{b}}.
\newblock \doi{10.1109/SP.2017.49}.

\bibitem[Chandola et~al.(2009)Chandola, Banerjee, and
  Kumar]{chandola2009anomaly}
Chandola, V., Banerjee, A., and Kumar, V.
\newblock Anomaly detection: A survey.
\newblock \emph{{ACM} computing surveys ({CSUR})}, 41\penalty0 (3):\penalty0
  1--58, 2009.

\bibitem[Davis \& Goadrich(2006)Davis and Goadrich]{davis2006relationship}
Davis, J. and Goadrich, M.
\newblock The relationship between {P}recision-{R}ecall and {ROC} curves.
\newblock In \emph{Proceedings of the 23rd international conference on Machine
  learning}, pp.\  233--240, 2006.

\bibitem[Dong et~al.(2011)Dong, Moses, and Li]{dong2011efficient}
Dong, W., Moses, C., and Li, K.
\newblock Efficient k-nearest neighbor graph construction for generic
  similarity measures.
\newblock In \emph{Proceedings of the 20th international conference on World
  wide web}, pp.\  577--586, 2011.

\bibitem[Dudoit \& Van Der~Laan(2007)Dudoit and Van
  Der~Laan]{dudoit2007multiple}
Dudoit, S. and Van Der~Laan, M.~J.
\newblock \emph{Multiple testing procedures with applications to genomics}.
\newblock Springer Science \& Business Media, 2007.

\bibitem[Fawcett(2006)]{fawcett2006introduction}
Fawcett, T.
\newblock An introduction to {ROC} analysis.
\newblock \emph{Pattern recognition letters}, 27\penalty0 (8):\penalty0
  861--874, 2006.

\bibitem[Fawzi et~al.(2016)Fawzi, Moosavi{-}Dezfooli, and
  Frossard]{fawzi2016robustness}
Fawzi, A., Moosavi{-}Dezfooli, S., and Frossard, P.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In \emph{Advances in Neural Information Processing Systems 29: Annual
  Conference on Neural Information Processing Systems}, pp.\  1624--1632, 2016.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Frossard]{fawzi2018analysis}
Fawzi, A., Fawzi, O., and Frossard, P.
\newblock Analysis of classifiers' robustness to adversarial perturbations.
\newblock \emph{Machine Learning}, 107\penalty0 (3):\penalty0 481--508, 2018.

\bibitem[Feinman et~al.(2017)Feinman, Curtin, Shintre, and
  Gardner]{feinman2017detecting}
Feinman, R., Curtin, R.~R., Shintre, S., and Gardner, A.~B.
\newblock Detecting adversarial samples from artifacts.
\newblock \emph{CoRR}, abs/1703.00410, 2017.
\newblock URL \url{http://arxiv.org/abs/1703.00410}.

\bibitem[Fisher(1992)]{fisher1992statistical}
Fisher, R.~A.
\newblock Statistical methods for research workers.
\newblock In \emph{Breakthroughs in statistics}, pp.\  66--70. Springer, 1992.

\bibitem[Flach \& Kull(2015)Flach and Kull]{flach2015precision}
Flach, P. and Kull, M.
\newblock Precision-recall-gain curves: {PR} analysis done right.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  838--846, 2015.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2015explain}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{3rd International Conference on Learning Representations,
  Conference Track Proceedings}, 2015.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015delving}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{{IEEE} International Conference on Computer Vision
  ({ICCV})}, pp.\  1026--1034. {IEEE} Computer Society, 2015.
\newblock \doi{10.1109/ICCV.2015.123}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2005)He, Cai, Yan, and Zhang]{he2005neighborhood}
He, X., Cai, D., Yan, S., and Zhang, H.-J.
\newblock Neighborhood preserving embedding.
\newblock In \emph{Tenth IEEE International Conference on Computer Vision
  (ICCV'05) Volume 1}, volume~2, pp.\  1208--1213. IEEE, 2005.

\bibitem[Hein et~al.(2019)Hein, Andriushchenko, and Bitterwolf]{hein2019relu}
Hein, M., Andriushchenko, M., and Bitterwolf, J.
\newblock Why relu networks yield high-confidence predictions far away from the
  training data and how to mitigate the problem.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition
  ({CVPR})}, pp.\  41--50. Computer Vision Foundation / {IEEE}, 2019.
\newblock \doi{10.1109/CVPR.2019.00013}.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and Gimpel]{hendrycks2017baseline}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{5th International Conference on Learning Representations,
  Conference Track Proceedings}. OpenReview.net, 2017.

\bibitem[Jha et~al.(2019)Jha, Raj, Fernandes, Jha, Jha, Jalaian, Verma, and
  Swami]{jha2019abc}
Jha, S., Raj, S., Fernandes, S.~L., Jha, S.~K., Jha, S., Jalaian, B., Verma,
  G., and Swami, A.
\newblock Attribution-based confidence metric for deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 32: Annual
  Conference on Neural Information Processing Systems}, pp.\  11826--11837,
  2019.

\bibitem[Jiang et~al.(2018)Jiang, Kim, Guan, and Gupta]{jiang2018trust}
Jiang, H., Kim, B., Guan, M.~Y., and Gupta, M.~R.
\newblock To trust or not to trust a classifier.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems}, pp.\  5546--5557, 2018.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2017)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2017imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock {ImageNet} classification with deep convolutional neural networks.
\newblock \emph{Communications of the {ACM}}, 60\penalty0 (6):\penalty0 84--90,
  2017.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and
  Bengio]{kurakin2017adversarial}
Kurakin, A., Goodfellow, I.~J., and Bengio, S.
\newblock Adversarial machine learning at scale.
\newblock In \emph{5th International Conference on Learning Representations,
  Conference Track Proceedings}. OpenReview.net, 2017.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the {IEEE}}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018simple}
Lee, K., Lee, K., Lee, H., and Shin, J.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems}, pp.\  7167--7177, 2018.

\bibitem[Li \& Li(2017)Li and Li]{li2017adversarial}
Li, X. and Li, F.
\newblock Adversarial examples detection in deep networks with convolutional
  filter statistics.
\newblock In \emph{{IEEE} International Conference on Computer Vision
  ({ICCV})}, pp.\  5775--5783. {IEEE} Computer Society, 2017.

\bibitem[Ma et~al.(2018)Ma, Li, Wang, Erfani, Wijewickrema, Schoenebeck, Song,
  Houle, and Bailey]{ma2018characterizing_iclr}
Ma, X., Li, B., Wang, Y., Erfani, S.~M., Wijewickrema, S. N.~R., Schoenebeck,
  G., Song, D., Houle, M.~E., and Bailey, J.
\newblock Characterizing adversarial subspaces using local intrinsic
  dimensionality.
\newblock In \emph{6th International Conference on Learning Representations,
  Conference Track Proceedings}. OpenReview.net, 2018.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{6th International Conference on Learning Representations,
  Conference Track Proceedings}. OpenReview.net, 2018.

\bibitem[Meng \& Chen(2017)Meng and Chen]{meng2017magnet}
Meng, D. and Chen, H.
\newblock Mag{N}et: {A} two-pronged defense against adversarial examples.
\newblock In \emph{Proceedings of the 2017 {ACM} {SIGSAC} Conference on
  Computer and Communications Security ({CCS})}, pp.\  135--147. {ACM}, 2017.

\bibitem[Miller et~al.(2019)Miller, Wang, and Kesidis]{miller2019ada}
Miller, D.~J., Wang, Y., and Kesidis, G.
\newblock When not to classify: {A}nomaly detection of attacks {(ADA)} on {DNN}
  classifiers at test time.
\newblock \emph{Neural Computation}, 31\penalty0 (8):\penalty0 1624--1670,
  2019.

\bibitem[Miller et~al.(2020)Miller, Xiang, and Kesidis]{miller2020adversarial}
Miller, D.~J., Xiang, Z., and Kesidis, G.
\newblock Adversarial learning targeting deep neural network classification:
  {A} comprehensive review of defenses against attacks.
\newblock \emph{Proceedings of the {IEEE}}, 108\penalty0 (3):\penalty0
  402--433, 2020.

\bibitem[Moosavi{-}Dezfooli et~al.(2016)Moosavi{-}Dezfooli, Fawzi, and
  Frossard]{Moosavi2016deepfool}
Moosavi{-}Dezfooli, S., Fawzi, A., and Frossard, P.
\newblock Deepfool: {A} simple and accurate method to fool deep neural
  networks.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition
  ({CVPR})}, pp.\  2574--2582. {IEEE} Computer Society, 2016.
\newblock \doi{10.1109/CVPR.2016.282}.

\bibitem[Moosavi{-}Dezfooli et~al.(2017)Moosavi{-}Dezfooli, Fawzi, Fawzi, and
  Frossard]{moosavi2017universal}
Moosavi{-}Dezfooli, S., Fawzi, A., Fawzi, O., and Frossard, P.
\newblock Universal adversarial perturbations.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition
  ({CVPR})}, pp.\  86--94. {IEEE} Computer Society, 2017.

\bibitem[Mu{\~{n}}oz{-}Gonz{\'{a}}lez et~al.(2017)Mu{\~{n}}oz{-}Gonz{\'{a}}lez,
  Biggio, Demontis, Paudice, Wongrassamee, Lupu, and Roli]{gonzalez2017towards}
Mu{\~{n}}oz{-}Gonz{\'{a}}lez, L., Biggio, B., Demontis, A., Paudice, A.,
  Wongrassamee, V., Lupu, E.~C., and Roli, F.
\newblock Towards poisoning of deep learning algorithms with back-gradient
  optimization.
\newblock In \emph{Proceedings of the 10th {ACM} Workshop on Artificial
  Intelligence and Security, AISec@CCS}, pp.\  27--38. {ACM}, 2017.
\newblock \doi{10.1145/3128572.3140451}.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Nguyen, A.~M., Yosinski, J., and Clune, J.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition
  ({CVPR})}, pp.\  427--436. {IEEE} Computer Society, 2015.

\bibitem[Papernot \& McDaniel(2018)Papernot and McDaniel]{papernot2018deep}
Papernot, N. and McDaniel, P.~D.
\newblock Deep k-nearest neighbors: Towards confident, interpretable and robust
  deep learning.
\newblock \emph{CoRR}, abs/1803.04765, 2018.
\newblock URL \url{http://arxiv.org/abs/1803.04765}.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Jha, Fredrikson, Celik, and
  Swami]{papernot2016limitations}
Papernot, N., McDaniel, P.~D., Jha, S., Fredrikson, M., Celik, Z.~B., and
  Swami, A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{{IEEE} European Symposium on Security and Privacy,
  EuroS{\&}P}, pp.\  372--387. {IEEE}, 2016.
\newblock \doi{10.1109/EuroSP.2016.36}.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock Automatic differentiation in {P}y{T}orch.
\newblock 2017.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{pedregosa2011scikit}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., et~al.
\newblock Scikit-learn: {M}achine learning in {P}ython.
\newblock \emph{Journal of machine learning research}, 12\penalty0
  (Oct):\penalty0 2825--2830, 2011.

\bibitem[Qian \& Saligrama(2012)Qian and Saligrama]{qian2012new}
Qian, J. and Saligrama, V.
\newblock New statistic in p-value estimation for anomaly detection.
\newblock In \emph{{IEEE} Statistical Signal Processing Workshop ({SSP})}, pp.\
   393--396. {IEEE}, 2012.
\newblock \doi{10.1109/SSP.2012.6319713}.

\bibitem[Rauber et~al.(2017)Rauber, Brendel, and Bethge]{rauber2017foolbox}
Rauber, J., Brendel, W., and Bethge, M.
\newblock Foolbox: {A} python toolbox to benchmark the robustness of machine
  learning models.
\newblock In \emph{Reliable Machine Learning in the Wild Workshop, 34th
  International Conference on Machine Learning}, 2017.

\bibitem[Read \& Cressie(2012)Read and Cressie]{read2012goodness}
Read, T.~R. and Cressie, N.~A.
\newblock \emph{Goodness-of-fit statistics for discrete multivariate data}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Root et~al.(2016)Root, Saligrama, and Qian]{root2016learning}
Root, J., Saligrama, V., and Qian, J.
\newblock Learning minimum volume sets and anomaly detectors from {KNN} graphs.
\newblock \emph{CoRR}, abs/1601.06105, 2016.
\newblock URL \url{http://arxiv.org/abs/1601.06105}.

\bibitem[Roth et~al.(2019)Roth, Kilcher, and Hofmann]{roth2019odds}
Roth, K., Kilcher, Y., and Hofmann, T.
\newblock The odds are odd: {A} statistical test for detecting adversarial
  examples.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning, {ICML}}, volume~97 of \emph{Proceedings of Machine Learning
  Research}, pp.\  5498--5507. {PMLR}, 2019.

\bibitem[Ruder(2016)]{ruder2016overview}
Ruder, S.
\newblock An overview of gradient descent optimization algorithms.
\newblock \emph{CoRR}, abs/1609.04747, 2016.
\newblock URL \url{http://arxiv.org/abs/1609.04747}.

\bibitem[Sastry \& Oore(2020)Sastry and Oore]{sastry2019gram}
Sastry, C.~S. and Oore, S.
\newblock Detecting out-of-distribution examples with gram matrices.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning ({ICML})}, volume 119 of \emph{Proceedings of Machine Learning
  Research}, pp.\  8491--8501. {PMLR}, 2020.

\bibitem[Sitawarin \& Wagner(2020)Sitawarin and Wagner]{sitawarin2020minimum}
Sitawarin, C. and Wagner, D.~A.
\newblock Minimum-norm adversarial examples on {KNN} and {KNN}-based models.
\newblock In \emph{{IEEE} Security and Privacy Workshops, {SP} Workshops}, pp.\
   34--40. {IEEE}, 2020.
\newblock \doi{10.1109/SPW50608.2020.00023}.

\bibitem[Steinhardt et~al.(2017)Steinhardt, Koh, and
  Liang]{steinhardt2017certified}
Steinhardt, J., Koh, P.~W., and Liang, P.
\newblock Certified defenses for data poisoning attacks.
\newblock In \emph{Advances in Neural Information Processing Systems 30: Annual
  Conference on Neural Information Processing Systems}, pp.\  3517--3529, 2017.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow,
  I.~J., and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{2nd International Conference on Learning Representations,
  Conference Track Proceedings}, 2014.

\bibitem[Tax \& Duin(2008)Tax and Duin]{tax2008growing}
Tax, D. M.~J. and Duin, R. P.~W.
\newblock Growing a multi-class classifier with a reject option.
\newblock \emph{Pattern Recognition Letters}, 29\penalty0 (10):\penalty0
  1565--1570, 2008.

\bibitem[Tram{\`{e}}r et~al.(2020)Tram{\`{e}}r, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Tram{\`{e}}r, F., Carlini, N., Brendel, W., and Madry, A.
\newblock On adaptive attacks to adversarial example defenses.
\newblock In \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems}, 2020.

\bibitem[Wilson(2019)]{wilson2019harmonic}
Wilson, D.~J.
\newblock The harmonic mean p-value for combining dependent tests.
\newblock \emph{Proceedings of the National Academy of Sciences}, 116\penalty0
  (4):\penalty0 1195--1200, 2019.

\bibitem[Xu et~al.(2018)Xu, Evans, and Qi]{xu2017feature1}
Xu, W., Evans, D., and Qi, Y.
\newblock Feature squeezing: {D}etecting adversarial examples in deep neural
  networks.
\newblock In \emph{25th Annual Network and Distributed System Security
  Symposium ({NDSS})}. The Internet Society, 2018.

\bibitem[Yang et~al.(2020)Yang, Chen, Hsieh, Wang, and Jordan]{yang2019ml}
Yang, P., Chen, J., Hsieh, C., Wang, J., and Jordan, M.~I.
\newblock {ML-LOO}: {D}etecting adversarial examples with feature attribution.
\newblock In \emph{The Thirty-Fourth {AAAI} Conference on Artificial
  Intelligence}, pp.\  6639--6647. {AAAI} Press, 2020.

\bibitem[Yuan et~al.(2019)Yuan, He, Zhu, and Li]{yuan2019adversarial}
Yuan, X., He, P., Zhu, Q., and Li, X.
\newblock Adversarial examples: Attacks and defenses for deep learning.
\newblock \emph{{IEEE} Transactions on Neural Networks and Learning Systems},
  30\penalty0 (9):\penalty0 2805--2824, 2019.
\newblock \doi{10.1109/TNNLS.2018.2886017}.

\bibitem[Zhao \& Saligrama(2009)Zhao and Saligrama]{zhao2009anomaly}
Zhao, M. and Saligrama, V.
\newblock Anomaly detection with score functions based on nearest neighbor
  graphs.
\newblock In \emph{Advances in Neural Information Processing Systems 22: 23rd
  Annual Conference on Neural Information Processing Systems}, pp.\
  2250--2258, 2009.

\bibitem[Zheng \& Hong(2018)Zheng and Hong]{zheng2018robust}
Zheng, Z. and Hong, P.
\newblock Robust detection of adversarial attacks by modeling the intrinsic
  properties of deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems}, pp.\  7924--7933, 2018.

\end{thebibliography}
