% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{airequirements-and-practices-survey}
Z.~Wan, X.~Xia, D.~Lo, and G.~C. Murphy, ``How does machine learning change
  software development practices?'' \emph{IEEE Transactions on Software
  Engineering}, vol.~47, no.~9, pp. 1857--1871, 2021.

\bibitem{fairnesssurvey}
N.~Mehrabi, F.~Morstatter, N.~Saxena, K.~Lerman, and A.~Galstyan, ``A survey on
  bias and fairness in machine learning,'' \emph{ACM Computing Surveys (CSUR)},
  vol.~54, no.~6, pp. 1--35, 2021.

\bibitem{robustness-survey}
S.~H. Silva and P.~Najafirad, ``Opportunities and challenges in deep learning
  adversarial robustness: A survey,'' \emph{arXiv preprint arXiv:2007.00753},
  2020.

\bibitem{safety-constrained-RL}
Q.~Yang, T.~D. Sim{\~a}o, S.~H. Tindemans, and M.~T. Spaan,
  ``Safety-constrained reinforcement learning with a distributional safety
  critic,'' \emph{Machine Learning}, vol. 112, no.~3, pp. 859--887, 2023.

\bibitem{fairness-const-dwork}
C.~Dwork, M.~Hardt, T.~Pitassi, O.~Reingold, and R.~Zemel, ``Fairness through
  awareness,'' in \emph{Proceedings of the 3rd innovations in theoretical
  computer science conference}, 2012, pp. 214--226.

\bibitem{fairness-const-2018-nips}
M.~Donini, L.~Oneto, S.~Ben-David, J.~S. Shawe-Taylor, and M.~Pontil,
  ``Empirical risk minimization under fairness constraints,'' \emph{Advances in
  neural information processing systems}, vol.~31, 2018.

\bibitem{chamon2020probably}
L.~Chamon and A.~Ribeiro, ``Probably approximately correct constrained
  learning,'' \emph{Advances in Neural Information Processing Systems},
  vol.~33, 2020.

\bibitem{tit}
L.~F. Chamon, S.~Paternain, M.~Calvo-Fullana, and A.~Ribeiro, ``Constrained
  learning with non-convex losses,'' \emph{IEEE Transactions on Information
  Theory}, 2022.

\bibitem{paternain2019constrainedRL}
S.~Paternain, L.~Chamon, M.~Calvo-Fullana, and A.~Ribeiro, ``Constrained
  reinforcement learning has zero duality gap,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~32, 2019.

\bibitem{fioretto-ddp-fairness}
C.~Tran, F.~Fioretto, and P.~Van~Hentenryck, ``Differentially private and fair
  deep learning: A lagrangian dual approach,'' in \emph{Proceedings of the AAAI
  Conference on Artificial Intelligence}, vol.~35, no.~11, 2021, pp.
  9932--9939.

\bibitem{fioretto2021lagrangian}
F.~Fioretto, P.~Van~Hentenryck, T.~W. Mak, C.~Tran, F.~Baldo, and M.~Lombardi,
  ``Lagrangian duality for constrained deep learning,'' in \emph{Machine
  Learning and Knowledge Discovery in Databases. Applied Data Science and Demo
  Track: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14--18,
  2020, Proceedings, Part V}.\hskip 1em plus 0.5em minus 0.4em\relax Springer,
  2021, pp. 118--135.

\bibitem{robey2021adversarial}
A.~Robey, L.~Chamon, G.~J. Pappas, H.~Hassani, and A.~Ribeiro, ``Adversarial
  robustness with semi-infinite constrained learning,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~34, pp. 6198--6215, 2021.

\bibitem{robey2021model-dg}
A.~Robey, G.~J. Pappas, and H.~Hassani, ``Model-based domain generalization,''
  \emph{Advances in Neural Information Processing Systems}, vol.~34, pp.
  20\,210--20\,229, 2021.

\bibitem{diana2021minimax}
E.~Diana, W.~Gill, M.~Kearns, K.~Kenthapadi, and A.~Roth, ``Minimax group
  fairness: Algorithms and experiments,'' in \emph{Proceedings of the 2021
  AAAI/ACM Conference on AI, Ethics, and Society}, 2021, pp. 66--76.

\bibitem{data-augment-constraints}
Y.~Xu, A.~Noy, M.~Lin, Q.~Qian, H.~Li, and R.~Jin, ``Wemix: How to better
  utilize data augmentation,'' \emph{arXiv preprint arXiv:2010.01267}, 2020.

\bibitem{vidal2023idealContinual}
L.~Peng, P.~V. Giampouras, and R.~Vidal, ``The ideal continual learner: An
  agent that never forgets,'' \emph{arXiv preprint arXiv:2305.00316}, 2023.

\bibitem{love-constraints}
\BIBentryALTinterwordspacing
J.~Gallego-Posada, J.~Ramirez, A.~Erraqabi, Y.~Bengio, and S.~Lacoste-Julien,
  ``Controlled sparsity via constrained optimization or: How i learned to stop
  tuning penalties and love constraints,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2208.04425}
\BIBentrySTDinterwordspacing

\bibitem{pocho-constrained-fl}
Z.~Shen, J.~Cervino, H.~Hassani, and A.~Ribeiro, ``An agnostic approach to
  federated learning with class imbalance,'' in \emph{International Conference
  on Learning Representations}, 2022.

\bibitem{heterogenous-fl}
T.~Nishio and R.~Yonetani, ``Client selection for federated learning with
  heterogeneous resources in mobile edge,'' in \emph{ICC 2019-2019 IEEE
  international conference on communications (ICC)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2019, pp. 1--7.

\bibitem{heterogeneous-2}
F.~Yu, W.~Zhang, Z.~Qin, Z.~Xu, D.~Wang, C.~Liu, Z.~Tian, and X.~Chen,
  ``Heterogeneous federated learning,'' \emph{arXiv preprint arXiv:2008.06767},
  2020.

\bibitem{CHicheAUgment}
I.~Hounie, L.~F.~O. Chamon, and A.~Ribeiro, ``Automatic data augmentation via
  invariance-constrained learning,'' \emph{ArXiv}, vol. abs/2209.15031, 2022.

\bibitem{augerino-finzi}
G.~Benton, M.~Finzi, P.~Izmailov, and A.~G. Wilson, ``Learning invariances in
  neural networks from training data,'' \emph{Advances in Neural Information
  Processing Systems}, vol.~33, pp. 17\,605--17\,616, 2020.

\bibitem{invariance_laplace}
\BIBentryALTinterwordspacing
A.~Immer, T.~F.~A. van~der Ouderaa, V.~Fortuin, G.~R{\"{a}}tsch, and M.~van~der
  Wilk, ``Invariance learning in deep neural networks with differentiable
  laplace approximations,'' \emph{CoRR}, vol. abs/2202.10638, 2022. [Online].
  Available: \url{https://arxiv.org/abs/2202.10638}
\BIBentrySTDinterwordspacing

\bibitem{ally-elenter}
J.~Elenter, N.~NaderiAlizadeh, and A.~Ribeiro, ``A lagrangian duality approach
  to active learning,'' \emph{arXiv preprint arXiv:2202.04108}, 2022.

\bibitem{reg-fair-1}
N.~Quadrianto, V.~Sharmanska, and O.~Thomas, ``Discovering fair representations
  in the data domain,'' in \emph{Proceedings of the IEEE/CVF conference on
  computer vision and pattern recognition}, 2019, pp. 8227--8236.

\bibitem{reg-fair-2}
S.~Baharlouei, M.~Nouiehed, A.~Beirami, and M.~Razaviyayn, ``R$\backslash$'enyi
  fair inference,'' \emph{arXiv preprint arXiv:1906.12005}, 2019.

\bibitem{reg-fair-3}
S.~Jung, D.~Lee, T.~Park, and T.~Moon, ``Fair feature distillation for visual
  recognition,'' in \emph{Proceedings of the IEEE/CVF conference on computer
  vision and pattern recognition}, 2021, pp. 12\,115--12\,124.

\bibitem{fairnes-reg-4}
S.~Jung, T.~Park, S.~Chun, and T.~Moon, ``Re-weighting based group fairness
  regularization via classwise robust optimization,'' \emph{arXiv preprint
  arXiv:2303.00442}, 2023.

\bibitem{sinha2017certifying}
A.~Sinha, H.~Namkoong, R.~Volpi, and J.~Duchi, ``Certifying some distributional
  robustness with principled adversarial training,'' \emph{arXiv preprint
  arXiv:1710.10571}, 2017.

\bibitem{zhang2019theoretically}
H.~Zhang, Y.~Yu, J.~Jiao, E.~Xing, L.~El~Ghaoui, and M.~Jordan, ``Theoretically
  principled trade-off between robustness and accuracy,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2019, pp. 7472--7482.

\bibitem{fairnes-const-1}
A.~Agarwal, A.~Beygelzimer, M.~Dud{\'\i}k, J.~Langford, and H.~Wallach, ``A
  reductions approach to fair classification,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2018, pp. 60--69.

\bibitem{fairnes-const-2}
M.~Donini, L.~Oneto, S.~Ben-David, J.~Shawe-Taylor, and M.~Pontil, ``Empirical
  risk minimization under fairness constraints,'' \emph{arXiv preprint
  arXiv:1802.08626}, 2018.

\bibitem{fairnes-const-3}
M.~Kearns, S.~Neel, A.~Roth, and Z.~S. Wu, ``Preventing fairness
  gerrymandering: Auditing and learning for subgroup fairness,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2018, pp. 2564--2572.

\bibitem{fairnes-const-4}
A.~Cotter, H.~Jiang, M.~R. Gupta, S.~Wang, T.~Narayan, S.~You, and
  K.~Sridharan, ``Optimization with non-differentiable constraints with
  applications to fairness, recall, churn, and other goals.'' \emph{Journal of
  Machine Learning Research}, vol.~20, no. 172, pp. 1--59, 2019.

\bibitem{robey-rob-2}
\BIBentryALTinterwordspacing
A.~Robey, L.~Chamon, G.~J. Pappas, and H.~Hassani, ``Probabilistically robust
  learning: Balancing average and worst-case performance,'' in
  \emph{Proceedings of the 39th International Conference on Machine Learning},
  ser. Proceedings of Machine Learning Research, K.~Chaudhuri, S.~Jegelka,
  L.~Song, C.~Szepesvari, G.~Niu, and S.~Sabato, Eds., vol. 162.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 17--23 Jul 2022, pp. 18\,667--18\,686.
  [Online]. Available: \url{https://proceedings.mlr.press/v162/robey22a.html}
\BIBentrySTDinterwordspacing

\bibitem{ecological-resilience}
C.~S. Holling, ``Resilience and stability of ecological systems,'' \emph{Annual
  Review of Ecology, Evolution, and Systematics}, vol.~4, pp. 1--23, 1973.

\bibitem{ecological-resilience-2}
------, ``Engineering resilience versus ecological resilience,''
  \emph{Engineering within ecological constraints}, vol.~31, no. 1996, p.~32,
  1996.

\bibitem{non-convex}
L.~F.~O. Chamon, S.~Paternain, M.~Calvo-Fullana, and A.~Ribeiro, ``Constrained
  learning with non-convex losses,'' \emph{IEEE Transactions on Information
  Theory}, vol.~69, no.~3, pp. 1739--1760, 2023.

\bibitem{boyd2004convex}
S.~Boyd, S.~P. Boyd, and L.~Vandenberghe, \emph{Convex optimization}.\hskip 1em
  plus 0.5em minus 0.4em\relax Cambridge university press, 2004.

\bibitem{bonnans-perturbations}
J.~F. Bonnans and A.~Shapiro, ``Optimization problems with perturbations: A
  guided tour,'' \emph{SIAM review}, vol.~40, no.~2, pp. 228--264, 1998.

\bibitem{mohri2018foundations-of-ml}
M.~Mohri, A.~Rostamizadeh, and A.~Talwalkar, \emph{Foundations of machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 2018.

\bibitem{Ge18l}
R.~Ge, J.~D. Lee, and T.~Ma, ``Learning one-hidden-layer neural networks with
  landscape design,'' in \emph{International Conference on Learning
  Representations}, 2018.

\bibitem{Brutzkus17g}
A.~Brutzkus and A.~Globerson, ``Globally optimal gradient descent for a convnet
  with gaussian inputs,'' in \emph{International Conference on Machine
  Learning}, 2017, pp. 605--614.

\bibitem{Soltanolkotabi18t}
M.~Soltanolkotabi, A.~Javanmard, and J.~D. Lee, ``Theoretical insights into the
  optimization landscape of over-parameterized shallow neural networks,''
  \emph{IEEE Transactions on Information Theory}, vol.~65, no.~2, pp. 742--769,
  2018.

\bibitem{federated-og}
R.~Shokri and V.~Shmatikov, ``Privacy-preserving deep learning,'' in
  \emph{Proceedings of the 22nd ACM SIGSAC conference on computer and
  communications security}, 2015, pp. 1310--1321.

\bibitem{fl-prox-li2020}
T.~Li, A.~K. Sahu, M.~Zaheer, M.~Sanjabi, A.~Talwalkar, and V.~Smith,
  ``Federated optimization in heterogeneous networks,'' \emph{Proceedings of
  Machine learning and systems}, vol.~2, pp. 429--450, 2020.

\bibitem{fl-non-iid-wang2020}
H.~Wang, Z.~Kaplan, D.~Niu, and B.~Li, ``Optimizing federated learning on
  non-iid data with reinforcement learning,'' in \emph{IEEE INFOCOM 2020-IEEE
  Conference on Computer Communications}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2020, pp. 1698--1707.

\bibitem{mnist}
Y.~LeCun, C.~Cortes, and C.~Burges, ``Mnist handwritten digit database,''
  \emph{ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  vol.~2, 2010.

\bibitem{fmnist}
H.~Xiao, K.~Rasul, and R.~Vollgraf, ``Fashion-mnist: a novel image dataset for
  benchmarking machine learning algorithms,'' 2017.

\bibitem{rocka_fella_duality_and_opt}
R.~T. Rockafellar, \emph{Conjugate duality and optimization}.\hskip 1em plus
  0.5em minus 0.4em\relax SIAM, 1974.

\bibitem{bertsekas_nonlinear}
D.~P. Bertsekas, ``Nonlinear programming,'' \emph{Journal of the Operational
  Research Society}, vol.~48, no.~3, pp. 334--334, 1997.

\bibitem{Bertsekas_ConvexOT}
D.~Bertsekas, \emph{Convex optimization theory}.\hskip 1em plus 0.5em minus
  0.4em\relax Athena Scientific, 2009, vol.~1.

\bibitem{rockafellarconvexanalysis}
R.~T. Rockafellar, \emph{Convex analysis}.\hskip 1em plus 0.5em minus
  0.4em\relax Princeton university press, 1997, vol.~11.

\bibitem{adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,''
  \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{subgrad-notes-boyd}
S.~Boyd, L.~Xiao, and A.~Mutapcic, ``Subgradient methods,'' \emph{lecture notes
  of EE392o, Stanford University, Autumn Quarter}, vol. 2004, pp. 2004--2005,
  2003.

\bibitem{FedAvg}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas,
  ``Communication-efficient learning of deep networks from decentralized
  data,'' in \emph{Artificial intelligence and statistics}.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 2017, pp. 1273--1282.

\bibitem{FedPD}
X.~Zhang, M.~Hong, S.~V. Dhople, W.~Yin, and Y.~Liu, ``Fedpd: A federated
  learning framework with adaptivity to non-iid data,'' \emph{IEEE Transactions
  on Signal Processing}, vol.~69, pp. 6055--6070, 2020.

\bibitem{FL-Dyn}
D.~A.~E. Acar, Y.~Zhao, R.~M. Navarro, M.~Mattina, P.~N. Whatmough, and
  V.~Saligrama, ``Federated learning based on dynamic regularization,''
  \emph{arXiv preprint arXiv:2111.04263}, 2021.

\bibitem{CIFAR10}
A.~Krizhevsky, ``Learning multiple layers of features from tiny images,''
  Canadian Institute for Advanced Research, Tech. Rep., 2009.

\bibitem{ratioloss}
L.~Wang, S.~Xu, X.~Wang, and Q.~Zhu, ``Addressing class imbalance in federated
  learning,'' in \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, vol.~35, no.~11, 2021, pp. 10\,165--10\,173.

\end{thebibliography}
