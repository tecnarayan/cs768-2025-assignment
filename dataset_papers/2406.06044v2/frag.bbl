\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bar-Tal et~al.(2022)Bar-Tal, Ofri-Amar, Fridman, Kasten, and Dekel]{bar2022text2live}
Bar-Tal, O., Ofri-Amar, D., Fridman, R., Kasten, Y., and Dekel, T.
\newblock Text2live: Text-driven layered image and video editing.
\newblock In \emph{European conference on computer vision}, pp.\  707--723. Springer, 2022.

\bibitem[Chai et~al.(2023)Chai, Guo, Wang, and Lu]{chai2023stablevideo}
Chai, W., Guo, X., Wang, G., and Lu, Y.
\newblock Stablevideo: Text-driven consistency-aware diffusion video editing.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  23040--23050, 2023.

\bibitem[Cong et~al.(2023)Cong, Xu, Simon, Chen, Ren, Xie, Perez-Rua, Rosenhahn, Xiang, and He]{cong2023flatten}
Cong, Y., Xu, M., Simon, C., Chen, S., Ren, J., Xie, Y., Perez-Rua, J.-M., Rosenhahn, B., Xiang, T., and He, S.
\newblock Flatten: optical flow-guided attention for consistent text-to-video editing.
\newblock \emph{arXiv preprint arXiv:2310.05922}, 2023.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal2021diffusion}
Dhariwal, P. and Nichol, A.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Geyer et~al.(2023)Geyer, Bar-Tal, Bagon, and Dekel]{geyer2023tokenflow}
Geyer, M., Bar-Tal, O., Bagon, S., and Dekel, T.
\newblock Tokenflow: Consistent diffusion features for consistent video editing.
\newblock \emph{arXiv preprint arXiv:2307.10373}, 2023.

\bibitem[He et~al.(2024)He, Li, Zhang, Yan, Si, and Li]{he2024freestyle}
He, F., Li, G., Zhang, M., Yan, L., Si, L., and Li, F.
\newblock Freestyle: Free lunch for text-guided style transfer using diffusion models.
\newblock \emph{arXiv preprint arXiv:2401.15636}, 2024.

\bibitem[Hertz et~al.(2022)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and Cohen-Or]{hertz2022prompt}
Hertz, A., Mokady, R., Tenenbaum, J., Aberman, K., Pritch, Y., and Cohen-Or, D.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock \emph{arXiv preprint arXiv:2208.01626}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and Fleet]{ho2022video}
Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D.~J.
\newblock Video diffusion models.
\newblock \emph{arXiv preprint arXiv:2204.03458}, 2022.

\bibitem[Hong et~al.(2022)Hong, Ding, Zheng, Liu, and Tang]{hong2022cogvideo}
Hong, W., Ding, M., Zheng, W., Liu, X., and Tang, J.
\newblock Cogvideo: Large-scale pretraining for text-to-video generation via transformers.
\newblock \emph{arXiv preprint arXiv:2205.15868}, 2022.

\bibitem[Huang et~al.(2024)Huang, Fang, Zhang, Song, Liu, Liu, and Li]{huang2024fouriscale}
Huang, L., Fang, R., Zhang, A., Song, G., Liu, S., Liu, Y., and Li, H.
\newblock Fouriscale: A frequency perspective on training-free high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2403.12963}, 2024.

\bibitem[Jain \& Dubes(1988)Jain and Dubes]{jain1988algorithms}
Jain, A.~K. and Dubes, R.~C.
\newblock \emph{Algorithms for clustering data}.
\newblock Prentice-Hall, Inc., 1988.

\bibitem[Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and Irani]{kawar2023imagic}
Kawar, B., Zada, S., Lang, O., Tov, O., Chang, H., Dekel, T., Mosseri, I., and Irani, M.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  6007--6017, 2023.

\bibitem[Khachatryan et~al.(2023)Khachatryan, Movsisyan, Tadevosyan, Henschel, Wang, Navasardyan, and Shi]{khachatryan2023text2video}
Khachatryan, L., Movsisyan, A., Tadevosyan, V., Henschel, R., Wang, Z., Navasardyan, S., and Shi, H.
\newblock Text2video-zero: Text-to-image diffusion models are zero-shot video generators.
\newblock \emph{arXiv preprint arXiv:2303.13439}, 2023.

\bibitem[Kim et~al.(2022)Kim, Kwon, and Ye]{kim2022diffusionclip}
Kim, G., Kwon, T., and Ye, J.~C.
\newblock Diffusionclip: Text-guided diffusion models for robust image manipulation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  2426--2435, 2022.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson, Xiao, Whitehead, Berg, Lo, et~al.]{kirillov2023segment}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.~C., Lo, W.-Y., et~al.
\newblock Segment anything.
\newblock \emph{arXiv preprint arXiv:2304.02643}, 2023.

\bibitem[Koo et~al.(2024)Koo, Yoon, and Yoo]{koo2024wavelet}
Koo, G., Yoon, S., and Yoo, C.~D.
\newblock Wavelet-guided acceleration of text inversion in diffusion-based image editing.
\newblock \emph{arXiv preprint arXiv:2401.09794}, 2024.

\bibitem[Langley(2000)]{langley00}
Langley, P.
\newblock Crafting papers on machine learning.
\newblock In Langley, P. (ed.), \emph{Proceedings of the 17th International Conference on Machine Learning (ICML 2000)}, pp.\  1207--1216, Stanford, CA, 2000. Morgan Kaufmann.

\bibitem[Liang et~al.(2022)Liang, Wang, Zhou, and Yang]{liang2022visual}
Liang, C., Wang, W., Zhou, T., and Yang, Y.
\newblock Visual abductive reasoning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  15565--15575, 2022.

\bibitem[Liu et~al.(2023)Liu, Zhang, Li, Lin, and Jia]{liu2023video}
Liu, S., Zhang, Y., Li, W., Lin, Z., and Jia, J.
\newblock Video-p2p: Video editing with cross-attention control.
\newblock \emph{arXiv preprint arXiv:2303.04761}, 2023.

\bibitem[Luo et~al.(2024)Luo, Huang, Gong, Jin, and Liu]{luo2024zero}
Luo, D., Huang, J., Gong, S., Jin, H., and Liu, Y.
\newblock Zero-shot video moment retrieval from frozen vision-language models.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pp.\  5464--5473, 2024.

\bibitem[Ma et~al.(2020)Ma, Yoon, Kim, Lee, Kang, and Yoo]{ma2020vlanet}
Ma, M., Yoon, S., Kim, J., Lee, Y., Kang, S., and Yoo, C.~D.
\newblock Vlanet: Video-language alignment network for weakly-supervised video moment retrieval.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXVIII 16}, pp.\  156--171. Springer, 2020.

\bibitem[Molad et~al.(2023)Molad, Horwitz, Valevski, Acha, Matias, Pritch, Leviathan, and Hoshen]{molad2023dreamix}
Molad, E., Horwitz, E., Valevski, D., Acha, A.~R., Matias, Y., Pritch, Y., Leviathan, Y., and Hoshen, Y.
\newblock Dreamix: Video diffusion models are general video editors.
\newblock \emph{arXiv preprint arXiv:2302.01329}, 2023.

\bibitem[Qi et~al.(2023)Qi, Cun, Zhang, Lei, Wang, Shan, and Chen]{qi2023fatezero}
Qi, C., Cun, X., Zhang, Y., Lei, C., Wang, X., Shan, Y., and Chen, Q.
\newblock Fatezero: Fusing attentions for zero-shot text-based video editing.
\newblock \emph{arXiv preprint arXiv:2303.09535}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{ronneberger2015u}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}, pp.\  234--241. Springer, 2015.

\bibitem[Si et~al.(2023)Si, Huang, Jiang, and Liu]{si2023freeu}
Si, C., Huang, Z., Jiang, Y., and Liu, Z.
\newblock Freeu: Free lunch in diffusion u-net.
\newblock \emph{arXiv preprint arXiv:2309.11497}, 2023.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Meng, and Ermon]{song2020denoising}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020{\natexlab{a}}.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole, B.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020{\natexlab{b}}.

\bibitem[Soomro et~al.(2012)Soomro, Zamir, and Shah]{soomro2012ucf101}
Soomro, K., Zamir, A.~R., and Shah, M.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the wild.
\newblock \emph{arXiv preprint arXiv:1212.0402}, 2012.

\bibitem[Teed \& Deng(2020)Teed and Deng]{teed2020raft}
Teed, Z. and Deng, J.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pp.\  402--419. Springer, 2020.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, et~al.]{van2017neural}
Van Den~Oord, A., Vinyals, O., et~al.
\newblock Neural discrete representation learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wu et~al.(2023{\natexlab{a}})Wu, Ge, Wang, Lei, Gu, Shi, Hsu, Shan, Qie, and Shou]{wu2023tune}
Wu, J.~Z., Ge, Y., Wang, X., Lei, S.~W., Gu, Y., Shi, Y., Hsu, W., Shan, Y., Qie, X., and Shou, M.~Z.
\newblock Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  7623--7633, 2023{\natexlab{a}}.

\bibitem[Wu et~al.(2023{\natexlab{b}})Wu, Li, Gao, Dong, Bai, Singh, Xiang, Li, Huang, Sun, et~al.]{wu2023cvpr}
Wu, J.~Z., Li, X., Gao, D., Dong, Z., Bai, J., Singh, A., Xiang, X., Li, Y., Huang, Z., Sun, Y., et~al.
\newblock Cvpr 2023 text guided video editing competition.
\newblock \emph{arXiv preprint arXiv:2310.16003}, 2023{\natexlab{b}}.

\bibitem[Yoon et~al.(2023{\natexlab{a}})Yoon, Yoon, Harvill, Hasegawa-Johnson, and Yoo]{yoon2023information}
Yoon, E., Yoon, H.~S., Harvill, J., Hasegawa-Johnson, M., and Yoo, C.-D.
\newblock Information-theoretic adversarial prompt tuning for enhanced non-native speech recognition.
\newblock In \emph{The 61st Annual Meeting of the Association for Computational Linguistics}. The 61st Annual Meeting of the Association for Computational Linguistics, 2023{\natexlab{a}}.

\bibitem[Yoon et~al.(2023{\natexlab{b}})Yoon, Tee, Yoon, Yoon, Kim, Li, and Yoo]{yoon2023esd}
Yoon, H.~S., Tee, J. T.~J., Yoon, E., Yoon, S., Kim, G., Li, Y., and Yoo, C.~D.
\newblock Esd: Expected squared difference as a tuning-free trainable calibration measure.
\newblock \emph{arXiv preprint arXiv:2303.02472}, 2023{\natexlab{b}}.

\bibitem[Yoon et~al.(2022{\natexlab{a}})Yoon, Hong, Yoon, Kim, Kim, Yoon, and Yoo]{yoon2022selective}
Yoon, S., Hong, J.~W., Yoon, E., Kim, D., Kim, J., Yoon, H.~S., and Yoo, C.~D.
\newblock Selective query-guided debiasing for video corpus moment retrieval.
\newblock In \emph{European Conference on Computer Vision}, pp.\  185--200. Springer, 2022{\natexlab{a}}.

\bibitem[Yoon et~al.(2022{\natexlab{b}})Yoon, Yoon, Yoon, Kim, and Yoo]{yoon2022information}
Yoon, S., Yoon, E., Yoon, H.~S., Kim, J., and Yoo, C.~D.
\newblock Information-theoretic text hallucination reduction for video-grounded dialogue.
\newblock \emph{arXiv preprint arXiv:2212.05765}, 2022{\natexlab{b}}.

\bibitem[Yoon et~al.(2023{\natexlab{c}})Yoon, Hong, Eom, Yoon, Yoon, Kim, Kim, Kim, and Yoo]{yoon2023counterfactual}
Yoon, S., Hong, J.~W., Eom, S., Yoon, H.~S., Yoon, E., Kim, D., Kim, J., Kim, C., and Yoo, C.~D.
\newblock Counterfactual two-stage debiasing for video corpus moment retrieval.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  1--5. IEEE, 2023{\natexlab{c}}.

\bibitem[Yoon et~al.(2023{\natexlab{d}})Yoon, Kim, Yoon, Yoon, Kim, and Yoo]{yoon-etal-2023-hear}
Yoon, S., Kim, D., Yoon, E., Yoon, H., Kim, J., and Yoo, C.
\newblock {HEAR}: Hearing enhanced audio response for video-grounded dialogue.
\newblock In Bouamor, H., Pino, J., and Bali, K. (eds.), \emph{Findings of the Association for Computational Linguistics: EMNLP 2023}, pp.\  11911--11924, Singapore, December 2023{\natexlab{d}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.findings-emnlp.797}.
\newblock URL \url{https://aclanthology.org/2023.findings-emnlp.797}.

\bibitem[Yoon et~al.(2023{\natexlab{e}})Yoon, Koo, Kim, and Yoo]{yoon2023scanet}
Yoon, S., Koo, G., Kim, D., and Yoo, C.~D.
\newblock Scanet: Scene complexity aware network for weakly-supervised video moment retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  13576--13586, 2023{\natexlab{e}}.

\bibitem[Zhang et~al.(2023)Zhang, Rao, and Agrawala]{zhang2023adding}
Zhang, L., Rao, A., and Agrawala, M.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  3836--3847, 2023.

\end{thebibliography}
