\begin{thebibliography}{84}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aka et~al.(2021)Aka, Burke, Bauerle, Greer, and Mitchell]{npmi}
Osman Aka, Ken Burke, Alex Bauerle, Christina Greer, and Margaret Mitchell.
\newblock {Measuring Model Biases in the Absence of Ground Truth}.
\newblock In \emph{{Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics,
  and Society}}, 2021.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bender et~al.(2021)Bender, Gebru, McMillan-Major, and
  Shmitchell]{bender2021}
Emily~M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
  Shmitchell.
\newblock On the dangers of stochastic parrots: Can language models be too
  big?\raisebox{-5pt}{\includegraphics[scale=0.075]{parrot.png}}.
\newblock In \emph{Proceedings of FAccT 2021}, 2021.

\bibitem[Birhane et~al.(2021)Birhane, Prabhu, and
  Kahembwe]{birhane2021laionaudit}
Abeba Birhane, Vinay~Uday Prabhu, and Emmanuel Kahembwe.
\newblock {Multimodal datasets: misogyny, pornography, and malignant
  stereotypes}.
\newblock In \emph{{arXiv:2110.01963}}, 2021.

\bibitem[Bordia and Bowman(2017)]{bordia-naacl-2017}
Shikha Bordia and Samuel~R. Bowman.
\newblock {Identifying and Reducing Gender Bias in Word-Level Language Models}.
\newblock In \emph{{NAACL}}, 2017.

\bibitem[Brock et~al.(2018)Brock, Donahue, and Simonyan]{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock \emph{arXiv preprint arXiv:1809.11096}, 2018.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{brown-neurips-2020}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
  Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter,
  Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
  Ilya Sutskever, and Dario Amodei.
\newblock {Language Models are Few-Shot Learners}.
\newblock In \emph{{NeurIPS}}, 2020.

\bibitem[Buolamwini and Gebru(2018)]{gendershades}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on Fairness, Accountability and Transparency, FAT
  2018, 23-24 February 2018, New York, NY, USA}, Proceedings of Machine
  Learning Research. PMLR, 2018.

\bibitem[Burns et~al.(2018)Burns, Hendricks, Darrell, and Rohrbach]{Burns2018}
Kaylee Burns, Lisa Hendricks, Trevor Darrell, and Anna Rohrbach.
\newblock Women also snowboard: Overcoming bias in captioning models.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2018.

\bibitem[Cho et~al.(2022)Cho, Zala, and Bansal]{dalleval}
Jaemin Cho, Abhay Zala, and Mohit Bansal.
\newblock Dall-eval: Probing the reasoning skills and social biases of
  text-to-image generative transformers.
\newblock \emph{arxiv:2202.04053}, 2022.

\bibitem[Chowdhery et~al.(2022)Chowdhery, Narang, Devlin, Bosma, Mishra,
  Roberts, Barham, Chung, Sutton, Gehrmann, Schuh, Shi, Tsvyashchenko, Maynez,
  Rao, Barnes, Tay, Shazeer, Prabhakaran, Reif, Du, Hutchinson, Pope, Bradbury,
  Austin, Isard, Gur-Ari, Yin, Duke, Levskaya, Ghemawat, Dev, Michalewski,
  Garcia, Misra, Robinson, Fedus, Zhou, Ippolito, Luan, Lim, Zoph, Spiridonov,
  Sepassi, Dohan, Agrawal, Omernick, Dai, Pillai, Pellat, Lewkowycz, Moreira,
  Child, Polozov, Lee, Zhou, Wang, Saeta, Diaz, Firat, Catasta, Wei,
  Meier-Hellstern, Eck, Dean, Petrov, and Fiedel]{palm-2022}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
  Abhishek Rao, Parker Barnes, Yi~Tay, Noam Shazeer, Vinodkumar Prabhakaran,
  Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
  Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
  Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
  Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
  Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
  Dohan, Shivani Agrawal, Mark Omernick, Andrew~M. Dai,
  Thanumalayan~Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
  Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
  Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
  Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
\newblock {PaLM: Scaling Language Modeling with Pathways}.
\newblock In \emph{{arXiv:2001.08361}}, 2022.

\bibitem[Crowson et~al.(2022)Crowson, Biderman, Kornis, Stander, Hallahan,
  Castricato, and Raff]{crowson2022vqgan}
Katherine Crowson, Stella Biderman, Daniel Kornis, Dashiell Stander, Eric
  Hallahan, Louis Castricato, and Edward Raff.
\newblock Vqgan-clip: Open domain image generation and editing with natural
  language guidance.
\newblock \emph{arXiv preprint arXiv:2204.08583}, 2022.

\bibitem[De~Bortoli et~al.(2021)De~Bortoli, Thornton, Heng, and
  Doucet]{de2021diffusion}
Valentin De~Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet.
\newblock Diffusion schr{\"o}dinger bridge with applications to score-based
  generative modeling.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Denton et~al.(2015)Denton, Chintala, Szlam, and
  Fergus]{denton-nips-2015}
Emily Denton, Soumith Chintala, Arthur Szlam, and Rob Fergus.
\newblock {Deep Generative Image Models using a Laplacian Pyramid of
  Adversarial Networks}.
\newblock In \emph{{NIPS}}, 2015.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-naacl-2019}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT: Pre-training of Deep Bidirectional Transformers for Language
  Understanding}.
\newblock In \emph{{NAACL}}, 2019.

\bibitem[Dhariwal and Nichol(2022)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alex Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock In \emph{{NeurIPS}}, 2022.

\bibitem[Ding et~al.(2021)Ding, Yang, Hong, Zheng, Zhou, Yin, Lin, Zou, Shao,
  Yang, et~al.]{ding2021cogview}
Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da~Yin, Junyang
  Lin, Xu~Zou, Zhou Shao, Hongxia Yang, et~al.
\newblock Cogview: Mastering text-to-image generation via transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[{Dulhanty, Chris}(2020)]{dulhantychrisIssuesComputerVision2020}
{Dulhanty, Chris}.
\newblock Issues in {{Computer Vision Data Collection}}: {{Bias}}, {{Consent}},
  and {{Label Taxonomy}}.
\newblock In \emph{{UWSpace}}, 2020.

\bibitem[Esser et~al.(2021)Esser, Rombach, and Ommer]{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12873--12883, 2021.

\bibitem[Franks and Waldman(2019)]{franks2019}
Mary~Anne Franks and Ari~Ezra Waldman.
\newblock Sex, lies and videotape: deep fakes and free speech delusions.
\newblock \emph{Maryland Law Review}, 78\penalty0 (4):\penalty0 892â€“898,
  2019.

\bibitem[Fu et~al.(2021)Fu, Wang, and Wang]{fu2021language}
Tsu-Jui Fu, Xin~Eric Wang, and William~Yang Wang.
\newblock {Language-Driven Image Style Transfer}.
\newblock \emph{{arXiv preprint arXiv:2106.00178}}, 2021.

\bibitem[Gafni et~al.(2022)Gafni, Polyak, Ashual, Sheynin, Parikh, and
  Taigman]{gafni2022make}
Oran Gafni, Adam Polyak, Oron Ashual, Shelly Sheynin, Devi Parikh, and Yaniv
  Taigman.
\newblock Make-a-scene: Scene-based text-to-image generation with human priors.
\newblock \emph{arXiv preprint arXiv:2203.13131}, 2022.

\bibitem[Gebru et~al.(2020)Gebru, Morgenstern, Vecchione, Vaughan, Wallach,
  Daum{\'e}~III, and Crawford]{gebruDatasheetsDatasets2020}
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer~Wortman Vaughan,
  Hanna Wallach, Hal Daum{\'e}~III, and Kate Crawford.
\newblock Datasheets for {{Datasets}}.
\newblock \emph{arXiv:1803.09010 [cs]}, March 2020.

\bibitem[Harvey and LaPlace(2019)]{MegaPixels}
Adam Harvey and Jules LaPlace.
\newblock {{MegaPixels}}: {{Origins}} and endpoints of biometric datasets
  "{{In}} the {{Wild}}".
\newblock https://megapixels.cc, 2019.

\bibitem[Hessel et~al.(2021)Hessel, Holtzman, Forbes, Bras, and
  Choi]{hessel2021clipscore}
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan~Le Bras, and Yejin Choi.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock \emph{arXiv preprint arXiv:2104.08718}, 2021.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock \emph{arXiv preprint arXiv:1706.08500}, 2017.

\bibitem[Ho and Salimans(2021)]{ho2021classifierfree}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock In \emph{NeurIPS 2021 Workshop on Deep Generative Models and
  Downstream Applications}, 2021.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock {Denoising Diffusion Probabilistic Models}.
\newblock \emph{{NeurIPS}}, 2020.

\bibitem[Ho et~al.(2022)Ho, Saharia, Chan, Fleet, Norouzi, and
  Salimans]{ho2021cascaded}
Jonathan Ho, Chitwan Saharia, William Chan, David~J Fleet, Mohammad Norouzi,
  and Tim Salimans.
\newblock Cascaded diffusion models for high fidelity image generation.
\newblock \emph{{JMLR}}, 2022.

\bibitem[Hughes et~al.(2021)Hughes, Zhu, and Bednarz]{hughes2021}
Rowan~T. Hughes, Liming Zhu, and Tomasz Bednarz.
\newblock Generative adversarial networks-enabled human-artificial intelligence
  collaborative applications for creative and design industries: A systematic
  review of current approaches and trends.
\newblock \emph{Frontiers in artificial intelligence}, 4, 2021.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  4904--4916. PMLR, 2021.

\bibitem[Kadkhodaie and Simoncelli(2020)]{kadkhodaie2020solving}
Zahra Kadkhodaie and Eero~P Simoncelli.
\newblock Solving linear inverse problems using the prior implicit in a
  denoiser.
\newblock \emph{arXiv preprint arXiv:2007.13640}, 2020.

\bibitem[Kadkhodaie and Simoncelli(2021)]{kadkhodaie2021stochastic}
Zahra Kadkhodaie and Eero~P Simoncelli.
\newblock Stochastic solutions for linear inverse problems using the prior
  implicit in a denoiser.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Kim and Ye(2021)]{kim2021diffusionclip}
Gwanghyun Kim and Jong~Chul Ye.
\newblock Diffusionclip: Text-guided image manipulation using diffusion models.
\newblock \emph{arXiv preprint arXiv:2110.02711}, 2021.

\bibitem[Kingma et~al.(2021)Kingma, Salimans, Poole, and
  Ho]{kingma2021variational}
Diederik~P Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock Variational diffusion models.
\newblock \emph{arXiv preprint arXiv:2107.00630}, 2021.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Bourdev, Girshick, Hays, Perona,
  Ramanan, Zitnick, and DollÃ¡r]{lin-eccv-2014}
Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick,
  James Hays, Pietro Perona, Deva Ramanan, Lawrence Zitnick, and Piotr DollÃ¡r.
\newblock {Microsoft COCO: Common Objects in Context}.
\newblock In \emph{{ECCV}}, 2014.

\bibitem[Mansimov et~al.(2016)Mansimov, Parisotto, Ba, and
  Salakhutdinov]{mansimov-iclr-2016}
Elman Mansimov, Emilio Parisotto, Jimmy~Lei Ba, and Ruslan Salakhutdinov.
\newblock {Generating Images from Captions with Attention}.
\newblock In \emph{{ICLR}}, 2016.

\bibitem[Marcus et~al.(2022)Marcus, Davis, and Aaronson]{marcus-arxiv-2022}
Gary Marcus, Ernest Davis, and Scott Aaronson.
\newblock {A very preliminary analysis of DALL-E 2}.
\newblock In \emph{{arXiv:2204.13807}}, 2022.

\bibitem[Menick and Kalchbrenner(2019)]{menick-iclr-2019}
Jacob Menick and Nal Kalchbrenner.
\newblock {Generating High Fidelity Images with Subscale Pixel Networks and
  Multidimensional Upscaling}.
\newblock In \emph{{ICLR}}, 2019.

\bibitem[Nichol and Dhariwal(2021)]{nichol2021improved}
Alex Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2102.09672}, 2021.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Pamela~Mishkin,
  Sutskever, and Chen]{nichol-glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Bob~McGrew
  Pamela~Mishkin, Ilya Sutskever, and Mark Chen.
\newblock {GLIDE: Towards Photorealistic Image Generation and Editing with
  Text-Guided Diffusion Models}.
\newblock In \emph{{arXiv:2112.10741}}, 2021.

\bibitem[Parmar et~al.(2022)Parmar, Zhang, and Zhu]{parmar-cvpr-2022}
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu.
\newblock {On Aliased Resizing and Surprising Subtleties in GAN Evaluation}.
\newblock In \emph{{CVPR}}, 2022.

\bibitem[Paullada et~al.(2021)Paullada, Raji, Bender, Denton, and
  Hanna]{Paullada2021}
Amandalynne Paullada, Inioluwa~Deborah Raji, Emily~M. Bender, Emily Denton, and
  Alex Hanna.
\newblock Data and its (dis)contents: A survey of dataset development and use
  in machine learning research.
\newblock \emph{Patterns}, 2\penalty0 (11):\penalty0 100336, 2021.

\bibitem[Prabhu and Birhane(2020)]{prabhu2020}
Vinay~Uday Prabhu and Abeba Birhane.
\newblock Large image datasets: A pyrrhic win for computer vision?
\newblock \emph{arXiv:2006.16923}, 2020.

\bibitem[Pushkarna et~al.(2022)Pushkarna, Zaldivar, and Kjartansson]{datacards}
Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson.
\newblock Data cards: Purposeful and transparent dataset documentation for
  responsible ai.
\newblock In \emph{Proceedings of the 2021 ACM Conference on Fairness,
  Accountability, and Transparency}, 2022.

\bibitem[Radford et~al.(2017)Radford, Jozefowicz, and
  Sutskever]{radford-arxiv-2017}
Alec Radford, Rafal Jozefowicz, and Ilya Sutskever.
\newblock {Learning to Generate Reviews and Discovering Sentiment}.
\newblock In \emph{{arXiv:1704.01444}}, 2017.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford-gpt}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock {Improving Language Understanding by Generative Pre-Training}.
\newblock In \emph{{preprint}}, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford-gpt2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock {Language Models are Unsupervised Multitask Learners}.
\newblock In \emph{{preprint}}, 2019.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{radford-icml-2021}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock {Learning Transferable Visual Models From Natural Language
  Supervision}.
\newblock In \emph{{ICML}}, 2021.

\bibitem[Rae et~al.(2021)Rae, Borgeaud, Cai, Millican, Hoffmann, Song,
  Aslanides, Henderson, Ring, Young, Rutherford, Hennigan, Menick, Cassirer,
  Powell, Driessche, Hendricks, Rauh, Huang, and Irving]{weidinger2021}
Jack Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann,
  Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young,
  Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell,
  George Driessche, Lisa Hendricks, Maribeth Rauh, Po-Sen Huang, and Geoffrey
  Irving.
\newblock Scaling language models: Methods, analysis \& insights from training
  gopher.
\newblock \emph{arXiv:2112.11446}, 2021.

\bibitem[Raffel et~al.(2017)Raffel, Luong, Liu, Weiss, and
  Eck]{raffel-icml-2017}
Colin Raffel, Minh-Thang Luong, Peter~J. Liu, Ron~J. Weiss, and Douglas Eck.
\newblock {Online and Linear-Time Attention by Enforcing Monotonic Alignments}.
\newblock In \emph{{ICML}}, 2017.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{raffel-jmlr-2020}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock {Exploring the Limits of Transfer Learning with a Unified
  Text-to-Text Transformer}.
\newblock \emph{{JMLR}}, 21\penalty0 (140), 2020.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{ramesh-dalle}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock {Zero-Shot Text-to-Image Generation}.
\newblock In \emph{{ICML}}, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh-dalle2}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock {Hierarchical Text-Conditional Image Generation with CLIP Latents}.
\newblock In \emph{{arXiv}}, 2022.

\bibitem[Razavi et~al.(2019)Razavi, Oord, and Vinyals]{razavi2019generating}
Ali Razavi, Aaron van~den Oord, and Oriol Vinyals.
\newblock Generating diverse high-fidelity images with vq-vae-2.
\newblock \emph{arXiv preprint arXiv:1906.00446}, 2019.

\bibitem[Reed et~al.(2016)Reed, Akata, Yan, Logeswaran, Schiele, and
  Lee]{reed2016generative}
Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and
  Honglak Lee.
\newblock Generative adversarial text to image synthesis.
\newblock In \emph{International conference on machine learning}, pages
  1060--1069. PMLR, 2016.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach-cvpr-2022}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ¶rn
  Ommer.
\newblock {High-Resolution Image Synthesis with Latent Diffusion Models}.
\newblock In \emph{{CVPR}}, 2022.

\bibitem[Saharia et~al.(2021{\natexlab{a}})Saharia, Chan, Chang, Lee, Ho,
  Salimans, Fleet, and Norouzi]{sahariac-palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris~A. Lee, Jonathan Ho, Tim
  Salimans, David~J. Fleet, and Mohammad Norouzi.
\newblock {Palette: Image-to-Image Diffusion Models}.
\newblock In \emph{{arXiv:2111.05826}}, 2021{\natexlab{a}}.

\bibitem[Saharia et~al.(2021{\natexlab{b}})Saharia, Ho, Chan, Salimans, Fleet,
  and Norouzi]{saharia2021image}
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David~J Fleet, and
  Mohammad Norouzi.
\newblock Image super-resolution via iterative refinement.
\newblock \emph{arXiv preprint arXiv:2104.07636}, 2021{\natexlab{b}}.

\bibitem[Scheuerman et~al.(2021)Scheuerman, Denton, and
  Hanna]{Scheuerman2021DoDH}
Morgan~Klaus Scheuerman, Emily~L. Denton, and A.~Hanna.
\newblock Do datasets have politics? disciplinary values in computer vision
  dataset development.
\newblock \emph{Proceedings of the ACM on Human-Computer Interaction},
  5:\penalty0 1 -- 37, 2021.

\bibitem[Schuhmann et~al.(2021)Schuhmann, Vencu, Beaumont, Kaczmarczyk, Mullis,
  Katta, Coombes, Jitsev, and Komatsuzaki]{schuhmann2021laion}
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk,
  Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran
  Komatsuzaki.
\newblock Laion-400m: Open dataset of clip-filtered 400 million image-text
  pairs.
\newblock \emph{arXiv preprint arXiv:2111.02114}, 2021.

\bibitem[Sequeira et~al.(2021)Sequeira, Moreschi, Jurno, and dos
  Santos]{Sequeira2021}
Lucas Sequeira, Bruno Moreschi, Amanda Jurno, and Vinicius~Arruda dos Santos.
\newblock {Which faces can AI generate? Normativity, whiteness and lack of
  diversity in This Person Does Not Exist}.
\newblock In \emph{{CVPR Workshop Beyond Fairness: Towards a Just, Equitable,
  and Accountable Computer Vision}}, 2021.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020.

\bibitem[Song and Ermon(2019)]{song2019generative}
Yang Song and Stefano Ermon.
\newblock {Generative Modeling by Estimating Gradients of the Data
  Distribution}.
\newblock \emph{{NeurIPS}}, 2019.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In \emph{{ICLR}}, 2021.

\bibitem[Srinivasan and Uchino(2021)]{Srinivasan2021}
Ramya Srinivasan and Kanji Uchino.
\newblock Biases in generative art: A causal look from the lens of art history.
\newblock In \emph{Proceedings of the 2021 ACM Conference on Fairness,
  Accountability, and Transparency}, page 41â€“51, 2021.

\bibitem[Steed and Caliskan(2021)]{Steed2021}
Ryan Steed and Aylin Caliskan.
\newblock Image representations learned with unsupervised pre-training contain
  human-like biases.
\newblock In \emph{Proceedings of the 2021 ACM Conference on Fairness,
  Accountability, and Transparency}, FAccT '21, page 701â€“713. Association for
  Computing Machinery, 2021.

\bibitem[Tao et~al.(2020)Tao, Tang, Wu, Sebe, Jing, Wu, and Bao]{tao2020df}
Ming Tao, Hao Tang, Songsong Wu, Nicu Sebe, Xiao-Yuan Jing, Fei Wu, and Bingkun
  Bao.
\newblock Df-gan: Deep fusion generative adversarial networks for text-to-image
  synthesis.
\newblock \emph{arXiv preprint arXiv:2008.05865}, 2020.

\bibitem[Tzen and Raginsky(2019)]{tzen2019neural}
Belinda Tzen and Maxim Raginsky.
\newblock {Neural Stochastic Differential Equations: Deep Latent Gaussian
  Models in the Diffusion Limit}.
\newblock In \emph{{arXiv:1905.09883}}, 2019.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, et~al.]{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Vincent(2011)]{vincent2011connection}
Pascal Vincent.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural Computation}, 23\penalty0 (7):\penalty0 1661--1674,
  2011.

\bibitem[Wang et~al.(2018)Wang, Liu, Zhu, Tao, Kautz, and
  Catanzaro]{wang2018high}
Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan
  Catanzaro.
\newblock High-resolution image synthesis and semantic manipulation with
  conditional gans.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 8798--8807, 2018.

\bibitem[Weston et~al.(2011)Weston, Bengio, and Usunier]{weston2011wsabie}
Jason Weston, Samy Bengio, and Nicolas Usunier.
\newblock Wsabie: Scaling up to large vocabulary image annotation.
\newblock In \emph{Twenty-Second International Joint Conference on Artificial
  Intelligence}, 2011.

\bibitem[Whang et~al.(2021)Whang, Delbracio, Talebi, Saharia, Dimakis, and
  Milanfar]{whang2021deblurring}
Jay Whang, Mauricio Delbracio, Hossein Talebi, Chitwan Saharia, Alexandros~G
  Dimakis, and Peyman Milanfar.
\newblock Deblurring via stochastic refinement.
\newblock \emph{arXiv preprint arXiv:2112.02475}, 2021.

\bibitem[Xu et~al.(2018{\natexlab{a}})Xu, Zhang, Huang, Zhang, Gan, Huang, and
  He]{xu-cvpr-2018}
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and
  Xiaodong He.
\newblock {AttnGAN: Fine-Grained Text to Image Generation with Attentional
  Generative Adversarial Networks}.
\newblock In \emph{{CVPR}}, 2018{\natexlab{a}}.

\bibitem[Xu et~al.(2018{\natexlab{b}})Xu, Zhang, Huang, Zhang, Gan, Huang, and
  He]{xu2018attngan}
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and
  Xiaodong He.
\newblock Attngan: Fine-grained text to image generation with attentional
  generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1316--1324, 2018{\natexlab{b}}.

\bibitem[Ye et~al.(2021)Ye, Yang, Takac, Sunderraman, and Ji]{ye2021improving}
Hui Ye, Xiulong Yang, Martin Takac, Rajshekhar Sunderraman, and Shihao Ji.
\newblock Improving text-to-image synthesis using contrastive learning.
\newblock \emph{arXiv preprint arXiv:2107.02423}, 2021.

\bibitem[Yu et~al.(2021)Yu, Li, Koh, Zhang, Pang, Qin, Ku, Xu, Baldridge, and
  Wu]{yu2021vector}
Jiahui Yu, Xin Li, Jing~Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander
  Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.
\newblock Vector-quantized image modeling with improved vqgan.
\newblock \emph{arXiv preprint arXiv:2110.04627}, 2021.

\bibitem[Yu et~al.(2022)Yu, Wang, Vasudevan, Yeung, Seyedhosseini, and
  Wu]{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
  Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock \emph{arXiv preprint arXiv:2205.01917}, 2022.

\bibitem[Zhang et~al.(2021)Zhang, Koh, Baldridge, Lee, and
  Yang]{zhang2021cross}
Han Zhang, Jing~Yu Koh, Jason Baldridge, Honglak Lee, and Yinfei Yang.
\newblock {Cross-Modal Contrastive Learning for Text-to-Image Generation}.
\newblock In \emph{{CVPR}}, 2021.

\bibitem[Zhou et~al.(2021)Zhou, Zhang, Chen, Li, Tensmeyer, Yu, Gu, Xu, and
  Sun]{zhou2021lafite}
Yufan Zhou, Ruiyi Zhang, Changyou Chen, Chunyuan Li, Chris Tensmeyer, Tong Yu,
  Jiuxiang Gu, Jinhui Xu, and Tong Sun.
\newblock Lafite: Towards language-free training for text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2111.13792}, 2021.

\bibitem[Zhu et~al.(2019)Zhu, Pan, Chen, and Yang]{zhu2019dm}
Minfeng Zhu, Pingbo Pan, Wei Chen, and Yi~Yang.
\newblock Dm-gan: Dynamic memory generative adversarial networks for
  text-to-image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 5802--5810, 2019.

\bibitem[Zhu et~al.(2015)Zhu, Kiros, Zemel, Salakhutdinov, Urtasun, Torralba,
  and Fidler]{zhu-iccv-2015}
Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun,
  Antonio Torralba, and Sanja Fidler.
\newblock {Aligning books and movies: Towards story-like visual explanations by
  watching movies and reading books}.
\newblock In \emph{ICCV}, 2015.

\end{thebibliography}
