@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}
@article{balestriero2020mad,
  title={Mad max: Affine spline insights into deep learning},
  author={Balestriero, Randall and Baraniuk, Richard G},
  journal={Proceedings of the IEEE},
  volume={109},
  number={5},
  pages={704--727},
  year={2020},
  publisher={IEEE}
}

@article{su2023roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  pages={127063},
  year={2023},
  publisher={Elsevier}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{hartvigsen2022toxigen,
    title = "{T}oxi{G}en: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
    author = "Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association of Computational Linguistics",
    year = "2022"
}
@article{ju2002probabilistic,
  title={Probabilistic methods for centroidal Voronoi tessellations and their parallel implementations},
  author={Ju, Lili and Du, Qiang and Gunzburger, Max},
  journal={Parallel Computing},
  volume={28},
  number={10},
  pages={1477--1500},
  year={2002},
  publisher={Elsevier}
}

@article{balestriero2018hard,
  title={From hard to soft: Understanding deep network nonlinearities via vector quantization and statistical inference},
  author={Balestriero, Randall and Baraniuk, Richard G},
  journal={arXiv preprint arXiv:1810.09274},
  year={2018}
}

@inproceedings{varadhan2004accurate,
  title={Accurate Minkowski sum approximation of polyhedral models},
  author={Varadhan, Gokul and Manocha, Dinesh},
  booktitle={12th Pacific Conference on Computer Graphics and Applications, 2004. PG 2004. Proceedings.},
  pages={392--401},
  year={2004},
  organization={IEEE}
}

@article{balestriero2019geometry,
  title={The geometry of deep networks: Power diagram subdivision},
  author={Balestriero, Randall and Cosentino, Romain and Aazhang, Behnaam and Baraniuk, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{balestriero2018spline,
  title={A spline theory of deep learning},
  author={Balestriero, Randall and others},
  booktitle={International Conference on Machine Learning},
  pages={374--383},
  year={2018},
  organization={PMLR}
}

@article{gao2020pile,
  title={The {P}ile: An 800{GB} dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{DatabricksBlog2023DollyV2,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
    journal = {online}
}
@inproceedings{humayun2022polarity,
  title={Polarity sampling: Quality and diversity control of pre-trained generative networks via singular values},
  author={Humayun, Ahmed Imtiaz and Balestriero, Randall and Baraniuk, Richard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10641--10650},
  year={2022}
}
@inproceedings{
humayun2022magnet,
title={Ma{GNET}: Uniform Sampling from Deep Generative Network Manifolds Without Retraining},
author={Ahmed Imtiaz Humayun and Randall Balestriero and Richard Baraniuk},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=r5qumLiYwf9}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}
@misc{jigsaw-toxic-comment-classification-challenge,
    author = {CJ Adams and Jeffrey, Sorensen and Julia, Elliott and Lucas, Dixon and Mark, McDonald and Nithum and Will, Cukierski},
    title = {Toxic Comment Classification Challenge},
    publisher = {Kaggle},
    year = {2017}
}
@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{burns2022discovering,
  title={Discovering latent knowledge in language models without supervision},
  author={Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2212.03827},
  year={2022}
}
@article{alishahi2019analyzing,
  title={Analyzing and interpreting neural networks for NLP: A report on the first BlackboxNLP workshop},
  author={Alishahi, Afra and Chrupa{\l}a, Grzegorz and Linzen, Tal},
  journal={Natural Language Engineering},
  volume={25},
  number={4},
  pages={543--557},
  year={2019},
  publisher={Cambridge University Press}
}
@article{wang2022interpretability,
  title={Interpretability in the wild: a circuit for indirect object identification in gpt-2 small},
  author={Wang, Kevin and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2211.00593},
  year={2022}
}
@article{elhage2021mathematical,
  title={A mathematical framework for transformer circuits},
  author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and others},
  journal={Transformer Circuits Thread},
  volume={1},
  year={2021}
}
@article{chughtai2023toy,
  title={A toy model of universality: Reverse engineering how networks learn group operations},
  author={Chughtai, Bilal and Chan, Lawrence and Nanda, Neel},
  journal={arXiv preprint arXiv:2302.03025},
  year={2023}
}
@article{dar2022analyzing,
  title={Analyzing transformers in embedding space},
  author={Dar, Guy and Geva, Mor and Gupta, Ankit and Berant, Jonathan},
  journal={arXiv preprint arXiv:2209.02535},
  year={2022}
}
@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@article{ravichander2020probing,
  title={Probing the probing paradigm: Does probing accuracy entail task relevance?},
  author={Ravichander, Abhilasha and Belinkov, Yonatan and Hovy, Eduard},
  journal={arXiv preprint arXiv:2005.00719},
  year={2020}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{zhao2023explainability,
  title={Explainability for large language models: A survey},
  author={Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
  journal={arXiv preprint arXiv:2309.01029},
  year={2023}
}
@article{bennett1969intrinsic,
  title={The intrinsic dimensionality of signal collections},
  author={Bennett, Robert},
  journal={IEEE Transactions on Information Theory},
  volume={15},
  number={5},
  pages={517--525},
  year={1969},
  publisher={IEEE}
}
@article{campadelli2015intrinsic,
  title={Intrinsic dimension estimation: Relevant techniques and a benchmark framework},
  author={Campadelli, Paola and Casiraghi, Elena and Ceruti, Claudio and Rozza, Alessandro},
  journal={Mathematical Problems in Engineering},
  year={2015},
  publisher={Hindawi}
}
@inproceedings{shekkizhar2020graph,
  title={Graph construction from data by non-negative kernel regression},
  author={Shekkizhar, Sarath and Ortega, Antonio},
  booktitle={Intl. Conf. on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3892--3896},
  year={2020},
  organization={IEEE}
}
@article{pope2021intrinsic,
  title={The intrinsic dimension of images and its impact on learning},
  author={Pope, Phillip and Zhu, Chen and Abdelkader, Ahmed and Goldblum, Micah and Goldstein, Tom},
  journal={arXiv preprint arXiv:2104.08894},
  year={2021}
}
@article{daneshmand2020batch,
  title={Batch normalization provably avoids ranks collapse for randomly initialised deep networks},
  author={Daneshmand, Hadi and Kohler, Jonas and Bach, Francis and Hofmann, Thomas and Lucchi, Aurelien},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18387--18398},
  year={2020}
}
@article{jing2021understanding,
  title={Understanding dimensional collapse in contrastive self-supervised learning},
  author={Jing, Li and Vincent, Pascal and LeCun, Yann and Tian, Yuandong},
  journal={arXiv preprint arXiv:2110.09348},
  year={2021}
}
@article{cosentino2022toward,
  title={Toward a geometrical understanding of self-supervised contrastive learning},
  author={Cosentino, Romain and Sengupta, Anirvan and Avestimehr, Salman and Soltanolkotabi, Mahdi and Ortega, Antonio and Willke, Ted and Tepper, Mariano},
  journal={arXiv preprint arXiv:2205.06926},
  year={2022}
}

@article{bradley1997use,
  title={The use of the area under the ROC curve in the evaluation of machine learning algorithms},
  author={Bradley, Andrew P},
  journal={Pattern recognition},
  volume={30},
  number={7},
  pages={1145--1159},
  year={1997},
  publisher={Elsevier}
}
@inproceedings{bourgeade2023did,
  title={What Did You Learn To Hate? A Topic-Oriented Analysis of Generalization in Hate Speech Detection},
  author={Bourgeade, Tom and Chiril, Patricia and Benamara, Farah and Moriceau, V{\'e}ronique},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={3477--3490},
  year={2023}
}
@article{van2018challenges,
  title={Challenges for toxic comment classification: An in-depth error analysis},
  author={Van Aken, Betty and Risch, Julian and Krestel, Ralf and L{\"o}ser, Alexander},
  journal={arXiv preprint arXiv:1809.07572},
  year={2018}
}
@article{boix2023transformers,
  title={Transformers learn through gradual rank increase},
  author={Boix-Adsera, Enric and Littwin, Etai and Abbe, Emmanuel and Bengio, Samy and Susskind, Joshua},
  journal={arXiv preprint arXiv:2306.07042},
  year={2023}
}
@article{song2023uncovering,
  title={Uncovering hidden geometry in Transformers via disentangling position and context},
  author={Song, Jiajun and Zhong, Yiqiao},
  journal={arXiv preprint arXiv:2310.04861},
  year={2023}
}
@article{jiang2023latent,
  title={A latent space theory for emergent abilities in large language models},
  author={Jiang, Hui},
  journal={arXiv preprint arXiv:2304.09960},
  year={2023}
}
@article{noci2022signal,
  title={Signal propagation in transformers: Theoretical perspectives and the role of rank collapse},
  author={Noci, Lorenzo and Anagnostidis, Sotiris and Biggio, Luca and Orvieto, Antonio and Singh, Sidak Pal and Lucchi, Aurelien},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27198--27211},
  year={2022}
}
@inproceedings{dong2021attention,
  title={Attention is not all you need: Pure attention loses rank doubly exponentially with depth},
  author={Dong, Yihe and Cordonnier, Jean-Baptiste and Loukas, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={2793--2803},
  year={2021},
  organization={PMLR}
}
@article{trockman2023mimetic,
  title={Mimetic Initialization of Self-Attention Layers},
  author={Trockman, Asher and Kolter, J Zico},
  journal={arXiv preprint arXiv:2305.09828},
  year={2023}
}
@article{hernandez2021low,
  title={The low-dimensional linear geometry of contextualized word representations},
  author={Hernandez, Evan and Andreas, Jacob},
  journal={arXiv preprint arXiv:2105.07109},
  year={2021}
}
@article{aghajanyan2020intrinsic,
  title={Intrinsic dimensionality explains the effectiveness of language model fine-tuning},
  author={Aghajanyan, Armen and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2012.13255},
  year={2020}
}
@article{chen2020lottery,
  title={The lottery ticket hypothesis for pre-trained bert networks},
  author={Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Wang, Zhangyang and Carbin, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={15834--15846},
  year={2020}
}
@article{aghajanyan2020better,
  title={Better fine-tuning by reducing representational collapse},
  author={Aghajanyan, Armen and Shrivastava, Akshat and Gupta, Anchit and Goyal, Naman and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2008.03156},
  year={2020}
}
@article{yun2019transformers,
  title={Are transformers universal approximators of sequence-to-sequence functions?},
  author={Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1912.10077},
  year={2019}
}
@inproceedings{weiss2021thinking,
  title={Thinking like transformers},
  author={Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  booktitle={International Conference on Machine Learning},
  pages={11080--11090},
  year={2021},
  organization={PMLR}
}
@article{hahn2020theoretical,
  title={Theoretical limitations of self-attention in neural sequence models},
  author={Hahn, Michael},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={156--171},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{zhang2023efficient,
  title={Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models},
  author={Zhang, Jiang and Wu, Qiong and Xu, Yiming and Cao, Cheng and Du, Zheng and Psounis, Konstantinos},
  journal={arXiv preprint arXiv:2312.08303},
  year={2023}
}

@article{zhang2023interpretable,
  title={Interpretable unified language checking},
  author={Zhang, Tianhua and Luo, Hongyin and Chuang, Yung-Sung and Fang, Wei and Gaitskell, Luc and Hartvigsen, Thomas and Wu, Xixin and Fox, Danny and Meng, Helen and Glass, James},
  journal={arXiv preprint arXiv:2304.03728},
  year={2023}
}
@article{caselli2020hatebert,
  title={Hatebert: Retraining bert for abusive language detection in english},
  author={Caselli, Tommaso and Basile, Valerio and Mitrovi{\'c}, Jelena and Granitzer, Michael},
  journal={arXiv preprint arXiv:2010.12472},
  year={2020}
}

@inproceedings{mathew2021hatexplain,
  title={Hatexplain: A benchmark dataset for explainable hate speech detection},
  author={Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={17},
  pages={14867--14875},
  year={2021}
}

@book{zhou2021challenges,
  title={Challenges in automated debiasing for toxic language detection},
  author={Zhou, Xuhui},
  year={2021},
  publisher={University of Washington}
}
@inproceedings{kim2022generalizable,
  title={Generalizable implicit hate speech detection using contrastive learning},
  author={Kim, Youngwook and Park, Shinwoo and Han, Yo-Sub},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={6667--6679},
  year={2022}
}
@article{wang2022toxicity,
  title={Toxicity detection with generative prompt-based inference},
  author={Wang, Yau-Shian and Chang, Yingshan},
  journal={arXiv preprint arXiv:2205.12390},
  year={2022}
}
