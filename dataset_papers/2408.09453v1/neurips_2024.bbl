\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amos et~al.(2023)Amos, Berant, and Gupta]{amos2023never}
I.~Amos, J.~Berant, and A.~Gupta.
\newblock Never train from scratch: Fair comparison of long-sequence models requires data-driven priors.
\newblock \emph{arXiv preprint arXiv:2310.02980}, 2023.

\bibitem[Arjovsky et~al.(2016)Arjovsky, Shah, and Bengio]{arjovsky2016unitary}
M.~Arjovsky, A.~Shah, and Y.~Bengio.
\newblock Unitary evolution recurrent neural networks.
\newblock In \emph{International conference on machine learning}, pages 1120--1128. PMLR, 2016.

\bibitem[Bai et~al.(2018{\natexlab{a}})Bai, Kolter, and Koltun]{bai2018empirical}
S.~Bai, J.~Z. Kolter, and V.~Koltun.
\newblock An empirical evaluation of generic convolutional and recurrent networks for sequence modeling.
\newblock \emph{arXiv preprint arXiv:1803.01271}, 2018{\natexlab{a}}.

\bibitem[Bai et~al.(2018{\natexlab{b}})Bai, Kolter, and Koltun]{bai2018trellis}
S.~Bai, J.~Z. Kolter, and V.~Koltun.
\newblock Trellis networks for sequence modeling.
\newblock \emph{arXiv preprint arXiv:1810.06682}, 2018{\natexlab{b}}.

\bibitem[Chetlur et~al.(2014)Chetlur, Woolley, Vandermersch, Cohen, Tran, Catanzaro, and Shelhamer]{chetlur2014cudnn}
S.~Chetlur, C.~Woolley, P.~Vandermersch, J.~Cohen, J.~Tran, B.~Catanzaro, and E.~Shelhamer.
\newblock cudnn: Efficient primitives for deep learning.
\newblock \emph{arXiv preprint arXiv:1410.0759}, 2014.

\bibitem[De and Smith(2020)]{de2020batch}
S.~De and S.~Smith.
\newblock Batch normalization biases residual blocks towards the identity function in deep networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 19964--19975, 2020.

\bibitem[Ding et~al.(2019)Ding, Guo, Ding, and Han]{ding2019acnet}
X.~Ding, Y.~Guo, G.~Ding, and J.~Han.
\newblock Acnet: Strengthening the kernel skeletons for powerful cnn via asymmetric convolution blocks.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 1911--1920, 2019.

\bibitem[Ding et~al.(2021{\natexlab{a}})Ding, Hao, Tan, Liu, Han, Guo, and Ding]{ding2021resrep}
X.~Ding, T.~Hao, J.~Tan, J.~Liu, J.~Han, Y.~Guo, and G.~Ding.
\newblock Resrep: Lossless cnn pruning via decoupling remembering and forgetting.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 4510--4520, 2021{\natexlab{a}}.

\bibitem[Ding et~al.(2021{\natexlab{b}})Ding, Zhang, Ma, Han, Ding, and Sun]{ding2021repvgg}
X.~Ding, X.~Zhang, N.~Ma, J.~Han, G.~Ding, and J.~Sun.
\newblock Repvgg: Making vgg-style convnets great again.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 13733--13742, 2021{\natexlab{b}}.

\bibitem[Ding et~al.(2022{\natexlab{a}})Ding, Chen, Zhang, Han, and Ding]{ding2022repmlpnet}
X.~Ding, H.~Chen, X.~Zhang, J.~Han, and G.~Ding.
\newblock Repmlpnet: Hierarchical vision mlp with re-parameterized locality.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 578--587, 2022{\natexlab{a}}.

\bibitem[Ding et~al.(2022{\natexlab{b}})Ding, Zhang, Han, and Ding]{ding2022scaling}
X.~Ding, X.~Zhang, J.~Han, and G.~Ding.
\newblock Scaling up your kernels to 31x31: Revisiting large kernel design in cnns.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 11963--11975, 2022{\natexlab{b}}.

\bibitem[Ding et~al.(2023)Ding, Zhang, Ge, Zhao, Song, Yue, and Shan]{ding2023unireplknet}
X.~Ding, Y.~Zhang, Y.~Ge, S.~Zhao, L.~Song, X.~Yue, and Y.~Shan.
\newblock Unireplknet: A universal perception large-kernel convnet for audio, video, point cloud, time-series and image recognition.
\newblock \emph{arXiv preprint arXiv:2311.15599}, 2023.

\bibitem[Erichson et~al.(2020)Erichson, Azencot, Queiruga, Hodgkinson, and Mahoney]{erichson2020lipschitz}
N.~B. Erichson, O.~Azencot, A.~Queiruga, L.~Hodgkinson, and M.~W. Mahoney.
\newblock Lipschitz recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:2006.12070}, 2020.

\bibitem[Fathi et~al.(2023)Fathi, Pilault, Bacon, Pal, Firat, and Goroshin]{fathi2023block}
M.~Fathi, J.~Pilault, P.-L. Bacon, C.~Pal, O.~Firat, and R.~Goroshin.
\newblock Block-state transformer.
\newblock \emph{arXiv preprint arXiv:2306.09539}, 2023.

\bibitem[Fu et~al.(2023{\natexlab{a}})Fu, Epstein, Nguyen, Thomas, Zhang, Dao, Rudra, and R{\'e}]{fu2023simple}
D.~Y. Fu, E.~L. Epstein, E.~Nguyen, A.~W. Thomas, M.~Zhang, T.~Dao, A.~Rudra, and C.~R{\'e}.
\newblock Simple hardware-efficient long convolutions for sequence modeling.
\newblock \emph{arXiv preprint arXiv:2302.06646}, 2023{\natexlab{a}}.

\bibitem[Fu et~al.(2023{\natexlab{b}})Fu, Kumbong, Nguyen, and R{\'e}]{fu2023flashfftconv}
D.~Y. Fu, H.~Kumbong, E.~Nguyen, and C.~R{\'e}.
\newblock Flashfftconv: Efficient convolutions for long sequences with tensor cores.
\newblock \emph{arXiv preprint arXiv:2311.05908}, 2023{\natexlab{b}}.

\bibitem[Gu and Dao(2023)]{gu2023mamba}
A.~Gu and T.~Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock \emph{arXiv preprint arXiv:2312.00752}, 2023.

\bibitem[Gu et~al.(2020{\natexlab{a}})Gu, Dao, Ermon, Rudra, and R{\'e}]{gu2020hippo}
A.~Gu, T.~Dao, S.~Ermon, A.~Rudra, and C.~R{\'e}.
\newblock Hippo: Recurrent memory with optimal polynomial projections.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1474--1487, 2020{\natexlab{a}}.

\bibitem[Gu et~al.(2020{\natexlab{b}})Gu, Gulcehre, Paine, Hoffman, and Pascanu]{gu2020improving}
A.~Gu, C.~Gulcehre, T.~Paine, M.~Hoffman, and R.~Pascanu.
\newblock Improving the gating mechanism of recurrent neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages 3800--3809. PMLR, 2020{\natexlab{b}}.

\bibitem[Gu et~al.(2021)Gu, Goel, and R{\'e}]{gu2021efficiently}
A.~Gu, K.~Goel, and C.~R{\'e}.
\newblock Efficiently modeling long sequences with structured state spaces.
\newblock \emph{arXiv preprint arXiv:2111.00396}, 2021.

\bibitem[Gu et~al.(2022{\natexlab{a}})Gu, Goel, Gupta, and R{\'e}]{gu2022parameterization}
A.~Gu, K.~Goel, A.~Gupta, and C.~R{\'e}.
\newblock On the parameterization and initialization of diagonal state space models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 35971--35983, 2022{\natexlab{a}}.

\bibitem[Gu et~al.(2022{\natexlab{b}})Gu, Johnson, Timalsina, Rudra, and R{\'e}]{gu2022train}
A.~Gu, I.~Johnson, A.~Timalsina, A.~Rudra, and C.~R{\'e}.
\newblock How to train your hippo: State space models with generalized orthogonal basis projections.
\newblock \emph{arXiv preprint arXiv:2206.12037}, 2022{\natexlab{b}}.

\bibitem[Hasani et~al.(2022)Hasani, Lechner, Wang, Chahine, Amini, and Rus]{hasani2022liquid}
R.~Hasani, M.~Lechner, T.-H. Wang, M.~Chahine, A.~Amini, and D.~Rus.
\newblock Liquid structural state-space models.
\newblock \emph{arXiv preprint arXiv:2209.12951}, 2022.

\bibitem[Hu et~al.(2022)Hu, Feng, Hua, Lai, Huang, Gong, and Hua]{hu2022online}
M.~Hu, J.~Feng, J.~Hua, B.~Lai, J.~Huang, X.~Gong, and X.-S. Hua.
\newblock Online convolutional re-parameterization.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 568--577, 2022.

\bibitem[Knigge et~al.(2023)Knigge, Romero, Gu, Gavves, Bekkers, Tomczak, Hoogendoorn, and Sonke]{knigge2023modelling}
D.~M. Knigge, D.~W. Romero, A.~Gu, E.~Gavves, E.~J. Bekkers, J.~M. Tomczak, M.~Hoogendoorn, and J.-J. Sonke.
\newblock Modelling long range dependencies in nd: From task-specific to a general purpose cnn.
\newblock \emph{arXiv preprint arXiv:2301.10540}, 2023.

\bibitem[Koutnik et~al.(2014)Koutnik, Greff, Gomez, and Schmidhuber]{koutnik2014clockwork}
J.~Koutnik, K.~Greff, F.~Gomez, and J.~Schmidhuber.
\newblock A clockwork rnn.
\newblock In \emph{International conference on machine learning}, pages 1863--1871. PMLR, 2014.

\bibitem[Li et~al.(2022)Li, Cai, Zhang, Chen, and Dey]{li2022makes}
Y.~Li, T.~Cai, Y.~Zhang, D.~Chen, and D.~Dey.
\newblock What makes convolutional models great on long sequence modeling?
\newblock \emph{arXiv preprint arXiv:2210.09298}, 2022.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Chen, Chen, Chen, Xiao, Wu, K{\"a}rkk{\"a}inen, Pechenizkiy, Mocanu, and Wang]{liu2022more}
S.~Liu, T.~Chen, X.~Chen, X.~Chen, Q.~Xiao, B.~Wu, T.~K{\"a}rkk{\"a}inen, M.~Pechenizkiy, D.~Mocanu, and Z.~Wang.
\newblock More convnets in the 2020s: Scaling up kernels beyond 51x51 using sparsity.
\newblock \emph{arXiv preprint arXiv:2207.03620}, 2022{\natexlab{a}}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 10012--10022, 2021.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Mao, Wu, Feichtenhofer, Darrell, and Xie]{liu2022convnet}
Z.~Liu, H.~Mao, C.-Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie.
\newblock A convnet for the 2020s.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 11976--11986, 2022{\natexlab{b}}.

\bibitem[Ma et~al.(2022)Ma, Zhou, Kong, He, Gui, Neubig, May, and Zettlemoyer]{ma2022mega}
X.~Ma, C.~Zhou, X.~Kong, J.~He, L.~Gui, G.~Neubig, J.~May, and L.~Zettlemoyer.
\newblock Mega: moving average equipped gated attention.
\newblock \emph{arXiv preprint arXiv:2209.10655}, 2022.

\bibitem[Massaroli et~al.(2023)Massaroli, Poli, Fu, Kumbong, Parnichkun, Timalsina, Romero, McIntyre, Chen, Rudra, et~al.]{massaroli2023laughing}
S.~Massaroli, M.~Poli, D.~Y. Fu, H.~Kumbong, R.~N. Parnichkun, A.~Timalsina, D.~W. Romero, Q.~McIntyre, B.~Chen, A.~Rudra, et~al.
\newblock Laughing hyena distillery: Extracting compact recurrences from convolutions.
\newblock \emph{arXiv preprint arXiv:2310.18780}, 2023.

\bibitem[Nonaka and Seita(2021)]{nonaka2021depth}
N.~Nonaka and J.~Seita.
\newblock In-depth benchmarking of deep neural network architectures for ecg diagnosis.
\newblock In \emph{Machine Learning for Healthcare Conference}, pages 414--439. PMLR, 2021.

\bibitem[Oord et~al.(2016)Oord, Dieleman, Zen, Simonyan, Vinyals, Graves, Kalchbrenner, Senior, and Kavukcuoglu]{oord2016wavenet}
A.~v.~d. Oord, S.~Dieleman, H.~Zen, K.~Simonyan, O.~Vinyals, A.~Graves, N.~Kalchbrenner, A.~Senior, and K.~Kavukcuoglu.
\newblock Wavenet: A generative model for raw audio.
\newblock \emph{arXiv preprint arXiv:1609.03499}, 2016.

\bibitem[Poli et~al.(2023)Poli, Massaroli, Nguyen, Fu, Dao, Baccus, Bengio, Ermon, and R{\'e}]{poli2023hyena}
M.~Poli, S.~Massaroli, E.~Nguyen, D.~Y. Fu, T.~Dao, S.~Baccus, Y.~Bengio, S.~Ermon, and C.~R{\'e}.
\newblock Hyena hierarchy: Towards larger convolutional language models.
\newblock \emph{arXiv preprint arXiv:2302.10866}, 2023.

\bibitem[Romero et~al.(2021{\natexlab{a}})Romero, Bruintjes, Tomczak, Bekkers, Hoogendoorn, and van Gemert]{romero2021flexconv}
D.~W. Romero, R.-J. Bruintjes, J.~M. Tomczak, E.~J. Bekkers, M.~Hoogendoorn, and J.~C. van Gemert.
\newblock Flexconv: Continuous kernel convolutions with differentiable kernel sizes.
\newblock \emph{arXiv preprint arXiv:2110.08059}, 2021{\natexlab{a}}.

\bibitem[Romero et~al.(2021{\natexlab{b}})Romero, Kuzina, Bekkers, Tomczak, and Hoogendoorn]{romero2021ckconv}
D.~W. Romero, A.~Kuzina, E.~J. Bekkers, J.~M. Tomczak, and M.~Hoogendoorn.
\newblock Ckconv: Continuous kernel convolution for sequential data.
\newblock \emph{arXiv preprint arXiv:2102.02611}, 2021{\natexlab{b}}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang, A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115:\penalty0 211--252, 2015.

\bibitem[Shi et~al.(2023)Shi, Wang, and Fox]{shi2023sequence}
J.~Shi, K.~A. Wang, and E.~Fox.
\newblock Sequence modeling with multiresolution convolutional memory.
\newblock In \emph{International Conference on Machine Learning}, pages 31312--31327. PMLR, 2023.

\bibitem[Smith et~al.(2022)Smith, Warrington, and Linderman]{smith2022simplified}
J.~T. Smith, A.~Warrington, and S.~W. Linderman.
\newblock Simplified state space layers for sequence modeling.
\newblock \emph{arXiv preprint arXiv:2208.04933}, 2022.

\bibitem[Tay et~al.(2020)Tay, Dehghani, Abnar, Shen, Bahri, Pham, Rao, Yang, Ruder, and Metzler]{tay2020long}
Y.~Tay, M.~Dehghani, S.~Abnar, Y.~Shen, D.~Bahri, P.~Pham, J.~Rao, L.~Yang, S.~Ruder, and D.~Metzler.
\newblock Long range arena: A benchmark for efficient transformers.
\newblock \emph{arXiv preprint arXiv:2011.04006}, 2020.

\bibitem[Trinh et~al.(2018)Trinh, Dai, Luong, and Le]{trinh2018learning}
T.~Trinh, A.~Dai, T.~Luong, and Q.~Le.
\newblock Learning longer-term dependencies in rnns with auxiliary losses.
\newblock In \emph{International Conference on Machine Learning}, pages 4965--4974. PMLR, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Warden(2018)]{warden2018speech}
P.~Warden.
\newblock Speech commands: A dataset for limited-vocabulary speech recognition.
\newblock \emph{arXiv preprint arXiv:1804.03209}, 2018.

\bibitem[Zhang et~al.(2023)Zhang, Ram, Hawkins, Zha, and Zhao]{zhang2023efficient}
Q.~Zhang, D.~Ram, C.~Hawkins, S.~Zha, and T.~Zhao.
\newblock Efficient long-range transformers: You need to attend more, but not necessarily at every layer.
\newblock \emph{arXiv preprint arXiv:2310.12442}, 2023.

\bibitem[Zuo et~al.(2022)Zuo, Liu, Jiao, Charles, Manavoglu, Zhao, and Gao]{zuo2022efficient}
S.~Zuo, X.~Liu, J.~Jiao, D.~Charles, E.~Manavoglu, T.~Zhao, and J.~Gao.
\newblock Efficient long sequence modeling via state space augmented transformer.
\newblock \emph{arXiv preprint arXiv:2212.08136}, 2022.

\end{thebibliography}
