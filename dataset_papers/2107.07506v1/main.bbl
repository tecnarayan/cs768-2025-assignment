\begin{thebibliography}{10}

\bibitem{sutton}
Richard~S. Sutton, Doina Precup, and Satinder Singh.
\newblock Between mdps and semi-mdps: A framework for temporal abstraction in
  reinforcement learning.
\newblock {\em Artificial Intelligence}, 112(1):181--211, 1999.

\bibitem{diayn}
Benjamin {Eysenbach}, Abhishek {Gupta}, Julian {Ibarz}, and Sergey {Levine}.
\newblock {Diversity is All You Need: Learning Skills without a Reward
  Function}.
\newblock {\em arXiv e-prints}, page arXiv:1802.06070, February 2018.

\bibitem{florensa17}
Carlos {Florensa}, Yan {Duan}, and Pieter {Abbeel}.
\newblock {Stochastic Neural Networks for Hierarchical Reinforcement Learning}.
\newblock {\em arXiv e-prints}, page arXiv:1704.03012, April 2017.

\bibitem{qualitydiv}
Justin~K. Pugh, Lisa~B. Soros, and Kenneth~O. Stanley.
\newblock Quality diversity: A new frontier for evolutionary computation.
\newblock {\em Frontiers in Robotics and AI}, 3:40, 2016.

\bibitem{markovsoccer}
Michael~L. Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In {\em Proceedings of the Eleventh International Conference on
  International Conference on Machine Learning}, ICML'94, page 157–163, San
  Francisco, CA, USA, 1994. Morgan Kaufmann Publishers Inc.

\bibitem{openaigym}
Greg {Brockman}, Vicki {Cheung}, Ludwig {Pettersson}, Jonas {Schneider}, John
  {Schulman}, Jie {Tang}, and Wojciech {Zaremba}.
\newblock {OpenAI Gym}.
\newblock {\em arXiv e-prints}, page arXiv:1606.01540, June 2016.

\bibitem{hypernets}
David {Ha}, Andrew {Dai}, and Quoc~V. {Le}.
\newblock {HyperNetworks}.
\newblock {\em arXiv e-prints}, page arXiv:1609.09106, September 2016.

\bibitem{ppo}
John {Schulman}, Filip {Wolski}, Prafulla {Dhariwal}, Alec {Radford}, and Oleg
  {Klimov}.
\newblock {Proximal Policy Optimization Algorithms}.
\newblock {\em arXiv e-prints}, page arXiv:1707.06347, July 2017.

\bibitem{rllib}
Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox, Ken
  Goldberg, Joseph Gonzalez, Michael Jordan, and Ion Stoica.
\newblock {RL}lib: Abstractions for distributed reinforcement learning.
\newblock In Jennifer Dy and Andreas Krause, editors, {\em Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of {\em
  Proceedings of Machine Learning Research}, pages 3053--3062. PMLR, 10--15 Jul
  2018.

\bibitem{neat}
Kenneth~O. Stanley and Risto Miikkulainen.
\newblock Evolving neural networks through augmenting topologies.
\newblock {\em Evolutionary Computation}, 10(2):99--127, 2002.

\bibitem{hyperneat}
Kenneth~O. Stanley, David~B. D'Ambrosio, and Jason Gauci.
\newblock {A Hypercube-Based Encoding for Evolving Large-Scale Neural
  Networks}.
\newblock {\em Artificial Life}, 15(2):185--212, 04 2009.

\bibitem{noveltysearch}
Joel Lehman and Kenneth~O. Stanley.
\newblock Abandoning objectives: Evolution through the search for novelty
  alone.
\newblock {\em Evolutionary Computation}, 19(2):189--223, 2011.

\bibitem{nslc}
Joel Lehman and Kenneth Stanley.
\newblock Evolving a diversity of creatures through novelty search and local
  competition.
\newblock pages 211--218, 01 2011.

\bibitem{mapelites}
Jean-Baptiste {Mouret} and Jeff {Clune}.
\newblock {Illuminating search spaces by mapping elites}.
\newblock {\em arXiv e-prints}, page arXiv:1504.04909, April 2015.

\bibitem{qdchallenges}
Justin~K. Pugh, L.~B. Soros, Paul~A. Szerlip, and Kenneth~O. Stanley.
\newblock Confronting the challenge of quality diversity.
\newblock In {\em Proceedings of the 2015 Annual Conference on Genetic and
  Evolutionary Computation}, GECCO '15, page 967–974, New York, NY, USA,
  2015. Association for Computing Machinery.

\bibitem{masood19}
Muhammad~A. {Masood} and Finale {Doshi-Velez}.
\newblock {Diversity-Inducing Policy Gradient: Using Maximum Mean Discrepancy
  to Find a Set of Diverse Policies}.
\newblock {\em arXiv e-prints}, page arXiv:1906.00088, May 2019.

\bibitem{hong2018}
Zhang-Wei {Hong}, Tzu-Yun {Shann}, Shih-Yang {Su}, Yi-Hsiang {Chang}, and
  Chun-Yi {Lee}.
\newblock {Diversity-Driven Exploration Strategy for Deep Reinforcement
  Learning}.
\newblock {\em arXiv e-prints}, page arXiv:1802.04564, February 2018.

\bibitem{popdiv}
Jack {Parker-Holder}, Aldo {Pacchiano}, Krzysztof {Choromanski}, and Stephen
  {Roberts}.
\newblock {Effective Diversity in Population Based Reinforcement Learning}.
\newblock {\em arXiv e-prints}, page arXiv:2002.00632, February 2020.

\bibitem{pbt}
Max {Jaderberg}, Valentin {Dalibard}, Simon {Osindero}, Wojciech~M.
  {Czarnecki}, Jeff {Donahue}, Ali {Razavi}, Oriol {Vinyals}, Tim {Green}, Iain
  {Dunning}, Karen {Simonyan}, Chrisantha {Fernando}, and Koray {Kavukcuoglu}.
\newblock {Population Based Training of Neural Networks}.
\newblock {\em arXiv e-prints}, page arXiv:1711.09846, November 2017.

\bibitem{valor}
Joshua {Achiam}, Harrison {Edwards}, Dario {Amodei}, and Pieter {Abbeel}.
\newblock {Variational Option Discovery Algorithms}.
\newblock {\em arXiv e-prints}, page arXiv:1807.10299, July 2018.

\bibitem{leslie}
Leslie~Pack Kaelbling.
\newblock Learning to achieve goals.
\newblock In {\em IN PROC. OF IJCAI-93}, pages 1094--1098. Morgan Kaufmann,
  1993.

\bibitem{planningwithgcp}
Soroush {Nasiriany}, Vitchyr~H. {Pong}, Steven {Lin}, and Sergey {Levine}.
\newblock {Planning with Goal-Conditioned Policies}.
\newblock {\em arXiv e-prints}, page arXiv:1911.08453, November 2019.

\bibitem{uvfa}
Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver.
\newblock Universal value function approximators.
\newblock In Francis Bach and David Blei, editors, {\em Proceedings of the 32nd
  International Conference on Machine Learning}, volume~37 of {\em Proceedings
  of Machine Learning Research}, pages 1312--1320, Lille, France, 07--09 Jul
  2015. PMLR.

\bibitem{gail}
Yiming {Ding}, Carlos {Florensa}, Mariano {Phielipp}, and Pieter {Abbeel}.
\newblock {Goal-conditioned Imitation Learning}.
\newblock {\em arXiv e-prints}, page arXiv:1906.05838, June 2019.

\bibitem{qmix}
Tabish {Rashid}, Mikayel {Samvelyan}, Christian {Schroeder de Witt}, Gregory
  {Farquhar}, Jakob {Foerster}, and Shimon {Whiteson}.
\newblock {QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent
  Reinforcement Learning}.
\newblock {\em arXiv e-prints}, page arXiv:1803.11485, March 2018.

\bibitem{roma}
Tonghan {Wang}, Heng {Dong}, Victor {Lesser}, and Chongjie {Zhang}.
\newblock {ROMA: Multi-Agent Reinforcement Learning with Emergent Roles}.
\newblock {\em arXiv e-prints}, page arXiv:2003.08039, March 2020.

\bibitem{maven}
Anuj {Mahajan}, Tabish {Rashid}, Mikayel {Samvelyan}, and Shimon {Whiteson}.
\newblock {MAVEN: Multi-Agent Variational Exploration}.
\newblock {\em arXiv e-prints}, page arXiv:1910.07483, October 2019.

\end{thebibliography}
