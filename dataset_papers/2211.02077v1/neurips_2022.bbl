\begin{thebibliography}{10}

\bibitem{abu2016youtube}
Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici,
  Balakrishnan Varadarajan, and Sudheendra Vijayanarasimhan.
\newblock Youtube-8m: A large-scale video classification benchmark.
\newblock {\em arXiv preprint arXiv:1609.08675}, 2016.

\bibitem{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock {\em arXiv preprint arXiv:1907.11692}, 2019.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{sun2019videobert}
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid.
\newblock Videobert: A joint model for video and language representation
  learning.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7464--7473, 2019.

\bibitem{alayrac2020self}
Jean-Baptiste Alayrac, Adria Recasens, Rosalia Schneider, Relja Arandjelovic,
  Jason Ramapuram, Jeffrey De~Fauw, Lucas Smaira, Sander Dieleman, and Andrew
  Zisserman.
\newblock Self-supervised multimodal versatile networks.
\newblock {\em NeurIPS}, 2(6):7, 2020.

\bibitem{arandjelovic2017look}
Relja Arandjelovic and Andrew Zisserman.
\newblock Look, listen and learn.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 609--617, 2017.

\bibitem{arandjelovic2018objects}
Relja Arandjelovic and Andrew Zisserman.
\newblock Objects that sound.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 435--451, 2018.

\bibitem{korbar2018cooperative}
Bruno Korbar, Du~Tran, and Lorenzo Torresani.
\newblock Cooperative learning of audio and video models from self-supervised
  synchronization.
\newblock {\em arXiv preprint arXiv:1807.00230}, 2018.

\bibitem{zolfaghari2021crossclr}
Mohammadreza Zolfaghari, Yi~Zhu, Peter Gehler, and Thomas Brox.
\newblock Crossclr: Cross-modal contrastive learning for multi-modal video
  representations.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1450--1459, 2021.

\bibitem{morgado2021audio}
Pedro Morgado, Nuno Vasconcelos, and Ishan Misra.
\newblock Audio-visual instance discrimination with cross-modal agreement.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12475--12486, 2021.

\bibitem{akbari2021vatt}
Hassan Akbari, Linagzhe Yuan, Rui Qian, Wei-Hong Chuang, Shih-Fu Chang, Yin
  Cui, and Boqing Gong.
\newblock Vatt: Transformers for multimodal self-supervised learning from raw
  video, audio and text.
\newblock {\em arXiv preprint arXiv:2104.11178}, 2021.

\bibitem{miech2019howto100m}
Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Makarand Tapaswi, Ivan
  Laptev, and Josef Sivic.
\newblock Howto100m: Learning a text-video embedding by watching hundred
  million narrated video clips.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2630--2640, 2019.

\bibitem{miech2020end}
Antoine Miech, Jean-Baptiste Alayrac, Lucas Smaira, Ivan Laptev, Josef Sivic,
  and Andrew Zisserman.
\newblock End-to-end learning of visual representations from uncurated
  instructional videos.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9879--9889, 2020.

\bibitem{wang2021efficientclip}
Jue Wang, Haofan Wang, Jincan Deng, Weijia Wu, and Debing Zhang.
\newblock Efficientclip: Efficient cross-modal pre-training by ensemble
  confident learning and language modeling.
\newblock {\em arXiv preprint arXiv:2109.04699}, 2021.

\bibitem{zhou2018towards}
Luowei Zhou, Chenliang Xu, and Jason~J Corso.
\newblock Towards automatic learning of procedures from web instructional
  videos.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{huang2022modality}
Yu~Huang, Junyang Lin, Chang Zhou, Hongxia Yang, and Longbo Huang.
\newblock Modality competition: What makes joint training of multi-modal
  network fail in deep learning?(provably).
\newblock {\em arXiv preprint arXiv:2203.12221}, 2022.

\bibitem{yu2020gradient}
Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and
  Chelsea Finn.
\newblock Gradient surgery for multi-task learning.
\newblock {\em arXiv preprint arXiv:2001.06782}, 2020.

\bibitem{alwassel2019self}
Humam Alwassel, Dhruv Mahajan, Bruno Korbar, Lorenzo Torresani, Bernard Ghanem,
  and Du~Tran.
\newblock Self-supervised learning by cross-modal audio-video clustering.
\newblock {\em arXiv preprint arXiv:1911.12667}, 2019.

\bibitem{recasens2021broaden}
Adri{\`a} Recasens, Pauline Luc, Jean-Baptiste Alayrac, Luyu Wang, Florian
  Strub, Corentin Tallec, Mateusz Malinowski, Viorica Patraucean, Florent
  Altch{\'e}, Michal Valko, et~al.
\newblock Broaden your views for self-supervised video learning.
\newblock {\em arXiv preprint arXiv:2103.16559}, 2021.

\bibitem{luo2020univl}
Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Jason
  Li, Taroon Bharti, and Ming Zhou.
\newblock Univl: A unified video and language pre-training model for multimodal
  understanding and generation.
\newblock {\em arXiv preprint arXiv:2002.06353}, 2020.

\bibitem{chen2020improved}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{gemmeke2017audio}
Jort~F Gemmeke, Daniel~PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence,
  R~Channing Moore, Manoj Plakal, and Marvin Ritter.
\newblock Audio set: An ontology and human-labeled dataset for audio events.
\newblock In {\em 2017 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 776--780. IEEE, 2017.

\bibitem{zhang2017survey}
Yu~Zhang and Qiang Yang.
\newblock A survey on multi-task learning.
\newblock {\em arXiv preprint arXiv:1707.08114}, 2017.

\bibitem{fifty2021efficiently}
Christopher Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, Rohan Anil, and Chelsea
  Finn.
\newblock Efficiently identifying task groupings for multi-task learning.
\newblock {\em arXiv preprint arXiv:2109.04617}, 2021.

\bibitem{chen2018gradnorm}
Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich.
\newblock Gradnorm: Gradient normalization for adaptive loss balancing in deep
  multitask networks.
\newblock In {\em International Conference on Machine Learning}, pages
  794--803. PMLR, 2018.

\bibitem{sener2018multi}
Ozan Sener and Vladlen Koltun.
\newblock Multi-task learning as multi-objective optimization.
\newblock {\em arXiv preprint arXiv:1810.04650}, 2018.

\bibitem{kendall2018multi}
Alex Kendall, Yarin Gal, and Roberto Cipolla.
\newblock Multi-task learning using uncertainty to weigh losses for scene
  geometry and semantics.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7482--7491, 2018.

\bibitem{wang2020gradient}
Zirui Wang, Yulia Tsvetkov, Orhan Firat, and Yuan Cao.
\newblock Gradient vaccine: Investigating and improving multi-task optimization
  in massively multilingual models.
\newblock {\em arXiv preprint arXiv:2010.05874}, 2020.

\bibitem{wang2020makes}
Weiyao Wang, Du~Tran, and Matt Feiszli.
\newblock What makes training multi-modal classification networks hard?
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12695--12705, 2020.

\bibitem{gutmann2010noise}
Michael Gutmann and Aapo Hyv{\"a}rinen.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In {\em Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 297--304. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem{chatterjee2020coherent}
Satrajit Chatterjee.
\newblock Coherent gradients: An approach to understanding generalization in
  gradient descent-based optimization.
\newblock {\em arXiv preprint arXiv:2002.10657}, 2020.

\bibitem{han2018co}
Bo~Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor~W Tsang,
  and Masashi Sugiyama.
\newblock Co-teaching: robust training of deep neural networks with extremely
  noisy labels.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 8536--8546, 2018.

\bibitem{jiang2018mentornet}
Lu~Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li~Fei-Fei.
\newblock Mentornet: Learning data-driven curriculum for very deep neural
  networks on corrupted labels.
\newblock In {\em International Conference on Machine Learning}, pages
  2304--2313. PMLR, 2018.

\bibitem{zhou2020robust}
Tianyi Zhou, Shengjie Wang, and Jeff Bilmes.
\newblock Robust curriculum learning: From clean label detection to noisy label
  self-correction.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{jiang2019accelerating}
Angela~H Jiang, Daniel L-K Wong, Giulio Zhou, David~G Andersen, Jeffrey Dean,
  Gregory~R Ganger, Gauri Joshi, Michael Kaminksy, Michael Kozuch, Zachary~C
  Lipton, et~al.
\newblock Accelerating deep learning by focusing on the biggest losers.
\newblock {\em arXiv preprint arXiv:1910.00762}, 2019.

\bibitem{li2020hero}
Linjie Li, Yen-Chun Chen, Yu~Cheng, Zhe Gan, Licheng Yu, and Jingjing Liu.
\newblock Hero: Hierarchical encoder for video+ language omni-representation
  pre-training.
\newblock {\em arXiv preprint arXiv:2005.00200}, 2020.

\bibitem{jaegle2021perceiver}
Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin
  Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan
  Shelhamer, et~al.
\newblock Perceiver io: A general architecture for structured inputs \&
  outputs.
\newblock {\em arXiv preprint arXiv:2107.14795}, 2021.

\bibitem{rouditchenko2020avlnet}
Andrew Rouditchenko, Angie Boggust, David Harwath, Brian Chen, Dhiraj Joshi,
  Samuel Thomas, Kartik Audhkhasi, Hilde Kuehne, Rameswar Panda, Rogerio Feris,
  et~al.
\newblock Avlnet: Learning audio-visual language representations from
  instructional videos.
\newblock {\em arXiv preprint arXiv:2006.09199}, 2020.

\bibitem{xu2021vlm}
Hu~Xu, Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph
  Feichtenhofer, Florian Metze, and Luke Zettlemoyer.
\newblock Vlm: Task-agnostic video-language model pre-training for video
  understanding.
\newblock {\em arXiv preprint arXiv:2105.09996}, 2021.

\bibitem{likhosherstov2021polyvit}
Valerii Likhosherstov, Anurag Arnab, Krzysztof Choromanski, Mario Lucic,
  Yi~Tay, Adrian Weller, and Mostafa Dehghani.
\newblock Polyvit: Co-training vision transformers on images, videos and audio.
\newblock {\em arXiv preprint arXiv:2111.12993}, 2021.

\bibitem{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock {\em arXiv preprint arXiv:1212.0402}, 2012.

\bibitem{kuehne2011hmdb}
Hildegard Kuehne, Hueihan Jhuang, Est{\'\i}baliz Garrote, Tomaso Poggio, and
  Thomas Serre.
\newblock Hmdb: a large video database for human motion recognition.
\newblock In {\em 2011 International conference on computer vision}, pages
  2556--2563. IEEE, 2011.

\bibitem{kay2017kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
  Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
\newblock The kinetics human action video dataset.
\newblock {\em arXiv preprint arXiv:1705.06950}, 2017.

\bibitem{piczak2015esc}
Karol~J Piczak.
\newblock Esc: Dataset for environmental sound classification.
\newblock In {\em Proceedings of the 23rd ACM international conference on
  Multimedia}, pages 1015--1018, 2015.

\bibitem{xu2016msr}
Jun Xu, Tao Mei, Ting Yao, and Yong Rui.
\newblock Msr-vtt: A large video description dataset for bridging video and
  language.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5288--5296, 2016.

\bibitem{smaira2020short}
Lucas Smaira, Jo{\~a}o Carreira, Eric Noland, Ellen Clancy, Amy Wu, and Andrew
  Zisserman.
\newblock A short note on the kinetics-700-2020 human action dataset.
\newblock {\em arXiv preprint arXiv:2010.10864}, 2020.

\end{thebibliography}
