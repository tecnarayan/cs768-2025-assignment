@inproceedings{edgepopup,
  author    = {Vivek Ramanujan and
               Mitchell Wortsman and
               Aniruddha Kembhavi and
               Ali Farhadi and
               Mohammad Rastegari},
  title     = {What's Hidden in a Randomly Weighted Neural Network?},
  booktitle = {Conference on Computer Vision and Pattern Recognition},
  year      = {2020}
}

@inproceedings{synflow,
  author    = {Hidenori Tanaka and
               Daniel Kunin and
               Daniel L. Yamins and
               Surya Ganguli},
  title     = {Pruning neural networks without any data by iteratively conserving
               synaptic flow},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020}
}

@inproceedings{grasp,
  author    = {Chaoqi Wang and
               Guodong Zhang and
               Roger B. Grosse},
  title     = {Picking Winning Tickets Before Training by Preserving Gradient Flow},
  booktitle = {International Conference on Learning Representations},
  year      = {2020}
}

@inproceedings{snip,
  author    = {Namhoon Lee and
               Thalaiyasingam Ajanthan and
               Philip H. S. Torr},
  title     = {Snip: single-Shot Network Pruning based on Connection sensitivity},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}

@inproceedings{kingma:15:adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}


@article{rbnn,
  title={Rotated Binary Neural Network},
  author={Lin, Mingbao and Ji, Rongrong and Xu, Zihan and Zhang, Baochang and Wang, Yan and Wu, Yongjian and Huang, Feiyue and Lin, Chia-Wen},
  journal={arXiv preprint arXiv:2009.13055},
  year={2020}
}
@article{slbn,
  title={Searching for low-bit weights in quantized neural networks},
  author={Yang, Zhaohui and Wang, Yunhe and Han, Kai and Xu, Chunjing and Xu, Chao and Tao, Dacheng and Xu, Chang},
  journal={arXiv preprint arXiv:2009.08695},
  year={2020}
}

@article{siman,
  title={SiMaN: Sign-to-Magnitude Network Binarization},
  author={Lin, Mingbao and Ji, Rongrong and Xu, Zihan and Zhang, Baochang and Chao, Fei and Xu, Mingliang and Lin, Chia-Wen and Shao, Ling},
  journal={arXiv preprint arXiv:2102.07981},
  year={2021}
}
@article{highcapacity,
  title={High-Capacity Expert Binary Networks},
  author={Bulat, Adrian and Martinez, Brais and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:2010.03558},
  year={2020}
}
@inproceedings{bnas,
  title={Learning architectures for binary networks},
  author={Kim, Dahyun and Singh, Kunal Pratap and Choi, Jonghyun},
  booktitle={European Conference on Computer Vision},
  pages={575--591},
  year={2020},
  organization={Springer}
}

@article{bats,
  title={Bats: Binary architecture search},
  author={Bulat, Adrian and Martinez, Brais and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:2003.01711},
  year={2020}
}

@article{qiu2020train,
  title={Train-by-Reconnect: Decoupling Locations of Weights from Their Values},
  author={Qiu, Yushi and Suda, Reiji},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{bulat2019xnor,
  title={XNOR-Net++: Improved binary neural networks},
  author={Bulat, Adrian and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:1909.13863},
  year={2019}
}

@article{martinez2020training,
  title={Training binary neural networks with real-to-binary convolutions},
  author={Martinez, Brais and Yang, Jing and Bulat, Adrian and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:2003.11535},
  year={2020}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT press Cambridge}
}

@incollection{moreau2019paradigm,
  title={A paradigm for democratizing artificial intelligence research},
  author={Moreau, Erwan and Vogel, Carl and Barry, Marguerite},
  booktitle={Innovations in Big Data Mining and Embedded Knowledge},
  pages={137--166},
  year={2019},
  publisher={Springer}
}

@article{strubell2019energy,
  title={Energy and policy considerations for deep learning in NLP},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  journal={arXiv preprint arXiv:1906.02243},
  year={2019}
}

@inproceedings{gaier2019weight,
  title={Weight agnostic neural networks},
  author={Gaier, Adam and Ha, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5364--5378},
  year={2019}
}

@inproceedings{xie2019exploring,
  title={Exploring randomly wired neural networks for image recognition},
  author={Xie, Saining and Kirillov, Alexander and Girshick, Ross and He, Kaiming},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1284--1293},
  year={2019}
}

@inproceedings{wortsman2019discovering,
  title={Discovering neural wirings},
  author={Wortsman, Mitchell and Farhadi, Ali and Rastegari, Mohammad},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2684--2694},
  year={2019}
}

@inproceedings{gu2019projection,
  title={Projection convolutional neural networks for 1-bit cnns via discrete back propagation},
  author={Gu, Jiaxin and Li, Ce and Zhang, Baochang and Han, Jungong and Cao, Xianbin and Liu, Jianzhuang and Doermann, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={8344--8351},
  year={2019}
}

@inproceedings{gong2019differentiable,
  title={Differentiable soft quantization: Bridging full-precision and low-bit neural networks},
  author={Gong, Ruihao and Liu, Xianglong and Jiang, Shenghu and Li, Tianxiang and Hu, Peng and Lin, Jiazhen and Yu, Fengwei and Yan, Junjie},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4852--4861},
  year={2019}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@INPROCEEDINGS{GlorotInit,
     author = {Glorot, Xavier and Bengio, Yoshua},
      month = may,
      title = {Understanding the difficulty of training deep feedforward neural networks},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
     volume = {9},
       year = {2010},
      pages = {249-256}
}

@article{han2020training,
  title={Training binary neural networks through learning with noisy supervision},
  author={Han, Kai and Wang, Yunhe and Xu, Yixing and Xu, Chunjing and Wu, Enhua and Xu, Chang},
  journal={arXiv preprint arXiv:2010.04871},
  year={2020}
}


@inproceedings{shen2020balanced,
  title={Balanced binary neural networks with gated residual},
  author={Shen, Mingzhu and Liu, Xianglong and Gong, Ruihao and Han, Kai},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4197--4201},
  year={2020},
  organization={IEEE}
}

@inproceedings{liu2018bi,
  title={Bi-real net: Enhancing the performance of 1-bit cnns with improved representational capability and advanced training algorithm},
  author={Liu, Zechun and Wu, Baoyuan and Luo, Wenhan and Yang, Xin and Liu, Wei and Cheng, Kwang-Ting},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={722--737},
  year={2018}
}

@inproceedings{lin2017towards,
  title={Towards accurate binary convolutional neural network},
  author={Lin, Xiaofan and Zhao, Cong and Pan, Wei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={345--353},
  year={2017}
}

@article{zhou2016dorefa,
  title={Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients},
  author={Zhou, Shuchang and Wu, Yuxin and Ni, Zekun and Zhou, Xinyu and Wen, He and Zou, Yuheng},
  journal={arXiv preprint arXiv:1606.06160},
  year={2016}
}

@article{courbariaux2016binarized,
  title={Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1},
  author={Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1602.02830},
  year={2016}
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binaryconnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Advances in neural information processing systems},
  pages={3123--3131},
  year={2015}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@article{zhou2017incremental,
  title={Incremental network quantization: Towards lossless cnns with low-precision weights},
  author={Zhou, Aojun and Yao, Anbang and Guo, Yiwen and Xu, Lin and Chen, Yurong},
  journal={arXiv preprint arXiv:1702.03044},
  year={2017}
}
@article{qin2020binary,
  title={Binary neural networks: A survey},
  author={Qin, Haotong and Gong, Ruihao and Liu, Xianglong and Bai, Xiao and Song, Jingkuan and Sebe, Nicu},
  journal={Pattern Recognition},
  pages={107281},
  year={2020},
  publisher={Elsevier}
}

@article{kim2020binaryduo,
  title={Binaryduo: Reducing gradient mismatch in binary activation network by coupling binary activations},
  author={Kim, Hyungjun and Kim, Kyungsu and Kim, Jinseok and Kim, Jae-Joon},
  journal={arXiv preprint arXiv:2002.06517},
  year={2020}
}

@article{lee2018snip,
  title={Snip: Single-shot network pruning based on connection sensitivity},
  author={Lee, Namhoon and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  journal={arXiv preprint arXiv:1810.02340},
  year={2018}
}

@article{liu2018rethinking,
  title={Rethinking the value of network pruning},
  author={Liu, Zhuang and Sun, Mingjie and Zhou, Tinghui and Huang, Gao and Darrell, Trevor},
  journal={arXiv preprint arXiv:1810.05270},
  year={2018}
}

@inproceedings{yang2019quantization,
  title={Quantization networks},
  author={Yang, Jiwei and Shen, Xu and Xing, Jun and Tian, Xinmei and Li, Houqiang and Deng, Bing and Huang, Jianqiang and Hua, Xian-sheng},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7308--7316},
  year={2019}
}

@inproceedings{bai2018proxquant,
  title={ProxQuant: Quantized Neural Networks via Proximal Operators},
  author={Bai, Yu and Wang, Yu-Xiang and Liberty, Edo},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009},
  publisher={Citeseer}
}



@inproceedings{2wang2020pruning,
  title={Pruning from Scratch.},
  author={Wang, Yulong and Zhang, Xiaolu and Xie, Lingxi and Zhou, Jun and Su, Hang and Zhang, Bo and Hu, Xiaolin},
  booktitle={AAAI},
  pages={12273--12280},
  year={2020}
}

@article{1wang2020picking,
  title={Picking winning tickets before training by preserving gradient flow},
  author={Wang, Chaoqi and Zhang, Guodong and Grosse, Roger},
  journal={arXiv preprint arXiv:2002.07376},
  year={2020}
}

@inproceedings{tung2018clip,
  title={Clip-q: Deep network compression learning by in-parallel pruning-quantization},
  author={Tung, Frederick and Mori, Greg},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7873--7882},
  year={2018}
}

@inproceedings{qin2020forward,
  title={Forward and Backward Information Retention for Accurate Binary Neural Networks},
  author={Qin, Haotong and Gong, Ruihao and Liu, Xianglong and Shen, Mingzhu and Wei, Ziran and Yu, Fengwei and Song, Jingkuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2250--2259},
  year={2020}
}
@incollection{Gui_NIPS2019,
title = {Model Compression with Adversarial Robustness: A Unified Optimization Framework},
author = {Gui, Shupeng and Wang, Haotao N and Yang, Haichuan and Yu, Chen and Wang, Zhangyang and Liu, Ji},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {1285--1296},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8410-model-compression-with-adversarial-robustness-a-unified-optimization-framework.pdf}
}

@misc{xu2020automatic,
    title={Automatic Perturbation Analysis on General Computational Graphs},
    author={Kaidi Xu and Zhouxing Shi and Huan Zhang and Minlie Huang and Kai-Wei Chang and Bhavya Kailkhura and Xue Lin and Cho-Jui Hsieh},
    year={2020},
    eprint={2002.12920},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Jin_2019,
   title={DeepSZ},
   ISBN={9781450366700},
   url={http://dx.doi.org/10.1145/3307681.3326608},
   DOI={10.1145/3307681.3326608},
   journal={Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing},
   publisher={ACM},
   author={Jin, Sian and Di, Sheng and Liang, Xin and Tian, Jiannan and Tao, Dingwen and Cappello, Franck},
   year={2019},
   month={Jun}
}

@misc{jakubovitz2018generalization,
    title={Generalization Error in Deep Learning},
    author={Daniel Jakubovitz and Raja Giryes and Miguel R. D. Rodrigues},
    year={2018},
    eprint={1808.01174},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{arora2018stronger,
    title={Stronger generalization bounds for deep nets via a compression approach},
    author={Sanjeev Arora and Rong Ge and Behnam Neyshabur and Yi Zhang},
    year={2018},
    eprint={1802.05296},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{liu2019algorithms,
    title={Algorithms for Verifying Deep Neural Networks},
    author={Changliu Liu and Tomer Arnon and Christopher Lazarus and Clark Barrett and Mykel J. Kochenderfer},
    year={2019},
    eprint={1903.06758},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{serra2020lossless,
    title={Lossless Compression of Deep Neural Networks},
    author={Thiago Serra and Abhinav Kumar and Srikumar Ramalingam},
    year={2020},
    eprint={2001.00218},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@ARTICLE{Compression_Article_2018,
  author={Y. {Cheng} and D. {Wang} and P. {Zhou} and T. {Zhang}},
  journal={IEEE Signal Processing Magazine}, 
  title={Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges}, 
  year={2018},
  volume={35},
  number={1},
  pages={126-136},
}

@misc{suzuki2019compression,
    title={Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network},
    author={Taiji Suzuki},
    year={2019},
    eprint={1909.11274},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{srinivas2016gendropout,
  author    = {Suraj Srinivas and R. Venkatesh Babu},
  title     = {Generalized Dropout},
  journal   = {CoRR},
  volume    = {abs/1611.06791},
  year      = {2016},
}

@article{cheng2017survey,
  title={An Overview of Neural Network Compression},
  author={Neill, James O'},
  journal={arXiv preprint arXiv:2006.03669},
  year={2020}
}
@inproceedings{lecun1990optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John S and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={598--605},
  year={1990}
}
@article{hou2016loss,
  title={Loss-aware binarization of deep networks},
  author={Hou, Lu and Yao, Quanming and Kwok, James T},
  journal={arXiv preprint arXiv:1611.01600},
  year={2016}
}

@article{ye2020good,
  title={Good Subnetworks Provably Exist: Pruning via Greedy Forward Selection},
  author={Ye, Mao and Gong, Chengyue and Nie, Lizhen and Zhou, Denny and Klivans, Adam and Liu, Qiang},
  journal={arXiv preprint arXiv:2003.01794},
  year={2020}
}
@inproceedings{neyshabur2017exploring,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  booktitle={Advances in neural information processing systems},
  pages={5947--5956},
  year={2017}
}


@inproceedings{hagiwara1993removal,
  title={Removal of hidden units and weights for back propagation networks},
  author={Hagiwara, Masafumi},
  booktitle={Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
  volume={1},
  pages={351--354},
  year={1993},
  organization={IEEE}
}
@inproceedings{weigend1991generalization,
  title={Generalization by weight-elimination with application to forecasting},
  author={Weigend, Andreas S and Rumelhart, David E and Huberman, Bernardo A},
  booktitle={Advances in neural information processing systems},
  pages={875--882},
  year={1991}
}

@inproceedings{Lin2020Dynamic,
title={Dynamic Model Pruning with Feedback},
author={Tao Lin and Sebastian U. Stich and Luis Barba and Daniil Dmitriev and Martin Jaggi},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{frankle2019lottery,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Frankle, Jonathan and Carbin, Michael},
booktitle={International Conference on Learning Representations},
year={2019},
}

@InProceedings{malach2020proving,
  title = 	 {Proving the Lottery Ticket Hypothesis: Pruning is All You Need},
  author =       {Malach, Eran and Yehudai, Gilad and Shalev-Schwartz, Shai and Shamir, Ohad},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020}
}

@inproceedings{zhou2019deconstructing,
  title={Deconstructing lottery tickets: Zeros, signs, and the supermask},
  author={Zhou, Hattie and Lan, Janice and Liu, Rosanne and Yosinski, Jason},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3597--3607},
  year={2019}
}

@inproceedings{ramanujan2019whats,
  title={What's Hidden in a Randomly Weighted Neural Network?},
  author={Ramanujan, Vivek and Wortsman, Mitchell and Kembhavi, Aniruddha and Farhadi, Ali and Rastegari, Mohammad},
  booktitle={Computer Vision and Pattern Recognition},
  pages={11893--11902},
  year={2020}
}
@article{hieberCompose,
author = {Johannes Schmidt-Hieber},
title = {{Nonparametric regression using deep neural networks with ReLU activation function}},
volume = {48},
journal = {The Annals of Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1875 -- 1897},
year = {2020}
}

@inproceedings{deepOverShallow,
author = {Mhaskar, Hrushikesh and Liao, Qianli and Poggio, Tomaso},
title = {When and Why Are Deep Networks Better than Shallow Ones?},
year = {2017},
booktitle = {AAAI Conference on Artificial Intelligence},
pages = {2343–2349},
numpages = {7}
}

@misc{sanyal2018robustness,
    title={Robustness via Deep Low-Rank Representations},
    author={Amartya Sanyal and Varun Kanade and Philip H. S. Torr and Puneet K. Dokania},
    eprint={1804.07090},
    archivePrefix={arXiv},
    year={2018}
}

@article{tanaka2020pruning,
  title={Pruning neural networks without any data by iteratively conserving synaptic flow},
  author={Tanaka, Hidenori and Kunin, Daniel and Yamins, Daniel LK and Ganguli, Surya},
  journal={arXiv preprint arXiv:2006.05467},
  year={2020}
}

@misc{morcos2019ticket,
    title={One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers},
    author={Ari S. Morcos and Haonan Yu and Michela Paganini and Yuandong Tian},
    year={2019},
    eprint={1906.02773},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{wang2020picking,
    title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
    author={Chaoqi Wang and Guodong Zhang and Roger Grosse},
    year={2020},
    eprint={2002.07376},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{merolla2016deep,
    title={Deep neural networks are robust to weight binarization and other non-linear distortions},
    author={Paul Merolla and Rathinakumar Appuswamy and John Arthur and Steve K. Esser and Dharmendra Modha},
    year={2016},
    eprint={1606.01981},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@inproceedings{pensia2020optimal,
 author = {Pensia, Ankit and Rajput, Shashank and Nagle, Alliot and Vishwakarma, Harit and Papailiopoulos, Dimitris},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {2599--2610},
 title = {Optimal Lottery Tickets via Subset Sum: Logarithmic Over-Parameterization is Sufficient},
 volume = {33},
 year = {2020}
}

@article{subsetsum,
author = {Lueker, George S.},
title = {Exponentially small bounds on the expected optimum of the partition and subset sum problems},
journal = {Random Structures \& Algorithms},
volume = {12},
number = {1},
pages = {51-62},
year = {1998}
}

@inproceedings{dyniso,
 author = {Burkholz, Rebekka and Dubatovka, Alina},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Initialization of {ReLUs} for Dynamical Isometry},
 volume = {32},
 year = {2019}
}

@inproceedings{meanfield,
  author    = {Samuel S. Schoenholz and
               Justin Gilmer and
               Surya Ganguli and
               Jascha Sohl{-}Dickstein},
  title     = {Deep Information Propagation},
  booktitle = {International Conference on Learning Representations},
  year      = {2017}
}

@misc{cosentino2019search,
    title={The Search for Sparse, Robust Neural Networks},
    author={Justin Cosentino and Federico Zaiter and Dan Pei and Jun Zhu},
    year={2019},
    eprint={1912.02386},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{wang2019pruning,
    title={Pruning from Scratch},
    author={Yulong Wang and Xiaolu Zhang and Lingxi Xie and Jun Zhou and Hang Su and Bo Zhang and Xiaolin Hu},
    year={2019},
    eprint={1909.12579},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{sehwag2020pruning,
    title={On Pruning Adversarially Robust Neural Networks},
    author={Vikash Sehwag and Shiqi Wang and Prateek Mittal and Suman Jana},
    year={2020},
    eprint={2002.10509},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in neural information processing systems},
  pages={1135--1143},
  year={2015}
}

@misc{kawaguchi2016deep,
    title={Deep Learning without Poor Local Minima},
    author={Kenji Kawaguchi},
    year={2016},
    eprint={1605.07110},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{li2017visualizing,
    title={Visualizing the Loss Landscape of Neural Nets},
    author={Hao Li and Zheng Xu and Gavin Taylor and Christoph Studer and Tom Goldstein},
    year={2017},
    eprint={1712.09913},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{huang2017snapshot,
    title={Snapshot Ensembles: Train 1, get M for free},
    author={Gao Huang and Yixuan Li and Geoff Pleiss and Zhuang Liu and John E. Hopcroft and Kilian Q. Weinberger},
    year={2017},
    eprint={1704.00109},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{zhang2018lq,
  title={Lq-nets: Learned quantization for highly accurate and compact deep neural networks},
  author={Zhang, Dongqing and Yang, Jiaolong and Ye, Dongqiangzi and Hua, Gang},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={365--382},
  year={2018}
}

@misc{ancona2019explaining,
    title={Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Values Approximation},
    author={Marco Ancona and Cengiz Öztireli and Markus Gross},
    year={2019},
    eprint={1903.10992},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{FATIMA20081673,
title = "A linear approximation method for the Shapley value",
journal = "Artificial Intelligence",
volume = "172",
number = "14",
pages = "1673 - 1699",
year = "2008",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2008.05.003",
url = "http://www.sciencedirect.com/science/article/pii/S0004370208000696",
author = "Shaheen S. Fatima and Michael Wooldridge and Nicholas R. Jennings",
keywords = "Coalitional game theory, Shapley value, Approximation method",
}

@misc{chen2019explaining,
    title={Explaining Models by Propagating Shapley Values of Local Components},
    author={Hugh Chen and Scott Lundberg and Su-In Lee},
    year={2019},
    eprint={1911.11888},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ancona2020shapley,
    title={Shapley Value as Principled Metric for Structured Network Pruning},
    author={Marco Ancona and Cengiz Öztireli and Markus Gross},
    year={2020},
    eprint={2006.01795},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{dhamdhere2019shapley,
    title={The Shapley Taylor Interaction Index},
    author={Kedar Dhamdhere and Ashish Agarwal and Mukund Sundararajan},
    year={2019},
    eprint={1902.05622},
    archivePrefix={arXiv},
    primaryClass={cs.GT}
}

@article{owen2014sobol,
author = {Owen, Art B.},
title = {Sobol' Indices and Shapley Value},
journal = {SIAM/ASA Journal on Uncertainty Quantification},
volume = {2},
number = {1},
pages = {245-251},
year = {2014},
doi = {10.1137/130936233},
}

@INPROCEEDINGS{khalid2019quantization,
  author={F. {Khalid} and H. {Ali} and H. {Tariq} and M. A. {Hanif} and S. {Rehman} and R. {Ahmed} and M. {Shafique}},
  booktitle={2019 IEEE 25th International Symposium on On-Line Testing and Robust System Design (IOLTS)}, 
  title={QuSecNets: Quantization-based Defense Mechanism for Securing Deep Neural Network against Adversarial Attacks}, 
  year={2019},
  volume={},
  number={},
  pages={182-187},
}

@misc{ding2019sensitivity,
    title={On the Sensitivity of Adversarial Robustness to Input Data Distributions},
    author={Gavin Weiguang Ding and Kry Yik Chau Lui and Xiaomeng Jin and Luyu Wang and Ruitong Huang},
    year={2019},
    eprint={1902.08336},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{rastegari2016xnornet,
  title={Xnor-net: Imagenet classification using binary convolutional neural networks},
  author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
  booktitle={European conference on computer vision},
  pages={525--542},
  year={2016},
  organization={Springer}
}


@misc{galloway2017attacking,
    title={Attacking Binarized Neural Networks},
    author={Angus Galloway and Graham W. Taylor and Medhat Moussa},
    year={2017},
    eprint={1711.00449},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{xue2020adversarial,
    title={Towards adversarial robustness with 01 loss neural networks},
    author={Yunzhe Xue and Meiyan Xie and Usman Roshan},
    year={2020},
    eprint={2008.09148},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{orseau2020logarithmic,
  title={Logarithmic pruning is all you need},
  author={Orseau, Laurent and Hutter, Marcus and Rivasplata, Omar},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{HeInit,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}


@article{wu2020sbnn,
author = {Wu, Qing and Lu, Xiaojin and Xue, Shan and Wang, Chao and Wu, Xundong and Fan, Jin},
year = {2020},
month = {03},
pages = {},
title = {SBNN: Slimming binarized neural network},
volume = {401},
journal = {Neurocomputing},
doi = {10.1016/j.neucom.2020.03.030}
}

@misc{zhang2019lookahead,
      title={Lookahead Optimizer: k steps forward, 1 step back}, 
      author={Michael R. Zhang and James Lucas and Geoffrey Hinton and Jimmy Ba},
      year={2019},
      eprint={1907.08610},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{simonyan2014very,
author = {Simonyan, Karen and Zisserman, Andrew},
year = {2014},
month = {09},
pages = {},
title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
journal = {arXiv 1409.1556}
}

@misc{mishra2017wrpn,
      title={WRPN: Wide Reduced-Precision Networks}, 
      author={Asit Mishra and Eriko Nurvitadhi and Jeffrey J Cook and Debbie Marr},
      year={2017},
      eprint={1709.01134},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{scarselli1998universal,
author = {Scarselli, Franco and Tsoi, Ah Chung},
title = {Universal Approximation Using Feedforward Neural Networks: A Survey of Some Existing Methods, and Some New Results},
year = {1998},
volume = {11},
number = {1},
journal = {Neural Netw.},
month = jan,
pages = {15–37},
numpages = {23},
}

@inproceedings{han2015learning,
author = {Han, Song and Pool, Jeff and Tran, John and Dally, William J.},
title = {Learning Both Weights and Connections for Efficient Neural Networks},
year = {2015},
booktitle = {International Conference on Neural Information Processing Systems},
}

@inbook{hanson1989comparing,
author = {Hanson, Stephen Jos\'{e} and Pratt, Lorien},
title = {Comparing Biases for Minimal Network Construction with Back-Propagation},
year = {1989},
booktitle = {Advances in Neural Information Processing Systems 1},
}

@inproceedings{hassibi1992second,
author = {Hassibi, Babak and Stork, David G.},
title = {Second Order Derivatives for Network Pruning: Optimal Brain Surgeon},
year = {1992},
booktitle = {International Conference on Neural Information Processing Systems},
}

@article{boyd2009sensor,
author = {Joshi, Siddharth and Boyd, Stephen},
title = {Sensor Selection via Convex Optimization},
year = {2009},
volume = {57},
number = {2},
journal = {Trans. Sig. Proc.},
month = feb,
pages = {451–462}
}

@misc{frankle2020training,
      title={Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNNs}, 
      author={Jonathan Frankle and David J. Schwab and Ari S. Morcos},
      year={2020},
      eprint={2003.00152},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

 @InProceedings{approx, 
 title = {Optimal approximation of continuous functions by very deep ReLU networks}, author = {Yarotsky, Dmitry}, 
 booktitle = {Conference On Learning Theory}, 
 pages = {639--649}, 
 year = {2018}
 }
 
@inproceedings{rescaleInit,
title={Robust Pruning at Initialization},
author={Soufiane Hayou and Jean-Francois Ton and Arnaud Doucet and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{frankle2021review,
title={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},
author={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{multiprize,
title={Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network},
author={James Diffenderfer and Bhavya Kailkhura},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{sigmoidl0,
 author = {Savarese, Pedro and Silva, Hugo and Maire, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Winning the Lottery with Continuous Sparsification},
 year = {2020}
}


@inproceedings{dong2017surgeon,
  author    = {Xin Dong and
               Shangyu Chen and
               Sinno Jialin Pan},
  title     = {Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain
               Surgeon},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017}
}

@inproceedings{li2017pruneconv,
  author    = {Hao Li and
               Asim Kadav and
               Igor Durdanovic and
               Hanan Samet and
               Hans Peter Graf},
  title     = {Pruning Filters for Efficient ConvNets},
  booktitle = {International Conference on Learning Representations},
  year      = {2017},
}

@inproceedings{molchanov2017pruneinf,
  author    = {Pavlo Molchanov and
               Stephen Tyree and
               Tero Karras and
               Timo Aila and
               Jan Kautz},
  title     = {Pruning Convolutional Neural Networks for Resource Efficient Inference},
  booktitle = {International Conference on Learning Representations},
  year      = {2017},
}

@article{DD,
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	title = {Reconciling modern machine-learning practice and the classical bias{\textendash}variance trade-off},
	year = {2019},
	journal = {Proceedings of the National Academy of Sciences}
}

@misc{nonzerobiases,
	author = {Fischer, Jonas and Gadhikar, Advait and Burkholz, Rebekka},
	title = {Lottery Tickets with Nonzero Biases},
	year = {2021},
	eprint={2110.11150},
	archivePrefix = {arXiv}
}

@inproceedings{orthoRepair,
title={A Signal Propagation Perspective for Pruning Neural Networks at Initialization},
author={Namhoon Lee and Thalaiyasingam Ajanthan and Stephen Gould and Philip H. S. Torr},
booktitle={International Conference on Learning Representations},
year={2020}
}

@misc{snipit,
      title={Pruning via Iterative Ranking of Sensitivity Statistics}, 
      author={Stijn Verdenius and Maarten Stol and Patrick Forré},
      year={2020},
      eprint={2006.00896},
      archivePrefix={arXiv}
}

@inproceedings{earlybird,
title={Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks},
author={Haoran You and Chaojian Li and Pengfei Xu and Yonggan Fu and Yue Wang and Xiaohan Chen and Richard G. Baraniuk and Zhangyang Wang and Yingyan Lin},
booktitle={International Conference on Learning Representations},
year={2020}
}


@InProceedings{rewind,
  title = 	 {Linear Mode Connectivity and the Lottery Ticket Hypothesis},
  author =       {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020}
}


@InProceedings{evci2019rigging,
  title = 	 {Rigging the Lottery: Making All Tickets Winners},
  author =       {Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020}
}

@inproceedings{rewindVsFinetune,
title={Comparing Rewinding and Fine-tuning in Neural Network Pruning},
author={Alex Renda and Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2020}
}

@InProceedings{weightcor,
  title = 	 {Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?},
  author =       {Liu, Ning and Yuan, Geng and Che, Zhengping and Shen, Xuan and Ma, Xiaolong and Jin, Qing and Ren, Jian and Tang, Jian and Liu, Sijia and Wang, Yanzhi},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021},
}

@inproceedings{LTreg,
 author = {Savarese, Pedro and Silva, Hugo and Maire, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Winning the Lottery with Continuous Sparsification},
 year = {2020}
}

@inproceedings{weightelim,
 author = {Weigend, Andreas and Rumelhart, David and Huberman, Bernardo},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Generalization by Weight-Elimination with Application to Forecasting},
 year = {1991}
}

@InProceedings{slot,
  title = 	 {Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks},
  author =       {Aladago, Maxwell M and Torresani, Lorenzo},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021},
}

@inproceedings{sanity,
 author = {Su, Jingtong and Chen, Yihang and Cai, Tianle and Wu, Tianhao and Gao, Ruiqi and Wang, Liwei and Lee, Jason D},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot},
 year = {2020}
}

@inproceedings{plastic,
  author    = {Shiwei Liu and
               Tianlong Chen and
               Xiaohan Chen and
               Zahra Atashgahi and
               Lu Yin and
               Huanyu Kou and
               Li Shen and
               Mykola Pechenizkiy and
               Zhangyang Wang and
               Decebal Constantin Mocanu},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Sparse Training via Boosting Pruning Plasticity with Neuroregeneration},
  year      = {2021}
}

@inproceedings{IMPfirst,
 author = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Learning both Weights and Connections for Efficient Neural Network},
 year = {2015}
}

@inproceedings{braindamage,
 author = {LeCun, Yann and Denker, John and Solla, Sara},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Optimal Brain Damage},
 year = {1990}
}

@article{denker,
author = {Denker, John and Schwartz, Daniel and Wittner, Ben and Solla, Sara and Howard, Richard and Jackel, Larry and Hopfield, John},
year = {1987},
month = {01},
title = {Large automatic learning, rule extraction, and generalization},
volume = {1},
journal = {Complex Systems}
}

@inproceedings{trimming,
 author = {Mozer, Michael C and Smolensky, Paul},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment},
 year = {1989}
}

@incollection{xor,
  author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
  booktitle = {Parallel Distributed Processing},
  chapter = 8,
  title = {Learning Internal Representations by Error Propagation},
  year = 1986
}

@article{sg,
  title={Learning symmetry groups with hidden units: beyond the perceptron},
  author={Terrence J. Sejnowski and Paul K. Kienker and Geoffrey E. Hinton},
  journal={Physica D: Nonlinear Phenomena},
  year={1986},
  volume={2},
  pages={260-275}
}

@INPROCEEDINGS{fft,
  author={Velik, Rosemarie},
  booktitle={International Conference on Computational Intelligence and Security}, 
  title={Discrete Fourier Transform Computation Using Neural Networks}, 
  year={2008}
}

@inproceedings{algoalign,
title={What Can Neural Networks Reason About?},
author={Keyulu Xu and Jingling Li and Mozhi Zhang and Simon S. Du and Ken-ichi Kawarabayashi and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{protein,
author = {Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and Žídek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and Velankar, Sameer and Kleywegt, Gerard and Bateman, Alex and Evans, Richard and Pritzel, Alexander and Figurnov, Michael and Ronneberger, Olaf and Bates, Russ and Kohl, Simon and Hassabis, Demis},
year = {2021},
month = {08},
pages = {1-9},
title = {Highly accurate protein structure prediction for the human proteome},
volume = {596},
journal = {Nature}
}

@inproceedings{pwlf,
title={Understanding Deep Neural Networks with Rectified Linear Units},
author={Raman Arora and Amitabh Basu and Poorya Mianjy and Anirbit Mukherjee},
booktitle={International Conference on Learning Representations},
year={2018}
}

@book{bishop,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}


@InProceedings{liu2021:finetune,
  title = 	 {Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?},
  author =       {Liu, Ning and Yuan, Geng and Che, Zhengping and Shen, Xuan and Ma, Xiaolong and Jin, Qing and Ren, Jian and Tang, Jian and Liu, Sijia and Wang, Yanzhi},
  booktitle = 	 {International Conference on Machine Learning},
  year = {2021}
}

@inproceedings{uniExist,
title={On the Existence of Universal Lottery Tickets},
author={Rebekka Burkholz and Nilanjana Laha and Rajarshi Mukherjee and Alkis Gotovos},
booktitle={International Conference on Learning Representations},
year={2022}
}

@inproceedings{plant,
title={Plant 'n' Seek: Can You Find the Winning Ticket?},
author={Jonas Fischer and Rebekka Burkholz},
booktitle={International Conference on Learning Representations},
year={2022}
}

@inproceedings{linInit,
 author = {Shang, Wenling and Sohn, Kihyuk and Almeida, Diogo and Lee, Honglak},
 title = {Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units},
 booktitle = {International Conference on International Conference on Machine Learning},
 year = {2016}
}
 
@article{han-efficient-nns,
  author    = {Song Han and
               Jeff Pool and
               John Tran and
               William J. Dally},
  title     = {Learning both Weights and Connections for Efficient Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1506.02626},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.02626},
  eprinttype = {arXiv},
  eprint    = {1506.02626},
  timestamp = {Fri, 20 Nov 2020 16:16:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/HanPTD15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{relu,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Icml},
  year={2010}
}

@article{provable-benefits-overparam,
  author    = {Xiangyu Chang and
               Yingcong Li and
               Samet Oymak and
               Christos Thrampoulidis},
  title     = {Provable Benefits of Overparameterization in Model Compression: From
               Double Descent to Pruning Neural Networks},
  journal   = {CoRR},
  volume    = {abs/2012.08749},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.08749},
  eprinttype = {arXiv},
  eprint    = {2012.08749},
  timestamp = {Sat, 02 Jan 2021 15:43:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-08749.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{random-pruning-vita,
  author    = {Shiwei Liu and
               Tianlong Chen and
               Xiaohan Chen and
               Li Shen and
               Decebal Constantin Mocanu and
               Zhangyang Wang and
               Mykola Pechenizkiy},
  title     = {The Unreasonable Effectiveness of Random Pruning: Return of the Most
               Naive Baseline for Sparse Training},
  journal   = {CoRR},
  volume    = {abs/2202.02643},
  year      = {2022},
  url       = {https://arxiv.org/abs/2202.02643},
  eprinttype = {arXiv},
  eprint    = {2202.02643},
  timestamp = {Tue, 05 Apr 2022 14:09:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2202-02643.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{are-wider-nets-better,
title={Are wider nets better given the same number of parameters?},
author={Anna Golubeva and Guy Gur-Ari and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021}
}

@article{mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012}
}

@article{cifar10,
title= {Learning Multiple Layers of Features from Tiny Images},
journal= {},
author= {Alex Krizhevsky},
year= {2009}
}

@inproceedings{cnnexist,
title={Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks},
author={Arthur da Cunha and Emanuele Natale and Laurent Viennot},
booktitle={International Conference on Learning Representations },
year={2022}
}

@InProceedings{convexist,
  title = 	 {Convolutional and Residual Networks Provably Contain Lottery Tickets},
  author =       {Burkholz, Rebekka},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2022},
  volume = 	 {162}
}

@inproceedings{depthexist,
title={Most Activation Functions Can Win the Lottery Without Excessive Depth},
author={Rebekka Burkholz},
booktitle={arXiv:2205.02321},
year={2022}
}

@inproceedings{sanity2,
title={Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?},
author={Xiaolong Ma and Geng Yuan and Xuan Shen and Tianlong Chen and Xuxi Chen and Xiaohan Chen and Ning Liu and Minghai Qin and Sijia Liu and Zhangyang Wang and Yanzhi Wang},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@inproceedings{elasticLTH,
title={The Elastic Lottery Ticket Hypothesis},
author={Xiaohan Chen and Yu Cheng and Shuohang Wang and Zhe Gan and Jingjing Liu and Zhangyang Wang},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@inproceedings{validateManifold,
title={Validating the Lottery Ticket Hypothesis with Inertial Manifold Theory},
author={Zeru Zhang and Jiayin Jin and Zijie Zhang and Yang Zhou and Xin Zhao and Jiaxiang Ren and Ji Liu and Lingfei Wu and Ruoming Jin and Dejing Dou},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@inproceedings{chen2021dataefficient,
title={Data-Efficient {GAN} Training Beyond (Just) Augmentations: A Lottery Ticket Perspective},
author={Tianlong Chen and Yu Cheng and Zhe Gan and Jingjing Liu and Zhangyang Wang},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@inproceedings{LTgeneralization,
title={Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Sparse Neural Networks},
author={Shuai Zhang and Meng Wang and Sijia Liu and Pin-Yu Chen and Jinjun Xiong},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}


@InProceedings{graphLTH,
  title = 	 {A Unified Lottery Ticket Hypothesis for Graph Neural Networks},
  author =       {Chen, Tianlong and Sui, Yongduo and Chen, Xuxi and Zhang, Aston and Wang, Zhangyang},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021}
}


@InProceedings{lessdatamore,
  title = 	 {Efficient Lottery Ticket Finding: Less Data is More},
  author =       {Zhang, Zhenyu and Chen, Xuxi and Chen, Tianlong and Wang, Zhangyang},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021}
}

@inproceedings{risotto,
 author = {Gadhikar, Advait and Burkholz, Rebekka},
 booktitle = {arXiv.2210.02411},
 title = {Dynamical Isometry for Residual Networks},
 year = {2022}
}

@inproceedings{ernets,
 author = {Gadhikar, Advait and Mukherjee, Sohom and Burkholz, Rebekka},
 booktitle = {arXiv.2210.02412},
 title = {How {E}rdoes and {R}enyi Win the Lottery},
 year = {2022}
}

