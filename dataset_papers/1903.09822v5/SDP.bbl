\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{Abadi}
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.~B., Mironov, I., Talwar, K.,
  and Zhang, L.
\newblock Deep learning with differential privacy.
\newblock \emph{arXiv:1607.00133}, 2016.

\bibitem[Abadi et~al.(2017)Abadi, Erlingsson, Goodfellow, McMahan, Mironov,
  Papernot, Talwar, and Zhang]{abadi2017protection}
Abadi, M., Erlingsson, U., Goodfellow, I., McMahan, H.~B., Mironov, I.,
  Papernot, N., Talwar, K., and Zhang, L.
\newblock On the protection of private information in machine learning systems:
  Two recent approches.
\newblock In \emph{2017 IEEE 30th Computer Security Foundations Symposium
  (CSF)}, pp.\  1--6. IEEE, 2017.

\bibitem[Abbasi \& Gagn{\'{e}}(2017)Abbasi and
  Gagn{\'{e}}]{DBLP:journals/corr/AbbasiG17}
Abbasi, M. and Gagn{\'{e}}, C.
\newblock Robustness to adversarial examples through an ensemble of
  specialists.
\newblock \emph{CoRR}, abs/1702.06856, 2017.
\newblock URL \url{http://arxiv.org/abs/1702.06856}.

\bibitem[Apostol(1967)]{Apostol}
Apostol, T.
\newblock \emph{Calculus}.
\newblock John Wiley \& Sons, 1967.

\bibitem[Arfken(1985)]{tagkey1985}
Arfken, G.
\newblock In \emph{Mathematical Methods for Physicists (Third Edition)}.
  Academic Press, 1985.

\bibitem[Baidu(2020)]{FedCubeBaidu}
Baidu.
\newblock Fedcube, 2020.
\newblock URL \url{http://fedcube.baidu.com/}.

\bibitem[Balle \& Wang(2018)Balle and Wang]{pmlr-v80-balle18a}
Balle, B. and Wang, Y.-X.
\newblock Improving the {G}aussian mechanism for differential privacy:
  Analytical calibration and optimal denoising.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pp.\  394--403, Stockholmsm√§ssan, Stockholm
  Sweden, 10--15 Jul 2018. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/balle18a.html}.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{7958570}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\
  39--57, May 2017.
\newblock \doi{10.1109/SP.2017.49}.

\bibitem[Chatzikokolakis et~al.(2013)Chatzikokolakis, Andr{\'e}s, Bordenabe,
  and Palamidessi]{Chatzikokolakis}
Chatzikokolakis, K., Andr{\'e}s, M.~E., Bordenabe, N.~E., and Palamidessi, C.
\newblock Broadening the scope of differential privacy using metrics.
\newblock In De~Cristofaro, E. and Wright, M. (eds.), \emph{Privacy Enhancing
  Technologies}, pp.\  82--102, 2013.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{pmlr-v70-cisse17a}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of \emph{Proceedings
  of Machine Learning Research}, pp.\  854--863, International Convention
  Centre, Sydney, Australia, 06--11 Aug 2017.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{pmlr-v97-cohen19c}
Cohen, J., Rosenfeld, E., and Kolter, Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pp.\  1310--1320, Long
  Beach, California, USA, 09--15 Jun 2019.

\bibitem[Dong et~al.(2017)Dong, Liao, Pang, Hu, and
  Zhu]{DBLP:journals/corr/abs-1710-06081}
Dong, Y., Liao, F., Pang, T., Hu, X., and Zhu, J.
\newblock Discovering adversarial examples with momentum.
\newblock \emph{CoRR}, abs/1710.06081, 2017.

\bibitem[Dwork \& Roth(2014)Dwork and Roth]{Dwork:2014:AFD:2693052.2693053}
Dwork, C. and Roth, A.
\newblock The algorithmic foundations of differential privacy.
\newblock \emph{Found. Trends Theor. Comput. Sci.}, 9\penalty0
  (3\&\#8211;4):\penalty0 211--407, August 2014.
\newblock ISSN 1551-305X.
\newblock \doi{10.1561/0400000042}.
\newblock URL \url{http://dx.doi.org/10.1561/0400000042}.

\bibitem[Dwork et~al.(2006)Dwork, McSherry, Nissim, and
  Smith]{dwork2006calibrating}
Dwork, C., McSherry, F., Nissim, K., and Smith, A.
\newblock {Calibrating noise to sensitivity in private data analysis}.
\newblock \emph{Theory of Cryptography}, pp.\  265--284, 2006.

\bibitem[Fredrikson et~al.(2015)Fredrikson, Jha, and
  Ristenpart]{Fredrikson:2015:MIA}
Fredrikson, M., Jha, S., and Ristenpart, T.
\newblock Model inversion attacks that exploit confidence information and basic
  countermeasures.
\newblock In \emph{Proceedings of the 22Nd ACM SIGSAC Conference on Computer
  and Communications Security}, CCS '15, pp.\  1322--1333, 2015.
\newblock \doi{10.1145/2810103.2813677}.

\bibitem[Gao et~al.(2017)Gao, Wang, and Qi]{DBLP:journals/corr/GaoWQ17}
Gao, J., Wang, B., and Qi, Y.
\newblock Deepmask: Masking {DNN} models for robustness against adversarial
  samples.
\newblock \emph{CoRR}, abs/1702.06763, 2017.
\newblock URL \url{http://arxiv.org/abs/1702.06763}.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{DBLP:journals/corr/GoodfellowSS14}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{CoRR}, abs/1412.6572, 2014.

\bibitem[Goyal et~al.(2017)Goyal, Doll{\'{a}}r, Girshick, Noordhuis,
  Wesolowski, Kyrola, Tulloch, Jia, and He]{DBLP:journals/corr/GoyalDGNWKTJH17}
Goyal, P., Doll{\'{a}}r, P., Girshick, R.~B., Noordhuis, P., Wesolowski, L.,
  Kyrola, A., Tulloch, A., Jia, Y., and He, K.
\newblock Accurate, large minibatch {SGD:} training imagenet in 1 hour.
\newblock \emph{CoRR}, abs/1706.02677, 2017.

\bibitem[Grosse et~al.(2017)Grosse, Manoharan, Papernot, Backes, and
  McDaniel]{DBLP:journals/corr/GrosseMP0M17}
Grosse, K., Manoharan, P., Papernot, N., Backes, M., and McDaniel, P.~D.
\newblock On the (statistical) detection of adversarial examples.
\newblock \emph{CoRR}, abs/1702.06280, 2017.
\newblock URL \url{http://arxiv.org/abs/1702.06280}.

\bibitem[Gu \& Rigazio(2014)Gu and Rigazio]{DBLP:journals/corr/GuR14}
Gu, S. and Rigazio, L.
\newblock Towards deep neural network architectures robust to adversarial
  examples.
\newblock \emph{CoRR}, abs/1412.5068, 2014.
\newblock URL \url{http://arxiv.org/abs/1412.5068}.

\bibitem[Gu et~al.(2017)Gu, Dolan{-}Gavitt, and
  Garg]{DBLP:journals/corr/abs-1708-06733}
Gu, T., Dolan{-}Gavitt, B., and Garg, S.
\newblock Badnets: Identifying vulnerabilities in the machine learning model
  supply chain.
\newblock \emph{CoRR}, abs/1708.06733, 2017.
\newblock URL \url{http://arxiv.org/abs/1708.06733}.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2018benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HJz6tiCqYm}.

\bibitem[Hosseini et~al.(2017)Hosseini, Chen, Kannan, Zhang, and
  Poovendran]{hosseini2017blocking}
Hosseini, H., Chen, Y., Kannan, S., Zhang, B., and Poovendran, R.
\newblock Blocking transferability of adversarial examples in black-box
  learning systems.
\newblock \emph{arXiv preprint arXiv:1703.04318}, 2017.

\bibitem[Kardan \& Stanley(2017)Kardan and Stanley]{7965897}
Kardan, N. and Stanley, K.~O.
\newblock Mitigating fooling with competitive overcomplete output layer neural
  networks.
\newblock In \emph{2017 International Joint Conference on Neural Networks
  (IJCNN)}, pp.\  518--525, 2017.

\bibitem[Kolter \& Wong(2017)Kolter and
  Wong]{DBLP:journals/corr/abs-1711-00851}
Kolter, J.~Z. and Wong, E.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock \emph{CoRR}, abs/1711.00851, 2017.
\newblock URL \url{http://arxiv.org/abs/1711.00851}.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kurakin et~al.(2016{\natexlab{a}})Kurakin, Goodfellow, and
  Bengio]{DBLP:journals/corr/KurakinGB16}
Kurakin, A., Goodfellow, I.~J., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock \emph{CoRR}, abs/1607.02533, 2016{\natexlab{a}}.

\bibitem[Kurakin et~al.(2016{\natexlab{b}})Kurakin, Goodfellow, and
  Bengio]{DBLP:journals/corr/KurakinGB16a}
Kurakin, A., Goodfellow, I.~J., and Bengio, S.
\newblock Adversarial machine learning at scale.
\newblock \emph{CoRR}, abs/1611.01236, 2016{\natexlab{b}}.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{Lecun726791}
Lecun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.
\newblock \doi{10.1109/5.726791}.

\bibitem[Lecuyer et~al.(2018)Lecuyer, Atlidakis, Geambasu, Hsu, and
  Jana]{Lecuyer2018}
Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., and Jana, S.
\newblock Certified robustness to adversarial examples with differential
  privacy.
\newblock In \emph{arXiv:1802.03471}, 2018.
\newblock URL \url{https://arxiv.org/abs/1802.03471}.

\bibitem[Lee \& Kifer(2018)Lee and Kifer]{Lee:2018:CDP:3219819.3220076}
Lee, J. and Kifer, D.
\newblock Concentrated differentially private gradient descent with adaptive
  per-iteration privacy budget.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  1656--1665, 2018.

\bibitem[Li et~al.(2018)Li, Chen, Wang, and
  Carin]{DBLP:journals/corr/abs-1809-03113}
Li, B., Chen, C., Wang, W., and Carin, L.
\newblock Second-order adversarial attack and certifiable robustness.
\newblock \emph{CoRR}, abs/1809.03113, 2018.
\newblock URL \url{http://arxiv.org/abs/1809.03113}.

\bibitem[Liu et~al.(2018)Liu, Ma, Aafer, Lee, Zhai, Wang, and Zhang]{Trojannn}
Liu, Y., Ma, S., Aafer, Y., Lee, W.-C., Zhai, J., Wang, W., and Zhang, X.
\newblock Trojaning attack on neural networks.
\newblock In \emph{25nd Annual Network and Distributed System Security
  Symposium, {NDSS} 2018, San Diego, California, USA, February 18-221, 2018}.
  The Internet Society, 2018.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Matyasko \& Chau(2017)Matyasko and Chau]{7965869}
Matyasko, A. and Chau, L.~P.
\newblock Margin maximization for robust classification using deep learning.
\newblock In \emph{2017 International Joint Conference on Neural Networks
  (IJCNN)}, pp.\  300--307, 2017.

\bibitem[McMahan et~al.(2016)McMahan, Moore, Ramage, and
  y~Arcas]{DBLP:journals/corr/McMahanMRA16}
McMahan, H.~B., Moore, E., Ramage, D., and y~Arcas, B.~A.
\newblock Federated learning of deep networks using model averaging.
\newblock \emph{CoRR}, abs/1602.05629, 2016.

\bibitem[Metzen et~al.(2017)Metzen, Genewein, Fischer, and
  Bischoff]{metzen2017detecting}
Metzen, J.~H., Genewein, T., Fischer, V., and Bischoff, B.
\newblock On detecting adversarial perturbations.
\newblock In \emph{Proceedings of 5th International Conference on Learning
  Representations (ICLR)}, 2017.
\newblock URL \url{https://arxiv.org/abs/1702.04267}.

\bibitem[Pang et~al.(2020)Pang, Shen, Zhang, Ji, Vorobeychik, Luo, Liu, and
  Wang]{pang2020tale}
Pang, R., Shen, H., Zhang, X., Ji, S., Vorobeychik, Y., Luo, X., Liu, A., and
  Wang, T.
\newblock A tale of evil twins: Adversarial inputs versus poisoned models.
\newblock In \emph{Proceedings of ACM SAC Conference on Computer and
  Communications (CCS)}, 2020.

\bibitem[Papernot \& McDaniel(2017)Papernot and
  McDaniel]{papernot2017extending}
Papernot, N. and McDaniel, P.
\newblock Extending defensive distillation.
\newblock \emph{arXiv preprint arXiv:1705.05264}, 2017.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{7467366}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{2016 IEEE European Symposium on Security and Privacy}, pp.\
  372--387, March 2016{\natexlab{a}}.
\newblock \doi{10.1109/EuroSP.2016.36}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Wu, Jha, and
  Swami]{7546524}
Papernot, N., McDaniel, P., Wu, X., Jha, S., and Swami, A.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{2016 IEEE Symposium on Security and Privacy (SP)}, pp.\
  582--597, May 2016{\natexlab{b}}.
\newblock \doi{10.1109/SP.2016.41}.

\bibitem[Papernot et~al.(2018)Papernot, Song, Mironov, Raghunathan, Talwar, and
  Erlingsson]{papernot2018scalable}
Papernot, N., Song, S., Mironov, I., Raghunathan, A., Talwar, K., and
  Erlingsson, {\'U}.
\newblock Scalable private learning with pate.
\newblock \emph{arXiv preprint arXiv:1802.08908}, 2018.

\bibitem[Phan et~al.(2016)Phan, Wang, Wu, and Dou]{Phan0WD16}
Phan, N., Wang, Y., Wu, X., and Dou, D.
\newblock Differential privacy preservation for deep auto-encoders: an
  application of human behavior prediction.
\newblock In \emph{AAAI'16}, pp.\  1309--1316, 2016.

\bibitem[Phan et~al.(2017{\natexlab{a}})Phan, Wu, and Dou]{PhanMLJ2017}
Phan, N., Wu, X., and Dou, D.
\newblock Preserving differential privacy in convolutional deep belief
  networks.
\newblock \emph{Machine Learning}, 2017{\natexlab{a}}.
\newblock \doi{10.1007/s10994-017-5656-2}.

\bibitem[Phan et~al.(2017{\natexlab{b}})Phan, Wu, Hu, and Dou]{NHPhanICDM17}
Phan, N., Wu, X., Hu, H., and Dou, D.
\newblock Adaptive laplace mechanism: Differential privacy preservation in deep
  learning.
\newblock In \emph{IEEE ICDM'17}, 2017{\natexlab{b}}.

\bibitem[Phan et~al.(2019)Phan, Vu, Liu, Jin, Dou, Wu, and Thai]{PhanIJCAI}
Phan, N., Vu, M.~N., Liu, Y., Jin, R., Dou, D., Wu, X., and Thai, M.~T.
\newblock Heterogeneous gaussian mechanism: Preserving differential privacy in
  deep learning with provable robustness.
\newblock In \emph{Proceedings of the 28th International Joint Conference on
  Artificial Intelligence (IJCAI'19)}, pp.\  4753--4759, 10--16 August 2019.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{DBLP:journals/corr/abs-1801-09344}
Raghunathan, A., Steinhardt, J., and Liang, P.
\newblock Certified defenses against adversarial examples.
\newblock \emph{CoRR}, abs/1801.09344, 2018.
\newblock URL \url{http://arxiv.org/abs/1801.09344}.

\bibitem[Rudin(1976)]{WalterRudin}
Rudin, W.
\newblock \emph{Principles of Mathematical Analysis}.
\newblock McGraw-Hill, 1976.

\bibitem[Salman et~al.(2019)Salman, Yang, Li, Zhang, Zhang, Razenshteyn, and
  Bubeck]{DBLP:journals/corr/abs-1906-04584}
Salman, H., Yang, G., Li, J., Zhang, P., Zhang, H., Razenshteyn, I.~P., and
  Bubeck, S.
\newblock Provably robust deep learning via adversarially trained smoothed
  classifiers.
\newblock \emph{CoRR}, abs/1906.04584, 2019.

\bibitem[Shafahi et~al.(2018)Shafahi, Huang, Najibi, Suciu, Studer, Dumitras,
  and Goldstein]{NIPS2018_7849}
Shafahi, A., Huang, W.~R., Najibi, M., Suciu, O., Studer, C., Dumitras, T., and
  Goldstein, T.
\newblock Poison frogs! targeted clean-label poisoning attacks on neural
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  6103--6113. 2018.

\bibitem[Shokri \& Shmatikov(2015)Shokri and Shmatikov]{ShokriVitaly2015}
Shokri, R. and Shmatikov, V.
\newblock Privacy-preserving deep learning.
\newblock In \emph{CCS'15}, pp.\  1310--1321, 2015.

\bibitem[{Song} et~al.(2019){Song}, {Shokri}, and
  {Mittal}]{2019arXiv190510291S}
{Song}, L., {Shokri}, R., and {Mittal}, P.
\newblock {Privacy Risks of Securing Machine Learning Models against
  Adversarial Examples}.
\newblock \emph{arXiv e-prints}, art. arXiv:1905.10291, May 2019.

\bibitem[TensorFlow()]{TensorFlowSoftMax}
TensorFlow.
\newblock URL
  \url{https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/nn_impl.py}.

\bibitem[\text{Operator norm}(2018)]{WikipediaOperatornorm}
\text{Operator norm}.
\newblock Operator norm, 2018.
\newblock URL \url{https://en.wikipedia.org/wiki/Operator\_norm}.

\bibitem[TinyImageNet()]{Imagenet}
TinyImageNet.
\newblock URL \url{https://tiny-imagenet.herokuapp.com}.

\bibitem[Tram{\`e}r et~al.(2017)Tram{\`e}r, Kurakin, Papernot, Boneh, and
  McDaniel]{tramer2017ensemble}
Tram{\`e}r, F., Kurakin, A., Papernot, N., Boneh, D., and McDaniel, P.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock \emph{arXiv preprint arXiv:1705.07204}, 2017.

\bibitem[Wang et~al.(2016)Wang, Guo, Zhang, II, Xing, Giles, and
  Liu]{DBLP:journals/corr/WangGZOXGL16}
Wang, Q., Guo, W., Zhang, K., II, A. G.~O., Xing, X., Giles, C.~L., and Liu, X.
\newblock Learning adversary-resistant deep neural networks.
\newblock \emph{CoRR}, abs/1612.01401, 2016.

\bibitem[Wu et~al.(2019)Wu, Zhao, Sun, Zhang, Su, Zeng, and
  Liu]{DBLP:journals/corr/abs-1905-12883}
Wu, B., Zhao, S., Sun, G., Zhang, X., Su, Z., Zeng, C., and Liu, Z.
\newblock {P3SGD:} patient privacy preserving {SGD} for regularizing deep cnns
  in pathological image classification.
\newblock In \emph{CVPR}, 2019.

\bibitem[Xie et~al.(2019)Xie, Wu, van~der Maaten, Yuille, and
  He]{Xie_2019_CVPR}
Xie, C., Wu, Y., van~der Maaten, L., Yuille, A.~L., and He, K.
\newblock Feature denoising for improving adversarial robustness.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2019.

\bibitem[Xu et~al.(2017)Xu, Evans, and Qi]{DBLP:journals/corr/XuEQ17}
Xu, W., Evans, D., and Qi, Y.
\newblock Feature squeezing: Detecting adversarial examples in deep neural
  networks.
\newblock \emph{CoRR}, abs/1704.01155, 2017.
\newblock URL \url{http://arxiv.org/abs/1704.01155}.

\bibitem[Xu et~al.(2020)Xu, Shi, Liu, Zhao, and Chen]{ADADP}
Xu, Z., Shi, S., Liu, X.~A., Zhao, J., and Chen, L.
\newblock An adaptive and fast convergent approach to differentially private
  deep learning.
\newblock In \emph{INFOCOM}, 2020.

\bibitem[Yu et~al.(2019)Yu, Liu, Pu, Gursoy, and Truex]{Yu2019}
Yu, L., Liu, L., Pu, C., Gursoy, M., and Truex, S.
\newblock Differentially private model publishing for deep learning.
\newblock In \emph{2019 IEEE Symposium on Security and Privacy (SP)}, pp.\
  326--343, 2019.

\bibitem[Zhang et~al.(2012)Zhang, Zhang, Xiao, Yang, and
  Winslett]{zhang2012functional}
Zhang, J., Zhang, Z., Xiao, X., Yang, Y., and Winslett, M.
\newblock Functional mechanism: regression analysis under differential privacy.
\newblock \emph{PVLDB}, 5\penalty0 (11):\penalty0 1364--1375, 2012.

\end{thebibliography}
