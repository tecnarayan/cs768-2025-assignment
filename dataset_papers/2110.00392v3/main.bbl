\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Zharmagambetov and Carreira-Perpinan(2020)]{zharmagambetov2020smaller}
Arman Zharmagambetov and Miguel Carreira-Perpinan.
\newblock Smaller, more accurate regression forests using tree alternating
  optimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  11398--11408. PMLR, 2020.

\bibitem[Kumar et~al.(2017)Kumar, Goyal, and Varma]{kumar2017resource}
Ashish Kumar, Saurabh Goyal, and Manik Varma.
\newblock Resource-efficient machine learning in 2 kb ram for the internet of
  things.
\newblock In \emph{International Conference on Machine Learning}, pages
  1935--1944. PMLR, 2017.

\bibitem[Zhu et~al.(2020{\natexlab{a}})Zhu, Farivar, and Shoaran]{zhu2020resot}
Bingzhao Zhu, Masoud Farivar, and Mahsa Shoaran.
\newblock Resot: Resource-efficient oblique trees for neural signal
  classification.
\newblock \emph{IEEE Transactions on Biomedical Circuits and Systems},
  14\penalty0 (4):\penalty0 692--704, 2020{\natexlab{a}}.

\bibitem[Shoaran et~al.(2018)Shoaran, Haghi, Taghavi, Farivar, and
  Emami-Neyestanak]{shoaran2018energy}
Mahsa Shoaran, Benyamin~Allahgholizadeh Haghi, Milad Taghavi, Masoud Farivar,
  and Azita Emami-Neyestanak.
\newblock Energy-efficient classification for resource-constrained biomedical
  applications.
\newblock \emph{IEEE Journal on Emerging and Selected Topics in Circuits and
  Systems}, 8\penalty0 (4):\penalty0 693--707, 2018.

\bibitem[Tanno et~al.(2019)Tanno, Arulkumaran, Alexander, Criminisi, and
  Nori]{tanno2019adaptive}
Ryutaro Tanno, Kai Arulkumaran, Daniel Alexander, Antonio Criminisi, and Aditya
  Nori.
\newblock Adaptive neural trees.
\newblock In \emph{International Conference on Machine Learning}, pages
  6166--6175. PMLR, 2019.

\bibitem[Carreira-Perpin{\'a}n and Tavallali(2018)]{carreira2018alternating}
Miguel~A Carreira-Perpin{\'a}n and Pooya Tavallali.
\newblock Alternating optimization of decision trees, with application to
  learning sparse oblique trees.
\newblock \emph{Advances in Neural Information Processing Systems},
  31:\penalty0 1211--1221, 2018.

\bibitem[Mathy et~al.(2015)Mathy, Derbinsky, Bento, Rosenthal, and
  Yedidia]{mathy2015boundary}
Charles Mathy, Nate Derbinsky, Jos{\'e} Bento, Jonathan Rosenthal, and Jonathan
  Yedidia.
\newblock The boundary forest algorithm for online supervised and unsupervised
  learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~29, 2015.

\bibitem[Zhu et~al.(2021)Zhu, Shin, and Shoaran]{zhu2021closed}
Bingzhao Zhu, Uisub Shin, and Mahsa Shoaran.
\newblock Closed-loop neural prostheses with on-chip intelligence: A review and
  a low-latency machine learning model for brain state detection.
\newblock \emph{IEEE Transactions on Biomedical Circuits and Systems}, 2021.

\bibitem[Silva et~al.(2020)Silva, Gombolay, Killian, Jimenez, and
  Son]{silva2020optimization}
Andrew Silva, Matthew Gombolay, Taylor Killian, Ivan Jimenez, and Sung-Hyun
  Son.
\newblock Optimization methods for interpretable differentiable decision trees
  applied to reinforcement learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1855--1865. PMLR, 2020.

\bibitem[Lundberg and Lee(2017)]{lundberg2017unified}
Scott Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock \emph{arXiv preprint arXiv:1705.07874}, 2017.

\bibitem[Lin et~al.(2013)Lin, Chen, and Yan]{lin2013network}
Min Lin, Qiang Chen, and Shuicheng Yan.
\newblock Network in network.
\newblock \emph{arXiv preprint arXiv:1312.4400}, 2013.

\bibitem[Norouzi et~al.(2015)Norouzi, Collins, Johnson, Fleet, and
  Kohli]{norouzi2015efficient}
Mohammad Norouzi, Maxwell~D Collins, Matthew Johnson, David~J Fleet, and
  Pushmeet Kohli.
\newblock Efficient non-greedy optimization of decision trees.
\newblock \emph{arXiv preprint arXiv:1511.04056}, 2015.

\bibitem[Kontschieder et~al.(2015)Kontschieder, Fiterau, Criminisi, and
  Bulo]{kontschieder2015deep}
Peter Kontschieder, Madalina Fiterau, Antonio Criminisi, and Samuel~Rota Bulo.
\newblock Deep neural decision forests.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 1467--1475, 2015.

\bibitem[Hazimeh et~al.(2020)Hazimeh, Ponomareva, Mol, Tan, and
  Mazumder]{hazimeh2020tree}
Hussein Hazimeh, Natalia Ponomareva, Petros Mol, Zhenyu Tan, and Rahul
  Mazumder.
\newblock The tree ensemble layer: Differentiability meets conditional
  computation.
\newblock In \emph{International Conference on Machine Learning}, pages
  4138--4148. PMLR, 2020.

\bibitem[Steinberg and Colla(2009)]{steinberg2009cart}
Dan Steinberg and Phillip Colla.
\newblock Cart: classification and regression trees.
\newblock \emph{The top ten algorithms in data mining}, 9:\penalty0 179, 2009.

\bibitem[Oliver(1992)]{oliver1992decision}
Jonathan Oliver.
\newblock \emph{Decision graphs: an extension of decision trees}.
\newblock Citeseer, 1992.

\bibitem[Sudo et~al.(2018)Sudo, Nuida, and Shimizu]{sudo2018efficient}
Hiroki Sudo, Koji Nuida, and Kana Shimizu.
\newblock An efficient private evaluation of a decision graph.
\newblock In \emph{International Conference on Information Security and
  Cryptology}, pages 143--160. Springer, 2018.

\bibitem[Zighed(2007)]{Zighed2007}
Djamel~Abdelkader Zighed.
\newblock \emph{Induction Graphs for Data Mining}, pages 419--430.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2007.

\bibitem[Benbouzid et~al.(2012)Benbouzid, Busa-Fekete, and
  K{\'e}gl]{benbouzid2012fast}
Djalel Benbouzid, R{\'o}bert Busa-Fekete, and Bal{\'a}zs K{\'e}gl.
\newblock Fast classification using sparse decision dags.
\newblock \emph{arXiv preprint arXiv:1206.6387}, 2012.

\bibitem[Platt et~al.(1999)Platt, Cristianini, Shawe-Taylor,
  et~al.]{platt1999large}
John~C Platt, Nello Cristianini, John Shawe-Taylor, et~al.
\newblock Large margin dags for multiclass classification.
\newblock In \emph{nips}, volume~12, pages 547--553, 1999.

\bibitem[Shotton et~al.(2013)Shotton, Sharp, Kohli, Nowozin, Winn, and
  Criminisi]{shotton2013decision}
Jamie Shotton, Toby Sharp, Pushmeet Kohli, Sebastian Nowozin, John Winn, and
  Antonio Criminisi.
\newblock Decision jungles: Compact and rich models for classification.
\newblock In \emph{NIPS'13 Proceedings of the 26th International Conference on
  Neural Information Processing Systems}, pages 234--242, 2013.

\bibitem[Lin et~al.(2020)Lin, Zhong, Hu, Rudin, and
  Seltzer]{lin2020generalized}
Jimmy Lin, Chudi Zhong, Diane Hu, Cynthia Rudin, and Margo Seltzer.
\newblock Generalized and scalable optimal sparse decision trees.
\newblock In \emph{International Conference on Machine Learning}, pages
  6150--6160. PMLR, 2020.

\bibitem[Zhu et~al.(2020{\natexlab{b}})Zhu, Murali, Phan, Nguyen, and
  Kalagnanam]{zhu2020scalable}
Haoran Zhu, Pavankumar Murali, Dzung~T Phan, Lam~M Nguyen, and Jayant~R
  Kalagnanam.
\newblock A scalable mip-based method for learning optimal multivariate
  decision trees.
\newblock \emph{arXiv preprint arXiv:2011.03375}, 2020{\natexlab{b}}.

\bibitem[Hu et~al.(2019)Hu, Rudin, and Seltzer]{hu2019optimal}
Xiyang Hu, Cynthia Rudin, and Margo Seltzer.
\newblock Optimal sparse decision trees.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2019.

\bibitem[Laurent and Rivest(1976)]{laurent1976constructing}
Hyafil Laurent and Ronald~L Rivest.
\newblock Constructing optimal binary decision trees is np-complete.
\newblock \emph{Information processing letters}, 5\penalty0 (1):\penalty0
  15--17, 1976.

\bibitem[Bradford et~al.(1998)Bradford, Kunz, Kohavi, Brunk, and
  Brodley]{bradford1998pruning}
Jeffrey~P Bradford, Clayton Kunz, Ron Kohavi, Cliff Brunk, and Carla~E Brodley.
\newblock Pruning decision trees with misclassification costs.
\newblock In \emph{European Conference on Machine Learning}, pages 131--136.
  Springer, 1998.

\bibitem[Kiran and Serra(2017)]{kiran2017cost}
B~Ravi Kiran and Jean Serra.
\newblock Cost-complexity pruning of random forests.
\newblock In \emph{International Symposium on Mathematical Morphology and Its
  Applications to Signal and Image Processing}, pages 222--232. Springer, 2017.

\bibitem[Shi(2007)]{shi2007best}
Haijian Shi.
\newblock \emph{Best-first decision tree learning}.
\newblock PhD thesis, The University of Waikato, 2007.

\bibitem[Zharmagambetov et~al.(2019)Zharmagambetov, Hada,
  Carreira-Perpi{\~n}{\'a}n, and Gabidolla]{zharmagambetov2019experimental}
Arman Zharmagambetov, Suryabhan~Singh Hada, Miguel~{\'A}
  Carreira-Perpi{\~n}{\'a}n, and Magzhan Gabidolla.
\newblock An experimental comparison of old and new decision tree algorithms.
\newblock \emph{arXiv preprint arXiv:1911.03054}, 2019.

\bibitem[UC()]{UC}
Uc irvine machine learning repository.
\newblock \url{http://archive.ics.uci.edu/ml/index.php}.
\newblock Accessed: 2021-05-02.

\bibitem[LIB()]{LIBSVM}
Libsvm data.
\newblock
  \url{https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html}.
\newblock Accessed: 2021-05-02.

\bibitem[Breiman(2001)]{breiman2001random}
Leo Breiman.
\newblock Random forests.
\newblock \emph{Machine learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Breiman(1996)]{breiman1996bagging}
Leo Breiman.
\newblock Bagging predictors.
\newblock \emph{Machine learning}, 24\penalty0 (2):\penalty0 123--140, 1996.

\bibitem[Freund and Schapire(1997)]{freund1997decision}
Yoav Freund and Robert~E Schapire.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock \emph{Journal of computer and system sciences}, 55\penalty0
  (1):\penalty0 119--139, 1997.

\bibitem[Chen and Guestrin(2016)]{chen2016xgboost}
Tianqi Chen and Carlos Guestrin.
\newblock Xgboost: A scalable tree boosting system.
\newblock In \emph{Proceedings of the 22nd acm sigkdd international conference
  on knowledge discovery and data mining}, pages 785--794, 2016.

\bibitem[Ke et~al.(2017)Ke, Meng, Finley, Wang, Chen, Ma, Ye, and
  Liu]{ke2017lightgbm}
Guolin Ke, Qi~Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei
  Ye, and Tie-Yan Liu.
\newblock Lightgbm: A highly efficient gradient boosting decision tree.
\newblock \emph{Advances in neural information processing systems},
  30:\penalty0 3146--3154, 2017.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\end{thebibliography}
