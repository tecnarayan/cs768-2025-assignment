\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bach et~al.(2017)Bach, Broecheler, Huang, and Getoor]{hlmrf17}
S.~H. Bach, M.~Broecheler, B.~Huang, and L.~Getoor.
\newblock Hinge-loss markov random fields and probabilistic soft logic.
\newblock \emph{Journal of Machine Learning Research}, pages 1--67, 2017.

\bibitem[Bertsekas(1999)]{bertsekas99}
D.~P. Bertsekas.
\newblock \emph{Nonlinear Programming, 2nd ed}.
\newblock Athena Scientific, Belmont, MA, 1999.

\bibitem[Bhandari and Russo(2024)]{bhandari2019global}
J.~Bhandari and D.~Russo.
\newblock Global optimality guarantees for policy gradient methods.
\newblock \emph{Operations Research}, 2024.

\bibitem[Bharadhwaj et~al.(2021)Bharadhwaj, Kumar, Rhinehart, Levine, Shkurti,
  and Garg]{sesh20}
H.~Bharadhwaj, A.~Kumar, N.~Rhinehart, S.~Levine, F.~Shkurti, and A.~Garg.
\newblock Conservative safety critics for exploration.
\newblock In \emph{Proc. of International Conference on Learning
  Representations}, 2021.

\bibitem[Boob et~al.(2022)Boob, Deng, and Lan]{gudi19}
D.~Boob, Q.~Deng, and G.~Lan.
\newblock Stochastic first-order methods for convex and nonconvex functional
  constrained optimization.
\newblock \emph{Mathematical Programming}, 2022.

\bibitem[Boyd and Vandenberghe(2004)]{boyd2004convex}
S.~Boyd and L.~Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Cartis et~al.(2011)Cartis, Gould, and Toint]{cartis2011evaluation}
C.~Cartis, N.~I. Gould, and P.~L. Toint.
\newblock On the evaluation complexity of composite function minimization with
  applications to nonconvex nonlinear programming.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (4):\penalty0
  1721--1739, 2011.

\bibitem[Crammer and Singer(2002)]{crammer2002learnability}
K.~Crammer and Y.~Singer.
\newblock On the learnability and design of output codes for multiclass
  problems.
\newblock \emph{Machine Learning}, 47\penalty0 (2):\penalty0 201--233, 2002.

\bibitem[Ding et~al.(2020)Ding, Zhang, Basar, and Jovanovic]{kaiqing20}
D.~Ding, K.~Zhang, T.~Basar, and M.~Jovanovic.
\newblock Natural policy gradient primal-dual method for constrained markov
  decision processes.
\newblock In \emph{Proc. of Advances in Neural Information Processing Systems},
  pages 8378--8390, 2020.

\bibitem[Fischer et~al.(2019)Fischer, Balunovic, Drachsler-Cohen, Gehr, Zhang,
  and Vechev]{fischer19a}
M.~Fischer, M.~Balunovic, D.~Drachsler-Cohen, T.~Gehr, C.~Zhang, and M.~Vechev.
\newblock {DL}2: Training and querying neural networks with logic.
\newblock In \emph{Proc. of International Conference on Machine Learning},
  pages 1931--1941, 2019.

\bibitem[Hajinezhad and Hong(2019)]{hajinezhad2019perturbed}
D.~Hajinezhad and M.~Hong.
\newblock Perturbed proximal primal--dual algorithm for nonconvex nonsmooth
  optimization.
\newblock \emph{Mathematical Programming}, 176\penalty0 (1):\penalty0 207--245,
  2019.

\bibitem[Hong et~al.(2016)Hong, Luo, and Razaviyayn]{hong2016convergence}
M.~Hong, Z.-Q. Luo, and M.~Razaviyayn.
\newblock Convergence analysis of alternating direction method of multipliers
  for a family of nonconvex problems.
\newblock \emph{SIAM Journal on Optimization}, 26\penalty0 (1):\penalty0
  337--364, 2016.

\bibitem[Kong et~al.(2019)Kong, Melo, and Monteiro]{kong2019complexity}
W.~Kong, J.~G. Melo, and R.~D. Monteiro.
\newblock Complexity of a quadratic penalty accelerated inexact proximal point
  method for solving linearly constrained nonconvex composite programs.
\newblock \emph{SIAM Journal on Optimization}, 29\penalty0 (4):\penalty0
  2566--2593, 2019.

\bibitem[Koshal et~al.(2011)Koshal, Nedi{\'c}, and
  Shanbhag]{koshal2011multiuser}
J.~Koshal, A.~Nedi{\'c}, and U.~V. Shanbhag.
\newblock Multiuser optimization: Distributed algorithms and error analysis.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (3):\penalty0
  1046--1081, 2011.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Li et~al.(2021)Li, Chen, Liu, Lu, and Xu]{li21d}
Z.~Li, P.-Y. Chen, S.~Liu, S.~Lu, and Y.~Xu.
\newblock Rate-improved inexact augmented lagrangian method for constrained
  nonconvex optimization.
\newblock In \emph{Proc. of International Conference on Artificial Intelligence
  and Statistics}, pages 2170--2178, 13--15 Apr. 2021.

\bibitem[Lin et~al.(2022)Lin, Ma, and Xu]{lin2019inexact}
Q.~Lin, R.~Ma, and Y.~Xu.
\newblock Complexity of an inexact proximal-point penalty method for
  constrained smooth non-convex optimization.
\newblock \emph{Computational Optimization and Applications}, pages 175--224,
  2022.

\bibitem[Lin et~al.(2020)Lin, Jin, and Jordan]{lin2020gradient}
T.~Lin, C.~Jin, and M.~Jordan.
\newblock On gradient descent ascent for nonconvex-concave minimax problems.
\newblock In \emph{Proc. of International Conference on Machine Learning},
  pages 6083--6093, 2020.

\bibitem[Lu(2022)]{lu2022single}
S.~Lu.
\newblock A single-loop gradient descent and perturbed ascent algorithm for
  nonconvex functional constrained optimization.
\newblock In \emph{Proc. of International Conference on Machine Learning},
  pages 14315--14357, 2022.

\bibitem[Lu et~al.(2020)Lu, Razaviyayn, Yang, Huang, and Hong]{lu2020finding}
S.~Lu, M.~Razaviyayn, B.~Yang, K.~Huang, and M.~Hong.
\newblock Finding second-order stationary points efficiently in smooth
  nonconvex linearly constrained optimization problems.
\newblock In \emph{Proc. of Advances in Neural Information Processing Systems},
  2020.

\bibitem[{Lu} et~al.(2020){Lu}, {Tsaknakis}, {Hong}, and {Chen}]{hibsa}
S.~{Lu}, I.~{Tsaknakis}, M.~{Hong}, and Y.~{Chen}.
\newblock Hybrid block successive approximation for one-sided non-convex
  min-max problems: Algorithms and applications.
\newblock \emph{IEEE Transactions on Signal Processing}, 68:\penalty0
  3676--3691, 2020.

\bibitem[Ma et~al.(2020)Ma, Lin, and Yang]{ma20d}
R.~Ma, Q.~Lin, and T.~Yang.
\newblock Quadratically regularized subgradient methods for weakly convex
  optimization with weakly convex constraints.
\newblock In \emph{Proc. of International Conference on Machine Learning},
  pages 6554--6564, 13--18 Jul. 2020.

\bibitem[Melo et~al.(2020)Melo, Monteiro, and Wang]{melo2020iteration}
J.~G. Melo, R.~D. Monteiro, and H.~Wang.
\newblock Iteration-complexity of an inexact proximal accelerated augmented
  lagrangian method for solving linearly constrained smooth nonconvex composite
  optimization problems.
\newblock \emph{arXiv preprint arXiv:2006.08048}, 2020.

\bibitem[Nocedal and Wright(2006)]{nocedal2006numerical}
J.~Nocedal and S.~Wright.
\newblock \emph{Numerical optimization}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[Pang and Scutari(2011)]{pang2011nonconvex}
J.-S. Pang and G.~Scutari.
\newblock Nonconvex games with side constraints.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (4):\penalty0
  1491--1522, 2011.

\bibitem[Sahin et~al.(2019)Sahin, Eftekhari, Alacaoglu, Latorre, and
  Cevher]{sahin2019inexact}
M.~F. Sahin, A.~Eftekhari, A.~Alacaoglu, F.~Latorre, and V.~Cevher.
\newblock An inexact augmented lagrangian framework for nonconvex optimization
  with nonlinear constraints.
\newblock In \emph{Proc. of Advances in Neural Information Processing Systems},
  pages 13965--13977, 2019.

\bibitem[{Shi} and {Hong}(2020)]{pdd}
Q.~{Shi} and M.~{Hong}.
\newblock Penalty dual decomposition method for nonsmooth nonconvex
  optimization-part i: Algorithms and convergence analysis.
\newblock \emph{IEEE Transactions on Signal Processing}, 68:\penalty0
  4108--4122, 2020.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Weston and Watkins(1998)]{weston1998multi}
J.~Weston and C.~Watkins.
\newblock Multi-class support vector machines.
\newblock Technical report, Citeseer, 1998.

\bibitem[Xie and Wright(2021)]{xie2021complexity}
Y.~Xie and S.~J. Wright.
\newblock Complexity of proximal augmented lagrangian for nonconvex
  optimization with nonlinear equality constraints.
\newblock \emph{Journal of Scientific Computing}, 86\penalty0 (3):\penalty0
  1--30, 2021.

\bibitem[Xu(2019)]{xu2019iteration}
Y.~Xu.
\newblock Iteration complexity of inexact augmented lagrangian methods for
  constrained convex programming.
\newblock \emph{Mathematical Programming}, pages 1--46, 2019.

\bibitem[Yang et~al.(2019)Yang, Zhu, and Liu]{yang2019ecc}
H.~Yang, Y.~Zhu, and J.~Liu.
\newblock Ecc: Platform-independent energy-constrained deep neural network
  compression via a bilinear regression model.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11206--11215, 2019.

\bibitem[Yu et~al.(2019)Yu, Yang, Kolar, and Wang]{yuya19}
M.~Yu, Z.~Yang, M.~Kolar, and Z.~Wang.
\newblock Convergent policy optimization for safe reinforcement learning.
\newblock In \emph{Proc. of Advances in Neural Information Processing Systems},
  2019.

\bibitem[Zeng et~al.(2022)Zeng, Yin, and Zhou]{wotao21}
J.~Zeng, W.~Yin, and D.-X. Zhou.
\newblock Moreau envelope augmented lagrangian method for nonconvex
  optimization with linear constraints.
\newblock \emph{Journal of Scientific Computing}, 2022.

\bibitem[Zhang and Luo(2020)]{zhang2020proximal}
J.~Zhang and Z.-Q. Luo.
\newblock A proximal alternating direction method of multiplier for linearly
  constrained nonconvex minimization.
\newblock \emph{SIAM Journal on Optimization}, 30\penalty0 (3):\penalty0
  2272--2302, 2020.

\bibitem[Zhang and Luo(2022)]{jialuo20}
J.~Zhang and Z.-Q. Luo.
\newblock A global dual error bound and its application to the analysis of
  linearly constrained nonconvex optimization.
\newblock \emph{SIAM Journal on Optimization}, 32\penalty0 (3):\penalty0
  2319--2346, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Xiao, Sun, and Luo]{zhang2020single}
J.~Zhang, P.~Xiao, R.~Sun, and Z.~Luo.
\newblock A single-loop smoothed gradient descent-ascent algorithm for
  nonconvex-concave min-max problems.
\newblock In \emph{Proc. of Advances in Neural Information Processing Systems},
  pages 7377--7389, 2020.

\end{thebibliography}
