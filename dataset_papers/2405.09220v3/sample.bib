@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@article{shen2024hugginggpt,
  title={ {HuggingGPT}: Solving {AI} tasks with {ChatGPT} and its friends in {Huggingface} },
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{liu2023controlllm,
  title={ {ControlLLM}: Augment language models with tools by searching on graphs},
  author={Liu, Zhaoyang and Lai, Zeqiang and Gao, Zhangwei and Cui, Erfei and Li, Zhiheng and Zhu, Xizhou and Lu, Lewei and Chen, Qifeng and Qiao, Yu and Dai, Jifeng and others},
  journal={arXiv preprint arXiv:2310.17796},
  year={2023}
}

@article{liu2024toolnet,
  title={ {ToolNet}: Connecting Large Language Models with Massive Tools via Tool Graph},
  author={Liu, Xukun and Peng, Zhiyuan and Yi, Xiaoyuan and Xie, Xing and Xiang, Lirong and Liu, Yuchen and Xu, Dongkuan},
  journal={arXiv preprint arXiv:2403.00839},
  year={2024}
}

@article{whittington2022build,
  title={How to build a cognitive map: insights from models of the hippocampal formation},
  author={Whittington, James CR and McCaffary, David and Bakermans, Jacob JW and Behrens, Timothy EJ},
  journal={arXiv preprint arXiv:2202.01682},
  year={2022}
}

@article{trinh2024solving,
  title={Solving {Olympiad} geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024},
  publisher={Nature Publishing Group}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{luo2024graphinstruct,
  title={GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability},
  author={Luo, Zihan and Song, Xiran and Huang, Hong and Lian, Jianxun and Zhang, Chenhao and Jiang, Jinqi and Xie, Xing and Jin, Hai},
  journal={arXiv preprint arXiv:2403.04483},
  year={2024}
}

@article{momennejad2024evaluating,
  title={Evaluating cognitive maps and planning in large language models with {CogEval} },
  author={Momennejad, Ida and Hasanbeig, Hosein and Vieira Frujeri, Felipe and Sharma, Hiteshi and Jojic, Nebojsa and Palangi, Hamid and Ness, Robert and Larson, Jonathan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{valmeekam2023planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{aghzal2023can,
  title={Can large language models be good path planners? a benchmark and investigation on spatial-temporal reasoning},
  author={Aghzal, Mohamed and Plaku, Erion and Yao, Ziyu},
  journal={arXiv preprint arXiv:2310.03249},
  year={2023}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}


@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2021decision,
  title={ {Decision Transformer}: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@article{chai2023graphllm,
  title={ {GraphLLM}: Boosting graph reasoning ability of large language model},
  author={Chai, Ziwei and Zhang, Tianjie and Wu, Liang and Han, Kaiqiao and Hu, Xiaohai and Huang, Xuanwen and Yang, Yang},
  journal={arXiv preprint arXiv:2310.05845},
  year={2023}
}

@article{allen2023physics,
  title={Physics of language models: Part 1, context-free grammar},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2305.13673},
  year={2023}
}

@inproceedings{giannou2023looped,
  title={Looped transformers as programmable computers},
  author={Giannou, Angeliki and Rajput, Shashank and Sohn, Jy-yong and Lee, Kangwook and Lee, Jason D and Papailiopoulos, Dimitris},
  booktitle={International Conference on Machine Learning},
  pages={11398--11442},
  year={2023},
  organization={PMLR}
}

@inproceedings{nanda2023Progress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Neel, Nanda and Lawrence, Chan and Tom, Lieberum and Jess, Smith and Jacob, Steinhardt},
  booktitle={International Conference on Learning Representations},
  year={2023},
}

@article{feng2024towards,
  title={Towards revealing the mystery behind chain of thought: a theoretical perspective},
  author={Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{guo2023gpt4graph,
  title={Gpt4graph: Can large language models understand graph structured data? an empirical evaluation and benchmarking},
  author={Guo, Jiayan and Du, Lun and Liu, Hengyu},
  journal={arXiv preprint arXiv:2305.15066},
  year={2023}
}

@article{wang2024can,
  title={Can language models solve graph problems in natural language?},
  author={Wang, Heng and Feng, Shangbin and He, Tianxing and Tan, Zhaoxuan and Han, Xiaochuang and Tsvetkov, Yulia},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{tang2023graphgpt,
  title={ {GraphGPT}: Graph instruction tuning for large language models},
  author={Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
  journal={arXiv preprint arXiv:2310.13023},
  year={2023}
}

@article{merrill2023parallelism,
  title={The parallelism tradeoff: Limitations of log-precision transformers},
  author={Merrill, William and Sabharwal, Ashish},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={531--545},
  year={2023}
}

@article{lee2023teaching,
  title={Teaching arithmetic to small transformers},
  author={Lee, Nayoung and Sreenivasan, Kartik and Lee, Jason D and Lee, Kangwook and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2307.03381},
  year={2023}
}

@article{zhang2023trained,
  title={Trained transformers learn linear models in-context},
  author={Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2306.09927},
  year={2023}
}

@article{yang2024efficient,
  title={Do Efficient Transformers Really Save Computation?},
  author={Yang, Kai and Ackermann, Jan and He, Zhenyu and Feng, Guhao and Zhang, Bohang and Feng, Yunzhen and Ye, Qiwei and He, Di and Wang, Liwei},
  journal={arXiv preprint arXiv:2402.13934},
  year={2024}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={1--26},
  year={2024}
}

@article{zhang2022unveiling,
  title={Unveiling {Transformers} with {LEGO}: a synthetic reasoning task},
  author={Zhang, Yi and Backurs, Arturs and Bubeck, S{\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Wagner, Tal},
  journal={arXiv preprint arXiv:2206.04301},
  year={2022}
}

@article{zhu2023physics,
  title={Physics of language models: Part 3.1, knowledge storage and extraction},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2309.14316},
  year={2023}
}

@article{allenzhu2023physics,
  title={Physics of language models: Part 3.2, knowledge manipulation},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2309.14402},
  year={2023}
}

@inproceedings{Achiam2023GPT4TR,
  title={{GPT-4} Technical Report},
  author={OpenAI Josh Achiam and Steven Adler and et al},
  year={2023},
}

@article{zhu2024physics,
  title={Physics of language models: Part 3.3, Knowledge Capacity Scaling Laws},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2404.05405},
  year={2024}
}

@article{zhu2024physics21,
	title={Physics of language models: Part 2.1, Grade-School Math and the Hidden Reasoning Process},
	author={Tian Ye and Zicheng Xu and Yuanzhi Li and Zeyuan Allen-Zhu},
	journal={arXiv preprint arXiv:2407.20311},
	year={2024}
}

@article{zhu2024physics22,
	title={Physics of language models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems},
	author={Tian Ye and Zicheng Xu and Yuanzhi Li and Zeyuan Allen-Zhu},
	journal={arXiv preprint arXiv:2408.16293},
	year={2024}
}

@article{bubeck2023Sparks,
	title={Sparks of Artificial General Intelligence: Early experiments with {GPT-4} },
	author={S{\'e}bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and
	Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
	journal={arXiv preprint arXiv:2303.12712},
	year={2023}
}