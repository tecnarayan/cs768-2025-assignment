% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{rajani_explain_2019,
  title={Explain Yourself! Leveraging Language Models for Commonsense Reasoning},
  author={Nazneen Fatema Rajani and Bryan McCann and Caiming Xiong and Richard Socher},
  booktitle={ACL 2019},
  year={2019},
  url={https://arxiv.org/pdf/1906.02361.pdf},
}

@inproceedings{zhang_bridging_2019,
  title={Bridging the Gap between Training and Inference for Neural Machine Translation},
  author={Wen Zhang and Yang Feng and Fandong Meng and Di You and Qun Liu},
  booktitle={ACL},
  year={2019},
  url={https://arxiv.org/pdf/1906.02448.pdf}
}

@inproceedings{pennington_glove:_2014,
  title={Glove: Global Vectors for Word Representation},
  author={Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle={EMNLP},
  year={2014},
  url={https://www-nlp.stanford.edu/pubs/glove.pdf}
}

@article{ribeiro_why_2016,
  title={"{W}hy {S}hould {I} {T}rust {Y}ou?": Explaining the Predictions of Any Classifier},
  author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  journal={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year={2016},
  url={https://arxiv.org/pdf/1602.04938.pdf}
}

@article{doshi-velez_towards_2017,
  title={Towards A Rigorous Science of Interpretable Machine Learning},
  author={Finale Doshi-Velez and Been Kim},
  journal={arXiv: Machine Learning},
  year={2017},
  url={https://arxiv.org/pdf/1702.08608.pdf}
}

@inproceedings{andreas_translating_2017,
  title={Translating Neuralese},
  author={Jacob Andreas and Anca D. Dragan and Dan Klein},
  booktitle={ACL},
  year={2017},
  url={https://arxiv.org/abs/1704.06960}
}

@article{collobert_natural_nodate,
  title={Natural Language Processing (Almost) from Scratch},
  author={Ronan Collobert and Jason Weston and L{\'e}on Bottou and Michael Karlen and Koray Kavukcuoglu and Pavel P. Kuksa},
  journal={J. Mach. Learn. Res.},
  year={2011},
  volume={12},
  pages={2493-2537},
  url={https://arxiv.org/pdf/1103.0398.pdf}
}

@inproceedings{li_paraphrase_2018,
  title={Paraphrase Generation with Deep Reinforcement Learning},
  author={Zichao Li and Xin Jiang and Lifeng Shang and Huang Li},
  booktitle={EMNLP},
  year={2018},
  url={https://arxiv.org/pdf/1711.00279.pdf}
}

@article{kaiser_fast_2018,
  title={Fast Decoding in Sequence Models using Discrete Latent Variables},
  author={≈Åukasz Kaiser and Aurko Roy and Ashish Vaswani and Niki Parmar and Samy Bengio and Jakob Uszkoreit and Noam Shazeer},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.03382},
  url={https://arxiv.org/pdf/1803.03382.pdf}
}

@inproceedings{talmor_commonsenseqa_2019,
  title={CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},
  author={Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},
  booktitle={NAACL-HLT 2019},
  year={2019},
  url={https://arxiv.org/pdf/1811.00937.pdf}
}

@inproceedings{dai_transformer-xl_2019,
  title={Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
  author={Zihang Dai and Zhilin Yang and Yiming Yang and Jaime G. Carbonell and Quoc V. Le and Ruslan Salakhutdinov},
  booktitle={ACL},
  year={2019},
  url={https://arxiv.org/pdf/1901.02860.pdf}
}

@inproceedings{radford_language_2019,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  booktitle={OpenAI Technical Report},
  url={https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}

@inproceedings{wang_does_2019,
  title={Does It Make Sense? And Why? A Pilot Study for Sense Making and Explanation},
  author={Cunxiang Wang and Shuailong Liang and Yue Zhang and Xiaonan Li and Tian Gao},
  booktitle={ACL 2019},
  year={2019},
  url={https://arxiv.org/pdf/1906.00363.pdf}
}


@inproceedings{liu_generating_2018,
  title={Generating Wikipedia by Summarizing Long Sequences},
  author={Peter J. Liu and Mohammad Saleh and Etienne Pot and Ben Goodrich and Ryan Sepassi and Lukasz Kaiser and Noam Shazeer},
  booktitle={ICLR},
  year={2018},
  url={https://arxiv.org/pdf/1801.10198.pdf}
}

@inproceedings{zhang_explicit_2019,
  title={Explicit Contextual Semantics for Text Comprehension},
  author={Zhuosheng Zhang and Yuwei Wu and Zuchao Li and Hai Zhao},
  year={2018},
  booktitle={PACLIC 33},
  url={https://arxiv.org/pdf/1809.02794.pdf}
}

@inproceedings{oord_neural_2018,
  title={Neural Discrete Representation Learning},
  author={A{\"a}ron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
  booktitle={NIPS},
  year={2017},
  url={https://arxiv.org/pdf/1711.00937.pdf}
}

@inproceedings{devlin_bert_2019,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year={2019},
  booktitle={ACL 2019},
  url={https://arxiv.org/pdf/1810.04805.pdf}
}

@inproceedings{strout_human_2019,
  title={Do Human Rationales Improve Machine Explanations?},
  author={Julia Strout and Ye Zhang and Raymond J. Mooney},
  booktitle={ACL},
  year={2019},
  url={https://arxiv.org/pdf/1905.13714.pdf}
}

@inproceedings{deyoung_eraser_2019,
  title={ERASER: A Benchmark to Evaluate Rationalized NLP Models},
  author={Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace},
  booktitle={ACL 2020},
  year={2020},
  volume={abs/1911.03429},
  url={https://arxiv.org/pdf/1911.03429.pdf}
}

@inproceedings{bhagavatula_abductive_2019,
  title={Abductive Commonsense Reasoning},
  author={Chandra Bhagavatula and Ronan Le Bras and Chaitanya Malaviya and Keisuke Sakaguchi and Ari Holtzman and Hannah Rashkin and Doug Downey and Scott Yih and Yejin Choi},
  booktitle={ICLR},
  year={2020},
  url={https://arxiv.org/pdf/1908.05739.pdf}
}

@article{ye_align_2019,
  title={Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models},
  author={Zhi-Xiu Ye and Qian Chen and Wen Wang and Zhen-Hua Ling},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.06725},
  url={https://arxiv.org/pdf/1908.06725.pdf}
}

@inproceedings{hancock_training_2018,
  title={Training Classifiers with Natural Language Explanations},
  author={Braden Hancock and Paroma Varma and Stephanie Wang and Martin Bringmann and Percy Liang and Christopher R{\'e}},
  booktitle={ACL},
  year={2018},
  url={https://pubmed.ncbi.nlm.nih.gov/31130772/}
}

@inproceedings{lei_rationalizing_2016,
  title={Rationalizing Neural Predictions},
  author={Tao Lei and Regina Barzilay and Tommi S. Jaakkola},
  booktitle={EMNLP},
  year={2016},
  url={https://arxiv.org/pdf/1606.04155.pdf}
}

@article{liu_roberta_2019,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692},
  url={https://arxiv.org/pdf/1907.11692.pdf}
}

@article{talmor_olmpics_2019,
  title={oLMpics - On what Language Model Pre-training Captures},
  author={Alon Talmor and Yanai Elazar and Yoav Goldberg and Jonathan Berant},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.13283},
  url={https://arxiv.org/pdf/1912.13283.pdf}
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	language = {en},
	number = {7553},
	urldate = {2020-01-02},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pages = {436-444},
}

@inproceedings{chandrasekaran_explanations_2018,
  title={Do explanations make VQA models more predictable to a human?},
  author={Arjun Chandrasekaran and Viraj Prabhu and Deshraj Yadav and Prithvijit Chattopadhyay and Devi Parikh},
  booktitle={EMNLP},
  year={2018},
  url={https://arxiv.org/pdf/1810.12366.pdf}
}

@article{lin_kagnet_2019,
	title = {{KagNet}: {Knowledge}-{Aware} {Graph} {Networks} for {Commonsense} {Reasoning}},
	shorttitle = {{KagNet}},
	url = {http://arxiv.org/abs/1909.02151},
	abstract = {Commonsense reasoning aims to empower machines with the human ability to make presumptions about ordinary situations in our daily life. In this paper, we propose a textual inference framework for answering commonsense questions, which effectively utilizes external, structured commonsense knowledge graphs to perform explainable inferences. The framework first grounds a question-answer pair from the semantic space to the knowledge-based symbolic space as a schema graph, a related sub-graph of external knowledge graphs. It represents schema graphs with a novel knowledge-aware graph network module named KagNet, and finally scores answers with graph representations. Our model is based on graph convolutional networks and LSTMs, with a hierarchical path-based attention mechanism. The intermediate attention scores make it transparent and interpretable, which thus produce trustworthy inferences. Using ConceptNet as the only external resource for Bert-based models, we achieved state-of-the-art performance on the CommonsenseQA, a large-scale dataset for commonsense reasoning.},
	urldate = {2020-01-02},
	journal = {arXiv:1909.02151 [cs]},
	author = {Lin, Bill Yuchen and Chen, Xinyue and Chen, Jamin and Ren, Xiang},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.02151},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\KL4LDW7S\\1909.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\8U96MH4D\\Lin et al. - 2019 - KagNet Knowledge-Aware Graph Networks for Commons.pdf:application/pdf}
}

@inproceedings{zellers_recognition_nodate,
  title={From Recognition to Cognition: Visual Commonsense Reasoning},
  author={Rowan Zellers and Yonatan Bisk and Ali Farhadi and Yejin Choi},
  booktitle={IEEE/CVF 2019},
  year={2019},
  url={https://ieeexplore.ieee.org/document/8953217}
}

@inproceedings{zhang_rationale-augmented_2016,
	address = {Austin, Texas},
	title = {Rationale-{Augmented} {Convolutional} {Neural} {Networks} for {Text} {Classification}},
	url = {https://www.aclweb.org/anthology/D16-1076},
	doi = {10.18653/v1/D16-1076},
	urldate = {2020-01-02},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Ye and Marshall, Iain and Wallace, Byron C.},
	month = nov,
	year = {2016},
	pages = {795--804},
	file = {Full Text PDF:C\:\\Users\\peter\\Zotero\\storage\\TFKD4A5M\\Zhang et al. - 2016 - Rationale-Augmented Convolutional Neural Networks .pdf:application/pdf}
}

@inproceedings{zaidan_using_2007,
	address = {Rochester, New York},
	title = {Using ‚Äú{Annotator} {Rationales}‚Äù to {Improve} {Machine} {Learning} for {Text} {Categorization}},
	url = {https://www.aclweb.org/anthology/N07-1033},
	urldate = {2020-01-02},
	booktitle = {Human {Language} {Technologies} 2007: {The} {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}; {Proceedings} of the {Main} {Conference}},
	publisher = {Association for Computational Linguistics},
	author = {Zaidan, Omar and Eisner, Jason and Piatko, Christine},
	month = apr,
	year = {2007},
	pages = {260--267},
	file = {Full Text PDF:C\:\\Users\\peter\\Zotero\\storage\\748D6T6P\\Zaidan et al. - 2007 - Using ‚ÄúAnnotator Rationales‚Äù to Improve Machine Le.pdf:application/pdf}
}

@inproceedings{ling_program_2017,
  title={Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems},
  author={Wang Ling and Dani Yogatama and Chris Dyer and Phil Blunsom},
  booktitle={ACL 2017},
  year={2017},
  url={https://arxiv.org/pdf/1705.04146.pdf}
}

@inproceedings{hendricks_generating_2016,
  title={Generating Visual Explanations},
  author={Lisa Anne Hendricks and Zeynep Akata and Marcus Rohrbach and Jeff Donahue and Bernt Schiele and Trevor Darrell},
  booktitle={ECCV 2016},
  year={2016},
  url={https://arxiv.org/pdf/1603.08507.pdf}
}

@inproceedings{kim_textual_2018,
  title={Textual Explanations for Self-Driving Vehicles},
  author={Jinkyu Kim and Anna Rohrbach and Trevor Darrell and John F. Canny and Zeynep Akata},
  booktitle={ECCV 2018},
  year={2018},
  url={https://arxiv.org/pdf/1807.11546.pdf}
}

@article{park_multimodal_2018,
  title={Multimodal Explanations: Justifying Decisions and Pointing to the Evidence},
  author={Dong Huk Park and Lisa Anne Hendricks and Zeynep Akata and Anna Rohrbach and Bernt Schiele and Trevor Darrell and Marcus Rohrbach},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018},
  pages={8779-8788},
  url={https://ieeexplore.ieee.org/document/8579013/}
}

@article{camburu_can_2019,
	title = {Can {I} {Trust} the {Explainer}? {Verifying} {Post}-hoc {Explanatory} {Methods}},
	shorttitle = {Can {I} {Trust} the {Explainer}?},
	url = {http://arxiv.org/abs/1910.02065},
	urldate = {2019-12-29},
	journal = {arXiv:1910.02065 [cs]},
	author = {Camburu, Oana-Maria and Giunchiglia, Eleonora and Foerster, Jakob and Lukasiewicz, Thomas and Blunsom, Phil},
	month = dec,
	year = {2019},
	note = {arXiv: 1910.02065},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\D3G8HBRP\\1910.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\54ELX4E6\\Camburu et al. - 2019 - Can I Trust the Explainer Verifying Post-hoc Expl.pdf:application/pdf}
}

@article{camburu_make_2019,
  title={Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations},
  author={Oana-Maria Camburu and Brendan Shillingford and Pasquale Minervini and Thomas Lukasiewicz and Phil Blunsom},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03065},
  url={https://arxiv.org/abs/1910.03065}
}

@inproceedings{camburu_e-snli:_2018,
  title={e-SNLI: Natural Language Inference with Natural Language Explanations},
  author={Oana-Maria Camburu and Tim Rockt{\"a}schel and Thomas Lukasiewicz and Phil Blunsom},
  booktitle={NeurIPS 2018},
  year={2018},
  url={https://arxiv.org/pdf/1812.01193.pdf}
}

@article{alvarez-melis_causal_2017,
	title = {A causal framework for explaining the predictions of black-box sequence-to-sequence models},
	url = {http://arxiv.org/abs/1707.01943},
	abstract = {We interpret the predictions of any black-box structured input-structured output model around a specific input-output pair. Our method returns an "explanation" consisting of groups of input-output tokens that are causally related. These dependencies are inferred by querying the black-box model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-to-sequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.},
	urldate = {2019-12-29},
	journal = {arXiv:1707.01943 [cs]},
	author = {Alvarez-Melis, David and Jaakkola, Tommi S.},
	month = nov,
	year = {2017},
	note = {arXiv: 1707.01943},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\QFYZF6LC\\1707.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\KQIJU8LU\\Alvarez-Melis and Jaakkola - 2017 - A causal framework for explaining the predictions .pdf:application/pdf}
}

@article{roy_unsupervised_2019,
	title = {Unsupervised {Paraphrasing} without {Translation}},
	url = {http://arxiv.org/abs/1905.12752},
	abstract = {Paraphrasing exemplifies the ability to abstract semantic content from surface forms. Recent work on automatic paraphrasing is dominated by methods leveraging Machine Translation (MT) as an intermediate step. This contrasts with humans, who can paraphrase without being bilingual. This work proposes to learn paraphrasing models from an unlabeled monolingual corpus only. To that end, we propose a residual variant of vector-quantized variational auto-encoder. We compare with MT-based approaches on paraphrase identification, generation, and training augmentation. Monolingual paraphrasing outperforms unsupervised translation in all settings. Comparisons with supervised translation are more mixed: monolingual paraphrasing is interesting for identification and augmentation; supervised translation is superior for generation.},
	urldate = {2019-12-29},
	journal = {arXiv:1905.12752 [cs, stat]},
	author = {Roy, Aurko and Grangier, David},
	month = may,
	year = {2019},
	note = {arXiv: 1905.12752},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\BICBWA6M\\1905.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\KGLXVDSA\\Roy and Grangier - 2019 - Unsupervised Paraphrasing without Translation.pdf:application/pdf}
}

@article{perez_finding_2019,
	title = {Finding {Generalizable} {Evidence} by {Learning} to {Convince} {Q}\&{A} {Models}},
	url = {http://arxiv.org/abs/1909.05863},
	abstract = {We propose a system that finds the strongest supporting evidence for a given answer to a question, using passage-based question-answering (QA) as a testbed. We train evidence agents to select the passage sentences that most convince a pretrained QA model of a given answer, if the QA model received those sentences instead of the full passage. Rather than finding evidence that convinces one model alone, we find that agents select evidence that generalizes; agent-chosen evidence increases the plausibility of the supported answer, as judged by other QA models and humans. Given its general nature, this approach improves QA in a robust manner: using agent-selected evidence (i) humans can correctly answer questions with only {\textasciitilde}20\% of the full passage and (ii) QA models can generalize to longer passages and harder questions.},
	urldate = {2019-12-21},
	journal = {arXiv:1909.05863 [cs]},
	author = {Perez, Ethan and Karamcheti, Siddharth and Fergus, Rob and Weston, Jason and Kiela, Douwe and Cho, Kyunghyun},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.05863},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Multiagent Systems},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\HYZ4R67B\\1909.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\E452P2H3\\Perez et al. - 2019 - Finding Generalizable Evidence by Learning to Conv.pdf:application/pdf}
}

@article{irving_ai_2018,
	title = {{AI} safety via debate},
	url = {http://arxiv.org/abs/1805.00899},
	abstract = {To make AI systems broadly useful for challenging real-world tasks, we need them to learn complex human goals and preferences. One approach to specifying complex goals asks humans to judge during training which agent behaviors are safe and useful, but this approach can fail if the task is too complicated for a human to directly judge. To help address this concern, we propose training agents via self play on a zero sum debate game. Given a question or proposed action, two agents take turns making short statements up to a limit, then a human judges which of the agents gave the most true, useful information. In an analogy to complexity theory, debate with optimal play can answer any question in PSPACE given polynomial time judges (direct judging answers only NP questions). In practice, whether debate works involves empirical questions about humans and the tasks we want AIs to perform, plus theoretical questions about the meaning of AI alignment. We report results on an initial MNIST experiment where agents compete to convince a sparse classifier, boosting the classifier's accuracy from 59.4\% to 88.9\% given 6 pixels and from 48.2\% to 85.2\% given 4 pixels. Finally, we discuss theoretical and practical aspects of the debate model, focusing on potential weaknesses as the model scales up, and we propose future human and computer experiments to test these properties.},
	urldate = {2019-12-19},
	journal = {arXiv:1805.00899 [cs, stat]},
	author = {Irving, Geoffrey and Christiano, Paul and Amodei, Dario},
	month = oct,
	year = {2018},
	note = {arXiv: 1805.00899},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\CK3CT6N6\\1805.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\QV3T5EQ2\\Irving et al. - 2018 - AI safety via debate.pdf:application/pdf}
}

@article{bowman_generating_2016,
	title = {Generating {Sentences} from a {Continuous} {Space}},
	url = {http://arxiv.org/abs/1511.06349},
	abstract = {The standard recurrent neural network language model (RNNLM) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an RNN-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.},
	urldate = {2019-12-19},
	journal = {arXiv:1511.06349 [cs]},
	author = {Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M. and Jozefowicz, Rafal and Bengio, Samy},
	month = may,
	year = {2016},
	note = {arXiv: 1511.06349},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\KYM3U2NS\\1511.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\5HV797CH\\Bowman et al. - 2016 - Generating Sentences from a Continuous Space.pdf:application/pdf}
}

@article{srinivas_full-gradient_2019,
	title = {Full-{Gradient} {Representation} for {Neural} {Network} {Visualization}},
	url = {http://arxiv.org/abs/1905.00780},
	abstract = {We introduce a new tool for interpreting neural net responses, namely full-gradients, which decomposes the neural net response into input sensitivity and per-neuron sensitivity components. This is the first proposed representation which satisfies two key properties: completeness and weak dependence, which provably cannot be satisfied by any saliency map-based interpretability method. For convolutional nets, we also propose an approximate saliency map representation, called FullGrad, obtained by aggregating the full-gradient components. We experimentally evaluate the usefulness of FullGrad in explaining model behaviour with two quantitative tests: pixel perturbation and remove-and-retrain. Our experiments reveal that our method explains model behaviour correctly, and more comprehensively than other methods in the literature. Visual inspection also reveals that our saliency maps are sharper and more tightly confined to object regions than other methods.},
	urldate = {2019-12-11},
	journal = {arXiv:1905.00780 [cs, stat]},
	author = {Srinivas, Suraj and Fleuret, Francois},
	month = dec,
	year = {2019},
	note = {arXiv: 1905.00780},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\4AMXYYWU\\1905.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\8Y9YDAXM\\Srinivas and Fleuret - 2019 - Full-Gradient Representation for Neural Network Vi.pdf:application/pdf}
}

@article{grathwohl_your_2019,
	title = {Your {Classifier} is {Secretly} an {Energy} {Based} {Model} and {You} {Should} {Treat} it {Like} {One}},
	url = {http://arxiv.org/abs/1912.03263},
	urldate = {2019-12-10},
	journal = {arXiv:1912.03263 [cs, stat]},
	author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, J√∂rn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.03263},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\E6MCNJ5D\\1912.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\KLW3IQAE\\Grathwohl et al. - 2019 - Your Classifier is Secretly an Energy Based Model .pdf:application/pdf}
}

@article{kim_interpretability_2018,
	title = {Interpretability {Beyond} {Feature} {Attribution}: {Quantitative} {Testing} with {Concept} {Activation} {Vectors} ({TCAV})},
	shorttitle = {Interpretability {Beyond} {Feature} {Attribution}},
	url = {http://arxiv.org/abs/1711.11279},
	urldate = {2019-11-29},
	journal = {arXiv:1711.11279 [stat]},
	author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
	month = jun,
	year = {2018},
	note = {arXiv: 1711.11279},
	keywords = {Statistics - Machine Learning},
}



@article{nie_adversarial_2019,
	title = {Adversarial {NLI}: {A} {New} {Benchmark} for {Natural} {Language} {Understanding}},
	shorttitle = {Adversarial {NLI}},
	url = {http://arxiv.org/abs/1910.14599},
	abstract = {We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the-art models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.},
	urldate = {2019-11-11},
	journal = {arXiv:1910.14599 [cs]},
	author = {Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.14599},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\U5KQCW35\\Nie et al. - 2019 - Adversarial NLI A New Benchmark for Natural Langu.pdf:application/pdf}
}

@article{bang_explaining_2019,
  title={Explaining a black-box using Deep Variational Information Bottleneck Approach},
  author={Seo-Jin Bang and Pengtao Xie and Wei Wu and Eric P. Xing},
  journal={ArXiv},
  year={2019},
  volume={abs/1902.06918},
  url={https://arxiv.org/abs/1902.06918}
}

@inproceedings{nguyen_comparing_2018,
  title={Comparing Automatic and Human Evaluation of Local Explanations for Text Classification},
  author={Dong Nguyen},
  booktitle={NAACL-HLT 2018},
  year={2018},
  url={https://www.aclweb.org/anthology/N18-1097.pdf}
}

@article{holtzman_curious_2019,
	title = {The {Curious} {Case} of {Neural} {Text} {Degeneration}},
	url = {http://arxiv.org/abs/1904.09751},
	abstract = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
	urldate = {2019-09-18},
	journal = {arXiv:1904.09751 [cs]},
	author = {Holtzman, Ari and Buys, Jan and Forbes, Maxwell and Choi, Yejin},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.09751},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1904.09751 PDF:C\:\\Users\\peter\\Zotero\\storage\\IC3YHFSP\\Holtzman et al. - 2019 - The Curious Case of Neural Text Degeneration.pdf:application/pdf}
}

@article{raffel_exploring_2019,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.10683},
  url={https://arxiv.org/pdf/1910.10683.pdf}
}

@article{dodge_fine-tuning_2020,
	title = {Fine-{Tuning} {Pretrained} {Language} {Models}: {Weight} {Initializations}, {Data} {Orders}, and {Early} {Stopping}},
	shorttitle = {Fine-{Tuning} {Pretrained} {Language} {Models}},
	url = {http://arxiv.org/abs/2002.06305},
	abstract = {Fine-tuning pretrained contextual word embedding models to supervised downstream tasks has become commonplace in natural language processing. This process, however, is often brittle: even with the same hyperparameter values, distinct random seeds can lead to substantially different results. To better understand this phenomenon, we experiment with four datasets from the GLUE benchmark, fine-tuning BERT hundreds of times on each while varying only the random seeds. We find substantial performance increases compared to previously reported results, and we quantify how the performance of the best-found model varies as a function of the number of fine-tuning trials. Further, we examine two factors influenced by the choice of random seed: weight initialization and training data order. We find that both contribute comparably to the variance of out-of-sample performance, and that some weight initializations perform well across all tasks explored. On small datasets, we observe that many fine-tuning trials diverge part of the way through training, and we offer best practices for practitioners to stop training less promising runs early. We publicly release all of our experimental data, including training and validation scores for 2,100 trials, to encourage further analysis of training dynamics during fine-tuning.},
	urldate = {2020-02-18},
	journal = {arXiv:2002.06305 [cs]},
	author = {Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.06305},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\NX5EY93K\\Dodge et al. - 2020 - Fine-Tuning Pretrained Language Models Weight Ini.pdf:application/pdf}
}

@article{he_lagging_2019,
	title = {Lagging {Inference} {Networks} and {Posterior} {Collapse} in {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/1901.05534},
	abstract = {The variational autoencoder (VAE) is a popular combination of deep latent variable model and accompanying variational learning technique. By using a neural inference network to approximate the model's posterior on latent variables, VAEs efficiently parameterize a lower bound on marginal data likelihood that can be optimized directly via gradient methods. In practice, however, VAE training often results in a degenerate local optimum known as "posterior collapse" where the model learns to ignore the latent variable and the approximate posterior mimics the prior. In this paper, we investigate posterior collapse from the perspective of training dynamics. We find that during the initial stages of training the inference network fails to approximate the model's true posterior, which is a moving target. As a result, the model is encouraged to ignore the latent encoding and posterior collapse occurs. Based on this observation, we propose an extremely simple modification to VAE training to reduce inference lag: depending on the model's current mutual information between latent variable and observation, we aggressively optimize the inference network before performing each model update. Despite introducing neither new model components nor significant complexity over basic VAE, our approach is able to avoid the problem of collapse that has plagued a large amount of previous work. Empirically, our approach outperforms strong autoregressive baselines on text and image benchmarks in terms of held-out likelihood, and is competitive with more complex techniques for avoiding collapse while being substantially faster.},
	urldate = {2020-02-18},
	journal = {arXiv:1901.05534 [cs, stat]},
	author = {He, Junxian and Spokoyny, Daniel and Neubig, Graham and Berg-Kirkpatrick, Taylor},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.05534},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\WTPNDDLI\\He et al. - 2019 - Lagging Inference Networks and Posterior Collapse .pdf:application/pdf}
}

@article{liu_towards_2019,
	title = {Towards {Explainable} {NLP}: {A} {Generative} {Explanation} {Framework} for {Text} {Classification}},
	shorttitle = {Towards {Explainable} {NLP}},
	url = {http://arxiv.org/abs/1811.00196},
	abstract = {Building explainable systems is a critical problem in the field of Natural Language Processing (NLP), since most machine learning models provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information is often ignored, and the systems do not explicitly generate the human-readable explanations. To better alleviate this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new datasets that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both datasets, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both datasets, and is able to generate concise explanations at the same time.},
	urldate = {2020-02-19},
	journal = {arXiv:1811.00196 [cs]},
	author = {Liu, Hui and Yin, Qingyu and Wang, William Yang},
	month = jun,
	year = {2019},
	note = {arXiv: 1811.00196},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\C3G84CBU\\Liu et al. - 2019 - Towards Explainable NLP A Generative Explanation .pdf:application/pdf}
}

@inproceedings{bowman_large_2015,
  title={A large annotated corpus for learning natural language inference},
  author={Samuel R. Bowman and Gabor Angeli and Christopher Potts and Christopher D. Manning},
  booktitle={EMNLP 2015},
  year={2015},
  url={https://arxiv.org/abs/1508.05326}
}

@article{olah_building_2018,
	title = {The {Building} {Blocks} of {Interpretability}},
	volume = {3},
	issn = {2476-0757},
	url = {https://distill.pub/2018/building-blocks},
	doi = {10.23915/distill.00010},
	abstract = {Interpretability techniques are normally studied in isolation. We explore the powerful interfaces that arise when you combine them -- and the rich structure of this combinatorial space.},
	language = {en},
	number = {3},
	urldate = {2020-03-18},
	journal = {Distill},
	author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	month = mar,
	year = {2018},
	pages = {e10},
}

@article{jansen_worldtree_2018,
	title = {{WorldTree}: {A} {Corpus} of {Explanation} {Graphs} for {Elementary} {Science} {Questions} supporting {Multi}-{Hop} {Inference}},
	shorttitle = {{WorldTree}},
	url = {http://arxiv.org/abs/1802.03052},
	abstract = {Developing methods of automated inference that are able to provide users with compelling human-readable justifications for why the answer to a question is correct is critical for domains such as science and medicine, where user trust and detecting costly errors are limiting factors to adoption. One of the central barriers to training question answering models on explainable inference tasks is the lack of gold explanations to serve as training data. In this paper we present a corpus of explanations for standardized science exams, a recent challenge task for question answering. We manually construct a corpus of detailed explanations for nearly all publicly available standardized elementary science question (approximately 1,680 3rd through 5th grade questions) and represent these as "explanation graphs" -- sets of lexically overlapping sentences that describe how to arrive at the correct answer to a question through a combination of domain and world knowledge. We also provide an explanation-centered tablestore, a collection of semi-structured tables that contain the knowledge to construct these elementary science explanations. Together, these two knowledge resources map out a substantial portion of the knowledge required for answering and explaining elementary science exams, and provide both structured and free-text training data for the explainable inference task.},
	urldate = {2020-03-27},
	journal = {arXiv:1802.03052 [cs]},
	author = {Jansen, Peter A. and Wainwright, Elizabeth and Marmorstein, Steven and Morrison, Clayton T.},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.03052},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\CZJ4FG3J\\Jansen et al. - 2018 - WorldTree A Corpus of Explanation Graphs for Elem.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\3YD4BNXT\\1802.html:text/html}
}

@article{lazaridou_towards_2016,
	title = {Towards {Multi}-{Agent} {Communication}-{Based} {Language} {Learning}},
	url = {http://arxiv.org/abs/1605.07133},
	abstract = {We propose an interactive multimodal framework for language learning. Instead of being passively exposed to large amounts of natural text, our learners (implemented as feed-forward neural networks) engage in cooperative referential games starting from a tabula rasa setup, and thus develop their own language from the need to communicate in order to succeed at the game. Preliminary experiments provide promising results, but also suggest that it is important to ensure that agents trained in this way do not develop an adhoc communication code only effective for the game they are playing},
	urldate = {2020-03-27},
	journal = {arXiv:1605.07133 [cs]},
	author = {Lazaridou, Angeliki and Pham, Nghia The and Baroni, Marco},
	month = may,
	year = {2016},
	note = {arXiv: 1605.07133},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\JT4Y8ES2\\Lazaridou et al. - 2016 - Towards Multi-Agent Communication-Based Language L.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\X9MCYSW5\\1605.html:text/html}
}

@inproceedings{lazaridou_multi-agent_2017,
  title={Multi-Agent Cooperation and the Emergence of (Natural) Language},
  author={Angeliki Lazaridou and Alexander Peysakhovich and Marco Baroni},
  booktitle={ICLR 2017},
  year={2017},
  url={https://arxiv.org/pdf/1612.07182.pdf}
}

@inproceedings{das_tarmac_nodate,
  title={TarMAC: Targeted Multi-Agent Communication},
  author={Abhishek Das and Th{\'e}ophile Gervet and Joshua Romoff and Dhruv Batra and Devi Parikh and Michael G. Rabbat and Joelle Pineau},
  booktitle={ICML 2018},
  year={2018},
  url={https://arxiv.org/abs/1810.11187}
}

@article{kottur_natural_2017,
	title = {Natural {Language} {Does} {Not} {Emerge} '{Naturally}' in {Multi}-{Agent} {Dialog}},
	url = {http://arxiv.org/abs/1706.08502},
	abstract = {A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, all learned without any human supervision! In this paper, using a Task and Tell reference game between two agents as a testbed, we present a sequence of 'negative' results culminating in a 'positive' one -- showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge 'naturally', despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.},
	urldate = {2020-03-27},
	journal = {arXiv:1706.08502 [cs]},
	author = {Kottur, Satwik and Moura, Jos√© M. F. and Lee, Stefan and Batra, Dhruv},
	month = aug,
	year = {2017},
	note = {arXiv: 1706.08502},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\AHEMUD72\\Kottur et al. - 2017 - Natural Language Does Not Emerge 'Naturally' in Mu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\A8PNEIQG\\1706.html:text/html}
}

@inproceedings{mordatch_emergence_nodate,
  title={Emergence of Grounded Compositional Language in Multi-Agent Populations},
  author={Igor Mordatch and Pieter Abbeel},
  booktitle={AAAI 2017},
  year={2017},
  url={https://arxiv.org/pdf/1703.04908.pdf}
}

@incollection{sukhbaatar_learning_2016,
	title = {Learning {Multiagent} {Communication} with {Backpropagation}},
	url = {http://papers.nips.cc/paper/6398-learning-multiagent-communication-with-backpropagation.pdf},
	urldate = {2020-03-31},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Sukhbaatar, Sainbayar and szlam, arthur and Fergus, Rob},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {2244--2252},
	file = {NIPS Full Text PDF:C\:\\Users\\peter\\Zotero\\storage\\AHSF47XW\\Sukhbaatar et al. - 2016 - Learning Multiagent Communication with Backpropaga.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\peter\\Zotero\\storage\\YPZNF4UQ\\6398-learning-multiagent-communication-with-backpropagation.html:text/html}
}

@article{lewis_bart_2019,
	title = {{BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}},
	shorttitle = {{BART}},
	url = {http://arxiv.org/abs/1910.13461},
	abstract = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.},
	urldate = {2020-04-06},
	journal = {arXiv:1910.13461 [cs, stat]},
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.13461},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\ZL9C68Q2\\Lewis et al. - 2019 - BART Denoising Sequence-to-Sequence Pre-training .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\XQ79FHPY\\1910.html:text/html}
}

@misc{atcinnik_explaining_2020,
Author = {Veronica Latcinnik and Jonathan Berant},
Title = {Explaining Question Answering Models through Text Generation},
Year = {2020},
Eprint = {arXiv:2004.05569},
}
@inproceedings{hendricks2018grounding,
  title={Grounding Visual Explanations},
  author={Lisa Anne Hendricks and Ronghang Hu and Trevor Darrell and Zeynep Akata},
  booktitle={ECCV 2018},
  year={2018},
  url={https://arxiv.org/pdf/1807.09685.pdf}
}

@misc{loshchilov_decoupled_2017,
Author = {Ilya Loshchilov and Frank Hutter},
Title = {Decoupled Weight Decay Regularization},
Year = {2017},
url={https://arxiv.org/pdf/1711.05101.pdf},
Eprint = {arXiv:1711.05101},
}

@article{narang_wt5?!_2020,
  title={W{T}5?! Training Text-to-Text Models to Explain their Predictions},
  author={Sharan Narang and Colin Raffel and Katherine J. Lee and Adam Roberts and Noah Fiedel and Karishma Malkan},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.14546},
  url={https://arxiv.org/pdf/2004.14546.pdf}
}

@article{treviso_towards_2020,
  title={Towards Prediction Explainability through Sparse Communication},
  author={Marcos Vin{\'i}cius Treviso and Andr{\'e} F. T. Martins},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.13876},
  url={https://arxiv.org/pdf/2004.13876.pdf}
}

@inproceedings{hase_evaluating_2020,
    title={Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?},
    author={Peter Hase and Mohit Bansal},
    url = {https://arxiv.org/pdf/2005.01831.pdf},
    booktitle = {ACL 2020},
    year={2020},
}

@inproceedings{papineni2002bleu,
  title={Bleu: a Method for Automatic Evaluation of Machine Translation},
  author={Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu},
  booktitle={ACL 2002},
  year={2002},
  url={https://www.aclweb.org/anthology/P02-1040.pdf}
}

@inproceedings{maddison_concrete_2016,
Author = {Chris J. Maddison and Andriy Mnih and Yee Whye Teh},
Title = {The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
booktitle={ICLR 2017},
Year = {2017},
url={https://arxiv.org/abs/1611.00712}
}

@article{williams_simple_1992,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Ronald J. Williams},
  journal={Machine Learning},
  year={1992},
  volume={8},
  pages={229-256},
  url={https://link.springer.com/article/10.1023/A:1022672621406}
}



@article{pearl_causal_2009,
	title = {Causal Inference in Statistics: {An} Overview},
	volume = {3},
	issn = {1935-7516},
	shorttitle = {Causal Inference in Statistics},
	url = {http://projecteuclid.org/euclid.ssu/1255440554},
	doi = {10.1214/09-SS057},
	language = {en},
	number = {0},
	urldate = {2020-05-23},
	journal = {Statistics Surveys},
	author = {Pearl, Judea},
	year = {2009},
	pages = {96--146},
	file = {Pearl - 2009 - Causal inference in statistics An overview.pdf:C\:\\Users\\Peter Hase\\Zotero\\storage\\FDL9H6S6\\Pearl - 2009 - Causal inference in statistics An overview.pdf:application/pdf}
}


@article{rudin_stop_2019,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Cynthia Rudin},
  journal={Nature Machine Intelligence},
  year={2018},
  volume={1},
  pages={206-215},
  url={https://www.nature.com/articles/s42256-019-0048-x}
}

@inproceedings{kumar_NILE_2020,
Author = {Sawan Kumar and Partha Talukdar},
Title = {NILE : Natural Language Inference with Faithful Natural Language Explanations},
booktitle = {ACL 2020},
Year = {2020},
url = {https://arxiv.org/abs/2005.12116}
}

@article{li_understanding_2016,
	title = {Understanding {Neural} {Networks} through {Representation} {Erasure}},
	url = {http://arxiv.org/abs/1612.08220},
	urldate = {2019-11-04},
	journal = {arXiv:1612.08220 [cs]},
	author = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	year = {2016},
	note = {arXiv: 1612.08220},
	keywords = {Computer Science - Computation and Language},
}

@article{platt,
author = {Platt, John},
year = {2000},
month = {06},
pages = {},
title = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
volume = {10},
journal = {Adv. Large Margin Classif.}
}

@inproceedings{hooker_benchmark_2019,
Author = {Sara Hooker and Dumitru Erhan and Pieter-Jan Kindermans and Been Kim},
Title = {A Benchmark for Interpretability Methods in Deep Neural Networks},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
url = {https://arxiv.org/abs/1806.10758},
Year = {2019},
Eprint = {arXiv:1806.10758},
}


@inproceedings{lowe_pitfalls_2019,
  title={On the Pitfalls of Measuring Emergent Communication},
  author={Ryan Lowe and Jakob N. Foerster and Y-Lan Boureau and Joelle Pineau and Yann Dauphin},
  booktitle={AAMAS 2019},
  year={2019},
  url={https://arxiv.org/pdf/1903.05168.pdf}
}


@book{efron1994introduction,
 title={An Introduction to the Bootstrap},
 author={Efron, Bradley and Tibshirani, Robert J},
 year={1994},
 publisher={CRC press}
}
@inproceedings{jacovi2020towards,
    title = {Towards Faithfully Interpretable NLP Systems: How should we define and evaluate faithfulness?},
    author = {Alon Jacovi and Yoav Goldberg},
  booktitle={ACL 2020},
  year={2020},
  url = {https://www.aclweb.org/anthology/2020.acl-main.386.pdf}
}

@article{jacovi2021aligning,
  title={Aligning faithful interpretations with their social attribution},
  author={Jacovi, Alon and Goldberg, Yoav},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={294--310},
  year={2021},
url={https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00367/98620/Aligning},
  publisher={MIT Press}
}

@book{cohen1988,
  added-at = {2017-03-30T21:37:25.000+0200},
  author = {Cohen, Jacob},
  biburl = {https://www.bibsonomy.org/bibtex/2a06021817e224b8dca50df7c138c128d/sveng},
  interhash = {ab4b29867f1552a9ab20b69edf9df19d},
  intrahash = {a06021817e224b8dca50df7c138c128d},
  isbn = {9780805802832},
  keywords = {- / Analysis, General, Mathematics Methodology, Multivariate Probabilities, Probability Probability, Psychology Research Science Social Statistical Statistics Statistics, \& analysis, methods, power sciences sciences, sciences/ statistic –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞—É–∫–∞,},
  publisher = {Routledge},
  timestamp = {2017-04-01T10:50:30.000+0200},
  title = {Statistical Power Analysis for the Behavioral Sciences},
  year = 1988
}


@article{pavlick2019,
author = {Pavlick, Ellie and Kwiatkowski, Tom},
title = {Inherent Disagreements in Human Textual Inferences},
journal = {Transactions of the Association for Computational Linguistics},
volume = {7},
number = {},
pages = {677-694},
year = {2019},
doi = {10.1162/tacl\_a\_00293},
URL = { 
        https://doi.org/10.1162/tacl_a_00293
    
},
eprint = { 
        https://doi.org/10.1162/tacl_a_00293
    
}
}

@inproceedings{lazaridou2020,
  author    = {Angeliki Lazaridou and
               Anna Potapenko and
               Olivier Tieleman},
  title     = {Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning},
  booktitle = {ACL 2020},
  pages     = {7663--7674},
  publisher = {Association for Computational Linguistics},
  year      = {2020},
  url       = {https://www.aclweb.org/anthology/2020.acl-main.685/},
  timestamp = {Wed, 24 Jun 2020 17:15:07 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/LazaridouPT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bastings-2019-interpretable,
    title = "Interpretable Neural Predictions with Differentiable Binary Variables",
    author = "Bastings, Jasmijn  and
      Aziz, Wilker  and
      Titov, Ivan",
    booktitle = {ACL 2019},
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1284",
    doi = "10.18653/v1/P19-1284",
    pages = "2963--2977",
}

@inproceedings{jain2020,
    title = "Learning to Faithfully Rationalize by Construction",
    author = "Jain, Sarthak  and
      Wiegreffe, Sarah  and
      Pinter, Yuval  and
      Wallace, Byron C.",
    booktitle = {ACL 2020},
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.409",
    doi = "10.18653/v1/2020.acl-main.409",
    pages = "4459--4473",
}

@article{dodge2020,
  author    = {Jesse Dodge and
               Gabriel Ilharco and
               Roy Schwartz and
               Ali Farhadi and
               Hannaneh Hajishirzi and
               Noah A. Smith},
  title     = {Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping},
  journal   = {CoRR},
  volume    = {abs/2002.06305},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.06305},
  archivePrefix = {arXiv},
  eprint    = {2002.06305},
  timestamp = {Mon, 02 Mar 2020 16:46:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-06305.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{post2018call,
  title={A Call for Clarity in Reporting BLEU Scores},
  author={Post, Matt},
  booktitle={Proceedings of the Third Conference on Machine Translation: Research Papers},
  pages={186--191},
  year={2018}
}

@inproceedings{talmor2020teaching,
  author    = {Alon Talmor and
               Oyvind Tafjord and
               Peter Clark and
               Yoav Goldberg and
               Jonathan Berant},
  title     = {Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge},
  booktitle  = {NeurIPS 2020},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.06609},
  archivePrefix = {arXiv},
  eprint    = {2006.06609},
  timestamp = {Sat, 13 Jun 2020 18:28:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-06609.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Co-Reyes2019Guiding,
  author    = {John D. Co{-}Reyes and
               Abhishek Gupta and
               Suvansh Sanjeev and
               Nick Altieri and
               Jacob Andreas and
               John DeNero and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Guiding Policies with Language via Meta-Learning},
  booktitle = {{ICLR} 2019},
  year      = {2019},
  url       = {https://openreview.net/forum?id=HkgSEnA5KQ},
  timestamp = {Thu, 25 Jul 2019 14:25:52 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/Co-ReyesGSAADAL19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rupprecht2018guide,
    author = "Rupprecht, Christian and Laina, Iro and Navab, Nassir and Harger, Gregory D. and Tombari, Federico",
    title = "Guide Me: Interacting with Deep Networks",
    booktitle = "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, {CVPR 2018}",
    url={https://arxiv.org/abs/1803.11544},
    year = "2018"
}

@inproceedings{ba2016using,
  author    = {Jimmy Ba and
               Geoffrey E. Hinton and
               Volodymyr Mnih and
               Joel Z. Leibo and
               Catalin Ionescu},
  editor    = {Daniel D. Lee and
               Masashi Sugiyama and
               Ulrike von Luxburg and
               Isabelle Guyon and
               Roman Garnett},
  title     = {Using Fast Weights to Attend to the Recent Past},
  booktitle = {NeurIPS 2016},
  year      = {2016},
  url       = {http://papers.nips.cc/paper/6057-using-fast-weights-to-attend-to-the-recent-past},
  timestamp = {Fri, 06 Mar 2020 17:00:15 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/BaHMLI16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{Munkhdalai2019Metalearned,
  author    = {Tsendsuren Munkhdalai and
               Alessandro Sordoni and
               Tong Wang and
               Adam Trischler},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Metalearned Neural Memory},
  booktitle = {NeurIPS 2019},
  pages     = {13310--13321},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/9488-metalearned-neural-memory},
  timestamp = {Fri, 06 Mar 2020 16:59:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/MunkhdalaiSWT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Srivastava2018LearningCF,
  title={Learning Classifiers from Declarative Language},
  author={Shashank Srivastava and I. Labutov and T. Mitchell},
  year={2017},
  booktitle={NeurIPS 2017},
  url={http://www.cs.cmu.edu/~shashans/papers/srivastava17-lldworkshop.pdf},
}

@inproceedings{awasthi2020learning,
  author    = {Abhijeet Awasthi and
               Sabyasachi Ghosh and
               Rasna Goyal and
               Sunita Sarawagi},
  title     = {Learning from Rules Generalizing Labeled Exemplars},
  booktitle = {ICLR 2020},
  year      = {2020},
  url       = {https://arxiv.org/pdf/2004.06025.pdf},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/AwasthiGGS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{huang2020counterfactually,
  author    = {William Huang and
               Haokun Liu and
               Samuel R. Bowman},
  title     = {Counterfactually-Augmented {SNLI} Training Data Does Not Yield Better
               Generalization Than Unaugmented Data},
  journal   = {CoRR},
  volume    = {abs/2010.04762},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.04762},
  archivePrefix = {arXiv},
  eprint    = {2010.04762},
  timestamp = {Tue, 20 Oct 2020 15:08:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-04762.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kaushik2020learning,
  author    = {Divyansh Kaushik and
               Eduard H. Hovy and
               Zachary Chase Lipton},
  title     = {Learning The Difference That Makes {A} Difference With Counterfactually-Augmented
               Data},
  booktitle = {ICLR 2020},
  year      = {2020},
  url       = {https://arxiv.org/abs/1909.12434},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/KaushikHL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{andreas2018learning,
  author    = {Jacob Andreas and
               Dan Klein and
               Sergey Levine},
  editor    = {Marilyn A. Walker and
               Heng Ji and
               Amanda Stent},
  title     = {Learning with Latent Language},
  booktitle = {NAACL-HLT 2018},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/n18-1197},
  doi       = {10.18653/v1/n18-1197},
  timestamp = {Tue, 28 Jan 2020 10:30:21 +0100},
  biburl    = {https://dblp.org/rec/conf/naacl/AndreasKL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{garnelo2018conditional,
  author    = {Marta Garnelo and
               Dan Rosenbaum and
               Christopher Maddison and
               Tiago Ramalho and
               David Saxton and
               Murray Shanahan and
               Yee Whye Teh and
               Danilo Jimenez Rezende and
               S. M. Ali Eslami},
  editor    = {Jennifer G. Dy and
               Andreas Krause},
  title     = {Conditional Neural Processes},
  booktitle = {ICML 2018},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v80/garnelo18a.html},
  timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/GarneloRMRSSTRE18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{requeima2019fast,
  author    = {James Requeima and
               Jonathan Gordon and
               John Bronskill and
               Sebastian Nowozin and
               Richard E. Turner},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Fast and Flexible Multi-Task Classification using Conditional Neural
               Adaptive Processes},
  booktitle = {NeurIPS 2019},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/9009-fast-and-flexible-multi-task-classification-using-conditional-neural-adaptive-processes},
  timestamp = {Fri, 06 Mar 2020 16:59:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/Requeima0BNT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kim2019attentive,
  author    = {Hyunjik Kim and
               Andriy Mnih and
               Jonathan Schwarz and
               Marta Garnelo and
               S. M. Ali Eslami and
               Dan Rosenbaum and
               Oriol Vinyals and
               Yee Whye Teh},
  title     = {Attentive Neural Processes},
  booktitle = {ICLR 2019},
  year      = {2019},
  url       = {https://openreview.net/forum?id=SkE6PjC9KX},
  timestamp = {Thu, 25 Jul 2019 14:25:41 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/KimMSGERVT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hinton1987using,
  title={Using fast weights to deblur old memories},
  author={Hinton, Geoffrey E and Plaut, David C},
  booktitle={Proceedings of the ninth annual conference of the Cognitive Science Society},
  url={http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.1011},
  year={1987}
}

@inproceedings{srivastava2018zero,
    title = "Zero-shot Learning of Classifiers from Natural Language Quantification",
    author = "Srivastava, Shashank  and
      Labutov, Igor  and
      Mitchell, Tom",
    booktitle = "ACL 2018",
    month = jul,
    year = "2018",
    url = "https://www.aclweb.org/anthology/P18-1029",
    doi = "10.18653/v1/P18-1029",
}

@article{sikka2020deep,
  title={Deep Adaptive Semantic Logic (DASL): Compiling Declarative Knowledge into Deep Neural Networks},
  author={Sikka, Karan and Silberfarb, Andrew and Byrnes, John and Sur, Indranil and Chow, Ed and Divakaran, Ajay and Rohwer, Richard},
  journal={arXiv preprint arXiv:2003.07344},
  year={2020},
  url={https://arxiv.org/pdf/2003.07344.pdf}
}

@article{mu2020compositional,
  title={Compositional explanations of neurons},
  author={Mu, Jesse and Andreas, Jacob},
  journal={arXiv preprint arXiv:2006.14032},
  year={2020},
  url={https://arxiv.org/pdf/2006.14032.pdf}
}

@inproceedings{nie-etal-2020-adversarial,
    title = "Adversarial {NLI}: A New Benchmark for Natural Language Understanding",
    author = "Nie, Yixin  and
      Williams, Adina  and
      Dinan, Emily  and
      Bansal, Mohit  and
      Weston, Jason  and
      Kiela, Douwe",
    booktitle = "ACL 2020",
    month = jul,
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.acl-main.441",
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={ICML 2017},
  year={2017},
  url={https://arxiv.org/pdf/1703.04730.pdf}
}

@InProceedings{perez2018film,
  title={FiLM: Visual Reasoning with a General Conditioning Layer},
  author={Ethan Perez and Florian Strub and Harm de Vries and Vincent Dumoulin and Aaron C. Courville},
  booktitle={AAAI},
  url={https://arxiv.org/pdf/1709.07871.pdf},
  year={2018}
}

@InProceedings{ha2016hypernetworks,
  title={Hypernetworks},
  booktitle={ICLR 2017},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  url={https://openreview.net/pdf?id=rkpACe1lx},
  year={2017}
}

@inproceedings{hase2020leakage,
  author    = {Peter Hase and
               Shiyue Zhang and
               Harry Xie and
               Mohit Bansal},
  title     = {Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?},
  booktitle   = {Findings of EMNLP},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.04119},
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1885--1894},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{lipton2017,
Author = {Zachary C. Lipton},
Title = {The Mythos of Model Interpretability},
booktitle = {2016 ICML Workshop on Human Interpretability in Machine Learning},
Year = {2016},
Eprint = {arXiv:1606.03490},
}

@INPROCEEDINGS{gilpin2019,  
author={L. H. {Gilpin} and D. {Bau} and B. Z. {Yuan} and A. {Bajwa} and M. {Specter} and L. {Kagal}},  booktitle={2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)},   title={Explaining Explanations: An Overview of Interpretability of Machine Learning},   year={2018},  volume={},  number={},  pages={80-89},}

@inproceedings{han2020explaining,
Author = {Xiaochuang Han and Byron C. Wallace and Yulia Tsvetkov},
Title = {Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions},
booktitle={ACL},
Year = {2020},
Eprint = {arXiv:2005.06676},
}

@article{hase2020evaluating,
  title={Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?},
  author={Hase, Peter and Bansal, Mohit},
  journal={ACL},
  year={2020}
}

@inproceedings{li_visualizing_2016,
	title = {Visualizing and {Understanding} {Neural} {Models} in {NLP}},
	url = {https://www.aclweb.org/anthology/N16-1082},
	doi = {10.18653/v1/N16-1082},
	urldate = {2019-06-27},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Jiwei and Chen, Xinlei and Hovy, Eduard and Jurafsky, Dan},
	month = jun,
	year = {2016},
	pages = {681--691},
}

@inproceedings{kim_interpretability_2018,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}


@inproceedings{ribeiro_anchors_2018,
	author = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
	url = {https://homes.cs.washington.edu/~marcotcr/aaai18.pdf},
	title = {Anchors: High-Precision Model-Agnostic Explanations},
	booktitle = {AAAI Conference on Artificial Intelligence},
	year = {2018}
}


@inproceedings{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
	urldate = {2019-11-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	author = {Lundberg, Scott M and Lee, Su-In},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {4765--4774},
}

@article{olah_building_2018,
	title = {The {Building} {Blocks} of {Interpretability}},
	volume = {3},
	issn = {2476-0757},
	url = {https://distill.pub/2018/building-blocks},
	doi = {10.23915/distill.00010},
	abstract = {Interpretability techniques are normally studied in isolation. We explore the powerful interfaces that arise when you combine them -- and the rich structure of this combinatorial space.},
	language = {en},
	number = {3},
	urldate = {2020-03-18},
	journal = {Distill},
	author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	month = mar,
	year = {2018},
	pages = {e10},
}
@article{olah2020an,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {An Overview of Early Vision in InceptionV1},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/early-vision},
  doi = {10.23915/distill.00024.002}
}
@article{mu2020compositional,
  title={Compositional explanations of neurons},
  author={Mu, Jesse and Andreas, Jacob},
  url={https://arxiv.org/pdf/2006.14032.pdf},
  journal={arXiv preprint arXiv:2006.14032},
  year={2020}
}

@article{cook1977detection,
  title={Detection of influential observation in linear regression},
  author={Cook, R Dennis},
  journal={Technometrics},
  volume={19},
  number={1},
  pages={15--18},
  year={1977},
  publisher={Taylor \& Francis Group}
}

@article{cook1986assessment,
  title={Assessment of local influence},
  author={Cook, R Dennis},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={48},
  number={2},
  pages={133--155},
  year={1986},
  publisher={Wiley Online Library}
}

@article{cook1980characterizations,
  title={Characterizations of an empirical influence function for detecting influential cases in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  journal={Technometrics},
  volume={22},
  number={4},
  pages={495--508},
  year={1980},
  publisher={Taylor \& Francis}
}

@book{cook1982residuals,
  title={Residuals and influence in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  year={1982},
  publisher={New York: Chapman and Hall}
}

@article{chatterjee1986influential,
  title={Influential observations, high leverage points, and outliers in linear regression},
  author={Chatterjee, Samprit and Hadi, Ali S and others},
  journal={Statistical science},
  volume={1},
  number={3},
  pages={379--393},
  year={1986},
  publisher={Institute of Mathematical Statistics}
}

@article{thomas1990assessing,
  title={Assessing influence on predictions from generalized linear models},
  author={Thomas, William and Cook, R Dennis},
  journal={Technometrics},
  volume={32},
  number={1},
  pages={59--65},
  year={1990},
  publisher={Taylor \& Francis}
}

@article{wei1998generalized,
  title={Generalized leverage and its applications},
  author={Wei, Bo-Cheng and Hu, Yue-Qing and Fung, Wing-Kam},
  journal={Scandinavian Journal of statistics},
  volume={25},
  number={1},
  pages={25--37},
  year={1998},
  publisher={Wiley Online Library}
}

@book{faraway2016extending,
  title={Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models},
  author={Faraway, Julian J},
  year={2016},
  publisher={CRC press}
}

@article{christmann2004robustness,
  title={On robustness properties of convex risk minimization methods for pattern recognition},
  author={Christmann, Andreas and Steinwart, Ingo},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={Aug},
  pages={1007--1034},
  year={2004}
}

@article{debruyne2008model,
  title={Model selection in kernel based regression using the influence function},
  author={Debruyne, Michiel and Hubert, Mia and Suykens, Johan AK},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Oct},
  pages={2377--2400},
  year={2008}
}

@inproceedings{liu2014efficient,
  title={Efficient approximation of cross-validation for kernel methods using Bouligand influence function},
  author={Liu, Yong and Jiang, Shali and Liao, Shizhong},
  booktitle={International Conference on Machine Learning},
  pages={324--332},
  year={2014}
}

@article{basu2020influence,
  title={Influence functions in deep learning are fragile},
  author={Basu, Samyadeep and Pope, Philip and Feizi, Soheil},
  journal={arXiv preprint arXiv:2006.14651},
  year={2020}
}

@inproceedings{koh2019accuracy,
  title={On the accuracy of influence functions for measuring group effects},
  author={Koh, Pang Wei W and Ang, Kai-Siang and Teo, Hubert and Liang, Percy S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5254--5264},
  year={2019}
}

@inproceedings{yang2020g,
  title={G-DAUG: Generative Data Augmentation for Commonsense Reasoning},
  author={Yang, Yiben and Malaviya, Chaitanya and Fernandez, Jared and Swayamdipta, Swabha and Bras, Ronan Le and Wang, Ji-Ping and Bhagavatula, Chandra and Choi, Yejin and Downey, Doug},
  booktitle={Findings of EMNLP},
  year={2020}
}

@inproceedings{ghorbani2019data,
  title={Data Shapley: Equitable Valuation of Data for Machine Learning},
  author={Ghorbani, Amirata and Zou, James},
  booktitle={International Conference on Machine Learning},
  pages={2242--2251},
  year={2019}
}

@article{ghorbani2020distributional,
  title={A Distributional Framework for Data Valuation},
  author={Ghorbani, Amirata and Kim, Michael P and Zou, James},
  journal={ICML},
  year={2020}
}

@article{belinkov2019analysis,
  title={Analysis methods in neural language processing: A survey},
  author={Belinkov, Yonatan and Glass, James},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={49--72},
  year={2019},
  publisher={MIT Press}
}

@inproceedings{jain2019attention,
  title={Attention is not Explanation},
  author={Jain, Sarthak and Wallace, Byron C},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={3543--3556},
  year={2019}
}

@inproceedings{wiegreffe2019attention,
  title={Attention is not not Explanation},
  author={Wiegreffe, Sarah and Pinter, Yuval},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={11--20},
  year={2019},
  url={https://arxiv.org/pdf/1908.04626.pdf},
}

@article{zhong2019fine,
  title={Fine-grained sentiment analysis with faithful attention},
  author={Zhong, Ruiqi and Shao, Steven and McKeown, Kathleen},
  journal={arXiv preprint arXiv:1908.06870},
  url={https://arxiv.org/pdf/1908.06870.pdf},
  year={2019}
}

@article{simonyan_2013_deep,
  title={Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={Workshop at International Conference on Learning Representations.},
  year={2013},
  url={https://arxiv.org/pdf/1312.6034.pdf}
}

@inproceedings{shrikumar2017learning,
  title={Learning Important Features Through Propagating Activation Differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={International Conference on Machine Learning},
  pages={3145--3153},
  year={2017},
  url={https://arxiv.org/pdf/1704.02685.pdf}
}

@inproceedings{sundararajan_2017_axiomatic,
  title={Axiomatic Attribution for Deep Networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International Conference on Machine Learning},
  pages={3319--3328},
  year={2017},
  url={https://arxiv.org/pdf/1703.01365.pdf}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017},
  url={https://arxiv.org/pdf/1706.03825.pdf}
}

@inproceedings{feng2018pathologies,
  title={Pathologies of Neural Models Make Interpretations Difficult},
  author={Feng, Shi and Wallace, Eric and Grissom II, Alvin and Iyyer, Mohit and Rodriguez, Pedro and Boyd-Graber, Jordan},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={3719--3728},
  year={2018}
}

@inproceedings{ribeiro2020beyond,
  author = {Marco Tulio Ribeiro and Tongshuang Wu and Carlos Guestrin and Sameer Singh},  
  title = {Beyond Accuracy: Behavioral Testing of NLP models with CheckList},  
  booktitle = {Association for Computational Linguistics (ACL)},  
  year = {2020}  
}

@inproceedings{wallace2019allennlp,
  title={AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models},
  author={Wallace, Eric and Tuyls, Jens and Wang, Junlin and Subramanian, Sanjay and Gardner, Matt and Singh, Sameer},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations},
  pages={7--12},
  year={2019}
}


@inproceedings{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  booktitle={Advances in neural information processing systems},
  pages={8930--8941},
  year={2019}
}

@inproceedings{hase2019interpretable,
  title={Interpretable Image Recognition with Hierarchical Prototypes},
  author={Hase, Peter and Chen, Chaofan and Li, Oscar and Rudin, Cynthia},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  year={2019}
}

@article{joshi2018xgems,
  title={xGEMs: Generating examplars to explain black-box models},
  author={Joshi, Shalmali and Koyejo, Oluwasanmi and Kim, Been and Ghosh, Joydeep},
  journal={arXiv preprint arXiv:1806.08867},
  year={2018}
}

@inproceedings{samangouei2018explaingan,
  title={Explaingan: Model explanation via decision boundary crossing transformations},
  author={Samangouei, Pouya and Saeedi, Ardavan and Nakagawa, Liam and Silberman, Nathan},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={666--681},
  year={2018}
}

@article{rajani2020explaining,
  title={Explaining and Improving Model Behavior with k Nearest Neighbor Representations},
  author={Rajani, Nazneen Fatema and Krause, Ben and Yin, Wengpeng and Niu, Tong and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:2010.09030},
  year={2020},
}

@article{Meng2020PairTD,
  title={Pair the Dots: Jointly Examining Training History and Test Stimuli for Model Interpretability},
  author={Yuxian Meng and C. Fan and Zijun Sun and E. Hovy and Fei Wu and J. Li},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.06943},
  url={https://arxiv.org/abs/2010.06943}
}

@article{agarwal2017second,
  title={Second-Order Stochastic Optimization for Machine Learning in Linear Time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={116},
  pages={1--40},
  year={2017}
}

@incollection{NEURIPS2019_9015,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems 32},
    pages = {8024--8035},
    year = {2019},
    publisher = {Curran Associates, Inc.},
    url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{lee2019would,
  title={What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning},
  author={Lee, Jaejun and Tang, Raphael and Lin, Jimmy},
  journal={arXiv preprint arXiv:1911.03090},
  year={2019}
}

@inproceedings{kobayashi-etal-2020-efficient,
    title = "Efficient Estimation of Influence of a Training Instance",
    author = "Kobayashi, Sosuke  and
      Yokoi, Sho  and
      Suzuki, Jun  and
      Inui, Kentaro",
    booktitle = "Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.sustainlp-1.6",
    pages = "41--47",
    abstract = "Understanding the influence of a training instance on a neural network model leads to improving interpretability. However, it is difficult and inefficient to evaluate the influence, which shows how a model{'}s prediction would be changed if a training instance were not used. In this paper, we propose an efficient method for estimating the influence. Our method is inspired by dropout, which zero-masks a sub-network and prevents the sub-network from learning each training instance. By switching between dropout masks, we can use sub-networks that learned or did not learn each training instance and estimate its influence. Through experiments with BERT and VGGNet on classification datasets, we demonstrate that the proposed method can capture training influences, enhance the interpretability of error predictions, and cleanse the training dataset for improving generalization.",
}

@inproceedings{treviso-martins-2020-explanation,
    title = "The Explanation Game: Towards Prediction Explainability through Sparse Communication",
    author = "Treviso, Marcos  and
      Martins, Andr{\'e} F. T.",
    booktitle = "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.blackboxnlp-1.10",
    pages = "107--118",
}

@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@inproceedings{mccoy2019right,
  title={Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
  author={McCoy, Tom and Pavlick, Ellie and Linzen, Tal},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3428--3448},
  year={2019}
}

@inproceedings{williams2018broad,
  title={A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  booktitle={Proceedings of NAACL-HLT},
  pages={1112--1122},
  year={2018}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@inproceedings{schulam2019can,
  title={Can You Trust This Prediction? Auditing Pointwise Reliability After Learning},
  author={Schulam, Peter and Saria, Suchi},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1022--1031},
  year={2019}
}

@inproceedings{brunet2019understanding,
  title={Understanding the origins of bias in word embeddings},
  author={Brunet, Marc-Etienne and Alkalay-Houlihan, Colleen and Anderson, Ashton and Zemel, Richard},
  booktitle={International Conference on Machine Learning},
  pages={803--811},
  year={2019},
  organization={PMLR}
}

@article{koh2018stronger,
  title={Stronger data poisoning attacks break data sanitization defenses},
  author={Koh, Pang Wei and Steinhardt, Jacob and Liang, Percy},
  journal={arXiv preprint arXiv:1811.00741},
  year={2018}
}

@inproceedings{basu2020second,
  title={On Second-Order Group Influence Functions for Black-Box Predictions},
  author={Basu, Samyadeep and You, Xuchen and Feizi, Soheil},
  booktitle={International Conference on Machine Learning},
  pages={715--724},
  year={2020},
  organization={PMLR}
}

@inproceedings{jia2019towards,
  title={Towards Efficient Data Valuation Based on the Shapley Value},
  author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G{\"u}rel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1167--1176},
  year={2019}
}

@article{jia2019efficient,
  title={Efficient task-specific data valuation for nearest neighbor algorithms},
  author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Gurel, Nezihe Merve and Li, Bo and Zhang, Ce and Spanos, Costas and Song, Dawn},
  journal={Proceedings of the VLDB Endowment},
  volume={12},
  number={11},
  pages={1610--1623},
  year={2019},
  publisher={VLDB Endowment}
}

@article{kwon2020efficient,
  title={Efficient computation and analysis of distributional Shapley values},
  author={Kwon, Yongchan and Rivas, Manuel A and Zou, James},
  journal={arXiv preprint arXiv:2007.01357},
  year={2020}
}

@inproceedings{khandelwal2019generalization,
  title={Generalization through Memorization: Nearest Neighbor Language Models},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{feldman2020neural,
  title={What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@article{papernot_deep_2018,
	title = {Deep k-{Nearest} {Neighbors}: {Towards} {Confident}, {Interpretable} and {Robust} {Deep} {Learning}},
	shorttitle = {Deep k-{Nearest} {Neighbors}},
	url = {http://arxiv.org/abs/1803.04765},
	urldate = {2019-11-05},
	journal = {arXiv:1803.04765 [cs, stat]},
	author = {Papernot, Nicolas and McDaniel, Patrick},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.04765},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}


@article{wiegreffe2020,
  author    = {Sarah Wiegreffe and
               Ana Marasovic and
               Noah A. Smith},
  title     = {Measuring Association Between Labels and Free-Text Rationales},
  journal   = {CoRR},
  volume    = {abs/2010.12762},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.12762},
  archivePrefix = {arXiv},
  eprint    = {2010.12762},
  timestamp = {Mon, 02 Nov 2020 18:17:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-12762.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{pruthi2020,
  author    = {Danish Pruthi and
               Bhuwan Dhingra and
               Livio Baldini Soares and
               Michael Collins and
               Zachary C. Lipton and
               Graham Neubig and
               William W. Cohen},
  title     = {Evaluating Explanations: How much do explanations from the teacher
               aid students?},
  journal   = {CoRR},
  volume    = {abs/2012.00893},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.00893},
  archivePrefix = {arXiv},
  eprint    = {2012.00893},
  timestamp = {Fri, 04 Dec 2020 12:07:23 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-00893.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{li2016understanding,
  title={Understanding Neural Networks through Representation Erasure},
  author={Li, Jiwei and Monroe, Will and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1612.08220},
  year={2016},
  url={https://arxiv.org/pdf/1612.08220.pdf}
}

@article{wolf2019huggingface,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={ArXiv},
  pages={arXiv--1910},
  year={2019}
}

@inproceedings{zaidan-etal-2007-using,
    title = "Using {``}Annotator Rationales{''} to Improve Machine Learning for Text Categorization",
    author = "Zaidan, Omar  and
      Eisner, Jason  and
      Piatko, Christine",
    booktitle = "NAACL HLT",
    month = apr,
    year = "2007",
    address = "Rochester, New York",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N07-1033",
    pages = "260--267",
}

@inproceedings{small2011constrained,
  title={The constrained weight space svm: learning with ranked features},
  author={Small, Kevin and Wallace, Byron C and Brodley, Carla E and Trikalinos, Thomas A},
  booktitle={ICML},
  pages={865--872},
  year={2011},
  urk = {https://icml.cc/2011/papers/465_icmlpaper.pdf}
}

@inproceedings{zhang-etal-2016-rationale,
    title = "Rationale-Augmented Convolutional Neural Networks for Text Classification",
    author = "Zhang, Ye  and
      Marshall, Iain  and
      Wallace, Byron C.",
    booktitle = "EMNLP",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1076",
    doi = "10.18653/v1/D16-1076",
    pages = "795--804",
}


@inproceedings{wang2019learning,
  title={Learning from explanations with neural execution tree},
  author={Wang, Ziqi and Qin, Yujia and Zhou, Wenxuan and Yan, Jun and Ye, Qinyuan and Neves, Leonardo and Liu, Zhiyuan and Ren, Xiang},
  booktitle={ICLR},
  year={2019},
  url={https://openreview.net/pdf?id=rJlUt0EYwS}
}

@inproceedings{bao-etal-2018-deriving,
    title = "Deriving Machine Attention from Human Rationales",
    author = "Bao, Yujia  and
      Chang, Shiyu  and
      Yu, Mo  and
      Barzilay, Regina",
    booktitle = "EMNLP",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1216",
    doi = "10.18653/v1/D18-1216",
    pages = "1903--1913",
}

@inproceedings{zhou2020towards,
  title={Towards Interpretable Natural Language Understanding with Explanations as Latent Variables},
  author={Zhou, Wangchunshu and Hu, Jinyi and Zhang, Hanlin and Liang, Xiaodan and Sun, Maosong and Xiong, Chenyan and Tang, Jian},
  booktitle={NeurIPS},
  year={2020},
  url={https://arxiv.org/pdf/2011.05268.pdf}
}

@inproceedings{zhao2020lirex,
  title={LIREx: Augmenting language inference with relevant explanation},
  author={Zhao, Xinyan and Vydiswaran, VG},
  booktitle={AAAI},
  year={2021}
}

@inproceedings{liang2020alice,
  author    = {Weixin Liang and
               James Zou and
               Zhou Yu},
  editor    = {Bonnie Webber and
               Trevor Cohn and
               Yulan He and
               Yang Liu},
  title     = {{ALICE:} Active Learning with Contrastive Natural Language Explanations},
  booktitle = {EMNLP},
  pages     = {4380--4391},
  publisher = {Association for Computational Linguistics},
  year      = {2020},
  url       = {https://www.aclweb.org/anthology/2020.emnlp-main.355/},
  timestamp = {Thu, 19 Nov 2020 16:13:16 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/LiangZY20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{murty2020expbert,author    = {Shikhar Murty and
               Pang Wei Koh and
               Percy Liang},
  editor    = {Dan Jurafsky and
               Joyce Chai and
               Natalie Schluter and
               Joel R. Tetreault},
  title     = {ExpBERT: Representation Engineering with Natural Language Explanations},
  booktitle = {ACL},
  pages     = {2106--2113},
  publisher = {Association for Computational Linguistics},
  year      = {2020},
  url       = {https://www.aclweb.org/anthology/2020.acl-main.190/},
  timestamp = {Wed, 24 Jun 2020 17:15:07 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/MurtyKL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ba2015predicting,
  author    = {Lei Jimmy Ba and
               Kevin Swersky and
               Sanja Fidler and
               Ruslan Salakhutdinov},
  title     = {Predicting Deep Zero-Shot Convolutional Neural Networks Using Textual
               Descriptions},
  booktitle = {2015 {IEEE} International Conference on Computer Vision, {ICCV} 2015,
               Santiago, Chile, December 7-13, 2015},
  pages     = {4247--4255},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  url       = {https://doi.org/10.1109/ICCV.2015.483},
  doi       = {10.1109/ICCV.2015.483},
  timestamp = {Wed, 16 Oct 2019 14:14:51 +0200},
  biburl    = {https://dblp.org/rec/conf/iccv/BaSFS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lewis2020retrieval,
  author    = {Patrick S. H. Lewis and
               Ethan Perez and
               Aleksandra Piktus and
               Fabio Petroni and
               Vladimir Karpukhin and
               Naman Goyal and
               Heinrich K{\"{u}}ttler and
               Mike Lewis and
               Wen{-}tau Yih and
               Tim Rockt{\"{a}}schel and
               Sebastian Riedel and
               Douwe Kiela},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle = {NeurIPS},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.11401},
  timestamp = {Fri, 04 Dec 2020 15:22:44 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/LewisPPPKGKLYR020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{weller-etal-2020-learning,
    title = "Learning from Task Descriptions",
    author = "Weller, Orion  and
      Lourie, Nicholas  and
      Gardner, Matt  and
      Peters, Matthew",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.105",
    doi = "10.18653/v1/2020.emnlp-main.105",
    pages = "1361--1375",
}

@inproceedings{roberts-etal-2020-much,
    title = "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
    author = "Roberts, Adam  and
      Raffel, Colin  and
      Shazeer, Noam",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.437",
    doi = "10.18653/v1/2020.emnlp-main.437",
    pages = "5418--5426",
}

@inproceedings{gpt3,
  author    = {Tom B. Brown and
               Benjamin Mann and
               Nick Ryder and
               Melanie Subbiah and
               Jared Kaplan and
               Prafulla Dhariwal and
               Arvind Neelakantan and
               Pranav Shyam and
               Girish Sastry and
               Amanda Askell and
               Sandhini Agarwal and
               Ariel Herbert{-}Voss and
               Gretchen Krueger and
               Tom Henighan and
               Rewon Child and
               Aditya Ramesh and
               Daniel M. Ziegler and
               Jeffrey Wu and
               Clemens Winter and
               Christopher Hesse and
               Mark Chen and
               Eric Sigler and
               Mateusz Litwin and
               Scott Gray and
               Benjamin Chess and
               Jack Clark and
               Christopher Berner and
               Sam McCandlish and
               Alec Radford and
               Ilya Sutskever and
               Dario Amodei},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Language Models are Few-Shot Learners},
  booktitle = {NeurIPS},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.14165},
  timestamp = {Fri, 04 Dec 2020 15:22:44 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/BrownMRSKDNSSAA20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{de-cao-etal-2020-decisions,
    title = "How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking",
    author = "De Cao, Nicola  and
      Schlichtkrull, Michael Sejr  and
      Aziz, Wilker  and
      Titov, Ivan",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.262",
    doi = "10.18653/v1/2020.emnlp-main.262",
    pages = "3243--3255",
}

@inproceedings{karpukhin-etal-2020-dense,
    title = "Dense Passage Retrieval for Open-Domain Question Answering",
    author = "Karpukhin, Vladimir  and
      Oguz, Barlas  and
      Min, Sewon  and
      Lewis, Patrick  and
      Wu, Ledell  and
      Edunov, Sergey  and
      Chen, Danqi  and
      Yih, Wen-tau",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.550",
    doi = "10.18653/v1/2020.emnlp-main.550",
    pages = "6769--6781",
}

@article{JDH17,
  title={Billion-scale similarity search with GPUs},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  year={2017},
  url={https://arxiv.org/pdf/1702.08734.pdf},
}

@article{miller2019explanation,
  author    = {Tim Miller},
  title     = {Explanation in artificial intelligence: Insights from the social sciences},
  journal   = {Artif. Intell.},
  volume    = {267},
  pages     = {1--38},
  year      = {2019},
  url       = {https://doi.org/10.1016/j.artint.2018.07.007},
  doi       = {10.1016/j.artint.2018.07.007},
  timestamp = {Fri, 25 Dec 2020 01:14:07 +0100},
  biburl    = {https://dblp.org/rec/journals/ai/Miller19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{madumal2020explainable,
  author    = {Prashan Madumal and
               Tim Miller and
               Liz Sonenberg and
               Frank Vetere},
  title     = {Explainable Reinforcement Learning through a Causal Lens},
  booktitle = {AAAI},
  pages     = {2493--2500},
  publisher = {{AAAI} Press},
  year      = {2020},
  url       = {https://aaai.org/ojs/index.php/AAAI/article/view/5631},
  timestamp = {Fri, 05 Jun 2020 09:50:08 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/Madumal0SV20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{reed2017few-shot,
  author    = {Scott E. Reed and
               Yutian Chen and
               Thomas Paine and
               A{\"{a}}ron van den Oord and
               S. M. Ali Eslami and
               Danilo Jimenez Rezende and
               Oriol Vinyals and
               Nando de Freitas},
  title     = {Few-shot Autoregressive Density Estimation: Towards Learning to Learn
               Distributions},
  journal   = {CoRR},
  volume    = {abs/1710.10304},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.10304},
  archivePrefix = {arXiv},
  eprint    = {1710.10304},
  timestamp = {Mon, 13 Aug 2018 16:46:27 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1710-10304.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{McCann2018Natural,
  author    = {Bryan McCann and
               Nitish Shirish Keskar and
               Caiming Xiong and
               Richard Socher},
  title     = {The Natural Language Decathlon: Multitask Learning as Question Answering},
  journal   = {CoRR},
  volume    = {abs/1806.08730},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.08730},
  archivePrefix = {arXiv},
  eprint    = {1806.08730},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-08730.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{reimers-gurevych-2019-sentence,
    title = "Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks",
    author = "Reimers, Nils  and
      Gurevych, Iryna",
    booktitle = "EMNLP-IJCNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1410",
    doi = "10.18653/v1/D19-1410",
    pages = "3982--3992",
}

@article{beltagy2020longformer,
  author    = {Iz Beltagy and
               Matthew E. Peters and
               Arman Cohan},
  title     = {Longformer: The Long-Document Transformer},
  journal   = {CoRR},
  volume    = {abs/2004.05150},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.05150},
  archivePrefix = {arXiv},
  eprint    = {2004.05150},
  timestamp = {Tue, 14 Apr 2020 16:40:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-05150.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{baldini-soares-etal-2019-matching,
    title = "Matching the Blanks: Distributional Similarity for Relation Learning",
    author = "Baldini Soares, Livio  and
      FitzGerald, Nicholas  and
      Ling, Jeffrey  and
      Kwiatkowski, Tom",
    booktitle = "ACL",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1279",
    doi = "10.18653/v1/P19-1279",
    pages = "2895--2905",
}

@article{lewis2020pretraining,
  author    = {Mike Lewis and
               Marjan Ghazvininejad and
               Gargi Ghosh and
               Armen Aghajanyan and
               Sida I. Wang and
               Luke Zettlemoyer},
  title     = {Pre-training via Paraphrasing},
  journal   = {CoRR},
  volume    = {abs/2006.15020},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.15020},
  archivePrefix = {arXiv},
  eprint    = {2006.15020},
  timestamp = {Wed, 23 Sep 2020 10:33:27 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-15020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{guu2020retrieval,
  author    = {Kelvin Guu and
               Kenton Lee and
               Zora Tung and
               Panupong Pasupat and
               Ming{-}Wei Chang},
  title     = {Retrieval Augmented Language Model Pre-Training},
  booktitle = {ICML},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {3929--3938},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/guu20a.html},
  timestamp = {Tue, 15 Dec 2020 17:40:18 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/GuuLTPC20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{sun2020selfexplaining,
  author    = {Zijun Sun and
               Chun Fan and
               Qinghong Han and
               Xiaofei Sun and
               Yuxian Meng and
               Fei Wu and
               Jiwei Li},
  title     = {Self-Explaining Structures Improve {NLP} Models},
  journal   = {CoRR},
  volume    = {abs/2012.01786},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.01786},
  archivePrefix = {arXiv},
  eprint    = {2012.01786},
  timestamp = {Fri, 04 Dec 2020 12:07:23 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-01786.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hendrickx-etal-2010-semeval,
    title = "{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals",
    author = "Hendrickx, Iris  and
      Kim, Su Nam  and
      Kozareva, Zornitsa  and
      Nakov, Preslav  and
      {\'O} S{\'e}aghdha, Diarmuid  and
      Pad{\'o}, Sebastian  and
      Pennacchiotti, Marco  and
      Romano, Lorenza  and
      Szpakowicz, Stan",
    booktitle = "Proceedings of the 5th International Workshop on Semantic Evaluation",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S10-1006",
    pages = "33--38",
}

@inproceedings{zhang2017tacred,
  author = {Zhang, Yuhao and Zhong, Victor and Chen, Danqi and Angeli, Gabor and Manning, Christopher D.},
  booktitle = {EMNLP},
  title = {Position-aware Attention and Supervised Data Improve Slot Filling},
  url = {https://nlp.stanford.edu/pubs/zhang2017tacred.pdf},
  pages = {35--45},
  year = {2017}
}

@article{liu2021can,
Author = {Nelson F. Liu and Tony Lee and Robin Jia and Percy Liang},
Title = {Can Small and Synthetic Benchmarks Drive Modeling Innovation? A Retrospective Study of Question Answering Modeling Approaches},
Year = {2021},
url={https://arxiv.org/pdf/2102.01065.pdf},
Eprint = {arXiv:2102.01065},
journal   = {CoRR},
}

@article{stammer2020right,
  author    = {Wolfgang Stammer and
               Patrick Schramowski and
               Kristian Kersting},
  title     = {Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting
               with their Explanations},
  journal   = {CoRR},
  volume    = {abs/2011.12854},
  year      = {2020},
  url       = {https://arxiv.org/abs/2011.12854},
  archivePrefix = {arXiv},
  eprint    = {2011.12854},
  timestamp = {Tue, 01 Dec 2020 14:59:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-12854.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ross2017right,
  author    = {Andrew Slavin Ross and Michael C. Hughes and Finale Doshi-Velez},
  title     = {Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations},
  booktitle = {IJCAI},
  pages     = {2662--2670},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/371},
  url       = {https://doi.org/10.24963/ijcai.2017/371},
}

@inproceedings{selvaraju2019taking,
  author    = {Ramprasaath Ramasamy Selvaraju and
               Stefan Lee and
               Yilin Shen and
               Hongxia Jin and
               Shalini Ghosh and
               Larry P. Heck and
               Dhruv Batra and
               Devi Parikh},
  title     = {Taking a {HINT:} Leveraging Explanations to Make Vision and Language
               Models More Grounded},
  booktitle = {ICCV},
  pages     = {2591--2600},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {https://doi.org/10.1109/ICCV.2019.00268},
  doi       = {10.1109/ICCV.2019.00268},
  timestamp = {Thu, 05 Mar 2020 13:43:22 +0100},
  biburl    = {https://dblp.org/rec/conf/iccv/SelvarajuLSJGHB19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ravfogel-etal-2020-null,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    booktitle = ACL,
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.647",
    doi = "10.18653/v1/2020.acl-main.647",
    pages = "7237--7256",
}

@article{Elazar2020amnesic,
       author = {{Elazar}, Yanai and {Ravfogel}, Shauli and {Jacovi}, Alon and {Goldberg}, Yoav},
        title = "{Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2020,
        month = jun,
          eid = {arXiv:2006.00995},
        pages = {arXiv:2006.00995},
archivePrefix = {arXiv},
       eprint = {2006.00995},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200600995E},
}

@inproceedings{kim-etal-2020-interpretation,
    title = "Interpretation of {NLP} models through input marginalization",
    author = "Kim, Siwon  and
      Yi, Jihun  and
      Kim, Eunji  and
      Yoon, Sungroh",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.255",
    doi = "10.18653/v1/2020.emnlp-main.255",
    pages = "3154--3167",
}

@article{Janizek2020Explaining,
  author    = {Joseph D. Janizek and
               Pascal Sturmfels and
               Su{-}In Lee},
  title     = {Explaining Explanations: Axiomatic Feature Interactions for Deep Networks},
  journal   = {CoRR},
  volume    = {abs/2002.04138},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.04138},
  archivePrefix = {arXiv},
  eprint    = {2002.04138},
  timestamp = {Wed, 12 Feb 2020 16:38:55 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-04138.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ebrahimi-etal-2018-hotflip,
    title = "{H}ot{F}lip: White-Box Adversarial Examples for Text Classification",
    author = "Ebrahimi, Javid  and
      Rao, Anyi  and
      Lowd, Daniel  and
      Dou, Dejing",
    booktitle = "ACL",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-2006",
    doi = "10.18653/v1/P18-2006",
    pages = "31--36",
}

@inproceedings{paranjape-etal-2020-information,
    title = "An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction",
    author = "Paranjape, Bhargavi  and
      Joshi, Mandar  and
      Thickstun, John  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.153",
    doi = "10.18653/v1/2020.emnlp-main.153",
    pages = "1938--1952",
}

@inproceedings{chen-ji-2020-learning,
    title = "Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers",
    author = "Chen, Hanjie  and
      Ji, Yangfeng",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.347",
    doi = "10.18653/v1/2020.emnlp-main.347",
    pages = "4236--4251",
}

@inproceedings{maksymilian2020feature,
 author = {Wojtas, Maksymilian and Chen, Ke},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {5105--5114},
 publisher = {Curran Associates, Inc.},
 title = {Feature Importance Ranking for Deep Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/36ac8e558ac7690b6f44e2cb5ef93322-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{belanger2016structured,
  author    = {David Belanger and
               Andrew McCallum},
  editor    = {Maria{-}Florina Balcan and
               Kilian Q. Weinberger},
  title     = {Structured Prediction Energy Networks},
  booktitle = {ICML},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {48},
  pages     = {983--992},
  publisher = {JMLR.org},
  year      = {2016},
  url       = {http://proceedings.mlr.press/v48/belanger16.html},
  timestamp = {Wed, 29 May 2019 08:41:46 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/BelangerM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{carton-etal-2020-evaluating,
    title = "Evaluating and Characterizing Human Rationales",
    author = "Carton, Samuel  and
      Rathore, Anirudh  and
      Tan, Chenhao",
    booktitle = EMNLP,
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.747",
    doi = "10.18653/v1/2020.emnlp-main.747",
    pages = "9294--9307",
}

@inproceedings{tu2018learning,
  author    = {Lifu Tu and
               Kevin Gimpel},
  title     = {Learning Approximate Inference Networks for Structured Prediction},
  booktitle = {ICLR},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=H1WgVz-AZ},
  timestamp = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TuG18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mothilal2020explaining,
  author    = {Ramaravind Kommiya Mothilal and
               Amit Sharma and
               Chenhao Tan},
  editor    = {Mireille Hildebrandt and
               Carlos Castillo and
               Elisa Celis and
               Salvatore Ruggieri and
               Linnet Taylor and
               Gabriela Zanfir{-}Fortuna},
  title     = {Explaining machine learning classifiers through diverse counterfactual
               explanations},
  booktitle = {FAT* '20: Conference on Fairness, Accountability, and Transparency},
  pages     = {607--617},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3351095.3372850},
  doi       = {10.1145/3351095.3372850},
  timestamp = {Thu, 26 Mar 2020 12:29:40 +0100},
  biburl    = {https://dblp.org/rec/conf/fat/MothilalST20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{schafer2013particle,
  title={Particle algorithms for optimization on binary spaces},
  author={Sch{\"a}fer, Christian},
  journal={ACM Transactions on Modeling and Computer Simulation (TOMACS)},
  volume={23},
  number={1},
  pages={1--25},
  year={2013},
  publisher={ACM New York, NY, USA},
  url={https://arxiv.org/pdf/1111.0574.pdf}
}

@inproceedings{lakkaraju2019faithful,
  title={Faithful and customizable explanations of black box models},
  author={Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={131--138},
  year={2019},
  url={https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf}
}

@inproceedings{baptista2018bayesian,
  title={Bayesian optimization of combinatorial structures},
  author={Baptista, Ricardo and Poloczek, Matthias},
  booktitle={International Conference on Machine Learning},
  pages={462--471},
  year={2018},
  organization={PMLR},
  url={http://proceedings.mlr.press/v80/baptista18a/baptista18a.pdf}
}

@inproceedings{belanger2017end-to-end,
  author    = {David Belanger and
               Bishan Yang and
               Andrew McCallum},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {End-to-End Learning for Structured Prediction Energy Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {429--439},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v70/belanger17a.html},
  timestamp = {Wed, 29 May 2019 08:41:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/BelangerYM17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{RobnikSikonja2008ExplainingCF,
  title={Explaining Classifications For Individual Instances},
  author={M. Robnik-Sikonja and I. Kononenko},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2008},
  volume={20},
  pages={589-600},
  url={http://lkm.fri.uni-lj.si/rmarko/papers/RobnikSikonjaKononenko08-TKDE.pdf}
}

@article{alvarez2019weight,
  title={Weight of evidence as a basis for human-oriented explanations},
  author={Alvarez-Melis, David and Daum{\'e} III, Hal and Vaughan, Jennifer Wortman and Wallach, Hanna},
  journal={arXiv preprint arXiv:1910.13503},
  year={2019},
  url={https://arxiv.org/pdf/1910.13503.pdf}
}

@article{li2015visualizing,
  title={Visualizing and understanding neural models in nlp},
  author={Li, Jiwei and Chen, Xinlei and Hovy, Eduard and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1506.01066},
  year={2015},
  url={https://arxiv.org/pdf/1506.01066.pdf}
}

@article{hendrycks2016baseline,
  title={A baseline for detecting misclassified and out-of-distribution examples in neural networks},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1610.02136},
  year={2016},
  url={https://arxiv.org/pdf/1610.02136.pdf}
}

A unifying view on dataset shift in classification

@article{moreno2012unifying,
  title={A unifying view on dataset shift in classification},
  author={Moreno-Torres, Jose G and Raeder, Troy and Alaiz-Rodr{\'\i}guez, Roc{\'\i}o and Chawla, Nitesh V and Herrera, Francisco},
  journal={Pattern recognition},
  volume={45},
  number={1},
  pages={521--530},
  year={2012},
  publisher={Elsevier},
  url={https://rtg.cis.upenn.edu/cis700-2019/papers/dataset-shift/dataset-shift-terminology.pdf}
}

@article{bernardo1998regression,
  title={Regression and classification using Gaussian process priors},
  author={Bernardo, J and Berger, J and Dawid, APAFMS and Smith, A and others},
  journal={Bayesian statistics},
  volume={6},
  pages={475},
  year={1998},
  url={http://www.cs.toronto.edu/~radford/ftp/val6gp.pdf}
}


@article{hendrycks2016baseline,
  title={A baseline for detecting misclassified and out-of-distribution examples in neural networks},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1610.02136},
  year={2016},
  url={https://arxiv.org/pdf/1610.02136.pdf}
}



@misc{yin2021faithfulness,
Author = {Fan Yin and Zhouxing Shi and Cho-Jui Hsieh and Kai-Wei Chang},
Title = {On the Faithfulness Measurements for Model Interpretations},
Year = {2021},
Eprint = {arXiv:2104.08782},
url={https://arxiv.org/pdf/2104.08782.pdf}
}

@misc{chrysostomou2021variable,
Author = {George Chrysostomou and Nikolaos Aletras},
Title = {Variable Instance-Level Explainability for Text Classification},
Year = {2021},
Eprint = {arXiv:2104.08219},
url={https://arxiv.org/pdf/2104.08219.pdf}
}

@article{claesen2015hyperparameter,
  title={Hyperparameter search in machine learning},
  author={Claesen, Marc and De Moor, Bart},
  journal={arXiv preprint arXiv:1502.02127},
  year={2015},
  url={https://arxiv.org/pdf/1502.02127.pdf}
}

@article{probst2019tunability,
  title={Tunability: Importance of hyperparameters of machine learning algorithms.},
  author={Probst, Philipp and Boulesteix, Anne-Laure and Bischl, Bernd},
  journal={J. Mach. Learn. Res.},
  volume={20},
  number={53},
  pages={1--32},
  year={2019},
  url={https://arxiv.org/pdf/1802.09596.pdf}
}

@inproceedings{van2018hyperparameter,
  title={Hyperparameter importance across datasets},
  author={Van Rijn, Jan N and Hutter, Frank},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2367--2376},
  year={2018},
  url={https://arxiv.org/pdf/1710.04725.pdf}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013},
  url={https://www.aclweb.org/anthology/D13-1170.pdf}
}

@article{brown2010ensemble,
  title={Ensemble Learning.},
  author={Brown, Gavin},
  journal={Encyclopedia of machine learning},
  volume={312},
  pages={15--19},
  year={2010},
  url={http://www.cs.man.ac.uk/~gbrown/research/brown10ensemblelearning.pdf}
}

@inproceedings{adebayo_sanity_2018,
author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
url = {https://arxiv.org/pdf/1810.03292.pdf},
title = {Sanity Checks for Saliency Maps},
year = {2018},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems}
}
  
  
@article{samek2016evaluating,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE},
  url={https://arxiv.org/pdf/1509.06321.pdf}
}

@inproceedings{dabkowski2017real,
 author = {Dabkowski, Piotr and Gal, Yarin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Real Time Image Saliency for Black Box Classifiers},
 url = {https://proceedings.neurips.cc/paper/2017/file/0060ef47b12160b9198302ebdb144dcf-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{chang2018explaining,
  title={Explaining image classifiers by counterfactual generation},
  author={Chang, Chun-Hao and Creager, Elliot and Goldenberg, Anna and Duvenaud, David},
  booktitle={ICLR},
  year={2019},
  url={https://arxiv.org/pdf/1807.08024.pdf}
}

@article{yi2020information,
  title={Information-theoretic visual explanation for black-box classifiers},
  author={Yi, Jihun and Kim, Eunji and Kim, Siwon and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2009.11150},
  year={2020},
  url={https://arxiv.org/pdf/2009.11150.pdf}
}

@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3429--3437},
  year={2017},
  url={https://arxiv.org/pdf/1704.03296.pdf}
}

@article{hsieh2020evaluations,
  title={Evaluations and Methods for Explanation through Robustness Analysis},
  author={Hsieh, Cheng-Yu and Yeh, Chih-Kuan and Liu, Xuanqing and Ravikumar, Pradeep and Kim, Seungyeon and Kumar, Sanjiv and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2006.00442},
  year={2020},
  url={https://arxiv.org/pdf/2006.00442.pdf}
}

@inproceedings{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={ICLR},
  year={2016},
  url={https://arxiv.org/pdf/1611.01144.pdf}
}

@article{pirlot1996general,
  title={General local search methods},
  author={Pirlot, Marc},
  journal={European journal of operational research},
  volume={92},
  number={3},
  pages={493--511},
  year={1996},
  publisher={Elsevier}
}

@inproceedings{clark-etal-2019-boolq,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1300",
    doi = "10.18653/v1/N19-1300",
    pages = "2924--2936",
}

@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1074",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
}

@inproceedings{khashabi-etal-2018-looking,
    title = "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences",
    author = "Khashabi, Daniel  and
      Chaturvedi, Snigdha  and
      Roth, Michael  and
      Upadhyay, Shyam  and
      Roth, Dan",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1023",
    doi = "10.18653/v1/N18-1023",
    pages = "252--262",
}

@inproceedings{lehman-etal-2019-inferring,
    title = "Inferring Which Medical Treatments Work from Reports of Clinical Trials",
    author = "Lehman, Eric  and
      DeYoung, Jay  and
      Barzilay, Regina  and
      Wallace, Byron C.",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1371",
    doi = "10.18653/v1/N19-1371",
    pages = "3705--3717",
}

@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1170",
    pages = "1631--1642",
}

@article{arras2017relevant,
  title={" What is relevant in a text document?": An interpretable machine learning approach},
  author={Arras, Leila and Horn, Franziska and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={12},
  number={8},
  pages={e0181142},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{arras-etal-2019-evaluating,
    title = "Evaluating Recurrent Neural Network Explanations",
    author = {Arras, Leila  and
      Osman, Ahmed  and
      M{\"u}ller, Klaus-Robert  and
      Samek, Wojciech},
    booktitle = "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4813",
    doi = "10.18653/v1/W19-4813",
    pages = "113--126",
}

@article{zhou2021feature,
  title={Do Feature Attribution Methods Correctly Attribute Features?},
  author={Zhou, Yilun and Booth, Serena and Ribeiro, Marco Tulio and Shah, Julie},
  journal={arXiv preprint arXiv:2104.14403},
  url={https://arxiv.org/pdf/2104.14403.pdf},
  year={2021}
}

@inproceedings{sundararajan2020many,
  title={The many Shapley values for model explanation},
  author={Sundararajan, Mukund and Najmi, Amir},
  booktitle={International Conference on Machine Learning},
  pages={9269--9278},
  year={2020},
  organization={PMLR},
  url={https://arxiv.org/pdf/1908.08474.pdf}
}

@article{sturmfels2020visualizing,
  title={Visualizing the impact of feature attribution baselines},
  author={Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In},
  journal={Distill},
  volume={5},
  number={1},
  pages={e22},
  year={2020},
  url={https://distill.pub/2020/attribution-baselines/}
}

@inproceedings{janzing2020feature,
  title={Feature relevance quantification in explainable AI: A causal problem},
  author={Janzing, Dominik and Minorics, Lenon and Bl{\"o}baum, Patrick},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2907--2916},
  year={2020},
  organization={PMLR},
  url={https://arxiv.org/pdf/1910.13413.pdf}
}

@inproceedings{zintgraf2017visualizing,
  title={Visualizing deep neural network decisions: Prediction difference analysis},
  author={Zintgraf, Luisa M and Cohen, Taco S and Adel, Tameem and Welling, Max},
  booktitle={ICLR},
  year={2017},
  url={https://arxiv.org/pdf/1702.04595.pdf}
}

@misc{turner-nodate-gaussian,
title={Gaussian Processes: From the Basics to the State-of-the-Art},
author={Turner, Richard E},
year={2016},
url={http://cbl.eng.cam.ac.uk/pub/Public/Turner/News/imperial-gp-tutorial.pdf}
}

@article{miyato2018virtual,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018},
  publisher={IEEE},
  url={https://arxiv.org/pdf/1704.03976.pdf}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{lucic2021multistakeholder,
  title={A Multistakeholder Approach Towards Evaluating AI Transparency Mechanisms},
  author={Lucic, Ana and Srikumar, Madhulika and Bhatt, Umang and Xiang, Alice and Taly, Ankur and Liao, Q Vera and de Rijke, Maarten},
  journal={arXiv preprint arXiv:2103.14976},
  year={2021},
  url={https://arxiv.org/pdf/2103.14976.pdf}
}


@inproceedings{haug2021baselines,
  title={On Baselines for Local Feature Attributions},
  author={Haug, Johannes and Z{\"u}rn, Stefan and El-Jiz, Peter and Kasneci, Gjergji},
  booktitle={AAAI},
  year={2021},
  url={https://arxiv.org/pdf/2101.00905.pdf}
}

@article{ehsan2021explainable,
  title={The who in explainable ai: How ai background shapes perceptions of ai explanations},
  author={Ehsan, Upol and Passi, Samir and Liao, Q Vera and Chan, Larry and Lee, I and Muller, Michael and Riedl, Mark O and others},
  journal={arXiv preprint arXiv:2107.13509},
  year={2021},
  url={https://arxiv.org/pdf/2107.13509.pdf}
}

@article{qiu2021resisting,
  title={Resisting Out-of-Distribution Data Problem in Perturbation of XAI},
  author={Qiu, Luyu and Yang, Yi and Cao, Caleb Chen and Liu, Jing and Zheng, Yueyuan and Ngai, Hilary Hei Ting and Hsiao, Janet and Chen, Lei},
  journal={arXiv preprint arXiv:2107.14000},
  year={2021}
}

@article{sanyal2021discretized,
  title={Discretized Integrated Gradients for Explaining Language Models},
  author={Sanyal, Soumya and Ren, Xiang},
  journal={arXiv preprint arXiv:2108.13654},
  year={2021},
  url={https://arxiv.org/pdf/2108.13654.pdf},
}

@inproceedings{dumodel,
  title={Model-Agnostic Local Explanations with Genetic Algorithms for Text Classification},
  author={Du, Qingfeng and Xu, Jincheng},
  booktitle={The 33rd International Conference on Software Engineering \& Knowledge Engineering},
  year={2021},
  url={https://ksiresearch.org/seke/seke21paper/paper040.pdf}
}

@inproceedings{jethani2021have,
  title={Have We Learned to Explain?: How Interpretability Methods Can Learn to Encode Predictions in their Interpretations.},
  author={Jethani, Neil and Sudarshan, Mukund and Aphinyanaphongs, Yindalon and Ranganath, Rajesh},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1459--1467},
  year={2021},
  organization={PMLR},
  url={https://arxiv.org/pdf/2103.01890.pdf}
}

@inproceedings{vafa2021rationales,
  title={Rationales for Sequential Predictions},
  author={Vafa, Keyon and Deng, Yuntian and Blei, David M and Rush, Alexander M},
  year={2021},
  booktitle={EMNLP},
  url={https://arxiv.org/pdf/2109.06387.pdf}
}