@article{shimizu2006linear,
  title={A linear non-Gaussian acyclic model for causal discovery},
  author={Shimizu, S. and Hoyer, P. O. and Hyv{\"a}rinen, A. and Kerminen, A.},
  journal={The Journal of Machine Learning Research},
  volume={7},
  pages={2003--2030},
  year={2006},
  publisher={JMLR}
}

@article{tangkaratt2015conditional,
  title={Conditional density estimation with dimensionality reduction via squared-loss conditional entropy minimization},
  author={Tangkaratt, Voot and Xie, Ning and Sugiyama, Masashi},
  journal={Neural Computation},
  volume={27},
  number={1},
  pages={228--254},
  year={2015},
  publisher={MIT Press}
}

@book{sugiyama_suzuki_kanamori_2012,
  place={Cambridge},
  title={Density Ratio Estimation in Machine Learning},
  publisher={Cambridge University Press},
  author={Sugiyama, Masashi and Suzuki, Taiji and Kanamori, Takafumi},
  year={2012}
}

@article{gretton_kernel_2012,
	title = {A Kernel Two-Sample Test},
	volume = {13},
	issnmemo = {1533-7928},
	urlmemo = {http://jmlr.csail.mit.edu/papers/v13/gretton12a.html},
	pages = {723--773},
	journaltitle = {Journal of Machine Learning Research},
	author = {Gretton, Arthur and Borgwardt, Karsten M. and Rasch, Malte J. and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
	urldate = {2019-05-22},
	date = {2012-03},
	year = {2012},
}

@article{sriperumbudur_hilbert_2010,
  author  = {Bharath K. Sriperumbudur and Arthur Gretton and Kenji Fukumizu and Bernhard Sch{{\"o}}lkopf and Gert R.G. Lanckriet},
  title   = {Hilbert Space Embeddings and Metrics on Probability Measures},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {50},
  pages   = {1517--1561},
  memourl = {http://jmlr.org/papers/v11/sriperumbudur10a.html}
}

@article{Cox85,
  title={A penalty method for nonparametric estimation of the logarithmic derivative of a density function},
  memo={Cox, Dennis D},
  author={Cox, D. D.},
  journal={Annals of the Institute of Statistical Mathematics},
  volume={37},
  number={1},
  pages={271--288},
  year={1985},
  publisher={Springer}
}

@article{Beran76,
  title={Adaptive estimates for autoregressive processes},
  memo={Beran, Rudolf},
  author={Beran, R.},
  journal={Annals of the Institute of Statistical Mathematics},
  volume={28},
  number={1},
  pages={77--89},
  year={1976},
  publisher={Springer}
}

@inproceedings{Sasaki14,
title={Clustering via Mode Seeking by Direct Estimation of the Gradient of a Log-Density},
memo={Sasaki, Hiroaki and Hyv{\"a}rinen, Aapo and Sugiyama, Masashi},
author={Sasaki, H. and Hyv{\"a}rinen, A. and Sugiyama, M.},
booktitle={Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD 2014)},
pages = {19--34},
year={2014},
memoaddress={Nancy, France}
}

@article{sugiyama_density-difference_2013,
	title = {Density-{Difference} {Estimation}},
	volume = {25},
	memoissn = {0899-7667, 1530-888X},
	memourl = {https://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00492},
	memodoi = {10.1162/NECO_a_00492},
	abstract = {We address the problem of estimating the difference between two probability densities. A naive approach is a two-step procedure of ﬁrst estimating two densities separately and then computing their difference. However, such a two-step procedure does not necessarily work well because the ﬁrst step is performed without regard to the second step and thus a small estimation error incurred in the ﬁrst stage can cause a big error in the second stage. In this paper, we propose a single-shot procedure for directly estimating the density difference without separately estimating two densities. We derive a non-parametric ﬁnite-sample error bound for the proposed single-shot density-difference estimator and show that it achieves the optimal convergence rate. We then show how the proposed density-difference estimator can be utilized in L2-distance approximation. Finally, we experimentally demonstrate the usefulness of the proposed method in robust distribution comparison such as class-prior estimation and change-point detection.},
	language = {en},
	number = {10},
	urldate = {2021-02-01},
	journal = {Neural Computation},
	author = {Sugiyama, Masashi and Kanamori, Takafumi and Suzuki, Taiji and Plessis, Marthinus Christoffel du and Liu, Song and Takeuchi, Ichiro},
	month = oct,
	year = {2013},
	pages = {2734--2775},
}

@article{yamane2016regularized,
  title={Regularized multitask learning for multidimensional log-density gradient estimation},
  author={Yamane, Ikko and Sasaki, Hiroaki and Sugiyama, Masashi},
  journal={Neural computation},
  volume={28},
  number={7},
  pages={1388--1410},
  year={2016},
  publisher={MIT Press}
}

@article{yamada2014high,
  title={High-dimensional feature selection by feature-wise kernelized lasso},
  author={Yamada, Makoto and Jitkrittum, Wittawat and Sigal, Leonid and Xing, Eric P and Sugiyama, Masashi},
  journal={Neural computation},
  volume={26},
  number={1},
  pages={185--207},
  year={2014},
  publisher={MIT Press}
}

@inproceedings{fukumizu2012gradient,
  title={Gradient-based kernel method for feature extraction and variable selection},
  author={Fukumizu, Kenji and Leng, Chenlei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2114--2122},
  year={2012}
}

@Article{Shiga2015,
author="Shiga, Motoki and Tangkaratt, Voot and Sugiyama, Masashi",
title="Direct conditional probability density estimation with sparse feature selection",
journal="Machine Learning",
year="2015",
month="9",
day="01",
volume="100",
number="2",
pages="161--182",
issnmemo="1573-0565",
doimemo="10.1007/s10994-014-5472-x",
urlmemo="https://doi.org/10.1007/s10994-014-5472-x"
}

@InProceedings{zhanga16,
  title = {On the Consistency of Feature Selection With Lasso for Non-linear Targets},
  author = {Yue Zhang and Weihong Guo and Soumya Ray},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  pages = {183--191},
  year = {2016},
  memoeditor = {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = {48},
  series = {Proceedings of Machine Learning Research},
  memoaddress = {New York, New York, USA},
  month = {6},
  publisher = {PMLR},
  pdfmemo = {http://proceedings.mlr.press/v48/zhanga16.pdf},
  urlmemo = {http://proceedings.mlr.press/v48/zhanga16.html},
}

@article{bertsimas2016,
  author = "Bertsimas, Dimitris and King, Angela and Mazumder, Rahul",
  journal = "The Annals of Statistics",
  memojournal = "Annals of Statist.",
  month = "04",
  number = "2",
  pages = "813--852",
  publisher = "The Institute of Mathematical Statistics",
  title = "Best subset selection via a modern optimization lens",
  volume = "44",
  year = "2016",
  doimemo = "10.1214/15-AOS1388",
  urlmemo = "https://doi.org/10.1214/15-AOS1388",
}



@article{suzuki_mutual_2009,
	title = {Mutual information estimation reveals global associations between stimuli and biological processes},
	volume = {10},
	pages = {S52},
	issue = {Suppl 1},
	journaltitle = {{BMC} Bioinformatics},
	shortjournal = {{BMC} Bioinformatics},
	author = {Suzuki, Taiji and Sugiyama, Masashi and Kanamori, Takafumi and Sese, Jun},
	date = {2009},
	langid = {english},
}


@article{jitkrittum_feature_2013,
	title = {Feature Selection via l1-Penalized Squared-Loss Mutual Information},
	volume = {E96.D},
	pages = {1513--1524},
	number = {7},
	journaltitle = {{IEICE} Transactions on Information and Systems},
	shortjournal = {{IEICE} Trans. Inf. {\textasciicircum}{\textbar}{\textasciicircum} Syst.},
	author = {Jitkrittum, Wittawat and Hachiya, Hirotaka and Sugiyama, Masashi},
	date = {2013},
	year = {2013},
	langid = {english},
}

@InProceedings{pmlr-v80-belghazi18a,
  title = {Mutual Information Neural Estimation},
  author = {Belghazi, Mohamed Ishmael and Baratin, Aristide and Rajeshwar, Sai and Ozair, Sherjil and Bengio, Yoshua and Courville, Aaron and Hjelm, Devon},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  pages = {531--540},
  year = {2018},
  memoeditor = {Dy, Jennifer and Krause, Andreas},
  volume = {80},
  series = {Proceedings of Machine Learning Research},
  addressmemo = {Stockholmsmässan, Stockholm Sweden},
  month = {10--15 Jul},
  publisher = {PMLR},
}

@article{hogan_point_set_1973,
    title = {Point-to-Set Maps in Mathematical Programming},
    volume = {15},
    pages = {591--603},
    number = {3},
    journaltitle = {{SIAM} Review},
    author = {Hogan, William W.},
    date = {1973},
    year = {1973},
    langid = {english},
}

@book{vaart1998asymp,
  place={Cambridge},
  series={Cambridge Series in Statistical and Probabilistic Mathematics},
  title={Asymptotic Statistics},
  memoDOI={10.1017/CBO9780511802256},
  publisher={Cambridge University Press},
  author={A. W. van der Vaart},
  year={1998},
  collection={Cambridge Series in Statistical and Probabilistic Mathematics}
}


@inbook{mcdiarmid_1989,
    place={Cambridge},
    series={London Mathematical Society Lecture Note Series},
    title={On the method of bounded differences},
    booktitle={Surveys in Combinatorics,
    1989: Invited Papers at the Twelfth British Combinatorial Conference},
    publisher={Cambridge University Press},
    author={McDiarmid,
    Colin},
    memoeditor={Siemons, J.Editor},
    year={1989},
    pages={148--188},
    collection={London Mathematical Society Lecture Note Series}
}

@INPROCEEDINGS{mittal_image_sentiment,
    author={N. {Mittal} and D. {Sharma} and M. L. {Joshi}},
    booktitle={2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)},
    title={Image Sentiment Analysis Using Deep Learning},
    year={2018},
    volume={},
    number={},
    pages={684--687},
}

@book{chapelle_semi-supervised_2006,
  memoaddress = {Cambridge, MA},
  series = {Adaptive computation and machine learning},
  title = {Semi-supervised learning},
  memoisbn = {978-0-262-03358-9},
  language = {en},
  publisher = {MIT Press},
  editor = {Chapelle, Olivier and Sch{\"o}lkopf, Bernhard and Zien, Alexander},
  year = {2006},
  keywords = {Supervised learning (Machine learning)},
}

@article{koltchinskii_rademacher_2001,
	title = {Rademacher penalties and structural risk minimization},
	volume = {47},
	memoissn = {0018-9448},
	memodoi = {10.1109/18.930926},
	number = {5},
	journal = {IEEE Transactions on Information Theory},
	author = {Koltchinskii, Vladimir},
	month = jul,
	year = {2001},
	pages = {1902--1914},
}

@book{mohri2012foundations,
	title={Foundations of Machine Learning},
	author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
	short_author={Mohri, M. and Rostamizadeh, A. and Talwalkar, A.},
	year={2012},
	publisher={MIT Press}
}

@book{shalev-shwartz_understanding_2014,
	memoaddress = {Cambridge},
	title = {Understanding Machine Learning: From Theory to Algorithms},
	shorttitle = {Understanding {Machine} {Learning}},
	publisher = {Cambridge University Press},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	year = {2014},
}

@article{van_engelen_survey_2020,
	title = {A survey on semi-supervised learning},
	volume = {109},
	language = {en},
	number = {2},
	urldate = {2020-06-02},
	journal = {Machine Learning},
	author = {van Engelen, Jesper E. and Hoos, Holger H.},
	month = feb,
	year = {2020},
	pages = {373--440},
}

@techreport{zhu_semi-supervised_nodate,
    title={Semi-supervised learning literature survey},
    author={Zhu, Xiaojin Jerry},
    year={2005},
    number={1530},
    institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@book{murphy_machine_2012,
	memoaddress = {Cambridge, MA},
	series = {Adaptive Computation and Machine Learning Series},
	title = {Machine Learning: A Probabilistic Perspective},
	shorttitle = {Machine Learning},
	language = {en},
	publisher = {MIT Press},
	author = {Murphy, Kevin P.},
	year = {2012},
	keywords = {Machine learning, Probabilities},
}

@article{zhang2019learning,
    title={Learning from Indirect Observations},
    author={Zhang, Yivan and Charoenphakdee, Nontawat and Sugiyama, Masashi},
    journal={arXiv preprint arXiv:1910.04394},
    year={2019}
}

@article{angluin_learning_1988,
	title = {Learning from noisy examples},
	volume = {2},
	language = {en},
	number = {4},
	urldate = {2020-06-05},
	journal = {Machine Learning},
	author = {Angluin, Dana and Laird, Philip},
	month = apr,
	year = {1988},
	pages = {343--370},
}

@article{blanchard_classification_2016,
	title = {Classification with {Asymmetric} {Label} {Noise}: {Consistency} and {Maximal} {Denoising}},
	shorttitle = {Classification with {Asymmetric} {Label} {Noise}},
	urldate = {2020-06-05},
	journal = {arXiv:1303.1208 [cs, stat]},
	author = {Blanchard, Gilles and Flaska, Marek and Handy, Gregory and Pozzi, Sara and Scott, Clayton},
	month = aug,
	year = {2016},
	note = {arXiv: 1303.1208},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@incollection{natarajan_learning_2013,
	title = {Learning with {Noisy} {Labels}},
	urldate = {2020-06-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 26},
	publisher = {Curran Associates, Inc.},
	author = {Natarajan, Nagarajan and Dhillon, Inderjit S and Ravikumar, Pradeep K and Tewari, Ambuj},
	memoeditor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
	year = {2013},
	pages = {1196--1204},
}

@incollection{kiryo_positive-unlabeled_2017,
	title = {Positive-{Unlabeled} {Learning} with {Non}-{Negative} {Risk} {Estimator}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Kiryo, Ryuichi and Niu, Gang and du Plessis, Marthinus C and Sugiyama, Masashi},
	memoeditor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {1675--1685},
}

@article{lu2019mitigating,
	title={Mitigating Overfitting in Supervised Classification from Two Unlabeled Datasets: A Consistent Risk Correction Approach},
	author={Lu, Nan and Zhang, Tianyi and Niu, Gang and Sugiyama, Masashi},
	journal={arXiv preprint arXiv:1910.08974},
	year={2019}
}

@article{medhat_sentiment_2014,
	title = {Sentiment analysis algorithms and applications: {A} survey},
	volume = {5},
	shorttitle = {Sentiment analysis algorithms and applications},
	language = {en},
	number = {4},
	urldate = {2020-06-02},
	journal = {Ain Shams Engineering Journal},
	author = {Medhat, Walaa and Hassan, Ahmed and Korashy, Hoda},
	month = dec,
	year = {2014},
	pages = {1093--1113},
}

@InProceedings{xu_show_2015,
  title = {Show Attend and Tell: Neural Image Caption Generation with Visual Attention},
  author = {Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhudinov and Rich Zemel and Yoshua Bengio},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  pages = {2048--2057},
  year = {2015},
  memoeditor = {Francis Bach and David Blei},
  volume = {37},
  series = {Proceedings of Machine Learning Research},
  memoaddress = {Lille, France},
  month = {07--09 Jul},
  publisher = {PMLR},
  memourl = {http://proceedings.mlr.press/v37/xuc15.html},
}

@book{vapnik_nature_stat_learn_1995,
  author = {Vapnik, Vladimir N.},
  title = {The Nature of Statistical Learning Theory},
  year = {1995},
  memoisbn = {0387945598},
  publisher = {Springer-Verlag},
  memoaddress = {Berlin, Heidelberg}
}

@misc{Idelbayev18a,
   author       = "Yerlan Idelbayev",
   title        = "Proper {ResNet} Implementation for {CIFAR10/CIFAR100} in {PyTorch}",
   howpublished = "\url{https://github.com/akamaster/pytorch_resnet_cifar10}",
   note         = "Accessed: 2020-7-16",
   year         = "2020"
}

@inproceedings{salimans_improved_gans,
 author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
 booktitle = {Advances in Neural Information Processing Systems},
 memoeditor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {2234--2242},
 publisher = {Curran Associates, Inc.},
 title = {Improved Techniques for Training GANs},
 memourl = {https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{kingma_improved_variational,
 author = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
 booktitle = {Advances in Neural Information Processing Systems},
 memoeditor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {4743--4751},
 publisher = {Curran Associates, Inc.},
 title = {Improved Variational Inference with Inverse Autoregressive Flow},
 memourl = {https://proceedings.neurips.cc/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf},
 volume = {29},
 year = {2016}
}


@inproceedings{gulrajani_improved_wgan,
 author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
 booktitle = {Advances in Neural Information Processing Systems},
 memoeditor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {5767--5777},
 publisher = {Curran Associates, Inc.},
 title = {Improved Training of Wasserstein GANs},
 memourl = {https://proceedings.neurips.cc/paper/2017/file/892c3b1c6dccd52936e27cbd0ff683d6-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{zhang_learning_2021,
	title = {Learning from {Aggregate} {Observations}},
	memourl = {http://arxiv.org/abs/2004.06316},
	abstract = {We study the problem of learning from aggregate observations where supervision signals are given to sets of instances instead of individual instances, while the goal is still to predict labels of unseen individuals. A well-known example is multiple instance learning (MIL). In this paper, we extend MIL beyond binary classiﬁcation to other problems such as multiclass classiﬁcation and regression. We present a probabilistic framework that is applicable to a variety of aggregate observations, e.g., pairwise similarity for classiﬁcation and mean/diﬀerence/rank observation for regression. We propose a simple yet eﬀective method based on the maximum likelihood principle, which can be simply implemented for various diﬀerentiable models such as deep neural networks and gradient boosting machines. Experiments on three novel problem settings — classiﬁcation via triplet comparison and regression via mean/rank observation indicate the eﬀectiveness of the proposed method.},
	language = {en},
	memourldate = {2021-02-01},
	journal = {arXiv:2004.06316 [cs, stat]},
	author = {Zhang, Yivan and Charoenphakdee, Nontawat and Wu, Zhenguo and Sugiyama, Masashi},
	month = jan,
	year = {2021},
	note = {arXiv: 2004.06316},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{madakam_internet_2015,
	title = {Internet of {Things} ({IoT}): {A} {Literature} {Review}},
	volume = {03},
	memoissn = {2327-5219, 2327-5227},
	shorttitle = {Internet of {Things} ({IoT})},
	memourl = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jcc.2015.35021},
	memodoi = {10.4236/jcc.2015.35021},
	abstract = {One of the buzzwords in the Information Technology is Internet of Things (IoT). The future is Internet of Things, which will transform the real world objects into intelligent virtual objects. The IoT aims to unify everything in our world under a common infrastructure, giving us not only control of things around us, but also keeping us informed of the state of the things. In Light of this, present study addresses IoT concepts through systematic review of scholarly research papers, corporate white papers, professional discussions with experts and online databases. Moreover this research article focuses on definitions, geneses, basic requirements, characteristics and aliases of Internet of Things. The main objective of this paper is to provide an overview of Internet of Things, architectures, and vital technologies and their usages in our daily life. However, this manuscript will give good comprehension for the new researchers, who want to do research in this field of Internet of Things (Technological GOD) and facilitate knowledge accumulation in efficiently.},
	language = {en},
	number = {05},
	urldate = {2021-02-02},
	journal = {Journal of Computer and Communications},
	author = {Madakam, Somayya and Ramaswamy, R. and Tripathi, Siddharth},
	year = {2015},
	pages = {164--173},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	memourl = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	memourldate = {2021-02-02},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{yamane_uplift_2018,
 author = {Yamane, Ikko and Yger, Florian and Atif, Jamal and Sugiyama, Masashi},
 booktitle = {Advances in Neural Information Processing Systems},
 memoeditor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {9927--9937},
 publisher = {Curran Associates, Inc.},
 title = {Uplift Modeling from Separate Labels},
 memourl = {https://proceedings.neurips.cc/paper/2018/file/198dd5fb9c43b2d29a548f8c77e85cf9-Paper.pdf},
 volume = {31},
 year = {2018}
}

@inproceedings{ronneberger_u-net_2015,
	memoaddress = {Cham},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	memoisbn = {978-3-319-24574-4},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	memoeditor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	pages = {234--241}
}


@INPROCEEDINGS{he_deep_2016,
  author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Deep Residual Learning for Image Recognition},
  year={2016},
  volume={},
  number={},
  pages={770--778},
  memodoi={10.1109/CVPR.2016.90}
}


@TECHREPORT{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  institution={University of Toronto},
}

@incollection{pytorch_NEURIPS2019,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  memoeditor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages = {8024--8035},
  year = {2019},
  publisher = {Curran Associates, Inc.},
  memourl = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@InProceedings{hein_overconf_2019,
  author = {Hein, Matthias and Andriushchenko, Maksym and Bitterwolf, Julian},
  title = {Why ReLU Networks Yield High-Confidence Predictions Far Away From the Training Data and How to Mitigate the Problem},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  pages={41--50},
  year = {2019}
}

@book{ledoux_probability_2011,
  address = {Berlin ; London},
  series = {Classics in mathematics},
  title = {Probability in {Banach} spaces: isoperimetry and processes},
  memoisbn = {978-3-642-20211-7 978-3-642-20212-4},
  shorttitle = {Probability in {Banach} spaces},
  language = {en},
  publisher = {Springer},
  author = {Ledoux, Michel and Talagrand, Michel},
  year = {2011},
}

@InProceedings{pmlr-v9-song10a,
  title = {Nonparametric Tree Graphical Models},
  author = {Song, Le and Gretton, Arthur and Guestrin, Carlos},
  booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages = {765--772},
  year = {2010},
  memoeditor = {Teh, Yee Whye and Titterington, Mike},
  volume = {9},
  series = {Proceedings of Machine Learning Research},
  address = {Chia Laguna Resort, Sardinia, Italy},
  memomonth = {13--15 May},
  publisher = {PMLR},
  memourl = {http://proceedings.mlr.press/v9/song10a.html},
}

@inproceedings{dhir_integrating_2020,
  title = {Integrating {Overlapping} {Datasets} {Using} {Bivariate} {Causal} {Discovery}},
  volume = {34},
  copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
  memoissn = {2374-3468},
  memourl = {https://ojs.aaai.org/index.php/AAAI/article/view/5789},
  memodoi = {10.1609/aaai.v34i04.5789},
  language = {en},
  number = {04},
  memourldate = {2021-06-03},
  booktitle = {Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI)},
  author = {Dhir, Anish and Lee, Ciaran M.},
  memomonth = apr,
  year = {2020},
  memonote = {Number: 04},
  pages = {3781--3790},
}

@MISC{mnist,
  author = {LeCun, Y. and Cortes, C. and Burges, C.J.},
  title = {The {MNIST} Database of Handwritten Digits},
  year = {1994},
  howpublished={\url{http://yann.lecun.com/exdb/mnist/}}
}

@misc{xiao2017fashionmnist,
  title={Fashion-{MNIST}: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  author={Han Xiao and Kashif Rasul and Roland Vollgraf},
  year={2017},
  eprint={1708.07747},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@incollection{NEURIPS2019_9015,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages = {8024--8035},
  year = {2019},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{rmdl2018,
  author = {Kowsari, Kamran and Heidarysafa, Mojtaba and Brown, Donald E. and Meimandi, Kiana Jafari and Barnes, Laura E.},
  title = {RMDL: Random Multimodel Deep Learning for Classification},
  year = {2018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 2nd International Conference on Information System and Data Mining},
  pages = {19–28},
  numpages = {10},
  keywords = {Image Classification, Supervised Learning, Text Classification, Data Mining, Deep Learning, Deep Neural Networks},
  location = {Lakeland, FL, USA},
  series = {ICISDM '18},
  memoisbn = {9781450363549},
  memourl = {https://doi.org/10.1145/3206098.3206111},
  memodoi = {10.1145/3206098.3206111}
}

@inproceedings{foret2021sharpnessaware,
  title={Sharpness-aware Minimization for Efficiently Improving Generalization},
  author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
  booktitle={International Conference on Learning Representations},
  year={2021},
  memourl={https://openreview.net/forum?id=6Tm1mposlrM}
}

@INPROCEEDINGS{fine_tuning_darts,
  author={Tanveer, Muhammad Suhaib and Karim Khan, Muhammad Umar and Kyung, Chong-Min},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  title={Fine-Tuning {DARTS} for Image Classification},
  year={2021},
  volume={},
  number={},
  pages={4789-4796},
  memodoi={10.1109/ICPR48806.2021.9412221}
}
