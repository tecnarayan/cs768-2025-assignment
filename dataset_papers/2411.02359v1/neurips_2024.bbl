\begin{thebibliography}{10}

\bibitem{achiam2023gpt4}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,
  Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
  Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{yang2023dawn}
Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng
  Liu, and Lijuan Wang.
\newblock The dawn of lmms: Preliminary explorations with gpt-4v (ision).
\newblock {\em arXiv preprint arXiv:2309.17421}, 2023.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{liu2024llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em NeurIPS}, 2024.

\bibitem{wake2023gpt4-V}
Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, and Katsushi
  Ikeuchi.
\newblock Gpt-4v (ision) for robotics: Multimodal task planning from human
  demonstration.
\newblock {\em arXiv preprint arXiv:2311.12015}, 2023.

\bibitem{chen2023towards}
Liang Chen, Yichi Zhang, Shuhuai Ren, Haozhe Zhao, Zefan Cai, Yuchi Wang, Peiyi
  Wang, Tianyu Liu, and Baobao Chang.
\newblock Towards end-to-end embodied decision making via multi-modal large
  language model: Explorations with gpt4-vision and beyond.
\newblock {\em arXiv preprint arXiv:2310.02071}, 2023.

\bibitem{rt-2}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi~Chen,
  Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea
  Finn, et~al.
\newblock Rt-2: Vision-language-action models transfer web knowledge to robotic
  control.
\newblock {\em CoRL}, 2023.

\bibitem{rt-x}
Abhishek Padalkar, Acorn Pooley, Ajinkya Jain, Alex Bewley, Alex Herzog, Alex
  Irpan, Alexander Khazatsky, Anant Rai, Anikait Singh, Anthony Brohan, et~al.
\newblock Open x-embodiment: Robotic learning datasets and rt-x models.
\newblock {\em arXiv preprint arXiv:2310.08864}, 2023.

\bibitem{roboflamingo}
Xinghang Li, Minghuan Liu, Hanbo Zhang, Cunjun Yu, Jie Xu, Hongtao Wu, Chilam
  Cheang, Ya~Jing, Weinan Zhang, Huaping Liu, et~al.
\newblock Vision-language foundation models as effective robot imitators.
\newblock {\em ICLR}, 2024.

\bibitem{mees2022calvin}
Oier Mees, Lukas Hermann, Erick Rosete-Beas, and Wolfram Burgard.
\newblock Calvin: A benchmark for language-conditioned policy learning for
  long-horizon robot manipulation tasks.
\newblock {\em IEEE Robotics and Automation Letters}, 7(3):7327--7334, 2022.

\bibitem{tellex2020robots}
Stefanie Tellex, Nakul Gopalan, Hadas Kress-Gazit, and Cynthia Matuszek.
\newblock Robots that use language.
\newblock {\em Annual Review of Control, Robotics, and Autonomous Systems},
  2020.

\bibitem{MCIL}
Corey Lynch and Pierre Sermanet.
\newblock Language conditioned imitation learning over unstructured data.
\newblock {\em arXiv preprint arXiv:2005.07648}, 2020.

\bibitem{HULC}
Oier Mees, Lukas Hermann, and Wolfram Burgard.
\newblock What matters in language conditioned robotic imitation learning over
  unstructured data.
\newblock {\em IEEE Robotics and Automation Letters}, 7(4):11205--11212, 2022.

\bibitem{mees2023hulc++}
Oier Mees, Jessica Borja-Diaz, and Wolfram Burgard.
\newblock Grounding language with visual affordances over unstructured data.
\newblock In {\em ICRA}, 2023.

\bibitem{rt-1}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis,
  Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine
  Hsu, et~al.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock {\em Proceedings of Robotics: Science and Systems}, 2024.

\bibitem{team2023octo}
Octo~Model Team, Dibya Ghosh, Homer Walke, Karl Pertsch, Kevin Black, Oier
  Mees, Sudeep Dasari, Joey Hejna, Charles Xu, Jianlan Luo, et~al.
\newblock Octo: An open-source generalist robot policy.
\newblock {\em First Workshop on Vision-Language Models for Navigation and
  Manipulation at ICRA 2024}, 2024.

\bibitem{palme}
Danny Driess, Fei Xia, Mehdi~SM Sajjadi, Corey Lynch, Aakanksha Chowdhery,
  Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et~al.
\newblock Palm-e: An embodied multimodal language model.
\newblock {\em ICML}, 2023.

\bibitem{saycan}
Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron
  David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman,
  et~al.
\newblock Do as i can, not as i say: Grounding language in robotic affordances.
\newblock {\em arXiv preprint arXiv:2204.01691}, 2022.

\bibitem{mu2024embodiedgpt}
Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin
  Wang, Jifeng Dai, Yu~Qiao, and Ping Luo.
\newblock Embodiedgpt: Vision-language pre-training via embodied chain of
  thought.
\newblock {\em NeurIPS}, 2023.

\bibitem{wan2023efficient}
Zhongwei Wan, Xin Wang, Che Liu, Samiul Alam, Yu~Zheng, Zhongnan Qu, Shen Yan,
  Yi~Zhu, Quanlu Zhang, Mosharaf Chowdhury, et~al.
\newblock Efficient large language models: A survey.
\newblock {\em arXiv preprint arXiv:2312.03863}, 1, 2023.

\bibitem{samsi2023words}
Siddharth Samsi, Dan Zhao, Joseph McDonald, Baolin Li, Adam Michaleas, Michael
  Jones, William Bergeron, Jeremy Kepner, Devesh Tiwari, and Vijay Gadepally.
\newblock From words to watts: Benchmarking the energy costs of large language
  model inference.
\newblock In {\em 2023 IEEE High Performance Extreme Computing Conference
  (HPEC)}, pages 1--9. IEEE, 2023.

\bibitem{zhou2024survey}
Zixuan Zhou, Xuefei Ning, Ke~Hong, Tianyu Fu, Jiaming Xu, Shiyao Li, Yuming
  Lou, Luning Wang, Zhihang Yuan, Xiuhong Li, et~al.
\newblock A survey on efficient inference for large language models.
\newblock {\em arXiv preprint arXiv:2404.14294}, 2024.

\bibitem{ainslie2023gqa}
Joshua Ainslie, James Lee-Thorp, Michiel de~Jong, Yury Zemlyanskiy, Federico
  Lebron, and Sumit Sanghai.
\newblock Gqa: Training generalized multi-query transformer models from
  multi-head checkpoints.
\newblock In {\em EMNLP}, 2023.

\bibitem{gu2023mamba}
Albert Gu and Tri Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock {\em arXiv preprint arXiv:2312.00752}, 2023.

\bibitem{peng2023rwkv}
Bo~Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Huanqi
  Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi~Kiran GV, et~al.
\newblock Rwkv: Reinventing rnns for the transformer era.
\newblock {\em Findings of EMNLP}, 2023.

\bibitem{sun2023retentive}
Yutao Sun, Li~Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong
  Wang, and Furu Wei.
\newblock Retentive network: A successor to transformer for large language
  models.
\newblock {\em arXiv preprint arXiv:2307.08621}, 2023.

\bibitem{han2023flatten}
Dongchen Han, Xuran Pan, Yizeng Han, Shiji Song, and Gao Huang.
\newblock Flatten transformer: Vision transformer using focused linear
  attention.
\newblock In {\em ICCV}, 2023.

\bibitem{liu2024mobilellm}
Zechun Liu, Changsheng Zhao, Forrest Iandola, Chen Lai, Yuandong Tian, Igor
  Fedorov, Yunyang Xiong, Ernie Chang, Yangyang Shi, Raghuraman Krishnamoorthi,
  et~al.
\newblock Mobilellm: Optimizing sub-billion parameter language models for
  on-device use cases.
\newblock {\em arXiv preprint arXiv:2402.14905}, 2024.

\bibitem{wang2024model}
Huanqian Wang, Yang Yue, Rui Lu, Jingxin Shi, Andrew Zhao, Shenzhi Wang, Shiji
  Song, and Gao Huang.
\newblock Model surgery: Modulating llm's behavior via simple parameter
  editing.
\newblock {\em arXiv preprint arXiv:2407.08770}, 2024.

\bibitem{frantar2023sparsegpt}
Elias Frantar and Dan Alistarh.
\newblock Sparsegpt: Massive language models can be accurately pruned in
  one-shot.
\newblock In {\em ICML}, pages 10323--10337, 2023.

\bibitem{sun2023simple}
Mingjie Sun, Zhuang Liu, Anna Bair, and J~Zico Kolter.
\newblock A simple and effective pruning approach for large language models.
\newblock {\em arXiv preprint arXiv:2306.11695}, 2023.

\bibitem{ma2023llm}
Xinyin Ma, Gongfan Fang, and Xinchao Wang.
\newblock Llm-pruner: On the structural pruning of large language models.
\newblock {\em NeurIPS}, 36:21702--21720, 2023.

\bibitem{park2023lut}
Gunho Park, Minsub Kim, Sungjae Lee, Jeonghoon Kim, Beomseok Kwon, Se~Jung
  Kwon, Byeongwook Kim, Youngjoo Lee, Dongsoo Lee, et~al.
\newblock Lut-gemm: Quantized matrix multiplication based on luts for efficient
  inference in large-scale generative language models.
\newblock In {\em ICLR}, 2023.

\bibitem{chee2023quip}
Jerry Chee, Yaohui Cai, Volodymyr Kuleshov, and Christopher~M De~Sa.
\newblock Quip: 2-bit quantization of large language models with guarantees.
\newblock {\em NeurIPS}, 2023.

\bibitem{xiao2023smoothquant}
Guangxuan Xiao, Ji~Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han.
\newblock Smoothquant: Accurate and efficient post-training quantization for
  large language models.
\newblock In {\em ICML}, pages 38087--38099, 2023.

\bibitem{li2023llm}
Shiyao Li, Xuefei Ning, Ke~Hong, Tengxuan Liu, Luning Wang, Xiuhong Li, Kai
  Zhong, Guohao Dai, Huazhong Yang, and Yu~Wang.
\newblock Llm-mq: Mixed-precision quantization for efficient llm deployment.
\newblock In {\em The Efficient Natural Language and Speech Processing Workshop
  with NeurIPS}, volume~9, 2023.

\bibitem{han2021dynamic}
Yizeng Han, Gao Huang, Shiji Song, Le~Yang, Honghui Wang, and Yulin Wang.
\newblock Dynamic neural networks: A survey.
\newblock {\em TPAMI}, 44(11):7436--7456, 2021.

\bibitem{del2023skipdecode}
Luciano Del~Corro, Allie Del~Giorno, Sahaj Agarwal, Bin Yu, Ahmed Awadallah,
  and Subhabrata Mukherjee.
\newblock Skipdecode: Autoregressive skip decoding with batching and caching
  for efficient llm inference.
\newblock {\em arXiv preprint arXiv:2307.02628}, 2023.

\bibitem{elhoushi2024layerskip}
Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram
  Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman,
  et~al.
\newblock Layer skip: Enabling early exit inference and self-speculative
  decoding.
\newblock {\em arXiv preprint arXiv:2404.16710}, 2024.

\bibitem{raposo2024mixture}
David Raposo, Sam Ritter, Blake Richards, Timothy Lillicrap, Peter~Conway
  Humphreys, and Adam Santoro.
\newblock Mixture-of-depths: Dynamically allocating compute in
  transformer-based language models.
\newblock {\em arXiv preprint arXiv:2404.02258}, 2024.

\bibitem{wang2021not}
Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, and Gao Huang.
\newblock Not all images are worth 16x16 words: Dynamic transformers for
  efficient image recognition.
\newblock {\em Advances in neural information processing systems},
  34:11960--11973, 2021.

\bibitem{bolukbasi2017adaptive}
Tolga Bolukbasi, Joseph Wang, Ofer Dekel, and Venkatesh Saligrama.
\newblock Adaptive neural networks for efficient inference.
\newblock In {\em ICML}, 2017.

\bibitem{msdnet}
Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens Van Der~Maaten, and
  Kilian~Q Weinberger.
\newblock Multi-scale dense networks for resource efficient image
  classification.
\newblock {\em ICLR}, 2018.

\bibitem{han2023dynamic}
Yizeng Han, Dongchen Han, Zeyu Liu, Yulin Wang, Xuran Pan, Yifan Pu, Chao Deng,
  Junlan Feng, Shiji Song, and Gao Huang.
\newblock Dynamic perceiver for efficient visual recognition.
\newblock In {\em ICCV}, 2023.

\bibitem{yang2021condensenet}
Le~Yang, Haojun Jiang, Ruojin Cai, Yulin Wang, Shiji Song, Gao Huang, and
  Qi~Tian.
\newblock Condensenet v2: Sparse feature reactivation for deep networks.
\newblock In {\em CVPR}, 2021.

\bibitem{10508473}
Yizeng Han, Zeyu Liu, Zhihang Yuan, Yifan Pu, Chaofei Wang, Shiji Song, and Gao
  Huang.
\newblock Latency-aware unified dynamic networks for efficient image
  recognition.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  pages 1--17, 2024.

\bibitem{elbayad2019depth}
Maha Elbayad, Jiatao Gu, Edouard Grave, and Michael Auli.
\newblock Depth-adaptive transformer.
\newblock {\em ICLR}, 2020.

\bibitem{xin2021berxit}
Ji~Xin, Raphael Tang, Yaoliang Yu, and Jimmy Lin.
\newblock Berxit: Early exiting for bert with better fine-tuning and extension
  to regression.
\newblock In {\em ACL}, 2021.

\bibitem{xin2020deebert}
Ji~Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy Lin.
\newblock Deebert: Dynamic early exiting for accelerating bert inference.
\newblock {\em arXiv preprint arXiv:2004.12993}, 2020.

\bibitem{liu2020fastbert}
Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Haotang Deng, and Qi~Ju.
\newblock Fastbert: a self-distilling bert with adaptive inference time.
\newblock {\em arXiv preprint arXiv:2004.02178}, 2020.

\bibitem{mangrulkar2022be3r}
Sourab Mangrulkar, Ankith MS, and Vivek Sembium.
\newblock Be3r: Bert based early-exit using expert routing.
\newblock In {\em KDD}, 2022.

\bibitem{chen2023ee}
Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, and Jingren Zhou.
\newblock Ee-llm: Large-scale training and inference of early-exit large
  language models with 3d parallelism.
\newblock {\em arXiv preprint arXiv:2312.04916}, 2023.

\bibitem{schuster2022confident}
Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Vinh Tran,
  Yi~Tay, and Donald Metzler.
\newblock Confident adaptive language modeling.
\newblock {\em NeurIPS}, 2022.

\bibitem{fei2022deecap}
Zhengcong Fei, Xu~Yan, Shuhui Wang, and Qi~Tian.
\newblock Deecap: Dynamic early exiting for efficient image captioning.
\newblock In {\em CVPR}, pages 12216--12226, 2022.

\bibitem{tang2023you}
Shengkun Tang, Yaqing Wang, Zhenglun Kong, Tianchi Zhang, Yao Li, Caiwen Ding,
  Yanzhi Wang, Yi~Liang, and Dongkuan Xu.
\newblock You need multiple exiting: Dynamic early exiting for accelerating
  unified vision language model.
\newblock In {\em CVPR}, 2023.

\bibitem{ghodrati2021frameexit}
Amir Ghodrati, Babak~Ehteshami Bejnordi, and Amirhossein Habibian.
\newblock Frameexit: Conditional early exiting for efficient video recognition.
\newblock In {\em CVPR}, 2021.

\bibitem{Ni2024AdaNAT}
Zanlin Ni, Yulin Wang, Renping Zhou, Rui Lu, Jiayi Guo, Jinyi Hu, Zhiyuan Liu,
  Yuan Yao, and Gao Huang.
\newblock Adanat: Exploring adaptive policy for token-based image generation.
\newblock In {\em ECCV}, 2024.

\bibitem{fang2024real}
Chengyu Fang, Chunming He, Fengyang Xiao, Yulun Zhang, Longxiang Tang, Yuelin
  Zhang, Kai Li, and Xiu Li.
\newblock Real-world image dehazing with coherence-based label generator and
  cooperative unfolding network.
\newblock {\em arXiv preprint arXiv:2406.07966}, 2024.

\bibitem{yue2023value}
Yang Yue, Bingyi Kang, Zhongwen Xu, Gao Huang, and Shuicheng Yan.
\newblock Value-consistent representation learning for data-efficient
  reinforcement learning.
\newblock In {\em AAAI}, 2023.

\bibitem{alayrac2022flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds,
  et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock {\em NeurIPS}, 2022.

\bibitem{awadalla2023openflamingo}
Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu,
  Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, et~al.
\newblock Openflamingo: An open-source framework for training large
  autoregressive vision-language models.
\newblock {\em arXiv preprint arXiv:2308.01390}, 2023.

\bibitem{vit}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zi-Hang Jiang,
  Francis~EH Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock In {\em ICCV}, 2021.

\bibitem{smallwood1973pomdp}
Richard~D Smallwood and Edward~J Sondik.
\newblock The optimal control of partially observable markov processes over a
  finite horizon.
\newblock {\em Operations research}, 1973.

\bibitem{lstm}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 1997.

\bibitem{yang2020resolution}
Le~Yang, Yizeng Han, Xi~Chen, Shiji Song, Jifeng Dai, and Gao Huang.
\newblock Resolution adaptive networks for efficient inference.
\newblock In {\em CVPR}, 2020.

\bibitem{teerapittayanon2016branchynet}
Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung Kung.
\newblock Branchynet: Fast inference via early exiting from deep neural
  networks.
\newblock {\em ICPR}, 2016.

\bibitem{shahriari2015bayes}
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan~P Adams, and Nando De~Freitas.
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock {\em Proceedings of the IEEE}, 2015.

\bibitem{Sutton1998RLbook}
Richard~S. Sutton and Andrew~G. Barto.
\newblock Reinforcement learning: An introduction.
\newblock 1998.

\bibitem{wu2023unleashing}
Hongtao Wu, Ya~Jing, Chilam Cheang, Guangzeng Chen, Jiafeng Xu, Xinghang Li,
  Minghuan Liu, Hang Li, and Tao Kong.
\newblock Unleashing large-scale video generative pre-training for visual robot
  manipulation, 2023.

\bibitem{zhou2023spil}
Hongkuan Zhou, Zhenshan Bing, Xiangtong Yao, Xiaojie Su, Chenguang Yang, Kai
  Huang, and Alois Knoll.
\newblock Language-conditioned imitation learning with base skill priors under
  unstructured data.
\newblock {\em ICML}, 2024.

\bibitem{susie}
Kevin Black, Mitsuhiko Nakamoto, Pranav Atreya, Homer Walke, Chelsea Finn,
  Aviral Kumar, and Sergey Levine.
\newblock Zero-shot robotic manipulation with pretrained image-editing
  diffusion models.
\newblock {\em ICLR}, 2024.

\bibitem{brooks2023instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In {\em CVPR}, 2023.

\bibitem{zhang2022lcd}
Edwin Zhang, Yujie Lu, William Wang, and Amy Zhang.
\newblock Language control diffusion: Efficiently scaling through space, time,
  and tasks.
\newblock {\em arXiv preprint arXiv:2210.15629}, 2022.

\bibitem{ba2016layernorm}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{seem}
Yang Yue, Rui Lu, Bingyi Kang, Shiji Song, and Gao Huang.
\newblock Understanding, predicting and better resolving q-value divergence in
  offline-rl.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{mpt}
MosaicML~NLP Team.
\newblock Introducing mpt-7b: A new standard for open-source, commercially
  usable llms, 2023.
\newblock Accessed: 2023-05-05.

\end{thebibliography}
