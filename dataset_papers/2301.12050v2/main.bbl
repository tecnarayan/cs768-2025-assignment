\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2022)Agarwal, Schwarzer, Castro, Courville, and
  Bellemare]{agarwal2022reincarnating}
Agarwal, R., Schwarzer, M., Castro, P.~S., Courville, A., and Bellemare, M.~G.
\newblock Reincarnating reinforcement learning: Reusing prior computation to
  accelerate progress.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.),
  \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=t3X5yMI_4G2}.

\bibitem[Ammanabrolu \& Riedl(2021)Ammanabrolu and
  Riedl]{ammanabrolu2021learning}
Ammanabrolu, P. and Riedl, M.
\newblock Learning knowledge graph-based world models of textual environments.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 3720--3731, 2021.

\bibitem[Ammanabrolu et~al.(2020)Ammanabrolu, Tien, Hausknecht, and
  Riedl]{ammanabrolu2020avoid}
Ammanabrolu, P., Tien, E., Hausknecht, M., and Riedl, M.~O.
\newblock How to avoid being eaten by a grue: Structured exploration strategies
  for textual worlds.
\newblock \emph{arXiv preprint arXiv:2006.07409}, 2020.

\bibitem[Anderson et~al.(2018)Anderson, Wu, Teney, Bruce, Johnson, Sünderhauf,
  Reid, Gould, and van~den Hengel]{Anderson_2018_CVPR}
Anderson, P., Wu, Q., Teney, D., Bruce, J., Johnson, M., Sünderhauf, N., Reid,
  I., Gould, S., and van~den Hengel, A.
\newblock Vision-and-language navigation: Interpreting visually-grounded
  navigation instructions in real environments.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2018.

\bibitem[Baker et~al.(2022)Baker, Akkaya, Zhokov, Huizinga, Tang, Ecoffet,
  Houghton, Sampedro, and Clune]{bakervideo}
Baker, B., Akkaya, I., Zhokov, P., Huizinga, J., Tang, J., Ecoffet, A.,
  Houghton, B., Sampedro, R., and Clune, J.
\newblock Video pretraining (vpt): Learning to act by watching unlabeled online
  videos.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Bisk et~al.(2020)Bisk, Holtzman, Thomason, Andreas, Bengio, Chai,
  Lapata, Lazaridou, May, Nisnevich, et~al.]{bisk2020experience}
Bisk, Y., Holtzman, A., Thomason, J., Andreas, J., Bengio, Y., Chai, J.,
  Lapata, M., Lazaridou, A., May, J., Nisnevich, A., et~al.
\newblock Experience grounds language.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  8718--8735, 2020.

\bibitem[Blukis et~al.(2022)Blukis, Paxton, Fox, Garg, and
  Artzi]{pmlr-v164-blukis22a}
Blukis, V., Paxton, C., Fox, D., Garg, A., and Artzi, Y.
\newblock A persistent spatial semantic representation for high-level natural
  language instruction execution.
\newblock In Faust, A., Hsu, D., and Neumann, G. (eds.), \emph{Proceedings of
  the 5th Conference on Robot Learning}, volume 164 of \emph{Proceedings of
  Machine Learning Research}, pp.\  706--717. PMLR, 08--11 Nov 2022.
\newblock URL \url{https://proceedings.mlr.press/v164/blukis22a.html}.

\bibitem[Branavan et~al.(2011)Branavan, Silver, and
  Barzilay]{branavan2011learning}
Branavan, S., Silver, D., and Barzilay, R.
\newblock Learning to win by reading manuals in a monte-carlo framework.
\newblock In \emph{Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies}, pp.\  268--277,
  2011.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Chevalier-Boisvert et~al.(2019)Chevalier-Boisvert, Bahdanau, Lahlou,
  Willems, Saharia, Nguyen, and Bengio]{chevalier-boisvert2018babyai}
Chevalier-Boisvert, M., Bahdanau, D., Lahlou, S., Willems, L., Saharia, C.,
  Nguyen, T.~H., and Bengio, Y.
\newblock Baby{AI}: First steps towards grounded language learning with a human
  in the loop.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=rJeXCo0cYX}.

\bibitem[Dambekodi et~al.(2020)Dambekodi, Frazier, Ammanabrolu, and
  Riedl]{dambekodi2020playing}
Dambekodi, S., Frazier, S., Ammanabrolu, P., and Riedl, M.
\newblock Playing text-based games with common sense.
\newblock In \emph{Proceedings of the NeurIPS Workshop on Wordplay: When
  Language Meets Games}, 2020.

\bibitem[Das et~al.(2018)Das, Datta, Gkioxari, Lee, Parikh, and
  Batra]{Das_2018_CVPR}
Das, A., Datta, S., Gkioxari, G., Lee, S., Parikh, D., and Batra, D.
\newblock Embodied question answering.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2018.

\bibitem[Fan et~al.(2022)Fan, Wang, Jiang, Mandlekar, Yang, Zhu, Tang, Huang,
  Zhu, and Anandkumar]{fanminedojo}
Fan, L., Wang, G., Jiang, Y., Mandlekar, A., Yang, Y., Zhu, H., Tang, A.,
  Huang, D.-A., Zhu, Y., and Anandkumar, A.
\newblock Minedojo: Building open-ended embodied agents with internet-scale
  knowledge.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}, 2022.

\bibitem[Gordon et~al.(2018)Gordon, Kembhavi, Rastegari, Redmon, Fox, and
  Farhadi]{gordon2018iqa}
Gordon, D., Kembhavi, A., Rastegari, M., Redmon, J., Fox, D., and Farhadi, A.
\newblock Iqa: Visual question answering in interactive environments.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4089--4098, 2018.

\bibitem[Guss et~al.(2019)Guss, Houghton, Topin, Wang, Codel, Veloso, and
  Salakhutdinov]{GussMineRL}
Guss, W.~H., Houghton, B., Topin, N., Wang, P., Codel, C., Veloso, M., and
  Salakhutdinov, R.
\newblock Minerl: A large-scale dataset of minecraft demonstrations.
\newblock In \emph{Proceedings of the 28th International Joint Conference on
  Artificial Intelligence}, IJCAI'19, pp.\  2442–2448. AAAI Press, 2019.
\newblock ISBN 9780999241141.

\bibitem[Hafner et~al.(2023)Hafner, Pasukonis, Ba, and
  Lillicrap]{danijardreamer}
Hafner, D., Pasukonis, J., Ba, J., and Lillicrap, T.
\newblock Mastering diverse domains through world models, 2023.
\newblock URL \url{https://arxiv.org/abs/2301.04104}.

\bibitem[Hanjie et~al.(2021)Hanjie, Zhong, and Narasimhan]{hanjie2021grounding}
Hanjie, A.~W., Zhong, V.~Y., and Narasimhan, K.
\newblock Grounding language to entities and dynamics for generalization in
  reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4051--4062. PMLR, 2021.

\bibitem[Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone,
  De~Laroussilhe, Gesmundo, Attariyan, and Gelly]{houlsby2019parameter}
Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De~Laroussilhe, Q.,
  Gesmundo, A., Attariyan, M., and Gelly, S.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2790--2799. PMLR, 2019.

\bibitem[Huang et~al.(2022{\natexlab{a}})Huang, Abbeel, Pathak, and
  Mordatch]{huang2022language}
Huang, W., Abbeel, P., Pathak, D., and Mordatch, I.
\newblock Language models as zero-shot planners: Extracting actionable
  knowledge for embodied agents.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9118--9147. PMLR, 2022{\natexlab{a}}.

\bibitem[Huang et~al.(2022{\natexlab{b}})Huang, Xia, Xiao, Chan, Liang,
  Florence, Zeng, Tompson, Mordatch, Chebotar, et~al.]{huanginner}
Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence, P., Zeng, A.,
  Tompson, J., Mordatch, I., Chebotar, Y., et~al.
\newblock Inner monologue: Embodied reasoning through planning with language
  models.
\newblock In \emph{6th Annual Conference on Robot Learning},
  2022{\natexlab{b}}.

\bibitem[Ichter et~al.(2022)Ichter, Brohan, Chebotar, Finn, Hausman, Herzog,
  Ho, Ibarz, Irpan, Jang, Julian, Kalashnikov, Levine, Lu, Parada, Rao,
  Sermanet, Toshev, Vanhoucke, Xia, Xiao, Xu, Yan, Brown, Ahn, Cortes, Sievers,
  Tan, Xu, Reyes, Rettinghouse, Quiambao, Pastor, Luu, Lee, Kuang, Jesmonth,
  Jeffrey, Ruano, Hsu, Gopalakrishnan, David, Zeng, and Fu]{ichter2022do}
Ichter, B., Brohan, A., Chebotar, Y., Finn, C., Hausman, K., Herzog, A., Ho,
  D., Ibarz, J., Irpan, A., Jang, E., Julian, R., Kalashnikov, D., Levine, S.,
  Lu, Y., Parada, C., Rao, K., Sermanet, P., Toshev, A.~T., Vanhoucke, V., Xia,
  F., Xiao, T., Xu, P., Yan, M., Brown, N., Ahn, M., Cortes, O., Sievers, N.,
  Tan, C., Xu, S., Reyes, D., Rettinghouse, J., Quiambao, J., Pastor, P., Luu,
  L., Lee, K.-H., Kuang, Y., Jesmonth, S., Jeffrey, K., Ruano, R.~J., Hsu, J.,
  Gopalakrishnan, K., David, B., Zeng, A., and Fu, C.~K.
\newblock Do as i can, not as i say: Grounding language in robotic affordances.
\newblock In \emph{6th Annual Conference on Robot Learning}, 2022.
\newblock URL \url{https://openreview.net/forum?id=bdHkMjBJG_w}.

\bibitem[Ku et~al.(2020)Ku, Anderson, Patel, Ie, and Baldridge]{ku2020room}
Ku, A., Anderson, P., Patel, R., Ie, E., and Baldridge, J.
\newblock Room-across-room: Multilingual vision-and-language navigation with
  dense spatiotemporal grounding.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  4392--4412, 2020.

\bibitem[Kuo et~al.(2021)Kuo, Katz, and Barbu]{kuo2021compositional}
Kuo, Y.-L., Katz, B., and Barbu, A.
\newblock Compositional networks enable systematic generalization for grounded
  language understanding.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pp.\  216--226, 2021.

\bibitem[Liang et~al.(2022{\natexlab{a}})Liang, Singh, Pertsch, and
  Thomason]{liang2022transformer}
Liang, A., Singh, I., Pertsch, K., and Thomason, J.
\newblock Transformer adapters for robot learning.
\newblock In \emph{CoRL 2022 Workshop on Pre-training Robot Learning},
  2022{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=H--wvRYBmF}.

\bibitem[Liang et~al.(2022{\natexlab{b}})Liang, Huang, Xia, Xu, Hausman,
  Florence, Zeng, et~al.]{liang2022code}
Liang, J., Huang, W., Xia, F., Xu, P., Hausman, K., Florence, P., Zeng, A.,
  et~al.
\newblock Code as policies: Language model programs for embodied control.
\newblock In \emph{Workshop on Language and Robotics at CoRL 2022},
  2022{\natexlab{b}}.

\bibitem[Liu et~al.(2022)Liu, Wei, Gu, Wu, Vosoughi, Cui, Zhou, and
  Dai]{liu2022mind}
Liu, R., Wei, J., Gu, S.~S., Wu, T.-Y., Vosoughi, S., Cui, C., Zhou, D., and
  Dai, A.~M.
\newblock Mind's eye: Grounded language model reasoning through simulation.
\newblock \emph{arXiv preprint arXiv:2210.05359}, 2022.

\bibitem[Lynch \& Sermanet(2020)Lynch and Sermanet]{Lynch2020LanguageCI}
Lynch, C. and Sermanet, P.
\newblock Language conditioned imitation learning over unstructured data.
\newblock \emph{Robotics: Science and Systems XVII}, 2020.

\bibitem[Mu et~al.(2022)Mu, Zhong, Raileanu, Jiang, Goodman, Rockt{\"a}schel,
  and Grefenstette]{mu2022improving}
Mu, J., Zhong, V., Raileanu, R., Jiang, M., Goodman, N., Rockt{\"a}schel, T.,
  and Grefenstette, E.
\newblock Improving intrinsic exploration with language abstractions.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.),
  \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=ALIYCycCsTy}.

\bibitem[Nottingham et~al.(2021)Nottingham, Liang, Shin, Fowlkes, Fox, and
  Singh]{nottingham2021modular}
Nottingham, K., Liang, L., Shin, D., Fowlkes, C.~C., Fox, R., and Singh, S.
\newblock Modular framework for visuomotor language grounding.
\newblock In \emph{Embodied AI Workshop @ CVPR}, 2021.

\bibitem[Nottingham et~al.(2022)Nottingham, Pyla, Singh, and
  Fox]{nottingham2022learning}
Nottingham, K., Pyla, A., Singh, S., and Fox, R.
\newblock Learning to query internet text for informing reinforcement learning
  agents.
\newblock In \emph{Reinforcement Learning and Decision Making Conference},
  2022.

\bibitem[OpenAI(2022)]{OpenAICodex}
OpenAI.
\newblock Powering next generation applications with openai codex, 2022.
\newblock URL \url{https://openai.com/blog/codex-apps/}.

\bibitem[Patil et~al.(2020)Patil, Hofmarcher, Dinu, Dorfer, Blies,
  Brandstetter, Arjona-Medina, and Hochreiter]{Patil2020AlignRUDDERLF}
Patil, V., Hofmarcher, M., Dinu, M.-C., Dorfer, M., Blies, P.~M., Brandstetter,
  J., Arjona-Medina, J.~A., and Hochreiter, S.
\newblock Align-rudder: Learning from few demonstrations by reward
  redistribution.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Petroni et~al.(2019)Petroni, Rockt{\"a}schel, Riedel, Lewis, Bakhtin,
  Wu, and Miller]{petroni2019language}
Petroni, F., Rockt{\"a}schel, T., Riedel, S., Lewis, P., Bakhtin, A., Wu, Y.,
  and Miller, A.
\newblock Language models as knowledge bases?
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pp.\  2463--2473, 2019.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Shridhar et~al.(2020)Shridhar, Thomason, Gordon, Bisk, Han, Mottaghi,
  Zettlemoyer, and Fox]{Shridhar_2020_CVPR}
Shridhar, M., Thomason, J., Gordon, D., Bisk, Y., Han, W., Mottaghi, R.,
  Zettlemoyer, L., and Fox, D.
\newblock Alfred: A benchmark for interpreting grounded instructions for
  everyday tasks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2020.

\bibitem[Simpkins \& Isbell(2019)Simpkins and Isbell]{Simpkins_Isbell_2019}
Simpkins, C. and Isbell, C.
\newblock Composable modular reinforcement learning.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  33\penalty0 (01):\penalty0 4975--4982, Jul. 2019.
\newblock \doi{10.1609/aaai.v33i01.33014975}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/4428}.

\bibitem[Singh et~al.(2022)Singh, Blukis, Mousavian, Goyal, Xu, Tremblay, Fox,
  Thomason, and Garg]{singhprogprompt}
Singh, I., Blukis, V., Mousavian, A., Goyal, A., Xu, D., Tremblay, J., Fox, D.,
  Thomason, J., and Garg, A.
\newblock Progprompt: Generating situated robot task plans using large language
  models.
\newblock In \emph{Second Workshop on Language and Reinforcement Learning},
  2022.

\bibitem[Skrynnik et~al.(2021)Skrynnik, Staroverov, Aitygulov, Aksenov,
  Davydov, and Panov]{SkrynnikForgetful}
Skrynnik, A., Staroverov, A., Aitygulov, E., Aksenov, K., Davydov, V., and
  Panov, A.~I.
\newblock Forgetful experience replay in hierarchical reinforcement learning
  from expert demonstrations.
\newblock \emph{Know.-Based Syst.}, 218\penalty0 (C), apr 2021.
\newblock ISSN 0950-7051.
\newblock \doi{10.1016/j.knosys.2021.106844}.
\newblock URL \url{https://doi.org/10.1016/j.knosys.2021.106844}.

\bibitem[Song et~al.(2022{\natexlab{a}})Song, Kil, Pan, Sadler, Chao, and
  Su]{Song_2022_CVPR}
Song, C.~H., Kil, J., Pan, T.-Y., Sadler, B.~M., Chao, W.-L., and Su, Y.
\newblock One step at a time: Long-horizon vision-and-language navigation with
  milestones.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  15482--15491, June 2022{\natexlab{a}}.

\bibitem[Song et~al.(2022{\natexlab{b}})Song, Wu, Washington, Sadler, Chao, and
  Su]{song2022llm}
Song, C.~H., Wu, J., Washington, C., Sadler, B.~M., Chao, W.-L., and Su, Y.
\newblock Llm-planner: Few-shot grounded planning for embodied agents with
  large language models.
\newblock \emph{arXiv preprint arXiv:2212.04088}, 2022{\natexlab{b}}.

\bibitem[Suglia et~al.(2021)Suglia, Gao, Thomason, Thattai, and
  Sukhatme]{SugliaEmbodied}
Suglia, A., Gao, Q., Thomason, J., Thattai, G., and Sukhatme, G.
\newblock Embodied bert: A transformer model for embodied, language-guided
  visual task completion.
\newblock \emph{CoRR}, abs/2108.04927, 2021.
\newblock URL \url{https://arxiv.org/abs/2108.04927}.

\bibitem[Tam et~al.(2022)Tam, Rabinowitz, Lampinen, Roy, Chan, Strouse, Wang,
  Banino, and Hill]{tam2022semantic}
Tam, A.~C., Rabinowitz, N.~C., Lampinen, A.~K., Roy, N.~A., Chan, S.~C.,
  Strouse, D., Wang, J.~X., Banino, A., and Hill, F.
\newblock Semantic exploration from language abstractions and pretrained
  representations.
\newblock \emph{arXiv preprint arXiv:2204.05080}, 2022.

\bibitem[Valmeekam et~al.(2022)Valmeekam, Olmo, Sreedharan, and
  Kambhampati]{valmeekam2022large}
Valmeekam, K., Olmo, A., Sreedharan, S., and Kambhampati, S.
\newblock Large language models still can't plan (a benchmark for llms on
  planning and reasoning about change).
\newblock In \emph{NeurIPS 2022 Foundation Models for Decision Making
  Workshop}, 2022.

\bibitem[Yu et~al.(2018)Yu, Zhang, and Xu]{yu2018interactive}
Yu, H., Zhang, H., and Xu, W.
\newblock Interactive grounded language acquisition and generalization in a 2d
  world.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Zellers et~al.(2021)Zellers, Holtzman, Peters, Mottaghi, Kembhavi,
  Farhadi, and Choi]{zellers2021piglet}
Zellers, R., Holtzman, A., Peters, M.~E., Mottaghi, R., Kembhavi, A., Farhadi,
  A., and Choi, Y.
\newblock Piglet: Language grounding through neuro-symbolic interaction in a 3d
  world.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pp.\  2040--2050, 2021.

\bibitem[Zhong et~al.(2020)Zhong, Rocktäschel, and
  Grefenstette]{Zhong2020RTFM}
Zhong, V., Rocktäschel, T., and Grefenstette, E.
\newblock Rtfm: Generalising to new environment dynamics via reading.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SJgob6NKvH}.

\end{thebibliography}
