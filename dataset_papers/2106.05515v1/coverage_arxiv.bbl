\begin{thebibliography}{73}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[bik(Accessed: May, 2021)]{bike}
Bike sharing data set.
\newblock \url{https://archive.ics.uci.edu/ml/datasets/bike+ sharing+dataset},
  Accessed: May, 2021.

\bibitem[com(Accessed: May, 2021)]{community}
Communities and crime data set.
\newblock \url{http://archive.ics.uci.edu/ml/datasets/ communities+and+crime},
  Accessed: May, 2021.

\bibitem[mep(Accessed: May, 2021{\natexlab{a}})]{meps19}
Medical expenditure panel survey, panel 19, Accessed: May, 2021{\natexlab{a}}.
\newblock URL \url{https://meps.ahrq.gov/mepsweb/data_
  stats/download_data_files_detail.jsp?cboPufNumber=HC-181}.

\bibitem[mep(Accessed: May, 2021{\natexlab{b}})]{meps20}
Medical expenditure panel survey, panel 20.
\newblock \url{https://meps.ahrq.gov/mepsweb/data_
  stats/download_data_files_detail.jsp?cboPufNumber=HC-181}, Accessed: May,
  2021{\natexlab{b}}.

\bibitem[mep(Accessed: May, 2021{\natexlab{c}})]{meps21}
Medical expenditure panel survey, panel 21.
\newblock \url{https://meps.ahrq.gov/mepsweb/data_
  stats/download_data_files_detail.jsp?cboPufNumber=HC-192}, Accessed: May,
  2021{\natexlab{c}}.

\bibitem[Achilles et~al.(2008)Achilles, Bain, Bellott, Boyd-Zaharias, Finn,
  Folger, Johnston, and Word]{star}
C.~Achilles, H.~P. Bain, F.~Bellott, J.~Boyd-Zaharias, J.~Finn, J.~Folger,
  J.~Johnston, and E.~Word.
\newblock Tennesseeâ€™s student teacher achievement ratio (star) project.
\newblock \emph{Harvard Dataverse}, 1:\penalty0 2008, 2008.

\bibitem[Angelopoulos et~al.(2020)Angelopoulos, Bates, Malik, and
  Jordan]{angelopoulos2020uncertainty}
A.~Angelopoulos, S.~Bates, J.~Malik, and M.~I. Jordan.
\newblock Uncertainty sets for image classifiers using conformal prediction.
\newblock \emph{arXiv preprint arXiv:2009.14193}, 2020.

\bibitem[Bai et~al.(2021)Bai, Mei, Wang, and Xiong]{bai2021don}
Y.~Bai, S.~Mei, H.~Wang, and C.~Xiong.
\newblock Don't just blame over-parametrization for over-confidence:
  Theoretical analysis of calibration in binary classification.
\newblock \emph{arXiv preprint arXiv:2102.07856}, 2021.

\bibitem[Barber et~al.(2019{\natexlab{a}})Barber, Candes, Ramdas, and
  Tibshirani]{barber2019conformal}
R.~F. Barber, E.~J. Candes, A.~Ramdas, and R.~J. Tibshirani.
\newblock Conformal prediction under covariate shift.
\newblock \emph{arXiv preprint arXiv:1904.06019}, 2019{\natexlab{a}}.

\bibitem[Barber et~al.(2019{\natexlab{b}})Barber, Candes, Ramdas, and
  Tibshirani]{barber2019limits}
R.~F. Barber, E.~J. Candes, A.~Ramdas, and R.~J. Tibshirani.
\newblock The limits of distribution-free conditional predictive inference.
\newblock \emph{arXiv preprint arXiv:1903.04684}, 2019{\natexlab{b}}.

\bibitem[Barber et~al.(2021)Barber, Candes, Ramdas, and
  Tibshirani]{barber2021predictive}
R.~F. Barber, E.~J. Candes, A.~Ramdas, and R.~J. Tibshirani.
\newblock Predictive inference with the jackknife+.
\newblock \emph{The Annals of Statistics}, 49\penalty0 (1):\penalty0 486--507,
  2021.

\bibitem[Bates et~al.(2021)Bates, Angelopoulos, Lei, Malik, and
  Jordan]{bates2021distribution}
S.~Bates, A.~Angelopoulos, L.~Lei, J.~Malik, and M.~I. Jordan.
\newblock Distribution-free, risk-controlling prediction sets.
\newblock \emph{arXiv preprint arXiv:2101.02703}, 2021.

\bibitem[Bayati and Montanari(2011)]{bayati2011dynamics}
M.~Bayati and A.~Montanari.
\newblock The dynamics of message passing on dense graphs, with applications to
  compressed sensing.
\newblock \emph{IEEE Transactions on Information Theory}, 57\penalty0
  (2):\penalty0 764--785, 2011.

\bibitem[Bayati et~al.(2015)Bayati, Lelarge, Montanari,
  et~al.]{bayati2015universality}
M.~Bayati, M.~Lelarge, A.~Montanari, et~al.
\newblock Universality in polytope phase transitions and message passing
  algorithms.
\newblock \emph{Annals of Applied Probability}, 25\penalty0 (2):\penalty0
  753--822, 2015.

\bibitem[Begoli et~al.(2019)Begoli, Bhattacharya, and Kusnezov]{begoli2019need}
E.~Begoli, T.~Bhattacharya, and D.~Kusnezov.
\newblock The need for uncertainty quantification in machine-assisted medical
  decision making.
\newblock \emph{Nature Machine Intelligence}, 1\penalty0 (1):\penalty0 20--23,
  2019.

\bibitem[Cand{\`e}s et~al.(2020)Cand{\`e}s, Sur, et~al.]{candes2020phase}
E.~J. Cand{\`e}s, P.~Sur, et~al.
\newblock The phase transition for the existence of the maximum likelihood
  estimate in high-dimensional logistic regression.
\newblock \emph{The Annals of Statistics}, 48\penalty0 (1):\penalty0 27--42,
  2020.

\bibitem[Cauchois et~al.(2020)Cauchois, Gupta, Ali, and
  Duchi]{cauchois2020robust}
M.~Cauchois, S.~Gupta, A.~Ali, and J.~C. Duchi.
\newblock Robust validation: Confident predictions even when distributions
  shift.
\newblock \emph{arXiv preprint arXiv:2008.04267}, 2020.

\bibitem[Cauchois et~al.(2021)Cauchois, Gupta, and Duchi]{cauchois2021knowing}
M.~Cauchois, S.~Gupta, and J.~C. Duchi.
\newblock Knowing what you know: valid and validated confidence sets in
  multiclass and multilabel prediction.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (81):\penalty0 1--42, 2021.

\bibitem[Christmann and Steinwart(2007)]{christmann2007svms}
A.~Christmann and I.~Steinwart.
\newblock How svms can estimate quantiles and the median.
\newblock In \emph{Advances in neural information processing systems}, pages
  305--312, 2007.

\bibitem[Donoho and Montanari(2016)]{donoho2016high}
D.~Donoho and A.~Montanari.
\newblock High dimensional robust m-estimation: Asymptotic variance via
  approximate message passing.
\newblock \emph{Probability Theory and Related Fields}, 166\penalty0
  (3):\penalty0 935--969, 2016.

\bibitem[Donoho et~al.(2009)Donoho, Maleki, and Montanari]{donoho2009message}
D.~L. Donoho, A.~Maleki, and A.~Montanari.
\newblock Message-passing algorithms for compressed sensing.
\newblock \emph{Proceedings of the National Academy of Sciences}, 106\penalty0
  (45):\penalty0 18914--18919, 2009.

\bibitem[Dua and Graff(2017)]{dua2017}
D.~Dua and C.~Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[El~Karoui et~al.(2013)El~Karoui, Bean, Bickel, Lim, and
  Yu]{el2013robust}
N.~El~Karoui, D.~Bean, P.~J. Bickel, C.~Lim, and B.~Yu.
\newblock On robust regression with high-dimensional predictors.
\newblock \emph{Proceedings of the National Academy of Sciences}, 110\penalty0
  (36):\penalty0 14557--14562, 2013.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Y.~Gal and Z.~Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pages
  1050--1059. PMLR, 2016.

\bibitem[Geisser(1975)]{geisser1975predictive}
S.~Geisser.
\newblock The predictive sample reuse method with applications.
\newblock \emph{Journal of the American statistical Association}, 70\penalty0
  (350):\penalty0 320--328, 1975.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock \emph{arXiv preprint arXiv:1706.04599}, 2017.

\bibitem[Gupta et~al.(2020)Gupta, Podkopaev, and Ramdas]{gupta2020distribution}
C.~Gupta, A.~Podkopaev, and A.~Ramdas.
\newblock Distribution-free binary classification: prediction sets, confidence
  intervals and calibration.
\newblock \emph{arXiv preprint arXiv:2006.10564}, 2020.

\bibitem[Huang et~al.(2017)Huang, Li, Pleiss, Liu, Hopcroft, and
  Weinberger]{huang2017snapshot}
G.~Huang, Y.~Li, G.~Pleiss, Z.~Liu, J.~E. Hopcroft, and K.~Q. Weinberger.
\newblock Snapshot ensembles: Train 1, get m for free.
\newblock \emph{arXiv preprint arXiv:1704.00109}, 2017.

\bibitem[Jiang et~al.(2012)Jiang, Osl, Kim, and
  Ohno-Machado]{jiang2012calibrating}
X.~Jiang, M.~Osl, J.~Kim, and L.~Ohno-Machado.
\newblock Calibrating predictive model estimates to support personalized
  medicine.
\newblock \emph{Journal of the American Medical Informatics Association},
  19\penalty0 (2):\penalty0 263--274, 2012.

\bibitem[Jung et~al.(2020)Jung, Lee, Pai, Roth, and Vohra]{jung2020moment}
C.~Jung, C.~Lee, M.~M. Pai, A.~Roth, and R.~Vohra.
\newblock Moment multicalibration for uncertainty estimation.
\newblock \emph{arXiv preprint arXiv:2008.08037}, 2020.

\bibitem[Karoui(2013)]{karoui2013asymptotic}
N.~E. Karoui.
\newblock Asymptotic behavior of unregularized and ridge-regularized
  high-dimensional robust regression estimators: rigorous results.
\newblock \emph{arXiv preprint arXiv:1311.2445}, 2013.

\bibitem[Kendall and Gal(2017)]{kendall2017uncertainties}
A.~Kendall and Y.~Gal.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock \emph{arXiv preprint arXiv:1703.04977}, 2017.

\bibitem[Kivaranovic et~al.(2020)Kivaranovic, Johnson, and
  Leeb]{kivaranovic2020adaptive}
D.~Kivaranovic, K.~D. Johnson, and H.~Leeb.
\newblock Adaptive, distribution-free prediction intervals for deep networks.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 4346--4356. PMLR, 2020.

\bibitem[Koenker and Bassett~Jr(1978)]{koenker1978regression}
R.~Koenker and G.~Bassett~Jr.
\newblock Regression quantiles.
\newblock \emph{Econometrica: journal of the Econometric Society}, pages
  33--50, 1978.

\bibitem[Koenker and Hallock(2001)]{koenker2001quantile}
R.~Koenker and K.~F. Hallock.
\newblock Quantile regression.
\newblock \emph{Journal of economic perspectives}, 15\penalty0 (4):\penalty0
  143--156, 2001.

\bibitem[Kumar et~al.(2019)Kumar, Liang, and Ma]{kumar2019verified}
A.~Kumar, P.~Liang, and T.~Ma.
\newblock Verified uncertainty calibration.
\newblock \emph{arXiv preprint arXiv:1909.10155}, 2019.

\bibitem[Lakshminarayanan et~al.(2016)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2016simple}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock \emph{arXiv preprint arXiv:1612.01474}, 2016.

\bibitem[Lei(2014)]{lei2014classification}
J.~Lei.
\newblock Classification with confidence.
\newblock \emph{Biometrika}, 101\penalty0 (4):\penalty0 755--769, 2014.

\bibitem[Lei et~al.(2018)Lei, Gâ€™Sell, Rinaldo, Tibshirani, and
  Wasserman]{lei2018distribution}
J.~Lei, M.~Gâ€™Sell, A.~Rinaldo, R.~J. Tibshirani, and L.~Wasserman.
\newblock Distribution-free predictive inference for regression.
\newblock \emph{Journal of the American Statistical Association}, 113\penalty0
  (523):\penalty0 1094--1111, 2018.

\bibitem[Liu et~al.(2019)Liu, Simchowitz, and Hardt]{liu2019implicit}
L.~T. Liu, M.~Simchowitz, and M.~Hardt.
\newblock The implicit fairness criterion of unconstrained learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  4051--4060. PMLR, 2019.

\bibitem[Mackay(1992)]{mackay1992bayesian}
D.~J.~C. Mackay.
\newblock \emph{Bayesian methods for adaptive models}.
\newblock PhD thesis, California Institute of Technology, 1992.

\bibitem[Maddox et~al.(2019)Maddox, Izmailov, Garipov, Vetrov, and
  Wilson]{maddox2019simple}
W.~J. Maddox, P.~Izmailov, T.~Garipov, D.~P. Vetrov, and A.~G. Wilson.
\newblock A simple baseline for bayesian uncertainty in deep learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 13153--13164, 2019.

\bibitem[Mai et~al.(2019)Mai, Liao, and Couillet]{mai2019large}
X.~Mai, Z.~Liao, and R.~Couillet.
\newblock A large scale analysis of logistic regression: Asymptotic performance
  and new insights.
\newblock In \emph{ICASSP 2019-2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 3357--3361. IEEE, 2019.

\bibitem[Malinin and Gales(2018)]{malinin2018predictive}
A.~Malinin and M.~Gales.
\newblock Predictive uncertainty estimation via prior networks.
\newblock \emph{arXiv preprint arXiv:1802.10501}, 2018.

\bibitem[Malinin et~al.(2019)Malinin, Mlodozeniec, and
  Gales]{malinin2019ensemble}
A.~Malinin, B.~Mlodozeniec, and M.~Gales.
\newblock Ensemble distribution distillation.
\newblock \emph{arXiv preprint arXiv:1905.00076}, 2019.

\bibitem[Meinshausen(2006)]{meinshausen2006quantile}
N.~Meinshausen.
\newblock Quantile regression forests.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0
  (35):\penalty0 983--999, 2006.

\bibitem[Michelmore et~al.(2018)Michelmore, Kwiatkowska, and
  Gal]{michelmore2018evaluating}
R.~Michelmore, M.~Kwiatkowska, and Y.~Gal.
\newblock Evaluating uncertainty quantification in end-to-end autonomous
  driving control.
\newblock \emph{arXiv preprint arXiv:1811.06817}, 2018.

\bibitem[Orabona(2020; Accessed: May, 2021)]{orabona2020last}
F.~Orabona.
\newblock Last iterate of sgd converges (even in unbounded domains), 2020;
  Accessed: May, 2021.
\newblock URL
  \url{https://parameterfree.com/2020/08/07/last-iterate-of-sgd-converges-even-in-unbounded-domains/}.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{ovadia2019can}
Y.~Ovadia, E.~Fertig, J.~Ren, Z.~Nado, D.~Sculley, S.~Nowozin, J.~V. Dillon,
  B.~Lakshminarayanan, and J.~Snoek.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock \emph{arXiv preprint arXiv:1906.02530}, 2019.

\bibitem[Papadopoulos(2008)]{papadopoulos2008inductive}
H.~Papadopoulos.
\newblock Inductive conformal prediction: Theory and application to neural
  networks.
\newblock In \emph{Tools in artificial intelligence}. Citeseer, 2008.

\bibitem[Platt et~al.(1999)]{platt1999probabilistic}
J.~Platt et~al.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock 1999.

\bibitem[Quenouille(1949)]{quenouille1949approximate}
M.~H. Quenouille.
\newblock Approximate tests of correlation in time-series.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 11\penalty0 (1):\penalty0 68--84, 1949.

\bibitem[Romano et~al.(2019)Romano, Patterson, and
  Cand{\`e}s]{romano2019conformalized}
Y.~Romano, E.~Patterson, and E.~J. Cand{\`e}s.
\newblock Conformalized quantile regression.
\newblock \emph{arXiv preprint arXiv:1905.03222}, 2019.

\bibitem[Shabat et~al.(2020)Shabat, Cohen, and Mansour]{shabat2020sample}
E.~Shabat, L.~Cohen, and Y.~Mansour.
\newblock Sample complexity of uniform convergence for multicalibration.
\newblock \emph{arXiv preprint arXiv:2005.01757}, 2020.

\bibitem[Shafer and Vovk(2008)]{shafer2008tutorial}
G.~Shafer and V.~Vovk.
\newblock A tutorial on conformal prediction.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (3), 2008.

\bibitem[Steinwart et~al.(2011)Steinwart, Christmann,
  et~al.]{steinwart2011estimating}
I.~Steinwart, A.~Christmann, et~al.
\newblock Estimating conditional quantiles with the help of the pinball loss.
\newblock \emph{Bernoulli}, 17\penalty0 (1):\penalty0 211--225, 2011.

\bibitem[Stojnic(2013)]{stojnic2013framework}
M.~Stojnic.
\newblock A framework to characterize performance of lasso algorithms.
\newblock \emph{arXiv preprint arXiv:1303.7291}, 2013.

\bibitem[Stone(1974)]{stone1974cross}
M.~Stone.
\newblock Cross-validatory choice and assessment of statistical predictions.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 36\penalty0 (2):\penalty0 111--133, 1974.

\bibitem[Sur and Cand{\`e}s(2019)]{sur2019modern}
P.~Sur and E.~J. Cand{\`e}s.
\newblock A modern maximum-likelihood theory for high-dimensional logistic
  regression.
\newblock \emph{Proceedings of the National Academy of Sciences}, 116\penalty0
  (29):\penalty0 14516--14525, 2019.

\bibitem[Takeuchi et~al.(2006)Takeuchi, Le, Sears, Smola,
  et~al.]{takeuchi2006nonparametric}
I.~Takeuchi, Q.~Le, T.~Sears, A.~Smola, et~al.
\newblock Nonparametric quantile estimation.
\newblock 2006.

\bibitem[Thrampoulidis et~al.(2015)Thrampoulidis, Oymak, and
  Hassibi]{thrampoulidis2015regularized}
C.~Thrampoulidis, S.~Oymak, and B.~Hassibi.
\newblock Regularized linear regression: A precise analysis of the estimation
  error.
\newblock In \emph{Conference on Learning Theory}, pages 1683--1709. PMLR,
  2015.

\bibitem[Thrampoulidis et~al.(2018)Thrampoulidis, Abbasi, and
  Hassibi]{thrampoulidis2018precise}
C.~Thrampoulidis, E.~Abbasi, and B.~Hassibi.
\newblock Precise error analysis of regularized $ m $-estimators in high
  dimensions.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0
  (8):\penalty0 5592--5628, 2018.

\bibitem[Tukey(1958)]{tukey1958bias}
J.~Tukey.
\newblock Bias and confidence in not quite large samples.
\newblock \emph{Ann. Math. Statist.}, 29:\penalty0 614, 1958.

\bibitem[Van~der Vaart(2000)]{van2000asymptotic}
A.~W. Van~der Vaart.
\newblock \emph{Asymptotic statistics}, volume~3.
\newblock Cambridge university press, 2000.

\bibitem[Vershynin(2018)]{vershynin2018high}
R.~Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge university press, 2018.

\bibitem[Vovk(2012)]{vovk2012conditional}
V.~Vovk.
\newblock Conditional validity of inductive conformal predictors.
\newblock In \emph{Asian conference on machine learning}, pages 475--490. PMLR,
  2012.

\bibitem[Vovk(2015)]{vovk2015cross}
V.~Vovk.
\newblock Cross-conformal predictors.
\newblock \emph{Annals of Mathematics and Artificial Intelligence}, 74\penalty0
  (1):\penalty0 9--28, 2015.

\bibitem[Vovk et~al.(2005)Vovk, Gammerman, and Shafer]{vovk2005algorithmic}
V.~Vovk, A.~Gammerman, and G.~Shafer.
\newblock \emph{Algorithmic learning in a random world}.
\newblock Springer Science \& Business Media, 2005.

\bibitem[Vovk et~al.(2018)Vovk, Nouretdinov, Manokhin, and
  Gammerman]{vovk2018cross}
V.~Vovk, I.~Nouretdinov, V.~Manokhin, and A.~Gammerman.
\newblock Cross-conformal predictive distributions.
\newblock In \emph{Conformal and Probabilistic Prediction and Applications},
  pages 37--51. PMLR, 2018.

\bibitem[Wilks(1941)]{wilks1941determination}
S.~S. Wilks.
\newblock Determination of sample sizes for setting tolerance limits.
\newblock \emph{The Annals of Mathematical Statistics}, 12\penalty0
  (1):\penalty0 91--96, 1941.

\bibitem[Wilks(1942)]{wilks1942statistical}
S.~S. Wilks.
\newblock Statistical prediction with special reference to the problem of
  tolerance limits.
\newblock \emph{The annals of mathematical statistics}, 13\penalty0
  (4):\penalty0 400--409, 1942.

\bibitem[Zadrozny and Elkan()]{zadrozny2001obtaining}
B.~Zadrozny and C.~Elkan.
\newblock Obtaining calibrated probability estimates from decision trees and
  naive bayesian classifiers.
\newblock Citeseer.

\bibitem[Zadrozny and Elkan(2002)]{zadrozny2002transforming}
B.~Zadrozny and C.~Elkan.
\newblock Transforming classifier scores into accurate multiclass probability
  estimates.
\newblock In \emph{Proceedings of the eighth ACM SIGKDD international
  conference on Knowledge discovery and data mining}, pages 694--699, 2002.

\end{thebibliography}
