% RLC main.bib Version 2024.1

@string{icra = {Proceedings of the IEEE International Conference on Robotics and
    Automation (ICRA)}}
@string{icra_abbrev = {Proc.\ IEEE Int'l Conf.\ on Robotics and
        Automation (ICRA)}}
@string{iclr ={Proceedings of the International Conference on Learning Representations (ICLR)}}
@string{iclr_abbrev ={Proc.\ Int'l Conf.\ on Learning Representations (ICLR)}}
@string{wafr = {Proceedings of the International Workshop on Algorithmic Foundations
    of Robotics (WAFR)}}
@string{wafr_abbrev = {Proc.\ Int'l Workshop on Algorithmic Foundations
    of Robotics (WAFR)}}
@string{iros = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}}
@string{iros_abbrev = {Proc. IEEE/RSJ Int'l Conf.\ on Intelligent Robots and Systems (IROS)}}
@string{iser = {Proceedings of the International Symposium on Experimental Robotics (ISER)}}
@string{iser_abbrev = {Proc.\ Int'l. Symp.\ on Experimental Robotics (ISER)}}
@string{cvprcs="Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)"}
@string{cvprcs_abbrev="Proc.\ IEEE Comp.\ Soc.\ Conf.\ on Computer Vision and Pattern Recognition (CVPR)"}
@string{cvpr="Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"}
@string{cvpr_abbrev="Proc.\ IEEE/CVF Conf.\ on Computer Vision and Pattern Recognition (CVPR)"}
@string{iccv="Proceedings of the International Conference on Computer Vision (ICCV)"}
@string{iccv_abbrev="Proc.\ European.\ Conf.\ on Computer Vision (ECCV)"}
@string{eccv="Proceedings of the European Conference on Computer Vision (ECCV)"}
@string{eccv_abbrev="Proc.\ Int'l.\ Conf.\ on Computer Vision (ICCV)"}
@string{ijcv="International Journal on Computer Vision"}
@string{ijcv_abbrev="Int'l J.\ on Computer Vision"}
@string{ijrr="International Journal of Robotics Research"}
@string{ijrr_abbrev="Int'l J.\ of Robotics Research"}
@string{isrr="Proceedings of the International Symposium of Robotics Research (ISRR)"}
@string{isrr_abbrev="Proc.\ Int'l Symp.\ of Robotics Research (ISRR)"}
@string{jfr="Journal of Field Robotics"}
@string{jfr_abbrev="J.\ of Field Robotics"}
@string{hri="Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI)"}
@string{hri_abbrev="Proc.\ ACM/IEEE Int'l. Conf.\ on Human-Robot Interaction (HRI)"}
@string{rss="Proceedings of Robotics: Science and Systems (RSS)"}
@string{rss_abbrev="Proc.\ Robotics: Science and Systems (RSS)"}
@string{aaai="Proceedings of the National Conference on Artificial Intelligence (AAAI)"}
@string{aaai_abbrev="Proc.\ Nat'l Conf.\ on Artificial Intelligence (AAAI)"}
@string{tro="Transactions on Robotics"}
@string{tro_abbrev="Trans.\ on Robotics"}
@string{uai="Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)"}
@string{uai_abbrev="Proc.\ Conf.\ on Uncertainty in Artificial Intelligence (UAI)"}
@string{icml="Proceedings of the International Conference on Machine Learning (ICML)"}
@string{icml_abbrev="Proc.\ Int'l Conf.\ on Machine Learning (ICML)"}
@string{jmlr="Journal of Machine Learning Research"}
@string{jmlr_abbrev="J.\ Machine Learning Research"}
@string{emnlp="Proceedings of the Conference on Empirical Methods in Natural OPTlanguage Processing (EMNLP)"}
@string{emnlp_abbrev="Proc.\ Conf.\ on Empirical Methods in Natural OPTlanguage Processing (EMNLP)"}
@string{hlt_emnlp="Proceedings of the Human OPTlanguage Technology Conference and the Conference on Empirical Methods in Natural OPTlanguage Processing (HLT/EMNLP)"}
@string{hlt_emnlp_abbrev="Proc.\ Human OPTlanguage Technology Conf.\ and the Conf.\ on Empirical Methods in Natural OPTlanguage Processing (HLT/EMNLP)"}
@string{tacl="Transactions of the Association for Computational Linguistics"}
@string{tacl_abbrev="Trans.\ Assoc.\ for Computational Linguistics"}
@string{acl="Proceedings of the Association for Computational Linguistics (ACL)"}
@string{acl_abbrev="Proc.\ Assoc.\ for Computational Linguistics (ACL)"}
@string{ijcai="Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)"}
@string{ijcai_abbrev="Proc.\ Int'l Joint Conf.\ on Artificial Intelligence (IJCAI)"}
@string{pami="IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{pami_abbrev="IEEE Trans.\ on Pattern Analysis and Machine Intelligence"}
@string{nips="Advances in Neural Information Processing Systems (NIPS)"}
@string{neurips="Advances in Neural Information Processing Systems (NeurIPS)"}
@string{naacl_hlt="Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics â€“ Human OPTlanguage Technologies (NAACL HLT)"}
@string{naacl_hlt_abbrev="Proc.\ Conf.\ of the North American Chapter of the Assoc.\ for Computational Linguistics -- Human OPTlanguage Technologies (NAACL HLT)"}
@string{naacl="Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)"}
@string{naacl_abbrev="Proc.\ Conf.\ of the North American Chapter of the Assoc.\ for Computational Linguistics (NAACL)"}
@string{icassp="Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"}
@string{icassp_abbrev="Proc.\ IEEE Int'l Conf.\ on Acoustics, Speech and Signal Processing (ICASSP)"}
@string{sensys="Proceedings of the ACM Conference on Embedded Networked Sensor Systems (SenSys)"}
@string{sensys_abbrev="Proc.\ ACM Conf.\ on Embedded Networked Sensor Systems (SenSys)"}
@string{mobisys="Proceedings of the International Conference on Mobile Systems, Applications, and Services (MobiSys)"}
@string{mobisys_abbrev="Proc. Int'l Conf.\ on Mobile Systems, Applications, and Services (MobiSys)"}
@string{mobicom="Proceedings of the International Conference on Mobile Computing and Networking (MobiCom)"}
@string{mobicom_abbrev="Proc.\ Int'l Conf.\ on Mobile Computing and Networking (MobiCom)"}
@string{dcoss="Proceedings of the International Conference on Distributed Computing in Sensor Networks (DCOSS)"}
@string{dcoss_abbrev="Proc.\ Int'l Conf.\ on Distributed Computing in Sensor Networks (DCOSS)"}
@string{ipsn="Proceedings of the International Symposium on Information Processing in Sensor Networks (IPSN)"}
@string{ipsn_abbrev="Proc.\ Int'l Symp.\ on Information Processing in Sensor Networks (IPSN)"}
@string{acc="Proceedings of the American Control Conference (ACC)"}
@string{acc_abbrev="Proc.\ American Control Conf.\ (ACC)"}
@string{siggraph_abbrev="Proc.\ Int'l Conf.\ on Computer Graphics and Interactive Techniques (SIGGRAPH)"}
@string{siggraph="Proceeding of the International Conference on Computer Graphics and Interactive Techniques (SIGGRAPH)"}
@string{robosoft="Proceedings of the IEEE International Conference on Soft Robotics (RoboSoft)"}
@string{robosoft_abbrev="Proc.\ IEEE Int'l Conf.\ on Soft Robotics (RoboSoft)"}
@string{ral="IEEE Robotics and Automation Letters"}
@string{gecco="Proceedings of the Annual Conference on Genetic and Evolutionary Computation (GECCO)"}
@string{gecco_abbrev="{Proc.\ Annual Conf.\ on Genetic and Evolutionary Computation (GECCO)}"}
@string{roman="Proceedings of the International Symposium on Robot and Human Interactive Communication (RO-MAN)"}
@string{roman_abbrev="Proc.\ Int'l Symp.\ on Robot and Human Interactive Communication (RO-MAN)"}
@string{corl="Proceedings of the Conference on Robot Learning (CoRL)"}
@string{corl_abbrev="Proc.\ Conf.\ on Robot Learning (CoRL)"}
@string{pnas="Proceedings of the National Academy of Sciences"}
@string{pnas_abbrev="Proc.\ the National Academy of Sciences"}
@string{aistats="Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)"}
@string{aistats_abbrev="Proc.\ Int'l Conf.\ on Artificial Intelligence and Statistics (AISTATS)"}
@string{tmlr="Transactions on Machine Learning Research"}
@string{tmlr_abbrev="Trans.\ on Machine Learning Research"}
@string{jair="Journal of Artificial Intelligence Research"}
@string{jair_abbrev="J.\ of Artificial Intelligence Research"}

@article{eysenbach2018diversity,
  title={Diversity is all you need: {L}earning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.06070},
  year={2018}
}


@inproceedings{pathak17,
	OPTaddress = {Sydney, Australia},
	author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
	booktitle = icml,
	OPTmonth = aug,
	pages = {2778--2787},
	title = {Curiosity-driven exploration by self-supervised prediction},
	year = {2017}}

@article{burda2018large,
  title={Large-scale study of curiosity-driven learning},
  author={Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A},
  journal={arXiv preprint arXiv:1808.04355},
  year={2018}
}


@article{burda18a,
	author = {Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
	journal = {arXiv preprint arXiv:1810.12894},
	title = {Exploration by random network distillation},
	year = {2018}}



@article{andrychowicz17,
	author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
	journal = {arXiv preprint arXiv:1707.01495},
	title = {Hindsight experience replay},
	year = {2017}}

@article{sharma2019dynamics,
  title={Dynamics-aware unsupervised discovery of skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  journal={arXiv preprint arXiv:1907.01657},
  year={2019}
}

@article{park2023controllability,
  title={Controllability-Aware Unsupervised Skill Discovery},
  author={Park, Seohong and Lee, Kimin and Lee, Youngwoon and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2302.05103},
  year={2023}
}

@article{amin2020locally,
  title={Locally persistent exploration in continuous control tasks with sparse rewards},
  author={Amin, Susan and Gomrokchi, Maziar and Aboutalebi, Hossein and Satija, Harsh and Precup, Doina},
  journal={arXiv preprint arXiv:2012.13658},
  year={2020}
}

@article{singh2020parrot,
  title={Parrot: Data-driven behavioral priors for reinforcement learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}


@article{sennrich15,
	author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
	journal = {arXiv preprint arXiv:1508.07909},
	title = {Neural machine translation of rare words with subword units},
	year = {2015}}


@article{gage94,
	author = {Gage, Philip},
	journal = {C Users Journal},
	number = {2},
	pages = {23--38},
	title = {A new algorithm for data compression},
	volume = {12},
	year = {1994}}


@inproceedings{chen21,
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	booktitle = neurips,
	month = dec,
	pages = {15084--15097},
	title = {Decision transformer: {R}einforcement learning via sequence modeling},
	year = {2021}}


@inproceedings{yarats21,
	author = {Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel},
	booktitle = icml,
	month = Jul,
	pages = {11920--11931},
	title = {Reinforcement learning with prototypical representations},
	year = {2021}}


@article{sutton99,
	author = {Sutton, Richard S. and Precup, D. and Singh, S.},
	journal = {Artificial Intelligence},
	month = {August},
	number = {1--2},
	pages = {181--211},
	title = {Between {MDP}s and semi-{MDP}s: {A} Framework for Temporal Abstraction in Reinforcement Learning},
	volume = {112},
	year = {1999}}


@inproceedings{kaelbling93,
	author = {Kaelbling, Leslie Pack},
	booktitle = ijcai,
	OPTmonth = Aug,
	pages = {1094--1099},
	title = {Learning to achieve goals},
	year = {1993}}


@inproceedings{kaelbling93a,
	author = {Kaelbling, Leslie Pack},
	booktitle = icml,
	pages = {167--173},
	title = {Hierarchical learning in stochastic domains: {P}reliminary results},
	year = {1993}}


@inproceedings{nachum18a,
	address = {Montr{\'e}al, Canada},
	author = {Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
	booktitle = neurips,
	OPTmonth = dec,
	title = {Data-efficient hierarchical reinforcement learning},
	year = {2018}}


@inproceedings{janner21,
	author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
	booktitle = neurips,
	OPTmonth = dec,
	pages = {1273--1286},
	title = {Offline reinforcement learning as one big sequence modeling problem},
	year = {2021}}


@inproceedings{shafiullah22,
	address = {New Orleans, LA},
	author = {Shafiullah, Nur Muhammad and Cui, Zichen and Altanzaya, Ariuntuya Arty and Pinto, Lerrel},
	booktitle = neurips,
	OPTmonth = dec,
	pages = {22955--22968},
	title = {Behavior transformers: {C}loning $k$ modes with one stone},
	year = {2022}}


@article{stadie15,
	author = {Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
	journal = {arXiv preprint arXiv:1507.00814},
	title = {Incentivizing exploration in reinforcement learning with deep predictive models},
	year = {2015}}

@inproceedings{pitis2020maximum,
  title={Maximum entropy gain exploration for long horizon multi-goal reinforcement learning},
  author={Pitis, Silviu and Chan, Harris and Zhao, Stephen and Stadie, Bradly and Ba, Jimmy},
  booktitle=icml,
  pages={7750--7761},
  year={2020},
  OPTorganization={PMLR}
}

@article{ajay2020opal,
  title={{OPAL}: {O}ffline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}


@inproceedings{pertsch21,
	OPTaddress = {London},
	author = {Pertsch, Karl and Lee, Youngwoon and Lim, Joseph},
	booktitle = corl,
	OPTmonth = nov,
	pages = {188--204},
	title = {Accelerating reinforcement learning with learned skill priors},
	year = {2021}}



@article{bagatella22,
	author = {Bagatella, Marco and Christen, Sammy and Hilliges, Otmar},
	journal = tmlr,
	title = {{SFP}: {S}tate-free priors for exploration in off-policy reinforcement learning},
	year = {2022}}


@article{christodoulou2019soft,
  title={Soft actor-critic for discrete action settings},
  author={Christodoulou, Petros},
  journal={arXiv preprint arXiv:1910.07207},
  year={2019}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}


@article{fu20,
	author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	journal = {arXiv preprint arXiv:2004.07219},
	title = {{D4RL}: {D}atasets for deep data-driven reinforcement learning},
	year = {2020}}


@article{vecerik17,
	author = {Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
	journal = {arXiv preprint arXiv:1707.08817},
	title = {Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
	year = {2017}}


 
@phdthesis{parr98,
	address = {Berkeley, CA},
	author = {Parr, Ronald Edward},
	school = {University of California, Berkeley},
	title = {Hierarchical control and learning for {M}arkov decision processes},
	year = {1998}}


@inproceedings{bradtke94,
	author = {Bradtke, Steven and Duff, Michael},
	booktitle = neurips,
	title = {Reinforcement learning methods for continuous-time {M}arkov decision problems},
	year = {1994}}


@inproceedings{vezhnevets17,
	address = {Sydney, Australia},
	author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
	booktitle = icml,
	month = aug,
	pages = {3540--3549},
	title = {Fe{U}dal networks for hierarchical reinforcement learning},
	year = {2017}}


@inproceedings{dayan92,
	author = {Dayan, Peter and Hinton, Geoffrey E},
	booktitle = neurips,
	title = {Feudal reinforcement learning},
	year = {1992}}


@article{dietterich00,
	author = {Thomas G. Dietterich},
	journal = jair,
	month = {November},
	pages = {227--303},
	title = {Hierarchical Reinforcement Learning with the {MAXQ} Value Function Decomposition},
	volume = {13},
	year = {2000}}


@inproceedings{boutilier97,
	OPTaddress = {Nagoya, Japan},
	author = {Boutilier, Craig and Brafman, Ronen I and Geib, Christopher},
	booktitle = ijcai,
	OPTmonth = aug,
	pages = {1156--1162},
	title = {Prioritized Goal Decomposition of {M}arkov Decision Processes: {T}oward a Synthesis of Classical and Decision Theoretic Planning},
	year = {1997}}


@inproceedings{parr97,
	author = {Ronald Parr and Stuart Russell},
	booktitle = neurips,
	pages = {1043--1049},
	title = {Reinforcement Learning with Hierarchies of Machines},
	year = {1997}}

@incollection{sutton95,
    OPTaddress = {Tahoe City, CA},
    author = {Sutton, Richard S},
    booktitle = icml,
    OPTmonth = Jul,
    pages = {531--539},
    title = {{TD} models: {M}odeling the world at a mixture of time scales},
    year = {1995}}



@article{levy17,
    author = {Levy, Andrew and Konidaris, George and Platt, Robert and Saenko, Kate},
    journal = {arXiv preprint arXiv:1712.00948},
    title = {Learning multi-level hierarchies with hindsight},
    year = {2017}}



@inproceedings{konidaris09a,
	OPTaddress = {Vancouver, B.C., Canada},
	author = {George Konidaris and Andrew Barto},
	booktitle = neurips,
	month = {December},
	title = {Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining},
	year = {2009}}


@inproceedings{bacon17,
	OPTaddress = {San Francisco, CA},
	author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
	booktitle = aaai,
	OPTmonth = feb,
	pages = {1726--1734},
	title = {The option-critic architecture},
	year = {2017}}


@inproceedings{harb18,
	address = {New Orleans, LA},
	author = {Harb, Jean and Bacon, Pierre-Luc and Klissarov, Martin and Precup, Doina},
	booktitle = aaai,
	month = feb,
	pages = {3165--3172},
	title = {When waiting is not an option: {L}earning options with a deliberation cost},
	year = {2018}}


@article{simon57,
	author = {Simon, Herbert A},
	journal = {Models of man, social and rational: {M}athematical essays on rational human behavior in a social setting},
	pages = {241--260},
	title = {A behavioral model of rational choice},
	year = {1957}}

 
@phdthesis{precup00,
	address = {Amherst, MA},
	author = {Precup, Doina},
	OPTmonth = {May},
	school = {University of Massachusetts Amherst},
	title = {Temporal abstraction in reinforcement learning},
	year = {2000}}

@inproceedings{dadashi2022continuous,
  title={Continuous Control with Action Quantization from Demonstrations},
  author={Dadashi, Robert and Hussenot, L{\'e}onard and Vincent, Damien and Girgin, Sertan and Raichuk, Anton and Geist, Matthieu and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={4537--4557},
  year={2022},
  OPTorganization={PMLR}
}


@article{wang22,
	author = {Wang, Zhendong and Hunt, Jonathan J and Zhou, Mingyuan},
	journal = {arXiv preprint arXiv:2208.06193},
	title = {Diffusion policies as an expressive policy class for offline reinforcement learning},
	year = {2022}}



@article{emmons21,
	author = {Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
	journal = {arXiv preprint arXiv:2112.10751},
	title = {{RvS}: {W}hat is Essential for Offline {RL} via Supervised Learning?},
	year = {2021}}

@article{zhou2022revisiting,
  title={Revisiting Discrete Soft Actor-Critic},
  author={Zhou, Haibin and Lin, Zichuan and Li, Junyou and Ye, Deheng and Fu, Qiang and Yang, Wei},
  journal={arXiv preprint arXiv:2209.10081},
  year={2022}
}

@article{mielke2021between,
  title={Between words and characters: A brief history of open-vocabulary modeling and tokenization in NLP},
  author={Mielke, Sabrina J and Alyafeai, Zaid and Salesky, Elizabeth and Raffel, Colin and Dey, Manan and Gall{\'e}, Matthias and Raja, Arun and Si, Chenglei and Lee, Wilson Y and Sagot, Beno{\^\i}t and others},
  journal={arXiv preprint arXiv:2112.10508},
  year={2021}
}

@inproceedings{he2020dynamic,
  title={Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation},
  author={He, Xuanli and Haffari, Gholamreza and Norouzi, Mohammad},
  booktitle=acl,
  pages={3042--3051},
  year={2020}
}

@inproceedings{provilkov2020bpe,
    title = "{BPE}-Dropout: Simple and Effective Subword Regularization",
    author = "Provilkov, Ivan  and
      Emelianenko, Dmitrii  and
      Voita, Elena",
      booktitle = acl,
      OPTmonth = jul,
    year = "2020",
    OPTaddress = "Online",
    OPTpublisher = "Association for Computational Linguistics",
    OPTurl = "https://aclanthology.org/2020.acl-main.170",
    OPTdoi = "10.18653/v1/2020.acl-main.170",
    pages = "1882--1892",
    abstract = "Subword segmentation is widely used to address the open vocabulary problem in machine translation. The dominant approach to subword segmentation is Byte Pair Encoding (BPE), which keeps the most frequent words intact while splitting the rare ones into multiple tokens. While multiple segmentations are possible even with the same vocabulary, BPE splits words into unique sequences; this may prevent a model from better learning the compositionality of words and being robust to segmentation errors. So far, the only way to overcome this BPE imperfection, its deterministic nature, was to create another subword segmentation algorithm (Kudo, 2018). In contrast, we show that BPE itself incorporates the ability to produce multiple segmentations of the same word. We introduce BPE-dropout - simple and effective subword regularization method based on and compatible with conventional BPE. It stochastically corrupts the segmentation procedure of BPE, which leads to producing multiple segmentations within the same fixed BPE framework. Using BPE-dropout during training and the standard BPE during inference improves translation quality up to 2.3 BLEU compared to BPE and up to 0.9 BLEU compared to the previous subword regularization.",
}

@inproceedings{kudo2018subword,
    title = "Subword Regularization: {I}mproving Neural Network Translation Models with Multiple Subword Candidates",
    author = "Kudo, Taku",
    booktitle = acl,
    OPTmonth = jul,
    year = "2018",
    OPTaddress = "Melbourne, Australia",
    OPTpublisher = "Association for Computational Linguistics",
    OPTurl = "https://aclanthology.org/P18-1007",
    doi = "10.18653/v1/P18-1007",
    pages = "66--75",
    OPTabstract = "Subword units are an effective way to alleviate the open vocabulary problems in neural machine translation (NMT). While sentences are usually converted into unique subword sequences, subword segmentation is potentially ambiguous and multiple segmentations are possible even with the same vocabulary. The question addressed in this paper is whether it is possible to harness the segmentation ambiguity as a noise to improve the robustness of NMT. We present a simple regularization method, subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training. In addition, for better subword sampling, we propose a new subword segmentation algorithm based on a unigram language model. We experiment with multiple corpora and report consistent improvements especially on low resource and out-of-domain settings.",
}

@inproceedings{schuster2012japanese,
  title={Japanese and korean voice search},
  author={Schuster, Mike and Nakajima, Kaisuke},
  booktitle=icassp,
  pages={5149--5152},
  year={2012},
  OPTorganization={IEEE}
}


@inproceedings{kulkarni16,
	address = {Barcelona, Spain},
	author = {Tejas D. Kulkarni and Karthik R. Narasimhan and Ardavan Saeedi and Joshua B. Tenenbaum},
	booktitle = neurips,
	month = {December},
	title = {Hierarchical Deep Reinforcement Learning: {I}ngegrating Temporal Abstaction and Intrinsic Motivation},
	year = {2016}}


@article{barto03,
	author = {Barto, Andrew G and Mahadevan, Sridhar},
	journal = {Discrete Event Dynamic Systems},
	pages = {41--77},
	title = {Recent Advances in Hierarchical Reinforcement Learning},
	volume = {13},
	year = {2003}}

@inproceedings{lynch2020learning,
  title={Learning latent plans from play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle=corl,
  pages={1113--1132},
  year={2020},
  OPTorganization={PMLR}
}

@inproceedings{park2022lipschitz,
  title={Lipschitz-constrained Unsupervised Skill Discovery},
  author={Park, Seohong and Choi, Jongwook and Kim, Jaekyeom and Lee, Honglak and Kim, Gunhee},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{cobbe2019quantifying,
  title={Quantifying generalization in reinforcement learning},
  author={Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
  booktitle={International Conference on Machine Learning},
  pages={1282--1289},
  year={2019},
  OPTorganization={PMLR}
}

@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  OPTorganization={PMLR}
}

@inproceedings{liu2021behavior,
  title={Behavior from the void: {U}nsupervised active pre-training},
  author={Liu, Hao and Abbeel, Pieter},
  booktitle=neurips,
  OPTvolume={34},
  pages={18459--18473},
  year={2021}
}

@article{jiang2022efficient,
  title={Efficient planning in a compact latent action space},
  author={Jiang, Zhengyao and Zhang, Tianjun and Janner, Michael and Li, Yueying and Rockt{\"a}schel, Tim and Grefenstette, Edward and Tian, Yuandong},
  journal={arXiv preprint arXiv:2208.10291},
  year={2022}
}

@inproceedings{park2021time,
  title={Time discretization-invariant safe action repetition for policy gradient methods},
  author={Park, Seohong and Kim, Jaekyeom and Kim, Gunhee},
  booktitle=neurips,
  OPTvolume={34},
  pages={267--279},
  year={2021}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {{Stable-Baselines3}: {R}eliable Reinforcement Learning Implementations},
  journal = jmlr,
  year    = {2021},
  volume  = {22},
  number  = {268},
  OPTpages   = {1-8},
  OPTurl     = {http://jmlr.org/papers/v22/20-1364.html}
}


@inproceedings{bellemare16,
    OPTaddress = {Barcelona, Spain},
    author = {Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
    booktitle = neurips,
    OPTmonth = dec,
    title = {Unifying count-based exploration and intrinsic motivation},
    year = {2016}}

@inproceedings{schmidhuber1991possibility,
  title={A possibility for implementing curiosity and boredom in model-building neural controllers},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the International Conference on Simulation of Adaptive Behavior: From Animals to Animats (SAB)},
  pages={222--227},
  year={1991}
}


@article{barto13,
	author = {Barto, Andrew G},
	journal = {Intrinsically motivated learning in natural and artificial systems},
	pages = {17--47},
	title = {Intrinsic motivation and reinforcement learning},
	year = {2013}}

 
@inproceedings{chentanez04,
    OPTaddress = {Vancouver, B.C., Canada},
    author = {Chentanez, Nuttapong and Barto, Andrew and Singh, Satinder},
    booktitle = neurips,
	OPTmonth = dec,
    title = {Intrinsically motivated reinforcement learning},
	year = {2004}}



@inproceedings{poupart06,
    address = {Pittsburgh, PA},
    author = {Poupart, Pascal and Vlassis, Nikos and Hoey, Jesse and Regan, Kevin},
    booktitle = icml,
    OPTmonth = jun,
    pages = {697--704},
    title = {An analytic solution to discrete {B}ayesian reinforcement learning},
    year = {2006}}


@inproceedings{lopes12,
    OPTaddress = {Lake Tahoe, CA},
	author = {Lopes, Manuel and Lang, Tobias and Toussaint, Marc and Oudeyer, Pierre-Yves},
    booktitle = neurips,
    OPTmonth = dec,
    title = {Exploration in model-based reinforcement learning by empirically estimating learning progress},
    year = {2012}}


@inproceedings{houthooft16,
    OPTaddress = {Barcelona, Spain},
	author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
	booktitle = neurips,
    OPTmonth = dec,
	title = {{VIME}: {V}ariational information maximizing exploration},
	year = {2016}}

 
@article{achiam17a,
	author = {Achiam, Joshua and Sastry, Shankar},
	journal = {arXiv preprint arXiv:1703.01732},
	title = {Surprise-based intrinsic motivation for deep reinforcement learning},
	year = {2017}}


@inproceedings{haber18,
	address = {Montr{\'e}al, Canada},
	author = {Haber, Nick and Mrowca, Damian and Wang, Stephanie and Fei-Fei, Li F and Yamins, Daniel L},
	booktitle = neurips,
	month = dec,
	title = {Learning to play with intrinsically-motivated, self-aware agents},
	year = {2018}}


@inproceedings{hazan19,
	OPTaddress = {Long Beach, CA},
	author = {Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
	booktitle = icml,
	OPTmonth = jun,
	pages = {2681--2691},
	title = {Provably efficient maximum entropy exploration},
	year = {2019}}




@article{lee19,
	author = {Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
	journal = {arXiv preprint arXiv:1906.05274},
	title = {Efficient exploration via state marginal matching},
	year = {2019}}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle=aaai,
  year={2018}
}


@inproceedings{mohamed15,
	OPTaddress = {Montr{\'e}al, Canada},
	author = {Mohamed, Shakir and Jimenez Rezende, Danilo},
	booktitle = neurips,
	OPTmonth = dec,
	title = {Variational information maximisation for intrinsically motivated reinforcement learning},
	year = {2015}}

@inproceedings{paszke2019pytorch,
  title={{PyTorch}: {A}n imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle=neurips,
  OPTvolume={32},
  year={2019}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@misc{falcon2019pytorch,
  title={{PyTorch} {L}ightning},
  author={Falcon, William A},
  howpublished={\url{https://lightning.ai}},
  OPTvolume={3},
  OPTyear={2019}
}


@inproceedings{daniel12,
	OPTaddress = {La Palma, Canary Islands},
	author = {Daniel, Christian and Neumann, Gerhard and Peters, Jan},
	booktitle = aistats,
	OPTmonth = apr,
	pages = {273--281},
	title = {Hierarchical relative entropy policy search},
	year = {2012}}


@article{gregor16,
	author = {Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan},
	journal = {arXiv preprint arXiv:1611.07507},
	title = {Variational intrinsic control},
	year = {2016}}


@article{warde-farley18,
	author = {Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
	journal = {arXiv preprint arXiv:1811.11359},
	title = {Unsupervised control through non-parametric discriminative rewards},
	year = {2018}}

@article{silver2017mastering,
  title={Mastering the game of {Go} without human knowledge},
  author={David Silver and Julian Schrittwieser and Karen Simonyan and Ioannis Antonoglou and Aja Huang and Arthur Guez and Thomas Hubert and Lucas Baker and Matthew Lai and Adrian Bolton and Yutian Chen and Timothy Lillicrap and Fan Hui and Laurent Sifre and George van den Driessche and Thore Graepel and Demis Hassabis},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  OPTpublisher={Nature Publishing Group}
}


@inproceedings{gu17,
	OPTaddress = {Singapore},
	author = {Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
	booktitle = icra,
	OPTmonth = may,
	pages = {3389--3396},
	title = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
	year = {2017}}


@article{mnih13,
	author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
	journal = {arXiv:1312.5602},
	title = {Playing Atari with Deep Reinforcement Learning},
	year = {2013}}


@article{haarnoja18a,
	author = {Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
	journal = {arXiv preprint arXiv:1812.11103},
	title = {Learning to walk via deep reinforcement learning},
	year = {2018}}

 @inproceedings{sharma2017learning,
  title={Learning to repeat: Fine grained action repetition for deep reinforcement learning},
  author={Sharma, Sahil and Srinivas, Aravind and Ravindran, Balaraman},
  booktitle={International Conference on Learning Representations},
  year={2017}
}


@inproceedings{kumar2020conservative,
  title={Conservative {Q}-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle=neurips,
  pages={1179--1191},
  year={2020}
}

@article{janner22,
	author = {Janner, Michael and Du, Yilun and Tenenbaum, Joshua B and Levine, Sergey},
	journal = {arXiv preprint arXiv:2205.09991},
	title = {Planning with Diffusion for Flexible Behavior Synthesis},
	year = {2022}}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{lange2019semantic,
  title={Semantic RL with Action Grammars: Data-Efficient Learning of Hierarchical Task Abstractions},
  author={Lange, Robert Tjarko and Faisal, Aldo},
  journal={arXiv preprint arXiv:1907.12477},
  year={2019}
}

@inproceedings{pertsch2022guided,
  title={Guided Reinforcement Learning with Learned Skills},
  author={Pertsch, Karl and Lee, Youngwoon and Wu, Yue and Lim, Joseph J},
  booktitle={Conference on Robot Learning},
  pages={729--739},
  year={2022},
  OPTorganization={PMLR}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}


@article{konidaris12,
	author = {Konidaris, G. and Kuindersma, Scott R. and Grupen, Rod A. and Barto, Andrew G.},
	journal = ijrr,
	month = {March},
	number = {3},
	pages = {360--375},
	title = {Robot Learning from Demonstration by Constructing Skill Trees},
	volume = {31},
	year = {2012}}


@inproceedings{skalse2022defining,
  title={Defining and characterizing reward gaming},
  author={Skalse, Joar and Howe, Nikolaus and Krasheninnikov, Dmitrii and Krueger, David},
  booktitle=neurips,
  pages={9460--9471},
  year={2022}
}

@misc{spirl-ssp-github,
    title = {Accelerating Reinforcement Learning with Learned Skill Priors---{GitHub}},
    url = {https://github.com/clvrai/spirl},
    author = {Karl Pertsch and Youngwoon Lee and Joseph Lim},
    year = {2024},
    note = {Accessed on March 1, 2024}
}

@misc{sfp-github,
    title = {{SFP}: {S}tate-free priors for exploration in
off-policy reinforcement learning---{GitHub}},
    url = {https://github.com/eth-ait/sfp},
    author = {Marco Bagatella and Sammy Christen and Otmar Hilliges.},
    year = {2024},
    note = {Accessed on March 1, 2024}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1278--1286},
  year={2014},
  organization={PMLR}
}

@article{zheng2024prise,
  title={PRISE: Learning Temporal Action Abstractions as a Sequence Compression Problem},
  author={Zheng, Ruijie and Cheng, Ching-An and Daum{\'e} III, Hal and Huang, Furong and Kolobov, Andrey},
  journal={arXiv preprint arXiv:2402.10450},
  year={2024}
}