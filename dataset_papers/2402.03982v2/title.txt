On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions