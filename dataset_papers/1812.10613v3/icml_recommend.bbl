\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel \& Ng(2004)Abbeel and Ng]{Abbeel2004ApprenticeshipLV}
Abbeel, P. and Ng, A.~Y.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{ICML}, 2004.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{chen2016xgboost}
Chen, T. and Guestrin, C.
\newblock Xgboost: A scalable tree boosting system.
\newblock In \emph{Proceedings of the 22Nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pp.\  785--794. ACM, 2016.

\bibitem[Cheng et~al.(2016)Cheng, Koc, Harmsen, Shaked, Chandra, Aradhye,
  Anderson, Corrado, Chai, Ispir, Anil, Haque, Hong, Jain, Liu, and
  Shah]{ChengKocHarmsen16}
Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H.,
  Anderson, G., Corrado, G., Chai, W., Ispir, M., Anil, R., Haque, Z., Hong,
  L., Jain, V., Liu, X., and Shah, H.
\newblock Wide \& deep learning for recommender systems.
\newblock In \emph{Proceedings of the 1st Workshop on Deep Learning for
  Recommender Systems}. ACM, 2016.

\bibitem[Clavera et~al.(2018)Clavera, Nagabandi, Fearing, Abbeel, Levine, and
  Finn]{IgnasiPieter18}
Clavera, I., Nagabandi, A., Fearing, R.~S., Abbeel, P., Levine, S., and Finn,
  C.
\newblock Learning to adapt: Meta-learning for model-based control.
\newblock \emph{arXiv preprint arXiv:1803.11347}, 2018.

\bibitem[Deisenroth et~al.(2015)Deisenroth, Fox, and
  Rasmussen]{DeisenrothFox15}
Deisenroth, M.~P., Fox, D., and Rasmussen, C.~E.
\newblock Gaussian processes for data-efficient learning in robotics and
  control.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2015.
\newblock ISSN 0162-8828.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{FinAbbLev17}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock \emph{arXiv preprint arXiv:1703.03400}, 2017.

\bibitem[Guo et~al.(2017)Guo, Tang, Ye, Li, and He]{guo2017deepfm}
Guo, H., Tang, R., Ye, Y., Li, Z., and He, X.
\newblock Deepfm: a factorization-machine based neural network for ctr
  prediction.
\newblock \emph{arXiv preprint arXiv:1703.04247}, 2017.

\bibitem[He et~al.(2016)He, Ostendorf, He, Chen, Gao, Li, and
  Deng]{He2016DeepRL}
He, J., Ostendorf, M., He, X., Chen, J., Gao, J., Li, L., and Deng, L.
\newblock Deep reinforcement learning with a combinatorial action space for
  predicting popular reddit threads.
\newblock In \emph{EMNLP}, 2016.

\bibitem[Hidasi et~al.(2015)Hidasi, Karatzoglou, Baltrunas, and
  Tikk]{hidasi2015session}
Hidasi, B., Karatzoglou, A., Baltrunas, L., and Tikk, D.
\newblock Session-based recommendations with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1511.06939}, 2015.

\bibitem[Hidasi et~al.(2016)Hidasi, Karatzoglou, Baltrunas, and
  Tikk]{HidKarBalTik16}
Hidasi, B., Karatzoglou, A., Baltrunas, L., and Tikk, D.
\newblock Session-based recommendations with recurrent neural networks.
\newblock In \emph{ICLR}, 2016.

\bibitem[Ho \& Ermon(2016)Ho and Ermon]{Ho2016GenerativeAI}
Ho, J. and Ermon, S.
\newblock Generative adversarial imitation learning.
\newblock In \emph{NIPS}, 2016.

\bibitem[Ho et~al.(2016)Ho, Gupta, and Ermon]{Ho2016ModelFreeIL}
Ho, J., Gupta, J.~K., and Ermon, S.
\newblock Model-free imitation learning with policy optimization.
\newblock In \emph{ICML}, 2016.

\bibitem[Jannach \& Ludewig(2017)Jannach and Ludewig]{jannach2017recurrent}
Jannach, D. and Ludewig, M.
\newblock When recurrent neural networks meet the neighborhood for
  session-based recommendation.
\newblock In \emph{Proceedings of the Eleventh ACM Conference on Recommender
  Systems}, pp.\  306--310. ACM, 2017.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{LiChuLanSch10}
Li, L., Chu, W., Langford, J., and Schapire, R.~E.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In \emph{Proceedings of the 19th international conference on World
  wide web}, pp.\  661--670. ACM, 2010.

\bibitem[Manski(1975)]{Manski75}
Manski, C.~F.
\newblock Maximum score estimation of the stochastic utility model of choice.
\newblock \emph{Journal of Econometrics}, pp.\  205 -- 228, 1975.
\newblock ISSN 0304-4076.

\bibitem[Mataric(1994)]{Mataric1994RewardFF}
Mataric, M.~J.
\newblock Reward functions for accelerated learning.
\newblock In \emph{ICML}, 1994.

\bibitem[Matignon et~al.(2006)Matignon, Laurent, and
  Fort-Piat]{Matignon2006RewardFA}
Matignon, L., Laurent, G.~J., and Fort-Piat, N.~L.
\newblock Reward function and initial values: Better choices for accelerated
  goal-directed reinforcement learning.
\newblock In \emph{ICANN}, 2006.

\bibitem[McFadden(1973)]{McFa73}
McFadden, D.
\newblock Conditional logit analysis of qualitative choice behaviour.
\newblock In Zarembka, P. (ed.), \emph{Frontiers in Econometrics}, pp.\
  105--142. Academic Press New York, 1973.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{MniKavSilGraetal13}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Nagabandi et~al.(2017)Nagabandi, Kahn, Fearing, and
  Levine]{NagabandiKahn17}
Nagabandi, A., Kahn, G., Fearing, R.~S., and Levine, S.
\newblock Neural network dynamics for model-based deep reinforcement learning
  with model-free fine-tuning.
\newblock \emph{arXiv preprint arXiv:1708.02596}, 2017.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{Ng1999PolicyIU}
Ng, A.~Y., Harada, D., and Russell, S.~J.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{ICML}, 1999.

\bibitem[Shi et~al.(2019)Shi, Yu, Da, Chen, and Zeng]{shi2019virtual}
Shi, J.-C., Yu, Y., Da, Q., Chen, S.-Y., and Zeng, A.-X.
\newblock Virtual-taobao: Virtualizing real-world online retail environment for
  reinforcement learning.
\newblock In \emph{Thirty-Third AAAI Conference on Artificial Intelligence},
  2019.

\bibitem[Torabi et~al.(2018)Torabi, Warnell, and Stone]{Torabi2018BehavioralCF}
Torabi, F., Warnell, G., and Stone, P.
\newblock Behavioral cloning from observation.
\newblock In \emph{IJCAI}, 2018.

\bibitem[Watkins(1989)]{Watkins89}
Watkins, C. J. C.~H.
\newblock \emph{Learning from Delayed Rewards}.
\newblock PhD thesis, King's College, Oxford, May 1989.
\newblock (To be reprinted by MIT Press.).

\bibitem[Yang et~al.(2011)Yang, Long, Smola, Zha, and Zheng]{YanLonSmoEtal11b}
Yang, S.-H., Long, B., Smola, A.~J., Zha, H., and Zheng, Z.
\newblock Collaborative competitive filtering: learning recommender using
  context of user choice.
\newblock In \emph{Proceedings of the 34th international ACM SIGIR conference
  on Research and development in Information Retrieval}, pp.\  295--304. ACM,
  2011.

\bibitem[Zhao et~al.(2018{\natexlab{a}})Zhao, Xia, Zhang, Ding, Yin, and
  Tang]{zhao2018deep}
Zhao, X., Xia, L., Zhang, L., Ding, Z., Yin, D., and Tang, J.
\newblock Deep reinforcement learning for page-wise recommendations.
\newblock 2018{\natexlab{a}}.

\bibitem[Zhao et~al.(2018{\natexlab{b}})Zhao, Zhang, Ding, Yin, Zhao, and
  Tang]{XiangyuLiangZhuoye18}
Zhao, X., Zhang, L., Ding, Z., Yin, D., Zhao, Y., and Tang, J.
\newblock Deep reinforcement learning for list-wise recommendations.
\newblock \emph{CoRR}, 2018{\natexlab{b}}.

\bibitem[Zheng et~al.(2018)Zheng, Zhang, Zheng, Xiang, Yuan, Xie, and
  Li]{zheng2018drn}
Zheng, G., Zhang, F., Zheng, Z., Xiang, Y., Yuan, N.~J., Xie, X., and Li, Z.
\newblock Drn: A deep reinforcement learning framework for news recommendation.
\newblock 2018.

\end{thebibliography}
