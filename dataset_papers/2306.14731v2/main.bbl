\begin{thebibliography}{10}

\bibitem{Bachoc2022}
F.~Bachoc, N.~Durrande, D.~Rullière, and C.~Chevalier.
\newblock {Properties and Comparison of Some Kriging Sub-model Aggregation
  Methods}.
\newblock {\em Mathematical Geosciences}, 2022.

\bibitem{cao2014generalized}
Y.~Cao and D.~J. Fleet.
\newblock Generalized product of experts for automatic and principled fusion of
  gaussian process predictions.
\newblock {\em arXiv preprint arXiv:1410.7827}, 2014.

\bibitem{eval_framework}
K.~Chalupka, C.~K. Williams, and I.~Murray.
\newblock A framework for evaluating approximation methods for gaussian process
  regression.
\newblock {\em Journal of Machine Learning Research}, 14:333--350, 2013.

\bibitem{Cohen20b}
S.~Cohen, R.~Mbuvha, T.~Marwala, and M.~Deisenroth.
\newblock Healing products of {G}aussian process experts.
\newblock In H.~D. III and A.~Singh, editors, {\em Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of {\em Proceedings
  of Machine Learning Research}, pages 2068--2077. PMLR, 2020-13.

\bibitem{Datta2016}
A.~Datta, S.~Banerjee, A.~O. Finley, and A.~E. Gelfand.
\newblock {Hierarchical Nearest-Neighbor Gaussian Process Models for Large
  Geostatistical Datasets}.
\newblock {\em Journal of the American Statistical Association},
  111(514):800--812, 2016.

\bibitem{Datta2016a}
A.~Datta, S.~Banerjee, A.~O. Finley, and A.~E. Gelfand.
\newblock {On nearest-neighbor Gaussian process models for massive spatial
  data}.
\newblock {\em Wiley Interdisciplinary Reviews: Computational Statistics},
  8(5):162--171, 2016.

\bibitem{deisenroth2015distributed}
M.~Deisenroth and J.~W. Ng.
\newblock Distributed gaussian processes.
\newblock In {\em International Conference on Machine Learning}, pages
  1481--1490. PMLR, 2015.

\bibitem{Finley2019}
A.~O. Finley, A.~Datta, B.~D. Cook, D.~C. Morton, H.~E. Andersen, and
  S.~Banerjee.
\newblock Efficient algorithms for bayesian nearest neighbor gaussian
  processes.
\newblock {\em Journal of Computational and Graphical Statistics},
  28(2):401--414, 2019.
\newblock PMID: 31543693.

\bibitem{Friedman1977}
J.~Friedman, J.~Bentley, and R.~Finkel.
\newblock {An Algorithm for Finding Best Matches in Logarithmic Expected Time}.
\newblock {\em ACM Transactions on Mathematical Software (TOMS)}, 3:209--226,
  1977.

\bibitem{Gard1}
J.~Gardner, G.~Pleiss, K.~Q. Weinberger, D.~Bindel, and A.~G. Wilson.
\newblock Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu
  acceleration.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{Gardner2018a}
J.~R. Gardner, G.~Pleiss, R.~Wu, K.~Q. Weinberger, and A.~G. Wilson.
\newblock {Product kernel interpolation for scalable gaussian processes}.
\newblock {\em International Conference on Artificial Intelligence and
  Statistics, AISTATS 2018}, 84:1407--1416, 2018.

\bibitem{Gyorfi2010}
L.~Györfi, M.~Kohler, A.~Krzyżak, and H.~Walk.
\newblock {\em {A Distribution-Free Theory of Nonparametric Regression}}.
\newblock Springer Series in Statistics, 2010.

\bibitem{Graphon_SoD}
K.~Hayashi, M.~Imaizumi, and Y.~Yoshida.
\newblock On random subsampling of gaussian process regression: A graphon-based
  analysis.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2055--2065. PMLR, 2020.

\bibitem{Hensman}
J.~Hensman, N.~Fusi, and N.~D. Lawrence.
\newblock Gaussian processes for big data.
\newblock {\em arXiv preprint arXiv:1309.6835}, 2013.

\bibitem{hinton2002training}
G.~E. Hinton.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock {\em Neural computation}, 14(8):1771--1800, 2002.

\bibitem{Jankowiak2020}
M.~Jankowiak, G.~Pleiss, and J.~Gardner.
\newblock Parametric {G}aussian process regressors.
\newblock In H.~D. III and A.~Singh, editors, {\em Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of {\em Proceedings
  of Machine Learning Research}, pages 4702--4712. PMLR, 13--18 Jul 2020.

\bibitem{lalchand_approximate_2020}
V.~Lalchand and C.~E. Rasmussen.
\newblock Approximate {Inference} for {Fully} {Bayesian} {Gaussian} {Process}
  {Regression}, Apr. 2020.
\newblock arXiv:1912.13440 [cs, stat].

\bibitem{amalg_SOD}
H.~Liu, J.~Cai, Y.~Wang, and Y.~S. Ong.
\newblock Generalized robust bayesian committee machine for large-scale
  gaussian process regression.
\newblock In {\em International Conference on Machine Learning}, pages
  3131--3140. PMLR, 2018.

\bibitem{GP_approx_review}
H.~Liu, Y.-S. Ong, X.~Shen, and J.~Cai.
\newblock When gaussian process meets big data: A review of scalable gps.
\newblock {\em IEEE transactions on neural networks and learning systems},
  31(11):4405--4423, 2020.

\bibitem{Oakley2004}
J.~E. Oakley and A.~O'Hagan.
\newblock Probabilistic sensitivity analysis of complex models: A bayesian
  approach.
\newblock {\em Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, 66(3):751--769, 2004.

\bibitem{Omohundro1989}
S.~Omohundro.
\newblock {Five Balltree Construction Algorithms}.
\newblock Technical report, International Computer Science Institute, 1989.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{Scholkopf2001}
B.~Schölkopf.
\newblock {The Kernel Trick for Distances}.
\newblock In T.~Leen, T.~Dietterich, and V.~Tresp, editors, {\em Advances in
  Neural Information Processing Systems}, volume~13. MIT Press, 2000.

\bibitem{Song2019}
H.~Song, T.~Diethe, M.~Kull, and P.~Flach.
\newblock {Distribution calibration for regression}.
\newblock {\em 36th International Conference on Machine Learning, ICML 2019},
  2019-June:10347--10356, 2019.

\bibitem{Stein2002}
M.~L. Stein.
\newblock The screening effect in kriging.
\newblock {\em Annals of Statistics}, 30(1):298--323, 2002.

\bibitem{Stein2011}
M.~L. Stein.
\newblock 2010 {Rietz} lecture when does the screening effect hold?
\newblock {\em Annals of Statistics}, 39(6):2795--2819, 2011.
\newblock arXiv: 1203.1801v1.

\bibitem{STEIN20141}
M.~L. Stein.
\newblock Limitations on low rank approximations for covariance matrices of
  spatial data.
\newblock {\em Spatial Statistics}, 8:1--19, 2014.
\newblock Spatial Statistics Miami.

\bibitem{Stein2004}
M.~L. Stein, Z.~Chi, and L.~J. Welty.
\newblock {Approximating likelihoods for large spatial data sets}.
\newblock {\em Journal of the Royal Statistical Society. Series B: Statistical
  Methodology}, 66(2):275--296, 2004.

\bibitem{synth_data2022}
A.~Stephenson, R.~Allison, and E.~Pyzer-Knapp.
\newblock Provably reliable large-scale sampling from gaussian processes.
\newblock {\em arXiv preprint arXiv:2211.08036}, 2022.

\bibitem{simulationlib}
S.~Surjanovic and D.~Bingham.
\newblock Virtual library of simulation experiments: Test functions and
  datasets.
\newblock Retrieved May 5, 2023, from \url{http://www.sfu.ca/~ssurjano}.

\bibitem{Titsias}
M.~Titsias.
\newblock Variational learning of inducing variables in sparse gaussian
  processes.
\newblock In {\em Artificial intelligence and statistics}, pages 567--574.
  PMLR, 2009.

\bibitem{Tran2020}
G.-L. Tran, D.~Milios, P.~Michiardi, and M.~Filippone.
\newblock Sparse within sparse gaussian processes using neighbor information.
\newblock In M.~Meila and T.~Zhang, editors, {\em Proceedings of the 38th
  International Conference on Machine Learning}, volume 139 of {\em Proceedings
  of Machine Learning Research}, pages 10369--10378. PMLR, 2021-18.

\bibitem{tresp2000bayesian}
V.~Tresp.
\newblock A bayesian committee machine.
\newblock {\em Neural computation}, 12(11):2719--2741, 2000.

\bibitem{vecchia_estimation_1988}
A.~V. Vecchia.
\newblock Estimation and {Model} {Identification} for {Continuous} {Spatial}
  {Processes}.
\newblock {\em Journal of the Royal Statistical Society. Series B
  (Methodological)}, 50(2):297--312, 1988.
\newblock Publisher: [Royal Statistical Society, Wiley].

\bibitem{exact_big_GP}
K.~Wang, G.~Pleiss, J.~Gardner, S.~Tyree, K.~Q. Weinberger, and A.~G. Wilson.
\newblock Exact gaussian processes on a million data points.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{GP_book}
C.~K. Williams and C.~E. Rasmussen.
\newblock {\em Gaussian processes for machine learning}, volume~2.
\newblock MIT press Cambridge, MA, 2006.

\bibitem{Wilson2015}
A.~G. Wilson and H.~Nickisch.
\newblock {Kernel interpolation for scalable structured Gaussian processes
  (KISS-GP)}.
\newblock {\em 32nd International Conference on Machine Learning, ICML 2015},
  3:1775--1784, 2015.

\bibitem{Wu2022}
L.~Wu, G.~Pleiss, and J.~Cunningham.
\newblock {Variational Nearest Neighbor Gaussian Process}.
\newblock {\em Proceedings of the 39th International Conference on Machine
  Learning}, 2022.

\bibitem{Yadav2021}
M.~Yadav, D.~Sheldon, and C.~Musco.
\newblock Faster kernel interpolation for gaussian processes.
\newblock In A.~Banerjee and K.~Fukumizu, editors, {\em Proceedings of The 24th
  International Conference on Artificial Intelligence and Statistics}, volume
  130 of {\em Proceedings of Machine Learning Research}, pages 2971--2979.
  PMLR, 13--15 Apr 2021.

\end{thebibliography}
