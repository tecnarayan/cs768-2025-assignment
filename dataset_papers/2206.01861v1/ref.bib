@ONLINE{code_compression,
  title = {Anonymous},
  year = 2022
}

@article{tenney2019bert,
  title={Bert rediscovers the classical nlp pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  journal={arXiv:1905.05950},
  year={2019}
}

@article{yao2021mlpruning,
  title={Mlpruning: A multilevel structured pruning framework for transformer-based models},
  author={Yao, Zhewei and Ma, Linjian and Shen, Sheng and Keutzer, Kurt and Mahoney, Michael W},
  journal={arXiv preprint arXiv:2105.14636},
  year={2021}
}

@inproceedings{kim2021bert,
  title={I-bert: Integer-only bert quantization},
  author={Kim, Sehoon and Gholami, Amir and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={International conference on machine learning},
  pages={5506--5518},
  year={2021},
  organization={PMLR}
}

@article{radford2019gpt,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@misc{colin2019t5,
    title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
    author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
    year={2019},
    eprint={1910.10683},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{bondarenko2021understanding,
  title={Understanding and overcoming the challenges of efficient transformer quantization},
  author={Bondarenko, Yelysei and Nagel, Markus and Blankevoort, Tijmen},
  journal={arXiv preprint arXiv:2109.12948},
  year={2021}
}

@article{marcinkiewicz1994building,
  title={Building a large annotated corpus of English: The Penn Treebank},
  author={Marcinkiewicz, Mary Ann},
  journal={Using Large Corpora},
  pages={273},
  year={1994},
  publisher={MIT Press}
}

@article{gholami2021survey,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2103.13630},
  year={2021}
}
@article{smith2022using,
  title={Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model},
  author={Smith, Shaden and Patwary, Mostofa and Norick, Brandon and LeGresley, Patrick and Rajbhandari, Samyam and Casper, Jared and Liu, Zhun and Prabhumoye, Shrimai and Zerveas, George and Korthikanti, Vijay and others},
  journal={arXiv preprint arXiv:2201.11990},
  year={2022}
}

@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@inproceedings{cai2020zeroq,
  title={Zeroq: A novel zero shot quantization framework},
  author={Cai, Yaohui and Yao, Zhewei and Dong, Zhen and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13169--13178},
  year={2020}
}

@inproceedings{nagel2019data,
  title={Data-free quantization through weight equalization and bias correction},
  author={Nagel, Markus and Baalen, Mart van and Blankevoort, Tijmen and Welling, Max},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1325--1334},
  year={2019}
}

@inproceedings{nagel2020up,
  title={Up or down? adaptive rounding for post-training quantization},
  author={Nagel, Markus and Amjad, Rana Ali and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen},
  booktitle={International Conference on Machine Learning},
  pages={7197--7206},
  year={2020},
  organization={PMLR}
}

@article{liu2021post,
  title={Post-training quantization for vision transformer},
  author={Liu, Zhenhua and Wang, Yunhe and Han, Kai and Zhang, Wei and Ma, Siwei and Gao, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{wolf2019huggingface,
  title={{HuggingFace's Transformers}: State-of-the-art Natural Language Processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={ArXiv},
  pages={arXiv--1910},
  year={2019}
}


@inproceedings{williams2018broad,
  title={A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={1112--1122},
  year={2018}
}

@article{dagan2013recognizing,
  title={Recognizing textual entailment: Models and applications},
  author={Dagan, Ido and Roth, Dan and Sammons, Mark and Zanzotto, Fabio Massimo},
  journal={Synthesis Lectures on Human Language Technologies},
  volume={6},
  number={4},
  pages={1--220},
  year={2013},
  publisher={Morgan \& Claypool Publishers}
}

@article{warstadt2018neural,
    title={Neural Network Acceptability Judgments},
    author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1805.12471},
    year={2018}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{hauser2001approximating,
  title={Approximating functions for embedded and ASIC applications},
  author={Hauser, James W and Purdy, Carla N},
  booktitle={Proceedings of the 44th IEEE 2001 Midwest Symposium on Circuits and Systems. MWSCAS 2001 (Cat. No. 01CH37257)},
  volume={1},
  pages={478--481},
  year={2001},
  organization={IEEE}
}

@article{sun2019patient,
  title={Patient knowledge distillation for bert model compression},
  author={Sun, Siqi and Cheng, Yu and Gan, Zhe and Liu, Jingjing},
  journal={arXiv preprint arXiv:1908.09355},
  year={2019}
}


@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}


@article{tang2019distilling,
  title={Distilling task-specific knowledge from bert into simple neural networks},
  author={Tang, Raphael and Lu, Yao and Liu, Linqing and Mou, Lili and Vechtomova, Olga and Lin, Jimmy},
  journal={arXiv preprint arXiv:1903.12136},
  year={2019}
}


@article{turc2019well,
  title={Well-read students learn better: On the importance of pre-training compact models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962},
  year={2019}
}


@article{sun2020mobilebert,
  title={Mobilebert: a compact task-agnostic bert for resource-limited devices},
  author={Sun, Zhiqing and Yu, Hongkun and Song, Xiaodan and Liu, Renjie and Yang, Yiming and Zhou, Denny},
  journal={arXiv preprint arXiv:2004.02984},
  year={2020}
}


@article{wang2020minilm,
  title={Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers},
  author={Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.10957},
  year={2020}
}


@article{fan2019reducing,
  title={Reducing transformer depth on demand with structured dropout},
  author={Fan, Angela and Grave, Edouard and Joulin, Armand},
  journal={arXiv preprint arXiv:1909.11556},
  year={2019}
}


@article{raganato2020fixed,
  title={Fixed encoder self-attention patterns in transformer-based machine translation},
  author={Raganato, Alessandro and Scherrer, Yves and Tiedemann, J{\"o}rg},
  journal={arXiv preprint arXiv:2002.10260},
  year={2020}
}


@article{mao2020ladabert,
  title={Ladabert: Lightweight adaptation of bert through hybrid model compression},
  author={Mao, Yihuan and Wang, Yujing and Wu, Chufan and Zhang, Chen and Wang, Yang and Yang, Yaming and Zhang, Quanlu and Tong, Yunhai and Bai, Jing},
  journal={arXiv preprint arXiv:2004.04124},
  year={2020}
}

@article{gordon2020compressing,
  title={Compressing bert: Studying the effects of weight pruning on transfer learning},
  author={Gordon, Mitchell A and Duh, Kevin and Andrews, Nicholas},
  journal={arXiv preprint arXiv:2002.08307},
  year={2020}
}


@article{ganesh2020compressing,
  title={Compressing large-scale transformer-based models: A case study on bert},
  author={Ganesh, Prakhar and Chen, Yao and Lou, Xin and Khan, Mohammad Ali and Yang, Yin and Chen, Deming and Winslett, Marianne and Sajjad, Hassan and Nakov, Preslav},
  journal={arXiv preprint arXiv:2002.11985},
  year={2020}
}

@article{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  journal={arXiv preprint arXiv:1905.10650},
  year={2019}
}





@article{bai2020binarybert,
  title={BinaryBERT: Pushing the Limit of BERT Quantization},
  author={Bai, Haoli and Zhang, Wei and Hou, Lu and Shang, Lifeng and Jin, Jing and Jiang, Xin and Liu, Qun and Lyu, Michael and King, Irwin},
  journal={arXiv preprint arXiv:2012.15701},
  year={2020}
}

@article{dehghani2018universal,
  title={Universal transformers},
  author={Dehghani, Mostafa and Gouws, Stephan and Vinyals, Oriol and Uszkoreit, Jakob and Kaiser, {\L}ukasz},
  journal={arXiv preprint arXiv:1807.03819},
  year={2018}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{jin2021kdlsq,
  title={KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with Learned Step Size Quantization},
  author={Jin, Jing and Liang, Cai and Wu, Tiancheng and Zou, Liqin and Gan, Zhiliang},
  journal={arXiv preprint arXiv:2101.05938},
  year={2021}
}


@article{esser2019learned,
  title={Learned step size quantization},
  author={Esser, Steven K and McKinstry, Jeffrey L and Bablani, Deepika and Appuswamy, Rathinakumar and Modha, Dharmendra S},
  journal={arXiv preprint arXiv:1902.08153},
  year={2019}
}

@article{zhang2020ternarybert,
  title={Ternarybert: Distillation-aware ultra-low bit bert},
  author={Zhang, Wei and Hou, Lu and Yin, Yichun and Shang, Lifeng and Chen, Xiao and Jiang, Xin and Liu, Qun},
  journal={arXiv preprint arXiv:2009.12812},
  year={2020}
}

@inproceedings{zadeh2020gobo,
  title={Gobo: Quantizing attention-based nlp models for low latency and energy efficient inference},
  author={Zadeh, Ali Hadi and Edo, Isak and Awad, Omar Mohamed and Moshovos, Andreas},
  booktitle={2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages={811--824},
  year={2020},
  organization={IEEE}
}

@article{fan2020training,
  title={Training with quantization noise for extreme fixed-point compression},
  author={Fan, Angela and Stock, Pierre and Graham, Benjamin and Grave, Edouard and Gribonval, Remi and Jegou, Herve and Joulin, Armand},
  journal={arXiv preprint arXiv:2004.07320},
  year={2020}
}

@article{waring1779vii,
  title={Vii. problems concerning interpolations},
  author={Waring, Edward},
  journal={Philosophical transactions of the royal society of London},
  year={1779},
  publisher={The Royal Society London}
}

@book{stewart1996afternotes,
  title={Afternotes on numerical analysis},
  author={Stewart, Gilbert W},
  year={1996},
  publisher={SIAM}
}

@inproceedings{dolan2005automatically,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, William B and Brockett, Chris},
  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},
  year={2005}
}

@article{cer2017semeval,
  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},
  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
  journal={arXiv preprint arXiv:1708.00055},
  year={2017}
}

@article{williams2017broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@article{iyer2017first,
  title={First Quora Dataset Release: Question Pairs.(2017)},
  author={Iyer, Shankar and Dandekar, Nikhil and Csernai, Kornl},
  journal={URL https://data. quora. com/First-Quora-Dataset-Release-Question-Pairs},
  year={2017}
}

@article{warstadt2019neural,
  title={Neural network acceptability judgments},
  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={625--641},
  year={2019},
  publisher={MIT Press}
}

@article{rajpurkar2016squad,
  title={{SQuAD}: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@inproceedings{dagan2005pascal,
  title={The PASCAL recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  pages={177--190},
  year={2005},
  organization={Springer}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},
  year={2012},
  organization={Citeseer}
}

@article{rosset2019turing,
  title={Turing-{NLG}: A 17-billion-parameter language model by microsoft},
  author={Rosset, C},
  journal={Microsoft Blog},
  year={2019}
}

@article{nvidia_wmma,
  title={Using Tensor Cores in CUDA Fortran},
  author={Greg Ruetsch},
  journal={Nvidia Blog},
  year={2021}
}

@misc{gpt-j,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021,
  month = May
}

@article{tao2022compression,
  title={Compression of Generative Pre-trained Language Models via Quantization},
  author={Tao, Chaofan and Hou, Lu and Zhang, Wei and Shang, Lifeng and Jiang, Xin and Liu, Qun and Luo, Ping and Wong, Ngai},
  journal={arXiv preprint arXiv:2203.10705},
  year={2022}
}

@software{gpt-neox,
  author = {Black, Sid and Biderman, Stella and Andonian, Alex and Anthony, Quentin and Gali, Preetham and Gao, Leo and Hallahan, Eric and Levy-Kramer, Josh and Leahy, Connor and Nestler, Lucas and Parker, Kip and Phang, Jason and Pieler, Michael and Purohit, Shivanshu and Songz, Tri and Wang, Phil and Weinbach, Samuel},
  title = {{GPT-NeoX}: Large Scale Autoregressive Language Modeling in PyTorch},
  url = {http://github.com/eleutherai/gpt-neox},
  year = {2021}
}

@article{shoeybi2019megatron,
  title={Megatron-{LM}: Training multi-billion parameter language models using gpu model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{lai2018cmsis,
  title={{CMSIS-NN}: Efficient neural network kernels for arm cortex-m cpus},
  author={Lai, Liangzhen and Suda, Naveen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1801.06601},
  year={2018}
}

@book{crandall2006prime,
  title={Prime numbers: a computational perspective},
  author={Crandall, Richard and Pomerance, Carl B},
  volume={182},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@article{conti2020technical,
  title={Technical Report: NEMO DNN Quantization for Deployment Model},
  author={Conti, Francesco},
  journal={arXiv preprint arXiv:2004.05930},
  year={2020}
}

@inproceedings{kwon2018co,
  title={Co-design of deep neural nets and neural net accelerators for embedded vision applications},
  author={Kwon, Kiseok and Amid, Alon and Gholami, Amir and Wu, Bichen and Asanovic, Krste and Keutzer, Kurt},
  booktitle={2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@article{li2016ternary,
  title={Ternary weight networks},
  author={Li, Fengfu and Zhang, Bo and Liu, Bin},
  journal={arXiv preprint arXiv:1605.04711},
  year={2016}
}

@article{courbariaux2016binarized,
  title={Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1},
  author={Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1602.02830},
  year={2016}
}

@inproceedings{howard2019searching,
  title={Searching for {MobilenetV3}},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1314--1324},
  year={2019}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units ({GELU}s)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{zhang2018record,
  title={Record: Bridging the gap between human and machine commonsense reading comprehension},
  author={Zhang, Sheng and Liu, Xiaodong and Liu, Jingjing and Gao, Jianfeng and Duh, Kevin and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:1810.12885},
  year={2018}
}


@article{yadav2019quick,
  title={Quick and (not so) dirty: Unsupervised selection of justification sentences for multi-hop question answering},
  author={Yadav, Vikas and Bethard, Steven and Surdeanu, Mihai},
  journal={arXiv preprint arXiv:1911.07176},
  year={2019}
}

@inproceedings{afshar2018copa,
  title={COPA: Constrained PARAFAC2 for sparse \& large datasets},
  author={Afshar, Ardavan and Perros, Ioakeim and Papalexakis, Evangelos E and Searles, Elizabeth and Ho, Joyce and Sun, Jimeng},
  booktitle={Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  pages={793--802},
  year={2018}
}

@article{clark2019boolq,
  title={BoolQ: Exploring the surprising difficulty of natural yes/no questions},
  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1905.10044},
  year={2019}
}

@article{lai2017race,
  title={Race: Large-scale reading comprehension dataset from examinations},
  author={Lai, Guokun and Xie, Qizhe and Liu, Hanxiao and Yang, Yiming and Hovy, Eduard},
  journal={arXiv preprint arXiv:1704.04683},
  year={2017}
}

@article{mihaylov2018can,
  title={Can a suit of armor conduct electricity? a new dataset for open book question answering},
  author={Mihaylov, Todor and Clark, Peter and Khot, Tushar and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:1809.02789},
  year={2018}
}

@article{williams2020anlizing,
  title={ANLIzing the adversarial natural language inference dataset},
  author={Williams, Adina and Thrush, Tristan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2010.12729},
  year={2020}
}

@article{boratko2018systematic,
  title={A systematic classification of knowledge, reasoning, and context within the ARC dataset},
  author={Boratko, Michael and Padigela, Harshit and Mikkilineni, Divyendra and Yuvraj, Pritish and Das, Rajarshi and McCallum, Andrew and Chang, Maria and Fokoue-Nkoutche, Achille and Kapanipathi, Pavan and Mattei, Nicholas and others},
  journal={arXiv preprint arXiv:1806.00358},
  year={2018}
}

@inproceedings{tata2003piqa,
  title={PiQA: An algebra for querying protein data sets},
  author={Tata, Sandeep and Patel, Jignesh M},
  booktitle={15th International Conference on Scientific and Statistical Database Management, 2003.},
  pages={141--150},
  year={2003},
  organization={IEEE}
}

@inproceedings{sakaguchi2020winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8732--8740},
  year={2020}
}

@inproceedings{berant-etal-2013-semantic,
    title = "Semantic Parsing on {F}reebase from Question-Answer Pairs",
    author = "Berant, Jonathan  and
      Chou, Andrew  and
      Frostig, Roy  and
      Liang, Percy",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1160",
    pages = "1533--1544",
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{joshi2017triviaqa,
  title={Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}

@article{paperno2016lambada,
  title={The LAMBADA dataset: Word prediction requiring a broad discourse context},
  author={Paperno, Denis and Kruszewski, Germ{\'a}n and Lazaridou, Angeliki and Pham, Quan Ngoc and Bernardi, Raffaella and Pezzelle, Sandro and Baroni, Marco and Boleda, Gemma and Fern{\'a}ndez, Raquel},
  journal={arXiv preprint arXiv:1606.06031},
  year={2016}
}

@article{zellers2019hellaswag,
  title={HellaSwag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@inproceedings{rasley2020deepspeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={3505--3506},
  year={2020}
}

@article{devlin2018bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}

@article{dodge2020fine,
  title={Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping},
  author={Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
  journal={arXiv preprint arXiv:2002.06305},
  year={2020}
}

@article{liu2019roberta,
  title={{RoBERTa}: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{krishnamoorthi2018quantizing,
  title={Quantizing deep convolutional networks for efficient inference: A whitepaper},
  author={Krishnamoorthi, Raghuraman},
  journal={arXiv preprint arXiv:1806.08342},
  year={2018}
}

@article{wu2020integer,
  title={Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation},
  author={Wu, Hao and Judd, Patrick and Zhang, Xiaojie and Isaev, Mikhail and Micikevicius, Paulius},
  journal={arXiv preprint arXiv:2004.09602},
  year={2020}
}

@inproceedings{dong2019hawq,
  title={{HAWQ}: Hessian aware quantization of neural networks with mixed-precision},
  author={Dong, Zhen and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={293--302},
  year={2019}
}

@inproceedings{shen2020q,
  title={{Q-BERT}: Hessian Based Ultra Low Precision Quantization of BERT.},
  author={Shen, Sheng and Dong, Zhen and Ye, Jiayu and Ma, Linjian and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={AAAI},
  pages={8815--8821},
  year={2020}
}

@article{zafrir2019q8bert,
  title={{Q8BERT}: Quantized 8bit bert},
  author={Zafrir, Ofir and Boudoukh, Guy and Izsak, Peter and Wasserblat, Moshe},
  journal={arXiv preprint arXiv:1910.06188},
  year={2019}
}

@article{bhandare2019efficient,
  title={Efficient 8-bit quantization of transformer neural machine language translation model},
  author={Bhandare, Aishwarya and Sripathi, Vamsi and Karkada, Deepthi and Menon, Vivek and Choi, Sun and Datta, Kushal and Saletore, Vikram},
  journal={arXiv preprint arXiv:1906.00532},
  year={2019}
}

@article{wu2018mixed,
  title={Mixed precision quantization of convnets via differentiable neural architecture search},
  author={Wu, Bichen and Wang, Yanghan and Zhang, Peizhao and Tian, Yuandong and Vajda, Peter and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1812.00090},
  year={2018}
}

@inproceedings{zhang2018lq,
  title={{LQ-Nets}: Learned quantization for highly accurate and compact deep neural networks},
  author={Zhang, Dongqing and Yang, Jiaolong and Ye, Dongqiangzi and Hua, Gang},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={365--382},
  year={2018}
}

@inproceedings{wu2016quantized,
  title={Quantized convolutional neural networks for mobile devices},
  author={Wu, Jiaxiang and Leng, Cong and Wang, Yuhang and Hu, Qinghao and Cheng, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4820--4828},
  year={2016}
}

@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2704--2713},
  year={2018}
}


@article{wang2018glue,
  title={{GLUE}: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@BOOK{Mah-mat-rev_BOOK,
  author =       {Michael W Mahoney},
  title =        {Randomized algorithms for matrices and data},
  publisher =    {NOW Publishers},
  year =         {2011},
  address =      {Boston},
  series =       {Foundations and Trends in Machine Learning},
}

@INCOLLECTION{RandNLA_PCMIchapter_chapter,
  author =       {Petros Drineas and Michael W Mahoney},
  title =        {Lectures on Randomized Numerical Linear Algebra},
  booktitle =    {The Mathematics of Data},
  year =         {2018},
  pages =        {1--48},
  series =       {IAS/Park City Mathematics Series},
  publisher =    {AMS/IAS/SIAM},
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting on association for computational linguistics},
  pages={311--318},
  year={2002},
  organization={Association for Computational Linguistics}
}

@inproceedings{wang2019learning,
  title={Learning Deep Transformer Models for Machine Translation},
  author={Wang, Qiang and Li, Bei and Xiao, Tong and Zhu, Jingbo and Li, Changliang and Wong, Derek F and Chao, Lidia S},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1810--1822},
  year={2019}
}

@article{mahoney2011large,
  title={Large text compression benchmark},
  author={Mahoney, Matt}
}

@article{younesshapes,
  title={Shapes and Diffeomorphisms},
  author={Younes, Laurent},
  journal={Springer Science \& Business Media}
}

@article{turing1990chemical,
  title={The chemical basis of morphogenesis},
  author={Turing, Alan Mathison},
  journal={Bulletin of mathematical biology},
  volume={52},
  number={1-2},
  pages={153--197},
  year={1952},
  publisher={Springer}
}

@BOOK{lions72,
  title = {Some Aspects of the Optimal Control of Distributed Parameter Systems},
  publisher = {SIAM},
  year = {1972},
  author = {Jacques-Louis Lions}
}

@book{rosenblatt1957perceptron,
  title={The perceptron, a perceiving and recognizing automaton Project Para},
  author={Rosenblatt, Frank},
  year={1957},
  publisher={Cornell Aeronautical Laboratory}
}

@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

@article{minsky1969perceptron,
  title={Perceptron: an introduction to computational geometry},
  author={Minsky, Marvin and Papert, Seymour},
  journal={The MIT Press, Cambridge, expanded edition},
  volume={19},
  number={88},
  pages={2},
  year={1969}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Elsevier}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@InProceedings{simonyan2014very,
  author       = "Simonyan, K. and Zisserman, A.",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "International Conference on Learning Representations",
  year         = "2015",
}



@inproceedings{szegedy2016rethinking,
  title={Rethinking the {Inception} architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{ma2018shufflenet,
  title={Shufflenet {V2}: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={116--131},
  year={2018}
}

@inproceedings{sandler2018mobilenetv2,
  title={{MobilenetV2}: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018}
}


@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={International Conference on Learning Representations},
  year={2016}
}

@article{zhou2017incremental,
  title={Incremental network quantization: Towards lossless cnns with low-precision weights},
  author={Zhou, Aojun and Yao, Anbang and Guo, Yiwen and Xu, Lin and Chen, Yurong},
  journal={International Conference on Learning Representations},
  year={2017}
}

@article{choi2018pact,
  title={{PACT}: Parameterized clipping activation for quantized neural networks},
  author={Choi, Jungwook and Wang, Zhuo and Venkataramani, Swagath and Chuang, Pierce I-Jen and Srinivasan, Vijayalakshmi and Gopalakrishnan, Kailash},
  journal={arXiv preprint arXiv:1805.06085},
  year={2018}
}





@article{polino2018model,
  title={Model compression via distillation and quantization},
  author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  journal={arXiv preprint arXiv:1802.05668},
  year={2018}
}

@article{howard2017mobilenets,
  title={{MobileNets}: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}
@article{iandola2016squeezenet,
  title={{SqueezeNet}: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}
@inproceedings{rastegari2016xnor,
  title={{XNOR-Net}: Imagenet classification using binary convolutional neural networks},
  author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
  booktitle={European Conference on Computer Vision},
  pages={525--542},
  year={2016},
  organization={Springer}
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binary{C}onnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Advances in neural information processing systems},
  pages={3123--3131},
  year={2015}
}

@InProceedings{Zhang_2018_ECCV,
author = {Zhang, Dongqing and Yang, Jiaolong and Ye, Dongqiangzi and Hua, Gang},
title = {{LQ-Nets}: Learned Quantization for Highly Accurate and Compact Deep Neural Networks},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{krogh1992simple,
  title={A simple weight decay can improve generalization},
  author={Krogh, Anders and Hertz, John A},
  booktitle={Advances in neural information processing systems},
  pages={950--957},
  year={1992}
}

@article{romero2014fitnets,
  title={{FitNet}s: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}

@inproceedings{grosse2016kronecker,
  title={A Kronecker-factored approximate Fisher matrix for convolution layers},
  author={Grosse, Roger and Martens, James},
  booktitle={International Conference on Machine Learning},
  pages={573--582},
  year={2016}
}

@inproceedings{redmon2017yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}


@inproceedings{sharma2018bit,
  title={Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural networks},
  author={Sharma, Hardik and Park, Jongse and Suda, Naveen and Lai, Liangzhen and Chau, Benson and Chandra, Vikas and Esmaeilzadeh, Hadi},
  booktitle={Proceedings of the 45th Annual International Symposium on Computer Architecture},
  pages={764--775},
  year={2018},
  organization={IEEE Press}
}

@inproceedings{bismo,
author = {Umuroglu, Yaman and Rasnayake, Lahiru and Sjalander, Magnus},
title = {BISMO: A Scalable Bit-Serial Matrix Multiplication Overlay for Reconfigurable Computing},
booktitle = {Field Programmable Logic and Applications (FPL), 2018 28th International Conference on},
series = {FPL '18},
year = {2018}
}

@article{li2016pruning,
  title={Pruning filters for efficient convnets},
  author={Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  journal={arXiv preprint arXiv:1608.08710},
  year={2016}
}

@article{molchanov2016pruning,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06440},
  year={2016}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={Workshop paper in NIPS},
  year={2014}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@article{shallue2018measuring,
  title={Measuring the effects of data parallelism on neural network training},
  author={Shallue, Christopher J and Lee, Jaehoon and Antognini, Joe and Sohl-Dickstein, Jascha and Frostig, Roy and Dahl, George E},
  journal={arXiv preprint arXiv:1811.03600},
  year={2018}
}

@article{osawa2018second,
  title={Second-order Optimization Method for Large Mini-batch: Training ResNet-50 on ImageNet in 35 Epochs},
  author={Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse, Akira and Yokota, Rio and Matsuoka, Satoshi},
  journal={arXiv preprint arXiv:1811.12019},
  year={2018}
}

@article{ba2016distributed,
  title={Distributed second-order optimization using Kronecker-factored approximations},
  author={Ba, Jimmy and Grosse, Roger and Martens, James},
  year={2016}
}

@article{KFAC-G15,
  author    = {James Martens and
               Roger B. Grosse},
  title     = {Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
  journal   = {CoRR},
  volume    = {abs/1503.05671},
  year      = {2015},
  url       = {http://arxiv.org/abs/1503.05671},
  archivePrefix = {arXiv},
  eprint    = {1503.05671},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MartensG15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
wd-kfac,
title={Three Mechanisms of Weight Decay Regularization},
author={Guodong Zhang and Chaoqi Wang and Bowen Xu and Roger Grosse},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{FACEBOOK-IMAGENET-1H,
  author    = {Priya Goyal and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Pieter Noordhuis and
               Lukasz Wesolowski and
               Aapo Kyrola and
               Andrew Tulloch and
               Yangqing Jia and
               Kaiming He},
  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},
  journal   = {CoRR},
  volume    = {abs/1706.02677},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02677},
  archivePrefix = {arXiv},
  eprint    = {1706.02677},
  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GoyalDGNWKTJH17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{GOOG-2M-IMAGENET,
  author    = {Yang You and
               Zhao Zhang and
               Cho{-}Jui Hsieh and
               James Demmel},
  title     = {100-epoch ImageNet Training with AlexNet in 24 Minutes},
  journal   = {CoRR},
  volume    = {abs/1709.05011},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.05011},
  archivePrefix = {arXiv},
  eprint    = {1709.05011},
  timestamp = {Mon, 13 Aug 2018 16:47:54 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-05011},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ma2017power,
  title={The power of interpolation: Understanding the effectiveness of SGD in modern over-parametrized learning},
  author={Ma, Siyuan and Bassily, Raef and Belkin, Mikhail},
  journal={arXiv preprint arXiv:1712.06559},
  year={2017}
}

@article{OpenAI-EMP-LBS,
  author    = {Sam McCandlish and
               Jared Kaplan and
               Dario Amodei and
               OpenAI Dota Team},
  title     = {An Empirical Model of Large-Batch Training},
  journal   = {CoRR},
  volume    = {abs/1812.06162},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06162},
  archivePrefix = {arXiv},
  eprint    = {1812.06162},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1812-06162},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Noah-EMP-CRIT-BS,
  author    = {Noah Golmant and
               Nikita Vemuri and
               Zhewei Yao and
               Vladimir Feinberg and
               Amir Gholami and
               Kai Rothauge and
               Michael W. Mahoney and
               Joseph Gonzalez},
  title     = {On the Computational Inefficiency of Large Batch Sizes for Stochastic
               Gradient Descent},
  journal   = {CoRR},
  volume    = {abs/1811.12941},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.12941},
  archivePrefix = {arXiv},
  eprint    = {1811.12941},
  timestamp = {Mon, 03 Dec 2018 07:50:28 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-12941},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{GOOG-LB-KFAC-HYPO,
  author    = {Christopher J. Shallue and
               Jaehoon Lee and
               Joseph M. Antognini and
               Jascha Sohl{-}Dickstein and
               Roy Frostig and
               George E. Dahl},
  title     = {Measuring the Effects of Data Parallelism on Neural Network Training},
  journal   = {CoRR},
  volume    = {abs/1811.03600},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.03600},
  archivePrefix = {arXiv},
  eprint    = {1811.03600},
  timestamp = {Fri, 23 Nov 2018 12:43:51 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-03600},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{gholami2017integrated,
  title={Integrated Model, Batch and Domain Parallelism in Training Neural Networks},
  author={Gholami, Amir and Azad, Ariful and Jin, Peter and Keutzer, Kurt and Buluc, Aydin},
  journal={ACM Symposium on Parallelism in Algorithms and Architectures(SPAA'18)},
note={\href{https://arxiv.org/pdf/1712.04432.pdf}{[PDF]}},
  year={2018}
}

@inproceedings{zhang2015deep,
  title={Deep learning with elastic averaging SGD},
  author={Zhang, Sixin and Choromanska, Anna E and LeCun, Yann},
  booktitle={Advances in Neural Information Processing Systems},
  pages={685--693},
  year={2015}
}

@article{jia2018highly,
  title={Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes},
  author={Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and others},
  journal={arXiv preprint arXiv:1807.11205},
  year={2018}
}


@article{bertsimas2011theory,
  title={Theory and applications of robust optimization},
  author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
  journal={SIAM review},
  volume={53},
  number={3},
  pages={464--501},
  year={2011},
  publisher={SIAM}
}

@article{maleki2017parallel,
  title={Parallel Stochastic Gradient Descent with Sound Combiners},
  author={Maleki, Saeed and Musuvathi, Madanlal and Mytkowicz, Todd},
  journal={arXiv preprint arXiv:1705.08030},
  year={2017}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{smith2018bayesian,
  title={A bayesian perspective on generalization and stochastic gradient descent},
  author={Smith, Samuel L and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.06451},
  year={2018}
}

@article{smith2017don,
  title={Don't Decay the Learning Rate, Increase the Batch Size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.00489},
  year={2017}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch SGD: training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{yao2018hessian,
  title={Hessian-based Analysis of Large Batch Training and Robustness to Adversaries},
  author={Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{dinh2017sharp,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1703.04933},
  year={2017}
}

@inproceedings{smith2017cyclical,
  title={Cyclical learning rates for training neural networks},
  author={Smith, Leslie N},
  booktitle={Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on},
  pages={464--472},
  year={2017},
  organization={IEEE}
}

@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get M for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  institution={Citeseer}
}

@article{lin2013network,
  title={Network in network},
  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},
  journal={arXiv preprint arXiv:1312.4400},
  year={2013}
}

@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  booktitle={NIPS workshop on deep learning and unsupervised feature learning},
  volume={2011},
  pages={5},
  year={2011}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{shwartz2017opening,
  title={Opening the black box of deep neural networks via information},
  author={Shwartz-Ziv, Ravid and Tishby, Naftali},
  journal={arXiv preprint arXiv:1703.00810},
  year={2017}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@inproceedings{dauphin2014identifying,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2933--2941},
  year={2014}
}

@article{devarakonda2017adabatch,
  title={AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks},
  author={Devarakonda, Aditya and Naumov, Maxim and Garland, Michael},
  journal={arXiv preprint arXiv:1712.02029},
  year={2017}
}


@article{zhu2018anisotropic,
  title={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}

@article{friedlander2012hybrid,
  title={Hybrid deterministic-stochastic methods for data fitting},
  author={Friedlander, Michael P and Schmidt, Mark},
  journal={SIAM Journal on Scientific Computing},
  volume={34},
  number={3},
  pages={A1380--A1405},
  year={2012},
  publisher={SIAM}
}

@article{balles2016coupling,
  title={Coupling adaptive batch sizes with learning rates},
  author={Balles, Lukas and Romero, Javier and Hennig, Philipp},
  journal={arXiv preprint arXiv:1612.05086},
  year={2016}
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1731--1741},
  year={2017}
}

@article{you2017scaling,
  title={Scaling sgd batch size to 32k for imagenet training},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@article{dong2017learning,
  title={Learning accurate low-bit deep neural networks with stochastic quantization},
  author={Dong, Yinpeng and Ni, Renkun and Li, Jianguo and Chen, Yurong and Zhu, Jun and Su, Hang},
  journal={British Machine Vision Conference},
  year={2017}
}

@article{puri2018large,
  title={Large Scale Language Modeling: Converging on 40GB of Text in Four Hours},
  author={Puri, Raul and Kirby, Robert and Yakovenko, Nikolai and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.01371},
  year={2018}
}

@article{goodfellow6572explaining,
  title={Explaining and harnessing adversarial examples (2014)},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}


@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{gholami2018squeezenext,
  title={{SqueezeNext}: Hardware-Aware Neural Network Design},
  author={Gholami, Amir and Kwon, Kiseok and Wu, Bichen and Tai, Zizheng and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Keutzer, Kurt},
  journal={Workshop paper in CVPR},
  year={2018}
}

@article{thakur2005optimization,
  title={Optimization of collective communication operations in MPICH},
  author={Thakur, Rajeev and Rabenseifner, Rolf and Gropp, William},
  journal={The International Journal of High Performance Computing Applications},
  volume={19},
  number={1},
  pages={49--66},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{zheng2016asynchronous,
  title={Asynchronous stochastic gradient descent with delay compensation},
  author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1609.08326},
  year={2016}
}

@inproceedings{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle={Advances in Neural Information Processing Systems},
  pages={873--881},
  year={2011}
}

@article{el1997robust,
  title={Robust solutions to least-squares problems with uncertain data},
  author={El Ghaoui, Laurent and Lebret, Herv{\'e}},
  journal={SIAM Journal on matrix analysis and applications},
  volume={18},
  number={4},
  pages={1035--1064},
  year={1997},
  publisher={SIAM}
}

@inproceedings{xu2009robust,
  title={Robust regression and lasso},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1801--1808},
  year={2009}
}

@article{xu2017second,
  title={Second-order optimization for non-convex machine learning: An empirical study},
  author={Xu, Peng and Roosta-Khorasan, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07827},
  year={2017}
}

@article{chen2018comparison,
  title={A comparison of second-order methods for deep convolutional neural networks},
  author={Chen, Patrick H and Hsieh, Cho-jui},
  journal={openreview under ICLR 2018},
  year={2018}
}

@inproceedings{martens2010deep,
  title={Deep learning via {H}essian-free optimization.},
  author={Martens, James},
  booktitle={ICML},
  volume={27},
  pages={735--742},
  year={2010}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2574--2582},
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={39--57},
  year={2017},
  organization={IEEE}
}

@article{kurakin2016adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}

@article{xu2017newton,
  title={Newton-type methods for non-convex optimization under inexact {H}essian information},
  author={Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07164},
  year={2017}
}

@inproceedings{yang2019synetgy,
  title={Synetgy: Algorithm-hardware co-design for {C}onv{N}et accelerators on embedded {FPGA}s},
  author={Yang, Yifan and Huang, Qijing and Wu, Bichen and Zhang, Tianjun and Ma, Liang and Gambardella, Giulio and Blott, Michaela and Lavagno, Luciano and Vissers, Kees and Wawrzynek, John and  Keutzer, Kurt},
  booktitle={Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  pages={23--32},
  year={2019},
  organization={ACM}
}

@article{ward2018adagrad,
  title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
  author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
  journal={arXiv preprint arXiv:1806.01811},
  year={2018}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@article{shaham2015understanding,
  title={Understanding adversarial training: Increasing local stability of neural nets through robust optimization},
  author={Shaham, Uri and Yamada, Yutaro and Negahban, Sahand},
  journal={arXiv preprint arXiv:1511.05432},
  year={2015}
}

@inproceedings{shrivastava2017learning,
  title={Learning from Simulated and Unsupervised Images through Adversarial Training.},
  author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
  booktitle={CVPR},
  volume={2},
  pages={5},
  year={2017}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{yao2018large,
  title={Large batch size training of neural networks with adversarial training and second-order information},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1810.01021},
  year={2018}
}

@misc{ginsburg2017tensor,
  title={Tensor processing using low precision format},
  author={Ginsburg, Boris and Nikolaev, Sergei and Kiswani, Ahmad and Wu, Hao and Gholaminejad, Amir and Kierat, Slawomir and Houston, Michael and Fit-Florea, Alex},
  year={2017},
  month=dec # "~28",
  publisher={Google Patents},
  note={US Patent App. 15/624,577}
}


@article{zhou2016dorefa,
  title={{DoReFa-Net}: Training low bitwidth convolutional neural networks with low bitwidth gradients},
  author={Zhou, Shuchang and Wu, Yuxin and Ni, Zekun and Zhou, Xinyu and Wen, He and Zou, Yuheng},
  journal={arXiv preprint arXiv:1606.06160},
  year={2016}
}
@article{hubara2017quantized,
  title={Quantized neural networks: Training neural networks with low precision weights and activations},
  author={Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6869--6898},
  year={2017},
  publisher={JMLR. org}
}

@article{miyashita2016convolutional,
  title={Convolutional neural networks using logarithmic data representation},
  author={Miyashita, Daisuke and Lee, Edward H and Murmann, Boris},
  journal={arXiv preprint arXiv:1603.01025},
  year={2016}
}

@inproceedings{denton2014exploiting,
  title={Exploiting linear structure within convolutional networks for efficient evaluation},
  author={Denton, Emily L and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
  booktitle={Advances in neural information processing systems},
  pages={1269--1277},
  year={2014}
}




@inproceedings{hubara2016binarized,
  title={Binarized neural networks},
  author={Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={4107--4115},
  year={2016}
}
@book{asanovic1991experimental,
  title={Experimental determination of precision requirements for back-propagation training of artificial neural networks},
  author={Asanovic, Krste and Morgan, Nelson},
  year={1991},
  publisher={International Computer Science Institute}
}


@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in neural information processing systems},
  pages={1135--1143},
  year={2015}
}


@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press}
}

@article{wang2018haq,
  title={{HAQ}: Hardware-Aware Automated Quantization},
  author={Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},
  journal={In Proceedings of  the IEEE  conference  on  computer  vision  and  pattern  recognition},
  year={2019}
}

@article{mao2017exploring,
  title={Exploring the regularity of sparse structure in convolutional neural networks},
  author={Mao, Huizi and Han, Song and Pool, Jeff and Li, Wenshuo and Liu, Xingyu and Wang, Yu and Dally, William J},
  journal={Workshop paper in CVPR},
  year={2017}
}


@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}


@inproceedings{park2018value,
  title={Value-aware quantization for training and inference of neural networks},
  author={Park, Eunhyeok and Yoo, Sungjoo and Vajda, Peter},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={580--595},
  year={2018}
}

@inproceedings{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6571--6583},
  year={2018}
}

@article{gholami2019anode,
  title={ANODE: Unconditionally Accurate Memory-Efficient Gradients for Neural ODEs},
  author={Gholami, Amir and Keutzer, Kurt and Biros, George},
  journal={arXiv preprint arXiv:1902.10298},
  year={2019}
}


@techreport{rosenblatt1961principles,
  title={Principles of neurodynamics. perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank},
  year={1961},
  institution={Cornell Aeronautical Lab Inc Buffalo NY}
}
@book{yan2009linear,
  title={Linear regression analysis: theory and computing},
  author={Yan, Xin and Su, Xiaogang},
  year={2009},
  publisher={World Scientific}
}



@book{gauss1809theoria,
  title={Theoria motus corporum coelestium in sectionibus conicis solem ambientium},
  author={Gauss, Carl Friedrich},
  volume={7},
  year={1809},
  publisher={Perthes et Besser}
}

@book{legendre1805nouvelles,
  title={Nouvelles m{\'e}thodes pour la d{\'e}termination des orbites des com{\`e}tes},
  author={Legendre, Adrien Marie},
  year={1805},
  publisher={F. Didot}
}


@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}


@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@book{rosenblatt1957perceptron,
  title={The perceptron, a perceiving and recognizing automaton Project Para},
  author={Rosenblatt, Frank},
  year={1957},
  publisher={Cornell Aeronautical Laboratory}
}



@article{weinan2017proposal,
  title={A proposal on machine learning via dynamical systems},
  author={Weinan, E},
  journal={Communications in Mathematics and Statistics},
  volume={5},
  number={1},
  pages={1--11},
  year={2017},
  publisher={Springer}
}
@article{haber2017stable,
  title={Stable architectures for deep neural networks},
  author={Haber, Eldad and Ruthotto, Lars},
  journal={Inverse Problems},
  volume={34},
  number={1},
  pages={014004},
  year={2017},
  publisher={IOP Publishing}
}
@article{ruthotto2018deep,
  title={Deep Neural Networks motivated by Partial Differential Equations},
  author={Ruthotto, Lars and Haber, Eldad},
  journal={arXiv preprint arXiv:1804.04272},
  year={2018}
}
@article{lu2017beyond,
  title={Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations},
  author={Lu, Yiping and Zhong, Aoxiao and Li, Quanzheng and Dong, Bin},
  journal={arXiv preprint arXiv:1710.10121},
  year={2017}
}
@article{ciccone2018nais,
  title={NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations},
  author={Ciccone, Marco and Gallieri, Marco and Masci, Jonathan and Osendorfer, Christian and Gomez, Faustino},
  journal={arXiv preprint arXiv:1804.07209},
  year={2018}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@inproceedings{tsuchida2018invariance,
  title={Invariance of Weight Distributions in Rectified MLPs},
  author={Tsuchida, Russell and Roosta-Khorasani, Farbod and Gallagher, Marcus},
  booktitle={International Conference on Machine Learning},
  pages={5002--5011},
  year={2018}
}




@article{ha2016hypernetworks,
  title={Hypernetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  journal={arXiv preprint arXiv:1609.09106},
  year={2016}
}

@article{stanley2009hypercube,
  title={A hypercube-based encoding for evolving large-scale neural networks},
  author={Stanley, Kenneth O and D'Ambrosio, David B and Gauci, Jason},
  journal={Artificial life},
  volume={15},
  number={2},
  pages={185--212},
  year={2009},
  publisher={MIT Press}
}

@inproceedings{stanley2006exploiting,
  title={Exploiting regularity without development},
  author={Stanley, Kenneth O},
  booktitle={Proceedings of the AAAI Fall Symposium on Developmental Systems},
  pages={37},
  year={2006},
  organization={AAAI Press Menlo Park, CA}
}
@article{stanley2007compositional,
  title={Compositional pattern producing networks: A novel abstraction of development},
  author={Stanley, Kenneth O},
  journal={Genetic programming and evolvable machines},
  volume={8},
  number={2},
  pages={131--162},
  year={2007},
  publisher={Springer}
}




@inproceedings{angeline1995morphogenic,
  title={Morphogenic Evolutionary Computations: Introduction, Issues and Example.},
  author={Angeline, Peter J},
  booktitle={Evolutionary Programming},
  pages={387--401},
  year={1995}
}

% -------


@article{lindenmayer1968mathematical,
  title={Mathematical models for cellular interactions in development I. Filaments with one-sided inputs},
  author={Lindenmayer, Aristid},
  journal={Journal of theoretical biology},
  volume={18},
  number={3},
  pages={280--299},
  year={1968},
  publisher={Elsevier}
}


@inproceedings{belew1993evolving,
  title={Evolving Aesthetic Sorting Networks Using Developmental Grammars.},
  author={Belew, Richard K and Kammeyer, Thomas E},
  booktitle={ICGA},
  pages={629},
  year={1993},
  organization={Citeseer}
}

@inproceedings{bentley1999three,
  title={Three ways to grow designs: A comparison of embryogenies for an evolutionary design problem},
  author={Bentley, Peter and Kumar, Sanjeev},
  booktitle={Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1},
  pages={35--43},
  year={1999},
  organization={Morgan Kaufmann Publishers Inc.}
}

@inproceedings{dellaert1996developmental,
  title={A developmental model for the evolution of complete autonomous agents},
  author={Dellaert, Frank and Beer, Randall D},
  booktitle={Proceedings of the fourth international conference on simulation of adaptive behavior},
  pages={393--401},
  year={1996},
  organization={MIT Press Cambridge, MA}
}

@inproceedings{eggenberger1997evolving,
  title={Evolving morphologies of simulated 3D organisms based on differential gene expression},
  author={Eggenberger, Peter},
  booktitle={Proceedings of the fourth european conference on Artificial Life},
  pages={205--213},
  year={1997}
}


@article{hornby2002creating,
  title={Creating high-level components with a generative representation for body-brain evolution},
  author={Hornby, Gregory S and Pollack, Jordan B},
  journal={Artificial life},
  volume={8},
  number={3},
  pages={223--246},
  year={2002},
  publisher={MIT Press}
}

@inproceedings{koutnik2010evolving,
  title={Evolving neural networks in compressed weight space},
  author={Koutnik, Jan and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 12th annual conference on Genetic and evolutionary computation},
  pages={619--626},
  year={2010},
  organization={ACM}
}



@inproceedings{fernando2016convolution,
  title={Convolution by evolution: Differentiable pattern producing networks},
  author={Fernando, Chrisantha and Banarse, Dylan and Reynolds, Malcolm and Besse, Frederic and Pfau, David and Jaderberg, Max and Lanctot, Marc and Wierstra, Daan},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference 2016},
  pages={109--116},
  year={2016},
  organization={ACM}
}


@article{moczulski2015acdc,
  title={Acdc: A structured efficient linear layer},
  author={Moczulski, Marcin and Denil, Misha and Appleyard, Jeremy and de Freitas, Nando},
  journal={arXiv preprint arXiv:1511.05946},
  year={2015}
}

@article{schmidhuber1992learning,
  title={Learning to control fast-weight memories: An alternative to dynamic recurrent networks},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={4},
  number={1},
  pages={131--139},
  year={1992},
  publisher={MIT Press}
}

@inproceedings{schmidhuber1993self,
  title={A self-referentialweight matrix},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={446--450},
  year={1993},
  organization={Springer}
}


@article{gholami2016inverse,
  title={An inverse problem formulation for parameter estimation of a reaction--diffusion model of low grade gliomas},
  author={Gholami, Amir and Mang, Andreas and Biros, George},
  journal={Journal of mathematical biology},
  volume={72},
  number={1-2},
  pages={409--433},
  year={2016},
  publisher={Springer}
}
@ONLINE{ibertcode,
  title = {https://github.com/kssteven418/I-BERT},
  year = 2021
}

@article{avron2011randomized,
  title={Randomized algorithms for estimating the trace of an implicit symmetric positive semi-definite matrix},
  author={Avron, Haim and Toledo, Sivan},
  journal={Journal of the ACM (JACM)},
  volume={58},
  number={2},
  pages={8},
  year={2011},
  publisher={ACM}
}

@article{bai1996some,
  title={Some large-scale matrix computation problems},
  author={Bai, Zhaojun and Fahey, Gark and Golub, Gene},
  journal={Journal of Computational and Applied Mathematics},
  volume={74},
  number={1-2},
  pages={71--89},
  year={1996},
  publisher={Elsevier}
}

@article{ubaru2017fast,
  title={Fast Estimation of tr(f(A)) via Stochastic {L}anczos Quadrature},
  author={Ubaru, Shashanka and Chen, Jie and Saad, Yousef},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={38},
  number={4},
  pages={1075--1099},
  year={2017},
  publisher={SIAM}
}

@article{lin2016approximating,
  title={Approximating spectral densities of large matrices},
  author={Lin, Lin and Saad, Yousef and Yang, Chao},
  journal={SIAM review},
  volume={58},
  number={1},
  pages={34--65},
  year={2016},
  publisher={SIAM}
}

@book{golub2009matrices,
  title={Matrices, moments and quadrature with applications},
  author={Golub, Gene H and Meurant, G{\'e}rard},
  year={2009},
  publisher={Princeton University Press}
}

@article{golub1969calculation,
  title={Calculation of {G}auss quadrature rules},
  author={Golub, Gene H and Welsch, John H},
  journal={Mathematics of computation},
  volume={23},
  number={106},
  pages={221--230},
  year={1969}
}

fmemory
@inproceedings{yang2019xlnet,
  title={{XLNet}: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={5753--5763},
  year={2019}
}

@inproceedings{dai2019transformer,
  title={Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime G and Le, Quoc and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2978--2988},
  year={2019}
}

@article{ghorbani2019investigation,
  title={An investigation into neural net optimization via {H}essian eigenvalue density},
  author={Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
  journal={arXiv preprint arXiv:1901.10159},
  year={2019}
}

@article{sagun2016eigenvalues,
  title={Eigenvalues of the {H}essian in deep learning: Singularity and beyond},
  author={Sagun, Levent and Bottou, Leon and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.07476},
  year={2016}
}

@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv preprint arXiv:1011.3027},
  year={2010}
}

@ONLINE{pyhessian,
  title = {https://github.com/amirgholami/PyHessian.git},
  month = Sep,
  year = 2019
}

@ONLINE{armcortexm,
  author={{ARM}},
  title = {{Cortex-M}, https://developer.arm.com/ip-products/processors/cortex-m},
  year = 2020
}

@ONLINE{tensorrtbert,
  author={ Mukherjee, Purnendu and Weill, Eddie and Taneja, Rohit and Onofrio, Davide and Ko, Young-Jun and Sharma, Siddharth},
  title = {Real-Time Natural Language Understanding with BERT Using TensorRT, hhttps://developer.nvidia.com/blog/nlu-with-tensorrt-bert/},
  year = 2019
}

@ONLINE{tensorrt,
  author={{NVIDIA}},
  title = {Tensor{RT}: https://developer.nvidia.com/tensorrt},
  year={2018}
}

@inproceedings{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2483--2493},
  year={2018}
}



@article{martin2019traditional,
  title={Traditional and heavy-tailed self regularization in neural network models},
  author={Martin, Charles H and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1901.08276},
  year={2019}
}


@article{clevert2015fast,
  title={Fast and accurate deep network learning by exponential linear units (elus)},
  author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:1511.07289},
  year={2015}
}

@inproceedings{klambauer2017self,
  title={Self-normalizing neural networks},
  author={Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  booktitle={Advances in neural information processing systems},
  pages={971--980},
  year={2017}
}

@article{mahoney2009cur,
  title={{CUR} matrix decompositions for improved data analysis},
  author={Mahoney, Michael W and Drineas, Petros},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={3},
  pages={697--702},
  year={2009},
  publisher={National Acad Sciences}
}

@article{drineas2006fast,
  title={Fast Monte Carlo algorithms for matrices {II}: Computing a low-rank approximation to a matrix},
  author={Drineas, Petros and Kannan, Ravi and Mahoney, Michael W},
  journal={SIAM Journal on computing},
  volume={36},
  number={1},
  pages={158--183},
  year={2006},
  publisher={SIAM}
}

@inproceedings{becker1988improving,
  title={Improving the convergence of back-propagation learning with second order methods},
  author={Becker, Sue and Le Cun, Yann},
  booktitle={Proceedings of the 1988 connectionist models summer school},
  pages={29--37},
  year={1988}
}

@article{sagun2017empirical,
  title={Empirical analysis of the hessian of over-parametrized neural networks},
  author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
  journal={arXiv preprint arXiv:1706.04454},
  year={2017}
}



@article{papyan2018full,
  title={The full spectrum of deep net hessians at scale: Dynamics with sample size},
  author={Papyan, Vardan},
  journal={arXiv preprint arXiv:1811.07062},
  year={2018}
}


@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@inproceedings{pennington2017geometry,
  title={Geometry of neural network loss surfaces via random matrix theory},
  author={Pennington, Jeffrey and Bahri, Yasaman},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2798--2806},
  year={2017},
  organization={JMLR. org}
}



@inproceedings{yao2019trust,
  title={Trust region based adversarial attack on neural networks},
  author={Yao, Zhewei and Gholami, Amir and Xu, Peng and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={11350--11359},
  year={2019}
}

@inproceedings{xu2016sub,
  title={Sub-sampled {N}ewton methods with non-uniform sampling},
  author={Xu, Peng and Yang, Jiyan and Roosta-Khorasani, Farbod and R{\'e}, Christopher and Mahoney, Michael W},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3000--3008},
  year={2016}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{byrd2011use,
  title={On the use of stochastic {H}essian information in optimization methods for machine learning},
  author={Byrd, Richard H and Chin, Gillian M and Neveitt, Will and Nocedal, Jorge},
  journal={SIAM Journal on Optimization},
  volume={21},
  number={3},
  pages={977--995},
  year={2011},
  publisher={SIAM}
}

@article{erdogdu2015convergence,
  title={Convergence rates of sub-sampled {N}ewton methods},
  author={Erdogdu, Murat A and Montanari, Andrea},
  journal={arXiv preprint arXiv:1508.02810},
  year={2015}
}

@article{roosta2016sub,
  title={Sub-sampled {N}ewton methods {I}: globally convergent algorithms},
  author={Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1601.04737},
  year={2016}
}

@book{conn2000trust,
	title={Trust region methods},
	author={Conn, Andrew R and Gould, Nicholas IM and Toint, Philippe L},
	series={Series on Optimization},
	publisher={SIAM},
	year={2000},
}

@article{nesterov2006cubic,
	title={{Cubic regularization of {N}ewton method and its global performance}},
	author={Nesterov, Yurii and Polyak, Boris T},
	journal={Mathematical Programming},
	volume={108},
	number={1},
	pages={177--205},
	year={2006},
	publisher={Springer}
}

@article{cartis2011adaptiveI,
	title={{Adaptive cubic regularisation methods for unconstrained optimization. Part I: motivation, convergence and numerical results}},
	author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
	journal={Mathematical Programming},
	volume={127},
	number={2},
	pages={245--295},
	year={2011},
	publisher={Springer}
}

@article{cartis2011adaptiveII,
	title={{Adaptive cubic regularisation methods for unconstrained optimization. Part II: worst-case function-and derivative-evaluation complexity}},
	author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
	journal={Mathematical programming},
	volume={130},
	number={2},
	pages={295--319},
	year={2011},
	publisher={Springer}
}

@article{yao2018inexact,
  title={Inexact non-convex {N}ewton-type methods},
  author={Yao, Zhewei and Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1802.06925},
  year={2018}
}

@article{xuNonconvexTheoretical2017,
	title={{Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian Information}},
	author={Peng Xu and Farbod Roosta-Khorasani and Michael W. Mahoney},
	journal={arXiv preprint arXiv:1708.07164},
	year={2017}
}

@inproceedings{martens2015optimizing,
  title={Optimizing neural networks with {K}ronecker-factored approximate curvature},
  author={Martens, James and Grosse, Roger},
  booktitle={International conference on machine learning},
  pages={2408--2417},
  year={2015}
}

@article{krishnan2017neumann,
  title={Neumann optimizer: A practical optimization algorithm for deep neural networks},
  author={Krishnan, Shankar and Xiao, Ying and Saurous, Rif A},
  journal={arXiv preprint arXiv:1712.03298},
  year={2017}
}

@article{xuNonconvexEmpirical2017,
	title={{Second-Order Optimization for Non-Convex Machine Learning: An Empirical Study}},
	author={Peng Xu and Farbod Roosta-Khorasani and Michael W. Mahoney},
	journal={arXiv preprint arXiv:1708.07827},
	year={2017}
}

@inproceedings{vatanen2013pushing,
  title={Pushing stochastic gradient towards second-order methods--backpropagation learning with transformations in nonlinearities},
  author={Vatanen, Tommi and Raiko, Tapani and Valpola, Harri and LeCun, Yann},
  booktitle={International Conference on Neural Information Processing},
  pages={442--449},
  year={2013},
  organization={Springer}
}

@inproceedings{lecun1991second,
  title={Second order properties of error surfaces: Learning time and generalization},
  author={LeCun, Yann and Kanter, Ido and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={918--924},
  year={1991}
}

@article{sagun2016singularity,
  title={Singularity of the hessian in deep learning},
  author={Sagun, Levent and Bottou, L{\'e}on and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.07476},
  year={2016}
}

@article{dong2019hawqv2,
  title={{HAWQ-V2}: {H}essian {A}ware trace-{W}eighted {Q}uantization of Neural Networks},
  author={Dong, Zhen and Yao, Zhewei and Arfeen, Daiyaan and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  journal={NeurIPS19 workshop on Beyond First-Order Optimization Methods in Machine Learning.},
  year={2019}
}


@article{agarwal2016second,
  title={Second-order stochastic optimization in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={Journal of Machine Learning Research},
  volume={1050},
  pages={15},
  year={2016}
}

@article{dembo1982inexact,
  title={Inexact {N}ewton methods},
  author={Dembo, Ron S and Eisenstat, Stanley C and Steihaug, Trond},
  journal={SIAM Journal on Numerical analysis},
  volume={19},
  number={2},
  pages={400--408},
  year={1982},
  publisher={SIAM}
}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the {H}essian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}

@article{pilanci2017newton,
  title={Newton sketch: A near linear-time optimization algorithm with linear-quadratic convergence},
  author={Pilanci, Mert and Wainwright, Martin J},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={1},
  pages={205--245},
  year={2017},
  publisher={SIAM}
}

@article{pratt1998gauss,
  title={Gauss--{N}ewton and full {N}ewton methods in frequency--space seismic waveform inversion},
  author={Pratt, R Gerhard and Shin, Changsoo and Hick, GJ},
  journal={Geophysical Journal International},
  volume={133},
  number={2},
  pages={341--362},
  year={1998},
  publisher={Blackwell Publishing Ltd Oxford, UK}
}

@article{amari1998natural,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}

@article{bollapragada2018progressive,
  title={A progressive batching {L-BFGS} method for machine learning},
  author={Bollapragada, Raghu and Mudigere, Dheevatsa and Nocedal, Jorge and Shi, Hao-Jun Michael and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1802.05374},
  year={2018}
}

@article{liu1989limited,
  title={On the limited memory {BFGS} method for large scale optimization},
  author={Liu, Dong C and Nocedal, Jorge},
  journal={Mathematical programming},
  volume={45},
  number={1-3},
  pages={503--528},
  year={1989},
  publisher={Springer}
}

@inproceedings{hassibi1993second,
  title={Second order derivatives for network pruning: Optimal brain surgeon},
  author={Hassibi, Babak and Stork, David G},
  booktitle={Advances in neural information processing systems},
  pages={164--171},
  year={1993}
}

@inproceedings{ma2019inefficiency,
  title={Inefficiency of {K-FAC} for Large Batch Size Training},
  author={Ma, Linjian and Montague, Gabe and Ye, Jiayu and Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={Thirty-Fourth AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{lecun1990optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John S and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={598--605},
  year={1990}
}






@article{bordes2009sgd,
  title={SGD-QN: Careful quasi-{N}ewton stochastic gradient descent},
  author={Bordes, Antoine and Bottou, L{\'e}on and Gallinari, Patrick},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Jul},
  pages={1737--1754},
  year={2009}
}



@article{dennis1974characterization,
  title={A characterization of superlinear convergence and its application to quasi-{N}ewton methods},
  author={Dennis, John E and Mor{\'e}, Jorge J},
  journal={Mathematics of computation},
  volume={28},
  number={126},
  pages={549--560},
  year={1974}
}


@article{nocedal1980updating,
  title={Updating quasi-{N}ewton matrices with limited storage},
  author={Nocedal, Jorge},
  journal={Mathematics of computation},
  volume={35},
  number={151},
  pages={773--782},
  year={1980}
}



@inproceedings{schraudolph2007stochastic,
  title={A stochastic quasi-{N}ewton method for online convex optimization},
  author={Schraudolph, Nicol N and Yu, Jin and G{\"u}nter, Simon},
  booktitle={Artificial intelligence and statistics},
  pages={436--443},
  year={2007}
}



@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={International Conference on Learning Representations},
  year={2015}
}

@article{yao2019pyhessian,
  title={PyHessian: Neural Networks Through the Lens of the Hessian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael},
  journal={arXiv preprint arXiv:1912.07145},
  year={2019}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@article{chaudhari2019entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2019},
  number={12},
  pages={124018},
  year={2019},
  publisher={IOP Publishing}
}

@inproceedings{
loshchilov2017decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{you2017large,
  title={Large batch training of convolutional networks},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@inproceedings{you2019large,
  title={Large batch optimization for deep learning: Training bert in 76 minutes},
  author={You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{reddi2019convergence,
  title={On the convergence of adam and beyond},
  author={Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1904.09237},
  year={2019}
}

@inproceedings{
loshchilov2016sgdr,
title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018}
}

@inproceedings{singh2015layer,
  title={Layer-specific adaptive learning rates for deep networks},
  author={Singh, Bharat and De, Soham and Zhang, Yangmuzi and Goldstein, Thomas and Taylor, Gavin},
  booktitle={2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)},
  pages={364--368},
  year={2015},
  organization={IEEE}
}



@inproceedings{wang2018giant,
  title={GIANT: Globally improved approximate Newton method for distributed optimization},
  author={Wang, Shusen and Roosta, Fred and Xu, Peng and Mahoney, Michael W},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2332--2342},
  year={2018}
}

@inproceedings{schaul2013no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle={International Conference on Machine Learning},
  pages={343--351},
  year={2013}
}

@inproceedings{liu2020On,
title={On the Variance of the Adaptive Learning Rate and Beyond},
author={Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{wilson2017marginal,
  title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4148--4158},
  year={2017}
}

@article{zeiler2012adadelta,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{bengio2015rmsprop,
  title={Rmsprop and equilibrated adaptive learning rates for nonconvex optimization},
  author={Bengio, Yoshua},
  journal={corr abs/1502.04390},
  year={2015}
}

@article{bekas2007estimator,
  title={An estimator for the diagonal of a matrix},
  author={Bekas, Costas and Kokiopoulou, Effrosyni and Saad, Yousef},
  journal={Applied numerical mathematics},
  volume={57},
  number={11-12},
  pages={1214--1229},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{ott2018scaling,
  title={Scaling Neural Machine Translation},
  author={Ott, Myle and Edunov, Sergey and Grangier, David and Auli, Michael},
  booktitle={Proceedings of the Third Conference on Machine Translation: Research Papers},
  pages={1--9},
  year={2018}
}

@inproceedings{ott2019fairseq,
  title = {{FairSeq}: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{zhang2019improving,
  title={Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention},
  author={Zhang, Biao and Titov, Ivan and Sennrich, Rico},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={897--908},
  year={2019}
}

@article{zhang2019fixup,
  title={Fixup initialization: Residual learning without normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  journal={arXiv preprint arXiv:1901.09321},
  year={2019}
}


@article{zhang2019adam,
  title={Why ADAM Beats SGD for Attention Models},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank J and Kumar, Sanjiv and Sra, Suvrit},
  journal={arXiv preprint arXiv:1912.03194},
  year={2019}
}

@article{naumov2019deep,
  title={Deep learning recommendation model for personalization and recommendation systems},
  author={Naumov, Maxim and Mudigere, Dheevatsa and Shi, Hao-Jun Michael and Huang, Jianyu and Sundaraman, Narayanan and Park, Jongsoo and Wang, Xiaodong and Gupta, Udit and Wu, Carole-Jean and Azzolini, Alisson G and others},
  journal={arXiv preprint arXiv:1906.00091},
  year={2019}
}

@inproceedings{mikolov2011empirical,
  title={Empirical evaluation and combination of advanced language modeling techniques},
  author={Mikolov, Tom{\'a}{\v{s}} and Deoras, Anoop and Kombrink, Stefan and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan},
  booktitle={Twelfth Annual Conference of the International Speech Communication Association},
  year={2011}
}

@inproceedings{merity2016pointer,
title={Pointer sentinel mixture models},
author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{ma2019tensorized,
  title={A tensorized transformer for language modeling},
  author={Ma, Xindian and Zhang, Peng and Zhang, Shuai and Duan, Nan and Hou, Yuexian and Zhou, Ming and Song, Dawei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2229--2239},
  year={2019}
}

@ONLINE{adahessian,
  title = {https://github.com/amirgholami/ADAHESSIAN.git},
  month = May,
  year = 2020
}

@article{phang2018sentence,
  title={Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks},
  author={Phang, Jason and F{\'e}vry, Thibault and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1811.01088},
  year={2018}
}


@article{iandola2020squeezebert,
  title={SqueezeBERT: What can computer vision teach NLP about efficient neural networks?},
  author={Iandola, Forrest N and Shaw, Albert E and Krishna, Ravi and Keutzer, Kurt W},
  journal={arXiv preprint arXiv:2006.11316},
  year={2020}
}

@article{martens2014new,
  title={New insights and perspectives on the natural gradient method},
  author={Martens, James},
  journal={arXiv preprint arXiv:1412.1193},
  year={2014}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
}


@inproceedings{martens2011learning,
  title={Learning recurrent neural networks with hessian-free optimization},
  author={Martens, James and Sutskever, Ilya},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={1033--1040},
  year={2011},
  organization={Citeseer}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{mcmahan2010adaptive,
  title={Adaptive bound optimization for online convex optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={arXiv preprint arXiv:1002.4908},
  year={2010}
}


@article{bollapragada2019exact,
  title={Exact and inexact subsampled Newton methods for optimization},
  author={Bollapragada, Raghu and Byrd, Richard H and Nocedal, Jorge},
  journal={IMA Journal of Numerical Analysis},
  volume={39},
  number={2},
  pages={545--578},
  year={2019},
  publisher={Oxford University Press}
}


@inproceedings{ge2015escaping,
  title={Escaping from saddle pointsonline stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on Learning Theory},
  pages={797--842},
  year={2015}
}

@inproceedings{jin2017escape,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1724--1732},
  year={2017},
  organization={JMLR. org}
}

@article{levy2016power,
  title={The power of normalization: Faster evasion of saddle points},
  author={Levy, Kfir Y},
  journal={arXiv preprint arXiv:1611.04831},
  year={2016}
}



@article{agarwal2016finding,
  title={Finding approximate local minima for nonconvex optimization in linear time},
  author={Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
  journal={arXiv preprint arXiv:1611.01146},
  year={2016}
}

@article{carmon2018accelerated,
  title={Accelerated methods for nonconvex optimization},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1751--1772},
  year={2018},
  publisher={SIAM}
}
@article{reddi2017generic,
  title={A generic approach for escaping saddle points},
  author={Reddi, Sashank J and Zaheer, Manzil and Sra, Suvrit and Poczos, Barnabas and Bach, Francis and Salakhutdinov, Ruslan and Smola, Alexander J},
  journal={arXiv preprint arXiv:1709.01434},
  year={2017}
}


@article{byrd1995limited,
  title={A limited memory algorithm for bound constrained optimization},
  author={Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  journal={SIAM Journal on scientific computing},
  volume={16},
  number={5},
  pages={1190--1208},
  year={1995},
  publisher={SIAM}
}

@article{gupta2018shampoo,
  title={Shampoo: Preconditioned stochastic tensor optimization},
  author={Gupta, Vineet and Koren, Tomer and Singer, Yoram},
  journal={arXiv preprint arXiv:1802.09568},
  year={2018}
}

@inproceedings{nesterov1983method,
  title={A method for unconstrained convex minimization problem with the rate of convergence O (1/k\^{} 2)},
  author={Nesterov, Yurii},
  booktitle={Doklady an ussr},
  volume={269},
  pages={543--547},
  year={1983}
}

@incollection{wang2017deep,
  title={Deep \& cross network for ad click predictions},
  author={Wang, Ruoxi and Fu, Bin and Fu, Gang and Wang, Mingliang},
  booktitle={Proceedings of the ADKDD'17},
  pages={1--7},
  year={2017},
}

@book{martens2016second,
  title={Second-order optimization for neural networks},
  author={Martens, James},
  year={2016},
  publisher={University of Toronto (Canada)}
}

@inproceedings{wu2019fbnet,
  title={{FBN}et: Hardware-aware efficient convnet design via differentiable neural architecture search},
  author={Wu, Bichen and Dai, Xiaoliang and Zhang, Peizhao and Wang, Yanghan and Sun, Fei and Wu, Yiming and Tian, Yuandong and Vajda, Peter and Jia, Yangqing and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10734--10742},
  year={2019}
}
@article{mishra2017apprentice,
  title={Apprentice: Using knowledge distillation techniques to improve low-precision network accuracy},
  author={Mishra, Asit and Marr, Debbie},
  journal={arXiv preprint arXiv:1711.05852},
  year={2017}
}

@article{chen2019fast,
  title={Fast Evaluation and Approximation of the Gauss-Newton Hessian Matrix for the Multilayer Perceptron},
  author={Chen, Chao and Reiz, Severin and Yu, Chenhan and Bungartz, Hans-Joachim and Biros, George},
  journal={arXiv preprint arXiv:1910.12184},
  year={2019}
}
@article{tan2019efficientnet,
  title={Efficient{N}et: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}
@article{han2017efficient,
  title={Efficient methods and hardware for deep learning},
  author={Han, Song and Dally, B},
  journal={University Lecture},
  year={2017}
}


@inproceedings{yin2020dreaming,
  title={Dreaming to distill: Data-free knowledge transfer via DeepInversion},
  author={Yin, Hongxu and Molchanov, Pavlo and Alvarez, Jose M and Li, Zhizhong and Mallya, Arun and Hoiem, Derek and Jha, Niraj K and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8715--8724},
  year={2020}
}
@inproceedings{yang2017designing,
  title={Designing energy-efficient convolutional neural networks using energy-aware pruning},
  author={Yang, Tien-Ju and Chen, Yu-Hsin and Sze, Vivienne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5687--5695},
  year={2017}
}


@article{yao2020hawqv3,
  title={{HAWQV3}: Dyadic Neural Network Quantization},
  author={Yao, Zhewei and Dong, Zhen and Zheng, Zhangcheng and Gholami, Amir and Yu, Jiali and Tan, Eric and Wang, Leyuan and Huang, Qijing and Wang, Yida and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2011.10680},
  year={2020}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@inproceedings{chen2018tvm,
  title={$\{$TVM$\}$: An automated end-to-end optimizing compiler for deep learning},
  author={Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Shen, Haichen and Cowan, Meghan and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and others},
  booktitle={13th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 18)},
  pages={578--594},
  year={2018}
}

@article{schraudolph1999fast,
  title={A fast, compact approximation of the exponential function},
  author={Schraudolph, Nicol N},
  journal={Neural Computation},
  volume={11},
  number={4},
  pages={853--862},
  year={1999},
  publisher={MIT Press}
}


@techreport{thomas2004libm,
  title={The libm library and floatingpoint arithmetic in HP-UX for Itanium-based systems},
  author={Thomas, James W and Okada, John P and Markstein, Peter and Li, Ren-Chang},
  year={2004},
  institution={Technical report, Hewlett-Packard Company, Palo Alto, CA, USA}
}

@inproceedings{detrey2005parameterized,
  title={A parameterized floating-point exponential function for FPGAs},
  author={Detrey, J{\'e}r{\'e}mie and de Dinechin, Florent},
  booktitle={Proceedings. 2005 IEEE International Conference on Field-Programmable Technology, 2005.},
  pages={27--34},
  year={2005},
  organization={IEEE}
}

@misc{cuda-graph,
  author = {NVIDIA blog},
  title = {{Employing CUDA Graphs in a Dynamic Environment}},
  howpublished = {\url{https://developer.nvidia.com/blog/employing-cuda-graphs-in-a-dynamic-environment/}},
  year = 2021,
  month = Nov
}

@misc{cutlass,
  author = {NVIDIA blog},
  title = {{CUTLASS: Fast Linear Algebra in CUDA C++}},
  howpublished = {\url{https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/}},
  year = 2017,
  month = Dec
}

@inproceedings{kernel-fusion,
  author    = {Guibin Wang and
               Yisong Lin and
               Wei Yi},
  editor    = {Peidong Zhu and
               Lizhe Wang and
               Feng Xia and
               Huajun Chen and
               Ian McLoughlin and
               Shiao{-}Li Tsao and
               Mitsuhisa Sato and
               Sun{-}Ki Chai and
               Irwin King},
  title     = {Kernel Fusion: An Effective Method for Better Power Efficiency on
               Multithreaded {GPU}},
  booktitle = {2010 {IEEE/ACM} Int'l Conference on Green Computing and Communications,
               GreenCom 2010, {\&} Int'l Conference on Cyber, Physical and Social
               Computing, CPSCom 2010, Hangzhou, China, December 18-20, 2010},
  pages     = {344--350},
  publisher = {{IEEE} Computer Society},
  year      = {2010},
  Xurl       = {https://doi.org/10.1109/GreenCom-CPSCom.2010.102},
  Xdoi       = {10.1109/GreenCom-CPSCom.2010.102},
  Xtimestamp = {Mon, 24 Jan 2022 12:58:37 +0100},
  Xbiburl    = {https://dblp.org/rec/conf/greencom/WangLY10.bib},
  Xbibsource = {dblp computer science bibliography, https://dblp.org}
}