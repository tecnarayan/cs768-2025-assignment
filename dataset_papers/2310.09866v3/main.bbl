% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{sener2018multi}
O.~Sener and V.~Koltun, ``Multi-task learning as multi-objective
  optimization,'' \emph{Advances in neural information processing systems},
  vol.~31, 2018.

\bibitem{you2020development}
J.~You, W.~Ampomah, and Q.~Sun, ``Development and application of a machine
  learning based multi-objective optimization workflow for co2-eor projects,''
  \emph{Fuel}, vol. 264, p. 116758, 2020.

\bibitem{zhou2023multi}
T.~Zhou, M.~Momma, C.~Dong, F.~Yang, C.~Guo, J.~Shang, and J.~K. Liu,
  ``Multi-task learning on heterogeneous graph neural network for substitute
  recommendation,'' in \emph{19th International Workshop on Mining and Learning
  with Graphs}, 2023.

\bibitem{shi2019multi}
J.~Shi, J.~Song, B.~Song, and W.~F. Lu, ``Multi-objective optimization design
  through machine learning for drop-on-demand bioprinting,''
  \emph{Engineering}, vol.~5, no.~3, pp. 586--593, 2019.

\bibitem{mlltr2023kdd}
D.~Mahapatra, C.~Dong, Y.~Chen, and M.~Momma, ``Multi-label learning to rank
  through multi-objective optimization,'' in \emph{Proceedings of the 29th ACM
  SIGKDD International Conference on Knowledge Discovery and Data Mining},
  2023.

\bibitem{querymlltr2023kdd}
D.~Mahapatra, C.~Dong, and M.~Momma, ``Querywise fair learning to rank through
  multi-objective optimization,'' in \emph{Proceedings of the 29th ACM SIGKDD
  Conference on Knowledge Discovery and Data Mining}, 2023.

\bibitem{momma2020multi}
M.~Momma, A.~Bagheri~Garakani, N.~Ma, and Y.~Sun, ``Multi-objective ranking via
  constrained optimization,'' in \emph{Companion Proceedings of the Web
  Conference 2020}, 2020, pp. 111--112.

\bibitem{fliege2019complexity}
J.~Fliege, A.~I.~F. Vaz, and L.~N. Vicente, ``Complexity of gradient descent
  for multiobjective optimization,'' \emph{Optimization Methods and Software},
  vol.~34, no.~5, pp. 949--959, 2019.

\bibitem{liu2021stochastic}
S.~Liu and L.~N. Vicente, ``The stochastic multi-gradient algorithm for
  multi-objective optimization and its application to supervised machine
  learning,'' \emph{Annals of Operations Research}, pp. 1--30, 2021.

\bibitem{zhang2007moea}
Q.~Zhang and H.~Li, ``Moea/d: A multiobjective evolutionary algorithm based on
  decomposition,'' \emph{IEEE Transactions on evolutionary computation},
  vol.~11, no.~6, pp. 712--731, 2007.

\bibitem{deb2002fast}
K.~Deb, A.~Pratap, S.~Agarwal, and T.~Meyarivan, ``A fast and elitist
  multiobjective genetic algorithm: Nsga-ii,'' \emph{IEEE transactions on
  evolutionary computation}, vol.~6, no.~2, pp. 182--197, 2002.

\bibitem{belakaria2020uncertainty}
S.~Belakaria, A.~Deshwal, N.~K. Jayakodi, and J.~R. Doppa, ``Uncertainty-aware
  search framework for multi-objective bayesian optimization,'' in
  \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  vol.~34, 2020, pp. 10\,044--10\,052.

\bibitem{laumanns2002bayesian}
M.~Laumanns and J.~Ocenasek, ``Bayesian optimization algorithms for
  multi-objective optimization,'' in \emph{International Conference on Parallel
  Problem Solving from Nature}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2002, pp. 298--307.

\bibitem{fliege2000steepest}
J.~Fliege and B.~F. Svaiter, ``Steepest descent methods for multicriteria
  optimization,'' \emph{Mathematical methods of operations research}, vol.~51,
  no.~3, pp. 479--494, 2000.

\bibitem{desideri2012multiple}
J.-A. D{\'e}sid{\'e}ri, ``Multiple-gradient descent algorithm (mgda) for
  multiobjective optimization,'' \emph{Comptes Rendus Mathematique}, vol. 350,
  no. 5-6, pp. 313--318, 2012.

\bibitem{peitz2018gradient}
S.~Peitz and M.~Dellnitz, ``Gradient-based multiobjective optimization with
  uncertainties,'' in \emph{NEO 2016}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2018, pp. 159--182.

\bibitem{michipmtl2022}
M.~Momma, C.~Dong, and J.~Liu, ``A multi-objective / multi-task learning
  framework induced by pareto stationarity,'' in \emph{Proceedings of the 39th
  International Conference on Machine Learning}, 2022.

\bibitem{zhou2022on}
\BIBentryALTinterwordspacing
S.~Zhou, W.~Zhang, J.~Jiang, W.~Zhong, J.~GU, and W.~Zhu, ``On the convergence
  of stochastic multi-objective gradient manipulation and beyond,'' in
  \emph{Advances in Neural Information Processing Systems}, A.~H. Oh,
  A.~Agarwal, D.~Belgrave, and K.~Cho, Eds., 2022. [Online]. Available:
  \url{https://openreview.net/forum?id=ScwfQ7hdwyP}
\BIBentrySTDinterwordspacing

\bibitem{fernando2022mitigating}
H.~Fernando, H.~Shen, M.~Liu, S.~Chaudhury, K.~Murugesan, and T.~Chen,
  ``Mitigating gradient bias in multi-objective learning: A provably convergent
  stochastic approach,'' \emph{arXiv preprint arXiv:2210.12624}, 2022.

\bibitem{xiao2023direction}
P.~Xiao, H.~Ban, and K.~Ji, ``Direction-oriented multi-objective learning:
  Simple and provable stochastic algorithms,'' \emph{arXiv preprint
  arXiv:2305.18409}, 2023.

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas,
  ``Communication-efficient learning of deep networks from decentralized
  data,'' in \emph{Artificial intelligence and statistics}.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 2017, pp. 1273--1282.

\bibitem{li2020fedprox}
T.~Li, A.~K. Sahu, M.~Zaheer, M.~Sanjabi, A.~Talwalkar, and V.~Smith,
  ``Federated optimization in heterogeneous networks,'' in \emph{Proceedings of
  Machine Learning and Systems}, I.~Dhillon, D.~Papailiopoulos, and V.~Sze,
  Eds., vol.~2, 2020, pp. 429--450.

\bibitem{acar2021feddyn}
D.~A.~E. Acar, Y.~Zhao, R.~M. Navarro, M.~Mattina, P.~N. Whatmough, and
  V.~Saligrama, ``Federated learning based on dynamic regularization,'' in
  \emph{International Conference on Learning Representations}, 2021.

\bibitem{wang2020fednova}
J.~Wang, Q.~Liu, H.~Liang, G.~Joshi, and H.~V. Poor, ``Tackling the objective
  inconsistency problem in heterogeneous federated optimization,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{lin2018don}
\BIBentryALTinterwordspacing
T.~Lin, S.~U. Stich, K.~K. Patel, and M.~Jaggi, ``Don't use large mini-batches,
  use local sgd,'' in \emph{International Conference on Learning
  Representations}, 2020. [Online]. Available:
  \url{https://openreview.net/forum?id=B1eyO1BFPr}
\BIBentrySTDinterwordspacing

\bibitem{yang2022taming}
\BIBentryALTinterwordspacing
H.~Yang, P.~Qiu, and J.~Liu, ``Taming fat-tailed
  ({\textquotedblleft}heavier-tailed{\textquotedblright} with potentially
  infinite variance) noise in federated learning,'' in \emph{Advances in Neural
  Information Processing Systems}, A.~H. Oh, A.~Agarwal, D.~Belgrave, and
  K.~Cho, Eds., 2022. [Online]. Available:
  \url{https://openreview.net/forum?id=8SilFGuXgmk}
\BIBentrySTDinterwordspacing

\bibitem{Karimireddy2020SCAFFOLD}
S.~P. Karimireddy, S.~Kale, M.~Mohri, S.~Reddi, S.~Stich, and A.~T. Suresh,
  ``{SCAFFOLD}: Stochastic controlled averaging for federated learning,'' in
  \emph{Proceedings of the 37th International Conference on Machine Learning},
  ser. Proceedings of Machine Learning Research, H.~D. III and A.~Singh, Eds.,
  vol. 119.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 13--18 Jul 2020, pp.
  5132--5143.

\bibitem{yang2021linearspeedup}
H.~Yang, M.~Fang, and J.~Liu, ``Achieving linear speedup with partial worker
  participation in non-{IID} federated learning,'' in \emph{International
  Conference on Learning Representations}, 2021.

\bibitem{yang2022anarchic}
H.~Yang, X.~Zhang, P.~Khanduri, and J.~Liu, ``Anarchic federated learning,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2022, pp. 25\,331--25\,363.

\bibitem{Zhang2022NETFLEETAL}
X.~Zhang, M.~Fang, Z.~Liu, H.~Yang, J.~Liu, and Z.~Zhu, ``Net-fleet: achieving
  linear convergence speedup for fully decentralized federated learning with
  heterogeneous data,'' \emph{Proceedings of the Twenty-Third International
  Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile
  Networks and Mobile Computing}, 2022.

\bibitem{yang2022sagda}
\BIBentryALTinterwordspacing
H.~Yang, Z.~Liu, X.~Zhang, and J.~Liu, ``{SAGDA}: Achieving
  $\mathcal{O}(\epsilon^{-2})$ communication complexity in federated min-max
  learning,'' in \emph{Advances in Neural Information Processing Systems},
  A.~H. Oh, A.~Agarwal, D.~Belgrave, and K.~Cho, Eds., 2022. [Online].
  Available: \url{https://openreview.net/forum?id=wTp4KgVIJ5}
\BIBentrySTDinterwordspacing

\bibitem{sharma2022federated}
P.~Sharma, R.~Panda, G.~Joshi, and P.~Varshney, ``Federated minimax
  optimization: Improved convergence analyses and algorithms,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2022, pp. 19\,683--19\,730.

\bibitem{khodadadian2022federated}
S.~Khodadadian, P.~Sharma, G.~Joshi, and S.~T. Maguluri, ``Federated
  reinforcement learning: Linear speedup under markovian sampling,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2022, pp. 10\,997--11\,057.

\bibitem{shi2021federated}
C.~Shi, C.~Shen, and J.~Yang, ``Federated multi-armed bandits with
  personalization,'' in \emph{International Conference on Artificial
  Intelligence and Statistics}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2021, pp. 2917--2925.

\bibitem{pmlr-v162-tarzanagh22a}
D.~A. Tarzanagh, M.~Li, C.~Thrampoulidis, and S.~Oymak, ``{F}ed{N}est:
  Federated bilevel, minimax, and compositional optimization,'' in
  \emph{Proceedings of the 39th International Conference on Machine Learning},
  ser. Proceedings of Machine Learning Research, K.~Chaudhuri, S.~Jegelka,
  L.~Song, C.~Szepesvari, G.~Niu, and S.~Sabato, Eds., vol. 162.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 17--23 Jul 2022, pp. 21\,146--21\,179.

\bibitem{hu2022federated}
Z.~Hu, K.~Shaloudegi, G.~Zhang, and Y.~Yu, ``Federated learning meets
  multi-objective optimization,'' \emph{IEEE Transactions on Network Science
  and Engineering}, 2022.

\bibitem{miettinen2012nonlinear}
K.~Miettinen, \emph{Nonlinear multiobjective optimization}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer Science \& Business Media, 2012, vol.~12.

\bibitem{lin2019pareto}
X.~Lin, H.-L. Zhen, Z.~Li, Q.-F. Zhang, and S.~Kwong, ``Pareto multi-task
  learning,'' \emph{Advances in neural information processing systems},
  vol.~32, 2019.

\bibitem{yang2022pareto}
\BIBentryALTinterwordspacing
Y.~Yang, J.~Jiang, T.~Zhou, J.~Ma, and Y.~Shi, ``Pareto policy pool for
  model-based offline reinforcement learning,'' in \emph{International
  Conference on Learning Representations}, 2022. [Online]. Available:
  \url{https://openreview.net/forum?id=OqcZu8JIIzS}
\BIBentrySTDinterwordspacing

\bibitem{blondin2021decentralized}
M.~J. Blondin and M.~Hale, ``A decentralized multi-objective optimization
  algorithm,'' \emph{Journal of Optimization Theory and Applications}, vol.
  189, no.~2, pp. 458--485, 2021.

\bibitem{bui2009local}
L.~T. Bui, H.~A. Abbass, and D.~Essam, ``Local models—an approach to
  distributed multi-objective optimization,'' \emph{Computational Optimization
  and Applications}, vol.~42, no.~1, pp. 105--139, 2009.

\bibitem{cui2021addressing}
S.~Cui, W.~Pan, J.~Liang, C.~Zhang, and F.~Wang, ``Addressing algorithmic
  disparity and performance inconsistency in federated learning,''
  \emph{Advances in Neural Information Processing Systems}, vol.~34, pp.
  26\,091--26\,102, 2021.

\bibitem{mehrabi2022towards}
N.~Mehrabi, C.~de~Lichy, J.~McKay, C.~He, and W.~Campbell, ``Towards
  multi-objective statistically fair federated learning,'' \emph{arXiv preprint
  arXiv:2201.09917}, 2022.

\bibitem{saber2020comparative}
T.~Saber, X.~Gandibleux, M.~O’Neill, L.~Murphy, and A.~Ventresque, ``A
  comparative study of multi-objective machine reassignment algorithms for data
  centres,'' \emph{Journal of Heuristics}, vol.~26, no.~1, pp. 119--150, 2020.

\bibitem{yin2021analytical}
L.~Yin, T.~Wang, and B.~Zheng, ``Analytical adaptive distributed
  multi-objective optimization algorithm for optimal power flow problems,''
  \emph{Energy}, vol. 216, p. 119245, 2021.

\bibitem{jin2006multi}
Y.~Jin, \emph{Multi-objective machine learning}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer Science \& Business Media, 2006, vol.~16.

\bibitem{ali2023}
A.~Mansoor, X.~Diao, and C.~Smidts, ``A method for backward failure propagation
  in conceptual system design,'' \emph{Nuclear Science and Engineering}, 2023.

\bibitem{ali2021}
A.~Mansoor, X.~Diao, and Smidts, ``Backward failure propagation for conceptual
  system design using isfa,'' 11 2021.

\bibitem{ghadimi2013stochastic}
S.~Ghadimi and G.~Lan, ``Stochastic first-and zeroth-order methods for
  nonconvex stochastic programming,'' \emph{SIAM Journal on Optimization},
  vol.~23, no.~4, pp. 2341--2368, 2013.

\bibitem{bottou2018optimization}
L.~Bottou, F.~E. Curtis, and J.~Nocedal, ``Optimization methods for large-scale
  machine learning,'' \emph{Siam Review}, vol.~60, no.~2, pp. 223--311, 2018.

\bibitem{mcmahan2021fl}
H.~B. McMahan \emph{et~al.}, ``Advances and open problems in federated
  learning,'' \emph{Foundations and Trends{\textregistered} in Machine
  Learning}, vol.~14, no.~1, 2021.

\bibitem{wang2021field}
J.~Wang, Z.~Charles, Z.~Xu, G.~Joshi, H.~B. McMahan, M.~Al-Shedivat, G.~Andrew,
  S.~Avestimehr, K.~Daly, D.~Data \emph{et~al.}, ``A field guide to federated
  optimization,'' \emph{arXiv preprint arXiv:2107.06917}, 2021.

\bibitem{sabour2017dynamic}
S.~Sabour, N.~Frosst, and G.~E. Hinton, ``Dynamic routing between capsules,''
  \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{nie2017image}
L.~Nie, K.~Wang, W.~Kang, and Y.~Gao, ``Image retrieval with
  attribute-associated auxiliary references,'' in \emph{2017 International
  Conference on Digital Image Computing: Techniques and Applications
  (DICTA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 1--6.

\bibitem{liu2015deep}
Z.~Liu, P.~Luo, X.~Wang, and X.~Tang, ``Deep learning face attributes in the
  wild,'' in \emph{Proceedings of the IEEE international conference on computer
  vision}, 2015, pp. 3730--3738.

\bibitem{mercier2018stochastic}
Q.~Mercier, F.~Poirion, and J.-A. D{\'e}sid{\'e}ri, ``A stochastic multiple
  gradient descent algorithm,'' \emph{European Journal of Operational
  Research}, vol. 271, no.~3, pp. 808--817, 2018.

\bibitem{lecun2010mnist}
Y.~LeCun, C.~Cortes, and C.~Burges, ``Mnist handwritten digit database,''
  \emph{Available: http://yann. lecun. com/exdb/mnist}, 1998.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition. cvpr. 2016,'' \emph{arXiv preprint arXiv:1512.03385}, 2016.

\end{thebibliography}
